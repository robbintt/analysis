---
ver: rpa2
title: Deep Variational Contrastive Learning for Joint Risk Stratification and Time-to-Event
  Estimation
arxiv_id: '2602.01367'
source_url: https://arxiv.org/abs/2602.01367
tags:
- survival
- learning
- risk
- deep
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the trade-off between predictive performance
  and interpretability in survival analysis by proposing CONVERSE, a deep survival
  model that unifies variational autoencoders with contrastive learning for interpretable
  risk stratification. The method combines variational embeddings with multiple intra-
  and inter-cluster contrastive losses, using self-paced learning for training stability
  and cluster-specific survival heads for ensemble predictions.
---

# Deep Variational Contrastive Learning for Joint Risk Stratification and Time-to-Event Estimation

## Quick Facts
- arXiv ID: 2602.01367
- Source URL: https://arxiv.org/abs/2602.01367
- Authors: Pinar Erbil; Alberto Archetti; Eugenio Lomurno; Matteo Matteucci
- Reference count: 28
- Primary result: Achieves competitive/surpassing performance on four benchmark datasets, with C-Index improvements of +0.70% over cluster-based approaches and IBS improvements of +1.63%

## Executive Summary
CONVERSE unifies variational autoencoders with contrastive learning to enable interpretable risk stratification in survival analysis. The model learns patient clusters in a regularized latent space while jointly predicting time-to-event outcomes, addressing the interpretability-performance trade-off. Evaluation on breast cancer and cardiovascular datasets shows the method achieves state-of-the-art discrimination while providing clinically meaningful stratification aligned with established prognostic factors.

## Method Summary
CONVERSE uses a three-stage training procedure: (1) pre-train a single or Siamese VAE with survival head using reconstruction, KL, and survival losses; (2) initialize clusters in the frozen latent space using K-means/GMM/spectral methods; (3) refine end-to-end with self-paced learning incorporating easy-to-hard samples. The model combines variational embeddings with three contrastive losses (IVCG, IVIW, IVCW) and supports both shared and cluster-specific survival heads. Hyperparameter optimization via Optuna searches over architectures, loss weights, and clustering algorithms across 5 bootstrap splits.

## Key Results
- Achieves competitive or superior performance compared to existing deep survival methods on four benchmark datasets
- C-Index improvements of +0.70% over cluster-based approaches and IBS improvements of +1.63%
- Provides clinically meaningful stratification, with clusters corresponding to hormone receptor status, tumor size, and age in breast cancer datasets

## Why This Works (Mechanism)

### Mechanism 1
Variational autoencoders with KL regularization learn smoother, more generalizable latent representations than deterministic autoencoders for survival tasks. The KL divergence constraint forces the approximate posterior toward a standard Gaussian prior, preventing memorization and encouraging contiguous latent regions that cluster meaningfully. Core assumption: Gaussian prior matches true latent distribution. Break condition: High latent dimensionality relative to sample size may yield uninformative spherical Gaussians.

### Mechanism 2
Multi-objective contrastive learning aligns latent representations with survival-relevant structure by pulling same-cluster uncensored patients together and pushing different-cluster patients apart. Three losses operate jointly: IVCG uses uncensored patients in same cluster as positives for censored anchors, transferring survival signal; IVIW enforces view-consistency in Siamese encoders; IVCW aligns soft cluster assignments across views via Student's t-distribution confidences. Core assumption: Patients sharing a cluster have similar latent representations regardless of censoring status. Break condition: Unstable cluster assignments early in training may reinforce incorrect groupings.

### Mechanism 3
Self-paced learning stabilizes training by filtering out high-loss boundary samples during early epochs, then gradually admitting harder instances. An adaptive threshold excludes samples with loss above threshold from optimization, with the threshold increasing over epochs to incorporate harder cases once representations stabilize. Core assumption: Easy samples (low reconstruction + clustering loss) are more reliable for initial representation learning than boundary cases. Break condition: Poorly calibrated loss weighting may result in the "easy" subset not reflecting true representation quality.

## Foundational Learning

- **Concept: Survival Analysis with Censoring**
  - Why needed here: The model must handle right-censored patients while learning from their partial information
  - Quick check question: Given a patient censored at t=5 years with no event, can you explain why they contribute to the likelihood but not the ranking loss?

- **Concept: Variational Autoencoder (ELBO Objective)**
  - Why needed here: CONVERSE uses VAEs rather than standard autoencoders; understanding the reconstruction-KL trade-off is essential for tuning α weights
  - Quick check question: What happens to latent space structure if α_KLD is set too high relative to α_REC?

- **Concept: InfoNCE Contrastive Loss**
  - Why needed here: All three contrastive objectives use InfoNCE formulation; temperature τ directly controls hard vs. soft negatives
  - Quick check question: If temperature τ → 0, how does the gradient behavior change for negative pairs?

## Architecture Onboarding

- **Component map:**
  Encoder(s) -> Clustering -> Contrastive module -> Survival heads -> Loss combiner

- **Critical path:**
  1. Stage 1: Autoencoder + survival head jointly optimize L_REC + L_KLD + L_SURV (no clustering)
  2. Stage 2: Run clustering algorithm on frozen latent representations → initialize centers M
  3. Stage 3: Full optimization with L_SPL + L_CL + L_SURV; reassign clusters each epoch

- **Design tradeoffs:**
  - Single vs. Siamese encoder: Siamese adds IVIW and IVCW losses but doubles parameters
  - Shared vs. cluster-specific heads: Specialized heads capture subpopulation dynamics but require more data per cluster
  - Clustering algorithm: K-means is fast but assumes spherical clusters; GMM handles ellipsoidal but requires covariance estimation
  - **Assumption:** The hyperparameter optimization is computationally expensive but necessary for dataset-specific configuration

- **Failure signatures:**
  - Clusters collapse to single group (K effective = 1): Check contrastive loss weights; IVCG may be too weak
  - C-Index high but IBS poor: Survival heads overfitting; increase β ranking loss weight
  - Training instability after Stage 2: SPL threshold may be excluding too many samples; verify λ_e progression
  - Latent space unstructured (UMAP shows no separation): Pre-training insufficient; increase Stage 1 epochs

- **First 3 experiments:**
  1. **Ablation on encoder type:** Compare single VAE vs. Siamese VAE on METABRIC with fixed K=2, measuring C-Index and cluster separation. Expect Siamese to improve when multi-view signal is informative.
  2. **SPL sensitivity analysis:** Vary the linear term coefficient in λ_e across {0.5, 1.0, 2.0} on GBSG. Monitor epoch-wise loss variance and final performance.
  3. **Head architecture comparison:** On TCGA_BRCA, compare shared head vs. cluster-specific heads with K ∈ {2, 4, 6}. Expect cluster-specific to help when K matches true subpopulations; degradation if K exceeds data support.

## Open Questions the Paper Calls Out

### Open Question 1
Can the calibration degradation observed on METABRIC for patients near cluster boundaries be mitigated without sacrificing interpretability? The paper identifies this as a fundamental trade-off but does not propose mechanisms to address boundary uncertainty. Development of boundary-aware weighting schemes or uncertainty quantification methods that improve IBS on METABRIC while maintaining cluster separation would resolve this.

### Open Question 2
Does CONVERSE generalize to clinical domains beyond breast cancer and cardiovascular survival analysis? Evaluation is limited to three breast cancer datasets and one cardiovascular dataset. Evaluation on diverse clinical datasets (e.g., oncology beyond breast cancer, chronic diseases, or competing risks scenarios) showing comparable performance gains would resolve this.

### Open Question 3
Can the optimal number of clusters be determined automatically rather than fixed a priori? The interpretability analysis fixes K=2 but does not explore adaptive cluster selection. Integration of non-parametric Bayesian methods or elbow/silhouette-based automatic selection demonstrating improved or equivalent performance without manual tuning would resolve this.

## Limitations

- **Architecture specifications**: Exact encoder/decoder dimensions, activation functions, and survival head architectures are unspecified, requiring assumptions in reproduction
- **Hyperparameter ranges**: Optuna search spaces for learning rates, batch sizes, time bins, and loss weight ranges are not provided, potentially affecting performance reproducibility
- **Dataset preprocessing details**: Specific handling of missing values, outlier treatment, or feature selection criteria remain unclear
- **SPL parameter sensitivity**: The self-paced learning mechanism depends on σ, ν, and Emax values not reported, which could significantly impact training stability

## Confidence

- **High confidence**: The overall framework combining VAEs with contrastive learning is theoretically sound and supported by the ablation showing cluster-specific survival heads improve performance
- **Medium confidence**: The claimed C-Index (+0.70%) and IBS (+1.63%) improvements are based on limited benchmark comparisons; the actual gain magnitude depends on hyperparameter optimization quality
- **Medium confidence**: The clinical interpretability claim (clusters aligning with hormone receptor status, tumor size, age) is plausible but not quantitatively validated with clinical metrics

## Next Checks

1. **Architecture sensitivity test**: Fix all hyperparameters at optimal values, then vary only encoder depth (1-3 hidden layers) and latent dimension (32-128) to establish baseline sensitivity
2. **SPL threshold analysis**: Implement λ_e tracking across epochs and compare final performance with/without SPL to quantify its contribution to stability
3. **Cluster quality validation**: Beyond C-Index/IBS, measure cluster separation (silhouette score) and concordance between predicted clusters and known clinical covariates (e.g., hormone receptor status) on METABRIC