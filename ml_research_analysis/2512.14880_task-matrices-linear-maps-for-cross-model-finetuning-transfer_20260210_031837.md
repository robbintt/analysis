---
ver: rpa2
title: 'Task Matrices: Linear Maps for Cross-Model Finetuning Transfer'
arxiv_id: '2512.14880'
source_url: https://arxiv.org/abs/2512.14880
tags:
- task
- matrix
- linear
- vision
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces task matrices, a method for efficient cross-model
  transfer learning by learning linear transformations between base and fine-tuned
  model representations. The authors demonstrate that these linear mappings can effectively
  approximate fine-tuned model performance across diverse vision and text tasks, often
  approaching or surpassing linear probe baselines while requiring minimal data and
  computational resources.
---

# Task Matrices: Linear Maps for Cross-Model Finetuning Transfer

## Quick Facts
- arXiv ID: 2512.14880
- Source URL: https://arxiv.org/abs/2512.14880
- Reference count: 31
- Primary result: Linear transformations between base and fine-tuned model representations can effectively approximate fine-tuned performance across vision and text tasks with minimal data.

## Executive Summary
This paper introduces task matrices, a method for efficient cross-model transfer learning that learns linear transformations between base and fine-tuned model representations. The authors demonstrate that these linear mappings can effectively approximate fine-tuned model performance across diverse vision and text tasks, often approaching or surpassing linear probe baselines while requiring minimal data and computational resources. Task matrices exhibit robustness in data-scarce settings, generalize across multiple tasks, and achieve competitive results on datasets like RoBERTa for text classification and CLIP ViT B-32 for vision tasks. The approach is validated through extensive experiments, showing consistent improvements over baselines and establishing the feasibility of leveraging linear relationships for domain adaptation.

## Method Summary
Task matrices learn linear transformations (W*) that map intermediate-layer base model embeddings to final-layer fine-tuned embeddings via least-squares regression. The method extracts [CLS] tokens from a specific base model layer and the fine-tuned model's final layer, then solves W* = argmin ||WX - Y||². At inference, base embeddings are transformed with W* and passed to the fine-tuned classifier head. The approach requires minimal data, exhibits double descent near embedding dimension, and shows optimal layer selection varies by modality (vision benefits from later layers, text from middle layers).

## Key Results
- Task matrices approach or surpass linear probe baselines across diverse vision and text classification tasks
- Data-scarce performance shows 82% improvement on ATIS and 81% on Trec-6 compared to linear probes
- Layer selection is task-dependent: vision tasks peak at later layers, text at intermediate layers (4-10 for RoBERTa)
- Multi-task matrices compress 8 datasets from 92% to 81% accuracy, demonstrating compression capabilities

## Why This Works (Mechanism)

### Mechanism 1: Cross-Layer Linear Encoding
The task matrix W* approximates the mapping from base model intermediate representations to fine-tuned final representations through least-squares regression. This works because fine-tuning primarily reinterprets existing intermediate-layer representations rather than constructing entirely new structures. The method assumes that for some layer i, there exists a matrix W such that Wx ≈ y for all pairs (x,y) in base and fine-tuned spaces. This linear substructure assumption is supported by related work on linear representation in transformers.

### Mechanism 2: Layer-Specific Decodability Gradients
Optimal source layer varies by modality due to different concentrations of task-relevant information at different depths. Vision tasks benefit from later layers while text benefits from middle layers (4-10 for RoBERTa) because task-relevant attributes are "enriched" at predictable layer positions. This is supported by observations that enriched subject representations containing key attributes appear prior to the last layer in transformers.

### Mechanism 3: Data-Efficient Regression with Double Descent
Task matrices can be learned with minimal data (sometimes <10 samples) but exhibit double descent near the embedding dimension (768 for CLIP). The least-squares solution becomes unstable when sample count approaches embedding dimensionality, then stabilizes with overdetermined systems. This occurs because the underlying linear relationship is sufficiently low-rank that early convergence happens before full dataset utilization.

## Foundational Learning

- **Concept: Least-Squares Regression with Closed-Form Solution**
  - Why needed here: The task matrix is computed analytically; understanding when solutions are unique vs. underdetermined is critical.
  - Quick check question: Can you explain why sample count equal to embedding dimension creates a unique but potentially unstable solution?

- **Concept: Transformer Layer Representations ([CLS] Token Extraction)**
  - Why needed here: The method extracts [CLS] tokens from specific layers; understanding what these represent determines layer selection strategy.
  - Quick check question: What does the [CLS] token encode differently at layer 4 vs. layer 11 in a 12-layer transformer?

- **Concept: Linear Probing vs. Feature Transformation**
  - Why needed here: The baseline comparison distinguishes learning a new classifier head from learning a representation transformation.
  - Quick check question: Why would transforming embeddings to match a fine-tuned space outperform training a new classifier on base embeddings?

## Architecture Onboarding

- **Component map:**
  Base Model (frozen) → Layer i extraction → Task Matrix W* → Fine-tuned classifier head → Prediction

- **Critical path:**
  1. Run inference on training data with BOTH base and fine-tuned models
  2. Extract [CLS] tokens from base intermediate layer(s) and fine-tuned final layer
  3. Solve W* = argmin ||WX - Y||² (closed-form via pseudo-inverse)
  4. At inference: transform base embeddings, pass to fine-tuned head

- **Design tradeoffs:**
  - **Layer selection:** Earlier layers capture more general features; later layers more task-specific. Paper shows no universal optimal layer—requires per-dataset sweep.
  - **Frozen vs. adapted head:** Frozen head works (Table 6) but requires the head be trained with frozen backbone during fine-tuning.
  - **Multi-task matrix:** Joint training trades single-task accuracy for compression; accuracy drops from 92%→81% across 8 datasets.

- **Failure signatures:**
  - Performance collapses to near-random when using wrong layer (e.g., early layers for high-class-count datasets)
  - Double descent dip when training samples ≈ embedding dimension
  - Linear probe outperforms task matrix → suggests non-linear transformation required (seen in some DINOv3 experiments, Table 14-15)

- **First 3 experiments:**
  1. **Single-layer sweep:** On a held-out validation set, test task matrix performance for each layer (0 to L) to identify optimal source layer for your specific model/task combination.
  2. **Data scaling curve:** Plot accuracy vs. training samples used for matrix construction (start at 10 samples, scale to full dataset) to identify minimum viable data regime.
  3. **Ablation—head only baseline:** Pass base model final-layer embeddings directly to fine-tuned classifier head (no transformation) to confirm the matrix provides signal beyond the adapted head.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can non-linear or iterative approximation techniques outperform least-squares regression in constructing task matrices?
- Basis in paper: Footnote 1 states, "Other approximation techniques, including those seen in Hernandez et al. (2023), are promising avenues for future work," noting that Ridge regression did not yield improvements.
- Why unresolved: The paper exclusively relies on least-squares loss to solve for W*, leaving the potential performance gains of more complex solvers untested.
- What evidence would resolve it: Comparative benchmarks showing task matrix accuracy when constructed via iterative refinement or non-linear mapping techniques versus the standard regression approach.

### Open Question 2
- Question: Does the "middle-layer enrichment" hypothesis explain why task matrices underperform on specific architectures like DINOv3?
- Basis in paper: Regarding DINOv3 results, the authors "posit the task matrix's lower performance to DINOv3 ViT-B/16's strong pre-trained backbone, and the lack of middle-layer enrichment."
- Why unresolved: This is presented as a hypothesis for negative results rather than a tested mechanism; the specific internal features of DINOv3 were not analyzed to confirm this lack of enrichment.
- What evidence would resolve it: A layer-wise analysis of DINOv3 representations compared to CLIP, specifically correlating the presence or absence of "enriched" attributes with task matrix efficacy.

### Open Question 3
- Question: Why do shallow networks demonstrate reduced approximation efficacy for task matrices?
- Basis in paper: The authors mention they "focused on architectures with sufficient depth, as shallow networks demonstrated reduced approximation efficacy" without providing a causal explanation.
- Why unresolved: It is unclear if the failure is due to insufficient dimensionality for linear separation or a fundamental non-linearity in shallow adaptations.
- What evidence would resolve it: Ablation studies varying model depth while controlling for embedding size to identify the minimum depth required for the linearity assumption to hold.

## Limitations

- The core assumption that fine-tuning learns primarily linear transformations of intermediate representations lacks direct empirical validation across diverse model architectures
- High-dimensional classification tasks with many classes (SUN397 with 397 classes, Stanford Cars with 196) show reduced intermediate linearities, limiting effectiveness for fine-grained recognition
- Optimal source layer varies by task and modality, requiring per-dataset sweeps that may not scale efficiently

## Confidence

**High Confidence (9/10):** The task matrix methodology is mathematically sound, with clear closed-form solutions for linear regression. The experimental results showing consistent improvements over linear probe baselines across diverse datasets are well-documented and reproducible. The double descent phenomenon near embedding dimensionality is clearly observed in the data scaling experiments.

**Medium Confidence (6/10):** The claim that task matrices approach or surpass fully fine-tuned baselines, particularly in data-scarce settings, is supported by the experimental results but would benefit from more extensive ablation studies across additional model architectures and tasks. The mechanism explaining why different modalities benefit from different source layers is plausible but lacks comprehensive theoretical grounding.

**Low Confidence (4/10):** The assertion that task matrices can achieve "near full fine-tuning performance" across all tested datasets is qualified by the observation that high-class-count tasks show reduced effectiveness. The multi-task matrix approach, while innovative, shows significant performance degradation (92%→81% across 8 datasets), suggesting limitations for compression applications.

## Next Checks

1. **Layer Generalization Test:** Apply task matrices across multiple fine-tuned models on the same dataset to determine if the optimal source layer is consistent across different fine-tuning approaches, or if it's specific to the fine-tuning methodology used in the paper.

2. **Regularization Impact Study:** Systematically test different regularization techniques (Ridge, Lasso, Elastic Net) across the full range of sample sizes to determine if any can mitigate the double descent instability observed near embedding dimension, particularly for high-dimensional tasks.

3. **Architecture Transferability Experiment:** Apply the task matrix approach to non-transformer architectures (e.g., ConvNeXt for vision, RNNs for text) to test whether the linear encoding hypothesis holds across different model families, or if it's specific to transformer-based architectures.