---
ver: rpa2
title: LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition
arxiv_id: '2512.22385'
source_url: https://arxiv.org/abs/2512.22385
tags:
- activity
- exemplar
- selection
- semantic
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study proposes an LLM-Guided Exemplar Selection framework for
  few-shot wearable-sensor human activity recognition. It integrates semantic reasoning
  from LLMs with geometric and structural cues to improve exemplar selection, addressing
  limitations of purely geometric methods.
---

# LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition

## Quick Facts
- **arXiv ID:** 2512.22385
- **Source URL:** https://arxiv.org/abs/2512.22385
- **Reference count:** 40
- **Primary result:** LLM-guided exemplar selection framework for few-shot HAR achieving 88.78% macro F1-score on UCI-HAR

## Executive Summary
This paper introduces an LLM-guided exemplar selection framework for few-shot human activity recognition (HAR) using wearable sensors. The method integrates semantic reasoning from large language models with geometric and structural cues to improve exemplar selection, addressing limitations of purely geometric approaches. Evaluated on the UCI-HAR dataset, the framework demonstrates superior performance compared to baselines like random sampling and k-center methods, while maintaining computational efficiency.

## Method Summary
The framework combines semantic priors from LLMs with geometric and structural information to select representative exemplars for few-shot HAR. It leverages activity semantic descriptions to guide the selection process alongside traditional geometric features and PageRank centrality measures. The approach uses facility-location optimization to identify optimal exemplars, creating a hybrid selection mechanism that balances semantic relevance with geometric diversity. The method is designed to enhance accuracy without increasing computational overhead during inference.

## Key Results
- Achieves 88.78% macro F1-score on UCI-HAR dataset
- Outperforms geometric-only baselines (random sampling, k-center) by significant margins
- Ablation studies confirm complementary roles of semantic priors, PageRank centrality, and facility-location optimization
- Demonstrates effectiveness under limited labeled data conditions

## Why This Works (Mechanism)
The framework works by combining complementary information sources: semantic understanding from LLMs provides context about activity relationships and characteristics, while geometric features capture the inherent structure of the data space. PageRank centrality identifies influential data points within the network structure, and facility-location optimization ensures optimal coverage of the activity space. This multi-faceted approach addresses the limitations of single-criterion selection methods by leveraging both high-level semantic relationships and low-level geometric properties.

## Foundational Learning

**Few-shot learning** - Learning from limited labeled examples; needed because HAR systems often have scarce labeled sensor data for new activities; quick check: verify understanding of n-way k-shot terminology.

**Exemplar selection** - Choosing representative samples from a dataset; needed to maximize information from limited labeled data; quick check: understand coverage vs. diversity tradeoffs.

**Semantic reasoning** - Using language models to understand relationships between concepts; needed to capture activity relationships beyond raw sensor patterns; quick check: verify LLM can distinguish between semantically similar activities.

**PageRank centrality** - Measuring node importance in network graphs; needed to identify influential data points in activity space; quick check: understand how centrality scores are computed from adjacency matrices.

**Facility-location optimization** - Selecting points to maximize coverage while minimizing cost; needed to balance exemplar diversity with computational efficiency; quick check: verify facility-location problem formulation matches application.

## Architecture Onboarding

**Component map:** LLM semantic extraction -> Geometric feature extraction -> PageRank centrality computation -> Facility-location optimization -> Exemplar selection

**Critical path:** The semantic extraction from LLM provides priors that guide the geometric selection process. The PageRank centrality identifies structurally important points, while facility-location optimization balances coverage and diversity. The integration happens at the optimization stage where semantic scores are combined with geometric and centrality measures.

**Design tradeoffs:** The framework trades increased preprocessing complexity (LLM integration) for improved selection quality and maintained computational efficiency during inference. Semantic integration adds dependency on LLM quality but provides valuable context missing from geometric approaches alone.

**Failure signatures:** Poor LLM descriptions of activities will degrade semantic priors, leading to suboptimal selections. Geometric-only failures occur when activities have similar sensor patterns but different semantics. PageRank centrality may fail if the network structure doesn't reflect true activity relationships.

**First experiments to run:**
1. Baseline comparison: random sampling vs. k-center vs. proposed method on UCI-HAR
2. Ablation study: remove semantic priors, remove PageRank, remove facility-location separately
3. Limited labeled data test: evaluate performance as labeled examples decrease from 10% to 1% of total

## Open Questions the Paper Calls Out

None identified in the provided material.

## Limitations

- Evaluation limited to single dataset (UCI-HAR), raising generalizability concerns
- Dependence on LLM quality for semantic priors introduces potential bottleneck
- Only tested on six basic activities, scalability to complex activity sets uncertain
- Computational overhead details for LLM integration not provided
- No personalization or user adaptation experiments conducted

## Confidence

**High confidence:** Improvement over geometric-only baselines (random sampling, k-center) is well-supported by ablation studies and direct comparisons on UCI-HAR.

**Medium confidence:** Claims about robustness under limited labeled data and adaptability to different activity sets, as only one dataset and six activities were tested.

**Low confidence:** Assertions about real-world deployment feasibility and scalability due to absence of diverse dataset experiments, complex activity set testing, or detailed computational profiling.

## Next Checks

1. Replicate the framework on multiple HAR datasets (e.g., PAMAP2, Opportunity) to assess generalizability and robustness to varied sensor modalities and activity complexities.

2. Perform a user study or personalization experiment to evaluate the framework's adaptability to individual sensor and activity patterns.

3. Conduct a computational overhead analysis, including runtime and memory costs for LLM integration, to establish practical deployment constraints.