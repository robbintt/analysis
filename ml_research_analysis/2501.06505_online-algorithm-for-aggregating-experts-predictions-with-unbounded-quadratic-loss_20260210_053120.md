---
ver: rpa2
title: Online Algorithm for Aggregating Experts' Predictions with Unbounded Quadratic
  Loss
arxiv_id: '2501.06505'
source_url: https://arxiv.org/abs/2501.06505
tags:
- algorithm
- experts
- predictions
- losses
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses online expert aggregation with unbounded quadratic
  loss, proposing an algorithm that adapts to unknown loss bounds without requiring
  prior knowledge. The method uses exponential reweighing of expert losses with a
  dynamically adjusted learning rate based on the maximum observed loss across experts.
---

# Online Algorithm for Aggregating Experts' Predictions with Unbounded Quadratic Loss

## Quick Facts
- arXiv ID: 2501.06505
- Source URL: https://arxiv.org/abs/2501.06505
- Reference count: 4
- Key outcome: Algorithm adapts to unknown loss bounds without requiring prior knowledge

## Executive Summary
This paper addresses online expert aggregation with unbounded quadratic loss, proposing an algorithm that adapts to unknown loss bounds without requiring prior knowledge. The method uses exponential reweighing of expert losses with a dynamically adjusted learning rate based on the maximum observed loss across experts. The key theoretical result establishes a regret bound of O(max_t,n l_{nt} · (ln N + 1)), where l_{nt} are individual expert losses and N is the number of experts.

## Method Summary
The paper proposes an algorithm that uses exponential reweighing of expert losses with a dynamically adjusted learning rate. The learning rate is updated based on the maximum prediction difference B_t across all experts, using η_t = 1/(2B_t^2). A doubling mechanism handles unbounded losses by updating B_t when the maximum prediction difference exceeds the current bound. This approach allows the algorithm to adapt to unknown loss bounds while maintaining theoretical guarantees through a data-dependent regret bound.

## Key Results
- Regret bound of O(max_t,n l_{nt} · (ln N + 1)) for unbounded quadratic loss
- Data-dependent bound holds even when losses are unbounded
- Dynamic learning rate adaptation through maximum loss tracking

## Why This Works (Mechanism)
The algorithm works by maintaining a dynamic bound on the maximum prediction difference across experts, which is used to adjust the learning rate. This allows the algorithm to adapt to unknown loss bounds without prior knowledge. The exponential reweighing scheme ensures that experts with lower losses receive higher weights over time, while the doubling mechanism guarantees that the algorithm can handle cases where the maximum loss grows unboundedly. The regret bound depends on the maximum observed loss rather than a priori bounds, making it applicable to a broader class of problems.

## Foundational Learning

1. **Exponential Weighted Average (EWA) Algorithms** - Why needed: Forms the basis of the aggregation strategy by weighting experts based on past performance. Quick check: Verify that weights sum to 1 and are updated multiplicatively based on losses.

2. **Online Learning Regret Bounds** - Why needed: Provides the theoretical framework for analyzing algorithm performance. Quick check: Ensure regret is measured against the best expert in hindsight and grows sublinearly with time.

3. **Doubling Trick for Unbounded Parameters** - Why needed: Allows handling of unbounded losses without knowing bounds in advance. Quick check: Confirm that parameter doubling maintains algorithm guarantees while adapting to new bounds.

4. **Quadratic Loss Functions** - Why needed: Defines the specific loss structure being optimized. Quick check: Verify that loss is convex in predictions and satisfies the required properties.

5. **Expert Aggregation Framework** - Why needed: Provides the problem setting and performance metric. Quick check: Ensure the framework allows for continuous predictions rather than just discrete choices.

## Architecture Onboarding

**Component Map:**
Expert Predictions -> Maximum Difference Calculator -> Learning Rate Adjuster -> Weight Updater -> Aggregated Prediction

**Critical Path:**
Expert predictions are received → Maximum difference B_t is calculated → Learning rate η_t = 1/(2B_t^2) is set → Expert weights are updated using exponential weighting → Aggregated prediction is computed as weighted average

**Design Tradeoffs:**
- Fixed vs. dynamic learning rate: Dynamic allows adaptation but adds complexity
- Explicit vs. implicit bound tracking: Explicit (doubling) is simpler but may introduce discontinuities
- Computational overhead of tracking maximum vs. theoretical guarantees

**Failure Signatures:**
- If B_t grows too slowly, learning rate becomes too small and algorithm underfits
- If B_t grows too quickly, learning rate becomes unstable and algorithm may diverge
- If maximum loss is dominated by outliers, regret bound becomes loose

**First 3 Experiments to Run:**
1. Test on synthetic data with known bounded losses to verify theoretical regret bound empirically
2. Test on data with heavy-tailed loss distributions to analyze sensitivity to outliers
3. Compare performance against standard EWA with known bounds when losses are actually bounded

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes experts' predictions are within a bounded range that is updated dynamically
- Doubling mechanism introduces potential discontinuities in the learning rate
- Regret bound depends on maximum observed loss, which may be significantly larger than actual regret
- Requires maintaining maximum prediction difference B_t, adding computational overhead

## Confidence

**Theoretical regret bound:** High
**Algorithm correctness:** High
**Practical performance:** Medium
**Computational efficiency:** Medium

## Next Checks

1. Implement the algorithm and test on synthetic data with known loss bounds to verify the theoretical regret bound empirically
2. Analyze the sensitivity of the algorithm to outliers by testing on data with heavy-tailed loss distributions
3. Compare the algorithm's performance against existing bounded-loss algorithms when losses are actually bounded to quantify the overhead of the doubling mechanism