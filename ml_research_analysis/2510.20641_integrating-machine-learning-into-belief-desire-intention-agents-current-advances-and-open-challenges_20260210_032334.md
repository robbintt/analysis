---
ver: rpa2
title: 'Integrating Machine Learning into Belief-Desire-Intention Agents: Current
  Advances and Open Challenges'
arxiv_id: '2510.20641'
source_url: https://arxiv.org/abs/2510.20641
tags:
- agents
- agent
- learning
- beliefs
- belief
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper surveys the integration of machine learning (ML) into
  BDI agents, a key area of research in autonomous systems. The survey systematically
  reviews 98 primary works, categorizing them by their interaction with BDI modules
  such as sensing, belief revision, belief representation, desire generation, intention
  filtering, planning, and acting.
---

# Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges

## Quick Facts
- arXiv ID: 2510.20641
- Source URL: https://arxiv.org/abs/2510.20641
- Reference count: 40
- Primary result: Survey of 98 works on ML-BDI integration reveals LLM dominance in belief representation/planning while other components remain underexplored

## Executive Summary
This survey systematically reviews 98 primary works on integrating machine learning into Belief-Desire-Intention agents, categorizing them by their interaction with BDI modules including sensing, belief revision, desire generation, intention filtering, planning, and acting. The analysis reveals a strong trend toward using large language models for belief representation and planning, while components like desire generation and intention filtering remain largely unexplored. Most approaches rely on static ML models without online learning, limiting their adaptability in real-world scenarios. The survey highlights the need for more robust frameworks that integrate symbolic and subsymbolic reasoning, ensure online learning, and address reliability and safety concerns in ML-BDI agents.

## Method Summary
The authors conducted a systematic review using keyword-based searches across multiple academic databases to identify relevant works on ML-BDI integration. The 98 primary works were classified based on their interaction with BDI components such as sensing, belief revision, belief representation, desire generation, intention filtering, planning, and acting. The survey period covers publications up to the present, with particular attention to trends in LLM usage and the balance between symbolic and subsymbolic approaches.

## Key Results
- LLM dominance in belief representation and planning components, with minimal exploration of desire generation and intention filtering
- Static ML models predominate over online learning approaches, limiting real-world adaptability
- Need for frameworks integrating symbolic and subsymbolic reasoning to ensure reliability and safety
- Future research directions include multi-agent collaboration, explicit intention representation, and improved plan verification

## Why This Works (Mechanism)
The integration of machine learning into BDI agents works by enhancing traditional cognitive architectures with data-driven capabilities while maintaining the structured reasoning framework. ML models, particularly LLMs, provide flexible belief representation and planning capabilities that can handle uncertainty and incomplete information. The modular nature of BDI allows ML components to be integrated at specific points in the decision-making pipeline, enabling targeted improvements in sensing, reasoning, and action selection. However, the effectiveness depends on balancing the symbolic reasoning of BDI with the statistical learning of ML models.

## Foundational Learning
- BDI Architecture: Cognitive model with three mental attitudes (beliefs, desires, intentions) enabling autonomous decision-making through reactive deliberation
  - Why needed: Provides structured framework for modeling agent cognition and behavior
  - Quick check: Can the agent maintain consistent beliefs while pursuing intentions?

- Belief Revision: Process of updating agent's knowledge base when new information conflicts with existing beliefs
  - Why needed: Enables agents to adapt to changing environments and learn from experience
  - Quick check: Does the agent correctly resolve conflicts between new evidence and prior beliefs?

- Intention Filtering: Selection mechanism that determines which desires become intentions for active pursuit
  - Why needed: Critical for resource management and goal prioritization in complex environments
  - Quick check: Are competing intentions properly evaluated and prioritized?

- Online Learning: Continuous adaptation of ML models during deployment rather than pre-training only
  - Why needed: Essential for maintaining relevance in dynamic, real-world environments
- Quick check: Can the agent update its models based on new experiences without catastrophic forgetting?

## Architecture Onboarding

Component Map:
Sensing -> Belief Revision -> Belief Representation -> Desire Generation -> Intention Filtering -> Planning -> Acting

Critical Path: Belief Revision -> Belief Representation -> Planning -> Acting
Design Tradeoffs: Static vs. Online Learning | Symbolic vs. Subsymbolic Reasoning | Modularity vs. Integration

Failure Signatures:
- Static ML models failing to adapt to environmental changes
- LLM hallucinations affecting belief accuracy
- Poor intention filtering leading to resource exhaustion
- Symbolic-subsymbolic integration failures causing inconsistent reasoning

First Experiments:
1. Test belief revision accuracy with conflicting evidence scenarios
2. Evaluate LLM-based planning against traditional BDI planning in dynamic environments
3. Measure online learning effectiveness when deployed in changing conditions

## Open Questions the Paper Calls Out
- How can ML components be integrated to ensure reliability and safety in critical applications?
- What frameworks can effectively combine symbolic and subsymbolic reasoning in BDI agents?
- How can online learning be implemented without compromising the stability of agent decision-making?
- What approaches can address the underexplored areas of desire generation and intention filtering?
- How can multi-agent collaboration be enhanced through ML-BDI integration?

## Limitations
- Keyword-based search may have missed relevant works using different terminology
- Classification of works into BDI modules may be subjective with some approaches spanning multiple categories
- Survey may not capture industrial implementations or unpublished research
- Analysis period ends before most recent LLM advances, potentially missing cutting-edge developments

## Confidence

High confidence in overall trend of LLM dominance in belief representation and planning components.

Medium confidence in claim about underexplored areas (desire generation, intention filtering) due to potential sampling bias.

Medium confidence in static ML model limitation observation based on available publications rather than comprehensive empirical testing.

## Next Checks

1. Conduct citation network analysis to verify that identified works represent core literature and discover significant omissions.

2. Implement small-scale replication study testing online learning capabilities of selected ML-BDI approaches to verify claimed limitations.

3. Interview active researchers in field to identify emerging trends and unpublished work that may challenge or support survey findings.