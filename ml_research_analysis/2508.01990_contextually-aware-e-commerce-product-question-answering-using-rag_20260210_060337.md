---
ver: rpa2
title: Contextually Aware E-Commerce Product Question Answering using RAG
arxiv_id: '2508.01990'
source_url: https://arxiv.org/abs/2508.01990
tags:
- product
- context
- information
- query
- queries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors present a context-aware e-commerce Product Question
  Answering system using Retrieval-Augmented Generation. The system integrates conversational
  history, user profiles, and heterogeneous product data (structured, unstructured,
  semi-structured) to deliver personalized and factually grounded answers.
---

# Contextually Aware E-Commerce Product Question Answering using RAG

## Quick Facts
- arXiv ID: 2508.01990
- Source URL: https://arxiv.org/abs/2508.01990
- Reference count: 30
- Key outcome: High accuracy RAG system for e-commerce QA with low hallucination rates (2.5%) deployed to 5M monthly active users

## Executive Summary
This paper presents a context-aware e-commerce Product Question Answering system using Retrieval-Augmented Generation. The system integrates conversational history, user profiles, and heterogeneous product data to deliver personalized and factually grounded answers. A modular pipeline includes query rewriting, catalog search, entropy-based intent modeling, two-stage retrieval, and LLM-based generation with mechanisms to acknowledge information gaps. The system achieves high accuracy across components and demonstrates low hallucination rates when deployed in production.

## Method Summary
The system uses a modular pipeline where a fine-tuned LLaMA 3-8B model rewrites conversational queries into standalone queries, a BERT-based intent classifier with entropy-based routing determines retrieval strategy, and a two-stage retrieval process with domain-adapted bi-encoder semantic matching selects relevant context. A second LLM generates answers using retrieved context and user profile information. The system handles structured, unstructured, and semi-structured product data while maintaining factual accuracy through context reduction and explicit acknowledgment of information gaps.

## Key Results
- SAQ module achieves 97.60% overall accuracy (99.08% turn-1, 95.93% multi-turn)
- Intent model shows 93.17% top-1 accuracy and 92.57% weighted F1 score
- Context reduction yields 98.32% Recall@k for relevant information retrieval
- Generation module demonstrates 96.5% precision and only 2.5% hallucination rate
- System deployed to over 5 million monthly active users with 8% increase in thumbs-up rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Rewriting queries to incorporate conversational history resolves referential ambiguity, enabling stateless downstream processing.
- Mechanism: The Standalone Query (SAQ) module (fine-tuned LLaMA 3-8B) ingests the current query and history to output a self-contained query. It resolves pronouns and relative references into canonical product names.
- Core assumption: Users speak inefficiently (using pronouns/context) rather than fully specified queries, and the LLM can reliably infer the specific entity from context.
- Evidence anchors: [abstract] "integrates conversational history... modular pipeline includes query rewriting." [Section 4.1] "resolving co-references... performing product disambiguation... allowing downstream components to operate without needing access to the full conversation history."

### Mechanism 2
- Claim: Entropy-based routing on intent classifications balances precision (targeted retrieval) with recall (broad retrieval) for ambiguous queries.
- Mechanism: A BERT-based classifier predicts intent probabilities. If entropy is low, the system fetches data for the top-1 intent. If entropy is high (indicating ambiguity), it retrieves data for the top-N intents to ensure coverage.
- Core assumption: A high entropy score in the classifier correlates with multi-faceted user intent rather than classifier confusion; fetching more data handles this without overwhelming the final generator.
- Evidence anchors: [abstract] "entropy-based intent modeling... two-stage retrieval." [Section 4.3] "low entropy indicates a clear dominant intent... while high entropy reflects ambiguity, prompting retrieval for the top-N."

### Mechanism 3
- Claim: A two-stage retrieval process with domain-adapted context reduction minimizes hallucination by restricting the LLM's generation scope.
- Mechanism: Stage 1 retrieves verbose data via APIs based on intent. Stage 2 uses a domain-adapted bi-encoder STS model to select only the top-k relevant snippets. This concise context forces the LLM to ground answers in provided text rather than parametric memory.
- Core assumption: Retrieving the wrong context or too much context leads to hallucination, and a bi-encoder is sufficient to identify the "gold" sentences before generation.
- Evidence anchors: [abstract] "low hallucination rates (2.5% overall)." [Section 5.2.4] "This reduced context is critical for improving the generative model's factual accuracy and mitigating hallucinations."

## Foundational Learning

- **Semantic Textual Similarity (STS) & Bi-Encoders**
  - Why needed here: Used in the Context Reduction module to filter verbose API outputs down to the most relevant chunks for the LLM.
  - Quick check question: How does a bi-encoder differ from a cross-encoder in terms of latency vs. accuracy for re-ranking?

- **Entropy in Classification**
  - Why needed here: Used in the Intent Model to detect ambiguity; high entropy triggers a broader search strategy.
  - Quick check question: Why is using a raw probability score often unreliable for confidence estimation compared to entropy or calibrated probabilities?

- **RAG Evaluation Metrics (Factuality vs. Faithfulness)**
  - Why needed here: The paper introduces a specific metric suite to distinguish between "hallucination" and "correct IDK".
  - Quick check question: In a RAG system, can an answer be "faithful" to the context but "factually incorrect" in the real world?

## Architecture Onboarding

- **Component map**: Input -> SAQ Rewriter (LLaMA 3-8B) -> Catalog Search (Fuzzy/Exact) -> Intent Model (BERT) -> Entropy Gate -> API Orchestrator -> STS Re-ranker -> Generator

- **Critical path**: SAQ Module. If the query rewrite fails, the Catalog Search fetches the wrong product ID, and all subsequent retrieval and generation is grounded in the wrong context.

- **Design tradeoffs**: Fixed Taxonomy vs. Open-Ended Intent. The authors note that the predefined intent taxonomy limits generalization to novel queries, trading flexibility for the reliability and efficiency of the API orchestration.

- **Failure signatures**:
  - IDK loops: Occur if Recall@k in the context reduction step drops
  - Product Hallucination: Occurs in the Catalog Search (0.75% rate noted) where the model invents a product name that maps to a real ID

- **First 3 experiments**:
  1. SAQ Context Resolution Validation: Pass multi-turn conversations with pronouns to verify canonical product name resolution
  2. Entropy Threshold Tuning: Sweep entropy threshold to find optimal balance between retrieval precision and user satisfaction
  3. STS Context Window Sizing: Vary top-k parameter to measure trade-off between generation latency and hallucination rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can an agentic architecture improve dynamic tool selection compared to the current fixed pipeline?
- Basis in paper: [explicit] The authors state their current modular pipeline "lacks flexibility in dynamically re-planning or self-correcting" and propose developing an "adaptive, agentic architecture" as a future direction.
- Why unresolved: The current sequential design handles well-defined queries efficiently but cannot autonomously adjust its workflow when faced with ambiguity or partial failures.
- What evidence would resolve it: A comparative study showing an agentic system dynamically sequencing tools to outperform the fixed baseline on ambiguous inputs.

### Open Question 2
- Question: How can the system generalize to handle compositional reasoning without relying on a predefined intent taxonomy?
- Basis in paper: [explicit] The paper notes the "predefined intent taxonomy" constrains the system's ability to generalize to "novel or complex user queries particularly those involving compositional reasoning."
- Why unresolved: The system relies on fixed intent classes, resulting in lower performance on the "long tail of diverse user needs" compared to high-frequency queries.
- What evidence would resolve it: A method capable of resolving compositional intents not present in the training data without manual taxonomy expansion.

### Open Question 3
- Question: Can automated pipelines effectively detect and resolve information gaps to reduce unanswerable queries?
- Basis in paper: [explicit] The authors identify the need to "build automated pipelines for catalog enrichment by detecting and resolving information gaps" to improve data completeness.
- Why unresolved: While the system identifies gaps to return "IDK", it lacks an automated loop to fix the underlying catalog data insufficiency in real-time.
- What evidence would resolve it: A decrease in "IDK" responses and an increase in Context Coverage following the deployment of such a pipeline.

## Limitations

- The system's performance is based on proprietary data from electronics and fashion categories, limiting generalization to other product domains
- The predefined intent taxonomy constrains the system's ability to handle novel or compositional user queries
- While the 2.5% hallucination rate is low, it still represents potential quality issues at scale for 5 million monthly active users

## Confidence

- **High Confidence**: The core RAG architecture and modular pipeline design are well-supported by empirical results and align with established best practices
- **Medium Confidence**: The SAQ module's ability to resolve conversational references is demonstrated through high accuracy metrics, but specific failure modes are not fully explored
- **Medium Confidence**: The entropy-based intent routing mechanism shows promise, but the correlation between entropy scores and true multi-faceted user intent is not empirically validated

## Next Checks

1. **Cross-Domain Generalization Test**: Deploy the system on product categories outside electronics and fashion and measure accuracy degradation across all modules

2. **Edge Case Stress Test**: Construct test cases where conversational history exceeds context windows and where references are ambiguous or visually implied to measure SAQ module failure rates

3. **Entropy Threshold Optimization**: Conduct A/B testing with varying entropy thresholds to empirically determine the optimal balance between retrieval precision and coverage, measuring impact on end-user satisfaction metrics