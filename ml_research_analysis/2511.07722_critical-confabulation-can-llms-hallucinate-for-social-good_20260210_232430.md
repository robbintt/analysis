---
ver: rpa2
title: 'Critical Confabulation: Can LLMs Hallucinate for Social Good?'
arxiv_id: '2511.07722'
source_url: https://arxiv.org/abs/2511.07722
tags:
- event
- prompt
- across
- confabulation
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes "critical confabulation" - using LLM hallucinations
  to reconstruct missing narratives in historical archives affected by social inequality.
  The authors frame this as a narrative cloze task: given a partial timeline of events
  for a "hidden figure," LLMs must generate the missing event.'
---

# Critical Confabulation: Can LLMs Hallucinate for Social Good?

## Quick Facts
- **arXiv ID:** 2511.07722
- **Source URL:** https://arxiv.org/abs/2511.07722
- **Reference count:** 40
- **Key outcome:** LLMs can achieve up to 60% accuracy in reconstructing missing historical events from unpublished Black intellectual archives when carefully prompted.

## Executive Summary
This paper introduces "critical confabulation" - a novel application of large language models where controlled hallucinations are used to reconstruct missing narratives in historical archives affected by social inequality. The authors frame this as a narrative cloze task: given a partial timeline of events for a "hidden figure," LLMs must generate the missing event. Using a corpus of unpublished Black intellectual history texts as ground truth, they test various open models and find that while most achieve under 50% accuracy, top models like GPT-5-CHAT reach up to 60% with careful prompting. Performance is sensitive to prompt design, event type (best on biographical "role" events, worst on "cognitive" states), event length, and position in timeline. The results validate LLMs' potential for evidence-constrained speculative storytelling, offering a new application where controlled hallucinations support knowledge production in digital humanities.

## Method Summary
The paper proposes a narrative cloze task where LLMs generate missing events in historical timelines ("critical confabulation"). Using the Black Writing and Thought Collection (BWTC) as ground truth, the authors extracted 156 character timelines (avg. 6 events) through a proprietary timeline extraction model. They evaluate various open LLMs (OLMo-2, GPT-4o, etc.) using zero-shot inference with six different prompt templates designed to induce confabulation. The core metric is accuracy of narrative verisimilitude, calculated as the percentage of generated events with cosine similarity ≥73.13 to ground truth embeddings using a "story-emb" embedding model. The methodology is inference-only with deterministic decoding, testing how well LLMs can fill in plausible missing historical events within known constraints.

## Key Results
- Top-performing model (GPT-5-CHAT) achieved up to 60% accuracy in generating missing historical events
- Model performance varied significantly by event type: best for "role" events (biographical), worst for "cognitive" states
- Event position in timeline strongly affected performance, with accuracy dropping for events at the end of longer timelines
- Careful prompt design was crucial, with some models showing prompt sensitivity and refusal behaviors

## Why This Works (Mechanism)
Critical confabulation leverages LLMs' generative capabilities to fill narrative gaps in historical archives where information is missing due to social inequality and archival biases. By framing the task as a controlled hallucination problem with evidence constraints, the approach transforms LLMs' tendency to confabulate from a liability into a tool for knowledge discovery. The methodology works because LLMs can draw connections between available historical events and generate plausible missing events that maintain narrative coherence and historical plausibility, validated against ground truth from unpublished archival sources.

## Foundational Learning
- **Narrative Cloze Task**: A language modeling task where a model predicts a missing element in a sequence. *Why needed:* Provides the evaluation framework for measuring LLMs' ability to fill historical knowledge gaps. *Quick check:* Test if model can complete "The cat sat on the [MASKED]" with "mat".
- **Cosine Similarity Thresholding**: Using a similarity cutoff (73.13) to determine if generated text matches ground truth. *Why needed:* Quantifies narrative verisimilitude between generated and actual events. *Quick check:* Verify threshold correctly classifies known matches and mismatches.
- **Prompt-Induced Confabulation**: Designing prompts that encourage controlled hallucination within evidence constraints. *Why needed:* Balances creativity with historical accuracy requirements. *Quick check:* Compare outputs from different prompt templates on same input.

## Architecture Onboarding
- **Component Map**: BWTC Corpus -> Timeline Extraction -> Masked Timelines -> LLM Inference -> Story-Embeddings -> Cosine Similarity -> Accuracy
- **Critical Path**: Timeline extraction → Masked timeline creation → LLM generation → Embedding comparison → Accuracy calculation
- **Design Tradeoffs**: Zero-shot inference vs. fine-tuning (simplicity vs. potential performance), deterministic decoding vs. sampling (reproducibility vs. diversity), strict similarity threshold vs. fuzzy matching (precision vs. recall)
- **Failure Signatures**: Unparseable outputs from certain models, refusal to answer under specific prompts, significant performance drop for end-of-timeline events and cognitive event types
- **Three First Experiments**:
  1. Run the Base Instruction Prompt on a small subset of masked timelines and verify embedding similarity computation
  2. Test multiple prompt templates on a single timeline to observe prompt sensitivity
  3. Stratify results by event position (begin/middle/end) to confirm position effect

## Open Questions the Paper Calls Out
None

## Limitations
- Data access restricted: BWTC corpus requires ARTFL permissions, making exact replication impossible without the specific historical archive
- Similarity threshold (73.13) was tuned on a small validation set and may not generalize to different domains or embedding models
- Proprietary timeline extraction pipeline introduces uncertainty about exact replication methodology

## Confidence
- **High confidence**: Zero-shot inference methodology and prompt design principles are clearly specified and reproducible
- **Medium confidence**: Accuracy metric and model comparison methodology are sound, though threshold calibration may require adjustment
- **Low confidence**: Generalizability to different historical domains and embedding model versions

## Next Checks
1. **Threshold Robustness**: Recompute the cosine similarity threshold using k-fold cross-validation on the 156-character dataset to assess stability and generalization
2. **Model Generalization**: Apply the same critical confabulation methodology to a different historical corpus (e.g., women's suffrage archives) to test domain transferability
3. **Error Analysis**: Conduct qualitative analysis of model failures, particularly for "cognitive" event types and end-of-timeline positions, to identify systematic weaknesses in long-range narrative reasoning