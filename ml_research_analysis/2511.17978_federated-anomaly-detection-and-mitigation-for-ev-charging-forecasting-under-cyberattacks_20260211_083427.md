---
ver: rpa2
title: Federated Anomaly Detection and Mitigation for EV Charging Forecasting Under
  Cyberattacks
arxiv_id: '2511.17978'
source_url: https://arxiv.org/abs/2511.17978
tags:
- data
- federated
- charging
- lstm
- centralized
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses cybersecurity threats to EV charging infrastructure,
  specifically DDoS attacks that compromise forecasting accuracy and grid stability.
  The proposed solution is a federated learning framework that integrates LSTM autoencoder-based
  distributed anomaly detection at each client, interpolation-based anomalous data
  mitigation, and collaborative federated LSTM networks that preserve data privacy.
---

# Federated Anomaly Detection and Mitigation for EV Charging Forecasting Under Cyberattacks

## Quick Facts
- arXiv ID: 2511.17978
- Source URL: https://arxiv.org/abs/2511.17978
- Reference count: 7
- Primary result: Federated LSTM framework achieves 15.2% better R² accuracy than centralized models while maintaining data privacy

## Executive Summary
This paper addresses cybersecurity threats to EV charging infrastructure, specifically DDoS attacks that compromise forecasting accuracy and grid stability. The proposed solution is a federated learning framework that integrates LSTM autoencoder-based distributed anomaly detection at each client, interpolation-based anomalous data mitigation, and collaborative federated LSTM networks that preserve data privacy. The framework is validated on real-world EV charging datasets combined with DDoS attack simulations. Results show the federated approach outperforms centralized models with 15.2% better R2 accuracy while maintaining data locality. The anomaly detection system recovers 47.9% of attack-induced performance degradation with 91.3% precision and 1.21% false positive rate. The federated architecture also achieves 18.1% faster training times compared to centralized approaches.

## Method Summary
The method combines LSTM autoencoder-based anomaly detection with federated learning for EV charging forecasting. Each client trains an LSTM autoencoder (50→25→25→50 neurons) on clean data, detecting anomalies via reconstruction error exceeding the 98th percentile threshold. Anomalous data points are mitigated through linear interpolation between non-anomalous boundary points. Local LSTM forecasters (50 units, Dense 10→1) are trained on filtered data and aggregated via Federated Averaging across 5 rounds with 10 local epochs per round. The framework is validated on Shenzhen EV charging data (3 zones, 4,344 hourly timestamps each) with simulated DDoS attacks.

## Key Results
- Federated model outperforms centralized approach by 15.2% in R² accuracy while operating on identical filtered datasets
- Anomaly detection achieves 91.3% precision and 1.21% false positive rate with 47.9% recovery of attack-induced performance degradation
- Federated architecture achieves 18.1% faster training times compared to centralized approaches
- Per-client anomaly detection precision varies (0.837 to 0.955) with recall ranging from 0.584 to 0.354 across zones

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LSTM autoencoder-based reconstruction error analysis enables unsupervised anomaly detection with high precision under DDoS-like attack patterns.
- Mechanism: The autoencoder (encoder: 50→25 neurons, decoder: 25→50 neurons with 0.2 dropout) learns to reconstruct normal charging patterns during training on clean data. During inference, anomalous inputs produce higher reconstruction errors because they deviate from learned normal patterns. A threshold at the 98th percentile of training MSE flags anomalies.
- Core assumption: DDoS attacks manifest as statistically distinct volume spikes that differ from legitimate demand variability in ways detectable via reconstruction error.
- Evidence anchors:
  - [abstract] "LSTM autoencoder-based distributed anomaly detection deployed at each federated client... maintaining exceptional precision (91.3%) and minimal false positive rates (1.21%)"
  - [section III-C] "The high overall precision (0.913) and low false positive rate (1.21%) indicate that flagged anomalies are highly likely to be genuine attacks"
  - [corpus] Related work (arxiv:2509.18126) confirms FL-based anomaly detection in EV charging stations preserves privacy while detecting anomalies, supporting feasibility.
- Break condition: If attacks produce subtle data manipulations rather than volume spikes, or if legitimate demand naturally exhibits extreme variability resembling attack signatures, precision may degrade. Zone 108's lower recall (0.354) suggests this already occurs for some patterns.

### Mechanism 2
- Claim: Linear interpolation between non-anomalous boundary points recovers forecasting performance while preserving temporal continuity.
- Mechanism: After anomaly detection flags corrupted timestamps, the algorithm identifies consecutive anomalous segments (allowing gaps ≤2 timestamps), then linearly interpolates between the nearest clean boundary points. This maintains time-series structure without requiring external data sources.
- Core assumption: Anomalous segments are bounded by recoverable clean data points, and linear interpolation provides sufficient approximation for short gaps.
- Evidence anchors:
  - [abstract] "interpolation-based anomalous data mitigation to preserve temporal continuity... recovering 47.9% of attack-induced performance degradation"
  - [section III-C] "R² of 0.8883, representing a 47.9% recovery of the attack-induced performance loss"
  - [corpus] No direct corpus evidence on interpolation efficacy; related papers focus on detection rather than mitigation. This represents a gap in validation breadth.
- Break condition: Long consecutive attack segments without proximate clean boundaries, or attacks targeting temporal patterns rather than point values, would limit interpolation utility. The 47.9% recovery (vs. full restoration) indicates inherent limitations.

### Mechanism 3
- Claim: Federated architecture with local specialization outperforms centralized models for spatially heterogeneous EV charging data, independent of privacy benefits.
- Mechanism: Each client trains a local LSTM model on zone-specific data (4,344 timestamps per zone). Federated Averaging synchronizes weights across clients without sharing raw data. Local models optimize for consistent zone-specific patterns rather than compromising across heterogeneous urban contexts.
- Core assumption: Charging patterns exhibit meaningful spatial heterogeneity that benefits from specialized models rather than a single global model.
- Evidence anchors:
  - [abstract] "federated approach achieves superior performance compared to centralized models, with 15.2% improvement in R² accuracy"
  - [section III-D] "federated model significantly outperformed the centralized model by 15.2% in R²... both operating on identical filtered datasets"
  - [section III-E] "centralized model's highly heterogeneous per-client performance... demonstrates this compromise effect"
  - [corpus] arxiv:2509.18126 confirms FL applicability for EV anomaly detection with privacy preservation, though direct architectural performance comparison is limited.
- Break condition: If charging patterns across zones are highly homogeneous, centralized models may match or exceed federated performance while reducing coordination overhead. Evidence here suggests heterogeneity exists, but generalization to other cities/zones requires validation.

## Foundational Learning

- Concept: **LSTM gating mechanisms (forget, input, output gates)**
  - Why needed here: The forecasting model relies on LSTM's ability to capture long-term temporal dependencies (24-hour sequences) that traditional RNNs cannot due to vanishing gradients. Understanding how gates control information flow explains why the model handles daily charging cycles.
  - Quick check question: Can you explain why an LSTM might retain a 12-hour-old charging spike pattern while discarding hourly noise?

- Concept: **Autoencoder reconstruction error as anomaly score**
  - Why needed here: The detection system uses reconstruction error as the sole anomaly signal. Without understanding that autoencoders learn to compress and reconstruct only seen patterns, the 98th percentile threshold logic is opaque.
  - Quick check question: If an autoencoder trained on normal data encounters a novel but legitimate demand pattern (e.g., a major sporting event), will reconstruction error increase? What does this imply for false positives?

- Concept: **Federated Averaging (FedAvg) weight synchronization**
  - Why needed here: The 15.2% performance gain depends on how local model updates aggregate into a global model. FedAvg averages client weights; non-IID data distributions across clients affect convergence.
  - Quick check question: If Client 3 (zone 108) has fundamentally different charging patterns than Clients 1 and 2, how might FedAvg produce a global model that underperforms for Client 3?

## Architecture Onboarding

- Component map:
  - EVChargingAnomalyFilter: LSTM autoencoder (50→25→25→50) + MSE threshold (98th percentile) + linear interpolation
  - Local LSTM Forecaster: Sequential model (LSTM 50 units → Dense 10 ReLU → Dense 1) per client
  - Federated Aggregator: FedAvg with 5 rounds, 10 epochs per round, LR=0.001, batch=32
  - Data Pipeline: MinMaxScaler per client, 24-timestep sequences, 80/20 temporal split

- Critical path:
  1. Raw charging data → MinMax normalization per client
  2. Normalized data → LSTM autoencoder reconstruction → MSE computation → threshold comparison
  3. Flagged anomalies → linear interpolation → filtered dataset
  4. Filtered data → local LSTM training (10 epochs)
  5. Local weights → FedAvg aggregation → global model distribution
  6. Repeat steps 4-5 for 5 federated rounds

- Design tradeoffs:
  - **Precision vs. Recall**: 98th percentile threshold yields 91.3% precision but recall varies (0.584 to 0.354 across zones). Lower thresholds increase attack detection but risk corrupting legitimate data via interpolation.
  - **Local specialization vs. Global generalization**: FedAvg may dilute zone-specific patterns. Paper shows local specialization wins here, but this is data-dependent.
  - **Interpolation simplicity vs. reconstruction fidelity**: Linear interpolation is computationally cheap but recovers only 47.9% degradation. Advanced imputation (e.g., generative models) could improve but adds complexity.

- Failure signatures:
  - **Low recall on specific zones**: Zone 108's recall=0.354 suggests pattern similarity between legitimate demand spikes and attack signatures. Investigate feature engineering or hybrid detection approaches.
  - **Centralized model unexpectedly outperforms federated**: Check data homogeneity across zones; if zones are similar, federated overhead may not justify performance gains.
  - **High false positives after deployment shift**: Retrain autoencoder on expanded normal data; threshold may be outdated if charging patterns evolve.

- First 3 experiments:
  1. **Baseline replication**: Train LSTM autoencoder on clean Client 1 data, compute MSE distribution, set 98th percentile threshold, inject simulated DDoS anomalies, measure precision/recall. Validate claimed 91.3%/58.4% figures.
  2. **Ablation on threshold sensitivity**: Vary threshold from 95th to 99.5th percentile. Plot precision-recall tradeoff curve. Identify zone-specific optimal thresholds.
  3. **Federated vs. centralized on synthetic homogeneous data**: Generate artificial dataset with identical patterns across three synthetic "zones." Compare federated and centralized R². Hypothesis: performance gap should narrow or reverse if spatial heterogeneity drives the federated advantage.

## Open Questions the Paper Calls Out

- **Question**: Would the federated LSTM framework maintain its 15.2% performance advantage over centralized approaches when validated against actual cyberattack data on EV charging infrastructure rather than simulated DDoS patterns adapted from network traffic datasets?
  - **Basis in paper**: [explicit] "validation with actual cyberattack data on EV infrastructure would strengthen the findings"
  - **Why unresolved**: The study relies on simulated DDoS attack patterns translated from network traffic characteristics rather than real-world attacks on EV systems.
  - **What evidence would resolve it**: Experimental validation using documented real-world cyberattack incidents on operational EV charging infrastructure.

- **Question**: Can the LSTM autoencoder-based detection system effectively identify subtle attack vectors such as false data injection, temporal pattern disruption, or adversarial manipulations that do not manifest as high-volume irregular spikes?
  - **Basis in paper**: [explicit] "other attack vectors such as subtle data manipulation or temporal pattern disruption warrant investigation"
  - **Why unresolved**: The current detection system focuses specifically on sustained high-volume irregular spikes; other sophisticated attack patterns remain unexplored.
  - **What evidence would resolve it**: Performance metrics (precision, recall, F1) on EV charging datasets containing diverse attack signatures beyond volume-based anomalies.

- **Question**: Would advanced reconstruction techniques such as deep generative models or sophisticated time-series imputation methods outperform linear interpolation in recovering attack-induced performance degradation beyond the demonstrated 47.9% recovery rate?
  - **Basis in paper**: [explicit] "More sophisticated reconstruction techniques leveraging deep generative models or advanced time-series imputation methods could potentially improve recovery performance"
  - **Why unresolved**: The current mitigation employs basic linear interpolation between non-anomalous boundary points, representing a fundamental approach.
  - **What evidence would resolve it**: Comparative experiments measuring degradation recovery rates using generative adversarial networks, variational autoencoders, or advanced imputation algorithms.

## Limitations

- The federated performance gain is dataset-specific and may not generalize to cities with homogeneous charging patterns across zones
- Linear interpolation only recovers 47.9% of attack-induced degradation, indicating fundamental limitations for complex attack patterns
- Zone 108's low recall (0.354) suggests the detection mechanism struggles with legitimate demand variability resembling attack signatures

## Confidence

- High confidence: Anomaly detection precision (91.3%) and false positive rate (1.21%) are well-supported by reconstruction error analysis on clean training data
- Medium confidence: The 15.2% federated performance improvement is methodologically sound but depends on spatial heterogeneity assumptions that require broader validation
- Medium confidence: The 47.9% degradation recovery through interpolation is demonstrated but represents partial restoration, suggesting room for more sophisticated mitigation techniques

## Next Checks

1. Test federated performance on synthetic homogeneous datasets where all zones share identical charging patterns; federated advantage should diminish or reverse if spatial heterogeneity drives current results
2. Implement and compare alternative interpolation methods (e.g., spline interpolation, generative models) against linear interpolation to quantify potential improvements in degradation recovery beyond 47.9%
3. Conduct cross-city validation using EV charging datasets from multiple urban areas to assess whether spatial heterogeneity patterns that benefit federated learning in Shenzhen replicate elsewhere