---
ver: rpa2
title: Fast Autoregressive Video Generation with Diagonal Decoding
arxiv_id: '2503.14070'
source_url: https://arxiv.org/abs/2503.14070
tags:
- video
- diagd
- generation
- decoding
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Diagonal Decoding (DiagD) is a training-free acceleration algorithm\
  \ for autoregressive video generation that generates tokens along diagonal paths\
  \ in the spatial-temporal token grid, enabling parallel decoding within each frame\
  \ and partially overlapping across consecutive frames. The method exploits spatial\
  \ and temporal correlations in videos to achieve up to 10\xD7 speedup compared to\
  \ naive sequential decoding while maintaining comparable visual fidelity."
---

# Fast Autoregressive Video Generation with Diagonal Decoding

## Quick Facts
- arXiv ID: 2503.14070
- Source URL: https://arxiv.org/abs/2503.14070
- Reference count: 40
- Primary result: Achieves up to 10× speedup in autoregressive video generation while maintaining quality

## Executive Summary
Diagonal Decoding (DiagD) introduces a training-free acceleration algorithm for autoregressive video generation that generates tokens along diagonal paths in the spatial-temporal token grid. This approach enables parallel decoding within each frame while maintaining partial overlap across consecutive frames, exploiting both spatial and temporal correlations in videos. The method achieves significant speed improvements compared to naive sequential decoding while preserving comparable visual fidelity, making it particularly valuable for large-scale video generation systems.

## Method Summary
DiagD works by restructuring the token generation order from sequential raster scanning to diagonal decoding patterns. This reorganization allows multiple tokens within the same frame to be decoded in parallel while maintaining the autoregressive property through carefully designed dependencies. The algorithm includes flexible hyperparameters to control the trade-off between speed and quality, and incorporates a cost-effective finetuning strategy that aligns attention patterns with the decoding order. The approach is particularly effective for smaller models where finetuning can significantly improve performance.

## Key Results
- Achieves up to 10× speedup compared to naive sequential decoding (e.g., reducing steps from 7.68k to 0.18k on Cosmos-12B)
- Maintains comparable visual fidelity as measured by FID scores across multiple models and datasets
- Demonstrates versatility across different tasks including video continuation and text-to-video generation
- Shows effectiveness on multiple autoregressive video generation models including Cosmos, WHAM, and MC-AR

## Why This Works (Mechanism)
The method exploits the inherent spatial and temporal correlations in videos by generating tokens along diagonal paths rather than traditional sequential raster scanning. This diagonal ordering allows for parallelization within frames while maintaining necessary dependencies through partial overlap between consecutive frames. The approach leverages the fact that neighboring tokens in video frames are highly correlated, enabling faster generation without sacrificing quality.

## Foundational Learning

**Autoregressive video generation**: Sequential prediction of video tokens where each token depends on previously generated tokens. Needed to understand the baseline that DiagD accelerates.

**Spatial-temporal token grids**: The 3D arrangement of tokens representing video frames over time. Critical for understanding how diagonal decoding reorganizes generation order.

**Parallel decoding**: Simultaneous generation of multiple tokens. Key concept for understanding how DiagD achieves speedups.

**Attention mechanisms in video models**: How models process dependencies between tokens. Important for understanding the finetuning strategy that aligns attention with diagonal decoding patterns.

**Raster scanning vs diagonal decoding**: Comparison of traditional sequential generation with the proposed diagonal approach. Fundamental to understanding the innovation.

## Architecture Onboarding

**Component map**: Input video tokens -> Diagonal decoding scheduler -> Parallel token generation units -> Output video tokens

**Critical path**: Token input → Diagonal ordering computation → Parallel decoding across spatial dimensions → Temporal dependency resolution → Output generation

**Design tradeoffs**: Speed vs quality balance through hyperparameter tuning, computational efficiency vs memory overhead from diagonal attention patterns, model scale vs effectiveness of finetuning strategy.

**Failure signatures**: Quality degradation when temporal dependencies are not properly maintained, increased memory usage from complex attention patterns, reduced effectiveness on very large models where finetuning becomes impractical.

**First experiments**: 1) Baseline comparison of sequential vs diagonal decoding on small video clips, 2) Ablation study varying diagonal pattern hyperparameters, 3) Quality assessment comparing FID scores across different model scales.

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Scalability concerns across different model sizes, with effectiveness limited primarily to smaller models for finetuning
- Memory overhead from diagonal attention patterns that could offset computational gains
- Limited generalizability to non-video autoregressive generation tasks or completely different model architectures
- Reliance on automated quality metrics that may not fully capture subjective human preferences

## Confidence
**Speedup measurements (High confidence)**: Well-supported by quantitative metrics and ablation studies, though validation across more diverse architectures would strengthen findings.

**Quality preservation (Medium confidence)**: Supported by FID scores and visual fidelity metrics, but relies heavily on automated metrics that may not capture subjective quality.

**Cross-model generalizability (Low-Medium confidence)**: Experiments cover three model families but unproven extent of transfer to completely different autoregressive architectures.

## Next Checks
1. **Memory profiling**: Conduct comprehensive memory usage analysis comparing diagonal decoding against baseline sequential decoding across different batch sizes and sequence lengths to quantify any memory overhead.

2. **Perceptual study**: Execute a human preference study comparing videos generated with diagonal decoding versus sequential decoding to validate automated quality metrics with subjective assessments.

3. **Architectural stress test**: Apply DiagD to a broader range of autoregressive architectures beyond video generation (e.g., text-to-image, audio generation) to evaluate its true generalizability across domains.