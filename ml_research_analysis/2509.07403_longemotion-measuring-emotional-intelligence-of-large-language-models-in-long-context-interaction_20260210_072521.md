---
ver: rpa2
title: 'LongEmotion: Measuring Emotional Intelligence of Large Language Models in
  Long-Context Interaction'
arxiv_id: '2509.07403'
source_url: https://arxiv.org/abs/2509.07403
tags:
- emotion
- emotional
- figure
- task
- coem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces LongEmotion, a benchmark for evaluating
  large language models'' emotional intelligence in long-context scenarios. It includes
  six tasks: Emotion Classification, Emotion Detection, Emotion QA, Emotion Conversation,
  Emotion Summary, and Emotion Expression, with an average context length of 15,341
  tokens.'
---

# LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction

## Quick Facts
- arXiv ID: 2509.07403
- Source URL: https://arxiv.org/abs/2509.07403
- Reference count: 39
- LongEmotion is a benchmark for evaluating LLMs' emotional intelligence in long-context scenarios with six tasks and an average context length of 15,341 tokens

## Executive Summary
LongEmotion introduces a comprehensive benchmark for measuring large language models' emotional intelligence (EI) in long-context interactions. The benchmark includes six tasks: Emotion Classification, Emotion Detection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion Expression. To address the challenges of processing long contexts, the authors propose a Collaborative Emotional Modeling (CoEM) framework that integrates Retrieval-Augmented Generation (RAG) and multi-agent collaboration. CoEM improves EI performance by dividing context into chunks, ranking them by relevance, enriching with emotional features, and generating ensemble responses. Experiments demonstrate consistent improvements across most tasks, with the framework using conversational context as a retrieval source rather than external knowledge bases.

## Method Summary
The LongEmotion benchmark evaluates LLMs across six tasks with an average context length of 15,341 tokens. The CoEM framework processes long contexts by first splitting them into manageable chunks, then ranking these chunks by relevance to the emotional task at hand. Each chunk is enriched with emotional features through RAG before being processed by specialized agents. The framework employs multi-agent collaboration where different agents handle specific aspects of emotional understanding and generation. Finally, ensemble generation combines responses from multiple agents to produce the final output. This approach allows for efficient processing of long contexts while maintaining emotional coherence and relevance throughout the interaction.

## Key Results
- CoEM framework shows consistent improvements in EI-related performance across most LongEmotion tasks
- Performance gains vary significantly between tasks, with some showing substantial improvements while others show modest gains
- GPT models exhibit different emotional intelligence capabilities and hallucination tendencies in comparative case studies
- The framework successfully processes contexts averaging 15,341 tokens while maintaining emotional coherence

## Why This Works (Mechanism)
The effectiveness of LongEmotion and CoEM stems from addressing the fundamental challenge of maintaining emotional coherence across extended conversations. By chunking the context and using relevance ranking, the system focuses computational resources on the most emotionally relevant portions of the conversation. The RAG component enriches these chunks with additional emotional context that may not be present in the original conversation, helping models better understand nuanced emotional states. Multi-agent collaboration allows for specialized processing of different emotional aspects, while ensemble generation combines these specialized insights into coherent responses that maintain emotional consistency throughout the long interaction.

## Foundational Learning
- Emotional Intelligence in NLP: Understanding how models process and generate emotionally appropriate responses is crucial for applications requiring human-like interaction. Quick check: Evaluate model responses on emotional appropriateness scales.
- Long-Context Processing: LLMs struggle with maintaining coherence across thousands of tokens, making chunking and relevance ranking essential. Quick check: Measure coherence scores at different context lengths.
- Retrieval-Augmented Generation: RAG helps supplement conversation context with relevant external information, crucial for emotional understanding. Quick check: Compare performance with and without RAG augmentation.
- Multi-Agent Systems: Distributing specialized tasks across multiple agents can improve overall system performance. Quick check: Measure individual agent contributions to final performance.
- Ensemble Methods: Combining multiple model outputs often yields better results than single-model approaches. Quick check: Analyze variance reduction in ensemble predictions.

## Architecture Onboarding
**Component Map:** Conversation Context -> Chunking Module -> Relevance Ranking -> RAG Enrichment -> Multi-Agent Processing -> Ensemble Generation -> Final Response

**Critical Path:** The most performance-critical components are the relevance ranking and ensemble generation stages. Relevance ranking determines which portions of the long context receive computational attention, while ensemble generation combines specialized agent outputs into coherent emotional responses.

**Design Tradeoffs:** The framework trades computational efficiency for emotional accuracy by processing only relevant chunks rather than the entire context. This approach may miss subtle emotional cues in lower-ranked chunks but enables processing of much longer contexts than would otherwise be possible.

**Failure Signatures:** Common failure modes include missing emotional context in low-ranked chunks, inconsistencies between agent responses in ensemble generation, and hallucination when RAG retrieves irrelevant emotional information. These failures typically manifest as emotionally inappropriate or contextually disconnected responses.

**Three First Experiments:**
1. Evaluate the impact of different chunk sizes on emotional understanding accuracy
2. Test various ensemble generation strategies (majority voting, weighted averaging, etc.)
3. Measure performance degradation when removing the RAG enrichment component

## Open Questions the Paper Calls Out
The paper acknowledges several important open questions regarding the generalizability and limitations of the LongEmotion benchmark. The dataset construction relies on synthetic data generation using GPT-4, which may introduce biases or inconsistencies affecting evaluation results. The six defined tasks represent specific emotional intelligence challenges but may not capture all important aspects of emotional intelligence in long-context interactions. Additionally, the benchmark's focus on Chinese language contexts may limit its applicability to other languages and cultural contexts, raising questions about cross-cultural generalizability.

## Limitations
- Synthetic data generation using GPT-4 may introduce biases that affect benchmark reliability
- The six-task structure may not comprehensively capture all aspects of emotional intelligence in long-context interactions
- Benchmark focus on Chinese language contexts limits cross-cultural applicability and generalizability
- Performance improvements show significant variation across tasks, with some tasks benefiting much more than others

## Confidence
- **High confidence** in the technical implementation and methodology described
- **Medium confidence** in the benchmark's representativeness of real-world emotional intelligence challenges
- **Medium confidence** in the comparative analysis between different model sizes
- **Low confidence** in the cross-cultural generalizability of the findings

## Next Checks
1. Conduct ablation studies to isolate the contribution of each component in the CoEM framework (RAG, multi-agent collaboration, ensemble generation) to verify which elements drive the performance improvements
2. Test the LongEmotion benchmark with additional language models beyond the ones evaluated in the paper to assess consistency of results across different model families
3. Validate the benchmark's task design through human evaluation studies to confirm that the tasks accurately measure emotional intelligence rather than just pattern matching or language understanding