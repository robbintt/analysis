---
ver: rpa2
title: Optimizing Energy Management of Smart Grid using Reinforcement Learning aided
  by Surrogate models built using Physics-informed Neural Networks
arxiv_id: '2510.17380'
source_url: https://arxiv.org/abs/2510.17380
tags:
- energy
- surrogate
- power
- environment
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of optimizing energy management
  in smart grids using reinforcement learning (RL), particularly when dealing with
  costly simulators that hinder sample efficiency. The authors propose using Physics-Informed
  Neural Networks (PINNs) as surrogate models to replace expensive smart grid simulators,
  thereby accelerating the RL policy training process.
---

# Optimizing Energy Management of Smart Grid using Reinforcement Learning aided by Surrogate models built using Physics-informed Neural Networks

## Quick Facts
- arXiv ID: 2510.17380
- Source URL: https://arxiv.org/abs/2510.17380
- Authors: Julen Cestero; Carmine Delle Femine; Kenji S. Muro; Marco Quartulli; Marcello Restelli
- Reference count: 40
- Key outcome: PINN-based surrogate models achieved a 50% reduction in policy training time and a 10x speed-up in inference time compared to the original environment, while maintaining accuracy and reliability.

## Executive Summary
This paper addresses the challenge of optimizing energy management in smart grids using reinforcement learning (RL), particularly when dealing with costly simulators that hinder sample efficiency. The authors propose using Physics-Informed Neural Networks (PINNs) as surrogate models to replace expensive smart grid simulators, thereby accelerating the RL policy training process. The proposed method was tested on the ANM6-Easy environment, a Gym-ANM framework simulating a simple distribution smart grid. Results showed that PINN-based surrogate models achieved a 50% reduction in policy training time and a 10x speed-up in inference time compared to the original environment, while maintaining accuracy and reliability. The PINN surrogate outperformed other state-of-the-art surrogate models (e.g., XGBoost, decision trees) in terms of convergence speed and robustness, demonstrating its effectiveness in capturing the underlying physical nature of the grid.

## Method Summary
The authors propose using Physics-Informed Neural Networks (PINNs) as surrogate models to replace computationally expensive smart grid simulators during RL policy training. The surrogate architecture consists of three neural networks: (1) KKT-informed networks for generator setpoints, (2) battery state transitions with SoC constraints, and (3) power balance network minimizing residuals of power flow equations. The PINN is trained using physics-informed loss functions rather than sampled data from the original environment. A parallel environment wrapper enables vectorized state transitions and parallel execution, achieving ~10x inference speedup. The approach was validated on the ANM6-Easy environment using PPO from Stable-Baselines3, with comprehensive comparisons to data-driven surrogate models (XGBoost, decision trees, DNNs).

## Key Results
- PINN-based surrogate models achieved a 50% reduction in policy training time and a 10x speed-up in inference time compared to the original environment
- The PINN surrogate outperformed other state-of-the-art surrogate models (XGBoost, decision trees) in terms of convergence speed and robustness
- Physics constraints in the loss function prevented error accumulation during long RL episodes, maintaining policy quality

## Why This Works (Mechanism)

### Mechanism 1: Physics-Constrained Surrogate for Sample-Efficient RL
Replacing computationally expensive smart grid simulators with PINN-based surrogates reduces RL policy training time by approximately 50% while maintaining policy quality. The PINN surrogate learns to approximate state transitions f: (st, at) → (st+1, rt) by embedding physical constraints directly into the loss function rather than fitting purely to sampled data. This allows the RL agent to sample transitions without calling the original iterative solver. Core assumption: The physics governing the grid can be expressed as differentiable constraints, and models trained on these constraints generalize better than data-driven models when exploring novel states during RL training.

### Mechanism 2: Physics-Informed Loss Prevents Error Accumulation
PINN surrogates outperform purely data-driven surrogates (XGBoost, decision trees, DNNs) because physics constraints bound extrapolation error, preventing compounding errors during long RL episodes. Data-driven models minimize MAE or maximize R² on test sets but can produce physically inconsistent predictions in unexplored state regions. PINNs explicitly penalize violations of Kirchhoff's laws (power balance equations) via loss terms, ensuring physically plausible predictions even when the agent visits states far from the training distribution. Core assumption: High R² on i.i.d. test data does not guarantee reliability for sequential decision-making, where the agent actively seeks novel states and prediction errors accumulate autocorrelatedly.

### Mechanism 3: Parallelization via Neural Network Surrogate
Replacing iterative numerical solvers with neural network surrogates enables vectorized state transitions and parallel environment execution, achieving ~10x inference speedup. The original ANM6-Easy environment uses Newton-Raphson iteration—an inherently sequential algorithm. Neural networks compute forward passes via matrix operations that parallelize naturally on GPU. The surrogate wrapper supports multiple concurrent environments (n_envs) with configurable buffer_size, allowing the PPO algorithm to collect transitions from n_envs episodes simultaneously. Optimal configuration found: n_envs=100, buffer_size=30.

## Foundational Learning

- **Concept: Physics-Informed Neural Networks (PINNs)**
  - Why needed here: PINNs are the core innovation distinguishing this work from standard surrogate modeling. Understanding how physical constraints are embedded as loss terms is essential for extending the approach.
  - Quick check question: Why does adding PDE residuals to the loss function improve generalization to out-of-distribution inputs compared to pure data-driven training?

- **Concept: RL Sample Efficiency and the Simulator Bottleneck**
  - Why needed here: The paper's motivation hinges on RL requiring millions of environment interactions. Without this context, the surrogate's value is unclear.
  - Quick check question: How many environment transitions are typically required for PPO to converge on a continuous control task, and why does simulator latency compound this cost?

- **Concept: Optimal Power Flow (OPF) and Grid Physics**
  - Why needed here: The surrogate architecture mirrors the OPF problem structure (generator dispatch, power balance, storage dynamics). Interpreting the three-network design requires understanding these physical subsystems.
  - Quick check question: What are the key constraints in AC power flow equations, and why does the slack bus serve as the voltage reference?

## Architecture Onboarding

- **Component map**:
  - Original Environment (ANM6-Easy) -> PINN Surrogate (3 modules) -> Terminal Classifier (XGBoost) -> Parallel Wrapper -> RL Agent (PPO)

- **Critical path**:
  1. Derive physical equations from ANM6-Easy (KKT conditions, power flow equations)
  2. Implement PINN training pipeline with Sobol sequence sampling
  3. Train terminal classifier on balanced dataset from original environment trajectories
  4. Integrate surrogate into parallel wrapper with gym interface
  5. Run structural parameter sweep (n_envs, buffer_size) to find optimal configuration
  6. Train PPO policy on surrogate, periodically evaluate on original environment

- **Design tradeoffs**:
  - Physics-informed vs. data-driven training: PINN requires domain expertise to formulate equations but generalizes robustly. Data-driven is simpler but fails on extrapolation.
  - n_envs vs. buffer_size: More parallel environments increase throughput but larger buffers slow policy updates. Correlation analysis shows buffer_size has stronger negative correlation with reward.
  - Network capacity vs. inference speed: Larger networks improve accuracy but reduce parallelization benefits.

- **Failure signatures**:
  - Data-driven surrogate with high R² but diverging RL policy: XGB achieves R²≈0.9997 but trained agents fail to learn.
  - Daily periodic error spikes: PINN MAE shows 24-hour periodicity correlated with battery SoC dynamics.
  - Parallelization without buffer tuning: Large n_envs with large buffer_size saturates GPU memory, slowing policy updates without improving reward.
  - Terminal classifier errors: 1% false negative rate may allow agent to enter unrecoverable states during training.

- **First 3 experiments**:
  1. Surrogate accuracy validation: Run expert and random agent episodes through both original and surrogate environments. Compute per-timestep MAE. Expect PINN error <0.5 across episode; data-driven baselines show error accumulation on expert trajectories despite similar R².
  2. Physics constraint ablation: Train surrogate variants with/without power balance loss. Measure error growth rate over 1000-step episodes. Expect 3-5x faster error accumulation without physics constraints.
  3. Structural parameter grid search: Test n_envs ∈ {50, 100, 200} × buffer_size ∈ {30, 100, 300}. Track wall-clock time to convergence and final reward. Validate paper's finding that buffer_size=30, n_envs=100 is near-optimal.

## Open Questions the Paper Calls Out
None

## Limitations
- The computational efficiency gains are demonstrated only on the ANM6-Easy environment, a relatively simple 6-bus grid, with untested scalability to larger, more complex grid environments.
- The approach requires significant domain expertise to formulate the underlying physical equations correctly, limiting its applicability without specialized knowledge.
- The daily periodic error pattern in battery state predictions suggests the surrogate may not perfectly capture all physical dynamics, particularly long-term storage behavior.

## Confidence

- **High confidence**: The computational efficiency improvements (speedup measurements, parallelization benefits) are well-supported by direct timing measurements and structural analysis of the algorithms involved.
- **Medium confidence**: The superiority of physics-informed surrogates over data-driven models for RL training is demonstrated but relies on the specific test case and may not generalize to all grid configurations or RL algorithms.
- **Low confidence**: The scalability of the approach to larger, more complex grid environments with different physical characteristics has not been validated.

## Next Checks

1. **Cross-environment generalization test**: Apply the PINN surrogate methodology to a larger, more complex grid environment (e.g., IEEE 30-bus or 118-bus systems) to validate scalability and assess whether the 50% training time reduction holds.

2. **Physical dynamics validation**: Conduct long-term simulations (multiple weeks) on both original and surrogate environments to quantify cumulative error in battery state predictions and assess whether the daily periodic error pattern persists or compounds.

3. **Robustness to grid modifications**: Test whether the PINN surrogate maintains accuracy when grid topology changes (adding/removing buses, lines, or devices) or when new types of physical constraints are introduced, requiring re-derivation of the physics-informed loss terms.