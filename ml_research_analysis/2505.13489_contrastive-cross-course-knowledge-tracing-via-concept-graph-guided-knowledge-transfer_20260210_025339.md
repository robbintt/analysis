---
ver: rpa2
title: Contrastive Cross-Course Knowledge Tracing via Concept Graph Guided Knowledge
  Transfer
arxiv_id: '2505.13489'
source_url: https://arxiv.org/abs/2505.13489
tags:
- knowledge
- cross-course
- learning
- course
- uni00000013
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TransKT, a contrastive cross-course knowledge
  tracing method that leverages concept graph guided knowledge transfer to enhance
  learner performance prediction across multiple courses. The method constructs a
  cross-course concept graph using zero-shot LLM prompting to establish implicit links
  between related concepts, then employs an LLM-to-LM pipeline to extract semantic
  features that enhance GCN-based knowledge transfer.
---

# Contrastive Cross-Course Knowledge Tracing via Concept Graph Guided Knowledge Transfer

## Quick Facts
- arXiv ID: 2505.13489
- Source URL: https://arxiv.org/abs/2505.13489
- Reference count: 23
- Method achieves up to 3.17% AUC and 1.51% accuracy improvement over state-of-the-art baselines

## Executive Summary
This paper introduces TransKT, a method for predicting learner performance across multiple courses by leveraging knowledge transfer through concept graph alignment. The approach constructs a cross-course concept graph using zero-shot LLM prompting to establish implicit links between related concepts, then employs an LLM-to-LM pipeline to extract semantic features that enhance GCN-based knowledge transfer. A cross-course contrastive objective aligns single-course and cross-course knowledge states to improve robustness. Experiments on three real-world cross-course datasets demonstrate that TransKT outperforms state-of-the-art baselines, achieving significant improvements in both AUC and accuracy metrics.

## Method Summary
TransKT constructs a cross-course concept graph by leveraging zero-shot LLM prompts to establish implicit links between related concepts across different courses. It then employs an LLM-to-LM pipeline to extract semantic features that enhance GCN-based knowledge transfer. The method uses a contrastive learning objective to align single-course and cross-course knowledge states, improving prediction robustness. The architecture consists of concept graph construction, semantic feature extraction via LLM summarization, GCN-based knowledge propagation, history encoding with self-attention, and contrastive alignment between single and cross-course knowledge states.

## Key Results
- Achieves up to 3.17% improvement in AUC and 1.51% in accuracy over state-of-the-art baselines
- Contrastive learning module provides consistent performance gains across all datasets
- Ablation studies confirm the effectiveness of each component: concept graph (2.78% AUC gain), semantic features (0.96% AUC gain), and contrastive learning (1.22% AUC gain at 128 interactions)

## Why This Works (Mechanism)

### Mechanism 1: Cross-Course Concept Graph Enables Sparse Knowledge Transfer
- Claim: Establishing implicit concept-concept links across courses allows knowledge state improvements from one course to inform predictions in another, even when explicit concept overlap is absent.
- Mechanism: Zero-shot LLM prompts classify pairwise concept relations (Prerequisite, Used for, Hyponym, Part of) across course boundaries; accepted relations become edges in a unified heterogeneous graph (questions + concepts). GCN layers then propagate semantic embeddings through these edges, allowing mastery signals from Course X to influence concept representations in Course Y.
- Core assumption: LLM-generated cross-course relations reflect pedagogically meaningful transfer pathways that correlate with actual learner skill dependencies.
- Evidence anchors: Abstract states "TransKT constructs a cross-course concept graph by leveraging zero-shot Large Language Model (LLM) prompts to establish implicit links between related concepts across different courses." Section 4.1 details the four relation types and edge creation process.
- Break condition: If LLM-generated relations have low precision (<50% pedagogically valid by expert review), GCN will propagate noise, degrading cross-course transfer.

### Mechanism 2: LLM-to-LM Pipeline Extracts Transferable Semantic Features
- Claim: Summarizing heterogeneous question/concept text via LLM, then encoding with a fine-tuned LM, produces embeddings that generalize better across courses than raw text or ID-based embeddings.
- Mechanism: (1) LLM receives prompt with course context and raw text, outputs structured summary (≤120 words); (2) RoBERTa-style LM fine-tuned on downstream KT objective encodes summary into D-dimensional vector; (3) These vectors initialize node features in GCN. The summarization normalizes format variance (e.g., code snippets vs. abstract concept names), enabling meaningful similarity computation across courses.
- Core assumption: LLM summaries capture task-relevant semantics while filtering format-specific noise; the LM encoder preserves these signals through fine-tuning.
- Evidence anchors: Section 4.2 describes the "open-ended" LLM summarization method. Table 3 shows baselines enhanced with semantic features demonstrate +0.96% average AUC improvement.
- Break condition: If questions are primarily code or mathematical notation where LLM summarization introduces hallucination or information loss, semantic features may underperform ID baselines.

### Mechanism 3: Contrastive Alignment Reduces Cross-Course Noise
- Claim: Enforcing mutual information maximization between single-course and cross-course knowledge states filters course-irrelevant noise while retaining transferable signals.
- Mechanism: For each learner, compute: (a) single-course history embedding g_X via self-attention over Course X interactions; (b) cross-course embedding g_{X∪Y} over merged interactions. Contrastive loss pulls (g_X, g_{X∪Y}) together while pushing (g_X, corrupted g_{X∪Y}) apart. Corruption uses hybrid hard negatives: response flipping and difficulty-based question replacement.
- Core assumption: Shared structure between single and cross-course views corresponds to transferable knowledge; divergent structure is noise.
- Evidence anchors: Section 4.4 explains the contrastive objective aims to "encourage the correlation of learners' knowledge states within and across courses." Figure 4 shows contrastive benefit scales with history length (1.22% AUC gain at 128 interactions).
- Break condition: If cross-course interactions are temporally interleaved with high variance in course relevance, alignment may suppress useful course-specific signals.

## Foundational Learning

- Concept: Knowledge Tracing (KT)
  - Why needed here: Core task definition—predicting future response correctness from interaction history; understanding sequential modeling of knowledge states is prerequisite.
  - Quick check question: Can you explain how DKT models knowledge state evolution differently from memory-based approaches like DKVMN?

- Concept: Graph Convolutional Networks (GCN) / GraphSAGE
  - Why needed here: GCN propagates information through the cross-course concept graph; understanding neighborhood aggregation is essential for debugging transfer quality.
  - Quick check question: Given a node with 5 neighbors, how does one GCN layer update its representation, and what happens if depth L is too large?

- Concept: Contrastive Learning with Mutual Information
  - Why needed here: The cross-course contrastive objective is the noise-filtering mechanism; understanding InfoNCE-style losses and hard negative sampling is critical.
  - Quick check question: Why would flipping responses or replacing questions with harder/easier versions create useful hard negatives for knowledge state discrimination?

## Architecture Onboarding

- Component map:
  1. Concept Graph Constructor: LLM zero-shot prompts → relation classification → edge creation (offline, one-time per course pair)
  2. LLM-to-LM Encoder: LLM summarization → RoBERTa fine-tuning → D-dim node features (trainable)
  3. GCN Knowledge Transfer: L-layer GraphSAGE over unified graph → enhanced question/concept embeddings
  4. History Encoder: Self-attention over padded interaction sequences → knowledge state vectors g_X, g_Y, g_{X∪Y}
  5. Contrastive Module: Bilinear discriminator + hybrid hard negative sampler → alignment loss
  6. Prediction Head: Concatenate joint state ĥ with target question embedding → BCE loss

- Critical path:
  Graph construction (offline) → LLM-to-LM encoding (once per question/concept) → GCN propagation (per epoch) → History encoding (per batch) → Contrastive + prediction losses (per batch)

- Design tradeoffs:
  - LLM cost vs. quality: Zero-shot relation extraction is cheap but noisy; few-shot prompting (5 examples in appendix) improves consistency at higher API cost
  - GCN depth L: L=1-2 balances multi-hop transfer and over-smoothing; L≥4 degrades performance
  - η (state blending): Controls single vs. cross-course influence; higher η helps when target course has sparse data, lower η when cross-course noise is high

- Failure signatures:
  - Cross-course AUC < single-course baseline → concept graph edges may be invalid; audit LLM relations
  - Performance drops for learners with short histories (<16 interactions) → contrastive objective under-constrained; consider disabling contrastive loss below threshold
  - Semantic ablation (w/o.LLM) outperforms full model → LLM summaries may introduce artifacts for domain-specific content; inspect summary quality

- First 3 experiments:
  1. Graph validation: Sample 100 LLM-generated cross-course edges; have domain experts label validity. Target >70% precision before GCN deployment.
  2. Encoding ablation: Compare (a) ID embeddings, (b) raw text → LM, (c) LLM summary → LM on held-out course pair. Identify content types where summarization helps vs. hurts.
  3. Contrastive sensitivity: Train with/without contrastive loss across history length bins [16, 32, 64, 128]. Verify that gains scale with length; if not, inspect negative sampling corruption rate θ₁, θ₂.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does TransKT scale to scenarios involving more than two simultaneous courses?
- **Basis in paper:** The formalization in Section 3 and experiments in Section 5 are restricted to two courses ($X$ and $Y$).
- **Why unresolved:** The padding strategy and the contrastive objective (aligning $g_X$ and $g_{X \cup Y}$) are explicitly designed for binary course relationships; extending the mutual information maximization to $N$ courses introduces alignment complexity not addressed by the current architecture.
- **What evidence would resolve it:** Performance benchmarks on datasets where learners are enrolled in three or more courses simultaneously, along with an analysis of how the contrastive loss adapts.

### Open Question 2
- **Question:** To what extent does the model's performance depend on the accuracy of the LLM-generated concept graph?
- **Basis in paper:** Section 4.1 relies on zero-shot LLM prompting to establish implicit links, which is prone to hallucination or inconsistency.
- **Why unresolved:** While the ablation study removes the graph entirely, it does not evaluate the model's robustness against a noisy graph containing spurious LLM-generated edges versus a manually curated ground truth.
- **What evidence would resolve it:** A comparative analysis of model performance using a human-verified "gold standard" graph versus the raw LLM-generated graph.

### Open Question 3
- **Question:** Is the LLM-to-LM pipeline effective for non-STEM subjects where concepts are less structured than code?
- **Basis in paper:** Section 5.1 validates the model exclusively on Computer Science and Mathematics datasets.
- **Why unresolved:** The semantic enhancement is optimized for "intricate code" and algorithmic logic; it is unclear if the same transfer mechanisms work for domains with subjective or ambiguous textual descriptions (e.g., humanities).
- **What evidence would resolve it:** Experimental results on cross-course datasets from non-STEM fields, such as history or literature.

## Limitations
- Zero-shot LLM relation extraction may introduce noise that isn't fully quantified, potentially degrading transfer quality
- Hybrid hard negative sampling strategy lacks specification of parameter thresholds (θ₁, θ₂)
- Generalizability beyond programming courses remains unverified; semantic features may not transfer to less structured domains

## Confidence
- **High confidence**: The core contrastive learning framework and its role in reducing cross-course noise is well-established
- **Medium confidence**: Empirical improvements on three datasets are compelling, but absolute gains may not justify additional complexity for all applications
- **Medium confidence**: The semantic feature extraction via LLM-to-LM pipeline shows promise but lacks extensive ablation across content types beyond programming

## Next Checks
1. Conduct expert review of 100 random cross-course concept relations from the graph to quantify precision and identify systematic LLM generation errors
2. Implement the hybrid hard negative sampling with varying θ₁, θ₂ thresholds to measure impact on contrastive learning effectiveness
3. Test TransKT on non-programming domains (e.g., mathematics, language learning) to assess generalizability of the LLM-based semantic features