---
ver: rpa2
title: 'NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary
  Markov Decision Processes'
arxiv_id: '2501.09646'
source_url: https://arxiv.org/abs/2501.09646
tags:
- environment
- agent
- change
- non-stationary
- ns-gym
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces NS-Gym, the first open-source simulation
  toolkit and benchmark suite for non-stationary Markov decision processes (NS-MDPs).
  The authors identify four key characteristics affecting decision-making in NS-MDPs:
  what changes, how it changes, whether changes are detectable, and whether their
  magnitude is known.'
---

# NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes

## Quick Facts
- arXiv ID: 2501.09646
- Source URL: https://arxiv.org/abs/2501.09646
- Reference count: 40
- First open-source simulation toolkit and benchmark suite for non-stationary Markov decision processes (NS-MDPs)

## Executive Summary
This paper introduces NS-Gym, an open-source toolkit that addresses the critical need for standardized benchmarking in non-stationary Markov decision processes (NS-MDPs). The authors identify four key characteristics that define NS-MDPs: what changes, how it changes, whether changes are detectable, and whether their magnitude is known. Building on the popular Gymnasium framework, NS-Gym provides wrappers that introduce non-stationarity through parameter changes in classic environments like CartPole and FrozenLake. The toolkit supports various problem types and configurable notification levels for agents, enabling reproducible evaluation of decision-making algorithms under changing conditions.

## Method Summary
NS-Gym extends the Gymnasium framework by introducing a scheduler component that manages non-stationarity through parameter changes in base environments. The toolkit implements four notification levels ranging from no notifications to full model knowledge, allowing agents to detect and adapt to environmental changes at different granularities. The framework wraps classic control and grid-world environments, applying non-stationarity through random walks, stepwise changes, and cyclical variations. Six algorithms were benchmarked including MCTS, AlphaZero, DDQN, PAMCTS, ADA-MCTS, and RATS across different NS-MDP settings to evaluate performance under varying notification levels and change patterns.

## Key Results
- Detailed notifications generally improve algorithm performance across all tested environments and methods
- Risk-averse strategies (particularly RATS) show superior performance in highly stochastic environments compared to standard approaches
- The notification level significantly impacts agent performance, with full model knowledge providing the best results when available
- Different non-stationarity patterns (random walks, stepwise, cyclical) affect algorithm performance differently, highlighting the importance of adaptable strategies

## Why This Works (Mechanism)
The framework works by systematically introducing controlled non-stationarity into standard MDP environments, allowing researchers to study how different algorithms respond to environmental changes. The scheduler component manages parameter changes while the notification system provides varying levels of information about these changes, creating a controlled experimental setup that isolates the effects of non-stationarity on decision-making performance.

## Foundational Learning
**MDP vs NS-MDP**: Standard MDPs assume stationary transition and reward functions, while NS-MDPs explicitly model temporal changes in these components. This distinction is crucial for understanding how algorithms must adapt their strategies over time.

**Change Detection Mechanisms**: The framework implements different levels of change detection, from no notification to full model updates, reflecting the spectrum of information availability agents might have in real-world scenarios.

**Risk-Averse Decision Making**: In highly stochastic NS-MDPs, strategies that explicitly account for uncertainty and potential losses (like RATS) can outperform standard risk-neutral approaches.

**Algorithm Adaptation**: Successful NS-MDP algorithms must balance exploration with the need to quickly adapt to environmental changes, requiring mechanisms beyond standard reinforcement learning approaches.

## Architecture Onboarding

**Component Map**: Base Environment -> NS-Gym Wrapper -> Scheduler -> Notification System -> Agent

**Critical Path**: The scheduler drives non-stationarity by modifying environment parameters according to predefined patterns, while the notification system communicates change information to the agent, which must then adapt its policy accordingly.

**Design Tradeoffs**: The framework trades computational overhead from the additional wrapper and scheduler layers against the benefit of standardized NS-MDP experimentation. The notification system represents a key design choice that affects both agent performance and real-world applicability.

**Failure Signatures**: Agents may fail to detect changes (under-adaptation), overreact to noise (over-adaptation), or struggle with continuous vs discrete parameter changes. Performance degradation typically correlates with the mismatch between notification level and actual change patterns.

**First Experiments**:
1. Run CartPole with stepwise changes and no notification to establish baseline performance degradation
2. Compare MCTS with and without notification in FrozenLake to quantify the benefit of change detection
3. Test RATS vs standard DDQN in CliffWalker under high stochasticity to validate risk-averse advantage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the risk-averse strategies that performed well in grid-world benchmarks (e.g., RATS) scale effectively to the high-dimensional, continuous control problems cited as motivation?
- Basis in paper: [explicit] The introduction lists autonomous driving and medical diagnosis as key applications, but the benchmark experiments are restricted to low-dimensional classic control (CartPole) and grid-worlds.
- Why unresolved: Computational costs for tree-search and risk analysis likely scale poorly with state dimension, limiting applicability to the motivating real-world scenarios.
- What evidence would resolve it: Benchmark results demonstrating the performance and latency of NS-Gym algorithms on high-dimensional continuous control environments.

### Open Question 2
- Question: How does the performance of algorithms degrade when the "runtime monitor" provides imperfect notifications (e.g., false positives or detection delays)?
- Basis in paper: [inferred] The framework explicitly defines a "runtime monitor" component to detect changes, but the benchmark experiments assume perfect binary notification or full model knowledge without modeling detection errors.
- Why unresolved: Real-world anomaly detectors are noisy, and the robustness of the benchmarked agents to erroneous change notifications remains unquantified.
- What evidence would resolve it: Experiments evaluating agent performance where the `env_change` notification signal has a configurable probability of error or latency.

### Open Question 3
- Question: How can the framework be extended to model adversarial non-stationarity, where parameter changes are driven by an opponent rather than a stochastic process?
- Basis in paper: [inferred] The paper reviews prior work involving various "Nature of the change" (Table 1), but the current implementation focuses on random walks and stepwise changes, omitting adversarial drift mentioned in related literature.
- Why unresolved: Many security applications involve intentional manipulation of environment parameters, which requires distinct algorithmic approaches beyond those tested on stochastic drifts.
- What evidence would resolve it: An extension of the `Scheduler` class to support adversarial optimization and subsequent benchmarking of agents in that setting.

## Limitations
- Limited to a small set of base environments that may not represent real-world NS-MDP diversity
- Benchmark results based on only six algorithms, potentially limiting generalizability
- Notification levels may not capture the full spectrum of information availability in practical applications
- Current framework focuses on discrete parameter changes, potentially limiting applicability to continuous dynamics

## Confidence

**High Confidence**: The core contribution of providing an open-source toolkit with standardized interfaces for NS-MDP research is well-established and reproducible.

**Medium Confidence**: The claim that detailed notifications generally improve performance is supported by the benchmarks but may vary depending on specific algorithm implementations and problem types.

**Medium Confidence**: The observation that risk-averse strategies perform better in highly stochastic environments is reasonable but would benefit from broader validation across more diverse problem settings.

## Next Checks
1. Extend benchmarking to include a wider range of existing NS-MDP algorithms from recent literature to validate generalizability of performance trends
2. Test the toolkit's notification system with real-world NS-MDP problems or more complex simulated environments to assess practical utility
3. Evaluate the framework's performance with continuous parameter changes and compare results against discrete change scenarios to understand limitations