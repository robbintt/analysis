---
ver: rpa2
title: 'From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature
  Learning'
arxiv_id: '2510.24812'
source_url: https://arxiv.org/abs/2510.24812
tags:
- have
- data
- inequality
- training
- follows
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates weak-to-strong generalization, where a
  stronger model trained under supervision from a weaker model can outperform its
  teacher. The authors analyze this phenomenon in a structured binary classification
  setting, using linear CNNs as weak models and two-layer ReLU CNNs as strong models.
---

# From Linear to Nonlinear: Provable Weak-to-Strong Generalization through Feature Learning

## Quick Facts
- arXiv ID: 2510.24812
- Source URL: https://arxiv.org/abs/2510.24812
- Authors: Junsoo Oh; Jerry Song; Chulhee Yun
- Reference count: 40
- Primary result: Proves conditions for weak-to-strong generalization across overfitting regimes in binary classification

## Executive Summary
This paper provides theoretical analysis of weak-to-strong generalization, where a stronger model trained under supervision from a weaker model can outperform its teacher. The authors examine this phenomenon using linear CNNs as weak models and two-layer ReLU CNNs as strong models in a structured binary classification setting. They identify two distinct regimes - data-scarce and data-abundant - each exhibiting different generalization behaviors. The analysis reveals that weak-to-strong generalization can occur through benign overfitting in the data-scarce regime or early stopping in the data-abundant regime, while overtraining can lead to performance degradation.

## Method Summary
The authors analyze weak-to-strong generalization in a structured binary classification setting using Gaussian data distributions. They compare linear CNNs (weak models) against two-layer ReLU CNNs (strong models) with identical architectures except for the activation function. The theoretical framework examines how the stronger model generalizes when trained under supervision from the weaker model's outputs. The analysis characterizes conditions for transitioning between different overfitting behaviors and proves when weak models can achieve near-optimal performance. The theoretical predictions are validated through experiments that demonstrate the existence of distinct overfitting regimes and the effectiveness of early stopping in the data-abundant regime.

## Key Results
- Proves existence of data-scarce and data-abundant regimes with distinct generalization behaviors
- Shows weak-to-strong generalization can occur via benign overfitting (data-scarce) or early stopping (data-abundant)
- Demonstrates that overtraining in data-abundant regime leads to performance degradation
- Characterizes conditions for transitions between harmful and benign overfitting behaviors
- Proves weak models can achieve near-optimal performance under certain conditions

## Why This Works (Mechanism)
Weak-to-strong generalization works through the strong model's ability to leverage the weaker model's learned features while adding its own nonlinear processing capabilities. In the data-scarce regime, the strong model can overfit in a beneficial way by learning to correct the weaker model's mistakes while inheriting its good features. In the data-abundant regime, the strong model can initially benefit from the weaker model's guidance but eventually overfits to noise if trained too long. The mechanism relies on the strong model's capacity to learn more expressive representations while being constrained by the weaker model's supervision.

## Foundational Learning
- **Gaussian data distributions**: Why needed - simplifies theoretical analysis; Quick check - verify assumptions hold in practice
- **Binary classification**: Why needed - reduces complexity for theoretical proofs; Quick check - test if results extend to multi-class
- **Overfitting regimes**: Why needed - characterizes different generalization behaviors; Quick check - measure test error vs. training data size
- **Early stopping**: Why needed - prevents overtraining in data-abundant regime; Quick check - compare performance with/without early stopping
- **Benign vs. harmful overfitting**: Why needed - distinguishes beneficial from detrimental overfitting; Quick check - analyze error decomposition
- **Feature learning**: Why needed - explains how strong models improve upon weak models; Quick check - visualize learned features

## Architecture Onboarding

Component Map:
Linear CNN (weak) -> ReLU CNN (strong) -> Classification Output

Critical Path:
The critical path involves the strong model learning to improve upon the weak model's predictions while maintaining the beneficial features learned by the weak model. This occurs through the strong model's ability to fit the residual errors of the weak model while preserving the overall structure of the weak model's decision boundary.

Design Tradeoffs:
The main tradeoff is between model capacity and generalization. Higher capacity in the strong model enables better feature learning but also increases overfitting risk. The choice of when to stop training (early stopping) balances the benefits of additional learning against the risks of overfitting.

Failure Signatures:
- Harmful overfitting: Performance degrades with more training data or longer training
- Lack of generalization: Strong model fails to outperform weak model despite higher capacity
- Early overfitting: Strong model overfits before learning useful features from weak model

First Experiments:
1. Compare test accuracy of weak vs. strong models across different dataset sizes
2. Measure performance degradation with overtraining in data-abundant regime
3. Test early stopping effectiveness by comparing performance with various stopping criteria

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis limited to binary classification with specific CNN architectures (linear vs. two-layer ReLU)
- Theoretical framework assumes Gaussian data distributions which may not hold in practice
- Results may not generalize to other model families (e.g., transformers, MLPs)
- Early stopping benefits depend on specific implementation details and may not transfer to all settings

## Confidence
- High confidence in theoretical characterization of overfitting regimes under stated assumptions
- Medium confidence in the generalizability of results to other architectures and data distributions
- Medium confidence in experimental validation given the specific experimental setup

## Next Checks
1. Test the theoretical predictions with different data distributions (non-Gaussian) and classification tasks (multi-class) to assess robustness
2. Evaluate the early stopping criterion on larger-scale models and real-world datasets to verify practical utility
3. Compare weak-to-strong generalization performance across different model architectures (e.g., transformers, MLPs) to establish broader applicability