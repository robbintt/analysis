---
ver: rpa2
title: 'What matters for Representation Alignment: Global Information or Spatial Structure?'
arxiv_id: '2512.10794'
source_url: https://arxiv.org/abs/2512.10794
tags:
- spatial
- generation
- irepa
- repa
- structure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Representation alignment (REPA) accelerates diffusion transformer
  training by distilling features from pretrained vision encoders. While widely used,
  the key factors driving REPA effectiveness remain unclear.
---

# What matters for Representation Alignment: Global Information or Spatial Structure?

## Quick Facts
- arXiv ID: 2512.10794
- Source URL: https://arxiv.org/abs/2512.10794
- Reference count: 40
- Primary result: Spatial structure, not global semantic accuracy, drives generation quality in representation alignment; spatial self-similarity metrics correlate >0.85 with FID scores vs 0.26 for ImageNet-1K accuracy.

## Executive Summary
Representation alignment (REPA) is widely used to accelerate diffusion transformer training by distilling features from pretrained vision encoders. However, what makes an encoder a good teacher for generation remains unclear. Through large-scale analysis across 27 diverse encoders and 3 model scales, this work reveals that spatial structure—measured by spatial self-similarity metrics—is the key factor driving generation quality, not global semantic performance. To leverage this insight, the authors introduce iREPA, a simple method using a convolutional projection layer and spatial normalization that consistently improves REPA convergence speed across diverse encoders, model sizes, and training recipes. These modifications can be implemented in fewer than 4 lines of code.

## Method Summary
The paper analyzes representation alignment for diffusion transformers by first identifying what properties of pretrained encoders matter for generation quality. It introduces the iREPA method, which modifies standard REPA through two simple changes: replacing the standard MLP projection layer with a lightweight convolutional layer (kernel size 3) to preserve spatial locality, and applying spatial normalization to target encoder features before alignment to maximize spatial contrast by removing global information. These modifications are shown to consistently improve REPA convergence speed across diverse encoders, model sizes, and training recipes including REPA, REPA-E, Meanflow, and JiT.

## Key Results
- Spatial self-similarity metrics show correlation coefficients above 0.85 with FID scores, compared to only 0.26 for ImageNet-1K accuracy.
- iREPA consistently improves REPA convergence speed across diverse encoders, model sizes, and training recipes.
- The method can be implemented in fewer than 4 lines of code.

## Why This Works (Mechanism)

### Mechanism 1
Representation alignment effectiveness for generation is strongly predicted by the spatial self-similarity structure of the target encoder, not its global semantic accuracy. The alignment loss distills the relational geometry between patch tokens (local vs. distant similarity) rather than just classification-relevant features. When an encoder maintains high spatial contrast (patches closer together are significantly more similar than distant ones), it provides a stronger learning signal for the diffusion model to organize its own latent space effectively. The diffusion model benefits more from learning "where things are relative to each other" than "what things are" globally during the alignment phase.

### Mechanism 2
Removing the global component from patch tokens via spatial normalization improves alignment by maximizing spatial contrast. Pretrained patch tokens often contain a strong "global overlay" (mean vector) that makes dissimilar regions appear correlated. By subtracting the spatial mean (and scaling), the method strips away this global signal, forcing the student model to focus on the residuals that define local spatial relationships (e.g., object boundaries vs. background). The "global overlay" in patch tokens acts as noise for the specific task of spatial structure transfer.

### Mechanism 3
Replacing a standard MLP projection layer with a lightweight Convolutional layer preserves spatial locality during dimensionality mapping. MLPs typically process tokens independently or flatten spatial structures, effectively scrambling the precise local neighborhood relationships required for the spatial alignment loss. A convolutional layer (kernel size 3) operates on local neighborhoods, acting as an inductive bias that preserves the relative positions of features before alignment. The standard MLP projection is lossy specifically regarding the local spatial geometry needed for generation.

## Foundational Learning

- **Concept: Spatial Self-Similarity (LDS Metric)**
  - Why needed here: This is the proposed proxy for "spatial structure." You must understand how to calculate the correlation between patch tokens as a function of their Manhattan distance to grasp why some encoders fail despite high accuracy.
  - Quick check question: If an encoder has high ImageNet accuracy but low LDS (Local vs. Distant Similarity), would the paper predict it to be a good or bad target for REPA? (Answer: Bad).

- **Concept: Representation Alignment (REPA)**
  - Why needed here: This is the base training technique being debugged and improved. You need to know that it involves minimizing a distance (e.g., MSE) between intermediate diffusion features and a frozen encoder's features.
  - Quick check question: In standard REPA, what component does iREPA propose replacing to stop the loss of spatial information? (Answer: The MLP projection layer).

- **Concept: Global vs. Local Feature Trade-off**
  - Why needed here: The paper challenges the dogma that "better global semantics = better teacher." You must distinguish between features good for classification (global semantics) and features good for generation (spatial coherence).
  - Quick check question: Why does adding global info (CLS token) to patch tokens hurt generation performance in this framework? (Answer: It reduces spatial contrast/self-similarity structure).

## Architecture Onboarding

- **Component map:** Image $I$ -> Encoder (Frozen) -> Patch Tokens $X$ -> Spatial Norm ($X_{norm}$) -> Diffusion Transformer intermediate features $F$ -> Conv Proj ($F_{proj}$) -> Loss (align $F_{proj}$ to $X_{norm}$)

- **Critical path:** The success of iREPA relies on the strict preservation of the *pairwise similarity matrix* of the tokens as they pass through the projection and normalization layers.

- **Design tradeoffs:**
  - Sacrificing Global Semantics: By aggressively normalizing (removing the mean), you lose global classification power in the target features. This is intentional to boost spatial contrast.
  - Convolutional Bottleneck: A Conv layer limits the projection to local interactions. If the alignment requires global mixing of channels, this might be restrictive, though the paper suggests it is beneficial.

- **Failure signatures:**
  - High FID with High-Accuracy Encoders: If your target encoder has high ImageNet accuracy but the model FID is stagnating, check the spatial structure (LDS) of the encoder—it likely has low spatial contrast.
  - Loss of Fine Details: If the Conv projection is too aggressive or spatial normalization ($\gamma$) is too high, you might see images that are spatially coherent but lack global semantic consistency (e.g., "dog" shape is right, but texture is wrong).

- **First 3 experiments:**
  1. Calculate the LDS score for 3 different encoders (e.g., DINOv2, CLIP, SAM2) and plot against their resulting FID when training a small SiT model to verify the $r > 0.85$ correlation claim.
  2. Implement iREPA with only the Conv projection (keep MLP, add Norm) and vice versa to measure the individual contribution of spatial normalization vs. local projection.
  3. Implement the "CLS token mixing" experiment from Section 2 on a baseline encoder to observe if adding global info actually degrades FID as predicted (sensitivity analysis).

## Open Questions the Paper Calls Out

### Open Question 1
What is the theoretical mechanism linking spatial self-similarity to improved denoising efficiency in diffusion transformers? The authors state in the conclusion that despite empirical successes, "there remains limited understanding of the precise mechanisms" and hope to "motivate future research to revisit the fundamental working mechanism of representational alignment." The paper establishes a strong empirical correlation ($|r| > 0.85$) between spatial metrics and FID, but does not derive a causal theoretical framework explaining why preserving spatial contrast accelerates the denoising process.

### Open Question 2
Can vision encoders be specifically trained or fine-tuned to maximize spatial structure metrics (LDS/SSM) for superior generation alignment? The paper analyzes 27 *existing* encoders (CLIP, DINO, etc.) which are trained for classification or segmentation. The finding that spatial structure is the key driver suggests current encoders are suboptimal byproducts rather than optimal targets. It is unknown if the "spatial structure" found in encoders like SAM2 or PE-Spatial is the upper bound, or if a dedicated training regime could produce better representations for generation than semantic classification.

### Open Question 3
Does the negative impact of global semantic information (CLS token mixing) persist in high-resolution synthesis or text-to-image tasks requiring strong semantic coherence? The paper shows adding global info hurts generation on ImageNet-256. However, text-to-image generation (e.g., Stable Diffusion) often relies on CLIP's global semantics for prompt adherence. The experiments focus primarily on class-conditional ImageNet (256px). It is unclear if the "global info hurts" principle applies when the generative task explicitly requires binding specific global concepts (text) to the image.

## Limitations
- The findings are demonstrated for diffusion transformers on ImageNet-256, and generalization to other generative tasks or non-diffusion architectures remains untested.
- The encoder diversity analysis may have sampling bias, as the specific selection and representation across architectural families is not explicitly addressed.
- The LDS metric's exact implementation details and sensitivity to different normalization schemes are not fully elaborated, making replication potentially dependent on undocumented choices.

## Confidence
- **High Confidence**: The empirical finding that spatial self-similarity metrics (LDS) correlate strongly (r > 0.85) with generation performance (FID) while global accuracy (ImageNet-1K) correlates weakly (r ≈ 0.26) is directly supported by the large-scale analysis across 27 encoders and three model scales.
- **Medium Confidence**: The mechanistic explanation for why spatial structure is more important than global semantics for diffusion training is plausible and supported by ablation evidence, but relies on indirect inference.
- **Medium Confidence**: The claim that iREPA's modifications are "easily implemented in fewer than 4 lines of code" is accurate for the core changes but may understate the effort required for correct integration into different REPA variants.

## Next Checks
1. Re-implement the LDS metric calculation and verify its correlation with FID across a *new* set of diverse pretrained encoders not used in the original study (e.g., MAE, BEiT, OpenCLIP).
2. Apply iREPA to a non-DiT generative architecture (e.g., a GAN or a flow-based model) that uses representation alignment.
3. Train a diffusion transformer on a higher-resolution dataset (e.g., ImageNet-512) with and without iREPA.