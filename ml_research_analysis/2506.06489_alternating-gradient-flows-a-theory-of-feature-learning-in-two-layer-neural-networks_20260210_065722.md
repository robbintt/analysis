---
ver: rpa2
title: 'Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural
  Networks'
arxiv_id: '2506.06489'
source_url: https://arxiv.org/abs/2506.06489
tags:
- learning
- utility
- networks
- neurons
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Alternating Gradient Flows (AGF), a framework
  that approximates gradient flow in two-layer neural networks with small initialization
  by alternating between utility maximization over dormant neurons and cost minimization
  over active ones. AGF characterizes feature learning as a saddle-to-saddle process
  where each iteration involves dormant neurons independently maximizing their utility
  (alignment to residuals) before the first to reach a threshold becomes active and
  joins a collective cost minimization phase.
---

# Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks

## Quick Facts
- arXiv ID: 2506.06489
- Source URL: https://arxiv.org/abs/2506.06489
- Reference count: 40
- Primary result: AGF approximates gradient flow in two-layer networks by alternating between dormant neuron utility maximization and active neuron cost minimization, predicting feature emergence order and loss dynamics.

## Executive Summary
This paper introduces Alternating Gradient Flows (AGF), a framework that approximates gradient flow in two-layer neural networks with small initialization by alternating between utility maximization over dormant neurons and cost minimization over active ones. AGF characterizes feature learning as a saddle-to-saddle process where each iteration involves dormant neurons independently maximizing their utility (alignment to residuals) before the first to reach a threshold becomes active and joins a collective cost minimization phase. The authors prove AGF converges to gradient flow for diagonal linear networks in the vanishing initialization limit, unifies prior analyses of saddle-to-saddle dynamics in fully connected linear networks (learning singular vectors) and attention-only linear transformers (learning principal components), and extends to novel settings by characterizing Fourier feature emergence in modular addition tasks. Experiments across these architectures show AGF accurately predicts the order, timing, and magnitude of loss drops during training, offering a promising step toward understanding feature learning through optimization dynamics.

## Method Summary
AGF approximates training of two-layer networks from small initialization (α ≪ 1) by partitioning neurons into dormant (‖θ_i‖ < O(1)) and active (‖θ_i‖ = O(1)) sets. Dormant neurons evolve independently via projected gradient flow on the unit sphere to maximize utility U_i(θ; r) = E_x[⟨f_i(x; θ), r(x)⟩] measuring alignment with the residual. The first neuron reaching accumulated utility S_i(t) = ∫ κŪ_i(s)ds > c_i/η activates and joins active neurons in minimizing L(Θ_A) via gradient flow. This alternation continues until no dormant neurons have non-zero utility gradient. The framework requires time rescaling η = E[c_i] for meaningful dynamics as α→0, and convergence to gradient flow is proven for diagonal linear networks.

## Key Results
- Proves AGF converges to gradient flow for diagonal linear networks as α→0, matching jump times and loss levels from prior constrained Lasso analyses
- Unifies saddle-to-saddle analyses across architectures: singular vector learning in fully connected linear networks and principal component learning in attention-only transformers
- Predicts Fourier feature emergence order in modular addition tasks, showing neurons align with dominant harmonics in decreasing order of their DFT magnitudes
- Demonstrates transition from discrete staircase loss curves to smooth "slide" behavior as network width increases relative to initialization scale

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Directional and radial parameter dynamics separate into distinct timescales near saddle points when initialization scale α → 0.
- Mechanism: For κ-homogeneous activations, directional dynamics dθ̄/dt scale as ‖θ‖^(κ−2) while radial dynamics d‖θ‖/dt scale as ‖θ‖^(κ−1). When ‖θ‖ ≪ 1, directional alignment occurs O(1/‖θ‖) times faster than radial growth, allowing dormant neurons to align to utility-maximizing directions before growing.
- Core assumption: Initialization scale α sufficiently small; homogeneous or approximately homogeneous activation σ with σ(0)=0.
- Evidence anchors:
  - [Section 2.1]: Equation (2) explicitly derives the separated dynamics with scaling factors ‖θ‖^(κ−2) and ‖θ‖^(κ−1).
  - [Section B.4]: Theorem B.2 proves alignment time scales as α^(κ−2), converging to instantaneous alignment for κ=2 as α→0.
  - [corpus]: Related work on early alignment in ReLU networks (Maennel et al. [56], Kumar & Haupt [58,59]) observes similar directional-radial separation, but AGF extends this to a unified saddle-to-saddle framework.
- Break condition: When κ > 2, alignment is not instantaneous without adaptive learning rates (Section B.5); when multiple neurons reach activation thresholds simultaneously, the discrete alternating structure breaks down (Figure 7).

### Mechanism 2
- Claim: Feature selection is governed by maximizing a utility function U_i(θ; r) = E_x[⟨f_i(x; θ), r(x)⟩] that measures alignment with the residual.
- Mechanism: Dormant neurons evolve independently via projected gradient flow on the unit sphere to maximize utility. The neuron first reaching accumulated utility S_i(t) = ∫ κŪ_i(s)ds > c_i/η activates, where c_i depends on initialization norm. This creates a race condition selecting features most correlated with remaining prediction error.
- Core assumption: Residual r(x) remains approximately constant during utility maximization (dormant neurons contribute negligibly).
- Evidence anchors:
  - [Section 2.1]: Equation (1) defines utility; Equation (3) defines jump time via accumulated utility threshold.
  - [Section 5, Theorem 5.1]: For modular addition, utility maximization forces neurons to align with dominant Fourier harmonics of the embedding vector.
  - [corpus]: The mean-field model of feature learning (arxiv:2510.15174) similarly identifies alignment with data structure as the driver of feature emergence, but uses Bayesian posteriors rather than optimization dynamics.
- Break condition: If utility landscape has multiple local maxima (not proven for all settings), neurons may converge to suboptimal features; active neurons returning to dormancy (Section B.3) can delay or redirect feature acquisition.

### Mechanism 3
- Claim: Training proceeds through discrete saddle-to-saddle transitions, with loss drops corresponding to cost minimization over newly activated neurons.
- Mechanism: After a neuron activates, all active neurons jointly minimize L(Θ_A) via gradient flow, reaching a constrained local minimum (e.g., Equation (5) for diagonal networks). The new residual defines utility for remaining dormant neurons. This alternation continues until no dormant neurons have non-zero utility gradient.
- Core assumption: Active neurons reach equilibrium before next activation; cost minimization converges to a critical point of the restricted loss.
- Evidence anchors:
  - [Section 2.2, Algorithm 1]: Formal specification of the alternating utility maximization and cost minimization steps.
  - [Section 3, Theorem 3.1]: Proves AGF converges to gradient flow trajectory for diagonal linear networks as α→0, with jump times and loss levels matching Pesme & Flammarion [18].
  - [corpus]: Phase transition analyses (arxiv:2602.01434) describe similar stepwise learning in multi-index models but focus on sample complexity rather than optimization dynamics.
- Break condition: When width H is large relative to initialization scale, multiple activations occur in rapid succession, smoothing the staircase into a "slide" (Figure 7); smooth loss curves on natural data may indicate overlapping cost-minimization phases.

## Foundational Learning
- Concept: Gradient flow and neural tangent kernel regimes
  - Why needed here: AGF applies specifically to the "rich" feature learning regime (α ≪ 1), distinct from the kernel/lazy regime (α → ∞) where the NTK is frozen.
  - Quick check question: For a two-layer network with initialization scale α=10^−4, would you expect the NTK to remain approximately constant during training?

- Concept: Homogeneous functions and Euler's theorem
  - Why needed here: The utility function inherits homogeneity degree κ = k+1 from k-homogeneous activations, enabling the directional-radial decomposition in Equation (2).
  - Quick check question: If σ(z) = z² (quadratic), what is κ and how does it affect the relative speed of directional vs. radial dynamics?

- Concept: Discrete Fourier Transform and cyclic groups
  - Why needed here: Section 5 analyzes modular addition using DFT to show neurons learn Fourier features; understanding conjugate symmetry and orthogonality of harmonics is essential.
  - Quick check question: Why does the utility function in Equation (63) exclude the k=0 frequency term?

## Architecture Onboarding
- Component map:
  - Dormant set D ⊆ [H]: neurons with ‖θ_i‖ < O(1), evolving via utility maximization
  - Active set A = [H] \ D: neurons at O(1) norm, evolving via cost minimization
  - Residual r(x; Θ_A) = y(x) − f(x; Θ_A): prediction error, defines utility
  - Accumulated utility S_i(t): integral determining jump time
  - Threshold c_i: −log(‖θ_i(0)‖) for κ=2, different form for κ>2

- Critical path:
  1. Initialize Θ ≈ 0 with scale α; all neurons dormant
  2. Utility maximization: dormant neurons align to maximize U_i (fast directional dynamics)
  3. Jump detection: first neuron with S_i > c_i/η activates
  4. Cost minimization: active neurons minimize L(Θ_A) via gradient flow (slow radial dynamics)
  5. Check for neurons returning to dormancy (can happen in constrained settings)
  6. Update residual; repeat from step 2 until ∇_D L = 0

- Design tradeoffs:
  - Initialization scale α: smaller α → sharper staircase, better AGF approximation; too small → numerical instability, long plateaus
  - Learning rate η = E[−log(α)]: time rescaling required for meaningful dynamics as α→0
  - Width H: must be ≥ number of features to learn; too large → overlapping activations, loss of discrete structure
  - For κ > 2: consider neuron-specific adaptive learning rate η_i = ‖θ_i‖^(2−κ)η for instantaneous alignment (Section B.5)

- Failure signatures:
  - Smooth loss curves without plateaus: initialization not small enough, or width too large causing overlapping activations
  - Non-monotonic feature learning: active neurons returning to dormancy (check preserved quantities like u²−v²)
  - Wrong feature order: utility maximization converging to local rather than global maximum (check if utility landscape is well-characterized)
  - AGF diverges from empirical GD: check if general position assumptions hold, or if resonant escape directions exist (Section F.2.1)

- First 3 experiments:
  1. Diagonal linear network (sparse regression): Verify AGF converges to GF as α→0 by plotting loss curves for α ∈ {10^−2, 10^−4, 10^−6}. Confirm staircase matches constrained Lasso solution.
  2. Modular addition with varying embedding: Train quadratic network on p=20 modular addition with embedding x having known Fourier spectrum. Verify frequencies appear in decreasing |x̂[k]| order with predicted jump times.
  3. Width ablation on CIFAR subset: Train two-layer ReLU networks with widths H ∈ {1, 2, 4, 8, 16, 32} and α=10^−4. Observe transition from staircase to slide as width increases (replicate Figure 7).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does AGF converge to gradient flow in the vanishing initialization limit for general two-layer networks beyond diagonal linear networks?
- Basis in paper: [explicit] "While AGF and GF exhibit similar behaviors at small-scale initialization (α≪1), a natural question is whether their trajectories converge to each other as α→0. While a general proof remains open..."
- Why unresolved: The convergence proof is only established for diagonal linear networks (Theorem 3.1). General networks involve coupled dynamics between dormant neurons that resist closed-form analysis.
- What evidence would resolve it: A rigorous proof extending Theorem 3.1's techniques to general activation functions and architectures, or identification of a counterexample where AGF diverges from GF.

### Open Question 2
- Question: How does Conjecture 4.1 behave when Σ_xx does not commute with Σ^⊺_yx Σ_yx in fully connected linear networks?
- Basis in paper: [explicit] "When Σ_xx and Σ^⊺_yx Σ_yx do not commute... we believe that Conjecture 4.1 remains open."
- Why unresolved: Non-commutativity breaks the alignment of dormant basis vectors across AGF iterations, making jump time calculations require understanding the geometry of singular vectors under projection.
- What evidence would resolve it: Analytical bounds on singular vectors under non-commutative transformations, or empirical validation of jump time predictions in non-commuting synthetic settings.

### Open Question 3
- Question: Can AGF be extended to analyze feature learning in deeper networks beyond two layers?
- Basis in paper: [explicit] "Lastly, the central limitation of the framework is its focus on two-layer networks, leaving open how it might generalize to deeper and more realistic architectures."
- Why unresolved: The dormant/active partition and utility function derivation relies on the two-layer structure; deeper networks have inter-layer couplings that may not admit similar decomposition.
- What evidence would resolve it: A modified AGF formulation for three-layer networks with empirical validation, or theoretical analysis showing saddle-to-saddle dynamics persist under certain architectural assumptions.

### Open Question 4
- Question: Why does the staircase loss structure dissolve into smoother curves at larger widths, and does AGF remain predictive in this regime?
- Basis in paper: [inferred] Figure 7 shows loss curves transitioning from staircase to "slide-like" as width increases, and the paper notes "the correspondence with AGF weakens" without fully explaining the mechanism.
- Why unresolved: The paper suggests cost-minimization phases may overlap when multiple neurons activate in succession, but does not formalize when or why this occurs.
- What evidence would resolve it: A modified AGF analysis accounting for simultaneous multi-neuron activation, or empirical characterization of the width-dependent transition threshold.

## Limitations
- Framework only rigorously proven for diagonal linear networks, with extensions to other settings relying on conjectured utility landscapes
- Assumes initialization scale α is sufficiently small for directional-radial separation; practical applicability depends on achieving this regime
- Requires dormant neurons to reach equilibrium before next activation, which may not hold when width is large relative to initialization scale

## Confidence
- **High Confidence**: The separation of directional and radial dynamics (Mechanism 1) is mathematically rigorous with explicit scaling laws and proven convergence for κ=2; the diagonal linear network case provides a clean analytical foundation.
- **Medium Confidence**: The utility maximization mechanism (Mechanism 2) correctly predicts feature emergence order in controlled settings (diagonal networks, modular addition with distinct Fourier components), but generalizability to natural data distributions remains untested.
- **Medium Confidence**: The saddle-to-saddle characterization (Mechanism 3) explains observed staircase loss patterns in synthetic experiments, though empirical validation on real-world tasks with smooth loss curves requires careful interpretation of overlapping phases.

## Next Checks
1. **General Position Testing**: Systematically evaluate AGF predictions on random Gaussian design matrices with varying eigenvalue spectra (from well-conditioned to ill-conditioned) to test the general position assumption and identify conditions where resonant escape directions break the framework.

2. **Adaptive Learning Rate Validation**: Implement neuron-specific adaptive learning rates η_i = ‖θ_i‖^(2-κ)η for κ > 2 settings and compare feature emergence timing and loss trajectories against fixed-rate AGF to verify the claimed improvement in directional alignment speed.

3. **Natural Data Extension**: Apply AGF to two-layer ReLU networks trained on CIFAR-10 subsets with small initialization, measuring whether the predicted Fourier or singular vector features emerge in the predicted order, and whether the smooth empirical loss curves can be decomposed into overlapping saddle-to-saddle transitions as the framework suggests.