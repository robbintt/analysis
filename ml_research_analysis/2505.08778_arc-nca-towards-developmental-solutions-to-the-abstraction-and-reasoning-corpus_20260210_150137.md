---
ver: rpa2
title: 'ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning
  Corpus'
arxiv_id: '2505.08778'
source_url: https://arxiv.org/abs/2505.08778
tags:
- engramnca
- training
- reasoning
- solve
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ARC-NCA leverages Neural Cellular Automata (NCA) and EngramNCA
  to solve the Abstraction and Reasoning Corpus (ARC) benchmark, which tests abstraction
  and reasoning capabilities from minimal examples. The developmental approach mimics
  biological growth and cognitive processes through iterative, self-organizing NCA
  models.
---

# ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning Corpus

## Quick Facts
- arXiv ID: 2505.08778
- Source URL: https://arxiv.org/abs/2505.08778
- Authors: Etienne Guichard; Felix Reimers; Mia Kvalsund; Mikkel Lepperød; Stefano Nichele
- Reference count: 6
- Primary result: 17.6% solve rate on ARC benchmark (20.9% with relaxed loss threshold)

## Executive Summary
ARC-NCA introduces a developmental approach to the Abstraction and Reasoning Corpus (ARC) using Neural Cellular Automata (NCA) with EngramNCA modifications. The system achieves 17.6% solve rate (20.9% with relaxed threshold), comparable to or exceeding ChatGPT 4.5 while requiring approximately 1000x less computational cost. By leveraging self-organizing, iterative NCA models that mimic biological growth and cognitive processes, ARC-NCA demonstrates that developmental computation can effectively capture abstraction and reasoning patterns in ARC tasks.

## Method Summary
ARC-NCA employs Neural Cellular Automata as its core computational framework, enhanced with EngramNCA modifications to improve reasoning capabilities. The approach operates on RGB-α pixel representations derived from ARC's integer grids, using developmental computation where solutions emerge through iterative self-organization rather than direct pattern matching. The system trains on the training set of ARC problems, learning to transform input grids into output solutions through cellular automaton rules that evolve over time steps.

## Key Results
- Achieved 17.6% solve rate on ARC benchmark with strict loss threshold (loss < -7)
- Relaxed threshold (loss < -6) improved performance to 20.9% solve rate
- Computational efficiency approximately 1000x better than ChatGPT while maintaining comparable performance
- Union of multiple NCA variants achieved better performance than any single model (17.6% vs 12.9% best single)

## Why This Works (Mechanism)
The developmental approach works by leveraging self-organizing cellular automata that evolve solutions iteratively, mimicking biological growth processes. This allows the system to discover abstract patterns and reasoning rules through emergent behavior rather than explicit programming. The iterative nature enables gradual refinement of solutions, while the cellular structure provides spatial reasoning capabilities essential for many ARC tasks.

## Foundational Learning
1. **Neural Cellular Automata** - Self-organizing computational models that evolve patterns through local rules
   - Why needed: Provides the developmental computation framework essential for iterative solution discovery
   - Quick check: Can the NCA model successfully evolve simple patterns from random initial conditions?

2. **EngramNCA** - Enhanced NCA architecture with memory-like properties for improved reasoning
   - Why needed: Enables better capture of complex spatial relationships and patterns in ARC tasks
   - Quick check: Does EngramNCA outperform standard NCA on simple reasoning tasks?

3. **Abstraction and Reasoning Corpus** - Benchmark testing general intelligence through visual reasoning tasks
   - Why needed: Provides standardized evaluation of the system's reasoning capabilities
   - Quick check: Can the model solve at least one task from each ARC category?

4. **Criticality in dynamical systems** - Operation at phase transition boundaries for optimal information processing
   - Why needed: May enable more effective learning of abstract reasoning patterns
   - Quick check: Compare performance of critical vs. non-critical NCA pre-training

## Architecture Onboarding

**Component Map**: Input Grid -> NCA/EngramNCA Processor -> Iterative Evolution -> Output Grid

**Critical Path**: The core computational pipeline involves transforming input grids through iterative NCA evolution steps, where each cell updates based on local neighborhood information and learned rules. The critical path is: Input → NCA Evolution Steps → Loss Evaluation → Output Generation.

**Design Tradeoffs**: The choice between pixel-space and latent-space operation affects computational efficiency versus abstraction capability. Pixel-space provides direct interpretability but may limit abstract reasoning, while latent-space could enable better abstraction at the cost of transparency.

**Failure Signatures**: Common failure modes include getting stuck in local minima during evolution, inability to capture long-range dependencies, and sensitivity to initialization patterns. The system may also struggle with tasks requiring non-local reasoning or those outside its learned distribution.

**Three First Experiments**:
1. Test NCA on simple pattern completion tasks to verify basic cellular automaton functionality
2. Evaluate EngramNCA vs standard NCA on tasks requiring memory-like behavior
3. Compare pixel-space vs latent-space representations on a subset of ARC tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would NCAs pre-trained at the "edge of chaos" (criticality) learn ARC tasks more effectively than randomly initialized NCAs?
- Basis in paper: Future Works states: "One hypothesis is that NCAs at criticality would be better suited for learning ARC tasks than randomly initialized NCAs."
- Why unresolved: No criticality pre-training experiments were conducted; all models were trained from random initialization.
- What evidence would resolve it: Compare solve rates of NCAs pre-trained to operate at criticality versus random initialization on the same ARC evaluation set.

### Open Question 2
- Question: Can LLMs effectively serve as error correction mechanisms for the "almost correct" developmental solutions produced by NCAs?
- Basis in paper: Future Works proposes: "LLMs with reasoning abilities may be used as error correction mechanisms for the (almost correct) developmental solutions provided by NCAs."
- Why unresolved: The paper documents 2-6% of problems as "almost solved" with minor pixel errors, but no correction mechanism was tested.
- What evidence would resolve it: Pipeline where NCA outputs near-solutions (loss > -7 but < -6) are fed to LLMs for refinement, measuring improvement in solve rate.

### Open Question 3
- Question: What architectural or inductive bias properties determine why different NCA variants solve non-overlapping subsets of ARC problems?
- Basis in paper: Results show union of models achieves 17.6% vs best single model at 12.9%, and "half of the EngramNCA v1 solutions were not found in EngramNCA v3."
- Why unresolved: The paper reports complementarity but does not analyze what problem characteristics favor specific architectures.
- What evidence would resolve it: Systematic analysis mapping problem categories (e.g., toroidal vs. non-toroidal, local vs. global patterns) to per-architecture success rates.

### Open Question 4
- Question: Would latent-space NCAs improve reasoning capabilities by shifting computation from pixel space to abstract representations?
- Basis in paper: Future Works states: "NCAs operating at an abstract, latent representation may be able to capture basic primitives beneficial for reasoning."
- Why unresolved: All experiments operated on RGB-α pixel representations derived from ARC integer grids.
- What evidence would resolve it: Implementing EngramNCA with a learned encoder/decoder operating in latent space and comparing solve rates to pixel-space baselines.

## Limitations
- Modest solve rate (17.6% with strict threshold, 20.9% relaxed) compared to the complexity of ARC tasks
- May be overfitting to specific task patterns rather than learning truly abstract reasoning principles
- Computational efficiency claim (1000x less than ChatGPT) needs clarification on specific operations being compared

## Confidence

**High confidence** in the architectural design and implementation of ARC-NCA with EngramNCA
**Medium confidence** in the solve rate comparisons with ChatGPT, given potential differences in evaluation methodology
**Medium confidence** in the claim of developmental computation effectively capturing abstraction, as the underlying reasoning mechanisms remain somewhat opaque
**Low confidence** in the long-term generalization of this approach to more complex reasoning tasks beyond the current ARC benchmark

## Next Checks
1. Conduct ablation studies removing the EngramNCA component to quantify its specific contribution to performance improvements
2. Test the model on out-of-distribution ARC-like tasks that weren't part of the training set to assess true generalization
3. Compare inference times and energy consumption per solved task with other ARC solvers using standardized benchmarking protocols