---
ver: rpa2
title: Distribution-Based Feature Attribution for Explaining the Predictions of Any
  Classifier
arxiv_id: '2511.09332'
source_url: https://arxiv.org/abs/2511.09332
tags:
- feature
- dfax
- methods
- attribution
- definition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of feature attribution in machine
  learning by introducing a formal problem definition that requires explanations to
  be supported by the underlying data distribution. The authors propose Distributional
  Feature Attribution eXplanations (DFAX), a novel model-agnostic method that explains
  classifier predictions directly based on data distribution using kernel density
  estimation.
---

# Distribution-Based Feature Attribution for Explaining the Predictions of Any Classifier

## Quick Facts
- **arXiv ID:** 2511.09332
- **Source URL:** https://arxiv.org/abs/2511.09332
- **Reference count:** 39
- **Primary result:** Distributional Feature Attribution eXplanations (DFAX) significantly outperforms state-of-the-art baselines on 9 out of 10 datasets, with average deletion and insertion scores of 0.3244 and 0.7708 respectively, while being orders of magnitude faster.

## Executive Summary
This paper introduces Distributional Feature Attribution eXplanations (DFAX), a novel model-agnostic method that explains classifier predictions by grounding feature importance in the conditional probabilities of the actual data distribution. Unlike existing methods that rely on synthetic perturbations or local approximations, DFAX uses Kernel Density Estimation (KDE) to measure the difference between the probability of a feature value given the predicted class versus its probability given all other classes. Through extensive experiments on ten real-world datasets, DFAX demonstrates superior performance compared to baselines like LINEX, SLISE, SHAP, MAPLE, and DLIME, achieving better deletion/insertion scores while being dramatically faster. The method's efficiency stems from its lazy learning approach that decouples explanation generation from repeated classifier queries.

## Method Summary
DFAX computes feature attribution scores by estimating conditional probabilities using Kernel Density Estimation in one-dimensional subspaces defined by each feature. For a target instance and feature, it calculates the difference between the density of that feature value in the subset of training data belonging to the predicted class versus the density in all other classes. The method operates in a lazy learning paradigm, using pre-computed predictions for the reference dataset and avoiding repeated classifier queries. DFAX can be accelerated using kernel mean maps (Nyström approximation) for O(1) density estimation after initial pre-computation. The approach is model-agnostic, requiring only input-output access to the classifier, and focuses on marginal distributions to maintain computational efficiency while providing interpretable explanations.

## Key Results
- DFAX achieves average deletion and insertion scores of 0.3244 and 0.7708 respectively, significantly outperforming baselines on 9 out of 10 datasets
- The method demonstrates orders-of-magnitude faster runtime compared to competing approaches, often requiring seconds instead of minutes or hours
- Qualitative evaluations on MNIST, FMNIST, and spatial transcriptomics data show DFAX produces more intuitive and semantically meaningful attributions than baseline methods
- DFAX maintains superior performance across both tabular and image datasets, validating its model-agnostic design

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** DFAX generates more faithful explanations by grounding feature importance in the conditional probabilities of the actual data distribution rather than synthetic or local perturbations.
- **Mechanism:** The method computes attribution scores as the difference between the probability of a feature value given the predicted class versus its probability given all other classes, estimated via Kernel Density Estimation (KDE).
- **Core assumption:** The dataset X provided is a representative empirical sample of the underlying distribution P, and the classifier's behavior is meaningful on this distribution.
- **Evidence anchors:** [Abstract]: "introducing a formal problem definition that requires explanations to be supported by the underlying probability distribution represented by the given dataset." [Section: Proposed Method: DFAX]: "DFAX computes the score as the difference between the conditional probability of x* given the target class and that given all the other classes... where the probability is computed using a KDE." [Corpus]: Related work supports the shift towards distributional contexts; "Conceptualizing Uncertainty" notes that feature attribution approaches often fail in high-dimensional settings, suggesting the need for distributional grounding.
- **Break condition:** If the dataset X is sparse or fails to capture the true distribution density (the "curse of dimensionality"), the KDE estimates may become unreliable, leading to noisy attributions.

### Mechanism 2
- **Claim:** The method improves computational efficiency by decoupling the explanation generation from repeated classifier queries and complex model retraining.
- **Mechanism:** DFAX operates in a "lazy learning" paradigm. It uses pre-computed predictions for the dataset X and can utilize kernel mean maps to accelerate density estimation to O(1) after a one-off pre-computation.
- **Core assumption:** Access to the dataset X and the classifier's predictions for that dataset is available; the kernel used admits a finite-dimensional feature map approximation (e.g., via the Nyström method).
- **Evidence anchors:** [Section: Proposed Method: DFAX]: "DFAX operates solely on X and its pre-computed predictions, eliminating the need for further queries to the classifier f." [Section: Kernel Density Estimation]: "This allows any subsequent probability/density estimation to be performed in O(1) time after a one-off computation for the kernel mean map." [Corpus]: Evidence is weak regarding specific efficiency comparisons to this exact method, though "P-TAME" discusses efficiency in perturbation-based explainers generally.
- **Break condition:** If using an exact Kernel Density Estimator without approximation (like exact GKDE on massive data), the O(N) complexity per query becomes a bottleneck, negating the efficiency claim.

### Mechanism 3
- **Claim:** Using 1-dimensional marginal distributions for scoring allows DFAX to bypass the complexity of modeling feature interactions while maintaining interpretability.
- **Mechanism:** The score I(x*, s|X) is computed in the one-dimensional subspace defined by feature s. This avoids the combinatorial explosion of evaluating feature subsets (as required by Shapley-based methods).
- **Core assumption:** Important features have distinct marginal distributions for the target class compared to the rest of the data (i.e., class-characterizing signals are detectable in 1D).
- **Evidence anchors:** [Section: Proposed Method: DFAX]: "the probability is computed using a KDE K_s in the one-dimensional subspace defined by feature s." [Section: Analyses of Existing Methods]: Contrasts this with Shapley methods that "approximate by sampling a tractable number of subsets" to avoid 2^d complexity. [Corpus]: No direct corpus support found for the specific 1D assumption validation.
- **Break condition:** If a feature is only important in conjunction with another (e.g., an XOR relationship), marginalizing to 1D may assign it a low score, failing to capture interaction effects.

## Foundational Learning

- **Concept: Kernel Density Estimation (KDE)**
  - **Why needed here:** DFAX relies entirely on KDE to estimate the likelihood of feature values occurring within specific class subsets. Without understanding kernel bandwidth and smoothing, one cannot debug why a feature might be scored highly or lowly.
  - **Quick check question:** How does the choice of kernel bandwidth (e.g., γ in the Gaussian kernel) affect the sensitivity of the attribution score to outliers in the dataset X?

- **Concept: Deletion and Insertion Metrics**
  - **Why needed here:** These are the primary evidence anchors for the paper's claim of superior performance. They measure the drop/rise in predicted probability as features are removed/added.
  - **Quick check question:** If a method achieves a low deletion score but a random insertion score, what does that imply about the completeness of the explanation?

- **Concept: Model Agnosticism**
  - **Why needed here:** The paper emphasizes treating the classifier as a black box. Understanding this constraint explains why DFAX avoids gradients or internal weights and relies solely on input-output behavior.
  - **Quick check question:** Why is "model agnosticism" a double-edged sword regarding the ability to detect internal model failures versus data distribution issues?

## Architecture Onboarding

- **Component map:** Input Layer (x*, X, f) -> Labeling Engine (f on X) -> Density Engine (KDE on class subsets) -> Scoring Layer (I = K(x*|X_{y*}) - K(x*|X\X_{y*})) -> Accelerator (Optional Nyström pre-computation)
- **Critical path:** The runtime is dominated by the density estimation step. If using the accelerated architecture, the critical path shifts to the initial pre-computation of the kernel mean map. If not, the critical path is the O(N) lookup against the dataset for every feature of every target instance.
- **Design tradeoffs:**
  - **GKDE vs. SiNNE:** GKDE is theoretically smoother but slower; SiNNE (Simplified iNNE) is faster but potentially noisier, trading accuracy for speed (Evidence: [Section: Kernel Density Estimation]).
  - **1D Marginal vs. Joint Distribution:** The paper chooses 1D speed and simplicity over the accuracy of modeling complex feature correlations.
- **Failure signatures:**
  - **Identical Scores:** If all features have similar scores, check the kernel bandwidth (too wide smooths everything to the mean; too narrow creates spikes).
  - **Sensitivity to Class Imbalance:** If the "other classes" set X \ X_{y*} dominates the density estimation, minority class features might be undervalued.
  - **OOD Inputs:** If x* is far from any point in X, KDE values will approach zero everywhere, resulting in near-zero attributions (correct behavior per the definition, but potentially confusing).
- **First 3 experiments:**
  1. **Sanity Check (Toy Data):** Create a dataset where Class A is clearly defined by Feature 1 (e.g., x_1 > 5). Run DFAX and verify Feature 1 has the highest score.
  2. **Runtime Scaling:** Reproduce Figure 3 by measuring inference time for 1 target instance as |X| grows from 100 to 10,000, comparing exact GKDE vs. the accelerated Nyström approximation.
  3. **Baseline Comparison:** Run the deletion test on a simple classifier (Logistic Regression) vs. a complex one (MLP) to verify if DFAX's performance holds regardless of model complexity (as claimed by model-agnosticism).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What axiomatic properties does DFAX satisfy, and do properties such as symmetry, additivity, or implementation invariance hold?
- **Basis in paper:** [explicit] "In the near future, we plan to investigate the axiomatic properties of DFAX"
- **Why unresolved:** The authors identify this as future work; no theoretical analysis of axioms is provided.
- **What evidence would resolve it:** Formal proofs or counterexamples demonstrating which axioms DFAX satisfies or violates, compared to Shapley-based methods.

### Open Question 2
- **Question:** Can DFAX be extended to feature-group attribution while maintaining its distributional guarantees and efficiency?
- **Basis in paper:** [explicit] "In the near future, we plan to...extend DFAX to the task of feature-group attribution"
- **Why unresolved:** DFAX currently operates on individual features in one-dimensional subspaces; group-level attribution requires handling correlated features jointly.
- **What evidence would resolve it:** A modified DFAX formulation for feature groups with empirical validation against GroupSHAP and GPFI.

### Open Question 3
- **Question:** How does the choice of kernel density estimator (GKDE vs. SiNNE vs. IKDE) and its hyperparameters affect attribution quality and robustness?
- **Basis in paper:** [inferred] The paper reports DFAXG and DFAXS with different hyperparameter settings per dataset but does not analyze sensitivity or provide principled selection guidance.
- **Why unresolved:** Optimal hyperparameters were selected via grid search; the relationship between data characteristics and kernel/hyperparameter choice remains unexplored.
- **What evidence would resolve it:** A systematic ablation study analyzing attribution stability across kernel choices and hyperparameter ranges.

### Open Question 4
- **Question:** Does DFAX generalize to regression tasks, and how should the conditional probability formulation be adapted for continuous outputs?
- **Basis in paper:** [inferred] All experiments involve classification; the formal definition and DFAX formulation assume discrete class predictions.
- **Why unresolved:** Extending p_s(x*|{y*}) to continuous y* requires defining meaningful conditional density differences for regression outputs.
- **What evidence would resolve it:** Modified DFAX for regression with experiments on regression benchmarks, comparing against existing regression explanation methods.

## Limitations

- **Dataset Representativeness Assumption:** DFAX assumes the reference dataset X is a representative sample of the underlying distribution, which may not hold in practice with sampling bias or limited data.
- **1D Marginal Approach:** The focus on one-dimensional subspaces may miss important feature interactions, particularly for features that are only important in conjunction with others.
- **Hyperparameter Sensitivity:** The method's performance depends on kernel bandwidth selection and other hyperparameters, but the paper doesn't provide principled guidance for hyperparameter tuning on new datasets.

## Confidence

- **Computational Efficiency (Mechanism 2):** Medium-High - The paper provides theoretical runtime analysis and empirical comparisons showing orders-of-magnitude speedup.
- **Distributional Grounding (Mechanism 1):** Medium - The approach is theoretically sound, but lacks validation on whether the dataset truly represents the underlying distribution.
- **1D Marginal Approach (Mechanism 3):** Low-Medium - No empirical validation on features with known interaction effects; the approach may miss important interaction patterns.

## Next Checks

1. **Dataset Representativeness Test:** Systematically evaluate DFAX on datasets with varying degrees of class imbalance and sampling density to measure how KDE performance degrades when the reference dataset fails to capture true feature distributions.

2. **Interaction Effect Validation:** Create synthetic datasets with known feature interactions (e.g., XOR patterns) where individual features should have near-zero attribution but the pair should have high importance. Test whether DFAX correctly identifies such patterns or misses them due to the 1D marginal approach.

3. **Bandwidth Sensitivity Analysis:** Conduct an ablation study systematically varying the Gaussian kernel bandwidth parameter across multiple orders of magnitude to quantify how sensitive the attribution scores and downstream evaluation metrics are to this hyperparameter choice.