---
ver: rpa2
title: Cohort-Based Active Modality Acquisition
arxiv_id: '2505.16791'
source_url: https://arxiv.org/abs/2505.16791
tags:
- 'true'
- acquisition
- proposed
- strategy
- probability0
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Cohort-based Active Modality Acquisition (CAMA),
  a novel setting for optimizing cohort-level performance through strategic test-time
  acquisition of additional data modalities under budget constraints. The method combines
  generative imputation models with discriminative classifiers to estimate the expected
  benefit of acquiring missing modalities, using acquisition functions based on metrics
  like KL-Divergence and uncertainty reduction.
---

# Cohort-Based Active Modality Acquisition

## Quick Facts
- arXiv ID: 2505.16791
- Source URL: https://arxiv.org/abs/2505.16791
- Reference count: 40
- The paper introduces CAMA, a novel setting for optimizing cohort-level performance through strategic test-time acquisition of additional data modalities under budget constraints.

## Executive Summary
This paper introduces Cohort-based Active Modality Acquisition (CAMA), a novel framework for optimizing cohort-level performance by strategically acquiring additional data modalities at test-time under budget constraints. The method combines generative imputation models with discriminative classifiers to estimate the expected benefit of acquiring missing modalities, using acquisition functions based on KL-Divergence and uncertainty reduction. Experiments demonstrate that CAMA's imputation-based strategies significantly outperform random selection and baselines, particularly the KL-Divergence approach which consistently achieved substantial gains. The method is validated on a large-scale healthcare dataset (UK Biobank), showing effective guidance for costly proteomics data acquisition for disease prediction.

## Method Summary
CAMA operates by jointly training generative imputers (Diffusion Transformers or BC-VAEs) and discriminative classifiers in latent space. The generative model learns to impute missing modality embeddings conditioned on available modalities, while the classifier is trained only on available data using masking. At inference, the system estimates the expected information gain from acquiring each missing modality by comparing pre-acquisition and post-imputation predictions. Acquisition functions based on KL-Divergence and uncertainty metrics rank samples, with the top candidates receiving the additional modality acquisition. The framework is evaluated using a normalized Area of Gain metric that measures acquisition efficiency relative to the maximum possible improvement.

## Key Results
- CAMA's imputation-based KL-Divergence strategy significantly outperforms random selection and baselines relying solely on pre-acquisition information
- The method achieves substantial performance gains on multimodal datasets with up to 15 modalities and 100,000 samples
- Validation on UK Biobank demonstrates effective guidance for costly proteomics data acquisition for disease prediction
- KL-Divergence-based approach consistently achieved the best results across all tested datasets and metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Estimating the divergence between pre-acquisition and post-imputation predictions identifies high-value samples more effectively than uncertainty-based baselines.
- Mechanism: The architecture uses a generative model to hallucinate plausible latent embeddings for missing modalities. A discriminative classifier evaluates both the "available" state and the "imputed" state. By calculating the KL-Divergence between the probability distributions, the system quantifies the expected information gain. Samples with high divergence are prioritized, as this signals that the missing modality is likely to significantly alter the prediction.
- Core assumption: The generative model samples from a conditional distribution that is sufficiently aligned with the true data distribution such that the expected shift in classifier belief correlates with ground-truth utility.
- Evidence anchors: [Abstract]: "Acquisition functions based on metrics like KL-Divergence and uncertainty reduction... demonstrate that CAMA's imputation-based strategies significantly outperform... baselines relying solely on pre-acquisition information." [Page 9/Section 6]: "The imputation-based KL-Divergence strategy effectively identifies samples predicted to have the largest shift in their class probability distribution."

### Mechanism 2
- Claim: Jointly training generative and discriminative components with decoupled data flows stabilizes the classifier against the distribution shift of synthetic inputs.
- Mechanism: During training, the classifier is trained only on real, available modalities using attention masks. The generative model is trained simultaneously to minimize reconstruction loss on the latents of missing modalities. Crucially, the classifier never sees the generator's outputs during training. This forces the classifier to learn robust representations from sparse real data, while the generator learns to produce latents compatible with the shared encoder space.
- Core assumption: The latent space shared by the encoders allows the generator to produce embeddings that are discriminatively useful to the classifier, even though the classifier was never explicitly trained on generated examples.
- Evidence anchors: [Page 7/Section 5]: "The generative outputs do not directly influence the classifier during training... Instead, the discriminative components... are trained only on available modalities via attention masks." [Page 9/Table 6]: Ablation shows removing decoupled data flow causes a drastic drop in performance.

### Mechanism 3
- Claim: Operating on latent embeddings rather than raw data enables scalable modality imputation across heterogeneous modalities.
- Mechanism: Instead of generating raw images or text sequences, the generative model imputes the output of the modality-specific encoders. This compresses the generative task from high-dimensional raw data to a lower-dimensional latent vector. This allows the use of efficient architectures like DiTs or VAEs to model the complex conditional dependencies between modalities.
- Core assumption: The encoder outputs capture sufficient semantic information that imputing the latent vector is functionally equivalent to imputing the raw data for the purpose of the downstream prediction task.
- Evidence anchors: [Page 7/Section 5]: "The generative modules are parameterized as Diffusion Transformers... trained to approximate the conditional distribution." [Page 10/Section 7]: "We impute latent embeddings optimized for the discriminative task rather than raw data."

## Foundational Learning

- **Variational Autoencoders (VAEs) & Diffusion Models**: The core of CAMA relies on generative models (BC-VAE or DDPM) to impute missing data. You must understand the difference between reconstructing a single point (AE) and sampling from a distribution (VAE/DDPM), as CAMA requires sampling diverse plausible imputations. Quick check: Why does CAMA sample K=100 imputations during inference rather than just taking the mean of the generator output?
- **KL-Divergence**: This is the metric used to rank samples. You need to understand that it measures the "distance" between two probability distributions. In CAMA, it measures how much the model's belief changes after seeing the imputed data. Quick check: If P_avail and P_imp are identical, what is the KL-Divergence, and what does that imply for acquisition priority?
- **Late Fusion & Multimodal Alignment**: The architecture uses modality-specific encoders feeding into a joint classifier. Understanding how to fuse these inputs (e.g., via Transformers) and handle missing inputs (via masking) is critical. Quick check: How does the classifier handle a sample where 3 out of 5 modalities are missing during training?

## Architecture Onboarding

- **Component map**: Raw multimodal data -> Modality-specific encoders -> Latent vectors -> Transformer fusion head -> Prediction
- **Critical path**:
  1. Preprocessing: Encode available modalities to z_avail
  2. Imputation: Use f_imp to sample K latent embeddings for the missing modality conditioned on z_avail
  3. Scoring: Pass both real and imputed z's through f_C to get s_avail and {s_imp}
  4. Ranking: Calculate KL-Divergence for all samples; acquire modalities for the top Î² samples
- **Design tradeoffs**:
  - DDPM vs. VAE: DDPMs offer higher performance but are ~8x slower during inference. VAEs are faster but less precise.
  - K (Imputation Samples): Higher K reduces variance in the acquisition score but increases inference cost linearly. The paper uses K=100.
- **Failure signatures**:
  - Imputation Collapse: The generator produces a constant vector for all inputs. s_imp becomes a constant, KL-Divergence vanishes, and acquisition degrades to random selection.
  - Overconfidence: The classifier outputs extreme logits on imputed data. Label smoothing is required to prevent this.
- **First 3 experiments**:
  1. Oracle vs. Random Baseline: Run the full pipeline using the "Oracle" acquisition function and "Random". Verify that there is a significant performance gap.
  2. Ablation on Decoupled Training: Train a model where the classifier is fed generated data during training (coupled). Compare its acquisition performance against the proposed decoupled training. Expect a drop of ~0.2 in normalized gain.
  3. Modality Gap Analysis: Visualize the latent space of real vs. imputed modalities (t-SNE/PCA). Ensure they overlap. If they are distinct clusters, the generator is failing to produce realistic embeddings.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can CAMA be extended to multi-class classification and regression tasks where the current KL-Divergence and uncertainty-based acquisition functions are not directly applicable?
- Basis in paper: [explicit] "Future work includes extending CAMA to multi-class problems or regression tasks"
- Why unresolved: Current acquisition functions are derived specifically for binary classification using metrics like AUROC/AUPRC and binary entropy H(p_i). Multi-class settings require fundamentally different formulations.
- What evidence would resolve it: Derivation and empirical evaluation of acquisition functions adapted for multi-class scenarios and regression.

### Open Question 2
- Question: How can the system dynamically select which modality to acquire for each sample rather than pre-selecting a single target modality for the entire cohort?
- Basis in paper: [explicit] Future work includes "dynamically selecting which modality to acquire instead of pre-selecting one"
- Why unresolved: Current CAMA assumes a fixed target modality k is known in advance. Real-world settings may have multiple potentially acquirable modalities with different costs and benefits per sample.
- What evidence would resolve it: Development and evaluation of a cost-aware, per-sample modality selection mechanism that jointly considers multiple candidate modalities.

### Open Question 3
- Question: Why does the imputation-based KL-Divergence strategy sometimes outperform the upper-bound heuristic that has access to true acquired scores?
- Basis in paper: [inferred] "To our surprise, the imputation-based KL-Divergence AF can slightly outperform the corresponding upper-bound heuristic (Table 5)"
- Why unresolved: Theoretically, upper-bound heuristics should dominate imputation-based methods since they use true acquired scores. The authors provide no explanation for this counterintuitive result.
- What evidence would resolve it: Analysis of the statistical properties of KL-divergence under imputation vs. ground truth, potentially revealing regularization effects or noise-induced benefits.

## Limitations

- The core assumption that latent-space imputation can faithfully represent raw modality information remains untested at scale - there's no direct comparison showing imputed latent vectors produce equivalent downstream predictions to imputed raw data.
- The budget allocation mechanism is somewhat simplified, treating all modalities as equally expensive and ignoring potential dependencies between modalities.
- Real-world validation is limited to UK Biobank, with other datasets using synthetic missingness patterns that may not reflect actual acquisition constraints.

## Confidence

- **High Confidence**: The KL-Divergence-based acquisition function significantly outperforms random selection and baseline uncertainty methods (demonstrated across multiple datasets and metrics).
- **Medium Confidence**: The decoupled training approach is necessary for stable performance, though the exact sensitivity to implementation details is unclear.
- **Medium Confidence**: Latent-space imputation provides sufficient information for effective acquisition decisions, but this could vary significantly with different encoder architectures.

## Next Checks

1. **Latent vs. Raw Imputation Comparison**: Conduct an ablation study comparing CAMA's latent-space imputation against a baseline that imputes raw data directly, measuring both acquisition effectiveness and downstream prediction accuracy.

2. **Budget Heterogeneity Test**: Evaluate CAMA's performance when modalities have different acquisition costs and when there are dependencies between modalities (e.g., acquiring one modality makes another redundant).

3. **Domain Transferability Assessment**: Test CAMA on a dataset where missingness patterns are driven by real acquisition constraints (e.g., medical imaging protocols) rather than synthetic patterns, comparing performance across domains.