---
ver: rpa2
title: GMM-Based Comprehensive Feature Extraction and Relative Distance Preservation
  For Few-Shot Cross-Modal Retrieval
arxiv_id: '2505.13306'
source_url: https://arxiv.org/abs/2505.13306
tags:
- cross-modal
- shot
- retrieval
- few-shot
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles few-shot cross-modal retrieval, addressing the
  challenge of learning robust cross-modal representations when training data is scarce
  and unseen classes must be handled during inference. Existing methods often fail
  to model the complex multi-peak distribution of data and suffer from intra-modal
  and inter-modal biases.
---

# GMM-Based Comprehensive Feature Extraction and Relative Distance Preservation For Few-Shot Cross-Modal Retrieval

## Quick Facts
- **arXiv ID:** 2505.13306
- **Source URL:** https://arxiv.org/abs/2505.13306
- **Reference count:** 40
- **Primary result:** GCRDP achieves state-of-the-art few-shot cross-modal retrieval performance, outperforming CLIP and FLEX-CLIP baselines by 2.5-4.6 points in mAP across multiple datasets.

## Executive Summary
This paper tackles the challenge of few-shot cross-modal retrieval, where models must handle unseen classes during inference with limited training data. The authors propose GCRDP, which combines Gaussian Mixture Models (GMM) for comprehensive feature extraction with a Cross-modal Relative Distance Preservation (RDP) constraint. The method addresses limitations of existing approaches that fail to capture complex multi-peak data distributions and suffer from inter-modal biases. Extensive experiments on Wikipedia, Pascal Sentence, and NUS-WIDE datasets demonstrate consistent improvements over six state-of-the-art methods in both zero-shot and few-shot (1, 3, 5-shot) settings.

## Method Summary
GCRDP uses GMM to model data as K Gaussian components, capturing complex intra-class distributions better than single-prototype methods. The method employs multi-positive contrastive learning where different Gaussian components from the same image serve as multiple positives, enhancing intra-sample semantic structure. The RDP constraint aligns similarity matrices across modalities for high-confidence pairs, ensuring semantic relationships are preserved. The total loss combines InfoNCE contrastive loss, cross-modal regularization, and RDP loss, optimized via Adam with learning rate 1e-4.

## Key Results
- GCRDP achieves 57.4 mAP on Wikipedia 5-shot, outperforming CLIP (52.8) and FLEX-CLIP (53.6)
- Ablation studies confirm GMM and RDP components each contribute 2.6-2.8 points improvement in performance
- Method generalizes across 1, 3, and 5-shot settings on four benchmark datasets
- RDP constraint particularly effective for reducing inter-modal bias under data scarcity

## Why This Works (Mechanism)

### Mechanism 1
GMM-based multi-prototype representation captures complex intra-class distributions better than single-prototype methods like Global Average Pooling. Instead of compressing all features into one vector, GMM models data as K Gaussian components, each representing a semantic sub-pattern. The EM algorithm iteratively assigns samples to components via posterior probabilities, creating K "viewpoints" per sample rather than one. This works when the underlying feature distribution is multi-modal and can be approximated by a mixture of Gaussians.

### Mechanism 2
Multi-positive contrastive learning preserves intra-sample semantic structure while maintaining inter-sample discriminability. Traditional contrastive learning uses one positive vs. many negatives, but this method treats different Gaussian components from the SAME image as multiple positives. The extended InfoNCE loss forces the model to learn that different parts of the same image are semantically related but distinct from parts of different images. This assumes multiple Gaussian components within one sample share semantic coherence while being locally distinct.

### Mechanism 3
Cross-modal Relative Distance Preservation (RDP) aligns manifold structures across modalities, reducing inter-modal bias under data scarcity. RDP enforces that if image A is more similar to image B than to image C in the image feature space, then text A should also be more similar to text B than to text C in the text feature space. This transfers relational knowledge from one modality to another, assuming semantic relationships are consistent across modalities.

## Foundational Learning

- **Concept: Expectation-Maximization (EM) Algorithm**
  - **Why needed here:** GMM parameters cannot be directly computed because we don't know which component each sample belongs to. EM iterates between guessing assignments (E-step) and updating parameters (M-step).
  - **Quick check question:** Can you explain why we need the posterior probability γ in Eq. (2) rather than hard assignments?

- **Concept: Contrastive Learning and InfoNCE Loss**
  - **Why needed here:** The paper extends standard InfoNCE to multi-positive scenarios. Understanding the original formulation (pulling positives closer, pushing negatives apart) is prerequisite to understanding how multiple Gaussian components as positives changes the learning dynamic.
  - **Quick check question:** What happens to the gradient when you increase the temperature τ in InfoNCE?

- **Concept: Cross-Modal Retrieval Metrics (mAP)**
  - **Why needed here:** The paper evaluates on mAP across I2T and T2I tasks. mAP accounts for ranking quality, not just top-1 accuracy, which matters for retrieval where users see multiple results.
  - **Quick check question:** If a system retrieves 5 items with relevant items at positions 1, 3, and 5, how would you compute AP for this query?

## Architecture Onboarding

- **Component map:** Feature Encoders -> GMM Module -> Multi-Positive Contrastive Learning -> RDP Module -> Joint Optimization
- **Critical path:** 1. Extract image/text features → 2. Fit GMM via EM → 3. Construct multi-positive pairs using component assignments → 4. Compute contrastive loss → 5. Compute RDP loss on high-confidence pairs → 6. Backpropagate combined loss
- **Design tradeoffs:**
  - Number of GMM components (K): Paper uses K=3. More components capture finer structure but risk overfitting with sparse data.
  - Similarity threshold (θ=0.5): Lower threshold includes more pairs but introduces noise; higher threshold is cleaner but may miss valid relationships.
  - Loss weights (α, λ): Balance between standard contrastive learning, cross-modal alignment, and RDP.
- **Failure signatures:**
  - GMM collapse: All samples assigned to one component (check mixture weights π in Eq. 3).
  - RDP not converging: D_v and D_t matrices diverging. Check if threshold θ is too restrictive.
  - Performance degrades from 3-shot to 5-shot: May indicate overfitting to limited data.
- **First 3 experiments:**
  1. Reproduce baseline comparison: Run GCRDP vs CLIP and FLEX-CLIP on Wikipedia zero-shot. Target: mAP ~55.4.
  2. Ablation on GMM components: Test K=1, 2, 3, 5 on Pascal Sentence 3-shot. Expect K=3 to be optimal.
  3. RDP threshold sensitivity: Test θ=0.3, 0.5, 0.7 on NUS-WIDE 5-shot. Paper uses 0.5 without justification.

## Open Questions the Paper Calls Out

- **Question 1:** How sensitive is the model's performance to the number of Gaussian components (K), and is the fixed setting of K=3 optimal across datasets with varying semantic complexity?
  - **Basis:** Section 4.3 states "we typically set the number of components to 3" but offers no justification or ablation study.
  - **What evidence would resolve it:** An ablation study analyzing mAP scores while varying K against dataset complexity.

- **Question 2:** Does the iterative Expectation-Maximization (EM) algorithm introduce prohibitive computational overhead or convergence instability compared to standard pooling methods?
  - **Basis:** Section 3.2 details the iterative E-steps and M-steps required for parameter estimation, but experiments omit analysis of training efficiency.
  - **What evidence would resolve it:** A comparative analysis of training duration and FLOPs between GCRDP and GAP-based baselines.

- **Question 3:** Can the Cross-modal Relative Distance Preservation (RDP) constraint effectively generalize to modalities with temporal dependencies, such as video or audio?
  - **Basis:** The paper evaluates exclusively on image-text pairs, focusing on spatial distribution of features.
  - **What evidence would resolve it:** Extending the method to Video-Text retrieval benchmarks to evaluate temporal features.

## Limitations
- The paper does not specify which feature encoder architectures (CLIP, ResNet, BERT variants) are used.
- Exact values for loss weighting hyperparameters (α, λ, τ) are missing from the implementation details.
- The dimensionality of the shared latent space is not specified, making exact reproduction challenging.
- RDP assumes consistent semantic relationships across modalities, which may not hold for all dataset pairs.

## Confidence

- **High Confidence:** GMM-based feature extraction mechanism and its ability to capture multi-peak distributions is well-supported by ablation studies.
- **Medium Confidence:** RDP mechanism's effectiveness is demonstrated empirically but underlying assumptions are not rigorously validated across diverse dataset pairs.
- **Low Confidence:** Specific implementation details (feature encoder choice, hyperparameter values, latent space dimension) are missing.

## Next Checks

1. **Component Sensitivity Analysis:** Test GMM with K=1, 2, 3, 5 components on Pascal Sentence 3-shot to identify optimal K and validate the paper's choice of K=3 against potential overfitting with higher values.

2. **RDP Threshold Robustness:** Evaluate RDP performance across θ=0.3, 0.5, 0.7 on NUS-WIDE 5-shot to determine if the chosen threshold of 0.5 is universally optimal or dataset-dependent.

3. **Encoder Architecture Impact:** Compare GCRDP performance using different feature encoders (e.g., CLIP-ViT vs ResNet-50 + BERT) on Wikipedia zero-shot to quantify the contribution of GMM and RDP components versus base feature representation quality.