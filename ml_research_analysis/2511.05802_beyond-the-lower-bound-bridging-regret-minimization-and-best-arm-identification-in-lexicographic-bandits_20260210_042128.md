---
ver: rpa2
title: 'Beyond the Lower Bound: Bridging Regret Minimization and Best Arm Identification
  in Lexicographic Bandits'
arxiv_id: '2511.05802'
source_url: https://arxiv.org/abs/2511.05802
tags:
- regret
- objective
- objectives
- arms
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper bridges regret minimization and best arm identification
  in lexicographic bandits by proposing two algorithms: LexElim-Out and LexElim-In.
  LexElim-Out eliminates arms sequentially layer by layer according to objective priorities,
  achieving regret bounds comparable to single-objective methods.'
---

# Beyond the Lower Bound: Bridging Regret Minimization and Best Arm Identification in Lexicographic Bandits

## Quick Facts
- arXiv ID: 2511.05802
- Source URL: https://arxiv.org/abs/2511.05802
- Reference count: 40
- Proposes LexElim-Out and LexElim-In algorithms that achieve regret bounds comparable to single-objective methods while enabling best arm identification

## Executive Summary
This paper addresses the challenge of bridging regret minimization and best arm identification in lexicographic multi-armed bandits with multiple objectives. The authors propose two algorithms, LexElim-Out and LexElim-In, that operate in a sequential elimination framework. LexElim-Out eliminates arms layer-by-layer according to objective priorities, while LexElim-In leverages cross-objective information simultaneously to accelerate elimination. Both algorithms provide anytime performance guarantees with minimax regret bounds of O(Λᵢ(λ)√(Kt)) for each objective i, matching single-objective results up to a factor depending on the trade-off parameter λ.

## Method Summary
The paper introduces two algorithms for lexicographic multi-armed bandits. LexElim-Out performs sequential elimination layer-by-layer, requiring knowledge of the number of arms optimal up to each objective. It uses confidence widths c(a) = √(4/n(a) · log(6Km·n(a)/δ)) for elimination decisions. LexElim-In operates by leveraging cross-objective information simultaneously, using scaled elimination thresholds (2 + 4λ + ... + 4λ^(i-1))·c(aₜ). Both algorithms update empirical means incrementally and pull arms with highest uncertainty. The methods are evaluated on synthetic bandit problems with K ∈ {10, 20, 30} arms and 3 objectives, using Gaussian rewards with specified means.

## Key Results
- LexElim-Out achieves regret bounds comparable to single-objective methods while enabling best arm identification
- LexElim-In surpasses known lower bounds for single-objective bandits by leveraging cross-objective information
- Both algorithms provide anytime performance guarantees with minimax regret bounds of O(Λᵢ(λ)√(Kt)) for each objective i
- Empirical results validate superior performance over baselines in both regret and sample complexity

## Why This Works (Mechanism)
The algorithms work by exploiting the hierarchical structure of lexicographic preferences. LexElim-Out eliminates arms sequentially based on objective priorities, ensuring that higher-priority objectives are optimized before considering lower-priority ones. LexElim-In goes further by using information from higher-priority objectives to inform elimination decisions for lower-priority objectives, effectively sharing statistical power across objectives. This cross-objective information sharing allows LexElim-In to achieve better performance than what would be possible by treating each objective independently.

## Foundational Learning
- **Lexicographic ordering**: Understanding how multi-objective preferences are structured hierarchically - needed to design elimination strategies that respect priority relationships
- **Sequential elimination**: The core technique of removing suboptimal arms based on confidence bounds - needed to achieve sublinear regret while identifying the optimal arm
- **Cross-objective information sharing**: Leveraging statistical information from higher-priority objectives to inform decisions about lower-priority ones - needed to surpass single-objective lower bounds
- **Confidence bounds**: Statistical tools for determining when arms can be safely eliminated - needed to balance exploration and exploitation
- **Anytime guarantees**: Performance bounds that hold at all time steps - needed for practical deployment in unknown-duration scenarios
- **Trade-off parameter λ**: Quantifies the relative importance between objectives - needed to calibrate the elimination thresholds in LexElim-In

## Architecture Onboarding
**Component Map**: Environment (reward generation) -> LexElim-Out/LexElim-In (elimination algorithms) -> Performance metrics (regret, sample complexity)
**Critical Path**: Arm sampling → Empirical mean update → Confidence bound computation → Elimination decision → Next arm selection
**Design Tradeoffs**: Sequential vs. simultaneous elimination; knowledge of |O*(i)| vs. parameter-free operation; simplicity vs. optimal performance
**Failure Signatures**: Incorrect |O*(i)| computation causes premature/delayed elimination; inappropriate λ value causes stagnation or excessive exploration
**First Experiments**: 1) Verify lexicographic optimal arm identification by computing μᵢ(a) for all arms; 2) Test LexElim-Out with known |O*(i)| values; 3) Systematically vary λ in LexElim-In to observe performance trade-offs

## Open Questions the Paper Calls Out
1. Can tighter lower bounds for lexicographic regret minimization and best arm identification be established that explicitly capture the interactions among objectives?
2. Can the LexElim-In algorithm be modified to operate effectively without prior knowledge of the parameter λ?
3. How does the performance of LexElim-In degrade if the cross-objective trade-off assumption is violated?

## Limitations
- The specific trade-off parameter λ used in experiments is not explicitly stated
- Baseline algorithm implementations lack detailed parameter specifications
- The synthetic reward generation follows specified formulas, but practical interpretation may vary

## Confidence
- High confidence in theoretical regret bounds and algorithmic framework
- Medium confidence in empirical results due to missing implementation details
- Medium confidence in comparative advantage claims pending exact baseline replication

## Next Checks
1. Implement and validate PF-LEX baseline with eO(T^{2/3}) regret parameters
2. Systematically test LexElim-In across λ ∈ {0, 0.5, 1} to identify optimal trade-off parameter
3. Verify lexicographic optimal arm identification by explicitly computing μᵢ(a) for all K arms