---
ver: rpa2
title: 'Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic
  Vulnerabilities in LLMs'
arxiv_id: '2512.24556'
source_url: https://arxiv.org/abs/2512.24556
tags:
- safety
- temporal
- hausa
- gemini
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study reveals that LLM safety is highly context-dependent,
  varying dramatically across linguistic and temporal frames. Through 1,440 evaluations
  of three state-of-the-art models using a novel HausaSafety dataset, researchers
  found a 9.2x disparity between the safest and most vulnerable configurations, with
  past-tense framing bypassing defenses (15.6% safe) while future-tense scenarios
  triggered hyper-conservative refusals (57.2% safe).
---

# Safe in the Future, Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in LLMs
## Quick Facts
- arXiv ID: 2512.24556
- Source URL: https://arxiv.org/abs/2512.24556
- Authors: Muhammad Abdullahi Said; Muhammad Sammani Sani
- Reference count: 15
- Key finding: LLM safety varies dramatically across linguistic and temporal contexts, with 9.2x disparity between safest and most vulnerable configurations

## Executive Summary
This study reveals that LLM safety is highly context-dependent, varying dramatically across linguistic and temporal frames. Through 1,440 evaluations of three state-of-the-art models using a novel HausaSafety dataset, researchers found that past-tense framing bypassed defenses (15.6% safe) while future-tense scenarios triggered hyper-conservative refusals (57.2% safe). Contrary to prior research showing multilingual safety gaps, two of three models were marginally safer in Hausa than English. The research identifies "Complex Interference" as the dominant vulnerability mechanism, where safety emerges from non-linear interactions between language, tense, and model architecture rather than simple degradation in low-resource settings.

## Method Summary
The researchers conducted 1,440 systematic evaluations of three state-of-the-art LLMs using a novel HausaSafety dataset. They tested various linguistic (Hausa vs English) and temporal (past vs future tense) configurations to measure safety performance. The study employed controlled prompt engineering and statistical analysis to identify patterns in model responses, measuring the percentage of prompts that were correctly classified as safe or dangerous across different contexts.

## Key Results
- 9.2x safety disparity between the safest (future-tense English) and most vulnerable (past-tense Hausa) configurations
- Two of three models were marginally safer in Hausa than English, contradicting prior multilingual safety gap research
- Nearly 50% of all prompts successfully jailbroke all three models simultaneously
- "Complex Interference" identified as the dominant vulnerability mechanism, showing non-linear interactions between linguistic and temporal factors

## Why This Works (Mechanism)
The study reveals that current LLM safety mechanisms rely on superficial heuristics rather than robust semantic understanding. Safety emerges from non-linear interactions between language, tense, and model architecture, creating "Safety Pockets" where certain configurations bypass defenses entirely. The temporal framing effect shows that models use tense as a proxy for threat assessment, with future-tense scenarios triggering over-cautious refusals while past-tense scenarios exploit narrative distance to bypass safety filters.

## Foundational Learning
- Temporal framing sensitivity: Models use tense as a threat assessment proxy - needed to understand why future scenarios trigger hyper-conservative responses while past scenarios bypass defenses
- Linguistic safety parity: Contrary to expectations, safety can improve in low-resource languages - needed to challenge assumptions about multilingual safety degradation
- Complex interference patterns: Non-linear interactions between variables create unpredictable safety outcomes - needed to move beyond simple additive models of vulnerability
- Jailbreak universality: Nearly half of prompts compromise all models simultaneously - needed to understand fundamental safety architecture weaknesses
- Safety pockets concept: Localized vulnerability zones that leave specific user populations exposed - needed to identify blind spots in current safety paradigms

## Architecture Onboarding
**Component Map**: Prompt Engineering -> Safety Classifier -> Response Generator -> Evaluation Metrics
**Critical Path**: Input framing (temporal/linguistic) → Safety heuristics activation → Decision boundary crossing → Vulnerability exploitation
**Design Tradeoffs**: Safety vs usability (hyper-conservative future responses) vs localized harm exposure (past-tense bypasses)
**Failure Signatures**: Past-tense jailbreaks (15.6% safe), universal jailbreak susceptibility (50% of prompts), Complex Interference patterns
**3 First Experiments**:
1. Test additional temporal frames (present tense) to map complete safety landscape
2. Evaluate safety parity across broader multilingual spectrum beyond Hausa-English
3. Measure Complex Interference persistence after additional safety fine-tuning iterations

## Open Questions the Paper Calls Out
The study explicitly notes that implementation strategies for "Invariant Alignment" require further research, as this proposed framework for ensuring safety stability across linguistic and temporal shifts remains theoretical. Additionally, the research acknowledges that safety mechanisms may differ qualitatively across cultural contexts not fully captured in the Hausa dataset.

## Limitations
- Focus on Hausa-English comparison without broader multilingual coverage
- Potential prompt design biases in the 1,440 evaluation set
- Absence of real-world deployment data to validate laboratory findings
- May reflect simpler linguistic structures rather than genuine robustness in Hausa improvements

## Confidence
- High confidence: Temporal vulnerability patterns (9.2x disparity consistently observed)
- Medium confidence: Multilingual safety parity claims (only 2 of 3 models showed marginal improvements)
- Medium confidence: Complex Interference mechanism characterization (non-linear interactions incompletely characterized)
- High confidence: Jailbreak universality (nearly 50% of prompts compromised all models)
- Medium confidence: Safety Pockets conclusion (extends prior research but may miss cultural nuances)
- Low confidence: Invariant Alignment framework (theoretical, implementation strategies unknown)

## Next Checks
1. Whether the 9.2x temporal disparity persists across additional languages and cultural contexts
2. Whether Complex Interference vulnerability patterns remain stable when models undergo additional safety fine-tuning iterations
3. Whether real-world deployment data confirms laboratory findings about jailbreak universality across different user populations and threat models