---
ver: rpa2
title: Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in
  RLHF-Aligned Language Models
arxiv_id: '2505.23848'
source_url: https://arxiv.org/abs/2505.23848
tags:
- refusal
- proportion
- token
- think
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a simple, parameter-free method to reduce
  refusal rates in RLHF-aligned language models by suppressing specific token sequences
  during generation. The authors observed that refusals in DeepSeek-R1 distillations
  often followed the token sequence " (followed by "\n\n"), and found that blocking
  "\n\n" after " (and optionally suppressing EOS after " greatly increased substantive
  answers to sensitive prompts without degrading performance on standard benchmarks.
---

# Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in RLHF-Aligned Language Models

## Quick Facts
- arXiv ID: 2505.23848
- Source URL: https://arxiv.org/abs/2505.23848
- Reference count: 11
- Authors: Harvey Dam; Jonas Knochelmann; Vinu Joseph; Ganesh Gopalakrishnan
- Key outcome: Simple, parameter-free method to reduce refusal rates in RLHF-aligned models by suppressing token sequences at output subspace boundaries

## Executive Summary
This paper presents a novel approach to reducing refusal rates in RLHF-aligned language models by targeting specific token generation patterns at output subspace boundaries. The authors discovered that refusals in DeepSeek-R1 distillations frequently followed the token sequence " (followed by "\n\n"), and found that blocking "\n\n" after " (with optional EOS suppression) significantly increased substantive answers to sensitive prompts. The method works across multiple model sizes (7B, 14B, 32B, 70B) without requiring parameter modification or retraining.

The technique leverages the observation that refusal behaviors can be manipulated at the generation level by identifying and suppressing specific token sequences that act as refusal triggers. This parameter-free approach achieved significant improvements in answered and relevant coherent responses across multiple datasets while maintaining performance on standard benchmarks. The findings suggest that refusal behaviors in RLHF-aligned models may be circumvented through careful manipulation of output subspace boundaries rather than through weight modification or training interventions.

## Method Summary
The authors developed a method that identifies and suppresses specific token sequences during generation that trigger refusal behaviors in RLHF-aligned language models. By analyzing the generation patterns of DeepSeek-R1 distillations, they discovered that refusals frequently followed the token sequence " (followed by "\n\n"). The method blocks the generation of "\n\n" after " (optionally suppressing EOS after " as well, effectively derailing the model from entering refusal mode. This approach is implemented at the generation level without modifying model weights or requiring additional training, making it a parameter-free solution to the refusal problem.

## Key Results
- Blocking "\n\n" after " (significantly increased substantive answers to sensitive prompts across 7B, 14B, 32B, and 70B model sizes
- The method maintained performance on standard benchmarks while improving answered and relevant coherent responses
- Statistical analysis confirmed significant improvements across multiple datasets with DeepSeek-R1 distillations
- The approach works without requiring parameter modification or additional training

## Why This Works (Mechanism)
The paper demonstrates that refusal behaviors in RLHF-aligned models can be triggered by specific token sequences at output subspace boundaries. When the model generates " (followed by "\n\n"), it enters a subspace that leads to refusal responses. By suppressing "\n\n" after " (, the model is prevented from entering this refusal-inducing subspace, allowing it to continue generating substantive content instead. This mechanism operates at the generation level, manipulating the model's trajectory through output space without requiring changes to the underlying parameters or training process.

## Foundational Learning

**Token Sequence Patterns**: Understanding how specific token sequences can trigger behavioral responses in language models. Why needed: The method relies on identifying refusal-triggering patterns. Quick check: Verify that the " (â†’"\n\n" sequence is consistently associated with refusals across different prompts and model sizes.

**Output Subspace Boundaries**: Knowledge of how language models navigate different regions of their output space during generation. Why needed: The approach manipulates generation at specific boundaries between different behavioral modes. Quick check: Confirm that suppressing certain tokens effectively redirects the model away from refusal subspaces.

**RLHF Alignment Mechanisms**: Understanding how reinforcement learning from human feedback creates refusal behaviors. Why needed: The method specifically targets RLHF-induced refusal patterns. Quick check: Validate that the approach works specifically on RLHF-aligned models and not on base models.

**Logit Suppression Techniques**: Familiarity with methods for manipulating token generation probabilities during decoding. Why needed: The core technique involves suppressing specific tokens during generation. Quick check: Ensure that logit suppression effectively prevents token generation without causing catastrophic generation failures.

## Architecture Onboarding

**Component Map**: Token Generation -> Pattern Detection -> Logit Suppression -> Continued Generation

**Critical Path**: The method operates during the decoding phase, where token generation is monitored in real-time for the target pattern (" followed by "\n\n"). When detected, logit suppression is applied to prevent the "\n\n" token from being generated, forcing the model to select alternative tokens and continue substantive generation instead of entering refusal mode.

**Design Tradeoffs**: The approach trades specificity for generality - it requires identifying model-specific refusal patterns but offers a lightweight, parameter-free solution. The method may need adaptation for different RLHF-aligned models or training paradigms, as refusal patterns may vary across architectures and training approaches.

**Failure Signatures**: The method may fail if refusal patterns differ significantly across models or if the suppressed token sequence is critical for legitimate generation contexts. Overuse of logit suppression could potentially lead to generation artifacts or coherence issues if not carefully implemented.

**First Experiments**:
1. Test the pattern detection accuracy across different prompt types and model sizes
2. Evaluate the impact of logit suppression on generation quality and coherence
3. Compare performance against baseline models without suppression to quantify improvement

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided content. However, implicit questions include: whether this approach generalizes to other RLHF-aligned models beyond DeepSeek-R1 distillations, how robust the method is to different training paradigms, and what the long-term safety implications are of consistently bypassing refusal mechanisms.

## Limitations

- The study relies entirely on synthetic token pattern detection without deeper interpretability analysis of why specific sequences trigger refusals
- The method assumes pattern generalizability across models and domains but lacks theoretical grounding for why these particular subspace boundaries matter
- Evaluation focuses narrowly on DeepSeek-R1 distillations and custom datasets, limiting generalizability to other RLHF-aligned models or broader real-world deployment
- The "parameter-free" claim obscures the need for dataset-specific pattern identification and manual token sequence specification

## Confidence

- **High confidence**: The empirical observation that suppressing "\n\n" after " (increases substantive responses is reproducible across tested model sizes and datasets
- **Medium confidence**: The claim that this approach doesn't degrade standard benchmark performance, as this depends on what constitutes "standard" and may not capture all failure modes
- **Low confidence**: The broader implication that refusal behaviors can be universally circumvented through output subspace manipulation without understanding underlying mechanisms

## Next Checks

1. Test the method across diverse RLHF-aligned models from different training pipelines (e.g., OpenAI, Anthropic, Meta) to assess cross-model generalizability
2. Conduct ablation studies to determine whether alternative token sequences (e.g., "I'm sorry" followed by "\n\n") produce similar effects, establishing whether the pattern is specific or represents a broader phenomenon
3. Evaluate long-term generation coherence and safety implications when refusals are consistently bypassed, particularly for prompts that legitimately warrant refusal