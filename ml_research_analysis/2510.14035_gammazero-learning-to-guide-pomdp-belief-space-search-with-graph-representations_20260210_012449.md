---
ver: rpa2
title: 'GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations'
arxiv_id: '2510.14035'
source_url: https://arxiv.org/abs/2510.14035
tags:
- belief
- planning
- problems
- graph
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GammaZero introduces a graph-based representation for belief states
  in POMDPs that enables zero-shot generalization across problem sizes. The method
  transforms belief states into action-centric graphs where predicate nodes are created
  only when sufficiently supported by particles, encoding uncertainty through graph
  topology.
---

# GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations

## Quick Facts
- arXiv ID: 2510.14035
- Source URL: https://arxiv.org/abs/2510.14035
- Authors: Rajesh Mangannavar; Prasad Tadepalli
- Reference count: 6
- Key result: Zero-shot generalization across POMDP problem sizes using graph-based belief representations

## Executive Summary
GammaZero introduces a novel approach to planning in partially observable Markov decision processes (POMDPs) that achieves zero-shot generalization across problem sizes. The method transforms belief states into action-centric graphs where predicate nodes are created only when sufficiently supported by particles, encoding uncertainty through graph topology. By combining this representation with a graph neural network, GammaZero can train on small problems (3x3 to 6x6 RockSample) and deploy on problems 2-4x larger without retraining.

The approach addresses a fundamental challenge in POMDP planning: the exponential growth of belief space with problem size. Traditional methods require separate training for each problem scale, while GammaZero's graph-based representation captures the essential structure of belief states in a size-invariant manner. Experimental results demonstrate that GammaZero achieves comparable or superior performance to BetaZero while uniquely enabling generalization across problem scales, requiring only m training runs to cover m domains with n×n×n size variations.

## Method Summary
GammaZero represents belief states as graphs where vertices correspond to predicates and edges capture relationships between them. The graph construction process creates nodes only for predicates with sufficient particle support (controlled by threshold κ), with node features encoding certainty and edge features encoding connectivity. A graph neural network processes these belief graphs to predict action values, which guide a Monte Carlo Tree Search in the belief space. The method is trained using AlphaZero-style self-play, where the policy network learns to select actions and the value network learns to evaluate belief states.

The key innovation is the transformation of continuous belief distributions into discrete graph structures that preserve uncertainty information while enabling size-invariant processing. During search, the algorithm maintains a belief particle set that is updated through belief propagation as actions are simulated. The graph neural network processes the resulting belief graphs to produce action distributions and value estimates that guide the search process. This combination allows the system to leverage learned heuristics for guiding search in previously unseen problem sizes.

## Key Results
- GammaZero achieves 11.05±1.95 average reward on RockSample(15,15,10) versus BetaZero's 10.96±0.98
- On RockSample(20,20,12), GammaZero obtains 5.35±1.01 versus BetaZero's 2.03±0.34
- The method demonstrates successful zero-shot scaling from 3x3-6x6 training problems to 15x15-20x20 test problems

## Why This Works (Mechanism)
The graph representation captures the essential structure of belief states while remaining invariant to problem size. By creating predicate nodes only when sufficiently supported by particles, the representation naturally encodes uncertainty through graph topology - sparse graphs indicate high uncertainty while dense graphs indicate high certainty. The graph neural network can then learn size-invariant patterns in belief structure that generalize across problem scales.

## Foundational Learning
- Particle-based belief representations: Needed for approximating continuous belief distributions in large state spaces; quick check: verify particle diversity and coverage
- Graph neural networks for belief processing: Needed to learn size-invariant patterns in belief structure; quick check: confirm GNN can propagate information across graph topology
- Monte Carlo Tree Search in belief space: Needed for efficient exploration of action sequences under partial observability; quick check: verify UCT balance between exploration and exploitation

## Architecture Onboarding
- Component map: Belief particles -> Graph construction -> GNN processing -> MCTS guidance -> Action selection
- Critical path: Particle update -> Graph creation -> GNN evaluation -> MCTS simulation -> Belief update
- Design tradeoffs: Graph sparsity vs. information loss, particle count vs. computational cost
- Failure signatures: Poor generalization indicates insufficient graph expressiveness; high variance suggests inadequate particle sampling
- First experiments: 1) Test graph construction on simple belief distributions, 2) Validate GNN predictions on known belief structures, 3) Verify MCTS performance with ground-truth value function

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on particle-based belief representations introduces sampling variance that may affect performance consistency
- Graph construction depends on configurable thresholds (κ, λ) that may require problem-specific tuning
- Experimental validation focuses primarily on RockSample domain with limited testing on other POMDP problems

## Confidence
- High confidence in graph representation's effectiveness for belief state encoding within tested domains
- Medium confidence in generality of results across different POMDP domains
- Medium confidence in practical scalability limits of the approach

## Next Checks
1. Test GammaZero on diverse POMDP domains beyond RockSample (e.g., Tiger, Tag, or real-world robotics problems) to evaluate cross-domain generalization
2. Conduct ablation studies removing the graph neural network component to quantify its contribution versus baseline search methods
3. Measure computational overhead and memory requirements scaling with problem size to identify practical implementation limits