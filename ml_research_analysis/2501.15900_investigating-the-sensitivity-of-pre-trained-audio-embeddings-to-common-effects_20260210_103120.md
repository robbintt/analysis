---
ver: rpa2
title: Investigating the Sensitivity of Pre-trained Audio Embeddings to Common Effects
arxiv_id: '2501.15900'
source_url: https://arxiv.org/abs/2501.15900
tags:
- audio
- effects
- embeddings
- effect
- embedding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the sensitivity of pre-trained audio embeddings
  to common audio effects (gain, low-pass filtering, reverberation, and bitcrushing)
  by applying parameterized audio effects and analyzing embedding responses. The authors
  propose using canonical correlation analysis (CCA) to quantify the dimensionality
  and linearizability of deformation trajectories in embedding space.
---

# Investigating the Sensitivity of Pre-trained Audio Embeddings to Common Effects

## Quick Facts
- arXiv ID: 2501.15900
- Source URL: https://arxiv.org/abs/2501.15900
- Reference count: 14
- Primary result: Linear subspace projection methods fail to improve robustness of audio embeddings to common effects (gain, filtering, reverb, bitcrushing) because deformations are high-dimensional rather than globally linearized.

## Executive Summary
This paper investigates how pre-trained audio embeddings (OpenL3, PANNs, CLAP) respond to common audio effects by applying parameterized transformations and analyzing embedding trajectories. Using canonical correlation analysis (CCA), the authors quantify the relationship between effect strength and embedding changes. While they find that individual samples exhibit monotonic responses along specific directions, the overall deformation subspace is high-dimensional, preventing effective linear post-processing for robustness. The results suggest that current pre-trained embeddings do not globally linearize audio effects, limiting the effectiveness of linear debiasing approaches.

## Method Summary
The authors apply parameterized audio effects (gain, low-pass filtering, reverberation, bitcrushing) to audio samples from the IRMAS dataset, then extract embeddings using three pre-trained models. They analyze sensitivity through global and sample-wise CCA to identify deformation directions and assess dimensionality via SVD of sample-wise CCA directions. Six linear projection methods (global CCA, sample-wise CCA SVD with various thresholds, PCA variants, average displacement, LDA) are tested for removing effect-induced variations. Downstream robustness is evaluated using logistic regression classifiers on instrument classification tasks, measuring ROC AUC across effect strengths.

## Key Results
- Embeddings exhibit high correlation with effect strength along certain directions but deformation subspace is generally high-dimensional
- Monotonic direction exists for each individual sample, but global linearization does not hold across samples
- Linear projection methods fail to systematically improve downstream classification robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: For each individual audio sample, there exists a direction in embedding space along which the embedding moves monotonically as audio effect strength increases.
- Mechanism: Canonical Correlation Analysis (CCA) identifies the direction u ∈ R^d that maximizes correlation ρ = corr(u^T Ξ, ay) between embedding variables Ξ and rank-transformed effect parameter y. Sample-wise CCA yields R² = 1.0 across all tested combinations.
- Core assumption: The deformation trajectory for a single sample under parametric effect variation follows a monotonic path in some embedding direction.
- Evidence anchors:
  - [abstract]: "We find that there exists a direction along which the embeddings move monotonically as the audio effect strength increases"
  - [section III, page 3]: "for all combinations of audio effect and embedding and all samples, the R2 coefficient is equal to 1"
  - [corpus]: Weak direct evidence; neighbor papers focus on effect style transfer and emotion rather than embedding geometry.
- Break condition: When embeddings become invariant to the effect (e.g., PANNs at bit depths >10 show clustering/near-collapse, yielding R² = 69.64% for bitcrushing).

### Mechanism 2
- Claim: The deformation subspace across samples is high-dimensional, contradicting low-dimensional global linearization.
- Mechanism: SVD analysis of sample-wise CCA directions reveals singular value decay comparable to original embedding PCA, indicating deformations span many dimensions rather than collapsing to a low-rank subspace.
- Core assumption: If effects were globally linearized, sample-wise deformation directions would cluster in a low-dimensional subspace with rapidly decaying singular values.
- Evidence anchors:
  - [abstract]: "the subspace containing the displacements is generally high-dimensional. This shows that pre-trained audio embeddings do not globally linearize the effects."
  - [section III, page 3, Figure 3]: Comparison of normalized singular values shows CCA direction spectrum closely matches original data variance spectrum.
  - [corpus]: No direct corpus evidence for this specific geometric claim.
- Break condition: OpenL3 with low-pass filtering shows slightly lower CCA direction dimensionality (partial exception noted in paper).

### Mechanism 3
- Claim: Linear subspace projection methods fail to systematically improve downstream robustness because deformation is high-dimensional.
- Mechanism: Six projection methods (global CCA, sample-wise CCA SVD with thresholds t∈{0.3,0.4,0.5}, PCA variants, average displacement, LDA) attempt to remove deformation directions. Classification ROC AUC remains sensitive to effect strength post-projection.
- Core assumption: If deformation were low-dimensional, orthogonal projection would neutralize sensitivity.
- Evidence anchors:
  - [abstract]: "projecting out the estimated deformation directions/subspaces through various methods... does not generally improve downstream classification robustness"
  - [section IV, page 4, Figure 4]: ROC AUC curves show minimal/no improvement; average displacement occasionally improves by 0.003-0.01 AUC but equally often degrades performance.
  - [corpus]: Wang et al. [3] showed dataset bias projection worked under low-dimensional assumption—this paper demonstrates that assumption fails for audio effects.
- Break condition: No consistent break condition found; failure is the norm across methods.

## Foundational Learning

- **Concept: Canonical Correlation Analysis (CCA)**
  - Why needed here: Core analytical tool for quantifying correlation between embedding deformations and effect parameters; distinguishes sample-wise monotonicity from global linearization.
  - Quick check question: If CCA finds R²=1 between embeddings and effect strength, does this prove low-dimensional deformation? (Answer: No—CCA only captures monotonic correlation along one direction; other dimensions may vary arbitrarily.)

- **Concept: Subspace Projection for Debiasing**
  - Why needed here: Prior work (e.g., dataset bias removal) assumed unwanted sensitivity lives in a low-dimensional, linearly-separable subspace that can be projected out.
  - Quick check question: When does orthogonal projection remove sensitivity? (Answer: Only when the sensitive variation is low-rank and orthogonal to task-relevant dimensions.)

- **Concept: Foundation Model Embeddings as Feature Extractors**
  - Why needed here: Motivates understanding what pre-trained embeddings encode and their invariance properties before deployment.
  - Quick check question: Are pre-trained embeddings guaranteed to be invariant to "irrelevant" transformations? (Answer: No—this paper empirically shows sensitivity to common effects like gain and reverb.)

## Architecture Onboarding

- **Component map:**
  - Effect application layer: Pedalboard/Scipy → parameterized audio transformations
  - Embedding extractors: OpenL3 (512-dim frame-wise), PANNs (2048-dim clip-level), CLAP (1024-dim clip-level)
  - Analysis layer: UMAP visualization → CCA correlation analysis → SVD dimensionality assessment
  - Mitigation layer: Six projection methods applied pre-classifier
  - Evaluation: Logistic regression classifier → ROC AUC on IRMAS instrument classification

- **Critical path:**
  1. Generate effected audio samples across parameter grid
  2. Extract embeddings for original + effected versions
  3. Fit CCA (global or sample-wise) to find deformation directions
  4. Assess dimensionality via SVD of sample-wise directions
  5. Apply projection methods and evaluate downstream classification

- **Design tradeoffs:**
  - Sample-wise CCA captures local monotonicity but doesn't generalize globally
  - Higher SVD threshold (t=0.5) projects more dimensions but risks removing task-relevant information
  - Normalized vs. non-normalized PCA: relative ratio (σ²ᵢ/τ²ᵢ) vs. absolute variance prioritization

- **Failure signatures:**
  - Projection methods that leave ROC AUC unchanged → deformation is high-dimensional
  - Projection methods that reduce AUC → removed task-relevant dimensions
  - Discontinuous UMAP trajectories → non-linear embedding response (e.g., CLAP with bitcrushing)

- **First 3 experiments:**
  1. Replicate global CCA correlation analysis on a single effect/embedding combination to verify R²>0.9; check for sample-wise R²=1.0.
  2. Run SVD dimensionality comparison (Figure 3 replication) to confirm high-dimensional deformation subspace.
  3. Apply average displacement projection and measure ROC AUC change on held-out instrument class to verify inconsistent improvement pattern.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can non-linear post-processing methods (e.g., learned neural transformations) effectively remove sensitivity to audio effects where linear subspace projection fails?
- Basis in paper: [inferred] The authors conclude that "a linear post-processing approach... may hardly improve the robustness" since deformation subspaces are high-dimensional, but do not explore non-linear alternatives.
- Why unresolved: All tested methods (CCA, PCA, LDA, average displacement) are linear projections; non-linear approaches remain unexplored.
- What evidence would resolve it: Empirical comparison of non-linear debiasing methods (autoencoders, adversarial learning, MLP-based transformations) on the same downstream classification tasks.

### Open Question 2
- Question: Do the findings on high-dimensional deformation subspaces generalize to other foundation models (e.g., speech models like Whisper) and other audio effects (e.g., compression, pitch shifting)?
- Basis in paper: [explicit] "The proposed pipeline could be potentially generalized to analyze the sensitivity of any foundation models to any known parameters, beyond audio effects."
- Why unresolved: Only three embedding models (OpenL3, PANNs, CLAP) and four effects were tested.
- What evidence would resolve it: Applying the same CCA-based analysis pipeline to additional models and effect types, reporting dimensionality and correlation statistics.

### Open Question 3
- Question: Can interventions during pre-training (e.g., adversarial training, effect-augmented contrastive learning) produce embeddings that inherently linearize audio effects?
- Basis in paper: [inferred] The negative results suggest pre-trained embeddings do not linearize effects, raising the question of whether different training objectives could achieve this property.
- Why unresolved: This work only analyzes existing pre-trained models without modifying their training procedures.
- What evidence would resolve it: Training new embedding models with effect-related objectives and testing whether deformation subspaces become lower-dimensional.

## Limitations
- The study only tests three pre-trained models and four specific audio effects, limiting generalizability to other models and transformations.
- All debiasing methods tested are linear projections; nonlinear approaches that might handle high-dimensional deformation better remain unexplored.
- Results are demonstrated on only one downstream task (instrument classification), leaving open whether findings generalize to other audio tasks.

## Confidence
- **High confidence**: Sample-wise monotonicity (R² = 1.0) is directly observed and failure of linear projection methods is consistently demonstrated
- **Medium confidence**: Dimensionality analysis methodology is sound but lacks statistical significance testing across all effect types
- **Medium confidence**: Broader interpretation that linear approaches are fundamentally limited extrapolates from specific projection methods

## Next Checks
1. **Statistical significance testing**: Perform permutation tests on the SVD singular value ratios to establish whether the high-dimensional deformation pattern is statistically significant compared to random directions.
2. **Cross-task generalization**: Replicate the projection experiments on a different audio classification task (e.g., environmental sound classification) to verify whether the failure of linear debiasing generalizes beyond instrument classification.
3. **Alternative projection methods**: Test nonlinear dimensionality reduction techniques (e.g., autoencoders, kernel PCA) to determine if the high-dimensional deformation can be better captured by nonlinear approaches.