---
ver: rpa2
title: 'PQFed: A Privacy-Preserving Quality-Controlled Federated Learning Framework'
arxiv_id: '2509.21704'
source_url: https://arxiv.org/abs/2509.21704
tags:
- clients
- data
- client
- each
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses data heterogeneity in federated learning by
  proposing PQFed, a privacy-preserving quality-controlled framework that enables
  early-stage client selection before federated training. PQFed extracts representative
  features from each client's raw data using PCA, applies local differential privacy
  by adding Laplacian noise, and uses clustering techniques to estimate inter-client
  dataset similarity.
---

# PQFed: A Privacy-Preserving Quality-Controlled Federated Learning Framework

## Quick Facts
- **arXiv ID:** 2509.21704
- **Source URL:** https://arxiv.org/abs/2509.21704
- **Reference count:** 40
- **Primary result:** PQFed achieves 15-30% accuracy improvements for target clients in federated learning by selecting collaboration partners based on dataset similarity before training begins.

## Executive Summary
PQFed addresses the fundamental challenge of data heterogeneity in federated learning by introducing a pre-training selection mechanism that identifies compatible collaboration partners. The framework extracts representative features from each client's raw data using PCA, applies local differential privacy by adding Laplacian noise, and uses clustering techniques to estimate inter-client dataset similarity. Based on Earth Mover's Distance between clustering distributions, PQFed recommends collaboration groups for each client. The framework is evaluated on CIFAR-10 and MNIST datasets integrated with three federated learning algorithms (FedAvg, FedProx, FedDyn). Experimental results show that PQFed consistently improves model performance for target clients, achieving accuracy improvements of 15-30% compared to local training only. The framework also outperforms the baseline clustering-based algorithm IFCA in most cases while reducing computational and communication costs by limiting participation to compatible clients only.

## Method Summary
PQFed operates as a pre-processing layer for federated learning that selects collaboration partners before training begins. The server first trains a PCA model on public data (500 samples from the test set) and broadcasts it to all clients. Each client applies the PCA model to their local data, generating 50-dimensional feature representations, then adds coordinate-wise Laplacian noise scaled to each component's sensitivity divided by the privacy parameter ε. The noisy features are sent to the server, which trains K-means clustering (K=15) on the aggregated features. The server computes Earth Mover's Distance (EMD) between the target client and all other clients based on their clustering distributions. Clients with EMD below a threshold (30-60% of maximum EMD) are selected for collaborative training. The selected clients then proceed with federated learning using FedAvg, FedProx, or FedDyn algorithms. This approach enables privacy-preserving dataset similarity estimation while filtering out heterogeneous data that would degrade target client performance.

## Key Results
- Target client accuracy improves by 15-30% when collaborating with 4 similar clients versus local training only
- FedAvg with PQFed achieves 72.33% accuracy on CIFAR-10 target client versus 51.67% with dissimilar collaborators
- PQFed reduces computational and communication costs by limiting participation to compatible clients only
- Outperforms baseline IFCA clustering-based algorithm in most experimental scenarios
- Membership inference attack power remains ≤0.2 at ε=10 and ≤0.08 at ε≤1

## Why This Works (Mechanism)

### Mechanism 1: Pre-Training Distribution Similarity Screening
- **Claim:** Selecting collaboration partners based on data distribution similarity before federated training improves target client accuracy compared to training with all available clients.
- **Mechanism:** PQFed uses Earth Mover's Distance (EMD) between clients' clustering distributions as a proxy for dataset similarity. Clients with EMD below threshold are invited to collaborate. This filters heterogeneous data that would otherwise cause model drift away from the target client's optimal representation.
- **Core assumption:** Distribution similarity (measured via clustering overlap) correlates with mutual benefit in collaborative training—clients with similar distributions provide gradients that align with the target client's learning objective.
- **Evidence anchors:**
  - [Table II]: Target client T collaborating with 4 similar clients achieves 72.33% accuracy on CIFAR-10 vs. 51.67% with 4 dissimilar clients.
  - [Table IV-V]: Adding dissimilar clients beyond the EMD threshold degrades performance (e.g., FedProx drops from 64.00% at 60% dissimilarity to 59.67% at 100%).
  - [corpus]: Related work (FedCCA, GC-Fed) addresses heterogeneity during training; PQFed differs by filtering before training begins.
- **Break condition:** If EMD computed on noisy PCA features fails to correlate with actual distributional shift (e.g., under very strong privacy ε<0.1), the selection mechanism degrades to random selection.

### Mechanism 2: Local Differential Privacy on Feature Representations
- **Claim:** Adding coordinate-wise Laplacian noise to PCA-transformed features provides ε-LDP while preserving sufficient structure for similarity estimation.
- **Mechanism:** Each client computes PCA projections of local data, then adds Laplacian noise scaled to each component's ℓ₁ sensitivity divided by ε. The noisy representations are sent to the server. Noise magnitude is calibrated to mask individual record contributions while preserving aggregate cluster structure.
- **Core assumption:** PCA compression concentrates useful variance in early components; adding noise proportional to component sensitivity preserves enough signal for clustering while obscuring individual samples.
- **Evidence anchors:**
  - [Section IV-B]: Formal ε-LDP guarantee via Laplacian mechanism: F(x) = f(x) + Lap(s/ε).
  - [Figure 4]: Membership inference attack power remains ≤0.2 at ε=10, ≤0.08 at ε≤1.
  - [Figure 3]: At ε=10, EMD curves closely track no-noise baseline, enabling effective similarity estimation.
  - [corpus]: Corpus evidence on LDP for feature representations is limited; no direct comparison papers found.
- **Break condition:** At very low ε (e.g., 0.1), noise overwhelms cluster structure, flattening EMD curves and breaking the selection mechanism.

### Mechanism 3: Clustering Distribution as Distribution Proxy
- **Claim:** The proportion of a client's data assigned to each K-means cluster serves as a sufficient statistic for comparing dataset distributions.
- **Mechanism:** Server trains K-means (K=15) on aggregated noisy PCA features. Each client's data is assigned to clusters, yielding a discrete distribution over cluster IDs. EMD between these distributions quantifies distributional distance without requiring raw data sharing.
- **Core assumption:** K-means clusters capture semantically meaningful groupings that align with class or feature distributions; similar cluster distributions imply similar underlying data distributions.
- **Evidence anchors:**
  - [Section VI-D]: "When 2 datasets exhibit similar clustering distributions, their label distributions also tend to align."
  - [Figure 3]: EMD increases monotonically with dissimilarity rate r under moderate noise, validating the proxy.
  - [corpus]: Corpus does not provide comparative evidence on clustering vs. other similarity metrics.
- **Break condition:** If K is too small (under-clustering) or too large (overfitting to noise), the proxy becomes unreliable; K selection via elbow method mitigates this but is heuristic.

## Foundational Learning

- **Concept: Federated Learning (FedAvg/FedProx/FedDyn)**
  - **Why needed here:** PQFed is a pre-processing layer that integrates with any FL algorithm; understanding these baselines is required to interpret improvement claims.
  - **Quick check question:** Can you explain why FedProx adds a proximal term and how it differs from FedAvg in heterogeneous settings?

- **Concept: Local Differential Privacy (LDP) and Laplacian Mechanism**
  - **Why needed here:** PQFed's privacy guarantee depends on correctly applying LDP to PCA features; implementation errors here invalidate privacy claims.
  - **Quick check question:** Given sensitivity s=0.5 and ε=10, what Laplacian noise scale should be added?

- **Concept: Earth Mover's Distance (EMD)**
  - **Why needed here:** EMD is the core similarity metric; understanding its properties (metric, captures spatial structure) is necessary to reason about threshold selection.
  - **Quick check question:** Why would EMD be preferred over KL divergence for comparing clustering distributions with different support?

## Architecture Onboarding

- **Component map:** Server (Public PCA trainer → PCA model M_p broadcast → K-means trainer on aggregated features → EMD calculator → Threshold-based client selector → FL aggregator) -> Client (Receive M_p → Apply M_p to local data → Add Laplacian noise (ε-LDP) → Send noisy features → Receive collaboration decision → Local FL training)

- **Critical path:**
  1. Server trains PCA on public data (500 samples from test set)
  2. Server broadcasts PCA model to all clients
  3. Each client extracts 50-dimensional PCA features, adds Laplacian noise, sends to server
  4. Server trains K-means (K=15) on all received features
  5. Server computes EMD between target client and all others
  6. Server selects clients with EMD ≤ threshold (30-60% of max EMD)
  7. Selected clients proceed with FL training (FedAvg/FedProx/FedDyn)

- **Design tradeoffs:**
  - **Privacy vs. Utility:** Lower ε increases privacy but flattens EMD, degrading selection accuracy. Paper recommends ε∈[1,10].
  - **Strict vs. Lenient Threshold:** 30% threshold is conservative (fewer clients, potentially higher quality); 60% includes more clients but risks noise from moderate heterogeneity.
  - **K Selection:** Higher K captures finer structure but may overfit to noise; K=15 chosen via elbow method but not rigorously validated.

- **Failure signatures:**
  - EMD values near zero for all client pairs: Likely ε too low; noise destroyed structure.
  - Accuracy worse than local-only training: Threshold may include highly dissimilar clients; re-calibrate threshold or check EMD computation.
  - Membership inference power >0.5: ε may be too high or sensitivity miscalculated.

- **First 3 experiments:**
  1. Reproduce Figure 3: Vary dissimilarity rate r and ε, plot EMD trends. Verify that ε=10 preserves monotonically increasing EMD.
  2. Reproduce Table II: Compare target client accuracy with similar vs. dissimilar collaborators (4 clients each, r=0 vs. r=1).
  3. Privacy-utility sweep: Fix r, vary ε∈{0.1,1,10,100}, measure both membership inference power and FL accuracy to identify optimal operating point.

## Open Questions the Paper Calls Out
None

## Limitations
- Primary limitation is the assumption that clustering distribution similarity correlates with mutual benefit in collaborative training, which is empirically validated but not theoretically proven
- Choice of K=15 for K-means clustering is heuristic, based on elbow method rather than rigorous validation
- Framework's performance on highly skewed or multi-modal distributions remains untested
- Privacy analysis assumes i.i.d. data within each client, which may not hold in practice

## Confidence
- **High confidence:** Pre-training distribution similarity screening improves target client accuracy when correctly implemented (supported by Table II and IV-V results)
- **Medium confidence:** ε-LDP via Laplacian noise on PCA features provides adequate privacy-utility tradeoff (membership inference results show effectiveness but no formal utility-privacy bounds)
- **Medium confidence:** Clustering distribution serves as sufficient proxy for dataset similarity (monotonic EMD trends observed but alternative metrics not compared)

## Next Checks
1. Test PQFed's robustness to non-i.i.d. label distributions within clients (e.g., power-law or zipfian distributions) to validate clustering proxy assumption
2. Conduct ablation study varying K (5, 10, 15, 20, 25) to determine sensitivity to clustering granularity and validate elbow method selection
3. Implement formal privacy accounting (Rényi DP or zCDP) to derive tight bounds on privacy-utility tradeoff and validate ε selection criteria