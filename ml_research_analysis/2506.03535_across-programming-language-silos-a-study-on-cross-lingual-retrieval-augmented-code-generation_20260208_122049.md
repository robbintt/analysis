---
ver: rpa2
title: 'Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented
  Code Generation'
arxiv_id: '2506.03535'
source_url: https://arxiv.org/abs/2506.03535
tags:
- code
- racg
- llms
- generation
- multi-lingual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study is the first to explore the utility and robustness of
  multi-lingual retrieval-augmented code generation (RACG) across 13 programming languages.
  It constructs a high-quality dataset with nearly 14k code generation instances to
  investigate knowledge transfer effectiveness and adversarial attack resilience.
---

# Across Programming Language Silos: A Study on Cross-Lingual Retrieval-augmented Code Generation

## Quick Facts
- arXiv ID: 2506.03535
- Source URL: https://arxiv.org/abs/2506.03535
- Reference count: 40
- First study to systematically explore cross-lingual RACG across 13 programming languages, revealing significant utility gains and novel adversarial robustness patterns.

## Executive Summary
This study pioneers the exploration of cross-lingual retrieval-augmented code generation (RACG) across 13 programming languages, constructing a high-quality dataset with nearly 14k code generation instances. The research reveals that multi-lingual LLMs significantly benefit from cross-lingual knowledge transfer, with Java demonstrating superior utility over Python as a knowledge source. While multi-lingual models show consistent gains across all languages, mono-lingual models experience native language degradation when augmented with cross-lingual knowledge. The study also uncovers that cross-lingual RACG exhibits unexpected resilience against adversarial attacks, with syntax-level perturbations sometimes improving performance by forcing focus on logical reasoning rather than surface syntax.

## Method Summary
The study constructs a parallel dataset across 13 programming languages, expanding HumanEval-X to ~14k instances. It employs CodeRankEmbed for retrieval and evaluates both multi-lingual (CodeLlama, Deepseek-Coder, Qwen2.5-Coder) and mono-lingual (Phi-1, Phi-1.5) LLMs. The RACG pipeline involves retrieving top-3 code documents from source languages, prompting the target language generator, and validating outputs via unit tests. Four settings are tested: same-language retrieval, cross-lingual retrieval, retrieval with adversarial perturbations, and cross-lingual retrieval with perturbations. Pass@1 serves as the primary metric, with comprehensive analysis of utility gains and adversarial robustness across language pairs.

## Key Results
- Cross-lingual RACG yields +12.84% average improvement for multi-lingual LLMs versus +3.06% for mono-lingual models
- Java demonstrates superior cross-lingual utility (+16.08% average improvement) compared to Python (+8.29%)
- Domain-specific retrievers (CodeRankEmbed) achieve 91.60% Precision@5 versus 6.57% for general text embedders
- Cross-lingual RACG mitigates adversarial attack impacts, with mono-lingual models suffering 35-88% degradation versus 10-30% for multi-lingual models

## Why This Works (Mechanism)

### Mechanism 1: Cross-Lingual Semantic Pattern Extraction
Multi-lingual LLMs extract semantic abstractions (control flow, algorithmic logic) from retrieved code across language boundaries, leveraging shared internal representations from multi-lingual pretraining. This works because cross-lingual pretraining creates overlapping semantic representations that survive language boundaries. Break condition: Source-target pairs with paradigm mismatch (e.g., Haskell→Python) may fail if semantic patterns are unrecognizable.

### Mechanism 2: Structured Language Superiority in Knowledge Transfer
Java's explicit typing and verbose structure expose semantic intent more clearly than Python's dynamic idioms, enabling LLMs to extract transferable patterns with less ambiguity. This assumes syntactic explicitness aids semantic extraction during cross-lingual reasoning. Break condition: Tasks requiring Python-specific idioms (decorators, dynamic typing patterns) may not benefit from Java corpus.

### Mechanism 3: Cross-Lingual Adversarial Noise Filtering
When adversarial code must be translated across PLs, semantic errors become more salient while syntactic noise is filtered. Multi-lingual LLMs prioritize internal knowledge over conflicting external signals. This assumes LLMs can detect implausible cross-lingual translations and default to internal knowledge. Break condition: Semantic-altering attacks (logic reversal, control flow modification) still degrade cross-lingual RACG, though less severely.

## Foundational Learning

- **Concept: RACG Pipeline Stages (Retrieval → Prompting → Generation → Evaluation)**
  - Why needed here: The paper isolates retrieval quality, corpus composition, and generation capability as independent variables.
  - Quick check question: Can you explain why "Doc w/o NL" setting underperforms "Doc" setting by ~7 percentage points?

- **Concept: Multi-lingual vs. Mono-lingual Code LLMs**
  - Why needed here: Their cross-lingual behavior diverges critically—multi-lingual LLMs gain across all PLs; mono-lingual LLMs degrade on native tasks.
  - Quick check question: Why does augmenting a Python-specialized LLM with Java corpus improve non-Python tasks but harm Python tasks?

- **Concept: Code Semantic Embedding vs. Lexical Matching**
  - Why needed here: Retriever choice determines whether RACG works at all (91.60% vs 6.57% Precision@5).
  - Quick check question: Why does BM25 fail catastrophically for pure code retrieval without NL comments?

## Architecture Onboarding

- **Component map:** User query → Retriever (CodeRankEmbed) → Top-3 code documents → Prompt construction → LLM generation → Unit test evaluation
- **Critical path:** 1) User query (NL) → Retriever queries corpus in source PL 2) Top-K code documents → Prompt construction with target PL specification 3) Prompt → LLM generates code in target PL 4) Generated code → Test harness validates correctness
- **Design tradeoffs:** Multi-lingual LLMs: Higher cross-lingual gains but may require larger models; Domain-specific retrievers: 40+ percentage point precision gain vs. general embedders, but requires specialized training data; Corpus with NL: Better retrieval (95.22% vs 88.21% Pass@K) but real-world code often lacks comments
- **Failure signatures:** Mono-lingual LLM + cross-lingual corpus → Native language degradation (-4.57% Python); BM25 retriever + Doc w/o NL → Near-random retrieval (4.79% Recall); Adversarial Java corpus → Higher error propagation than Python (30% vs 24% degradation)
- **First 3 experiments:** 1) Establish mono-lingual baseline: Same-language RACG with Doc setting across 13 PLs, measure Pass@K per language 2) Cross-lingual transfer matrix: For each source-target pair among top-5 PLs, measure Pass@K delta vs. baseline; identify high-performing pairs 3) Adversarial robustness test: Apply syntax and semantic perturbations to Java/Python corpus; compare degradation in mono-lingual vs. cross-lingual settings

## Open Questions the Paper Calls Out

### Open Question 1
How can hybrid retrieval strategies be optimized to balance linguistic affinity (e.g., between JavaScript and TypeScript) with task-specific knowledge requirements to avoid amplifying capability disparities? The study identifies that naive cross-lingual retrieval can amplify disparities (e.g., PHP/Scala corpora degrading performance), but does not propose or test a weighted or hybrid selection mechanism to mitigate this.

### Open Question 2
Can mono-lingual code LLMs be adapted to utilize cross-lingual retrieval without suffering performance degradation in their native language? Finding 2 notes that while multi-lingual LLMs gain consistently, mono-lingual models suffer native language degradation (approx. -4.57%) when augmented with cross-lingual knowledge, but the paper does not explore architectural fine-tuning or prompt engineering methods to filter conflicting cross-lingual signals.

### Open Question 3
Does the beneficial effect of syntax-level perturbations on logical reasoning generalize to larger proprietary models (e.g., >7B parameters) and complex software engineering tasks? Finding 8 hypothesizes that syntax perturbations help LLMs focus on logic rather than syntax rules, but the analysis is limited to models ≤ 7B, leaving uncertainty about whether this is a robust feature or an artifact of smaller model capacities.

## Limitations
- Synthetic corpus construction may not capture real-world code complexity where comments are sparse
- Performance gap between Doc and Doc w/o NL settings (8-12 percentage points) suggests brittleness in production scenarios
- Focus on small-scale models (7B parameters) and Pass@1 evaluation leaves open questions about scaling effects and multi-output robustness

## Confidence
- **High Confidence:** Cross-lingual utility gains for multi-lingual LLMs (+12.84% average improvement), Java superiority as cross-lingual knowledge source, and domain-specific retriever performance (91.60% vs 6.57% Precision@5)
- **Medium Confidence:** Adversarial attack mitigation patterns, particularly the claim that perturbed code sometimes improves RACG performance through semantic noise filtering
- **Low Confidence:** Generalization to larger models, production codebases lacking comments, and long-term adversarial robustness under sustained attacks

## Next Checks
1. **Production Corpus Validation:** Test RACG performance on a real-world dataset of 1000+ code snippets without comments to measure the practical gap between Doc and Doc w/o NL settings
2. **Model Scaling Study:** Evaluate cross-lingual RACG performance with 70B+ parameter models to determine if utility gains scale proportionally or exhibit diminishing returns
3. **Adversarial Resilience Benchmark:** Design a systematic attack suite combining syntax, lexicon, and semantic perturbations to quantify cross-lingual filtering effectiveness across multiple attack intensities