---
ver: rpa2
title: 'DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only
  Antigen-Antibody Affinity Prediction'
arxiv_id: '2512.22007'
source_url: https://arxiv.org/abs/2512.22007
tags:
- antibody
- affinity
- antigen
- binding
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DuaDeep-SeqAffinity, a novel sequence-only
  deep learning framework for predicting antigen-antibody binding affinity scores.
  The core innovation lies in a dual-stream hybrid architecture that combines ESM-2
  protein language model embeddings with 1D Convolutional Neural Networks (CNNs) for
  local motif detection and Transformer encoders for global contextual representation.
---

# DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction

## Quick Facts
- arXiv ID: 2512.22007
- Source URL: https://arxiv.org/abs/2512.22007
- Reference count: 40
- Primary result: Achieves Pearson correlation of 0.688 and AUC of 0.890 for sequence-only antigen-antibody affinity prediction

## Executive Summary
This paper introduces DuaDeep-SeqAffinity, a novel sequence-only deep learning framework for predicting antigen-antibody binding affinity scores. The core innovation lies in a dual-stream hybrid architecture that combines ESM-2 protein language model embeddings with 1D Convolutional Neural Networks (CNNs) for local motif detection and Transformer encoders for global contextual representation. A fusion module integrates these multi-faceted features, which are then passed to a fully connected network for final score regression. Experimental results demonstrate that DuaDeep-SeqAffinity significantly outperforms existing state-of-the-art methods, achieving a Pearson correlation of 0.688, an R² of 0.460, and a Root Mean Square Error (RMSE) of 0.737. Notably, the model achieves an AUC of 0.890, surpassing sequence-only benchmarks and even structure-sequence hybrid models. These findings prove that high-fidelity sequence embeddings can capture essential binding patterns typically reserved for structural modeling, providing a highly scalable and efficient solution for high-throughput screening of vast sequence libraries.

## Method Summary
DuaDeep-SeqAffinity employs a dual-stream architecture that processes antibody and antigen sequences separately before combining them for affinity prediction. The first stream uses ESM-2 embeddings to capture evolutionary and structural information, while the second stream employs 1D CNNs to detect local sequence motifs and Transformers to model global contextual relationships. A fusion module integrates these complementary feature representations, which are then passed through a fully connected network for final regression. The model is trained end-to-end using binding affinity scores as targets, with performance evaluated using Pearson correlation, R², RMSE, and AUC metrics.

## Key Results
- Achieves Pearson correlation of 0.688 and R² of 0.460 on affinity prediction
- Demonstrates RMSE of 0.737 and AUC of 0.890, outperforming sequence-only benchmarks
- Surpasses structure-sequence hybrid models while maintaining sequence-only approach

## Why This Works (Mechanism)
The dual-stream architecture captures both local sequence motifs and global contextual relationships through specialized neural network components. ESM-2 embeddings provide rich evolutionary and structural information learned from large protein sequence databases, while CNNs identify local binding-relevant patterns. Transformers model long-range dependencies and contextual relationships that influence binding affinity. The fusion module effectively combines these complementary feature sets, allowing the model to capture the complex, multi-scale nature of antigen-antibody interactions that depend on both local contact points and global structural compatibility.

## Foundational Learning
- Protein language models (ESM-2): Capture evolutionary relationships and structural patterns from sequence data; needed for extracting meaningful features from raw sequences
- Convolutional Neural Networks: Detect local sequence motifs and patterns; essential for identifying binding-relevant local features
- Transformer encoders: Model global contextual relationships and long-range dependencies; required for understanding sequence-level interactions
- Feature fusion techniques: Combine complementary representations from different network streams; necessary for integrating multi-scale information
- Regression vs classification: Different approaches for predicting continuous affinity scores vs discrete binding states; impacts evaluation metrics and model design

## Architecture Onboarding

**Component map:** Input sequences -> ESM-2 embeddings -> CNN feature extraction -> Transformer encoding -> Fusion module -> Fully connected network -> Affinity prediction

**Critical path:** Input sequence processing through ESM-2 and CNN/Transformer streams, followed by feature fusion and regression output

**Design tradeoffs:** Sequence-only approach sacrifices structural detail for scalability and efficiency; dual-stream design balances local and global feature extraction

**Failure signatures:** Poor performance on sequences with rare motifs, failure to capture long-range dependencies, overfitting to training distribution

**First experiments:** 1) Test ESM-2 embeddings alone vs combined with CNN/Transformer streams; 2) Evaluate different fusion strategies (concatenation vs attention); 3) Compare single-stream vs dual-stream architectures

## Open Questions the Paper Calls Out
None

## Limitations
- Claims about matching structural modeling capabilities lack direct comparison with high-resolution structural models
- Practical utility limited by lack of sensitivity/specificity values for classification threshold
- Sequence-only approach inherently cannot capture three-dimensional structural interactions

## Confidence

**Performance metrics and comparison with existing methods:** High
**Claim about sequence embeddings matching structural modeling capabilities:** Medium
**Generalizability to diverse antibody-antigen pairs:** Medium
**Scalability claims for high-throughput screening:** High

## Next Checks
1. Benchmark DuaDeep-SeqAffinity against structure-based affinity prediction methods on the same dataset to directly assess the claim about sequence-only approaches matching structural modeling capabilities.

2. Evaluate model performance across different antibody isotypes and antigen classes to assess generalizability beyond the training distribution.

3. Perform ablation studies systematically removing components (ESM-2, CNNs, Transformers) to quantify individual contributions and validate the dual-stream architecture's effectiveness.