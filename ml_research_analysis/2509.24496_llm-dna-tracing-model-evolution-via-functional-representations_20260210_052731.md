---
ver: rpa2
title: 'LLM DNA: Tracing Model Evolution via Functional Representations'
arxiv_id: '2509.24496'
source_url: https://arxiv.org/abs/2509.24496
tags:
- only
- decoder
- apache-2
- unknown
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LLM DNA, a mathematical framework for representing
  large language models (LLMs) as low-dimensional vectors that capture functional
  behavior and evolutionary relationships. The method defines DNA via a bi-Lipschitz
  mapping from the LLM function space, ensuring inheritance (small model changes preserve
  DNA) and genetic determinism (similar DNA implies similar behavior).
---

# LLM DNA: Tracing Model Evolution via Functional Representations

## Quick Facts
- **arXiv ID**: 2509.24496
- **Source URL**: https://arxiv.org/abs/2509.24496
- **Reference count**: 40
- **Primary result**: Introduces a mathematical framework representing LLMs as low-dimensional vectors that capture functional behavior and evolutionary relationships with proven inheritance properties.

## Executive Summary
This paper presents LLM DNA, a framework that maps large language models to low-dimensional vectors while preserving functional relationships through bi-Lipschitz mapping. The method theoretically guarantees that small model changes produce small DNA changes (inheritance) and similar DNA implies similar behavior (genetic determinism). Using random Gaussian projections on semantic embeddings of model outputs, DNA vectors can be extracted without training or architecture-specific engineering. Experiments on 305 diverse LLMs demonstrate DNA's ability to detect documented and undocumented relationships, outperform existing methods on routing tasks (AUC 0.957), and construct phylogenetic trees revealing architectural shifts and evolutionary patterns across model families.

## Method Summary
The method generates LLM DNA by sampling prompts from benchmark datasets, generating responses from target models, encoding these responses using a semantic embedding model (Qwen3-Embedding-8B), concatenating embeddings, and applying random Gaussian projection. For each LLM, responses to t prompts are embedded into p-dimensional vectors, concatenated into a single vector, and projected via a random matrix A to produce a DNA vector in R^L. Key hyperparameters include L=128 projection dimensions, t=600 total prompts (100 from each of 6 benchmarks), and embedding via Qwen3-Embedding-8B with max_length=1024. The method requires no training or architecture-specific engineering, making it universally applicable across diverse LLMs.

## Key Results
- DNA accurately detects documented and undocumented relationships between 305 diverse LLMs
- Outperforms existing model representation methods on routing tasks with AUC 0.957
- Constructs phylogenetic trees revealing architectural shifts and varying evolutionary speeds across model families
- Validates inheritance property where fine-tuned models remain close to base models in DNA space

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bi-Lipschitz mapping preserves functional similarity between LLMs in low-dimensional DNA space
- Mechanism: Mapping satisfies c₁·dH(f₁,f₂) ≤ dτ(τf₁,τf₂) ≤ c₂·dH(f₁,f₂), ensuring small functional changes yield small DNA changes and similar DNAs imply similar functions
- Core assumption: LLM functional space forms a Hilbert space with valid inner product over bounded input sequences
- Evidence anchors: Formal bi-Lipschitz condition in Section 3.1; weak corpus support
- Break condition: If functional distance dH is not well-defined, bi-Lipschitz guarantee fails

### Mechanism 2
- Claim: Random Gaussian projection suffices to extract DNA without training or architecture-specific engineering
- Mechanism: Johnson-Lindenstrauss lemma guarantees distance preservation in O(((c₂+c₁)/(c₂-c₁))² log K) dimensions
- Core assumption: Functional space admits JL embedding; acceptable distortion tolerance
- Evidence anchors: JL lemma application in abstract and Section 4; weak corpus support
- Break condition: If K grows extremely large or distortion tolerance approaches zero, scalability breaks

### Mechanism 3
- Claim: Stochastic sampling plus semantic embedding approximates true functional distance with provable concentration
- Mechanism: Sample t prompts, generate responses, embed them, project; Hoeffding's inequality provides exponential convergence
- Core assumption: Output differences bounded; embedding model preserves semantic similarity proportional to functional similarity
- Evidence anchors: Concentration bound in Section 5.2; random Gaussian projections in abstract; weak corpus support
- Break condition: If embedding model fails to capture functional differences, DNA distances become uninformative

## Foundational Learning

- **Concept**: Bi-Lipschitz mappings
  - Why needed here: Core mathematical property ensuring DNA preserves functional relationships bidirectionally
  - Quick check question: Given f₁, f₂ with dH=0.1 and c₁=0.9, c₂=1.1, what is the valid range for dτ?

- **Concept**: Johnson-Lindenstrauss Lemma
  - Why needed here: Guarantees random projection preserves distances in much lower dimensions
  - Quick check question: For K=305 LLMs and distortion ε=0.1, what approximate dimension L is required?

- **Concept**: Hilbert spaces and inner products
  - Why needed here: Prerequisite for applying JL lemma and defining functional distance
  - Quick check question: Why does finiteness of input space Sₘ matter for establishing Hilbert space structure?

## Architecture Onboarding

- **Component map**: Input sampler → Target LLM → Sentence embedding model → Concatenation → Random Gaussian projection → DNA vector
- **Critical path**: Sample quality → Embedding model fidelity → Projection dimension L
- **Design tradeoffs**: Higher L improves fidelity but increases storage cost; higher t tightens concentration bounds but increases inference cost; embedding model choice balances semantics vs. speed
- **Failure signatures**: Random DNA clustering suggests embedding failure; fine-tuned models far from base models suggest insufficient sampling; cross-architecture comparison failures suggest embedding architecture dependence
- **First 3 experiments**:
  1. Reproduce 8-model test from Zhu et al. (2025): compute DNAs for 4 correlated + 4 independent models relative to Llama-2-7B-hf; verify SVM separation
  2. Mantel stability test: extract DNAs from two disjoint prompt sets; confirm Pearson r > 0.75 between distance matrices
  3. Routing proxy test: replace EmbedLLM embeddings with frozen DNAs in matrix factorization routing; compare accuracy against random and single-best baselines

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the LLM DNA extraction pipeline to the choice of the semantic embedding model $\phi$, and does switching $\phi$ alter the inferred phylogenetic relationships?
- Basis in paper: Section 5.1 introduces $\phi$ as fixed component but provides no analysis on sensitivity to embedding geometry
- Why unresolved: Definition of Stochastic Functional Distance depends entirely on embedding model's ability to capture semantic similarity
- What evidence would resolve it: Comparative study using distinct SOTA embedding models and measuring correlation of resulting DNA distance matrices

### Open Question 2
- Question: What is the theoretical minimum number of input samples ($t$) required to ensure empirical functional distance approximates true Hilbert distance within fixed error margin $\epsilon$?
- Basis in paper: Lemma 5.2 provides concentration bound but experimental setup arbitrarily selects t=600 without optimizing for sample efficiency
- Why unresolved: Bound depends on C_{max} which is difficult to estimate a priori
- What evidence would resolve it: Ablation study plotting DNA stability and downstream task performance against varying sample sizes

### Open Question 3
- Question: Does the input probability distribution $\mu$ introduce bias in the DNA that favors specific model families or capabilities?
- Basis in paper: Section 5.2 defines Stochastic Functional Distance over μ, using uniform mixture of 6 specific datasets
- Why unresolved: If μ over-represents certain reasoning types, models fine-tuned on those distributions might appear artificially closer to base models
- What evidence would resolve it: Comparison of DNA trees extracted from domain-specific distributions to assess if relative positioning of specialized models changes

## Limitations

- Semantic embedding assumption represents a single point of failure - if embeddings fail to capture behavioral differences, the entire framework loses validity
- Bi-Lipschitz condition requires careful construction of Hilbert space structure that may not hold for all LLM behaviors
- Practical scalability limitations as projection dimension L scales with log K for larger model populations
- 8-bit quantization requirement for larger models may introduce artifacts affecting DNA extraction fidelity

## Confidence

- **High Confidence**: Mathematical framework for bi-Lipschitz mapping and Johnson-Lindenstrauss application is rigorously proven; routing task results (AUC 0.957) provide strong empirical support
- **Medium Confidence**: Claim that DNA captures undocumented evolutionary relationships is supported by phylogenetic tree construction but evidence is somewhat indirect; Mantel test suggests structural stability but doesn't prove meaningful functional relationships
- **Low Confidence**: Assertion that random Gaussian projection without training is sufficient assumes embedding model perfectly captures functional similarity; without direct validation, confidence in method's robustness across all LLM types remains limited

## Next Checks

1. **Embedding Validation Experiment**: Test DNA extraction using multiple embedding models (sentence-BERT, OpenAI embeddings, Qwen3) on model pairs with known functional differences; verify DNA distances correlate with actual behavioral differences measured through task performance metrics

2. **Fine-tuning Sensitivity Analysis**: Systematically fine-tune a base model with progressively larger modifications; measure how DNA distances scale with functional changes to verify bi-Lipschitz bounds hold empirically and inheritance property manifests as predicted

3. **Cross-Architecture Consistency Test**: Apply DNA extraction to models spanning fundamentally different architectures (transformers, RNNs, symbolic systems); evaluate whether semantic embedding consistently captures functional relationships across architectural boundaries or requires architectural normalization steps