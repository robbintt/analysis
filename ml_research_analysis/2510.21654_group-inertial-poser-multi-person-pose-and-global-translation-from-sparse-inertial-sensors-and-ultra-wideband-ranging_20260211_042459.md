---
ver: rpa2
title: 'Group Inertial Poser: Multi-Person Pose and Global Translation from Sparse
  Inertial Sensors and Ultra-Wideband Ranging'
arxiv_id: '2510.21654'
source_url: https://arxiv.org/abs/2510.21654
tags:
- pose
- motion
- estimation
- inertial
- translation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Group Inertial Poser (GIP), a novel method
  for multi-person 3D pose and global translation estimation using sparse inertial
  sensors and ultra-wideband ranging. The key innovation is leveraging inter-person
  distance measurements to overcome drift and provide spatial references between individuals,
  which purely inertial approaches cannot achieve.
---

# Group Inertial Poser: Multi-Person Pose and Global Translation from Sparse Inertial Sensors and Ultra-Wideband Ranging

## Quick Facts
- **arXiv ID:** 2510.21654
- **Source URL:** https://arxiv.org/abs/2510.21654
- **Reference count:** 40
- **Primary result:** 72% reduction in distance error vs. state-of-the-art inertial-only methods for multi-person pose estimation.

## Executive Summary
This paper introduces Group Inertial Poser (GIP), a novel method for multi-person 3D pose and global translation estimation using sparse inertial sensors and ultra-wideband ranging. The key innovation is leveraging inter-person distance measurements to overcome drift and provide spatial references between individuals, which purely inertial approaches cannot achieve. GIP employs structured state-space models for initial pose estimation, followed by two-step optimization that aligns individuals in a shared world frame using between-person distances and refines trajectory estimates. The authors also introduce GIP-DB, the first IMU+UWB dataset for two-person tracking with 200 minutes of diverse motion recordings from 14 participants. Evaluation on both synthetic (InterHuman) and real-world (GIP-DB) datasets demonstrates substantial improvements over state-of-the-art methods, with GIP reducing distance error by up to 72% at 20 seconds and achieving significant gains in pose and translation accuracy. The approach effectively captures inter-personal interaction dynamics and preserves meaningful spatial relationships between people during motion.

## Method Summary
GIP addresses the challenge of multi-person 3D pose estimation by fusing sparse inertial sensors (IMUs) with ultra-wideband (UWB) ranging. The method uses a structured state-space model (S4) to predict initial joint angles and velocities from IMU data, then applies a two-step optimization process. First, it aligns the relative starting position of individuals using between-person UWB distances. Second, it refines the full trajectory while enforcing smoothness constraints. The approach handles the drift inherent in inertial sensors by using UWB as an absolute reference, enabling accurate tracking of both pose and global translation in a shared coordinate frame.

## Key Results
- **Distance Error Reduction:** Up to 72% reduction in distance error compared to inertial-only methods at 20 seconds.
- **Pose Accuracy:** 9.94° angle error and 21.05 mm joint error on synthetic InterHuman dataset.
- **Real-World Performance:** 15.46 cm distance error on GIP-DB dataset, demonstrating practical effectiveness.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Leveraging absolute distance measurements between sensors worn by different individuals significantly reduces global translation drift and aligns users in a shared coordinate frame.
- **Mechanism:** While inertial sensors (IMUs) are self-referential and prone to drift, Ultra-Wideband (UWB) ranging provides absolute distance constraints ($D_t^{12}$) between sensor pairs across users. The system minimizes the discrepancy between these measured distances and distances derived from the predicted pose, effectively anchoring the drifting inertial estimates to a relative spatial reality.
- **Core assumption:** The UWB ranging errors (noise) are sufficiently random or filterable to allow the optimizer to converge on a correct spatial configuration, despite real-world occlusions (e.g., the human body blocking the signal).
- **Evidence anchors:**
  - [abstract] "...leveraging the distances between sparse wearable sensors—both on each individual and across multiple individuals."
  - [section 3.5] "The first term (7) enforces alignment between predicted and observed between-person sensor distances."
  - [corpus] Related work (UIP) establishes UWB utility for single-person drift; this paper extends it to multi-person spatial constraints.
- **Break condition:** If UWB signals suffer from consistent bias (e.g., systematic overestimation due to occlusion) rather than random noise, the "anchor" will pull the avatars into incorrect relative positions.

### Mechanism 2
- **Claim:** Structured State-Space Models (S4) provide superior temporal context for pose estimation compared to RNNs (LSTMs) by efficiently modeling long-range dependencies.
- **Mechanism:** The S4 model discretizes a continuous-time system defined by ODEs, allowing the network to capture complex sequential patterns in the inertial data without the "vanishing gradient" issues common in LSTMs. This allows the model to integrate motion history over longer windows to predict joint angles and velocities more accurately.
- **Core assumption:** Human motion dynamics can be approximated by the linear recurrence relations defined in the SSM formulation after appropriate discretization.
- **Evidence anchors:**
  - [section 3.3] "Compared to traditional models like LSTMs... S4 offers improved scalability, long-range dependency modeling, and parallelization."
  - [table 4] Ablation study shows the SSM-based model reducing Angle Error to 9.94° compared to LSTM's 12.88°.
  - [corpus] "SSD-Poser" and other neighbors confirm the trend toward State-Space models for efficient sequential modeling in pose estimation.
- **Break condition:** If the input sequence contains extreme discontinuities or high-frequency noise that violates the SSM's continuity assumptions, the state propagation may fail to track rapid pose changes.

### Mechanism 3
- **Claim:** Decoupling the optimization into an initial position step followed by a trajectory refinement step is necessary for stable convergence and accurate relative tracking.
- **Mechanism:** Attempting to optimize the full trajectory of two people simultaneously without a known starting offset is an ill-posed problem prone to local minima. By first optimizing only the relative starting position ($T_{12}^0$) and then refining the full trajectory ($T^1, T^2$), the system establishes a coherent global frame before smoothing the motion paths.
- **Core assumption:** The initial pose estimates from the neural network are accurate enough to compute the forward kinematics required to solve for the initial relative position.
- **Evidence anchors:**
  - [section 3.2] "Directly optimizing the entire trajectory (without the first optimization step) results in unstable convergence to unrealistic paths."
  - [section 3.4] "The goal here is to adjust $T_{12}^0$ so that the predicted and actual between-person sensor distances align."
- **Break condition:** If the initial poses are significantly wrong (e.g., limbs inverted), the forward-kinematics-derived sensor positions will be incorrect, causing the initial position optimizer to converge to the wrong relative offset.

## Foundational Learning

- **Concept: Ultra-Wideband (UWB) Ranging & Noise**
  - **Why needed here:** Unlike GPS or cameras, UWB measures time-of-flight of radio pulses to get distance. In this paper, understanding that UWB is susceptible to Non-Line-Of-Sight (NLOS) errors (reported as 15cm RMSE for between-person) is critical to understanding why the system requires a robust optimizer rather than just direct inversion.
  - **Quick check question:** Does a higher UWB RMSE imply the algorithm should rely *more* or *less* on the physics/regularization terms during optimization?

- **Concept: Forward Kinematics (FK)**
  - **Why needed here:** The optimization loop doesn't just guess positions; it calculates where sensors *should* be based on the predicted joint angles ($\Theta$) and a body model (SMPL). Understanding FK is required to see how "Angle Error" translates to "Distance Error."
  - **Quick check question:** If the SMPL mesh vertices are incorrect, how does that propagate through $f_k(\Theta)$ into the UWB distance loss?

- **Concept: L-BFGS Optimization**
  - **Why needed here:** The paper uses L-BFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno) for refinement. This is a quasi-Newton method that approximates the Hessian matrix. It is chosen here because it converges fast (few iterations) and handles the smoothness constraints well, which is vital for near-real-time processing.
  - **Quick check question:** Why would a gradient descent method with a fixed learning rate potentially fail here compared to L-BFGS with line search?

## Architecture Onboarding

- **Component map:** Inputs (6x IMU + UWB) -> SSMs (J/R/V/C) -> Raw Joint Angles -> Physics Optimizer -> Valid SMPL Poses -> Initial Position Optimizer (solve $T_{12}^0$) -> Trajectory Optimizer (refine $T^1, T^2$)

- **Critical path:** The **Trajectory Optimizer** is the critical bridge. It takes the pose from the SSM (which is relative/drifted) and the distances from UWB (which are absolute but noisy) and fuses them. If this component fails, the users will appear to "drift" apart or overlap incorrectly.

- **Design tradeoffs:**
  - **Latency vs. Accuracy:** The optimization loop adds computational overhead (2.04s for 30s sequence). A pure feed-forward network would be faster but drift significantly.
  - **Sensor Count:** The paper uses 6 sensors/person. Reducing this (e.g., to 3) would likely break the optimization as the FK mapping becomes too ambiguous to satisfy distance constraints.

- **Failure signatures:**
  - **"Rubber banding":** Avatars snapping towards/away from each other abruptly (indicates UWB noise spikes overwhelming the smoothness regularization).
  - **Frozen relative pose:** Users moving independently but locked at a fixed distance (optimizer stuck in local minimum of distance loss).
  - **Foot Sliding:** Explicitly mentioned in the paper as a limitation of the trajectory optimization physics.

- **First 3 experiments:**
  1. **UWB Noise Stress Test:** Synthetically increase the noise/std deviation of the "between-person" distances in the dataset to find the breaking point where the optimizer fails to converge.
  2. **Ablation on Sequence Length:** Vary the window size $N$ of the SSM input to determine the minimum history required for stable initial pose estimation before the physics optimizer kicks in.
  3. **Multi-User Scaling:** Replicate the "N people" experiment (Table 3) but introduce "failure" in one user's UWB to see if the group optimization degrades gracefully or corrupts the entire group's trajectory.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the computational overhead of the optimization-based inference be reduced to enable real-time performance on resource-constrained or mobile devices?
- Basis in paper: [explicit] Section 7 notes that optimization introduces overhead (2.04s for 30s of motion), which limits deployment on resource-constrained hardware.
- Why unresolved: The current L-BFGS optimizer, while accurate, is iterative and computationally heavier than pure feed-forward networks, making real-time "in the wild" mobile capture difficult.
- What evidence would resolve it: Demonstration of a real-time variant (e.g., using learned optimizations or hardware acceleration) that maintains trajectory accuracy with significantly reduced latency.

### Open Question 2
- Question: Can body shape variation be estimated from sparse IMU and UWB data without compromising pose accuracy?
- Basis in paper: [explicit] Section 7 states the method assumes a mean body shape and does not account for inter-individual shape variation.
- Why unresolved: Variations in body shape affect the precise locations of sensors on the body, which influences the interpretation of UWB distances and kinematic chains.
- What evidence would resolve it: Successful integration of a shape parameterization module (e.g., SMPL shape parameters) that improves sensor-to-joint mapping and reduces translation errors for diverse body types.

### Open Question 3
- Question: Can Non-Line-of-Sight (NLOS) UWB noise be effectively mitigated to improve multi-person tracking accuracy in dense interactions?
- Basis in paper: [explicit] Section 7 identifies UWB noise from signal obstruction as a significant challenge, particularly for between-person measurements (15 cm RMSE).
- Why unresolved: While the method fuses data, it does not explicitly model or correct for the physics of signal obstruction caused by human bodies during close interaction.
- What evidence would resolve it: Evaluation of an NLOS-aware signal processing module or learning-based error correction that significantly reduces the RMSE of between-person distance measurements during occlusion.

### Open Question 4
- Question: How can the trajectory optimization be modified to explicitly prevent foot sliding artifacts?
- Basis in paper: [explicit] Section 7 acknowledges that the method does not explicitly mitigate foot sliding, which can arise from the trajectory optimization step.
- Why unresolved: The trajectory optimizer prioritizes aligning global paths with UWB distances, potentially overriding physical contact constraints if not carefully balanced.
- What evidence would resolve it: A modified optimization loss function that includes foot contact constraints, resulting in visual fidelity (no sliding) while maintaining global trajectory accuracy.

## Limitations
- **Computational Overhead:** Optimization-based inference introduces 2.04s overhead for 30s sequences, limiting real-time mobile deployment.
- **Shape Variation:** Method assumes mean body shape and does not account for inter-individual shape variation, potentially affecting sensor-to-joint mapping.
- **Foot Sliding:** Trajectory optimization cannot enforce ground contact constraints, leading to foot sliding artifacts.

## Confidence

- **High Confidence:** The claim that GIP improves multi-person pose and global translation estimation over purely inertial methods (UIP) is strongly supported by quantitative results on both synthetic (InterHuman) and real-world (GIP-DB) datasets. The ablation study demonstrating the necessity of the two-step optimization (Initial Position + Trajectory) is also convincing.
- **Medium Confidence:** The claim that Structured State-Space Models (S4) provide superior temporal context for pose estimation is supported by the ablation study (Table 4), but this is based on a single comparison with LSTMs on a synthesized dataset. More diverse temporal modeling comparisons would strengthen this claim.
- **Medium Confidence:** The claim of "up to 72% reduction" in distance error is specific and backed by Table 2, but this is an aggregate result across varying conditions. The performance degradation with increased UWB noise is shown, but the exact failure threshold is not tested.

## Next Checks
1. **UWB Noise Stress Test:** Synthetically increase the noise/std deviation of the "between-person" distances in the InterHuman dataset to find the breaking point where the optimizer fails to converge. This will validate the method's robustness to real-world UWB variability.
2. **Multi-User Failure Mode Analysis:** Replicate the "N people" experiment (Table 3) but introduce "failure" in one user's UWB signal to see if the group optimization degrades gracefully or corrupts the entire group's trajectory. This will test the method's robustness to partial sensor failure.
3. **Long-Term Drift Validation:** Extend the GIP-DB evaluation to longer sequences (e.g., 60-120 seconds) to assess the cumulative effect of UWB noise and optimization errors on long-term trajectory accuracy. This will validate the method's practical utility for extended tracking sessions.