---
ver: rpa2
title: Application of Generative Adversarial Network (GAN) for Synthetic Training
  Data Creation to improve performance of ANN Classifier for extracting Built-Up pixels
  from Landsat Satellite Imagery
arxiv_id: '2501.19283'
source_url: https://arxiv.org/abs/2501.19283
tags:
- pixels
- built-up
- original
- data
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of insufficient high-quality
  training data for pixel-based land use classification using low-resolution Landsat
  imagery. To overcome this limitation, the authors propose a generative adversarial
  network (GAN) to create synthetic built-up pixels that match the distribution of
  original training data.
---

# Application of Generative Adversarial Network (GAN) for Synthetic Training Data Creation to improve performance of ANN Classifier for extracting Built-Up pixels from Landsat Satellite Imagery

## Quick Facts
- **arXiv ID**: 2501.19283
- **Source URL**: https://arxiv.org/abs/2501.19283
- **Reference count**: 0
- **Primary result**: GAN-generated synthetic pixels significantly improve ANN classifier performance for built-up pixel detection in Landsat imagery

## Executive Summary
This study addresses the challenge of insufficient high-quality training data for pixel-based land use classification using low-resolution Landsat imagery. To overcome this limitation, the authors propose a generative adversarial network (GAN) to create synthetic built-up pixels that match the distribution of original training data. The GAN architecture, consisting of a generator and discriminator with 4-layer neural networks, produces 300 synthetic built-up pixels from an original set of 100. The validity of the generated pixels is confirmed through Kolmogorov-Smirnov tests for marginal distributions and Ball Divergence tests for joint distributions across all spectral bands. These synthetic pixels are then incrementally added to the original training set to train an artificial neural network (ANN) classifier. The results demonstrate a significant improvement in classification performance, with overall accuracy increasing from 0.9331 to 0.9983 and Cohen's kappa coefficient rising from 0.8277 to 0.9958.

## Method Summary
The methodology employs a 4-layer GAN (generator and discriminator) trained on 100 pure built-up pixels from Landsat7 ETM+ imagery to generate synthetic samples. The generated pixels undergo validation through non-parametric statistical tests (KS and Ball Divergence) to ensure distributional fidelity. An ANN classifier with a single hidden layer (2 nodes) is then trained incrementally with the original and synthetic data using grid search and 10-fold cross-validation with L2 regularization. The approach is tested on a 7000-pixel dataset (2000 built-up, 5000 non-built-up) to evaluate classification performance improvements.

## Key Results
- Overall accuracy improves from 0.9331 to 0.9983 with synthetic data augmentation
- Cohen's kappa coefficient increases from 0.8277 to 0.9958
- All classification metrics (sensitivity, specificity, PPV, NPV) show progressive improvement as synthetic pixels are incrementally added

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: GAN-generated synthetic pixels can substitute for scarce real training data when distributional fidelity is maintained.
- **Mechanism**: The generator learns to map uniform noise to the data space such that output samples become statistically indistinguishable from real built-up pixels across all spectral bands. The discriminator's failure to distinguish generated from real samples indicates the generator has captured the underlying data distribution.
- **Core assumption**: The original training samples (100 built-up pixels) are sufficiently representative of the true built-up pixel distribution.
- **Evidence anchors**:
  - [abstract] "generate synthetic data having the same distribution as the sample data with which it is trained"
  - [section 3] GAN objective defined as minimax game with value function V(G,D) optimizing log probabilities
  - [corpus] TAEGAN paper confirms GANs remain competitive for synthetic tabular data generation (FMR=0.635)
- **Break condition**: If original training samples are biased or non-representative, the generator will amplify rather than correct this bias.

### Mechanism 2
- **Claim**: Incremental addition of validated synthetic data improves ANN classifier generalization.
- **Mechanism**: Synthetic samples expand the training distribution's coverage, reducing overfitting to the small original set. The ANN encounters more variation during training, leading to better decision boundaries.
- **Core assumption**: Generated samples maintain marginal and joint distributional equivalence with original data.
- **Evidence anchors**:
  - [section 4] "performance of the ANN model has steadily improves with the inclusion of generated set" — accuracy: 0.9331→0.9983, kappa: 0.8277→0.9958
  - [table 3] Progressive improvement across all metrics (sensitivity, specificity, PPV, NPV) as 100→200→300 synthetic pixels added
  - [corpus] GAN-augmented brain tumor classification study shows similar pattern with proportional synthetic data ratios
- **Break condition**: If synthetic samples drift from the true distribution (mode collapse), classifier performance may degrade or plateau.

### Mechanism 3
- **Claim**: Non-parametric statistical tests provide a quality gate for synthetic data before downstream use.
- **Mechanism**: KS test validates marginal distributions per band; Ball Divergence test validates multivariate joint distributions. High p-values (>0.05) indicate generated and original samples are statistically indistinguishable.
- **Core assumption**: Statistical indistinguishability on available samples implies the generator has learned the true data-generating process.
- **Evidence anchors**:
  - [section 4, table 1] KS test p-values range 0.1545–0.9062 across all bands and generated sets
  - [section 4, table 2] Ball Divergence p-values: 0.35, 0.54, 0.23 for three generated sets
  - [corpus] No direct corpus evidence for this specific validation approach in satellite imagery
- **Break condition**: Statistical tests on small samples (n=100) may have insufficient power to detect meaningful distributional differences.

## Foundational Learning

- **Concept: Generative Adversarial Network (GAN) minimax objective**
  - Why needed here: Understanding why generator and discriminator improve through adversarial training, not cooperative training
  - Quick check question: If the discriminator achieves 50% accuracy on real vs. generated samples, what does this indicate about the generator?

- **Concept: Non-parametric two-sample testing (KS test, Ball Divergence)**
  - Why needed here: Validating synthetic data quality without assuming Gaussian distributions for spectral bands
  - Quick check question: Why use non-parametric tests rather than comparing means and variances directly?

- **Concept: L2 regularization (weight decay) in neural networks**
  - Why needed here: Understanding why λ varied (0.1–0.4) across training configurations and its role in preventing overfitting
  - Quick check question: What happens to model weights when λ is too large versus too small?

## Architecture Onboarding

- **Component map**:
  - Generator: 100→100→100→6 nodes, Sigmoid→ReLU→ReLU activations, input: uniform noise z∈[-1,1]⁵⁰
  - Discriminator: 6→100→100→1 node, same activation pattern, input: 6-band pixel vectors
  - ANN Classifier: 1 hidden layer (2 nodes), output: built-up vs. non-built-up, L2 regularization

- **Critical path**:
  1. Curate pure training pixels (100 built-up, verified via Google Earth Engine)
  2. Train GAN until discriminator/generator reach equilibrium
  3. Generate synthetic samples, validate via KS + Ball Divergence (p>0.05 required)
  4. Incrementally augment training set, retrain ANN with grid search + 10-fold CV

- **Design tradeoffs**:
  - Simple 4-layer GAN chosen over VAE/Diffusion for computational efficiency on low-dimensional data (6 features)
  - Single hidden layer in ANN justified by universal approximation theorem, but may limit complexity
  - Assumption: Small generator capacity sufficient for 6-dimensional spectral space

- **Failure signatures**:
  - KS/Ball Divergence p-values <0.05: generator has not converged or mode collapse
  - Classifier accuracy plateaus or degrades: synthetic data introducing distributional drift
  - High variance in cross-validation folds: insufficient training data even with augmentation

- **First 3 experiments**:
  1. Replicate with original 100 built-up pixels only — establish baseline accuracy (~0.93 expected per paper)
  2. Train GAN, generate 100 synthetic pixels, run KS test per band — confirm p>0.05 before proceeding
  3. Add synthetic pixels incrementally (100, 200, 300), tracking accuracy/kappa at each step — expect monotonic improvement

## Open Questions the Paper Calls Out
- The authors state that "multi-spectral Landsat7 data has been used but the same idea could be applied to other types of satellite images as well."
- The authors note that "any other generative models (like VAE, Diffusion models etc.) could also be developed for the same purpose" and suggest training large networks might be computationally expensive.

## Limitations
- Small sample size (100 built-up pixels) for GAN training may limit generator's ability to capture full data distribution
- Critical GAN hyperparameters (epochs, batch size, learning rate, optimizer settings) are unspecified
- ANN architecture with only 2 hidden nodes may be overly simplistic for complex spectral relationships

## Confidence
- **GAN architecture & training**: Medium — 4-layer design is justified but hyperparameters are unspecified
- **Synthetic data validation**: Medium — KS and Ball Divergence tests are appropriate but may lack power with n=100 samples
- **Performance improvements**: High — accuracy gains are substantial and clearly demonstrated through incremental synthetic data addition

## Next Checks
1. Test GAN robustness by varying the number of original training pixels (25, 50, 100) to establish minimum viable dataset size
2. Compare ANN performance with alternative architectures (4, 8, 16 hidden nodes) to verify the 2-node design is optimal
3. Conduct cross-site validation using Landsat data from different geographic regions to assess generalizability of the synthetic data generation approach