---
ver: rpa2
title: Optimal Best Arm Identification with Post-Action Context
arxiv_id: '2502.03061'
source_url: https://arxiv.org/abs/2502.03061
tags:
- context
- problem
- best
- optimal
- identification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a new best arm identification (BAI) problem
  in stochastic multi-armed bandits where the learner receives additional post-action
  context alongside rewards. Two settings are analyzed: non-separator (reward depends
  on both action and context) and separator (reward depends only on context).'
---

# Optimal Best Arm Identification with Post-Action Context

## Quick Facts
- arXiv ID: 2502.03061
- Source URL: https://arxiv.org/abs/2502.03061
- Reference count: 40
- Primary result: Introduces BAI problem with post-action context; proposes optimal algorithms achieving lower bounds with orders-of-magnitude improvement in stopping times.

## Executive Summary
This paper introduces a new best arm identification problem in stochastic multi-armed bandits where the learner receives additional post-action context alongside rewards. Two settings are analyzed: non-separator (reward depends on both action and context) and separator (reward depends only on context). For both cases, instance-dependent lower bounds on sample complexity are derived and algorithms achieving optimal asymptotic sample complexity are proposed. The non-separator algorithm extends track-and-stop with D-tracking, while the separator algorithm introduces G-tracking, which directly tracks context frequencies using the geometry of the context space. Experiments show significant improvements over state-of-the-art methods that ignore post-action context, with stopping times reduced by orders of magnitude in some cases.

## Method Summary
The paper proposes two algorithms for best arm identification with post-action context. For the non-separator setting, Non-Separator Track-and-Stop (NSTS) extends the classical track-and-stop framework by modifying the D-tracking rule to optimize over the joint distribution of context and reward. For the separator setting, Separator Track-and-Stop (STS) introduces a novel G-tracking rule that directly tracks context frequencies using the convex geometry of the context space. Both algorithms use Generalized Likelihood Ratio (GLR) stopping rules with mixture martingale thresholds to achieve δ-correctness.

## Key Results
- Derived instance-dependent lower bounds on sample complexity for both separator and non-separator settings
- Proved NSTS achieves optimal sample complexity for non-separator case
- Introduced G-tracking rule for separator case that achieves optimal sample complexity
- Experimental results show stopping times reduced by orders of magnitude compared to baseline methods
- Demonstrated significant improvements across various random instances and specific problem instances

## Why This Works (Mechanism)

### Mechanism 1: Geometry-based Policy Tracking (G-Tracking)
In the separator setting, tracking the frequency of contexts rather than actions yields optimal sample complexity by allowing the learner to gather specific information through suboptimal arm pulls. The algorithm maps arms to a policy space defined as the convex hull of context probability vectors and projects current context frequency onto this hull to find the "policy" pushing observed context frequency toward optimal target.

### Mechanism 2: Extended Track-and-Stop for Mixed Distributions
Standard BAI fails or is suboptimal when rewards are mixtures of distributions due to context. The Non-Separator Track-and-Stop algorithm adapts D-tracking to minimize a complexity term involving KL divergence between joint distributions (P(Z,Y|X)), optimizing arm pull allocation based on distinguishing the best arm using mixed signals.

### Mechanism 3: Information Acceleration via Intermediate Feedback
Leveraging intermediate feedback (post-action context) significantly reduces sample complexity compared to waiting for final reward alone, particularly when contexts provide high-information proxies for the reward. The learner utilizes the correlation between context Z and reward Y to update beliefs about arm quality much faster.

## Foundational Learning

- **Multi-Armed Bandits (MAB) & Best Arm Identification (BAI)**: Base problem class distinguishing between regret minimization (learning while earning) and BAI (pure exploration to find best arm with confidence δ). Quick check: Why might an algorithm designed for BAI pull a "bad" arm more often than a "good" arm in specific contexts?

- **Track-and-Stop Algorithms & D-Tracking**: Baseline framework where D-tracking tracks proportion of arm pulls to match optimal theoretical allocation. Quick check: How does D-tracking decide which arm to pull next if an arm is "under-sampled"?

- **Convex Geometry (Convex Hull)**: Essential for separator setting where algorithm treats set of possible context distributions as geometric space to find sampling path. Quick check: If you have 3 arms generating context probabilities A₁, A₂, A₃, how does the convex hull help generate a target context frequency that isn't exactly A₁, A₂, or A₃?

## Architecture Onboarding

- **Component map**: Context Probability Matrix A -> Action X_t -> Observes (Z_t, Y_t) -> Updates Empirical Means -> Solves Optimization for w* -> Selects Action via Tracking -> Stopping decision

- **Critical path**: 1) Initialization: Pull arms until every action-context pair has at least one sample; 2) Estimation: Compute empirical means and GLR statistic; 3) Optimization: Solve max-min optimization to find optimal weights; 4) Tracking: Select next action based on D-tracking or G-tracking; 5) Stopping: Check if GLR statistic exceeds threshold

- **Design tradeoffs**: Known vs. Unknown A (paper assumes known, unknown makes optimization non-convex); Separator vs. Non-Separator (Separator is more specialized but potentially faster, Non-Separator is more general but less aggressive)

- **Failure signatures**: Non-termination if optimization fails or GLR threshold is too conservative; High variance in context if A is near-degenerate

- **First 3 experiments**: 1) Baseline Comparison: Run NSTS vs. standard Track-and-Stop on random instances to verify improvement; 2) Separator Geometry: Replicate specific instance to visualize STS reducing L₂ distance faster; 3) Robustness Check: Inject noise into matrix A and observe degradation of δ-correctness or stopping time

## Open Questions the Paper Calls Out

- Can we develop a computationally efficient algorithm for BAI with post-action context when the context probability matrix A is unknown? The optimization becomes non-convex when A is unknown, rendering efficient algorithm design challenging.

- Can the G-tracking rule be extended to handle continuous or high-dimensional context spaces? The algorithm's efficiency degrades as context dimension k grows due to exponential complexity in computing convex hull intersections.

- What are the optimal sample complexity bounds and algorithms for the fixed-budget setting with post-action context? The paper focuses on fixed-confidence setting, while fixed-budget BAI requires different analysis techniques.

## Limitations

- Assumes known context probability matrix A, which may not hold in practical applications
- Restrictive assumption of Gaussian rewards with unit variance (extension to other distributions not empirically validated)
- GLR threshold computation relies on mixing martingale properties that may not hold under all data-generating processes

## Confidence

- **High Confidence**: Core theoretical framework connecting post-action context to information gain is sound; lower bound derivations and structural differences are mathematically rigorous
- **Medium Confidence**: Extension of Track-and-Stop to non-separator setting via D-tracking is well-grounded but needs more extensive validation; separator algorithm's geometric approach is novel but relies heavily on known-A assumption
- **Low Confidence**: Experimental claims of "orders of magnitude" improvement are based on limited synthetic instances; lacks comparison against bandit algorithms that could learn A online or tests of robustness to model misspecification

## Next Checks

1. **Robustness to Unknown A**: Implement online learning approach from Appendix G and test performance degradation as A estimate becomes noisier, measuring stopping time inflation and error rate increases

2. **Cross-Distribution Validation**: Test algorithms beyond Gaussian rewards with unit variance using Bernoulli rewards and heavy-tailed distributions to assess whether KL-divergence based analysis remains valid and algorithms remain δ-correct

3. **Context Informativeness Threshold**: Systematically vary correlation between context Z and reward Y (e.g., by adding noise to separator assumption) to identify minimum context informativeness required for proposed algorithms to outperform standard Track-and-Stop