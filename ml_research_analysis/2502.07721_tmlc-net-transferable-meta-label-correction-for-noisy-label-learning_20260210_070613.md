---
ver: rpa2
title: 'TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning'
arxiv_id: '2502.07721'
source_url: https://arxiv.org/abs/2502.07721
tags:
- noise
- tmlc-net
- learning
- label
- noisy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TMLC-Net introduces a transferable meta-learning approach for correcting
  noisy labels in deep learning. The method addresses the challenge of label noise
  in real-world datasets by learning a general-purpose correction strategy that can
  be applied across different datasets and model architectures without extensive retraining.
---

# TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning

## Quick Facts
- arXiv ID: 2502.07721
- Source URL: https://arxiv.org/abs/2502.07721
- Authors: Mengyang Li
- Reference count: 40
- Primary result: Achieves 85.2% accuracy on CIFAR-10 and 60.3% on CIFAR-100 with 40% symmetric noise

## Executive Summary
TMLC-Net introduces a transferable meta-learning approach for correcting noisy labels in deep learning models. The method addresses the challenge of label noise in real-world datasets by learning a general-purpose correction strategy that can be applied across different datasets and model architectures without extensive retraining. By combining normalized noise perception, time-series encoding, and subclass decoding, TMLC-Net consistently outperforms state-of-the-art methods on benchmark datasets with various noise types and levels.

## Method Summary
TMLC-Net employs a meta-learning framework to correct noisy labels by learning transferable correction strategies. The method consists of three core components: Normalized Noise Perception for handling distribution shifts, Time-Series Encoding using LSTM to model temporal evolution of sample statistics, and Subclass Decoding to predict corrected label distributions. The approach is designed to work across different datasets and model architectures without requiring extensive retraining, making it particularly suitable for real-world applications where label noise is prevalent.

## Key Results
- Achieves 85.2% accuracy on CIFAR-10 with 40% symmetric noise, surpassing baselines
- Achieves 60.3% accuracy on CIFAR-100 with 40% symmetric noise
- Demonstrates strong transferability across different datasets and noise conditions
- Shows favorable trade-off between performance improvement and training overhead

## Why This Works (Mechanism)
TMLC-Net works by learning a transferable correction strategy through meta-learning that can adapt to different noise patterns and datasets. The method captures temporal patterns in label noise through time-series encoding, allowing it to model the evolution of sample statistics over training iterations. The normalized noise perception component handles distribution shifts effectively, while subclass decoding provides fine-grained label correction. The meta-learning framework enables the model to learn general correction patterns rather than dataset-specific rules, facilitating transfer to new domains.

## Foundational Learning

**Meta-learning**: Why needed - enables learning of general correction strategies applicable across datasets; Quick check - verify that the meta-learned parameters improve performance on held-out datasets

**Time-series analysis with LSTM**: Why needed - captures temporal evolution of label noise patterns; Quick check - ensure LSTM captures meaningful temporal dependencies in sample statistics

**Distribution shift handling**: Why needed - real-world datasets often have varying noise distributions; Quick check - test performance across different noise levels and types

**Subclass decomposition**: Why needed - allows fine-grained label correction beyond coarse class-level adjustments; Quick check - verify that subclass-level corrections improve overall accuracy

## Architecture Onboarding

**Component map**: Raw data -> Normalized Noise Perception -> Time-Series Encoding (LSTM) -> Subclass Decoding -> Corrected labels

**Critical path**: The core pipeline involves processing input data through normalized noise perception to identify noise patterns, then using time-series encoding to model their temporal evolution, followed by subclass decoding to predict corrected label distributions.

**Design tradeoffs**: The method trades increased model complexity (LSTM and additional decoding layers) for improved generalization and transferability. The meta-learning approach requires more initial training but reduces the need for dataset-specific fine-tuning.

**Failure signatures**: Performance degradation may occur when applied to datasets with noise patterns significantly different from training conditions, or when the temporal evolution of noise is highly irregular and not well-captured by LSTM.

**First experiments**:
1. Test baseline performance on CIFAR-10 with varying noise levels to establish performance bounds
2. Evaluate component ablation to isolate contributions of normalized noise perception, time-series encoding, and subclass decoding
3. Assess transferability by applying the trained model to a different dataset (e.g., Clothing1M) without fine-tuning

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability across extremely diverse domains beyond standard vision benchmarks remains uncertain
- Performance may degrade on datasets with complex noise patterns not captured in training
- Limited validation on asymmetric noise patterns and other benchmark datasets
- Computational overhead analysis lacks detailed breakdown across different hardware configurations

## Confidence

High confidence in the technical feasibility of the proposed components (Normalized Noise Perception, Time-Series Encoding, Subclass Decoding) based on the described methodology and experimental setup.

Medium confidence in the reported performance improvements, as they are benchmarked on standard datasets but may not fully represent real-world complexity.

Medium confidence in the transferability claims, given the limited scope of experimental validation across different noise types and dataset distributions.

## Next Checks

1. Conduct experiments on asymmetric noise patterns and datasets outside the standard vision benchmarks to assess the robustness of TMLC-Net's performance claims.

2. Perform ablation studies to isolate the contribution of each component (Normalized Noise Perception, Time-Series Encoding, Subclass Decoding) to the overall effectiveness of the method.

3. Evaluate the computational overhead and scalability of TMLC-Net across different hardware configurations and model architectures to provide a comprehensive analysis of its practical applicability.