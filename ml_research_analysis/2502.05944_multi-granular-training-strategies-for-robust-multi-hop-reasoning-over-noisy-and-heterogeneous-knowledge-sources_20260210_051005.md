---
ver: rpa2
title: Multi-granular Training Strategies for Robust Multi-hop Reasoning Over Noisy
  and Heterogeneous Knowledge Sources
arxiv_id: '2502.05944'
source_url: https://arxiv.org/abs/2502.05944
tags:
- reasoning
- knowledge
- amkor
- multi-hop
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AMKOR, a generative framework for multi-hop
  question answering that dynamically integrates parametric and retrieved knowledge
  while exploring reasoning trajectories using probabilistic beam reasoning. AMKOR
  employs a multi-granular learning strategy optimizing both local reasoning steps
  and global answer accuracy.
---

# Multi-granular Training Strategies for Robust Multi-hop Reasoning Over Noisy and Heterogeneous Knowledge Sources

## Quick Facts
- arXiv ID: 2502.05944
- Source URL: https://arxiv.org/abs/2502.05944
- Reference count: 36
- Key outcome: AMKOR achieves SOTA performance on multi-hop QA, improving average F1 by 2.5% over baselines

## Executive Summary
This paper introduces AMKOR, a generative framework for multi-hop question answering that dynamically integrates parametric and retrieved knowledge while exploring reasoning trajectories using probabilistic beam reasoning. AMKOR employs a multi-granular learning strategy optimizing both local reasoning steps and global answer accuracy. Evaluated on four multi-hop QA datasets including HotpotQA and MuSiQue, AMKOR achieves state-of-the-art performance, improving average F1 scores by 2.5% over baseline methods. It demonstrates superior robustness to noisy knowledge, scalability, and effectiveness on complex multi-hop reasoning tasks. The framework effectively balances reasoning quality and computational efficiency through dynamic knowledge fusion and probabilistic trajectory exploration.

## Method Summary
AMKOR is a three-component framework for multi-hop question answering. First, it uses multi-source knowledge fusion via scaled dot-product attention to combine parametric LLM knowledge with retrieved external snippets. Second, it employs probabilistic beam reasoning to explore multiple reasoning trajectories, selecting the optimal path through joint probability maximization. Third, it uses multi-granular loss functions that simultaneously optimize local reasoning step accuracy and global answer consistency. The framework is trained end-to-end using SGD over the combined loss function, with inference performed using beam search. It's evaluated on four benchmark datasets (HotpotQA, 2WikiMQA, MuSiQue, Bamboogle) using token-level F1 as the primary metric.

## Key Results
- Achieves SOTA F1 scores across all four benchmark datasets
- Improves average F1 by 2.5% over baseline methods
- Demonstrates superior robustness to noisy knowledge (maintains performance up to 40% irrelevant retrievals)
- Shows effective scalability to complex 2-4 hop reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Scaled dot-product attention fusion of parametric and retrieved knowledge reduces knowledge conflict errors.
- Mechanism: At each reasoning step $t_i$, embeddings from the LLM's parametric knowledge ($h_{param}$) and retrieved snippets ($\{h_k\}_{k=1}^s$) are merged via attention: $\text{Fuse}(h_{param}, \{h_k\}) = \text{Softmax}(QK^\top / \sqrt{d})V$. This allows the model to dynamically weight source relevance per step rather than treating all sources uniformly.
- Core assumption: Attention weights correlate with knowledge reliability; the model can learn to downweight noisy or contradictory sources.
- Evidence anchors:
  - [abstract] "dynamically fuse parametric and retrieved knowledge"
  - [Section 3.2] Equations (2)-(3) define the fusion function explicitly.
  - [corpus] ParallaxRAG (arXiv:2510.15552) similarly addresses noisy path exploration in KG-RAG, supporting the premise that structured fusion aids multi-hop tasks.
- Break condition: If retrieved sources are systematically biased or parametric knowledge is outdated, attention may amplify incorrect signals rather than suppress them.

### Mechanism 2
- Claim: Probabilistic beam reasoning mitigates cascading errors by maintaining multiple trajectory hypotheses.
- Mechanism: Instead of committing to a single greedy path, the model generates $b$ candidate steps per hop with probabilities $P(t_i^j | t_{<i}, q, K)$. The optimal trajectory maximizes the joint probability $\prod_{i=1}^m P(t_i | t_{<i}, q, K)$. If one path fails, alternatives remain viable.
- Core assumption: The correct reasoning path has higher joint probability than incorrect alternatives; beam width captures sufficient diversity.
- Evidence anchors:
  - [abstract] "exploring reasoning trajectories using probabilistic beam reasoning"
  - [Section 4.3, Table 2] Ablation shows removing probabilistic beam reasoning causes the largest F1 drop (37.4 → 30.9 on MuSiQue).
  - [corpus] HydraRAG (arXiv:2505.17464) and related RAG works similarly emphasize multi-hop trajectory handling, though most lack explicit probabilistic aggregation.
- Break condition: If all $b$ candidates share a common early error, or if computational budget forces narrow beams, cascading failures can still propagate.

### Mechanism 3
- Claim: Multi-granular loss functions improve both intermediate step accuracy and final answer consistency.
- Mechanism: The total loss $L = \lambda_{local} L_{local} + \lambda_{global} L_{global}$ combines local step-wise cross-entropy ($L_{local} = -\frac{1}{m} \sum_{i=1}^m \log P(t_i | t_{<i}, q, K)$) with global answer likelihood ($L_{global} = -\log P(a | T, q, K)$). This creates supervision pressure at each hop, not just the endpoint.
- Core assumption: Local supervision signals are reliable and align with correct global reasoning; gradient flow balances both objectives.
- Evidence anchors:
  - [abstract] "optimizing both local reasoning steps and global answer accuracy using a multi-granular learning strategy"
  - [Section 3.4] Equations (6)-(8) formalize the loss decomposition.
  - [Section 4.3, Table 2] Removing multi-granular loss drops F1 from 37.4 to 32.8 on MuSiQue.
  - [corpus] Limited explicit multi-granular training references in neighbors; this appears to be a relatively novel contribution in the RAG space.
- Break condition: If local steps are mislabeled or if $\lambda$ hyperparameters are poorly tuned, the model may optimize locally correct but globally inconsistent paths.

## Foundational Learning

- Concept: Scaled dot-product attention
  - Why needed here: The knowledge fusion module uses this to combine heterogeneous sources. Without understanding attention weights and softmax normalization, the fusion dynamics are opaque.
  - Quick check question: Given query $Q$ and keys $K$, what does $\text{Softmax}(QK^\top / \sqrt{d})$ compute, and why divide by $\sqrt{d}$?

- Concept: Beam search in sequence generation
  - Why needed here: Probabilistic beam reasoning extends standard beam search to multi-hop trajectories. Understanding candidate expansion and pruning is essential.
  - Quick check question: How does beam search differ from greedy decoding, and what happens to computational cost as beam width increases?

- Concept: Multi-task / multi-objective loss weighting
  - Why needed here: The multi-granular strategy requires balancing $L_{local}$ and $L_{global}$. Incorrect weighting can collapse one objective.
  - Quick check question: If $\lambda_{local} \gg \lambda_{global}$, what behavior would you expect during training?

## Architecture Onboarding

- Component map: Query $q$ → Retrieval → Fusion → Beam Reasoning (iterate $m$ hops) → Final answer $a$
- Critical path: The fusion layer feeds directly into each beam expansion step
- Design tradeoffs:
  - Beam width $b$: Higher values improve robustness but increase latency (Table 5 shows 1.2s latency with 2.3 avg retrievals)
  - Fusion mechanism: Attention is flexible but adds parameters; simpler concatenation + MLP would be faster but less expressive
  - Loss weighting $\lambda_{local}, \lambda_{global}$: Paper does not disclose values; tuning is dataset-dependent
- Failure signatures:
  - Knowledge omission (41.2% of errors on MuSiQue per Table 6): Retrieval fails to surface relevant evidence
  - Knowledge conflicts (35.4%): Fusion cannot resolve contradictions between parametric and retrieved sources
  - Reasoning inaccuracies (23.4%): Beam selects low-probability correct paths or hallucinates intermediate steps
- First 3 experiments:
  1. **Ablation replication**: Run AMKOR on MuSiQue with each component removed (fusion, beam, multi-granular loss) to verify the reported F1 drops (Table 2)
  2. **Noise injection test**: Replicate Table 7 by adding 20-40% irrelevant retrievals to HotpotQA; confirm degradation curve and compare against ProbTree baseline
  3. **Beam width sensitivity**: Sweep $b \in \{1, 3, 5, 10\}$ on a held-out split; plot F1 vs. latency to identify the operating point that matches the paper's 2.3 retrievals and 1.2s latency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the framework be adapted to maintain robustness in environments with extremely high noise levels that exceed the 40% threshold tested in the paper?
- Basis in paper: [Explicit] The conclusion explicitly states that "handling extremely noisy environments remain open areas for future work," noting that current robustness has limits.
- Why unresolved: The robustness analysis in Section 4.8 only evaluates performance up to 40% irrelevant retrieved knowledge; the model's behavior under more severe noise conditions is unknown.
- What evidence would resolve it: Experimental results on datasets injected with 50%+ noise levels or evaluations on naturally noisy, uncurated web data showing stable F1 scores.

### Open Question 2
- Question: What specific advancements in retrieval mechanisms are required to reduce the high rate of "knowledge omission" errors (41.2%) identified in the error analysis?
- Basis in paper: [Explicit] The discussion in Section 4.7 notes that "most errors arise from knowledge omission" and explicitly suggests that "improvements in retrieval mechanisms... could enhance AMKOR's performance."
- Why unresolved: The current retrieval component fails to surface necessary evidence in nearly half of the error cases, indicating a bottleneck in the multi-source integration pipeline that is not addressed by the reasoning modules.
- What evidence would resolve it: A comparative study integrating advanced sparse or dense retrieval methods demonstrating a statistically significant reduction in the "Knowledge Omission" error category.

### Open Question 3
- Question: Can the fusion strategy be refined to better resolve "knowledge conflicts" (35.4% of errors) without relying solely on probabilistic beam reasoning?
- Basis in paper: [Explicit] The conclusion lists "further reducing knowledge conflicts" as a specific open challenge, supported by the error analysis which identifies conflicts as the second largest source of failure.
- Why unresolved: While AMKOR uses dot-product attention for fusion (Section 3.2), the high frequency of conflict-related errors suggests this mechanism is insufficient for resolving contradictions between parametric and retrieved knowledge.
- What evidence would resolve it: An ablation study featuring an enhanced fusion mechanism (e.g., contrastive or explicitly contradiction-aware layers) that yields higher F1 scores on conflict-heavy subsets of MuSiQue or Bamboogle.

## Limitations

- Computational complexity scales multiplicatively with hop count and beam width, potentially limiting scalability to deeper reasoning tasks
- Claims about robustness to real-world noisy knowledge are based on synthetic random noise models rather than systematic biases
- Multi-granular loss weighting hyperparameters are not specified, leaving optimal configuration unclear

## Confidence

- **High**: Claims about achieving state-of-the-art F1 scores on benchmark datasets are well-supported by ablation studies showing significant drops when key components are removed
- **Medium**: The mechanism explaining how scaled dot-product attention reduces knowledge conflict errors is theoretically sound but relies on the assumption that attention weights reliably indicate source quality, which may not hold in practice
- **Medium**: Claims about computational efficiency are supported by reported latency figures, but the trade-off between beam width and performance could be more thoroughly explored across a wider parameter range

## Next Checks

1. **Real-world noise robustness**: Test AMKOR on a dataset with known systematic knowledge source biases (e.g., temporally outdated or culturally skewed sources) rather than synthetic random noise to validate claims about handling real-world noisy knowledge
2. **Scalability stress test**: Evaluate performance and computational cost on reasoning tasks requiring 6+ hops to identify the practical limits of the probabilistic beam reasoning approach and determine when it breaks down
3. **Hyperparameter sensitivity analysis**: Conduct a systematic sweep of λlocal and λglobal values across multiple datasets to establish guidelines for optimal multi-granular loss weighting in different reasoning scenarios