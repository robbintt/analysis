---
ver: rpa2
title: 'LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios'
arxiv_id: '2508.17692'
source_url: https://arxiv.org/abs/2508.17692
tags:
- agent
- reasoning
- arxiv
- agents
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides the first systematic classification of LLM-based
  agentic reasoning frameworks, decomposing them into single-agent, tool-based, and
  multi-agent methods. Using a unified formal language, it analyzes how these frameworks
  evolve reasoning processes across different scenarios including scientific discovery,
  healthcare, software engineering, and social simulation.
---

# LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios

## Quick Facts
- arXiv ID: 2508.17692
- Source URL: https://arxiv.org/abs/2508.17692
- Reference count: 40
- This survey provides the first systematic classification of LLM-based agentic reasoning frameworks, decomposing them into single-agent, tool-based, and multi-agent methods.

## Executive Summary
This survey systematically classifies LLM-based agentic reasoning frameworks using a unified formal language that decomposes them into single-agent, tool-based, and multi-agent methods. The authors analyze how these frameworks evolve reasoning processes across different scenarios including scientific discovery, healthcare, software engineering, and social simulation. Using a comprehensive taxonomy, the survey identifies key design patterns, application-specific adaptations, and evaluation strategies, offering a panoramic view of the field's strengths and challenges. The work serves as a comprehensive roadmap for understanding and advancing agentic reasoning systems while outlining future research directions focusing on scalability, open-ended learning, ethics, and explainable reasoning.

## Method Summary
The survey proposes a unified formal language and general algorithm (Algorithm 1) that models agentic reasoning as an iterative loop where an LLM selects actions from a defined space (reasoning, tool use, or reflection) to update an evolving context until a termination condition is met. The framework supports single-agent, tool-based, and multi-agent paradigms through a common mathematical structure. The methodology involves systematic literature review across multiple domains, classification of frameworks based on their reasoning mechanisms, and analysis of their application scenarios and evaluation strategies.

## Key Results
- Provides the first systematic classification of LLM-based agentic reasoning frameworks into single-agent, tool-based, and multi-agent categories
- Identifies three core mechanisms: persistent context accumulation, capability extension via tool integration, and structured self-improvement through reflection
- Analyzes application scenarios including scientific discovery, healthcare, software engineering, and social simulation
- Outlines key research directions focusing on scalability, open-ended learning, ethics, and explainable reasoning

## Why This Works (Mechanism)

### Mechanism 1: Persistent Context Accumulation
The survey proposes that agentic systems outperform standard LLMs by maintaining a persistent, evolving context ($C_k$) across iterative reasoning steps, rather than relying on single-shot inference. The system iterates through an action loop where outputs ($y_{k+1}$) are explicitly folded back into the context ($C_{k+1}$) via a context update action ($a'_k$). This accumulation allows the system to "remember" intermediate results and correct course.

### Mechanism 2: Capability Extension via Tool Integration
The survey suggests that agents overcome the intrinsic knowledge limitations (hallucinations, outdated knowledge) of base LLMs by offloading specific tasks to a defined toolkit ($T$). The reasoning framework selects a tool ($t_{k+1}$) from a toolkit and executes an action ($a_{tool}$). The result is treated as grounded truth and integrated into the agent's context, bypassing the need for the LLM to internally "know" the answer.

### Mechanism 3: Structured Self-Improvement (Reflection)
The survey identifies "reflection" as a critical mechanism where an agent analyzes its past trajectory to generate verbal summaries of failures, storing them in episodic memory for future correction. After an action, instead of simply appending the result, a specific reflection action ($a_{reflect}$) synthesizes a high-level summary (e.g., "Plan failed because X") which is prioritized in the context for the next iteration.

## Foundational Learning

- **Concept: Context Window Management**
  - **Why needed here:** The core algorithm relies entirely on the context ($C_k$) growing without exceeding the model's token limit. Understanding how to prune, summarize, or vectorize history is essential for long-horizon tasks.
  - **Quick check question:** If an agent runs for 50 steps, how does the system ensure the initial instruction remains visible in the context window?

- **Concept: Action Space Formulation**
  - **Why needed here:** The survey defines reasoning as selecting actions from a space $A = \{a_{reason}, a_{tool}, a_{reflect}\}$. One must understand how to constrain this space so the model doesn't choose invalid actions.
  - **Quick check question:** What is the difference between the action $a$ (producing an output) and the action $a'$ (updating the state), and why does the survey explicitly separate them?

- **Concept: Coordination Topologies**
  - **Why needed here:** Section 3.4 introduces Centralized vs. Decentralized vs. Hierarchical structures. Choosing the wrong structure can lead to bottlenecks (Centralized) or coordination failures (Decentralized).
  - **Quick check question:** In a Hierarchical multi-agent system, does information flow horizontally between peers or strictly vertically to a manager?

## Architecture Onboarding

- **Component map:** Context Manager ($C$) -> LLM Core -> Action Controller -> Tool Interface ($T$) -> Termination Checker ($Q$)
- **Critical path:**
  1. **Initialization:** $C_0 \leftarrow \text{Init}(P_U, P^*)$ (User query + Engineered Prompt)
  2. **Iteration:** Select Action $\to$ Execute Action (Reason/Tool/Reflect) $\to$ Update Context ($C_{k+1}$)
  3. **Termination:** Check Condition $Q$. If false, repeat.
- **Design tradeoffs:**
  - **Prompt Engineering vs. Self-Improvement:** Static prompts are cheap and fast but rigid; Self-Improvement is adaptive but computationally expensive and prone to instability.
  - **Tool Selection Strategy:** Autonomous selection is flexible but error-prone; Rule-based selection is reliable but brittle and hard to scale.
- **Failure signatures:**
  - **Infinite Loops:** The agent fails to trigger termination condition $Q$, repeating steps indefinitely.
  - **Tool Drift:** The agent starts using tools for tasks they weren't designed for, leading to syntax errors or nonsensical results.
  - **Context Distraction:** The context $C_k$ becomes cluttered with failed attempts, causing the model to ignore the original goal $g$.
- **First 3 experiments:**
  1. **Baseline Prompting:** Implement a single-agent with only "Role-Playing" prompt engineering to establish a baseline success rate for a specific task.
  2. **Tool Ablation:** Introduce a single tool (e.g., a calculator or search API) and compare "Autonomous Selection" vs. "Rule-Based Selection" to measure reliability gains vs. flexibility.
  3. **Multi-Agent Scalability:** Set up a simple Centralized 3-agent system vs. a Decentralized 3-agent system to observe communication overhead and task completion speed.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can agentic frameworks be designed to self-regulate and dynamically reconfigure their interaction topologies (e.g., switching between centralized and decentralized) during the execution of a single complex task?
- **Basis in paper:** Section 5.3 states that current adaptability is high-level, whereas future research should focus on a framework's ability to "self-regulate during the reasoning process for a single task" and "dynamically reconfigure the interaction topology."
- **Why unresolved:** Current frameworks largely employ static organizational architectures or only adjust collaboration patterns for different tasks, not dynamically within the micro-steps of a single reasoning process.
- **What evidence would resolve it:** The development of a framework that autonomously alters its agent communication graph in response to real-time reasoning bottlenecks, alongside metrics balancing resource efficiency against reasoning quality.

### Open Question 2
- **Question:** What architectures enable agents to autonomously generate and optimize their own tools dynamically rather than relying on static toolsets?
- **Basis in paper:** Section 5.2 argues for evolving agents from "users" to "creators" of knowledge and tools, specifically calling for the "ability to dynamically generate and optimize tools" to handle complex, zero-shot problems.
- **Why unresolved:** Most existing reasoning frameworks rely on fixed toolkits and predefined prompts, which constrains the agent's creativity and flexibility in novel environments.
- **What evidence would resolve it:** Systems that successfully write, debug, and integrate new API wrappers or utilities on the fly during a task, validated by benchmarks specifically designed to evaluate open-ended tool creation.

### Open Question 3
- **Question:** How can quantifiable, uncertainty-aware confidence estimation be implemented for tool invocation and introspective reasoning to ensure reliable deployment in critical fields?
- **Basis in paper:** Section 5.6 highlights the need to establish "quantifiable mechanisms for uncertainty-aware confidence estimation" and specifically notes the importance of "calibrating the agent's confidence during tool invocation."
- **Why unresolved:** Interactions with external environments are major sources of uncertainty, and current agents lack reliable internal mechanisms to align self-declared confidence with actual task ambiguity or tool reliability.
- **What evidence would resolve it:** A calibrated confidence scoring mechanism where high uncertainty correlates with specific failure modes (e.g., tool hallucination), prompting the agent to seek human clarification or alternative tools.

## Limitations
- The survey lacks empirical benchmarking to validate the proposed unified formal language against baseline LLMs or competing frameworks
- The theoretical framework is not accompanied by specific prompt templates or tool interface specifications needed for practical implementation
- The survey identifies evaluation challenges but does not provide concrete metrics or experimental results demonstrating the superiority of agentic approaches

## Confidence
- **High confidence** in the taxonomic contribution—the classification of frameworks into single-agent, tool-based, and multi-agent categories is methodologically sound and well-supported by the literature review
- **Medium confidence** in the proposed unified formal language—the mathematical formulation provides a coherent framework, but the absence of specific prompt templates and tool interface specifications limits practical reproducibility
- **Low confidence** in the evaluation strategies—the survey identifies evaluation challenges but does not provide concrete metrics or experimental results demonstrating the superiority of agentic approaches

## Next Checks
1. **Empirical Benchmarking**: Implement the unified formal language with specific prompt templates and evaluate performance across three representative scenarios (scientific discovery, healthcare, software engineering) against standard prompting baselines.
2. **Context Management Stress Test**: Systematically test context window limits by running agents through progressively longer reasoning chains, measuring degradation in performance and testing the effectiveness of proposed mitigation strategies (iterative optimization, reflection).
3. **Multi-Agent Coordination Comparison**: Compare Centralized, Decentralized, and Hierarchical coordination topologies on a standardized multi-agent task to quantify communication overhead, task completion speed, and error propagation patterns.