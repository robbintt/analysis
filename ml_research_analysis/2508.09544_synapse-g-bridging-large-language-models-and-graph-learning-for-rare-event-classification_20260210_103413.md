---
ver: rpa2
title: 'SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event
  Classification'
arxiv_id: '2508.09544'
source_url: https://arxiv.org/abs/2508.09544
tags:
- data
- positive
- seeds
- synthetic
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SYNAPSE-G, a pipeline for rare event classification
  using LLM-generated synthetic data combined with graph-based semi-supervised learning.
  The method addresses the cold-start problem by generating synthetic seeds, propagating
  labels via similarity graphs, and iteratively expanding labeled data.
---

# SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification

## Quick Facts
- arXiv ID: 2508.09544
- Source URL: https://arxiv.org/abs/2508.09544
- Reference count: 32
- Proposed SYNAPSE-G pipeline addresses rare event classification by combining LLM-generated synthetic seeds with graph-based label propagation

## Executive Summary
This paper introduces SYNAPSE-G, a novel pipeline that bridges large language models and graph learning to address the cold-start problem in rare event classification. The method generates synthetic labeled data using LLMs, constructs similarity graphs from LLM embeddings, and propagates labels through semi-supervised learning to discover rare positive instances. The approach is particularly valuable when labeled data is scarce, as it can identify rare events without requiring extensive manual annotation. Theoretical analysis provides precision and recall guarantees based on the validity and diversity of synthetic seeds.

## Method Summary
SYNAPSE-G addresses rare event classification by first generating synthetic labeled data using LLMs, then constructing a similarity graph from LLM embeddings of both synthetic and unlabeled data. The method uses label propagation to iteratively expand labeled data from synthetic seeds, identifying rare positive instances in the unlabeled pool. The pipeline involves three main steps: synthetic data generation via LLM prompts, graph construction using k-NN graphs based on SBERT embeddings, and semi-supervised learning through label propagation. The approach is designed to work when only a small fraction of data is labeled, making it particularly useful for discovering rare events that traditional supervised methods struggle to identify.

## Key Results
- With only 2.4% of MHS data labeled, SYNAPSE-G identifies 28.6% of true positives
- Outperforms baselines including nearest neighbor search and logistic regression
- Theoretical analysis shows precision and recall depend on validity and diversity of synthetic seeds
- Successfully demonstrates effectiveness on both SST2 and MHS datasets

## Why This Works (Mechanism)
The method leverages the ability of LLMs to generate synthetic examples of rare positive events, creating initial labeled seeds for the learning process. By constructing similarity graphs from LLM embeddings, the approach captures semantic relationships between instances, allowing label propagation to spread information from the synthetic seeds to similar unlabeled instances. The semi-supervised learning component iteratively expands the labeled set, effectively mining for rare events without requiring extensive manual annotation. The theoretical framework provides guarantees on precision and recall based on the quality of synthetic seeds, ensuring that the discovered events are likely to be true positives.

## Foundational Learning
- Graph-based semi-supervised learning: Why needed - Enables label propagation from few labeled seeds to large unlabeled datasets; Quick check - Verify k-NN graph construction maintains connected components
- LLM embedding similarity: Why needed - Captures semantic relationships for effective label propagation; Quick check - Measure cosine similarity distribution in k-NN graphs
- Synthetic data generation quality: Why needed - Directly impacts theoretical precision guarantees; Quick check - Calculate empirical validity rate of generated seeds

## Architecture Onboarding

Component map: LLM Generation -> Graph Construction -> Label Propagation -> Rare Event Mining

Critical path: Synthetic seeds are generated by LLM, embedded using SBERT, connected in k-NN graph, then labels are propagated through graph to identify rare positive instances in unlabeled data.

Design tradeoffs: The method trades computational complexity (O(nÂ²) for exact graph construction) for precision in label propagation. Using LSH for approximate nearest neighbors reduces complexity but may impact theoretical guarantees.

Failure signatures: Poor performance indicates either invalid synthetic seeds (LLM generation failure), disconnected graph components (embedding issues), or insufficient seed diversity (prompt engineering problems).

First experiments:
1. Generate synthetic seeds using different LLM prompts and measure resulting validity rates
2. Construct k-NN graphs with varying k values and analyze connectivity properties
3. Compare label propagation results using exact vs. LSH-approximated graphs

## Open Questions the Paper Calls Out

### Open Question 1
How do specific prompt engineering strategies influence the validity ($p$) and diversity ($h(S^+)$) parameters, and can they be optimized to stay above the theoretical precision threshold derived in the paper?

### Open Question 2
How does the violation of the "independent set" assumption (Assumption 1) in real-world LLM outputs degrade the theoretical guarantees of the label propagation algorithm?

### Open Question 3
To what extent does the approximation error from scalable graph construction methods (e.g., Locality Sensitive Hashing) impact the precision-recall trade-offs compared to the exact graphs analyzed theoretically?

### Open Question 4
Can the SYNAPSE-G pipeline be effectively adapted to multi-label or multi-class rare event scenarios without requiring the construction of independent graphs for every class?

## Limitations

- Theoretical guarantees rely heavily on assumptions about synthetic seed quality that aren't fully validated in practice
- Method's effectiveness appears to depend significantly on the quality of LLM-generated synthetic data, which isn't thoroughly explored
- Datasets used (SST2 and MHS) are relatively small and may not generalize to more complex real-world scenarios

## Confidence

- Overall method effectiveness: Medium
- Theoretical analysis: Low
- Practical efficiency claims: Medium

## Next Checks

1. Implement a validation mechanism to verify the quality of LLM-generated synthetic seeds beyond initial labeling, potentially using human review or additional automated checks.

2. Conduct experiments varying the LLM model, generation strategy, and graph construction parameters to assess their impact on performance and identify optimal configurations.

3. Test the method on larger, more diverse datasets from different domains to evaluate its scalability and generalizability beyond the current SST2 and MHS datasets.