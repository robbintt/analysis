---
ver: rpa2
title: 'It Takes Two: A Dual Stage Approach for Terminology-Aware Translation'
arxiv_id: '2511.07461'
source_url: https://arxiv.org/abs/2511.07461
tags:
- terminology
- translation
- target
- term
- lang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DuTerm, a dual-stage system for terminology-aware
  machine translation that combines a fine-tuned NMT model with LLM-based post-editing.
  The approach uses synthetic training data with explicit terminology tags to adapt
  the NMT, then employs an LLM to refine translations and enforce terminology constraints.
---

# It Takes Two: A Dual Stage Approach for Terminology-Aware Translation

## Quick Facts
- arXiv ID: 2511.07461
- Source URL: https://arxiv.org/abs/2511.07461
- Reference count: 19
- Primary result: Dual-stage NMT + LLM approach achieves BLEU scores of 48.06 (DE), 58.51 (ES), and 35.80 (RU) with ≥0.97 terminology success rates

## Executive Summary
This paper presents DuTerm, a dual-stage system for terminology-aware machine translation that combines a fine-tuned NMT model with LLM-based post-editing. The approach uses synthetic training data with explicit terminology tags to adapt the NMT, then employs an LLM to refine translations and enforce terminology constraints. Evaluated on English→German, English→Spanish, and English→Russian using WMT 2025 shared task metrics, DuTerm achieves strong performance: strict terminology enforcement yields BLEU scores of 48.06 (DE), 58.51 (ES), and 35.80 (RU) with near-perfect terminology success rates (≥0.97). The results show that flexible, context-aware LLM post-editing produces higher-quality translations than rigid constraint enforcement, demonstrating the effectiveness of guided refinement over direct generation for terminology-sensitive translation tasks.

## Method Summary
DuTerm operates in two stages: first, a fine-tuned NLLB-200 3.3B model generates terminology-aware translations from synthetic tagged data, then GPT-4o post-edits the outputs using explicit source-target term mappings. Synthetic data (10k-15k pairs per direction) is generated with GPT-4o at temperature 0.3-0.7, filtered by COMETQE scores (0.85-0.9 threshold), and trained multilingually with LoRA. The NMT stage adds [TERM]...[/TERM] tokens to the vocabulary to prevent subword fragmentation. Post-editing uses temperature 0.3 with explicit term mappings, validating format integrity and terminology satisfaction. The system is evaluated on WMT 2025 Terminology Shared Task corpus across three language pairs using BLEU, chrF2++, and terminology success rates.

## Key Results
- Dual-stage architecture achieves BLEU scores of 48.06 (DE), 58.51 (ES), and 35.80 (RU) with ≥0.97 terminology success rates
- Flexible LLM post-editing outperforms rigid constraint enforcement, particularly for morphologically rich languages like Russian
- Context-driven refinement produces higher-quality translations than strict constraint enforcement
- Russian shows widest gap between proper and noterm modes, highlighting challenges with morphology-rich languages

## Why This Works (Mechanism)

### Mechanism 1: Task Decomposition via Two-Stage Architecture
Separating translation into generation (NMT) and refinement (LLM) stages yields higher quality than either component alone. The NMT stage provides a structurally sound, lexically grounded base translation using fine-tuned terminology awareness. The LLM stage receives this "partially correct scaffold" and focuses computational capacity on higher-order adjustments—resolving ambiguities, adjusting word order, and refining morphological agreement—rather than generating from scratch. Core assumption: NMT models produce sufficiently accurate base translations that LLM refinement improves rather than degrades.

### Mechanism 2: Explicit Terminology Tagging with Vocabulary Extension
Extending model vocabulary with atomic terminology markup tokens prevents subword fragmentation and ensures consistent boundary handling. Synthetic training data wraps required terms with `[TERM]...[/TERM]` tags. By adding these as distinct vocabulary tokens, the model learns to treat terminology spans as indivisible units during both training and inference, improving tag fidelity and constraint learning. Core assumption: Terminology boundaries are clear and consistently annotated in both synthetic training data and inference inputs.

### Mechanism 3: Context-Driven Refinement Over Rigid Constraint Enforcement
LLM post-editing with explicit term mappings produces better translations than constrained decoding or strict constraint injection. Rather than forcing terminology into fixed slots during generation, the LLM receives source text, draft translation, and required term mappings as context. This allows the model to apply terminology in morphologically appropriate forms while maintaining fluency—particularly valuable for morphologically rich languages like Russian and German. Core assumption: The LLM has sufficient multilingual capability to recognize and correctly inflect terminology for target language morphology.

## Foundational Learning

- **Concept: Neural Machine Translation (NMT) Fine-Tuning**
  - **Why needed here:** The system adapts a pre-trained multilingual model (NLLB-200) to terminology-aware translation using synthetic tagged data. Understanding how parameter-efficient fine-tuning modifies model behavior is essential.
  - **Quick check question:** Can you explain why adding domain-specific synthetic data to training changes model behavior without catastrophic forgetting?

- **Concept: Quality Estimation (COMETQE)**
  - **Why needed here:** The pipeline uses COMETQE scores to filter synthetic data before training. Understanding what QE models measure—and their limitations—helps interpret why 60-70% retention thresholds were chosen.
  - **Quick check question:** What does a quality estimation score of 0.85 actually predict about translation quality?

- **Concept: Constrained Decoding vs. Post-Editing**
  - **Why needed here:** The paper positions itself against inference-time constraint methods (constrained beam search). Understanding this distinction clarifies the architectural motivation.
  - **Quick check question:** Why might forcing a specific word during beam search produce grammatically awkward output?

## Architecture Onboarding

- **Component map:** Source Text + Term Dictionary → [Stage 1: NMT] NLLB-200 3.3B (fine-tuned on tagged synthetic data) → Draft Translation with [TERM] tags → [Stage 2: LLM Post-Edit] GPT-4o (prompted with source, draft, term mappings) → Final Translation (validated for tag integrity, term satisfaction)

- **Critical path:** Synthetic data quality → NMT fine-tuning effectiveness → LLM refinement quality. If synthetic data contains misaligned term pairs or incorrect translations, errors propagate through both stages.

- **Design tradeoffs:**
  - Latency: Two sequential model calls (NMT + LLM) vs. single-pass alternatives
  - Cost: GPT-4o API calls for both synthetic generation and post-editing
  - Controllability: Flexible LLM handling vs. guaranteed constraint satisfaction from strict decoding

- **Failure signatures:**
  - Tag integrity loss: `[TERM]` markers fragmented or missing in output
  - Terminology drift: LLM substitutes synonyms despite explicit mappings
  - Morphology mismatch: Terms applied with incorrect case/inflection for context
  - Over-editing: LLM paraphrases beyond terminology refinement, altering meaning

- **First 3 experiments:**
  1. **Baseline comparison:** Run NMT-only (no LLM post-edit) on test set to isolate LLM contribution to BLEU/chrF2++ gains.
  2. **Tag ablation:** Train NMT without terminology tags, then apply same LLM post-editing to measure tagging's contribution to constraint learning.
  3. **Temperature sensitivity:** Test LLM post-editing at temperatures [0.1, 0.3, 0.5, 0.7] to characterize the fluency/constraint trade-off curve.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can memory-augmented or end-to-end architectures maintain terminology consistency across full documents more effectively than the current sentence-level approach?
- Basis in paper: [explicit] The conclusion proposes that "End-to-end or memory-augmented architectures that maintain consistency across sentences and documents hold promise for more coherent outputs."
- Why unresolved: The current DuTerm system operates sequentially at the sentence level, which the authors admit "overlooks opportunities for document-level consistency."
- What evidence would resolve it: Evaluation of a modified DuTerm architecture on document-level benchmarks, measuring terminological consistency across paragraphs using metrics like DocTER or targeted human evaluation.

### Open Question 2
- Question: Do adaptive learning mechanisms for terminology integration offer greater robustness across diverse domains compared to static prompt-based enforcement?
- Basis in paper: [explicit] The authors suggest that "exploring adaptive learning mechanisms that integrate terminology dynamically, rather than relying on static prompts, could enhance robustness across domains."
- Why unresolved: The current system relies on carefully crafted static prompts which may fail to generalize well to unseen domains or varying linguistic contexts.
- What evidence would resolve it: A comparative study testing static-prompt DuTerm against a reinforcement learning or adaptive fine-tuning variant on out-of-domain (e.g., medical/legal) datasets.

### Open Question 3
- Question: Is the success of the LLM-based post-editing stage dependent on the specific capabilities of GPT-4o, or does it generalize to smaller or open-source language models?
- Basis in paper: [inferred] The Limitations section notes that the "evaluation, conducted solely on GPT-4o... restricts the generalizability of findings," while the conclusion calls for "expanding evaluations to other language models."
- Why unresolved: It is unclear if the high performance is a result of the architecture or the specific power of GPT-4o; smaller models might struggle with the "guided refinement" tasks.
- What evidence would resolve it: Ablation studies substituting GPT-4o with open-source models (e.g., Llama, Mistral) to compare the degradation in BLEU/chrF2++ and terminology success rates.

### Open Question 4
- Question: To what extent do automated metrics like COMETQE and BLEU correlate with human judgment regarding terminological precision and contextual appropriateness in this dual-stage setup?
- Basis in paper: [inferred] The Limitations section states that automated metrics "may not fully reflect terminological precision and contextual appropriateness, suggesting the need for complementary evaluation methods that include human judgment."
- Why unresolved: High BLEU scores might mask subtle contextual errors or unnatural phrasing resulting from the post-editing process.
- What evidence would resolve it: A human evaluation study where expert translators assess the "naturalness" and "accuracy" of outputs compared to the automated scores reported in the paper.

## Limitations

- System dependence on GPT-4o for both synthetic data generation and post-editing creates cost dependencies and potential brittleness
- Synthetic data quality control lacks detailed error analysis of terminology misalignments in filtered datasets
- Cross-lingual generalization varies significantly across language pairs, with Russian showing largest performance gaps
- Evaluation scope limited to WMT 2025 Terminology Shared Task data without out-of-domain testing

## Confidence

**High Confidence:** The dual-stage architecture providing performance benefits over single-stage approaches. The mechanism of using LLM refinement on NMT-generated scaffolds is well-supported by the experimental results showing consistent improvements across all three language pairs.

**Medium Confidence:** The effectiveness of explicit terminology tagging for constraint learning. While the paper provides theoretical justification and observed performance improvements, the lack of ablation studies on tag usage makes it difficult to quantify the marginal contribution of vocabulary extension versus other factors.

**Low Confidence:** The systematic advantages of context-driven refinement over rigid constraint enforcement. The paper asserts this but doesn't directly compare against constrained decoding baselines on the same test sets, making it difficult to isolate the LLM's contribution from other architectural choices.

## Next Checks

1. **Constrained Decoding Baseline:** Implement and evaluate a constrained beam search baseline using the same NMT model to directly compare rigid constraint enforcement against LLM post-editing for the same terminology pairs.

2. **Temperature Sensitivity Analysis:** Systematically evaluate LLM post-editing performance across a broader temperature range (e.g., 0.1-0.9) to map the fluency-constraint trade-off curve and identify optimal settings per language pair.

3. **Out-of-Domain Terminology Transfer:** Test the fine-tuned NMT model and post-editing pipeline on terminology pairs not present in the training dictionaries to assess generalization to unseen terminology and domain shifts.