---
ver: rpa2
title: 'Lost in Transmission: When and Why LLMs Fail to Reason Globally'
arxiv_id: '2505.08140'
source_url: https://arxiv.org/abs/2505.08140
tags:
- prefix
- bapo
- attention
- suffix
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Bounded Attention Prefix Oracle (BAPO)
  model to explain why transformer-based LLMs struggle with global reasoning tasks.
  The core idea is that LLMs have limited bandwidth for accurately transmitting information
  across residual streams, which causes failures on problems requiring complex inter-token
  dependencies.
---

# Lost in Transmission: When and Why LLMs Fail to Reason Globally

## Quick Facts
- **arXiv ID**: 2505.08140
- **Source URL**: https://arxiv.org/abs/2505.08140
- **Reference count**: 40
- **Primary result**: Introduces BAPO theory explaining LLM failures on global reasoning via bandwidth constraints

## Executive Summary
This paper presents the Bounded Attention Prefix Oracle (BAPO) model to explain why transformer-based LLMs struggle with tasks requiring complex inter-token dependencies. The core insight is that LLMs have limited bandwidth for accurately transmitting information across residual streams, causing failures on problems requiring global reasoning. The authors formalize this through theoretical complexity results showing certain problems (like graph reachability and majority) are BAPO-hard, requiring super-constant bandwidth. Empirical validation demonstrates that state-of-the-art models consistently fail on BAPO-hard tasks while succeeding on BAPO-easy ones, with chain-of-thought reasoning shown to decompose hard problems into manageable steps.

## Method Summary
The authors validate their BAPO theory by testing multiple LLM families (GPT-4o, Claude, Gemini) on synthetic problems with varying token lengths (n ∈ {6, 50, 100, 200}). They compare performance on BAPO-easy problems (INDEX, EQUALITY, DISJOINTNESS, MATCH2) against BAPO-hard problems (REACHABILITY, MAJORITY, MATCH3, UNIQUE, SETDIFF) using zero-shot API evaluation with structured JSON outputs. The SPACE hotel review dataset provides real-world validation for graph reachability analogs. CoT experiments add step-by-step reasoning prompts with token budget constraints, measuring reasoning depth and accuracy improvements.

## Key Results
- LLMs consistently fail on BAPO-hard problems (REACHABILITY, MAJORITY) while succeeding on BAPO-easy problems (INDEX, EQUALITY) across all tested model families
- Accuracy degradation on BAPO-hard tasks scales with problem size (n), while BAPO-easy tasks maintain high accuracy
- Chain-of-thought reasoning significantly improves performance on BAPO-hard problems by decomposing them into BAPO-easy steps
- Extended CoT models (o3, Gemini 2.5 Flash) use thousands of reasoning tokens, suggesting deeper reasoning capability

## Why This Works (Mechanism)
The BAPO model explains LLM failures through bandwidth limitations in transformer residual streams. Information must be transmitted accurately across tokens for global reasoning, but transformers have constrained capacity for this communication. BAPO-hard problems require super-constant bandwidth to solve, exceeding what current architectures can reliably provide. CoT reasoning works by breaking down complex global dependencies into local, sequential reasoning steps that require only constant bandwidth each.

## Foundational Learning
- **BAPO complexity classes**: Problems classified as BAPO-easy (constant bandwidth) vs BAPO-hard (super-constant bandwidth) based on information transmission requirements
  - *Why needed*: Provides theoretical framework for understanding when LLMs should succeed vs fail
  - *Quick check*: Verify INDEX is BAPO-easy (constant) and REACHABILITY is BAPO-hard (super-constant)

- **Residual stream bandwidth**: The capacity for information transmission between tokens through transformer layers
  - *Why needed*: Core mechanism limiting global reasoning capabilities
  - *Quick check*: Confirm bandwidth requirements scale with problem complexity

- **Chain-of-thought decomposition**: Breaking down BAPO-hard problems into sequences of BAPO-easy reasoning steps
  - *Why needed*: Explains why CoT improves performance on complex reasoning tasks
  - *Quick check*: Verify CoT token counts increase for BAPO-hard vs BAPO-easy problems

## Architecture Onboarding

**Component map**: BAPO theory -> Synthetic problem generation -> LLM API evaluation -> Accuracy measurement -> CoT analysis

**Critical path**: Problem generation → Zero-shot prompting → Structured output parsing → Accuracy computation → Bandwidth analysis

**Design tradeoffs**: Synthetic vs real-world tasks (controlled vs ecological validity), zero-shot vs few-shot prompting (purity vs performance), structured vs free-form outputs (reliability vs flexibility)

**Failure signatures**: BAPO-hard problems show accuracy degradation with increasing n; BAPO-easy problems maintain high accuracy; CoT fails to improve BAPO-hard problems when token limits are too restrictive

**Three first experiments**:
1. Replicate INDEX vs REACHABILITY accuracy comparison across n values for GPT-4o
2. Test CoT benefit on MAJORITY problem with and without token budget constraints
3. Validate SPACE dataset results for graph reachability analog

## Open Questions the Paper Calls Out
None

## Limitations
- Results rely heavily on synthetic benchmarks that may not fully capture real-world reasoning complexity
- Model version dependency could affect reproducibility as API versions evolve
- Practical implications for architectural improvements remain speculative without broader empirical validation

## Confidence

**High confidence**: Theoretical framework and complexity proofs are mathematically sound and follow established computational approaches

**Medium confidence**: Empirical validation on synthetic problems is compelling, but real-world generalization remains limited to narrow applications

**Low confidence**: Claims about architectural improvements and universal CoT decomposition capabilities need broader validation across diverse reasoning tasks

## Next Checks

1. **Replicate with current model versions**: Rerun core experiments (INDEX vs REACHABILITY) using latest GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro to verify BAPO distinctions persist

2. **Test on additional reasoning benchmarks**: Validate BAPO predictions on GSM8K, MATH, and ARC datasets to check alignment with theoretical expectations

3. **Vary context window and architecture**: Test whether increasing context window size or using alternative architectures (Mamba, RWKV) reduces failures on BAPO-hard problems