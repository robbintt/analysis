---
ver: rpa2
title: Negatives-Dominant Contrastive Learning for Generalization in Imbalanced Domains
arxiv_id: '2601.21999'
source_url: https://arxiv.org/abs/2601.21999
tags:
- domain
- domains
- ndcl
- generalization
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of Imbalanced Domain Generalization
  (IDG), where models must generalize across multiple source domains with both domain
  shifts and label shifts, particularly under heterogeneous long-tailed distributions.
  The authors theoretically establish the first generalization bound for IDG, emphasizing
  the critical roles of posterior discrepancy and decision margin.
---

# Negatives-Dominant Contrastive Learning for Generalization in Imbalanced Domains

## Quick Facts
- **arXiv ID:** 2601.21999
- **Source URL:** https://arxiv.org/abs/2601.21999
- **Reference count:** 40
- **Primary result:** NDCL consistently outperforms 21 baselines on IDG benchmarks, achieving up to 1.5% higher accuracy and significantly better minority class performance.

## Executive Summary
This paper addresses Imbalanced Domain Generalization (IDG), where models must generalize across multiple source domains with both domain shifts and label shifts, particularly under heterogeneous long-tailed distributions. The authors theoretically establish the first generalization bound for IDG, emphasizing the critical roles of posterior discrepancy and decision margin. Based on this theoretical insight, they propose a novel Negative-Dominant Contrastive Learning (NDCL) method that enhances inter-class decision-boundary separation by emphasizing negative samples in contrastive learning, encourages intra-class compactness through re-weighted cross-entropy, and enforces posterior consistency across domains via prediction-central alignment. Extensive experiments on three benchmarks (VLCS, PACS, OfficeHome) under three distinct imbalance settings demonstrate that NDCL consistently outperforms 21 recent strong baselines, achieving up to 1.5% higher accuracy and significantly better performance on minority classes.

## Method Summary
NDCL is a contrastive learning framework that operates in prediction space (not feature space) to address IDG under label imbalance. It combines three losses: (1) a negative-dominant contrastive loss that amplifies gradient signals for minority classes by emphasizing negative samples, (2) a re-weighted cross-entropy loss for intra-class compactness, and (3) a prediction-central alignment loss that aligns class prototypes across domains. The method uses a ResNet-50 backbone with a projection head, trained with Adam optimizer for 5,000 steps at learning rate 5e-5. Hyperparameters α and β control the strength of contrastive and alignment losses respectively, while ρ controls the Beta distribution for hard negative augmentation.

## Key Results
- NDCL outperforms 21 recent IDG baselines across three benchmarks (VLCS, PACS, OfficeHome)
- Achieves up to 1.5% higher average accuracy compared to strongest competitors
- Demonstrates significantly better performance on minority classes (Many/Medium/Few splits)
- Maintains robust performance across three distinct imbalance settings (GINIDG, TotalHeavyTail, Duality)

## Why This Works (Mechanism)

### Mechanism 1: Negative-Dominant Gradient Amplification for Minority Classes
- **Claim:** Reformulating contrastive loss to emphasize negatives amplifies gradient signals for minority classes, counteracting decision boundary bias toward majority classes.
- **Mechanism:** The modified objective places negative pairs in the numerator, creating an amplification factor Σ_p(1-s) / Σ_n(1-s) that strengthens negative gradients when minority samples are surrounded by nearby majority negatives (denominator shrinks → factor increases). This increases repulsion against confusing negatives at the boundary.
- **Core assumption:** Minority-class samples tend to cluster near majority-class decision boundaries, and increasing negative repulsion preserves their class boundaries without requiring explicit re-weighting.
- **Evidence anchors:**
  - [abstract]: "inter-class decision-boundary separation is enhanced by placing greater emphasis on negatives as the primary signal in our contrastive learning, naturally amplifying gradient signals for minority classes"
  - [Section 2.3]: Gradient derivation showing amplification factor dynamics when "the local neighborhood of the anchor is dominated by negatives"
  - [corpus]: Related work on negative-class contrastive learning (FixCLR, arXiv:2506.20841) similarly emphasizes negatives for domain generalization
- **Break condition:** If minority and majority classes are already well-separated, the amplification factor becomes less discriminative; standard contrastive objectives may suffice.

### Mechanism 2: Hard Negative Synthesis via Confidence-Based Mixup
- **Claim:** Generating synthetic hard negatives by mixing low-confidence positives with high-confidence negatives focuses learning on ambiguous boundary regions.
- **Mechanism:** For each class k, samples with low predicted confidence (uncertain positives) are mixed with out-of-class samples with high confidence for class k (hard negatives). This creates samples in the decision boundary region, encouraging the model to maintain separation where it matters most.
- **Core assumption:** The model's prediction confidence correlates with proximity to class boundaries; low-confidence positives lie near decision margins, and mixing with confident negatives yields informative boundary examples.
- **Evidence anchors:**
  - [Section 2.3, Eq. 2]: "encouraging the model to focus on more ambiguous and informative instances"
  - [Appendix C]: Adaptive mechanism where confidence thresholds are determined per mini-batch based on sorted predictions
  - [corpus]: Hard negative mixing for contrastive learning (Kalantidis et al., cited in paper) provides precedent for prioritizing semantically ambiguous samples
- **Break condition:** If class distributions are highly imbalanced and minority classes have very few samples, the pool of low-confidence positives may be insufficient for effective mixup.

### Mechanism 3: Prediction-Space Prototype Alignment for Cross-Domain Consistency
- **Claim:** Aligning class prototypes across domains in prediction space (not feature space) enforces posterior consistency while being robust to sample proportion imbalance.
- **Mechanism:** Compute prediction vectors μ_d^k = E[f_θ(x)] for each domain-class pair, then apply a SupCon-inspired loss that pulls same-class prototypes together across domains. First-order moment matching decouples alignment from sample counts, preventing majority domains from dominating.
- **Core assumption:** Posterior consistency across domains is sufficient for generalization even when prior distributions differ; aligning predictions directly avoids distortion from imbalanced representation alignment.
- **Evidence anchors:**
  - [Section 2.3, Eq. 3]: "aligning first-order statistics instead of individual samples, this strategy can effectively mitigate imbalance-induced bias by decoupling alignment from sample proportions"
  - [Theorem 1]: Theoretical bound includes "posterior distribution discrepancy" term motivating this mechanism
  - [corpus]: Limited direct corpus support for prediction-space alignment; most DG methods align feature representations (assumption-based extension)
- **Break condition:** If source domains have fundamentally different class semantics (same label but different meanings), prototype alignment may enforce harmful consistency.

## Foundational Learning

- **Concept: Decision Margin in Imbalanced Learning**
  - **Why needed here:** The theoretical bound explicitly includes a margin term Pr[γ(h) ≤ δ]; understanding how imbalance compresses minority-class margins is essential for interpreting why negative emphasis helps.
  - **Quick check question:** Can you explain why majority classes tend to compress decision margins for minority classes in long-tailed distributions?

- **Concept: Contrastive Learning Objective Functions (InfoNCE vs. Supervised Contrastive)**
  - **Why needed here:** NDCL modifies InfoNCE by inverting the dominance from positives to negatives; understanding the standard formulation reveals what changes and why gradient behavior differs.
  - **Quick check question:** In standard InfoNCE, what role do positive and negative pairs play in the loss, and how does NDCL's formulation differ structurally?

- **Concept: H-divergence and Domain Generalization Bounds**
  - **Why needed here:** The paper extends classical DG bounds to include posterior discrepancy; grasping the original bound helps understand what's new and why it matters for imbalanced settings.
  - **Quick check question:** What does H-divergence measure, and how does adding a posterior term change the theoretical requirements for generalization?

## Architecture Onboarding

- **Component map:**
  Input → Encoder (ResNet-50) → Projection Head → Prediction Space
                                                      ↓
                                          ┌─────────┴─────────┐
                                          │                   │
                                    L_con (Negative-    L_const (Prototype
                                    Dominant)            Alignment)
                                          │                   │
                                          └─────────┬─────────┘
                                                    ↓
                                              L_ce (Re-weighted)
                                                    ↓
                                              Total Loss (Eq. 5)

- **Critical path:**
  1. Forward pass through encoder and projection head to obtain prediction vectors p = f_θ(x)
  2. Compute three losses in prediction space (not feature space—this is key)
  3. L_con requires building hard negative sets via confidence-based mixup per mini-batch
  4. L_const requires maintaining domain-class prototypes across iterations
  5. Combine with re-weighted CE using loss-based sample weights

- **Design tradeoffs:**
  - **Prediction space vs. feature space:** NDCL operates on predictions, not embeddings. This directly targets posterior alignment but may lose fine-grained spatial information.
  - **Negative emphasis vs. positive compactness:** The reformulation sacrifices strong positive pulling for stronger negative pushing; beneficial under imbalance but may reduce intra-class tightness.
  - **Prototype-based alignment vs. sample-level alignment:** First-order statistics are robust to imbalance but ignore second-order distribution properties.

- **Failure signatures:**
  - **Minority classes still underperforming:** Check if hard negative mining is creating meaningful boundary samples; verify amplification factor is actually larger for minority anchors.
  - **Domain misalignment despite L_const:** Prototypes may be unstable for minority domain-class pairs with very few samples; consider minimum sample thresholds.
  - **Training instability:** Large α/β values (Eq. 5) can dominate CE loss; validate balance hyperparameters are in suggested range [10^-3, 10^0].

- **First 3 experiments:**
  1. **Ablation on L_con formulation:** Compare NDCL's negative-dominant variant against standard InfoNCE and SupCon on a single benchmark (e.g., PACS) under TotalHeavyTail setting; track per-class accuracy to verify minority improvement.
  2. **Hard negative mining analysis:** Visualize t-SNE of augmented negatives vs. original samples; verify they lie near decision boundaries and are not trivially separable.
  3. **Prototype stability check:** Track μ_d^k norms and inter-domain prototype distances during training; unstable prototypes for small domain-class pairs indicate insufficient regularization or data.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can causality-inspired mechanisms be integrated to disentangle underlying factors more effectively than the current decision-boundary focus?
- **Basis in paper:** [explicit] The authors state in the conclusion that future work may integrate causality-inspired mechanisms to offer a "promising path toward more generalizable models."
- **Why unresolved:** The current method focuses on decision boundaries and posterior consistency but does not explicitly disentangle the underlying causal factors of domain and label shifts.
- **What evidence would resolve it:** Demonstrated improvements on IDG benchmarks using a framework that combines NDCL with causal disentanglement modules.

### Open Question 2
- **Question:** How can domain priors be explicitly modeled under severe imbalance without introducing ill-posedness in representation alignment?
- **Basis in paper:** [explicit] The conclusion highlights that while NDCL indirectly mitigates prior discrepancy, explicit modeling remains challenging due to "potential ill-posedness in representation alignment."
- **Why unresolved:** Severe imbalance makes the statistical estimation of domain priors unstable, leading to distorted representation spaces if aligned directly.
- **What evidence would resolve it:** A theoretical formulation or algorithm that stabilizes prior alignment under extreme label shift without degrading minority class accuracy.

### Open Question 3
- **Question:** Does the performance of Negative-Dominant Contrastive Learning generalize to Transformer-based architectures (e.g., ViT)?
- **Basis in paper:** [inferred] The experiments exclusively utilize ResNet-50 as the backbone, leaving the interaction between the proposed contrastive objective and Vision Transformer architectures untested.
- **Why unresolved:** Transformers rely on different inductive biases (global attention) compared to CNNs (locality), which may affect how negative samples contribute to decision margins.
- **What evidence would resolve it:** Comparative evaluation of NDCL using a ViT backbone on the VLCS, PACS, and OfficeHome benchmarks.

## Limitations

- The theoretical generalization bound relies on posterior distribution discrepancy rather than feature space alignment, but the paper does not validate whether posterior alignment in prediction space is sufficient for practical generalization compared to established feature-level methods.
- The mechanism connecting negative amplification to minority-class gradient enhancement, while theoretically sound, lacks empirical validation showing the actual gradient distributions during training.
- The confidence-based hard negative synthesis assumes prediction confidence correlates with boundary proximity, but this relationship may not hold uniformly across all domain shifts and imbalance patterns.

## Confidence

- **High confidence:** The empirical results showing NDCL outperforming 21 baselines across three benchmarks and three imbalance settings are robust and well-documented. The ablation studies on individual loss components provide strong evidence for their contributions.
- **Medium confidence:** The theoretical generalization bound and its connection to the proposed method is mathematically rigorous but relies on assumptions about posterior discrepancy that may not fully capture practical domain generalization challenges. The mechanism explanations are plausible but require more direct empirical validation.
- **Low confidence:** The claim that prediction-space prototype alignment is superior to feature-space alignment for domain generalization lacks direct comparative evidence against feature-level alternatives.

## Next Checks

1. **Gradient Analysis Experiment:** Visualize and compare the gradient magnitudes for minority vs. majority class samples during training with NDCL versus standard contrastive methods to directly verify the negative amplification mechanism.

2. **Feature vs. Prediction Space Alignment:** Implement a variant of NDCL that operates in feature space rather than prediction space and compare generalization performance to test the hypothesis about prediction-space superiority.

3. **Confidence Correlation Validation:** Systematically measure the relationship between model prediction confidence and actual distance to decision boundaries across multiple domains to validate the hard negative synthesis assumption.