---
ver: rpa2
title: 'AndroidGen: Building an Android Language Agent under Data Scarcity'
arxiv_id: '2504.19298'
source_url: https://arxiv.org/abs/2504.19298
tags:
- task
- agent
- arxiv
- android
- click
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents AndroidGen, a framework designed to build an
  Android language agent under data scarcity. The key challenges addressed include
  the need for high-quality data sources, complex task data collection, and effective
  data filtration.
---

# AndroidGen: Building an Android Language Agent under Data Scarcity

## Quick Facts
- **arXiv ID**: 2504.19298
- **Source URL**: https://arxiv.org/abs/2504.19298
- **Reference count**: 29
- **Primary result**: Introduces AndroidGen framework for building Android language agents without manually labeled data

## Executive Summary
AndroidGen addresses the challenge of building Android language agents in data-scarce environments by introducing a framework that leverages completed trajectories for in-context learning. The system introduces four core modules: ExpSearch for learning from completed trajectories, ReflectPlan for self-reflection and plan updates, AutoCheck for operation validity verification, and StepCritic for fine-grained trajectory evaluation. By collecting trajectories from human tasks and training open-source LLMs, AndroidGen achieves significant improvements in task completion rates on AndroidWorld and AitW benchmarks without requiring manually labeled data.

## Method Summary
AndroidGen operates by first collecting trajectories from human-completed Android tasks, then using these trajectories to train an Android language agent through its four-module architecture. The ExpSearch module enables in-context learning from completed trajectories, while ReflectPlan provides self-reflection capabilities for plan refinement. AutoCheck validates the operations generated by the agent, and StepCritic evaluates trajectories at a fine-grained level. This framework allows for the development of robust Android agents even when training data is limited, as it can leverage existing human task completions rather than requiring extensive manual labeling.

## Key Results
- Demonstrates significant improvements in task completion rates on AndroidWorld and AitW benchmarks
- Achieves robust Android agent performance without manually labeled data
- Showcases potential for AndroidGen as a versatile tool for mobile application tasks

## Why This Works (Mechanism)
The framework's effectiveness stems from its ability to learn from completed trajectories rather than requiring extensive labeled training data. By combining in-context learning (ExpSearch) with self-reflection capabilities (ReflectPlan), the system can iteratively improve its task completion strategies. The AutoCheck module ensures operation validity, while StepCritic provides fine-grained evaluation that enables continuous improvement. This multi-layered approach allows the agent to handle complex Android tasks even in data-scarce environments.

## Foundational Learning
- **In-context learning**: Why needed - Enables learning from examples without fine-tuning; Quick check - Agent can complete tasks using provided examples
- **Self-reflection**: Why needed - Allows plan refinement and error correction; Quick check - Agent improves performance after reviewing failed attempts
- **Operation validity verification**: Why needed - Ensures generated actions are executable; Quick check - Agent avoids invalid or impossible operations
- **Fine-grained trajectory evaluation**: Why needed - Enables detailed performance assessment; Quick check - Agent receives specific feedback on each step

## Architecture Onboarding
- **Component map**: Human tasks -> ExpSearch -> ReflectPlan -> AutoCheck -> StepCritic -> Agent output
- **Critical path**: Task input → ExpSearch (in-context learning) → ReflectPlan (plan refinement) → AutoCheck (validation) → StepCritic (evaluation) → Action execution
- **Design tradeoffs**: Prioritizes data efficiency over potentially higher performance from larger labeled datasets; balances computational overhead with accuracy
- **Failure signatures**: Invalid operations passing through AutoCheck, poor trajectory evaluation by StepCritic, ineffective plan refinement by ReflectPlan
- **First experiments**: 1) Validate ExpSearch learning from single trajectory; 2) Test ReflectPlan on simple task failures; 3) Verify AutoCheck catches basic invalid operations

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on existing benchmarks without statistical significance testing
- Does not address potential biases in collected trajectories
- Scalability to more complex Android tasks remains unproven
- Computational overhead of all four modules is not quantified

## Confidence

**High Confidence**: The architectural design of AndroidGen's four core modules and their individual functionalities are clearly described and logically structured.

**Medium Confidence**: The reported improvements in task completion rates on AndroidWorld and AitW benchmarks are plausible but lack statistical validation and detailed ablation studies.

**Low Confidence**: The claim that AndroidGen is a "versatile tool for mobile application tasks" extends beyond the presented evidence, focusing primarily on benchmark tasks.

## Next Checks
1. Conduct statistical significance testing on reported performance improvements across multiple runs to establish result reliability.

2. Perform ablation studies to quantify individual and combined contributions of each module (ExpSearch, ReflectPlan, AutoCheck, StepCritic).

3. Evaluate AndroidGen on diverse real-world Android applications beyond benchmark tasks to assess practical applicability and identify failure modes.