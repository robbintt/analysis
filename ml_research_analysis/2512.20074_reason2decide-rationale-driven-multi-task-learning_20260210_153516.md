---
ver: rpa2
title: 'Reason2Decide: Rationale-Driven Multi-Task Learning'
arxiv_id: '2512.20074'
source_url: https://arxiv.org/abs/2512.20074
tags:
- rationale
- rationales
- reason2decide
- triage
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Reason2Decide addresses the challenge of generating explanations
  aligned with predictions in clinical decision support systems. The two-stage framework
  first trains on rationale generation, then jointly optimizes predictions and rationales
  using task-level scheduled sampling that gradually shifts from gold labels to predicted
  labels.
---

# Reason2Decide: Rationale-Driven Multi-Task Learning

## Quick Facts
- arXiv ID: 2512.20074
- Source URL: https://arxiv.org/abs/2512.20074
- Reference count: 0
- Key outcome: 40x parameter efficiency over foundation models with improved F1 and rationale fidelity metrics

## Executive Summary
Reason2Decide introduces a rationale-driven multi-task learning framework that enhances clinical decision support systems by generating predictions aligned with human-understandable explanations. The approach addresses the challenge of aligning model predictions with explanatory rationales through a two-stage training process. By first pre-training on rationale generation and then jointly optimizing predictions and rationales using task-level scheduled sampling, the framework achieves state-of-the-art performance across three medical datasets while using models 40x smaller than traditional foundation models.

## Method Summary
The framework employs a two-stage training process. First, the model pre-trains on rationale generation tasks to establish a foundation for explanation generation. Second, it jointly optimizes both prediction and rationale generation tasks using task-level scheduled sampling that gradually transitions from gold labels to predicted labels. This approach allows the model to learn aligned prediction-explanation pairs while maintaining efficiency. The framework demonstrates robustness across different rationale sources including LLM-generated, nurse-authored, and post-processed rationales.

## Key Results
- Achieves 40x parameter efficiency compared to foundation models while maintaining or improving prediction accuracy
- Outperforms fine-tuning baselines on both prediction metrics (F1) and rationale fidelity metrics (BERTScore, BLEU, LLM-as-a-Judge)
- Demonstrates consistent performance across three medical datasets with varying rationale sources

## Why This Works (Mechanism)
The framework's success stems from its two-stage training approach that first establishes strong rationale generation capabilities before integrating prediction tasks. The task-level scheduled sampling technique ensures smooth transitions between gold and predicted labels during training, preventing catastrophic forgetting while promoting alignment between predictions and rationales. The multi-task learning setup creates a synergistic relationship where rationale generation helps improve prediction quality, and prediction feedback refines the rationale generation process.

## Foundational Learning
- Multi-task learning: Jointly training prediction and rationale generation tasks creates complementary learning signals. Why needed: Clinical decisions require both accurate predictions and trustworthy explanations.
- Scheduled sampling: Gradually transitioning from gold to predicted labels during training. Why needed: Prevents exposure bias and improves generalization to real-world conditions.
- Rationale generation: Creating human-understandable explanations for model predictions. Why needed: Critical for clinical trust and regulatory compliance in healthcare AI.
- Parameter-efficient fine-tuning: Using smaller models with targeted training approaches. Why needed: Reduces computational costs while maintaining performance.

## Architecture Onboarding

Component map: Rationale pre-training -> Joint optimization -> Prediction + Rationale generation
Critical path: Pre-training rationale generation -> Scheduled sampling schedule -> Joint loss optimization
Design tradeoffs: Smaller model size vs. foundation models, rationale quality vs. prediction accuracy
Failure signatures: Misaligned predictions and rationales, degradation in rationale quality during joint optimization
First experiments: 1) Ablation study on pre-training vs. joint optimization 2) Different scheduled sampling schedules 3) Cross-dataset generalization tests

## Open Questions the Paper Calls Out
None

## Limitations
- Performance on nurse-authored rationales in real clinical settings remains untested
- Assumes monotonic improvement path that may not hold across all clinical domains
- Evaluation metrics for rationale fidelity still face challenges in capturing clinical relevance

## Confidence
High: 40x parameter efficiency advantage over foundation models is well-supported by controlled experiments
Medium: Generalization across rationale sources demonstrated but primarily on curated datasets
Medium: Multi-task learning superiority over fine-tuning baselines is robust but gains may vary with dataset complexity

## Next Checks
1. Conduct ablation studies to isolate contributions of task-level scheduled sampling versus rationale pre-training on diverse clinical datasets
2. Evaluate performance on long-form clinical narratives and multi-modal data to assess scalability
3. Perform human evaluation study comparing clinical expert trust and preference for Reason2Decide outputs versus traditional clinical decision support explanations