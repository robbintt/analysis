---
ver: rpa2
title: Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning
arxiv_id: '2507.20906'
source_url: https://arxiv.org/abs/2507.20906
tags:
- task
- tasks
- shot
- last
- letter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a method called Soft Injection of Task Embeddings
  (SITE) to improve in-context learning (ICL) in large language models. The key idea
  is to construct task embeddings from few-shot ICL prompts and then softly inject
  them into the model's attention head activations using optimized interpolation weights,
  called soft head-selection parameters.
---

# Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning

## Quick Facts
- arXiv ID: 2507.20906
- Source URL: https://arxiv.org/abs/2507.20906
- Authors: Jungwon Park; Wonjong Rhee
- Reference count: 40
- Primary result: SITE achieves 10.2%-14.3% average performance gains over 10-shot ICL across 57 tasks and 12 models (4B–70B parameters)

## Executive Summary
This paper introduces Soft Injection of Task Embeddings (SITE), a method that improves in-context learning (ICL) in large language models by constructing task embeddings from few-shot demonstrations and softly injecting them into the model's attention head activations. Unlike traditional ICL that requires in-prompt demonstrations during inference, SITE learns optimized interpolation weights (soft head-selection parameters) to blend task embeddings into attention layers, enabling zero-shot-style inference with significantly better performance. The approach demonstrates consistent improvements across diverse tasks and model sizes while maintaining inference efficiency.

## Method Summary
SITE constructs task embeddings from few-shot ICL prompts and then softly injects these embeddings into the model's attention head activations using optimized interpolation weights called soft head-selection parameters. During inference, the model can perform tasks without in-prompt demonstrations, leveraging the pre-learned task embeddings and soft injection mechanism. This approach significantly outperforms standard 10-shot ICL while maintaining zero-shot inference speed and memory efficiency.

## Key Results
- SITE achieves average performance gains of 10.2%–14.3% over 10-shot ICL baselines
- Tested across 57 tasks and 12 models ranging from 4B to 70B parameters
- Matches zero-shot inference speed and memory usage while requiring only one-time computation of embeddings and parameters

## Why This Works (Mechanism)
SITE works by decomposing the ICL problem into two phases: first learning task-specific embeddings from few-shot demonstrations, then optimizing soft injection parameters that control how these embeddings are blended into the model's attention mechanism. This separation allows the model to leverage the knowledge captured in task embeddings without the computational overhead of maintaining demonstrations during inference. The soft head-selection parameters provide fine-grained control over how much each task embedding influences different attention heads, enabling task-specific modulation of the model's internal representations.

## Foundational Learning
- **In-context learning**: The ability of language models to perform tasks given few examples in the prompt. Why needed: Understanding ICL is crucial as SITE builds upon and improves this fundamental capability. Quick check: Can the model complete a task with only 3-5 examples in the prompt?
- **Attention mechanisms**: The core component that SITE modifies through soft injection. Why needed: SITE's performance gains come from effectively modifying attention head activations. Quick check: Does the model use multi-head self-attention?
- **Task embeddings**: Learned representations specific to particular tasks. Why needed: SITE constructs and injects these embeddings rather than using raw demonstrations. Quick check: Can the model generate meaningful embeddings for different task types?
- **Parameter optimization**: The process of learning soft head-selection parameters. Why needed: These parameters control the injection strength and are critical to SITE's performance. Quick check: Does the optimization converge and generalize to unseen examples?
- **Inference efficiency**: Maintaining fast inference while improving performance. Why needed: SITE claims to match zero-shot inference characteristics. Quick check: Does inference time remain comparable to baseline models?
- **Few-shot learning**: The paradigm SITE uses to construct initial task representations. Why needed: SITE relies on quality few-shot demonstrations for embedding construction. Quick check: Are the few-shot examples representative of the target task?

## Architecture Onboarding

**Component Map**
Task Demonstrations -> Task Embedding Construction -> Soft Head-Selection Parameter Optimization -> Attention Head Injection -> Inference without Demonstrations

**Critical Path**
The critical path involves the construction of task embeddings from demonstrations, followed by the optimization of soft head-selection parameters that control the injection process. During inference, the pre-computed embeddings and parameters are applied to modify attention head activations, enabling task performance without in-context examples.

**Design Tradeoffs**
SITE trades the simplicity and interpretability of in-prompt demonstrations for improved performance and inference efficiency. While traditional ICL requires demonstration examples to be present during inference, SITE moves this knowledge into learned parameters, reducing memory overhead but requiring an additional optimization step. The soft injection approach provides more flexibility than hard injection methods but may introduce optimization challenges in finding optimal interpolation weights.

**Failure Signatures**
Performance degradation may occur if task embeddings are poorly constructed from unrepresentative few-shot demonstrations, if soft head-selection parameters overfit to training examples, or if the injection mechanism disrupts the model's pre-trained representations. The method may also struggle with tasks requiring deep domain expertise that cannot be adequately captured from limited demonstrations.

**3 First Experiments**
1. Verify that task embeddings can be constructed from few-shot demonstrations and meaningfully represent the target task
2. Test the soft injection mechanism on a simple attention layer to confirm that embeddings can be successfully blended
3. Evaluate performance on a single task with varying numbers of demonstration examples to determine the optimal demonstration count

## Open Questions the Paper Calls Out
None

## Limitations
- Performance highly dependent on quality and diversity of initial few-shot demonstrations
- Assumes task-specific embeddings can be effectively learned from small numbers of examples
- May not generalize well to tasks requiring deep domain expertise or with highly ambiguous few-shot contexts

## Confidence
- **High Confidence**: Consistent performance gains over 10-shot ICL baselines across multiple tasks and model sizes
- **Medium Confidence**: Claim of matching zero-shot inference speed and memory usage
- **Low Confidence**: Generalizability to tasks with extremely limited or noisy few-shot demonstrations

## Next Checks
1. Test SITE on tasks with intentionally biased or low-quality few-shot demonstrations to evaluate robustness to demonstration quality
2. Conduct ablation studies to determine the impact of varying the number of demonstrations used to construct task embeddings
3. Benchmark SITE against other state-of-the-art in-context learning methods, such as prompt tuning or prefix tuning, to contextualize its relative performance