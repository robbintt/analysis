---
ver: rpa2
title: ARC-AGI Without Pretraining
arxiv_id: '2512.06104'
source_url: https://arxiv.org/abs/2512.06104
tags:
- puzzle
- compressarc
- puzzles
- training
- tensor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CompressARC is a 76K-parameter model that solves 20% of ARC-AGI-1
  evaluation puzzles without pretraining by minimizing description length (MDL) at
  inference time. It learns only from the target puzzle itself, without using any
  training data.
---

# ARC-AGI Without Pretraining

## Quick Facts
- **arXiv ID:** 2512.06104
- **Source URL:** https://arxiv.org/abs/2512.06104
- **Reference count:** 40
- **Primary result:** 76K-parameter model solves 20% of ARC-AGI-1 evaluation puzzles without pretraining by minimizing description length at inference time

## Executive Summary
CompressARC demonstrates that extreme data efficiency is possible in deep learning by solving ARC-AGI puzzles without any pretraining data. The approach frames puzzle solving as a code-golfing problem, optimizing neural network weights to compress puzzle data into weight matrices that can be hard-coded into a program. By minimizing the description length (MDL) of the target puzzle purely during inference time, the method achieves generalization from as few as two demonstration pairs, suggesting MDL as an alternative path to intelligence beyond conventional pretraining.

## Method Summary
The method treats ARC-AGI as a compression problem where the goal is to find the shortest program that generates the puzzle data. A 76K-parameter equivariant neural network is optimized from scratch for each puzzle, minimizing a loss function composed of KL divergence (latent complexity) and cross-entropy reconstruction error. The architecture uses specialized "multitensor" layers that guarantee equivariance to common ARC-AGI transformations like color permutations and rotations. Inference-time learning allows the model to adapt its entire parameter space to the specific regularities of a single puzzle, achieving generalization without any external training data.

## Key Results
- Solves 20% of ARC-AGI-1 evaluation puzzles with exact grid match
- Achieves generalization from as few as two demonstration pairs
- Requires ~20 minutes of optimization per puzzle at inference time
- Uses only 76K parameters compared to typical pretrained models

## Why This Works (Mechanism)

### Mechanism 1: MDL-Based Pattern Discovery
The method optimizes network weights and latent variables to minimize description length, incentivizing discovery of underlying patterns rather than memorization. The loss function (KL + Cross-Entropy) serves as a differentiable proxy for the total bit-length of a program generating the puzzle data. Lower program length implies discovery of more efficient, generalizable rules (e.g., "color the box based on direction") rather than storing raw pixel data. This applies Occam's razor to neural network optimization.

### Mechanism 2: Equivariance for Symmetry-Aware Learning
The architecture enforces equivariance to transformations common in ARC-AGI (permutations of examples, colors, rotations, flips) using specialized multitensor layers. This drastically reduces the search space and forces the model to learn symmetry-aware rules by default. To solve asymmetric puzzles, the model must expend "bits" in its latent code to break these symmetries in a controlled way, localizing variations as compact exceptions.

### Mechanism 3: Inference-Time Adaptation
Instead of fixed weights from pretraining, the entire network and latent distribution parameters are optimized from scratch for each puzzle using gradient descent. The network "learns" the specific rule of the puzzle by fitting demonstration pairs, and this learned rule is then applied to the test input. This allows adaptation to the specific regularities of a single puzzle, achieving generalization without requiring large datasets.

## Foundational Learning

- **Concept: Minimum Description Length (MDL) and Kolmogorov Complexity**
  - Why needed here: This is the core theoretical justification. Understanding that the loss function (KL + Cross-Entropy) is a proxy for finding the shortest program (Kolmogorov complexity) is essential to grasp why the method should generalize.
  - Quick check question: Explain how the KL divergence term in the loss function relates to the length of a program's code.

- **Concept: Equivariance in Neural Networks**
  - Why needed here: The architecture is built on this principle. Understanding equivariance is necessary to comprehend how the model imposes structural priors (e.g., "a rule should be the same if I swap the training examples") and reduces the effective search space.
  - Quick check question: If an input image is rotated 90 degrees, what should happen to the output of an equivariant layer?

- **Concept: Variational Autoencoders (VAEs) and Relative Entropy Coding (REC)**
  - Why needed here: The paper frames its method as analogous to a VAE decoder and uses concepts from REC to justify its loss function approximation. A basic understanding of latent variables and reconstruction loss is needed.
  - Quick check question: In a VAE, what are the two competing terms in the loss function, and how do they map to the components of CompressARC's loss?

## Architecture Onboarding

- **Component map:**
  Input Preprocessing -> Multitensor Format -> Decoding Layer -> Residual Backbone -> Specialized Layers -> Linear Heads -> Loss Computation

- **Critical path:**
  1. Puzzle is loaded and preprocessed into a multitensor with a target shape
  2. The latent code z is sampled from an initial distribution N(μ, Σ)
  3. The z tensor passes through the decoding layer and into the core residual backbone
  4. The backbone applies a sequence of equivariant operations (communication, softmax, cummax, etc.) to transform z into a representation of the puzzle
  5. The final linear heads convert this representation into probability distributions over pixel colors and grid shapes
  6. The total description length (Loss = KL + CrossEntropy) is computed
  7. Gradients update μ, Σ and all network weights θ
  8. After many steps, the model is used to sample a final solution grid

- **Design tradeoffs:**
  - **Architectural Complexity vs. Program Length:** The authors hand-designed a complex, specialized architecture with many custom layers. This makes the "template program" long, but it allows the "seeds" (weights) to be shorter. A simpler architecture would require longer seeds, which might not be found.
  - **Compute vs. Accuracy:** Solving each puzzle requires thousands of optimization steps (reported as ~20 mins/puzzle), making the approach computationally expensive at inference time compared to a single forward pass of a pretrained model.
  - **Generalization vs. Fitting:** The MDL principle is the only mechanism preventing the network from simply memorizing the demonstration pairs with an arbitrarily complex latent code. The KL penalty forces a balance.

- **Failure signatures:**
  - **Mode Collapse:** Certain tensors in the latent code z may see their KL contribution fall to zero, meaning they carry no information. The paper notes this is hard to recover from (Section K.3).
  - **Noise Amplification:** Operations like directional cummax can propagate noise. The architecture uses normalization and specific initializations to mitigate this.
  - **Inability to Plan:** The paper explicitly lists inability to plan or simulate agents as a failure mode (Section H), suggesting limitations in sequential reasoning.

- **First 3 experiments:**
  1. **Reproduce on a subset:** Run the provided code on a few simple training puzzles (e.g., 272f95fa "Color the Boxes") to verify the training loop and confirm the loss decreases and the sampled output stabilizes. This validates the implementation.
  2. **Ablate Equivariance:** Remove the directional cummax/shift layers or break the permutation equivariance by using standard convolutions. Measure performance on puzzles that require these spatial operations to confirm their contribution.
  3. **Vary Compute Budget:** Run the solver with significantly fewer training steps (e.g., 100, 500, 1000) to plot the accuracy curve (pass@k) against compute time. This quantifies the trade-off between inference cost and performance and identifies the point of diminishing returns.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can joint compression through weight sharing across puzzles significantly improve solve rates compared to independent puzzle compression?
- Basis in paper: [explicit] Appendix K.1: "We might be able to further shorten the template program length by sharing a single θ between all the puzzles, enhancing the compression and creating more correct puzzle solutions."
- Why unresolved: The authors considered this approach but did not implement it because it would require running all puzzles in parallel, slowing down research iteration.
- What evidence would resolve it: Experiments with LoRA-based weight perturbations or hypernetwork-based puzzle embeddings that share base weights across puzzles.

### Open Question 2
- Question: Can a scheduled KL floor prevent posterior collapse and improve training consistency?
- Basis in paper: [explicit] Appendix K.3: "If we artificially hold the KL above zero for an extended period of training, then the network may learn to use the tensor's information, incentivizing the KL to stay above zero when released again."
- Why unresolved: The authors implemented a KL floor but found the network did not learn fast enough; they suggest exploring decay schedules but did not test them.
- What evidence would resolve it: Ablation studies comparing different KL floor schedules and their effects on tensor recovery rates and final solve accuracy.

### Open Question 3
- Question: Would explicitly compressing the network weights θ through regularization improve CompressARC's performance?
- Basis in paper: [explicit] Appendix K.4: "It is somewhat reckless for us to neglect compressing θ in our work due to the sheer number of bits θ contributes, and making this change may improve our results."
- Why unresolved: The current method treats θ as uncompressed program overhead; the authors acknowledge this violates strict MDL principles but did not implement weight compression.
- What evidence would resolve it: Experiments adding L2 regularization to θ and measuring resulting solve rates on evaluation puzzles.

### Open Question 4
- Question: Can architectures with inductive biases for shape copying operations improve performance on the subset of puzzles requiring such transformations?
- Basis in paper: [inferred] Appendix K.2 and H document that CompressARC cannot perform translation, rotation, reflection, or rescaling—abilities that convolution-like layers might enable. The authors tried tropical convolutions but discarded them.
- Why unresolved: Standard convolutions amplify noise; tropical convolutions worked on toy puzzles but not ARC-AGI training puzzles. The fundamental question of whether neural shape-copying operations can be made viable remains open.
- What evidence would resolve it: Novel convolution variants tested specifically on the shape-transformation puzzles listed as unsolvable (e.g., puzzles 0e206a2e, 5ad4f10b, 2bcee788).

## Limitations
- Extremely expensive inference-time optimization (~20 minutes per puzzle) compared to pretrained models
- Specialized architecture may not generalize beyond ARC-AGI-style puzzles with specific symmetry groups
- Only achieves 20% accuracy on evaluation puzzles, leaving 80% unsolved
- Method's scalability to harder problems or larger models remains unproven

## Confidence
- **High Confidence:** The core mechanism of framing ARC-AGI as a code-golfing problem using MDL principles is clearly explained and supported by the paper's mathematical framework. The experimental results showing 20% accuracy on evaluation puzzles are directly stated.
- **Medium Confidence:** The explanation of how equivariance layers contribute to generalization is reasonable but lacks extensive empirical validation. The paper describes the architecture's design choices but doesn't provide ablation studies proving the necessity of each component.
- **Low Confidence:** Claims about the method's broader implications for AI development ("suggesting MDL as an alternative path to intelligence beyond conventional pretraining") are speculative. The paper doesn't demonstrate this approach's effectiveness on other benchmark tasks or compare it meaningfully to conventional pretraining methods.

## Next Checks
1. **Ablation Study of Architectural Components:** Remove the directional cummax/shift layers or break the permutation equivariance by using standard convolutions, then measure performance degradation on puzzles that require these spatial operations. This would quantify the contribution of each specialized component to the overall success rate.

2. **Compute Budget Sensitivity Analysis:** Systematically vary the optimization steps (e.g., 100, 500, 1000, 2000) and plot pass@k accuracy against inference time. This would reveal the point of diminishing returns and help assess whether the method's computational cost is justified by its performance gains.

3. **Cross-Domain Generalization Test:** Apply the same MDL-based inference-time learning approach to a different reasoning task (such as the Enigmata logical reasoning puzzles or linguistic Olympiad puzzles mentioned in the corpus) using an appropriately modified architecture. This would test whether the core insight extends beyond ARC-AGI's specific visual reasoning domain.