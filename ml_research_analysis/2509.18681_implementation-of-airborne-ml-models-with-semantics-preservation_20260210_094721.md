---
ver: rpa2
title: Implementation of airborne ML models with semantics preservation
arxiv_id: '2509.18681'
source_url: https://arxiv.org/abs/2509.18681
tags:
- mlmd
- onnx
- metric
- which
- semantics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to verify that an ML model replicated
  in a target environment (TIM) preserves the same properties as the original model
  (TFM) verified during training. The approach defines semantic levels of ML model
  representation and uses metrics with associated error margins to ensure properties
  like accuracy and generalization are maintained despite differences in numerical
  precision or hardware.
---

# Implementation of airborne ML models with semantics preservation

## Quick Facts
- arXiv ID: 2509.18681
- Source URL: https://arxiv.org/abs/2509.18681
- Reference count: 40
- Primary result: Method to verify ML model replication preserves original properties using error margins

## Executive Summary
This paper addresses the critical challenge of verifying that a machine learning model deployed in an embedded system (Target Implementation Model) preserves the same properties as the original model trained in a development environment (Training Framework Model). The authors propose a semantic preservation framework that defines different levels of ML model representation and establishes metrics with associated error margins to ensure properties like accuracy and generalization are maintained despite differences in numerical precision or hardware. The approach is demonstrated on industrial use cases including helicopter avionics, showing that C code generated from ONNX models can replicate the original model's behavior within acceptable bounds.

## Method Summary
The authors define a semantic preservation framework with four levels of ML model representation, from abstract mathematical functions to concrete binary implementations. They establish a method to verify that a Target Implementation Model (TIM) preserves the properties of the original Training Framework Model (TFM) by checking if the maximum prediction error remains within a calculated error margin (ε_M). The process involves training models in a high-precision environment (Keras with FP32), exporting to ONNX format, generating C code using various tools (acetone, onnx2c, or Scade), and then verifying that the TIM's predictions on the test set do not exceed the error margin calculated from the TFM's performance metrics. The framework accounts for hardware-specific factors like floating-point precision and fused multiply-add operations.

## Key Results
- Successfully demonstrated semantic preservation for helicopter avionics use cases (weight estimation via LSTM, load computation via MLP)
- Verified that C code generated from ONNX models running on embedded platforms can replicate TFM behavior within acceptable error bounds
- Found that very low numerical precision formats can cause TIM predictions to exceed error margins
- Showed that models can be exactly replicated on target systems by comparing predictions against defined metrics and error margins

## Why This Works (Mechanism)
The method works by establishing a formal verification framework that bridges the semantic gap between abstract model definitions and concrete implementations. By defining multiple semantic levels of representation and using metrics with explicit error margins, the approach provides a quantifiable way to ensure that transformations through the ML deployment pipeline don't degrade model performance beyond acceptable bounds.

## Foundational Learning
- **Semantic levels of ML representation (SL0-SL3)**: Understanding these levels is crucial for identifying where semantic information might be lost during deployment. Quick check: Map your model transformation pipeline to these semantic levels to identify potential information loss points.
- **Error margin calculation (ε_M)**: The process of determining acceptable prediction error based on model performance metrics. Quick check: Verify your ε_M calculation accounts for both model uncertainty and hardware precision limitations.
- **ONNX as intermediate representation**: Serves as the bridge between high-level frameworks and target implementations. Quick check: Validate that your ONNX export preserves all necessary computational semantics of your original model.

## Architecture Onboarding
- **Component map**: TFM (Keras/FP32) -> ONNX export -> C code generation (acetone/onnx2c/Scade) -> TIM (embedded target)
- **Critical path**: Model training → ONNX conversion → C generation → Compilation → Prediction comparison with ε_M validation
- **Design tradeoffs**: Higher precision implementations preserve more semantic information but require more resources; lower precision saves resources but may violate ε_M
- **Failure signatures**: Prediction errors exceeding ε_M, operator decomposition failures in ONNX-to-C conversion, precision-related rounding errors
- **First experiments**: 1) Export simple Keras model to ONNX and inspect graph structure, 2) Generate C code from ONNX and verify compilation, 3) Compare TFM vs TIM predictions on small test set

## Open Questions the Paper Calls Out
- How can a sound proof of the error margin threshold (ε_M) be established without relying on the test set sampling used in this study?
- How can specific input space sampling strategies be developed to bound the probability of the TIM exceeding the error margin (P(ε > ε_M) < P_M)?
- How can intermediate ML representations (like ONNX) be enhanced to fully capture SL1 semantics regarding operator overflow and machine number limitations?

## Limitations
- Relies on proprietary industrial data and models, preventing exact replication of reported results
- Verification methodology depends critically on accurate computation of error margins (ε_M) that are context-specific
- ONNX-to-C code generation process may encounter compatibility issues with certain operators, particularly complex recurrent cell implementations

## Confidence
- High confidence: The semantic preservation framework itself is theoretically sound and well-articulated
- Medium confidence: The industrial application demonstrates feasibility but cannot be independently verified
- Low confidence: Specific numerical thresholds and error margins would differ substantially for any non-proprietary dataset

## Next Checks
1. Cross-Platform Consistency: Reproduce the TFM→TIM verification pipeline using a public regression dataset and compare prediction consistency across different target architectures
2. Operator Coverage Testing: Systematically test ONNX-to-C generators on a suite of common neural network operations to identify decomposition requirements and precision degradation patterns
3. Threshold Sensitivity Analysis: Vary the ε_M calculation method and assess impact on verification pass/fail rates for a fixed TFM/TIM pair