---
ver: rpa2
title: Unveiling the Training Dynamics of ReLU Networks through a Linear Lens
arxiv_id: '2511.05628'
source_url: https://arxiv.org/abs/2511.05628
tags:
- effective
- network
- weights
- linear
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel analytical framework for understanding
  the training dynamics of ReLU networks by recasting them as input-dependent linear
  models. The core idea is to define an "effective weight matrix" Weff(x) for each
  input sample, which captures the unique linear transformation the network applies
  to that specific input.
---

# Unveiling the Training Dynamics of ReLU Networks through a Linear Lens

## Quick Facts
- arXiv ID: 2511.05628
- Source URL: https://arxiv.org/abs/2511.05628
- Authors: Longqing Ye
- Reference count: 1
- Primary result: Introduces an analytical framework recasting ReLU networks as input-dependent linear models through "effective weight matrices" to reveal representation learning dynamics.

## Executive Summary
This paper presents a novel analytical framework for understanding how ReLU networks learn during training by viewing them as input-dependent linear models. The core innovation is the introduction of an "effective weight matrix" Weff(x) for each input sample, which captures the unique linear transformation the network applies to that specific input by composing active weights across all layers according to ReLU activation patterns. This framework enables tracking how representations evolve during training, revealing that effective weights for samples from the same class converge while those from different classes diverge, providing new insights into how neural networks form class-specific decision boundaries and semantic representations.

## Method Summary
The paper introduces a framework that recasts ReLU networks as input-dependent linear models by defining an "effective weight matrix" Weff(x) for each input sample. This matrix is computed by composing the active weights across all layers, considering the ReLU activation patterns that are specific to each input. By tracking the evolution of these effective weights during training, the framework reveals fundamental principles of representation learning, showing how networks transform initially structured but confused representations into highly organized, semantically effective ones.

## Key Results
- Effective weights for samples from the same class converge during training while those from different classes diverge
- t-SNE projections of effective weight manifolds show a transition from initially structured but confused space to highly organized, semantically effective representations
- The framework provides a new lens for interpreting how neural networks learn class-specific decision boundaries and semantic representations through a dynamic, input-dependent understanding

## Why This Works (Mechanism)
The framework works by exploiting the piecewise-linear nature of ReLU networks. Since ReLU activations create input-dependent linear regions, each input experiences a unique linear transformation defined by which neurons are active. The effective weight matrix Weff(x) captures this transformation by composing the active weights across layers. During training, gradient updates modify these effective weights, and the framework reveals that optimization naturally drives effective weights for same-class samples to converge while pushing different-class samples apart, thereby forming discriminative representations.

## Foundational Learning
- **Piecewise-linear nature of ReLU networks**: Why needed - To understand how ReLU networks can be viewed as collections of linear functions. Quick check - Verify that ReLU(x) = max(0,x) creates linear regions separated by hyperplanes.
- **Input-dependent activation patterns**: Why needed - To grasp why each input experiences a unique linear transformation. Quick check - Trace through a simple 2-layer network to see how ReLU activations differ for different inputs.
- **Matrix composition across layers**: Why needed - To understand how effective weights are computed from individual layer weights. Quick check - Verify that for a linear network, W_eff = W_n * ... * W_1 for input-dependent active weights.
- **t-SNE dimensionality reduction**: Why needed - To visualize high-dimensional effective weight manifolds in 2D/3D space. Quick check - Apply t-SNE to a synthetic dataset with known clusters to verify it preserves local structure.

## Architecture Onboarding

**Component Map**: Input -> ReLU layers -> Output layer -> Effective weight computation -> t-SNE visualization

**Critical Path**: Forward pass through network → Identify active neurons per layer → Compose active weights into Weff(x) → Track Weff evolution during training → Visualize with t-SNE

**Design Tradeoffs**: The framework trades computational efficiency for interpretability - tracking effective weights for all inputs during training is computationally expensive but provides rich insights into representation dynamics. Alternative approaches might sample inputs or use approximations to reduce cost.

**Failure Signatures**: If effective weights show no convergence within classes or no divergence between classes, this could indicate optimization issues, poor network capacity, or that the dataset lacks clear class structure. If t-SNE visualizations appear random rather than showing clear organization, this might suggest the effective weight representation isn't capturing meaningful structure.

**First Experiments**: 1) Apply the framework to a simple synthetic dataset with clearly separable classes to verify expected convergence/divergence patterns. 2) Test on a standard benchmark like MNIST to compare with known learning dynamics. 3) Apply to a network with random labels to see if effective weights still show convergence within classes (testing whether the framework captures true semantic structure or just statistical patterns).

## Open Questions the Paper Calls Out
None

## Limitations
- Key methodological details and empirical validation results remain unspecified, making reproducibility uncertain
- Computational complexity of tracking effective weights for all inputs during training could be prohibitive for large models
- Empirical claims about convergence/divergence patterns lack quantitative supporting evidence

## Confidence
- Low confidence: Universal applicability across different network architectures, quantitative significance of observed patterns, interpretability of effective weight trajectories
- Medium confidence: Theoretical foundation that ReLU networks can be viewed as input-dependent linear models
- Low confidence: Assertion that this framework provides a "new lens" for interpreting neural network training

## Next Checks
1. Implement the effective weight computation algorithm for a simple feedforward network and verify that the composed weights accurately capture the input-dependent linear transformation through controlled synthetic experiments.

2. Conduct quantitative analysis of effective weight convergence/divergence by measuring within-class and between-class distances over training epochs, comparing these metrics across multiple random seeds and network initializations.

3. Evaluate computational scalability by measuring the runtime overhead of tracking effective weights during training for networks of increasing depth and width, and assess whether the insights gained justify the computational cost.