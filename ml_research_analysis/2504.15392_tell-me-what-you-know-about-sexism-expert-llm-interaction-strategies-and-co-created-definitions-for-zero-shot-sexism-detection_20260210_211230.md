---
ver: rpa2
title: 'Tell Me What You Know About Sexism: Expert-LLM Interaction Strategies and
  Co-Created Definitions for Zero-Shot Sexism Detection'
arxiv_id: '2504.15392'
source_url: https://arxiv.org/abs/2504.15392
tags:
- sexism
- definitions
- definition
- experts
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates hybrid intelligence between sexism researchers
  and LLMs through a four-component pipeline. Nine experts first answered questions
  about their LLM expertise, then assessed an LLM's knowledge of sexism and co-created
  definitions with it.
---

# Tell Me What You Know About Sexism: Expert-LLM Interaction Strategies and Co-Created Definitions for Zero-Shot Sexism Detection

## Quick Facts
- **arXiv ID:** 2504.15392
- **Source URL:** https://arxiv.org/abs/2504.15392
- **Reference count:** 40
- **Key outcome:** Hybrid intelligence between experts and LLMs improves sexism detection, with LLM-generated definitions generally outperforming expert-written ones

## Executive Summary
This study investigates hybrid intelligence between sexism researchers and LLMs through a four-component pipeline. Nine experts first answered questions about their LLM expertise, then assessed an LLM's knowledge of sexism and co-created definitions with it. Finally, zero-shot classification experiments evaluated GPT4o using three definitions per expert (expert-written, LLM-generated, co-created) on 2,500 texts from five sexism benchmarks. The study found that LLM-generated definitions outperformed expert-written ones in classification, though some experts improved performance with co-created definitions. Expert-LLM interactions led to longer, more complex definitions. Results suggest that while LLM-generated definitions generally perform best for zero-shot sexism detection, hybrid intelligence approaches can benefit certain experts, particularly those less experienced with LLMs.

## Method Summary
The study employed a four-component pipeline to investigate expert-LLM collaboration for sexism detection. First, experts completed a background questionnaire about their LLM experience and sexism expertise. Second, they evaluated an LLM's knowledge of sexism through direct questioning. Third, experts co-created definitions with the LLM through iterative dialogue. Finally, zero-shot classification experiments tested GPT4o using three definitions per expert (expert-written, LLM-generated, co-created) across five benchmark datasets containing 2,500 texts total. The approach aimed to understand how expert-LLM interaction strategies affect definition quality and downstream classification performance.

## Key Results
- LLM-generated definitions outperformed expert-written definitions in zero-shot classification across all five benchmarks
- Some experts (particularly those with lower LLM expertise) achieved better performance with co-created definitions than with either expert-written or LLM-generated definitions alone
- Expert-LLM interactions resulted in longer, more complex definitions with increased elaboration and detail

## Why This Works (Mechanism)
The success of LLM-generated definitions in zero-shot classification likely stems from LLMs' ability to synthesize patterns from large-scale training data, capturing subtle linguistic patterns that human experts might overlook or underspecify. The co-creation process benefits experts with limited LLM experience by exposing them to the LLM's reasoning patterns and terminology, effectively bridging their knowledge gap through guided interaction.

## Foundational Learning
- **Zero-shot classification**: Classification without model fine-tuning, using only prompt-based instructions - needed because it tests definition quality in isolation from model adaptation
- **Hybrid intelligence**: Collaborative problem-solving between humans and AI systems - needed to understand complementary strengths and limitations
- **Definition quality metrics**: Measures of definition clarity, completeness, and operationalizability - needed to evaluate whether definitions can effectively guide classification
- **Prompt engineering**: Crafting effective instructions for LLMs - needed because small changes in definition formulation can significantly impact classification outcomes
- **Benchmark diversity**: Using multiple datasets to test generalizability - needed to ensure findings aren't specific to particular text types or contexts

## Architecture Onboarding

**Component Map:** Expert Background Assessment -> LLM Knowledge Evaluation -> Definition Co-Creation -> Zero-Shot Classification Testing

**Critical Path:** The definition co-creation phase is critical as it determines the quality of input for the classification experiments. Poor co-creation outcomes directly degrade classification performance.

**Design Tradeoffs:** The study prioritized methodological rigor over scalability by limiting expert numbers (9) but ensuring diverse expertise levels. This provides deep insights into interaction strategies but may limit generalizability.

**Failure Signatures:** If LLM-generated definitions underperform, it suggests either domain-specific limitations of the LLM or that sexism detection requires nuanced understanding beyond pattern matching. If co-created definitions don't improve performance for low-expertise experts, it indicates insufficient transfer of LLM capabilities.

**First Experiments:**
1. Test the same definitions on a non-English sexism dataset to evaluate cross-linguistic robustness
2. Compare zero-shot results with few-shot classification using the same definitions as exemplars
3. Conduct expert interviews to understand which co-creation interaction patterns correlate with performance improvements

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on single LLM (GPT4o) limits generalizability to other models or domains
- Small expert sample (9) may not represent full spectrum of sexism research expertise
- Zero-shot classification approach doesn't reflect real-world scenarios where labeled data is typically available
- Potential domain-specific nature of LLM performance on sexism detection

## Confidence
- **Main finding (LLM-generated definitions outperform expert-written):** Medium-High
- **Hybrid intelligence benefits:** Medium
- **Methodological contributions:** Medium-High

## Next Checks
1. Replicate the study with additional LLMs (e.g., Claude, Llama) to assess whether performance patterns hold across different model architectures
2. Test the definitions on out-of-domain datasets (e.g., non-English texts, historical documents) to evaluate robustness
3. Conduct a longitudinal study to determine if repeated expert-LLM interactions lead to improved co-creation outcomes over time