---
ver: rpa2
title: Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language
  Models
arxiv_id: '2508.18651'
source_url: https://arxiv.org/abs/2508.18651
tags:
- knowledge
- code
- wang
- faithfulness
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the trade-off between faithfulness and expressiveness
  in knowledge-grounded large language models. The proposed Collaborative Decoding
  (CoDe) method dynamically fuses internal and external knowledge distributions using
  Jensen-Shannon Divergence and model confidence, guided by adaptive fusion weights.
---

# Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models

## Quick Facts
- arXiv ID: 2508.18651
- Source URL: https://arxiv.org/abs/2508.18651
- Authors: Chenxu Yang; Qingyi Si; Zheng Lin
- Reference count: 33
- Key outcome: Proposes Collaborative Decoding (CoDe) to dynamically fuse internal and external knowledge, achieving state-of-the-art performance across six LLMs, three datasets, and nine evaluation metrics while improving faithfulness by up to 3.9%

## Executive Summary
This paper addresses the fundamental trade-off between faithfulness (accuracy of generated content to source knowledge) and expressiveness (linguistic quality and diversity) in knowledge-grounded large language models. The authors propose Collaborative Decoding (CoDe), a method that dynamically fuses internal and external knowledge distributions using Jensen-Shannon Divergence and model confidence, guided by adaptive fusion weights. A knowledge-aware reranking mechanism further ensures faithful responses while maintaining high-quality output.

The proposed framework achieves state-of-the-art performance across multiple evaluation settings, outperforming ten baseline decoding methods. By integrating both internal model knowledge and external grounding information in a dynamic, context-aware manner, CoDe successfully breaks the traditional trade-off, improving faithfulness metrics by up to 3.9% while maintaining superior expressiveness across diverse benchmarks.

## Method Summary
The Collaborative Decoding (CoDe) framework operates by dynamically fusing internal and external knowledge distributions during the decoding process. The method uses Jensen-Shannon Divergence to measure the difference between these distributions and employs model confidence scores to guide adaptive fusion weights. During generation, the model continuously evaluates the reliability of both internal and external knowledge sources, adjusting the fusion weights in real-time based on context. A knowledge-aware reranking mechanism is applied post-generation to ensure the final output maintains faithfulness to the source knowledge while preserving linguistic quality. The approach is evaluated across six different LLMs, three knowledge-grounded datasets, and nine distinct evaluation metrics, demonstrating consistent improvements over existing decoding strategies.

## Key Results
- Achieves state-of-the-art performance across six LLMs, three datasets, and nine evaluation metrics
- Improves faithfulness by up to 3.9% while maintaining superior expressiveness
- Outperforms ten baseline decoding methods
- Successfully breaks the traditional trade-off between faithfulness and expressiveness

## Why This Works (Mechanism)
The method works by addressing the core challenge in knowledge-grounded generation: models often rely too heavily on either their internal parametric knowledge or external sources, leading to either hallucinations or overly constrained responses. CoDe's adaptive fusion mechanism allows the model to dynamically balance these sources based on context-specific reliability. The Jensen-Shannon Divergence provides a principled way to measure distribution differences, while the confidence-based weighting ensures that the model gives more weight to reliable sources in ambiguous situations. The knowledge-aware reranking acts as a final safeguard, filtering out responses that deviate from the source knowledge while preserving high-quality language generation.

## Foundational Learning

**Jensen-Shannon Divergence**: Measures similarity between probability distributions; needed to quantify differences between internal and external knowledge distributions; quick check: values range from 0 (identical) to 1 (completely different)

**Adaptive Fusion Weights**: Dynamic weighting mechanism that adjusts based on context and reliability; needed to balance internal vs external knowledge in real-time; quick check: weights sum to 1 and vary across tokens

**Knowledge-Aware Reranking**: Post-generation filtering mechanism; needed to ensure final outputs meet faithfulness criteria; quick check: reranked outputs consistently score higher on faithfulness metrics

## Architecture Onboarding

**Component Map**: Input Knowledge Sources -> JS Divergence Calculator -> Confidence Estimator -> Adaptive Weight Generator -> Dynamic Fuser -> Decoder -> Knowledge-Aware Reranker -> Final Output

**Critical Path**: The dynamic fusion and reranking components are critical - they directly impact both faithfulness and expressiveness metrics. The JS divergence calculation must be efficient to avoid latency issues during generation.

**Design Tradeoffs**: Computational overhead vs performance gain (reranking adds latency but improves faithfulness), model complexity vs generalizability (adaptive weights work well on tested datasets but may need tuning for new domains), and precision vs recall in knowledge matching (stricter matching improves faithfulness but may reduce expressiveness).

**Failure Signatures**: Over-reliance on external knowledge (loss of expressiveness), excessive internal knowledge use (hallucinations), inconsistent fusion weights across similar contexts (unstable performance), and reranking that overly constrains generation (reduced diversity).

**First Experiments**:
1. Ablation study removing JS divergence component to measure its individual contribution
2. Testing with fixed vs adaptive fusion weights to quantify dynamic adjustment benefits
3. Comparing different reranking thresholds to optimize faithfulness-expressiveness balance

## Open Questions the Paper Calls Out
None

## Limitations
- Statistical significance of 3.9% faithfulness improvement needs verification across multiple runs
- Computational overhead from knowledge-aware reranking mechanism not fully characterized
- Generalizability to out-of-domain knowledge sources and significantly different question types remains uncertain
- Effectiveness may depend heavily on specific dataset characteristics and evaluation protocols

## Confidence

**Methodological claims**: High - The CoDe framework's core approach using collaborative decoding with Jensen-Shannon Divergence is well-defined and theoretically grounded

**Performance improvements**: Medium - While consistent improvements are reported, practical significance needs independent verification and statistical significance testing

**Trade-off breaking claim**: Low - The claim of fundamentally breaking the trade-off is strong and requires extensive validation beyond the reported improvements

## Next Checks

1. Conduct ablation studies removing individual components (JS divergence weighting, confidence-based fusion, knowledge-aware reranking) to quantify their individual contributions to performance improvements.

2. Test the method on out-of-distribution knowledge sources and questions that are significantly different from training and evaluation datasets to assess true generalizability.

3. Perform extensive statistical significance testing across all reported metrics with multiple runs to confirm observed improvements are not due to random variation.