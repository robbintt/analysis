---
ver: rpa2
title: Verbalized Algorithms
arxiv_id: '2509.08150'
source_url: https://arxiv.org/abs/2509.08150
tags:
- verbalized
- algorithms
- sorting
- language
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Verbalized algorithms decompose reasoning tasks into simple LLM-based\
  \ atomic operations while retaining classical algorithms' theoretical guarantees.\
  \ The paper demonstrates this approach on four tasks: finding maximum (O(n) runtime),\
  \ sorting (O(n log n) or O((log n)\xB2) with parallelism), clustering (O(n log n)),\
  \ and submodular maximization (1 - 1/e optimality)."
---

# Verbalized Algorithms

## Quick Facts
- **arXiv ID**: 2509.08150
- **Source URL**: https://arxiv.org/abs/2509.08150
- **Reference count**: 24
- **Key outcome**: Verbalized algorithms significantly outperform or match baseline approaches even with small models—for example, a 1.7B model verbalized sorting achieved better accuracy than a 32B baseline.

## Executive Summary
Verbalized algorithms decompose complex reasoning tasks into simple LLM-based atomic operations while retaining classical algorithms' theoretical guarantees. The approach transforms LLM inference from open-ended generation into constrained binary operations (yes/no comparisons), enabling classical algorithms to run with LLMs as oracles. This method achieves better performance than naive approaches across four tasks: finding maximum (O(n) runtime), sorting (O(n log n) or O((log n)²) with parallelism), clustering (O(n log n)), and submodular maximization (1 - 1/e optimality).

## Method Summary
The method replaces classical algorithm oracles with LLM queries while preserving the algorithm's control flow. For example, sorting algorithms use LLM-based comparisons instead of native comparisons, clustering algorithms use LLM-based triplet similarity queries, and submodular maximization uses LLM-based greedy selection. The approach includes robustification via majority voting (K=3 samples) and symmetrization to correct positional bias. No training is required—only inference with constrained decoding to ensure binary outputs. The work uses Qwen3 models (1.7B, 4B, 32B) and demonstrates that smaller models with verbalized algorithms can outperform larger baseline models.

## Key Results
- A 1.7B verbalized sorting model achieved better accuracy than a 32B baseline model
- Bitonic sorting network achieved 2.3x speedup through parallelism
- Verbalized algorithms maintain correctness guarantees that naive LLM approaches lack (avoiding missing/duplicated elements)
- Outperformed embedding methods on out-of-distribution tasks (clustering by lightness vs hue)

## Why This Works (Mechanism)

### Mechanism 1: Atomic Operation Restriction
LLMs perform simple classification/comparison tasks with higher fidelity than complex multi-step reasoning. Classical algorithms are decomposed into elementary operations (e.g., binary comparisons "Is X > Y?") that constrain LLM output to {yes, no} via constrained decoding. The LLM never sees the full problem state—only pairs.

### Mechanism 2: Theoretical Guarantee Transfer via Oracle Substitution
Replacing the comparison oracle in a classical algorithm with an LLM preserves algorithmic guarantees if the oracle is sufficiently accurate. A verbalized algorithm instantiates algorithm A[τ] with τ=str, implementing f[str] as an LLM query while keeping the control flow unchanged.

### Mechanism 3: Robustification via Redundancy and Symmetrization
Sampling K=3 outputs with majority voting improves comparison accuracy exponentially in K; symmetrization mitigates positional bias and sycophancy by querying both (p₁₂ + (1-p₂₁))/2.

## Foundational Learning

- **Comparison-based sorting complexity (O(n log n))**
  - Why needed: Understanding why verbalized sorting uses Powersort or bitonic networks—not insertion sort—requires knowing the lower bound.
  - Quick check: Explain why any comparison-based sorting algorithm requires at least Ω(n log n) comparisons.

- **Submodularity and diminishing returns**
  - Why needed: VGSM (verbalized greedy submodular maximization) relies on greedy selection achieving (1-1/e) approximation for monotone submodular functions.
  - Quick check: Given a set function f, what property must f satisfy for greedy selection to guarantee constant-factor optimality?

- **Prefix KV-cache sharing in Transformers**
  - Why needed: Runtime analysis shows 1.4x–2.3x speedup from caching shared prefixes across comparison queries.
  - Quick check: In batched LLM inference with shared prompt prefix, how does prefix caching change the per-query attention computation from O(L_p + L)² to O(L²)?

## Architecture Onboarding

- **Component map**: Input strings -> Algorithm Controller -> Batching Engine -> Cache Manager -> LLM Oracle Layer -> Majority Voting (if robust) -> Boolean result -> Algorithm proceeds
- **Critical path**: Input strings → algorithm controller initiates comparisons → comparison query → LLM oracle with constrained decoding → batching engine groups independent queries → cache manager reuses prefix KV-cache → majority voting (if robust VA) → boolean result → algorithm proceeds with result; repeat until termination
- **Design tradeoffs**: Naive vs. Robust VA (accuracy 2–5x better but 3x cost); Sequential vs. Parallel Sorting (bitonic increases total comparisons but reduces latency); Symmetrized vs. Naive Probabilistic (corrects systematic bias but requires 2 queries)
- **Failure signatures**: Missing/duplicate elements in output indicates baseline constraint decoding failure; accuracy degrades with input size for non-VA methods; performance collapse on OOD tasks with embedding methods
- **First 3 experiments**: 1) Reproduce verbalized maximum on n=100 random integers comparing baseline vs verbalized using 1.7B and 4B models; 2) Benchmark bitonic vs Powersort latency on n=128 strings using 32B model; 3) Test clustering OOD generalization on xkcdcolors-l

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can Floyd's tortoise-and-hare cycle detection algorithm be verbalized to detect tautologies?
- **Basis**: The authors explicitly ask, "Can Floyd's tortoise-and-hare cycle detection algorithm for linked lists be verbalized to perform a tautology detection?"
- **Why unresolved**: This is a speculative application requiring a mapping between graph traversal and semantic logic.
- **What evidence would resolve it**: A successful implementation of verbalized cycle detection tested on logical formulas to identify tautologies.

### Open Question 2
- **Question**: Can garbage collection algorithms be verbalized to identify unimportant sentences in text?
- **Basis**: The authors ask, "Can garbage collection algorithms detect unimportant sentences in a paper draft?"
- **Why unresolved**: This requires mapping "unreachable memory" to "irrelevant context," a non-trivial semantic challenge.
- **What evidence would resolve it**: An evaluation showing a verbalized mark-and-sweep algorithm effectively pruning irrelevant sentences while maintaining global coherence.

### Open Question 3
- **Question**: Does the reliability of the LLM "atomic oracle" degrade ungracefully as the context window of the prompt increases?
- **Basis**: The authors note that selecting from 48 candidates caused a 0.6B model's performance to drop compared to 24 candidates, citing "long context comprehension" challenges.
- **Why unresolved**: VAs rely on the assumption that the atomic operation is reliable; if the oracle's error rate increases significantly with input size, theoretical guarantees may not translate to practical accuracy.
- **What evidence would resolve it**: A sensitivity analysis measuring the oracle's accuracy as a function of the number of items included in the prompt context.

## Limitations

- The assumption of independent LLM comparison errors may not hold in practice, potentially invalidating theoretical error bounds
- Performance advantage on out-of-distribution tasks relies on a single illustrative example and needs broader validation
- The approach requires constrained decoding infrastructure that may not be available for all LLM deployments

## Confidence

- **High Confidence**: Runtime complexity claims (O(n), O(n log n), O((log n)²)) and parallelism benefits are mathematically sound and empirically demonstrated
- **Medium Confidence**: Transfer of algorithmic guarantees assumes oracle noise characteristics that are plausible but not rigorously validated
- **Low Confidence**: Generalizability claim for OOD tasks relies on limited empirical validation

## Next Checks

1. **Error Correlation Analysis**: Test whether LLM comparison errors exhibit systematic correlations across queries that would invalidate Hoeffding bound assumptions
2. **OOD Generalization Benchmark**: Evaluate verbalized vs. embedding clustering on at least 5 additional out-of-distribution tasks with varying similarity metrics
3. **Scalability Stress Test**: Measure performance degradation as input size increases to n=1000+ for sorting and clustering tasks to identify where verbalized algorithms outperform or underperform baseline approaches