---
ver: rpa2
title: Integration of Large Language Models and Traditional Deep Learning for Social
  Determinants of Health Prediction
arxiv_id: '2505.04655'
source_url: https://arxiv.org/abs/2505.04655
tags:
- sdoh
- dataset
- classi
- learning
- traditional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of automatically extracting
  Social Determinants of Health (SDoH) from clinical text using both traditional deep
  learning and Large Language Models (LLMs). The authors develop and evaluate multiple
  classification approaches, including supervised fine-tuned LLMs (Llama 3.1 and 3.3),
  traditional deep learning models (RoBERTa), and a novel two-step classifier that
  combines a binary traditional model for efficiency with an LLM for precision.
---

# Integration of Large Language Models and Traditional Deep Learning for Social Determinants of Health Prediction

## Quick Facts
- **arXiv ID**: 2505.04655
- **Source URL**: https://arxiv.org/abs/2505.04655
- **Reference count**: 39
- **Primary result**: Combines LLMs with traditional deep learning for SDoH extraction, achieving 10-point improvement over baseline with macro F1 of 0.67

## Executive Summary
This paper addresses the challenge of automatically extracting Social Determinants of Health (SDoH) from clinical text using both traditional deep learning and Large Language Models (LLMs). The authors develop and evaluate multiple classification approaches, including supervised fine-tuned LLMs (Llama 3.1 and 3.3), traditional deep learning models (RoBERTa), and a novel two-step classifier that combines a binary traditional model for efficiency with an LLM for precision. They train and evaluate these models on MIMIC-III clinical text data, both alone and supplemented with synthetic data. The best performing model achieves a macro F1 score of 0.67, outperforming a previous baseline by 10 points. The two-step classifier provides a favorable trade-off between accuracy (macro F1 0.62) and inference speed (12X faster than the smallest LLM). Cross-validation results show stable performance across folds, and ablation studies reveal the impact of different feature combinations on model performance. The authors also release their code, data splits, and prompts to facilitate reproducibility.

## Method Summary
The authors employ a multi-faceted approach to SDoH classification, comparing traditional deep learning models with fine-tuned LLMs and hybrid architectures. They use the MIMIC-III dataset for training and evaluation, creating both single-task and multi-task classification setups. The models are trained on clinical text alone and with synthetic data augmentation. A novel two-step classifier is introduced that first uses a binary traditional model to filter non-SDoH text, then applies an LLM for more precise classification. The study includes cross-validation for robustness assessment and ablation studies to understand feature contributions.

## Key Results
- Best model achieves macro F1 score of 0.67, outperforming previous baseline by 10 points
- Two-step classifier provides favorable trade-off: macro F1 0.62 with 12X faster inference than smallest LLM
- Cross-validation shows stable performance across folds
- Ablation studies reveal impact of different feature combinations on model performance

## Why This Works (Mechanism)
The integration of LLMs with traditional deep learning leverages the strengths of both approaches: LLMs provide strong contextual understanding and classification precision, while traditional models offer computational efficiency for initial filtering. The two-step architecture specifically addresses the trade-off between accuracy and speed by using a lightweight binary classifier to reduce the computational burden on the more expensive LLM. Synthetic data augmentation helps address class imbalance and improves model generalization by exposing the models to a wider variety of SDoH-related text patterns.

## Foundational Learning
- **SDoH Classification**: Extracting social determinants of health from clinical text is crucial for understanding patient contexts and improving care outcomes. Why needed: SDoH factors significantly impact health outcomes but are often buried in unstructured clinical notes. Quick check: Verify the seven SDoH categories align with standard healthcare frameworks.
- **LLM Fine-tuning**: Adapting pre-trained LLMs to specific classification tasks improves performance on domain-specific text. Why needed: General-purpose LLMs require adaptation to handle the specialized language and context of clinical documentation. Quick check: Confirm that fine-tuning data is properly balanced across SDoH categories.
- **Synthetic Data Augmentation**: Generating artificial training examples to address class imbalance and improve model generalization. Why needed: Clinical SDoH data is often limited and imbalanced, making augmentation valuable for robust model training. Quick check: Evaluate synthetic data quality to ensure it represents realistic clinical scenarios.
- **Two-Stage Classification**: Using a cascade of models where an initial filter reduces computational load on subsequent precise models. Why needed: Balances the trade-off between inference speed and classification accuracy in resource-constrained clinical settings. Quick check: Verify that the binary classifier effectively identifies true negatives to maximize efficiency gains.

## Architecture Onboarding

**Component Map**: Clinical Text -> Tokenizer -> Feature Extractor -> Binary Classifier -> LLM Classifier -> SDoH Categories

**Critical Path**: The binary traditional model serves as the critical path component, as it determines which texts proceed to the more computationally expensive LLM for detailed classification. Its accuracy directly impacts both speed gains and overall classification quality.

**Design Tradeoffs**: The primary tradeoff is between accuracy and inference speed. The two-step approach sacrifices some precision (macro F1 drops from 0.67 to 0.62) to achieve 12X faster inference. This tradeoff is justified for applications where real-time or high-throughput classification is needed, but may be less suitable for clinical decision support where maximum accuracy is paramount.

**Failure Signatures**: Performance degradation occurs when the binary classifier incorrectly classifies SDoH-relevant text as non-SDoH, causing it to be filtered out before LLM analysis. Additionally, if the LLM fails to capture nuanced contextual cues in clinical language, classification accuracy suffers despite the filtering efficiency.

**First Experiments**:
1. Evaluate binary classifier's precision on SDoH text to ensure minimal false negatives
2. Compare LLM performance with and without synthetic data augmentation
3. Test the two-step classifier on a held-out dataset to validate the speed-accuracy tradeoff

## Open Questions the Paper Calls Out
None

## Limitations
- Macro F1 score of 0.67 remains modest, indicating room for improvement in SDoH classification accuracy
- Evaluation on MIMIC-III data may not fully capture diversity of clinical documentation across different healthcare settings
- Two-step classifier's inference speed advantage comes at cost of reduced accuracy (macro F1 0.62)
- Study focuses on English clinical text only, limiting applicability to multilingual healthcare environments

## Confidence
- **High Confidence**: Experimental methodology, reproducibility efforts (code/data release), and comparative analysis with baseline
- **Medium Confidence**: Cross-validation stability and ablation study results
- **Low Confidence**: Generalizability to non-MIMIC-III clinical settings and synthetic data impact assessment

## Next Checks
1. External validation on clinical text from multiple healthcare institutions to assess generalizability across different documentation styles and patient populations
2. Ablation study specifically isolating the contribution of synthetic data versus model architecture improvements to the observed performance gains
3. Clinical impact assessment measuring whether the improved SDoH classification translates to meaningful improvements in patient care or health outcomes