---
ver: rpa2
title: 'Interpretable Heart Disease Prediction via a Weighted Ensemble Model: A Large-Scale
  Study with SHAP and Surrogate Decision Trees'
arxiv_id: '2511.01947'
source_url: https://arxiv.org/abs/2511.01947
tags:
- ensemble
- lightgbm
- clinical
- performance
- risk
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of predicting cardiovascular
  disease (CVD) risk using large-scale clinical data while ensuring model interpretability
  for clinical trust and adoption. The proposed method is a strategically weighted
  ensemble model that combines LightGBM (70%), XGBoost (20%), and a CNN (10%) to predict
  CVD risk, trained on a preprocessed dataset of 229,781 patients with a class imbalance
  of 1:8.7.
---

# Interpretable Heart Disease Prediction via a Weighted Ensemble Model: A Large-Scale Study with SHAP and Surrogate Decision Trees

## Quick Facts
- **arXiv ID:** 2511.01947
- **Source URL:** https://arxiv.org/abs/2511.01947
- **Reference count:** 19
- **Primary result:** Weighted ensemble model (70% LightGBM, 20% XGBoost, 10% CNN) achieves Test AUC 0.8371 (p=0.003) on imbalanced CVD prediction task

## Executive Summary
This study addresses the challenge of predicting cardiovascular disease (CVD) risk using large-scale clinical data while ensuring model interpretability for clinical trust and adoption. The proposed method is a strategically weighted ensemble model that combines LightGBM (70%), XGBoost (20%), and a CNN (10%) to predict CVD risk, trained on a preprocessed dataset of 229,781 patients with a class imbalance of 1:8.7. Feature engineering expanded the original 22 features to 25, including engineered risk indicators. The ensemble model achieved a statistically significant improvement over the best individual model, with a Test AUC of 0.8371 (p=0.003), and demonstrated high recall (80.0%) for screening applications. Interpretability was ensured through SHAP analysis, which identified Age, General Health, and engineered risk scores as top predictors, and a surrogate decision tree (89.9% mimicry accuracy) that highlighted BMI-BP interaction as the primary risk factor. The approach combines robust predictive performance with actionable, clinically transparent decision pathways, making it suitable for real-world deployment in public health screening.

## Method Summary
The method employs a weighted ensemble of three models: LightGBM (70% weight), XGBoost (20% weight), and a CNN (10% weight). The approach handles class imbalance through strategic weighting rather than oversampling, and incorporates feature engineering to create risk scores. A surrogate decision tree (depth=4) provides interpretability by mimicking the ensemble's predictions with 89.9% accuracy. SHAP analysis identifies key predictors, while the ensemble architecture combines the strengths of tree-based models and neural networks to achieve superior performance on the imbalanced CVD prediction task.

## Key Results
- Test AUC of 0.8371 with statistically significant improvement (p=0.003) over best individual model
- High recall of 80.0% suitable for screening applications
- Surrogate decision tree achieves 89.9% mimicry accuracy, highlighting BMI-BP interaction as primary risk factor
- SHAP analysis identifies Age, General Health, and engineered risk scores as top predictors

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A weighted average ensemble combining tree-based and neural architectures yields statistically significant discrimination improvements over individual models.
- **Mechanism:** The 70/20/10 weighting (LightGBM/XGBoost/CNN) likely reduces variance by averaging errors from architecturally distinct learning paradigms (gradient boosting vs. convolution). While tree models excel at tabular feature splits, the CNN extracts sequential patterns from reshaped features; their correlation is high (0.9952), but the residual divergence allows the ensemble to marginally correct misclassifications.
- **Core assumption:** The models make errors on different subsets of the difficult minority class, or at least sufficiently distinct errors to improve the aggregate AUC.
- **Evidence anchors:** Abstract reports "statistically significant improvement... Test AUC of 0.8371 (p=0.003)"; Findings and Evaluation notes "high correlation between model predictions... explains the modest absolute gain."

### Mechanism 2
- **Claim:** Strategic class weighting addresses the 1:8.7 imbalance more effectively than synthetic oversampling for maintaining data integrity.
- **Mechanism:** By assigning a higher penalty to misclassifying the minority class (CVD positive) during loss calculation, the model is forced to learn decision boundaries for the rare class without inflating the dataset with artificial ADASYN samples.
- **Core assumption:** The minority class samples in the training set are representative of the true underlying distribution, and the cost of false negatives outweighs false positives.
- **Evidence anchors:** Introduction critiques ADASYN for "artificial dataset inflation" and "compromised real-world generalizability"; Methodology states "class imbalance was managed through strategic weighting."

### Mechanism 3
- **Claim:** Surrogate decision trees provide clinical transparency by approximating complex ensemble logic without sacrificing the original model's performance.
- **Mechanism:** A Decision Tree is trained not on ground truth labels, but on the probability outputs of the complex ensemble (mimicry). This distills the high-dimensional "black box" logic into a hierarchical set of rules (e.g., BMI-BP Interaction) that clinicians can validate against known pathophysiology.
- **Core assumption:** A depth-4 tree is sufficiently expressive to approximate the decision boundary of the ensemble (89.9% fidelity implies ~10% logic is lost or too complex for simple rules).
- **Evidence anchors:** Abstract reports "surrogate decision tree (89.9% mimicry accuracy)... highlighted BMI-BP interaction"; Interpretability Analysis confirms "Mimicry Accuracy 89.9%... High fidelity in replicating the complex LightGBM model."

## Foundational Learning

- **Concept: Area Under the Curve (AUC) vs. Recall/F1-Score**
  - **Why needed here:** The study reports a high AUC (0.837) but a low F1-score (~0.37). Understanding this gap is critical: AUC measures ranking ability across all thresholds, while F1 measures accuracy at a specific threshold. In imbalanced datasets, high AUC often coexists with low precision/F1.
  - **Quick check question:** If the model has an AUC of 0.84, why can the F1-score be as low as 0.38?

- **Concept: SHAP (SHapley Additive exPlanations) Values**
  - **Why needed here:** The paper uses SHAP not just for feature importance, but to explain individual predictions (local interpretability).
  - **Quick check question:** Does a high SHAP value for "Age" mean that being old *causes* heart disease, or just that the model uses age as a strong predictor?

- **Concept: Model Fidelity in Surrogates**
  - **Why needed here:** The surrogate tree is useful only if it faithfully copies the ensemble.
  - **Quick check question:** If a surrogate model has 89.9% fidelity, what happens to the explanation for the remaining 10.1% of cases?

## Architecture Onboarding

- **Component map:** BRFSS dataset (229,781 patients × 25 features) → Feature Engineering (HealthRiskScore, BMI_BP_Interaction) → Standard Scaler → 80/20 Stratified Split → Base Models (LightGBM 70%, XGBoost 20%, CNN 10%) → Weighted Average Aggregator → SHAP Explainer + Surrogate Decision Tree

- **Critical path:**
  1. Preprocessing: Do *not* use ADASYN/SMOTE. Apply `StandardScaler` and Class Weights (1:8.7 ratio).
  2. Feature Engineering: Create `BMI_BP_Interaction` and `HealthRiskScore` (HighBP + HighChol + Diabetes). The paper identifies these as top drivers.
  3. Thresholding: Default threshold is 0.5 (optimized for Recall/Screening). For diagnosis (Precision), shift to ~0.65.

- **Design tradeoffs:**
  - Recall vs. Precision: The ensemble is tuned for high Recall (80%). It is suitable for *screening* (catching as many positives as possible) but will generate more False Positives than a model tuned for Precision.
  - Complexity vs. Interpretability: The ensemble is a black box; you must rely on the Surrogate Tree for clinical logic, accepting ~10% information loss.

- **Failure signatures:**
  - Low F1-Score: Expected on this dataset due to 1:8.7 imbalance. Do not panic if F1 is ~0.37 while AUC is ~0.83.
  - Overfitting on CNN: The CNN is small (0.1 weight); if validation loss diverges early, reduce CNN complexity or weight to 0.
  - Surrogate Divergence: If mimicry accuracy drops <80%, the tree is too simple (increase depth) or the ensemble is too chaotic.

- **First 3 experiments:**
  1. Baseline Reproduction: Train LightGBM with class weighting on the raw 22 features vs. the engineered 25 features to validate the "HealthRiskScore" contribution.
  2. Ablation Study: Remove the CNN component (set weight to 0) and check if the statistical significance (p=0.003) vanishes, confirming the CNN's role in error correction.
  3. Threshold Sensitivity: Plot Precision-Recall curves for the Ensemble vs. LightGBM to find the optimal operating point for a "high-specificity" diagnostic use case vs. the "high-sensitivity" screening use case.

## Open Questions the Paper Calls Out

- **Question:** Does the weighted ensemble model maintain its performance advantage when validated on external, geographically distinct clinical datasets?
  - **Basis in paper:** [explicit] The introduction cites Cai et al. [7] to identify the lack of external validation as a "critical research gap" and a barrier to clinical utility, a gap the current study does not address by relying solely on the BRFSS dataset.
  - **Why unresolved:** The study utilizes a single data source (BRFSS 2015) split into training and testing sets, which does not verify generalizability to populations with different demographics or data collection methods.
  - **What evidence would resolve it:** Reporting Test AUC and Recall metrics on an independent cohort, such as the Framingham Heart Study or UK Biobank.

- **Question:** Is the specific ensemble weighting strategy (70% LightGBM, 20% XGBoost, 10% CNN) robust across varying class imbalance ratios, or is it overfitted to the specific 1:8.7 imbalance of the study dataset?
  - **Basis in paper:** [inferred] The weights were "strategically" optimized on a validation set to maximize AUC, but the paper does not demonstrate if this fixed ratio remains optimal for data with different prevalence rates.
  - **Why unresolved:** The methodology describes a targeted optimization for the specific validation split without testing the stability of these weights under different data conditions.
  - **What evidence would resolve it:** A sensitivity analysis showing model performance when the weighting strategy is applied to datasets with different minority class distributions.

- **Question:** Does the 10.1% discrepancy in surrogate decision tree mimicry obscure critical, high-risk feature interactions that are necessary for clinical safety?
  - **Basis in paper:** [inferred] The surrogate tree achieved 89.9% accuracy in replicating the ensemble, implying a non-trivial error rate where the interpretable explanation diverges from the actual model prediction.
  - **Why unresolved:** The paper reports aggregate mimicry accuracy but does not analyze whether these errors correspond to systematic failures in detecting complex, high-risk cases.
  - **What evidence would resolve it:** An error analysis of the surrogate tree specifically focused on false negative classifications to determine if critical risk factors are lost in translation.

## Limitations

- The specific CNN optimizer settings and training epochs are not explicitly specified, which could affect the ensemble's 0.1 weight contribution.
- The exact optimal hyperparameters for LightGBM and XGBoost (beyond search ranges) are not provided, potentially impacting reproducibility of the reported Test AUC (0.8371).
- The source and exact preprocessing of the BRFSS 2015 dataset (handling of missing values, categorical encoding) are not fully detailed.

## Confidence

- **High:** The ensemble's statistical significance (p=0.003) over individual models is well-supported by the described methodology.
- **Medium:** The interpretability claims via SHAP and surrogate tree are valid, but the 89.9% mimicry fidelity implies ~10% of the model's logic is too complex for simple rules.
- **Medium:** The class weighting strategy is a reasonable choice over ADASYN, but its superiority is not rigorously validated against other imbalance techniques in this study.

## Next Checks

1. **Hyperparameter Sensitivity:** Perform an ablation study to confirm that the specific 70/20/10 weighting ratio is necessary for the reported statistical significance (p=0.003).
2. **Threshold Optimization:** Validate that the default 0.5 threshold is optimal for the intended screening application by plotting Precision-Recall curves across the full range.
3. **Feature Engineering Impact:** Train a baseline LightGBM model on the raw 22 features vs. the engineered 25 features to quantify the contribution of `HealthRiskScore` and `BMI_BP_Interaction` to the final performance.