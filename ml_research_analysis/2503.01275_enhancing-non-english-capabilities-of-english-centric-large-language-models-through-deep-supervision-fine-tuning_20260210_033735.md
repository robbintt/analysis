---
ver: rpa2
title: Enhancing Non-English Capabilities of English-Centric Large Language Models
  through Deep Supervision Fine-Tuning
arxiv_id: '2503.01275'
source_url: https://arxiv.org/abs/2503.01275
tags:
- language
- english
- supervision
- arxiv
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes deep supervision fine-tuning (DFT) to enhance
  the non-English capabilities of English-centric large language models. The key insight
  is that LLMs implicitly convert non-English queries to English at the bottom layers
  and perform English reasoning at the middle layers, but lack explicit supervision
  for this internal workflow.
---

# Enhancing Non-English Capabilities of English-Centric Large Language Models through Deep Supervision Fine-Tuning

## Quick Facts
- arXiv ID: 2503.01275
- Source URL: https://arxiv.org/abs/2503.01275
- Reference count: 14
- Key outcome: DFT significantly outperforms traditional fine-tuning methods on 8 multilingual datasets, with improvements particularly in multilingual QA tasks

## Executive Summary
This paper addresses the challenge of enhancing non-English capabilities of English-centric LLMs by introducing deep supervision fine-tuning (DFT). The method adds supervision signals at intermediate layers to guide the implicit workflow where LLMs convert non-English inputs to English at bottom layers and perform English reasoning at middle layers. By explicitly constraining these intermediate stages through logits-based or feature-based supervision, DFT improves multilingual task performance while maintaining translation capabilities. Extensive experiments on LLaMA-2 and Gemma-2 demonstrate significant improvements across multiple languages and task types.

## Method Summary
DFT adds supervision signals at different stages of LLM processing: bottom layers for constraining non-English to English conversion, and middle layers for constraining English reasoning. The method uses two supervision types - logits-based (stricter) and feature-based (more relaxed) - applied via modified loss functions. An entropy-based strategy identifies critical layers for supervision placement. The model processes non-English instruction pairs with parallel English translations, applying supervision at identified critical layers during training. The total loss combines traditional fine-tuning with auxiliary supervision terms for language conversion and English thinking stages.

## Key Results
- DFT outperforms traditional fine-tuning methods on 8 multilingual datasets
- Logits-based supervision excels for QA/generation tasks while feature-based better preserves translation capabilities
- Supervision at middle layers (around layer 15 for LLaMA-2-7B) yields optimal performance
- Entropy-based layer selection effectively identifies critical processing boundaries

## Why This Works (Mechanism)

### Mechanism 1: Intermediate Layer Supervision for Language Conversion
- Claim: Adding supervision signals at bottom layers constrains the accuracy of non-English to English conversion.
- Mechanism: The model's early layers transform multilingual input into an English representation space. By applying either logits-based supervision (forcing prediction of the English query) or feature alignment (aligning hidden states), the conversion becomes more accurate, improving downstream reasoning.
- Core assumption: Bottom layers are primarily responsible for cross-lingual conversion, and this conversion is prerequisite to reasoning quality.
- Evidence anchors:
  - [abstract]: "LLMs implicitly convert non-English queries into English ones at the bottom layers...due to the absence of explicit supervision...internal representations during these stages may become inaccurate."
  - [section]: "In the bottom layers of the model, DFT guides the conversion from non-English to English."
  - [corpus]: Paper 87504 confirms "English-centric large language models map multilingual content into English-aligned representations at intermediate layers."
- Break condition: If the model's language conversion is distributed across layers rather than localized at bottom layers, or if conversion accuracy doesn't correlate with final output quality.

### Mechanism 2: English Thinking Supervision at Middle Layers
- Claim: Supervising middle layers to produce English answers improves reasoning quality for non-English inputs.
- Mechanism: After conversion, the model reasons in English. Explicit supervision at this stage—via logits (predicting English answers) or feature alignment with final-layer English representations—ensures the reasoning path remains accurate before language reversion begins.
- Core assumption: English reasoning predominantly occurs in middle layers, and supervising this stage improves final target-language output.
- Evidence anchors:
  - [abstract]: "[LLMs] adopt English for thinking at the middle layers."
  - [section]: Table 3 shows English Thinking supervision yielded more significant improvements than Language Conversion supervision across most tasks.
  - [corpus]: Paper 57696 confirms "middle layers perform reasoning within an English-centric latent space."
- Break condition: If reasoning is distributed uniformly across layers, or if supervising English answers at middle layers conflicts with the language reversion process.

### Mechanism 3: Entropy-Based Critical Layer Identification
- Claim: Layer-wise entropy patterns can identify optimal supervision placement points.
- Mechanism: Entropy measures uncertainty in processing. Two entropy drops are observed: the first indicates language conversion completion, the second marks reasoning completion. Supervision applied at these inflection points is most effective.
- Core assumption: Entropy drops correlate with functional boundaries between processing stages, and these boundaries are consistent across samples.
- Evidence anchors:
  - [abstract]: "introduces an entropy-based strategy to identify critical layers for supervision"
  - [section]: Figure 3 shows entropy drops at layer 2 and ~layer 15 for LLaMA-2-7b; supervision at layer 15 achieves best performance.
  - [corpus]: No direct corpus evidence on entropy-based layer selection methods.
- Break condition: If entropy patterns vary significantly across tokens, languages, or model architectures, making universal layer selection unreliable.

## Foundational Learning

- Concept: **Deep Supervision Networks (DSNs)**
  - Why needed here: DFT adapts DSN principles but differs critically—traditional DSNs use intermediate supervision with the same target as the final output, while DFT uses different targets (English query/answer) at intermediate layers.
  - Quick check question: How does DFT's intermediate supervision differ from traditional deep supervision in image classification?

- Concept: **Cross-Lingual Representation Alignment**
  - Why needed here: The feature-based supervision method relies on aligning hidden representations between semantically equivalent English and non-English inputs using cosine similarity.
  - Quick check question: When would feature-based alignment be preferred over logits-based supervision?

- Concept: **Three-Stage Multilingual Processing Pipeline**
  - Why needed here: The entire method assumes a specific workflow: Language Conversion → English Thinking → Language Reversion. Understanding this pipeline is essential for correct layer selection and supervision placement.
  - Quick check question: What happens if you apply English Thinking supervision too late in the pipeline?

## Architecture Onboarding

- Component map:
  Input Processing -> Bottom Layers (0 to i) [Language Conversion] -> Middle Layers (i to j) [English Thinking] -> Top Layers (j to L) [Language Reversion] -> Output

- Critical path:
  1. Run entropy analysis on validation samples to identify critical layers i and j
  2. Prepare parallel English-non-English instruction pairs (source used Stanford Alpaca translations)
  3. Select supervision type based on task (logits for generation, feature for understanding)
  4. Train with combined loss, monitoring intermediate supervision terms

- Design tradeoffs:
  - Logits vs Feature: Logits is stricter, better for QA/generation; Feature is more relaxed, better for NLU tasks and preserves translation capability
  - Layer selection precision: The paper acknowledges entropy-based selection is "rough" and may vary by token
  - Supervision strength at early layers: Strong logits-based LC supervision can harm original model capabilities (Table 4 shows catastrophic en-zh translation drop)

- Failure signatures:
  - Catastrophic translation performance drop when using logits-based Language Conversion (68.37 → 36.79 COMET score for en-zh)
  - Performance decline when English Thinking supervision applied at late layers (interferes with language reversion)
  - Stagnant results if critical layers are misidentified or if supervision type mismatches task

- First 3 experiments:
  1. **Entropy profiling**: Run entropy analysis on your specific model and target language—do not assume layer 15 is universal (the paper tested only LLaMA-2-7b and Gemma-2-2B).
  2. **Supervision type ablation**: Compare DFT-logits vs DFT-feature on your primary task type; expect logits to excel at generation, feature at understanding.
  3. **Single-stage ablation**: Test LC-only vs ET-only to determine which stage contributes more to your use case before committing to full DFT.

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions but acknowledges limitations in its entropy-based layer selection method and the tradeoff between supervision types.

## Limitations
- Limited model and language coverage: Experiments focus only on LLaMA-2-7B and Gemma-2-2B with Chinese, Vietnamese, and Arabic
- Tradeoff between supervision types: No clear criteria for choosing between logits-based and feature-based supervision beyond task type
- Generalization uncertainty: Critical layer positions may not transfer across different model architectures or depths

## Confidence
**High Confidence:**
- DFT improves multilingual QA performance compared to traditional fine-tuning
- Logits-based supervision is more effective than feature-based for QA/generation tasks
- Layer 15 is critical for English thinking supervision on 32-layer LLaMA-2-7B
- Applying English thinking supervision too late in the pipeline degrades performance

**Medium Confidence:**
- Entropy drops reliably identify functional boundaries in multilingual processing
- The three-stage pipeline (Language Conversion → English Thinking → Language Reversion) is universal across multilingual LLMs
- The relative contribution of LC vs ET supervision is consistent across tasks

**Low Confidence:**
- DFT's effectiveness generalizes to model architectures beyond LLaMA-2 and Gemma-2
- The entropy-based layer identification method works reliably across different languages and tokenization schemes
- The performance improvements observed for Chinese/Vietnamese/Arabic extend to other language families

## Next Checks
1. **Cross-Model Critical Layer Validation**
   Run entropy analysis on at least three additional multilingual LLM architectures (e.g., different depths, different pretraining objectives) to verify whether the layer 2 and layer 15 critical points are universal or architecture-specific. Document how critical layer positions correlate with model depth and architecture choices.

2. **Mixed Supervision Strategy Evaluation**
   Design an experiment testing hybrid supervision strategies: (a) using both logits and feature supervision simultaneously at the same layer, (b) switching between supervision types mid-training based on validation performance, or (c) applying logits supervision only to the final generation step while using feature supervision earlier. Measure impact on both task performance and translation preservation.

3. **Low-Resource Language Generalization Test**
   Apply DFT to a truly low-resource language pair (e.g., Swahili-English or Yoruba-English) with limited parallel data. Compare performance against high-resource language pairs and analyze whether the entropy-based layer selection and supervision effectiveness degrade as linguistic distance from English increases or as parallel data becomes scarce.