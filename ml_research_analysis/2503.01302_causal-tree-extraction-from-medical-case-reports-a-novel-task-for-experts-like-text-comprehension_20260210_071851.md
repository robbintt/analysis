---
ver: rpa2
title: 'Causal Tree Extraction from Medical Case Reports: A Novel Task for Experts-like
  Text Comprehension'
arxiv_id: '2503.01302'
source_url: https://arxiv.org/abs/2503.01302
tags:
- case
- causal
- medical
- evaluation
- tree
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Causal Tree Extraction (CTE), a novel task
  that extracts multi-layered causal relationships from medical case reports into
  a tree structure with the primary disease as the root. The authors constructed J-Casemap,
  a Japanese case report dataset with 14,094 annotated causal trees.
---

# Causal Tree Extraction from Medical Case Reports: A Novel Task for Experts-like Text Comprehension

## Quick Facts
- arXiv ID: 2503.01302
- Source URL: https://arxiv.org/abs/2503.01302
- Reference count: 39
- Proposed generation-based method using LLMs achieved 82.7 in human evaluation, outperforming baseline RE method by 20.2 points

## Executive Summary
This paper introduces Causal Tree Extraction (CTE), a novel task for extracting multi-layered causal relationships from medical case reports into a tree structure with the primary disease as the root. The authors constructed J-Casemap, a Japanese case report dataset with 14,094 annotated causal trees, and proposed a generation-based method using LLMs that significantly outperformed traditional relation extraction baselines. The study also developed evaluation metrics with heuristic weighting that better reflect clinician preferences. Experiments demonstrated that J-Casemap improves medical QA performance, showing potential for various medical applications.

## Method Summary
The proposed method uses a generation-based approach with large language models (LLMs) to extract causal relationships from medical case reports. The process involves prompting the LLM to identify causal links between medical events and organize them into a tree structure rooted at the primary disease. The authors developed J-Casemap, a Japanese dataset containing 14,094 case reports with manually annotated causal trees. They also created evaluation metrics that incorporate heuristic weighting to better capture clinical relevance and expert preferences. The generation-based method was compared against a baseline relation extraction approach to demonstrate its effectiveness.

## Key Results
- Generation-based LLM method achieved 82.7 in human evaluation
- Outperformed baseline relation extraction method by 20.2 points
- J-Casemap dataset with 14,094 annotated causal trees improved medical QA performance

## Why This Works (Mechanism)
The generation-based approach works by leveraging LLMs' ability to understand complex contextual relationships in medical text. Unlike traditional relation extraction methods that identify isolated causal links, the generation-based method can capture multi-layered causal chains and organize them into coherent tree structures. The heuristic weighting in evaluation metrics better reflects how clinicians prioritize different causal relationships based on clinical relevance and importance. The J-Casemap dataset provides high-quality training data that captures the complexity of real medical case reports, enabling the model to learn nuanced causal patterns that experts recognize.

## Foundational Learning
- **Causal Tree Structure**: Why needed: Medical case reports contain complex multi-layered causal relationships that require hierarchical organization. Quick check: Can the model correctly identify root causes versus intermediate effects in a medical scenario.
- **Medical Terminology Processing**: Why needed: Accurate understanding of medical terms is crucial for identifying causal relationships. Quick check: Does the model correctly interpret clinical abbreviations and specialized medical language.
- **LLM Prompt Engineering**: Why needed: Effective prompts are essential for guiding LLMs to extract structured causal information. Quick check: Can different prompt formulations significantly impact extraction accuracy.
- **Heuristic Evaluation Metrics**: Why needed: Traditional metrics may not capture clinical relevance that experts prioritize. Quick check: Do heuristic-weighted metrics better align with clinician assessments compared to standard metrics.
- **Cross-lingual Transfer Learning**: Why needed: The current dataset is Japanese-only, limiting broader applicability. Quick check: Can the method be effectively applied to medical case reports in other languages.

## Architecture Onboarding
Component Map: Medical Case Report -> LLM Generation Model -> Causal Tree Output -> Heuristic Evaluation
Critical Path: Case Report Input → Prompt Processing → Causal Link Identification → Tree Structure Generation → Evaluation Scoring
Design Tradeoffs: Generation-based methods offer flexibility in capturing complex relationships but may sacrifice precision compared to rule-based approaches. The Japanese-only dataset provides high-quality annotations but limits generalizability.
Failure Signatures: Common failures include incorrect identification of primary diseases, missing intermediate causal links, or creating circular dependencies in the tree structure.
First Experiments:
1. Test generation-based method on simple medical scenarios with clear causal chains
2. Evaluate model performance on case reports with varying complexity levels
3. Compare different LLM architectures and their impact on extraction accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on Japanese-only dataset limits generalizability to other languages and medical domains
- Evaluation metrics are heuristic-based and may not fully capture clinical relevance
- Generation-based method's dependency on LLM quality introduces performance variability
- Human evaluation results lack detailed statistical significance testing
- Study does not address potential biases in case report selection or annotation processes

## Confidence
- High Confidence: Dataset construction methodology and basic task definition are well-established
- Medium Confidence: Generation-based extraction method shows promising results but needs broader validation
- Medium Confidence: Evaluation metrics, while intuitive, require further validation against clinical outcomes

## Next Checks
1. **Cross-language validation**: Test the generation-based method on English medical case reports or translate J-Casemap to English to verify generalizability
2. **Clinical outcome correlation**: Measure whether extracted causal trees actually improve clinical decision-making or patient outcomes in real-world scenarios
3. **Long-term stability assessment**: Evaluate the generation-based method's performance across different LLM versions and over extended time periods to ensure robustness