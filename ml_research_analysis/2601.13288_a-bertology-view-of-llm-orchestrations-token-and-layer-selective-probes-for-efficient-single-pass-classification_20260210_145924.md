---
ver: rpa2
title: 'A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes
  for Efficient Single-Pass Classification'
arxiv_id: '2601.13288'
source_url: https://arxiv.org/abs/2601.13288
tags:
- uni00000051
- uni00000013
- layer
- uni00000020
- uni00000014
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method to perform classification tasks
  using hidden states from a frozen large language model (LLM) during its forward
  pass, avoiding the need for a separate guard model. The approach treats classification
  as a representation-selection problem over the full token-layer hidden-state tensor,
  using a two-stage aggregation architecture to summarize tokens within each layer
  and then aggregate across layers.
---

# A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification

## Quick Facts
- **arXiv ID:** 2601.13288
- **Source URL:** https://arxiv.org/abs/2601.13288
- **Reference count:** 24
- **Primary result:** Classification probes using frozen LLM hidden states achieve competitive performance with minimal parameter overhead

## Executive Summary
This paper introduces a novel approach to classification that leverages hidden states from a frozen large language model during its forward pass, eliminating the need for separate guard models. The method treats classification as a representation-selection problem over the full token-layer hidden-state tensor using a two-stage aggregation architecture. Experiments demonstrate that these probes outperform logit-only reuse methods and achieve competitive results with substantially larger task-specific baselines while maintaining near-serving latency.

## Method Summary
The approach performs classification using hidden states from a frozen LLM during its forward pass, avoiding separate guard model training. It treats classification as a representation-selection problem over the full token-layer hidden-state tensor, employing a two-stage aggregation architecture. The first stage summarizes tokens within each layer, while the second aggregates across layers. This design enables efficient single-pass classification with only 35M trainable parameters while preserving near-serving latency.

## Key Results
- Probes improve over logit-only reuse methods across safety moderation (ToxicChat, WildGuardMix) and sentiment classification (IMDB, SST-2, Emotion) benchmarks
- Achieves competitive performance with substantially larger task-specific baselines
- Requires only 35M trainable parameters while preserving near-serving latency

## Why This Works (Mechanism)
The method works by treating classification as a representation-selection problem over the full token-layer hidden-state tensor from a frozen LLM. Rather than relying solely on final logits, it leverages the rich intermediate representations available throughout the model's layers. The two-stage aggregation architecture first summarizes tokens within each layer, capturing local context, then aggregates across layers to combine information at different depths. This allows the probe to selectively attend to task-relevant information distributed across the model's architecture.

## Foundational Learning
1. **BERTology** - Understanding how information is distributed across transformer layers is crucial for designing effective probes that can extract relevant features at appropriate depths.
   - *Why needed:* To identify where task-relevant information resides within the model
   - *Quick check:* Verify layer-attention patterns align with known BERTology findings

2. **Representation Learning** - The ability to transform raw hidden states into task-specific representations determines classification performance.
   - *Why needed:* To map high-dimensional hidden states to meaningful classification signals
   - *Quick check:* Assess representation quality through intermediate probing tasks

3. **Multi-head Attention** - Understanding how attention mechanisms distribute information across tokens and layers informs probe architecture design.
   - *Why needed:* To leverage the model's existing attention patterns for efficient information extraction
   - *Quick check:* Examine attention distributions for task-relevant patterns

## Architecture Onboarding

**Component Map:** Input Hidden States -> Token Aggregation Layer -> Layer Aggregation Module -> Classification Output

**Critical Path:** The forward pass proceeds through frozen LLM layers, token aggregation within each layer, layer aggregation across depths, and final classification. The probe operates entirely during the LLM's forward pass, avoiding additional inference steps.

**Design Tradeoffs:** The architecture balances parameter efficiency (35M trainable parameters) against representational capacity. Using frozen LLM weights preserves serving latency but limits adaptability to task-specific nuances. The two-stage aggregation provides flexibility in information extraction while maintaining computational efficiency.

**Failure Signatures:** Performance degradation may occur when task-relevant information is concentrated in layers poorly captured by the aggregation mechanism, or when token-level patterns require fine-grained modeling beyond the probe's capacity.

**First Experiments:**
1. Ablation study removing layer aggregation to assess importance of cross-layer information
2. Comparison with baseline using only final layer representations
3. Analysis of probe behavior on out-of-distribution examples

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Evaluation is primarily focused on classification tasks, with unexplored effectiveness on generation or multi-modal tasks
- 35M parameter probe size may still be prohibitive for resource-constrained deployment
- Generalizability to complex classification tasks beyond safety and sentiment remains to be validated

## Confidence
- **High Confidence:** Experimental results showing improved performance over logit-only reuse methods across multiple benchmarks
- **Medium Confidence:** Competitiveness with substantially larger task-specific baselines, though generalizability requires further validation
- **Medium Confidence:** Layer-attention analysis revealing distributed task-relevant information, though optimal layer selection interpretation needs additional ablation studies

## Next Checks
1. **Generalization Testing:** Evaluate probe architecture on diverse classification tasks including fine-grained and multi-label scenarios to assess robustness
2. **Resource Efficiency Analysis:** Measure actual memory consumption and throughput under various batch sizes and sequence lengths in real-world serving conditions
3. **Transferability Study:** Test probe transfer effectiveness to related tasks with minimal additional training to assess practical reusability