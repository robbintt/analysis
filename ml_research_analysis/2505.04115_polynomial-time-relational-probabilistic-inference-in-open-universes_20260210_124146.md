---
ver: rpa2
title: Polynomial-Time Relational Probabilistic Inference in Open Universes
arxiv_id: '2505.04115'
source_url: https://arxiv.org/abs/2505.04115
tags:
- cleo
- sum-of-squares
- logic
- knowledge
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a polynomial-time relational probabilistic
  inference method for open universes that extends sum-of-squares logic to first-order
  relational settings. The core idea is to ground the knowledge base with a number
  of generic names equal to the quantifier rank, then use sum-of-squares refutations
  on this lifted grounding.
---

# Polynomial-Time Relational Probabilistic Inference in Open Universes

## Quick Facts
- arXiv ID: 2505.04115
- Source URL: https://arxiv.org/abs/2505.04115
- Reference count: 21
- The paper introduces a polynomial-time relational probabilistic inference method for open universes that extends sum-of-squares logic to first-order relational settings.

## Executive Summary
This paper presents a polynomial-time method for relational probabilistic inference in open universes, where the number of objects is unknown or infinite. The core innovation is a lifted sum-of-squares approach that grounds the knowledge base using a finite number of generic names based on quantifier rank, then solves a semidefinite program to check consistency. This enables tractable reasoning about expected values of hybrid (discrete and continuous) variables while maintaining soundness and completeness guarantees for bounded quantifier rank and relation arity.

## Method Summary
The method works by first parsing the knowledge base to compute its quantifier rank k, then grounding the theory using k generic names plus explicit constants. Ground monomials are grouped into equivalence classes based on renaming substitutions to exploit symmetry and reduce dimensionality. A sum-of-squares semidefinite program is constructed from these equivalence classes, where moment and localizing matrices encode the constraints. The SDP solver checks feasibility: if feasible, a pseudomodel exists proving the query is consistent with the knowledge base; if infeasible, a degree-d sum-of-squares refutation proves inconsistency.

## Key Results
- Lifted sum-of-squares inference is sound and complete for fixed degrees and runs in polynomial time in the number of constants, clauses, and predicates
- Grounding with k generic names (where k is quantifier rank) is equivalent to reasoning over infinite domains for bounded quantifier rank knowledge bases
- Equivalence class compression reduces moment matrix dimension from exponential to polynomial in the number of generic names
- The framework handles hybrid variables (discrete and continuous) while maintaining tractability guarantees

## Why This Works (Mechanism)

### Mechanism 1: Finite Grounding of Infinite Domains via Generic Names
Reasoning in open universes can be reduced to a finite propositional theory without domain closure by grounding with k "generic names" where k equals the quantifier rank. This exploits the fact that satisfiability over infinite domains is equivalent to satisfiability over finite rank-sized grounding.

### Mechanism 2: Sum-of-Squares (SOS) Relaxation for Logical Consistency
Determining if probabilistic and logical constraints are consistent can be solved in polynomial time by reducing to a semidefinite program. Logical constraints and expectation bounds are converted to polynomial inequalities, and the method searches for sum-of-squares proofs of inconsistency.

### Mechanism 3: Symmetry Exploitation via Equivalence Classes
The complexity of the grounded theory is reduced from exponential to polynomial by grouping ground monomials into equivalence classes based on renaming substitutions. This exploits the indistinguishability of generic objects, drastically reducing the dimension of the moment matrix used in the SDP.

## Foundational Learning

- **Concept: First-Order Logic (Quantifier Rank)**
  - Why needed here: The tractability result depends entirely on "quantifier rank" (nesting depth of variables). You cannot determine grounding size k without computing this rank from the knowledge base syntax.
  - Quick check question: Given a formula ∀x ∃y R(x, y), what is its quantifier rank?

- **Concept: Expectation vs. Probability**
  - Why needed here: This framework generalizes probabilistic inference to "inference about expectations." You must understand that e(P(x)) represents probability only if P is Boolean, but the system handles continuous values where e(P) is simply the mean.
  - Quick check question: If a random variable X takes values in {0, 1, 2}, is e(X) equivalent to the probability that X > 0?

- **Concept: Semidefinite Programming (SDP) & Moment Matrices**
  - Why needed here: The reasoning engine is an SDP solver. Knowledge is encoded in moment matrices (expectations of products of variables). Understanding positive semidefiniteness is required to debug solver failures.
  - Quick check question: In a degree-2 SOS system, what does the entry M_{i,j} = e(x_i x_j) represent in the moment matrix?

## Architecture Onboarding

- **Component map:** Parser -> Grounder -> Symmetrizer -> SDP Builder -> Solver
- **Critical path:** The Symmetrizer implementation is most fragile. It must correctly identify interchangeable generic names under specific constraints. If done incorrectly, valid models are lost.
- **Design tradeoffs:**
  - Expressivity vs. Speed: Increasing degree d captures more complex inferences but causes SDP matrix size to grow as O(n^{d/2})
  - Generic Names vs. Constants: Adding constants is cheap (polynomial), but increasing quantifier rank k raises complexity significantly
- **Failure signatures:**
  - Silent Incompleteness: Solver returns "feasible" with pseudomodel when query is actually false (requires degree d+1 but system set to degree d)
  - Symmetry Breaking: Solver fails to find model because distinct generic names were incorrectly forced to be equal
- **First 3 experiments:**
  1. Basic Boolean Consistency: Implement grounder for KB of purely Boolean clauses (2-SAT). Verify SDP feasibility matches standard SAT solver results for small n
  2. Hybrid Inference Test: Replicate Example 2 (War/Cleopatra). Create hybrid system with one continuous and one Boolean variable. Check if inferred bounds tighten as degree d increases from 2 to 4
  3. Scalability Stress Test: Fix rank k=2 and degree d=4. Increase constants c (10, 100, 1000). Verify runtime scales polynomially as claimed in Theorem 3

## Open Questions the Paper Calls Out

### Open Question 1
Can the framework be extended to represent and reason about independence of random variables without introducing intractability? The authors note that representing independence typically leads to intractable polynomial optimization problems, but it's unknown if this is truly inherent.

### Open Question 2
Can the semidefinite program be further simplified by exploiting relational structure or sparsity? The current formulation directly grounds to polynomial-size SDP, but relational symmetry and sparsity patterns are not systematically exploited to reduce program size.

### Open Question 3
Is there a systematic method to determine a priori what moment degree suffices to solve a given inference problem? The paper notes tractability holds "for fixed degrees" but doesn't provide general upper bounds on required degree.

### Open Question 4
Can the explicit compactness requirement be relaxed while maintaining soundness and completeness guarantees? The completeness theorems assume "explicitly compact" systems where ground terms obtain bounded values, but it's unclear if this can be weakened.

## Limitations
- Completeness guarantees hold only for fixed degree d, with no general upper bound on required degree for arbitrary queries
- Polynomial runtime assumes quantifier rank k is bounded and treated as constant, with no guidance on when k becomes too large for practical use
- Explicit compactness assumption (bounded values) is critical but not thoroughly explored for real-world open universe scenarios

## Confidence

- **High confidence** in theoretical framework linking quantifier rank to finite grounding and polynomial-time complexity bound
- **Medium confidence** in practical applicability due to limited empirical validation and unclear guidance on degree selection
- **Medium confidence** in SDP formulation's ability to capture all relevant constraints, as implementation details are not fully specified

## Next Checks

1. **Degree Sensitivity Analysis:** Systematically test Example 2 by running inference at degrees d=2, 3, 4 and document how bounds tighten to validate whether degree selection can be guided by observable changes.

2. **Quantifier Rank Stress Test:** Implement parser to compute quantifier rank for increasingly complex formulas (rank 1-3). Measure grounding time and solution quality as rank increases to identify practical limits.

3. **Symmetry Verification:** For a simple KB with two generic names and symmetric constraints, verify that the symmetrizer correctly identifies equivalent monomials by checking that the moment matrix has expected block structure.