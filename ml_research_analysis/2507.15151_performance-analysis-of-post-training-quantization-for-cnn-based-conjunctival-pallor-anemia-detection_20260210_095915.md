---
ver: rpa2
title: Performance Analysis of Post-Training Quantization for CNN-based Conjunctival
  Pallor Anemia Detection
arxiv_id: '2507.15151'
source_url: https://arxiv.org/abs/2507.15151
tags:
- quantization
- anemia
- accuracy
- precision
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the use of deep learning models, specifically
  a fine-tuned MobileNet architecture, for detecting anemia through conjunctival pallor
  analysis using the CP-AnemiC dataset of 710 pediatric images. The model achieved
  high performance with 93.13% accuracy, 93.74% precision, and 94.28% F1 score.
---

# Performance Analysis of Post-Training Quantization for CNN-based Conjunctival Pallor Anemia Detection

## Quick Facts
- arXiv ID: 2507.15151
- Source URL: https://arxiv.org/abs/2507.15151
- Reference count: 18
- Primary result: FP16 quantization achieved 92.50% accuracy, reducing model size while maintaining diagnostic accuracy for mobile anemia detection

## Executive Summary
This study evaluates post-training quantization (PTQ) for a MobileNet-based deep learning model detecting anemia through conjunctival pallor analysis in pediatric patients. The model, trained on the CP-AnemiC dataset of 710 pediatric images, achieved high performance (93.13% accuracy, 93.74% precision, 94.28% F1 score). PTQ was applied at FP32, FP16, INT8, and INT4 bit-widths using NVIDIA ModelOpt/TensorRT tools. FP16 quantization successfully balanced model efficiency and diagnostic accuracy, maintaining 92.50% accuracy with reduced model size and faster inference. However, INT8 and INT4 quantization led to significant performance degradation (71.25% and 43.13% accuracy respectively), indicating their unsuitability for this medical application without further optimization.

## Method Summary
The study used a MobileNetV2 backbone with ImageNet pre-trained weights for binary classification of anemia from conjunctival pallor images in children (6-59 months). The CP-AnemiC dataset contained 710 images (424 anemic/286 non-anemic, Hb threshold <11 g/dL, collected in Ghana Jan-Jun 2022). The model was trained with 5-fold cross-validation, Adam optimizer (lr=10^-4), binary cross-entropy loss, and early stopping on F1 score (patience 10 epochs). Data augmentation included random horizontal flips, rotations, and shifts. Post-training quantization was applied via ONNX and NVIDIA ModelOpt/TensorRT: FP16 used truncation, INT8 employed MaxCalibrator with per-channel weights, and INT4 used AWQ-lite with block size 128.

## Key Results
- FP16 quantization maintained high accuracy (92.50%) while reducing model size and inference time
- INT8 quantization achieved 71.25% accuracy, failing to preserve diagnostic utility
- INT4 quantization severely degraded performance to 43.13% accuracy
- Standard MobileNet achieved 93.13% accuracy, 93.74% precision, and 94.28% F1 score on CP-AnemiC dataset

## Why This Works (Mechanism)
The MobileNet architecture's efficiency comes from depthwise separable convolutions, which significantly reduce computational cost while maintaining sufficient representational power for image classification tasks. The FP16 quantization preserved model accuracy by maintaining adequate numerical precision for gradient calculations during inference, while INT8/INT4 quantization lost precision critical for distinguishing subtle pallor differences. The early stopping mechanism prevented overfitting on the relatively small CP-AnemiC dataset, ensuring the model generalized well to validation data.

## Foundational Learning
- **Conjunctival pallor as anemia indicator**: Why needed - establishes the clinical basis for using eye images in diagnosis; Quick check - verify pallor correlates with hemoglobin levels in validation cohort
- **Post-training quantization vs quantization-aware training**: Why needed - determines appropriate optimization strategy for deployment; Quick check - compare accuracy drop between PTQ and QAT for same bit-widths
- **Depthwise separable convolutions**: Why needed - explains MobileNet's efficiency advantage; Quick check - measure FLOPs reduction vs standard convolutions
- **Calibration dataset importance**: Why needed - critical for accurate INT8/INT4 quantization; Quick check - test accuracy sensitivity to calibration set size
- **Early stopping with F1 metric**: Why needed - prevents overfitting on imbalanced medical dataset; Quick check - verify training/validation F1 curves converge
- **Mobile healthcare deployment constraints**: Why needed - contextualizes performance requirements; Quick check - benchmark latency on target edge devices

## Architecture Onboarding

**Component Map**: Input Images (224×224) -> MobileNetV2 Backbone -> Global Average Pooling -> Dense Layer (1 unit, sigmoid) -> Binary Output

**Critical Path**: Image preprocessing → Model inference → Post-processing (sigmoid threshold) → Binary classification decision

**Design Tradeoffs**: MobileNet prioritizes computational efficiency over raw accuracy, making it suitable for edge deployment but potentially limiting performance on complex visual tasks. The choice of FP16 over INT8/INT4 represents a tradeoff between maintaining diagnostic accuracy and achieving maximum model compression.

**Failure Signatures**: 
- INT8/INT4 quantization causing >20% accuracy drop indicates insufficient precision for subtle pallor distinctions
- Overfitting indicated by >10% gap between training and validation F1 scores
- Calibration failure if INT8/INT4 models show high variance across runs

**First Experiments**:
1. Test FP16 quantized model on edge device (NVIDIA Jetson) to measure actual latency vs RTX 4090
2. Vary calibration set size (10, 50, 100, 500 samples) to find minimum for stable INT8 quantization
3. Implement mixed-precision inference to combine FP16 weights with INT8 activations

## Open Questions the Paper Calls Out
- **Inference latency on edge devices**: The authors plan to study impact on NVIDIA Jetson Xavier NX and TX2 NX, as current RTX 4090 benchmarks don't represent mobile constraints
- **Full integer arithmetic optimization**: Systematically achieving layer-by-layer full integer computation to recover INT8/INT4 performance degradation
- **Mixed-precision arithmetic strategies**: Leveraging combined precision formats to optimize speed while maintaining diagnostic accuracy

## Limitations
- The CP-AnemiC dataset's specific pediatric population and controlled imaging conditions may limit generalization to other demographics
- No cross-dataset validation or comparison with alternative architectures constrains robustness assessment
- Exact quantization implementation details (calibration strategy, data augmentation parameters) are unspecified, affecting reproducibility

## Confidence
- **High Confidence**: MobileNet training methodology with standard augmentations and 5-fold CV; FP16 quantization implementation
- **Medium Confidence**: INT8/INT4 quantization procedures and accuracy impacts; dataset collection methodology
- **Low Confidence**: Generalization claims to other populations; absolute performance superiority over alternatives

## Next Checks
1. Validate quantization calibration by testing with varying calibration set sizes (10, 50, 100, 500 samples) to determine minimum for stable INT8/INT4 performance
2. Perform cross-dataset evaluation using separate conjunctival pallor dataset to assess model generalization beyond CP-AnemiC
3. Compare against baseline ResNet or EfficientNet architectures using identical training and quantization protocols to establish MobileNet's relative performance