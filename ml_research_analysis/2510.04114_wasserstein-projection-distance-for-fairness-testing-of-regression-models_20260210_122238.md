---
ver: rpa2
title: Wasserstein projection distance for fairness testing of regression models
arxiv_id: '2510.04114'
source_url: https://arxiv.org/abs/2510.04114
tags:
- fairness
- regression
- theorem
- testing
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a Wasserstein projection-based framework
  for fairness testing in regression models, addressing the underexplored area of
  fairness evaluation for continuous prediction tasks. The authors propose a hypothesis-testing
  approach and an optimal data perturbation method to improve fairness while balancing
  accuracy, focusing on expectation-based fairness criteria.
---

# Wasserstein projection distance for fairness testing of regression models

## Quick Facts
- arXiv ID: 2510.04114
- Source URL: https://arxiv.org/abs/2510.04114
- Reference count: 40
- Primary result: Wasserstein projection framework for fairness testing in regression models with hypothesis testing and data perturbation.

## Executive Summary
This paper introduces a Wasserstein projection-based framework for fairness testing in regression models, addressing the underexplored area of fairness evaluation for continuous prediction tasks. The authors propose a hypothesis-testing approach and an optimal data perturbation method to improve fairness while balancing accuracy, focusing on expectation-based fairness criteria. Theoretical contributions include a detailed categorization of fairness criteria for regression, a dual reformulation of the Wasserstein projection test statistic, and the derivation of asymptotic bounds and limiting distributions. Experiments on synthetic and real-world datasets demonstrate that the proposed method offers higher specificity compared to permutation-based tests and effectively detects and mitigates biases in applications such as student performance and housing price prediction.

## Method Summary
The framework tests fairness in regression models by computing the Wasserstein projection distance between the model's prediction distribution and a fairness-constrained set. The core test statistic is defined as the minimum Wasserstein-2 distance between the empirical distribution of predictions and the set of distributions satisfying a given fairness criterion. The authors derive a dual reformulation that converts this into a nested optimization problem, with the inner optimization solved via BFGS and the outer via 1D maximization. For linear regression with equal mean fairness, they provide a closed-form solution. They establish asymptotic bounds and limiting distributions for the test statistic, enabling p-value computation. The framework also supports optimal data perturbation to improve fairness by projecting the data distribution onto the fairness set.

## Key Results
- The Wasserstein projection test achieves higher specificity than permutation-based tests while maintaining similar power in synthetic benchmarks.
- On the Student Performance dataset, the test identifies significant gender-based bias in Linear, Lasso, Ridge, and SVR models predicting math grades.
- The optimal data perturbation method effectively reduces bias in student performance and Boston housing price prediction tasks with minimal accuracy loss.

## Why This Works (Mechanism)
The Wasserstein projection distance quantifies how far a model's predictions deviate from satisfying a fairness criterion by measuring the minimal "effort" needed to transform the prediction distribution into a fair one. By minimizing this distance over all distributions that satisfy the fairness constraint, the framework captures the closest fair distribution to the model's predictions. The dual reformulation enables efficient computation through optimization, while the asymptotic analysis provides statistical guarantees for hypothesis testing. The cost function parameters (α for feature distance, β for label distance) allow flexible control over what aspects of the data can be modified during perturbation.

## Foundational Learning

**Wasserstein Distance**: A metric between probability distributions that measures the minimal cost of transforming one distribution into another. Needed to quantify distributional differences between model predictions and fairness-constrained distributions. Quick check: Verify W₂(P,Q) ≥ 0 and equals 0 iff P=Q.

**Dual Formulation**: A mathematical technique to convert a difficult primal optimization problem into a potentially easier dual problem. Required to make the Wasserstein projection computationally tractable. Quick check: Confirm strong duality holds (primal and dual optimal values are equal).

**Asymptotic Distribution**: The limiting distribution of a test statistic as sample size approaches infinity. Essential for deriving p-values and hypothesis testing procedures. Quick check: Simulate N×T for increasing N and verify convergence to θχ²₁.

**Fair Prediction Distribution**: The set of prediction distributions that satisfy a given fairness criterion. Forms the constraint set for the Wasserstein projection. Quick check: Verify that all distributions in F_R satisfy the specified fairness condition.

## Architecture Onboarding

**Component Map**: Data → Model → Predictions → Wasserstein Projection Test → p-value; optionally → Optimal Perturbation → Fair Model

**Critical Path**: Compute empirical distribution of predictions → Set up Wasserstein projection problem → Apply dual reformulation → Solve nested optimization → Compute test statistic → Estimate asymptotic parameters → Calculate p-value

**Design Tradeoffs**: Closed-form solution for linear regression vs. computational complexity of nested optimization for general models; expectation-based fairness criteria vs. broader fairness definitions; statistical power vs. computational efficiency

**Failure Signatures**: p-values stuck at 0 or 1 due to numerical instability; division by near-zero values in parameter estimation; inconsistent results between Wasserstein and permutation tests

**3 First Experiments**:
1. Verify closed-form test statistic T for linear regression with equal mean criterion on synthetic data
2. Validate limiting distribution N×T → θχ²₁ with varying sample sizes
3. Apply Wasserstein test to Student Performance dataset with gender as sensitive attribute

## Open Questions the Paper Calls Out

**Open Question 1**: How can the computational efficiency of the nested optimization procedure (inner BFGS, outer 1D maximization) be improved for large-scale datasets or highly non-linear models? The current dual reformulation relies on a computationally intensive nested optimization loop that may not scale well. An algorithmic modification (e.g., stochastic optimization or approximation bounds) that reduces runtime complexity while maintaining statistical power would resolve this.

**Open Question 2**: Can the Wasserstein projection framework be theoretically extended to support average ratio-based fairness definitions, such as the ratio of independence or separation? The current theoretical derivations focus on expectation-based (difference-based) criteria, and the dual reformulation may not hold directly for ratio constraints. Derivation of a modified test statistic and limiting distribution that remains valid under ratio-based constraints would resolve this.

**Open Question 3**: Do the derived asymptotic bounds and limiting distributions remain valid for non-differentiable regression models, such as Random Forests? Theorems 4.3 and 4.4 explicitly assume the regressor's gradient is locally Lipschitz continuous, yet the experiments apply the method to models (like SVR with RBF) where this might be complex or approximated. A theoretical proof or empirical analysis showing the test statistic's convergence properties when ∇ₓR(x) is undefined or non-Lipschitz would resolve this.

## Limitations

- The Wasserstein projection distance may not fully capture individual fairness or causal fairness notions beyond expectation-based criteria.
- The nested optimization with BFGS could be sensitive to hyperparameters and local minima, affecting reproducibility.
- Asymptotic results assume large sample sizes, which may not hold with imbalanced sensitive attribute groups.
- The cost function parameters (α, β) significantly impact results but lack systematic guidance for selection.

## Confidence

**High confidence**: The mathematical formulation of the Wasserstein projection test statistic and its dual reformulation (Theorem 4.2) are rigorous and reproducible. The closed-form solution for linear regression (Corollary 4.2.1) is clearly specified and verifiable.

**Medium confidence**: The asymptotic distribution results (Theorem 4.4) and θ estimation procedure (Corollary 4.4.1) are theoretically sound, but practical performance may vary with finite samples and non-ideal conditions.

**Low confidence**: The optimal data perturbation method (Section 5) and its empirical validation lack sufficient detail for complete reproduction. The generality of the approach to non-linear models and complex fairness criteria requires further investigation.

## Next Checks

1. Reproduce the limiting distribution N×T → θχ²₁ on synthetic data with varying sample sizes and group proportions to verify Theorem 4.4 empirically.
2. Implement the Wasserstein projection test on additional datasets with known fairness violations to assess sensitivity and specificity across different model types.
3. Conduct ablation studies varying α and β parameters in the cost function to quantify their impact on fairness-accuracy trade-offs.