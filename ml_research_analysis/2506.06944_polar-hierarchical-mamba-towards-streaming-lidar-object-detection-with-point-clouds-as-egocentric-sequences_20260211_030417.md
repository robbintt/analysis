---
ver: rpa2
title: 'Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point
  Clouds as Egocentric Sequences'
arxiv_id: '2506.06944'
source_url: https://arxiv.org/abs/2506.06944
tags:
- streaming
- methods
- mamba
- polar
- sector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the trade-off between latency and accuracy\
  \ in LiDAR-based 3D object detection for autonomous vehicles. Traditional methods\
  \ process full 360\xB0 scans, causing significant delays, while streaming approaches\
  \ reduce latency but suffer from reduced accuracy due to limited visibility and\
  \ spatial distortion in polar coordinates."
---

# Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences

## Quick Facts
- **arXiv ID:** 2506.06944
- **Source URL:** https://arxiv.org/abs/2506.06944
- **Authors:** Mellon M. Zhang; Glen Chou; Saibal Mukhopadhyay
- **Reference count:** 40
- **Primary result:** State-of-the-art streaming LiDAR detection, outperforming prior streaming methods by 10% mAP on Waymo Open Dataset while matching full-scan accuracy at twice the update rate

## Executive Summary
This paper addresses the fundamental tradeoff between latency and accuracy in LiDAR-based 3D object detection for autonomous vehicles. Traditional full-scan methods process entire 360° point clouds but introduce significant delays, while streaming approaches reduce latency but suffer from reduced accuracy due to limited visibility and spatial distortion in polar coordinates. The authors propose Polar-Fast-Cartesian-Full (PFCF), a hybrid detector that combines fast polar processing with accurate Cartesian reasoning via a sector feature buffer. Central to PFCF is Polar Hierarchical Mamba (PHiM), a streaming backbone designed for polar coordinates that uses bidirectional Mamba blocks for local spatial encoding and forward Mamba for temporal modeling, along with dimensionally-decomposed convolutions to mitigate distortion.

## Method Summary
The method processes LiDAR point clouds as egocentric sequences by dividing full scans into partial angular sectors. PHiM, the core backbone, stacks blocks containing bidirectional local Mamba layers for spatial encoding, dimensionally-decomposed convolutions for distortion mitigation, and forward global Mamba for temporal modeling. The sector feature buffer accumulates lightweight polar features from incoming sectors, stitches them into a full feature map, and transforms to Cartesian BEV coordinates for global reasoning. The system achieves streaming-level throughput while maintaining full-scan accuracy through this hybrid coordinate processing approach, implemented in OpenPCDet with Adam optimizer and OneCycle LR policy on Waymo Open Dataset.

## Key Results
- Achieves 71.89% mAP and 67.72% mAPH on Waymo validation, matching full-scan accuracy
- Outperforms prior streaming methods by 10% mAP while maintaining twice the update rate
- Demonstrates effective streaming performance on nuScenes with 74.5% NDS and 73.2% mAP
- Shows 16 mAP improvement over baseline Voxel Mamba adapted for streaming

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Processing partial LiDAR sectors in polar coordinates with a feature buffer enables streaming-level throughput with full-scan accuracy.
- **Mechanism:** The sector feature buffer accumulates lightweight polar features from incoming partial sectors, stitches them into a full feature map, then transforms to Cartesian BEV for global reasoning. This decouples sector processing latency from full-scene prediction frequency.
- **Core assumption:** Sector-level polar features can be meaningfully aggregated into a global Cartesian representation without catastrophic information loss.
- **Break condition:** If polar-to-Cartesian feature projection introduces unacceptable distortion or information loss for small/thin objects, accuracy gains will not materialize.

### Mechanism 2
- **Claim:** Bidirectional local Mamba combined with forward global Mamba enables effective spatiotemporal modeling without geometric serialization heuristics.
- **Mechanism:** Local bidirectional SSM captures intra-sector spatial dependencies; global forward SSM propagates cross-sector context via hidden states. Azimuthal ordering provides natural serialization, eliminating Hilbert/Z-curve requirements.
- **Core assumption:** Temporal ordering by azimuth angle preserves sufficient spatial locality for SSM-based sequence modeling.
- **Break condition:** If azimuthal ordering fails to preserve spatial adjacency for objects spanning multiple sectors, SSM hidden states will not carry meaningful cross-sector context.

### Mechanism 3
- **Claim:** Dimensionally-decomposed 2D convolutions on (r,z) and (θ,z) planes mitigate polar distortion while preserving spatial locality.
- **Mechanism:** By avoiding convolution on the high-distortion (r,θ) plane and decomposing 3D operations into separate 2D passes, kernels operate in planes with better translation invariance. This reduces the need for post-hoc distortion correction.
- **Core assumption:** The (r,θ) plane accounts for sufficient distortion that avoiding it measurably improves feature quality.
- **Break condition:** If distortion in (r,z) or (θ,z) planes is also substantial, or if decomposition prevents learning joint (r,θ) features, accuracy will degrade.

## Foundational Learning

- **Concept:** Polar vs. Cartesian coordinate systems for LiDAR
  - **Why needed here:** The entire architecture hinges on understanding why polar coordinates are efficient for streaming but introduce distortion, and why Cartesian coordinates enable accurate global reasoning.
  - **Quick check question:** Can you explain why objects of equal physical size appear differently in polar coordinates based on distance from the ego vehicle?

- **Concept:** State space models (SSMs) and Mamba architecture
  - **Why needed here:** PHiM is built on Mamba blocks; understanding how SSMs handle sequences via hidden states and discretization is essential to grasp the temporal modeling approach.
  - **Quick check question:** How does a discretized SSM differ from an RNN in terms of computational complexity during training and inference?

- **Concept:** Streaming vs. full-scan perception tradeoffs
  - **Why needed here:** The paper explicitly targets the latency-accuracy Pareto frontier; you must understand sensor latency, throughput, and the constraints each paradigm imposes.
  - **Quick check question:** Why can't full-scan methods exceed 10 predictions per second with a 100ms-scanning LiDAR, regardless of model speed?

## Architecture Onboarding

- **Component map:** Input sector -> Voxelization in cylindrical coordinates -> PHiM block sequence -> Local spatial encoding + temporal hidden state propagation -> Feature extraction -> SFB aggregation -> Polar-to-Cartesian transform -> BEV backbone -> Detection output

- **Critical path:**
  1. Input sector → voxelization in cylindrical coordinates
  2. PHiM block sequence → local spatial encoding + temporal hidden state propagation
  3. Feature extraction → SFB aggregation
  4. Polar-to-Cartesian transform → BEV backbone → detection output

- **Design tradeoffs:**
  - **Sector size vs. throughput:** Smaller sectors increase update rate but shorten SSM sequences, potentially reducing spatiotemporal modeling capacity.
  - **Decomposed convolutions vs. parameter efficiency:** Avoiding (r,θ) convolutions reduces distortion but adds sequential layer overhead; reported ~2× parameter reduction vs. Voxel Mamba.
  - **SFB memory vs. latency:** Larger buffers hold more sector features for better context but increase peak memory; paper uses buffer size matching full-scan (e.g., 4 sectors at 1/4 size).

- **Failure signatures:**
  - **Objects at sector boundaries:** If missed in initial detection and not recovered after buffering, indicates insufficient cross-sector propagation in global Mamba or inadequate SFB aggregation.
  - **Distortion artifacts on near-range objects:** Suggests decomposed convolutions still propagate (r,θ) distortion through (r,z) or (θ,z) planes.
  - **Memory OOM on smaller GPUs:** Peak memory ~1.7 GB reported for PHiM; SFB adds overhead proportional to sector count and feature dimensions.

- **First 3 experiments:**
  1. **Ablate PHiM vs. baseline Mamba:** Replace PHiM with Voxel Mamba adapted for streaming (as in Table 5) to isolate architectural contribution; expect ~16 mAP gap on Waymo 1/100 subsample.
  2. **Vary sector granularity:** Run PFCF at 1/1, 1/2, 1/4, 1/8 sectors; plot throughput vs. mAP to verify streaming benefits and identify diminishing returns point.
  3. **Visualize polar-to-Cartesian feature projection:** Output intermediate BEV feature maps from SFB before/after Cartesian backbone; check for systematic distortion patterns or missing regions near sector boundaries.

## Open Questions the Paper Calls Out
- How does PHiM perform in long-horizon driving scenarios involving hundreds of sectors spanning multiple full LiDAR rotations?
- Can the depth-scaling limitations of decomposed convolutions be mitigated to allow for deeper polar feature extraction?
- Can the inference overhead of Mamba blocks be optimized to prevent throughput degradation at extremely small sector sizes?

## Limitations
- The polar-to-Cartesian feature projection mechanism relies on accumulated sector features that may introduce information loss for objects spanning sector boundaries or thin structures, though quantitative boundary artifact analysis is not provided.
- The performance gains depend on specific Waymo Open Dataset characteristics; generalization to other datasets with different point density distributions or scanning patterns remains unverified.
- Computational overhead of the sector feature buffer and coordinate transformation pipeline is not fully characterized across different hardware configurations.

## Confidence
- **High Confidence:** The hybrid coordinate processing approach (polar for speed, Cartesian for accuracy) is well-motivated and technically sound, with clear architectural separation of concerns.
- **Medium Confidence:** The Mamba-based spatiotemporal modeling shows promise, but the claim that azimuthal ordering naturally serializes spatial relationships without geometric heuristics needs empirical validation on boundary cases.
- **Low Confidence:** The dimensionally-decomposed convolution approach for distortion mitigation is theoretically justified but lacks ablation studies showing the specific impact of avoiding (r,θ) convolutions versus alternative approaches.

## Next Checks
1. **Boundary Effect Analysis:** Visualize and quantify detection accuracy degradation specifically for objects near sector boundaries in the SFB output before Cartesian transformation to validate cross-sector context propagation claims.
2. **Alternative Coordinate Serializations:** Implement and compare PHiM performance using Hilbert curve or Z-curve ordering versus azimuthal ordering to test whether the claimed naturalness of temporal serialization holds.
3. **Distortion Sensitivity Testing:** Systematically vary the degree of polar distortion (e.g., by simulating different LiDAR mounting heights or scanning geometries) and measure the corresponding accuracy impact to validate the decomposed convolution design choice.