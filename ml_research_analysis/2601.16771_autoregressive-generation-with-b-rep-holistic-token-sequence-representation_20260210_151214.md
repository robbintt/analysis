---
ver: rpa2
title: AutoRegressive Generation with B-rep Holistic Token Sequence Representation
arxiv_id: '2601.16771'
source_url: https://arxiv.org/abs/2601.16771
tags:
- b-rep
- generation
- sequence
- token
- face
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BrepARG introduces the first holistic token sequence representation
  for B-rep generation, encoding geometry and topology into a unified sequence of
  geometry tokens, position tokens, and face index tokens. A decoder-only transformer
  autoregressive model is trained on this representation to generate complete B-rep
  models.
---

# AutoRegressive Generation with B-rep Holistic Token Sequence Representation

## Quick Facts
- arXiv ID: 2601.16771
- Source URL: https://arxiv.org/abs/2601.16771
- Reference count: 40
- Primary result: First holistic token sequence representation for B-rep generation achieving 87.6% validity on DeepCAD

## Executive Summary
BrepARG introduces a novel approach to B-rep generation by encoding geometry, position, and topology into a unified token sequence. The framework combines VQ-VAE for geometric features, uniform scalar quantization for positional data, and direct indexing for topological relationships. A decoder-only transformer autoregressive model is trained on this representation to generate complete B-rep models. The method achieves state-of-the-art performance on standard CAD datasets while demonstrating superior training and inference efficiency.

## Method Summary
The method encodes B-rep models into three token types: geometry tokens via VQ-VAE, position tokens via uniform scalar quantization, and face index tokens for topology. A topology-aware sequentialization strategy using DFS for faces and MAX-IDX-A for edges creates a causal token order. A decoder-only transformer (8 layers, 256 dim) is trained to predict the next token in sequence. During inference, nucleus sampling generates new sequences which are detokenized through VQ-VAE decoding, dequantization, and post-processing with union-find vertex clustering to ensure watertight models.

## Key Results
- Achieves 87.6% validity score on DeepCAD dataset (vs 76.6% for previous best)
- Demonstrates improved COV/MMD/JSD metrics compared to prior methods
- Trains on DeepCAD in 1.2 days using 4 H20 GPUs
- Inference takes 1.5 seconds per model on RTX 4090 GPU

## Why This Works (Mechanism)

### Mechanism 1: Unified Tokenization for Joint Distribution Learning
By encoding heterogeneous B-rep data into a single holistic token sequence, the model learns joint probability distributions of topological connectivity and geometric shape simultaneously. This unified approach allows geometric decisions to be conditioned directly on topological history through self-attention across the unified token stream.

### Mechanism 2: Topology-Aware Sequentialization
Imposing deterministic, topology-aware ordering (DFS for faces, MAX-IDX-A for edges) reduces distribution complexity by placing related geometric primitives close together. This creates a causal flow where local structural relationships are preserved, shortening the attention span required to resolve connectivity.

### Mechanism 3: Uniform Scalar Quantization for Position
Mapping continuous 3D coordinates directly to discrete indices via uniform scalar quantization prevents training instability often seen with VQ for positional data. This deterministic mapping ensures stable gradient flow and precise reconstruction without the degeneracy issues of single-codeword approaches.

## Foundational Learning

- **Boundary Representation (B-rep)**: Understanding that B-rep requires strict topological consistency (watertightness) is essential for grasping why validity metrics are critical. Quick check: Can you explain why generating a valid face sequence is insufficient if edge connectivity is inconsistent?

- **VQ-VAE (Vector Quantized Variational Autoencoder)**: Geometry tokens are indices from a VQ-VAE codebook, not raw data. Understanding the difference between continuous latent space and discrete codebook is key to debugging reconstruction errors. Quick check: If VQ-VAE codebook utilization is low, how would that affect generated B-rep face diversity?

- **Decoder-only Transformer & Causal Masking**: The generative engine is an autoregressive transformer where causal masking prevents cheating by looking at future tokens during training. Quick check: In sequence $S = [START, S_f, SEP, S_e, END]$, which tokens are visible when processing the first edge token?

## Architecture Onboarding

- **Component map**: Tokenizer (UV sampling → VQ-VAE/Uniform Quantizer/Direct Indexing) → Sequencer (DFS/MAX-IDX-A ordering) → Transformer (8-layer decoder-only) → Detokenizer (VQ-VAE Decoder + Dequantization + Union-Find post-processing)

- **Critical path**: The Sequentialization Strategy is the most brittle component. The paper shows random ordering drops validity by ~20%, so modifying DFS logic or MAX-IDX-A edge sorting requires re-verifying convergence.

- **Design tradeoffs**: $L=2048$ for position quantization balances precision against sequence vocabulary size. Lower $L$ speeds training but risks geometric intersections; higher $L$ increases transformer burden on sparse positional tokens.

- **Failure signatures**:
  - "Drifting" Geometry: Valid topology but faces don't close (low Validity), likely VQ-VAE reconstruction error or insufficient context
  - Codebook Collapse: Low geometry variety suggests checking VQ-VAE codebook usage and applying CVQ-VAE restart strategies

- **First 3 experiments**:
  1. Tokenization Reconstruction Test: Pass real B-reps through Tokenizer→Detokenizer pipeline to measure pure geometric loss
  2. Ordering Ablation: Train with Random vs. proposed DFS ordering on subset to observe convergence speed difference
  3. Validity Stress Test: Generate 1000 samples and verify watertightness through CAD kernel (OpenCascade)

## Open Questions the Paper Calls Out

### Open Question 1
Can higher-fidelity geometric quantization schemes reduce precision loss that leads to invalid geometries? The authors identify "precision loss introduced by the VQ-VAE" as a primary failure cause and propose this for future work. This remains unresolved as the current codebook size may be insufficient for fine-grained geometric details.

### Open Question 2
What efficient autoregressive modeling strategies can mitigate instability from long token sequences? The paper lists "increased complexity of modeling long autoregressive sequences" as a failure factor, calling for more efficient strategies. This is unresolved as standard transformer attention scales quadratically with sequence length.

### Open Question 3
How does the method perform on B-rep models exceeding the 50-face dataset limit? The paper filters to models with fewer than 50 faces, suggesting potential limitations for complex industrial CAD models. It's unclear if topology-aware sequentialization maintains effectiveness as sequence length grows significantly.

## Limitations

- Scalability constraints: 50-face limit on DeepCAD suggests potential issues with industrial CAD models containing hundreds of faces and complex internal voids
- Geometric fidelity: VQ-VAE reconstruction only guarantees 1% bounding box accuracy without reporting per-vertex positional errors or angular deviations for curved surfaces
- Expressiveness bounds: 8-layer transformer with 256 embedding dimension may be insufficient for capturing long-range topological dependencies in highly complex B-reps

## Confidence

**High Confidence**: Core methodology of unified tokenization is technically sound and experimental framework is reproducible. The 87.6% validity improvement over 76.6% is statistically significant.

**Medium Confidence**: "State-of-the-art" claim requires qualification as DeepCAD filtering constraints may favor autoregressive approach, and graph-based B-rep generation methods weren't benchmarked on the same filtered data.

**Low Confidence**: Scalability claims to industrial CAD data are unsupported. No evidence provided that the approach works beyond curated DeepCAD and ABC datasets, particularly for models with hierarchical features or non-manifold geometries.

## Next Checks

1. **Industrial Dataset Validation**: Apply BrepARG to professional CAD datasets (GrabCAD, Thingiverse) with 100+ faces and complex internal structures. Measure validity, reconstruction error per vertex, and generation time to test if 50-face constraint is fundamental.

2. **Attention Pattern Analysis**: Extract and visualize attention weights from trained transformer to verify meaningful topological relationships (adjacent faces attend to each other) rather than positional encoding reliance. Compare patterns between high-validity and low-validity generations.

3. **Reconstruction Error Characterization**: Compute maximum vertex displacement, mean surface normal deviation, and edge length error for reconstructed B-reps beyond 1% bounding box metric to establish whether VQ-VAE introduces manufacturing-relevant geometric distortions.