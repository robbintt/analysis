---
ver: rpa2
title: 'FLEKE: Federated Locate-then-Edit Knowledge Editing'
arxiv_id: '2502.15677'
source_url: https://arxiv.org/abs/2502.15677
tags:
- knowledge
- editing
- client
- clients
- fleke
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces FLEKE, a novel federated learning task enabling
  multiple clients to collaboratively perform knowledge editing on large language
  models while preserving privacy and reducing redundant computations. To address
  this, the authors propose FedEdit, a two-stage framework where clients first apply
  local LEKE and upload mediator knowledge vectors (MKVs), then retrieve relevant
  MKVs from the server for re-editing based on cosine similarity.
---

# FLEKE: Federated Locate-then-Edit Knowledge Editing

## Quick Facts
- arXiv ID: 2502.15677
- Source URL: https://arxiv.org/abs/2502.15677
- Reference count: 18
- FLEKE achieves over 96% retention of non-federated LEKE performance while reducing redundant computations in federated knowledge editing

## Executive Summary
FLEKE introduces a novel federated learning task that enables multiple clients to collaboratively perform knowledge editing on large language models while preserving privacy. The framework addresses the challenge of redundant computations in federated settings by introducing a two-stage approach where clients first perform local knowledge editing and then share mediator knowledge vectors for efficient collaboration. The method significantly outperforms traditional federated averaging baselines while maintaining high performance on knowledge editing tasks.

## Method Summary
FLEKE proposes FedEdit, a two-stage framework for federated knowledge editing. In the first stage, clients apply local Locate-then-Edit Knowledge Editing (LEKE) and upload mediator knowledge vectors (MKVs) to a central server. In the second stage, clients retrieve relevant MKVs from the server based on cosine similarity and use them to re-edit their local models. This approach preserves privacy by avoiding direct model sharing while reducing redundant computations through mediator knowledge vector sharing.

## Key Results
- Retains over 96% of non-federated LEKE performance on zsRE and COUNTERFACT datasets
- Achieves approximately twofold improvements over FedAvg-based baselines
- Demonstrates consistent performance across different client numbers and time slots
- FedMEMIT variant shows particular robustness in federated settings

## Why This Works (Mechanism)
FLEKE works by separating the knowledge editing process into two distinct stages that optimize for both privacy preservation and computational efficiency. The mediator knowledge vectors act as compressed representations of editing knowledge that can be shared without exposing raw model parameters. The cosine similarity-based retrieval ensures that only relevant editing knowledge is transferred between clients, minimizing redundant computations while maintaining editing effectiveness.

## Foundational Learning
- Federated Learning: Distributed machine learning where multiple clients collaborate without sharing raw data - needed for privacy preservation in knowledge editing tasks
- Locate-then-Edit Knowledge Editing: A paradigm where models first locate relevant knowledge and then edit it - required for precise and efficient knowledge updates
- Mediator Knowledge Vectors: Compact representations of editing knowledge that preserve privacy while enabling knowledge transfer - essential for reducing communication overhead
- Cosine Similarity Retrieval: Vector similarity measure for matching relevant editing knowledge - crucial for efficient mediator knowledge vector selection
- Knowledge Editing vs Fine-tuning: Direct modification of specific knowledge in LLMs versus general parameter updates - important for targeted and efficient knowledge updates

## Architecture Onboarding

**Component Map:**
Client -> Local LEKE -> MKV Upload -> Server Storage -> MKV Retrieval -> Re-editing

**Critical Path:**
1. Local knowledge editing by clients
2. MKV generation and upload to server
3. Cosine similarity-based MKV retrieval
4. Re-editing using retrieved MKVs

**Design Tradeoffs:**
- Privacy vs. Performance: Direct model sharing would be more efficient but compromises privacy
- MKV compression vs. editing fidelity: More compressed vectors reduce communication but may lose editing precision
- Retrieval frequency vs. computational overhead: More frequent retrievals improve performance but increase computational costs

**Failure Signatures:**
- Performance degradation when cosine similarity fails to match relevant MKVs
- Communication bottlenecks from excessive MKV uploads
- Local editing conflicts when multiple clients edit the same knowledge regions

**First Experiments to Run:**
1. Single-client baseline to establish non-federated LEKE performance
2. Two-client federated experiment to test basic MKV sharing functionality
3. Varying client number experiment to assess scalability and performance retention

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Results generalizability limited to two specific datasets (zsRE and COUNTERFACT)
- Computational overhead analysis lacks comprehensive comparison with full cost accounting
- Cosine similarity-based retrieval robustness under heterogeneous data quality requires further validation

## Confidence
- Performance retention claims: High confidence
- Generalization across datasets: Medium confidence
- Computational efficiency improvements: Medium confidence

## Next Checks
1. Evaluate FLEKE on additional knowledge editing benchmarks with diverse data distributions to assess generalizability beyond zsRE and COUNTERFACT datasets
2. Conduct comprehensive computational cost analysis comparing total resource usage (including mediator knowledge vector generation and retrieval) between FLEKE and both non-federated LEKE and other federated approaches
3. Test the robustness of the cosine similarity-based MKV retrieval mechanism under scenarios with heterogeneous data quality and varying levels of noise across client nodes