---
ver: rpa2
title: A Unified Gradient-based Framework for Task-agnostic Continual Learning-Unlearning
arxiv_id: '2505.15178'
source_url: https://arxiv.org/abs/2505.15178
tags:
- learning
- unlearning
- data
- task
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a unified gradient-based framework (UG-CLU)
  for continual learning-unlearning (CLU), which combines knowledge acquisition and
  data removal in intelligent systems. The authors reveal that CL and MU share an
  intrinsic connection through Kullback-Leibler divergence minimization, decomposing
  gradient updates into four components: learning, unlearning, preserving, and modulating
  via weight saliency.'
---

# A Unified Gradient-based Framework for Task-agnostic Continual Learning-Unlearning

## Quick Facts
- arXiv ID: 2505.15178
- Source URL: https://arxiv.org/abs/2505.15178
- Reference count: 40
- Primary result: UG-CLU framework achieves lowest KL divergence to oracle models while maintaining high computational efficiency across CIFAR-10 and TinyImageNet benchmarks

## Executive Summary
This paper introduces a unified gradient-based framework (UG-CLU) for continual learning-unlearning (CLU) that combines knowledge acquisition and data removal in intelligent systems. The authors reveal that CL and MU share an intrinsic connection through Kullback-Leibler divergence minimization, decomposing gradient updates into four components: learning, unlearning, preserving, and modulating via weight saliency. A key challenge addressed is balancing knowledge update and retention during sequential learning-unlearning cycles. The proposed solution introduces a remain-preserved manifold constraint with fast-slow weight adaptation to efficiently approximate second-order optimization, combined with adaptive weighting and balanced weight saliency. Experiments on CIFAR-10 and TinyImageNet demonstrate that UG-CLU effectively coordinates incremental learning, precise unlearning, and knowledge stability across multiple datasets and model architectures, achieving the lowest KL divergence to oracle models while maintaining high computational efficiency. The paper also pioneers task-agnostic CLU scenarios supporting fine-grained unlearning at cross-task category and random sample levels.

## Method Summary
UG-CLU is a unified gradient-based framework that combines continual learning and machine unlearning through KL divergence minimization. The method decomposes gradient updates into four components: learning (gradient descent on new data), unlearning (gradient ascent on target data), preservation (gradient on retained data via memory buffer), and saliency modulation (weight importance adjustment). The core innovation is the remain-preserved manifold constraint, which uses KL divergence on remaining data as the optimization metric to induce Hessian compensation for CLU iterations. This is implemented through a fast-slow weight adaptation mechanism that efficiently approximates second-order optimization without explicit Hessian inversion. The framework employs a reservoir memory buffer (5,000 samples) and uses adaptive coefficients with balanced weight saliency masks to coordinate incremental learning, precise unlearning, and knowledge stability.

## Key Results
- UG-CLU achieves the lowest KL divergence to oracle models compared to baseline methods across both CIFAR-10 and TinyImageNet datasets
- The framework demonstrates effective task-agnostic unlearning at both cross-task category and random sample levels, outperforming task-aware baselines
- Computational efficiency is maintained through single-buffer updates, with memory overhead scaling linearly with dataset size

## Why This Works (Mechanism)

### Mechanism 1
Unifying continual learning and machine unlearning as KL divergence minimization to an oracle model provides a theoretically grounded optimization direction. The framework models the ideal CLU outcome as an oracle model trained on the joint learning data minus unlearning data. By minimizing KL divergence between the current model's output distribution and this oracle, it derives a gradient update direction decomposed into four components: learning, unlearning, preservation, and saliency modulation. This approach assumes the oracle model parameters exist and are locally optimal, and that the current model can be characterized as an intermediate point on the optimization trajectory between initial and oracle parameters.

### Mechanism 2
The remain-preserved manifold constraint uses KL divergence on remaining data as the optimization metric to modulate updates via online Hessian approximation. Instead of Euclidean metric, the method uses DKL(pzR(θk)||pzR(θk+1)) as the manifold metric for steepest descent. This induces a correction term involving (HR^k)^-1, the inverse Hessian on remaining data, which directs updates along paths that minimally impact the output distribution on retained set. This mechanism assumes the current and oracle models are well-trained on remaining data, so their gradients on that set are near zero, enabling valid second-order Taylor expansion.

### Mechanism 3
The fast-slow weight adaptation mechanism efficiently approximates the Hessian-modulated update direction without explicit, costly Hessian inversion. The method uses bi-level optimization where "fast" weights take a step on current task to get θQ^k, then several "slow" gradient steps are taken on remaining data to fine-tune from θQ^k to a point θR^k. The difference θk - θR^k is theoretically shown to approximate βk²(HR^k)^-1∇LQ(θk), the desired Hessian-preconditioned task gradient. This assumes small learning rates, the loss L_R is µ-smooth, and both θk and θQ^k lie within a neighborhood of the optimal remaining-data model θR^k.

## Foundational Learning

- Concept: **Continual Learning (Catastrophic Forgetting)**
  - Why needed here: The entire CLU problem inherits the stability-plasticity dilemma from CL. Understanding why sequential learning degrades performance on old tasks is essential to grasp the purpose of the remaining data buffer and the preservation gradient component.
  - Quick check question: Can you explain why training on a new task with standard gradient descent often reduces accuracy on previously learned tasks?

- Concept: **Machine Unlearning and Privacy (Membership Inference)**
  - Why needed here: A core goal is to remove the influence of specific data. Understanding the threat model (e.g., Membership Inference Attacks - MIA) clarifies why unlearning is more than just reducing accuracy on the target data (UA) and must also remove statistical traces.
  - Quick check question: Why is it insufficient to judge unlearning success only by the model's accuracy drop on the forgotten data? What attack could still succeed?

- Concept: **Second-Order Optimization & Hessian Approximation**
  - Why needed here: The central theoretical contribution uses the Hessian of the loss on the remaining data to shape the update trajectory. Knowing why exact Hessian use is impractical (O(n²) storage/compute) and common approximation strategies (Fisher, diagonal) exist helps evaluate the proposed fast-slow method's design.
  - Quick check question: What is the computational barrier to using the full Hessian matrix for a large neural network? Name one standard technique for approximating curvature information.

## Architecture Onboarding

- Component map:
  1. Reservoir Memory Buffer: Stores a fixed-size, representative subset of historical data to approximate the remaining set DR for gradient and Hessian computation
  2. Task Handler: Determines the request type (Qt ∈ {L, U}) and routes data Dt to the appropriate gradient computation
  3. Adaptive Coefficient Module: Computes sample-wise weights (ε̃^L_k or ε̃^U_k) for the task gradient based on loss magnitude and iteration step
  4. Weight Saliency Masker: Computes a binary mask m using the ratio of task gradient magnitude to initial remaining gradient magnitude
  5. Fast-Slow Optimizer: Implements the inner loop (masked, weighted task gradient step) and outer loop (remaining data fine-tuning and linear interpolation) to produce the final model update
  6. KL Divergence Monitor: Evaluates the primary objective by comparing model outputs to a separately trained oracle model

- Critical path: The correctness of the fast-slow optimization loop is most critical. A bug in the interpolation step or the fine-tuning process will break the implicit Hessian approximation, directly undermining the framework's core stability mechanism.

- Design tradeoffs:
  - Buffer Size vs. Fidelity: A larger buffer better approximates DR, improving stability but increasing memory and per-step compute
  - Inner/Outer Loop Steps vs. Compute: More fine-tuning steps (K_in) may improve the Hessian approximation accuracy but linearly increase training time
  - Saliency Threshold (γ) vs. Plasticity-Stability: A higher threshold creates a sparser mask, protecting more weights but potentially limiting the model's ability to learn/unlearn effectively

- Failure signatures:
  1. Unlearning Failure: High UA and MIA scores post-unlearning. Likely causes: incorrect gradient sign for unlearning, adaptive coefficients not decaying, or mask overly suppressing unlearning gradients
  2. Excessive Forgetting: Sharp drop in LA and high FM. Likely causes: buffer too small or corrupted, β_R too high causing overshoot, or saliency mask mis-configured
  3. Optimization Divergence: Loss explodes during training. Likely cause: gradient ascent step for unlearning is too large relative to stability mechanisms

- First 3 experiments:
  1. Task-Aware CLU Baseline: Replicate the Table 2 setup on CIFAR-10/ResNet-18 with standard task sequence
  2. Ablation on Buffer Size: Run task-agnostic class-wise unlearning setup with varying buffer sizes (1k, 5k, 10k)
  3. Saliency Threshold Sweep: On same task-agnostic setup, vary the mask threshold γ to confirm sensitivity analysis

## Open Questions the Paper Calls Out

- Can the UG-CLU framework be effectively transferred to Natural Language Processing (NLP) and multi-modal domains?
  - Basis: Experimental validation focuses on image classification tasks, and applicability to NLP and multi-modal scenarios remains to be verified
  - Why unresolved: The theoretical derivation relies on Hessian approximations and gradient modulations tested primarily on CNNs and Vision Transformers using cross-entropy loss; it is unclear if manifold constraints and weight saliency masks hold for distinct loss landscapes and architectures typical of NLP
  - What evidence would resolve it: Empirical evaluations of UG-CLU method on sequential text classification or multi-modal benchmarks, demonstrating comparable unlearning efficacy and knowledge retention to vision tasks

- Can dynamic importance sampling strategies for the memory buffer improve the stability-efficiency trade-off compared to current reservoir sampling approach?
  - Basis: The method employs only basic reservoir sampling strategy, suggesting future work could explore optimization mechanisms such as dynamic importance sampling
  - Why unresolved: Reservoir sampling treats all retained data equally, potentially failing to prioritize samples critical for maintaining the "remain-preserving manifold" during complex unlearning operations
  - What evidence would resolve it: Experiments integrating gradient-based or uncertainty-based importance sampling into UG-CLU buffer, showing improved forgetting metrics or stability without increasing buffer size

- What are the theoretical convergence guarantees for gradient iterations within the unified CLU optimization framework?
  - Basis: The authors acknowledge that analyzing convergence of gradient iterations and their impact on generalization in deep CLU systems remains challenging
  - Why unresolved: The paper relies on Assumption 2 (local convexity) and Taylor expansions to derive update rules, but does not provide formal proof that alternating fast-slow weight updates converge to stable solution in non-convex deep networks
  - What evidence would resolve it: A formal theoretical analysis establishing convergence bounds for the proposed steepest descent directions under the unified KL divergence objective

## Limitations

- The framework's performance heavily depends on accurate second-order approximations through fast-slow mechanism, requiring careful hyperparameter tuning and small learning rates
- The memory buffer's representativeness directly impacts Hessian approximation quality, creating inherent tradeoff between stability and computational cost
- Theoretical assumptions of local convexity and well-trained remaining data models may not hold in highly non-convex deep neural network landscapes

## Confidence

- **High Confidence**: The KL divergence decomposition into four gradient components is mathematically rigorous and well-supported by Proposition 1. Experimental results showing improved KL divergence and task-agnostic unlearning performance are reproducible with provided specifications.
- **Medium Confidence**: The remain-preserved manifold constraint's effectiveness relies on accurate Hessian approximation through fast-slow mechanism. While Proposition 3 provides theoretical justification, practical performance depends heavily on hyperparameter tuning and may vary across architectures.
- **Low Confidence**: The framework's scalability to large-scale datasets and complex model architectures beyond ResNet-18 and Swin-T remains unproven. Computational efficiency claims are based on single-buffer updates, but memory overhead for large-scale applications is unclear.

## Next Checks

1. **Long-term Stability Test**: Evaluate UG-CLU on extended task sequences (10+ tasks) to verify whether the remain-preserved manifold constraint prevents catastrophic forgetting over longer horizons than current 4-6 task experiments.

2. **Architecture Generalization**: Test the framework on transformer-based architectures (e.g., ViT, BERT) and larger models to assess whether the fast-slow Hessian approximation scales effectively beyond convolutional networks.

3. **Memory Efficiency Analysis**: Measure actual memory consumption and runtime overhead across different buffer sizes (1k, 5k, 10k) and compare against theoretical O(n) scaling claims, particularly for TinyImageNet-scale datasets.