---
ver: rpa2
title: Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic
  Constraints
arxiv_id: '2505.07883'
source_url: https://arxiv.org/abs/2505.07883
tags:
- latent
- event
- probabilities
- embeddings
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of incoherent probability estimates
  from large language models (LLMs), where probabilities assigned to complementary
  events often fail to sum to one, violating the axioms of probability theory. The
  authors propose an unsupervised method to recover coherent probabilities directly
  from LLM embeddings by enforcing axiomatic constraints through a modified variational
  autoencoder (VAE).
---

# Recovering Event Probabilities from Large Language Model Embeddings via Axiomatic Constraints

## Quick Facts
- arXiv ID: 2505.07883
- Source URL: https://arxiv.org/abs/2505.07883
- Authors: Jian-Qiao Zhu; Haijiang Yan; Thomas L. Griffiths
- Reference count: 40
- Key outcome: Recovers coherent probabilities from LLM embeddings, reducing incoherence from 0.13 to 0.02 while maintaining accuracy

## Executive Summary
This paper addresses the problem of incoherent probability estimates from large language models (LLMs), where probabilities assigned to complementary events often fail to sum to one, violating the axioms of probability theory. The authors propose an unsupervised method to recover coherent probabilities directly from LLM embeddings by enforcing axiomatic constraints through a modified variational autoencoder (VAE). The VAE is trained to both reconstruct the original embeddings and predict embeddings of complementary events by selectively modifying a subset of latent variables, with a Gaussian prior enforcing the additive rule for complementary events.

## Method Summary
The method uses a β-VAE (β=5) to compress LLM embeddings into a compact latent space where a single latent variable z(1) represents event probability as log-odds. The VAE is trained in two steps: Step 1 reconstructs original embeddings, while Step 2 predicts complementary event embeddings by negating z(1). This sign-flipping operation enforces the additive axiom for complementary events. After training, the sigmoid transformation of z(1) yields recovered probabilities that exhibit significantly greater coherence than text-based probability judgments.

## Key Results
- Incoherence reduced from 0.13 to 0.02 on training set for recovered probabilities
- Precovered maintains comparable accuracy to Pjudged (MSE 0.059 vs 0.060)
- Precovered shows stronger alignment with true probabilities (Pearson's r = 0.83 vs 0.80)
- Ablation study confirms two-step training approach is essential for interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A single latent variable can encode event probability as log-odds while other latent variables capture orthogonal prompt features.
- Mechanism: The VAE compresses high-dimensional LLM embeddings (d dimensions) into a compact latent space (k ≪ d). The first latent variable z(1) is explicitly designated to represent log-odds of event probability. Conversion via sigmoid yields P_recovered = e^z(1) / (1 + e^z(1)). Non-modified latent variables (z(2:10)) capture interpretable features like number of rolls (z(9), R²=50%) and comparison type (z(5), R²=61%).
- Core assumption: Probability information is linearly separable within embeddings and can be isolated through unsupervised compression.
- Evidence anchors:
  - [section 4] Figure 3 shows only z(1) exhibits negative correlation between complementary events; all others show positive relationships.
  - [section 4] Table 2 confirms z(1) has strongest association with true probabilities (coefficient 2.08) via Lasso regression.
  - [corpus] Limited direct corpus support; related work on disentanglement (Higgins et al., 2017) suggests feasibility but doesn't confirm for probability specifically.
- Break condition: If latent variables exhibit polysemantic mixing where z(1) correlates with non-probability features, interpretability degrades.

### Mechanism 2
- Claim: Sign-flipping the probability latent variable enforces the additive axiom for complementary events.
- Mechanism: The transformation T(z) = [-z(1), z(-1)] negates only the first latent variable while preserving others. Since z(1) represents log-odds, negation yields complementary probability: log(P/(1-P)) → log((1-P)/P). A centered Gaussian prior N(0, I) regularizes z(1) toward zero, corresponding to P=0.5, which is the expected mean under the additive constraint.
- Core assumption: The relationship between complementary event embeddings can be captured entirely through this selective latent modification.
- Evidence anchors:
  - [abstract] "Gaussian prior enforcing the additive rule for complementary events"
  - [section 3] Equation 7 demonstrates mathematically that sign-flipping enforces P_recovered + (1-P_recovered) = 1.
  - [section 4] Precovered achieves incoherence of 0.02 vs 0.13 for Pjudged on training set.
  - [corpus] No direct corpus validation of this specific mechanism.
- Break condition: If the encoder-decoder cannot accurately predict complementary embeddings from modified latents, the constraint fails to propagate.

### Mechanism 3
- Claim: Interleaved two-step training is necessary for interpretable disentanglement; standard VAE fails.
- Mechanism: Step 1 trains reconstruction (maximize p(e)). Step 2 trains complementary prediction (maximize p(¬e|e)) with modified latent objective L_2. Interleaving every 10 episodes allows the encoder to simultaneously satisfy both objectives, forcing z(1) to become the "probability axis." Without Step 2, polysemanticity dominates—all latent variables show unclear relationships.
- Core assumption: The reconstruction and complementary-prediction objectives share sufficient structure to converge jointly.
- Evidence anchors:
  - [section 4] Ablation study: ablated model (no Step 2) shows incoherence 0.29 vs 0.02, MSE 0.075 vs 0.059 on training set.
  - [section 4] Figure 5 shows ablated latent variables lack clear negative relationships between complementary events.
  - [section 6] "Ablation study confirms that the two-step training approach is essential."
  - [corpus] Chen et al. (2018) on disentanglement in VAEs provides theoretical grounding but doesn't address this specific interleaving scheme.
- Break condition: If interleaving frequency is too low, Step 1 may converge to a local minimum incompatible with Step 2's constraints.

## Foundational Learning

- Concept: **Variational Autoencoder (VAE) and Evidence Lower Bound (ELBO)**
  - Why needed here: The method extends standard VAE by adding a second variational bound L_2 for complementary prediction. Understanding ELBO decomposition (reconstruction + KL divergence) is prerequisite to grasping how axiomatic constraints enter through the prior.
  - Quick check question: Can you derive why maximizing ELBO approximates maximizing marginal likelihood p(e)?

- Concept: **Log-odds representation and sigmoid transformation**
  - Why needed here: The paper interprets z(1) as log-odds rather than raw probability. This representation naturally enforces P + (1-P) = 1 through sign-flipping, and the Gaussian prior at zero corresponds to maximum uncertainty (P=0.5).
  - Quick check question: If z(1) = 0.693, what is P_recovered? (Answer: 0.67, since e^0.693/(1+e^0.693) ≈ 2/3)

- Concept: **β-VAE and controllable regularization strength**
  - Why needed here: The method uses β=5 to strengthen KL divergence penalty, more aggressively enforcing the Gaussian prior that encodes the additive axiom. Higher β trades reconstruction fidelity for constraint adherence.
  - Quick check question: What happens to latent space structure if β is set too high (e.g., β=100)?

## Architecture Onboarding

- Component map:
  - Encoder q_φ(z|e) -> Decoder p_θ(e|z) -> Latent modification module -> Training loop

- Critical path:
  1. Extract last-token embeddings from LLM final layer (e.g., Gemma-2-9b layer 41)
  2. Train VAE with interleaved objectives on complementary event pairs (E and ¬E)
  3. After convergence, encode new embeddings and read z(1) as log-odds
  4. Apply sigmoid transformation to recover calibrated probability

- Design tradeoffs:
  - Latent dimensionality (k=10): Lower k increases compression but risks information loss; paper shows k=10 sufficient for dice domain
  - β value (β=5): Higher β enforces stronger axiomatic constraint but may degrade reconstruction; β=5 balances coherence and accuracy
  - Interleaving frequency (every 10 episodes): More frequent interleaving may improve disentanglement but slows convergence

- Failure signatures:
  - High incoherence in Precovered (>0.1): Suggests Step 2 training failed or β is too low
  - Precovered clustered near 0.5: Encoder may not be learning probability-relevant features; check embedding extraction layer
  - Negative correlation between Precovered and Ptrue (earlier layers): Paper shows layers <25 exhibit this; use final layer embeddings
  - Ablated model performs similarly: Verify Step 2 loss is actually computed; check that complementary pairs are correctly paired

- First 3 experiments:
  1. Reproduction on dice domain: Train on provided dice events, verify incoherence drops from ~0.13 to ~0.02; confirm Figure 3 visualization shows only z(1) with negative relationship
  2. Layer ablation: Extract embeddings from layers {41, 37, 33, 29, 25} and compare Precovered quality; expect degradation in earlier layers per Table 3
  3. β sensitivity analysis: Train with β ∈ {1, 3, 5, 10, 20} and plot incoherence vs. MSE tradeoff; identify optimal β for new domains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the learned latent representations be used for causal interventions to force LLMs to generate coherent probability judgments in text?
- Basis in paper: [explicit] Section 6.1 states, "A natural next step is to investigate whether editing neuron activations based on the learned latent variables can produce more coherent probability judgments."
- Why unresolved: The current work only extracts probabilities from embeddings (P_recovered); it does not demonstrate that modifying the latent space (z) alters the model's output behavior (P_judged).
- What evidence would resolve it: An experiment where the latent variable z(1) is artificially manipulated, resulting in a predictable, coherent shift in the text probabilities generated by the LLM.

### Open Question 2
- Question: Can this framework be extended to enforce complex probabilistic relationships, such as Bayes' rule for conditional and conjunctive events?
- Basis in paper: [explicit] Section 6.1 notes, "The relationship between conjunctive and constituent events could be enforced through Bayes' rule... Future work could explore methods for effectively implementing such axiomatic constraints."
- Why unresolved: The current method only enforces the additive rule for complementary events (P(A) + P(¬A) = 1) via a simple sign-flip operation, which may not suffice for more complex dependencies.
- What evidence would resolve it: A modified architecture that successfully disentangles latent variables for conditional events, recovering probabilities that satisfy P(A and B) = P(A)P(B|A).

### Open Question 3
- Question: Does the quality of recovered probabilities degrade when applied to ambiguous real-world events lacking clear ground truth?
- Basis in paper: [inferred] The paper relies exclusively on dice events to validate accuracy against "true probabilities." It mentions applications in finance and medicine but does not test them.
- Why unresolved: Dice probabilities are distinct from real-world uncertainties; the embeddings for ambiguous events may lack the consistent structure required for the VAE to successfully disentangle the probability information.
- What evidence would resolve it: Evaluation on a dataset of real-world predictions (e.g., economic forecasts) where the recovered probabilities show improved coherence and calibration compared to text-based judgments.

## Limitations

- The method requires explicit knowledge of complementary event pairs, limiting applicability to domains where such pairs are readily available
- The latent variable interpretability depends on the assumption that probability information is linearly separable within embeddings, which may not hold across diverse domains
- The approach is currently validated only on dice-specific event structures and may not generalize to open-domain probability elicitation

## Confidence

- High Confidence: The experimental results showing reduced incoherence (0.13 → 0.02) and maintained accuracy are well-supported by the dice domain data
- Medium Confidence: The mechanism claims about latent variable interpretability and the effectiveness of the sign-flipping transformation are supported by the evidence but rely on assumptions about embedding structure
- Low Confidence: The generalizability of the approach to non-complementary event relationships and the scalability to more complex probability scenarios remain unproven

## Next Checks

1. Cross-Domain Transferability: Apply the method to non-dice probability domains (e.g., weather forecasting, medical diagnosis) where complementary events exist but embedding structures may differ. Measure whether coherence improvements transfer and whether the same latent variable (z(1)) consistently captures probability information.

2. Generalization to Non-Complementary Relationships: Extend beyond complementary events to test whether the method can recover coherent probabilities for related but non-opposite events (e.g., "rain tomorrow" vs "heavy rain tomorrow"). Evaluate whether modified axiomatic constraints can enforce more general probability consistency rules.

3. Real-World LLM Integration: Implement the VAE as a post-processing layer on a deployed LLM (e.g., GPT-4) and evaluate coherence improvements on real-world probability elicitation tasks. Test whether the method can handle the broader distribution of prompts and responses encountered in practice.