---
ver: rpa2
title: 'Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness
  and Susceptibility Among Large Language Models'
arxiv_id: '2503.01829'
source_url: https://arxiv.org/abs/2503.01829
tags:
- persuasion
- claim
- agreement
- persuasive
- persuadee
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "PMIYC introduces an automated framework for evaluating both the\
  \ persuasive effectiveness and susceptibility to persuasion of LLMs through multi-agent\
  \ conversations. It simulates dialogues between a PERSUADER and a PERSUADEE, tracking\
  \ how the PERSUADEE\u2019s stance changes over multiple turns."
---

# Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models

## Quick Facts
- arXiv ID: 2503.01829
- Source URL: https://arxiv.org/abs/2503.01829
- Reference count: 40
- PMIYC framework reveals larger models (Llama-3.3-70B, GPT-4o) are most persuasive, with GPT-4o showing notable resistance to misinformation

## Executive Summary
PMIYC introduces an automated framework for evaluating LLM persuasion dynamics through multi-agent conversations. The framework simulates dialogues between PERSUADER and PERSUADEE agents, tracking stance changes via self-reported agreement scores. Across subjective and misinformation contexts, PMIYC quantifies both persuasive effectiveness and susceptibility using the Normalized Change in Agreement (NCA) metric. The framework is validated against human judgments and shows alignment with prior studies, providing a scalable alternative to human annotation for assessing LLM persuasion dynamics.

## Method Summary
PMIYC evaluates persuasion through t-turn conversations between PERSUADER and PERSUADEE agents using structured prompts with message/ranking tags. The framework tracks self-reported agreement on a 5-point Likert scale, computing NCA to measure stance changes. It evaluates models across subjective claims (Durmus et al. [2024] + Perspectrum) and misinformation claims (TruthfulQA), comparing single-turn (t=3) and multi-turn (t=9) settings. The NCA metric normalizes agreement changes by maximum possible shift, enabling fair cross-model comparisons.

## Key Results
- Larger models (Llama-3.3-70B and GPT-4o) demonstrate highest persuasive effectiveness
- GPT-4o exhibits notably greater resistance to misinformation persuasion than other models
- Multi-turn conversations show significantly higher persuasion effectiveness than single-turn exchanges
- Human validation shows 76% agreement rate with model self-reports (Cohen's κ=0.63)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-turn conversations amplify both persuasive effectiveness and susceptibility compared to single-turn exchanges.
- Mechanism: Iterative argument-exchange allows PERSUADERs to address counterpoints, while PERSUADEEs accumulate exposure to arguments across turns, leading to gradual belief drift—particularly effective in the first two turns where influence peaks.
- Core assumption: Models track and update internal representations of claims across conversation history rather than treating each turn independently.
- Evidence anchors:
  - [abstract] "PMIYC reveals that larger models like Llama-3.3-70B and GPT-4o are the most persuasive"
  - [section 4.2] "the effectiveness of the PERSUADERS increases in multi-turn conversations" and Figure 5(a) shows higher NCA in multi-turn vs single-turn
  - [corpus] "Disagreements in Reasoning" (arxiv 2509.21054) examines how thinking processes dictate persuasion in multi-agent systems, supporting the multi-turn dynamics hypothesis
- Break condition: If models fail to maintain coherent state across turns or treat each response as independent, multi-turn amplification would not occur.

### Mechanism 2
- Claim: Self-reported agreement scores serve as reliable proxies for tracking belief changes during persuasion.
- Mechanism: PERSUADEEs report agreement on a 5-point Likert scale after each turn; the Normalized Change in Agreement (NCA) metric captures stance shifts relative to starting position, enabling cross-model and cross-claim comparisons.
- Core assumption: Models' self-reported scores reflect genuine internal stance rather than surface-level compliance or sycophancy.
- Evidence anchors:
  - [abstract] "The framework is validated against human judgments and aligns with prior studies"
  - [section 5.3.1] Human annotations show 76% match rate with model self-reports, Cohen's κ=0.63 indicating substantial agreement
  - [corpus] Weak direct corpus evidence on self-report reliability specifically; "MMPersuade" (arxiv 2510.22768) focuses on multimodal persuasion evaluation but doesn't validate self-report mechanisms
- Break condition: If models engage in "fake persuasion" (Section D)—reporting agreement without genuine stance change—the NCA metric would overestimate persuasion. Action-based MCQ tasks show 64-78% genuine persuasion rates, suggesting this is a partial but not total failure mode.

### Mechanism 3
- Claim: Persuader effectiveness increases when the model genuinely agrees with the claim it advocates.
- Mechanism: Models classified as "Supporting" (score 4-5) the claim produce higher NCA scores than "Neutral" or "Opposing" persuaders, likely because belief-aligned arguments are more coherent and compelling.
- Core assumption: Models encode genuine beliefs about claims rather than generating arguments purely from role-play instructions.
- Evidence anchors:
  - [section 5.4] Figure 7 shows PERSUADERs with Supporting agreement achieve higher NCA than Opposing persuaders across both subjective and misinformation settings
  - [corpus] No direct corpus evidence on persuader belief alignment; related work focuses on persuasiveness measurement rather than internal belief effects
- Break condition: If models can fully compartmentalize role-play from internal beliefs, or if instruction-following overrides genuine stance, the belief-effectiveness correlation would disappear.

## Foundational Learning

- Concept: **Normalized Change in Agreement (NCA)**
  - Why needed here: Raw agreement score changes are biased toward PERSUADEEs starting at neutral positions (more room to shift). NCA normalizes by the maximum possible shift given the starting score, enabling fair comparison across different initial stances.
  - Quick check question: If a PERSUADEE starts at score 2 and ends at 4, what's the NCA? (Answer: +2/3 ≈ 0.67, since max possible increase from 2 is 3 points)

- Concept: **Role-based Prompt Engineering**
  - Why needed here: PMIYC relies on distinct system prompts for PERSUADER (advocate regardless of belief) and PERSUADEE (evaluate sensibly). Understanding how role instructions interact with model beliefs is critical for interpreting results.
  - Quick check question: What happens if you give a model a PERSUADER prompt for a claim it strongly opposes?

- Concept: **Sycophancy vs. Genuine Persuasion**
  - Why needed here: The paper identifies cases where PERSUADEEs temporarily agree during conversation but revert at final decision—this is sycophantic conformity, not genuine belief change. Distinguishing these is essential for accurate susceptibility measurement.
  - Quick check question: How would you detect sycophancy in a multi-turn persuasion transcript?

## Architecture Onboarding

- Component map:
  Conversation Generator -> Agent Prompts (PERSUADER/PERSUADEE) -> Agreement Tracker -> NCA Calculator -> Early Stopping

- Critical path:
  1. Initialize PERSUADEE with claim → get initial agreement score (sEE0)
  2. For turns 1 to t-1: PERSUADER argues → PERSUADEE responds with updated score
  3. Final decision prompt → PERSUADEE provides final stance
  4. Compute NCA = (sEE_t - sEE_0) / (5 - sEE_0) or (sEE_t - sEE_0) / (sEE_0 - 1)

- Design tradeoffs:
  - **Structured vs. natural dialogue**: Alternating turn-taking lacks human-like interruptions/overlaps but provides reproducible evaluation (Section B.0.1)
  - **Self-report vs. external judge**: LLM-as-judge scoring achieved only ~55% accuracy (Appendix E), motivating the self-report approach
  - **Likert vs. binary**: 5-point scale captures nuance but introduces inter-annotator disagreement at adjacent levels (Section F)

- Failure signatures:
  - **Generation errors**: Models refuse sensitive topics or produce malformed responses lacking tags (>4% failure in subjective domain, Section B.0.1)
  - **Fake persuasion**: PERSUADEE agrees with shifted interpretation rather than original claim (Figure 24 example)
  - **Early stopping edge case**: If PERSUADEE starts at 5, NCA calculation requires handling division by zero

- First 3 experiments:
  1. Reproduce single-turn subjective results (Figure 2) with two model pairs to validate pipeline integration
  2. Test PERSUADEE consistency by prompting same claim 5 times—verify low standard deviation (Table 1 benchmarks: target <0.1 for reliable models)
  3. Run 10 conversations in misinformation setting, manually inspect for "fake persuasion" patterns where PERSUADEE agrees with reformulated claim rather than original

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent do specific architectural choices, pretraining corpora, and alignment procedures causally influence LLM persuasive behavior?
- Basis in paper: [explicit] The conclusion states the framework "does not yet disentangle why these differences arise" and suggests leveraging "families of fully open-source models to enable controlled analyses."
- Why unresolved: The current study evaluates models as black boxes, identifying performance differences without isolating the underlying training or architectural factors responsible.
- What evidence would resolve it: Ablation studies on open-weight models where individual variables (e.g., instruction-tuning data vs. base pretraining) are isolated to measure their specific impact on NCA scores.

### Open Question 2
- Question: Can persuasive effectiveness and susceptibility be systematically controlled or mitigated using data derived from persuasion attempts?
- Basis in paper: [explicit] The conclusion invites "investigating methods to control persuasive effectiveness and susceptibility, such as leveraging data from successful and unsuccessful persuasion attempts."
- Why unresolved: PMIYC currently functions as an evaluation framework; it quantifies traits but does not experiment with fine-tuning or reinforcement learning to alter them.
- What evidence would resolve it: Experiments using PMIYC logs as feedback for RLHF or DPO to specifically reduce a model's susceptibility to misinformation or adjust its persuasiveness.

### Open Question 3
- Question: Do naturalistic conversational features amplify or diminish persuasion susceptibility compared to the strict turn-based protocol used in PMIYC?
- Basis in paper: [inferred] Appendix B acknowledges the limitation of the structured, alternating turn-based protocol, suggesting future work investigate "uneven turn lengths, disfluencies, or partial overlaps."
- Why unresolved: The current framework imposes a rigid structure that may not fully capture the dynamics of human-like or unstructured agent-to-agent dialogue.
- What evidence would resolve it: Extending the PMIYC environment to allow asynchronous or overlapping speech and comparing the resulting susceptibility rates with the baseline turn-taking model.

## Limitations
- Reliance on LLM self-reporting introduces measurement uncertainty, with 24% disagreement rate between model self-reports and human judgments
- Framework focuses on English-language subjective and misinformation claims, limiting generalizability across cultural contexts
- Structured turn-taking protocol may not capture naturalistic conversational dynamics that influence persuasion

## Confidence
- **High Confidence**: Multi-turn conversations show higher persuasion effectiveness than single-turn exchanges
- **Medium Confidence**: Larger models are more persuasive (Llama-3.3-70B, GPT-4o) and GPT-4o shows higher resistance to misinformation
- **Medium Confidence**: Self-reported agreement scores correlate with human judgments (76% match rate, Cohen's κ=0.63)

## Next Checks
1. Implement action-based MCQ validation for a subset of conversations to verify whether self-reported agreement changes correspond to actual belief changes in downstream tasks
2. Test framework robustness by evaluating persuasion across different cultural contexts and non-English language pairs to assess generalizability
3. Conduct ablation studies on prompt engineering components (role instructions, message/ranking tags) to quantify their impact on persuasion measurement accuracy