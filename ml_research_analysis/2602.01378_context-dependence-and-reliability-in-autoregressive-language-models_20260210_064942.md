---
ver: rpa2
title: Context Dependence and Reliability in Autoregressive Language Models
arxiv_id: '2602.01378'
source_url: https://arxiv.org/abs/2602.01378
tags:
- context
- redundancy
- attribution
- information
- units
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of attribution stability in large
  language models under redundant or overlapping context, which undermines trustworthiness
  and increases vulnerability to prompt injection. The authors introduce RISE (Redundancy-Insensitive
  Scoring of Explanation), a method that computes the conditional unique dependence
  of each context unit by measuring how much unique information it provides about
  the next-token distribution conditioned on the remaining context.
---

# Context Dependence and Reliability in Autoregressive Language Models
## Quick Facts
- arXiv ID: 2602.01378
- Source URL: https://arxiv.org/abs/2602.01378
- Reference count: 18
- Authors: Poushali Sengupta; Shashi Raj Pandey; Sabita Maharjan; Frank Eliassen
- Primary result: RISE achieves near-zero redundancy sensitivity in synthetic experiments while maintaining rank stability

## Executive Summary
This paper addresses the problem of attribution stability in large language models under redundant or overlapping context, which undermines trustworthiness and increases vulnerability to prompt injection. The authors introduce RISE (Redundancy-Insensitive Scoring of Explanation), a method that computes the conditional unique dependence of each context unit by measuring how much unique information it provides about the next-token distribution conditioned on the remaining context. RISE normalizes these contributions to produce attribution scores that suppress redundant context. In controlled experiments with prompt duplication, paraphrasing, and overlapping retrieval, RISE achieves significantly lower redundancy sensitivity compared to attention-based and perturbation-based baselines, while maintaining comparable rank stability.

## Method Summary
RISE is built on an information-theoretic foundation that measures conditional unique dependence by quantifying the reduction in next-token uncertainty when a specific context unit is included, given all other context units. The method computes attribution scores by evaluating the KL divergence between next-token distributions with and without each context unit, then normalizes these scores to suppress redundancy. The approach is model-agnostic and operates at inference time without requiring retraining. RISE's mathematical formulation ensures that overlapping or paraphrased context receives lower attribution weight, addressing a key vulnerability in current attribution methods that can be exploited through prompt injection attacks.

## Key Results
- RISE achieves Dup-Split scores near zero on synthetic redundancy tasks, compared to attention scores showing strong dependence on duplication
- The method maintains rank stability comparable to baseline attribution methods while significantly reducing redundancy sensitivity
- RISE attribution scores effectively identify and suppress redundant context in paraphrasing and overlapping retrieval scenarios

## Why This Works (Mechanism)
RISE works by directly modeling the conditional dependence between each context unit and the next-token distribution, accounting for the information already provided by other context units. By measuring unique information contribution rather than absolute contribution, the method naturally suppresses redundant attributions. The normalization procedure ensures that overlapping context units share attribution credit proportionally to their unique information content. This information-theoretic approach captures the actual decision-making process of autoregressive models more accurately than attention-based methods, which can over-attribute to recently attended tokens regardless of redundancy.

## Foundational Learning
- Conditional Mutual Information: Why needed - quantifies unique information contribution between context and predictions. Quick check - verify the KL divergence formulation correctly captures conditional dependence.
- Next-token Distribution Modeling: Why needed - attribution must reflect actual model predictions, not just input processing. Quick check - ensure probability distributions are properly normalized.
- Context Unit Decomposition: Why needed - attribution requires defining what constitutes a "unit" of context. Quick check - validate that token, sentence, or segment boundaries preserve attribution meaning.

## Architecture Onboarding
- Component map: Context tokens -> RISE scoring -> Attribution scores -> Redundancy suppression
- Critical path: Input context → Token embedding → Next-token distribution estimation → RISE computation → Normalized attribution
- Design tradeoffs: RISE trades computational overhead for improved attribution quality; model-agnostic design sacrifices potential optimization opportunities
- Failure signatures: Over-normalization may suppress legitimate context; under-normalization fails to suppress redundancy; computational bottlenecks in long-context scenarios
- First experiments: 1) Verify RISE scores on simple duplication tasks, 2) Compare attribution stability across different context sizes, 3) Test RISE against basic prompt injection scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation on real-world prompt injection attacks beyond synthetic scenarios
- Performance characterization on long-context scenarios remains unexplored
- No analysis of correlation between RISE scores and actual model behavior or downstream task performance

## Confidence
- RISE's information-theoretic foundation and mathematical formulation: High
- Experimental superiority in redundancy suppression: High
- Model-agnostic and inference-time applicability: High
- Generalizability to real-world prompt injection scenarios: Medium
- Computational efficiency and scalability claims: Medium
- Performance on long-context scenarios: Low

## Next Checks
1. Test RISE against real prompt injection attacks from established benchmarks (e.g., AdvGLUE, RealPoison) to validate practical security benefits
2. Conduct ablation studies varying context window sizes (512, 1024, 2048 tokens) to assess scalability and performance degradation
3. Measure inference-time overhead and memory usage across different model sizes (7B, 70B parameters) to confirm computational efficiency claims