---
ver: rpa2
title: 'InteractComp: Evaluating Search Agents With Ambiguous Queries'
arxiv_id: '2510.24668'
source_url: https://arxiv.org/abs/2510.24668
tags:
- interaction
- search
- agents
- arxiv
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: INTERACTCOMP evaluates search agents on ambiguous queries requiring
  interaction. We design a target-distractor methodology creating questions ambiguous
  without interaction, validated by expert annotators.
---

# InteractComp: Evaluating Search Agents With Ambiguous Queries

## Quick Facts
- **arXiv ID:** 2510.24668
- **Source URL:** https://arxiv.org/abs/2510.24668
- **Reference count:** 40
- **Primary result:** Evaluates search agents on ambiguous queries requiring interaction

## Executive Summary
INTERACTCOMP introduces a novel benchmark for evaluating search agents on ambiguous queries that require interaction for clarification. The methodology creates target-distractor pairs that are ambiguous without user interaction, validated by expert annotators. Across 17 models tested on 210 questions, the best model achieves only 13.73% accuracy versus 71.50% with complete context. Forcing interaction doubles accuracy, exposing latent capability. Longitudinal analysis reveals that interaction abilities stagnated over 15 months while search performance improved seven-fold.

## Method Summary
The INTERACTCOMP benchmark evaluates search agents on ambiguous queries requiring clarification through a target-distractor methodology. Questions are designed to be ambiguous without interaction, creating pairs where agents must recognize the need for clarification. The benchmark tests whether agents can actively clarify user intent rather than making incorrect assumptions. Expert annotators validate the ambiguity and ensure the questions effectively measure interaction capabilities. The evaluation includes both natural interaction patterns and forced interaction scenarios to assess latent capabilities.

## Key Results
- Best model achieves 13.73% accuracy on ambiguous queries versus 71.50% with complete context
- Forcing interaction doubles accuracy, exposing latent capability in search agents
- Longitudinal analysis shows interaction abilities stagnated over 15 months while search performance improved seven-fold

## Why This Works (Mechanism)
The methodology works by creating realistic ambiguous query scenarios that force search agents to recognize uncertainty and seek clarification rather than making assumptions. The target-distractor pairs ensure that correct answers require understanding user intent, which can only be achieved through interaction. This approach exposes the fundamental limitation of current agents: they systematically overconfidently provide incorrect answers rather than acknowledging ambiguity and requesting clarification.

## Foundational Learning
- **Ambiguity recognition**: Agents must identify when queries lack sufficient context for accurate responses
  - Why needed: Without recognizing ambiguity, agents make incorrect assumptions leading to poor results
  - Quick check: Test if agent flags queries requiring clarification

- **Active clarification**: Ability to ask targeted questions to disambiguate user intent
  - Why needed: Passive responses fail to resolve ambiguity effectively
  - Quick check: Measure number of clarifying questions generated

- **Contextual inference**: Understanding relationships between target and distractor elements
  - Why needed: Correct interpretation requires distinguishing between similar but distinct concepts
  - Quick check: Evaluate accuracy on disambiguated queries

## Architecture Onboarding

**Component Map:** Query Processor -> Ambiguity Detector -> Clarification Generator -> Response Synthesizer

**Critical Path:** The most critical sequence is Query Processor → Ambiguity Detector → Clarification Generator, as failure at any point prevents proper interaction.

**Design Tradeoffs:** The benchmark prioritizes realistic ambiguity over artificial complexity, accepting fewer but more representative test cases versus larger but less meaningful datasets.

**Failure Signatures:** Systematic overconfidence manifests as high-confidence incorrect responses without clarification attempts; stagnation appears as flat performance curves across model versions despite overall search improvements.

**First 3 Experiments:** 1) Run baseline models without interaction on ambiguous queries, 2) Enable forced interaction mode and measure accuracy improvement, 3) Compare interaction patterns across different model architectures.

## Open Questions the Paper Calls Out
None

## Limitations
- Focus exclusively on ambiguous queries may not generalize to all search scenarios
- 210-question benchmark may not capture full diversity of real-world ambiguous queries
- Forced interaction methodology may not reflect natural user behavior patterns

## Confidence
- Systematic overconfidence claim: High
- Stagnation in interaction abilities: High
- Seven-fold improvement in search performance: High
- Generalizability across domains: Medium
- Natural interaction patterns: Medium

## Next Checks
1. Test INTERACTCOMP methodology across diverse domains beyond the current benchmark to assess generalizability
2. Conduct user studies comparing forced interaction versus natural clarification patterns in real-world search scenarios
3. Analyze whether the seven-fold improvement in search performance translates to actual user satisfaction and task completion rates