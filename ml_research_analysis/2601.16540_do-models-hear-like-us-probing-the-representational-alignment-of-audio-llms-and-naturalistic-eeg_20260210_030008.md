---
ver: rpa2
title: Do Models Hear Like Us? Probing the Representational Alignment of Audio LLMs
  and Naturalistic EEG
arxiv_id: '2601.16540'
source_url: https://arxiv.org/abs/2601.16540
tags:
- audio
- alignment
- similarity
- spearman
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a systematic comparison of internal representations
  between 12 open-source Audio LLMs and human EEG signals during naturalistic speech
  listening. The authors temporally align layer-wise model states with sentence-level
  EEG segments and quantify representational similarity using eight metrics, including
  Spearman-based RSA and covariance-based measures.
---

# Do Models Hear Like Us? Probing the Representational Alignment of Audio LLMs and Naturalistic EEG

## Quick Facts
- **arXiv ID:** 2601.16540
- **Source URL:** https://arxiv.org/abs/2601.16540
- **Reference count:** 40
- **Primary result:** Strong rank-dependence split between Audio LLMs and human EEG signals during naturalistic speech listening

## Executive Summary
This paper systematically compares internal representations between 12 open-source Audio LLMs and human EEG signals during naturalistic speech listening. The authors temporally align layer-wise model states with sentence-level EEG segments and quantify representational similarity using eight metrics, including Spearman-based RSA and covariance-based measures. Results reveal a strong rank-dependence split: rank-based geometry and dependence-based measures peak at different model depths, and their cross-model rankings are metric-dependent. Time-resolved scalp analyses show strongest alignment in the 250-500 ms window, consistent with N400-related neural dynamics. A prosody-aware tri-modal analysis further uncovers that negative prosody reduces rank-based similarity while increasing covariance-based dependence, indicating that affective modulation reshapes temporal neighborhood structure rather than uniformly scaling coupling.

## Method Summary
The study analyzes EEG recordings from two naturalistic speech datasets (49 subjects, 84 sentences; 19 subjects, 736 sentences) while subjects listen to speech stimuli. EEG signals are sentence-segmented, z-score normalized per electrode, and temporally aligned with Audio LLM token sequences via linear interpolation. Hidden states from all transformer layers are extracted and reduced to 20 principal components. Eight similarity metrics (Pearson/Spearman RSA, Kendall τ, dCor, RV, MI proxy, CKA-L, CKA-RBF) are computed on correlation-distance RDMs. Significance is assessed via 500 time-shuffle permutations. Prosody and affect analysis uses eGeMAPS acoustic features with K-means clustering and valence weighting.

## Key Results
- Rank-dependence split: rank-based geometry and dependence-based measures peak at different model depths
- Strongest alignment in 250-500 ms window, consistent with N400 neural dynamics
- Negative prosody reduces geometric similarity while increasing covariance-based dependence
- Model rankings are strongly metric-dependent across all similarity measures

## Why This Works (Mechanism)

### Mechanism 1: Representational Dissimilarity Matrix (RDM) Alignment
Temporally aligned RDMs capture cross-modal representational geometry between EEG and Audio LLMs. The method resamples EEG to the LLM token grid via linear interpolation, constructs correlation-distance RDMs for each modality, then compares upper-triangular vectorizations using rank-based (Spearman RSA) and dependence-based (dCor, CKA) metrics. This measures whether time-point pairs with similar EEG patterns also have similar LLM hidden states.

### Mechanism 2: Depth-Dependent Layer Trajectories
Different similarity metrics peak at different layers, revealing a dissociation between rank-based geometry and statistical dependence. The 12 Audio LLMs show divergent layer-wise profiles—rank metrics (Spearman RSA, Kendall) often peak early while dependence metrics (dCor, CKA-RBF) frequently peak late, reflecting architectural differences in how speech features propagate through transformer blocks.

### Mechanism 3: Affective Dissociation via Tri-modal Consistency
The Tri-modal Neighborhood Consistency (TNC) criterion jointly constrains acoustic-EEG, EEG-LLM, and acoustic-LLM alignment. Negative prosody sentences show reduced Spearman RSA but elevated dCor/CKA, suggesting affective processing reshapes temporal neighborhood structure rather than uniformly scaling coupling.

## Foundational Learning

- **Representational Similarity Analysis (RSA)**
  - Why needed here: Core methodology for comparing representational geometry across modalities without requiring pointwise correspondence
  - Quick check question: Can you explain why Spearman RSA is more robust than Pearson RSA when comparing RDMs from different modalities?

- **N400 Neural Response Component**
  - Why needed here: The 250-500ms window alignment finding is interpreted relative to this canonical semantic integration marker
  - Quick check question: What cognitive process does the N400 component index, and why would Audio LLM representations align with it?

- **Centered Kernel Alignment (CKA)**
  - Why needed here: One of 8 complementary metrics; captures representation-space similarity via kernel similarity, distinguishing linear from nonlinear alignment
  - Quick check question: How does CKA differ from RSA in what it measures about two representation spaces?

## Architecture Onboarding

- **Component map:** EEG preprocessing (sentence segmentation → z-score → linear interpolation → feature extraction) → Audio LLM feature extraction (waveform → tokens → layer states → PCA) → Similarity computation (8 metrics on RDMs) → Permutation testing (GPU-batched) → Prosody/affect analysis (eGeMAPS → valence proxy → sentence partitioning → TNC)

- **Critical path:** 1. Temporal alignment (resampling EEG to token grid) 2. RDM construction (correlation distance) 3. Metric computation (8 complementary measures) 4. Permutation testing (significance validation)

- **Design tradeoffs:** PCA k=20 reduces computational cost but may discard relevant variance; 500 permutations balance practicality and sensitivity; sentence-level aggregation increases SNR but loses word-level granularity; token-synchronous alignment preserves structure but assumes uniform token duration

- **Failure signatures:** All metrics near zero (likely temporal misalignment); negative RSA only (may indicate sign-flipped features); metric-dependent rankings with no consistent pattern (expected, not failure); TNC near zero while pairwise RSA high (confound-driven inflation)

- **First 3 experiments:** 1. Replicate layer-wise similarity trajectories on a single model and dataset, verifying permutation significance 2. Compare Spearman RSA vs. CKA-RBF trajectories for one model to confirm rank-dependence split 3. Partition sentences by affect groups and compute metric differences to reproduce affective dissociation pattern

## Open Questions the Paper Calls Out
None

## Limitations
- Temporal alignment assumption may not hold across different tokenization schemes
- Affect analysis lacks direct validation of valence proxy against human ratings
- Sentence-level segmentation may mask finer-grained alignment patterns

## Confidence

**High Confidence:**
- Depth-dependent layer trajectories showing metric-dependent peaks
- N400 window alignment (250-500ms) with existing neural literature
- RDM alignment methodology and permutation significance framework

**Medium Confidence:**
- Affective dissociation mechanism (negative prosody effects)
- Tri-modal consistency framework utility
- Rank-dependence split interpretation across 8 metrics

**Low Confidence:**
- Cross-model ranking stability across affect conditions
- Generalizability to other speech corpora or EEG recording setups
- Causal interpretation of alignment patterns (correlation vs. causation)

## Next Checks
1. **Temporal Resolution Validation**: Replicate analysis using word-level EEG segmentation to verify whether sentence-level aggregation obscures or creates alignment patterns, and test sensitivity to alignment window width (±50ms, ±100ms)

2. **Affect Proxy Validation**: Compute correlation between eGeMAPS-derived valence scores and independent human affect ratings for a subset of sentences, and perform ablation studies removing energy/duration correlates from acoustic features

3. **Cross-Modality Ablation**: Systematically remove each of the 8 similarity metrics and recompute rankings to identify which specific measures drive the metric-dependent model rankings, and test whether the rank-dependence split persists with alternative RDM construction methods