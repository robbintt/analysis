---
ver: rpa2
title: 'Make Still Further Progress: Chain of Thoughts for Tabular Data Leaderboard'
arxiv_id: '2505.13421'
source_url: https://arxiv.org/abs/2505.13421
tags:
- pred
- tabular
- label
- data
- neighbors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Chain of Tabular Thoughts (CoT2), a method
  that uses large language models (LLMs) to perform instance-specific ensemble of
  tabular model predictions. The method constructs a context for each test instance
  using its nearest neighbors and external model predictions, then guides the LLM
  through structured reasoning steps to integrate these predictions.
---

# Make Still Further Progress: Chain of Thoughts for Tabular Data Leaderboard

## Quick Facts
- arXiv ID: 2505.13421
- Source URL: https://arxiv.org/abs/2505.13421
- Reference count: 40
- Primary result: Chain of Tabular Thoughts (CoT2) improves classification accuracy on TinyBench2 datasets by using LLMs for instance-specific ensemble of tabular model predictions

## Executive Summary
This paper introduces Chain of Tabular Thoughts (CoT2), a method that leverages large language models (LLMs) to improve tabular data prediction through instance-specific ensemble reasoning. Rather than accessing raw features, CoT2 constructs context for each test instance using nearest neighbors and external model predictions, then guides the LLM through structured reasoning steps to integrate these predictions. The approach achieves state-of-the-art performance on TinyBench2 benchmarks while reducing inference costs by selectively applying LLMs only to hard samples.

The key innovation is bypassing raw feature access entirely and instead providing LLMs with re-weighted neighbor contexts and external model predictions as reasoning material. This enables the LLM to act as a sophisticated aggregator that can reason about prediction disagreements and leverage local label patterns. The method demonstrates significant improvements over standard ensemble techniques while maintaining computational efficiency through selective inference.

## Method Summary
CoT2 operates by first retrieving k nearest neighbors for each test instance using a re-weighted distance metric that emphasizes label similarity. For each test sample, the method constructs a context containing the neighbor labels (re-weighted by distance) and predictions from an ensemble of base models. An LLM then processes this context through a chain-of-thought reasoning pipeline with structured steps: understanding the problem, analyzing neighbor information, examining model predictions, reasoning about discrepancies, and producing a final prediction. The method selectively applies LLM inference only to samples where base model predictions disagree beyond a threshold τ, reducing overall computational cost while focusing reasoning power on challenging instances.

## Key Results
- CoT2 improves classification accuracy on TinyBench2 datasets compared to standard ensemble methods
- Achieves highest average ranking across both classification and regression tasks on TinyBench2
- Outperforms traditional ensemble approaches while reducing inference cost through selective LLM application to hard samples

## Why This Works (Mechanism)
CoT2 works by leveraging LLMs' reasoning capabilities to integrate multiple sources of information without requiring direct feature access. The method provides LLMs with distilled knowledge from nearest neighbors (re-weighted by similarity) and diverse model predictions, creating a rich context for reasoning. The chain-of-thought structure guides systematic analysis of prediction disagreements and local label patterns. By focusing LLM computation only on samples where base models disagree, the method achieves efficiency gains while maintaining accuracy improvements. The approach exploits the LLM's ability to identify and resolve conflicts between different prediction sources through structured reasoning rather than pattern matching on raw features.

## Foundational Learning

### Nearest Neighbor Retrieval with Re-weighted Distance
**Why needed**: To provide LLMs with local label patterns without raw feature access
**Quick check**: Verify that re-weighted distance (Equation 1) properly balances feature similarity with label agreement

### Chain-of-Thought Reasoning Structure
**Why needed**: To guide systematic integration of multiple prediction sources and neighbor contexts
**Quick check**: Confirm that each reasoning step in the prompt template serves a distinct analytical purpose

### Selective LLM Inference Strategy
**Why needed**: To reduce computational cost by applying LLMs only to samples requiring complex reasoning
**Quick check**: Validate that disagreement threshold τ effectively identifies samples benefiting from LLM analysis

### External Model Ensemble Integration
**Why needed**: To provide diverse prediction perspectives for the LLM to reason about
**Quick check**: Ensure base model predictions are properly formatted and weighted in the LLM context

## Architecture Onboarding

**Component Map**: Test instance → Neighbor Retrieval → Context Construction → LLM Chain-of-Thought → Final Prediction

**Critical Path**: The most important sequence is Test instance → Neighbor Retrieval → Context Construction → LLM inference, as this determines the quality of information available for reasoning.

**Design Tradeoffs**: The method trades direct feature access for reasoning-based integration, accepting potential information loss from bypassing raw features in exchange for leveraging LLM reasoning capabilities and maintaining privacy. The selective inference strategy balances accuracy gains against computational cost.

**Failure Signatures**: Performance degradation occurs when: (1) nearest neighbors provide misleading local patterns, (2) external model predictions are systematically biased or correlated, (3) disagreement threshold τ misclassifies easy samples as hard or vice versa, or (4) LLM reasoning fails to properly integrate the provided context.

**3 First Experiments**:
1. Verify neighbor retrieval quality by checking label agreement between retrieved neighbors and test instances across different distance metrics
2. Test LLM performance on context-only prediction (without chain-of-thought) versus full CoT2 pipeline to isolate reasoning contribution
3. Experiment with different disagreement thresholds τ to find optimal balance between accuracy gains and inference cost reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CoT2's performance scale with the number of external models in the ensemble pool, and is there a point of diminishing returns or increased confusion?
- Basis in paper: [inferred] The ablation study (Figure 4) shows improvements from 4 to 8 to 12 models, but does not establish theoretical or empirical bounds on optimal pool size.
- Why unresolved: The paper tests three configurations but does not analyze the trade-off between information richness and LLM reasoning complexity as the model count grows.
- What evidence would resolve it: Systematic experiments varying model pool size from 2 to 50+ models, measuring both accuracy and inference cost, with analysis of LLM attention patterns over the context.

### Open Question 2
- Question: Can CoT2 effectively distinguish between genuinely hard samples versus samples where external models systematically fail due to shared inductive biases?
- Basis in paper: [explicit] The paper defines hard samples via disagreement threshold τ, but acknowledges on page 7: "hard samples not solvable by base ensembles alone may be excluded from LLM inference."
- Why unresolved: The selective strategy assumes disagreement indicates difficulty, but could also indicate correlated model errors that LLMs cannot rectify without access to raw features.
- What evidence would resolve it: Analysis comparing LLM performance on "hard" samples with diverse model disagreement patterns vs. samples with systematic model failures; comparison with oracle hard sample selection.

### Open Question 3
- Question: How robust is CoT2 to the quality and diversity of the nearest neighbor retrieval, particularly for datasets with sparse or adversarial structures?
- Basis in paper: [inferred] The method relies on re-weighted distance for neighbor retrieval (Equation 1), but the ablation only tests distance metrics, not dataset structures where nearest neighbors may be misleading or sparse.
- Why unresolved: Tabular datasets can have complex manifolds where local similarity does not imply label similarity, yet CoT2 depends on neighbor labels as ground truth signals.
- What evidence would resolve it: Experiments on datasets with controlled noise levels, cluster structures, or adversarial examples; ablation varying the number of neighbors k in extreme settings (k=1, k=50).

## Limitations
- Performance gains may reflect LLM's strong baseline prediction abilities rather than the chain-of-thought structure itself
- Method's performance is bounded by quality of nearest neighbor retrieval and external model predictions
- Paper doesn't provide quantitative comparisons of actual computational overhead versus traditional ensemble methods

## Confidence

**High confidence**: The claim that CoT2 improves classification accuracy on TinyBench2 datasets compared to standard ensemble methods. The experimental results are clearly presented and the methodology is reproducible.

**Medium confidence**: The claim that CoT2 achieves the highest average ranking across both classification and regression tasks. While the results support this, the relatively small number of datasets (9 classification, 6 regression) limits generalizability.

**Medium confidence**: The claim that bypassing raw feature access and using LLMs' reasoning abilities drives performance improvements. The reasoning is plausible but the paper doesn't definitively prove this causal mechanism.

## Next Checks

1. Conduct an ablation study isolating the contribution of the chain-of-thought reasoning structure from the LLM's raw prediction capabilities by comparing CoT2 against an LLM that directly predicts without the structured reasoning steps.

2. Test CoT2 on additional tabular datasets beyond TinyBench2 to evaluate generalizability, particularly datasets with different characteristics (high-dimensional features, categorical vs numerical distributions, varying sample sizes).

3. Measure and compare the actual inference time and computational cost of CoT2 versus traditional ensemble methods across different hardware configurations to quantify the claimed efficiency benefits.