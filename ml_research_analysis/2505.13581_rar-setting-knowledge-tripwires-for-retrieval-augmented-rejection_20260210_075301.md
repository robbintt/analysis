---
ver: rpa2
title: 'RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection'
arxiv_id: '2505.13581'
source_url: https://arxiv.org/abs/2505.13581
tags:
- documents
- negative
- rejection
- moderation
- content
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RAR introduces a novel content moderation approach that leverages
  retrieval-augmented generation (RAG) systems by strategically inserting flagged
  "negative documents" into the vector database. When user queries retrieve these
  documents, the system can dynamically reject unsafe requests without model retraining
  or architectural changes.
---

# RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection

## Quick Facts
- arXiv ID: 2505.13581
- Source URL: https://arxiv.org/abs/2505.13581
- Authors: Tommaso Mario Buonocore; Enea Parimbelli
- Reference count: 1
- Primary result: Achieves 88.8% rejection accuracy on harmful queries by strategically inserting "negative documents" into RAG vector databases

## Executive Summary
RAR introduces a novel content moderation approach that leverages retrieval-augmented generation (RAG) systems by strategically inserting flagged "negative documents" into the vector database. When user queries retrieve these documents, the system can dynamically reject unsafe requests without model retraining or architectural changes. The method achieves 88.8% rejection accuracy on the HarmfulQA test set, outperforming built-in LLM guardrails (69.4%) while maintaining flexibility to adapt to emerging threats through real-time document updates. RAR's key advantage lies in its transparency and explainability, as rejections can be traced to specific triggering documents. The approach demonstrates particular effectiveness in domains like education and technology, though it may introduce false positives that can be tuned via threshold optimization.

## Method Summary
RAR repurposes standard RAG retrieval as a moderation layer by inserting "negative documents" - text snippets describing malicious intent with metadata flags - into the vector database. When a user query retrieves these documents with high similarity scores, the system rejects the request based on configurable thresholds (proportion of negatives ≥0.5 or highest-ranked negative at position 1). The approach requires no model retraining and maintains transparency by providing explainable rejections linked to specific triggering documents. Negative documents are generated using an uncensored LLM (Deepseek R1 abliterated) to describe malicious intent across different topics, then embedded alongside legitimate content in the vector database.

## Key Results
- Achieves 88.8% rejection accuracy on HarmfulQA test set versus 69.4% for built-in Claude 3.5 guardrails
- Demonstrates 73.0% true positive rate with only 11.2% false negative rate
- Outperforms standalone LLM guardrails while maintaining explainability through traceable rejections
- Shows particular effectiveness in education and technology domains with lower performance on philosophy/ethics and social sciences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Harmful queries exhibit measurably different retrieval patterns than safe queries when negative documents are present in the index.
- Mechanism: The semantic embedding space captures malicious intent similarity. When a user query shares semantic features with a negative document (e.g., both discuss "creating explosions from household items"), the retriever surfaces it with high similarity scores and prominent ranking positions. This creates a separable distribution between safe and unsafe queries along two dimensions: proportion of retrieved negatives and highest rank position of any negative.
- Core assumption: Malicious intent has detectable semantic signatures that generalize across paraphrasing and minor obfuscation attempts.
- Evidence anchors:
  - [abstract] "By strategically inserting and marking malicious documents into the vector database, the system can identify and reject harmful requests when these documents are retrieved."
  - [section] Figure 2 shows "clear separation between safe and unsafe user queries" on kernel density estimates for both retrieval count and rank metrics.
  - [corpus] Related work on RAG vulnerabilities (Shafran et al.) confirms single blocker documents can systematically trigger retrieval-based refusal behavior—demonstrating the underlying mechanism is observable, though used defensively here.
- Break condition: Novel attack vectors without corresponding negative documents in the index will not trigger retrieval. Coverage is bounded by the negative document library.

### Mechanism 2
- Claim: Multiple threshold configurations allow tunable trade-offs between security strictness and legitimate query throughput.
- Mechanism: RAR supports count-based thresholds (reject if N negatives in top-k), rank-based thresholds (reject if any negative in top-N), and score-based thresholds (reject if mean reciprocal rank exceeds threshold). The paper found optimal separation at 0.5 proportion threshold and rank-1 detection threshold for their dataset. These can be optimized for different risk profiles: maximizing rejection accuracy for high-risk applications versus maximizing true positive rate for permissive settings.
- Core assumption: The retrieval ranking and scoring functions provide calibrated signals that correlate with query harmfulness.
- Evidence anchors:
  - [section] "Based on these results, we set the rejection thresholds for RAR, respectively, to 0.5 for the proportion of retrieved negative documents and 1 for the highest ranked negative document."
  - [section] Figure 3 demonstrates grid-search optimization across three objective functions with distinct threshold optima.
  - [corpus] No direct corpus evidence for threshold tuning methodology; this appears to be paper-specific contribution.
- Break condition: Aggressive thresholds increase false positives (paper reports 26% of safe queries blocked with conservative settings); overly permissive thresholds allow harmful queries through.

### Mechanism 3
- Claim: Concatenating RAR with existing LLM guardrails creates complementary defense layers with improved coverage.
- Mechanism: RAR and LLM-based moderation exhibit different failure modes. RAR catches queries that embed semantic signals matching negative documents but may be subtly worded to evade LLM guardrails. Conversely, LLM guardrails may catch novel attack patterns absent from the RAR index. Sequential application (RAR first, then LLM) achieved highest rejection accuracy (0.908) and lowest false negative rate (0.092) in the evaluation.
- Core assumption: RAR and embedded LLM safety mechanisms make partially independent errors.
- Evidence anchors:
  - [section] Table 2 shows LLM+RAR achieves 0.908 rejection accuracy versus 0.888 (RAR alone) and 0.694 (LLM alone).
  - [section] "RAR catches many unsafe queries that the Claude guardrail misses... Even when users attempt to obfuscate intent, the negative documents still trigger due to shared semantics."
  - [corpus] Class-RAG (Chen et al.) demonstrated RAG-based classification outperforms fine-tuned models on robustness, supporting the premise that retrieval-based signals provide complementary detection.
- Break condition: Both layers must be maintained; RAR requires negative document updates while LLM guardrails require model updates for emerging threats.

## Foundational Learning

- Concept: **Retrieval-Augmented Generation (RAG) Architecture**
  - Why needed here: RAR repurposes standard RAG retrieval as a moderation layer. Understanding the retrieval-generation pipeline, embedding models, and vector databases is essential to grasp where RAR inserts its logic.
  - Quick check question: Can you trace where in a RAG pipeline the retrieved documents are used, and how RAR intercepts this flow before generation?

- Concept: **Embedding Space Semantics and Similarity Search**
  - Why needed here: RAR's effectiveness depends on harmful queries clustering near negative documents in embedding space. Understanding how semantic similarity is computed and what it captures (and misses) is critical.
  - Quick check question: If two queries have cosine similarity 0.85 in embedding space, what does that tell you about their semantic relationship, and what might it miss?

- Concept: **Binary Classification Metrics (TPR, FPR, Precision, Recall, F1)**
  - Why needed here: Evaluating moderation systems requires understanding trade-offs between catching harmful content (rejection accuracy, true positive rate) and avoiding over-blocking (false positives). The paper optimizes for different metrics depending on risk profile.
  - Quick check question: If a moderation system has rejection accuracy 0.90 and true positive rate 0.70, what proportion of safe queries are being incorrectly blocked?

## Architecture Onboarding

- Component map: Vector Database -> Embedding Model -> Retriever -> Rejection Logic Module -> LLM Generator
- Critical path:
  1. Query arrives → embedding computed
  2. Top-k documents retrieved from vector database
  3. Rejection logic examines: Are any negative documents present? Do they meet threshold criteria?
  4. If threshold met → reject with explainable reference to triggering document(s)
  5. If threshold not met → pass query + retrieved context to LLM for generation

- Design tradeoffs:
  - **Conservative vs. permissive thresholds**: Higher security (reject if any negative retrieved) vs. higher throughput (require multiple negatives or high similarity)
  - **Coverage vs. maintenance burden**: More negative documents improve coverage but require curation and may increase false positives
  - **Standalone vs. cascaded deployment**: RAR alone offers simplicity; RAR+LLM guardrails offer better coverage but added latency and complexity
  - **Static vs. dynamic negative document library**: Pre-built libraries vs. real-time generation for emerging threats

- Failure signatures:
  - **High false positive rate**: Legitimate queries triggering negative documents (paper observed 26% with conservative settings) → indicates threshold tuning needed or overly broad negative documents
  - **Novel attack bypass**: Harmful query not triggering any negative document → indicates coverage gap in negative document library
  - **Semantic drift**: Negative documents becoming ineffective as attack language evolves → indicates need for library refresh
  - **Adversarial manipulation**: Attackers identifying and exploiting gaps in negative document coverage → indicates need for adversarial testing

- First 3 experiments:
  1. **Baseline threshold calibration**: Using held-out labeled data (safe/unsafe queries), run grid search over count-based and rank-based thresholds to visualize the precision-recall trade-off surface. Replicate Figure 3 for your domain.
  2. **Coverage gap analysis**: Deploy RAR and log all queries that pass through to the LLM but are subsequently flagged by the LLM's own guardrails. These represent negative document coverage gaps—use them to generate new tripwire documents.
  3. **Ablation on negative document design**: Test three variants: (a) short question-style negatives, (b) narrative description of malicious intent, (c) hybrid. Measure which style produces better separation in retrieval patterns for your query distribution.

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness critically depends on quality and coverage of negative documents, with no exact prompt templates provided for reproducibility
- Performance varies by domain, showing lower accuracy on philosophy/ethics and social sciences topics
- Requires ongoing maintenance and updates to negative document library to address emerging threats and semantic drift
- May introduce significant false positives (26% reported) that require careful threshold tuning

## Confidence

- **High confidence**: The retrieval-based rejection mechanism works as described (supported by clear separation in kernel density estimates and quantitative metrics)
- **Medium confidence**: Threshold optimization methodology and specific values (0.5 proportion, rank-1) are appropriate for the tested dataset
- **Medium confidence**: Claim of complementary error patterns with LLM guardrails (supported by concatenation results but not fully explored)

## Next Checks

1. **Coverage gap validation**: Deploy RAR in a live system and systematically log queries that pass RAR but are caught by downstream LLM guardrails. Use these to quantify actual negative document coverage gaps versus the assumed 100% in evaluation.

2. **Adversarial robustness test**: Conduct red-team exercises specifically attempting to craft queries that evade retrieval-based detection while expressing harmful intent, measuring RAR's resilience to paraphrasing and obfuscation.

3. **Cross-domain transfer study**: Evaluate RAR performance on non-HarmfulQA datasets (e.g., general chat, educational, or enterprise content) to determine if threshold calibration and negative document generation methods transfer effectively.