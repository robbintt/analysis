---
ver: rpa2
title: 'Software Engineering Principles for Fairer Systems: Experiments with GroupCART'
arxiv_id: '2504.12587'
source_url: https://arxiv.org/abs/2504.12587
tags:
- fairness
- software
- groupcart
- data
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GroupCART addresses the problem of algorithmic bias in decision
  tree models by proposing a multi-objective optimization approach that avoids bias
  during model construction. The method optimizes both for decreased entropy in the
  target attribute and increased entropy in protected attributes, using fairness-aware
  decision trees with tunable weights.
---

# Software Engineering Principles for Fairer Systems: Experiments with GroupCART

## Quick Facts
- **arXiv ID**: 2504.12587
- **Source URL**: https://arxiv.org/abs/2504.12587
- **Reference count**: 40
- **Primary result**: GroupCART achieves up to 50% improvement in distance to heaven scores and perfect flip rate scores for individual fairness in decision tree models

## Executive Summary
GroupCART introduces a multi-objective optimization approach to decision tree learning that directly addresses algorithmic bias by optimizing for both predictive performance and fairness. The method modifies the standard CART splitting criterion to maximize protected attribute entropy alongside target attribute information gain, preventing the model from isolating disadvantaged groups. Through ensemble voting across Pareto-optimal configurations, GroupCART achieves superior performance-fairness trade-offs compared to state-of-the-art methods while maintaining individual fairness through scalable ensemble sizes.

## Method Summary
GroupCART trains multiple fairness-aware decision trees (FDTs) with varying weights between information gain on class labels (IGC) and information gain on protected attributes (IGS). The splitting criterion optimizes a weighted sum of decreased entropy in the target attribute and increased entropy in protected attributes. After training N trees (typically N=20), the method applies non-dominated sorting to identify Pareto-optimal models based on accuracy, F1, average odds difference, and disparate impact metrics. Final predictions are generated through majority voting across all Pareto-optimal models, ensuring robust trade-offs between performance and fairness.

## Key Results
- Achieves up to 50% improvement in distance to heaven scores compared to state-of-the-art methods
- Perfect individual fairness (Flip Rate = 0) in most cases through ensemble size scaling
- Successfully handles multiple protected attributes simultaneously while maintaining performance

## Why This Works (Mechanism)

### Mechanism 1: Fairness-Aware Splitting via Dual Entropy Optimization
The method modifies decision tree split criteria to maximize protected attribute entropy, preventing the model from creating pure leaves that correspond to specific demographic groups. By structurally embedding fairness into the inductive bias, the tree is prevented from isolating disadvantaged groups. This assumes that bias manifests as low entropy in protected attributes within decision leaves.

### Mechanism 2: Pareto Frontier Aggregation for Trade-off Stability
Instead of selecting a single "best" configuration, GroupCART aggregates predictions from multiple models on the Pareto frontier using majority voting. This smooths out idiosyncrasies of any single hyperparameter setting and provides more robust trade-offs between fairness and performance. The approach assumes the optimal trade-off is a consensus among diverse, non-dominated perspectives.

### Mechanism 3: Individual Fairness via Ensemble Size Scaling
Increasing ensemble size drives individual unfairness (Flip Rate) to zero by reducing prediction variance. As the ensemble size increases, the model converges to a state where flipping a protected attribute does not flip the prediction. This smoothing effect neutralizes individual-level instability, though convergence depends on computational resources.

## Foundational Learning

- **Entropy and Information Gain**: Decision trees use entropy to select split points; GroupCART alters this logic by adding protected attribute entropy. Quick check: If a split results in a group that is 100% one gender, is the entropy regarding gender high or low?

- **Pareto Frontier (Multi-Objective Optimization)**: The architecture relies on selecting non-dominated models that are better at fairness without ruining performance. Quick check: If Model A has 90% accuracy / 60% fairness and Model B has 80% accuracy / 80% fairness, which one is on the Pareto frontier?

- **Flip Rate (Individual Fairness)**: This metric measures prediction inconsistency when protected attributes are changed, distinct from group metrics like Demographic Parity. Quick check: Does a Flip Rate of 0.1 mean 10% of the population changed predictions when their gender was flipped, or that predictions changed by 10%?

## Architecture Onboarding

- **Component map**: Config Generator -> FDT (Custom Splitting) -> Pareto Filter -> Aggregator
- **Critical path**: The custom splitting function within the FDT. If the implementation of "increased entropy in protected attributes" is incorrect, the tree will prioritize one objective entirely, and the Pareto frontier will collapse.
- **Design tradeoffs**: Larger ensemble size improves individual fairness but increases training time linearly. The choice of metrics (Accuracy, F1, AOD, DI) determines the shape of the Pareto frontier.
- **Failure signatures**: High variance in results indicates N may be too small. A collapsed frontier suggests data lacks signal for trade-offs or IGS weight range is too narrow. Perfect fairness with zero accuracy indicates w for IGC is too low.
- **First 3 experiments**:
  1. Baseline Comparison: Run standard CART vs. GroupCART on Adult dataset to visualize Pareto frontier points
  2. Hyperparameter Sensitivity: Vary ensemble size (5, 10, 20) and plot resulting Flip Rate to verify convergence claim
  3. Metric Correlation: Test if optimizing for Disparate Impact also improves Average Odds Difference

## Open Questions the Paper Calls Out

1. **Non-tree adaptation**: Can GroupCART be effectively adapted for non-tree-based classification algorithms? The method relies on information gain on protected attributes, native to decision trees.

2. **Multi-class extension**: Does GroupCART maintain effectiveness in multi-class classification or regression tasks? The specific fairness metrics and splitting criteria are designed for binary outcomes.

3. **Metric selection sensitivity**: Would alternative combinations of objective metrics yield superior performance-fairness trade-offs? The choice of four specific metrics was based on preliminary experiments.

## Limitations

- Assumes increased entropy in protected attributes is universally beneficial, which may fail when target and protected attributes are highly correlated due to historical bias
- Implementation details of the fairness-aware splitting function are not fully specified, creating reproducibility challenges
- The claim that ensemble size guarantees perfect individual fairness may not generalize beyond tested cases

## Confidence

- **High confidence**: Multi-objective optimization framework and Pareto frontier aggregation methodology
- **Medium confidence**: Experimental results showing improved distance to heaven scores and individual fairness metrics
- **Low confidence**: Claim that increasing ensemble size guarantees convergence to perfect individual fairness across all datasets

## Next Checks

1. **Implementation Verification**: Implement the FDT splitting criterion with normalized IGC and IGS weights, then verify that the tree actually increases protected attribute entropy during training by examining leaf node distributions.

2. **Hyperparameter Sensitivity Analysis**: Systematically vary ensemble size (N=5, 10, 20, 40) and document the convergence behavior of Flip Rate to verify the claimed relationship between ensemble size and individual fairness.

3. **Robustness to Correlation**: Create synthetic datasets with varying degrees of correlation between target and protected attributes (0%, 50%, 80%, 95%) and evaluate whether GroupCART maintains performance without completely collapsing when strong correlations exist.