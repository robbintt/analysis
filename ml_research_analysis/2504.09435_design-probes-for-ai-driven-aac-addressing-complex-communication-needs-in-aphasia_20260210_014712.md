---
ver: rpa2
title: 'Design Probes for AI-Driven AAC: Addressing Complex Communication Needs in
  Aphasia'
arxiv_id: '2504.09435'
source_url: https://arxiv.org/abs/2504.09435
tags:
- system
- pwas
- design
- communication
- aphasia
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored how AI can support individuals with aphasia
  in communication through a two-phase research through design approach. The researchers
  developed four AI-enhanced AAC prototypes addressing real-time communication and
  future conversation preparation needs, then evaluated them with 11 participants.
---

# Design Probes for AI-Driven AAC: Addressing Complex Communication Needs in Aphasia

## Quick Facts
- **arXiv ID**: 2504.09435
- **Source URL**: https://arxiv.org/abs/2504.09435
- **Reference count**: 40
- **Primary result**: AI-enhanced AAC prototypes with visual verification, keyword-to-sentence generation, and multimodal feedback improved communication for people with aphasia, though challenges remain with timing, intent alignment, and varying effectiveness across severity levels.

## Executive Summary
This research explored AI-driven augmentative and alternative communication (AAC) solutions for individuals with aphasia through a two-phase design research approach. The study developed four AI-enhanced prototypes addressing real-time communication needs and future conversation preparation, then evaluated them with 11 participants. Key innovations included visual verification of AI outputs, sentence generation from keywords, error correction capabilities, and multimodal feedback systems. The research revealed that while AI significantly enhanced communication capabilities, challenges persisted with timing in group conversations, alignment between AI outputs and user intent, and varying effectiveness based on aphasia severity levels.

## Method Summary
The study employed a research through design methodology spanning two phases. Phase 1 involved user interviews with 12 participants to identify communication challenges and preferences, followed by the design and development of four AI-enhanced AAC prototypes. Phase 2 conducted user evaluations with 11 participants, using a within-subject study design where each participant tested all four prototypes in simulated scenarios. Data collection included task completion metrics, questionnaire responses, and qualitative feedback through think-aloud protocols and post-study interviews.

## Key Results
- Visual verification features and sentence generation from keywords were particularly beneficial for reducing misunderstandings and validating expressions
- Participants valued multiple sentence options for autonomy and multimodal feedback for clarity in communication
- Challenges included timing issues in group conversations, misalignment between AI outputs and user intent, and varying effectiveness based on aphasia severity

## Why This Works (Mechanism)
The effectiveness stems from addressing the core communication barriers faced by people with aphasia through AI augmentation. Visual verification reduces cognitive load by providing immediate feedback on AI outputs, while keyword-to-sentence generation bypasses word-finding difficulties. Multimodal feedback (visual and auditory) accommodates different sensory processing capabilities common in aphasia. The system's ability to provide multiple sentence options supports the autonomy needs of users who struggle with limited expression options in traditional AAC systems.

## Foundational Learning
- **Aphasia heterogeneity**: Different types and severities of aphasia require flexible solutions - critical because one-size-fits-all approaches fail; quick check: map symptom profiles to feature effectiveness
- **Visual processing advantages**: Many aphasia patients retain visual processing capabilities - needed for verification features; quick check: test visual vs. text-only feedback
- **Cognitive load management**: Reduced mental effort through AI assistance is crucial - necessary because traditional AAC requires high cognitive effort; quick check: measure task completion time and errors
- **Autonomy preservation**: Multiple options prevent learned helplessness - essential for long-term engagement; quick check: track user choice patterns over time
- **Real-time constraints**: Communication timing affects social participation - important for natural conversation flow; quick check: measure latency impact on conversation success
- **Intent alignment**: AI must accurately interpret user intent - fundamental for communication accuracy; quick check: compare intended vs. generated messages

## Architecture Onboarding
**Component Map**: User Input -> NLP Engine -> AI Output Generator -> Verification Module -> Display Interface -> Feedback Loop
**Critical Path**: User keyword/phrase input → NLP processing → Sentence generation → Visual verification → User selection → Communication output
**Design Tradeoffs**: Accuracy vs. speed (more processing time improves output quality but slows conversation), complexity vs. usability (richer features may overwhelm users), personalization vs. generalization (customized systems work better but are harder to scale)
**Failure Signatures**: Timing delays causing conversation breakdown, AI misinterpretation leading to incorrect expressions, visual verification mismatches causing confusion, system crashes during critical moments
**First Experiments**: 1) Compare keyword-to-sentence accuracy across different aphasia severity levels, 2) Measure communication success rates with vs. without visual verification, 3) Test multimodal feedback effectiveness across different sensory processing capabilities

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions for future research.

## Limitations
- Small sample size (11 participants) limits generalizability across the broader aphasia population
- Simulated scenarios may not capture the full complexity of real-world communication contexts
- Limited evaluation period prevents assessment of long-term user adaptation and system effectiveness

## Confidence
- **Sample size adequacy**: Medium - small participant group restricts generalizability
- **Methodological rigor**: Medium - well-designed study but constrained by simulation approach
- **Real-world applicability**: Medium - findings need validation in natural communication settings
- **Technical validation**: Medium - AI performance needs broader testing across diverse scenarios

## Next Checks
1. Conduct longitudinal field studies with larger, more diverse participant groups to assess real-world effectiveness and long-term adaptation
2. Implement A/B testing of different AI algorithms and output formats to quantify the impact of design choices on communication success rates
3. Develop standardized metrics for evaluating AI-AAC system performance across different aphasia severities and communication contexts