---
ver: rpa2
title: 'VERBA: Verbalizing Model Differences Using Large Language Models'
arxiv_id: '2507.02241'
source_url: https://arxiv.org/abs/2507.02241
tags:
- dataset
- accmismatch
- accmatch
- differences
- level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VERBA, a framework that leverages large language
  models to generate natural-language descriptions of differences between machine
  learning models. VERBA addresses the challenge of navigating and selecting among
  a proliferation of models with similar performance but different behaviors.
---

# VERBA: Verbalizing Model Differences Using Large Language Models

## Quick Facts
- arXiv ID: 2507.02241
- Source URL: https://arxiv.org/abs/2507.02241
- Reference count: 25
- Primary result: LLM-based framework verbalizes differences between ML models with up to 80% accuracy

## Executive Summary
VERBA introduces a framework that uses large language models to generate natural-language descriptions of differences between machine learning models. As model proliferation makes it challenging to navigate and select among models with similar performance but different behaviors, VERBA addresses this by sampling input-output pairs from two models, serializing them, and using an LLM to verbalize the differences. The framework is evaluated on logistic regression, decision trees, and multilayer perceptrons, showing effective verbalization of differences with up to 80% accuracy for model pairs with up to 5% performance difference but 20-25% behavioral differences. Including structural information about models improves accuracy to 90%.

## Method Summary
VERBA operates by sampling input-output pairs from two models, serializing these pairs along with model structure information, and passing them to an LLM to generate verbal descriptions of differences. The framework is evaluated using an LLM-based evaluation protocol across three model types: logistic regression, decision trees, and multilayer perceptrons. The approach focuses on pairwise comparisons and leverages the LLM's natural language capabilities to transform technical model behavior differences into human-readable descriptions. Performance is measured by comparing generated verbalizations against ground truth descriptions of model differences.

## Key Results
- VERBA achieves up to 80% accuracy in verbalizing model differences for pairs with up to 5% performance difference but 20-25% behavioral differences
- Accuracy improves to 90% when structural information about models is included in the verbalization process
- Framework demonstrates effectiveness across logistic regression, decision trees, and multilayer perceptrons

## Why This Works (Mechanism)
VERBA leverages LLMs' natural language understanding and generation capabilities to bridge the gap between technical model behavior and human-interpretable descriptions. By providing serialized input-output pairs and model structure information to the LLM, VERBA taps into the LLM's pattern recognition and language synthesis abilities to identify and articulate differences that might not be apparent through traditional metrics alone.

## Foundational Learning

**LLM-based model comparison** - Using LLMs to analyze and describe model behavior differences
Why needed: Traditional metrics often fail to capture nuanced behavioral differences between models
Quick check: Can the LLM accurately identify differences in model predictions on specific inputs?

**Pairwise model analysis** - Focusing on comparing two models at a time rather than evaluating models in isolation
Why needed: Direct comparison highlights relative strengths and weaknesses more effectively
Quick check: Does the framework maintain accuracy when scaling to multiple pairwise comparisons?

**Serialization of model behavior** - Converting model inputs, outputs, and structure into a format LLMs can process
Why needed: LLMs require structured text input to generate meaningful analysis
Quick check: Is the serialization format comprehensive enough to capture all relevant behavioral differences?

## Architecture Onboarding

Component map: Data sampling -> Model serialization -> LLM prompt generation -> LLM processing -> Verbalization output

Critical path: The most critical path is from data sampling through LLM processing to verbalization output, as any failure in serialization or prompt engineering directly impacts the quality of verbalizations.

Design tradeoffs: The framework trades computational efficiency for interpretability - pairwise comparisons provide detailed insights but don't scale well to large model collections. Including structural information improves accuracy but increases complexity and may not always be available.

Failure signatures: Poor verbalizations occur when input-output pairs don't capture representative differences, when serialization misses key behavioral aspects, or when LLM prompts are inadequately engineered.

First experiments: 1) Test verbalization accuracy on synthetic data with known differences, 2) Compare results with and without structural information, 3) Evaluate performance across different model complexity levels.

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Evaluation primarily uses controlled synthetic data rather than real-world datasets
- Pairwise comparison approach may not scale efficiently for large model collections
- Quality heavily depends on LLM choice and prompt engineering quality

## Confidence
High: Framework effectiveness for controlled experiments with simple models and binary comparisons
Medium: Generalizability to complex architectures and real-world practical utility

## Next Checks
1. Evaluate VERBA on real-world datasets and more complex model architectures (e.g., transformers, ensemble methods) to assess practical applicability.
2. Test the scalability and computational efficiency of pairwise comparisons when applied to model collections of 10+ models, and explore alternative comparison strategies.
3. Conduct user studies with domain experts to validate the interpretability and usefulness of VERBA's verbalizations in actual model selection and debugging tasks.