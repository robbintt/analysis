---
ver: rpa2
title: Increasing LLM response trustworthiness using voting ensembles
arxiv_id: '2510.04048'
source_url: https://arxiv.org/abs/2510.04048
tags:
- arxiv
- voting
- ensemble
- accuracy
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper introduces a theoretical framework for understanding\
  \ LLM question-answering reliability through the lens of ensemble voting. It characterizes\
  \ question difficulty using two parameters\u2014deceptiveness (\u03B4) and bewilderment\
  \ (\u03B7)\u2014and shows that restrictive voting ensembles can dramatically increase\
  \ trustworthiness by abstaining from answering when consensus is not reached."
---

# Increasing LLM response trustworthiness using voting ensembles

## Quick Facts
- arXiv ID: 2510.04048
- Source URL: https://arxiv.org/abs/2510.04048
- Authors: Aparna Nair-Kanneganti; Trevor J. Chan; Shir Goldfinger; Emily Mackay; Brian Anthony; Alison Pouch
- Reference count: 40
- One-line primary result: Restrictive voting ensembles can increase LLM response trustworthiness from ~70% to over 90% by abstaining when consensus is insufficient, while maintaining accuracy and only modestly reducing yield.

## Executive Summary
This paper introduces a theoretical framework for understanding LLM question-answering reliability through ensemble voting. It characterizes question difficulty using deceptiveness (δ) and bewilderment (η) parameters, showing that restrictive voting ensembles can dramatically increase trustworthiness by abstaining from answering when consensus is not reached. Experimental results on arithmetic and clinical-note domains demonstrate that highly restrictive voting thresholds can achieve over 90% trust while maintaining accuracy and only modestly reducing yield. The method is particularly valuable in high-stakes applications like healthcare where certainty is critical and not every question needs to be automatically answered.

## Method Summary
The method involves querying n independent LLM instances per question, then returning a consensus answer if any response receives at least k votes; otherwise returning "no consensus." The approach varies k/n ratios to trade off trust versus yield. For arithmetic problems, 500 multiplication and order-of-operations questions were evaluated using Llama3-70B with n=50 samples per question. Clinical experiments extracted LVEF and mitral valve severity from 500 perioperative echocardiogram reports using Llama3-8B with temperature=1.0. Accuracy (P(C)), trust (P(C|consensus)), and yield (P(consensus)) were measured across different threshold values.

## Key Results
- Restrictive voting thresholds (k/n close to 1) can increase trust from ~70% to over 90% while maintaining accuracy
- Maximum achievable accuracy for large ensembles depends solely on question deceptiveness (δ), not ensemble size
- Clinical extraction showed trust gains from 0.85→0.94 (mitral stenosis) and 0.70→0.93 (mitral regurgitation) with restrictive thresholds
- The method maintains accuracy while modestly reducing yield, enabling application-specific calibration

## Why This Works (Mechanism)

### Mechanism 1: Threshold-Based Consensus Filtering
Restrictive voting thresholds improve trustworthiness by selectively abstaining when agent agreement is insufficient. When k/n approaches 1, the ensemble only outputs answers when strong agreement exists. Questions that deceive or bewilder agents produce diverse responses that fail to reach threshold, yielding "no consensus" rather than incorrect answers. Trust increases because the NC state absorbs ambiguous cases. This works when correct answers cluster more consistently than incorrect answers for questions where δ < 0.5.

### Mechanism 2: Deceptiveness-Bounded Accuracy Ceiling
Maximum achievable accuracy for large ensembles depends solely on question deceptiveness (δ), not ensemble size. As n → ∞, the multinomial response distribution concentrates at its expected value. If P(C) > P(I) (i.e., δ < 0.5), the correct answer eventually dominates; if δ > 0.5, the specious answer dominates. Bewilderment (η) affects convergence rate but not the limit. This assumes agent responses are independent and identically distributed.

### Mechanism 3: Trust-Yield Tradeoff via Abstention
Restrictive voting exchanges yield (response coverage) for trust (conditional accuracy), enabling application-specific calibration. Increasing k reduces both P(C) and P(I), but reduces P(I) proportionally more when the correct answer has a natural advantage. Trust = P(C)/(P(C)+P(I)) rises; yield = P(C)+P(I) falls modestly for favorable question distributions. This works when partial coverage with high certainty is acceptable, such as in triage or data annotation.

## Foundational Learning

- Concept: Multinomial distribution over response categories
  - Why needed here: Agent responses are modeled as draws from a multinomial with three categories (correct C, dominant incorrect I, other incorrect R), enabling closed-form probability calculations for ensemble outcomes.
  - Quick check question: For n=10 agents with δ=0.3 and η=0.2, what are the expected counts for C, I, and R?

- Concept: Consensus vs. plurality voting
  - Why needed here: The paper distinguishes permissive (k=1, plurality/first-past-the-post) from restrictive (k→n, consensus) voting, which have fundamentally different accuracy/yield/trust properties.
  - Quick check question: In a 5-agent ensemble with a 3–2 vote split, what happens under k=3 vs. k=5?

- Concept: Conditional probability (trust vs. raw accuracy)
  - Why needed here: Trust is P(C|¬NC)—accuracy conditional on reaching consensus—distinct from raw accuracy P(C). This conditional framing is central to the method's value in high-stakes settings.
  - Quick check question: If P(C)=0.6 and P(NC)=0.3, what is trust T?

## Architecture Onboarding

- Component map: Query dispatcher -> Response collector -> Vote counter -> Threshold comparator -> Consensus resolver
- Critical path: Parallel inference (n× compute of single query) -> Aggregation and counting O(unique responses) -> Threshold comparison -> Optional tie-breaking (additional queries or random selection)
- Design tradeoffs: Higher k/n → higher trust, lower yield, same or lower accuracy; Larger n → better convergence, higher latency and cost; Temperature: higher T increases η (diversity) but not δ; Tie-breaking: abstain vs. additional agents vs. random choice
- Failure signatures: δ > 0.5: ensemble confidently converges on wrong answer; Very high k/n with small n: NC rate >50%; Non-independent agents: theoretical guarantees degrade; Open-ended questions: framework assumes discrete response sets
- First 3 experiments: 1) Baseline calibration on arithmetic: n=50, sweep k=1..n; plot accuracy/trust/yield; verify theoretical curves against empirical δ, η estimates; 2) Domain transfer to clinical extraction: fix k/n, measure whether trust-yield tradeoff transfers; estimate per-domain δ, η; 3) Temperature sensitivity: fix k/n, vary T∈[0.6,1.2]; measure yield changes and δ/η stability

## Open Questions the Paper Calls Out

### Open Question 1
What is the optimal temperature setting for voting ensembles to maximize trust? The paper notes in Appendix D that it is not clear what temperature is optimal, or how sensitive these approaches are to temperature, despite noting that temperature modulates bewilderment (η).

### Open Question 2
Can voting thresholds be dynamically adjusted based on real-time estimates of question difficulty? The framework mentions that estimating δ and η can help optimize competing demands, but experiments used fixed thresholds without validating whether difficulty can be predicted a priori.

### Open Question 3
How does agent heterogeneity impact the theoretical bounds of ensemble accuracy and trust? The framework defines ensembles as homogeneous collections of independent agents, but real-world applications might mix models, violating the assumption that all agents share the same δ and η.

## Limitations

- Theoretical framework assumes response independence and sufficient ensemble size for asymptotic convergence, which may not hold for correlated LLM outputs
- Clinical experiments lack explicit specification of ensemble size and prompt formatting, making faithful reproduction challenging
- Performance on questions with δ > 0.5 is untested, representing a potential failure mode for high-stakes applications

## Confidence

- **High confidence**: The mechanism of trust-yield tradeoff via abstention is well-supported by empirical results across both arithmetic and clinical domains
- **Medium confidence**: The deceptiveness-bounded accuracy ceiling claim relies on asymptotic theory that may not hold for practical ensemble sizes or correlated responses
- **Low confidence**: The framework's performance on questions with δ > 0.5 is untested, representing a potential failure mode for high-stakes applications

## Next Checks

1. **Independence validation**: Generate correlation matrices of LLM responses across different seeds/temperatures for both arithmetic and clinical tasks. Quantify the degree of response independence and test whether ensemble performance degrades with correlated outputs.

2. **Parameter estimation validation**: For a subset of questions, manually classify response categories to estimate true δ and η values. Compare these ground-truth parameters against estimates derived from ensemble voting outcomes to validate the theoretical framework.

3. **Failure mode analysis**: Systematically construct arithmetic questions with known δ > 0.5 (e.g., problems where a common misconception leads to a dominant incorrect answer). Measure whether restrictive voting amplifies rather than filters errors, as the theory predicts.