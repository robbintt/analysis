---
ver: rpa2
title: Bi-directional Recurrence Improves Transformer in Partially Observable Markov
  Decision Processes
arxiv_id: '2505.11153'
source_url: https://arxiv.org/abs/2505.11153
tags:
- learning
- reinforcement
- memory
- environments
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel bi-recurrent model architecture for
  reinforcement learning in partially observable environments, replacing multiple
  feed-forward layers with a single bi-directional GRU layer. Experiments on 23 POMDP
  environments show that the proposed DBGFQN model outperforms existing transformer-based,
  attention-based, and recurrence-based methods by margins ranging from 87.39% to
  482.04% on average, while reducing overall parameter count by 25%.
---

# Bi-directional Recurrence Improves Transformer in Partially Observable Markov Decision Processes

## Quick Facts
- arXiv ID: 2505.11153
- Source URL: https://arxiv.org/abs/2505.11153
- Reference count: 40
- Replaces multiple feed-forward layers with a single bi-directional GRU layer, reducing parameters by 25% while improving performance across 23 POMDP environments.

## Executive Summary
This paper introduces DBGFQN, a novel bi-recurrent transformer architecture for reinforcement learning in partially observable environments. The key innovation replaces standard feed-forward expansion layers with a single bi-directional GRU layer, achieving both parameter efficiency and improved performance. The model outperforms existing transformer-based, attention-based, and recurrence-based methods across 23 POMDP environments by margins ranging from 87.39% to 482.04% on average, while using 25% fewer parameters. The bidirectional GRU improves the model's ability to handle partial observability and increases sample efficiency.

## Method Summary
The DBGFQN architecture processes observation sequences through learned positional encoding and multi-head self-attention, followed by a single bi-directional GRU layer that replaces the standard feed-forward network. The model uses 2 encoder layers, 8 attention heads, context length K=50, and embedding dimension D=128 (64 for some environments). Training follows DQN-style online reinforcement learning with a replay buffer of 500,000 transitions, batch size 32, learning rate 0.0003, and 2 million simulation timesteps. The architecture achieves parameter reduction by eliminating the 4x feed-forward expansion ratio typical in transformers.

## Key Results
- Outperforms DTQN, DRQN, and DGFQN baselines by 87.39% to 482.04% average improvement across 23 POMDP environments
- Reduces parameter count by 25% compared to standard transformer architectures
- Demonstrates highest performance gains in environments with strong conditional dependencies or dense structural patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bi-directional recurrence captures temporal dependencies more effectively than feed-forward layers in structured POMDPs.
- Mechanism: The BiGRU layer processes observation sequences in both forward and backward directions, integrating context from past and future timesteps within the context window.
- Core assumption: The environment contains conditional dependencies where future observations help disambiguate past states.
- Evidence anchors:
  - [abstract] "replaces the multiple feed forward layers with a single layer of bi-directional recurrence unit to better capture and utilize sequential dependencies and contextual information"
  - [section 5.2] "The most significant difference in performance is observed in the Gridverse Memory Four Rooms 7x7 environment, where bi-directional recurrence clearly outperforms, while uni-directional recurrence performs worse than the vanilla DTQN"
  - [corpus] Weak direct support; neighbor papers address POMDP inference but not bidirectional recurrence specifically.
- Break condition: In environments where observations are temporally independent or where future observations provide no disambiguating signal for past states, bidirectional processing may add computational overhead without performance gains.

### Mechanism 2
- Claim: Replacing feed-forward expansion with a single recurrent layer reduces parameter count while maintaining or improving performance.
- Mechanism: Standard transformers use feed-forward networks with 4x expansion ratios (input dimension to hidden dimension), which increases parameter count substantially.
- Core assumption: The representational bottleneck in POMDPs is temporal integration rather than per-timestep feature transformation.
- Evidence anchors:
  - [abstract] "reduces overall parameter count by 25%"
  - [section 5.1] "no strong correlation between the feed-forward expansion size and the performance across the multiple environments"
  - [corpus] No direct corroboration found; parameter efficiency claims are paper-specific.
- Break condition: Environments requiring complex per-timestep feature transformations (e.g., high-dimensional visual inputs with intricate spatial patterns) may still benefit from larger feed-forward capacity.

### Mechanism 3
- Claim: Dense structural patterns and conditional dependencies in environments favor recurrent architectures over pure attention-based approaches.
- Mechanism: Environments with room structures, sequential key-door mechanics, or multi-step memory requirements create strong temporal correlations.
- Core assumption: Environment structure can be characterized by the density of conditional dependencies between temporally separated observations.
- Evidence anchors:
  - [section 5.3] "Recurrent architectures are favored in environments with strong conditional dependencies or dense structure"
  - [section 5.4] "artificially introducing such challenges led to improved performance" when structure was "hallucinated" into empty grids
  - [corpus] No external validation of environment classification scheme.
- Break condition: Environments with sparse dependencies or primarily local observation relevance may not exhibit this advantage, and performance gains diminish where memory requirements are minimal.

## Foundational Learning

- Concept: **Partially Observable Markov Decision Processes (POMDPs)**
  - Why needed here: The entire architecture is designed to handle scenarios where agents cannot observe the full environment state, requiring memory mechanisms to infer hidden state from observation history.
  - Quick check question: Can you explain why standard DQN fails when the agent only sees a 2×3 grid in a larger maze?

- Concept: **Gated Recurrent Units (GRUs) and Bi-directional Processing**
  - Why needed here: The core architectural innovation replaces feed-forward layers with BiGRU; understanding gate mechanisms (reset and update gates) is essential for debugging gradient flow and sequence modeling behavior.
  - Quick check question: How does a bi-directional GRU differ from stacking two uni-directional GRUs, and what information does the backward pass provide that forward-only processing cannot?

- Concept: **Q-Learning and Temporal Difference Updates**
  - Why needed here: The model outputs Q-values and is trained using Bellman error; understanding value function approximation is necessary to interpret training dynamics and loss behavior.
  - Quick check question: What does the Bellman error measure, and why might it be unstable in partially observable settings?

## Architecture Onboarding

- Component map: Observation sequence → Embedding + Positional Encoding → Multi-Head Self-Attention → Add & Norm → BiGRU → Add & Norm → Linear decoder → Q-values

- Critical path:
  1. Observation embedding must correctly project environment observations to dimension D (64 or 128)
  2. Positional encoding provides sequence order; learned encodings used (not sinusoidal)
  3. Self-attention computes dependencies across context length K=50
  4. BiGRU processes attention output bidirectionally with hidden dimension H=32 or 64
  5. Q-value prediction uses final linear layer; action selected greedily during evaluation

- Design tradeoffs:
  - Parameter efficiency vs. computational overhead: BiGRU adds sequential processing cost during training despite fewer parameters
  - Context length K=50: Longer contexts capture more history but increase memory and computation
  - Bi-directional vs. uni-directional: Bidirectional requires full sequence before prediction, unsuitable for true online streaming without modifications

- Failure signatures:
  - Performance degradation on simple environments: Indicates over-parameterization or unnecessary recurrence complexity
  - Training instability with long sequences: May require gradient clipping or truncated backpropagation
  - No improvement over DTQN baseline: Check if environment actually has conditional dependencies; some POMDPs may not benefit from bidirectional processing

- First 3 experiments:
  1. Replicate DTQN vs. DBGFQN comparison on a single Gridverse Memory environment (e.g., 7x7) to validate implementation; expect DBGFQN to show higher success rate.
  2. Ablate bidirectionality: Compare DBGFQN (bi-directional) vs. DGFQN (uni-directional) on Gridverse Memory Four Rooms; paper shows largest gap here.
  3. Test on a memory-light environment (e.g., simple Hallway) to identify where recurrence adds minimal benefit, establishing performance bounds.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a formal taxonomy or classification scheme be developed for POMDP environments that predicts which architectural approach (transformer, recurrence, or hybrid) will be most effective?
- Basis in paper: [explicit] The authors state: "This distinction suggests a potential for further classification of POMDPs based on the effectiveness of different modeling approaches" and mention "the existence of further distinct classes of POMDP environments, where different architectural choices may lead to varying degrees of success."
- Why unresolved: The current analysis identifies "dense structural patterns" and "strong conditional dependencies" as properties favoring bi-directional recurrence, but this remains an empirical observation without a formal characterization framework.
- What evidence would resolve it: A systematic study across a broader range of POMDPs with formal metrics for structural density and conditional dependency strength, correlated with architectural performance.

### Open Question 2
- Question: Do the performance gains of DBGFQN generalize to continuous control tasks and real-world robotic applications beyond grid-based environments?
- Basis in paper: [explicit] The limitations section states: "the environments tested are primarily grid-based and may not fully capture the complexity of real-world continuous control tasks."
- Why unresolved: All 23 tested environments are discrete grid-worlds or similar structured domains; no continuous control benchmarks (e.g., MuJoCo, robotics simulations) were evaluated.
- What evidence would resolve it: Experiments on continuous POMDP benchmarks such as partially observable robotic manipulation or locomotion tasks, comparing DBGFQN against existing baselines.

### Open Question 3
- Question: Can the computational overhead of bi-directional recurrence be mitigated for very long action-observation histories without sacrificing performance?
- Basis in paper: [explicit] The limitations section notes: "the introduction of bidirectional recurrence adds computational overhead during training, particularly for long sequences."
- Why unresolved: The paper does not explore efficient variants (e.g., truncated bi-directional processing, hierarchical recurrence, or state-space alternatives) that could reduce this overhead.
- What evidence would resolve it: Ablation studies on sequence length scaling and comparison with efficient sequence models (e.g., S4, S5, linear attention) in the same architectural role.

## Limitations
- All tested environments are discrete grid-based domains; generalization to continuous control tasks remains unproven
- Bidirectional recurrence adds computational overhead during training, particularly for long sequences
- The proposed environment classification based on structural density lacks formal definition and external validation

## Confidence

- **High confidence**: The claim that DBGFQN reduces parameter count by 25% relative to DTQN, and the basic observation that performance varies across environments with different structural properties.
- **Medium confidence**: The claim that bidirectional recurrence specifically enables better handling of partial observability, as the ablation study does not isolate bidirectionality as the sole contributing factor.
- **Low confidence**: The proposed environment classification scheme (based on conditional dependency density) lacks external validation and may not generalize beyond the tested environments.

## Next Checks

1. Run a direct ablation comparing BiGRU (bidirectional) vs. UniGRU (unidirectional) with matched parameter budgets on Gridverse Memory Four Rooms to isolate the effect of bidirectionality.
2. Implement and test the architecture on a true streaming RL environment (e.g., partially observable control tasks) to verify online feasibility of bidirectional recurrence.
3. Apply the proposed environment classification scheme to a held-out set of POMDPs not used in the original experiments to test whether recurrence-based approaches consistently outperform attention-based ones in environments predicted to have strong conditional dependencies.