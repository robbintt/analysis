---
ver: rpa2
title: Catoni Contextual Bandits are Robust to Heavy-tailed Rewards
arxiv_id: '2502.02486'
source_url: https://arxiv.org/abs/2502.02486
tags:
- bound
- variance
- where
- lemma
- catoni
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper develops a robust contextual bandit algorithm using
  Catoni's estimator to handle heavy-tailed rewards with general function approximation.
  The key insight is that by applying the Catoni estimator to estimate excess loss,
  the algorithm can achieve regret bounds that depend polynomially on cumulative reward
  variance while only scaling logarithmically with reward range R.
---

# Catoni Contextual Bandits are Robust to Heavy-tailed Rewards

## Quick Facts
- arXiv ID: 2502.02486
- Source URL: https://arxiv.org/abs/2502.02486
- Authors: Chenlu Ye; Yujia Jin; Alekh Agarwal; Tong Zhang
- Reference count: 40
- One-line primary result: Catoni-based robust estimators enable variance-dependent regret bounds in contextual bandits with heavy-tailed rewards

## Executive Summary
This paper addresses contextual bandits with heavy-tailed rewards where the reward range R can be much larger than the variance σ². The key insight is that by applying Catoni's robust estimator to the excess loss (difference in predictive performance between functions) rather than just the rewards, the algorithm can achieve regret bounds that depend polynomially on cumulative variance while only scaling logarithmically with reward range. The authors develop two algorithms: Catoni-OFUL for known variance achieving regret scaling as √(∑σ²t), and VACB for unknown variance using a peeling approach with aggregate variance estimation.

## Method Summary
The paper proposes two algorithms for contextual bandits with heavy-tailed rewards. Catoni-OFUL (Algorithm 1) uses a known variance σt at each round, applying Catoni's robust estimator Ψ to construct confidence sets for the function class F. The algorithm solves a min-max optimization problem where the excess loss includes a noise-dependent term weighted by inverse variance. VACB (Algorithm 2) handles the unknown variance case through a peeling strategy with L levels, using Catoni's estimator to compute an aggregate variance proxy ˆVar_t^l for each layer. Both algorithms achieve variance-dependent regret bounds rather than scaling with the worst-case reward range.

## Key Results
- Catoni-OFUL achieves regret ˜O(√(∑σ²t · dim₁(T) · log N(F, ν)) for known variance case
- VACB achieves regret ˜O(√(∑σ²t · log N(F, ν)) · dim₁(T) + dim₁(T) · (log N(F, ν))^(3/4) · (√c_η + σ_η)) for unknown variance
- Lower bounds show the variance dependence is optimal, matching the upper bounds
- The approach works for general function approximation via eluder dimension, not just linear bandits

## Why This Works (Mechanism)

### Mechanism 1: Robustifying the Excess Loss Estimator
- **Claim:** Robustifying the excess loss estimator (rather than the reward estimator) enables variance-dependent regret bounds
- **Mechanism:** Standard approaches minimize squared error, which scales with reward range R. By applying Catoni's estimator to the excess loss term, the algorithm effectively "trims" extreme noise events, allowing confidence bounds to depend on cumulative variance rather than worst-case range
- **Core assumption:** Heavy-tailed but bounded variance noise, realizable function class F containing f*
- **Evidence anchors:** Abstract highlights this as key innovation; section 3.2 shows L_t(f,f') is robust sample-based estimator
- **Break condition:** Unbounded variance noise violates Catoni estimator's concentration guarantees

### Mechanism 2: Variance-Adaptive Weighting
- **Claim:** Weighting regression loss by inverse variance allows scaling with actual noise rather than worst-case upper bound
- **Mechanism:** Catoni-OFUL uses weights σ̄_t = max(α, σ_t, √(4ι(δ)L_f·D_F(x;...))) to normalize loss. Low-variance rounds contribute more precisely while high-variance rounds are down-weighted
- **Core assumption:** Known per-round variance σ_t
- **Evidence anchors:** Section 3.2 defines σ̄_t and table 1 shows explicit variance dependence
- **Break condition:** Inaccurate variance information (underestimation) amplifies noise and breaks guarantees

### Mechanism 3: Peeling with Aggregate Variance Estimation
- **Claim:** Peeling strategy with robust aggregate variance estimation enables optimal bounds without per-round variance
- **Mechanism:** VACB decomposes decision space into layers, estimating cumulative weighted variance ˆVar_t^l using Catoni's estimator instead of individual σ_t values. This aggregate estimate serves as sufficient proxy for regression weights
- **Core assumption:** Noise satisfies Assumption 1 (bounded fourth moment)
- **Evidence anchors:** Section 4 describes peeling-based approach and Equation 6 for aggregate variance estimation
- **Break condition:** Poor tuning of peeling levels or confidence parameters causes excessive computational overhead or suboptimal regret scaling

## Foundational Learning

- **Concept: Contextual Bandits**
  - **Why needed here:** Core environment where learner observes context, picks action, receives reward, and aims to minimize regret
  - **Quick check:** Can you distinguish between "regret" (loss relative to optimal) and "reward" (absolute gain)?

- **Concept: Catoni's Estimator (Robust Statistics)**
  - **Why needed here:** Engine of the paper - uses strictly increasing function Ψ to bound influence of heavy-tailed data points
  - **Quick check:** Why would Ψ(x) handle massive outliers better than sample mean x̄?

- **Concept: Eluder Dimension**
  - **Why needed here:** Quantifies function class complexity, serving role similar to dimension d in linear bandits but generalizes to non-linear functions
  - **Quick check:** Does higher eluder dimension imply easier or harder learning with limited data?

## Architecture Onboarding

- **Component map:** Environment -> Estimator Core -> Variance Proxy (VACB) -> Confidence Set Manager -> Action Selector
- **Critical path:**
  1. Input: Receive context X_t and (if Catoni-OFUL) known variance σ_t
  2. Optimization: Solve robust estimator f̂_t via min-max Catoni formulation or candidate set approach
  3. Selection: Select action x_t by maximizing optimistic reward estimate
  4. Update: Observe reward y_t and update confidence set F_t and variance proxy (if VACB)

- **Design tradeoffs:**
  - Catoni-OFUL vs. VACB: Known variance gives better regret constants but requires impractical assumption; VACB is practical but has worse eluder dimension dependence
  - Min-max vs. Candidate Set: Exact optimization is hard; Algorithm 3 offers easier implementation but may need more samples

- **Failure signatures:**
  - Regret scales with R: Catoni parameters not properly truncating tails, algorithm behaves like standard OLS
  - Confidence collapse: In VACB, biased-low ˆVar causes overly tight confidence sets, pushing f* outside
  - Numerical instability: Improper θ initialization causes division-by-zero or NaN errors in early rounds

- **First 3 experiments:**
  1. Synthetic Heavy-Tailed Linear Bandit: Pareto noise, compare Catoni-OFUL (true variance) vs. standard OFUL to validate logarithmic R dependence
  2. VACB Stress Test: Same linear data but hide variance, check if regret scales with true cumulative variance ∑σ²t rather than T
  3. Non-Linear Function Approximation: Neural Network or Kernel function class, compare regret against theoretical bound involving Eluder dimension

## Open Questions the Paper Calls Out

- **Open Question 1:** Can Catoni estimator approach be extended to handle adversarial corruption in addition to heavy-tailed rewards?
  - Basis: Conclusion states "it might also be useful to investigate if it enables us to handle other forms of noise, such as adversarial corruption"
  - Unresolved: Paper focuses on heavy-tailed stochastic noise, not adversarial corruption requiring different analytical tools
  - Resolution evidence: Algorithms and regret bounds handling both heavy tails and adversarial corruption with polylogarithmic R dependence

- **Open Question 2:** Can worse eluder dimension dependence in unknown variance case be improved to match known variance case?
  - Basis: Conclusion states "improving this is left as a future direction" regarding worse eluder dimension dependence
  - Unresolved: Peeling approach introduces additional complexity terms not present in known variance case
  - Resolution evidence: Algorithm achieving same eluder dimension dependence without knowing per-round variances

- **Open Question 3:** Can theoretical results be extended to general MDPs with heavy-tailed rewards?
  - Basis: Conclusion states "It would also be interesting to extend the results to general MDPs"
  - Unresolved: Current analysis specific to contextual bandits; MDPs require handling temporal dependencies and value function approximation
  - Resolution evidence: Variance-dependent regret bounds for general MDPs with heavy-tailed rewards using function approximation

## Limitations

- Catoni-OFUL requires impractical assumption of known per-round variance, limiting real-world applicability
- VACB suffers from worse eluder dimension dependence (scaling as d_F^(3/2) rather than d_F), making it computationally expensive for complex function classes
- Min-max optimization in Equation 3 is described as "hard to solve exactly" with incomplete implementation details for the candidate set approach

## Confidence

**High Confidence**: Variance-dependent regret bounds are well-supported by mathematical analysis and matching lower bounds; robustifying excess loss mechanism is clearly explained and logically sound

**Medium Confidence**: Peeling strategy in VACB appears theoretically sound but may be challenging to tune correctly; transition from min-max optimization to Algorithm 3 is justified but lacks complete implementation details

**Low Confidence**: Computational complexity of solving min-max optimization for complex function classes is not fully characterized; paper notes difficulty but doesn't provide concrete runtime guarantees or efficient implementation strategies

## Next Checks

1. **Numerical Validation**: Implement Catoni estimator and verify concentration properties on synthetic heavy-tailed data with known variance; compare empirical coverage probabilities against theoretical guarantees in Lemma 1

2. **Regret Scaling Verification**: Run both Catoni-OFUL (with oracle variance) and VACB on linear bandit with controlled heavy-tailed noise; measure regret scaling empirically to confirm √(∑σ²t) dependence rather than R-scaling, and compare against standard OFUL baseline

3. **Peeling Strategy Robustness**: Test VACB with varying numbers of peeling levels L and different confidence radius parameters β̂; evaluate sensitivity to hyperparameters and identify regimes where algorithm fails or succeeds