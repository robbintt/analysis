---
ver: rpa2
title: 'Eluder dimension: localise it!'
arxiv_id: '2601.09825'
source_url: https://arxiv.org/abs/2601.09825
tags:
- bound
- loss
- function
- proposition
- assumption
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of obtaining first-order regret\
  \ bounds in generalised linear models (GLMs) using eluder dimension-based analysis.\
  \ Standard approaches based on the global eluder dimension cannot yield first-order\
  \ regret bounds because they introduce worst-case information gain parameters (\u03BA\
  ) that cancel out the small-cost term \u03B7(a), destroying the first-order gains."
---

# Eluder dimension: localise it!

## Quick Facts
- arXiv ID: 2601.09825
- Source URL: https://arxiv.org/abs/2601.09825
- Reference count: 40
- This paper introduces localisation of eluder dimension to achieve first-order regret bounds in generalised linear models, overcoming limitations of global eluder dimension analysis.

## Executive Summary
This paper addresses the fundamental challenge of obtaining first-order regret bounds in generalised linear models (GLMs) using eluder dimension-based analysis. Standard approaches based on global eluder dimension cannot achieve first-order regret because they introduce worst-case information gain parameters (κ) that cancel out the small-cost term η(a*), destroying the first-order gains. The authors introduce a novel localisation method for the eluder dimension that restricts analysis to a small neighbourhood of the optimal model parameter, avoiding the problematic κ dependency while maintaining first-order adaptivity.

The key innovation is moving the κ dependence from the leading term to an additive lower-order term through localisation analysis. This enables truly instance-adaptive regret bounds for both stochastic bandits and reinforcement learning. The authors prove that global ℓ1- and ℓ2-eluder dimensions must scale with κ in the GLM setting, making localisation necessary. They propose the ℓ-UCB algorithm with empirical risk minimisation-based confidence intervals and extend their method to reinforcement learning via ℓ-GOLF, providing the first genuine first-order regret bounds for finite-horizon RL with bounded rewards/costs.

## Method Summary
The authors develop a localisation technique for eluder dimension analysis that overcomes the fundamental limitation preventing first-order regret bounds in GLMs. They prove that global eluder dimensions scale with the worst-case information gain parameter κ, making them incompatible with first-order adaptivity. The localisation approach restricts the analysis to a neighbourhood of the optimal parameter, using empirical risk minimisation to construct confidence intervals. The ℓ-UCB algorithm implements this framework with carefully designed loss functions and confidence widths. For stochastic bandits, the method requires bounded loss functions, Bernstein variance conditions, and triangle conditions. The extension to reinforcement learning via ℓ-GOLF adapts the localisation technique to the MDP setting, maintaining the first-order regret guarantees while accounting for the additional complexity of state transitions and Bellman equations.

## Key Results
- Global ℓ1- and ℓ2-eluder dimensions scale with κ in GLM settings, preventing first-order regret bounds with standard approaches
- ℓ-UCB algorithm achieves small-cost bounds under bounded loss, Bernstein variance, and triangle conditions
- ℓ-GOLF provides first genuine first-order regret bounds for finite-horizon RL with bounded rewards/costs
- Localisation moves κ dependence from leading term to additive lower-order term, enabling instance-adaptive regret

## Why This Works (Mechanism)
The mechanism works by shifting the analysis from global properties to local ones. Standard eluder dimension analysis captures worst-case information requirements across the entire parameter space, which forces the inclusion of κ in the regret bound. By localising to a neighbourhood of the optimal parameter, the analysis only needs to account for information requirements in a restricted region where the optimal action has small cost. This allows the small-cost term η(a*) to remain prominent in the bound while relegating κ to an additive term that grows more slowly with time. The empirical risk minimisation framework provides practical confidence intervals that respect this localised structure.

## Foundational Learning
- Generalised Linear Models (GLMs): Required for understanding the function class and why standard eluder dimension analysis fails in this setting. Quick check: Verify that the link function satisfies the required conditions for the analysis.
- Eluder dimension: Fundamental to the information-theoretic analysis of sequential decision making. Quick check: Confirm that the localisation preserves the key properties needed for the regret analysis.
- Information gain parameter (κ): Critical for understanding the limitation being addressed. Quick check: Calculate κ for specific GLM instances to see how it scales.
- Empirical risk minimisation: The core algorithmic technique used for constructing confidence intervals. Quick check: Verify that the chosen loss function satisfies the required convexity and boundedness properties.

## Architecture Onboarding
- Component map: Parameter estimation -> Confidence interval construction -> Action selection -> Regret calculation
- Critical path: The algorithm maintains parameter estimates within a localised confidence region, uses these to select actions via UCB-style exploration, and updates estimates based on observed losses
- Design tradeoffs: Localisation provides first-order adaptivity but requires stronger assumptions (bounded loss, Bernstein variance, triangle condition) and introduces sensitivity to initialisation
- Failure signatures: Violation of boundedness assumptions leads to unbounded confidence widths; poor initialisation may result in slow convergence to the optimal neighbourhood
- First experiments: 1) Test ℓ-UCB on synthetic GLM bandits with known κ to verify first-order scaling. 2) Evaluate performance under varying levels of Bernstein variance. 3) Compare ℓ-GOLF with non-localised methods on simple MDPs with bounded rewards.

## Open Questions the Paper Calls Out
None

## Limitations
- Strong assumptions required: bounded loss functions, Bernstein variance conditions, and triangle conditions may not hold in many practical scenarios
- Localisation approach heavily relies on GLM structure and may not generalise easily to other function classes
- Dependence on optimal parameter's neighbourhood introduces sensitivity to initialisation and may require careful hyperparameter tuning
- While κ is moved to additive term, it remains in the bound and could be significant for some problem instances

## Confidence
- Stochastic bandits theoretical framework: High
- Extension to reinforcement learning via ℓ-GOLF: Medium
- Practical performance in real-world settings: Low

## Next Checks
1. **Empirical Evaluation**: Conduct experiments on synthetic and real-world datasets to verify that ℓ-UCB achieves claimed first-order regret bounds and outperforms non-localised methods in practice.

2. **Assumption Relaxation**: Investigate whether Bernstein variance and triangle conditions can be relaxed or replaced with more general conditions while maintaining first-order regret guarantees.

3. **Extension to Non-Stochastic Settings**: Adapt the localisation technique to adversarial or contaminated environments to assess robustness and broader applicability beyond stochastic bandits.