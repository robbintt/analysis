---
ver: rpa2
title: Zero-shot Forecasting by Simulation Alone
arxiv_id: '2601.00970'
source_url: https://arxiv.org/abs/2601.00970
tags:
- series
- time
- forecasting
- data
- zero-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses zero-shot time series forecasting, which is
  challenging due to limited real data and leakage risks. The authors propose SarSim0,
  a fast SARIMA-based simulator that generates realistic time series on-the-fly.
---

# Zero-shot Forecasting by Simulation Alone

## Quick Facts
- arXiv ID: 2601.00970
- Source URL: https://arxiv.org/abs/2601.00970
- Reference count: 40
- Key outcome: SarSim0 synthetic data enables zero-shot forecasting that matches or exceeds real-data models on M-Series and GiftEval benchmarks

## Executive Summary
This paper tackles the challenge of zero-shot time series forecasting where models must perform well on unseen data without any target-side adaptation. The authors propose SarSim0, a fast SARIMA-based simulator that generates realistic synthetic time series data on-the-fly, addressing the dual challenges of limited real data and leakage risks in zero-shot settings. By training neural networks exclusively on SarSim0-generated data, the approach achieves strong performance across multiple forecasting benchmarks, with the surprising result that SarSim0-pretrained models even outperform their statistical "teacher" (AutoARIMA) on the GiftEval benchmark.

The key innovation is the SarSim0 simulator's three-stage pipeline: (1) SARIMA with pole sampling for stability, (2) SARIMA-2 superposition for multi-seasonality, and (3) heavy-tailed noise generators for burstiness. This allows generation of ~1B unique time series sequences that capture realistic temporal patterns while maintaining computational efficiency. The zero-shot nature of the evaluation—where models are frozen and applied to benchmarks without any hyperparameter tuning—demonstrates that high-quality synthetic data can effectively substitute for real data in certain forecasting scenarios.

## Method Summary
The core approach involves training neural forecasting models on purely synthetic time series generated by the SarSim0 simulator, then applying these models zero-shot to real-world forecasting benchmarks. SarSim0 generates time series using a three-stage pipeline: (1) stable SARIMA processes with poles sampled uniformly within the unit circle, (2) SARIMA-2 superposition to capture bi-seasonality through additive or multiplicative combinations of two SARIMA processes, and (3) heavy-tailed noisers (Poisson, Generalized Gamma, Lognormal) to model burstiness. Models are trained with standard deep learning techniques (Adam optimizer, lr=0.0001, batch size 4096) on synthetic data generated on-the-fly, then evaluated on M-Series (M1, M3, M4, Tourism) and GiftEval benchmarks using multi-horizon, multi-quantile loss (sCRPS and MASE metrics).

## Key Results
- SarSim0-pretrained NBEATS achieves competitive performance on M-Series and GiftEval benchmarks
- On GiftEval, SarSim0-pretrained models outperform their statistical "teacher" AutoARIMA
- SARIMA-2 superposition is identified as the largest contributor to accuracy gains
- Heavy-tailed noisers significantly improve burstiness modeling compared to Gaussian noise
- Zero-shot models perform competitively without any target-side hyperparameter tuning

## Why This Works (Mechanism)
The approach works by creating a rich, diverse synthetic data distribution that captures key time series characteristics through the SARIMA framework. The pole sampling ensures stability while maintaining variability, SARIMA-2 superposition captures complex seasonal patterns, and heavy-tailed noise models real-world burstiness. By training on this diverse synthetic distribution, neural models learn generalizable forecasting patterns that transfer effectively to real-world data without requiring target-specific adaptation.

## Foundational Learning

**SARIMA stability**: Understanding how autoregressive (AR) coefficients relate to pole locations in the complex plane, where poles inside the unit circle ensure stable processes. *Why needed*: Stability is critical for generating realistic, non-divergent time series. *Quick check*: Verify that all generated AR coefficients correspond to poles within radius 0.9 of the origin.

**Multi-seasonality modeling**: The concept that real-world time series often exhibit multiple seasonal patterns (e.g., daily and weekly cycles) that can be captured through superposition of SARIMA processes. *Why needed*: Single-seasonality models fail to capture complex temporal dependencies. *Quick check*: Confirm that SARIMA-2 combinations produce realistic multi-periodic patterns in synthetic data.

**Heavy-tailed distributions**: Understanding that real-world time series often exhibit burstiness and extreme events better modeled by heavy-tailed distributions than Gaussian noise. *Why needed*: Gaussian assumptions fail for many real-world patterns with sudden spikes. *Quick check*: Compare synthetic burstiness statistics against real-world benchmarks.

## Architecture Onboarding

**Component map**: Synthetic Data Generation (SarSim0) -> Neural Model Training -> Zero-shot Forecasting Application. The pipeline flows from SARIMA simulation through superposition and noise addition to model training, then directly to frozen deployment on benchmarks.

**Critical path**: The most critical path is the synthetic data generation quality, particularly the SARIMA-2 superposition stage, which the ablation study shows has the largest impact on accuracy. The heavy-tailed noisers provide important but secondary improvements.

**Design tradeoffs**: The approach trades computational efficiency (fast on-the-fly generation) for potential distributional mismatches between synthetic and real data. It also accepts the limitation of univariate forecasting to enable zero-shot application without target-side adaptation.

**Failure signatures**: Poor zero-shot performance typically indicates inadequate synthetic data diversity, particularly in seasonal patterns (if SARIMA-2 is insufficient) or burstiness modeling (if noisers are inadequate). Divergence in generated series suggests pole sampling instability.

**First experiments**: 1) Generate sample synthetic series and visually inspect for realistic patterns and stability, 2) Run ablation studies removing SARIMA-2 or noisers to quantify their impact, 3) Compare synthetic data statistics (autocorrelation, seasonality strength) against real benchmark data.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation comparison against AutoARIMA may be unfair since AutoARIMA tunes hyperparameters on test data while neural models remain frozen
- Synthetic data may not fully capture all real-world time series patterns, particularly highly non-linear or non-stationary processes
- Limited evaluation to specific benchmarks (M-Series and GiftEval) raises questions about generalization to other domains

## Confidence

**High Confidence**: SarSim0 can generate large volumes of synthetic time series rapidly; training on SarSim0 enables zero-shot forecasting; the three-stage pipeline produces realistic synthetic series.

**Medium Confidence**: SarSim0-pretrained models match or exceed real-data models (fairness concerns); SarSim0 outperforms AutoARIMA on GiftEval (methodology favors statistical baseline); SARIMA-2 is the largest accuracy contributor (internally consistent ablation).

**Low Confidence**: Synthetic data can fully substitute for real data in all zero-shot scenarios; the approach generalizes beyond tested benchmarks and architectures.

## Next Checks

1. Implement fair comparison protocol where both neural models and AutoARIMA operate under identical zero-shot constraints, measuring performance when all methods have identical information access.

2. Conduct systematic distributional analysis comparing synthetic time series generated by SarSim0 against real-world time series across multiple benchmarks to quantify representational gaps, particularly for non-Gaussian patterns.

3. Evaluate zero-shot performance of SarSim0-pretrained models on time series domains not represented in the training distribution (e.g., financial data, sensor networks, medical signals) to assess true generalization capability beyond M-Series and GiftEval benchmarks.