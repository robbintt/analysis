---
ver: rpa2
title: Utilizing Earth Foundation Models to Enhance the Simulation Performance of
  Hydrological Models with AlphaEarth Embeddings
arxiv_id: '2601.01558'
source_url: https://arxiv.org/abs/2601.01558
tags:
- basins
- attributes
- similarity
- embeddings
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Earth Foundation Models can improve hydrological simulation in
  ungauged basins by providing richer basin representations than traditional attributes.
  Models using AlphaEarth embeddings outperformed those using CAMELS attributes, with
  NSE rising from 0.553 to 0.612 in out-of-sample tests.
---

# Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings

## Quick Facts
- arXiv ID: 2601.01558
- Source URL: https://arxiv.org/abs/2601.01558
- Reference count: 0
- Primary result: Earth Foundation Models can improve hydrological simulation in ungauged basins by providing richer basin representations than traditional attributes

## Executive Summary
This study demonstrates that AlphaEarth Foundation (AEF) embeddings, derived from satellite imagery, significantly outperform traditional CAMELS attributes for hydrological modeling in ungauged basins. Using LSTM models with AEF embeddings achieved an out-of-sample NSE of 0.612 compared to 0.553 with CAMELS attributes. The embeddings capture integrated environmental dynamics and enable more effective donor basin selection through similarity-based clustering. However, cross-regime generalization remains challenging, suggesting the need for either regionalized approaches or hybrid models that combine surface and subsurface information.

## Method Summary
The research employs LSTM networks to predict streamflow in ungauged basins, comparing two static basin representations: traditional CAMELS attributes (17 dimensions) versus AlphaEarth Foundation embeddings (64 dimensions). The model processes meteorological time series (precipitation, temperature, radiation, etc.) fused with static basin features through an MLP layer. Training uses multi-basin regionalization with spatial cross-validation, testing both in-sample and out-of-sample performance. The study evaluates three similarity metrics for donor basin selection and conducts scaling experiments to determine optimal training set sizes for PUB scenarios.

## Key Results
- AEF embeddings improved out-of-sample NSE from 0.553 to 0.612 compared to CAMELS attributes
- Embedding-based similarity enabled more hydrologically coherent donor basin selection
- Cross-regime tests showed AEF embeddings performed worse than CAMELS attributes, indicating current models struggle to unify distinct hydrologic regimes
- Performance degraded when training sets included too many dissimilar basins, highlighting importance of similarity-aware selection

## Why This Works (Mechanism)

### Mechanism 1: Environmental Feature Enrichment
- Satellite-derived embeddings capture integrated environmental dynamics (vegetation phenology, surface texture) missing from sparse, hand-crafted attributes
- AEF embeddings encode continuous, high-dimensional environmental signals learned via self-supervised training on petabyte-scale satellite imagery
- This richer context allows LSTM models to infer hydrological behavior more effectively when specific basin data is missing

### Mechanism 2: Embedding-Space Coherence
- AEF embeddings define similarity metrics that organize basins into tighter, more hydrologically coherent clusters
- The 64-dimensional vector space creates a "neighbor purity" effect, reducing noise when learning from a small set of highly relevant donors
- Hydrological functional similarity is better captured by visual/environmental surface patterns than traditional catchment attributes

### Mechanism 3: Discriminative Precision (The Granularity-Generalization Trade-off)
- While AEF's high discriminative power aids donor selection, it hinders cross-regime generalization
- AEF creates sharp, distinct clusters that penalize dissimilarity too harshly, preventing models from bridging gaps between regimes
- CAMELS attributes' "blurrier" nature paradoxically aids generalization by averaging out distinct local features

## Foundational Learning

**Concept: Prediction in Ungauged Basins (PUB)**
- Why needed: The core objective is transferring information from gauged "donor" basins to ungauged targets
- Quick check: Can you explain why training on *all* available basins might yield worse results for a specific ungauged basin than training on a subset?

**Concept: Foundation Model Embeddings vs. Attributes**
- Why needed: The study replaces 17 expert-defined attributes with 64 learned embedding dimensions
- Quick check: How does the information content of a 64-dim satellite embedding differ from a standard catchment attribute table?

**Concept: Regionalization & Similarity Metrics**
- Why needed: The paper tests different ways to define "similarity" (Attribute vs. MLP-Fusion vs. AEF)
- Quick check: Does cosine similarity in the AEF space represent physical proximity or functional environmental similarity?

## Architecture Onboarding

**Component map:**
Meteorological Time Series + MLP Fusion Layer + LSTM (128 hidden states) + Linear Output Head

**Critical path:**
1. Extract 64-dim AEF embeddings (spatially/temporally averaged from 10m resolution)
2. Compute cosine similarity between target basin and all candidates
3. Select top-k donor basins based on similarity
4. Train LSTM on selected donors
5. Predict streamflow for target basin using its AEF embedding

**Design tradeoffs:**
- Use AEF for better Out-of-Sample accuracy and smaller training sets
- Use CAMELS for better cross-regime generalization
- Smaller, similarity-filtered sets (k≈200) outperform full dataset training due to noise reduction

**Failure signatures:**
- Heterogeneity Collapse: Performance degrades as k increases (>300) if dissimilar basins are included
- Cross-Regime Drop: Significant NSE drop when testing on basin with no environmentally similar counterparts

**First 3 experiments:**
1. In-Sample vs. Out-of-Sample Baseline: Compare AEF vs. CAMELS with temporal holdout vs. spatial CV
2. Scaling Analysis (k-NN): Incrementally increase training set size (k=100 to 670) using AEF-similarity vs. Random selection
3. Leave-One-Cluster-Out: Cluster basins using AEF embeddings; train on one cluster, test on another

## Open Questions the Paper Calls Out

**Open Question 1**
- Can a single unified hydrological model be developed that automatically adapts to diverse hydrological regimes without retraining?
- The conclusion states future work should develop unified models using conditional computation or mixture-of-experts
- Current entity-aware models struggle to decouple physical laws from specific static contexts
- A model architecture that dynamically activates parameter substructures based on basin attributes would resolve this

**Open Question 2**
- Does expanding training data to a global scale offset the cross-regime generalization degradation observed in AEF-based models?
- The authors ask whether global-scale datasets might enable learning truly transferable patterns
- The CAMELS-US dataset is insufficient for separating general physical patterns from unique local characteristics
- Training on global datasets (e.g., Caravan) and comparing in-cluster vs. cross-regime performance would resolve this

**Open Question 3**
- Can integrating non-surface data (e.g., subsurface geology) into Earth Foundation Models close the "context gap" that limits cross-regime generalization?
- The discussion notes that surface-based remote sensing misses critical subsurface information
- AEF embeddings capture fine-grained surface details but fail to represent deeper hydrological drivers
- Ablation studies augmenting AEF with geologic or soil depth attributes would test if this recovers lost cross-regime performance

## Limitations

- Temporal mismatch between AEF (2017-2024) and CAMELS (1980-2014) data may affect stability
- Cross-regime generalization failure under AEF embeddings demonstrated but not mechanistically explained
- Optimal donor set size (k≈200-300) is empirical and may not generalize to other geographies

## Confidence

- High confidence: Improved out-of-sample NSE (0.553→0.612) with AEF embeddings; donor basin selection advantage
- Medium confidence: Optimal donor set size and its impact on performance; similarity-aware selection benefits
- Low confidence: Cross-regime generalization failure mechanism; temporal stability of AEF embeddings

## Next Checks

1. Verify temporal stability by comparing AEF embeddings across multiple years and checking correlation with 1980-2014 CAMELS period
2. Perform ablation study on MLP architecture to confirm its contribution to performance gains
3. Test cross-regime generalization with regionalized models rather than single global model