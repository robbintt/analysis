---
ver: rpa2
title: 'Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling'
arxiv_id: '2505.22290'
source_url: https://arxiv.org/abs/2505.22290
tags:
- scaling
- reasoning
- search
- time
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper challenges the assumption that Large Language Models\
  \ (LLMs) cannot solve complex problems previously deemed \"unsolvable.\" The authors\
  \ systematically explore the combined potential of advanced in-context search prompting\
  \ (CoT and AoT) and test-time scaling methods (parallel, sequential, and internal\
  \ scaling) on controlled NP-hard tasks and real-world planning benchmarks. Their\
  \ approach achieves up to 30\xD7 improvement in success rates compared to previously\
  \ reported results, even without external mechanisms."
---

# Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling

## Quick Facts
- arXiv ID: 2505.22290
- Source URL: https://arxiv.org/abs/2505.22290
- Authors: Fanzeng Xia; Yidong Luo; Tinko Sebastian Bartels; Yaqi Xu; Tongxin Li
- Reference count: 40
- This paper challenges the assumption that Large Language Models (LLMs) cannot solve complex problems previously deemed "unsolvable."

## Executive Summary
This paper challenges the assumption that Large Language Models (LLMs) cannot solve complex problems previously deemed "unsolvable." The authors systematically explore the combined potential of advanced in-context search prompting (CoT and AoT) and test-time scaling methods (parallel, sequential, and internal scaling) on controlled NP-hard tasks and real-world planning benchmarks. Their approach achieves up to 30× improvement in success rates compared to previously reported results, even without external mechanisms. The key finding is that commonly used evaluation configurations systematically underestimate LLM reasoning capabilities. Theoretical analysis further supports this by showing that combining in-context search with internal scaling significantly extends the complexity class of solvable reasoning problems.

## Method Summary
The method evaluates a matrix of In-Context Search strategies (Direct, Chain-of-Thought with greedy search examples, Algorithm-of-Thought with DFS/backtracking examples) combined with Test-Time Scaling (Parallel Best-of-N, Sequential Self-Refine, Internal Scaling). The key configuration uses AoT prompts demonstrating DFS logic with Internal Scaling (extended "Thinking" mode) enabled. Experiments run on 100 instances per task at Difficulty Level 10 across NP-hard benchmarks (Vertex Cover, 3DM) and planning tasks (Trip/Meeting Planning). Success rate measures percentage of instances with verifiably correct solutions.

## Key Results
- AoT-IS combination achieves 31% success on Vertex Cover and 40% on Trip Planning where direct prompting achieved 0%
- Up to 30× improvement in success rates compared to previously reported results without external mechanisms
- Internal scaling is the critical multiplier when combined with in-context search
- Current evaluation configurations systematically underestimate LLM reasoning boundaries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Combining in-context search prompting with internal scaling extends the complexity class of problems LLMs can solve
- Mechanism: CoT enables polynomial-time computation (P), AoT enables non-deterministic polynomial-time (NP). Internal scaling allows thought traces to scale exponentially, pushing capability boundaries toward EXP and NEXP
- Core assumption: Transformers with sufficient CoT steps can simulate deterministic Turing machines step-by-step
- Evidence anchors: [abstract]: "Theoretically, we show that in-context search prompting, when combined with internal scaling, significantly extends the complexity class of solvable reasoning problems"; [Theorem 3.3/3.4]: CoT(exp(n)) = EXP and AoT(exp(n)) = NEXP
- Break condition: If the reasoning tokens generated are redundant rather than computationally core (Theorem 3.5), complexity gains do not materialize

### Mechanism 2
- Claim: Advanced in-context search alone provides only marginal gains on hard tasks
- Mechanism: CoT and AoT provide structured reasoning templates that guide exploration, but without computational scaling, they cannot overcome inherent complexity barriers
- Core assumption: The model must understand the task's solution path from in-context examples
- Evidence anchors: [Section 2.2, Level 2]: "Claude 3.7's success rate rises by 2% and 3% respectively [under CoT-WS and AoT-WS], whereas Qwen 3 remains fixed at 0%"; [Section 2.2]: "the effectiveness of all in-context search and test-time scaling variants is highly correlated with the inherent capabilities of the base model"
- Break condition: If base model lacks capacity to follow algorithmic examples, prompting gains vanish

### Mechanism 3
- Claim: Current evaluation configurations systematically underestimate LLM reasoning boundaries
- Mechanism: Most evaluations use direct prompting with simple scaling, missing the synergy of combining structured search with extended computation
- Core assumption: Tasks with <5% reported success rates are not inherently unsolvable
- Evidence anchors: [abstract]: "achieves up to a 30x improvement in success rates compared to previously reported results without any external mechanisms"; [Table 1/2]: AoT-IS combination yields 31% success on Vertex Cover and 40% on Trip Planning where direct prompting achieved 0%
- Break condition: If tasks require external tools or domain knowledge not captured in prompting, improvement ceiling remains bounded

## Foundational Learning

- Concept: Complexity classes P, NP, EXP, NEXP
  - Why needed here: The theoretical claims rest on understanding what problem classes become tractable under different token budgets
  - Quick check question: Why can CoT with exponential tokens solve problems beyond NP?

- Concept: Autoregressive generation as computation
  - Why needed here: The mechanism treats generated tokens as a computational trace, not just output
  - Quick check question: How does causal masking enable simulation of sequential computation?

- Concept: Internal scaling vs. parallel/sequential scaling
  - Why needed here: The paper shows internal scaling is the critical multiplier when combined with in-context search
  - Quick check question: Why does internal scaling outperform parallel scaling (Best-of-N) on NP-hard tasks?

## Architecture Onboarding

- Component map: Base Model -> Prompting Strategy (Direct/CoT/AoT) -> Scaling Method (Parallel/Sequential/Internal) -> Evaluation on NP-hard Tasks
- Critical path: Start with base model → select prompting strategy → enable internal scaling → measure on difficulty level 10 instances
  - Without internal scaling, even AoT peaks at ~3-9% on hardest tasks
  - AoT + Internal Scaling yields the 24-40% range
- Design tradeoffs:
  - AoT prompts require hand-crafted algorithmic examples; CoT is easier to construct but lacks backtracking demonstration
  - Internal scaling depends on model training (Claude 3.7 and Qwen3 have explicit thinking modes)
  - Exponential token generation is theoretically meaningful but practically constrained by compute
- Failure signatures:
  - Qwen3 shows 0% on numerical abstract reasoning (Vertex Cover, 3DM) even with AoT—suggests architectural/training gaps
  - Parallel/Sequential scaling without in-context search: 0% across all models on hardest instances
  - Direct prompting with any scaling: fails to exceed 4% success
- First 3 experiments:
  1. Replicate Trip Planning ablation: Direct-WS vs. CoT-IS vs. AoT-IS on 100 instances at difficulty 10
  2. Test generalization: Apply AoT-IS to a new NP-hard task (e.g., Graph Coloring) with hand-crafted DFS examples
  3. Ablate core reasoning tokens: Measure success vs. total tokens generated to validate Theorem 3.5

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can theoretical expressivity analysis be extended to cover parallel and sequential test-time scaling methods?
- Basis in paper: [explicit] The authors explicitly identify the need for "extending the theoretical analysis, which currently emphasizes internal scaling, to comprehensively cover parallel and sequential scaling methods."
- Why unresolved: Theorems 3.1 through 3.4 characterize complexity classes (P, NP, EXP, NEXP) strictly in terms of internal scaling (token length), leaving the computational power of Best-of-N or Self-Refine undefined.
- What evidence would resolve it: New formal proofs mapping parallel or sequential scaling strategies to specific complexity classes.

### Open Question 2
- Question: Do hybrid test-time scaling strategies outperform the isolated methods tested in this study?
- Basis in paper: [explicit] The paper lists "exploring the potential of hybrid test-time scaling approaches" as a specific limitation, noting they were "not considered in this work."
- Why unresolved: The study evaluates parallel, sequential, and internal scaling independently (ablation style), but does not test combinations (e.g., Parallel Search combined with Internal Scaling).
- What evidence would resolve it: Empirical results comparing the performance of combined scaling configurations against single-method baselines on "unsolvable" NP-hard tasks.

### Open Question 3
- Question: Does simulating alternative search algorithms like Monte Carlo Tree Search (MCTS) yield further improvements over Depth-First Search (DFS)?
- Basis in paper: [explicit] The authors call for "diversifying the in-context search algorithm examples beyond Depth-First Search to include techniques like Monte Carlo Tree Search."
- Why unresolved: The empirical success of Algorithm of Thoughts (AoT) relies solely on prompts mimicking DFS; the efficacy of other algorithmic traces remains unknown.
- What evidence would resolve it: Benchmark experiments using MCTS-based or Graph Search-based prompts on the Natural Plan or 3-Dimensional Matching tasks.

## Limitations
- The theoretical analysis currently emphasizes internal scaling and needs extension to comprehensively cover parallel and sequential scaling methods
- The effectiveness of all in-context search and test-time scaling variants is highly correlated with the inherent capabilities of the base model
- The study evaluates in-context search and test-time scaling in isolation and does not consider hybrid test-time scaling approaches

## Confidence

**High Confidence**: The empirical demonstration that combining AoT prompting with internal scaling achieves 30× improvements over baseline configurations. The ablation studies are systematic and the success rate measurements on controlled NP-hard instances are verifiable.

**Medium Confidence**: The theoretical framework connecting in-context search and test-time scaling to complexity class extensions. While the theorems are formally stated, their practical applicability depends on conditions (like non-redundant reasoning tokens) that require further empirical validation.

**Low Confidence**: The generalizability of AoT prompting across different model architectures. The stark performance gap between Claude 3.7 and Qwen3 on the same tasks suggests the methodology may be model-dependent in ways not fully explained.

## Next Checks

1. **Token Redundancy Analysis**: Measure the correlation between reasoning token count and success rate across multiple runs to empirically validate Theorem 3.5. Generate token-level heatmaps showing which portions of the reasoning trace contribute to solution discovery versus redundant exploration.

2. **Model Architecture Transfer**: Apply the AoT-IS methodology to at least two additional model families (e.g., GPT-4, Llama) to test whether the 30× improvement generalizes beyond Claude 3.7 and Qwen3. Document any prompt engineering required for different model architectures.

3. **Complexity Class Boundary Testing**: Systematically vary instance difficulty and token budgets to map the precise boundary where AoT-IS transitions from polynomial to exponential time behavior. Compare this empirically observed boundary against the theoretical predictions in Theorems 3.3-3.4.