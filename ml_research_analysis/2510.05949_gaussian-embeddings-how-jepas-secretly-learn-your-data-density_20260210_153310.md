---
ver: rpa2
title: 'Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density'
arxiv_id: '2510.05949'
source_url: https://arxiv.org/abs/2510.05949
tags:
- density
- learning
- data
- samples
- jepas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reveals that Joint Embedding Predictive Architectures
  (JEPAs) implicitly learn the data density during pretraining. The key insight is
  that JEPAs' anti-collapse term, often viewed as merely preventing representation
  collapse, actually estimates the data density through the model's Jacobian matrix.
---

# Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density

## Quick Facts
- arXiv ID: 2510.05949
- Source URL: https://arxiv.org/abs/2510.05949
- Reference count: 38
- Key outcome: JEPAs implicitly learn data density during pretraining through their anti-collapse term, which estimates density via the model's Jacobian matrix.

## Executive Summary
This paper reveals that Joint Embedding Predictive Architectures (JEPAs) implicitly learn the data density during pretraining. The key insight is that JEPAs' anti-collapse term, often viewed as merely preventing representation collapse, actually estimates the data density through the model's Jacobian matrix. The authors prove that producing Gaussian embeddings (a core JEPA objective) requires the model to learn the underlying data density up to mean-preserving rescaling within each level set. They introduce JEPA-SCORE, a method to extract this learned density efficiently using the Jacobian's singular values. Empirical validation across datasets (synthetic, controlled, and ImageNet) and models (I-JEPA, DINOv2, MetaCLIP) shows that JEPA-SCORE accurately ranks samples by likelihood, with higher scores for typical samples and lower scores for outliers or out-of-distribution data. This finding bridges JEPAs and generative modeling, enabling new applications in outlier detection and model assessment.

## Method Summary
The paper introduces JEPA-SCORE, a method to extract the implicit data density learned by pretrained JEPAs using the Jacobian matrix of the encoder. The approach computes the sum of log singular values of the Jacobian at each input, which serves as a density estimate. The method requires a pretrained JEPA model, input images, and computes the Jacobian via autograd. Implementation involves computing the Jacobian using `torch.autograd.functional.jacobian`, performing SVD, clipping singular values, taking logs, and summing. The resulting scores rank samples by likelihood, with higher scores indicating higher density regions. The method is validated across synthetic data (GMM with known density), ImageNet-1k/A/R, and out-of-distribution datasets (MNIST, Galaxy10).

## Key Results
- JEPA-SCORE accurately ranks samples by likelihood on synthetic GMM data with correlation to true log p(x)
- On ImageNet, JEPA-SCORE assigns higher scores to typical samples and lower scores to outliers or OOD data
- The method works across multiple JEPA variants (I-JEPA, DINOv2, MetaCLIP) without retraining

## Why This Works (Mechanism)

### Mechanism 1: Gaussian Concentration on Hypersphere
- **Claim:** Standardized high-dimensional Gaussian embeddings concentrate on the unit hypersphere surface, becoming approximately uniform in angular distribution.
- **Mechanism:** As embedding dimension K increases, the Chi-distributed norms of normalized Gaussians converge to a Dirac delta at radius 1 (scaled Chi-distribution variance = 2/K), leaving only uniform angular variation.
- **Core assumption:** Embedding dimension K is sufficiently large (empirically K ≥ 64 shows convergence).
- **Evidence anchors:** [abstract] "JEPAs' anti-collapse term [...] actually estimates the data density through the model's Jacobian matrix" [section 2.1] Lemma 1 proof shows K→∞ convergence of f_N(0,I/K) to δ(r-1)·f_U(S(0,R,K,K)) [corpus] Related work on LpJEPA extensions assumes similar isotropic constraints; no direct contradiction found.
- **Break condition:** If embedding dimension is too low (e.g., K < 32), concentration weakens and uniformity assumption fails.

### Mechanism 2: Density-Preserving Change of Variables
- **Claim:** For encoder output f(X) to be uniform/Gaussian, the encoder's Jacobian must inversely scale with input density—high-density regions must be compressed, low-density regions expanded.
- **Mechanism:** The change-of-variables formula (Eq. 1) relates output density to input density via ∏σ_k(J_f(x)). To maintain constant output density despite varying input density, the Jacobian singular values must compensate: p_X(x) ∝ ∏σ_k(J_f(x))⁻¹.
- **Core assumption:** The encoder is differentiable and the level sets have consistent dimensionality (rank stability).
- **Evidence anchors:** [abstract] "producing Gaussian embeddings [...] requires the model to learn the underlying data density up to mean-preserving rescaling" [section 2.2] Eq. (1) and Lemma 2 establish the formal relationship [corpus] Weak direct corpus support—this is the paper's novel theoretical contribution.
- **Break condition:** If the encoder is bijective with degenerate Jacobian (singular values near zero), the formula becomes unstable.

### Mechanism 3: JEPA-SCORE as Density Estimator
- **Claim:** The sum of log singular values of the encoder Jacobian at input x recovers log p(x) up to a constant.
- **Mechanism:** JEPA-SCORE(x) = Σ log(σ_k(J_f(x))) (Eq. 5). This is the Monte Carlo estimator of Theorem 1's expectation over augmentation transforms.
- **Core assumption:** JEPA training has converged (predictive invariance + anti-collapse diversity both optimized).
- **Evidence anchors:** [abstract] "JEPA-SCORE accurately ranks samples by likelihood, with higher scores for typical samples" [section 2.3] Theorem 1 and empirical validation across I-JEPA, DINOv2, MetaCLIP [corpus] LeJEPA (2511.08544) provides complementary JEPA theory but doesn't address density estimation.
- **Break condition:** If JEPA is undertrained or collapse occurs, embeddings won't be Gaussian and score is meaningless.

## Foundational Learning

- **Concept:** Jacobian matrix and singular value decomposition
  - **Why needed here:** JEPA-SCORE computation requires extracting all singular values of J_f(x)—a D×K matrix of partial derivatives ∂f_k/∂x_d.
  - **Quick check question:** Given a 3-layer MLP f: ℝ⁷⁸⁴ → ℝ²⁵⁶, what is the shape of its Jacobian at a single input?

- **Concept:** Probability density change-of-variables
  - **Why needed here:** Understanding why p_Y(y) = p_X(x)/|det(J)| for bijective f, and how this generalizes to non-bijective encoders via Eq. (1).
  - **Quick check question:** If f(x) = 2x and X ~ Uniform[0,1], what is p_Y(1.5)?

- **Concept:** JEPA dual objectives (invariance + diversity)
  - **Why needed here:** The theory requires both terms—prediction enforces level-set structure, anti-collapse enforces Gaussian output.
  - **Quick check question:** What happens if you remove the diversity term from Eq. (2)?

## Architecture Onboarding

- **Component map:** Encoder f_θ → Embedding z → Jacobian J_f(x) → SVD → JEPA-SCORE
- **Critical path:**
  1. Take pretrained JEPA encoder (any architecture: ViT, ResNet, etc.)
  2. At inference, compute Jacobian J_f(x) via autograd (Listing 1)
  3. Compute SVD and sum: `score = svdvals(J).clip(eps).log().sum()`
  4. Higher score = higher density = more typical sample

- **Design tradeoffs:**
  - Single-sample vs multi-sample: Eq. (4) shows expectation over transforms T; Eq. (5) is single-sample approximation—faster but noisier.
  - Bijective vs surjective encoders: Bijective gives exact p_X; surjective has level-set ambiguity (Lemma 2).
  - Embedding dimension K: Higher K → better concentration but more expensive Jacobian computation.

- **Failure signatures:**
  - Scores invariant to input: Encoder collapsed (all same embedding)
  - Negative infinite scores: Singular values hitting zero (rank deficiency)
  - Inconsistent rankings across seeds: Training not converged

- **First 3 experiments:**
  1. **Sanity check on synthetic GMM:** Train small JEPA on 2D Gaussian mixture; verify JEPA-SCORE correlates with true log p(x) (replicate Fig. 2, top-right heatmap).
  2. **OOD detection benchmark:** Compute JEPA-SCORE on ImageNet validation vs MNIST vs Galaxy10; confirm distribution shift (replicate Fig. 3 histograms).
  3. **Within-class ranking:** For a single ImageNet class, rank samples by JEPA-SCORE; visually inspect if low-score samples are outliers (replicate Fig. 1 pattern: seated birds score lower than flying birds).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can JEPA-SCORE be estimated efficiently for high-dimensional inputs without explicitly computing the full Jacobian matrix?
- **Basis:** [inferred] The method relies on Singular Value Decomposition (SVD) of the model's Jacobian (Listing 1), which scales poorly with input dimension (e.g., pixel count), potentially limiting real-time application.
- **Why unresolved:** While the math is closed-form, the computational complexity of calculating exact Jacobians for modern vision transformers on high-resolution images is prohibitive.
- **What evidence would resolve it:** The development and validation of a stochastic estimator (e.g., using Hutchinson's method) that approximates the log-determinant or singular value sum without full matrix materialization.

### Open Question 2
- **Question:** How sensitive is the density estimation to the degree of training convergence or the specific weighting of the anti-collapse term?
- **Basis:** [inferred] Theorem 1 and Lemma 2 rely on the assumption that the model is "at optimality," a state rarely perfectly achieved in practical deep learning training.
- **Why unresolved:** It is unclear if the JEPA-SCORE retains fidelity early in training or if it requires the representation to be fully formed (Gaussian) to yield meaningful density rankings.
- **What evidence would resolve it:** A study plotting the correlation between the training loss (prediction vs. anti-collapse terms) and the accuracy of the JEPA-SCORE against a ground truth density over training steps.

### Open Question 3
- **Question:** How does JEPA-SCORE compare quantitatively to explicit generative models or feature-space density estimators in standard out-of-distribution (OOD) detection benchmarks?
- **Basis:** [explicit] The paper states that JEPA-SCORE opens "new avenues in using JEPA-SCORE for outlier detection," but the experimental validation focuses on qualitative sample ranking and relative histogram shifts.
- **Why unresolved:** The paper does not provide standard OOD metrics (e.g., AUROC, AUPR) comparing JEPA-SCORE against established baselines like Flow models or Mahalanobis distance in the feature space.
- **What evidence would resolve it:** A benchmark evaluation on datasets like CIFAR-10 vs. SVHN/CIFAR-100 showing the discriminative power of JEPA-SCORE versus explicit likelihood models.

## Limitations
- The Gaussian concentration assumption is asymptotic with limited finite-sample guarantees
- Full Jacobian computation is O(DK²) per sample, making it impractical for large-scale deployment
- Results may not extend to non-JEPA contrastive methods or models trained with different objectives

## Confidence
- **High Confidence:** The empirical validation that JEPA-SCORE correlates with data likelihood on synthetic data and ranks ImageNet samples by typicality
- **Medium Confidence:** The asymptotic concentration arguments hold for tested embedding dimensions, but finite-sample guarantees are lacking
- **Low Confidence:** The assertion that this mechanism is the "secret" purpose of the anti-collapse term—it could be an emergent property rather than intentional design

## Next Checks
1. **Finite-Sample Analysis:** Quantify how JEPA-SCORE accuracy degrades as embedding dimension K decreases below 64. Test K=32, 16, 8 to establish practical limits of the concentration assumption.

2. **Alternative Objectives:** Replace JEPA's diversity term with other regularization methods (weight decay, spectral normalization) and test if JEPA-SCORE still extracts meaningful density estimates. This would validate whether the mechanism is specific to JEPA's formulation.

3. **Scalability Study:** Implement and benchmark Jacobian approximation methods (random projections, Hutchinson's estimator) to enable JEPA-SCORE computation on larger models and datasets. Measure accuracy vs computational cost tradeoffs.