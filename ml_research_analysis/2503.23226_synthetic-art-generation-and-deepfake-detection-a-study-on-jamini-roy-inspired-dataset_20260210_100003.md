---
ver: rpa2
title: Synthetic Art Generation and DeepFake Detection A Study on Jamini Roy Inspired
  Dataset
arxiv_id: '2503.23226'
source_url: https://arxiv.org/abs/2503.23226
tags:
- images
- noise
- detection
- controlnet
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines deepfake detection in the context of synthetic
  Indian art, focusing on Jamini Roy's distinctive style. A novel dataset was created
  using a fine-tuned Stable Diffusion 3 model with ControlNet and IPAdapter, generating
  synthetic artworks alongside authentic Jamini Roy paintings.
---

# Synthetic Art Generation and DeepFake Detection A Study on Jamini Roy Inspired Dataset

## Quick Facts
- arXiv ID: 2503.23226
- Source URL: https://arxiv.org/abs/2503.23226
- Reference count: 33
- Key outcome: This study examines deepfake detection in the context of synthetic Indian art, focusing on Jamini Roy's distinctive style. A novel dataset was created using a fine-tuned Stable Diffusion 3 model with ControlNet and IPAdapter, generating synthetic artworks alongside authentic Jamini Roy paintings. Qualitative, quantitative, and frequency domain analyses were conducted to identify subtle differences between real and AI-generated images. The results showed that ControlNet and IPAdapter improved image quality but also obscured common artifacts, making detection more challenging. State-of-the-art deepfake detection models were evaluated, revealing varying performance across different noise levels and highlighting the need for more adaptive, specialized approaches. The findings demonstrate that while synthetic artworks can closely mimic artistic styles, distinct artifacts remain detectable, particularly in the frequency domain, emphasizing the importance of developing robust detection methods for culturally specific art forms.

## Executive Summary
This study investigates deepfake detection for synthetic art generation, specifically focusing on Jamini Roy's distinctive Indian painting style. The researchers created a novel dataset by fine-tuning Stable Diffusion 3 with ControlNet and IPAdapter, generating synthetic artworks alongside authentic Jamini Roy paintings. Through qualitative, quantitative, and frequency domain analyses, they identified subtle but detectable differences between real and AI-generated images, with ControlNet and IPAdapter improving image quality while simultaneously obscuring common detection artifacts. State-of-the-art detection models were benchmarked, revealing performance degradation when artifacts were masked, particularly for frequency-aware methods. The research highlights the growing challenge of detecting synthetic art and the need for culturally-aware detection approaches that can handle non-Western artistic styles.

## Method Summary
The researchers created a dataset of 770 authentic Jamini Roy paintings scraped from ArtNet, then manually curated 300 "hard samples" representing complex stylistic features. They fine-tuned Stable Diffusion 3 medium using DreamBooth for 28,000 steps on these samples with the prompt "art in the style of Jamini Roy." Synthetic images were generated using Automatic1111 with DPM++ 2M sampler, Karras schedule, 100 steps, CFG scale 7, at four noise levels (0.0, 0.25, 0.5, 0.75) with and without ControlNet+IPAdapter. Quality metrics (MSE, SSIM, PSNR, histogram correlation) were computed alongside frequency domain analysis (power spectrum, phase spectrum, autocorrelation of noise residuals). Three state-of-the-art detection models were trained and evaluated: a frequency-aware model, a diffusion-specific detector, and a universal ViT-based classifier, each for 50 epochs with default settings.

## Key Results
- ControlNet and IPAdapter improved image quality metrics (SSIM 0.7287, PSNR 25.16 dB) comparable to baseline but significantly obscured detection artifacts
- Frequency domain analysis revealed authentic paintings exhibit distinctive cross-shaped high-frequency patterns that synthetic images lack, with 95.3% similar power spectra but diminished intensity
- Detection accuracy varied significantly across models and noise levels, with frequency-aware models showing particular degradation when artifacts were masked by ControlNet
- Synthetic images showed periodic checkerboard artifacts in autocorrelation analysis, a known signature of diffusion-based generation
- All detection models showed reduced performance on culturally specific Indian art compared to general deepfake detection benchmarks

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning Stable Diffusion 3 on curated "hard samples" enables the model to internalize culturally-specific artistic patterns (Jamini Roy's style) within its latent representations. DreamBooth adapts pre-trained diffusion weights by training on 300 manually-selected samples exhibiting complex artistic elements. The latent diffusion architecture performs denoising in compressed latent space, implicitly capturing both high-level features (composition) and fine-grained details (brushwork patterns). Training for 28,000 steps with prompt "art in the style of Jamini Roy" conditions the model on stylistic tokens. Core assumption: The latent space of a pre-trained vision-language model can encode non-Western artistic idioms despite potential training data bias toward Western art traditions. Evidence: "we fine-tuned Stable Diffusion 3 and used techniques like ControlNet and IPAdapter to generate realistic images" [abstract]; "DreamBooth facilitates domain-specific customization by enabling the model to internalize intricate patterns and details unique to the provided dataset" [section III.C]. Break condition: If the pre-trained model's latent space lacks sufficient representation of non-Western artistic idioms, fine-tuning may produce superficial stylistic mimicry without capturing underlying structural patterns.

### Mechanism 2
ControlNet with IPAdapter preserves structural coherence and stylistic fidelity even at elevated noise levels (0.5-0.75), but simultaneously obscures forensic detection artifacts. ControlNet injects auxiliary conditioning (edge maps, pose data) through a parallel network that guides the diffusion process without modifying base weights. IPAdapter adds an intermediate perceptual module aligning outputs with target visual attributes. Together, they constrain the denoising trajectory toward structural consistency with the reference image. Core assumption: Improved structural fidelity correlates with reduced detectability of synthetic artifacts—a double-edged sword for detection. Evidence: "while ControlNet and IPAdapter improve image quality, they also obscure common detection artifacts" [abstract]; "ControlNet achieves comparable mean [SSIM] of 0.7287... with nearly identical standard deviation" [section IV.B]; Detection accuracy drops for Model 1 (frequency-aware) on ControlNet images: 54.6% → 58.6% at noise 0.0, compared to Model 2's relative stability. Break condition: If detection methods shift from artifact-based to semantic inconsistency analysis (cultural pattern disruption), ControlNet's benefits for evasion may diminish.

### Mechanism 3
Synthetic images exhibit quantifiable frequency-domain anomalies—specifically diminished cross-pattern intensity, more uniform power spectrum distribution, and periodic autocorrelation artifacts—that differ from authentic artwork. Fourier analysis reveals that authentic Jamini Roy paintings show distinctive cross-shaped high-frequency patterns (reflecting brushwork complexity) and asymmetric energy distribution. Synthetic images display: (1) reduced high-frequency detail intensity (95.3% similarity by MSE but with diminished clarity), (2) more isotropic/uniform energy distribution, and (3) periodic checkerboard artifacts in autocorrelation of noise residuals. Core assumption: These spectral differences are intrinsic to the diffusion generation process, not artifacts of the specific training data. Evidence: "Fourier domain assessments and autocorrelation metrics, revealing distinct differences between synthetic and authentic images" [abstract]; "Authentic paintings exhibit a distinctive cross-shaped pattern in the high-frequency domain... In contrast, images generated with ControlNet display a 95.3% similar power spectrum... but with diminished intensity and fewer high-frequency details" [section IV.C]; "Both versions show periodic checkerboard artifacts, a sign of synthetic generation" [Appendix A]. Break condition: If generative models evolve to better match natural spectral distributions, frequency-domain detection may become obsolete.

## Foundational Learning

- **Concept: Latent Diffusion Models**
  - Why needed here: Stable Diffusion 3 operates by denoising in a compressed latent space rather than pixel space. Understanding this is essential to grasp why fine-tuning can be efficient (fewer parameters, compressed representation) and why frequency artifacts may emerge from the VAE decoder's upsampling.
  - Quick check question: Can you explain why denoising in latent space rather than pixel space affects both computational efficiency and the types of artifacts that appear in generated images?

- **Concept: Fourier Domain Image Analysis**
  - Why needed here: The paper's primary forensic methodology relies on power spectrum and phase spectrum analysis to distinguish synthetic from authentic art. Without understanding how spatial patterns (brushwork, texture) manifest in frequency representations, the artifact analysis will be opaque.
  - Quick check question: Given an image with strong horizontal and vertical edge structures, what pattern would you expect to see in its 2D power spectrum, and how would a loss of fine texture detail manifest?

- **Concept: Conditional Control in Generative Models (ControlNet/IPAdapter)**
  - Why needed here: The paper's central finding—that enhanced control mechanisms improve image quality while obscuring detection artifacts—requires understanding how auxiliary conditioning networks interface with the base diffusion model without modifying its core weights.
  - Quick check question: How does ControlNet's approach of adding a parallel trainable network differ from directly fine-tuning the base model, and what implications does this have for preserving vs. modifying learned representations?

## Architecture Onboarding

- **Component map:**
  Input Pipeline: ArtNet scraping → 770 raw images → Manual curation → 300 hard samples
  Training Pipeline: Hard samples + DreamBooth → Fine-tuned SD3 weights (28K steps)
  Generation Pipeline: Reference image → [Automatic1111 interface] → SD3 (±ControlNet+IPAdapter) → Synthetic output
  Parameters: DPM++ 2M sampler, Karras schedule, 100 steps, CFG=7, noise levels {0.0, 0.25, 0.5, 0.75}
  Analysis Pipeline: Image set (real + synthetic) → [MSE/SSIM/PSNR/Histogram metrics] + [FFT → Power/Phase spectra] + [Autocorrelation of noise residuals]
  Detection Pipeline: Dataset → Three SOTA detectors (Model 1: frequency-aware, Model 2: diffusion-specific, Model 3: universal ViT-based) → Validation accuracy by noise level and ControlNet condition

- **Critical path:** The paper's core contribution flows through: (1) Dataset creation with culturally-specific hard samples → (2) Fine-tuned generation with enhanced control → (3) Frequency-domain artifact characterization → (4) Detection benchmarking. The break point for reproducibility is Step 1; the break point for generalization is Step 4.

- **Design tradeoffs:**
  - Hard sample selection vs. automated filtering: Manual selection of 300 "hard samples" introduces subjectivity but targets stylistic complexity. Assumption: Curator expertise aligns with features that challenge detectors.
  - ControlNet for quality vs. detectability: Adding control improves SSIM (0.7287) and PSNR (25.16 dB) comparable to baseline, but reduces detection accuracy for frequency-aware methods.
  - Noise level calibration: Noise 1.0 excluded due to "extreme randomness and subtle signs of nudity"—ethical constraint that limits exploring the full noise spectrum but maintains artistic intent alignment.

- **Failure signatures:**
  - High-quality/low-noise synthetic images: Near-random detection performance (53.5%-76.1% accuracy depending on model) suggests detectors lack reliable forensic cues.
  - ControlNet-enhanced images: Frequency-aware Model 1 shows minimal improvement even at high noise (54.6%→58.6%), indicating control mechanisms suppress target artifacts.
  - Cultural specificity gap: All models trained on general/Western-centric datasets; performance on Indian art may not transfer.

- **First 3 experiments:**
  1. Replicate frequency analysis on a single image pair: Take one Jamini Roy original, generate synthetic versions with/without ControlNet at noise 0.0, compute power spectra and autocorrelation. Verify the cross-pattern diminution and checkerboard artifacts reported in Figure 7.
  2. Ablate ControlNet conditioning strength: Run generation at control weights {0.0, 0.5, 1.0, 1.5} while holding noise constant. Measure both SSIM/PSNR (quality) and detection accuracy (detectability) to characterize the quality-detectability tradeoff curve.
  3. Test cross-artist generalization: Apply the fine-tuned Jamini Roy detector to synthetic images in the style of another Indian artist (e.g., Amrita Sher-Gil) to assess whether frequency artifacts are style-specific or generator-specific.

## Open Questions the Paper Calls Out

### Open Question 1
Can the detection methodologies developed for Jamini Roy's style generalize effectively to other Indian artists with distinct stylistic elements? The authors state in Section VII that "testing this study on works of other Indian artists... could provide valuable insights into the generalizability of the detection methodologies." The current study is restricted to a single artist, and it is unclear if the identified model-specific artifacts or stylistic inconsistencies translate to other cultural art forms. Benchmarking the detection models against datasets of other Indian artists (e.g., Rabindranath Tagore) to compare accuracy and false positive rates would resolve this.

### Open Question 2
Do hybrid detection approaches integrating both spatial and frequency domain features offer superior robustness compared to single-domain methods as generative models improve? Section VII advocates for "the development of hybrid detection approaches that integrate both spatial and frequency domain features" to counter future models that may minimize frequency artifacts. Current detection relies heavily on frequency artifacts; if future models eliminate these, single-domain approaches may fail, but the efficacy of a hybrid solution is untested in this context. Developing and testing a dual-domain detector that maintains high accuracy even when frequency domain artifacts are deliberately suppressed in the synthetic images would resolve this.

### Open Question 3
Can few-shot learning techniques successfully address the scarcity of training data for culturally specific deepfake detection? The paper identifies "the application of few-shot learning techniques to address the scarcity of training data" as a "promising direction for future research." Specialized datasets for non-Western art are limited, and it is unknown if standard detectors can achieve high generalization with minimal examples. Demonstrating that a detector fine-tuned with very few samples (e.g., 5-10 shots) achieves performance metrics comparable to models trained on the full dataset would resolve this.

## Limitations
- Cultural Representation Gap: Deepfake detection models are predominantly trained on Western-centric datasets, yet the paper does not quantify how this bias affects performance on Indian art specifically.
- Synthetic-Forensic Artifact Generalization: Frequency-domain artifacts demonstrated on Jamini Roy-style images may not transfer to other generative architectures, as the paper cites Corvi et al. noting that "whether diffusion models exhibit grid-like frequency patterns depends heavily on the specific model used."
- Dataset Construction Subjectivity: The "hard sample" selection process relies on manual curation without specified criteria or validation that these samples genuinely represent the most challenging stylistic features for detection.

## Confidence
- **High Confidence**: The core observation that ControlNet/IPAdapter improves image quality while obscuring detection artifacts is well-supported by quantitative metrics (SSIM 0.7287, PSNR 25.16 dB) and detection accuracy degradation (54.6%→58.6% for frequency-aware models).
- **Medium Confidence**: The frequency-domain artifact analysis shows consistent patterns across experiments, but the claim that these artifacts are intrinsic to diffusion generation rather than dataset-specific requires further validation across different art styles and generative models.
- **Low Confidence**: Claims about cultural pattern disruption lack quantitative support. While the paper notes that "cultural patterns embedded in artistic styles may be disrupted," it provides no empirical measurement of this phenomenon or comparison to how Western artistic styles might be similarly affected.

## Next Checks
1. **Cross-Style Artifact Transfer**: Apply the frequency analysis methodology to synthetic images generated in the style of Western artists (e.g., Van Gogh) using the same fine-tuned model to determine whether observed artifacts are style-specific or architecture-specific.
2. **Detection Model Ablation**: Systematically vary key detection model hyperparameters (learning rate, batch size, number of epochs beyond 50) while holding dataset constant to establish whether "default settings" were optimal or if performance could be significantly improved.
3. **Cultural Pattern Quantification**: Develop metrics to quantify stylistic feature preservation (e.g., brushstroke orientation entropy, color palette fidelity) and measure degradation across noise levels and control conditions to empirically validate the cultural disruption hypothesis.