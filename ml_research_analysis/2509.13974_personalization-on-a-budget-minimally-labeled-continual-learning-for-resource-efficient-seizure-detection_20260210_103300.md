---
ver: rpa2
title: 'Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient
  Seizure Detection'
arxiv_id: '2509.13974'
source_url: https://arxiv.org/abs/2509.13974
tags:
- data
- learning
- seizure
- samples
- update
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of personalized seizure detection
  using deep learning while minimizing computational and labeling costs. The proposed
  method, EpiSMART, uses a continual learning framework that incrementally adapts
  to individual patient EEG patterns while preserving past knowledge through a size-constrained
  replay buffer.
---

# Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection

## Quick Facts
- arXiv ID: 2509.13974
- Source URL: https://arxiv.org/abs/2509.13974
- Authors: Amirhossein Shahbazinia; Jonathan Dan; Jose A. Miranda; Giovanni Ansaloni; David Atienza
- Reference count: 40
- Primary result: 21% F1 score improvement over baseline with only 6.46 minutes of labeled data per patient

## Executive Summary
This paper addresses the critical challenge of personalized seizure detection using deep learning while minimizing computational and labeling costs. The proposed EpiSMART framework uses continual learning to incrementally adapt to individual patient EEG patterns, requiring minimal expert annotation while maintaining performance. The method balances the need for personalization with practical deployment constraints in wearable healthcare systems through intelligent sample selection and knowledge preservation.

## Method Summary
EpiSMART employs a continual learning framework that incrementally adapts a seizure detection model to individual patients using a size-constrained replay buffer. The system selects informative samples based on entropy and predicted seizure labels, requiring minimal expert annotation while preserving knowledge of previously seen patients. The framework processes incoming EEG data in real-time, making selective updates to the model that balance personalization needs with computational efficiency. This approach enables effective personalization while maintaining computational efficiency suitable for wearable devices.

## Key Results
- Achieves 21% improvement in F1 score compared to baseline without updates
- Requires only 6.46 minutes of labeled data per patient on average
- Maintains computational efficiency with 6.28 updates per day on average

## Why This Works (Mechanism)
EpiSMART works by combining continual learning principles with intelligent sample selection. The system maintains a replay buffer that stores representative samples from previously seen patients, preventing catastrophic forgetting when adapting to new patients. Entropy-based sample selection identifies the most informative data points for labeling and model updates, minimizing the need for extensive expert annotation. The incremental update mechanism allows the model to continuously improve its performance on individual patients while preserving generalization capabilities across the patient population.

## Foundational Learning
- Continual Learning: Why needed - Prevents catastrophic forgetting when adapting to new patients; Quick check - Verify model maintains performance on previous patients after updates
- Entropy-based Sample Selection: Why needed - Identifies most informative samples for labeling; Quick check - Confirm selected samples have high uncertainty and diverse label distribution
- Replay Buffer Management: Why needed - Preserves knowledge of previously seen patients; Quick check - Ensure buffer contains representative samples from all encountered patients
- Real-time EEG Processing: Why needed - Enables continuous monitoring in wearable devices; Quick check - Validate latency remains within acceptable bounds for clinical use

## Architecture Onboarding

Component Map: Raw EEG -> Feature Extraction -> Continual Learning Module -> Model Updates -> Personalized Model

Critical Path: Incoming EEG data → Feature extraction → Entropy calculation → Sample selection → Expert labeling (minimal) → Model update → Personalized model output

Design Tradeoffs:
- Buffer size vs. computational efficiency: Larger buffers preserve more knowledge but increase memory usage
- Update frequency vs. battery life: More frequent updates improve personalization but consume more power
- Sample selection criteria: Entropy vs. label uncertainty affects which samples require expert attention

Failure Signatures:
- Performance degradation on previously seen patients indicates catastrophic forgetting
- High entropy on most samples suggests model uncertainty and need for more training data
- Excessive update frequency may indicate poor initial model generalization

First Experiments:
1. Test baseline performance without continual learning updates
2. Evaluate catastrophic forgetting by testing on previous patients after multiple updates
3. Assess sample selection quality by comparing entropy scores across different data segments

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation on single dataset (CHB-MIT) may not generalize to diverse real-world settings
- No validation on actual edge hardware to confirm computational efficiency claims
- Potential catastrophic forgetting in long-term deployment not fully characterized

## Confidence
High confidence in F1 score improvement claims (21% over baseline)
Medium confidence in computational efficiency claims (6.28 updates/day, 6.46 minutes labeled data)
Low confidence in real-world deployment feasibility due to limited hardware validation

## Next Checks
1. Evaluate EpiSMART on multiple independent EEG datasets with varying recording conditions and patient demographics
2. Deploy the method on actual edge hardware (e.g., Raspberry Pi, wearable development boards) to validate computational efficiency and measure real-world power consumption
3. Conduct a longitudinal study simulating months of continuous operation to assess catastrophic forgetting and buffer management effectiveness over extended deployment periods