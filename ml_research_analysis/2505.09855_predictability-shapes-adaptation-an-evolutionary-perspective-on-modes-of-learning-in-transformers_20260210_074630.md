---
ver: rpa2
title: 'Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of
  Learning in Transformers'
arxiv_id: '2505.09855'
source_url: https://arxiv.org/abs/2505.09855
tags:
- stability
- learning
- environmental
- task
- reliability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper applies concepts from evolutionary biology to understand
  how Transformer models balance in-weights learning (IWL) and in-context learning
  (ICL). Inspired by the biological trade-off between genetically encoded traits and
  phenotypic plasticity, the authors manipulate two dimensions of environmental predictability
  in synthetic tasks: cue reliability (the clarity of information in a single prompt)
  and environmental stability (the consistency of task structure across training batches).'
---

# Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers

## Quick Facts
- arXiv ID: 2505.09855
- Source URL: https://arxiv.org/abs/2505.09855
- Reference count: 40
- Primary result: Predictability (cue reliability and environmental stability) shapes learning strategy choice between in-weights learning and in-context learning in Transformers

## Executive Summary
This paper introduces an evolutionary biology-inspired framework to understand how Transformer models adapt their learning strategies based on environmental predictability. Drawing parallels between genetically encoded traits and phenotypic plasticity in biology, the authors systematically manipulate two dimensions of predictability—cue reliability (clarity of information in a single prompt) and environmental stability (consistency of task structure across training batches)—in synthetic tasks. They demonstrate that high environmental stability strongly favors in-weights learning (IWL) while high cue reliability enhances in-context learning (ICL), particularly when stability is low. The study reveals task-dependent learning dynamics, including transient ICL-to-IWL and IWL-to-ICL transitions, which they explain through a relative-cost hypothesis about computational ease of strategy acquisition.

## Method Summary
The authors create a synthetic experimental framework where they manipulate environmental predictability through two orthogonal dimensions: cue reliability (the informativeness of individual prompts) and environmental stability (the consistency of task structure across training batches). They test these manipulations across sinusoid regression and Omniglot classification tasks, systematically varying predictability conditions. Learning outcomes are measured by comparing performance between frozen-weight (ICL-only) and fine-tuned (IWL-only) models, as well as models trained without intervention. The framework draws inspiration from evolutionary biology's concepts of genetic assimilation and phenotypic plasticity, applying these principles to understand adaptive learning in neural networks.

## Key Results
- High environmental stability strongly correlates with preference for in-weights learning (IWL)
- High cue reliability enhances in-context learning (ICL) performance, especially under low stability conditions
- Learning dynamics show task-dependent transience with ICL-to-IWL and IWL-to-ICL transitions
- A relative-cost hypothesis explains strategy transitions based on computational ease of acquisition

## Why This Works (Mechanism)
The evolutionary framework works because it captures fundamental trade-offs in adaptive systems between genetically encoded (IWL) and environmentally responsive (ICL) strategies. When environments are stable, investing in fixed, reliable representations through IWL is advantageous, similar to how stable biological environments favor genetic encoding of beneficial traits. When environments are variable but cues are reliable, flexible ICL strategies allow rapid adaptation without costly retraining. The relative-cost hypothesis explains transitions as emergent from the computational complexity of acquiring each strategy, with models initially adopting whichever approach is easier to learn before potentially switching based on task demands.

## Foundational Learning
- Environmental predictability trade-offs: Understanding how organisms balance fixed vs. flexible responses to environmental conditions (why needed: provides theoretical foundation for learning strategy selection; quick check: review evolutionary biology literature on phenotypic plasticity)
- Transformer learning mechanisms: Knowledge of how Transformers implement both weight-based and prompt-based adaptation (why needed: essential for interpreting results in neural network context; quick check: verify understanding of attention mechanisms and weight updates)
- Synthetic task design: Ability to create controlled environments with precise predictability parameters (why needed: enables systematic investigation of learning strategy trade-offs; quick check: confirm task parameters can be independently manipulated)

## Architecture Onboarding
- Component map: Task generator -> Transformer model -> Predictability manipulation -> Learning strategy assessment
- Critical path: Predictability parameters → Model training → Performance evaluation → Strategy identification
- Design tradeoffs: Synthetic vs. naturalistic tasks (control vs. realism), frozen vs. fine-tuned architectures (isolation vs. integration of learning modes)
- Failure signatures: Inability to distinguish IWL from ICL strategies, inconsistent predictability parameter effects across tasks
- First experiments: 1) Verify predictability parameters can be independently manipulated in both task domains, 2) Confirm baseline performance differences between frozen and fine-tuned models, 3) Test relative-cost hypothesis with simplified computational models

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Synthetic tasks may not capture complexity of real-world learning scenarios encountered by large language models
- Two-dimensional predictability framework is a simplification of multifaceted environmental factors
- Distinction between IWL and ICL relies on architectural interventions that may not reflect full strategy spectrum
- Learning dynamics analysis lacks mechanistic explanations for transient vs. persistent ICL behavior
- Relative-cost hypothesis remains qualitative without quantitative cost modeling

## Confidence
- High confidence: Empirical observation that environmental stability correlates with IWL preference and cue reliability enhances ICL performance
- Medium confidence: Generalizability of predictability framework to more complex tasks
- Medium confidence: Relative-cost hypothesis as explanatory mechanism for ICL-to-IWL transitions
- Low confidence: Complete separation of IWL and ICL as distinct strategies within transformer architectures

## Next Checks
1. Test the predictability framework on more naturalistic language and vision tasks with varying complexity and ambiguity
2. Conduct ablation studies varying model depth, attention mechanisms, and training regimes to determine architecture-dependent learning strategy trade-offs
3. Implement quantitative analysis of computational costs associated with IWL versus ICL acquisition to empirically validate the relative-cost hypothesis