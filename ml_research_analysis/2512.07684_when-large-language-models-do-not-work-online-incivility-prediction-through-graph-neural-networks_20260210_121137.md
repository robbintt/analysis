---
ver: rpa2
title: 'When Large Language Models Do Not Work: Online Incivility Prediction through
  Graph Neural Networks'
arxiv_id: '2512.07684'
source_url: https://arxiv.org/abs/2512.07684
tags:
- online
- graph
- comments
- incivility
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses online incivility detection using graph neural
  networks, proposing a novel approach that represents user comments as nodes connected
  by text-based similarity edges. The model employs a hybrid architecture combining
  graph neural networks with multi-layer perceptrons, using dynamic attention to balance
  textual and structural information.
---

# When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks

## Quick Facts
- arXiv ID: 2512.07684
- Source URL: https://arxiv.org/abs/2512.07684
- Authors: Zihan Chen; Lanyu Yu
- Reference count: 32
- This paper proposes a GNN-based approach that outperforms twelve state-of-the-art LLMs on Wikipedia incivility detection while requiring significantly lower computational cost

## Executive Summary
This paper addresses online incivility detection by proposing a graph neural network approach that captures relational context among user comments. Unlike traditional text-only methods or large language models, the proposed architecture represents comments as nodes connected by text-based similarity edges, enabling the model to leverage both textual content and structural relationships. The hybrid GNN-MLP architecture employs dynamic attention mechanisms to balance textual and structural information, achieving superior performance on the Wikipedia Detox dataset across three incivility dimensions (toxicity, aggression, and personal attacks) while maintaining computational efficiency.

## Method Summary
The proposed method constructs a graph where user comments serve as nodes, connected by edges based on text-based similarity measures. A hybrid architecture combines graph neural networks with multi-layer perceptrons, using dynamic attention mechanisms to integrate textual features extracted from comments with structural information from the graph topology. The model processes comment content through NLP modules while simultaneously learning from the relational patterns encoded in the graph structure. This dual approach allows the system to capture both individual comment characteristics and contextual relationships between comments, enabling more accurate detection of incivil content across multiple dimensions including toxicity, aggression, and personal attacks.

## Key Results
- Achieves AUC scores of 0.957 for personal attacks, 0.962 for aggression, and 0.970 for toxicity detection
- Outperforms twelve state-of-the-art large language models across multiple evaluation metrics
- Demonstrates significantly lower computational cost compared to LLM-based approaches while maintaining superior accuracy

## Why This Works (Mechanism)
The model works by leveraging graph neural networks to capture relational context between comments that text-only approaches miss. By representing comments as interconnected nodes, the architecture can learn from patterns of similarity and interaction that often correlate with incivility. The dynamic attention mechanism allows the model to adaptively weigh textual versus structural information depending on the specific context, making it more flexible than static approaches. This combination enables detection of subtle incivility patterns that emerge from the relationships between comments rather than just their individual content.

## Foundational Learning
- **Graph Neural Networks (GNNs)**: Why needed - to capture relational patterns between comments; Quick check - can the model learn from node connections, not just node features
- **Dynamic Attention Mechanisms**: Why needed - to adaptively balance textual and structural information; Quick check - does attention weight distribution change meaningfully across different comment contexts
- **Text-based Similarity Metrics**: Why needed - to construct meaningful edges between comment nodes; Quick check - does cosine similarity effectively capture semantic relationships relevant to incivility
- **Multi-task Learning Framework**: Why needed - to detect multiple incivility dimensions simultaneously; Quick check - can the model distinguish between toxicity, aggression, and personal attacks
- **Hybrid GNN-MLP Architecture**: Why needed - to combine structural learning with traditional feature extraction; Quick check - does the combination improve performance over either approach alone
- **Wikipedia Detox Dataset**: Why needed - provides labeled examples of online incivility; Quick check - is the dataset representative of broader online discourse patterns

## Architecture Onboarding

**Component Map**
Text Embedding Layer -> GNN Layers -> MLP Classifier -> Attention Mechanism -> Output Layer

**Critical Path**
The critical path flows from text embedding through GNN layers for structural learning, then through MLP for classification, with the attention mechanism integrating both information streams before final output prediction.

**Design Tradeoffs**
- **Graph Construction**: Text-based similarity edges are computationally efficient but may miss nuanced relationships that temporal or user-based edges could capture
- **Hybrid Architecture**: Combines strengths of GNNs and MLPs but adds complexity and potential training instability
- **Dynamic Attention**: Adapts to context but requires careful tuning to prevent overfitting to specific patterns
- **Computational Efficiency**: Lower than LLMs but still requires graph processing overhead compared to simple text classifiers

**Failure Signatures**
- Poor performance on platforms with different interaction patterns than Wikipedia
- Degradation when text similarity doesn't reflect meaningful relationships
- Over-reliance on structural patterns may miss isolated but highly incivil comments
- Attention mechanisms may fail to adapt appropriately to new discourse contexts

**First Experiments**
1. Ablation study: Test GNN-only, MLP-only, and hybrid performance to validate architectural contributions
2. Edge construction comparison: Evaluate different similarity metrics (cosine, Jaccard, learned embeddings) for graph construction
3. Cross-platform validation: Test model performance on Reddit or Twitter data to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- The model's effectiveness on Wikipedia data requires validation on other platforms with different communication patterns and moderation policies
- The text-based similarity approach may not capture the full complexity of user interactions, potentially missing important contextual factors
- Computational efficiency claims lack detailed benchmarking methodology for independent verification

## Confidence
- High confidence in model outperforming tested LLMs on Wikipedia data
- Medium confidence in generalizability to other platforms without additional validation
- Medium confidence in computational efficiency claims pending more transparent benchmarking

## Next Checks
1. Cross-platform validation: Test the model on multiple online platforms (Reddit, Twitter, YouTube) to assess generalizability across different discourse environments and moderation policies
2. Temporal robustness evaluation: Assess model performance across different time periods and emerging linguistic trends to ensure sustained effectiveness as online language evolves
3. Edge quality analysis: Conduct ablation studies comparing different edge construction methods (semantic similarity vs. temporal proximity vs. user interaction patterns) to optimize graph structure for incivility detection