---
ver: rpa2
title: 'Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs'
arxiv_id: '2504.19019'
source_url: https://arxiv.org/abs/2504.19019
tags:
- prompt
- security
- virus
- measures
- software
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Graph of Attacks (GoAT), a black-box jailbreaking
  method for Large Language Models (LLMs) that leverages a graph-based reasoning framework
  to generate adversarial prompts. Unlike prior methods constrained by linear or tree-based
  reasoning, GoAT enables collaborative exploration of reasoning paths through a graph
  structure, allowing information sharing across multiple attack strategies.
---

# Graph of Attacks: Improved Black-Box and Interpretable Jailbreaks for LLMs

## Quick Facts
- arXiv ID: 2504.19019
- Source URL: https://arxiv.org/abs/2504.19019
- Reference count: 27
- One-line primary result: Graph-based black-box jailbreak method achieves up to 5x higher success rate against robust LLMs compared to state-of-the-art approaches

## Executive Summary
This paper introduces Graph of Attacks (GoAT), a novel black-box jailbreaking framework that overcomes the limitations of prior linear and tree-based reasoning methods. GoAT represents reasoning paths as a graph structure, enabling collaborative exploration and information sharing across multiple attack strategies. The method achieves significantly higher success rates against robust models like Llama while maintaining human-readable prompts and requiring no model access. GoAT demonstrates particular effectiveness against strong closed-source models such as GPT-4 and Claude, outperforming baselines in both success rates and query efficiency.

## Method Summary
Graph of Attacks (GoAT) introduces a graph-based reasoning framework for black-box jailbreaking that enables collaborative exploration of attack strategies. Unlike previous methods constrained to linear or tree-based reasoning paths, GoAT represents attack strategies as nodes in a graph where information can be shared across different reasoning paths. The method generates adversarial prompts through iterative graph traversal, where successful attack patterns inform subsequent attempts. This collaborative approach allows the system to leverage successful strategies across multiple attack vectors simultaneously, significantly improving jailbreak success rates while maintaining interpretability of generated prompts.

## Key Results
- Achieves up to 5x higher success rates against robust Llama models compared to state-of-the-art methods
- Outperforms baselines like TAP and PAIR in both success rates and query efficiency
- Maintains human-readable prompts while successfully jailbreaking strong closed-source models including GPT-4 and Claude

## Why This Works (Mechanism)
GoAT's effectiveness stems from its graph-based collaborative reasoning framework that overcomes the fundamental limitation of prior approaches - the inability to share information across different reasoning paths. By representing attack strategies as a graph structure, GoAT enables successful attack patterns to inform and enhance subsequent attempts across the entire reasoning space. This collaborative information sharing allows the system to efficiently explore the attack space while building on successful strategies, rather than treating each attack attempt in isolation. The graph structure also maintains interpretability, producing human-readable prompts that can be analyzed and understood.

## Foundational Learning

**Graph-based reasoning**: Why needed - Enables collaborative information sharing across attack strategies. Quick check - Verify graph connectivity and path diversity.

**Black-box adversarial prompting**: Why needed - Allows jailbreaking without model access or parameter information. Quick check - Confirm prompt effectiveness against different model variants.

**Collaborative exploration**: Why needed - Leverages successful strategies across multiple attack vectors. Quick check - Measure information transfer between successful and unsuccessful paths.

**Human-readable jailbreaks**: Why needed - Maintains interpretability for analysis and deployment. Quick check - Verify prompt coherence and natural language quality.

## Architecture Onboarding

Component map: Input prompt -> Graph node creation -> Collaborative reasoning -> Adversarial prompt generation -> Output

Critical path: The core reasoning loop where successful attack patterns are identified, shared across the graph structure, and used to inform subsequent attack attempts.

Design tradeoffs: GoAT prioritizes collaborative information sharing and interpretability over the raw attack power of more opaque methods. This results in human-readable prompts at the cost of potentially more complex graph management overhead.

Failure signatures: Poor graph connectivity leading to isolated reasoning paths, insufficient information sharing between successful and unsuccessful attempts, or prompts that become too complex to remain interpretable.

First experiments:
1. Baseline comparison: Measure success rates against TAP and PAIR on Llama models
2. Graph connectivity analysis: Evaluate information sharing efficiency across reasoning paths
3. Interpretability assessment: Analyze prompt readability and coherence scores

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, focusing instead on demonstrating the effectiveness of the GoAT approach.

## Limitations
- May require more computational resources due to graph management overhead
- Performance may vary across different task domains and model architectures
- Success depends on maintaining effective information sharing across the graph structure

## Confidence

| Claim | Confidence |
|-------|------------|
| 5x improvement over state-of-the-art | High |
| Human-readable prompt generation | High |
| Effective against closed-source models | Medium |

## Next Checks

1. Validate graph connectivity metrics across different reasoning path complexities
2. Benchmark query efficiency against additional black-box jailbreaking methods
3. Test transferability of successful attack patterns to different model families and domains