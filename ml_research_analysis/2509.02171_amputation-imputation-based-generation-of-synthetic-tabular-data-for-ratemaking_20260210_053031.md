---
ver: rpa2
title: Amputation-imputation based generation of synthetic tabular data for ratemaking
arxiv_id: '2509.02171'
source_url: https://arxiv.org/abs/2509.02171
tags:
- data
- synthetic
- variables
- mice
- variable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating high-quality synthetic
  actuarial data for ratemaking when access to real data is limited due to privacy
  concerns or cost. The authors propose amputation-imputation methods based on Multiple
  Imputation by Chained Equations (MICE) with Random Forests (RFs) as imputation models.
---

# Amputation-imputation based generation of synthetic tabular data for ratemaking

## Quick Facts
- **arXiv ID:** 2509.02171
- **Source URL:** https://arxiv.org/abs/2509.02171
- **Reference count:** 11
- **Primary result:** MICE with Random Forests achieves competitive performance in preserving marginal distributions and multivariate relationships for synthetic actuarial data generation, with superior ease of use compared to deep generative models

## Executive Summary
This paper addresses the challenge of generating high-quality synthetic actuarial data for ratemaking when access to real data is limited due to privacy concerns or cost. The authors propose amputation-imputation methods based on Multiple Imputation by Chained Equations (MICE) with Random Forests (RFs) as imputation models. They compare these MICE-based approaches against other generative models like Variational Autoencoders (VAEs) and Conditional Tabular GANs (CTGANs) using the freMTPL2freq dataset. The primary results show that MICE-based methods, particularly MICE with RFs, achieve competitive performance in preserving marginal distributions and multivariate relationships among covariates while demonstrating superior ease of use compared to deep generative models.

## Method Summary
The authors propose an amputation-imputation approach where they create synthetic data by duplicating training data, amputating 75% of cell values in the duplicate, and then using MICE with Random Forest imputations to fill in the missing values. The synthetic dataset consists of the previously amputated rows after imputation. This approach is compared against CTGAN and VAE models using the freMTPL2freq dataset. The evaluation framework assesses preservation of marginal distributions, multivariate relationships, and consistency with Generalized Linear Models (GLMs) through metrics including coefficient distance, variable selection accuracy, Poisson deviance, and distribution similarity measures.

## Key Results
- MICE with Random Forests achieves competitive performance in preserving marginal distributions and multivariate relationships among covariates
- MICE approach demonstrates superior ease of use compared to deep generative models and shows better performance in capturing univariate distributions of numeric variables
- While no method outperforms training data, MICE and CTGAN show the most balanced performance across evaluation metrics
- Augmenting original data with synthetic data does not generally improve GLM performance for predicting claim counts, with only one exception observed where a small proportion of synthetic data slightly improved coefficient estimation

## Why This Works (Mechanism)
The amputation-imputation approach works by creating a controlled missing data problem that forces the imputation model to learn the joint distribution of the data. By amputating 75% of values, the MICE algorithm must leverage the relationships between variables to impute missing values, effectively learning the data distribution. Random Forests as the imputation model handle non-linear relationships and interactions well, which is crucial for capturing the complex relationships in actuarial data. The approach is particularly effective because it doesn't require training on the complete data distribution but instead learns through the imputation process.

## Foundational Learning
**MICE (Multiple Imputation by Chained Equations):** Iterative imputation method that models each variable conditional on others
- *Why needed:* Handles multivariate missing data while preserving relationships between variables
- *Quick check:* Verify convergence of imputation chains and reasonable distribution of imputed values

**Random Forest Imputation:** Uses ensemble of decision trees for each conditional imputation step
- *Why needed:* Captures non-linear relationships and interactions better than linear methods
- *Quick check:* Compare imputation quality with simpler methods like predictive mean matching

**Poisson GLM for Ratemaking:** Models count data with log-link function for insurance claim frequency
- *Why needed:* Standard approach for predicting claim counts in actuarial science
- *Quick check:* Verify dispersion parameter is close to 1 for overdispersion assessment

## Architecture Onboarding

**Component Map:** Training Data -> Amputation -> MICE-RF Imputation -> Synthetic Data -> GLM Training -> Evaluation Metrics

**Critical Path:** The amputation step is critical as it determines the quality of synthetic data. The 75% amputation rate creates sufficient missing data to force the MICE algorithm to learn the joint distribution, but may be dataset-specific.

**Design Tradeoffs:** The amputation-imputation approach trades computational efficiency for ease of use and interpretability. While deep generative models like CTGAN may capture more complex patterns, they require extensive hyperparameter tuning and lack interpretability compared to the transparent MICE-RF approach.

**Failure Signatures:** 
- Poor synthetic data quality when amputation rate is too high (>80%) or too low (<50%)
- Implausible values generated (e.g., driver age < 18) when business constraints aren't enforced
- Convergence issues in MICE when variables are highly correlated or sparse

**First Experiments:**
1. Test varying amputation rates (50%, 75%, 90%) to find optimal balance between synthetic data quantity and quality
2. Implement business rule constraints during imputation to prevent logically impossible values
3. Compare MICE-RF performance with different random forest hyperparameters (ntree, mtry)

## Open Questions the Paper Calls Out
None

## Limitations
- Random forest hyperparameters within the mice package are not documented, affecting reproducibility
- The specific number of discretization bins for distribution evaluation metrics is unclear
- The 75% amputation rate, while effective, creates an extreme data sparsity scenario that may not generalize to other datasets
- The finding that synthetic data augmentation rarely improves GLM performance requires further validation and may be dataset-specific

## Confidence

**High Confidence:**
- Core methodology of amputation-imputation using MICE-RF is clearly specified and reproducible
- Evaluation framework comparing marginal distributions, multivariate relationships, and GLM consistency is well-defined

**Medium Confidence:**
- Comparative performance results against CTGAN and VAE show MICE-RF as competitive
- Superior ease of use claim is supported but could benefit from more detailed user experience metrics

**Low Confidence:**
- Finding that synthetic data augmentation rarely improves GLM performance contradicts common expectations and may be dataset-specific

## Next Checks
1. Test MICE-RF with varying amputation rates (50%, 75%, 90%) to determine the optimal balance between synthetic data quantity and imputation quality
2. Implement business rule constraints during the imputation process to prevent generation of logically impossible values (e.g., driver age < 18)
3. Evaluate the impact of different random forest hyperparameters (ntree, mtry) on synthetic data quality and computational efficiency