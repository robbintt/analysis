---
ver: rpa2
title: 'PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation
  for Proactive Agents'
arxiv_id: '2602.01532'
source_url: https://arxiv.org/abs/2602.01532
tags:
- prism
- need
- cost
- slow
- decision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PRISM addresses the challenge of proactive AI agents that must
  decide when and whether to intervene without becoming intrusive. It formulates the
  problem as cost-sensitive selective intervention, coupling a decision-theoretic
  gate with a dual-process reasoning architecture.
---

# PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents

## Quick Facts
- arXiv ID: 2602.01532
- Source URL: https://arxiv.org/abs/2602.01532
- Reference count: 40
- Primary result: PRISM achieves 22.78% reduction in false alarms and 20.14% improvement in F1 on ProactiveBench by coupling cost-sensitive intervention gating with dual-process reasoning.

## Executive Summary
PRISM introduces a risk-sensitive, uncertainty-aware framework for proactive AI agents, addressing the challenge of deciding when to intervene without becoming intrusive. The approach formulates proactive assistance as cost-sensitive selective intervention, coupling a decision-theoretic gate with a dual-process reasoning architecture. The agent intervenes only when the calibrated acceptance probability exceeds a dynamic threshold derived from asymmetric costs of missed help and false alarms, concentrating slow reasoning near decision boundaries. Training uses gate-aligned distillation with explicit decoupling of the response policy from the intervention gate. On ProactiveBench, PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines, demonstrating precise, computationally efficient, and controllable proactive assistance.

## Method Summary
PRISM formulates proactive assistance as a cost-sensitive selective intervention problem, where the agent must decide when and whether to intervene. The method couples a risk-sensitive decision-theoretic gate with a dual-process reasoning architecture. The gate computes a dynamic threshold based on the ratio of costs for false alarms versus missed help, and the agent intervenes only when the calibrated acceptance probability exceeds this threshold. This concentrates slow reasoning on boundary cases, improving computational efficiency. Training uses gate-aligned distillation to decouple the intervention gate from the response policy, ensuring the gate generalizes beyond the training distribution. The approach is evaluated on ProactiveBench, demonstrating significant improvements in precision and false alarm reduction compared to strong baselines.

## Key Results
- PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines on ProactiveBench.
- The dual-process architecture concentrates slow reasoning near decision boundaries, improving computational efficiency.
- The risk-sensitive gate ensures interventions are made only when the cost-benefit tradeoff justifies action, minimizing intrusive assistance.

## Why This Works (Mechanism)
PRISM's effectiveness stems from its integration of cost-sensitive decision-making with uncertainty-aware dual-process reasoning. By explicitly modeling the asymmetric costs of false alarms and missed help, the gate policy dynamically adjusts intervention thresholds to minimize overall expected cost. The dual-process architecture leverages fast, low-cost inference for most decisions, reserving slow, high-accuracy reasoning only for ambiguous cases near the decision boundary. This design reduces computational overhead while maintaining high intervention accuracy. Gate-aligned distillation further ensures the intervention policy generalizes to unseen contexts by decoupling gate learning from response policy optimization.

## Foundational Learning
- **Cost-sensitive intervention**: Needed to balance false alarms against missed help in proactive assistance; quick check: compare FPR and recall across different cost ratios.
- **Uncertainty calibration**: Required for reliable gate decisions; quick check: calibration plots of predicted probabilities vs. empirical accuracy.
- **Dual-process reasoning**: Reduces computational cost by allocating slow reasoning only to ambiguous cases; quick check: measure inference time per sample across confidence bins.
- **Gate-aligned distillation**: Ensures gate policy generalizes by decoupling from response policy; quick check: validate gate performance on out-of-distribution inputs.

## Architecture Onboarding
**Component Map**: Input features → Uncertainty calibrator → Gate policy → (if intervene) Slow reasoning module → Response policy → Output
**Critical Path**: Uncertainty calibration → Gate threshold comparison → Conditional slow reasoning → Final response
**Design Tradeoffs**: Computational efficiency vs. accuracy (dual-process), intervention precision vs. recall (cost sensitivity), gate generalization vs. response optimality (distillation decoupling).
**Failure Signatures**: High false alarm rate (threshold too low), missed interventions (threshold too high), slow inference (inefficient boundary detection), poor generalization (overfitting gate to training distribution).
**First Experiments**: 1) Vary cost asymmetry ratio ω and measure impact on FPR and recall; 2) Ablate dual-process reasoning and compare inference time and accuracy; 3) Test gate policy on out-of-distribution samples to assess generalization.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation confined to ProactiveBench, limiting generalizability to other proactive agent domains.
- Cost sensitivity analysis relies on fixed, pre-specified asymmetry ratios that may not transfer to environments with different cost structures.
- Focus on single-turn proactive decisions may not capture the complexity of multi-turn or temporally extended interventions.

## Confidence
**High Confidence**: Formulation as cost-sensitive selective intervention; empirical gains on F1, false alarm reduction, and FPR on ProactiveBench; dual-process design reducing slow reasoning to boundary cases; gate-aligned distillation methodology.
**Medium Confidence**: Robustness of risk-sensitive threshold across diverse user contexts; long-term stability of distilled gate policy; practical computational savings in deployment scenarios.
**Low Confidence**: Performance in multi-turn or real-world settings beyond the benchmark; generalizability to tasks outside the evaluated proactive assistance scope; sensitivity to hyperparameter choices for cost asymmetry and uncertainty calibration.

## Next Checks
1. Evaluate PRISM on multi-turn proactive assistance tasks to assess temporal coherence and repeated intervention decisions.
2. Conduct a user study with real-time deployment to measure practical overhead and user experience impacts.
3. Perform ablation studies on cost sensitivity parameters and uncertainty calibration to determine robustness across varying application domains.