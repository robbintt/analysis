---
ver: rpa2
title: Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models,
  and Search-Based Retrieval Agents Improves Interpretable Claim Verification
arxiv_id: '2511.03217'
source_url: https://arxiv.org/abs/2511.03217
tags:
- evidence
- claim
- label
- language
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a hybrid fact-checking system that combines
  knowledge graphs, large language models, and web search retrieval to improve interpretable
  claim verification. The approach uses a KG-first strategy for rapid structured lookups,
  followed by LLM-based classification and web search fallback for NEI cases.
---

# Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification

## Quick Facts
- arXiv ID: 2511.03217
- Source URL: https://arxiv.org/abs/2511.03217
- Reference count: 32
- Key outcome: Hybrid system combining KGs, LLMs, and web search achieves 0.93 F1 on FEVER supported/refuted claims with improved interpretability

## Executive Summary
This paper presents a hybrid fact-checking system that combines knowledge graphs, large language models, and web search retrieval to improve interpretable claim verification. The approach uses a KG-first strategy for rapid structured lookups, followed by LLM-based classification and web search fallback for NEI cases. The modular pipeline achieves 0.93 F1 on FEVER's supported/refuted split without task-specific fine-tuning and generalizes well to other datasets. A reannotation study shows the system uncovers valid evidence for over 70% of claims originally labeled NEI, demonstrating improved coverage and interpretability through structured and unstructured evidence integration.

## Method Summary
The proposed hybrid fact-checking system operates through a three-stage pipeline. First, it performs rapid structured lookups against a knowledge graph to identify supporting evidence. If KG evidence is insufficient, the system employs an LLM-based classification module to assess claim veracity. For cases where neither KG nor LLM can provide definitive answers (NEI cases), a web search retrieval agent is activated to gather additional context. The system maintains interpretability by preserving evidence provenance throughout the pipeline, allowing users to trace verification decisions back to specific knowledge sources. Notably, the approach achieves strong performance without requiring task-specific fine-tuning of the LLM components.

## Key Results
- Achieves 0.93 F1 score on FEVER supported/refuted split without task-specific fine-tuning
- Identifies valid evidence for 70% of claims originally labeled NEI in reannotation study
- Demonstrates generalization across multiple fact-checking datasets including FEVER, SciFact, and ClimateFEVER

## Why This Works (Mechanism)
The hybrid approach leverages complementary strengths of different verification methods. Knowledge graphs provide fast, structured evidence retrieval with high precision for well-represented facts. LLMs offer flexible reasoning capabilities and can handle claims requiring inference or contextual understanding. Web search retrieval agents can access up-to-date information and handle claims about recent events not yet in KGs. The KG-first strategy minimizes computational costs while maintaining accuracy, only invoking more expensive LLM and search components when necessary. The system's interpretability stems from maintaining evidence provenance throughout the pipeline, enabling transparent verification traces.

## Foundational Learning
- **Knowledge Graph Querying**: Understanding how to efficiently retrieve structured facts from KGs is essential for the KG-first approach. Quick check: Can you formulate SPARQL queries for simple fact retrieval?
- **LLM Classification Principles**: Familiarity with how LLMs can be used for classification tasks without fine-tuning is crucial. Quick check: Can you explain zero-shot classification with LLMs?
- **Web Search Retrieval**: Understanding how search agents can gather evidence for claims requires knowledge of search APIs and result processing. Quick check: Can you design a simple search agent pipeline?
- **Hybrid System Design**: The ability to integrate multiple verification methods requires understanding system orchestration and evidence fusion. Quick check: Can you describe how to combine structured and unstructured evidence?
- **Interpretability in AI Systems**: Understanding techniques for maintaining transparency in AI verification systems is important for the interpretability claims. Quick check: Can you list three methods for providing interpretable AI decisions?
- **Fact-Checking Dataset Characteristics**: Knowledge of common fact-checking datasets like FEVER and their evaluation metrics is necessary. Quick check: Can you explain the FEVER dataset's claim-evidence pairs?

## Architecture Onboarding

**Component Map**: KG Lookup -> LLM Classification -> Web Search Retrieval

**Critical Path**: Claims enter the KG-first module; if insufficient evidence found, proceed to LLM classification; if still uncertain, activate web search agent. The KG-first strategy optimizes for speed and cost by using the cheapest method first.

**Design Tradeoffs**: The system prioritizes interpretability and structured evidence over pure accuracy. The KG-first approach sacrifices some recall for faster processing and clearer evidence provenance. The decision to avoid task-specific fine-tuning reduces development overhead but may limit maximum performance on specialized domains.

**Failure Signatures**: 
- KG lookup failures occur when facts are not well-represented in the knowledge graph
- LLM classification may struggle with ambiguous or context-dependent claims
- Web search retrieval can fail on recent events with limited online coverage
- The system may struggle with claims requiring domain expertise not captured in any evidence source

**First Experiments**:
1. Test KG lookup accuracy on a subset of FEVER claims to establish baseline performance
2. Evaluate LLM zero-shot classification performance on simple supported/refuted claims
3. Assess web search retrieval quality for NEI cases by measuring evidence relevance and coverage

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Potential overfitting to FEVER dataset's specific claim structure and evidence patterns
- Lack of comparison against state-of-the-art hybrid fact-checking systems
- Unaddressed computational costs and latency of the multi-stage pipeline

## Confidence
- Technical soundness: Medium-High - The modular architecture is well-designed but lacks comprehensive baseline comparisons
- Empirical results: Medium - Strong FEVER performance but limited cross-dataset validation
- Generalization claims: Medium - Demonstrated on three datasets but scope remains limited
- Interpretability claims: Medium - Supported by evidence provenance but lacks user studies

## Next Checks
1. Conduct ablation studies comparing the KG-first, LLM, and web search components individually against the full hybrid system to quantify each component's contribution
2. Perform cross-dataset validation on fact-checking benchmarks from different domains (e.g., political claims, health misinformation) to assess true generalization
3. Implement a user study evaluating the interpretability and trustworthiness of the system's evidence presentation compared to baseline approaches