---
ver: rpa2
title: 'AskNearby: An LLM-Based Application for Neighborhood Information Retrieval
  and Personalized Cognitive-Map Recommendations'
arxiv_id: '2512.02502'
source_url: https://arxiv.org/abs/2512.02502
tags:
- information
- retrieval
- local
- spatial
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AskNearby, an AI-driven system designed to
  address the Local Life Information Accessibility (LLIA) problem in the context of
  15-minute cities. LLIA focuses on enabling residents to efficiently access timely,
  context-aware local information at the neighborhood scale through both active retrieval
  and passive recommendation.
---

# AskNearby: An LLM-Based Application for Neighborhood Information Retrieval and Personalized Cognitive-Map Recommendations

## Quick Facts
- arXiv ID: 2512.02502
- Source URL: https://arxiv.org/abs/2512.02502
- Reference count: 40
- Outperforms baselines in retrieval accuracy, spatial-temporal relevance, and hallucination reduction for local neighborhood information

## Executive Summary
AskNearby is an AI-driven system designed to address the Local Life Information Accessibility (LLIA) problem by enabling efficient access to timely, context-aware local information at the neighborhood scale. The system combines a three-layer Retrieval-Augmented Generation (RAG) pipeline with a cognitive map model that captures individual spatial preferences. Evaluations on real-world RedNote data from Shenzhen demonstrate significant improvements over LLM-based baselines and existing local service platforms in retrieval accuracy, spatial-temporal relevance, and hallucination reduction, while also excelling in personalized recommendations and community engagement.

## Method Summary
AskNearby integrates a three-layer RAG pipeline—geographic, graph-based, and semantic-vector retrieval—with a TF-IWF-based cognitive map model for personalized recommendations. The system uses PostGIS for geographic filtering, NebulaGraph for semantic relationship expansion, and pgvector with bge-large-zh-v1.5 embeddings for semantic ranking. User preferences are captured through TF-IWF weighting of place attributes over time, combined with distance decay and public familiarity scoring. The architecture processes both active queries and passive recommendations, with evaluations showing superior performance in retrieval accuracy, hallucination reduction, and personalized recommendation quality compared to baselines.

## Key Results
- Outperforms LLM baselines (GPT-4o, DeepSeek-R1) in retrieval accuracy (Precision@4: 75.6% vs. best baseline 78.3%; NDCG@4: 0.96)
- Achieves 83.8% spatial-temporal relevance vs. 58.7% without GeoRAG
- Reduces hallucination to 2.5% vs. up to 15.8% in baselines
- Delivers high-quality personalized recommendations with Hit@5 of 0.612 and MRR of 0.421

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-layer retrieval (GraphRAG + VectorRAG + GeoRAG) improves local information relevance over single-modality retrieval.
- Mechanism: Each layer constrains the search space differently—GeoRAG enforces geographic bounds, GraphRAG expands semantic relationships via graph traversal, VectorRAG refines via dense embedding similarity. The layers compose sequentially: geographic candidates → graph-expanded semantics → vector-ranked results.
- Core assumption: User queries contain separable spatial, relational, and semantic signals that benefit from independent processing before fusion.
- Evidence anchors:
  - Table 2 shows full three-layer RAG achieves 83.8% STR vs. 58.7% without GeoRAG; hallucination rises from 2.5% to 4.5% when GraphRAG removed.
  - "three-layer Retrieval-Augmented Generation (RAG) pipeline—combining graph-based, semantic-vector, and geographic retrieval"
  - Related work (PersonaAI, arXiv:2503.15489) demonstrates RAG + personalization gains but lacks geographic layering.
- Break condition: If query lacks geographic intent (e.g., abstract questions), GeoRAG provides no signal; if knowledge graph is sparse for domain, GraphRAG returns empty expansions.

### Mechanism 2
- Claim: TF-IWF-based cognitive map captures time-varying functional semantics for personalized neighborhood recommendations.
- Mechanism: TF-IWF weights place attributes by local frequency within time windows, inversely by global frequency—capturing that a location is "dining-heavy" at evening but "office-heavy" at midday. User profile aggregates TF-IWF vectors from frequently visited places, compared via inner product to candidate items.
- Core assumption: User's past visited places reveal stable cognitive preferences that generalize to new recommendations within the same time context.
- Evidence anchors:
  - Equation (7) defines TF-IWF; Equation (6) shows multiplicative scoring combining semantic relevance, spatial proximity, and public familiarity.
  - Table 3 shows S + P + Sem achieves best Hit@5 (0.612) and MRR (0.421) vs. spatial-only baseline (0.542, 0.357).
  - Weak corpus support—no directly comparable TF-IWF spatial cognition models in neighbors; most use collaborative filtering or embedding-based personalization.
- Break condition: If user has insufficient visit history (cold-start), profile vector is sparse; if time window too narrow, TF-IWF estimates become noisy.

### Mechanism 3
- Claim: Geographic grounding via GeoRAG + PostGIS reduces hallucination by constraining LLM outputs to verified spatial entities.
- Mechanism: GeoRAG filters candidates to those within distance threshold θ (e.g., 1km) from user location using spatial database queries. Retrieved candidates are injected into LLM context, anchoring generation to real places rather than inferred fabrications.
- Core assumption: Knowledge base contains accurate, up-to-date POI coordinates and metadata; hallucination primarily arises from unconstrained generation, not from stale geodata.
- Evidence anchors:
  - "hallucination reduction (2.5% vs. up to 15.8%)"
  - Equation (3) formalizes distance filtering; Figure 4 shows baseline LLM fabricates non-existent address while AskNearby returns verified location with contact details.
  - Neighborhood Disparities paper (arXiv:2501.04363) highlights spatial data quality and adoption gaps in smart city services—relevant to data freshness assumption.
- Break condition: If knowledge base lacks coverage for queried area, GeoRAG returns empty set; if user location is spoofed or inaccurate, filtering returns irrelevant results.

## Foundational Learning

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: AskNearby's core architecture; you must understand how retrieved context is injected into LLM prompts to reason about hallucination reduction and ranking.
  - Quick check question: Given a user query "late-night pharmacy nearby," what three retrieval signals would each RAG layer contribute?

- Concept: **Spatial databases and distance metrics**
  - Why needed here: GeoRAG uses PostGIS with haversine distance for proximity filtering; understanding spatial indexing and distance thresholds is critical for tuning θ.
  - Quick check question: Why might haversine distance underestimate actual walk time in a dense urban grid?

- Concept: **Term Frequency–Inverse Document Frequency variants (TF-IDF, TF-IWF)**
  - Why needed here: Cognitive map semantic relevance uses TF-IWF to weight time-varying place attributes; you need to interpret how "local distinctiveness" is computed.
  - Quick check question: If a coffee shop is the only café in a residential zone but one of fifty in a commercial district, how does TF-IWF differentiate its semantic weight?

## Architecture Onboarding

- Component map:
  User Query → LLM Intent Extraction → [GeoRAG (PostGIS) + GraphRAG (NebulaGraph)] → VectorRAG (pgvector + bge-large-zh-v1.5) → Candidate Set → Cognitive Map Scoring → Ranked Results → LLM Generation
  Separate passive recommendation path: User context (s_u, t_u, p_u) → TF-IWF profile → Multiplicative scoring → Top-K recommendations.

- Critical path:
  1. Query parsing must extract spatial entities (via LLM) before GeoRAG can filter; failure here cascades to empty retrieval.
  2. GraphRAG expansion must return non-empty semantic neighbors; sparse graph = weak signal to VectorRAG.
  3. VectorRAG embedding quality (bge-large-zh-v1.5) determines final ranking; mismatched embeddings = semantic drift.

- Design tradeoffs:
  - Distance threshold θ: Larger values increase recall but reduce neighborhood specificity; paper uses 1km but does not tune per context.
  - Weights α, β, γ: Initialized equally at 1.0; optimal weighting unexplored—grid search could improve but adds complexity.
  - Single LLM (ChatGLM-4) vs. multi-model: Optimized for Chinese but may underperform on multilingual queries; no fallback documented.

- Failure signatures:
  - Empty retrieval: Query lacks extractable spatial entity + user location unavailable → GeoRAG returns nothing.
  - High hallucination despite RAG: Knowledge base stale or incomplete → LLM generates plausible but ungrounded details.
  - Poor recommendation diversity: Public familiarity term γ dominates → popular POIs crowd out personalized niche suggestions.

- First 3 experiments:
  1. **Ablation by query type**: Partition test queries into simple keyword (e.g., "Starbucks") vs. complex spatiotemporal (e.g., "quiet café for afternoon work"); measure precision gap to understand where AskNearby's semantic advantage is largest.
  2. **Distance threshold sensitivity**: Sweep θ from 0.5km to 3km; plot STR vs. recall to identify optimal neighborhood radius for different urban densities.
  3. **Cold-start user simulation**: Zero out p_u (frequently visited places) in cognitive map scoring; measure Hit@5 degradation to quantify personalization contribution vs. spatial + popularity baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the cognitive map model be enhanced with adaptive mechanisms to capture evolving individual user preferences and temporal shifts in spatial behavior patterns?
- Basis in paper: Authors state: "we aim to refine the core cognitive map model, focusing on more sophisticated, adaptive mechanisms to capture individual user nuances and their evolving preferences"
- Why unresolved: Current cognitive map model uses static TF-IWF representations and fixed weights (α=β=γ=1.0), which may not adequately model dynamic preference changes over time or individual variation in how users weight spatial vs. semantic factors
- What evidence would resolve it: Longitudinal user studies tracking preference drift; comparative experiments testing learned vs. fixed weighting schemes; adaptive models that show improved recommendation metrics over time

### Open Question 2
- Question: What is the optimal weighting strategy among semantic relevance, spatial proximity, and public familiarity in the recommendation scoring function?
- Basis in paper: Authors acknowledge: "a more optimal weight combination could potentially be found through grid search on the validation set, and we leave this for future work"
- Why unresolved: Equal weights (1.0) were assigned without empirical optimization; different urban contexts or user types may benefit from different weight configurations
- What evidence would resolve it: Grid search or Bayesian optimization experiments across validation sets; A/B testing with different weight configurations in deployed system; analysis of weight sensitivity across user segments

### Open Question 3
- Question: To what extent does AskNearby's performance generalize across diverse urban contexts, data sources, and cultural-linguistic settings beyond Shenzhen and Chinese-language content?
- Basis in paper: Authors state they will work on "diversifying data sources and geographical coverage beyond initial settings" and "conducting broader deployments to validate its effectiveness across diverse urban contexts"
- Why unresolved: Evaluation limited to single city (Shenzhen), single platform (RedNote), and Chinese language with ChatGLM-4; urban morphology, cultural factors, and data availability vary significantly across cities
- What evidence would resolve it: Multi-city deployment studies; cross-platform evaluation using alternative UGC sources; multilingual testing with local LLM variants; comparative performance metrics across urban density gradients

### Open Question 4
- Question: How does AskNearby perform for cold-start users with minimal spatial history, and what strategies can mitigate the cold-start problem in cognitive-map-based recommendation?
- Basis in paper: The cognitive map model relies on frequently visited places (p_u) to construct user profiles, but no evaluation or discussion addresses users without established spatial histories
- Why unresolved: TF-IWF-based semantic matching requires historical visitation data; new residents or occasional users may receive suboptimal recommendations without personalized cognitive profiles
- What evidence would resolve it: Controlled experiments with synthetic cold-start user profiles; ablation studies measuring performance degradation as p_u size decreases; comparison of fallback strategies (e.g., popularity-based, demographic-based) for cold-start scenarios

## Limitations
- Graph construction details unspecified (entity types, relation schema, edge definitions from knowledge base)
- Key hyperparameters (distance decay λ_d, similarity threshold δ, prompt templates) not reported
- Data provenance unclear (RedNote data collection methodology, user visit history acquisition)

## Confidence
- **High**: Retrieval accuracy improvements (Precision@4, NDCG@4) and hallucination reduction (2.5% vs. 15.8%) are well-supported by quantitative tables and ablation studies.
- **Medium**: Spatial-temporal relevance (STR) gains rely on the assumption that GeoRAG effectively grounds outputs; the mechanism is clear but dependent on data quality.
- **Low**: Cognitive map personalization claims (Hit@5, MRR) lack strong corpus support; TF-IWF is novel but not benchmarked against established personalization methods.

## Next Checks
1. **Ablation by query type**: Partition test queries into simple keyword vs. complex spatiotemporal; measure precision gap to understand where AskNearby's semantic advantage is largest.
2. **Distance threshold sensitivity**: Sweep θ from 0.5km to 3km; plot STR vs. recall to identify optimal neighborhood radius for different urban densities.
3. **Cold-start user simulation**: Zero out p_u (frequently visited places) in cognitive map scoring; measure Hit@5 degradation to quantify personalization contribution vs. spatial + popularity baseline.