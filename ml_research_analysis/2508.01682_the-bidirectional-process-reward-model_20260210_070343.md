---
ver: rpa2
title: The Bidirectional Process Reward Model
arxiv_id: '2508.01682'
source_url: https://arxiv.org/abs/2508.01682
tags:
- biprm
- step
- ours
- reasoning
- reward
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BiPRM, a novel bidirectional evaluation paradigm
  for process reward models that addresses the limitations of unidirectional left-to-right
  (L2R) evaluation by incorporating a parallel right-to-left (R2L) stream. The method
  achieves this through prompt reversal and a dynamic gating mechanism that fuses
  rewards from both directions, requiring only a 0.3% parameter increase and approximately
  5% inference latency overhead.
---

# The Bidirectional Process Reward Model

## Quick Facts
- arXiv ID: 2508.01682
- Source URL: https://arxiv.org/abs/2508.01682
- Authors: Lingyin Zhang; Jun Gao; Xiaoxue Ren; Ziqiang Cao
- Reference count: 21
- One-line primary result: BiPRM achieves 10.6% average relative improvement across solution-level benchmarks and 37.7% on step-level error detection by fusing bidirectional streams.

## Executive Summary
This paper introduces BiPRM, a novel bidirectional evaluation paradigm for process reward models that addresses the limitations of unidirectional left-to-right (L2R) evaluation by incorporating a parallel right-to-left (R2L) stream. The method achieves this through prompt reversal and a dynamic gating mechanism that fuses rewards from both directions, requiring only a 0.3% parameter increase and approximately 5% inference latency overhead. Extensive experiments on two solution-level benchmarks (GSM-Plus and MATH500) and one step-level benchmark (ProcessBench) demonstrate that BiPRM consistently outperforms unidirectional baselines across three different backbones (Rho-Math-1B, Qwen2.5-Math-1.5B, Deepseek-Math-7B) and three PRM objectives (BCE, MSE, Q-value rankings).

## Method Summary
BiPRM constructs a reversed trajectory and processes it in parallel with the original L2R stream, enabling later reasoning steps to help assess earlier ones through retrospective verification. The method uses a lightweight gating MLP to compute position-adaptive fusion weights that combine rewards from both streams, with weights that monotonically increase toward later steps. This bidirectional evaluation paradigm requires minimal architectural changes (0.3% parameter overhead) and achieves practical efficiency through parallel batch execution that maintains only ~5% wall-clock latency overhead compared to unidirectional evaluation.

## Key Results
- BiPRM achieves an average relative improvement of 10.6% across 54 solution-level configurations on GSM-Plus and MATH500 benchmarks
- The method shows 37.7% improvement across 12 step-level error detection scenarios on ProcessBench
- Performance gains are consistent across three different backbone models and three PRM objectives, demonstrating the method's robustness

## Why This Works (Mechanism)

### Mechanism 1
- Bidirectional context access enables retrospective verification that detects errors invisible to forward-only evaluation
- BiPRM processes a reversed trajectory in parallel with the original stream, allowing later steps to verify earlier ones through full downstream visibility
- The gating mechanism fuses both perspectives position-adaptively
- Core assumption: Early-step validity often depends on downstream logical consequences
- Break condition: If reasoning tasks are purely local (each step's correctness is context-independent)

### Mechanism 2
- Position-aware dynamic gating exploits complementary error profiles of L2R and R2L streams
- A lightweight MLP computes per-step fusion weights that monotonically increase toward later steps
- The learned weights rely more on R2L early (when backward view has fuller context) and L2R late (when forward accumulation is more informative)
- Core assumption: L2R and R2L have systematically different error distributions across reasoning positions
- Break condition: If error profiles are uniform across positions, dynamic gating provides no advantage over static averaging

### Mechanism 3
- Parallel batch execution converts theoretical 2× FLOPs into ~5% wall-clock latency overhead
- L2R and R2L streams are independent until gating fusion, allowing GPU parallelism to amortize dual computation
- Only 0.3% parameter overhead is added to the base model
- Core assumption: Inference hardware has sufficient parallel capacity to absorb the doubled batch
- Break condition: If batch size is already at memory capacity, or if inference framework lacks efficient batching

## Foundational Learning

- **Process Reward Models (PRMs):** PRMs assign scalar rewards to intermediate steps, typically trained via BCE/MSE/Q-value ranking on labeled or roll-out-generated data. Quick check: Given a 5-step solution trajectory, can you explain why a standard L2R-PRM cannot use Step 4's content when scoring Step 2?

- **Autoregressive Gradient Isolation:** Standard L2R evaluation has zero gradients from future steps to earlier ones (∂r^L2R_t/∂s_{t+k} = 0). Quick check: If you modified a causal attention mask to allow Step 2 to attend to Step 4, what side effects would this have on generation during training?

- **Gating and Mixture Mechanisms:** The dynamic gating MLP uses sigmoid-gated weighted sums with position-dependent weights. Quick check: If the gating MLP outputs σ_t = 0.7 for Step 3, what proportion of the final score comes from L2R vs R2L? What happens if the MLP always outputs 0.5?

## Architecture Onboarding

- **Component map:** Input (q + trajectory) -> L2R branch (forward evaluation) -> R2L branch (reversed trajectory) -> Gating MLP ([h^L2R_t; h^R2L_t] -> σ_t) -> Fusion (r_t = σ_t·r^L2R_t + (1-σ_t)·r^R2L_t) -> Aggregation (min operator)

- **Critical path:** Prompt construction for R2L (reversal logic) -> parallel batched forward pass -> extract hidden states from both streams -> per-step gating -> fused rewards -> trajectory aggregation

- **Design tradeoffs:** FLOPs vs. latency (2× compute but ~5% wall-clock); static vs. dynamic fusion (static averaging underperforms on challenging datasets); aggregation operator (min vs. mean for logical consistency)

- **Failure signatures:** R2L may over-penalize or under-detect local arithmetic skips; gating may fail if hidden states lack positional discriminability; parallel execution fails if memory cannot hold both streams

- **First 3 experiments:** 1) Train BiPRM on Math-Shepherd with Qwen2.5-Math-1.5B + BCE; compare BON@N against L2R baseline on GSM-Plus subset; 2) Replace dynamic MLP with static 0.5 weighting; measure performance drop on MATH500; 3) Profile wall-clock latency across batch sizes 1, 4, 16, 64 on single GPU; confirm overhead remains ~5%

## Open Questions the Paper Calls Out
The paper explicitly states that validation is currently confined to mathematical reasoning and that generalizability to other domains "remains to be verified." The limitations section notes that while wall-clock latency is managed via parallelization, the theoretical computational cost and energy consumption remain doubled ("unavoidable trade-off").

## Limitations
- Validation is confined to mathematical reasoning benchmarks; generalizability to other domains remains unverified
- The bidirectional fusion mechanism may struggle with local arithmetic inconsistencies that maintain internal logical coherence
- Theoretical 2× FLOPs computational overhead remains an unavoidable trade-off despite ~5% wall-clock latency

## Confidence
- **High confidence:** Bidirectional architecture design and theoretical justification are well-supported by equations and ablation studies
- **Medium confidence:** Performance improvements are convincing within experimental scope, but domain generalizability is uncertain
- **Low confidence:** Claims about effectiveness on "diverse reasoning tasks" beyond mathematics are not validated in the paper

## Next Checks
1. Evaluate BiPRM on non-mathematical reasoning tasks (e.g., code synthesis, commonsense reasoning) to verify cross-domain effectiveness
2. Systematically test different gating MLP architectures while keeping other components constant to isolate gating design impact
3. Measure actual wall-clock latency across different batch sizes and hardware configurations to verify the 5% overhead claim under resource-constrained conditions