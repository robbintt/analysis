---
ver: rpa2
title: 'Mapping AI Risk Mitigations: Evidence Scan and Preliminary AI Risk Mitigation
  Taxonomy'
arxiv_id: '2512.11931'
source_url: https://arxiv.org/abs/2512.11931
tags:
- risk
- mitigations
- safety
- mitigation
- management
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of fragmented AI risk mitigation
  frameworks by developing a structured taxonomy to organize and standardize AI risk
  mitigations. The authors conducted a rapid evidence scan of 13 AI risk mitigation
  frameworks published between 2023-2025, extracting 831 distinct mitigations into
  a living database.
---

# Mapping AI Risk Mitigations: Evidence Scan and Preliminary AI Risk Mitigation Taxonomy

## Quick Facts
- arXiv ID: 2512.11931
- Source URL: https://arxiv.org/abs/2512.11931
- Reference count: 38
- Primary result: Developed structured taxonomy organizing 831 AI risk mitigations from 13 frameworks into 4 categories and 23 subcategories

## Executive Summary
This study addresses the challenge of fragmented AI risk mitigation frameworks by developing a structured taxonomy to organize and standardize AI risk mitigations. The authors conducted a rapid evidence scan of 13 AI risk mitigation frameworks published between 2023-2025, extracting 831 distinct mitigations into a living database. Using iterative thematic analysis and framework synthesis methods, they organized these mitigations into a preliminary AI Risk Mitigation Taxonomy with four categories (Governance & Oversight, Technical & Security, Operational Process, and Transparency & Accountability) and 23 subcategories. The taxonomy successfully classified 98% of extracted mitigations and provides a common reference framework for diverse AI stakeholders to discuss, coordinate, and implement risk mitigations effectively. The database and taxonomy are publicly available at airisk.mit.edu for iteration, feedback, and use.

## Method Summary
The study employed a rapid evidence scan methodology to identify and analyze AI risk mitigation frameworks published between 2023-2025. The researchers systematically extracted 831 distinct mitigations from 13 selected frameworks, then used iterative thematic analysis and framework synthesis methods to organize these mitigations. Multiple team members participated in the coding process to enhance reliability, resulting in a preliminary taxonomy with four main categories and 23 subcategories. The methodology emphasizes transparency and iteration, with the living database designed to evolve based on stakeholder feedback.

## Key Results
- Extracted 831 distinct mitigations from 13 AI risk mitigation frameworks
- Developed taxonomy with 4 categories and 23 subcategories
- Successfully classified 98% of extracted mitigations
- Created publicly accessible living database at airisk.mit.edu

## Why This Works (Mechanism)
The taxonomy works by providing a standardized classification system that bridges the fragmentation across diverse AI risk mitigation frameworks. By organizing mitigations into clearly defined categories and subcategories, it enables stakeholders to identify relevant risk controls, compare approaches across frameworks, and implement coordinated risk management strategies. The iterative development process with multiple coders ensures reliability and comprehensiveness, while the living database approach allows continuous improvement as new frameworks emerge.

## Foundational Learning
1. AI Risk Mitigation Framework Diversity
   - Why needed: Different sectors and organizations approach AI risk differently
   - Quick check: Can identify at least 3 distinct types of AI risk frameworks (technical, governance, operational)

2. Thematic Analysis in Taxonomy Development
   - Why needed: Essential for organizing complex, overlapping risk mitigation concepts
   - Quick check: Can explain how themes emerge from repeated patterns in mitigation descriptions

3. Rapid Evidence Scan Methodology
   - Why needed: Balances comprehensiveness with timeliness in fast-evolving AI field
   - Quick check: Can identify key criteria for selecting relevant frameworks in rapid scans

4. Iterative Coding Process
   - Why needed: Improves reliability and captures nuanced differences in mitigations
   - Quick check: Can describe benefits of multiple coders reviewing the same mitigations

5. Living Database Concept
   - Why needed: AI risk landscape evolves rapidly, requiring flexible knowledge organization
   - Quick check: Can explain how stakeholder feedback improves taxonomy utility

6. Cross-framework Synthesis
   - Why needed: Enables comparison and integration of diverse risk mitigation approaches
   - Quick check: Can identify at least two frameworks that address similar risks differently

## Architecture Onboarding

**Component Map:** 13 AI Risk Mitigation Frameworks -> 831 Distinct Mitigations -> 4 Main Categories -> 23 Subcategories -> Living Database

**Critical Path:** Framework Selection → Mitigation Extraction → Thematic Coding → Taxonomy Development → Database Publication → Stakeholder Feedback → Iteration

**Design Tradeoffs:** Rapid evidence scan (speed vs. comprehensiveness) → Iterative coding (reliability vs. time investment) → Living database (flexibility vs. standardization) → Public accessibility (broad input vs. quality control)

**Failure Signatures:** 
- Mitigations falling outside taxonomy categories (indicates missing risk domains)
- High disagreement rates in inter-rater reliability tests (indicates unclear category definitions)
- Stakeholder confusion about taxonomy application (indicates usability issues)
- Database becomes outdated as new frameworks emerge (indicates need for update cycle)

**First 3 Experiments:**
1. Test taxonomy classification on 50 mitigations from frameworks not in original scan to measure coverage
2. Conduct structured interviews with 10 AI practitioners to assess practical utility and usability
3. Implement A/B testing of different taxonomy structures with stakeholder groups to optimize navigation

## Open Questions the Paper Calls Out
None

## Limitations
- Rapid scan methodology may have missed emerging frameworks published after cutoff date
- Exclusion of risk identification and assessment frameworks limits end-to-end risk management coverage
- Subcategory stability uncertain as ongoing feedback may reveal organizational improvements needed

## Confidence

**High Confidence:**
- Methodological rigor of evidence scan and taxonomy development
- Four-category structure based on clear thematic distinctions
- 98% classification success rate for extracted mitigations

**Medium Confidence:**
- Representativeness of 13 selected frameworks
- Stability of 23 subcategories given ongoing feedback
- Completeness for end-to-end risk management

## Next Checks

1. Conduct systematic review of AI risk mitigation frameworks published in 2025-2026 to assess taxonomy coverage of emerging risk domains

2. Implement cross-validation exercise with independent teams classifying mitigations from non-included frameworks to measure inter-rater reliability

3. Test taxonomy practical utility through structured interviews with AI practitioners across healthcare, finance, and government sectors