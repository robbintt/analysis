---
ver: rpa2
title: 'FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation'
arxiv_id: '2601.01687'
source_url: https://arxiv.org/abs/2601.01687
tags:
- segmentation
- medical
- falcon
- image
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'FALCON introduces a cross-domain few-shot segmentation framework
  for medical imaging that achieves high-precision 3D volume segmentation by processing
  data as 2D slices. The method addresses data scarcity and computational overhead
  in medical image segmentation through a three-phase approach: meta-training on natural
  images, adversarial fine-tuning with boundary-aware learning on medical data, and
  task-aware inference.'
---

# FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation

## Quick Facts
- arXiv ID: 2601.01687
- Source URL: https://arxiv.org/abs/2601.01687
- Reference count: 9
- Primary result: Achieves lowest Hausdorff Distance scores across four medical datasets while maintaining Dice Similarity Coefficient comparable to state-of-the-art models

## Executive Summary
FALCON introduces a cross-domain few-shot segmentation framework for medical imaging that achieves high-precision 3D volume segmentation by processing data as 2D slices. The method addresses data scarcity and computational overhead in medical image segmentation through a three-phase approach: meta-training on natural images, adversarial fine-tuning with boundary-aware learning on medical data, and task-aware inference. Key innovations include unlabeled support integration via a relation module, boundary-aware adversarial fine-tuning (BAAF) using Hausdorff distance loss, and patient-specific adaptation during inference.

## Method Summary
FALCON processes 3D medical volumes as 2D slices and employs a three-phase approach. First, it meta-trains on natural images (FSS-1000) using episodic few-shot learning. Second, it performs adversarial fine-tuning on medical datasets using boundary-aware adversarial fine-tuning (BAAF) that combines Hausdorff distance loss with weighted Dice loss. Third, it adapts to individual patients during inference by conditioning on unlabeled support slices. The architecture uses a U-Net with EfficientNet-B0 encoder and a relation module in the bottleneck that aggregates support features into prototypes. The framework achieves superior boundary accuracy while requiring significantly less labeled data and computational resources compared to existing methods.

## Key Results
- Consistently achieves the lowest Hausdorff Distance (HD95) scores across all four benchmarks (CHAOS-CT, Spleen-CT, COVID-19 CT, Cardiac MRI)
- Maintains Dice Similarity Coefficient comparable to state-of-the-art models
- Requires significantly less labeled data and no data augmentation
- Achieves substantial computational efficiency with 9.9M parameters and 2.3 GFLOPs

## Why This Works (Mechanism)
The method's effectiveness stems from its cross-domain adaptation strategy that leverages natural image pretraining to overcome medical image scarcity. The boundary-aware adversarial fine-tuning explicitly optimizes for precise boundary delineation through Hausdorff distance loss, which directly measures the maximum boundary deviation. The relation module enables effective use of unlabeled support data by creating patient-specific prototypes that guide segmentation. Patient-specific adaptation during inference allows the model to account for individual anatomical variations without requiring extensive labeled data per patient.

## Foundational Learning
- **Hausdorff Distance**: Measures maximum boundary deviation between predicted and ground truth segmentation masks. Why needed: Provides precise boundary accuracy metric beyond Dice coefficient. Quick check: Verify HD95 implementation matches Karimi & Salcudean (2020) definition.
- **Relation Module**: Aggregates K support features into a prototype and concatenates with query features. Why needed: Enables few-shot learning by transferring knowledge from support to query images. Quick check: Confirm prototype computation as F_proto = Σ F_Sj.
- **Adversarial Fine-Tuning**: Uses discriminator to align feature distributions between source and target domains. Why needed: Bridges domain gap between natural and medical images. Quick check: Verify discriminator includes batch norm, LeakyReLU (0.2), and dropout (0.25).
- **Episodic Meta-Training**: Trains on simulated few-shot tasks. Why needed: Prepares model for few-shot scenarios during inference. Quick check: Confirm task sampling strategy creates balanced support/query splits.
- **Boundary-Aware Loss**: Combines Hausdorff loss with weighted Dice loss. Why needed: Balances boundary precision with overall segmentation quality. Quick check: Verify λ1=0.9 for Dice stability in early training.
- **Patient-Specific Adaptation**: Conditions segmentation on unlabeled support slices per patient. Why needed: Accounts for individual anatomical variations. Quick check: Confirm inference uses K unlabeled support slices per patient.

## Architecture Onboarding
- **Component map**: FSS-1000 -> U-Net(EfficientNet-B0 + Relation Module) -> Discriminator -> Medical Datasets
- **Critical path**: Meta-training on FSS-1000 → Adversarial fine-tuning on medical data → Patient-specific inference
- **Design tradeoffs**: Uses 2D slices for 3D segmentation to reduce computational overhead vs. direct 3D approaches; unlabeled support integration vs. fully supervised methods; boundary-aware loss vs. traditional Dice-only optimization
- **Failure signatures**: Poor boundary accuracy (high HD) indicates Hausdorff loss implementation issues; domain gap problems suggest meta-training convergence issues; overfitting suggests insufficient regularization or unlabeled support utilization
- **First experiments**: 1) Train on FSS-1000 with episodic tasks to verify meta-learning capability; 2) Fine-tune on single medical dataset with BAAF to validate domain adaptation; 3) Test patient-specific inference with varying K shots to determine optimal support size

## Open Questions the Paper Calls Out
None

## Limitations
- Does not specify the number of support shots (K) used during inference, which directly affects performance
- Lacks detailed training hyperparameters including episode counts, batch sizes, and learning rate schedules
- Incomplete discriminator architecture specification beyond basic layer types and dropout rate
- Does not detail episode sampling strategy for meta-training or specific support slice selection during inference

## Confidence
- **High confidence**: Core three-phase framework design, U-Net + EfficientNet-B0 + Relation Module architecture, overall experimental results showing superior boundary accuracy
- **Medium confidence**: BAAF mechanism and Hausdorff loss implementation details
- **Low confidence**: Exact performance metrics reproducibility without knowing K, training epochs, batch sizes, and precise discriminator architecture

## Next Checks
1. Confirm K shots and support slice selection: Determine exact number of support slices and selection method (random, evenly spaced, or clinical criteria)
2. Validate discriminator architecture: Implement and test multiple discriminator variants to find configuration achieving stable adversarial training
3. Test boundary accuracy sensitivity: Run ablation studies varying λ1, λ2, and a to verify reported HD95 improvements are robust to hyperparameter changes