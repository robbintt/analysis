---
ver: rpa2
title: 'Fair for a few: Improving Fairness in Doubly Imbalanced Datasets'
arxiv_id: '2506.14306'
source_url: https://arxiv.org/abs/2506.14306
tags:
- dataset
- fairness
- data
- level
- ratio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses fairness challenges in machine learning when
  datasets are imbalanced both in label distribution and sensitive attribute groups,
  termed "doubly imbalanced datasets." Existing debiasing methods often fail in such
  scenarios, particularly when balancing only one aspect of the dataset. The authors
  propose a multi-criteria optimization approach that jointly balances both the label
  distribution and sensitive attribute groups.
---

# Fair for a few: Improving Fairness in Doubly Imbalanced Datasets

## Quick Facts
- **arXiv ID:** 2506.14306
- **Source URL:** https://arxiv.org/abs/2506.14306
- **Reference count:** 40
- **Primary result:** Tri-parametric sampling approach improves fairness and accuracy on doubly imbalanced fraud detection datasets

## Executive Summary
This study addresses fairness challenges in machine learning when datasets are imbalanced in both label distribution and sensitive attribute groups, termed "doubly imbalanced datasets." The authors propose a multi-criteria optimization approach that jointly balances both the label distribution and sensitive attribute groups using three parameters (α, β, γ) to control balancing across privileged/unprivileged groups and favorable/unfavorable labels. Experiments on fraud detection datasets demonstrate significant improvements in both fairness (measured by Disparate Impact Ratio) and accuracy (measured by Matthews Correlation Coefficient) compared to baseline methods.

## Method Summary
The proposed method uses tri-parametric constrained undersampling to balance doubly imbalanced datasets. It constructs a sampled dataset by enforcing constraints on four partitions (privileged/favorable, privileged/unfavorable, unprivileged/favorable, unprivileged/unfavorable) simultaneously. The method employs a two-level grid search strategy with parameters α (unprivileged rate), β (unfavorable label rate), and γ (relative favorable label rate) to find optimal trade-offs between fairness and classification accuracy. The approach is model-agnostic and applicable to both doubly and singly imbalanced datasets.

## Key Results
- The method achieves significant improvements in both fairness and accuracy on fraud detection datasets compared to baseline debiasing methods
- Pareto front analysis reveals clear trade-offs between fairness (DI Ratio) and accuracy (MCC) across different parameter configurations
- The approach maintains model performance while improving fairness, unlike naive balancing methods that degrade accuracy

## Why This Works (Mechanism)

### Mechanism 1: Tri-Parametric Constrained Undersampling
The method mitigates standard debiasing failure modes by explicitly decoupling the balancing of sensitive attribute (α), class label (β), and conditional label distribution across groups (γ). By parameterizing the search space, it interpolates between the original distribution and a "perfectly balanced" state, preventing data reduction that causes classifier failure.

### Mechanism 2: Multi-Criteria Loss Optimization
Simultaneously minimizing Combined Loss (MCC Loss + DI Ratio Loss) allows identification of Pareto-optimal sampling ratios where improving fairness doesn't catastrophically collapse classification utility. This finds configurations where you cannot improve fairness without hurting accuracy, and vice versa.

### Mechanism 3: Hierarchical Search Refinement
A two-level grid search strategy (coarse Level 0 with step 0.1, then fine-grained Level 1 with step 0.01) mitigates computational cost while maintaining solution quality. This efficiently refines rough estimates of optimal balance structures.

## Foundational Learning

- **Concept: Disparate Impact (DI) Ratio**
  - **Why needed:** Primary fairness metric the model seeks to optimize, quantifying ratio of favorable outcomes for unprivileged vs. privileged groups
  - **Quick check:** If a model accepts 50% of Young applicants and 10% of Old applicants, what is the DI Ratio? (Answer: 0.2, indicating high bias)

- **Concept: Matthews Correlation Coefficient (MCC)**
  - **Why needed:** Paper rejects Accuracy and F1 for this task because they're misleading in imbalanced datasets; MCC accounts for true negatives, false positives, etc., in a single metric
  - **Quick check:** Why would a model with 99% accuracy be considered a failure in fraud detection? (Answer: It likely missed all actual fraud cases, resulting in low MCC despite high accuracy)

- **Concept: Double Imbalance**
  - **Why needed:** Core problem definition referring to simultaneous skew in class labels AND sensitive attributes; standard methods often fix one skew and break the other
  - **Quick check:** If you balance a dataset for Fraud/Non-Fraud but ignore Age, what might happen to the DI Ratio? (Answer: It may remain biased if the Age distribution within the "Fraud" class is skewed)

## Architecture Onboarding

- **Component map:** Data Partitioner -> Parametric Sampler -> Model Wrapper -> Loss Aggregator -> Grid Search Controller
- **Critical path:** Sampling logic (Equation 8) is the highest-risk component; ensuring "maximum size of D'" calculation is correct is vital to prevent empty datasets
- **Design tradeoffs:**
  - Grid granularity vs. compute: 0.1 step is fast but may miss narrow optimal regions; 0.01 is accurate but expensive
  - Metric weighting: Fixed c₁=c₂=1 may not be optimal across all domains
  - Sampling vs. generation: Undersampling discards data; for very small datasets, synthetic oversampling might be preferable
- **Failure signatures:**
  - NaN DI Ratio: Classifier predicted 0 instances of positive class for privileged group (denominator zero)
  - Extreme MCC drop: If MCC drops below baseline while DI Ratio improves, model is likely guessing randomly
  - Pareto Front collapse: Single point indicates no flexibility in trade-off
- **First 3 experiments:**
  1. Implement exploratory analysis (Section 4) to confirm baseline failure modes
  2. Run Level 0 grid search and plot Pareto Front to verify trade-off curve
  3. Run optimal parameters on Random Forest vs. Logistic Regression to verify model-dependence

## Open Questions the Paper Calls Out

1. **Search mechanism efficiency:** Can more efficient search mechanisms, such as Bayesian optimization, replace the two-level grid search to lower computational costs while maintaining solution quality?
2. **Generalization to multiple attributes:** Does the proposed sampling strategy generalize effectively to datasets with non-binary sensitive attributes or multi-class labels?
3. **Dynamic balancing strategies:** How do dynamic balancing strategies, where sampling ratios adapt during training, compare to the static sampling approach proposed?

## Limitations
- Reliance on undersampling discards potentially valuable information, problematic for very small datasets
- Fixed weighting of fairness and accuracy metrics (c₁=c₂=1) may not be optimal across all domains
- Exclusive focus on binary classification limits applicability to multi-class scenarios

## Confidence

- **Mechanism 1 (Tri-Parametric Sampling):** Medium-High
- **Mechanism 2 (Multi-Criteria Optimization):** High
- **Mechanism 3 (Hierarchical Search):** Medium

## Next Checks
1. Verify the sampling logic implementation by reproducing the exploratory analysis (Section 4) to confirm baseline failure modes occur as described
2. Test the method's performance on non-fraud datasets to assess generalizability beyond experimental domains
3. Conduct ablation studies on the three parameters (α, β, γ) to quantify their individual contributions to fairness and accuracy improvements