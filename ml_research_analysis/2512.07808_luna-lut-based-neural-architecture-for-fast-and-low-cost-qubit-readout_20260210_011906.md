---
ver: rpa2
title: 'LUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout'
arxiv_id: '2512.07808'
source_url: https://arxiv.org/abs/2512.07808
tags:
- readout
- fidelity
- design
- latency
- fpga
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LUNA addresses the challenge of resource-efficient qubit readout
  in superconducting quantum processors by integrating integrator-based preprocessing
  with LUT-mapped neural networks. It uses a low-cost integrator to compress raw I/Q
  time-series into compact features, reducing dimensionality without multipliers.
---

# LUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout

## Quick Facts
- arXiv ID: 2512.07808
- Source URL: https://arxiv.org/abs/2512.07808
- Authors: M. A. Farooq; G. Di Guglielmo; A. Rajagopala; N. Tran; V. A. Chhabria; A. Arora
- Reference count: 22
- Primary result: LUT-based neural network achieves 10.95× reduction in LUT usage, 30% lower latency, and zero DSP utilization while maintaining fidelities above 95.9% for superconducting qubit readout

## Executive Summary
LUNA introduces a resource-efficient neural architecture for superconducting qubit readout that combines integrator-based preprocessing with LUT-mapped neural networks. The system uses a low-cost integrator to compress raw I/Q time-series data into compact features, reducing dimensionality without requiring multipliers. The classifier employs a LogicNet approach where each neuron is directly synthesized into FPGA LUTs, achieving ultra-low latency and minimal area utilization. This architecture is specifically designed to meet the stringent timing constraints of mid-circuit measurement and quantum error correction while maintaining high classification fidelity.

## Method Summary
The LUNA architecture integrates integrator-based preprocessing with a LUT-mapped neural network classifier. Raw I/Q time-series data from qubit measurements is first processed by a low-cost integrator that compresses the signal into compact features, eliminating the need for multipliers. The classifier is implemented as a LogicNet where each neuron is directly synthesized into FPGA LUTs rather than using traditional arithmetic operations. A differential evolution-based joint optimization explores both preprocessing and classifier parameters to find optimal configurations. The FPGA implementation targets Xilinx Zynq UltraScale+ devices, demonstrating significant improvements in resource utilization while maintaining high classification fidelity above 95.9%.

## Key Results
- 10.95× reduction in LUT usage compared to traditional MLP implementations
- 30% lower latency (22-32ns inference time) for qubit state classification
- Zero DSP utilization through LUT-based neural network implementation
- Fidelity maintenance above 95.9% while achieving substantial resource savings

## Why This Works (Mechanism)
The integrator-based preprocessing reduces the dimensionality of raw I/Q time-series data while preserving the essential information needed for qubit state discrimination. This compression eliminates the need for resource-intensive multipliers, significantly reducing computational complexity. The LogicNet approach maps neural network neurons directly to FPGA LUTs, avoiding traditional arithmetic operations that consume more resources. The differential evolution optimization jointly explores both preprocessing and classifier parameters, finding configurations that balance accuracy and resource efficiency. This combination enables high-speed classification with minimal hardware footprint, crucial for quantum error correction where timing and resource constraints are severe.

## Foundational Learning

**Integrator-based preprocessing**
- Why needed: Compresses high-dimensional I/Q time-series data while preserving qubit state information
- Quick check: Verify integrator reduces feature dimension by at least 50% without significant fidelity loss

**LUT-mapped neural networks**
- Why needed: Eliminates multipliers and DSP blocks, reducing resource utilization and latency
- Quick check: Confirm each neuron maps to a single LUT and verify latency improvement over arithmetic implementations

**Differential evolution optimization**
- Why needed: Explores mixed-discrete design space to find optimal balance between accuracy and resource efficiency
- Quick check: Validate convergence to Pareto-optimal solutions across multiple runs

**Single-qubit readout pipeline**
- Why needed: Provides baseline performance metrics before extending to multi-qubit scenarios
- Quick check: Confirm fidelity exceeds 95% on test dataset

## Architecture Onboarding

**Component map**
Integrator -> Feature compressor -> LUT-mapped LogicNet -> State classification

**Critical path**
Integrator output → LogicNet neurons → Classification decision (22-32ns total)

**Design tradeoffs**
- Accuracy vs. resource utilization: Higher-dimensional features improve fidelity but increase LUT usage
- Integration window size vs. latency: Longer windows capture more information but increase delay
- Network depth vs. area: Deeper networks improve discrimination but consume more LUTs

**Failure signatures**
- Fidelity drop below 95% indicates insufficient feature extraction or inadequate network capacity
- Excessive LUT utilization suggests poor optimization or over-parameterized network
- Latency spikes indicate routing congestion or inefficient LUT mapping

**First experiments**
1. Measure integrator compression ratio and corresponding fidelity on validation dataset
2. Compare LogicNet latency against traditional arithmetic MLP implementation
3. Evaluate resource utilization (LUTs, DSPs) for different network depths

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LUNA maintain its resource efficiency and fidelity when applied to multi-qubit or higher-dimensional readout traces?
- Basis in paper: [explicit] The authors state: "Evaluating LUNA on additional datasets, including multi-qubit or higher-dimensional readout traces, will help assess generality."
- Why unresolved: The paper validates the architecture using a specific single-qubit superconducting dataset [3], leaving the performance on multiplexed or higher-dimensional data unconfirmed.
- What evidence would resolve it: Fidelity and resource utilization results from training and deploying LUNA on a dataset containing multiplexed readout traces from multiple qubits simultaneously.

### Open Question 2
- Question: How can the architecture be extended to support multi-qubit joint classifiers to capture crosstalk and correlated noise?
- Basis in paper: [explicit] The authors note: "Extending the architecture to multi-qubit joint classifiers could capture crosstalk and correlated noise, a limitation of per-qubit pipelines noted in prior work."
- Why unresolved: The current LUNA implementation assumes a per-qubit pipeline which ignores correlations between qubits, limiting accuracy in systems with significant crosstalk.
- What evidence would resolve it: A modified LUNA architecture that processes multiple qubit streams simultaneously and demonstrates superior fidelity compared to independent per-qubit classifiers in the presence of correlated noise.

### Open Question 3
- Question: Can richer search strategies uncover better design points than the Differential Evolution (DE) approach used in this study?
- Basis in paper: [explicit] The discussion suggests: "Finally, richer search strategies may provide improved coverage of the design space and may uncover even better solutions."
- Why unresolved: While effective, the DE approach relies on heuristics and pruning which may not guarantee global optima in the vast, mixed-discrete design space.
- What evidence would resolve it: A comparative study using advanced techniques (e.g., Reinforcement Learning) showing lower composite costs or higher fidelity solutions than those found by the DE-based search.

### Open Question 4
- Question: What is the total system latency when LUNA is integrated into a closed-loop quantum error correction (QEC) cycle?
- Basis in paper: [inferred] The paper reports "inference latency" (22–32ns) as the primary metric, but acknowledges the need for "mid-circuit measurement and feedback... within coherence windows" (Introduction).
- Why unresolved: The reported latency measures only the FPGA classification time and does not account for the complete round-trip delay including signal transmission, pulse generation, and feedback application.
- What evidence would resolve it: End-to-end timing analysis of LUNA operating within a live feedback loop on a quantum processor, measuring the time from readout pulse start to control update.

## Limitations

- FPGA-specific implementation may not directly translate to ASIC or other FPGA families
- Joint optimization relies on differential evolution heuristics that may not find global optima
- Per-qubit pipeline architecture cannot capture crosstalk and correlated noise between qubits
- Limited validation on single-qubit dataset without extensive testing across different noise conditions

## Confidence

**High confidence in:** Fundamental feasibility of LUT-based neural network implementation for qubit readout and core integration of integrator preprocessing with neural classification. Resource reductions (10.95× LUT reduction, 30% latency improvement, zero DSP utilization) are well-supported by experimental results.

**Medium confidence in:** Fidelity claims above 95.9% across all conditions and effectiveness of joint optimization methodology, which could benefit from more rigorous ablation studies and alternative optimization comparisons.

**Low confidence in:** Scalability claims for mid-circuit measurement and quantum error correction applications requiring validation on actual quantum processors, and long-term reliability under varying operating conditions.

## Next Checks

1. Implement and test LUNA on multiple FPGA platforms (including different vendors) to verify cross-platform performance consistency and identify any platform-specific limitations.

2. Conduct comprehensive benchmarking against other quantum readout approaches including variational quantum circuits and advanced classical machine learning methods, measuring not just resource usage but also robustness to different noise models.

3. Deploy LUNA in a real quantum processor environment for mid-circuit measurement and quantum error correction tasks, measuring end-to-end performance including the impact of readout latency on overall quantum circuit execution.