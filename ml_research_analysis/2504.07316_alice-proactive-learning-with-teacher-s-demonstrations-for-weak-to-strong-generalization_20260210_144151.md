---
ver: rpa2
title: 'Alice: Proactive Learning with Teacher''s Demonstrations for Weak-to-Strong
  Generalization'
arxiv_id: '2504.07316'
source_url: https://arxiv.org/abs/2504.07316
tags:
- teacher
- arxiv
- student
- w2sg
- alice
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Alice, a proactive learning framework for
  weak-to-strong generalization (W2SG) that enables stronger student models to self-generate
  improved supervision signals using teacher demonstrations and uncertainty expressions.
  Unlike traditional W2SG's passive learning approach, Alice probes teacher models
  for uncertainty and uses this information alongside student zero-shot responses
  to produce higher-quality training data.
---

# Alice: Proactive Learning with Teacher's Demonstrations for Weak-to-Strong Generalization

## Quick Facts
- arXiv ID: 2504.07316
- Source URL: https://arxiv.org/abs/2504.07316
- Reference count: 20
- Primary result: Achieves 4.0%, 22.62%, and 12.11% relative improvements over W2SG on knowledge-based, mathematical, and logical reasoning tasks respectively.

## Executive Summary
This paper introduces Alice, a proactive learning framework that extends weak-to-strong generalization (W2SG) by enabling stronger student models to self-generate improved supervision signals using teacher demonstrations and uncertainty expressions. Unlike traditional W2SG's passive learning approach, Alice probes teacher models for uncertainty and uses this information alongside student zero-shot responses to produce higher-quality training data. The framework also introduces cascade Alice, a hierarchical training approach for large capability gaps between teacher and student models. Experiments across knowledge-based reasoning, mathematical reasoning, and logical reasoning tasks show Alice significantly outperforms original W2SG, consistently enabling student models to surpass the performance of models trained directly on ground-truth labels.

## Method Summary
Alice transforms W2SG from passive imitation to proactive self-generation. First, weak teacher models are fine-tuned on supervised Q-CoT-A pairs (human CoT for GSM8K, rejection-sampled CoT for others). Then, for unlabeled questions, the system generates 100 teacher responses, clusters them semantically using embeddings, and prompts a large model to synthesize uncertainty statements that articulate inconsistencies across clusters. Students receive (question, teacher answer, teacher uncertainty, student's zero-shot response) and are prompted to synthesize an improved response, which becomes their supervision. For large capability gaps, cascade Alice trains intermediate models sequentially, leveraging the observation that intermediate models often exceed ground-truth-trained baselines.

## Key Results
- Alice consistently outperforms original W2SG across all tested datasets and capability gaps
- Cascade Alice provides stable supervision for large capability gaps (e.g., 1.5B→7B) where direct training fails
- Student models trained via Alice can outperform those trained directly on ground-truth labels
- The framework shows robust performance across knowledge-based, mathematical, and logical reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
Probing teacher uncertainty surfaces specific knowledge gaps that students can correct. The system generates 100 chain-of-thought responses per question, clusters them semantically using embeddings, and prompts a large model to synthesize natural-language uncertainty statements that articulate inconsistencies across clusters. Core assumption: teachers often produce inconsistent reasoning trajectories that, when explicitly articulated, reveal fixable gaps to stronger students. Evidence: removing uncertainty reduces performance (e.g., ARC-Challenge drops from 90.09% to 88.96% in cascade setting).

### Mechanism 2
Students generate higher-quality supervision by synthesizing teacher guidance with their own zero-shot reasoning. Each student receives (question, teacher answer, teacher uncertainty, student's zero-shot response) and is prompted to either keep its answer, adopt the teacher's, or generate a new response integrating both signals. Core assumption: strong students possess latent capabilities that passive imitation of noisy teachers suppresses; explicit guidance unlocks self-correction. Evidence: Alice consistently outperforms original W2SG (e.g., GSM8K: 72.27% vs 57.71% for Qwen 1.5B→3B).

### Mechanism 3
Cascade decomposition transforms large capability gaps into stable, incremental transfers. For large gaps, Alice trains intermediate models (e.g., 1.5B→3B), which then serve as teachers for stronger students (3B→7B). Intermediate models often exceed ground-truth-trained baselines, providing better supervision. Core assumption: progressive gap reduction preserves and enriches knowledge better than direct weak-to-strong jumps. Evidence: removing cascade (1.5B→7B direct) drops performance vs cascade (e.g., GSM8K: 76.78% vs 79.16%).

## Foundational Learning

- **Weak-to-Strong Generalization (W2SG)**: Why needed: Alice extends W2SG by replacing passive imitation with proactive synthesis; understanding the baseline problem (strong student trained on weak teacher labels can still generalize) is prerequisite. Quick check: Can you explain why strong students generalize beyond weak teachers in standard W2SG?

- **Chain-of-Thought (CoT) Reasoning**: Why needed: Alice trains teachers with CoT, and student responses integrate reasoning chains; CoT quality directly affects uncertainty elicitation and final supervision quality. Quick check: How would you verify that a generated CoT is valid for a given answer?

- **Uncertainty Quantification for LLMs**: Why needed: Alice's uncertainty elicitation depends on interpreting response variability; misunderstanding how models express confidence/inconsistency breaks the mechanism. Quick check: What methods can surface uncertainty in LLM outputs without logit access?

## Architecture Onboarding

- Component map: Teacher fine-tuning → Uncertainty elicitation (100 responses → clustering → uncertainty synthesis) → Proactive learning (student zero-shot + synthesis → fine-tuning) → Cascade (optional intermediate models)

- Critical path: 1) Teacher CoT fine-tuning (requires ground-truth labels for first-half training data). 2) Uncertainty elicitation on unlabeled questions (second-half training set). 3) Student proactive response generation (zero-shot inference). 4) Student fine-tuning on self-generated responses. 5) If cascade: iterate with intermediate student as next teacher.

- Design tradeoffs:
  - Uncertainty elicitation cost: 100 samples + clustering + large-model summarization per question is expensive; reducing samples may miss inconsistencies.
  - Cascade vs direct: Cascade adds training rounds but enables larger gaps; direct is simpler but may fail when teacher-student gap is large.
  - Cross-family teachers: Can provide diverse perspectives (Table 2 shows mixed results), but increases prompt complexity and potential interference.

- Failure signatures:
  - Student fails to integrate guidance (outputs ignore teacher/uncertainty).
  - Uncertainty statements are generic ("N/A") due to uniform teacher responses.
  - Cascade doesn't improve intermediate model (suggests teacher quality or gap too large).
  - Performance degrades below original W2SG (check prompt formatting, data contamination).

- First 3 experiments:
  1. Baseline check: Replicate original W2SG (Q-CoT-A) and Alice on Qwen 1.5B→3B with GSM8K; verify Table 1 gains.
  2. Uncertainty ablation: Run Alice with uncertainty removed; expect drops per Table 2.
  3. Cascade scaling: Test 1.5B→3B→7B cascade vs 1.5B→7B direct on HotpotQA; confirm cascade advantage.

## Open Questions the Paper Calls Out

### Open Question 1
Can multi-turn, dynamic interaction between teacher and student models improve W2SG generalization performance beyond the single-turn Alice paradigm? Basis: The authors state "we still believe that exploring more effective mechanisms for multi-turn model interactions remains an important direction for improving generalization performance." Why unresolved: The authors implemented a two-turn interaction but found it unpromising, leaving the design of effective multi-turn mechanisms unexplored. What evidence would resolve it: A systematic study comparing single-turn vs. well-designed multi-turn interaction protocols, showing significant performance gains on standard W2SG benchmarks.

### Open Question 2
How does Alice perform when decomposed into more than two cascade stages for increasingly large capability gaps? Basis: The authors note "decomposing the supervision into multiple intermediate stages should be implemented to ensure stable knowledge transfer and reach the optimal supervision outcome." Why unresolved: Practical constraints (limited model sizes, computational resources) restricted experiments to two-stage cascades. What evidence would resolve it: Experiments with 3+ cascade stages across varying capability gaps, demonstrating whether performance scales or plateaus.

### Open Question 3
How robust is Alice when teacher model uncertainty is inaccurately elicited or expressed? Basis: The limitations section states "In cases where the teacher model's uncertainty expression fails to be accurately elicited, the framework's effectiveness may be significantly reduced." Why unresolved: No systematic analysis of failure modes or sensitivity to uncertainty quality was conducted. What evidence would resolve it: Ablation studies with synthetic noise injected into uncertainty expressions, measuring performance degradation.

## Limitations
- The uncertainty elicitation step relies heavily on semantic clustering of 100 teacher responses per question, but the optimal clustering threshold is unspecified and may significantly impact performance.
- The method assumes teacher models produce diverse reasoning trajectories when prompted for 100 responses, but for simpler problems or highly confident teachers, responses may cluster tightly, yielding minimal uncertainty signals.
- Cascade Alice's success depends on intermediate models outperforming ground-truth-trained baselines, which is not guaranteed across all capability gaps or model families.

## Confidence
- **High confidence**: Alice's empirical improvements over W2SG across multiple reasoning tasks are well-supported by experimental results (Table 1, 2, 3).
- **Medium confidence**: The uncertainty elicitation mechanism works as described, though the optimal clustering parameters and prompt templates may require tuning for different domains.
- **Low confidence**: The generalizability of Alice to significantly larger capability gaps (beyond the 1.5B→7B tested) or to non-reasoning tasks remains uncertain.

## Next Checks
1. **Clustering threshold sensitivity**: Systematically vary the semantic clustering threshold T (0.6-0.9) and measure its impact on final student performance to identify the optimal value for each dataset.
2. **Uncertainty quality analysis**: Manually inspect a sample of uncertainty statements produced by the Qwen2.5-70B summarizer to verify they meaningfully capture teacher reasoning inconsistencies versus being generic or empty.
3. **Teacher diversity experiment**: Test Alice with multiple teacher models of different architectures (e.g., Qwen + Llama) providing parallel supervision, measuring whether diverse perspectives improve student performance beyond single-teacher Alice.