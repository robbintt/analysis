---
ver: rpa2
title: "Distributed Multi-Agent Bandits Over Erd\u0151s-R\xE9nyi Random Networks"
arxiv_id: '2510.22811'
source_url: https://arxiv.org/abs/2510.22811
tags:
- regret
- graph
- bound
- communication
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies a distributed multi-agent multi-armed bandit\
  \ problem with heterogeneous rewards over time-varying Erd\u0151s-R\xE9nyi random\
  \ communication graphs. The key challenge is that agents must learn optimal actions\
  \ while communicating over random networks where each edge in a base graph is present\
  \ with probability p, and the resulting graph may be disconnected at each time step."
---

# Distributed Multi-Agent Bandits Over Erdős-Rényi Random Networks

## Quick Facts
- arXiv ID: 2510.22811
- Source URL: https://arxiv.org/abs/2510.22811
- Authors: Jingyuan Liu; Hao Qiu; Lin Yang; Mengfan Xu
- Reference count: 40
- Key outcome: O(∑ₖ:Δₖ>0 logT/Δₖ + N²logT/(pλN−1(Lap(G))) + KN²logT/p) regret bound for distributed MA-MAB over random networks

## Executive Summary
This paper addresses distributed multi-agent multi-armed bandit problems with heterogeneous rewards over time-varying Erdős-Rényi random communication graphs. The key challenge is learning optimal actions while communicating over random networks where edge connectivity varies stochastically. The authors propose Gossip Successive Elimination (GSE), a fully distributed algorithm that integrates arm elimination with gossip-based consensus. The algorithm uses a refined weight matrix based on graph Laplacian and introduces a novel confidence interval design accounting for both estimation and consensus errors. The theoretical contribution provides a regret upper bound that scales with network parameters (link probability p and algebraic connectivity λN−1), holding for any p ∈ (0,1] without requiring connectivity assumptions.

## Method Summary
The paper studies distributed MA-MAB with heterogeneous rewards where agents must learn optimal arms through local observations and limited communication over Erdős-Rényi random graphs. Each agent maintains local reward estimates and participates in gossip-based consensus to compute global estimates. The GSE algorithm integrates arm elimination with gossip updates: agents select arms with minimum pull counts, update local estimates, perform Laplacian-based gossip updates, eliminate arms based on confidence bounds, and synchronize active sets. The confidence bounds separate estimation error from consensus error, with the latter decaying as gossip mixing time τ* = O(N log(T)/(p·λN−1)) passes. When p is unknown, a burn-in phase estimates it with O(N log T / p²) overhead.

## Key Results
- Regret upper bound O(∑ₖ:Δₖ>0 logT/Δₖ + N²logT/(pλN−1(Lap(G))) + KN²logT/p) captures impact of communication efficiency through link probability p and algebraic connectivity
- Nearly optimal regret lower bound Ω(∑ₖ:Δₖ>0 logT/Δₖ) showing centralized component is tight
- Theoretical guarantees hold for any p ∈ (0,1] without requiring connectivity assumptions
- Numerical experiments validate logarithmic regret growth and communication-revelation trade-off across graph topologies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random gossip communication enables global mean estimation despite time-varying graph disconnectivity.
- Mechanism: Each round t, agents share global estimates zᵢ,ₖ(t) with active neighbors via weight matrix Wₜ = I - (1/N)Lap(Gₜ). After τ* = O(N log(T)/(p·λN−1)) rounds, information propagates to all agents with high probability, enabling consensus on global mean rewards even when Gₜ is disconnected at individual time steps.
- Core assumption: Base graph G is connected; λN−1(Lap(G)) > 0.
- Evidence anchors:
  - [abstract]: "integrates the arm elimination strategy with the random gossip algorithm"
  - [Section 4, Eq. 4]: "zi,k(t+1) = Σ_{j∈Ni(t)∪{i}} [W_t]_{i,j}·z_j,k(t) + μ̂_i,k(t) - μ̂_i,k(t-1)"
  - [corpus]: Weak/missing direct corpus support for this specific gossip-Laplacian construction; related work uses gossip for consensus but under different assumptions.
- Break condition: If base graph G is disconnected, λN−1 = 0, and τ* → ∞, causing linear regret.

### Mechanism 2
- Claim: Arm elimination with minimum-pull-count selection ensures balanced exploration across agents, preventing any single agent's observations from dominating global estimates.
- Mechanism: Each agent selects arm argminₖ∈Sᵢ Tᵢ,ₖ(t) from its active set. This "round-robin within active set" policy guarantees |Tᵢ,ₖ(t) - Tⱼ,ₖ(t)| ≤ KL* for all agent pairs, ensuring global estimates zᵢ,ₖ(t) are not biased toward high-pulling agents.
- Core assumption: Communication eventually synchronizes active sets across agents (Lemma A.4).
- Evidence anchors:
  - [Section 4, Algorithm 1 Line 4]: "Select arm A_i(t) ∈ S_i with the minimum pull count T_{i,k}(t)"
  - [Section 4 text]: "ensures that, for every agent, each arm in the active set is pulled a roughly equal number of times"
  - [corpus]: Heterogeneous Multi-Agent Bandits with Parsimonious Hints uses similar balanced exploration rationales.
- Break condition: If agents eliminate arms at vastly different times (e.g., due to communication delays > L*), pull counts diverge and global estimates become unreliable.

### Mechanism 3
- Claim: Two-component confidence interval separates estimation error from consensus error, enabling correct arm elimination under delayed information.
- Mechanism: Confidence radius cᵢ,ₖ(t) = √(4log(T)/(N·max{Tᵢ,ₖ(t)-KL*,1})) + 4(√N + τ*)/max{Tᵢ,ₖ(t)-KL*,1}. First term: standard Hoeffding bound on reward variance. Second term: bound on gossip consensus error, decaying as τ* rounds pass.
- Core assumption: Estimation and consensus errors can be bounded independently; τ* sufficiently captures mixing time.
- Evidence anchors:
  - [Section 4, Eq. 5]: "ci,k(t) = √(4log(T)/(N·max{Ti,k(t)-KL*,1})) + 4(√N+τ*)/max{Ti,k(t)-KL*,1}"
  - [Section 4 text]: "first term captures the estimation error...second term captures the consensus error"
  - [corpus]: No direct corpus precedent for this specific two-component decomposition in MA-MAB.
- Break condition: If p is mis-specified (e.g., overestimated), τ* under-estimates true mixing time, consensus error bound fails, premature arm elimination occurs.

## Foundational Learning

- **Concept: Multi-armed bandit regret (stochastic)**
  - Why needed here: The paper's objective function; regret = cumulative suboptimality gap ∑ₜ Δ_{A(t)}. Understanding why O(log T) is "optimal" is prerequisite.
  - Quick check question: Explain why UCB achieves O(log T) regret while ε-greedy achieves O(√T) in the stochastic setting.

- **Concept: Gossip algorithms and consensus**
  - Why needed here: GSE relies on gossip-based information aggregation; Wₜ matrices must be doubly stochastic for convergence to uniform average.
  - Quick check question: Given weight matrix W = I - (1/d)Lap(G) for a d-regular graph G, prove that W is doubly stochastic and lim_{t→∞} W^t = (1/N)11^T.

- **Concept: Erdős-Rényi random graphs and algebraic connectivity**
  - Why needed here: Regret bound depends on λN−1(Lap(G)); understanding how p and graph topology affect mixing time is critical.
  - Quick check question: For a complete base graph with p=0.5, estimate the expected algebraic connectivity of the resulting random graph E[Gₜ].

## Architecture Onboarding

- **Component map:**
[Agent i] → Pull arm A_i(t) (min pull count)
    ↓
[Local reward X_{i,A_i(t)}(t)] → Update μ̂_{i,k}(t)
    ↓
[Active neighbors N_i(t)] → Receive z_{j,k}(t) from j ∈ N_i(t)
    ↓
[Gossip update] → z_{i,k}(t+1) = Σ_j [W_t]_{i,j}·z_{j,k}(t) + Δμ̂_i
    ↓
[Confidence bounds] → GUCB/GLCB computation
    ↓
[Arm elimination] → Remove k if GLCB_{k'} ≥ GUCB_k
    ↓
[Active set sync] → S_i ← ∩_{j∈N_i(t)∪{i}} S_j

- **Critical path:**
1. Initialize: S_i = [K], z_{i,k}(0) = 0, μ̂_{i,k}(0) = 0
2. Per-round: observe N_i(t), pull arm, receive reward, gossip update, check elimination, sync active set
3. Parameters needed: λ_{N-1}(Lap(G)) [known], p [can be estimated via burn-in], T, K, N

- **Design tradeoffs:**
  - **p (link probability):** Higher p → lower regret but higher communication cost (expected pN communications/round). Trade-off: Regret ∝ 1/p.
  - **Base graph topology:** Complete graph (λN−1=N) yields best regret but requires all-pairs connectivity. Grid/expanders have lower λ, higher regret.
  - **Burn-in for p estimation:** If p unknown, O(N log T / p²) regret overhead from estimation phase.

- **Failure signatures:**
  - **Linear regret growth:** Base graph G is disconnected → λN−1=0 → information never propagates → agents never learn global optimal.
  - **Premature optimal arm elimination:** Confidence bound τ* underestimated (e.g., p overestimated) → consensus error exceeds bound → optimal arm's GUCB falls below suboptimal arm's GLCB.
  - **Active set desynchronization:** Communication edges rarely activate (p too low, L* large) → agents eliminate arms at different times → pull count imbalance → biased global estimates.

- **First 3 experiments:**
1. **Validate O(1/p) scaling:** Fix N=10, K=5, complete base graph, vary p ∈ {0.1, 0.2, ..., 0.9}. Plot regret vs 1/p. Expected: linear relationship. Check: does log(Regret) ≈ -log(p) + const?
2. **Compare base graph topologies:** Fix N=16, K=5, p=0.5. Test: complete graph (λN−1=16), 4×4 grid (λN−1≈0.1), Petersen graph (λN−1=2). Expected: regret ∝ 1/λN−1. Verify ranking.
3. **Ablation: p estimation burn-in:** Run GSE with true p vs estimated p̂ (Algorithm 2). Measure regret overhead from burn-in phase. Expected: O(N log T / p²) additional regret when estimating.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can an algorithm achieve the optimal trade-off among regret, communication efficiency, and privacy in heterogeneous multi-agent multi-armed bandits (MA-MAB)?
- Basis in paper: [explicit] Section 7 (Conclusion and Future Work) states that achieving this optimal trade-off "points out a meaningful direction for future research," noting it has previously been studied only in homogeneous settings.
- Why unresolved: The current paper focuses on characterizing the regret-communication trade-off with heterogeneous rewards but does not incorporate privacy constraints or mechanisms (e.g., differential privacy) into the algorithmic design or analysis.
- What evidence would resolve it: An algorithm for heterogeneous MA-MAB that provides theoretical guarantees simultaneously bounding regret, communication rounds, and privacy loss (e.g., $\epsilon$-differential privacy).

### Open Question 2
- Question: Can the proposed gossip-based elimination framework be extended to contextual bandit settings with dynamic, non-stationary contexts?
- Basis in paper: [explicit] Section 7 identifies the extension to other reward models, specifically "contextual bandits, where rewards depend on dynamic, non-stationary contexts," as a valuable direction for future work.
- Why unresolved: The theoretical guarantees in this paper rely on stochastic, time-invariant reward distributions. The analysis does not cover scenarios where expected rewards change based on context vectors available to agents.
- What evidence would resolve it: A modified gossip algorithm that maintains $O(\log T)$ or sub-linear regret in a contextual setting, along with convergence proofs handling the interplay between context dimensionality and network connectivity.

### Open Question 3
- Question: Can a formal lower bound be derived that explicitly characterizes the regret dependency on the communication graph topology (link probability $p$ and algebraic connectivity)?
- Basis in paper: [explicit] Remark 5.10 notes that while the centralized regret term is tight, "providing a formal lower bound proof that fully characterizes this effect [of the communication graph] remains an interesting direction."
- Why unresolved: The current lower bound (Theorem 5.9) matches the centralized term but does not formally prove that the additional cost terms (e.g., $N^2 \log T / p$) are unavoidable; the paper currently relies on intuitive arguments regarding information propagation time.
- What evidence would resolve it: A derivation showing that any consistent policy on Erdős-Rényi networks must incur regret scaling inversely with the link probability $p$ or the spectral gap of the graph.

## Limitations

- The confidence interval design relies on theoretical bounds for gossip consensus that may not hold under finite-sample conditions, particularly when p is small or the base graph has low algebraic connectivity.
- The paper assumes perfect knowledge of p and λN−1(Lap(G)), which is unrealistic in practice and introduces additional regret overhead when these parameters must be estimated.
- The heterogeneous rewards assumption (μᵢ,ₖ = qᵢ·(k-1)/(K-1)) is relatively simple compared to more complex reward structures that might arise in real applications.

## Confidence

- **High confidence:** The structural claim that gossip-based consensus enables global learning despite time-varying network disconnectivity. This is well-supported by gossip algorithm theory and the specific weight matrix construction.
- **Medium confidence:** The regret upper bound O(∑ₖ:Δₖ>0 logT/Δₖ + N²logT/(pλN−1(Lap(G))) + KN²logT/p) holds for the theoretical construction, but the constants and practical performance may vary significantly based on graph topology and communication parameters.
- **Low confidence:** The nearly optimal lower bound proof Ω(∑ₖ:Δₖ>0 logT/Δₖ) and its tightness relative to the upper bound, as the distributed setting introduces additional complexity not fully captured in the lower bound analysis.

## Next Checks

1. **Validate τ* scaling:** Run GSE with varying p ∈ {0.1, 0.3, 0.5, 0.7, 0.9} on complete base graphs. Measure actual consensus error decay rate and verify it matches O(1/τ*) as predicted by τ* = O(N log(T)/(p·λN−1)).
2. **Test base graph topology sensitivity:** Fix N=16, K=5, p=0.5. Compare GSE performance on complete graph vs grid vs expander graphs. Verify regret scaling matches 1/λN−1(Lap(G)) predictions.
3. **Evaluate p estimation overhead:** Implement Algorithm 2 for burn-in phase. Measure regret overhead from p estimation across different true p values. Confirm O(N log T / p²) additional regret when p is unknown versus known.