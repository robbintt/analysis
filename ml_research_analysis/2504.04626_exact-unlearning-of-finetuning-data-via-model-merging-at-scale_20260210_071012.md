---
ver: rpa2
title: Exact Unlearning of Finetuning Data via Model Merging at Scale
arxiv_id: '2504.04626'
source_url: https://arxiv.org/abs/2504.04626
tags:
- unlearning
- merging
- merge
- tasks
- sift-masks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SIFT-Masks, a method for exact unlearning of
  fine-tuning data via model merging at scale. Existing approximate unlearning methods
  are brittle and can be attacked to reveal supposedly unlearned information, while
  exact unlearning methods have prohibitively expensive relearning costs.
---

# Exact Unlearning of Finetuning Data via Model Merging at Scale

## Quick Facts
- arXiv ID: 2504.04626
- Source URL: https://arxiv.org/abs/2504.04626
- Reference count: 40
- This paper proposes SIFT-Masks, a method for exact unlearning of fine-tuning data via model merging at scale, achieving up to 250x less compute for exact unlearning compared to other merging baselines while maintaining high accuracy.

## Executive Summary
This paper addresses the challenge of exact unlearning in federated learning scenarios where multiple local models are fine-tuned on separate tasks and merged into a global model. Existing approaches either provide only approximate unlearning that can leak information or require prohibitively expensive retraining. SIFT-Masks introduces a lightweight framework that enables efficient exact unlearning by constraining fine-tuning with a global sign vector and using local-only mask construction. The method achieves significant accuracy improvements (5-80%) over naive merging while using substantially less compute for unlearning operations.

## Method Summary
SIFT-Masks works by fine-tuning a pretrained model separately on each task, then merging these local models into a global model while applying task-specific masks for localization. The core innovation is using sign-fixed tuning with a global random sign vector to prevent destructive interference during merging, and constructing local masks that depend only on local information rather than the merged model. This enables exact unlearning through simple deterministic retraining and subtraction, avoiding the need to retrain all local models when one task is removed.

## Key Results
- SIFT-Masks improves accuracy by 5-80% over naive merging across four datasets (TOFU, Sent140, Reddit, StackOverflow)
- The method uses up to 250x less compute for exact unlearning compared to other merging baselines
- Particularly effective when data is heterogeneous across tasks, with diminishing returns for homogeneous data
- Demonstrates exact unlearning capability by deterministically reproducing and subtracting task vectors

## Why This Works (Mechanism)

### Mechanism 1: Sign-Fixed Tuning Eliminates Destructive Interference
Constraining all task vectors to share a pre-defined sign pattern prevents weight cancellation during merging. A global random sign vector is initialized before training, and gradient updates are projected to align with this vector, clipping weights with conflicting signs to zero rather than allowing them to oppose the global pattern.

### Mechanism 2: Local-Only Mask Construction Decouples Tasks for Exact Unlearning
Task-specific masks depend solely on local information, remaining valid after other tasks are removed. The sign constraint naturally induces sparsity, and masks are computed using only the local model and global sign vector without access to other tasks or the merged model.

### Mechanism 3: Exact Unlearning via Deterministic Retraining and Subtraction
When task vectors and masks are independent of the merged model, unlearning reduces to retraining one task and subtracting its vector. This approach is ~250x cheaper than full retraining because remaining task masks remain valid since they never depended on the removed task.

## Foundational Learning

- **Concept: Task Vectors and Model Arithmetic**
  - Why needed here: SIFT operates on task vectors (τ = M_finetuned - M_pretrained), not raw weights
  - Quick check: Given pretrained M0 and finetuned M1, what is the task vector? If you have task vectors τ1 and τ2, what is the merged model? (Answer: τ1 = M1 - M0; M_merged = M0 + τ1 + τ2)

- **Concept: Exact vs Approximate Unlearning**
  - Why needed here: The paper critiques approximate unlearning as attackable and positions SIFT as exact
  - Quick check: After exact unlearning of task u from model trained on {1,2,...,T}, what model should result? (Answer: The model identical to one trained on {1,2,...,T}\{u} from scratch)

- **Concept: Sign Conflicts in Weight Averaging**
  - Why needed here: The core insight is that when averaging many task vectors, opposing signs at the same parameter cancel destructively
  - Quick check: If task A has weight +0.5 and task B has weight -0.3 at the same position, what is their average? Why might this be problematic? (Answer: +0.1—the signals partially cancel, reducing useful information from both tasks)

## Architecture Onboarding

- **Component map:**
  - Pretrained model M0 (frozen, shared foundation)
  - Global sign vector v ∈ {+1, -1}^d (random, initialized once before all training, stored)
  - Per-task: task vector τt (transient), mask mt ∈ {0,1}^d (stored at 1/32 model size via boolean encoding)
  - Merged model: M = M0 + Σt τt (single copy stored)
  - Inference path: For task t query, apply mask: M_t = M0 + mt ⊙ (Σ τi) / |T|

- **Critical path:**
  1. Initialize v = sign(random_uniform(d) - 0.5) before any training begins
  2. For each task t: finetune M0 on local data, projecting τt ← τt ⊙ 1{τt ⊙ v ≥ 0} after each gradient step
  3. Extract and store mask mt = 1{τt ⊙ v > 0}; discard τt or accumulate into merged model
  4. Merge: τ_global = Σt τt; discard individual τt
  5. To unlearn task u: deterministically retrain to get τu, update τ_global ← τ_global - τu, discard mu

- **Design tradeoffs:**
  - Storage overhead: M(1 + T/32) for model + masks vs M for naive merge—acceptable for T up to ~500
  - Finetuning constraint: Sign projection may slightly slow convergence (~2x more steps needed at early training)
  - Data heterogeneity sensitivity: Benefits strongest when tasks have conflicting/unique data; diminishing returns for homogeneous data

- **Failure signatures:**
  - Performance degrades to zeroshot level if merging >100 models without masks
  - Unlearning produces incorrect model if retraining isn't perfectly deterministic
  - Local model underperforms baseline if sign constraint is too restrictive for the task
  - Marginal benefit vs Central FT when task data is highly overlapping/homogeneous

- **First 3 experiments:**
  1. **Sanity check—sign constraint impact**: Compare per-task accuracy of SIFT vs standard FT before any merging
  2. **Scaling validation**: Merge 1→200→500 models, plot accuracy for FT+Merge, SIFT+Merge, SIFT-Masks
  3. **Exact unlearning verification**: Unlearn task u, compare resulting model weights to a freshly-merged model that never included u

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does replacing the random global sign vector with a data-informed initialization improve SIFT-Mask performance without compromising the local independence required for efficient unlearning?
- Basis in paper: The method section states that SIFT initializes a "uniformly random sign vector" that is independent of the tasks, but the authors do not investigate if this random choice is optimal or if learned signs could boost utility.
- What evidence would resolve it: Experiments comparing the accuracy of models finetuned with random sign vectors versus those initialized using the pre-trained model's weight signs or a meta-learned global vector.

### Open Question 2
- Question: Can the merged model quality be improved beyond simple averaging to handle interference at scales significantly larger than 500 tasks?
- Basis in paper: The Conclusion explicitly states that "future work should focus on (1) ways to improve the quality of the merged model," noting that naive averaging is the current standard in the proposed pipeline.
- What evidence would resolve it: A study applying non-linear merging techniques (e.g., surgical merging or routing) that respect the sign-fixed constraints, tested on merging 1,000+ tasks.

### Open Question 3
- Question: To what extent does data heterogeneity determine the viability of merging-based unlearning versus centralized training?
- Basis in paper: The results show Central FT outperforms SIFT-Masks on StackOverflow (homogeneous data), whereas SIFT excels on heterogeneous datasets like Reddit.
- What evidence would resolve it: A controlled ablation synthesizing datasets with varying degrees of overlap between tasks to plot the performance crossover point between Central FT and SIFT-Masks.

## Limitations
- Performance gains appear highly dependent on task heterogeneity, with diminishing benefits when tasks share similar data distributions
- Exact unlearning claims assume perfect determinism in training, which may not hold across different hardware configurations
- The method focuses on LLM unlearning but doesn't address potential privacy leakage through model artifacts beyond task vectors

## Confidence
- **High Confidence**: The core mechanism of sign-fixed tuning preventing destructive interference during merging is well-supported by experimental results across four datasets with up to 500 models
- **Medium Confidence**: The efficiency claims (250x reduction in unlearning compute) are demonstrated but rely on ideal conditions including perfect determinism
- **Medium Confidence**: The claim that local-only masks perform comparably to globally-optimized masks is supported by results on four datasets but lacks broader validation

## Next Checks
1. **Robustness Testing**: Validate SIFT-Masks performance across additional datasets with varying degrees of task heterogeneity
2. **Determinism Validation**: Test unlearning exactness across different hardware configurations and training frameworks
3. **Architecture Generalization**: Evaluate SIFT-Masks on non-LLM architectures to assess whether sign-fixing benefits generalize beyond language modeling scenarios