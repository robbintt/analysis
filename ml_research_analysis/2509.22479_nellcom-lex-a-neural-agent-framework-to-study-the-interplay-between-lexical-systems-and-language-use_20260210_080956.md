---
ver: rpa2
title: 'NeLLCom-Lex: A Neural-agent Framework to Study the Interplay between Lexical
  Systems and Language Use'
arxiv_id: '2509.22479'
source_url: https://arxiv.org/abs/2509.22479
tags:
- context
- agents
- color
- training
- informativeness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NeLLCom-Lex is a neural-agent framework that simulates lexical
  semantic change by grounding agents in a real language and systematically manipulating
  their communicative needs. Using a color naming task, agents first learn human-like
  color labels through supervised learning, then adapt their naming behavior through
  reinforcement learning in context-sensitive communication games.
---

# NeLLCom-Lex: A Neural-agent Framework to Study the Interplay between Lexical Systems and Language Use

## Quick Facts
- arXiv ID: 2509.22479
- Source URL: https://arxiv.org/abs/2509.22479
- Reference count: 16
- Neural agents reproduce human-like color naming patterns through context-sensitive pragmatic adaptation

## Executive Summary
NeLLCom-Lex is a neural-agent framework that simulates lexical semantic change by grounding agents in a real language and systematically manipulating their communicative needs. Using a color naming task, agents first learn human-like color labels through supervised learning, then adapt their naming behavior through reinforcement learning in context-sensitive communication games. Experiments show that agents trained with context access develop pragmatic naming behavior, using more informative words in harder contexts, and achieve human-like system-level informativeness (IL=2.6 vs. 2.78 for humans) and lexical diversity (34.5 word types vs. 49 for humans). When exposed to different communicative needs during training, agents adapt their lexicons accordingly, with those trained on difficult contexts showing stronger pragmatic adaptation.

## Method Summary
The framework uses referential communication games where a speaker agent must describe a target color among two distractors using a single word, while a listener agent identifies the target. Agents are FNNs with three color encoders (target + 2 distractors) concatenated and processed through shared layers to produce word distributions. The framework uses a two-phase learning approach: supervised learning on human color naming data establishes initial lexical grounding, then reinforcement learning optimizes communicative success. Context access is manipulated by either including or zeroing distractor embeddings during training.

## Key Results
- Context-aware agents develop pragmatic naming behavior, using more informative words in harder contexts (β(E_ctx) = -0.002 to -0.003)
- Two-phase learning (SL→RL) produces human-like lexical properties: IL=2.6 vs. human 2.78, lexical diversity 34.5 vs. human 49 word types
- Communicative need distribution shapes lexical granularity: AllClose agents show strongest pragmatic adaptation (β = -0.005)

## Why This Works (Mechanism)

### Mechanism 1: Context-Contingent Lexical Selection
- Claim: Access to distractor context during training enables agents to modulate word informativeness based on communicative difficulty.
- Mechanism: The speaker encodes target + distractors jointly; when distractors are similar to target (hard context), the network learns to select narrower terms (e.g., "sage" vs. "green"). During RL, reward feedback reinforces context-appropriate choices.
- Core assumption: The mapping from perceptual similarity to lexical granularity is learnable from human naming data plus reward signal.
- Evidence anchors: [abstract] "Context access during training and communication pressure are key to these behaviors." [Section 5.1] Agents with context access show significant negative β(E_ctx) (-0.002 to -0.003); agents without context show β ≈ 0.

### Mechanism 2: Two-Phase Learning Grounds Then Adapts
- Claim: Supervised pre-training on human data provides lexical grounding; RL then optimizes for communicative efficiency.
- Mechanism: SL establishes word-to-color mappings via cross-entropy loss. RL with REINFORCE then shifts word usage toward communicative success, expanding vocabulary and adjusting informativeness.
- Core assumption: The human naming corpus contains sufficient structure to bootstrap; RL can refine without catastrophic forgetting.
- Evidence anchors: [abstract] "agents first learn to 'speak' English through supervised learning, then adapt via reinforcement learning" [Section 5.1, Table 1] SL+ alone yields 12.7 word types; SL+RL+ yields 34.5 (human: 49).

### Mechanism 3: Communicative Need Distribution Shapes Lexicon Granularity
- Claim: The distribution of context difficulty during RL training affects lexical granularity and pragmatic sensitivity.
- Mechanism: Agents trained on hard (close) contexts develop finer-grained lexicons; agents trained on easy (far) contexts generalize more coarsely.
- Core assumption: Lexical adaptation occurs within a single generation via accumulated interaction experience.
- Evidence anchors: [Section 5.2, Table 2] AllClose condition shows strongest context sensitivity (β = -0.005); AllFar shows weakest (β = -0.003) [Section 5.2, Figure 5] "pink" spans broader CIELAB region in AllFar (lower I_w) vs. narrower region in AllClose (higher I_w).

## Foundational Learning

- **Referential Communication Games (Lewis Games)**
  - Why needed here: The core task is a discriminative reference game—speaker must enable listener to identify target among distractors.
  - Quick check question: Can you explain why communication success depends on both speaker informativeness and listener interpretation?

- **Policy Gradient / REINFORCE**
  - Why needed here: RL phase uses REINFORCE to optimize communication success; understanding the gradient estimator is essential for debugging.
  - Quick check question: How does the reward signal r_L = log p(i|w,c; θ_L) shape speaker policy?

- **Rational Speech Acts (RSA) Basics**
  - Why needed here: The paper situates pragmatic adaptation in RSA tradition; informativeness vs. effort trade-offs are central.
  - Quick check question: Why would a rational speaker use "Dalmatian" in a context with other dogs but "dog" when no dogs are present?

## Architecture Onboarding

- **Component map:**
  - Speaker: Three FNN encoders (target + 2 distractors) → concatenation → FNN → softmax over vocabulary V
  - Listener: FNN encoder per color candidate (3) + word embedding → dot-product similarity → softmax over positions
  - Context manipulation: Distractor embeddings zeroed in context-unaware condition

- **Critical path:**
  1. SL phase: Train speaker to predict human labels given (target, distractors); train listener to identify target given label + shuffled triplet.
  2. RL phase: Joint optimization via REINFORCE; speaker samples word, listener predicts position, reward = log-probability of correct position.

- **Design tradeoffs:**
  - Context-aware vs. context-unaware speaker: Awareness enables pragmatics but requires more training data.
  - RL context distribution: AllClose maximizes pragmatic sensitivity; AllFar risks uniform coarseness.
  - Semantic drift vs. human-likeness: RL improves lexical properties but diverges from human prototypes.

- **Failure signatures:**
  - No pragmatic adaptation (flat β(E_ctx)): Check context encoder; distractors may be zeroed.
  - Tiny vocabulary (<15 types): Likely missing RL phase or context access.
  - Low close-context accuracy (<70%): Insufficient hard-context training.

- **First 3 experiments:**
  1. Replicate SL+RL+ vs. SL−RL− comparison; verify β(E_ctx) significant only with context.
  2. Vary RL context distribution (AllFar/AllClose); confirm informativeness shifts in color denotation plots.
  3. Ablate listener: freeze listener after SL; observe whether speaker still adapts pragmatically (tests co-adaptation necessity).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does varying the entropy regularization parameter influence agents' pragmatic naming behavior and emergent lexicon structure?
- Basis in paper: [explicit] Authors state: "Future work could explore how varying the entropy regularization parameter influences agents' pragmatic naming behavior and contributes to the shaping of their emergent lexicon."
- Why unresolved: Current study uses fixed entropy regularization (0.15); relationship between regularization strength, pragmatic adaptation, and lexical diversity remains untested.
- What evidence would resolve it: Systematic experiments varying entropy regularization values while measuring pragmatic adaptation (β values), lexical diversity (|W|), and system-level informativeness (I_L).

### Open Question 2
- Question: Can NeLLCom-Lex simulate specific lexical semantic change phenomena like meaning narrowing and broadening?
- Basis in paper: [explicit] Authors explicitly plan: "In future work, we plan to use NeLLCom-Lex to simulate specific instances of lexical semantic change, such as meaning narrowing and broadening."
- Why unresolved: Current study validates general framework on color naming but does not test whether agents exhibit targeted semantic shifts characteristic of diachronic change.
- What evidence would resolve it: Exposing agents to manipulated communicative environments designed to trigger narrowing/broadening and measuring prototype shifts and informativeness changes comparable to documented historical cases.

### Open Question 3
- Question: Is exposure to difficult contexts more important than exposure to context variety for developing adaptive pragmatic behavior?
- Basis in paper: [inferred] Authors note: "This suggests that dealing with more specific contexts may be more important than being exposed to qualitatively different contexts, though further tests are needed to probe this hypothesis."
- Why unresolved: AllClose agents showed strongest context sensitivity, but confounds exist between context difficulty and training distribution composition.
- What evidence would resolve it: Controlled experiments systematically varying difficulty levels and context type variety independently to isolate their effects on pragmatic adaptation metrics.

### Open Question 4
- Question: How do agents' internal word embedding representations change through interaction, and how do these changes relate to observed semantic drift in production?
- Basis in paper: [explicit] Authors state: "We leave to future work a more in-depth analysis of how the agents' word embedding spaces change through interaction, and how those changes relate to the semantic drift observed in the agents' production."
- Why unresolved: Preliminary visualization shows embedding changes during RL, but quantitative relationship between embedding space restructuring and production drift (D_L) remains unexamined.
- What evidence would resolve it: Correlational analyses between embedding similarity shifts and semantic drift distances across training epochs and conditions.

## Limitations
- Transferability of results: Findings based on color naming task may not generalize to more complex lexical domains or languages with different color terminology systems.
- Model architecture constraints: Simplified FNN-based design may not capture all aspects of human semantic processing; relies on perfect color perception assumption.
- Single-generation adaptation: RL phase simulates lexical change within a single agent's lifetime rather than across generations.

## Confidence
- High Confidence: Context access during training is necessary for pragmatic naming behavior; two-phase learning (SL→RL) produces more human-like lexical properties than either phase alone; communicative need distribution shapes lexical granularity.
- Medium Confidence: The model captures core mechanisms of lexical semantic change; neural agents can serve as valid tools for studying language evolution; pragmatic adaptation occurs through context-contingent word selection.
- Low Confidence: Generalizability to other semantic domains beyond color; exact correspondence between model parameters and human cognitive processes; long-term stability of learned lexical systems.

## Next Checks
1. **Cross-linguistic validation**: Test whether the framework reproduces lexical patterns in languages with different color terminology systems (e.g., languages with fewer/more basic color terms) to assess generalizability beyond English color naming.

2. **Domain transfer experiment**: Apply the same framework to a non-color semantic domain (e.g., animal names or shape categories) to verify whether context-aware pragmatic adaptation and communicative need-driven lexical change are domain-general phenomena.

3. **Ablation on context encoding**: Systematically vary the amount of contextual information provided to the speaker (from full distractor embeddings to minimal summary features) to identify the minimal context requirements for pragmatic adaptation.