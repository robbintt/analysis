---
ver: rpa2
title: Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing
  Scene Description
arxiv_id: '2512.11098'
source_url: https://arxiv.org/abs/2512.11098
tags:
- infrared
- thermal
- zero-shot
- images
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents VLM-IRIS, a zero-shot framework that adapts
  vision-language models (VLMs) to thermal infrared imagery for object presence detection
  in additive manufacturing. The framework preprocesses infrared images into RGB-compatible
  inputs and applies centroid-based prompt ensembling with CLIP ViT-B/32 to achieve
  high accuracy without model retraining.
---

# Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing Scene Description

## Quick Facts
- arXiv ID: 2512.11098
- Source URL: https://arxiv.org/abs/2512.11098
- Authors: Nazanin Mahjourian; Vinh Nguyen
- Reference count: 35
- Primary result: VLM-IRIS framework achieves 100% accuracy for object presence detection in infrared additive manufacturing using CLIP ViT-B/32 with magma colormap preprocessing and centroid-based prompt ensembling.

## Executive Summary
This paper introduces VLM-IRIS, a zero-shot framework that adapts vision-language models (VLMs) to thermal infrared imagery for object presence detection in additive manufacturing environments. The framework addresses the challenge of using pre-trained VLMs, originally trained on RGB data, to interpret thermal infrared images without requiring costly retraining. By preprocessing infrared images into RGB-compatible inputs and applying centroid-based prompt ensembling with CLIP ViT-B/32, the system achieves high accuracy for monitoring objects in low-light manufacturing settings.

The research demonstrates that appropriate preprocessing and prompt design can enable VLMs to effectively interpret thermal scenes in additive manufacturing contexts. Experiments conducted on a 3D printer testbed show that the magma colormap preprocessing with centroid prompting achieves perfect accuracy under room-temperature conditions, outperforming alternative approaches such as grayscale and viridis color mappings. This label-free approach offers a promising solution for industrial sensing where traditional computer vision methods may struggle due to lighting constraints.

## Method Summary
The VLM-IRIS framework preprocesses thermal infrared images into RGB-compatible inputs using color mapping techniques, specifically employing the magma colormap which preserves thermal gradient information effectively. The preprocessed images are then processed through CLIP ViT-B/32, a vision-language model originally trained on RGB data. A centroid-based prompt ensembling approach is applied to enhance detection accuracy by combining multiple prompts centered around detected object regions. This zero-shot method enables object presence detection without requiring model retraining or labeled thermal datasets, making it particularly suitable for industrial additive manufacturing environments where lighting conditions may be suboptimal for traditional computer vision approaches.

## Key Results
- VLM-IRIS framework achieves 100% accuracy for object presence detection under room-temperature conditions in a 3D printer testbed
- Magma colormap preprocessing outperforms grayscale and viridis approaches for thermal image conversion to RGB format
- CLIP ViT-B/32 with centroid-based prompt ensembling provides effective zero-shot detection without model retraining
- Framework successfully demonstrates that VLMs trained on RGB data can interpret thermal infrared imagery when supported by appropriate preprocessing

## Why This Works (Mechanism)
The framework works by bridging the domain gap between thermal infrared imagery and RGB-trained vision-language models. Thermal images contain temperature-based intensity information rather than color information, so the preprocessing step converts this thermal data into a visual format that CLIP can interpret while preserving the essential thermal gradients. The magma colormap is particularly effective because it provides a perceptually uniform mapping that maintains temperature relationships. The centroid-based prompt ensembling technique improves detection by focusing the model's attention on object-centered regions and combining multiple perspectives, compensating for potential ambiguities in the thermal representation.

## Foundational Learning
- **Thermal-infrared imaging**: Captures heat radiation rather than visible light; needed to understand the input domain and why standard RGB models struggle with raw thermal data
- **Vision-language models (VLMs)**: Jointly trained on image-text pairs; needed to understand the foundation of CLIP and how it learns cross-modal representations
- **Color mapping techniques**: Methods to convert single-channel thermal data to RGB format; needed to understand how to make thermal images interpretable by RGB-trained models
- **Centroid-based prompt ensembling**: Technique to combine multiple prompts centered on detected regions; needed to understand how to improve detection accuracy in the thermal domain
- **Zero-shot learning**: Ability to perform tasks without task-specific training; needed to understand why this approach avoids costly retraining
- **Additive manufacturing environments**: 3D printing contexts with specific lighting and thermal characteristics; needed to understand the application domain constraints

## Architecture Onboarding
**Component map**: Thermal Camera -> Preprocessor (Magma Colormap) -> CLIP ViT-B/32 -> Prompt Ensembler (Centroid-based) -> Detection Output

**Critical path**: The thermal image flows through the preprocessing stage where the magma colormap converts temperature data to RGB representation, then through CLIP ViT-B/32 for feature extraction, and finally through the centroid-based prompt ensembler for object detection.

**Design tradeoffs**: The framework trades model specificity for generalizability by using zero-shot learning instead of fine-tuning. While this avoids the need for labeled thermal datasets, it may not achieve optimal performance in more complex thermal scenarios. The magma colormap choice represents a balance between perceptual uniformity and computational efficiency.

**Failure signatures**: The system may struggle with objects that have similar temperatures to their background, thermal noise in industrial environments, or temperature gradients that don't map well to the chosen colormap. Objects with very small temperature differences may be indistinguishable after colormap conversion.

**First experiments**: 1) Test accuracy across different ambient temperature ranges beyond room temperature; 2) Compare magma colormap performance against alternative color mappings like viridis and plasma in varied thermal conditions; 3) Evaluate detection performance with objects at different distances and angles from the thermal camera.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions for future research.

## Limitations
- Framework relies on controlled, room-temperature operating conditions which may not generalize to industrial environments with varying thermal backgrounds
- Magma colormap preprocessing, while effective in tested scenarios, may not be optimal across diverse thermal imaging contexts
- Study uses a single 3D printer testbed, limiting generalizability to other additive manufacturing processes
- Zero-shot approach may have limitations in complex thermal scenarios requiring fine-tuned domain adaptation

## Confidence
- Accuracy claims under controlled conditions: High
- Generalization to industrial environments: Low
- Effectiveness of magma colormap preprocessing: Medium
- Zero-shot capability without retraining: High

## Next Checks
1. Test framework accuracy across a wider temperature range (e.g., 15-35Â°C) to evaluate robustness beyond room temperature
2. Conduct experiments with multiple 3D printer models and additive manufacturing processes to assess generalizability
3. Compare detection performance with fine-tuned models on labeled thermal datasets to quantify the zero-shot approach's limitations