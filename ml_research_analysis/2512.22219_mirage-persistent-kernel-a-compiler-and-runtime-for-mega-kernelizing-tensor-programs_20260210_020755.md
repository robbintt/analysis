---
ver: rpa2
title: 'Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor
  Programs'
arxiv_id: '2512.22219'
source_url: https://arxiv.org/abs/2512.22219
tags:
- task
- tasks
- kernel
- event
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MPK addresses the limitations of kernel-per-operator GPU execution
  by automatically transforming multi-GPU model inference into a single high-performance
  mega-kernel. It introduces an SM-level graph representation (tGraph) that captures
  data dependencies at the granularity of individual streaming multiprocessors, enabling
  cross-operator software pipelining and fine-grained kernel overlap.
---

# Mirage Persistent Kernel: A Compiler and Runtime for Mega-Kernelizing Tensor Programs

## Quick Facts
- **arXiv ID:** 2512.22219
- **Source URL:** https://arxiv.org/abs/2512.22219
- **Reference count:** 40
- **Primary result:** MPK reduces end-to-end inference latency by up to 1.7x compared to SGLang and vLLM

## Executive Summary
MPK addresses the limitations of kernel-per-operator GPU execution by automatically transforming multi-GPU model inference into a single high-performance mega-kernel. It introduces an SM-level graph representation (tGraph) that captures data dependencies at the granularity of individual streaming multiprocessors, enabling cross-operator software pipelining and fine-grained kernel overlap. The MPK compiler generates optimized SM-level task graphs and CUDA implementations, while the in-kernel parallel runtime executes these tasks within a single mega-kernel using decentralized scheduling. Evaluation shows MPK reduces end-to-end inference latency by up to 1.7x compared to existing kernel-per-operator LLM serving systems like SGLang and vLLM, pushing performance close to hardware limits.

## Method Summary
MPK transforms PyTorch models into a single mega-kernel through compiler-driven operator decomposition and runtime-managed execution. The MPK compiler lowers models to an SM-level task graph (tGraph) that captures dependencies at streaming multiprocessor granularity, enabling fine-grained synchronization and task overlap. The in-kernel runtime executes these tasks using a decentralized scheduling approach with workers and schedulers launched via `torch.compile(backend="MPK")`. The system handles both static and dynamic workloads through hybrid JIT/AOT task launch strategies, with a paged shared-memory abstraction enabling cross-task pipelining. The compiler generates CUDA code using the Mirage superoptimizer, while the runtime manages task queues, event synchronization, and shared memory allocation across SMs.

## Key Results
- MPK reduces end-to-end inference latency by up to 1.7x compared to SGLang and vLLM
- Achieves 1.0-1.7x throughput improvement across five models and three GPU generations (A100, H100, B200)
- Cross-task pipelining reduces task runtime by 1.2-1.3x and outperforms cuBLAS compiled kernels

## Why This Works (Mechanism)

### Mechanism 1: SM-Level Task Graph (tGraph) Representation
Representing dependencies at SM granularity rather than kernel granularity exposes parallelism previously hidden by coarse-grained kernel barriers. MPK decomposes operators into tasks assigned to individual SMs, with events as synchronization points. Each task depends on at most one event and triggers at most one event (after normalization), enabling a linearized representation where contiguous task groups share triggering events. This permits tasks from different operators (e.g., MatMul and AllReduce) to execute concurrently when data dependencies permit. The core assumption is that the overhead of managing fine-grained events and task queues is lower than the latency cost of kernel barriers and pipeline bubbles.

### Mechanism 2: Paged Shared-Memory Abstraction for Cross-Task Pipelining
Partitioning shared memory into pages enables pre-loading data for the next task while computing the current task, eliminating pipeline bubbles between operators. Tasks acquire and release shared-memory pages monotonically. When a task signals release, the runtime preallocates pages for the next task and begins TMA-based data prefetch. The pre-loading phase of task T2 overlaps with the compute phase of task T1, with intra-SM barriers preventing conflicts. The core assumption is that sufficient shared-memory pages exist to support overlapping; TMA and compute units can operate concurrently without contention.

### Mechanism 3: Hybrid JIT/AOT Task Launch for Dynamic Workloads
Combining just-in-time and ahead-of-time task dispatch balances load-distribution flexibility with low-latency dispatch overhead. Tasks from operators with data-dependent durations (e.g., attention) use JIT launch—schedulers assign tasks only after dependencies clear, enabling work-stealing. Tasks from predictable operators use AOT launch—pre-enqueued to workers, who wait locally on event activation (single synchronization vs. two). Workers prioritize JIT tasks; AOT tasks execute when JIT queues empty and dependencies are satisfied. The core assumption is that most operators have predictable execution times; only a subset (attention) induces imbalance that JIT mitigates.

## Foundational Learning

- **Kernel Barriers and CUDA Execution Model**: MPK's core value proposition is eliminating kernel barriers. Understanding that GPUs implicitly synchronize between consecutive kernel launches on the same stream is essential to grasp why mega-kernels enable cross-operator pipelining. *Quick check:* Why can't two dependent kernels (e.g., MatMul followed by AllReduce) overlap execution in standard CUDA?

- **Software Pipelining on Heterogeneous GPUs**: MPK exploits TMA (Tensor Memory Accelerator), Tensor Cores, and CUDA Cores operating concurrently. Software pipelining interleaves data movement and compute across iterations. *Quick check:* What hardware units can operate simultaneously during a software-pipelined GEMM, and what prevents cross-operator pipelining in kernel-per-operator execution?

- **Thread Block Scheduling and SM Assignment**: tGraph represents tasks at SM granularity. Understanding that thread blocks map to SMs and that CUDA provides no cross-block synchronization within a kernel clarifies why MPK needs its own event-driven coordination. *Quick check:* How does MPK coordinate dependencies across SMs without hardware support for cross-block synchronization?

## Architecture Onboarding

- **Component map:** MPK Compiler (input → operator decomposition → dependency analysis → event fusion → tGraph normalization → tGraph linearization → CUDA code generation) → In-Kernel Runtime (workers → schedulers → shared memory manager)
- **Critical path:** Start event enqueued to scheduler → scheduler activates event, dispatches dependent tasks to workers → workers execute tasks, notify triggering events → events activate when counter reaches zero, enqueue to scheduler → repeat until terminal event
- **Design tradeoffs:** JIT vs. AOT (flexibility vs. latency), task granularity (parallelism vs. overhead), worker/scheduler ratio (contention vs. compute resources)
- **Failure signatures:** Deadlock (missing notification, incorrect counter initialization), shared-memory exhaustion (tasks stall waiting for pages), load imbalance (some workers idle while others have deep queues)
- **First 3 experiments:** 1) Validate tGraph correctness with simple 2-operator graph and instrumented event counters, 2) Measure pipelining benefit comparing single-operator runtime with cross-task pipelining enabled vs. disabled, 3) Profile worker utilization collecting per-SM task completion counts to verify load balancing

## Open Questions the Paper Calls Out

- **Global scheduling coordination:** What are the performance trade-offs of globally coordinated scheduling strategies compared to MPK's current decentralized approach? The paper notes this as an interesting direction for future work but hasn't evaluated scenarios where global coordination might improve load balancing or reduce tail latency.

- **Memory overhead for dynamic batch sizes:** Does generating multiple specialized tGraphs for dynamic batch sizes induce prohibitive memory overhead at scale? The paper doesn't quantify the storage overhead of maintaining multiple compiled graphs in device memory, which could limit the effective batch size range for memory-constrained GPUs.

- **Wide model architectures:** How does MPK's performance scale with "wide" model architectures that have high operator parallelism? The evaluation focuses exclusively on sequential LLM workloads, leaving the efficiency of the normalization transformation on highly parallel architectures unverified.

## Limitations
- Generalization beyond LLM architectures remains untested, particularly for models with different computational patterns
- Effectiveness of paged shared-memory abstraction under extreme memory pressure scenarios hasn't been thoroughly validated
- Hybrid JIT/AOT launch strategy assumes most operators have predictable runtimes, which may not hold for all workloads

## Confidence

- **High Confidence:** The core claim that mega-kernels eliminate kernel barriers and reduce launch overhead is well-established. Performance gains over SGLang and vLLM are directly measurable and reproducible.
- **Medium Confidence:** The SM-level task graph representation's ability to expose cross-operator parallelism depends on specific model structure and batch size. Benefits may vary significantly across different model architectures.
- **Low Confidence:** The paged shared-memory abstraction's effectiveness under extreme memory pressure scenarios hasn't been thoroughly validated. The claimed 1.2-1.3x speedup from cross-task pipelining may not hold for models with different memory access patterns.

## Next Checks

1. **Cross-Architecture Validation:** Evaluate MPK on non-LLM models (e.g., ViT, diffusion models) to verify the tGraph mechanism generalizes beyond transformer architectures.

2. **Memory Pressure Stress Test:** Systematically vary tensor sizes and shared-memory page counts to identify the breaking point where cross-task pipelining degrades or fails.

3. **AOT-Only Baseline:** Implement and benchmark an MPK variant using only AOT task launch to quantify the actual contribution of JIT launch to the reported performance gains.