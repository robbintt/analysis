---
ver: rpa2
title: Semi-Supervised Hierarchical Open-Set Classification
arxiv_id: '2601.16541'
source_url: https://arxiv.org/abs/2601.16541
tags:
- data
- training
- learning
- class
- classes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces semi-supervised hierarchical open-set classification,
  a new problem setting that enables the use of large unlabeled datasets in hierarchical
  novelty detection. The core method introduces subtree pseudo-labels, which provide
  robust supervision for OOD data by indicating membership within a specific subtree
  rather than committing to a specific class.
---

# Semi-Supervised Hierarchical Open-Set Classification

## Quick Facts
- **arXiv ID:** 2601.16541
- **Source URL:** https://arxiv.org/abs/2601.16541
- **Authors:** Erik Wallin; Fredrik Kahl; Lars Hammarstrand
- **Reference count:** 40
- **Primary result:** SemiHOC matches full ID supervision using only 20 labels per class on iNaturalist19.

## Executive Summary
This paper introduces semi-supervised hierarchical open-set classification, enabling large unlabeled datasets to improve hierarchical novelty detection. The core innovation is subtree pseudo-labels, which provide robust supervision for OOD data by indicating membership within a specific subtree rather than committing to a specific class. An age-gating mechanism prevents overconfident, overly specific predictions of OOD data by blocking pseudo-labels assigned unexpectedly late during training. The proposed SemiHOC framework integrates these components with a teacher-student architecture using ProHOC for hierarchical predictions. Experiments on iNaturalist19 show that SemiHOC matches the performance of full ID supervision while using only 20 labels per class, outperforming self-supervised pretraining followed by supervised adaptation.

## Method Summary
SemiHOC extends hierarchical open-set classification to semi-supervised learning by using subtree pseudo-labels for unlabeled data. The framework uses a teacher-student architecture with DinoV2 ViT-L/14 backbone (frozen) and depth-specific classification heads. Subtree pseudo-labels are generated by summing hierarchical probabilities over subtrees and thresholding at 0.95 confidence. Age-gating prevents overconfident, overly specific predictions by blocking pseudo-labels assigned late in training based on assignment frequency patterns. The method builds on ProHOC, which factorizes hierarchical prediction into conditional probabilities from depth-specific networks, avoiding manual bias parameters for ID/OOD trade-offs.

## Key Results
- SemiHOC achieves BMHD Mix of 2.21 on iNaturalist19 with 20 labels per class, matching full ID supervision performance
- Outperforms self-supervised pretraining + supervised adaptation by significant margin on hierarchical open-set metrics
- Subtree pseudo-labels provide robust supervision where standard node-level pseudo-labels fail for OOD data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Aggregating class probabilities into **subtree pseudo-labels** creates a reliable supervision signal for OOD data where standard node-specific pseudo-labels fail.
- **Mechanism:** Standard confidence-based pseudo-labeling assumes high confidence correlates with accuracy. For OOD samples, node-level confidence is noisy, but the probability mass generally accumulates within the correct sub-branch of the hierarchy. By summing probabilities over a subtree (an internal node and all its descendants), the method achieves high precision at high confidence thresholds, allowing safe pseudo-labeling of unknown classes at a coarse level.
- **Core assumption:** The feature representation is sufficiently structured such that OOD samples share more visual features with the correct ancestor node than with unrelated branches.
- **Evidence anchors:**
  - [abstract] Mentions subtree pseudo-labels provide robust supervision by indicating membership within a specific subtree.
  - [section 3.3] Fig. 2 shows that while node confidence (top panel) is uncorrelated with accuracy for OOD, subtree confidence (bottom panel) restores the correlation, enabling high precision.
  - [corpus] *ProSub* highlights the general difficulty of using softmax confidence for OOD detection in open-set SSL, validating the need for probabilistic relaxation.

### Mechanism 2
- **Claim:** **Age-gating** mitigates the accumulation of errors by preventing overconfident, overly specific pseudo-label assignments that occur late in training.
- **Mechanism:** The authors observe that correct hierarchical assignments for OOD data typically occur early in training. As training progresses, the model tends to "overshoot" and incorrectly assign OOD samples to overly deep (specific) nodes. Age-gating logs the epoch of the first pseudo-label assignment per sample; if the assignment frequency for a node drops significantly after an initial peak, a cutoff is triggered to block new assignments for that node.
- **Core assumption:** Correct hierarchical generalization happens faster than the overfitting/confidence drift that causes overprediction.
- **Evidence anchors:**
  - [section 3.4] Fig. 4 visualizes this dynamic: correct assignments peak early, while incorrect "overshooting" assignments peak significantly later.
  - [section 4.5] Fig. 7 shows that without age-gating, the purity of pseudo-labels degrades over training; with age-gating, purity is maintained.
  - [corpus] No direct corpus evidence for this specific temporal dynamic; this appears to be a novel behavioral observation in this paper.

### Mechanism 3
- **Claim:** Using **ProHOC** (Probabilistic Hierarchical OOD Classification) allows the framework to operate without manual bias parameters to trade off ID vs. OOD performance.
- **Mechanism:** ProHOC factorizes the hierarchical prediction into a product of conditional probabilities from depth-specific networks. Unlike top-down approaches that require tuning OOD thresholds at every node, ProHOC naturally balances the prediction depth based on the entropy of the conditional distributions.
- **Core assumption:** The hierarchy is known and fixed, and depth-specific classifiers can be trained effectively on remapped ID labels.
- **Evidence anchors:**
  - [section 3.2] States SemiHOC builds on ProHOC because it avoids tuning bias parameters usually required for ID/OOD trade-offs.
  - [section 2.3] Contrasts ProHOC with flatten/top-down baselines that suffer from threshold sensitivity.
  - [corpus] *Hi-OSCAR* corroborates the difficulty of balancing hierarchical granularity with open-set rejection thresholds.

## Foundational Learning

- **Concept:** **Open-Set Semi-Supervised Learning (OSSL)**
  - **Why needed here:** Standard SSL assumes unlabeled data belongs to known classes. This paper assumes unlabeled data is "polluted" with OOD classes. You must understand that standard pseudo-labeling destroys performance in this setting because it forces OOD data into ID classes.
  - **Quick check question:** *What happens to an OOD sample in standard FixMatch if its max-probability exceeds the threshold?* (Answer: It is incorrectly treated as a confident ID sample, reinforcing error.)

- **Concept:** **Hierarchical Classification (Taxonomy)**
  - **Why needed here:** The core innovation relies on "rolling up" errors to ancestor nodes. You need to distinguish between *Leaf Nodes* (ID/Specific) and *Internal Nodes* (OOD/General) and understand that predicting an internal node is a valid, conservative output, not just a failure to decide.
  - **Quick check question:** *Is predicting the "Animal" node for a specific "Dog" image a hierarchical error?* (Answer: Yes, it is an under-prediction/over-generalization, but better than predicting "Car".)

- **Concept:** **Mean Teacher (EMA)**
  - **Why needed here:** The architecture relies on a Teacher model to generate stable targets for the Student. Understanding that the Teacher is an Exponential Moving Average of the Student weights (and thus more stable/regularized) is critical to why the pseudo-labels are usable at all.
  - **Quick check question:** *Does the Teacher model receive gradient updates directly?* (Answer: No, only the Student updates; the Teacher weights are a temporal average of Student history.)

## Architecture Onboarding

**Component Map:**
Backbone -> Teacher Heads -> ProHOC -> SPL Engine -> Age Gate -> Student Heads

**Critical Path:**
1. Unlabeled batch enters Backbone
2. Teacher Heads predict logits -> ProHOC calculates hierarchical probabilities
3. **SPL Engine:** Converts probabilities to Subtree Pseudo-labels
4. **Age Gate:** Checks if current epoch > detected cutoff for the assigned node. If so, discard label
5. Validated pseudo-labels train Student Heads via Cross-Entropy

**Design Tradeoffs:**
- **Confidence Threshold (τ):** High τ (0.95) ensures high precision (safety) but lower recall (coverage) for OOD data
- **Age-Gating Sensitivity (γ, w):** Aggressive gating (high drop threshold) blocks more late-stage errors but risks gating correct "slow-learners"
- **Regularization (Dropout/LR):** Higher regularization hurts ID performance (leaves) but improves OOD generalization (internal nodes). The paper suggests tuning for the "shoulder point" of this curve

**Failure Signatures:**
- **Overprediction (OOD -> Specific Leaf):** Age-gating is disabled or cutoff detection failed to trigger. Model becomes overconfident on OOD
- **Underprediction (ID -> High-level Node):** Regularization (Dropout/LR) is too strong, or confidence threshold is too high; the model refuses to commit to leaf classes
- **Collapse to Root:** Subtree pseudo-labeling logic is broken, or threshold is too low; model defaults to predicting the safest, most generic node

**First 3 experiments:**
1. **Sanity Check (ProHOC):** Verify the base ProHOC setup works on labeled ID data. Ensure hierarchical metrics are calculated correctly (Balanced Mean Hierarchical Distance)
2. **Ablation on SPL vs Node Pseudo-labels:** Train the SemiHOC framework using *standard* node-level pseudo-labels vs. Subtree Pseudo-labels. Expect to see the Node version fail on OOD samples (Fig 2 logic)
3. **Age-Gating Timing:** Run a training loop for 400 epochs. Plot "Purity of OOD pseudo-labels" vs "Epoch". Expect to see purity drop without age-gating and stabilize with age-gating (replicate Fig 7)

## Open Questions the Paper Calls Out

- **Can the SemiHOC framework generalize to test sets containing OOD classes that were completely absent from the unlabeled training data?**
  - **Basis in paper:** [explicit] The authors state in the Limitations section that "an interesting extension for the future is to consider test sets with previously unseen OOD classes."
  - **Why unresolved:** The current experimental setup assumes the open-world distribution is static, using the same OOD classes in both the unlabeled training data and the test data.
  - **What evidence would resolve it:** Evaluation on benchmarks where the set of OOD classes in the test split is strictly disjoint from the OOD classes present in the unlabeled training split.

- **How can models more accurately separate uncertain in-distribution (ID) data from OOD data during semi-supervised training?**
  - **Basis in paper:** [explicit] The Conclusion notes that "finding methods for accurately separating OOD data from uncertain ID data would be very valuable in this semi-supervised setting."
  - **Why unresolved:** Standard confidence-based pseudo-labeling struggles to distinguish OOD samples from uncertain ID samples, and while subtree pseudo-labels mitigate this, the challenge persists.
  - **What evidence would resolve it:** A method that achieves significantly higher precision in identifying OOD samples among low-confidence predictions compared to the proposed subtree pseudo-labeling approach.

- **What alternative mechanisms to age-gating can effectively prevent overconfident, overly specific predictions for OOD data?**
  - **Basis in paper:** [explicit] The Conclusion suggests that "alternative strategies to our age-gating strategy can be explored to address the overconfidence issue."
  - **Why unresolved:** The current age-gating mechanism relies on a temporal heuristic (peaks in assignment frequency) which may be brittle or suboptimal for different datasets.
  - **What evidence would resolve it:** A strategy that maintains pseudo-label purity for OOD data without relying on temporal cutoffs, potentially improving the trade-off between coverage and false positive rates.

## Limitations

- The subtree pseudo-labeling strategy critically depends on OOD samples sharing sufficient visual features with their true ancestors in the hierarchy, limiting coverage for completely disjoint domains
- The age-gating mechanism relies on the observation that correct hierarchical assignments occur early in training—a pattern observed in this work but not yet validated across diverse architectures or datasets
- The method inherits ProHOC's requirement for a known, fixed taxonomy, limiting applicability to dynamic or learned hierarchies

## Confidence

- **High confidence:** Core experimental results on iNaturalist19 benchmarks, including the comparative performance against supervised baselines and self-supervised pretraining
- **Medium confidence:** The validity of subtree pseudo-labeling as a general solution for OOD supervision (supported by Fig. 2 but not extensively validated across datasets)
- **Medium confidence:** Age-gating's effectiveness in preventing overprediction (Fig. 4 and 7 provide supporting evidence, but the temporal dynamics may not generalize)

## Next Checks

1. **Dataset diversity test:** Validate SemiHOC on a dataset where OOD samples are visually dissimilar to all ID classes (e.g., using synthetic OOD or a completely disjoint domain) to test the limits of subtree pseudo-labeling coverage
2. **Ablation on age-gating parameters:** Systematically vary γ (drop threshold) and w (window size) across multiple random seeds to quantify sensitivity and identify failure modes when the "early correct assignment" assumption breaks
3. **Hierarchical depth analysis:** Evaluate how SemiHOC's performance degrades as hierarchy depth increases, measuring whether the product of conditional probabilities in ProHOC suffers from numerical underflow or compounding errors in deeper taxonomies