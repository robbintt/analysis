---
ver: rpa2
title: Harmonizing Generalization and Personalization in Ring-topology Decentralized
  Federated Learning
arxiv_id: '2504.19103'
source_url: https://arxiv.org/abs/2504.19103
tags:
- client
- learning
- data
- federated
- clients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of data heterogeneity and low
  information-sharing efficiency in ring-topology decentralized federated learning
  (RDFL). The proposed DRDFL method uses a divide-and-conquer strategy with two complementary
  modules: PersonaNet for personalized learning and Learngene for shared knowledge
  extraction.'
---

# Harmonizing Generalization and Personalization in Ring-topology Decentralized Federated Learning

## Quick Facts
- arXiv ID: 2504.19103
- Source URL: https://arxiv.org/abs/2504.19103
- Reference count: 40
- Proposed DRDFL method achieves up to 3.28% higher local test accuracy with minimal communication overhead of 0.58 MB per iteration

## Executive Summary
This paper addresses the challenge of data heterogeneity and low information-sharing efficiency in ring-topology decentralized federated learning (RDFL). The proposed DRDFL method uses a divide-and-conquer strategy with two complementary modules: PersonaNet for personalized learning and Learngene for shared knowledge extraction. PersonaNet employs Gaussian mixture distributions to capture class-specific features, while Learngene uses adversarial training to extract invariant shared knowledge. The method achieves significant improvements in personalization performance while maintaining strong generalization, with minimal communication overhead of only 0.58 MB per iteration.

## Method Summary
DRDFL employs a divide-and-conquer strategy to decouple the model into personalized and shared components. The local model is decomposed into PersonaNet (capturing class-specific features via Gaussian mixture distributions) and Learngene (extracting invariant shared knowledge via adversarial training). These components are trained together using a VAE framework, with Learngene parameters and class statistics shared through the ring topology. Each client updates its Learngene by averaging with the received model and updating class statistics via exponential moving average, enabling collaborative learning without a central server.

## Key Results
- DRDFL achieves up to 3.28% higher local test accuracy compared to state-of-the-art methods
- Minimal communication overhead of 0.58 MB per iteration, significantly lower than full-model sharing approaches
- Superior convergence speed and model performance across multiple datasets including CIFAR-10, CIFAR-100, and Tiny-ImageNet
- Effective handling of both feature distribution skew and label distribution skew in non-IID data scenarios

## Why This Works (Mechanism)

### Mechanism 1: Disentanglement of Personalized and Shared Representations
- **Claim:** A divide-and-conquer strategy decouples the model into personalized and shared components, mitigating the conflict between local adaptation and global generalization under data heterogeneity.
- **Mechanism:** The local model is decomposed into PersonaNet, Learngene, decoder, and classifier. PersonaNet is trained with KL divergence and log-likelihood loss against a global Gaussian mixture prior for class-specific features. Learngene uses KL divergence to a standard normal prior and adversarial training to extract class-invariant features.
- **Core assumption:** Data heterogeneity can be decomposed into feature distribution skew and label distribution skew, which can be independently addressed by learning separate latent representations.
- **Evidence anchors:** Abstract mentions DRDFL uses a divide-and-conquer strategy with PersonaNet and Learngene modules. Section IV methodology details the disentanglement mechanism based on VAE. Corpus signals show related work rethinking information representation.
- **Break condition:** Disentanglement fails if shared and personalized latent spaces are not sufficiently separated, such as when the adversarial classifier can easily predict class labels from Learngene outputs.

### Mechanism 2: Ring-Topology Collaborative Learning via Learngene and Global Priors
- **Claim:** In ring-topology DFL, Learngene and global class-wise Gaussian statistics serve as efficient carriers of shared knowledge, enabling collaborative learning without a central server and with minimal communication overhead.
- **Mechanism:** After local training, each client transmits updated Learngene parameters and local class statistics to its neighbor. The receiving client initializes its Learngene as the average of its current and received parameters and updates class statistics using exponential moving average.
- **Core assumption:** Point-to-point communication in ring topology is sufficient for knowledge dissemination and consensus formation over time.
- **Evidence anchors:** Abstract highlights minimal communication overhead of 0.58 MB per iteration. Algorithm 1 details reception and integration of neighbor's Learngene and global priors. Corpus mentions decentralized federated learning but DRDFL's specific use of Learngene is distinct.
- **Break condition:** This mechanism fails if the communication graph becomes disconnected or if convergence rate through the ring is too slow for practical use.

### Mechanism 3: Adversarial Alignment for Class-Invariant Knowledge
- **Claim:** Adversarial training forces Learngene to produce class-invariant representations, crucial for strong generalization across clients with different label distributions.
- **Mechanism:** An adversarial classifier is attached to Learngene's output. Learngene is trained to minimize this classifier's ability to predict class labels, using loss terms that encourage uniform class distribution output from the classifier.
- **Core assumption:** Class-invariant features are the primary drivers of generalization performance across heterogeneous clients.
- **Evidence anchors:** Abstract states Learngene uses adversarial training to extract invariant shared knowledge. Section IV-B details the adversarial classifier for adversarial training. Corpus mentions FedST achieving disentanglement through orthogonal feature decoupling.
- **Break condition:** The adversarial game fails to converge or collapse, resulting in Learngene that still contains significant class-specific information.

## Foundational Learning

- **Concept: Variational Autoencoders (VAEs) and ELBO**
  - **Why needed here:** The paper's architecture is built on a VAE framework to disentangle representations. Understanding ELBO is crucial to grasp the loss functions for PersonaNet and Learngene.
  - **Quick check question:** What are the two terms in the ELBO objective, and what role does each play in training the encoder and decoder? (Answer: 1. Reconstruction error, which forces the decoder to produce accurate outputs from latent codes. 2. KL divergence, which regularizes the encoder's latent distribution to match a prior, enabling generation.)

- **Concept: Non-IID Data in Federated Learning**
  - **Why needed here:** This is the core problem the paper addresses. Definitions of Feature Distribution Skew and Label Distribution Skew provide formal motivation for the proposed disentanglement strategy.
  - **Quick check question:** How does Label Distribution Skew differ from Feature Distribution Skew, and which component of DRDFL targets each? (Answer: Label skew: $p_i(y) \neq p_j(y)$, targeted by Learngene's uniform prior training. Feature skew: $p_i(x|y) \neq p_j(x|y)$, targeted by PersonaNet's client-specific Gaussian distributions.)

- **Concept: Adversarial Training**
  - **Why needed here:** Learngene's ability to learn class-invariant features hinges on adversarial training. Understanding the minimax game between Learngene encoder and adversarial classifier is essential.
  - **Quick check question:** In the adversarial setup for Learngene, what is the objective of the adversarial classifier and what is the counter-objective of Learngene? (Answer: The classifier tries to maximize its prediction accuracy of class labels from $z_l$. Learngene tries to minimize this accuracy, ideally forcing the classifier's output towards a uniform distribution over classes.)

## Architecture Onboarding

- **Component map:**
  1. PersonaNet Encoder ($\psi_m$): Client-private encoder. Input: raw data $x$. Output: personalized latent code $z_p$. Trained with Gaussian mixture loss ($L_{PR}$).
  2. Learngene Encoder ($\phi$): Shared encoder. Input: raw data $x$. Output: shared latent code $z_l$. Trained with KL loss ($L_{kl}$) and adversarial loss ($L_{adv}, L_{adv}^u$).
  3. Adversarial Classifier ($\vartheta$): Small classifier attached to Learngene. Input: $z_l$. Output: class prediction. Used only during training.
  4. Decoder ($\theta_m$): Client-private decoder. Input: concatenated $[z_p, z_l]$. Output: reconstructed data $x'$. Trained with reconstruction loss ($L_{rec}$).
  5. Prediction Classifier ($\omega_m$): Client-private classifier for final task. Input: original $x$ and perturbed reconstructed $x_p$. Output: final prediction.

- **Critical path:**
  1. Each client initializes its model components.
  2. **Local Training:** Forward pass through PersonaNet and Learngene. Compute losses ($L_{PR}, L_{GL}$). Reconstruct via decoder ($L_{rec}$). Perform final prediction ($L_{ce}$). Backpropagate to update all parameters.
  3. **Communication:** Trained Learngene parameters $\phi$ and class statistics $\{(\mu_k, \Sigma_k)\}$ passed to next client in ring.
  4. **Integration:** Next client initializes Learngene by averaging with received Learngene and updates class statistics via EMA.
  5. Repeat steps 2-4 for set number of global rounds.

- **Design tradeoffs:**
  - Communication Cost vs. Model Capacity: Sharing only lightweight Learngene (0.58 MB) keeps communication low but may limit shared knowledge representation capacity.
  - Personalization vs. Generalization: Disentanglement explicitly manages this tradeoff. Adversarial training strength and Gaussian prior weighting are key hyperparameters.
  - Convergence Speed: Ring topology is inherently slower to converge than server-based or fully connected topologies.

- **Failure signatures:**
  - Learngene Collapse: If adversarial loss dominates, Learngene may produce uninformative, constant outputs.
  - Poor Reconstruction: If decoder fails to reconstruct data well from latent codes, end-to-end training signal is weak.
  - Divergent Models: If local data is extremely heterogeneous or EMA update rate is poorly chosen, class statistics and models may not converge.
  - Slow Convergence: If ring is large, it may take many rounds for good knowledge from one client to reach others.

- **First 3 experiments:**
  1. **Ablation on Components:** Train models with only PersonaNet or only Learngene shared (or ablating adversarial loss) to quantify contribution of each part to Local-T and Global-T performance.
  2. **Convergence Analysis:** Plot Local-T and Global-T accuracy over communication rounds for different Non-IID settings to verify convergence speed and stability.
  3. **Visualization of Latent Spaces:** Use t-SNE or PCA to visualize learned $z_p$ and $z_l$ representations for different classes and clients to verify disentanglement.

## Open Questions the Paper Calls Out
None

## Limitations
- The method relies on Gaussian mixture distributions for modeling class-specific features, which may not capture complex, multi-modal data distributions effectively.
- Ring topology convergence speed remains a concern, potentially requiring more global rounds to achieve comparable performance to server-based methods.
- Experimental validation is limited to standard image datasets and does not explore more challenging modalities like text or graph data.

## Confidence
- **High Confidence:** Core mechanism of disentanglement using VAE framework and effectiveness of adversarial training for Learngene are well-supported by theoretical formulation and experimental results.
- **Medium Confidence:** Claim of "significant improvements" in personalization performance is supported by ablation studies, but magnitude varies across datasets.
- **Low Confidence:** Scalability claims to very large networks are not thoroughly tested, and method's robustness to extreme heterogeneity is not explicitly evaluated.

## Next Checks
1. **Extreme Heterogeneity Test:** Evaluate DRDFL on label-only skewed data where some clients possess only a single class to test limits of adversarial alignment and shared knowledge extraction.
2. **Convergence Speed Analysis:** Measure and compare wall-clock time and number of communication rounds required to reach target accuracy against server-based federated learning baselines, particularly in large ring topologies.
3. **Alternative Prior Distributions:** Replace the Gaussian mixture prior in PersonaNet with a more flexible distribution (e.g., normalizing flows) to assess whether performance improvements justify increased complexity.