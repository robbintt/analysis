---
ver: rpa2
title: 'MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time
  Series Forecasting'
arxiv_id: '2509.03852'
source_url: https://arxiv.org/abs/2509.03852
tags:
- lead-lag
- time
- dependencies
- forecasting
- scale
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MillGNN is a graph neural network method for multivariate time
  series forecasting that learns multi-scale lead-lag dependencies. It addresses the
  challenge of capturing hierarchical lead-lag effects across individual variates
  and variate groups at different scales.
---

# MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting

## Quick Facts
- **arXiv ID:** 2509.03852
- **Source URL:** https://arxiv.org/abs/2509.03852
- **Reference count:** 40
- **Primary result:** Achieves state-of-the-art performance on 11 real-world MTS datasets, outperforming 16 baselines with average MSE of 0.373 on ETTm1 and 0.170 on Electricity.

## Executive Summary
MillGNN introduces a novel graph neural network architecture for multivariate time series forecasting that explicitly models multi-scale lead-lag dependencies. The key insight is that temporal dependencies between variates manifest at different scales—some effects are stable and coarse-grained, while others are fine-grained and transient. MillGNN addresses this by constructing a hierarchical graph structure where variates are grouped at multiple scales based on temporal similarity, then learns lead-lag relationships within and across these scales using a combination of statistical cross-correlation and learnable decay mechanisms.

## Method Summary
MillGNN operates on multivariate time series by first constructing a multi-scale hierarchy through clustering variates based on Dynamic Time Warping similarity. For each scale, it learns lead-lag dependencies using FFT-based cross-correlation to identify candidate lags, then refines edge weights with a decay-aware attention mechanism that captures how influence propagates over time. The hierarchical lead-lag message passing module propagates information within scales and across scales using a duplication-based approach that maintains efficiency while capturing hierarchical effects. The model is trained end-to-end using MSE loss with Adam optimization and hyperparameter tuning via NNI toolkit.

## Key Results
- Outperforms 16 state-of-the-art methods across 11 real-world datasets for both long-term and short-term forecasting
- Achieves average MSE of 0.373 on ETTm1 and 0.170 on Electricity datasets
- Demonstrates efficient training while maintaining superior accuracy
- Ablation studies confirm the importance of hierarchical lead-lag modeling

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical grouping allows the model to capture stable, coarse-grained dependencies that are invisible at the individual variate level. The model uses Dynamic Time Warping (DTW) to measure temporal similarity between variates, then applies clustering to construct a hierarchy of variate groups. This creates "coarse" nodes where fine-grained noise is smoothed out, enabling the detection of broader system-wide propagation patterns.

### Mechanism 2
Combining statistical cross-correlation with learnable decay features enables the model to detect asynchronous dependencies while respecting physical "fading" effects. The SiLL-GL module first uses FFT-based cross-correlation to identify candidate time lags, then refines edge weights using a decay-aware attention mechanism that models "excitatory" and "inhibitory" rates, capturing how the influence of a leading variate decays or revives over time.

### Mechanism 3
Duplication-based message passing efficiently propagates multi-scale effects without the quadratic cost of connecting every node across all scales. The HiLL-MP module aggregates messages within scales and across scales, using a "duplication" operation that averages messages at the group level and duplicates them to member variates, enforcing a consistent hierarchical influence.

## Foundational Learning

- **Lead-Lag vs. Instantaneous Correlation**: Standard GNNs assume contemporaneous edges ($t$ to $t$), but MillGNN is built entirely on edges connecting $t$ to $t+\tau$. **Quick check:** Can you explain why standard Pearson correlation would fail to detect that Sensor A's spike causes Sensor B's spike 10 minutes later?

- **FFT for Cross-Correlation (Wiener–Khinchin Theorem)**: The paper relies on FFT to compute dependencies in $O(L \log L)$ rather than $O(L^2)$. **Quick check:** How does transforming a time series to the frequency domain allow you to calculate time-domain lags efficiently?

- **Graph Pooling & Unpooling (Hierarchy)**: The model creates coarser graphs to learn group dynamics and then distributes info back to variates. **Quick check:** In a standard Graph Pooling layer, how does the resolution of the node features change, and how does the "assignment matrix" control this?

## Architecture Onboarding

- **Component map:** Input MTS -> Pre-compute Assignment Matrices -> FFT Correlation -> Learn Decay Weights -> Message Passing -> Prediction
- **Critical path:** Input -> Pre-compute Assignment Matrices (offline/once) -> FFT Correlation (fixed/init) -> Learn Decay Weights (trainable) -> Message Passing -> Prediction
- **Design tradeoffs:** Spectral vs. K-means Clustering (accuracy vs. computational cost), Duplication vs. Learnable Inter-scale Weights (efficiency vs. capacity), Lag Selection ($K$) impacts noise vs. dependency coverage
- **Failure signatures:** Lag Drift (misalignment if delays change), Over-smoothing (node features converge), Group Rigidity (poor clustering propagates noise)
- **First 3 experiments:** 1) Cluster Ablation (replace Spectral with Random partitioning), 2) Lag Stability Test (train on first half, test on second), 3) Scale Visualization (compare learned weights for fast vs. slow scales)

## Open Questions the Paper Calls Out
- How can high-order lead-lag dependencies be effectively integrated into the multi-scale graph structure to model complex cascading effects?
- Can efficient, differentiable grouping strategies outperform the current static clustering approach for non-stationary time series?
- How can the model dynamically adapt its lead-lag graph construction when the lag distribution drifts between training and testing phases?

## Limitations
- The paper relies on an internal AutoML process (NNI) for hyperparameter tuning, making exact reproducibility challenging
- Performance drops when lag distributions drift between training and testing phases (e.g., ETTh2 dataset)
- The binarization threshold for the similarity matrix is not specified, creating ambiguity in preprocessing

## Confidence
- **High:** The general concept of multi-scale lead-lag dependencies and hierarchical GNN architecture is valid and well-supported by ablation studies
- **Medium:** The specific implementation details (decay-aware attention, exact clustering parameters) are likely sound but require missing thresholds for perfect replication
- **Low:** Claims about outperforming all 16 baselines are strong but must be taken with a grain of salt due to complex, dataset-specific tuning process

## Next Checks
1. Cluster Ablation: Replace Spectral clustering with Random partitioning to verify that informed grouping is actually driving the performance gain
2. Lag Stability Test: Train on the first half of a dataset and test on the second. Plot the change in cross-correlation lags over time to see if performance correlates with lag stability
3. Scale Visualization: Visualize the learned weights $\mathbf{\Lambda}^s$ for a "fast" scale vs. a "slow" scale to confirm that fine scales capture short lags and coarse scales capture long lags