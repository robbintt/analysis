---
ver: rpa2
title: 'EdgeNavMamba: Mamba Optimized Object Detection for Energy Efficient Edge Devices'
arxiv_id: '2510.14946'
source_url: https://arxiv.org/abs/2510.14946
tags:
- edge
- detection
- object
- navigation
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents EdgeNavMamba, a reinforcement learning-based
  framework for energy-efficient goal-directed navigation using a lightweight Mamba
  object detection model. The authors introduce a custom shape detection dataset collected
  in diverse indoor settings and optimize the Mamba architecture using knowledge distillation
  to achieve significant size and energy reductions while maintaining detection accuracy.
---

# EdgeNavMamba: Mamba Optimized Object Detection for Energy Efficient Edge Devices

## Quick Facts
- **arXiv ID:** 2510.14946
- **Source URL:** https://arxiv.org/abs/2510.14946
- **Reference count:** 40
- **Primary result:** Student Mamba detector achieves 67% size reduction and up to 73% energy savings on edge devices while maintaining detection accuracy.

## Executive Summary
EdgeNavMamba presents a reinforcement learning-based framework for energy-efficient goal-directed navigation using a lightweight Mamba object detection model. The system uses knowledge distillation to compress a teacher model into a student architecture with significantly fewer parameters and lower energy consumption while preserving detection accuracy. A custom shape detection dataset collected in diverse indoor settings enables training and evaluation. The navigation policy, trained in MiniWorld simulator, achieves over 90% success rate across environments of varying complexity, demonstrating the framework's effectiveness for autonomous navigation on resource-constrained edge devices.

## Method Summary
The framework integrates a hierarchical Mamba-based object detector with a reinforcement learning policy for autonomous navigation. The detector uses Lite-Conv-SSM blocks combining convolutional and Mamba (LiteSS2D) layers to extract features efficiently. Knowledge distillation transfers knowledge from a frozen teacher model to a compressed student model using combined loss functions (detection, KL divergence, and feature matching). The student model achieves 67% size reduction while maintaining detection accuracy. For navigation, the detector extracts bounding box coordinates as state inputs to a PPO policy, which learns to navigate toward target objects in the environment. The system is evaluated in both simulation and on physical edge devices including NVIDIA Jetson Orin Nano and Raspberry Pi 5.

## Key Results
- Student model achieves 67% reduction in size (from 9.1MB to 2.5MB) while maintaining detection accuracy
- Up to 73% reduction in energy per inference on edge devices compared to teacher model
- Navigation policy achieves over 90% success rate across environments of varying complexity
- Framework reduces parameters by 31% compared to baseline models while maintaining high detection accuracy

## Why This Works (Mechanism)

### Mechanism 1
Knowledge distillation enables significant model compression while preserving detection accuracy. A frozen teacher model guides student training through combined loss: detection loss ($L_{det}$), KL divergence on logits ($L_{KD}$), and feature matching ($L_{feat}$). The student learns to mimic intermediate representations and output distributions, allowing channel dimension reduction (teacher: [64,128,256,512] → student: [32,64,128,256]).

### Mechanism 2
State Space Model (SSM) architecture provides computational efficiency over attention-based backbones for edge deployment. LiteSS2D performs four-direction selective scanning with shared SSM weights, avoiding repeated tensor reshaping. The dual-branch structure (Conv + SSM) captures local and global features with linear-time complexity $O(n)$ versus Transformers' $O(n^2)$.

### Mechanism 3
Bounding box coordinates as state representation enable efficient RL policy learning for navigation. The detector extracts BBox coordinates $(x_1, y_1, x_2, y_2)$ for $n$ objects, producing a $1 \times (4n)$ vector. This concatenates with one-hot goal and last-action vectors, yielding compact state $1 \times (5n + a)$ for PPO policy—avoiding high-dimensional raw image input.

## Foundational Learning

- **Knowledge Distillation (KD)**: Enables 67% model size reduction by transferring teacher knowledge to compressed student. Quick check: Can you explain why temperature scaling in KL divergence softens probability distributions?
- **Selective State Space Models (Mamba)**: Provides efficient alternative to attention mechanisms for feature extraction under edge constraints. Quick check: How does the SSM equation $y(t) = Cx(t)$ differ from self-attention's query-key-value computation?
- **Proximal Policy Optimization (PPO)**: Trains navigation policy using bounding box state inputs and shaped rewards. Quick check: What advantage does PPO's clipped objective provide over vanilla policy gradient methods?

## Architecture Onboarding

- **Component map**: Input Image (224×224) → Patch Embedding → [Lite-Conv-SSM Blocks ×4 stages with Patch Merging] → Detector Head → BBox Coordinates → [State Vector: BBox + goal + last-action] → PPO Policy → Discrete Action {left, right, forward}
- **Critical path**: The Lite-Conv-SSM block's dual-branch design (Conv branch: DWConv→PWConv; SSM branch: LiteSS2D) followed by concatenation and shuffle determines feature quality. Monitor feature map dimensions at each stage: dim1→dim2→dim3→dim4.
- **Design tradeoffs**: Larger channel dimensions improve mAP but increase energy per inference (teacher: 9.1MB, student: 2.5MB); deeper stage depths improve accuracy but raise latency; current config [2,2,4,2] balances both.
- **Failure signatures**: mAP drops significantly on validation set → check for over-distillation, reduce $\lambda_{kd}$; navigation policy oscillates or collides → inspect reward shaping, increase distance-change reward weight; energy consumption higher than expected → verify ONNX export optimization.
- **First 3 experiments**: 1) Reproduce teacher-student distillation on Shapes dataset with reported hyperparameters; confirm mAP ≈ 0.93 for both models. 2) Deploy student model on Jetson Orin Nano; measure energy per inference—target <0.37× teacher energy. 3) Train PPO navigation policy in MiniWorld single-object environment; verify >95% success rate before adding distractors.

## Open Questions the Paper Calls Out

### Open Question 1
What is the end-to-end navigation success rate and latency when deploying the EdgeNavMamba framework on the physical robot platforms in real-world environments? The paper reports navigation success rates exclusively in MiniWorld simulator while detailing physical hardware setup, but lacks quantitative results from physical robot trials.

### Open Question 2
How well does the compressed student model generalize to complex visual scenes with a larger number of object classes compared to standard benchmarks? The experimental evaluation relies on a custom shape detection dataset with only three classes, not demonstrating capacity to handle visual complexity of standard datasets like COCO.

### Open Question 3
What is the specific trade-off in detection accuracy introduced by the LiteSS2D module compared to a standard 2D selective scan? The paper introduces LiteSS2D for efficiency gains but provides no ablation study isolating this component to verify if efficiency comes at cost of spatial reasoning accuracy.

## Limitations

- Limited generalization to complex visual scenes due to narrow scope of custom dataset with only three object classes
- Uncertainty about optimal teacher architecture dimensions for distillation, making compression claims difficult to benchmark
- Potential ONNX export and edge inference issues due to Mamba/SSM block compatibility with edge deployment frameworks

## Confidence

- **High confidence**: Detection accuracy (mAP ~0.93) and navigation success rate (>90%) in MiniWorld simulator
- **Medium confidence**: Energy reduction claims (up to 73%) due to potential hardware-specific optimizations
- **Low confidence**: Generalization to real-world indoor navigation and scalability to more object classes

## Next Checks

1. **Replicate distillation on Shapes dataset**: Train both teacher and student models using specified hyperparameters and confirm mAP ≈ 0.93 for both.
2. **Deploy and measure on edge hardware**: Export student model to ONNX and run on NVIDIA Jetson Orin Nano with energy monitoring; verify energy per inference is ≤0.37× teacher's energy.
3. **Test navigation robustness**: Evaluate PPO policy in MiniWorld with varying object counts and distractor complexity; ensure success rate remains above 90% and diagnose failures.