---
ver: rpa2
title: 'EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method
  for Large Language Models'
arxiv_id: '2508.09471'
source_url: https://arxiv.org/abs/2508.09471
tags:
- pruning
- eggs-ptp
- weight
- each
- weights
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EGGS-PTP, a novel post-training pruning method
  for LLMs that integrates expander graph theory with N:M structured sparsity. The
  method uses importance-aware and connectivity-aware pruning strategies to preserve
  both high-impact weights and robust information flow.
---

# EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method for Large Language Models

## Quick Facts
- **arXiv ID:** 2508.09471
- **Source URL:** https://arxiv.org/abs/2508.09471
- **Reference count:** 32
- **Primary result:** Achieves up to 6.69% better perplexity and 3.90% better zero-shot accuracy than baselines under 2:4 and 4:8 sparsity

## Executive Summary
EGGS-PTP introduces a post-training pruning method for large language models that combines expander graph theory with N:M structured sparsity. The method uses importance-aware and connectivity-aware pruning strategies to preserve both high-impact weights and robust information flow. Extensive experiments show EGGS-PTP outperforms existing methods like Wanda and RIA in perplexity and zero-shot accuracy across multiple LLaMA models, achieving up to 6.69% better performance under 2:4 sparsity and 3.90% under 4:8 sparsity. Theoretical analysis confirms that the pruned layers maintain expander graph properties, ensuring efficient connectivity and reduced channel corruption.

## Method Summary
EGGS-PTP operates on pre-trained LLaMA models using post-training pruning without fine-tuning. The method computes Relative Importance Aggregation (RIA) scores using input activations and Relative Row Importance (RRI) scores. Channels are permuted via round-robin allocation based on RIA scores, then rows are sorted within pruning groups by RRI. The hybrid pruning strategy applies connectivity-aware pruning (diagonal selection) to blocks with lowest RRI scores and importance-aware pruning to higher-RRI blocks, controlled by hyperparameter B. This approach ensures N:M structured sparsity while maintaining expander graph properties in the pruned layers.

## Key Results
- EGGS-PTP improves over RIA by 6.69% on average perplexity under 2:4 sparsity and 3.90% under 4:8 sparsity
- Achieves 1.64× inference speedup on LLaMA2-13B with 2:4 sparsity
- Maintains expansion properties in pruned layers with theoretical guarantees (Lemma 1)

## Why This Works (Mechanism)

### Mechanism 1: Expander Graph Properties Preserve Information Flow
- Claim: Modeling pruned layers as expander graphs maintains robust connectivity under aggressive sparsity, reducing channel corruption.
- Mechanism: Each linear layer is modeled as a bipartite graph where neurons are vertices and weights are edges. The connectivity-aware pruning strategy ensures each neuron retains at least B connections, satisfying the expander property where small subsets of neurons remain well-connected.
- Core assumption: Maintaining expander graph properties directly translates to preserved information flow in neural networks.
- Evidence anchors: Abstract states method "ensures information flow within the pruned network"; Lemma 1 proves expansion property with bounds dependent on B and layer dimensions.

### Mechanism 2: Channel Permutation Redistributes Critical Weights
- Claim: Permuting input channels via round-robin allocation prevents clustering of important weights in the same pruning group.
- Mechanism: Channels are sorted by aggregated RIA scores and distributed across pruning groups, ensuring N:M constraints don't force simultaneous pruning of multiple high-importance weights from the same functional region.
- Core assumption: Importance scores from pre-trained weights and activations reliably predict downstream criticality.
- Evidence anchors: Section 4.2 states "Channel permutation effectively reduces the likelihood that important weights are clustered in the same group."

### Mechanism 3: Hybrid Pruning Separates Quantitative and Qualitative Objectives
- Claim: Partitioning blocks by RRI scores—applying connectivity-aware pruning to low-RRI blocks and importance-aware pruning to high-RRI blocks—outperforms either strategy alone.
- Mechanism: Within each pruning group, rows are sorted by aggregated RRI. The B lowest-RRI blocks receive diagonal selection (preserving structure), while remaining blocks retain top M-N weights by RIA (preserving magnitude).
- Core assumption: Low row-wise relative importance indicates weights matter more for connectivity than direct performance contribution.
- Evidence anchors: Section 5.4 describes the hybrid approach; Tables 1-2 show EGGS-PTP improvements over RIA.

## Foundational Learning

- **Expander Graphs**
  - Why needed here: The theoretical guarantee (Lemma 1) and diagonal selection motivation both depend on understanding that expanders are sparse graphs where small vertex subsets have disproportionately large neighborhoods.
  - Quick check question: In a bipartite expander with expansion factor 2, if 10 input neurons are selected, what's the minimum number of distinct output neurons they must connect to?

- **N:M Structured Sparsity**
  - Why needed here: This hardware-friendly constraint (exactly N zeros per M consecutive elements) is the design target. Understanding it explains why naive pruning fails and why structured approaches are needed.
  - Quick check question: In 2:4 sparsity with weights [0.9, 0.1, 0.8, 0.2], which 2 weights would magnitude pruning retain?

- **Post-Training Pruning (PTP)**
  - Why needed here: EGGS-PTP operates on pre-trained models without fine-tuning, using activations (not gradients) for importance scoring.
  - Quick check question: Why is PTP preferred over pruning-aware training for 70B+ parameter models?

## Architecture Onboarding

- **Component map:** RIA computation -> Channel permutation -> RRI scoring -> Block partitioning -> Hybrid pruning (connectivity-aware + importance-aware)
- **Critical path:** Diagonal selection (Algorithm 1, lines 10-12). This is the novel component distinguishing EGGS-PTP from RIA with permutation.
- **Design tradeoffs:** B ∈ [1, 20] controls connectivity vs importance balance. Paper finds optimal B increases with model size. Tune via cross-validation.
- **Failure signatures:** Exploding perplexity (>100) indicates B too small → channel corruption. Verify diagonal selection applied to B lowest-RRI blocks.
- **First 3 experiments:**
  1. Reproduce LLaMA-3.2-1B 2:4 result (target: ~60.9 perplexity). Validates full pipeline.
  2. Sweep B ∈ {1, 5, 10, 15, 20} on LLaMA2-7B. Confirm U-shaped perplexity curve.
  3. Measure A100 inference speedup on LLaMA2-13B. Expect ~1.64× (Table 5).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the hyperparameter B be determined automatically through theoretical analysis rather than cross-validation?
- Basis in paper: [explicit] Remark 1 states "B is a hyperparameter that can be selected based on cross-validation" and notes the tradeoff between importance-aware and connectivity-aware pruning.
- Why unresolved: The paper provides no principled method for setting B; it relies entirely on empirical tuning via 1-fold cross-validation over the range [1, 20].
- What evidence would resolve it: A theoretical derivation linking optimal B to model properties (e.g., Fℓ, Fℓ−1, sparsity ratio N:M) validated against empirically optimal values.

### Open Question 2
- Question: Does combining EGGS-PTP with post-training quantization methods (e.g., GPTQ, AWQ) yield additive or compounding compression benefits?
- Basis in paper: [inferred] The paper cites quantization methods [3, 6, 14, 27] in the introduction but focuses exclusively on pruning, leaving the interaction with quantization unexplored.
- Why unresolved: Quantization reduces precision while pruning reduces connectivity; their combined effect on expander graph properties and information flow is unknown.
- What evidence would resolve it: Experiments applying both EGGS-PTP pruning and INT4/INT8 quantization, measuring perplexity degradation and inference speedup.

### Open Question 3
- Question: Does EGGS-PTP generalize to non-LLaMA architectures (e.g., Mistral, Gemma, decoder-encoder models)?
- Basis in paper: [inferred] Section 7.1 explicitly tests only "models from both the LLaMA2 and LLaMA3 families," with no justification for this restriction or discussion of architecture-specific assumptions.
- Why unresolved: Expander graph properties may interact differently with attention patterns, MLP ratios, or activation functions in other architectures.
- What evidence would resolve it: Perplexity and zero-shot results on 3+ non-LLaMA model families under identical N:M sparsity constraints.

### Open Question 4
- Question: What are the theoretical performance bounds for any N:M pruning method relative to dense model performance?
- Basis in paper: [inferred] Section 7.2 notes "as performance approaches the dense baseline, it becomes challenging to achieve a significant increase" and that "smaller dense models often rival larger pruned models," suggesting a theoretical ceiling exists.
- Why unresolved: Lemma 1 proves expander properties are maintained but does not establish bounds on how much information loss is unavoidable under N:M constraints.
- What evidence would resolve it: A theoretical lemma bounding perplexity increase given sparsity ratio N:M and model dimension, validated against empirical results from multiple pruning methods.

## Limitations
- The core claims about expander graph properties preserving information flow remain theoretical without direct empirical isolation
- The method's dependence on RIA scores as importance proxies assumes pre-trained weights encode sufficient predictive signal
- The claim that EGGS-PTP scales to "larger LLaMA models" beyond the tested range is speculative without experimental evidence

## Confidence
- **High confidence:** The hybrid pruning strategy demonstrably improves perplexity metrics over baselines (2:4 - 6.69% better than RIA, 4:8 - 3.90% better). The 1.64× A100 inference speedup on LLaMA2-13B is reproducible.
- **Medium confidence:** The channel permutation mechanism's contribution to performance gains is harder to isolate, as it builds on prior RIA work. The theoretical expander graph guarantees are mathematically sound but their practical significance needs more direct validation.
- **Low confidence:** The claim about preventing "severe channel corruption" is theoretically motivated but not empirically verified through targeted ablation studies.

## Next Checks
1. **Ablation study on B parameter:** Systematically test B values beyond the reported [1, 20] range on LLaMA3-8B to identify if the optimal B scaling with model size holds or if there are diminishing returns/failure modes at extreme values.

2. **Direct information flow measurement:** Design experiments that isolate whether diagonal selection (expander-based pruning) actually preserves gradient flow or activation patterns better than magnitude pruning alone, using techniques like Jacobian analysis or singular value spectrum comparison.

3. **Cross-architecture validation:** Apply EGGS-PTP to non-LLaMA architectures (e.g., OPT, Mistral) to test whether the expander graph approach generalizes beyond the specific weight distributions and layer patterns of LLaMA models.