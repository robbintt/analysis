---
ver: rpa2
title: Exact Shapley Attributions in Quadratic-time for FANOVA Gaussian Processes
arxiv_id: '2508.14499'
source_url: https://arxiv.org/abs/2508.14499
tags:
- features
- feature
- shapley
- xxxs
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents FGPX-Shapley, a method for computing exact\
  \ Shapley attributions in quadratic time for FANOVA Gaussian Processes. The core\
  \ contribution is leveraging the functional ANOVA decomposition structure to derive\
  \ a closed-form stochastic M\xF6bius representation, enabling efficient recursive\
  \ computation of both local and global Shapley values without exponential enumeration."
---

# Exact Shapley Attributions in Quadratic-time for FANOVA Gaussian Processes

## Quick Facts
- arXiv ID: 2508.14499
- Source URL: https://arxiv.org/abs/2508.14499
- Authors: Majid Mohammadi; Krikamol Muandet; Ilaria Tiddi; Annette Ten Teije; Siu Lun Chau
- Reference count: 40
- Primary result: Presents FGPX-Shapley, achieving exact Shapley attributions in quadratic time for FANOVA Gaussian Processes

## Executive Summary
This paper introduces FGPX-Shapley, a method for computing exact Shapley attributions in quadratic time for Functional Analysis of Variance (FANOVA) Gaussian Processes. The core innovation leverages the functional ANOVA decomposition structure to derive a closed-form stochastic Möbius representation, enabling efficient recursive computation of both local and global Shapley values without exponential enumeration. The method provides uncertainty-aware explanations for probabilistic models, achieving superior accuracy compared to state-of-the-art explainers while maintaining computational efficiency.

## Method Summary
FGPX-Shapley exploits the orthogonal decomposition of FANOVA GPs to compute exact Shapley values in quadratic time. For local explanations, it computes stochastic Shapley values capturing uncertainty through a joint Gaussian distribution. For global explanations, it computes variance-based Shapley values quantifying each feature's contribution to model sensitivity. The method uses Newton's identities and elementary symmetric polynomials to recursively compute means and covariances without enumerating all subsets.

## Key Results
- Reduces computational complexity from exponential to quadratic time, scaling to 100 features in seconds versus hours for naive approaches
- Provides exact, uncertainty-aware local explanations through stochastic Shapley values
- Demonstrates superior accuracy in recovering influential features compared to SHAP, LIME, MAPLE, and feature selectors
- Maintains computational efficiency while providing axiomatically sound explanations for probabilistic models

## Why This Works (Mechanism)
The method exploits the orthogonal decomposition of FANOVA GPs to derive a closed-form Möbius representation of the value function. This representation enables recursive computation of means and covariances using Newton's identities and elementary symmetric polynomials, avoiding exponential subset enumeration. The orthogonality condition ensures that variance and covariance calculations have closed-form expressions, making the approach computationally efficient.

## Foundational Learning
- **FANOVA Decomposition**: Separates GP functions into additive components for efficient computation. Why needed: Enables orthogonal decomposition for closed-form Shapley calculations. Quick check: Verify kernel satisfies orthogonality constraints.
- **Möbius Representation**: Stochastic formulation capturing value function contributions. Why needed: Enables recursive mean/covariance computation. Quick check: Validate µ(T) sums to v(X).
- **Elementary Symmetric Polynomials**: Recursive computation of polynomial coefficients. Why needed: Avoids explicit subset enumeration. Quick check: Verify ESP recursion produces correct coefficients.
- **Newton's Identities**: Relates power sums to elementary symmetric polynomials. Why needed: Enables efficient ESP computation. Quick check: Test polynomial expansion for small feature sets.

## Architecture Onboarding

- **Component Map:**
  - FANOVA GP Core -> Stochastic Möbius Engine -> Quadratic-Time Solver -> Explainer Interfaces (FGPX-Shapley-L/G)

- **Critical Path:**
  1. Train FANOVA GP with additive kernel and orthogonality constraints
  2. Compute kernel vectors z_j = k̃_j(x_j, X_j) for test instance
  3. Compute ESPs over Z_{-i} using numerically stable polynomial expansion
  4. Calculate Shapley value means and covariances using recursive formulas from Theorems 6 and 8

- **Design Tradeoffs:**
  - Exactness vs. Model Class: Achieves exact values only for FANOVA GPs, not general black-box models
  - Analytical vs. Empirical: Relies on analytical formulas for orthogonal kernels; empirical estimation introduces approximation error if assumptions violated

- **Failure Signatures:**
  - Exploding Runtimes: FANOVA structure not exploited correctly (recursive ESP computation failing)
  - Negative Variance: Error in covariance calculation (Eq. 7)
  - Efficiency Axiom Violation: Möbius representation calculation incorrect (sum of global Shapley values ≠ total variance)

- **First 3 Experiments:**
  1. Synthetic Recovery Test: Generate data from known function, train FANOVA GP, verify Shapley values identify influential features
  2. Scalability Benchmark: Measure execution time while increasing features d from 5 to 100, confirm quadratic scaling
  3. Uncertainty-Aware Comparison: On real dataset, compute local stochastic Shapley values, visualize mean attribution with variance, identify high-uncertainty features

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the stochastic Möbius representation and quadratic-time Shapley algorithms be extended to product-kernel Gaussian processes where orthogonality does not necessarily hold?
- Basis in paper: explicit, FAQ section states computing variance/covariance under product kernels is nontrivial since orthogonality is not necessarily held
- Why unresolved: Derivation fundamentally relies on orthogonal decomposition; without orthogonality, Möbius representation lacks clean covariance structures
- What evidence would resolve it: Theoretical extension for non-orthogonal additive kernels or proof that quadratic-time exact computation is impossible without orthogonality

### Open Question 2
- Question: How can uncertainty quantification from stochastic Shapley values be leveraged for active learning or Bayesian optimization in feature selection?
- Basis in paper: inferred, paper demonstrates uncertainty-aware comparison but only explores visualization, joint Gaussian structure could inform acquisition functions
- Why unresolved: Introduces machinery but does not develop downstream applications beyond explanation visualization
- What evidence would resolve it: Experiments showing improved sample efficiency in active feature selection when using SSV uncertainty compared to deterministic methods

### Open Question 3
- Question: Can FGPX-Shapley detect higher-order feature interactions directly, beyond attributing importance to individual features?
- Basis in paper: inferred, Möbius representation µ(T) captures contributions from interaction subsets T, but paper aggregates into per-feature Shapley values rather than analyzing interaction terms
- Why unresolved: Decomposition exists but paper does not address efficient extraction and ranking of specific interaction effects
- What evidence would resolve it: Algorithm extension computing interaction Shapley values in polynomial time with empirical validation on datasets with known ground-truth interactions

## Limitations
- Restricted to FANOVA GPs with additive/orthogonal kernels, limiting general-purpose explainability
- Practical interpretation of stochastic Shapley value uncertainty not extensively discussed
- Empirical validation focuses on feature recovery and efficiency, lacking systematic evaluation of explanation faithfulness

## Confidence
- Core algorithmic contributions (quadratic-time exact computation): High
- Claims about general-purpose explainability: Medium
- Practical guidance for uncertainty-aware explanations: Medium
- Explanation quality claims: Medium
- Scalability claims for very high dimensions: High for moderate dimensions, warrants further investigation

## Next Checks
1. **Ablation on FANOVA Structure**: Disable FANOVA decomposition (use standard GP) and demonstrate runtime reverts to exponential behavior, confirming efficiency gains from FANOVA structure
2. **Uncertainty Interpretation Study**: Conduct user study or sensitivity analysis to evaluate how practitioners should interpret and act upon variance estimates in stochastic Shapley values
3. **Out-of-Distribution Robustness**: Test FGPX-Shapley on data where feature distributions deviate from Gaussian assumptions required for orthogonal kernel to quantify impact on explanation accuracy