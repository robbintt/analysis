---
ver: rpa2
title: Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for
  Neural Network Verification
arxiv_id: '2507.05405'
source_url: https://arxiv.org/abs/2507.05405
tags:
- bounds
- verification
- neural
- reachable
- crown
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a probabilistic framework for neural network
  verification that improves upon deterministic and existing probabilistic methods
  by providing tighter linear relaxation bounds with quantifiable confidence guarantees.
  The core idea combines statistical tolerance limits (Wilks' theorem) with extreme
  value theory to compute probabilistically sound intermediate reachable sets, which
  are then integrated into LiRPA-based verification methods.
---

# Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verification

## Quick Facts
- arXiv ID: 2507.05405
- Source URL: https://arxiv.org/abs/2507.05405
- Authors: Luca Marzari; Ferdinando Cicalese; Alessandro Farinelli
- Reference count: 12
- Primary result: Achieves up to 3.62× improvement in certified robustness bounds compared to deterministic CROWN method

## Executive Summary
This paper presents a probabilistic framework for neural network verification that improves upon deterministic and existing probabilistic methods by providing tighter linear relaxation bounds with quantifiable confidence guarantees. The core idea combines statistical tolerance limits (Wilks' theorem) with extreme value theory (EVT) to compute probabilistically sound intermediate reachable sets, which are then integrated into LiRPA-based verification methods. By using sampling to estimate node bounds and adding EVT-based error corrections, the approach achieves tighter final output bounds while maintaining probabilistic soundness over the entire perturbation region.

## Method Summary
The method combines over-approximation techniques from LiRPA-based approaches with sampling-based methods to compute tight intermediate reachable sets. It uses Wilks' theorem to determine sample sizes for coverage guarantees and EVT to quantify the magnitude of potential bound violations. The approach replaces traditional IBP bounds in LiRPA backward propagation with probabilistically corrected bounds derived from sampled pre-activation values, achieving both soundness and improved tightness.

## Key Results
- Achieves 1.6×-3.62× improvement in certified robustness bounds compared to deterministic CROWN baseline
- Provides probabilistically sound guarantees with at least 99% confidence over entire perturbation regions
- Particularly effective on challenging VNN-COMP benchmarks where traditional methods fail
- Minimal computational overhead (typically under one second per verification) due to GPU acceleration

## Why This Works (Mechanism)

### Mechanism 1: Sampling-Based Intermediate Bound Tightening
Sampling from the perturbation region produces tighter intermediate reachable sets than deterministic over-approximation methods like IBP. Instead of computing conservative worst-case bounds, the method draws n i.i.d. samples, propagates them forward, and uses empirical min/max values as intermediate bounds.

### Mechanism 2: EVT-Based Error Quantification
Extreme value theory bounds the magnitude of potential bound violations, enabling probabilistically sound guarantees. From sample order statistics, the method estimates tail indices and computes corrections that add safety margins to observed bounds.

### Mechanism 3: Propagation of Tightened Bounds Through LiRPA
Tighter intermediate reachable sets produce tighter final output linear bounds while maintaining probabilistic soundness. The corrected bounds replace IBP bounds in the LiRPA backward pass, with the resulting linear bounds inheriting the probabilistic guarantee.

## Foundational Learning

- **Concept: LiRPA / CROWN-family verification**
  - Why needed: The framework builds on replacing IBP bounds in existing LiRPA methods
  - Quick check: Given a ReLU with pre-activation bounds [l, u] where l<0<u, can you compute lower-bound linear relaxation coefficients when next-layer coefficient A_j is negative?

- **Concept: Statistical tolerance limits (Wilks' theorem)**
  - Why needed: Provides theoretical foundation for sample size calculation
  - Quick check: If you need 99% confidence that at least 99.9% of points satisfy bounds, what minimum sample size does Wilks' theorem require?

- **Concept: Extreme Value Theory (order statistics, tail estimation)**
  - Why needed: Wilks' theorem bounds fraction of violations; EVT bounds their magnitude
  - Quick check: Why does Theorem 3.7 require splitting unstable ReLUs for the differentiability assumption?

## Architecture Onboarding

- **Component map:** Sample inputs → Forward propagate → Collect order statistics → Apply EVT correction → Construct D^(i), b^(i) → Backward LiRPA → Output bounds

- **Critical path:**
  1. Sample n points uniformly from perturbation region C
  2. Forward propagate all samples, collect pre-activation values per neuron
  3. Compute order statistics and EVT corrections
  4. Construct D^(i), b^(i) matrices using corrected bounds [ˆl, ˆu]
  5. Run backward LiRPA pass to get output bounds
  6. If f^C < 0, return UNSAFE; if f_C > 0, return SAFE; else split and recurse

- **Design tradeoffs:**
  - Sample size n: Larger n → tighter bounds but more memory/GPU time (paper uses 350k as stable point)
  - ξ parameter: Controls ν=⌊n^ξ⌋ for tail estimation (paper finds ξ∈[0.6, 0.85] stable)
  - Confidence p: Higher confidence (smaller p) → larger EVT correction → looser bounds

- **Failure signatures:**
  - GPU memory errors: Reduce batch size or sample count
  - Bounds looser than CROWN: Check EVT correction is not excessively large
  - Verification fails on known-safe instances: Intermediate bounds may be underestimated

- **First 3 experiments:**
  1. Reproduce toy example with 2-layer network: compute CROWN bounds, then PT-LiRPA bounds with n=10k samples, compare to MIP ground truth
  2. Run ξ sensitivity analysis on MNIST_2×[1024]_ReLU: sweep ξ∈{0.2, 0.4, 0.6, 0.8}, plot mean estimation error
  3. Integrate PT-LiRPA into α,β-CROWN toolbox and verify CIFAR_biasfield benchmark with n=350k, ξ=0.85, p=0.01; compare verified accuracy and time to baseline

## Open Questions the Paper Calls Out

### Open Question 1
Can the results of Theorem 3.7 be utilized to directly obtain a tight estimation of the output reachable set without relying on the LiRPA combination, while mitigating the risk of underestimation?

### Open Question 2
Is there a closed-form expression to determine the minimum sample size required to achieve a desired precision and confidence level, avoiding the need for empirical tuning?

### Open Question 3
How can EVT-based error corrections be adapted for non-differentiable activation functions (like ReLU) without the computational overhead of explicitly splitting unstable nodes?

## Limitations
- EVT-based error correction assumes pre-activation values follow distributions with well-defined tail indices, requiring ReLU splitting that introduces approximation error
- Method assumes uniform sampling from perturbation region, but adversarial regions may be highly non-uniform
- Computational efficiency claims depend heavily on GPU memory availability for large sample sets

## Confidence
- **Certified robustness improvements (3.62× vs CROWN):** High confidence - supported by extensive experimental results
- **Probabilistic soundness guarantees:** Medium confidence - theoretical framework sound but relies on assumptions
- **Computational efficiency claims:** Medium confidence - reported times reasonable but hardware-dependent
- **EVT-based error correction effectiveness:** Medium confidence - theoretical justification sound but practical impact varies

## Next Checks
1. **Tail index sensitivity analysis:** Systematically evaluate how different methods for estimating tail index affect final certified bounds and runtime
2. **Non-uniform sampling evaluation:** Compare uniform sampling against adaptive sampling strategies that prioritize regions near activation boundaries
3. **Memory-constrained scaling study:** Evaluate performance on larger networks under strict GPU memory constraints (4-8GB) and document performance degradation points