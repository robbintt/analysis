---
ver: rpa2
title: 'Armada: Memory-Efficient Distributed Training of Large-Scale Graph Neural
  Networks'
arxiv_id: '2502.17846'
source_url: https://arxiv.org/abs/2502.17846
tags:
- training
- graph
- armada
- batch
- grem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GNN workloads must distribute massive graphs across machines for
  efficient training, but this requires balancing memory usage with communication
  costs from neighborhood sampling. State-of-the-art min-edge-cut partitioning (e.g.,
  METIS) is effective but orders of magnitude slower and more memory-intensive than
  training itself.
---

# Armada: Memory-Efficient Distributed Training of Large-Scale Graph Neural Networks

## Quick Facts
- arXiv ID: 2502.17846
- Source URL: https://arxiv.org/abs/2502.17846
- Reference count: 26
- Key outcome: GREM achieves 8-65× less memory and 8-46× faster than METIS while matching edge-cut quality; disaggregated CPU-GPU separation yields up to 4.5× speedup and 3.1× cost reduction.

## Executive Summary
Distributed GNN training faces a bottleneck: partitioning massive graphs across machines requires balancing memory usage with communication costs from neighborhood sampling. State-of-the-art min-edge-cut partitioning (e.g., METIS) is orders of magnitude slower and more memory-intensive than training itself. Armada addresses this with GREM, a streaming greedy partitioning algorithm that continuously refines assignments using lightweight statistics, achieving edge-cut quality close to METIS while using 8-65× less memory and running 8-46× faster. Armada also introduces a disaggregated architecture, separating CPU batch preparation from GPU model computation, enabling independent scaling of each component. This eliminates CPU bottlenecks during multi-GPU training, yielding up to 4.5× runtime improvements and 3.1× cost reductions compared to existing systems.

## Method Summary
Armada tackles the memory and runtime bottleneck of graph partitioning in distributed GNN training. It introduces GREM, a streaming greedy partitioning algorithm that processes edge chunks (size 1-10%) and refines assignments using weighted neighbor count averaging. GREM starts with a METIS seed for the first chunk and iteratively improves partitions for subsequent chunks. The system also features a disaggregated architecture where CPU workers (m6a.16xlarge) handle batch preparation (sampling and feature loading) and GPU workers (p3.16xlarge) perform model computation. This separation allows independent scaling and eliminates CPU bottlenecks during multi-GPU training. The method is evaluated on OGBN-Papers100M, OGB-WikiKG90Mv2, OGBN-Products, and FB15K-237 using 3-layer GraphSage models with feature caching and mini-batch grouping.

## Key Results
- GREM achieves 8-65× less memory and 8-46× faster than METIS while maintaining comparable edge-cut quality.
- Disaggregated architecture yields up to 4.5× runtime speedup and 3.1× cost reduction compared to aggregated CPU-GPU setups.
- On OGBN-Papers100M with 8 GPUs, disaggregation improves epoch runtime by 7.5× versus traditional aggregation.

## Why This Works (Mechanism)
GREM works by streaming edges in chunks and using lightweight statistics to continuously refine partition assignments. Instead of computing exact min-edge-cut (which is NP-hard), it uses a greedy refinement step that averages neighbor counts across processed chunks. This allows it to make incremental improvements without the memory overhead of global optimization. The disaggregated architecture works by separating the CPU-bound batch preparation (sampling, feature loading) from GPU-bound model computation. This allows each component to scale independently and eliminates the CPU bottleneck that occurs when both tasks share the same node, especially with multiple GPUs.

## Foundational Learning

**Graph Partitioning (why needed)**: Dividing a graph across machines while minimizing edges cut between partitions. Needed to enable distributed GNN training on massive graphs. Quick check: Understand METIS as the gold standard for min-edge-cut partitioning.

**Streaming Greedy Partitioning (why needed)**: Partitioning graphs in a single pass without loading the entire graph into memory. Needed to handle graphs larger than available RAM. Quick check: Implement basic streaming greedy on OGBN-Products to verify edge-cut quality.

**Disaggregated Architecture (why needed)**: Separating CPU batch preparation from GPU model computation. Needed to eliminate CPU bottlenecks during multi-GPU training. Quick check: Compare scaling efficiency of 1 vs. 8 GPUs in aggregated vs. disaggregated setups.

**Feature Caching (why needed)**: Storing loaded node features in memory to avoid repeated disk/network access. Needed to reduce batch preparation time. Quick check: Measure cache hit rates in disaggregated setup.

**Mini-batch Grouping (why needed)**: Grouping multiple mini-batches with similar sampling patterns to amortize preparation costs. Needed to improve CPU utilization. Quick check: Compare preparation time with and without grouping on OGBN-Papers100M.

## Architecture Onboarding

**Component Map**: Edge Files -> GREM Partitioner -> Partitioned Graph -> Batch Workers (CPU) -> Compute Workers (GPU) -> Model Training

**Critical Path**: Edge processing in GREM → Partition assignment → Batch preparation (CPU) → Batch transfer → Model computation (GPU) → Gradient update

**Design Tradeoffs**: GREM trades optimal edge-cut quality for 8-46× faster runtime and 8-65× less memory usage. Disaggregation trades network communication overhead for elimination of CPU bottlenecks during multi-GPU training.

**Failure Signatures**: 
- Sublinear GPU scaling indicates CPU bottleneck or network congestion between batch and compute workers
- High edge cuts in GREM suggest incorrect implementation of the refinement step
- Low cache hit rates indicate insufficient memory allocation for feature caching

**First Experiments**:
1. Implement and benchmark GREM on OGBN-Products to verify edge-cut quality relative to standard streaming greedy
2. Construct minimal disaggregated prototype using DGL/PyG to test CPU-GPU separation benefit on smaller dataset
3. Profile network traffic in disaggregated setup to identify potential bottlenecks

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- No source code provided, making exact reproduction of disaggregated system architecture challenging
- GREM's edge-cut quality claim relative to METIS is asserted but not quantitatively benchmarked in paper tables
- GREM refinement step critical for performance but not fully detailed in terms of weighting scheme

## Confidence
**High Confidence**: GREM's memory efficiency and speed advantage over METIS are well-supported by scaling experiments. Disaggregated architecture's benefit in eliminating CPU bottlenecks is validated by speedup and cost reduction metrics.

**Medium Confidence**: GREM's edge-cut quality being "close to METIS" is asserted but exact cut ratios not provided for direct comparison.

**Major Limitations**: Lack of source code makes exact reproduction challenging. GREM refinement step is critical but not fully detailed.

## Next Checks
1. Implement and benchmark GREM on OGBN-Products to verify claimed edge-cut quality relative to standard streaming greedy methods
2. Construct minimal disaggregated prototype using DGL/PyG to test CPU-GPU separation benefit on smaller dataset
3. Profile network traffic in disaggregated setup to identify potential bottlenecks that could negate CPU-GPU separation benefit