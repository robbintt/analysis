---
ver: rpa2
title: 'User Perceptions vs. Proxy LLM Judges: Privacy and Helpfulness in LLM Responses
  to Privacy-Sensitive Scenarios'
arxiv_id: '2510.20721'
source_url: https://arxiv.org/abs/2510.20721
tags:
- llms
- proxy
- participants
- privacy
- evaluations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Researchers conducted a user study with 94 participants to evaluate\
  \ perceptions of privacy and helpfulness in LLM responses to 90 privacy-sensitive\
  \ scenarios from PrivacyLens. Participants found LLM responses generally helpful\
  \ and privacy-preserving but showed low agreement with each other when rating the\
  \ same response (Krippendorff\u2019s \u03B1=0.36)."
---

# User Perceptions vs. Proxy LLM Judges: Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios

## Quick Facts
- **arXiv ID**: 2510.20721
- **Source URL**: https://arxiv.org/abs/2510.20721
- **Reference count**: 40
- **Primary result**: Proxy LLMs cannot accurately estimate user perceptions of privacy and helpfulness in privacy-sensitive scenarios, showing weak-to-moderate correlation with human ratings while missing contextual nuances

## Executive Summary
This study investigates whether proxy LLM judges can accurately assess privacy and helpfulness in responses to privacy-sensitive scenarios. The researchers conducted a user study with 94 participants who rated 90 scenarios from PrivacyLens, revealing substantial individual variation in privacy and helpfulness perceptions (Krippendorff's α=0.36). Five different proxy LLM models showed strong agreement with each other (α=0.78) but only weak-to-moderate correlation with participants' average ratings (Spearman's ρ∈[0.24,0.68]). The findings demonstrate that proxy LLMs often miss contextual nuances and overlook sensitive information that participants identified, indicating they cannot reliably estimate the wide range of user perceptions regarding utility and privacy.

## Method Summary
The researchers conducted a user study with 94 participants who evaluated responses to 90 privacy-sensitive scenarios from PrivacyLens. Participants rated both the helpfulness and privacy-preserving nature of LLM responses. The study compared human ratings against five different proxy LLM models that independently evaluated the same responses. Inter-rater agreement was measured using Krippendorff's alpha, and correlation between human and proxy LLM ratings was assessed using Spearman's rho. The scenarios covered various privacy-sensitive contexts, and participants provided ratings on multiple dimensions of privacy and helpfulness.

## Key Results
- Proxy LLMs showed strong agreement with each other (Krippendorff's α=0.78) but only weak-to-moderate correlation with human ratings (Spearman's ρ∈[0.24,0.68])
- Participants found LLM responses generally helpful and privacy-preserving, but showed low agreement with each other (Krippendorff's α=0.36)
- Proxy LLMs often missed contextual nuances and overlooked clearly sensitive information that participants identified

## Why This Works (Mechanism)
The mechanism underlying these findings relates to the fundamental differences between human judgment and algorithmic evaluation. Humans bring contextual understanding, cultural background, and personal experiences to privacy assessments that current proxy LLMs cannot fully replicate. The low inter-rater agreement among participants (α=0.36) suggests that privacy perceptions are highly subjective and context-dependent, while proxy LLMs tend to apply more consistent but potentially oversimplified criteria. This discrepancy arises because LLMs rely on patterns in training data and predefined evaluation metrics, whereas humans consider nuanced contextual factors, personal values, and situational awareness when assessing privacy and helpfulness.

## Foundational Learning
- **Krippendorff's alpha**: Measures inter-rater reliability across multiple raters - needed to quantify agreement between participants and between proxy LLMs
- **Spearman's rank correlation**: Assesses monotonic relationships between human and LLM ratings - needed to evaluate how well proxy LLMs align with human judgments
- **PrivacyLens framework**: Provides standardized privacy-sensitive scenarios - needed to ensure consistent evaluation contexts across participants
- **Proxy LLM evaluation**: Uses LLMs to assess other LLMs' responses - needed to scale evaluation beyond human raters
- **Human-centered evaluation**: Incorporates actual user perceptions rather than proxy metrics - needed to capture real-world privacy concerns

## Architecture Onboarding

**Component Map**: User Interface -> Scenario Presentation -> Rating Collection -> Proxy LLM Evaluation -> Statistical Analysis

**Critical Path**: User submits rating → Aggregate human ratings → Proxy LLM evaluation → Correlation analysis → Agreement measurement

**Design Tradeoffs**: The study prioritized comprehensive human evaluation over larger scale automated assessment, sacrificing breadth for depth of understanding human perceptions. This choice provides rich qualitative insights but limits generalizability.

**Failure Signatures**: Low inter-rater agreement among humans (α=0.36) indicates subjective nature of privacy perceptions. Weak correlation between proxy LLMs and humans (ρ∈[0.24,0.68]) reveals systematic gaps in automated evaluation. Strong agreement among proxy LLMs (α=0.78) suggests potential echo chamber effects.

**First Experiments**: 1) Test additional proxy LLM models with different architectures to identify model-specific limitations, 2) Conduct stratified sampling of scenarios to isolate types where proxy LLMs fail most, 3) Implement human-in-the-loop validation for critical privacy decisions

## Open Questions the Paper Calls Out
Major uncertainties remain regarding the generalizability of these findings beyond the specific scenarios and user demographics studied. The relatively low inter-rater agreement among participants (Krippendorff's α=0.36) suggests substantial individual variation in privacy and helpfulness perceptions, but the underlying causes of this disagreement are not fully characterized. Additionally, the study only examined five proxy LLM models, leaving open questions about whether results would differ with other models or different prompting strategies.

## Limitations
- Study only examined five specific proxy LLM models, limiting generalizability to other architectures
- Participant demographics may not represent the full diversity of privacy perceptions across different populations
- Low inter-rater agreement among participants (α=0.36) makes it difficult to establish ground truth for privacy assessments
- Scenarios were drawn from a specific PrivacyLens dataset, which may not capture all privacy-sensitive contexts

## Confidence
**High Confidence**: The finding that proxy LLMs show strong agreement with each other (α=0.78) while showing weak-to-moderate correlation with human ratings (ρ∈[0.24,0.68])

**Medium Confidence**: The conclusion that proxy LLMs cannot accurately estimate user perceptions across the full spectrum of privacy and helpfulness judgments

**Medium Confidence**: The observation that proxy LLMs miss contextual nuances and overlook clearly sensitive information identified by participants

## Next Checks
1. Conduct the same study with a more diverse participant pool across different age groups, cultural backgrounds, and privacy expertise levels to assess generalizability
2. Test additional proxy LLM models with varying capabilities, architectures, and prompting strategies to determine if results are model-specific
3. Perform qualitative analysis of the specific types of contextual nuances and privacy considerations that proxy LLMs consistently miss compared to human participants