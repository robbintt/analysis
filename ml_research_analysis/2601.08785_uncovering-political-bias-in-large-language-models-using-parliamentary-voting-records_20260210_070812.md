---
ver: rpa2
title: Uncovering Political Bias in Large Language Models using Parliamentary Voting
  Records
arxiv_id: '2601.08785'
source_url: https://arxiv.org/abs/2601.08785
tags:
- bias
- political
- parties
- llms
- ideological
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel methodology for detecting political\
  \ bias in large language models (LLMs) by aligning model-generated voting predictions\
  \ with real-world parliamentary voting records. The authors construct three cross-national\
  \ benchmarks\u2014PoliBiasNL, PoliBiasNO, and PoliBiasES\u2014using thousands of\
  \ motions and corresponding party votes from the Netherlands, Norway, and Spain."
---

# Uncovering Political Bias in Large Language Models using Parliamentary Voting Records

## Quick Facts
- **arXiv ID:** 2601.08785
- **Source URL:** https://arxiv.org/abs/2601.08785
- **Reference count:** 40
- **Primary result:** LLMs exhibit consistent left-leaning/centrist tendencies and negative bias toward right-conservative parties when evaluated against parliamentary voting records

## Executive Summary
This paper introduces a novel methodology for detecting political bias in large language models (LLMs) by aligning model-generated voting predictions with real-world parliamentary voting records. The authors construct three cross-national benchmarks—PoliBiasNL, PoliBiasNO, and PoliBiasES—using thousands of motions and corresponding party votes from the Netherlands, Norway, and Spain. A key innovation is projecting both political parties and LLMs into a shared two-dimensional CHES ideological space via Partial Least Squares regression, enabling direct comparisons between model behavior and real-world political actors. Experiments with nine widely used LLMs reveal consistent left-leaning or centrist tendencies, alongside clear negative biases toward right-conservative parties across all three parliaments. These findings highlight the value of transparent, cross-national evaluation grounded in actual legislative behavior for understanding and auditing political bias in modern LLMs.

## Method Summary
The authors develop a comprehensive methodology for detecting political bias in LLMs using real-world parliamentary voting records. They construct three country-specific benchmarks (Netherlands, Norway, Spain) containing thousands of legislative motions and corresponding party voting data. The methodology involves three key steps: first, gathering parliamentary voting records and party positions; second, using Partial Least Squares (PLS) regression to project both parties and LLMs into a shared two-dimensional CHES ideological space; and third, comparing model voting predictions against actual party positions to quantify bias. The approach enables direct measurement of how closely LLM voting behavior aligns with specific political parties across different ideological dimensions.

## Key Results
- LLMs consistently exhibit left-leaning or centrist tendencies across all three country benchmarks
- Clear negative biases detected against right-conservative parties in Dutch, Norwegian, and Spanish parliaments
- Models can be positioned within the same ideological space as real political parties using PLS regression
- The methodology successfully reveals systematic political biases that vary by model and country context

## Why This Works (Mechanism)
The methodology works by creating a common evaluative framework where both political parties and LLMs can be directly compared. By using actual parliamentary voting records as ground truth and projecting all actors into a standardized ideological space, the approach eliminates the ambiguity inherent in subjective bias measurements. The PLS regression technique effectively captures the multidimensional nature of political ideology while reducing it to comparable dimensions. This allows for quantitative assessment of how closely model behavior matches real-world political positions across different policy domains.

## Foundational Learning
- **Parliamentary voting records as ground truth:** Real legislative votes provide objective, verifiable data about political positions; needed because subjective bias measures lack reliability; quick check: verify voting data covers diverse policy areas
- **CHES ideological scaling:** Standardizes political positions across countries; needed because direct comparison of different parliamentary systems is complex; quick check: ensure CHES dimensions capture meaningful political variation
- **PLS regression for dimensionality reduction:** Projects high-dimensional voting patterns into comparable space; needed because raw voting data is too complex for direct comparison; quick check: validate that PLS captures sufficient variance
- **Cross-national benchmarking:** Tests bias patterns across different political systems; needed because bias may manifest differently in different contexts; quick check: compare bias patterns across countries
- **Motion-based evaluation:** Uses specific legislative proposals rather than general statements; needed because concrete votes reveal clearer positions; quick check: ensure motion diversity across policy domains
- **Multi-model comparison:** Tests multiple LLMs to identify systematic patterns; needed because individual model variations could mask broader trends; quick check: assess consistency of bias patterns across models

## Architecture Onboarding

**Component Map:** Parliamentary Data -> PLS Projection -> LLM Voting Simulation -> Bias Quantification

**Critical Path:** Data Collection → PLS Regression → Model Evaluation → Bias Analysis

**Design Tradeoffs:** 
- Using English parliamentary data for non-English countries enables broader testing but may introduce linguistic bias
- Small sample size (7 motions/party) provides focused analysis but may miss nuanced positions
- Cross-national approach increases generalizability but adds complexity in data harmonization

**Failure Signatures:** 
- Inconsistent bias patterns across countries suggest methodological issues
- Poor PLS fit indicates inadequate ideological scaling
- Random voting patterns suggest models lack political understanding

**First Experiments:**
1. Test model voting consistency on identical motions across different prompts
2. Compare PLS projections with alternative dimensionality reduction methods
3. Evaluate model performance on motions from single policy domains

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on English-language parliamentary data for non-English speaking countries may introduce linguistic bias
- Assumption of stable party positions over time may not hold during political realignments
- Small sample size (seven motions per party) may not fully capture complex party ideologies

## Confidence
- **High Confidence:** Left-leaning/centrist tendencies are well-supported by consistent directional patterns across all three country benchmarks
- **Medium Confidence:** Specific quantitative positioning of models relative to parties has moderate confidence due to small sample size
- **Medium Confidence:** Cross-national generalizability claims are reasonably supported but would benefit from additional country samples

## Next Checks
1. Replicate analysis using native-language parliamentary data for Spain and Norway to assess linguistic bias effects
2. Expand motion sample size per party to 15-20 items to improve characterization stability and test robustness
3. Conduct temporal validation by comparing model predictions across different parliamentary sessions to assess bias stability over time