---
ver: rpa2
title: Efficient Optimal PAC Learning
arxiv_id: '2502.03620'
source_url: https://arxiv.org/abs/2502.03620
tags:
- training
- line
- probability
- which
- least
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents an efficient optimal PAC learner that improves\
  \ upon previous approaches by Hanneke and Larsen. The key insight is using empirical\
  \ risk minimization (ERM) with only \u0398(d) training examples to create majority\
  \ voters with good margins, then combining these through a recursive subsampling\
  \ scheme."
---

# Efficient Optimal PAC Learning

## Quick Facts
- arXiv ID: 2502.03620
- Source URL: https://arxiv.org/abs/2502.03620
- Reference count: 40
- Primary result: Achieves optimal PAC generalization error O((d + ln(1/δ))/m) with training complexity O(ln(m/(δ(d + ln(1/δ)))) · ln(m/δ) · (O(m + d ln(m)) + UT(550d) + 3m UI))

## Executive Summary
This paper presents an efficient optimal PAC learner that improves upon previous approaches by Hanneke and Larsen. The key insight is using empirical risk minimization (ERM) with only Θ(d) training examples to create majority voters with good margins, then combining these through a recursive subsampling scheme. The algorithm achieves the optimal PAC generalization error bound O((d + ln(1/δ))/m) while using only 550d training examples per ERM call. The approach differs from previous methods by avoiding the computational blowup from boosting while maintaining optimal error bounds.

## Method Summary
The algorithm recursively partitions the dataset into structured subsamples, trains weak learners (via ERM on small subsamples of size 550d) on each using a modified AdaBoost (AdaBoostSample), and constructs a final hypothesis by sampling one classifier from each ensemble and taking a majority vote. This achieves the optimal PAC generalization error bound while reducing the number of ERM queries from O(m) to O(d) per query. The training complexity is nearly linear in m, and inference complexity is logarithmic in m, representing a significant improvement over previous optimal PAC learners that required O(m) ERM queries.

## Key Results
- Achieves optimal PAC generalization error bound O((d + ln(1/δ))/m)
- Reduces ERM sample size from O(m) to O(d) while maintaining weak learner status
- Training complexity: O(ln(m/(δ(d + ln(1/δ)))) · ln(m/δ) · (O(m + d ln(m)) + UT(550d) + 3m UI))
- Inference complexity: O(ln(m/(δ(d + ln(1/δ))))) UI

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Limiting ERM queries to subsamples of size O(d) reduces training complexity dependency from UT(m) to UT(d) while maintaining weak learner status.
- Mechanism: The algorithm relies on the uniform convergence bound (Lemma 1), which implies that an ERM trained on ≈ 550d examples achieves a constant error (e.g., ≤ 1/20) with probability at least 1 - exp(-Θ(d)). This allows ERM to serve as a valid weak learner for boosting without processing the full dataset m.
- Core assumption: The hypothesis class has finite VC-dimension d, and the setting is realizable (target concept c ∈ H).
- Evidence anchors:
  - [abstract]: "queries the ERM subroutine with fewer training examples... of size O(d) instead of O(m)"
  - [section 3]: "ERM trained on Θ(d) training examples has a small constant error with probability at least 1 - exp(-d)"
  - [corpus]: Corpus signals discuss "Samplability makes learning easier" and "Proper Learnability," aligning with the strategy of leveraging structural properties of the hypothesis class to reduce sample complexity, though they do not validate the specific 550d constant.
- Break condition: If UT(550d) ≈ UT(m) (i.e., ERM does not scale with input size), the training complexity advantage disappears (see [Appendix A] Perceptron example).

### Mechanism 2
- Claim: A modified AdaBoost (AdaBoostSample) constructs a majority vote with large margins (3/4) on the training sequence using only the small-sample ERM queries.
- Mechanism: Since the ERM on 550d points is a γ-weak learner (γ ≈ 1/20), AdaBoost runs for t=O(ln m) rounds. The algorithm explicitly stops when the majority vote f = Σhi/t achieves a margin of θ=3/4 on the subsample. This guarantees that individual voters within the ensemble have high agreement with the label.
- Core assumption: The weak learner succeeds with sufficient probability in each round to maintain the boosting progress (failure probability δ/m per round).
- Evidence anchors:
  - [section 2]: "B uses ERM as a weak learner... output of B(Si) is a voting classifier... with good margins."
  - [section 7 Lemma 10]: Proof that the margin loss is bounded by (24/25)^t.
  - [corpus]: No direct corpus evidence for this specific boosting modification.
- Break condition: If the ERM weak learner failure probability exceeds the designed bound (e.g., if VC-dimension bounds are loose for the specific distribution), the boosting loop might terminate early without achieving margins.

### Mechanism 3
- Claim: Inference complexity is minimized by sampling a single hypothesis from the boosted ensembles rather than querying the full ensemble vote.
- Mechanism: The algorithm uses a hierarchical subsampling structure (Algorithm 4). The analysis proves that for most new examples, "3/4 of the majority voters have 3/4 of their voters correct." Therefore, sampling a row (subsample) and then a single hypothesis h from its boosted ensemble yields a correct prediction with probability >(3/4)^2 ≈ 0.56. By repeating this sampling l = O(ln(m/δ)) times, a majority vote of these individual hypotheses achieves the optimal PAC bound.
- Core assumption: The structured subsampling (Algorithm 4) creates sufficient independence and coverage (1/4-1/5 overlap analysis) to ensure the "majority of majorities" property holds.
- Evidence anchors:
  - [abstract]: "majority vote of classifiers trained on carefully structured subsamples... allowing the final learner to... with reduced computational cost."
  - [section 3.2]: "The inference complexity... does not suffer an increase of Θ(ln(m)) from the boosting step... since we can sample on the voters level."
  - [corpus]: Neighbor "Conditional Performance Guarantee for Large Reasoning Models" references PAC reasoning but does not support this specific hierarchical sampling mechanism.
- Break condition: If the base learners are not sufficiently better than random guessing on hard sub-problems, the probability (3/4)^2 drops, requiring l to increase significantly (though the paper argues this holds strictly because it is realizable).

## Foundational Learning

- Concept: **Empirical Risk Minimization (ERM) Sample Complexity**
  - Why needed here: The paper's core efficiency gain depends on understanding that you do not need m samples to find a consistent hypothesis; O(d) samples suffice to find a "pretty good" hypothesis (weak learner) for boosting.
  - Quick check question: Given a hypothesis class with VC-dim d, how many samples are needed to guarantee an ERM has error ≤ ε?

- Concept: **PAC Learning (Realizable Setting)**
  - Why needed here: The target "optimal PAC learner" is defined by the bound Θ((d + ln(1/δ))/m). One must distinguish between proper learning bounds (which include a ln(1/ε) factor) and the optimal improper bounds this paper achieves.
  - Quick check question: Why does standard ERM fail to achieve the *optimal* PAC bound, necessitating an improper learner like bagging or the method in this paper?

- Concept: **Boosting (AdaBoost)**
  - Why needed here: The paper uses a modified AdaBoost to convert the "weak" ERM learner (trained on small samples) into a "strong" majority voter with good margins.
  - Quick check question: How does the number of boosting rounds T relate to the training error and the edge γ of the weak learner?

## Architecture Onboarding

- Component map: Splitter -> AdaBoostSample (multiple instances) -> Final Learner
- Critical path: The execution time is dominated by the loop in Algorithm 6, specifically the ERM call and the 3m UI operations required to update the distribution over the entire training sequence S after each query.
- Design tradeoffs: The paper trades an increase in inference complexity (from 1 ERM query to l queries) and internal distribution updates (O(m) per boosting round) for a drastic reduction in ERM input size (from m to 550d). This is beneficial if UT(m) >> UT(d).
- Failure signatures:
  - Inefficient for fast ERMs: If UT(n) is linear or constant (e.g., simple linear separator), the overhead of distribution updates (O(m ln m)) may make this slower than standard ERM or Bagging.
  - Bloating l: If the "3/4 of majorities have 3/4 correct voters" condition fails, the sampling variance increases, requiring a larger l to maintain error bounds.
- First 3 experiments:
  1. Unit Test: Implement the sampler C^{-1} (Line 10, Algo 6) to verify that sampling 550d points from a weighted distribution Di yields a valid weighted subsample.
  2. Weak Learner Validation: Run ERM on 550d random samples from a realizable synthetic dataset (e.g., intervals on a line) and verify the error is consistently ≤ 1/20 to satisfy the boosting requirement.
  3. Perceptron Benchmark: Replicate the Appendix A experiment using the Perceptron algorithm as the ERM. Compare the runtime of Algorithm 5 vs. Larsen [2023] Bagging on a distribution with small margin to verify the O(m^2) vs O(m ln^2 m) gap.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can an optimal PAC learner be designed with training complexity that is strictly linear in the number of training examples m, removing the poly-logarithmic factors present in this work?
- Basis in paper: [explicit] The paper states that it "almost answers the second question affirmatively," achieving complexity that is linear "up to a ln^2(m)-factor."
- Why unresolved: The proposed algorithm introduces logarithmic dependencies on m and δ through the boosting steps and the sampling of structured sub-training sequences.
- What evidence would resolve it: An algorithm that achieves the optimal PAC error bound with a training complexity of O(m) without logarithmic multiplicative factors.

### Open Question 2
- Question: How does the computational complexity of the learner change under a refined model that accounts for the cost of generating the required randomness?
- Basis in paper: [explicit] The authors explicitly note in the "Use of randomness" section that they "are not taking into account if there is some computational cost in creating the randomness" and that the model is "arguably simplistic."
- Why unresolved: The analysis assumes reading a random variable costs one unit of computation, ignoring the potential overhead of generating Θ(d ln(m/δ)) continuous uniform random variables.
- What evidence would resolve it: A complexity analysis that integrates the bit-cost of randomness generation or an algorithm that achieves the same bounds using significantly less randomness.

### Open Question 3
- Question: Does the training cost of the ERM oracle on d points, denoted UT(d), inherently depend on the total sample size m in the distribution-free setting?
- Basis in paper: [explicit] The paper notes that "it is not always the case that these quantities are fixed as a function of m" and highlights the Perceptron example where training complexity scales with properties related to m.
- Why unresolved: While the algorithm queries the ERM with only O(d) points, the computational cost of solving the ERM on that subsample may theoretically scale with the distribution parameters implicit in the larger sample size m.
- What evidence would resolve it: A formal proof that UT(d) is independent of m for standard hypothesis classes in the distribution-free setting, or a characterization of the cases where such dependence exists.

### Open Question 4
- Question: Can the efficiency guarantees of this optimal learner be extended to the agnostic PAC learning setting?
- Basis in paper: [inferred] The paper explicitly restricts its scope to the "realizable setting" in Definition 1 and relies on the existence of a consistent hypothesis (ERM) for its margin guarantees.
- Why unresolved: The algorithm's reliance on AdaBoostSample and zero empirical risk minimizers does not directly translate to the agnostic setting where a perfect classifier may not exist.
- What evidence would resolve it: A modification of the subsampling and boosting framework that maintains optimal error bounds and efficient query complexity when the target concept is not perfectly realizable by the hypothesis class.

## Limitations

- The paper lacks empirical validation; no experimental results demonstrate claimed efficiency gains on real or synthetic datasets.
- The algorithm's advantage depends critically on the ERM complexity scaling poorly with sample size, which may not hold for many practical hypothesis classes.
- The constants (550d samples, 3/4 margin threshold) appear to be derived theoretically but may not be tight in practice.

## Confidence

- **High Confidence**: The theoretical framework and proof structure are sound, following established PAC learning and boosting theory. The reduction from O(m) to O(d) ERM samples is well-justified through uniform convergence bounds.
- **Medium Confidence**: The computational complexity analysis assumes specific scaling properties of ERM that may vary by implementation. The claimed training complexity gains depend on UT(m) >> UT(550d), which requires empirical verification.
- **Low Confidence**: The constants (550d, 3/4 margin) are derived from theoretical bounds but their practical optimality is unclear without experimental validation.

## Next Checks

1. **Empirical Efficiency Benchmark**: Implement the algorithm and compare training times against standard ERM and Larsen's Bagging on a synthetic dataset with known margin properties, measuring actual runtime vs. theoretical complexity predictions.

2. **Weak Learner Robustness Test**: Systematically vary the sample size (from 100d to 1000d) in the ERM subroutine and measure the resulting margin achievement rate in AdaBoostSample to determine if the 550d constant is tight.

3. **VC Dimension Sensitivity**: Test the algorithm on hypothesis classes with different VC dimensions (e.g., intervals vs. axis-aligned rectangles vs. linear separators) to verify the d scaling claims and identify when the algorithm provides the most benefit.