---
ver: rpa2
title: Knowledge Graph Tokenization for Behavior-Aware Generative Next POI Recommendation
arxiv_id: '2509.12350'
source_url: https://arxiv.org/abs/2509.12350
tags:
- kgtb
- next
- recommendation
- uni00000013
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the limitations of existing generative POI
  recommendation methods: information loss during tokenization and insufficient mobility
  understanding during generation. It proposes KGTB, which constructs a knowledge
  graph to preserve heterogeneous recommendation data and develops a KG-based tokenizer
  to generate structural IDs (StruIDs) that incorporate this information.'
---

# Knowledge Graph Tokenization for Behavior-Aware Generative Next POI Recommendation

## Quick Facts
- arXiv ID: 2509.12350
- Source URL: https://arxiv.org/abs/2509.12350
- Authors: Ke Sun; Mayi Xu
- Reference count: 10
- One-line primary result: KGTB achieves up to 14.4% improvement in NDCG@10 compared to best baseline

## Executive Summary
The paper addresses information loss during tokenization and insufficient mobility understanding in generative POI recommendation methods. It proposes KGTB, which constructs a knowledge graph to preserve heterogeneous recommendation data and develops a KG-based tokenizer to generate structural IDs (StruIDs) that incorporate this information. Additionally, KGTB introduces multi-behavior learning with tasks for predicting next POI, category, and region visit behaviors to enhance LLM understanding of mobility. Experiments on four real-world datasets demonstrate KGTB's superior performance, achieving up to 14.4% improvement in NDCG@10 compared to the best baseline.

## Method Summary
KGTB constructs a knowledge graph containing users, POIs, categories, and regions with relations including visit, adjacency, categorization, and location. A 3-layer RGCN encoder generates node embeddings, which are quantized into discrete StruIDs using a 3-layer residual quantization system. The LLM (GPT-2 or Llama3) is fine-tuned with LoRA adapters on instruction-tuned data that combines user trajectories with multi-behavior prediction tasks. The tokenizer is supervised by KG reconstruction loss to preserve structural relationships, while the LLM is trained on predicting next POI, category, and region behaviors simultaneously.

## Key Results
- Achieves up to 14.4% improvement in NDCG@10 compared to best baseline
- Better handling of cold-start POIs through structural ID representation
- Stronger out-of-domain generalization capabilities
- Improved computational efficiency in recommendation tasks

## Why This Works (Mechanism)

### Mechanism 1
Structural IDs (StruIDs) reduce information loss compared to feature-based Semantic IDs (SIDs) by preserving heterogeneous relational data during tokenization. The system constructs a Knowledge Graph (KG) containing users, POIs, categories, and regions. An RGCN encoder generates node embeddings, which are then quantized into discrete tokens (StruIDs). Crucially, a KG Reconstruction objective ($L_{KG}$) trains the quantizer to recover graph links (e.g., POI-to-Category) from the discrete tokens. This forces the tokenizer to retain structural "fingerprints" in the ID itself, rather than just semantic feature similarity.

### Mechanism 2
Multi-behavior learning improves next-POI accuracy by providing auxiliary supervision signals (category and region prediction) that contextualize user intent. The LLM is fine-tuned not just on "Predict Next POI," but simultaneously on "Predict Next Category" and "Predict Next Region." By learning to predict the type of place and the area first, the model implicitly learns a hierarchical decision process (Intent → Region → Specific POI), which regularizes the LLM against spurious correlations in the main POI prediction task.

### Mechanism 3
StruIDs enhance generalization to cold-start and out-of-domain scenarios because similarity in StruID space implies structural equivalence rather than just ID matching. Because StruIDs are derived from RGCN neighborhoods, two different POIs in different cities but with similar relational contexts (e.g., "coffee shop adjacent to a subway station") will generate similar StruID prefixes. This allows the LLM to transfer patterns learned in the source domain to unseen target domains or new POIs based on their graph context.

## Foundational Learning

- **Concept**: Relational Graph Convolutional Networks (RGCN)
  - **Why needed here**: Standard GCNs treat all edges equally; RGCNs use relation-specific weights, allowing the model to distinguish between a "Visit" edge and an "Adjacent" edge, which is critical for the KG tokenizer.
  - **Quick check question**: Can you explain why a standard GCN would struggle to differentiate the importance of a user visiting a POI vs. that POI being near another POI?

- **Concept**: Residual Quantization (RQ-VAE)
  - **Why needed here**: This generates the multi-token "StruID". It approximates the continuous node embedding via a sum of discrete vectors from a codebook, allowing an LLM to process graph nodes as sequences of text tokens.
  - **Quick check question**: How does the "residual" connection in RQ-VAE ensure that later tokens in a StruID capture finer-grained details?

- **Concept**: Instruction Tuning
  - **Why needed here**: This bridges the gap between the LLM's pre-training and the recommendation task. It converts the structured recommendation data into natural language prompts ("The user visited X, predict Y").
  - **Quick check question**: Why is the format of the "Input Block" (preference + trajectory) critical for the LLM to understand the sequential context?

## Architecture Onboarding

- **Component map**: Data Ingest → Knowledge Graph Construction → Tokenizer (RGCN Encoder → Multi-layer Quantizer → StruID vocabulary) → LLM Engine (GPT-2/Llama3 with LoRA) → Prompt Handler

- **Critical path**: The KG Reconstruction Loss ($L_{KG}$). If this is not trained to convergence, the StruIDs become random noise, and the LLM cannot decode structural relationships. You must verify that the tokenizer can reconstruct edge types before starting LLM training.

- **Design tradeoffs**:
  - **Codebook Size ($K$) vs. Sequence Length ($L$)**: Larger codebooks capture more distinct concepts per token but increase memory; deeper sequences ($L$) capture more detail but increase LLM inference latency. The paper uses $L=3$.
  - **RGCN Depth**: Deeper layers capture global graph structure but risk "over-smoothing" node embeddings, making distinct POIs indistinguishable.

- **Failure signatures**:
  - **Tokenizer Collapse**: StruIDs cluster poorly (visualization looks like noise). Fix: Check learning rate or increase codebook size.
  - **LLM Hallucination**: Model generates valid StruIDs that do not exist in the vocabulary. Fix: Constrain decoding or check vocabulary mapping.
  - **Domain Drop**: Performance tanks on new city. Fix: Check if the new city's graph density matches training assumptions.

- **First 3 experiments**:
  1. **Tokenizer Integrity**: Train the RGCN+Quantizer. Measure the reconstruction accuracy of links ($L_{KG}$) on a hold-out set. If low, the IDs are defective.
  2. **Ablation on Tasks**: Train the LLM with only POI prediction vs. POI + Category + Region. Compare N@5 to quantify the "Multi-Behavior" lift.
  3. **Cold Start Injection**: Mask 20% of POIs during training (treating them as "new") and check if the model can still recommend them based solely on their StruID (derived from category/region links).

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the text provided.

## Limitations
- Region granularity definition is ambiguous (grid size, administrative boundaries, or clustering method not specified)
- Codebook utilization statistics across quantization layers are not reported
- Multi-behavior task weighting and potential gradient interference are not explored

## Confidence

- **High Confidence**: Experimental methodology (metrics, datasets, evaluation protocol) is well-defined and reproducible. Ablation studies comparing StruIDs to Semantic IDs are robust.
- **Medium Confidence**: Multi-behavior learning contribution is plausible but exact gradient dynamics and potential for negative transfer are not explored.
- **Low Confidence**: Out-of-domain generalization claim relies on single cross-city transfer experiment without diverse domain shifts.

## Next Checks

1. **Region Granularity Sensitivity Analysis**: Re-run KG construction with different region granularities (e.g., 500m, 1km, 2km grids) and measure impact on POI recommendation accuracy.

2. **Codebook Utilization Audit**: Train tokenizer and produce histogram of code usage across all three quantization layers. Verify no layer collapses to using fewer than 20% of available codes.

3. **Cross-Domain Topology Test**: Evaluate KGTB on dataset with drastically different graph structure (e.g., Gowalla vs. rural area with sparse check-ins). Measure performance drop compared to claimed out-of-domain generalization advantage.