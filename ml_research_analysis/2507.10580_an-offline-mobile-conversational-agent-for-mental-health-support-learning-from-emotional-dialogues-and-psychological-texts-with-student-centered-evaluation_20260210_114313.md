---
ver: rpa2
title: 'An Offline Mobile Conversational Agent for Mental Health Support: Learning
  from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation'
arxiv_id: '2507.10580'
source_url: https://arxiv.org/abs/2507.10580
tags:
- health
- mental
- support
- emotional
- your
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EmoSApp is an offline smartphone-based conversational AI designed
  to provide mental health and emotional support to students. It fine-tunes and quantizes
  LLaMA-3.2-1B-Instruct on a custom knowledge dataset of 14,582 mental health QA pairs
  plus multi-turn conversational data, enabling fully on-device inference on resource-constrained
  devices.
---

# An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation

## Quick Facts
- arXiv ID: 2507.10580
- Source URL: https://arxiv.org/abs/2507.10580
- Reference count: 27
- EmoSApp achieves 39.34% accuracy on MHQA and 46.63 F1 on Dreaddit using QAT-LoRA while running fully offline on 6GB RAM devices

## Executive Summary
EmoSApp is an offline smartphone-based conversational AI designed to provide mental health and emotional support to students. It fine-tunes and quantizes LLaMA-3.2-1B-Instruct on a custom knowledge dataset of 14,582 mental health QA pairs plus multi-turn conversational data, enabling fully on-device inference on resource-constrained devices. Quantitative evaluation on nine general benchmarks and two mental health-specific datasets shows competitive performance versus larger baselines, with the QAT-LoRA variant achieving 39.34% accuracy on MHQA and 46.63 F1 on Dreaddit while using as little as 6 GB RAM. Qualitative student, professional, and LLM-based evaluations demonstrate that EmoSApp delivers coherent, empathetic, and contextually relevant responses with safety scores near 1 (completely safe). The system offers a portable, privacy-preserving alternative to internet-dependent mental health chatbots.

## Method Summary
The authors developed EmoSApp by fine-tuning LLaMA-3.2-1B-Instruct on three custom datasets: a Knowledge Dataset of 14,582 mental health QA pairs from psychology textbooks, ESConv with 1,300 dialogues, and ServeForEmo with 3,743 dialogues. Three training variants were explored: Full fine-tuning, LoRA + PTQ, and QAT-LoRA. The QAT-LoRA approach uses LoRA rank r=16, alpha=32 on attention projections with Int8DynActInt4WeightQAT quantization (4-bit group-wise weights, 8-bit dynamic activations), fake quantization delayed 1,000 steps. Training used AdamW optimizer with lr=3e-5, linear warmup over 1% steps, batch size 4, and 5 epochs. Models were deployed via ExecuTorch for on-device inference on Android devices with ≥6GB RAM.

## Key Results
- QAT-LoRA variant achieves 39.34% accuracy on MHQA and 46.63 F1 on Dreaddit
- Full fine-tuned model scores 44.40% on MHQA and 58.23 F1 on Dreaddit
- Memory usage: QAT-LoRA uses 6 GB RAM, Full fine-tuning requires 8 GB RAM

## Why This Works (Mechanism)
EmoSApp works by combining domain-specific knowledge with emotional intelligence through multi-stage fine-tuning. The model first learns general conversational patterns from emotional dialogue datasets, then incorporates specialized mental health knowledge from textbooks. Quantization techniques preserve performance while reducing memory footprint, enabling deployment on consumer smartphones. The instruction-tuned base model provides strong general reasoning capabilities that transfer well to mental health contexts when combined with targeted fine-tuning on relevant data.

## Foundational Learning
- **Instruction Tuning**: Why needed: Enables models to follow conversational prompts and user instructions. Quick check: Test model response to varied instruction formats and complexity levels.
- **LoRA Fine-tuning**: Why needed: Reduces training costs while maintaining performance on specialized tasks. Quick check: Compare performance with and without LoRA across different rank values.
- **Quantization**: Why needed: Reduces memory footprint for mobile deployment without significant accuracy loss. Quick check: Measure accuracy drop when moving from FP16 to INT4/INT8 representations.

## Architecture Onboarding
- **Component Map**: Knowledge Dataset -> Fine-tuning -> Quantization -> ExecuTorch Export -> Android Inference
- **Critical Path**: Custom datasets → Multi-stage fine-tuning → Quantization (QAT-LoRA) → ExecuTorch deployment → On-device inference
- **Design Tradeoffs**: Memory vs. accuracy (QAT-LoRA: 6GB/39.34% vs Full: 8GB/44.40%), computational efficiency vs. response quality, privacy vs. internet dependency
- **Failure Signatures**: Memory OOM errors on devices with <6GB RAM, degraded response quality when using LoRA+PTQ instead of QAT-LoRA, slow inference if ExecuTorch optimizations not properly applied
- **3 First Experiments**: 1) Test basic inference on Android device with 6GB RAM, 2) Compare QAT-LoRA vs LoRA+PTQ performance on MHQA, 3) Validate response quality on sample emotional dialogues

## Open Questions the Paper Calls Out
None

## Limitations
- Qualitative evaluation based on small sample (12 students, 3 professionals) limiting generalizability
- No long-term effectiveness studies or user engagement metrics reported
- Clinical efficacy not validated through controlled trials or comparison with professional mental health services

## Confidence
- **High confidence**: Technical implementation details, quantitative benchmark results, memory footprint measurements
- **Medium confidence**: Qualitative evaluation findings, safety and empathy ratings
- **Low confidence**: Claims about replacing or complementing traditional mental health services

## Next Checks
1. Conduct statistical significance testing on benchmark comparisons between QAT-LoRA, LoRA+PTQ, and Full fine-tuning variants
2. Expand qualitative evaluation to 50+ participants across diverse demographics with longitudinal assessment over 4+ weeks
3. Perform clinical validation through controlled trials comparing EmoSApp responses against professional mental health guidelines and measuring user outcomes against established assessment tools