---
ver: rpa2
title: Dynamic Priors in Bayesian Optimization for Hyperparameter Optimization
arxiv_id: '2511.02570'
source_url: https://arxiv.org/abs/2511.02570
tags:
- priors
- regret
- optimization
- prior
- dynabo
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces DynaBO, a Bayesian optimization framework
  that allows users to dynamically inject prior knowledge during hyperparameter optimization.
  Unlike prior work, which restricts user input to initialization, DynaBO enables
  repeated interventions at runtime, combining prior-weighted acquisition functions
  with a safeguard to detect and reject misleading priors.
---

# Dynamic Priors in Bayesian Optimization for Hyperparameter Optimization

## Quick Facts
- arXiv ID: 2511.02570
- Source URL: https://arxiv.org/abs/2511.02570
- Reference count: 40
- Enables dynamic user input during Bayesian optimization, outperforming state-of-the-art HPO methods

## Executive Summary
This paper introduces DynaBO, a novel framework that allows users to dynamically inject prior knowledge during Bayesian optimization for hyperparameter optimization. Unlike existing methods that restrict user input to initialization, DynaBO enables repeated interventions at runtime through a prior-weighted acquisition function combined with a safeguard mechanism to detect and reject misleading priors. The framework generalizes πBO by supporting multiple decaying priors while maintaining theoretical convergence guarantees. Empirical results demonstrate that DynaBO outperforms state-of-the-art competitors across diverse benchmarks, including deep learning models, for various prior types from expert knowledge to adversarial inputs.

## Method Summary
DynaBO extends Bayesian optimization by introducing a dynamic prior injection mechanism that allows users to provide information during the optimization process, not just at initialization. The core innovation is a prior-weighted acquisition function that combines multiple user-provided priors with decaying weights over time, preventing any single prior from dominating the search. A key safeguard mechanism automatically detects and rejects misleading priors by monitoring their impact on optimization progress. The framework maintains convergence guarantees by ensuring the combined acquisition function remains an unbiased estimator of the true objective. DynaBO builds upon πBO's foundation but generalizes it to handle multiple priors simultaneously while preserving theoretical properties.

## Key Results
- Outperforms state-of-the-art HPO methods across diverse benchmarks including deep learning models
- Robust to all prior types, from expert knowledge to adversarial inputs
- Prior rejection mechanism improves robustness without significant performance degradation
- Maintains theoretical convergence guarantees while enabling dynamic user interaction

## Why This Works (Mechanism)
DynaBO works by decomposing the acquisition function into multiple weighted components, each representing a user-provided prior or the default optimization objective. The dynamic weighting scheme ensures that priors gradually decay in influence, preventing them from overwhelming the optimization process while still benefiting from early guidance. The safeguard mechanism monitors optimization progress and automatically reduces the weight of priors that appear to be misleading, effectively filtering out bad advice while preserving useful information. This combination allows users to provide continuous feedback without risking optimization failure, creating a robust human-in-the-loop system.

## Foundational Learning
- Bayesian Optimization fundamentals: Understanding acquisition functions and GP surrogates is essential for grasping how DynaBO modifies standard BO
- Prior injection mechanisms: Knowledge of how priors influence optimization decisions explains why dynamic injection is valuable
- Decay scheduling: Understanding how to balance prior influence over time is crucial for preventing premature convergence
- Safeguard detection: Learning how to identify misleading priors without explicit user feedback is key to robust operation

## Architecture Onboarding
Component map: User Interface -> Prior Processor -> Weighted Acquisition -> GP Model -> Optimizer -> Results
Critical path: User provides prior → Prior processor validates and weights → Acquisition function combines priors with BO objective → GP model updates → Optimizer selects next point → Results inform next iteration
Design tradeoffs: Balancing prior influence versus exploration, computational overhead of multiple priors versus single initialization, complexity of safeguard mechanism versus simple prior weighting
Failure signatures: Optimization stuck in poor regions (overly strong priors), excessive computation time (too many priors), oscillation between regions (conflicting priors)
First experiments: 1) Single prior injection on synthetic function, 2) Multiple prior injection on standard HPO benchmark, 3) Adversarial prior testing on deep learning model

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability to extremely high-dimensional hyperparameter spaces remains uncertain
- Robustness when user-provided priors are both strong and adversarial needs further validation
- Sample efficiency claims may not generalize to industrial-scale deep learning models with hundreds of hyperparameters

## Confidence
High confidence in theoretical framework and convergence guarantees
Medium confidence in empirical performance claims
Low confidence in practical usability assessment

## Next Checks
1. Test DynaBO on high-dimensional HPO problems (100+ hyperparameters) from real-world deep learning applications
2. Conduct ablation studies with varying prior rejection thresholds to establish practitioner guidelines
3. Perform user studies measuring cognitive load and decision-making patterns during prior injection