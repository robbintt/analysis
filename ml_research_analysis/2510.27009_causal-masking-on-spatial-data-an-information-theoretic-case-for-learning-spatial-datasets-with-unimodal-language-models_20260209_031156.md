---
ver: rpa2
title: 'Causal Masking on Spatial Data: An Information-Theoretic Case for Learning
  Spatial Datasets with Unimodal Language Models'
arxiv_id: '2510.27009'
source_url: https://arxiv.org/abs/2510.27009
tags:
- chess
- causal
- spatial
- move
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates whether causal masking can be applied to
  spatial data without the information loss incurred by sequentializing that data
  first. Using chess as a testbed, the authors compare models trained on FEN (spatial
  board state) with and without causal masking to models trained on PGN (sequential
  moves).
---

# Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models

## Quick Facts
- **arXiv ID**: 2510.27009
- **Source URL**: https://arxiv.org/abs/2510.27009
- **Reference count**: 30
- **Primary result**: Causal masking on spatial data remains viable and often preferable to sequential linearization for training unimodal LLMs on structured spatial tasks

## Executive Summary
This paper investigates whether causal masking can be applied to spatial data without the information loss incurred by sequentializing that data first. Using chess as a testbed, the authors compare models trained on FEN (spatial board state) with and without causal masking to models trained on PGN (sequential moves). They find that FEN-trained models consistently outperform PGN-trained models, and that a causal-masked FEN model achieves grandmaster-level play (≈2630 Elo) despite losing bidirectional information. This demonstrates that applying causal masking directly to spatial data is viable—and in this domain, preferable to sequential linearization—for training unimodal language models on structured spatial tasks.

## Method Summary
The authors fine-tune decoder-only transformer models (Llama-3.1-1.3B and NanoGPT) on chess data using character-level tokenization of FEN strings with causal masking. The training objective is masked cross-entropy over best-move tokens only. FEN-trained models learn a direct mapping from board state to moves, while PGN-trained models must learn a composition of functions to reconstruct spatial structure from sequential move history. Models are evaluated on held-out ChessBench positions for valid/legal/best move rates and Elo performance against Stockfish.

## Key Results
- Causal-masked FEN model achieves ~2630 Elo vs. bidirectional FEN model at ~2680 Elo—only marginally worse
- Causal FEN model achieves 58% best-move accuracy vs. 40% for causal PGN
- Character-level tokenization was necessary for stable convergence with pretrained LLMs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Training on spatial representations (FEN) outperforms sequential representations (PGN) for inherently spatial reasoning tasks, even when causal masking is applied to the spatial data.
- **Mechanism**: PGN-trained models must learn a composition of functions G ∘ (F → S), where G reconstructs latent spatial board states from sequential move history. FEN-trained models learn a direct mapping F → S, bypassing the representational complexity of spatial reconstruction.
- **Core assumption**: The representational complexity of reconstructing spatial structure from sequential data exceeds the information loss from applying causal masking to spatial data.
- **Evidence anchors**: [abstract] "models trained on spatial board states - even with causal masking - consistently achieve stronger playing strength than models trained on sequential data"; [section 3.1] "We hypothesize that the composition G ∘ (F → S) entails greater representational complexity than the direct mapping from FEN to SAN moves F → S"

### Mechanism 2
- **Claim**: Causal masking on spatial data remains viable because the task-relevant information in chess is primarily about current board state relationships, not bidirectional context within a single FEN string.
- **Mechanism**: FEN represents a single board snapshot. While causal masking prevents attending to "future" tokens in the FEN string, the spatial relationships between pieces are encoded in the token sequence itself. The model learns to extract spatial patterns through sequential processing of spatially-structured tokens.
- **Core assumption**: The information lost by preventing bidirectional attention within a single FEN string is less critical than preserving native spatial structure.
- **Evidence anchors**: [section 4.3] Causal-masked Llama achieves ~2630 Elo vs. bidirectional FEN model at ~2680 Elo—only marginally worse; [section 4.3] Causal FEN model achieves 58% best-move accuracy vs. 60% for bidirectional FEN

### Mechanism 3
- **Claim**: Character-level tokenization aligned to domain structure is necessary for stable convergence when adapting pretrained LLMs to structured symbolic domains.
- **Mechanism**: Pretrained tokenizers merge character sequences (e.g., "pk" → single token), creating ambiguous representations that misalign with domain semantics. Character-level tokenization ensures each piece and empty square maps consistently.
- **Core assumption**: Tokenizer-domain misalignment creates gradient signal interference during training.
- **Evidence anchors**: [section 5.3] "Both the Pythia and Llama models failed to converge under their default tokenizers... After this modification, models trained stably and achieved strong performance"; [appendix F] Llama's tokenizer would merge "pk" as [21486], but character-level enforces [79, 74]

## Foundational Learning

- **Concept: Causal vs. Bidirectional Attention**
  - **Why needed here**: Understanding what information is lost when causal masking is applied to spatial data is central to interpreting the results.
  - **Quick check question**: Can a causally-masked model attend to tokens that appear later in the input sequence?

- **Concept: Markov Property in Sequential Decision-Making**
  - **Why needed here**: Chess is nearly first-order Markovian (current state determines optimal policy), which explains why FEN (current state only) performs well despite lacking move history.
  - **Quick check question**: Why does the threefold repetition rule technically violate the Markov property in chess?

- **Concept: Teacher Forcing and Exposure Bias**
  - **Why needed here**: The training objective uses teacher forcing; understanding the train-inference distribution gap helps interpret reported exposure bias metrics.
  - **Quick check question**: What distribution mismatch occurs between training and inference in autoregressive models?

## Architecture Onboarding

- **Component map**: FEN string + legal moves list → character-level tokenizer → templated prompt → decoder-only transformer with lower-triangular causal mask → SAN move tokens → masked loss on best-move tokens

- **Critical path**:
  1. Flatten FEN run-length encodings (e.g., "3" → "...")
  2. Enforce character-level tokenization
  3. Construct prompt with FEN + legal moves + best move
  4. Apply causal mask; compute loss only on best-move tokens

- **Design tradeoffs**:
  - Character-level tokenization increases sequence length but ensures domain alignment
  - Causal masking loses bidirectional context but enables use of standard decoder-only architectures
  - FEN-only training cannot detect threefold repetition (limitation noted by authors)

- **Failure signatures**:
  - Non-converging loss with default tokenizer (ambiguous merges)
  - High illegal move rate indicates prompt/tokenizer misalignment
  - Large train-inference gap suggests exposure bias (authors report modest ~3% drop)

- **First 3 experiments**:
  1. Validate tokenization: Train a small model with default vs. character-level tokenizer on a held-out subset; compare convergence curves.
  2. Ablate attention type: Train identical architectures with causal vs. bidirectional masking on FEN; measure Elo gap (expect ~50 points based on paper).
  3. Cross-validate representation: Train on PGN vs. FEN with matched data and compute; report best-move accuracy and loss (expect ~20 percentage point gap).

## Open Questions the Paper Calls Out

- **Open Question 1**: Does pretraining quality or non-embedding parameter count determine performance differences when models are overparameterized relative to a task? (Basis: Section 5.1 observation that Llama outperformed Pythia despite both being overparameterized; resolution requires controlled experiments varying pretraining duration/quality while holding parameter count constant, and vice versa)

- **Open Question 2**: Does applying causal masking directly to spatial data outperform sequentialization in domains beyond chess? (Basis: Abstract states results "may have broader implications"; resolution requires replicating FEN-vs-PGN comparison paradigm on other structured spatial domains with dual representations)

- **Open Question 3**: Can causal-masked spatial models be augmented to handle state-history-dependent rules without sacrificing their performance advantages? (Basis: Section 6 limitation that FEN models are blind to threefold repetition rule; resolution requires comparing mechanisms that inject history information against baseline causal-masked FEN model)

## Limitations

- Experimental scope limited to chess as single testbed, preventing broader claims about spatial data in general
- FEN-only models cannot detect threefold repetition, representing a known domain-specific blind spot
- Character-level tokenization intervention may not generalize to all domains

## Confidence

- **High confidence**: Causal masking on spatial data (FEN) outperforms sequential data (PGN) for chess, and spatial representations remain viable despite losing bidirectional context
- **Medium confidence**: The mechanism that FEN-trained models learn a simpler function than PGN-trained models is plausible but not definitively proven
- **Medium confidence**: Character-level tokenization is necessary for stable convergence with pretrained LLMs on structured symbolic domains

## Next Checks

1. Apply the same methodology to another spatial reasoning task (e.g., Go, Sokoban, or circuit design) to test whether FEN-style spatial representations consistently outperform PGN-style sequentializations under causal masking

2. Train FEN models with different attention patterns (e.g., sparse attention, local windows) to isolate how much of the performance comes from spatial structure versus the specific attention mechanism

3. Systematically vary tokenizer granularity (character, subword, byte-pair) across multiple structured domains to quantify when tokenizer-domain misalignment becomes problematic