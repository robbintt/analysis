---
ver: rpa2
title: 'Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large
  Language Model'
arxiv_id: '2501.11953'
source_url: https://arxiv.org/abs/2501.11953
tags:
- translation
- proverb
- proverbs
- language
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how well current machine translation (MT)
  systems, including both NMT and LLM-based models, can translate proverbs, which
  are culturally rooted expressions. The authors construct two datasets: one with
  standalone proverbs and another with proverbs used in conversations across four
  language pairs.'
---

# Proverbs Run in Pairs: Evaluating Proverb Translation Capability of Large Language Model

## Quick Facts
- arXiv ID: 2501.11953
- Source URL: https://arxiv.org/abs/2501.11953
- Authors: Minghan Wang; Viet-Thanh Pham; Farhad Moghimifar; Thuy-Trang Vu
- Reference count: 27
- Key outcome: LLMs outperform NMT models in proverb translation, especially for culturally similar languages, but automatic evaluation metrics are inadequate for assessing proverb translation quality.

## Executive Summary
This paper investigates how well current machine translation systems, including both NMT and LLM-based models, can translate proverbs, which are culturally rooted expressions. The authors construct two datasets: one with standalone proverbs and another with proverbs used in conversations across four language pairs. They evaluate multiple models using automatic metrics (BLEU, CHRF++, COMET) and LLM-as-a-judge. Results show that LLMs generally outperform NMT models in proverb translation, especially between languages from similar cultural backgrounds. The study also reveals that existing automatic evaluation metrics are inadequate for assessing the quality of proverb translation, as they are overly sensitive to lexical differences and fail to capture semantic equivalence.

## Method Summary
The paper constructs two proverb translation datasets: the extended MAPS dataset containing standalone proverbs with translations and explanations, and the Proverb-in-Conversation (PiC) dataset mined from OpenSubtitles using edit-distance matching, LLM filtering, and quality estimation. The authors evaluate multiple models including NLLB (600M-3.3B), instruction-tuned LLMs (Mistral-7B, Qwen2-7B, Llama-3.1-8B/70B, Gemma2-9B), and ALMA-R 13B using five prompt templates (zero-shot, one-shot, proverb explanation, dialogue context, concatenation context). Evaluation uses BLEU, CHRF++, COMET metrics plus LLM-as-a-judge (GPT-4o-mini).

## Key Results
- LLMs outperform NMT models in proverb translation, with Llama-3.1 70B achieving the highest scores
- Conversation context significantly improves translation quality, with dialogue format more effective than simple concatenation
- Automatic evaluation metrics (BLEU, CHRF++, COMET) are inadequate for proverb translation as they penalize valid semantic paraphrases
- Translation performance correlates with cultural similarity between language pairs (DE↔EN outperforms BN↔EN)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Conversation context improves proverb translation by providing disambiguating signals.
- **Mechanism:** LLMs use preceding/proceeding dialogue to infer the intended sense of figurative expressions, reducing reliance on literal word-by-word translation.
- **Core assumption:** Proverb meaning shifts based on situational use, and context provides recoverable clues.
- **Evidence anchors:**
  - [abstract] "conversation context significantly improves translation quality"
  - [section 4.2] "incorporating conversational context significantly enhances translation performance... framing the context as a dialogue proves to be more effective than simple concatenation"
- **Break condition:** When context is misaligned (e.g., subtitle reordering), concatenation introduces noise that degrades performance.

### Mechanism 2
- **Claim:** LLMs outperform NMT on proverb translation due to broader cultural knowledge encoded during pretraining.
- **Mechanism:** Large-scale pretraining exposes LLMs to multilingual cultural patterns and proverb equivalents, enabling cross-lingual cultural adaptation beyond what parallel corpora alone provide.
- **Core assumption:** Proverb knowledge generalizes from pretraining corpora to translation tasks without task-specific fine-tuning.
- **Evidence anchors:**
  - [abstract] "LLMs generally outperform NMT models in proverb translation"
  - [section 4.1] "LLAMA-3.1 70B emerging as the strongest model... LLMs achieve higher BLEU and CHRF++ scores when translating figurative proverbs"
- **Break condition:** For language pairs with limited pretraining representation (e.g., Bengali), or when models lack instruction-following capability, LLM advantage diminishes.

### Mechanism 3
- **Claim:** Standard lexical and neural MT metrics fail to capture proverb translation adequacy because they penalize valid paraphrases and cultural equivalents.
- **Mechanism:** BLEU/CHRF++ rely on surface n-gram overlap; COMET, while more semantic, still lacks cultural grounding.
- **Core assumption:** High metric scores correlate with translation quality for general text but not for culturally-situated figurative expressions.
- **Evidence anchors:**
  - [abstract] "current automatic evaluation metrics... are inadequate for reliably assessing the quality of proverb translation"
  - [section 5.1] "metrics are overly sensitive to surface-level lexical differences... fail to recognize the equivalence due to their reliance on word overlap"
- **Break condition:** When reference translations are literal or near-identical to hypotheses, metrics appear reliable; this breaks when references use cultural equivalents or paraphrases.

## Foundational Learning

- **Concept: Non-compositional language (idioms/proverbs)**
  - **Why needed here:** Proverbs cannot be translated word-by-word; meaning is distributed across the whole expression and cultural context.
  - **Quick check question:** Can you explain why "kick the bucket" does not involve either kicking or buckets?

- **Concept: Cultural proximity in language pairs**
  - **Why needed here:** Translation quality varies by cultural similarity (DE↔EN outperforms BN↔EN), affecting model selection and expectation setting.
  - **Quick check question:** Why might German↔English proverb translation be easier than Bengali↔English?

- **Concept: Evaluation metric limitations for figurative language**
  - **Why needed here:** Relying on BLEU/COMET for proverb translation evaluation will mislead system development; human or culturally-aware evaluation is required.
  - **Quick check question:** If a model translates "Spare the rod and spoil the child" as "Discipline brings forth filial children," why might BLEU give it a near-zero score?

## Architecture Onboarding

- **Component map:** Standalone proverbs (MAPS extension) -> Proverb-in-Conversation (PiC) mining from OpenSubtitles -> LLM filtering and quality estimation -> Translation generation with multiple models and prompts -> Evaluation with automatic metrics and LLM-as-judge
- **Critical path:** Context retrieval → Proverb identification → Translation generation → Evaluation (must use human or culturally-grounded evaluation, not BLEU alone)
- **Design tradeoffs:**
  - Dialogue context vs. concatenation: Dialogue format better for LLMs but sensitive to alignment errors; concatenation more robust to reordering but less natural
  - Model size vs. language coverage: Larger models better for figurative reasoning but may still fail on low-resource languages
  - Automatic vs. human evaluation: Automatic metrics faster but unreliable; human evaluation accurate but expensive and non-scalable
- **Failure signatures:**
  - BLEU/COMET high but translation misses cultural meaning
  - Model translates literally (e.g., "The face of a tiger, the heart of a mouse" → "The look of a tiger, the heart of a rat" scored lower despite similar meaning)
  - ALMA-R underperforms NLLB on languages not in its fine-tuning data (Bengali, Indonesian)
  - Mistral lags due to limited multilingual capability
- **First 3 experiments:**
  1. **Baseline establishment:** Run zero-shot translation on standalone proverbs across all language pairs with NLLB-3.3B and Llama-3.1-70B; compare BLEU/COMET scores split by literal vs. figurative proverbs.
  2. **Context ablation:** On PiC subset, compare zero-shot, one-shot, dialogue context, and concatenation prompts using COMET; hypothesize dialogue context > concatenation > one-shot > zero-shot.
  3. **Metric reliability check:** Select 50 samples where semantically similar hypotheses have large metric divergence (using sentence embedding similarity); manually annotate whether lower-scoring hypothesis is actually worse, or if the metric is penalizing valid paraphrases.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can evaluation metrics be designed to reliably assess cultural nuance and semantic equivalence in proverb translation without being overly sensitive to lexical overlaps?
- **Basis in paper:** [explicit] The abstract and conclusion state that current automatic metrics like BLEU, CHRF++, and COMET are "inadequate for reliably assessing the quality of proverb translation," and Section 5.1 demonstrates that these metrics penalize valid semantic paraphrasing.
- **Why unresolved:** Current metrics rely heavily on surface-level n-gram overlap or embeddings that fail to recognize valid metaphorical rephrasing (e.g., "rat" vs. "mouse") or functional equivalence.
- **What evidence would resolve it:** The development and validation of a new metric that correlates strongly with human judgment of "cultural appropriateness" and "translation accuracy" on a diverse set of figurative language pairs.

### Open Question 2
- **Question:** Does the performance gap between LLMs and NMT models in translating culturally specific content persist when scaling up dataset size and language diversity?
- **Basis in paper:** [explicit] The authors note in the "Limitation" section that the dataset scale is "currently relatively small" due to strict filtering and the limited number of proverbs available, which constrains the comprehensiveness of the evaluation.
- **Why unresolved:** It is unclear if the observed superiority of LLMs is an artifact of the specific small-scale, high-quality dataset used, or if it generalizes to larger, noisier datasets or truly low-resource language pairs.
- **What evidence would resolve it:** A follow-up study expanding the data sources (beyond movie subtitles) and evaluating performance on a significantly larger corpus of proverbs across more language families.

### Open Question 3
- **Question:** How does proverb translation capability scale for models with parameters significantly larger than 70B or smaller than 7B?
- **Basis in paper:** [explicit] The "Limitation" section states that the selected models "cannot fully represent the capabilities of other models, especially those with more than 70B or fewer than 7B parameters."
- **Why unresolved:** The study focused on a specific range of instruction-tuned LLMs (mostly 7B-70B), leaving the performance boundaries of massive frontier models or highly compressed edge models unknown.
- **What evidence would resolve it:** Benchmarking the specific proverb translation prompts on frontier models (e.g., GPT-4 Turbo) and sub-7B models (e.g., mobile-optimized LLMs) to map the performance curve.

## Limitations
- Proverb-in-Conversation (PiC) dataset availability: The exact filtered dataset is not yet public, limiting reproducibility of the conversation context experiments.
- Evaluation metric reliability: While the paper identifies BLEU/COMET inadequacy for proverb translation, the LLM-as-judge approach using GPT-4o-mini lacks validation against human judgments for cultural equivalence assessment.
- Language pair imbalance: Performance differences across language pairs may reflect pretraining data distribution rather than inherent model capability, particularly for low-resource languages like Bengali.

## Confidence
- **High confidence**: LLMs generally outperform NMT models on proverb translation
- **Medium confidence**: Conversation context significantly improves translation quality
- **Medium confidence**: Automatic evaluation metrics are inadequate for proverb translation

## Next Checks
1. **Human evaluation validation**: Recruit native speakers for manual assessment of 100 randomly selected proverb translations, comparing semantic equivalence between LLM and NMT outputs, to validate automatic metric findings and LLM-as-judge reliability.
2. **Cross-dataset generalization**: Test top-performing models on an external proverb dataset (e.g., MasalBench for Persian proverbs) to assess whether findings generalize beyond the constructed MAPS and PiC datasets.
3. **Low-resource language stress test**: Evaluate the same models on additional low-resource language pairs (e.g., Swahili-English or Hausa-English) to determine if the LLMs' cultural knowledge advantage persists when pretraining data is sparse.