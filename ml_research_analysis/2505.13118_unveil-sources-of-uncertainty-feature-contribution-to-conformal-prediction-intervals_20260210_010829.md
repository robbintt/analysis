---
ver: rpa2
title: 'Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction
  Intervals'
arxiv_id: '2505.13118'
source_url: https://arxiv.org/abs/2505.13118
tags:
- shapley
- rank
- values
- value
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel model-agnostic uncertainty attribution\
  \ (UA) method that combines cooperative game theory with conformal prediction (CP)\
  \ to interpret predictive uncertainty feature-wise. The method defines cooperative\
  \ games where CP interval properties\u2014such as width and bounds\u2014serve as\
  \ value functions, and uses the broader Harsanyi allocation family (including proportional\
  \ Shapley values) to attribute uncertainty to input features."
---

# Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals

## Quick Facts
- **arXiv ID:** 2505.13118
- **Source URL:** https://arxiv.org/abs/2505.13118
- **Reference count:** 40
- **Primary result:** Novel model-agnostic uncertainty attribution method combining cooperative game theory with conformal prediction for feature-wise uncertainty interpretation.

## Executive Summary
This paper introduces a novel uncertainty attribution (UA) method that leverages cooperative game theory and conformal prediction (CP) to interpret predictive uncertainty feature-wise. The method attributes uncertainty to input features using CP interval properties (width and bounds) as value functions, employing the Harsanyi allocation family for attribution. A Monte Carlo approximation scheme provides computational efficiency gains while maintaining statistical guarantees. Experiments demonstrate that CP-based uncertainty attributions diverge from traditional moment-based importance rankings, offering actionable insights for high-stakes ML applications.

## Method Summary
The proposed method defines cooperative games where CP interval properties serve as value functions, using the broader Harsanyi allocation family (including proportional Shapley values) to attribute uncertainty to input features. To address computational efficiency, a Monte Carlo approximation scheme with statistical guarantees is developed, achieving up to 10-fold speed-up compared to exact computation. The approach is model-agnostic and validated on both synthetic and real-world datasets, showing that CP-based uncertainty attributions provide complementary insights to traditional importance rankings.

## Key Results
- CP-based uncertainty attributions diverge from traditional moment-based importance rankings
- Monte Carlo approximation achieves up to 10-fold computational speed-up
- Method provides actionable insights into how each feature affects predictive uncertainty
- Demonstrates locally diverse definitions of importance suitable for high-stakes ML applications

## Why This Works (Mechanism)
The method works by treating uncertainty attribution as a cooperative game where features are players and CP interval properties are the value functions. By using the Harsanyi allocation family, the approach can distribute uncertainty contributions fairly among features. The Monte Carlo approximation enables efficient computation while maintaining statistical validity, making the method practical for real-world applications where exact computation would be prohibitively expensive.

## Foundational Learning

**Conformal Prediction (CP)** - Distribution-free uncertainty quantification method that provides prediction intervals with statistical guarantees. *Why needed:* Provides the foundation for uncertainty quantification that can be attributed to features. *Quick check:* Verify CP intervals maintain coverage probability across different datasets.

**Cooperative Game Theory** - Mathematical framework for distributing gains or costs among players working together. *Why needed:* Enables fair attribution of uncertainty contributions to individual features. *Quick check:* Confirm allocation methods satisfy desired properties like efficiency and symmetry.

**Shapley Values** - Solution concept in cooperative game theory that fairly distributes gains based on marginal contributions. *Why needed:* Provides a principled way to attribute uncertainty to features. *Quick check:* Validate Shapley value computation matches theoretical expectations on simple games.

**Harsanyi Allocation Family** - Generalization of cooperative game solutions that includes proportional Shapley values. *Why needed:* Offers flexibility in defining fairness criteria for uncertainty attribution. *Quick check:* Compare different allocation methods on benchmark problems.

## Architecture Onboarding

**Component Map:** Features -> Cooperative Game Definition -> CP Interval Properties -> Value Function -> Attribution Algorithm -> Uncertainty Attribution Scores

**Critical Path:** Input features are processed through the CP algorithm to generate intervals, these interval properties define the value function for the cooperative game, the attribution algorithm (using Harsanyi allocation) computes feature contributions, resulting in interpretable uncertainty attributions.

**Design Tradeoffs:** Exact Shapley value computation is computationally expensive but provides precise attributions; Monte Carlo approximation offers efficiency at the cost of some approximation error; different value functions (width vs. bounds) capture different aspects of uncertainty.

**Failure Signatures:** If CP intervals fail to maintain coverage, attributions will be unreliable; if the cooperative game is poorly defined, attributions may not reflect true feature contributions; if Monte Carlo samples are insufficient, approximation error may dominate.

**First Experiments:** 1) Validate CP coverage on synthetic data with known feature importance; 2) Compare attribution results across different value function choices; 3) Benchmark computational efficiency against exact computation methods.

## Open Questions the Paper Calls Out

None

## Limitations

- Computational efficiency improvements rely on Monte Carlo approximation, but trade-off between approximation error and efficiency gains remains under-characterized
- Experimental validation focuses on synthetic and standard benchmark datasets with limited assessment on high-dimensional or noisy real-world data
- Attribution results depend on choice of cooperative game definition, but sensitivity to these design choices is not thoroughly explored
- While claimed to be model-agnostic, practical implications for complex models like deep neural networks are not addressed

## Confidence

**High:** The theoretical foundation linking cooperative game theory to uncertainty attribution is sound and well-established.

**Medium:** The computational efficiency improvements and their practical impact are demonstrated but require broader validation.

**Medium:** The divergence of CP-based attributions from moment-based importance is shown but needs deeper theoretical justification.

## Next Checks

1. Evaluate the method on high-dimensional, noisy datasets to assess robustness and scalability.
2. Compare the attribution results across different cooperative game definitions (e.g., interval width vs. bounds) to quantify sensitivity.
3. Test the method on complex models like deep neural networks to validate its model-agnostic claims in practice.