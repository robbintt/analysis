---
ver: rpa2
title: Deep Learning for On-Street Parking Violation Prediction
arxiv_id: '2505.06818'
source_url: https://arxiv.org/abs/2505.06818
tags:
- parking
- data
- violation
- time
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of predicting fine-grained parking
  violation rates in urban on-street parking systems, where illegal parking undermines
  system reliability and driver trust. The proposed solution employs a deep learning
  model that forecasts violation rates at hourly intervals for individual parking
  sectors.
---

# Deep Learning for On-Street Parking Violation Prediction

## Quick Facts
- arXiv ID: 2505.06818
- Source URL: https://arxiv.org/abs/2505.06818
- Reference count: 14
- Primary result: Residual DNN achieves MAE of 0.146 (smoothed test set) vs 0.251 baseline for parking violation prediction

## Executive Summary
This paper addresses the challenge of predicting fine-grained parking violation rates in urban on-street parking systems. The proposed solution employs a deep learning model that forecasts violation rates at hourly intervals for individual parking sectors, using a novel data augmentation and smoothing technique to handle sparse and noisy ground truth data from police scans. Experiments on real data from Thessaloniki, Greece, demonstrate significant improvements over baseline methods, achieving MAE of 0.146 on smoothed test data.

## Method Summary
The method predicts hourly parking violation rates for 396 on-street parking sectors using a residual deep neural network. The model takes as input 19 PoI distances from sector center, sector capacity, sine-encoded temporal features, 6-hour averaged weather conditions, and binary indicators for holidays and pandemic periods. A key innovation is a Gaussian smoothing technique (σ=210 minutes) that distributes observed violation rates to neighboring time slots, creating continuous pseudo-labels from sparse police scan data. The network architecture consists of 6 hidden layers (512→256→128→64→128→32) with ReLU activations and a residual connection between layers 3 and 5. The model is trained using Adamax optimizer with exponential learning rate decay, and targets are re-normalized to [0.1, 0.9] to prevent sigmoid saturation.

## Key Results
- Residual DNN achieves MAE of 0.169 on raw test set and 0.146 on smoothed test set
- Outperforms baseline (average violation rate) with MAE of 0.251 by 41.4%
- Data augmentation and smoothing technique improves prediction accuracy under sparse, noisy data conditions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Gaussian-based temporal smoothing reduces prediction error when ground truth labels are sparse and discontinuous.
- **Mechanism:** Police scans provide violation rates only at specific moments, creating noisy, gap-filled labels. The smoothing technique distributes observed violation rates to neighboring time slots using exponential decay weighted by temporal distance (σ = 210 minutes), creating continuous pseudo-labels that bridge annotation gaps.
- **Core assumption:** Violation rates change gradually over time rather than spiking discontinuously between scans.
- **Evidence anchors:**
  - [abstract] "we developed a data augmentation and smoothing technique for further improving the accuracy of DL models under the presence of missing and noisy data"
  - [Section 2, Eq. 6] Defines Gaussian smoothing: y = (1/|S|) Σ exp(-ds/σ) · ps
  - [corpus] Weak direct corpus support; related parking papers focus on occupancy prediction rather than violation smoothing.
- **Break condition:** If violation rates exhibit sharp, unpredictable spikes (e.g., enforcement blitzes), smoothing may obscure genuine signal.

### Mechanism 2
- **Claim:** Encoding sector location via distances to Points of Interest (PoIs) enables better generalization than raw coordinates.
- **Mechanism:** Instead of absolute GPS coordinates, each sector is represented as a 19-dimensional vector of distances to predefined PoIs (museums, city hall, parks). This captures functional proximity to high-traffic destinations, allowing the model to learn that sectors near similar PoIs exhibit similar violation patterns.
- **Core assumption:** Parking demand—and thus violation rates—correlates with proximity to popular destinations rather than absolute geographic position.
- **Evidence anchors:**
  - [Section 2] "Given that traffic and demand for parking slots are higher across different PoIs, this way of encoding the information can allow a DL model to associate PoIs with expected parking violation rates"
  - [Section 2] "A total of 19 points of interest were employed, leading to a 19-dimensional representation for each sector"
  - [corpus] Indirect support from "Truck Parking Usage Prediction with Decomposed Graph Neural Networks" which models spatial relationships for parking prediction.
- **Break condition:** If PoIs are poorly chosen (e.g., not actually high-traffic) or city structure changes significantly, the encoding loses predictive power.

### Mechanism 3
- **Claim:** Sine-based encoding of temporal features preserves periodic continuity and improves model learning.
- **Mechanism:** Raw integer encoding (e.g., Monday=0, Sunday=6) creates artificial discontinuity at week boundaries. Sine encoding (e.g., sin(2πw/7)) ensures adjacent time periods (Sunday→Monday) have similar representations, capturing true periodicity of human behavior patterns.
- **Core assumption:** Parking violation patterns are periodic (weekly, monthly) and continuous at cycle boundaries.
- **Evidence anchors:**
  - [Section 2, Eqs. 1-3] Explicit sine encoding formulas for weekday, day, and month features
  - [Section 2] "To capture the periodic nature of these features and prevent discontinuities in the features we opted for using sine-based encoding"
  - [corpus] Standard practice in time-series deep learning; not explicitly validated in neighbor papers for parking domain.
- **Break condition:** If non-periodic events dominate violations (e.g., one-time concerts, construction), periodic encoding underfits these anomalies.

## Foundational Learning

- **Concept: Label Smoothing for Noisy Annotations**
  - **Why needed here:** Ground truth comes from police scans that are infrequent and irregular, creating inherently noisy labels. Without smoothing, the model would overfit to sparse, potentially unrepresentative samples.
  - **Quick check question:** If you only observe violations at 10:00 AM and 2:00 PM, what assumption do you make about 11:00 AM?

- **Concept: Residual Connections in Deep Networks**
  - **Why needed here:** The 6-layer architecture risks gradient degradation during backpropagation. The skip connection between layers 3 and 5 preserves gradient flow and allows the model to learn identity mappings when beneficial.
  - **Quick check question:** What happens to gradient magnitude as it backpropagates through many layers without skip connections?

- **Concept: Feature Normalization (Standardization)**
  - **Why needed here:** Input features span different scales (distances in meters, temperature in °C, binary holiday flags). Without normalization, gradient descent becomes unstable and features with larger magnitudes dominate learning.
  - **Quick check question:** Why would a distance feature (0-5000m) cause training instability compared to a binary holiday flag (0 or 1)?

## Architecture Onboarding

- **Component map:** Input features (19 PoI distances + capacity + temporal + weather + indicators) → 512→256→128→64→128→32 neurons → sigmoid output
- **Critical path:** Raw police scan data → violation rate calculation per sector/time slot → Gaussian smoothing (σ=210 min) → feature extraction and standardization → residual MLP training with Adamax → evaluation on raw/smoothed test sets
- **Design tradeoffs:** Smoothing parameter σ (larger values reduce noise but may blur genuine rate changes); PoI count (19 PoIs chosen manually, more could improve resolution but increase dimensionality); output renormalization (0.1-0.9 prevents sigmoid saturation but clips extreme predictions)
- **Failure signatures:** MAE close to baseline (0.251): model not learning; check feature scaling or data pipeline; validation loss diverging: learning rate too high or smoothing too aggressive; predictions clustered near mean: insufficient model capacity or residual connection broken
- **First 3 experiments:**
  1. **Baseline comparison:** Train without smoothing, evaluate on raw test set; expect MAE ≈ 0.175 (per Table I)
  2. **Smoothing ablation:** Apply smoothing to training data only; compare MAE on raw vs. smoothed test sets
  3. **Temporal encoding test:** Replace sine encoding with raw integers; expect performance degradation at week/month boundaries

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Graph Neural Networks (GNNs) improve prediction accuracy over the current residual Deep Neural Network by explicitly modeling spatial dependencies between parking sectors?
- Basis in paper: [explicit] The authors state in the Conclusion that "graph neural networks can be used to better model spatial relations between sectors."
- Why unresolved: The current architecture relies on distances from Points of Interest (PoIs) to encode geography, which may not fully capture the adjacency or mutual influence between neighboring sectors.
- What evidence would resolve it: Experiments comparing the existing residual model against a GNN implementation using the same Thessaloniki dataset to observe a statistically significant drop in Mean Absolute Error (MAE).

### Open Question 2
- Question: Does the inclusion of real-time city traffic data significantly enhance the prediction of on-street parking violation rates?
- Basis in paper: [explicit] The Conclusion suggests that "traffic on city streets can affect the rate of parking violations, hinting that this could be an additional feature."
- Why unresolved: Traffic density is intuitively linked to parking demand, but it was not included in the current feature set (weather, time, PoIs), so its predictive power remains unquantified in this context.
- What evidence would resolve it: Ablation studies incorporating traffic flow metrics into the input vectors to measure the resulting change in model error.

### Open Question 3
- Question: Does the binary feature designed to capture COVID-19 pandemic effects generalize effectively to subsequent flu seasons or periods of reduced mobility?
- Basis in paper: [explicit] The authors hypothesize in Section 2 that "this feature might be also useful during subsequent flu seasons due to increased public awareness."
- Why unresolved: The feature was trained specifically on data from the COVID-19 period; it is unverified whether "flu season" behavioral patterns correlate strongly enough with the learned "pandemic" weights to act as a reliable predictor.
- What evidence would resolve it: Evaluating the trained model on unseen data from post-pandemic flu seasons to determine if the feature activations correspond to actual changes in violation rates.

### Open Question 4
- Question: To what extent does the manual selection of the 19 Points of Interest (PoIs) bias the model's spatial representation compared to automated or exhaustive encoding?
- Basis in paper: [inferred] The paper states in Section 3 that "we manually defined 19 PoIs used for encoding the distances for each sector."
- Why unresolved: Manual selection introduces human heuristics that may overlook non-obvious spatial drivers of illegal parking, and the sensitivity of the model to the specific number and location of these PoIs is not analyzed.
- What evidence would resolve it: An ablation study varying the number of PoIs or comparing manual selection against automated clustering methods for spatial encoding.

## Limitations

- Gaussian smoothing parameter σ=210 minutes chosen empirically without ablation studies, creating uncertainty about optimal smoothing duration
- Manual selection of 19 PoIs lacks reproducibility - specific coordinates and selection criteria not provided
- Training hyperparameters including batch size and exact cross-validation fold count unspecified

## Confidence

- **High Confidence:** The residual network architecture and basic training procedure are well-specified and follow standard practices. The overall performance improvement over baseline (MAE reduction from 0.251 to 0.146) is substantial and internally consistent.
- **Medium Confidence:** The data augmentation and smoothing technique shows theoretical validity and achieves reported results, but the choice of smoothing parameters and its impact on different violation patterns remains uncertain without ablation studies.
- **Low Confidence:** The PoI-based feature encoding approach relies on manually selected points without systematic validation or sensitivity analysis to PoI choice or count.

## Next Checks

1. **Smoothing sensitivity analysis:** Systematically vary σ from 60 to 420 minutes and measure impact on MAE for both raw and smoothed test sets to determine optimal smoothing duration
2. **PoI encoding ablation:** Replace PoI distances with raw sector coordinates and compare performance; alternatively, test different PoI counts (10, 15, 25) to assess encoding sensitivity
3. **Temporal encoding comparison:** Implement and compare three temporal encodings (sine, raw integers, one-hot) to quantify the impact of periodic encoding on week/month boundary predictions