---
ver: rpa2
title: 'MedKGent: A Large Language Model Agent Framework for Constructing Temporally
  Evolving Medical Knowledge Graph'
arxiv_id: '2508.12393'
source_url: https://arxiv.org/abs/2508.12393
tags:
- knowledge
- triples
- entity
- medical
- biomedical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MedKGent, a LLM agent framework for constructing
  temporally evolving medical knowledge graphs (KGs). MedKGent addresses the challenge
  of integrating evolving biomedical knowledge by incrementally processing over 10
  million PubMed abstracts from 1975-2023 on a daily basis.
---

# MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph

## Quick Facts
- arXiv ID: 2508.12393
- Source URL: https://arxiv.org/abs/2508.12393
- Reference count: 40
- Processes 10M+ PubMed abstracts (1975-2023) to construct medical KG with 156,275 entities and 2,971,384 relational triples

## Executive Summary
MedKGent introduces a novel LLM agent framework for constructing temporally evolving medical knowledge graphs from PubMed abstracts. The system addresses the challenge of integrating rapidly evolving biomedical knowledge by using two specialized agents: an Extractor Agent that identifies biomedical triples with confidence scores, and a Constructor Agent that integrates these triples into a dynamic KG while resolving conflicts. The framework processes over 10 million abstracts from 1975-2023 on a daily basis, enabling continuous knowledge graph updates that reflect the latest biomedical discoveries.

The resulting KG demonstrates high quality with accuracy approaching 90% and enables practical applications in medical question answering and literature-based drug repurposing. By incorporating temporal evolution and confidence-aware causal inference, MedKGent provides a scalable solution for maintaining up-to-date medical knowledge representations that can support downstream clinical and research applications.

## Method Summary
MedKGent employs a dual-agent architecture consisting of an Extractor Agent and a Constructor Agent. The Extractor Agent processes PubMed abstracts to identify biomedical triples (subject-predicate-object relationships) using large language models, incorporating sampling-based estimation to assign confidence scores to each extracted triple. The Constructor Agent then integrates these triples into a dynamic knowledge graph, employing conflict resolution strategies to handle contradictory information and maintain temporal coherence. The system processes abstracts incrementally on a daily basis, enabling the KG to evolve and incorporate new biomedical discoveries as they are published. The framework uses prompt engineering techniques to guide LLM reasoning and employs sampling-based confidence estimation to assess extraction quality without requiring expensive human annotation.

## Key Results
- Successfully processes over 10 million PubMed abstracts from 1975-2023, constructing a KG with 156,275 entities and 2,971,384 relational triples
- Achieves accuracy approaching 90% in knowledge graph quality assessment
- Demonstrates consistent improvements in medical question answering tasks compared to non-augmented baselines
- Enables literature-based drug repurposing through confidence-aware causal inference from the KG

## Why This Works (Mechanism)
The framework's effectiveness stems from its specialized agent architecture that separates extraction and construction tasks, allowing each agent to focus on specific challenges. The Extractor Agent leverages LLM capabilities for understanding complex biomedical text while using sampling-based confidence estimation to quantify extraction reliability. The Constructor Agent handles the complexity of integrating new knowledge while resolving conflicts and maintaining temporal consistency. The incremental daily processing enables the KG to evolve continuously, capturing the dynamic nature of biomedical knowledge without requiring complete rebuilds.

## Foundational Learning

**Biomedical Named Entity Recognition (BioNER)** - Why needed: Identifies medical entities (diseases, drugs, genes) from text. Quick check: Can the system distinguish between drug names and chemical compounds in PubMed abstracts?

**Relation Extraction** - Why needed: Determines relationships between identified entities. Quick check: Does the system correctly identify causal relationships between treatments and outcomes?

**Confidence Estimation** - Why needed: Quantifies reliability of extracted triples without human annotation. Quick check: Are confidence scores correlated with actual extraction accuracy?

**Conflict Resolution** - Why needed: Handles contradictory information from different sources. Quick check: How does the system resolve conflicting information about treatment efficacy?

**Temporal Evolution Tracking** - Why needed: Maintains knowledge changes over time. Quick check: Can the system identify when new evidence contradicts previous medical understanding?

**Causal Inference** - Why needed: Enables drug repurposing by identifying potential causal relationships. Quick check: Does the system correctly identify plausible drug-disease connections based on indirect evidence?

## Architecture Onboarding

**Component Map**: PubMed Abstracts -> Extractor Agent -> Constructor Agent -> Temporally Evolving KG

**Critical Path**: The core processing pipeline involves daily batch processing of PubMed abstracts through the Extractor Agent to identify triples with confidence scores, followed by the Constructor Agent integrating these triples into the KG while resolving conflicts and maintaining temporal consistency.

**Design Tradeoffs**: The system prioritizes accuracy over speed by using sampling-based confidence estimation rather than real-time scoring, and employs conflict resolution heuristics that may introduce bias but ensure consistency. The dual-agent architecture adds complexity but enables specialized handling of extraction versus construction challenges.

**Failure Signatures**: Common failure modes include low-confidence extractions from complex sentence structures, conflict resolution errors when contradictory evidence is presented, and temporal inconsistencies when older knowledge is superseded by newer findings without proper deprecation.

**3 First Experiments**:
1. Run the Extractor Agent on a small set of annotated PubMed abstracts to validate confidence score calibration against ground truth
2. Test the Constructor Agent's conflict resolution on synthetic contradictory triples to evaluate resolution strategies
3. Process a one-year subset of PubMed abstracts to measure KG growth rate and entity stability over time

## Open Questions the Paper Calls Out
None

## Limitations
- Lacks systematic comparison with established biomedical KGs like UMLS or BioKG for comprehensive benchmarking
- Drug repurposing case study relies on single illustrative example without validation across multiple drug-disease pairs
- Sampling-based confidence estimation lacks validation against human-annotated ground truth

## Confidence

**High**: Core architecture and basic functionality demonstrated through successful processing of 10M+ PubMed abstracts and KG construction with 156,275 entities

**Medium**: Downstream applications, particularly drug repurposing, which relies on single example without systematic validation

## Next Checks

1. Conduct systematic comparison of MedKGent's KG quality against established biomedical knowledge bases (UMLS, BioKG) using standardized evaluation metrics like precision, recall, and F1-score on shared entity and relation types.

2. Perform temporal analysis by processing PubMed abstracts from consecutive years (e.g., 2020-2023) to quantify how the KG evolves, measuring entity/relation growth rates and stability of confidence scores over time.

3. Validate the drug repurposing capability through clinical expert review of at least 20 randomly selected drug-disease pairs from the KG, comparing LLM-suggested repurposing hypotheses against established medical literature and clinical guidelines.