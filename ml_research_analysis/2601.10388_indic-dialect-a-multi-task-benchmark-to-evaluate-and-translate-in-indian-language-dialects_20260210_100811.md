---
ver: rpa2
title: 'INDIC DIALECT: A Multi Task Benchmark to Evaluate and Translate in Indian
  Language Dialects'
arxiv_id: '2601.10388'
source_url: https://arxiv.org/abs/2601.10388
tags:
- dialect
- language
- dialects
- translation
- hindi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces INDIC-DIALECT, a new human-curated parallel
  corpus containing 13,000 sentence pairs across 11 Hindi and Odia dialects. The corpus
  enables evaluation of three dialect-aware tasks: dialect classification, multiple-choice
  question answering, and machine translation.'
---

# INDIC DIALECT: A Multi Task Benchmark to Evaluate and Translate in Indian Language Dialects

## Quick Facts
- **arXiv ID:** 2601.10388
- **Source URL:** https://arxiv.org/abs/2601.10388
- **Reference count:** 6
- **Primary result:** Fine-tuned IndicBERT achieves 89.8% F1 on dialect classification vs 19.6% for zero-shot LLMs

## Executive Summary
This paper introduces INDIC-DIALECT, a human-curated parallel corpus containing 13,000 sentence pairs across 11 Hindi and Odia dialects from 3 Indian states. The corpus enables evaluation of three dialect-aware tasks: dialect classification, multiple-choice question answering, and machine translation. Experiments demonstrate that fine-tuned Indic-specific models like IndicBERT substantially outperform zero-shot multilingual LLMs on classification tasks. For machine translation, hybrid AI approaches achieve the best performance: 61.32 BLEU for dialect-to-language translation and 48.44 BLEU for language-to-dialect translation, outperforming baseline methods. The study demonstrates the need for dialect-specific models and targeted translation strategies due to high linguistic proximity between dialects and standard languages.

## Method Summary
The INDIC-DIALECT benchmark comprises 13,000 parallel sentence pairs across 11 dialects from Himachal Pradesh, Uttar Pradesh, and Odisha, plus standard Hindi and Odia. The corpus was created by translating standard language sentences into dialects. Three tasks are evaluated: (1) Dialect classification using fine-tuned IndicBERT V2, (2) MCQ answering with hard distractors generated using nearest-neighbor techniques, and (3) Machine translation using four approaches: dictionary-based rules, AI-only fine-tuning, rule-based followed by AI, and hybrid AI (concatenating dictionary output with source). Models are trained with AdamW optimizer (lr=2e-5, batch size 32) for 100-150 epochs, with hardware requirements of NVIDIA RTX A6000 48GB.

## Key Results
- Fine-tuned IndicBERT achieves 89.75 F1 on dialect classification vs 19.62 F1 for zero-shot LLMs
- Hybrid AI approach achieves 61.32 BLEU for dialect-to-language translation (vs 46.57 for AI-only baseline)
- Rule-based followed by AI approach achieves 48.44 BLEU for language-to-dialect translation (vs 27.59 for AI-only baseline)
- State-specific models improve F1 by 12-17 points for confused dialect families (e.g., UP dialects: 83.5 vs 71.66)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuned Indic-specific transformer models substantially outperform zero-shot multilingual LLMs on dialect classification when trained on modest dialectal data.
- Mechanism: Models pre-trained on Indian languages (e.g., IndicBERT on 24 languages) encode script familiarity, vocabulary overlap, and morphological patterns that zero-shot LLMs lack. Fine-tuning on dialect-specific data then learns decision boundaries for closely related varieties.
- Core assumption: Dialects share sufficient lexical/orthographic structure with their parent languages for transfer to occur.
- Evidence anchors:
  - [abstract] "fine-tuned transformer based models pretrained on Indian languages substantially improve performance e.g., improving F1 from 19.6% to 89.8% on dialect classification"
  - [section 4.1, Table 3] IndicBERT V2 (FT): 89.75 F1 vs GEMINI 2.5 pro (ZS): 19.62 F1; ChatGPT-4o (ZS): 4.25 F1 (below random baseline of 9.09%)
  - [corpus] Related work on IndicMMLU-Pro confirms Indic-specific benchmarks reveal LLM weaknesses not visible in standard evaluations.

### Mechanism 2
- Claim: Hybrid AI approaches (dictionary-based translation concatenated with source sentence as model input) optimize dialect-to-standard-language translation.
- Mechanism: The bilingual dictionary provides explicit lexical mappings, reducing search space for low-frequency dialect words. The AI model then resolves syntactic reordering, contextual disambiguation, and grammatical consistency. Concatenation allows cross-attention between both signals.
- Core assumption: Dialect-to-language mapping is primarily lexical with predictable syntactic alignment.
- Evidence anchors:
  - [abstract] "hybrid AI model achieves highest BLEU score of 61.32 compared to the baseline score of 23.36"
  - [section 4.3.1, Table 6] Hybrid AI: 61.32 BLEU vs AI-only baseline: 46.57 BLEU vs Rule-based: 23.36 BLEU

### Mechanism 3
- Claim: Rule-based preprocessing followed by AI refinement optimizes standard-language-to-dialect translation, outperforming AI-only approaches.
- Mechanism: Language-to-dialect translation requires generating region-specific morphology and phonetic shifts that follow systematic patterns. Rule-based dictionary substitution explicitly enforces these transformations before AI refinement, preventing the model from defaulting to standard language forms due to high lexical proximity.
- Core assumption: Dialectal transformations are systematic and rule-governable rather than purely statistical.
- Evidence anchors:
  - [abstract] "for language to dialect translation the 'rule-based followed by AI' approach achieves best BLEU score of 48.44 compared to the baseline score of 27.59"
  - [section 4.3.2, Table 7] Rule-based followed by AI: 48.44 BLEU vs AI-only baseline: 27.59 BLEU

## Foundational Learning

- **Concept: BLEU (Bilingual Evaluation Understudy) Score**
  - Why needed here: Primary metric for evaluating translation quality across all MT experiments;不理解 BLEU 则无法解读表 6、表 7 的改进幅度。
  - Quick check question: If Model A scores 61.32 BLEU and Model B scores 27.59 BLEU on the same test set, what does this approximately 34-point gap indicate about translation quality?

- **Concept: Lexical Proximity / Edit Distance**
  - Why needed here: Explains why closely related dialects (e.g., Meerut vs Hindi) cause model confusion in classification but may benefit MCQ tasks; central to section 4.4 analysis.
  - Quick check question: Why would a dialect with LOW edit distance from its parent language be harder to classify but easier to translate?

- **Concept: Zero-Shot vs Fine-Tuned Evaluation**
  - Why needed here: The paper's central claim hinges on the dramatic gap between zero-shot LLM performance (F1 ~19%) and fine-tuned IndicBERT (F1 ~90%); understanding this distinction is essential for interpreting all results.
  - Quick check question: What does it mean when GPT-4o scores below random baseline (4.25% vs 9.09%) on 11-class dialect classification?

## Architecture Onboarding

- **Component map:**
```
INDIC-DIALECT Pipeline
├── Data Layer
│   ├── Parallel corpus: 13K sentence pairs × 11 dialects + 2 standard languages
│   ├── MCQ dataset: dialect sentence + 1 correct + 3 hard distractors
│   └── Bilingual dictionaries: derived from training set for rule-based components
├── Model Layer
│   ├── IndicBERT V2 (encoder): classification, MCQ
│   └── IndicBERTSS (encoder-decoder): translation tasks
├── Translation Strategies
│   ├── AI-only: fine-tuned transformer
│   ├── Rule-based: dictionary word replacement
│   ├── Rule→AI: dictionary output as model input
│   └── Hybrid AI: [dictionary_output] + [source_sentence] as concatenated input
└── Evaluation
    ├── Classification: Precision, Recall, F1
    ├── MCQ: Accuracy, F1
    └── MT: BLEU
```

- **Critical path:**
  1. Start with **IndicBERT V2** as backbone for all tasks (proven 89.75 F1 on classification)
  2. For **dialect→language translation**: use Hybrid AI architecture (concatenate dictionary translation with source)
  3. For **language→dialect translation**: use Rule-based→AI pipeline (dictionary output fed to model)
  4. For **classification/MCQ**: train state-specific models when dialects cluster geographically

- **Design tradeoffs:**
  - Combined vs state-specific models: Combined offers simpler deployment; state-specific yields +12-17 F1 points for confused dialect families (e.g., UP dialects: 83.5 vs 71.66)
  - AI-only vs Hybrid: AI-only simpler but sacrifices 15+ BLEU points on dialect→language
  - Rule→AI vs Hybrid: Rule→AI better for generation tasks (language→dialect: 48.44 vs 33.82); Hybrid better for normalization tasks (dialect→language: 61.32 vs 54.21)

- **Failure signatures:**
  - Zero-shot LLM classification near or below random baseline → indicates dialect not represented in pre-training data
  - High classification F1 but low MCQ/MT scores → model learned brittle decision boundaries from lexical proximity, not true dialect understanding
  - Language→dialect BLEU < 30 with AI-only → model defaulting to standard language forms; needs explicit rule-based guidance
  - t-SNE embeddings show heavy overlap between standard language and dialects → confirm lexical proximity is causing confusion

- **First 3 experiments:**
  1. **Reproduce classification baseline**: Fine-tune IndicBERT V2 on combined 11-dialect dataset; verify F1 ≥ 89 on held-out test. Compare with zero-shot GPT-4o/Gemini to confirm 70+ point gap
  2. **Ablate translation strategies**: For one dialect pair (e.g., Kulluvi↔Hindi), compare all four MT approaches (AI-only, Rule-based, Rule→AI, Hybrid); verify Hybrid wins dialect→language and Rule→AI wins language→dialect
  3. **Test state-specific vs combined**: Train separate IndicBERT classifiers for HP, UP, Odisha dialects; verify UP-specific model recovers from 71.66 to 83+ F1 by reducing cross-state confusion

## Open Questions the Paper Calls Out

- **Generalization to other language families**: The study focuses on Indo-Aryan families and findings "may not generalize to the vast linguistic diversity of other language families" like Dravidian or Tibeto-Burman.

- **Organic dialectal speech**: The corpus was created by translating standard sentences and "may not fully capture the organic, dialectal speech, which often includes extensive code-switching."

- **Architectural improvements for high lexical proximity**: Models struggle to separate dialects from standard languages due to "tight overlap," resulting in confusion despite high classification accuracy. Better architectures are needed to disentangle representations in embedding space.

## Limitations
- Dataset covers only 3 Indian states with 11 dialects, limiting claims about broader Indian dialectal diversity
- Dictionary quality and manual vs automatic creation methods are not detailed
- Only automatic metrics (F1, BLEU) are reported; human evaluation is absent

## Confidence
- **Fine-tuning vs zero-shot classification**: High - Direct, well-controlled comparison with clear numerical improvements
- **Hybrid AI for dialect→language translation**: Medium - BLEU gains are substantial but depend on dictionary quality
- **Rule→AI for language→dialect translation**: Medium - Systematic improvements observed, but rule-based preprocessing may introduce artifacts
- **State-specific model advantage**: Medium - F1 improvements shown but limited to 3 states

## Next Checks
1. **External dialect evaluation**: Test the fine-tuned IndicBERT classifier on an independent dialect corpus from a fourth Indian state not in INDIC-DIALECT to verify transfer beyond the original 3-state scope
2. **Ablation of dictionary size**: Systematically vary the size and coverage of the bilingual dictionary used in hybrid/rule→AI models to quantify its contribution to BLEU improvements
3. **Human evaluation of translations**: Conduct bilingual human assessment (fluency, adequacy, dialect authenticity) on a sample of the best-performing translation outputs to validate automatic BLEU scores against subjective quality