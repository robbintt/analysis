---
ver: rpa2
title: 'Delayed Momentum Aggregation: Communication-efficient Byzantine-robust Federated
  Learning with Partial Participation'
arxiv_id: '2509.02970'
source_url: https://arxiv.org/abs/2509.02970
tags:
- momentum
- non-iid
- epoch
- byzantine
- participation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of Byzantine-robust federated
  learning under partial client participation. Existing methods assume full participation,
  but in practice clients are sampled, and Byzantine majority rounds can break existing
  robust aggregators.
---

# Delayed Momentum Aggregation: Communication-efficient Byzantine-robust Federated Learning with Partial Participation

## Quick Facts
- arXiv ID: 2509.02970
- Source URL: https://arxiv.org/abs/2509.02970
- Authors: Kaoru Otsuka; Yuki Takezawa; Makoto Yamada
- Reference count: 40
- This paper addresses Byzantine-robust federated learning under partial client participation, where existing methods fail when Byzantine clients form a majority in sampled rounds.

## Executive Summary
This paper addresses the critical challenge of Byzantine-robust federated learning under partial client participation. Existing robust aggregation methods assume full participation, but in practice clients are sampled, creating scenarios where Byzantine clients can form a majority in sampled rounds and break existing defenses. The authors propose delayed momentum aggregation (DeMoA), which aggregates both fresh momentum from sampled clients and cached momentum from non-sampled clients, ensuring Byzantine clients never form a majority from the server's perspective. The method adds no communication overhead by reusing cached momentum vectors. Theoretical analysis proves DeMoA maintains Byzantine robustness and convergence guarantees under partial participation, with conditions on the number of honest clients and Byzantine ratio. Experiments show that with 20% Byzantine ratio and 10% participation rate, DeMoA achieves the best accuracy compared to existing methods that fail empirically.

## Method Summary
DeMoA is a federated learning algorithm that maintains momentum vectors for all n clients on the server. In each round, the server samples a subset of clients with probability p, broadcasts the current model, and collects fresh momentum from sampled clients. For non-sampled clients, the server updates their cached momentum by applying the momentum decay coefficient. The server then applies a robust aggregator to the full set of n momentum vectors (sampled fresh + non-sampled cached) to produce the global update. The key innovation is that by including cached momentum from non-sampled clients, the aggregator always sees an honest majority even when the sampled subset contains mostly Byzantine clients, as long as the global Byzantine ratio δ < 1/2. The method uses a preprocessing function to correct for implicit momentum bias in delayed updates and employs a variance-controlled momentum decay coefficient of (1-αp) for all clients.

## Key Results
- DeMoA achieves the best accuracy (62.85%) under 20% Byzantine ratio and 10% participation rate on CIFAR-10, while FedAvg and FedCM fail completely.
- Theoretical guarantees prove Byzantine robustness and convergence under partial participation with bounded delay effects.
- The method adds no communication overhead while maintaining memory storage for all client momentum vectors.

## Why This Works (Mechanism)

### Mechanism 1: Byzantine Minority Guarantee via Global Aggregation View
- Claim: Aggregating cached momentum from non-sampled clients alongside fresh updates prevents Byzantine clients from ever forming a majority in any aggregation round.
- Mechanism: The server maintains momentum vectors for all n clients and applies the robust aggregator to the full set rather than just the sampled subset. Since the global Byzantine ratio δ < 1/2, the aggregator always sees an honest majority even when the sampled set St contains mostly Byzantine clients.
- Core assumption: The global Byzantine ratio satisfies δ < 1/2 across all n clients, and honest clients' delayed momentum remains approximately valid.
- Evidence anchors:
  - [abstract]: "This principle ensures Byzantine clients remain a minority from the server's perspective even when they dominate the sampled set."
  - [Section 3.1]: "Delayed momentum aggregation maintains that Agg(·) consistently sees the global Byzantine ratio δ < 1/2, ensuring robustness even with partial participation."
  - [corpus]: Related papers (e.g., "Do We Really Need to Design New Byzantine-robust Aggregation Rules?") focus on aggregator design but do not address partial participation's Byzantine majority round problem directly.
- Break condition: If honest clients' cached momentum becomes severely stale (very large τ(i,t)), the approximation to fresh gradients degrades; theoretical bounds assume bounded delay effects.

### Mechanism 2: Variance-Controlled Momentum Decay
- Claim: Using (1−αp) as the momentum coefficient for all clients (sampled or not) reduces variance compared to applying (1−α) only to sampled clients.
- Mechanism: By decaying momentum uniformly via (1−αp), the design prevents the momentum coefficient itself from becoming random. The conditional expectation recovers standard momentum recursion E[mti|Ft−1] = (1−αp)mt−1i + αp∇fi(xt−1), but variance remains independent of cached momentum norm.
- Core assumption: Bernoulli sampling with probability p; unbiased stochastic gradients.
- Evidence anchors:
  - [Section 3.2]: "Our design satisfies Var[mti|xt−1] = α²tpt(1−pt)∥∇fi(xt−1)∥², while the alternative incurs an additional term α²tpt(1−pt)∥vt−1i∥²."
  - [Section A.2]: Detailed variance comparison showing the alternative design's extra variance from implicit momentum effect.
  - [corpus]: No direct comparison in related work; this is a novel design choice specific to DeMoA.
- Break condition: If sampling becomes highly non-uniform or client availability is correlated with Byzantine behavior, the variance analysis assumptions may not hold.

### Mechanism 3: Implicit Momentum Correction via Preprocessing
- Claim: The preprocessing function P removes implicit momentum bias introduced by delayed updates, preventing convergence degradation.
- Mechanism: For a client with delay τ(i,t), P reweights cached momentum by Πs(1−αsps), exactly matching the server-side decay applied during non-sampled rounds. This ensures delayed momentum vectors are comparable to fresh ones when passed to the aggregator.
- Core assumption: Delay τ(i,t) is bounded; step-size η is small enough that xt−1 ≈ xt−τ(i,t) for gradient approximation.
- Evidence anchors:
  - [Section 3.1]: "P is a (lightweight) preprocessing function that removes implicit momentum effect from delayed momentum."
  - [Section A.1]: "This corresponds exactly to the server-side update for non-sampled clients (Algorithm 1, line 10)."
  - [corpus]: Related work MIFA (Gu et al., 2021) uses caching without Byzantine robustness or momentum correction; OrMo addresses asynchronous momentum but under different assumptions.
- Break condition: If delays grow unboundedly (e.g., clients drop out permanently), cached momentum becomes irrelevant and may harm aggregation.

## Foundational Learning

- Concept: **Robust Aggregators (δ, c)-Robustness**
  - Why needed here: DeMoA's guarantees depend on the aggregator satisfying Definition 2.4—the aggregation error is bounded by cδρ² where ρ captures honest-client dispersion.
  - Quick check question: Can you explain why coordinate-wise median or Krum, when combined with bucketing, satisfies the (δ, c)-robust aggregator definition?

- Concept: **Time-Coupled Byzantine Attacks (e.g., ALIE)**
  - Why needed here: The paper emphasizes that robust aggregation alone is insufficient; local momentum is required to distinguish Byzantine drift from stochastic noise across rounds.
  - Quick check question: Why does a small Byzantine perturbation each round accumulate to cause divergence even with median aggregation?

- Concept: **Implicit Momentum in Asynchronous/Stochastic Sampling**
  - Why needed here: The (1−αp) coefficient design directly addresses implicit momentum effects from Bernoulli sampling; understanding this is essential to grasp why the "obvious" alternative fails.
  - Quick check question: If sampling probability p=0.1 and momentum α=0.9, what is the effective momentum parameter in expectation under DeMoA's design?

## Architecture Onboarding

- Component map:
  - Client-side: Computes local momentum mti ← (1−αpt)mt−1i + α∇fi(xt−1; ξti) when sampled; no computation otherwise.
  - Server-side cache: Stores mti for all n clients; updates non-sampled clients via mti ← (1−αpt)mt−1i.
  - Aggregator: Applies robust Agg(·) to full set {mti}i∈[n] (sampled fresh + non-sampled cached).
  - Model update: xt ← xt−1 − ηmt where mt is aggregator output.

- Critical path:
  1. Server samples St with probability p (Bernoulli per client).
  2. Broadcast xt−1 to sampled clients only (communication-efficient).
  3. Sampled clients return fresh mti; server updates cache for all.
  4. Aggregator combines all n momentum vectors.
  5. Global model updates and repeats.

- Design tradeoffs:
  - Memory vs. communication: Server stores n momentum vectors (O(nd) memory) but communication remains O(|St|d) per round.
  - Freshness vs. robustness: Stale cached momentum may introduce bias but ensures honest majority; paper shows decay correction mitigates this.
  - Breakdown point: Theoretical δ threshold decreases as participation rate p decreases (Section 3.3.2); very low p limits tolerable Byzantine ratio.

- Failure signatures:
  - Immediate collapse: If aggregator's breakdown point is exceeded (e.g., avg with any Byzantine presence), accuracy drops sharply in first Byzantine-majority round.
  - High variance under non-IID: Byz-VR-MARINA-PP shows unstable convergence with non-IID data due to clipping bias (Figure 2).
  - Delayed momentum staleness: If p is extremely low and training is short, some clients may never be sampled, making their cached momentum useless.

- First 3 experiments:
  1. Baseline without Byzantines (δ=0): Run DeMoA vs. FedCM on CIFAR-10 with p=0.1, non-IID data. Expected: DeMoA outperforms due to implicit regularization from delayed aggregation (replicate Figure 2).
  2. Byzantine majority stress test: Set p=0.1, δ=0.2, use CCLIP aggregator with ALIE attack. Verify FedAvg/FedCM collapse in first epoch while DeMoA remains stable (replicate Figure 1b).
  3. Aggregator ablation: Test DeMoA with different aggregators (CCLIP, CM, Krum, RFA) under IPM attack. Identify which aggregators' breakdown points are exceeded at p=0.1, δ=0.2 (consult Appendix C extended results).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the delayed momentum aggregation principle be extended to non-Bernoulli client selection schemes (e.g., clustered sampling, power-of-choice) while maintaining Byzantine robustness guarantees?
- Basis in paper: [explicit] "The delayed momentum aggregation principle opens promising avenues for extension to other client selection schemes... beyond Bernoulli sampling." (Conclusion, page 8)
- Why unresolved: The current analysis and algorithm assume independent Bernoulli sampling per client; other schemes introduce correlated sampling that may affect how Byzantine clients appear in aggregations.
- What evidence would resolve it: Theoretical analysis extending Theorem 3.1 to alternative sampling distributions, plus empirical validation using schemes like clustered sampling or power-of-choice selection.

### Open Question 2
- Question: What are the optimal pairings between DeMoA and specific robust aggregators under varying partial participation rates and Byzantine ratios?
- Basis in paper: [inferred] Experiments show "for certain aggregators, DeMoA performs poorly" when "the combination of partial participation rate and Byzantine ratio exceeds the breakdown point of the corresponding aggregator." (Section 5.1, page 8)
- Why unresolved: The paper tests five aggregators but does not characterize the interaction between aggregator choice, participation rate p, and Byzantine ratio δ systematically.
- What evidence would resolve it: A comparative study mapping breakdown point boundaries for each aggregator-DeMoA combination across (p, δ) parameter space.

### Open Question 3
- Question: How tight are the theoretical conditions on the Byzantine ratio δ (breakdown point δ < 1/(60c(B² + α(1-p)))) under partial participation?
- Basis in paper: [inferred] The experiments achieve robustness with δ=0.2 and p=0.1, but the theoretical breakdown condition becomes restrictive as p→0, suggesting a potential gap between theory and practice. (Section 3.3.2 discussion, page 5)
- Why unresolved: The bounds include unspecified constants from the Lyapunov analysis that may be loose; empirical results suggest robustness may hold under weaker conditions.
- What evidence would resolve it: Tighter lower bound constructions showing when DeMoA provably fails, or refined analysis reducing constants in the breakdown point expression.

## Limitations

- The theoretical guarantees assume cached momentum remains approximately valid for gradient estimation; the paper does not rigorously bound the error introduced by stale momentum vectors under realistic delay distributions.
- While the paper claims communication efficiency, the memory overhead of storing momentum vectors for all n clients (O(nd)) is not addressed as a practical limitation.
- The variance analysis relies on specific assumptions about unbiased stochastic gradients and independent sampling; real-world federated learning may violate these assumptions.

## Confidence

- High confidence: The core mechanism of delayed momentum aggregation maintaining Byzantine minority via global aggregation view (Mechanism 1) is well-supported by both theory and experiments.
- Medium confidence: The variance analysis and preprocessing correction (Mechanisms 2 and 3) are theoretically sound but depend on idealized assumptions about sampling and gradient behavior.
- Medium confidence: The empirical results showing DeMoA's superiority over baselines at p=0.1, δ=0.2 are convincing but limited to specific datasets and attack configurations.

## Next Checks

1. Test DeMoA with extremely low participation rates (p=0.05 or lower) to empirically verify when the theoretical Byzantine ratio threshold breaks down.
2. Implement and evaluate DeMoA with real-world client availability patterns (e.g., correlated dropout, non-Bernoulli sampling) to assess robustness beyond the theoretical assumptions.
3. Measure and report the memory overhead of maintaining n momentum vectors across different model sizes and client counts to evaluate practical scalability.