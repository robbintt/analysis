---
ver: rpa2
title: 'SIEDD: Shared-Implicit Encoder with Discrete Decoders'
arxiv_id: '2506.23382'
source_url: https://arxiv.org/abs/2506.23382
tags:
- video
- encoding
- siedd
- encoder
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SIEDD, a method for accelerating the encoding
  of Implicit Neural Representations (INRs) for video compression. INRs offer high
  fidelity but are impractical due to slow encoding times.
---

# SIEDD: Shared-Implicit Encoder with Discrete Decoders

## Quick Facts
- arXiv ID: 2506.23382
- Source URL: https://arxiv.org/abs/2506.23382
- Authors: Vikram Rangarajan; Shishira Maiya; Max Ehrlich; Abhinav Shrivastava
- Reference count: 38
- Primary result: Achieves 20-30X encoding speed-up on HD and 4K benchmarks while maintaining competitive reconstruction quality

## Executive Summary
SIEDD introduces a method to accelerate encoding of Implicit Neural Representations (INRs) for video compression. The approach addresses the impracticality of traditional INRs due to slow encoding times by using a shared encoder trained on sparse anchor frames to capture low-frequency video features, then freezing this encoder and training lightweight, discrete decoders for frame groups in parallel. This design achieves significant speed improvements while maintaining coordinate-based control for continuous resolution decoding without requiring transcoding.

## Method Summary
SIEDD employs a two-phase training approach for INR-based video compression. First, a shared encoder is trained on sparse anchor frames to learn low-frequency video features. This encoder is then frozen and used across all frame groups. Second, lightweight, discrete decoders are trained in parallel for each frame group, allowing for massive encoding parallelization. The method preserves coordinate-based control, enabling continuous resolution decoding without transcoding, while achieving 20-30X speed-up on HD and 4K benchmarks.

## Key Results
- Achieves 20-30X encoding speed-up on HD and 4K benchmarks
- Maintains competitive reconstruction quality compared to traditional INRs
- Eliminates need for transcoding by preserving coordinate-based control

## Why This Works (Mechanism)
The method works by separating the encoding process into feature extraction and frame-specific decoding. The shared encoder captures universal low-frequency features from anchor frames, while discrete decoders handle high-frequency, frame-specific details in parallel. This architecture allows for massive parallelization during encoding while maintaining the continuous resolution capabilities of INRs through the frozen shared encoder.

## Foundational Learning
- Implicit Neural Representations (INRs): Continuous function-based representation of images/videos that can be decoded at arbitrary resolution
  - Why needed: Traditional discrete representations limit resolution and compression efficiency
  - Quick check: Verify INR can reconstruct test image at multiple scales
- Anchor frames: Sparse key frames selected from video sequence for feature extraction
  - Why needed: Provide efficient way to capture global video features without processing every frame
  - Quick check: Confirm anchor frames capture representative video content
- Coordinate-based decoding: Ability to decode INR at any spatial/temporal resolution
  - Why needed: Enables continuous resolution without resolution-specific encoding
  - Quick check: Decode same INR at 480p, 1080p, and 4K to verify quality consistency

## Architecture Onboarding

**Component Map:**
Shared Encoder -> Frozen Weights -> Discrete Decoders (parallel) -> Frame Groups

**Critical Path:**
Anchor frames → Shared encoder training → Freeze encoder → Parallel decoder training → Encoding phase

**Design Tradeoffs:**
- Speed vs. Quality: Sacrifices some encoding quality for 20-30X speed improvement
- Memory vs. Parallelism: Multiple decoders increase memory usage but enable parallel encoding
- Flexibility vs. Specialization: Frozen shared encoder provides generalization but may limit adaptation to specific video types

**Failure Signatures:**
- Poor anchor frame selection leads to inadequate feature capture
- Insufficient decoder capacity results in reconstruction artifacts
- Mismatched training data distribution causes performance degradation on new video types

**3 First Experiments:**
1. Benchmark encoding speed on synthetic HD video with varying frame counts
2. Compare reconstruction quality metrics (PSNR, SSIM) against traditional INRs
3. Test coordinate-based decoding at multiple resolutions (480p, 1080p, 4K)

## Open Questions the Paper Calls Out
None

## Limitations
- Performance on real-world video content remains untested beyond synthetic benchmarks
- No analysis of anchor frame selection optimization or robustness to missing/corrupted anchors
- Limited evaluation of continuous resolution capabilities across diverse video types

## Confidence
- 20-30X encoding speed-up on benchmarks: High (supported by experimental results)
- Maintained competitive reconstruction quality: Medium (quality metrics provided but limited to synthetic datasets)
- No transcoding requirement for coordinate-based decoding: High (architectural claim directly supported)

## Next Checks
1. Test SIEDD's performance on diverse real-world video datasets (e.g., diverse resolutions, motion types, compression ratios) beyond the synthetic benchmarks presented
2. Evaluate the robustness of the method when anchor frames are missing, corrupted, or selected suboptimally
3. Measure any degradation in continuous resolution capabilities and coordinate-based control compared to traditional INRs across different video content types