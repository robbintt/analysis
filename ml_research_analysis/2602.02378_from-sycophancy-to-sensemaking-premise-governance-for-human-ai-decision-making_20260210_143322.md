---
ver: rpa2
title: 'From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making'
arxiv_id: '2602.02378'
source_url: https://arxiv.org/abs/2602.02378
tags:
- decision
- premises
- premise
- evidence
- substrate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem of sycophantic LLM behavior in
  human-AI decision-making under deep uncertainty, where fluent agreement without
  calibrated judgment leads to poor commitments. The core method introduces "premise
  governance": a framework where AI assistants maintain explicit, auditable decision
  bases with load-bearing premises, typed discrepancies (teleological, epistemic,
  procedural), and commitment gating to block action on uncommitted assumptions.'
---

# From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making

## Quick Facts
- arXiv ID: 2602.02378
- Source URL: https://arxiv.org/abs/2602.02378
- Reference count: 5
- Primary result: Framework that shifts AI collaboration from answer generation to structured negotiation over decision-critical premises, reducing sycophantic behavior through commitment gating and typed discrepancy routing

## Executive Summary
The paper addresses sycophantic LLM behavior in human-AI decision-making under deep uncertainty, where fluent agreement without calibrated judgment leads to poor commitments. The core method introduces "premise governance": a framework where AI assistants maintain explicit, auditable decision bases with load-bearing premises, typed discrepancies (teleological, epistemic, procedural), and commitment gating to block action on uncommitted assumptions. This shifts collaboration from answer generation to structured negotiation over decision-critical premises. The framework operationalizes trust as "appropriate reliance" by making it computable when to accept, defer, verify, or challenge.

## Method Summary
The method implements a governed substrate maintaining decision bases with explicit premise lifecycle (DRAFT → CONTESTED → COMMITTED → REJECTED), typed discrepancies (teleological/epistemic/procedural), and commitment gating that blocks action on uncommitted load-bearing premises. The framework uses a discrepancy-driven control loop where the LLM proposes operations over compiled decision slices, routing repairs based on violated object types. Value-gated challenge employs VOI logic to prioritize probes that resolve decision-sensitive uncertainty while managing interaction costs.

## Key Results
- Introduces commitment gating to block consequential action when load-bearing premises are uncommitted
- Proposes typed discrepancy routing (teleological, epistemic, procedural) to enable systematic repair operator selection
- Implements value-gated challenge using VOI principles to allocate probing under interaction cost constraints

## Why This Works (Mechanism)

### Mechanism 1: Commitment Gating
Blocking consequential action when load-bearing premises are uncommitted prevents premature commitment under underspecification. The gating rule allows commit(a) only if all load-bearing premises on a's dependency path are COMMITTED, or the expert explicitly overrides under logged risk.

### Mechanism 2: Typed Discrepancy Routing
Classifying discrepancies by alignment category (teleological, epistemic, procedural) enables systematic repair operator selection. Routing derives from the violated object's type in the substrate—goals/constraints → TELEOLOGICAL (REFRAME), causal hypotheses → EPISTEMIC (INVESTIGATE), thresholds/protocols → PROCEDURAL (NEGOTIATE).

### Mechanism 3: Value-Gated Challenge
Treating probing and challenge as decisions under interaction cost enables "strategic disagreement" that surfaces decision-critical uncertainty. VOI logic prioritizes probes that resolve load-bearing, decision-sensitive uncertainty, with epistemic repair taking priority when multiple CONTESTED premises are on the critical path.

## Foundational Learning

- **Load-bearing premises**: Identify which premises, if false, would change the recommended action. Quick check: Given a pending decision, can you trace which assumptions, if overturned, would change the recommendation?

- **Value of Information (VOI)**: Epistemic control uses VOI to decide when probing is worth the interaction cost. Quick check: If a probe costs 2 minutes and has a 30% chance of changing a decision worth $1000 in expected value, is it worth running?

- **Outcome bias in decision evaluation**: In deep-uncertainty domains, outcomes unreliably certify decision quality. Evaluating decisions ex ante (by decision-basis rigor) is the alternative. Quick check: A decision with a sound basis yields a bad outcome due to bad luck. Did the decision-maker err?

## Architecture Onboarding

- **Component map**: Governed substrate -> LLM controller -> Slice compiler -> Routing layer -> Expert negotiation -> Commitment gating check
- **Critical path**: Discrepancy detection → object localization → type inference → routing to repair operator → slice compilation → expert negotiation → commitment gating check → finalize or defer
- **Design tradeoffs**: Granularity of premise representation vs. maintenance overhead; override friction vs. decision speed; provenance depth vs. storage complexity
- **Failure signatures**: Silent premise hardening, routing confusion, override fatigue
- **First 3 experiments**:
  1. Implement minimal substrate with DRAFT/COMMITTED status and dependency links; test commitment gating in controlled task
  2. Build discrepancy classifier routing TELEOLOGICAL/EPISTEMIC/PROCEDURAL; measure routing accuracy
  3. Pilot value-gated probing with simulated interaction budget; compare decision quality and interaction cost

## Open Questions the Paper Calls Out

- How to learn escalation policies from expert feedback
- What minimal substrate primitives suffice in practice
- How to represent irreconcilable stakeholder conflicts

## Limitations
- Substrate schema and VOI policy details remain underspecified
- Evaluation criteria are framed as predictions but lack empirical validation
- Implementation ambiguity in premise dependency representation and slice extraction algorithms

## Confidence
- **High confidence**: Problem framing and general architecture are well-articulated and theoretically sound
- **Medium confidence**: Commitment gating mechanism and typed discrepancy routing concepts are clearly specified
- **Low confidence**: Value-gated challenge implementation and empirical validation of falsifiable criteria remain speculative

## Next Checks
1. Implement minimal substrate with premise lifecycle tracking and dependency links; validate commitment gating prevents actions with uncommitted load-bearing premises
2. Build and evaluate typed discrepancy classifier against expert-labeled data to verify routing accuracy
3. Design and execute pilot study comparing decision quality and interaction costs between value-gated probing and baseline approaches on realistic decision tasks