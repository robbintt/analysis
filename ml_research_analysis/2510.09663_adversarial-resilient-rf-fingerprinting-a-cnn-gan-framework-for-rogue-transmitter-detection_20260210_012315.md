---
ver: rpa2
title: 'Adversarial-Resilient RF Fingerprinting: A CNN-GAN Framework for Rogue Transmitter
  Detection'
arxiv_id: '2510.09663'
source_url: https://arxiv.org/abs/2510.09663
tags:
- devices
- genuine
- rogue
- samples
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a CNN-GAN framework for rogue device detection
  using RF fingerprinting. The approach addresses the problem of distinguishing genuine
  devices from both real rogue devices and synthetically generated ones that mimic
  genuine RF characteristics.
---

# Adversarial-Resilient RF Fingerprinting: A CNN-GAN Framework for Rogue Transmitter Detection

## Quick Facts
- **arXiv ID:** 2510.09663
- **Source URL:** https://arxiv.org/abs/2510.09663
- **Reference count:** 14
- **Primary result:** CNN achieves 96.7% rogue detection and 97.6% genuine classification accuracy using softmax probability thresholding, with GAN-generated synthetic samples validated by Fréchet Distance score of 0.0545

## Executive Summary
This paper presents a CNN-GAN framework for detecting rogue RF transmitters through RF fingerprinting. The approach uses a CNN trained only on genuine device data to classify devices and detect rogues via softmax probability thresholding, combined with a GAN that generates synthetic rogue samples for adversarial testing. The system achieves high detection accuracy (96.7% rogue, 97.6% genuine) on data from ten ADALM-PLUTO SDRs, with the GAN samples closely matching real I/Q constellations. The method addresses the challenge of distinguishing genuine devices from both real and synthetically generated rogue devices while maintaining computational efficiency for real-time implementation.

## Method Summary
The framework processes I/Q samples from OFDM signals, concatenating 10 frames (720 samples total) from signal headers to capture extended temporal hardware imperfection patterns. A CNN classifier trained on genuine devices uses softmax probability thresholding (temperature-scaled at T=2.5) to detect rogues based on low confidence scores. A GAN generator creates synthetic rogue samples using feature matching loss to approximate genuine device distributions. The detection threshold is calibrated on validation data to maximize F1-score for rogue detection. The system processes data in real-time with a detection latency of approximately 1.2ms.

## Key Results
- CNN detection accuracy: 96.7% for rogue devices, 97.6% for genuine devices
- All genuine devices correctly classified (100% accuracy)
- GAN-generated samples achieve Fréchet Distance score of 0.0545, indicating close match to real I/Q constellations
- Detection latency of approximately 1.2ms, suitable for real-time implementation
- System achieves F1-score of 0.9871 for rogue detection

## Why This Works (Mechanism)

### Mechanism 1: Softmax Probability Thresholding for Open-Set Detection
Open-set rogue detection requires rejecting unknown classes while classifying known ones. The CNN trained only on genuine devices (7 classes) produces systematically lower maximum softmax probabilities for out-of-distribution inputs (rogue devices or synthetic mimics). Temperature scaling (T=2.5) amplifies this uncertainty signal, enabling a threshold (θ*=0.1987) to separate genuine from rogue with 96.7-97.6% accuracy. This works because out-of-distribution devices produce flatter probability distributions than in-distribution genuine devices.

### Mechanism 2: Extended Temporal Frame Concatenation
Each I/Q sample contains 72 samples from signal headers. By concatenating 10 consecutive frames (720 samples total), the input captures longer-range temporal correlations in hardware-induced distortions (phase noise, frequency drift, amplifier nonlinearities). This provides richer fingerprint features for the CNN to learn, as hardware imperfections manifest as consistent patterns across extended temporal windows. The 720-sample sequences provide sufficient statistics without introducing device-unrelated variability.

### Mechanism 3: GAN-Generated Synthetic Samples for Adversarial Testing
The GAN generator learns to map random noise to I/Q samples that match the training distribution of genuine devices. Feature matching loss (comparing discriminator intermediate activations) rather than just adversarial loss encourages distributional similarity. The low Fréchet Distance score (0.0545) indicates generated samples closely match real sample statistics, approximating the adversarial threat model where attackers attempt signal-level mimicry. This stress-tests the detection framework against synthetic threats.

## Foundational Learning

- **Concept: Open-Set Recognition via Confidence Thresholding**
  - Why needed: Standard classification assumes all test inputs belong to known classes. Rogue detection requires rejecting unknown classes while still classifying known ones.
  - Quick check: If you train a 7-class classifier and present input from an 8th class, what will the softmax output look like, and how would you detect it?

- **Concept: I/Q Signal Representation**
  - Why needed: In-phase and Quadrature components capture the complex baseband signal. Hardware imperfections modulate both amplitude and phase, which manifest as subtle I/Q deviations.
  - Quick check: Why are I/Q samples treated as a 2-channel input rather than a single complex-valued input for the CNN?

- **Concept: Temperature Scaling in Softmax**
  - Why needed: Controls the "sharpness" of probability distributions. Higher temperature (T=2.5 used here) softens confidence, potentially improving calibration for out-of-distribution detection.
  - Quick check: What happens to softmax probabilities as T→∞ and T→0? How does this affect threshold-based anomaly detection?

## Architecture Onboarding

- **Component map:** Raw I/Q frames (72 samples) → Frame concatenation (720 samples) → Standardization (train-set statistics) → CNN (Conv2D-32 → Dense-352 → Dense-7) → Temperature-scaled softmax → Max probability extraction → Threshold comparison → If genuine: classify to device class; If rogue: reject. Parallel path: GAN Generator (noise → Dense layers → reshape 720×2) used only for test-set augmentation.

- **Critical path:** The threshold calibration on validation data is the single point of failure. The validation set includes device 10 (unseen during training) as the rogue exemplar, so threshold generalization depends entirely on this one device being representative of future rogues.

- **Design tradeoffs:** Threshold selection: Higher threshold → more rogue detections but more false rejections of genuine devices. Paper optimizes for F1-score of rogue class. Temperature T=2.5: Chosen via grid search on validation F1-score. Higher T helps OOD detection but may reduce classification accuracy on genuine devices. Frame concatenation: Longer sequences capture more hardware information but reduce effective training samples (19920 → 1992 per device).

- **Failure signatures:** Rogue devices consistently scoring above threshold: Threshold too low or validation rogue not representative. Genuine devices rejected: Threshold too high or significant domain shift between training and deployment. GAN samples detected more easily than real rogues: Generator not capturing discriminative features, or FD metric insufficient.

- **First 3 experiments:** 1) Threshold sensitivity analysis: Vary threshold from 0.1 to 0.5 in 0.01 increments. Plot genuine acceptance rate vs. rogue rejection rate (ROC curve). 2) Leave-one-device-out validation: Rotate which of the 7 genuine devices is held out during training and used as "rogue" for threshold setting. 3) Temperature ablation: Test T ∈ {0.5, 1.0, 1.5, 2.0, 2.5, 3.0} on a held-out test set with different rogue/real ratios.

## Open Questions the Paper Calls Out
- The study is limited to ten devices, whereas real-world IoT or UAV networks may involve hundreds of devices. The current experimental design uses a small, closed set of 7 genuine classes; it is unclear if the softmax thresholding technique remains effective or computationally efficient with significantly higher class cardinality.
- All data were collected from stationary devices, acknowledging that real-time systems often involve mobile nodes. The current validation relies on static channel conditions; movement introduces Doppler shifts and time-varying fading which may alter the RF fingerprint distributions and invalidate the fixed threshold.
- The threshold (0.1987) is derived from an indoor lab environment, implying high SNR and stable channel conditions not representative of outdoor operations. The paper does not analyze how degrading channel conditions lower the confidence (softmax probability) of genuine devices, which could lead to higher false rejection rates if the threshold is not adaptive.

## Limitations
- Evaluation relies on a single validation device (device 10) to set the detection threshold, creating potential overfitting to one device's characteristics.
- Threat model assumes GAN-generated samples represent realistic adversarial capabilities, but Fréchet Distance metric may not capture higher-order distributional features that matter for CNN discrimination.
- Method's performance against adaptive adversaries who optimize signals to maximize softmax confidence remains unproven.
- Fixed softmax probability threshold robustness across varying SNR and outdoor environments is unverified.

## Confidence
- **High Confidence:** CNN architecture specifications, data preprocessing pipeline, basic threshold-based detection mechanism
- **Medium Confidence:** Threshold optimization procedure (validation on single device), GAN training approach, reported performance metrics
- **Low Confidence:** Generalization to unseen rogue devices, robustness against sophisticated adversarial attacks, comparative advantage over existing RF fingerprinting methods

## Next Checks
1. **Cross-device threshold validation:** Hold out each of the 7 genuine devices in rotation, train CNN, and use held-out device as "rogue" to calibrate threshold. Compare resulting detection performance to current single-device validation approach.
2. **Adaptive adversary testing:** Implement a simple white-box attack where an adversary optimizes synthetic I/Q samples to maximize CNN confidence scores for genuine classes. Measure degradation in detection accuracy and compare to current black-box GAN performance.
3. **Higher-order distribution analysis:** Compute additional distributional similarity metrics (Maximum Mean Discrepancy, Wasserstein distance) between real and GAN-generated samples. Train the CNN to distinguish real from synthetic samples and report classification accuracy to assess whether FD=0.0545 captures all relevant differences.