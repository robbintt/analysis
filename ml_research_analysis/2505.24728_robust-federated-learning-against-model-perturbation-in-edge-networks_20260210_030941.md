---
ver: rpa2
title: Robust Federated Learning against Model Perturbation in Edge Networks
arxiv_id: '2505.24728'
source_url: https://arxiv.org/abs/2505.24728
tags:
- perturbations
- smrfl
- local
- perturbation
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses robustness of federated learning (FL) under
  non-malicious perturbations (communication noise, quantization, differential privacy)
  in edge networks. Existing methods struggle because perturbations persist throughout
  training and degrade performance.
---

# Robust Federated Learning against Model Perturbation in Edge Networks

## Quick Facts
- arXiv ID: 2505.24728
- Source URL: https://arxiv.org/abs/2505.24728
- Reference count: 18
- This paper proposes SMRFL, a federated learning method that achieves robustness against communication noise, quantization, and differential privacy perturbations through flatness-aware optimization

## Executive Summary
This paper addresses the critical challenge of model perturbation in federated learning, particularly in edge network environments where non-malicious perturbations from communication noise, quantization, and differential privacy are common. The authors propose SMRFL (Sharpness-Aware Minimization for Robust Federated Learning), which enhances FL robustness by encouraging convergence to flat minima in the loss landscape. Unlike traditional approaches that struggle with persistent perturbations, SMRFL's min-max optimization framework explicitly minimizes worst-case loss within a neighborhood of model parameters, making it inherently resilient to perturbations throughout the training process.

## Method Summary
SMRFL introduces a sharpness-aware federated learning framework that modifies the standard FL objective by incorporating a min-max optimization problem. The method seeks parameters that minimize the worst-case loss within a neighborhood, effectively finding flat minima that are less sensitive to perturbations. During each training round, SMRFL computes both the standard gradient and a sharpness-aware gradient that accounts for local loss landscape curvature. This dual optimization approach is integrated with federated averaging, allowing clients to perform local updates while maintaining robustness guarantees. The method is designed to be compatible with various FL algorithms like FedAvg and can be applied across different network architectures.

## Key Results
- SMRFL achieves O(1/√R) convergence rate, matching unperturbed FL performance theoretically
- Experimental results on MNIST and CIFAR-10 show SMRFL significantly outperforms FedAvg, Scaffold, and Feddyn under downlink, uplink, and combined perturbation scenarios
- SMRFL demonstrates robustness even with non-IID data distributions, maintaining higher test accuracy and faster convergence compared to baseline methods

## Why This Works (Mechanism)
SMRFL works by explicitly optimizing for flat minima in the loss landscape, which are inherently more robust to perturbations. The min-max formulation ensures that the found solution performs well not just at a single point but across a neighborhood of parameters. This approach is particularly effective because perturbations in FL effectively move the model parameters away from their ideal values, and flat minima are less affected by such small displacements. By minimizing the worst-case loss within a local neighborhood, SMRFL creates models that maintain performance even when subject to the persistent perturbations common in edge networks.

## Foundational Learning

**Sharpness-Aware Minimization**: Optimization technique that finds parameters with uniformly low loss in their neighborhood rather than just low loss at a point. Why needed: Perturbations move parameters slightly, so we need parameters whose performance doesn't degrade with small displacements. Quick check: Verify the method finds parameters with similar loss across multiple nearby points.

**Min-max Optimization**: Framework that minimizes the maximum loss over a parameter neighborhood. Why needed: Provides theoretical guarantees for worst-case performance under perturbations. Quick check: Ensure the inner maximization problem is properly constrained and solvable.

**Convergence Analysis**: Mathematical proof of convergence rates under perturbation conditions. Why needed: Establishes that robustness improvements don't come at the cost of convergence speed. Quick check: Verify the O(1/√R) rate holds under realistic perturbation levels.

## Architecture Onboarding

**Component Map**: Clients -> Local SMRFL updates -> Server aggregation -> Model broadcast

**Critical Path**: Local sharpness-aware optimization → Gradient computation → Server model update → Client synchronization

**Design Tradeoffs**: 
- Computational overhead of min-max optimization vs. robustness gains
- Communication efficiency vs. precision in gradient sharing
- Local update frequency vs. global convergence stability

**Failure Signatures**: 
- Degraded performance with very high perturbation levels
- Increased communication overhead due to additional gradient computations
- Potential instability in highly heterogeneous data scenarios

**First Experiments**:
1. Baseline comparison: Run FedAvg vs. SMRFL under controlled noise levels
2. Perturbation sensitivity: Test performance across different perturbation magnitudes
3. Data heterogeneity: Evaluate robustness with varying degrees of non-IID data

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, focusing instead on presenting the SMRFL method and its theoretical and empirical validation.

## Limitations

- Convergence analysis assumes smooth loss landscapes and bounded gradient norms, which may not hold in all practical scenarios
- Experiments are limited to image classification tasks with CNN and ResNet18 architectures, leaving uncertainty about performance on other data types and models
- The method addresses non-malicious perturbations but does not explicitly handle adversarial attacks, which are critical in many federated learning deployments

## Confidence

- High confidence in theoretical convergence guarantees under stated assumptions
- Medium confidence in empirical results due to limited dataset and architecture diversity
- Medium confidence in practical applicability across different edge network conditions

## Next Checks

1. Test SMRFL on diverse datasets (e.g., text, tabular) and model architectures (e.g., Transformers, LSTMs) to assess generalizability
2. Evaluate performance under realistic network conditions with variable bandwidth and packet loss
3. Investigate robustness against adversarial attacks while maintaining flat minimum optimization benefits