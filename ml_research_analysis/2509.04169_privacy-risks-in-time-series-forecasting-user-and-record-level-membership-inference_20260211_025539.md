---
ver: rpa2
title: 'Privacy Risks in Time Series Forecasting: User- and Record-Level Membership
  Inference'
arxiv_id: '2509.04169'
source_url: https://arxiv.org/abs/2509.04169
tags:
- attacks
- membership
- data
- attack
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces two novel membership inference attacks for\
  \ time series forecasting models: a multi-signal variant of LiRA that leverages\
  \ multiple statistical signals from model outputs, and DTS, a deep learning\u2013\
  based classifier that learns membership directly from prediction-target pairs. Evaluated\
  \ on EEG and electricity consumption datasets using LSTM and N-HiTS architectures,\
  \ the attacks show that user-level MIAs can achieve perfect detection under strict\
  \ threat models, with online attacks outperforming offline ones."
---

# Privacy Risks in Time Series Forecasting: User- and Record-Level Membership Inference

## Quick Facts
- **arXiv ID:** 2509.04169
- **Source URL:** https://arxiv.org/abs/2509.04169
- **Reference count:** 40
- **Primary result:** Novel multi-signal and deep learning attacks show user-level MIAs can achieve perfect detection under strict threat models, with vulnerability increasing for longer horizons and smaller populations.

## Executive Summary
This paper introduces two novel membership inference attacks for time series forecasting models: a multi-signal variant of LiRA that leverages multiple statistical signals from model outputs, and DTS, a deep learningâ€“based classifier that learns membership directly from prediction-target pairs. Evaluated on EEG and electricity consumption datasets using LSTM and N-HiTS architectures, the attacks show that user-level MIAs can achieve perfect detection under strict threat models, with online attacks outperforming offline ones. The DTS attack achieves the strongest ROC-AUC scores, while vulnerability increases with longer prediction horizons and smaller training populations. These results establish new baselines for privacy risk assessment in time series forecasting.

## Method Summary
The authors propose two attacks: (1) Multi-Signal LiRA, which extracts statistical signals like MSE, MAE, trend, seasonality, and TS2Vec embeddings from model outputs and computes likelihood ratios using shadow models, and (2) DTS, a deep learning classifier trained on prediction-target pairs that learns membership inference end-to-end. Both attacks are evaluated at record and user levels on EEG (TUH) and electricity (ELD) datasets with LSTM and N-HiTS architectures. The attacks use 64 shadow models trained on auxiliary data, with online attacks including target records and offline attacks excluding them. User-level inference aggregates record-level scores across a user's multiple records.

## Key Results
- Multi-Signal LiRA and DTS attacks achieve strong ROC-AUC scores, with DTS generally performing best across settings
- Online attacks (shadow models trained with target data) significantly outperform offline attacks, demonstrating the impact of data distribution shifts
- User-level attacks achieve perfect detection under strict threat models by aggregating record-level signals
- Vulnerability increases with longer prediction horizons (H=20 vs H=10) and smaller training populations (20 users vs 40)
- Attack effectiveness varies by dataset, with EEG showing higher vulnerability than electricity consumption data

## Why This Works (Mechanism)

### Mechanism 1
Time series forecasting models memorize training data, and this memorization can be detected by exploiting differences in statistical signals between training and non-training data. Forecasting models produce subtly different outputs for training records vs. non-training records. These differences manifest in error-based signals (MSE, MAE, SMAPE), structural signals (trend, seasonality), and representation-based signals (TS2Vec embeddings). By collecting these signals from shadow models trained with and without the target record, an attacker can model the distributions for member vs. non-member records and compute a likelihood ratio score. The core assumption is that the output of a model on training data is statistically distinguishable from its output on non-training data, assuming the model has learned or memorized patterns specific to the training set.

### Mechanism 2
Aggregating membership inference signals across multiple records belonging to the same user significantly amplifies the attack's success rate, often enabling perfect detection. Individual records may provide weak membership signals. However, since a single user contributes multiple records, an attacker can compute a user-level membership score by aggregating record-level scores (e.g., by taking their product). This increases the signal-to-noise ratio, as consistent patterns across related records provide stronger evidence of user-level membership. The core assumption is that records from the same user are treated near-independently by the model, allowing aggregation of their membership scores, and that the user's data distribution is distinct enough to create a detectable aggregate signal.

### Mechanism 3
A deep learning classifier (DTS) trained directly on prediction-target pairs can learn to distinguish members from non-members more effectively than handcrafted statistical signals. Instead of manually designing features, the DTS attack trains a neural network on pairs of ground-truth sequences and model predictions. The classifier learns to identify subtle, high-dimensional patterns indicative of membership that are missed by simpler statistics. The core assumption is that the raw (prediction, target) pairs contain discriminative information about membership that is difficult to capture with pre-defined statistical metrics, and that the classifier requires a representative auxiliary dataset to train effectively.

## Foundational Learning

- **Concept:** Likelihood Ratio Attack (LiRA)
  - **Why needed here:** The paper's "Multi-Signal LiRA" is a core proposed attack. Understanding LiRA's use of shadow models to model member/non-member distributions is essential.
  - **Quick check question:** How does LiRA use shadow models to determine if a specific data point was in a target model's training set?

- **Concept:** Time Series Forecasting
  - **Why needed here:** The target models are forecasting models (LSTM, N-HiTS). Understanding the task (predicting future `Y` from past `X`), key terms (lookback `L`, horizon `H`), and error metrics is critical.
  - **Quick check question:** In a time series forecasting model, what is the 'prediction horizon' and how does its length relate to privacy risk as found in the paper?

- **Concept:** Membership Inference Attacks (MIAs)
  - **Why needed here:** This is the central problem. One must understand the MIA's goal (binary classification: member or not?) and the difference between record-level and user-level attacks.
  - **Quick check question:** What is the primary objective of a Membership Inference Attack, and how does a user-level MIA differ from a record-level MIA?

## Architecture Onboarding

- **Component map:** Target Model (LSTM or N-HiTS) trained on D_train -> Adversary with black-box query access -> Auxiliary Dataset D_aux -> Shadow Models (64) -> Attack-specific components: (1) LiRA/RMIA: Signal extractors (MSE, TS2Vec, etc.) and statistical scoring; (2) DTS: Membership Classifier trained on (target, prediction, label) triplets from shadow models -> User-level: Aggregation of record-level scores for all user's records

- **Critical path:**
  1. Train target forecasting model f_theta
  2. Train K shadow models on subsets of D_aux (online) or separate data (offline)
  3. For LiRA/RMIA: Extract signals from target and shadow models for audit record. Model signal distributions for "in" and "out" groups. Compute likelihood ratio
  4. For DTS: Generate training triplets from shadow models. Train theta_DTS classifier. Feed target record's (Y, f_theta(X)) pair to classifier for probability
  5. For user-level: Aggregate record-level scores for all user's records

- **Design tradeoffs:**
  - Online vs. Offline: Online attacks (shadow models include target record data) are far more powerful but less realistic. Offline attacks are realistic but weaker due to distribution shift
  - Statistical vs. Learned: LiRA/RMIA are interpretable and need fewer shadow models. DTS can be more powerful but is sensitive to data distribution shifts and requires classifier training
  - Number of Shadow Models: More models (e.g., 64 vs 400+) improve stability but increase computational cost

- **Failure signatures:**
  - Strong Generalization: If target model shows no overfitting, member/non-member distributions overlap, causing near-random attack performance
  - Large Population: Performance drops as the number of training individuals increases
  - Distribution Shift: If auxiliary data is unrepresentative, offline attacks and DTS fail

- **First 3 experiments:**
  1. Baseline Reproduction: Implement a basic LiRA attack using MSE against an LSTM on a simple dataset. Reproduce the online vs. offline performance gap
  2. Signal Comparison: Compare ROC-AUC of LiRA using different signals (MSE, TS2Vec, Multi-Signal) against an N-HiTS model
  3. DTS Sensitivity: Implement DTS and train the classifier with varying fractions of auxiliary data (1%, 5%, 10%) to measure data efficiency

## Open Questions the Paper Calls Out

### Open Question 1
Can an end-to-end deep learning approach outperform the current independent score aggregation method for user-level membership inference? The conclusion states that "refining user-level inference, moving beyond independent score aggregation to end-to-end approaches, remains an important open challenge." Current methods assume record-level scores are independent and aggregate them via multiplication, which may fail to capture complex dependencies between records belonging to the same user. Developing a classifier that processes a collection of records simultaneously and comparing its ROC-AUC against the score-product method would resolve this.

### Open Question 2
Do these membership inference vulnerabilities persist in Transformer-based architectures and probabilistic forecasting settings? The authors limit their scope to LSTM and N-HiTS, explicitly calling for evaluations on "alternative architectures such as transformers... and settings incorporating... probabilistic forecasts." Attention mechanisms and probabilistic outputs may exhibit different memorization characteristics or leakage signals compared to the deterministic, recurrent models tested. Applying the DTS and LiRA attacks to Transformer-based time series forecasters and analyzing the resulting TPR at low FPRs would resolve this.

### Open Question 3
Does modeling the full covariance matrix between attack signals significantly improve the performance of Multi-Signal LiRA? The paper notes in Section V-A that a "principled approach" would estimate the full covariance matrix, but they were forced to use a diagonal approximation due to the practical constraint of training only 64 shadow models. Stable estimation of covariance requires a significantly larger number of shadow models (e.g., 400+) than the study utilized. Training hundreds of shadow models to compare the ROC-AUC of Multi-Signal LiRA using diagonal versus full covariance matrices would resolve this.

## Limitations

- **Computational cost:** Training 64 shadow models for each attack is computationally expensive and may not be practical for large-scale deployments
- **Strict threat model:** The attacks achieve perfect detection under online settings with shadow models trained on target data, but these conditions are rarely met in practice
- **Data distribution sensitivity:** DTS classifier performance heavily depends on the auxiliary dataset's representativeness, and the paper doesn't extensively validate this sensitivity

## Confidence

- **Record-level attack efficacy:** High confidence - Extensive experimental validation across multiple datasets, model architectures, and signal types with consistent results
- **User-level attack amplification:** Medium confidence - Theoretical framework is sound but high variance in user-level TPR at low FPR suggests dataset and user dependency
- **DTS classifier advantages:** Medium confidence - Shows promise but limited discussion of architecture details and sensitivity to auxiliary data distribution creates uncertainty

## Next Checks

1. **Offline attack sensitivity analysis:** Systematically vary the similarity between auxiliary and target data distributions to quantify the degradation in DTS and LiRA performance. This would clarify the practical limits of these attacks under realistic data shifts.

2. **Regularization impact study:** Train target models with varying levels of L2 regularization and dropout to establish a quantitative relationship between overfitting and membership inference vulnerability. This would help identify when these attacks become ineffective.

3. **Computational efficiency comparison:** Implement and benchmark the runtime and memory requirements of LiRA vs. DTS attacks at scale (e.g., 1000+ shadow models) to determine the practical feasibility of each approach for real-world threat modeling.