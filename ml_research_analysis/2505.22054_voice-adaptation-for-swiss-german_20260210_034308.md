---
ver: rpa2
title: Voice Adaptation for Swiss German
arxiv_id: '2505.22054'
source_url: https://arxiv.org/abs/2505.22054
tags:
- stt4sg
- german
- speech
- dialect
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of developing voice adaptation
  technology for Swiss German dialects, which are underrepresented in existing speech
  synthesis systems. The authors create a large pseudo-labeled dataset (SRG-corpus)
  by automatically transcribing and dialect-tagging approximately 5,000 hours of Swiss
  podcast speech, then fine-tune the XTTSv2 model on this data.
---

# Voice Adaptation for Swiss German

## Quick Facts
- **arXiv ID**: 2505.22054
- **Source URL**: https://arxiv.org/abs/2505.22054
- **Reference count**: 0
- **Primary result**: Voice adaptation for Swiss German dialects achieved through pseudo-labeled dataset and XTTSv2 fine-tuning, with human evaluations showing near-human voice similarity scores

## Executive Summary
This paper addresses the challenge of developing voice adaptation technology for Swiss German dialects, which are underrepresented in existing speech synthesis systems. The authors create a large pseudo-labeled dataset (SRG-corpus) by automatically transcribing and dialect-tagging approximately 5,000 hours of Swiss podcast speech, then fine-tune the XTTSv2 model on this data. Their approach achieves strong results in both automated and human evaluations: automated metrics show WER as low as 0.107 and BLEU scores up to 0.898 for German content, while human evaluations report CMOS scores up to -0.28 (near human quality) and SMOS scores of 3.8 (very similar voices). The study demonstrates that high-quality voice adaptation for Swiss German dialects is feasible using weakly labeled data and large-scale fine-tuning.

## Method Summary
The authors developed a comprehensive approach to Swiss German voice adaptation by first creating the SRG-corpus, a large-scale pseudo-labeled dataset of approximately 5,000 hours of Swiss podcast speech. They used automated transcription and dialect classification to generate this corpus, then fine-tuned the XTTSv2 voice cloning model on the resulting data. The fine-tuning process incorporated data augmentation techniques and was evaluated using both automated metrics (WER, BLEU, CER) and human evaluations (CMOS for voice similarity, SMOS for naturalness, MOS for overall quality). The methodology leverages weakly labeled data to overcome the scarcity of Swiss German speech resources while maintaining high adaptation quality.

## Key Results
- Automated metrics show WER as low as 0.107 and BLEU scores up to 0.898 for German content
- Human evaluations report CMOS scores up to -0.28, indicating near-human voice quality
- SMOS scores of 3.8 demonstrate very similar voices between adapted and target speakers
- MOS evaluations for naturalness range from 2.5-2.9, indicating room for improvement

## Why This Works (Mechanism)
The success of this approach stems from leveraging weakly supervised learning on large-scale podcast data, which provides diverse and natural Swiss German speech patterns. By using automated transcription and dialect classification, the authors overcome the data scarcity problem that typically plagues minority dialect adaptation. The XTTSv2 model's architecture is particularly well-suited for voice adaptation tasks, as it can effectively learn speaker characteristics from relatively small amounts of fine-tuning data while maintaining the target dialect's phonetic and prosodic features.

## Foundational Learning
- **Pseudo-labeling**: Automatically generating labels for unlabeled data; needed to scale dataset creation without manual annotation
- **Dialect classification**: Automatically identifying Swiss German dialects; needed to maintain dialect-specific characteristics in synthesized speech
- **Voice adaptation vs voice cloning**: Adapting existing models to new speakers vs creating new voices from scratch; needed to understand the scope and limitations of the approach
- **Automated evaluation metrics**: WER, BLEU, CER for objective quality assessment; needed for scalable quality measurement
- **Human evaluation protocols**: CMOS, SMOS, MOS for subjective quality assessment; needed to capture perceptual aspects that automated metrics miss
- **Data augmentation**: Techniques to artificially increase training data diversity; needed to improve model robustness and generalization

## Architecture Onboarding

**Component Map**: Podcast audio → ASR transcription → Dialect classification → SRG-corpus → XTTSv2 fine-tuning → Voice adaptation model

**Critical Path**: The most important sequence is Podcast audio → ASR transcription → Dialect classification → SRG-corpus, as the quality of pseudo-labels directly impacts adaptation performance.

**Design Tradeoffs**: The authors chose automated pseudo-labeling over manual annotation to scale dataset creation, accepting potential transcription errors for coverage. They prioritized Swiss German dialect representation over perfect German transcription accuracy, recognizing that dialect-specific features are more critical for voice adaptation.

**Failure Signatures**: Poor voice similarity scores would indicate issues with either the pseudo-labeling quality or the fine-tuning process. High WER but low BLEU scores would suggest transcription errors without affecting content preservation. Dialect misclassification would manifest as unnatural prosody or incorrect phonetic realizations.

**First Experiments**:
1. Fine-tune XTTSv2 on a small subset of manually verified pseudo-labels to establish baseline adaptation quality
2. Test voice adaptation performance on held-out speakers from the same dialect region to assess speaker-specific generalization
3. Evaluate cross-dialect adaptation by fine-tuning on one Swiss German dialect and testing on another

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset creation relies on German ASR systems, potentially introducing systematic errors for Swiss German vocabulary and grammar
- Dialect imbalance in SRG-corpus, with Bernese Swiss German comprising 44% of content
- Human evaluation sample size is relatively small (23 raters) and lacks diversity in language backgrounds
- Generated speech naturalness scores (2.5-2.9) indicate performance still falls short of human quality

## Confidence

**High confidence**: The approach successfully fine-tunes XTTSv2 for Swiss German voice adaptation using pseudo-labeled data

**Medium confidence**: The methodology achieves near-human voice similarity (CMOS scores up to -0.28) - limited by evaluation sample size

**Medium confidence**: The SRG-corpus enables effective voice adaptation - limited by potential transcription errors and dialect imbalance

## Next Checks
1. Conduct cross-validation with human-transcribed Swiss German speech to quantify transcription error impact on adaptation quality
2. Test the fine-tuned models on out-of-domain Swiss German speech to assess robustness beyond podcast content
3. Evaluate voice adaptation performance across all Swiss German dialects, particularly underrepresented ones like Ticinese and Walser German