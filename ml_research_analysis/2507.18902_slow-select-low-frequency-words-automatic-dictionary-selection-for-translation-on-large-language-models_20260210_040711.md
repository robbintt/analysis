---
ver: rpa2
title: 'SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation
  on Large Language Models'
arxiv_id: '2507.18902'
source_url: https://arxiv.org/abs/2507.18902
tags:
- translation
- slow
- dictionary
- language
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Automatic Dictionary Selection (ADS)
  task to optimize dictionary usage for LLM-based translation. The proposed method,
  SLoW (Select Low-frequency Words!), selects dictionaries with lower frequency words,
  improving translation quality while reducing token usage.
---

# SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models

## Quick Facts
- arXiv ID: 2507.18902
- Source URL: https://arxiv.org/abs/2507.18902
- Authors: Hongyuan Lu; Zixuan Li; Zefan Zhang; Wai Lam
- Reference count: 14
- One-line primary result: SLoW improves translation quality while reducing token usage by selecting low-frequency dictionary words

## Executive Summary
This paper introduces the Automatic Dictionary Selection (ADS) task to optimize dictionary usage for LLM-based translation. The proposed method, SLoW (Select Low-frequency Words!), selects dictionaries with lower frequency words, improving translation quality while reducing token usage. Evaluated on 100 languages from FLORES, SLoW outperforms strong baselines like noun/verb/adjective dictionaries and even surpasses full dictionary usage in some cases. Across models (ChatGPT, Llama, DeepSeek), SLoW improves translation performance in most language pairs, with many improvements exceeding 20 COMET points. The method requires no access to LLM training data, using public resources for frequency estimation instead.

## Method Summary
SLoW addresses the challenge of optimizing dictionary selection for LLM-based translation by selecting V lowest-frequency words from available dictionaries. The method estimates word frequencies using public web resources (wordfreq library) rather than requiring access to LLM training data. For each translation task, SLoW extracts candidate dictionary entries matching source tokens, sorts them by estimated frequency, and selects the V lowest-frequency entries. These selected entries are then formatted into translation prompts. The method is evaluated across 100 languages from FLORES using GPT-4o-mini, Llama-3.1-8b, and DeepSeek-V3 models, with performance measured using COMET, BLEU, and chrF metrics.

## Key Results
- SLoW consistently outperforms strong baselines including noun-only, verb-only, and adjective-only dictionary selection methods
- The method improves translation performance in most language pairs, with many improvements exceeding 20 COMET points
- SLoW achieves better results than high-frequency dictionary selection, demonstrating the superiority of low-frequency word selection
- The approach reduces token consumption while maintaining or improving translation quality compared to full dictionary usage
- Performance gains are observed across multiple LLM models including ChatGPT, Llama, and DeepSeek

## Why This Works (Mechanism)

### Mechanism 1
Low-frequency words in training data are less well-learned by LLMs, so dictionary entries for these words provide higher marginal utility for translation. Frequency in pre-training corpus correlates with model's internal representation quality. Lower-frequency tokens have weaker embeddings and contextual associations. Providing explicit dictionary mappings compensates for this deficit at inference time without requiring model fine-tuning. Core assumption: Word frequency estimates from public web resources (wordfreq) approximate the true frequency distribution in LLM pre-training data. Break condition: If frequency estimates from public resources diverge significantly from true pre-training distributions (e.g., domain-mismatched corpora), selection quality may degrade.

### Mechanism 2
Reducing dictionary size via selective inclusion lowers prompt token count while maintaining or improving translation quality, avoiding context window dilution. LLMs can be distracted by irrelevant or redundant context. Full-dictionary prompting includes many high-frequency words already well-represented internally; these entries add noise without benefit. SLoW filters these out, focusing context budget on informative entries. Core assumption: The relationship between dictionary size and translation quality is non-monotonicâ€”beyond a point, more entries hurt rather than help. Break condition: If an application requires highly specialized terminology where even high-frequency words have domain-specific meanings, filtering by general frequency may incorrectly exclude relevant entries.

### Mechanism 3
Selective dictionary prompting using estimated frequency is portable across LLMs without access to their training data. Frequency distributions across large web-scale corpora are relatively stable; estimates from one source generalize as proxies. This enables a "train-free" method applicable to closed-source models. Core assumption: The correlation between estimated and true frequency is sufficiently strong across diverse models and languages. Break condition: For models with highly non-standard pre-training corpora (e.g., domain-specific LLMs), public web frequency may be a poor proxy.

## Foundational Learning

- Concept: Dictionary-based prompting for MT
  - Why needed here: The entire SLoW method operates as a selection layer on top of dictionary-augmented prompting; understanding how dictionaries are injected into prompts is prerequisite
  - Quick check question: Given a source sentence "The cat sleeps", how would you format a dictionary entry for "cat" into a translation prompt for French?

- Concept: Token budget and context window constraints
  - Why needed here: ADS explicitly optimizes for a fixed dictionary size V; practitioners must understand the trade-off space between context length and performance
  - Quick check question: If a full dictionary has 3,000 entries but your budget V is 1,500, what is the selection objective?

- Concept: Frequency estimation from external corpora
  - Why needed here: SLoW relies on wordfreq-style resources; understanding how these estimates are computed and their limitations is critical for replication and extension
  - Quick check question: If you only have access to a small domain-specific corpus, what risks arise when using it for frequency estimation?

## Architecture Onboarding

- Component map: Input (source sentence, bilingual dictionary D, frequency estimator G, budget V) -> Selection module (sort entries by frequency ascending, select V lowest-frequency entries) -> Prompt constructor (inject selected entries into translation prompt template) -> Output (translated sentence from LLM)

- Critical path:
  1. Pre-compute or retrieve frequency estimates for all dictionary entries (using wordfreq or similar)
  2. For each source sentence, extract candidate dictionary entries matching source tokens
  3. Sort candidates by frequency, retain V lowest
  4. Format prompt with selected dictionary entries
  5. Call LLM, parse translation output

- Design tradeoffs:
  - Budget V selection: Paper aligns V with "Differ in Round-trip" baseline; smaller V saves tokens but may miss useful entries; larger V approaches full dictionary with diminishing returns
  - Frequency source: Public web resources vs. domain-specific corpora vs. true training data (unavailable)
  - Language of frequency estimation: Paper uses English frequency for English-centric LLMs; non-English-centric directions may require different choices

- Failure signatures:
  - Degradation vs. full dictionary (observed in ~8-25% of language pairs depending on direction/model)
  - Incorrect frequency estimates leading to exclusion of genuinely helpful entries
  - POS imbalance if low-frequency selection systematically excludes certain word classes needed for syntax

- First 3 experiments:
  1. Reproduce SLoW on a small subset of FLORES (e.g., 5 languages) using wordfreq; compare COMET/BLEU against Vanilla, Noun-only, and Full-dictionary baselines
  2. Ablation: Vary budget V (e.g., 25%, 50%, 75% of full dictionary) and plot performance vs. token count; identify knee point
  3. Sensitivity: Replace wordfreq with a different frequency source (e.g., Wikipedia-derived counts) and measure correlation in selected entries and translation quality impact

## Open Questions the Paper Calls Out

### Open Question 1
Would an optimally tuned dictionary size V (rather than one aligned to the "Differ in Round-trip" baseline) enable SLoW to consistently outperform full-dictionary prompting? The paper fixes V to match another baseline's token count rather than performing a systematic hyperparameter search. Experiments sweeping V across a range of values on a held-out validation set, reporting performance vs. token-cost curves, would resolve this.

### Open Question 2
How closely does web-resource-based frequency (e.g., wordfreq) approximate the actual token frequency distributions in LLM pretraining corpora, and does approximation error affect SLoW's gains? The method relies on an external frequency estimator without quantifying its fidelity to the true LLM training distribution. Correlation analysis between web-based frequencies and training-data frequencies, followed by ablation comparing SLoW with true vs. estimated frequencies, would resolve this.

### Open Question 3
Does dynamically adapting dictionary selection per sentence (e.g., based on source-side lexical difficulty or model confidence) improve upon the current fixed-selection strategy? The paper applies a globally fixed V across all sentences and languages, without considering instance-level variation. Implementing per-sentence adaptive selection and comparing against static SLoW would resolve this.

## Limitations
- Reliance on frequency estimates from public web resources that may not accurately reflect true LLM training distributions
- Dictionary construction via ChatGPT prompting introduces variability that could affect reproducibility
- Observed degradation in ~8-25% of language pairs indicates low-frequency selection is not universally beneficial
- Potential POS class imbalances from systematic exclusion of certain word categories

## Confidence

- **High Confidence**: Empirical results demonstrating SLoW's superiority over noun-only and adjective-only baselines, and its ability to outperform full dictionary usage in some cases, are well-supported by extensive FLORES evaluation across 100 languages and multiple models
- **Medium Confidence**: Theoretical mechanism linking low-frequency words to higher marginal utility is plausible but relies on untested assumption that public frequency estimates correlate well with model pre-training distributions
- **Low Confidence**: Claim that low-frequency selection works universally across all language pairs and models, given observed failures in non-trivial percentage of cases and lack of validation on domain-specific or non-English-centric LLMs

## Next Checks

1. **Frequency Proxy Validation**: Conduct controlled experiment using LLM with accessible pre-training data to measure correlation between wordfreq estimates and actual training frequencies, then assess how this correlation affects SLoW's selection quality and translation performance

2. **POS Class Balance Analysis**: Analyze distribution of POS tags in SLoW-selected dictionaries versus full dictionaries across multiple language pairs to determine if systematic exclusion of certain classes occurs and whether this correlates with degradation cases

3. **Domain Adaptation Test**: Evaluate SLoW on domain-specific translation task (e.g., biomedical or legal text) where frequency distributions differ from general web data, comparing performance against both full dictionary and frequency-based selection using domain-specific frequency estimates