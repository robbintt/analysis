---
ver: rpa2
title: 'CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs'
arxiv_id: '2505.13778'
source_url: https://arxiv.org/abs/2505.13778
tags:
- reasoning
- token
- tokens
- coin
- inflation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CoIn, a framework to audit token usage in
  commercial opaque LLM APIs that hide reasoning traces while charging for them. It
  addresses the problem of token count inflation, where providers can overcharge users
  by reporting more tokens than generated or injecting low-quality synthetic tokens.
---

# CoIn: Counting the Invisible Reasoning Tokens in Commercial Opaque LLM APIs

## Quick Facts
- arXiv ID: 2505.13778
- Source URL: https://arxiv.org/abs/2505.13778
- Reference count: 40
- Primary result: Detects token inflation with up to 94.7% success rate while maintaining <40% embedding exposure and <4% token visibility

## Executive Summary
CoIn is a framework that audits token usage in commercial opaque LLM APIs that hide reasoning traces while charging for them. The system addresses token count inflation, where providers overcharge users by reporting more tokens than generated or injecting low-quality synthetic tokens. CoIn combines two verification methods: a Merkle hash tree that commits to token embeddings for quantity verification, and a lightweight matching head that checks semantic relevance between reasoning and answer tokens for validity verification. Experiments show that CoIn detects token inflation with up to 94.7% success rate, even under adaptive attacks with strong token injection, while maintaining low exposure of hidden content.

## Method Summary
CoIn combines two complementary verification methods to audit token usage in opaque LLM APIs. The Token Quantity Verification uses Merkle hash trees built on token embeddings to create commitment proofs that can verify the number of tokens processed without exposing their content. The Semantic Validity Verification employs lightweight matching heads trained to detect whether reasoning tokens are semantically relevant to the final answer, flagging injected or fabricated tokens. The framework is evaluated on five DeepSeek-R1 distilled datasets (Medical, Code, Math, General, Math-OOD) with 20K training samples and 1K evaluation samples per dataset, testing across various inflation rates and adaptive attack strategies.

## Key Results
- Achieves up to 94.7% detection success rate for token inflation under adaptive attacks with strong token injection
- Maintains low exposure with <40% embedding exposure and <4% token visibility during auditing
- Successfully detects various inflation strategies including Naive, Counterfeit, Impersonation, and advanced adaptive inflation methods

## Why This Works (Mechanism)
The framework works by creating a verifiable commitment to token embeddings through Merkle trees, which provides cryptographic proof of token quantity without exposing actual content. The semantic matching heads learn to distinguish genuine reasoning tokens from injected ones by analyzing the relationship between reasoning traces and final answers. By combining cryptographic verification with machine learning-based semantic analysis, CoIn creates multiple layers of accountability that are difficult for providers to circumvent simultaneously.

## Foundational Learning
**Merkle Hash Trees** - Hierarchical data structure where each leaf is a hash and each non-leaf node is a hash of its children. Needed to create cryptographic commitments to token sets that can be verified without revealing content. Quick check: Verify hash tree construction time scales linearly with block size.

**Token Embedding Matching** - Using all-MiniLM-L6-v2 embeddings (384-dim) as feature vectors combined with 2-layer FFN to predict semantic relevance between token pairs. Needed to detect fabricated reasoning tokens that don't connect to the answer. Quick check: Train matching heads on balanced positive/negative samples and verify >90% accuracy on validation set.

**DeepSets Architecture** - Permutation-invariant neural network that processes variable-length sets of token embeddings to produce fixed-size representations. Needed to aggregate reasoning block embeddings for semantic validity verification. Quick check: Verify DeepSets produces consistent outputs regardless of token order within reasoning blocks.

## Architecture Onboarding
**Component Map**: Token Embeddings -> Merkle Tree Construction -> Hash Proof Generation -> Matching Head Verification -> Detection Decision
**Critical Path**: Token generation → embedding extraction → Merkle tree commitment → matching head evaluation → detection decision
**Design Tradeoffs**: CoIn balances audit effectiveness against content exposure by using random sampling (γ=0.3) rather than full content exposure, trading some detection sensitivity for privacy protection.
**Failure Signatures**: Low DSR indicates matching head underfitting; high AER on benign samples suggests threshold misconfiguration; hash verification failures indicate implementation errors in tree construction.
**First Experiments**:
1. Verify Merkle tree construction and proof verification work correctly with test token embeddings
2. Train matching heads on Naive inflation samples and verify detection accuracy
3. Test full pipeline on simple inflation scenarios (IR=0.5) to validate end-to-end functionality

## Open Questions the Paper Calls Out
**Open Question 1**: How can the detection sensitivity of CoIn be improved for token count inflation with very low inflation rates (e.g., < 10%)? The current framework exhibits suboptimal performance when the Inflation Rate is low because statistical deviations become indistinguishable from noise.

**Open Question 2**: Can the auditing framework remain effective if the COLA provider acts maliciously by selecting an adversarially optimized embedding model or manipulation strategy? The framework assumes third-party embeddings but doesn't test against gradient-based adversarial attacks on the embedding space.

**Open Question 3**: How can the requirement for active provider cooperation be relaxed to support auditing of fully non-compliant or opaque services? The current process requires provider cooperation for Merkle proof generation and embedding provision, creating circular dependency with untrustworthy providers.

## Limitations
- Suboptimal performance for detecting malicious samples when the Inflation Rate is low
- Requires active cooperation of COLA providers for the auditing process
- Effectiveness may be compromised if providers use adversarially optimized embedding models or manipulation strategies

## Confidence
- **High confidence** in the core conceptual framework combining Merkle tree verification with semantic matching for token auditability
- **Medium confidence** in reported DSR values (94.7%) given the underspecified matching head architecture and training procedures
- **Low confidence** in the comparative analysis of adaptive inflation strategies due to missing implementation details for each inflation type
- **Medium confidence** in the exposure metrics (AER <40%) given the high-level description of random sampling strategy without precise parameters

## Next Checks
1. Reconstruct the complete matching head architecture with explicit hidden dimensions, activation functions, and dropout rates, then verify DSR performance matches reported values across all inflation types
2. Implement each adaptive inflation strategy with precise token selection criteria and insertion patterns, comparing against the reported inflation rates and semantic relevance thresholds
3. Test the Merkle tree construction and verification pipeline with actual token embeddings from a commercial API, measuring hash generation time and proof verification latency across different block sizes (256, 512, 1024) to validate the linear scaling claim