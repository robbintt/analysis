---
ver: rpa2
title: Evaluating transfer learning strategies for improving dairy cattle body weight
  prediction in small farms using depth-image and point-cloud data
arxiv_id: '2601.01044'
source_url: https://arxiv.org/abs/2601.01044
tags:
- learning
- data
- transfer
- point
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated transfer learning strategies to improve dairy
  cattle body weight prediction on small farms with limited data. Top-view depth images
  and point cloud data were collected from three farms of varying sizes.
---

# Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data

## Quick Facts
- arXiv ID: 2601.01044
- Source URL: https://arxiv.org/abs/2601.01044
- Reference count: 19
- Primary result: Transfer learning from larger farms significantly improves body weight prediction accuracy on small farms using depth-image and point-cloud data

## Executive Summary
This study investigates transfer learning strategies to enhance dairy cattle body weight prediction on small farms with limited data availability. The research collected top-view depth images and point cloud data from three farms of varying sizes and evaluated four deep learning models (ConvNeXt and MobileViT for depth images, PointNet and DGCNN for point clouds) under different learning paradigms. Transfer learning from larger farms demonstrated substantial improvements in prediction performance on small-farm test sets, with gains comparable to or exceeding those from joint learning approaches. The study identifies MobileViT and DGCNN as particularly effective for transfer learning applications in this domain.

## Method Summary
The research collected top-view depth images and point cloud data from three dairy farms of varying sizes, with the small farm contributing 1,005 images and larger farms providing 1,515 and 1,530 images respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth-image-based predictions, and PointNet and DGCNN for point-cloud-based predictions. Three learning paradigms were compared: single-source learning (training only on small-farm data), joint learning (combining data from all farms), and transfer learning (pre-training on larger-farm data then fine-tuning on small-farm data). Models were assessed using mean absolute error (MAE) and concordance correlation coefficient (CCC) metrics on small-farm test sets.

## Key Results
- Transfer learning from larger farms significantly improved body weight prediction accuracy on small-farm test sets across all four models
- MobileViT and DGCNN demonstrated the strongest transfer benefits compared to other models
- No consistent performance difference was observed between depth-image-based and point-cloud-based approaches
- Transfer learning gains were comparable to or exceeded those from joint learning strategies

## Why This Works (Mechanism)
Transfer learning works effectively in this context because larger farms provide more diverse training samples that capture a wider range of body conformations and postures across different cattle. The pre-trained models learn general features about cattle body structure that transfer well to small-farm populations, even when the specific farm environment differs. This approach overcomes the data scarcity problem on small farms while avoiding the need for extensive new data collection or cross-farm data sharing.

## Foundational Learning
- **Transfer learning**: Why needed - enables model adaptation when target domain has limited data; Quick check - compare pre-trained vs randomly initialized weights on small-farm test set
- **Point cloud processing**: Why needed - captures 3D spatial relationships of cattle body structure; Quick check - verify point cloud normalization and coordinate alignment
- **Depth image analysis**: Why needed - provides efficient 2D representation of 3D cattle shape; Quick check - confirm depth calibration and camera positioning consistency
- **Concordance correlation coefficient**: Why needed - measures both precision and accuracy of predictions; Quick check - calculate CCC alongside MAE for complete performance assessment

## Architecture Onboarding

**Component Map:**
Point cloud/3D depth image acquisition -> Data preprocessing -> Model architecture (ConvNeXt/MobileViT/PointNet/DGCNN) -> Transfer learning (pre-training on large farm -> fine-tuning on small farm) -> Prediction output

**Critical Path:**
Data acquisition -> Model pre-training on large-farm dataset -> Fine-tuning on small-farm dataset -> Evaluation on held-out small-farm test set

**Design Tradeoffs:**
The study balances model complexity against data availability, using relatively lightweight architectures suitable for small-farm deployment. Depth images offer computational efficiency while point clouds provide richer spatial information. Transfer learning reduces the need for extensive small-farm data collection but requires careful fine-tuning to avoid overfitting.

**Failure Signatures:**
Poor performance on small-farm test sets may indicate domain shift between farm environments, inadequate fine-tuning duration, or model overfitting to larger-farm characteristics. Low CCC values suggest systematic prediction biases or poor correlation with actual weights.

**First Experiments:**
1. Train base model on small-farm data only, evaluate baseline performance
2. Pre-train model on large-farm data, fine-tune on small-farm data with varying learning rates
3. Compare depth-image and point-cloud predictions on identical test samples

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Limited dataset size with only 4,050 images across three farms, restricting generalizability
- Single imaging perspective (top-view) may miss important body conformation features
- No comparison with traditional non-ML weight estimation methods
- Privacy and logistical constraints motivating transfer learning were not empirically tested

## Confidence
- **High confidence**: Transfer learning from larger farms improves prediction accuracy on small-farm test sets across all evaluated models
- **Medium confidence**: MobileViT and DGCNN show the strongest transfer benefits; no consistent performance difference between depth-image and point-cloud models
- **Medium confidence**: Transfer learning gains are comparable to or exceed joint learning benefits

## Next Checks
1. Validate model performance across multiple cattle breeds and farm types beyond the three studied farms
2. Compare transfer learning performance against traditional weight estimation methods (e.g., heart girth measurements) on the same test sets
3. Test model robustness under varying environmental conditions (lighting, camera angles, cattle movement) and validate with temporally separated data from the same farms