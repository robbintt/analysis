---
ver: rpa2
title: 'Dealing with Inconsistency for Reasoning over Knowledge Graphs: A Survey'
arxiv_id: '2502.19023'
source_url: https://arxiv.org/abs/2502.19023
tags:
- reasoning
- knowledge
- inconsistency
- abox
- tbox
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey presents a comprehensive overview of the state-of-the-art
  in reasoning over inconsistent Knowledge Graphs (KGs). It addresses the problem
  of reasoning in KGs that have been populated through (semi-)automated processes
  or integration of heterogeneous datasets, which often leads to inconsistencies that
  hinder reasoning tasks.
---

# Dealing with Inconsistency for Reasoning over Knowledge Graphs: A Survey

## Quick Facts
- arXiv ID: 2502.19023
- Source URL: https://arxiv.org/abs/2502.19023
- Reference count: 20
- The survey provides a comprehensive overview of approaches for reasoning over inconsistent Knowledge Graphs

## Executive Summary
This survey addresses the critical challenge of reasoning over Knowledge Graphs (KGs) that contain inconsistencies arising from automated population processes or heterogeneous dataset integration. The work systematically categorizes approaches across three complementary directions: detecting inconsistent parts of KGs, fixing inconsistencies to achieve consistency, and performing reasoning despite inconsistencies without necessarily resolving them. The survey provides a structured framework for understanding the trade-offs between completeness and scalability, particularly important for large-scale KGs. It identifies key challenges including the need for scalable inconsistency detection, efficient KG fixing approaches, and effective inconsistency-tolerant reasoning techniques for expressive languages.

## Method Summary
The survey employs a comprehensive literature review methodology, systematically analyzing existing approaches to reasoning over inconsistent KGs. It categorizes methods based on their primary function - detection, fixing, or tolerant reasoning - and evaluates them across dimensions including scalability, expressiveness, and completeness guarantees. The analysis considers both theoretical properties and practical considerations, though the survey acknowledges limitations in its coverage of emerging neural and hybrid approaches. The methodology emphasizes understanding the relationships between different approaches and identifying open challenges in the field.

## Key Results
- Provides a comprehensive framework for addressing inconsistency through detection, fixing, and tolerant reasoning approaches
- Identifies scalability vs completeness trade-offs as a fundamental challenge for large-scale KGs
- Highlights the need for more efficient detection and fixing methods for expressive reasoning languages

## Why This Works (Mechanism)
The survey's effectiveness stems from its systematic categorization of inconsistency handling approaches into three complementary directions, allowing for clear understanding of how different methods address the same underlying problem from different angles. By analyzing the trade-offs between completeness and scalability, the survey provides practical guidance for selecting appropriate approaches based on specific KG characteristics and reasoning requirements. The framework helps practitioners understand which methods are suitable for their particular consistency challenges, whether they need full resolution or can work with tolerated inconsistencies.

## Foundational Learning

**Knowledge Graph Consistency** - Why needed: Understanding what constitutes consistency in KGs is fundamental to addressing inconsistency problems. Quick check: Can you identify the logical rules that would be violated by an inconsistent triple?

**Inconsistency Detection Methods** - Why needed: Detecting where inconsistencies occur is the first step in any inconsistency handling approach. Quick check: Given a set of triples, can you manually identify minimal inconsistent subsets?

**Repair Strategies** - Why needed: Once inconsistencies are detected, repair strategies are needed to restore consistency or enable reasoning despite inconsistencies. Quick check: Can you describe the difference between minimal and preferred repairs?

## Architecture Onboarding

**Component Map**: Data Sources -> Inconsistency Detection -> Repair/Resolution -> Reasoning Engine

**Critical Path**: The most important sequence is: (1) Identify inconsistent subsets, (2) Apply appropriate detection/fixing strategy, (3) Perform reasoning with consistency guarantees

**Design Tradeoffs**: Completeness vs Scalability - More complete approaches (e.g., finding all minimal inconsistent subsets) are computationally expensive, while scalable approaches may miss some inconsistencies. Expressiveness vs Efficiency - More expressive reasoning languages enable richer knowledge representation but make inconsistency handling more complex.

**Failure Signatures**: Inability to scale to large KGs, false positives in inconsistency detection, suboptimal repairs that remove too much information, and reasoning engines that fail to handle tolerated inconsistencies properly.

**First Experiments**:
1. Apply detection methods to benchmark KGs with known inconsistencies and measure detection accuracy
2. Compare repair strategies on the same KGs to evaluate information preservation
3. Test tolerant reasoning approaches on inconsistent KGs to assess reasoning quality without repair

## Open Questions the Paper Calls Out
The survey identifies several open challenges including the need for scalable inconsistency detection methods for large-scale KGs, efficient KG fixing approaches that preserve as much information as possible, and effective inconsistency-tolerant reasoning techniques for expressive reasoning languages. It also notes the rapid evolution of the field and the need to incorporate neural and hybrid approaches that have emerged recently.

## Limitations
- Primarily focuses on symbolic reasoning approaches, potentially missing important neural and hybrid methods
- May oversimplify relationships between different approaches, particularly in how detection, fixing, and tolerant reasoning techniques interact
- Provides qualitative trade-off discussions without concrete benchmarks or quantitative comparisons across methods

## Confidence
- High confidence in the survey's core framework of addressing inconsistency through detection, fixing, and tolerant reasoning approaches
- Medium confidence in the identification of key challenges like scalability and expressiveness
- Low confidence in the completeness of the survey given the rapid evolution of KG reasoning techniques

## Next Checks
1. Verify whether recent neural-symbolic approaches for inconsistency handling are adequately represented in the survey through a targeted literature review
2. Conduct a quantitative comparison of detection and fixing methods on benchmark KG datasets to validate claimed scalability trade-offs
3. Evaluate the practical applicability of surveyed methods on real-world KGs with known inconsistencies to assess their effectiveness beyond theoretical guarantees