---
ver: rpa2
title: Mitigating Degree Bias in Graph Representation Learning with Learnable Structural
  Augmentation and Structural Self-Attention
arxiv_id: '2504.15075'
source_url: https://arxiv.org/abs/2504.15075
tags:
- graph
- nodes
- node
- structural
- augmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of degree bias in graph neural
  networks, where low-degree nodes are under-represented due to insufficient messages,
  while high-degree nodes receive excessive messages. The core method, DegFairGT,
  mitigates this bias by discovering structural similarities between non-adjacent
  nodes through learnable structural augmentation and structural self-attention.
---

# Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention

## Quick Facts
- **arXiv ID:** 2504.15075
- **Source URL:** https://arxiv.org/abs/2504.15075
- **Reference count:** 40
- **Primary result:** Outperforms state-of-the-art baselines in degree fairness, node classification, and node clustering on six datasets.

## Executive Summary
This paper introduces DegFairGT, a Graph Transformer-based method designed to mitigate degree bias in Graph Neural Networks. Degree bias occurs when low-degree nodes receive insufficient messages while high-degree nodes are overwhelmed, leading to unfair representations. DegFairGT addresses this by generating informative edges between non-adjacent nodes with high structural similarity through a learnable structural augmentation. A structural self-attention mechanism captures high-order proximity and node roles, while a self-supervised learning task preserves global graph structures and regularizes the augmentation. Experiments on six datasets demonstrate improved fairness metrics (ΔSP, ΔEO) and competitive performance in node classification and clustering.

## Method Summary
DegFairGT mitigates degree bias by augmenting the graph with edges between non-adjacent nodes that share similar structural roles within the same community. It computes a degree-weighted matrix that prioritizes low-degree nodes and combines it with the original adjacency matrix. Edges are sampled via a differentiable Bernoulli process (Gumbel-Softmax). A structural self-attention mechanism is then used to capture high-order proximity and node roles by injecting structural priors into the attention scores. To preserve global graph structures and prevent augmentation collapse, a self-supervised learning task is employed, combining a reconstruction loss (preserving p-step transition probabilities and node features) with an augmentation regularization loss (BCE between original and augmented adjacency matrices).

## Key Results
- Outperforms state-of-the-art baselines in degree fairness analysis (ΔSP, ΔEO) on six datasets.
- Achieves competitive performance in node classification and node clustering tasks.
- Ablation studies confirm the necessity of the augmentation module and the self-supervised loss for mitigating degree bias.

## Why This Works (Mechanism)

### Mechanism 1: Structural Augmentation for Balanced Message Distribution
The DegFairGT model generates informative edges between non-adjacent nodes with high structural similarity, balancing message distribution in GNNs. It constructs a degree-weighted matrix (D) that quantifies structural similarity between node pairs, prioritizing low-degree nodes. This matrix is linearly combined with the original adjacency matrix (A) to form an augmented adjacency matrix (Ã), from which edges are sampled via a differentiable Bernoulli process (Gumbel-Softmax). This process is constrained by a community-aware sampling strategy that identifies context nodes within k-hop neighborhoods. The mechanism assumes that nodes with similar structural roles (quantified by low degrees) within the same community and k-hop distance are likely to share informative features, and connecting them preserves the homophily principle.

### Mechanism 2: Structural Self-Attention for High-Order Proximity
A structural self-attention mechanism enables the model to capture high-order proximity and node roles, which are not learned by standard self-attention in graph transformers. The attention score is modified to incorporate two structural signals: (1) a high-order proximity vector (s_ij) computed from the intersection-over-union of k-hop neighborhoods, and (2) a linearly transformed degree-weighted score (f^l_d(D_ij)). These are injected into the query and key projections and added as a bias term in the attention calculation. This mechanism assumes that structural similarity and proximity information can be effectively captured by hand-crafted metrics (k-hop neighbor overlap, degree products) and that their integration into the attention mechanism will guide representation learning more effectively than data-driven positional encodings alone.

### Mechanism 3: Self-Supervised Regularization for Global Structure Preservation
A dual self-supervised learning task preserves the global graph structure and regularizes the augmentation process, preventing it from generating degenerate or noisy graphs. The model is trained with a combined loss: (1) a reconstruction loss (L1) that forces the output embeddings to preserve the p-step transition probability matrix of the original graph and to reconstruct initial node features; (2) an augmentation regularization loss (L2, a Binary Cross-Entropy) that penalizes the augmented adjacency matrix for deviating too far from the original one. The total loss is L = L1 + αL2. This assumes that the p-step transition probability matrix is a sufficient proxy for global graph structure and that the BCE loss is an effective regularizer to prevent the augmentation from collapsing into a fully connected graph or a graph with no edges.

## Foundational Learning

- **Concept:** Message Passing in Graph Neural Networks (GNNs)
  - *Why needed here:* DegFairGT is built to solve a specific problem (degree bias) that arises from the standard GNN message-passing mechanism. Understanding that nodes update their representations by aggregating information from neighbors is fundamental to grasping why low-degree nodes receive insufficient messages and high-degree nodes receive too many.
  - *Quick check question:* Explain in one sentence how a node's representation is updated in a standard GNN layer, and why this process can disadvantage nodes with few neighbors.

- **Concept:** Self-Attention in Transformers
  - *Why needed here:* The DegFairGT model is a Graph Transformer. Its core innovation is a modified structural self-attention mechanism. A reader must understand the baseline operation of self-attention (computing attention scores from query, key, and value projections) to appreciate how DegFairGT injects structural priors into this process.
  - *Quick check question:* In a standard transformer, what are the query, key, and value matrices, and how are they used to compute the attention score between two elements?

- **Concept:** Graph Augmentation and Regularization
  - *Why needed here:* The paper's first main contribution is a learnable structural graph augmentation. Understanding the general goal of augmentation (creating modified views of data to improve robustness or performance) and the risk of it causing degradation is essential for understanding why the authors introduce a specific regularization loss (L2).
  - *Quick check question:* What is the primary risk of randomly adding edges in a graph augmentation process, and what general technique does the paper use to mitigate this risk?

## Architecture Onboarding

- **Component map:**
    1.  **Input Processing**: Node features (X) and adjacency matrix (A).
    2.  **Precomputation Module**: Computes the p-step transition matrix (M(p)), performs k-means clustering to define communities, and calculates the high-order proximity matrix (s) and degree-weighted matrix (D). This is outside the main gradient path but crucial for inputs.
    3.  **Learnable Augmentation Module**: Takes A and D, combines them (Ã = ξA + ζD), and samples to produce the augmented adjacency matrix (A'). This is differentiable via Gumbel-Softmax.
    4.  **Structural Self-Attention Module**: The core Graph Transformer encoder. It takes node features (H) and structural signals (s, D) to compute attention scores (α) and produce updated node representations.
    5.  **Self-Supervised Head**: Computes the two losses (L1, L2). L1 uses the final embeddings (Z) to reconstruct M(p) and X. L2 compares A' to A.

- **Critical path:**
    1.  **Data Preprocessing**: Cluster nodes, compute k-hop neighborhoods, and precompute the `s` (proximity) and `D` (degree-weighted) matrices. **Action**: Verify this step completes without OOM errors on large graphs, as k-hop expansion can be memory-intensive.
    2.  **Model Initialization**: Initialize projection weights for the transformer and the linear combinations for the augmentation module. **Action**: Ensure ξ and ζ (augmentation mix) are set according to Table 2 (e.g., ξ=0.8, ζ=0.2).
    3.  **Forward Pass**: Pass inputs through augmentation, then the transformer encoder. **Action**: Profile the attention computation, as the structural bias adds overhead to the standard O(N²) complexity.
    4.  **Loss Computation and Backpropagation**: Compute L1 and L2. The total loss `L = L1 + αL2`. **Action**: Monitor both loss terms individually to ensure L2 is effectively regularizing the augmentation and not dominating.

- **Design tradeoffs:**
    1.  **Fairness vs. Structure Preservation (α)**: The hyperparameter α in `L = L1 + αL2` directly controls the trade-off. A higher α forces the augmented graph to stay closer to the original (preserving structure) but may limit its ability to add informative edges for low-degree nodes (limiting fairness gains). The paper finds α=1.0 to be a good balance.
    2.  **Augmentation Composition (ξ vs. ζ)**: The `ξ` and `ζ` parameters in `Ã = ξA + ζD` control how much the augmentation relies on the original graph versus the degree-weighted similarity matrix. Higher ζ (e.g., >0.2 in Table 9) was observed to generate noisier edges.
    3.  **Clustering Algorithm Choice**: Using K-means on node features versus spectral clustering on the graph structure. The paper (Table 10) shows K-means yields a better fairness-accuracy balance, suggesting feature similarity is more important for defining useful communities for this task than pure connectivity.

- **Failure signatures:**
    1.  **Augmentation Collapse**: If L2 is too weak or α is too low, the model may generate a nearly fully connected or empty graph. **Signature**: L2 loss remains high or increases; downstream task performance degrades sharply.
    2.  **Noisy Edge Generation**: If the clustering fails to group meaningful nodes or ζ is too high, the model adds edges between structurally dissimilar nodes, adding noise. **Signature**: Model performance, especially on high-degree nodes or overall accuracy, degrades compared to a non-augmented baseline.
    3.  **Scalability Issues**: The O(N²) complexity of self-attention and the precomputation of k-hop neighborhoods. **Signature**: Training time or memory usage increases quadratically with graph size, causing timeouts or OOM errors on graphs larger than those in the paper's experiments.

- **First 3 experiments:**
    1.  **Verify Augmentation on a Small Graph**: Run the augmentation module on a small, hand-crafted graph (e.g., a star graph with one hub and many leaves) and visualize the generated A' matrix. **Goal**: Confirm that it preferentially adds edges between leaf (low-degree) nodes and respects the community constraint.
    2.  **Ablation on Loss Terms**: Train DegFairGT with only L1, then only L2, and then both. Compare node classification accuracy and ΔSP/ΔEO fairness metrics. **Goal**: Validate that both the reconstruction objective (L1) and the augmentation regularization (L2) are necessary, as claimed in Table 8.
    3.  **Hyperparameter Sensitivity Check**: Vary the α parameter (e.g., 0.01, 0.1, 0.5, 1.0, 10.0) and the number of clusters M. Plot the resulting accuracy vs. ΔSP. **Goal**: Reproduce the sensitivity curves in Figure 7 and determine if the recommended defaults hold for a new dataset.

## Open Questions the Paper Calls Out

- **Question 1:** Can linear self-attention techniques effectively reduce the quadratic complexity of DegFairGT without sacrificing the model's ability to mitigate degree bias?
  - *Basis in paper:* [explicit] The authors state in the conclusion that a "follow-up study will aim to improve the computational efficiency and time complexity of self-attention mechanisms by leveraging linear self-attention techniques."
  - *Why unresolved:* The current model inherits the standard transformer's quadratic complexity (O(N²)), which is computationally expensive for large graphs, but it is unclear if efficient approximations maintain the specific structural attention required for fairness.
  - *What evidence would resolve it:* A study implementing linear attention in DegFairGT and benchmarking its speed and fairness metrics (ΔSP, ΔEO) against the standard version on large-scale graphs.

- **Question 2:** Does incorporating semantic subgraph-level similarity (e.g., motifs) improve the model's capacity to capture structural roles compared to relying solely on node degree and community membership?
  - *Basis in paper:* [explicit] The conclusion notes that "there exist other forms of structural similarity, such as semantic subgraph-level similarity," and suggests future work should focus on "discovering semantic subgraph-level relationships."
  - *Why unresolved:* The current method focuses on node degree and community, which may miss high-order structural dependencies found in complex substructures.
  - *What evidence would resolve it:* An ablation study or extension of DegFairGT that integrates motif-based features into the structural similarity calculation, showing improved performance on datasets where role identification depends on subgraph patterns.

- **Question 3:** How do graph partitioning or sparse attention strategies impact the preservation of global graph structures within the structural self-attention module?
  - *Basis in paper:* [explicit] The authors mention that "graph partition or sparse attention" are techniques that "could be explored to improve efficiency without compromising performance, which we leave as future work."
  - *Why unresolved:* While these techniques improve speed, they inherently limit the attention range, potentially disrupting the model's ability to capture the global graph structures essential for long-range message passing.
  - *What evidence would resolve it:* Experiments evaluating the node clustering performance (Conductance/Modularity) and global structure preservation of a partitioned/sparse version of DegFairGT versus the full-attention baseline.

## Limitations

- The core claims about fairness gains rely on experiments on 6 relatively small datasets.
- The structural augmentation's effectiveness depends heavily on the quality of the community clustering and k-hop neighborhood computations, which are not validated for noisy or very large graphs.
- The paper acknowledges but does not fully solve scalability issues, as the O(N²) self-attention and k-hop preprocessing can be prohibitive for large graphs.

## Confidence

- **High confidence:** The method's ability to reduce degree bias (ΔSP/ΔEO) is consistently demonstrated across datasets. The ablation studies (Table 8) provide strong evidence for the necessity of the augmentation module and the self-supervised loss.
- **Medium confidence:** The improvements in node classification accuracy and clustering metrics (C, Q) are positive but less dramatic than the fairness gains. These gains could be partially due to the SSL regularization rather than the bias mitigation itself.
- **Low confidence:** The method's performance on large, noisy, or heterophilic graphs is unknown. The sensitivity to the clustering algorithm and the k-hop parameter is noted but not thoroughly explored for graphs outside the tested domain.

## Next Checks

1. **Scalability Test:** Run the model on a graph with 100K+ nodes (e.g., a large Reddit or Amazon co-purchase subset) and report training time and memory usage. Monitor the k-hop neighborhood computation for OOM errors.
2. **Clustering Ablation:** Replace the k-means clustering with a purely connectivity-based method (e.g., spectral clustering) on a test dataset and compare ΔSP/ΔEO and accuracy to the main results.
3. **Parameter Sensitivity:** Perform a grid search over k (e.g., 2, 3, 4, 5) and α (e.g., 0.1, 0.5, 1.0, 2.0) on a single dataset (e.g., Cora) and plot the trade-off curves for fairness vs. accuracy to see if the optimal values generalize.