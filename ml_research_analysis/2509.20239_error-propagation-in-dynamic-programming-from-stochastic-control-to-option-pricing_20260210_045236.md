---
ver: rpa2
title: 'Error Propagation in Dynamic Programming: From Stochastic Control to Option
  Pricing'
arxiv_id: '2509.20239'
source_url: https://arxiv.org/abs/2509.20239
tags:
- control
- error
- optimal
- stochastic
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides theoretical foundations for stochastic optimal
  control in discrete time, focusing on error propagation in dynamic programming.
  The authors propose a kernel-based regression framework that combines Monte Carlo
  sampling with regularized empirical risk minimization (specifically KRR) to approximate
  value functions in reproducing kernel Hilbert spaces.
---

# Error Propagation in Dynamic Programming: From Stochastic Control to Option Pricing

## Quick Facts
- **arXiv ID:** 2509.20239
- **Source URL:** https://arxiv.org/abs/2509.20239
- **Reference count:** 36
- **Primary result:** Provides theoretical foundations for stochastic optimal control with explicit error bounds in discrete time

## Executive Summary
This paper develops a kernel-based regression framework for stochastic optimal control problems, specifically focusing on error propagation in dynamic programming. The authors propose using Kernel Ridge Regression (KRR) within reproducing kernel Hilbert spaces to approximate value functions in a backward induction process. They provide explicit convergence rates by decomposing the total approximation error into regression error, Monte Carlo sampling error, and propagation error, with particular attention to model misspecification through source conditions.

## Method Summary
The method implements a backward induction algorithm where, at each time step t, it generates training targets by applying an empirical Bellman operator to the value function approximation from t+1. These targets are then fitted using KRR in an RKHS. The framework uses Monte Carlo sampling to approximate the Markov transition expectations, making it scalable to high dimensions. The algorithm employs FALKON (a scalable KRR solver) for computational efficiency, with RBF kernels and regularization parameter Œª=10‚Åª‚Å∂. The method is applied to American option pricing, demonstrating competitive performance against benchmark methods while providing theoretical error guarantees.

## Key Results
- Error decomposition shows total approximation error at time t depends on both sample size and propagated error from later stages
- Error recursion becomes contractive when discount factor is strictly positive (r > 0), preventing error explosion
- Theoretical convergence rates are derived under model misspecification using source conditions
- Competitive performance demonstrated on American option pricing tasks in dimensions d ‚àà {2, 5, 10, 20}

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** KRR in RKHS provides controlled error accumulation even under model misspecification
- **Mechanism:** Recursive Bellman equation solution using KRR projection transforms stochastic control into supervised learning tasks
- **Core assumption:** Target function satisfies source condition allowing approximation with rate Œ≤‚Çú
- **Evidence anchors:** [abstract] KRR in RKHSs; [section 3] supervised learning method; [corpus] Universal Approximation Theorem for Deep Q-Learning
- **Break condition:** Incompatible kernel choice or poor regularization tuning causes regression error to dominate

### Mechanism 2
- **Claim:** Empirical Monte Carlo averages enable high-dimensional scaling with probabilistic error bounds
- **Mechanism:** Replaces exact Markov transition expectations with sample means over M‚Çú i.i.d. samples
- **Core assumption:** Function class ùí¢À£·µó has sufficient regularity for empirical mean convergence at O(1/‚àöM‚Çú)
- **Evidence anchors:** [section 3] empirical approximation definition; [section 4] Monte Carlo error bounds using Massart's Lemma
- **Break condition:** High variance processes or insufficient M‚Çú prevent convergence

### Mechanism 3
- **Claim:** Error propagation is contractive with positive discount factor
- **Mechanism:** Total error E‚Çú includes propagation term c‚ÇöE‚Çú‚Çä‚ÇÅ; discount factor ensures c‚Çö < 1
- **Core assumption:** Square integrability holds with c‚Çö < 1 (requires r > 0)
- **Evidence anchors:** [abstract] recursion becomes contractive; [section 4] propagation error bound
- **Break condition:** Lack of discount mechanism or explosive dynamics (c‚Çö ‚â• 1) invalidates error bounds

## Foundational Learning

- **Concept: Reproducing Kernel Hilbert Spaces (RKHS)**
  - **Why needed here:** Required to understand KRR approximation and source condition error bounds
  - **Quick check question:** If kernel k(x,x') is linear, what functions can RKHS represent, and would it approximate kinked American option payoffs well?

- **Concept: Dynamic Programming & The Bellman Equation**
  - **Why needed here:** Structural backbone of backward induction from T to 0
  - **Quick check question:** In American options, what does Bellman operator ùíØ‚Çú represent intuitively at each time step?

- **Concept: Statistical Learning Theory (Rademacher Complexity)**
  - **Why needed here:** Understanding Monte Carlo error bounds requires complexity measures
  - **Quick check question:** Why does bounding complexity of function class ùí¢ matter when just taking Monte Carlo averages?

## Architecture Onboarding

- **Component map:** Data Generator -> Empirical Bellman Estimator -> KRR Solver -> Backward Loop
- **Critical path:** Interaction between Empirical Bellman Estimator and KRR Solver; MC sampling variance affects regression difficulty
- **Design tradeoffs:**
  - Sample sizes: Theorem 1 suggests M‚Çú ~ n‚Çú^(Œ≤‚Çú/(Œ≤‚Çú+1)); increasing n‚Çú improves rate, M‚Çú scales sub-linearly
  - Computational Cost: FALKON used instead of exact KRR (O(n¬≥)) for speed with minor accuracy tradeoff
- **Failure signatures:**
  - Explosive Variance: Insufficient M‚Çú causes KRR to fit noise
  - Non-Contractive Settings: r=0 makes error propagation bounds vacuous
  - Misspecification: Standard RBF kernel on discontinuous payoffs yields low Œ≤‚Çú and slow convergence
- **First 3 experiments:**
  1. Replicate Geometric Basket Put (Table 1) with basic RBF kernel to verify regression error decreases with n‚Çú
  2. Tune M‚Çú vs n‚Çú to find knee where Monte Carlo error becomes negligible; check alignment with scaling relation
  3. Stress test contraction by setting r=0; observe if t=0 approximation becomes unstable

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can advanced quadrature schemes replace Monte Carlo sampling while preserving convergence guarantees?
- **Basis:** [explicit] Conclusion suggests replacing MC with quadrature schemes
- **Why unresolved:** Theoretical bounds differ fundamentally; quadrature error analysis may interact unpredictably with Bellman recursion
- **What evidence would resolve it:** Theoretical bounds on Monte Carlo error using quadrature plus empirical convergence rate comparison

### Open Question 2
- **Question:** Can random projection techniques (Nystr√∂m, random features, sketching) preserve Theorem 1 error bounds?
- **Basis:** [explicit] Conclusion aims to integrate random projections while preserving statistical guarantees
- **Why unresolved:** Random projections add approximation error terms that current three-term decomposition doesn't capture
- **What evidence would resolve it:** Modified error decomposition including projection error with matching convergence rates

### Open Question 3
- **Question:** Does model misspecification (Œ≤‚Çú) improve, degrade, or remain constant through backward recursion?
- **Basis:** [inferred] Page 8 notes supremum in Bellman operator prevents guaranteed smoothing through time
- **Why unresolved:** Max operator introduces kinks while conditional expectation smooths; effects may cancel or compound
- **What evidence would resolve it:** Empirical Œ≤‚Çú estimation at each time step or theoretical characterization of Œ≤‚Çú evolution

### Open Question 4
- **Question:** How do error bounds extend to continuous control spaces U‚Çú ‚äÇ ‚Ñù·µà?
- **Basis:** [inferred] Appendix B.2 discusses continuous control case with different Rademacher complexity bounds
- **Why unresolved:** Supremum over infinite action spaces requires uniform convergence; finite-class analysis doesn't apply
- **What evidence would resolve it:** Modified Theorem 1 with covering number or Lipschitz-based complexity bounds validated on continuous control benchmarks

## Limitations

- **Source Condition Dependence:** Theoretical bounds critically depend on Œ≤‚Çú parameter, but no practical method provided for determining it in real applications
- **Sample Size Scaling:** Empirical results show reasonable performance, but gap between theoretical predictions and observed behavior in high dimensions remains unclear
- **Model Misspecification:** Practical implications not fully explored; experiments only demonstrate standard option pricing tasks where model assumptions approximately hold

## Confidence

- **High Confidence:** Backward induction framework and error decomposition are well-established; American option application follows standard approaches
- **Medium Confidence:** Theoretical convergence rates follow established learning theory, but practical source condition determination needs investigation
- **Low Confidence:** Claims about scalability to high dimensions are primarily computational rather than theoretical; curse of dimensionality in sample complexity not addressed

## Next Checks

1. **Source Condition Sensitivity Analysis:** Systematically vary assumed Œ≤‚Çú in synthetic experiments with known function smoothness to quantify robustness and validate theoretical predictions

2. **High-Dimensional Stress Test:** Extend experiments beyond d=20 to d=50 or d=100 using simplified option structures to identify practical limits and compare against theoretical scaling predictions

3. **Alternative Kernel Comparison:** Replace RBF kernel with polynomial and Mat√©rn kernels on same option pricing tasks to understand kernel sensitivity and identify best-suited kernels for different payoffs