---
ver: rpa2
title: Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in
  RLHF-Aligned Language Models
arxiv_id: '2505.23848'
source_url: https://arxiv.org/abs/2505.23848
tags:
- refusal
- proportion
- token
- think
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a simple, parameter-free method to reduce
  refusal rates in RLHF-aligned language models by suppressing specific token sequences
  during generation. The authors observed that refusals in DeepSeek-R1 distillations
  often followed the token sequence " (followed by "\n\n"), and found that blocking
  "\n\n" after " (and optionally suppressing EOS after " greatly increased substantive
  answers to sensitive prompts without degrading performance on standard benchmarks.
---

# Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in RLHF-Aligned Language Models

## Quick Facts
- arXiv ID: 2505.23848
- Source URL: https://arxiv.org/abs/2505.23848
- Reference count: 11
- Key outcome: Simple parameter-free method reduces refusal rates by suppressing token sequences during generation

## Executive Summary
This paper introduces a novel approach to reducing refusal rates in RLHF-aligned language models by suppressing specific token sequences during generation. The authors observed that refusals in DeepSeek-R1 distillations often followed the token sequence " (followed by "\n\n"), and found that blocking "\n\n" after " (and optionally suppressing EOS after " greatly increased substantive answers to sensitive prompts without degrading performance on standard benchmarks. The method operates by manipulating generation at specific output subspace boundaries rather than through weight modification or training.

## Method Summary
The authors developed a parameter-free intervention that identifies and suppresses token sequences associated with model refusals during text generation. The key insight was recognizing that refusals in DeepSeek-R1 distillations consistently followed the pattern of a space followed by a double quote character, then a newline sequence. By blocking the generation of "\n\n" after " (and optionally suppressing end-of-sequence tokens after ", the method effectively derails the model from producing non-answers. This approach works at the generation level without requiring any model retraining or parameter modification.

## Key Results
- Statistical analysis confirmed significant improvements in answered and relevant coherent responses across multiple model sizes (7B, 14B, 32B, 70B) and datasets
- The method increased substantive answers to sensitive prompts without degrading performance on standard benchmarks
- Results suggest refusal behaviors can be circumvented by manipulating generation at specific output subspace boundaries rather than through weight modification or training

## Why This Works (Mechanism)
The mechanism behind this approach appears to exploit specific generation patterns that lead to refusal behaviors. By identifying and suppressing the token sequence that typically precedes refusals (" followed by "\n\n"), the method prevents the model from entering a refusal state. This works because the suppressed tokens would normally signal the model to transition into a non-answering mode, and by removing this pathway, the model continues generating content instead of refusing.

## Foundational Learning

**RLHF (Reinforcement Learning from Human Feedback)**: Why needed - Understanding the training paradigm that creates aligned models and their refusal behaviors. Quick check - Can identify how human preferences shape model responses and refusal patterns.

**Token sequence patterns**: Why needed - Recognizing how specific token combinations trigger model behaviors. Quick check - Can map input-output relationships at the token level in language models.

**Output subspace boundaries**: Why needed - Understanding how models transition between different response modes. Quick check - Can identify boundary conditions where model behavior changes.

## Architecture Onboarding

**Component map**: Input prompt -> Token generation sequence -> Output subspace boundary detection -> Token suppression logic -> Modified token generation -> Final response

**Critical path**: The critical path involves detecting the specific token pattern (" followed by "\n\n") during generation and suppressing the "\n\n" token before it triggers a refusal state.

**Design tradeoffs**: The method trades off the ability to generate certain legitimate text patterns (like quoted text ending with newlines) for the benefit of reducing refusals. It's parameter-free but requires pattern-specific implementation.

**Failure signatures**: The method may fail if refusal patterns change or if the suppressed token sequence appears in legitimate contexts where newlines are actually desired after quotes.

**First experiments**: 1) Test the method on a small dataset of sensitive prompts to verify refusal reduction, 2) Measure impact on benchmark performance to ensure no degradation, 3) Validate that legitimate text generation with quotes and newlines remains functional.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's reliance on a single observed token pattern (" (followed by "\n\n") may not generalize to other refusal patterns across different model architectures or training regimes
- The study's focus on DeepSeek-R1 distillations means effectiveness for other RLHF-aligned models remains unverified
- The analysis does not address potential degradation in reasoning capabilities or logical consistency when the method is applied

## Confidence

High: The statistical improvements in answered and relevant coherent responses are well-supported by experimental results across multiple model sizes and datasets. The observation that the " (token sequence predicts refusals is consistently replicated.

Medium: The claim that this method reduces refusals "without degrading performance on standard benchmarks" is based on benchmark evaluations, but the depth and scope of these benchmarks are not fully detailed. The assertion that refusal behaviors can be "circumvented by manipulating generation at specific output subspace boundaries" is plausible but lacks a theoretical framework explaining the mechanism.

Low: The broader implication that this approach represents a general solution for refusal reduction in RLHF-aligned models is overstated, given the narrow scope of tested patterns and models. The claim that this is a "simple, parameter-free method" may be misleading if the pattern detection and suppression require complex implementation or tuning in practice.

## Next Checks

1. Validate the method's effectiveness on non-DeepSeek RLHF-aligned models (e.g., Llama-2-Chat, GPT-4, Claude) to test generalizability across architectures and training approaches.

2. Conduct a formal analysis of logical consistency and reasoning quality in responses generated with the method applied, using tasks that require multi-step reasoning or complex inference.

3. Test whether the method inadvertently increases the generation of harmful or unsafe content by removing refusal mechanisms, using established safety benchmarks and adversarial prompts.