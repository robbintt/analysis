---
ver: rpa2
title: 'MetaCLBench: Meta Continual Learning Benchmark on Resource-Constrained Edge
  Devices'
arxiv_id: '2504.00174'
source_url: https://arxiv.org/abs/2504.00174
tags:
- learning
- accuracy
- methods
- anml
- meta-cl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MetaCLBench, a comprehensive benchmark framework
  designed to evaluate Meta-Continual Learning (Meta-CL) methods on resource-constrained
  edge devices. The framework assesses six representative Meta-CL methods across three
  network architectures (CNN, YAMNet, ViT) and five datasets spanning image and audio
  modalities, measuring not only accuracy but also deployment-critical metrics including
  memory footprint, latency, and energy consumption on devices ranging from 512 MB
  to 4 GB RAM.
---

# MetaCLBench: Meta Continual Learning Benchmark on Resource-Constrained Edge Devices

## Quick Facts
- arXiv ID: 2504.00174
- Source URL: https://arxiv.org/abs/2504.00174
- Reference count: 40
- Primary result: Comprehensive benchmark framework evaluating Meta-CL methods on resource-constrained edge devices

## Executive Summary
This paper introduces MetaCLBench, a comprehensive benchmark framework designed to evaluate Meta-Continual Learning (Meta-CL) methods on resource-constrained edge devices. The framework assesses six representative Meta-CL methods across three network architectures (CNN, YAMNet, ViT) and five datasets spanning image and audio modalities, measuring not only accuracy but also deployment-critical metrics including memory footprint, latency, and energy consumption on devices ranging from 512 MB to 4 GB RAM. The study reveals that while many Meta-CL methods can learn new classes effectively for both image and audio modalities, they impose significant computational and memory costs on edge devices, with up to three methods causing out-of-memory failures on sub-1 GB devices. The research demonstrates that LifeLearner achieves near-oracle accuracy while consuming 2.54-7.43× less energy than the Oracle method, and that larger or more sophisticated architectures like ViT and YAMNet do not necessarily yield better Meta-CL performance, challenging conventional assumptions about model complexity.

## Method Summary
MetaCLBench evaluates Meta-Continual Learning methods by testing six representative approaches across three network architectures (CNN, YAMNet, ViT) and five datasets spanning image and audio modalities. The framework measures accuracy alongside deployment-critical metrics including memory footprint, latency, and energy consumption on edge devices ranging from 512 MB to 4 GB RAM. The evaluation process involves systematically assessing each Meta-CL method's performance as new classes are introduced, tracking both learning effectiveness and resource utilization throughout the continual learning process. The benchmark provides practical deployment guidelines by revealing which methods can successfully operate within the memory constraints of typical edge devices while maintaining acceptable accuracy levels.

## Key Results
- LifeLearner achieves near-oracle accuracy while consuming 2.54-7.43× less energy than the Oracle method
- Up to three Meta-CL methods cause out-of-memory failures on sub-1 GB devices
- Larger or more sophisticated architectures like ViT and YAMNet do not necessarily yield better Meta-CL performance

## Why This Works (Mechanism)
MetaCLBench works by systematically evaluating the trade-offs between learning effectiveness and resource consumption in Meta-Continual Learning on edge devices. The benchmark framework captures the fundamental challenge that Meta-CL methods, while effective at learning new classes, often require substantial memory and computational resources that exceed the constraints of resource-limited edge devices. By measuring both accuracy and deployment metrics across multiple hardware configurations, the framework reveals that simpler architectures like CNN can outperform more complex ones like ViT and YAMNet in Meta-CL scenarios, despite the conventional wisdom that larger models are more capable. The success of LifeLearner in achieving high accuracy with lower energy consumption demonstrates that carefully designed Meta-CL algorithms can effectively balance learning performance with resource efficiency.

## Foundational Learning
- **Meta-Continual Learning**: Why needed - Enables models to learn new classes continuously without forgetting previous knowledge. Quick check - Does the method maintain accuracy across sequential learning tasks?
- **Edge Device Constraints**: Why needed - Real-world deployment requires models to operate within strict memory and power limits. Quick check - Can the method run without out-of-memory errors on devices under 1 GB RAM?
- **Resource-Aware Evaluation**: Why needed - Traditional accuracy metrics don't capture deployment viability. Quick check - Does the method measure latency, energy, and memory alongside accuracy?
- **Cross-Modal Learning**: Why needed - Real applications often involve multiple data types. Quick check - Does the method work effectively on both image and audio datasets?
- **Architecture-Algorithm Interaction**: Why needed - Model architecture significantly impacts Meta-CL performance. Quick check - Do different architectures yield different Meta-CL effectiveness for the same method?

## Architecture Onboarding
- **Component Map**: Edge Device (512 MB-4 GB RAM) -> Meta-CL Method (6 variants) -> Network Architecture (CNN, YAMNet, ViT) -> Dataset (5 cross-modal datasets) -> Metrics (Accuracy, Memory, Latency, Energy)
- **Critical Path**: The critical path involves the interaction between the Meta-CL algorithm's memory requirements and the edge device's available RAM, which determines whether the method can successfully execute without out-of-memory failures while maintaining acceptable accuracy.
- **Design Tradeoffs**: Simpler architectures (CNN) vs. complex architectures (ViT/YAMNet) - simpler models consume fewer resources but may have lower baseline accuracy; Meta-CL methods must balance learning new classes with memory constraints; evaluation must include both learning effectiveness and deployment metrics.
- **Failure Signatures**: Out-of-memory errors on sub-1 GB devices for up to three methods; poor accuracy retention across sequential learning tasks; excessive latency or energy consumption making real-time deployment impractical.
- **First Experiments**: 1) Test each Meta-CL method with CNN architecture on 512 MB device to identify baseline memory limitations; 2) Compare energy consumption of LifeLearner vs Oracle method across all architectures; 3) Evaluate accuracy degradation when scaling from 512 MB to 4 GB RAM devices.

## Open Questions the Paper Calls Out
None

## Limitations
- Benchmark focuses on a relatively small set of six Meta-CL methods and three network architectures
- Evaluation constrained to specific hardware configurations (512 MB to 4 GB RAM devices)
- Limited exploration of trade-offs between different types of memory optimizations

## Confidence
- **High Confidence**: Meta-CL methods impose significant computational and memory costs on edge devices; LifeLearner achieves near-oracle accuracy with reduced energy consumption
- **Medium Confidence**: Larger architectures like ViT and YAMNet don't necessarily yield better Meta-CL performance
- **Low Confidence**: Benchmark framework will enable fair evaluation across accuracy and system-level metrics

## Next Checks
1. Conduct comprehensive ablation studies to isolate impact of specific architectural components on Meta-CL performance and resource consumption
2. Extend benchmark to include wider range of Meta-CL methods, particularly those focused on memory efficiency
3. Test framework on more diverse set of edge devices with varying computational capabilities and memory constraints