---
ver: rpa2
title: 'MechDetect: Detecting Data-Dependent Errors'
arxiv_id: '2512.04138'
source_url: https://arxiv.org/abs/2512.04138
tags:
- data
- error
- errors
- missing
- mcar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MechDetect is a machine learning-based algorithm that infers error
  generation mechanisms (MCAR, MAR, or MNAR) in tabular data. Given a dataset and
  corresponding error mask, the algorithm performs two statistical tests comparing
  classifier performances under different training setups to determine whether errors
  depend on the data and whether they depend on values in the target column.
---

# MechDetect: Detecting Data-Dependent Errors

## Quick Facts
- arXiv ID: 2512.04138
- Source URL: https://arxiv.org/abs/2512.04138
- Authors: Philipp Jung; Nicholas Chandler; Sebastian Jäger; Felix Biessmann
- Reference count: 36
- Primary result: ML-based algorithm detecting MCAR/MAR/MNAR error mechanisms with 89.14% mean accuracy across 101 datasets

## Executive Summary
MechDetect is a machine learning algorithm that identifies whether data errors follow Missing Completely at Random (MCAR), Missing at Random (MAR), or Missing Not at Random (MNAR) patterns. The algorithm uses classifier performance comparisons under different training setups to determine error dependency on both feature values and target variables. Tested on 101 real-world datasets with synthetic missing value errors, MechDetect achieved high accuracy across varying error rates while maintaining robustness to dataset characteristics.

## Method Summary
MechDetect performs two statistical tests comparing classifier performances to detect error generation mechanisms. First, it compares performance between using original features versus masked error indicators to determine if errors depend on data values. Second, it compares performance between training on complete data versus training with injected errors to assess target dependency. The algorithm leverages supervised learning classifiers and statistical hypothesis testing to classify error patterns as MCAR, MAR, or MNAR based on performance differences.

## Key Results
- Achieved 89.14% mean accuracy across 101 real-world datasets with synthetic missing value errors
- Perfect median accuracy for MAR detection, ~95% for MCAR, and ~86% for MNAR
- Performance remained above 89% across error rates from 0.1 to 0.9
- Robust to varying dataset characteristics while maintaining high detection accuracy

## Why This Works (Mechanism)
The algorithm exploits the fundamental difference in predictability between error types. MCAR errors are independent of data and target, making them unpredictable from features. MAR errors depend on observed data but not the target, creating predictable patterns from features but not improving target prediction. MNAR errors depend on the target value itself, making them predictable from both features and target information. By comparing classifier performance under different training conditions, MechDetect isolates these distinct patterns of dependency.

## Foundational Learning

### Supervised Classification
Why needed: Forms the core predictive component for detecting error patterns
Quick check: Verify classifier can distinguish between clean and error-affected samples

### Statistical Hypothesis Testing
Why needed: Provides formal framework for comparing classifier performance differences
Quick check: Confirm test statistics follow expected distributions under null hypotheses

### Missing Data Mechanisms (MCAR/MAR/MNAR)
Why needed: Defines the theoretical foundation for error pattern classification
Quick check: Validate that synthetic errors follow intended generation mechanisms

## Architecture Onboarding

### Component Map
Data -> Error Mask Generation -> Classifier Training (Setup 1) -> Performance Measurement -> Statistical Test 1
Data -> Error Mask Generation -> Classifier Training (Setup 2) -> Performance Measurement -> Statistical Test 2
Test Results -> Mechanism Classification

### Critical Path
Error mask generation → dual classifier training setups → performance comparison → statistical testing → mechanism classification

### Design Tradeoffs
Accuracy vs. computational cost: Multiple classifier trainings increase runtime but improve detection reliability
Synthetic vs. real errors: Synthetic errors ensure controlled evaluation but may not capture all real-world patterns

### Failure Signatures
Low accuracy across all mechanisms suggests classifier capacity issues or feature-target dependency violations
Conflicting test results indicate complex error patterns beyond simple MCAR/MAR/MNAR classifications

### First Experiments
1. Verify classifier performance differences exceed statistical significance thresholds
2. Test algorithm sensitivity to varying error rates and dataset sizes
3. Validate mechanism classification accuracy on datasets with known error patterns

## Open Questions the Paper Calls Out
None

## Limitations
- Requires ground truth error masks, limiting applicability to scenarios without error annotations
- Performance may vary on datasets with complex or highly correlated features
- Synthetic error patterns may not fully represent real-world error distributions
- Feature independence assumption in statistical tests could introduce bias when violated

## Confidence

### Accuracy Claims
- High confidence in MCAR and MAR detection (95% and perfect median accuracy)
- Medium confidence in MNAR detection (86% accuracy) and generalizability to non-missing-value errors
- Medium confidence in robustness across varying error rates and dataset characteristics

## Next Checks

1. Evaluate MechDetect on real-world error datasets with known ground truth error masks to assess performance on non-synthetic error patterns
2. Test the algorithm on datasets with high feature correlation to examine sensitivity to the feature independence assumption
3. Conduct ablation studies to determine the impact of different classifier choices and statistical test parameters on detection accuracy