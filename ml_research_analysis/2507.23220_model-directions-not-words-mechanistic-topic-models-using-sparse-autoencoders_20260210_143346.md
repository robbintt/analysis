---
ver: rpa2
title: 'Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders'
arxiv_id: '2507.23220'
source_url: https://arxiv.org/abs/2507.23220
tags:
- topic
- topics
- features
- feature
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Mechanistic Topic Models (MTMs), which apply
  topic modeling to interpretable features from sparse autoencoders (SAEs) rather
  than traditional bag-of-words representations. By leveraging SAE features that capture
  abstract semantic concepts, MTMs can discover richer topics and generate more expressive
  descriptions.
---

# Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders

## Quick Facts
- **arXiv ID**: 2507.23220
- **Source URL**: https://arxiv.org/abs/2507.23220
- **Reference count**: 40
- **One-line primary result**: Mechanistic Topic Models (MTMs) using sparse autoencoder features match or exceed traditional topic models on coherence and enable controllable text generation via steering vectors.

## Executive Summary
This paper introduces Mechanistic Topic Models (MTMs), which apply topic modeling to interpretable features from sparse autoencoders (SAEs) rather than traditional bag-of-words representations. By leveraging SAE features that capture abstract semantic concepts, MTMs can discover richer topics and generate more expressive descriptions. The authors propose three MTM variants: mLDA (adapting LDA), mETM (extending ETM with SAE features), and mBERTopic (using SAE features for clustering). To evaluate MTMs fairly against word-based models, they introduce topic judge, an LLM-based pairwise comparison framework that assesses which model's topics better capture document content. Across five datasets, MTMs achieve strong performance, matching or exceeding traditional and neural baselines on coherence metrics, and are consistently preferred by topic judge. Additionally, MTMs uniquely enable controllable text generation through topic-based steering vectors, allowing users to bias LLM outputs toward specific themes while maintaining generation quality.

## Method Summary
The method applies three topic modeling variants (mLDA, mETM, mBERTopic) to SAE feature counts rather than word counts. SAE activations are thresholded at the 80th percentile per feature to produce interpretable counts, then filtered to remove spurious features (programming/math/grammar terms, high-frequency features). The topic models learn distributions over SAE features instead of words. For controllable generation, topic-feature weights are converted to steering vectors by normalizing the weighted sum of feature directions. Steering intervenes on the parallel component of activations during generation. The framework includes topic judge, an LLM-based pairwise evaluation using Bradley-Terry/Elo ratings to compare models fairly despite different feature spaces.

## Key Results
- MTMs match or exceed traditional topic models (LDA, ETM, BERTopic) and neural baselines on coherence metrics across five datasets
- Topic judge shows MTMs are consistently preferred by LLM evaluators for topic-document alignment
- MTMs enable controllable text generation via steering vectors, with topic relevance win rates exceeding 85% while maintaining near-baseline perplexity at low steering strengths
- Steering effectiveness varies by model type, with mLDA and mETM showing more consistent positive topic shifts than mBERTopic

## Why This Works (Mechanism)

### Mechanism 1: SAE Features Capture Semantically Abstract Concepts Beyond Word Co-occurrence
- Claim: SAE features extracted from LLM activations encode contextual and semantic nuances that bag-of-words representations miss.
- Mechanism: LLMs encode high-level features as approximately linear directions in activation space (Linear Representation Hypothesis). SAEs trained to reconstruct these activations with sparsity constraints learn decoder columns that correspond to interpretable features (e.g., style, tone, discourse patterns). These features activate based on semantic content rather than mere word presence.
- Core assumption: A sufficiently large subset of semantically meaningful features obeys the linear representation hypothesis and is recoverable via SAE training.
- Evidence anchors: Section 3 explains the linear representation hypothesis; Section 4.1 states SAE features capture contextual and semantic concepts; related work shows SAE objectives can be derived from LDA extensions.

### Mechanism 2: Thresholded Feature Counts Enable Valid Topic Modeling
- Claim: Continuous SAE activations can be converted to interpretable count distributions suitable for probabilistic topic models.
- Mechanism: For each feature i, count how often its activation exceeds a feature-specific threshold (80th percentile of its training distribution). This produces sparse count vectors per document, analogous to word counts, that can be fed into LDA, ETM, or clustering-based topic models.
- Core assumption: Thresholding at the 80th percentile retains semantically meaningful activations while filtering noise.
- Evidence anchors: Section 4.1, Eq 5 shows the thresholding formula; Section 4.1 states this produces interpretable counts.

### Mechanism 3: Topic-Feature Weights Construct Effective Steering Vectors
- Claim: Topic-feature distributions learned by MTMs can be converted to steering vectors that bias LLM generation toward specific topics.
- Mechanism: For topic k, construct unit steering vector sk by normalizing the weighted sum of SAE feature directions. During generation, replace the activation component parallel to sk with a scaled version.
- Core assumption: Topic-feature weights βk meaningfully characterize topic expression, and intervening on the parallel component suffices for control.
- Evidence anchors: Section 4.3, Eq 16-19 shows steering vector construction; Section 5.4 reports topic relevance win rates exceeding 85% with acceptable perplexity degradation at higher strengths.

## Foundational Learning

- **Sparse Autoencoders (SAEs)**: Why needed: SAEs are the featurization backbone. Without understanding how SAEs learn sparse, interpretable directions from LLM activations, the entire MTM pipeline is opaque. Quick check: Given an LLM activation a ∈ R^H, explain how an SAE produces sparse feature activations α(a) and what the decoder columns represent.

- **Latent Dirichlet Allocation (LDA)**: Why needed: mLDA directly adapts LDA by replacing word counts with SAE feature counts. Understanding Dirichlet priors and posterior inference is essential. Quick check: In LDA, what do θ_d and β_k represent, and how does mLDA modify these?

- **Activation Steering / Intervention**: Why needed: MTMs uniquely enable controllable generation via steering vectors derived from topic-feature weights. Quick check: If a = Σ_i α_i·w_i + b and you add steering vector s = Σ_i δ_i·w_i, what happens to feature expression? How does the paper's ablation-then-addition approach differ from direct addition?

## Architecture Onboarding

- **Component map**: SAE Feature Extraction -> Preprocessing (thresholding + filtering) -> Topic Model Core (mLDA/mETM/mBERTopic) -> Topic Interpretation (top features + summarization) -> Steering Vector Construction

- **Critical path**: SAE selection (layer + width) -> Feature filtering -> Thresholding -> Topic model training -> Evaluation (topic judge + coherence metrics)

- **Design tradeoffs**: SAE layer choice (earlier layers capture localized features; later layers capture higher-level themes), feature filtering vs. retention (aggressive filtering reduces noise but may discard rare-but-meaningful features), summarization vs. raw features (summarization improves topic judge performance on abstract datasets but adds cost and potential information loss)

- **Failure signatures**: High perplexity at moderate λ indicates steering vector is not well-calibrated to topic semantics; low topic diversity (TD < 0.5) suggests homogeneous feature counts; spurious features persist despite filtering

- **First 3 experiments**:
  1. Validate SAE feature quality on your corpus: Sample 50 documents, extract top-activating features per document, manually assess whether feature descriptions match document content
  2. Compare mLDA vs. LDA on a held-out subset: Run both on 1000 documents; use topic judge (or manual review) to compare topic-document alignment
  3. Test steering controllability: For a discovered topic, generate 10 samples at λ ∈ {0, 10, 20, 30} and measure topic relevance via LLM judge; plot relevance vs. perplexity tradeoff

## Open Questions the Paper Calls Out

- **Open Question 1**: Why does mBERTopic show inconsistent steering behavior (positive ∆ℓ shifts) compared to mLDA and mETM, which consistently increase on-topic document likelihood with steering strength? The authors hypothesize the TF-IDF weighting may be responsible but do not test this mechanism.

- **Open Question 2**: What principles should guide SAE layer selection for topic modeling on different corpus types? The authors note layer selection was made heuristically based on qualitative observations about feature coverage, not through principled comparison.

- **Open Question 3**: How sensitive are MTM results to the 80th-percentile thresholding strategy for SAE feature count discretization? The thresholding approach is presented without justification or sensitivity analysis.

- **Open Question 4**: Can the topic judge framework's reliance on LLM evaluators be validated against human preferences? The authors assume the LLM judge is a good assessor of relative topic quality but do not include human evaluation in their study.

## Limitations

- The evaluation framework relies on LLM-based topic judge, which may systematically prefer abstract SAE features over concrete words for certain domains
- The 80th percentile threshold for binarizing activations is heuristic and not validated across different SAE architectures or datasets
- Feature filtering rules (programming/math/grammar terms, >1% of SAE training data, >90% of corpus) may not perfectly balance noise reduction and signal retention

## Confidence

- **High Confidence**: SAE features can be thresholded to produce interpretable counts; steering vector construction and its basic controllability are well-validated; topic judge framework is methodologically sound with proper statistical controls
- **Medium Confidence**: SAE features capture semantically abstract concepts beyond word co-occurrence; MTMs "match or exceed" traditional baselines; MTMs uniquely enable controllable generation
- **Low Confidence**: The specific choice of 80th percentile threshold is optimal; filtering rules perfectly balance noise reduction and signal retention; topic judge results would be identical with human evaluators

## Next Checks

1. **SAE Feature Quality Validation**: Extract SAE features from 100 randomly sampled documents from your target corpus. For each document, manually review the top-5 activating features and assess whether their descriptions (from Neuronpedia metadata) align with the document content. Compute the fraction where descriptions match content.

2. **Cross-Domain Topic Judge Robustness**: Run topic judge on a held-out subset of your data using two different LLM judges (GPT-4o-mini and Claude 3.5 Sonnet). Compare Elo ratings and win rates. Calculate Cohen's kappa to measure inter-judge agreement. If kappa < 0.6, investigate domain-specific prompt engineering needs.

3. **Steering Tradeoff Analysis**: For your most interpretable topic, generate 50 samples at steering strengths λ ∈ {0, 10, 20, 30, 40, 50}. Measure (a) topic relevance via topic judge, (b) perplexity, and (c) semantic drift using a pre-trained sentence embedding distance metric. Plot the three-way tradeoff to identify the optimal operating point for your use case.