---
ver: rpa2
title: 'Subtract the Corruption: Training-Data-Free Corrective Machine Unlearning
  using Task Arithmetic'
arxiv_id: '2511.18660'
source_url: https://arxiv.org/abs/2511.18660
tags:
- proxy
- corruption
- training
- task
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses corrective machine unlearning (CMU) in a source-free
  setting, where original training data is unavailable and only a proxy dataset of
  corrupted samples is accessible. Existing CMU methods typically rely on identified
  corrupted training samples, making them ineffective or inapplicable here.
---

# Subtract the Corruption: Training-Data-Free Corrective Machine Unlearning using Task Arithmetic

## Quick Facts
- arXiv ID: 2511.18660
- Source URL: https://arxiv.org/abs/2511.18660
- Reference count: 40
- Primary result: CUTS removes label noise and backdoor triggers without original training data, outperforming specialized CMU methods

## Executive Summary
This paper addresses corrective machine unlearning in a source-free setting where original training data is unavailable and only a small proxy dataset of corrupted samples can be used. The authors propose CUTS (Corrective Unlearning in Task Space), a lightweight post-training method that treats clean and corruption signals as distinct tasks and removes corruption by subtracting a calibrated corruption task vector from the corrupted model's weights. Unlike existing CMU methods that require identified corrupted training samples, CUTS works effectively with only proxy data, recovering large fractions of lost utility under label noise and nearly eliminating backdoor attacks with minimal performance damage.

## Method Summary
CUTS treats clean and corruption signals as distinct tasks in the model's weight space. Given a corrupted model θ_mix trained on poisoned/noisy data, the method fine-tunes this model on a small proxy dataset D_proxy (2% of training split held out before corruption and then corrupted) to obtain θ_proxy. The corruption task vector τ_p = θ_proxy - θ_mix captures the corruption signal. An optimal scaling factor α* is found via grid search that maximizes a utility objective (kNN self-agreement with coverage penalty for label noise, or minimizes attack success rate for poison). The corrected model is then obtained as θ_u = θ_mix - α*·τ_p. The method excludes BatchNorm parameters from task vectors for ResNets to maintain stability.

## Key Results
- Recovers 75-90% of utility under symmetric/asymmetric label noise (η∈{10%,20%,40%,60%,80%}) across multiple architectures
- Eliminates 95-100% of backdoor attack success rates (η∈{2%,10%,20%}) with minimal utility loss
- Outperforms specialized CMU methods in source-free setting while being architecture-agnostic
- Works across CIFAR10/100, MNIST, and Clothing1M with ResNets, CLIP, and ViTs

## Why This Works (Mechanism)
The core insight is that corruption (label noise or backdoor triggers) and clean learning represent distinct tasks that manifest as separable directions in the model's weight space. By fine-tuning the corrupted model on a small proxy set of corrupted samples, CUTS isolates the corruption task vector. Subtracting a calibrated multiple of this vector effectively "undoes" the corruption without requiring access to clean data. The proxy set, held out before corruption, provides a consistent corruption signal for isolation while being too small to memorize, making it suitable for task vector estimation.

## Foundational Learning

**Task Arithmetic**: The mathematical framework for composing and decomposing tasks in neural network weight space by linear operations. Why needed: Enables CUTS to isolate and remove corruption as a distinct task. Quick check: Verify that θ_proxy - θ_mix produces a meaningful task vector by testing if adding it to clean models induces corruption.

**kNN Self-Agreement**: A proxy metric measuring consistency between a model's predictions and k-nearest neighbors in feature space. Why needed: Provides a proxy for utility maximization when clean validation data is unavailable. Quick check: Compute SA(α) on proxy features and verify it correlates with downstream accuracy.

**Coverage Penalty**: A regularization term ensuring sufficient cluster representation in the kNN metric. Why needed: Prevents degenerate solutions where SA is maximized by focusing on easily classified samples. Quick check: Verify that clusters with fewer than k+1 samples are excluded from SA computation.

## Architecture Onboarding

**Component Map**: Training data (withheld 2% proxy) -> Corrupted model training -> Proxy fine-tuning -> Task vector computation -> α* grid search -> Weight subtraction -> Corrected model

**Critical Path**: The essential sequence is: (1) corrupt training and obtain θ_mix, (2) hold out and corrupt proxy, (3) fine-tune proxy to get θ_proxy, (4) compute τ_p, (5) search α*, (6) apply subtraction. Any deviation from this path breaks the source-free assumption.

**Design Tradeoffs**: Fixed iteration fine-tuning vs. accuracy-based stopping provides reproducibility but may under/over-shoot the corruption signal. Including vs. excluding BatchNorm parameters affects stability but the paper shows exclusion is necessary for ResNets.

**Failure Signatures**: Including BatchNorm parameters in τ_p causes activation instability and performance collapse. Insufficient proxy fine-tuning iterations result in weak corruption signal estimation. Using validation data instead of proxy for α* selection violates source-free constraint.

**First Experiments**:
1. Train θ_mix to near 100% accuracy on corrupted CIFAR10 (40% symmetric noise), hold out 2% proxy, and verify corruption manifests in validation accuracy.
2. Fine-tune θ_mix on corrupted proxy for 800 iterations (lr=1e-5) and compute τ_p, checking that adding it to clean model induces corruption.
3. Compute kNN self-agreement on proxy features across α values to verify the utility objective has a clear optimum.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends on careful hyperparameter selection (α* via grid search) which may not generalize well across diverse corruption scenarios
- Proxy fine-tuning stopping criterion is ambiguous, with main text suggesting accuracy-based stopping while experiments use fixed iterations
- Architecture-specific handling (BatchNorm exclusion) suggests limited generalizability beyond tested architectures

## Confidence
- **High confidence**: Core mathematical formulation of task arithmetic subtraction is sound and empirical methodology is reproducible
- **Medium confidence**: Relative performance comparisons between CUTS and specialized CMU methods are valid
- **Medium confidence**: Claims about working across multiple architectures are supported but show architecture-specific limitations

## Next Checks
1. Reproduce proxy fine-tuning experiments using both fixed iteration counts and accuracy-based stopping criteria to verify which yields results matching reported performance
2. Implement and validate the exact coverage penalty computation by comparing cluster representation metrics against described threshold
3. Test CUTS on a held-out corruption scenario (different trigger patterns or noise types) to assess robustness beyond reported experimental conditions