---
ver: rpa2
title: Better Pseudo-labeling with Multi-ASR Fusion and Error Correction by SpeechLLM
arxiv_id: '2506.11089'
source_url: https://arxiv.org/abs/2506.11089
tags:
- data
- speech
- textual
- training
- multi-asr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a unified framework for improving automatic
  speech recognition (ASR) by leveraging multiple ASR models combined with postprocessing
  via either textual or speech-based large language models (LLMs). Traditional ensemble
  methods rely on complex voting or rule-based systems that can propagate errors and
  lack joint optimization.
---

# Better Pseudo-labeling with Multi-ASR Fusion and Error Correction by SpeechLLM

## Quick Facts
- arXiv ID: 2506.11089
- Source URL: https://arxiv.org/abs/2506.11089
- Reference count: 0
- One-line primary result: Multi-ASR ensemble combined with speechLLM-based postprocessing achieves WER as low as 3.22% on clean test sets and produces pseudo-labels that train ASR models to exceed human transcription accuracy

## Executive Summary
This paper introduces a unified framework for improving automatic speech recognition (ASR) by leveraging multiple ASR models combined with postprocessing via either textual or speech-based large language models (LLMs). Traditional ensemble methods rely on complex voting or rule-based systems that can propagate errors and lack joint optimization. The proposed approach replaces these with a prompt-driven architecture that uses the confusion sets from multiple ASR outputs, refined by either a textual LLM or a multimodal speechLLM. The speechLLM approach incorporates both the textual hypotheses and acoustic information from the original audio, enabling better disambiguation. Experiments on diverse datasets show that multi-ASR ensemble achieves competitive results, while textual LLM postprocessing significantly improves accuracy, and speechLLM further enhances performance by effectively combining speech and text. ASR models trained on pseudo-labels from the speechLLM approach match or exceed the accuracy of models trained on human transcriptions, demonstrating the effectiveness of this unified, end-to-end approach for semi-supervised ASR training.

## Method Summary
The method combines three diverse ASR models (Icefall, Nemo Parakeet, Whisper) to generate parallel hypotheses, then uses text alignment to identify disagreement regions marked as confusion sets. These confusion networks are processed by either a textual LLM (Llama-3.2-1B) or a multimodal speechLLM (Qwen2-Audio) that has been fine-tuned on 27K instruction-tuning samples from DefinedAI. The speechLLM architecture combines a speech encoder with a lightweight adapter that maps audio embeddings to the LLM's representation space. The system filters utterances with exact ASR matches (CER=0) to avoid unnecessary processing, then uses the fine-tuned LLM to resolve confusion sets by weighing alternatives and selecting correct transcriptions. This approach enables end-to-end error correction without manually engineered rules or pipeline modules.

## Key Results
- Multi-ASR ensemble with textual LLM achieves 3.40% WER on test-clean and 8.68% WER on test-other
- SpeechLLM further improves performance to 3.22% WER on test-clean and 8.34% WER on test-other
- ASR models trained on speechLLM pseudo-labels achieve lower WER (8.0-8.7%) than models trained on human ground truth (8.2-9.0%) on DefinedAI domains
- Improvement is greater for DefinedAI datasets due to domain alignment with fine-tuning data, but improvements are also observed on other domains showing robustness
- The approach effectively combines complementary ASR outputs and leverages LLM language knowledge for end-to-end error correction

## Why This Works (Mechanism)

### Mechanism 1
Confusion networks derived from multiple ASR models provide structured uncertainty information that LLMs can resolve more effectively than voting-based arbitration. Three diverse ASR models generate parallel hypotheses, and text alignment identifies disagreement regions marked as confusion sets. Fine-tuned LLM learns to weigh alternatives and select correct transcriptions using language knowledge and context, replacing hand-crafted rules. Core assumption: each ASR model brings unique perspectives to transcription generation, implying complementary error patterns across models.

### Mechanism 2
Incorporating original audio alongside textual confusion networks enables speechLLM to disambiguate using acoustic evidence unavailable to text-only systems. SpeechLLM architecture combines speech encoder + lightweight adapter + textual LLM. The adapter maps audio embeddings to LLM representation space. During training, triplets (audio waveform, confusion set instruction, ground truth) teach the model to attend to acoustic cues when resolving textual disagreements. Joint fine-tuning aligns modalities. Core assumption: acoustic information contains disambiguating signal for cases where text-only context is insufficient.

### Mechanism 3
Domain-aligned fine-tuning data enables LLM correctors to learn domain-specific error patterns and vocabulary, improving generalization within that domain. 27K instruction-tuning samples from DefinedAI (banking, insurance, retail, telco) teach the LLM domain-specific corrections. The paper notes greater improvements on DefinedAI datasets "due to the domain alignment with the fine-tuning data." Same model architecture generalizes to other domains but with reduced gains. Core assumption: error patterns and vocabulary are partially domain-specific, and LLMs can internalize these patterns from limited task-specific supervision.

## Foundational Learning

- **Concept: Confusion Networks (Word/Token Alignment)**
  - Why needed here: Core data structure for representing ASR disagreement. Understanding how alignment marks uncertainty regions is essential for constructing LLM prompts.
  - Quick check question: Given two hypotheses "the cat sat" and "the bat sat," what would the confusion network representation look like?

- **Concept: Parameter-Efficient Fine-Tuning (LoRA/QLoRA)**
  - Why needed here: Paper uses QLoRA with rank 32 for both text and speech LLMs. Must understand how adapter layers enable fine-tuning without full model updates.
  - Quick check question: Why might QLoRA (4-bit quantization) be preferred over full fine-tuning for a 1B parameter LLM on 27K samples?

- **Concept: WER vs. CER as Alignment Metrics**
  - Why needed here: CER determines which utterances need second-pass decoding; WER evaluates final quality. Understanding when each metric applies is critical for pipeline debugging.
  - Quick check question: When comparing ASR outputs for alignment, why might CER be preferred over WER for identifying near-matches?

## Architecture Onboarding

- **Component map**: Raw audio waveform → 3 parallel ASR decodings (first-pass) → CER filtering → Icefall second-pass (LM-guided beam search, n=200) → Text alignment generates confusion networks → Confusion networks + (optional) audio → fine-tuned LLM → LLM outputs corrected pseudo-labels → Pseudo-labels used for semi-supervised ASR training

- **Critical path**: 1. Audio → 3 parallel ASR decodings (first-pass); 2. CER filtering: exact matches bypass correction; 3. Mismatched