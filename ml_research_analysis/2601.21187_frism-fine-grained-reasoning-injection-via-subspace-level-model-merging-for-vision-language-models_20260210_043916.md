---
ver: rpa2
title: 'FRISM: Fine-Grained Reasoning Injection via Subspace-Level Model Merging for
  Vision-Language Models'
arxiv_id: '2601.21187'
source_url: https://arxiv.org/abs/2601.21187
tags:
- reasoning
- merging
- frism
- visual
- capabilities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of efficiently enhancing reasoning
  capabilities in Vision-Language Models (VLMs) by merging them with Large Reasoning
  Models (LRMs), while preserving their original visual perception abilities. Existing
  methods operate at a coarse layer level, leading to a trade-off between reasoning
  injection and visual capability preservation.
---

# FRISM: Fine-Grained Reasoning Injection via Subspace-Level Model Merging for Vision-Language Models

## Quick Facts
- arXiv ID: 2601.21187
- Source URL: https://arxiv.org/abs/2601.21187
- Reference count: 40
- Key outcome: Achieves 2.4% improvement in reasoning score on Qwen2.5-VL-32B-Instruct while preserving visual perception

## Executive Summary
This paper addresses the challenge of enhancing reasoning capabilities in Vision-Language Models (VLMs) through model merging with Large Reasoning Models (LRMs). Traditional layer-level merging approaches create a trade-off between reasoning injection and visual capability preservation. FRISM introduces a fine-grained subspace-level merging technique that decomposes LRM task vectors via SVD, enabling precise control over reasoning injection while maintaining visual performance. The framework employs a label-free self-distillation learning strategy with dual-objective optimization to balance these competing objectives.

## Method Summary
FRISM operates at the subspace level rather than the coarse layer level used in existing approaches. The method begins by decomposing the LRM task vectors into subspaces using Singular Value Decomposition (SVD). Each subspace is then adaptively tuned through scaling coefficients, providing fine-grained control over the reasoning injection process. A novel label-free self-distillation learning strategy is employed, utilizing common vision-language perception datasets to optimize dual objectives: maximizing reasoning capabilities while preserving visual perception. This approach eliminates the need for additional labeled data while effectively balancing the trade-off inherent in model merging.

## Key Results
- Achieves state-of-the-art performance across diverse visual reasoning benchmarks
- Demonstrates 2.4% improvement in reasoning score on Qwen2.5-VL-32B-Instruct
- Successfully preserves original visual perception capabilities during reasoning enhancement
- Shows consistent performance improvements across multiple VLM architectures

## Why This Works (Mechanism)
FRISM's effectiveness stems from its fine-grained subspace-level approach to model merging. By decomposing LRM task vectors via SVD into multiple subspaces, the framework can selectively inject reasoning capabilities at a much finer granularity than traditional layer-level merging. The adaptive tuning of scaling coefficients for each subspace allows precise control over the reasoning injection process, preventing the over- or under-injection that occurs with coarse layer-level methods. The dual-objective optimization framework, trained through label-free self-distillation on common vision-language datasets, effectively balances the competing goals of reasoning enhancement and visual capability preservation.

## Foundational Learning

**Singular Value Decomposition (SVD)**: Matrix factorization technique that decomposes data into orthogonal components ordered by importance. Why needed: Enables decomposition of LRM task vectors into meaningful subspaces for fine-grained control. Quick check: Verify that top k singular values capture sufficient variance in the task vectors.

**Self-Distillation Learning**: Training strategy where a model learns from its own outputs without external labels. Why needed: Eliminates dependency on additional labeled data while providing supervision for both reasoning and visual preservation objectives. Quick check: Monitor training stability and ensure consistent convergence across both objectives.

**Dual-Objective Optimization**: Optimization framework that simultaneously minimizes multiple loss functions. Why needed: Balances the trade-off between reasoning injection and visual capability preservation. Quick check: Verify that neither objective dominates the optimization process through careful loss weighting.

## Architecture Onboarding

**Component Map**: Input Data -> SVD Decomposition -> Subspace Scaling -> Dual-Objective Optimization -> Merged Model

**Critical Path**: The SVD decomposition and subspace scaling coefficients represent the critical path, as they directly determine the granularity and effectiveness of reasoning injection. The dual-objective optimization loop is essential for balancing the competing goals.

**Design Tradeoffs**: 
- Fine-grained control vs. computational overhead (more subspaces provide better control but increase computation)
- Self-distillation vs. labeled data (eliminates labeling costs but may have weaker supervision signals)
- Balancing reasoning vs. visual preservation (requires careful tuning of loss weights)

**Failure Signatures**: 
- Over-injection of reasoning leading to degraded visual performance
- Under-injection resulting in minimal reasoning improvements
- Training instability in dual-objective optimization
- SVD decomposition sensitivity to rank selection

**3 First Experiments**:
1. Baseline comparison of layer-level vs. subspace-level merging on a single VLM-LRM pair
2. Ablation study varying the number of SVD subspaces to determine optimal granularity
3. Loss weight sensitivity analysis in the dual-objective optimization framework

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Evaluation focuses primarily on merging VLMs and LRMs from the same family (Qwen2.5), raising generalizability concerns
- SVD-based decomposition may be sensitive to rank selection and subspace count choices
- Label-free self-distillation relies on common vision-language datasets, but selection criteria and potential biases are not thoroughly examined

## Confidence

**High Confidence**: The core methodology of fine-grained subspace-level merging and dual-objective optimization framework is well-supported by experimental results across multiple benchmarks.

**Medium Confidence**: Claims of "state-of-the-art" performance are supported within tested model families, but broader comparisons with alternative reasoning enhancement techniques are limited.

**Medium Confidence**: Demonstration of preserved visual capabilities while enhancing reasoning is shown, but long-term stability across extended use cases requires further validation.

## Next Checks

1. Evaluate FRISM's performance when merging VLMs and LRMs from different model families (e.g., LLaVA with DeepSeek-R1) to assess cross-family generalization.

2. Conduct ablation studies varying the number of SVD subspaces and their scaling coefficients to determine optimal configurations and sensitivity.

3. Test merged models on out-of-distribution visual reasoning tasks and long-horizon reasoning problems to assess robustness beyond reported benchmarks.