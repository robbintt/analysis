---
ver: rpa2
title: 'AugAbEx : Way Forward for Extractive Case Summarization'
arxiv_id: '2511.12290'
source_url: https://arxiv.org/abs/2511.12290
tags:
- summaries
- legal
- case
- extractive
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of creating extractive gold
  standard summaries for legal case summarization by transforming existing abstractive
  gold standard summaries. The authors propose a transparent, cost-effective pipeline
  that leverages ROUGE-based candidate sentence selection and Maximal Marginal Relevance
  (MMR) to generate extractive summaries while preserving expert opinions.
---

# AugAbEx : Way Forward for Extractive Case Summarization

## Quick Facts
- arXiv ID: 2511.12290
- Source URL: https://arxiv.org/abs/2511.12290
- Authors: Purnima Bindal; Vikas Kumar; Sagar Rathore; Vasudha Bhatnagar
- Reference count: 7
- Primary result: Transformed extractive gold (TEG) summaries are structurally and semantically comparable to original abstractive summaries and better preserve legal entities

## Executive Summary
This study presents AugAbEx, a novel approach to creating extractive gold standard summaries for legal case summarization by transforming existing abstractive gold standard summaries. The method employs ROUGE-based candidate sentence selection combined with Maximal Marginal Relevance (MMR) to generate extractive summaries while preserving expert opinions and legal entities. The transformed extractive gold (TEG) summaries are evaluated across structural, lexical, semantic, and domain-specific dimensions against both the original abstractive summaries and unsupervised LSA summaries. Results demonstrate that TEG summaries maintain comparable quality to original abstractive summaries while offering the advantages of extractive format for training and evaluation purposes.

## Method Summary
The AugAbEx pipeline transforms abstractive gold standard summaries into extractive format through a transparent, cost-effective process. The method uses ROUGE-based candidate sentence selection to identify relevant sentences from case documents, followed by Maximal Marginal Relevance (MMR) to ensure diversity and relevance in the final extractive summary. This approach leverages existing expert-created abstractive summaries as the foundation, eliminating the need for expensive manual creation of extractive gold standards. The transformation process aims to preserve the substantive legal content and reasoning present in the original abstractive summaries while converting them to extractive format suitable for training extractive summarizers.

## Key Results
- TEG summaries are structurally and semantically comparable to original abstractive summaries across most datasets
- TEG summaries show higher legal entity counts compared to both abstractive summaries and LSA baselines
- Better alignment with source case documents in most datasets, with some exceptions showing better alignment with abstractive summaries
- Demonstrates cost-effectiveness and transparency compared to manual extractive gold standard creation

## Why This Works (Mechanism)
The transformation approach works by leveraging existing expert knowledge encoded in abstractive gold standards rather than creating new summaries from scratch. By using ROUGE-based selection, the method captures sentences that closely match the content of abstractive summaries, ensuring semantic preservation. The MMR component adds diversity while maintaining relevance, preventing redundancy. This hybrid approach bridges the gap between abstractive and extractive summarization paradigms, creating reliable training data for extractive models while preserving the quality and completeness of expert-generated content.

## Foundational Learning
- **ROUGE-based candidate selection**: Why needed - to identify sentences most relevant to abstractive summary content; Quick check - verify selected sentences cover key concepts from abstractive summary
- **Maximal Marginal Relevance (MMR)**: Why needed - to balance relevance with diversity and prevent redundancy; Quick check - confirm summary diversity metrics meet thresholds
- **Legal entity recognition**: Why needed - domain-specific evaluation metric for legal summarization quality; Quick check - count legal entities in summaries and compare to gold standards
- **Structural evaluation metrics**: Why needed - to assess summary organization and completeness; Quick check - verify summary length and structure match expectations
- **Semantic similarity measures**: Why needed - to evaluate content preservation beyond surface-level matching; Quick check - compare semantic embeddings between abstractive and TEG summaries
- **LSA baseline comparison**: Why needed - to establish baseline performance for unsupervised extractive summarization; Quick check - ensure LSA results are consistent with prior literature

## Architecture Onboarding

**Component map**: Case documents -> ROUGE scoring -> Candidate sentence selection -> MMR ranking -> TEG summary generation

**Critical path**: The ROUGE scoring and candidate selection stage is most critical, as poor sentence selection cannot be corrected by subsequent MMR ranking. Sentence selection quality directly determines final summary quality.

**Design tradeoffs**: The approach trades some precision in sentence selection (ROUGE may miss semantically equivalent but lexically different sentences) for scalability and cost-effectiveness. MMR selection may occasionally prioritize diversity over strict relevance.

**Failure signatures**: 
- Low ROUGE scores between TEG and abstractive summaries indicate poor content preservation
- High redundancy in TEG summaries suggests MMR parameters need adjustment
- Missing key legal entities indicates candidate selection is not capturing domain-specific content adequately

**First experiments**:
1. Run ROUGE scoring on a small case subset to verify candidate sentence quality before full pipeline execution
2. Test MMR parameters on sample sentences to optimize diversity-relevance balance
3. Compare TEG summary quality on 5 cases against manual extractive summaries to establish baseline performance

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on ROUGE-based selection may bias toward surface-level lexical matches rather than deeper semantic equivalence
- Automated evaluation lacks extensive human validation to confirm preservation of substantive legal reasoning
- Domain adaptation challenges when applying to legal systems with different case structures or citation practices
- Comparison with LSA baselines doesn't establish absolute quality against human-created extractive summaries

## Confidence
- Structural and semantic comparability to abstractive summaries: Medium
- Domain-specific legal entity count advantages: Medium
- Cost-effectiveness and transparency of the pipeline: High
- TEG summaries as reliable gold standards: Medium

## Next Checks
1. Conduct expert legal reviewer assessments to validate that TEG summaries preserve the essential legal reasoning and conclusions present in original abstractive summaries
2. Perform ablation studies comparing ROUGE-MMR transformation against alternative sentence selection methods (e.g., semantic embeddings, legal-specific features) to quantify the impact of the chosen approach
3. Test the TEG generation pipeline on legal case corpora from different jurisdictions or legal systems to evaluate generalizability beyond the current dataset scope