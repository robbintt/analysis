---
ver: rpa2
title: 'Social Comparison without Explicit Inference of Others'' Reward Values: A
  Constructive Approach Using a Probabilistic Generative Model'
arxiv_id: '2512.18687'
source_url: https://arxiv.org/abs/2512.18687
tags:
- partner
- reward
- subjective
- social
- comparison
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigated whether monkeys infer their partner''s
  subjective reward valuations during social comparison, or if they rely solely on
  observing objective rewards. Using a constructive computational modeling approach,
  three models with varying social information processing were developed: an Internal
  Prediction Model (IPM) that infers partner subjective values, a No Comparison Model
  (NCM) that disregards partner information, and an External Comparison Model (ECM)
  that directly incorporates partner''s objective rewards.'
---

# Social Comparison without Explicit Inference of Others' Reward Values: A Constructive Approach Using a Probabilistic Generative Model

## Quick Facts
- arXiv ID: 2512.18687
- Source URL: https://arxiv.org/abs/2512.18687
- Reference count: 36
- Primary result: Monkeys' social comparison relies on direct observation of objective reward differences rather than inference of partner's subjective values, as demonstrated by an External Comparison Model achieving superior performance (Rand Index 0.88) compared to models with partner subjective-value inference.

## Executive Summary
This study investigates whether monkeys infer their partner's subjective reward valuations during social comparison, or if they rely solely on observing objective rewards. Using a constructive computational modeling approach, the researchers developed three probabilistic generative models with varying social information processing capabilities. The External Comparison Model (ECM), which directly incorporates partner's objective rewards without inferring subjective states, achieved the highest classification accuracy for subjective-value categorization and best predicted monkeys' anticipatory licking behavior. The findings suggest that social comparison in monkeys relies primarily on direct observation of objective reward differences rather than inferences about subjective states, indicating a more computationally efficient mechanism than previously hypothesized.

## Method Summary
The researchers employed a multi-layered multimodal latent Dirichlet allocation (mMLDA) framework implemented via the SERKET architecture to model social comparison behavior in macaque monkeys. Three models were constructed: an Internal Prediction Model (IPM) that infers partner subjective values, a No Comparison Model (NCM) that disregards partner information, and an External Comparison Model (ECM) that directly incorporates partner's objective rewards. The models were trained on 292 days of experimental data (233 days for training, 59 for testing) from monkeys performing a social comparison task with six experimental conditions varying self and partner reward probabilities. Gibbs sampling with 300 iterations (100 per module × 3 message-passing cycles) was used for inference, with Bayesian optimization tuning modality weights. Model performance was evaluated using Rand Index for subjective-value classification, licking behavior prediction, and normalized mutual information analysis between model nodes.

## Key Results
- The ECM achieved the highest Rand Index classification score (0.88) compared to IPM (0.79) and NCM (0.75), demonstrating superior subjective-value categorization
- ECM best predicted monkeys' anticipatory licking behavior across experimental conditions, including extrapolation to unobserved reward distributions
- Normalized mutual information analysis revealed that ECM transmitted information more efficiently between nodes, with significantly higher NMI values for partner-reward nodes compared to IPM
- The results suggest that social comparison relies on objective reward differences rather than inferences about subjective states

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Direct observation of objective partner rewards enables more accurate subjective-value categorization than inferring the partner's internal valuation.
- Mechanism: The External Comparison Model (ECM) bypasses the partner's subjective-value node entirely, routing partner reward observations (w^RP) and action intentions (z^AP) directly to the situation-awareness node (z^S). This eliminates noise propagation from imperfect partner action-intention categorization through a subjective-value layer that would otherwise degrade information quality before integration.
- Core assumption: Partner licking behavior contains sufficient noise that its categorization into subjective values introduces error, whereas raw reward frequencies transmit more reliably.
- Evidence anchors:
  - [abstract] "The ECM achieved the highest classification score in the Rand Index (0.88 vs. 0.79 for the IPM)... suggesting that social comparison relies on objective reward differences rather than inferences about subjective states."
  - [section 4.1] "The partner's licking behavior contained inherent variability and noise, which could lead to imperfect categorization in the partner's action-intention node. These inaccuracies propagated to the partner's subjective-value node, potentially degrading the quality of information available to the situation-awareness node."

### Mechanism 2
- Claim: Hierarchical message passing between MLDA layers enables bidirectional integration of multimodal information for subjective-value representation.
- Mechanism: The multi-layered MLDA (mMLDA) architecture performs bottom-up inference where lower-layer latent variables (action intentions from licking, reward frequencies) serve as observations for higher layers, while top-down messages from situation-awareness nodes modulate categorization. Gibbs sampling alternates between updating latent assignments conditioned on local observations and incorporating backward messages from parent nodes.
- Core assumption: The generative process—where subjective values causally influence action intentions and correlate with reward distributions—can be inverted via approximate posterior inference to recover latent categories consistent with behavioral data.
- Evidence anchors:
  - [abstract] "To test model performance, we used a multi-layered, multimodal latent Dirichlet allocation."
  - [section 2.2.1] "The inference process first calculates the probability distribution of action intention categories... These action categories serve as observational data for the upper layer's subjective-value categories, and the action-intention categories are updated stochastically based on the subjective value model."

### Mechanism 3
- Claim: Normalized mutual information (NMI) between nodes reveals that ECM transmits socially-relevant information more efficiently despite having fewer free parameters.
- Mechanism: By computing NMI = 2I(A;B)/[H(A)+H(B)] between each node and the self-subjective-value node (z^RS), the analysis quantifies information transmission fidelity. ECM showed significantly higher NMI for partner-reward nodes and for most other nodes, indicating that removing the partner subjective-value node strengthened rather than weakened information flow.
- Core assumption: Higher NMI between a node and the target subjective-value node reflects more efficient, behaviorally-relevant information transmission rather than overfitting or spurious correlation.
- Evidence anchors:
  - [abstract] "Normalized mutual information analysis revealed that the ECM transmitted information more efficiently between nodes."
  - [section 3.3, Table 2] "Except for the pair (w^RS, z^RS), NMI was significantly higher in the ECM for every node examined... granting the model direct access to partner-related variables, therefore, strengthened not only the information pathway from those variables to the self-valuation node but also dependencies involving other nodes."

## Foundational Learning

- Concept: Latent Dirichlet Allocation (LDA) and Multimodal LDA (MLDA)
  - Why needed here: The entire modeling framework builds on probabilistic topic models where "topics" represent latent categories (subjective values, action intentions). Without understanding how Dirichlet priors govern multinomial observations and how Gibbs sampling estimates posterior topic assignments, the model architecture is opaque.
  - Quick check question: Given a corpus of documents, how would increasing the Dirichlet hyperparameter α affect the distribution of topics per document?

- Concept: Message passing in hierarchical generative models
  - Why needed here: The mMLDA architecture relies on bidirectional information flow—bottom-up from observations to latent variables and top-down from higher-layer latents to constrain lower-layer categorization. Understanding this is essential for debugging convergence or interpretation failures.
  - Quick check question: In a two-layer MLDA where the lower layer categorizes licking behavior and the upper layer integrates licking and reward information, what happens if the top-down message from the upper layer is disabled?

- Concept: Social comparison and reward valuation in primates
  - Why needed here: The paper interprets model outputs through the lens of primate social cognition—specifically, whether monkeys represent others' subjective states. Without this context, the three models appear as arbitrary architectural variants rather than competing hypotheses about cognitive mechanisms.
  - Quick check question: If monkeys exhibited theory-of-mind abilities for belief attribution (as in Hayashi et al. 2020), why might this not extend to reward-value inference during social comparison?

## Architecture Onboarding

- Component map: w^A (licking) -> z^A (action intention) -> z^R (subjective value) <- w^R (reward) -> z^S (situation awareness) <- z^RP (partner subjective value) <- w^RP (partner reward), with z^S also receiving z^AP (partner action intention) <- w^AP (partner licking)

- Critical path:
  1. Preprocess raw licking time series into block-level frequency vectors (Appendix B.3)
  2. Encode reward distributions as {n_reward, n_no_reward} frequency vectors (Appendix B.2)
  3. Extract visual stimulus features via VQ-VAE pre-trained on CIFAR-10 (Appendix B.1)
  4. Run 300 Gibbs sampling iterations per module (100 iterations × 3 message-passing cycles)
  5. Evaluate subjective-value categorization against ground-truth experimental conditions using Rand Index
  6. Predict licking behavior from stimulus-only inputs and compare to held-out test data

- Design tradeoffs:
  - Topic count K=6 matches experimental conditions but assumes each condition maps to a distinct subjective value; this constrains model expressivity
  - Dirichlet priors set uniformly to 1.0 (uninformative); informative priors could accelerate convergence but require domain knowledge
  - KL divergence used for weight optimization rather than likelihood because weight scaling changes multinomial sample sizes, making likelihood incomparable across configurations (Appendix C)
  - Trial-level reward correspondence (self vs. partner rewarded simultaneously) is abstracted away in block-level frequency vectors, potentially losing temporal social comparison dynamics

- Failure signatures:
  - NCM predicts increased licking with increased partner reward (reversal of observed social comparison effect) → indicates missing social information pathway
  - IPM conflates Self-25% and Partner-25% conditions → indicates that partner subjective-value inference introduces confusion between distinct social contexts
  - ECM shows minor confusion between Self-50% and Self-75% conditions → indicates limit of discriminability at high self-reward probabilities
  - Gibbs sampling fails to converge if message-passing cycles < 3 or iteration counts < 100 per module

- First 3 experiments:
  1. Reproduce the Rand Index comparison across IPM/NCM/ECM on the provided train-test split (233/59 days) to validate implementation; expected result: ECM > IPM > NCM
  2. Ablate the top-down message from z^S to z^RS in ECM and measure degradation in subjective-value classification accuracy; this tests the claim that bidirectional flow is essential
  3. Vary the number of latent topics (K=4, 6, 8) and measure both classification accuracy and NMI patterns; if ECM's advantage persists across K values, this strengthens the conclusion that architectural structure—not topic count—drives performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do neural correlates in the primate brain specifically map to the computational nodes of the External Comparison Model (ECM)?
- Basis in paper: [explicit] The authors state that "correlating model components with local field potential recordings from the monkeys' brains... could provide neurological validation of our computational findings."
- Why unresolved: The current study relies on a constructive modeling approach using behavioral data; it does not include concurrent neural recordings to verify if the brain actually implements the "direct objective comparison" mechanism proposed.
- What evidence would resolve it: Identification of neural activity patterns in areas like the medial prefrontal cortex (MPFC) or lateral hypothalamus that selectively track the objective reward comparison variables defined in the ECM architecture.

### Open Question 2
- Question: Can monkeys be induced to infer a partner's subjective valuation if the experimental paradigm forces distinct subjective values for identical rewards?
- Basis in paper: [explicit] The authors suggest that "if the experimental paradigm forces the self and the partner to assign completely different subjective values to the same thing... subjective value inference might be prompted."
- Why unresolved: In the current dataset, the reward (water) likely held similar subjective value for both subjects, potentially rendering complex inference unnecessary; thus, the inability of the IPM to outperform the ECM may be context-dependent.
- What evidence would resolve it: A modified social comparison experiment using asymmetric exchange ratios (e.g., ultimatum game settings) where the same reward holds different values for the self versus the partner, testing if the IPM becomes the superior predictive model.

### Open Question 3
- Question: Do humans utilize the same computationally efficient "objective reward" mechanism as monkeys during social comparison?
- Basis in paper: [explicit] The authors propose a "natural extension would be to conduct analogous experiments with human participants to determine whether similar computational mechanisms underlie social comparison across primates."
- Why unresolved: While humans possess advanced theory of mind, it is unknown if they engage in computationally expensive subjective inference for value comparison or rely on the efficient external comparison observed in monkeys.
- What evidence would resolve it: Human experiments measuring social comparison behaviors alongside explicit reports of partner-state inference, analyzed via the same constructive model comparison framework.

## Limitations
- The abstraction from trial-level to block-level data may lose critical moment-to-moment social comparison signals that could reveal different computational mechanisms
- The three-model comparison cannot definitively prove the absence of partner subjective-value inference—it only shows that direct reward observation suffices for the experimental conditions tested
- The models are highly abstracted from neurobiological reality, limiting claims about actual cognitive mechanisms in the brain

## Confidence

- **High confidence**: Quantitative superiority of ECM for Rand Index classification (0.88 vs 0.79 vs 0.75) and its better licking prediction performance
- **Medium confidence**: Interpretation that this superiority reflects computational efficiency rather than model misspecification or overfitting
- **Low confidence**: Claims about the cognitive mechanism underlying social comparison in monkeys, as the models are highly abstracted from neurobiological reality

## Next Checks

1. Test ECM with varying numbers of latent topics (K=4, 8) to determine whether the architecture's advantage is robust to topic count variations
2. Implement a fourth model variant that includes partner subjective-value nodes but with constrained inference (e.g., higher Dirichlet concentration) to test whether architectural differences or inference constraints drive the results
3. Reconstruct the experimental timeline at trial-level resolution to test whether block-level aggregation artificially favors the ECM architecture by smoothing temporal social comparison dynamics