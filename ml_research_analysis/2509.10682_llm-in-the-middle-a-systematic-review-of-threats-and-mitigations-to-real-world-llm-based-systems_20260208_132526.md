---
ver: rpa2
title: 'LLM in the Middle: A Systematic Review of Threats and Mitigations to Real-World
  LLM-based Systems'
arxiv_id: '2509.10682'
source_url: https://arxiv.org/abs/2509.10682
tags:
- arxiv
- data
- security
- llms
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey systematically reviews security and privacy threats
  to large language model (LLM)-based systems, mapping threats to the software and
  LLM life cycles. We identify 198 unique threats, classify them using the CIA triad,
  and assign severity scores via CVSS v3.1 and OWASP Risk Rating.
---

# LLM in the Middle: A Systematic Review of Threats and Mitigations to Real-World LLM-based Systems

## Quick Facts
- arXiv ID: 2509.10682
- Source URL: https://arxiv.org/abs/2509.10682
- Reference count: 40
- Primary result: Survey systematically reviews 198 LLM security/privacy threats, classifying by CIA triad and applying CVSS/OWASP scoring across four deployment scenarios

## Executive Summary
This systematic review analyzes security and privacy threats to large language model (LLM)-based systems by mapping threats to software and LLM life cycles. The authors identify 198 unique threats, classify them using the CIA triad, and assign severity scores via CVSS v3.1 and OWASP Risk Rating. Through STRIDE threat modeling applied to four real-world deployment scenarios, the study reveals that jailbreak attacks remain the dominant threat class, while threats vary significantly based on deployment architecture (on-device vs. cloud), development vs. operation phases, and general-purpose vs. goal-oriented LLM use. The research concludes that defense-in-depth is essential since no single countermeasure fully addresses all threats, highlighting open challenges including evolving jailbreak methods, lack of comprehensive attack testbeds, and limited reproducibility in research.

## Method Summary
The study employs PRISMA-guided systematic screening across ACM DL, IEEE Xplore, Google Scholar, and arXiv, using LLM-security keyword combinations. After title/abstract and full-text screening with explicit inclusion/exclusion criteria, 198 unique threats were identified and classified by CIA triad. Severity was assigned using CVSS v3.1 and OWASP Risk Rating frameworks. Four canonical deployment scenarios were analyzed using STRIDE threat modeling, and 47 mitigation techniques were mapped to lifecycle phases and attack strategies. The methodology emphasizes reproducibility challenges in LLM security research, noting that many attacks lack standardized testing frameworks.

## Key Results
- Identified 198 unique security and privacy threats to LLM systems, with jailbreak attacks representing the dominant threat class
- Demonstrated that threat severity and attack vectors vary significantly across deployment architectures (on-device vs. cloud) and LLM use cases (general-purpose vs. goal-oriented)
- Established that defense-in-depth is essential, as no single mitigation strategy provides comprehensive protection against the full spectrum of identified threats

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Jailbreak attacks represent the dominant threat class against LLM-based systems, primarily by manipulating prompts to bypass safety guardrails
- Mechanism: Attackers craft adversarial prompts (direct or indirect) that exploit the model's context processing to make it generate restricted content, perform unauthorized actions, or leak sensitive data. The paper identifies 198 unique threats, with prompt-based jailbreaks being the most frequent
- Core assumption: LLMs, despite alignment training, remain vulnerable to carefully crafted input manipulations that can subvert their safety constraints
- Evidence anchors:
  - [abstract] States "jailbreak attacks remain the dominant threat class"
  - [Section V] Details numerous jailbreak techniques (I09-I27) under Integrity threats, using strategies like direct prompt, obfuscation, and context manipulation
  - [corpus] Related work "The Promptware Kill Chain" describes how prompt injections evolved into multi-step attacks, supporting the mechanism's evolution
- Break condition: The mechanism assumes the attacker can deliver a crafted prompt. It may fail if robust, context-aware input filtering or detection (e.g., M33) effectively blocks malicious prompts before LLM processing

### Mechanism 2
- Claim: The threat landscape for an LLM system is fundamentally shaped by its deployment architecture and design choices (e.g., on-device vs. cloud, general-purpose vs. goal-oriented)
- Mechanism: Different architectures expose different attack surfaces. On-device deployment risks reverse engineering and malware (physical access), while cloud deployment risks insider threats and exploitation of shared infrastructure. Goal-oriented agents with tool access risk remote code execution (RCE)
- Core assumption: Threats are not monolithic; their likelihood and severity are conditional on the system's configuration and operational context
- Evidence anchors:
  - [abstract] Notes "threats differ significantly across on-device vs. cloud deployment, development vs. operation phases, and general-purpose vs. goal-oriented LLM use"
  - [Section VIII] Applies STRIDE threat modeling to four distinct scenarios, showing how risks like "Impersonating the User" have different CVSS scores (5.0 on-device vs. 6.4 on-cloud) based on the attack vector
  - [corpus] "SoK: Privacy Risks and Mitigations in Retrieval-Augmented Generation Systems" highlights scenario-specific risks in RAG architectures, aligning with this mechanism
- Break condition: The mechanism relies on correctly modeling the system's boundaries and trust levels. It may break if an unforeseen design choice (e.g., a novel continuous learning method) introduces an unaccounted attack vector

### Mechanism 3
- Claim: No single mitigation strategy is sufficient; effective defense requires a defense-in-depth approach combining multiple techniques across the system lifecycle
- Mechanism: Mitigations are mapped to specific lifecycle phases (development, operation) and attack strategies. For example, input preprocessing (M33-M36) targets prompt injection, while infrastructure monitoring (M23) detects resource exhaustion. Layering these reduces overall risk
- Core assumption: Individual mitigations have known coverage gaps, and an attacker can chain exploits. A layered security posture increases the cost and complexity of a successful attack
- Evidence anchors:
  - [abstract] Concludes "defense-in-depth is essential, as no single countermeasure fully addresses all threats"
  - [Section VII] Categorizes 47 mitigation techniques (M01-M47) and maps them to life cycle phases and attack strategies in Table VIII, showing a single technique rarely addresses all strategies
  - [corpus] "A Survey of Attacks on Large Language Models" likely reinforces the breadth of attack surfaces, implicitly supporting the need for layered defenses
- Break condition: The mechanism assumes the defender has resources to implement and maintain multiple layers. It fails if the cumulative complexity creates misconfigurations or gaps between layers that a skilled attacker can exploit

## Foundational Learning

- Concept: **CIA Triad & STRIDE Threat Modeling**
  - Why needed here: The paper uses the Confidentiality, Integrity, Availability (CIA) triad to classify 198 threats (Section V) and the STRIDE framework to model threats for specific scenarios (Section VIII). Understanding these models is prerequisite to interpreting threat severity and mapping defenses
  - Quick check question: Can you map a "Model Replication" attack to a CIA property and a STRIDE category? (Answer: Confidentiality, Information Disclosure)

- Concept: **LLM System Life Cycle Phases**
  - Why needed here: Threats and mitigations are anchored to phases like Data Engineering, LLM Development, LLM Integration, and Operation (Section IV-A). A clear view of this lifecycle is necessary to apply the right defense at the right time
  - Quick check question: During which phase would you primarily apply "Training Data Sanitization" (M05)? (Answer: Data Engineering phase)

- Concept: **Attack Strategies vs. Threats**
  - Why needed here: The paper distinguishes between high-level strategies (e.g., Direct Prompt, Supply Chain, Side-Channel) and specific threats (e.g., I09, C15). Understanding this hierarchy is key to selecting appropriate mitigations
  - Quick check question: What attack strategies are attenuated by "Model Supply Chain Protection" (M32)? (Answer: Supply Chain [3])

## Architecture Onboarding

- Component map: User Interface ↔ LLM System (App/Agent) ↔ LLM ↔ External Resources (Tools/DBs/Internet). Security layers exist at Input Processing, Model Protection, Output Processing, Infrastructure, and User Device
- Critical path: For a secure deployment, the path is: 1) Define scenario (ST:O/UC:CB/...), 2) Apply STRIDE to identify high-CVSS risks, 3) Map risks to relevant mitigations from Table VII, 4) Implement defense-in-depth prioritizing mitigations for the highest-severity threats (e.g., M33, M34, M40 for a chat-bot with jailbreak risk)
- Design tradeoffs: **On-device vs. Cloud:** On-device offers better data privacy (no data leaves device) but risks reverse engineering (C14) and is harder to patch. Cloud offers easier management but risks insider threats (C15) and shared-infrastructure attacks (C06). **General-purpose vs. Goal-oriented:** Goal-oriented agents with tool access (e.g., AR:Tools) increase utility but significantly raise the risk of RCE (I14)
- Failure signatures: 
  - **Jailbreak Success:** Model generates disallowed content or performs unauthorized actions despite guardrails
  - **Prompt/Data Leakage:** Sensitive system prompts or user data appear in outputs
  - **Service Disruption:** Unexplained latency, resource exhaustion, or repeated crashes
  - **Unexpected Model Behavior:** Sudden onset of biased, incorrect, or malicious outputs, indicating possible poisoning (I01, I02)
- First 3 experiments:
  1. **Baseline Threat Modeling:** For a chosen scenario (e.g., ST:O/UC:AP/DI:C), perform a STRIDE analysis to list top 5 threats and map them to mitigations. Compare your output with Tables X-XIII
  2. **Mitigation Layering Test:** Select a high-severity threat like Indirect Prompt Injection (I16). Implement at least two mitigations from different categories (e.g., M35 Input Sanitization + M38 Output Detection). Test if the combination provides better protection than either alone
  3. **Attack-Defense Simulation:** Use an open-source jailbreak tool (corpus: "Game Theory Meets LLM and Agentic AI..." discusses red-teaming) against a test LLM. Apply a subset of mitigations (M33, M29) and measure the change in attack success rate, documenting the tradeoff in model utility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can a framework be developed to quantitatively assess the efficacy, implementation complexity, and cost of combining multiple mitigation strategies (Defense-in-Depth) for LLM systems?
- Basis in paper: [explicit] Section IX-B, "Measuring efficacy of mitigation strategies," explicitly asks for a framework to analyze the protection extent and costs of combining strategies
- Why unresolved: The paper notes that while Defense-in-Depth is essential, current literature lacks a method to evaluate how different mitigations interact or their specific trade-offs in real-world scenarios
- What evidence would resolve it: A standardized methodology that maps threat modeling insights to quantitative metrics on protection levels, implementation costs, and operational overhead for combined defense strategies

### Open Question 2
- Question: How can the research community construct comprehensive attack testbeds that go beyond jailbreak prompts to include privacy attacks and system integration vulnerabilities?
- Basis in paper: [explicit] Section IX-B, "Testbed of attacks to LLM systems," identifies a gap in testbeds that cover privacy-related attacks, side-channels, and the integration of applications with LLMs
- Why unresolved: Current datasets largely focus on prompt injection or jailbreaking, failing to capture the complexity of exploiting the software supply chain or API integrations in real-world deployments
- What evidence would resolve it: The release of a unified benchmark dataset containing diverse attack vectors (e.g., RCE, side-channel, poisoning) applicable to full LLM-based system architectures rather than just the model

### Open Question 3
- Question: What standardized mechanisms are required to ensure the reproducibility of proposed attack techniques on real-world LLM deployments?
- Basis in paper: [explicit] Section IX-B, "Reproducibility," notes that many proposed attacks lack straightforward methods for application and testing on models
- Why unresolved: The rapid pace of "arxiv-first" publishing without peer review has led to a proliferation of attacks that are difficult to verify or compare against state-of-the-art defenses in consistent environments
- What evidence would resolve it: The adoption of community-wide tools or protocols that allow researchers to easily replicate and compare attack success rates across different models and deployment scenarios

## Limitations

- Threat landscape evolves rapidly, with new attack vectors emerging between search period and publication
- CVSS and OWASP risk ratings rely on subjective parameter choices that may vary across raters, introducing potential scoring inconsistencies
- Practical effectiveness of proposed mitigations against real-world attacks requires further empirical validation, as many solutions lack rigorous testing against advanced adversaries

## Confidence

- Jailbreak attacks as dominant threat class: High confidence due to extensive enumeration of prompt manipulation techniques and their prevalence in literature
- Scenario-dependent nature of threats: High confidence as STRIDE analysis across four distinct deployment models shows clear variations in threat severity and attack vectors
- Defense-in-depth recommendation: Medium confidence while theoretical coverage gaps are well-documented, empirical evidence of layered defense effectiveness against chained attacks remains limited

## Next Checks

1. Replicate the systematic search using the exact query parameters and inclusion criteria, then compare the resulting threat taxonomy to verify completeness and classification consistency
2. Conduct controlled experiments testing the effectiveness of multiple mitigation layers against a representative set of jailbreak techniques, measuring both attack success rates and model utility degradation
3. Perform a longitudinal analysis tracking the emergence of new threat categories and attack strategies since the study's search period, assessing whether the identified threat landscape remains current