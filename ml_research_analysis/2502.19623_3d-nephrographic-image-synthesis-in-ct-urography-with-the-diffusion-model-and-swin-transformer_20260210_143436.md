---
ver: rpa2
title: 3D Nephrographic Image Synthesis in CT Urography with the Diffusion Model and
  Swin Transformer
arxiv_id: '2502.19623'
source_url: https://arxiv.org/abs/2502.19623
tags:
- images
- image
- phase
- nephrographic
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study developed a novel deep learning model (dsSNICT) using
  diffusion models with Swin transformer backbones to synthesize 3D nephrographic
  phase images in CT urography from non-contrast and excretory phase inputs. This
  approach aims to reduce radiation dose by 33% by eliminating the need for dedicated
  nephrographic phase acquisition.
---

# 3D Nephrographic Image Synthesis in CT Urography with the Diffusion Model and Swin Transformer

## Quick Facts
- **arXiv ID**: 2502.19623
- **Source URL**: https://arxiv.org/abs/2502.19623
- **Reference count**: 40
- **Primary result**: Developed a 3D diffusion model with Swin Transformer that synthesizes nephrographic phase CT images from non-contrast and excretory phases, achieving PSNR of 26.3 dB, SSIM of 0.84, and enabling 33% radiation dose reduction in CT urography.

## Executive Summary
This study introduces dsSNICT, a novel deep learning model that synthesizes 3D nephrographic phase CT images from non-contrast and excretory phase inputs using a diffusion model with Swin Transformer backbone. The approach addresses the need for dose reduction in CT urography by eliminating the need for a dedicated nephrographic phase acquisition, which typically requires an additional 3-minute delay and 33% more radiation exposure. Trained on 267 patients and validated on 60 patients, the model achieves high performance metrics and produces synthetic images that radiologists judged to be visually equivalent to real nephrographic images, with no significant differences in quality assessment (P=0.5).

## Method Summary
The dsSNICT model uses a diffusion-based architecture with Swin Transformer backbone to synthesize 3D nephrographic phase images from paired non-contrast and excretory phase inputs. The methodology involves two-stage preprocessing: global affine registration followed by kidney-specific registration, with images normalized to window/level 400/50 and filtered by SSIM_select >0.65. Kidney segmentation is performed using a Swin+diffusion model trained on KiTS19 data. The synthetic model takes 192×64×32 voxel inputs and predicts mean/variance parameters through ResBlock and Swin transformer layers. Training uses AdamW optimizer with learning rate 2×10⁻⁵, MAE loss, and batch size 4 on NVIDIA A100 80GB GPU, with data augmentation through sliding windows and rotations.

## Key Results
- Achieved PSNR of 26.3±4.4 dB, SSIM of 0.84±0.069, MAE of 12.74±5.22 HU, and FVD of 1323 on test set
- Two radiologists rated synthetic images with no significant difference from real images (P=0.5) using 5-point Likert scale
- Successfully synthesized high-quality 3D nephrographic images enabling 33% radiation dose reduction
- Maintained diagnostic image quality while reducing acquisition time by eliminating 3-minute nephrographic delay

## Why This Works (Mechanism)
The diffusion model framework enables gradual denoising of random noise into target images through learned denoising steps, while the Swin Transformer backbone captures long-range spatial dependencies in 3D volumes. This combination allows the model to learn the complex relationship between the non-contrast and excretory phases and the target nephrographic phase, preserving anatomical details and contrast enhancement patterns critical for diagnostic imaging.

## Foundational Learning
- **3D convolutional networks**: Essential for processing volumetric medical imaging data while preserving spatial relationships across slices
  - Why needed: CT images are inherently 3D structures requiring volumetric analysis
  - Quick check: Verify model processes 3D patches rather than 2D slices

- **Diffusion models**: Generate high-quality images by learning to denoise from random noise through iterative steps
  - Why needed: Enables generation of realistic medical images with preserved anatomical details
  - Quick check: Monitor denoising quality at different timesteps

- **Swin Transformer architecture**: Captures long-range dependencies in 3D volumes through shifted window self-attention
  - Why needed: Traditional CNNs have limited receptive fields, while Swin handles complex spatial relationships
  - Quick check: Verify attention patterns capture relevant anatomical structures

- **Registration techniques**: Align images from different phases to ensure accurate synthesis
  - Why needed: Phase differences due to timing and patient motion require precise alignment
  - Quick check: Measure registration accuracy through SSIM and visual inspection

- **Window/level normalization**: Standardizes HU values for consistent model training
  - Why needed: Medical images have wide HU ranges requiring consistent input scaling
  - Quick check: Verify normalization preserves relevant contrast information

- **Kidney segmentation preprocessing**: Focuses synthesis on region of interest while reducing computational load
  - Why needed: CT urography primarily visualizes urinary tract, not whole body
  - Quick check: Validate segmentation Dice scores exceed 0.9

## Architecture Onboarding

Component Map: CTU volumes -> Registration (Antspy) -> Segmentation (KiTS19-trained) -> Windowing/Leveling -> SSIM_filter -> dsSNICT (Diffusion+Swin) -> Synthetic Nephrographic

Critical Path: The model requires accurate registration of phase images before synthesis, as temporal differences and patient motion can degrade quality. The kidney segmentation step is essential for reducing input size and computational complexity while maintaining focus on the region of interest.

Design Tradeoffs: The study chose 3D synthesis over 2D to preserve volumetric relationships critical for renal imaging, accepting higher computational requirements. Window/level normalization simplifies training but may clip extreme HU values. The two-stage registration approach balances global alignment with local kidney-specific accuracy.

Failure Signatures: Poor registration quality manifests as misaligned anatomical structures and ghosting artifacts. Mode collapse appears as overly smooth or repetitive synthetic patterns. Segmentation errors cause synthetic images to include non-kidney structures or miss renal boundaries.

First Experiments:
1. Validate registration quality by measuring SSIM between registered phase pairs and visualizing alignment errors
2. Test kidney segmentation model on KiTS19 validation set to ensure Dice >0.9
3. Evaluate diffusion model training stability by monitoring loss curves and synthetic image quality progression

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would a crossover reader study demonstrate non-inferior diagnostic accuracy when radiologists interpret CT urography with synthetic nephrographic images compared to real nephrographic images?
- Basis in paper: The authors state "Such preliminary findings set the stage for further investigation into incorporating the synthesized images into clinical practice, which could be further evaluated with a cross-over radiologist reader study to compare CT urography data sets with synthetic images to those with ground truth nephrographic images."
- Why unresolved: The current study evaluated image quality metrics and visual similarity but did not assess whether synthetic images support equivalent diagnostic performance for detecting and characterizing renal pathologies in actual clinical interpretation.
- What evidence would resolve it: A prospective crossover study where multiple radiologists independently interpret cases with synthetic versus real nephrographic images, with comparison of sensitivity, specificity, and diagnostic confidence for detecting renal masses, urothelial lesions, and other abnormalities.

### Open Question 2
- Question: How well does the dsSNICT model generalize to external institutions with different scanner manufacturers, protocols, and patient populations?
- Basis in paper: The authors identify "lack of data from external institutions" as a limitation, noting that despite collecting from eight local hospitals, "the patient population is essentially the same, as all participants are from the same region."
- Why unresolved: The model was trained and validated on a geographically restricted dataset, and performance may degrade when applied to institutions with different CT scanners, contrast injection protocols, or patient demographics.
- What evidence would resolve it: External validation studies at geographically distinct institutions with diverse scanner platforms, demonstrating sustained performance metrics (PSNR, SSIM, MAE) and qualitative radiologist assessment.

### Open Question 3
- Question: Would using the full range of attenuation values instead of window-limited values (400/50) improve synthesis accuracy for lesions with extreme HU values?
- Basis in paper: The authors acknowledge "we currently set the window and level to 400 and 50 in the preprocessing step for better registration and easier training of the synthetic model" and state "we will apply the full range of attenuation values in a future study."
- Why unresolved: Windowing may clip clinically important attenuation information for hyperdense or hypodense lesions, potentially limiting diagnostic accuracy for certain pathologies.
- What evidence would resolve it: Re-training the model with full attenuation range using improved registration algorithms, comparing synthesis accuracy across the full HU spectrum, particularly for high-attenuation hemorrhagic cysts and enhancing masses.

## Limitations
- Incomplete methodological specification regarding Swin Transformer architecture details and diffusion hyperparameters
- Data curation excluded cases with "poor image quality" without defining criteria, potentially introducing selection bias
- Lack of external validation across different CT scanner manufacturers and protocols
- Radiologist evaluation involved only two readers without formal ROC analysis design

## Confidence
- **High confidence**: The feasibility of diffusion-based 3D image synthesis for CT urography is demonstrated; radiation dose reduction potential (33%) is technically achievable; kidney segmentation preprocessing methodology is sound
- **Medium confidence**: The specific performance metrics reported are reproducible given the same data and computational resources; the qualitative equivalence between synthetic and real images based on radiologist scores
- **Low confidence**: Generalization to clinical practice outside the single institution; robustness across different scanner types and acquisition protocols; clinical utility beyond radiation dose reduction (e.g., diagnostic accuracy for specific pathologies)

## Next Checks
1. **External validation**: Test the model on CT urography datasets from different institutions with varying scanner manufacturers and protocols to assess generalizability beyond the training population
2. **Diagnostic accuracy assessment**: Conduct a reader study with multiple radiologists using receiver operating characteristic (ROC) analysis to compare diagnostic performance between synthetic nephrographic images and real images for clinically relevant findings (stones, masses, urothelial abnormalities)
3. **Longitudinal stability evaluation**: Assess temporal consistency of synthetic images across repeated examinations in the same patients to ensure reliability for follow-up imaging and disease monitoring