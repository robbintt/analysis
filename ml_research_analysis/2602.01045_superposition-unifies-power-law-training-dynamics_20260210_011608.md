---
ver: rpa2
title: Superposition unifies power-law training dynamics
arxiv_id: '2602.01045'
source_url: https://arxiv.org/abs/2602.01045
tags:
- superposition
- training
- loss
- dynamics
- power-law
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how feature superposition affects power-law
  training dynamics in neural networks using a teacher-student framework. The authors
  first derive an analytic theory for the no-superposition case, showing that the
  training exponent depends on both input data statistics and channel importance.
---

# Superposition unifies power-law training dynamics

## Quick Facts
- arXiv ID: 2602.01045
- Source URL: https://arxiv.org/abs/2602.01045
- Reference count: 36
- Key outcome: Feature superposition induces a universal power-law exponent of approximately 1 in neural network training, representing up to tenfold acceleration compared to sequential learning

## Executive Summary
This paper investigates how feature superposition affects power-law training dynamics in neural networks using a teacher-student framework. The authors develop an analytic theory showing that training exponents depend on both input data statistics and channel importance in the no-superposition case. They demonstrate that introducing a superposition bottleneck induces a transition to a universal power-law exponent of approximately 1, independent of data and channel statistics. This represents significant acceleration in training dynamics compared to traditional sequential learning approaches.

## Method Summary
The authors employ a teacher-student framework to study feature learning dynamics in neural networks. They first derive an analytic theory for the no-superposition case, establishing the relationship between training exponents and input data statistics plus channel importance. To investigate superposition effects, they introduce a bottleneck architecture that forces feature superposition, then empirically demonstrate the emergence of universal power-law dynamics with exponent approximately 1. The work includes both theoretical analysis and extensive empirical validation across different model configurations and training scenarios.

## Key Results
- Analytic theory shows training exponent depends on both input data statistics and channel importance in no-superposition case
- Superposition bottleneck induces transition to universal power-law exponent of approximately 1
- Represents up to tenfold acceleration compared to sequential learning
- Optimal model size scales with compute budget
- Randomness in superposition bottleneck is near-optimal for mid-training dynamics

## Why This Works (Mechanism)
The mechanism underlying these results centers on how superposition bottlenecks alter the geometry of the optimization landscape. When features are forced to overlap in the bottleneck, the gradient dynamics become dominated by the most relevant features, creating a universal learning rate that leads to the exponent of 1. This contrasts with the no-superposition case where different features compete based on their individual statistics and importance, leading to variable exponents. The superposition effectively regularizes the learning dynamics, making them more predictable and faster by focusing the optimization on the most salient information.

## Foundational Learning
- **Power-law training dynamics**: The observation that neural network loss decreases as a power-law during training. Why needed: Forms the baseline behavior being modified by superposition. Quick check: Does loss follow L ~ t^(-α) where t is training steps?
- **Teacher-student framework**: A setup where a student network learns from a fixed teacher network. Why needed: Provides controlled environment to study feature learning. Quick check: Can the student perfectly represent the teacher's function given enough capacity?
- **Feature superposition**: When multiple features are encoded in overlapping representational dimensions. Why needed: The core mechanism that induces universal dynamics. Quick check: Do feature representations share common dimensions in the bottleneck?
- **Channel importance**: The relative significance of different input features for the task. Why needed: Determines learning rates in no-superposition case. Quick check: Can importance be measured by variance or gradient magnitude?
- **Optimization landscape geometry**: How the loss surface is shaped in parameter space. Why needed: Explains why superposition changes learning dynamics. Quick check: Does the Hessian have specific spectral properties?

## Architecture Onboarding

**Component map:**
Teacher network -> Bottleneck superposition layer -> Student network -> Loss function

**Critical path:**
Input features → Teacher network computation → Bottleneck projection → Student network learning → Gradient update

**Design tradeoffs:**
- No-superposition: Allows parallel learning but with variable exponents dependent on data statistics
- Superposition: Forces universal exponent but may require careful bottleneck sizing
- Random initialization: Near-optimal for mid-training but may not be globally optimal

**Failure signatures:**
- Exponent deviating significantly from 1 in superposition case
- Training instability when bottleneck is too small
- Loss plateaus when channel importance is highly imbalanced

**First experiments:**
1. Measure training exponent with varying bottleneck sizes
2. Compare learning dynamics with random vs. structured superposition
3. Test scaling laws for optimal model size vs. compute budget

## Open Questions the Paper Calls Out
None

## Limitations
- Analytic theory relies on simplifying assumptions about input statistics that may not hold in realistic deep learning scenarios
- Empirical demonstration of universal exponent shows some variance across different configurations
- Claims about acceleration compared to sequential learning may not generalize across all architectures
- Theory assumes specific teacher-student framework that may not capture all aspects of real neural network training
- Near-optimality of random superposition bottlenecks based on limited experiments

## Confidence
- Analytic theory for no-superposition case: Medium confidence (relies on simplifying assumptions)
- Universal exponent of approximately 1 in superposition: High confidence with moderate uncertainty (well-supported but shows variance)
- Tenfold acceleration claim: Medium confidence (supported by specific results but may not generalize)
- Random superposition optimality: Medium confidence (limited systematic exploration)

## Next Checks
1. Test superposition effects across different neural network architectures beyond the teacher-student framework, particularly modern deep architectures
2. Validate the scaling predictions with real-world datasets and training scenarios, comparing against standard power-law observations
3. Conduct a more systematic study of initialization strategies for the superposition bottleneck to confirm the near-optimality of random initialization across different training regimes