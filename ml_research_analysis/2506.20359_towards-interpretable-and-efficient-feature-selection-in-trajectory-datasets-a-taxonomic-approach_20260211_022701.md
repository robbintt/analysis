---
ver: rpa2
title: 'Towards Interpretable and Efficient Feature Selection in Trajectory Datasets:
  A Taxonomic Approach'
arxiv_id: '2506.20359'
source_url: https://arxiv.org/abs/2506.20359
tags:
- feature
- selection
- features
- data
- taxonomy-based
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates a taxonomy-based feature selection approach
  for trajectory datasets to address the problem of feature explosion caused by the
  extraction of numerous features from movement data. The proposed method organizes
  features into a hierarchical taxonomy based on geometric and kinematic properties,
  reducing the combinatorial space for feature selection.
---

# Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach

## Quick Facts
- arXiv ID: 2506.20359
- Source URL: https://arxiv.org/abs/2506.20359
- Reference count: 35
- Key outcome: Taxonomy-based feature selection achieves comparable or superior predictive performance on trajectory datasets while significantly reducing computational time and providing interpretability through feature category analysis.

## Executive Summary
This paper addresses the feature explosion problem in trajectory datasets by proposing a taxonomy-based feature selection approach. The method organizes 72+ extracted features into a hierarchical taxonomy based on geometric and kinematic properties, reducing the combinatorial search space from exponential to 15 fixed combinations. Experiments on Arctic Fox, AIS, and Tropical Cyclone datasets with four machine learning models demonstrate that this approach achieves comparable or superior predictive performance, particularly with Random Forest, while drastically reducing computational time. The taxonomy also provides interpretability by identifying which feature categories are most sensitive to each dataset.

## Method Summary
The method extracts 72 statistical features from trajectory data (curvature, indentation, speed, and acceleration metrics), maps them to 4 taxonomic categories, and performs exhaustive search across all 15 non-empty combinations of these categories. This is compared against classical wrapper methods (forward/backward selection) that search the full feature space. The approach uses 4 machine learning models (Logistic Regression, Random Forest, XGBoost, and MLP) with 5-fold stratified cross-validation and Weighted-F1 as the evaluation metric. Feature extraction uses Scipy and Geopy libraries, with preprocessing including StandardScaler and SimpleImputer for missing values.

## Key Results
- Taxonomy-based selection achieved comparable or superior Weighted-F1 scores compared to wrapper methods across all datasets and models
- Random Forest particularly benefited from taxonomy-based selection, suggesting alignment with tree-based split logic
- Computational time was drastically reduced due to the smaller search space (15 combinations vs. exponential search)
- Arctic Fox dataset favored taxonomy method, indicating effectiveness with small datasets
- Speed and acceleration features were frequently selected across datasets, indicating sensitivity to kinematic properties

## Why This Works (Mechanism)

### Mechanism 1: Computational Efficiency Through Reduced Search Space
- Traditional wrapper methods search $2^N$ feature combinations; taxonomy reduces this to $2^K$ category combinations
- Grouping 72+ features into 4 categories shrinks search space from exponential to 15 fixed combinations
- Core assumption: Features within taxonomic groups are sufficiently correlated to preserve signal when grouped
- Break condition: If features within a category are highly uncorrelated, grouping dilutes discriminative signal

### Mechanism 2: Domain-Regularization Through Semantic Grouping
- Semantic categories (Geometric vs. Kinematic) act as regularization, preventing overfitting to statistical quirks
- Forces models to rely on broader movement behaviors rather than micro-patterns
- Core assumption: Taxonomy aligns with underlying data generation process
- Break condition: If classes are defined by subtle micro-patterns rather than aggregate properties, taxonomic smoothing washes out signal

### Mechanism 3: Interpretability Through Dataset Sensitivity Analysis
- Exhaustive search identifies which physical properties drive classification by analyzing frequency of best-performing subsets
- Core assumption: High-performing subsets imply semantic importance
- Break condition: Multicollinearity between categories makes frequency analysis misleading

## Foundational Learning

- **Feature Explosion (Curse of Dimensionality)**: Adding too many statistical features from trajectories reduces model efficiency and increases redundancy. Quick check: Why does adding more features potentially reduce model accuracy in trajectory data?

- **Wrapper vs. Filter Methods**: Wrapper methods (like forward/backward selection) are computationally expensive but accurate by iteratively adding/removing features. Quick check: Why are wrapper methods generally more computationally intensive than filter methods?

- **Movement Primitives (Kinematics vs. Geometry)**: Taxonomy splits features into Geometry (Shape: Curvature/Indentation) and Kinematics (Motion: Speed/Acceleration). Quick check: Would classifying vessel types rely more on geometric path shape or kinematic speed profiles?

## Architecture Onboarding

- **Component map**: Raw CSV → Feature Extraction (72 stats) → Taxonomic Mapping (4 categories) → Feature Selection (15 combos) → Model Training (4 models) → Evaluation (Weighted-F1)

- **Critical path**: Feature Extraction & Mapping step - incorrect calculations or mis-mapped features invalidate the semantic argument

- **Design tradeoffs**: Taxonomy trades granularity for speed; interpretability for precision; provides semantic insights but not specific statistical aggregations

- **Failure signatures**: Hyperparameter instability (tuning sometimes reduced performance), low-signal domains (Tropical Cyclone poor results), incorrect feature extraction/mapping

- **First 3 experiments**:
  1. Sanity Check: Run pipeline on Arctic Fox to verify taxonomy completes faster than backward selection
  2. Noise Robustness Test: Add synthetic noise to AIS labels to test taxonomy's robustness vs. wrappers
  3. Sensitivity Ablation: Remove kinematic category from AIS to validate vessel classification depends on speed/acceleration

## Open Questions the Paper Calls Out

### Open Question 1: Can backward deletion and forward selection algorithms be adapted to operate within taxonomic hierarchy?
- Paper proposes implementing selection algorithms within taxonomy to handle larger taxonomies while decreasing computational complexity
- Unresolved: Current brute-force approach becomes infeasible as taxonomic categories grow
- Resolution needs: Study comparing hierarchical taxonomic search algorithms against brute-force on larger taxonomies

### Open Question 2: Can clustering techniques be applied at taxonomic level to reduce redundancy?
- Paper suggests clustering at taxonomic level to eliminate redundant features while maintaining interpretability
- Unresolved: Current taxonomy doesn't handle statistical redundancy within groups
- Resolution needs: Experiments showing clustering maintains/improves performance vs. standard taxonomy

### Open Question 3: To what extent does taxonomy-based selection quantitatively reduce computational time?
- Paper observed taxonomy was "much faster" but didn't quantitatively measure timing
- Unresolved: Efficiency claims lack empirical benchmarking
- Resolution needs: Exact time measurements comparing taxonomy vs. wrapper methods

## Limitations
- Taxonomy effectiveness relies on semantic grouping aligning with data generation process; may wash out discriminative signals for micro-pattern-defined classes
- Requires careful feature engineering for accurate extraction and proper mapping to taxonomic categories
- Multicollinearity between categories can make frequency-based interpretability analysis misleading

## Confidence

- **High confidence**: Computational efficiency gains - well-supported by reduced search space
- **Medium confidence**: Predictive performance claims - results show comparable/superior performance but depend on dataset characteristics
- **Medium confidence**: Interpretability claims - frequency analysis provides insights but may be misleading with multicollinearity

## Next Checks

1. **Sanity Check**: Run pipeline on Arctic Fox dataset to verify taxonomy method completes significantly faster than backward selection

2. **Noise Robustness Test**: Introduce synthetic noise to AIS dataset labels to test taxonomy's robustness compared to wrapper methods

3. **Sensitivity Ablation**: Remove kinematic category from AIS dataset to validate the paper's claim about vessel classification depending on speed/acceleration features