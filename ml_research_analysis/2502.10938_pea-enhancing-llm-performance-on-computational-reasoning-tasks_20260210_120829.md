---
ver: rpa2
title: 'PEA: Enhancing LLM Performance on Computational-Reasoning Tasks'
arxiv_id: '2502.10938'
source_url: https://arxiv.org/abs/2502.10938
tags:
- location
- package
- city
- truck
- block
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces the Predicate-Enumeration-Aggregation (PEA)
  framework, a formal approach to describe and solve computational reasoning problems
  using first-order logic. PEA decomposes problems into predicate, enumeration, and
  aggregation components, employing LLMs to synthesize programs for exhaustive enumeration
  and evaluation.
---

# PEA: Enhancing LLM Performance on Computational-Reasoning Tasks

## Quick Facts
- arXiv ID: 2502.10938
- Source URL: https://arxiv.org/abs/2502.10938
- Authors: Zi Wang; Shiwei Weng; Mohannad Alhanahnah; Somesh Jha; Tom Reps
- Reference count: 36
- Primary result: PEA improves LLM accuracy on computational reasoning tasks by ~50% compared to direct reasoning methods

## Executive Summary
This paper introduces the Predicate-Enumeration-Aggregation (PEA) framework to enhance large language model (LLM) performance on computational reasoning tasks. PEA decomposes problems into three components—predicate evaluation, enumeration generation, and result aggregation—using LLMs to synthesize executable programs rather than performing reasoning directly. The approach achieves approximately 50% average accuracy improvement over direct reasoning methods on SAT, Game of 24, and planning tasks while significantly reducing computation time through efficient program synthesis and execution.

## Method Summary
PEA transforms computational reasoning problems into first-order logic expressions, then decomposes them into predicate, enumeration, and aggregation components. LLMs synthesize Python code implementing three functions based on structured prompts. The framework validates synthesized code through syntactic checks (AST parsing) and semantic validation (execution on one held-out example). For problems with large search spaces, PEA employs optimized enumeration strategies generated by LLMs. The approach targets NP-complete problems like SAT and PSPACE problems like optimal planning, using exhaustive enumeration implemented in deterministic code rather than LLM reasoning chains.

## Key Results
- PEA achieves perfect accuracy on SAT instances where direct reasoning methods show significant accuracy drops
- For Game of 24, PEA achieves 98.8% accuracy versus 49.4% for direct reasoning and 48.5% for Chain-of-Thought
- Blocksworld and Logistics planning tasks show 30.4% and 28.1% accuracy improvements respectively over baseline methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Program synthesis offloads enumeration-heavy reasoning from LLMs to deterministic code execution.
- Mechanism: LLMs generate three functions (predicate evaluator, enumerator, aggregator) that implement brute-force search. The program's execution—not the LLM's tokens—produces the reasoning trace. For problems with O(n³) or exponential reasoning length, the program description remains O(n).
- Core assumption: LLMs synthesize correct code more reliably than they directly produce exhaustive reasoning chains.
- Evidence anchors:
  - [abstract] "PEA decomposes these problems into predicate and enumeration components, using LLMs to synthesize programs based on specified predicates, enumeration, and aggregation rules."
  - [section 4.1] "For coverage below 10%, LLMs provide permutation-generation instructions rather than explicit results"—demonstrating LLMs default to programmatic approaches for large enumerations.
  - [corpus] Weak direct support; related papers discuss LLM reasoning broadly but not this specific decomposition mechanism.
- Break condition: When code synthesis fails validation (syntax/semantic errors persist beyond iteration budget m=10), the pipeline returns empty and produces no solution.

### Mechanism 2
- Claim: First-order logic formalization maps computational complexity classes to structured program templates.
- Mechanism: Existential quantifiers (∃x.P(x)) map to disjunction-based aggregation (any candidate succeeds); universal quantifiers (∀x.P(x)) map to conjunction (all must succeed). This allows PEA to handle NP (SAT), co-NP (tautology), and harder PSPACE problems through the same enumeration-aggregation pattern.
- Core assumption: The target problem can be expressed with efficiently decidable predicates over finite domains.
- Evidence anchors:
  - [section 3.2] "The SAT problem can be expressed in the following form: ∃x. P(x), where P(x): φ(x) = 1"
  - [section 3.3] "For an existentially quantified predicate: ∃x ∈ X². P(x) = P(c₁,c₁) ∨ P(c₁,c₂) ∨ P(c₂,c₁) ∨ P(c₂,c₂)"
  - [corpus] No direct corpus validation of this formalization's novelty.
- Break condition: Problems requiring infinite domains or undecidable predicates fall outside PEA's scope.

### Mechanism 3
- Claim: Validation loops with sanity checks ensure synthesized programs correctly implement the PEA structure before deployment.
- Mechanism: Two-stage validation—syntactic (AST parsing for function presence, I/O types, non-empty definitions) and semantic (execution on one held-out example comparing output to expected). Programs must pass both within m=10 iterations.
- Core assumption: One example provides sufficient signal for semantic correctness across the dataset.
- Evidence anchors:
  - [section 3.5] "Code integrity is checked through syntactic and semantic validation... Semantic checking executes the generated code with a fixed example... and compares the output to the expected result."
  - [section 4] "successful code generation typically necessitates fewer than three LLM queries to pass integrity checks"
  - [corpus] Not addressed in corpus papers.
- Break condition: If the validation example is unrepresentative or contains errors, semantically incorrect programs may pass and produce wrong answers on the full dataset.

## Foundational Learning

- Concept: **First-order logic with quantifiers** (∃, ∀)
  - Why needed here: Understanding how PEA maps problems to quantified predicates is essential for correctly structuring the three-function decomposition.
  - Quick check question: Given "find if any assignment of 3 booleans satisfies formula F," write the formal expression using ∃.

- Concept: **Computational complexity classes (NP, co-NP, PSPACE)**
  - Why needed here: The paper frames PEA's applicability in terms of problem complexity; knowing why 3-SAT is harder than 2-SAT informs when enumeration is tractable.
  - Quick check question: Why does the paper separate 2-SAT results (P-class) from 3-SAT/4-SAT (NP-complete)?

- Concept: **Breadth-first search for optimal planning**
  - Why needed here: The Blocksworld and Logistics tasks use BFS in the aggregation function; understanding state-space search clarifies how enumeration connects to solution finding.
  - Quick check question: In the Blocksworld prompt, why does the aggregation function use BFS rather than DFS?

## Architecture Onboarding

- Component map: Input -> LLM Synthesis -> Validator -> Executor -> Output
- Critical path: Getting valid code through sanity checks. If m iterations exhausted, pipeline fails. The paper reports <3 queries typically suffice, but failure here means no fallback.
- Design tradeoffs:
  - Naive enumeration (simple synthesis, may timeout) vs. optimized enumeration (complex synthesis, faster execution)—the paper shows GPT-4o failed to synthesize optimized Logistics code, causing 207/285 timeouts.
  - One-example semantic validation (cheap, may miss edge cases) vs. multi-example validation (more robust, higher cost per synthesis).
  - Reusing one synthesized program across dataset (amortized cost, assumes homogeneity) vs. per-instance synthesis.
- Failure signatures:
  - Timeout during execution → enumeration space too large without optimization
  - Empty return from Algorithm 1 → synthesis failed all m iterations
  - Low accuracy despite passing validation → semantic check example was unrepresentative
- First 3 experiments:
  1. **Reproduce SAT baseline**: Implement PEA prompt for 3-SAT, verify GPT-4o achieves perfect accuracy on the 172+27 instances. This validates the core pipeline.
  2. **Stress-test enumeration limits**: Run permutation enumeration experiment (Table 1) with your target LLM to characterize where it switches from explicit listing to code generation. This establishes feasibility bounds.
  3. **Ablate validation**: Remove semantic checking and measure accuracy drop on Game of 24. This quantifies the validation loop's contribution to reliability.

## Open Questions the Paper Calls Out
None

## Limitations
- The approach requires problems to be expressible with efficiently decidable predicates over finite domains, excluding many real-world reasoning tasks
- Semantic validation using one example risks approving incorrect programs when the example is unrepresentative
- The optimization step for enumeration is not fully specified and failed for GPT-4o on Logistics tasks

## Confidence
- **High confidence**: The basic mechanism of decomposing reasoning into predicate-enumeration-aggregation and validating code synthesis is sound
- **Medium confidence**: The 50% average accuracy improvement claim is robust within the studied benchmarks but generalizability is uncertain
- **Low confidence**: The claimed significant reduction in computation time relies heavily on the optional optimization step, which had mixed success across models

## Next Checks
1. Apply PEA to a new computational reasoning benchmark outside the paper's scope (e.g., graph coloring or constraint satisfaction) to test whether the 50% improvement generalizes.
2. Intentionally provide incorrect but superficially plausible examples for semantic checking and measure how often invalid programs pass validation and produce wrong answers.
3. Run the Logistics task with and without enumeration optimization enabled, measuring both success rates and execution times to isolate the optimization step's contribution to claimed efficiency gains.