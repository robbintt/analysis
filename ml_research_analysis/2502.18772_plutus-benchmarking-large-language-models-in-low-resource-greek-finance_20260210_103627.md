---
ver: rpa2
title: 'Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance'
arxiv_id: '2502.18772'
source_url: https://arxiv.org/abs/2502.18772
tags:
- financial
- greek
- language
- arxiv
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Plutus-ben, the first Greek financial evaluation
  benchmark, and Plutus-8B, the first Greek financial large language model. The benchmark
  covers five core financial NLP tasks including numeric and textual named entity
  recognition, question answering, abstractive summarization, and topic classification.
---

# Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance

## Quick Facts
- **arXiv ID:** 2502.18772
- **Source URL:** https://arxiv.org/abs/2502.18772
- **Reference count:** 40
- **Primary result:** Introduces Plutus-ben, the first Greek financial evaluation benchmark, and Plutus-8B, the first Greek financial LLM, with expert-annotated datasets

## Executive Summary
This paper introduces Plutus-ben, the first Greek financial evaluation benchmark, and Plutus-8B, the first Greek financial large language model. The benchmark covers five core financial NLP tasks including numeric and textual named entity recognition, question answering, abstractive summarization, and topic classification. To support these tasks, the authors developed three high-quality Greek financial datasets (GRFinNUM, GRFinNER, GRFinQA) annotated by expert native Greek speakers, along with two existing resources. The comprehensive evaluation of 22 LLMs reveals that Greek financial NLP remains challenging due to linguistic complexity, domain-specific terminology, and financial reasoning gaps. Plutus-8B, fine-tuned on Greek financial data, achieves state-of-the-art performance with a mean score of 0.60, outperforming GPT-4 by 15.38% and GPT-4o by 46.34%. The study highlights the limitations of cross-lingual transfer and demonstrates the necessity of financial expertise in Greek-trained models. All datasets and models are publicly released to advance Greek financial NLP research.

## Method Summary
The authors developed Plutus-ben, a comprehensive Greek financial evaluation benchmark covering five core NLP tasks: numeric and textual named entity recognition, question answering, abstractive summarization, and topic classification. They created three new high-quality Greek financial datasets (GRFinNUM, GRFinNER, GRFinQA) through expert annotation by native Greek speakers with financial expertise. These datasets, along with two existing resources, were used to fine-tune and evaluate 22 large language models. The evaluation methodology employed rigorous testing across all benchmark tasks, with particular attention to Greek-specific linguistic challenges and domain-specific financial terminology.

## Key Results
- Plutus-8B achieves state-of-the-art performance with a mean score of 0.60
- Outperforms GPT-4 by 15.38% and GPT-4o by 46.34% on the Greek financial benchmark
- Greek financial NLP remains challenging due to linguistic complexity and domain-specific terminology

## Why This Works (Mechanism)
The success of Plutus-8B stems from targeted fine-tuning on domain-specific Greek financial data rather than relying on cross-lingual transfer from English models. The expert-annotated datasets capture the unique morphological and syntactic features of Greek financial language, while incorporating specialized terminology and reasoning patterns essential for financial applications. By training on purpose-built Greek financial corpora, the model develops native language understanding that outperforms general-purpose models like GPT-4o, which struggle with Greek-specific linguistic nuances despite their overall capabilities.

## Foundational Learning

**Greek Financial Terminology** - Understanding domain-specific vocabulary unique to Greek financial markets and regulatory contexts is essential for accurate entity recognition and question answering. Quick check: Verify model correctly identifies Greek financial instruments like "τράπεζα" (bank) and "μετοχή" (share) in context.

**Morphological Complexity** - Greek's rich inflectional system affects how financial terms appear in different grammatical contexts. Quick check: Test model's ability to recognize financial entities across various morphological forms and cases.

**Cross-Lingual Transfer Limitations** - Direct transfer of knowledge from English financial models fails due to linguistic and cultural differences in financial reporting and terminology. Quick check: Compare performance of English-finetuned vs Greek-finetuned models on identical financial concepts.

**Financial Reasoning Patterns** - Greek financial documents follow specific reasoning structures and argumentation styles that differ from other languages. Quick check: Evaluate model's ability to follow logical chains in Greek financial analysis and reporting.

## Architecture Onboarding

**Component Map:** Data Annotation -> Dataset Creation -> Model Fine-tuning -> Benchmark Evaluation -> Performance Analysis

**Critical Path:** Expert annotation of Greek financial data → Creation of specialized datasets → Fine-tuning Plutus-8B on Greek financial corpora → Comprehensive benchmark evaluation across five tasks

**Design Tradeoffs:** The authors prioritized domain-specific expertise over model scale, choosing to fine-tune an 8B parameter model on high-quality Greek financial data rather than using larger general-purpose models. This approach sacrifices some raw computational power for improved task-specific performance and language authenticity.

**Failure Signatures:** Cross-lingual transfer models fail on Greek-specific morphological variations and domain terminology. Models without financial expertise struggle with reasoning tasks requiring domain knowledge. General-purpose models show degraded performance on numeric entity recognition in Greek financial contexts.

**First 3 Experiments:** 1) Test Plutus-8B on each of the five benchmark tasks individually to identify specific strengths and weaknesses. 2) Compare performance across different dataset sizes to establish minimum effective training data requirements. 3) Evaluate model's ability to generalize to unseen financial subdomains not represented in training data.

## Open Questions the Paper Calls Out
None

## Limitations
- The relatively small scale of annotated datasets (5K-4K samples) may limit robustness and generalization across diverse financial contexts
- Inter-annotator agreement metrics are not reported, making it difficult to assess annotation consistency
- Benchmark coverage may not fully represent all real-world Greek financial applications, particularly time-series analysis or regulatory compliance tasks

## Confidence
- **High confidence:** Plutus-ben is indeed the first Greek financial evaluation benchmark; Plutus-8B is the first Greek financial LLM; the benchmark covers the stated five NLP tasks; three new Greek financial datasets were created with expert annotation.
- **Medium confidence:** The 15.38% and 46.34% performance improvements over GPT-4 variants are accurate within the evaluation setup but may not generalize across all financial reasoning scenarios; cross-lingual transfer limitations are observed but mechanistic explanations could be deeper.
- **Low confidence:** Claims about the necessity of financial expertise in Greek-trained models are asserted but not empirically validated through ablation studies comparing models trained with vs without financial experts.

## Next Checks
1. Conduct inter-annotator agreement analysis (Cohen's kappa or similar) on the GRFin datasets to quantify annotation reliability and identify potential inconsistencies in financial entity labeling or answer extraction.
2. Perform ablation studies comparing Plutus-8B against versions trained without financial expert involvement to empirically validate the claimed necessity of domain expertise in model development.
3. Extend evaluation to include financial reasoning tasks not covered in the current benchmark (e.g., trend analysis, regulatory document interpretation) to test whether performance gains transfer beyond the five core tasks.