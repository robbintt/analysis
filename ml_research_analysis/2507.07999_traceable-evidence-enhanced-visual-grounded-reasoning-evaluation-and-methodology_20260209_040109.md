---
ver: rpa2
title: 'Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology'
arxiv_id: '2507.07999'
source_url: https://arxiv.org/abs/2507.07999
tags:
- reasoning
- arxiv
- visual
- answer
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TreeBench, the first benchmark designed to
  evaluate visual grounded reasoning capabilities in large multimodal models. TreeBench
  emphasizes focused visual perception of subtle targets in complex scenes, traceable
  evidence through bounding box evaluation, and second-order reasoning beyond simple
  object localization.
---

# Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology

## Quick Facts
- **arXiv ID**: 2507.07999
- **Source URL**: https://arxiv.org/abs/2507.07999
- **Reference count**: 40
- **Primary result**: TreeVGR improves performance by +16.8 on V* Bench, +12.6 on MME-RealWorld, and +13.4 on TreeBench using dual IoU reward and cold-start SFT

## Executive Summary
This paper introduces TreeBench, the first benchmark designed to evaluate visual grounded reasoning capabilities in large multimodal models. TreeBench emphasizes focused visual perception of subtle targets in complex scenes, traceable evidence through bounding box evaluation, and second-order reasoning beyond simple object localization. The benchmark consists of 405 challenging visual question-answering pairs derived from 1K high-quality images, with small target objects occupying an average of 3.05% of the image area. Even state-of-the-art models like OpenAI-o3 achieve only 54.87% accuracy on this benchmark. To address these challenges, the authors propose TreeVGR, a training paradigm that jointly supervises localization and reasoning using reinforcement learning with a dual IoU reward. Initialized from Qwen2.5-VL-7B, TreeVGR demonstrates that traceable evidence is key to advancing vision-grounded reasoning.

## Method Summary
TreeVGR employs a two-stage training approach: cold-start supervised fine-tuning followed by traceable reinforcement learning. The method converts normalized coordinates from VGR-158K to absolute coordinates for Qwen2.5-VL-7B compatibility, filters for multi-box samples, and constructs reflective subsets with error injection. Cold-start SFT trains on 35K samples to establish grounding-then-answering patterns, followed by RL training on 37K samples (30K hard samples from V* and 7K from VisDrone counting) using GRPO with a dual IoU reward that balances precision and recall. The reward function combines accuracy judgment from Qwen2.5-72B-Instruct, format validation, and spatial localization metrics.

## Key Results
- TreeVGR achieves 91.1% on V* Bench, +16.8 over baseline
- Model reaches 83.5% on MME-RealWorld, +12.6 improvement
- TreeBench performance increases by +13.4, demonstrating traceable evidence effectiveness
- Dual IoU reward prevents box enumeration while ensuring complete localization
- Cold-start SFT reduces training time from 48 hours (47K samples) to 5 epochs (37K samples)

## Why This Works (Mechanism)

### Mechanism 1: Dual IoU Reward Balances Precision and Recall in Localization
Jointly optimizing precision and recall via dual IoU reward produces more accurate and complete localizations than accuracy-only supervision. The recall term ensures each ground-truth box has at least one matching prediction while the precision term penalizes spurious boxes that match nothing. Together, they prevent incomplete grounding (missing targets) and exhaustive enumeration (spamming candidate boxes). This works because the model learns to calibrate box generation quantity and quality when explicitly penalized for both false negatives and false positives.

### Mechanism 2: Cold-Start SFT Reduces RL Sample Inefficiency
Supervised fine-tuning with grounding trajectories before RL substantially accelerates convergence and reduces compute compared to RL-from-scratch. Cold-start SFT teaches the model the formatting and spatial reasoning patterns (outputting bounding boxes with reasoning chains), so RL can focus on refining rather than discovering the grounding-then-answering policy. This works because the SFT distribution is sufficiently aligned with the target RL task that initialization transfers without severe negative transfer.

### Mechanism 3: Traceable Evidence Correlates with Perception Performance
Higher localization accuracy (mIoU) positively correlates with perception-task performance, but the correlation weakens for complex reasoning tasks. Perception tasks (attributes, material, physical state) depend directly on identifying the correct visual region while reasoning tasks (perspective transform, spatial containment) require additional cognitive operations beyond localization. This works because perception tasks can be reduced to accurate spatial localization while reasoning requires logical operations that transcend precise spatial localization.

## Foundational Learning

- **Concept: Intersection-over-Union (IoU) for Spatial Evaluation**
  - Why needed: The dual IoU reward is fundamental to TreeVGR; you must understand IoU computation and its limitations
  - Quick check: Given two boxes with 50% overlap, what happens to IoU if one box doubles in size while maintaining the same overlap area?

- **Concept: Group Relative Policy Optimization (GRPO)**
  - Why needed: TreeVGR uses GRPO for RL training; understanding how group-based advantage estimation differs from PPO-style clipping is essential
  - Quick check: How does GRPO's group-wise normalization affect variance when sample groups have highly heterogeneous rewards?

- **Concept: Coordinate System Alignment (Normalized vs. Absolute)**
  - Why needed: TreeVGR converts normalized coordinates to absolute for Qwen2.5-VL; misalignment causes systematic grounding errors
  - Quick check: If a model trained on normalized coordinates receives absolute pixel coordinates at inference, what systematic bias would you expect in box predictions?

## Architecture Onboarding

- **Component map**: Qwen2.5-VL-7B-Instruct (base) -> TreeVGR-SFT-35K (SFT stage) -> TreeVGR-RL-37K (RL stage) -> Dual IoU reward with GRPO optimizer

- **Critical path**:
  1. Convert VGR-158K coordinates from normalized to absolute
  2. Filter for multi-box samples, construct reflective subset with error injection
  3. Train TreeVGR-7B-CI with SFT (5e-6 lr, cosine decay, 256 global batch)
  4. Prepare RL dataset with ground-truth bounding box annotations
  5. Train with GRPO using R = R_acc + R_format + R_IoU

- **Design tradeoffs**:
  - 7B vs. larger models: Authors acknowledge 7B limits scalability but enables efficient experimentation
  - Text-space grounding vs. image cropping: TreeVGR avoids replaying cropped images, trading visual fidelity for training efficiency
  - Benchmark size vs. quality: TreeBench has only 405 samples, prioritizing annotation quality over statistical power

- **Failure signatures**:
  - Response length explosion during RL: indicates missing precision term
  - High accuracy but low mIoU: indicates missing recall term
  - Format violations in outputs: indicates insufficient formatting reward weight

- **First 3 experiments**:
  1. Reproduce cold-start baseline: Train Qwen2.5-VL-7B on TreeVGR-SFT-35K without RL; evaluate on V* Bench to verify +5-6 point gain
  2. Ablate dual IoU components: Run RL with only recall term, only precision term, and both; measure mIoU and accuracy gap on TreeBench perception vs. reasoning subsets
  3. Cross-benchmark transfer: Evaluate TreeVGR-7B on AI2D, MathVista, and MMStar to confirm performance decoupling from traditional multimodal benchmarks

## Open Questions the Paper Calls Out
- Can the TreeVGR training paradigm maintain its efficiency and performance gains when scaled to architectures significantly larger than the 7B parameter model?
- Do the performance rankings of state-of-the-art models hold when TreeBench is expanded to cover a wider diversity of domains and complex scenes?
- What specific training mechanisms are required to bridge the gap between precise visual localization (high mIoU) and successful second-order cognitive reasoning?

## Limitations
- TreeBench's small scale (405 samples) limits statistical power for detecting fine-grained performance differences between top models
- Ground-truth annotation fidelity assumptions may not hold if annotations miss subtle targets or contain ambiguity
- Cross-dataset generalization effectiveness for domains outside VGR-158K distribution remains unproven

## Confidence
- **High**: Claims about TreeBench's novel focus on small targets (3.05% average area) and the state-of-the-art performance gap (54.87% OpenAI-o3 accuracy)
- **Medium**: Claims about dual IoU reward effectiveness and cold-start SFT acceleration, supported by ablation studies and training efficiency metrics
- **Low**: Claims about localization-recall correlation without independent validation of ground-truth annotation quality

## Next Checks
1. Conduct inter-annotator agreement studies on 100 randomly sampled TreeBench bounding boxes to quantify annotation reliability
2. Evaluate TreeVGR-7B on MathVista, AI2D, and MMStar beyond reported Table 5 to assess generalization
3. Create synthetic benchmark with increasing numbers of small targets (2-10) to test dual IoU reward effectiveness under enumeration pressure