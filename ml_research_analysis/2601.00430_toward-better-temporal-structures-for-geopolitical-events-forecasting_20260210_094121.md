---
ver: rpa2
title: Toward Better Temporal Structures for Geopolitical Events Forecasting
arxiv_id: '2601.00430'
source_url: https://arxiv.org/abs/2601.00430
tags:
- facts
- entities
- temporal
- 'true'
- 'false'
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the limitation of existing temporal knowledge
  graph structures in representing complex geopolitical events involving multiple
  entities. It introduces Hyper-Relational Temporal Knowledge Generalized Hypergraphs
  (HTKGHs) to efficiently express such events and presents the htkgh-polecat dataset
  built on POLECAT.
---

# Toward Better Temporal Structures for Geopolitical Events Forecasting

## Quick Facts
- arXiv ID: 2601.00430
- Source URL: https://arxiv.org/abs/2601.00430
- Reference count: 16
- The study introduces Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs) for representing complex geopolitical events and evaluates LLMs on relation prediction tasks, showing strong adaptability with performance gains from test-time scaling.

## Executive Summary
This paper addresses the limitations of existing temporal knowledge graph structures in representing complex geopolitical events involving multiple entities. It introduces HTKGHs to efficiently capture such events and presents the htkgh-polecat dataset built on POLECAT. The study evaluates popular LLMs on relation prediction tasks, showing their strong adaptability and resilience, with performance improvements through test-time scaling and larger context. LLMs outperform supervised graph-based models when high-quality context is provided, highlighting their potential for complex forecasting scenarios.

## Method Summary
The study constructs HTKGH facts from POLECAT event data, filtering to keep only facts with actors or actors+recipients. For each test query, it retrieves up to 100 historical facts using entity, location, and context filters. LLMs perform in-context learning using formatted prompts, while GNNs use window encoders with hypergraph aggregators. The primary metric is relation prediction accuracy compared against frequency, recency, and copy heuristics. GNNs are trained for 8 epochs with AdamW optimizer and learning rate sweeps.

## Key Results
- LLMs show strong adaptability to temporal relation prediction tasks, with performance scaling positively with context relevance
- Thinking models (Qwen3 family) achieve 6.0-7.6% accuracy gains over non-thinking variants
- LLMs outperform GNNs by up to 21% accuracy when high-quality context filtering is applied
- Strict filtering (entity + location + context) significantly improves LLM performance while GNNs show flat results across filter settings

## Why This Works (Mechanism)

### Mechanism 1
HTKGH extends HTKG by allowing edges to connect arbitrary entity sets rather than single entity pairs. Second-order edges between first-order edges reintroduce directionality and enable Set2Set relationships. This avoids redundancy and sparsity introduced by decomposing n-ary facts into multiple binary edges. Core assumption: Real-world geopolitical events frequently involve >2 primary entities in semantically meaningful ways.

### Mechanism 2
LLMs receive historical facts as context and predict missing relations through pattern recognition. Performance improves when context is filtered by entity overlap, location, and contextual relevance. Thinking models generate internal reasoning chains before prediction, yielding 6.0-7.6% gains over non-thinking variants. Core assumption: LLMs' pre-training on diverse text corpora transfers to structured temporal reasoning patterns.

### Mechanism 3
High-quality context retrieval enables LLMs to outperform GNNs that have inherent information bottlenecks in window-level aggregation. GNNs aggregate all facts within time windows into single vectors before temporal encoding, creating bottlenecks when context is sparse but relevant. LLMs attend to individual facts directly. Core assumption: The bottleneck arises from window-level pooling rather than insufficient model capacity.

## Foundational Learning

- **Hyper-relational temporal knowledge graphs (HTKGs)**: Understanding baseline HTKG structure (quadruples + qualifiers) is prerequisite for grasping HTKGH's extensions. HTKGH adds backward-compatible support for entity sets.
  - Quick check: Can you write the formal definition of an HTKG fact with qualifiers?

- **Forecasting vs. completion queries**: The paper explicitly focuses on forecasting (prediction using only pre-query timestamps). This constraint affects model selectionâ€”supervised models require temporally-stratified splits.
  - Quick check: Given a test query at time t=2024, which historical facts can a forecasting model access?

- **Generalized hypergraphs with second-order edges**: This is the core structural innovation. Second-order edges between first-order edges enable directional relationships between entity sets.
  - Quick check: How would you represent "US and UK sanction Russia and Belarus in 2022" using HTKGH formalization?

## Architecture Onboarding

- **Component map**: POLECAT data -> HTKGH facts -> Entity/location/context filters -> LLM/GNN models -> Relation prediction accuracy
- **Critical path**: 1) Construct HTKGH facts from raw POLECAT events 2) Retrieve filtered historical context for each test query 3) Format prompt with context samples + query + candidate relations 4) Extract prediction from LLM output
- **Design tradeoffs**: LLM flexibility vs. GNN efficiency; context quantity vs. relevance; thinking vs. non-thinking models (16K token overhead for +6-7.6% accuracy)
- **Failure signatures**: DeepSeek-R1-Distill-Qwen-7B shows high misformatting rates with increased context; Llama-3.1-8B-Instruct struggles with all filters enabled; GNNs show flat performance across filter settings
- **First 3 experiments**: 1) Replicate baseline heuristics on 1% stratified test set 2) Ablate context filters independently 3) Compare shuffled vs. regular entity variations

## Open Questions the Paper Calls Out

### Open Question 1
How can GNN architectures be redesigned to mitigate the information bottleneck caused by collapsing window representations in HTKGH forecasting? The authors note the current window encoding formulation introduces a bottleneck by collapsing facts. A new GNN architecture that preserves fine-grained fact-level details within temporal windows could resolve this.

### Open Question 2
What is the impact of HTKGH structure on query time and complexity compared to standard HTKGs when utilizing technologies like SPARQL? The Limitations section identifies querying time and complexity as an often overlooked criterion requiring future study.

### Open Question 3
Does HTKGH formalization and observed LLM adaptability generalize to non-geopolitical domains featuring complex multi-entity interactions? The authors state there are many other domains that could use such formalization, but the study is restricted to geopolitical events.

## Limitations
- HTKGH structure lacks empirical validation showing decomposed representations would fail for this dataset
- Significant performance gains from strict filtering may be partially attributed to data leakage or overly optimistic retrieval
- GNN baselines may not represent state-of-the-art temporal graph methods, particularly those using hierarchical attention

## Confidence

**High Confidence**: LLMs adapt well to temporal relation prediction tasks through in-context learning; thinking models provide 6.0-7.6% accuracy gains.

**Medium Confidence**: LLMs outperform GNNs with high-quality context; generalization claims to unseen relations and entities are reasonable but based on limited samples.

**Low Confidence**: HTKGH structure is strictly necessary for representing complex geopolitical events; claims about LLM resilience across different filter settings require more absolute performance data.

## Next Checks

1. **Ablation of HTKGH complexity**: Re-run experiments using decomposed binary relations (standard HTKG) to empirically verify whether the hypergraph structure provides measurable performance benefits over simpler representations.

2. **GNN architecture stress test**: Implement a GNN baseline that preserves fact-level granularity through hierarchical attention or separate entity embeddings rather than window-level pooling to determine if the observed LLM advantage persists.

3. **Retrieval bias analysis**: Systematically vary the proportion of relevant vs. irrelevant facts in the context window (synthetic mixing) to quantify the minimum relevance threshold required for LLMs to outperform heuristics.