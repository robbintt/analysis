---
ver: rpa2
title: Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic
  NLP
arxiv_id: '2508.03204'
source_url: https://arxiv.org/abs/2508.03204
tags:
- text
- data
- anonymization
- approaches
- pseudonymization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This report surveys domain-agnostic text anonymization techniques
  for NLP preprocessing, focusing on pseudonymization and ontology-driven approaches.
  The study highlights the challenge of protecting privacy in large language models
  trained on data containing personally identifiable information (PII), as such models
  can leak private data.
---

# Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic NLP

## Quick Facts
- arXiv ID: 2508.03204
- Source URL: https://arxiv.org/abs/2508.03204
- Reference count: 5
- Domain-agnostic text anonymization techniques surveyed for NLP preprocessing to protect PII in LLMs

## Executive Summary
This survey examines domain-agnostic text anonymization approaches for NLP preprocessing, addressing the critical challenge of protecting personally identifiable information (PII) in large language models. The study reviews pseudonymization techniques that replace PII with realistic substitutes and ontology-driven approaches using knowledge graphs for PII masking. Key findings highlight the privacy-utility tradeoff, with over-masking reducing data utility while under-masking risks privacy leakage. The authors identify limitations including limited non-English coverage, costly annotation requirements, and lack of standardized evaluation metrics.

## Method Summary
The survey synthesizes four main pseudonymization approaches: NER-based detection with Wikidata replacement, Seq2Seq fine-tuning on pseudonymized corpora, LLM-based extraction and substitution, and ontology-driven generalization with k-anonymity. No original experiments were conducted; instead, the authors analyze existing methodologies and their performance characteristics. The paper emphasizes the need for standardized evaluation metrics and domain-agnostic, multilingual approaches to advance privacy-preserving NLP preprocessing.

## Key Results
- NER-based, Seq2Seq, and LLM-based pseudonymization can reduce privacy leakage while preserving downstream task utility
- Ontology-driven approaches with k-anonymity show over-masking tendencies that reduce data utility
- Current methods are primarily evaluated on English corpora with limited coverage of non-English languages
- Lack of standardized evaluation metrics hinders cross-method comparison and field advancement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NER-based pseudonymization can reduce privacy leakage while preserving downstream task utility.
- Mechanism: Named Entity Recognition models identify PII-containing text spans (PERSON, LOC, ORG), which are then replaced with similar entity types sampled from the Wikidata Knowledge Graph under predefined constraints.
- Core assumption: The NER model accurately detects all privacy-sensitive spans, and replacement entities from Wikidata maintain semantic plausibility.
- Evidence anchors:
  - [abstract] "Experiments show that pseudonymization can preserve data utility while reducing privacy leakage, but results vary by method."
  - [section 2.1] "The detected text spans were replaced with similar types of named entities from Wikidata Knowledge Graph."
  - [corpus] Weak direct corpus support; neighbor papers focus on differential privacy rather than substitution-based approaches.
- Break condition: NER recall on quasi-identifiers falls below threshold, or Wikidata lacks coverage for domain-specific entities.

### Mechanism 2
- Claim: Seq2Seq models can learn to pseudonymize text when fine-tuned on NER-pseudonymized corpora.
- Mechanism: A BART model is fine-tuned on text pairs where the source is original text and the target is NER-pseudonymized text, learning to transform PII spans into plausible replacements as a sequence-to-sequence task.
- Core assumption: The silver-standard training data from NER-based pseudonymization is sufficiently accurate and diverse for the Seq2Seq model to generalize.
- Evidence anchors:
  - [section 2.1] "The authors used BART. This BART model was finetuned on a corpus of pseudonymized texts, generated by NER-based pseudonymization techniques."
  - [corpus] Corpus papers on differentially private text generation offer related but distinct generation approaches.
- Break condition: Domain shift between training and inference data causes the model to miss entity types or generate implausible replacements.

### Mechanism 3
- Claim: Ontology-driven generalization with k-anonymity can mask PII while preserving some utility, though over-masking remains a risk.
- Mechanism: An inverted index is constructed from a knowledge graph (e.g., Wikidata subset). Detected entities are generalized to broader ontology terms ensuring each entity is indistinguishable from at least k−1 others; if k-anonymity is violated, the algorithm selects terms via greedy or random selection.
- Core assumption: The ontology has sufficient hierarchical depth to provide useful generalizations, and entity-linking disambiguation is reliable.
- Evidence anchors:
  - [section 2.2] "k-anonymity was used to ensure each personally identifiable (PII-related) entity is indistinguishable from at least k−1 other entities of similar category."
  - [section 3] "For the ontology-driven PII-masking approach results show an over-masking tendency, resulting in low data utility."
  - [corpus] No direct corpus validation; neighbor papers emphasize differential privacy rather than k-anonymity.
- Break condition: Entity-linking ambiguity causes incorrect generalizations, or over-generalization renders text unintelligible for downstream tasks.

## Foundational Learning

- Concept: Named Entity Recognition (NER)
  - Why needed here: NER is the detection layer for all pseudonymization pipelines; understanding precision/recall tradeoffs is essential.
  - Quick check question: Can you explain how NER recall on quasi-identifiers differs from precision on direct identifiers?

- Concept: k-Anonymity
  - Why needed here: Ontology-based masking relies on k-anonymity to guarantee indistinguishability; understanding k selection is critical.
  - Quick check question: If k=5 and an entity class has only 3 members, what does the algorithm do?

- Concept: Knowledge Graphs and Entity Linking
  - Why needed here: Wikidata provides replacement candidates and generalization hierarchies; entity-linking ambiguity is a known failure mode.
  - Quick check question: How would you handle a mention like "Apple" that could refer to a fruit or a company?

## Architecture Onboarding

- Component map:
  - Detection Layer: NER models (e.g., RoBERTa-based sequence labelers) or LLM-based extractors (GPT-3)
  - Replacement Layer: Wikidata queries, fine-tuned Seq2Seq (BART), or LLM-based substitution (ChatGPT)
  - Generalization Layer: Ontology hierarchy traversal with k-anonymity enforcement
  - Evaluation Layer: Entity-level recall, token-level precision (per Pilán et al.), downstream task performance

- Critical path:
  1. Define PII entity types for your domain (start with PERSON, LOC, ORG; extend per Pilán et al.'s 8 categories)
  2. Select detection approach (NER vs. LLM-based) based on precision/recall requirements
  3. Choose replacement strategy (ontology lookup vs. Seq2Seq vs. LLM) considering latency and coverage
  4. Implement k-anonymity checks if using ontology generalization
  5. Evaluate on held-out data using both privacy metrics (recall on identifiers) and utility metrics (downstream task performance)

- Design tradeoffs:
  - NER-based + ontology: Higher precision, but limited to known entity types and subject to over-masking
  - Seq2Seq: Faster inference after fine-tuning, but inherits errors from silver training data
  - LLM-based: Highest flexibility, but higher latency and cost; quality depends on prompt design

- Failure signatures:
  - Over-masking: Text becomes generic ("PERSON_1 worked at ORG_1") → downstream model cannot learn domain patterns
  - Under-masking: Rare entity types missed by NER → privacy leakage persists
  - Implausible replacements: "John from Microsoft" becomes "Table from Toyota" → utility degradation

- First 3 experiments:
  1. Baseline NER evaluation: Measure precision/recall on PERSON, LOC, ORG using a manually annotated sample (n≥100) from your target domain.
  2. Replacement quality audit: For each pseudonymization method, manually review 50 transformed examples for semantic plausibility and privacy coverage.
  3. Downstream utility test: Train a text classifier on pseudonymized vs. original data; compare accuracy drop to quantify utility cost.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do pseudonymization techniques perform on PII categories beyond PERSON, LOC, and ORG?
- Basis in paper: [explicit] The authors note that current studies, specifically Yermilov et al. [YRC23], are limited to only three entity types, leaving the performance on other PII types mentioned in Pilán et al. [Pi22] unknown.
- Why unresolved: Current domain-agnostic research has restricted its scope, failing to evaluate whether models can handle the full spectrum of direct and indirect identifiers.
- What evidence would resolve it: Evaluation results from NER-based, Seq2Seq, and LLM-based pseudonymization on datasets annotated with diverse PII categories (e.g., demographics, codes).

### Open Question 2
- Question: Can domain-agnostic anonymization models be effectively adapted for languages with tokenization schemes significantly different from English?
- Basis in paper: [explicit] The paper highlights that existing experimentations were performed exclusively on English datasets, despite the fact that privacy-sensitive data exists in languages like German or Mandarin.
- Why unresolved: The transferability of current preprocessing approaches to languages with distinct linguistic structures remains unverified.
- What evidence would resolve it: Successful application and benchmarking of the discussed pseudonymization and ontology-driven methods on non-English corpora.

### Open Question 3
- Question: Does combining multiple anonymization approaches yield better utility and privacy preservation than single-method baselines?
- Basis in paper: [explicit] The authors suggest it "would be interesting to see how such multiple approaches can be combined" to address limitations like the over-masking found in ontology-driven methods.
- Why unresolved: There is no comparative analysis evaluating hybrid architectures against the standalone NER-based, Seq2Seq, or LLM-based approaches discussed in the survey.
- What evidence would resolve it: Ablation studies comparing hybrid models (e.g., ontology-aware Seq2Seq) against single-method models using standardized privacy and utility metrics.

## Limitations

- Lack of standardized evaluation metrics across privacy-preserving NLP approaches hinders cross-method comparison
- Current methods are primarily evaluated on English corpora, with limited coverage of non-English languages and tokenization schemes
- Over-masking tendency in ontology-driven approaches reduces data utility, creating fundamental privacy-utility tradeoffs

## Confidence

**High Confidence**: The general taxonomy of pseudonymization approaches (NER-based, Seq2Seq, LLM-based, ontology-driven) is well-established and corroborated by the corpus analysis. The privacy-utility tradeoff discussion aligns with broader ML literature.

**Medium Confidence**: Claims about specific performance characteristics (e.g., "over-masking tendency resulting in low data utility") are drawn from cited works but lack consolidated experimental validation across the field. The assertion that current approaches are "domain-agnostic" appears aspirational given most implementations focus on English text and limited entity types.

**Low Confidence**: Specific quantitative claims about method performance, resource requirements, or comparative effectiveness are not provided in this survey format. The paper does not present original experimental data to support methodological recommendations.

## Next Checks

1. **Ground truth validation**: Create a manually annotated dataset (n≥100) covering PERSON, LOC, ORG, and quasi-identifier categories from Pilán et al. to establish baseline entity recognition performance for your specific domain.

2. **Replacement quality audit**: For each pseudonymization method under consideration, manually review 50 transformed examples to assess semantic plausibility and privacy coverage, focusing on entity-linking accuracy and replacement appropriateness.

3. **Downstream utility measurement**: Train a text classification model on pseudonymized vs. original data from your domain; measure accuracy degradation to quantify the privacy-utility tradeoff and identify over-masking thresholds where utility becomes unacceptable.