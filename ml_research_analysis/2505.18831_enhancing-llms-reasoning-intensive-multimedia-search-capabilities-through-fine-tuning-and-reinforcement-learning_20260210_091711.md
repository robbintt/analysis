---
ver: rpa2
title: Enhancing LLMs' Reasoning-Intensive Multimedia Search Capabilities through
  Fine-Tuning and Reinforcement Learning
arxiv_id: '2505.18831'
source_url: https://arxiv.org/abs/2505.18831
tags:
- search
- arxiv
- language
- query
- searchexpert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of existing LLM-driven search
  agents in handling complex reasoning-intensive queries and multimedia content, particularly
  their reliance on prompt engineering and inefficient Python-based search plan representations.
  The authors propose SearchExpert, a two-stage training framework that introduces
  an efficient natural language representation for search plans, supervised fine-tuning
  for searching (SFTS) with automated dataset construction, and reinforcement learning
  from search feedback (RLSF) that uses search result quality as reward signals.
---

# Enhancing LLMs' Reasoning-Intensive Multimedia Search Capabilities through Fine-Tuning and Reinforcement Learning

## Quick Facts
- arXiv ID: 2505.18831
- Source URL: https://arxiv.org/abs/2505.18831
- Authors: Jinzheng Li; Sibo Ju; Yanzhou Su; Hongguang Li; Yiqing Shen
- Reference count: 40
- One-line primary result: SearchExpert achieves 82.33% accuracy on FinSearchBench-24 and 71.50% on SearchExpertBench-25, outperforming commercial search methods

## Executive Summary
This paper addresses the limitations of existing LLM-driven search agents in handling complex reasoning-intensive queries and multimedia content. Current approaches rely heavily on prompt engineering and use inefficient Python-based representations for search plans, making them difficult to optimize and scale. The authors propose SearchExpert, a comprehensive two-stage training framework that introduces an efficient natural language representation for search plans, enabling better optimization through fine-tuning and reinforcement learning.

The proposed framework includes supervised fine-tuning for searching (SFTS) with automated dataset construction and reinforcement learning from search feedback (RLSF) that uses search result quality as reward signals. Additionally, the system incorporates a multimedia understanding and generation agent to process visual inputs and outputs. Experimental results demonstrate significant improvements over commercial search methods, with SearchExpert achieving 82.33% accuracy on FinSearchBench-24 (vs. 76.20% for FinSearch) and 71.50% on SearchExpertBench-25 (vs. 32.50% for Perplexity Pro), while reducing token consumption by 42-53% compared to Python-based implementations.

## Method Summary
SearchExpert introduces a novel approach to LLM-driven search through a two-stage training framework. The first stage involves supervised fine-tuning for searching (SFTS), where the system learns from automatically constructed datasets generated by existing search engines. The second stage employs reinforcement learning from search feedback (RLSF), using the quality of search results as reward signals to optimize the search agent's behavior. A key innovation is the use of natural language representation for search plans, replacing the traditional Python-based approach that was inefficient and difficult to optimize. The framework also includes a multimedia understanding and generation agent capable of processing visual inputs and outputs, extending the system's capabilities beyond text-based search. This comprehensive approach addresses both the reasoning complexity of queries and the need to handle diverse multimedia content types.

## Key Results
- SearchExpert achieves 82.33% accuracy on FinSearchBench-24, outperforming FinSearch's 76.20%
- On SearchExpertBench-25, SearchExpert reaches 71.50% accuracy compared to Perplexity Pro's 32.50%
- The system reduces token consumption by 42-53% compared to Python-based search plan implementations
- Human evaluations confirm superior analytical completeness and reasoning capabilities

## Why This Works (Mechanism)
The effectiveness of SearchExpert stems from addressing the fundamental limitations of existing LLM search agents. By replacing Python-based search plan representations with natural language, the system becomes more interpretable and easier to optimize through fine-tuning and reinforcement learning. The natural language representation allows for more flexible and nuanced search strategies that can better handle complex reasoning tasks. The two-stage training approach combines the structured learning from supervised fine-tuning with the adaptive optimization of reinforcement learning, creating a system that can both learn from existing search patterns and improve through feedback. The integration of multimedia understanding capabilities enables the system to handle the full spectrum of modern search queries that often involve images, charts, and other visual content alongside text.

## Foundational Learning
- Natural Language Processing for Search: Needed to understand and process complex query structures; quick check: evaluate performance on multi-step reasoning queries
- Reinforcement Learning from Human Feedback: Required to optimize search strategies based on result quality; quick check: measure improvement in search accuracy across training iterations
- Multimedia Understanding: Essential for processing visual inputs and generating appropriate outputs; quick check: test system performance on image-based queries
- Automated Dataset Construction: Critical for scaling supervised fine-tuning without manual annotation; quick check: compare performance against manually curated datasets
- Search Plan Optimization: Fundamental for efficient query execution and resource management; quick check: measure token consumption and response time

## Architecture Onboarding

**Component Map:**
Input Query -> Natural Language Search Plan Generator -> Search Execution Module -> Result Processing -> Reinforcement Learning Feedback Loop -> Optimized Search Agent

**Critical Path:**
The critical path involves query understanding, search plan generation in natural language, execution through appropriate search APIs, result processing and synthesis, and feedback incorporation for optimization. The multimedia understanding agent operates in parallel to handle visual content.

**Design Tradeoffs:**
The choice of natural language over Python for search plans prioritizes interpretability and optimization flexibility over execution speed. The automated dataset construction trades potential data quality for scalability. The reinforcement learning approach balances immediate search effectiveness with long-term strategy optimization.

**Failure Signatures:**
Poor performance on highly specialized domain queries, difficulty with extremely long or complex reasoning chains, potential biases from the search engines used in automated dataset construction, and challenges with ambiguous or underspecified queries.

**3 First Experiments:**
1. Compare search accuracy and token efficiency between natural language and Python-based search plan representations
2. Evaluate the impact of SFTS alone versus the full two-stage training approach
3. Test multimedia understanding capabilities on image-based search queries with and without the specialized agent

## Open Questions the Paper Calls Out
None

## Limitations
- Automated dataset construction may introduce bias toward specific search engine behaviors
- RLSF depends on noisy reward signals that may not perfectly correlate with search effectiveness
- Evaluation relies on non-open-source benchmark datasets, limiting reproducibility
- Human evaluation introduces subjectivity and may not capture full performance across domains

## Confidence
- High confidence: Technical implementation of natural language search plan representation and basic performance improvements
- Medium confidence: Generalizability to domains beyond financial and general-purpose search
- Medium confidence: Claimed efficiency improvements (42-53% token reduction)

## Next Checks
1. Conduct ablation studies to isolate contributions of natural language representation, SFTS, and RLSF components
2. Test framework on additional benchmark datasets with different domain focuses for cross-domain evaluation
3. Implement controlled experiments comparing automated dataset construction against manually curated training data to assess potential biases