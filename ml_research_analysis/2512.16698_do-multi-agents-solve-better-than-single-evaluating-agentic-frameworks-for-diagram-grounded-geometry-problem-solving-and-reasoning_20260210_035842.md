---
ver: rpa2
title: Do Multi-Agents Solve Better Than Single? Evaluating Agentic Frameworks for
  Diagram-Grounded Geometry Problem Solving and Reasoning
arxiv_id: '2512.16698'
source_url: https://arxiv.org/abs/2512.16698
tags:
- line
- angle
- geometric
- point
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically compares single-agent and multi-agent
  pipelines for diagram-grounded geometry problem solving across four benchmarks.
  Open-source models (Qwen-2.5-VL 7B/32B) consistently improve with multi-agent decomposition,
  gaining up to 9.4% on OlympiadBench, while closed-source models like Gemini-2.0-Flash
  perform better in single-agent mode on classic benchmarks, with only modest gains
  on newer We-Math dataset.
---

# Do Multi-Agents Solve Better Than Single? Evaluating Agentic Frameworks for Diagram-Grounded Geometry Problem Solving and Reasoning

## Quick Facts
- arXiv ID: 2512.16698
- Source URL: https://arxiv.org/abs/2512.16698
- Reference count: 40
- Key outcome: Multi-agent pipelines achieve new SOTA zero-shot results with fewer parameters, showing agentic decomposition is beneficial for open-source models but not universally optimal

## Executive Summary
This study systematically compares single-agent and multi-agent pipelines for diagram-grounded geometry problem solving across four benchmarks. Open-source models (Qwen-2.5-VL 7B/32B) consistently improve with multi-agent decomposition, gaining up to 9.4% on OlympiadBench, while closed-source models like Gemini-2.0-Flash perform better in single-agent mode on classic benchmarks, with only modest gains on newer We-Math dataset. Multi-agent pipelines achieve new state-of-the-art zero-shot results with fewer parameters, demonstrating that agentic decomposition is beneficial for open-source models but not universally optimal.

## Method Summary
The study employs a controlled experimental design comparing single-agent and multi-agent pipelines across four geometry benchmarks. Four agentic pipelines were constructed: AgentIC (3-agent), AgentIIC (3-agent), AgentIS (3-agent), and AgentIIS (4-agent). These pipelines decompose geometry problem solving into specialized roles including diagram analysis, parsing, planning, and validation. The evaluation includes both open-source models (Qwen-2.5-VL 7B/32B) and closed-source models (Gemini-2.0-Flash), with zero-shot and few-shot settings. Performance is measured across three dimensions: diagram parsing, problem-solving, and final answer accuracy.

## Key Results
- Open-source models (Qwen-2.5-VL 7B/32B) consistently improve with multi-agent decomposition, gaining up to 9.4% on OlympiadBench
- Closed-source models like Gemini-2.0-Flash perform better in single-agent mode on classical benchmarks
- Multi-agent pipelines achieve new SOTA zero-shot results with fewer parameters

## Why This Works (Mechanism)
The effectiveness of multi-agent decomposition stems from specialized role allocation, where different agents handle distinct aspects of geometry problem solving. This division of labor allows each agent to focus on specific tasks (diagram analysis, parsing, planning, validation) rather than requiring a single model to excel at all aspects simultaneously. The modular design enables more efficient use of model parameters, as each agent can be optimized for its specific function. Additionally, the iterative feedback loops between agents allow for error correction and refinement that would be difficult for a single agent to achieve. The approach leverages the principle that complex reasoning tasks benefit from decomposition into simpler, specialized subtasks.

## Foundational Learning
- Diagram-grounded geometry problem solving: Understanding how geometric problems are solved when diagrams are provided as visual input rather than purely textual descriptions. This is crucial because it requires integrating visual reasoning with mathematical logic.
- Agentic pipeline design: The systematic construction of multi-agent systems where each agent has a specific role and the pipeline orchestrates their interactions. This matters because the effectiveness depends on proper role allocation and communication protocols.
- Zero-shot versus few-shot learning: The distinction between solving problems without any training examples (zero-shot) versus with limited examples (few-shot). This is important because it demonstrates the robustness of the approach across different data regimes.

## Architecture Onboarding
- Component map: Diagram Analyzer -> Parser -> Planner -> Solver -> Validator (4-agent pipeline)
- Critical path: Visual input → Diagram analysis → Problem parsing → Solution planning → Mathematical reasoning → Answer validation
- Design tradeoffs: Single-agent simplicity vs. multi-agent specialization; parameter efficiency vs. coordination overhead; model size vs. pipeline complexity
- Failure signatures: Single-agent models struggle with multi-step reasoning when diagram interpretation is required; multi-agent pipelines may suffer from communication bottlenecks or inconsistent agent outputs
- First experiments: 1) Compare 2-agent vs 3-agent vs 4-agent configurations on the same benchmark; 2) Test the same pipeline with different model sizes (7B vs 32B); 3) Evaluate on non-geometric reasoning tasks to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- The study reveals model-specific performance variations, with open-source models benefiting from multi-agent decomposition while closed-source models perform better in single-agent configurations
- The evaluation primarily centers on geometry problems with diagram grounding, limiting generalizability to other domains or problem types
- The focus on only two specific models (Qwen-2.5-VL 7B/32B and Gemini-2.0-Flash) limits the ability to draw broader conclusions about agentic frameworks across the full spectrum of available models

## Confidence
- High confidence: The experimental methodology is sound, with systematic comparisons across multiple benchmarks and clear quantitative results showing parameter-efficient improvements with multi-agent pipelines for open-source models
- Medium confidence: The claim that multi-agent decomposition is beneficial for open-source models but not universally optimal, given the model-specific performance variations observed
- Low confidence: The assertion that these findings represent a fundamental limitation of multi-agent approaches rather than model-specific characteristics, due to the limited model diversity tested

## Next Checks
1. Test the same multi-agent pipeline configurations across a broader range of both open-source and closed-source models (at least 5-7 models spanning different architectures) to determine if the observed pattern holds consistently or is specific to the tested models

2. Evaluate the multi-agent approach on non-geometric reasoning tasks (such as text-based logical reasoning or scientific problem solving) to assess whether the benefits observed in diagram-grounded geometry problems generalize to other domains

3. Conduct ablation studies that systematically vary the number of agents in the pipeline (2-agent, 3-agent, 4-agent configurations) to determine the optimal decomposition strategy and identify whether there are diminishing returns or negative effects from excessive agent splitting