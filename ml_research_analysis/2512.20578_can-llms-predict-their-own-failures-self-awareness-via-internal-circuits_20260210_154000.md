---
ver: rpa2
title: Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits
arxiv_id: '2512.20578'
source_url: https://arxiv.org/abs/2512.20578
tags:
- gnosis
- attention
- arxiv
- hidden
- correctness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Gnosis, a lightweight mechanism enabling frozen
  LLMs to self-assess correctness by decoding signals from their own internal states
  during inference. Instead of relying on external judges or multi-sample consistency,
  Gnosis passively observes final-layer hidden states and attention maps, compresses
  them into fixed-budget descriptors, and predicts a scalar correctness score.
---

# Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits

## Quick Facts
- arXiv ID: 2512.20578
- Source URL: https://arxiv.org/abs/2512.20578
- Reference count: 9
- Key outcome: Gnosis enables frozen LLMs to self-assess correctness using internal states with only ~5M additional parameters and negligible inference overhead

## Executive Summary
Gnosis presents a novel approach for frozen LLMs to self-assess their output correctness by decoding signals from internal states during inference. The system passively observes final-layer hidden states and attention maps, compresses them into fixed-budget descriptors, and predicts a scalar correctness score. This lightweight mechanism adds only ~5M parameters, operates independently of sequence length, and achieves AUROC scores above 0.92 across multiple benchmarks. Notably, a head trained on a 1.7B model can transfer zero-shot to judge larger models, demonstrating promising generalizability.

## Method Summary
Gnosis operates by monitoring the final-layer hidden states and attention maps during LLM inference, compressing these signals into fixed-budget descriptors that capture generation dynamics. The architecture includes a lightweight head (~5M parameters) that maps these compressed descriptors to a scalar correctness score. The system functions independently of sequence length and adds negligible inference overhead. A key innovation is the ability to predict failures from partial generations, enabling early termination and compute-aware control. The method was evaluated across math reasoning, open-domain QA, and academic benchmarks, consistently outperforming strong internal baselines and large external judges.

## Key Results
- Achieves AUROC scores above 0.92 across math reasoning, QA, and academic benchmarks
- Adds only ~5M parameters to frozen LLMs with negligible inference overhead
- Demonstrates zero-shot transferability from 1.7B model head to judge larger models
- Enables early failure prediction from partial generations for compute-aware control

## Why This Works (Mechanism)
The mechanism leverages the observation that internal states and attention patterns during generation contain intrinsic signals about output correctness. As the LLM processes tokens, its internal representations naturally encode confidence and reasoning quality information. Gnosis extracts and compresses these signals from the final layer's hidden states and attention maps, creating compact descriptors that capture the essence of the generation process. The lightweight head then maps these descriptors to correctness scores through learned patterns that correlate internal dynamics with output quality.

## Foundational Learning
- **Hidden State Analysis**: Understanding how final-layer representations capture reasoning quality - needed to extract meaningful signals; quick check: visualize hidden state patterns for correct vs incorrect outputs
- **Attention Map Compression**: Techniques for reducing high-dimensional attention matrices to fixed-budget descriptors - needed for computational efficiency; quick check: verify descriptor dimensionality matches model capacity
- **Zero-Shot Transfer Learning**: Methods for training on smaller models and applying to larger ones - needed for scalability; quick check: test transferability across different model families
- **Calibration Metrics**: Understanding AUROC, reliability diagrams, and other evaluation metrics - needed for proper performance assessment; quick check: verify calibration curves are well-formed
- **Early Termination Detection**: Recognizing failure patterns in partial sequences - needed for compute-aware control; quick check: test detection accuracy on truncated generations

## Architecture Onboarding

**Component Map**: Input tokens -> LLM backbone -> Final hidden states + attention maps -> Compression layer -> Fixed-budget descriptors -> Lightweight head -> Correctness score

**Critical Path**: The critical path flows from the LLM's final layer outputs through the compression mechanism to the correctness prediction head, with minimal additional latency

**Design Tradeoffs**: The architecture balances expressiveness (sufficient to capture correctness signals) against efficiency (minimal parameter overhead and inference cost). The compression mechanism trades some signal fidelity for computational tractability and sequence-length independence

**Failure Signatures**: Common failure modes include: over-compression losing critical correctness signals, insufficient training data for certain task types, and calibration degradation on out-of-distribution inputs

**First Experiments**:
1. Compare Gnosis performance against a frozen external judge baseline on a simple math dataset
2. Test transferability by training on 1.7B model and evaluating on 7B model outputs
3. Measure inference overhead across different sequence lengths to verify constant-time claims

## Open Questions the Paper Calls Out
None

## Limitations
- Transferability results demonstrated only one direction (1.7B to larger models) and may not generalize across different model families
- Compression mechanism effectiveness could degrade for substantially longer sequences (>4K tokens) or more complex reasoning tasks
- Computational overhead claims not benchmarked across different hardware configurations or under varying load conditions

## Confidence
- High confidence: Core mechanism of extracting correctness signals from internal states, comparative performance against baselines, calibration results
- Medium confidence: Zero-shot transferability claims and generalizability to completely unseen task domains
- Medium confidence: Computational efficiency claims, pending broader hardware validation

## Next Checks
1. Test Gnosis transferability across diverse model families (different architectures, training objectives) to establish robustness of zero-shot generalization
2. Evaluate performance on substantially longer sequences (10K+ tokens) to verify compression mechanism scalability
3. Benchmark inference overhead across multiple hardware platforms (CPU, GPU, edge devices) under varying load conditions to validate computational efficiency claims