---
ver: rpa2
title: Causality-Aware Next Location Prediction Framework based on Human Mobility
  Stratification
arxiv_id: '2503.18179'
source_url: https://arxiv.org/abs/2503.18179
tags:
- prediction
- location
- causal
- mobility
- next
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a causality-aware framework for next location
  prediction by addressing the limitations of existing methods that ignore causal
  relationships in human mobility data. The proposed approach stratifies human mobility
  data based on travel patterns (anchor vs.
---

# Causality-Aware Next Location Prediction Framework based on Human Mobility Stratification

## Quick Facts
- arXiv ID: 2503.18179
- Source URL: https://arxiv.org/abs/2503.18179
- Reference count: 37
- Key outcome: 19.09% improvement in Recall@5 over baseline models

## Executive Summary
This study introduces a causality-aware framework for next location prediction that addresses the limitations of existing methods by incorporating causal relationships in human mobility data. The framework stratifies human mobility data into anchor-targeted and non-anchor-targeted travels based on visit frequency, then applies counterfactual interventions to enhance indirect causal effects for non-anchor-targeted travels. Evaluation on real-world datasets shows significant performance improvements across multiple metrics, with Recall@5 increasing by up to 19.09% compared to baseline models.

## Method Summary
The framework stratifies human mobility data into anchor-targeted travels (routine destinations like home/work) and non-anchor-targeted travels (non-routine) based on visit frequency thresholds. A novel causal graph captures both direct and indirect causal effects between variables, with direct paths (H→Y and L→Y) and indirect paths through hidden state G. For non-anchor-targeted travels, counterfactual interventions are applied to enhance indirect effects by computing predictions with counterfactual values and subtracting them from original predictions. The framework is designed as a plug-and-play module that integrates with state-of-the-art prediction models, using two-branch prediction with hidden states h = f_h(user⊕time) and g = f_g(h⊕location).

## Key Results
- Significant performance improvements across multiple metrics: Recall@5 increases by up to 19.09%, MRR@5 by up to 7.98%, and NDCG@5 by up to 17.27% compared to baseline models
- The framework shows consistent improvements across various POI categories and different baseline models (GRU, DeepMove, Flashback, HSTLSTM, GETNext)
- Ablation study confirms the importance of the proposed causal graph structure, with 7.47% performance drop when both direct links are removed

## Why This Works (Mechanism)

### Mechanism 1: Human Mobility Stratification by Travel Pattern
Stratifying human mobility data into anchor-targeted and non-anchor-targeted travels enables differentiated prediction strategies. Location information acts as a confounder for anchor-targeted travels but is informative for non-anchor-targeted travels. Stratification allows the model to suppress confounding in one case while leveraging it in the other.

### Mechanism 2: Causal Graph with Separated Direct/Indirect Effects
The causal graph introduces an intermediate hidden state G with explicit direct causal paths (H→Y and L→Y) that captures both direct and indirect effects. This separation allows targeted intervention on indirect pathways that conventional models conflate.

### Mechanism 3: Counterfactual Intervention to Isolate Indirect Effects
For non-anchor-targeted travels, computing predictions with counterfactual interventions (ŷ_pred - ŷ_causal) enhances the contribution of indirect causal pathways. The do(G=g*) intervention severs incoming edges to G, replacing it with counterfactual values.

## Foundational Learning

- **Concept: Causal Graphs and Confounding**
  - Why needed here: The paper models prediction as a causal inference problem where location can be a confounder; understanding DAGs, confounding, and causal paths is essential.
  - Quick check question: In Figure 3b, why does L have arrows to both G and Y, and what would happen if L→Y were removed?

- **Concept: do-calculus and Counterfactuals**
  - Why needed here: The intervention do(G=g*) is central to computing counterfactual predictions; understanding what this operation does structurally and semantically is critical.
  - Quick check question: When we apply do(G=g*), which edges in the causal graph are "severed" and why?

- **Concept: Sequence Models with Hidden States**
  - Why needed here: The framework integrates with RNN/Transformer baselines where hidden states h and g must be extracted and manipulated.
  - Quick check question: How would you extract the final hidden state from a GRU processing a trajectory, and what does it represent?

## Architecture Onboarding

- **Component map:**
  Embedding layers (dim=128) -> f_h (user⊕time -> h) -> f_g (h⊕location -> g) -> MLP output (h⊕g⊕l -> prediction logits) -> Loss computation (standard CE for T1, CE on difference for T2)

- **Critical path:**
  1. Stratify trajectories by anchor threshold (frequency ≥ threshold → anchor-targeted)
  2. Forward pass: compute hτ, gτ, concatenate with lτ, predict via MLP
  3. For T2 samples: generate counterfactual g*, compute ŷ_causal, subtract from ŷ_pred
  4. Apply appropriate loss per trajectory type

- **Design tradeoffs:**
  - Threshold selection: Too low → no stratification benefit; too high → insufficient anchor samples for learning regular patterns
  - Strategy selection: I/II (random/zero) outperform III (mean of others) in most cases
  - Baseline model choice: GRU/DeepMove/Flashback show larger gains than HSTLSTM/GETNext

- **Failure signatures:**
  - Negative improvement (HSTLSTM on Blogwatcher: -2.73%) suggests incompatibility with some model architectures
  - Performance plateaus when threshold → 0 (no stratification applied)
  - Strategy III ineffective when trajectory diversity is high (mean of others not representative)

- **First 3 experiments:**
  1. Reproduce stratification analysis (Figure 2) on your data: measure prediction accuracy with/without previous location information for different destination types to verify the confounding pattern exists.
  2. Implement ablation (Table II): remove L→Y and H→Y links separately and together to confirm direct causal paths contribute independently.
  3. Compare counterfactual strategies on a validation set using multiple baselines; identify which strategy-model combinations yield consistent improvements before full integration.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas remain unexplored based on the analysis of limitations and performance patterns.

## Limitations
- The assumed causal graph structure is not empirically validated against alternative DAGs, leaving open the possibility of omitted confounders or incorrect edge directions
- Counterfactual generation strategies rely on ad-hoc perturbations without theoretical grounding in the true data-generating process
- The stratification threshold (frequency ≥ 10) is dataset-specific and may not generalize to mobility data with different spatial or temporal scales

## Confidence
- High: The stratification mechanism (T1 vs T2) and its effect on prediction accuracy are well-supported by ablation and qualitative results
- Medium: The counterfactual intervention improves performance on non-anchor-targeted travels, but the mechanism is less rigorously validated
- Low: The theoretical justification for the causal graph structure and counterfactual strategies is limited; empirical gains may stem from architectural changes rather than causal reasoning

## Next Checks
1. Conduct a sensitivity analysis on the anchor threshold: Vary the frequency cutoff (e.g., 5, 10, 15) and measure how stratification performance changes to identify the optimal value for new datasets.
2. Test alternative causal graph structures: Replace the current DAG with variations (e.g., remove L→Y, add H→L) and compare performance to assess robustness to structural assumptions.
3. Validate counterfactual strategies on a held-out dataset: Apply the three counterfactual methods to a new mobility dataset (e.g., Gowalla) and report which strategy consistently outperforms others across multiple baselines.