---
ver: rpa2
title: 'FoQA: A Faroese Question-Answering Dataset'
arxiv_id: '2502.07642'
source_url: https://arxiv.org/abs/2502.07642
tags:
- faroese
- dataset
- question
- questions
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FoQA, the first Faroese extractive question-answering
  dataset with 2,000 validated samples. The authors develop a semi-automated methodology
  that combines GPT-4-turbo for initial QA generation with human validation by native
  speakers.
---

# FoQA: A Faroese Question-Answering Dataset

## Quick Facts
- arXiv ID: 2502.07642
- Source URL: https://arxiv.org/abs/2502.07642
- Authors: Annika Simonsen; Dan Saattrup Nielsen; Hafsteinn Einarsson
- Reference count: 7
- Primary result: First Faroese extractive QA dataset with 2,000 validated samples

## Executive Summary
This paper introduces FoQA, the first Faroese extractive question-answering dataset developed through a semi-automated methodology combining GPT-4-turbo generation with human validation. The dataset contains 2,000 validated QA pairs created from Faroese Wikipedia articles, with questions rephrased to increase complexity and answers requiring verbatim matches in source text. The authors evaluate multiple models including GPT-4-turbo, FoBERT, and mDeBERTa-v3, finding significant performance differences favoring decoder architectures. The dataset and code are released open-source to support Faroese language technology development.

## Method Summary
The dataset construction methodology employs a two-stage process combining automated generation with human validation. GPT-4-turbo generates initial QA pairs from Faroese Wikipedia articles, with questions then rephrased to increase complexity and ensure they cannot be answered from simple context. Human validators, native Faroese speakers, review and validate samples, rejecting those that don't meet quality standards. The final dataset includes three versions: 2,000 validated samples, 10,001 total generated samples, and 2,395 rejected samples for error analysis. This semi-automated approach enables rapid dataset creation while maintaining linguistic quality through human oversight.

## Key Results
- GPT-4-turbo achieves highest performance with F1 score of 77.6 and exact match of 55.6
- Encoder models (FoBERT, mDeBERTa-v3) perform significantly worse than decoder architectures
- Dataset construction methodology enables creation of quality Faroese QA data with limited native speaker resources
- Performance evaluation reveals potential architectural biases favoring decoder models for this task

## Why This Works (Mechanism)
The semi-automated approach leverages GPT-4-turbo's strong language understanding capabilities while maintaining quality through human validation. The rephrasing process increases question complexity beyond simple extraction, requiring deeper semantic understanding. The verbatim answer requirement ensures precise model evaluation while the human validation process catches generation errors and linguistic nuances that automated systems might miss. The combination of Wikipedia source material provides diverse, well-structured text that supports varied question types.

## Foundational Learning

Question-Answering Task Fundamentals
- Why needed: Understanding extractive QA mechanics is crucial for dataset construction and evaluation
- Quick check: Verify that questions have single, unambiguous answers in source text

Semi-automated Dataset Construction
- Why needed: Enables efficient creation of quality datasets with limited native speaker resources
- Quick check: Monitor validation rejection rates to identify systematic generation issues

Faroese Language Characteristics
- Why needed: Understanding unique linguistic features ensures appropriate dataset design
- Quick check: Validate that generated questions capture Faroese-specific grammatical structures

## Architecture Onboarding

Component Map:
GPT-4-turbo -> Question Generation -> Human Validation -> Dataset Creation -> Model Evaluation

Critical Path:
Source text selection → GPT-4-turbo generation → Human validation → Final dataset compilation → Model testing

Design Tradeoffs:
- Automated generation enables scale but requires human validation for quality
- Verbatim answer requirement ensures precision but may limit question complexity
- Wikipedia source material provides diversity but may not represent all Faroese domains

Failure Signatures:
- High rejection rates indicate generation quality issues
- Poor encoder model performance suggests dataset biases
- Validation inconsistencies reveal ambiguous question construction

First Experiments:
1. Analyze rejected samples to identify systematic generation failures
2. Test model performance across different question complexity levels
3. Evaluate cross-domain generalization with non-Wikipedia Faroese texts

## Open Questions the Paper Calls Out

None

## Limitations

- GPT-4-turbo generation introduces potential biases in question types and complexity
- Human validation may not fully capture semantic equivalence across all generated questions
- Small dataset size (2,000 samples) may limit coverage of Faroese linguistic phenomena
- Performance gap between decoder and encoder models raises architectural concerns
- Limited evaluation of unanswerable questions and ambiguous contexts

## Confidence

Dataset validity and construction methodology: Medium
Performance evaluation results: High
Language technology impact claims: Medium

## Next Checks

1. Conduct comprehensive error analysis on rejected samples to identify systematic biases in GPT-4-turbo's question generation and human validation patterns
2. Evaluate model performance across different question types (factual, inferential, comparison) to identify potential biases in dataset's question distribution
3. Test dataset's generalization by evaluating models on cross-domain Faroese texts not included in original source material