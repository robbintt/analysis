---
ver: rpa2
title: Large Language Models for Drug Overdose Prediction from Longitudinal Medical
  Records
arxiv_id: '2504.11792'
source_url: https://arxiv.org/abs/2504.11792
tags:
- overdose
- data
- medical
- patient
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated large language models (LLMs) for predicting
  drug overdose risk from longitudinal medical records. GPT-4o was tested in zero-shot
  and fine-tuned settings using structured insurance claims data, with predictions
  made for 7-day and 30-day overdose risk.
---

# Large Language Models for Drug Overdose Prediction from Longitudinal Medical Records

## Quick Facts
- arXiv ID: 2504.11792
- Source URL: https://arxiv.org/abs/2504.11792
- Reference count: 25
- Primary result: Fine-tuned LLMs achieved 84.53 F1 score for 7-day overdose prediction, outperforming traditional ML models by ~6 points

## Executive Summary
This study evaluates large language models for predicting drug overdose risk from longitudinal insurance claims data. GPT-4o demonstrated strong zero-shot predictive ability, particularly with detailed medical descriptions, achieving 54.32 F1 for 7-day predictions. The study found that fine-tuned LLMs with aggregated visit statistics outperformed traditional ML models, reaching 84.53 F1 score. The research highlights LLMs' potential as clinical decision support tools for overdose risk assessment, though performance varies significantly based on input format and representation choices.

## Method Summary
The study used Merative MarketScan Research Databases (2020-2022) to create case (overdose patients), control (non-overdose), and exposed (opioid/stimulant users without overdose) cohorts. Data was converted to JSON format with two representations: detailed visit-level records with diagnoses, procedures, prescriptions, and demographics, or aggregated frequency vectors. Four prompt formats were tested: detailed visit (descriptive codes) and summarized visit (medical codes). Zero-shot GPT-4o predictions were compared against fine-tuned GPT-4o models and traditional baselines (Random Forest, XGBoost) using 900 samples per split.

## Key Results
- Zero-shot GPT-4o achieved 54.32 F1 score for 7-day predictions with detailed medical descriptions
- Fine-tuned LLMs with aggregated statistics achieved 84.53 F1 score, outperforming XGBoost (78.92) by ~6 points
- Detailed sequential visits underperformed aggregated statistics for fine-tuned models (69.99 vs. 84.53 F1)
- Descriptive text formats cost 25% more than medical codes but provided better zero-shot performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs leverage pre-trained medical knowledge for zero-shot overdose prediction
- **Mechanism:** Pre-training on biomedical texts enables pattern recognition between clinical events and overdose risk without task-specific examples
- **Core assumption:** Pre-training corpus contained sufficient biomedical text for clinically relevant pattern learning
- **Evidence anchors:** Zero-shot F1 of 54.32 with descriptive text vs. 52.69 with codes only; recall of 56% for 30-day predictions
- **Break condition:** Performance drops when medical codes are used without descriptive context

### Mechanism 2
- **Claim:** JSON serialization preserves temporal medical sequences for LLM reasoning
- **Mechanism:** Structured text representation allows LLMs to process chronological visit dependencies
- **Core assumption:** LLMs can effectively parse structured text without explicit temporal encoding
- **Evidence anchors:** JSON format chosen for simplicity and structured representation; performance plateaus at 30+ encounters
- **Break condition:** Context saturation beyond 30 encounters degrades performance

### Mechanism 3
- **Claim:** Aggregated statistics enable fine-tuned LLMs to outperform traditional models
- **Mechanism:** Feature occurrence counts reduce complexity while preserving predictive signals during fine-tuning
- **Core assumption:** 900-sample fine-tuning dataset represents underlying feature-outcome distribution
- **Evidence anchors:** Fine-tuned F1 of 84.53 vs. 78.92 for XGBoost; 6-point improvement over best baseline
- **Break condition:** Fine-tuning fails with detailed visits (69.99 F1) compared to aggregated stats

## Foundational Learning

- **Concept: Zero-shot inference**
  - **Why needed here:** Essential for interpreting baseline performance and assessing fine-tuning investment value
  - **Quick check question:** Can you explain why a model with no exposure to your specific dataset can still achieve >50% recall on overdose prediction?

- **Concept: Feature aggregation vs. sequential representation**
  - **Why needed here:** Explains why aggregated statistics outperformed detailed sequences for fine-tuned models
  - **Quick check question:** Why would counting feature occurrences across visits potentially preserve more predictive signal than providing the full visit sequence?

- **Concept: Token budget optimization**
  - **Why needed here:** Input length affects both model performance and deployment cost
  - **Quick check question:** If a patient has 50 visits and you must predict within a $0.01 per-instance budget, which representation format should you select?

## Architecture Onboarding

- **Component map:** Claims Database -> Cohort Selection -> Preprocessing -> Format Conversion -> Model Layer -> Prediction

- **Critical path:** Data preprocessing (cutoff date logic) -> Format selection (descriptive vs. code, detailed vs. aggregated) -> Model configuration (zero-shot vs. fine-tuned). Cutoff date errors will leak future information.

- **Design tradeoffs:**
  - Descriptive text: Higher zero-shot performance, 25% higher token cost, better clinical interpretability
  - Medical codes: Lower token cost, comparable fine-tuned performance, EHR-compatible format
  - Detailed visits: Preserves temporal patterns, zero-shot advantage, but underperforms in fine-tuning
  - Aggregated stats: Best fine-tuned performance, 73% cost reduction, but loses sequential context

- **Failure signatures:**
  - Zero-shot models over-predict overdose for opioid-exposed controls (73.67% accuracy)
  - Performance degrades beyond 30 encounters (context saturation)
  - Fine-tuned models with detailed visits underperform aggregated baselines by ~14 F1 points

- **First 3 experiments:**
  1. Reproduce zero-shot baseline with 30 encounters using descriptive format; verify F1 â‰ˆ 54-58 range
  2. Ablate input fields to confirm diagnosis history provides primary predictive signal
  3. Fine-tune with aggregated statistics on held-out subset; compare against XGBoost baseline

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does incorporating laboratory data improve LLM predictive performance compared to claims data alone?
- **Basis:** Authors plan to incorporate lab data in future work, noting it was missing from current dataset
- **Why unresolved:** Merative MarketScan dataset lacks laboratory data
- **What evidence would resolve it:** Comparative study evaluating LLM performance with and without structured laboratory results

### Open Question 2
- **Question:** Does increasing training dataset size beyond 900 patients enhance fine-tuned LLM capabilities?
- **Basis:** Limited to 900 patients due to fine-tuning costs; authors want to investigate scaling effects
- **Why unresolved:** Computational and financial constraints limited fine-tuning sample size
- **What evidence would resolve it:** Performance benchmarks from models fine-tuned on 2,000, 5,000, and 10,000 patients

### Open Question 3
- **Question:** Can minimal supplementary context alongside raw medical codes enhance LLM interpretability and accuracy?
- **Basis:** Authors suggest exploring hybrid approaches between full descriptions and raw codes
- **Why unresolved:** Study only evaluated extremes (full descriptions vs. raw codes)
- **What evidence would resolve it:** Experiments pairing medical codes with brief clinical definitions to measure cost-accuracy tradeoffs

## Limitations

- Small sample size (900 per cohort) raises generalizability concerns across broader populations
- Reliance on insurance claims data excludes non-insured populations and may underrepresent certain demographics
- Performance gaps between zero-shot (54.32 F1) and fine-tuned (84.53 F1) models suggest substantial improvement potential
- Study does not address potential biases in medical coding practices across different healthcare settings

## Confidence

- **High Confidence:** Zero-shot performance with descriptive medical text (54.32 F1, 56% recall)
- **Medium Confidence:** Fine-tuned LLM superiority over traditional models (84.53 vs. 78.92 F1)
- **Low Confidence:** Aggregated statistics outperforming detailed sequential visits for fine-tuned models

## Next Checks

1. **External Validation:** Test best-performing model on independent dataset from different healthcare system to assess generalizability

2. **Bias Analysis:** Conduct subgroup analysis by age, gender, race, and socioeconomic indicators to identify performance disparities

3. **Temporal Robustness:** Evaluate model performance across different time periods to assess stability and identify potential overfitting to temporal trends