---
ver: rpa2
title: Distilling Tool Knowledge into Language Models via Back-Translated Traces
arxiv_id: '2506.19171'
source_url: https://arxiv.org/abs/2506.19171
tags:
- tool
- reasoning
- error
- expression
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of mathematical reasoning in
  large language models, particularly for problems requiring exact computation and
  multi-step algebraic reasoning. The authors propose a new paradigm that distills
  tool knowledge into language models through back-translation: a Solver Agent generates
  tool-integrated reasoning traces, which are then converted into natural language
  reasoning traces using Translator and Rephrase Agents.'
---

# Distilling Tool Knowledge into Language Models via Back-Translated Traces

## Quick Facts
- **arXiv ID**: 2506.19171
- **Source URL**: https://arxiv.org/abs/2506.19171
- **Reference count**: 40
- **Primary result**: Fine-tuning Qwen2.5-MATH-7B-Instruct on 11.6k back-translated traces improves performance on AIME (7.8%→10.0%), Olympiad Bench (41.2%→43.1%), and AMC (51.2%→52.4%).

## Executive Summary
This paper addresses the challenge of mathematical reasoning in large language models, particularly for problems requiring exact computation and multi-step algebraic reasoning. The authors propose a new paradigm that distills tool knowledge into language models through back-translation: a Solver Agent generates tool-integrated reasoning traces, which are then converted into natural language reasoning traces using Translator and Rephrase Agents. The resulting traces are used to fine-tune a small open-source model via supervised fine-tuning. Empirically, fine-tuning Qwen2.5-MATH-7B-Instruct on 11.6k back-translated traces improves performance on challenging benchmarks like AIME (7.8%→10.0%), Olympiad Bench (41.2%→43.1%), and AMC (51.2%→52.4%), demonstrating the model's ability to internalize structured reasoning patterns and tool knowledge without requiring tool access at inference.

## Method Summary
The approach involves a three-stage pipeline: (1) a Solver Agent uses GPT-4.1-mini with a SymPy toolkit to generate tool-integrated reasoning (TIR) traces for mathematical problems; (2) Translator, Judge, and Rephrase Agents convert these traces into natural language reasoning; (3) the resulting back-translated traces are used to fine-tune a small model (Qwen2.5-MATH-7B-Instruct) via supervised fine-tuning with LoRA (rank-64, ~1% parameters). The method filters for correct answers only (46% acceptance rate from 25k problems), ensuring training data quality while limiting diversity.

## Key Results
- Fine-tuning on back-translated traces improves AIME accuracy from 7.8% to 10.0%
- Olympiad Bench performance increases from 41.2% to 43.1%
- AMC accuracy improves from 51.2% to 52.4%
- GSM8K performance degrades from 95.5% to 91.1% due to over-reasoning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Converting tool-augmented reasoning traces into natural language enables models to internalize symbolic computation patterns without requiring tool access at inference.
- **Mechanism:** A three-stage back-translation pipeline transforms abstract tool calls into detailed step-by-step natural language reasoning. The Translator Agent reformulates each tool call as a subproblem with explicit reasoning; the Judge Agent verifies mathematical equivalence; the Rephrase Agent merges all components into a coherent narrative. This preserves symbolic integrity while making reasoning accessible for standard SFT.
- **Core assumption:** The computational logic underlying tool operations can be faithfully expressed in natural language without loss of reasoning fidelity.
- **Evidence anchors:** [abstract]: "convert interleaved TIR traces into natural language reasoning traces... enables it to internalize both tool knowledge and structured reasoning patterns"; [section 4]: "The resulting back-translated traces preserve the symbolic integrity of tool-augmented reasoning while making it accessible in a language-only format"; [corpus]: Weak direct corpus support for back-translation specifically; related work (Nemotron-Math, ET-Agent) focuses on TIR training but not NL conversion.

### Mechanism 2
- **Claim:** Structured problem decomposition (planning → execution → reflection) transfers to student models through exposure to agent-generated solution patterns.
- **Mechanism:** The Solver Agent explicitly separates high-level planning from step-wise execution. Each step includes tool invocation, reflection on outputs, plan refinement, and next-action determination. SFT on these traces teaches the model to mimic this decomposition without tool dependencies.
- **Core assumption:** Models can learn to decompose problems into structured reasoning steps through pattern imitation, even when tools are unavailable at inference.
- **Evidence anchors:** [section 3.2]: "The solving process begins with a high-level planning phase... It then determines the next action—either continuing with NL reasoning or invoking another tool"; [section 5.2]: "the SFT model decomposes the geometric problem into intermediate subgoals... enabling accurate area calculation"; [corpus]: KaVa and related work suggest latent/internalized reasoning is viable but don't specifically validate planning transfer.

### Mechanism 3
- **Claim:** Strict correctness filtering of TIR traces before back-translation ensures training data quality by only retaining reasoning paths that produce correct final answers.
- **Mechanism:** Only traces where the Solver Agent produces the correct final answer (verified against ground truth) are retained. From 25k problems, 11.6k valid TIR traces passed filtering (46% acceptance rate). This removes traces with tool errors, reasoning mistakes, or incorrect answers.
- **Core assumption:** Correct final answers correlate with valid reasoning processes; traces leading to wrong answers contain learnable errors.
- **Evidence anchors:** [section 4]: "Only the traces that result in correct final answers are retained for back-translation and the rest which encounter tool call errors or lead to incorrect answers are discarded"; [section 5]: "we obtain 11.6k TIR traces, with an overall accuracy around 46%"; [corpus]: No direct corpus comparison; concurrent work (ToRL, rStar-Math) uses different filtering/selection strategies.

## Foundational Learning

- **Concept: Tool-Integrated Reasoning (TIR)**
  - Why needed here: The entire method builds on interleaving natural language reasoning with symbolic tool calls; understanding this paradigm is prerequisite to understanding what's being distilled.
  - Quick check question: Can you explain why TIR improves mathematical reasoning but creates deployment challenges?

- **Concept: Supervised Fine-Tuning (SFT) with LoRA**
  - Why needed here: The back-translated traces are used for SFT; understanding LoRA (rank-64, ~1% parameters) is necessary to reproduce the training setup.
  - Quick check question: What are the key hyperparameters for the SFT configuration used in this work?

- **Concept: SymPy Symbolic Computation**
  - Why needed here: The toolkit is built on SymPy; understanding the tool categories (algebraic simplification, equation solving, calculus, linear algebra) is essential for extending or modifying the toolkit.
  - Quick check question: What grammatical constraints must inputs satisfy for SymPy compatibility (e.g., absolute value notation)?

## Architecture Onboarding

- **Component map:** Math Problem → Solver Agent (GPT-4.1-mini + SymPy Toolkit) → TIR Trace (planning + tool calls + reflection) → Correctness Filter (ground truth comparison) → Translator Agent (per-tool-call NL reasoning) → Judge Agent (equivalence verification) → Rephrase Agent (holistic NL trace) → SFT Dataset (11.6k traces) → Student Model (Qwen2.5-MATH-7B-Instruct + LoRA)

- **Critical path:** (1) High-quality TIR trace generation depends on SymPy toolkit coverage and Solver Agent capability; (2) Faithful back-translation depends on Translator Agent accurately reproducing tool reasoning in NL. Tool categories with complex intermediate reasoning (solve_univariate_inequality: ~60% acceptance) are bottlenecks.

- **Design tradeoffs:**
  - Data quantity vs. quality: Strict filtering (46% retention) ensures quality but limits diversity
  - Tool coverage vs. specialization: Current toolkit lacks geometry and combinatorics support (identified limitation)
  - Complex vs. simple reasoning: SFT improves hard benchmarks (AIME +2.2%) but degrades simple ones (GSM8K -4.4%) due to over-reasoning

- **Failure signatures:**
  - Over-reasoning on simple problems: Model introduces unnecessary variables/constraints when heuristics suffice (see GSM8K case study in Section 5.2)
  - Tool translation failures: Complex algebraic tools show lower acceptance rates; failures retain original tool call info
  - Tool misuse patterns: 10 error types identified including "Did Not Use Tool" (22%), "Mistake in Reasoning" (22%), "Misuse of Tool" (10%)

- **First 3 experiments:**
  1. **Reproduce baseline comparison:** Train Qwen2.5-MATH-7B-Instruct on the released 11.6k dataset using specified LoRA config (rank=64, lr=2e-4, 3 epochs); verify AIME (7.8%→10.0%) and AMC (51.2%→52.4%) improvements.
  2. **Ablate filtering threshold:** Compare strict filtering (correct answers only) vs. relaxed filtering (include verified reasoning steps even if final answer wrong) to quantify quality-diversity tradeoff.
  3. **Extend toolkit coverage:** Add geometry tools (vector projection, angle computation) and evaluate on geometry-heavy MATH subsets to test generalization beyond current algebraic focus.

## Open Questions the Paper Calls Out
None

## Limitations
- Current SymPy toolkit lacks geometry and combinatorics support, limiting domain coverage
- Strict filtering (46% acceptance) ensures quality but may introduce Solver Agent biases and limit diversity
- Performance degradation on simpler problems (GSM8K: 95.5%→91.1%) indicates over-reasoning when heuristic approaches suffice

## Confidence
**High Confidence**: The mechanism of converting tool-integrated reasoning traces to natural language for SFT is well-supported by the empirical results showing consistent improvements across AIME, Olympiad Bench, and AMC benchmarks (AIME: 7.8%→10.0%, Olympiad: 41.2%→43.1%, AMC: 51.2%→52.4%). The three-stage back-translation pipeline is clearly specified and reproducible.

**Medium Confidence**: The claim that structured problem decomposition transfers to student models through pattern imitation is supported by case studies but requires further validation across diverse problem types. The filtering strategy's impact on model generalization remains uncertain without ablation studies comparing strict versus relaxed filtering.

**Low Confidence**: The scalability of this approach to more complex mathematical domains (geometry, combinatorics) and the long-term generalization benefits of back-translated traces versus direct TIR training are not yet established. The trade-offs between model complexity and performance gains for different problem categories need more systematic investigation.

## Next Checks
1. **Ablation of Filtering Strategy**: Compare strict filtering (correct answers only) versus relaxed filtering (verified reasoning steps regardless of final answer) to quantify the quality-diversity tradeoff and assess the impact on generalization to unseen problems.

2. **Toolkit Extension and Domain Coverage**: Extend the SymPy toolkit to include geometry tools (vector operations, angle computations) and evaluate performance on geometry-heavy MATH subsets to validate scalability beyond algebraic domains.

3. **Generalization Across Problem Complexity**: Systematically evaluate model performance on problems of varying difficulty levels (easy/medium/hard subsets of MATH) to characterize when the structured reasoning approach adds value versus when simpler heuristics suffice.