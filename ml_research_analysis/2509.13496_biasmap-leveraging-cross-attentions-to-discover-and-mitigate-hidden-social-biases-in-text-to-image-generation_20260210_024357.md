---
ver: rpa2
title: 'BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social
  Biases in Text-to-Image Generation'
arxiv_id: '2509.13496'
source_url: https://arxiv.org/abs/2509.13496
tags:
- bias
- entanglement
- diffusion
- miou
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BiasMap discovers and mitigates hidden social biases in text-to-image
  generation by leveraging cross-attention attribution maps to quantify concept-level
  representational entanglements between demographics and semantics. The method uses
  Intersection-over-Union (IoU) metrics to measure spatial overlap in attention maps
  during generation, revealing biases invisible to output-level analysis.
---

# BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation

## Quick Facts
- **arXiv ID:** 2509.13496
- **Source URL:** https://arxiv.org/abs/2509.13496
- **Reference count:** 40
- **Primary result:** BiasMap achieves 40.8% reduction in gender concept entanglement (mIoU: 0.363→0.215) and 39.6% reduction for race (mIoU: 0.414→0.250) while maintaining generation quality comparable to baseline methods.

## Executive Summary
BiasMap is a novel method for discovering and mitigating hidden social biases in text-to-image generation models. The approach leverages cross-attention attribution maps to reveal structural entanglements between demographics (e.g., gender, race) and semantics (e.g., professions) that are invisible to traditional output-level bias metrics. By quantifying spatial overlap between demographic and semantic attention patterns using Intersection over Union (IoU), BiasMap provides a new metric for measuring representational bias. The method introduces energy-guided diffusion sampling that directly modifies latent noise space to minimize expected SoftIoU during denoising, achieving significant bias reduction while preserving image quality.

## Method Summary
BiasMap operates by first extracting cross-attention attribution maps from diffusion-based image generators, capturing where demographic and semantic concepts become spatially entangled during generation. The method constructs attribution prompts containing both demographic tokens (e.g., "male," "Asian") and semantic tokens (e.g., "doctor") and aggregates cross-attention matrices across U-Net blocks, timesteps, and attention heads. Bias is quantified using IoU metrics on thresholded attention masks, with lower IoU indicating better separation of concepts. For mitigation, BiasMap employs energy-guided diffusion sampling that modifies the noise prediction at each denoising step by adding a scaled gradient of a SoftIoU energy function, steering the generation process toward lower-entanglement latent states while maintaining image fidelity through careful guidance scale selection.

## Key Results
- Achieves 40.8% reduction in gender concept entanglement (mIoU: 0.363→0.215) and 39.6% reduction for race (mIoU: 0.414→0.250)
- Demonstrates that representational bias (measured by mIoU) is distinct from distributional bias (measured by Risk Difference), as shown by FairDiffusion reducing RD but increasing mIoU
- Combined with distributional debiasing, achieves optimal performance with mIoU of 0.189
- Maintains generation quality with FID scores around 44.89, demonstrating effective fairness-quality tradeoff

## Why This Works (Mechanism)

### Mechanism 1: Cross-Attention Attribution for Bias Localization
Cross-attention maps spatially localize where demographic and semantic concepts become entangled during diffusion-based image generation. OVAM (Open Vocabulary Attention Maps) computes cross-attention matrices between spatial queries from latent states and textual keys for arbitrary concepts—including those absent from the original prompt. Aggregating across U-Net blocks, timesteps, and attention heads produces attribution maps showing which pixels each concept influences. The core assumption is that spatial co-activation in attention patterns reflects representational coupling, not coincidental feature co-occurrence.

### Mechanism 2: IoU as a Quantitative Entanglement Metric
Intersection over Union (IoU) on thresholded attention masks quantifies concept entanglement invisible to output-level distribution metrics like Risk Difference. Binary masks are created by thresholding attention heatmaps at the 70th percentile. IoU measures spatial overlap between demographic and semantic masks. High IoU indicates the model generates these concepts with coupled spatial attention—representational bias distinct from skewed output counts. The core assumption is that threshold selection meaningfully separates high-attention regions and mask intersection captures conceptual coupling strength.

### Mechanism 3: Energy-Guided Sampling for Real-Time Mitigation
Minimizing a differentiable SoftIoU energy function during denoising reduces concept entanglement while preserving image fidelity. At each timestep, cross-attention maps are computed dynamically. SoftTopK (via entropy-regularized optimal transport) produces differentiable soft masks. The SoftIoU energy gradient corrects the noise prediction, steering sampling toward lower-entanglement latent states. The core assumption is that the energy gradient direction meaningfully disentangles concepts without destroying semantic content, and the scaling factor appropriately balances guidance across noise levels.

## Foundational Learning

- **Concept: Cross-Attention in Latent Diffusion**
  - Why needed here: The entire framework extracts bias signals from cross-attention layers where text conditions interact with spatial features.
  - Quick check question: Explain how cross-attention differs from self-attention, and identify which layers in Stable Diffusion's U-Net contain cross-attention.

- **Concept: Score-Based Diffusion and Noise Prediction**
  - Why needed here: Mitigation modifies noise prediction via energy gradients. Understanding the score–noise relationship is essential.
  - Quick check question: What is the mathematical relationship between the score function $\nabla_{z_t}\log p(z_t|P)$ and the predicted noise $\epsilon_\theta(z_t, P)$?

- **Concept: Differentiable Approximations via Optimal Transport**
  - Why needed here: Hard thresholding for IoU is non-differentiable. The paper uses entropy-regularized optimal transport (Sinkhorn) to create soft, differentiable masks.
  - Quick check question: Why can't gradients flow through a hard TopK operation, and how does adding entropy regularization make the selection differentiable?

## Architecture Onboarding

- **Component map:** OVAM Module -> SoftTopK Module -> SoftIoU Energy Function -> Energy-Guided Sampler

- **Critical path:**
  1. Construct attribution prompt $P'$ containing both demographic and semantic tokens
  2. At each denoising step $t$, extract cross-attention maps $M^{(t)}_a, M^{(t)}_b$ via OVAM
  3. Apply SoftTopK at percentile $q=0.7$ to generate soft masks $\tilde{M}^{(t)}_a, \tilde{M}^{(t)}_b$
  4. Compute energy $E(z_t) = SoftIoU(\tilde{M}^{(t)}_a, \tilde{M}^{(t)}_b)$
  5. Backpropagate to latent for gradient $\nabla_{z_t}E(z_t)$
  6. Modify noise: $\hat{\epsilon}_{final} = \hat{\epsilon}_{cfg} + \lambda\sqrt{1-\bar{\alpha}_t}\nabla_{z_t}E(z_t)$

- **Design tradeoffs:**
  - **Guidance scale $\lambda$**: Higher values improve fairness (lower mIoU) but degrade FID. $\lambda=100$ captures ~60-70% of max fairness gain with acceptable quality; $\lambda>400$ causes quality collapse.
  - **Threshold percentile $q$**: 70th percentile balances mask accuracy vs. discriminative power.
  - **Block targeting**: Restricting to Up×64 and Down×64 blocks achieves comparable mIoU with better efficiency than all blocks.

- **Failure signatures:**
  - **Distributional mitigation paradox**: FairDiffusion reduces RD but *increases* mIoU (0.363→0.393), worsening representational entanglement.
  - **Hierarchical resistance**: mBIoU improves less than mIoU (e.g., driver: 30.4% mIoU improvement vs. 10.0% mBIoU), indicating deeper entanglements resist intervention.
  - **Quality collapse**: FID exceeds 100 when $\lambda \geq 400$.

- **First 3 experiments:**
  1. **Validate mIoU captures semantic relationships**: Compute cosine similarity vs. mIoU for concept pairs to confirm metric validity before bias measurement.
  2. **Ablate threshold percentile**: Test mask accuracy across thresholds for your target demographics to confirm optimal $q$.
  3. **Sweep $\lambda$ for Pareto frontier**: Generate images at $\lambda \in \{50, 100, 150, 200\}$ on 3-5 professions to identify the fairness-quality balance before full evaluation.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do compounding demographic attributes influence internal representations when extending BiasMap to intersectional identities?
- **Basis in paper:** The Conclusion explicitly states future work will "extend BiasMap to handle intersectional identities and investigate how compounding demographic attributes influence internal representations and concept entanglement patterns."
- **Why unresolved:** The current framework and experiments evaluate gender and race strictly as independent, isolated variables.
- **What evidence would resolve it:** Experimental results applying BiasMap to compound prompts (e.g., "Black female doctor") that quantify entanglement for intersectional groups.

### Open Question 2
- **Question:** Can the hierarchical resistance of block-wise entanglement (mBIoU) be overcome to match global spatial entanglement (mIoU) reductions?
- **Basis in paper:** Appendix B.7 notes that mBIoU demonstrates "greater resistance to mitigation" than mIoU, suggesting deeper hierarchical entanglements are structurally more difficult to disentangle.
- **Why unresolved:** BiasMap achieves ~40% reduction in mIoU but only ~10% in mBIoU, indicating the energy-guided sampling fails to sufficiently alter deeper U-Net blocks.
- **What evidence would resolve it:** A modified guidance strategy that achieves parity between mBIoU and mIoU reduction rates.

### Open Question 3
- **Question:** Does the spatial overlap assumption hold for semantic concepts beyond professions, such as abstract adjectives or activities?
- **Basis in paper:** The methodology restricts experiments to 20 "occupation prompts" (Section 4) and relies on spatial localization (IoU) that may not apply to non-physical concepts.
- **Why unresolved:** Professions have predictable spatial features (faces/bodies); it is unclear if abstract concepts (e.g., "intelligent") exhibit distinct spatial attention patterns measurable by IoU.
- **What evidence would resolve it:** Validation of the BiasMap metric on abstract semantic concepts showing significant attention map overlap.

## Limitations

- The core assumption that spatial co-activation in cross-attention maps indicates representational bias (rather than legitimate semantic coupling) remains largely untested.
- The method's generalizability to non-Stable-Diffusion architectures and other generation modalities (video, 3D) remains unknown.
- Energy-guided sampling shows promise but lacks comparison to alternative mitigation strategies like classifier-free guidance modification or fine-tuning approaches.

## Confidence

- **High Confidence:** The cross-attention extraction mechanism (OVAM) and IoU-based quantification methodology are technically sound and reproducible.
- **Medium Confidence:** The claim that representational bias (measured by mIoU) is distinct from distributional bias (measured by Risk Difference) is well-supported by FairDiffusion comparison.
- **Low Confidence:** The assertion that combined representational-distributional mitigation achieves optimal performance (mIoU 0.189) lacks comparison to other combined approaches.

## Next Checks

1. **Bias Correlation Validation:** Conduct human evaluation studies to correlate mIoU scores with perceived harmful bias in generated images. Test whether concepts with high mIoU (e.g., "female+construction worker") actually produce stereotypical outputs that human raters identify as problematic.

2. **Threshold Sensitivity Analysis:** Systematically vary the mask threshold percentile (50th-90th) and evaluate how mIoU scores and mitigation effectiveness change across different demographic-semantic pairs. This would validate whether the 70th percentile is optimal for bias detection or merely convenient.

3. **Architecture Transferability Test:** Apply BiasMap to a different text-to-image architecture (e.g., Imagen, DALL-E 2, or a fine-tuned Stable Diffusion variant) to assess whether cross-attention-based bias detection and mitigation generalize beyond the original model. Compare mIoU reductions and quality preservation across architectures.