---
ver: rpa2
title: Evaluating Morphological Alignment of Tokenizers in 70 Languages
arxiv_id: '2507.06378'
source_url: https://arxiv.org/abs/2507.06378
tags:
- language
- https
- languages
- alignment
- morphological
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates whether tokenizer morphological alignment\u2014\
  measured using an expanded MorphScore metric across 70 languages\u2014correlates\
  \ with downstream language model performance. The authors expanded MorphScore to\
  \ include context, POS and frequency information, and introduced precision/recall-based\
  \ scoring to avoid oversegmentation bias."
---

# Evaluating Morphological Alignment of Tokenizers in 70 Languages

## Quick Facts
- **arXiv ID**: 2507.06378
- **Source URL**: https://arxiv.org/abs/2507.06378
- **Authors**: Catherine Arnett; Marisa Hudspeth; Brendan O'Connor
- **Reference count**: 40
- **Primary result**: Morphological alignment, as measured by MorphScore, shows a small negative correlation with downstream language model performance and explains less than 6% of variance across 70 languages.

## Executive Summary
This paper investigates whether morphological alignment of tokenizers—measured using an expanded MorphScore metric across 70 languages—correlates with downstream language model performance. The authors expanded MorphScore to include context, POS and frequency information, and introduced precision/recall-based scoring to avoid oversegmentation bias. They tested five pre-trained models (BLOOM, Gemma3, Llama2, Llama3, XGLM) on seven tasks. While frequency scaling slightly improved prediction, morphological alignment showed a small negative correlation with model performance, explaining less than 6% of variance even after controlling for model size and training data proportions. This suggests morphological alignment alone is not a strong predictor of language model task performance.

## Method Summary
The paper evaluates morphological alignment by creating gold morphological segmentations from Universal Dependencies treebanks for 70 languages, then comparing these to tokenizations from five pre-trained models. The MorphScore metric calculates precision and recall at both boundary and subword levels, with configurable parameters for frequency scaling and one-token word inclusion. The evaluation focuses on concatenative morphology (prefix-stem-suffix) and excludes isolating and introflexive languages. The authors correlate alignment scores with downstream task performance using linear mixed-effects models.

## Key Results
- Morphological alignment scores explain less than 6% of variance in model performance across all tasks
- The correlation between morphological alignment and model performance is negative rather than positive
- Frequency scaling and excluding one-token words slightly improves the predictive power of alignment metrics
- Morphological alignment alone is not a strong predictor of language model success

## Why This Works (Mechanism)

### Mechanism 1: Frequency Scaling and Exclusion of Single-Token Words Improves Predictive Power
Incorporating word frequency information and excluding single-token words from the evaluation score slightly improves the predictive power of morphological alignment metrics for downstream model performance. Frequency scaling upweights the alignment score of high-frequency words, under the assumption that these items are more important to model performance. Excluding single-token words removes cases that do not inform on the quality of subword segmentation, preventing score inflation for tokenizers with large vocabularies. This mechanism assumes that the optimal setting for the evaluation metric is determined by its ability to predict model performance, not by maximizing the raw alignment score.

### Mechanism 2: Precision Penalizes Oversegmentation, Making It a More Informative Metric than Accuracy
Using precision instead of accuracy as a metric for morphological alignment prevents a tokenizer from receiving a high score simply by segmenting words into characters or bytes. High accuracy can be trivially achieved by oversegmenting a word (e.g., into characters), as this will include all correct morpheme boundaries. Precision explicitly penalizes this by calculating the ratio of correct boundaries to total predicted boundaries, thus rewarding efficiency. This mechanism assumes that oversegmentation is undesirable and should not be conflated with good morphological alignment.

### Mechanism 3: Morphological Alignment Alone is a Weak, Often Negative, Predictor of Downstream Performance
The degree to which a tokenizer aligns with morphological boundaries is not, in itself, a strong or reliable predictor of a language model's performance on downstream tasks. The paper's primary finding is that morphological alignment scores explain very little of the variance in model performance, even after accounting for model size and training data. The observed correlation is small and negative, challenging the intuitive assumption that more linguistically sound tokenization should lead to better models. This mechanism assumes that morphological alignment captures a dimension of tokenizer quality that is relevant to how models learn and process language.

## Foundational Learning

**Concept: Morphological Alignment (Tokenization)**
*Why needed here:* This is the core concept being evaluated. It refers to how well the tokens produced by a tokenizer correspond to the meaningful morphological units (morphemes) of a word.
*Quick check question:* If a tokenizer splits the English word "unhappiness" into `[un, happy, ness]`, is this considered a morphologically aligned tokenization?

**Concept: MorphScore Evaluation Metric**
*Why needed here:* The paper introduces and expands this specific metric. Understanding its components (precision, recall) and parameters (frequency scaling, one-token word exclusion) is essential to grasp the paper's methodology and results.
*Quick check question:* Why does the paper argue for using precision instead of accuracy when calculating MorphScore?

**Concept: Downstream Task Performance**
*Why needed here:* The paper's main conclusion is about the relationship (or lack thereof) between morphological alignment and how well models perform on these tasks (e.g., XCOPA, XNLI, MultiBLiMP). This is the ultimate measure of model success.
*Quick check question:* What is the primary conclusion of the paper regarding the correlation between morphological alignment and performance on downstream tasks?

## Architecture Onboarding

**Component map:** UD Treebanks -> Gold Segmentation Creation -> Evaluation Metrics (MorphScore) -> Tokenizer -> Analysis Pipeline -> Correlation with Downstream Performance

**Critical path:** A new engineer should first understand the Gold Segmentation Creation logic, then the Evaluation Metrics (especially the difference between precision/recall and accuracy), and finally the Analysis Pipeline used to correlate scores with model performance.

**Design tradeoffs:**
- **Evaluation Metric (Precision vs. Recall vs. Accuracy):** Accuracy rewards oversegmentation. The paper chooses to report precision and recall to provide a more nuanced view, with precision penalizing oversegmentation.
- **Scoring Parameters:** The decision to frequency-scale and exclude one-token words is a tradeoff. Excluding one-token words removes data points but avoids inflating scores for tokenizers with large vocabularies. Frequency scaling is based on the assumption that high-frequency words matter more.
- **Language and Morphology Coverage:** The current approach only handles concatenative morphology (prefix-stem-suffix). It excludes isolating languages and introflexive languages (like Semitic languages) due to the difficulty in creating a gold segmentation with the current heuristic.

**Failure signatures:**
- **Language Exclusion:** A tokenizer for a Semitic (e.g., Arabic) or isolating (e.g., Chinese) language would not be evaluable with this version of MorphScore.
- **Inflated Scores:** Using accuracy as a metric would give high scores to character-level or byte-level tokenizers, which may not be useful.
- **Unexpected Negative Correlation:** Finding that higher morphological alignment is correlated with slightly worse performance. This doesn't mean the tokenizer is "broken," but it contradicts a common design assumption.

**First 3 experiments:**
1. **Replicate the MorphScore calculation:** Take the provided code and data, and run the evaluation on a tokenizer you are familiar with (e.g., a standard BPE tokenizer) for a single language (e.g., English). Compare the precision and recall scores.
2. **Ablate a scoring parameter:** Using the same tokenizer and language, run the evaluation with the "include one-token words" parameter set to `True` vs. `False`. Observe the difference in the final MorphScore.
3. **Evaluate a different tokenizer:** Take the evaluation pipeline and apply it to a different tokenizer on the same language (e.g., a tokenizer known for being less morphologically aligned) and compare the resulting scores. This validates your understanding of what the metric is measuring.

## Open Questions the Paper Calls Out
None

## Limitations
- The MorphScore metric only handles concatenative morphology and excludes isolating and introflexive languages like Chinese, Vietnamese, and Semitic languages
- The negative correlation between morphological alignment and model performance may reflect limitations in how morphological alignment is operationalized rather than a fundamental property of language modeling
- The small effect size (R² < 0.06) suggests morphological alignment may capture dimensions of tokenizer quality less relevant to downstream performance

## Confidence
**High Confidence (9/10):** The methodology for creating gold morphological segmentations from UD treebanks is well-documented and reproducible. The statistical analysis using linear mixed-effects models is appropriate for the data structure, and the finding that morphological alignment explains little variance in downstream performance is robust across different model architectures and tasks.

**Medium Confidence (6/10):** The expansion of MorphScore to include context, POS, and frequency information represents reasonable methodological improvements, but the optimal parameter settings are determined empirically rather than theoretically. The choice to use precision and recall over accuracy is well-justified, but implementation details could influence results.

**Low Confidence (3/10):** The interpretation of the negative correlation between morphological alignment and model performance should be treated cautiously. This finding contradicts common assumptions in the field and may reflect artifacts of the specific evaluation methodology rather than a genuine relationship.

## Next Checks
1. **Cross-linguistic validation with alternative alignment metrics:** Apply the same analysis pipeline using a different morphological alignment metric (such as the one proposed in "Rethinking Tokenization for Rich Morphology") to the same 70 languages and compare whether the negative correlation persists. This would test whether the finding is specific to MorphScore or reflects a more general relationship.

2. **Task-specific correlation analysis:** Instead of aggregating across all seven downstream tasks, analyze the correlation between morphological alignment and performance separately for each task type (e.g., natural language inference, coreference resolution, question answering). This could reveal whether morphological alignment matters more for certain linguistic phenomena.

3. **Token-level ablation study:** For languages showing the strongest negative correlation, conduct a token-level analysis to identify specific morphological patterns where alignment correlates positively or negatively with performance. This granular analysis could reveal whether certain types of morphological complexity (e.g., productive vs. unproductive affixation) have different relationships with model success.