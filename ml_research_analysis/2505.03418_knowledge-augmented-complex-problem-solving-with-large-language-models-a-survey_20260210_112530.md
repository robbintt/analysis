---
ver: rpa2
title: 'Knowledge Augmented Complex Problem Solving with Large Language Models: A
  Survey'
arxiv_id: '2505.03418'
source_url: https://arxiv.org/abs/2505.03418
tags:
- arxiv
- reasoning
- knowledge
- llms
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey explores the capabilities and limitations of Large
  Language Models (LLMs) in complex problem-solving, covering methodologies like Chain-of-Thought
  (CoT) reasoning, knowledge augmentation, and verification techniques. It highlights
  domain-specific challenges in software engineering, mathematics, data science, and
  scientific research, emphasizing the need for multi-step reasoning, domain knowledge
  integration, and result verification.
---

# Knowledge Augmented Complex Problem Solving with Large Language Models: A Survey

## Quick Facts
- arXiv ID: 2505.03418
- Source URL: https://arxiv.org/abs/2505.03418
- Reference count: 40
- Primary result: Comprehensive survey of LLM-based approaches to complex problem-solving across multiple domains

## Executive Summary
This survey examines the capabilities and limitations of Large Language Models (LLMs) in complex problem-solving, focusing on methodologies like Chain-of-Thought reasoning, knowledge augmentation, and verification techniques. The paper systematically reviews approaches across software engineering, mathematics, data science, and scientific research domains, highlighting the critical need for multi-step reasoning, domain knowledge integration, and result verification. The survey identifies key challenges including data scarcity, computational costs, and the need for improved reasoning abilities. It proposes future research directions aimed at enhancing LLMs' problem-solving capabilities through better knowledge integration and robust evaluation frameworks.

## Method Summary
The survey synthesizes existing literature on LLM-based complex problem-solving approaches through systematic review of methodologies including Chain-of-Thought reasoning, knowledge augmentation techniques, and verification frameworks. The authors analyze these approaches across multiple domains (software engineering, mathematics, data science, scientific research) to identify common patterns, challenges, and opportunities. The methodology involves categorizing problem-solving techniques, evaluating their effectiveness based on reported results in the literature, and identifying gaps in current approaches. The survey emphasizes the importance of multi-step reasoning and domain-specific knowledge integration while highlighting computational and data-related limitations.

## Key Results
- LLMs require knowledge augmentation and verification techniques to effectively solve complex, multi-step problems
- Different domains (software engineering, mathematics, data science, scientific research) present unique challenges for LLM problem-solving
- Current limitations include data scarcity, high computational costs, and insufficient reasoning capabilities
- Future directions include improving reasoning abilities, enhancing knowledge integration, and developing robust evaluation frameworks

## Why This Works (Mechanism)
The survey works by systematically organizing and analyzing existing research on LLM-based complex problem-solving, identifying patterns across different methodologies and domains. By categorizing approaches like Chain-of-Thought reasoning, knowledge augmentation, and verification techniques, the paper reveals how these methods address the fundamental challenge of breaking down complex problems into manageable steps while ensuring accuracy through verification.

## Foundational Learning
- **Chain-of-Thought (CoT) reasoning**: Step-by-step problem decomposition needed to enable LLMs to handle multi-step problems; quick check: verify whether intermediate reasoning steps lead to correct final answers
- **Knowledge augmentation**: Integration of external domain knowledge to supplement LLM capabilities; quick check: measure performance improvement when adding specific domain knowledge
- **Verification techniques**: Methods to validate LLM-generated solutions; quick check: compare verification accuracy against ground truth across multiple problem types
- **Multi-step reasoning**: Ability to maintain coherence across sequential problem-solving steps; quick check: test whether LLMs can correctly chain together multiple reasoning operations
- **Domain-specific adaptation**: Tailoring LLM approaches to particular problem domains; quick check: evaluate performance differences across software engineering, mathematics, and scientific domains

## Architecture Onboarding

Component map: Problem Statement -> Knowledge Retrieval -> Chain-of-Thought Reasoning -> Solution Generation -> Verification -> Final Output

Critical path: The most critical path is Problem Statement -> Knowledge Retrieval -> Chain-of-Thought Reasoning -> Verification, as each step builds on the previous one and errors compound through the pipeline.

Design tradeoffs: Accuracy vs. computational cost (more verification steps increase reliability but require more resources), knowledge breadth vs. specificity (general vs. domain-specific knowledge integration), and reasoning depth vs. practical usability (complex reasoning vs. real-time application).

Failure signatures: Incorrect intermediate steps in Chain-of-Thought reasoning, knowledge retrieval failures leading to hallucination, verification systems missing critical errors, and domain mismatch between problem context and retrieved knowledge.

First experiments:
1. Compare Chain-of-Thought reasoning performance with and without knowledge augmentation on multi-step math problems
2. Test verification system accuracy by introducing controlled errors at different stages of the problem-solving pipeline
3. Evaluate computational cost scaling when increasing knowledge retrieval depth and verification steps

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but implicitly raises several through its discussion of limitations and future directions, including how to improve LLMs' inherent reasoning capabilities, how to efficiently integrate domain knowledge, and how to develop standardized evaluation frameworks for complex problem-solving.

## Limitations
- Claims about methodology effectiveness are primarily based on literature reviews rather than original empirical validation
- Limited discussion of reproducibility challenges and specific conditions under which approaches succeed or fail
- May not fully capture nuanced differences in problem-solving requirements across different domains

## Confidence
- High Confidence: General problem-solving challenges and the need for verification are well-supported by existing literature
- Medium Confidence: Specific methodology effectiveness claims are reasonable but lack direct empirical validation in this work
- Low Confidence: Predictions about future research directions and their potential impact are necessarily speculative

## Next Checks
1. Conduct systematic reproduction studies comparing different knowledge augmentation and verification approaches across multiple problem domains to validate claimed effectiveness
2. Perform controlled experiments testing the scalability and computational efficiency of proposed methods under varying data availability conditions
3. Develop standardized evaluation frameworks that can assess complex problem-solving capabilities across different domains while accounting for domain-specific requirements and constraints