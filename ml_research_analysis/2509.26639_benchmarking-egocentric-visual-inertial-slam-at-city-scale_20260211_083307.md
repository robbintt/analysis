---
ver: rpa2
title: Benchmarking Egocentric Visual-Inertial SLAM at City Scale
arxiv_id: '2509.26639'
source_url: https://arxiv.org/abs/2509.26639
tags:
- egocentric
- sequence
- slam
- data
- sequences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LaMAria, a new dataset and benchmark for
  egocentric visual-inertial SLAM at city scale. The dataset addresses the lack of
  benchmarks that reflect the unique challenges of egocentric data, such as diverse
  motion patterns, low-light conditions, moving platforms, and long-duration recordings.
---

# Benchmarking Egocentric Visual-Inertial SLAM at City Scale

## Quick Facts
- arXiv ID: 2509.26639
- Source URL: https://arxiv.org/abs/2509.26639
- Authors: Anusha Krishnan; Shaohui Liu; Paul-Edouard Sarlin; Oscar Gentilhomme; David Caruso; Maurizio Monge; Richard Newcombe; Jakob Engel; Marc Pollefeys
- Reference count: 40
- Introduces LaMAria, a new dataset and benchmark for egocentric visual-inertial SLAM at city scale

## Executive Summary
This paper introduces LaMAria, a new dataset and benchmark for egocentric visual-inertial SLAM at city scale. The dataset addresses the lack of benchmarks that reflect the unique challenges of egocentric data, such as diverse motion patterns, low-light conditions, moving platforms, and long-duration recordings. It features multi-modal sensor data captured by glasses-like devices worn by participants navigating through Zurich's city center, covering extensive trajectories spanning kilometers.

The dataset includes centimeter-accurate ground-truth poses derived from surveyed control points, enabling precise evaluation of SLAM algorithms. The authors evaluate state-of-the-art VIO/SLAM systems, revealing significant performance gaps under egocentric conditions compared to controlled environments. The results highlight the need for advancements in handling time-varying calibration, dynamic environments, and robust tracking under challenging conditions. The dataset and benchmark are publicly released to foster progress in multi-sensor SLAM research.

## Method Summary
The LaMAria dataset was collected using glasses-like devices equipped with multiple sensors including cameras and IMUs. Participants navigated through Zurich's city center while wearing these devices, capturing multi-modal sensor data across extensive trajectories spanning kilometers. Ground-truth poses were obtained through centimeter-accurate surveying of control points throughout the environment. The dataset addresses challenges specific to egocentric SLAM including diverse motion patterns, low-light conditions, moving platforms, and long-duration recordings.

## Key Results
- State-of-the-art VIO/SLAM systems show significant performance degradation under egocentric conditions compared to controlled environments
- Centimeter-accurate ground-truth poses enable precise evaluation of SLAM algorithms
- LaMAria dataset captures unique challenges including time-varying calibration and dynamic urban environments
- Public release enables community-wide benchmarking and algorithm development

## Why This Works (Mechanism)
The success of LaMAria stems from its realistic representation of egocentric SLAM challenges in urban environments. By capturing data from wearable glasses in real-world conditions, the dataset exposes algorithms to motion patterns, lighting variations, and dynamic elements that are difficult to simulate. The centimeter-accurate ground-truth enables precise error measurement, while the diverse trajectory coverage ensures robustness evaluation across different scenarios.

## Foundational Learning

### Visual-Inertial Odometry
**Why needed:** Fuses camera and IMU data for accurate motion estimation in GPS-denied environments
**Quick check:** Verify sensor fusion equations and time synchronization between camera frames and IMU measurements

### SLAM Loop Closure
**Why needed:** Corrects drift accumulation over long trajectories through place recognition and pose graph optimization
**Quick check:** Confirm loop detection rate and optimization convergence across the full trajectory

### Calibration
**Why needed:** Ensures accurate sensor alignment and scale for proper data fusion
**Quick check:** Validate extrinsic calibration accuracy and time-varying compensation methods

## Architecture Onboarding

### Component Map
Sensor Suite -> Data Acquisition -> Preprocessing -> SLAM Pipeline -> Ground Truth Comparison

### Critical Path
IMU Data → Visual Feature Extraction → Motion Estimation → Map Building → Loop Closure → Pose Optimization

### Design Tradeoffs
High-frequency IMU vs computational cost, visual feature density vs processing time, map size vs localization accuracy

### Failure Signatures
Tracking loss in low-light conditions, drift accumulation during dynamic scenes, calibration errors from rapid motion

### First Experiments
1. Baseline VIO performance on static segments
2. Dynamic scene tracking robustness evaluation
3. Long-term drift analysis over extended trajectories

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability to other urban environments beyond Zurich may be limited
- Specific impact of different motion patterns on algorithm performance requires further analysis
- Ground-truth accuracy methodology across extended urban trajectories needs more detailed validation

## Confidence

- Dataset creation methodology: Medium - Describes sensor setup but lacks ground-truth verification details
- Performance gap claims: High - Well-documented results showing VIO/SLAM degradation under egocentric conditions
- Benchmark utility for research community: Medium - Public release noted but community adoption analysis not provided

## Next Checks

1. Conduct cross-validation studies using LaMAria with additional VIO/SLAM algorithms not included in original benchmark
2. Perform comparative analysis between LaMAria and other egocentric SLAM datasets to quantify unique challenges
3. Implement and evaluate error-correction techniques specifically designed for long-duration urban SLAM