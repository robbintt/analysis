---
ver: rpa2
title: Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search
arxiv_id: '2509.20838'
source_url: https://arxiv.org/abs/2509.20838
tags:
- privacy
- rewrite
- rewriting
- sentence
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses privacy risks in cloud-based LLM services by
  proposing a zero-shot, tree-search-based iterative rewriting method that systematically
  removes or obscures private information while preserving text naturalness and utility.
  The core method, NaPaRe, uses Monte Carlo Tree Search (MCTS) with a reward model
  to incrementally rewrite privacy-sensitive segments, exploring deletion and obscuring
  strategies through structured decision-making.
---

# Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search
## Quick Facts
- arXiv ID: 2509.20838
- Source URL: https://arxiv.org/abs/2509.20838
- Authors: Shuo Huang; Xingliang Yuan; Gholamreza Haffari; Lizhen Qu
- Reference count: 18
- Primary result: 22.3% relative improvement in privacy preservation over baselines

## Executive Summary
This paper presents NaPaRe, a zero-shot privacy-aware text rewriting method that systematically removes or obscures private information from text while preserving naturalness and utility. The approach uses Monte Carlo Tree Search (MCTS) with a reward model to incrementally rewrite privacy-sensitive segments through deletion or obscuring strategies. Experiments on NAP2 dialogue and ECHR legal judgment datasets demonstrate significant privacy preservation gains while maintaining high text quality and utility scores.

## Method Summary
NaPaRe employs a tree-search-based iterative rewriting approach that incrementally modifies text through structured decision-making. The method uses MCTS to explore deletion and obscuring strategies for privacy-sensitive segments, guided by a reward model that balances privacy preservation with text utility. The system operates without fine-tuning, making it deployable on medium-sized LLMs locally. The iterative process systematically identifies and rewrites privacy-sensitive content while maintaining text coherence and semantic meaning.

## Key Results
- Achieves 22.3% relative improvement in privacy preservation (PRIVACY_NLI) over baselines
- Maintains ROUGE-1 scores above 73% while keeping perplexity within 1.5 points of original text
- Demonstrates robustness against optimal reconstruction attacks while preserving text utility

## Why This Works (Mechanism)
The method works by combining structured search with reward-based decision making to systematically identify and modify privacy-sensitive content. MCTS explores multiple rewriting paths, allowing the system to find optimal trade-offs between privacy removal and text preservation. The reward model guides this exploration by quantifying the privacy-utility balance, enabling the system to make informed decisions about which segments to delete or obscure.

## Foundational Learning
- Monte Carlo Tree Search (MCTS): A search algorithm that balances exploration and exploitation to find optimal decision paths. Needed for systematic exploration of rewriting strategies.
- Reward modeling: Framework for quantifying trade-offs between competing objectives. Critical for balancing privacy preservation with text utility.
- Privacy risk scoring: Methods for identifying sensitive information in text. Essential for targeting privacy-sensitive segments during rewriting.
- Text utility metrics: ROUGE and perplexity measures for evaluating text quality. Used to ensure rewriting preserves meaningful content.

## Architecture Onboarding
Component map: Input text -> Privacy scorer -> MCTS search -> Reward model -> Output text

Critical path: Privacy identification → Search space construction → MCTS decision making → Text rewriting → Quality evaluation

Design tradeoffs: The method balances privacy preservation against text utility, with MCTS providing systematic exploration but at computational cost. The zero-shot approach avoids fine-tuning but may be less precise than specialized models.

Failure signatures: 
- Over-aggressive rewriting leading to loss of meaningful content
- Under-aggressive rewriting leaving privacy risks intact
- Computational timeouts on long documents
- Inconsistent outputs across multiple runs

First experiments:
1. Run baseline privacy preservation on sample text to establish reference metrics
2. Execute single MCTS iteration on privacy-sensitive segment to verify search mechanics
3. Test reward model calibration on simple deletion vs. obscuring decisions

## Open Questions the Paper Calls Out
None

## Limitations
- Privacy preservation claims rely on model-based metrics that may not capture all real-world privacy threats
- Computational overhead of MCTS may limit scalability for long documents and real-time applications
- Iterative rewriting process may introduce subtle semantic drifts not captured by standard metrics

## Confidence
- Privacy Preservation Efficacy: High (supported by multiple evaluation metrics and cross-dataset validation)
- Text Utility Maintenance: High (ROUGE scores above 73% and controlled perplexity demonstrate quality preservation)
- Computational Feasibility: Medium (works on medium-sized models but scalability limitations remain)

## Next Checks
1. Conduct systematic adversarial attacks using state-of-the-art privacy extraction methods to verify robustness beyond optimal attack baseline
2. Evaluate method's effectiveness and computational efficiency on documents exceeding 1000 words to quantify quadratic scaling behavior
3. Implement fine-grained semantic similarity metrics to detect subtle meaning changes from multiple rewriting iterations not captured by ROUGE scores