---
ver: rpa2
title: Sentiment Analysis On YouTube Comments Using Machine Learning Techniques Based
  On Video Games Content
arxiv_id: '2511.06708'
source_url: https://arxiv.org/abs/2511.06708
tags:
- sentiment
- comments
- gaming
- data
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study applied sentiment analysis to YouTube gaming comments\
  \ using TextBlob and machine learning classifiers (Na\xEFve Bayes, Logistic Regression,\
  \ SVM). The 11,781 comments from three IGN gaming review videos were pre-processed\
  \ (lowercasing, stop word removal, tokenization, lemmatization) and classified into\
  \ positive, negative, or neutral sentiments."
---

# Sentiment Analysis On YouTube Comments Using Machine Learning Techniques Based On Video Games Content

## Quick Facts
- arXiv ID: 2511.06708
- Source URL: https://arxiv.org/abs/2511.06708
- Reference count: 0
- Primary result: SVM achieved highest classification accuracy across 11,781 YouTube gaming comments

## Executive Summary
This study conducted sentiment analysis on YouTube gaming comments using machine learning techniques. The research focused on 11,781 comments from three IGN gaming review videos, applying preprocessing techniques including lowercasing, stop word removal, tokenization, and lemmatization. TextBlob was used for initial sentiment labeling, followed by classification using Naïve Bayes, Logistic Regression, and SVM classifiers. The study aimed to provide insights for game developers to improve user experience based on community feedback.

## Method Summary
The methodology involved collecting 11,781 YouTube comments from three IGN gaming review videos, followed by standard text preprocessing (lowercasing, stop word removal, tokenization, lemmatization). TextBlob provided initial sentiment labels (positive, negative, neutral), which were then used to train and evaluate three machine learning classifiers: Naïve Bayes, Logistic Regression, and SVM. The classifiers were assessed on their ability to categorize comments into sentiment categories, with SVM demonstrating consistent superiority across all dataset sizes (854, 3,526, and 7,401 comments).

## Key Results
- SVM classifier achieved highest accuracy across all three comment datasets
- Text preprocessing pipeline included lowercasing, stop word removal, tokenization, and lemmatization
- Sentiment analysis categorized comments into positive, negative, or neutral sentiments
- Results provide actionable insights for game developers to refine designs

## Why This Works (Mechanism)
Assumption: SVM's kernel trick effectively maps high-dimensional comment text into separable feature spaces, enabling accurate sentiment classification despite noisy gaming-specific language patterns.

## Foundational Learning
- Text preprocessing: why needed - to standardize and clean text data for analysis; quick check - verify consistent output format
- Machine learning classifiers: why needed - to automate sentiment categorization; quick check - test with known sentiment examples
- SVM algorithm: why needed - handles high-dimensional feature spaces well; quick check - compare with baseline classifiers
- TextBlob lexicon: why needed - provides initial sentiment labeling; quick check - validate against human-labeled data

## Architecture Onboarding
**Component Map:** TextBlob -> Preprocessing -> SVM Classifier -> Sentiment Classification
**Critical Path:** Raw comments → Preprocessing → SVM Training → Sentiment Classification
**Design Tradeoffs:** Standard preprocessing vs. gaming-specific terminology retention
**Failure Signatures:** Incorrect classification of slang, sarcasm, and gaming-specific language
**First Experiments:** 1) Compare SVM with other classifiers on gaming-specific dataset 2) Test TextBlob against gaming-specialized sentiment tools 3) Evaluate preprocessing impact on classification accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset limited to IGN gaming review videos, reducing representativeness
- Preprocessing may oversimplify gaming-specific language and slang
- Binary classification approach oversimplifies nuanced sentiment expressions
- TextBlob lexicon not optimized for gaming-specific language patterns

## Confidence
- SVM classification performance: Medium-High
- TextBlob sentiment labeling: Medium
- Pre-processing effectiveness: Medium
- Generalizability of findings: Low

## Next Checks
1. Replicate analysis using diverse YouTube gaming comment corpus from multiple sources and gaming genres
2. Compare TextBlob performance against gaming-specific sentiment analysis tools and fine-tuned transformer models
3. Conduct ablation studies to assess impact of different preprocessing decisions on classification accuracy