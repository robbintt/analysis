---
ver: rpa2
title: Extracting Rule-based Descriptions of Attention Features in Transformers
arxiv_id: '2510.18148'
source_url: https://arxiv.org/abs/2510.18148
tags:
- features
- feature
- attention
- rules
- output
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes rule-based descriptions for SAE features in
  attention layers, aiming to provide interpretable explanations beyond exemplar inspection.
  It formalizes three types of rules: skip-gram patterns promoting outputs, absence
  rules suppressing them, and counting rules based on frequency.'
---

# Extracting Rule-based Descriptions of Attention Features in Transformers

## Quick Facts
- arXiv ID: 2510.18148
- Source URL: https://arxiv.org/abs/2510.18148
- Reference count: 21
- Key outcome: Rule-based descriptions (skip-gram, absence, counting) achieve high F1 scores (up to 0.8) for SAE features in attention layers, with performance declining in higher layers.

## Executive Summary
This paper introduces a method to automatically extract interpretable rule-based descriptions for features in transformer attention layers. The approach decomposes attention computations into key-query feature interactions and ranks them by importance using either weight-based or gradient-based heuristics. Applied to GPT-2 small, skip-gram rules achieve high F1 scores with ~100 terms, while absence rules are found in over 25% of features even in early layers. The method reveals non-obvious suppression and counting mechanisms beyond simple exemplar inspection, though performance degrades in deeper layers.

## Method Summary
The method trains Sparse Autoencoders (SAEs) on attention layer outputs to decompose dense activations into interpretable features. For each attention head, it computes attention-score and value-score matrices by projecting attention weights into SAE feature space. The approach selects top candidate key-query pairs (10,000 total), then ranks them using weight-based importance (attention-score Ã— value-score) or gradient-based importance. Rules are evaluated by predicting binary feature activation from sequences and computing precision, recall, and F1 scores against ground truth.

## Key Results
- Skip-gram rules achieve F1 scores up to 0.8 with ~100 terms in early layers
- Absence rules found in over 25% of features even in early layers
- Counting rules identified in layer 0, where activation scales with pattern frequency
- Performance degrades significantly in higher layers, requiring exponentially more terms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Attention head behavior can be approximated by skip-gram rules where specific query-key feature pairs predict output activation.
- Mechanism: The method decomposes output activation into weighted sums of attention-score (measuring query-key alignment) and value-score (measuring key-output promotion). High values for both scores predict the output feature activation.
- Core assumption: SAE features are monosemantic enough that individual key-query pairs carry distinct semantic meaning.
- Evidence: Skip-gram rules achieve high F1 scores (up to 0.8) with ~100 terms; concrete examples show rules like "...[If]...[then]" explaining feature behavior.

### Mechanism 2
- Claim: Attention features implement absence rules that suppress output when distractor patterns are present.
- Mechanism: A distractor key can suppress output by stealing attention focus (higher attention-score than original key) while having low or negative value-score for the output feature.
- Core assumption: Softmax competition in attention is sufficient for single distractors to suppress outputs.
- Evidence: Absence rules found in over 25% of features; sequences containing both key-query pairs and distractors show lower activation on average.

### Mechanism 3
- Claim: Certain attention features operate as counting rules, activating based on pattern frequency.
- Mechanism: Output activation aggregates contributions from multiple instances of a key feature with positive value-score, creating frequency-dependent behavior.
- Core assumption: Query features attend broadly enough to capture multiple instances of key features.
- Evidence: Features show activation scaling linearly with the number of times specific words (e.g., "games") appear in sequences.

## Foundational Learning

- Concept: Sparse Autoencoders (SAEs)
  - Why needed here: The entire method relies on decomposing dense residual stream into interpretable input and output features before rules can be extracted.
  - Quick check question: Can you explain the difference between a feature activation and a feature vector in the context of the SAE reconstruction equation?

- Concept: Key-Query-Value (KQV) Decomposition
  - Why needed here: The paper rewrites standard attention into specific score terms (attention-score and value-score). Understanding that Q drives "what to look for" and K drives "what is available" is essential to skip-gram rules.
  - Quick check question: In the equation attn-score(q, k) = d_q^T W_Q^T W_K d_k, which term represents the "query" feature and which represents the "key" feature?

- Concept: Gradient-based Attribution
  - Why needed here: Simple weight magnitude isn't always sufficient to determine functional importance. The paper uses gradients to rank which key-query pairs actually cause output features to fire.
  - Quick check question: Why might a feature pair have large weight magnitude but small gradient impact on final output activation?

## Architecture Onboarding

- Component map: Input Layer (SAE on residual stream) -> Analysis Core (attention weights projected to SAE space) -> Scoring Engine (attn-score and value-score matrices) -> Rule Extractor (ranking and selection)

- Critical path: The extraction of value-score and attn-score matrices. If these decompositions are noisy or SAEs are misaligned, downstream rules will be hallucinated or inaccurate.

- Design tradeoffs:
  - Weight-based vs. Gradient-based Ranking: Weight-based methods are faster and purely structural, while gradient-based methods capture functional causality better at computational cost.
  - Layer Depth: Works best on early layers (0-2); deeper layers require exponentially more terms due to feature superposition or non-linear interactions.

- Failure signatures:
  - Illusory Rules: High F1 on validation but fail on out-of-distribution text (indicates SAE features not generalizing)
  - Missing Absence Rules: High false positives indicate missing distractor key in rule description
  - Superposition Collapse: If active features >> expected sparsity, linear decomposition fails and rules become incoherent

- First 3 experiments:
  1. Reproduce L0H0 "If...then" Skip-gram: Extract features for Layer 0 Head 0, verify top-scoring key-query pairs correspond to conditional tokens, measure F1 score
  2. Validate an Absence Rule: Identify URL-detection feature, inject "twitter" into activating sequences, measure activation drop
  3. Probe a Counting Rule: Isolate "games" counting feature and plot activation as function of "games" frequency to verify linearity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can rule-based descriptions be formulated when attention computation depends on multiple active features at a single token?
- Basis in paper: Section 5 states future work is needed for features where rules depend on balance between positive and negative feature interactions at each position.
- Why unresolved: Current method assumes single feature per token, simplifying complexity of positional and semantic feature mixing.
- What evidence would resolve it: A method successfully disentangling and representing rules involving multiple concurrent feature interactions, validated by improved F1 scores.

### Open Question 2
- Question: Can optimizing input feature decomposition jointly with attention output features improve rule quality?
- Basis in paper: Section 5 suggests developing methods for optimizing input feature decomposition jointly with attention output features, with regularization to favor shorter rules.
- Why unresolved: Current approach uses pre-trained SAEs that may not align perfectly with attention computation.
- What evidence would resolve it: Demonstrating jointly trained SAE yields higher precision/recall for rule extraction with fewer terms compared to static SAEs.

### Open Question 3
- Question: How can extracted attention rules for individual heads be composed to characterize larger computational units?
- Basis in paper: Section 5 asks how to characterize how single-head features combine to form multi-head features and cross-layer circuits.
- Why unresolved: Work focuses on per-head feature extraction; aggregation and interaction across full model architecture remain unexplored.
- What evidence would resolve it: A framework successfully linking individual head rules into larger computational graphs and validating through causal intervention.

## Limitations

- Dependence on SAE feature quality and monosemanticity assumptions
- Constrained analysis to GPT-2 small, limiting generalization to larger models
- Lack of rigorous mathematical framework for counting rule emergence
- Focus on individual feature behavior rather than compositional interactions

## Confidence

- **High confidence**: Skip-gram rules achieving F1 scores up to 0.8 with ~100 terms (directly measurable and well-validated)
- **Medium confidence**: Absence rules found in over 25% of features even in early layers (mechanism plausible but statistical significance not rigorously established)
- **Low confidence**: Counting rules activating based on frequency thresholds (empirical cases presented but lacking formal mathematical framework)

## Next Checks

1. **Ablation study on SAE sparsity**: Systematically vary SAE dictionary size and sparsity targets to measure impact on rule F1 scores, quantifying sensitivity to SAE quality.

2. **Out-of-distribution robustness test**: Apply extracted rules to text from different domains (code, formal writing) and measure performance degradation to validate linguistic pattern capture.

3. **Compositionality probe**: Design test sequences requiring multiple simultaneous rules (skip-gram + absence) and measure whether model can compose these mechanisms to test full expressive power capture.