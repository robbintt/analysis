---
ver: rpa2
title: Evaluating the Effect of Retrieval Augmentation on Social Biases
arxiv_id: '2502.17611'
source_url: https://arxiv.org/abs/2502.17611
tags:
- bias
- social
- documents
- biases
- diff-bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper systematically investigates how retrieval-augmented
  generation (RAG) influences social biases in large language models across three
  languages (English, Japanese, Chinese) and four bias types (gender, race, age, religion).
  Using the Bias Question Answering (BBQ) benchmark, the study evaluates social biases
  in RAG responses from document collections with varying levels of stereotypical
  biases and multiple generator LLMs.
---

# Evaluating the Effect of Retrieval Augmentation on Social Biases

## Quick Facts
- arXiv ID: 2502.17611
- Source URL: https://arxiv.org/abs/2502.17611
- Reference count: 40
- Key outcome: Retrieval-augmented generation significantly amplifies social biases in generated responses, even when base models have low intrinsic bias

## Executive Summary
This paper systematically investigates how retrieval-augmented generation (RAG) influences social biases across multiple languages and bias types. Using the Bias Question Answering (BBQ) benchmark, the study evaluates social biases in RAG responses from document collections with varying levels of stereotypical biases and multiple generator LLMs. The key finding is that biases in document collections are often significantly amplified in generated responses, even when the generating LLM exhibits low intrinsic bias. This bias amplification effect was observed across all languages and bias types tested, raising concerns about the use of RAG for injecting novel facts into NLG systems.

## Method Summary
The study evaluates social biases in RAG responses using the BBQ benchmark across three languages (English, Japanese, Chinese) and four bias types (gender, race, age, religion). The evaluation systematically varies document collections with different levels of stereotypical biases and tests multiple generator LLMs. The methodology includes both baseline evaluations of LLMs without retrieval and RAG-enhanced evaluations where retrieved documents influence the generation. The study also examines instruction-tuned models to assess whether fine-tuning reduces bias amplification in RAG scenarios.

## Key Results
- Biases in document collections are significantly amplified in generated responses, even when base LLMs have low intrinsic bias
- Instruction tuning can reduce baseline model bias but this improvement is fragile and easily compromised by RAG
- Bias amplification occurs consistently across all tested languages and bias types

## Why This Works (Mechanism)
RAG systems retrieve documents and use them to augment the generation process, meaning any biases present in retrieved documents directly influence the output. When documents contain stereotypical biases, these biases are incorporated into the generation context, leading to amplified biased responses. The mechanism involves the retriever selecting biased documents and the generator incorporating these biases into its output, creating a multiplicative effect where document biases combine with any existing model biases.

## Foundational Learning
- **RAG (Retrieval-Augmented Generation)**: Why needed - To understand how retrieval affects generation; Quick check - Can you explain how retrieved documents influence LLM outputs?
- **Social bias metrics**: Why needed - To quantify bias amplification; Quick check - Can you define common bias evaluation metrics used in NLP?
- **Instruction tuning**: Why needed - To assess whether fine-tuning mitigates bias amplification; Quick check - Can you explain how instruction tuning differs from standard fine-tuning?

## Architecture Onboarding
Component map: Retriever -> Document collection -> Generator LLM -> Generated response

Critical path: Question -> Retriever selects documents -> Generator uses documents for context -> Response generated with potential bias amplification

Design tradeoffs: Balancing information retrieval accuracy with bias mitigation - more relevant documents may also be more biased

Failure signatures: Systematic amplification of stereotypes across different language pairs and bias types, regardless of base model bias levels

First experiments:
1. Test bias amplification using documents with known, controlled bias levels
2. Compare bias amplification across different retriever models
3. Evaluate whether debiasing techniques applied to retriever vs generator have different effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Findings are based on synthetic document collections that may not represent real-world retrieval scenarios
- The bias intensity in test documents may be stronger than typically found in real documents
- Document structure in synthetic collections may differ from real-world documents

## Confidence
- Confidence in core finding of bias amplification: High
- Confidence in practical implications for RAG deployment: Medium (due to artificial test conditions)
- Confidence in generator model choice affecting amplification: Medium (limited number of models tested)

## Next Checks
1. Test the same methodology on real-world document collections to assess external validity
2. Conduct ablation studies to isolate relative contributions of retriever vs generator bias
3. Evaluate whether bias mitigation techniques applied to either component can reduce or eliminate bias amplification