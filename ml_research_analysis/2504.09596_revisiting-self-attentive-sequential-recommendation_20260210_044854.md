---
ver: rpa2
title: Revisiting Self-Attentive Sequential Recommendation
arxiv_id: '2504.09596'
source_url: https://arxiv.org/abs/2504.09596
tags:
- sequential
- item
- recommender
- more
- items
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper revisits the self-attentive sequential recommendation
  (SASRec) model and identifies several areas for improvement. The authors highlight
  issues with personalization, embedding usage, and positional encoding in SASRec.
---

# Revisiting Self-Attentive Sequential Recommendation

## Quick Facts
- arXiv ID: 2504.09596
- Source URL: https://arxiv.org/abs/2504.09596
- Reference count: 9
- This paper identifies issues with personalization, embedding usage, and positional encoding in SASRec and proposes new experiments to address them.

## Executive Summary
This paper critically examines the self-attentive sequential recommendation (SASRec) model and identifies several areas for improvement. The authors highlight problems with positional embedding implementation, sampling bias, and personalization limitations. Rather than presenting new results, the paper proposes a series of foundational experiments to address these issues and motivate further research on scaling up self-attentive sequential recommenders. The work serves as a roadmap for future research by identifying specific technical challenges and experimental methodologies.

## Method Summary
The paper revisits the SASRec architecture for sequential recommendation, which uses transformer decoder layers to predict the next item in a user's interaction sequence. The method employs item embeddings combined with positional embeddings, with causal masking to ensure predictions depend only on previous items. The authors propose modifications including corrected positional embedding usage (batching by sequence length to ensure relative positions), autoregressive prediction capabilities, item tokenization for scalability, duality between users and items for consistency regularization, and alternative sampling algorithms to address bias. While no primary results are presented, the paper outlines implementation approaches for each proposed experiment.

## Key Results
- No primary experimental results presented; paper focuses on proposing new experimental methodologies
- Identifies positional embedding implementation flaw where absolute positions are used instead of relative positions to prediction point
- Proposes duality experiment between user and item representations to improve embedding consistency
- Highlights sampling bias issue where training data reflects baseline model outputs rather than ground truth
- Suggests tokenization of items as necessary for scaling beyond current limitations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Correcting positional embedding usage may improve training signal quality and model scalability.
- Mechanism: The current SASRec implementation applies absolute positional embeddings incorrectly when batching sequences. For a prediction at position k within a packed sequence, items receive positional embeddings relative to the sequence end rather than relative to the prediction point. Reorganizing training samples by sequence length (batching all length=1 together, length=2 together, etc.) would ensure positional embeddings encode semantically correct relative positions.
- Core assumption: Positional information relative to the prediction point carries meaningful signal for sequential recommendation; absolute position is less informative.
- Evidence anchors:
  - [abstract]: "correcting positional embedding usage" listed as one of five critical experiments
  - [section 3.3]: Documents the specific mismatch—e.g., `[ix1, ix2, ..., ixl−2] → [(eix1 + epl−1), ...]` used instead of expected `[... + epl−2)]` for position-relative encoding
  - [corpus]: Weak direct evidence; neighboring papers focus on attention enhancements rather than positional encoding corrections
- Break condition: If positional embeddings provide negligible signal in item-ID sequences (which may be more sparse/random than language tokens), corrections yield minimal gains.

### Mechanism 2
- Claim: Enforcing consistency between user-derived and item-derived embeddings may improve representation robustness.
- Mechanism: Under the "you are what you interacted with" assumption, users can be represented as sequences of item embeddings. The duality experiment proposes also representing items as sequences of user embeddings (users who interacted with that item), then enforcing consistency between high-order item embeddings and original item embeddings—similar to round-trip translation consistency.
- Core assumption: User-item interaction graphs contain symmetric structure exploitable via bidirectional encoding; embedding spaces can be regularized through cycle-consistency constraints.
- Evidence anchors:
  - [abstract]: "exploring duality between users and items" proposed as experiment
  - [section 4.4]: Describes the duality approach with analogy to machine translation back-and-forth consistency
  - [corpus]: No direct corpus evidence for this specific mechanism in neighboring papers
- Break condition: If user sequences for items are too sparse or high-velocity (items with few interactions, rapidly changing user bases), consistency regularization introduces noise rather than signal.

### Mechanism 3
- Claim: Treating recommendation as autoregressive generation rather than single-step prediction may reveal model characteristics and optimization opportunities.
- Mechanism: Standard sequential recommendation leaves the last item for testing and second-to-last for validation. Autoregressive generation produces longer outputs, exposing model behavior across extended prediction horizons. This diagnostic capability could inform architecture refinements without changing core structure.
- Core assumption: Model weaknesses (e.g., drift, hallucination-like behavior in recommendation) manifest more clearly over longer generation horizons.
- Evidence anchors:
  - [abstract]: "enabling autoregressive predictions" listed as proposed experiment
  - [section 4.2]: States that longer outputs reveal more about model characteristics for optimization
  - [corpus]: Corpus papers (e.g., "Think Before Recommend") explore reasoning mechanisms but not specifically autoregressive diagnostics
- Break condition: If item-ID sequences lack the compositional structure of language tokens, autoregressive generation may not expose meaningful diagnostics.

## Foundational Learning

- Concept: **Positional vs. Absolute Embeddings**
  - Why needed here: The paper's central critique hinges on distinguishing between positional embeddings that encode relative order versus those encoding absolute position. Understanding this distinction is prerequisite to evaluating the proposed correction experiment.
  - Quick check question: Given sequence [A, B, C] where we predict after B, should position 1 encode "first item in the sequence" or "two positions before prediction"?

- Concept: **Negative Sampling Bias**
  - Why needed here: Section 3.2 and 4.5 discuss how training data reflects baseline model outputs (not ground truth) and how negative sampling excludes interacted items, introducing systematic bias.
  - Quick check question: If a user interacted with item X because it was recommended by a baseline model, what confounding factor does this introduce when training a new model to predict X?

- Concept: **Embedding as High-Dimensional Space**
  - Why needed here: Section 3.3 frames embeddings as "item positions in a high-dimensional supermarket" and discusses padding embedding issues acting as unintended bias terms.
  - Quick check question: If padding tokens have non-zero embeddings, what incorrect signal do they contribute to the final representation?

## Architecture Onboarding

- Component map:
  - Input Layer: Item ID sequences + positional embeddings (currently misaligned)
  - Embedding Layer: Item embeddings (ei) and positional embeddings (ep) — padding handling is critical
  - Transformer Decoder Stack: Self-attention layers operating on combined embeddings
  - Output Layer: Next-item prediction via softmax over item vocabulary
  - Training Loop: Masked sequence prediction with negative sampling

- Critical path:
  1. Sequence construction from interaction history (sorted by timestamp)
  2. Embedding lookup (item + positional, with padding check)
  3. Causal masking in self-attention
  4. Prediction head computes logits over item vocabulary
  5. Loss computation with sampled negatives

- Design tradeoffs:
  - Batching efficiency vs. positional correctness: Current packed batching is efficient but breaks relative positional semantics; proposed fix requires reorganizing by sequence length (may reduce throughput)
  - Item-ID vs. tokenized sequences: Item-IDs are sparse and high-cardinality; tokenization could reduce vocabulary but may lose item-specific signal
  - Explicit user embeddings vs. history-only representation: Adding user embeddings enables personalization but increases parameters and may overfit

- Failure signatures:
  - Positional embedding disorder: Model over-relies on item content and underutilizes sequence order
  - Padding contamination: Non-zero padding embeddings act as bias, shifting predictions systematically
  - Sampling bias: Model learns platform exposure patterns rather than user preferences
  - Scaling collapse: Adding layers doesn't improve performance (personalization deficit from averaging behavior)

- First 3 experiments:
  1. Positional embedding audit: Modify training to batch by sequence length; log positional embedding values applied to each position; compare metrics against baseline with absolute positions.
  2. Padding initialization test: Set padding embeddings to zero explicitly; measure prediction shift on sequences with varying padding ratios.
  3. Autoregressive diagnostic: Generate sequences of 5-10 items autoregressively; analyze whether predictions remain coherent or drift toward popular items (indicating personalization collapse).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does reorganizing training batches to ensure positional embeddings are relative to the prediction point (rather than absolute) improve model accuracy and scalability?
- Basis in paper: [explicit] The author states that the standard implementation applies positional embeddings incorrectly (absolute vs. relative) and proposes reorganizing samples by length to fix this "disorder."
- Why unresolved: The paper identifies the implementation flaw but does not provide experimental results confirming that correcting it enhances performance.
- What evidence would resolve it: Ablation studies comparing the standard masking approach against the proposed length-sorted batching across standard sequential recommendation benchmarks.

### Open Question 2
- Question: Can a "reverse tokenization" process, which decomposes items into basic elements, overcome the scalability limits imposed by sparse and random item-ID sequences?
- Basis in paper: [explicit] The author argues that item-ID sequences are more random than language tokens and suggests breaking down items into combinations of basic elements is necessary to "really scale up."
- Why unresolved: This is proposed as a necessary modification for scaling, but no specific architecture or results for this tokenization method are provided.
- What evidence would resolve it: Experiments comparing the scaling laws of models trained on atomic item-IDs versus those trained on decomposed item features.

### Open Question 3
- Question: Does enforcing consistency between original item embeddings and embeddings reconstructed from sequences of user interactions (duality) improve model robustness?
- Basis in paper: [explicit] The paper proposes using sequences of user embeddings to represent items and enforcing consistency with the original item embedding to mitigate "dimensional collapse."
- Why unresolved: The duality concept is presented as a theoretical approach to improve consistency, but the specific training dynamics or gains remain unverified.
- What evidence would resolve it: Comparative analysis of embedding stability and recommendation metrics in models trained with and without the proposed duality consistency loss.

## Limitations

- No primary experimental results are presented, making the proposed improvements speculative
- Lacks specific evaluation metrics, datasets, and implementation details necessary for reproduction
- Assumes symmetric structure in user-item interaction graphs that may not exist in practice
- Does not quantify the impact of sampling bias on recommendation quality

## Confidence

- Positional embedding correction mechanism: Medium confidence - the theoretical argument is sound, but empirical impact is unknown
- Embedding duality mechanism: Low confidence - relies on strong assumptions about graph structure symmetry with no supporting evidence
- Autoregressive diagnostic utility: Medium confidence - the reasoning is plausible but not specific to recommendation domain

## Next Checks

1. Positional embedding audit experiment: Implement both absolute and relative positional encoding variants, batch by sequence length to eliminate padding, and measure prediction accuracy on standard sequential recommendation datasets (e.g., MovieLens, Amazon reviews). Log positional embedding values applied to each position to verify correct implementation.

2. Duality feasibility study: Construct user sequences for items (users who interacted with each item) and attempt consistency regularization. Measure the sparsity and coverage of these reverse sequences across different item popularity tiers to quantify when the approach breaks down.

3. Autoregressive drift analysis: Generate 10-item sequences autoregressively from a trained SASRec model, compare predicted item distributions to actual user behavior distributions, and quantify personalization collapse by measuring entropy increase in predictions over generation steps.