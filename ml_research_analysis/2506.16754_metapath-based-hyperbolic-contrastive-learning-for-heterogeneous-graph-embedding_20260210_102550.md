---
ver: rpa2
title: Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding
arxiv_id: '2506.16754'
source_url: https://arxiv.org/abs/2506.16754
tags:
- hyperbolic
- metapath
- space
- heterogeneous
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes MHCL, a framework that leverages multiple hyperbolic
  spaces and metapath-based contrastive learning for heterogeneous graph embedding.
  The key idea is to assign distinct hyperbolic spaces to different metapaths, allowing
  each to capture unique power-law structures more effectively than a single hyperbolic
  space.
---

# Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding

## Quick Facts
- arXiv ID: 2506.16754
- Source URL: https://arxiv.org/abs/2506.16754
- Authors: Jongmin Park; Seunghoon Han; Won-Yong Shin; Sungsu Lim
- Reference count: 36
- Key outcome: MHCL outperforms state-of-the-art baselines in node classification, clustering, and link prediction on IMDB, DBLP, ACM, and LastFM datasets using multiple hyperbolic spaces and metapath-based contrastive learning.

## Executive Summary
This paper introduces MHCL, a novel framework for heterogeneous graph embedding that leverages multiple hyperbolic spaces and metapath-based contrastive learning. The key innovation is assigning distinct hyperbolic spaces to different metapaths, allowing each to capture unique power-law structures more effectively than a single hyperbolic space. Additionally, a contrastive learning method is introduced to enhance the discriminability of metapath embeddings by minimizing distances between embeddings of the same metapath while maximizing distances between embeddings of different metapaths.

## Method Summary
MHCL combines multiple hyperbolic spaces with metapath-based contrastive learning for heterogeneous graph embedding. The framework assigns distinct hyperbolic spaces to different metapaths, enabling each metapath to capture unique power-law structures more effectively. A contrastive learning method is introduced to enhance metapath embedding discriminability by minimizing distances between embeddings of the same metapath while maximizing distances between embeddings of different metapaths. Experiments on real-world datasets (IMDB, DBLP, ACM, LastFM) demonstrate superior performance compared to state-of-the-art baselines in node classification, clustering, and link prediction tasks.

## Key Results
- On DBLP dataset: 95.38% Macro-F1 and 95.70% Micro-F1 in node classification
- On DBLP dataset: 84.52% NMI and 88.89% ARI in clustering
- Visualization results show improved separability of metapath embeddings with contrastive learning

## Why This Works (Mechanism)
MHCL works by recognizing that different metapaths in heterogeneous graphs often exhibit distinct power-law structures. By assigning separate hyperbolic spaces to different metapaths, the model can better capture these unique structural properties. The contrastive learning component further enhances performance by explicitly learning to distinguish between metapath embeddings, reducing ambiguity and improving discriminability. This dual approach addresses both the geometric properties of heterogeneous graph structures and the need for more discriminative embeddings.

## Foundational Learning

**Hyperbolic Geometry**
*Why needed:* Power-law structures in real-world graphs are better represented in hyperbolic space than Euclidean space.
*Quick check:* Understand that hyperbolic space has negative curvature, allowing exponential volume growth and better modeling of hierarchical/tree-like structures.

**Metapaths in Heterogeneous Graphs**
*Why needed:* Different metapaths capture different semantic relationships between nodes.
*Quick check:* Recognize that a metapath is a path defined over node types and edge types (e.g., Paper-Author-Paper vs. Paper-Conference-Paper).

**Contrastive Learning**
*Why needed:* To enhance embedding discriminability by learning to distinguish between similar and dissimilar pairs.
*Quick check:* Understand the contrastive loss function that pulls positive pairs together and pushes negative pairs apart.

## Architecture Onboarding

**Component Map**
Input Graph -> Metapath Extraction -> Multiple Hyperbolic Spaces -> Contrastive Learning Module -> Final Metapath Embeddings

**Critical Path**
1. Metapath extraction from heterogeneous graph
2. Assignment of metapaths to distinct hyperbolic spaces
3. Embedding generation in respective hyperbolic spaces
4. Contrastive learning to enhance discriminability
5. Aggregation of metapath embeddings for downstream tasks

**Design Tradeoffs**
The use of multiple hyperbolic spaces increases representational capacity but also computational overhead. The metapath assignment strategy balances between having enough spaces to capture distinct structures while maintaining efficiency.

**Failure Signatures**
Poor performance on datasets with uniform or non-hierarchical structures, where hyperbolic embeddings provide less advantage. Suboptimal metapath assignments could lead to similar metapaths sharing spaces, reducing the effectiveness of contrastive learning.

**3 First Experiments**
1. Ablation study removing the contrastive learning component to measure its contribution
2. Test with different numbers of hyperbolic spaces to find optimal configuration
3. Compare performance using single hyperbolic space versus multiple spaces

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead of managing multiple hyperbolic spaces not thoroughly discussed
- Performance gains' robustness across diverse graph structures and sizes needs further validation
- Scalability for large-scale graphs with many metapaths remains an open question

## Confidence

**Theoretical Motivation for Multiple Hyperbolic Spaces**: High
**Practical Implementation Details**: Medium
**Comparative Performance Claims**: Medium
**Scalability Analysis**: Low

## Next Checks
1. Conduct experiments on additional heterogeneous graph datasets with varying sizes and structural properties to assess generalizability
2. Perform detailed scalability analysis to quantify computational overhead of the multiple hyperbolic space approach
3. Conduct ablation studies to isolate contribution of each component (multiple hyperbolic spaces, contrastive learning, metapath assignments) to overall performance