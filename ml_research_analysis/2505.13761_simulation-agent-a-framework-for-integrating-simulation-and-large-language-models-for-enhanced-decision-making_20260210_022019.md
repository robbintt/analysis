---
ver: rpa2
title: 'Simulation Agent: A Framework for Integrating Simulation and Large Language
  Models for Enhanced Decision-Making'
arxiv_id: '2505.13761'
source_url: https://arxiv.org/abs/2505.13761
tags:
- simulation
- agent
- framework
- users
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a simulation agent framework that integrates
  large language models (LLMs) with simulation models to make complex simulations
  accessible to non-technical users. The framework addresses the usability challenges
  of traditional simulations while avoiding the hallucination issues of standalone
  LLMs by grounding the LLM in accurate simulation models.
---

# Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making

## Quick Facts
- arXiv ID: 2505.13761
- Source URL: https://arxiv.org/abs/2505.13761
- Reference count: 28
- Key outcome: Integration of large language models with simulation models enables non-technical users to configure, run, and interpret complex simulations via natural language, addressing usability challenges while avoiding LLM hallucination through grounding in accurate simulation models.

## Executive Summary
This paper introduces a simulation agent framework that combines large language models with traditional simulation models to make complex simulations accessible to non-technical users. The framework addresses the usability gap in traditional simulation tools while avoiding the hallucination issues common in standalone LLMs by grounding the LLM in accurate simulation models. Through natural language interaction, users can configure simulations, execute runs, and interpret results without requiring deep technical expertise. Initial experiments demonstrate the framework's effectiveness as an AI-powered assistant for forecasting outcomes using simulation models, with potential for broad applicability across diverse domains and simulation types.

## Method Summary
The framework employs a LangChain-based AI agent powered by OpenAI's GPT-4o, integrated with three specialized tools: "run simulation," "modify inputs," and "interpret outputs." The system takes simulation input files (parameters, agent characteristics, scenarios) and output files (high-dimensional time-series CSVs) as data sources. The agent's system prompt contains model documentation and causal relationships to ground its responses in simulation reality. The simulation is exported as a standalone executable callable via API, allowing flexible integration with various simulation types including discrete-event, system dynamics, and agent-based approaches. The approach leverages natural language processing to bridge the gap between technical simulation models and end-user requirements.

## Key Results
- Integration of LLMs with simulation models enables non-technical users to effectively configure and run complex simulations through natural language interaction
- The framework successfully avoids LLM hallucination by grounding responses in accurate simulation models and documented causal relationships
- Initial experiments demonstrate the system's effectiveness as an AI-powered assistant for forecasting outcomes, suggesting broad applicability across diverse simulation domains

## Why This Works (Mechanism)
The framework works by leveraging the LLM's natural language understanding capabilities while constraining its outputs to the boundaries of the simulation model. By providing the LLM with system documentation, causal relationships, and structured tools for interacting with the simulation, the framework ensures that the LLM's responses remain grounded in simulation reality. The three-tool architecture (run, modify, interpret) creates a controlled interaction loop where the LLM can only access and modify simulation data through defined interfaces, preventing arbitrary generation while maintaining conversational flexibility.

## Foundational Learning
- **LangChain framework integration**: Why needed - Provides the agent architecture and tool integration capabilities; Quick check - Verify agent can call multiple tools in sequence
- **LLM grounding techniques**: Why needed - Prevents hallucination by constraining responses to simulation model boundaries; Quick check - Test agent responses against known simulation outputs
- **Natural language simulation configuration**: Why needed - Enables non-technical users to specify complex simulation parameters; Quick check - Validate parameter modifications match user intent
- **Tool-based LLM control**: Why needed - Restricts LLM to defined actions rather than free-form generation; Quick check - Monitor tool call patterns and success rates
- **Simulation model export and API design**: Why needed - Enables flexible integration with various simulation types; Quick check - Test different simulation models through the same agent interface
- **Context window management**: Why needed - Handles large simulation outputs without overwhelming the LLM; Quick check - Verify JSON summaries capture key information without data loss

## Architecture Onboarding

**Component map**: User Input -> LLM Agent -> Tool Router -> (Run Simulation Tool, Modify Inputs Tool, Interpret Outputs Tool) -> Simulation Model/API

**Critical path**: Natural language user query → LLM interpretation → appropriate tool selection → simulation execution or data processing → response generation

**Design tradeoffs**: Flexibility vs. control (natural language interface vs. tool constraints), generality vs. specificity (broad simulation support vs. domain-specific optimization), simplicity vs. capability (three tools vs. more specialized functions)

**Failure signatures**: LLM misconfigures input parameters (wrong file/field/value), context overflow or hallucination when interpreting large outputs, tool execution failures, simulation runtime errors

**First experiments**:
1. Test end-to-end natural language interaction for configuring a simple M/M/1 queue simulation and interpreting results
2. Inject known input errors and verify whether the agent detects and corrects them through tool-based validation
3. Conduct a small user study comparing task completion time and accuracy between non-technical users using the AI agent versus traditional simulation interfaces

## Open Questions the Paper Calls Out
None

## Limitations
- No formal evaluation metrics defined for prediction accuracy, decision support quality, or user efficiency
- Implementation details missing (tool signatures, prompt templates, simulation API design)
- Lack of quantitative user studies or comparative benchmarks against traditional simulation interfaces
- Untested across diverse simulation types despite claims of broad applicability

## Confidence
- Framework architecture is **high-confidence** based on established LangChain and LLM integration principles
- "Any simulation model can be integrated" claim is **high-confidence** in principle but untested across diverse types
- "Broad applicability" assertion is **medium-confidence** without evidence of cross-domain robustness
- Decision-support effectiveness is **low-confidence** due to absence of quantitative user studies

## Next Checks
1. Reproduce the agent using a simple discrete-event simulation (e.g., M/M/1 queue) and test end-to-end natural language interaction for configuration and result interpretation
2. Systematically test tool accuracy by injecting known input errors and verifying whether the agent detects and corrects them
3. Conduct a small user study comparing task completion time and accuracy between non-technical users using the AI agent versus traditional simulation interfaces