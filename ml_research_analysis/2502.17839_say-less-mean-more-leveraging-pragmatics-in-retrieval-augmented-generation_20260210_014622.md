---
ver: rpa2
title: 'Say Less, Mean More: Leveraging Pragmatics in Retrieval-Augmented Generation'
arxiv_id: '2502.17839'
source_url: https://arxiv.org/abs/2502.17839
tags:
- evidence
- question
- retrieval
- query
- step-back
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method to enhance retrieval-augmented generation
  (RAG) by leveraging pragmatic principles, specifically the maxims of relevance,
  quantity, and manner. The method identifies and highlights the most relevant sentences
  in retrieved documents that cover all topics addressed in the question and no more.
---

# Say Less, Mean More: Leveraging Pragmatics in Retrieval-Augmented Generation

## Quick Facts
- arXiv ID: 2502.17839
- Source URL: https://arxiv.org/abs/2502.17839
- Reference count: 20
- The paper proposes a method to enhance retrieval-augmented generation (RAG) by leveraging pragmatic principles, specifically the maxims of relevance, quantity, and manner. The method identifies and highlights the most relevant sentences in retrieved documents that cover all topics addressed in the question and no more. This highlighted evidence is then provided to the LLM within its original context. Experiments on three question-answering tasks (ARC-Challenge, PubHealth, and PopQA) using five different LLMs show that this approach consistently improves performance, with up to 19.7% relative accuracy improvement on PubHealth and 10% on ARC-Challenge compared to a conventional RAG system. The method is particularly effective for tasks involving single-hop or multi-hop logical deduction and analogical reasoning.

## Executive Summary
This paper addresses a critical challenge in retrieval-augmented generation (RAG) systems: the quality of retrieved evidence significantly impacts LLM performance, yet traditional RAG systems often provide excessive or irrelevant context. The authors propose a pragmatic approach that applies Grice's maxims of conversation to filter and highlight only the most relevant sentences from retrieved documents, effectively saying less to mean more. By ensuring retrieved evidence is both comprehensive and concise, the method improves LLM accuracy across multiple question-answering tasks without requiring model fine-tuning or architectural modifications.

The approach demonstrates that strategic evidence selection based on pragmatic principles can outperform simply providing more information to LLMs. The method's effectiveness across five different LLMs and three diverse datasets suggests that pragmatic filtering addresses a fundamental limitation in RAG systems rather than being tied to specific model architectures. The improvements are particularly notable for tasks requiring logical deduction and reasoning, indicating that cleaner evidence enables better inference.

## Method Summary
The authors introduce a pragmatic filtering approach that applies Grice's maxims of relevance, quantity, and manner to select the most informative sentences from retrieved documents. The method identifies topic boundaries in questions, retrieves relevant documents, then applies heuristic rules to select sentences that fully address all question topics without redundancy or extraneous information. This filtered, highlighted evidence is provided to the LLM within its original context. The approach is model-agnostic and requires no fine-tuning, making it compatible with any RAG system. Experiments on ARC-Challenge, PubHealth, and PopQA datasets using five different LLMs demonstrate consistent performance improvements compared to conventional RAG systems.

## Key Results
- Achieved up to 19.7% relative accuracy improvement on PubHealth dataset compared to conventional RAG
- Demonstrated 10% improvement on ARC-Challenge dataset
- Consistently improved performance across five different LLM models including GPT-4 and Claude
- Method is particularly effective for single-hop and multi-hop reasoning tasks

## Why This Works (Mechanism)
The approach works by addressing the fundamental limitation of information overload in RAG systems. When LLMs receive excessive or partially relevant context, they must expend computational resources filtering out noise, which can lead to errors in reasoning and answer generation. By applying pragmatic principles to select only the most relevant and complete information, the method reduces cognitive load on the LLM while ensuring all necessary information is present. This creates cleaner evidence that enables more accurate inference, particularly for tasks requiring logical deduction or analogical reasoning where extraneous information can confuse the reasoning process.

## Foundational Learning
- **Grice's Cooperative Principle**: A framework for effective communication that assumes speakers cooperate to be informative and relevant. Needed to establish the theoretical foundation for pragmatic filtering. Quick check: Verify understanding of the four maxims (quantity, quality, relevance, manner) and how they apply to information retrieval.
- **Pragmatic filtering heuristics**: Rule-based methods for selecting sentences that maximize relevance while minimizing redundancy. Needed to implement the theoretical principles in a computationally tractable way. Quick check: Review the specific heuristic rules used for topic coverage and redundancy elimination.
- **Evidence highlighting techniques**: Methods for marking relevant portions of retrieved documents while preserving original context. Needed to ensure LLMs can easily identify and utilize the filtered information. Quick check: Examine how highlighted evidence is formatted and presented to different LLM architectures.
- **Topic boundary detection**: Techniques for identifying distinct topics within questions to ensure comprehensive coverage. Needed to determine what information must be included in the filtered evidence. Quick check: Review the methods used to segment questions into distinct topics.
- **Information redundancy detection**: Methods for identifying and eliminating repetitive or overlapping information. Needed to satisfy the quantity maxim by avoiding unnecessary information. Quick check: Understand how the system detects when multiple sentences provide the same information.

## Architecture Onboarding

Component map: Question -> Topic Segmentation -> Document Retrieval -> Pragmatic Filtering -> Evidence Highlighting -> LLM Input

Critical path: The critical path runs from question analysis through pragmatic filtering to LLM input. Topic segmentation must complete before filtering can begin, and filtering must complete before highlighting. The most time-sensitive component is document retrieval, as it must return results quickly enough to maintain interactive response times.

Design tradeoffs: The approach trades computational overhead in the filtering stage for improved LLM performance, avoiding the need for fine-tuning or architectural modifications. This represents a shift from "more information is better" to "cleaner information is better." The heuristic-based filtering is simpler to implement than learned approaches but may not generalize as well across diverse domains.

Failure signatures: The system may fail when questions contain ambiguous topics that are difficult to segment, when retrieved documents lack clear topical boundaries, or when heuristic rules incorrectly eliminate relevant information. Performance degradation may also occur on highly complex reasoning tasks where the initial filtering misses subtle but important connections between topics.

First experiments: (1) Run the pragmatic filtering pipeline on a simple single-hop question to verify basic functionality, (2) Compare filtered vs. unfiltered evidence on a multi-hop reasoning task to observe performance differences, (3) Test the method with different LLM models on the same question to verify model-agnostic improvements.

## Open Questions the Paper Calls Out
None

## Limitations
- The heuristic-based approach may not generalize well across diverse domains or question types
- Performance improvements may not translate to other knowledge-intensive tasks beyond the tested question-answering focus
- The method's effectiveness appears tied to structured datasets with clear topic boundaries, potentially limiting utility for open-domain or highly nuanced queries

## Confidence
- Core experimental results: Medium - Consistent improvements across multiple models and datasets, but limited scope of evaluated tasks
- Generalization claims: Medium - Improvements demonstrated on three datasets but no cross-domain validation
- Methodological soundness: Medium - Sound theoretical foundation but relies on heuristic rules without comparison to learned alternatives

## Next Checks
- Test the method on diverse, multi-domain datasets including scientific literature and legal documents to assess robustness beyond the current question-answering focus
- Compare pragmatic filtering against learned evidence selection approaches (e.g., attention-based methods) to determine whether the heuristic rules provide optimal performance
- Evaluate the approach's behavior on questions requiring deep contextual understanding or those involving ambiguous terminology to identify potential failure modes in more complex reasoning scenarios