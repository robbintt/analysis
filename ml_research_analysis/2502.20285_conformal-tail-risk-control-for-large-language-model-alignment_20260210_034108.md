---
ver: rpa2
title: Conformal Tail Risk Control for Large Language Model Alignment
arxiv_id: '2502.20285'
source_url: https://arxiv.org/abs/2502.20285
tags:
- risk
- human
- control
- machine
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of aligning large language models
  (LLMs) with human judgments by controlling distortion risk measures of their outputs.
  The authors develop a lightweight calibration framework that ensures alignment with
  provable guarantees, focusing on tail risk control rather than average-case performance.
---

# Conformal Tail Risk Control for Large Language Model Alignment

## Quick Facts
- arXiv ID: 2502.20285
- Source URL: https://arxiv.org/abs/2502.20285
- Reference count: 40
- Primary result: Lightweight calibration framework that controls distortion risk measures of LLM outputs with provable guarantees, achieving target risk levels while being less conservative than alternative approaches.

## Executive Summary
This paper addresses the challenge of aligning large language models with human judgments by controlling the tail risk of their outputs rather than just average-case performance. The authors develop a conformal distortion risk control framework that provides finite-sample guarantees for any distortion risk measure (like CVaR or VaR) by leveraging L-statistics. The method generates multiple responses per prompt, scores them with a machine model, and selects responses while controlling the distortion risk measure of human-rated disutility. The approach is demonstrated on toxicity control using Detoxify, showing superior performance to DKW and Berk-Jones baselines while maintaining provable guarantees.

## Method Summary
The core method involves generating multiple candidate responses per prompt and selecting one based on machine-generated disutility scores while controlling the distortion risk measure of human-rated disutility. The framework uses L-statistics to estimate distortion risk measures as linear combinations of order statistics, enabling asymptotically valid confidence bounds. A threshold is selected by inverting these confidence bounds, providing risk control guarantees. The method requires only a small calibration set with human annotations and works without distributional assumptions about the LLM or machine scoring model. The approach is demonstrated by controlling toxicity in LLM outputs, achieving target risk levels while being less conservative than alternative methods.

## Key Results
- CDRC-L achieves target risk levels across different settings of distortion risk measure parameter β and varying degrees of misalignment between human and machine ratings
- The method maintains advantage over DKW and Berk-Jones baselines in deployment cost while achieving the same risk control guarantees
- Risk control is demonstrated on held-out prompts with human annotations, validating the 95% confidence coverage claim
- Performance is evaluated across multiple target risk levels (α ∈ {0.15, 0.2, 0.25, 0.3, 0.35}) and distortion measures (VaR and CVaR with β ∈ {0.5, 0.75, 0.9})

## Why This Works (Mechanism)

### Mechanism 1: L-Statistics Enable Asymptotically Valid Risk Bounds
Distortion risk measures can be estimated with asymptotically valid confidence bounds using L-statistics, enabling risk control without distributional assumptions. The estimator is a linear combination of order statistics with asymptotically normal distribution under boundedness and continuity assumptions.

### Mechanism 2: Monotonic Threshold Inversion Converts Bounds to Control
A threshold selected by inverting pointwise upper confidence bounds provides asymptotic risk control at level α with confidence 1-δ. The monotonicity of the risk function ensures that crossing the true risk α implies the UCB also crossed.

### Mechanism 3: Candidate Set Filtering Preserves Information While Enabling Selection
Generating diverse, high-quality candidate responses and filtering by machine score threshold enables risk-controlled response selection without model retraining. The worst-case assignment ensures any selection from the filtered set inherits the guarantee.

## Foundational Learning

- **Concept: Distortion Risk Measures (VaR, CVaR)**
  - Why needed here: The paper targets tail risk (rare toxic outputs), which expected loss fails to capture. CVaRβ averages the worst