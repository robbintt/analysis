---
ver: rpa2
title: 'On the Evolution of Federated Post-Training Large Language Models: A Model
  Accessibility View'
arxiv_id: '2508.16261'
source_url: https://arxiv.org/abs/2508.16261
tags:
- federated
- tuning
- llms
- learning
- fedllm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides a comprehensive survey on federated post-training
  of large language models (FedLLM), addressing the challenges of computational efficiency
  and privacy preservation in decentralized settings. The authors propose a novel
  taxonomy categorizing FedLLM approaches along two axes: model access-based (white-box,
  gray-box, black-box) and parameter efficiency-based optimization.'
---

# On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View

## Quick Facts
- arXiv ID: 2508.16261
- Source URL: https://arxiv.org/abs/2508.16261
- Reference count: 15
- This paper provides the first comprehensive survey on federated post-training of large language models, proposing a novel taxonomy based on model accessibility and parameter efficiency.

## Executive Summary
This survey comprehensively explores federated post-training of large language models (FedLLM), addressing the critical challenges of computational efficiency and privacy preservation in decentralized settings. The authors propose a novel taxonomy categorizing FedLLM approaches along two axes: model access-based (white-box, gray-box, black-box) and parameter efficiency-based optimization. They trace the evolution from full-model fine-tuning to parameter-efficient methods like LoRA and prompt tuning, and examine emerging black-box techniques that treat LLMs as inference APIs using gradient-free optimization. The survey identifies key challenges in federated value alignment (DPO, RLHF, RLAIF) and emphasizes the need for enhanced privacy and security mechanisms in black-box settings.

## Method Summary
The survey synthesizes 15 research papers to establish a taxonomy of FedLLM approaches based on two dimensions: model access (white-box, gray-box, black-box) and parameter efficiency (full fine-tuning, LoRA, prompt tuning). The authors analyze three main categories: (1) White-box FedAvg with full model updates, (2) Gray-box parameter-efficient methods including FedLoRA (adapter-based) and FedPrompt (prompt tuning), and (3) Black-box gradient-free optimization using Zeroth-Order Optimization and CMA-ES. The methodology involves systematic literature review, conceptual analysis of optimization techniques, and identification of open challenges in privacy, security, and value alignment within federated settings.

## Key Results
- FedLLM methods can be systematically categorized along model accessibility (white/gray/black-box) and parameter efficiency dimensions
- Parameter-efficient methods like LoRA and prompt tuning achieve comparable performance to full fine-tuning while reducing communication costs
- Black-box approaches using ZOO enable federated tuning when only inference API access is available, though at higher query costs
- Off-site tuning with compressed emulators enables model ownership protection while maintaining parameter efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Parameter-efficient methods (LoRA, prompt tuning) enable federated LLM fine-tuning with reduced communication and computation while preserving model utility
- LoRA factorizes weight update matrices into lower-rank representations, reducing transmitted parameters. Prompt tuning freezes model weights entirely, optimizing only prepended token embeddings that steer model behavior without modifying architecture
- Core assumption: The knowledge required for downstream tasks need not reside entirely within model parameters but can be stored in adapters or input-level representations
- Evidence anchors:
  - [abstract]: "highlighting the evolution from full-model fine-tuning to parameter-efficient methods like LoRA and prompt tuning"
  - [section 1]: "LoRA reduces the dimensionality of weight update matrices... achieving a lower-dimensional representation without the need for additional adapters"
  - [section 3]: "these techniques usually achieve effects comparable to (not significantly less than) conventional full model fine-tuning"
  - [corpus]: Related work on quantization (arXiv:2505.08620) confirms parameter efficiency is an active research direction

### Mechanism 2
- Zeroth-order optimization (ZOO) enables federated tuning when only inference API access is available, eliminating gradient dependency
- Methods like FedMeZO and BBT use finite-difference approximations and derivative-free search strategies (e.g., CMA-ES) to estimate gradient direction from input-output pairs alone. Random subspace projection reduces search dimensionality for prompt optimization
- Core assumption: The optimization landscape is sufficiently smooth that local perturbations of inputs provide meaningful signal for parameter updates, and API query costs are tolerable
- Evidence anchors:
  - [abstract]: "emerging black-box techniques that treat LLMs as inference APIs using gradient-free optimization"
  - [section 5]: "BBT projects the prompt space onto a smaller subspace using random linear projection, solving the optimization with derivative-free methods"
  - [section 5]: "FedMeZO incorporating a memory-efficient Zeroth-Order Optimization method... analyzes the convergence to examine the theoretical underpinnings"
  - [corpus]: FedOne (arXiv:2506.14929) directly addresses query efficiency in black-box discrete prompt learning

### Mechanism 3
- Off-site tuning with compressed emulators enables federated learning while preserving server model ownership and reducing client-side computation
- The server compresses the frozen LLM into a lightweight emulator using layer-drop techniques, sends only this proxy plus trainable adapters to clients. Clients fine-tune adapters locally; only adapter updates return to server. Bi-level optimization aligns emulator behavior with original model using public datasets
- Core assumption: Compressed emulators preserve sufficient task-relevant information for adapter training, and public datasets adequately bridge distribution gaps between server and client data
- Evidence anchors:
  - [section 4.1]: "offsite-tuning divides θ into... a lightweight and trainable adapter (A)... and the remaining frozen model (ε), compressed into an emulator"
  - [section 4.1]: "FedBiOT formulates a bi-level optimization to minimize the negative effect of data discrepancy"
  - [section 4.1, eq. 2-3]: Mathematical formulation shows server optimizes emulator alignment while clients optimize adapters
  - [corpus]: No direct corpus papers validate emulator-based approaches

## Foundational Learning

- Concept: **Federated Averaging (FedAvg)**
  - Why needed here: The foundational algorithm for all FedLLM approaches; defines the round-based communication protocol where clients receive global parameters, train locally, and return updates for aggregation
  - Quick check question: Can you explain how FedAvg handles heterogeneous local data distributions (non-IID data) and why weighted averaging might outperform simple averaging?

- Concept: **Low-Rank Adaptation (LoRA)**
  - Why needed here: The dominant parameter-efficient technique referenced throughout gray-box FedLLM methods; understanding matrix factorization is essential for grasping communication savings
  - Quick check question: Given a weight matrix W of dimension d×k, how many trainable parameters does LoRA introduce with rank r, and how does this scale with transformer layer count?

- Concept: **Zeroth-Order Optimization**
  - Why needed here: Critical for understanding black-box FedLLM methods that operate without gradient access; requires familiarity with finite-difference approximation and evolutionary strategies
  - Quick check question: If you can only query a model's outputs for given inputs, how would you estimate the gradient direction for a scalar loss function using two-point differences?

## Architecture Onboarding

- Component map:
  - Server -> Clients -> Communication layer -> Aggregation module
  - Server holds full LLM (white/gray-box) or provides inference API (black-box); clients hold local private datasets; communication transmits parameters, adapters/prompts, or queries/responses; aggregation implements FedAvg or variants

- Critical path:
  1. Determine model access level (white/gray/black-box) based on deployment constraints
  2. Select parameter efficiency method (full fine-tuning, LoRA, prompt tuning, ZOO)
  3. Configure communication protocol (parameter transmission vs. API queries)
  4. Implement privacy mechanisms (differential privacy, secure aggregation if required)

- Design tradeoffs:
  - Communication vs. accuracy: Full model updates preserve performance but incur massive overhead; prompt tuning minimizes transmission but may underperform on complex tasks
  - Model access vs. flexibility: White-box enables all optimization methods; black-box restricts to gradient-free approaches with higher query costs
  - Emulator compression vs. adapter quality: Aggressive compression reduces client compute but risks misalignment between emulator and original model behavior

- Failure signatures:
  - Convergence stalls with high variance across client updates → indicates non-IID data heterogeneity exceeding aggregation method capacity
  - Black-box query costs explode without loss improvement → suggests ZOO hyperparameters (perturbation scale, subspace dimension) need tuning
  - Emulator-trained adapters fail on original model → distribution shift between public calibration data and client data

- First 3 experiments:
  1. Implement FedSFT (full model), FedLoRA, and FedPrompt on identical non-IID data split; measure accuracy vs. communication cost to validate efficiency claims from Section 4
  2. Deploy FedBPT or FedMeZO with varying API query limits per round; plot convergence curves to identify practical query thresholds for your target task complexity
  3. Test layer-drop rates from 10-50% compression for gray-box off-site tuning; evaluate adapter performance gap between emulator and original model to calibrate compression vs. utility tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the pre-trained model in FedLLM effectively generate preferences to reward its fine-tuned version, creating a self-contained system without relying on auxiliary external LLMs?
- **Basis in paper:** [explicit] The authors explicitly ask, "can the pre-trained model in FedLLM effectively generate preferences to reward its fine-tuned version and create a self-contained FL system?" in Section 6
- **Why unresolved:** Current RLAIF relies on distinct, off-the-shelf LLMs for annotation. In FedLLM, relying on external auxiliary models complicates the system architecture and may negate efficiency or privacy benefits
- **What evidence would resolve it:** Empirical studies demonstrating that a model can provide high-quality AI feedback for its own federated fine-tuning loop, achieving performance comparable to systems using separate teacher models

### Open Question 2
- **Question:** How can the inherent instability and convergence difficulties of Federated RLHF (FedRLHF) be mitigated under statistical heterogeneity?
- **Basis in paper:** [explicit] Section 6 notes that FedRLHF "tends to be more unstable and may struggle to converge, especially when facing the inherent statistical heterogeneity in FL systems"
- **Why unresolved:** The two-stage process of RLHF (reward model training plus policy optimization) is tedious and unstable in federated settings, making standard implementations impractical
- **What evidence would resolve it:** The development of adapted optimization algorithms (e.g., proximal policy optimization variants) that prove stable and converge efficiently when data is non-IID across clients

### Open Question 3
- **Question:** What comprehensive mechanisms can secure privacy and verify computational integrity in inference-only, black-box FedLLM environments?
- **Basis in paper:** [explicit] The authors state that "detecting and attributing issues such as trojans or poisoning becomes significantly harder" and call for "comprehensive mechanisms" in Section 6
- **Why unresolved:** While treating LLMs as APIs solves accessibility issues, it introduces risks where users must query APIs with private inputs, and the lack of internal access makes auditing for malicious computation (like trojans) extremely difficult
- **What evidence would resolve it:** New protocols for secure inference and zero-knowledge proofs or equivalent verification methods that function without access to model weights or gradients

## Limitations
- The survey lacks unified experimental validation across the proposed taxonomy, relying on literature aggregation rather than systematic benchmarking
- Critical hyperparameters (learning rates, LoRA ranks, query budgets) for the 15 referenced methods are not standardized, making cross-method comparisons difficult
- Black-box ZOO approaches assume smooth loss landscapes without addressing potential local minima issues in high-dimensional prompt spaces
- Emulator compression methods (off-site tuning) lack external validation papers in the corpus, representing a research gap

## Confidence
- High confidence: White-box and gray-box FedLLM mechanisms (FedAvg, LoRA, prompt tuning) are well-established with strong empirical support
- Medium confidence: Black-box ZOO approaches show theoretical promise but practical scalability remains unproven
- Medium confidence: Off-site tuning with emulators is conceptually sound but lacks comprehensive validation across diverse client-server data distributions

## Next Checks
1. Implement systematic benchmark comparing FedSFT, FedLoRA, and FedPrompt on identical non-IID datasets to quantify communication vs. accuracy tradeoffs
2. Conduct black-box query efficiency analysis varying API budget limits to identify practical convergence thresholds for real-world deployment
3. Evaluate emulator compression rates (10-50% layer-drop) against original model performance to calibrate off-site tuning utility in heterogeneous client environments