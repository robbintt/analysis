---
ver: rpa2
title: Sparse minimum Redundancy Maximum Relevance for feature selection
arxiv_id: '2508.18901'
source_url: https://arxiv.org/abs/2508.18901
tags:
- features
- feature
- screening
- knockoff
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SmRMR, a feature selection method that integrates
  both feature-feature and feature-target relationships. It extends the classic mRMR
  algorithm by incorporating a non-convex penalty, enabling accurate identification
  of inactive features.
---

# Sparse minimum Redundancy Maximum Relevance for feature selection

## Quick Facts
- arXiv ID: 2508.18901
- Source URL: https://arxiv.org/abs/2508.18901
- Reference count: 40
- Primary result: SmRMR integrates feature-feature redundancy with feature-target relevance using non-convex penalties, enabling FDR control and accurate identification of inactive features while selecting fewer features than HSIC-LASSO

## Executive Summary
This paper introduces SmRMR, a feature selection method that extends the classic mRMR algorithm by incorporating non-convex penalties (SCAD, MCP) and a knockoff filter for FDR control. The method reformulates mRMR as a continuous penalized M-estimation problem, allowing it to identify zero coefficients exactly and handle ultra-high-dimensional settings through a two-stage screening and selection pipeline. Empirical results show SmRMR performs comparably to HSIC-LASSO in terms of accuracy while being more conservative in feature selection, requiring only an FDR threshold rather than a predetermined number of features.

## Method Summary
SmRMR operates through a two-stage pipeline: first, it screens features using penalized mRMR with Projection Correlation or HSIC measures, reducing the feature space to a manageable size where knockoffs can be constructed; second, it applies a knockoff filter to the screened features to control FDR at the specified level. The method uses data splitting (n0 for screening, n1 for knockoff) to handle p ≫ n settings, and solves the non-convex penalized problem using Local Linear Approximation. The approach requires only an FDR threshold α as input, automatically determining the number of features to select while maintaining statistical guarantees under specific conditions.

## Key Results
- SmRMR achieves comparable accuracy to HSIC-LASSO but selects significantly fewer features, demonstrating its conservative nature
- The method successfully controls FDR below the specified threshold α=0.3 in synthetic experiments across multiple data generating processes
- Empirical results show SmRMR is more conservative than HSIC-LASSO, often returning empty sets when signal strength is weak or α is low
- PC association measure outperforms HSIC in non-linear settings (e.g., Poisson response with TPR=0.58 vs 0.20)

## Why This Works (Mechanism)

### Mechanism 1
Integrating feature-feature redundancy into the objective function filters out correlated features more effectively than ranking features solely by target relevance. The method reformulates the discrete mRMR algorithm into a continuous penalized M-estimation problem. It minimizes a loss function $L_{v,n}(\theta)$ that subtracts relevance ($\theta_k \hat{D}_v(X_k, Y)$) and adds a redundancy penalty ($\theta_k \theta_l \hat{D}_v(X_k, X_l)$). If features $k$ and $l$ are highly dependent, $\hat{D}_v(X_k, X_l)$ is large, forcing one of the coefficients ($\theta$) toward zero to minimize the loss.

### Mechanism 2
Non-convex penalties (SCAD, MCP) allow the exact recovery of zero coefficients (identifying inactive features) without suffering the estimation bias inherent in the LASSO. Unlike the LASSO (which shrinks large coefficients), SCAD and MCP approach a constant penalty for large coefficients. Theoretically, if the minimum true signal is sufficiently large relative to the regularization parameter ($\lambda_n$), the estimator satisfies "sparsistency"—zero coefficients are estimated exactly as zero.

### Mechanism 3
Data splitting coupled with a knockoff filter controls the False Discovery Rate (FDR) even when the initial feature space is larger than the sample size ($p \gg n$). Since knockoffs require $n > 2p$, the method first splits data ($n_0, n_1$). It uses $n_0$ to screen features down to a set $\hat{S}_0$ such that $2|\hat{S}_0| < n_1$. It then generates knockoffs on $n_1$ and calculates importance scores $W_k$. Features are selected only if $W_k$ exceeds a data-dependent threshold $T(\alpha)$.

## Foundational Learning

### Concept: mRMR (Minimum Redundancy Maximum Relevance)
Why needed: This is the base heuristic being "sparsified." You must understand that standard mRMR is a discrete selection algorithm (forward selection) which is computationally hard, whereas this paper proposes a continuous relaxation.
Quick check: How does the continuous relaxation in Equation (2.3) change the optimization landscape compared to standard mutual information-based filtering?

### Concept: Knockoff Filter
Why needed: This is the statistical engine for FDR control. The paper assumes you know that knockoffs are "fake" variables designed to mimic the correlation structure of real variables but are independent of the response.
Quick check: Why does the method require data splitting ($n_0, n_1$) before constructing knockoffs in an ultra-high-dimensional setting ($p \gg n$)?

### Concept: Non-convex Regularization (SCAD/MCP)
Why needed: The paper claims superiority over LASSO for specific theoretical properties (sparsistency).
Quick check: In Figure 4 results, why might MCP perform better than the L1 penalty on categorical or non-linear data generating processes?

## Architecture Onboarding

### Component map:
Input Data -> Splitter (n0, n1) -> Pre-screener (Marginal utility) -> SmRMR Solver (penalized mRMR) -> Knockoff Generator -> Selector (W_k statistics + threshold)

### Critical path:
The Screening Step. If the pre-screener ($n_0$) fails to capture the active features in $\hat{S}_0$, the subsequent knockoff filter operates on a corrupted set, violating the assumptions of Theorem 4.1. Furthermore, you must ensure $n_1 > 2|\hat{S}_0|$ or the knockoff construction fails mathematically.

### Design tradeoffs:
- **HSIC vs. PC Association**: HSIC requires kernel selection (e.g., Gaussian width); PC is kernel-free but computationally distinct (Equation 2.5 vs 2.7)
- **SmRMR vs. SmRMR2**: SmRMR2 (modifying $\alpha$ loop) ensures features are returned but breaks FDR guarantees (Page 19)
- **Penalty Choice**: SCAD/MCP requires iterative LLA solving (Algorithm 1), which is slower than single-pass LASSO but offers better theoretical support recovery

### Failure signatures:
- **Empty Set Return**: The method is conservative; high $\alpha$ or weak signal often returns $\emptyset$. The code handles this via the "SmRMR2" fallback, but this indicates low statistical power
- **LLA Non-convergence**: If learning rates or initialization (usually LASSO) are poor, the non-convex solver may stall

### First 3 experiments:
1. **Sanity Check (Linear DGP 1.a)**: Run SmRMR on linear data with $n=100, p=100$. Verify FDR $\le \alpha$ and compare selected feature count against HSIC-LASSO to confirm the "conservative" nature
2. **Stress Test (Non-linear DGP 2.c)**: Use Poisson-distributed targets. Test PC association measure vs. HSIC to see which captures the dependency better in a non-linear setting (Figure 4)
3. **Empty Set Diagnosis**: Set $\alpha=0.1$ on a difficult dataset (e.g., DGP 2.b with small $n$) to observe if the algorithm returns an empty set, triggering the SmRMR2 modification

## Open Questions the Paper Calls Out

### Open Question 1
Can support recovery guarantees be established for SmRMR with non-convex penalties (SCAD, MCP) in the high-dimensional setting where p diverges with n?
Basis: The authors state that support recovery "holds in our framework when p_n is fixed, but it is not necessarily satisfied in the large-dimensional case" and that "an alternative estimation framework would be required" for non-convex penalties.
Why unresolved: The current sparsistency result only guarantees zero coefficient recovery asymptotically, but not that the estimated support exactly equals the true support with high probability in diverging dimensions.
What evidence would resolve it: A theoretical proof establishing conditions under which P(Ŝ_n = S_n) → 1 as n → ∞, or a counterexample demonstrating where support recovery fails despite sparsistency.

### Open Question 2
Would incorporating adaptive LASSO weights into the SmRMR framework improve support recovery while maintaining computational tractability?
Basis: The authors note that "One way to fix this issue would be the adaptive LASSO" for the LASSO penalty's inability to simultaneously satisfy consistency and signal recovery conditions, but they "prefer to avoid an additional layer of complexity."
Why unresolved: Adaptive LASSO requires two-stage estimation with stochastic weights, potentially conflicting with the multi-stage knockoff procedure already employed.
What evidence would resolve it: Empirical comparison of SmRMR with adaptive LASSO versus existing penalties on benchmark datasets, measuring support recovery accuracy and FDR control.

### Open Question 3
Can theoretical guidance be provided for optimally selecting between Projection Correlation and HSIC association measures based on data characteristics?
Basis: The experiments show PC outperforms HSIC for non-linear DGPs (e.g., 2.c: TPR=0.58 vs 0.20), while no clear trend exists for other settings, yet no principled selection criterion is offered.
Why unresolved: Both measures are theoretically justified and the choice appears data-dependent, but the paper provides no decision framework linking data properties to optimal measure selection.
What evidence would resolve it: A theoretical or empirical study characterizing conditions (e.g., noise structure, dimensionality, nonlinearity type) under which each measure dominates.

### Open Question 4
How can the SmRMR2 heuristic (incrementing α when empty sets occur) be modified to maintain FDR control guarantees while avoiding overly conservative behavior?
Basis: The authors acknowledge "the FDR is not controlled in every situation for SmRMR2, the modified method to prevent the empty set return" and that this modification "upper biases and naturally leads to an increase in the FDR."
Why unresolved: The current heuristic ad hocly relaxes FDR control to ensure feature selection, breaking the theoretical guarantees that motivate the method.
What evidence would resolve it: A modified threshold selection procedure with provable FDR bounds, or empirical demonstration of alternative strategies (e.g., power-aware α selection) that maintain control.

## Limitations

- Theoretical guarantees (sparsistency, FDR control) depend on strict conditions that may not hold in real-world noisy settings
- Empirical comparison to HSIC-LASSO shows similar accuracy but fewer selected features, limiting practical utility when moderate FDR is acceptable
- Non-convex optimization (SCAD/MCP) requires careful tuning and may be sensitive to initialization, though LLA is used

## Confidence

- **High confidence**: The two-stage screening+knockoff framework is valid for FDR control when conditions are met; the conservative feature selection behavior is observed empirically
- **Medium confidence**: The specific theoretical claims (e.g., exact zero recovery with SCAD/MCP) hold under stated assumptions, but real-world violations are unclear
- **Low confidence**: Relative performance vs. HSIC-LASSO in complex, non-linear settings beyond the reported experiments

## Next Checks

1. **Reproduce Figure 4**: Run SmRMR on DGP 2.c (Poisson response) with both PC and HSIC measures to verify FDR control and feature selection differences
2. **Screening Sensitivity**: Systematically vary the marginal screening threshold and observe the impact on final FDR and feature count to stress-test the n0 → n1 pipeline
3. **Solver Stability**: Test LLA convergence across multiple random seeds and initializations (e.g., LASSO vs. random) for SCAD/MCP to quantify optimization robustness