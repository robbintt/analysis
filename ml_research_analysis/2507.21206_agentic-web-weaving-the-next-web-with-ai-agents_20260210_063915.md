---
ver: rpa2
title: 'Agentic Web: Weaving the Next Web with AI Agents'
arxiv_id: '2507.21206'
source_url: https://arxiv.org/abs/2507.21206
tags:
- agents
- agentic
- agent
- arxiv
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a conceptual framework for the emerging Agentic\
  \ Web, where autonomous AI agents powered by large language models interact directly\
  \ with each other to plan, coordinate, and execute complex tasks on behalf of users.\
  \ The framework introduces three key dimensions\u2014intelligence, interaction,\
  \ and economics\u2014that collectively enable the core capabilities of AI agents."
---

# Agentic Web: Weaving the Next Web with AI Agents

## Quick Facts
- arXiv ID: 2507.21206
- Source URL: https://arxiv.org/abs/2507.21206
- Reference count: 40
- Primary result: Proposes a conceptual framework for the Agentic Web where autonomous AI agents use semantic protocols to plan, coordinate, and execute complex tasks, shifting from human-driven information retrieval to agent-driven orchestration.

## Executive Summary
This paper presents a conceptual framework for the emerging Agentic Web, where autonomous AI agents powered by large language models interact directly with each other to plan, coordinate, and execute complex tasks on behalf of users. The framework introduces three key dimensions—intelligence, interaction, and economics—that collectively enable the core capabilities of AI agents. It traces the historical evolution from the PC Web era, characterized by static pages and keyword search, through the Mobile Web era of recommendation systems and attention economy, to the Agentic Web era defined by agent-based paradigms. The paper highlights transformative shifts in web architecture, moving from user-driven information retrieval to agent-driven orchestration, and from static content delivery to dynamic agent-mediated task execution. It proposes that the web will evolve into a machine-native ecosystem where agents both generate and consume content, enabling continuous, intelligent workflows. Key technical directions include the development of agent-native communication protocols like MCP and A2A, addressing systemic challenges such as agent discovery, semantic interoperability, and billing models. The paper concludes by outlining research challenges and the potential for autonomous digital economies, emphasizing the need for open, secure, and scalable ecosystems shaped by both human intent and autonomous agent behavior.

## Method Summary
The paper constructs a conceptual Client-Agent-Server system to autonomously execute complex web tasks, such as the "Travel Itinerary Planning" example. It relies on a base LLM and implements the MCP Client/Server interface to wrap backend APIs (e.g., Weather, Maps). The workflow involves a Request Parser extracting intent, a Tool Orchestrator invoking services via MCP, and a Result Synthesizer aggregating output. The Agentic Web Roadmap architecture comprises a User Client, Intelligent Agent (Request Parser, Tool Orchestrator, Result Synthesizer), and Backend Services, utilizing MCP for agent-to-tool communication and A2A for inter-agent coordination.

## Key Results
- Introduces the Agentic Web framework with three key dimensions: intelligence, interaction, and economics
- Proposes agent-native protocols (MCP, A2A) to replace human-centric web protocols for semantic interoperability
- Highlights the shift from user-driven information retrieval to agent-driven orchestration and task execution

## Why This Works (Mechanism)

### Mechanism 1: Semantic Protocol Interoperability
- **Claim:** The Agentic Web functions by replacing human-centric, syntactic web protocols (HTTP/RPC) with agent-native, semantic communication protocols.
- **Mechanism:** Protocols like the Model Context Protocol (MCP) and Agent-to-Agent (A2A) allow agents to dynamically discover capabilities and maintain task context across multi-step workflows. Unlike static APIs, these protocols support "capability declaration" and "semantic context preservation," enabling agents to understand *what* a tool does and *how* to use it without human intervention.
- **Core assumption:** Agents possess sufficient reasoning capabilities to parse semantic metadata and construct valid execution plans based solely on protocol definitions.
- **Evidence anchors:**
  - [abstract] Mentions "agent-native communication protocols like MCP and A2A" as key technical directions.
  - [section 5.3.1] Argues that traditional HTTP/RPC lacks "semantic-level support" and "logical semantics," necessitating MCP/A2A for context-aware interactions.
  - [corpus] The neighbor paper "From Semantic Web and MAS to Agentic AI" supports the narrative of transitioning from static documents to semantic agent environments.
- **Break condition:** If semantic definitions are ambiguous or hallucinations cause agents to misinterpret tool constraints, the orchestration fails.

### Mechanism 2: Intent-to-Planning Translation
- **Claim:** The web shifts from information retrieval to task execution via LLM-based planning architectures that decompose high-level user intent into executable action sequences.
- **Mechanism:** The "Intelligence Dimension" (Sec 3.3.1) converts a user's natural language goal (e.g., "book a flight") into a structured plan. This involves "Long-Horizon Planning" and "Contextual Understanding" to select tools, execute actions, and refine plans based on feedback (re-planning).
- **Core assumption:** The underlying LLM has a reliable world model and sufficient context window to maintain state across long, multi-step interactions without catastrophic forgetting.
- **Evidence anchors:**
  - [abstract] Defines the Agentic Web as enabling "agents... to plan, coordinate, and execute complex tasks."
  - [section 4.2] Describes the transition from static recommendation to "proactive process involving multi-step planning."
  - [corpus] "Agentic Reasoning for Large Language Models" explicitly links reasoning capabilities to this shift.
- **Break condition:** Failure occurs if the agent cannot resolve ambiguity in user intent or if the environment changes faster than the agent can re-plan.

### Mechanism 3: The Agent Attention Economy
- **Claim:** Value creation shifts from capturing human attention (clicks/eyeballs) to capturing "Agent Attention" (selection and invocation).
- **Mechanism:** In this new economic layer (Sec 2.3.2), services compete to be selected by agents during task execution. Agents optimize for task completion metrics (cost, reliability, success rate) rather than engagement. This forces service providers to expose machine-readable "Agent Cards" or metadata to be discoverable by the agent's router/orchestrator.
- **Core assumption:** Agents have a reliable "Demand-Skill Vector Mapper" (Sec 5.2.2) to accurately evaluate and rank competing services based on user constraints.
- **Evidence anchors:**
  - [abstract] Highlights "emerging paradigms such as the Agent Attention Economy."
  - [section 2.3.2] Details how services must compete for agent invocation, similar to early SEO but for utility.
- **Break condition:** If economic incentives encourage "adversarial" metadata optimization (lying about capabilities to get invoked), trust in the ecosystem degrades.

## Foundational Learning

- **Concept: Model Context Protocol (MCP)**
  - **Why needed here:** The paper positions MCP as the foundational "HTTP for Agents," bridging the gap between LLM reasoning and external tool execution.
  - **Quick check question:** Can you explain the difference between an API call made by a human developer versus a tool invocation negotiated via MCP by an autonomous agent?

- **Concept: Long-Horizon Planning**
  - **Why needed here:** The paper distinguishes "Agentic Web" from "Mobile Web" by the ability to sustain complex, multi-step goals over time, rather than single-turn interactions.
  - **Quick check question:** How does an agent handle a "break" in a plan (e.g., a booked flight is cancelled) without restarting the entire user interaction?

- **Concept: Semantic Interoperability**
  - **Why needed here:** Section 5.3 argues that current web protocols are insufficient because they lack semantic meaning. Understanding how agents share "meaning" (not just data) is critical for the proposed architecture.
  - **Quick check question:** Why is "syntactic" compatibility (e.g., valid JSON) insufficient for an agent to autonomously use a new API it has never seen before?

## Architecture Onboarding

- **Component map:**
  - User Client -> Intelligent Agent (Request Parser, Tool Orchestrator, Result Synthesizer) -> Backend Services (via MCP/A2A)

- **Critical path:**
  1. **Input:** User delegates high-level intent.
  2. **Discovery:** Agent queries registry (via A2A/MCP) to find capabilities.
  3. **Orchestration:** Agent decomposes task and maps skills to services (Demand-Skill Vector Mapping).
  4. **Execution:** Agent invokes tools; protocols maintain context.
  5. **Settlement:** Economic layer tracks resource usage/billing (Cross-Agent Billing Ledger).

- **Design tradeoffs:**
  - **API-based vs. GUI-based Interaction:** The paper notes (Sec 6.2.2) a tradeoff between API interaction (reliable, fast) and GUI automation (universal, but brittle and slow). Hybrid architectures are emerging.
  - **Autonomy vs. Control:** High autonomy reduces user burden but increases "Agent Drift" risk (Sec 7.1).

- **Failure signatures:**
  - **Tool Use Paradox:** Agents must trust tools to act but verify them to remain secure (Sec 8.1).
  - **Context Injection:** Malicious services injecting false context into the agent's memory via MCP (Sec 7.1.1).

- **First 3 experiments:**
  1. **Implement a minimal MCP Server:** Wrap a simple API (e.g., weather) in an MCP server to understand capability declaration and context passing.
  2. **Intent Decomposition Test:** Provide a complex prompt (e.g., "Plan a 3-day trip") to an LLM and force it to output a dependency graph of sub-tasks before executing.
  3. **Simulate A2A Discovery:** Create two simple agents; have one query the other's "Agent Card" to determine if it can handle a specific sub-task.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can resource consumption be accurately tracked and attributed to a single high-level user command when it spawns multiple sub-agents that delegate tasks further?
- **Basis in paper:** [explicit] Section 5.4.2 explicitly asks how resource consumption can be tracked and attributed to prevent "bill shock" when agents collaborate.
- **Why unresolved:** The variability of computational costs (LLM tokens, API calls) and the decentralized nature of multi-agent delegation make traditional flat-rate subscription models inadequate.
- **What evidence would resolve it:** A granular, transparent billing framework that successfully maps high-level goals to low-level resource costs in real-time without creating user friction.

### Open Question 2
- **Question:** How can "tool skepticism" be integrated into agent architectures to validate external tool responses without crippling the agent's decisiveness?
- **Basis in paper:** [explicit] Section 8.1 identifies the "Tool-Use Paradox" and explicitly asks how to build this skepticism without preventing the agent from acting.
- **Why unresolved:** Current agents lack a zero-trust architecture to validate tool outputs, creating a vulnerability loop where a malicious tool response can trigger cascading failures.
- **What evidence would resolve it:** A "security kernel" or policy engine that validates tool responses against security policies in real-time without significantly degrading task success rates or latency.

### Open Question 3
- **Question:** What new interaction primitives are required to facilitate meaningful human oversight in "agent browsers" without undermining agent autonomy?
- **Basis in paper:** [explicit] Section 5.4.1 explicitly asks what new interaction primitives are required to allow for human oversight in the emerging agent browser paradigm.
- **Why unresolved:** Traditional browsers rely on direct manipulation and linear paths; agent browsers operate as "black boxes" with dynamic reasoning, creating a gap in user trust and understanding.
- **What evidence would resolve it:** UI/UX frameworks that successfully visualize agent reasoning paths and allow for granular intervention (pause/modify/resume) during complex workflows.

## Limitations

- The framework relies heavily on untested assumptions about the capabilities and reliability of autonomous agents in real-world web environments.
- The semantic interoperability of protocols like MCP and A2A remains speculative, with their actual implementation and adoption across diverse services unproven.
- The economic model for the Agent Attention Economy depends on agents having accurate, non-adversarial metadata about services, introducing potential vulnerabilities around trust and verification.

## Confidence

- **High Confidence:** The historical narrative tracing the evolution from PC Web to Mobile Web to Agentic Web is well-grounded and aligns with observable technological trends. The identification of key technical challenges (discovery, interoperability, billing) is reasonable and actionable.
- **Medium Confidence:** The core mechanisms (semantic protocol interoperability, intent-to-planning translation, agent attention economy) are logically coherent and supported by existing research, but their practical implementation and scalability remain unproven. The paper provides conceptual clarity but lacks empirical validation.
- **Low Confidence:** The assumptions about agent reasoning capabilities (e.g., parsing semantic metadata without human intervention, maintaining long-term context) are aspirational and not yet demonstrated in production systems. The economic and security implications of autonomous agent ecosystems are outlined but not rigorously tested.

## Next Checks

1. **Implement and test a minimal MCP server** wrapping a simple API (e.g., weather or calendar) to validate the capability declaration and context-passing mechanisms described in the paper. Measure success rates and error modes in agent-driven tool invocation.
2. **Conduct a controlled experiment** on intent decomposition by providing complex, multi-step prompts (e.g., "Plan a 3-day trip including flights, hotels, and activities") to an LLM and forcing it to output a structured dependency graph before execution. Assess accuracy and completeness of the plan.
3. **Simulate A2A discovery and negotiation** between two simple agents using mock "Agent Cards" to test the Demand-Skill Vector Mapper concept. Evaluate how well agents can match capabilities to task requirements and identify failure points in semantic matching.