---
ver: rpa2
title: 'IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support
  in Dialogue Systems'
arxiv_id: '2506.05947'
source_url: https://arxiv.org/abs/2506.05947
tags:
- seeker
- emotional
- support
- response
- intention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces IntentionESC, a framework that centers on\
  \ supporters\u2019 intentions in emotional support conversations, addressing the\
  \ gap where most existing approaches focus on seeker\u2019s emotions or strategies\
  \ without considering the supporter\u2019s underlying motivations. IntentionESC\
  \ explicitly defines supporters\u2019 intentions, maps them to appropriate strategies,\
  \ and introduces ICECoT, a reasoning chain mechanism that mimics human emotional\
  \ support processes by analyzing emotional states, inferring intentions, and selecting\
  \ strategies before generating responses."
---

# IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems

## Quick Facts
- arXiv ID: 2506.05947
- Source URL: https://arxiv.org/abs/2506.05947
- Authors: Xinjie Zhang; Wenxuan Wang; Qin Jin
- Reference count: 17
- Primary result: ICECoT significantly outperforms competitive baselines across multiple emotional support dimensions

## Executive Summary
IntentionESC introduces a novel intention-centered framework for emotional support conversations that addresses the gap in existing approaches by explicitly modeling supporters' intentions between emotional state analysis and strategy selection. The framework defines 12 supporter intentions adapted from counseling theory, maps them to appropriate strategies, and introduces ICECoT, a reasoning chain mechanism that mimics human emotional support processes. Extensive experiments on the ESConv dataset demonstrate that ICECoT significantly outperforms competitive baselines including BlenderBot, MultiESC, and ESCoT across dimensions like Fluency, Empathy, and Informativeness. The ablation study confirms that intention-driven reasoning is crucial for improving response quality.

## Method Summary
The framework uses GPT-4 to automatically annotate the ESConv dataset with emotional states (4 aspects: issues, emotions, needs, relationship dynamics), intentions (12 categories), and refined strategies (9 types). ICECoT is then fine-tuned on LLAMA3.1-8B-Instruct using a mixed training approach combining full 4-step reasoning chains (emotional state → intention → strategy → response) with strategy-only data. The model is trained on 8 GPUs with batch size 2 per GPU, learning rate 1e-5, and max sequence length 4096. Evaluation includes both single response metrics (Fluency, Empathy, Informativeness) and full conversation metrics (Identification, Comforting, Suggestion, Overall) using human annotators and GPT-4 simulations.

## Key Results
- ICECoT significantly outperforms competitive baselines (BlenderBot, MultiESC, ESCoT) across multiple evaluation dimensions
- Ablation study shows intention inference is crucial for performance, with full ICECoT achieving best results when combined with strategy-only training data
- Response quality improves across Fluency, Empathy, and Informativeness metrics compared to direct generation approaches
- The framework demonstrates effective intention-strategy mapping with high reliability scores for emotional state and intention extraction

## Why This Works (Mechanism)

### Mechanism 1: Intention-Mediated Strategy Selection
- Explicit intention inference improves strategy appropriateness by bridging emotional understanding and response generation
- Inserts an intermediate "intention" layer between emotions and strategies to constrain and guide strategy selection
- 12 defined intentions (e.g., Cathart, Insight, Support) each map to specific strategy sets, reducing strategy-emotion mismatch
- Weak direct evidence in corpus; related work supports structured reasoning but not intention-centered design specifically

### Mechanism 2: Sequential Chain-of-Thought Grounding (ICECoT)
- Forcing LLMs through structured 4-step reasoning (Emotional State → Intention → Strategy → Response) improves response quality
- Training requires generating both reasoning chain and response simultaneously to learn execution of each reasoning step
- Mixed training with strategy-only data helps recover performance lost to long reasoning chains
- COMPEER supports generalization of structured psychological reasoning chains improving empathy

### Mechanism 3: Cumulative Emotional State Tracking
- Maintaining evolving emotional state annotations across dialogue turns enables contextually appropriate intention inference
- Each seeker utterance triggers re-annotation of all 4 emotional state aspects to capture dynamic changes
- Prevents redundant focus on resolved issues and captures evolving emotional needs
- No direct corpus validation for cumulative tracking mechanism specifically

## Foundational Learning

- **Helping Skills Theory (Hill, 2009)**
  - Why needed here: The intention taxonomy and mapping derives from counseling theory
  - Quick check question: Can you explain why "intention" is distinct from "strategy" in a counseling context?

- **Chain-of-Thought Prompting for LLMs**
  - Why needed here: ICECoT extends CoT to emotional support with domain-specific reasoning steps
  - Quick check question: What is the key difference between standard CoT and ICECoT's structured 4-step chain?

- **Automated Annotation with LLMs**
  - Why needed here: Framework relies on GPT-4 for generating emotional state and intention annotations
  - Quick check question: What risks does the paper identify in using automated annotation on an existing dataset with pre-existing strategy labels?

## Architecture Onboarding

- **Component map**: Dialogue History → Emotional State Analyzer → Intention Inferrer → Strategy Selector → Response Generator
- **Critical path**: Dialogue History → Emotional State Analysis → Intention Inference → Strategy Selection → Response. Breaks at Intention Inference if emotional state is incomplete or inconsistent
- **Design tradeoffs**: Full reasoning chain vs. mixed training; 12 intention categories vs. fewer granularity; cumulative vs. single-turn state annotation
- **Failure signatures**: Strategy-response mismatch; intention without state analysis; reasoning chain degradation
- **First 3 experiments**:
  1. Reproduce annotation pipeline on subset: Run GPT-4 emotional state annotation on 50 ESConv dialogues; manually validate extraction accuracy
  2. Ablate intention layer: Train model with emotional state → strategy (skipping intention inference) and compare to full ICECoT
  3. Test strategy-response consistency: Evaluate whether generated responses match selected strategies on held-out test set

## Open Questions the Paper Calls Out

- Can the intention annotation framework be generalized to diverse emotional support datasets beyond ESConv, and what domain-specific adaptations would be required?
- How does the length and complexity of the ICECoT reasoning chain affect model performance, and is there an optimal reasoning depth for emotional support tasks?
- What are the failure modes when the model correctly infers intentions but fails to select appropriate strategies, and can targeted interventions improve strategy selection accuracy?

## Limitations
- Framework relies heavily on automated LLM annotations (GPT-4) with no human validation of annotation quality
- Intention-strategy mapping assumes counselor-derived taxonomies transfer directly to conversational AI contexts without empirical validation
- Mixed training strategy benefits haven't been tested beyond ESConv dataset characteristics

## Confidence

- **High confidence**: ICECoT architecture design and ablation results showing sequential reasoning improves response quality
- **Medium confidence**: Generalizability of intention-centered approach beyond ESConv dataset
- **Medium confidence**: Strategy-response alignment issues identified in Section 5.5

## Next Checks
1. Conduct human evaluation of GPT-4-generated emotional state and intention annotations on a held-out sample to quantify annotation accuracy
2. Test ICECoT framework on a different emotional support dataset (e.g., DailyDialog or IEMOCAP) to assess cross-dataset generalization
3. Implement cross-validation of intention-strategy mappings by having human counselors verify that model-inferred intentions align with professional expectations for given emotional states