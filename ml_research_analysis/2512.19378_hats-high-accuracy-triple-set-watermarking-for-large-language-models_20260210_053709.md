---
ver: rpa2
title: 'HATS: High-Accuracy Triple-Set Watermarking for Large Language Models'
arxiv_id: '2512.19378'
source_url: https://arxiv.org/abs/2512.19378
tags:
- detection
- text
- language
- arxiv
- watermarking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a three-color vocabulary partitioning watermarking
  method for large language models to improve detection accuracy and robustness while
  maintaining text quality. The method divides the vocabulary into green, yellow,
  and red sets, with green and yellow used for generation and red strictly forbidden.
---

# HATS: High-Accuracy Triple-Set Watermarking for Large Language Models

## Quick Facts
- arXiv ID: 2512.19378
- Source URL: https://arxiv.org/abs/2512.19378
- Authors: Zhiqing Hu; Chenxu Zhao; Jiazhong Lu; Xiaolei Liu
- Reference count: 27
- Key outcome: Three-color vocabulary partitioning achieves 61.67% TPR and 0.50% FPR while preserving text quality

## Executive Summary
This paper introduces HATS (High-Accuracy Triple-Set Watermarking), a novel approach for embedding and detecting watermarks in LLM-generated text. The method partitions the vocabulary into three sets—green, yellow, and red—with different generation biases and usage constraints. Green tokens are used preferentially, yellow tokens are discouraged, and red tokens are strictly forbidden. Detection relies on statistical analysis of green enrichment and red depletion patterns, combined via Fisher's method for robust classification. Experiments on Llama 2 7B demonstrate significant improvements over baseline methods while maintaining text quality.

## Method Summary
The HATS watermarking system divides the vocabulary into three disjoint sets using a LeftHash seeding mechanism that ensures reproducibility. During generation, green tokens receive positive logit bias (δ), yellow tokens receive negative bias (-δ), and red tokens are assigned negative infinity logits to prevent their use. Detection computes z-scores for green enrichment and red depletion using Poisson-binomial statistics, then combines these via Fisher's method to produce a final detection score. The approach leverages the fact that while individual token frequencies are not guaranteed, statistical patterns across long sequences provide reliable detection signals.

## Key Results
- Achieves 61.67% true positive rate for detecting watermarked text
- Maintains 0.50% false positive rate across diverse corpora
- Outperforms baseline methods in the TPR-FPR tradeoff space
- Preserves semantic quality with minimal perplexity increase

## Why This Works (Mechanism)
The three-color partitioning creates asymmetric constraints that are difficult to reverse-engineer or circumvent. Green tokens bias generation toward a specific distribution, while red tokens create hard constraints that attackers cannot easily satisfy. The combination of these effects through Fisher's method provides statistical power even when individual components might be weakened by attacks. The LeftHash seeding ensures that both generation and detection use identical partitions without requiring explicit communication of the watermark.

## Foundational Learning

**Vocabulary partitioning**: Dividing the token space into disjoint sets with different generation rules. *Why needed*: Enables creation of statistical signatures that can be detected without altering the underlying model. *Quick check*: Verify that partitions sum to 100% and are mutually exclusive.

**Logits biasing**: Adding constant offsets to token logits during generation. *Why needed*: Controls token selection probabilities without modifying the model's learned representations. *Quick check*: Ensure biased logits don't create numerical instability.

**Fisher's method**: Combining independent p-values using -2∑ln(p_i) ~ χ²_{2k}. *Why needed*: Provides robust detection by aggregating evidence from multiple statistical tests. *Quick check*: Verify p-values are properly computed and independent.

**Poisson-binomial statistics**: Modeling sum of independent Bernoulli trials with different probabilities. *Why needed*: Accurately captures the distribution of green/red token counts in variable-length sequences. *Quick check*: Confirm variance calculations account for token-specific probabilities.

**LeftHash seeding**: Using commutative hash functions to create reproducible partitions. *Why needed*: Enables both parties to derive identical partitions without explicit communication. *Quick check*: Test that the same seed produces identical partitions across different runs.

## Architecture Onboarding

**Component map**: Tokenizer -> Vocabulary Partitioner (LeftHash) -> Logits Processor -> LLM Generator -> Text Output; Detector: Tokenizer -> Partition Replayer -> Green/Yellow/Red Counters -> z-score Calculator -> Fisher Combiner -> χ² Threshold

**Critical path**: Seed generation → Vocabulary partitioning → Logits biasing during generation → Statistical detection using Fisher's method

**Design tradeoffs**: Three-color system vs two-color (better control vs complexity), soft vs hard constraints (robustness vs quality), Fisher combination vs individual tests (power vs interpretability)

**Failure signatures**: High perplexity indicates δ too large or red ratio too high; Low TPR suggests partitioning inconsistency or hash function issues; High FPR indicates threshold miscalibration

**First experiments**: 1) Generate text with known watermark and verify detection succeeds; 2) Generate text without watermark and verify detection fails; 3) Test detection with adversarially crafted prompts designed to trigger red tokens

## Open Questions the Paper Calls Out
None

## Limitations
- Robustness against adaptive attacks is not empirically evaluated
- No sensitivity analysis for hyperparameter choices (partition ratios, bias δ, Fisher weight λf)
- Limited cross-model testing to verify watermark detection independence from generation model

## Confidence
- **High confidence**: Core watermarking mechanism using three-color vocabulary partitioning is well-specified and reproducible
- **Medium confidence**: Experimental results showing improved TPR/FPR tradeoff compared to baselines are plausible given the method design
- **Low confidence**: Claims about robustness to adaptive attacks and superiority over all potential attack strategies are not empirically supported

## Next Checks
1. **Attack resistance validation**: Implement and evaluate the three proposed attack vectors (adversarial prompts, LLM-based filtering, dictionary attacks) to quantify real-world robustness of the detection mechanism
2. **Hyperparameter sensitivity analysis**: Systematically vary partition ratios (γg, γr), bias δ, and Fisher weight λf to identify optimal configurations and understand sensitivity to parameter choices
3. **Cross-model generalization**: Test detection accuracy when watermarked text is generated by one model (e.g., Llama-2-7b) but detected using a different model (e.g., Llama-3 or GPT-4) to assess model independence of the watermarking scheme