---
ver: rpa2
title: Targeted Fine-Tuning of DNN-Based Receivers via Influence Functions
arxiv_id: '2509.15950'
source_url: https://arxiv.org/abs/2509.15950
tags:
- influence
- fine-tuning
- training
- relative
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Influence functions are applied for the first time to deep learning-based\
  \ wireless receivers, using them to identify which training samples most affect\
  \ predictions and enabling targeted fine-tuning on beneficial data. Applied to DeepRx,\
  \ a fully convolutional receiver, the approach reduces the bit error rate gap to\
  \ a genie-aided benchmark by up to 47.8%\xB18.5% in single-target adaptation, outperforming\
  \ random fine-tuning."
---

# Targeted Fine-Tuning of DNN-Based Receivers via Influence Functions

## Quick Facts
- arXiv ID: 2509.15950
- Source URL: https://arxiv.org/abs/2509.15950
- Authors: Marko Tuononen; Heikki Penttinen; Ville Hautamäki
- Reference count: 0
- Primary result: Influence functions reduce BER gap to genie-aided benchmark by up to 47.8%±8.5% in single-target adaptation

## Executive Summary
This paper introduces influence functions to deep learning-based wireless receivers for the first time, using them to identify training samples that most affect bit predictions. Applied to DeepRx, a fully convolutional receiver, the approach enables targeted fine-tuning on beneficial data that improves performance beyond random selection. The method achieves up to 47.8%±8.5% reduction in bit error rate gap to a genie-aided benchmark in single-target adaptation, with ℓ-relative influence and capacity-like binary cross-entropy loss showing the most consistent gains.

## Method Summary
The authors apply influence functions to identify training samples whose upweighting would reduce test loss, enabling targeted fine-tuning that converges faster than random selection. They approximate the Hessian inverse using Arnoldi iteration with 40 eigenvalues to scale to large receivers. Fine-tuning proceeds by selecting the top-50 beneficial samples based on influence scores and performing gradient descent updates. The receiver is evaluated on its ability to reduce the BER gap to a genie-aided LMMSE baseline with perfect channel state information.

## Key Results
- Single-target influence-guided fine-tuning reduces BER gap by 47.8%±8.5% (800k samples) and 65.6%±13.5% (200k samples) versus random selection
- ℓ-relative influence with BCE loss consistently outperforms other variants across training regimes
- First-order gradient descent fine-tuning outperforms influence-aligned second-order updates despite theoretical justification
- Multi-target adaptation struggles with conflicting gradient directions and underperforms single-target approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Influence functions identify training samples whose upweighting would reduce test loss, enabling targeted fine-tuning that converges faster than random selection.
- Mechanism: Influence functions approximate the derivative of model parameters with respect to training sample weights via the inverse Hessian (Eq. 1). For a test instance $z_{test}$ and training sample $z_i$, classic influence (Eq. 2) $I_{Classic}(z_{test}, z_i) = -\nabla_\theta \ell(z_{test}, \hat{\theta})^\top H_{\hat{\theta}}^{-1} \nabla_\theta \ell(z_i, \hat{\theta})$ yields negative values for beneficial samples. Fine-tuning on these samples produces first-order loss reduction proportional to influence magnitude.
- Core assumption: The Hessian and influence estimates remain approximately valid for the first few fine-tuning steps; the loss landscape is locally quadratic.
- Evidence anchors:
  - [abstract]: "influence analysis reveals which training samples drive bit predictions, enabling targeted fine-tuning of poorly performing cases"
  - [Section 3, Step 3]: "the receiver is briefly trained on beneficial samples, providing a quick nudge in the right direction"
  - [corpus]: Limited direct corroboration; corpus focuses on neural receiver architectures and OOD detection rather than influence-based adaptation. Assumption: mechanism transferability from CV/NLP (Koh & Liang [21]) to wireless domain.
- Break condition: After ~15 fine-tuning steps, influence becomes outdated and influence-guided converges to random selection (Fig. 3a); Hessian changes invalidate IHVP estimates.

### Mechanism 2
- Claim: ℓ-relative influence with capacity-like BCE loss normalizes by self-influence, improving sample selection consistency across training regimes.
- Mechanism: ℓ-relative influence (Eq. 5) $I_{\ell\text{-relative}}(z_{test}, z_i) = I_{Classic}(z_{test}, z_i) / \sqrt{I_{Classic}(z_i, z_i)}$ divides classic influence by the square root of self-influence. This downweights high-leverage points that exert outsized influence on any target, yielding more interpretable and stable rankings.
- Core assumption: Self-influence captures sample-specific properties (e.g., difficulty, representativeness) that should be normalized for fair comparison.
- Evidence anchors:
  - [Section 2.2]: "These normalize influence, providing a localized view of it and making comparisons across models or datasets more interpretable"
  - [Table 1]: BCE with ℓ-relative achieves 65.6±13.5% (200k) and 47.8±8.5% (800k) gap reduction—most consistent across regimes
  - [corpus]: No direct corpus evidence for ℓ-relative specifically in receivers; related work on neural receivers (DeepRx MIMO [32]) uses same BCE loss but not influence variants.
- Break condition: When self-influence estimates are noisy (small eigenvalue truncation), normalization may amplify noise rather than correct leverage.

### Mechanism 3
- Claim: Arnoldi-based Hessian approximation enables scalable influence computation for large receivers by projecting onto a low-dimensional Krylov subspace.
- Mechanism: Rather than computing the full Hessian inverse, Arnoldi iteration (Eq. 7) projects $H$ onto a $k$-dimensional subspace via $G^\top \hat{H}^{-1} Gv = \sum_{i=1}^k \frac{1}{\lambda_i} g_i(g_i^\top v)$, using only the top-$k$ Ritz values/vectors. The paper uses $k=40$ eigenvalues determined by elbow analysis (Figs. 5-6).
- Core assumption: The truncated spectrum captures the curvature directions most relevant to influence estimation; low-eigenvalue modes contribute negligible signal.
- Evidence anchors:
  - [Section 4.1]: "We kept the top-40 eigenvalues, beyond which accuracy gains were negligible"
  - [Appendix 8.1]: Marginal relative drops plateau below 4% beyond 40 terms
  - [corpus]: Schioppa et al. [25] (referenced in paper) establishes Arnoldi-based IF scaling; corpus lacks independent replication in wireless domain.
- Break condition: If critical influence signal resides in discarded high-frequency eigenmodes (unlikely for smooth loss landscapes), truncation introduces systematic bias.

## Foundational Learning

- Concept: **Influence Functions (Robust Statistics)**
  - Why needed here: Core tool for tracing prediction behavior back to training data; requires understanding of empirical risk minimization, Hessian geometry, and infinitesimal weight perturbations.
  - Quick check question: Given Eq. (2), explain why negative influence indicates a beneficial sample for reducing test loss.

- Concept: **Fully Convolutional Receivers (DeepRx Architecture)**
  - Why needed here: Target architecture processes raw frequency-domain OFDM signals directly; differs from semantic vision/language inputs where influence methods were originally developed.
  - Quick check question: Why does the multi-label bit prediction setting (thousands of independent binary outputs) prevent direct application of label-correction unlearning methods?

- Concept: **Genie-Aided Benchmarking in Wireless**
  - Why needed here: Evaluation baseline assumes perfect channel state information; the relative BER gap (Eq. 9) quantifies how close the neural receiver approaches theoretical limits.
  - Quick check question: Why is the genie-aided LMMSE receiver an appropriate upper bound rather than the baseline LMMSE?

## Architecture Onboarding

- Component map: Received signals → DeepRx (Conv encoder + bit estimator) → Predicted bits → Evaluation: BER vs. Genie-aided LMMSE (full CSI) → Target selection: Top-5 highest relative BER gap (BER_Genie ≥ 10⁻³) → Influence computation: Arnoldi IF (k=40) with BCE loss, ℓ-relative → Fine-tuning: First-order GD on top-50 beneficial samples (3 steps, lr=0.002)

- Critical path: Accurate influence estimation depends on Hessian approximation quality (k=40 eigenvalues → ~2.4M HVPs). Fine-tuning effectiveness degrades rapidly after ~15 steps as influence becomes stale.

- Design tradeoffs:
  - First-order vs. second-order updates: First-order (gradient descent) outperforms influence-aligned second-order (Eq. 11) despite theoretical justification—Hessian reuse assumption breaks quickly.
  - BCE vs. BER-oriented loss: BCE (training loss) outperforms BER surrogate despite metric misalignment—suggests gradient quality matters more than metric alignment.
  - Single vs. multi-target: Single-target adaptation effective; multi-target struggles with conflicting gradient directions.

- Failure signatures:
  - Fine-tuning on harmful samples with gradient ascent causes catastrophic BER degradation (Fig. 3b)
  - Multi-target influence-guided tuning matches or underperforms random on non-targets (Fig. 4c-d)
  - Large learning rates (>0.01) destabilize fine-tuning; optimal range 0.001–0.002 (Figs. 9-10)

- First 3 experiments:
  1. **Reproduce single-target result**: Train DeepRx on 200k/800k samples, compute ℓ-relative influence for worst evaluation instance, fine-tune 3 steps on top-50 beneficial samples. Verify ~48–66% gap reduction vs. ~14% random baseline.
  2. **Ablate influence variants**: Compare Classic, Newfluence, θ-relative, and ℓ-relative with both BCE and BER-surrogate losses. Confirm ℓ-relative + BCE most consistent.
  3. **Probe influence decay**: Track BER over 0–20 fine-tuning steps for influence-guided vs. random. Confirm convergence around step 15, validating influence staleness hypothesis.

## Open Questions the Paper Calls Out
None

## Limitations
- Results specific to DeepRx architecture and synthetic channel conditions; performance on MIMO, time-varying channels, or hardware remains untested
- Hessian approximation via 40 eigenvalues may miss critical curvature directions for highly non-convex loss landscapes
- ℓ-relative influence normalization lacks theoretical grounding for cross-regime consistency
- Adaptive gains measured only in controlled synthetic channels, not real-world RF environments

## Confidence
- **High Confidence**: Influence-guided fine-tuning outperforms random selection within first 15 steps, with gap reductions of 47.8±8.5% and 65.6±13.5% in single-target adaptation. Supported by multiple experiments and ablation studies.
- **Medium Confidence**: ℓ-relative influence with BCE loss is most consistent variant. While Table 1 and ablation support this, corpus lacks independent replication.
- **Low Confidence**: Second-order Hessian-based updates and multi-target adaptation are ineffective. These conclusions rest on single experimental conditions and conflict with theoretical justifications.

## Next Checks
1. **Cross-Architecture Generalization**: Apply influence-guided fine-tuning to DeepRx MIMO and alternative neural receiver architectures under identical channel conditions to test architectural robustness.

2. **Eigenvalue Truncation Sensitivity**: Systematically vary the number of Arnoldi eigenvalues (k=10, 20, 40, 80) and measure influence accuracy via held-out validation, identifying minimum k that preserves >95% beneficial sample identification.

3. **Real-World Channel Transfer**: Evaluate influence-guided adaptation on over-the-air OFDM transmissions with imperfect CSI, comparing synthetic channel performance to hardware results to quantify environmental degradation.