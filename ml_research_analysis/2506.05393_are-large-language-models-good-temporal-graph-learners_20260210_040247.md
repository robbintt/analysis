---
ver: rpa2
title: Are Large Language Models Good Temporal Graph Learners?
arxiv_id: '2506.05393'
source_url: https://arxiv.org/abs/2506.05393
tags:
- node
- temporal
- graph
- llms
- destination
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TGTalker, the first framework applying large
  language models (LLMs) to real-world temporal graphs for link prediction. The core
  method encodes recent temporal graph structure and neighbor information as natural
  language prompts for LLMs, enabling predictions without fine-tuning.
---

# Are Large Language Models Good Temporal Graph Learners?

## Quick Facts
- arXiv ID: 2506.05393
- Source URL: https://arxiv.org/abs/2506.05393
- Reference count: 40
- Primary result: TGTalker framework enables LLMs to achieve competitive temporal link prediction performance without fine-tuning, while providing interpretable explanations

## Executive Summary
This paper introduces TGTalker, the first framework applying large language models (LLMs) to real-world temporal graphs for link prediction. The core method encodes recent temporal graph structure and neighbor information as natural language prompts for LLMs, enabling predictions without fine-tuning. Experiments across five datasets and six LLM families show TGTalker achieves competitive performance with state-of-the-art temporal graph neural networks, consistently outperforming popular TGNN baselines. The framework also generates interpretable textual explanations for predictions, revealing reasoning patterns like recency bias and repeated interactions. Ablation studies confirm that temporal neighbor sampling is critical for performance. Results demonstrate LLMs can effectively reason about dynamic graph structures while providing explainability, opening new directions for temporal graph learning.

## Method Summary
TGTalker converts temporal graph structures into natural language prompts that LLMs can process for link prediction. The framework retrieves the most recent edges globally (Background Set) and the most recent neighbors of the source node (Temporal Neighbor Sampling), then serializes this information along with few-shot examples into a text prompt. The LLM processes this prompt using in-context learning to predict the destination node ID. The method exploits recency bias in temporal graphs to manage context window limitations while maintaining competitive performance compared to traditional temporal graph neural networks.

## Key Results
- TGTalker achieves competitive performance with state-of-the-art temporal graph neural networks across five datasets
- The framework consistently outperforms popular TGNN baselines like HTDN and TGN without requiring any fine-tuning
- Ablation studies show temporal neighbor sampling is critical, with performance dropping significantly when removed
- Generated explanations reveal reasoning patterns including recency bias and repeated interactions, though some explanations may be hallucinations

## Why This Works (Mechanism)

### Mechanism 1: Context-Aware Retrieval via Recency Bias
TGTalker maintains competitive performance by exploiting the strong recency bias inherent in temporal graphs, narrowing the prediction search space to temporally local interactions. The framework retrieves the $b$ most recent edges globally and the $m$ most recent neighbors of the source node, reducing cognitive load on the model and aligning input context with the statistical likelihood that future links correlate with recent activity. This assumes future interactions depend more heavily on recent history than long-range temporal dependencies. Evidence shows removing temporal neighbors drops performance significantly on tested datasets. Performance will degrade on datasets with long-range periodic patterns where recent edges don't correlate with next active periods.

### Mechanism 2: In-Context Learning (ICL) for Structural Pattern Recognition
The framework enables LLMs to perform link prediction without weight updates by formatting the task as a pattern-completion problem using few-shot prompting. TGTalker constructs an Example Set with question-answer pairs that the LLM uses to infer underlying rules of graph dynamics solely through attention mechanisms over the prompt context. This assumes the pre-trained LLM possesses sufficient reasoning capabilities to map sequential text descriptions of graph edges to logical structural predictions without gradient updates. The approach relies on the LLM's ability to recognize patterns from provided examples. Complex multi-hop reasoning exceeding the context window or logical capacity will cause the model to fail.

### Mechanism 3: Serialization of Topology into Natural Language
Converting discrete graph topology into standardized text tuples allows the LLM to process relational data using its native token prediction capabilities. Graph elements are serialized into strings like `(src node ID, dst node ID, timestamp)`, transforming the graph prediction task into a text-to-text mapping problem. The LLM predicts the destination node ID as the next likely token sequence based on the "grammar" of the provided interaction history. This assumes integer IDs and timestamps, when formatted as text, preserve enough structural information for the LLM to differentiate nodes and infer temporal causality. Hallucination of non-existent node IDs or failure to respect integer ordering may occur if the model treats IDs purely as unstructured tokens.

## Foundational Learning

- **Concept: Continuous-Time Dynamic Graphs (CTDG)**
  - Why needed here: TGTalker is built specifically for CTDGs (event streams) rather than Discrete-Time Dynamic Graphs (snapshots). You must understand that the model processes a stream of timed events $(s, d, t)$ rather than a sequence of static images.
  - Quick check question: Does the model process the graph as a sequence of snapshots or a stream of timestamped events?

- **Concept: Recency Bias**
  - Why needed here: This is the core heuristic assumption of the paper. Understanding this is critical to explaining why TGTalker samples only recent neighbors and why it outperforms older historical models on specific datasets.
  - Quick check question: Why might a model that only looks at the last 300 edges outperform a model that has "seen" the entire graph history?

- **Concept: In-Context Learning (ICL)**
  - Why needed here: TGTalker relies entirely on ICL to function. Unlike TGNNs (like TGN or HTDN), TGTalker does not update weights during training or inference.
  - Quick check question: How does the model "learn" the link prediction task if the neural network weights are frozen?

## Architecture Onboarding

- **Component map:** Temporal Neighbor Sampler -> Background Set Generator -> Prompt Constructor -> LLM Engine -> Output Parser
- **Critical path:** The prompt construction is the bottleneck. The system must efficiently query the graph history to build the Background Set and Temporal Neighbors before the LLM can begin inference.
- **Design tradeoffs:**
  - Token Limit ($l_{max}$) vs. Context: Increasing the background set size ($b$) improves global awareness but consumes the context window, potentially pushing out relevant local history or few-shot examples.
  - Serialization Format: The paper uses integer IDs. This is token-efficient but loses semantic info compared to text descriptors (used in other LLM-graph works).
- **Failure signatures:**
  - "Hallucinated IDs": The LLM outputs a destination ID that does not exist in the graph or appears in the training set but not the valid candidate set.
  - Recency Collapse: On datasets with low "surprise index" (repetitive edges), the model may overfit to the "Most Recent Interaction" heuristic and fail to detect structural patterns.
  - Reasoning Disconnect: As seen in the "Lack of Data" category, the LLM may generate a logical explanation that does not mathematically correspond to the predicted ID.
- **First 3 experiments:**
  1. Ablation on Neighbors: Run TGTalker with `temporal_neighbors=0` vs `temporal_neighbors=2` (Table 8/9) to confirm that local context is the primary driver of performance.
  2. Explanation Verification: Check if the "Most Recent Interaction" explanation category actually correlates with the ground truth (high MRR) vs. "Lack of Data" (low MRR) in Figure 3.
  3. Dataset Surprise Index: Evaluate performance on a high-surprise dataset (like UCI) vs. a low-surprise one to see where the "recency bias" mechanism breaks down.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can LLM-based temporal graph frameworks effectively capture long-range temporal dependencies given the strict constraints of finite context windows?
- Basis in paper: [explicit] Appendix A states that converting graphs to text is "inherently constrained by the context window," and relying on recent edges "may overlook long-range dependencies," potentially degrading performance on datasets where links span long durations.
- Why unresolved: TGTalker currently addresses context limits by subsampling edges based on recency bias, effectively truncating older historical data that the model cannot attend to.
- What evidence would resolve it: A modified framework incorporating compression or retrieval mechanisms for historical states that demonstrates improved performance on datasets specifically designed to test long-term temporal reasoning.

### Open Question 2
- Question: Why do smaller open-source models (e.g., Qwen2.5-7B) frequently outperform larger proprietary models like GPT-4.1-mini on temporal link prediction tasks?
- Basis in paper: [explicit] Section 5.1 observes that "GPT-4.1-mini often underperforms its open-source counterparts of comparable or even smaller sizes," noting this trend is particularly pronounced on tgbl-wiki and Reddit.
- Why unresolved: The paper empirically reports the performance gap but does not analyze the underlying causes, such as differences in pre-training data composition, tokenization strategies, or instruction-tuning alignment.
- What evidence would resolve it: An ablation study analyzing the impact of different tokenization methods for graph structures or a probing analysis of intrinsic temporal reasoning capabilities across model families.

### Open Question 3
- Question: How can the reliability of generated natural language explanations be verified to distinguish valid reasoning from hallucinations?
- Basis in paper: [explicit] Appendix B notes that "LLMs can hallucinate and provide unreliable explanations," and Section 5.2 identifies that explanations in the 'Default or Most Common Node' category often appeared to be hallucinations.
- Why unresolved: While the paper categorizes explanations, it relies on the LLM to self-report reasoning without a ground-truth mechanism to validate if the stated logic (e.g., "Pattern Continuation") actually matches the model's inference process.
- What evidence would resolve it: The development of a consistency metric that correlates specific explanation categories with intervention-based outcomes (e.g., removing the cited pattern to see if the prediction changes).

## Limitations

- Framework's reliance on recency bias may not generalize to datasets with bursty interactions or periodic patterns where recent history doesn't predict future links
- Serialization using integer IDs loses semantic information compared to text representations, with unclear trade-offs between token efficiency and semantic richness
- Explanation generation capability shows reasoning disconnect, with some explanations appearing to be post-hoc rationalizations rather than genuine reasoning traces

## Confidence

**High Confidence:** The core claim that TGTalker achieves competitive performance with state-of-the-art TGNNs is well-supported by experimental results across five datasets and six LLM families, with ablation studies providing strong evidence for the mechanism's effectiveness.

**Medium Confidence:** The claim about in-context learning enabling LLMs to perform link prediction without fine-tuning is plausible but requires more investigation, as success may depend heavily on specific prompting strategy and example selection.

**Low Confidence:** The explanation generation capability's authenticity and usefulness remain questionable, as explanations show weak correlation with actual prediction mechanisms and lack systematic validation beyond categorization.

## Next Checks

1. **Dataset Diversity Test:** Evaluate TGTalker on a dataset with bursty interactions or periodic patterns (e.g., traffic networks or seasonal user behavior) to determine if the recency bias mechanism generalizes beyond current test sets.

2. **Serialization Comparison:** Implement a semantic text representation variant of TGTalker (using node descriptions instead of integer IDs) and compare performance against the current integer-based approach to quantify the trade-off between token efficiency and semantic richness.

3. **Explanation Verification:** Design a systematic evaluation protocol to measure the correlation between generated explanations and prediction accuracy, such as checking whether "Most Recent Interaction" explanations correspond to higher MRR scores compared to "Lack of Data" explanations.