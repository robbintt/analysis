---
ver: rpa2
title: 'The Multimodal Paradox: How Added and Missing Modalities Shape Bias and Performance
  in Multimodal AI'
arxiv_id: '2505.03020'
source_url: https://arxiv.org/abs/2505.03020
tags:
- multimodal
- performance
- modalities
- fairness
- modality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how the addition and absence of modalities
  impact the performance and fairness of multimodal AI models, using healthcare datasets
  MIMIC-Eye and MIMIC-IV-Ext-MDS-ED. The authors evaluate two research questions:
  (RQ1) whether adding modalities consistently improves performance and fairness,
  and (RQ2) how missing modalities at inference affect robustness.'
---

# The Multimodal Paradox: How Added and Missing Modalities Shape Bias and Performance in Multimodal AI

## Quick Facts
- arXiv ID: 2505.03020
- Source URL: https://arxiv.org/abs/2505.03020
- Reference count: 18
- Primary result: Adding modalities improves performance but fairness impacts vary unpredictably; even small percentages of missing modalities degrade both performance and fairness

## Executive Summary
This paper investigates how adding and removing modalities affects multimodal AI performance and fairness in healthcare settings. Using MIMIC-Eye and MIMIC-IV-Ext-MDS-ED datasets, the authors evaluate two research questions: whether adding modalities consistently improves performance and fairness, and how missing modalities at inference affect robustness. Their method incrementally adds modalities during training and randomly masks modalities during inference. Results show that while adding modalities improves overall performance (F1 scores up to 0.92 and AUC-ROC up to 0.91), fairness disparities fluctuate, particularly for race and gender. Missing modalities, even in small percentages, consistently degrade both performance and fairness.

## Method Summary
The method converts diverse clinical modalities (images, time series, structured data) into a shared text-based embedding space using domain-specific encoders (MedBERT for structured text, fine-tuned Qwen 2.5 VL for chest X-rays, PULSE-7B for ECG). These modality-specific embeddings are concatenated and processed through a self-attention module to capture cross-modal interactions before classification. The approach incrementally adds modalities during training to assess performance and fairness impacts, then applies random modality masking at inference using Bernoulli sampling to evaluate robustness. Performance metrics include F1, AUC-ROC, AUPRC, and Balanced Accuracy, while fairness is evaluated using Demographic Parity and True Positive Rate across race and gender groups.

## Key Results
- Adding modalities consistently improves performance metrics (F1 up to 0.92, AUC-ROC up to 0.91)
- Fairness disparities fluctuate unpredictably when adding modalities, with some widening racial gaps
- Missing modalities as small as 0.1-0.2% cause measurable degradation in both performance and fairness metrics

## Why This Works (Mechanism)

### Mechanism 1: Unified Text-Based Feature Space for Heterogeneous Modalities
Converting diverse clinical modalities into a shared text-based embedding space enables cross-modal attention and fusion. Domain-specific encoders generate modality-specific embeddings that are concatenated and processed through self-attention to capture cross-modal interactions before classification. Core assumption: text-based representations preserve sufficient signal from non-text modalities. Evidence: paper describes unified embedding generation and self-attention processing. Break condition: if non-text modalities lose critical patterns during text conversion.

### Mechanism 2: Incremental Modality Addition Enhances Performance but Not Necessarily Fairness
Adding modalities during training monotonically improves performance metrics but fairness disparities fluctuate unpredictably across demographic groups. Each modality contributes complementary predictive signal but may also carry modality-specific biases. Core assumption: modality monotonicity holds for performance but fairness effects are context-dependent. Evidence: paper shows performance improvements but varying fairness trends across datasets. Break condition: if a modality introduces strong spurious correlations with protected attributes, it could amplify rather than reduce bias.

### Mechanism 3: Missing Modalities at Inference Degrade Both Performance and Fairness
Random modality masking via Bernoulli sampling removes input signals the model learned to depend on during training, reducing prediction quality and potentially amplifying disparities. Core assumption: models trained with full modality availability don't inherently learn robust fallback representations. Evidence: paper demonstrates measurable drops even with 0.1-0.2% missing modalities. Break condition: if models are trained with modality dropout or missing-aware pre-training, robustness could be improved.

## Foundational Learning

- Concept: Multimodal Fusion Architectures
  - Why needed here: The paper uses early fusion via concatenation followed by self-attention; understanding fusion strategies is essential for interpreting why missing modalities cause performance drops.
  - Quick check question: Can you explain the difference between early, late, and hybrid fusion, and why early fusion makes models more vulnerable to missing modalities at inference?

- Concept: Fairness Metrics in Classification (Demographic Parity, True Positive Rate)
  - Why needed here: The paper evaluates fairness using DP and TPR across race and gender; understanding these metrics is necessary to interpret the fairness variability findings.
  - Quick check question: For a binary classification task predicting ICU admission, what would it mean if DP differs by race but TPR does not?

- Concept: Modality Monotonicity Assumption
  - Why needed here: The paper tests whether this widely-held assumption holds for both performance and fairness; understanding it frames the research questions.
  - Quick check question: Why might adding a modality improve overall accuracy but worsen fairness for a specific demographic group?

## Architecture Onboarding

- Component map: Input modalities (structured EHR, chest X-rays, ECG signals) → modality-specific text conversion → MedBERT embedding → concatenation → self-attention module → feedforward network → classification head → performance/fairness evaluation

- Critical path: Input modalities → modality-specific text conversion → MedBERT embedding → concatenation → self-attention → classification → performance/fairness evaluation. Assumption: The critical bottleneck is the text-based unification; errors in modality-to-text conversion propagate through all downstream components.

- Design tradeoffs:
  - Text-based unification vs. native multimodal encoders: Text conversion enables use of a single encoder (MedBERT) but may lose modality-specific patterns (e.g., spatial in images, temporal in ECG).
  - Random masking vs. structured missingness: Random Bernoulli masking tests general robustness but may not reflect real-world missingness patterns (e.g., financial barriers correlating with demographics).
  - Concatenation + self-attention vs. modality-specific heads: Current design is simple but may not learn robust fallback representations for missing modalities.

- Failure signatures:
  - Performance drops sharply when specific high-value modalities (e.g., "Arrival" in MIMIC-Eye with F1=0.920) are missing.
  - Fairness disparities widen for Non-White groups as more modalities are added (MIMIC-Eye pattern).
  - Even 0.1% missing modalities causes measurable degradation, indicating lack of robustness.

- First 3 experiments:
  1. Reproduce modality-wise analysis on a single dataset: Train unimodal models for each modality, report F1, AUC-ROC, and DP/TPR by demographic group to establish baseline contributions.
  2. Implement random modality masking at inference: Start with 0%, 10%, 20%, 50% missing rates and plot performance and fairness degradation curves; compare against the paper's finding that even 0.1% causes drops.
  3. Test modality dropout during training: Add Bernoulli masking during training (not just inference) to assess whether this improves robustness to missing modalities at inference; this directly addresses the paper's call for more robust model design.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What mechanisms can identify and select modalities that maximize performance gains while minimizing fairness degradation before deployment?
- Basis in paper: The conclusion states "fairness disparities vary across datasets, emphasizing the need for careful modality selection to balance metrics effectively."
- Why unresolved: The paper demonstrates that adding modalities improves performance but fairness impacts are unpredictable—some modalities widen racial disparities while others mitigate them. No principled selection method is proposed.
- What evidence would resolve it: A modality selection framework that predicts fairness impact from modality characteristics, validated across multiple datasets showing consistent performance-fairness tradeoffs.

### Open Question 2
- Question: How can multimodal models be designed to maintain both performance and fairness when modalities are missing at inference time?
- Basis in paper: The authors state: "We call upon the research community to focus on developing methods to address these challenges, ensuring that future multimodal models are not only performant but also robust and fair in real-world applications, where modality availability can fluctuate."
- Why unresolved: The paper shows even 0.1-0.2% missing modalities degrade performance and fairness, but proposes no mitigation strategies. Current architectures lack robustness to partial inputs.
- What evidence would resolve it: Novel training procedures or architectural modifications that preserve fairness metrics within acceptable bounds when modalities are absent, tested under controlled missing-modality conditions.

### Open Question 3
- Question: Do fairness and robustness findings generalize beyond healthcare to other multimodal domains with different modality relationships?
- Basis in paper: Methodological limitation—the study uses only MIMIC-EYE and MIMIC-IV-Ext-MDS-ED healthcare datasets. Modality relationships in clinical data may differ fundamentally from other domains like autonomous driving or content moderation.
- Why unresolved: Healthcare modalities have specific correlation structures and clinical dependencies. Whether the paradoxical fairness fluctuations and missing-modality sensitivity hold across domains remains unknown.
- What evidence would resolve it: Replication studies on multimodal datasets from non-healthcare domains showing similar patterns of modality-addition fairness variability and missing-modality robustness degradation.

## Limitations
- Architectural specifics remain underspecified (self-attention layer dimensions, classifier hyperparameters, exact training procedures)
- Missing details on how masked modalities are represented at inference (zero vectors vs learned tokens)
- Demographic group sizes and distribution balance across datasets are not reported, limiting interpretation of fairness disparities

## Confidence
- **High**: Performance monotonicity (adding modalities improves F1/AUC-ROC)
- **Medium**: Fairness variability findings (disparities fluctuate across measures but directionally consistent patterns exist)
- **Low**: Missing modality robustness claims (even 0.1% degradation is theoretically sound but practical significance unclear without subgroup analysis)

## Next Checks
1. Replicate modality-wise baseline models to confirm individual modality contributions and establish anchor points for fairness/fairness comparisons
2. Implement incremental modality training with controlled random seeds to verify monotonicity and fairness fluctuation patterns
3. Test robustness to structured (not random) missingness patterns that correlate with demographics to assess real-world applicability of findings