---
ver: rpa2
title: Optimizing Quantum Circuits via ZX Diagrams using Reinforcement Learning and
  Graph Neural Networks
arxiv_id: '2504.03429'
source_url: https://arxiv.org/abs/2504.03429
tags:
- circuit
- quantum
- circuits
- optimization
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of reducing two-qubit gate count
  in quantum circuits, which is critical for mitigating noise on near-term quantum
  hardware. The authors introduce a novel reinforcement learning framework that uses
  ZX calculus, graph neural networks, and tree search to discover arbitrary circuit
  optimization rules.
---

# Optimizing Quantum Circuits via ZX Diagrams using Reinforcement Learning and Graph Neural Networks

## Quick Facts
- **arXiv ID:** 2504.03429
- **Source URL:** https://arxiv.org/abs/2504.03429
- **Reference count:** 40
- **Primary result:** RL agent using ZX-calculus and GNNs reduces CNOT count by up to 30% on diverse random circuits compared to state-of-the-art optimizers.

## Executive Summary
This work introduces a novel reinforcement learning framework for quantum circuit optimization that operates directly on ZX-diagrams using graph neural networks and tree search. The method learns to select optimal sequences of ZX-calculus rewrite rules to minimize two-qubit gate count, outperforming traditional heuristic optimizers like PyZX full reduce and template-matching approaches. By combining policy-based RL with tree search, the agent can explore non-monotonic transformation paths and discover new optimization patterns, achieving strong generalization across different circuit types and scaling to large 50-qubit circuits through peephole optimization.

## Method Summary
The authors develop an RL agent that operates on ZX-graphs (tensor-network representations of quantum circuits) to optimize CNOT gate count. The agent uses two GNNs: one predicts rule/position pairs for ZX-calculus transformations, and another handles tree-level node selection and value estimation. The method employs Proximal Policy Optimization (PPO) with a tree search budget of 128 steps, allowing backtracking through non-monotonic optimization paths. The agent is trained on randomly generated 5-qubit circuits with specific gate ratios, learning to apply a subset of ZX-calculus rules (spider fusion, un-fusion, π-commute, color change, bialgebra, and Euler decomposition) to minimize CNOT gates while ensuring the resulting diagrams remain extractable into valid circuits.

## Key Results
- Agent achieves up to 30% reduction in CNOT count compared to PyZX full reduce and template-matching methods on diverse random circuits
- Strong generalization demonstrated on pure-CNOT and equal-ratio circuit distributions, outperforming baselines despite training on mixed circuits
- Scales to 50-qubit circuits using peephole optimization, maintaining competitive performance while discovering new optimization patterns
- Outperforms greedy approaches and MCTS variants, validating the tree search with backtracking mechanism

## Why This Works (Mechanism)

### Mechanism 1: ZX-Calculus Rule Sequencing via Learned Policy
A learned policy can outperform fixed heuristics at selecting which ZX-calculus rewrite rules to apply and where, specifically for CNOT gate reduction. The RL agent operates on ZX-graphs by selecting from a bounded set of rewrite rules—spider fusion, un-fusion, π-commute, color change, bialgebra, and Euler decomposition. The GNN encodes graph structure into embeddings that inform both rule selection and application position. By training on random circuits with reward signal $R = 1 - \text{CNOT}(n)/\text{CNOT}(r)$, the policy learns multi-step transformation sequences that may temporarily increase gate count before achieving net reduction.

### Mechanism 2: Tree Search with Backtracking Enables Non-Monotonic Optimization
Maintaining a single search tree across optimization allows recovery from locally suboptimal rule applications, improving final CNOT reduction compared to greedy or single-path methods. Each tree node stores a circuit state. At each step: (1) GNN predicts weight $W(n)$ for all expandable nodes; (2) path weights $\tilde{W}(n)$ accumulate from root; (3) softmax sampling selects node to expand; (4) policy $\pi_{zx}$ selects rule+position; (5) new state added as child. After $K=128$ expansions, best circuit in tree is selected.

### Mechanism 3: Implicit Learning of Extraction-Aware Transformations
By including circuit extraction as part of the reward computation, the agent learns to produce ZX-diagrams that require minimal post-processing during extraction, avoiding transformations that break extractability. The reward is computed post-extraction, not on the ZX-diagram directly. Extraction uses 4+ levels of preprocessing (pivoting, local complementation) if initial extraction fails. The agent's average extraction level varies by circuit type, suggesting learned adaptation to extraction requirements.

## Foundational Learning

- **Concept: ZX-Calculus Basics (Spiders, Fusion, Graph-Like Form)**
  - **Why needed here:** The entire state representation and action space is defined in ZX terms. Without understanding that Z-spiders (green) and X-spiders (red) compose via wire connection, and that fusion combines same-colored connected spiders, you cannot interpret the GNN inputs or action outputs.
  - **Quick check question:** Given two Z-spiders connected by one wire with phases $\alpha$ and $\beta$, what is the result of applying spider fusion?

- **Concept: Policy Gradient Methods (PPO specifically)**
  - **Why needed here:** The agent uses Proximal Policy Optimization with actor-critic architecture (policy $\pi_{zx}$, value $V$). Understanding clipped surrogate objectives and advantage estimation is necessary to debug training instability.
  - **Quick check question:** Why does PPO use a clipped objective rather than direct policy gradient? What role does the value function play in computing advantages?

- **Concept: Graph Neural Networks (Message Passing, GCN Layers)**
  - **Why needed here:** Two GNNs process ZX-graphs: one for rule/position prediction, one for tree-level value/weight. The paper uses 4-layer GCNs with width scaled by number of rules. Understanding permutation invariance and neighborhood aggregation is critical for architectural modifications.
  - **Quick check question:** If you swap all Z-spiders with X-spiders in a ZX-graph, should the GNN output change? How does the paper's feature engineering ensure this?

## Architecture Onboarding

**Component map:**
Input Circuit → ZX Conversion (PyZX) → Search Tree (root = initial diagram) → GNN-Tree: Predict W(n), V(n) → Softmax sample node n → GNN-Rule: Process ZX-graph → Predict π_zx(rule, position | n) → Apply rule → New ZX diagram → Add as child → [Loop K=128 times] → Select best node by CNOT count → Extraction (levels 1-5) → Output circuit

**Critical path:**
1. ZX rule set selection (Fig. 2) — constrains action space
2. GNN feature engineering (rule-applicability features, not raw colors/phases)
3. Tree weight accumulation (Eq. 6) — determines exploration
4. Extraction level selection — determines final CNOT count

**Design tradeoffs:**
- **Rule subset vs. completeness:** Paper uses 6 rules (plus identity removal); full ZX-calculus completeness requires additional rules. Tradeoff: smaller action space speeds training but may miss optimal transformations.
- **GNN vs. MLP for scaling:** For 50-qubit circuits, paper replaces GNN with MLP using handcrafted features (Table IV), trading position-awareness for speed. Requires random action sampling with retries.
- **Tree budget (K=128):** Higher K explores more but increases inference time linearly. Paper uses 3 restarts for large circuits.

**Failure signatures:**
- **Extraction failure:** If agent applies bialgebra rule excessively, extraction requires Level 4+ preprocessing; if still fails, falls back to PyZX full_reduce (loses learned optimization).
- **Entropy collapse:** If weight function $W$ converges to uniform or policy $\pi_{zx}$ collapses to single action, exploration ceases. Monitor via entropy coefficient ($10^{-5}$ in paper).
- **Generalization gap:** Training on 5-qubit random circuits; performance on structured 50-qubit circuits requires peephole partitioning. Direct application without partitioning will likely fail.

**First 3 experiments:**
1. **Reproduction on training distribution:** Generate 5-qubit circuits with CNOT/H/Rx/Rz ratio 0.6/0.2/0.1/0.1, 80 gates. Train agent from scratch. Target: match or exceed Table I baseline (27.3±4.7 CNOTs). Verify extraction level distribution.
2. **Ablation on tree search:** Replace tree-based selection with greedy (always expand best current node). Compare CNOT reduction on held-out circuits. Hypothesis: non-monotonic sequences will be missed, reducing performance.
3. **Rule subset sensitivity:** Train with only spider fusion + un-fusion (no bialgebra). Test on pure-CNOT circuits. Quantify performance gap from Table II (5.1±0.9). Assumption: bialgebra is critical for certain cancellations but may harm extractability.

## Open Questions the Paper Calls Out

### Open Question 1
Can an agent trained exclusively on small quantum circuits generalize effectively to optimize significantly larger circuits natively? The authors state they expect GNN generalization capabilities to allow "training on a small graph but optimizing circuits of much larger size," noting this as a focus for future work. Current experiments on large 50-qubit circuits rely on peephole optimization (partitioning large circuits into small sub-circuits) rather than end-to-end optimization by the agent.

### Open Question 2
Does access to the complete set of ZX-calculus transformation rules yield better optimization results than the restricted subset used in this study? Section V notes that "the agent did not have access to the complete set of transformations" and that extending the agent to access the "complete set of ZX transformation rules" is necessary to find near-optimal solutions. The authors limited the rule set to ensure convergence and minimize action space, leaving the trade-off between rule completeness and learning stability unexplored.

### Open Question 3
How can the inference speed of neural tree-search schemes be optimized to make them practical for standard compilation pipelines? Section IV-E concludes that while their method performs best, "it is also the slowest optimization algorithm," stating that "optimizing inference speed for neural tree-search schemes, such as ours, remains an open problem." The computational overhead of maintaining a search tree and running GNN inference repeatedly currently outweighs the speed of heuristic methods like PyZX or Qiskit.

### Open Question 4
Can the framework be successfully adapted to minimize metrics other than CNOT count, such as T-count or routing depth? Section V states that the current focus on two-qubit gates "can be adapted towards other optimization goals such as T-count minimization and routing." The current reward function (Eq. 10) is explicitly defined as maximizing the reduction of CNOT gates, and the agent's behavior is shaped specifically around the extraction challenges related to two-qubit gates.

## Limitations

- **Incomplete ZX-calculus rule set:** The agent uses a restricted subset of 6 rules, limiting its ability to find globally optimal solutions for circuits requiring more complex transformations
- **Scalability trade-offs:** For 50-qubit circuits, the paper replaces GNN with MLP using handcrafted features, sacrificing position-awareness for computational efficiency
- **Computational overhead:** Neural tree-search approach is significantly slower than standard heuristic optimizers, limiting practical deployment in compilation pipelines

## Confidence

- **Learning arbitrary circuit optimization rules:** Medium confidence - demonstrates strong performance on training distribution but restricted rule subset limits general applicability
- **Tree search enables non-monotonic optimization:** High confidence - explicitly designed for backtracking and validated through ablation experiments
- **Strong generalization:** Medium confidence - achieves better CNOT reduction but absolute counts remain higher than specialized optimizers on specific circuit types
- **Scalability to large circuits:** High confidence for peephole approach, but architectural changes (GNN→MLP) represent significant modifications

## Next Checks

1. Implement and validate the feature engineering for GNN inputs by testing on circuits where rule applicability is known (e.g., verify the model can identify spider fusion opportunities)
2. Reproduce the core results on the training distribution (5-qubit, 80 gates, specified ratios) and verify extraction level statistics match reported values
3. Conduct ablation studies removing the tree search component to quantify the performance gain from non-monotonic optimization paths