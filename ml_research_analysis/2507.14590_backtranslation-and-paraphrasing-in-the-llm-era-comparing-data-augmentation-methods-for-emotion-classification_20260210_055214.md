---
ver: rpa2
title: Backtranslation and paraphrasing in the LLM era? Comparing data augmentation
  methods for emotion classification
arxiv_id: '2507.14590'
source_url: https://arxiv.org/abs/2507.14590
tags:
- data
- augmentation
- dataset
- backtranslation
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates data augmentation techniques for emotion
  classification in low-resource settings using large language models. It compares
  traditional methods like backtranslation and paraphrasing with modern LLM-based
  generation approaches on the GoEmotions dataset.
---

# Backtranslation and paraphrasing in the LLM era? Comparing data augmentation methods for emotion classification

## Quick Facts
- arXiv ID: 2507.14590
- Source URL: https://arxiv.org/abs/2507.14590
- Reference count: 37
- LLM-based data augmentation improves emotion classification for underrepresented classes

## Executive Summary
This paper investigates data augmentation techniques for emotion classification in low-resource settings using large language models. The study compares traditional methods like backtranslation and paraphrasing with modern LLM-based generation approaches on the GoEmotions dataset. Four augmentation strategies were tested: oversampling, GPT-based paraphrasing, zero/few-shot generation, and backtranslation using multiple translation models. Results show that all methods improved classification performance, with backtranslation yielding the highest gains, especially using DeepL.

## Method Summary
The authors fine-tuned LaBSE and DistilBERT models on GoEmotions dataset with five underrepresented emotion classes (embarrassment, nervousness, relief, pride, grief). They implemented four augmentation methods: (1) Oversampling 3x, (2) GPT-based paraphrasing with iterative prompting, (3) Zero-shot and few-shot generation, and (4) Backtranslation using DeepL, GPT-4-turbo, and MarianMT across 10 pivot languages. Models were evaluated using F1-macro, F1-micro, lexical diversity metrics (Jaccard, TTR, entropy), and semantic fidelity metrics (BERTScore, cosine similarity).

## Key Results
- Backtranslation using DeepL achieved the highest performance gains across all evaluation metrics
- LLM paraphrasing with GPT-4 significantly boosted F1 scores for underrepresented emotion classes
- Zero/few-shot generation showed no significant difference in performance between 0-shot and 5-shot learning
- All augmentation methods improved classification performance compared to baseline oversampling

## Why This Works (Mechanism)

### Mechanism 1: Backtranslation for Semantic Fidelity and Lexical Diversity
Backtranslation converts text into a pivot language and back, forcing structural reformulation while preserving meaning. When using diverse pivot languages (e.g., Japanese, Polish, Finnish), this creates manifold valid variations for minority class samples without hallucinating off-topic content. The core assumption is that high-quality translation models preserve emotional nuance during round-trip translation, and structural variations improve generalization.

### Mechanism 2: LLM Paraphrasing for Decision Boundary Expansion
LLM paraphrasing generates new points along the same decision boundary rather than copying samples, forcing the classifier to learn robust features. GPT-4 demonstrated higher Jaccard dissimilarity than GPT-3.5, indicating better lexical diversity. This prevents the model from memorizing specific points and relying on spurious correlations found in original examples.

### Mechanism 3: Zero/Few-Shot Generation for In-Context Regularization
Generating synthetic examples via ZSL/FSL learning leverages the LLM's pre-trained emotional knowledge to regularize the downstream classifier. This method injects the LLM's pre-training distribution into the specialized dataset, effectively smoothing the data distribution for extremely scarce classes.

## Foundational Learning

- **Semantic Fidelity vs. Lexical Diversity**: Understanding this tradeoff is essential for interpreting results. High Jaccard dissimilarity alone doesn't guarantee better performance if semantic fidelity is lost.

- **Multi-Label Imbalance (Long-Tail Distribution)**: GoEmotions has 27 labels with severe class imbalance. Standard accuracy metrics are useless; Macro-F1 is required to measure performance on tail classes.

- **Transformer Embedding Spaces (LaBSE/DistilBERT)**: Augmentation works by populating sparse regions of the vector space these models use to separate emotions. Different model architectures may show different sensitivity to augmented data noise.

## Architecture Onboarding

- **Component map**: Source Selector -> Augmentation Engine (BT Path, Gen Path) -> Evaluator (Lexical Diversity, Semantic Fidelity) -> Trainer (Fine-tune DistilBERT/LaBSE) -> Tester (F1-macro comparison)
- **Critical path**: Quality of Backtranslation pivot selection and Paraphrasing prompt design determine if augmented data is signal or noise
- **Design tradeoffs**: DeepL vs. GPT-4 for BT (DeepL better for fidelity), Paraphrasing vs. Generation (Paraphrasing safer, Generation more creative)
- **Failure signatures**: Semantic drift (BERTScore < 0.75), repetitive overfitting (low TTR), correlation bleed between similar emotions
- **First 3 experiments**: 1) Baseline sanity check with Oversampling 3x, 2) DeepL Backtranslation with single language, 3) Semantic Fidelity Threshold Test with GPT-4 Paraphrasing

## Open Questions the Paper Calls Out

The authors identify several areas for future research: evaluating methods using different models and datasets beyond GoEmotions (Reddit-only), using LLM-as-a-judge for evaluating generated text quality, and assessing the impact of LLM and in-context learning biases on data augmentation.

## Limitations

- Results may not generalize to datasets outside GoEmotions or to languages other than English
- API costs for LLM-based augmentation could be prohibitive for large-scale applications
- Exact prompt templates for GPT-based methods were not fully specified, making replication challenging

## Confidence

- **High Confidence**: DeepL backtranslation yields highest performance gains with clear statistical differences
- **Medium Confidence**: LLM paraphrasing advantage depends heavily on prompt engineering quality
- **Low Confidence**: Generalizability to other emotion classification datasets or different NLP tasks remains untested

## Next Checks

1. Cross-Dataset Validation: Test the same augmentation pipeline on at least two other emotion classification datasets (e.g., ISEAR, EmoBank) to assess generalizability

2. Domain Adaptation Test: Apply augmentation methods to non-social-media dataset (e.g., clinical text, product reviews) to evaluate performance on different linguistic characteristics

3. Cost-Effectiveness Analysis: Implement pilot comparing F1-macro gains against actual API costs for each method to determine best performance-to-cost ratio