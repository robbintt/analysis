---
ver: rpa2
title: Phase Transitions for Feature Learning in Neural Networks
arxiv_id: '2602.01434'
source_url: https://arxiv.org/abs/2602.01434
tags:
- lemma
- learning
- have
- page
- hard
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies feature learning in neural networks through
  the lens of multi-index models. The authors analyze when two-layer neural networks
  can learn low-dimensional representations by studying the spectrum of the Hessian
  along the gradient descent trajectory.
---

# Phase Transitions for Feature Learning in Neural Networks

## Quick Facts
- arXiv ID: 2602.01434
- Source URL: https://arxiv.org/abs/2602.01434
- Reference count: 40
- This paper studies feature learning in neural networks through the lens of multi-index models, identifying a threshold δ_NN in sample complexity that controls when networks can learn latent low-dimensional representations.

## Executive Summary
This paper provides a rigorous analysis of when two-layer neural networks can learn latent low-dimensional representations through feature learning. The authors identify a sample complexity threshold δ_NN determined by the emergence of negative outlier eigenvalues in the Hessian of the empirical risk along the gradient descent trajectory. For δ > δ_NN, these outliers enable learning of "hard" directions in the latent space; for δ < δ_NN, such learning is impossible. The analysis explains the grokking phenomenon as arising from delayed learning of these hard directions, where generalization error first increases then decreases.

## Method Summary
The authors analyze two-layer neural networks trained on multi-index models y = h(Θ*ᵀx, ε) using full-batch gradient descent. They employ dynamical mean field theory (DMFT) to characterize the high-dimensional limit of gradient descent trajectories at any finite time t. The Hessian spectrum is then analyzed to identify outlier eigenvalues that emerge from the bulk at a critical threshold δ_NN. The outlier equation involves the Stieltjes transform of the bulk spectrum and determines both the location and alignment of these eigenvalues with the latent subspace.

## Key Results
- A sample complexity threshold δ_NN exists, determined by BBP-type spectral transitions in the Hessian along the gradient descent trajectory.
- For δ > δ_NN, negative outlier eigenvalues emerge from the bulk spectrum, enabling feature learning of "hard" directions; for δ < δ_NN, no such outliers exist.
- The grokking phenomenon (delayed generalization) emerges when δ > δ_NN but the spectral gap is small, causing slow convergence to hard-direction alignment.
- The threshold δ_NN is generally suboptimal compared to optimal spectral algorithms, creating a gap δ_NN - δ_alg.

## Why This Works (Mechanism)

### Mechanism 1: Two-Phase Feature Learning via Gradient-to-Hessian Dynamics
- Claim: Gradient descent learns latent features in two distinct phases—easy directions first (via gradient flow), hard directions second (via Hessian curvature).
- Mechanism: Training initially visits parameter regions where the empirical risk gradient is large; these gradients span the "easy" latent subspace, enabling learning in O(1) steps. Once the gradient diminishes, dynamics become dominated by negative Hessian eigenvalues aligned with the "hard" subspace, enabling escape from the resulting saddle point.
- Core assumption: The latent space can be decomposed into "easy" (gradient-detectable) and "hard" (curvature-detectable) subspaces; gradient descent trajectory reaches a saddle near the easy subspace before curvature-driven learning activates.
- Evidence anchors:
  - [abstract] "Gradient descent first visits points for which the gradient of the empirical risk is large and learns the directions spanned by these gradients. Then the gradient becomes smaller and the dynamics becomes dominated by negative directions of the Hessian."
  - [Section 1.1.1] "hard directions cannot be learned in O(1) time"
  - [corpus] Related work on saddle-to-saddle dynamics (ABAM23) supports two-phase learning but does not provide spectral threshold characterizations.
- Break condition: If the hard subspace dimension is zero (all directions are easy), the second phase disappears; if δ < δ_NN, no negative Hessian outliers emerge and hard directions remain unlearned.

### Mechanism 2: Spectral Phase Transition at δ_NN Controls Feature Learning Threshold
- Claim: A sample complexity threshold δ_NN exists, determined by a BBP-type spectral transition in the Hessian, above which hard directions become learnable and below which they do not.
- Mechanism: After t=O(1) gradient steps, the Hessian H_j(t) = (1/n) Σ_i g(Θ(t)ᵀx_i, y_i; j) x_i x_iᵀ has a bulk spectrum following a generalized Marchenko-Pastur law. For δ > δ_NN, outlier eigenvalues emerge below the bulk's left edge, with corresponding eigenvectors correlated with the hard subspace; for δ < δ_NN, no such outliers exist.
- Core assumption: The DMFT process converges to a stationary distribution (Assumption 3); the outlier equation det(-zI + E[δG/(δ+Gα(z)) V* V*ᵀ]) = 0 has a real negative solution only when δ exceeds the threshold.
- Evidence anchors:
  - [abstract] "The threshold δ_NN is determined by outlier eigenvalues emerging from the bulk spectrum"
  - [Section 2.5] Theorem 1 provides explicit outlier equations and eigenvector alignment formulas
  - [corpus] "Overparametrization bends the landscape" (arXiv:2510.18435) discusses BBP transitions at initialization but not along GD trajectories; this work extends spectral analysis to dependent data settings.
- Break condition: If the activation function σ'' is uniformly zero (e.g., ReLU at initialization), the Hessian loses the critical curvature term, breaking the outlier mechanism.

### Mechanism 3: Grokking Emerges from Delayed Hard-Direction Learning
- Claim: The "grokking" phenomenon (delayed generalization) occurs when δ > δ_NN but the spectral gap is small; the network first overfits, then abruptly learns hard directions, causing a sudden test error drop.
- Mechanism: For δ moderately above δ_NN, the outlier eigenvalue z* is close to the bulk edge c(t), yielding a small spectral gap. Power iteration on the Hessian (implicit in gradient descent dynamics) converges slowly when the gap is small, delaying hard-direction learning. Once alignment occurs, generalization error drops rapidly.
- Core assumption: Gradient descent on longer timescales (t ≫ O(1)) behaves like a spectral method that computes low-lying Hessian eigenvectors; this hypothesis is supported numerically but not rigorously proven.
- Evidence anchors:
  - [Section 3.2] "We observe grokking for δ > δ_NN... The training time required for the drop in generalization error increases as δ ↓ δ_NN"
  - [Figure 2] Shows training/test risk divergence followed by alignment drop at t ≈ 80 for δ=17.5
  - [corpus] Grokking was empirically observed in [PBE+22] but lacked theoretical explanation; this work provides a quantitative mechanistic account.
- Break condition: If δ ≫ δ_NN, the spectral gap is large, hard-direction learning occurs rapidly, and grokking disappears (uniform convergence bounds dominate).

## Foundational Learning

- Concept: **Multi-index models and latent subspace recovery**
  - Why needed here: The paper studies learning y = h(Θ*ᵀx, ε) where Θ* ∈ ℝ^{d×k} with k≪d; understanding "weak recovery" of Θ*'s column space is the central object.
  - Quick check question: Given isotropic x ~ N(0,I_d) and y depending only on a k-dimensional projection, what is the minimum sample complexity to estimate that subspace with non-trivial correlation?

- Concept: **Spectral methods and BBP transitions**
  - Why needed here: The Hessian outlier analysis reduces to detecting a spiked structure in XᵀDX where D depends on training; the Baik–Ben Arous–Péché transition characterizes when signal eigenvalues detach from noise bulk.
  - Quick check question: For a sample covariance matrix (1/n) XᵀX with X ∈ ℝ^{n×d}, what happens to the largest eigenvalue when n/d → δ and a rank-1 signal is added?

- Concept: **Dynamical Mean Field Theory (DMFT)**
  - Why needed here: DMFT provides the exact high-dimensional limit of gradient descent at any finite t, enabling tractable analysis of the Hessian along the trajectory.
  - Quick check question: How does DMFT reduce the description of (Θ(0),...,Θ(t)) from dimension O(md) to O(m²t) while preserving all relevant correlations?

## Architecture Onboarding

- Component map:
  - Data generator -> Two-layer network -> Training loop -> Analysis pipeline
  - x_i ~ N(0, I_d), y_i = h(Θ*ᵀx_i, ε_i) -> f_Θ(x) = (1/m) Σ_j a_j σ(θ_jᵀx + b_j) -> Full-batch GD on empirical risk -> DMFT → Hessian spectrum → Outlier equation → Threshold δ_NN(t)

- Critical path:
  1. Run DMFT simulation to obtain (V(t), Θ(t), G_t, α_t(z)) for t = 0,1,...,T
  2. For each t, compute bulk left edge c(t) via edge equation (38)
  3. For each t and candidate δ, solve outlier equation (39) for z < min(c(t), 0)
  4. Identify δ*(t) as the infimum δ where a negative outlier exists
  5. Extrapolate δ*(∞) from sequence {δ*(t)} (e.g., polynomial fit in 1/t)

- Design tradeoffs:
  - **Activation choice**: σ'' ≠ 0 required (e.g., GeLU, Quad); ReLU requires nonzero bias to provide curvature
  - **Loss function**: Huber loss ensures bounded ℓ' and ℓ'', preventing unbounded bulk support
  - **Width m**: Lemma 2.3 shows block-diagonal approximation is accurate for m ≫ 1; small m requires direct Hessian analysis
  - **Initialization**: Random uniform on sphere; spectral initialization can lower threshold but is suboptimal for δ_alg < δ < δ_NN

- Failure signatures:
  - **No phase transition observed**: δ < δ_NN (increase samples), or σ'' ≈ 0 (change activation/bias)
  - **Grokking too slow to observe**: δ close to δ_NN (increase δ), or dimension d too small (DMFT approximation degrades)
  - **Outlier equation has no solution**: Check that z < min(c(t), 0) condition is satisfied; may need to increase t

- First 3 experiments:
  1. **Phase transition curve**: For fixed d ∈ {1000, 2000, 4000}, vary n to cover δ ∈ [1, 15], run GD to convergence (or max 1000 steps), compute final correlation ρ(T) = |⟨θ(T), θ*⟩|/||θ(T)||; plot success rate (ρ≥0.5) vs δ; expect sigmoid transition at δ ≈ δ_NN (match Figure 4).
  2. **Grokking dynamics**: Fix d=5000, δ=10 (above predicted δ_NN≈6), track ρ(t), train risk, test risk over t ∈ [0, 500]; expect overfitting phase (train↓, test→) followed by alignment drop and test↓; verify time-to-grokking increases as δ → δ_NN.
  3. **DMFT threshold computation**: Implement discrete DMFT recursion (22)-(25) with Monte Carlo for expectations; for each t ∈ {0,...,25}, binary search for δ*(t) where outlier equation first has solution; fit δ*(∞) via polynomial in 1/t; compare empirical transition to predicted δ_NN (validate Figure 6).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the connection between the spectral phase transition at δ_NN(∞) and gradient descent dynamics on timescales t ≳ log d be made rigorous?
- **Basis in paper:** [explicit] The authors state this as problem (i) in Section 6, noting that the connection is currently a hypothesis supported by numerical simulations but lacks mathematical proof.
- **Why unresolved:** Proving this requires analyzing dynamics beyond t = O(1), where the discrete-time DMFT characterization no longer applies directly.
- **What evidence would resolve it:** A rigorous proof showing GD dynamics follow saddle-point escape governed by the Hessian spectral properties characterized in Theorems 1 and 2.

### Open Question 2
- **Question:** Does the gap δ_NN − δ_alg between the neural network threshold and optimal algorithmic threshold vanish as network width m → ∞?
- **Basis in paper:** [inferred] Section 3.4 discusses suboptimality of the neural network preprocessing compared to optimal spectral methods, and Appendix E shows phase transition thresholds shift with width, but the limiting behavior remains unknown.
- **Why unresolved:** Lemma 2.3's reduction to block-diagonal form assumes m large after n,d → ∞, but the dependence of δ_NN on m is not fully characterized.
- **What evidence would resolve it:** Theoretical characterization of δ_NN as a function of m, or empirical studies showing convergence to δ_alg as m increases proportionally with dimension.

### Open Question 3
- **Question:** How do non-Gaussian or non-isotropic covariate distributions interact with the latent subspace structure in determining δ_NN?
- **Basis in paper:** [explicit] Listed as problem (iii) in Section 6, where authors note importance of understanding interplay between structure in h and structure in the covariates.
- **Why unresolved:** The analysis relies heavily on Gaussian conditioning (Section 5.1) and rotation invariance of the covariate distribution.
- **What evidence would resolve it:** Extension of the DMFT framework to structured covariates, or empirical studies of phase transitions under correlated/non-Gaussian data.

## Limitations
- The analysis assumes isotropic Gaussian inputs and additive noise models, limiting generalizability to real-world datasets with correlations and structured features.
- The threshold δ_NN is computed for a specific class of two-layer networks; extensions to deeper architectures or convolutional networks require new theoretical tools.
- The gap δ_NN − δ_alg between the neural network threshold and optimal algorithmic threshold indicates suboptimal feature learning in certain regimes.

## Confidence
- **High confidence**: Mechanism 1 (Two-Phase Feature Learning) - supported by explicit DMFT trajectory analysis and alignment formulas.
- **Medium confidence**: Mechanism 2 (Spectral Phase Transition) - supported by rigorous BBP-type analysis but depends on DMFT assumptions.
- **Low confidence**: Mechanism 3 (Grokking) - empirical observation with mechanistic explanation but lacks formal proof of gradient descent behaving as spectral method.

## Next Checks
1. **Convergence of DMFT**: For different activation functions (ReLU, GeLU, Quad), verify numerically that the DMFT process reaches a stationary distribution by checking that the overlap matrix Q(t) and auxiliary variables stabilize over t.
2. **Eigenvector Alignment Scaling**: For fixed d=5000, vary δ from δ_NN to 2δ_NN, compute the correlation between the outlier eigenvector and the hard subspace as a function of the spectral gap z*-c(t); test if alignment time scales as 1/(z*-c(t)) as predicted by power iteration analysis.
3. **Beyond Isotropic Data**: Repeat the phase transition experiment with x_i drawn from a spiked covariance model (with low-rank structure) to test if the theoretical threshold δ_NN predicts the onset of feature learning in non-isotropic settings.