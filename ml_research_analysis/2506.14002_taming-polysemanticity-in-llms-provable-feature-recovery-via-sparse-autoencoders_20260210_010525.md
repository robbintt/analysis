---
ver: rpa2
title: 'Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders'
arxiv_id: '2506.14002'
source_url: https://arxiv.org/abs/2506.14002
tags:
- lemma
- feature
- have
- proof
- neuron
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the problem of feature recovery in Large Language
  Models (LLMs) using Sparse Autoencoders (SAEs), addressing the lack of rigorous
  theoretical guarantees and practical limitations such as hyperparameter sensitivity
  in existing methods. The authors introduce a novel statistical framework modeling
  polysemantic features as sparse mixtures of monosemantic concepts, along with a
  new notion of feature identifiability.
---

# Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders

## Quick Facts
- **arXiv ID**: 2506.14002
- **Source URL**: https://arxiv.org/abs/2506.14002
- **Reference count**: 40
- **Primary result**: First SAE algorithm with theoretical recovery guarantees for monosemantic feature extraction from polysemantic LLM activations

## Executive Summary
This paper addresses the critical challenge of feature recovery in Large Language Models (LLMs) using Sparse Autoencoders (SAEs), introducing both theoretical guarantees and practical algorithms. The authors develop a novel statistical framework that models polysemantic features as sparse mixtures of monosemantic concepts, along with a new notion of feature identifiability. They propose the Group Bias Adaptation (GBA) algorithm, which adaptively adjusts neural network bias parameters to enforce appropriate activation sparsity, overcoming limitations of traditional ℓ1 regularization and TopK activation methods. The work provides the first provably convergent SAE algorithm for recovering all monosemantic features under their statistical model assumptions.

## Method Summary
The paper introduces a statistical framework modeling polysemantic features as sparse mixtures of monosemantic concepts, establishing a new notion of feature identifiability. Building on this foundation, the authors propose the Group Bias Adaptation (GBA) algorithm, which adaptively adjusts bias parameters in the autoencoder to achieve desired activation sparsity without the drawbacks of ℓ1 regularization or TopK activation methods. GBA's adaptive bias adjustment mechanism enforces sparsity while maintaining reconstruction quality, and the algorithm is proven to recover all monosemantic features when input data follows the proposed statistical model. The method is evaluated on LLMs up to 1.5 billion parameters, demonstrating superior performance in reconstruction quality, activation sparsity, and feature consistency compared to benchmark methods.

## Key Results
- GBA provably recovers all monosemantic features under the statistical model assumptions
- Achieves superior reconstruction quality compared to existing SAE methods on LLMs up to 1.5 billion parameters
- Demonstrates improved activation sparsity and feature consistency over benchmark approaches

## Why This Works (Mechanism)
The Group Bias Adaptation algorithm works by dynamically adjusting the bias parameters of the autoencoder's activation function to achieve the desired sparsity level. Unlike ℓ1 regularization which can lead to biased feature weights, or TopK activation which may not capture the true sparsity structure, GBA adapts the bias during training to naturally enforce sparsity while preserving feature recovery. This adaptive mechanism ensures that the autoencoder learns to activate only the most relevant features for each input, effectively separating polysemantic activations into their constituent monosemantic components. The theoretical framework establishes conditions under which this adaptation leads to provably correct feature recovery.

## Foundational Learning

**Polysemantic vs Monosemantic Features**: Polysemantic features correspond to multiple distinct concepts in LLM activations, while monosemantic features represent single concepts. Understanding this distinction is crucial for feature recovery because SAEs aim to decompose polysemantic activations into interpretable monosemantic components.

**Sparse Autoencoder Training**: SAEs learn sparse representations by reconstructing input activations through a bottleneck architecture. Traditional training uses ℓ1 regularization or activation thresholding, but these methods can introduce biases or fail to capture true sparsity patterns in LLM activations.

**Feature Identifiability**: This concept ensures that the learned features can be uniquely mapped back to the underlying concepts in the data. Without proper identifiability conditions, SAEs might learn arbitrary representations that don't correspond to meaningful features in the LLM.

**Statistical Mixture Models**: The paper models polysemantic features as sparse mixtures of monosemantic concepts, similar to how topic models represent documents as mixtures of topics. This framework provides the theoretical foundation for proving feature recovery guarantees.

**Adaptive Bias Adjustment**: Instead of using fixed regularization parameters, GBA dynamically adjusts bias terms during training to achieve target sparsity. This approach is more flexible than traditional methods and can better adapt to the varying activation patterns in LLM representations.

## Architecture Onboarding

**Component Map**: Input Activations -> GBA Encoder -> Sparse Code -> GBA Decoder -> Reconstructed Activations

**Critical Path**: The key computational path involves encoding the input through the GBA-adjusted encoder, applying the sparsity-enforcing mechanism via adaptive bias, and reconstructing through the decoder. The bias adaptation occurs during both encoding and decoding phases.

**Design Tradeoffs**: GBA trades off computational overhead from adaptive bias updates against improved feature recovery quality. Unlike ℓ1 regularization which adds constant computational cost, GBA's adaptive mechanism requires additional computation but achieves better theoretical guarantees and empirical performance.

**Failure Signatures**: The algorithm may fail when the statistical assumptions about feature mixtures don't hold, or when the adaptive bias mechanism cannot find appropriate bias values for the target sparsity. Additionally, extreme sparsity targets might lead to poor reconstruction quality.

**First Experiments**: 1) Compare reconstruction error curves for GBA vs ℓ1 regularization on synthetic polysemantic data with known ground truth. 2) Analyze feature activation histograms before and after GBA bias adaptation to verify sparsity enforcement. 3) Test GBA's sensitivity to initial bias values and learning rates on small-scale LLM activations.

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical guarantees rely on idealized assumptions about feature mixture models that may not capture real-world LLM activation complexity
- Scalability to extremely large models (100B+ parameters) remains untested and could face computational challenges
- The adaptive bias mechanism introduces additional computational overhead compared to traditional SAE training methods

## Confidence
**High**: The theoretical framework for feature identifiability and GBA algorithm are rigorously defined and analyzed under specific statistical assumptions. Empirical results show clear improvements over existing methods on moderate-sized LLMs.

**Medium**: Practical applicability of theoretical guarantees to diverse real-world LLM activation patterns given idealized model assumptions. Scalability of GBA to much larger models and its computational efficiency in large-scale settings.

**Low**: Direct impact of GBA on broader interpretability goals beyond specific evaluation metrics used, such as utility in mechanistic interpretability tasks or contribution to AI transparency.

## Next Checks
1. Test GBA on larger LLMs (e.g., 10B+ parameters) to assess scalability and robustness to more complex activation patterns
2. Evaluate GBA's computational overhead and efficiency compared to traditional SAE training methods in large-scale settings
3. Investigate the utility of features recovered by GBA in downstream mechanistic interpretability tasks, such as causal interventions or circuit analysis