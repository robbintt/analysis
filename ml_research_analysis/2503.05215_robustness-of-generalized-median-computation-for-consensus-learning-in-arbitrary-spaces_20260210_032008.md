---
ver: rpa2
title: Robustness of Generalized Median Computation for Consensus Learning in Arbitrary
  Spaces
arxiv_id: '2503.05215'
source_url: https://arxiv.org/abs/2503.05215
tags:
- distance
- median
- objects
- metric
- weighted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the robustness of generalized median (GM) computation\
  \ for consensus learning in arbitrary spaces. The main contributions include proving\
  \ that GM has a breakdown point \u2265 0.5 for metric distance functions, and providing\
  \ bounds on the maximum displacement of the GM in case of outliers."
---

# Robustness of Generalized Median Computation for Consensus Learning in Arbitrary Spaces

## Quick Facts
- arXiv ID: 2503.05215
- Source URL: https://arxiv.org/abs/2503.05215
- Reference count: 40
- Primary result: GM computation has breakdown point ≥ 0.5 for metric distance functions with theoretical displacement bounds

## Executive Summary
This paper establishes theoretical foundations for the robustness of generalized median (GM) computation in consensus learning tasks across arbitrary spaces. The authors prove that GM has a breakdown point of at least 0.5 for metric distance functions, providing upper bounds on median displacement when outliers are present. The work addresses a critical gap in understanding how GM behaves under adversarial conditions, offering practical guidance for avoiding non-robust computation. Through theoretical analysis and experiments on 3D rotation and ranking averaging, the paper demonstrates that GM remains stable under moderate outlier contamination.

## Method Summary
The paper analyzes GM computation by establishing theoretical bounds on robustness through breakdown point analysis and displacement measures. The method involves computing the median of a dataset under metric distance functions and comparing it to the median of corrupted datasets with added or replaced outliers. For synthetic experiments, the authors generate base datasets (3D rotations and rankings), introduce k outliers, and compute both GM and mean-based solutions. The displacement between original and corrupted medians is measured and compared against theoretical bounds from Theorems 2 and 3. The approach uses gradient descent for rotation median optimization and enumeration for small ranking spaces.

## Key Results
- GM has breakdown point ≥ 0.5 for metric distance functions
- Upper bound on GM displacement: δ(ō, q̄) ≤ 2/(n-k)Ω_O(ō) for added outliers
- Upper bound on sum of distance difference: Ω_Q(ō) - Ω_Q(q̄) < 2k/(n-k)Ω_O(ō) for added outliers

## Why This Works (Mechanism)
None

## Foundational Learning

**Metric Space Properties**: Distance functions must satisfy non-negativity, symmetry, and triangle inequality. Why needed: These properties enable the mathematical proofs of robustness bounds. Quick check: Verify distance function satisfies d(x,y) ≥ 0, d(x,y) = d(y,x), and d(x,z) ≤ d(x,y) + d(y,z).

**Breakdown Point Concept**: Maximum fraction of outliers that can be tolerated before estimator fails. Why needed: Provides theoretical guarantee of robustness limits. Quick check: Calculate k < ⌊(n-1)/2⌋ for metric GM to ensure breakdown point ≥ 0.5.

**Kendall-Tau Distance**: Counts pairwise disagreements between rankings. Why needed: Specific metric for ranking consensus problems. Quick check: For permutations of length m, distance ranges from 0 to m(m-1)/2.

## Architecture Onboarding

**Component Map**: Dataset generation -> Outlier injection -> GM computation -> Median comparison -> Bound verification

**Critical Path**: Generate clean dataset → Introduce k outliers → Compute GM via optimization → Measure displacement → Compare against theoretical bounds

**Design Tradeoffs**: Using metric δ for GM vs non-metric δ² for mean enables fair comparison but limits analysis to specific distance function classes. The choice of small n=21 datasets enables exhaustive computation but may not scale to real-world scenarios.

**Failure Signatures**: Bound violations indicate either non-metric distance functions being used, k ≥ ⌊(n-1)/2⌋, or outlier clustering effects not captured by theory.

**First Experiments**:
1. Generate 3D rotations with varying noise levels (σ = 0.1, 0.5, 1.0) and verify displacement bounds
2. Test ranking GM with different base rankings (uniform, skewed distributions)
3. Compare GM vs RANSAC on synthetic datasets with known outlier rates

## Open Questions the Paper Calls Out

**Open Question 1**: Can the breakdown point for generalized median exceed 0.5 for non-trivial special metric distance functions? The authors' general proof establishes ≥0.5 but leaves open whether tighter bounds exist for specific metric structures.

**Open Question 2**: How can robustness be characterized for non-metric distance functions beyond the powered distance class (δp)? The paper only analyzes δp (powered distances) for non-metric cases; other non-metric functions remain unexplored.

**Open Question 3**: What algorithms can reduce or ideally eliminate outlier influence on GM computation beyond the displacement bounds established? The paper provides theoretical bounds but does not propose algorithms that achieve tighter practical robustness.

**Open Question 4**: Under what additional conditions can weighted GM robustness be guaranteed when the weight assumption (Σwp < Σwx) is violated? The sufficient condition for weighted GM robustness is known, but necessary conditions or alternative guarantees are not characterized.

## Limitations

- Theoretical bounds may become looser in higher dimensions or with non-uniform outlier distributions
- Empirical validation limited to small-scale synthetic examples (n=21 objects)
- Analysis assumes outliers are detectable through distance metrics, which may not hold in practice
- Results specific to metric distance functions, with limited treatment of non-metric cases

## Confidence

**Theoretical Results**: High - Mathematical proofs are rigorous and peer-reviewed
**Empirical Validation**: Medium - Small sample sizes, limited to specific domains
**Practical Applicability**: Low-Medium - Real-world datasets often violate assumptions of symmetry and outlier detectability

## Next Checks

1. Test bound tightness across varying dimensions (d=3→10→50) for rotation averaging to assess scaling behavior
2. Validate displacement bounds when outliers form clusters rather than isolated points
3. Benchmark against established robust estimators (RANSAC, M-estimators) on real-world datasets with known outlier rates