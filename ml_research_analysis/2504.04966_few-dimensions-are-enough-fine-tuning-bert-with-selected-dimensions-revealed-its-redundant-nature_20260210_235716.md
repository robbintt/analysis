---
ver: rpa2
title: 'Few Dimensions are Enough: Fine-tuning BERT with Selected Dimensions Revealed
  Its Redundant Nature'
arxiv_id: '2504.04966'
source_url: https://arxiv.org/abs/2504.04966
tags:
- dimensions
- test
- layers
- valid
- dimension
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the redundancy and effectiveness of token
  vectors, layers, and dimensions in BERT models during fine-tuning on GLUE tasks.
  The authors evaluated whether token vectors other than the CLS vector, subsets of
  dimensions, or outputs from hidden layers could match the performance of the standard
  fine-tuning approach.
---

# Few Dimensions are Enough: Fine-tuning BERT with Selected Dimensions Revealed Its Redundant Nature

## Quick Facts
- arXiv ID: 2504.04966
- Source URL: https://arxiv.org/abs/2504.04966
- Reference count: 40
- Key result: Most GLUE tasks require only 2-3 dimensions from BERT's final layer for comparable performance to full fine-tuning

## Executive Summary
This study investigates redundancy in BERT's architecture by evaluating whether token vectors other than CLS, subsets of dimensions, or outputs from hidden layers can match standard fine-tuning performance. Results show that max-pooling token selection performs similarly to CLS across most tasks, using only 2-3 dimensions yields comparable accuracy, and outputs from certain hidden layers provide sufficient information for inference. The findings suggest BERT's parameter count may be excessive for many tasks and demonstrate that fine-tuning significantly modifies hidden layers while their redundancy enables adaptability to multiple tasks.

## Method Summary
The authors fine-tuned bert-base-uncased on GLUE tasks using standard procedures (dropout 0.1, learning rate 5e-5, batch size 64, max 5 epochs). They implemented three main experimental variations: token-wise max-pooling to replace CLS vector selection, dimension-wise experiments using DropConnect to mask unselected dimensions, and layer-wise selection from hidden layers. For dimension selection, they randomly sampled 2D/3D combinations from the 768D CLS vector and selected top-performing sets based on validation performance. Sequential fine-tuning experiments trained models on one task then another to assess cross-task adaptability.

## Key Results
- Max-pooling token selection matches CLS performance on 7/8 GLUE tasks
- Using only 2-3 dimensions from final layer achieves comparable accuracy to all 768 dimensions
- Outputs from certain hidden layers provide sufficient information for inference
- Sequential fine-tuning shows no degradation compared to direct training
- Freezing pretrained layers causes performance collapse on complex tasks

## Why This Works (Mechanism)

### Mechanism 1: Sparse Subnetwork Sufficiency
Task-specific decision boundaries for GLUE tasks can be reconstructed using only 2-3 dimensions of the final layer vector, suggesting the model operates on highly sparse "winning tickets" during inference. BERT's 768-dimensional space appears over-parameterized for specific downstream tasks, with gradient signal concentrating semantic relevance into small neuron subsets during fine-tuning.

### Mechanism 2: Contextual Token Aggregation Equivalence
The [CLS] token is not the exclusive carrier of sentence-level semantics; aggregate token signals can serve as functional equivalents. Self-attention distributes contextual information across the sequence, and max-pooling extracts highest magnitude activations across tokens, correlating with most salient features.

### Mechanism 3: Redundant Capacity Utilization in Sequential Adaptation
Sequential fine-tuning (Task A → Task B) does not degrade performance on Task B compared to direct fine-tuning, implying "forgetting" is mitigated by the model having enough redundant dimensions to overwrite old tasks without erasing capacity needed for new ones.

## Foundational Learning

- **Concept: The Lottery Ticket Hypothesis**
  - Why needed here: Explains why small subnetworks within BERT's dense parameters can learn tasks alone, accounting for 99% dimension removal without accuracy loss
  - Quick check question: If you randomly re-initialized weights of a "winning ticket" subnetwork, would it still perform well? (Answer: Generally no)

- **Concept: Max-Pooling**
  - Why needed here: Used as alternative to [CLS] token; selects maximum value across a set, capturing most activated feature regardless of position
  - Quick check question: How does Max-Pooling handle a feature spread evenly but weakly across all tokens?

- **Concept: Freezing vs. Fine-Tuning**
  - Why needed here: Contrasts frozen layers (features fixed) against standard fine-tuning; critical for interpreting results that BERT layers must adapt significantly during downstream tasks
  - Quick check question: If freezing layers caused performance to drop to near random, what does that imply about pre-trained features' direct applicability?

## Architecture Onboarding

- **Component map:** Input Text → Tokenizer → Transformer Layers (1-12) → Final Layer Output → Selection (Token/Dim) → Classifier Head

- **Critical path:** Input Text → Tokenizer → Transformer Layers (1-12) → Final Layer Output → Selection (Token/Dim) → Classifier Head

- **Design tradeoffs:**
  - CLS vs. MaxPool: Use MaxPool for robustness to token-position variations; CLS for standard pipeline compatibility
  - Dimension Selection: Searching for "Effective Dimensions" is computationally expensive but yields minimal footprint; random selection is cheap but ineffective
  - Freezing: Drastically reduces training time/compute but fails on complex tasks

- **Failure signatures:**
  - Frozen Backbone Collapse: Accuracy drops to <60% on complex tasks or random chance if backbone frozen with extra FC layer
  - RTE Performance Drop: MaxPooling fails to capture nuanced entailment signals required for RTE compared to CLS

- **First 3 experiments:**
  1. Dimension Scan: Fine-tune on SST-2, iterate inference using top 5 dimension pairs from CLS vector to verify sparsity claim
  2. Token Aggregation Test: Replace model.pooler output with torch.max(last_hidden_state, dim=1) operation and compare validation loss against CLS baseline
  3. Sequential Fine-tuning: Train on MNLI, save model, then train on QNLI, compare QNLI score against model trained on QNLI from scratch

## Open Questions the Paper Calls Out
- Does dimension-wise redundancy observed in BERT generalize to decoder-based architectures like GPT?
- Is the 2-3 dimension redundancy consistent across morphologically rich or non-English languages?
- What specific linguistic or syntactic features are encoded within the few effective dimensions identified?

## Limitations
- Sampling bias in effective dimensions: Low sampling rate (0.0001-0.1%) may not explore full search space
- Task-specificity of redundancy: Results may not generalize to more complex reasoning tasks beyond GLUE
- MaxPooling aggregation assumptions: Heuristic may not hold for tasks requiring precise relational understanding between sentence pairs

## Confidence
- **High Confidence**: CLS token performance matched by max-pooling on 7/8 GLUE tasks; 2-3 dimensions achieve comparable accuracy to all 768 dimensions
- **Medium Confidence**: Sequential fine-tuning results showing no degradation compared to direct training
- **Low Confidence**: Generalization claim that BERT's parameter count is "excessive for many tasks" based on GLUE results

## Next Checks
1. Perform ablation of sequential fine-tuning mechanism by testing tasks requiring conflicting representations in same dimensions
2. Test dimension-reduction approach on more complex reasoning tasks or generation tasks beyond GLUE
3. Compare performance using top 5 dimension sets found via sampling against 5 randomly selected dimension sets of same size for each task