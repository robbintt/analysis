---
ver: rpa2
title: Investigating an Overfitting and Degeneration Phenomenon in Self-Supervised
  Multi-Pitch Estimation
arxiv_id: '2506.23371'
source_url: https://arxiv.org/abs/2506.23371
tags:
- data
- training
- supervised
- music
- self-supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates a phenomenon in self-supervised multi-pitch
  estimation (MPE) where a model simultaneously overfits to supervised training data
  while degenerating on self-supervised data. The authors extend supervised MPE by
  incorporating self-supervised objectives based on pitch-invariant and pitch-equivariant
  properties, showing substantial improvements under closed training conditions.
---

# Investigating an Overfitting and Degeneration Phenomenon in Self-Supervised Multi-Pitch Estimation

## Quick Facts
- arXiv ID: 2506.23371
- Source URL: https://arxiv.org/abs/2506.23371
- Reference count: 0
- Primary result: Model simultaneously overfits to supervised data while degenerating on self-supervised data during joint training for multi-pitch estimation

## Executive Summary
This paper investigates a previously unreported phenomenon in self-supervised multi-pitch estimation where models trained with joint supervised and self-supervised objectives exhibit simultaneous overfitting to labeled data and degeneration on unlabeled data. The authors extend supervised MPE by incorporating self-supervised objectives based on pitch-invariant and pitch-equivariant properties, showing substantial improvements under closed training conditions. However, when applying these objectives to broader data without supervision, the model outputs blank predictions on the unlabeled data while maintaining performance on the supervised data, revealing a fundamental challenge in self-supervised polyphonic music processing.

## Method Summary
The method builds on a modified Timbre-Trap 2D autoencoder that processes harmonic constant-Q transform (HCQT) spectrograms to predict multi-pitch salience-grams. The model incorporates supervised binary cross-entropy loss with Gaussian-blurred targets, combined with self-supervised invariance and equivariance objectives. Training uses URMP dataset with additional self-supervision from NSynth, MusicNet, and FMA datasets. The architecture features 4 encoder/decoder blocks with dilated convolutions, residual connections, and layer normalization. Training employs AdamW optimizer with 2500 epochs, learning rate warmup, and gradient clipping, with validation checkpoint selection based on maximum F1-score on URMP validation set.

## Key Results
- Joint training with self-supervised objectives significantly improves supervised MPE performance under closed conditions (URMP only), achieving 80-90% F1 on GuitarSet
- When extending training to broader unlabeled data, the model degenerates to blank predictions on self-supervised data while maintaining performance on supervised data
- Energy-based objectives can prevent degeneration but introduce false positives that degrade overall performance
- Fine-tuning from pretrained weights does not resolve the degeneration phenomenon

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Joint training with self-supervised objectives improves supervised MPE when applied to the same data distribution.
- **Mechanism:** Invariance objectives (timbre, percussion) encourage the model to ignore non-pitch attributes, while equivariance objectives (geometric transformations) enforce consistent pitch representation under shifts. These provide explicit regularization signals that complement the supervised BCE loss.
- **Core assumption:** The HCQT representation preserves geometric relationships between pitch and frequency bins, enabling the model to learn equivariance efficiently.
- **Evidence anchors:**
  - [abstract] "This joint training results in a substantial improvement under closed training conditions"
  - [Section 3.3] "Combining the supervised objective with all invariance- and equivariance-based objectives produces the best performance... yields a significant improvement across all datasets"
  - [corpus] PESTO demonstrates equivariance objectives work for monophonic pitch estimation; this paper extends to polyphonic.

### Mechanism 2
- **Claim:** Self-supervised objectives on unlabeled data cause the model to collapse toward blank (trivial) predictions on that data while maintaining performance on supervised data.
- **Mechanism:** Without ground-truth anchoring, the model discovers that minimizing invariance/equivariance losses is easiest by outputting uniformly low salience values. The supervised loss keeps predictions alive only on the supervised distribution.
- **Core assumption:** The self-supervised losses alone do not contain sufficient signal to enforce content existence; they only enforce consistency.
- **Evidence anchors:**
  - [abstract] "model simultaneously overfits to the supervised data while degenerating on data used for self-supervision only"
  - [Section 4.1] "predictions degenerate to a trivial solution (blank predictions) for all datasets except for URMP"
  - [Section 4.3] "underlying issue is too strong of a pull towards the trivial solution for the non-supervised data"
  - [corpus] Related work on monophonic pitch estimation (PESTO, SPICE) uses categorical cross-entropy which naturally prevents collapse; polyphonic MPE lacks this protection.

### Mechanism 3
- **Claim:** Energy-based objectives can prevent degeneration but introduce false positives that degrade overall performance.
- **Mechanism:** The weighted harmonic average target (eX) provides a lower-bound signal for pitch activity, but contains many spurious activations. The sparsity loss (Lspr) attempts to compensate but the balance remains imperfect.
- **Core assumption:** A better energy-based stimulus could theoretically maintain non-trivial predictions without over-constraining the model.
- **Evidence anchors:**
  - [Section 2.3.2] "eX[k,n] by nature is quite coarse and contains many false alarms"
  - [Section 4.2] "energy-based objectives actually further degrade performance, likely due to conflicting with the supervised objective"
  - [corpus] Weak direct evidence; related self-supervised music models (MuQ, MERT) use contrastive objectives rather than energy-based approaches.

## Foundational Learning

- **Concept: Equivariance vs. Invariance**
  - **Why needed here:** The entire self-supervised framework depends on understanding that equivariance means "output transforms with input" (pitch shifting) while invariance means "output stays stable" (timbre changes).
  - **Quick check question:** If you transpose an audio signal up 5 semitones, should the model's output shift up or stay the same?

- **Concept: Harmonic CQT (HCQT) Representation**
  - **Why needed here:** The HCQT stacks harmonic frequencies across channels, creating a pitch-equivariant structure where vertical shifts correspond directly to pitch changes.
  - **Quick check question:** Why does the HCQT make geometric equivariance objectives easier to implement than standard spectrograms?

- **Concept: Trivial Solution / Model Collapse**
  - **Why needed here:** Self-supervised losses without grounding can be minimized by outputting constant values (blank predictions), a failure mode central to this paper's findings.
  - **Quick check question:** Why might a model output silence rather than attempting to predict pitch when only consistency objectives are present?

## Architecture Onboarding

- **Component map:**
  - Audio (22,050 Hz) -> HCQT extraction (6 harmonics, 440 bins, 5 bins/semitone) -> Encoder (4 blocks, dilated convs, residual connections) -> Latent space (conv + layer norm) -> Decoder (4 blocks, transposed convs) -> Multi-pitch salience-gram output

- **Critical path:**
  1. HCQT computation must preserve 5-bin-per-semitone resolution and harmonic indexing
  2. Self-supervised transformations (tiv, tev) applied at spectrogram level before model
  3. Loss aggregation: supervised averaged over labeled samples, SSL averaged over all samples
  4. Validation checkpoint selection based on maximum F1 on URMP validation set

- **Design tradeoffs:**
  - More self-supervised samples per batch -> stronger regularization but higher degeneration risk
  - Energy-based objectives -> prevent collapse but introduce false positive noise
  - Fine-tuning from pretrained weights -> does not resolve degeneration (paper-tested)
  - Wider supervised dataset -> untested but hypothesized to reduce distribution mismatch

- **Failure signatures:**
  - Blank/empty salience-gram outputs on specific datasets while others work correctly
  - High precision but very low recall (model being overly conservative)
  - Stable validation F1 on supervised data but collapsing F1 on evaluation datasets over training
  - Degeneration severity correlates with amount of self-supervised-only samples

- **First 3 experiments:**
  1. Reproduce the reference experiment (Ltotal on URMP only) to verify baseline F1 scores match Table 1 (~90% on Bach10, ~64% on Su)
  2. Add 16 additional samples per batch from a different dataset (e.g., MusicNet) with only self-supervised losses; monitor for blank prediction emergence
  3. Gradually reduce additional samples (16 → 8 → 4 → 2) to confirm relationship between sample count and degeneration severity observed in Figure 3

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does increasing the scale and diversity of the supervised training dataset prevent the observed overfitting and degeneration phenomenon?
- **Basis in paper:** [explicit] Section 4.3 states, "It is unclear whether these interactions would persist if larger and more diverse data were used for supervision."
- **Why unresolved:** The primary experiments utilized the relatively small URMP dataset (1–2 hours), limiting the ability to generalize findings to large-scale data regimes.
- **What evidence would resolve it:** Repeating the joint training experiments using significantly larger supervised datasets (e.g., full MusicNet or MedleyDB) to observe if the degeneration on self-supervised data persists.

### Open Question 2
- **Question:** Can a self-supervised objective be formulated to enforce the existence of pitch content in predictions without introducing the inflexibility of current energy-based targets?
- **Basis in paper:** [inferred] Section 4.3 notes that while energy-based objectives protect against trivial solutions, they are "too inflexible" and ultimately degrade performance.
- **Why unresolved:** The paper demonstrates a trade-off where preventing collapse via energy targets results in poor prediction quality, suggesting a need for a more nuanced constraint.
- **What evidence would resolve it:** The development of a new regularization term or loss function that maintains non-zero pitch salience on self-supervised data without increasing false alarms.

### Open Question 3
- **Question:** How can the successful inductive biases of monophonic self-supervised methods be adapted to prevent degeneration in the polyphonic setting?
- **Basis in paper:** [explicit] Section 4.3 observes that degeneration appears unique to MPE, contrasting with monophonic methods that utilize categorical cross-entropy and strong inductive biases.
- **Why unresolved:** Polyphonic models lack the constraint of monophony, allowing them to converge to blank outputs (trivial solutions) more easily than monophonic counterparts.
- **What evidence would resolve it:** Adapting categorical constraints or equivariant objectives from monophonic architectures to the multi-pitch estimation framework to verify if degeneration is eliminated.

## Limitations

- The study focuses on closed training conditions (same data distribution) versus open conditions (broader data), but does not explore intermediate scenarios like domain adaptation or semi-supervised learning approaches that might mitigate degeneration
- The exact URMP train/val split indices are referenced from MT3 paper but not explicitly provided, creating uncertainty in reproduction
- The b_oct parameter for pitch shift range in geometric equivariance transformations is unspecified, potentially affecting the equivariance loss computation
- The base filter count for the original Timbre-Trap architecture is unclear, making it difficult to verify the "doubled filters" modification precisely

## Confidence

**High Confidence**: The core phenomenon of simultaneous overfitting to supervised data while degenerating on self-supervised data is well-supported by the experimental evidence. The mechanism that self-supervised objectives lack grounding signals, leading to trivial blank predictions, is clearly demonstrated.

**Medium Confidence**: The explanation that energy-based objectives introduce false positives that conflict with supervised loss is reasonable but relies on qualitative assessment. The severity of this conflict and whether alternative formulations could resolve it remains uncertain.

**Low Confidence**: The claim that fine-tuning from pretrained weights does not resolve degeneration is stated but not empirically demonstrated in the paper. The relationship between energy-based objective design and performance degradation is asserted but lacks quantitative analysis.

## Next Checks

1. **Reproduce baseline performance**: Implement the closed training condition (URMP only) and verify F1 scores match reported values (~90% on Bach10, ~64% on Su). Monitor for blank prediction emergence when adding unsupervised samples.

2. **Parameter sensitivity analysis**: Systematically vary the number of unsupervised samples per batch (2, 4, 8, 16) while monitoring F1 curves across all evaluation datasets. Confirm the relationship between sample count and degeneration severity shown in Figure 3.

3. **Energy objective ablation study**: Compare performance with and without L_eg and L_spr objectives while keeping other losses constant. Quantify the trade-off between preventing blank predictions and introducing false positives through precision-recall analysis.