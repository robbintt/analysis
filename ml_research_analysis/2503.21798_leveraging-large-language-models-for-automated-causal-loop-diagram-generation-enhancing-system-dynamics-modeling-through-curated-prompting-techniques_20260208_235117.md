---
ver: rpa2
title: 'Leveraging Large Language Models for Automated Causal Loop Diagram Generation:
  Enhancing System Dynamics Modeling through Curated Prompting Techniques'
arxiv_id: '2503.21798'
source_url: https://arxiv.org/abs/2503.21798
tags:
- clds
- llms
- prompting
- causal
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for automating Causal Loop Diagram
  (CLD) generation using Large Language Models (LLMs) with curated prompting techniques.
  By transforming dynamic hypotheses into CLDs, the study addresses the challenge
  of manual CLD creation for novice System Dynamics modelers.
---

# Leveraging Large Language Models for Automated Causal Loop Diagram Generation: Enhancing System Dynamics Modeling through Curated Prompting Techniques

## Quick Facts
- **arXiv ID:** 2503.21798
- **Source URL:** https://arxiv.org/abs/2503.21798
- **Reference count:** 9
- **Primary result:** Automated CLD generation using LLMs with curated prompting achieves expert-level accuracy on textbook examples, with two-stage approach showing highest performance

## Executive Summary
This paper introduces a method for automating Causal Loop Diagram (CLD) generation using Large Language Models (LLMs) with curated prompting techniques. The approach transforms text-based Dynamic Hypotheses into structured CLDs, addressing the challenge of manual CLD creation for novice System Dynamics modelers. Four prompting strategies were tested: Baseline (zero-shot), Minimal Context (few-shot), Guided (few-shot with instructions), and Two-Stage (sequential variable extraction and relationship mapping). Experiments using a dataset of 44 textbook examples showed that LLMs can generate CLDs comparable to expert-built ones, with the Two-Stage approach achieving the highest accuracy in variable identification and causal relationship depiction.

## Method Summary
The methodology employs OpenAI's text-davinci-003 with greedy decoding to translate Dynamic Hypotheses into DOT format CLDs. Four prompting approaches were compared: (1) Baseline - zero-shot generation, (2) Minimal Context - few-shot without instructions, (3) Guided - few-shot with explicit rules for variable naming and polarity notation, and (4) Two-Stage - sequential process separating variable extraction from relationship mapping. The Two-Stage approach showed superior performance by reducing inference burden per step and mimicking expert modeler cognition. Outputs were evaluated qualitatively against expert-built CLDs, with accuracy measured in terms of correct variable identification and causal relationship polarity.

## Key Results
- LLMs with guided prompts can generate CLDs comparable to expert-built ones from Dynamic Hypotheses
- Two-Stage approach achieved highest accuracy in variable identification and causal relationship depiction
- Performance improves with complexity, though challenges remain with exogenous variables and complex feedback loops
- Few-shot approaches significantly outperformed zero-shot baseline in producing structured graphical outputs

## Why This Works (Mechanism)

### Mechanism 1: Few-Shot Pattern Transfer to Structured Output
LLMs retrieve and adapt patterns from in-context examples, mapping natural language causal descriptions to formal graph notation (DOT format with arrowhead polarities). The model's pre-training corpus contains sufficient structured representations and causal language patterns to support transfer.

### Mechanism 2: Sequential Task Decomposition
Breaking CLD generation into separate variable identification and relationship mapping stages reduces inference burden per step, allowing focused attention on variable extraction before relationship logic—mimicking expert modeler cognition.

### Mechanism 3: Instruction-Guided Causal Inference
Explicit rules about variable naming conventions and polarity notation constrain output space and improve causal extraction quality by providing reasoning scaffolds that guide attention to directionality and causal direction.

## Foundational Learning

- **Causal Loop Diagrams (CLDs) and Feedback Structure**
  - Why needed: CLDs are the target output format; understanding reinforcing (R) vs. balancing (B) loops is essential for evaluating generated quality
  - Quick check question: Given "price rises → demand falls → inventory grows → price falls," can you identify the loop polarity?

- **Few-Shot Prompting vs. Zero-Shot Learning**
  - Why needed: Core technique differentiating the four experimental approaches; determines whether examples are provided
  - Quick check question: What is the key difference between Approach 1 (Baseline) and Approaches 2-4 in the experiment?

- **Digraph/DOT Format and Graphviz Visualization**
  - Why needed: Technical representation layer; outputs are generated as DOT strings with `arrowhead=vee` (positive) or `arrowhead=tee` (negative)
  - Quick check question: How would you represent "increased smoking causes increased addiction" in the paper's DOT format?

## Architecture Onboarding

- **Component map:** Dynamic Hypothesis text → Prompt template population → LLM inference → DOT string → Graphviz digraph → Visual CLD output

- **Critical path:** DH text → Prompt template population → LLM inference → DOT string → Graphviz digraph → Visual CLD output

- **Design tradeoffs:**
  - Prompt specificity vs. flexibility: More curated instructions improve accuracy but reduce generalizability
  - Single-pass vs. two-stage: Two-stage improves quality but doubles API calls and latency
  - Dataset simplicity vs. real-world validity: Paper uses textbook CLDs (N=44); real systems may lack clear DH articulation

- **Failure signatures:**
  - Exogenous variables omitted or misclassified (e.g., "addiction time" in smoking example)
  - Incorrect polarity assignment on causal links
  - Missing secondary feedback loops in multi-loop systems
  - Conflating loop descriptions ("reinforcing behavior") with actual variables

- **First 3 experiments:**
  1. Replicate the smoking addiction single-loop example across all four approaches to validate implementation and compare against paper's reported outputs
  2. Test on a held-out DH-CLD pair not in training set with 2-3 feedback loops to assess generalization beyond textbook examples
  3. Ablation study: Remove specific instruction components (naming rules, polarity rules) from Guided Prompts to identify which constraints drive performance gains

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the Two-Stage prompting approach maintain high accuracy when applied to larger datasets containing complex, multi-loop CLDs typical of real-world scenarios?
- **Open Question 2:** Can this methodology be extended to generate fully executable simulation model code (e.g., XMILE) rather than static causal diagrams?
- **Open Question 3:** How can prompting strategies be refined to improve the identification of exogenous variables that are peripheral to the primary feedback loops?

## Limitations

- Dataset accessibility: The full dataset of 44 DH-CLD pairs is not publicly available, limiting independent validation of generalizability claims
- Qualitative evaluation: Assessment of CLD quality relies on expert judgment without quantitative metrics beyond variable and relationship counts
- Transferability: Results from textbook examples may not extend to complex real-world systems with ambiguous causal relationships

## Confidence

- **High confidence:** Few-shot prompting with structured examples can generate valid CLD outputs in DOT format
- **Medium confidence:** Two-stage approach consistently outperforms single-pass generation for variable identification and causal relationship mapping
- **Medium confidence:** Guided prompts with explicit rules improve accuracy over minimal context approaches
- **Low confidence:** Performance claims generalize beyond the 44 textbook examples to real-world System Dynamics modeling

## Next Checks

1. **Dataset validation:** Replicate the Three Sisters Garden example using the Two-Stage approach to verify claims about missing feedback loops and exogenous variable handling

2. **Ablation study:** Systematically remove specific instruction components (naming rules, polarity rules, variable extraction rules) from the Guided Prompts approach to isolate which constraints drive performance improvements

3. **Cross-model validation:** Test the Two-Stage prompting approach with different LLMs (GPT-4, Claude) and decoding strategies (temperature sampling vs. greedy) to assess robustness beyond text-davinci-003