---
ver: rpa2
title: Benchmarking Temporal Reasoning and Alignment Across Chinese Dynasties
arxiv_id: '2502.16922'
source_url: https://arxiv.org/abs/2502.16922
tags:
- temporal
- figure
- qwen2
- reasoning
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Chinese Time Reasoning (CTM) benchmark
  to evaluate Large Language Models' (LLMs) temporal reasoning and alignment across
  Chinese dynasties. The benchmark includes 8,750 question-answering pairs and 60
  instances of Timeline Ito Games, emphasizing contextualization, cross-entity relationships,
  and pairwise temporal alignment.
---

# Benchmarking Temporal Reasoning and Alignment Across Chinese Dynasties

## Quick Facts
- **arXiv ID:** 2502.16922
- **Source URL:** https://arxiv.org/abs/2502.16922
- **Reference count:** 40
- **Primary result:** Introduces CTM benchmark revealing significant LLM challenges in Chinese temporal reasoning, with performance degrading as entity count increases and temporal intervals decrease.

## Executive Summary
This paper introduces the Chinese Time Reasoning (CTM) benchmark to evaluate Large Language Models' (LLMs) temporal reasoning and alignment across Chinese dynasties. The benchmark includes 8,750 question-answering pairs and 60 instances of Timeline Ito Games, emphasizing contextualization, cross-entity relationships, and pairwise temporal alignment. Experiments on various LLMs reveal significant challenges, with performance degrading as the number of entities increases and temporal intervals decrease. The results indicate that temporal reasoning remains difficult for current LLMs, especially in nuanced cultural and historical contexts, highlighting the need for improved pretraining, structured knowledge integration, and refined reasoning mechanisms.

## Method Summary
The CTM benchmark comprises 8,750 QA pairs and 60 Timeline Ito Game instances generated from a repository of 4,700+ Chinese historical entities (figures, places, allusions, ingredients, heritage) mapped to dynasty periods. LLMs are evaluated zero-shot and with Chain-of-Thought prompting across 12 models (GPT-4o, Qwen-max, o1-preview, LLaMA3.1-8b, ChatGLM3-6b, InternLM2.5-7b, Qwen2.5-7b/14b/32b/72b, DeepSeek-R1). Accuracy is measured using GPT-4o as a CoT evaluator, with Timeline Ito Game scored via Pass@K metric (K=3,8).

## Key Results
- Performance degrades significantly as cross-temporal entity count increases, dropping from ~60% (1 entity) to ~30% (≥4 entities)
- Accuracy declines from ~55% (interval=9) to ~35% (interval=0) as temporal intervals between entities shorten
- CoT prompting improves larger models but can harm smaller models (<32B) or long-context scenarios
- All models fail at pairwise temporal alignment, with Pass@K <10% for models under 32B parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temporal reasoning performance degrades as the number of entities involved in cross-temporal relationships increases.
- Mechanism: Each additional entity requires the model to retrieve and maintain precise temporal coordinates while simultaneously reasoning about pairwise relationships, compounding working memory load and increasing opportunities for retrieval error.
- Core assumption: Models encode temporal facts with finite precision, and multi-entity reasoning requires successful retrieval for all entities.
- Evidence anchors: [abstract] "performance degrading as the number of entities increases"; [section] Table 2 shows accuracy dropping from ~60% (cross-temp count=1) to ~30% (cross-temp count≥4); [corpus] Related work on temporal reasoning confirms complexity scaling.

### Mechanism 2
- Claim: Shorter inter-dynastic intervals between entities increase reasoning difficulty due to finer-grained temporal discrimination requirements.
- Mechanism: When entities are from adjacent or same dynasties, models must distinguish precise year-level boundaries rather than relying on coarse dynasty-level heuristics, requiring higher-resolution temporal representations.
- Core assumption: Models rely partially on dynasty-level shortcuts; precise year comparisons are harder.
- Evidence anchors: [section] Figure 4 shows accuracy declining from ~55% (interval=9) to ~35% (interval=0); [section] "As the interval decreases, performance declines... closer intervals demanding more precise examination."

### Mechanism 3
- Claim: Chain-of-thought (CoT) prompting improves temporal reasoning for larger models but can harm smaller models or long-context scenarios.
- Mechanism: CoT decomposes multi-step temporal reasoning into explicit intermediate steps, reducing inference complexity. However, small models may lack parametric knowledge to complete reasoning steps, and long contexts introduce distraction or error propagation.
- Core assumption: CoT benefits require sufficient parametric knowledge; reasoning steps are only as good as retrieved facts.
- Evidence anchors: [section] Table 2 shows GPT-4o CoT improving 8 tasks but LSEC (long context) dropping 22 points; [section] "CoT can enhance performance, however, when the LLM is very small or the context is excessively long, it can even negatively impact."

## Foundational Learning

- **Concept: Temporal Coordinate Systems**
  - Why needed here: Chinese dynastic chronology spans -2100 to 1912 with 10 major periods; understanding requires mapping entities to this non-uniform timeline
  - Quick check question: Given "Li Bai (701-762)" and "Bai Juyi (772-846)", can you determine they cannot coexist?

- **Concept: Cross-Entity Temporal Relationships**
  - Why needed here: CTM tasks require reasoning about multiple entities simultaneously (e.g., Li Bai + Bai Juyi + chili peppers + guqin art)
  - Quick check question: In the script error correction task, how many temporal entities must be verified for consistency?

- **Concept: Pairwise Temporal Alignment**
  - Why needed here: Timeline Ito Game requires agents to collaboratively infer relative chronological positions without explicit dates
  - Quick check question: If Agent A chooses "blueberry" (smallest fruit) and Agent B chooses "watermelon" (largest), who represents the earlier dynasty?

## Architecture Onboarding

- **Component map:** Entity Repository -> QA Task Generator -> Model Inference -> GPT-4o Evaluation -> Accuracy/Pass@K Computation
- **Critical path:** 1. Entity sampling from repository → 2. Question generation with temporal constraints → 3. Model inference → 4. GPT-4o evaluation → 5. Accuracy/Pass@K computation
- **Design tradeoffs:** LLM-based generation vs rule-based (more flexible/contextual but requires validation); Dynasty simplification to 10 periods (improves coverage but loses granularity); GPT-4o as evaluator (handles varied formats but introduces evaluator dependency)
- **Failure signatures:** Models scoring <10% on Pass@K in Ito Game (all models <32B); LSEC accuracy near random; CoT regression on small models
- **First 3 experiments:**
  1. Baseline evaluation: Run direct prompting on all 8 QA task types, stratify by cross-temp count (1, 2, 3, ≥4) to confirm entity-count degradation pattern
  2. CoT ablation: Apply CoT prompting, measure delta per task type and model size; expect positive for ≥14B, negative for LSEC across all sizes
  3. Open-book augmentation: Retrieve top-10 Google snippets for entities, measure improvement on TIC and SEC tasks where precision matters most

## Open Questions the Paper Calls Out

- **Question:** Can dynamically adapted prompt designs significantly outperform static zero-shot or Chain-of-Thought (CoT) settings in complex temporal reasoning tasks?
  - **Basis in paper:** [explicit] The limitations section states, "Future work could explore the possibility of dynamically adapting prompt designs to better suit specific temporal reasoning tasks."
  - **Why unresolved:** The current study primarily evaluates performance using standard direct prompting and CoT, acknowledging that effectiveness varies across tasks without testing adaptive strategies.
  - **What evidence would resolve it:** Experiments comparing static baselines against a system that selects or modifies prompts based on the specific temporal task type.

- **Question:** Under what specific conditions does Chain-of-Thought (CoT) reasoning degrade performance in temporal tasks due to "knowledge sensitivity"?
  - **Basis in paper:** [inferred] Page 4 notes that CoT can negatively impact performance, particularly for small LLMs or long contexts, potentially due to knowledge sensitivity, but the exact mechanism or threshold is not defined.
  - **Why unresolved:** The paper identifies the phenomenon where reasoning paths hurt accuracy but does not isolate whether the failure is due to hallucination over long contexts or lack of parametric knowledge in small models.
  - **What evidence would resolve it:** An ablation study analyzing the relationship between model size, context length, and factual grounding to pinpoint when CoT becomes detrimental.

- **Question:** What specific structured knowledge integration methods are required to improve pairwise temporal alignment in models smaller than 32B parameters?
  - **Basis in paper:** [inferred] The analysis on Page 4 states that "Small LLMs cannot align entities across different dimensions," with Pass@K performance for models <32B not exceeding 10, suggesting a fundamental capability gap.
  - **Why unresolved:** While the paper highlights the failure of smaller models in the Timeline Ito Game, it does not investigate whether this is a failure of parametric memory or reasoning architecture.
  - **What evidence would resolve it:** Evaluating sub-32B models fine-tuned on structured temporal graphs to see if explicit knowledge integration bridges the performance gap with larger models like GPT-4o.

## Limitations
- Generalizability to non-Chinese historical contexts remains uncertain due to dataset's focus on Chinese dynastic chronology
- GPT-4o as evaluation judge introduces potential evaluator bias that could systematically affect results across different model families
- The simplified 10-dynasty framework may mask finer-grained temporal reasoning challenges within individual dynasties

## Confidence
- **High:** Entity-count degradation effects are consistent across all tested models and task types
- **Medium-High:** Temporal interval performance decline shows clear visual trends in the data
- **Medium:** CoT effectiveness analysis requires further validation with additional model families due to non-monotonic effects

## Next Checks
1. **Cross-cultural temporal reasoning:** Replicate the entity-count and interval experiments using Western historical timelines to test whether the degradation patterns persist across cultural contexts.

2. **Evaluator independence validation:** Run the same CTM benchmark through an alternative evaluation framework (e.g., rule-based validation or different judge LLM) to assess sensitivity to evaluator choice.

3. **Structured knowledge integration test:** Implement a hybrid approach where temporal facts are provided as structured knowledge graph inputs alongside prompts, measuring whether this mitigates the entity-count and interval effects observed.