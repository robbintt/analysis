---
ver: rpa2
title: An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring
arxiv_id: '2505.24239'
source_url: https://arxiv.org/abs/2505.24239
tags:
- agents
- agent
- adversarial
- credibility
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a credibility scoring framework to make multi-agent
  LLM systems robust against adversarial agents. The core idea is to dynamically assign
  credibility scores to agents based on their past contributions and use these scores
  to weigh agent outputs during aggregation.
---

# An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring
## Quick Facts
- arXiv ID: 2505.24239
- Source URL: https://arxiv.org/abs/2505.24239
- Authors: Sana Ebrahimi; Mohsen Dehghankar; Abolfazl Asudeh
- Reference count: 23
- Primary result: Credibility scoring improves accuracy by 6-30 percentage points against adversarial agents

## Executive Summary
This paper introduces a credibility scoring framework to make multi-agent LLM systems robust against adversarial agents. The core idea is to dynamically assign credibility scores to agents based on their past contributions and use these scores to weigh agent outputs during aggregation. Contributions are measured via Shapley values or an LLM judge, and credibility is updated iteratively using rewards. Experiments across five benchmarks show that this method consistently improves accuracy—by 6-30 percentage points—compared to baselines, even when a majority of agents are adversarial. The approach is topology-agnostic and effective across different agent roles and communication structures.

## Method Summary
The method initializes credibility scores (CrS) at 0.5 for all agents in a team. After each query, agents communicate per topology (SAA, SIA, or CrS-ordered chain), generate outputs, and these outputs are aggregated using CrS-weighted centroid or an LLM coordinator. An external judge (GPT-4o mini) evaluates the final answer, assigns a reward rt ∈ [-1,1], and computes contribution scores (CSc) via Shapley values (for no-communication) or LLM-as-Judge analysis (for communication). CrS updates follow: CrS_t = CrS_{t-1} × (1 + η × CSc × rt). The system uses backbone agents like LLaMA 3.2, Mistral, and Qwen2.5, testing on benchmarks including GSM8K, MMLU-MS, MATH, ResearchQA, and HumanEval.

## Key Results
- Accuracy improves by 6-30 percentage points across five benchmarks compared to baselines
- Credibility scores converge to separate faithful agents (CrS ~0.55) from adversarial agents (CrS ~0.35-0.40) after ~40-60 queries
- CrS-ordered chain topology maintains accuracy even with 4/5 agents adversarial
- Diminishing returns observed beyond 6 communication links in SIA topology

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Weighting agent outputs by learned credibility scores reduces adversarial influence during aggregation.
- **Mechanism:** Each agent maintains a CrS ∈ [0,1] reflecting historical reliability. During aggregation, the system computes a credibility-weighted centroid or passes CrS values to a coordinator LLM. Higher-CrS agents exert greater influence on final outputs.
- **Core assumption:** Adversarial agents produce consistently lower-quality contributions over time, creating a separable distribution from faithful agents.
- **Evidence anchors:** Weighted centroid formula (section 4), 6-30pp accuracy gains (section 6.3.1), SentinelNet validation (2510.16219).
- **Break condition:** Strategic correct answers by adversaries slow convergence; ~40-60 queries needed for stable separation (Figure 2).

### Mechanism 2
- **Claim:** Contribution scores (CSc) fairly attribute team rewards to individual agents, enabling meaningful CrS updates.
- **Mechanism:** Shapley values compute marginal contribution across all agent subsets; LLM-as-Judge analyzes dialogue logs to quantify each agent's impact on the final answer.
- **Core assumption:** The judge can accurately distinguish genuine contributions from adversarial noise by examining message-passing history.
- **Evidence anchors:** Gradual CrS learning (abstract), Shapley for fair reward distribution (section 5.1), comparable convergence with LLM-Judge (section 6.3.4).
- **Break condition:** Weak judges (e.g., LLaMA-3.2 3B) produce fluctuating CrS trajectories and 54% accuracy degradation (section 6.3.5).

### Mechanism 3
- **Claim:** Iterative reward-based CrS updates create a positive feedback loop for reliable agents.
- **Mechanism:** After each query, team receives reward rt ∈ [-1,1]. CrS updates via: CrS(i)t = CrS(i)t-1 × (1 + η × CSc(i) × rt). Faithful agents accumulate credit; adversarial agents decay.
- **Core assumption:** Reward signals correlate with ground-truth correctness and are not gameable by adversaries.
- **Evidence anchors:** Gradual CrS learning (abstract), explicit update rule (section 5.2), faithful agents' CrS rising from 0.5 → 0.55 (Figure 2).
- **Break condition:** Judge misevaluation (HumanEval code tasks) corrupts CrS updates (Table 3).

## Foundational Learning

- **Shapley Values (Cooperative Game Theory)**
  - Why needed here: Core to CSc computation; fairly distributes reward based on marginal contributions across all coalitions
  - Quick check question: Given agents {A, B, C} with rewards for subsets {{A,B}=0.8, {A}=0.3, {B}=0.2, ∅=0}, what is A's marginal contribution to {A,B}?

- **LLM-as-Judge Evaluation Paradigm**
  - Why needed here: Practical alternative to Shapley for communication-heavy topologies; requires understanding prompt design for evaluation
  - Quick check question: What failure modes occur when a weak model judges outputs from a stronger model?

- **Weighted Ensemble Aggregation**
  - Why needed here: Understanding how CrS-weighted centroid differs from majority voting and why it handles adversary-majority settings
  - Quick check question: If 3/5 agents are adversarial with CrS=0.35 each and 2/5 are faithful with CrS=0.55, what is the effective voting weight ratio?

## Architecture Onboarding

- **Component map:** Agent Pool → Team Formation → Communication Layer → Aggregation Module → Final Output → Judge Evaluation → CSc Computation → CrS Update → (next query)
- **Critical path:** Query → Team Assembly → Local Inference → Peer Communication → Individual Outputs → CrS-Weighted Aggregation → Final Output → Judge Evaluation → CSc Computation → CrS Update → (next query)
- **Design tradeoffs:**
  - Shapley vs. LLM-Judge: Shapley is theoretically fair but O(2^N) cost; LLM-Judge scales but introduces judge-quality dependency
  - Link density: >6 links in SIA causes "diminishing returns" and token compression overhead (Figure 5)
  - Judge strength: Stronger judges improve CrS quality but raise cost; weaker judges corrupt the entire system
- **Failure signatures:**
  - CrS non-convergence: Faithful and adversarial CrS remain ~0.5 → check judge outputs for malformed responses
  - Accuracy drops with more communication: Adversaries persuading faithful agents → reduce link density or enforce CrS-ordered chains
  - Reward signal noise: Judge assigns rt=1 to incorrect answers (HumanEval pattern) → task-specific judge selection required
- **First 3 experiments:**
  1. Baseline replication: 5-agent team (2 faithful, 3 adversarial) on GSM8K with SIA topology, GPT-4o-mini judge; verify ~6-10pp accuracy gain with CrS vs. naive coordination
  2. Judge sensitivity: Replace GPT-4o-mini with LLaMA-3.2-3B judge on same setup; confirm CrS trajectory instability and accuracy degradation per Section 6.3.5
  3. Topology comparison: Run identical agent/judge config on SAA, SIA (6 links), and CrS-ordered chain; validate that chain topology maintains accuracy even with 4/5 adversaries (Figure 4)

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on single external judge (GPT-4o mini); weaker judges degrade accuracy by 54%
- Assumes adversarial agents produce consistently lower-quality contributions, which may not hold if adversaries adapt strategies
- Shapley computation is exponential in agent count, limiting scalability despite LLM-as-Judge alternative
- Claim of topology-agnosticism weakened by diminishing returns beyond 6 communication links

## Confidence
- **High confidence**: Core mechanism of credibility-weighted aggregation improving accuracy in adversarial settings (6-30pp gains consistently reported)
- **Medium confidence**: Shapley-based contribution scoring producing fair attribution in communication-free topologies; less validation for LLM-as-Judge in complex topologies
- **Medium confidence**: 6 communication links as optimal topology, based on performance plateau beyond this threshold

## Next Checks
1. Test system robustness when adversaries deliberately produce correct answers on alternating queries to avoid detection patterns in credibility scoring
2. Validate performance when replacing GPT-4o mini judge with weaker models across all topologies, measuring accuracy degradation and CrS convergence stability
3. Scale system beyond 5 agents to verify computational feasibility and accuracy retention, particularly examining whether LLM-as-Judge maintains attribution quality with larger agent teams