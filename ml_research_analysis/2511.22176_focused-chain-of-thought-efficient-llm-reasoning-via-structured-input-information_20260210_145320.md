---
ver: rpa2
title: 'Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information'
arxiv_id: '2511.22176'
source_url: https://arxiv.org/abs/2511.22176
tags:
- reasoning
- context
- information
- question
- f-cot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the inefficiency of large language models (LLMs)
  in reasoning tasks, which often produce verbose chain-of-thought (CoT) traces that
  increase token usage and inference latency. The authors propose Focused Chain-of-Thought
  (F-CoT), a training-free, input-centric approach inspired by cognitive psychology
  that separates information extraction from reasoning.
---

# Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information

## Quick Facts
- arXiv ID: 2511.22176
- Source URL: https://arxiv.org/abs/2511.22176
- Reference count: 40
- Primary result: 2-3x token reduction with comparable accuracy on arithmetic word problems

## Executive Summary
This paper addresses the inefficiency of large language models (LLMs) in reasoning tasks, which often produce verbose chain-of-thought (CoT) traces that increase token usage and inference latency. The authors propose Focused Chain-of-Thought (F-CoT), a training-free, input-centric approach inspired by cognitive psychology that separates information extraction from reasoning. F-CoT organizes essential information from a query into a structured context, which the model then uses exclusively for reasoning. This prevents attention to irrelevant details and naturally shortens reasoning paths.

Experiments on arithmetic word problems show that F-CoT reduces generated tokens by 2-3× while maintaining accuracy comparable to standard zero-shot CoT. The method uses two-step prompting: first extracting key facts into structured XML-like context blocks, then performing reasoning only over this extracted information. Results demonstrate significant efficiency gains without sacrificing reasoning quality, making it a promising approach for reducing computational costs in LLM reasoning applications.

## Method Summary
F-CoT is a training-free approach that separates information extraction from reasoning in LLM workflows. The method uses a two-step prompting strategy where the first step extracts key facts from the original query into structured XML-like `<context>` blocks, and the second step performs reasoning only over this extracted context. This prevents the model from attending to irrelevant details and naturally shortens reasoning paths. The approach is inspired by cognitive psychology principles and can be implemented with any reasoning-capable LLM without model fine-tuning.

The implementation involves: (1) context extraction using prompts that guide the LLM to identify and format essential information, (2) reasoning over the extracted context using standard zero-shot CoT prompting, and (3) measuring both accuracy (Pass@5) and token efficiency. The method was evaluated on arithmetic word problem benchmarks including SVAMP, GSM-Hard, and MATH-500 using various Qwen3 model sizes with specific inference parameters (temperature=0.6, top-p=0.95, top-k=20, max_tokens=32k).

## Key Results
- F-CoT reduces generated tokens by 2-3× compared to standard zero-shot CoT
- Maintains comparable accuracy to standard zero-shot CoT on arithmetic word problems
- Achieves significant efficiency gains without model fine-tuning or architectural changes
- Demonstrates consistent performance improvements across different model sizes (0.6B to 32B parameters)

## Why This Works (Mechanism)
F-CoT works by mimicking human cognitive processes that separate information gathering from reasoning. Instead of having the LLM process the entire input during reasoning (including irrelevant details), it first extracts only the essential information into a structured format. This structured context serves as a focused workspace for the reasoning step, preventing the model from getting distracted by extraneous information. The separation of concerns allows the model to work more efficiently, similar to how humans organize information before solving complex problems.

The XML-like structure enforces explicit formatting that helps the model clearly identify what information is relevant, reducing ambiguity and improving the quality of extracted context. By constraining the reasoning step to only the extracted context, the model avoids generating lengthy CoT traces that include information processing steps, instead focusing directly on the logical steps needed to reach a solution.

## Foundational Learning
**Information Extraction from Text**: The ability to identify and extract relevant facts from natural language queries. Why needed: Forms the basis of the first F-CoT step. Quick check: Can you extract key entities, numbers, and relationships from a sample word problem?

**Structured Data Formatting**: Converting unstructured information into well-defined formats like XML. Why needed: Enables clear separation between context and reasoning steps. Quick check: Can you create valid XML tags around extracted information without breaking structure?

**Chain-of-Thought Reasoning**: The standard approach where LLMs generate step-by-step reasoning traces. Why needed: Serves as the baseline comparison for F-CoT. Quick check: Can you implement basic CoT prompting and observe token generation patterns?

**Prompt Engineering for Information Extraction**: Designing prompts that effectively guide LLMs to extract specific types of information. Why needed: Critical for generating high-quality context in F-CoT. Quick check: Can you modify extraction prompts to improve completeness and accuracy?

**Zero-Shot Learning**: Prompting techniques that don't require model fine-tuning. Why needed: F-CoT is a training-free approach. Quick check: Can you design prompts that work without examples or fine-tuning?

## Architecture Onboarding

**Component Map**: Query -> Context Extraction Module -> Structured Context -> Reasoning Module -> Answer

**Critical Path**: The two-step process (extraction → reasoning) is the critical path. Any failure in context extraction directly impacts reasoning quality. The system must ensure valid XML context generation before proceeding to reasoning.

**Design Tradeoffs**: F-CoT trades potential information completeness for efficiency. While the extraction step may miss some subtle details, the structured format and focused reasoning often compensate by preventing distraction. The approach also trades model universality for efficiency gains.

**Failure Signatures**: 
- Invalid XML context (malformed tags, missing closing tags)
- Incomplete information extraction (missing key numbers or relationships)
- Context that's too verbose, negating token efficiency benefits
- Reasoning failures due to missing context that was present in original query

**First 3 Experiments**:
1. Implement basic F-CoT on SVAMP dataset and measure token reduction vs standard CoT
2. Test different context extraction prompts to optimize information completeness
3. Evaluate F-CoT performance across multiple model sizes to assess scalability

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness may not generalize beyond arithmetic word problems to other reasoning domains
- Performance depends heavily on quality of information extraction, which may vary with different models
- The 2-3× token reduction claim is specific to arithmetic problems and may not hold for all reasoning tasks
- GPT-5 mini dependency for context extraction creates reproducibility challenges

## Confidence

**High confidence**: Token reduction claims (2-3×) are well-supported by controlled experiments on standard benchmarks with clear metrics.

**Medium confidence**: Accuracy maintenance claim holds within tested arithmetic domain but may not extend to broader reasoning tasks or different LLM architectures.

**Low confidence**: Scalability claims to other problem domains and sensitivity to different context extraction models are not empirically validated.

## Next Checks

1. **Cross-domain validation**: Test F-CoT on non-arithmetic reasoning tasks (e.g., commonsense reasoning, multi-hop inference) to assess generalizability beyond math word problems.

2. **Extraction robustness study**: Compare context extraction quality using available models (GPT-4o-mini, Claude Haiku) against reported GPT-5 mini performance to quantify impact of extraction quality on downstream reasoning accuracy.

3. **Sensitivity analysis**: Systematically vary context extraction prompt and reasoning prompt parameters to identify which components are critical for maintaining token reduction-accuracy tradeoff.