---
ver: rpa2
title: 'Collaboration of Fusion and Independence: Hypercomplex-driven Robust Multi-Modal
  Knowledge Graph Completion'
arxiv_id: '2509.23714'
source_url: https://arxiv.org/abs/2509.23714
tags:
- modality
- knowledge
- zhang
- m-hyper
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes M-Hyper, the first multi-modal knowledge graph
  completion (MMKGC) method operating in hypercomplex space. Existing MMKGC paradigms
  either fuse modalities with fixed strategies (losing modality-specific information)
  or keep modalities independent (missing cross-modal interactions).
---

# Collaboration of Fusion and Independence: Hypercomplex-driven Robust Multi-Modal Knowledge Graph Completion

## Quick Facts
- **arXiv ID**: 2509.23714
- **Source URL**: https://arxiv.org/abs/2509.23714
- **Reference count**: 22
- **Primary result**: Achieves state-of-the-art MRR of 41.25% on DB15K, outperforming 18 baselines while maintaining computational efficiency

## Executive Summary
This paper introduces M-Hyper, the first multi-modal knowledge graph completion method operating in hypercomplex space. The key innovation is using biquaternion algebra to simultaneously preserve both fused and independent modality representations, addressing a fundamental limitation of existing MMKGC paradigms that either fuse modalities with fixed strategies (losing modality-specific information) or keep modalities independent (missing cross-modal interactions). The method employs two novel modules—FERF for fine-grained entity representation factorization and R2MF for robust relation-aware modality fusion—and maps these representations to biquaternion bases for comprehensive modality interaction.

## Method Summary
M-Hyper operates by first decomposing each modality's representation into modality-specific and task-specific components through the FERF module. These are then fused using relation-aware gating with noise-powered self-distillation in the R2MF module. The resulting four representations (fused, structural, visual, textual) are mapped to biquaternion bases (1, i, j, k) and scored using Hamilton product operations. The model is trained with cross-entropy loss plus reconstruction and distillation losses, optimized with Adagrad on Adagrad on large batches with triple augmentation.

## Key Results
- Achieves MRR of 41.25% on DB15K, 37.02% on MKG-W, and 39.46% on MKG-Y
- Outperforms 18 baselines including MoMoK and AdaMF across all three datasets
- Maintains computational efficiency with faster training than ensemble baselines
- Demonstrates superior robustness to modality missing and noise scenarios

## Why This Works (Mechanism)

### Mechanism 1
Biquaternion algebra provides orthogonal bases that enable simultaneous preservation of modality-specific information and cross-modal interaction. Four modalities map to biquaternion bases (1, i, j, k), with the Hamilton product inherently generating all pairwise interaction terms through algebraic expansion, eliminating the need for explicit fusion modules or separate sub-models.

### Mechanism 2
Decomposing modality embeddings into modality-specific and task-specific components improves robustness to missing/noisy modalities. Each modality produces two vectors: em_m (modality-specific, from pretrained encoders + MLP) and em_t (task-specific, learnable). Reconstruction loss forces task-specific embeddings to cooperate across modalities to reconstruct original modality information, creating implicit cross-modal regularization.

### Mechanism 3
Noise-powered self-distillation during gated fusion training yields robustness to modality perturbations. Gaussian noise is added to a subset of entity embeddings, with noise-free fused embeddings serving as "teacher" to supervise noisy "student" embeddings via L2 distillation loss. The relation-aware gating learns to weight modalities adaptively per relation context.

## Foundational Learning

- **Concept: Quaternion algebra (i, j, k imaginary units with Hamilton product)**
  - Why needed here: The entire architecture rests on representing 4 modalities as quaternion bases and using Hamilton product for interactions. Without understanding orthogonal bases and non-commutative multiplication, the scoring function is opaque.
  - Quick check question: Compute the Hamilton product of Q1 = 1 + 2i + 3j + 4k and Q2 = 1 + i. Does ij = ji?

- **Concept: Knowledge graph embedding score functions (TransE, ComplEx, RotatE)**
  - Why needed here: M-Hyper extends RotatE's rotation-in-complex-space idea to biquaternion space with both translation (⊕) and rotation (⊗). Prior familiarity with translational vs. semantic-matching paradigms clarifies design choices.
  - Quick check question: In TransE, how is ||h + r - t|| interpreted? How does RotatE modify this for complex space?

- **Concept: Multi-modal fusion vs. ensemble paradigms**
  - Why needed here: The paper's core motivation is that fusion loses modality specificity, ensemble lacks cross-modal interaction. Understanding this tradeoff clarifies why biquaternion is proposed as a unified solution.
  - Quick check question: Name one drawback of early fusion (concatenating modality features) and one drawback of late ensemble (averaging modality-specific predictions).

## Architecture Onboarding

- **Component map:** Raw entity modalities → FERF decomposition (modality-specific + task-specific) → R2MF fusion with relation-aware gating → Biquaternion assembly → Hamilton product scoring → Cross-entropy + reconstruction + distillation losses

- **Critical path:** Raw entity modalities → FERF decomposition (modality-specific + task-specific) → R2MF fusion with relation-aware gating → Biquaternion assembly → Hamilton product scoring → Cross-entropy + reconstruction + distillation losses

- **Design tradeoffs:**
  - Expressiveness vs. efficiency: Biquaternion requires 8d real parameters per entity (4 bases × 2 for complex), but paper shows faster training than ensemble baselines due to unified scoring
  - Robustness vs. complexity: Noise distillation adds training variance but improves modality-missing scenarios
  - Orthogonality vs. correlation: Biquaternion bases are algebraically orthogonal, but real modalities may be correlated—assumption may not hold for all datasets

- **Failure signatures:**
  - Gating collapse: If attention weights become uniform across modalities, check temperature τ_r (may be too high) or learning rate
  - Embedding explosion: N3 regularization λ too low; watch for ||e||_3 growth
  - Missing modality crash: If β (noise rate) > 0.4 or reconstruction loss dominates, model may overfit to noise patterns
  - Relation-specific failure: Check per-relation MRR (Table 3)—if symmetric relations (spouse) underperform, rotation embedding may be misconfigured

- **First 3 experiments:**
  1. **Reproduce DB15K baseline:** Use d=256, α=0.01, λ=0.01, β=0.2; verify MRR ~41% per Table 1. Check that removing biquaternion (using quaternion only, i.e., w/o complex coefficients) drops performance as shown in ablation.
  2. **Ablate modalities:** Zero out each of êj, ês, êv, êt in turn. Per Table 2, joint modality removal causes largest drop (~5% MRR). If structural removal causes minimal drop, check KG density—sparse graphs may underutilize structure.
  3. **Robustness stress test:** Randomly delete 20-40% of modality embeddings in validation set. Compare MRR degradation vs. MoMoK and AdaMF baselines. If M-Hyper degrades faster, distillation may be undertrained—increase β or add distillation epochs.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the M-Hyper framework be extended to accommodate more than three independent modalities (e.g., incorporating audio or video) given the rigid four-basis structure of biquaternions?
- **Open Question 2:** To what extent is M-Hyper's performance bottlenecked by the use of frozen, lower-capacity feature encoders (VGG-19, BERT-base) compared to modern Large Language Models?
- **Open Question 3:** Does the computational efficiency of the Hamilton product scale effectively to knowledge graphs with millions of entities?

## Limitations

- Biquaternion orthogonality assumption may not hold for correlated modalities, potentially limiting capacity in practice
- Noise-powered self-distillation hyperparameters (β, τ_r) are critical but poorly specified, with risk of undertraining or overfitting
- Reconstruction loss weighting relative to main objective is unspecified, affecting FERF component balance

## Confidence

- Mechanism 1 (Biquaternion algebra): Medium - Strong theoretical basis but weak empirical validation of orthogonality benefits
- Mechanism 2 (Modality decomposition): High - Clear ablation evidence and alignment with prior work (IndiSeek)
- Mechanism 3 (Noise distillation): Medium - Robustness claims supported but distillation mechanism details underspecified

## Next Checks

1. **Orthogonality validation**: Measure pairwise modality correlation in learned biquaternion space vs. baseline fusion methods
2. **Noise sensitivity analysis**: Systematically vary β from 0.1 to 0.4 and measure distillation loss convergence curves
3. **Per-relation performance breakdown**: Analyze which relation types (symmetric, compositional, hierarchical) benefit most from biquaternion interactions