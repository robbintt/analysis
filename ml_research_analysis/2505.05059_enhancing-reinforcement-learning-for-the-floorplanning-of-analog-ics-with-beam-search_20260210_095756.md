---
ver: rpa2
title: Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam
  Search
arxiv_id: '2505.05059'
source_url: https://arxiv.org/abs/2505.05059
tags:
- search
- agent
- beam
- hpwl
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a hybrid reinforcement learning and beam search
  method for analog IC floorplanning that achieves 5-85% improvement in area, dead
  space, and half-perimeter wire length compared to standard RL approaches. The key
  innovation is a beam search enhancement of the inference process that builds and
  prunes a search tree representing the RL agent's state space, allowing flexible
  objective weightings and congestion management without retraining.
---

# Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search

## Quick Facts
- **arXiv ID:** 2505.05059
- **Source URL:** https://arxiv.org/abs/2505.05059
- **Reference count:** 16
- **Primary result:** Hybrid RL-beam search method achieves 5-85% improvement in area, dead space, and HPWL compared to standard RL.

## Executive Summary
This paper introduces a hybrid approach that combines reinforcement learning with beam search to improve analog IC floorplanning. The method enhances a pre-trained RL agent's inference process by building a search tree and applying periodic beam search pruning, allowing for better exploration-exploitation balance without retraining. The approach achieves significant improvements across multiple metrics (dead space, HPWL, area) while maintaining the RL agent's generalization ability and enabling CPU-based execution instead of requiring GPU resources.

## Method Summary
The method builds a search tree from a pre-trained RL policy π*, where each node samples q=5 actions. The tree is pruned with probability ε=0.7 using beam width β=10, keeping at most 10^3 nodes per level. Node values are computed using weighted metrics (area, HPWL), and a RUDY congestion estimator filters actions, resampling 60% if congestion thresholds are exceeded. The approach uses 6 benchmark circuits from Infineon 130nm technology and evaluates performance across dead space, HPWL, and reward metrics through 100 trials per benchmark.

## Key Results
- 5-85% improvement in dead space (DS) compared to standard RL approaches
- 5-85% improvement in half-perimeter wire length (HPWL)
- Better stability and comparable performance to fine-tuning approaches without requiring GPU resources

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decoupling exploration from policy training via inference-time search improves solution quality without retraining.
- **Mechanism:** The method constructs a search tree where nodes represent floorplanning states, sampling multiple actions per step instead of greedy rollout.
- **Core assumption:** The pre-trained RL policy is robust enough to propose viable candidate actions containing optimal trajectories when combined and pruned.
- **Evidence anchors:** [abstract] "BS algorithm enhances agent's inference process... without policy retraining"; [section III.C] "search tree is built"; [corpus] RL-BS approaches support hybrid optimization.
- **Break condition:** If base RL policy is poorly trained, expanding search tree only propagates low-quality states.

### Mechanism 2
- **Claim:** Periodic pruning balances computational cost with solution quality by retaining high-potential trajectories.
- **Mechanism:** A value function evaluates nodes based on weighted metrics; with probability ε, the algorithm prunes to retain top β nodes per level.
- **Core assumption:** Intermediate reward/value function correlates strongly with final optimal floorplan.
- **Evidence anchors:** [abstract] "combines RL with search tree and periodic BS pruning"; [section III.C] "prunes using beam search... leaving (at most) β nodes"; [corpus] BS literature confirms pruning reduces memory requirements.
- **Break condition:** If beam width β is too low, search becomes too greedy and may miss global optima.

### Mechanism 3
- **Claim:** Integrating congestion estimator into action sampling improves routability without explicit constraint training.
- **Mechanism:** RUDY routing demand estimator evaluates congestion; if threshold exceeded, 60% of actions are re-sampled.
- **Core assumption:** Congestion can be accurately estimated locally before full floorplan completion.
- **Evidence anchors:** [abstract] "addressing congestion without policy retraining"; [section III.C] "RUDY computed... If congestion exceeds threshold... actions are re-sampled"; [corpus] "Advancing Routing-Awareness in Analog ICs Floorplanning".
- **Break condition:** If RUDY threshold is too aggressive, agent may exhaust valid placement options.

## Foundational Learning

- **Concept: Markov Decision Process (MDP) in Floorplanning**
  - **Why needed here:** Floorplanning is framed as sequential decision problem (S, A, P, R, γ) where agent places modules to maximize cumulative reward.
  - **Quick check question:** How does the "state" change when the agent places a specific module bi?

- **Concept: Beam Search vs. Monte Carlo Tree Search (MCTS)**
  - **Why needed here:** Distinguishing BS from MCTS is critical; BS prunes siblings (keeps best β nodes per level) while MCTS focuses on depth and rollouts.
  - **Quick check question:** Does this algorithm explore deep branches using rollouts, or prune wide branches level-by-level?

- **Concept: HPWL (Half-Perimeter Wire Length)**
  - **Why needed here:** Primary proxy for wire length and timing optimization in reward function; minimizing bounding box of connected modules correlates with better performance.
  - **Quick check question:** Why is HPWL used instead of exact routed wire length during floorplanning phase?

## Architecture Onboarding

- **Component map:** RL Policy Network → Search Tree Manager → RUDY Estimator → BS Pruner
- **Critical path:** Inference loop: Sampling actions → RUDY Congestion Check → Tree Expansion → Value Calculation → Probabilistic Pruning (ε). Repeats until floorplan complete.
- **Design tradeoffs:**
  - Arity (q) vs. Runtime: Increasing q improves results but linearly increases memory/compute per step
  - Beam Width (β) vs. Optimality: Lower β is faster but risks "search errors" (discarding optimal path)
  - Weights (α, δ): User must tune post-training to prioritize Area vs. HPWL
- **Failure signatures:**
  - Runtime Explosion: If pruning probability ε is too low or beam width β too high, tree grows too large
  - Incoherent Floorplans: If base RL agent is not pre-trained effectively, BS enhancement cannot salvage results
  - Constraint Deadlock: Excessive congestion thresholds causing re-sampling loop to fail finding valid actions
- **First 3 experiments:**
  1. Baseline Validation: Run 0-shot RL agent against BS-RL on smallest test circuit (OTA-1) to verify ≈5% improvement
  2. Ablation on Beam Width (β): Run BS-RL with β ∈ {1, 5, 10, 20} to observe curve of diminishing returns
  3. Congestion Sensitivity: Enable RUDY constraint and vary threshold to confirm routing-friendly outputs don't degrade HPWL significantly

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does BS-RL scale in runtime and performance when applied to analog circuits with significantly higher complexity (>100 modules)?
- **Basis in paper:** [explicit] Authors state runtime "doesn't increase significantly on problems of even higher complexity, but new data would be needed for assessment."
- **Why unresolved:** Experimental evaluation limited to specific circuits with low structural complexity (5-19 structures), leaving scaling behavior on large industrial blocks unverified.
- **What evidence would resolve it:** Benchmark results on larger netlists demonstrating runtime growth rate and solution quality relative to problem size increase.

### Open Question 2
- **Question:** Can floorplanning agent be integrated into closed-loop layout generation flow using feedback from post-layout verification (DRC, LVS, ERC) to refine device placement?
- **Basis in paper:** [explicit] Conclusion outlines future goal to "augment floorplan algorithm with detailed routing information, and feedbacks from post-layout verification, to incrementally refine device placement."
- **Why unresolved:** Current paper focuses solely on floorplanning stage using proxy metrics, stopping short of generating verified production-ready layouts.
- **What evidence would resolve it:** Demonstration of automated pipeline iteratively modifying floorplan based on back-end verification errors to produce clean layout.

### Open Question 3
- **Question:** Is there specific hyperparameter configuration (q, ε, β) that provides universally superior results, or can these be dynamically adjusted for specific circuit topologies?
- **Basis in paper:** [explicit] Authors note while specific setup was chosen for evaluation, "future investigations may uncover more interesting and potentially superior results" regarding different configurations.
- **Why unresolved:** Paper relies on single fixed set of hyperparameters (q=5, ε=0.7, β=10) to balance results and time without exploring sensitivity or optimality across different design constraints.
- **What evidence would resolve it:** Ablation study or sensitivity analysis showing performance variance across wider range of hyperparameter settings.

## Limitations
- Performance claims heavily depend on quality of pre-trained RL agent from [6], which is not fully specified
- Choice of beam search value function weights (α, δ) is left user-adjustable with no reported optimal values
- RUDY congestion estimator parameters may require tuning for different circuit topologies or technology nodes

## Confidence
- **High Confidence:** Mechanism of using beam search to enhance inference-time exploration is theoretically sound and supported by RL-BS literature; CPU-based execution advantage is well-established
- **Medium Confidence:** 5-85% improvement range is plausible but dataset-dependent and contingent on base RL policy quality; congestion management claim is reasonable but not extensively validated
- **Low Confidence:** Claim of maintaining generalization ability without retraining is not directly tested; paper focuses on improved performance rather than evaluating generalization to unseen circuit types

## Next Checks
1. **RL Agent Verification:** Obtain and validate pre-trained RL agent from [6]; if unavailable, train comparable relational GNN policy using same reward structure and benchmark circuits
2. **Parameter Sensitivity Analysis:** Systematically vary beam width β and value function weights α, δ to quantify impact on performance and identify optimal settings for different objective priorities
3. **Congestion Threshold Robustness:** Test RUDY-based constraint with multiple threshold values (e.g., 0.05, 0.1, 0.2) and analyze trade-off between routing friendliness and dead space/HPWL metrics