---
ver: rpa2
title: Scaling laws for activation steering with Llama 2 models and refusal mechanisms
arxiv_id: '2507.11771'
source_url: https://arxiv.org/abs/2507.11771
tags:
- steering
- activation
- refusal
- arxiv
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates how the effectiveness of activation steering
  techniques scales with model size, specifically using Llama 2 models (7B, 13B, 70B).
  It applies contrastive activation addition (CAA) to steer refusal behavior by injecting
  learned steering vectors into residual streams at various layers.
---

# Scaling laws for activation steering with Llama 2 models and refusal mechanisms

## Quick Facts
- arXiv ID: 2507.11771
- Source URL: https://arxiv.org/abs/2507.11771
- Authors: Sheikh Abdur Raheem Ali; Justin Xu; Ivory Yang; Jasmine Xinze Li; Ayse Arslan; Clark Benham
- Reference count: 6
- One-line primary result: CAA steering effectiveness decays exponentially with model size and peaks at early-mid layers (~40% depth), with negative steering being more potent than positive across all scales.

## Executive Summary
This paper investigates how contrastive activation addition (CAA) effectiveness scales with model size when steering refusal behavior in Llama 2 models (7B, 13B, 70B). CAA works by computing steering vectors from contrastive pairs and injecting them into residual streams at different layers during the forward pass. The study finds that steering effectiveness decays exponentially with parameter count and peaks at early-mid layers, suggesting larger models "drown out" steering signals more effectively. The research also reveals an asymmetry where negative steering (toward non-refusal) is consistently more effective than positive steering, possibly due to RLHF training dynamics.

## Method Summary
The method involves running forward passes on contrastive pairs (refusal vs non-refusal examples), caching residual stream vectors for the last token at every layer, and computing steering vectors by subtracting harmful behavior vectors from desired behavior vectors per layer. These vectors are averaged and normalized, then injected at every token position before the add & normalize step after the MLP. The approach sweeps across all layers to measure effectiveness, comparing positive vs negative steering and examining scaling behavior across different model sizes.

## Key Results
- CAA effectiveness diminishes exponentially with increasing model size (y = 0.081 + 2.4·e^(-0.42·x), where y is peak effectiveness and x is parameter count)
- Steering is most effective at early-mid layers (~0.4 × total layers)
- Negative steering toward non-refusal is more effective than positive steering toward more refusal across all model sizes
- Larger models "drown out" steering signals more effectively than smaller models

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Activation Addition (CAA)
CAA finds desirable directions in the model's residual stream vector space using contrastive pairs and adds this direction to the residual stream during the forward pass. The method caches residual stream vectors from positive and negative examples, computes the difference between harmful and desired behavior vectors for each layer, then averages and normalizes these direction vectors. The steering vector is injected before the add & normalize step after the MLP.

### Mechanism 2: Early-Mid Layer Intervention
CAA is most effective when applied at early-mid layers, specifically at approximately 40% of total layer count. The residual stream serves as a communication channel between layers, with early layers processing low-level features and later layers integrating information for prediction. Early-mid layers appear to be where high-level conceptual features like "refusal" are most malleable before being integrated into final predictions.

### Mechanism 3: RLHF Asymmetry
Negative steering (toward non-refusal) is significantly more effective than positive steering (toward more refusal) across all model sizes. The paper hypothesizes this asymmetry results from RLHF training, where pre-trained models are pushed to maximum refusal, leaving more "space" to steer back toward non-refusal than to further increase already-saturated refusal behavior.

## Foundational Learning

- **Concept: Transformer Residual Stream**
  - Why needed here: CAA operates by intervening on the residual stream, which accumulates information as it passes through each layer
  - Quick check question: Does the residual stream at layer `L` contain information modified by all layers before `L`?

- **Concept: Linear Superposition in LLMs**
  - Why needed here: CAA assumes behaviors like "refusal" can be represented as a direction (vector) in the residual stream's high-dimensional space
  - Quick check question: If a "refusal direction" exists, does adding a scaled version of that vector to the residual stream imply the model will refuse more?

- **Concept: RLHF (Reinforcement Learning from Human Feedback)**
  - Why needed here: The paper's hypothesis about steering asymmetry depends on understanding how RLHF pushes models toward maximum refusal
  - Quick check question: Would a base model (pre-training only) without RLHF exhibit the same asymmetry between positive and negative steering for refusal?

## Architecture Onboarding

- **Component map**: Residual stream injection point → after MLP, before Add & Normalize step of transformer decoder block
- **Critical path**: Generating contrastive pairs → extracting and caching residual vectors for all layers → calculating steering vector (difference of means) → sweeping injection across every layer → evaluating downstream effect
- **Design tradeoffs**:
  - **Injection Position**: Too early may be overwritten; too late may not influence the decision. Paper finds ~40% depth optimal
  - **Vector Magnitude**: Paper normalizes steering vectors. Larger scaling may have stronger effects but risks degrading capabilities
  - **Single vs. Multi-Layer Injection**: Paper tests single-layer injection. Multi-layer injection is proposed extension but could interact complexly
- **Failure signatures**:
  - **Broken Coherence**: Model outputs nonsensical text, suggesting steering vector magnitude is too high
  - **No Effect**: Model behavior doesn't change, indicating wrong layer choice or flawed contrastive pairs
  - **Opposite Effect**: Model behaves contrary to steering direction, suggesting inversion effect between layers
- **First 3 experiments**:
  1. **Baseline & Replication**: On Llama 2 7B, replicate core finding by generating refusal steering vector and plotting effectiveness across all layers, confirming peak at ~40% depth
  2. **Asymmetry Test**: Using same setup, compare maximum effect of positive steering (add vector) vs negative steering (subtract vector), confirming negative steering is more pronounced
  3. **Scaling Test**: Run same experiment on Llama 2 13B, measuring peak effectiveness and checking if it has decreased compared to 7B model

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the asymmetry between positive and negative steering effectiveness generalize to behaviors beyond refusal?
  - Basis in paper: [explicit] "However, further experiments with a more complete set of behaviors are needed to support this claim" regarding RLHF-based hypothesis
  - Why unresolved: Study only tested refusal behavior; observed asymmetry may be specific to this domain
  - What evidence would resolve it: Systematic experiments testing positive vs negative steering across multiple behavioral domains

- **Open Question 2**: Can modified injection strategies (multi-layer injection or scaled vectors) recover steering effectiveness in larger models?
  - Basis in paper: [explicit] "Immediate experiments include scaling up steering vector or injecting one vector at multiple layers while monitoring capability degradation"
  - Why unresolved: Current single-layer injection shows diminishing returns with scale; alternative strategies unexplored
  - What evidence would resolve it: Ablation studies varying injection layer count and vector magnitude scaling across model sizes

- **Open Question 3**: Does CAA effectiveness scale similarly across different model architectures?
  - Basis in paper: [explicit] "Llama is a decoder only model, so differences in the result of activation steering could yield insight about how to align models of different architectures"
  - Why unresolved: Only Llama 2 (decoder-only) was tested; encoder-decoder and encoder-only models may exhibit different scaling
  - What evidence would resolve it: Comparative CAA experiments on different architectures at matched parameter counts

- **Open Question 4**: Is there a systematic relationship between feature category and the layer of peak steering effectiveness?
  - Basis in paper: [explicit] "Performing sweeps with different categories of steering features to uncover relationships between feature category and layer of peak effectiveness could also prove fruitful"
  - Why unresolved: Only refusal behavior was tested; different semantic features may peak at different layers
  - What evidence would resolve it: Layer-wise steering sweeps across diverse behavioral categories mapped against their peak effectiveness layers

## Limitations

- The mechanistic explanations (RLHF asymmetry hypothesis, mid-layer effectiveness) remain speculative without deeper causal analysis
- The paper doesn't test steering vector transferability between model sizes, which would strengthen claims about feature representation stability
- The exponential decay model is based on only three data points (7B, 13B, 70B), limiting confidence in the scaling relationship

## Confidence

- **High confidence**: Empirical finding that steering effectiveness diminishes with model size and peaks at mid-layers is well-supported by experimental data across all three model sizes
- **Medium confidence**: CAA mechanism description and general pattern of negative steering being more effective are well-documented, but specific reasons (RLHF saturation, superposition) are hypotheses
- **Low confidence**: Mechanistic explanations for why early-mid layers are optimal and why RLHF asymmetry exists are plausible but not definitively proven

## Next Checks

1. Test steering vector transferability: Generate steering vectors from a 7B model and apply them to 13B and 70B models to determine if the same directions work across scales or must be recomputed for each size

2. Investigate the RLHF asymmetry with base models: Repeat steering experiments on base (non-RLHF) Llama 2 models to determine if negative steering advantage persists without RLHF fine-tuning

3. Validate the scaling law with additional model sizes: Test the exponential decay model on intermediate sizes (e.g., 8B, 34B) or models from different families to confirm universality of the scaling relationship