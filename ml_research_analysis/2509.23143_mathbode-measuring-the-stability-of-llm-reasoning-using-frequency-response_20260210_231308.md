---
ver: rpa2
title: 'MathBode: Measuring the Stability of LLM Reasoning using Frequency Response'
arxiv_id: '2509.23143'
source_url: https://arxiv.org/abs/2509.23143
tags:
- phase
- arxiv
- frequency
- linear
- amplitude
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "MathBode introduces a frequency-domain diagnostic for LLM mathematical\
  \ reasoning, driving a single problem parameter sinusoidally and measuring first-harmonic\
  \ gain and phase errors relative to exact solutions. Across five closed-form families,\
  \ models exhibit systematic low-pass behavior with frequency-dependent gain loss\
  \ and phase lag\u2014even when static accuracy is high."
---

# MathBode: Measuring the Stability of LLM Reasoning using Frequency Response

## Quick Facts
- arXiv ID: 2509.23143
- Source URL: https://arxiv.org/abs/2509.23143
- Authors: Charles L. Wang
- Reference count: 8
- One-line primary result: Frequency-domain analysis of LLM reasoning reveals systematic low-pass behavior—amplitude loss and phase lag—that correlates with problem complexity but not necessarily with static accuracy.

## Executive Summary
MathBode introduces a frequency-domain diagnostic for LLM mathematical reasoning by sinusoidally sweeping a single problem parameter and measuring first-harmonic gain and phase errors relative to exact solutions. Across five closed-form problem families, models exhibit systematic low-pass behavior with frequency-dependent gain loss and phase lag—even when static accuracy is high. DeepSeek V3.1 achieves the best overall dynamics (MB-Core 0.834, MB-Plus 0.656), while other models show notable amplitude distortions in ratio/saturation and timing errors in linear systems. The protocol surfaces reasoning stability issues that final-answer accuracy alone obscures, providing a compact, reproducible metric for model selection and robustness assessment.

## Method Summary
MathBode drives a single problem parameter sinusoidally (p_t = p_0 + εsin(ωt + φ_0)) across five closed-form families, then fits first-harmonic responses of model outputs and exact solutions. From least-squares regression onto {sin(ωt), cos(ωt), 1}, the method extracts gain (amplitude ratio) and phase (timing lag) at each frequency, supplemented by R², residual autocorrelation, and nonlinearity diagnostics. Mid-band frequencies {4, 8} are emphasized to avoid Nyquist artifacts, with MB-Core aggregating gain/phase deviations and MB-Plus adding penalties for poor fit quality. A symbolic baseline validates instrument calibration (G ≈ 1, φ ≈ 0).

## Key Results
- Models exhibit systematic low-pass behavior: gain loss and phase lag increase with frequency, even at high static accuracy
- DeepSeek V3.1 achieves best overall stability (MB-Core 0.834, MB-Plus 0.656), Mixtral 8×7B worst (MB-Core 0.581, MB-Plus 0.501)
- Linear System shows largest inter-model spread (DeepSeek 0.331 vs. Mixtral 0.029 on MB-Core), while Similar Triangles stays near perfect across all models
- Residual diagnostics reveal that R² drops and autocorrelation rises in Exponential Interest and Linear System, indicating emergent nonlinearities rather than random noise

## Why This Works (Mechanism)

### Mechanism 1: First-Harmonic Response Fitting
- Claim: Sinusoidal parameter sweeps reveal amplitude tracking (gain) and timing (phase) errors that static accuracy metrics miss
- Core assumption: First-harmonic approximation sufficiently captures the dominant response mode for closed-form mathematical problems
- Evidence anchors: Abstract states method yields interpretable, frequency-resolved metrics—gain (amplitude tracking) and phase (lag); section 2 details regression onto {sin(ωt), cos(ωt), 1}; no comparable frequency-domain LLM evaluation methods found
- Break condition: If R² drops significantly (<0.7) or residual ACF(1) shows strong positive autocorrelation, first-harmonic model is insufficient

### Mechanism 2: Frequency-Resolved Low-Pass Detection
- Claim: Models exhibit systematic low-pass behavior (gain loss, phase lag) that correlates with problem complexity but not necessarily with static accuracy
- Core assumption: Frequency-dependent gain/phase patterns reflect reasoning stability rather than training data memorization or recall
- Evidence anchors: Abstract notes systematic low-pass behavior with frequency-dependent gain loss and phase lag even when static accuracy is high; Table 3 shows Linear System largest inter-model spread; cross-domain validity suggested by control systems frequency analysis literature
- Break condition: If gain/phase patterns are inconsistent across start phases {0°, 120°, 240°}, response is phase-dependent and not interpretable as stable system behavior

### Mechanism 3: Multi-Axis Residual Diagnostics
- Claim: Residual autocorrelation, R², and H2/H1 nonlinearity proxy distinguish structured reasoning errors from random noise
- Core assumption: High residual structure reflects reasoning inconsistencies rather than mere numeric precision limitations
- Evidence anchors: Section 2 notes R² and residual diagnostics validate first-harmonic approximation and expose unexplained structure; section 4 shows R² near 1 for Similar Triangles, drops in Exponential Interest and Linear System point to emergent nonlinearities; spectral diagnostics literature supports broader applicability
- Break condition: If compliance drops below 95%, residual diagnostics may conflate formatting failures with reasoning quality issues

## Foundational Learning

- Concept: Bode plots and frequency response analysis
  - Why needed here: MathBode borrows directly from control theory—understanding gain (amplitude ratio) and phase (timing lag) across frequencies is essential for interpreting the diagnostic
  - Quick check question: If a system shows G=0.5 and φ=-45° at ω=4, what does this tell you about its output amplitude and timing relative to input?

- Concept: First-harmonic / fundamental frequency fitting
  - Why needed here: The method projects outputs onto a sine/cosine basis; understanding least-squares regression onto trigonometric basis functions is required
  - Quick check question: Given samples y(t_i), how would you formulate the least-squares problem to fit y(t) ≈ a sin(ωt) + b cos(ωt) + c?

- Concept: Parametric problem families with closed-form solutions
  - Why needed here: MathBode requires exact solutions as ground truth; understanding why these five families were chosen (linear, saturating, exponential, coupled, proportional) informs extension to new domains
  - Quick check question: Why might Exponential Interest (compounding) exhibit different nonlinearity profiles (H2/H1) than Linear Solve?

## Architecture Onboarding

- Component map: Problem generator -> Model inference -> Strict parser -> Harmonic fitter -> Score aggregator
- Critical path: Generate sweep (47,040 rows) → Model inference → Parse → Fit first harmonic → Aggregate scores. Always run symbolic baseline first to verify calibration (G ≈ 1, φ ≈ 0).
- Design tradeoffs:
  - T=64 with ω ∈ {1, 2, 4, 8, 16} balances frequency resolution against inference cost
  - Mid-band emphasis ({4, 8}) avoids Nyquist artifacts at ω=16
  - Temperature 0 ensures reproducibility but may mask sampling variability
  - Single-tone drive is analytically simple but cannot capture multi-frequency interactions
- Failure signatures:
  - Low compliance (<95%): Check answer tag formatting, model output structure
  - R² < 0.7 at mid-band: Model outputs poorly described by single sinusoid; inspect raw outputs for erratic values
  - Residual ACF(1) > 0.3: Temporal structure not captured; consider richer probe signals
  - Inconsistent gain/phase across start phases: Phase-dependent behavior invalidates single-curve interpretation
  - MB-Core >> MB-Plus gap: High nonlinearity or poor fit quality penalizing MB-Plus
- First 3 experiments:
  1. Validate symbolic baseline: Run symbolic solver on all five families at ω ∈ {4, 8}; verify G ≈ 1 ± 0.01, |φ| < 1°, R² > 0.999
  2. Single-model frequency sweep: Test one model (e.g., GPT-4o) on Linear Solve and Exponential Interest across ω ∈ {1, 2, 4, 8, 16}; plot gain/phase curves to observe low-pass rolloff
  3. Reproduce inter-model gaps: Compare DeepSeek V3.1 vs. Mixtral 8×7B on Linear System and Ratio Saturation; expect largest MB-Core differences (Linear System: 0.331 vs. 0.029; Ratio Saturation: 0.997 vs. 0.000)

## Open Questions the Paper Calls Out

- How do MathBode frequency fingerprints correlate with internal model mechanisms, such as attention head dynamics or layer-wise delays?
  - Basis in paper: Conclusion identifies need to "link frequency fingerprints to internal mechanisms (e.g., attention dynamics, layer-wise delays)"
  - Why unresolved: Current work treats LLM as black-box system, measuring input-output stability without analyzing internal activation states causing observed phase lag
  - What evidence would resolve it: Mechanistic interpretability studies mapping specific attention heads or layers responsible for amplitude attenuation and timing errors

- Do models exhibit similar dynamic instability when driven by non-sinusoidal inputs like chirps or step functions?
  - Basis in paper: Authors explicitly limit scope to "single-tone drives" and list adding "richer inputs (chirps, steps)" as future work
  - Why unresolved: Unclear if observed low-pass behavior is artifact of single-frequency probing method or fundamental property of model's reasoning process
  - What evidence would resolve it: Extension to sweep frequencies simultaneously (chirps) or introduce sudden parameter changes (steps) to compare transient responses

- Can optimizing for MathBode metrics (gain/phase fidelity) directly improve performance on standard static benchmarks?
  - Basis in paper: Paper establishes high static accuracy can mask dynamic instability, suggesting metrics are complementary, but does not test if fixing dynamics improves accuracy
  - Why unresolved: Provides diagnostic tool but does not explore inverse relationship—whether reducing phase lag or gain error serves as training objective to enhance general reasoning robustness
  - What evidence would resolve it: Training run or fine-tuning experiment where models optimized using loss function derived from MathBode gain/phase errors, followed by evaluation on GSM8K or MATH

## Limitations

- The five problem families, while mathematically diverse, represent closed-form symbolic reasoning tasks, leaving unclear how well frequency-response stability generalizes to more complex, open-ended reasoning domains
- MB-Core and MB-Plus scoring functions involve unspecified normalization constants and aggregation formulas, making exact replication challenging without access to codebase
- Frequency-domain stability claims hinge on first-harmonic approximation holding across all problem families and model responses, with insufficient established robustness thresholds for breakdown

## Confidence

- High confidence: Fundamental mechanism of sinusoidal parameter sweeping and first-harmonic fitting is well-specified and reproducible; symbolic baseline validation demonstrates instrument calibration
- Medium confidence: Interpretation of gain/phase patterns as stability indicators is plausible but relies on assumption that frequency-domain behavior reflects reasoning quality rather than training data patterns or numerical precision limits
- Low confidence: Comparative rankings across models (e.g., DeepSeek V3.1 superiority) are specific to chosen problem families and may not generalize to other mathematical domains or reasoning tasks

## Next Checks

1. **Threshold validation**: Systematically vary R² thresholds (0.7, 0.8, 0.9) and assess impact on MB-Core/MB-Plus rankings across all five families
2. **Cross-domain generalization**: Apply MathBode to at least one non-closed-form problem (e.g., numerical integration or optimization) to test stability metric transferability
3. **Calibration verification**: Reproduce symbolic baseline on all five families at mid-band frequencies and verify that G ≈ 1 ± 0.01, |φ| < 1°, and R² > 0.999 across all cases