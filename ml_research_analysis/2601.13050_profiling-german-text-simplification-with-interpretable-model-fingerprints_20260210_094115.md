---
ver: rpa2
title: Profiling German Text Simplification with Interpretable Model-Fingerprints
arxiv_id: '2601.13050'
source_url: https://arxiv.org/abs/2601.13050
tags:
- simplification
- text
- https
- profiler
- german
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Simplification Profiler, a diagnostic
  toolkit that generates multidimensional, interpretable fingerprints of simplified
  texts to diagnose the nuanced behavior of Large Language Models (LLMs) in text simplification.
  Instead of relying on monolithic evaluation metrics, the Profiler uses compositional
  analysis of specific linguistic properties like semantic fidelity, linguistic quality,
  and coherence to provide granular insights.
---

# Profiling German Text Simplification with Interpretable Model-Fingerprints

## Quick Facts
- arXiv ID: 2601.13050
- Source URL: https://arxiv.org/abs/2601.13050
- Authors: Lars KlÃ¶ser; Mika Beele; Bodo Kraft
- Reference count: 40
- Primary result: 71.9% F1 classification of model configurations using interpretable fingerprints

## Executive Summary
This paper introduces the Simplification Profiler, a diagnostic toolkit that generates multidimensional, interpretable fingerprints of simplified texts to diagnose the nuanced behavior of Large Language Models (LLMs) in text simplification. Instead of relying on monolithic evaluation metrics, the Profiler uses compositional analysis of specific linguistic properties like semantic fidelity, linguistic quality, and coherence to provide granular insights. A meta-evaluation demonstrates that the Profiler's complete feature set enables a linear classifier to distinguish high-level variations (e.g., prompting strategies) and fine-grained changes (e.g., few-shot examples) in generated simplifications, achieving classification F1-scores up to 71.9%, improving upon simple baselines by over 48 percentage points. The tool offers developers a transparent, actionable analysis to build more effective and adaptive text simplification systems, particularly valuable for languages like German where data scarcity limits traditional evaluation methods.

## Method Summary
The paper proposes a diagnostic toolkit that generates interpretable fingerprints for German text simplification by analyzing 23 linguistically grounded metrics across three dimensions: semantic fidelity (COR, COV), linguistic quality (SIM, LNG), and coherence (COH, LEN, ENT, ASL). The method involves generating simplifications using Gemma models (1B, 4B, 12B) with four prompting strategies (Plain, Target, Rules, Content) and few-shot variants, computing the fingerprint features for each output, and training a Logistic Regression classifier to identify the source configuration. The evaluation uses German Wikipedia excerpts segmented into 5-sentence windows, with a greedy sampling algorithm constructing a 1,000-example subset ensuring coverage of rare linguistic phenomena. The complete feature set enables classification F1-scores up to 71.9% for the 1B model, significantly outperforming random and simple baselines that use only length features.

## Key Results
- 71.9% F1 score achieved for classifying 1B model configurations using complete fingerprint feature set
- 48+ percentage point improvement over baselines using only length features (6 metrics)
- "Middle-ground problem" observed: 4B model achieves only 3.4% F1 in multi-class setting but improves to 72.2% in pairwise classification
- Complete feature set enables detection of both high-level variations (prompting strategies) and fine-grained changes (few-shot examples)

## Why This Works (Mechanism)
The Simplification Profiler works by decomposing text simplification evaluation into interpretable, compositional features that capture specific linguistic properties. Instead of treating simplification as a monolithic task, the Profiler analyzes semantic fidelity through NLI-based metrics (COR for correctness, COV for coverage), linguistic quality through LanguageTool-based metrics (SIM for simplicity, LNG for grammatical correctness), and coherence through sentence embeddings (COH) along with readability (FBR), length (LEN), entropy (ENT), and average sentence length (ASL). This multidimensional approach creates a fingerprint that captures the nuanced behavior of different model configurations and prompting strategies, enabling a linear classifier to distinguish between them based on their characteristic feature patterns rather than relying on a single aggregated score.

## Foundational Learning
- **German Wikipedia text segmentation**: Why needed - Source data for simplification; Quick check - Verify 5-sentence window segmentation produces coherent passages
- **NLI-based semantic fidelity metrics**: Why needed - Quantify preservation of meaning during simplification; Quick check - Test COR/COV metrics on controlled simplification pairs
- **LanguageTool-based linguistic quality metrics**: Why needed - Detect grammatical and stylistic issues in German; Quick check - Validate SIM/LNG metrics against known correct/incorrect examples
- **Sentence embedding coherence metrics**: Why needed - Measure discourse-level consistency in simplified texts; Quick check - Compare COH scores for coherent vs. incoherent text pairs
- **Greedy sampling for evaluation subset**: Why needed - Ensure coverage of rare linguistic phenomena; Quick check - Verify sampling algorithm produces balanced distribution across phenomena
- **Multi-dimensional fingerprint construction**: Why needed - Create interpretable diagnostic features; Quick check - Confirm all 23 features are computable and meaningful

## Architecture Onboarding

Component Map: German Wikipedia -> Text Segmentation -> Gemma Models (1B/4B/12B) -> Prompt Strategies (Plain/Target/Rules/Content) -> Simplification Generation -> Fingerprint Computation (23 metrics) -> Logistic Regression Classifier -> Configuration Prediction

Critical Path: The critical path involves generating simplifications with specific model/prompt configurations, computing the complete fingerprint feature set, and training the classifier to predict the source configuration. The most sensitive components are the prompt templates (which are only described, not provided) and the NLI/sentence embedding models used for semantic and coherence metrics.

Design Tradeoffs: The Profiler trades computational simplicity (linear classifier) for feature complexity (23 metrics), prioritizing interpretability over black-box performance. The choice of German-specific tools (LanguageTool, German Wikipedia) limits generalizability but provides domain-specific insights. The focus on compositional analysis sacrifices the simplicity of monolithic metrics for granular diagnostic power.

Failure Signatures: Low classification F1 scores indicate either insufficient feature differentiation between configurations or problems with the simplification generation process. The "middle-ground problem" (4B model achieving only 3.4% F1) suggests that intermediate model sizes may produce outputs too similar to distinguish. Inconsistent FBR scores indicate problems with German-specific preprocessing or syllable counting.

First Experiments:
1. Implement and test the 9 explicitly specified fingerprint metrics on a small sample of simplifications to verify they produce meaningful values
2. Generate simplifications using one model size and one prompt strategy to establish baseline fingerprint patterns
3. Train a simple classifier on a minimal feature set to verify the end-to-end pipeline works before scaling to full 23-feature analysis

## Open Questions the Paper Calls Out
None

## Limitations
- Prompt templates and few-shot examples are only described but not provided, limiting faithful reproduction
- 14 of 23 fingerprint features are unspecified, creating uncertainty about the complete methodology
- NLI and sentence embedding models used for key metrics are not specified, requiring assumptions
- Results depend on the specific linguistic phenomena distribution in the 1,000-example evaluation set
- German-specific focus limits generalizability to other languages despite potential applicability

## Confidence

High confidence:
- General framework of using interpretable fingerprints for model configuration diagnosis
- Methodology for compositional analysis is clearly specified
- "Middle-ground problem" observation aligns with model behavior explanations

Medium confidence:
- Specific F1-score values and improvement margins over baselines
- Classification performance depends on correct implementation of all 23 features
- Results may vary without complete feature specifications and prompt templates

Low confidence:
- Claims about German-specific applicability and data scarcity advantages
- Cannot fully validate without access to complete German Wikipedia corpus
- Comparison against other German simplification approaches not possible

## Next Checks

1. Implement and test the full set of 23 fingerprint features using placeholder values for the 14 unspecified metrics to assess whether classification performance degrades significantly, indicating whether these features are critical to the results.

2. Replicate the pairwise classification experiments (Table 3) for the 1B model using only the 9 explicitly specified features to determine the minimum viable feature set required for achieving the reported 71.9% F1 score.

3. Conduct an ablation study removing individual prompt strategies (Plain, Target, Rules, Content) to identify which strategies contribute most to classification performance and whether the 48+ percentage point improvement over baselines holds when only the most effective strategies are used.