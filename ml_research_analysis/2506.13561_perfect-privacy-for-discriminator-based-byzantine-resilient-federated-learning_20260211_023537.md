---
ver: rpa2
title: Perfect Privacy for Discriminator-Based Byzantine-Resilient Federated Learning
arxiv_id: '2506.13561'
source_url: https://arxiv.org/abs/2506.13561
tags:
- users
- federator
- privacy
- learning
- secret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ByITFL and LoByITFL, two novel federated
  learning schemes that simultaneously achieve Byzantine resilience, Information-Theoretic
  privacy, and dropout tolerance. ByITFL uses Lagrange Coded Computing with re-randomization
  to achieve perfect privacy at high communication cost, while LoByITFL reduces communication
  overhead by using a Trusted Third Party only during initialization.
---

# Perfect Privacy for Discriminator-Based Byzantine-Resilient Federated Learning

## Quick Facts
- **arXiv ID:** 2506.13561
- **Source URL:** https://arxiv.org/abs/2506.13561
- **Reference count:** 40
- **Primary result:** Introduces ByITFL and LoByITFL, achieving Byzantine resilience, Information-Theoretic privacy, and dropout tolerance simultaneously

## Executive Summary
This paper presents two novel federated learning schemes, ByITFL and LoByITFL, that simultaneously achieve Byzantine resilience, Information-Theoretic privacy, and dropout tolerance. ByITFL uses Lagrange Coded Computing with re-randomization to achieve perfect privacy at high communication cost, while LoByITFL reduces communication overhead by using a Trusted Third Party only during initialization. Both schemes employ a discriminator function based on polynomial approximations to assign trust scores to users, enabling robust aggregation. Theoretical guarantees on privacy, Byzantine resilience, and convergence are provided, with experimental results demonstrating comparable performance to existing methods under various Byzantine attacks.

## Method Summary
The paper proposes two federated learning schemes that use polynomial discriminator functions and secure aggregation to achieve Byzantine resilience with information-theoretic privacy. ByITFL uses Lagrange Coded Computing with re-randomization, requiring no trusted third party but incurring O(n⁴) communication complexity. LoByITFL uses Beaver triples with MACs and a trusted third party during initialization only, reducing communication to O(n²). Both schemes employ a degree-3 polynomial to approximate ReLU for trust score computation based on cosine similarity between user updates and the federator's update. The aggregation uses weighted averaging where trust scores determine the weights, with theoretical guarantees on privacy, Byzantine resilience, and convergence under standard assumptions.

## Key Results
- ByITFL and LoByITFL achieve information-theoretic privacy against up to t colluding users
- Both schemes tolerate up to b Byzantine users and e dropouts with provable convergence guarantees
- Experimental results show comparable performance to existing methods on MNIST, Fashion MNIST, and CIFAR-10
- ByITFL achieves privacy without trusted third party but at O(n⁴) communication cost
- LoByITFL reduces communication to O(n²) by using TTP only during initialization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Polynomial discriminator functions can replace ReLU for trust score computation while remaining compatible with secret-sharing-based privacy.
- Mechanism: Instead of ReLU(cos(θᵢ)) which requires comparison operations difficult to compute privately, the scheme uses a degree-3 polynomial h(⟨ū₀, ūᵢ⟩) that mimics ReLU's behavior. Updates opposing the federator's direction receive small trust scores, while aligned updates receive proportionally higher scores. The polynomial form enables computation over secret shares via Lagrange Coded Computing's homomorphic properties.
- Core assumption: Byzantine adversaries cannot extract more benefit from negative trust scores than from simply flipping their update direction.
- Evidence anchors: [abstract] "crafting a discriminator function allowing the mitigation of corrupt users' contributions"; [Section VI-A] "it is not required to accurately approximate the ReLU function by high-degree polynomials... instead, we carefully choose a degree-3 polynomial"; [corpus] Related work (Brave, Nesterov-Accelerated Robust FL) uses different aggregation rules; this approach specifically targets cosine-similarity-based trust scoring.

### Mechanism 2
- Claim: Lagrange Coded Computing with re-randomization achieves perfect information-theoretic privacy against colluding users and the federator.
- Mechanism: Each local update is partitioned into m sub-vectors and encoded via degree-(m+t-1) polynomial with t random terms. Any t colluding users see statistically independent shares. After computing the aggregation polynomial, re-randomization (sub-sharing shares via ITVSS and linear combining) creates new encoding polynomials, hiding even the aggregated values until final reconstruction. The federator only observes λΣ₁ and λΣ₂, revealing only the quotient ν = Σ₂/Σ₁.
- Core assumption: Finite field size p ≥ 2ndτq^(2τ+1) + 1 prevents wrap-around; random λ ≠ 0.
- Evidence anchors: [abstract] "ByITFL employs Lagrange coded computing and re-randomization, making it the first Byzantine-resilient FL scheme with perfect Information-Theoretic (IT) privacy"; [Section IV-D] "To this end, each user i: (a) chooses an independent value λᵢ uniformly at random... (c) multiplies Σ₁[i] and Σ₂[i] by λ[i] and performs re-randomization"; [corpus] ByITFL precursor paper (arXiv:2405.08698) provides foundational analysis.

### Mechanism 3
- Claim: Beaver triples with MACs enable multiplicative homomorphism at reduced communication cost while preserving integrity.
- Mechanism: A Trusted Third Party distributes pre-generated Beaver triples (γ, ω, κ = γω) and one-time MAC keys during initialization. During training, users compute products like ⟨ū₀, ūᵢ⟩ by revealing s−γ and v−ω (masked values), then locally computing (sv)[i]. The MAC allows the federator to verify computation correctness without learning individual values. This avoids re-randomization overhead.
- Core assumption: TTP is honest during initialization only; MAC forgery probability (1/p per scalar) is negligible for large p.
- Evidence anchors: [abstract] "LoByITFL... requires a Trusted Third Party, used only in a one-time initialization phase before training"; [Section V] "The TTP generates a sufficient number of Beaver triples... sends ri, rj[i] for j ∈ [n], and λ[i] to user i"; [corpus] LoByITFL paper (arXiv:2405.19217) provides detailed comparison with ByITFL.

## Foundational Learning

- Concept: **Threshold Secret Sharing (Shamir/LCC)**
  - Why needed here: Understanding how secrets encoded as polynomial evaluations can be distributed such that any t shares reveal nothing, but k shares enable reconstruction.
  - Quick check question: Given shares of two values s[i] and v[i], can you compute shares of s + v locally? What about s·v?

- Concept: **Beaver Triples for Secure Multiplication**
  - Why needed here: Enables multiplication over secret shares without revealing operands, by using pre-distributed random masks.
  - Quick check question: If you hold shares of s, v, γ, ω, κ, what must be revealed publicly to compute shares of s·v?

- Concept: **Reed-Solomon Error Correction and Byzantine Resilience**
  - Why needed here: Byzantine contributions are treated as errors in RS codewords; understanding the relationship between code parameters (n, k, distance) and tolerable Byzantine/dropout counts.
  - Quick check question: With n users, b Byzantine, e dropouts, what's the minimum n needed to decode correctly if the polynomial degree is d?

## Architecture Onboarding

- **Component map:**
  - Users → Secret Sharing Module → ITVSS (ByITFL) or TTP (LoByITFL) → Federator
  - Federator → Global Model → Users
  - Users → Local Updates → Aggregation

- **Critical path:**
  1. Normalization + quantization (all parties)
  2. Secret sharing of updates (users → users)
  3. Norm validation via shares (users → federator)
  4. Trust score computation via polynomial on shares (users)
  5. Weighted aggregation on shares with random λ masking (users)
  6. Reconstruction of λΣ₁, λΣ₂ (federator)
  7. Global model update: ν = λΣ₂/λΣ₁, direction check, normalization

- **Design tradeoffs:**
  - ByITFL vs LoByITFL: ByITFL (O(n⁴) user communication) requires no TTP; LoByITFL (O(n²)) requires TTP
  - Partition parameter m: Higher m reduces per-share dimension but increases minimum user count requirement
  - Discriminator degree τ: Higher τ enables better ReLU approximation but increases communication (LoByITFL) and minimum n (both)

- **Failure signatures:**
  - **Decoding failure:** n < 2b + (τ+2)(m+t-1) + e + 1 (ByITFL) or n < b + m + t + e (LoByITFL)
  - **Privacy breach via wrap-around:** p too small for model dimension d and quantization level q
  - **MAC forgery (LoByITFL):** TTP generates non-random β values or reuses MAC keys
  - **Byzantine normalization bypass:** ε threshold set too high, allowing magnitude manipulation

- **First 3 experiments:**
  1. **Baseline convergence:** Train without Byzantine users on MNIST/CIFAR-10, comparing degree-3 polynomial discriminator vs ReLU (FLTrust) to verify approximation quality doesn't degrade accuracy.
  2. **Byzantine attack surface:** Inject b Byzantine users with label flipping and scaling attacks; verify that the scheme maintains accuracy within 2-3% of baseline while FedAvg collapses.
  3. **Communication scaling:** Measure per-iteration communication for ByITFL and LoByITFL with n=40, d=1M parameters, varying m=1,5,10 to validate O(n³) vs O(n²) scaling claims.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can meaningful theoretical guarantees for Byzantine-resilient aggregation be established without relying on restrictive assumptions like a root dataset?
- Basis in paper: [explicit] The conclusion states that "Establishing meaningful theoretical guarantees for robust aggregation with less restrictive assumptions, is yet unsolved."
- Why unresolved: The proposed schemes depend on the federator holding a representative root dataset (D₀) to bootstrap trust, which may not be feasible in all settings.
- Evidence: A convergence proof for a Byzantine-resilient, IT-private FL scheme that does not require a root dataset.

### Open Question 2
- Question: What constitutes a systematic theoretical understanding of cosine-similarity based Byzantine resilience?
- Basis in paper: [explicit] The authors state that "Byzantine resilience approaches based on cosine-similarity are still not fully understood, and a systematic and careful study remains an open problem."
- Why unresolved: While empirically effective, the approach may have specific weaknesses (e.g., to backdoor attacks) that are not fully theoretically characterized.
- Evidence: A comprehensive theoretical framework defining the exact bounds of resilience and potential failure modes for cosine-similarity discriminators.

### Open Question 3
- Question: What is the optimal polynomial discriminator function for private federated learning?
- Basis in paper: [inferred] The paper notes there is "no proof or principled reason to believe that the ReLU is the best discriminator function" and selects a degree-3 polynomial heuristically.
- Why unresolved: The authors designed a specific polynomial to approximate ReLU, but it is unknown if this shape maximizes convergence speed or robustness.
- Evidence: A theoretical derivation of an optimal polynomial function h(x) that provably maximizes the convergence bound.

## Limitations

- Privacy guarantees are theoretically sound but practically constrained by prohibitive finite field size requirements for high-dimensional models
- ByITFL's O(n⁴) communication complexity creates scalability barriers, while LoByITFL's TTP reliance introduces single-point-of-failure risk
- Most convergence guarantees assume convexity, which doesn't hold for deep neural networks used in experiments

## Confidence

**High Confidence** (Well-supported by theory and experimental evidence):
- Byzantine resilience mechanism: The polynomial discriminator function and aggregation rule are mathematically sound and validated against multiple attack types
- Convergence guarantees: The scheme converges under standard FL assumptions (strongly convex objectives, bounded gradients)
- Dropout tolerance: The Reed-Solomon coding structure inherently provides the stated dropout tolerance

**Medium Confidence** (Theoretical but with practical concerns):
- Information-theoretic privacy: The privacy proof holds mathematically, but practical implementation constraints (field size, wrap-around) may degrade guarantees
- Communication efficiency claims: While asymptotic complexity is proven, real-world performance with large models remains unverified

**Low Confidence** (Theoretical assumptions with limited validation):
- TTP initialization security: The single-point-of-failure nature of TTP is acknowledged but not stress-tested
- Generalization to non-convex objectives: Most convergence guarantees assume convexity, which doesn't hold for deep neural networks

## Next Checks

1. **Field Size Feasibility Study:** Implement a prototype with a 64-bit prime field and test whether privacy guarantees hold for realistic model sizes (ResNet-18/CNN on CIFAR-10) without wrap-around. Measure the probability of field overflow under typical quantization levels (q=2^8, q=2^16).

2. **Communication Overhead Benchmarking:** Implement both ByITFL and LoByITFL and measure actual communication costs for n=40 users with ResNet-18 (21M parameters). Compare against baseline FedAvg and secure aggregation schemes like Brave to validate the O(n⁴) vs O(n²) claims.

3. **TTP Compromise Analysis:** Conduct a threat modeling exercise where the TTP is compromised during initialization. Can an attacker extract secrets that enable future reconstruction of user updates? Develop and test mitigation strategies (e.g., multi-party computation for Beaver triple generation).