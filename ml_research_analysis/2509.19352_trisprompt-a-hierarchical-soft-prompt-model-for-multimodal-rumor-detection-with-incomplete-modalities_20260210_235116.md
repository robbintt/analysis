---
ver: rpa2
title: 'TriSPrompt: A Hierarchical Soft Prompt Model for Multimodal Rumor Detection
  with Incomplete Modalities'
arxiv_id: '2509.19352'
source_url: https://arxiv.org/abs/2509.19352
tags:
- prompt
- detection
- missing
- uni00000013
- modality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'TriSPrompt tackles multimodal rumor detection with incomplete
  data by introducing a hierarchical soft prompt framework. It combines three prompts:
  modality-aware (recovering missing features using available modality information),
  modality-missing (encoding missing state indicators), and mutual-views (modeling
  relationships between subjective and objective perspectives in rumors).'
---

# TriSPrompt: A Hierarchical Soft Prompt Model for Multimodal Rumor Detection with Incomplete Modalities

## Quick Facts
- **arXiv ID**: 2509.19352
- **Source URL**: https://arxiv.org/abs/2509.19352
- **Reference count**: 24
- **Primary result**: Over 13% accuracy improvement vs. state-of-the-art on multimodal rumor detection with incomplete data

## Executive Summary
TriSPrompt introduces a hierarchical soft prompt framework for multimodal rumor detection when data is incomplete. The model employs three specialized prompts: Modality-Aware (MA) for reconstructing missing features using correlations between available modalities, Modality-Missing (MM) for encoding missing state indicators, and Mutual-Views (MV) for modeling relationships between subjective (text/image) and objective (comment) perspectives. Experiments on three real-world datasets demonstrate significant performance gains over state-of-the-art methods, with robust handling of high missing rates and strong ablation results confirming each component's importance.

## Method Summary
TriSPrompt uses a hierarchical architecture with VAE encoders for each modality, followed by three learnable soft prompts. The MA prompt reconstructs missing modality features by averaging available latent vectors and decoding them, capturing both heterogeneous and homogeneous cross-modal information. The MM prompt is a learnable embedding that flags missing modalities to the classifier. The MV prompt employs a hierarchical structure with downsampling, cross-enhancement, and upsampling to model subjective-objective relationships. The model is trained end-to-end with classification loss, KL divergence for VAE regularization, and reconstruction loss for available modalities only.

## Key Results
- Achieves over 13% accuracy improvement compared to state-of-the-art methods
- Maintains robust performance even under high missing rates (up to 70% modality loss)
- Ablation studies confirm importance of each prompt component (2-3% accuracy drop each)
- Outperforms MRD, IML, and MLLM baselines in accuracy, efficiency, and memory usage

## Why This Works (Mechanism)

### Mechanism 1: Modality Inpainting via Heterogeneous/Homogeneous Prompts
The MA prompt leverages shared latent correlations between available modalities to reconstruct missing features. By averaging latent vectors from available modalities and decoding them through the prompt, it "hallucinates" missing data in a controlled latent space rather than pixel/token space. This works when modalities share statistical correlation but fails if they're statistically independent.

### Mechanism 2: Missing-State Awareness
The MM prompt explicitly flags which modalities are reconstructed versus original, allowing the classifier to weigh uncertainty appropriately. This learnable embedding concatenated to feature vectors acts as a "confidence tag" that theoretically enables the attention mechanism to discount features from reconstruction.

### Mechanism 3: Perspective Disentanglement
The MV prompt uses hierarchical structure to model the contradiction or consistency between subjective publisher views (Text/Image) and objective crowd views (Comments). By first fusing subjective modalities then using this context to enhance objective features, it captures the "reaction to the content" that's critical for rumor detection.

## Foundational Learning

- **Concept**: Variational Autoencoders (VAE)
  - **Why needed here**: VAE encoders map inputs to distributions (μ, σ), providing regularized latent spaces for MA prompt reconstruction
  - **Quick check question**: Why is minimizing KL divergence necessary for reconstruction loss to function effectively?

- **Concept**: Soft Prompting (vs. Hard Prompting)
  - **Why needed here**: Learnable continuous vectors optimized via backpropagation shape the latent space for MA and MM mechanisms
  - **Quick check question**: How does a soft prompt differ from a standard dense layer, and why is it treated as a distinct input prefix?

- **Concept**: Cross-Attention Mechanisms
  - **Why needed here**: MV prompt relies on cross-attention to fuse subjective and objective views
  - **Quick check question**: In the cross-attention step (p_sub vs z_T/ẑ_I), which modality serves as Query and which as Key/Value?

## Architecture Onboarding

- **Component map**: Input Layer (BERT/ResNet) → VAE Encoders → MA Module → MM Module → MV Module → Classifier
- **Critical path**: Encoding → Reconstruction (MA) → Flagging (MM) → Perspective Fusion (MV)
- **Design tradeoffs**: Prompt length (L_aware=32 optimal), missing rate tolerance (degrades after R_m=0.7), computational overhead vs. efficiency gains
- **Failure signatures**: Posterior collapse (KL→0), over-smoothing (generic reconstructions), gradient starvation (MM prompt learns too quickly)
- **First 3 experiments**:
  1. Reconstruction Quality Check: Measure cosine similarity between MA-reconstructed and ground-truth embeddings
  2. Ablation on Prompts: Remove MA/MM/MV prompts individually to verify ~2-3% ACC drop each
  3. Missing Rate Stress Test: Sweep R_m from 0.0 to 0.7 and plot accuracy curve vs. baseline

## Open Questions the Paper Calls Out

### Open Question 1
**Question**: How can TriSPrompt be integrated with Large Language Models to better handle real-world multimodal rumor data complexity?
**Basis in paper**: [explicit] Limitations section suggests current method "falls short" and future works with LLMs would solve this problem
**Why unresolved**: Current architecture relies on specific encoder-decoder structures while LLMs offer generative capabilities and external knowledge not explored
**What evidence would resolve it**: New model variant demonstrating superior performance on noisy, "in-the-wild" datasets

### Open Question 2
**Question**: How can modality recovery be improved when only comments (objective) are available for reconstructing subjective modalities?
**Basis in paper**: [explicit] Appendix D states comment-only reconstruction fails because comments lack intrinsic subjective information
**Why unresolved**: Current MA prompt averages available features, insufficient to bridge semantic gap between objective comments and subjective source content
**What evidence would resolve it**: Quantitative results showing successful reconstruction from "Only Comments Available" case

### Open Question 3
**Question**: Does TriSPrompt maintain robustness when modality missingness is systematic (MNAR) rather than random (MCAR)?
**Basis in paper**: [inferred] Current evaluation uses random missing protocol, but real-world missingness may correlate with content type
**Why unresolved**: Model trained on random dropout untested on correlated absence patterns
**What evidence would resolve it**: Results using structured missing protocol where modalities absent for specific rumor classes

## Limitations

- Architectural details underspecified (VAE layer counts, cross-attention configurations, Conv/RB parameters)
- Reconstruction mechanism depends on strong shared latent space assumptions that may not hold
- MM prompt effectiveness relies on implicit rather than explicit weighting mechanism
- Random missing protocol may not reflect real-world systematic missingness patterns

## Confidence

**High Confidence**: 13%+ accuracy improvement claims well-supported by comprehensive experiments across three datasets with multiple baselines; ablation study directly measured
**Medium Confidence**: Mechanism explanations for MA prompt reconstruction and MM prompt state-awareness theoretically sound but depend on unspecified implementation details
**Low Confidence**: Exact architectural configurations required for faithful reproduction not provided; robustness claims under high missing rates sensitive to implementation specifics

## Next Checks

1. **Reconstruction Quality Verification**: Implement MA prompt reconstruction on held-out test set with synthetically removed modalities. Measure cosine similarity between reconstructed and ground-truth embeddings, verifying significant correlation that degrades gracefully with missing rates.

2. **Ablation Prompt Effectiveness**: Systematically remove MA, MM, and MV prompts individually from complete model on Weibo-19 dataset. Measure accuracy drops to verify they match reported ~2-3% per component.

3. **Missing Rate Robustness Curve**: Implement full missing rate sweep (R_m from 0.0 to 0.7) on Weibo-19 and plot accuracy curve against RedCore baseline, verifying smoother degradation and higher accuracy throughout range, especially at high missing rates.