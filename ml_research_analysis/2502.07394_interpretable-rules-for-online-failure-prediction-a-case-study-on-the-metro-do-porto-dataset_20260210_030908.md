---
ver: rpa2
title: 'Interpretable Rules for Online Failure Prediction: A Case Study on the Metro
  do Porto dataset'
arxiv_id: '2502.07394'
source_url: https://arxiv.org/abs/2502.07394
tags:
- failure
- data
- rules
- failures
- flowmeter
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses predictive maintenance for Metro do Porto
  trains, focusing on predicting failures in the Air Production Unit (APU). The authors
  propose an online rule-based explainability approach that generates interpretable
  rules for failure prediction using an Autoencoder architecture.
---

# Interpretable Rules for Online Failure Prediction: A Case Study on the Metro do Porto dataset

## Quick Facts
- arXiv ID: 2502.07394
- Source URL: https://arxiv.org/abs/2502.07394
- Authors: Matthias Jakobs; Bruno Veloso; Joao Gama
- Reference count: 22
- Primary result: Online rule-based explainability approach achieves perfect F1 score (1.0) for predicting Air Production Unit failures using only three sensors.

## Executive Summary
This study addresses predictive maintenance for Metro do Porto trains by developing an online rule-based approach for interpretable failure prediction. The authors propose using a Convolutional Autoencoder to detect anomalies in the Air Production Unit (APU) through reconstruction error, then extracting human-readable rules via decision tree training. By applying their method to the MetroPT2 dataset, they demonstrate that only three sensors—Flowmeter, Oil temperature, and Motor current—are sufficient to predict failures with simple threshold rules, achieving detection more than two hours before the Low Pressure Signal activates.

## Method Summary
The approach combines an online rule-learning algorithm with a Convolutional Autoencoder trained on failure-free data. Raw sensor data is processed into 30-minute windows with 5-minute strides, aggregated into summary statistics (mean, min, max, variance), and fed to the AE. Reconstruction error serves as an anomaly score, which is smoothed via low-pass filtering to reduce false positives. When failure probability exceeds thresholds, the system triggers rule learning on buffered data using decision trees, producing interpretable threshold rules. The method operates online with bounded memory requirements through state management (Normal/Warning/Failure).

## Key Results
- Perfect F1 score (1.0) achieved on MetroPT2 dataset with zero false positives
- Both failure types detected more than two hours before Low Pressure Signal activation
- Only three sensors required: Flowmeter, Oil temperature, and Motor current
- Simple interpretable rules extracted, such as "Flowmeter max > 16.05" for Air Leak detection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reconstruction error from an Autoencoder trained on failure-free data serves as a proxy for anomaly detection.
- Mechanism: The AE learns to compress and reconstruct normal operating patterns. When input data deviates significantly from training distribution (e.g., during failures), reconstruction error increases proportionally to the deviation magnitude.
- Core assumption: Failure modes produce sensor patterns that are meaningfully different from normal operation and are not well-reconstructed by the AE.
- Evidence anchors:
  - [abstract] "The authors propose an online rule-based explainability approach that generates interpretable rules for failure prediction using an Autoencoder architecture."
  - [Page 4] "For anomaly and failure detection, the expected reconstruction error for non-anomalous data is assumed to be significantly smaller than the reconstruction error of failures."
  - [corpus] Related work (Silva et al., 2023) achieved similar F1 scores using Wasserstein Autoencoder GAN, suggesting reconstruction-based approaches are effective for this dataset.

### Mechanism 2
- Claim: Low-pass filtering of binary anomaly predictions reduces false positives while preserving true failure detection.
- Mechanism: The smoothed output `z_t = z_{t-1} + α(y_t - z_{t-1})` creates inertia in the prediction signal. Transient anomalies (noise) are suppressed, while sustained anomalies (true failures) accumulate to exceed the failure threshold τ_fail = 0.5.
- Core assumption: True failures produce sustained high reconstruction errors over multiple consecutive windows, whereas false positives are transient.
- Evidence anchors:
  - [Page 4] "This reduces the false-positive rate because only prolonged occurrence of anomalous data points should be considered a failure."
  - [Page 7] "After fitting the model to the training data, we found that a smoothing factor α = 0.15 and an anomaly threshold of τ_anom = 3·q99 lead to a perfect F1 score."

### Mechanism 3
- Claim: Aggregating raw sensor values over windows (mean, min, max, variance) yields interpretable features for rule extraction.
- Mechanism: Instead of learning rules on 1800 individual timesteps per window, aggregation reduces dimensionality to 4×C interpretable statistics. Decision trees trained on these features produce human-readable threshold rules.
- Core assumption: Failure-relevant patterns manifest in summary statistics over 30-minute windows rather than fine-grained temporal dynamics.
- Evidence anchors:
  - [Page 5] "In this work, we utilize each windows' variance, minimum, maximum and mean value for higher interpretability."
  - [Page 7, Table 2] "Flowmeter max > 16.05" and "Flowmeter max > 16.18" as simple threshold rules for Air Leak and Oil Leak respectively.

## Foundational Learning

- Concept: **Autoencoders for anomaly detection**
  - Why needed here: The core failure detection mechanism relies on understanding how AE reconstruction error distinguishes normal from anomalous data.
  - Quick check question: Can you explain why an AE trained only on normal data will have higher reconstruction error for anomalous inputs?

- Concept: **Online/streaming learning with bounded memory**
  - Why needed here: The rule-learning algorithm operates on streaming data with history H and buffer B, requiring understanding of incremental updates and memory management.
  - Quick check question: What happens to the history buffer H if the system runs for months without failure—does it grow unbounded?

- Concept: **Threshold-based rule extraction from decision trees**
  - Why needed here: Rules like "Flowmeter max > 16.05" are extracted by training decision trees to perfect fit; understanding tree-to-rule conversion is essential.
  - Quick check question: How would you convert a decision tree path into a single conjunctive rule?

## Architecture Onboarding

- Component map:
  Data Preprocessing -> Convolutional Autoencoder -> Anomaly Scoring -> Smoothing Filter -> Rule Learner

- Critical path:
  1. Data ingestion (1 Hz sensor readings)
  2. Window creation (every 5 minutes, look back 30 minutes)
  3. AE reconstruction and error computation
  4. Smoothing and failure probability update
  5. State transition triggers rule learning on buffered data
  6. Rule extraction and storage

- Design tradeoffs:
  - **Window length (30 min) vs. detection latency**: Longer windows provide more stable features but delay detection.
  - **Smoothing factor (α=0.15) vs. responsiveness**: Lower α reduces false positives but slows failure confirmation.
  - **History size**: Currently unbounded; perfect rule fit requires all historical normal data, but this doesn't scale.
  - **Flowmeter inclusion vs. problem difficulty**: Including Flowmeter makes the problem trivially easy; excluding it requires more complex rules.

- Failure signatures:
  - **High reconstruction error without sustained increase**: Likely transient noise; check sensor quality.
  - **Rules failing to generalize**: History may not be representative; consider periodic rule retraining.
  - **Empty ruleset after failure**: Buffer may not have captured sufficient anomalous examples; adjust τ_warn.
  - **Rules dependent on Flowmeter only**: Dataset may be too easy; test on MetroPT3 for robustness.

- First 3 experiments:
  1. **Reproduce baseline with Flowmeter**: Train AE on training split, verify F1=1.0 on test split, confirm detection >2 hours before LPS signal for both failures.
  2. **Ablate Flowmeter sensor**: Retrain AE and rule learner excluding Flowmeter; compare rule complexity and detection performance against Table 3 results.
  3. **Stress test on MetroPT3**: Apply trained model to MetroPT3 dataset (no Flowmeter sensor); measure false positive rate and detection capability to assess generalization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the online rule-learning algorithm be adapted to maintain a bounded history size while retaining the ability to generate perfect-fitting rules for long-term real-world deployment?
- Basis in paper: [explicit] The authors state that the current unbounded history "will not scale in real-world scenarios" and suggest investigating strategies like random subsampling or removing old windows.
- Why unresolved: The current implementation stores all non-failure windows, which grows indefinitely over months or years of operation.
- What evidence would resolve it: A modified algorithm using a fixed memory buffer that achieves comparable F1 scores on extended data streams without memory overflow.

### Open Question 2
- Question: Can the Convolutional Autoencoder approach be successfully transferred to the MetroPT3 dataset, which lacks the highly predictive Flowmeter sensor?
- Basis in paper: [explicit] The authors note that initial experiments on MetroPT3 yielded many false positives and that "different methods... would be necessary" due to the absence of the Flowmeter.
- Why unresolved: The high performance on MetroPT2 relied heavily on a single sensor; removing it makes the problem substantially more complex for the current architecture.
- What evidence would resolve it: Successful failure detection on MetroPT3 with minimal false positives using an adapted or different model architecture.

### Open Question 3
- Question: How can the ambiguity of infinite valid rule thresholds be resolved to identify the precise physical breaking points of the Air Production Unit?
- Basis in paper: [explicit] The authors acknowledge that an "infinite number of rules could be retrieved" (e.g., thresholds of 9.58 vs 9.59) and thus they "cannot confidently gain knowledge about potential breaking points."
- Why unresolved: Purely statistical fitting offers many mathematically valid boundaries, making it difficult to pinpoint the exact physical condition that triggers the failure.
- What evidence would resolve it: A methodology that narrows rule thresholds to a specific range that aligns with physical degradation limits validated by maintenance experts.

## Limitations

- Perfect F1 score (1.0) may not generalize to more challenging datasets without the highly predictive Flowmeter sensor.
- Unbounded history buffer required for perfect rule fitting poses scalability challenges for long-term deployment.
- No validation on MetroPT3 dataset, which lacks the Flowmeter sensor that drives current performance.

## Confidence

- **High Confidence**: Autoencoder reconstruction error effectively detects anomalies when failure patterns differ from normal operation (supported by consistent performance across related works using reconstruction-based approaches).
- **Medium Confidence**: Low-pass filtering reduces false positives without missing true failures (based on reasonable parameter choices but limited ablation testing).
- **Low Confidence**: The proposed approach generalizes to more challenging scenarios without Flowmeter sensor (no empirical validation on MetroPT3 dataset).

## Next Checks

1. **Generalization Testing**: Apply the trained model to MetroPT3 dataset to verify performance when Flowmeter sensor is unavailable, measuring both detection accuracy and false positive rates.

2. **Robustness Analysis**: Systematically vary window length (15-45 minutes) and smoothing factor (α=0.05-0.25) to assess sensitivity and identify optimal parameters beyond the reported values.

3. **Concept Drift Evaluation**: Simulate gradual changes in normal operating conditions over time to test whether the rule-learning mechanism adapts appropriately or requires periodic retraining.