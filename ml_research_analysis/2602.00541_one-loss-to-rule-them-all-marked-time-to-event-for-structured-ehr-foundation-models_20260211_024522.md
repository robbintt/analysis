---
ver: rpa2
title: 'One Loss to Rule Them All: Marked Time-to-Event for Structured EHR Foundation
  Models'
arxiv_id: '2602.00541'
source_url: https://arxiv.org/abs/2602.00541
tags:
- loss
- tasks
- time-to-event
- event
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ORA, a marked time-to-event pretraining objective
  for EHR foundation models that jointly models event timing and associated numerical
  measurements. This approach addresses the limitation of traditional next-token prediction,
  which fails to capture the irregular temporal structure and numerical values inherent
  in clinical records.
---

# One Loss to Rule Them All: Marked Time-to-Event for Structured EHR Foundation Models

## Quick Facts
- arXiv ID: 2602.00541
- Source URL: https://arxiv.org/abs/2602.00541
- Reference count: 40
- One-line primary result: ORA pretraining objective improves EHR foundation model performance across 14 tasks, achieving average improvements of 10.7-11.4% over next-token prediction baselines

## Executive Summary
This paper introduces ORA, a marked time-to-event pretraining objective for EHR foundation models that jointly models event timing and associated numerical measurements. The approach addresses the limitation of traditional next-token prediction, which fails to capture the irregular temporal structure and numerical values inherent in clinical records. ORA is implemented across both Transformer and Mamba architectures and evaluated on two large EHR datasets (MIMIC-IV and CUMC) across 14 downstream tasks.

The method demonstrates superior performance compared to next-token prediction baselines, with particularly strong gains in regression tasks (33.6-38.3% improvement). The approach shows good generalization across different architectures, tasks, and datasets, suggesting that pretraining objectives aligned with EHR structure are critical for developing more expressive and generalizable foundation models.

## Method Summary
ORA frames EHR as marked temporal point processes where each event is represented as a tuple (t, m, v) - timestamp, clinical code, and optional numerical value. The pretraining objective maximizes a composite likelihood over all first-occurrence events at each timestep, using a discretized joint time-value space. A factorized two-stage projection head outputs probability matrices P^m(x) ∈ [0,1]^{T×V} for each code, where T represents time bins and V represents value quantiles. The model handles both observed and censored events through appropriate likelihood formulations, enabling efficient pretraining that captures the irregular temporal structure and numerical measurements characteristic of clinical data.

## Key Results
- ORA achieves average improvements of 10.7% and 11.4% over next-token prediction baselines across Transformer and Mamba architectures respectively
- Particularly strong gains in regression tasks: 33.6-38.3% improvement in R² scores
- Consistently outperforms baselines across 14 tasks (7 classification, 4 time-to-event, 3 regression) on MIMIC-IV and CUMC datasets
- Shows good cross-dataset generalization when pretrained on one dataset and evaluated on another

## Why This Works (Mechanism)

### Mechanism 1
Jointly modeling event timing and associated numerical values yields more generalizable representations than predicting only event codes. ORA formulates EHR as a marked point process where each event is a tuple (t, m, v) - timestamp, code, optional value - and maximizes a code-specific likelihood over this joint distribution rather than autoregressive next-token prediction. Core assumption: Event timing and values are conditionally independent across codes given patient history.

### Mechanism 2
Predicting all potential future events (not just the next observed one) provides denser supervision signals. At each timestep, ORA computes loss over F_i,j - the set of first occurrences for all codes - rather than only the single next event, addressing sparse supervision inherent in next-token prediction. Core assumption: Predicting unobserved but plausible future events improves representation quality.

### Mechanism 3
Discretizing the joint time-value space enables tractable optimization while preserving clinically meaningful structure. The model outputs probability matrices P^m(x) ∈ [0,1]^{T×V} (time bins × value quantiles) via a factorized two-stage projection head, using quantile-based discretization to handle heterogeneous distributions. Core assumption: Discretization preserves sufficient information for downstream tasks.

## Foundational Learning

- **Temporal Point Processes**: Understanding intensity functions λ(t) and event likelihoods is prerequisite for grasping the ORA loss formulation. Quick check: Can you explain why the joint likelihood for a temporal point process requires integrating the intensity function over the observation window?

- **Survival Analysis with Censoring**: The paper handles censored events (δ=0) where outcomes aren't observed within the record window. Quick check: What is the difference between the likelihood contribution for an observed event vs. a censored observation in survival analysis?

- **Discretized Distribution Approximation**: ORA discretizes continuous time-value spaces; understanding the tradeoffs (computational efficiency vs. approximation error) is critical. Quick check: How does quantile-based binning differ from uniform binning, and when would each be preferred?

## Architecture Onboarding

- **Component map**: EHR tuples -> Tokenizer (entropy-based filtering, ~7000 codes) -> Backbone (Transformer or Mamba) -> Factorized projection head (E→H_j ∈ R^{T×D_2} -> P^m ∈ [0,1]^{T×V}) -> Discretized ORA loss

- **Critical path**: 1) Preprocess EHR to (t, m, v) tuples with entropy-filtered vocabulary 2) Forward pass through backbone with time-aware positional encoding 3) Factorized projection to time-value probability matrices for all codes 4) Compute composite loss summing over first-occurrence events in F_i,j

- **Design tradeoffs**: Discretization granularity (T=8 time bins, V=10 value bins - coarser bins are faster but lose resolution), Factorized vs. direct projection (factorization reduces parameters by ~20% but may limit expressivity), Transformer vs. Mamba (Mamba scales linearly with sequence length; Transformers provide more interpretable attention but quadratic scaling)

- **Failure signatures**: Regression underperforms baseline (check if lab codes are in vocabulary; verify value quantiles aren't collapsing predictions), No improvement over NTP (may occur for frequently recurring conditions where prior occurrences dominate), Censored event loss dominates (verify δ indicators correctly set; check observation window truncation)

- **First 3 experiments**: 1) Ablation on discretization granularity: Vary T∈{4,8,16} and V∈{5,10,20}; evaluate on regression tasks 2) Loss component isolation: Compare full ORA vs. time-only vs. value-only on held-out regression tasks 3) Architecture transfer check: Train ORA on MIMIC-IV, linear-probe on CUMC (and reverse) to verify cross-site generalization

## Open Questions the Paper Calls Out

1. Do the performance improvements of ORA over next-token prediction persist as model size scales beyond the 120M parameter budget?

2. How does the ORA pretraining objective influence downstream performance when using full fine-tuning instead of linear probing?

3. Can more expressive or adaptive discretization methods improve ORA's ability to model sharply peaked distributions?

4. Does pretraining ORA on multiple datasets simultaneously improve robustness to distribution shift?

## Limitations

- The cross-architecture generalization is based on only two architectures with similar parameter counts, leaving uncertainty about scaling to much larger models
- The discretization approach may inadequately capture sharply peaked or multimodal value distributions, a limitation explicitly acknowledged but not quantified
- The conditional independence assumption across event codes could break down in complex clinical scenarios with strong code interdependencies

## Confidence

**High Confidence**: The claim that ORA improves performance over next-token prediction baselines is well-supported by the 14-task evaluation across two datasets, showing consistent gains particularly in regression tasks (33.6-38.3% improvement).

**Medium Confidence**: The claim about cross-architecture generalization is supported by positive results on both Transformer and Mamba, but the limited architectural diversity (two similar-sized models) reduces confidence.

**Low Confidence**: The claim that ORA is "overkill" for frequently recurring conditions lacks direct empirical validation beyond the Stroke example.

## Next Checks

1. **Discretization sensitivity analysis**: Systematically vary T (time bins) and V (value bins) across a wider range (e.g., T∈{4,8,16,32}, V∈{5,10,20,50}) and measure impact on regression performance, particularly for codes with sharply peaked value distributions.

2. **Architecture scaling experiment**: Train ORA with parameter counts spanning 3-4 orders of magnitude (e.g., 10M, 100M, 1B, 10B) to test whether the performance gains scale consistently or plateau.

3. **Conditional independence stress test**: Design synthetic EHR sequences where event codes are strongly correlated (e.g., drug administration always followed by specific lab tests) and measure ORA's performance degradation compared to baseline models.