---
ver: rpa2
title: In-Context Clustering with Large Language Models
arxiv_id: '2510.08466'
source_url: https://arxiv.org/abs/2510.08466
tags:
- clustering
- data
- attention
- clusters
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes In-Context Clustering (ICC), a method for using
  large language models (LLMs) to perform clustering on diverse data types. The core
  idea is to leverage the attention mechanism in LLMs, which captures contextual relationships
  among inputs, as a flexible similarity measure for clustering.
---

# In-Context Clustering with Large Language Models

## Quick Facts
- **arXiv ID:** 2510.08466
- **Source URL:** https://arxiv.org/abs/2510.08466
- **Reference count:** 40
- **Primary result:** Large language models can perform zero-shot clustering on diverse data types by leveraging attention mechanisms as a similarity measure, with fine-tuning further improving performance.

## Executive Summary
This paper introduces In-Context Clustering (ICC), a novel approach that leverages the attention mechanisms within large language models (LLMs) to perform unsupervised clustering on diverse data types, including numeric and image data. The core innovation is treating the attention matrix from intermediate transformer layers as a learned similarity measure, which can then be used for clustering via spectral methods or directly read from autoregressive label outputs. The authors demonstrate that pretrained LLMs exhibit strong zero-shot clustering capabilities on text-encoded numeric data, with attention matrices revealing salient cluster patterns. To further enhance clustering capabilities, they propose fine-tuning LLMs using the Next Token Prediction (NTP) loss on synthetic clustering data, significantly improving performance on complex distributions. The flexibility of LLM prompting enables text-conditioned image clustering, a capability absent in classical clustering methods.

## Method Summary
The ICC method involves formatting input data as text (for numeric data) or passing images through a multimodal LLM's vision encoder (for image data). For images, an average pooling layer is inserted after the vision projector to reduce token count and fit the context window. The LLM processes the input sequence, and the attention matrix from intermediate transformer layers is extracted. This attention matrix serves as an affinity matrix for spectral clustering or is used to read autoregressive cluster labels. Fine-tuning with NTP loss on synthetic clustering episodes further enhances performance by shaping the attention mechanism to better differentiate clusters. The method is evaluated on synthetic t-distributed numeric data and real image datasets like ImageNet and Stanford 40 Action.

## Key Results
- Pretrained LLMs achieve competitive zero-shot clustering performance on text-encoded numeric data, with attention matrices revealing salient cluster patterns.
- Fine-tuning with NTP loss on synthetic clustering data significantly improves clustering performance on both numeric and image data.
- ICC enables text-conditioned image clustering, allowing a single model to cluster images based on different attributes (e.g., color vs. shape) through prompt conditioning.
- The method outperforms recent caption-based LLM clustering approaches and shows strong generalization to out-of-domain datasets.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Intermediate transformer layers in LLMs function as implicit similarity engines, generating affinity matrices that reveal cluster structures.
- **Mechanism:** The self-attention mechanism computes pairwise scores between input tokens (data points). When visualized, the input-input attention block ($A_{II}$) in intermediate layers exhibits a block structure where high attention weights align with ground-truth cluster membership. This matrix effectively acts as a learned similarity measure, replacing predefined metrics like Euclidean distance.
- **Core assumption:** The pre-training data distribution exposes the model to relational structures that generalize to clustering numeric or visual inputs, even if explicit clustering tasks were rare.
- **Evidence anchors:**
  - [abstract]: "attention matrices showing salient cluster patterns."
  - [Section 3.2]: "attention matrices in intermediate layers show block structures that align with cluster identities."
  - [corpus]: "Attention-based clustering" supports the theoretical plausibility of transformers extracting unsupervised structure, though specific ICC evidence is limited to the paper.
- **Break condition:** If attention heads uniformly distribute weight or default to positional biases (e.g., vertical-slash patterns) without distinct block structures, the mechanism fails.

### Mechanism 2
- **Claim:** Fine-tuning with Next Token Prediction (NTP) on synthetic episodes shapes the attention mechanism to differentiate clusters.
- **Mechanism:** By presenting the model with a sequence of unlabeled data points followed by a cluster label, the NTP loss forces the model to attend to relevant features of previous tokens to predict the correct label for the current token. This "in-context" pressure refines the query/key projections, making the attention matrix sharper and more diagnostic of cluster boundaries.
- **Core assumption:** The model can bridge the gap between "text-encoded numbers" or "image patches" and the abstract concept of grouping without explicit gradient updates to a dedicated clustering head.
- **Evidence anchors:**
  - [Section 4]: "Fine-tuning LLMs using the Next Token Prediction loss further enhances clustering performance."
  - [Section 4.1]: "LLM exhibits a two-phase learning pattern... gradually develops a clustering mechanism."
  - [corpus]: Weak direct evidence in provided neighbors regarding NTP for clustering specifically; primarily inferred from the paper's experimental results.
- **Break condition:** If the model overfits to the specific cluster counts or data distributions seen during fine-tuning (e.g., failing on unseen $c=5$), the mechanism is brittle.

### Mechanism 3
- **Claim:** Text prompts act as control vectors that condition the attention mechanism to select specific features for similarity comparison.
- **Mechanism:** The natural language instruction (e.g., "cluster by color") embeds into the context window. This conditions the key/value vectors of the image inputs, causing the attention mechanism to prioritize specific semantic features (color vs. shape) when computing pairwise scores. This allows a single frozen model to switch similarity metrics dynamically.
- **Core assumption:** The multimodal LLM (e.g., LLaVA) has sufficiently aligned vision and language representations such that text concepts can gate visual attention.
- **Evidence anchors:**
  - [Section 5]: "flexibility of LLM prompting enables text-conditioned image clustering."
  - [Figure 5]: Shows identical image sets yielding different clusters based on the prompt condition.
  - [corpus]: "Unveiling Effective In-Context Configurations..." touches on ICL in multimodal models, but specific conditioning evidence is primarily from the paper.
- **Break condition:** If the visual encoder projects images into a space where fine-grained attributes (like texture) are already pooled away, the text condition cannot recover that information for clustering.

## Foundational Learning

- **Concept:** **Self-Attention as a Similarity Kernel**
  - **Why needed here:** ICC replaces standard distance metrics (Euclidean, Cosine) with the attention matrix itself. You must understand that $A = \text{softmax}(QK^T)$ is fundamentally a pairwise comparison operation.
  - **Quick check question:** Can you explain why a "block structure" in an attention matrix implies that the corresponding inputs belong to the same cluster?

- **Concept:** **Spectral Clustering**
  - **Why needed here:** The paper validates ICC by using the attention matrix as the input to spectral clustering (treating it as an affinity matrix).
  - **Quick check question:** What does spectral clustering do with an affinity matrix, and why is it a better proxy for "cluster quality" than just reading the raw attention values?

- **Concept:** **Causal Masking in Autoregressive Models**
  - **Why needed here:** The LLM generates labels sequentially. Understanding causal masking is critical to interpreting the lower-triangular structure of the attention matrices discussed in the paper.
  - **Quick check question:** Why can the token at position $t$ attend to position $t-1$ but not $t+1$, and how does this constraint affect the visualization of cluster formation?

## Architecture Onboarding

- **Component map:** Data (Numeric/String or Image) -> Token Reduction (Average Pooling for images) -> Transformer LLM -> Attention Matrix Extraction -> Spectral Clustering or Label Generation
- **Critical path:**
  1. Format data -> Text/Visual Tokens.
  2. (Images only) Apply Average Pooling to reduce sequence length.
  3. Forward pass through Transformer.
  4. Extract Attention Weights from intermediate layers (e.g., Layer 15).
  5. Use $A_{II}$ for Spectral Clustering OR read autoregressive label output.
- **Design tradeoffs:**
  - **Pooling Granularity:** Large pooling (fewer tokens) improves context efficiency and speed but loses fine-grained visual details necessary for conditional clustering (Section 5). Small pooling preserves details but risks context overflow.
  - **NTP Fine-tuning:** Improves accuracy on complex distributions but requires synthesizing training data. Zero-shot avoids this but performs poorly on non-Gaussian/complex data.
- **Failure signatures:**
  - **Vertical Slash Pattern:** Attention matrices in final layers often show this (Section 3.2), indicating the model is attending to the most recent token rather than groupingâ€”avoid using final layers for spectral clustering.
  - **Instruction Ignoring:** Small models (1B/3B) may fail to follow the "output labels" instruction, producing repetitive text instead of cluster indices.
  - **Caption Bottleneck:** If comparing against baselines like IC|TC, performance will drop if the captioning model lacks domain-specific knowledge (e.g., satellite imagery), whereas ICC uses raw visual features.
- **First 3 experiments:**
  1. **Zero-Shot Numeric:** Run Llama-3.1-8B on text-encoded t-distributed data with low degrees of freedom (heavy tails). Visualize $A_{II}$ to confirm block structures emerge.
  2. **Spectral Probe:** Extract attention from Layer 15 vs. Layer 31. Apply spectral clustering to both. Verify that intermediate layers outperform the final layer.
  3. **Fine-tuning Ablation:** Fine-tune a 1B model on simple Gaussian clusters vs. heavy-tailed clusters. Test generalization to lognormal distributions to verify if the model learned a "mechanism" vs. a distribution shape.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can theoretical frameworks be developed to explain the emergence of cluster structures in LLM attention matrices, particularly accounting for architectural complexities like multi-head attention and layer normalization?
  - **Basis in paper:** [explicit] The authors state that "Developing theoretical frameworks to explain and exploit these attention structures remains an important open direction," noting that current theoretical studies rely on simplified settings without multi-head attention or feed-forward layers.
  - **Why unresolved:** Current theoretical models do not account for the full complexity of modern transformer architectures, leaving the mechanism behind the observed "salient cluster patterns" in intermediate layers unexplained.
  - **What evidence would resolve it:** A formal mathematical framework that accurately predicts the formation of cluster structures in attention matrices under the full LLM architecture.

- **Open Question 2:** How can In-Context Clustering (ICC) be adapted to efficiently handle large-scale datasets that exceed the context window limitations of current LLMs?
  - **Basis in paper:** [explicit] The conclusion notes that "For application to larger datasets, it would be particularly promising to scale ICC to longer contexts, which can be computationally expensive," and suggests investigating dynamic context selection or token pruning.
  - **Why unresolved:** The current ICC method is constrained by the quadratic cost of attention and fixed context windows, making it difficult to apply to large datasets without heavy compression (like average pooling), which may lose information.
  - **What evidence would resolve it:** Demonstration of an ICC variant that maintains clustering accuracy on datasets significantly larger than the training context window without excessive computational overhead.

- **Open Question 3:** Why is there a significant performance gap between zero-shot spectral clustering using attention matrices and direct generative clustering, and how can this be bridged without fine-tuning?
  - **Basis in paper:** [inferred] The paper highlights a "surprising" result where spectral clustering on attention matrices achieves 85% accuracy compared to the pretrained model's 74% generative accuracy, suggesting the model "knows" the structure but cannot output it.
  - **Why unresolved:** It is unclear why the structural information encoded in the attention mechanism is not fully utilized by the model's decoding head for generation in a zero-shot setting.
  - **What evidence would resolve it:** Mechanistic interpretability analysis identifying the specific bottlenecks preventing the transfer of attention-based structural knowledge to the output tokens.

## Limitations
- The method's effectiveness may be highly dependent on specific architectural features of the LLM, such as attention patterns and multimodal alignment capabilities, which are not fully characterized.
- The fine-tuning process uses synthetic data generated from specific distributions (Gaussian, t-distributed), which may not reflect the complexity of real-world clustering tasks, potentially limiting generalization.
- The use of average pooling to reduce image token count is critical for fitting the context window but introduces sensitivity to the pooling kernel size, which appears dataset-dependent and is not fully explored.

## Confidence
- **High confidence:** The core mechanism of using intermediate-layer attention matrices for clustering is well-supported by the visualizations and quantitative results. The block structure in attention matrices aligning with ground-truth clusters is clearly demonstrated across multiple datasets and model scales.
- **Medium confidence:** The claim that fine-tuning with NTP loss significantly improves performance is supported by the ablation studies, but the exact learning dynamics and the degree of generalization to out-of-domain distributions remain incompletely characterized. The "two-phase learning pattern" described is observed but not deeply analyzed.
- **Low confidence:** The assertion that text-conditioned image clustering is a "capability absent in classical clustering methods" overstates the case, as classical methods can be adapted for conditional clustering with appropriate feature engineering. The novelty claim would be stronger if it compared against text-guided classical clustering baselines.

## Next Checks
1. **Robustness to distribution shift:** Test the fine-tuned models on clustering tasks with distributions that differ substantially from the training data (e.g., uniform, exponential, or multi-modal Gaussian mixtures). Measure whether the model has learned a general "clustering mechanism" or has overfit to specific synthetic distributions.
2. **Architectural ablation study:** Systematically compare the performance of ICC when using different intermediate layers (not just Layer 15), different model scales (1B vs. 8B vs. 70B), and different attention heads within the same layer. This would clarify whether the method's success is due to specific architectural features or is more general.
3. **Real-world application test:** Apply ICC to a challenging, real-world unsupervised clustering task (e.g., clustering customer behavior data, gene expression profiles, or satellite imagery) where ground truth is not available. Evaluate the quality of the clusters using downstream task performance or human evaluation to assess practical utility beyond synthetic benchmarks.