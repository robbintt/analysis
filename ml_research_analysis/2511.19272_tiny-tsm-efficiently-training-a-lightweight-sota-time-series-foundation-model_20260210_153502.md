---
ver: rpa2
title: 'Tiny-TSM: Efficiently Training a Lightweight SOTA Time Series Foundation Model'
arxiv_id: '2511.19272'
source_url: https://arxiv.org/abs/2511.19272
tags:
- series
- time
- forecasting
- foundation
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Tiny-TSM is a small-scale time series foundation model (23M parameters)
  trained efficiently on a single GPU in under a week. It leverages synthetic data
  generation (SynthTS) and a causal normalization scheme (DART-Norm) to enable dense
  next-token prediction without leakage.
---

# Tiny-TSM: Efficiently Training a Lightweight SOTA Time Series Foundation Model

## Quick Facts
- **arXiv ID**: 2511.19272
- **Source URL**: https://arxiv.org/abs/2511.19272
- **Reference count**: 11
- **Primary result**: 23M parameter model trained on single GPU in under a week, achieving SOTA on GIFT-Eval-NF benchmark

## Executive Summary
Tiny-TSM presents a lightweight time series foundation model that achieves state-of-the-art performance while remaining computationally efficient. The model uses 23 million parameters and can be trained on a single GPU in under a week, leveraging synthetic data generation (SynthTS) and a causal normalization scheme (DART-Norm) to enable dense next-token prediction without leakage. The approach demonstrates that compute-efficient, synthetic-data-driven models can rival industrial-scale forecasters with minimal tuning, particularly excelling in medium- and long-term forecasting under MSE loss while remaining competitive in short-term accuracy.

## Method Summary
The model employs a synthetic data generation pipeline (SynthTS) that creates diverse time series patterns through sine waves, steps, trends, and noise components. Training uses a causal normalization scheme (DART-Norm) to prevent information leakage during dense next-token prediction. A coarse-grid loss function enables efficient long-horizon forecasting, while stride-interleaved inference (SIFI) extends prediction context beyond training limits. The architecture is transformer-based with 23M parameters, optimized for single-GPU training through careful memory management and efficient batch processing.

## Key Results
- Achieves state-of-the-art performance on GIFT-Eval-NF benchmark
- Outperforms much larger models in medium- and long-term forecasting under MSE loss
- Maintains competitive short-term accuracy while requiring only single-GPU training

## Why This Works (Mechanism)
The approach succeeds through synthetic data generation that creates diverse training patterns without expensive real-world data collection. The causal normalization (DART-Norm) prevents leakage during dense prediction, while the coarse-grid loss optimizes for long-horizon accuracy. SIFI inference extends context limits by interleaving predictions, allowing the model to handle longer sequences than its training context window would normally permit.

## Foundational Learning

**Synthetic Data Generation (SynthTS)**
- *Why needed*: Enables efficient training without expensive real-world data collection
- *Quick check*: Verify synthetic patterns cover realistic time series distributions

**Causal Normalization (DART-Norm)**
- *Why needed*: Prevents information leakage during dense next-token prediction
- *Quick check*: Confirm no future information leaks into current predictions

**Coarse-Grid Loss**
- *Why needed*: Optimizes model for long-horizon forecasting efficiency
- *Quick check*: Validate accuracy improvement for extended prediction windows

**Stride-Interleaved Inference (SIFI)**
- *Why needed*: Extends context beyond training limits for longer sequences
- *Quick check*: Measure accuracy degradation with increasing stride sizes

## Architecture Onboarding

**Component Map**
Tiny-TSM -> Synthetic Data Generator -> DART-Norm Layer -> Transformer Encoder -> Coarse-Grid Loss -> SIFI Inference

**Critical Path**
Data generation → Normalization → Encoding → Loss calculation → Inference extension

**Design Tradeoffs**
The 23M parameter size balances performance with efficiency, sacrificing some accuracy for single-GPU trainability. Synthetic data generation trades realism for diversity and volume. SIFI inference adds computational overhead for extended context capabilities.

**Failure Signatures**
- Synthetic data bias leading to poor real-world generalization
- DART-Norm instability causing training divergence
- Coarse-grid loss missing fine-grained patterns
- SIFI inference accuracy degradation with large strides

**First Experiments**
1. Evaluate synthetic data diversity against real-world time series datasets
2. Test DART-Norm stability across different normalization configurations
3. Benchmark SIFI accuracy degradation across varying stride sizes and prediction horizons

## Open Questions the Paper Calls Out

None explicitly stated in the provided content.

## Limitations

- Synthetic datasets use narrow time series patterns (sine, step, trend, noise) that may not capture real-world complexity
- DART-Norm effectiveness relative to other normalization strategies remains untested
- SIFI computational overhead and accuracy degradation for very long horizons are not quantified

## Confidence

- **GIFT-Eval-NF performance claims**: High confidence (standardized metrics, multiple horizons)
- **Single-GPU training efficiency**: High confidence (detailed hardware specs, training curves)
- **Real-world dataset scalability**: Medium confidence (primarily benchmark-focused evaluations)

## Next Checks

1. Evaluate Tiny-TSM on industrial time series datasets (energy consumption, sensor networks) to assess real-world generalization beyond synthetic and benchmark data
2. Compare DART-Norm against alternative causal normalization schemes (LayerNorm, RMSNorm) in controlled ablation studies
3. Benchmark SIFI inference time and accuracy degradation across varying stride sizes and prediction horizons to establish practical limits