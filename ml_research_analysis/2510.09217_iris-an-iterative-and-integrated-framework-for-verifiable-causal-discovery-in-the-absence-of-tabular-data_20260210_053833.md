---
ver: rpa2
title: 'IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery
  in the Absence of Tabular Data'
arxiv_id: '2510.09217'
source_url: https://arxiv.org/abs/2510.09217
tags:
- causal
- variables
- discovery
- relations
- variable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: IRIS introduces a hybrid causal discovery framework that automatically
  collects relevant documents, extracts variable values, and uncovers both known and
  novel causal relations without requiring pre-existing datasets. The method combines
  statistical algorithms with LLM-based causal relation extraction and verification,
  while also identifying missing variables to relax the causal sufficiency and acyclicity
  assumptions.
---

# IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data

## Quick Facts
- arXiv ID: 2510.09217
- Source URL: https://arxiv.org/abs/2510.09217
- Reference count: 31
- IRIS consistently outperforms baselines across multiple datasets, achieving up to 0.70 F1 score and 0.30 NHD ratio on cancer data, and scaling effectively from 4 to 27 initial variables.

## Executive Summary
IRIS introduces a hybrid causal discovery framework that automatically collects relevant documents, extracts variable values, and uncovers both known and novel causal relations without requiring pre-existing datasets. The method combines statistical algorithms with LLM-based causal relation extraction and verification, while also identifying missing variables to relax the causal sufficiency and acyclicity assumptions. Experimental results show IRIS consistently outperforms baselines across multiple datasets, achieving up to 0.70 F1 score and 0.30 NHD ratio on cancer data, and scaling effectively from 4 to 27 initial variables. Individual components also surpass their respective baselines, with GPT-4o-based value extraction reaching 0.79 F1 and the missing variable proposal achieving up to 1.00 success rate.

## Method Summary
IRIS is a hybrid framework that integrates automated document retrieval, LLM-based extraction, and statistical causal discovery methods to identify causal relations without requiring pre-existing tabular data. The framework operates iteratively: it starts with an initial set of variables, retrieves relevant documents, extracts causal relations and variable values using LLMs, and applies causal discovery algorithms. It addresses the causal sufficiency and acyclicity assumptions by proposing and validating missing variables. The system uses GPT-4o for value extraction, achieves F1 scores up to 0.79, and can scale from 4 to 27 initial variables while maintaining performance. The approach combines statistical algorithms with LLM-based causal relation extraction and verification.

## Key Results
- IRIS achieves up to 0.70 F1 score and 0.30 NHD ratio on cancer data
- The framework scales effectively from 4 to 27 initial variables
- GPT-4o-based value extraction reaches 0.79 F1 score
- Missing variable proposal achieves up to 1.00 success rate

## Why This Works (Mechanism)
IRIS works by combining automated information retrieval with LLM-based extraction and statistical causal discovery methods. The framework iteratively expands its variable set by identifying missing variables that could explain observed dependencies, then verifies these additions through document-based extraction. By relaxing the causal sufficiency assumption (that all relevant variables are observed), IRIS can discover novel causal relations that traditional methods miss. The integration of LLMs allows for extracting causal relations from unstructured text, while statistical algorithms validate these relations against observed variable distributions.

## Foundational Learning
- **Causal sufficiency assumption**: The assumption that all relevant variables are observed in the dataset. This is needed because traditional causal discovery methods fail when important variables are missing. Quick check: Verify if your dataset might be missing key confounding variables.
- **Causal graph structure**: The directed acyclic graph representing causal relationships between variables. This is needed to visualize and analyze causal dependencies. Quick check: Ensure your graph remains acyclic after adding new variables.
- **LLM-based causal extraction**: Using large language models to identify causal relations in unstructured text. This is needed because causal information often exists in text but not in structured form. Quick check: Validate extracted relations against multiple source documents.
- **Iterative variable expansion**: The process of adding missing variables to improve causal discovery. This is needed because initial variable sets are often incomplete. Quick check: Monitor performance changes as variables are added.
- **Document retrieval for causal discovery**: Using search engines to find relevant documents containing causal information. This is needed to access external knowledge sources. Quick check: Ensure retrieved documents are relevant and credible.
- **Causal verification**: The process of validating proposed causal relations using statistical methods and document evidence. This is needed to ensure discovered relations are reliable. Quick check: Cross-validate causal edges using multiple methods.

## Architecture Onboarding

### Component Map
Document Retrieval -> LLM Extraction -> Variable Expansion -> Causal Discovery -> Verification

### Critical Path
The critical path is: Initial Variables → Document Retrieval → LLM Extraction → Causal Discovery → Verification → (Optional) Variable Expansion → Repeat. This loop continues until no new variables are discovered or performance plateaus.

### Design Tradeoffs
The framework trades computational efficiency for comprehensiveness, using multiple LLMs and iterative processing to ensure thorough causal discovery. The reliance on document retrieval assumes sufficient relevant information exists, which may not hold for all domains. The integration of LLMs introduces variability in extraction quality, balanced against their superior performance in understanding natural language.

### Failure Signatures
Performance degrades significantly when initial variable sets are small (as in the Countries dataset), indicating sensitivity to starting conditions. The method's success depends heavily on the quality and quantity of retrieved documents, making it vulnerable to sparse or biased information sources. LLM extraction quality varies with prompt design and model version, introducing potential inconsistency.

### Exactly 3 First Experiments
1. Test with a minimal initial variable set (4-5 variables) to observe performance degradation and identify minimum viable starting conditions.
2. Conduct experiments under controlled retrieval constraints (limited document access, biased corpora) to assess sensitivity to information availability.
3. Perform a blind external validation where domain experts assess the novelty and correctness of proposed causal edges in a held-out dataset.

## Open Questions the Paper Calls Out
None

## Limitations
- The evaluation relies on ground-truth causal graphs from publicly available datasets, but does not address the challenge that such "gold standards" may themselves be incomplete or contested in real-world domains.
- The method's performance degrades when initial variable sets are small, raising questions about reliability in sparse-information settings.
- The integration of LLMs introduces opaque variability: extraction quality depends heavily on prompt design and model version, neither of which are systematically controlled across experiments.

## Confidence
- Core iterative framework and variable expansion mechanism: **High**
- Quantitative improvements over baselines: **Medium**
- Novel causal discovery in real-world settings: **Low**

## Next Checks
1. Conduct a blind external validation where domain experts assess the novelty and correctness of proposed causal edges in a held-out dataset.
2. Test robustness by systematically varying the initial variable set size and measuring performance degradation curves.
3. Evaluate performance under controlled retrieval constraints (e.g., limited document access, biased corpora) to assess sensitivity to information availability.