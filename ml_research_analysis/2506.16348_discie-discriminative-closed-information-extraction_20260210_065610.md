---
ver: rpa2
title: DISCIE -- Discriminative Closed Information Extraction
arxiv_id: '2506.16348'
source_url: https://arxiv.org/abs/2506.16348
tags:
- information
- entity
- relation
- discie
- extraction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a discriminative approach to closed information
  extraction (CIE) that uses type and entity-specific information to improve relation
  extraction accuracy, especially for long-tail relations. Unlike generative models
  that must learn entire knowledge graphs, the method first identifies salient text
  segments, then uses entity linking and type information to classify relations within
  a predefined set.
---

# DISCIE -- Discriminative Closed Information Extraction

## Quick Facts
- arXiv ID: 2506.16348
- Source URL: https://arxiv.org/abs/2506.16348
- Reference count: 40
- Key outcome: DISCIE achieves 74.97% F1 on REBEL, outperforming generative models by 5+ F1 points through type-informed discriminative architecture

## Executive Summary
This paper introduces a discriminative approach to closed information extraction (CIE) that uses type and entity-specific information to improve relation extraction accuracy, especially for long-tail relations. Unlike generative models that must learn entire knowledge graphs, the method first identifies salient text segments, then uses entity linking and type information to classify relations within a predefined set. The approach employs lightweight models for mention recognition, entity candidate generation, entity candidate ranking, and relation extraction, incorporating fine-grained Wikidata types to improve classification. On the large-scale REBEL dataset with 857 relations, the method outperforms state-of-the-art generative models by over 5 F1 points, achieving 74.97% F1 overall and over 9 points better macro F1. It also shows improved performance on long-tail relations, with efficiency gains of about 27x over generative models.

## Method Summary
DISCIE uses a four-stage discriminative pipeline: (1) Mention Recognizer identifies entity mentions through token-pair classification, (2) Entity Candidate Generator retrieves potential entity matches using bi-encoder retrieval with FAISS indexing, (3) Entity Candidate Ranker refines candidates using cross-encoder re-ranking, and (4) Relation Extractor classifies relations using both textual context and fine-grained Wikidata type embeddings. The relation extractor combines textual logits with type-based logits computed from learnable type embeddings, enabling the model to learn ontological constraints without explicit rules. All components use DistilBERT or MiniLM variants, trained sequentially on the REBEL dataset. The approach grounds all outputs to Wikidata identifiers (QIDs for entities, PIDs for relations) and incorporates fine-grained types from the P31 relation plus supertypes.

## Key Results
- Achieves 74.97% F1 on REBEL, surpassing state-of-the-art generative models by over 5 F1 points
- Improves macro F1 by over 9 points compared to generative approaches
- Shows 27x efficiency gains (21.17 vs 571.95 seconds per 1000 examples on GeoNRE)
- Fine-grained type information improves F1 by 6.65 points over coarse-grained types (Table 6)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-grained type information substantially improves relation extraction, particularly for long-tail relations.
- Mechanism: Entity types (from Wikidata P31 relation) are embedded as learnable vectors. Type-based relation logits are computed separately from textual logits, then summed. This allows the model to learn ontological constraints (e.g., "employer" requires subject type Person, object type Organization) without explicit rules.
- Core assumption: Relations in the KG follow implicit type constraints that are learnable from training data.
- Evidence anchors:
  - [abstract] "In particular, the integration of type-information proves instrumental in achieving performance levels on par with or surpassing those of a larger generative model."
  - [section 3.2] Ablation shows removing type information drops F1 from 74.97 to 65.58; coarse-grained types only achieve 68.32 F1.
  - [corpus] Weak direct corpus support; neighbor papers focus on generative/discriminative hybridization but not type injection specifically.
- Break condition: If entity type annotations in your KG are sparse or noisy, type embeddings may not converge; verify P31 coverage before relying on this mechanism.

### Mechanism 2
- Claim: Discriminative pipeline architecture enables external KG integration that generative models cannot easily incorporate.
- Mechanism: Unlike generative models that must memorize the entire KG during training, DISCIE retrieves entity candidates from a vector index at inference time. This allows the model to use an evolving KG without retraining and to leverage entity descriptions/labels directly.
- Core assumption: Candidate generation can efficiently narrow the entity search space to a tractable subset for accurate re-ranking.
- Evidence anchors:
  - [abstract] "Unlike generative models that must learn entire knowledge graphs, the method first identifies salient text segments, then uses entity linking and type information to classify relations within a predefined set."
  - [section 1] "Generative model is forced to learn the entire KG during training. As the size of such a KG can be huge, this can inhibit performance."
  - [corpus] Neighbor paper "Bridging Generative and Discriminative Learning" supports hybrid benefits but doesn't validate the specific KG integration claim.
- Break condition: If your entity vocabulary exceeds vector index capacity or retrieval latency budgets, the bi-encoder retrieval quality may degrade unacceptably.

### Mechanism 3
- Claim: Lightweight discriminative models achieve ~27x efficiency gains over generative approaches while maintaining or exceeding accuracy.
- Mechanism: Pipeline parallelism and non-autoregressive inference. Each component (mention recognition, candidate generation, ranking, relation extraction) uses small encoder-only models (DistilBERT, MiniLM) that process independently rather than sequential token-by-token generation.
- Core assumption: Error propagation across pipeline stages is offset by type information constraining the relation space.
- Evidence anchors:
  - [section 3.3] "DISCIE is approximately 27 times as fast as GenIE" (21.17 vs 571.95 seconds/1000 examples on GeoNRE).
  - [section 2.2] Uses distilbert-base-cased and all-MiniLM-L12-v2 across all components.
  - [corpus] No direct corpus validation of efficiency claims; neighbor papers don't report comparable metrics.
- Break condition: If early-stage errors (mention recognition, candidate generation) cascade, efficiency gains are irrelevant—accuracy will collapse. Monitor per-component error rates.

## Foundational Learning

- Concept: Bi-encoder vs Cross-encoder architectures
  - Why needed here: DISCIE uses bi-encoder for fast candidate retrieval and cross-encoder for accurate re-ranking. Understanding the efficiency/accuracy tradeoff is essential.
  - Quick check question: Can you explain why bi-encoders are faster but cross-encoders more accurate for entity matching?

- Concept: Closed Information Extraction (CIE) vs Open IE
  - Why needed here: CIE requires grounding all entities and relations to KG identifiers (Wikidata QIDs/PIDs), not just extracting surface strings.
  - Quick check question: Given "Barack Obama was born in Hawaii," what distinguishes CIE output from Open IE output?

- Concept: Long-tail relation problem
  - Why needed here: The paper's primary contribution is improving performance on relations with few training examples; understanding class imbalance is critical for evaluation.
  - Quick check question: Why might macro F1 be more informative than micro F1 when evaluating on datasets with 857 relations?

## Architecture Onboarding

- Component map:
Input Text → Mention Recognizer (token-pair classifier)
         → Entity Candidate Generator (bi-encoder + vector index)
         → Entity Candidate Ranker (cross-encoder)
         → Relation Extractor (textual logits + type logits)
         → Output Triples (QID, PID, QID)

- Critical path: Mention recognition → Candidate generation errors dominate failure modes (42.1% and 39.8% of errors respectively per Figure 3). Prioritize tuning thresholds εm and εc before relation extraction.

- Design tradeoffs:
  - F1 calibration: Higher precision (77.41%), lower recall (72.68%)—best when false positives are costly.
  - F2 calibration: Higher recall (81.93%), lower precision (62.13%)—best for recall-oriented benchmarks like FewRel.
  - Type granularity: Fine-grained types (930 types) outperform coarse (PER/ORG/LOC/MISC) by ~6.6 F1 points.

- Failure signatures:
  - Mention recognition misses: 42.1% of errors—check token-pair threshold εm.
  - Relation extraction false positives: 39.8% of errors—verify type information is correctly loaded.
  - Candidate ranking errors: 12.5%—cross-encoder may need hard negative mining refinement.
  - Hallucinated relations: Both DISCIE and GenIE predict triples like "(Spain, capital, Madrid)" when not in text—implicit knowledge leakage from training.

- First 3 experiments:
  1. Reproduce ablation: Train DISCIE without type information on REBEL subset; expect ~9 F1 point drop. Validates type mechanism is working.
  2. Threshold sensitivity: Sweep εm, εc, εr on validation set; plot precision-recall tradeoff curves. Establishes optimal calibration for your use case.
  3. Long-tail analysis: Bin relations by training frequency; compare F1 vs GenIE on bins with 16-64 occurrences. Should show ~2x improvement per Figure 2.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the model architecture be modified to eliminate the reliance on explicit entity mention positions during training?
- Basis in paper: [explicit] The authors state they want to "investigate whether the model can be modified to skip the mention recognition" because the current setup relies on mention positions, unlike generative models.
- Why unresolved: The current discriminative training setup requires mention position inputs, restricting the data sources or supervision methods to those with span annotations.
- What evidence would resolve it: A variant of DISCIE trained without mention supervision that achieves comparable F1 scores to the current model on the REBEL dataset.

### Open Question 2
- Question: Does replacing the greedy inference procedure with global optimization of the disambiguation graph significantly improve extraction accuracy?
- Basis in paper: [explicit] The authors note that "inference procedure is currently performed in a greedy way" and they suspect "globally optimizing the disambiguation graph can lead to an increase in performance."
- Why unresolved: The current pipeline processes components sequentially/greedily, potentially propagating errors or missing globally optimal entity-relation configurations.
- What evidence would resolve it: Comparative results on the REBEL or WikipediaNRE datasets showing F1 score improvements when applying a global optimization algorithm to the entity and relation selection process.

### Open Question 3
- Question: Does incorporating fine-grained type information into the entity linking module (candidate generation and ranking) provide performance gains?
- Basis in paper: [explicit] The authors hypothesize that "incorporating the type information into the entity linking module might lead to improvement."
- Why unresolved: While type information proved beneficial for relation extraction, it was not integrated into the entity linking steps, leaving its potential utility there unverified in this specific pipeline.
- What evidence would resolve it: An ablation study demonstrating changes in entity linking accuracy and overall CIE F1 scores when type embeddings are added to the candidate generator and ranker.

## Limitations

- Evaluation limited to REBEL dataset and three smaller benchmarks; generalization to other KGs or domains not demonstrated
- Efficiency comparison lacks hardware and batch size specifications
- Claims of matching larger generative models are qualified—DISCIE matches on micro F1 but exceeds on macro F1
- No evaluation on truly zero-shot long-tail relations or transfer to different knowledge graph schemas

## Confidence

- **High confidence**: Discriminative pipeline efficiency gains (~27x faster), type information improving macro F1 on long-tail relations, mention recognition and candidate generation being primary error sources
- **Medium confidence**: Fine-grained type embeddings improving F1 by 6.65 points (direct ablation), discriminative models handling evolving KGs better than generative approaches
- **Low confidence**: Claims about matching larger generative models on micro F1 without hardware details, generality to other KGs/datasets beyond REBEL

## Next Checks

1. **Type mechanism ablation**: Train DISCIE without type embeddings on REBEL's long-tail subset (relations with 16-64 training examples); verify macro F1 drops by ~6-7 points. This directly validates the type injection mechanism.

2. **Cross-dataset transfer**: Evaluate DISCIE on a second KG (e.g., Freebase or proprietary KG) with different entity type schema. Success indicates the type embedding approach generalizes beyond Wikidata's P31 relation.

3. **Error propagation analysis**: Measure per-component error rates on a validation sample where mention recognition succeeds but relation extraction fails. Calculate how many false positives stem from type embeddings vs. textual logits. This quantifies whether type information is introducing new error modes.