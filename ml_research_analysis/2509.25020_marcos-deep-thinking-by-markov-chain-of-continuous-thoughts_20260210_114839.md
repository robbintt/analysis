---
ver: rpa2
title: 'MARCOS: Deep Thinking by Markov Chain of Continuous Thoughts'
arxiv_id: '2509.25020'
source_url: https://arxiv.org/abs/2509.25020
tags:
- uni00000013
- reasoning
- which
- thinking
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational inefficiency of token-based
  chain-of-thought reasoning in large language models. The authors propose MARCOS,
  a new paradigm that models reasoning as a hidden Markov chain of continuous high-dimensional
  "thoughts," decoupling the thinking and speaking processes.
---

# MARCOS: Deep Thinking by Markov Chain of Continuous Thoughts

## Quick Facts
- arXiv ID: 2509.25020
- Source URL: https://arxiv.org/abs/2509.25020
- Reference count: 11
- Key outcome: Achieves 8.66% accuracy improvement over best continuous reasoning model and 4.7% over token-based CoT with up to 15.7× speedup on GSM8K

## Executive Summary
MARCOS introduces a novel paradigm for deep reasoning in large language models by modeling the thinking process as a hidden Markov chain of continuous high-dimensional thoughts, decoupling deliberation from verbalization. The model iteratively updates continuous neuron states during thinking, optionally translating these latent states into natural language during speaking. Trained via a two-phase variational scheme with step-level randomness control, MARCOS achieves state-of-the-art performance on mathematical reasoning benchmarks while offering significant inference speedups and controllability over the reasoning process.

## Method Summary
MARCOS models reasoning as a hidden Markov chain where each step transitions between continuous high-dimensional "thought" states rather than discrete tokens. The architecture consists of four components: an Understander encoder, a Thinker bidirectional transformer that updates continuous neurons, a Randomness Predictor/Encoder for step-level stochasticity, and an optional Speaker decoder. Training occurs in two phases: first optimizing reconstruction with sparsity loss on the random variable, then training the predictor to match posterior distributions. The model maintains two neuron sets (deep for reasoning, shallow for verbalization) and uses a fixed 3-step reasoning chain for mathematical problems.

## Key Results
- 8.66% accuracy improvement over best continuous reasoning model on GSM8K
- 4.7% accuracy improvement over token-based CoT while achieving 15.7× speedup
- Step-level randomness control enables intervention on output properties without accuracy loss
- Sparse random variable dimensions critical for preventing model collapse and enabling controllability

## Why This Works (Mechanism)

### Mechanism 1: Continuous Thought Propagation
High-bandwidth information transfer between reasoning steps through continuous vector states bypasses token-level discretization, preserving richer representations for reasoning. The Thinker updates neurons conditioned on input and random variables, avoiding the information bottleneck of discrete tokens.

### Mechanism 2: Decoupled Thinking and Speaking
Separating latent reasoning computation from verbalization enables faster processing and deeper deliberation. The thinking stage iteratively resolves reasoning in continuous space before optional parallelizable translation to natural language.

### Mechanism 3: Step-Level Variational Control
Modeling transitions as multimodal distributions via auxiliary random variables enables exploration of diverse reasoning paths and controllability. The two-phase variational training with sparsity loss encourages interpretable latent dimensions that control output properties.

## Foundational Learning

- **Concept: Markov Chain**
  - Why needed here: MARCOS models reasoning as sequential states where each depends only on the current state
  - Quick check question: Can you explain why modeling reasoning as a Markov chain implies each thinking step depends only on current continuous thought state and question?

- **Concept: Variational Autoencoder (VAE) & ELBO**
  - Why needed here: Two-phase variational training scheme for learning latent thought transitions uses VAE principles
  - Quick check question: In MARCOS training loss, what is the role of KL divergence between prior (from predictor) and posterior (from encoder)?

- **Concept: Non-Autoregressive (NAR) Decoding**
  - Why needed here: Decoupling thinking from speaking makes final generation amenable to parallel decoding
  - Quick check question: Why does decoupling thinking from speaking enable non-autoregressive decoding compared to standard LLMs?

## Architecture Onboarding

- **Component map**: Input -> Understander -> Thinker (updates neurons) -> Randomness Predictor/Encoder -> Speaker -> Output
- **Critical path**: Encode question → Loop K steps: predict randomness → update neurons → Decode states to text
- **Design tradeoffs**: Fixed K=3 simplifies training but may be inefficient; neuron scale shows performance saturation; NAR speaker trades accuracy for speed
- **Failure signatures**: Removing sparsity loss causes model collapse (accuracy ~1%); deterministic transitions hurt performance more on text than equations
- **First 3 experiments**: 1) Reproduce w/o Sparsity ablation to confirm model collapse; 2) Intervene on R_k dimensions to test controllability; 3) Compare NAR vs AR speaker accuracy/efficiency tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
How to pre-train MARCOS on large-scale unstructured corpora lacking step-by-step reasoning annotations? Current training requires supervised step-by-step data; pre-training needs defining reasoning steps without annotations.

### Open Question 2
Can reinforcement learning algorithms leveraging step-level randomness control improve MARCOS's reasoning on complex tasks? The variational random variables provide controllable stochasticity but no RL experiments have been conducted.

### Open Question 3
How does MARCOS perform on more challenging mathematical datasets (MATH, AIME) and non-mathematical reasoning domains? Current benchmarks are relatively simple; generalization to harder problems and other domains is untested.

### Open Question 4
Can advanced non-autoregressive decoding strategies further accelerate speaking stage while maintaining reasoning quality? Only simple one-pass NAR decoder tested; more sophisticated methods remain unexplored.

## Limitations

- Two-phase variational training requires careful hyperparameter tuning, particularly sparsity loss weight λ which is not specified
- Theoretical grounding connecting continuous Markov chain formulation to improved reasoning remains primarily empirical
- Scalability analysis limited to small 0.5B parameter models may not extend to larger models
- 15.7× speedup assumes ideal parallel decoding conditions that may not hold with current hardware

## Confidence

- **High confidence**: State-of-the-art empirical results on GSM8K, SVAMP, MultiArith benchmarks with measurable accuracy improvements
- **Medium confidence**: Continuous representations enable better information transfer, but exact mechanisms not fully characterized
- **Medium confidence**: Decoupling thinking from speaking enables faster reasoning, but real-world advantages may be more modest
- **Medium confidence**: Step-level controllability demonstrated, but interpretation of latent dimensions requires further validation

## Next Checks

1. Validate the sparsity loss criticality by reproducing w/o Sparsity ablation and systematically varying λ
2. Characterize the continuous representation space using dimensionality reduction on neuron states across different problems
3. Test scalability to larger 7B parameter models to determine if improvements scale proportionally or if new optimization challenges emerge