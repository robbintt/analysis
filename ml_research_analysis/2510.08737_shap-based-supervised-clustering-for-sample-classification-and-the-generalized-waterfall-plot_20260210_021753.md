---
ver: rpa2
title: SHAP-Based Supervised Clustering for Sample Classification and the Generalized
  Waterfall Plot
arxiv_id: '2510.08737'
source_url: https://arxiv.org/abs/2510.08737
tags:
- shap
- values
- data
- each
- clustering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SHAP-based supervised clustering provides a novel approach to analyzing
  machine learning model predictions by grouping samples not just by their predicted
  class, but by the specific features driving those predictions. The method clusters
  SHAP values (which quantify feature contributions to predictions) rather than raw
  data, revealing subgroups of samples that arrive at similar predictions through
  distinct pathways.
---

# SHAP-Based Supervised Clustering for Sample Classification and the Generalized Waterfall Plot

## Quick Facts
- **arXiv ID:** 2510.08737
- **Source URL:** https://arxiv.org/abs/2510.08737
- **Reference count:** 13
- **Primary result:** SHAP-based supervised clustering reveals clinically meaningful subgroups within predicted classes that raw data clustering cannot detect

## Executive Summary
This paper introduces SHAP-based supervised clustering, a novel approach that groups samples not by their raw feature values but by the specific SHAP values (feature contributions to model predictions) that drive those predictions. Unlike traditional clustering that groups similar patients, this method clusters patients who arrive at similar predictions through distinct pathways. The approach successfully identifies subgroups within clinical categories in Alzheimer's disease data, revealing nuanced patterns that could inform more personalized treatment approaches. The researchers also develop a generalization of waterfall plots for multi-classification problems, enabling visualization of high-dimensional SHAP paths.

## Method Summary
The method involves training an XGBoost classifier, computing cross-validated SHAP values (to prevent overfitting), flattening the multi-class SHAP tensor into a 2D matrix, applying UMAP for dimensionality reduction, and using HDBSCAN for clustering. The resulting clusters are visualized using generalized waterfall plots that represent prediction paths through k-dimensional space. Applied to simulated data (1,500 samples, 10 features) and ADNI Alzheimer's data (2,422 patients, 39 features), the approach achieves 90% and 93% accuracy respectively while revealing clinically meaningful subgroups within predicted classes.

## Key Results
- Successfully identified three target classes in simulated data and discovered Class 2 contained two distinct subgroups based on different feature combinations
- Applied to 2,422 ADNI patients, revealing nuanced subgroups within cognitively normal, mild cognitive impairment, and Alzheimer's/dementia categories
- XGBoost models achieved 90% accuracy on simulated data and 93% on ADNI data
- Generalized waterfall plots effectively visualize high-dimensional SHAP paths for multi-class classification

## Why This Works (Mechanism)

### Mechanism 1: SHAP Values Encode Decision Logic, Not Just Feature Values
Clustering SHAP values groups samples by "prediction for similar reasons" rather than similar raw feature distributions. SHAP values decompose each prediction into per-feature contributions that sum to the model output deviation from baseline. When clustered, samples with similar contribution profiles group together, revealing distinct pathways to equivalent predictions that raw data clustering cannot detect.

### Mechanism 2: Cross-Validated SHAP Calculation Prevents Overfitting
Computing SHAP values on held-out folds during cross-validation produces stable, generalizable explanations. Each fold's SHAP values come from a model trained on other folds, ensuring feature attributions reflect learned patterns rather than memorized noise. Averaging across repeated runs reduces partitioning bias.

### Mechanism 3: High-Dimensional Waterfall Plots Enable Multi-Class Path Visualization
Multi-class SHAP vectors can be visualized as paths through k-dimensional space, with projections preserving interpretability. Each sample's SHAP values form a k-dimensional vector per feature. Concatenating features creates a path from baseline to prediction. PCA projection or pairwise class plots reveal which features drive predictions toward specific classes.

## Foundational Learning

- **Shapley Values and SHAP Decomposition**
  - Why needed here: Core mathematical foundation—understanding why SHAP values sum to prediction-baseline difference, and what positive/negative values mean for each class
  - Quick check question: Given a 3-class problem where baseline probability is [0.33, 0.33, 0.33], if a sample's SHAP values for feature X are [+0.2, -0.1, -0.1], what does this tell you about feature X's contribution?

- **Density-Based vs. Centroid-Based Clustering**
  - Why needed here: HDBSCAN is chosen specifically for variable-density clusters and noise handling—understanding why KMeans would fail here prevents misapplication
  - Quick check question: Why would KMeans struggle to detect clusters of different densities in SHAP space?

- **UMAP's Local Structure Preservation**
  - Why needed here: SHAP clustering interpretation relies on 2D visualization; UMAP prioritizes local neighborhoods differently than t-SNE or PCA
  - Quick check question: If two samples are neighbors in UMAP space but distant in raw feature space, what does this imply about their SHAP profiles?

## Architecture Onboarding

- **Component map:**
Raw Data → XGBoost Model → Cross-Validated SHAP Calculation → SHAP Matrix (n × p × k) → HDBSCAN ← UMAP Embedding (optional visualization) ← Flatten to (n × pk) → Generalized Waterfall Plots

- **Critical path:**
  1. Model quality (accuracy) determines SHAP reliability—validate here first
  2. Cross-validation fold count and repeats control SHAP stability (paper uses unspecified fold count with repeated runs)
  3. HDBSCAN `min_cluster_size` parameter determines cluster granularity (finer clustering shown in p.13-15)

- **Design tradeoffs:**
  - XGBoost vs. other models: TreeSHAP is exact for tree models; neural networks require kernel/approximate SHAP (slower, noisier)
  - UMAP for visualization vs. direct HDBSCAN: UMAP may distort distances; clustering on full SHAP space preserves fidelity
  - PCA projection vs. pairwise class plots: PCA preserves global variance; pairwise better for targeted class comparison

- **Failure signatures:**
  - Model accuracy <70%: SHAP values explain noise → clusters reflect random patterns
  - All samples assigned to one cluster or mostly noise: HDBSCAN `min_cluster_size` too large or SHAP variance too low
  - Cluster interpretation inconsistent with domain knowledge: Possible model overfitting or feature scaling issues
  - Waterfall paths overlapping excessively: Classes may be insufficiently separated; consider feature selection

- **First 3 experiments:**
  1. Replicate simulated experiment with known ground truth (3 classes, Features 0-1 drive class assignment) to validate clustering recovers expected subgroups
  2. Sensitivity analysis: Vary HDBSCAN `min_cluster_size` (e.g., 5, 10, 20) on same SHAP data to assess cluster stability and identify appropriate granularity
  3. Apply to your own multi-class dataset with baseline accuracy check; if accuracy >85%, proceed with full pipeline and compare SHAP clusters against raw data UMAP clusters to quantify added insight

## Open Questions the Paper Calls Out

### Open Question 1
Can high-dimensional generalizations of other SHAP visualization plots (bar plots, heatmaps, beeswarm plots, violin plots) effectively represent multi-class interactions in supervised clustering? Current visualizations either project onto pairwise class comparisons (losing information) or use PCA (reducing interpretability).

### Open Question 2
Do SHAP-identified subgroups within clinical categories (e.g., the distinct AD Clusters 2 and 5 with different driving features) correspond to biologically or treatment-response relevant subtypes? The ADNI analysis is observational; no prospective validation of whether these subgroups differ in prognosis or treatment response exists.

### Open Question 3
How robust are SHAP-based supervised clustering results to the choice of predictive model, dimensionality reduction method, and clustering algorithm? The methodology uses XGBoost, UMAP, and HDBSCAN as interchangeable components, but only tests this single combination without sensitivity analysis.

## Limitations

- Hyperparameter specifications for XGBoost, cross-validation, UMAP, and HDBSCAN are not provided, making exact reproduction challenging
- Waterfall plot generalization lacks validation for datasets with more than three classes where 2D projections may compress critical information
- Claims about clinical interpretability in ADNI data require external validation to confirm biological relevance

## Confidence

- **High confidence:** SHAP values correctly capture feature contributions to predictions when models are well-trained
- **Medium confidence:** Cross-validated SHAP calculation prevents overfitting based on theoretical soundness
- **Medium confidence:** HDBSCAN clustering reveals meaningful subgroups in SHAP space, though parameter sensitivity needs exploration
- **Low confidence:** Waterfall plot generalization validity for >3 classes without additional validation
- **Low confidence:** Claims about clinical interpretability in ADNI data without external validation

## Next Checks

1. Replicate the simulated experiment with known ground truth to verify clustering recovers the two distinct subgroups within Class 2
2. Perform sensitivity analysis varying HDBSCAN min_cluster_size and UMAP parameters to assess cluster stability and optimal granularity
3. Apply the full pipeline to a new multi-class dataset with baseline accuracy verification, comparing SHAP-based clusters against raw data clustering to quantify the added insight from supervised clustering