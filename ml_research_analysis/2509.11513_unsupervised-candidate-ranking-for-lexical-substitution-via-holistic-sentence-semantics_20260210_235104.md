---
ver: rpa2
title: Unsupervised Candidate Ranking for Lexical Substitution via Holistic Sentence
  Semantics
arxiv_id: '2509.11513'
source_url: https://arxiv.org/abs/2509.11513
tags:
- target
- token
- semantic
- lexical
- substitution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an unsupervised method for ranking lexical
  substitution candidates using holistic sentence semantics. The approach computes
  token-level semantic similarity between original and substituted sentences, weighted
  by either attention scores or Integrated Gradients to measure contextual influence.
---

# Unsupervised Candidate Ranking for Lexical Substitution via Holistic Sentence Semantics

## Quick Facts
- arXiv ID: 2509.11513
- Source URL: https://arxiv.org/abs/2509.11513
- Reference count: 0
- DeBERTa-v3 achieves GAP scores of 65.4 on LS07 and 64.4 on SWORDS datasets

## Executive Summary
This paper presents an unsupervised method for ranking lexical substitution candidates by leveraging holistic sentence semantics. The approach computes token-level semantic similarity between original and substituted sentences, using attention scores or Integrated Gradients to weight contextual influence. Experimental results on LS07 and SWORDS datasets demonstrate significant improvements over methods that only consider target token changes, with attention and Integrated Gradients weighting strategies showing highly consistent performance. The method requires minimal parameter tuning while providing interpretable weights for token contributions.

## Method Summary
The proposed method ranks lexical substitution candidates by calculating semantic similarity between original and substituted sentences at the token level. Two weighting strategies are employed: attention scores and Integrated Gradients, which measure the contextual influence of each token on the target word. This holistic approach captures sentence-level semantic changes rather than focusing solely on the target token, enabling more accurate ranking of substitution candidates. The unsupervised nature of the method eliminates the need for labeled training data, while the weighting mechanisms provide interpretability by highlighting which tokens contribute most to semantic preservation.

## Key Results
- DeBERTa-v3 achieves GAP scores of 65.4 on LS07 and 64.4 on SWORDS datasets
- Attention and Integrated Gradients weighting strategies yield highly consistent results
- Both contextual weighting approaches significantly outperform methods considering only target token changes
- Minimal parameter tuning required due to unsupervised nature of the method

## Why This Works (Mechanism)
The method works by capturing holistic sentence semantics through token-level semantic similarity calculations. By weighting tokens using attention scores or Integrated Gradients, the approach quantifies each token's contextual influence on the target word. This enables the system to identify which substitutions preserve overall sentence meaning rather than just matching individual words. The unsupervised ranking leverages pre-trained language models' understanding of semantic relationships, allowing for effective candidate evaluation without requiring labeled training data.

## Foundational Learning

### Semantic Similarity Computation
**Why needed:** To quantify how well substitution candidates maintain overall sentence meaning
**Quick check:** Verify that cosine similarity between token embeddings captures semantic relationships accurately

### Contextual Token Weighting
**Why needed:** To identify which tokens most influence the target word's semantic role in the sentence
**Quick check:** Confirm that attention scores and Integrated Gradients produce consistent weight distributions

### Holistic Sentence Analysis
**Why needed:** To evaluate substitutions based on complete sentence semantics rather than isolated word changes
**Quick check:** Ensure that token-level similarity aggregation preserves sentence-level semantic relationships

## Architecture Onboarding

### Component Map
Input sentence -> Token embedding extraction -> Semantic similarity computation -> Weight calculation (attention/Integrated Gradients) -> Aggregation -> Candidate ranking

### Critical Path
The core processing pipeline involves: (1) generating substituted sentences for each candidate, (2) extracting token embeddings using DeBERTa-v3, (3) computing token-level semantic similarity between original and substituted versions, (4) applying contextual weighting through attention or Integrated Gradients, and (5) aggregating weighted similarities to produce final rankings.

### Design Tradeoffs
The method prioritizes unsupervised learning to avoid dependency on labeled data, but this limits direct semantic validation. Attention-based weighting offers computational efficiency while Integrated Gradients provides gradient-based interpretability. The choice between these methods involves balancing speed versus theoretical grounding in attribution methods.

### Failure Signatures
Performance degradation occurs when semantic similarity measures fail to capture nuanced meaning changes, when contextual weighting overemphasizes irrelevant tokens, or when the method encounters domain-specific language patterns not well-represented in pre-training data.

### First Experiments
1. Baseline comparison using target token similarity only versus full contextual weighting
2. Ablation study comparing attention-based versus Integrated Gradients weighting performance
3. Qualitative analysis of high-weighted tokens to validate interpretability claims

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on unsupervised ranking without direct semantic validation
- Potential overfitting to benchmark datasets (LS07 and SWORDS)
- Assumption that contextual similarity via token-level changes captures semantic equivalence

## Confidence
- High confidence in claims about contextual weighting superiority (experimental results consistently favor attention and Integrated Gradients)
- Medium confidence in claims about interpretability (qualitative inspection mentioned but systematic validation absent)
- High confidence in claims about minimal parameter tuning (unsupervised nature eliminates most hyperparameters)

## Next Checks
1. Test the method on out-of-domain texts (e.g., technical writing, social media) to assess generalization of GAP scores beyond LS07 and SWORDS
2. Conduct ablation studies removing contextual weighting (attention/Integrated Gradients) to quantify the exact contribution of holistic sentence semantics versus target token similarity
3. Perform qualitative analysis with human evaluators to validate whether high-weighted tokens align with intuitive semantic importance in substituted sentences