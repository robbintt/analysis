---
ver: rpa2
title: 'MUR: Momentum Uncertainty guided Reasoning for Large Language Models'
arxiv_id: '2507.14958'
source_url: https://arxiv.org/abs/2507.14958
tags:
- uncertainty
- reasoning
- scaling
- momentum
- steps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work tackles the inefficiency of Large Language Models (LLMs)
  in reasoning-intensive tasks, where excessive token usage during test-time scaling
  often leads to overthinking without performance gains. Inspired by momentum in physics,
  it introduces Momentum Uncertainty-guided Reasoning (MUR), a training-free approach
  that dynamically allocates computational budgets to critical reasoning steps by
  tracking and aggregating step-wise uncertainty over time.
---

# MUR: Momentum Uncertainty guided Reasoning for Large Language Models

## Quick Facts
- arXiv ID: 2507.14958
- Source URL: https://arxiv.org/abs/2507.14958
- Reference count: 40
- Key result: Reduces token usage by 50%+ while improving accuracy 0.62-3.37% on math reasoning tasks

## Executive Summary
This work tackles the inefficiency of Large Language Models (LLMs) in reasoning-intensive tasks, where excessive token usage during test-time scaling often leads to overthinking without performance gains. Inspired by momentum in physics, it introduces Momentum Uncertainty-guided Reasoning (MUR), a training-free approach that dynamically allocates computational budgets to critical reasoning steps by tracking and aggregating step-wise uncertainty over time. MUR uses a γ-control mechanism to flexibly tune the reasoning budget via a single hyperparameter. Theoretical analysis proves MUR's advantages in stability, convergence, and discounted credit assignment.

## Method Summary
MUR introduces a training-free approach that dynamically allocates test-time compute based on step-wise uncertainty measurement. The method tracks uncertainty momentum across reasoning steps, using a momentum parameter (α=0.9) to aggregate uncertainty values. When uncertainty exceeds a threshold determined by the γ-control mechanism (default γ=0.9), additional test-time scaling is applied to that step. The approach is evaluated on four challenging benchmarks (MATH-500, AIME24, AIME25, GPQA-diamond) using Qwen3 models (1.7B, 4B, 8B) with a GenPRM 1.5B reward model for scaling decisions.

## Key Results
- Reduces token usage by over 50% on average across all evaluated models and benchmarks
- Improves accuracy by 0.62-3.37% compared to baseline test-time scaling approaches
- Maintains performance gains across different model sizes (1.7B, 4B, 8B) and challenging mathematical reasoning tasks

## Why This Works (Mechanism)
MUR works by dynamically allocating computational resources to reasoning steps based on their uncertainty levels, rather than applying uniform scaling across all steps. By tracking uncertainty momentum across steps, it identifies critical decision points where additional computation is most likely to improve outcomes. The γ-control mechanism provides a single tunable parameter to balance computational efficiency against reasoning depth, allowing the system to skip unnecessary scaling on low-uncertainty steps while focusing resources where they matter most.

## Foundational Learning

### Uncertainty quantification
- Why needed: Forms the basis for deciding when additional computation is warranted
- Quick check: Verify negative log-likelihood calculation per token and per-step averaging

### Momentum-based aggregation
- Why needed: Smooths noisy uncertainty measurements and identifies trends across reasoning steps
- Quick check: Confirm α=0.9 momentum parameter implementation and initialization (M0=0)

### Test-time scaling
- Why needed: Provides the computational budget that MUR allocates dynamically
- Quick check: Verify temperature=0.6 setting and vLLM inference configuration

## Architecture Onboarding

### Component map
Input Problem -> Step Segmentation -> Token Generation -> Uncertainty Measurement -> Momentum Update -> γ-control Decision -> (Optional) Test-time Scaling -> Output Solution

### Critical path
Problem → Step Segmentation → Token Generation → Uncertainty Measurement → γ-control Decision → Output (or TTS → Output)

### Design tradeoffs
- Fixed vs adaptive γ: Manual tuning vs automatic adjustment
- Binary vs granular scaling: All-or-nothing vs variable compute allocation
- Single vs multiple uncertainty metrics: Simplicity vs potential accuracy gains

### Failure signatures
- Momentum too noisy: Poor uncertainty estimation or insufficient aggregation
- Scaling too aggressive: γ set too high, triggering scaling on low-value steps
- Scaling too sparse: γ set too low, missing critical reasoning opportunities

### 3 first experiments
1. Validate uncertainty measurement on a single step with known difficulty
2. Test momentum accumulation across 3-5 reasoning steps
3. Evaluate γ-control threshold crossing behavior with varying γ values

## Open Questions the Paper Calls Out

### Open Question 1
Can compute allocation be made granular rather than binary? MUR's detector is currently binary—triggering scaling or not—without controlling scaling intensity. Future work could vary N in Best-of-N or thinking length based on uncertainty magnitude.

### Open Question 2
Does momentum uncertainty generalize across diverse model architectures beyond Qwen3? All experiments use only Qwen3 models; cross-architecture evaluation would validate broader applicability.

### Open Question 3
Can γ and α be automatically tuned rather than manually set? Optimal values may depend on task difficulty, model size, or reasoning domain. An adaptive mechanism could dynamically adjust these hyperparameters.

## Limitations
- Implementation details for prompt templates and reward model specifics are not fully specified
- Performance gains may be sensitive to hyperparameter tuning (γ and α)
- Evaluation limited to mathematical reasoning tasks, limiting generalizability

## Confidence

**High confidence**: Theoretical analysis of stability and convergence properties
**Medium confidence**: Performance improvements are likely reproducible but may vary with implementation details
**Low confidence**: Absolute magnitude of gains across different model families and domains

## Next Checks

1. Test the impact of different step segmentation prompts on uncertainty measurement quality and downstream performance
2. Systematically vary γ (0.7, 0.8, 0.9, 0.95) and α (0.7, 0.8, 0.9, 0.95) to determine hyperparameter robustness
3. Evaluate MUR on non-mathematical reasoning tasks (e.g., commonsense reasoning, code generation) to assess domain generalization