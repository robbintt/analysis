---
ver: rpa2
title: 'MaRVIn: A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference,
  from ISA Extension to Hardware Acceleration'
arxiv_id: '2509.15187'
source_url: https://arxiv.org/abs/2509.15187
tags:
- mixed-precision
- accuracy
- precision
- design
- power
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the lack of efficient architectural support
  for mixed-precision neural network execution on embedded RISC-V processors, which
  leads to performance bottlenecks due to excessive data packing/unpacking and underutilized
  arithmetic units. The authors propose MaRVIn, a cross-layer hardware-software co-design
  framework that extends the RISC-V ISA with nine new mixed-precision instructions
  and implements micro-architectural enhancements including configurable mixed-precision
  arithmetic (2, 4, 8 bits), multi-pumping for reduced execution latency, and soft
  SIMD for efficient 2-bit operations.
---

# MaRVIn: A Cross-Layer Mixed-Precision RISC-V Framework for DNN Inference, from ISA Extension to Hardware Acceleration

## Quick Facts
- **arXiv ID:** 2509.15187
- **Source URL:** https://arxiv.org/abs/2509.15187
- **Reference count:** 40
- **Primary result:** Achieves 17.6× average speedup with <1% accuracy loss for DNN inference on RISC-V via mixed-precision ISA extensions and microarchitectural enhancements.

## Executive Summary
This paper introduces MaRVIn, a cross-layer co-design framework that extends the RISC-V ISA with mixed-precision instructions and enhances the Ibex core to accelerate DNN inference. The framework addresses inefficiencies in current RISC-V processors caused by data packing overhead and underutilization of arithmetic units during neural network execution. By integrating a new ISA, microarchitectural changes (including a fourth multiplier and soft SIMD), and a design space exploration for mixed quantization, MaRVIn demonstrates significant speedups and energy efficiency on standard DNN benchmarks.

## Method Summary
MaRVIn proposes a hardware-software co-design approach to enable efficient mixed-precision DNN inference on embedded RISC-V processors. The method involves: (1) ISA extension with nine new mixed-precision MAC instructions supporting 2, 4, and 8-bit operands, (2) microarchitectural enhancements to the Ibex core including a fourth multiplier, multi-pumping for ALU frequency doubling, and soft SIMD for 2-bit operations, (3) a software layer that performs pruning-aware fine-tuning followed by a greedy-based design space exploration to find Pareto-optimal layer-wise mixed-precision configurations, and (4) evaluation via cycle-accurate emulation and synthesis targeting both FPGA and ASIC implementations.

## Key Results
- Achieves an average 17.6× speedup over baseline Ibex with less than 1% accuracy loss on standard DNNs.
- Delivers up to 1.8 TOPs/W energy efficiency in 22nm ASIC implementation.
- Demonstrates significant reduction in memory accesses due to mixed-precision data representation and reduced bit-width operations.

## Why This Works (Mechanism)
MaRVIn works by eliminating the overhead of data packing/unpacking in mixed-precision neural network execution and by better utilizing the processor's arithmetic resources. The new ISA extensions allow direct mixed-precision MAC operations, while microarchitectural enhancements like multi-pumping and soft SIMD enable parallel and efficient execution of low-bit-width operations. The software layer's design space exploration ensures that each layer uses an optimal bit-width configuration, balancing accuracy and performance.

## Foundational Learning
- **Mixed-precision quantization:** Reducing the numerical precision (bit-width) of weights and activations in DNNs to save memory and computation. Needed because higher precision consumes more resources without proportional accuracy gains. Quick check: Verify that 2/4/8-bit quantization is supported and correctly implemented.
- **ISA extension:** Adding new custom instructions to a processor's instruction set to enable specialized operations. Needed to support efficient mixed-precision MACs directly in hardware. Quick check: Confirm the nine new instructions are correctly integrated and functional.
- **Multi-pumping:** Running parts of the hardware (e.g., ALU) at a higher clock frequency than the core to improve throughput. Needed to enable parallel execution of multiple low-bit operations. Quick check: Verify timing closure at the target frequencies.
- **Soft SIMD:** Software-based implementation of SIMD (Single Instruction, Multiple Data) for parallel processing of multiple low-bit data elements. Needed to efficiently handle 2-bit operations. Quick check: Confirm that 2-bit data packing and unpacking logic is correct.
- **Design Space Exploration (DSE):** Systematic search for optimal configurations (e.g., bit-width per layer) that balance accuracy and efficiency. Needed to identify Pareto-optimal mixed-precision models. Quick check: Verify that the DSE produces expected Pareto fronts and configurations.
- **Pruning-aware fine-tuning:** Fine-tuning a DNN after structured pruning to recover accuracy. Needed to allow aggressive quantization without significant accuracy loss. Quick check: Confirm that fine-tuning recovers accuracy after pruning.

## Architecture Onboarding
- **Component map:** Ibex core (ALU, multiplier, decoder) -> ISA extensions (9 custom nn_mac instructions) -> Microarchitectural enhancements (4th multiplier, multi-pumping, soft SIMD) -> Software DSE and fine-tuning -> Cycle-accurate emulation (Verilator) and synthesis (Vivado/Synopsys).
- **Critical path:** The critical path involves the new mixed-precision MAC operations, which rely on the fourth multiplier and soft SIMD logic. Multi-pumping introduces a timing-critical fast clock domain for the ALU.
- **Design tradeoffs:** The addition of a fourth multiplier and increased ALU frequency improves performance but increases area and power. Soft SIMD adds complexity to data packing/unpacking. DSE adds exploration overhead but enables optimal configurations.
- **Failure signatures:** Timing violations on the fast ALU clock (multi-pumping), accuracy loss beyond acceptable thresholds, and synthesis failures due to resource constraints.
- **First experiments:**
    1. Synthesize the modified Ibex core and verify timing closure at target frequencies.
    2. Run the DSE on a pre-trained MobileNetV1 to generate mixed-precision configurations.
    3. Execute a simple DNN kernel using the custom instructions on the emulator and measure cycle counts.

## Open Questions the Paper Calls Out
- **Post-layout stability:** How do physical effects (e.g., routing delays) impact the stability and power efficiency of the multi-pumping technique, since post-layout validation was not performed?
- **Depthwise separable convolutions:** Can the hardware architecture be optimized to close the performance gap for depthwise separable convolutions, which do not benefit as much from the current data reuse strategies?
- **Compiler integration:** What is the trade-off in code efficiency and developer effort between the current manual intrinsic approach and automated compiler support, given that the framework does not integrate with the compiler?

## Limitations
- The framework has not been validated through post-layout physical design, so the actual power and timing performance may differ from synthesis estimates.
- Significant performance gains are not observed for networks with many depthwise separable convolutions (e.g., MCUNet) due to limited data reuse.
- The reliance on manual inline assembly for custom instructions limits ease of use and may miss broader optimization opportunities available through compiler integration.

## Confidence
- **Speedup claim (17.6×):** Medium — supported by emulation and synthesis, but dependent on the completeness of the public framework.
- **Accuracy loss (<1%):** Medium — results are based on the described methodology, but fine-tuning hyperparameters are not fully specified.
- **Energy efficiency (1.8 TOPs/W):** Medium — derived from ASIC synthesis, which is sensitive to implementation details and lacks post-layout validation.

## Next Checks
1. **RTL Completeness Check:** Verify the GitHub repository contains the full SystemVerilog implementation of the 4th multiplier, soft SIMD packing logic, and the decoder changes for the 9 custom instructions.
2. **DSE Algorithm Validation:** Replicate the greedy-based Design Space Exploration on a known pre-trained MobileNetV1/ResNet18 and compare the identified Pareto-optimal configurations against the paper's reported values.
3. **Timing Closure Validation:** Synthesize the modified Ibex core targeting the specified frequency (e.g., 250MHz core, 500MHz ALU) and confirm timing closure is achieved without timing violations on the critical path.