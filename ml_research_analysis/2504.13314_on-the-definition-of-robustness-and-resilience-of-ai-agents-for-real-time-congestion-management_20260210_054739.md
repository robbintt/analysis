---
ver: rpa2
title: On the Definition of Robustness and Resilience of AI Agents for Real-time Congestion
  Management
arxiv_id: '2504.13314'
source_url: https://arxiv.org/abs/2504.13314
tags:
- agent
- perturbation
- system
- robustness
- reward
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a framework to assess the robustness and resilience\
  \ of reinforcement learning (RL) agents in real-time congestion management, addressing\
  \ a gap in the European Union\u2019s AI Act, which mandates robustness and resilience\
  \ but lacks assessment methodologies. The approach uses the Grid2Op digital environment,\
  \ where perturbation agents simulate natural and adversarial disruptions by altering\
  \ AI input data without modifying the actual system state."
---

# On the Definition of Robustness and Resilience of AI Agents for Real-time Congestion Management

## Quick Facts
- arXiv ID: 2504.13314
- Source URL: https://arxiv.org/abs/2504.13314
- Reference count: 19
- This paper proposes a framework to assess robustness and resilience of RL agents in real-time congestion management, addressing a gap in the EU's AI Act.

## Executive Summary
This paper addresses the EU AI Act's requirement for robust and resilient AI systems by proposing a quantitative framework to assess RL agents for real-time congestion management in power grids. The approach uses the Grid2Op digital environment where perturbation agents simulate natural and adversarial disruptions by modifying AI input data without altering the actual grid state. Experimental results on the IEEE-14 bus system demonstrate that the framework effectively identifies vulnerabilities, with RL-based perturbation agents causing significant performance degradation (below 30% in key metrics) compared to random and gradient-based perturbations.

## Method Summary
The framework employs three types of perturbation agents to test AI robustness and resilience: Random Perturbation Agent (RPA), Gradient Estimation Perturbation Agent (GEPA), and RL-based Perturbation Agent (RLPA). These agents operate in the Grid2Op environment using the IEEE-14 bus system, where they intercept and modify input observations to the AI agent without changing the physical grid state. Robustness is evaluated through six metrics including reward gap, action changes, and vulnerability mapping, while resilience is quantified by degradation duration, recovery time, and the area between perturbed and unperturbed reward trajectories. The framework runs 35+ episodes per perturbation method and normalizes results against an unperturbed baseline.

## Key Results
- RL-based perturbation agents (RLPA) cause significant performance drops below 30% in key metrics
- RLPA outperforms random and gradient-based perturbations in terms of action changes (53.4 per 1000 steps)
- The framework effectively identifies vulnerabilities in AI agents for real-time congestion management
- Resilience is quantified through degradation time, restorative time, and recovery area metrics

## Why This Works (Mechanism)

### Mechanism 1: Input-Space Perturbation for Safe Vulnerability Assessment
- Claim: Perturbation agents can assess AI vulnerabilities by intercepting and modifying input data without altering the actual grid state
- Mechanism: The perturbation agent operates on the observation space (s_gen, s_load, s_flow) the AI receives, not the physical system
- Core assumption: The AI system's critical vulnerabilities are primarily in how it interprets input data
- Evidence anchors: [abstract] perturbation agents simulate disruptions by perturbing AI input without altering actual state; [section III.A] can intercept input and alter data measurements
- Break condition: If failure modes extend beyond input interpretation (e.g., actuator failures), this mechanism would not capture those risks

### Mechanism 2: RL-Based Adversarial Optimization Outperforms Gradient Methods
- Claim: RL-based perturbation agents discover more effective attack strategies than gradient estimation or random perturbations
- Mechanism: RLPA learns optimal timing and perturbation types via Q-learning, maximizing long-term performance degradation across episodes
- Core assumption: The state-action space has exploitable structure that RL can learn over multiple episodes
- Evidence anchors: [abstract] RL-based perturbation agents causing significant performance drops below 30%; [section IV.B, Table I] RLPA causes the most action changes
- Break condition: If the AI agent is adversarially trained against RL-based attacks, effectiveness gap would diminish

### Mechanism 3: Resilience Quantification via Degradation-Recovery Dynamics
- Claim: Resilience can be measured by quantifying degradation duration, recovery time, and the area between perturbed/unperturbed reward trajectories
- Mechanism: Framework defines h_min (minimum reward after perturbation onset) and h_max (recovery point), then computes degradation/restorative time and integrated reward gap
- Core assumption: The AI system can recover from perturbations without external intervention
- Evidence anchors: [abstract] resilience is quantified by recovery from performance degradation; [section III.C] mathematical formulation of degradation/restorative time
- Break condition: If perturbations cause cascading failures that prevent recovery, resilience metrics become undefined

## Foundational Learning

- Concept: Markov Decision Processes (MDPs) and Q-Learning
  - Why needed here: RLPA uses Q-learning to learn optimal perturbation strategies
  - Quick check question: Why does the perturbation agent store Q(s,p) rather than Q(s,a)?

- Concept: Adversarial Examples (FGSM, Projected Gradient Descent)
  - Why needed here: GEPA uses PGD and RLPA uses Fast Gradient Sign Method; both require understanding gradient-based input manipulation
  - Quick check question: What does the 10% perturbation bound (ξ) represent, and why is this threshold used?

- Concept: Power System State Estimation and SCADA Architecture
  - Why needed here: The paper focuses on state-space perturbations because SCADA/estimation systems are realistic attack surfaces
  - Quick check question: Why does the paper exclude action-space and reward-function attacks from scope?

## Architecture Onboarding

- Component map: Grid2Op environment -> AI agent (curriculum agent) -> Perturbation agents (RPA, GEPA, RLPA) -> Metrics module

- Critical path:
  1. Load pre-trained AI agent and Grid2Op scenario
  2. Initialize perturbation agent with parameters
  3. Run 35+ episodes, logging performance metrics
  4. Compute robustness metrics per episode; aggregate across runs
  5. Compute resilience metrics (degradation time, restorative time, recovery area)

- Design tradeoffs:
  - Perturbation budget (ξ = 10%): Chosen as undetectable by AC state estimation
  - Episode length (8064 steps): Enables multiple degradation-recovery cycles
  - RLPA training time vs. attack effectiveness: Longer training yields better strategies

- Failure signatures:
  - RLPA causes >70% drop in survival time/reward: AI agent highly vulnerable
  - Similarity score <0.05 per changed action: Alternative actions fundamentally different
  - Restorative time >1000 steps: AI struggles to recover; may require adversarial training

- First 3 experiments:
  1. Baseline characterization: Run unperturbed AI agent for 35 episodes
  2. RPA sensitivity sweep: Vary perturbation probability (p = 20%, 40%, 60%, 80%, 100%)
  3. Vulnerability mapping: Run RLPA for 50+ episodes; generate heatmap of most-exploitable grid components

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can threshold values for the proposed robustness and resilience metrics be systematically co-identified with decision-makers to certify an AI-based system for safe operation?
- Basis in paper: [explicit] Future work includes developing methodology to co-identify thresholds with decision-makers
- Why unresolved: The paper provides quantitative metrics but does not establish acceptable performance levels or certification criteria
- What evidence would resolve it: A structured methodology validated with grid operators that maps metric thresholds to risk tolerance levels

### Open Question 2
- Question: How can adversarial agents be enhanced to optimize attack strategies by incorporating features such as attack location selection and perturbation budget constraints into their reward functions?
- Basis in paper: [explicit] Future work includes developing more intelligent adversarial agents with features in reward function
- Why unresolved: Current RLPA uses fixed 10% perturbation bound and does not learn optimal attack allocation
- What evidence would resolve it: Demonstrations of enhanced RL-based perturbation agents that outperform RLPA

### Open Question 3
- Question: Does the proposed framework scale effectively to larger, more complex power grid topologies beyond the simplified IEEE-14 bus system?
- Basis in paper: [inferred] Case study acknowledges IEEE-14 is a simple approximation but no experiments on larger systems
- Why unresolved: Computational complexity may grow non-linearly with network size
- What evidence would resolve it: Experimental results applying framework to larger benchmark grids

## Limitations

- The framework assumes vulnerabilities primarily stem from corrupted observations rather than downstream system failures
- The 10% perturbation threshold is borrowed from state estimation literature without independent validation for congestion management
- Comparative effectiveness of perturbation methods lacks statistical significance testing

## Confidence

- High confidence: The mathematical framework for quantifying robustness and resilience (Eqs. 3-16) is internally consistent
- Medium confidence: The comparative effectiveness of perturbation methods is demonstrated but lacks statistical validation
- Medium confidence: The resilience metrics based on degradation-recovery dynamics are theoretically sound but may not generalize to all systems

## Next Checks

1. **Statistical validation**: Run 100+ episodes per perturbation method to establish confidence intervals and perform statistical significance testing on performance differences

2. **Budget sensitivity analysis**: Test the framework with different perturbation bounds (ξ = 5%, 15%, 20%) to validate the "undetectable" threshold assumption and assess attack effectiveness scaling

3. **Cross-grid validation**: Apply the framework to at least two additional grid configurations (e.g., IEEE-39 or IEEE-118) to verify generalizability beyond the IEEE-14 bus system