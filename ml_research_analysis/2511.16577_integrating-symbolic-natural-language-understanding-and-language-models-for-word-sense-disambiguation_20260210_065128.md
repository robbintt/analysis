---
ver: rpa2
title: Integrating Symbolic Natural Language Understanding and Language Models for
  Word Sense Disambiguation
arxiv_id: '2511.16577'
source_url: https://arxiv.org/abs/2511.16577
tags:
- language
- disambiguation
- semantic
- word
- symbolic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses word sense disambiguation for fine-grained
  semantic distinctions by integrating symbolic natural language understanding (NLU)
  systems with large language models (LLMs). The core method generates multiple candidate
  meanings from a symbolic NLU system, converts them to natural language descriptions,
  and uses an LLM to select the most appropriate interpretation given context.
---

# Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation

## Quick Facts
- arXiv ID: 2511.16577
- Source URL: https://arxiv.org/abs/2511.16577
- Reference count: 3
- Primary result: Hybrid symbolic-LLM approach achieves 82.5% accuracy on fine-grained predicate disambiguation vs 20.2% for BERT

## Executive Summary
This paper presents a hybrid approach to word sense disambiguation that combines symbolic natural language understanding (NLU) systems with large language models (LLMs). The method generates multiple candidate meanings from a symbolic NLU system, converts them to natural language descriptions, and uses an LLM to select the most appropriate interpretation given context. This eliminates the need for hand-annotated training data while achieving substantial improvements over traditional neural baselines. The approach demonstrates effectiveness for both coarse-grained frame disambiguation (84.2% accuracy) and fine-grained predicate disambiguation (82.5% accuracy), with particularly striking improvements over BERT baselines (20.2% accuracy).

## Method Summary
The core methodology involves a symbolic NLU system generating multiple candidate meanings for words in context, which are then converted to natural language descriptions. An LLM evaluates these candidates against the surrounding context to select the most appropriate interpretation. This hybrid approach leverages the explicit knowledge representation of symbolic systems with the contextual understanding capabilities of LLMs. The method avoids the need for extensive hand-annotated training data typically required for supervised disambiguation approaches, instead relying on the knowledge base of the symbolic system and the reasoning capabilities of the LLM to make disambiguation decisions.

## Key Results
- Achieves 84.2% accuracy for coarse-grained frame disambiguation on COPA premises
- Achieves 82.5% accuracy for fine-grained predicate disambiguation on COPA premises
- Outperforms BERT baselines significantly: 69.3% vs 84.2% (coarse) and 20.2% vs 82.5% (fine-grained)

## Why This Works (Mechanism)
The method works by combining the explicit semantic knowledge representation of symbolic NLU systems with the contextual reasoning capabilities of LLMs. The symbolic system provides structured candidate meanings with semantic relationships, while the LLM evaluates these candidates in context to make final disambiguation decisions. This hybrid approach overcomes the limitations of both pure symbolic methods (which may lack contextual flexibility) and pure neural methods (which may struggle with fine-grained semantic distinctions without extensive training data).

## Foundational Learning
- **Symbolic NLU Systems**: Knowledge representation systems that encode semantic relationships explicitly - needed to generate structured candidate meanings with semantic precision
- **Large Language Models**: Neural models trained on vast text corpora - needed for contextual reasoning and selection among candidate meanings
- **Word Sense Disambiguation**: The task of determining which meaning of a word is used in context - needed to enable precise semantic interpretation in NLP applications
- **Frame Semantics**: Theory that words evoke frames (conceptual structures) - needed for organizing semantic knowledge in symbolic systems
- **Predicate Disambiguation**: Distinguishing between fine-grained senses of predicates - needed for precise semantic interpretation beyond coarse categories

## Architecture Onboarding
- **Component Map**: Symbolic NLU System -> Candidate Generation -> LLM Evaluation -> Final Disambiguation
- **Critical Path**: Input text → Symbolic candidate generation → NL description conversion → LLM context evaluation → Selected meaning output
- **Design Tradeoffs**: Symbolic precision vs neural flexibility; no training data requirement vs potential knowledge base limitations
- **Failure Signatures**: When symbolic system coverage is incomplete; when LLM context evaluation is ambiguous; when fine-grained distinctions exceed LLM reasoning capabilities
- **3 First Experiments**:
  1. Test symbolic NLU system coverage on diverse domains beyond COPA
  2. Evaluate computational cost of candidate generation and LLM evaluation pipeline
  3. Conduct ablation study removing either symbolic component or LLM selection

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to COPA dataset, raising questions about generalizability to other domains and languages
- Computational cost of generating multiple candidates and processing through LLM not addressed
- No detailed error analysis to understand failure modes and limitations

## Confidence
- Hybrid approach effectiveness: High
- Claims about eliminating training data needs: High
- Generalizability beyond COPA: Low
- Computational efficiency: Low

## Next Checks
1. Test the method on additional benchmark datasets beyond COPA to assess generalizability across different domains and linguistic phenomena
2. Conduct a detailed ablation study to determine the contribution of individual components (symbolic NLU system vs. LLM selection) and identify potential bottlenecks
3. Perform an error analysis on challenging cases to understand the types of semantic distinctions that remain difficult for the hybrid approach and whether certain word classes or semantic relations pose particular challenges