---
ver: rpa2
title: Cost and accuracy of long-term memory in Distributed Multi-Agent Systems based
  on Large Language Models
arxiv_id: '2601.07978'
source_url: https://arxiv.org/abs/2601.07978
tags:
- arxiv
- available
- online
- memory
- mem0
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a testbed to evaluate long-term memory frameworks\
  \ in distributed multi-agent systems under varying network conditions. Two memory\
  \ systems\u2014mem0 (vector-based) and Graphiti (graph-based)\u2014were compared\
  \ using the LoCoMo benchmark in unconstrained and constrained network scenarios."
---

# Cost and accuracy of long-term memory in Distributed Multi-Agent Systems based on Large Language Models

## Quick Facts
- arXiv ID: 2601.07978
- Source URL: https://arxiv.org/abs/2601.07978
- Reference count: 40
- Primary result: Vector-based memory (mem0) significantly outperforms graph-based memory (Graphiti) in computational and financial efficiency while maintaining equivalent accuracy

## Executive Summary
This study evaluates two long-term memory frameworks—mem0 (vector-based) and Graphiti (graph-based)—in distributed multi-agent systems under varying network conditions. Using the LoCoMo benchmark in both unconstrained and constrained network scenarios, the research demonstrates that mem0 offers substantial improvements in loading time, resource consumption, and cost without sacrificing accuracy. The findings suggest mem0 is Pareto optimal for DMAS environments, providing a statistically validated framework for selecting memory systems based on cost and accuracy trade-offs.

## Method Summary
The study employs a factorial design comparing mem0 and Graphiti across unconstrained and constrained network profiles using the LoCoMo benchmark. The three-agent MAS architecture includes a coordinator (qwen2.5:3b-instruct), memory agent (mem0 with Qdrant or Graphiti with Neo4j), and responder (gpt-4o-mini). Network constraints are simulated via toxiproxy with 200ms latency and 8Mbit bandwidth. Performance is measured across computational (CPU, RAM, disk, network), financial (OpenAI tokens, USD cost), and accuracy (string + semantic similarity) metrics, with statistical significance determined through Wilson CIs, z-tests, and Pareto efficiency analysis.

## Key Results
- mem0 was 86.5% faster during the loading phase compared to Graphiti
- mem0 achieved 14.7% faster query response times with 232.5% less disk usage at the edge
- Statistical analysis showed no significant accuracy differences between frameworks, making mem0 the Pareto optimal choice based on cost-efficiency

## Why This Works (Mechanism)

### Mechanism 1
Vector-based memory with LLM compression (mem0) reduces loading-phase latency and resource consumption significantly compared to graph-based knowledge extraction (Graphiti) for conversational data. mem0 relies on efficient embedding generation and vector storage, whereas Graphiti requires computationally intensive entity extraction and relationship construction within the Neo4j database. This architectural difference minimizes the computational overhead per "turn" of conversation ingested.

### Mechanism 2
Despite structural differences, vector and graph retrievals yield statistically equivalent accuracy for the specific task of question-answering on the LoCoMo benchmark. Both systems successfully retrieve a context window sufficient for the responder LLM to formulate an answer. The high "I don't know" rate suggests the bottleneck is often the lack of information in the source text or retrieval recall limits common to both approaches, rather than the precision of the specific storage format.

### Mechanism 3
A hybrid cloud-edge DMAS architecture is resilient to moderate network degradation regarding total cost and latency. The dominant cost drivers are local computation and LLM inference calls, which outweigh the transmission time of relatively small JSON payloads. The system is not "chatty" enough for 200ms latency to degrade total runtime significantly.

## Foundational Learning

- **Concept: Vector Database vs. Knowledge Graph**
  - **Why needed here:** The core comparison is between these two memory paradigms. Vectors rely on semantic similarity while Graphs rely on explicit entities and relationships.
  - **Quick check question:** If I ask "Who works with whom?", which system likely requires fewer hops to find the answer if the data was ingested as raw chat logs?

- **Concept: Statistical Significance (p-value)**
  - **Why needed here:** The paper claims mem0 is better based entirely on the lack of statistical significance in accuracy differences. Understanding that "raw accuracy 11.1% vs 7.5%" might be random noise (p=0.22) is crucial to accepting the conclusion.
  - **Quick check question:** If the p-value was 0.01 instead of 0.22, would the conclusion of "Pareto efficiency" still hold?

- **Concept: Pareto Efficiency**
  - **Why needed here:** This is the decision framework used. A solution is Pareto optimal if it improves one metric without degrading another.
  - **Quick check question:** In this study, does mem0 strictly "dominate" Graphiti, or is it a trade-off?

## Architecture Onboarding

- **Component map:** Coordinator (Cloud) -> Memory Agent (Edge) -> Responder (Edge)
- **Critical path:** 1) Ingestion: LoCoMo -> Coordinator -> Memory Agent (Store). 2) Query: Coordinator -> Memory Agent (Retrieve) -> Responder (Synthesize)
- **Design tradeoffs:**
  - mem0: Optimized for speed and cost using LLM compression. Risk: May lose nuance in compression.
  - Graphiti: Optimized for structural richness building explicit knowledge graph. Risk: High computational cost during loading.
  - Network: Prioritizes robustness over speed. Network degradation is tolerated but not the bottleneck.
- **Failure signatures:**
  - High IDK Rate (>60%): Indicates retrieval mechanism failure or model conservatism
  - Loading Timeouts: Likely specific to Graphiti under resource constraints
  - Disk Saturation: Graphiti showed significantly higher disk usage in the cloud component
- **First 3 experiments:**
  1. Baseline Reproduction: Run unconstrained experiment to verify 86% loading time difference and statistical overlap in accuracy
  2. IDK Root Cause Analysis: Modify Responder prompt to be less conservative and measure if accuracy gap widens
  3. Network Stress Test: Increase latency to >500ms or bandwidth to <1 Mbit to find the actual break point

## Open Questions the Paper Calls Out

- **Root causes of high IDK responses:** The authors note that the DMAS responded to a significant number of questions with IDK and suggest future work should investigate the root causes of these responses. Ablation studies analyzing retrieval logs and prompt adherence could distinguish between retrieval failures and model refusals.

- **Comparison with standard RAG baseline:** The paper suggests running experiments with a standard RAG system based on a vector database as a control group to clarify how mem0's compression algorithm or Graphiti's knowledge graph engine influences result quality.

- **Performance in autonomous DMAS architectures:** The current study relied on prescribed loading and Q&A phases; the overhead of autonomous discovery in a distributed environment is unmeasured. The paper suggests future work should enable agents to explore their surrounding network participants on their own accord.

## Limitations
- Results are based on a specific three-agent system architecture with fixed prompt structures and may not generalize to other configurations
- The statistical significance framework revealed only marginal accuracy differences that could become meaningful with different datasets or more complex relational queries
- Network constraints were simulated at moderate levels (200ms latency, 8Mbit bandwidth) and may not reflect real-world edge deployments under extreme conditions

## Confidence
- **High confidence:** Computational and financial efficiency comparisons between mem0 and Graphiti (supported by concrete metrics across multiple resource dimensions with clear statistical differences)
- **Medium confidence:** Statistical equivalence of accuracy between memory frameworks (supported by non-significant p-values but based on single benchmark with high "I don't know" rates)
- **Medium confidence:** Network constraint resilience (supported by minimal performance variation but limited to moderate simulated conditions)

## Next Checks
1. **Architecture sensitivity test:** Modify the responder prompt to be less conservative and measure if accuracy differences between mem0 and Graphiti become statistically significant, revealing whether the current IDK rate masks true retrieval performance differences.

2. **Query complexity escalation:** Test both memory systems with queries requiring multi-hop reasoning to determine if Graphiti's structural advantages emerge for relational queries beyond simple factual retrieval.

3. **Network stress threshold identification:** Systematically increase network constraints to identify the actual break point where network overhead overtakes computation time, revealing the true limits of the system's network resilience.