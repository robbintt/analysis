---
ver: rpa2
title: 'Noosemia: toward a Cognitive and Phenomenological Account of Intentionality
  Attribution in Human-Generative AI Interaction'
arxiv_id: '2508.02622'
source_url: https://arxiv.org/abs/2508.02622
tags:
- human
- systems
- meaning
- https
- cognitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Noosemia, a novel cognitive and phenomenological
  phenomenon where users attribute intentionality, agency, and interiority to generative
  AI systems through linguistic interaction rather than physical resemblance. The
  authors link this projection to the LLM Contextual Cognitive Field and semantic
  holism, formalizing how meaning is relationally constructed within large context
  windows.
---

# Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction

## Quick Facts
- **arXiv ID:** 2508.02622
- **Source URL:** https://arxiv.org/abs/2508.02622
- **Reference count:** 32
- **Primary result:** Introduces Noosemia, a cognitive-phenomenological phenomenon where users attribute intentionality and agency to generative AI through linguistic interaction

## Executive Summary
Noosemia is a novel cognitive and phenomenological phenomenon where humans attribute intentionality, agency, and interiority to generative AI systems through linguistic interaction rather than physical resemblance. The authors link this projection to the LLM Contextual Cognitive Field and semantic holism, formalizing how meaning is relationally constructed within large context windows. Noosemia is contrasted with pareidolia, animism, and the uncanny valley, and is positioned alongside Dennett's intentional stance. The study highlights the dual explanatory gaps—mechanistic and intentional—that arise from AI's epistemic opacity, fostering new forms of cognitive engagement and dependency.

## Method Summary
This is a theoretical paper that introduces the conceptual framework of Noosemia without empirical validation. The authors provide three formal definitions: LLM Potential Semantic Space (V^N combinatorial space), LLM Contextual Cognitive Field, and LLM Semantic Holism. The paper synthesizes 32 references across philosophy, semiotics, and cognitive science to ground the phenomenon conceptually, using anecdotal examples from author interactions with ChatGPT and GPT-4V. The study explicitly states that operationalizing and measuring Noosemia is beyond its scope, positioning itself as groundwork for future empirical research.

## Key Results
- Introduces Noosemia as a distinct cognitive-phenomenological phenomenon triggered by linguistic interaction with generative AI
- Links Noosemia to LLM Contextual Cognitive Field and semantic holism, where meaning emerges relationally across context windows
- Identifies dual explanatory gaps (mechanistic and intentional) that force users to adopt intentional stance when interacting with opaque AI systems

## Why This Works (Mechanism)

### Mechanism 1
The LLM's "Contextual Cognitive Field" generates a "simulacrum of agency" by treating the context window as a unified semantic unit rather than a sequence of isolated tokens. The Transformer architecture calculates token meaning relationally across the entire active context window, producing outputs that appear to possess unified "intent" or "understanding." Users interpret this linguistic coherence as evidence of a governing "mind."

### Mechanism 2
The "Dual Explanatory Gap" (mechanistic and intentional) forces users to adopt an "intentional stance" to make sense of opaque outputs. Because the internal causal chain and rationale are inaccessible in deep neural networks, users fill the epistemic void by projecting intentionality, treating the AI as a rational agent with beliefs and desires to predict its behavior.

### Mechanism 3
"Dialogic Surprise" (the "Wow Effect") acts as the catalyst for Noosemia by momentarily disrupting the user's predictive model. When an LLM resolves ambiguity or demonstrates creative inference that exceeds user expectation, it triggers "cognitive astonishment," suspending disbelief and allowing users to momentarily perceive a "spark of intelligence."

## Foundational Learning

- **Concept: Dennett's Intentional Stance**
  - Why needed here: Positions Noosemia as a modern specification of this broader philosophical strategy for predicting behavior when design/physical stances fail
  - Quick check question: Can you explain why we ascribe "beliefs" to a chess computer even though it only calculates matrix multiplications?

- **Concept: Semantic Holism vs. Atomic Semantics**
  - Why needed here: Core argument relies on meaning in LLMs being distributed (holistic) rather than fixed (atomic)
  - Quick check question: Does the word "bank" have a fixed meaning in an LLM, or does its vector representation shift based on context words?

- **Concept: Emergence in Complex Systems**
  - Why needed here: Authors argue agency is an emergent property of hierarchy and feedback loops, not a programmed feature
  - Quick check question: How does feedback in Transformer attention differ from simple feed-forward networks, and why does this matter for "emergent" behavior?

## Architecture Onboarding

- **Component map:** User Prompt (Sign) -> LLM Contextual Cognitive Field (Context Window + Multi-head Attention) -> Potential Semantic Space (V^N) -> Fluent Response -> Interpreter (User)
- **Critical path:** User inputs ambiguous prompt → Transformer builds hierarchical representations → Attention enacts Semantic Holism → System generates coherent output → User encounters Epistemic Opacity → User projects Noosemia to explain output
- **Design tradeoffs:** Opacity vs. Agency (complexity increases Noosemia but decreases interpretability); Surprise vs. Reliability (creative inference maximizes Wow Effect but risks hallucinations)
- **Failure signatures:** A-noosemia (collapse of projection due to repetitive errors or habituation); Semantic Drift (loss of coherence across long context windows)
- **First 3 experiments:**
  1. "Wow" Threshold Test: Measure user reports of surprise vs. utility across tasks of varying novelty to isolate Noosemia trigger
  2. Opacity vs. Explanation Ablation: Compare agency attribution between black-box LLM users and those with exposed chain-of-thought reasoning
  3. Context Field Saturation: Test if larger context windows correlate with higher perceived agency, validating Semantic Holism link

## Open Questions the Paper Calls Out

### Open Question 1
How can Noosemia be empirically operationalized and distinguished from related constructs like the "Eliza effect"? The paper provides formal definitions but lacks methodological protocols for quantitative measurement, requiring development of psychometric scales or behavioral coding schemes.

### Open Question 2
How does increased opacity and "misaligned confabulation" in reasoning models and agentic AI alter the Noosemic effect? Current observations are based on generative LLMs, while advanced "reasoning" agents introduce new layers of causal inscrutability requiring comparative user studies.

### Open Question 3
What specific cognitive or technical thresholds trigger the shift from Noosemia to A-noosemia? While A-noosemia is defined as withdrawal due to repeated failures or loss of surprise, the paper does not specify quantitative boundaries or error frequencies required to collapse psychological attribution.

## Limitations
- No empirical validation or operationalization of Noosemia as a measurable phenomenon
- Distinction between Noosemia and related attribution phenomena relies on philosophical argumentation rather than experimental evidence
- Specific mechanisms linking architectural features to cognitive projection remain speculative without systematic testing

## Confidence

- **High Confidence:** Formal definitions of LLM Potential Semantic Space (V^N), Contextual Cognitive Field, and Semantic Holism are mathematically precise and internally consistent
- **Medium Confidence:** Mechanism linking Transformer attention to semantic holism and agency attribution is plausible but not empirically demonstrated
- **Low Confidence:** Claims about "dialogic surprise" triggering Noosemia and habituation leading to A-noosemia are based on anecdotal observation rather than systematic study

## Next Checks

1. **Phenomenon Isolation Test:** Design controlled experiments comparing user attribution responses to LLM outputs versus rule-based chatbots versus human partners, systematically varying context window size, output coherence, and explanation availability.

2. **Opacity Manipulation Study:** Create parallel conditions where users interact with identical LLM outputs but with varying levels of mechanistic transparency (black box vs. attention visualization vs. chain-of-thought reasoning), measuring attribution scores.

3. **Surprise Habituation Protocol:** Implement longitudinal interaction studies tracking attribution intensity over repeated exposure, measuring whether the "wow effect" diminishes with familiarity and correlates with reduced interiority attribution.