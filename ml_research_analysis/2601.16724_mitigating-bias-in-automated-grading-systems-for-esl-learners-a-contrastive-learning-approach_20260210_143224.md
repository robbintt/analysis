---
ver: rpa2
title: 'Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive
  Learning Approach'
arxiv_id: '2601.16724'
source_url: https://arxiv.org/abs/2601.16724
tags:
- essay
- learning
- score
- contrastive
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses bias in automated essay scoring (AES) systems
  against ESL learners, where high-proficiency ESL essays were scored 10.3% lower
  than native essays of identical quality. The authors propose a contrastive learning
  approach using matched essay pairs to align latent representations of ESL and native
  writing based on quality rather than linguistic origin.
---

# Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach

## Quick Facts
- arXiv ID: 2601.16724
- Source URL: https://arxiv.org/abs/2601.16724
- Reference count: 11
- Primary result: Reduced scoring disparity between ESL and native essays by 39.9% (from 10.3% to 6.2%) while maintaining QWK=0.76

## Executive Summary
This paper addresses systematic bias in automated essay scoring systems against high-proficiency ESL learners, where baseline models scored ESL essays 10.3% lower than native essays of identical quality. The authors propose a two-stage contrastive learning approach using triplet margin loss to align latent representations of ESL and native writing based on quality rather than linguistic origin. By constructing 17,161 triplets of anchor, positive, and negative essays, they fine-tuned a DeBERTa-v3 model to reduce the scoring gap by 39.9% while maintaining substantial agreement (QWK=0.76) in educational assessment. The approach successfully disentangled sentence complexity from grammatical errors, preventing valid L2 syntactic structures from being penalized.

## Method Summary
The method employs a two-stage training process: Phase 1 uses LoRA fine-tuning on DeBERTa-v3-base with triplet margin loss to align ESL and native essay embeddings based on quality scores, and Phase 2 freezes the backbone and trains a linear regression head. The approach constructs 17,161 fairness triplets from merged ASAP 2.0 and ELLIPSE datasets, with anchor=Native essay, positive=ESL essay within ±0.02 normalized score, and negative essay outside ±0.20 margin. The model reduces the high-proficiency scoring disparity from 10.3% to 6.2% while maintaining QWK=0.76, above the 0.70 threshold for substantial agreement in educational assessment.

## Key Results
- Reduced scoring disparity between ESL and native essays by 39.9% (from 10.3% to 6.2%)
- Maintained QWK=0.76, exceeding the 0.70 threshold for substantial agreement in educational assessment
- Successfully disentangled sentence complexity from grammatical errors, preventing penalization of valid L2 syntactic structures

## Why This Works (Mechanism)

### Mechanism 1: Triplet-Based Representation Alignment
Matched essay pairs force the latent embedding space to cluster by quality rather than linguistic origin. Triplet margin loss explicitly minimizes Euclidean distance between Native anchor and ESL positive essays sharing the same human-rated score (±0.02), while maximizing distance to negative essays with different scores (±0.20). This requires semantically equivalent essays to occupy proximate embedding positions regardless of author demographic. Core assumption: Human-rated scores are valid ground truth for semantic quality, and surface-level L2 features are orthogonal to actual writing competence.

### Mechanism 2: Shortcut Learning Disruption via Attention Reallocation
Contrastive training disrupts spurious correlations between surface-level L2 markers and predicted scores by forcing the model to attend to semantic content. The triplet constraint prevents the model from using L2 surface features (prepositional misuse, clause structures) as reliable score predictors since ESL essays with these features appear in positive pairs that must be close to Native anchors lacking them. The model learns that these features do not predict score differences within matched pairs. Core assumption: Transformer attention heads in baseline models disproportionately attend to L2 markers as proxies for lower scores rather than evaluating semantic reasoning.

### Mechanism 3: Disentanglement of Syntactic Complexity from Error
Post-hoc analysis suggests the model learned to treat L2 syntactic complexity as a stylistic feature rather than an error signal. By pairing ESL essays containing valid complex L2 structures with Native essays of equivalent scores, the contrastive objective prevents the model from penalizing sentence complexity that would be rewarded in Native writing. The embedding space separates "complexity" from "error" dimensions. Core assumption: Syntactic complexity correlates positively with quality in Native essays but was being penalized in ESL essays due to spurious association with grammatical error.

## Foundational Learning

- **Concept: Triplet Margin Loss**
  - Why needed here: Core mathematical framework for contrastive alignment—understanding how margin α enforces minimum separation between quality levels while collapsing within-quality distance
  - Quick check question: Given anchor score 0.85, ESL positive score 0.84, and negative score 0.65, which distance must satisfy d(A,P) + α < d(A,N)?

- **Concept: Quadratic Weighted Kappa (QWK)**
  - Why needed here: Primary evaluation metric that accounts for chance agreement and ordinal score relationships—necessary to interpret whether 0.76 represents acceptable reliability
  - Quick check question: Why would QWK be more informative than MAE for detecting systematic bias against a subgroup?

- **Concept: Shortcut Learning in Transformers**
  - Why needed here: Explains why high-accuracy models can exhibit demographic bias—attention mechanisms may learn surface heuristics (e.g., "preposition errors → low score") instead of semantic evaluation
  - Quick check question: If a sentiment model learns that informal language correlates with negative sentiment, what failure mode does this represent when applied to professional reviews?

## Architecture Onboarding

**Component map:**
Input Essay → DeBERTa-v3-base Encoder → [CLS] Token (768-dim) → Stage 1: Triplet Margin Loss (α=1.0) → LoRA fine-tuning (r=16, query/value projections) → Stage 2: Freeze Backbone → Linear Regression Head → Normalized Score [0,1]

**Critical path:**
1. Data preparation: Merge ASAP 2.0 (Native N≈17,000, ESL N≈2,600) + ELLIPSE (ESL N≈6,000); normalize scores to [0,1]; stratify split by ESL status
2. Triplet construction: For each Native anchor with score S, select ESL positive within [S±0.02], negative within [S±0.20]
3. Stage 1 training: Contrastive fine-tuning with Triplet Margin Loss, 2 epochs, LoRA r=16
4. Stage 2 training: Freeze backbone, train linear regression head for 5 epochs
5. Evaluation: QWK on full test set + stratified residual analysis for high-proficiency essays (score >0.8)

**Design tradeoffs:**
- Margin α=1.0 vs 2.0: Aggressive alignment (α=2.0) reduced QWK to 0.718 without additional bias reduction—α=1.0 is Pareto-optimal
- Positive matching tolerance ±0.02: Ensures high-confidence quality matching (~1% score range) but constrains triplet availability
- LoRA vs full fine-tuning: Preserves pre-trained linguistic knowledge while adapting embedding space

**Failure signatures:**
- Systematic under-scoring: Both groups show negative residuals (Native: -0.27, ESL: -0.33), indicating compressed score variance rather than pure semantic understanding
- Persistent gap >8%: Suggests triplet quality issues—verify score matching tolerance and ESL representation in training
- QWK <0.70: Margin may be too aggressive; reduce α and re-evaluate

**First 3 experiments:**
1. Baseline validation: Train DeBERTa-v3 with MSE regression only (no contrastive), compute QWK and stratified residuals by ESL status to replicate 10.3% gap
2. Triplet quality audit: Manually review 50-100 triplets to verify positive pairs share semantic quality beyond score proximity (check for topic/prompt matching)
3. Margin ablation sweep: Train contrastive models with α∈{0.5, 1.0, 1.5, 2.0}, plot fairness (1 - bias gap) vs accuracy (QWK) to confirm Pareto frontier at α=1.0

## Open Questions the Paper Calls Out

- **Generalization to other architectures**: Cross-architecture generalization with BERT, RoBERTa, ELECTRA, etc. is required for real-world validation
- **Comparison with adversarial debiasing**: Comparison with alternative debiasing methods such as adversarial training is necessary future work
- **Score recalibration for accuracy**: Whether score recalibration techniques can fix the systematic underscore caused by compressed variance without re-introducing bias

## Limitations

- Systematic under-scoring for both groups suggests compressed score variance rather than pure semantic understanding
- Triplet construction relies on potentially biased human-rated scores that may perpetuate rather than correct unfairness
- Post-hoc linguistic analysis of disentanglement is correlational rather than causal, lacking direct attention mechanism evidence

## Confidence

- **High Confidence**: The quantitative reduction in scoring disparity (39.9% reduction from 10.3% to 6.2%) is methodologically sound and reproducible given the described experimental setup
- **Medium Confidence**: The mechanism claims regarding shortcut learning disruption and attention reallocation are theoretically plausible but lack direct empirical evidence from attention heatmaps or causal intervention studies
- **Low Confidence**: The assumption that human-rated scores are unbiased ground truth for semantic quality. If human raters exhibit anti-ESL bias, the triplet construction could perpetuate rather than correct this bias

## Next Checks

1. **Human Rater Bias Audit**: Re-score a stratified sample of 100 high-proficiency ESL and Native essays using multiple independent raters, then analyze inter-rater reliability and potential demographic bias patterns before constructing triplets
2. **Attention Pattern Analysis**: Generate and compare attention heatmaps for baseline vs. contrastive models on matched essay pairs, specifically examining whether L2 surface features receive systematically different attention weights post-training
3. **Causal Intervention Test**: Using intervention-based methods (e.g., causal mediation analysis), quantify the direct effect of ESL status on predictions while holding semantic features constant, to verify that bias reduction occurs through semantic alignment rather than score compression