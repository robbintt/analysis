---
ver: rpa2
title: 'FarsiMCQGen: a Persian Multiple-choice Question Generation Framework'
arxiv_id: '2510.15134'
source_url: https://arxiv.org/abs/2510.15134
tags:
- questions
- question
- generation
- answer
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents FarsiMCQGen, a Persian multiple-choice question
  generation framework that addresses the challenge of generating high-quality MCQs
  in low-resource languages. The framework combines candidate generation, filtering,
  and ranking techniques using Transformers, knowledge graphs, and rule-based approaches
  to create credible distractors.
---

# FarsiMCQGen: a Persian Multiple-choice Question Generation Framework

## Quick Facts
- **arXiv ID**: 2510.15134
- **Source URL**: https://arxiv.org/abs/2510.15134
- **Reference count**: 16
- **Primary result**: Framework generates Persian MCQs with 29.5%-49.2% accuracy across six LLMs

## Executive Summary
FarsiMCQGen addresses the challenge of generating high-quality multiple-choice questions in Persian, a low-resource language. The framework combines candidate generation, filtering, and ranking techniques using Transformers, knowledge graphs, and rule-based approaches to create credible distractors. A novel Persian MCQ dataset of 10,289 questions was constructed from Wikipedia content and evaluated using six state-of-the-art large language models. Human evaluation confirmed 97.5% valid questions and 94.5% effective distractors, demonstrating the framework's effectiveness in generating challenging and contextually appropriate MCQs for Persian language assessment.

## Method Summary
The framework employs a three-stage approach: candidate generation using a knowledge graph and transformer models to identify potential answers and distractors, candidate filtering through rule-based approaches to eliminate invalid options, and candidate ranking using machine learning models to prioritize the most plausible distractors. The knowledge graph is constructed from Persian Wikipedia content, while transformer models are fine-tuned on Persian text. The system generates questions by selecting key facts from source material and creating plausible incorrect answers that test comprehension while maintaining contextual appropriateness.

## Key Results
- Hard accuracy ranges from 29.5% to 49.2% across six state-of-the-art large language models
- Qwen2.5-14B-Instruct achieved the highest performance among evaluated models
- Human evaluation confirmed 97.5% valid questions and 94.5% effective distractors on 200 samples

## Why This Works (Mechanism)
The framework's effectiveness stems from its multi-layered approach that combines semantic understanding from transformer models with structured knowledge representation from the knowledge graph. This hybrid methodology allows the system to generate distractors that are both semantically plausible and contextually appropriate, addressing the common challenge of creating challenging yet fair multiple-choice questions. The rule-based filtering ensures that distractors are not only incorrect but also believable within the context of the question, while the ranking system prioritizes the most effective options.

## Foundational Learning
- **Persian Knowledge Graph Construction**: Essential for organizing domain-specific information and relationships in Persian; quick check: verify graph connectivity and coverage across diverse topics
- **Transformer Fine-tuning for Persian**: Required to capture language-specific nuances and idiomatic expressions; quick check: test model performance on Persian NLP benchmarks
- **Rule-based Distractor Validation**: Necessary to eliminate obviously incorrect or contextually implausible options; quick check: measure precision of filtering rules on validation set
- **Candidate Ranking Algorithms**: Critical for selecting the most challenging and effective distractors; quick check: compare ranking performance against human-selected distractors
- **Persian Wikipedia Corpus Analysis**: Foundation for understanding language patterns and domain coverage; quick check: assess topic distribution and language complexity metrics
- **MCQ Generation Quality Metrics**: Needed to evaluate both question validity and distractor effectiveness; quick check: correlate automatic metrics with human evaluation scores

## Architecture Onboarding

**Component Map**: Knowledge Graph -> Transformer Models -> Rule-based Filter -> Ranking System -> Question Generator

**Critical Path**: Source Text → Knowledge Graph Extraction → Answer Identification → Distractor Generation → Filtering → Ranking → Final MCQ

**Design Tradeoffs**: Prioritizes distractor plausibility over diversity, using knowledge graph constraints that may limit creative but valid incorrect options; balances computational efficiency with comprehensive candidate generation

**Failure Signatures**: Poor distractor quality indicates knowledge graph coverage gaps; low accuracy suggests transformer model limitations in Persian; filtering failures result in obviously incorrect options

**First Experiments**:
1. Test knowledge graph coverage on 100 random Persian Wikipedia articles across different domains
2. Evaluate transformer model's ability to generate contextually appropriate distractors for 50 sample questions
3. Validate rule-based filtering precision by comparing automated results against human judgment on 100 distractor candidates

## Open Questions the Paper Calls Out
None identified in the paper.

## Limitations
- Performance evaluation relies entirely on automatic scoring by large language models rather than human-verified ground truth
- Human evaluation conducted on limited sample (200 questions, ~2% of dataset) with binary quality assessments
- Claims about generalizability to domains beyond Wikipedia content are not empirically supported

## Confidence
- **High Confidence**: Technical architecture combining Transformers, knowledge graphs, and rule-based filtering is sound
- **Medium Confidence**: Reported accuracy ranges are plausible but limited by absence of human-verified ground truth
- **Low Confidence**: Generalizability claims to diverse Persian linguistic structures and non-Wikipedia domains lack empirical support

## Next Checks
1. Conduct comprehensive human evaluation on a stratified sample (minimum 500 questions) across different domains, difficulty levels, and question types
2. Perform cross-linguistic validation by testing framework on Persian texts from varied sources beyond Wikipedia
3. Implement ablation studies comparing full framework against baseline approaches to quantify component contributions