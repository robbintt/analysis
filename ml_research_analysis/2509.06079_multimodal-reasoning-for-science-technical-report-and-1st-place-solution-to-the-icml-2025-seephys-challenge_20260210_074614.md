---
ver: rpa2
title: 'Multimodal Reasoning for Science: Technical Report and 1st Place Solution
  to the ICML 2025 SeePhys Challenge'
arxiv_id: '2509.06079'
source_url: https://arxiv.org/abs/2509.06079
tags:
- reasoning
- image
- captioning
- figure
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a caption-assisted reasoning framework that
  bridges visual and textual modalities to improve multimodal reasoning in science
  tasks. The authors found that generating concise, structured captions from images
  can effectively mitigate the difficulty models face in capturing key visual details,
  and that reasoning solely on captions can yield highly competitive results.
---

# Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge

## Quick Facts
- arXiv ID: 2509.06079
- Source URL: https://arxiv.org/abs/2509.06079
- Authors: Hao Liang; Ruitao Wu; Bohan Zeng; Junbo Niu; Wentao Zhang; Bin Dong
- Reference count: 35
- 1st place in ICML 2025 SeePhys Challenge with 66.0% accuracy using caption-assisted reasoning

## Executive Summary
This paper introduces a caption-assisted reasoning framework that bridges visual and textual modalities to improve multimodal reasoning in science tasks. The authors found that generating concise, structured captions from images can effectively mitigate the difficulty models face in capturing key visual details, and that reasoning solely on captions can yield highly competitive results. Their method achieved 1st place in the ICML 2025 SeePhys Challenge and demonstrated strong generalization on the MathVerse benchmark. Across both benchmarks, caption-assisted reasoning consistently improved performance, with accuracy gains of up to 8% over direct multimodal baselines.

## Method Summary
The approach converts dense visual inputs into concise, structured text format through a specialized captioning step, then applies powerful text-based reasoning models to solve problems. The pipeline consists of Structured Captioning → optional Image Reintegration → Format Optimization → Critical Review. The method leverages the stronger logical deduction capabilities of text-only LLMs (like GPT-o3, DeepSeek-R1) by decoupling perception from reasoning. Structured captions filter noise and reduce visual redundancy while highlighting only the information needed for reasoning. The Critical Review stage acts as a secondary "judge" to catch conceptual or calculation errors before finalizing answers.

## Key Results
- Achieved 1st place in ICML 2025 SeePhys Challenge with 66.0% accuracy
- Caption-assisted reasoning improved accuracy by up to 8% over direct multimodal baselines
- Strong reasoning-oriented LLMs equipped with high-quality captions can rival or outperform end-to-end multimodal reasoning pipelines
- Demonstrated strong generalization on MathVerse benchmark beyond the primary SeePhys dataset

## Why This Works (Mechanism)

### Mechanism 1: Information Filtering and Semantic Compression
- Claim: Generating structured textual captions from images improves multimodal reasoning performance by filtering noise and reducing visual redundancy.
- Mechanism: The framework converts dense visual inputs into a concise, structured text format. This process explicitly extracts and organizes key entities, relations, and values while discarding irrelevant visual details. This creates a more direct mapping to the symbolic and logical operations required for solving science problems.
- Core assumption: The visual complexity of scientific diagrams in these benchmarks is low enough that their essential information can be fully captured in text, and that the reasoning bottleneck is visual grounding, not the loss of visual nuance.
- Break condition: This mechanism will likely fail on images where critical information is spatial, continuous, or non-verbal that cannot be easily discretized into text.

### Mechanism 2: Leveraging Stronger Textual Reasoning Capabilities
- Claim: Text-only LLMs, when provided with high-quality image captions, can match or exceed the performance of end-to-end multimodal models.
- Mechanism: Current top-tier text-only LLMs have more powerful and stable logical deduction capabilities compared to their multimodal counterparts. By using a separate, specialized captioning step to bridge the visual-to-text gap, the problem is transformed into the native domain where the reasoning model is strongest.
- Core assumption: A capable vision model can perceive the image correctly, and the error introduced by imperfect captioning is smaller than the error introduced by the multimodal model's weaker internal reasoning.
- Break condition: This mechanism assumes a powerful captioner. If the captioner is weak or hallucinates, the reasoning model will fail.

### Mechanism 3: Error Correction via a Multi-Stage Pipeline
- Claim: A sequential pipeline of structured captioning, primary reasoning, and secondary critical review reduces reasoning errors compared to single-step inference.
- Mechanism: The pipeline acts as a series of error-correcting steps. Structured captioning enforces consistency and reduces ambiguity for the reasoning model. The Critical Review step acts as a second, independent "judge" to catch conceptual or calculation errors in the initial solution before finalizing the answer.
- Core assumption: Errors in early stages are detectable and correctable by subsequent stages, and the cost of additional inference steps is justified by the accuracy gain.
- Break condition: If the initial reasoning is flawed in a way that misleads the reviewer, or if the models in the pipeline share similar systematic biases, the review step could reinforce an incorrect answer.

## Foundational Learning

- **Concept: Multimodal Alignment**
  - **Why needed here:** The core problem is bridging the gap between visual inputs (diagrams) and textual reasoning. Understanding how textual descriptions of visual elements serve as an alignment layer is central to grasping the paper's contribution.
  - **Quick check question:** How does a "structured caption" function as an alignment mechanism between a vision model and a reasoning LLM?

- **Concept: Chain-of-Thought (CoT) Reasoning**
  - **Why needed here:** The method relies on powerful text-based reasoning. The prompts are designed to elicit step-by-step logic ("step-by-step solution"). Understanding CoT is a prerequisite for understanding why the text-only models are effective.
  - **Quick check question:** Why is prompting for a step-by-step solution critical for the "Answer" component of the pipeline?

- **Concept: Model Ensembling and Cascading**
  - **Why needed here:** The proposed architecture is not a single model but a cascade of specialized models (one for captioning, another for reasoning, a third for review).
  - **Quick check question:** In the "Critical Review" stage, what are the trade-offs of using the *same* model versus a *different* model as the reviewer?

## Architecture Onboarding

- **Component map:** Input (Image + Text) -> [Captioning Module] -> Structured Caption -> [Reasoning Module] -> Proposed Answer -> [Format Optimizer] -> Formatted Answer -> [Critical Review Module] -> Final Answer

- **Critical path:** The quality of the **Structured Caption** is the most critical bottleneck. A poor or hallucinated caption will propagate errors through the entire reasoning chain, leading to a confidently wrong final answer.

- **Design tradeoffs:**
  - **Latency vs. Accuracy:** The full pipeline requires multiple sequential API calls, significantly increasing latency and cost compared to a single multimodal call.
  - **Generality vs. Specificity:** The captioning prompts are specialized for physics and geometry. Applying this to other domains would require prompt re-engineering.

- **Failure signatures:**
  - **Caption Hallucination:** The captioner invents values or relationships not present in the image, leading to a mathematically sound but factually incorrect solution.
  - **Context Window Overflow:** Long, structured captions combined with re-introduced images could exceed the reasoning model's context window for very complex problems.
  - **Review Reinforcement:** The Critical Review model is swayed by the reasoning of the first model, even if that reasoning is flawed, failing to correct the error.

- **First 3 experiments:**
  1. **Baseline Reproduction:** Implement the "Direct Multimodal Reasoning" baseline and the "Structured Captioning + Reasoning" pipeline to reproduce the performance gap on a small held-out set of SeePhys-mini problems.
  2. **Ablation of Caption Structure:** Test the "Structured Captioning" prompt against the "Default Captioning" prompt to measure the specific impact of the structured output format on reasoning accuracy.
  3. **Ablation of Critical Review:** Run the pipeline with and without the "Critical Review" step to quantify the accuracy gain provided by the secondary review model.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adaptive captioning strategies dynamically adjust granularity to handle varying task complexity?
- Basis in paper: The authors state in Future Work: "an important direction is the development of adaptive captioning strategies that can dynamically adjust the granularity and structure of captions according to task complexity."
- Why unresolved: The current "Structured Captioning" method uses fixed templates. These may be token-inefficient for simple problems or insufficient for highly complex visual inputs.
- What evidence would resolve it: A study comparing fixed-template vs. dynamic captioning performance on a stratified dataset of varying visual complexity.

### Open Question 2
- Question: Does the caption-assisted framework generalize to scientific domains with high visual information density?
- Basis in paper: The authors justify their approach by noting tasks involve "relatively simple figures" with "sparse" information. They do not test on domains where critical information is textural rather than symbolic.
- Why unresolved: Captions naturally filter "distracting visual elements," but for tasks like biology or chemistry, this filtering might discard critical high-frequency features necessary for reasoning.
- What evidence would resolve it: Evaluation on benchmarks requiring fine-grained visual discrimination rather than schematic diagrams.

### Open Question 3
- Question: How can tool-augmented reasoning be effectively integrated into the caption-based pipeline?
- Basis in paper: The authors propose integrating "program-of-thought and tool-augmented reasoning" in future work to strengthen problem-solving.
- Why unresolved: It is unclear whether external tools should operate on the raw image or the generated caption, and if the caption's semantic abstraction hinders tool utility.
- What evidence would resolve it: An ablation study measuring accuracy when tool inputs are derived from structured captions versus raw multimodal features.

## Limitations
- Limited Generalization Beyond Scientific Diagrams: The framework's effectiveness relies heavily on the assumption that scientific diagrams contain sufficient structure for complete textual encoding.
- Evaluation Dependency: The binary accuracy metric depends on GPT-o3 as an automated judge without independent validation of this judge's reliability.
- Data and Model Access Constraints: Reproducing results requires access to proprietary models and specific dataset splits with limited guidance on data acquisition.

## Confidence
- **High Confidence**: The claim that caption-assisted reasoning improves performance over direct multimodal approaches (up to 8% accuracy gains) is well-supported by empirical results on both SeePhys and MathVerse benchmarks.
- **Medium Confidence**: The assertion that strong text-based reasoners can match or exceed end-to-end multimodal models is plausible given the evidence, but depends critically on caption quality.
- **Low Confidence**: The effectiveness of the Critical Review stage as an error-correction mechanism lacks strong empirical support and doesn't provide ablation studies showing what specific error types the review catches.

## Next Checks
1. **Cross-Domain Robustness Test**: Apply the framework to non-scientific imagery (e.g., medical scans, technical drawings from engineering) to quantify performance degradation when visual information exceeds the capacity of textual abstraction.

2. **Judge Reliability Validation**: Conduct human evaluation on a subset of SeePhys problems to independently verify GPT-o3's binary accuracy judgments and identify systematic scoring biases.

3. **Caption Quality Impact Analysis**: Systematically vary caption quality (using different captioning models or intentionally degraded captions) to empirically establish the relationship between caption fidelity and final reasoning accuracy.