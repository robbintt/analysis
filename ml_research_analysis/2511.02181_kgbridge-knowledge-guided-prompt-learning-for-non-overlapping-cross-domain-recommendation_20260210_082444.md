---
ver: rpa2
title: 'KGBridge: Knowledge-Guided Prompt Learning for Non-overlapping Cross-Domain
  Recommendation'
arxiv_id: '2511.02181'
source_url: https://arxiv.org/abs/2511.02181
tags:
- knowledge
- cross-domain
- user
- recommendation
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces KGBridge, a knowledge-guided prompt learning
  framework for cross-domain sequential recommendation under non-overlapping user
  scenarios. The method addresses key challenges in knowledge graph (KG)-enhanced
  cross-domain recommendation, including KG sparsity and popularity bias, dependence
  on overlapping users, and lack of semantic disentanglement between transferable
  and domain-specific knowledge.
---

# KGBridge: Knowledge-Guided Prompt Learning for Non-overlapping Cross-Domain Recommendation

## Quick Facts
- **arXiv ID**: 2511.02181
- **Source URL**: https://arxiv.org/abs/2511.02181
- **Reference count**: 40
- **Primary result**: KGBridge achieves 12.21% average improvement over KGAT and 50.89% over KSR on cross-domain sequential recommendation benchmarks while remaining robust under KG sparsity.

## Executive Summary
This paper introduces KGBridge, a knowledge-guided prompt learning framework for cross-domain sequential recommendation under non-overlapping user scenarios. The method addresses key challenges in knowledge graph (KG)-enhanced cross-domain recommendation, including KG sparsity and popularity bias, dependence on overlapping users, and lack of semantic disentanglement between transferable and domain-specific knowledge. KGBridge consists of two core components: a KG-enhanced Prompt Encoder that models relation-level semantics as soft prompts to provide structured and dynamic priors for user sequence modeling, and a Two-stage Training Paradigm that combines cross-domain pretraining and privacy-preserving fine-tuning to enable knowledge transfer without user overlap. By combining relation-aware semantic control with correspondence-driven disentanglement, KGBridge explicitly separates and balances domain-shared and domain-specific semantics.

## Method Summary
KGBridge operates through a two-stage training paradigm: first, cross-domain pretraining jointly optimizes shared and specific prompt banks derived from KG relation embeddings; second, target-domain fine-tuning with frozen shared prompts and updated specific prompts using contrastive regularization. The method uses TransE to embed KG relations, mean pooling with noise to generate prompt banks, and attention-based fusion to dynamically guide sequential representation learning. The architecture separates domain-shared and domain-specific knowledge through correspondence-driven disentanglement, preventing negative transfer while preserving beneficial cross-domain knowledge.

## Key Results
- KGBridge consistently outperforms state-of-the-art baselines, achieving significant improvements in recommendation accuracy across multiple cross-domain scenarios.
- The method maintains stable performance under varying KG sparsity levels, showing minimal degradation even with 80% KG triple removal.
- KGBridge achieves 12.21% average improvement over KGAT and 50.89% over KSR on benchmark datasets.

## Why This Works (Mechanism)

### Mechanism 1
Shifting modeling focus from entity-level to relation-level representations reduces sensitivity to KG sparsity and popularity bias in cross-domain transfer. Real-world KGs exhibit long-tail entity distributions where few popular entities dominate connectivity. By modeling relations—which are fewer, more semantically stable, and connect diverse entities—the framework avoids inheriting entity-level popularity bias. Relations provide compact semantic abstractions that transfer more reliably across domains.

### Mechanism 2
Soft prompts derived from KG relations function as context-aware semantic controllers that dynamically guide sequential representation learning. TransE learns relation embeddings; Prompt Generator aggregates variable-sized relation sets into fixed-length prompt banks (shared/specific). During sequence modeling, attention-based fusion weights each prompt's contribution to item representations based on contextual relevance, allowing prompts to adaptively emphasize transferable vs. domain-sensitive semantics.

### Mechanism 3
Correspondence-driven disentanglement with contrastive regularization explicitly separates domain-shared and domain-specific semantics, preventing negative transfer and stabilizing adaptation. During fine-tuning, shared prompts are frozen (preserving cross-domain priors) while specific prompts adapt. InfoNCE loss encourages corresponding shared-specific prompt pairs to remain semantically related while pushing non-corresponding pairs apart, ensuring complementarity rather than redundancy between knowledge types.

## Foundational Learning

- **Concept: Knowledge Graph Embedding (TransE)**
  - Why needed here: Understand how relations are initially encoded before prompt generation; TransE's translational principle (h+r≈o) provides the semantic foundation for relation embeddings.
  - Quick check question: Why does TransE learn relation embeddings that capture semantic meaning rather than arbitrary vectors?

- **Concept: Soft Prompts vs. Hard Prompts**
  - Why needed here: KGBridge uses continuous learnable prompts rather than discrete text; understand the flexibility and optimization advantages.
  - Quick check question: What is the key difference between soft prompts and textual prompts in terms of gradient-based optimization?

- **Concept: Contrastive Learning (InfoNCE Loss)**
  - Why needed here: The disentanglement mechanism relies on InfoNCE; understand how positive/negative pairs are defined and how temperature affects separation.
  - Quick check question: In Eq. 12, what defines a positive pair vs. negative pair, and what happens if τ→0 vs. τ→∞?

- **Concept: Pretrain-Finetune Transfer Learning**
  - Why needed here: The two-stage paradigm is central to the approach; understand why parameter freezing prevents catastrophic forgetting.
  - Quick check question: Why freeze shared prompts but update specific prompts during fine-tuning rather than updating all parameters?

## Architecture Onboarding

- **Component map**:
  ```
  Knowledge Graph (G)
       ↓
  TransE Embedding Layer → Relation Embeddings (R^shared, R^spec)
       ↓
  Prompt Generator (mean pooling + noise) → P^shared, P^spec
       ↓
  Sequence Input (ItemEmb + PosEmb) → E_u
       ↓
  Knowledge-guided Item Enrichment (Attention Fusion) → ê_i
       ↓
  Transformer Encoder → z_u (user preference)
       ↓
  Prediction Head → Recommendation logits
  ```
  *Stage 1: Joint pretraining across domains. Stage 2: Target-domain fine-tuning with frozen P^shared, L_disen regularization.*

- **Critical path**: TransE quality → Prompt initialization → Attention fusion weights → Disentanglement regularization strength (λ). If TransE embeddings are poor (e.g., sparse KG), downstream prompts inherit weak semantics.

- **Design tradeoffs**:
  - **Prompt length L**: Paper uses L=2. Longer prompts capture more semantics but increase parameters and risk overfitting. Shorter prompts may underrepresent relation diversity.
  - **Mean pooling vs. attention pooling for Prompt Generator**: Mean pooling with noise chosen for regularization; attention pooling more expressive but risks high-frequency relation overfitting.
  - **Freezing strategy**: Freezing shared prompts stabilizes transfer but may prevent adaptation if shared knowledge is imperfect. Alternative: learning rate decay for shared prompts.

- **Failure signatures**:
  - **Attention collapse**: If α_i,j becomes uniform across prompts, semantic guidance is lost. Monitor attention weight distributions.
  - **Disentanglement failure**: If L_disen dominates (λ too high), shared and specific prompts may become overly separated, losing beneficial coupling.
  - **Negative transfer**: If shared prompts encode source-domain bias, frozen transfer harms target performance. Check: fine-tune performance vs. from-scratch training.
  - **KG sparsity threshold**: Under extreme sparsity (>80% triples removed), relation embeddings degrade. Monitor: TransE validation loss before prompt initialization.

- **First 3 experiments**:
  1. **Baseline sanity check**: Reproduce SASRec and MCRPL on a single domain pair (FB-Movie→Book). Verify your evaluation pipeline produces reported Recall@10 within ±0.5% before implementing KGBridge.
  2. **Ablation by component**: Run -KGInit, -Shared, -Spec, -Disen variants on one dataset. Confirm -KGInit causes largest drop (per Table V), validating relation initialization importance.
  3. **Sparsity robustness test**: Train on FB-Music→Book with 20%, 40%, 60% KG triple removal. Plot Recall@10 vs. sparsity for KGBridge, GRU4RecKG, and KSR. Confirm KGBridge shows smoothest degradation curve (per Fig. 3).

## Open Questions the Paper Calls Out
- **Question:** How can large language models (LLMs) be effectively integrated with the KGBridge framework to enhance semantic reasoning over incomplete knowledge graphs?
  - **Basis in paper:** [explicit] The Conclusion explicitly states: "In future work, we plan to integrate large language models with incomplete knowledge graphs to enhance semantic reasoning and further improve cross-domain knowledge transfer."
  - **Why unresolved:** The current framework relies exclusively on structured TransE embeddings for relation-level priors and does not incorporate the reasoning capabilities of LLMs to handle KG incompleteness.
  - **What evidence would resolve it:** Empirical results comparing the performance of TransE-derived soft prompts against LLM-enhanced prompts on benchmarks with high KG sparsity.

- **Question:** Is the quality of the generated prompts constrained by the use of TransE, given its known limitations in modeling complex relation patterns (e.g., symmetry, transitivity)?
  - **Basis in paper:** [inferred] Section III.A.1 justifies the selection of TransE solely by its "computational efficiency," without evaluating if more expressive Knowledge Graph Embedding (KGE) methods would improve the prompt semantics.
  - **Why unresolved:** TransE enforces a simple translational principle that struggles with 1-to-N, symmetric, or transitive relations, potentially limiting the semantic richness of the prompts derived from these embeddings.
  - **What evidence would resolve it:** Ablation studies replacing the TransE initialization with complex-space embeddings (e.g., RotatE, ComplEx) or GNN-based embeddings and measuring the downstream impact on recommendation accuracy.

- **Question:** Does the fixed short prompt length (L=2) create an information bottleneck that limits the representation of complex relational semantics?
  - **Basis in paper:** [inferred] Section IV.B.3 sets the prompt length L=2 as a fixed hyperparameter, but the paper does not analyze the trade-off between prompt length and semantic capacity.
  - **Why unresolved:** Aggregating variable-sized relation sets into only two prompt vectors via mean pooling may compress semantic information excessively, failing to capture the full diversity of domain-specific relations.
  - **What evidence would resolve it:** A sensitivity analysis tracking performance metrics (Recall/NDCG) as the prompt length L is scaled up, particularly in domains with a high number of distinct relation types.

## Limitations
- The method relies on specific Transformer architecture parameters (layers, heads, hidden dimensions) that are not explicitly specified in the paper.
- TransE is chosen for computational efficiency without evaluating whether more expressive KG embedding methods would improve prompt semantics.
- The fixed prompt length of L=2 may create an information bottleneck that limits the representation of complex relational semantics.

## Confidence
- **High confidence**: The core claim that relation-level modeling outperforms entity-level approaches under KG sparsity (supported by empirical comparisons and ablation studies).
- **Medium confidence**: The two-stage training paradigm's effectiveness in preventing negative transfer (strong empirical support but relies on specific implementation details).
- **Low confidence**: The optimality of the specific prompt length (L=2) and noise injection strategy (insufficient ablation on these design choices).

## Next Checks
1. **Parameter sensitivity analysis**: Systematically vary Transformer depth (1-4 layers), attention heads (1-4), and prompt length (1-4) to identify performance plateaus and optimal configurations.
2. **Disentanglement quality evaluation**: Beyond recommendation metrics, measure semantic alignment between shared/specific prompt pairs using cosine similarity and mutual information to verify InfoNCE effectiveness.
3. **Extreme sparsity robustness**: Evaluate performance with >80% KG triple removal to identify the practical lower bound where relation semantics degrade beyond usefulness.