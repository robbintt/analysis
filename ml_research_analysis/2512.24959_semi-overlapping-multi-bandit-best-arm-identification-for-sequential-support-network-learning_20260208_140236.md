---
ver: rpa2
title: Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support
  Network Learning
arxiv_id: '2512.24959'
source_url: https://arxiv.org/abs/2512.24959
tags:
- learning
- best
- arms
- semi-overlapping
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the semi-overlapping multi-bandit (SOMMAB)
  model and a generalized GapE algorithm for sequential support network learning (SSNL).
  The SOMMAB framework extends multi-bandit best arm identification by allowing arms
  to be semi-overlapping, where a single evaluation provides distinct feedback to
  multiple bandits due to structural overlap among their arms.
---

# Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning

## Quick Facts
- arXiv ID: 2512.24959
- Source URL: https://arxiv.org/abs/2512.24959
- Reference count: 22
- Introduces semi-overlapping multi-bandit (SOMMAB) model and generalized GapE algorithm with improved theoretical bounds

## Executive Summary
This paper introduces the semi-overlapping multi-bandit (SOMMAB) model for sequential support network learning, where arms can be semi-overlapping across bandits, allowing a single evaluation to provide distinct feedback to multiple bandits. The authors develop a generalized GapE algorithm that improves the best known constant in the error exponent for multi-bandit best arm identification by more than a factor of 3.5, with bounds scaling linearly with the degree of overlap. This work provides theoretical foundations and improved performance guarantees for identifying support networks from sparse candidates in applications like multi-task learning, federated learning, and multi-agent systems.

## Method Summary
The method introduces semi-overlapping arms organized into evaluation groups, where pulling one arm updates multiple bandits simultaneously with distinct reward samples. The generalized GapE algorithm computes gap-based indices for each bandit-arm pair, balancing exploitation (small gaps) and exploration (few samples) through an exploration bonus inversely proportional to pull count. The algorithm operates in pure exploration mode to maximize identification accuracy rather than cumulative reward, with theoretical guarantees showing exponential error probability decay scaling with overlap order.

## Key Results
- Error exponent improves by factor >3.5 compared to best known multi-bandit bounds
- Bounds scale linearly with overlap order r: ℓ(n) ≤ 2MK n exp(-(rn-MK+1)/(41H-36))
- For r-order SOMMABs, rn replaces n in the numerator of the exponent term
- Linear sample complexity scaling with overlap degree directly translates to sample efficiency gains

## Why This Works (Mechanism)

### Mechanism 1: Semi-overlapping Arms Enable Shared Evaluation with Distinct Feedback
A single evaluation can simultaneously update multiple bandits with different reward signals, reducing total sample complexity when bandits share structural overlap. Arms are organized into disjoint evaluation groups—sets of arms from different bandits that are pulled together. When an evaluation group is pulled, each constituent arm receives its own reward sample from its distinct distribution, but only one pull is charged against the budget.

### Mechanism 2: Gap-Based Index Prioritizes Arms by Uncertainty-Adjusted Suboptimality
Using estimated gaps rather than raw means allows GapE to treat the multi-bandit problem as a unified optimization over MK arms while respecting per-bandit structure. The algorithm computes an index B_mk(t) = -estimated_gap_mk(t) + b√(a/T_mk(t)) for each bandit-arm pair, naturally balancing exploitation (small gaps) and exploration (few samples).

### Mechanism 3: Linear Sample Complexity Scaling with Overlap Order
For r-order SOMMAB, the error exponent improves by a factor of r in the leading term, directly translating structural overlap into sample efficiency gains. The proof's counting argument shows that if any arm is under-sampled, then all arms must be under-sampled, leading to a contradiction when a is set appropriately.

## Foundational Learning

- Concept: **Best Arm Identification (BAI) vs. Regret Minimization**
  - Why needed here: GapE operates in pure exploration setting—maximizing identification accuracy rather than cumulative reward
  - Quick check question: Does your objective require maximizing total reward during learning, or correctly identifying the optimal arm at the end?

- Concept: **Gap-Based Complexity (H = Σ b²/Δ²_mk)**
  - Why needed here: The theoretical bounds and recommended parameter settings depend on this complexity measure
  - Quick check question: If all arms in a bandit have nearly equal means, is H large or small? (Answer: large—small gaps make identification hard.)

- Concept: **Chernoff-Hoeffding Concentration**
  - Why needed here: The proof relies on confidence bounds of the form |μ̂ - μ| < c√(a/T) holding with high probability
  - Quick check question: How many samples are needed to estimate a mean within ε with probability 1-δ? (Answer: roughly O(log(1/δ)/ε²).)

## Architecture Onboarding

- Component map: Initialization module → Index computation → Selection oracle → Evaluation group expansion → Update engine → Recommendation layer
- Critical path: Index computation → Selection → Evaluation group expansion → Reward observation → Update → Repeat. The O(MK) per-iteration cost is dominated by index computation and update.
- Design tradeoffs:
  - Initialization length l: Larger l (up to 152 per theorem) improves the constant in the exponent but increases upfront sampling cost
  - Exploration parameter a: Set a = rn/(c₁H - c₂) for theoretical guarantees, but H is typically unknown
  - Budget allocation: Total budget n must exceed lMK to enter the adaptive phase
- Failure signatures:
  - All recommendations identical: Exploration parameter a too small; algorithm exploiting prematurely
  - Error probability not decreasing with n: Possible violation of semi-overlapping structure or mis-specified bounds
  - Inconsistent results across runs with same seed: Check random number generation in evaluation group expansion
- First 3 experiments:
  1. Synthetic validation: Construct M=3 bandits with K=5 arms each, define 2-order overlap, set known gaps, verify error probability decreases exponentially with n
  2. Ablation on overlap order: Fix budget n and problem complexity H, vary overlap order r from 1 to M, confirm error probability scales as exp(-crn/H)
  3. Application proxy: Implement with M tasks as bandits, candidate auxiliary sets as arms, cross-validation error as reward, compare against uniform exploration baseline

## Open Questions the Paper Calls Out

- Can the GapE-Variance algorithm be extended to the SOMMAB setting with improved theoretical bounds? The current work only derives bounds for standard GapE; analysis for GapE-V remains to be done.
- What are the performance guarantees for adaptive GapE algorithms in SOMMAB setting when problem complexity is unknown? Existing adaptive versions lack formal proofs for the semi-overlapping case.
- How can the fixed candidate set constraint be removed to allow for open-ended coalition optimization in SOMMABs? The current results rely on pre-defined candidate lists rather than combinatorial search.

## Limitations

- No empirical validation or concrete experiments demonstrating the semi-overlapping structure's benefits
- Overlap degree r must be known a priori for optimal parameter setting, which may not hold in practice
- Bound's tightness depends on uniform overlap order across all evaluation groups, an assumption that may not hold in real applications

## Confidence

- Theoretical bounds and mechanisms: **High** - Proofs follow established multi-armed bandit literature with clear extensions
- Practical applicability to sequential support network learning: **Medium** - Framework is well-defined but no application demonstrations provided
- GapE algorithm effectiveness in SOMMAB setting: **Medium** - Algorithm is natural extension of known methods, but no empirical verification

## Next Checks

1. Implement SOMMAB GapE with M=3 bandits, K=5 arms, 2-order overlap; verify error probability decreases exponentially with budget n at predicted rate
2. Conduct ablation study varying overlap order r from 1 to M; confirm error scaling matches theoretical prediction exp(-crn/H)
3. Apply to auxiliary task selection in federated learning; compare GapE against uniform exploration baseline on synthetic cross-validation tasks