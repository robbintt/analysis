---
ver: rpa2
title: 'Roleplaying with Structure: Synthetic Therapist-Client Conversation Generation
  from Questionnaires'
arxiv_id: '2510.25384'
source_url: https://arxiv.org/abs/2510.25384
tags:
- client
- therapist
- evaluation
- data
- your
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the scarcity of authentic therapy dialogues
  for AI mental health applications by introducing a pipeline that generates synthetic
  counseling conversations from structured client profiles and psychological questionnaires.
  The approach uses open-weight LLMs to create dialogues simulating therapist-client
  interactions grounded in Cognitive Behavioral Therapy principles, ensuring data
  privacy compliance by avoiding proprietary models.
---

# Roleplaying with Structure: Synthetic Therapist-Client Conversation Generation from Questionnaires

## Quick Facts
- **arXiv ID**: 2510.25384
- **Source URL**: https://arxiv.org/abs/2510.25384
- **Reference count**: 40
- **Key outcome**: Introduces pipeline to generate synthetic therapy dialogues from structured client profiles and psychological questionnaires, evaluated by human experts and automated benchmarks for CBT-aligned performance.

## Executive Summary
This paper addresses the critical shortage of authentic therapy dialogues for AI mental health applications by introducing a pipeline that generates synthetic counseling conversations from structured client profiles and psychological questionnaires. The approach uses open-weight LLMs to create dialogues simulating therapist-client interactions grounded in Cognitive Behavioral Therapy principles, ensuring data privacy compliance by avoiding proprietary models. The generated SQPsychConv dataset and fine-tuned SQPsychLLM models are evaluated through human expert assessments and automated benchmarks, demonstrating strong performance in therapeutic skills such as identifying cognitive distortions and core beliefs. Expert and LLM-based evaluations show that the synthetic conversations align with clinical practices and are preferred over baseline models.

## Method Summary
The study presents a multi-stage pipeline for generating synthetic therapy conversations using structured client profiles and psychological questionnaires. The system leverages open-weight LLMs to create dialogues that simulate therapist-client interactions based on Cognitive Behavioral Therapy principles. The pipeline generates the SQPsychConv dataset, which is then used to fine-tune the SQPsychLLM models. Evaluation involves both human expert assessments from clinical psychologists and automated benchmarks measuring therapeutic skills like cognitive distortion identification and core belief analysis.

## Key Results
- Human expert evaluations demonstrate that synthetic conversations largely follow CBT principles
- The generated dialogues are preferred over baseline models by both experts and LLM-based evaluators
- SQPsychLLM models show strong performance in identifying cognitive distortions and core beliefs in therapeutic contexts

## Why This Works (Mechanism)
The approach succeeds by grounding synthetic dialogue generation in structured psychological assessment data, which provides the necessary clinical context and framework for realistic therapeutic interactions. By using open-weight LLMs and focusing on CBT principles, the system can generate contextually appropriate responses while maintaining data privacy. The multi-stage pipeline ensures that generated conversations are both clinically informed and technically sound, with evaluation through multiple methods providing confidence in the system's therapeutic validity.

## Foundational Learning
- **Cognitive Behavioral Therapy (CBT)**: Evidence-based psychotherapy focusing on the relationship between thoughts, feelings, and behaviors; needed to ground synthetic conversations in established clinical framework; quick check: system must identify and address cognitive distortions appropriately.
- **Structured Clinical Questionnaires**: Standardized assessment tools that quantify psychological states and symptoms; needed to provide consistent, measurable input for dialogue generation; quick check: input profiles must capture relevant clinical dimensions.
- **Open-weight LLM Architecture**: Language models with publicly available weights that can be fine-tuned without proprietary restrictions; needed to ensure privacy compliance and customization capability; quick check: model can be adapted to therapeutic domain while maintaining safety.
- **Multi-turn Dialogue Generation**: The process of creating coherent conversation sequences with context persistence across exchanges; needed to simulate realistic therapeutic interactions; quick check: generated conversations must maintain logical flow and therapeutic focus.
- **Clinical Expert Evaluation**: Assessment of AI-generated content by licensed mental health professionals; needed to validate therapeutic quality and safety; quick check: experts must rate conversations as clinically appropriate and effective.
- **Automated Clinical Benchmarks**: Computational metrics that evaluate therapeutic skills in generated content; needed for scalable quality assessment; quick check: system must demonstrate measurable performance on established clinical tasks.

## Architecture Onboarding

**Component Map**
Profile Data -> LLM Generation Engine -> Dialogue Refinement -> SQPsychConv Dataset -> SQPsychLLM Fine-tuning -> Expert/Automated Evaluation

**Critical Path**
1. Structured client profile creation from questionnaires
2. Multi-stage LLM-based dialogue generation
3. Dataset compilation and model fine-tuning
4. Expert and automated evaluation

**Design Tradeoffs**
- Open-weight vs proprietary models: Privacy and customization vs potential performance gains
- Synthetic vs real data: Scalability and compliance vs authenticity and nuance
- Expert vs automated evaluation: Clinical validity vs scalability and consistency

**Failure Signatures**
- Generated conversations lacking therapeutic coherence or clinical appropriateness
- Failure to identify or address cognitive distortions appropriately
- Responses that violate therapeutic boundaries or safety protocols
- Inconsistent therapeutic approach across conversation turns

**3 First Experiments**
1. Generate sample dialogues using minimal client profiles to test basic functionality
2. Evaluate generated conversations with a small group of clinical experts for initial quality assessment
3. Test automated benchmarks on sample dialogues to establish baseline performance metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Clinical generalization uncertainty due to reliance on synthetic rather than real therapy conversations
- Limited safety validation for high-risk scenarios like suicidal ideation or acute crises
- Relatively small sample size in human expert evaluations (7 therapists, 18 conversations each)

## Confidence
- **High Confidence**: Technical implementation of multi-stage generation pipeline and basic functionality of SQPsychConv dataset creation
- **Medium Confidence**: Quality of generated dialogues as measured by expert ratings and automated benchmarks
- **Low Confidence**: Claims about system readiness for clinical deployment or real-world mental health application effectiveness

## Next Checks
1. Conduct comprehensive safety protocol testing for high-risk scenarios including suicidal ideation, abuse disclosures, and acute psychological crises using expert clinician review and standardized safety checklists
2. Design and execute controlled study comparing outcomes from therapy sessions assisted by AI system against standard care, measuring therapeutic alliance and symptom improvement over multiple sessions
3. Implement staged deployment in controlled settings (university counseling centers or telehealth platforms) with rigorous monitoring of model outputs, user satisfaction, and adverse events before broader clinical applications