---
ver: rpa2
title: Semi-Gradient SARSA Routing with Theoretical Guarantee on Traffic Stability
  and Weight Convergence
arxiv_id: '2503.14927'
source_url: https://arxiv.org/abs/2503.14927
tags:
- state
- policy
- convergence
- algorithm
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses dynamic routing in parallel server systems
  where traditional reinforcement learning approaches face challenges with unbounded
  state spaces and non-stationary environments. The authors propose a semi-gradient
  SARSA (SGS) algorithm with linear function approximation that learns near-optimal
  routing policies.
---

# Semi-Gradient SARSA Routing with Theoretical Guarantee on Traffic Stability and Weight Convergence

## Quick Facts
- **arXiv ID**: 2503.14927
- **Source URL**: https://arxiv.org/abs/2503.14927
- **Reference count**: 40
- **Primary result**: Proposes SGS algorithm guaranteeing joint traffic state stability and weight convergence for dynamic routing in parallel server systems with unbounded state spaces

## Executive Summary
This paper addresses the challenge of dynamic routing in parallel server systems where traditional RL approaches struggle with unbounded state spaces and non-stationary environments. The authors propose a semi-gradient SARSA (SGS) algorithm with linear function approximation that learns near-optimal routing policies while maintaining system stability. By combining Lyapunov analysis with ordinary differential equation methods, the algorithm jointly characterizes traffic state and weight convergence, ensuring both stability and almost sure convergence to optimal weights. The method naturally supports idling policies and avoids the curse of dimensionality through generic basis functions.

## Method Summary
The SGS algorithm operates on parallel server systems where jobs arrive at rate λ and are routed to one of N servers with exponential service rates μ_n. The algorithm uses linear function approximation ĔQ(x,a;w) = Σ_n Σ_j w_{n,j}ϕ_{n,j}(x_n + I{n=a}) with generic basis functions ϕ. A softmax policy with temperature ι=0.01 selects routing actions. Weights are updated using semi-gradient SARSA with restraint parameter B_α[k] to prevent weight collapse. The key innovation is the Lyapunov drift condition (Assumption 1) that ensures traffic stability during learning, combined with ODE analysis showing almost sure convergence of weights to the optimal solution.

## Key Results
- SGS guarantees joint convergence of traffic state (ergodicity and bounded norm) and weight vector (almost surely) when the system is stabilizable
- Empirical validation shows 41% lower average cost than join-the-shortest-queue baseline
- Converges over 5 times faster than neural network-based SARSA while maintaining minimal optimality gap (2%)
- Theoretical guarantees absent in comparison methods, including stability and convergence proofs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The approximate value function serves as a Lyapunov function, guaranteeing traffic state stability during learning.
- Mechanism: Basis functions satisfy drift conditions ensuring Lyapunov drift LwWe(x) ≤ -(Be·g(x) + 1) + BwI{x=0}, which bounds the moment-generating function of states, implying ergodicity and positive Harris recurrence.
- Core assumption: System is stabilizable (λ < Σμn); basis functions satisfy derivative bounds and growth conditions.
- Evidence: Abstract states joint characterization of traffic state and weights; Section III-A proof shows bounded MGF implies stability; weak direct corpus support.
- Break condition: If λ ≥ Σμn or basis functions grow too slowly relative to cost function.

### Mechanism 2
- Claim: Weight updates converge almost surely to optimal weights via ODE method, even with unbounded state space and TD errors.
- Mechanism: Stochastic approximation iteration tracks ODE ẇ = Edw[αkδw(x,w)/Bα[k]], with global asymptotic stability following from d||w-w*||²/dt ≤ -2Bd||w-w*||².
- Core assumption: Step sizes satisfy Σαk = ∞, Σαk² < ∞; policy is Lipschitz continuous w.r.t. w; ergodicity holds for each fixed w.
- Evidence: Abstract guarantees almost sure convergence; Section III-C shows w* satisfies Bellman equation and convergence; federated SARSA paper provides related bounds.
- Break condition: If temperature ι is too large or step sizes decay too slowly.

### Mechanism 3
- Claim: Linear function approximation with generic basis functions enables natural idling policies and avoids curse of dimensionality.
- Mechanism: Q-approximation decomposes across servers; when x=0, ĔQ(0,n) = wn,1, allowing routing to faster servers even when slower ones are empty.
- Core assumption: Basis functions are non-decreasing with bounded higher-order derivatives; highest-degree term satisfies growth condition.
- Evidence: Section II-B states idling policies are naturally possible; Section IV shows ĔQ(0,n) = wn,1 enables idling; MESS+ paper addresses similar problems without theoretical guarantees.
- Break condition: If basis functions cannot express true value function well.

## Foundational Learning

- **Lyapunov stability for Markov chains**
  - Why needed here: The proof that traffic states remain stochastically bounded relies on constructing a Lyapunov function whose drift is negative outside a finite set.
  - Quick check question: Given a Markov chain with transition kernel P and function V, what does it mean for V to satisfy a Foster-Lyapunov drift condition?

- **Stochastic approximation and ODE method**
  - Why needed here: The weight convergence proof maps the discrete stochastic iteration to a continuous ODE and shows global asymptotic stability.
  - Quick check question: Why do the step-size conditions Σαk = ∞ and Σαk² < ∞ ensure the stochastic approximation tracks the ODE solution?

- **SARSA(0) with function approximation**
  - Why needed here: The core algorithm is on-policy TD learning with linear approximation using semi-gradient updates.
  - Quick check question: In semi-gradient SARSA, why doesn't the TD error account for the gradient of the target term γĔQ(x',a';w)?

## Architecture Onboarding

- **Component map**:
  State observer -> Feature extractor -> Q-approximator -> Policy module -> TD error computer -> Weight updater -> Lyapunov function monitor

- **Critical path**:
  1. Arrival/departure event triggers state observation
  2. Feature extractor computes ϕ(x,a) for all actions
  3. Policy samples action a[k] from softmax distribution
  4. Environment transitions to x[k+1], incurs cost c[k+1]
  5. TD error computed, weights updated before next event
  6. Lyapunov function We(x) = Σn exp(νw_n^Tϕn(xn)) monitored for stability

- **Design tradeoffs**:
  - Temperature ι: Lower ι → more deterministic policy but potentially worse exploration; paper uses ι = 0.01
  - Basis function order P: Higher P → better approximation but more weights to learn; paper uses P=4
  - Step size sequence: Faster decay → quicker convergence but risk of premature convergence to suboptimal weights
  - Restraint parameter Bα[k]: Prevents wn,H from dropping below wl, ensuring stability, but may slow learning

- **Failure signatures**:
  - Queue blow-up: ||x[k]||₁ growing unboundedly indicates Lyapunov drift condition violated; check if λ < Σμn
  - Weight divergence: ||w[k]|| → ∞ suggests step sizes too large or Bα[k] insufficient; reduce αk or increase wl
  - Oscillating costs: Policy alternates between actions suggests ι too large or basis functions poorly conditioned
  - Stuck in local optimum: Consistent 2%+ gap from JSQ suggests basis functions under-expressing true value

- **First 3 experiments**:
  1. **Stability boundary test**: Vary arrival rate λ from 0.5× to 1.1× of Σμn; verify queue lengths remain bounded for λ < Σμn and diverge for λ ≥ Σμn. Confirm Lyapunov function We(x) remains bounded.
  2. **Basis function ablation**: Test polynomial-only (ϕn,j = xn^j) vs. mixed (include logarithmic terms); measure convergence speed and final average cost. Paper uses mixed basis with exponents {0.01, 0.2, 1, 1.5}.
  3. **Temperature sensitivity**: Sweep ι ∈ {0.001, 0.01, 0.1, 1.0}; plot convergence time vs. final optimality gap. Verify ι = 0.01 provides best tradeoff as paper suggests.

## Open Questions the Paper Calls Out

- **Extension to general service networks**: Can the joint convergence result and SGS algorithm be extended to general service network topologies beyond parallel servers? The conclusion identifies this as future work, as the current Lyapunov and ODE analysis depends on parallel server structure.

- **Finite-time convergence rates and approximation error bounds**: What are the finite-time convergence rates and explicit approximation error bounds for the SGS algorithm? The conclusion identifies analysis of approximation error and convergence rate as future work, as current theory establishes asymptotic convergence but not convergence speed.

- **Robustness to model assumptions**: How robust is the convergence guarantee to non-exponential service distributions, finite buffers, or non-Poisson arrivals? The current analysis assumes Poisson arrivals, exponential service times, and infinite buffers, which may not hold in real-world systems.

- **Explicit temperature bounds**: What explicit bounds on the temperature parameter ι ensure convergence, and how does it affect the exploration-exploitation trade-off? The proof assumes "ι is sufficiently small" but doesn't provide explicit thresholds or sensitivity analysis.

## Limitations

- The stability analysis relies heavily on carefully designed basis functions satisfying Assumption 1, but doesn't provide general construction guidelines for arbitrary cost functions.
- The restraint parameter Bα[k] is critical for preventing weight collapse but its computation is underspecified in reproduction materials.
- The convergence proof requires λ < Σμn for stabilizability but doesn't address boundary behavior or what happens when this condition is violated.
- Step-size sensitivity isn't explored beyond the theoretical conditions Σαk = ∞ and Σαk² < ∞.

## Confidence

- **High confidence**: Lyapunov stability argument for traffic states is well-supported by drift condition proof and standard Foster-Lyapunov theory. Empirical results showing SGS outperforms JSQ and neural SARSA are clearly demonstrated.
- **Medium confidence**: Almost sure convergence of weights follows from standard stochastic approximation theory, but application to unbounded state spaces requires careful verification. Assumption about making Lπ sufficiently small needs more rigorous justification.
- **Low confidence**: Claim that linear function approximation naturally enables idling policies is demonstrated for specific basis choice but lacks general construction guidelines. Paper shows this works for their basis but doesn't prove it for arbitrary basis satisfying Assumption 1.

## Next Checks

1. **Stability boundary verification**: Systematically test the algorithm at different load levels λ/Σμn ∈ [0.5, 1.5] to confirm queue lengths remain bounded only when λ < Σμn and diverge otherwise. Monitor the Lyapunov function We(x) to verify it stays bounded under stable conditions.

2. **Basis function sensitivity analysis**: Compare convergence speed and final cost using different basis function families (polynomial-only vs. mixed with logarithmic terms) while maintaining the same approximation order P=4. This validates whether the specific choice of exponents {0.01, 0.2, 1, 1.5} is critical or if stability results hold more generally.

3. **Restraint parameter calibration**: Systematically vary the lower bound wl and observe its effect on convergence speed and stability. Determine the minimum wl that prevents weight divergence without significantly slowing learning, and verify the computation of Bα[k] for different initialization schemes.