---
ver: rpa2
title: Majority Bit-Aware Watermarking For Large Language Models
arxiv_id: '2508.03829'
source_url: https://arxiv.org/abs/2508.03829
tags:
- majormark
- message
- text
- decoding
- green
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the text quality-degradation problem in existing\
  \ multi-bit watermarking methods for LLMs, where large green lists improve text\
  \ quality but hurt decoding accuracy. The authors propose MajorMark, a majority-bit-aware\
  \ encoding scheme that ensures a minimum green list ratio of 0.5 and an expected\
  \ ratio of 0.5 + 1/\u221A(2\u03C0b), eliminating the need for hyperparameter tuning."
---

# Majority Bit-Aware Watermarking For Large Language Models

## Quick Facts
- arXiv ID: 2508.03829
- Source URL: https://arxiv.org/abs/2508.03829
- Reference count: 40
- One-line primary result: MajorityMark+ consistently outperforms baselines in both decoding accuracy (e.g., +4.30% over RSBH at b=64) and text quality (lower perplexity, higher top-5 hit rates).

## Executive Summary
This paper tackles the text quality-degradation problem in existing multi-bit watermarking methods for LLMs, where large green lists improve text quality but hurt decoding accuracy. The authors propose MajorMark, a majority-bit-aware encoding scheme that ensures a minimum green list ratio of 0.5 and an expected ratio of 0.5 + 1/√(2πb), eliminating the need for hyperparameter tuning. Instead of relying on token frequency counting, MajorMark uses clustering-based decoding, which maintains high accuracy even with large green lists. They further introduce MajorMark+, which divides the message into blocks for independent encoding and deterministic decoding, further improving text quality and accuracy. Extensive experiments on LLaMA-2-7B show MajorMark+ consistently outperforms baselines in both decoding accuracy (e.g., +4.30% over RSBH at b=64) and text quality (lower perplexity, higher top-5 hit rates), while also showing robustness against copy-paste and paraphrase attacks.

## Method Summary
MajorMark introduces majority-bit-aware encoding where the green list is constructed by unioning vocabulary shards corresponding to the majority bit of the message, guaranteeing γ ≥ 0.5 with expected E[γ] = 0.5 + 1/√(2πb). Instead of frequency-counting, it uses clustering-based decoding that tracks which vocabulary shards each token belongs to across generation steps. MajorMark+ further improves this by dividing the message into blocks for independent encoding and deterministic decoding, with expected γ improving to 0.5 + 1/√(2π(b/r)). The methods use hash-based vocabulary sharding with secret keys, ensuring consistent encoding/decoding. MajorMark+ employs exhaustive enumeration of (majority_bit, occurrence_count) combinations per block to find the configuration yielding maximum shard-count variance.

## Key Results
- MajorMark+ consistently outperforms baselines in both decoding accuracy (+4.30% over RSBH at b=64) and text quality (lower perplexity, higher top-5 hit rates)
- MajorMark uses clustering-based decoding that maintains high accuracy even with large green lists
- MajorMark+ shows robustness against copy-paste and paraphrase attacks while improving text quality metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Majority bit-aware encoding achieves larger green lists while maintaining decode-ability, improving text quality.
- Mechanism: The encoding identifies which bit (0 or 1) dominates the message (appears ≥⌈b/2⌉ times), then constructs the green list by unioning vocabulary shards corresponding to that majority bit. This guarantees γ ≥ 0.5 with expected E[γ] = 0.5 + 1/√(2πb), versus prior methods that cap γ at 0.25-0.5.
- Core assumption: Message bits are uniformly distributed Bernoulli(0.5); extreme cases (all 0s or all 1s) are rare or explicitly excluded.
- Evidence anchors:
  - [abstract] "MajorMark selects preferred token sets based on the majority bit of the message, enabling a larger and more flexible sampling of tokens."
  - [section 3.2] Theorem 1 proves γ ≥ 0.5 and derives the expected value formula.
  - [corpus] Related work (WorldCup Sampling, MirrorMark) also seeks larger green lists but via different mechanisms; no direct corpus support for majority-bit approach specifically.
- Break condition: If message distribution is adversarially biased toward 50-50 splits, the γ advantage shrinks; if b → ∞, E[γ] → 0.5, diminishing gains.

### Mechanism 2
- Claim: Clustering-based decoding decouples decoding accuracy from green list size, unlike frequency-counting methods.
- Mechanism: Instead of counting how often tokens fall into a reconstructed green list (which weakens as γ grows), MajorMark tracks which vocabulary shards each token belongs to across generation steps, then clusters shards by occurrence counts. The higher-count cluster maps to the majority bit.
- Core assumption: Watermarked tokens show skewed shard occurrence patterns; non-watermarked tokens distribute uniformly across shards.
- Evidence anchors:
  - [abstract] "MajorMark uses clustering-based decoding, which maintains high accuracy even with large green lists."
  - [section 3.2] "MajorMark's decoding function eliminates this dependency. This enables accurate message decoding under a large green list setting."
  - [corpus] No direct corpus papers validate clustering for watermark decoding; this appears novel to this work.
- Break condition: If watermark bias δ is too low or text is heavily edited (paraphrase attacks), shard occurrence skew diminishes, clustering fails to separate clearly.

### Mechanism 3
- Claim: Block-wise partitioning with deterministic decoding (MajorMark+) further improves text quality and accuracy.
- Mechanism: Divides message into r blocks, each encoded independently per token using block-specific majority bits. Expected γ improves to 0.5 + 1/√(2π(b/r)). Decoding exhaustively tests (majority_bit, occurrence_count) combinations and picks the one yielding maximum shard-count variance.
- Core assumption: Block-level majority bits are independently recoverable; enumerating b-r configurations is computationally acceptable.
- Evidence anchors:
  - [abstract] "MajorMark+ divides the message into blocks for independent encoding and deterministic decoding, further improving text quality and accuracy."
  - [section 3.3] Theorem 2 proves the improved expected γ; Algorithm 4 shows deterministic enumeration.
  - [corpus] MPAC and RSBH also use block-wise encoding but with smaller fixed γ (0.25, 0.5) and frequency-based decoding.
- Break condition: If r is too large relative to b, each block has too few bits for reliable majority-bit estimation; if r=1, reverts to base MajorMark.

## Foundational Learning

- Concept: Zero-bit vs. multi-bit watermarking
  - Why needed here: Understanding that prior methods embed only "is this AI-generated?" (zero-bit) versus embedding user IDs, timestamps, etc. (multi-bit).
  - Quick check question: Can you explain why multi-bit decoding complexity scales as 2^b for naive methods?

- Concept: Green/red list logit biasing
  - Why needed here: Core mechanism—tokens in green list get logit boost δ, increasing sampling probability. Larger green list = less distortion = better quality.
  - Quick check question: If γ=1.0 (entire vocabulary is green list), what happens to the watermark signal?

- Concept: Hash-based vocabulary sharding
  - Why needed here: Vocabulary is permuted via hash(secret_key, context_tokens, ...) then split into equal shards. Consistency between encode/decode requires identical hash inputs.
  - Quick check question: Why does the paper add x_{t-2} and the majority bit λ to the hash function, not just x_{t-1}?

## Architecture Onboarding

- Component map:
  - Hash Function: Hash(k, x_{t-1}, x_{t-2}, λ[, h_λ]) → seed s. Must be identical for encode/decode.
  - Vocabulary Permuter: seed s → permuted vocabulary V'.
  - Shard Partitioner: V' → b (or b/r) equal shards.
  - Green List Builder: Union of shards where m_i == majority_bit.
  - Logit Modifier: Add δ to green list tokens.
  - Decoder (MajorMark): Enumerate λ ∈ {0,1}, count shard occurrences, KMeans(K=2), assign bits.
  - Decoder (MajorMark+): Enumerate (λ', h'_λ) for each block, find max-variance configuration, assign top-h'_λ shards to majority bit.

- Critical path:
  1. Encode: Prompt + message → extract majority bit → for each token: hash → permute → shard → build green list → bias logits → sample.
  2. Decode: Text + secret key → for each token: reconstruct hash → determine shard membership → accumulate counts → cluster or enumerate → reconstruct message.

- Design tradeoffs:
  - Block count r: Higher r → better γ/quality, but more decode configurations (b-r). Default r=2 balances both.
  - Bias δ: Higher δ → stronger watermark signal → better accuracy but worse perplexity. Tested δ ∈ {2, 4, 6}.
  - Clustering algorithm: KMeans default; AC and GMM viable alternatives with similar performance (ablation confirms robustness).

- Failure signatures:
  - Low bit accuracy with high PPL: δ too low; increase bias.
  - High PPL with acceptable accuracy: δ too high or γ too low; consider MajorMark+ with higher r.
  - Decode fails on short texts: Insufficient tokens T for reliable shard statistics; need T ≥ ~400-500.
  - Uniform shard counts in decode: Wrong λ hypothesis or text not watermarked; check hash consistency.

- First 3 experiments:
  1. Baseline comparison on C4 with LLaMA-2-7B: Replicate Table 2 settings (b ∈ {32, 64}, δ ∈ {2, 4, 6}). Measure BA, PPL, Top-5 hit rate vs. MPAC, RSBH.
  2. Robustness test: Apply copy-paste (10% non-watermarked mixing) and paraphrase attacks on b=32, δ=4 watermarked text. Compare BA degradation.
  3. Block count ablation: For MajorMark+, vary r ∈ {1, 2, 4, 8} on b=32. Plot BA vs. PPL tradeoff curve to validate r=2 as optimal default.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the green list ratio ($\gamma$) and watermarking bias ($\delta$) be jointly optimized or co-designed to maximize decoding accuracy while preserving text utility?
- Basis: [explicit] Appendix A.9 states that "Co-designing in the green list ratio $\gamma$ and the watermarking bias $\delta$ is also a promising future direction."
- Why unresolved: The current work focuses primarily on optimizing the green list ratio via majority-bit encoding, treating $\delta$ as a static hyperparameter rather than optimizing them in tandem.
- What evidence would resolve it: A framework that dynamically adjusts both parameters to optimize the utility-accuracy trade-off, showing improved performance over fixed-$\delta$ baselines.

### Open Question 2
- Question: Can the MajorMark framework be modified to allow for a more flexible specification of the green list ratio ($\gamma$) without losing the advantages of frequency-independent decoding?
- Basis: [explicit] Appendix A.9 notes that the "majority bit-aware encoding... imposes constraints on the flexibility of $\gamma$ in certain scenarios" and suggests developing methods that allow for "more flexible specification of $\gamma$."
- Why unresolved: The current encoding scheme automatically determines $\gamma$ based on the majority bit of the message, limiting the ability to manually tune the list size for specific application needs.
- What evidence would resolve it: A modified encoding scheme that enables arbitrary $\gamma$ values while maintaining the clustering-based or deterministic decoding performance.

### Open Question 3
- Question: Can the decoding efficiency of MajorMark+ be further improved to reduce the computational overhead associated with the deterministic enumeration process?
- Basis: [explicit] Appendix A.9 identifies that "Further improving its decoding efficiency remains a promising direction for future work" despite the method being more efficient than brute-force baselines.
- Why unresolved: MajorMark+ requires enumerating $b-r$ configurations to recover the majority bit and its frequency, which adds computational overhead compared to simpler decoding methods.
- What evidence would resolve it: An optimized decoding algorithm that reduces the time complexity or absolute runtime of the message recovery process without sacrificing bit accuracy.

## Limitations
- The clustering-based decoding mechanism introduces complexity and may be sensitive to text length and token distribution characteristics not fully explored in the experiments.
- The computational overhead of MajorMark+'s exhaustive enumeration over (majority_bit, occurrence_count) configurations scales with b-r, potentially limiting practical deployment for very high-bit messages.
- The primary assumption that message bits follow a uniform distribution (Bernoulli(0.5)) is critical to the expected green list ratio formula; real-world deviations may diminish theoretical advantages.

## Confidence
- **High confidence**: The core mechanism of majority-bit-aware encoding achieving larger green lists (γ ≥ 0.5) and the experimental demonstration of improved text quality (lower perplexity, higher top-5 hit rates) are well-supported by the presented results.
- **Medium confidence**: The clustering-based decoding approach's ability to maintain accuracy regardless of green list size is demonstrated but relies on novel methodology without extensive corpus validation from prior work.
- **Low confidence**: The theoretical bounds on green list ratios (E[γ] = 0.5 + 1/√(2πb)) assume ideal uniform message distributions, and the paper acknowledges edge cases (all 0s or all 1s) are explicitly excluded.

## Next Checks
1. **Distribution sensitivity test**: Systematically evaluate MajorMark's performance across non-uniform message distributions (e.g., biased bit ratios, structured patterns) to validate whether the theoretical γ advantage holds under realistic conditions where messages may not be perfectly random.
2. **Clustering robustness validation**: Compare MajorMark's KMeans-based decoding against alternative clustering algorithms (GMM, hierarchical clustering) and frequency-counting methods across diverse text lengths and token distributions to establish the claimed independence from green list size more comprehensively.
3. **Extended attack surface evaluation**: Test MajorMark and MajorMark+ against additional attack vectors beyond copy-paste and paraphrase, including synonym replacement, sentence reordering, and model-specific watermark detection techniques, to fully characterize the claimed robustness limitations.