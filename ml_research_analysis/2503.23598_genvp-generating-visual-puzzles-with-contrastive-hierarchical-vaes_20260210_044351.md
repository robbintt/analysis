---
ver: rpa2
title: 'GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs'
arxiv_id: '2503.23598'
source_url: https://arxiv.org/abs/2503.23598
tags:
- genvp
- rule
- puzzle
- rules
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GenVP is a generative model for Raven's Progressive Matrices (RPM)
  that learns to create and solve visual puzzles by jointly modeling the generation
  of complete RPM matrices from abstract rules and the inference of those rules from
  given puzzles. The method uses a hierarchical VAE with contrastive learning and
  a Mixture of Experts (MoE) to robustly predict rules from partial puzzle views.
---

# GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs

## Quick Facts
- **arXiv ID**: 2503.23598
- **Source URL**: https://arxiv.org/abs/2503.23598
- **Reference count**: 40
- **Primary result**: State-of-the-art RPM-solving accuracy (avg 94.7% on RAVEN) using hierarchical VAE with contrastive learning and MoE.

## Executive Summary
GenVP is a generative model for Raven's Progressive Matrices (RPM) that learns to create and solve visual puzzles by jointly modeling the generation of complete RPM matrices from abstract rules and the inference of those rules from given puzzles. The method uses a hierarchical VAE with contrastive learning and a Mixture of Experts (MoE) to robustly predict rules from partial puzzle views. Experiments show GenVP achieves state-of-the-art RPM-solving accuracy on five datasets, significantly outperforming prior generative approaches, especially in challenging out-of-distribution scenarios involving unseen attribute values and rule sets. Notably, GenVP can generate novel, coherent RPM instances from rule specifications, demonstrating strong rule abstraction and generalization.

## Method Summary
GenVP is a Contrastive Hierarchical VAE that encodes image matrices into latent variables, splits them into rule-relevant and irrelevant attributes, predicts rules via a Mixture of Experts, and decodes to reconstruct images or generate new puzzles. The model is trained with ELBO optimization plus global and local contrastive losses that contrast valid puzzles against invalid completions. Key hyperparameters include latent dimensions K=64, K_Zo=54, K_Z̄o=10, and contrastive weights β_G=β_L=20.

## Key Results
- Achieves 94.7% average accuracy on RAVEN dataset, outperforming prior generative approaches.
- Successfully generates novel, coherent RPM instances from abstract rule specifications with 78.0% generation coherence.
- Demonstrates strong out-of-distribution generalization on SIZE-I attribute interpolation, but struggles with SIZE-E attribute extrapolation (45.0% accuracy).

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Latent Variable Decomposition with Relevance Splitting
Separating latent representations into rule-relevant (Z_o) and rule-irrelevant (Z̄_o) attributes enables robust rule inference by filtering distracting visual features. The encoder produces a combined latent Z, which is partitioned into Z_o (54 dimensions) and Z̄_o (10 dimensions). Puzzle-level variable Z_r aggregates row-wise relationships, conditioning rule prediction R on clean representations. Core assumption: Distractor attributes follow different generative distributions and can be decoupled via Gaussian posteriors.

### Mechanism 2: Mixture of Experts (MoE) for Robust Rule Prediction
Aggregating rule predictions from multiple partial puzzle views reduces prediction noise and mitigates shortcut learning. Four predictors estimate rules from full Z_o, context-only Z_o^ctx, partial-row Z_o^prow, and row representations Z_r. Their outputs are combined via weighted averaging. Core assumption: Individual predictors make uncorrelated errors, so averaging cancels noise.

### Mechanism 3: Dual-Level Contrastive Learning with Valid/Invalid Puzzle Discrimination
Contrasting valid puzzles against invalid completions teaches the model to distinguish rule-consistent from rule-violating structures. Global masked contrastive loss compares rule matrices across different puzzles, masking differing attributes. Local masked contrastive loss creates invalid puzzles by inserting negative candidates and contrasting against valid puzzles. Core assumption: Invalid puzzles can be meaningfully represented by setting modified attribute rules to "no rule," providing informative negative signals.

## Foundational Learning

- **Concept: Variational Autoencoders (VAEs) and ELBO Optimization**
  - **Why needed here:** GenVP is a hierarchical VAE; understanding the reconstruction-regularization trade-off (ELBO decomposition) is essential for debugging latent collapse or poor reconstruction.
  - **Quick check question:** Can you explain why β-VAE weighting (β_1 through β_6) might be adjusted differently for rule learning vs image reconstruction?

- **Concept: Contrastive Learning Foundations (InfoNCE, SimCLR)**
  - **Why needed here:** The dual-level contrastive scheme builds on standard contrastive principles; understanding positive/negative pair construction helps diagnose why invalid puzzles are used as negatives.
  - **Quick check question:** How does masked contrastive loss differ from standard image-level contrastive losses like SimCLR?

- **Concept: Mixture of Experts and Ensemble Averaging**
  - **Why needed here:** The MoE mechanism aggregates predictions from four experts; understanding bias-variance trade-offs in ensembles explains why averaging works and when it might fail.
  - **Quick check question:** Why does the weighted average outperform product-based aggregation?

## Architecture Onboarding

- **Component map:**
  Input: Puzzle images X [M×N×H×W] → EncoderZ → Z [M×N×K] → Encoder(Z→Z_o) → Z_o [rule-relevant] → MoE Aggregation → Rule Matrix R → Decoder(Z_r|R) → Decoder(Z_o|Z_r) → Decoder(Z|Z_o,Z̄_o) → Decoder(X|Z)
                         ↓                    ↓                    ↓                    ↓
                 Encoder(Z→Z̄_o)         R(Z_o)    R(Z_o^ctx)  R(Z_o^prow)    R(Z_r) ← MoE Aggregation → Rule Matrix R
                         ↓
                   Z̄_o [distractors]

- **Critical path:** Image encoding → Z_o/Z̄_o split → Z_r extraction → MoE rule prediction → (generation path) Z_r sampling from R → Z_o → X reconstruction.

- **Design tradeoffs:**
  - More experts vs. computational cost: Adding predictors improves robustness but increases forward passes. Paper uses 4 experts as a balance.
  - Strong contrastive weighting (β_G, β_L=20) vs. training stability: Table 15 shows β_G, β_L=1 drops accuracy to 92.1%; higher weights stabilize but may over-regularize.
  - Latent dimensionality vs. capacity: Table 16 shows K=32 achieves 91.6%; K=64-128 achieves ~95%. Diminishing returns above K=64.

- **Failure signatures:**
  - OOD extrapolation failure: SIZE-E performance drops to 45.0% due to unseen small objects; encoder fails to extract features from tiny shapes.
  - Rule prediction collapse: If β_2=0 and contrastive loss is disabled, model may predict constant rules regardless of input (Table 8: 50.5% without contrastive).
  - O-IC/O-IG color generalization gap: Deterministic training colors cause 10-18% drops when testing with gray tones.

- **First 3 experiments:**
  1. Reproduce ELBO-only vs. ELBO+Contrastive gap: Train GenVP on RAVEN with β_G=β_L=0, then with β_G=β_L=20. Verify accuracy jumps from ~50% to ~95%.
  2. Ablate MoE aggregation strategies: Compare weighted average vs. simple average vs. product vs. learned NN mixture. Confirm weighted average is optimal.
  3. Test OOD size extrapolation: Evaluate trained model on SIZE-E test set. Expect ~45% accuracy; analyze failure modes on smallest objects.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the visual comprehension of numerical relationships be improved to handle intricate arithmetic rules in complex grid configurations?
- **Basis in paper:** The Conclusion states that models face challenges with "intricate arithmetic rules" and that "Improving visual comprehension of numerical relationships is an ongoing challenge, and we reserved this for future work."
- **Why unresolved:** Current performance on configurations involving number and position attributes is lower than on simpler configurations.
- **What evidence would resolve it:** Significant accuracy improvements on arithmetic-based rules within the O-IG and 3x3 layouts compared to current results.

### Open Question 2
- **Question:** What architectural or training modifications are required to improve generalization in attribute extrapolation scenarios, particularly for object size?
- **Basis in paper:** Section 4.1.2 notes "poor generalization during size extrapolation (SIZE-E)," attributing this to encoders struggling to extract features from "significantly smaller visual objects" not seen during training.
- **Why unresolved:** While the model handles interpolation well, it fails to generalize when visual attributes fall outside the training distribution range.
- **What evidence would resolve it:** Improved accuracy on the SIZE-E test set that approaches performance on SIZE-I or in-distribution data.

### Open Question 3
- **Question:** How can the generative pathway be refined to ensure higher coherence between the input abstract rules and the generated visual puzzles?
- **Basis in paper:** Table 5 shows an average "Generation Coherence" of only 78.0%, indicating a gap between the model's ability to solve puzzles and its ability to generate rule-abiding ones from scratch.
- **Why unresolved:** The latent space appears to struggle to consistently satisfy all rule constraints during unconditional generation.
- **What evidence would resolve it:** An increase in the "GEN. COHERENCE" metric, particularly for complex layouts like O-IG and 3x3.

## Limitations
- **Scalability concerns:** Performance on naturalistic visual reasoning tasks beyond controlled RPM datasets remains untested.
- **Contrastive learning assumptions:** Reliance on synthetic negative candidates may not capture the full complexity of real-world rule violations.
- **OOD generalization gaps:** Struggles with attribute extrapolation scenarios, particularly for object size (SIZE-E performance drops to 45.0%).

## Confidence
- **High confidence:** MoE mechanism improving rule prediction robustness (Table 14 quantitative gains). ELBO+Contrastive outperforming ELBO-only (Table 8: ~95% vs 50.5% on RAVEN).
- **Medium confidence:** OOD generalization capability (Table 2 shows performance drops on SIZE-E/SIZE-I, but no ablation on why). Z_o/Z̄_o disentanglement effectiveness (weak/no direct empirical validation).
- **Low confidence:** Real-world applicability beyond RPMs (no experiments on naturalistic visual reasoning datasets). Contrastive learning capturing semantic rule violations (no qualitative analysis of negative candidate quality).

## Next Checks
1. **Stress-test contrastive learning:** Replace synthetic negative candidates with hard negatives generated by human annotators introducing subtle rule violations. Measure if local contrastive loss maintains performance gains.
2. **Probe latent disentanglement:** Perform intervention studies on Z_o/Z̄_o dimensions by systematically perturbing each attribute and measuring downstream rule prediction changes. Validate whether irrelevant attributes truly remain unused in rule inference.
3. **Test transfer to naturalistic reasoning:** Fine-tune GenVP on a subset of natural images requiring abstract reasoning (e.g., CATER or CLEVRER) and measure if learned rule abstraction transfers without RPM-specific architectural modifications.