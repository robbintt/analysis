---
ver: rpa2
title: 'DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue
  Life Prediction'
arxiv_id: '2503.22475'
source_url: https://arxiv.org/abs/2503.22475
tags:
- fatigue
- learning
- life
- deepoformer
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of predicting fatigue life of
  aluminum alloys using machine learning, given the small size of experimental fatigue
  datasets that typically leads to overfitting. The authors propose DeepOFormer, a
  deep operator learning model that treats stress-life (S-N) curve prediction as learning
  a nonlinear operator mapping material and stress-related features to fatigue life.
---

# DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction

## Quick Facts
- **arXiv ID:** 2503.22475
- **Source URL:** https://arxiv.org/abs/2503.22475
- **Reference count:** 34
- **Primary result:** R² of 0.9515, MAE of 0.2080, and MRE of 0.5077 on aluminum alloy fatigue prediction

## Executive Summary
This paper introduces DeepOFormer, a deep operator learning model designed to predict fatigue life of aluminum alloys from S-N curves using limited experimental data. The approach formulates fatigue prediction as an operator learning problem, using a Transformer-based encoder to process material properties alongside domain-informed features derived from empirical fatigue models. DeepOFormer significantly outperforms state-of-the-art methods including DeepONet, TabTransformer, and XGBoost on a small dataset of 54 S-N curves, achieving R² of 0.9515 and demonstrating improved generalization to unseen alloys.

## Method Summary
DeepOFormer treats fatigue life prediction as learning a nonlinear operator mapping material properties and stress-related features to fatigue life. The architecture consists of a Transformer-based encoder (Branch Net) processing material features and an MLP (Trunk Net) processing stress and domain-informed features. Domain-informed features (Stüssi, Weibull, and Pascual-Meeker) are derived from empirical fatigue models and normalize stress relative to material limits. The model uses a customized Mean L2 Relative Error loss function optimized via Adam over 3000 epochs. Training uses a curve-level split with 47 curves for training and 7 for testing, repeated 10 times.

## Key Results
- Achieves R² of 0.9515, MAE of 0.2080, and MRE of 0.5077 on the test set
- Outperforms DeepONet (R² 0.82), TabTransformer, and XGBoost
- Domain-informed features improve R² from 0.9339 to 0.9515 when included
- ML2RE loss function stabilizes training on multi-scale fatigue life data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Formulating fatigue prediction as an operator learning problem improves generalization to unseen material alloys compared to standard regression.
- **Mechanism:** By splitting the architecture into a "Branch Net" (processing material properties $u$) and a "Trunk Net" (processing stress conditions $y$), the model learns a mapping $G(u)(y)$ rather than a direct input-output mapping. This separates the material state from the loading state, allowing the "Trunk" to learn a general stress-life relationship modulated by the "Branch."
- **Core assumption:** The fatigue life can be accurately approximated by a sum of products of basis functions representing material properties and stress features (Equation 5).
- **Evidence anchors:** [abstract] "formulating S-N curve prediction as an operator learning problem... significantly outperforming... DeepONet, TabTransformer, and XGBoost." [section III.A] "By formulating the fatigue life prediction problem as an operator learning problem... generalizes more robustly to new or unseen combinations." [corpus] Related work typically uses standard MLPs or Random Forests; DeepOFormer's operator approach aligns with recent trends in scientific ML (DeepONet) for function spaces.

### Mechanism 2
- **Claim:** Injecting domain-informed features (Stüssi, Weibull, PM) reduces the hypothesis space and data requirement for the neural network.
- **Mechanism:** Instead of forcing the network to learn the complex nonlinear relationship between raw stress ($\sigma_a$) and life ($N$) from scratch, the model is provided with intermediate "features" derived from empirical fatigue laws (Eq. 1-3). These features explicitly encode normalized distances to material limits (like UTS or Fatigue Strength), acting as a strong inductive bias.
- **Core assumption:** The empirical models (Stüssi, Weibull, PM), while insufficient as standalone predictors due to "parameter uncertainties," provide a mathematically relevant basis for the true fatigue relationship.
- **Evidence anchors:** [section IV, Table I] Removing domain features drops $R^2$ from 0.9515 to 0.9339 and increases MRE, indicating they provide unique information not captured by raw features alone. [section II] Describes how features normalize UTS relative to stress amplitude and fatigue strength. [corpus] Corpus neighbors validate that feature engineering is a critical mechanism for improving ML in fatigue domains.

### Mechanism 3
- **Claim:** A Transformer-based encoder for material features prevents information loss when handling mixed categorical (Temper) and continuous data.
- **Mechanism:** Standard MLPs often struggle with high-cardinality categorical variables. DeepOFormer uses self-attention (Eq. 4) to create "contextual embeddings" for categorical features (Temper) before fusing them with continuous mechanical properties. This allows the model to weigh the importance of specific temper treatments relative to strength properties dynamically.
- **Core assumption:** Categorical processing benefits from sequential attention mechanisms (as in NLP) even when data is tabular.
- **Evidence anchors:** [abstract] "DeepOFormer improves the deep operator learning framework with a transformer-based encoder." [section IV] DeepONet+Transformer (modifying the branch) improves over vanilla DeepONet ($R^2$ 0.82 $\to$ 0.87), supporting the utility of attention in this architecture. [corpus] Corpus signals mention "TabTransformer" in comparisons, suggesting Transformer architectures are becoming standard for tabular material data.

## Foundational Learning

- **Concept: Operator Learning (DeepONet)**
  - **Why needed here:** This paper is not standard regression; it learns a mapping between *functions*. You must understand that the "Branch" network encodes the input function (material properties) while the "Trunk" evaluates the output at specific coordinates (stress).
  - **Quick check question:** If you change the material (input function) but keep the stress level the same, which network (Branch or Trunk) requires re-evaluation?

- **Concept: Empirical Fatigue Models (S-N Curves)**
  - **Why needed here:** The "secret sauce" of this paper is the feature engineering. You need to grasp what Stüssi and Weibull features represent physically (probability of failure and stress normalized by limits) to understand why they help the model.
  - **Quick check question:** Why would a feature that normalizes stress by the Ultimate Tensile Strength (UTS) help a model predict failure better than raw stress alone?

- **Concept: Mean L2 Relative Error (ML2RE)**
  - **Why needed here:** Fatigue life spans orders of magnitude ($10^4$ to $10^{10}$). A standard Mean Squared Error (MSE) would prioritize high-cycle failures. This loss function forces the model to prioritize relative accuracy across all scales.
  - **Quick check question:** How does dividing by the true value $y_j^2$ in the loss function (Eq. 6) change the penalty for errors in predicting long lifetimes vs. short lifetimes?

## Architecture Onboarding

- **Component map:** Material Inputs (UTS, TYS, Temper, R) -> Transformer Encoder -> Contextual Embeddings -> MLP -> Vector b; Stress Inputs ($\sigma_a, \sigma_a^3$, Stüssi, Weibull, PM) -> MLP -> Vector t; Dot product of b and t + bias

- **Critical path:** The interaction between the **Transformer Encoder** and the **Domain Features** is the critical path. If the Transformer fails to fuse the "Temper" data correctly, or if the Stüssi features are calculated incorrectly, the operator approximation fails.

- **Design tradeoffs:**
  - **Data Efficiency vs. Complexity:** The model adds complexity (Transformers) to handle very small data (257 points) effectively by using strong inductive biases (Domain features). Without these features, the complex model would likely overfit.
  - **Loss Function:** ML2RE stabilizes training on multi-scale data but requires a small $\epsilon$ to prevent division by zero.

- **Failure signatures:**
  - **Nan Loss:** Check the $\epsilon$ in ML2RE (set to $10^{-30}$); if true values are zero or near-zero, division can destabilize.
  - **Poor Generalization:** If the Transformer overfits the categorical "Temper" data (dropout is set to 0.2/0.1), performance on new alloys will drop sharply.
  - **High MRE:** If domain features are omitted, the Mean Relative Error (MRE) spikes (as seen in Table I), indicating errors in order-of-magnitude prediction.

- **First 3 experiments:**
  1. **Baseline Validation:** Replicate the DeepONet result (Table I, Row 3) to ensure your Trunk/Branch setup is functional.
  2. **Feature Ablation:** Run the model *without* Stüssi/Weibull/PM features to quantify the exact contribution of the domain knowledge (expect ~2% drop in $R^2$).
  3. **Loss Sensitivity:** Swap ML2RE for standard MSE to observe how the error distribution shifts from high-cycle to low-cycle data points.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can integrating a physics-informed loss function effectively penalize physically implausible predictions and improve generalization in DeepOFormer?
- **Basis in paper:** [explicit] The conclusion explicitly states that "designing a physics-informed loss function could provide stronger constraints on the learning process by penalizing physically implausible predictions" as a direction for future work.
- **Why unresolved:** The current implementation relies on a data-driven Mean L2 Relative Error (ML2RE) loss, which does not explicitly enforce physical laws or constraints during training.
- **What evidence would resolve it:** A comparative study showing that a physics-informed loss reduces the prediction of non-physical fatigue lives (e.g., increasing life with increasing stress) compared to the ML2RE baseline.

### Open Question 2
- **Question:** How does DeepOFormer's performance scale when applied to a larger, more diverse dataset of aluminum alloys?
- **Basis in paper:** [explicit] The authors identify the small dataset size (257 points) as a limitation and state, "Our future work will focus on enriching the dataset."
- **Why unresolved:** The current results are based on a small sample of 54 S-N curves from seven alloys, which restricts the diversity of alloy compositions and potentially limits the validation of the model's robustness.
- **What evidence would resolve it:** Evaluation metrics (R2, MAE, MRE) from training and testing DeepOFormer on an expanded dataset containing a wider variety of aluminum alloy compositions and treatment conditions.

### Open Question 3
- **Question:** Is the proposed framework transferable to fatigue life prediction for other material classes, such as steel or titanium alloys?
- **Basis in paper:** [inferred] While the introduction discusses fatigue prediction broadly, the methodology and experiments are restricted to aluminum alloys; the conclusion suggests the tool must be improved to extend its utility to "diverse industrial... applications."
- **Why unresolved:** The domain-informed features (Stüssi, Weibull, PM) and the model weights were derived or trained specifically for aluminum, and it is unclear if the empirical feature definitions apply directly to materials with different fatigue mechanisms.
- **What evidence would resolve it:** Successful application of the DeepOFormer architecture, potentially with adapted domain features, to fatigue datasets for non-aluminum materials without significant loss of accuracy.

## Limitations
- Small dataset (257 points) limits generalizability and statistical significance
- Data split reproducibility is challenging without specific curve indices
- Model is only validated on aluminum alloys, transferability unknown
- Strong performance depends on domain-informed features that may not generalize

## Confidence

- **High Confidence:** The operator learning framework and its superiority over standard regression for S-N curve prediction are well-supported by the ablation study and comparison with DeepONet, TabTransformer, and XGBoost.
- **Medium Confidence:** The specific architectural choices (e.g., Transformer encoder, ML2RE loss) are likely beneficial, but the small dataset size means the optimal configuration is not definitively established.
- **Medium Confidence:** The claim that domain-informed features provide a strong inductive bias is supported by the ablation study, but the exact contribution of each individual feature is not isolated.

## Next Checks

1. **Dataset Split Replication:** Contact the authors to obtain the exact indices of the 47 training and 7 test curves used in the study to ensure a fair and reproducible comparison.

2. **Domain Feature Sensitivity:** Conduct a feature ablation study to quantify the individual contribution of each domain-informed feature (Stüssi, Weibull, PM) to the overall model performance.

3. **Cross-Material Validation:** Evaluate the DeepOFormer model on a different material system (e.g., steel alloys) to assess its generalizability beyond the aluminum alloy dataset.