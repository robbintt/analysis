---
ver: rpa2
title: Multi-Task Vehicle Routing Solver via Mixture of Specialized Experts under
  State-Decomposable MDP
arxiv_id: '2510.21453'
source_url: https://arxiv.org/abs/2510.21453
tags:
- basis
- moses
- time
- cada
- lora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new framework for multi-task vehicle routing
  problems (VRPs) that leverages the compositional structure of VRP variants by reusing
  basis solvers specialized for each component. The authors introduce a State-Decomposable
  MDP (SDMDP) framework to reformulate VRPs, enabling the optimal unified policy to
  be recovered from optimal basis policies via a mixture function in the latent space.
---

# Multi-Task Vehicle Routing Solver via Mixture of Specialized Experts under State-Decomposable MDP

## Quick Facts
- arXiv ID: 2510.21453
- Source URL: https://arxiv.org/abs/2510.21453
- Reference count: 40
- Primary result: Reduces average optimality gaps by up to 25.6% compared to state-of-the-art unified solvers

## Executive Summary
This paper addresses the challenge of solving multiple VRP variants by leveraging their compositional structure through a State-Decomposable MDP framework. The authors propose a Mixture-of-Specialized-Experts Solver (MoSES) that decomposes VRP state spaces into basis components and reuses specialized experts via LoRA adapters and adaptive gating. Extensive experiments across 16 VRP variants demonstrate MoSES achieves superior performance with strong out-of-distribution generalization while maintaining reasonable computational efficiency.

## Method Summary
The method employs a three-stage pipeline: first pretraining a backbone encoder-decoder on Capacitated VRP, then specializing four LoRA experts for non-capacity basis constraints (Open Route, Backhaul, Duration Limit, Time Window), and finally unifying them with an adaptive gating network and trainable residual LoRA. The State-Decomposable MDP (SDMDP) framework reformulates VRPs by expressing state spaces as Cartesian products of basis components, while the Latent Space SDMDP (LS-SDMDP) extension enables policy reuse by mixing embeddings from optimal basis policies. MoSES implements this using frozen backbone models, specialized Gated-LoRA experts, and dynamic aggregation based on learned routing weights.

## Key Results
- MoSES achieves 25.6% lower average optimality gaps compared to state-of-the-art unified solvers across 16 VRP variants
- Strong out-of-distribution generalization capabilities on unseen vehicle capacities and time windows
- Maintains computational efficiency despite mild overhead from fine-grained aggregation
- Dense routing (activating all experts) outperforms variant-aware routing, suggesting partial correlations between basis tasks are useful

## Why This Works (Mechanism)

### Mechanism 1: Compositional State Decomposition (SDMDP)
The framework treats VRP variants as Cartesian products of independent basis state spaces, allowing a unified solver to generalize across combinatorial constraints without training on every specific variant combination. This decomposition is valid when VRP constraints are conditionally independent given the action.

### Mechanism 2: Latent Space Policy Reuse (LS-SDMDP)
A unified policy is recovered by mixing embeddings generated by optimal basis policies through a learnable mixture function. This enables the reuse of specialized knowledge while maintaining a single policy architecture.

### Mechanism 3: Low-Rank Adaptation (LoRA) of Specialized Experts (MoSES)
Parameter-efficient fine-tuning via LoRA allows scaling to many VRP variants by keeping the backbone frozen and only training small specialized adapters. The adaptive gating mechanism dynamically selects relevant experts during inference.

## Foundational Learning

- **Concept: Vehicle Routing Problems (VRP) & Constraints**
  - Why needed: Understanding how constraints define basis tasks is crucial for the compositional approach
  - Quick check: Can you explain why adding a "Backhaul" constraint changes the action mask compared to a standard "Capacitated" VRP?

- **Concept: Reinforcement Learning (RL) & REINFORCE**
  - Why needed: Neural solvers are trained using REINFORCE to maximize expected cumulative rewards
  - Quick check: How does the reward signal penalize infeasible solutions vs. simply long tours?

- **Concept: Low-Rank Adaptation (LoRA)**
  - Why needed: Core architectural contribution relies on using LoRA to create experts efficiently
  - Quick check: In a linear layer $h_{out} = W_0 h_{in}$, how does LoRA modify the forward pass to inject new task-specific knowledge?

## Architecture Onboarding

- **Component map:** Input VRP Instance -> Frozen Backbone Encoder -> All LoRA Experts in parallel -> Gating Network computes weights -> Weighted sum of LoRA outputs + trainable residual -> Decoder for action selection

- **Critical path:**
  1. Instance Encoding: Input through frozen backbone and all LoRA experts
  2. Dynamic Aggregation: Gating Network assigns coefficients to each LoRA output
  3. Mixture: Weighted sum of LoRA outputs added to backbone output
  4. Decoding: Decoder predicts next node using aggregated context

- **Design tradeoffs:** Dense routing (activating all experts) works best, suggesting partial correlations between basis tasks are useful; higher LoRA rank is generally better but frozen experts more critical for smaller instances

- **Failure signatures:**
  - Expert Collapse: Gating network consistently outputs high weights for backbone and near-zero for others
  - OOD Degradation: Significant performance drops on unseen vehicle capacities or time windows
  - Catastrophic forgetting of basis skills during unified training

- **First 3 experiments:**
  1. Train each LoRA expert individually on its respective basis variant to ensure convergence
  2. Compare "Dense Routing" vs. "Variant-Aware Routing" on held-out variants to verify automatic constraint discovery
  3. Evaluate performance on N=50 vs. N=100 while varying LoRA ranks to determine expert contribution sensitivity

## Open Questions the Paper Calls Out
- Can more efficient aggregation techniques be designed to mitigate computational overhead from dynamic routing mechanisms?
- Can the State-Decomposable MDP framework be generalized to broader decision-making settings beyond vehicle routing problems?
- How does the framework's theoretical optimality recovery hold when the assumption of conditional independence between basis states is violated?

## Limitations
- Relies heavily on the assumption of conditional independence between basis state spaces, which may not hold for all VRP variants
- The optimal mixture function is assumed to be a deterministic bijection, but this is not rigorously proven for the specific variants studied
- Adaptive gating mechanism may not generalize well to entirely new constraint combinations beyond the 16 variants tested

## Confidence
- **High confidence** in compositional state decomposition approach (SDMDP) - aligns with established MDP theory and robust empirical results
- **Medium confidence** in latent space policy reuse mechanism (LS-SDMDP) - theoretical foundation sound but practical implementation details unclear
- **Medium confidence** in LoRA-based expert specialization (MoSES) - architectural details well-defined but scaling behavior for extremely large numbers of variants untested

## Next Checks
1. **Constraint Coupling Test:** Systematically evaluate performance degradation when adding correlated constraints that violate conditional independence assumption
2. **Mixture Function Sensitivity:** Conduct ablation studies varying mixture function complexity to quantify impact on policy quality and verify bijection assumption
3. **Gating Generalization Stress Test:** Test MoSES on novel VRP variants with constraint combinations not seen during training to measure generalization capability