---
ver: rpa2
title: 'Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models
  via Decentralized Bayesian Inference'
arxiv_id: '2504.09620'
source_url: https://arxiv.org/abs/2504.09620
tags:
- mhcg
- agent
- agents
- learning
- coco
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the Metropolis-Hastings Captioning Game (MHCG),
  a method for fusing knowledge between vision-language models (VLMs) through a decentralized
  Bayesian inference process inspired by emergent communication. The approach treats
  two pre-trained VLMs as agents that communicate by alternately proposing captions
  for images and accepting/rejecting them based on the Metropolis-Hastings algorithm.
---

# Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference

## Quick Facts
- **arXiv ID**: 2504.09620
- **Source URL**: https://arxiv.org/abs/2504.09620
- **Reference count**: 19
- **Primary result**: Proposes a decentralized Bayesian inference method for fusing knowledge between pre-trained VLMs without catastrophic forgetting

## Executive Summary
This paper introduces the Metropolis-Hastings Captioning Game (MHCG), a novel approach for fusing knowledge between pre-trained vision-language models (VLMs) through emergent communication. The method treats two VLMs as agents that communicate by proposing and accepting/rejecting image captions based on the Metropolis-Hastings algorithm. Through iterative interactions, the agents learn from each other's plausible captions while preserving their original knowledge, avoiding catastrophic forgetting. The approach demonstrates consistent improvements in reference-free evaluation metrics when fusing VLMs trained on different datasets, outperforming both fine-tuning and ensemble baselines.

## Method Summary
The Metropolis-Hastings Captioning Game (MHCG) is a decentralized Bayesian inference framework that enables knowledge fusion between two pre-trained VLMs. The method simulates emergent communication by treating the VLMs as agents that alternately propose captions for images. Each proposed caption is evaluated using the Metropolis-Hastings algorithm, where acceptance depends on the likelihood of the caption given the image and the proposal distribution. This iterative process allows the agents to learn from each other's plausible captions while maintaining their original knowledge. The approach is particularly effective for cross-dataset knowledge fusion, as demonstrated by experiments with VLMs pre-trained on COCO and CC3M datasets, achieving improved performance without requiring increased inference time.

## Key Results
- MHCG achieves consistent improvements in reference-free evaluation metrics when fusing VLMs pre-trained on different datasets (COCO and CC3M)
- The method outperforms fine-tuning and ensemble approaches, particularly in cross-dataset captioning tasks
- Category-level analysis shows MHCG agents effectively balance retaining original knowledge while acquiring complementary information from counterparts

## Why This Works (Mechanism)
The Metropolis-Hastings Captioning Game leverages emergent communication principles to enable knowledge fusion between pre-trained VLMs without catastrophic forgetting. By treating VLMs as agents that communicate through caption proposals and acceptances, the method creates a decentralized Bayesian inference process where each agent learns from the other's plausible outputs. The Metropolis-Hastings acceptance criterion ensures that only beneficial knowledge transfers are incorporated, while the iterative nature of the game allows for gradual, stable learning. This approach is particularly effective because it avoids direct parameter sharing or fine-tuning, instead relying on the VLMs' existing capabilities to generate and evaluate captions, which preserves their original knowledge while enabling complementary learning.

## Foundational Learning
- **Emergent Communication**: Understanding how agents can develop shared protocols for communication through interaction. Why needed: Forms the theoretical basis for the MHCG's agent communication model. Quick check: Can be verified by observing whether the agents develop consistent caption patterns over iterations.
- **Bayesian Inference**: The mathematical framework for updating beliefs based on evidence. Why needed: Provides the probabilistic foundation for the Metropolis-Hastings acceptance criterion. Quick check: Verify that the acceptance probability calculations follow proper Bayesian updating rules.
- **Catastrophic Forgetting**: The phenomenon where neural networks lose previously learned information when trained on new tasks. Why needed: Understanding this problem motivates the need for MHCG's approach to knowledge preservation. Quick check: Compare performance on original vs. new datasets before and after fusion.
- **Metropolis-Hastings Algorithm**: A Markov Chain Monte Carlo method for sampling from probability distributions. Why needed: Provides the acceptance/rejection mechanism for caption proposals. Quick check: Ensure proper implementation of the acceptance probability formula.
- **Vision-Language Model Architectures**: Understanding how VLMs process and generate image captions. Why needed: Essential for implementing the MHCG's agent interactions. Quick check: Verify that caption generation and evaluation functions work as expected.
- **Reference-Free Evaluation Metrics**: Metrics that evaluate caption quality without ground truth references. Why needed: Used to assess the quality of generated captions in MHCG. Quick check: Validate that metrics correlate with human judgments.

## Architecture Onboarding

Component map: Image Input -> VLM Agent 1 (Proposer) -> Metropolis-Hastings Acceptance -> VLM Agent 2 (Evaluator) -> Knowledge Update -> VLM Agent 1 (Evaluator) -> Metropolis-Hastings Acceptance -> VLM Agent 2 (Proposer) -> ... (Iterative Loop)

Critical path: The core loop consists of: (1) one agent proposes a caption for an image, (2) the other agent evaluates and potentially accepts/rejects based on Metropolis-Hastings, (3) the accepted caption updates the accepting agent's knowledge, (4) roles reverse and the process repeats. This cycle continues until convergence or a stopping criterion is met.

Design tradeoffs: The main tradeoff is between exploration (proposing diverse captions) and exploitation (accepting only highly probable captions). The temperature parameter in the Metropolis-Hastings acceptance criterion controls this balance. Higher temperatures allow more exploration but risk incorporating incorrect knowledge, while lower temperatures are more conservative but may miss beneficial knowledge transfers.

Failure signatures: Common failure modes include: (1) one agent dominating the interaction and preventing knowledge transfer, (2) excessive rejection of captions leading to no learning, (3) acceptance of poor captions degrading performance, (4) catastrophic forgetting if the acceptance criteria are too lenient, (5) getting stuck in local optima where agents repeatedly propose similar captions.

First experiments: 
1. Test the MHCG framework with a single image and two VLMs to verify basic functionality and observe the caption proposal/acceptance cycle
2. Run ablation studies with different temperature settings to understand their impact on knowledge transfer and catastrophic forgetting
3. Compare the convergence behavior of MHCG with traditional fine-tuning approaches on a small dataset to establish baseline performance differences

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on reference-free evaluation metrics, which may not fully capture caption quality compared to human judgments
- Effectiveness across different VLM architectures beyond CLIP-based models remains untested
- Computational overhead of the Metropolis-Hastings sampling process during training, while not affecting inference time, could be significant for larger-scale applications

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Claims about knowledge fusion effectiveness | High |
| Claims about avoiding catastrophic forgetting | High |
| Claims about performance without increased inference time | High |
| Claims about superiority over ensemble methods | Medium |

## Next Checks
1. Conduct human evaluation studies to validate the reference-free metric results and assess caption quality from a user perspective
2. Test the MHCG framework with non-CLIP-based VLM architectures to evaluate generalizability
3. Perform ablation studies to determine the impact of the Metropolis-Hastings acceptance rate and temperature parameters on knowledge fusion outcomes