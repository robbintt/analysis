---
ver: rpa2
title: Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and
  Knowledge-Distilled Kronecker Networks
arxiv_id: '2512.19488'
source_url: https://arxiv.org/abs/2512.19488
tags:
- student
- teacher
- detection
- pruning
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of deploying accurate intrusion\
  \ detection systems (IDS) on resource-constrained IoT devices, where conventional\
  \ deep learning models are too large and computationally intensive. The proposed\
  \ solution combines SHAP-guided feature pruning with knowledge-distilled Kronecker\
  \ networks: a high-capacity teacher model uses SHAP explanations to identify and\
  \ prune irrelevant features, while a compressed student network with Kronecker-structured\
  \ layers is trained via knowledge distillation to mimic the teacher\u2019s decision\
  \ boundaries."
---

# Lightweight Intrusion Detection in IoT via SHAP-Guided Feature Pruning and Knowledge-Distilled Kronecker Networks

## Quick Facts
- **arXiv ID:** 2512.19488
- **Source URL:** https://arxiv.org/abs/2512.19488
- **Reference count:** 14
- **Primary result:** SHAP-guided pruning + Kronecker networks yield 1000× size reduction with F1 > 0.986 on TON IoT dataset

## Executive Summary
This paper tackles the challenge of deploying accurate intrusion detection systems on resource-constrained IoT devices by combining SHAP-guided feature pruning with knowledge-distilled Kronecker networks. A high-capacity teacher model uses SHAP explanations to identify and prune irrelevant features, while a compressed student network with Kronecker-structured layers is trained via knowledge distillation to mimic the teacher’s decision boundaries. Experiments on the TON IoT dataset demonstrate that the student model is nearly three orders of magnitude smaller than the teacher yet maintains macro-F1 above 0.986, with millisecond-level inference latency. This approach enables scalable, low-latency, and energy-efficient IDS suitable for heterogeneous IoT environments.

## Method Summary
The approach integrates SHAP (SHapley Additive exPlanations) for feature importance ranking, followed by aggressive feature pruning to reduce input dimensionality. A teacher network is trained on the pruned feature set, then a student Kronecker network is trained via knowledge distillation to mimic the teacher’s behavior while maintaining a drastically reduced parameter count. Kronecker-structured layers approximate full weight matrices using Kronecker products, enabling significant compression without severe accuracy loss.

## Key Results
- Student model is ~1000× smaller than teacher model
- Macro-F1 score maintained above 0.986
- Inference latency in millisecond range
- Validated on TON IoT dataset

## Why This Works (Mechanism)
The method leverages SHAP for interpretability-driven feature selection, ensuring only the most impactful features are retained. Knowledge distillation transfers the teacher’s learned decision boundaries to a compact student network, while Kronecker factorization compresses the student’s layers without significant accuracy loss. This combination allows for both computational efficiency and high detection performance.

## Foundational Learning
- **SHAP (SHapley Additive exPlanations):** Provides feature importance scores via game-theoretic attribution; needed to identify redundant or irrelevant features; quick check: verify SHAP values are stable across different model initializations.
- **Knowledge Distillation:** Trains a compact student network to mimic a larger teacher; needed to preserve accuracy while compressing the model; quick check: compare student and teacher predictions on validation set.
- **Kronecker Product Factorization:** Decomposes weight matrices into Kronecker products for compression; needed to reduce model size without full retraining; quick check: confirm Kronecker approximation error is within acceptable bounds.
- **Feature Pruning:** Removes low-importance features to reduce input dimensionality; needed to minimize computational load; quick check: measure inference speedup after pruning.
- **Macro-F1 Score:** Evaluates model performance across all classes equally; needed for balanced detection in multi-class IoT intrusion scenarios; quick check: ensure no class is consistently misclassified.

## Architecture Onboarding
- **Component Map:** IoT traffic → SHAP feature selection → Teacher network → Knowledge distillation → Kronecker student network → Intrusion detection output
- **Critical Path:** Feature pruning (SHAP) → Teacher training → Student distillation → Deployment
- **Design Tradeoffs:** High accuracy vs. model size, interpretability vs. computational overhead, generalizability vs. dataset specificity
- **Failure Signatures:** Performance drop on unseen attack types, unstable SHAP rankings, excessive distillation loss
- **First Experiments:**
  1. Validate SHAP feature rankings on a subset of TON dataset
  2. Train teacher network and benchmark against baseline models
  3. Distill teacher into Kronecker student and measure size/accuracy tradeoff

## Open Questions the Paper Calls Out
None

## Limitations
- Performance claims rely on TON IoT dataset, which may not generalize to other IoT traffic patterns or attack types
- No reported real-world energy consumption or battery impact on actual IoT devices
- SHAP-based feature selection may introduce bias if explanations are unstable across model initializations
- Kronecker student’s generalizability to evolving attack patterns remains untested
- Training pipeline’s computational requirements for larger IoT deployments are not addressed

## Confidence
- **High confidence:** Model size reduction and inference latency measurements
- **Medium confidence:** F1-score retention claims (dependent on single dataset)
- **Low confidence:** Robustness to concept drift and evolving attack patterns

## Next Checks
1. Evaluate the proposed IDS on multiple IoT datasets (e.g., N-BaIoT, CICIDS2017) to assess generalization across different environments and attack scenarios
2. Conduct real-world deployment tests on battery-powered IoT devices to measure actual energy consumption and operational lifespan under typical IDS workloads
3. Implement and test the system's adaptability to concept drift by simulating evolving attack patterns and measuring the need for retraining or model updates