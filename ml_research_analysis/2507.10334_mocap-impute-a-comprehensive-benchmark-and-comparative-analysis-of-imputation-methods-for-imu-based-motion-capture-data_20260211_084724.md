---
ver: rpa2
title: 'MoCap-Impute: A Comprehensive Benchmark and Comparative Analysis of Imputation
  Methods for IMU-based Motion Capture Data'
arxiv_id: '2507.10334'
source_url: https://arxiv.org/abs/2507.10334
tags:
- data
- missing
- imputation
- methods
- points
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces the first benchmark dataset and systematic\
  \ evaluation framework for imputing missing values in IMU-based motion capture (MoCap)\
  \ data. The authors simulate three missingness mechanisms\u2014MCAR, block missingness,\
  \ and transition-point-dependent missingness\u2014across 53 karate practitioners\
  \ performing 39 kinematic variables."
---

# MoCap-Impute: A Comprehensive Benchmark and Comparative Analysis of Imputation Methods for IMU-based Motion Capture Data

## Quick Facts
- arXiv ID: 2507.10334
- Source URL: https://arxiv.org/abs/2507.10334
- Reference count: 40
- Primary result: Multivariate imputation methods (GAIN, Iterative Imputer) reduce MAE by up to 50% compared to univariate approaches in challenging transition-point scenarios

## Executive Summary
This paper introduces the first systematic benchmark for imputing missing values in IMU-based motion capture data, addressing a critical gap in the MoCap research pipeline. The authors evaluate 53 karate practitioners performing 39 kinematic variables across three missingness mechanisms: MCAR, block missingness, and transition-point-dependent missingness. Through comprehensive comparisons of statistical, machine learning, and deep learning imputation methods, the study demonstrates that multivariate approaches consistently outperform univariate techniques, with advanced methods like GAIN and Iterative Imputer achieving up to 50% MAE reduction in the most challenging scenarios. The work provides practical recommendations and establishes a critical baseline for future MoCap data imputation research.

## Method Summary
The benchmark evaluates imputation methods across three contexts: univariate (single series), multivariate across players (cohort-based), and multivariate across angles (biomechanically coupled features). The study uses a 53×100×39 tensor representing 53 players, 100 time points, and 39 kinematic angles from karate movements. Three missingness mechanisms are simulated: MCAR (random), block (contiguous segments), and transition-point-dependent (local extrema). Imputation methods include SimpleFill (mean/median), KNN, Iterative Imputer, and GAIN, evaluated using mean absolute error on masked positions. The framework provides context-aware slicing and normalization with inverse transforms for evaluation.

## Key Results
- Multivariate-angle context consistently achieves best performance by leveraging biomechanical coupling
- Transition-point dependent missingness is most challenging, with simple methods producing physically implausible reconstructions
- GAIN and Iterative Imputer achieve up to 50% MAE reduction (from 10.8 to 5.8) compared to univariate techniques
- Cohort-based imputation (multivariate-player) reduces KNN MAE from 12.0±9.89 to 4.29±7.06 (64% reduction)
- SimpleFill methods fail catastrophically when averaging biomechanically distinct joint angles

## Why This Works (Mechanism)

### Mechanism 1: Biomechanical Coupling Exploitation (Multivariate-Angle Context)
Imputation using multiple kinematic angles from the same subject achieves best performance by leveraging inherent physical constraints of the human kinematic chain. When one joint angle's data is missing, synchronized measurements from other joints provide structural constraints—the elbow's state correlates with shoulder and wrist states due to biomechanical coupling. Models like Iterative Imputer learn these cross-feature correlations and reconstruct missing values consistent with physically plausible motion.

### Mechanism 2: Cohort Similarity Leverage (Multivariate-Player Context)
Using data from multiple players performing the same standardized skill provides a population-based prior that improves reconstruction for individual missing values. When one player's sensor data is missing at critical moments, the distribution of equivalent movements across other players creates a statistical template. Models learn a "shared archetype" for the skill, enabling reconstruction even when individual temporal context is lost.

### Mechanism 3: Transition-Point Sensitivity to Missingness Mechanism
Value-dependent missingness at transition points (local extrema) creates fundamentally harder imputation challenges than MCAR, requiring models capable of capturing non-linear dynamics rather than statistical averages. Transition points represent high kinetic change (peaks/valleys). Simple statistical methods flatten these dynamics, producing physically implausible reconstructions. Advanced models capture non-linear temporal patterns, enabling better approximation of missing extrema.

## Foundational Learning

- **Concept: Missing Data Mechanisms (MCAR, MAR, MNAR)**
  - Why needed: The paper evaluates three mechanisms, and misclassifying your real-world missingness pattern will lead to inappropriate method selection.
  - Quick check: If sensor data is lost specifically during rapid acceleration peaks due to signal clipping, is this MCAR, MAR, or MNAR—and which imputation approach would you prioritize?

- **Concept: GAIN (Generative Adversarial Imputation Networks) Architecture**
  - Why needed: GAIN is a top performer; understanding its generator-discriminator game helps diagnose training failures and tune hyperparameters.
  - Quick check: In GAIN, the discriminator receives a "hint" vector H that partially reveals the mask. What happens to training stability if the hint is too informative vs. too sparse?

- **Concept: Iterative Imputation (Chained Equations)**
  - Why needed: Iterative Imputer consistently performs well; understanding its convergence behavior helps set appropriate iteration limits and detect non-convergence.
  - Why it works for MoCap: Each angle is modeled as a function of others, iteratively refining predictions—matching the biomechanical correlation structure.
  - Quick check: If Iterative Imputer fails to converge after 100 iterations on your MoCap data, what does that suggest about the correlation structure between features?

## Architecture Onboarding

- **Component map:**
  Raw Tensor X (53×100×39) → Normalization Module → Missing Mask Generator (MCAR/Transition/Block)
                                              ↓
                                    Context Dispatcher
                         ┌─────────────────┼─────────────────┐
                    Univariate      Multivariate-Player  Multivariate-Angle
                    (P×T×A slices)     (P×T per angle)      (T×A per player)
                         ↓                  ↓                    ↓
                         └─────────────────┬────────────────────┘
                                    Imputation Engine
                         [GAIN | Iterative | KNN | BSI | SimpleFill]
                                              ↓
                               Inverse Transform → MAE Evaluation
                                              ↓
                                     Results Aggregation

- **Critical path:**
  1. Load MoCap tensor and apply min-max normalization (save min/max for inverse transform)
  2. Generate missing mask M using specified mechanism (MCAR, transition-point, block) with target missingness rate
  3. Dispatch to context handler: slice tensor appropriately
  4. Apply imputation algorithm with fitted parameters
  5. Inverse-transform predictions to original scale
  6. Compute MAE only at masked positions (M==1)

- **Design tradeoffs:**
  - **Context selection**: Multivariate-angle provides best accuracy but requires full sensor suite; multivariate-player requires cohort data; univariate works for single-sensor scenarios but fails on complex missingness
  - **Algorithm complexity**: SimpleFill (O(n)) vs GAIN (requires GAN training) vs Iterative Imputer (multiple regression fits per iteration)
  - **Parallelization**: Independent series/contexts can run concurrently (paper uses Python multiprocessing), but GPU-based methods like GAIN may need batching strategy

- **Failure signatures:**
  - MAE > 300 on transition-point missingness in univariate → method cannot capture dynamics; switch to multivariate context
  - High variance (std >> mean MAE) → method unstable on certain angles/players; investigate outliers
  - SimpleFill methods showing MAE > 100 in multivariate-angle context → averaging across biomechanically distinct joints produces physically impossible values
  - GAIN discriminator loss → 0 early in training → mode collapse; check hint vector configuration

- **First 3 experiments:**
  1. **Sanity check**: Run all methods on MCAR at 5% missingness in univariate context. Verify SimpleFill mean produces MAE ≈ std of the data (baseline). Confirm KNN and Iterative Imputer improve over baseline.
  2. **Stress test on hardest case**: Test GAIN, Iterative Imputer, and KNN on transition-point missingness at 25% across all three contexts. Identify which context-method combination achieves < 10 MAE.
  3. **Cohort sensitivity analysis**: Hold out 10 players as test set, train imputation models on remaining 43. Measure how cohort size affects multivariate-player context performance to understand minimum data requirements for production deployment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do current benchmark-leading methods (e.g., GAIN, Iterative Imputer) perform on naturally occurring missing data versus the simulated mechanisms (MCAR, Block, Transition) studied?
- Basis in paper: The conclusion states future researchers should focus on "transparent validation studies when working with real observations that will have naturally occurring gaps."
- Why unresolved: This study relied entirely on synthetically generated missingness to ensure controlled comparison; real-world sensor dropouts may exhibit more complex or chaotic dependencies.

### Open Question 2
- Question: Do these imputation findings generalize to longer motion sequences or diverse movement vocabularies beyond the 100 time-point karate skills evaluated?
- Basis in paper: The conclusion notes the dataset scale (53 subjects, 100 time points) "may limit the generalisability of our findings to sequences longer or with more diverse movements."
- Why unresolved: The current benchmark is restricted to short, specific karate skills, potentially missing long-range temporal dependencies found in continuous activities like walking or running.

### Open Question 3
- Question: How robust are the top-performing imputation methods when applied to raw IMU data containing drift or magnetic interference, rather than pre-processed kinematic angles?
- Basis in paper: The paper acknowledges IMU issues like drift and magnetic interference in Section 2.1, yet the benchmark dataset consists of processed kinematic variables.
- Why unresolved: It is unclear if deep learning models like GAIN can effectively separate signal from noise when imputing raw sensor streams, or if they require the cleaned data used in this study.

## Limitations

- Dataset specificity: Study relies on single karate dataset with fixed temporal resolution (100 timesteps), raising questions about generalizability to other MoCap scenarios
- Computational complexity: GAIN's training complexity and convergence sensitivity may limit practicality in resource-constrained settings
- Context limitation: Analysis focuses on univariate and bivariate contexts, potentially missing opportunities for more sophisticated multi-context fusion approaches

## Confidence

- **High confidence**: Multivariate-angle context consistently outperforming univariate methods across all missingness mechanisms; the biomechanical coupling mechanism as primary driver of performance gains
- **Medium confidence**: Transition-point dependent missingness being the most challenging scenario; cohort-based imputation benefits for multivariate-player context
- **Low confidence**: Specific GAIN hyperparameter choices and their impact on performance; the exact relationship between missingness mechanism detection and method selection in real-world deployments

## Next Checks

1. **Cross-domain generalization test**: Apply the best-performing methods (Iterative Imputer, GAIN) to a different MoCap dataset (e.g., walking, running, or other sports) with different temporal characteristics to validate biomechanically-driven imputation generalizes beyond karate movements.

2. **Real-world missingness simulation**: Replace artificial missingness generation with real IMU failure patterns from operational systems to test method robustness against actual sensor degradation patterns rather than controlled simulations.

3. **Computational efficiency benchmarking**: Quantify training and inference times for GAIN versus statistical methods across different hardware configurations to establish practical deployment thresholds and identify optimal use cases for each approach.