---
ver: rpa2
title: Defending the Hierarchical Result Models of Precedential Constraint
arxiv_id: '2512.13505'
source_url: https://arxiv.org/abs/2512.13505
tags:
- factors
- have
- case
- hierarchical
- bench-capon
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper defends the hierarchical result models of precedential
  constraint against criticisms by Trevor Bench-Capon regarding their handling of
  intermediate factors. The key argument is that Bench-Capon's examples implicitly
  treat intermediate factors as dimensions, making van Woerkom's dimension-based hierarchical
  result model (DHRM) applicable.
---

# Defending the Hierarchical Result Models of Precedential Constraint

## Quick Facts
- arXiv ID: 2512.13505
- Source URL: https://arxiv.org/abs/2512.13505
- Reference count: 18
- Primary result: The dimension-based hierarchical result model (DHRM) correctly handles intermediate factors with varying strengths across cases, resolving Bench-Capon's criticisms.

## Executive Summary
This paper defends hierarchical result models of precedential constraint against criticisms by Trevor Bench-Capon regarding their handling of intermediate factors. The authors argue that Bench-Capon's examples implicitly treat intermediate factors as dimensions, making van Woerkom's dimension-based hierarchical result model (DHRM) applicable. Through formal analysis of two family example cases (MaxMonday and EmmaMonday), the paper demonstrates that the DHRM can distinguish cases based on varying strengths of intermediate factors without violating precedential constraint, while the original hierarchical result model cannot. The key contribution is showing that when Bench-Capon's examples are reformulated using dimensions with partial orders, the DHRM provides a more flexible and appropriate framework for modeling precedential constraint.

## Method Summary
The paper employs formal logical analysis to compare the standard hierarchical result model (HRM) with the dimension-based hierarchical result model (DHRM). The authors use two case examples (MaxMonday and EmmaMonday) from Bench-Capon's work, reformulating them using dimensions rather than factors. They implement the recursive constraint checking algorithms defined in Definitions 2.3 (HRM) and 4.3 (DHRM), analyzing whether precedents force decisions in new cases. The analysis focuses on the ability to distinguish cases based on different strengths of intermediate factors, particularly examining how the DHRM handles numeric dimension values while the HRM cannot. The formal verification involves checking lower bounds on dimension values recursively through the hierarchy.

## Key Results
- The DHRM correctly distinguishes MaxMonday from EmmaMonday based on different strengths of intermediate factors
- When intermediate factors are modeled as dimensions with partial orders, the DHRM satisfies precedential constraint while HRM does not
- The DHRM enables case distinguishing via subordinate dimension bounds even when parent dimensions would otherwise force constraint
- DHRM provides a more flexible framework for modeling precedential constraint when intermediate factors have varying strengths across cases

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Constraint Propagation
- Claim: Precedential constraint propagates recursively through factor hierarchies, allowing decisions to constrain future cases at multiple abstraction levels.
- Mechanism: Given a factor hierarchy (P, H) with Pro and Con relations, a case base CB forces decision p for fact situation F when either F directly satisfies p, OR there exists a precedent G satisfying p where all Pro(p) factors in G are forced in F (recursively) and all Con(p) factors forced in F are satisfied in G. This creates a recursive "a fortiori" comparison at each hierarchy level.
- Core assumption: Factor hierarchies are well-founded (irreflexive transitive closure) with a unique maximal element (the outcome).
- Evidence anchors:
  - [abstract] "hierarchical case-based-reasoning models of precedential constraint"
  - [section] Definition 2.3: "CB, F |= p iff either F |= p; or p ∈ A and there exists a case G ∈ CB with G |= p such that 1. for all q ∈ Pro(p): if G |= q then CB, F |= q, and 2. for all q ∈ Con(p): if CB, F |= q then G |= q"
  - [corpus] Limited corpus relevance—neighbor papers address classifier models and argumentation frameworks but not hierarchical constraint specifically.
- Break condition: Constraint propagation fails when F lacks a required Pro factor present in the precedent, or when F has a Con factor absent from the precedent.

### Mechanism 2: Dimension-Based Strength Differentiation
- Claim: Replacing binary factors with ordered dimension values allows intermediate concepts to be established with varying strengths, resolving Bench-Capon's critique.
- Mechanism: Dimensions d have value sets with partial orders ⪯ where v ⪯ v' means v' is at least as good for π as v. Instead of F |= p (true/false), fact situations assign X(d) ∈ d. Constraint then requires comparing values: CB forces π if ∃ precedent Y with Y(d) ⪯ X(d) for all d. Intermediate dimensions (P, Q, R) can take integer values encoding how strongly base factors establish them.
- Core assumption: The partial order ⪯ correctly captures which dimension values favor which outcomes; values are comparable within dimensions.
- Evidence anchors:
  - [abstract] "intermediate factors are established with different strengths by different base-level factors"
  - [section] Section 5: "M: F1 = 1, F5 = 1, P = 2, Q = 2, R = 3, π = 1" vs "E: F2 = 1, F6 = 1, P = 3, Q = 3, R = ?, π = ?" showing numeric strength assignments
  - [corpus] Weak corpus support—neighbor paper on fuzzy numbers addresses imprecise values but not in precedential constraint context.
- Break condition: Fails if dimension values are incomparable under ⪯, or if the ordering doesn't match legal intuitions about strength.

### Mechanism 3: Case Distinguishing via Subordinate Dimension Bounds
- Claim: The DHRM enables distinguishing cases based on differences in subordinate dimension values even when parent dimensions would otherwise force constraint.
- Mechanism: Lower/upper bounds on dimension d for fact situation X are computed recursively: CB |= v ⪯ X(d) iff v ⪯ X(d) directly, OR d is abstract and ∃ precedent Y with v ⪯ Y(d) and CB |= Y(e) ⪯ X(e) for all subordinate dimensions e ∈ H(d). If any subordinate comparison fails, the bound fails, distinguishing the case.
- Core assumption: Subordinate dimensions fully determine parent dimension constraint; no independent parent-level constraint exists.
- Evidence anchors:
  - [section] Definition 4.3: "d ∈ A and there is Y ∈ CB satisfying v ⪯ Y(d) such that CB |= Y(e) ⪯ X(e) holds for all e ∈ H(d)"
  - [section] Section 5 analysis: "0 ⪯ 1 (as values in F6)... does not hold: 1 ⪯ 0 in F6 by definition, because interrupting the teacher is a con-π factor"
  - [corpus] No direct corpus support for this specific mechanism.
- Break condition: Distinguishing fails when all subordinate dimension comparisons succeed, meaning the bound holds and constraint applies.

## Foundational Learning

- Concept: **Factors vs. Dimensions in AI & Law**
  - Why needed here: The paper's core contribution depends on understanding that factors are binary (present/absent) while dimensions have ordered values encoding strength. Misunderstanding this leads to confusing HRM with DHRM.
  - Quick check question: If "financial need" can be weak, moderate, or severe, is it best modeled as a factor or dimension?

- Concept: **A Fortiori Reasoning / Precedential Constraint**
  - Why needed here: The entire framework formalizes "a fortiori" argument—if a precedent was decided for π given factors G, then a new case F with all of G's pro-π factors and none of G's con-π factors should also be decided for π. The hierarchical extension propagates this principle upward.
  - Quick check question: Precedent case G has factors {F1, F2} → outcome π. New case F has {F1, F2, F3}. Should F be forced to π?

- Concept: **Hierarchical Abstraction in Legal Concepts**
  - Why needed here: Legal reasoning often involves abstract concepts (e.g., "behavior at home") established by concrete facts (e.g., "folded clothes," "made bed"). The hierarchy (Figure 1) with Pro/Con relations formalizes this structure.
  - Quick check question: In Figure 1, what determines whether Q (behavior at home) supports π or δ?

## Architecture Onboarding

- Component map:
  - Factor/Dimension Hierarchy: Directed acyclic graph with Pro (+) and Con (−) relations, terminating in outcome node π. Base-level factors/dimensions (leaves) vs. abstract (internal nodes).
  - Case Base (CB): Set of decided cases, each a complete fact situation with outcome.
  - Constraint Engine: Implements Definitions 2.3 (HRM) or 4.3 (DHRM), recursively computing whether precedent forces decision.
  - Fact Situation: Partial function from factors/dimensions to truth values or ordered values.

- Critical path:
  1. Represent legal domain as factor or dimension hierarchy (define P, H, Pro, Con relations).
  2. Encode precedent cases as complete fact situations with outcomes.
  3. For new case F, compute constraint: for each potential outcome s, check if ∃ precedent (G, s) where HRM/DHRM conditions hold.
  4. If forced, decision is constrained; if not, case is distinguishable.

- Design tradeoffs:
  - **HRM (factors)**: Simpler, boolean logic; cannot express strength differences. Fails when intermediate factors need varying strength (Bench-Capon's critique).
  - **DHRM (dimensions)**: More expressive, handles strength; requires defining partial orders per dimension. More complex implementation.
  - **Including vs. omitting intermediate factors in cases**: Including them constrains future cases at abstract level; omitting them allows more distinguishing but less guidance.

- Failure signatures:
  - **HRM failure mode**: Two cases with same intermediate factor presence but different strengths produce unintuitive constraint (e.g., MaxMonday should not force EmmaMonday outcome, but HRM may not distinguish).
  - **DHRM failure mode**: Incorrect partial order definitions cause wrong constraint direction; incomparable values block constraint propagation.
  - **Hierarchy design failure**: Circular dependencies (irreflexivity violation) or multiple maximal elements invalidate formal properties.

- First 3 experiments:
  1. **Reproduce MaxMonday/EmmaMonday analysis**: Implement HRM and DHRM; verify HRM doesn't distinguish the cases as expected while DHRM does (F6 > F5 breaks the bound on R).
  2. **Vary dimension value orderings**: Test whether reversing the order on a dimension (e.g., making higher values favor δ instead of π) produces correct constraint reversal.
  3. **Scale to multi-precedent case base**: Add multiple precedents and verify constraint accumulates correctly (union of bounds from all relevant precedents).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can Bench-Capon's criticisms regarding intermediate factors be resolved for the hierarchical *reason* model of precedential constraint using a dimension-based approach similar to the DHRM?
- Basis in paper: [explicit] The conclusion states, "In future work it would be interesting to investigate whether Bench-Capon’s criticism can for [7]’s hierarchical reason model of precedential constraint be met in similar ways as for the result model."
- Why unresolved: A dimension-based version of the hierarchical reason model does not currently exist, so the defense used for the result model in this paper cannot yet be applied to the reason model.
- What evidence would resolve it: The formulation of a dimension-based hierarchical reason model and a formal analysis demonstrating that it handles the varying strengths of intermediate factors without violating precedential constraint.

### Open Question 2
- Question: Does the Dimension-based Hierarchical Result Model (DHRM) accurately reflect the practices of existing common-law systems?
- Basis in paper: [explicit] The authors state in the conclusion, "Whether the DHRM correctly models existing common law is beyond our expertise but we believe that it is correct as a model of rational case-based decision-making..."
- Why unresolved: The paper validates the model's logical coherence and rationality using hypothetical examples, but it does not provide an empirical analysis of actual legal cases to verify the fit.
- What evidence would resolve it: Empirical studies applying the DHRM to real-world case law data to verify if it correctly predicts judicial reasoning regarding intermediate concepts.

### Open Question 3
- Question: Is the requirement to define "cut-off points" for dimension values a significant practical barrier to adopting dimension-based models over factor-based models in legal AI?
- Basis in paper: [inferred] The conclusion notes that Bench-Capon favors transforming dimensions to factors, but the authors counter that "cut-off points are in practice not always easy to identify."
- Why unresolved: The paper argues for the theoretical utility of dimensions but does not address the practical difficulty of mapping real-world legal facts to precise dimension values without relying on arbitrary thresholds.
- What evidence would resolve it: A comparative implementation study in a complex legal domain (e.g., trade secrets) showing whether continuous dimensions provide a more robust modeling environment than boolean factors despite the difficulty of defining strict cut-offs.

### Open Question 4
- Question: Is the hierarchical result model more effective than the hierarchical reason model for explaining decisions in data-driven machine learning systems?
- Basis in paper: [explicit] The authors focus on the result model, citing that "Van Woerkom has in [15,16] argued that the result model is better than the reason model suited for explaining the decisions of data-driven machine-learning systems."
- Why unresolved: The paper assumes this superiority to focus its defense on the result model, but does not experimentally demonstrate the comparative explanatory power of the result model over the reason model in an ML context.
- What evidence would resolve it: Experiments applying both hierarchical models to the outputs of legal prediction algorithms to compare the fidelity and interpretability of the resulting explanations.

## Limitations

- **Corpus relevance gap**: Neighbor papers (0.0 avg citations) don't directly validate hierarchical precedential constraint mechanisms, relying on theoretical construction rather than empirical legal precedent analysis.
- **Dimension ordering assumptions**: The paper assumes partial orders ⪯ are intuitive and correct but doesn't address how these are validated in practice, where incorrect orderings would break constraint propagation.
- **Hierarchy design complexity**: The framework requires well-founded hierarchies with unique maximal elements, but real legal domains may have multiple outcomes or circular dependencies that violate these assumptions.

## Confidence

- **High confidence**: The formal definitions of HRM vs DHRM are internally consistent. The MaxMonday/EmmaMonday analysis correctly demonstrates DHRM's distinguishing capability.
- **Medium confidence**: The recursive constraint propagation mechanism is sound, but practical implementation complexity may limit adoption.
- **Low confidence**: Claims about DHRM being "more flexible and appropriate" for real legal reasoning lack empirical validation beyond the toy examples.

## Next Checks

1. **Cross-case generalization test**: Apply DHRM to 10+ diverse legal examples beyond family law to verify consistent distinguishing behavior across domains.
2. **User study with legal practitioners**: Test whether trained lawyers find DHRM-generated distinctions intuitive compared to HRM's flat-factor approach.
3. **Computational complexity analysis**: Measure runtime scaling as hierarchy depth and case base size increase to identify practical implementation limits.