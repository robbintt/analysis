---
ver: rpa2
title: 'Lost in Embeddings: Information Loss in Vision-Language Models'
arxiv_id: '2509.11986'
source_url: https://arxiv.org/abs/2509.11986
tags:
- loss
- image
- embeddings
- reconstruction
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper quantifies information loss in vision-language model
  (VLM) connectors by analyzing latent representation spaces. The authors introduce
  two complementary approaches: (1) k-nearest neighbors overlap ratio to measure geometric
  preservation before/after projection, and (2) patch-level embedding reconstruction
  to localize visual information loss.'
---

# Lost in Embeddings: Information Loss in Vision-Language Models

## Quick Facts
- **arXiv ID:** 2509.11986
- **Source URL:** https://arxiv.org/abs/2509.11986
- **Reference count:** 16
- **Primary result:** Connector modules in VLMs substantially distort local geometry (40-60% k-NN divergence) and information loss correlates with downstream task performance degradation.

## Executive Summary
This paper quantifies information loss in vision-language model connectors by analyzing latent representation spaces. The authors introduce two complementary approaches: (1) k-nearest neighbors overlap ratio to measure geometric preservation before/after projection, and (2) patch-level embedding reconstruction to localize visual information loss. Experiments across three connector-based VLMs (LLaVA, Idefics2, Qwen2.5-VL) on six datasets show that connectors substantially distort local geometry, with k-nearest neighbors diverging by 40-60% post-projection, correlating with retrieval performance degradation. Patch-level reconstruction reveals that areas of high information loss predict model failures in visually grounded question answering tasks.

## Method Summary
The study employs two complementary metrics to quantify information loss: k-nearest neighbors overlap ratio (KNOR) measures geometric distortion by comparing neighbor rankings before and after projection, while patch-level embedding reconstruction trains inverse models to map projected embeddings back to visual space, with reconstruction error serving as a proxy for information retention. The authors extract pre- and post-projection embeddings from three connector-based VLMs (LLaVA-MLP, Idefics2-Perceiver, Qwen2.5-VL-Patch Merger) and evaluate on multiple datasets including SEED-Bench, VQAv2, VizWiz, CUB-200-2011, Flickr30k, and COCO. Reconstruction models are trained on COCO 2017 train set using 3-layer MLPs for LLaVA and 16-layer transformers for compressing connectors, with correlation analysis against downstream task performance.

## Key Results
- Connectors distort local geometry significantly, with k-nearest neighbors diverging by 40-60% post-projection across all three VLMs tested
- Reconstruction loss correlates negatively with downstream performance (Spearman ~0.2 for Idefics2 captioning)
- Patch-level reconstruction loss successfully predicts VQA failures, with high-loss patches spatially aligned to answer regions
- LLaVA and Idefics2 show negative correlations between reconstruction loss and task performance, while Qwen2.5-VL's compression approach yields more semantically meaningful representations

## Why This Works (Mechanism)

### Mechanism 1: Geometric Distortion via Projection
The connector module in VLMs distorts the local geometric structure of visual embeddings, potentially degrading semantic retrieval. The projection function (Connector $C$) transforms visual features into the LLM embedding space, reshuffling neighbor rankings (k-NN), implying that relative similarities between images are altered. The pre-projection neighbor relationships (derived from the vision encoder) represent a "ground truth" semantic structure that should ideally be preserved for faithful representation.

### Mechanism 2: Reconstruction Loss as a Proxy for Information Retention
The error in reconstructing original visual embeddings from projected ones (Reconstruction Loss) serves as a quantitative proxy for the visual information accessible to the Language Model. By training an inverse model $f_\theta$ to map projected embeddings back to the original vision space, we measure how much "signal" survives the connector bottleneck. High Mean Squared Error (MSE) suggests the connector has discarded fine-grained features.

### Mechanism 3: Localized Loss Predicts Reasoning Failure
Information loss is spatially variant; high reconstruction loss in task-relevant image patches predicts failure in Visual Question Answering (VQA). Connectors often compress or pool features. If specific patches containing critical details (e.g., small text or specific objects) are poorly projected (high $L_{patch}$), the LLM effectively "hallucinates" or fails because the visual grounding is missing.

## Foundational Learning

- **Concept: k-Nearest Neighbors (k-NN) in Latent Space**
  - **Why needed here:** This is the primary metric (KNOR) used to detect geometric distortion. You must understand that if $Image_A$ is closest to $Image_B$ before projection but not after, the "meaning" of the embedding has shifted.
  - **Quick check question:** If the k-NN overlap ratio is 1.0, does it mean the connector is an identity function, or just that distances are preserved?

- **Concept: Autoencoders & Reconstruction**
  - **Why needed here:** The paper uses a "reconstruction model" to define information loss. This is effectively training a decoder to reverse the connector. Understanding the bottleneck concept is key.
  - **Quick check question:** Why does the paper use a larger model for reconstruction than the original connector? (To ensure the bottleneck is the connector, not the reconstructor).

- **Concept: Vision-Language Connectors (Projectors)**
  - **Why needed here:** You need to distinguish between "Feature-preserving" (e.g., MLP in LLaVA) and "Feature-compressing" (e.g., Perceiver in Idefics2) architectures to interpret the results.
  - **Quick check question:** Which type of connector would theoretically suffer more from "spatial" information loss?

## Architecture Onboarding

- **Component map:** Image $x$ -> Vision Encoder ($\psi$) -> Pre-projection embeddings -> Connector ($C$) -> Post-projection embeddings -> LLM
- **Critical path:**
  1. Hook into the VLM to extract embeddings immediately **before** and **after** the connector
  2. Compute k-NN overlap (KNOR) between these two sets of embeddings across a dataset
  3. Train the reconstructor $f_\theta$ using the post-projection embeddings as input and pre-projection embeddings as targets

- **Design tradeoffs:**
  - **LLaVA (MLP):** Preserves sequence length (576 patches → 576 patches). Lower reconstruction loss, but potentially noisier context for LLM
  - **Idefics2 (Perceiver):** Compresses sequence (576 → 64). Higher compression likely causes higher spatial loss but creates a shorter context for the LLM to attend to
  - **Qwen (Patch Merger):** Compresses (4:1 merge). Shows that compression *can* improve semantics if trained well, breaking the correlation between reconstruction loss and simple retrieval

- **Failure signatures:**
  - **Global:** Low KNOR (<0.5) combined with a drop in retrieval Recall@5
  - **Local:** High MSE ($L_{patch}$) in specific spatial regions corresponding to the "ground truth" answer mask in VQA datasets

- **First 3 experiments:**
  1. **Validation of Codebase:** Reproduce the KNOR statistic for LLaVA on a small subset (e.g., 1k images from COCO) to verify the 40-60% divergence claim
  2. **Capacity Test:** Train a small MLP reconstructor for LLaVA. Plot reconstruction loss vs. CIDEr score for 100 images to see if the negative correlation holds locally
  3. **Visualization:** Run an inference on a VizWiz "failure" case and overlay the patch-wise reconstruction loss heatmap to verify if it highlights the object the model failed to recognize

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can reconstruction loss be effectively incorporated as a regularization term during the pretraining of vision-language models to mitigate information loss?
- **Basis in paper:** [explicit] The authors state in the conclusion that "the reconstruction loss at the embedding level could potentially be incorporated during model pretraining as regularization."
- **Why unresolved:** The current study quantifies loss in already-trained models using post-hoc reconstruction; it does not validate if optimizing for this metric during training improves downstream task performance.
- **What evidence would resolve it:** Training new VLM variants with an auxiliary reconstruction loss objective and demonstrating improved performance on visually-grounded tasks (e.g., VizWiz VQA).

### Open Question 2
- **Question:** Does the measured information loss result from the connector's inherent compression or the reconstruction model's inability to learn the inverse mapping?
- **Basis in paper:** [explicit] The limitations section notes the authors "cannot conclusively determine whether the observed information loss stems from the connector layer itself or from potential learning limitations of the trained reconstruction network."
- **Why unresolved:** High reconstruction loss could imply the connector destroys information, or simply that the specific decoder architecture used ($f_\theta$) failed to recover it.
- **What evidence would resolve it:** Establishing theoretical bounds on recoverability or demonstrating that a sufficiently complex decoder can perfectly reconstruct connector outputs.

### Open Question 3
- **Question:** Do cross-attention-based architectures preserve visual information geometry better than the connector-based projection methods analyzed?
- **Basis in paper:** [explicit] The authors list as a limitation that findings "may not generalize to architectures that employ cross-attention for modality fusion," focusing only on connector-based models.
- **Why unresolved:** Cross-attention mechanisms integrate modalities differently than MLP or Perceiver connectors, potentially avoiding the geometric distortion observed in this study.
- **What evidence would resolve it:** Applying the k-nearest neighbors overlap ratio (KNOR) and patch-level reconstruction metrics to cross-attention models like BLIP or Llama 3.2.

## Limitations
- The analysis assumes pre-projection embeddings represent "ground truth" semantic structure, which may not hold if vision encoders produce noisy representations
- KNOR calculations use mean pooling, potentially obscuring spatial information patterns that could be important for understanding information loss
- Correlation between reconstruction loss and downstream tasks shows moderate effect sizes (Spearman ~0.2), suggesting other factors beyond geometric distortion influence performance

## Confidence
- **High confidence:** KNOR methodology and geometric distortion findings (40-60% divergence is robustly measured with FAISS-based k-NN overlap)
- **Medium confidence:** Correlation between reconstruction loss and task performance (moderate effect sizes, but consistent across models and tasks)
- **Medium confidence:** Localized loss predicting reasoning failures (visual patterns are interpretable but require careful spatial alignment)

## Next Checks
1. **Ablation Study:** Test KNOR sensitivity to pooling strategies (mean vs max vs attention pooling) on a subset of images to determine if spatial information is being lost in aggregation
2. **Reconstruction Capacity:** Train reconstruction models with varying capacity (from simple MLP to full-size transformer) to establish whether observed loss stems from connector or reconstructor limitations
3. **Temporal Stability:** Evaluate whether information loss patterns persist across different model checkpoints or training iterations of the same VLM architecture