---
ver: rpa2
title: "Hacia la interpretabilidad de la detecci\xF3n anticipada de riesgos de depresi\xF3\
  n utilizando grandes modelos de lenguaje"
arxiv_id: '2503.20939'
source_url: https://arxiv.org/abs/2503.20939
tags:
- para
- modelo
- como
- depresi
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for interpretable early detection
  of depression risks using Large Language Models (LLMs) on Spanish texts. The approach
  involves a reasoning criterion defined by a specialist using the Beck Depression
  Inventory (BDI) symptoms, combined with in-context learning applied to the Gemini
  model.
---

# Hacia la interpretabilidad de la detección anticipada de riesgos de depresión utilizando grandes modelos de lenguaje

## Quick Facts
- arXiv ID: 2503.20939
- Source URL: https://arxiv.org/abs/2503.20939
- Authors: Horacio Thompson; Maximiliano Sapino; Edgardo Ferretti; Marcelo Errecalde
- Reference count: 0
- Primary result: Achieves 84% F1 score and 0.84 F-latency on Spanish depression risk detection with interpretable reasoning traces

## Executive Summary
This paper presents a method for interpretable early detection of depression risks using Large Language Models (LLMs) on Spanish texts. The approach involves a reasoning criterion defined by a specialist using the Beck Depression Inventory (BDI) symptoms, combined with in-context learning applied to the Gemini model. The system generates predictions supported by explanatory reasoning, allowing for a deeper understanding of the solution. Experiments on the MentalRiskES 2023 dataset show superior performance compared to state-of-the-art methods, achieving 84% F1 score, 0.84 F-latency, and outperforming competitors in accuracy, precision, recall, ERDE5, and ERDE30 metrics.

## Method Summary
The method uses in-context learning with Gemini-Pro to detect depression risks through structured reasoning traces based on BDI criteria. The approach constructs prompts with expert-defined reasoning chains linking observations to clinical symptoms, then applies few-shot examples to condition the model. The system processes user posts sequentially, identifying the specific post where evidence is sufficient to trigger an alarm, optimizing for early detection while maintaining accuracy.

## Key Results
- Achieves 84% F1 score and 0.84 F-latency on the MentalRiskES 2023 test set
- Outperforms state-of-the-art methods in accuracy, precision, recall, ERDE5, and ERDE30 metrics
- Demonstrates interpretable predictions through BDI-aligned reasoning traces
- Successfully detects depression risks in Spanish social media text with early warning capability

## Why This Works (Mechanism)

### Mechanism 1
In-context learning with expert-defined reasoning traces elicits domain-specific diagnostic behavior from general-purpose LLMs without weight updates. The method constructs a prompt containing structured reasoning paths derived from BDI criteria, conditioning the LLM to generate outputs that mimic specialist logic rather than generic pattern matching.

### Mechanism 2
Sequential analysis of user posts with explicit "verification" and "post detection" steps reduces detection latency. The prompt forces the model to identify the specific post number where evidence is sufficient, optimizing the trade-off between early alarm and accuracy.

### Mechanism 3
Constraining model generation with low temperature (0.2) and specific output schemas improves reliability of structured diagnostic reasoning. This configuration narrows the probability distribution, forcing the model to select high-confidence tokens that align with the strict output format.

## Foundational Learning

- **In-Context Learning (ICL) / Few-Shot Prompting**: Critical for adapting the Gemini model to depression detection without fine-tuning. Understanding how demonstration examples shape the model's attention and output distribution is essential. *Quick check: Can you explain why prepending expert reasoning traces might improve performance better than simply prepending input-output pairs?*

- **Early Risk Detection Error (ERDE) & F-latency**: Standard F1 score is insufficient here. These metrics penalize late correct predictions heavily. *Quick check: Why would a model with 90% accuracy but requiring 100 posts to make a decision be considered a failure in EDR context?*

- **Beck Depression Inventory (BDI)**: The "interpretable" component is explicitly grounded in BDI symptoms (e.g., sadness, pessimism, suicidal ideation). *Quick check: If the model generates a valid reasoning trace that does not map to a BDI symptom, should it be considered valid explanation in this architecture?*

## Architecture Onboarding

- **Component map**: Input Layer (Raw User Posts) -> Preprocessing/Reasoning Infusion (Specialist Analysis -> BDI Criteria) -> Prompt Engineering (Role + Task + Few-Shot) -> Inference Engine (Gemini-Pro, Temp=0.2) -> Output Parser (Prediction + Post Number)

- **Critical path**: The quality of the Specialist's Reasoning Samples. The entire system's "interpretability" and accuracy rely on the few-shot examples containing high-quality, BDI-aligned logic.

- **Design tradeoffs**: 
  - Determinism vs. Nuance: Low temperature ensures consistent formatting but may miss nuanced expressions
  - Interpretability vs. Automation: Provides reasons (valuable for clinicians) but requires more verbose generation
  - Context Window vs. User History: 32k token limit restricts how much history can be analyzed in single inference

- **Failure signatures**:
  - Hallucinated Symptoms: Model cites BDI symptoms not present in text (False Positives)
  - Retrospective Confusion: Fails to distinguish past vs. current depression
  - Third-Party Attribution: Misattributes depression to user when describing others (False Positive)

- **First 3 experiments**:
  1. Baseline Validation: Run Gemini configuration on MentalRiskES test set to reproduce reported metrics
  2. Ablation on Reasoning: Remove Observations/Conclusions from few-shot examples to measure performance drop
  3. Robustness Check (Temperature): Incrementally increase temperature to observe degradation of structured output

## Open Questions the Paper Calls Out
None

## Limitations
- The quality of the method depends heavily on the expert-annotated reasoning samples, which are not disclosed
- The MentalRiskES 2023 dataset is restricted, preventing independent validation
- Low temperature configuration may suppress nuanced, subtle expressions of depression

## Confidence

- **High Confidence**: Technical feasibility of in-context learning for structured reasoning output
- **Medium Confidence**: Superiority over prior Spanish-language depression detection baselines
- **Low Confidence**: True clinical interpretability of the model's reasoning

## Next Checks

1. **Few-Shot Ablation Study**: Remove structured reasoning traces from few-shot examples and compare performance drop in F1 and ERDE

2. **Clinical Expert Review**: Have a licensed psychologist review model's reasoning traces on held-out data for clinical validity

3. **Zero-Shot Prompting Comparison**: Run task with only task definition and BDI criteria (no few-shot examples) to isolate impact of in-context learning