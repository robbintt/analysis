---
ver: rpa2
title: Continual Learning Should Move Beyond Incremental Classification
arxiv_id: '2502.11927'
source_url: https://arxiv.org/abs/2502.11927
tags:
- learning
- task
- continual
- classification
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that continual learning (CL) research should expand
  beyond incremental classification to address more complex real-world scenarios.
  Through examples including multi-target classification, robotics with output constraints,
  continuous task domains, and abstract concept memorization, the authors demonstrate
  limitations of current CL approaches.
---

# Continual Learning Should Move Beyond Incremental Classification

## Quick Facts
- arXiv ID: 2502.11927
- Source URL: https://arxiv.org/abs/2502.11927
- Reference count: 14
- Key outcome: Paper argues CL research should expand beyond incremental classification to address complex real-world scenarios like continuous task domains, constrained robotics, and abstract concept memorization.

## Executive Summary
This paper challenges the current focus of continual learning (CL) research on incremental classification problems, arguing that this narrow scope limits CL's applicability to real-world scenarios. Through four example domains—multi-target classification, constrained robotics, continuous task domains, and abstract concept memorization—the authors demonstrate fundamental limitations of existing CL approaches. They identify three key challenges: handling continuous learning problems, selecting appropriate similarity metrics for non-standard problems, and incorporating learning objectives beyond classification. The paper advocates for expanding CL's theoretical foundations to make it more applicable to practical problems while maintaining rigorous methodology.

## Method Summary
The paper provides a conceptual analysis of continual learning limitations through theoretical examples and recommendations rather than implementing new algorithms. It critiques existing methods (iCaRL, EWC, Knowledge Distillation, Coresets) by demonstrating their failures in non-standard scenarios. The authors propose three mechanisms for addressing these limitations: distribution processes for modeling temporal drift, principled metric selection across parameter/data/function spaces, and integration of generative and density-based objectives. No new algorithm is proposed; instead, the paper offers recommendations for formalizing temporal dynamics, developing approaches for continuous task spaces, and expanding learning objectives beyond classification.

## Key Results
- CL methods face cluster explosion when applied to multi-target classification (2^12 = 4096 clusters for 12 binary targets)
- Parameter-space regularization like EWC violates manifold constraints on outputs in robotics tasks
- Continuous task domains expose the inadequacy of discrete task boundary assumptions in current CL approaches
- Abstract concept memorization challenges reveal limitations of concrete example-based memory methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distribution processes provide a principled formalism for capturing temporal drift in continual learning streams.
- Mechanism: Rather than assigning per-datapoint distributions Di, associate each xi with a time ti such that distributions Dt are Markov kernels in the time domain. This makes temporal correlations explicit and enables limiting statements about mean distributions over time periods.
- Core assumption: Temporally close distributions are more similar than distant ones; this correlation structure is learnable and exploitable.
- Evidence anchors:
  - [Section 3.1]: "We advocate here for the approach of Hinder et al. (2020), who propose a Distribution Process to capture this drift by associating each datapoint xi with a time ti, such that two datapoints sharing a time also share the same distribution."
  - [Corpus]: Weak direct evidence—neighbor papers focus on task ordering and replay rather than distribution process formalisms.
- Break condition: When data presentation schedules have no temporal correlation (i.i.d. streams), or when task boundaries are sharp discrete shifts without smooth transitions.

### Mechanism 2
- Claim: Selecting the appropriate space and metric for similarity measurement is critical for CL method success in non-standard problems.
- Mechanism: Distance can be measured in parameter space (Euclidean, Fisher-weighted), data space (raw features, latent representations), or function space (KL divergence between output distributions). The choice determines what "close" means for regularization and memory selection.
- Core assumption: The metric captures task-relevant similarity; Euclidean distance in the wrong space (e.g., joint angles vs end-effector pose) will not preserve functional equivalence.
- Evidence anchors:
  - [Section 2.2]: "If one were to naively apply a parameter-space regularization method, such as EWC... even if the predictions at θ*t obey the manifold constraints, the predictions of some arbitrary θ which is merely close to θ*t according to the Fisher matrix will not."
  - [Section 3.2]: "Sometimes there will be a natural choice (e.g., the Fisher metric in function space for classification tasks)... In an application such as weight space regularization, there is a simple choice of the Euclidean metric, but this choice is inherently incapable of identifying more or less important parameters."
  - [Corpus]: Tangential support—neighbor papers on adversarial transferability in CL (arXiv:2508.08920) implicitly rely on metric choices but don't analyze them.
- Break condition: When the chosen metric doesn't reflect the true loss surface geometry (e.g., using Euclidean distance on a Riemannian manifold).

### Mechanism 3
- Claim: Generative and density-based objectives provide complementary benefits for forgetting mitigation and task identification that classification objectives alone cannot.
- Mechanism: Generative models enable synthetic replay without storing raw data; density estimation enables principled OOD detection and task boundary identification via likelihood thresholds.
- Core assumption: Generative models can be trained continually without suffering their own catastrophic forgetting; density estimates are calibrated enough for threshold decisions.
- Evidence anchors:
  - [Section 3.3]: "Where the base task incorporates a generative objective, many challenges related to regularizing on or reviewing data examples from previous tasks are greatly simplified by direct exploitation of this generative function."
  - [Corpus]: Moderate support—CCD paper (arXiv:2505.11936) addresses "Generative Catastrophic Forgetting" in diffusion models, confirming this is non-trivial.
- Break condition: When generative models themselves suffer severe forgetting, or when density estimates are unreliable in high-dimensional spaces.

## Foundational Learning

- **Catastrophic Forgetting**
  - Why needed here: The paper assumes familiarity with why standard gradient descent overwrites previous task knowledge. Without this, the motivation for regularization, replay, and architectural approaches is unclear.
  - Quick check question: Can you explain why training on task B degrades performance on task A, even with identical architecture?

- **KL Divergence Asymmetry**
  - Why needed here: Section 3.2 emphasizes that "distance" measures in CL often correspond to asymmetric KL divergences. Understanding why DKL(P||Q) ≠ DKL(Q||P) is essential for choosing the correct direction in task identification and regularization.
  - Quick check question: If a memory buffer contains data from tasks A and B, but new data comes only from B, should the "distance" between buffer and new data be small or large?

- **Manifold Geometry Basics**
  - Why needed here: The robotics examples (Section 2.2) involve outputs constrained to nonlinear manifolds (e.g., sphere surfaces). Understanding that Euclidean distance doesn't respect manifold structure is prerequisite for the metric selection discussion.
  - Quick check question: Why is the shortest path between two points on a sphere not a straight line in 3D space?

## Architecture Onboarding

- **Component map**: Space selector -> Metric module -> Continuity handler -> Objective combiner
- **Critical path**: 1. Identify if outputs have geometric constraints → determines metric choice 2. Determine if task space is discrete or continuous → determines continuity handler 3. Assess whether classification-only objectives suffice → determines if generative/density components needed
- **Design tradeoffs**:
  - Discrete task labels vs continuous task inference: Discrete enables task-specific components but fails when boundaries don't exist
  - Parameter-space vs function-space regularization: Parameter-space is simpler but may violate output constraints; function-space respects outputs but requires careful metric selection
  - Replay buffer vs generative replay: Buffers are simple but scale poorly; generative replay avoids storage but introduces its own forgetting problem
- **Failure signatures**:
  - Constraint violations after updates (robotics): Indicates metric doesn't respect manifold geometry
  - Exponential cluster explosion (multi-target): Indicates naive discretization of inherently continuous label spaces
  - Inability to distinguish new vs old data (continuous domains): Indicates task identification relies on discrete boundaries that don't exist
  - Strategic concepts not retained despite buffer (RL): Indicates memory stores concretes rather than abstractions
- **First 3 experiments**:
  1. **Metric ablation on constrained outputs**: Take a simple robotics task (e.g., trajectory on sphere surface from Section 2.2). Compare Euclidean vs Fisher vs geodesic distance for regularization. Measure constraint violation rate.
  2. **Multi-target classification scaling**: Implement iCaRL-style buffer selection on a multi-target problem. Vary number of targets and measure buffer size explosion. Confirm combinatorial scaling predicted in Section 2.1.
  3. **Continuous task boundary detection**: Create a synthetic stream where task parameters drift continuously (e.g., varying weight distributions from Section 2.3). Test whether KL-based detection identifies meaningful boundaries vs arbitrary thresholds.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can continual learning systems handle task identity in truly continuous task spaces where no discrete task labels can be coherently assigned?
- Basis in paper: [explicit] The authors state: "principled methods of handling task identity in the truly continuous case... should be developed. Task-specific components, for example, should still be possible where task identity is not discrete."
- Why unresolved: Existing task-free CL methods still assume discrete underlying task sets; continuous task spaces introduce non-trivial geometry that current task-specific component approaches cannot handle.
- What evidence would resolve it: A principled framework for task identification and task-specific component selection that operates on continuous task embeddings, with demonstrations on problems like the box-pushing scenario described.

### Open Question 2
- Question: How can continual learning systems retain abstract strategic knowledge (e.g., the mere possibility of a strategy) rather than only concrete input-output pairs?
- Basis in paper: [explicit] The authors ask: "The mere possibility of a zergling rush, even if rarely executed, deeply shapes the game. Humans remember this strategic principle—how can we capture this sort of abstract knowledge in CL systems?"
- Why unresolved: Coreset and prototype-based memory methods depend on storing concrete examples that contribute meaningfully to gradients, but abstract concepts may have sparse concrete instantiations with low gradient contribution.
- What evidence would resolve it: Memory architectures that successfully retain strategic possibilities with few or no concrete examples, evaluated on tasks where remembering counterfactual strategies improves performance.

### Open Question 3
- Question: How should similarity metrics be chosen and applied asymmetrically when measuring distances between tasks in continual learning?
- Basis in paper: [explicit] The authors note: "One should also pay attention to any asymmetries in the application of a notion of distance... Whether you would like your distance measure to behave like forward KL divergence or reverse KL divergence depends on the purpose."
- Why unresolved: Asymmetries in KL divergence and related distance measures become most salient when tasks are dissimilar, but most CL evaluations use similar tasks where both directions agree, masking the problem.
- What evidence would resolve it: Systematic comparison of forward vs. reverse KL-based task similarity measures across tasks with varying dissimilarity, showing when each direction is appropriate.

### Open Question 4
- Question: Can parameter-space regularization methods like EWC be modified to maintain manifold constraints on outputs throughout continual learning?
- Basis in paper: [inferred] The paper demonstrates that naively applying EWC to constrained output spaces (e.g., robot trajectories on a sphere) will violate constraints since proximity in Fisher-weighted parameter space does not guarantee constraint satisfaction.
- Why unresolved: Current regularization methods assume Euclidean output spaces; the relationship between parameter-space proximity and constraint satisfaction on manifolds is poorly understood.
- What evidence would resolve it: Modified regularization methods that provably maintain manifold constraints while preventing catastrophic forgetting, validated on robotics tasks with safety-critical output constraints.

## Limitations
- Paper provides conceptual analysis without empirical validation or quantitative results
- No specific datasets, hyperparameters, or implementation details provided for any example domain
- Recommendations are theoretical and lack systematic comparison against existing methods
- Open questions remain largely unresolved with no proposed concrete solutions

## Confidence
- Distribution process formalism: Low - relies on assumptions about temporal correlation structure without validation
- Metric selection recommendations: Low - doesn't provide principled criteria for choosing between parameter, data, or function space
- Generative objective proposals: Low - acknowledges but doesn't resolve fundamental challenge of continual generative model training

## Next Checks
1. Implement the robotics manifold constraint experiment to verify that Euclidean regularization violates output constraints while Fisher-weighted or geodesic methods preserve them
2. Scale iCaRL cluster analysis to multi-target problems to confirm combinatorial explosion from 2^n label combinations
3. Test continuous task boundary detection on drifting distributions to validate whether distributional processes outperform discrete task assumptions