---
ver: rpa2
title: 'SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite
  and Drone Imagery with Fine-Tuning for Cross Domain Evaluation'
arxiv_id: '2508.00750'
source_url: https://arxiv.org/abs/2508.00750
tags:
- esrgan
- semantic
- uncertainty
- drone
- imagery
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SU-ESRGAN, a novel super-resolution framework
  that integrates semantic segmentation guidance and uncertainty quantification into
  the ESRGAN architecture. The method combines Monte Carlo dropout for pixel-wise
  uncertainty estimation with DeepLabv3 segmentation loss to preserve semantic consistency
  in satellite and drone imagery.
---

# SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation

## Quick Facts
- **arXiv ID:** 2508.00750
- **Source URL:** https://arxiv.org/abs/2508.00750
- **Reference count:** 17
- **Key outcome:** SU-ESRGAN integrates semantic segmentation guidance and Monte Carlo dropout uncertainty estimation into ESRGAN, achieving PSNR of 25.01 dB and SSIM of 0.696 on satellite datasets while producing uncertainty maps; cross-domain fine-tuning shows better adaptation to similar-altitude drone datasets (SSIM: 0.742) than mismatched domains (SSIM: 0.637).

## Executive Summary
This paper presents SU-ESRGAN, a novel super-resolution framework that integrates semantic segmentation guidance and uncertainty quantification into the ESRGAN architecture. The method combines Monte Carlo dropout for pixel-wise uncertainty estimation with DeepLabv3 segmentation loss to preserve semantic consistency in satellite and drone imagery. Trained on UCMerizona and AID datasets, SU-ESRGAN achieves PSNR of 25.01 dB and SSIM of 0.696, with perceptual quality comparable to the baseline ESRGAN. The model produces uncertainty maps that highlight areas of low confidence, particularly in fine detail regions. Cross-domain fine-tuning on drone datasets reveals domain adaptation challenges, with better performance on the Aerial Maritime Drone Dataset (SSIM: 0.742, LPIPS: 0.1769) compared to UAVid. The results demonstrate that semantic guidance can shift outputs toward perceptual fidelity at the expense of sharpness, and emphasize the importance of domain-aware training for remote sensing applications.

## Method Summary
SU-ESRGAN modifies the ESRGAN architecture by adding Monte Carlo dropout (p=0.2) after the initial convolution layer for uncertainty estimation, and incorporating a semantic segmentation loss using DeepLabv3 features. During inference, T=20 forward passes generate stochastic predictions, with pixel-wise mean and standard deviation producing the final output and uncertainty map. The semantic loss (Lsem) computes L1 distance between arg-max class indices from DeepLabv3 features of SR output and HR ground truth. The model is trained on satellite datasets (UCMerizona, AID) then fine-tuned on drone datasets with reduced learning rate (1×10⁻⁵) for cross-domain evaluation.

## Key Results
- SU-ESRGAN achieves PSNR of 25.01 dB and SSIM of 0.696 on satellite test sets
- Uncertainty maps highlight low-confidence regions, particularly in fine detail areas
- Cross-domain fine-tuning shows SSIM of 0.742 on Aerial Maritime Drone Dataset vs 0.637 on UAVid
- Integration of segmentation loss shifts outputs toward perceptual fidelity at the expense of sharpness
- UAVid fine-tuning results in FID of 3.750, suggesting mode collapse despite lower FID value

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Monte Carlo dropout enables pixel-wise uncertainty estimation without architectural changes to the generator.
- **Mechanism:** Dropout layers (p=0.2) are kept active during inference. T=20 stochastic forward passes produce different SR predictions per pass. Per-pixel mean (μ) becomes the final output; per-pixel standard deviation (σ) becomes the uncertainty map. High σ indicates regions where the model produces inconsistent predictions across passes.
- **Core assumption:** Assumption: Dropout variance correlates with epistemic uncertainty in SR reconstruction. This requires that dropout samples approximate a Bayesian posterior distribution.
- **Evidence anchors:**
  - [abstract]: "utilizes Monte Carlo Dropout at test time for the production of pixel-wise uncertainty estimation"
  - [section III.C]: "T = 20 stochastic forward passes over the network are made via the uncertainty estimation procedure, producing T distinct super-resolved predictions"
  - [corpus]: Weak direct evidence. Related paper [13] (Adapa et al.) applies MC dropout to ESRGAN for uncertainty, but corpus neighbors focus on other SR approaches (diffusion models, flow matching) rather than uncertainty quantification validation.
- **Break condition:** If σ values do not correlate with actual reconstruction error or subjective quality degradation in low-confidence regions, the uncertainty maps lose practical utility for downstream decision-making.

### Mechanism 2
- **Claim:** Semantic segmentation loss preserves class-level consistency at the cost of perceptual sharpness.
- **Mechanism:** DeepLabv3 extracts semantic features from both SR output and HR ground truth. The semantic loss (Lsem) computes average L1 distance between arg-max class indices at each pixel. Minimizing this loss constrains the generator to produce outputs where class boundaries match the reference, reducing hallucinated textures that would alter semantic class assignments.
- **Core assumption:** Assumption: DeepLabv3's segmentation predictions on SR images meaningfully correlate with human-perceived class structure, and class-preserving regularization does not interfere with texture synthesis excessively.
- **Evidence anchors:**
  - [abstract]: "segmentation loss via DeepLabv3 for class detail preservation"
  - [section V]: "SU-ESRGAN consistently produced visually blurrier results... the integration of segmentation loss has shifted the model's outputs towards prioritizing fidelity over the sharp, hallucinated details"
  - [corpus]: Related work SSG-RWSR [12] validates semantic guidance in SR, though in a different domain. No direct corpus validation for DeepLabv3-specific loss in remote sensing SR.
- **Break condition:** If blurrier outputs degrade downstream task performance (e.g., object detection accuracy) more than baseline hallucinations, the semantic guidance trade-off becomes counterproductive.

### Mechanism 3
- **Claim:** Cross-domain performance depends on imaging characteristic alignment between source training and target deployment data.
- **Mechanism:** Model trained on nadir satellite imagery (UCMerced, AID) is fine-tuned on drone datasets with different altitudes and viewing angles. Domain-similar target (Aerial Maritime: lower altitude, similar oblique characteristics) shows better adaptation (SSIM 0.742) than domain-dissimilar target (UAVid: higher altitude, oblique perspective, SSIM 0.637). Fine-tuning uses reduced learning rate (1×10⁻⁵) and short schedules.
- **Core assumption:** Assumption: The observed performance gaps are primarily due to domain shift rather than dataset size or fine-tuning hyperparameters. The FID anomaly (3.750 for UAVid suggesting mode collapse) indicates training dynamics, not just domain mismatch.
- **Evidence anchors:**
  - [abstract]: "Performance evaluation of the fine-tuned models show a stronger adaptation to the Aerial Maritime Drone Dataset, whose imaging characteristics align with the training data"
  - [section V]: "Fine-tuning on the domain mismatched, UAVid dataset results in lower PSNR/SSIM and an unusually low FID of 3.750 suggesting mode collapse"
  - [corpus]: Tang et al. [14] documents resolution/angle disparities in satellite-to-drone transfer. UAS-guided SR paper (corpus neighbor) similarly addresses multi-platform resolution gaps but with different methodology.
- **Break condition:** If fine-tuning hyperparameters (learning rate, epochs, early stopping) are not properly tuned per target domain, observed gaps may reflect optimization failure rather than fundamental domain incompatibility.

## Foundational Learning

- **Concept:** Monte Carlo Dropout as Bayesian Approximation
  - **Why needed here:** Understanding why test-time dropout produces meaningful uncertainty requires grasping that dropout samples approximate posterior distributions. Without this, the uncertainty maps appear arbitrary.
  - **Quick check question:** Why must dropout remain active during inference for uncertainty estimation, when standard practice disables it?

- **Concept:** Perceptual-Distortion Trade-off in GAN-based SR
  - **Why needed here:** The paper explicitly trades sharpness for semantic fidelity. Understanding that GAN losses encourage realistic textures while pixel-losses encourage accuracy explains why semantic guidance produces blurrier outputs.
  - **Quick check question:** Why does adding semantic loss reduce hallucinated details but also reduce sharpness?

- **Concept:** FID Interpretation and Mode Collapse Detection
  - **Why needed here:** The UAVid FID of 3.750 vs baseline 68.617 signals mode collapse, not superior generation. Misinterpreting low FID could lead to false conclusions about model quality.
  - **Quick check question:** A lower FID typically indicates better image quality. Why did the lowest FID in this study (3.750) correspond to the worst-performing model?

## Architecture Onboarding

- **Component map:**
  Input (LR, 3ch, 64×64) → Conv → 64 feature maps → Dropout (p=0.2) → 5× RRDB blocks → Conv (3×3) → 64 ch → Skip-add to dropped features → Upsampling Stage 1: Conv → 256 ch → PixelShuffle(×2) → LeakyReLU → Upsampling Stage 2: Conv → 256 ch → PixelShuffle(×2) → LeakyReLU → Conv → 3 ch (SR output, 256×256) → [Branch to DeepLabv3 for Lsem] | [Branch to Discriminator] | [T×forward passes for uncertainty]

- **Critical path:** The dropout placement immediately after the initial convolution is critical—it injects stochasticity before detail extraction in RRDBs. Moving dropout deeper would reduce uncertainty variance; removing it eliminates uncertainty estimation entirely. The skip connection from dropped features to post-RRDB output must preserve spatial alignment.

- **Design tradeoffs:**
  - Semantic loss weight vs sharpness: Higher semantic loss weighting improves class preservation but increases blur (PSNR dropped from 25.99 to 25.01).
  - T (forward passes) vs inference speed: T=20 provides uncertainty; increasing T improves estimate stability but linearly increases inference time.
  - Fine-tuning learning rate vs stability: 1×10⁻⁵ prevents overfitting on small drone datasets but may under-adapt; higher rates risk catastrophic forgetting.

- **Failure signatures:**
  - FID < 10 with degraded SSIM/PSNR: Likely mode collapse (see UAVid: FID 3.750, SSIM 0.637).
  - Uncertainty maps uniformly dark (low σ): Dropout may be disabled, or model is overconfident due to insufficient training diversity.
  - Uncertainty maps uniformly bright: Training instability, or dropout rate too high for meaningful convergence.
  - SR outputs blurrier than expected: Semantic loss weight too high relative to adversarial/perceptual losses.

- **First 3 experiments:**
  1. **Uncertainty calibration check:** On held-out test set, bin pixels by σ values and compute actual reconstruction error per bin. If high-σ bins don't show higher error, the uncertainty signal is not calibrated.
  2. **Semantic loss ablation:** Train three variants—(a) no semantic loss, (b) Lsem weight=0.1, (c) Lsem weight=0.5—and compare sharpness (via LPIPS) vs semantic consistency (via segmentation mIoU on SR outputs).
  3. **Domain gap quantification:** Before fine-tuning, compute feature distribution distance (e.g., CORAL or MMD) between source (AID) and each target dataset. Correlate this distance with fine-tuning performance gaps to validate domain alignment hypothesis.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the semantic guidance mechanism in SU-ESRGAN be modified to reduce the blurriness in generated outputs while still preserving semantic consistency and uncertainty estimation capabilities?
- Basis in paper: [explicit] The conclusion states: "Future work shall focus on improving SU-ESRGAN's design to mitigate blurriness in generated imagery."
- Why unresolved: The paper demonstrates that adding segmentation loss shifts outputs toward fidelity at the expense of sharpness, but does not investigate architectural or loss-function modifications to address this trade-off.
- What evidence would resolve it: Comparative experiments using adaptive loss weighting, alternative semantic loss formulations, or modified generator architectures that achieve higher perceptual sharpness (e.g., lower LPIPS) while maintaining semantic consistency scores.

### Open Question 2
- Question: What domain-aware adaptation strategies can effectively improve satellite-to-drone transfer performance, particularly for datasets with significant altitude and perspective differences like UAVid?
- Basis in paper: [explicit] The conclusion calls for "emphasis on domain aware adaptation strategies for drone applications" after showing poor adaptation to UAVid (PSNR: 23.78, suspected mode collapse with FID: 3.750).
- Why unresolved: The paper only uses simple fine-tuning with reduced learning rate, which fails for domain-mismatched data; no advanced adaptation techniques (e.g., feature alignment, progressive transfer) are explored.
- What evidence would resolve it: Systematic comparison of domain adaptation methods (e.g., adversarial domain adaptation, curriculum learning across altitude levels) showing improved PSNR/SSIM on UAVid without mode collapse symptoms.

### Open Question 3
- Question: How should FID be interpreted in super-resolution fine-tuning contexts, and what complementary evaluation protocols can distinguish between mode collapse and genuine distribution alignment?
- Basis in paper: [inferred] The paper notes that the unusually low FID of 3.750 on UAVid "suggest[s] mode collapse in generated images," contrasting with higher FID (154.153) on the better-performing Maritime dataset, revealing ambiguity in FID interpretation for SR tasks.
- Why unresolved: Standard FID interpretation assumes lower is better, but this contradicts observed qualitative results; the paper does not validate mode collapse through additional diagnostics.
- What evidence would resolve it: Analysis combining FID with diversity metrics (e.g., intra-cluster LPIPS variance), sample-level inspection protocols, or alternative distribution metrics that correlate better with human judgment in SR-specific contexts.

### Open Question 4
- Question: How well do the Monte Carlo dropout uncertainty estimates correlate with actual reconstruction errors, and can they be calibrated to provide reliable confidence bounds for downstream decision-making?
- Basis in paper: [inferred] The paper produces uncertainty maps but does not quantitatively validate their reliability or demonstrate their utility in any downstream task.
- Why unresolved: Without calibration analysis or correlation with error metrics, the practical value of uncertainty estimates for "risk-aware interpretation" remains unproven.
- What evidence would resolve it: Scatter plots of pixel-wise uncertainty vs. reconstruction error, expected calibration error (ECE) metrics, or demonstration of uncertainty-weighted performance improvements in a downstream task such as building detection or land-cover classification.

## Limitations

- Uncertainty calibration not validated: The paper demonstrates uncertainty map generation but does not validate whether pixel-wise σ values correlate with actual reconstruction error.
- Semantic guidance trade-off unproven: The blurriness introduced by semantic loss may be detrimental to downstream task performance despite improved semantic consistency.
- Domain adaptation attribution uncertain: Performance differences between datasets may reflect hyperparameter tuning rather than fundamental domain incompatibility.

## Confidence

- **PSNR/SSIM Performance Claims:** High confidence - These are standard, reproducible metrics with clear baselines.
- **Uncertainty Map Generation:** High confidence - The MC dropout mechanism is well-established and correctly implemented.
- **Semantic Consistency Improvement:** Medium confidence - Visual observations support this, but quantitative downstream task validation is absent.
- **Domain Adaptation Conclusions:** Medium confidence - Performance differences are clear, but causal attribution to domain characteristics requires additional analysis.

## Next Checks

1. **Uncertainty calibration:** Bin test set pixels by their σ values and compute average reconstruction error (PSNR) per bin. Validate that high-σ bins show significantly worse reconstruction quality.

2. **Downstream task evaluation:** Apply a pre-trained object detector to SR outputs from baseline ESRGAN and SU-ESRGAN. Compare detection mAP to determine if semantic preservation actually improves practical utility despite reduced sharpness.

3. **Domain gap quantification:** Before fine-tuning, compute MMD or CORAL distance between source (AID) and target datasets (Aerial Maritime, UAVid). Correlate these distances with observed performance gaps to empirically validate the domain alignment hypothesis.