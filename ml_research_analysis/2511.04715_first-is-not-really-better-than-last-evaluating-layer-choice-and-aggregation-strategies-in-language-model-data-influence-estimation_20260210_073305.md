---
ver: rpa2
title: 'First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation
  Strategies in Language Model Data Influence Estimation'
arxiv_id: '2511.04715'
source_url: https://arxiv.org/abs/2511.04715
tags:
- influence
- layers
- tracin
- datainf
- cosine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying the most informative
  model layers for computing data influence in large language models (LLMs), a critical
  step for effective data attribution and model interpretability. The authors challenge
  the widely accepted assumption that embedding layers are optimal for influence estimation,
  instead proposing that middle attention layers often provide more reliable signals.
---

# First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation

## Quick Facts
- arXiv ID: 2511.04715
- Source URL: https://arxiv.org/abs/2511.04715
- Authors: Dmytro Vitel; Anshuman Chhabra
- Reference count: 40
- Primary result: Middle attention layers and vote-based aggregation outperform embedding layers and mean aggregation for data influence estimation

## Executive Summary
This paper investigates which layers of large language models are most informative for data influence estimation and how to best aggregate influence scores across layers. Contrary to the common belief that embedding layers are optimal, the authors demonstrate that middle attention layers provide more reliable signals for detecting detrimental training samples. They introduce novel aggregation strategies—Ranking and Vote—that significantly improve filtering accuracy by reducing the dominance of individual high-magnitude scores. Additionally, they propose the Noise Detection Rate (NDR) as a practical proxy metric for evaluating influence methods without costly retraining.

## Method Summary
The method involves fine-tuning an LLM with LoRA on GLUE tasks with 20% synthetic label noise, computing influence scores per layer group using TracIn/Cosine/DataInf, aggregating scores via Mean/Rank/Vote strategies, filtering the bottom 30% least influential samples, and retraining. Key components include embedding compression for efficiency, systematic layer group analysis (WE, 4 attention groups, CL), and evaluation using both downstream accuracy and NDR correlation.

## Key Results
- Middle attention layers consistently outperform embedding and classification head layers for influence estimation
- Vote aggregation improves filtering accuracy by up to 15% over mean aggregation, with win rates increasing from 0.71 to 0.84 on Mistral 7B
- NDR correlates strongly with downstream performance (Spearman ρ up to 0.9) and serves as a practical evaluation shortcut
- The gradient cancellation effect is an unreliable predictor of influence performance

## Why This Works (Mechanism)

### Mechanism 1
Middle attention layers provide more discriminative influence scores than embedding layers for detecting detrimental training samples. Middle layers encode task-relevant representations that are most sensitive to noisy/mislabeled samples, whereas embeddings capture low-level lexical features and later layers may overfit to noise. The gradient magnitude separation between clean and noisy samples peaks in early-to-middle attention layers.

### Mechanism 2
Positional voting aggregation preserves layer-specific discriminative signals better than mean aggregation. Mean aggregation allows opposing influence scores across layers to cancel out. Voting assigns positional scores (k, k-1, ...) based on rank, reducing dominance by high-magnitude outliers and preserving consensus across layers and validation samples.

### Mechanism 3
Noise Detection Rate (NDR) correlates with downstream task accuracy and can serve as a cheap proxy for influence method evaluation. NDR measures the fraction of known mislabeled samples ranked among least influential. High NDR indicates the influence function correctly identifies detrimental samples, predicting retraining improvement without actual retraining.

## Foundational Learning

- **Concept: Influence Functions (gradient-based)**
  - Why needed here: Core method for estimating training sample impact on model predictions without retraining
  - Quick check question: Can you explain why computing the inverse Hessian is intractable for billion-parameter models?

- **Concept: LoRA Modules (Query/Value Projections)**
  - Why needed here: Influence is computed on low-rank adapters rather than full weights for computational feasibility
  - Quick check question: Which LoRA module (Query A/B, Value A/B) should you prioritize for influence scoring based on this paper?

- **Concept: Layer-wise Representation in Transformers**
  - Why needed here: Understanding why different layers encode different information is critical for selecting the right layer
  - Quick check question: Why might early layers capture lexical features while middle layers capture task-relevant representations?

## Architecture Onboarding

- **Component map:** Noise injection + checkpoint preparation -> Fine-tuning on noisy data -> Influence computation per layer group -> Aggregation + NDR calculation -> Filter 30% lowest-influence samples + retrain

- **Critical path:** Layer selection → influence method choice (DataInf/TracIn/Cosine) → aggregation strategy. The paper recommends: early-to-middle attention layers, Value B LoRA module, Vote aggregation.

- **Design tradeoffs:**
  - DataInf vs TracIn: DataInf is more accurate but O(n²m) vs O(nm) memory
  - Mean vs Vote: Mean is simpler; Vote requires tuning k but outperforms in most cases
  - Embedding compression: Speeds up computation but may lose token-level signal

- **Failure signatures:**
  - Influence methods underperforming Random baseline (observed for Llama-3.2 1B with Mean aggregation)
  - High NDR but low downstream accuracy (suggests noise distribution mismatch)
  - Classification head (CL) consistently worst across methods—avoid using CL for filtering

- **First 3 experiments:**
  1. **Baseline check:** Compute TracIn on middle attention layers with mean aggregation; verify NDR > 50% at 30% threshold on a GLUE task
  2. **Aggregation comparison:** Replace mean with Vote (k=30) on same setup; expect 5-15% accuracy gain
  3. **Layer sweep:** Run NDR across all layer groups for your model to confirm middle layers peak; plot NDR vs layer to identify optimal region

## Open Questions the Paper Calls Out

- **Open Question 1:** How does the optimal number of votes (k) in positional voting scale with different noise levels and dataset sizes? The paper only tested k=30 and observed k∈[10,50] performed best, but did not systematically vary noise levels.

- **Open Question 2:** Can unsupervised or multi-objective aggregation methods outperform the proposed ranking and positional voting strategies? The paper only tested mean, rank, and vote aggregations; more sophisticated methods combining influence signals remain unexplored.

- **Open Question 3:** Do the layer choice and aggregation findings generalize to full fine-tuning without LoRA compression? All experiments use LoRA modules on attention layers, potentially altering which layers appear most informative.

- **Open Question 4:** Do the findings transfer to naturally occurring data quality issues versus synthetic label noise? The methodology injects synthetic noise; real-world noisy data may exhibit different distribution patterns than uniform label flipping.

## Limitations

- Findings are primarily based on Mistral 7B and Llama-3.2 models on GLUE tasks with synthetic noise, limiting generalizability to other architectures and real-world data contamination
- NDR's effectiveness as a proxy metric depends on synthetic label noise adequately representing real detrimental samples
- LoRA-based influence computation may restrict gradient computation to low-rank projections, potentially altering which layers appear most informative

## Confidence

- **High Confidence:** Middle attention layers consistently outperform embedding and classification head layers for influence estimation
- **Medium Confidence:** Vote aggregation provides robust improvements over mean aggregation (win rates increase from 0.71 to 0.84 on Mistral 7B)
- **Medium Confidence:** NDR correlates strongly with downstream performance (Spearman ρ up to 0.9 under Vote aggregation)

## Next Checks

1. **Cross-architecture validation:** Test the layer selection and aggregation recommendations on BERT-style encoder models and decoder-only models on tasks outside GLUE (e.g., SQuAD, sentiment analysis) to verify generalizability

2. **Real-world contamination testing:** Replace synthetic label noise with real mislabeled samples or other data quality issues (e.g., outliers, ambiguous samples) to validate NDR's effectiveness as a proxy metric

3. **Ablation on k-parameter:** Systematically vary the k parameter in Vote aggregation across a broader range (k=10 to k=50) to identify optimal settings for different model sizes and task complexities