---
ver: rpa2
title: 'EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes'
arxiv_id: '2508.00180'
source_url: https://arxiv.org/abs/2508.00180
tags:
- bema
- training
- performance
- learning
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BEMA, a bias-corrected exponential moving
  average method designed to stabilize training of language models by reducing the
  gradient variance that arises from small batch sizes. While EMA is widely used for
  stabilization, it introduces lag due to bias from older iterates, which slows convergence.
---

# EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes

## Quick Facts
- arXiv ID: 2508.00180
- Source URL: https://arxiv.org/abs/2508.00180
- Reference count: 40
- Introduces BEMA, a bias-corrected EMA method that accelerates convergence while retaining variance reduction benefits

## Executive Summary
This paper addresses the lag problem in Exponential Moving Average (EMA) methods commonly used to stabilize language model training. Standard EMA reduces gradient variance from small batch sizes but introduces bias by trailing behind the current optimum. BEMA solves this by adding a displacement correction term that accounts for the total movement from the initial weights, effectively removing the lag while preserving EMA's variance-reduction benefits. Theoretically derived as the optimal estimator for noisy quadratic models, BEMA achieves faster convergence and higher final accuracy across multiple language modeling tasks with minimal implementation overhead.

## Method Summary
BEMA enhances standard EMA by computing the Maximum Likelihood Estimate (MLE) for an Ornstein-Uhlenbeck process that models SGD on quadratic losses. The method maintains three weight copies: current parameters, an EMA buffer, and an initial reference point. It applies exponential smoothing to reduce variance, then adds a bias correction proportional to the displacement from the initial point. The correction uses a scalar approximation of the inverse Hessian to avoid memory overhead. This design eliminates the trailing lag of EMA while preserving its noise-reduction benefits, requiring only minor code modifications to existing training pipelines.

## Key Results
- BEMA consistently outperforms both vanilla training and standard EMA across multiple tasks including BoolQ, GSM8K, and MMLU-HS
- Achieves 0.2% to 5.6% accuracy improvements when fine-tuning Qwen2.5-1.5B, Gemma3-1B, and Llama3.2-1B models
- Demonstrates faster convergence speed while maintaining the variance reduction benefits of EMA
- Requires minimal code changes, making it practical for production training

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Adding a scaled displacement term to the moving average corrects the "lag" inherent in standard EMA.
- **Mechanism:** Standard EMA effectively averages iterates but ignores the directional trend of the optimization path, causing it to trail behind the optimum. BEMA computes the MLE for the Ornstein-Uhlenbeck (OU) process, which includes a term proportional to the total displacement $(\theta_t - \theta_0)$ (Eq. 8). By adding this term back, the estimator "leads" the target, counteracting the drag from older iterates.
- **Core assumption:** The optimization trajectory behaves like a noisy quadratic (Ornstein-Uhlenbeck process) near the minimum (Section 2).
- **Evidence anchors:**
  - [abstract] "BEMA... retains variance-reduction benefits while eliminating bias."
  - [section 3] Theorem 2 derives the MLE, showing the explicit dependence on the displacement term $A^{-1}(\theta_T - \theta_0)$.
  - [corpus] Related work (Polyak/Ruppert averaging) discusses iterate averaging, but specific "displacement correction" mechanisms for lag reduction are not detailed in the provided corpus.
- **Break condition:** If the loss landscape is highly non-convex or the "burn-in" period places $\theta_0$ far from the basin of attraction, the linear correction may mislead the trajectory.

### Mechanism 2
- **Claim:** BEMA retains the variance reduction properties of EMA while improving convergence speed.
- **Mechanism:** The algorithm computes a standard EMA ($\hat{\mu}_{EMA}$) to smooth stochastic noise (variance reduction). It then applies the bias correction *on top* of this smoothed estimate. This decoupling allows the variance reduction to proceed independently of the bias correction.
- **Core assumption:** The stochastic noise is zero-mean and the quadratic approximation holds sufficiently for the EMA to act as a consistent estimator of the mean trajectory.
- **Evidence anchors:**
  - [section 1] "EMA reduces stochasticity... but the introduction of bias... creates a lag."
  - [algorithm 1] Explicitly separates the EMA update step from the bias correction update step.
- **Break condition:** If batch sizes are extremely small such that noise swamps the signal (exceeding the model's capacity to smooth), BEMA may inherit EMA's instability.

### Mechanism 3
- **Claim:** Finite-time estimation is accelerated by approximating the inverse Hessian with a scalar decay factor.
- **Mechanism:** Theoretically, the MLE requires the inverse Hessian $A^{-1}$ (Eq. 8). In practice, BEMA approximates this with a time-dependent scaling factor $\alpha_t$ (derived from the EMA decay $\beta_t$). This avoids the memory cost of storing the Hessian while effectively rescaling the gradient steps implicit in the displacement term.
- **Core assumption:** The Hessian can be approximated by a scalar multiple of the identity ($\hat{A} = \alpha I$) without destabilizing the update.
- **Evidence anchors:**
  - [section 4] "In practice, we find that taking $\hat{A} = \alpha I$ suffices... $\alpha_t = (\rho + \gamma t)^{-\eta}$."
  - [corpus] Corpus neighbors discuss adaptive/preconditioned methods (Shampoo, Adam), supporting the difficulty of full Hessian storage, but do not validate this specific scalar approximation for BEMA.
- **Break condition:** If the problem is ill-conditioned (Hessian eigenvalues vary widely), a scalar approximation may over-amplify updates in flat directions.

## Foundational Learning

- **Concept:** Ornstein-Uhlenbeck (OU) Process
  - **Why needed here:** The paper models SGD on a quadratic loss as an OU process (a stochastic differential equation). This model allows the authors to derive the "optimal" estimator (BEMA) analytically, framing training as a statistical estimation problem.
  - **Quick check question:** Can you explain why modeling optimization as a "noisy drift towards a mean" allows us to treat the final weights as statistical estimates rather than deterministic points?

- **Concept:** Bias-Variance Tradeoff in Iterate Averaging
  - **Why needed here:** Standard EMA reduces variance (noise) but introduces bias (lag). BEMA is proposed specifically to attack the bias term. Understanding this decomposition is necessary to see why BEMA adds complexity to standard EMA.
  - **Quick check question:** If you average a time-series of weights moving monotonically away from the start, why does the resulting average necessarily "lag" behind the final weight?

- **Concept:** Maximum Likelihood Estimation (MLE)
  - **Why needed here:** The authors justify BEMA by proving it is the MLE of the optimum $\mu^\star$ in the OU model. This provides the theoretical guarantee that it is the "best" use of the trajectory history.
  - **Quick check question:** Why does the MLE for an OU process depend on the *total displacement* ($\theta_T - \theta_0$) in addition to the time-average of the path?

## Architecture Onboarding

- **Component map:**
  - Current Weights ($\theta_t$) -> EMA Buffer ($\hat{\mu}_{EMA}$) -> BEMA Weights ($\hat{\mu}_{BEMA}$)

- **Critical path:**
  1. **Burn-in (Optional):** If $\tau > 0$, run standard training; update $\theta_0$ to current weights after $\tau$ steps.
  2. **Optimizer Step:** Update $\theta_t$ via Adam/SGD.
  3. **EMA Update:** Update shadow buffer $\hat{\mu}_{EMA} \leftarrow (1-\beta_t)\hat{\mu}_{EMA} + \beta_t \theta_t$.
  4. **Bias Correction:** Compute $\alpha_t = \beta_t^{0.4}$ (approx).
  5. **BEMA Update:** Set $\hat{\mu}_{BEMA} \leftarrow \alpha_t (\theta_t - \theta_0) + \hat{\mu}_{EMA}$.
  6. **Evaluation:** Use $\hat{\mu}_{BEMA}$ for validation/inference.

- **Design tradeoffs:**
  - **Memory vs. Correctness:** BEMA requires storing **3 copies** of the model ($\theta_t$, EMA, $\theta_0$) vs. 2 for standard EMA. This adds ~50% memory overhead for the optimizer states/weights.
  - **Frequency ($\phi$) vs. Speed:** Updating BEMA every step is computationally expensive (requires weight copying). The paper suggests updating every 400 steps ($\phi=400$) to balance convergence speed and wall-clock time.
  - **Strength ($\eta$) vs. Stability:** Lower $\eta$ (stronger correction) speeds up convergence but risks collapse if the loss is non-convex. Higher $\eta$ (weaker correction) behaves more like standard EMA.

- **Failure signatures:**
  - **Performance Collapse:** Accuracy drops sharply (Figure 3) if $\eta$ is too low (correction too strong), likely due to the quadratic assumption failing.
  - **No Improvement over EMA:** If $\theta_0$ is set poorly (e.g., burn-in is too long or starting point is far from the basin), the displacement term $(\theta_t - \theta_0)$ provides misleading directional info.

- **First 3 experiments:**
  1. **Sanity Check (Quadratic):** Implement BEMA on a simple noisy quadratic function. Plot distance to minimum vs. time. Verify BEMA converges faster than EMA and Vanilla (replicate Figure 2).
  2. **Hyperparameter Sensitivity ($\eta$):** Fine-tune a small LM (e.g., Qwen-1.5B subset) with fixed $\kappa=0.5$. Sweep $\eta \in \{0.5, 0.2, 0.1\}$. Observe if performance collapses for low $\eta$ (replicate Figure 3).
  3. **Ablation on Initial Point ($\theta_0$):** Run BEMA with $\tau=0$ (immediate) vs $\tau=1000$ (delayed start). Verify that immediate stabilization ($\tau=0$) yields better final performance (replicate Figure 9).

## Open Questions the Paper Calls Out
None

## Limitations
- The scalar approximation of the Hessian (αI) lacks extensive validation for ill-conditioned problems common in deep learning
- Memory overhead of maintaining three weight copies (~50% increase) may be prohibitive for resource-constrained settings
- Performance improvements vary significantly (0.2% to 5.6%), suggesting effectiveness depends on specific training conditions

## Confidence
- **High**: Theoretical optimality proof for OU model, basic variance reduction mechanism of EMA
- **Medium**: Empirical performance improvements across tasks, practical effectiveness of scalar Hessian approximation
- **Low**: Generalization to highly non-convex landscapes, optimal hyperparameter settings across diverse architectures

## Next Checks
1. **Non-Convex Stress Test**: Evaluate BEMA on tasks known for rugged loss landscapes (e.g., low-resource machine translation or adversarial training) to assess whether the quadratic approximation breaks down under realistic conditions.

2. **Memory-Efficient Variant**: Implement a memory-optimized version that stores only the displacement vector rather than three full weight copies, then benchmark whether the performance degradation is acceptable for practical deployment.

3. **Transfer Learning Dynamics**: Test BEMA when fine-tuning from pre-trained checkpoints versus training from scratch on quadratic problems to understand how the choice of θ₀ affects convergence in transfer learning scenarios.