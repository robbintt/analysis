---
ver: rpa2
title: 'Osprey: Production-Ready Agentic AI for Safety-Critical Control Systems'
arxiv_id: '2508.15066'
source_url: https://arxiv.org/abs/2508.15066
tags:
- control
- arxiv
- osprey
- execution
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Osprey is a framework for deploying agentic AI in safety-critical
  control systems, addressing the challenge of translating operator intent into precise
  hardware actions while maintaining strict safety oversight. The framework introduces
  a plan-first orchestrator that generates complete execution plans with dependencies
  for human review before any hardware interaction.
---

# Osprey: Production-Ready Agentic AI for Safety-Critical Control Systems

## Quick Facts
- arXiv ID: 2508.15066
- Source URL: https://arxiv.org/abs/2508.15066
- Authors: Thorsten Hellert; João Montenegro; Antonin Sulc
- Reference count: 0
- One-line primary result: Osprey is a framework for deploying agentic AI in safety-critical control systems, addressing the challenge of translating operator intent into precise hardware actions while maintaining strict safety oversight.

## Executive Summary
Osprey is a framework for deploying agentic AI in safety-critical control systems, addressing the challenge of translating operator intent into precise hardware actions while maintaining strict safety oversight. The framework introduces a plan-first orchestrator that generates complete execution plans with dependencies for human review before any hardware interaction. A coordination layer manages complex data flows, ensures data type consistency, and automatically downsamples large datasets. A classifier dynamically selects only the tools required for each task, preventing prompt inflation as facilities expand capabilities. Connector abstractions provide protocol-agnostic access to control systems, while containerized execution enforces safety through pattern detection and PV boundary checks. In a production deployment at the Advanced Light Source, Osprey manages real-time operations across hundreds of thousands of control channels, demonstrating reliable, auditable orchestration of multi-step procedures from natural language requests.

## Method Summary
Osprey implements a plan-first orchestrator that generates complete execution plans with explicit dependencies for human review before any hardware interaction. A coordination layer manages complex data flows, ensures data type consistency, and automatically downsamples large datasets. A classifier dynamically selects only the tools required for each task, preventing prompt inflation as facilities expand capabilities. Connector abstractions provide protocol-agnostic access to control systems, while containerized execution enforces safety through pattern detection and PV boundary checks. In a production deployment at the Advanced Light Source, Osprey manages real-time operations across hundreds of thousands of control channels, demonstrating reliable, auditable orchestration of multi-step procedures from natural language requests.

## Key Results
- Plan-first orchestration enables human review before hardware interaction, reducing risk of unintended control operations
- Per-capability binary classification prevents prompt inflation as facility tool inventories grow
- Multi-layer safety enforcement (pattern detection + PV boundary checks + container isolation) provides defense-in-depth against unsafe hardware writes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Plan-first orchestration enables human review before hardware interaction, reducing risk of unintended control operations.
- Mechanism: The orchestrator generates a complete execution plan with explicit dependencies (e.g., channel resolution → archiver retrieval → analysis) and presents it for operator approval. Only after approval does execution begin. This decouples intent interpretation from action execution.
- Core assumption: Operators can effectively evaluate proposed plans when presented with resolved channels, dependencies, and safety annotations.
- Evidence anchors:
  - [abstract] "plan-first orchestrator that generates complete execution plans, including all dependencies, for human review before any hardware is touched"
  - [Section III B 3] "Operators can view, modify, or reject this plan before execution."
  - [corpus] Weak direct evidence; neighbor papers discuss agentic workflows generally but not this specific plan-first pattern.
- Break condition: If plan complexity exceeds operator cognitive capacity, or if time-critical faults require immediate action, the review step becomes a bottleneck.

### Mechanism 2
- Claim: Per-capability binary classification prevents prompt inflation as facility tool inventories grow.
- Mechanism: Before planning, a classifier performs a relevance test for each capability ("Is this capability required?"). Only classified-relevant tools proceed to the orchestrator. This keeps prompts compact regardless of total capability count.
- Core assumption: The classifier accurately identifies relevant capabilities; false negatives would exclude necessary tools.
- Evidence anchors:
  - [abstract] "classifier dynamically selects only the tools required for a given task, preventing prompt inflation as facilities expand capabilities"
  - [Section III B 2] "Only the tools classified as relevant should proceed to planning."
  - [corpus] RAG-MCP (Ref. 19) addresses similar tool-selection bloat via retrieval-augmented generation.
- Break condition: If classifier accuracy degrades with domain-specific jargon or novel task types, critical capabilities may be omitted.

### Mechanism 3
- Claim: Multi-layer safety enforcement (pattern detection + PV boundary checks + container isolation) provides defense-in-depth against unsafe hardware writes.
- Mechanism: (1) Pattern detection scans generated Python for control-system write calls (e.g., `caput`). (2) PV boundary checking validates setpoints against facility-defined limits and whitelists. (3) Containerized execution separates read-only from write-enabled environments. Any layer can veto an operation.
- Core assumption: Facility-provided boundary databases are complete and up-to-date; pattern detection regex covers all control-system write primitives.
- Evidence anchors:
  - [abstract] "containerized execution enforces safety through pattern detection and PV boundary checks"
  - [Section III B 5] "These checks implement a defense-in-depth safety architecture in which multiple, independent layers can veto an unsafe operation."
  - [corpus] MAIF (arXiv:2511.15097) emphasizes artifact-centric provenance for AI trust; complementary but not overlapping.
- Break condition: If novel write primitives bypass regex patterns, or if boundary databases lag behind control-system changes, unsafe operations could reach hardware.

## Foundational Learning

- Concept: EPICS Process Variables (PVs) and control-system gateways
  - Why needed here: Osprey targets facilities with 10K–1M+ PVs; understanding channel addressing, read/write semantics, and gateway abstraction is essential for configuring connectors and interpreting execution plans.
  - Quick check question: Can you explain why separate read-only and write-enabled EPICS gateways provide a network-level safety layer?

- Concept: Dependency-aware task graphs
  - Why needed here: The plan-first orchestrator outputs explicit step dependencies (e.g., time-range parsing → channel finding → archiver retrieval). Understanding DAG execution is necessary to debug plan failures.
  - Quick check question: Given steps A→B and A→C, what happens if step A fails?

- Concept: Container isolation and execution sandboxing
  - Why needed here: Generated Python runs in Docker/Podman containers with controlled network access. Understanding container boundaries helps troubleshoot connector failures and safety-policy enforcement.
  - Quick check question: Why would a read-only container prevent a `caput` call even if the code contains one?

## Architecture Onboarding

- Component map: Orchestrator -> Capability Classifier -> Connectors -> Code Generators -> Execution Layer
- Critical path: Natural-language request → Task extraction → Capability classification → Plan generation → [Human review if write operations] → Containerized execution → Artifact storage
- Design tradeoffs:
  - Plan-first vs. reactive execution: Transparency and safety vs. latency for time-critical responses
  - Classifier-based tool selection vs. full-tool prompts: Scalability vs. risk of false-negative exclusions
  - Container isolation vs. local execution: Reproducibility/auditing vs. deployment complexity
- Failure signatures:
  - Classifier omits required capability → plan lacks necessary step → downstream execution fails with missing data
  - Pattern detection flags false positive → unnecessary approval delay for read-only operations
  - PV boundary database stale → valid setpoint rejected or invalid setpoint allowed (Assumption: depends on update frequency)
- First 3 experiments:
  1. Run the Control Assistant tutorial with mock connectors; verify plan generation for "Give me a time series of beam current over the last hour" and inspect the 5-step plan structure
  2. Add a custom capability (e.g., a new diagnostic tool) and test classifier relevance decisions with and without few-shot examples
  3. Trigger a write-operation scenario (e.g., propose a `caput` in generated code) and confirm pattern detection flags it, PV boundary checks evaluate limits, and approval workflow activates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific quantitative metrics are required to rigorously validate the reliability and safety of agent-assisted control operations beyond qualitative case studies?
- Basis in paper: [explicit] The conclusion explicitly states that future work will focus on "richer validation metrics for agent-assisted operations."
- Why unresolved: The current evaluation relies on successful task completion in case studies (e.g., hysteresis measurements) rather than formalized benchmarks or statistical safety guarantees.
- What evidence would resolve it: A standardized benchmark suite reporting success rates, error recovery frequencies, and safety violation avoidance across diverse operational scenarios.

### Open Question 2
- Question: How effectively does the framework generalize to facilities with control system architectures substantially different from the EPICS-based Advanced Light Source?
- Basis in paper: [explicit] The authors identify "broader cross-facility deployments" as a necessary step for future work to demonstrate wider applicability.
- Why unresolved: While the paper claims protocol agnosticism, the primary validation is performed at a single EPICS-based facility (ALS).
- What evidence would resolve it: Successful deployment documentation from facilities using fundamentally different control protocols (e.g., Tango, OPC-UA) requiring minimal architectural changes.

### Open Question 3
- Question: What architectural extensions are needed for deep integration with heterogeneous facility data standards and unstructured knowledge bases?
- Basis in paper: [explicit] The conclusion lists "deeper integration with facility data standards and knowledge bases" as a specific direction for future research.
- Why unresolved: The current system utilizes connectors and MCP servers, but the paper does not detail how the agent reasons over complex, unstructured institutional knowledge.
- What evidence would resolve it: Demonstrations of the agent automatically ingesting and reasoning over diverse facility documentation formats to resolve ambiguous operator queries.

## Limitations
- Plan-first approach assumes operator cognitive capacity to evaluate complex multi-step plans, but no empirical data validates this under production load
- Container isolation and pattern detection rely on regex coverage of control-system primitives, which may not scale to novel facility-specific APIs
- Framework's scalability and safety guarantees depend heavily on facility-specific boundary databases and classifier accuracy, neither of which are provided in detail

## Confidence
- Plan-first orchestration with human review: High
- Classifier-based tool selection: Medium
- Multi-layer safety enforcement: Medium

## Next Checks
1. Deploy Osprey in a staging facility environment with realistic PV counts and execute a representative sample of operator queries; measure plan review time, classifier accuracy, and safety veto rates.
2. Perform a penetration test by attempting to bypass safety layers through novel write patterns or outdated boundary databases; document detection rates and response times.
3. Conduct a cognitive load study with facility operators reviewing plans of increasing complexity; establish thresholds for when human review becomes a bottleneck and document fallback procedures.