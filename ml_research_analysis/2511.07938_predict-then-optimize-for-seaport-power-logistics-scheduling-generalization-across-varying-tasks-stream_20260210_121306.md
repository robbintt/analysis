---
ver: rpa2
title: 'Predict-then-Optimize for Seaport Power-Logistics Scheduling: Generalization
  across Varying Tasks Stream'
arxiv_id: '2511.07938'
source_url: https://arxiv.org/abs/2511.07938
tags:
- task
- tasks
- power
- forecasting
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Predict-then-Optimize for Seaport Power-Logistics Scheduling: Generalization across Varying Tasks Stream

## Quick Facts
- **arXiv ID:** 2511.07938
- **Source URL:** https://arxiv.org/abs/2511.07938
- **Reference count:** 40
- **Key outcome:** Fisher-regularized Decision-Focused Continual Learning (DFCL) achieves 9.6% average regret reduction versus sequential DFL with EWC and 4.1% versus DFL with Rehearsal across six seaport scheduling tasks.

## Executive Summary
This paper introduces a Decision-Focused Continual Learning (DFCL) framework for seaport power-logistics scheduling that addresses catastrophic forgetting when adapting to varying vessel arrival configurations. The method combines a regret-based loss (minimizing cost difference from optimal), a differentiable KNN surrogate to handle discrete berth assignments, and Fisher information regularization to preserve critical parameters from previous tasks. Empirical results show the framework achieves 9.6% lower average regret than sequential DFL with EWC and 4.1% lower than DFL with rehearsal, while maintaining stability across an unbounded task stream.

## Method Summary
The framework trains a Transformer-MLP model to forecast electricity prices and loads, which feeds into a differentiable KNN surrogate that approximates discrete vessel-berth assignments. These predictions are used in a convex power-flow optimization layer whose solution is differentiated via KKT conditions. The model is trained sequentially across six tasks using a regret loss (cost difference from oracle) plus Fisher information regularization to prevent catastrophic forgetting. The method leverages Elastic Weight Consolidation (EWC) to penalize changes to parameters critical to previous tasks, approximated through the empirical Fisher Information Matrix.

## Key Results
- DFCL achieves 9.6% average regret reduction versus sequential DFL with EWC across six tasks
- DFCL outperforms DFL with rehearsal by 4.1% on average regret
- The framework maintains performance stability across an unbounded task stream while sequential methods degrade

## Why This Works (Mechanism)

### Mechanism 1: Cross-Task Generalization via Fisher Regularization
- **Claim:** Constraining updates to parameters with high Fisher information preserves decision-critical knowledge from prior tasks.
- **Mechanism:** The framework calculates the empirical Fisher Information Matrix to identify weights heavily influencing regret loss on previous tasks, then applies a quadratic penalty to restrict changes to these critical weights during new task updates.
- **Core assumption:** The parameter posterior for previous tasks can be approximated as a Gaussian distribution (Laplace approximation), and Fisher information serves as a sufficient proxy for parameter importance.
- **Evidence anchors:** Section 3.2 derives the penalty term from the log-posterior; Abstract states the Fisher regularization "preserves parameters critical to prior tasks."
- **Break condition:** If new tasks require significant alteration of parameters previously deemed "critical," the regularization may prevent necessary adaptation.

### Mechanism 2: Gradient Stabilization via KNN-based Convex Surrogate
- **Claim:** Approximating non-convex, mixed-integer decisions with a memory-based surrogate enables stable gradient backpropagation.
- **Mechanism:** Uses K-Nearest Neighbors (KNN) to lookup discrete decisions from a memory buffer based on forecast similarity, fixing these discrete variables to convexify the remaining power-flow problem into a linear program solvable via implicit differentiation.
- **Core assumption:** Historical scheduling decisions stored in memory are sufficiently representative of optimal decisions for current forecasts.
- **Evidence anchors:** Section 4.2.1 states KNN "yields stable and interpretable gradient estimates."
- **Break condition:** Novel vessel configurations with no close neighbors in memory buffer may produce infeasible or suboptimal discrete variables.

### Mechanism 3: Regret-Based Loss Alignment
- **Claim:** Training forecasting models to minimize "regret" (cost difference from optimal) rather than statistical error aligns predictions with asymmetric economic penalties.
- **Mechanism:** Defines loss as the difference between the cost incurred by predicted decision and the cost of optimal decision with perfect hindsight, forcing forecaster to prioritize accuracy in high-cost time periods.
- **Core assumption:** The "perfect foresight" baseline is computable and serves as a stable target for gradient descent.
- **Evidence anchors:** Section 3.1 defines regret formally; Section 5.2 shows DFL achieves lower cost than SBL despite higher MAE.
- **Break condition:** If cost function is highly non-convex or noisy, regret loss gradients may vanish or explode.

## Foundational Learning

- **Concept: Predict-then-Optimize (PTO) vs. Decision-Focused Learning (DFL)**
  - **Why needed here:** The paper's primary motivation is misalignment between standard statistical training (MSE) and downstream decision quality in PTO pipelines.
  - **Quick check question:** If you minimize Mean Squared Error (MSE) for electricity price forecasting, have you guaranteed minimum operational cost for the battery storage system? (Answer: No, due to asymmetric costs).

- **Concept: Elastic Weight Consolidation (EWC)**
  - **Why needed here:** This is the core continual learning technique adapted in Section 3.2.
  - **Quick check question:** In EWC, does the Fisher Information matrix constrain all weights equally, or only those critical to the loss landscape of the previous task?

- **Concept: Implicit Differentiation**
  - **Why needed here:** The paper differentiates through the optimization layer via KKT conditions in Section 4.2.2.
  - **Quick check question:** Why can't we use standard backpropagation through a mixed-integer linear program (MILP)?

## Architecture Onboarding

- **Component map:** Input (Context + Vessel arrivals) -> Transformer Encoder + MLP -> Differentiable KNN (Soft-Top-k) -> Convex LP solver (KKT conditions) -> Regret Loss; Continual Learning Controller accumulates Fisher Matrix.

- **Critical path:** Gradient flows from Regret Loss -> Optimization Layer (via implicit diff) -> Forecasting Layer. Surrogate Layer is a "side-chain" that convexifies the problem.

- **Design tradeoffs:** KNN Surrogate chosen for non-parametric flexibility and stability over neural surrogates, but requires maintaining growing memory buffer. EWC Regularization (λ) balances plasticity vs. stability.

- **Failure signatures:** Catastrophic Forgetting (Regret on Task 1 rises after Task 2 training); Surrogate Mismatch (Solver returns infeasible status).

- **First 3 experiments:** 1) Alignment Check: Compare MSE-trained vs. Regret-trained model on single static task. 2) Forgetting Baseline: Train standard DFL sequentially on Task 1→2 to establish forgetting need. 3) Continual Validation: Run DFCL on full stream (Tasks 1-6) and plot Forgetting Measure over time.

## Open Questions the Paper Calls Out

- **Open Question 1:** What are the theoretical underpinnings of task relatedness in DFCL, and how does it influence generalization? [explicit] The paper empirically demonstrates generalization but doesn't provide a theoretical framework defining when tasks are sufficiently "related" for EWC regularization to be beneficial rather than detrimental.

- **Open Question 2:** How can the memory set M for the KNN surrogate be managed to ensure scalability over an unbounded task stream without performance degradation? [inferred] The paper claims adaptation to "unbounded task stream" but doesn't detail a mechanism for pruning or updating memory set M as stream grows infinitely.

- **Open Question 3:** Is the Laplace approximation (Gaussian posterior) valid for the complex, non-convex loss landscapes inherent in DFL? [inferred] Section 3.2 justifies regularization using Laplace approximation, but Figure 2 illustrates DFL loss landscapes are irregular and may not support Gaussian approximation.

## Limitations

- The Fisher-based regularization assumes Gaussian posterior approximation may not hold for highly non-convex regret landscapes.
- KNN surrogate performance critically depends on representativeness of memory buffer - poor coverage for novel vessel configurations breaks downstream solve.
- Regret-based training requires computing oracle optimal solution for each example, creating computational bottleneck that scales poorly with problem size.

## Confidence

**High Confidence:** Regret-based loss alignment mechanism is well-established in DFL literature and directly evidenced by Table 2 showing DFL outperforming SBL despite higher MAE.  
**Medium Confidence:** Fisher regularization mechanism is theoretically sound but relies on empirical evidence; novelty of applying EWC specifically to DFL contexts warrants cautious interpretation.  
**Low Confidence:** Gradient stability claims for KNN surrogate are primarily theoretical - paper claims "stable and interpretable gradients" but sensitivity to memory buffer quality is not thoroughly validated.

## Next Checks

1. **Cross-Task Stability Test:** Systematically evaluate Forgetting Measure (FM) when training on Task 1→2→3 versus 3→2→1 to verify EWC regularization genuinely preserves knowledge regardless of task ordering.

2. **Surrogate Robustness Analysis:** Create adversarial vessel configurations with no close neighbors in memory buffer and measure regret degradation to quantify surrogate's failure mode.

3. **Oracle Baseline Comparison:** For subset of examples, compute both regret-trained model's cost and cost when using perfect price/load forecasts (oracle) to determine if model genuinely learns to align with cost function or simply memorizes working patterns.