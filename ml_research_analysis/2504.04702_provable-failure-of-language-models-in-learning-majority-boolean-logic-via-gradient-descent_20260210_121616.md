---
ver: rpa2
title: Provable Failure of Language Models in Learning Majority Boolean Logic via
  Gradient Descent
arxiv_id: '2504.04702'
source_url: https://arxiv.org/abs/2504.04702
tags:
- step
- follows
- nition
- section
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes theoretical limitations of Transformers
  in learning majority Boolean functions via gradient descent. The authors analyze
  a simplified Transformer variant and prove that, even with polynomial or exponential
  numbers of training samples, the generalization error remains large and grows exponentially
  with input dimension.
---

# Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent

## Quick Facts
- arXiv ID: 2504.04702
- Source URL: https://arxiv.org/abs/2504.04702
- Authors: Bo Chen; Zhenmei Shi; Zhao Song; Jiahao Zhang
- Reference count: 40
- Primary result: Transformers cannot learn majority Boolean functions via gradient descent, with generalization error growing exponentially with input dimension

## Executive Summary
This paper establishes fundamental limitations of Transformers in learning majority Boolean functions through gradient descent optimization. The authors prove that even with polynomial or exponential numbers of training samples, Transformers fail to achieve low generalization error when learning majority functions, with error bounds that grow exponentially with input dimension. The theoretical analysis introduces novel combinatorial and probabilistic techniques to characterize gradient variance and establish rigorous lower bounds on generalization error. These findings highlight intrinsic optimization challenges in training Transformers for basic logical reasoning tasks.

## Method Summary
The authors analyze a simplified Transformer variant to establish theoretical limitations on learning majority Boolean functions via gradient descent. They employ combinatorial techniques to bound gradient variance and prove that after polynomial gradient queries, the model cannot learn the majority function with bounded generalization error. The analysis combines probabilistic methods with combinatorial arguments to characterize the optimization landscape and demonstrate fundamental barriers to learning. The theoretical framework provides rigorous mathematical proofs showing that the generalization error remains large and grows exponentially with input dimension, even with polynomial or exponential training samples.

## Key Results
- Transformers cannot learn majority Boolean functions via gradient descent, even with polynomial gradient queries
- Generalization error grows exponentially with input dimension and remains bounded away from zero
- Novel combinatorial and probabilistic techniques characterize gradient variance and establish error lower bounds

## Why This Works (Mechanism)
The mechanism underlying these limitations stems from the interaction between the Transformer architecture and the optimization landscape of majority functions. The simplified Transformer variant exhibits gradient variance that cannot be sufficiently reduced through polynomial gradient queries, preventing convergence to low-error solutions. The combinatorial structure of majority functions creates optimization barriers that gradient descent cannot overcome within polynomial time. The probabilistic analysis reveals that the variance of gradients remains too large relative to the signal needed to learn the target function, leading to persistent generalization errors.

## Foundational Learning
- Boolean function learning theory: Understanding the complexity of learning Boolean functions is essential for analyzing Transformer limitations. Quick check: Verify basic concepts of PAC learning and function class complexity.
- Gradient descent optimization: Knowledge of optimization dynamics and convergence properties is crucial for understanding failure modes. Quick check: Review gradient descent convergence rates and variance effects.
- Combinatorial analysis: Techniques for counting and bounding combinatorial structures are fundamental to the proof approach. Quick check: Understand basic combinatorial bounds and probabilistic methods.
- Generalization theory: Concepts of generalization error and sample complexity are central to the theoretical framework. Quick check: Review bounds on generalization error and VC dimension concepts.
- Transformer architecture: Understanding the core components of Transformers is necessary to interpret the simplified model analysis. Quick check: Review attention mechanisms and positional encoding basics.
- Probabilistic methods: Concentration inequalities and probabilistic bounds are key tools in the analysis. Quick check: Review basic concentration inequalities like Hoeffding and Bernstein.

## Architecture Onboarding

Component map: Input embeddings -> Attention layers -> Feed-forward networks -> Output layer

Critical path: The critical path for learning majority functions involves the attention mechanism's ability to aggregate input bits, followed by the feed-forward network's transformation and final classification. The attention mechanism must effectively capture the majority relationship between input bits, which proves challenging due to the combinatorial complexity of the function.

Design tradeoffs: The Transformer architecture trades off computational efficiency and representational power against optimization complexity. While Transformers excel at capturing long-range dependencies and hierarchical representations, this complexity introduces optimization challenges for simple logical functions like majority. The attention mechanism's ability to weigh inputs proportionally becomes problematic when the optimal weighting is highly sensitive to input combinations.

Failure signatures: Key failure signatures include persistent high generalization error regardless of training sample size, gradient variance that remains large relative to the learning signal, and inability to converge to low-error solutions within polynomial gradient queries. The model exhibits systematic misclassification patterns that reflect its inability to capture the majority function's combinatorial structure.

First experiments:
1. Verify gradient variance bounds empirically on simplified Transformer variants with varying input dimensions
2. Test learning curves for majority functions across different training sample sizes and model architectures
3. Analyze attention weight distributions during training to identify patterns of optimization difficulty

## Open Questions the Paper Calls Out
None

## Limitations
- The analysis relies on a simplified Transformer variant that may not fully capture practical implementations
- Results focus specifically on majority functions and may not extend to other Boolean function classes
- Theoretical predictions require empirical validation on real-world Transformer architectures

## Confidence
High: The proof techniques for establishing lower bounds on generalization error in the simplified Transformer model are mathematically sound and the combinatorial analysis of gradient variance appears rigorous. The polynomial gradient query limitation is well-established within the theoretical framework.

Medium: The extension of results from the simplified model to practical Transformers requires additional empirical validation. The assumption that exponential sample complexity is necessary for majority function learning may not hold for all training scenarios or model variations.

Low: The applicability of these theoretical limitations to large-scale practical Transformers with modern training techniques (like pre-training, fine-tuning, or architectural modifications) remains uncertain without empirical verification.

## Next Checks
1. Empirical testing of the theoretical predictions on practical Transformer implementations across varying input dimensions and training sample sizes
2. Extension of the analysis to other Boolean function classes beyond majority functions to test the generality of the limitations
3. Investigation of whether architectural modifications (attention mechanisms, layer normalization, etc.) can overcome the identified learning barriers