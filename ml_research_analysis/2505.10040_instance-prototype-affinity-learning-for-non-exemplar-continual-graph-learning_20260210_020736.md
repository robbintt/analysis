---
ver: rpa2
title: Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning
arxiv_id: '2505.10040'
source_url: https://arxiv.org/abs/2505.10040
tags:
- learning
- task
- feature
- tasks
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of catastrophic forgetting in
  Graph Neural Networks (GNNs) under the Non-Exemplar Continual Graph Learning (NECGL)
  setting, where historical raw data is inaccessible. The proposed Instance-Prototype
  Affinity Learning (IPAL) framework combines Prototype Contrastive Learning (PCL)
  with three key innovations: Topology-Integrated Gaussian Prototypes (TIGP) that
  weight node contributions using PageRank to emphasize influential nodes, Instance-Prototype
  Affinity Distillation (IPAD) that aligns instance-prototype relationships to flexibly
  regularize feature space while maintaining compatibility with PCL, and a Decision
  Boundary Perception (DBP) mechanism that leverages high-entropy instances near decision
  boundaries to enhance inter-class separability.'
---

# Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning

## Quick Facts
- **arXiv ID:** 2505.10040
- **Source URL:** https://arxiv.org/abs/2505.10040
- **Reference count:** 40
- **Primary result:** Proposed IPAL framework outperforms state-of-the-art methods on node classification benchmarks while maintaining better plasticity-stability trade-offs.

## Executive Summary
This paper introduces the Instance-Prototype Affinity Learning (IPAL) framework for Non-Exemplar Continual Graph Learning (NECGL), addressing catastrophic forgetting when historical raw data is inaccessible. IPAL combines Prototype Contrastive Learning with three innovations: Topology-Integrated Gaussian Prototypes (TIGP) that weight nodes using PageRank, Instance-Prototype Affinity Distillation (IPAD) that aligns instance-prototype relationships, and Decision Boundary Perception (DBP) that enhances inter-class separability. The framework consistently outperforms existing methods across four node classification benchmarks while maintaining better trade-offs between plasticity and stability.

## Method Summary
The IPAL framework addresses catastrophic forgetting in GNNs under the NECGL setting by integrating Prototype Contrastive Learning (PCL) with three key innovations. TIGP constructs prototypes by weighting node contributions using PageRank to emphasize influential nodes. IPAD aligns instance-prototype relationships to provide flexible regularization while maintaining PCL compatibility. DBP leverages high-entropy instances near decision boundaries to enhance inter-class separability. The framework operates by constructing task-specific prototypes during training, then using these prototypes with contrastive learning to mitigate feature drift while preserving knowledge from previous tasks without requiring raw historical data.

## Key Results
- IPAL consistently outperforms state-of-the-art methods on four node classification benchmarks (CS-CL, CoraFull-CL, Arxiv-CL, Reddit-CL)
- The framework achieves superior average performance while maintaining better trade-offs between plasticity and stability
- IPAL addresses limitations of conventional Prototype Replay by reducing feature drift through PCL while providing more flexible knowledge retention compared to feature distillation approaches

## Why This Works (Mechanism)
IPAL works by creating a more robust representation learning framework that combines the strengths of prototype-based methods with contrastive learning. The TIGP component ensures that prototypes are built from influential nodes rather than simple averages, making them more representative of the underlying data distribution. IPAD provides a flexible regularization mechanism that aligns current instance-prototype relationships with historical patterns without the rigidity of direct feature matching. DBP enhances the decision boundary by focusing on uncertain instances, improving the model's ability to distinguish between classes in challenging regions of the feature space.

## Foundational Learning
- **Graph Neural Networks (GNNs):** Neural networks designed to operate on graph-structured data, aggregating information from neighboring nodes to learn node representations.
  - *Why needed:* Forms the foundation for processing graph-structured data in continual learning scenarios
  - *Quick check:* Verify understanding of message passing and aggregation mechanisms in GNNs

- **Catastrophic Forgetting:** The phenomenon where neural networks rapidly forget previously learned information when trained on new tasks
  - *Why needed:* Core problem IPAL aims to solve in continual graph learning
  - *Quick check:* Understand how forgetting manifests in sequential task learning

- **PageRank Centrality:** Algorithm that measures node importance based on the structure of incoming links, recursively weighting nodes by the importance of their neighbors
  - *Why needed:* Core mechanism for weighting node contributions in TIGP prototypes
  - *Quick check:* Verify understanding of how PageRank scores are computed and interpreted

- **Prototype Contrastive Learning:** Self-supervised learning approach that pulls instances toward class prototypes while pushing different class prototypes apart
  - *Why needed:* Foundation for the PCL component that drives feature space regularization
  - *Quick check:* Understand the contrastive loss formulation and its role in feature space organization

- **Knowledge Distillation:** Technique where a model learns to mimic the behavior of another model or itself from previous iterations
  - *Why needed:* Basis for the IPAD mechanism that aligns instance-prototype relationships across tasks
  - *Quick check:* Verify understanding of distillation loss and its application in continual learning

## Architecture Onboarding

**Component Map:** Raw Graph Data -> GNN Backbone -> TIGP Prototype Construction -> IPAD Distillation -> DBP Boundary Enhancement -> Contrastive Loss -> Updated Model

**Critical Path:** The essential sequence for IPAL's operation follows: feature extraction through GNN → prototype construction via TIGP → instance-prototype alignment through IPAD → decision boundary enhancement via DBP → final contrastive optimization.

**Design Tradeoffs:** IPAL trades computational overhead from PageRank calculations and entropy computations for improved representation quality and reduced forgetting. The framework balances between the stability of prototype-based methods and the flexibility of contrastive learning approaches.

**Failure Signatures:** Performance degradation may occur when graphs have significantly different structural properties across tasks, when PageRank centrality doesn't correlate with feature importance (heterophilic graphs), or when decision boundaries are inherently complex and high-entropy regions dominate the feature space.

**First Experiments:**
1. Verify TIGP prototype quality by comparing class separation metrics with mean-based prototypes on a simple graph dataset
2. Test IPAD regularization effectiveness by measuring feature drift between consecutive tasks
3. Evaluate DBP impact by comparing decision boundary sharpness with and without the high-entropy instance focus

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How can the IPAL framework be effectively adapted for online continual graph learning settings where data arrives in mini-batch streams rather than complete task batches?
- Basis in paper: The authors explicitly state in the Conclusion and Appendix C that future work will seek to adapt IPAL to "online settings, where data arrives in a mini-batch streaming manner."
- Why unresolved: The current implementation relies on clear task boundaries to perform Feature Drift Compensation and generate offline TIGP prototypes, operations designed for discrete task completion rather than continuous streaming.
- What evidence would resolve it: A modified framework demonstrating stable Average Performance on a streaming graph benchmark without access to explicit task identifiers or fixed task boundaries.

### Open Question 2
- Question: Can the IPAL framework generalize to cross-domain scenarios where tasks involve heterogeneous graphs rather than class-based partitions of a single unified graph?
- Basis in paper: Appendix C notes that current approaches simulate tasks via subgraph partitioning within a unified dataset, leaving "cross-domain generalizability... to be validated."
- Why unresolved: The TIGP component relies on PageRank calculations within a consistent structural context; shifting between graphs with vastly different topological properties may invalidate the fixed weighting assumptions.
- What evidence would resolve it: Empirical results showing IPAL's performance when sequential tasks are drawn from distinct graph datasets with different feature dimensions and structural patterns.

### Open Question 3
- Question: Does the reliance on PageRank for TIGP negatively impact performance on heterophilic graphs where neighbor features are dissimilar?
- Basis in paper: Section 4.1 posits that high-PageRank nodes are more "indicative," but this centrality assumption may fail in heterophilic graphs where high-degree nodes often connect to nodes of different classes.
- Why unresolved: The evaluation benchmarks are primarily homophilic citation or social networks; the paper does not test scenarios where structural importance diverges from feature similarity.
- What evidence would resolve it: A comparative ablation study on heterophilic benchmarks showing whether PageRank weighting degrades performance compared to mean-based prototypes.

## Limitations
- Evaluation limited to node classification tasks on four graph datasets, leaving generalization to other graph learning tasks unverified
- Computational overhead from PageRank calculations and DBP mechanism not explicitly quantified against baseline methods
- Performance on larger-scale graphs with millions of nodes remains unverified
- Specific PageRank parameter sensitivity and hyperparameter tuning requirements not thoroughly explored

## Confidence
**High Confidence:** The core contributions of TIGP, IPAD, and DBP are well-supported by theoretical motivation and experimental results. The framework's design addresses clear limitations in existing prototype-based continual learning methods.

**Medium Confidence:** The claim of "superior average performance" across all benchmarks is supported by experiments, but the relative improvements over state-of-the-art methods vary significantly across datasets, suggesting dataset-specific effectiveness that requires further investigation.

**Medium Confidence:** The assertion that IPAL provides a "better trade-off between plasticity and stability" is empirically demonstrated but could benefit from more quantitative analysis of forgetting measures and plasticity metrics across tasks.

## Next Checks
1. Conduct extensive ablation studies to isolate the individual contributions of TIGP, IPAD, and DBP components, including their performance under varying task sequence lengths and graph sizes.

2. Evaluate IPAL on additional graph learning tasks beyond node classification, particularly link prediction and graph classification, to assess cross-task generalization.

3. Perform computational complexity analysis comparing IPAL against baselines, specifically quantifying the additional memory and processing requirements introduced by the DBP mechanism and PageRank-based weighting.