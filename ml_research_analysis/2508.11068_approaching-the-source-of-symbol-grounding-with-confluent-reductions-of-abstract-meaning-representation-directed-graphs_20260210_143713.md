---
ver: rpa2
title: Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract
  Meaning Representation Directed Graphs
arxiv_id: '2508.11068'
source_url: https://arxiv.org/abs/2508.11068
tags:
- dictionaries
- reductions
- words
- dictionary
- definitions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper models dictionary definitions as AMR directed graphs
  to study symbol grounding, converting each definition into a graph where nodes represent
  concepts and arcs represent definitional relations. It applies graph reductions
  (LOOP, INCLIQUE, OUTCLIQUE, PIE) confluently to reduce the graphs while preserving
  feedback vertex sets.
---

# Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs

## Quick Facts
- arXiv ID: 2508.11068
- Source URL: https://arxiv.org/abs/2508.11068
- Authors: Nicolas Goulet; Alexandre Blondin Massé; Moussa Abdendi
- Reference count: 12
- Primary result: Converting dictionary definitions to AMR digraphs and applying confluent reductions identifies minimal grounding sets correlated with earlier-acquired, more abstract words.

## Executive Summary
This paper proposes a novel approach to symbol grounding by modeling dictionary definitions as Abstract Meaning Representation (AMR) directed graphs and applying confluent graph reductions to identify minimal grounding sets. The method converts each definition into a semantic graph where nodes represent concepts and arcs represent definitional relations, then systematically reduces these graphs while preserving feedback vertex sets. Experiments on 8 English dictionaries demonstrate that AMR representations yield smaller but denser kernels, with reduced kernels containing more abstract, earlier-acquired words. The approach advances the identification of primitive concepts requiring sensorimotor grounding rather than definitional closure.

## Method Summary
The method converts dictionary definitions into AMR digraphs by first rephrasing definitions using templates like "s is defined as d," then parsing with the bart model from AMRlib. The resulting AMR graphs are validated for define-01 root nodes and proper ARG1/ARG2 structure, with invalid graphs either patched or discarded. Individual definition graphs are merged into dictionary digraphs, then reduced using confluent operators (LOOP, INCLIQUE, OUTCLIQUE, SUBSET, PIE) in priority order. The reduced kernels are analyzed for psycholinguistic properties including age of acquisition and concreteness, with the goal of identifying minimum feedback vertex sets corresponding to grounding primitives.

## Key Results
- AMR digraphs produce smaller but denser kernels compared to plain-text dictionary representations
- Confluent reductions efficiently remove most vertices while preserving the minimum feedback vertex set
- Reduced kernels contain words with younger age of acquisition and higher abstractness
- 18-33% final validity rate for AMR parses across dictionaries, with 65-80% definition loss due to collisions and invalid parses
- OUTCLIQUE reduction dominates the reduction process in most dictionaries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AMR digraphs capture denser semantic relations than raw dictionary graphs, yielding larger kernels with fewer preserved definitions.
- Mechanism: Abstract Meaning Representation decomposes definitions into semantic role structures (ARG1, ARG2, etc.) rather than treating words atomically. This non-atomic representation maps polysemous words to distinct Propbank frames (e.g., admonish-01 vs. admonish-02), enabling more precise definitional arcs.
- Core assumption: Semantic role decomposition preserves definitional dependencies better than word-level co-occurrence.
- Evidence anchors:
  - [abstract] "AMR representations yield smaller but denser kernels"
  - [section 3.2] "AMR represents the concept of negation using polarity, or the notion of conjunction through instances like or"
  - [corpus] Corpus shows weak direct evidence; related papers focus on AMR parsing/generation, not grounding applications.
- Break condition: If AMR parsers produce invalid graphs (missing ARG1/ARG2, wrong root nodes) for >50% of definitions, semantic enrichment fails. Paper reports 18-33% final validity rate across dictionaries (Table 5).

### Mechanism 2
- Claim: Confluent reductions (LOOP, INCLIQUE, OUTCLIQUE, SUBSET, PIE) preserve the minimum feedback vertex set while deterministically simplifying dictionary graphs.
- Mechanism: These reductions remove vertices/arcs that cannot belong to any circuit or are guaranteed to be in/excluded from any MFVS. Confluence guarantees unique irreducible output regardless of reduction order, proved in Abdenabi et al. (2024).
- Core assumption: The circuit space of dictionary graphs encodes the grounding structure.
- Evidence anchors:
  - [section 4.2] "It was recently proved that the pointed operators... form a set of confluent reductions"
  - [section 5] "the majority of the reductions could be performed confluently" (Figure 9 shows OUTCLIQUE dominates)
  - [corpus] No corpus papers address confluent graph reductions for MFVS.
- Break condition: If dictionaries contain large acyclic subgraphs, confluent reductions alone insufficient; non-confluent DOME++ required for further reduction.

### Mechanism 3
- Claim: Reduced kernel words correlate with earlier age-of-acquisition and higher abstractness, consistent with grounding set hypotheses.
- Mechanism: Recursive removal of non-defined and non-defining words isolates the strongly-connected definitional core. Reductions eliminate vocabulary explainable through other paths, leaving primitives requiring sensorimotor grounding.
- Core assumption: Psycholinguistic variables (AoA, concreteness) proxy for grounding necessity.
- Evidence anchors:
  - [section 6] "As we reduce the directed graphs, the concepts are learned at a younger age and they become more abstract"
  - [figure 10] Violin plots show clear AoA/concreteness shifts in AMR dictionaries through reduction stages
  - [corpus] No corpus validation; psycholinguistic correlation is paper-internal.
- Break condition: If reduced kernels contain mostly concrete nouns rather than abstract relations, the method identifies basic-level categories rather than true grounding primitives.

## Foundational Learning

- Concept: **Feedback Vertex Set (FVS)**
  - Why needed here: The paper equates "grounding sets" (words needing direct experience) with minimum FVS (nodes whose removal breaks all definition cycles).
  - Quick check question: Given a graph with cycle A→B→C→A, which vertex sets break all cycles?

- Concept: **Abstract Meaning Representation (AMR)**
  - Why needed here: Definitions are converted to AMR graphs using Propbank frames, not raw words. Understanding ARG0/ARG1/ARG2 roles is essential.
  - Quick check question: How would AMR represent "the boy gave the girl a flower" differently from "a flower was given to the girl by the boy"?

- Concept: **Confluence in Rewrite Systems**
  - Why needed here: Reductions must yield unique irreducible graphs regardless of application order for reproducible grounding set identification.
  - Quick check question: If rules R1 and R2 both apply to a graph, does applying R1 then R2 give the same result as R2 then R1?

## Architecture Onboarding

- Component map: AMR Parser -> Validator/Patcher -> Polysemy Resolver -> Graph Union -> Reduction Engine -> MFVS Solver
- Critical path: Valid AMR generation -> Kernel extraction -> Confluent reduction -> MFVS solving. The 65-80% definition loss rate (Table 5: collisions, invalid parses) is the primary bottleneck.
- Design tradeoffs:
  - AMR vs. raw text: AMR captures richer semantics but loses more definitions (collisions, invalid parses)
  - Confluent vs. non-confluent: Confluent guarantees uniqueness; DOME++ achieves more reduction but sacrifices determinism
  - First-sense vs. all-senses: Paper uses first-sense to avoid WSD complexity; loses polysemy resolution benefits
- Failure signatures:
  - High invalid AMR rate (>50%): Parser mismatch with dictionary style; consider fine-tuning on definition sentences
  - Empty kernel after reduction: Dictionary too sparse or reduction rules too aggressive
  - No correlation with AoA/concreteness: Semantic representation not capturing grounding-relevant structure
- First 3 experiments:
  1. Parse 100 definitions through AMRlib, manually validate ARG1/ARG2 structure; measure validity rate by dictionary source
  2. Apply confluent reductions to WordNet kernel; verify confluence by running Algorithm 1 with shuffled reduction orders
  3. Extract reduced kernel from one dictionary, cross-reference with Brysbaert AoA norms; replicate Figure 10 correlation analysis

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do dictionary structures and their minimal grounding sets exhibit similar properties across different languages when modeled as AMR digraphs?
- Basis in paper: [explicit] The authors state: "we hope to extend our methods to dictionaries of different languages to see if dictionaries structures are similar across languages" and mention working toward French dictionaries.
- Why unresolved: The current study is limited to English dictionaries only; cross-linguistic data was not yet available at the time of writing.
- What evidence would resolve it: Applying the same AMR digraph methodology to dictionaries in multiple languages (e.g., French, Spanish, Mandarin) and comparing kernel sizes, reduction patterns, and MFVS composition across languages.

### Open Question 2
- Question: Can extending the semantic formalism from AMR to BabelNet-Meaning-Representation (BMR) improve grounding set identification by leveraging its multilingual, multi-modal, and disambiguated properties?
- Basis in paper: [explicit] The authors write: "We also hope to extend our semantic formalism to other languages by going from Abstract-Meaning-Representation to BabelNet-Meaning-Representation."
- Why unresolved: BMR integration was proposed as future work but not implemented or tested in the current study.
- What evidence would resolve it: Comparative experiments showing whether BMR-based dictionary graphs yield different kernel structures or more semantically meaningful grounding sets than AMR-based graphs.

### Open Question 3
- Question: How can graph reductions (INCLIQUE, OUTCLIQUE, PIE, DOME++) be better interpreted from a psycholinguistic perspective to explain why certain words are excluded from reduced kernels?
- Basis in paper: [explicit] The authors note: "the removal of edges is mostly justified by the pursuit of the MFVS and lacks a clear psycholinguistic motivation" and call for "a more in-depth study."
- Why unresolved: Current reductions are justified graph-theoretically but not psycholinguistically; the authors acknowledge this interpretability gap.
- What evidence would resolve it: Studies correlating specific reduction types with psycholinguistic variables (e.g., age of acquisition, concreteness) to establish cognitive plausibility of exclusion patterns.

## Limitations
- The approach depends heavily on AMR parser accuracy, which shows only 18-33% final validity rates across dictionaries
- High definition loss (65-80%) due to polysemy resolution and invalid AMRs may compromise grounding set comprehensiveness
- The correlation between reduced kernel properties and psycholinguistic variables is demonstrated only within the paper's own methodology, lacking external validation

## Confidence
- High confidence in confluent reduction mechanisms and graph theoretical foundations (proven in Abdenabi et al. 2024)
- Medium confidence in AMR parser integration and validation procedures, given the significant invalid parse rates
- Low confidence in the psycholinguistic grounding claims, as these rely solely on internal correlations without external validation

## Next Checks
1. Measure AMR parser validity rate on 100 randomly selected dictionary definitions across multiple dictionaries, comparing against reported 18-33% final rates
2. Apply confluent reductions to WordNet kernel and verify uniqueness of irreducible output by running reduction with multiple random orderings
3. Extract reduced kernel from one dictionary and cross-reference with external psycholinguistic databases (Brysbaert AoA norms, MRC database) to validate correlation patterns shown in Figure 10