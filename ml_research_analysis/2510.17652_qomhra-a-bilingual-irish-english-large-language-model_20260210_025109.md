---
ver: rpa2
title: 'Qomhra: A Bilingual Irish-English Large Language Model'
arxiv_id: '2510.17652'
source_url: https://arxiv.org/abs/2510.17652
tags:
- irish
- language
- data
- qomhr
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Qomhr\xE1, an 8B bilingual Irish-English\
  \ LLM developed under extremely low-resource constraints. The core method combines\
  \ bilingual continued pre-training, instruction tuning, and a novel synthetic human\
  \ preference dataset generation approach."
---

# Qomhra: A Bilingual Irish-English Large Language Model

## Quick Facts
- arXiv ID: 2510.17652
- Source URL: https://arxiv.org/abs/2510.17652
- Reference count: 12
- Primary result: 8B bilingual Irish-English LLM developed under extremely low-resource constraints

## Executive Summary
Qomhrá is an 8B bilingual Irish-English LLM developed under extremely low-resource constraints. The core method combines bilingual continued pre-training, instruction tuning, and a novel synthetic human preference dataset generation approach. To select a translator LLM, the authors conduct a human evaluation with L1 and L2 Irish speakers, ranking Google's Gemini-2.5-Pro highest. They then translate 30K English instruction-tuning samples to Irish and synthesize a 1K human preference dataset. Evaluation shows Qomhrá outperforms UCCIX by up to 29% in Irish and 44% in English across translation, gender understanding, topic identification, and world knowledge benchmarks.

## Method Summary
The paper introduces Qomhrá, an 8B bilingual Irish-English LLM developed under extremely low-resource constraints. The core method combines bilingual continued pre-training, instruction tuning, and a novel synthetic human preference dataset generation approach. To select a translator LLM, the authors conduct a human evaluation with L1 and L2 Irish speakers, ranking Google's Gemini-2.5-Pro highest. They then translate 30K English instruction-tuning samples to Irish and synthesize a 1K human preference dataset. Evaluation shows Qomhrá outperforms UCCIX by up to 29% in Irish and 44% in English across translation, gender understanding, topic identification, and world knowledge benchmarks.

## Key Results
- Qomhrá outperforms UCCIX by up to 29% in Irish and 44% in English across multiple benchmarks
- Synthetic preference data achieves near-perfect alignment (Cohen's κ = 0.978) with L1 speaker judgments
- The work provides a complete pipeline for developing LLMs in low-resource languages

## Why This Works (Mechanism)
The method succeeds by addressing the fundamental challenge of low-resource language modeling through synthetic data generation and careful model selection. By translating high-quality English instruction data and validating the translation process with human evaluators, the approach creates a bridge between abundant English resources and scarce Irish data. The synthetic preference dataset generation allows for effective alignment without requiring large-scale human annotation in the target language.

## Foundational Learning
- Bilingual continued pre-training: Why needed - To adapt the model to handle both languages effectively; Quick check - Evaluate bilingual perplexity on mixed-language corpora
- Instruction tuning: Why needed - To enable the model to follow natural language instructions in both languages; Quick check - Test performance on multilingual instruction-following benchmarks
- Synthetic human preference generation: Why needed - To align the model without requiring extensive human annotation in low-resource languages; Quick check - Validate synthetic preferences against human judgments
- Translation-based data augmentation: Why needed - To leverage abundant English resources for Irish language development; Quick check - Compare model performance with original vs. translated data
- Human evaluation for model selection: Why needed - To ensure translation quality from LLM translators; Quick check - Conduct blind human evaluations of translated outputs

## Architecture Onboarding

**Component Map:**
Llama-3-8B-Base -> Bilingual Continued Pre-training -> Instruction Tuning (translated) -> Synthetic Preference Alignment

**Critical Path:**
The critical path follows the progression from base model through bilingual pre-training, instruction tuning with translated data, and finally preference alignment using synthetic data. Each stage builds upon the previous one, with the synthetic preference alignment being particularly crucial for achieving the reported performance gains.

**Design Tradeoffs:**
The approach trades off potential information loss during translation against the practical necessity of leveraging existing English instruction data. The synthetic preference generation trades computational cost for reduced human annotation burden. The selection of a single translator LLM (Gemini-2.5-Pro) based on limited human evaluation may not capture all translation nuances.

**Failure Signatures:**
- Performance degradation in idiomatic Irish expressions
- Translation artifacts affecting instruction-following capabilities
- Over-reliance on English language patterns in Irish outputs
- Synthetic preference misalignment with actual human preferences in edge cases

**Three First Experiments:**
1. Evaluate zero-shot performance on Irish-specific cultural tasks not covered in the benchmark suite
2. Test whether using alternative translator LLMs with their respective synthetic preference datasets produces comparable alignment quality
3. Assess performance degradation when instruction-tuning data is randomly sampled versus translated

## Open Questions the Paper Calls Out
None

## Limitations
- The synthetic human preference dataset generation relies entirely on one translator LLM (Gemini-2.5-Pro) evaluated by only 10 participants
- The bilingual instruction tuning protocol uses translated English samples without systematic evaluation of translation quality or information loss
- The evaluation suite lacks zero-shot/cross-lingual generalization tests and Irish-specific cultural tasks beyond translation

## Confidence
- High confidence: Core methodology for bilingual continued pre-training and instruction tuning
- Medium confidence: Synthetic preference dataset generation and validation approach
- Medium confidence: Benchmark performance comparisons with UCCIX

## Next Checks
1. Evaluate Qomhrá's zero-shot performance on Irish-specific cultural tasks and idiomatic expressions not covered in the current benchmark suite
2. Test whether using alternative translator LLMs (Claude-3.5-Sonnet, GPT-4o-mini) with their respective synthetic preference datasets produces comparable alignment quality
3. Assess performance degradation when instruction-tuning data is randomly sampled versus translated, to quantify translation-induced information loss