---
ver: rpa2
title: 'Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language
  Models'
arxiv_id: '2511.20531'
source_url: https://arxiv.org/abs/2511.20531
tags:
- knowledge
- reasoning
- entities
- verification
- factual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a multi-hop reasoning framework for improving
  factual accuracy in vision-language models (VLMs) by leveraging structured knowledge
  graphs. The approach systematically verifies generated captions through visual entity
  recognition, knowledge graph traversal, and fact-based refinement using three knowledge
  representation formats (triples, hierarchical trees, and bullet-point facts).
---

# Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models

## Quick Facts
- arXiv ID: 2511.20531
- Source URL: https://arxiv.org/abs/2511.20531
- Authors: Shamima Hossain
- Reference count: 8
- This work introduces a multi-hop reasoning framework for improving factual accuracy in vision-language models (VLMs) by leveraging structured knowledge graphs.

## Executive Summary
This paper addresses the critical problem of hallucinated entities in vision-language model (VLM) image captions by introducing a multi-hop reasoning framework that leverages structured knowledge graphs. The approach systematically verifies generated captions through visual entity recognition, knowledge graph traversal, and fact-based refinement using three knowledge representation formats (triples, hierarchical trees, and bullet-point facts). Evaluated on a curated dataset of landmark images, the framework achieves a 31.8% reduction in hallucinated entities while demonstrating improved factual consistency. The modular design enables interpretable reasoning paths and supports various verification tasks, addressing a fundamental limitation in current VLMs for applications requiring high factual precision.

## Method Summary
The framework implements a multi-hop reasoning pipeline that enhances VLM-generated captions through systematic verification against structured knowledge. It begins with a VLM (Qwen2-VL-2B-Instruct) generating a base caption from an input image, followed by spaCy NER extracting named entities. These entities are then matched against a knowledge graph using both exact and fuzzy matching (all-MiniLM-L6-v2 embeddings with 0.85 threshold). Three knowledge representation formats—triple-based, hierarchical, and bullet-point—are used to verify factual claims, with results integrated through prompt engineering to regenerate corrected captions. The approach is evaluated on a curated dataset of 100 landmark images, measuring Entity Accuracy, Fact Verification Rate, and Caption Coherence.

## Key Results
- Achieved 31.8% reduction in hallucinated entities through systematic knowledge graph verification
- Hierarchical knowledge representation achieved highest Entity Accuracy (78.1%) but lowest caption coherence (4.1/5)
- Bullet-point representation maintained highest caption fluency (4.3/5) but lowest verification accuracy (65.7% EA)
- Modular framework enables interpretable reasoning paths and supports multiple verification tasks

## Why This Works (Mechanism)

### Mechanism 1: Entity Extraction and Knowledge Graph Matching
Extracting named entities from VLM-generated captions and matching them against a structured knowledge graph enables systematic identification of hallucinated entities. The framework uses spaCy's NER model to extract entities, then performs both exact matching and fuzzy matching (using all-MiniLM-L6-v2 sentence embeddings with a 0.85 confidence threshold) against the knowledge graph. This produces two sets: verified entities and potential hallucinations.

### Mechanism 2: Multi-Format Knowledge Representation for Verification
Using multiple knowledge representation formats (triple-based, hierarchical, bullet-point) enables more robust fact verification than any single format alone. Each format captures different types of relationships: triples capture direct (subject, relation, object) relationships; hierarchical trees capture containment and inheritance; bullet-points enable direct attribute lookup. The framework cross-validates across formats.

### Mechanism 3: Post-Hoc Caption Correction via Verified Facts
Injecting verified facts back into the VLM via prompt engineering produces factually improved captions while maintaining fluency. The correction hop synthesizes verification results (confirmed facts, discrepancies, confidence scores) and uses template-based prompt engineering to regenerate captions with corrected entities and relationships.

## Foundational Learning

- **Named Entity Recognition (NER)**: The framework relies on extracting entities from VLM captions as the first step in the verification pipeline. Without accurate NER, the knowledge graph matching step cannot function. *Quick check*: Can you explain how spaCy's NER model categorizes entities (FAC, GPE, ORG) and why entity type matters for downstream matching?

- **Knowledge Graph Traversal and Multi-Hop Reasoning**: The framework validates relationships by traversing paths in the knowledge graph (e.g., Lalbagh Fort → Located_In → Dhaka → Capital_Of → Bangladesh). Understanding path-based reasoning is essential for debugging verification failures. *Quick check*: Given a triple (A, relation, B) and (B, relation, C), what is a multi-hop inference, and what could cause it to fail?

- **Fuzzy Matching with Sentence Embeddings**: Exact string matching fails when VLMs generate variations (e.g., "Lalbagh Fort" vs. "Lalbagh Kella"). The framework uses embedding similarity with a threshold (0.85) to handle this. *Quick check*: What happens if the embedding threshold is set too low (e.g., 0.5) vs. too high (e.g., 0.95)?

## Architecture Onboarding

- **Component map**: Image → Base Caption → Entity Extraction → KG Matching → Verification → Corrected Caption
- **Critical path**: The Entity Extraction → KG Matching sequence is the bottleneck; if NER misses entities, downstream verification cannot recover them.
- **Design tradeoffs**: Hierarchical representation achieves best EA (78.1%) but reduces caption coherence (4.1/5). Bullet-point representation has highest coherence (4.3/5) but lowest EA (65.7%). Trade-off depends on use case (education vs. casual description).
- **Failure signatures**: Low confidence matches (< 0.85 threshold) indicate likely hallucinations or out-of-domain entities. Empty verification report suggests entity extraction failed or KG lacks coverage. Incoherent corrected captions indicate over-constrained prompt or conflicting facts.
- **First 3 experiments**:
  1. Run pipeline on 20 images with entity extraction logging to verify NER accuracy and KG match rates.
  2. Compare triple-only vs. hierarchical-only vs. bullet-only on same 20 images to confirm accuracy-coherence trade-offs.
  3. Vary fuzzy matching threshold (0.75, 0.85, 0.95) to determine optimal threshold for domain entity naming variance.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on landmark images with relatively complete knowledge graph coverage; performance on out-of-domain or novel entity types remains untested.
- Framework's reliance on spaCy NER may struggle with rare proper nouns or unusual entity types, potentially cascading errors into knowledge graph matching.
- 31.8% hallucination reduction is promising but based on a curated dataset; generalization to broader image domains is unproven.

## Confidence
- **High confidence**: Multi-format knowledge representation approach and its comparative performance (hierarchical 78.1% EA vs triples 72.3% vs bullet-points 65.7%)
- **Medium confidence**: Overall 31.8% hallucination reduction claim, given limited dataset size (100 images) and potential selection bias
- **Low confidence**: Generalization to non-landmark domains and robustness to rare entity types not present in the knowledge graph

## Next Checks
1. Evaluate framework on COCO Captions and Conceptual Captions subsets with minimal landmark content to measure performance degradation when knowledge graph coverage is sparse.
2. Create test set with rare proper nouns, compound entities, and ambiguous entity types to measure spaCy NER accuracy and its impact on downstream knowledge graph matching.
3. Systematically measure the relationship between KG coverage (percentage of entities with known facts) and verification accuracy to identify the minimum coverage threshold for reliable multi-hop reasoning.