---
ver: rpa2
title: Data-Efficient Multi-Agent Spatial Planning with LLMs
arxiv_id: '2502.18822'
source_url: https://arxiv.org/abs/2502.18822
tags:
- rollout
- arxiv
- taxi
- llms
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores using large language models (LLMs) to efficiently
  solve multi-agent taxi routing problems by leveraging world knowledge and prompting
  techniques. The approach involves converting environmental states and actions into
  natural language prompts for an LLM, which outputs decisions on where taxis should
  move or pick up passengers.
---

# Data-Efficient Multi-Agent Spatial Planning with LLMs
- arXiv ID: 2502.18822
- Source URL: https://arxiv.org/abs/2502.18822
- Reference count: 40
- Llama 3-8B fine-tuned model achieves lowest passenger waiting time across all load levels with 50x fewer environmental interactions than prior methods

## Executive Summary
This paper investigates using large language models for data-efficient multi-agent spatial planning in taxi routing problems. The approach encodes environmental states and actions into natural language prompts, allowing LLMs to leverage world knowledge for decision-making. Through zero-shot prompting and fine-tuning techniques, the method demonstrates strong performance while requiring significantly fewer environmental interactions than traditional approaches. The research shows that incorporating shortest-path information and using semantic prompts for environmental factors substantially improves planning outcomes.

## Method Summary
The approach converts multi-agent taxi routing problems into natural language prompts that capture environmental states, taxi locations, passenger requests, and available actions. LLMs process these prompts to output routing decisions, with performance enhanced through fine-tuning on collected trajectories. The method employs a rollout algorithm that combines LLM predictions with environmental feedback to iteratively improve decision quality. Shortest-path information is explicitly included in prompts to guide routing decisions, while semantic prompts encode environmental factors like weather conditions that affect travel times.

## Key Results
- Zero-shot LLM performance is surprisingly competitive with specialized methods
- Fine-tuning combined with rollout algorithm achieves 50x fewer environmental interactions than state-of-the-art graph neural networks
- Incorporating shortest-path information into prompts substantially improves routing efficiency
- Llama 3-8B fine-tuned model achieves lowest average passenger waiting time across all load levels

## Why This Works (Mechanism)
LLMs succeed in this spatial planning task by leveraging their extensive world knowledge encoded during pretraining. The natural language interface allows the model to reason about spatial relationships, traffic patterns, and optimal routing strategies using semantic understanding rather than purely mathematical optimization. The fine-tuning process adapts this general knowledge to specific environment dynamics while preserving the model's ability to generalize across different scenarios. The rollout algorithm provides a mechanism for iterative improvement by exposing the LLM to consequences of its decisions, enabling learning from experience with minimal environmental interaction.

## Foundational Learning
- **Natural Language Prompt Engineering**: Required to translate spatial planning problems into LLM-readable formats while preserving critical decision information
  - *Why needed*: Enables LLMs to process structured planning problems through their text-based interface
  - *Quick check*: Verify prompts contain all necessary state information and maintain consistent formatting

- **Multi-Agent Decision Theory**: Understanding how individual agent decisions aggregate to system-level outcomes
  - *Why needed*: Ensures LLM outputs coordinate effectively across multiple taxis
  - *Quick check*: Test whether joint decisions produce better system performance than greedy individual choices

- **Graph Neural Networks**: Provides baseline comparison for spatial reasoning capabilities
  - *Why needed*: Establishes performance benchmarks for specialized spatial planning architectures
  - *Quick check*: Compare LLM performance against GNN baselines across different load levels

- **Reinforcement Learning via Rollout**: Algorithm for improving decisions through simulated experience
  - *Why needed*: Enables efficient learning without extensive environmental interactions
  - *Quick check*: Measure performance improvement as rollout depth increases

## Architecture Onboarding

**Component Map**: Environment State -> Prompt Encoder -> LLM -> Decision Output -> Environment -> Feedback Loop -> Fine-tuning Module

**Critical Path**: The sequence from environment state observation through LLM decision to action execution and feedback collection represents the primary inference loop. Fine-tuning occurs asynchronously using collected trajectory data.

**Design Tradeoffs**: Natural language prompts provide flexibility and world knowledge leverage but introduce computational overhead and potential information loss compared to structured representations. The balance between prompt detail and LLM token limits affects performance.

**Failure Signatures**: Performance degradation occurs when prompts lack critical spatial information, when environmental dynamics change significantly from training conditions, or when passenger request patterns exceed the model's learned distribution.

**First Experiments**: 1) Zero-shot performance testing across varying passenger loads to establish baseline capabilities, 2) Ablation study removing shortest-path information from prompts to quantify its impact, 3) Fine-tuning performance comparison with different training data volumes to verify data efficiency claims.

## Open Questions the Paper Calls Out
None identified in source material.

## Limitations
- Evaluation restricted to single grid-based environment, limiting generalizability to complex real-world road networks
- Performance comparisons against only two baseline methods may not represent full solution landscape
- Simplified assumptions about passenger behavior and environmental dynamics may not hold in practice
- Limited testing of environmental variations beyond basic weather conditions

## Confidence
High confidence: Zero-shot LLM performance being competitive for this specific task; fine-tuning improves results; shortest-path information effectiveness
Medium confidence: 50x reduction in environmental interactions claim depending on baseline selection
Low confidence: Robustness across diverse real-world conditions given controlled evaluation environment

## Next Checks
1. Evaluate approach on complex, non-grid environments with irregular road networks and varying speed limits
2. Test fine-tuned model performance after deployment without further fine-tuning to assess degradation
3. Conduct ablation studies removing shortest-path information to quantify exact contribution to performance improvements