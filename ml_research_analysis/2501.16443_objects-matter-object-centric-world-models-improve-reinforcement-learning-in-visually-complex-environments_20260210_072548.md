---
ver: rpa2
title: 'Objects matter: object-centric world models improve reinforcement learning
  in visually complex environments'
arxiv_id: '2501.16443'
source_url: https://arxiv.org/abs/2501.16443
tags:
- uni00000013
- object
- learning
- uni00000052
- uni00000057
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces an object-centric world model for reinforcement
  learning that addresses the inefficiency of traditional pixel-based approaches in
  visually complex environments. The key insight is that using segmentation masks
  to extract object features through a pre-trained vision model allows agents to focus
  on decision-relevant elements rather than being dominated by large background areas.
---

# Objects matter: object-centric world models improve reinforcement learning in visually complex environments

## Quick Facts
- **arXiv ID**: 2501.16443
- **Source URL**: https://arxiv.org/abs/2501.16443
- **Reference count**: 40
- **Primary result**: OC-STORM achieves 134.8% human-normalized scores on Atari 100k (18/26 games) vs 114.2% for baseline STORM

## Executive Summary
This paper introduces OC-STORM, an object-centric world model that addresses the inefficiency of pixel-based reinforcement learning in visually complex environments. The key insight is that by using segmentation masks to extract object features through a pre-trained vision model, agents can focus on decision-relevant elements rather than being dominated by large background areas. OC-STORM integrates these object features with raw observations to predict environmental dynamics and trains policies using imagined trajectories. The method significantly outperforms the baseline STORM on both the Atari 100k benchmark and the visually complex game Hollow Knight, demonstrating faster convergence and stronger performance on challenging boss fights.

## Method Summary
OC-STORM builds on the STORM world model architecture by incorporating object-centric representations alongside raw pixel observations. The approach uses pre-trained segmentation masks to extract object features, which are then integrated with the raw visual input through a gated mechanism that determines how much weight to give each representation. The model predicts environmental dynamics using both object features and raw observations, enabling more efficient learning in visually complex environments. During training, policies are learned by imagining trajectories in the world model rather than requiring extensive real-environment interaction. The gated integration allows the model to dynamically balance between object-centric and pixel-based representations depending on the task requirements.

## Key Results
- OC-STORM outperforms baseline STORM on 18 of 26 Atari 100k games, achieving 134.8% human-normalized scores vs 114.2%
- On Hollow Knight, OC-STORM converges faster and achieves 100% win rates on certain boss fights vs 0% for baseline
- The object-centric approach demonstrates particular strength in environments with large background areas and multiple interacting objects

## Why This Works (Mechanism)
The method works by addressing a fundamental inefficiency in pixel-based RL: when large portions of the observation space are static or irrelevant (like backgrounds), learning dynamics becomes sample-inefficient. By extracting object features through segmentation masks, the model can focus on the elements that actually matter for decision-making. The gated integration mechanism allows the model to determine when object features are more informative versus when raw pixels are needed, providing flexibility across different visual environments. This selective attention to relevant visual elements reduces the effective dimensionality of the learning problem and enables more efficient policy learning.

## Foundational Learning
- **World Models in RL**: Why needed - enable learning through imagined trajectories instead of real interactions; Quick check - can the model generate plausible future states
- **Object-Centric Representations**: Why needed - reduce dimensionality by focusing on decision-relevant elements; Quick check - do object features capture essential dynamics
- **Segmentation Mask Integration**: Why needed - provide pre-structured object information to the model; Quick check - quality of object feature extraction
- **Gated Feature Integration**: Why needed - allow dynamic weighting between object and pixel representations; Quick check - does gating adapt to different environments
- **Sample Efficiency**: Why needed - reduce the number of environment interactions required; Quick check - compare learning curves with baseline methods

## Architecture Onboarding

Component Map:
Segmentation Mask Provider -> Object Feature Extractor -> Gated Integration -> World Model Dynamics -> Policy Learner

Critical Path:
Raw Observation + Object Features → Gated Integration → World Model → Imagined Trajectories → Policy Update

Design Tradeoffs:
- Pre-trained segmentation masks provide strong priors but limit generalization to novel environments
- Object features reduce dimensionality but may miss subtle pixel-level details
- Gated integration adds complexity but enables adaptive representation learning

Failure Signatures:
- Poor segmentation mask quality leading to noisy object features
- Gating mechanism stuck in local optima favoring one representation type
- World model failing to capture interactions between objects and background

Three First Experiments:
1. Test OC-STORM performance degradation when using imperfect segmentation masks
2. Compare gated vs fixed-weight integration of object and pixel features
3. Evaluate ablations with only object features vs only raw observations

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Evaluation limited to two domains (Atari 100k and Hollow Knight), raising generalizability concerns
- Reliance on pre-trained segmentation masks as input without addressing acquisition for novel environments
- Single-game evaluation for Hollow Knight results may not generalize to other complex games
- Unclear whether improvements come specifically from object-centric approach or other architectural differences

## Confidence
High: Core technical contribution of integrating object features with raw observations is well-executed; Atari 100k results are robust across multiple games
Medium: Hollow Knight results demonstrate potential for complex environments, though single-game evaluation limits generalizability
Low: Claims about handling truly novel visually complex environments given reliance on pre-trained segmentation masks

## Next Checks
1. Evaluate OC-STORM on additional visually complex RL benchmarks beyond Atari and Hollow Knight, including environments with varying visual complexity and object interaction patterns
2. Test performance degradation when using imperfect or noisy segmentation masks to understand robustness to segmentation quality
3. Compare against alternative approaches that use different forms of visual abstraction (e.g., attention mechanisms, saliency maps) to isolate specific benefits of object-centric representation