---
ver: rpa2
title: 'ENJ: Optimizing Noise with Genetic Algorithms to Jailbreak LSMs'
arxiv_id: '2509.11128'
source_url: https://arxiv.org/abs/2509.11128
tags:
- noise
- attack
- speech
- audio
- jailbreak
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes ENJ, a genetic algorithm-based method that optimizes
  environmental noise as an attack carrier to jailbreak Large Speech Models (LSMs).
  The method fuses malicious instructions with real-world noise samples and iteratively
  evolves them through crossover, mutation, and selection to create audio that sounds
  harmless to humans but bypasses model safety mechanisms.
---

# ENJ: Optimizing Noise with Genetic Algorithms to Jailbreak LSMs

## Quick Facts
- **arXiv ID:** 2509.11128
- **Source URL:** https://arxiv.org/abs/2509.11128
- **Reference count:** 0
- **Primary result:** Genetic algorithm-optimized environmental noise jailbreaks LSMs with 95% ASR and 4.74 HS

## Executive Summary
ENJ introduces a novel approach to jailbreaking Large Speech Models (LSMs) by leveraging environmental noise as an attack vector. The method employs a genetic algorithm to iteratively evolve noise samples that remain acoustically benign to human listeners while effectively bypassing model safety mechanisms. By fusing malicious instructions with real-world noise and optimizing through crossover, mutation, and selection, ENJ demonstrates that environmental audio can be weaponized to compromise LSM security. Experiments across four commercial LSMs show consistently high attack success, highlighting a significant vulnerability in current speech model defenses.

## Method Summary
ENJ operates by encoding malicious prompts into environmental noise using a genetic algorithm framework. The process begins with a population of noise samples carrying fused malicious instructions, which are then iteratively evolved through genetic operations—crossover, mutation, and selection—based on their ability to evade safety detection while maintaining acoustic plausibility. The optimization targets both Attack Success Rate (ASR) and Harmfulness Score (HS), ensuring the final audio is both effective and indistinguishable from harmless noise. This evolutionary process exploits the gap between human perception and model interpretation in complex acoustic environments.

## Key Results
- Achieves an average ASR of 95% across four LSMs
- Attains an average Harmfulness Score of 4.74
- Outperforms existing audio and text-based jailbreak baselines

## Why This Works (Mechanism)
ENJ exploits the perceptual mismatch between humans and LSMs in noisy environments. By optimizing environmental noise to carry hidden malicious intent, the method ensures the audio remains innocuous to human listeners while subtly manipulating model interpretation. The genetic algorithm enables fine-grained control over both acoustic properties and semantic payload, allowing the attack to bypass safety filters that rely on clean or structured input. This approach reveals that LSMs are particularly vulnerable to adversarial perturbations embedded in real-world acoustic contexts.

## Foundational Learning
- **Genetic Algorithms:** Evolutionary optimization technique for searching solution spaces; needed to iteratively refine noise samples toward desired adversarial properties.
- **Environmental Noise as Attack Vector:** Real-world audio background can carry hidden malicious instructions; needed to demonstrate a novel, practical attack surface.
- **Perceptual Gap Exploitation:** Difference between human and model interpretation of noisy audio; needed to ensure attack remains undetectable to users.
- **Attack Success Rate (ASR):** Metric quantifying the proportion of successful jailbreaks; needed to objectively measure attack effectiveness.
- **Harmfulness Score (HS):** Metric assessing the severity of jailbroken outputs; needed to evaluate the practical danger posed by successful attacks.

## Architecture Onboarding
- **Component Map:** Environmental noise samples -> Genetic algorithm (crossover, mutation, selection) -> Optimized adversarial audio -> LSM input
- **Critical Path:** Noise encoding → Genetic optimization → Attack evaluation → Model jailbreak
- **Design Tradeoffs:** Balancing acoustic plausibility (human perception) with attack efficacy (model bypass); genetic diversity vs. convergence speed.
- **Failure Signatures:** Low ASR indicates ineffective noise encoding or poor convergence; low HS suggests insufficient harmfulness in final output.
- **First Experiments:**
  1. Test baseline attack success on clean audio vs. environmental noise.
  2. Vary noise types (traffic, crowd, machinery) to assess generalization.
  3. Compare genetic algorithm convergence with random search for optimization efficiency.

## Open Questions the Paper Calls Out
None

## Limitations
- Results rely on a single environmental noise class (traffic), limiting generalization.
- No explicit worst-case or edge-case performance metrics provided.
- Defense evaluation against ENJ is absent, leaving practical mitigability uncertain.

## Confidence
- **95% ASR and 4.74 HS reliability:** Medium (averaged without uncertainty quantification, dependent on external APIs)
- **Environmental noise as "severe security threat":** Medium to High (consistent success, but limited noise diversity and no defense testing)
- **Superiority over baselines:** Medium (comparison details and statistical significance not provided)

## Next Checks
1. Replicate the attack on Whisper and Gemini Live using locally hosted or version-locked models to control for API variability.
2. Test the attack against a broader set of environmental noise samples (e.g., crowd, machinery, nature sounds) and measure performance variance.
3. Evaluate the attack's success when combined with existing audio safety mechanisms (e.g., speech enhancement, voice activity detection) to assess practical robustness.