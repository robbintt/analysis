---
ver: rpa2
title: Effects of Initialization Biases on Deep Neural Network Training Dynamics
arxiv_id: '2511.20826'
source_url: https://arxiv.org/abs/2511.20826
tags:
- loss
- training
- predicted
- class
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates how initialization biases, termed Initial\
  \ Guessing Bias (IGB), affect early-stage training dynamics in deep neural networks.\
  \ The authors examine how different loss functions\u2014Cross-Entropy (CE), Blurry\
  \ Loss (BL), and Piecewise-Zero Loss (PZ)\u2014interact with IGB during the initial\
  \ training phase on CIFAR-10 using a ResNet-50 architecture."
---

# Effects of Initialization Biases on Deep Neural Network Training Dynamics

## Quick Facts
- **arXiv ID**: 2511.20826
- **Source URL**: https://arxiv.org/abs/2511.20826
- **Reference count**: 24
- **Primary result**: Initialization biases cause early-class dominance that can be corrected by proper loss function choice

## Executive Summary
This study investigates how initialization biases, termed Initial Guessing Bias (IGB), affect early-stage training dynamics in deep neural networks. The authors examine how different loss functions—Cross-Entropy (CE), Blurry Loss (BL), and Piecewise-Zero Loss (PZ)—interact with IGB during the initial training phase on CIFAR-10 using a ResNet-50 architecture. IGB causes untrained networks to disproportionately favor certain classes, assigning high probabilities to a few classes and near-zero to others. Results show that CE quickly corrects this imbalance by providing strong gradients even for low-probability classes, leading to faster convergence and improved accuracy across all classes. BL achieves similar outcomes but at a slower rate, while PZ struggles to overcome IGB due to its gradient-suppressing nature, resulting in the initially favored class dominating throughout training. These findings emphasize the critical role of loss function choice in mitigating initialization biases and ensuring robust early-stage learning.

## Method Summary
The authors investigate initialization biases through controlled experiments on CIFAR-10 using ResNet-50 architecture. They define Initial Guessing Bias (IGB) as the tendency of untrained networks to assign disproportionately high probabilities to certain classes. Three loss functions are compared: Cross-Entropy (CE), Blurry Loss (BL), and Piecewise-Zero Loss (PZ). The experiments track how each loss function handles IGB during early training stages by monitoring class-wise probability distributions and gradient magnitudes. The study systematically varies initialization parameters and measures their impact on training dynamics, focusing on the critical first few epochs when IGB is most pronounced.

## Key Results
- Cross-Entropy loss effectively corrects IGB by providing strong gradients for all classes, including those initially assigned near-zero probabilities
- Blurry Loss achieves similar IGB correction but at a slower rate compared to Cross-Entropy
- Piecewise-Zero Loss fails to overcome IGB due to its gradient-suppressing properties, allowing the initially favored class to dominate training
- Loss function choice significantly impacts early-stage training dynamics and overall model performance

## Why This Works (Mechanism)
The mechanism behind IGB correction relates to gradient magnitude differences across loss functions. Cross-Entropy provides non-zero gradients for all class probabilities, enabling rapid correction of initial imbalances. When a class has very low initial probability, CE still generates substantial gradient signals that push the model to increase those probabilities. In contrast, Piecewise-Zero Loss effectively suppresses gradients for low-probability classes, preventing the model from correcting initial biases. This gradient availability difference explains why CE succeeds where PZ fails in overcoming IGB.

## Foundational Learning

**Initial Guessing Bias (IGB)**: The tendency of untrained networks to assign high probabilities to certain classes and near-zero to others. *Why needed*: Understanding IGB is crucial for diagnosing early training failures and designing better initialization schemes. *Quick check*: Examine softmax outputs of untrained networks across all classes.

**Gradient Magnitude Effects**: The relationship between loss function design and gradient strength for different probability ranges. *Why needed*: Determines how quickly a model can correct initialization biases. *Quick check*: Compare gradient magnitudes for low vs high probability classes under different loss functions.

**Early Training Dynamics**: The behavior of neural networks during the first few epochs when initialization effects are most pronounced. *Why needed*: Critical period where initialization biases can become entrenched. *Quick check*: Monitor class-wise accuracy and probability distributions during first 5-10 epochs.

## Architecture Onboarding

**Component Map**: ResNet-50 backbone -> Softmax layer -> Loss function -> Gradient computation -> Parameter updates

**Critical Path**: Initialization -> Forward pass (softmax) -> Loss computation -> Backward pass (gradient calculation) -> Parameter update

**Design Tradeoffs**: Strong gradients (CE) vs gradient suppression (PZ) - balancing rapid correction against stability concerns

**Failure Signatures**: Class dominance by initially favored class, poor convergence across multiple classes, gradient vanishing for low-probability classes

**First Experiments**:
1. Compare class-wise probability distributions before and after 1 epoch of training with different loss functions
2. Measure gradient magnitudes for low-probability vs high-probability classes under each loss function
3. Track convergence speed of initially under-represented classes across different loss functions

## Open Questions the Paper Calls Out
None

## Limitations
- Study focuses exclusively on ResNet-50 architecture, limiting generalizability to other network types
- Experiments conducted only on CIFAR-10 dataset, not testing scalability to larger, more complex datasets
- Definition of IGB relies on specific probabilistic assumptions about softmax outputs that may not capture all initialization bias forms

## Confidence
- **High**: Experimental observations regarding CE's superior performance in correcting IGB and PZ's difficulty overcoming it
- **Medium**: Theoretical explanations linking gradient magnitudes to IGB correction mechanisms
- **Low**: Broader claims about loss function design principles requiring validation across diverse architectures and tasks

## Next Checks
1. Replicate experiments on ImageNet and other large-scale datasets to test scalability of findings
2. Test the same initialization and loss function combinations on architectures beyond ResNet (CNNs, transformers, etc.) to assess architecture dependence
3. Implement and evaluate additional loss functions with intermediate gradient properties to map the full spectrum between CE and PZ behavior