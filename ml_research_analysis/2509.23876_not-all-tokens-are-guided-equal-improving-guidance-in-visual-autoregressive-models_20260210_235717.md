---
ver: rpa2
title: 'Not All Tokens are Guided Equal: Improving Guidance in Visual Autoregressive
  Models'
arxiv_id: '2509.23876'
source_url: https://arxiv.org/abs/2509.23876
tags:
- guidance
- diffusion
- sampling
- generation
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of misaligned guidance in autoregressive
  (AR) image generation models, particularly those using next-scale prediction. Unlike
  diffusion models, where guidance signals remain sharp and aligned to semantically
  important regions, AR models suffer from dispersed and progressively weaker guidance
  across sampling steps, leading to reduced image quality and coherence.
---

# Not All Tokens are Guided Equal: Improving Guidance in Visual Autoregressive Models

## Quick Facts
- arXiv ID: 2509.23876
- Source URL: https://arxiv.org/abs/2509.23876
- Reference count: 37
- Primary result: IGG achieves SOTA FID of 2.56 on ImageNet 512×512 class-conditioned generation

## Executive Summary
This paper addresses a fundamental problem in scale-wise autoregressive (SwAR) image generation: guidance signals become dispersed and lose alignment with semantically important regions as resolution increases, unlike in diffusion models. The authors propose Information-Grounding Guidance (IGG), which applies self-attention to guidance signals themselves, dynamically emphasizing tokens in foreground objects while suppressing background regions. IGG consistently outperforms classifier-free guidance (CFG) across both class-conditioned and text-to-image generation tasks, achieving state-of-the-art FID scores and providing interpretable metrics (evenness and divergence) that correlate with sampling quality.

## Method Summary
IGG modifies the standard CFG formulation by computing a "nudge" vector as the difference between conditioned and unconditioned logits. It then applies self-attention directly to these guidance vectors: tokens with nudges similar to other high-magnitude nudges receive higher weights, effectively anchoring guidance to semantically important clusters (typically foreground objects). The attention weights are computed via softmax over guidance vector products normalized by sqrt(vocab size), then applied element-wise to the guidance signal before adding to unconditional predictions. This approach ensures tighter alignment between guidance and content, improving overall image fidelity.

## Key Results
- Achieves new SOTA FID of 2.56 on ImageNet class-conditioned generation at 512×512 resolution, surpassing CFG's 2.61
- Improves text-to-image generation on Switti from GenEval 0.62 to 0.64 and FID from 17.6 to 16.9
- Provides interpretable metrics (evenness and divergence) that correlate with sampling quality and help optimize guidance weights
- Shows diminishing returns on smaller models, with significant gains primarily on larger backbones (VAR-d36 vs VAR-d30)

## Why This Works (Mechanism)

### Mechanism 1: Diagnosis of Guidance Dispersion in Scale-wise AR
In Scale-wise Autoregressive (SwAR) models, standard Classifier-Free Guidance (CFG) signals scatter and lose alignment with semantic objects as resolution increases. This dispersion occurs because "information inconsistencies" introduced by progressive scaling cause guidance signals to drift away from foreground objects, becoming evenly distributed across background and foreground tokens. High-quality generation requires guidance to be "uneven" (low evenness) and highly divergent from the background distribution, a pattern observed in successful diffusion models.

### Mechanism 2: Attention-Weighted Guidance Amplification (IGG)
Applying self-attention directly to guidance signals allows the model to dynamically amplify guidance for semantically important tokens. The method calculates a guidance nudge vector and applies self-attention over these nudges: tokens with nudges similar to other high-magnitude nudges receive higher weights. This effectively grounds the guidance to clusters of high-information pixels (e.g., foreground objects) and suppresses it in background regions, ensuring semantically important tokens receive stronger guidance signals.

### Mechanism 3: Evenness-Divergence Equilibrium
The optimal guidance weight corresponds to a balance point where "evenness" (distribution spread) and "divergence" (distance from unguided) metrics converge. Simply increasing guidance weight is insufficient; optimal FID is achieved when scaled evenness and divergence scores are approximately equal, suggesting a theoretical "sweet spot" for sampling quality. This equilibrium provides a principled way to tune guidance weights beyond empirical trial-and-error.

## Foundational Learning

- **Concept:** Classifier-Free Guidance (CFG)
  - Why needed here: IGG modifies the standard CFG formulation. You must understand that CFG creates a "nudge" vector by subtracting unconditioned logits from conditioned logits.
  - Quick check question: If `conditioned_score` is [0.8, 0.2] and `unconditioned_score` is [0.5, 0.5], what is the resulting CFG nudge vector for a guidance scale of 1.0?

- **Concept:** Scale-wise Autoregressive Modeling (SwAR)
  - Why needed here: The paper targets the specific failure of guidance in *multi-scale* prediction (predicting a map of tokens at once) vs. standard next-token prediction.
  - Quick check question: In SwAR, does the model predict a single token per step or a grid/map of tokens per step?

- **Concept:** Self-Attention on Signals
  - Why needed here: The core novelty applies attention to *guidance vectors*, not image features.
  - Quick check question: In standard self-attention $QK^T$, what do the Query and Key represent in the IGG formulation? (Answer: The guidance nudge vectors).

## Architecture Onboarding

- **Component map:** Backbone -> Guidance Calculator -> IGG Attention Module -> Logit Integrator
- **Critical path:** The critical implementation detail is Equation 6. Ensure the attention is computed over the guidance vectors *before* they are added back to final probabilities. The dimension of attention is $h_k w_k \times |V|$ (token count × vocab size).
- **Design tradeoffs:**
  - Global vs. Sliding Window Attention: Sliding window offers no quality gain but significant computational savings for high resolutions
  - Mixed Guidance: Combining CFG and IGG works well for text-to-image but requires tuning two weights ($w, w'$)
- **Failure signatures:**
  - Mode Collapse / Artifacts: If Evenness and Divergence are highly imbalanced
  - Marginal gains on small models: IGG relies on a reasonably strong backbone to extract useful attention maps
- **First 3 experiments:**
  1. Visualize Guidance Maps: Plot heatmaps of $\vec{p}$ for standard CFG vs. IGG to confirm "dispersed vs. grounded" hypothesis
  2. Metric Correlation Check: Plot FID vs. Guidance Weight with overlaid Evenness/Divergence curves to verify intersection point
  3. Sliding Window Ablation: Swap global attention for sliding window variant at 1024×1024 and measure latency vs. FID drop

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Why does applying IGG with a negative guidance weight improve sample quality in diffusion models, whereas a positive weight degrades it?
- **Basis in paper:** [explicit] Appendix A.5 states this is "based purely on empirical observations" and "would greatly benefit from further research"
- **Why unresolved:** The authors observe the phenomenon but lack theoretical explanation for why subtracting guidance signal is beneficial in diffusion models
- **What evidence would resolve it:** Theoretical analysis or ablation study connecting negative weighting to denoising trajectory and semantic refinement rates

### Open Question 2
- **Question:** Why does a mixed guidance scheme (combining CFG and IGG) improve text-to-image generation but fail to improve FID in class-conditioned generation?
- **Basis in paper:** [explicit] Section 6.4 notes the mixed scheme improved metrics but resulted in worse FID, calling for investigation on why mixing works well in diffusion modeling
- **Why unresolved:** The discrepancy suggests the balance between evenness and divergence is task-dependent or the equilibrium is disrupted by mixed approach in class-conditioned settings
- **What evidence would resolve it:** Comparative analysis of guidance signal distributions between class-conditioned and text-to-image models using mixed scheme

### Open Question 3
- **Question:** Can sliding-window attention mechanisms achieve performance parity with global attention in IGG for very high-resolution image generation?
- **Basis in paper:** [inferred] Section 6.4 tested sliding-window variant which showed no quality improvement, but Section 7 suggests future research on new strategies
- **Why unresolved:** Global attention is computationally expensive for large token maps, but tested sliding window did not yield same quality improvements
- **What evidence would resolve it:** Experiments on resolutions ≥1024×1024 comparing FID/IS and latency between global and optimized sliding-window attention

## Limitations

- The Evenness-Divergence equilibrium theory is derived primarily from experiments on two architectures and may not generalize to diverse backbone models
- IGG introduces additional computational overhead during sampling that could be significant for real-time applications at high resolutions
- The mixed guidance approach shows inconsistent benefits across different conditioning types, requiring additional hyperparameter tuning

## Confidence

**High Confidence (8-10/10):**
- The core mechanism of applying attention to guidance signals to emphasize semantically important tokens is well-defined and mathematically sound
- The improvement in FID scores over baseline CFG on ImageNet class-conditional generation (2.61 → 2.56) is statistically significant and reproducible
- The visualization evidence showing dispersed vs. grounded guidance patterns is compelling and directly supports the proposed solution

**Medium Confidence (5-7/10):**
- The Evenness-Divergence equilibrium theory as a general principle for guidance optimization
- The claim that IGG consistently outperforms CFG across all tested conditions
- The interpretation that guidance dispersion is a fundamental limitation of scale-wise autoregressive models

**Low Confidence (1-4/10):**
- The scalability of IGG to much higher resolutions (e.g., 1024×1024 or 2048×2048) without architectural modifications
- The performance of IGG on non-class-conditional generation tasks beyond the tested ImageNet and text-to-image benchmarks
- The claim that the attention mechanism amplifies signal rather than potentially amplifying noise in low-information regions

## Next Checks

**Validation Check 1:** Replicate the Evenness-Divergence correlation analysis on a third architecture (e.g., a standard next-token autoregressive model or a diffusion model) to test whether the equilibrium theory generalizes beyond VAR and Switti.

**Validation Check 2:** Implement a sliding window attention variant of IGG and systematically measure the FID-quality vs. computational latency tradeoff across resolutions from 256×256 to 1024×1024 to establish practical deployment boundaries.

**Validation Check 3:** Apply IGG to a conditional generation task with a different conditioning modality (e.g., segmentation maps or depth maps) to evaluate whether the guidance concentration mechanism works equally well when the conditioning signal has different semantic structures than text or class labels.