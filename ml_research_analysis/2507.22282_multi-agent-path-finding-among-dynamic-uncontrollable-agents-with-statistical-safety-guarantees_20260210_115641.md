---
ver: rpa2
title: Multi-Agent Path Finding Among Dynamic Uncontrollable Agents with Statistical
  Safety Guarantees
arxiv_id: '2507.22282'
source_url: https://arxiv.org/abs/2507.22282
tags:
- agents
- agent
- mapf
- prediction
- cp-solver
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses Multi-Agent Path Finding (MAPF) among dynamic
  uncontrollable agents (DUA), where controllable agents must navigate around unpredictable,
  non-cooperative agents in shared environments. The core method, CP-Solver, combines
  trajectory prediction with conformal prediction (CP) to quantify uncertainty and
  integrates these predictions into a modified Enhanced Conflict-Based Search (ECBS)
  algorithm.
---

# Multi-Agent Path Finding Among Dynamic Uncontrollable Agents with Statistical Safety Guarantees

## Quick Facts
- **arXiv ID:** 2507.22282
- **Source URL:** https://arxiv.org/abs/2507.22282
- **Reference count:** 6
- **Primary result:** CP-Solver combines trajectory prediction with conformal prediction to provide statistical safety guarantees while achieving competitive throughput in MAPF scenarios with dynamic uncontrollable agents.

## Executive Summary
This paper introduces CP-Solver, a method for Multi-Agent Path Finding (MAPF) that enables controllable agents to navigate safely among dynamic uncontrollable agents with statistical guarantees. The approach combines trajectory prediction with conformal prediction (CP) to quantify uncertainty and integrates these predictions into a modified Enhanced Conflict-Based Search (ECBS) algorithm. CP-Solver operates in both one-shot and lifelong settings, using rolling horizon conflict resolution. Experiments demonstrate that CP-Solver achieves competitive throughput, reduced collisions, and provides statistical safety guarantees (δ=0.05) with collision rates below the failure probability bound.

## Method Summary
CP-Solver combines trajectory prediction with conformal prediction to provide statistical safety guarantees in MAPF scenarios with dynamic uncontrollable agents. The method uses a predictor (LSTM) to estimate future positions of uncontrollable agents, then applies conformal prediction to compute statistically valid confidence intervals around these predictions. These intervals are discretized onto the graph and integrated into Enhanced Conflict-Based Search (ECBS), where conflicts involving uncontrollable agents result in asymmetric constraints applied only to controllable agents. The system operates in both one-shot (open-loop) and lifelong (closed-loop) settings, with the closed-loop version using rolling horizon replanning to maintain feasibility over time.

## Key Results
- CP-Solver achieves collision rates below the theoretical bound δ=0.05 across all tested scenarios
- Competitive throughput compared to state-of-the-art MAPF methods while providing safety guarantees
- Statistical safety guarantees are maintained even as prediction accuracy varies
- The method scales to lifelong missions through a receding horizon sequence of one-shot instances

## Why This Works (Mechanism)

### Mechanism 1: Statistical Uncertainty Quantification via Conformal Prediction
The system guarantees that the true location of an uncontrollable agent falls within the computed interval with probability ≥ 1 - δ. It uses calibration data to compute nonconformity scores and selects a quantile value based on the user-defined failure rate δ, converting point estimates into statistically valid confidence sets. The core assumption is that the data distribution of uncontrollable agents is stationary or shifts minimally.

### Mechanism 2: Asymmetric Constraint Generation in Conflict-Based Search
The solver projects continuous CP intervals onto discrete graph vertices. When a conflict is detected between a controllable agent and a CP interval vertex, a constraint is generated only for the controllable agent, effectively giving uncontrollable agents "right-of-way." This forces the controllable fleet to navigate around uncertainty regions.

### Mechanism 3: Rolling Horizon Re-planning for Drift Correction
The closed-loop solver operates on a window H, observing current states, planning a path for t to t+H, and executing only the first H steps before re-planning. This discards stale long-term predictions and recalibrates the CP intervals based on new observations, correcting for drift in agent behavior or environment changes.

## Foundational Learning

- **Concept: Conformal Prediction (CP)**
  - **Why needed here:** CP is the mathematical engine providing the "statistical safety guarantee"
  - **Quick check question:** If I increase the calibration dataset size |D_cal|, how does the precision of the δ-quantile change, and does it make the intervals tighter or looser? (Answer: More data improves quantile estimation precision but does not inherently tighten intervals unless the predictor itself improves)

- **Concept: Conflict-Based Search (CBS)**
  - **Why needed here:** The paper modifies CBS to handle dynamic agents
  - **Quick check question:** In standard CBS, if Agent A and Agent B collide, how many child nodes are created in the constraint tree? (Answer: Two, one with a constraint on A, one on B)

- **Concept: Exchangeability**
  - **Why needed here:** This is the core statistical assumption for CP validity
  - **Quick check question:** Does the sequence of prediction errors need to be independent for CP to work, or just exchangeable?

## Architecture Onboarding

- **Component map:** Predictor (LSTM) -> Calibrator (Algorithm 1) -> Discretizer -> Planner (CP-Solver/Algorithm 2)
- **Critical path:** The Discretizer is the fragile bridge. If CP intervals are large, the Discretizer will mark huge swathes of the graph as forbidden, quickly leading to solver failure.
- **Design tradeoffs:**
  - Safety (δ) vs. Solvability: Lower δ inflates intervals, potentially blocking all corridors
  - Horizon (H) vs. Runtime: Longer H improves long-term planning but increases prediction uncertainty and ECBS tree depth
- **Failure signatures:**
  - Infinite Loops/Timeouts: Often caused by intervals blocking the goal vertex
  - Collision Rate > δ: Indicates distribution shift or bugs in discretization logic
- **First 3 experiments:**
  1. Calibration Validation: Run Algorithm 1 on held-out test data to verify empirical coverage matches 1 - δ
  2. Stress Test Density: Fix predictor accuracy and vary uncontrollable agents to find density threshold where "Infeasible" error rate spikes
  3. Ablation on Safety: Compare throughput when δ=0.01 vs. δ=0.2 to quantify the "cost of safety"

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can statistical safety guarantees be preserved when controlled agents influence the behavior of dynamic uncontrollable agents (violating Assumption 2)?
- Basis in paper: [explicit] The authors note that while Assumption 2 holds approximately for socially acceptable robots, "in cases where such interaction is present, robust uncertainty quantification could help preserve guarantees."
- Why unresolved: The current method assumes independence between controlled and uncontrolled agents, a condition that fails in interactive or adversarial environments.
- What evidence would resolve it: Empirical results from simulations where dynamic agents react to controlled agents, demonstrating that collision bounds remain satisfied under robust uncertainty quantification.

### Open Question 2
- Question: To what extent does CP-Solver maintain safety guarantees and throughput under significant distribution shifts between training data and deployment environments?
- Basis in paper: [explicit] The conclusion explicitly lists "robustness to distribution shifts" as a focus for future work, acknowledging CP's vulnerability to shifts despite theoretical robustness under small perturbations.
- Why unresolved: The experiments use A* agents for dynamic trajectories, which may not fully represent real-world human unpredictability or distinct operational domains.
- What evidence would resolve it: Testing CP-Solver on out-of-distribution datasets or environments with significantly different agent dynamics while monitoring collision rates relative to the δ bound.

### Open Question 3
- Question: Can CP-Solver be integrated with continuous-space MAPF algorithms without compromising statistical guarantees or real-time applicability?
- Basis in paper: [explicit] The real-time applicability section suggests future work could "integrate CP-Solver with continuous-space forms of MAPF."
- Why unresolved: The current formulation relies on discrete graphs (G=(V,E)) and a specific discretization step for CP intervals, which may not translate directly to continuous domains.
- What evidence would resolve it: A formulation of CP intervals in continuous coordinates that integrates with a continuous MAPF solver, demonstrating comparable statistical safety bounds.

## Limitations

- The method assumes exchangeability between calibration and test data, which may not hold in adversarial or highly interactive environments
- Large CP intervals from poor prediction accuracy can block all paths, causing solver failure
- Runtime scalability to very large agent populations (>100 agents) and extremely dense environments is not explored

## Confidence

- **High Confidence:** The core mechanism of asymmetric constraint generation in ECBS and the rolling horizon replanning strategy
- **Medium Confidence:** The statistical safety guarantee, which relies on CP assumptions that may not hold in adversarial or highly dynamic environments
- **Low Confidence:** Runtime scalability to very large agent populations (>100 agents) and extremely dense environments

## Next Checks

1. **Distribution Shift Stress Test:** Systematically vary the behavior of uncontrollable agents (e.g., introduce aggressive or evasive patterns) and measure whether collision rates remain within the δ bound. This directly tests the exchangeability assumption.

2. **Calibration Sensitivity Analysis:** Run Algorithm 1 with varying calibration dataset sizes and compositions to quantify how interval size and collision rate vary. This would reveal the minimum viable calibration requirements.

3. **Extreme Density Failure Point:** Incrementally increase the number of uncontrollable agents until the solver consistently fails to find solutions, identifying the environmental density threshold where the method breaks down.