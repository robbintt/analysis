---
ver: rpa2
title: 'Concept than Document: Context Compression via AMR-based Conceptual Entropy'
arxiv_id: '2511.18832'
source_url: https://arxiv.org/abs/2511.18832
tags:
- context
- semantic
- compression
- language
- concepts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of information overload in long-context
  processing for large language models, particularly in retrieval-augmented generation
  tasks where extensive supporting documents introduce redundant content that degrades
  reasoning accuracy and increases computational overhead. The proposed method introduces
  an unsupervised context compression framework that leverages Abstract Meaning Representation
  (AMR) graphs and information-theoretic principles to identify and preserve semantically
  essential information while filtering out irrelevant content.
---

# Concept than Document: Context Compression via AMR-based Conceptual Entropy

## Quick Facts
- arXiv ID: 2511.18832
- Source URL: https://arxiv.org/abs/2511.18832
- Reference count: 32
- Primary result: 50% context reduction with improved RAG accuracy

## Executive Summary
This paper addresses information overload in long-context processing for large language models by proposing an unsupervised context compression framework. The method leverages Abstract Meaning Representation (AMR) graphs and information-theoretic principles to identify and preserve semantically essential information while filtering out redundant content. By focusing on conceptual entropy at the node level of AMR graphs, the approach effectively reconstructs condensed contexts that maintain core semantic information while reducing computational overhead.

## Method Summary
The proposed framework constructs AMR graphs from raw contexts and computes node-level conceptual entropy to estimate the importance of each semantic concept. Statistical significance testing identifies high-information nodes that form the backbone for reconstructing a condensed context. This unsupervised approach operates without requiring labeled data for training, making it broadly applicable across different domains and document types. The method demonstrates substantial performance improvements over vanilla RAG and existing compression baselines while achieving approximately 50% context reduction.

## Key Results
- Achieved higher accuracy than vanilla RAG while reducing context length by approximately 50%
- Demonstrated consistent gains across different model sizes
- Showed particular effectiveness in long-context scenarios with lower variance across backbone LLMs

## Why This Works (Mechanism)
The method works by leveraging AMR graphs to represent semantic structure and computing conceptual entropy to identify information-rich nodes. This information-theoretic approach captures the intrinsic importance of semantic concepts rather than relying on surface-level features. Statistical significance testing ensures that only genuinely informative nodes are preserved, creating a compressed context that maintains the semantic backbone necessary for accurate reasoning and generation.

## Foundational Learning
- **AMR Graphs**: Abstract Meaning Representation captures semantic structure independent of syntactic variations - needed to normalize diverse expressions of the same meaning; quick check: verify AMR parser accuracy on domain-specific terminology
- **Conceptual Entropy**: Information-theoretic measure of uncertainty at semantic nodes - needed to quantify information content beyond simple frequency; quick check: validate entropy distribution matches human judgment of concept importance
- **Statistical Significance Testing**: Filters noise from signal in semantic selection - needed to avoid including spurious correlations; quick check: compare compression results with/without significance filtering

## Architecture Onboarding
**Component Map**: Context -> AMR Parser -> Conceptual Entropy Computation -> Statistical Significance Testing -> Context Reconstruction
**Critical Path**: The AMR parsing step is the primary bottleneck, as downstream entropy computation and reconstruction depend entirely on parsing quality
**Design Tradeoffs**: Unsupervised approach trades supervised fine-tuning precision for broader applicability and no training data requirements
**Failure Signatures**: Poor AMR parsing quality directly degrades downstream compression effectiveness; domain-specific terminology may not be well-represented in AMR structures
**First Experiments**: 
1. Benchmark AMR parser performance on domain-specific corpus
2. Compare conceptual entropy rankings with human-annotated importance scores
3. Test compression effectiveness across varying document lengths and complexities

## Open Questions the Paper Calls Out
The paper identifies major uncertainties regarding performance in multi-document scenarios and scalability to domains with different linguistic characteristics. The evaluation focuses on English-language datasets, leaving open questions about cross-linguistic applicability and performance with morphologically rich languages. While the method shows consistent gains across different model sizes, the specific architecture choices for AMR parsing and sensitivity to parser quality represent potential bottlenecks not thoroughly explored.

## Limitations
- Performance in multi-document scenarios remains uncertain
- Scalability to morphologically rich languages not validated
- AMR parser quality sensitivity not thoroughly characterized

## Confidence
- **High confidence**: The core information-theoretic framework for semantic concept preservation demonstrates theoretical soundness and experimental validation on benchmark datasets
- **Medium confidence**: The 50% context reduction claim requires careful interpretation, as compression rates likely vary significantly with document complexity and domain specificity
- **Medium confidence**: Generalizability across diverse domains remains underexplored, with current validation limited to question-answering contexts

## Next Checks
1. Conduct ablation studies isolating the contribution of AMR parsing quality versus the entropy-based selection mechanism to quantify each component's impact on final performance
2. Test the method on multi-lingual and morphologically complex languages to evaluate cross-linguistic robustness and identify potential architectural adaptations needed
3. Perform extensive analysis on varying document types (scientific literature, legal documents, social media) to establish compression effectiveness across diverse semantic structures and writing styles