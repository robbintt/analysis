---
ver: rpa2
title: LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination
  with Causal Prompt Engineering
arxiv_id: '2509.10818'
source_url: https://arxiv.org/abs/2509.10818
tags:
- questions
- expert
- have
- generalized
- mental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a method to mitigate hallucinations in large
  language models (LLMs) by incorporating domain expert mental models (EMMs) through
  causal prompt engineering. The approach uses monotone Boolean and k-valued functions
  to create computationally tractable expert models via optimized human-machine dialogue,
  structured in four steps: factor identification, hierarchical structuring, generalized
  model specification, and detailed model generation.'
---

# LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering

## Quick Facts
- arXiv ID: 2509.10818
- Source URL: https://arxiv.org/abs/2509.10818
- Reference count: 21
- This paper presents a method to reduce LLM hallucinations by incorporating domain expert mental models through causal prompt engineering

## Executive Summary
This paper introduces a novel approach to mitigate hallucinations in large language models (LLMs) by integrating domain expert mental models (EMMs) through causal prompt engineering. The method employs monotone Boolean and k-valued functions to create computationally tractable expert models via optimized human-machine dialogue. The four-step process involves factor identification, hierarchical structuring, generalized model specification, and detailed model generation. Through case studies in proposal evaluation, cybersecurity design, and healthcare decisions, the authors demonstrate significant reduction in the number of questions needed from domain experts while maintaining accuracy.

## Method Summary
The proposed method uses monotone Boolean and k-valued functions to create computationally tractable expert models through optimized human-machine dialogue. The process consists of four steps: (1) identifying decision factors and their values, (2) organizing these factors hierarchically, (3) specifying the generalized model with qualitative variables and their causal relations, and (4) generating the detailed model with quantitative relations. This structured approach enables efficient elicitation of expert knowledge while reducing the cognitive burden on domain experts. The method leverages monotonicity properties to minimize the number of questions needed, achieving dramatic reductions in scenario complexity - for instance, reducing a 20-factor decision task from over one million scenarios to just 11 questions.

## Key Results
- Demonstrated significant reduction in expert consultation time through optimized questioning (20-factor proposal task reduced from 1,048,576 scenarios to 11 questions)
- Case studies show effectiveness across diverse domains including proposal evaluation, cybersecurity design, and healthcare decisions
- Method outperforms traditional aggregation logic while providing interpretable, explainable decision support
- Successfully composed multiple decision models for complex, multi-domain problems

## Why This Works (Mechanism)
The method works by systematically extracting and formalizing expert mental models through structured dialogue that exploits monotonicity properties. By using monotone Boolean and k-valued functions, the approach creates computationally efficient representations of expert knowledge that can be directly incorporated into LLM prompts. The hierarchical organization of factors and causal relations allows for efficient information gathering through targeted questions that maximize information gain while minimizing redundancy. This structured approach ensures that the LLM's responses are grounded in validated expert knowledge rather than being based on patterns learned from potentially noisy training data.

## Foundational Learning
- Monotone Boolean Functions: Why needed - to create computationally efficient representations of expert knowledge that preserve directional relationships; Quick check - verify that the function correctly represents monotonic relationships between factors
- K-valued Functions: Why needed - to handle multi-valued decision factors beyond simple binary choices; Quick check - ensure the function correctly maps all possible combinations of input values
- Hierarchical Factor Organization: Why needed - to structure complex decision spaces in a way that enables efficient knowledge elicitation; Quick check - validate that the hierarchy correctly captures causal relationships between factors
- Optimized Questioning: Why needed - to minimize the number of questions needed from experts while maximizing information gain; Quick check - verify that each question provides maximum new information
- Monotonicity Properties: Why needed - to exploit directional relationships for efficient knowledge extraction; Quick check - ensure that the extracted knowledge preserves monotonic relationships

## Architecture Onboarding

Component Map:
Expert Knowledge -> Factor Identification -> Hierarchical Structuring -> Generalized Model -> Detailed Model -> LLM Prompt Engineering

Critical Path:
Factor Identification -> Hierarchical Structuring -> Generalized Model -> Detailed Model -> LLM Prompt Engineering

Design Tradeoffs:
- Depth vs. Breadth: Deeper hierarchies provide more granular control but increase complexity; Shallower hierarchies simplify the model but may miss important nuances
- Quantitative vs. Qualitative: Quantitative models provide more precision but require more data; Qualitative models are easier to elicit but less precise
- Monotonicity Assumption: Assumes monotonic relationships between factors, which may not hold in all domains

Failure Signatures:
- Oversimplification: Model becomes too simplistic to capture important domain nuances
- Expert Fatigue: Too many questions lead to reduced expert engagement and potential errors
- Monotonicity Violation: Real-world relationships don't follow assumed monotonic patterns
- Composition Complexity: Combining multiple models becomes intractable for very complex problems

Three First Experiments:
1. Test the factor identification step with a simple binary decision problem to verify the monotonicity assumption
2. Validate the hierarchical structuring process by comparing expert-provided hierarchies with automatically generated ones
3. Evaluate the questioning optimization by measuring information gain per question in a controlled domain

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- The method's reliance on expert availability and willingness to engage in structured dialogue may limit implementation in resource-constrained settings
- The scalability to more complex, real-world decision spaces with hundreds of factors remains unverified
- The connection between expert mental models and actual hallucination reduction in LLMs needs direct experimental demonstration
- While interpretability is claimed, the evaluation of explainability quality is not thoroughly addressed

## Confidence
- Effectiveness of computational tractability claims for 20-factor decision tasks: High confidence
- Generalizability of four-step methodology across diverse domains: Medium confidence
- Connection between expert mental models and prompt engineering for hallucination mitigation: Low confidence

## Next Checks
1. Conduct controlled experiments measuring hallucination reduction rates when applying the causal prompt engineering approach versus baseline LLM responses across multiple domains
2. Test the scalability of the factor identification and hierarchical structuring steps with decision problems involving 50+ factors to verify computational tractability claims
3. Perform user studies with domain experts to evaluate the efficiency and accuracy of the structured elicitation process compared to traditional expert consultation methods