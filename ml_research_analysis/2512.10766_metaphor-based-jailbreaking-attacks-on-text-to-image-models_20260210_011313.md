---
ver: rpa2
title: Metaphor-based Jailbreaking Attacks on Text-to-Image Models
arxiv_id: '2512.10766'
source_url: https://arxiv.org/abs/2512.10766
tags:
- adversarial
- sensitive
- attack
- prompts
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces MJA, a metaphor-based jailbreaking method
  for text-to-image models that generates adversarial prompts by combining metaphorical
  descriptions with contextual cues. It employs a three-agent LLM framework to retrieve
  metaphors, match contexts, and generate diverse prompts, then optimizes selection
  using a surrogate model and Bayesian acquisition strategy.
---

# Metaphor-based Jailbreaking Attacks on Text-to-Image Models

## Quick Facts
- arXiv ID: 2512.10766
- Source URL: https://arxiv.org/abs/2512.10766
- Reference count: 40
- Key result: 0.98 bypass rate and 0.76 attack success rate on Stable Diffusion models

## Executive Summary
This paper introduces MJA, a metaphor-based jailbreaking method that generates adversarial prompts to bypass safety filters in text-to-image models. The system employs a three-agent LLM framework to decompose prompt generation into metaphor retrieval, context matching, and prompt synthesis, producing diverse adversarial prompts that indirectly reference sensitive content. A Bayesian optimization module with surrogate modeling enables efficient prompt selection with minimal queries to the target model. Evaluated against eight external and seven internal defenses on Stable Diffusion and other T2I models, MJA achieves high bypass rates while outperforming six baselines in both effectiveness and query efficiency.

## Method Summary
MJA uses a three-agent LLM system to generate metaphor-rich adversarial prompts: the Metaphor Agent retrieves imagery from fiction, the Context Agent matches artistic styles, and the Prompt Agent synthesizes both into candidate prompts. These candidates are optimized using a surrogate model (Gaussian Process Regression) and Expected Improvement acquisition strategy, which balances exploitation and exploration to identify effective prompts with minimal queries to the black-box T2I system. The method achieves high success rates by leveraging figurative language that evades keyword-based filters while remaining interpretable by T2I models trained on large text-image corpora.

## Key Results
- 0.98 bypass rate and 0.76 attack success rate on Stable Diffusion models
- Requires 7-8 queries on average versus 23-24 for baseline methods
- Strong cross-model transferability with 30-50% ASR-C drop when applying prompts across different T2I architectures

## Why This Works (Mechanism)

### Mechanism 1: Metaphor-based Semantic Obfuscation
Metaphorical descriptions convey sensitive semantics while evading keyword-based and semantic filters by decomposing content into metaphor + context pairs that indirectly reference target concepts, making detection difficult while remaining interpretable by T2I models.

### Mechanism 2: Multi-Agent Task Decomposition
Specialized LLM agents (Metaphor, Context, Prompt) with distinct objectives produce more diverse adversarial prompts than monolithic generation, coordinated through shared memory and in-context learning.

### Mechanism 3: Bayesian Optimization for Query Efficiency
Gaussian Process Regression trained on small observation sets predicts attack success, with Expected Improvement acquisition balancing exploitation (high predicted success) and exploration (high uncertainty) to identify effective prompts with minimal queries.

## Foundational Learning

- **Gaussian Process Regression for Surrogate Modeling**: GPR provides both predictions μ(x) and uncertainty estimates σ²(x), enabling acquisition strategy to balance exploitation vs exploration. Quick check: In Eq. 14, what does high variance σ²(x_adv) indicate about a candidate prompt, and how should that affect the acquisition decision?

- **Expected Improvement (EI) Acquisition Function**: EI selects the next candidate to query, with two terms involving Φ(Z) and ϕ(Z) that dominate differently based on uncertainty level. Quick check: In Eq. 15, which term dominates when uncertainty σ is very high vs very low?

- **In-Context Learning with Shared Memory**: Agents retrieve relevant examples from successful past attacks to guide generation; understanding this mechanism is critical for debugging poor agent performance. Quick check: If CLIP-based retrieval returns examples with low cosine similarity to current sensitive prompt, what impact would that have on agent output quality?

## Architecture Onboarding

- **Component map**: Sensitive prompt → MLAG (Metaphor Agent → Context Agent → Prompt Agent) → 49 candidates → APO (GPR surrogate + EI acquisition) → Query T2I → Observation set update

- **Critical path**: Load unaligned LLM and CLIP encoder → Metaphor Agent retrieves 7 metaphors → Context Agent generates 7 styles per metaphor → Prompt Agent produces 49 candidates → LHS sampling creates 5-sample observation set → Train GPR → Iterative optimization loop with EI selection → Return best adversarial prompt

- **Design tradeoffs**: 49 candidates (N×M) balance diversity vs overhead; 5-sample observation set improves surrogate accuracy but requires initial queries; 0.26 similarity threshold ensures semantic match; early stopping prevents overfitting

- **Failure signatures**: Low bypass rate (<0.80) suggests metaphor leakage; low ASR despite high BR indicates metaphor too abstract; high query count (>15) suggests poor surrogate learning; high perplexity (>200) indicates unnatural prompts

- **First 3 experiments**: 1) Single-filter baseline on SD1.4 with text-cls to validate pipeline; 2) Agent ablation study comparing four configurations on text-cls+image-clip defense; 3) Cross-model transfer from SD1.4 to SDXL/SD3/FLUX without re-optimization

## Open Questions the Paper Calls Out
None

## Limitations
- Transferability shows 30-50% ASR-C drop when applying prompts across different T2I architectures, limiting practical attack utility
- Effectiveness represents snapshot in time as modern T2I models frequently update safety mechanisms that may degrade metaphor-based obfuscation
- Query access assumption may not scale when multiple attempts needed across different sensitive prompts or rate limiting enforced

## Confidence
- **High Confidence**: Core metaphor-based obfuscation mechanism (BR=0.98) supported by ablation study showing 10 percentage point improvement
- **Medium Confidence**: Bayesian optimization efficiency claims supported by quantitative comparisons, but limited observation set raises robustness questions
- **Low Confidence**: Long-term effectiveness against evolving defenses and scalability to broader T2I models and content categories remain uncertain

## Next Checks
1. Re-run MJA against updated versions of Stable Diffusion to measure degradation in bypass rate and identify detectable metaphor patterns
2. Test transferability across at least 8 additional T2I models including newer architectures to establish model-agnostic effectiveness
3. Systematically vary sensitivity level of target prompts to map boundary where metaphor-based obfuscation fails