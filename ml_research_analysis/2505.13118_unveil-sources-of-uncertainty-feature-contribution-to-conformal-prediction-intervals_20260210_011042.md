---
ver: rpa2
title: 'Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction
  Intervals'
arxiv_id: '2505.13118'
source_url: https://arxiv.org/abs/2505.13118
tags:
- shapley
- rank
- values
- value
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel model-agnostic uncertainty attribution\
  \ (UA) method that combines cooperative game theory with conformal prediction (CP)\
  \ to interpret predictive uncertainty feature-wise. The method defines cooperative\
  \ games where CP interval properties\u2014such as width and bounds\u2014serve as\
  \ value functions, and uses the broader Harsanyi allocation family (including proportional\
  \ Shapley values) to attribute uncertainty to input features."
---

# Unveil Sources of Uncertainty: Feature Contribution to Conformal Prediction Intervals

## Quick Facts
- **arXiv ID:** 2505.13118
- **Source URL:** https://arxiv.org/abs/2505.13118
- **Reference count:** 40
- **Primary result:** Novel model-agnostic uncertainty attribution method combining cooperative game theory with conformal prediction, achieving up to 10-fold speed-up via Monte Carlo approximation

## Executive Summary
This paper introduces a model-agnostic uncertainty attribution (UA) method that leverages conformal prediction (CP) intervals as value functions within cooperative game theory. By treating features as players in a cooperative game where CP interval properties (width, bounds) serve as dividends, the method allocates total predictive uncertainty back to individual features using Shapley values and their proportional extensions. A Monte Carlo approximation scheme with statistical guarantees enables practical application to high-dimensional datasets while maintaining interpretability. Experiments demonstrate that CP-based uncertainty attributions diverge from traditional moment-based importance rankings, offering enhanced insights for high-stakes machine learning applications.

## Method Summary
The method defines cooperative games where CP interval properties serve as value functions, then allocates these dividends to individual features using Shapley values and the broader Harsanyi allocation family. For a feature subset A, a model is trained on those features, CP intervals are computed on calibration data, and the interval width or bounds become the value function v(A). Standard Shapley values divide the coalition dividend equally among members, while Proportional Shapley values distribute it proportionally to each feature's standalone importance. To address computational complexity from training 2^d models, the method employs Monte Carlo permutation sampling to approximate allocations with provable statistical guarantees, achieving up to 10-fold speed-up compared to exact computation.

## Key Results
- CP-based uncertainty attributions differ significantly from traditional moment-based importance rankings
- Monte Carlo approximation achieves up to 10-fold speed-up while maintaining statistical guarantees
- Proportional Shapley values provide more nuanced attribution than standard Shapley values by weighting contributions based on individual feature importance
- Method successfully identifies features driving predictive uncertainty in both synthetic and real-world datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Predictive uncertainty, quantified via Conformal Prediction (CP) interval properties (width, bounds), can be decomposed into feature-level contributions using cooperative game theory.
- **Mechanism:** The method treats features as "players" in a cooperative game. It defines a value function v(A) based on the CP interval (e.g., width) generated using only the feature subset A. It then allocates the total interval width back to individual features using Shapley values, ensuring the sum of contributions equals the total width.
- **Core assumption:** The properties of a prediction interval (specifically width or boundary values) are valid value functions for a cooperative game, and the model can be retrained on feature subsets A to compute these values.
- **Evidence anchors:**
  - [abstract] "...defining cooperative games where CP interval properties—such as width and bounds—serve as value functions..."
  - [section 3.1] Defines v^CP,w(A, x) := ΔĈ_A(x^(A)) as the value function for interval width.
  - [corpus] The intersection of Conformal Prediction and Shapley values appears in recent literature (e.g., "Uncertainty-Aware Multimodal Learning via Conformal Shapley Intervals"), suggesting the integration of these two theories is a viable emerging approach.
- **Break condition:** The mechanism fails if the CP interval width is not sensitive to the presence of specific features (resulting in zero dividends), or if the underlying model cannot be meaningfully retrained on arbitrary subsets of features.

### Mechanism 2
- **Claim:** Proportional Shapley values provide a more nuanced attribution of uncertainty than standard (egalitarian) Shapley values by weighting contributions based on individual feature importance.
- **Mechanism:** While standard Shapley values divide the "dividend" of a coalition equally among players, Proportional Shapley values divide the dividend proportionally to the value the feature creates alone (v({j})). This implies that features with higher individual uncertainty impact receive a larger share of the interaction uncertainty.
- **Core assumption:** The standalone value v({j}) is a meaningful proxy for a feature's "power" or "weight" in the game, and the Harsanyi set of allocations provides a valid framework for this redistribution.
- **Evidence anchors:**
  - [abstract] "...use the richer class of Harsanyi allocations, and in particular the proportional Shapley values, which distribute attribution proportionally to feature importance."
  - [section 2.2] Defines the Proportional Shapley value formula using weights λ^PS_j.
  - [corpus] Weak direct corpus evidence for "Proportional Shapley" in this specific context; it appears as a novel extension compared to standard Shapley approaches in neighbor papers.
- **Break condition:** The mechanism is ill-defined if v({j}) = 0 for a feature that nonetheless contributes via interactions (the paper notes this requires a subgame adjustment), or if the normalization assumptions are violated.

### Mechanism 3
- **Claim:** Monte Carlo approximation via permutation sampling makes uncertainty attribution computationally feasible for high-dimensional datasets without losing statistical guarantees.
- **Mechanism:** Instead of training 2^d models for every subset, the method approximates the allocation by sampling m permutations of features. For each permutation, it computes marginal contributions, requiring at most m × d model evaluations. Importance sampling allows reusing samples to estimate different allocation types.
- **Core assumption:** The value function is sufficiently smooth or the permutation space can be sampled efficiently to provide unbiased, consistent estimates with finite samples.
- **Evidence anchors:**
  - [abstract] "We propose a Monte Carlo approximation scheme... with robust statistical guarantees..."
  - [section 3.2] Describes the procedure to sample permutations to estimate allocations; Theorem 1 proves unbiasedness and consistency.
  - [corpus] Neighbor papers like "Exact Shapley Attributions..." confirm that computational complexity is a primary bottleneck in Shapley methods, validating the need for this approximation.
- **Break condition:** Efficiency gains are lost if a very high number of permutations m is required for convergence (observed in Figure 1 convergence curves), or if the value function evaluation itself is prohibitively expensive.

## Foundational Learning

### Concept: Split Conformal Prediction (SCP)
- **Why needed here:** This is the engine that generates the uncertainty intervals. You cannot define the value function v(A) without understanding how calibration scores and quantiles produce the interval width ΔĈ.
- **Quick check question:** How does the choice of conformity score s (e.g., absolute residual vs. quantile) change the interpretation of the "uncertainty" being attributed?

### Concept: Harsanyi Dividends & Shapley Values
- **Why needed here:** The paper moves beyond standard SHAP by utilizing the Harsanyi set. Understanding that features interact in coalitions to produce "dividends" of uncertainty is critical for interpreting the output.
- **Quick check question:** Explain the difference in how a standard Shapley value vs. a Proportional Shapley value would treat a feature that has low standalone uncertainty but high interaction uncertainty.

### Concept: Monte Carlo Integration
- **Why needed here:** To implement the approximation efficiently. You must understand why averaging marginal contributions over random permutations yields an unbiased estimate of the expected contribution.
- **Quick check question:** If you sample 500 permutations and the estimate fluctuates wildly, what parameter or assumption should you check?

## Architecture Onboarding

- **Component map:** Data Splitter -> Subset Generator -> Model Zoo -> Value Evaluator -> Allocation Aggregator
- **Critical path:** The Model Training Loop. While the math focuses on allocation, the engineering bottleneck is training thousands of models for different feature subsets.
- **Design tradeoffs:**
  - SMR vs. CQR intervals: SMR produces constant-width intervals (less informative attribution), while CQR/LACP are adaptive but more computationally complex to fit.
  - Exact vs. Monte Carlo: Exact is reproducible but scales as O(2^d). Monte Carlo scales linearly with permutations m but introduces estimation variance.
  - Value Function Choice: Attributing width explains total uncertainty; attributing bounds explains the location of risk (e.g., why is the upper bound so high?).
- **Failure signatures:**
  - Non-convergence: Monte Carlo estimates oscillate without settling (solution: increase permutations or check for high-variance features).
  - Zero-Value Features: Proportional Shapley fails if a feature has zero standalone value but non-zero interaction value (requires subgame logic mentioned in Appendix A.3).
  - Constant Attribution: If using Standard Mean Regression (SMR) with simple residuals, the interval width is constant for all x, leading to uniform/feature-independent attribution (Section 2.1).
- **First 3 experiments:**
  1. Validation Run (Synthetic): Implement the modified Friedman benchmark (Section 4.2) to verify that the "Variance" features are correctly identified as driving interval width more than "Mean" features.
  2. Convergence Diagnostic: Replicate Figure 1 by running the Monte Carlo approximation with m ∈ {100, 1000, 5000} permutations on a small dataset (e.g., Concrete) to determine the necessary m for stable estimates.
  3. Allocation Comparison: Compute both Standard and Proportional Shapley values for a dataset (e.g., Facebook) to identify features where the two methods disagree (indicating complex interaction effects vs. strong individual effects).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can optimal Harsanyi allocations be automatically defined and selected for specific XAI tasks?
- **Basis in paper:** [explicit] "Future work includes automatically defining optimal allocations specialized for XAI tasks..."
- **Why unresolved:** The current framework relies on standard allocations (Shapley, Proportional Shapley) but suggests a need for context-specific weight systems.
- **What evidence would resolve it:** An algorithm or theoretical framework that prescribes specific weight systems λ_j(A) based on data characteristics or user-defined interpretability goals.

### Open Question 2
- **Question:** How can this attribution framework be extended to conformal prediction for time series or classification sets?
- **Basis in paper:** [explicit] "Future work includes... exploring other venues to link XAI and the CP framework (e.g., beyond SCP, CP intervals for time series or sets)."
- **Why unresolved:** The current methodology focuses exclusively on regression intervals derived from Split Conformal Prediction (SCP).
- **What evidence would resolve it:** A derivation of cooperative game value functions suitable for prediction sets in classification or interval structures that handle temporal dependencies in time series.

### Open Question 3
- **Question:** What are the statistical guarantees of the Monte Carlo approximation when using surrogate models to estimate value functions?
- **Basis in paper:** [explicit] "Future work includes... the statistical study and adaptation of the approximation schemes based on surrogate models."
- **Why unresolved:** Using surrogate models reduces the computational cost of retraining but introduces approximation errors that may violate the unbiasedness or consistency guarantees of the exact method.
- **What evidence would resolve it:** Theoretical proofs (e.g., bounds on estimation error) and empirical validation showing that surrogate-based approximations maintain the statistical properties established for the exact value functions.

## Limitations
- The Proportional Shapley extension has limited empirical validation compared to standard Shapley values in this context.
- The assumption that retraining models on feature subsets yields meaningful CP intervals may break down with highly correlated features or sensitive model architectures.
- Monte Carlo approximation introduces variance that may obscure true feature importance, particularly for features with small but non-zero contributions.

## Confidence

- **High Confidence:** The integration of CP intervals as value functions for cooperative games is mathematically sound and computationally demonstrated. The divergence between CP-based and moment-based importance rankings is empirically supported.
- **Medium Confidence:** The theoretical extension to Proportional Shapley values is valid, but practical advantages over standard Shapley require more extensive validation across diverse datasets and models.
- **Low Confidence:** The claim of "up to 10-fold speed-up" is based on limited experiments and may vary significantly with dataset dimensionality and value function complexity.

## Next Checks

1. **Robustness to Model Architecture:** Repeat uncertainty attribution experiments using different base models (e.g., linear regression, neural networks) to verify that feature contributions are model-agnostic.
2. **Convergence Diagnostics:** Systematically vary the number of Monte Carlo permutations m and measure the stability of feature rankings to determine the minimum m required for reliable attribution.
3. **Feature Correlation Sensitivity:** Design synthetic experiments where features are strongly correlated to test whether the method correctly attributes uncertainty to individual features versus groups of correlated features.