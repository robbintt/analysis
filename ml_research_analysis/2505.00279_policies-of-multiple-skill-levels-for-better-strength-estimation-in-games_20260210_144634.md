---
ver: rpa2
title: Policies of Multiple Skill Levels for Better Strength Estimation in Games
arxiv_id: '2505.00279'
source_url: https://arxiv.org/abs/2505.00279
tags:
- rank
- strength
- chess
- estimation
- players
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study improves human skill level estimation in games by leveraging
  policies from multiple skill levels. The method combines strength scores from a
  state-of-the-art estimator, move probabilities from imitation models trained across
  different skill levels, and average score losses relative to strong AI players.
---

# Policies of Multiple Skill Levels for Better Strength Estimation in Games

## Quick Facts
- **arXiv ID:** 2505.00279
- **Source URL:** https://arxiv.org/abs/2505.00279
- **Reference count:** 40
- **Primary result:** Multi-policy strength estimation achieves 80% accuracy with 10 matches and 92% with 20 matches in Go, improving over SOTA by 8-9%.

## Executive Summary
This study improves human skill level estimation in games by leveraging policies from multiple skill levels. The method combines strength scores from a state-of-the-art estimator, move probabilities from imitation models trained across different skill levels, and average score losses relative to strong AI players. Experiments on Go and chess showed that the approach achieved 80% accuracy with 10 matches and 92% with 20 matches in Go, improving over previous state-of-the-art by 8-9%. Similar improvements were observed in chess. The results demonstrate that integrating diverse skill-level models enhances estimation accuracy and supports more effective human-AI interaction in games.

## Method Summary
The method extracts three feature types per player per match: (1) mean strength scores from Chen et al.'s estimator, (2) geometric mean of move priors from L imitation models at different skill levels (KataGo HumanSL for Go, Maia models for chess), and (3) MeanLoss, MedLoss, StdLoss computed from strong AI evaluations within positional truncation limits. These features are aggregated across n matches and fed to a LightGBM regression meta-model that predicts player rank. The approach leverages complementary discriminative power across skill levels, with geometric means of move likelihoods encoding rank-specific behavioral patterns.

## Key Results
- 80% accuracy with 10 matches and 92% with 20 matches in Go (8-9% improvement over SOTA)
- Similar improvements observed in chess estimation
- Multi-level policy combination provides complementary discriminative signals across rank groups
- Loss features show limited impact despite theoretical expectations

## Why This Works (Mechanism)

### Mechanism 1: Complementary Discriminative Power Across Skill Levels
Imitation models at different skill levels provide complementary signals for distinguishing rank groups. Lower-skill models assign lower probabilities to high-rank moves than higher-skill models, creating separation even when higher-skill models show similar probabilities. Geometric means of move likelihoods across skill levels encode this discriminative pattern.

### Mechanism 2: Aggregated Strength Scores as Baseline Signal
Bradley-Terry model-derived strength scores provide foundational strength signal that is enhanced but not replaced by policy-based features. The meta-model uses this as primary feature alongside policy features.

### Mechanism 3: Loss Features with Positional Truncation
Score losses relative to strong AI provide limited but complementary information about tactical reading ability. Positional truncation (Ncut=100 for Go, Ncut=50 for chess) mitigates variance by excluding high-variance endgame moves.

## Foundational Learning

- **Bradley-Terry Model**: Underpins the strength estimator that produces primary input features; understanding pairwise comparisons to scalar strength scores is essential for debugging feature quality. Quick check: Given three players A, B, C where A beats B 70% of the time and B beats C 60% of the time, what does the Bradley-Terry model predict for A vs. C?

- **Ensemble Stacking with Gradient Boosting**: The meta-model (LightGBM) combines heterogeneous features from three distinct sources; understanding feature importance and interaction detection in tree-based ensembles is critical for ablation analysis. Quick check: Why might stacking outperform simply averaging predictions from multiple base models? What role does the meta-learner play?

- **Policy Networks and Move Priors**: Imitation models output probability distributions over legal moves; geometric mean of likelihoods is a key feature extraction operation. Quick check: If a policy network assigns probability 0.001 to a move played by a grandmaster, what does the geometric mean of priors across 100 moves tell you about that player's likely rank?

## Architecture Onboarding

- **Component map:**
State-Move Pairs (from n matches) → Strength Estimator → Mean(β₁...βₖ)
State-Move Pairs → Imitation Models (L skill levels) → GM₁, GM₂, ..., GMₗ (geometric means)
State-Move Pairs → Strong AI → MeanLoss, MedLoss, StdLoss (within Ncut)
↓
Feature Vector (aggregated over n matches)
↓
LightGBM Meta-Model (regression)
↓
Predicted Rank (rounded to nearest integer)

- **Critical path:**
1. Collect k state-move pairs per player per match
2. Extract βᵢ from pre-trained strength estimator for each pair
3. Query each of L imitation models for move probability pⱼ,ᵢ
4. Compute geometric means GMⱼ = (Πᵢ pⱼ,ᵢ)^(1/k) for each skill level j
5. Compute losses lᵢ using strong AI state evaluations (with logit transform for chess)
6. Aggregate features across n matches via averaging
7. Feed to LightGBM meta-model; round output to nearest rank group

- **Design tradeoffs:**
- Ncut selection: Lower values reduce variance but may miss middle-game mistakes; higher values capture more signal but introduce noise
- Imitation model coverage: Models need not cover all target ranks, but coverage gaps reduce discriminative power
- n match count: More matches improve accuracy but require more data collection

- **Failure signatures:**
- Accuracy plateau despite more matches: Check if imitation models adequately cover target rank range
- Large gap between random sampling and player-specific accuracy: Individual player variance exceeds group-level averaging
- Loss features showing near-zero importance: Verify state evaluation outputs are on correct scale

- **First 3 experiments:**
1. Reproduce baseline comparison: Train meta-model on Go data with n=10, 20 using only strength scores, then add priors, then add losses
2. Ablation by rank group: Compute per-group accuracy when removing each feature category
3. Imitation model coverage test: Train meta-models with subsets of Maia models and measure accuracy degradation for low vs. high rank groups

## Open Questions the Paper Calls Out

- **Generalization to other games**: Can the method be effectively generalized to games with partial observability or different data structures? The conclusion states future research includes exploring applicability to wider range of games.

- **Player-specific calibration**: What specific calibration methods can address the performance gap between random sampling and player-specific rank estimation? The conclusion identifies need for further calibration methods to address outliers and variations.

- **Loss feature utility**: How can the utility of loss features be improved to better reflect players' reading abilities? Despite theoretical expectations, ablation study showed removing loss features had minimal impact on overall accuracy.

## Limitations
- Imitation model dependency: Performance critically depends on availability and quality of imitation models covering target rank range
- Data distribution assumptions: Strength estimator effectiveness assumes Bradley-Terry outputs generalize across player populations
- Fixed positional truncation: Choice of Ncut thresholds is heuristic rather than theoretically justified

## Confidence
- **High Confidence**: Improvement over SOTA (8-9% absolute gain in Go, 4-7% in chess) is well-supported by experimental results
- **Medium Confidence**: Multi-level policy combination mechanism is empirically supported but not formally proven; Ncut choice remains heuristic
- **Low Confidence**: Exact impact of individual feature categories on different rank groups is not fully characterized; paper doesn't explore performance variation with player-specific factors

## Next Checks
1. **Rank coverage sensitivity analysis**: Systematically test estimation accuracy when using different subsets of imitation models to quantify how coverage gaps affect performance across rank groups
2. **Cross-domain transfer test**: Apply the method to a third game domain where imitation models exist but were not part of original development
3. **Feature interaction investigation**: Conduct detailed ablation study varying combinations of three feature types across all rank groups to identify most beneficial combinations for specific skill ranges