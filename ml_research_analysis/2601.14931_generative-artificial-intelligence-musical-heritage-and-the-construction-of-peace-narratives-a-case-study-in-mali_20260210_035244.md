---
ver: rpa2
title: 'Generative Artificial Intelligence, Musical Heritage and the Construction
  of Peace Narratives: A Case Study in Mali'
arxiv_id: '2601.14931'
source_url: https://arxiv.org/abs/2601.14931
tags:
- mali
- peace
- musical
- cultural
- national
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that generative AI, when integrated into
  a culturally informed participatory framework, can serve as a tool for constructing
  peace narratives and revitalizing musical heritage in Mali. Through a co-creation
  workshop with 30 participants from diverse backgrounds, the research produced 12
  AI-assisted compositions that blend traditional Malian instruments (kora, balafon,
  djembe) with contemporary arrangements in national languages.
---

# Generative Artificial Intelligence, Musical Heritage and the Construction of Peace Narratives: A Case Study in Mali

## Quick Facts
- arXiv ID: 2601.14931
- Source URL: https://arxiv.org/abs/2601.14931
- Reference count: 14
- One-line primary result: AI-assisted music creation in Mali achieved 85% perceived cultural authenticity and 80% participant capability for independent creation through structured prompt engineering

## Executive Summary
This study demonstrates that generative AI, when integrated into a culturally informed participatory framework, can serve as a tool for constructing peace narratives and revitalizing musical heritage in Mali. Through a co-creation workshop with 30 participants from diverse backgrounds, the research produced 12 AI-assisted compositions that blend traditional Malian instruments (kora, balafon, djembe) with contemporary arrangements in national languages. The workshop achieved high participant satisfaction (average 4.15/5) with 85% perceiving authentic cultural representation and 80% feeling capable of independent creation afterward. The resulting hybrid musical architectures—such as Afrobeat-Mandingo patterns and meditative Tuareg models—feature multilingual lyrics, reconciliation lexicon, and symbolic instrumentation. Institutional recognition at SENARE 2025 confirms social relevance. Challenges include linguistic corpus limitations, algorithmic censorship, and authenticity-innovation tensions, highlighting the need for ethical frameworks supporting cultural sovereignty in AI applications.

## Method Summary
The research employed a 3-day workshop with 30 participants stratified across institutional, generational, artistic, and gender dimensions. Participants underwent three phases: familiarization with GenAI principles, integration of tradition and modernity through structured prompt engineering, and linguistic authenticity with phonetic transcription. The prompt framework [Genre/Style] + [Instrumentation] + [Tempo/Mood] + [Cultural References] + [Thematic Content] guided iterative generation (8-12 cycles per composition) using Suno AI for music and ChatGPT/Gemini for lyrics. Evaluation combined thematic analysis (Braun & Clarke) with adapted Agawu African music analysis framework, supplemented by post-workshop surveys and semi-structured interviews.

## Key Results
- Achieved 85% participant perception of authentic cultural representation and 80% feeling capable of independent creation
- Generated 12 compositions featuring three hybridization patterns: Afrobeat-Mandingo (120-130 BPM), Reggae-Sabar (bipartite structure), and Meditative Tuareg (80-110 BPM pentatonic scales)
- Demonstrated multilingual reconciliation narratives using stratified language strategies across Bambara, Fulfulde, Tamasheq, Songhai, and Dogon

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GenAI embedded in culturally-conscious participatory frameworks can catalyze peace narrative construction through iterative co-creation.
- Mechanism: Structured 3-phase training (familiarization → tradition-modernity integration → linguistic authenticity) enables participants with varying technological literacy to appropriate AI tools for culturally-grounded production. The participatory structure—bringing together diverse stakeholders (ministry representatives, youth, women's organizations, traditional music students)—creates plurality of perspectives essential for credible narrative co-construction.
- Core assumption: Participants can develop sophisticated prompt engineering skills within short training periods when provided structured frameworks.
- Evidence anchors:
  - [abstract] "Gen AI, embedded in a culturally conscious participatory framework, can act as a catalyst for symbolic diplomacy, amplifying local voices instead of standardizing them"
  - [section 2.3] Workshop structure with three phases; [section 2.6] prompts revealed growing sophistication enabling specification of traditional scales and tonal structures
  - [corpus] "Generative AI in Heritage Practice" (arxiv 2510.13811) shows similar GenAI integration into professional heritage practice with fine-tuning for domain-specific guidance
- Break condition: If training is insufficient or participants lack cultural grounding, outputs remain stereotypical (as seen with initial generic prompts yielding "African music with drums" lacking specificity).

### Mechanism 2
- Claim: Structured prompt engineering framework enables balanced hybridization between technological innovation and cultural authenticity.
- Mechanism: The framework [Genre/Style] + [Instrumentation] + [Tempo/Mood] + [Cultural References] + [Thematic Content] translates cultural knowledge into machine-interpretable specifications. Iterative refinement (8-12 attempts per composition) progressively improves output. Three hybridization patterns emerged: Afrobeat-Mandingo (120-130 BPM, kora/balafon with brass/wind), Reggae-Sabar (bipartite reflection-to-celebration), and Meditative Tuareg (80-110 BPM, pentatonic scales, imzad/tende).
- Core assumption: AI systems have sufficient training data on specific cultural instruments and styles to generate recognizable outputs.
- Evidence anchors:
  - [section 2.4] Successful prompt example with specific instrumentation and cultural references; rejection reasons: inappropriate instrumentation (34%), tempo mismatches (22%), vocal quality (28%), stylistic incongruence (16%)
  - [section 3.1] Three hybridization patterns with specific BPM, instrumentation, and cultural significance
  - [corpus] Weak direct corpus evidence for this specific hybridization mechanism; related work on cultural heritage applications focuses on preservation rather than musical hybridization
- Break condition: Requests for instruments with limited training data (e.g., imzad defaulting to generic violin) or overly complex prompts combining >3 traditions produce incoherent outputs.

### Mechanism 3
- Claim: Stratified multilingualism combined with reconciliation lexicon creates symbolic infrastructure for collective identity reconstruction.
- Mechanism: Four discursive strategies—stratified multilingualism (systematic use of multiple national languages in single works), reconciliation lexicon (recurrent terms like *bɛn*, *alâfiyet*, *kelenya*), unifying geographical imagery ("From Kayes to Gao"), and Sahelian organic metaphors (Niger river, palaver tree)—anchor peace discourse in collective imagination. Four-phase narrative structure (Invocation → Diagnostic → Collective Resolution → Spiritual Elevation) provides progressive emotional arc.
- Core assumption: National languages have sufficient phonetic transcribability and AI systems can respect tonal structures.
- Evidence anchors:
  - [section 3.2] Detailed linguistic strategies with examples in Bambara, Fulfulde, Tamasheq, Songhai, Dogon
  - [section 3.3] Four-phase narrative architecture; [section 4.2] Algorithmic censorship of words like "Niger" and "soko" due to associations in other contexts
  - [corpus] "Measuring and Fostering Peace through ML/AI" (arxiv 2601.05232) explores AI for peace promotion but through media diet analysis rather than creative production
- Break condition: Insufficient linguistic corpora for some national languages cause transcription and tonal recognition problems; algorithmic content moderation may flag culturally-appropriate terms.

## Foundational Learning

- Concept: **Prompt engineering for cultural specificity**
  - Why needed here: Generic prompts produce stereotypical outputs; participants needed structured frameworks to translate cultural knowledge into machine-readable specifications
  - Quick check question: Can you explain why "African music with drums" fails to produce culturally-authentic Malian output, and what specific elements the successful Afrobeat-Mandingo prompt adds?

- Concept: **Iterative refinement cycles in generative systems**
  - Why needed here: Each composition required 8-12 generation attempts; understanding rejection patterns (instrumentation 34%, vocal quality 28%, tempo 22%) guides efficient iteration
  - Quick check question: Given the rejection statistics, which aspect of prompt design should be prioritized first in an iteration workflow?

- Concept: **Linguistic corpus limitations and tonal languages**
  - Why needed here: Five Malian languages have varying corpora availability; Bambara, Fulfulde, Tamasheq, Songhai, Dogon present different transcription challenges
  - Quick check question: Why might prompts in national languages without phonetic guidance produce mispronunciations, and what workaround does the study employ?

## Architecture Onboarding

- Component map:
  - Generation layer: Suno AI (music from text prompts), ChatGPT/GEMINI (text generation and translation into national languages)
  - Cultural knowledge layer: Traditional instrument specifications (kora, balafon, djembe, imzad, tahardent, tende), national language lexicons, hybridization pattern templates
  - Workshop facilitation layer: 3-phase structure (training → integration → linguistic authenticity), participant stratification framework
  - Prompt engineering framework: [Genre/Style] + [Instrumentation] + [Tempo/Mood] + [Cultural References] + [Thematic Content]
  - Evaluation layer: Thematic analysis (Braun & Clarke 6-phase), adapted Agawu African music analysis framework

- Critical path:
  1. Participant recruitment with stratified sampling (institutional/generational/artistic/gender diversity)
  2. Phase 1 training on GenAI principles and prompt engineering
  3. Phase 2 development of tradition-modernity hybrid prompts
  4. Phase 3 linguistic authenticity with phonetic transcription
  5. Iterative generation (8-12 cycles per composition)
  6. Thematic and musical analysis
  7. Post-workshop survey and semi-structured interviews

- Design tradeoffs:
  - **Breadth vs. depth in linguistic coverage**: 5 languages included but corpora quality varies; consider focusing on fewer languages with richer corpora
  - **Workshop duration vs. skill development**: 3-day format limits sophistication; participants noted short duration as limitation
  - **Platform constraints vs. cultural specificity**: Content policies block artist imitations; some instruments (imzad) default to generic sounds due to training data gaps
  - **Immediate enthusiasm vs. sustained impact**: Post-workshop survey may capture novelty effect; longitudinal studies needed

- Failure signatures:
  - **Generic outputs**: Initial prompts lack cultural specificity → refine using structured framework with explicit instrument/genre/cultural reference specifications
  - **Linguistic mispronunciation**: National language prompts without phonetic guidance → add phonetic transcription and prosodic indications
  - **Stylistic incoherence**: Prompts combining >3 musical traditions → limit hybridization complexity
  - **Algorithmic censorship**: Culturally-appropriate terms flagged → identify and document problematic vocabulary, develop workaround synonyms

- First 3 experiments:
  1. **Baseline prompt comparison**: Generate identical thematic content (e.g., "peace song") using (a) generic prompt, (b) structured framework with instrument specifications, (c) structured framework with full cultural references. Measure perceived authenticity ratings.
  2. **Linguistic corpus stress test**: Test generation in each of the 5 national languages with and without phonetic guidance. Document error types (pronunciation, tone, vocabulary gaps) per language.
  3. **Iteration efficiency mapping**: Track rejection reasons across generation cycles for 3 compositions. Identify which prompt elements (instrumentation, tempo, vocal style) require most iterations and optimize prompt framework accordingly.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent is the observed social cohesion driven by the generative AI tool itself, rather than the collaborative workshop structure?
- Basis in paper: [explicit] The Discussion notes that positive outcomes may be attributable to the "collaborative environment" or "novelty effect" and explicitly calls for "control conditions" to isolate the specific contribution of AI.
- Why unresolved: The single-group design (N=30) could not disentangle the technology's impact from the natural social bonding that occurs during any intensive collaborative activity.
- What evidence would resolve it: A randomized controlled trial comparing AI-assisted music creation groups with traditional collaborative music groups.

### Open Question 2
- Question: Do the reported feelings of cultural empowerment and peace narrative internalization persist beyond the immediate post-workshop period?
- Basis in paper: [explicit] The Conclusion identifies "longitudinal studies assessing sustainable impact" as a key future research perspective.
- Why unresolved: Surveys were administered immediately after the intervention, potentially capturing transient enthusiasm rather than durable changes in perception or "peace narrative" integration.
- What evidence would resolve it: Follow-up assessments (e.g., 6 months post-intervention) to measure sustained changes in cultural perception and continued autonomous use of the tools.

### Open Question 3
- Question: How can the ethical tension between generative AI training data and the intellectual property rights of traditional music holders be resolved?
- Basis in paper: [explicit] The Discussion highlights participant concerns regarding "the origin of training data, intellectual property, and the remuneration of holders of traditional musical heritage."
- Why unresolved: Commercial generative models operate as "black boxes" regarding training data provenance, leaving a gap between the "cultural sovereignty" promoted by the authors and the reality of uncompensated data extraction.
- What evidence would resolve it: The development and testing of a transparent licensing or benefit-sharing model specifically for traditional cultural expressions used in AI training.

## Limitations

- Single-workshop design cannot distinguish AI-specific effects from general collaborative benefits
- Linguistic corpus limitations for national languages cause transcription and tonal recognition problems
- Post-workshop survey timing may capture novelty effects rather than sustained impact

## Confidence

**High Confidence** (4/5): The workshop structure and prompt engineering framework demonstrated effectiveness in achieving participant satisfaction (4.15/5) and perceived cultural authenticity (85%). The three identified hybridization patterns (Afrobeat-Mandingo, Reggae-Sabar, Meditative Tuareg) show replicable results when using the specified prompt structure.

**Medium Confidence** (3/5): The linguistic authenticity mechanisms and reconciliation lexicon strategies show promise but face significant technical constraints. The study identifies problems (algorithmic censorship, tonal language limitations) without fully solving them, and corpus limitations for national languages remain unresolved.

**Low Confidence** (2/5): Long-term impact claims and broader applicability to other conflict contexts lack empirical support. The post-workshop survey may capture immediate enthusiasm rather than sustained engagement, and institutional recognition at SENARE 2025 doesn't demonstrate broader societal adoption.

## Next Checks

1. **Longitudinal Impact Assessment**: Conduct follow-up studies at 3, 6, and 12 months post-workshop to measure sustained participant engagement, actual usage of AI tools for independent creation, and evolution of peace narratives beyond the workshop setting.

2. **Algorithmic Censorship Documentation**: Systematically test and document which culturally-specific terms trigger content moderation across multiple AI platforms, then develop and validate alternative phrasing strategies that preserve cultural meaning while avoiding algorithmic rejection.

3. **Linguistic Corpus Expansion Study**: Conduct controlled experiments comparing AI output quality across the 5 national languages with varying corpus availability, measuring specific error types (pronunciation, tone, vocabulary gaps) and testing targeted corpus enrichment approaches to improve generation quality for underrepresented languages.