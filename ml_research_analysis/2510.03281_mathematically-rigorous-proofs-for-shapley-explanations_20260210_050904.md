---
ver: rpa2
title: Mathematically rigorous proofs for Shapley explanations
arxiv_id: '2510.03281'
source_url: https://arxiv.org/abs/2510.03281
tags:
- will
- have
- symmetry
- values
- shapley
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis provides mathematically rigorous proofs for two key
  results from Lundberg and Lee's 2017 paper on Shapley explanations. The first result
  proves that Shapley values are the unique explanation satisfying local accuracy,
  missingness, restricted symmetry, and restricted consistency - correcting Lundberg
  and Lee's claim that consistency implies symmetry by providing a counterexample.
---

# Mathematically rigorous proofs for Shapley explanations
## Quick Facts
- arXiv ID: 2510.03281
- Source URL: https://arxiv.org/abs/2510.03281
- Reference count: 0
- This thesis provides mathematically rigorous proofs for two key results from Lundberg and Lee's 2017 paper on Shapley explanations.

## Executive Summary
This thesis addresses critical gaps in the mathematical foundations of Shapley explanations by providing rigorous proofs for two fundamental results. The work focuses on Lundberg and Lee's 2017 paper, identifying and correcting an error in their claim about the consistency property leading to symmetry. By reformulating the original properties to eliminate contradictions, the thesis establishes that Shapley values are uniquely determined by four specific properties: local accuracy, missingness, restricted symmetry, and restricted consistency. Additionally, the thesis demonstrates that Shapley values can be characterized as the unique solution to a weighted linear regression problem, providing a practical framework for efficient computation.

## Method Summary
The thesis employs mathematical proof techniques to establish the uniqueness of Shapley values under specific axiomatic properties. The approach involves reformulating the original properties from Lundberg and Lee's work to resolve contradictions, particularly between consistency and symmetry. The proof methodology leverages the correspondence between machine learning models and cooperative games, using game-theoretic concepts to analyze the explanation properties. The second major result uses optimization theory to show that Shapley values solve a specific weighted linear regression problem, enabling practical approximation methods that address the original method's exponential computational complexity.

## Key Results
- Proved Shapley values are uniquely determined by local accuracy, missingness, restricted symmetry, and restricted consistency properties
- Demonstrated that Lundberg and Lee's original consistency property leads to contradiction with symmetry, providing a counterexample
- Established that Shapley values are the unique solution to a weighted linear regression problem, enabling efficient computation

## Why This Works (Mechanism)
The theoretical framework works because it establishes a rigorous mathematical foundation for Shapley explanations by identifying and correcting flaws in previous work. The uniqueness proofs rely on showing that any explanation satisfying the specified properties must be the Shapley value, using techniques from cooperative game theory and optimization. The regression formulation works because it transforms the exponential complexity of exact Shapley value computation into a tractable optimization problem, leveraging linear algebra techniques for efficient approximation.

## Foundational Learning
- Cooperative game theory: Provides the mathematical framework for understanding how features interact in ML models through characteristic functions and value allocation. Quick check: Verify understanding of Shapley value definition in cooperative games.
- Axiomatic properties of explanations: Local accuracy, missingness, symmetry, and consistency form the basis for characterizing fair explanations. Quick check: Confirm each property's mathematical formulation and intuitive meaning.
- Correspondence between ML and cooperative games: Maps ML model predictions to characteristic functions in cooperative games. Quick check: Trace how feature subsets become coalitions in the game-theoretic representation.
- Weighted linear regression formulation: Transforms Shapley value computation into an optimization problem. Quick check: Derive the regression objective function from the Shapley value definition.
- Uniqueness proofs in mathematics: Techniques for showing that a solution is the only one satisfying given properties. Quick check: Understand the structure of the uniqueness argument used in both main results.

## Architecture Onboarding
- Component map: Shapley value computation -> Game-theoretic properties -> Uniqueness proof -> Regression formulation -> Efficient approximation
- Critical path: ML model → Cooperative game representation → Shapley value computation → Explanation properties verification → Uniqueness proof
- Design tradeoffs: Exact computation (exponential complexity) vs. regression approximation (polynomial complexity) vs. theoretical rigor vs. practical usability
- Failure signatures: Contradictions between properties, computational intractability, violation of local accuracy or missingness
- First experiments: 1) Validate the counterexample showing consistency-symmetry contradiction 2) Implement the regression formulation and compare with exact Shapley values 3) Test the framework on diverse ML models to verify property satisfaction

## Open Questions the Paper Calls Out
None

## Limitations
- Mathematical proofs require independent verification by domain experts
- Practical computational improvements need empirical validation on real-world datasets
- The framework's applicability across diverse ML model types remains to be tested
- The effectiveness of optimization techniques for regression formulation is not yet demonstrated

## Confidence
- High: The general framework connecting Shapley values to cooperative game theory and machine learning
- Medium: The mathematical proofs of uniqueness under reformulated properties
- Low: The practical computational improvements from the regression formulation

## Next Checks
1. Replicate the counterexample showing the contradiction between Lundberg and Lee's consistency and symmetry properties
2. Implement and benchmark the weighted linear regression approach against existing Shapley value approximation methods
3. Test the theoretical framework across diverse ML models (tree-based, neural networks, etc.) to verify general applicability