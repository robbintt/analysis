---
ver: rpa2
title: 'MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images'
arxiv_id: '2510.11883'
source_url: https://arxiv.org/abs/2510.11883
tags:
- breast
- tissue
- cancer
- mammodino
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MammoDINO introduces a self-supervised learning framework for mammography
  that addresses the limitations of standard SSL methods, which often focus on irrelevant
  background regions and miss cross-slice anatomical coherence in 3D DBT volumes.
  It incorporates a breast tissue-aware data augmentation sampler that ensures crops
  and masked patches are constrained to clinically meaningful breast tissue, and a
  3D DBT adjacent slice contrastive loss that enforces consistency across neighboring
  slices in DBT volumes.
---

# MammoDINO: Anatomically Aware Self-Supervision for Mammographic Images

## Quick Facts
- **arXiv ID:** 2510.11883
- **Source URL:** https://arxiv.org/abs/2510.11883
- **Reference count:** 0
- **Primary result:** MammoDINO outperforms DINOv2, RadDINO, BiomedCLIP, and MammoCLIP baselines on five mammography benchmarks with AUC up to 0.918 on cancer detection.

## Executive Summary
MammoDINO introduces an anatomically aware self-supervised learning framework for mammography that addresses limitations of standard SSL methods, which often focus on irrelevant background regions and miss cross-slice anatomical coherence in 3D DBT volumes. The framework incorporates a breast tissue-aware data augmentation sampler that ensures crops and masked patches are constrained to clinically meaningful breast tissue, and a 3D DBT adjacent slice contrastive loss that enforces consistency across neighboring slices. Pretrained on 1.4 million mammographic images, MammoDINO achieves state-of-the-art performance across cancer detection, lesion detection, BIRADS score prediction, and breast density classification tasks.

## Method Summary
MammoDINO extends DINOv2 self-supervised learning for mammography by incorporating two anatomically aware innovations: a breast tissue-aware data augmentation sampler and a 3D DBT adjacent slice contrastive loss. The framework uses ViT-B/14 backbone with 518×518 input resolution, training on 1.4M mammograms with three combined losses: DINO-M (breast-aware crops), iBOT-M (breast-aware masking), and DINO-adj (adjacent DBT slice contrastive). Breast tissue masks are generated via percentile thresholding and morphological operations, with crops and masks constrained to regions exceeding minimum tissue coverage. For DBT volumes, the adjacent slice loss enforces representation consistency between neighboring slices.

## Key Results
- Achieves AUC of 0.918 for cancer detection on VinDr dataset
- Achieves AUC of 0.712 for lesion detection on VinDr dataset
- Outperforms state-of-the-art baselines including DINOv2, RadDINO, BiomedCLIP, and MammoCLIP across five benchmark datasets

## Why This Works (Mechanism)

### Mechanism 1: Breast Tissue-Aware Sampling Redirects Supervision Signal
Constraining image crops to breast tissue regions improves representation quality by eliminating background-dominated training signal. A binary tissue mask is generated via percentile-based intensity thresholding followed by morphological closing/opening with a 9×9 kernel. Crop windows are only accepted if breast tissue coverage ratio exceeds minimum threshold, ensuring the contrastive loss operates exclusively on clinically relevant anatomy.

### Mechanism 2: Tissue-Aware Masked Image Modeling Focuses Patch-Level Learning
Patch masking weighted by breast tissue coverage improves masked image modeling by prioritizing clinically informative regions for reconstruction. Mask pieces are sampled with probability weighted by tissue coverage ratio, with coordinates below minimum coverage discarded. The iBOT cross-entropy loss is computed only on masked patches within tissue regions.

### Mechanism 3: Cross-Slice Consistency Enforces Anatomical Coherence
Enforcing representation consistency between adjacent DBT slices captures 3D anatomical continuity absent in 2D-only SSL. A contrastive loss aligns student CLS token predictions on slice k with teacher predictions on adjacent slice k±d. Both slices undergo conservative tissue-aware transforms to preserve spatial correspondence.

## Foundational Learning

- **Concept: DINO Self-Supervised Learning Framework**
  - Why needed here: MammoDINO builds directly on DINOv2's student-teacher knowledge distillation with centering and temperature sharpening; understanding this is prerequisite.
  - Quick check question: Can you explain why DINO uses a teacher network updated via exponential moving average rather than gradient descent?

- **Concept: Vision Transformer (ViT) Patch Embeddings and CLS Token**
  - Why needed here: The architecture uses ViT-base with patch size 14; CLS tokens are the primary representation used in both DINO-M and DINO-adj losses.
  - Quick check question: What information does the CLS token aggregate in a Vision Transformer, and why is it used for global image-level contrastive learning?

- **Concept: Digital Breast Tomosynthesis (DBT) vs 2D Mammography**
  - Why needed here: The adjacent slice loss exploits DBT's 3D structure; understanding why DBT provides cross-slice coherence that 2D mammography lacks is essential.
  - Quick check question: How does DBT differ from conventional 2D mammography in terms of depth information and slice structure?

## Architecture Onboarding

- **Component map:** Input preprocessing (16-bit→8-bit→normalize→CLAHE) → Tissue mask generator (percentile→morphological cleanup) → Breast tissue-aware sampler (coverage-filtered crops/masks) → ViT-base encoder (student/teacher, patch size 14, 518×518) → Loss heads (DINO-M CLS token, iBOT-M patch tokens, DINO-adj CLS token) → Aggregated loss

- **Critical path:** 1. Generate tissue mask M from input mammogram 2. Sample valid crops/masks meeting coverage threshold ρ 3. For DBT volumes, sample adjacent slice pairs with conservative transforms 4. Forward pass through student and teacher ViT encoders 5. Compute CLS and patch token probabilities with temperature sharpening and centering 6. Aggregate weighted losses and backpropagate

- **Design tradeoffs:** Minimum coverage ratio ρ (higher values enforce stricter tissue focus but may reduce crop diversity), slice offset d in DINO-adj (small offsets capture fine-grained continuity; larger offsets may introduce anatomical discontinuity), input resolution 518×518 (higher resolution preserves fine lesion detail but increases memory and compute)

- **Failure signatures:** Tissue mask over-segmentation (crops rejected or concentrated in small regions → training instability), slice misalignment in DBT (adjacent slice loss pulls representations together despite anatomical mismatch → degraded feature discriminability), excessive masking in iBOT-M (high mask ratio on tissue-heavy regions → CLS token receives insufficient context)

- **First 3 experiments:** 1. Visualize tissue mask generation on diverse mammograms (varying density, vendor) to validate segmentation quality before full training 2. Run controlled ablation: train DINOv2 + DINO-M only (no iBOT-M, no DINO-adj) on small subset, evaluate on cancer detection to isolate tissue-aware crop contribution 3. Train on single DBT volume set with and without DINO-adj loss, measure cross-slice representation similarity (cosine distance) to verify consistency enforcement

## Open Questions the Paper Calls Out

- Can the anatomically-aware SSL framework (breast tissue aware augmentation and cross-slice contrastive learning) transfer effectively to other 3D medical imaging modalities like CT and MRI?
- What is the optimal offset distance d for the 3D DBT adjacent slice loss, and how does performance vary with different slice spacings?
- Why does MammoDINO underperform compared to baseline methods on RSNA cancer detection and BIRADS prediction tasks?
- How sensitive is model performance to the percentile threshold τ and minimum breast coverage ratio ρ used in tissue-aware augmentation?

## Limitations
- Major hyperparameters (percentile threshold τ, minimum coverage ratio ρ, loss weights) not specified, limiting reproducibility
- Lack of cross-validation details and potential domain shift between pretraining and evaluation datasets introduces statistical uncertainty
- No systematic evaluation of tissue mask robustness on extremely dense or low-contrast images

## Confidence

- **High confidence:** Core architectural integration of breast tissue-aware sampling and DBT adjacent slice contrastive learning, supported by clear algorithmic descriptions and baseline comparisons
- **Medium confidence:** Claims of state-of-the-art performance on benchmark datasets, given reported metrics but limited experimental detail on training stability and cross-validation
- **Low confidence:** Generalization across different mammography vendors and breast densities, as no ablation studies test tissue mask robustness on extremely dense or low-contrast images

## Next Checks

1. **Tissue mask robustness testing:** Generate breast tissue masks on mammograms spanning the full ACR density scale (1-4) and different vendors; quantify coverage ratio distributions and identify failure modes where ρ thresholds reject valid samples

2. **Cross-slice loss sensitivity analysis:** Systematically vary DBT slice offset d (1, 2, 3 slices) and measure representation similarity between adjacent slices; evaluate whether anatomical discontinuities at larger offsets degrade feature quality

3. **Lesion masking impact assessment:** Conduct controlled experiments where small (≤5mm) lesions are deliberately masked during iBOT-M training; measure downstream detection sensitivity to quantify potential occlusion effects on clinically critical features