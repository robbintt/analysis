---
ver: rpa2
title: Enhancing Adversarial Transferability in Visual-Language Pre-training Models
  via Local Shuffle and Sample-based Attack
arxiv_id: '2511.00831'
source_url: https://arxiv.org/abs/2511.00831
tags:
- adversarial
- uni00000011
- uni00000057
- uni00000003
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the challenge of improving the transferability
  of multimodal adversarial attacks against Vision-Language Pre-training (VLP) models.
  The core method, Local Shuffle and Sample-based Attack (LSSA), tackles overfitting
  issues in existing attacks by enhancing input diversity: it randomly shuffles local
  image blocks to preserve spatial information and generate diverse adversarial images,
  then samples neighborhoods around these images to create adversarial texts using
  both original and sampled image-text pairs.'
---

# Enhancing Adversarial Transferability in Visual-Language Pre-training Models via Local Shuffle and Sample-based Attack

## Quick Facts
- arXiv ID: 2511.00831
- Source URL: https://arxiv.org/abs/2511.00831
- Reference count: 23
- Authors: Xin Liu; Aoyang Zhou; Aoyang Zhou
- One-line result: Local Shuffle and Sample-based Attack (LSSA) significantly improves multimodal adversarial attack transferability across VLP models, achieving 10-15% higher black-box success rates than existing methods.

## Executive Summary
This paper addresses the challenge of improving adversarial attack transferability in Vision-Language Pre-training (VLP) models. The authors propose Local Shuffle and Sample-based Attack (LSSA), which enhances input diversity through two key mechanisms: locally shuffling image blocks to preserve spatial information while generating diverse inputs, and creating adversarial texts using both original and sampled image neighbors. Extensive experiments demonstrate that LSSA achieves near-100% white-box attack success and significantly improves black-box transferability (10-15% gains) across various VLP architectures and downstream tasks, including image-text retrieval and visual question answering.

## Method Summary
LSSA combines local image shuffling with sample-based text generation to create adversarial examples that transfer better across VLP models. The method first partitions each image into blocks, shuffles one local region while preserving overall spatial structure, and generates multiple perturbed variants. It then accumulates gradients across these variants to create a stable perturbation direction. For the text component, LSSA generates adversarial captions using both the original image and sampled neighbors of the adversarial image, forcing misalignment across a broader feature manifold. This dual approach addresses overfitting issues in existing attacks and improves cross-model transferability.

## Key Results
- LSSA achieves near-100% white-box attack success rates across VLP models
- Improves black-box attack success rates by 10-15% compared to existing methods
- Outperforms state-of-the-art attacks on both fused models (ALBEF, TCL) and aligned models (CLIP) across multiple benchmark datasets
- Demonstrates strong cross-task transferability, maintaining effectiveness across image-text retrieval and visual question answering tasks
- Shows consistent performance improvements on Large Vision-Language Models (LVLMs)

## Why This Works (Mechanism)

### Mechanism 1: Local Shuffle Preserves Spatial Structure While Adding Diversity
- **Claim:** Shuffling only one local image block maintains spatial information for retrieval tasks while creating diverse training inputs that prevent surrogate overfitting.
- **Evidence:** Local Shuffle achieves 96.45% white-box vs 91.97% for Global Shuffle, with 56.16% vs 48.26% black-box success rates.
- **Break condition:** If target VLP model uses position-agnostic features, spatial preservation becomes irrelevant.

### Mechanism 2: Sample-Based Text Generation Disrupts Multi-Region Feature Alignment
- **Claim:** Generating adversarial text using both original and sampled neighbors creates perturbations that disrupt alignment across broader feature manifold.
- **Evidence:** Sample-based SGA outperforms standard SGA by ~6% ASR on TCL benchmark.
- **Break condition:** Poor λ tuning (λ=0 or λ=1) collapses the balance between original and sampled information.

### Mechanism 3: Momentum-Accumulated Gradients Over Shuffled Ensemble
- **Claim:** Accumulating gradients across N=20 locally-shuffled variants creates stable perturbation direction that transfers better.
- **Evidence:** ASR increases with N, plateauing at N≈20; gradient averaging finds common directions across loss landscapes.
- **Break condition:** Highly non-convex loss with many local minima may converge to weak, non-transferable directions.

## Foundational Learning

- **Concept: White-box vs. Black-box Transferability in VLP**
  - **Why needed:** Core claim is improving black-box ASR, not just white-box success
  - **Quick check:** If you achieve 99% white-box but 15% black-box ASR on different architecture, has attack succeeded?

- **Concept: Cross-Modal Feature Alignment in VLP Models**
  - **Why needed:** LSSA targets alignment disruption between image and text embeddings
  - **Quick check:** Why would adversarial text optimized against CLIP's contrastive loss potentially fail against ALBEF's multimodal encoder?

- **Concept: Input Diversity as Transferability Regularization**
  - **Why needed:** Theoretical framing relies on diversity preventing overfitting
  - **Quick check:** If doubled N from 20 to 40 and saw no ASR improvement, what would this suggest about diversity hypothesis?

## Architecture Onboarding

- **Component map:** Input (v, t) → Local Shuffle Module → N shuffled variants → Image Perturbation Loop → Adversarial Image v_adv → Sample M neighbors → Text Perturbation → Adversarial Text t_adv

- **Critical path:**
  1. Local shuffle configuration (block size, N) directly determines gradient diversity
  2. Momentum decay μ=1.0 is non-negotiable; lower values cause instability
  3. Loss weight λ=0.5 balances original vs sampled information

- **Design tradeoffs:**
  - N=20 provides maximum ASR gain but increases compute ~20x per iteration
  - Smaller block sizes increase diversity but risk spatial incoherence
  - Random shuffle position averages out positional bias

- **Failure signatures:**
  - White-box ASR drops below 95% → likely over-aggressive shuffling or incorrect block partitioning
  - Black-box ASR plateaus despite increasing N → gradient directions may be surrogate-specific
  - Text perturbation fails to change caption semantics → λ may be too high

- **First 3 experiments:**
  1. Reproduce Table 1 (ALBEF→TCL transfer) with N=0, N=10, N=20 to validate shuffle contribution
  2. Run LSSA with only Local Shuffle vs only Sample-based to isolate mechanism contributions
  3. Generate on ALBEF, test on CLIP_ViT and CLIP_CNN to verify 3-5% improvement claims

## Open Questions the Paper Calls Out
1. **Video-Language Extension:** How does LSSA perform on temporal data like video-text pairs where spatial shuffling may disrupt temporal coherence? (Authors explicitly state current focus is image-text models only)
2. **Defensive Applications:** Can LSSA's input diversity strategies be used for robust adversarial training defense mechanisms? (Authors suggest this connection but don't investigate)
3. **Attention Map Correlation:** Does shuffling effectiveness correlate with visual backbone attention heatmaps (ViT vs CNN)? (Authors observe position-dependent performance but don't analyze attention correlation)

## Limitations
- Heavy computational cost from N=20 ensemble increases attack generation time by ~20x per iteration
- Assumes VLP models maintain spatial structure in image representations, which may not hold for all architectures
- Sample-based text generation adds complexity without guaranteed transferability improvements if text space is poorly structured

## Confidence
- **High confidence** in local shuffle mechanism (well-supported by 5% absolute difference in Table 1)
- **Medium confidence** in sample-based text generation (novel approach with no direct corpus comparison)
- **High confidence** in overall attack performance improvements (10-15% gains consistently shown)

## Next Checks
1. **Transferability gap analysis:** Test LSSA attacks against ALBEF systematically on CLIP_ViT, CLIP_CNN, and two other VLP architectures to verify 3-5% improvement holds across diverse architectures
2. **Computational efficiency test:** Implement dynamic N selection that monitors gradient variance and stops early when additional variants no longer improve ASR, validating if practical runtime can be reduced
3. **Spatial coherence stress test:** Evaluate LSSA against position-agnostic VLP models (if available) to determine if spatial preservation assumption is critical for transferability gains