---
ver: rpa2
title: 'Noosemia: toward a Cognitive and Phenomenological Account of Intentionality
  Attribution in Human-Generative AI Interaction'
arxiv_id: '2508.02622'
source_url: https://arxiv.org/abs/2508.02622
tags:
- human
- systems
- meaning
- https
- cognitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Noosemia, a novel cognitive and phenomenological
  phenomenon where users attribute intentionality, agency, and interiority to generative
  AI systems through linguistic interaction rather than physical resemblance. The
  authors link this projection to the LLM Contextual Cognitive Field and semantic
  holism, formalizing how meaning is relationally constructed within large context
  windows.
---

# Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction

## Quick Facts
- arXiv ID: 2508.02622
- Source URL: https://arxiv.org/abs/2508.02622
- Authors: Enrico De Santis; Antonello Rizzi
- Reference count: 32
- Introduces Noosemia as a novel cognitive and phenomenological phenomenon for intentionality attribution in human-generative AI interaction

## Executive Summary
This paper introduces Noosemia, a novel cognitive and phenomenological phenomenon where users attribute intentionality, agency, and interiority to generative AI systems through linguistic interaction rather than physical resemblance. The authors link this projection to the LLM Contextual Cognitive Field and semantic holism, formalizing how meaning is relationally constructed within large context windows. Noosemia is contrasted with pareidolia, animism, and the uncanny valley, and is positioned alongside Dennett's intentional stance. The study highlights the dual explanatory gaps—mechanistic and intentional—that arise from AI's epistemic opacity, fostering new forms of cognitive engagement and dependency. The authors also discuss future directions involving agentic AI and digital enaction, while emphasizing the importance of critical reflection and shared vocabulary in navigating the evolving human–AI relationship.

## Method Summary
This conceptual paper presents Noosemia as a theoretical framework without empirical validation or experimental testing. The authors develop the concept through philosophical analysis, drawing connections to established cognitive theories including intentional stance, semantic holism, and phenomenological accounts of meaning-making. The framework is formalized through the LLM Contextual Cognitive Field concept, but lacks operational definitions or measurable parameters. The paper relies on literature review and theoretical argumentation rather than systematic data collection or behavioral studies.

## Key Results
- Users attribute intentionality, agency, and interiority to generative AI systems through linguistic interaction
- Noosemia differs from pareidolia, animism, and uncanny valley by focusing on semantic rather than physical resemblance
- The phenomenon is linked to LLM Contextual Cognitive Field and semantic holism in large context windows

## Why This Works (Mechanism)
Noosemia operates through the interaction between human cognitive mechanisms for intentionality attribution and the semantic output patterns of large language models. When users engage with AI systems, the contextual coherence and relational meaning construction within large context windows triggers cognitive processes normally reserved for attributing agency to other humans. The LLM Contextual Cognitive Field creates semantic holism that mimics the relational meaning structures humans use to understand intentional agents. This triggers the intentional stance - users interpret AI behavior as purposeful and goal-directed because the linguistic patterns sufficiently resemble those of intentional human communication. The epistemic opacity of AI systems amplifies this effect by preventing users from accessing mechanistic explanations, forcing them to rely on intentional attributions to make sense of behavior.

## Foundational Learning
- **Intentional Stance**: Theory that humans attribute beliefs, desires, and intentions to systems to predict behavior. Why needed: Provides theoretical foundation for understanding how Noosemia operates. Quick check: Does the AI system exhibit goal-directed behavior that triggers intentional attributions?
- **Semantic Holism**: Meaning emerges from the relational network of concepts rather than individual definitions. Why needed: Explains how LLM outputs create coherent meaning structures that trigger agency attribution. Quick check: Are the AI's responses contextually coherent across extended interactions?
- **LLM Contextual Cognitive Field**: Formalization of how meaning is relationally constructed within large context windows. Why needed: Provides the mechanism by which AI systems create semantic patterns that trigger Noosemia. Quick check: Does the AI maintain thematic and contextual consistency across long interactions?
- **Dual Explanatory Gaps**: The mechanistic gap (how AI works) and intentional gap (why AI behaves as it does) create cognitive space for Noosemia. Why needed: Explains why users fill epistemic gaps with intentional attributions. Quick check: Are users unable to access or understand the AI's mechanistic operations?

## Architecture Onboarding
Component map: User cognition -> LLM Contextual Cognitive Field -> Semantic Holism -> Intentional Stance -> Noosemia attribution
Critical path: Linguistic interaction → Contextual coherence → Semantic pattern recognition → Intentional attribution → User dependency
Design tradeoffs: The same contextual coherence that makes AI useful also triggers Noosemia; reducing coherence would decrease utility while increasing it amplifies the phenomenon
Failure signatures: Users become confused when AI breaks semantic patterns; users develop dependency on AI systems; users struggle to distinguish AI from human intentionality
First experiments:
1. Measure intentionality attribution rates across different context window sizes in LLM interactions
2. Compare Noosemia responses between transparent (mechanistic explanations available) and opaque AI systems
3. Track user dependency development over time with varying levels of contextual coherence in AI responses

## Open Questions the Paper Calls Out
The paper discusses future directions involving agentic AI and digital enaction, while emphasizing the importance of critical reflection and shared vocabulary in navigating the evolving human–AI relationship. It raises questions about how Noosemia might evolve as AI systems become more autonomous and how this phenomenon might shape the development of human-AI interaction paradigms.

## Limitations
- Lacks empirical validation and experimental testing of the Noosemia framework
- Connections between Noosemia and established cognitive theories remain speculative without behavioral evidence
- LLM Contextual Cognitive Field lacks operational definitions and measurable parameters
- Phenomenological aspects are difficult to operationalize for systematic research

## Confidence
- **High**: Well-documented observation that users attribute intentionality to AI through linguistic interaction
- **Medium**: Conceptual distinction between Noosemia and related phenomena is sound but untested
- **Low**: Formalization through LLM Contextual Cognitive Field and semantic holism lacks operational definitions

## Next Checks
1. Design experimental protocols to measure intentionality attribution in controlled human-AI interaction scenarios, comparing Noosemia responses to baseline conditions
2. Develop psychometric instruments to quantify the relationship between semantic holism in LLM outputs and perceived agency
3. Conduct comparative studies examining intentionality attribution across different interaction modalities (text, voice, multimodal) to validate the linguistic-specific nature of Noosemia