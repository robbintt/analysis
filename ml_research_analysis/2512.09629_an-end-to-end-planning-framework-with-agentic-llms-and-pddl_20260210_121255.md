---
ver: rpa2
title: An End-to-end Planning Framework with Agentic LLMs and PDDL
arxiv_id: '2512.09629'
source_url: https://arxiv.org/abs/2512.09629
tags:
- planning
- pddl
- plan
- problem
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an end-to-end framework that converts natural
  language specifications into PDDL models, then uses an orchestrator and specialized
  agents to iteratively refine the models for correctness and optimality. The system
  dynamically selects agents based on solver and validator feedback, generating PDDL
  domains and problems without human intervention.
---

# An End-to-end Planning Framework with Agentic LLMs and PDDL

## Quick Facts
- arXiv ID: 2512.09629
- Source URL: https://arxiv.org/abs/2512.09629
- Reference count: 40
- One-line primary result: Framework achieves 30% accuracy gains on Google NaturalPlan and 40% on PlanBench vs baseline LLMs

## Executive Summary
This paper presents an end-to-end framework that converts natural language specifications into PDDL models, then uses an orchestrator and specialized agents to iteratively refine the models for correctness and optimality. The system dynamically selects agents based on solver and validator feedback, generating PDDL domains and problems without human intervention. Experimental results show accuracy improvements of up to 30% on Google NaturalPlan and 40% on PlanBench benchmarks compared to baseline LLMs, with verified accuracy gains across multiple domains.

## Method Summary
The framework uses an orchestrator LLM to convert natural language specifications into structured JSON representations, then generates PDDL domains and problems. A solver attempts to generate plans, with validator feedback (VAL/uVAL) triggering iterative refinement by specialized agents (SyntaxPDDL, DeepThinkConstraints, TemporalConsistency, etc.). The orchestrator dynamically selects agents based on observed defects rather than following a fixed pipeline. Plans are validated externally and back-translated to natural language for interpretability.

## Key Results
- 30% accuracy improvement on Google NaturalPlan calendar scheduling, meeting planning, and trip planning tasks
- 40% accuracy improvement on PlanBench logistics, depots, and Blocksworld benchmarks
- Successfully solves challenging Tower of Hanoi instances where standard LLMs fail
- Verified accuracy gains demonstrate robustness across multiple planning domains

## Why This Works (Mechanism)

### Mechanism 1
Iterative refinement with external verifier feedback reduces PDDL generation errors that LLMs produce in a single pass. The orchestrator routes solver/validator logs (syntax errors, semantic mismatches) to specialized agents which patch specific defect classes. This decomposition isolates error types rather than attempting monolithic correction. Core assumption: Error signals from VAL/uVAL are sufficiently diagnostic for the orchestrator to select a corrective agent.

### Mechanism 2
Dynamic agent orchestration adapts workflow to task-specific failure modes better than fixed pipelines. The orchestrator maintains history of previously selected agents and chooses the next agent based on current artifacts (PDDL domain/problem, plan, logs) rather than following a predetermined sequence. Agent selection is conditional on observed defect type. Core assumption: The orchestrator LLM can reliably diagnose artifact state and map it to agent capabilities described in its prompt.

### Mechanism 3
PDDL as an intermediate representation grounds LLM output in formal semantics, enabling correctness guarantees from external solvers. Natural language → JSON → PDDL domain + problem → solver plan → natural language back-translation. The solver guarantees plan validity w.r.t. the PDDL model; validators check PDDL conformance. Core assumption: The NL→JSON→PDDL translation preserves semantic intent without critical information loss.

## Foundational Learning

- **PDDL (Planning Domain Definition Language) syntax and semantics**: The framework's core artifact is PDDL; understanding domain/problem structure, predicates, actions, preconditions, and effects is prerequisite to debugging agent behavior.
  - Quick check: Given a blocks-world action "pick-up(block)", what would its preconditions and effects look like in PDDL?

- **Automated planning fundamentals (STRIPS/heuristic search)**: The framework delegates to solvers like Fast Downward; understanding what solvers guarantee (completeness, optimality) and their limitations informs when refinement loops should terminate.
  - Quick check: Why does Fast Downward reject PDDL with :fluents or conditional effects?

- **Multi-agent coordination constraints**: The JSON representation models multiple agents with private information and goals; understanding how constraints propagate across agents clarifies orchestrator design.
  - Quick check: In calendar scheduling, what happens if two agents' availability intervals are specified at different time granularities?

## Architecture Onboarding

- **Component map**: NL input → JSON Generator → PDDL Generator → Solver → Validator → Orchestrator → Agent Pool → PDDL Generator → Solver (iterate) → Back-translator → NL output
- **Critical path**: 1. NL input → JSON representation (orchestrator-guided) 2. JSON → initial PDDL domain + problem 3. PDDL → solver → plan (or failure) 4. Validator logs → orchestrator → agent selection 5. Agent modifies PDDL → return to step 3 (iterate until valid or budget exhausted) 6. Valid plan → back-translation → NL output
- **Design tradeoffs**: Budget vs. quality (more refinement improves correctness but increases latency and cost); Agent pool size (more specialized agents enable finer-grained repairs but increase orchestrator decision complexity); Human-in-the-loop (Clarifier agent improves handling of ambiguous specs but requires human intervention)
- **Failure signatures**: Orchestrator repeatedly selects same agent without progress (check agent capability vs. actual error type); Solver timeout on large problems (reduce PDDL problem size or increase timeout agent threshold); Plan semantically wrong despite passing validator (constraint mis-specification in NL→JSON or JSON→PDDL stages); Back-translation produces incoherent NL (verify AgentNaturalLanguage has full action predicate context)
- **First 3 experiments**: 1. Reproduce Blocksworld "Easy" results (2-4 actions) with a single agent (SyntaxPDDL only) vs. full pool to isolate contribution of orchestration. 2. Inject a known syntax error into a valid PDDL problem and trace which agent the orchestrator selects and whether repair succeeds within budget. 3. Run Google NaturalPlan calendar scheduling with and without TemporalConsistency agent to quantify its specific contribution.

## Open Questions the Paper Calls Out

- **How can the brittleness of dynamic orchestration be mitigated to reduce sensitivity to slight variations in input prompts and the agent pool?** The authors observe that "agentic systems are brittle" because introducing a specific agent (TemporalConsistency) causes the orchestrator to select it in "most cases" regardless of the specific task context. A formal analysis of agent selection probability distributions or a benchmark measuring success rate variance against prompt perturbations and varying agent pools would resolve this.

- **What formal evaluation methods can replace "LLM-as-a-Judge" to reliably verify plan correctness without requiring superior model performance?** The discussion notes that unless the judge model is superior to the generator, it risks failing to understand the task, making evaluation "ill-posed" and an "open problem." Development of a standardized evaluation protocol that maps natural language plans to formal verifier inputs (like VAL) to objectively check constraints without a generative judge would resolve this.

- **What are the theoretical convergence properties and optimality guarantees of dynamically generated multi-agent workflows?** In the conclusion, the authors state that "a deeper theoretical analysis of the properties of dynamically generated workflows may provide new insights" into the intersection of learning-based orchestration and symbolic guarantees. A theoretical framework defining the conditions (e.g., agent capability bounds, finite state space) under which the agentic loop is guaranteed to terminate with a valid, cost-optimal plan would resolve this.

## Limitations
- The framework's reliance on GPT-5-mini (a model not publicly available) limits immediate reproducibility and may affect scalability claims if substituted with current models
- Performance gains are benchmark-specific; the framework shows weaker results on Blocksworld compared to domain-specific baselines, suggesting limited generalization
- The orchestrator's decision-making process lacks transparency regarding how it maps validator feedback to specific agent capabilities

## Confidence
- **High confidence**: The iterative refinement mechanism improves PDDL correctness over single-pass LLM generation (supported by comparative benchmarks and VAL/uVAL validation)
- **Medium confidence**: Dynamic orchestration outperforms static pipelines (indirect evidence from agent usage patterns; no direct comparison provided)
- **Low confidence**: The framework achieves "end-to-end" planning without human intervention (human-in-the-loop Clarifier agent exists but was disabled in experiments)

## Next Checks
1. Reproduce Blocksworld "Easy" results (2-4 actions) with single agent (SyntaxPDDL only) vs. full pool to isolate orchestration contribution
2. Inject known syntax errors into valid PDDL problems and trace orchestrator agent selection to verify diagnostic capability
3. Run Google NaturalPlan calendar scheduling with and without TemporalConsistency agent to quantify its specific contribution (second-most frequent agent for this task)