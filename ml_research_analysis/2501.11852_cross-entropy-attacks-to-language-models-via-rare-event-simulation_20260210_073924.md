---
ver: rpa2
title: Cross-Entropy Attacks to Language Models via Rare Event Simulation
arxiv_id: '2501.11852'
source_url: https://arxiv.org/abs/2501.11852
tags:
- adversarial
- attack
- attacks
- performance
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating effective adversarial
  examples for black-box NLP models, where the lack of model access and the discrete
  nature of text complicate the optimization process. Existing methods often struggle
  with versatility, limited performance, and semantic integrity.
---

# Cross-Entropy Attacks to Language Models via Rare Event Simulation

## Quick Facts
- arXiv ID: 2501.11852
- Source URL: https://arxiv.org/abs/2501.11852
- Reference count: 40
- Primary result: Novel Cross-Entropy Attacks (CEA) achieve superior attack success rates (e.g., 98% on AG News with BERT) while maintaining high semantic similarity and fluency compared to state-of-the-art baselines.

## Executive Summary
This paper introduces Cross-Entropy Attacks (CEA), a novel approach for generating adversarial examples against black-box NLP models. CEA treats adversarial example generation as a rare event simulation problem, using cross-entropy optimization to iteratively identify optimal word substitutions. The method employs sememe-level substitutions to preserve semantic coherence and defines specific adversarial objectives for both soft-label and hard-label settings. Experiments on document classification and neural machine translation tasks demonstrate CEA's effectiveness, achieving high attack success rates while maintaining imperceptibility and text quality.

## Method Summary
CEA generates adversarial examples through an iterative Cross-Entropy optimization process. For each word position, it constructs a candidate substitution set by intersecting context-aware predictions from a Masked Language Model (MLM) with sememe-based synonyms from HowNet. The CE optimizer maintains a probability distribution over these candidates, samples N=100 candidates per iteration, and updates the distribution parameters based on the top-performing fraction (1-ρ=0.5) of candidates. The method employs different objective functions for soft-label (using confidence scores) and hard-label (binary indicator) settings, with a maximum of 50 iterations per attack.

## Key Results
- CEA achieves 98% attack success rate on AG News dataset with BERT in soft-label settings.
- The method maintains high semantic similarity (USE-based SS scores) while requiring fewer word modifications compared to baselines.
- CEA outperforms state-of-the-art black-box attack methods in both attack success rates and semantic preservation metrics.

## Why This Works (Mechanism)

### Mechanism 1: Rare Event Simulation for Discrete Optimization
The method treats adversarial example generation as a rare event simulation problem, assuming valid adversarial examples exist as low-probability configurations within the space of word substitutions. By iteratively sampling from a multivariate Categorical distribution and updating parameters to maximize the likelihood of "elite" samples (those exceeding performance threshold γ), the algorithm shifts probability mass toward successful attacks without requiring model gradients.

### Mechanism 2: Iterative Distribution Refinement via Elite Sampling
In each iteration, N adversarial candidates are sampled and performance scores are computed. The algorithm sorts candidates and updates substitution probabilities based on their frequency among the top (1-ρ) quantile of performers. This effectively "prunes" unpromising substitutions and amplifies effective ones by focusing only on the top-performing fraction of candidates.

### Mechanism 3: Sememe-Guided Semantic Preservation
The candidate set for each word is the intersection of context-aware predictions from a Masked Language Model and sememe-based synonyms from HowNet. This dual constraint ensures replacements are both grammatically plausible (via MLM) and semantically grounded (via sememes), reducing the trade-off between attack success and text quality.

## Foundational Learning

- **Concept: Cross-Entropy Method (CEM)**
  - Why needed: This is the core optimization engine that differs from standard deep learning "Cross-Entropy Loss" - it's an iterative Monte Carlo method for rare-event simulation and combinatorial optimization.
  - Quick check: Can you explain how the "elite sample" concept in CEM differs from "batch gradient descent"?

- **Concept: Black-Box Attack Settings (Soft vs. Hard Label)**
  - Why needed: The architecture defines different objective functions based on available information - understanding this distinction is necessary to implement the correct reward signal for the optimizer.
  - Quick check: Why does the hard-label setting rely solely on the indicator function 1(F(x) ≠ y), and how does this affect optimization difficulty compared to soft-label confidence scores?

- **Concept: Sememes**
  - Why needed: The paper leverages HowNet to define semantic units smaller than words - this granularity is claimed to be critical for high-quality adversarial examples.
  - Quick check: How does a sememe-based substitution differ from a standard synonym replacement using WordNet?

## Architecture Onboarding

- **Component map:** Input Text → Generate Candidates (Offline/Once) → CE Loop: Sample → Query Victim → Evaluate → Update → Output: Best Substitution
- **Critical path:** Input Text → Generate Candidates (Offline/Once) → **CE Loop:** Sample → Query Victim → Evaluate → Update → **Output:** Best Substitution
- **Design tradeoffs:**
  - Sample Size (N=100): Larger N improves exploration but linearly increases query cost
  - Threshold Update Rate (ρ=0.5): Higher rate speeds convergence but risks premature commitment to local optima
  - Semantic Constraints: Stricter intersection guarantees fluency but may shrink candidate pool
- **Failure signatures:**
  - Stagnation: Threshold γ stops increasing before successful attack (candidate pool lacks effective words or N is too small)
  - Semantic Drift: High success but low SS scores (intersection filter is leaking or semantic penalty ε is too high)
  - Query Exhaustion: Fails to flip label within 50 iterations (common in hard-label settings with sparse signal)
- **First 3 experiments:**
  1. Hyperparameter Calibration (AG News): Run ablation on N and ρ using TextCNN to find convergence speed vs. success rate sweet spot
  2. Soft vs. Hard Label Comparison (SST2): Implement Eq 5 vs Eq 6 on same BERT victim to measure performance gap
  3. Semantic Quality Check (IMDB): Generate 100 examples and manually inspect semantic preservation claim

## Open Questions the Paper Calls Out

- **Open Question 1:** Can adaptive defense mechanisms be designed to specifically mitigate Cross-Entropy Attacks (CEA) while preserving model interpretability and usability? The paper states future research will focus on "designing adaptive defense mechanisms capable of mitigating emerging attack techniques."

- **Open Question 2:** Can cross-entropy optimization principles be applied during model training to develop inherently robust and secure NLP systems? The authors suggest "exploring the application of cross-entropy optimization principles to develop more robust and secure NLP systems."

- **Open Question 3:** How does the reliance on external knowledge bases like HowNet affect the scalability of CEA to low-resource languages lacking comprehensive sememe annotations? The method's efficacy in languages without sememe databases remains unverified as experiments are limited to English and English-to-Chinese translation.

## Limitations

- Dependence on sememe-level constraints and HowNet thesaurus quality - incomplete databases may lead to insufficient candidate pools
- Specific threshold values (ε, η) and MLM K value not specified numerically, making exact replication challenging
- Comparison limited to specific baselines without demonstrating generalizability to other attack types (e.g., targeted attacks)

## Confidence

- **High Confidence:** The CE optimization mechanism for rare event simulation is theoretically sound and well-supported by black-box optimization literature; claim of outperforming baselines is directly supported by experimental results
- **Medium Confidence:** Sememe-based semantic constraints are novel but effectiveness heavily tied to HowNet quality; "superior imperceptibility" relies on proxy measures rather than human evaluation
- **Low Confidence:** No detailed ablation on sememe constraint's isolated contribution; hard-label performance claims should be interpreted cautiously due to inherent setting difficulty

## Next Checks

1. **Candidate Pool Size Ablation:** Reproduce AG News attack with varying K values (10, 50, 100) and with sememe constraint removed to quantify HowNet intersection contribution to success and semantic preservation

2. **Hard-Label Objective Function Test:** Implement exact hard-label objective function (Eq 6) and run side-by-side comparison with soft-label version (Eq 5) on SST2 using same BERT model to measure empirical performance gap

3. **Manual Semantic Inspection:** Generate 50 adversarial examples from IMDB dataset and conduct human evaluation of semantic preservation, focusing on cases where sememe-intersection allowed successful substitutions