---
ver: rpa2
title: Safe Online Bid Optimization with Return on Investment and Budget Constraints
arxiv_id: '2201.07139'
source_url: https://arxiv.org/abs/2201.07139
tags:
- gcbsafe
- constraints
- budget
- problem
- constraint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies online bid optimization for advertising campaigns
  with Return on Investment (ROI) and budget constraints. The core challenge is that
  exploration during learning may violate these constraints, making algorithms unsafe
  for real-world use.
---

# Safe Online Bid Optimization with Return on Investment and Budget Constraints

## Quick Facts
- **arXiv ID:** 2201.07139
- **Source URL:** https://arxiv.org/abs/2201.07139
- **Reference count:** 40
- **Primary result:** No algorithm can guarantee both sublinear regret and sublinear constraint violations for ROI/budget-constrained bidding unless P = NP.

## Executive Summary
This paper studies online bid optimization for advertising campaigns with strict Return on Investment (ROI) and budget constraints. The core challenge is that exploration during learning may violate these constraints, making algorithms unsafe for real-world use. The authors prove that no algorithm can guarantee both sublinear regret and sublinear constraint violations unless P = NP. They propose three algorithms: GCB achieves sublinear regret but incurs linear constraint violations; GCBsafe ensures constraint safety w.h.p. at the cost of linear regret; and GCBsafe(ψ, φ) trades small tolerances on the ROI and budget constraints for both sublinear regret and safety. Experiments on synthetic data confirm these theoretical findings and show GCBsafe(ψ, 0) with small ψ provides a practical balance between revenue and safety.

## Method Summary
The paper proposes a Combinatorial Bandit framework where each "arm" is a vector of bids across N subcampaigns. Click and cost functions are modeled using Gaussian Processes, allowing the system to learn without parametric assumptions. The GCB algorithm uses optimistic GP bounds to maximize revenue, while GCBsafe uses conservative bounds to guarantee safety w.h.p. GCBsafe(ψ, φ) introduces fixed tolerances to the constraints, breaking the theoretical impossibility of achieving both sublinear regret and safety. The optimization is solved via Dynamic Programming over discretized bid and cost spaces.

## Key Results
- Proves an impossibility result: no algorithm can guarantee both sublinear regret and sublinear constraint violations unless P = NP.
- GCB achieves sublinear regret but incurs linear constraint violations.
- GCBsafe ensures constraint safety w.h.p. but suffers linear regret.
- GCBsafe(ψ, φ) with appropriate tolerances achieves both sublinear regret and safety.
- Experiments confirm theoretical findings and show GCBsafe(ψ, 0) provides practical balance.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Optimizing for revenue using optimistic estimates (GCB) leads to high revenue but frequent constraint violations, whereas using conservative estimates (GCBsafe) ensures safety but limits revenue growth.
- **Mechanism:** The algorithm constructs confidence intervals around expected clicks and costs using Gaussian Processes. GCB applies an "optimism in the face of uncertainty" approach, using upper bounds for both the revenue objective and the constraint numerators. This artificially inflates the feasible set, often selecting bids that violate real-world constraints. GCBsafe conversely uses lower bounds for the ROI numerator and upper bounds for costs in the constraints, artificially shrinking the feasible set to ensure safety w.h.p.
- **Core assumption:** The underlying click and cost functions are well-modeled by Gaussian Processes, and stochastic noise is sub-Gaussian.
- **Evidence anchors:**
  - [Abstract]: "We provide the GCB algorithm that guarantees sublinear regret at the cost of a linear number of constraint violations and GCBsafe... at the cost of a linear regret."
  - [Section 5.1]: Comparison of $\bar{w}_j$ and $\underline{w}_j$ definitions in Equations (6) vs (8)-(10).
  - [Corpus]: The neighbor paper "Online Bidding Algorithms with Strict Return on Spend (ROS) Constraint" also addresses strict constraints, though this paper uniquely highlights the theoretical tradeoff (Theorem 2) preventing simultaneous sublinear regret and violations.
- **Break condition:** If the noise distribution is heavy-tailed (non-sub-Gaussian), the confidence intervals $b_t$ may fail to bound the true parameters, causing GCBsafe to violate safety guarantees.

### Mechanism 2
- **Claim:** Introducing small, fixed tolerances ($\psi, \phi$) to the constraints breaks the theoretical impossibility of achieving simultaneous sublinear regret and sublinear safety.
- **Mechanism:** GCBsafe($\psi, \phi$) solves an "auxiliary" optimization problem with a relaxed ROI threshold ($\lambda - \psi$) and expanded budget ($\beta + \phi$). This expansion creates a "safety buffer" larger than the maximum estimation error. By optimizing for the relaxed constraints (which are strictly easier to satisfy), the algorithm can explore the action space (achieving sublinear regret) while ensuring the solution remains within the original strict constraints w.h.p.
- **Core assumption:** The tolerance values are chosen proportional to the standard deviation of the noise ($\sigma_c$) and scale with the number of subcampaigns ($N$).
- **Evidence anchors:**
  - [Section 6.3]: "GCBsafe($\psi, \phi$) guarantees both the violation w.h.p. of the constraints for a constant number of times and a pseudo-regret sublinear both in $T$..."
  - [Theorem 8]: Specifies the exact dependency of required $\psi$ and $\phi$ on noise and subcampaign count.
  - [Corpus]: Weak corpus connection; neighbor "HALO" focuses on hindsight augmentation rather than tolerance-based relaxation.
- **Break condition:** If the number of subcampaigns $N$ is very large, the required tolerance $\phi$ (which scales linearly with $N$ in Theorem 8) may become impractically large, rendering the "safe" solution effectively useless to the advertiser.

### Mechanism 3
- **Claim:** Modeling the bidding landscape as a Combinatorial Bandit with Gaussian Process (GP) surrogates allows the system to optimize over a continuous, uncertain bid space without relying on parametric assumptions.
- **Mechanism:** Instead of assuming a specific curve (e.g., sigmoid) for clicks/costs vs. bids, the system maintains a GP posterior for every subcampaign. At each round $t$, it computes $\hat{n}_{j,t-1}(x)$ and $\hat{\sigma}_{j,t-1}(x)$ (mean and std dev). These are fed into a Dynamic Programming subroutine which selects the combinatorial "super-arm" (set of bids across all subcampaigns) that maximizes total revenue while satisfying constraints derived from the GP bounds.
- **Core assumption:** The Sequential decision problem satisfies the "Lipschitz continuity" assumption, meaning similar bid vectors yield similar revenues.
- **Evidence anchors:**
  - [Section 5.1]: Equations (2)-(5) define the GP posterior updates.
  - [Algorithm 2]: The Opt subroutine uses the GP outputs $\mu$ to solve the combinatorial selection.
  - [Corpus]: Neighbor "Generative Large-Scale Pre-trained Models for Automated Ad Bidding" suggests alternative generative approaches, highlighting that this paper's mechanism relies on classical optimization (DP) over learned surrogates (GPs).
- **Break condition:** If the time horizon $T$ is very long, the GP inversion (cubic complexity in data points) becomes computationally infeasible without sparse approximations, though the paper notes the optimization subroutine itself is pseudo-polynomial.

## Foundational Learning

- **Concept:** **Combinatorial Multi-Armed Bandits (CMAB)**
  - **Why needed here:** The problem isn't picking one bid, but a vector of bids (one per subcampaign) that sum to a budget. Understanding that the "arm" is the *combination* of bids is crucial for grasping why the optimization subroutine (Algorithm 2) is necessary.
  - **Quick check question:** If I have 5 subcampaigns and 10 bid options each, is the action space size 10 or $10^5$? (Answer: $10^5$, combinatorial).

- **Concept:** **Regret vs. Constraint Violation**
  - **Why needed here:** Standard bandit theory optimizes for Regret (revenue loss). This paper introduces a dual metric: the count of days constraints were violated. You must understand that minimizing one often maximizes the other (Theorem 2).
  - **Quick check question:** Does "Safe" mean the algorithm never spends more than the budget? (Answer: No, it means violations are bounded/constant w.h.p., specifically $\delta$-safe).

- **Concept:** **Maximum Information Gain ($\gamma_T$)**
  - **Why needed here:** The regret bounds in Theorems 4 and 8 depend on $\gamma_T$, not just $T$. This term quantifies how much information the GP can extract about the unknown function over time. It is the theoretical bottleneck for convergence speed.
  - **Quick check question:** Does more data always reduce regret linearly in a GP-bandit? (Answer: No, it depends on the kernel's information gain $\gamma_T$, which often scales as $O((\ln T)^2)$ for SE kernels).

## Architecture Onboarding

- **Component map:** Input -> Estimator (GP) -> Constructor (bounds) -> Optimizer (DP) -> Executor -> Input
- **Critical path:** The interaction between the Constructor and the Optimizer. If the Constructor generates loose bounds (large $\hat{\sigma}$), the Optimizer will either over-explore (GCB) or over-constrain (GCBsafe). The system's performance hinges on the Optimizer correctly solving the pseudo-polynomial knapsack problem defined by the Constructor.
- **Design tradeoffs:**
  - GCB vs. GCBsafe: A binary choice between "make money but risk bankruptcy" vs. "stay safe but stagnate."
  - Tolerance Tuning ($\psi, \phi$): The practical middle ground. Small tolerances allow the algorithm to consider "risky but profitable" bids that are *statistically* unlikely to violate strict constraints by more than $\phi$.
  - Discretization: The paper notes the optimization problem is NP-hard for continuous variables (Theorem 1). The system relies on discretizing the bid/cost spaces ($X, Y, R$), trading precision for computational tractability.
- **Failure signatures:**
  - GCB: Consistent violation of daily budget > 50% of the time (Figure 1c).
  - GCBsafe: Revenue flatlines at a level significantly below the Clairvoyant optimum (Figure 1a, t < 20).
  - Scalability Crash: If $N$ (subcampaigns) grows large, the tolerance $\phi$ required by Theorem 8 may exceed the budget slack, effectively disabling the safety mechanism.
- **First 3 experiments:**
  1. **Sanity Check (Active Budget):** Run GCB vs. GCBsafe in a setting where the Budget is the active constraint (e.g., Exp #1). Verify that GCBsafe spends significantly less than $\beta$ while GCB exceeds $\beta$.
  2. **Tolerance Sweep (Active ROI):** Run GCBsafe($\psi$, 0) varying $\psi$ (e.g., Exp #3). Plot the "elbow curve" showing how tiny increases in $\psi$ yield large jumps in revenue without spiking violations.
  3. **Impossibility Verification:** Attempt to tune GCB (reduce confidence $b_t$) to achieve both sublinear regret and sublinear violations. Confirm Theorem 2 by observing that as violations drop, regret spikes to linear (or vice versa).

## Open Questions the Paper Calls Out

- **Dynamic Constraint Relaxation:** Can an online learning algorithm be designed to dynamically identify the active constraint and automatically relax non-active constraints during the learning process? The paper identifies this as a future direction, noting that the proposed algorithms treat constraints as static or require fixed tolerance parameters to be set a priori.

- **Constraint Relaxation vs. Revenue Trade-off:** What is the quantitative relationship between the relaxation of a specific constraint and the resulting increase in revenue? While experiments show that relaxing the ROI constraint improves revenue compared to the strictly safe algorithm, the paper provides no formal theoretical link quantifying this trade-off.

- **Scalability of Tolerance Parameters:** Can the required tolerance parameters for GCBsafe($\psi, \phi$) be made independent of the number of subcampaigns to ensure effectiveness in large-scale instances? The current theoretical bounds imply that to maintain safety in high-dimensional settings (many subcampaigns), the algorithm must accept large constraint violations, negating the safety purpose.

## Limitations
- Computational intractability for continuous action spaces requires discretization.
- GP scalability issues for large N or T.
- Impossibility of simultaneously achieving sublinear regret and constraint violations.
- Practical tolerance values may be too large when N is large.
- Results are on synthetic data with specific parametric forms.

## Confidence
- **Theorem 2 (Impossibility):** High confidence - clean reduction from known NP-hard problem.
- **Regret bounds for GCB/GCBsafe:** Medium confidence - rely on GP information gain which can be loose.
- **Tolerance-based relaxation:** Medium confidence - theory is sound but practical parameter tuning isn't fully characterized.

## Next Validation Checks
1. **Scalability Test**: Run experiments with varying N (subcampaigns) and verify whether the required tolerance φ in Theorem 8 becomes impractically large, breaking the safety mechanism.

2. **Kernel Sensitivity**: Test GCBsafe(ψ, φ) with different kernel choices (e.g., Matérn instead of SE) to validate whether the information gain bounds and resulting tolerances are kernel-dependent.

3. **Noisy Reward Analysis**: Introduce heavy-tailed noise (beyond sub-Gaussian) to check if the confidence interval construction fails, causing GCBsafe to violate its safety guarantees.