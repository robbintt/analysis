---
ver: rpa2
title: Measuring South Asian Biases in Large Language Models
arxiv_id: '2505.18466'
source_url: https://arxiv.org/abs/2505.18466
tags:
- children
- bias
- hindu
- many
- muslim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Measuring South Asian Biases in Large Language Models

## Quick Facts
- **arXiv ID:** 2505.18466
- **Source URL:** https://arxiv.org/abs/2505.18466
- **Reference count:** 40
- **Primary result:** Evaluates intersectional bias in large language models across 10 South Asian languages using 48 identity combinations and a defined bias lexicon.

## Executive Summary
This paper introduces a framework to measure intersectional biases in large language models (LLMs) across 10 South Asian languages (Indo-Aryan and Dravidian). The study uses mT0-xxl (13B parameters) to generate text for 48 unique identity combinations across 3 applications (Story, To-do List, Hobbies/Values). A bias lexicon is constructed and used to calculate an "Intersectional Bias Score" based on TF-IDF values of lexicon terms in the generated text. Two debiasing strategies (Simple and Complex) are applied and evaluated.

## Method Summary
The study evaluates intersectional bias by generating text for 48 identity combinations using mT0-xxl with specific hyperparameters (Temperature=0.7, Top-k=50). Generated text is translated to English using IndicTrans2. Bias is measured using an Intersectional Bias Score, which sums TF-IDF values for terms in a constructed bias lexicon found in the translated text. Two debiasing approaches are tested: a simple general instruction and a complex intersectional instruction. The method involves prompt construction, text generation, translation, and TF-IDF-based bias scoring.

## Key Results
- Bias scores are calculated for 48 identity combinations across 10 South Asian languages
- Two debiasing strategies (Simple and Complex) are compared
- Results show measurable intersectional bias in mT0-xxl across all tested languages
- The study demonstrates the effectiveness of intersectional instructions in reducing bias

## Why This Works (Mechanism)
The study works by systematically generating text for controlled identity combinations, then measuring bias through lexicon-based TF-IDF scoring. The intersectional approach captures how multiple identity attributes interact to produce bias, rather than treating each attribute independently.

## Foundational Learning
- **TF-IDF scoring:** Why needed - to quantify bias term importance; Quick check - verify IDF calculation handles document frequency correctly
- **Multilingual text generation:** Why needed - to evaluate bias across South Asian languages; Quick check - confirm mT0-xxl generates appropriate text for all 10 languages
- **Bias lexicon construction:** Why needed - to define measurable bias indicators; Quick check - validate lexicon terms cover all identified bias categories

## Architecture Onboarding

**Component Map:** mT0-xxl (13B) -> Text Generation -> IndicTrans2 -> English Translation -> TF-IDF Calculation -> Bias Score

**Critical Path:** Prompt Construction → mT0-xxl Generation → Translation → TF-IDF Scoring → Bias Analysis

**Design Tradeoffs:** Uses mT0-xxl for multilingual generation (tradeoff: potential quality issues in low-resource languages) vs. translating prompts to English first. TF-IDF-based scoring provides quantitative measure but may miss contextual nuances.

**Failure Signatures:** Sentinel tokens in output, English text when non-English expected, inconsistent bias scores across document lengths, translation errors affecting bias measurement.

**First Experiments:**
1. Generate text for a single identity combination to verify mT0-xxl functionality
2. Test IndicTrans2 translation on sample outputs to ensure quality
3. Calculate TF-IDF scores on a small document set to validate scoring methodology

## Open Questions the Paper Calls Out
None specified in the reproduction notes.

## Limitations
- Unspecified random seed affects reproducibility of stochastic generation
- Exact debiasing prompt phrasing needed for identical instruction following
- Potential quality issues with mT0-xxl on low-resource South Asian languages
- TF-IDF method may not capture all contextual aspects of bias

## Confidence

**High Confidence:** Experimental design, identity combination construction, and general debiasing strategies
**Medium Confidence:** Generation parameters and translation methodology
**Low Confidence:** Exact bias lexicon construction and precise TF-IDF calculation implementation

## Next Checks
1. Run mT0-xxl with specified parameters and fixed random seed, compare sample outputs to original study
2. Reconstruct bias lexicon from Tables 4-6, apply synonym expansion and lemmatization, validate against original
3. Implement exact TF-IDF formula (Equation 20) with smoothing factor, compare scores on sample document to original study values