---
ver: rpa2
title: 'CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees'
arxiv_id: '2510.19754'
source_url: https://arxiv.org/abs/2510.19754
tags:
- coverage
- confextree
- counterfactual
- conformal
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CONFEX addresses the problem of generating reliable counterfactual
  explanations by incorporating predictive uncertainty into the explanation process.
  The core method idea uses conformal prediction with localized coverage guarantees,
  solving an optimization problem via mixed-integer linear programming to find counterfactuals
  that are both close to the original instance and have high certainty in their predictions.
---

# CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees

## Quick Facts
- **arXiv ID:** 2510.19754
- **Source URL:** https://arxiv.org/abs/2510.19754
- **Reference count:** 40
- **Key outcome:** CONFEX-Tree consistently produces more plausible and stable counterfactual explanations across diverse datasets compared to state-of-the-art methods, with plausibility scores ranging from 0.42-0.72 and sensitivity scores between 0.05-0.28, while providing formal coverage guarantees that vanilla conformal prediction methods fail to achieve.

## Executive Summary
CONFEX addresses the problem of generating reliable counterfactual explanations by incorporating predictive uncertainty into the explanation process. The core method uses conformal prediction with localized coverage guarantees, solving an optimization problem via mixed-integer linear programming to find counterfactuals that are both close to the original instance and have high certainty in their predictions. The evaluation shows that CONFEX-Tree consistently produces more plausible and stable explanations across diverse datasets compared to state-of-the-art methods, with plausibility scores ranging from 0.42-0.72 and sensitivity scores between 0.05-0.28, while also providing formal coverage guarantees that vanilla conformal prediction methods fail to achieve.

## Method Summary
CONFEX generates uncertainty-aware counterfactual explanations by constraining the search space to points that lead to singleton conformal prediction regions. The method uses a tree-based spatial partitioning approach to restore local coverage guarantees that vanilla conformal prediction loses when test points are not exchangeable with calibration data. The optimization problem is solved via mixed-integer linear programming, encoding both the model and conformal constraints as linear inequalities. The approach works with various classifiers including MLPs and random forests, and provides formal coverage guarantees while maintaining interpretability through localized prediction regions.

## Key Results
- CONFEX-Tree achieves plausibility scores ranging from 0.42-0.72 across datasets, significantly outperforming baseline methods
- The method provides coverage guarantees with near-zero gap (0.1-1.2%) when using appropriate bandwidth, while CONFEX-Naive shows gaps of -18.9% to -41.1%
- Sensitivity scores remain low (0.05-0.28) indicating stable counterfactual explanations across perturbations
- The approach successfully handles both numerical and categorical features through appropriate encoding and stratification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Constraining counterfactual search to singleton conformal prediction regions yields explanations with provably higher prediction certainty.
- **Mechanism:** The optimization only accepts counterfactuals x' where C_{1-α}(x') = {y^+}, meaning the conformal prediction region contains only the target class. This is encoded via score constraints: s(x', y^+) ≤ q_{1-α} AND ∀y≠y^+: s(x', y) > q_{1-α}.
- **Core assumption:** The log-likelihood ratio score function s(x,y) = -l(x)_y + max_{y'≠y} l(x)_{y'} correctly ranks prediction certainty.
- **Evidence anchors:** [abstract] "constraining the search space for CFXs only to those points leading to a singleton prediction region"
- **Break condition:** Very small α (e.g., 0.01) with small bandwidth yields 100% failure rates—no feasible CFX satisfies singleton constraint.

### Mechanism 2
- **Claim:** Tree-based spatial partitioning restores local coverage guarantees that vanilla CP loses when test points are not exchangeable with calibration data.
- **Mechanism:** An offline kd-tree-like construction splits feature space into leaves where max L∞ distance < bandwidth h. Each leaf stores a precomputed local quantile from calibration points within that region. At test time, traversing to a leaf provides the local quantile without runtime calibration reweighting.
- **Core assumption:** The L1-box kernel H(x,x') = 1(||x-x'||_1 ≤ h) correctly defines "local" neighborhoods for the application.
- **Evidence anchors:** [Section 4.2] "P(y ∈ C^{Tree}_{1-α}(x*) | x* ∈ X_g) ≥ 1-α for all g ∈ G" — group-conditional coverage guarantee
- **Break condition:** Bandwidth too large → converges to marginal CP (loses local benefits, plausibility drops); bandwidth too small → quantiles estimated from too few points, unstable or infeasible.

### Mechanism 3
- **Claim:** MILP encoding guarantees both constraint satisfaction (valid CP regions) and optimality (minimum distance), which gradient-based methods cannot ensure.
- **Mechanism:** The classifier (if linearly representable, e.g., ReLU MLP), score function (linear in logits), and tree traversal (via big-M constraints) are all encoded as linear constraints. The solver exhaustively searches for the minimum-distance feasible point.
- **Core assumption:** The model architecture is MILP-representable; sigmoid/softmax outputs cannot be exactly encoded (but can use logits directly for classification).
- **Evidence anchors:** [Section 3] Score function "can be equivalently expressed in a linear form... making it efficiently representable in MILP"
- **Break condition:** Computational infeasibility on large models (stated in Limitations); models with non-piecewise-linear activations require approximations.

## Foundational Learning

- **Conformal Prediction (Distribution-Free Uncertainty)**
  - Why needed here: CONFEX's core innovation is wrapping CFX generation in CP's finite-sample coverage guarantees. You need to understand calibration quantiles, non-conformity scores, and why CP works without distributional assumptions.
  - Quick check question: Given a calibration set of 100 points with scores s_1,...,s_100, what quantile do you use for 90% coverage, and why is there a +∞ term in the distribution?

- **Exchangeability vs. IID**
  - Why needed here: CFX generation fundamentally violates exchangeability because the search targets specific regions (class-flipping zones) that are not randomly sampled. Understanding why this breaks standard CP guarantees motivates the entire localized approach.
  - Quick check question: If I search for counterfactuals that satisfy f(x')=y^+, am I sampling x' exchangeably with my calibration data? Why or why not?

- **MILP Encodings for Neural Networks**
  - Why needed here: The method encodes both the model and CP constraints as linear inequalities with integer variables for piecewise-linear activations and tree branches.
  - Quick check question: A ReLU activation max(0, z) can be encoded with one binary variable and big-M constraints. Sketch the three constraints needed.

## Architecture Onboarding

- **Component map:** Training Data → Classifier Training → Calibration Data → Score Computation → Tree Builder → Partition Tree (offline) → MILP Formulator → Gurobi Solver → Counterfactual x_cf

- **Critical path:**
  1. Train classifier, set aside 20% data for calibration
  2. Compute scores s(x_i, y_i) for all calibration points
  3. Build partition tree (Algorithm 1)—this is O(n log n) per stratum
  4. For each factual: formulate MILP with distance objective + singleton CP constraint + tree leaf selection, solve
  5. Validate with LOF plausibility and coverage simulation

- **Design tradeoffs:**
  - **Bandwidth h**: Start with 10-35% of median pairwise calibration distance. Smaller = more local coverage but more failures; larger = better feasibility but lower plausibility
  - **α (miscoverage rate)**: 0.05-0.1 typical. Lower = stricter certainty, fewer feasible CFXs, larger distances
  - **Tree depth vs. leaf size**: Leaves with <5 points produce unstable quantiles; merge or increase bandwidth

- **Failure signatures:**
  - `NaN` results in table → 100% failure rate (infeasible for all test points); increase bandwidth or α
  - Validity <90% → MILP encoding error or numerical issues in classifier constraints
  - High coverage gap (>5%) for CONFEX-Tree → bandwidth too large, localizing insufficiently

- **First 3 experiments:**
  1. **Sanity check on 2D synthetic data (replicate Figure 1):** Train small MLP, generate CFXs with MILP-MinDist, CONFEX-Naive, CONFEX-Tree (bandwidth=0.35×median distance, α=0.1). Plot decision boundary, calibration points, and resulting CFXs to visually confirm CONFEX-Tree finds data-supported counterfactuals while MinDist and CONFEX-Naive may not.
  2. **Bandwidth sensitivity sweep:** On CaliforniaHousing with MLP, sweep bandwidth from 0.05 to 0.45×median distance at α=0.1. Plot distance, plausibility, and coverage gap vs. bandwidth. Identify the "sweet spot" where plausibility peaks before dropping.
  3. **Coverage validation simulation:** Follow Section 5's simulated setup—sample test points, find closest point with singleton CP region, check if true label falls in prediction region. Compare empirical coverage vs. target 1-α for CONFEX-Naive vs. CONFEX-Tree across bandwidths. Confirm naive fails (gap ~-15% to -40%) while localized methods achieve near-zero gap at appropriate bandwidths.

## Open Questions the Paper Calls Out

- **Can CONFEX be adapted to scale to very large models while retaining optimality guarantees?**
  - Basis in paper: [explicit] The authors state the method "will struggle scaling to very large models" because it uses MILP, whereas gradient-based methods scale better but lack guarantees.
  - Why unresolved: MILP complexity makes the encoding computationally infeasible for large architectures like deep transformers.
  - What evidence would resolve it: A modified algorithm achieving similar coverage guarantees on large models with polynomial time complexity.

- **Is there a principled, automated method for selecting the kernel bandwidth $h$?**
  - Basis in paper: [explicit] The paper notes that "Picking an appropriate kernel bandwidth is an additional task which requires domain knowledge or evaluation on a validation set."
  - Why unresolved: Performance varies significantly with bandwidth, yet the current work relies on manual tuning or validation sets rather than an intrinsic property of the data.
  - What evidence would resolve it: A theoretical derivation or empirical strategy for optimal h selection based on local data density.

- **How robust is CONFEX in data-scarce environments regarding the size of the calibration set?**
  - Basis in paper: [explicit] The authors note that requiring a held-out calibration dataset "may be problematic when data is scarce."
  - Why unresolved: While CP guarantees technically hold, it is unclear how small calibration sets impact the practical plausibility and stability of the generated counterfactuals.
  - What evidence would resolve it: An ablation study measuring performance degradation as calibration set size decreases.

## Limitations
- Computational complexity of MILP encoding makes the method infeasible for very large models or high-dimensional feature spaces
- Requires a held-out calibration dataset, which may be problematic when data is scarce
- Bandwidth selection remains somewhat arbitrary and requires domain knowledge or validation set tuning

## Confidence
- **High Confidence:** The theoretical framework connecting singleton CP regions to counterfactual validity is well-established. The plausibility and sensitivity metrics show consistent improvements across all datasets.
- **Medium Confidence:** The MILP encoding approach is sound in theory, but practical implementation challenges (numerical stability, solver performance) could affect results. The bandwidth sensitivity findings appear robust but depend on the arbitrary bandwidth selection.
- **Low Confidence:** The coverage simulation methodology and the exact conditions under which exchangeability violations occur need more rigorous validation beyond the reported experiments.

## Next Checks
1. **Coverage Gap Validation:** Replicate the simulated coverage gap experiment from Section 5.3 using the provided methodology. Generate 1000 test points, find their closest counterfactuals with singleton CP regions, and compute empirical coverage vs. target 1-α. Compare naive vs. tree-based methods across bandwidths to verify the reported -18.9% to -41.1% gaps for naive methods.

2. **MILP Encoding Verification:** Take a small synthetic dataset (2D with clear class boundaries) and implement the full CONFEX-Tree pipeline. Manually verify that the MILP solution satisfies all constraints: singleton CP region, minimum distance, and correct tree leaf membership. Compare against a brute-force search to confirm optimality.

3. **Bandwidth Sensitivity Replication:** On the AdultIncome dataset with MLP, systematically sweep bandwidth from 0.05 to 0.45×median pairwise distance at α=0.1. Plot plausibility, distance, and coverage gap as in the paper's results. Identify the bandwidth value where plausibility peaks before dropping, validating the trade-off between local guarantees and feasibility.