---
ver: rpa2
title: Are You Sure You're Positive? Consolidating Chain-of-Thought Agents with Uncertainty
  Quantification for Aspect-Category Sentiment Analysis
arxiv_id: '2508.17258'
source_url: https://arxiv.org/abs/2508.17258
tags:
- list
- pairs
- agents
- sentiment
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates zero-shot aspect-category sentiment analysis
  (ACSA) using large language models (LLMs) without requiring labeled training data.
  The authors propose a method that employs multiple chain-of-thought (CoT) agents,
  each following a different reasoning sequence for extracting category-sentiment
  pairs, and aggregates their outputs using token-level uncertainty scores from the
  LLMs.
---

# Are You Sure You're Positive? Consolidating Chain-of-Thought Agents with Uncertainty Quantification for Aspect-Category Sentiment Analysis

## Quick Facts
- **arXiv ID:** 2508.17258
- **Source URL:** https://arxiv.org/abs/2508.17258
- **Reference count:** 30
- **Primary result:** Multi-agent LLM ensemble with uncertainty quantification achieves 5-7% F1 gain over single agents in zero-shot aspect-category sentiment analysis

## Executive Summary
This paper investigates zero-shot aspect-category sentiment analysis (ACSA) using large language models (LLMs) without requiring labeled training data. The authors propose a method that employs multiple chain-of-thought (CoT) agents, each following a different reasoning sequence for extracting category-sentiment pairs, and aggregates their outputs using token-level uncertainty scores from the LLMs. Experiments with 3B and 70B parameter Llama and Qwen models on four datasets show that combining multiple CoT agents significantly improves recall compared to individual agents. The highest probability list aggregation technique consistently yields the best results, and token confidence scores are found to correlate with prediction accuracy. The study demonstrates that zero-shot LLM approaches can effectively address ACSA tasks while avoiding annotation biases inherent in supervised learning.

## Method Summary
The method uses six CoT agents per model, each with different element ordering permutations (aspect→opinion→category variations) to generate (category, polarity) tuples from reviews. Token-level log probabilities from LLM output are extracted and converted to confidence scores. These are averaged per tuple to create confidence-weighted aggregations. Five aggregation strategies are tested: highest probability list, most common list, highest probability pairs, clustered pairs, and most confident agent. The highest probability list method, which selects the agent output with the highest mean tuple confidence, consistently outperforms others. Categories are mapped using difflib fuzzy matching against predefined domain-specific lists.

## Key Results
- Multi-agent ensemble improves recall by 5-7% F1 over individual agents across all datasets and model scales
- Highest probability list aggregation outperforms other methods consistently
- Token confidence scores correlate with prediction accuracy (correlation 0.51-0.71)
- Small 3B models over-generate pairs and produce conflicting polarities for same category, requiring careful aggregation

## Why This Works (Mechanism)
The approach leverages LLM reasoning diversity through multiple CoT permutations, capturing different valid extraction paths. Token-level uncertainty quantification provides confidence scores that correlate with prediction reliability. Ensemble aggregation mitigates individual agent biases and hallucinations. The method avoids supervised learning biases by using zero-shot prompting, though it requires predefined category lists as input.

## Foundational Learning
- **Chain-of-Thought Prompting**: Why needed - enables structured reasoning for complex extraction tasks; Quick check - verify prompt template produces expected reasoning sequence
- **Token-level Uncertainty Quantification**: Why needed - provides confidence scores for aggregation decisions; Quick check - confirm log-probs extraction from LLM API
- **Multi-agent Ensemble Methods**: Why needed - reduces individual agent bias and improves recall; Quick check - measure performance variance across agents
- **Fuzzy String Matching**: Why needed - handles category name variations and spelling differences; Quick check - test difflib threshold on known category variations
- **Multi-label Classification Metrics**: Why needed - evaluates multiple simultaneous predictions per instance; Quick check - verify micro-F1 calculation implementation
- **Aspect-Category Sentiment Analysis**: Why needed - domain-specific task requiring extraction of category-sentiment pairs; Quick check - confirm dataset format matches SemEval standards

## Architecture Onboarding

**Component Map:**
LLM API/Inference -> CoT Agent (6 permutations) -> Token Log-Prob Extraction -> Confidence Scoring -> Aggregation Engine -> Final Output

**Critical Path:**
Review text → CoT prompt generation (6 variants) → LLM inference → Token probability extraction → Tuple confidence calculation → Aggregation selection → Category mapping → Output

**Design Tradeoffs:**
- **Pro**: Zero-shot approach avoids annotation costs and biases
- **Con**: Requires predefined category lists, limiting generalization to new domains
- **Pro**: Token-level uncertainty provides interpretable confidence scores
- **Con**: Small models produce inconsistent outputs requiring careful aggregation
- **Pro**: Ensemble approach captures diverse reasoning patterns
- **Con**: Computational cost increases linearly with number of agents

**Failure Signatures:**
- Same category appears with multiple polarities (small model hallucination)
- Unmappable categories due to formatting differences
- Malformed Python list outputs from LLM
- Aggregation selects low-confidence agent due to implementation error

**3 First Experiments:**
1. Test single CoT agent with one dataset to verify basic extraction pipeline
2. Implement two-agent ensemble with highest probability list aggregation on same dataset
3. Compare token confidence correlation with accuracy using validation split

## Open Questions the Paper Calls Out
None

## Limitations
- Small datasets (max 579 test instances) limit generalizability claims
- Requires predefined category lists, not addressing open-domain discovery
- No systematic hallucination detection or false positive analysis
- Narrow comparison framework without evaluation against other zero-shot approaches

## Confidence

**Major Claims Confidence:**
- **High Confidence**: Multi-agent ensemble improves recall over individual agents; highest probability list aggregation outperforms other methods
- **Medium Confidence**: Token-level uncertainty scores correlate with prediction accuracy; method generalizes across multiple domains and model scales
- **Low Confidence**: Claims about avoiding annotation biases; superiority over all existing zero-shot approaches; robustness to noisy or unseen categories

## Next Checks

1. **Generalization Test:** Evaluate on a dataset with 50+ categories and varying domain (e.g., electronics reviews) to test scalability and cross-domain performance, particularly focusing on small model (3B) behavior with increased category complexity.

2. **Confidence Calibration Analysis:** Conduct proper calibration assessment using reliability diagrams and Expected Calibration Error metrics to determine if token-level probabilities provide meaningful uncertainty quantification beyond correlation analysis.

3. **Hallucination Detection Validation:** Implement systematic evaluation of false positive rates by introducing adversarial test cases with no valid category-sentiment pairs, measuring the method's ability to abstain from predictions when appropriate.