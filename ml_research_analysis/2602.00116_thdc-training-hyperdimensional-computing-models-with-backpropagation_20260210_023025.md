---
ver: rpa2
title: 'THDC: Training Hyperdimensional Computing Models with Backpropagation'
arxiv_id: '2602.00116'
source_url: https://arxiv.org/abs/2602.00116
tags:
- thdc
- hyperdimensional
- computing
- encoding
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: THDC introduces trainable embeddings and a one-layer binary neural
  network to jointly learn Item Memory and Associative Memory in hyperdimensional
  computing, enabling end-to-end training via backpropagation. This approach addresses
  limitations of static hypervectors and ultra-high dimensionality while preserving
  efficient inference.
---

# THDC: Training Hyperdimensional Computing Models with Backpropagation

## Quick Facts
- arXiv ID: 2602.00116
- Source URL: https://arxiv.org/abs/2602.00116
- Reference count: 18
- Primary result: Achieves 15.38% average accuracy improvement over baseline HDC at 8000 dimensions and reaches 94.50% accuracy on Fashion-MNIST at just 64 dimensions

## Executive Summary
THDC introduces trainable embeddings and a one-layer binary neural network to jointly learn Item Memory and Associative Memory in hyperdimensional computing, enabling end-to-end training via backpropagation. This approach addresses limitations of static hypervectors and ultra-high dimensionality while preserving efficient inference. Evaluated on MNIST, Fashion-MNIST, and CIFAR-10, THDC achieves accuracy improvements over baseline HDC (15.38% average increase at 8000 dimensions) and matches or exceeds learning-based HDC models at lower dimensions. Notably, THDC reaches 94.50% accuracy on Fashion-MNIST at just 64 dimensions, and 48.48% on CIFAR-10 at 1000 dimensions. t-SNE visualizations confirm that learned embeddings produce clearer class clusters than random initialization. The method maintains inference efficiency while significantly reducing dimensionality requirements, making HDC more suitable for resource-constrained edge devices.

## Method Summary
THDC modifies traditional HDC by replacing randomly initialized Item Memory (IM) with trainable embedding matrices for position and value representations, and learning the Associative Memory (AM) through a one-layer binary neural network trained end-to-end with backpropagation. The method uses straight-through estimator to handle binarization during training, allowing gradients to flow through both embeddings and classifier weights. After training, the binarized classifier weights become the class hypervectors in AM, while the trained embeddings form the learned IM. The approach is evaluated on image classification tasks (MNIST, Fashion-MNIST, CIFAR-10) with dimensionality ranging from 32 to 8000, demonstrating significant accuracy improvements and dimensional efficiency compared to baseline HDC.

## Key Results
- 15.38% average accuracy improvement over baseline HDC at 8000 dimensions
- 94.50% accuracy on Fashion-MNIST at just 64 dimensions (vs 8000 required for baseline HDC)
- 48.48% accuracy on CIFAR-10 at 1000 dimensions
- t-SNE visualizations show clearer class clusters with learned embeddings vs random initialization
- Dimensionality reduced from 10,000 to as low as 64 while maintaining or improving accuracy

## Why This Works (Mechanism)

### Mechanism 1
Trainable embeddings produce more discriminative hypervector representations than static random initialization. Position and value embeddings are optimized via backpropagation, learning to map semantically similar inputs to hypervectors that cluster together in representation space. This replaces reliance on near-orthogonality from random high-dimensional vectors with learned, task-adaptive structure. The core assumption is that optimal representation subspace exists where class-discriminative information is preserved more efficiently than through random projection.

### Mechanism 2
A single-layer binary neural network is sufficient to learn optimal class hypervectors when combined with trainable embeddings. The BNN classifier is trained end-to-end using cross-entropy loss with straight-through estimator, allowing gradients to flow through binarized weights. After training, binary weights become class hypervectors in Associative Memory, replacing heuristic bundling of encoded samples. The core assumption is that binary weights provide sufficient representational capacity for class discrimination when input embeddings are well-optimized.

### Mechanism 3
Joint learning of Item Memory and Associative Memory enables dimensional efficiency without sacrificing accuracy. Simultaneous optimization allows embeddings and classifier weights to co-adapt—embeddings learn representations easier for classifier to separate, while classifier learns decision boundaries matching embedding space geometry. This eliminates redundancy inherent in treating all training samples equally during AM construction. The core assumption is that optimal IM and AM are interdependent and can only be found through joint optimization.

## Foundational Learning

- **Hyperdimensional Computing (HDC) Fundamentals**: Understanding how binding combines position and value, how bundling aggregates information, and how similarity comparison retrieves class predictions is essential since THDC modifies core HDC components. Quick check: Given a 1000-dimensional hypervector representing an image, how would you classify it using an Associative Memory containing 10 class hypervectors?

- **Binary Neural Networks and Straight-Through Estimator (STE)**: THDC trains a one-layer BNN using STE to propagate gradients through binarized weights. Understanding why binarization normally blocks gradients and how STE approximates them is essential for debugging training instability. Quick check: Why can't we directly compute gradients through a sign function, and how does the straight-through estimator solve this?

- **Embedding Layers as Lookup Tables**: Position and value memories are implemented as trainable embedding matrices. Understanding that embeddings are learned lookup tables mapping discrete indices to continuous vectors clarifies how THDC replaces random hypervectors with adaptive representations. Quick check: If you have 64 color bins and want 1000-dimensional embeddings, what is the shape of the value embedding matrix V?

## Architecture Onboarding

- Component map: Input -> Position Memory (P) -> Value Memory (V) -> Encoding (binding + bundling) -> BNN Classifier -> Output

- Critical path: 1) Initialize P and V with random values; initialize binary classifier weights; 2) For each image: encode -> pass through BNN -> compute cross-entropy loss; 3) Backpropagate using STE: gradients flow to classifier weights and embeddings; 4) Update P, V, and classifier weights via Adam optimizer; 5) After convergence: binarize classifier weights -> store as class hypervectors (AM); extract P and V as learned IM

- Design tradeoffs:
  - **Dimensionality (D)**: Lower D reduces memory and computation but may lose discriminative power. Paper shows D=64 works for MNIST/Fashion-MNIST; CIFAR-10 needs D≥1000
  - **Encoding scheme**: Color-bin encoding (64 bins) preserves semantic color relationships and reduces IM size vs. channel concatenation, but loses fine-grained RGB information
  - **Single-layer BNN**: Maintains inference efficiency but limits expressiveness for complex tasks—acknowledged limitation for CIFAR-10

- Failure signatures:
  - Training loss plateaus early with low accuracy: Embeddings may be initialized poorly or learning rate is too high/low. Check gradient magnitudes
  - t-SNE shows overlapping clusters after training: IM not learning discriminative representations—may need longer training or different encoding
  - Large gap between training and test accuracy: Overfitting due to insufficient dimensionality or too many embedding parameters relative to data
  - Inference accuracy differs from training accuracy: Verify classifier weights are properly binarized and AM is correctly extracted

- First 3 experiments:
  1. **Baseline comparison at D=1000**: Implement THDC on MNIST with random (fixed) embeddings vs. learned embeddings. Plot accuracy curves and t-SNE of encoded samples to verify clustering improvement
  2. **Dimensionality sweep**: Train THDC on Fashion-MNIST with D∈{32, 64, 100, 1000, 2000, 4000, 8000}. Compare against baseline HDC to reproduce the paper's dimensionality-accuracy tradeoff curve
  3. **Encoding ablation on CIFAR-10**: Compare flattened RGB encoding vs. color-bin encoding at D=1000. Quantify accuracy difference and measure IM memory footprint to validate the semantic preservation claim

## Open Questions the Paper Calls Out
- How can data-specific encoding schemes be automatically designed or optimized to maximize the benefits of trainable Item Memory?
- Can learning-based HDC methods bridge the accuracy gap with deep neural networks on complex recognition tasks?
- Do the advantages of trainable embeddings generalize to non-image HDC applications, such as speech recognition or robotic control?

## Limitations
- CIFAR-10 performance (48.48% at 1000 dimensions) remains substantially below traditional deep learning approaches, suggesting single-layer BNN architecture has inherent limitations for complex visual tasks
- The paper does not extensively explore whether multi-layer architectures or alternative encoding schemes could close the accuracy gap while preserving efficiency
- Long-term generalization and robustness claims are not extensively analyzed, focusing primarily on accuracy metrics without detailed analysis of model stability or adversarial robustness

## Confidence
- **High Confidence**: Dimensionality reduction effectiveness (MNIST/Fashion-MNIST results), learned embeddings producing clearer class clusters (t-SNE evidence), and inference efficiency preservation
- **Medium Confidence**: CIFAR-10 results and generalizability to more complex tasks, as the performance gap with traditional methods is significant and the architecture's limitations are acknowledged
- **Low Confidence**: Long-term generalization and robustness claims, as the paper focuses primarily on accuracy metrics without extensive analysis of model stability or adversarial robustness

## Next Checks
1. **Multi-layer BNN ablation**: Implement THDC with 2-3 layer binary networks on CIFAR-10 to determine whether the single-layer constraint is the primary bottleneck for complex tasks, while measuring the tradeoff with inference efficiency
2. **Cross-domain generalization test**: Evaluate THDC on a non-image HDC task (e.g., EEG signal classification or text data) to verify that learned embeddings provide benefits beyond image-specific patterns
3. **Robustness analysis**: Test THDC against input noise, adversarial examples, and distribution shifts to quantify whether dimensional efficiency gains compromise model resilience compared to traditional HDC