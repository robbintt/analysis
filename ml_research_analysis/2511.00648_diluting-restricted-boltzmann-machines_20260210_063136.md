---
ver: rpa2
title: Diluting Restricted Boltzmann Machines
arxiv_id: '2511.00648'
source_url: https://arxiv.org/abs/2511.00648
tags:
- pruning
- training
- trained
- networks
- quality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether sparse neural networks can maintain
  strong generative performance by studying Restricted Boltzmann Machines (RBMs) under
  extreme pruning conditions. The authors trained RBMs on MNIST, then applied progressive
  pruning to both randomly initialized and fully trained networks, examining the impact
  on generation quality using multiple metrics.
---

# Diluting Restricted Boltzmann Machines

## Quick Facts
- arXiv ID: 2511.00648
- Source URL: https://arxiv.org/abs/2511.00648
- Authors: C. DÃ­az-Faloh; R. Mulet
- Reference count: 31
- Key outcome: RBMs maintain high-quality generation even when up to 80% of connections are pruned before training, but cannot recover performance through retraining after additional pruning.

## Executive Summary
This paper investigates whether sparse neural networks can maintain strong generative performance by studying Restricted Boltzmann Machines (RBMs) under extreme pruning conditions. The authors trained RBMs on MNIST, then applied progressive pruning to both randomly initialized and fully trained networks, examining the impact on generation quality using multiple metrics. They found that RBMs can achieve high-quality generation even when up to 80% of connections are pruned before training, supporting the Lottery Ticket Hypothesis. However, performance degrades abruptly when pruning exceeds a critical threshold, suggesting a minimal core of essential connections. Crucially, networks cannot recover lost performance through retraining after additional pruning - retrained models consistently underperform reference models trained from scratch at equivalent sparsity levels. This demonstrates that initial training conditions create path dependencies that determine ultimate capabilities. The findings suggest that for sparse networks to work effectively, pruning should be implemented early in training rather than attempted afterward, and that the performance of a network is highly sensitive to its initial conditions.

## Method Summary
The authors conducted experiments on RBMs trained on MNIST, systematically applying progressive pruning to both randomly initialized networks (before training) and fully trained networks (after training). They examined the impact of pruning on generation quality using multiple evaluation metrics including likelihood estimates, reconstruction error, and sample quality. The study compared pre-training pruning (lottery ticket approach) against post-training pruning and retraining scenarios. The experiments explored the relationship between sparsity levels and performance, identifying a critical threshold around 80% pruning where performance remains acceptable for pre-training pruning but degrades sharply beyond this point.

## Key Results
- RBMs can achieve high-quality generation even when up to 80% of connections are pruned before training, supporting the Lottery Ticket Hypothesis
- Performance degrades abruptly when pruning exceeds a critical threshold, suggesting a minimal core of essential connections
- Networks cannot recover lost performance through retraining after additional pruning - retrained models consistently underperform reference models trained from scratch at equivalent sparsity levels

## Why This Works (Mechanism)
The paper's findings suggest that sparse neural networks exhibit path-dependent behavior where initial training conditions fundamentally determine ultimate capabilities. The mechanism appears to involve the formation of critical subnetworks during early training that contain essential connections for maintaining performance. When pruning occurs before training, the network can adapt its learning trajectory to work within the sparse architecture, effectively finding winning tickets. However, when pruning occurs after training, the network loses connections that were crucial for its learned representation, and subsequent retraining cannot rediscover equivalent solutions. This suggests that the optimization landscape for sparse networks is highly sensitive to initialization and that certain connection patterns create privileged pathways for learning that cannot be easily reconstructed.

## Foundational Learning
- **Restricted Boltzmann Machines (RBMs)**: Energy-based generative models with visible and hidden layers - needed to understand the baseline architecture being studied; quick check: can you explain how RBMs model probability distributions?
- **Lottery Ticket Hypothesis**: The idea that dense networks contain sparse subnetworks that can be trained in isolation to match full network performance - needed to contextualize why pre-training pruning succeeds; quick check: can you describe what makes a "winning ticket"?
- **Progressive Pruning**: Sequentially removing connections from neural networks - needed to understand the experimental methodology; quick check: can you differentiate between magnitude pruning and random pruning?
- **Path Dependency in Optimization**: The phenomenon where early training decisions constrain later optimization outcomes - needed to explain why retraining fails to recover performance; quick check: can you give an example of how initialization affects training trajectories?
- **Generative Model Evaluation**: Metrics for assessing the quality of generated samples including likelihood, reconstruction error, and visual inspection - needed to interpret the performance measurements; quick check: can you list three ways to evaluate generative model quality?
- **Critical Thresholds in Neural Networks**: Points where small changes in architecture produce large changes in behavior - needed to understand the abrupt performance degradation; quick check: can you explain what a phase transition means in the context of neural network training?

## Architecture Onboarding

**Component Map:**
Input layer -> Visible units -> Hidden units -> Output layer
The RBM consists of visible units (data representation) connected to hidden units (latent representation) through weighted connections. No intra-layer connections exist within visible or hidden layers.

**Critical Path:**
The critical path for generating samples involves: (1) Initializing visible units, (2) Performing Gibbs sampling between visible and hidden layers, (3) Updating hidden unit activations based on visible input, (4) Updating visible units based on hidden activations, (5) Repeating until convergence.

**Design Tradeoffs:**
The primary tradeoff explored is between sparsity (fewer connections, lower computational cost) and generation quality. The paper demonstrates that aggressive pruning before training maintains quality better than pruning after training, suggesting that the timing of sparsity introduction is crucial. This contrasts with traditional approaches that prune after training to reduce model size.

**Failure Signatures:**
Performance degradation manifests as: (1) Reduced sample quality and diversity, (2) Increased reconstruction error on test data, (3) Lower likelihood estimates of held-out data, (4) Abrupt drops in performance when exceeding the critical pruning threshold (around 80%).

**First 3 Experiments:**
1. Apply progressive pruning to a randomly initialized RBM (0-90% sparsity) before training on MNIST, then train and evaluate generation quality
2. Train a dense RBM on MNIST, then apply progressive post-training pruning (0-90% sparsity) and evaluate whether retraining can recover performance
3. Compare generation quality across different pruning strategies at equivalent sparsity levels (pre-training vs post-training pruning vs random sparse initialization)

## Open Questions the Paper Calls Out
None

## Limitations
- The analysis focuses exclusively on RBMs applied to MNIST, limiting generalizability to other architectures, datasets, or learning paradigms
- While the results demonstrate clear path dependencies and critical pruning thresholds, the exact mechanisms underlying these phenomena remain unexplained
- The abrupt performance degradation at high pruning levels suggests a phase transition-like behavior, but the paper does not investigate whether this threshold varies with network depth, hidden layer size, or training hyperparameters

## Confidence

**High confidence:** The observation that pre-training pruning (up to 80%) maintains performance better than post-training pruning. The empirical evidence and multiple evaluation metrics strongly support this finding.

**Medium confidence:** The claim about "minimal core" of essential connections. While the abrupt degradation suggests criticality, the paper doesn't systematically identify which connections are truly essential versus merely beneficial.

**Medium confidence:** The path dependency assertion that retraining cannot recover performance. This is demonstrated empirically but could potentially be mitigated with different training schedules or optimization methods not explored in the study.

## Next Checks
1. Test whether the critical pruning threshold (approximately 80% in this study) scales predictably with network architecture complexity - does deeper or wider RBMs tolerate more aggressive pruning?
2. Investigate whether alternative training strategies (cyclical learning rates, curriculum learning, or different initialization schemes) can enable recovery of performance after severe post-training pruning.
3. Validate the Lottery Ticket Hypothesis claims by implementing iterative magnitude pruning with rewinding to identify if matching "winning tickets" can be found across different random seeds and whether they share structural similarities.