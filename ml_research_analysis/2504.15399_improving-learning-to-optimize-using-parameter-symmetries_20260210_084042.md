---
ver: rpa2
title: Improving Learning to Optimize Using Parameter Symmetries
arxiv_id: '2504.15399'
source_url: https://arxiv.org/abs/2504.15399
tags:
- learning
- neural
- teleportation
- symmetry
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes a learning-to-optimize (L2O) algorithm that
  incorporates parameter space symmetries to enhance optimization efficiency. The
  method augments L2O with learned symmetry transformations (teleportation) that move
  parameters across symmetry orbits before applying updates.
---

# Improving Learning to Optimize Using Parameter Symmetries

## Quick Facts
- **arXiv ID**: 2504.15399
- **Source URL**: https://arxiv.org/abs/2504.15399
- **Reference count**: 22
- **Primary result**: Learned symmetry-based teleportation can improve meta-optimizer performance on neural networks when combined with learned momentum, though vanilla L2O often outperforms teleportation on low-dimensional test functions.

## Executive Summary
This paper introduces a method for learning-to-optimize (L2O) that incorporates parameter space symmetries through learned teleportation transformations. The approach augments standard L2O with a module that learns to apply symmetry transformations (rotations in 2D) to parameters before applying gradient-based updates. The authors provide theoretical analysis showing that even without finding optimal symmetry transformations, the method locally resembles Newton's method for convex functions. Empirically, they demonstrate mixed results on low-dimensional test functions but show improvements on neural network training tasks when combining teleportation with learned momentum.

## Method Summary
The method builds on L2O frameworks where an LSTM meta-optimizer learns to produce optimization updates. Teleportation is added by learning a group element (rotation angle θ for 2D) that transforms parameters before applying the meta-optimizer's update. The training procedure involves R outer loops over a task distribution, with N inner optimization steps unrolled every T steps. For neural networks, a second LSTM head learns momentum coefficients β_t that combine with teleportation. The method is evaluated on two 2D test function families (generalized Booth and Rosenbrock) and neural network training tasks, comparing against vanilla L2O and Adam baselines.

## Key Results
- Vanilla L2O consistently outperforms teleportation-augmented L2O on low-dimensional test functions
- Teleportation combined with learned momentum improves meta-optimizer performance on neural network training tasks
- Theoretical analysis shows teleportation locally resembles Newton's method for convex functions, even without optimal symmetry identification
- Learned teleportation can be detrimental on certain task distributions, potentially moving iterates further from optima

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Symmetry-based teleportation accelerates optimization by maximizing gradient norm within level sets.
- Mechanism: Given an invariant function f(g(x)) = f(x), teleportation finds g* ∈ argmax_g ∥∇f(g(x))∥, moving to parameters with larger gradients before applying updates. The descent lemma then guarantees larger per-step reduction since f(x_{t+1}) ≤ f(x_t) - α/2 ∥∇f(x_t)∥².
- Core assumption: The optimizee f has exploitable symmetry structure (e.g., SO(2) rotations for the test functions) and larger gradient norm translates to faster convergence.
- Evidence anchors:
  - [abstract] "moving parameters across symmetry orbits before applying updates"
  - [section 3.1] "replacing x_t with x'_t ∈ argmax_{x: f(x)≤f(x_t)} ∥∇f(x)∥ will accelerate optimization"
  - [corpus] "Symmetry in Neural Network Parameter Spaces" discusses how symmetries create redundancy and shape optimization landscapes
- Break condition: Non-convex functions where gradient norm increase doesn't correlate with progress toward optimum (see Appendix A counterexample with indefinite matrix).

### Mechanism 2
- Claim: Teleportation locally approximates Newton's method even without finding optimal symmetry transformations.
- Mechanism: Newton's direction v₂ = -H⁻¹∇L decomposes into gradient component v∥ and orthogonal "symmetry component" v⊥. Proposition 4.1 proves that for convex L, the directional derivative of gradient norm squared along v⊥ is non-negative—meaning this component systematically increases ∥∇L∥, matching teleportation's effect.
- Core assumption: Function is twice-differentiable and convex (Lemma A.1 requires positive definite Hessian).
- Evidence anchors:
  - [abstract] "even without identifying the optimal group element, the method locally resembles Newton's method"
  - [section 4.1] "small teleportation brings the subsequent first-order updates closer to second-order updates"
  - [corpus] Weak direct evidence—neighboring papers focus on symmetry existence rather than Newton method connections
- Break condition: Non-convex objectives where Proposition 4.1 doesn't hold (authors explicitly note the lemma fails for indefinite matrices).

### Mechanism 3
- Claim: Learned momentum combined with learned teleportation improves meta-optimizer performance on neural network tasks.
- Mechanism: An LSTM-based meta-optimizer learns both the group element g_t and momentum coefficient β_t simultaneously. The velocity update v_t ← β_t v_{t-1} - α∇_t provides temporal smoothing while teleportation provides spatial repositioning, giving the optimizer two orthogonal degrees of freedom.
- Core assumption: Neural network training tasks have consistent symmetry structure that can be exploited; the combined optimization landscape for (θ, β, α) is learnable.
- Evidence anchors:
  - [abstract] "adding learned momentum to the teleportation algorithm improves meta-optimizer performance on neural network training tasks"
  - [section 5.2] Figure 7 shows LSTM(lr,tele,momentum) outperforms both GD and LSTM(lr,tele) baselines
  - [corpus] Weak direct evidence—corpus papers don't address learned optimizers with teleportation
- Break condition: Task distributions where teleportation is frequently detrimental (authors note: "If teleportation is frequently detrimental within a task distribution, the learned optimizer will perform no better than vanilla L2O").

## Foundational Learning

- Concept: **Group theory and symmetry orbits**
  - Why needed here: Understanding that parameters related by symmetry transformations (the "orbit") yield identical loss values but different gradients is essential for grasping why teleportation works.
  - Quick check question: If f(x) = x^TAx with A positive definite, what is the symmetry group of f and what does an orbit look like?

- Concept: **Newton's method and Hessian geometry**
  - Why needed here: The theoretical justification relies on decomposing Newton's direction and understanding its relationship to gradient norm increase.
  - Quick check question: Why does Newton's method use H⁻¹ and how does this relate to the curvature of level sets?

- Concept: **Meta-learning / Learning-to-Optimize (L2O)**
  - Why needed here: The method builds on L2O frameworks where an LSTM learns to produce optimizer updates; understanding the training loop (Algorithm 1) is prerequisite.
  - Quick check question: In L2O, what is being meta-learned and how does backpropagation through the unrolled optimization trajectory work?

## Architecture Onboarding

- Component map:
  - Optimizee f -> Meta-optimizer m_ϕ -> Teleportation module g_θ -> Parameter update x_t
  - Momentum module (for NN experiments) -> Velocity update v_t

- Critical path:
  1. Implement baseline L2O (Algorithm 1) with LSTM meta-optimizer
  2. Add teleportation: x_t ← g · (x_{t-1} + m_ϕ(z_t))
  3. Implement group-specific operations (for 2D: rotation matrices; for NNs: permutation/positive scaling groups)
  4. Add momentum head if targeting neural network tasks
  5. Meta-train on task distribution with gradient updates to ϕ every unroll interval

- Design tradeoffs:
  - **Low-dimensional test functions vs. neural networks**: 2D functions enable easy teleportation implementation and visualization but show mixed results (vanilla L2O often wins); neural networks show clearer benefits with momentum augmentation
  - **Teleportation frequency**: The set Z in Algorithm 3 controls when teleportation occurs—too frequent may disrupt learned dynamics
  - **Group parameterization**: Rotation angle θ is simple for 2D; NN symmetry groups (permutation, positive scaling) require more complex parameterization

- Failure signatures:
  - Vanilla L2O outperforming teleportation version on certain distributions (Figures 3-6)
  - Teleportation moving iterates further from optimum (overshooting)
  - Non-convex functions where gradient norm increase doesn't help (theoretical break condition from Appendix A)
  - Meta-optimizer learning harmful teleportation strategies when task distribution is misaligned

- First 3 experiments:
  1. **Sanity check on convex quadratics**: Implement the 2D ellipse experiment (Figure 3) with fixed h(x,y) = A[x;y] + b where A has different eigenvalues. Verify that teleportation directions align with shorter axis of level sets as claimed in Appendix B.
  2. **Ablation on teleportation frequency**: Test different values of teleportation set Z (every step, every 5 steps, every 10 steps) on both convex and non-convex task distributions to identify when teleportation helps vs. hurts.
  3. **Momentum augmentation on small neural network**: Apply Algorithm 3 to a 2-layer MLP on a simple classification task. Compare three conditions: (a) LSTM learning rate only, (b) LSTM + teleportation, (c) LSTM + teleportation + momentum. Track loss curves and analyze whether learned momentum coefficients correlate with teleportation effectiveness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does incorporating a distance-to-optimum metric into the L2O training loss effectively mitigate harmful teleportation behaviors?
- Basis in paper: [explicit] The Discussion section states, "Future work could refine the cost function, e.g., incorporating distance to the optimum to mitigate harmful teleportation."
- Why unresolved: The authors note that teleportation can move iterates further from the optimum or disrupt dynamics to cause overshooting, but they did not test alternative reward signals to correct this.
- What evidence would resolve it: Empirical results comparing standard L2O loss against a loss augmented with distance-to-optimal-weights on the provided benchmark tasks.

### Open Question 2
- Question: Does the theoretical result that teleportation resembles Newton's method hold for non-convex functions?
- Basis in paper: [inferred] Appendix A proves Proposition 4.1 using Lemma A.1 but explicitly states, "Lemma A.1 does not hold for non-convex functions," and provides a counter-example.
- Why unresolved: The theoretical justification for teleportation's efficiency currently relies on convexity assumptions which are violated in deep learning landscapes.
- What evidence would resolve it: A theoretical extension of the gradient-norm increase property to specific non-convex classes or empirical analysis showing alignment with Newton-like updates in non-convex settings.

### Open Question 3
- Question: What specific geometric or structural properties of a task distribution determine whether learned teleportation will outperform vanilla L2O?
- Basis in paper: [explicit] Section 5.1.2 states, "Vanilla L2O consistently outperforms the teleportation-augmented variant... A learned teleport strategy that improves convergence on one distribution might misalign with another."
- Why unresolved: The paper demonstrates that success varies by distribution (failing on low-dimensional test functions but helping neural networks), but does not isolate the features that predict success.
- What evidence would resolve it: An ablation study correlating the performance gap between vanilla and teleportation-augmented L2O against quantifiable properties of the loss landscape (e.g., condition number, symmetry group complexity).

## Limitations
- Theoretical analysis relies on convexity assumptions that break down for non-convex deep learning objectives
- Empirical results show mixed performance on low-dimensional test functions, with vanilla L2O often outperforming teleportation
- Neural network experiments lack detailed specifications for architecture, dataset, and training procedures
- Benchmark assumes SO(2) symmetry which may not generalize to higher-dimensional or real-world optimization problems

## Confidence

- **High confidence**: The mechanism connecting gradient norm increase to faster convergence via the descent lemma (Mechanism 1). The connection between teleportation and Newton's method for convex functions (Mechanism 2) is theoretically rigorous within its stated assumptions.
- **Medium confidence**: The learned momentum augmentation showing improved meta-optimizer performance on neural networks (Mechanism 3). The empirical results are positive but lack detailed experimental specifications for reproduction.
- **Low confidence**: Generalization of results from 2D test functions with SO(2) symmetry to complex neural network landscapes with richer symmetry structures (permutation and scaling groups).

## Next Checks

1. **Convexity break test**: Implement the indefinite matrix counterexample from Appendix A. Verify that teleportation increases gradient norm but moves the iterate away from the minimum, demonstrating the theoretical limitation.

2. **Momentum correlation analysis**: In neural network experiments, compute the correlation between learned momentum coefficients β_t and teleportation effectiveness (gradient norm increase). This would validate whether the two mechanisms work synergistically or redundantly.

3. **Symmetry group generalization**: Extend the benchmark beyond SO(2) to test functions with permutation symmetry or scaling symmetry. Compare teleportation performance across different symmetry groups to identify which structures benefit most from the approach.