---
ver: rpa2
title: 'Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to
  Model Reasoning'
arxiv_id: '2502.09022'
source_url: https://arxiv.org/abs/2502.09022
tags:
- reasoning
- eap-ig
- layers
- self-influence
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a new mechanistic interpretation framework,
  SICAF, to trace and analyze the reasoning processes that language models (LMs) employ
  during complex reasoning tasks. The approach combines circuit analysis and self-influence
  functions to identify critical model components and evaluate the changing importance
  of each token throughout the reasoning process.
---

# Mechanistic Unveiling of Transformer Circuits: Self-Influence as a Key to Model Reasoning

## Quick Facts
- arXiv ID: 2502.09022
- Source URL: https://arxiv.org/abs/2502.09022
- Reference count: 22
- Authors: Lin Zhang; Lijie Hu; Di Wang
- Primary result: New framework traces reasoning processes in language models, revealing hierarchical circuit structures

## Executive Summary
This paper introduces a novel mechanistic interpretation framework, SICAF, that combines circuit analysis with self-influence functions to trace and analyze reasoning processes in language models during complex tasks. Applied to GPT-2 on an indirect object identification task, the method successfully maps reasoning pathways and reveals a hierarchical structure in the model's reasoning process that resembles human reasoning steps. The approach demonstrates that small circuits (1-2% of edges) can faithfully recover ≥85% of model performance, with key parameters concentrated in the first and last few layers.

## Method Summary
The paper presents SICAF (Self-Influence Circuit Analysis Framework), which integrates circuit analysis and self-influence functions to identify critical model components and evaluate token importance throughout the reasoning process. The framework analyzes how each token's influence changes during model processing, enabling researchers to trace the reasoning pathways that lead to final outputs. By applying this method to GPT-2 on an indirect object identification task, the authors demonstrate how to systematically uncover the hierarchical reasoning structure within transformer models, moving beyond simple input-output correlations to reveal the internal decision-making processes.

## Key Results
- Successfully mapped reasoning pathways in GPT-2 for indirect object identification task
- Identified small circuits (1-2% of edges) that faithfully recover ≥85% of model performance
- Revealed hierarchical reasoning structure resembling human reasoning steps
- Found key parameters concentrated in first and last few layers of the model

## Why This Works (Mechanism)
The framework works by combining two complementary approaches: circuit analysis to identify critical model components and self-influence functions to track how each token's importance evolves throughout the reasoning process. This dual approach allows for both structural identification of key pathways and temporal analysis of information flow, creating a comprehensive map of the reasoning process that captures both what components matter and when they matter during inference.

## Foundational Learning
1. **Self-influence functions** - Track how each token's representation changes as it propagates through the model layers, revealing which tokens drive reasoning at each step
   - Why needed: Essential for understanding temporal dynamics of reasoning
   - Quick check: Verify self-influence scores correlate with token importance in final predictions

2. **Circuit analysis in transformers** - Identifies minimal sets of parameters that capture most of the model's reasoning capability
   - Why needed: Enables efficient interpretation by focusing on high-impact components
- Quick check: Confirm small circuits maintain high performance after ablation

3. **Hierarchical reasoning structures** - Models reasoning as layered processes where information flows from simple to complex representations
   - Why needed: Provides interpretable framework for understanding multi-step reasoning
   - Quick check: Validate hierarchical patterns across different reasoning tasks

## Architecture Onboarding

**Component Map**: Input tokens → Embedding layer → Attention heads (layers 1-24) → MLP layers → Output layer

**Critical Path**: Input embedding → First few layers (feature extraction) → Middle layers (intermediate reasoning) → Last few layers (decision making) → Output prediction

**Design Tradeoffs**: 
- Small circuit size (1-2% edges) vs. complete performance recovery (≥85%)
- Early layer parameter concentration vs. distributed processing
- Hierarchical structure vs. parallel reasoning pathways

**Failure Signatures**: 
- Performance drops when key circuit components are ablated
- Disrupted token influence patterns when self-influence functions are perturbed
- Loss of hierarchical reasoning structure in adversarial scenarios

**3 First Experiments**:
1. Apply SICAF to a simple arithmetic reasoning task to validate hierarchical structure discovery
2. Test circuit ablation on critical components to establish causal relationships
3. Compare self-influence patterns across different input types within the same task

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Generalizability of identified circuits beyond IOI task and GPT-2 architecture remains unproven
- Relationship between identified circuits and actual decision-making processes is correlative rather than definitively causal
- Framework has not been stress-tested against adversarial inputs or evaluated for detecting reasoning failures

## Confidence

**High Confidence**: Identification of small, high-performance circuits in GPT-2 for the IOI task
**Medium Confidence**: Hierarchical structure resembling human reasoning steps
**Medium Confidence**: Framework's ability to enhance transparency and interpretability

## Next Checks
1. Test the SICAF framework across multiple transformer architectures (BERT, RoBERTa, LLaMA) and reasoning tasks to evaluate generalizability
2. Conduct ablation studies on the identified circuits to establish causal relationships between circuit activation and model outputs
3. Apply the framework to adversarial examples and reasoning failures to assess its diagnostic capabilities and limitations