---
ver: rpa2
title: 'Doubling Your Data in Minutes: Ultra-fast Tabular Data Generation via LLM-Induced
  Dependency Graphs'
arxiv_id: '2507.19334'
source_url: https://arxiv.org/abs/2507.19334
tags:
- data
- feature
- dataset
- tabular
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of generating high-quality synthetic
  tabular data while balancing computational efficiency, logical consistency, and
  privacy preservation. Current methods based on large language models (LLMs) often
  suffer from dense feature dependency modeling that introduces bias and high sampling
  overhead.
---

# Doubling Your Data in Minutes: Ultra-fast Tabular Data Generation via LLM-Induced Dependency Graphs

## Quick Facts
- **arXiv ID**: 2507.19334
- **Source URL**: https://arxiv.org/abs/2507.19334
- **Reference count**: 40
- **Primary result**: Reduces constraint violations by 4% vs diffusion methods while achieving ~9,500× faster sampling than LLM baselines

## Executive Summary
This paper addresses the challenge of generating high-quality synthetic tabular data by combining LLM-based dependency extraction with lightweight generation models. The proposed SPADA framework extracts sparse dependency graphs from tabular features using LLMs, then generates data by traversing these graphs and conditioning each feature only on its parents. This approach achieves significant speedups (nearly 9,500×) over pure LLM-based methods while maintaining data quality and privacy. Experiments demonstrate SPADA's effectiveness across four datasets, showing improved constraint satisfaction and downstream utility compared to existing methods.

## Method Summary
SPADA works by first prompting an LLM to identify logical dependencies between tabular features, creating a directed graph. An ILP solver removes minimal edges to break cycles, producing a DAG. Data generation then proceeds in topological order, where each feature is synthesized conditioned only on its parent nodes using either kernel density estimation (KDE) or conditional normalizing flows (NFs). This decouples dependency modeling from generation, enabling dramatic speedups. The KDE path uses fuzzy matching and Gaussian KDE for training-free synthesis, while the NF path trains lightweight conditional models per feature. Both approaches condition only on parent nodes, avoiding the computational overhead of full LLM-based generation.

## Key Results
- Reduces constraint violations by 4% compared to diffusion-based methods
- Achieves nearly 9,500× faster sampling than LLM-based baselines (GReaT)
- Maintains strong downstream utility while preserving privacy
- KDE path has higher privacy risk (DCR ~0.1) than NF path (DCR ~0.2)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Explicit sparse dependency modeling reduces bias from fully-connected feature fusion in neural networks
- Mechanism: LLM (GPT-4o) identifies logical constraints between features, compiled into directed graph. ILP solver removes minimal edges to break cycles, producing DAG
- Core assumption: Real-world tabular entities have sparse, heterogeneous relations rather than fully-connected dependencies
- Evidence anchors: [abstract] "explicitly captures sparse dependencies via an LLM-induced graph"; [section 3.2] LLM attention creates spurious correlations; Eq. (1)-(2) define graph extraction
- Break condition: If LLM produces systematically incorrect dependencies or domain has genuinely dense interactions

### Mechanism 2
- Claim: Parent-only conditioning during topological traversal is sufficient for high-fidelity generation
- Mechanism: Features generated in topological order, each sampled from p(v_j | {v_k : f_k ∈ F̂_{f_j}}) conditioned only on direct parents
- Core assumption: Feature dependencies are non-transitive; Markov property holds
- Evidence anchors: [abstract] "conditioning each feature solely on its parent nodes"; [Appendix B, Figure 5] parent-only vs ancestor-aware conditioning shows nearly identical performance
- Break condition: If dependencies are transitive in practice, parent-only conditioning loses signal

### Mechanism 3
- Claim: Decoupling dependency modeling from data generation enables ~9,500× speedup while maintaining quality
- Mechanism: Instead of autoregressive LLM generation, uses KDE (fuzzy matching + Gaussian KDE) or lightweight conditional NF models (single linear layer + SwiGLU)
- Core assumption: Conditional distributions p(v_j | parents) are learnable/smooth enough for KDE or NF to approximate well
- Evidence anchors: [abstract] "accelerates generation by nearly 9,500×"; [Table 3] Sampling time: GReaT ~9 sec/sample vs SPADA-NF <1 ms/sample
- Break condition: If conditional distributions are highly multimodal or discontinuous, both KDE and NF may fail

## Foundational Learning

- **Directed Acyclic Graphs (DAGs) and Topological Ordering**
  - Why needed: Entire SPADA pipeline depends on understanding DAG enables sequential generation where parents precede children
  - Quick check: Given edges A→B, B→C, A→C, what is one valid topological order? If you add C→A, what happens and why must cycles be broken?

- **Kernel Density Estimation (KDE) with Bandwidth Selection**
  - Why needed: Non-parametric synthesis path uses Gaussian KDE to estimate conditional densities from fuzzy-matched subsets
  - Quick check: If h is too small, what happens to the estimated density? If h is too large? What does "asymptotic consistency" require of h as sample size grows?

- **Normalizing Flows and Change of Variables**
  - Why needed: Parametric path learns invertible transformations f_θ from base Gaussian to target conditional distribution
  - Quick check: If you have a 1D flow z → v = f_θ(z), write the log-likelihood of v in terms of the base density and the Jacobian. Why does invertibility matter?

## Architecture Onboarding

- **Component map**: LLM Dependency Extractor -> Cycle Breaker -> KDE/NF Synthesizer -> Traversal Engine
- **Critical path**:
  1. Prompt LLM with dataset description + feature list → raw dependency edges
  2. Run ILP cycle-breaking → validated DAG
  3. (KDE path) Build BallTrees; (NF path) Train conditional NFs for each feature in topological order
  4. At inference: traverse DAG, for each node retrieve KDE estimate or run NF forward pass conditioned on generated parent values

- **Design tradeoffs**:
  - KDE vs NF: KDE is training-free and fast but has higher privacy risk (DCR ~0.1) and struggles with small |T̂|. NF requires training but offers better privacy (DCR ~0.2) and smoother extrapolation
  - Sparsity enforcement: Sparse graphs reduce unwanted correlations but may miss genuine long-range dependencies
  - LLM choice: GPT-4o, Claude 3.7, Deepseek-R1, Gemini 2.0 all tested; performance varies slightly but all outperform baselines

- **Failure signatures**:
  - Empty T̂ during KDE: Fuzzy matching tolerance ϵ too strict; increase ϵ or check for out-of-distribution parent value combinations
  - High violation rates: Dependency graph may be incomplete or incorrect; manually inspect LLM outputs for missing edges
  - NF training instability: Check Lipschitz constraints on SwiGLU layers, reduce learning rate, verify conditioning inputs are normalized
  - Cycles not resolved: ILP may fail on highly connected graphs; inspect raw LLM output for mutually dependent features

- **First 3 experiments**:
  1. Validate dependency graph quality: Take small dataset (e.g., Iris with 5 features), run LLM extraction, manually verify edges against domain knowledge. Compute Jaccard similarity across multiple LLM calls
  2. Compare KDE vs NF on data scarcity: Subsample Adult Income to 500 rows. Run both synthesis paths, measure downstream classifier accuracy and violation rates
  3. Profile sampling latency: Generate 10,000 synthetic samples using both SPADA paths and baseline (e.g., GReaT or TabSyn). Confirm ~9,500× speedup claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can SPADA be extended to handle multimodal datasets containing images or open-domain text features?
- Basis in paper: [explicit] Section 7 (Limitations) states the framework is inapplicable to multimodal datasets and cannot generate open-domain text or novel tokens
- Why unresolved: Current synthesis strategies assume features are either categorical or numerical, lacking mechanism to model high-dimensional latent spaces for images or free-form text
- What evidence would resolve it: Modified SPADA implementation that successfully synthesizes tabular records containing realistic images or descriptive text fields while maintaining logical consistency

### Open Question 2
- Question: How can dependency extraction phase be scaled to high-dimensional datasets without prohibitive LLM annotation costs?
- Basis in paper: [explicit] Appendix E.2 notes prompting LLMs for large number of features incurs prohibitive costs and suggests using lightweight predictors like GNNs
- Why unresolved: Current method relies on prompting LLM with all feature names, becoming bottleneck when feature counts reach thousands
- What evidence would resolve it: Learning-based predictor (e.g., Graph Neural Network) that can infer dependency graph with accuracy comparable to GPT-4o but with significantly lower computational overhead

### Open Question 3
- Question: Can SPADA be combined with attention-based architectures to effectively model global feature interactions without losing benefits of sparse dependency modeling?
- Basis in paper: [explicit] Appendix E.2 suggests exploring hybrid architectures combining SPADA with low-rank attention layers for systems with global interactions
- Why unresolved: SPADA assumes local dependencies dominate, but real-world systems may contain complex global correlations that strictly sparse graph fails to capture
- What evidence would resolve it: Hybrid model that integrates sparse graph traversal with low-rank attention mechanisms, demonstrating improved fidelity on datasets with dense global feature correlations

## Limitations
- Heavy reliance on LLM accuracy for dependency extraction may fail in domains with complex or highly interconnected feature relationships
- KDE synthesis path has inherent privacy leakage (DCR ~0.1) due to retrieval from real data, unsuitable for sensitive applications
- Parent-only conditioning assumption may break down in datasets with transitive dependencies or when critical grandparent information is lost

## Confidence
- **High confidence** in computational efficiency gains (9,500× speedup empirically validated in Table 3)
- **Medium confidence** in bias reduction claims (supported by violation rate reduction but sparse direct evidence on bias mechanisms)
- **Medium confidence** in privacy preservation (differential privacy claims supported but practical leakage varies significantly between KDE and NF paths)
- **Low confidence** in LLM robustness across domains (no systematic evaluation of extraction quality on diverse tabular schemas)

## Next Checks
1. **Dependency Extraction Robustness**: Run SPADA on datasets with known causal structures and measure F1-score of extracted dependencies against ground truth
2. **Privacy Leakage Quantification**: Conduct membership inference attacks on KDE-synthesized data versus NF-synthesized data to validate the claimed DCR difference
3. **Long-range Dependency Impact**: Create synthetic datasets with explicit grandparent-grandchild dependencies where parent information is insufficient, then measure downstream task performance degradation