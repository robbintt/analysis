---
ver: rpa2
title: Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English
arxiv_id: '2508.19270'
source_url: https://arxiv.org/abs/2508.19270
tags:
- vietnamese
- english
- phoneme
- recognition
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of cross-lingual phoneme recognition
  between Vietnamese and English, particularly handling tonal Vietnamese and stress-based
  English phonemes in code-switching scenarios. The authors construct a bilingual
  phoneme set that maps English words to Vietnamese syllables, accommodating both
  standard and localized (Vietlish) pronunciations.
---

# Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English

## Quick Facts
- arXiv ID: 2508.19270
- Source URL: https://arxiv.org/abs/2508.19270
- Authors: Nguyen Huu Nhat Minh; Tran Nguyen Anh; Truong Dinh Dung; Vo Van Nam; Le Pham Tuyen
- Reference count: 27
- Primary result: Proposed system achieves PER scores of 16.7% (FOSD), 8.85% (Vivos), 13.02% (CmV), and 22.4% (VLSP 2020) on Vietnamese datasets, and 7.02% (IEV), 16.21% (Vietlish), and 28.55% (En native) on synthetic bilingual datasets

## Executive Summary
This paper presents a cross-lingual phoneme recognition system for Vietnamese and English, addressing the challenges of tonal Vietnamese and stress-based English phonemes in code-switching scenarios. The authors construct a bilingual phoneme set that maps English words to Vietnamese syllables, accommodating both standard and localized (Vietlish) pronunciations. Using a PhoWhisper pre-trained encoder with a Transformer decoder, the system achieves state-of-the-art performance on both real Vietnamese datasets and synthetic bilingual datasets.

## Method Summary
The authors propose an end-to-end cross-lingual phoneme recognition system that leverages a PhoWhisper pre-trained encoder combined with a Transformer decoder. They construct a bilingual phoneme set that maps English words to Vietnamese syllables, handling both standard English pronunciations and Vietlish variants. The system is trained on both real Vietnamese speech datasets and synthetic bilingual datasets created through text-to-speech generation. The architecture is designed to handle the tonal nature of Vietnamese and the stress patterns of English in code-switching contexts.

## Key Results
- Achieves PER of 16.7% on FOSD Vietnamese dataset
- Achieves PER of 8.85% on Vivos Vietnamese dataset
- Achieves PER of 7.02% on IEV synthetic bilingual dataset
- Outperforms baseline systems on all evaluated datasets

## Why This Works (Mechanism)
The system's effectiveness stems from its ability to handle both tonal and stress-based phonemes through a unified bilingual phoneme set. By mapping English words to Vietnamese syllables, the system can leverage the tonal characteristics of Vietnamese while accommodating English stress patterns. The use of a pre-trained PhoWhisper encoder provides strong acoustic feature extraction capabilities, while the Transformer decoder enables effective sequence modeling for phoneme recognition. The synthetic bilingual dataset generation helps address data scarcity in code-switching scenarios.

## Foundational Learning
1. **Tonal vs Stress Phonemes** - Why needed: Vietnamese uses tones while English uses stress patterns, requiring different acoustic modeling approaches. Quick check: Verify system can distinguish between different tone categories and stress patterns.
2. **Code-switching Phoneme Mapping** - Why needed: Code-switching requires mapping between different phonological systems. Quick check: Validate bilingual phoneme set covers all necessary phoneme transitions.
3. **Pre-trained Acoustic Models** - Why needed: Leveraging pre-trained models reduces training data requirements. Quick check: Confirm PhoWhisper encoder provides robust feature extraction.
4. **Synthetic Data Generation** - Why needed: Real code-switching data is scarce, synthetic generation helps fill gaps. Quick check: Verify synthetic data quality matches real speech characteristics.
5. **Transformer-based Sequence Modeling** - Why needed: Transformers excel at sequence-to-sequence tasks. Quick check: Confirm Transformer decoder effectively handles phoneme sequence prediction.

## Architecture Onboarding

**Component Map:**
PhoWhisper Encoder -> Transformer Decoder -> Phoneme Output

**Critical Path:**
Audio input → PhoWhisper feature extraction → Transformer attention layers → Phoneme sequence prediction

**Design Tradeoffs:**
The use of a pre-trained encoder reduces training requirements but limits architectural flexibility. The bilingual phoneme set simplifies cross-lingual mapping but may introduce ambiguity in phoneme alignment. Synthetic data generation addresses data scarcity but may not fully capture natural code-switching patterns.

**Failure Signatures:**
- Poor performance on rare code-switching patterns
- Confusion between similar tonal and stress phonemes
- Degradation when encountering non-standard Vietlish pronunciations
- Performance drop on speakers with strong accents

**3 First Experiments:**
1. Test baseline performance without pre-trained encoder
2. Evaluate performance on pure Vietnamese vs pure English speech
3. Analyze error patterns between tonal and stress phoneme recognition

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on synthetic bilingual datasets may not fully capture natural code-switching patterns
- Pre-trained PhoWhisper encoder limits reproducibility and architectural flexibility
- Potential ambiguity in English-to-Vietnamese phoneme mapping for Vietlish pronunciations
- Limited analysis of phoneme confusion patterns and error types

## Confidence

**High confidence:** PER performance on real Vietnamese datasets (FOSD, Vivos, CmV, VLSP 2020)
**Medium confidence:** Synthetic dataset results and cross-lingual generalization
**Medium confidence:** Bilingual phoneme set design and Vietlish pronunciation handling

## Next Checks
1. Test the system on additional natural code-switching speech datasets to validate synthetic data performance transfer
2. Conduct ablation studies removing the PhoWhisper encoder to assess the contribution of the pre-trained component
3. Perform detailed error analysis focusing on specific phoneme confusion patterns between tonal and stress-based phonemes