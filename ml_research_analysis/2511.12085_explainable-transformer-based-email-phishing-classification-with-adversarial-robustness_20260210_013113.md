---
ver: rpa2
title: Explainable Transformer-Based Email Phishing Classification with Adversarial
  Robustness
arxiv_id: '2511.12085'
source_url: https://arxiv.org/abs/2511.12085
tags:
- phishing
- email
- adversarial
- robustness
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces a hybrid transformer-based phishing detection
  framework combining DistilBERT with adversarial training and Explainable AI. It
  addresses vulnerabilities in phishing classifiers to both adversarial perturbations
  and character-level noise by employing FGM-based embedding-level adversarial training
  and stochastic character-level perturbations during training.
---

# Explainable Transformer-Based Email Phishing Classification with Adversarial Robustness

## Quick Facts
- arXiv ID: 2511.12085
- Source URL: https://arxiv.org/abs/2511.12085
- Authors: Sajad U P
- Reference count: 40
- Primary result: Hybrid DistilBERT framework with adversarial training and XAI achieves >98% clean accuracy and 4.9% degradation under severe noise

## Executive Summary
This study introduces a hybrid transformer-based framework for phishing email detection that addresses both adversarial robustness and interpretability. The system combines DistilBERT with embedding-level adversarial training using the Fast Gradient Method and stochastic character-level perturbations during training. This dual defense approach significantly outperforms single-method defenses, reducing accuracy degradation from 43.5% to 4.9% under severe character-level noise while maintaining clean accuracy above 98%. The framework also incorporates Explainable AI techniques (LIME, SHAP, Integrated Gradients) combined with Flan-T5-Small to generate user-friendly explanations that achieve high clarity scores in expert evaluations.

## Method Summary
The proposed framework employs a hybrid approach combining DistilBERT with two complementary defense mechanisms. First, it uses Fast Gradient Method (FGM)-based adversarial training at the embedding level to improve robustness against gradient-based attacks. Second, it incorporates stochastic character-level perturbations during training to enhance resilience against noisy inputs. For explainability, the system uses LIME, SHAP, and Integrated Gradients to generate token-level feature attributions, which are then fed into Flan-T5-Small to produce concise, user-friendly explanations. The approach is evaluated on multiple datasets including CSDMC2010, PhishTank, and cross-domain testing with Enron, demonstrating both superior performance and interpretability compared to baseline models.

## Key Results
- Hybrid approach reduces accuracy degradation from 43.5% to 4.9% under severe character-level noise
- Clean accuracy remains above 98% while adversarial accuracy reaches 96.5%
- User feedback shows high clarity and information focus of generated explanations
- Cross-domain testing confirms improved generalization compared to single-method defenses

## Why This Works (Mechanism)
The framework's effectiveness stems from addressing phishing detection vulnerabilities through complementary defenses. Adversarial training with FGM strengthens the model against gradient-based attacks by exposing it to perturbed examples during training, forcing it to learn more robust feature representations. Stochastic character-level perturbations improve resilience to real-world noise such as typos and obfuscation techniques commonly used in phishing emails. The hybrid approach creates a more comprehensive defense than either method alone, as embedding-level attacks and character-level noise represent different attack vectors that require distinct mitigation strategies.

## Foundational Learning
1. **Adversarial training (FGM)**: Needed to defend against gradient-based attacks that exploit model vulnerabilities. Quick check: Verify gradient flow and perturbation magnitude during training.
2. **Character-level noise injection**: Required to handle real-world phishing variations like typos and character substitutions. Quick check: Test model performance with controlled noise levels.
3. **Explainable AI techniques (LIME, SHAP, IG)**: Essential for providing transparency and building user trust in automated decisions. Quick check: Validate attribution consistency across different explanation methods.
4. **Flan-T5-Small for explanation generation**: Transforms complex feature attributions into accessible natural language explanations. Quick check: Evaluate explanation clarity and accuracy with domain experts.
5. **Cross-domain evaluation**: Critical for assessing generalization beyond training data distribution. Quick check: Test on datasets from different sources and time periods.
6. **Hybrid defense strategy**: Combines multiple complementary approaches for comprehensive robustness. Quick check: Compare against individual defense mechanisms.

## Architecture Onboarding

**Component Map**: Input emails -> DistilBERT encoder -> Embedding perturbation (FGM) -> Character noise injection -> Classification head -> Feature attribution (LIME/SHAP/IG) -> Explanation generation (Flan-T5-Small)

**Critical Path**: Email text → DistilBERT → Adversarial training → Classification → Explanation generation. The DistilBERT encoder serves as the core feature extractor, with both defense mechanisms operating before classification.

**Design Tradeoffs**: The hybrid approach increases computational overhead during training but provides superior robustness. Using multiple explanation methods ensures comprehensive feature attribution but adds complexity. Flan-T5-Small enables user-friendly explanations but requires additional fine-tuning.

**Failure Signatures**: Performance degradation occurs when noise levels exceed training distribution, when attacks combine embedding and character-level perturbations, or when phishing techniques significantly differ from training examples. The model may also struggle with explanations for edge cases where feature attributions are ambiguous.

**First Experiments**: 1) Compare clean vs. noisy accuracy on held-out test set, 2) Evaluate explanation consistency across LIME, SHAP, and IG methods, 3) Test cross-domain generalization on Enron dataset.

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Evaluation primarily focuses on English language and specific phishing datasets, limiting generalizability to other languages and contexts
- Adversarial robustness evaluation relies on specific attack methodologies, requiring testing against more sophisticated attack techniques
- User feedback on explainability comes from a small sample size (five experts), necessitating larger-scale user studies

## Confidence
- High confidence in hybrid approach effectiveness: Consistent quantitative improvements across multiple metrics with clear methodology
- Medium confidence in explainability utility: Expert feedback indicates high clarity but small sample size and focus on perceived understandability rather than actual decision-making
- Medium confidence in generalization claims: Cross-domain testing provides evidence but limited domain diversity and evaluation timeframe

## Next Checks
1. Conduct user studies with larger, more diverse participant pools to evaluate whether explanations actually improve real-world decision-making and trust
2. Test framework against advanced adversarial attacks using natural language processing techniques to generate contextually relevant phishing emails
3. Evaluate performance across multiple languages and phishing types (spear-phishing, smishing, vishing) to assess true cross-domain and cross-context robustness