---
ver: rpa2
title: Do Large Language Models Truly Understand Cross-cultural Differences?
arxiv_id: '2512.07075'
source_url: https://arxiv.org/abs/2512.07075
tags:
- cultural
- cross-cultural
- injection
- across
- concept
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses limitations in evaluating cross-cultural understanding
  of LLMs, including lack of contextual scenarios, insufficient cross-cultural concept
  mapping, and limited deep cultural reasoning. It proposes SAGE, a scenario-based
  benchmark built through cross-cultural core concept alignment and generative task
  design.
---

# Do Large Language Models Truly Understand Cross-cultural Differences?

## Quick Facts
- arXiv ID: 2512.07075
- Source URL: https://arxiv.org/abs/2512.07075
- Reference count: 30
- Primary result: Current LLMs achieve only 0.41 accuracy on cross-cultural reasoning tasks

## Executive Summary
This paper addresses critical limitations in evaluating cross-cultural understanding of LLMs, including lack of contextual scenarios, insufficient concept mapping, and limited deep cultural reasoning. The authors propose SAGE, a scenario-based benchmark built through cross-cultural core concept alignment and generative task design. Experiments show that current LLMs have critically deficient cross-cultural reasoning capabilities, with best zero-shot performance reaching only 0.41 accuracy. The benchmark reveals consistent performance hierarchies across cultural dimensions, with abstract domains like spirituality and metaphysics showing the largest gaps.

## Method Summary
The SAGE benchmark uses a three-layer taxonomy of cross-cultural core concepts (Symbolic, Ritual, Value) across 9 cultural dimensions, embedded in 15 real-world scenarios with 4 context types. The evaluation framework tests models under three injection levels: zero-shot (no background), weak (one-sentence definition), and strong (detailed cultural divergence explanation). The benchmark includes 4,530 items in Chinese and Spanish, with question types including multiple-choice (62.5%), true/false (20.3%), and short-answer (17.2%). Models are evaluated for accuracy across dimensions, injection sensitivity, bias diagnosis, and cross-cultural stability.

## Key Results
- Best zero-shot performance reaches only 0.41 accuracy across all models
- Abstract domains like spirituality and metaphysics show largest performance gaps
- Knowledge injection substantially improves performance, especially in abstract dimensions and Spanish-language tasks
- Cross-lingual transfer is successful to Korean but shows significant language disparities

## Why This Works (Mechanism)

### Mechanism 1: Contextual Constraint Dissolution
- **Claim:** Isolated factual queries artificially inflate performance by allowing superficial pattern matching; scenarios force reliance on deep cultural schemas
- **Mechanism:** Embedding concepts within specific interactions forces models to resolve context-dependent ambiguity rather than rely on static associations
- **Core assumption:** Cultural competence requires pragmatics and situational awareness, not just semantic knowledge
- **Evidence anchors:** "integrating real-world cultural scenarios with cross-cultural core concepts"; "evaluations fail to capture models' ability to reason within culturally situated contexts"
- **Break condition:** If models solve scenarios via simple keyword association without situational reasoning

### Mechanism 2: Scaffolded Knowledge Retrieval
- **Claim:** Models store cultural knowledge but fail to retrieve it for zero-shot reasoning; explicit concept definitions act as retrieval cues
- **Mechanism:** Providing definitions or detailed explanations primes the model's latent knowledge, separating capability gaps from retrieval gaps
- **Core assumption:** Pre-training distribution contains valid cultural signals that are inaccessible during inference
- **Evidence anchors:** "show marked improvement with concept-level knowledge injection"; "injection strength is positively associated with accuracy"
- **Break condition:** If "Strong Injection" does not significantly improve performance over "Zero Injection"

### Mechanism 3: Schema-Driven Cross-Lingual Transfer
- **Claim:** Cross-cultural transfer efficiency depends on alignment of deep cultural schemas rather than linguistic surface features
- **Mechanism:** Transfer is more successful between cultures sharing conceptual cores than between linguistically distant cultures with divergent values
- **Core assumption:** LLMs encode culture-specific heuristics that are more portable across culturally similar languages
- **Evidence anchors:** "Cultural proximity effectively mitigates linguistic divergence... shared East Asian Confucian heritage"; "experiments confirm its transferability to other languages"
- **Break condition:** If transfer fails despite high cultural similarity or succeeds despite low similarity

## Foundational Learning

- **Concept:** Cross-cultural Core Concepts (CCCs)
  - **Why needed here:** Standard benchmarks use arbitrary facts; CCCs provide structured, theoretically grounded vocabulary to systematically probe cultural depth
  - **Quick check question:** Can you distinguish between a "Symbolic" layer concept (e.g., Dragon) and a "Value" layer concept (e.g., Harmony)?

- **Concept:** Cultural Vacancy vs. Partial Correspondence
  - **Why needed here:** Models often force one-to-one mappings; understanding that concepts may lack equivalents prevents "concept imposition" errors
  - **Quick check question:** If a concept exists in Culture A but has no lexicalized equivalent in Culture B, should the evaluation force a translation?

- **Concept:** Epistemic Distance
  - **Why needed here:** Explains why models fail more on "Metaphysics" or "Spirituality" than "Social Order"; abstract domains require deeper inferential leaps
  - **Quick check question:** Why would a model perform better on "dining etiquette" (observable) than "metaphysical cosmology" (abstract)?

## Architecture Onboarding

- **Component map:**
  - CCC Taxonomy: 3 Layers (Symbolic, Ritual, Value) → 9 Categories (e.g., Metaphor, Ethics)
  - Scenario Engine: 4 Context Types (e.g., Conflict, Adaptation) → 15 Specific Scenarios
  - Generation Pipeline: Core-to-Secondary Expansion → Context Matching → Distractor Injection (6 trap types)
  - Evaluation Wrapper: Zero/Weak/Strong Injection prompts

- **Critical path:** The definition of the CCC Set (Stage I & II) is the bottleneck. If core concepts are not culturally salient or theoretically sound, downstream scenarios and questions will lack validity.

- **Design tradeoffs:**
  - **Depth vs. Automation:** Experts for CCC selection but LLMs for candidate generation/retrieval; relying too heavily on LLMs risks amplifying existing model biases
  - **Static vs. Dynamic:** CCCs treated as stable semantic units for evaluation, though the paper acknowledges they are historically dynamic

- **Failure signatures:**
  - Prototype Collapse: Model predicts "positive" for "Dragon" in all contexts, ignoring specific scenario cues
  - Injection Insensitivity: Little improvement from Zero to Strong injection indicates the model lacks internal knowledge representation
  - Language Disparity: High performance in Chinese but near-random performance in Spanish indicates overfitting to training culture

- **First 3 experiments:**
  1. **Zero-Shot Baseline:** Run target model on full 4,530 items without context to establish "operational gap" across 9 dimensions
  2. **Ablation on Distractors:** Remove "cultural trap" distractors to see if performance improves; if it does, model is susceptible to specific misunderstanding types
  3. **Sensitivity Analysis:** Compare "Weak" vs. "Strong" injection; if "Weak" provides 80% of "Strong" gain, prioritize efficient context retrieval over long prompts

## Open Questions the Paper Calls Out

- **Open Question 1:** Can SAGE be effectively utilized for instruction tuning to permanently embed cross-cultural reasoning capabilities into LLMs, thereby removing the need for explicit context injection?
  - **Basis in paper:** The Conclusion states, "Future work can leverage SAGE to guide instruction tuning and cross-lingual alignment."
  - **Why unresolved:** Current study uses SAGE primarily as a diagnostic tool rather than as a training dataset, so efficacy for fine-tuning remains untested
  - **What evidence would resolve it:** Empirical results showing performance improvements on zero-shot SAGE tasks after fine-tuning on the dataset

- **Open Question 2:** Does the minimal-intervention transfer methodology successfully extend SAGE to linguistically and culturally distant low-resource languages without introducing noise or cultural misalignment?
  - **Basis in paper:** The Methodology section claims support for extension to "low-resource languages via minimal human intervention," but experiments only validate transfer to Korean
  - **Why unresolved:** Paper demonstrates transferability to Korean (culturally proximate) but lacks evidence for languages lacking such affinity
  - **What evidence would resolve it:** Successful benchmark construction and evaluation results for diverse low-resource languages using proposed protocol

- **Open Question 3:** Can the "epistemic distance" between concrete institutional concepts and abstract value-laden domains be bridged through specific architectural modifications or data curation?
  - **Basis in paper:** Observation 2 identifies a "cultural dimension hierarchy" where models succeed at institutional reasoning but fail catastrophically at abstract reasoning
  - **Why unresolved:** Paper diagnoses this systematic limitation but offers no solution for overcoming this specific abstraction barrier
  - **What evidence would resolve it:** A model architecture or training objective demonstrating statistically significant improvements specifically in "Value Layer" domains

## Limitations

- **Limited language scope:** Experiments only validate transfer to Korean, a culturally proximate language, without testing linguistically distant low-resource languages
- **Static concept assumption:** CCCs are treated as stable semantic units despite the paper's acknowledgment that they are historically dynamic
- **Benchmark construction bias:** Reliance on expert selection for core concepts while using LLMs for candidate generation may amplify existing model biases

## Confidence

- **Cross-cultural concept framework:** High - well-grounded in cultural theory with clear three-layer taxonomy
- **Scenario-based evaluation methodology:** Medium - innovative approach but limited validation across diverse languages
- **Model performance results:** High - systematic evaluation across multiple models and dimensions shows consistent patterns
- **Knowledge injection mechanism:** Medium - demonstrated effectiveness but limited exploration of optimal injection strategies

## Next Checks

1. **Validate benchmark construction:** Verify the 4,530 items, 9 dimensions, and bilingual CN/ES balance in the released dataset
2. **Test prompt templates:** Confirm exact prompt templates for each question type and injection level are available and correctly implemented
3. **Replicate performance patterns:** Run zero-shot baseline and injection sensitivity analysis on target models to reproduce the 0.41 accuracy ceiling and injection gains reported in the paper