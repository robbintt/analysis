---
ver: rpa2
title: IoT-based Android Malware Detection Using Graph Neural Network With Adversarial
  Defense
arxiv_id: '2512.20004'
source_url: https://arxiv.org/abs/2512.20004
tags:
- graph
- malware
- android
- detector
- application
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Graph Neural Network (GNN)-based method for
  Android malware detection that uses API graph embeddings combined with permission
  and intent features. The approach achieves high accuracy (98.33% on CICMaldroid
  and 98.68% on Drebin datasets) but is vulnerable to adversarial attacks that add
  fake relationships to evade detection.
---

# IoT-based Android Malware Detection Using Graph Neural Network With Adversarial Defense

## Quick Facts
- arXiv ID: 2512.20004
- Source URL: https://arxiv.org/abs/2512.20004
- Authors: Rahul Yumlembam; Biju Issac; Seibu Mary Jacob; Longzhi Yang
- Reference count: 40
- Primary result: GNN-based Android malware detection achieves 98%+ accuracy on CICMaldroid and Drebin datasets

## Executive Summary
This paper proposes a Graph Neural Network (GNN)-based method for Android malware detection that uses API graph embeddings combined with permission and intent features. The approach achieves high accuracy (98.33% on CICMaldroid and 98.68% on Drebin datasets) but is vulnerable to adversarial attacks that add fake relationships to evade detection. To address this, the authors introduce VGAE-MalGAN, a GAN-based attack algorithm that generates adversarial malware API graphs while preserving original semantics. Experimental results show that VGAE-MalGAN can significantly reduce detection rates, but retraining the model with adversarial samples improves robustness and helps mitigate such attacks.

## Method Summary
The proposed approach uses a Graph Neural Network to detect Android malware by constructing API call graphs from APK files and combining them with permission and intent features. The GNN processes these graphs to learn malicious patterns and classify applications. To test robustness against adversarial attacks, the authors develop VGAE-MalGAN, which generates adversarial API graphs by adding fake relationships that preserve semantic meaning while evading detection. The system is evaluated on CICMaldroid and Drebin datasets, demonstrating high baseline accuracy but vulnerability to attacks that significantly reduce detection rates. Retraining with adversarial examples improves model robustness against these attacks.

## Key Results
- GNN-based detection achieves 98.33% accuracy on CICMaldroid and 98.68% on Drebin datasets
- VGAE-MalGAN adversarial attack reduces detection accuracy by 20-30% in experiments
- Retraining with adversarial samples improves robustness and mitigates attack effectiveness
- Model successfully maintains original semantics while generating adversarial examples

## Why This Works (Mechanism)
The approach works by leveraging graph neural networks to capture complex relationships between API calls in Android applications. GNNs excel at learning structural patterns in graph data, making them well-suited for analyzing API call graphs where malicious behavior often manifests through specific call sequences and dependencies. By combining these structural features with permission and intent information, the model gains a comprehensive view of application behavior. The adversarial defense mechanism works by exposing the model to attack patterns during training, helping it learn to distinguish between genuine malicious relationships and fake ones introduced by attackers.

## Foundational Learning
- Graph Neural Networks (GNNs): Deep learning models designed for graph-structured data - needed for processing API call graphs effectively; quick check: verify understanding of message passing and aggregation mechanisms
- Adversarial Machine Learning: Techniques for generating inputs that fool machine learning models - needed to test and improve model robustness; quick check: understand evasion attacks and their impact on classification
- Variational Graph Autoencoders (VGAEs): Probabilistic models for graph generation - needed for creating realistic adversarial examples; quick check: grasp how latent space representations work for graphs
- GAN-based attacks: Generative Adversarial Networks for creating adversarial samples - needed to generate sophisticated evasion attempts; quick check: understand generator-discriminator dynamics in adversarial contexts
- Static Analysis: Analyzing code without execution - needed for extracting API calls and features from APKs; quick check: know common static analysis techniques for Android apps

## Architecture Onboarding

**Component Map:**
APK Static Analysis -> API Graph Construction -> GNN Feature Extraction -> Permission/Intent Feature Extraction -> Combined Feature Vector -> Malware Classification

**Critical Path:**
Static analysis extracts API calls → API graphs built → GNN processes graphs for structural features → Permission/intent features extracted → Features combined → Classification decision made

**Design Tradeoffs:**
- GNNs vs traditional ML: Better capture of graph structure but higher computational complexity
- Static vs dynamic analysis: Faster and more scalable but may miss runtime behaviors
- Adversarial training: Improves robustness but requires additional computational resources and labeled adversarial examples

**Failure Signatures:**
- High false positives with obfuscated API calls
- Vulnerability to API call graph manipulation
- Performance degradation with novel malware families not seen during training
- Sensitivity to feature extraction quality and completeness

**First Experiments:**
1. Test baseline detection accuracy on held-out test set from same distribution
2. Evaluate VGAE-MalGAN attack success rate on trained model
3. Measure robustness improvement after retraining with adversarial examples

## Open Questions the Paper Calls Out
None

## Limitations
- Limited evaluation of dynamic/runtime behavior analysis
- Focus on a specific adversarial attack model (VGAE-MalGAN) without comparison to other attack methodologies
- Potential overfitting to the CICMaldroid and Drebin datasets
- Unclear scalability to larger, more diverse malware datasets

## Confidence
- High confidence in the baseline GNN model's detection accuracy (98%+ on benchmark datasets), as these results align with established graph-based malware detection literature
- Medium confidence in the adversarial attack effectiveness, as results depend on specific attack parameters and assumptions about attacker capabilities
- Medium confidence in the robustness improvements from adversarial training, as the long-term effectiveness against evolving attack strategies remains untested

## Next Checks
1. Test the model's robustness against multiple adversarial attack strategies beyond VGAE-MalGAN, including black-box and transfer-based attacks
2. Evaluate performance on additional real-world malware datasets with varying family distributions and temporal splits
3. Conduct runtime/dynamic analysis validation to assess detection accuracy in actual execution environments