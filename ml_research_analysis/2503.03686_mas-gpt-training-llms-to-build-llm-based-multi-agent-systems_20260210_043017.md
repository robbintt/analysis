---
ver: rpa2
title: 'MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems'
arxiv_id: '2503.03686'
source_url: https://arxiv.org/abs/2503.03686
tags:
- mas-gpt
- multi-agent
- code
- answer
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MAS-GPT is a large language model designed to generate executable
  multi-agent systems (MAS) for user queries within a single inference. The approach
  reframes MAS construction as a generative language task, representing MAS as executable
  Python code and training on a consistency-oriented dataset of query-MAS pairs.
---

# MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems

## Quick Facts
- arXiv ID: 2503.03686
- Source URL: https://arxiv.org/abs/2503.03686
- Authors: Rui Ye; Shuo Tang; Rui Ge; Yaxin Du; Zhenfei Yin; Siheng Chen; Jing Shao
- Reference count: 40
- Primary result: Single-inference LLM that generates executable multi-agent systems (MAS), achieving up to 3.89% accuracy improvement over strong baselines on 9 benchmarks

## Executive Summary
MAS-GPT reframes the construction of LLM-based multi-agent systems as a generative language task, where the model outputs executable Python code defining agent interactions. This approach significantly simplifies MAS creation by eliminating the need for manual configuration or multi-inference optimization. The method uses a consistency-oriented data construction pipeline to train on high-quality query-MAS pairs, resulting in a model that can adapt to diverse queries while maintaining efficiency.

## Method Summary
MAS-GPT fine-tunes Qwen2.5-Coder-32B-Instruct to generate executable Python code for multi-agent systems from user queries. The approach constructs a training dataset through consistency-oriented pairing: evaluating multiple MAS designs across queries, clustering similar queries, and assigning the best-performing MAS to each cluster. The model is trained to output a complete `forward` function that defines agent prompts, LLM calls, and interaction logic in a single inference step.

## Key Results
- Achieves average 3.89% accuracy improvement over strong baselines across 9 benchmarks
- Outperforms iterative baselines like DyLAN and GPTSwarm in both accuracy and efficiency
- Successfully generalizes to unseen queries and can augment reasoning capabilities of advanced models like o1-preview
- Demonstrates significant inference cost reduction compared to multi-inference approaches

## Why This Works (Mechanism)

### Mechanism 1
Representing MAS as executable Python code enables the LLM to output immediately verifiable system architectures. Agent prompts become variables, LLM calls become function calls, and interactions are string concatenations, allowing syntactic and logical validation.

### Mechanism 2
Inter-consistency clustering groups similar queries and assigns them the same high-performing MAS architecture, reducing noise in training data and teaching the model robust correlations between query types and system topologies.

### Mechanism 3
Intra-consistency refinement uses a Teacher LLM to specialize agent prompts for specific queries and generate reasoning statements, strengthening the semantic link between user queries and generated MAS structures.

## Foundational Learning

- **Concept: Supervised Fine-Tuning (SFT) on Synthetic Data**
  - Why needed: Base LLM has no inherent concept of outputting agent systems; must be taught the query-to-code format
  - Quick check: Can the model distinguish between answering the query vs. generating code to build a system that answers it?

- **Concept: Code-as-Policy / Executable Agent Definitions**
  - Why needed: The mechanism relies entirely on valid Python output with variables, imports, and function calls
  - Quick check: Does the generated code block define `math_output` before passing it to `feedback_agent`?

- **Concept: Query-MAS Alignment**
  - Why needed: Different MAS architectures suit different query types; model must learn to select appropriate topology
  - Quick check: If the query is "Write a poem," does the generated MAS create a "Debate" or "Writer-Editor" topology?

## Architecture Onboarding

- **Component map:** Query Pool + MAS Pool → Evaluation → Selection (Inter-Consistency) → Refinement (Intra-Consistency) → Training Dataset → MAS-GPT → Python Code (MAS) → Executor → Final Answer

- **Critical path:** Data Construction Pipeline (specifically the Consistency-Oriented steps) is critical, as code quality depends entirely on inter-consistency clustering and intra-consistency refinement

- **Design tradeoffs:**
  - Single-inference generation (fast, adaptable) vs. iterative optimization (slower, potentially higher peak performance)
  - Model size constraints (32B used; smaller models fail to produce valid code)

- **Failure signatures:**
  - Extraction Failure: Outputs natural language instead of code
  - Execution Failure: Generates code with undefined variables or incorrect imports
  - Reasoning Failure: Generates valid MAS but unsuited topology for the query

- **First 3 experiments:**
  1. Data Ablation: Compare random vs. inter-consistency pairing on validation set performance
  2. Generalization Test: Run on completely unseen domains (medical, legal reasoning)
  3. Inference Cost Benchmark: Compare wall-clock time and token usage against iterative baselines

## Open Questions the Paper Calls Out
None

## Limitations
- Data construction transparency issues: exact MAS implementations and clustering methodology unspecified
- Generalization boundaries untested for completely novel domains or memory-intensive tasks
- Scaling limitations noted for smaller models but performance degradation curve unclear

## Confidence
- High Confidence: Single-inference code generation for MAS construction
- Medium Confidence: Inter-consistency clustering effectiveness (8.39% MATH drop in ablation)
- Medium Confidence: Intra-consistency refinement generalization beyond training queries

## Next Checks
1. Dependency Robustness Test: Execute generated MAS in minimal Python environment to verify self-contained code
2. Cross-Domain Generalization: Test on completely unseen domains (medical diagnosis, legal reasoning)
3. Error Recovery Analysis: Systematically inject syntax errors and measure model's ability to produce corrected versions