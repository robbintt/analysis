---
ver: rpa2
title: 'SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning'
arxiv_id: '2602.01990'
source_url: https://arxiv.org/abs/2602.01990
tags:
- task
- expert
- tasks
- instruction
- tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SAME addresses catastrophic forgetting in multimodal continual
  instruction tuning by stabilizing both expert routing and expert functionality.
  It uses spectral-aware routing to decompose routing dynamics into task-relevant
  and history-preserving subspaces, updating only critical directions for new tasks
  while protecting those important for previous tasks.
---

# SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning

## Quick Facts
- arXiv ID: 2602.01990
- Source URL: https://arxiv.org/abs/2602.01990
- Authors: Zhen-Hao Xie; Jun-Tao Tang; Yu-Cheng Shi; Han-Jia Ye; De-Chuan Zhan; Da-Wei Zhou
- Reference count: 40
- Key outcome: Achieves 66.82% average accuracy on CoIN benchmark, outperforming best baseline by 2.8%

## Executive Summary
SAME addresses catastrophic forgetting in multimodal continual instruction tuning by stabilizing both expert routing and expert functionality. The method uses spectral-aware routing to decompose routing dynamics into task-relevant and history-preserving subspaces, updating only critical directions for new tasks while protecting those important for previous tasks. It applies curvature-aware Riemannian scaling to regulate expert updates using historical input covariance, preventing overwriting of previously acquired behaviors. Additionally, SAME introduces adaptive expert activation to freeze low-utility yet historically important experts during training, reducing computation and cross-task interference.

## Method Summary
SAME introduces three core stabilization mechanisms for multimodal continual instruction tuning. First, spectral-aware routing decomposes routing dynamics into task-relevant and history-preserving subspaces, updating only critical directions for new tasks while protecting previously learned task-specific patterns. Second, curvature-aware Riemannian scaling regulates expert updates using historical input covariance, preventing overwriting of previously acquired behaviors. Third, adaptive expert activation freezes low-utility yet historically important experts during training, reducing both computation and cross-task interference. The method is evaluated on the CoIN benchmark with six multimodal tasks, demonstrating state-of-the-art performance while reducing per-task training time by 32.1 minutes and GPU memory usage by 2.3K MiB/GPU.

## Key Results
- Achieves 66.82% average accuracy on CoIN benchmark, outperforming best baseline by 2.8%
- Superior long-horizon stability, particularly on challenging tasks like TextVQA (60.69%) and ImageNet (90.21%)
- Reduces per-task training time by 32.1 minutes and GPU memory usage by 2.3K MiB/GPU

## Why This Works (Mechanism)
SAME works by addressing the fundamental challenge of catastrophic forgetting in multimodal continual instruction tuning through three complementary stabilization mechanisms. Spectral-aware routing prevents forgetting by decomposing routing dynamics into subspaces, ensuring that updates for new tasks do not overwrite critical routing patterns learned for previous tasks. Curvature-aware Riemannian scaling uses historical input covariance to regulate how experts update, maintaining previously acquired expert behaviors while allowing adaptation to new tasks. Adaptive expert activation introduces a selective freezing mechanism that protects historically important experts from interference during training, reducing both computational overhead and cross-task interference. Together, these mechanisms create a stabilized MoE architecture that can learn continuously across multiple multimodal tasks without degradation in performance on previously learned tasks.

## Foundational Learning
**Catastrophic forgetting**: The tendency of neural networks to rapidly lose previously acquired knowledge when trained on new tasks. Why needed: Fundamental challenge in continual learning that SAME explicitly addresses through its stabilization mechanisms. Quick check: Monitor performance degradation on earlier tasks when training on new tasks.

**Riemannian geometry in optimization**: Mathematical framework using curved spaces to measure distances and angles, enabling more stable parameter updates. Why needed: Provides principled way to control update magnitudes and directions in SAME's curvature-aware scaling. Quick check: Verify that updates follow geodesics on the parameter manifold rather than Euclidean directions.

**Spectral decomposition**: Technique for breaking down matrices into eigenvectors and eigenvalues, revealing underlying structure in routing dynamics. Why needed: Enables SAME to separate task-relevant from history-preserving routing components. Quick check: Confirm that routing matrix decomposition yields meaningful subspaces for different tasks.

**Mixture-of-Experts (MoE)**: Neural network architecture with multiple specialized sub-networks (experts) and a gating mechanism for routing inputs. Why needed: Provides the foundation for SAME's expert-based continual learning approach. Quick check: Validate that expert specialization emerges naturally during training.

**Input covariance tracking**: Monitoring the statistical relationships between input features over time. Why needed: Essential for SAME's curvature-aware scaling to understand historical input distributions. Quick check: Track covariance matrix evolution across task sequences.

## Architecture Onboarding

**Component map**: Input -> Gating Network -> Expert Pool (32 experts) -> Spectral Routing Decomposition -> Curvature-Aware Scaling -> Adaptive Expert Activation -> Output

**Critical path**: Input → Gating Network → Spectral Decomposition → Expert Selection → Curvature Scaling → Output

**Design tradeoffs**: SAME balances stability vs. plasticity by using spectral decomposition to protect historical routing patterns while allowing selective updates for new tasks. The curvature-aware scaling introduces computational overhead but provides crucial protection against overwriting previous knowledge. Adaptive expert activation trades off potential loss of flexibility for significant gains in efficiency and reduced interference.

**Failure signatures**: Degradation in performance on earlier tasks when training on new tasks indicates insufficient stabilization. Excessive routing entropy suggests spectral decomposition is not properly separating task-relevant from history-preserving components. High variance in expert activations may indicate poor adaptive expert selection thresholds.

**First experiments**: 1) Verify spectral decomposition correctly identifies task-relevant vs. history-preserving subspaces across task transitions. 2) Test curvature-aware scaling effectiveness by comparing parameter update magnitudes with and without historical covariance regularization. 3) Evaluate adaptive expert activation by measuring computational savings and interference reduction compared to standard MoE training.

## Open Questions the Paper Calls Out
None

## Limitations
- Generalizability beyond CoIN benchmark remains uncertain, as evaluation is limited to six specific tasks
- Computational efficiency improvements measured only on specific hardware configuration, may vary across different GPU architectures
- Adaptive expert activation introduces additional hyperparameters requiring careful tuning, with limited ablation studies on parameter sensitivity

## Confidence
- High confidence: Core stabilization mechanisms (spectral-aware routing, curvature-aware scaling, adaptive activation) are technically sound with well-established mathematical foundations
- Medium confidence: Empirical results on CoIN benchmark impressive but limited to single evaluation suite, may not represent real-world deployment scenarios
- Medium confidence: Computational efficiency claims quantified but may not generalize across different hardware configurations or model scales

## Next Checks
1. Evaluate SAME on alternative multimodal continual learning benchmarks (e.g., GLAM, VQA-CP) to assess cross-benchmark generalization
2. Conduct ablation studies varying the number of experts and active experts per token to determine sensitivity to architectural hyperparameters
3. Test SAME on tasks with longer task sequences (>6 tasks) to evaluate long-horizon stability beyond CoIN benchmark scope