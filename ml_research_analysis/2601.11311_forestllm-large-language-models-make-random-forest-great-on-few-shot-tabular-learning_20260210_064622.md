---
ver: rpa2
title: 'FORESTLLM: Large Language Models Make Random Forest Great on Few-shot Tabular
  Learning'
arxiv_id: '2601.11311'
source_url: https://arxiv.org/abs/2601.11311
tags:
- data
- forestllm
- tabular
- few-shot
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FORESTLLM uses LLMs as offline model designers to guide decision
  tree construction in few-shot tabular learning. It replaces statistical splitting
  criteria with LLM-evaluated semantic prompts over labeled and unlabeled data, and
  stabilizes leaf predictions via one-time in-context inference.
---

# FORESTLLM: Large Language Models Make Random Forest Great on Few-shot Tabular Learning

## Quick Facts
- **arXiv ID:** 2601.11311
- **Source URL:** https://arxiv.org/abs/2601.11311
- **Reference count:** 40
- **Primary result:** Achieves state-of-the-art few-shot tabular learning performance with 4-48 labeled examples, outperforming strong baselines including tree ensembles, neural networks, and other LLM-based methods

## Executive Summary
FORESTLLM introduces a novel approach to few-shot tabular learning by using large language models (LLMs) as offline model designers for Random Forest construction. The method replaces traditional statistical splitting criteria with LLM-evaluated semantic prompts that incorporate both labeled and unlabeled data, and stabilizes leaf predictions through one-time in-context inference. By treating the LLM strictly as a training-time tool, FORESTLLM preserves the inference efficiency of classical decision forests while leveraging semantic priors for improved generalization under data scarcity. Across diverse classification and regression benchmarks, the approach achieves top-tier performance without requiring LLM inference at test time.

## Method Summary
FORESTLLM uses LLMs to construct Random Forests for few-shot tabular learning by replacing statistical splitting criteria with semantic evaluation. The method takes small labeled datasets (4-48 samples) and large unlabeled datasets, converting them into text prompts that include feature summaries (marginal distributions from unlabeled data) and serialized labeled examples. During training, the LLM acts as a "Causal Feature Prober" and "Evidential Split Synthesizer" to propose semantically meaningful split thresholds, and performs one-time in-context leaf label inference to set deterministic predictions. The resulting forest structure is static and executable without LLM calls at inference time, preserving efficiency while achieving state-of-the-art few-shot performance.

## Key Results
- FORESTLLM achieves state-of-the-art or second-best performance across 12 classification and 8 regression benchmarks
- Outperforms strong baselines including tree ensembles, neural networks, and other LLM-based methods with as few as 4 labeled examples
- Eliminates LLM inference at test time, maintaining classical Random Forest efficiency while improving generalization

## Why This Works (Mechanism)

### Mechanism 1: Semantic Splitting via LLM Evaluation
Traditional statistical splitting criteria become unstable with few labels. FORESTLLM constructs prompts containing feature summaries (marginal distributions of unlabeled data) and serialized labeled examples, then uses the LLM to evaluate candidate partitions based on their semantic coherence. The LLM proposes split thresholds aligned with semantic concepts rather than arbitrary numerical thresholds, implicitly applying the cluster assumption to prefer splits in low-density regions.

### Mechanism 2: One-Time Leaf Label Inference
Leaf node predictions in few-shot settings suffer from high variance due to sparse empirical estimates. FORESTLLM translates the decision path into a natural language rule and combines it with retrieved few-shot examples to prompt the LLM for a deterministic label. This decouples inference from noisy empirical estimates at training time, providing more stable predictions than simple majority voting or averaging.

### Mechanism 3: LLM as Offline Model Designer
By treating the LLM strictly as a training-time tool, FORESTLLM preserves the inference efficiency of classical decision forests. The LLM determines the tree structure and leaf values during construction, but the resulting model is a standard Random Forest executable without API calls or GPU acceleration, making it practical for deployment.

## Foundational Learning

- **Decision Tree Inductive Bias (Statistical Purity)**
  - *Why needed here:* To understand the baseline failure mode. Standard trees rely on information gain or Gini impurity, which require sufficient label statistics. With few labels, these metrics are noisy (high variance), leading to poor splits.
  - *Quick check question:* Why does Gini impurity fail when only 4 labeled examples are available at a node?

- **Semi-Supervised Learning (The Cluster Assumption)**
  - *Why needed here:* The paper leverages unlabeled data via "Feature Summaries" to guide splits. The theory relies on the cluster assumption: decision boundaries should lie in low-density regions (areas with few unlabeled examples).
  - *Quick check question:* How does knowing the distribution of unlabeled features help the LLM decide where to split the data?

- **In-Context Learning (ICL)**
  - *Why needed here:* The "Leaf Label Inference" mechanism relies on the LLM's ability to infer a label from a prompt containing a rule and examples without weight updates.
  - *Quick check question:* In the leaf inference step, does the model update its weights, or does it derive the answer solely from the prompt context?

## Architecture Onboarding

- **Component map:** Labeled Data + Unlabeled Data -> Semantic Data Distillation -> LLM Controller -> Forest Constructor -> Inference Engine (standard Random Forest)
- **Critical path:** The Prompt Construction (Semantic Data Distillation) is the most critical step. If the statistical summaries of the unlabeled data or the serialization of labeled examples are ambiguous, the LLM will generate suboptimal splits.
- **Design tradeoffs:**
  - *Training Latency vs. Inference Speed:* High API latency during training to build the tree, but millisecond-level inference speed later
  - *Interpretability vs. Stochasticity:* Trees are highly interpretable (natural language rules), but LLM output is stochastic (mitigated by temperature 0 for splits/inference)
- **Failure signatures:**
  - Hallucinated Thresholds: LLM might suggest impossible split thresholds if feature summaries are misinterpreted
  - Semantic Drift: Long decision paths may lead to incoherent leaf predictions
  - Invalid Splits: LLM may propose features or thresholds not present in the data
- **First 3 experiments:**
  1. Cold Start Baseline: Compare FORESTLLM against standard Random Forest on small datasets (e.g., Blood or Credit-g) with exactly 4 labeled samples
  2. Ablation on Unlabeled Data: Run FORESTLLM with unlabeled data removed to measure feature summary contribution
  3. Leaf Inference Validation: Manually inspect decision path rules and predictions for interpretability

## Open Questions the Paper Calls Out

### Open Question 1
Can the framework remain computationally tractable for high-dimensional datasets or deep tree structures? The per-node LLM queries are a significant bottleneck, especially with expensive proprietary model APIs.

### Open Question 2
Can smaller, open-source models replace GPT-4o without significant performance degradation? Current reliance on frontier-level reasoning capabilities limits accessibility and reproducibility.

### Open Question 3
To what extent does "causal feature probing" actually recover causal mechanisms versus simple correlations? LLMs may hallucinate causal links or rely on spurious correlations present in their training data.

## Limitations
- Computational costs scale poorly with tree depth and forest size due to per-node LLM calls
- Feature summary formatting and prompt templates are underspecified, though code is available
- The semantic splitting mechanism may hallucinate invalid thresholds if feature summaries are misinterpreted

## Confidence
- **High confidence:** FORESTLLM achieves state-of-the-art few-shot performance and eliminates inference-time LLM calls
- **Medium confidence:** The semantic splitting mechanism meaningfully improves generalization over statistical baselines
- **Low confidence:** The exact contribution of unlabeled data feature summaries vs. labeled examples to split quality

## Next Checks
1. Replicate the 4-shot ablation experiment (with/without unlabeled data) to verify the cluster assumption benefit
2. Manually inspect generated decision path rules and predictions for interpretability and semantic coherence
3. Measure training latency and API costs for different forest sizes to validate the efficiency tradeoff