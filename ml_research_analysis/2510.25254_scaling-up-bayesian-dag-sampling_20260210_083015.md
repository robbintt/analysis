---
ver: rpa2
title: Scaling Up Bayesian DAG Sampling
arxiv_id: '2510.25254'
source_url: https://arxiv.org/abs/2510.25254
tags:
- bayesian
- networks
- posterior
- node
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces algorithmic techniques to improve Bayesian
  structure MCMC sampling of directed acyclic graphs (DAGs). The first technique,
  called Gibby, is a new implementation of basic single-arc moves that speeds up computation
  by 1-3 orders of magnitude through efficient proposal generation and higher acceptance
  rates.
---

# Scaling Up Bayesian DAG Sampling

## Quick Facts
- arXiv ID: 2510.25254
- Source URL: https://arxiv.org/abs/2510.25254
- Reference count: 40
- One-line primary result: New MCMC techniques for Bayesian DAG sampling achieve 1-3 orders of magnitude speed improvements through efficient move proposals and parent set pruning

## Executive Summary
This paper introduces algorithmic techniques to dramatically improve Bayesian structure MCMC sampling of directed acyclic graphs (DAGs). The authors present Gibby, a new implementation of single-arc moves that speeds up computation by 1-3 orders of magnitude through efficient proposal generation and higher acceptance rates. They also introduce a pruning method that discards irrelevant parent sets during parent set resampling moves, reducing computation time and memory requirements by 1-3 orders of magnitude. Integrating these techniques into an enhanced Gibby implementation, the authors demonstrate significant computational gains compared to previous methods on benchmark Bayesian networks, enabling sampling from larger networks than previously feasible.

## Method Summary
The Gibby sampler uses an efficient MCMC scheme with tentative acceptance probabilities for basic moves (add/delete/reverse) to skip rejected proposals, and ε-pruning for parent set resampling (REV/MBR moves). The approach employs a sparse structure prior P(G) ∝ n⁻|A| and BDeu score with Equivalent Sample Size (ESS) = 1.0. The pruning method uses an accuracy parameter ε = 2⁻¹⁵ and limits candidate parents to 64. The implementation requires GCC compilation with -march=native -O3 flags and uses different move ratios depending on network size (100 basic moves for small networks, 50 for large networks).

## Key Results
- Computational speed improvements of 1-3 orders of magnitude over previous methods
- Ability to reliably approximate DAG posterior with substantial efficiency gains
- Enables sampling from larger Bayesian networks than previously feasible
- Demonstrates superior performance in both mixing and accuracy compared to existing samplers

## Why This Works (Mechanism)
The efficiency gains come from two key innovations: First, the tentative acceptance mechanism skips computing scores for rejected proposals by only evaluating acyclic proposals, reducing unnecessary computations. Second, the ε-pruning method eliminates parent sets whose scores are unlikely to contribute to the posterior, dramatically reducing the search space while maintaining accuracy within the specified tolerance.

## Foundational Learning
- **Bayesian Dirichlet (BD) score**: The scoring function used to evaluate DAGs, necessary for understanding how network structures are evaluated
  - *Why needed*: Forms the basis for comparing different DAG structures
  - *Quick check*: Verify understanding by computing BD score for simple DAG structures
- **Markov Chain Monte Carlo (MCMC)**: The sampling framework used to explore the space of DAGs
  - *Why needed*: Provides the probabilistic foundation for structure learning
  - *Quick check*: Confirm MCMC convergence by examining trace plots
- **Parent set pruning**: The technique of eliminating unlikely parent combinations
  - *Why needed*: Dramatically reduces computational complexity
  - *Quick check*: Measure memory usage with and without pruning on medium-sized networks
- **Acyclicity checking**: Verification that proposed graph modifications maintain DAG structure
  - *Why needed*: Ensures valid Bayesian network structures
  - *Quick check*: Test acyclicity detection on graphs with known cycles

## Architecture Onboarding
**Component map:** Data generation -> Gibby sampler -> MCMC chain -> Posterior estimation
**Critical path:** Proposal generation → Acyclicity check → Score computation → Acceptance decision → Chain update
**Design tradeoffs:** Speed vs. accuracy (ε parameter), memory vs. completeness (pruning depth), basic moves vs. parent set resampling
**Failure signatures:** High memory usage indicates insufficient pruning, poor mixing suggests incorrect move acceptance logic, slow execution points to inefficient acyclicity checking
**3 first experiments:**
1. Run Gibby on small benchmark network (ALARM) with default parameters to verify basic functionality
2. Test pruning efficiency by comparing execution time with ε = 2⁻¹⁵ vs. no pruning on medium network
3. Verify move acceptance logic by checking acceptance rate distribution across different move types

## Open Questions the Paper Calls Out
- Can the efficiency gains from the proposed basic move simulation and score pruning be effectively translated to continuous or mixed-variable Bayesian networks?
- Can the new pruning and move acceleration techniques be successfully integrated into the partition MCMC framework to resolve its specific mixing issues?
- What specific structural or statistical properties of a dataset determine the efficiency of the ε-pruning method?

## Limitations
- Focuses exclusively on discrete Bayesian networks under BDeu scoring
- Pruning accuracy (ε = 2⁻¹⁵) may not generalize to all scoring functions
- Theoretical guarantees for MCMC convergence under Gibby's proposal distribution require further validation

## Confidence
- **High confidence** in empirical speed improvements (1-3 orders of magnitude)
- **Medium confidence** in theoretical correctness of pruning method
- **Low confidence** in general applicability to non-BDeu scoring functions

## Next Checks
1. Test Gibby's performance on continuous Bayesian networks using BGe scoring
2. Validate convergence properties of pruning method across different prior specifications
3. Benchmark Gibby against exact inference methods on smaller networks to quantify approximation error