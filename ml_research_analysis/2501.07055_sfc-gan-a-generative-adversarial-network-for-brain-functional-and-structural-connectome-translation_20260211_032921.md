---
ver: rpa2
title: 'SFC-GAN: A Generative Adversarial Network for Brain Functional and Structural
  Connectome Translation'
arxiv_id: '2501.07055'
source_url: https://arxiv.org/abs/2501.07055
tags:
- brain
- translated
- connectivity
- functional
- connectomes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces SFC-GAN, a bidirectional generative adversarial
  network framework for translating between structural connectivity (SC) and functional
  connectivity (FC) in brain connectomes. The model extends CycleGAN with convolutional
  layers and incorporates a structure-preserving loss to maintain topological integrity
  and symmetry of connectomes.
---

# SFC-GAN: A Generative Adversarial Network for Brain Functional and Structural Connectome Translation

## Quick Facts
- arXiv ID: 2501.07055
- Source URL: https://arxiv.org/abs/2501.07055
- Reference count: 29
- Key outcome: Introduces SFC-GAN, a bidirectional CycleGAN framework that translates between structural and functional brain connectomes with structure-preserving losses, achieving superior MSE/MAE and cosine similarity metrics compared to baselines

## Executive Summary
This paper presents SFC-GAN, a bidirectional generative adversarial network framework for translating between structural connectivity (SC) and functional connectivity (FC) in brain connectomes. The model extends CycleGAN with convolutional layers and incorporates a structure-preserving loss to maintain topological integrity and symmetry of connectomes. SFC-GAN enables both direct and inverse mapping between SC and FC, addressing the challenge of analyzing brain connectivity when only one modality is available. Experimental results on ADNI and DUMC-MDD datasets demonstrate superior performance compared to baseline models, with lower MSE and MAE values and higher cosine similarity.

## Method Summary
SFC-GAN implements a CycleGAN architecture with two generators (FC→SC and SC→FC) and two discriminators. The model uses 116×116 connectome matrices from ADNI and DUMC-MDD datasets, with FC derived from fMRI correlations and SC from dMRI fiber counts using AAL atlas. Training employs Adam optimizer (lr=0.0001) for 200 epochs with losses combining adversarial, cycle consistency, identity, and structure-preserving components. The structure-preserving loss includes both global and local Pearson correlation terms alongside MSE. A key architectural feature is a Lambda layer that enforces matrix symmetry to maintain biological validity of undirected brain graphs.

## Key Results
- SFC-GAN achieves lower MSE (1.16) and MAE (0.66) values compared to baseline models for FC translation in ADNI dataset
- Generated connectomes preserve graph properties with APD scores: density (1.24), CPL (0.21), efficiency (0.14), and modularity (0.11)
- Translated connectomes maintain classification performance with SVM accuracy ranging from 73.33% to 93.33% across different experimental conditions

## Why This Works (Mechanism)

### Mechanism 1: Cycle-Consistent Domain Adaptation
The framework enables bidirectional translation between unpaired structural and functional connectomes without requiring one-to-one mapping in the training set. By adapting CycleGAN, the model enforces a cycle consistency loss that regularizes the mapping, preventing generators from producing arbitrary connectomes that deviate from the specific input's topology.

### Mechanism 2: Multi-Scale Structure-Preserving Regularization
Standard pixel-wise losses fail to capture the global topological organization of brain networks. The proposed structure-preserving loss combines MSE with Pearson Correlation Coefficient computed globally and locally, forcing the generator to maintain relative connection strengths even if absolute values shift, preserving community structure.

### Mechanism 3: Enforced Symmetry via Architectural Constraint
Brain connectomes are symmetric matrices representing undirected graphs. The generator architecture explicitly enforces symmetry through a Lambda layer that averages the matrix with its transpose, ensuring biologically valid outputs.

## Foundational Learning

- **Concept: Cycle Consistency (CycleGAN)**
  - Why needed here: Enables learning FC↔SC mappings without paired data
  - Quick check question: If cycle loss were removed, what prevents the generator from mapping all SC inputs to a single "average" FC?

- **Concept: Graph Topology in Connectomes**
  - Why needed here: Evaluation goes beyond MSE to graph properties like modularity
  - Quick check question: Why would two matrices with identical MSE have vastly different "global efficiency"?

- **Concept: Pearson Correlation Coefficient (PCC)**
  - Why needed here: Splits PCC into global and local components for structure preservation
  - Quick check question: Why is PCC often better for "pattern similarity" in FC than MSE?

## Architecture Onboarding

- **Component map:** Input matrices → Generator (Encoder-Decoder CNN with symmetric Lambda layer) → Output matrices → Discriminator (PatchGAN) → Loss aggregator
- **Critical path:** Feed FC to G_SC → Get SC_hat → Feed SC_hat to D_SC (Adversarial) AND G_FC (Cycle) → Calculate L_SP between FC and SC_hat → Backpropagate combined objective
- **Design tradeoffs:** Uses Conv2D on matrices treating brain as image vs. GNNs; Lambda symmetry guarantees biological validity but removes ability to learn asymmetric noise
- **Failure signatures:** Mode collapse (same output for all inputs), checkerboard artifacts from Conv2DTranspose, asymmetric outputs if Lambda layer fails
- **First 3 experiments:** 1) Identity check: verify generated matrices look like FC/FC domain, 2) Ablate L_SP: compare modularity/Efficiency with and without structure-preserving loss, 3) Symmetry test: compute ||M_gen - M_gen^T||_F to verify architectural constraint

## Open Questions the Paper Calls Out

- **Open Question 1:** What architectural refinements are needed to improve classification performance when translating FC in ADNI and SC in DUMC-MDD datasets, where translated connectomes showed inferior SVM classification performance?
- **Open Question 2:** Does strict symmetry enforcement suppress biologically relevant lateralized asymmetries inherent in ground-truth connectomes?
- **Open Question 3:** Can SFC-GAN generalize to multi-site datasets or different brain parcellation atlases without requiring retraining?

## Limitations
- Performance degradation in cross-dataset classification tasks suggests limited generalization to disease-specific biomarker preservation
- Strict symmetry enforcement may discard meaningful asymmetric features found in raw connectomes
- Framework tested only on 116-region AAL parcellation, leaving robustness to other atlases unexplored

## Confidence
- **High confidence:** Core CycleGAN architecture, symmetry enforcement mechanism, experimental design
- **Medium confidence:** Structure-preserving loss effectiveness and graph property preservation claims
- **Low confidence:** Generalization to other brain atlases or parcellation schemes beyond AAL 116-node resolution

## Next Checks
1. Systematically vary L_GAN:L_cyc:L_id:L_SP ratios to quantify sensitivity to loss weighting
2. Measure matrix asymmetry error on test set and compare against baseline models without symmetry enforcement
3. Evaluate performance when translating connectomes built from different atlases (e.g., Power 264 vs AAL 116) to test cross-parcellation robustness