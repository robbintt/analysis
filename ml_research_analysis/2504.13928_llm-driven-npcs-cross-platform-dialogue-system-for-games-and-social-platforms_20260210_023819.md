---
ver: rpa2
title: 'LLM-Driven NPCs: Cross-Platform Dialogue System for Games and Social Platforms'
arxiv_id: '2504.13928'
source_url: https://arxiv.org/abs/2504.13928
tags:
- game
- system
- discord
- player
- dialogue
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the limitation of NPCs confined to single platforms
  by developing a cross-platform dialogue system connecting a Unity-based game and
  Discord through a cloud database. The system enables a single LLM-powered NPC to
  maintain coherent, memory-consistent conversations with players across platforms,
  adapting responses based on context and player location.
---

# LLM-Driven NPCs: Cross-Platform Dialogue System for Games and Social Platforms

## Quick Facts
- arXiv ID: 2504.13928
- Source URL: https://arxiv.org/abs/2504.13928
- Authors: Li Song
- Reference count: 10
- Primary result: A single LLM-powered NPC maintains coherent, memory-consistent conversations across Unity game and Discord platforms using a cloud database for synchronization.

## Executive Summary
This paper presents a cross-platform dialogue system that enables a single non-player character (NPC) to maintain coherent conversations across both a Unity-based game and Discord. The system uses a cloud database to synchronize dialogue history and player interactions, allowing the NPC to adapt responses based on context and platform-specific affordances. The NPC maintains a favorability score that changes only during in-game interactions, creating a distinction between "face-to-face" and "online" relationship progression.

## Method Summary
The system connects a Unity game client and a Discord bot through a shared cloud database (LeanCloud), enabling a single LLM-powered NPC to maintain cross-platform conversations. Player messages from either platform are stored with metadata including character, user ID, content, favorability score, platform, and timestamp. Before generating responses, the system retrieves the most recent six dialogue rounds for that user and includes them in the LLM prompt along with NPC rules and background story. The DeepSeek-R1 model generates responses that are then returned to the originating platform. Favorability updates only during in-game interactions, creating an asymmetric relationship progression between platforms.

## Key Results
- Successful cross-platform memory retention demonstrated through dialogue consistency tests
- Platform-specific response adaptation shown in experimental results (Table 2)
- NPC correctly recalls player details and guides interactions appropriately between game and Discord environments
- Six-round context window effectively maintains coherence for short to medium-length conversations

## Why This Works (Mechanism)

### Mechanism 1: Centralized Memory Synchronization
A shared cloud database enables a single NPC persona to maintain conversational continuity across disjoint platforms. Every player message is written to LeanCloud with fields (character, user ID, content, favorability, platform, timestamp). Before generating a response, the system retrieves the most recent six rounds of dialogue history for that user, regardless of source platform, and includes it in the LLM prompt. Core assumption: The LLM can infer coherent continuity from a flat, chronologically-ordered dialogue log without explicit state modeling.

### Mechanism 2: Platform-Aware Context Injection
Encoding the source platform in each message enables the LLM to adapt responses to platform affordances. The "platform" field is stored per message and included in the prompt context. The LLM receives implicit guidance about what actions are appropriate per platform—for example, visual interactions are in-game only. Core assumption: The LLM has sufficient world knowledge to infer platform constraints from minimal cues without explicit rule enumeration.

### Mechanism 3: Asymmetric State Mutation by Channel
Restricting favorability changes to in-game interactions creates a meaningful distinction between "face-to-face" and "online" relationship progression. The system only increments favorability when messages originate from the game client. Discord interactions are read-only with respect to this metric. This is a design choice, not an LLM inference. Core assumption: Players will perceive "in-person" vs. "remote" interaction as having different relational weight, increasing perceived realism.

## Foundational Learning

- Concept: LLM context windows and prompt engineering
  - Why needed here: The entire system relies on stuffing dialogue history into prompts; understanding token limits and context dilution is essential for scaling beyond six rounds.
  - Quick check question: Given a 4096-token context window and ~50 tokens per dialogue round, how many rounds can you safely include before risking truncation of system instructions?

- Concept: Event-sourced data models
  - Why needed here: Dialogue logs are stored as immutable events with timestamps; reconstructing state requires replay or aggregation logic.
  - Quick check question: If you needed to compute total favorability for a user with 500 stored messages, would you query each message or maintain a derived aggregate? What are the consistency tradeoffs?

- Concept: Discord bot fundamentals (gateway, rate limits, intents)
  - Why needed here: The Discord integration must handle async messaging, rate limiting, and proper intent declarations to function reliably in production.
  - Quick check question: What happens to your NPC's responsiveness if Discord's message rate limit is exceeded during a high-traffic event?

## Architecture Onboarding

- Component map: Unity client -> LeanCloud SDK -> writes messages, reads NPC responses; Discord bot (Python) -> LeanCloud SDK -> writes messages, reads NPC responses; LeanCloud (cloud database) -> stores all dialogue events; LLM (DeepSeek-R1) -> receives prompt bundle, returns generated response; Orchestration layer (implied) -> retrieves history, constructs prompt, handles API calls

- Critical path: 1. Message received -> 2. Persist to LeanCloud -> 3. Query last 6 rounds by user ID -> 4. Construct prompt (rules + history + current message) -> 5. Call LLM -> 6. Persist response -> 7. Return to originating platform. Any failure at steps 2 or 4 breaks cross-platform memory.

- Design tradeoffs: Six-round history cap reduces token cost but sacrifices long-term memory; single shared database simplifies sync but creates a central point of failure; static personality prompt ensures consistency but prevents dynamic character evolution.

- Failure signatures: Memory drift: NPC forgets key facts after >6 rounds; solution path is RAG/vector storage; Platform confusion: NPC suggests in-game-only actions on Discord; check prompt rule coverage; Stale favorability: Haogandu doesn't update on Discord by design—confirm this is intentional, not a bug.

- First 3 experiments: 1. Extend the dialogue consistency test beyond 20 rounds to quantify memory degradation; log which facts are lost and when. 2. Add explicit platform-affordance rules to the prompt and measure reduction in platform-confused responses. 3. Prototype a vector database for long-term memory; compare retrieval-augmented responses against the current six-round baseline for fact retention.

## Open Questions the Paper Calls Out

### Open Question 1
Can retrieval-augmented generation (RAG) or vector databases effectively resolve the issue of memory dilution in long-term cross-platform interactions without excessive token consumption? Basis in paper: The Discussion section states that NPC memory may fade after approximately twenty rounds of dialogue and suggests that introducing a vector database or RAG could reduce token usage while supporting persistent memory. Why unresolved: The current prototype limits context retrieval to the most recent six rounds of dialogue to manage prompt size, lacking a mechanism for long-term semantic recall. What evidence would resolve it: An implementation study demonstrating successful recall of specific user details from sessions exceeding 50+ interactions, compared against token latency metrics.

### Open Question 2
How can an NPC's personality evolve dynamically over time beyond the constraints of a static prompt definition? Basis in paper: The Conclusion identifies the limitation that the NPC's personality is defined solely by a static prompt and lacks dynamic development. Why unresolved: The current system relies on a fixed background story and a basic "favorability" metric, which alters tone but does not fundamentally change character traits or growth. What evidence would resolve it: A longitudinal user study showing measurable, emergent changes in NPC character traits (e.g., becoming more cautious or adventurous) based on cumulative player experiences.

### Open Question 3
How can cross-platform NPC functionality be expanded to directly influence in-game states and mechanics? Basis in paper: The Conclusion notes that the current system is restricted to dialogue and memory synchronization, suggesting future work should focus on functionality that affects in-game states. Why unresolved: The current implementation treats the Unity game and Discord as separate input/output interfaces for text, without integrating game logic (e.g., inventory, quest progress) into the LLM's action space. What evidence would resolve it: A prototype where specific dialogue events triggered on Discord successfully unlock items, alter environments, or modify stats within the Unity game client.

## Limitations
- Six-round context window creates memory degradation for conversations exceeding 20 rounds
- Platform-aware adaptation relies on LLM's implicit understanding rather than explicit rule enforcement
- Lack of user perception data on asymmetric favorability design and platform-specific limitations
- Single shared database creates central point of failure without redundancy

## Confidence

**High Confidence**: Cross-platform memory synchronization works as described, with successful platform-specific response adaptation demonstrated in experimental results. The centralized database architecture effectively maintains conversational continuity when properly implemented.

**Medium Confidence**: Platform-aware context injection operates reliably within the tested parameters, but effectiveness depends heavily on prompt quality and LLM capabilities that aren't fully characterized. Asymmetric state mutation design is logically sound but lacks empirical validation of player perception and engagement impact.

**Low Confidence**: Long-term memory retention beyond six rounds remains unvalidated. The system's behavior under high concurrency or Discord rate limiting hasn't been tested. The impact of favorability-only-in-game design on player satisfaction is unknown.

## Next Checks

1. **Memory Degradation Analysis**: Extend dialogue tests to 20+ rounds and systematically log which facts are forgotten and when, creating a degradation timeline to quantify the six-round limit's impact.

2. **Platform Rule Specification Test**: Implement explicit platform-affordance rules in the prompt (e.g., "On Discord, you cannot show visual appearance") and measure the reduction in platform-confused responses compared to the current implicit approach.

3. **RAG Implementation Comparison**: Prototype a vector database for long-term memory and compare retrieval-augmented responses against the current six-round baseline for fact retention accuracy and response quality.