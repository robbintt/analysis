---
ver: rpa2
title: 'Explainable Preference Learning: a Decision Tree-based Surrogate Model for
  Preferential Bayesian Optimization'
arxiv_id: '2512.14263'
source_url: https://arxiv.org/abs/2512.14263
tags:
- optimization
- data
- function
- functions
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a decision-tree-based surrogate model for
  Preferential Bayesian Optimization (PBO) to address interpretability and scalability
  issues with Gaussian Process (GP) models. The proposed method uses a novel splitting
  heuristic called Consistency Score to partition the space into leaves and fits Gaussian
  distributions to each leaf to estimate utility values.
---

# Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization

## Quick Facts
- arXiv ID: 2512.14263
- Source URL: https://arxiv.org/abs/2512.14263
- Authors: Nick Leenders; Thomas Quadt; Boris Cule; Roy Lindelauf; Herman Monsuur; Joost van Oijen; Mark Voskuijl
- Reference count: 40
- Key outcome: Decision Tree surrogate outperforms GP models on spiky benchmark functions while maintaining competitive performance on smooth ones, with ~30s runtime vs 2900s for GPs

## Executive Summary
This paper introduces a decision tree-based surrogate model for Preferential Bayesian Optimization to address interpretability and scalability limitations of Gaussian Process models. The method uses a novel Consistency Score splitting heuristic that maximizes separation of winners and losers across thresholds while discarding comparison pairs that straddle splits. Extensive experiments on eight benchmark functions demonstrate superior performance on spiky functions and significantly better scalability. A case study on the Sushi dataset showcases the model's interpretability and ability to handle mixed categorical and continuous data.

## Method Summary
The method replaces traditional GP surrogates with a decision tree structure that partitions the feature space using a Consistency Score heuristic. This heuristic maximizes the separation of "winners" and "losers" across potential splits while discarding pairs that straddle the threshold. Each leaf then fits a Gaussian distribution via Laplace Approximation to estimate utility values, with a sum-to-zero constraint applied to resolve translational invariance. The model is trained on pairwise comparison data and optimized using qEUBO acquisition, with experiments showing runtime improvements from thousands of seconds to approximately 30 seconds while maintaining or improving regret performance.

## Key Results
- Outperforms GP-based alternatives on spiky functions (Holder, De Jong N.5) while remaining competitive on smooth functions (Branin, Rosenbrock)
- Achieves runtime of ~30 seconds versus ~1000-2900 seconds for GP models
- Demonstrates interpretability on Sushi dataset, revealing patterns like "cheaper sushi is generally less liked"
- Handles both categorical and continuous data effectively

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Partitioning the feature space using a "Consistency Score" enables the surrogate model to capture sharp discontinuities (spikes) and categorical shifts that smooth kernels cannot.
- **Mechanism:** Unlike standard regression trees that minimize variance, this method uses a splitting heuristic that maximizes the separation of "winners" and "losers" across a threshold (|n_right - n_left|). Critically, it discards comparison pairs that straddle a split (where winner and loser fall on different sides), ensuring that each leaf contains internally consistent preference data.
- **Core assumption:** Discarding straddling pairs removes noise rather than essential cross-dimensional information. The paper notes this poses a problem for high-dimensional functions (d > 10).
- **Evidence anchors:** [abstract] "outperforms GP-based alternatives on spiky functions"; [section 3.1] "This method is different... our method trains directly on preference pairs... discarding pairs that straddle the split."; [corpus] Neighbors like "BARK" also explore tree-based kernels for non-smooth landscapes, supporting the move away from strictly smooth GPs.

- **Break condition:** Performance degrades in high-dimensional spaces (d>10) where the "straddler discarding" logic starves child nodes of training data.

### Mechanism 2
- **Claim:** Fitting Gaussian distributions to tree leaves via Laplace Approximation allows a non-parametric tree to function as a probabilistic surrogate for Bayesian optimization.
- **Mechanism:** The tree structure partitions the space, but the utility values are latent. The model treats the mean utility of each leaf as a parameter to be learned. It places a Gaussian prior on these means and uses a pairwise likelihood function (p(D|f)) to find the Maximum a Posteriori (MAP) estimate and posterior variance via the Hessian.
- **Core assumption:** The Laplace Approximation (fitting a Gaussian to the posterior mode) is sufficiently accurate for the acquisition function, even if the true posterior is skewed.
- **Evidence anchors:** [abstract] "fits Gaussian distributions to each leaf to estimate utility values"; [section 3.2] "We approximate the posterior with a Gaussian centered at the MAP estimate... via LA."

- **Break condition:** If the number of comparisons per leaf is too low, the Hessian becomes ill-conditioned, causing numerical instability or misleading uncertainty estimates.

### Mechanism 3
- **Claim:** Imposing a sum-to-zero constraint on leaf values resolves the "translational invariance" of pairwise comparisons, preventing variance explosion.
- **Mechanism:** Pairwise preferences (A > B) provide no information about the absolute scale of utility (f(A), f(B)), only the difference. Without a constraint, the uncertainty (variance) grows indefinitely. By conditioning the posterior on Σf = 0, the model anchors the scale, making the uncertainty estimates actionable for acquisition functions like qEUBO.
- **Core assumption:** The relative utility scale is consistent across the tree.
- **Evidence anchors:** [section 3.2] "This invariance causes two problems... To remedy these issues, the model is made identifiable by adding a sum-to-zero constraint."; [appendix A] Detailed mathematical derivation of the conditional distribution.

- **Break condition:** If a specific region of the search space has no data, the sum-to-zero constraint may artificially distort local utility estimates to satisfy the global average.

## Foundational Learning

- **Concept:** Preferential Bayesian Optimization (PBO)
  - **Why needed here:** This is the core loop. You must understand that we never observe the objective function f(x) (e.g., "how good is this sushi?"), only comparisons (f(A) > f(B)). The model must reconstruct f from these relative judgments.
  - **Quick check question:** Can you explain why standard Bayesian Optimization (which relies on direct function observations y = f(x) + ε) fails in this context?

- **Concept:** Laplace Approximation
  - **Why needed here:** The paper uses this to turn a non-Gaussian posterior (derived from pairwise probabilities) into a Gaussian one. Understanding this is crucial for debugging the leaf-fitting step (Section 3.2).
  - **Quick check question:** How does the curvature of the log-posterior (the Hessian) relate to the uncertainty (variance) of the estimate?

- **Concept:** Acquisition Functions (specifically qEUBO)
  - **Why needed here:** The mechanism for "active learning." The model doesn't just fit data; it decides which question to ask next to maximize information gain.
  - **Quick check question:** Why does the paper suggest modifying qEUBO to prioritize "within-leaf" comparisons for the Decision Tree model?

## Architecture Onboarding

- **Component map:** Input -> Partitioner -> Estimator -> Constraint Engine -> Acquisition
- **Critical path:** The Straddler Discarding Logic in Section 3.1. This is the most sensitive deviation from standard trees. If implemented incorrectly (e.g., keeping straddlers), the leaf purity drops, and the probabilistic estimates fail.
- **Design tradeoffs:**
  - Interpretability vs. Smoothness: You gain a readable tree and handle spikes/categorical data well, but you lose the smooth interpolation of GPs (performing slightly worse on smooth functions like Rosenbrock).
  - Speed vs. Precision: The tree is fast (~30s vs 2900s for GP), but the Laplace Approximation is a simplification of the true posterior compared to MCMC methods.

- **Failure signatures:**
  - High Dim Starvation: If d > 10, check node sample counts. If empty, the "straddler" logic is discarding too much data.
  - Variance Explosion: If uncertainty estimates are massive, check the Sum-to-Zero constraint implementation (Section 3.2/Appendix A).
  - Flat Acquisition: If qEUBO suggests random pairs, check if the leaf variances are collapsing to zero prematurely.

- **First 3 experiments:**
  1. Spiky vs. Smooth Benchmark: Replicate the "Holdertable" (spiky) vs. "Branin" (smooth) comparison to verify the implementation correctly favors the DT on spikes and GP on smooth surfaces (Figure 2).
  2. Straddler Analysis: Run ablation on the splitting logic. What happens to tree depth and regret if you keep straddlers (assigning them based on winner location) vs. discarding them?
  3. Scaling Test: Verify the ~30s runtime claim against the GP baseline using the "Sushi" dataset (categorical-heavy) to confirm the scalability advantage.

## Open Questions the Paper Calls Out

- **Question:** Can the data loss associated with discarding "straddler" pairs in high-dimensional spaces (d > 10) be mitigated by retaining the pairs but excluding the split dimension from the consistency score calculation?
  - **Basis in paper:** [explicit] Section 3.1 states that discarding pairs that straddle splits poses a problem for higher dimensions and suggests, "Potentially this could be solved by not discarding the straddlers... This is left as future work."
  - **Why unresolved:** The current implementation discards these pairs to ensure pure partitions, which reduces effective data size as dimensionality increases.
  - **What evidence would resolve it:** Benchmark results on functions with d > 10 comparing the current retention method against a modified algorithm that preserves straddlers.

- **Question:** How can the model be extended to allow the decision-maker to state indifference between items in a pairwise comparison?
  - **Basis in paper:** [explicit] Section 6 lists allowing the DM "to state indifference between a PC" as an interesting direction for future work.
  - **Why unresolved:** The current likelihood function (Eq. 2) assumes a strict preference (x ≻ x') and does not accommodate an "equal" outcome.
  - **What evidence would resolve it:** A modification of the likelihood function to handle ties and experiments showing convergence speed with the inclusion of indifference statements.

- **Question:** Would using Expectation Propagation or MCMC methods for posterior approximation improve the accuracy of the leaf utility estimates compared to the currently used Laplace Approximation?
  - **Basis in paper:** [explicit] Section 2.2 mentions that Laplace Approximation is used for computational simplicity, noting, "The use of different approximation methods is left for future research."
  - **Why unresolved:** While Laplace Approximation is fast, it may not capture the posterior uncertainty as accurately as sampling methods, particularly with sparse data in tree leaves.
  - **What evidence would resolve it:** A comparative analysis of regret scores and uncertainty quantification between LA, EP, and MCMC implementations of the tree model.

## Limitations

- High-dimensional fragility: The Consistency Score splitting heuristic fails when dimensionality exceeds ~6-8 due to severe data starvation from straddler discarding
- Scalability tradeoff: While faster than GPs for interpretability-focused problems, the method may fail on high-dimensional continuous problems where GPs excel
- Approximation limitations: Laplace Approximation may not capture true posterior structure when pairwise likelihood creates strong skewness

## Confidence

- **High confidence:** The scalability advantage (30s vs 2900s) and interpretability benefits on the Sushi dataset are well-supported by direct empirical evidence
- **Medium confidence:** The superior performance on spiky functions is demonstrated across multiple benchmarks, but the comparison is limited to 2D-6D problems where the method is known to work well
- **Medium confidence:** The claim about handling categorical data better than GPs is supported by the Sushi case study but would benefit from more systematic evaluation on mixed-type datasets
- **Low confidence:** The scalability to high-dimensional continuous problems (>10D) is explicitly identified as a limitation, with no proposed solution beyond noting the problem

## Next Checks

1. **High-dimensional stress test:** Systematically evaluate the method on 10-20 dimensional benchmark functions to quantify exactly where and how the straddler-discard mechanism fails. Measure data retention rates and compare performance degradation against GPs.

2. **Laplace Approximation validation:** Compare the Laplace Approximation uncertainty estimates against MCMC sampling on a small benchmark problem to assess the accuracy of the Gaussian assumption for acquisition function optimization.

3. **Alternative splitting heuristics:** Implement and test modified versions of the Consistency Score that handle straddlers differently (e.g., weighted assignment, bucketing) to determine if the scalability limitation is fundamental or can be mitigated with algorithmic changes.