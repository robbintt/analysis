---
ver: rpa2
title: 'Structured Legal Document Generation in India: A Model-Agnostic Wrapper Approach
  with VidhikDastaavej'
arxiv_id: '2504.03486'
source_url: https://arxiv.org/abs/2504.03486
tags:
- legal
- document
- generation
- documents
- structured
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work introduces VidhikDastaavej, the first anonymized dataset
  of private legal documents in the Indian legal domain, to address the challenge
  of automated legal document generation. A Model-Agnostic Wrapper (MAW) framework
  is proposed to improve coherence and factual accuracy by structuring document generation
  in two phases: section title generation followed by section-wise content generation.'
---

# Structured Legal Document Generation in India: A Model-Agnostic Wrapper Approach with VidhikDastaavej

## Quick Facts
- arXiv ID: 2504.03486
- Source URL: https://arxiv.org/abs/2504.03486
- Reference count: 34
- Primary result: VidhikDastaavej dataset introduced; Model-Agnostic Wrapper significantly improves legal document generation quality and reduces hallucinations compared to direct fine-tuning

## Executive Summary
This work introduces VidhikDastaavej, the first anonymized dataset of private legal documents in the Indian legal domain, to address the challenge of automated legal document generation. A Model-Agnostic Wrapper (MAW) framework is proposed to improve coherence and factual accuracy by structuring document generation in two phases: section title generation followed by section-wise content generation. The NyayaShilp model, fine-tuned on Indian legal texts, is evaluated alongside multiple open-source and proprietary models. Results show that direct fine-tuning on small datasets does not always improve performance, but the MAW significantly enhances document quality and reduces hallucinations. Expert-based evaluations confirm that the wrapper-assisted approach achieves high reliability, with scores comparable to GPT-4o, making it a viable, cost-effective alternative for structured legal drafting in India.

## Method Summary
The method introduces a two-phase Model-Agnostic Wrapper (MAW) for structured legal document generation. Phase 1 generates section titles from user-provided document title and description, allowing user review and editing. Phase 2 iteratively generates content for each section while leveraging retrieval-based mechanisms - after each section is generated, a summary is created and stored in ChromaDB. During subsequent iterations, relevant section summaries are retrieved and injected into the context window to maintain coherence and factual consistency across sections. The NyayaShilp model is created through continued pretraining on 38K+ Indian legal cases followed by supervised fine-tuning on 469 private legal documents using LoRA parameter-efficient fine-tuning.

## Key Results
- Direct fine-tuning on small legal datasets (n=469) degraded model performance across all evaluated models
- The MAW wrapper approach achieved factual accuracy scores of 8.07 (vs. 5.93 for base LLaMA-3-8B) and completeness scores of 7.65 (vs. 5.46) on expert evaluation
- Expert evaluations confirmed the wrapper approach achieves quality comparable to GPT-4o while being more cost-effective
- Models with wrapper assistance showed significantly reduced hallucinations compared to direct generation approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Separating title generation from content generation improves document coherence and reduces hallucinations in long-form legal documents.
- **Mechanism:** The Model-Agnostic Wrapper (MAW) enforces a two-phase workflow: Phase 1 generates section titles with user review/editing; Phase 2 iteratively generates content for each section. By decomposing the task, each generation step operates within a narrower context window, reducing the cognitive load on the LLM and grounding subsequent content in explicitly approved structural scaffolding.
- **Core assumption:** Legal document quality is constrained more by structural incoherence and context drift than by lack of domain knowledge in the base model.
- **Evidence anchors:**
  - [abstract] "MAW, a two-step framework that first generates structured section titles and then iteratively produces content while leveraging retrieval-based mechanisms to ensure coherence and factual accuracy."
  - [Section 6.1] "By adopting a two-phase workflow, we ensure that adequate time is dedicated to both section title generation and section content generation separately, rather than attempting to generate both simultaneously."
  - [corpus] Neighbor paper *TreeWriter* similarly advocates hierarchical planning and writing for long-form documents, suggesting broader validity of decomposition strategies.
- **Break condition:** If documents are short (under ~500 tokens) or require real-time streaming generation without user review, the overhead of two-phase separation may outweigh benefits.

### Mechanism 2
- **Claim:** Retrieving summaries of previously generated sections improves cross-section coherence and factual consistency.
- **Mechanism:** After generating content for each section, the wrapper generates a concise summary and stores it in ChromaDB (a vector database). In subsequent iterations, the system retrieves top-k relevant summaries using semantic similarity and injects them into the LLM's context window. This provides a compressed, queryable memory of prior content.
- **Core assumption:** Section summaries contain sufficient signal to maintain factual and logical continuity without requiring the full text of all prior sections.
- **Evidence anchors:**
  - [Section 6.1, Phase 2] "The generated summary is stored in a vector database (ChromaDB) to facilitate contextual referencing. During subsequent iterations, the vector database is queried for relevant section summaries."
  - [Section 9.3] "The wrapper enhances consistency across sections, ensuring logical flow and improving document quality."
  - [corpus] *Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation* employs similar retrieval-augmented approaches for document generation, though corpus evidence specifically linking summarization+retrieval to coherence is weak.
- **Break condition:** If sections are highly interdependent with complex cross-references (e.g., legal documents with dense mutual exclusivity clauses), summary-based retrieval may miss critical nuances.

### Mechanism 3
- **Claim:** The wrapper approach reduces hallucinations more effectively than direct fine-tuning on small legal datasets.
- **Mechanism:** Structured generation constrains the output space by (1) pre-defining section boundaries, (2) grounding content generation in user-approved titles, and (3) maintaining a retrieval-augmented context. These constraints reduce the probability of generating factually inconsistent or fabricated content compared to unconstrained end-to-end generation.
- **Core assumption:** Hallucinations in legal document generation primarily stem from unconstrained generation rather than fundamental model limitations.
- **Evidence anchors:**
  - [Section 9.3] "By enforcing a structured, stepwise document generation approach, the wrapper minimizes hallucinations by ensuring that the generated content remains grounded in the given instructions and previously generated sections."
  - [Section 9.2] "SFT led to performance degradation across models instead of improvement... fine-tuning on a limited number of samples per category might have caused overfitting."
  - [corpus] Direct corpus evidence for hallucination reduction mechanisms is not available; this inference relies primarily on the paper's internal claims.
- **Break condition:** If the base model has severe factual gaps in the target domain (e.g., no exposure to Indian legal terminology), structural constraints alone cannot compensate.

## Foundational Learning

- **Concept: Continued Pretraining (CPT) vs. Supervised Fine-Tuning (SFT)**
  - **Why needed here:** NyayaShilp uses CPT on Indian legal corpora (38K+ cases) to inject domain knowledge, followed by SFT on 469 private documents. The paper shows SFT degraded performance, highlighting the distinction's practical importance.
  - **Quick check question:** Given a 7B-parameter model and 500 domain-specific documents, would you expect CPT, SFT, or their combination to yield better results—and why?

- **Concept: Parameter-Efficient Fine-Tuning (LoRA)**
  - **Why needed here:** The authors use Low-Rank Adaptation (rank=16, alpha=64) to fine-tune without full model updates, enabling training on a single A100 GPU.
  - **Quick check question:** What is the tradeoff between LoRA rank size and model expressiveness in domain adaptation tasks?

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** The MAW stores section summaries in ChromaDB and retrieves relevant context during generation. Understanding vector similarity search is essential for implementing or modifying this component.
  - **Quick check question:** How does chunking strategy (document vs. section vs. paragraph) affect retrieval quality in long-document generation?

## Architecture Onboarding

- **Component map:** Document title + description (user-provided) -> Phase 1: LLM generates section titles -> User reviews/edits -> Finalized titles -> Phase 2 (per section): LLM generates content -> Generates summary -> Store in ChromaDB -> Retrieve relevant summaries for next section -> Aggregated document with all sections

- **Critical path:** The wrapper's Phase 2 retrieval loop is the bottleneck. If summary retrieval is slow or irrelevant, cross-section coherence degrades. Start by profiling ChromaDB query latency and relevance with representative embeddings.

- **Design tradeoffs:**
  - **Complexity vs. quality:** Wrapper adds orchestration overhead (multiple LLM calls, vector DB queries) but significantly improves expert evaluation scores (factual accuracy: 8.07 vs. 5.93 for base LLaMA-3-8B).
  - **Cost vs. performance:** Open-source models with wrapper approach GPT-4o quality at lower inference cost, but require more engineering.
  - **User control vs. automation:** HITL enables title editing but introduces friction; fully automated pipelines sacrifice this control.

- **Failure signatures:**
  - **SFT degradation:** Fine-tuning on small datasets (n=469) caused performance drops across all models—symptom: outputs mirror prompts rather than generating new content (see Appendix Table 6).
  - **Perfect IAA on failed outputs:** If all experts rate a model identically at zero, the model likely failed to produce coherent output (observed with Phi-3 mini and SFT models).
  - **Hallucination patterns:** Post-SFT models produced gibberish or legally invalid content (see Appendix Table 6). Diagnostic: detect repeated/mirrored prompts, non-ASCII characters, or nonsensical clauses; use wrapper to enforce structure and reduce ungrounded generation.

- **First 3 experiments:**
  1. **Baseline comparison:** Run MAW over LLaMA-2-7B-chat without any fine-tuning. Measure Rouge, BERTScore, and expert factual accuracy on 5 documents. Establish a baseline to quantify wrapper contribution.
  2. **Ablation: Remove retrieval:** Disable ChromaDB retrieval in Phase 2 and generate sections independently. Compare coherence scores and cross-section factual consistency to identify retrieval's marginal contribution.
  3. **Vary summary granularity:** Test three summarization strategies: (a) full section text as context, (b) LLM-generated summary, (c) extractive summary (first/last N sentences). Measure impact on expert completeness scores and inference latency.

## Open Questions the Paper Calls Out
None

## Limitations
- VidhikDastaavej dataset unavailable for independent validation of SFT results and wrapper effectiveness
- Claims about hallucination reduction rely heavily on internal expert evaluations without controlled ablation studies
- Mechanism by which CPT+Corpus differs from direct fine-tuning is inferred but not experimentally validated

## Confidence
- **High Confidence:** The wrapper's two-phase architecture (title generation → content generation) and its implementation details (ChromaDB for summary retrieval)
- **Medium Confidence:** Claims about SFT degradation and the superiority of the wrapper approach, as these are based on internal evaluations that cannot be independently verified
- **Low Confidence:** Specific quantitative improvements (e.g., factual accuracy scores) due to the unavailability of the test dataset and prompts

## Next Checks
1. **Replicate wrapper architecture:** Implement the MAW with open-source legal documents to verify that the two-phase approach improves coherence over direct generation
2. **Test SFT on small datasets:** Conduct controlled experiments with varying dataset sizes to confirm whether fine-tuning on <500 samples consistently degrades performance
3. **Analyze hallucination patterns:** Compare hallucination rates between wrapper-assisted and direct generation approaches using established metrics (e.g., factuality scores, repeated content detection) on publicly available legal document benchmarks