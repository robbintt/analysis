---
ver: rpa2
title: 'SEASON: Mitigating Temporal Hallucination in Video Large Language Models via
  Self-Diagnostic Contrastive Decoding'
arxiv_id: '2512.04643'
source_url: https://arxiv.org/abs/2512.04643
tags:
- temporal
- video
- hallucination
- spatial
- while
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "SEASON tackles temporal hallucination in video language models\
  \ by introducing self-diagnostic contrastive decoding. It constructs temporally\
  \ homogenized negatives to expose spurious temporal correlations, and dynamically\
  \ diagnoses each token\u2019s hallucination tendency via frame-attention divergence\
  \ to apply adaptive contrastive penalties."
---

# SEASON: Mitigating Temporal Hallucination in Video Large Language Models via Self-Diagnostic Contrastive Decoding

## Quick Facts
- arXiv ID: 2512.04643
- Source URL: https://arxiv.org/abs/2512.04643
- Reference count: 40
- SEASON outperforms training-free baselines on three hallucination benchmarks while preserving general video understanding performance.

## Executive Summary
SEASON addresses the problem of temporal hallucination in video language models by introducing a self-diagnostic contrastive decoding framework. The method identifies and mitigates spurious temporal correlations by constructing temporally homogenized negative samples and dynamically diagnosing each token's hallucination tendency through frame-attention divergence. Experimental results demonstrate that SEASON effectively reduces temporal hallucination while maintaining or improving performance on general video understanding tasks across multiple benchmarks.

## Method Summary
SEASON introduces a self-diagnostic contrastive decoding approach that targets temporal hallucination in video language models. The method constructs temporally homogenized negative samples to expose spurious temporal correlations in the model's predictions. It then dynamically diagnoses each token's hallucination tendency by measuring frame-attention divergence, which captures inconsistencies in how the model attends to different frames when generating tokens. Based on this diagnosis, SEASON applies adaptive contrastive penalties during decoding to suppress hallucinated content. This training-free approach operates at inference time and does not require additional model training or fine-tuning.

## Key Results
- SEASON outperforms training-free baselines on three temporal hallucination benchmarks
- Method preserves or improves performance on four general video understanding tasks
- Demonstrates effective mitigation of temporal hallucination without sacrificing general video understanding capabilities

## Why This Works (Mechanism)
SEASON works by leveraging the model's own attention patterns to identify temporal inconsistencies. When a video language model generates tokens, it attends to different video frames to inform its predictions. SEASON measures the divergence in these attention patterns across frames - if the model's attention shifts erratically between frames for the same token context, this indicates potential temporal hallucination. By constructing negatives that are temporally homogenized, the method creates contrastive examples that help the model distinguish between temporally consistent and inconsistent predictions. The adaptive contrastive penalties then suppress tokens that show high attention divergence, effectively reducing temporal hallucination while preserving accurate temporal reasoning.

## Foundational Learning
- Temporal Hallucination: When video models generate content inconsistent with the actual temporal sequence - needed because standard video models often fail to maintain temporal coherence across frames; quick check: compare generated captions across sequential frames for consistency
- Frame-Attention Divergence: Measure of inconsistency in how model attends to different frames when generating the same token - needed to identify tokens likely to be hallucinated; quick check: plot attention weights across frames for suspect tokens
- Contrastive Decoding: Using negative samples to improve generation quality - needed to provide the model with alternatives that highlight temporal inconsistencies; quick check: verify contrastive samples are truly temporally homogenized
- Temporal Homogenization: Process of creating negatives that maintain consistent temporal properties - needed to ensure contrastive examples effectively expose temporal hallucinations; quick check: analyze temporal features of constructed negatives
- Self-Diagnostic Framework: Model uses its own outputs to diagnose problems - needed to avoid external supervision and enable training-free operation; quick check: validate that diagnosed tokens correlate with actual hallucinations

## Architecture Onboarding

Component Map: Video Encoder -> Language Model -> Attention Analyzer -> Contrastive Decoder -> Output Filter

Critical Path: Input Video Frames -> Visual Features -> Token Generation -> Attention Divergence Measurement -> Contrastive Penalty Application -> Final Output

Design Tradeoffs:
- Training-free vs. fine-tuning: SEASON avoids additional training but may be less optimal than task-specific fine-tuning
- Computational overhead: Self-diagnostic analysis adds inference-time computation but provides adaptive mitigation
- Temporal vs. spatial accuracy: Focus on temporal hallucination may potentially impact spatial understanding

Failure Signatures:
- High attention divergence across frames without corresponding hallucination
- Inconsistent performance across different video lengths or frame rates
- Over-suppression of temporally accurate but attention-divergent content

First Experiments:
1. Measure baseline attention divergence patterns on clean, temporally consistent videos
2. Generate contrastive samples and verify temporal homogenization effectiveness
3. Test adaptive penalty thresholds on controlled hallucination examples

## Open Questions the Paper Calls Out
None

## Limitations
- Does not evaluate whether temporal accuracy improvements come at the cost of spatial accuracy or overall coherence
- Reliance on attention divergence as hallucination proxy may not consistently correlate with actual hallucination in diverse real-world scenarios
- Performance claims based on only four general video understanding datasets, which may not represent broader task diversity

## Confidence

High confidence in method's ability to reduce temporal hallucination on benchmark datasets.
Medium confidence in generalizability to videos with complex temporal dynamics or multiple concurrent events.
Low confidence in performance on open-ended, real-world video understanding tasks beyond evaluated benchmarks.

## Next Checks

1. Evaluate SEASON's performance on long-form videos (10+ minutes) to assess temporal consistency over extended durations.
2. Test the method on videos with overlapping events or ambiguous temporal sequences to validate robustness.
3. Conduct ablation studies to determine the relative contribution of the contrastive decoding and self-diagnostic components.