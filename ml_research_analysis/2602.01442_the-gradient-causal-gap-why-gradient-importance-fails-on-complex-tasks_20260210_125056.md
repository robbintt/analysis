---
ver: rpa2
title: 'The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks'
arxiv_id: '2602.01442'
source_url: https://arxiv.org/abs/2602.01442
tags:
- gradient
- seed
- causal
- bloats
- components
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper identifies the Gradient-Causal Gap, showing that gradient\
  \ magnitude fails as a proxy for component importance in Transformers on algorithmic\
  \ tasks. While gradient-causal alignment is strong on simple tasks (\u03C1=0.73\
  \ for reversal), it collapses with complexity (\u03C1=0.32 for sorting), sometimes\
  \ inverting (\u03C1=-0.11)."
---

# The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks

## Quick Facts
- arXiv ID: 2602.01442
- Source URL: https://arxiv.org/abs/2602.01442
- Reference count: 26
- Key outcome: Gradient magnitude fails as proxy for component importance in Transformers on algorithmic tasks; correlation drops from ρ=0.73 (reversal) to ρ=0.32 (sorting)

## Executive Summary
This paper identifies the Gradient-Causal Gap, demonstrating that gradient magnitude fails as a reliable proxy for component importance in Transformers on algorithmic tasks. While gradient-causal alignment is strong on simple tasks (ρ=0.73 for reversal), it collapses with complexity (ρ=0.32 for sorting), sometimes inverting (ρ=-0.11). Pruning experiments reveal two failure modes: "Hidden Heroes" (low-gradient but causally essential components) cause 32% OOD accuracy drops when removed, while "Gradient Bloats" (high-gradient but unimportant components) have unpredictable effects—either harmless (optimization noise) or catastrophic (overfitting circuits). This unpredictability means gradient-based pruning cannot reliably preserve model capabilities.

## Method Summary
The study trains 4-layer decoder-only Transformers (4 heads/layer, d_model=128, d_ff=512) on Sequence Reversal and Sequence Sorting tasks with sequences of length N∈[3,7]. Models are trained to ≥90% accuracy or 15,000 steps max using Adam optimizer (lr=10⁻³). Causal importance is measured via mean ablation (replacing activations with dataset-averaged values), while gradient magnitude is computed as mean Frobenius norm over OOD batches. Spearman correlation ρ between gradient magnitude and causal importance is calculated, with components classified as Hidden Heroes (∆i ≤ -6), Gradient Bloats (∆i ≥ 6), or Aligned (|∆i| < 6).

## Key Results
- Gradient-causal correlation collapses with task complexity: ρ=0.73 (reversal) → ρ=0.32 (sorting) → ρ=-0.11 (severe inversion)
- Pruning Hidden Heroes consistently devastates OOD accuracy (-32% ± 5%)
- Gradient Bloats show bimodal pruning effects: harmless optimization noise or catastrophic overfitting circuits
- Heroes cluster in later layers (L2-L3), Bloats cluster in early layers (L0-L1)

## Why This Works (Mechanism)

### Mechanism 1: Gradient-Causal Decoupling Under Complexity
Gradients aggregate backpropagation signals across all token positions, serving as broad feature extractors that optimize training loss. Causal importance, measured via ablation, captures sparse logic required for OOD generalization. These objectives diverge when algorithmic reasoning requires localized operations. This is not a depth artifact as the Reversal task exhibits late-layer Bloats (L2 MLP) and early-layer Heroes (L1 MLP), confirming the gap is driven by task semantics.

### Mechanism 2: Hidden Heroes—Low-Gradient, High-Causal Components
"Hidden Heroes" implement sparse, localized algorithmic logic that produces weak gradient signals during training but is necessary for OOD execution. On sorting, these concentrate in L2-L3 (especially L3_H3, appearing in 7/10 seeds). Removing low-gradient "Hidden Heroes" consistently devastates OOD accuracy (-32%).

### Mechanism 3: Gradient Bloat Ambiguity—Harmless Noise or Catastrophic Shortcuts
High-gradient components split into "Optimization Noise" (safe to prune) and "Overfitting Circuits" (catastrophic to prune) with no gradient-based signal to distinguish them. The bimodality reflects distinct functional regimes rather than measurement noise. Pruning Gradient Bloats did not produce a uniform effect, but rather split into two distinct functional regimes with mean ID drop of 2.9% ± 14.4%.

## Foundational Learning

- **Gradient magnitude vs. causal importance as distinct signals**: The paper's central claim requires understanding that gradient norm measures optimization sensitivity, not functional necessity. Quick check: If you double the learning rate and gradient magnitude increases, does causal importance change? (Expected: No direct relationship.)

- **Mean ablation methodology**: The paper uses mean ablation (replacing activations with dataset-averaged values) as its causal measure—different from zero or noise ablation. Quick check: Why might mean ablation preserve residual stream structure better than zero ablation? (Expected: Mean preserves distributional statistics.)

- **OOD generalization vs. training loss as objectives**: The gap emerges because gradients optimize training loss while causal importance reflects OOD generalization. Quick check: Can a component have zero gradient (at local optimum) but high causal importance? (Expected: Yes, if the component is necessary but not being updated.)

## Architecture Onboarding

- **Component map**: L0_H0 -> L0_H1 -> L0_H2 -> L0_H3 -> L0_MLP -> L1_H0 -> L1_H1 -> L1_H2 -> L1_H3 -> L1_MLP -> L2_H0 -> L2_H1 -> L2_H2 -> L2_H3 -> L2_MLP -> L3_H0 -> L3_H1 -> L3_H2 -> L3_H3 -> L3_MLP

- **Critical path**: For Sorting, the critical OOD path runs through late-layer heads (L2_H1, L2_H2, L3_H0, L3_H2, L3_H3). Early-layer heads (L1_H0-H3) are high-gradient but functionally ambiguous.

- **Design tradeoffs**: Small scale (4 layers) enables exhaustive component analysis but limits generalization to large models. Mean ablation chosen over activation patching for computational efficiency, may miss context-dependent effects. Algorithmic tasks provide controlled testbed but may not reflect naturalistic reasoning.

- **Failure signatures**: Pruning Heroes: Sudden -30%+ OOD accuracy drop with minimal ID change. Pruning Bloats (Noise regime): No accuracy change or slight improvement. Pruning Bloats (Shortcut regime): Catastrophic ID collapse (>30% drop). Negative ρ correlation: Indicator of severe gradient-causal inversion.

- **First 3 experiments**: 1) Replicate correlation analysis: Train 4-layer Transformer on Reversal and Sorting with 5+ seeds. Compute Spearman ρ between gradient magnitude and causal importance. Verify ρ drops from ~0.7 to ~0.3. 2) Layer-wise clustering check: For Sorting models, compute ∆_i = Rank(G_i) - Rank(C_i) for all 20 components. Confirm Heroes (∆ ≤ -6) cluster in L2-L3 and Bloats (∆ ≥ 6) cluster in L0-L1. 3) Pruning validation: Ablate top-2 Heroes and top-2 Bloats separately. Measure OOD accuracy change. Expect Heroes: -30%±5%, Bloats: bimodal distribution (harmless or catastrophic).

## Open Questions the Paper Calls Out

- **Does the Gradient-Causal Gap persist in large-scale models (e.g., 7B+ parameters), or is it an artifact of small architecture capacity?** The computational cost of exhaustive causal ablations and the complexity of circuits in LLMs make verification difficult. Replicating the gradient-causal correlation analysis on larger models (e.g., GPT-2 Small or Llama-7B) using comparable algorithmic or reasoning benchmarks would resolve this.

- **Does the gap between gradient magnitude and causal importance appear in naturalistic tasks (e.g., NLP reasoning) lacking explicit algorithmic structure?** Algorithmic tasks induce specific "clean" circuits; messy, natural data might distribute logic differently, altering the divergence. Measuring gradient-causal alignment on models trained for tasks like sentiment analysis or natural language inference would resolve this.

- **Can "Gradient Bloats" be distinguished as "Optimization Noise" or "Overfitting Circuits" prior to destructive pruning?** Current analysis relies on post-hoc pruning to classify these components; no predictive signal has been identified. Identifying training dynamics or activation statistics that correlate with whether a high-gradient component is functionally redundant or harmful would resolve this.

- **Does the choice of causal intervention method (e.g., activation patching vs. mean ablation) change the identification of "Hidden Heroes"?** Mean ablation assumes a specific baseline behavior which might penalize components differently than resampling-based interventions. Comparing the Gradient-Causal Gap using both mean ablation and activation patching on the same trained models would resolve this.

## Limitations

- The analysis is based on a highly controlled setup with a small 4-layer Transformer architecture, which limits direct generalization to larger models.
- The correlation measurements rely on mean ablation methodology, which may not fully capture distributed representations or context-dependent effects.
- The bimodality observed in Gradient Bloats pruning outcomes requires further investigation to distinguish between intrinsic gradient ambiguity and seed-dependent architectural variations.

## Confidence

- **High confidence**: Empirical observation that gradient-causal alignment deteriorates with task complexity (from ρ=0.73 to ρ=0.32) and basic pruning effects showing Heroes cause ~32% OOD accuracy drops while Bloats show unpredictable responses.
- **Medium confidence**: Mechanistic explanations, particularly the claim that gradients track optimization dynamics rather than functional logic, and the clustering patterns of Heroes in later layers versus Bloats in early layers.
- **Low confidence**: Transferability of these findings to larger models and more naturalistic tasks, given the simplified algorithmic nature of the experiments and the small-scale architecture.

## Next Checks

1. **Architecture scaling test**: Replicate the correlation analysis on a 12-layer Transformer trained on the same tasks to determine whether the Gradient-Causal Gap persists or diminishes with increased model depth.

2. **Ablation method comparison**: Compare mean ablation results against zero ablation and activation patching on a subset of models to assess whether measurement methodology influences the observed gap magnitude.

3. **Distribution shift robustness**: Evaluate the same components under OOD length distributions that differ from the evaluation distribution (e.g., test on N=12-15 after training on N=3-7) to verify that Heroes maintain their causal importance across varying generalization challenges.