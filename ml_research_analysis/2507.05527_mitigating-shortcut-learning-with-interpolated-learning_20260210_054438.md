---
ver: rpa2
title: Mitigating Shortcut Learning with InterpoLated Learning
arxiv_id: '2507.05527'
source_url: https://arxiv.org/abs/2507.05527
tags:
- interpoll
- minority
- examples
- pages
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: InterpoLL addresses shortcut learning in NLP by interpolating representations
  of majority and intra-class minority examples to weaken shortcut influence and improve
  minority generalization. The method identifies majority/minority examples via an
  under-parameterized auxiliary model, then interpolates their representations during
  training, with interpolation ratios sampled from Uniform(0, 0.5) to avoid substantial
  alterations.
---

# Mitigating Shortcut Learning with InterpoLated Learning

## Quick Facts
- **arXiv ID**: 2507.05527
- **Source URL**: https://arxiv.org/abs/2507.05527
- **Reference count**: 36
- **Primary result**: InterpoLL improves minority generalization by 3.9-4.2% over ERM and state-of-the-art methods while maintaining majority accuracy

## Executive Summary
InterpoLL addresses shortcut learning in NLP by interpolating representations of majority and intra-class minority examples to weaken shortcut influence and improve minority generalization. The method identifies majority/minority examples via an under-parameterized auxiliary model, then interpolates their representations during training, with interpolation ratios sampled from Uniform(0, 0.5) to avoid substantial alterations. Evaluated across six NLU datasets and three model architectures (encoder, encoder-decoder, decoder-only), InterpoLL consistently improves minority generalization by 3.9-4.2% over ERM and state-of-the-art methods while maintaining majority accuracy. It reduces shortcut extractability from representations, demonstrates robustness to noisy labels, and provides balanced training dynamics between example groups.

## Method Summary
InterpoLL works by first training an under-parameterized auxiliary model to identify majority and minority examples in the training data - examples correctly classified by the auxiliary model are labeled majority (exploit shortcuts), while misclassified examples are labeled minority (rely on non-shortcut features). During training, for each majority example, the method samples a same-class minority example and interpolates their representations using a ratio sampled from Uniform(0, 0.5). This interpolation process dilutes shortcut features in majority examples while preserving task-relevant signals, improving generalization to minority examples. The approach requires no prior knowledge of minority/majority groups and works across different model architectures and scales.

## Key Results
- Improves minority generalization by 3.9-4.2% over ERM and state-of-the-art methods across six NLU datasets
- Maintains majority accuracy while improving minority performance, demonstrating balanced training dynamics
- Reduces shortcut extractability from representations, showing the interpolation effectively weakens spurious correlations
- Demonstrates robustness to noisy labels and effectiveness across model scales from BERT-tiny to T5-3B
- Works across encoder, encoder-decoder, and decoder-only architectures without architecture-specific tuning

## Why This Works (Mechanism)

### Mechanism 1: Representation-Space Shortcut Dilution
Interpolating majority representations with intra-class minority examples may weaken shortcut features while preserving task-relevant signals. For each majority example x_i, InterpoLL constructs z_i = (1−λ)f_enc(x_i) + λf_enc(x_j) where x_j is a same-class minority example and λ ~ Uniform(0, 0.5). This linearly dilutes shortcut-dominant features in x_i by injecting shortcut-mitigating features from x_j. If minority examples lack effective shortcut-mitigating features, or if λ is too large (≥0.5), majority representations become substantially altered, impairing both majority and minority performance.

### Mechanism 2: Implicit Feature Distribution Balancing
Repeated interpolation may act as implicit augmentation, balancing training dynamics across majority/minority groups. Across epochs, majority examples repeatedly receive minority feature injections, increasing effective exposure to underrepresented patterns. This counters ERM's tendency to fit majority shortcuts first. When minority set is extremely small or noisy, repeated sampling may overfit to limited minority patterns.

### Mechanism 3: Auxiliary-Based Minority Identification Without Group Annotations
Under-parameterized auxiliary models can identify minority examples by failing on shortcut-dependent predictions. An under-parameterized auxiliary model f_ϕ is trained with ERM; misclassified examples are labeled minority (rely on non-shortcut features), correctly classified examples are majority (exploit shortcuts). Under-parameterization amplifies shortcut reliance, causing systematic failures on minority examples that don't exhibit spurious correlations. If the auxiliary model is over-regularized or poorly trained, it may misidentify minority examples, degrading interpolation quality.

## Foundational Learning

- **Concept: Shortcut Learning in NLP** - Understanding that ERM exploits spurious correlations (e.g., word overlap → entailment in MNLI) that fail on minority examples where correlations don't hold. Quick check: Why does high word overlap between premise-hypothesis create a problematic shortcut in NLI, and what type of minority example would break this pattern?

- **Concept: Under-parameterization and Bias Sensitivity** - InterpoLL relies on smaller models being more shortcut-sensitive for minority identification; understanding this inverse scaling is critical. Quick check: Would a BERT-large auxiliary model be more or less effective than BERT-tiny for identifying minority examples, and why?

- **Concept: Representation-Space vs Input-Space Interpolation** - InterpoLL operates on CLS embeddings, not raw text; understanding this distinction is essential for implementation and debugging. Quick check: What information is preserved vs. lost when interpolating sentence embeddings compared to interpolating token sequences?

## Architecture Onboarding

- **Component map**: Auxiliary model (f_ϕ) -> Minority/Majority Classification -> Interpolation Module -> Learner model (f_θ) -> Classifier -> Loss Computation

- **Critical path**: 1) Train auxiliary model f_ϕ with ERM; classify training data: misclassified → minority (g_min), correct → majority (g_maj) 2) For each training batch, identify majority examples; for each, sample same-class minority example from g_min 3) Compute interpolated representation z_i using Equation 2; pass z_i to classifier for loss computation 4) Backpropagate through encoder and classifier using interpolated representations for majority, original for minority

- **Design tradeoffs**: λ ~ U(0, 0.5) balances shortcut weakening vs. majority preservation; U(0, 1) or Beta distributions degrade performance. Table 5 shows comparable performance across BERT-tiny/base/large and under-trained/regularized variants; no-auxiliary variant (learner self-identifies) also viable. Figure 5 indicates upper encoder layers (9–12 for BERT-base) are most effective; early layers show smaller gains. Table 4 confirms effectiveness across encoder (BERT, RoBERTa), encoder-decoder (T5), and decoder-only (GPT-2) architectures.

- **Failure signatures**: In-distribution accuracy drop as trade-off for OOD gains. Inter-class interpolation introduces irrelevant features, degrading both ID and OOD performance. Inverted interpolation direction (minority with majority) improves majority but harms minority accuracy. If auxiliary recall <90%, minority identification degrades, reducing interpolation effectiveness.

- **First 3 experiments**: 1) Baseline reproduction: Implement InterpoLL with BERT-base learner and TinyBERT auxiliary on MNLI; measure ID/OOD accuracy on HANS stress test to verify 3.9–4.2% gains vs. GroupDRO 2) Interpolation ratio ablation: Test λ ~ U(0, 0.5), U(0, 1), Beta(0.5, 0.5), Beta(2, 2) on MNLI→HANS to replicate Figure 2; expect U(0, 0.5) to achieve best balance 3) Layer-wise interpolation: Apply interpolation at layers 1, 6, 9, 12 of BERT-base; evaluate on HANS to confirm upper-layer advantage per Figure 5

## Open Questions the Paper Calls Out

- **Does the suppression of shortcut features via InterpoLL inadvertently degrade other useful, task-relevant semantic information within the learned representations?** The authors note their analysis doesn't examine whether this suppression inadvertently impacts other aspects of the learned representations. The probing experiments focused strictly on measuring the extractability of shortcut features but didn't evaluate if non-spurious semantic features are diluted during interpolation.

- **Can the interpolation ratio λ be adapted dynamically to mitigate the specific trade-off between in-distribution (ID) accuracy and out-of-distribution (OOD) generalization?** The Limitations section notes that InterpoLL can result in reduced ID accuracy, and the analysis shows λ is currently sampled statically from Uniform(0, 0.5). The paper doesn't explore if this trade-off curve can be optimized via adaptive parameters based on example difficulty.

- **Does InterpoLL generalize effectively to multilingual settings or modalities beyond English Natural Language Understanding (NLU)?** The authors list as a limitation that their experiments focus on specific English-language natural language understanding tasks, leaving InterpoLL's broader applicability to other tasks and languages unexplored. Shortcut structures and representation spaces differ significantly across languages and modalities.

## Limitations
- May reduce in-distribution accuracy as a trade-off for out-of-distribution generalization gains
- Limited evaluation to English NLU tasks; generalization to other languages and modalities remains unexplored
- Does not examine whether shortcut suppression inadvertently impacts other aspects of learned representations

## Confidence
- **High**: Representation interpolation mechanism effectiveness (4.2% gains on six datasets), auxiliary-based minority identification without annotations, robustness to noisy labels
- **Medium**: Architecture-agnostic effectiveness across encoder/decoder models, layer-specific optimization, scalability to larger models
- **Low**: Generalization to non-NLU tasks, performance in extremely imbalanced datasets, long-term robustness to distribution shifts

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically evaluate learning rates, batch sizes, and optimization schedules across the six datasets to determine if reported gains are robust to training configuration changes.
2. **Cross-Domain Transferability**: Test InterpoLL on computer vision and tabular datasets (e.g., CIFAR-10-C, Adult Income) to validate whether representation interpolation generalizes beyond NLP.
3. **Failure Mode Characterization**: Intentionally introduce varying degrees of label noise (10-50%) and shortcut prevalence to identify exact failure thresholds where InterpoLL degrades or breaks down.