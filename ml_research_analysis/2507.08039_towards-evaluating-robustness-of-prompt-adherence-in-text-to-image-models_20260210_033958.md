---
ver: rpa2
title: Towards Evaluating Robustness of Prompt Adherence in Text to Image Models
arxiv_id: '2507.08039'
source_url: https://arxiv.org/abs/2507.08039
tags:
- images
- image
- diffusion
- stable
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel evaluation framework for assessing
  prompt adherence in text-to-image models. The authors create a new 256x256 resolution
  dataset inspired by dSprites, containing simple geometric shapes (square, circle,
  triangle) with controlled factors of variation.
---

# Towards Evaluating Robustness of Prompt Adherence in Text to Image Models

## Quick Facts
- arXiv ID: 2507.08039
- Source URL: https://arxiv.org/abs/2507.08039
- Reference count: 40
- Models struggle with spatial positioning even at high resolutions, with quadrant prediction F1-scores below 0.5 across all tested variants

## Executive Summary
This paper presents a novel evaluation framework for assessing prompt adherence in text-to-image models. The authors create a new 256x256 resolution dataset inspired by dSprites, containing simple geometric shapes (square, circle, triangle) with controlled factors of variation. They employ a pipeline combining gpt-4o for image description generation and trained VAEs for reconstruction analysis to evaluate how well text-to-image models follow input prompts.

The evaluation tests three Stable Diffusion variants and two Janus Pro models using their ground truth dataset of 9,216 images. Results show that while models can generate correct shapes, they struggle significantly with spatial positioning. Shape prediction F1-scores also degrade notably at lower resolutions (256x256), dropping to around 50% for Stable Diffusion models. The study reveals that current text-to-image models lack sufficient spatial awareness despite high guidance scales, highlighting the need for architectural improvements to enhance prompt adherence for simple geometric positioning tasks.

## Method Summary
The authors create a custom 256x256 binary dataset with 3 shapes (square, circle, triangle), 3 scales, and 32x32 position grid, sampling 9,216 test images from 1.4M total. They train β-TCVAE (8-dim latent, 300 epochs) on this dataset and use gpt-4o to generate structured JSON descriptions extracting shape, quadrant, and textual descriptions. Text-to-image models (SD3 Medium, SD3.5 Large, SD3.5 Large Turbo at 256/512/1024, Janus Pro 1B/7B at 384) generate images from these descriptions using guidance_scale=9.0. The evaluation loop involves: ground truth → gpt-4o description → T2I generation → gpt-4o re-description (2 iterations), comparing predictions with F1-scores and computing VAE reconstruction loss (MSE).

## Key Results
- Quadrant prediction F1-scores remain below 0.5 across all models and resolutions, with best performance at 0.41 for Stable Diffusion and 0.5 for Janus Pro
- Shape prediction F1-scores degrade to around 50% at 256x256 resolution for Stable Diffusion models
- Iterative description-generation cycles cause compounding information loss, with spatial positioning degrading faster (9-28% F1 drop) than shape identity (3-13% drop)

## Why This Works (Mechanism)

### Mechanism 1
- Iterative description-generation cycles cause compounding information loss, degrading prompt adherence predictably
- Core assumption: GPT-4o descriptions faithfully capture factors of variation and T2I models process these without systematic bias
- Evidence: F1 score for shape decreases 3-13% and quadrant drops 9-28% across iterations
- Break condition: If GPT-4o's descriptions fail to capture quadrant information accurately on ground truth images

### Mechanism 2
- Resolution directly constrains spatial encoding capacity, with lower resolutions causing disproportionate degradation in positional adherence
- Core assumption: Relationship between resolution and spatial adherence is monotonic and transferable across architectures
- Evidence: No model reached 70% F1 at 256x256, highest quadrant F1 was 0.41 for SD3.5 Large Turbo at 1024x1024
- Break condition: If guidance scale interacts non-linearly with resolution causing mode collapse

### Mechanism 3
- VAE reconstruction loss serves as proxy for distributional alignment between generated images and target datasets
- Core assumption: VAE has learned data distribution and reconstruction loss correlates with semantic adherence
- Evidence: Reconstruction quality for ground truth images is good, confirming VAE training success
- Break condition: If generated images have correct semantics but different pixel statistics, reconstruction loss may penalize stylistic differences

## Foundational Learning

- Concept: **Guidance Scale in Diffusion Models**
  - Why needed here: Paper uses guidance scale = 9.0 to enforce prompt adherence
  - Quick check: If you increase guidance scale from 5.0 to 15.0, would you expect quadrant accuracy to improve monotonically? Why or why not?

- Concept: **Disentanglement in VAEs (β-TCVAE)**
  - Why needed here: Paper trains β-TCVAE to isolate factors of variation (shape, position, scale)
  - Quick check: A VAE has 8 latent dimensions. If dimension 3 controls X-position and dimension 7 controls Y-position, what would a traversal of dimension 3 show?

- Concept: **F1-Score for Multi-class Evaluation**
  - Why needed here: Paper reports F1-scores for shape (3 classes) and quadrant (4 classes)
  - Quick check: If a model always generates shapes in the top-left quadrant, what would its quadrant accuracy be? What would its macro F1-score be?

## Architecture Onboarding

- Component map: Ground Truth Dataset (9,216 binary images) → Description Generator (GPT-4o) → Image Generators (SD3 variants, Janus Pro) → VAE Evaluator (β-TCVAE) → Metrics Pipeline (F1-scores + MSE loss)

- Critical path: Sample ground truth image → GPT-4o description → Text-to-Image generation → GPT-4o re-description → Compare predictions; Generated image → Resize to 256x256 → Pass through VAE → Compute reconstruction loss

- Design tradeoffs: Binary vs. continuous images simplify VAE training but create pixel-level mismatches; quadrant discretization loses precision but current LMMs cannot reliably report exact positions; high guidance enforces adherence but may cause mode collapse

- Failure signatures: SD3 Medium produced frequent blank images, artificially lowering reconstruction loss; images with shapes near centerlines excluded (50px margin) due to GPT-4o reliability issues; 64x64 generation produces "random noise"

- First 3 experiments: 1) Baseline iteration test: Run one full iteration on 100 images with SD3.5 Large Turbo at 1024x1024, verify F1 degradation matches paper (~90% shape, ~40% quadrant on iteration 1); 2) VAE sanity check: Train small β-TCVAE on 10,000 ground truth images, confirm reconstruction loss on held-out ground truth is <0.02, then test on manually corrupted images; 3) Guidance scale ablation: For SD3.5 Large at 512x512, generate images with guidance scale ∈ {3.0, 6.0, 9.0, 12.0}, plot shape F1 and quadrant F1 against guidance scale

## Open Questions the Paper Calls Out

- What specific architectural components in diffusion models (e.g., MMDiT) or unified transformers cause significant degradation in spatial prompt adherence at lower resolutions? The paper identifies failure but doesn't perform ablation studies or internal activation analysis to pinpoint structural bottlenecks.

- Why do unified autoregressive architectures (Janus Pro) outperform specialized diffusion models (Stable Diffusion) in spatial adherence despite generating lower-resolution images? The paper observes the phenomenon but lacks comparative analysis of how decoupled visual encoding versus rectified flow impacts spatial reasoning.

- Does inability to adhere to prompts for simple binary geometric shapes reliably predict failures in complex, natural image generation? The evaluation is restricted to synthetic binary images, leaving unproven if spatial blindness correlates with compositional failures in high-fidelity datasets.

## Limitations

- The study relies on quadrant-based spatial evaluation, which may oversimplify continuous spatial relationships and doesn't test finer spatial distinctions
- Binary ground truth images vs. anti-aliased generated images create pixel-level mismatches that may inflate VAE reconstruction loss without indicating semantic errors
- The paper identifies 64x64 as producing "random noise," suggesting fundamental limitations in current architectures' ability to handle extremely low resolutions for geometric primitives

## Confidence

- **High confidence**: Systematic degradation of spatial positioning across iterative description-generation cycles is robustly demonstrated
- **Medium confidence**: Resolution directly constrains spatial encoding capacity is supported but interactions with guidance scale and model architectures may confound the relationship
- **Medium confidence**: VAE reconstruction loss as proxy for distributional alignment is methodologically sound but binary-to-anti-aliased pixel mismatch is a known limitation

## Next Checks

1. **Resolution-Guidance Interaction Test**: Systematically vary both resolution (256→512→1024) and guidance scale (3.0→15.0) to identify whether resolution effects are independent of guidance-induced mode collapse, particularly for SD3 Medium

2. **Spatial Granularity Validation**: Test whether finer spatial discretization (8 or 16 regions instead of 4 quadrants) reveals additional spatial adherence limitations, or if GPT-4o's spatial reasoning remains the bottleneck

3. **Cross-Model Generalization**: Evaluate additional architectures beyond Stable Diffusion and Janus Pro (e.g., Imagen, DALL-E) to determine whether spatial positioning limitations are universal across text-to-image paradigms or specific to diffusion-based approaches