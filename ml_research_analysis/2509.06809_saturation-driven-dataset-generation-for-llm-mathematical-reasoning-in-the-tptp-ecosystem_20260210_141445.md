---
ver: rpa2
title: Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the
  TPTP Ecosystem
arxiv_id: '2509.06809'
source_url: https://arxiv.org/abs/2509.06809
tags:
- proof
- task
- reasoning
- theorem
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces a symbolic data generation framework that
  uses automated theorem prover E to exhaustively saturate TPTP axioms, producing
  mathematically valid theorems without relying on LLMs. The generated theorems are
  curated using AGInTRater interest metrics and transformed into three reasoning tasks:
  entailment verification, minimal premise selection, and proof graph reconstruction.'
---

# Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem

## Quick Facts
- arXiv ID: 2509.06809
- Source URL: https://arxiv.org/abs/2509.06809
- Reference count: 40
- Introduces symbolic data generation framework using E-prover saturation on TPTP axioms, producing mathematically valid theorems without LLM involvement, with experiments showing GPT-5 models struggle with hierarchical reasoning tasks

## Executive Summary
This paper presents a symbolic data generation framework that uses automated theorem prover E to exhaustively saturate TPTP axioms, producing mathematically valid theorems without relying on LLMs. The generated theorems are curated using AGInTRater interest metrics and transformed into three reasoning tasks: entailment verification, minimal premise selection, and proof graph reconstruction. Experiments on GPT-5 models in zero-shot settings show performance degrades with proof depth and structural complexity, with even the largest models failing to reconstruct complete proof graphs, revealing a fundamental weakness in hierarchical reasoning. The framework provides a scalable, error-free source of high-quality logical data for training and benchmarking LLM mathematical reasoning.

## Method Summary
The framework implements a three-stage pipeline: (1) E-prover runs in saturation mode on TPTP CNF axioms to generate derivation graphs through exhaustive application of superposition calculus rules, (2) AGInTRater scores non-axiom clauses using complexity, surprisingness, and usefulness metrics to filter for "interesting" theorems, and (3) Task generation creates three reasoning tasks with difficulty controlled by proof depth d and distractor count k. Vampire prover validates all generated tasks to ensure 100% correctness. The approach guarantees mathematical validity while providing controllable difficulty levels for evaluating LLM reasoning capabilities.

## Key Results
- E-prover saturation generates mathematically valid theorems with zero error rate compared to LLM-based generation methods
- GPT-5 model performance systematically degrades with increased proof depth d and distractor count k
- Even the largest GPT-5 model fails to reconstruct complete proof graphs, suggesting fundamental limitations in hierarchical reasoning
- Zero-shot performance remains below 50% accuracy on most task-difficulty combinations

## Why This Works (Mechanism)

### Mechanism 1: Saturation-Based Exhaustive Derivation
- Claim: Exhaustive application of inference rules on axiom sets produces a guaranteed-valid theorem space without LLM involvement.
- Mechanism: E-prover runs in pure saturation mode (no goal-directed search), applying superposition calculus rules (resolution, paramodulation) to explore the deductive closure of TPTP axioms, bounded by timeout. This generates a directed acyclic graph where every derived clause is mathematically valid by construction.
- Core assumption: The deductive closure contains sufficiently many non-trivial theorems to be useful; saturation timeout provides practical tractability.
- Evidence anchors:
  - [abstract]: "leverages E-prover's saturation capabilities on the vast TPTP axiom library to derive a massive, guaranteed-valid corpus of theorems"
  - [Section 3.1]: "We configure E-prover to output a full proof graph, which meticulously records every derived clause and its parent(s)"
  - [corpus]: Limited direct corpus support; related TPTP infrastructure paper (arXiv:2508.09318) discusses classical/non-classical logics but not saturation-driven generation
- Break condition: Combinatorial explosion exceeds computational resources before interesting theorems are found; axiom sets too sparse to generate meaningful derivations.

### Mechanism 2: Interest-Weighted Curation
- Claim: Heuristic filtering based on structural properties focuses the vast saturation output on mathematically meaningful statements.
- Mechanism: AGInTRater scores non-axiom clauses using three metrics: (1) Complexity/Weight penalizes structurally large formulas; (2) Surprisingness measures infrequent predicate co-occurrences; (3) Usefulness calculates ratio of "interesting" descendants. Top-scored items per domain/depth are retained.
- Core assumption: These heuristics correlate with mathematical utility for LLM training; pruned theorems maintain logical diversity.
- Evidence anchors:
  - [Section 3.2]: "AGInTRater assigns a score to each non-axiom clause based on a combination of heuristic metrics designed to emulate human judgment"
  - [abstract]: "filter for 'interesting' theorems"
  - [corpus]: No corpus evidence for AGInTRater's effectiveness in LLM contexts
- Break condition: Heuristics systematically exclude important theorem classes; filtering over-aggressive leaving insufficient training data.

### Mechanism 3: Difficulty-Controlled Task Decomposition
- Claim: Decomposing theorem proving into granular tasks with controllable parameters isolates specific reasoning capabilities.
- Mechanism: Three tasks probe different skills: (1) Entailment Verification tests deductive verification with perturbed premises; (2) Minimal Premise Selection requires identifying necessary hypotheses from k distractors; (3) Proof Graph Reconstruction demands hierarchical planning by ordering shuffled steps. Difficulty modulated by proof depth d and distractor count k.
- Core assumption: Task performance gaps reflect genuine reasoning limitations rather than surface-form artifacts; CNF representation transfers to natural language reasoning.
- Evidence anchors:
  - [Section 4]: Detailed task formulations with difficulty parameters
  - [Section 5.2]: "performance systematically degrades with increased logical complexity... particularly stark for the Proof Reconstruction task"
  - [corpus]: SAND-Math (arXiv:2507.20527) uses LLMs for problem generation but doesn't address structural decomposition
- Break condition: Tasks measure prompt-following ability rather than reasoning; models exploit shallow statistical patterns in CNF syntax.

## Foundational Learning

- Concept: Clausal Normal Form (CNF) and First-Order Logic Semantics
  - Why needed here: All generated theorems are expressed in CNF; understanding resolution/superposition requires knowing how clauses represent logical formulas.
  - Quick check question: Given clause `(disjoint(X1,X2) | member(f23(X1,X2),X1))`, what disjunction of literals does this represent?

- Concept: Saturation and Superposition Calculus
  - Why needed here: The core generative mechanism relies on E-prover's exhaustive inference; understanding what saturation guarantees (and doesn't) is essential.
  - Quick check question: Why does saturation not guarantee finding all logical consequences in practice?

- Concept: Directed Acyclic Graphs for Proof Representation
  - Why needed here: Tasks operate on proof DAGs; Reconstruction task specifically requires models to recover parent-child dependencies.
  - Quick check question: In a proof DAG, what does an edge from clause A to clause B represent?

## Architecture Onboarding

- Component map: TPTP Library (30K+ axioms across 50 domains) → E-prover (saturation engine, outputs derivation graph) → AGInTRater (interest scoring) → Task Generator (creates entailment/selection/reconstruction instances) → Vampire (ground-truth validation oracle)

- Critical path: Saturation timeout and AGInTRater threshold settings determine output quality; Vampire validation ensures 100% task correctness (up to its timeout). Start with small axiom subsets to validate pipeline before scaling.

- Design tradeoffs: CNF-only representation sacrifices natural language realism for guaranteed validity; Vampire validation adds computational overhead but eliminates label noise; single-pass saturation vs. iterative loops trades depth for simplicity.

- Failure signatures:
  - Saturation produces trivial clauses only → axiom set too weak or timeout too short
  - AGInTRater scores all clauses similarly → metrics not discriminative for domain
  - Vampire validation timeouts → generated entailment queries exceed prover capacity
  - Reconstruction task unsolvable → proof subgraph has non-binary inference steps

- First 3 experiments:
  1. Replicate saturation on single TPTP domain (e.g., SET) with 60-second timeout; inspect derivation graph statistics (nodes, edges, depth distribution).
  2. Generate 50 entailment tasks at depth d=2 with k=2 perturbations; manually verify 10 random instances against Vampire output.
  3. Evaluate gpt-5-nano on Reconstruction task at d=2; analyze error patterns (structural vs. logical failures using the paper's two-stage metric).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are symbolic reasoning skills acquired from CNF-based logical tasks transferable to natural language mathematical reasoning?
- Basis in paper: [explicit] "Our primary research direction is to use the datasets generated by our framework for fine-tuning Large Language Models. This will allow us to test a central hypothesis: are symbolic reasoning skills transferable to natural language?"
- Why unresolved: The paper only demonstrates diagnostic evaluation; no fine-tuning experiments have been conducted yet.
- What evidence would resolve it: Fine-tune LLMs on the generated symbolic tasks and evaluate on established natural language math benchmarks (e.g., GSM8K, MATH) with statistically significant improvements.

### Open Question 2
- Question: Would iterative saturation loops (feeding high-interest theorems back as axioms) generate tasks that remain challenging for advanced models?
- Basis in paper: [explicit] "To generate even more complex and diverse problems, we will implement an iterative saturation loop... this would allow us to explore the deductive closure of a theory more deeply."
- Why unresolved: Current implementation uses single-pass saturation only; iterative feedback remains unimplemented.
- What evidence would resolve it: Compare task difficulty distributions and model failure rates between single-pass and iterative saturation at equivalent computational budgets.

### Open Question 3
- Question: What architectural innovations beyond scale are required to enable hierarchical proof graph reconstruction?
- Basis in paper: [inferred] The paper finds that "model scale is a key factor, but it is not a panacea for structural reasoning" and that the Reconstruction task failure "stems from a core deficit in the architectural capabilities of current models for hierarchical, symbolic planning."
- Why unresolved: The paper diagnoses the weakness but does not propose or test architectural solutions.
- What evidence would resolve it: Design architectures with explicit hierarchical planning modules and measure improvements on the Reconstruction task at fixed parameter counts.

### Open Question 4
- Question: How does the AGInTRater heuristic correlate with human mathematicians' judgments of problem "interestingness"?
- Basis in paper: [inferred] "We emphasize that AGInTRater provides a heuristic score. We use it to prioritize non-trivial theorems in a principled way, without claiming alignment with human judgments of mathematical interest."
- Why unresolved: No human evaluation was conducted to validate the curation metric.
- What evidence would resolve it: Collect expert ratings on a sample of curated theorems and compute correlation coefficients with AGInTRater scores.

## Limitations

- Scalability unproven for larger axiom sets beyond small-scale experiments demonstrated
- AGInTRater filtering relies on heuristics that may not generalize across domains
- CNF representation may lose important mathematical structure relevant for reasoning

## Confidence

**High Confidence**: The saturation-based generation mechanism using E-prover is technically sound and produces mathematically valid theorems. The proof graph representation and three-task decomposition are well-defined and theoretically grounded.

**Medium Confidence**: The AGInTRater interest metrics will effectively filter for mathematically meaningful theorems across diverse TPTP domains. The difficulty parameterization (proof depth d and distractors k) will provide consistent and meaningful variation in task complexity.

**Low Confidence**: The CNF representation will adequately capture the mathematical reasoning required for LLM training. The observed performance degradation with proof depth reflects fundamental reasoning limitations rather than prompt-following artifacts or representation issues.

## Next Checks

1. **Saturation Scalability Test**: Run E-prover saturation on increasingly large TPTP domains (SET → TOP → ALG) with controlled timeouts, measuring clause generation rates and computational requirements to establish practical limits.

2. **AGInTRater Validation**: Manually evaluate 100 filtered theorems from different domains to verify that AGInTRater's complexity/surprisingness/usefulness scores correlate with human assessments of mathematical interest and utility.

3. **Task Format Transfer**: Generate parallel task instances in both CNF and natural language formats, then evaluate model performance on both versions to determine whether CNF representation creates artifacts that don't reflect true reasoning capabilities.