---
ver: rpa2
title: Multi-Objective Multi-Fidelity Bayesian Optimization with Causal Priors
arxiv_id: '2602.00788'
source_url: https://arxiv.org/abs/2602.00788
tags:
- uni00000013
- uni00000011
- causal
- uni00000014
- uni00000003
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents RESCUE, a multi-objective multi-fidelity Bayesian
  optimization method that integrates causal calculus to address poorly aligned lower-fidelity
  approximations. The core idea is to learn a structural causal model capturing causal
  relationships between inputs, fidelities, and objectives, then use it to construct
  a multi-fidelity causal GP surrogate that encodes intervention effects.
---

# Multi-Objective Multi-Fidelity Bayesian Optimization with Causal Priors

## Quick Facts
- arXiv ID: 2602.00788
- Source URL: https://arxiv.org/abs/2602.00788
- Reference count: 40
- Primary result: RESCUE improves sample efficiency over state-of-the-art methods on synthetic and real-world problems, with AUR gains of 130% over qEHVI, 225% over MOMF, and 77% over HVKG.

## Executive Summary
This paper presents RESCUE, a multi-objective multi-fidelity Bayesian optimization method that integrates causal calculus to address poorly aligned lower-fidelity approximations. The core idea is to learn a structural causal model capturing causal relationships between inputs, fidelities, and objectives, then use it to construct a multi-fidelity causal GP surrogate that encodes intervention effects. RESCUE introduces a causal hypervolume knowledge-gradient acquisition strategy to select input-fidelity pairs that balance expected multi-objective improvement and cost. Theoretical analysis shows RESCUE's cumulative hypervolume regret is bounded to its single-fidelity counterpart and remains finite even with arbitrarily unreliable auxiliary sources. Empirically, RESCUE improves sample efficiency over state-of-the-art methods on synthetic and real-world problems in robotics, AutoML, and healthcare.

## Method Summary
RESCUE combines causal discovery from observational data with multi-fidelity Bayesian optimization. The method learns a Causal Performance Model (CPM) representing causal relationships, uses it to construct a Multi-Fidelity Causal GP (MF-CGP) surrogate with interventional priors, and selects queries via a Causal Hypervolume Knowledge-Gradient (C-HVKG) acquisition function that balances expected hypervolume improvement against evaluation cost. The approach is theoretically grounded with regret bounds that remain finite even with unreliable auxiliary sources.

## Key Results
- RESCUE achieves 130% AUR gain over qEHVI, 225% over MOMF, and 77% over HVKG on benchmark problems
- Theoretical regret bound remains finite even with arbitrarily unreliable auxiliary sources
- Demonstrated effectiveness on synthetic problems and real-world applications in robotics, AutoML, and healthcare
- Sample efficiency improves significantly compared to state-of-the-art multi-fidelity methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating a structural causal model into the surrogate allows the optimizer to estimate true intervention effects, improving sample efficiency when low-fidelity sources are poorly aligned with the target.
- Mechanism: The Causal Performance Model (CPM) captures relationships between inputs, fidelities, and objectives via a directed acyclic graph and structural equations. The learned CPM parameterizes the prior mean and covariance of the multi-fidelity causal Gaussian Process (MF-CGP) surrogate. By encoding causal knowledge, the MF-CGP provides better-informed predictions for unexplored configurations, allowing C-HVKG to prioritize promising regions and avoid infeasible ones.
- Core assumption: The observational data contains sufficient information to recover the underlying causal structure, and the learned CPM provides a bounded approximation of the true intervention effect.
- Evidence anchors:
  - [abstract]: "RESCUE learns a structural causal model capturing causal relationships between inputs, fidelities, and objectives, and uses it to construct a probabilistic multi-fidelity (MF) surrogate that encodes intervention effects."
  - [section 4.1]: The MF-CGP is defined with prior mean μ(x) = f_do(x), using the interventional estimate f_do computed from the CPM.
  - [corpus]: Multi-Objective Causal Bayesian Optimization (arXiv:2502.14755) discusses exploiting causal relationships for sequential interventions, supporting the principle of causal exploitation.
- Break condition: Causal discovery produces a highly misspecified graph (e.g., many missing or reversed edges), making ξ (the causal prior error) large. In this regime, the prior misguides the GP, leading to slow convergence or entrapment in suboptimal regions.

### Mechanism 2
- Claim: A causal hypervolume knowledge-gradient acquisition function enables cost-effective, multi-objective optimization by balancing expected hypervolume improvement with evaluation cost, even with unreliable auxiliary sources.
- Mechanism: C-HVKG estimates the expected gain in hypervolume at the target fidelity per unit of evaluation cost. It combines two terms: HVGP from the MF-CGP posterior and HVCI from the CPM, weighted by a parameter w. By maximizing this quantity over both configuration and fidelity, the strategy selects queries that provide high expected information gain about the target objective while remaining within budget, and actively avoids infeasible regions.
- Core assumption: The hypervolume improvement is a meaningful proxy for progress toward the Pareto front, and the cost function accurately reflects the true expense of evaluations.
- Evidence anchors:
  - [abstract]: "...causal hypervolume knowledge-gradient acquisition strategy to select input–fidelity pairs that balance expected multi-objective improvement and cost."
  - [section 4.2]: Defines C-HVKG as A(x, s) = (1/c(x, s)) * E_D[max HV - current best], balancing cost and expected improvement.
  - [corpus]: A Constrained Multi-Fidelity Bayesian Optimization Method (arXiv:2510.10984) addresses similar challenges in constrained MFBO, implying this is a recognized problem.
- Break condition: The cost model is inaccurate or the relationship between cost and information gain is highly irregular. If low-cost sources provide negligible or misleading information, the acquisition will waste budget on uninformative queries.

### Mechanism 3
- Claim: Theoretical analysis provides a bound on cumulative hypervolume regret that remains finite even with arbitrarily unreliable auxiliary sources, ensuring robustness.
- Mechanism: The regret analysis (Theorem 5.9) decomposes the per-iteration hypervolume error into GP uncertainty and causal misspecification error (ξ). Crucially, the bound is proven to be independent of the cross-fidelity bias δ(x, s) because the causal prior at the target fidelity is learned from observational data via do-calculus, not by extrapolating from auxiliary sources. This guarantees that even if a simulator is completely misaligned with reality, the regret will not diverge.
- Core assumption: Assumption 5.4 ("Agnostic causal prior approximation") holds, meaning the true objective is uniformly ξ-close to an RKHS function used as the causal prior.
- Evidence anchors:
  - [abstract]: "Theoretical analysis shows RESCUE's cumulative hypervolume regret is bounded to its single-fidelity counterpart and remains finite even with arbitrarily unreliable auxiliary sources."
  - [section 5, Theorem 5.9 & Corollary 5.10]: Explicitly proves the regret bound and its independence from δ.
  - [corpus]: No direct corpus papers were found analyzing the specific regret bounds for causal MF-MOBO. This appears to be a novel contribution of RESCUE.
- Break condition: The theoretical assumptions (e.g., bounded RKHS norm, Lipschitz continuity) are violated by the true objective function, rendering the guarantee inapplicable.

## Foundational Learning

### Structural Causal Models (SCMs) & do-calculus
- Why needed here: Understanding how RESCUE represents causal mechanisms and computes interventional quantities (f_do) is essential. The paper uses a CPM, a specialized SCM, to model the system and applies do-calculus rules to estimate the effect of configuration changes.
- Quick check question: Given a simple graph X → Y ← Z, can you explain why observing X=x and intervening to set do(X=x) may lead to different probability distributions for Y?

### Gaussian Process (GP) Surrogates
- Why needed here: The MF-CGP is the predictive engine. Understanding GP priors, posteriors, and how they are updated with data is critical for comprehending how uncertainty is quantified and how the acquisition function is computed.
- Quick check question: In a standard GP, what is the relationship between the kernel function and the types of functions that can be well-approximated by the prior?

### Multi-Objective Optimization and Hypervolume
- Why needed here: The optimization goal is a Pareto front of solutions, not a single optimum. The hypervolume indicator is the key performance metric and the quantity the acquisition function seeks to improve.
- Quick check question: Why is a Pareto front necessary in multi-objective optimization, and what does an increase in hypervolume signify about the quality of an approximate Pareto set?

## Architecture Onboarding

### Component map
Observational Data (bD) -> Causal Performance Model (CPM) -> Multi-Fidelity Causal GP (MF-CGP) -> C-HVKG Acquisition Function -> Interventional Data (D)

### Critical path
1. Collect observational data and learn the CPM (once or periodically)
2. Initialize MF-CGP with a causal prior from the CPM
3. Loop: Compute C-HVKG, select query, evaluate, update MF-CGP, (periodically re-learn CPM)
4. Return final Pareto front

### Design tradeoffs
- CPM Update Frequency (Nl): Frequent updates improve accuracy but incur high cost from causal discovery
- Weighting Factor (w): Balances the influence of the GP posterior vs. the causal prior in the acquisition function. High w relies more on the causal model, which is good when data D is sparse but risky if the CPM is misspecified

### Failure signatures
- Poor Causal Discovery: If bD is small or non-representative, the learned DAG may be wrong, leading to a harmful prior and poor optimization performance
- Runtime Overhead: The need to compute C-HVKG with MC fantasies and perform causal inference makes RESCUE slower per iteration than baselines like qEHVI
- Constraint Violations: If the feasibility indicators g(x,s) are poorly modeled, the algorithm may select infeasible configurations

### First 3 experiments
1. Ablation on CPM Quality: Replace the learned CPM with a random or empty graph. Expect a significant drop in sample efficiency, demonstrating the value of the causal prior.
2. Sensitivity to Auxiliary Source Bias: Test on a synthetic problem where the bias δ(x, s) of the low-fidelity source is systematically increased. Show that RESCUE's performance degrades more gracefully than a standard MFBO baseline that relies on associational correlations.
3. Scalability Test: Run on a higher-dimensional problem (d > 50). Monitor the runtime of causal discovery and GP updates to identify computational bottlenecks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does incorporating configuration-dependent cost modeling affect RESCUE's performance and regret bounds compared to the current fidelity-only cost assumption?
- Basis in paper: [explicit] Page 8 states the current setup assumes all configurations incur the same cost for a fixed fidelity, "leaving configuration-dependent cost modeling to future work."
- Why unresolved: The current cost function $c(x, s) = \exp(4.8s)$ simplifies the optimization landscape but fails to capture scenarios where specific parameter settings (e.g., physics solver precision) drastically alter evaluation expenses.
- What evidence would resolve it: A theoretical extension of Theorem 5.9 including configuration-dependent costs, and empirical benchmarks using cost functions where $c(x, s)$ varies significantly with $x$.

### Open Question 2
- Question: Can the learned causal effect estimates be used to adaptively prune the configuration space to improve sample efficiency in high-dimensional problems?
- Basis in paper: [explicit] Page 8 suggests using causal effect estimates to "identify options with negligible causal effect on the performance objectives" to focus the search, noting this may further improve efficiency.
- Why unresolved: While the paper demonstrates superior performance, it does not implement active dimensionality reduction, which is critical as the dimensionality $d$ scales (e.g., the Robot Navigation problem has $d=26$).
- What evidence would resolve it: An ablation study comparing RESCUE against a variant that dynamically fixes or removes parameters identified as having low causal influence on the objectives.

### Open Question 3
- Question: What mechanisms can prevent the causal prior from causing ill-conditioned covariance matrices in the MF-CGP when the CPM is severely misspecified?
- Basis in paper: [inferred] Page 7 discusses the limitation that a "misspecified or overly confident" CPM can misguide the GP posterior and cause ill-conditioned covariance, requiring "additional regularization."
- Why unresolved: The paper assumes the approximation error $\xi$ is bounded (Assumption 5.4), but it does not provide a specific automated mechanism to detect or correct for the structural failure of the causal graph within the kernel calculation.
- What evidence would resolve it: Analysis of RESCUE's performance on synthetic problems where the causal graph is intentionally corrupted, paired with a sensitivity analysis on the required jitter/regularization terms.

## Limitations

- The performance gain is highly sensitive to the quality of causal discovery; poor observational data can lead to harmful priors
- The computational overhead from causal discovery and C-HVKG acquisition with MC fantasies is not fully characterized
- The method requires careful tuning of hyperparameters like the weighting factor w and the number of MC fantasy samples

## Confidence

- High Confidence: The core mechanism of using a learned causal model to parameterize a GP prior and the theoretical regret bound (Theorem 5.9) are well-defined and supported by the manuscript
- Medium Confidence: The empirical performance claims (AUR gains of 130% over qEHVI, etc.) are based on a range of benchmarks, but the paper does not fully explore the method's limitations or provide a detailed computational complexity analysis
- Low Confidence: The impact of the balance weight w and the number of MC fantasy samples on the C-HVKG acquisition function is not specified, making it difficult to assess the sensitivity of the method to these hyperparameters

## Next Checks

1. Ablation on CPM Quality: Replace the learned CPM with a random or empty graph and measure the degradation in sample efficiency. This would directly test the value of the causal prior.
2. Sensitivity to Auxiliary Source Bias: Systematically increase the bias δ(x, s) of the low-fidelity source in a synthetic problem and compare the robustness of RESCUE to a standard MFBO baseline.
3. Scalability Test: Run RESCUE on a higher-dimensional problem (d > 50) and monitor the runtime of causal discovery and GP updates to identify computational bottlenecks and assess the method's scalability.