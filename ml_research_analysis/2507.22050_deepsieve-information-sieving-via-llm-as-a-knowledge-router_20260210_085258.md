---
ver: rpa2
title: 'DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router'
arxiv_id: '2507.22050'
source_url: https://arxiv.org/abs/2507.22050
tags:
- deepsieve
- routing
- reasoning
- retrieval
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DeepSieve addresses the challenge of reasoning over heterogeneous
  knowledge sources by introducing an LLM-as-a-knowledge-router framework that performs
  multi-stage information sieving. The method decomposes complex queries into structured
  sub-questions, routes each to the most appropriate source via LLM-based decision-making,
  iteratively refines answers through reflexion, and fuses results into a coherent
  final response.
---

# DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router

## Quick Facts
- arXiv ID: 2507.22050
- Source URL: https://arxiv.org/abs/2507.22050
- Authors: Minghao Guo; Qingcheng Zeng; Xujiang Zhao; Yanchi Liu; Wenchao Yu; Mengnan Du; Haifeng Chen; Wei Cheng
- Reference count: 25
- Primary result: DeepSieve achieves avg F1 of 58.9 with DeepSeek-V3 and 51.2 with GPT-4o, outperforming pure RAG and agentic RAG baselines while using 3.9K tokens vs 37.9K+ for alternatives.

## Executive Summary
DeepSieve addresses the challenge of reasoning over heterogeneous knowledge sources by introducing an LLM-as-a-knowledge-router framework that performs multi-stage information sieving. The method decomposes complex queries into structured sub-questions, routes each to the most appropriate source via LLM-based decision-making, iteratively refines answers through reflexion, and fuses results into a coherent final response. Experiments on three multi-hop QA benchmarks demonstrate that DeepSieve achieves significantly better performance than both pure RAG baselines and agentic RAG methods while using substantially fewer tokens.

## Method Summary
DeepSieve implements a four-stage pipeline: (1) Decomposition, where an LLM planner breaks down complex queries into a directed acyclic graph (DAG) of atomic subquestions; (2) Routing, where an LLM-as-router selects the most appropriate tool-corpus pair for each subquestion based on semantic profiles and failure history; (3) Retrieval+Reflexion, where answers are retrieved and iteratively refined through a reflexion loop that detects insufficient answers and triggers re-routing with alternative sources; and (4) Fusion, where successful subanswers are synthesized into a final coherent response. The framework supports plug-and-play integration with diverse tools and sources, using DeepSeek-V3 or GPT-4o as the backbone LLM via OpenAI-compatible API with temperature=0.0, max_retries=3, timeout=60s, and exponential backoff.

## Key Results
- DeepSieve achieves avg F1 of 58.9 with DeepSeek-V3 and 51.2 with GPT-4o on multi-hop QA benchmarks
- Uses significantly fewer tokens (3.9K) compared to agentic RAG baselines (37.9K+)
- Maintains strong performance under simulated heterogeneous conditions where standard RAG fails due to context pollution

## Why This Works (Mechanism)

### Mechanism 1: Query-side Information Sieving via Structured Decomposition
- Breaking complex multi-hop queries into structured subquestions improves retrieval precision and reduces hallucination compared to atomic query retrieval
- Core assumption: Complex queries contain latent compositional structure that can be reliably extracted by LLMs
- Break condition: If queries are not compositional or the LLM fails to correctly identify dependencies, decomposition may produce irrelevant or unanswerable subquestions

### Mechanism 2: Source-side Information Sieving via LLM-as-a-Knowledge-Router
- Dynamically routing subquestions to the most appropriate (Tool, Corpus) pair based on semantic and metadata profiles improves retrieval relevance over flat, unified indices
- Core assumption: LLMs can accurately match subquestion semantics to source profiles and learn from failure histories
- Break condition: If source profiles are incomplete, ambiguous, or semantically overlapping, routing decisions may be suboptimal or incorrect

### Mechanism 3: Iterative Refinement via Reflexion and Re-routing
- A reflexion loop that detects insufficient answers and triggers re-routing with alternative sources improves final answer correctness without modifying the original subquestion
- Core assumption: The LLM can reliably assess answer sufficiency and that alternative sources exist for failed subquestions
- Break condition: If all relevant sources have been exhausted or the assessment of "unsatisfactory" is flawed, the loop may fail to converge or waste tokens

## Foundational Learning
- **Multi-hop Question Answering**: Why needed - DeepSieve's core value proposition is improving performance on multi-hop QA tasks, where answers require reasoning across multiple information sources. Quick check - Can you define a multi-hop question and explain why standard single-hop retrieval fails for it?
- **Retrieval-Augmented Generation (RAG)**: Why needed - DeepSieve is an "agentic RAG" framework. Understanding the basic RAG paradigm (retriever + generator) is essential to grasp what DeepSieve improves upon. Quick check - What are the two main components of a standard RAG system, and what is their primary limitation that DeepSieve addresses?
- **Agentic AI / LLM-as-a-Controller**: Why needed - DeepSieve uses an LLM not just for generation, but as a "router" or "controller" that makes decisions about which tools and sources to use. Quick check - How does using an LLM as a controller differ from using it only as a text generator?

## Architecture Onboarding
- **Component map**: Query -> Decomposer -> {Subquestions} -> (Router -> Retrieval Tool -> Reflexion -> Memory) [loop for each subquestion] -> Fusion Module -> Final Answer
- **Critical path**: Query enters Decomposer, produces DAG of subquestions, each subquestion goes through Router selection of (Tool, Corpus), Retrieval attempts, Reflexion evaluation with possible re-routing, successful results stored in Memory, finally Fusion module synthesizes final answer
- **Design tradeoffs**: Modularity vs. Complexity (highly modular design allows component swapping but increases orchestration complexity); Accuracy vs. Token Cost (reflexion loop adds cost but is used judiciously); Flexibility vs. Routing Complexity (supporting heterogeneous sources adds power but burdens LLM router's ability to interpret profiles)
- **Failure signatures**: Incorrect Decomposition (ambiguous or unanswerable subquestions lead to nonsensical answers); Routing Failure (LLM router consistently chooses wrong sources leading to irrelevant retrievals); Reflexion Loop Exhaustion (system gets stuck trying different sources without finding satisfactory answer)
- **First 3 experiments**: 1) Run End-to-End on HotpotQA subset to validate core claims; 2) Ablation of the Router by replacing with round-robin selector to quantify router's contribution; 3) Token Cost Profiling to identify cost bottlenecks and verify token efficiency claims

## Open Questions the Paper Calls Out
- **Can extending the router to support fine-grained, parameterized tool selection improve adaptive performance?**: The authors note current routing is coarse-grained and suggest extending action space to include tool-specific parameters for cost-aware decisions. Evidence needed: ablation showing configuration-specific outputs yield better cost-accuracy trade-offs.
- **How can personalized routing and memory modules be integrated to adapt DeepSieve to individual user access patterns?**: The paper highlights current system treats all subquestions uniformly and proposes personalized routing as future direction. Evidence needed: improved retrieval accuracy in multi-user setting where router learns user-specific source preferences.
- **Can the DeepSieve framework effectively adapt to dynamic, interactive environments where information retrieval must align with evolving states?**: The authors state they haven't explored applicability in dynamic scenarios like computer-use agents or digital twin simulations. Evidence needed: successful application in computer-use or game prototyping benchmark showing robustness to non-static query contexts.

## Limitations
- Heavy dependence on LLM performance for critical pipeline stages (decomposition, routing, reflexion) introduces brittleness that isn't fully characterized
- Simulated heterogeneous corpus experiments are compelling but methodology isn't detailed, making it difficult to assess realism of evaluation scenarios
- Limited evidence about performance in production environments with varying source quality, schema mismatches, and ambiguous metadata

## Confidence
- **High Confidence**: Empirical results showing DeepSieve outperforming pure RAG and agentic RAG baselines on three multi-hop QA benchmarks (F1 scores of 58.9 and 51.2; token efficiency claims of 3.9K vs 37.9K+ tokens)
- **Medium Confidence**: Mechanism claims about why DeepSieve works (structured decomposition and LLM-based routing as primary drivers), though ablation studies provide supporting but not isolating evidence
- **Low Confidence**: Generalization to truly diverse, real-world heterogeneous knowledge sources beyond simulated scenarios, as paper demonstrates effectiveness on academic benchmarks but provides limited production environment evidence

## Next Checks
1. **Router Performance Isolation**: Implement variant replacing LLM router with simple heuristic while keeping all other components identical, run on three benchmarks to quantify exact contribution of LLM routing mechanism
2. **Decomposition Quality Analysis**: Manually inspect 50 randomly selected decomposed queries from each benchmark to assess whether LLM consistently produces atomic, unambiguous subquestions, measure correlation between decomposition failures and final answer quality
3. **Heterogeneity Simulation Validation**: Reproduce exact methodology used to simulate heterogeneous corpus conditions, run standard RAG baseline and DeepSieve on both original and simulated datasets, measure retrieval precision at subquestion level to verify claimed "context pollution" effect