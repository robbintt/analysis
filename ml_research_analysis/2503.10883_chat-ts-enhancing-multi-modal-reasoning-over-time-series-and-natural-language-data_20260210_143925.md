---
ver: rpa2
title: 'Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language
  Data'
arxiv_id: '2503.10883'
source_url: https://arxiv.org/abs/2503.10883
tags:
- time-series
- data
- reasoning
- dataset
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Chat-TS, a large language model (LLM) framework
  for reasoning over time-series and natural language data. It integrates time-series
  tokens into LLMs' vocabulary to enhance reasoning across both modalities without
  compromising core language capabilities.
---

# Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language Data

## Quick Facts
- **arXiv ID:** 2503.10883
- **Source URL:** https://arxiv.org/abs/2503.10883
- **Reference count:** 40
- **Primary result:** State-of-the-art multimodal reasoning over time-series and natural language data

## Executive Summary
Chat-TS introduces a large language model framework that integrates time-series tokens directly into the LLM vocabulary, enabling unified reasoning across numerical sequences and natural language without sacrificing core language capabilities. The framework employs a discrete tokenizer to quantize time-series values into discrete tokens, which are then processed alongside natural language inputs. Through a two-stage training approach, Chat-TS achieves significant improvements in time-series reasoning while maintaining strong natural language proficiency, outperforming existing baselines by approximately 13% on the TS Instruct QA Gold Benchmark.

## Method Summary
Chat-TS uses a discrete tokenizer to map normalized time-series values into discrete tokens that are added to the LLM's vocabulary. The training follows a two-phase approach: Phase 1 involves TS-only pretraining with frozen transformer blocks (only embeddings and heads are tuned), while Phase 2 performs joint instruction tuning on a mixture of time-series and text data. The model is trained on the TS Instruct dataset (18,306 multimodal samples) combined with Open-Orca text data (100,000 samples), using Llama 3.1-8B as the base model. Training employs 4×A100 40GB GPUs with specific hyperparameters including batch size 4, gradient accumulation 16, and bf16 precision.

## Key Results
- Achieves state-of-the-art performance in multimodal reasoning tasks
- Improves time-series reasoning by approximately 13% on TS Instruct QA Gold Benchmark compared to existing baselines
- Maintains strong natural language proficiency with MMLU-Pro scores within ~2% of the base Llama-3.1-8B model
- Demonstrates effective preservation of instruction-following capabilities through mixed data training

## Why This Works (Mechanism)

### Mechanism 1: Discrete Tokenization for Unified Vocabulary
Mapping time-series values directly into the LLM's vocabulary allows native processing of numerical sequences as text. The discrete tokenizer quantizes normalized time-series values into K-1 bins, mapping them to discrete tokens added to the LLM's vocabulary. This approach achieves lower validation MSE compared to learned compression methods and enables the model to ingest numerical data without external adapters.

### Mechanism 2: Two-Stage Training for Capability Preservation
Decoupling time-series token alignment from instruction tuning mitigates catastrophic forgetting of natural language capabilities. Phase 1 pretrains on time-series tokens with frozen transformer blocks, while Phase 2 instruction-tunes on both text and time-series data. This approach maintains MMLU-Pro scores within ~2% of the base model, indicating preserved NLU.

### Mechanism 3: Interleaved Data Mixing for Instruction Adherence
Mixing general text instructions with time-series instructions during tuning is required to maintain output formatting and instruction-following abilities. Training on a combination of TS Instruct dataset and Open-Orca dataset prevents the model from overfitting to the rigid structure of synthetic TS conversations and ensures proper response formatting.

## Foundational Learning

- **Concept: Quantization Binning**
  - **Why needed here:** This is the core translation layer converting continuous time-series values into discrete tokens the LLM can process.
  - **Quick check question:** Given a normalized range of [-3, 3] and a codebook size of 8192, how would a value of 0.5 be mapped to a bin index?

- **Concept: Catastrophic Forgetting**
  - **Why needed here:** The primary risk in this architecture is improving time-series reasoning at the cost of losing the LLM's original text generation and logic capabilities.
  - **Quick check question:** Why does freezing the Transformer blocks during Phase 1 pre-training help preserve the model's existing knowledge?

- **Concept: Instruction Tuning**
  - **Why needed here:** The model must learn to associate visual/statistical patterns in the time-series with natural language reasoning (e.g., "The trend is upward").
  - **Quick check question:** What is the specific format of the "TS Instruct" dataset entries (e.g., User/Assistant pairs, image inputs)?

## Architecture Onboarding

- **Component map:** Tokenizer (maps TS → Integers) → Input Layer (Expanded Embedding Matrix) → Backbone (Standard Llama-3.1 Transformer) → Output (LM Head)
- **Critical path:** Data Prep: Normalize TS → Discretize to Tokens → Append to Text Prompt → Training: Phase 1 (Embeddings only) → Phase 2 (Full Model with mixed data) → Inference: Prompt + Tokenized TS → Autoregressive generation
- **Design tradeoffs:** Simple discrete bins vs. Learned VQ-VAE (paper chooses bins for OOD robustness and reconstruction accuracy); Mean initialization vs. Pre-training (pre-training yields better alignment but adds pipeline step); Context Window (tokenized TS consumes tokens rapidly, limiting series length)
- **Failure signatures:** Normalization Hallucination (model fabricates specific real-world values because it only sees normalized data); Instruction Drift (model ignores formatting constraints if trained on TS data without interleaved text data)
- **First 3 experiments:** 1) Tokenizer Validation: Reconstruct hold-out set of time-series to measure MSE against ground truth; 2) Ablation Run: Train "TS-Only" variant (no OpenOrca data) and verify if it fails to follow multiple-choice formatting; 3) Regression Test: Evaluate fine-tuned Chat-TS on MMLU-Pro to confirm performance hasn't dropped >2% relative to base Llama-3.1

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the Chat-TS framework be adapted to enable reliable time-series generation and forecasting?
- **Basis in paper:** The authors state in the Limitations section that "Accurate time-series generation has yet to be achieved, as our models struggle to reliably forecast time-series data."
- **Why unresolved:** The current model architecture and training objectives prioritize reasoning over static input data rather than autoregressive generation of future numerical values.
- **What evidence would resolve it:** Successful application of the model to standard time-series forecasting benchmarks, demonstrating prediction accuracy comparable to specialized forecasting models.

### Open Question 2
- **Question:** What training modifications are required to improve zero-shot time-series classification performance?
- **Basis in paper:** The paper notes "Time-series classification is another area requiring improvement" and suggests that "designing classification datasets which focus on few-shot learning examples may help the model."
- **Why unresolved:** The current training data consists of simple conversational samples, causing the model to "guess or repeat class predictions" when faced with zero-shot classification tasks.
- **What evidence would resolve it:** Ablation studies showing that fine-tuning on a few-shot classification dataset significantly increases accuracy on unseen classification benchmarks compared to the baseline.

### Open Question 3
- **Question:** How does scaling model parameters beyond 8 billion and increasing data volume affect multimodal reasoning performance?
- **Basis in paper:** The authors acknowledge that "Scaling up this framework both in terms of data volume and model size would almost certainly lead to improved performance," though they limited experiments to Llama-3.1-8B.
- **Why unresolved:** The study prioritized accessibility and compute efficiency, leaving the potential gains from larger models (e.g., 70B parameters) unverified.
- **What evidence would resolve it:** A comparative analysis evaluating larger Chat-TS variants on the TS Instruct QA Gold Benchmark to establish scaling laws for this specific multimodal task.

## Limitations

- **Context Window Constraints:** The discrete tokenization approach maps each time-series value to a single token, consuming significant context window space and limiting series length to sub-1000 points.
- **Normalization Dependency:** The tokenizer operates on normalized time-series values (±3σ range), preventing accurate real-world numerical predictions without additional calibration.
- **Data Generation Transparency:** The TS Instruct Training Dataset generation process involves configurable sliding window parameters that are not fully specified, creating uncertainty about reproducibility.

## Confidence

**High Confidence Claims:**
- The two-stage training approach effectively preserves natural language capabilities while improving time-series reasoning
- The discrete tokenizer with K=8192 bins achieves lower reconstruction error than learned quantization methods for short time-series
- Including Open-Orca data during instruction tuning is necessary to maintain proper instruction-following behavior

**Medium Confidence Claims:**
- Chat-TS achieves state-of-the-art performance on multimodal reasoning tasks
- The 13% improvement over baselines on TS Instruct QA Gold Benchmark is meaningful
- The model can reason about time-series trends and patterns effectively

**Low Confidence Claims:**
- Performance on real-world time-series data beyond the evaluation benchmarks
- Scalability to time-series longer than 1000 points
- Generalizability across diverse time-series domains (finance, healthcare, industrial) beyond synthetic generation

## Next Checks

1. **Context Window Stress Test:** Evaluate Chat-TS performance on time-series sequences of increasing length (500, 1000, 2000, 4000 points) to identify the point at which performance degrades significantly.

2. **Real-World Domain Transfer:** Test Chat-TS on naturally occurring time-series datasets from different domains (e.g., financial stock data, medical vital signs, industrial sensor data) to assess generalization beyond synthetic data.

3. **Numerical Precision Calibration:** Implement and evaluate a calibration layer that maps normalized predictions back to real-world values, then measure prediction accuracy on datasets with known ground truth values.