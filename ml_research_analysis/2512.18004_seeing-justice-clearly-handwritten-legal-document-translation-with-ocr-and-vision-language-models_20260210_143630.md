---
ver: rpa2
title: 'Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and
  Vision-Language Models'
arxiv_id: '2512.18004'
source_url: https://arxiv.org/abs/2512.18004
tags:
- legal
- handwritten
- translation
- text
- marathi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper compares two approaches\u2014OCR-MT pipelines and Vision\
  \ Large Language Models (vLLMs)\u2014for translating handwritten Marathi legal documents\
  \ into English. OCR-MT pipelines combine tools like Tesseract, EasyOCR, and PaddleOCR\
  \ with translation models (IndicTrans2, Sarvam-1) to extract and translate text,\
  \ while vLLMs (Chitrarth, Maya-8B, Ovis2) perform direct image-to-text translation."
---

# Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models

## Quick Facts
- **arXiv ID**: 2512.18004
- **Source URL**: https://arxiv.org/abs/2512.18004
- **Reference count**: 7
- **Primary result**: OCR-MT pipelines achieved lower CER/WER on printed text but struggled with handwritten content, leading to cascading translation errors, while vLLMs showed potential but often hallucinated content in legal translations.

## Executive Summary
This paper compares OCR-MT pipelines and vision-language models (vLLMs) for translating handwritten Marathi legal documents into English. OCR-MT approaches combined tools like Tesseract, EasyOCR, and PaddleOCR with translation models (IndicTrans2, Sarvam-1), while vLLMs (Chitrarth, Maya-8B, Ovis2) performed direct image-to-text translation. The study found that OCR-MT achieved better accuracy on printed text but suffered from cascading errors when processing handwriting, while vLLMs showed promise but frequently hallucinated content. Human evaluation revealed that vLLM outputs were less reliable for precise legal translation, highlighting the need for hybrid approaches and better fine-tuning strategies.

## Method Summary
The study evaluated six OCR-MT pipelines combining three OCR tools (Tesseract, EasyOCR, PaddleOCR) with two translation models (IndicTrans2, Sarvam-1) on ~60 scanned Marathi legal documents. OCR fidelity was measured using CER and WER, and translation quality was assessed through human evaluation on fluency, adequacy, and correctness. vLLMs (Chitrarth, Maya-8B, Ovis2-16B/34B) were tested in zero-shot mode with manually designed prompts for legal document translation. The methodology compared modular OCR-MT approaches against end-to-end vLLM translation, with human annotators rating outputs across three quality dimensions.

## Key Results
- OCR-MT pipelines achieved lower CER/WER on printed text but struggled significantly with handwritten content, causing cascading translation errors
- vLLMs showed potential for multimodal reasoning but frequently hallucinated content (invented names, dates, meeting narratives) instead of accurate legal translation
- Human evaluation revealed vLLM outputs were less reliable for precise legal translation compared to OCR-MT approaches, despite OCR-MT's cascading error issues

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: OCR-MT pipelines exhibit cascading errors where misrecognized characters propagate into degraded translations.
- **Mechanism**: OCR systems extract text from handwritten images with variable accuracy. When OCR misrecognizes characters in handwriting, the translation model receives corrupted input and produces incorrect output (e.g., "Gaav" transliterated instead of "Village").
- **Core assumption**: Translation quality is bounded by OCR fidelity; downstream MT cannot recover from upstream recognition errors.
- **Evidence anchors**: Abstract states OCR-MT "struggled with handwritten content, leading to cascading translation errors"; results show "OCR errors significantly affected translation quality" and "error propagation across pipeline stages."
- **Break condition**: If OCR accuracy on handwriting approaches printed-text levels (>95% character accuracy), cascading effects diminish substantially.

### Mechanism 2
- **Claim**: vLLMs can bypass OCR entirely by jointly processing visual and linguistic modalities in a single forward pass.
- **Mechanism**: Vision-language models encode document images through vision encoders, align visual embeddings with language model representations, and generate translations directly without intermediate text extraction.
- **Core assumption**: Joint multimodal reasoning enables the model to leverage visual context (layout, stamps, structure) to inform translation decisions.
- **Evidence anchors**: Abstract notes vLLMs "perform direct image-to-text translation"; introduction states vLLMs "can jointly process image and text inputs, reducing dependency on rigid pipeline stages."
- **Break condition**: If vision-language alignment is weak or training data lacks handwritten legal documents, the model defaults to generic visual descriptions rather than faithful transcription.

### Mechanism 3
- **Claim**: vLLM translation quality is highly sensitive to prompt design, with insufficient instructions leading to hallucination or misaligned outputs.
- **Mechanism**: Zero-shot vLLMs generate outputs based on prompt context. Without explicit instructions for legal document translation, models may interpret images as generic scenes rather than legal records.
- **Core assumption**: Prompt engineering can partially compensate for lack of domain-specific fine-tuning.
- **Evidence anchors**: Results show "prompt engineering was critical: results improved significantly with detailed instructions"; qualitative comparison reveals Chitrarth produced "hallucinated summary about a meeting, with invented names, dates, and locations."
- **Break condition**: Even optimal prompts cannot overcome fundamental model limitations in recognizing specific handwriting styles without fine-tuning.

## Foundational Learning

- **Concept**: Character Error Rate (CER) and Word Error Rate (WER)
  - **Why needed here**: These are the primary metrics for evaluating OCR fidelity before translation. Understanding edit-distance-based metrics is essential to diagnose whether errors originate in recognition or translation stages.
  - **Quick check question**: If a document has CER=5% on printed text but CER=25% on handwriting, what does this suggest about downstream translation quality?

- **Concept**: Cascading Error Propagation in Modular Pipelines
  - **Why needed here**: The paper's central finding is that OCR errors compound in translation. Understanding error propagation helps diagnose whether to improve OCR, switch to vLLMs, or pursue hybrid approaches.
  - **Quick check question**: In a two-stage pipeline where Stage 1 accuracy is 80% and Stage 2 accuracy is 90% on clean input, what is the approximate end-to-end accuracy?

- **Concept**: Zero-Shot Multimodal Reasoning
  - **Why needed here**: vLLMs in this study operate in zero-shot mode—no task-specific training. Understanding zero-shot capabilities and limitations sets realistic expectations for deployment without fine-tuning.
  - **Quick check question**: Why might a zero-shot vLLM describe a legal document as a "study guide" instead of translating it?

## Architecture Onboarding

- **Component map**: Image input → [OCR extraction OR vLLM encoding] → [MT translation OR vLLM generation] → English output → Human evaluation

- **Critical path**: Document image flows through either OCR extraction or vLLM encoding, then to either MT translation or direct vLLM generation, producing English translation for human evaluation.

- **Design tradeoffs**:
  - OCR-MT: Modular, transparent, debuggable; suffers cascading errors; better for printed text
  - vLLM: Unified, bypasses OCR errors; prone to hallucination; requires prompt engineering; zero-shot lacks legal precision
  - Hybrid (proposed): OCR for structural cues + vLLM for contextual translation—untested but suggested

- **Failure signatures**:
  - OCR-MT: Transliteration instead of translation ("Gaav" → "Gaon" not "Village"); dropped content; mixed-language output with trailing untranslated fragments
  - vLLM: Hallucinated content (invented names, dates, meeting narratives); generic descriptions instead of verbatim translation; partial extraction with fabricated details

- **First 3 experiments**:
  1. **Baseline OCR comparison**: Run Tesseract, EasyOCR, and PaddleOCR on the same handwritten document subset; measure CER/WER to identify best OCR before MT integration.
  2. **Prompt sensitivity test**: Evaluate Ovis2-16B with three prompt variations (minimal, domain-specified, detailed legal instructions) on 5 documents; compare hallucination rates and translation fidelity.
  3. **Hybrid feasibility probe**: Extract text with EasyOCR, then feed both the OCR output and the original image to Ovis2-16B with a prompt instructing it to correct OCR errors using visual context; assess whether this reduces cascading errors.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can hybrid OCR-vLLM architectures that combine OCR-derived structural cues with vLLM contextual reasoning achieve higher translation fidelity than either approach alone for handwritten legal documents?
- **Basis in paper**: Authors state: "Hybrid OCR–vLLM Pipelines: Combining OCR for structural cues with vLLMs for contextual translation may yield better accuracy than either approach alone."
- **Why unresolved**: The paper evaluated OCR-MT and vLLM approaches separately but did not test combined architectures; error propagation in OCR-MT and hallucination in vLLMs both remain unsolved.
- **What evidence would resolve it**: Ablation studies comparing standalone OCR-MT, standalone vLLM, and hybrid pipelines on the same legal document benchmark, measuring CER, WER, and human-rated translation adequacy.

### Open Question 2
- **Question**: What domain-specific fine-tuning strategies most effectively reduce hallucination rates in vLLMs while preserving legal terminology accuracy?
- **Basis in paper**: Authors note vLLMs "often hallucinated content or failed to accurately extract legal details" and explicitly call for "fine-tuning on larger annotated datasets of handwritten legal documents."
- **Why unresolved**: Zero-shot vLLM evaluation showed severe hallucination (e.g., Chitrarth invented meeting details); the paper did not test fine-tuned models.
- **What evidence would resolve it**: Comparative evaluation of vLLMs fine-tuned on handwritten legal corpora versus zero-shot baselines, with quantitative hallucination metrics and legal terminology accuracy scores.

### Open Question 3
- **Question**: Which evaluation metrics best capture factual consistency, terminology preservation, and completeness for legal document translation beyond standard CER/WER?
- **Basis in paper**: Authors state: "We will develop evaluation metrics tailored to legal translation, focusing on factual consistency, terminology preservation, and completeness."
- **Why unresolved**: Human evaluation relied on subjective fluency/adequacy/correctness criteria; existing metrics (CER, WER) do not penalize hallucinations or missing legal clauses appropriately.
- **What evidence would resolve it**: Correlation analysis between proposed legal-specific metrics and expert human judgments on a held-out test set of translated legal documents.

## Limitations

- The study relies on qualitative human evaluation rather than systematic quantitative hallucination detection metrics, making it difficult to distinguish legitimate translation variations from hallucinated content.
- Zero-shot vLLM evaluation may underrepresent their potential—the paper did not explore fine-tuning on legal document datasets that could substantially improve performance.
- The proposed hybrid approach (OCR for structure + vLLM for context) remains untested, leaving open whether it can effectively address both cascading errors and hallucination issues.

## Confidence

- **High confidence**: OCR-MT cascading error mechanism and printed text performance (CER/WER metrics are objective and directly measured)
- **Medium confidence**: vLLM hallucination patterns and prompt engineering importance (based on human evaluation but lacks systematic hallucination quantification)
- **Low confidence**: Claims about vLLMs being "promising" for legal translation (results show inconsistency and hallucination issues outweigh benefits)

## Next Checks

1. Implement systematic hallucination detection metrics to quantify fabricated content in vLLM outputs versus legitimate translation variations
2. Test the proposed hybrid approach (OCR for structure + vLLM for context) to determine if it reduces cascading errors while maintaining translation accuracy
3. Evaluate vLLM performance after fine-tuning on a small legal document dataset to assess whether zero-shot limitations are fundamental or addressable through training