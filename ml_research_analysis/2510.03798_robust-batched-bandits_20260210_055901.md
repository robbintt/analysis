---
ver: rpa2
title: Robust Batched Bandits
arxiv_id: '2510.03798'
source_url: https://arxiv.org/abs/2510.03798
tags:
- regret
- logt
- should
- where
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies batched multi-armed bandit problems with heavy-tailed
  reward distributions, bridging a critical gap between batched bandit theory and
  real-world applications where outcomes exhibit heavy-tailed characteristics. The
  authors develop robust batched bandit algorithms that can handle heavy-tailed rewards
  in both finite-arm and Lipschitz settings.
---

# Robust Batched Bandits

## Quick Facts
- arXiv ID: 2510.03798
- Source URL: https://arxiv.org/abs/2510.03798
- Reference count: 40
- Primary result: This paper studies batched multi-armed bandit problems with heavy-tailed reward distributions, bridging a critical gap between batched bandit theory and real-world applications where outcomes exhibit heavy-tailed characteristics.

## Executive Summary
This paper addresses batched multi-armed bandit problems with heavy-tailed reward distributions, where traditional algorithms relying on sub-Gaussian assumptions fail. The authors develop robust algorithms using Median-of-Means estimators that can handle heavy-tailed rewards in both finite-arm and Lipschitz settings. A key finding is that heavier-tailed rewards require fewer communication batches to achieve near-optimal regret in instance-independent and Lipschitz settings, which is somewhat counterintuitive since heavier tails produce noisier samples.

## Method Summary
The paper develops batched bandit algorithms that handle heavy-tailed rewards by using robust mean estimators (Median-of-Means) instead of empirical means. For finite-arm settings, they propose Batched Successive Elimination with Heavy-tails (BaSE-H) using communication grids tied to the heavy-tail parameter ε. For Lipschitz settings, they develop a batched version of the Lipschitz Bandit algorithm (BLiN). The key innovation is explicitly tying communication time points to the heavy-tail parameter ε, allowing the algorithms to maintain theoretical guarantees even when rewards have infinite variance but finite (1+ε)-th moments.

## Key Results
- Heavier-tailed rewards require fewer communication batches to achieve near-optimal regret in instance-independent and Lipschitz settings
- The optimal communication pattern in instance-dependent settings does not depend on tail heaviness
- The paper provides upper and lower bounds on regret and establishes minimum batch requirements for near-optimal performance
- Theoretical analysis shows the optimal communication schedule depends on the interplay between reward tail heaviness and learning setting

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Theoretically, using robust mean estimators allows the algorithm to maintain concentration bounds even when rewards have infinite variance, provided the $(1+\epsilon)$-th moment is bounded.
- **Mechanism:** The algorithm employs the **Median-of-Means (MoM)** estimator rather than the empirical mean. It partitions samples into groups, computes the mean of each group, and takes the median of these means. This structure limits the influence of extreme outliers that would otherwise dominate a simple average.
- **Core assumption:** Rewards are i.i.d. with a finite $(1+\epsilon)$-th moment ($\mathbb{E}[|\nu_x - \mu_x|^{1+\epsilon}] \leq v$) for some $\epsilon \in (0, 1]$.
- **Evidence anchors:** [Section 3.1] Defines the robust mean estimator and Lemma 1 derived from [11]. [Section 4] Algorithm 1 explicitly calculates $\hat{\mu}_i$ using the robust estimator logic. [corpus] "Catoni-Style Change Point Detection... Heavy-Tailed Bandits" confirms the general necessity of specialized estimators for heavy-tailed regret minimization.

### Mechanism 2
- **Claim:** In the instance-independent setting, the optimal communication schedule depends on tail heaviness; specifically, heavier tails (lower $\epsilon$) necessitate fewer communication batches.
- **Mechanism:** Theoretical analysis suggests that heavier tails impose a fundamental limit on information gain per sample. The paper proposes that increasing batch frequency (adaptivity) cannot overcome this "informational deficit" caused by noise. Therefore, the optimal strategy shifts toward longer aggregation periods (fewer batches) rather than frequent policy updates.
- **Core assumption:** The setting is instance-independent (min-max regret) or Lipschitz.
- **Evidence anchors:** [Section 1] Introduction explicitly calls this "counterintuitive" and details the relationship. [Corollary 1] Derives the minimum number of batches scaling with $\log^{-1}\left(\frac{1+\epsilon}{\epsilon}\right) \log \log T$. [corpus] Corpus neighbors generally focus on optimal batch sizes for standard settings; this specific tail-dependent batch reduction appears unique to this paper.

### Mechanism 3
- **Claim:** Batched Successive Elimination (BaSE) achieves near-optimal regret by decoupling exploration within batches from elimination at batch boundaries.
- **Mechanism:** During a batch, the agent plays all active arms uniformly (round-robin). At the end of a batch (communication time $t_m$), the algorithm calculates a "robust" confidence width. Arms whose estimated mean falls significantly below the best estimated arm are eliminated.
- **Core assumption:** The user can define specific communication grids $\mathcal{T}_1$ (instance-independent) or $\mathcal{T}_2$ (instance-dependent) prior to running the full horizon.
- **Evidence anchors:** [Algorithm 1] Details the "Uniform Play" and "Adaptive Elimination" steps. [Section 4.1] Defines the explicit time grids $t_m$ dependent on the heavy-tail parameter $\epsilon$. [corpus] "Batched Nonparametric Bandits" mentions similar uniform sampling strategies in batched contexts.

## Foundational Learning

- **Concept: Moment bounds ($1+\epsilon$)**
  - **Why needed here:** Unlike sub-Gaussian assumptions used in standard bandits, this paper assumes only that the $(1+\epsilon)$-th moment exists. You must understand that as $\epsilon \to 0$, the distribution becomes heavier-tailed (approaching infinite variance), necessitating the robust estimator.
  - **Quick check question:** If a distribution has finite variance, does it satisfy the condition for $\epsilon=1$? (Yes).

- **Concept: Communication Grids (Batching)**
  - **Why needed here:** The policy is not updated every step. The algorithm requires a pre-defined or adaptive schedule of time points $\{t_0, t_1, \dots, t_M\}$ where data is revealed and policy updates occur.
  - **Quick check question:** Can the policy change its action at step $t=5$ if the previous batch end was $t_1=4$ and the next is $t_2=10$? (No, the policy is fixed between batches).

- **Concept: Instance-Dependent vs. Instance-Independent Regret**
  - **Why needed here:** The paper reveals a sharp divergence: the "fewer batches for heavier tails" rule applies to instance-independent/minimax settings, but **not** to instance-dependent settings (where batch count is invariant to tail heaviness).
  - **Quick check question:** Does the optimal number of batches decrease with heavier tails if you are optimizing for a specific problem instance with large sub-optimality gaps? (No, according to Section 1 and Table 1).

## Architecture Onboarding

- **Component map:**
  - **Input:** Arm set $X$, Horizon $T$, Batch count $M$, Tail parameters $(\epsilon, v)$.
  - **Scheduler:** Defines grid $\mathcal{T}$ (Eq. 1 or 2).
  - **Estimator:** Median-of-Means module (processes batch data).
  - **Eliminator:** Compares $\hat{\mu}_{max} - \hat{\mu}_i$ against threshold $C \cdot v^{\frac{1}{1+\epsilon}} (\frac{\log}{\tau})^{\frac{\epsilon}{1+\epsilon}}$.

- **Critical path:**
  1. Initialize active arms $A$.
  2. **Batch Loop:** Play arms in $A$ uniformly for duration $t_m - t_{m-1}$.
  3. **Estimation:** Compute robust means $\hat{\mu}_i$ for all active arms using MoM.
  4. **Elimination:** Remove arms failing the confidence check.
  5. Repeat until $T$ is exhausted.

- **Design tradeoffs:**
  - **Grid Selection:** You must choose between $\mathcal{T}_1$ (optimized for worst-case/instance-independent) and $\mathcal{T}_2$ (optimized for instance-dependent). The paper suggests $\mathcal{T}_1$ yields the counterintuitive "fewer batches" benefit for heavy tails.
  - **Sensitivity:** The threshold in Algorithm 1 depends on $v$ (the moment bound). If $v$ is misspecified, theoretical guarantees may break.

- **Failure signatures:**
  - **Divergence:** If rewards do not possess the $(1+\epsilon)$-th moment (e.g., tails are heavier than assumed), the Median-of-Means estimator will fail to concentrate, leading to random eliminations.
  - **Stagnation:** If the confidence radius is too conservative (overestimating $v$), the algorithm may never eliminate suboptimal arms.

- **First 3 experiments:**
  1. **Sanity Check (Finite Arm):** Implement Algorithm 1 with synthetic heavy-tailed data (e.g., Pareto distributions) and verify that the robust estimator outperforms the empirical mean.
  2. **Batch Ablation:** Run the algorithm with $M=5$ vs $M=20$ batches on heavy-tailed data ($\epsilon=0.5$) to validate the claim that fewer batches suffice for near-optimal regret in the instance-independent setting.
  3. **Lipschitz Stress Test:** Implement Algorithm 2 (BLiN) on a $[0,1]^d$ grid with heavy-tailed noise to observe if the "zooming dimension" logic holds under batch constraints.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed algorithms (BaSE-H and BLiN) perform empirically on real-world datasets with heavy-tailed characteristics?
- Basis in paper: [explicit] The authors state in Section 7: "Empirical analysis is absent in this version; evaluating the proposed methods through empirical studies would strengthen the findings."
- Why unresolved: The paper focuses exclusively on theoretical proofs of upper and lower bounds without providing simulation or experimental validation.
- What evidence would resolve it: Experimental results on datasets (e.g., clinical trials or financial data) showing regret curves and batch allocation behavior compared to standard sub-Gaussian algorithms.

### Open Question 2
- Question: Can the logarithmic gaps between the regret upper and lower bounds in both finite-arm and Lipschitz settings be closed?
- Basis in paper: [explicit] The authors note in Section 7: "There remain logarithmic gaps between the upper and lower bounds, which warrant further exploration."
- Why unresolved: Current proof techniques for upper bounds introduce logarithmic factors that are not present or different in the lower bound constructions.
- What evidence would resolve it: A refined analysis or novel algorithm that achieves a regret upper bound matching the lower bound up to constant factors, specifically addressing the $\log T$ or $\log \log T$ dependencies.

### Open Question 3
- Question: Do the relationships between tail heaviness and batch complexity hold for the linear bandit setting?
- Basis in paper: [inferred] The paper solves finite-arm and Lipschitz settings, but cites heavy-tailed *linear* bandits [39] and batched *linear* bandits [21] as separate fields.
- Why unresolved: The interaction between the heavy-tail parameter $\varepsilon$, the dimension $d$ (in linear settings), and the batch schedule is unexplored.
- What evidence would resolve it: Theoretical derivation of regret bounds for batched heavy-tailed linear bandits to determine if fewer batches are still optimal for heavier tails in high-dimensional spaces.

## Limitations

- **Theoretical Constant Dependencies:** The confidence constants $c$ in the elimination threshold and $C$ in the minimum batch count (Corollary 1) are not explicitly provided, affecting practical implementability.
- **Empirical Validation Gap:** The paper provides only theoretical analysis without experimental results, leaving theoretical bounds unverified against synthetic or real heavy-tailed data.
- **Moment Bound Sensitivity:** The algorithms depend critically on correctly knowing the moment bound $v$, with no guidance on robust estimation or sensitivity analysis provided.

## Confidence

**High Confidence:** The theoretical framework connecting robust mean estimation (MoM) to heavy-tailed regret bounds is well-established in the literature. The mechanisms for how heavier tails affect communication schedules in instance-independent settings appear technically sound based on the mathematical derivation.

**Medium Confidence:** The claim that fewer batches suffice for heavier tails in instance-independent settings is theoretically derived but lacks empirical verification. The intuition about information gain limits is compelling but needs experimental validation.

**Low Confidence:** The practical implementability of the algorithms is uncertain due to unspecified constants and lack of hyperparameter guidance. The transition from theoretical bounds to practical performance remains an open question.

## Next Checks

1. Implement Algorithm 1 with Pareto-distributed rewards (varying $\epsilon$) and verify that robust MoM estimation outperforms standard empirical mean estimation in terms of cumulative regret.

2. Run controlled experiments comparing $M=5$ vs $M=20$ batches on heavy-tailed data ($\epsilon=0.5$) to empirically validate the "fewer batches for heavier tails" claim in instance-independent settings.

3. Test Algorithm 2 (BLiN) on a $[0,1]^d$ grid with heavy-tailed noise, measuring whether the zooming dimension framework maintains performance under batch constraints compared to standard Lipschitz bandits.