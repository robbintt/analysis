---
ver: rpa2
title: Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge
arxiv_id: '2509.03256'
source_url: https://arxiv.org/abs/2509.03256
tags:
- training
- loss
- each
- speech
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work addressed automatic word-level pronunciation assessment
  for children learning Norwegian as a second language. Three end-to-end architectures
  were evaluated: an encoder-decoder Siamese model (E2E-R), a prefix-tuned wav2vec2.0-based
  direct classification model, and a novel GOP-CTC-based model integrating alignment-free
  goodness-of-pronunciation features computed via CTC.'
---

# Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge

## Quick Facts
- arXiv ID: 2509.03256
- Source URL: https://arxiv.org/abs/2509.03256
- Reference count: 0
- Three end-to-end architectures evaluated for automatic word-level pronunciation assessment of children learning Norwegian as L2

## Executive Summary
This paper addresses automatic word-level pronunciation assessment for children learning Norwegian as a second language, presenting three end-to-end architectures for the NOCASA 2025 challenge. The models include an encoder-decoder Siamese architecture, a prefix-tuned wav2vec2.0-based direct classification model, and a novel GOP-CTC-based model that integrates alignment-free goodness-of-pronunciation features computed via CTC. A weighted ordinal cross-entropy loss function is introduced to balance performance across different evaluation metrics. The GOP-CTC-based model achieved the highest performance on the challenge leaderboard, substantially surpassing baseline systems with strong results across multiple evaluation metrics.

## Method Summary
The study evaluates three distinct end-to-end architectures for pronunciation assessment. The first is an encoder-decoder Siamese model (E2E-R) that directly predicts pronunciation scores. The second employs prefix-tuning on a pre-trained wav2vec2.0 model for direct classification. The third, novel approach integrates GOP features computed via CTC alignment-free scoring into the model architecture. All models are trained using a weighted ordinal cross-entropy loss to optimize for both unweighted average recall and mean absolute error simultaneously. The models are evaluated on a dataset of Norwegian L2 children's speech, with performance measured across standard pronunciation assessment metrics.

## Key Results
- GOP-CTC-based model achieved highest performance with UAR of 44.8%, F1 of 47.4%, and MAE of 0.505
- Substantial improvement over challenge baselines across all evaluation metrics
- Novel integration of CTC-based GOP features proved effective for pronunciation assessment
- Weighted ordinal cross-entropy loss successfully balanced competing evaluation objectives

## Why This Works (Mechanism)
The effectiveness of the proposed approach stems from integrating alignment-free goodness-of-pronunciation features computed via CTC decoding into the model architecture. This allows the model to leverage explicit pronunciation quality signals without requiring explicit phoneme alignments, which are challenging to obtain for child speech and L2 learners. The weighted ordinal cross-entropy loss function enables the model to optimize for multiple evaluation metrics simultaneously, addressing the inherent trade-offs between classification accuracy and regression error. The CTC-based GOP computation provides robust pronunciation quality estimates that complement the learned representations from the encoder.

## Foundational Learning
- **CTC (Connectionist Temporal Classification)**: Needed for computing alignment-free GOP features without requiring explicit phoneme alignments; quick check: verify CTC decoding produces meaningful pronunciation quality scores
- **Goodness of Pronunciation (GOP)**: Measures pronunciation quality by comparing acoustic likelihoods; quick check: ensure GOP scores correlate with human judgments of pronunciation quality
- **Ordinal Cross-Entropy**: Appropriate loss for ordinal regression tasks with discrete score levels; quick check: verify proper handling of ordinal relationships between score classes
- **Prefix-tuning**: Parameter-efficient fine-tuning method for pre-trained models; quick check: confirm prefix parameters effectively adapt wav2vec2.0 to pronunciation assessment task
- **Siamese Architecture**: Enables direct comparison between reference and test utterances; quick check: verify symmetric encoding produces meaningful similarity representations
- **Unweighted Average Recall**: Evaluation metric that treats all score classes equally regardless of frequency; quick check: calculate class-wise recall to identify performance disparities

## Architecture Onboarding

**Component Map:**
Input Audio -> Feature Extractor (wav2vec2.0 or Custom Encoder) -> GOP-CTC Module -> Classification Head -> Pronunciation Score

**Critical Path:**
Audio features → GOP-CTC computation → Feature fusion → Score prediction

**Design Tradeoffs:**
- CTC-based GOP features vs. learned representations: explicit pronunciation signals vs. end-to-end optimization
- Weighted loss vs. standard loss: balanced metric optimization vs. simpler training dynamics
- Siamese vs. direct classification: pairwise comparison capability vs. simpler architecture

**Failure Signatures:**
- Poor generalization to speakers outside training distribution
- Over-reliance on acoustic features rather than pronunciation quality
- Suboptimal balance between UAR and MAE optimization

**First Experiments:**
1. Evaluate model performance on held-out speakers to assess generalization
2. Compare CTC-GOP features against standard acoustic features in ablation study
3. Test different weightings in the ordinal cross-entropy loss to optimize metric balance

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Limited dataset size (12 hours from 18 children) may affect generalizability to larger populations
- Focus on Norwegian L2 learners limits external validity for other languages and contexts
- Evaluation metrics may not fully capture pedagogical utility for classroom implementation
- Potential biases in assessment outcomes related to children's native languages or backgrounds not addressed

## Confidence
- **High confidence**: Experimental methodology is sound with clear implementation details and appropriate evaluation metrics
- **Medium confidence**: GOP-CTC model superiority is well-supported, though performance gains should be interpreted cautiously given limited dataset size
- **Medium confidence**: Weighted ordinal cross-entropy loss formulation appears theoretically sound, though specific parameterization impact could benefit from further analysis

## Next Checks
1. Test model generalization across multiple L2 languages and age groups to assess robustness beyond Norwegian child learner context
2. Conduct bias analysis to evaluate whether assessment outcomes systematically differ across children's native language backgrounds or demographic characteristics
3. Implement ablation studies to quantify specific contribution of GOP-CTC features compared to standard architectures, and test performance with varying training data amounts to establish data efficiency characteristics