---
ver: rpa2
title: 'Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders'
arxiv_id: '2506.14002'
source_url: https://arxiv.org/abs/2506.14002
tags:
- lemma
- feature
- have
- proof
- neuron
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the problem of feature recovery in Large Language
  Models (LLMs) using Sparse Autoencoders (SAEs), addressing the lack of rigorous
  theoretical guarantees and practical limitations such as hyperparameter sensitivity
  in existing methods. The authors introduce a novel statistical framework modeling
  polysemantic features as sparse mixtures of monosemantic concepts, along with a
  new notion of feature identifiability.
---

# Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders

## Quick Facts
- arXiv ID: 2506.14002
- Source URL: https://arxiv.org/abs/2506.14002
- Authors: Siyu Chen; Heejune Sheen; Xuyuan Xiong; Tianhao Wang; Zhuoran Yang
- Reference count: 40
- One-line primary result: Introduces Group Bias Adaptation (GBA) algorithm with provable recovery guarantees for monosemantic features in Sparse Autoencoders, overcoming limitations of traditional methods

## Executive Summary
This paper addresses the challenge of recovering interpretable features from Large Language Models (LLMs) using Sparse Autoencoders (SAEs), a critical component for mechanistic interpretability. The authors identify key limitations in existing SAE approaches, including sensitivity to hyperparameters and lack of theoretical guarantees for feature recovery. They propose a novel statistical framework modeling polysemantic features as sparse mixtures of monosemantic concepts, and introduce the Group Bias Adaptation (GBA) algorithm that adaptively adjusts bias parameters to enforce appropriate activation sparsity. The work provides the first SAE algorithm with provable recovery guarantees, demonstrated through theoretical analysis and empirical validation on LLMs up to 1.5 billion parameters.

## Method Summary
The paper introduces a novel statistical framework for modeling polysemantic features as sparse mixtures of monosemantic concepts, establishing a new notion of feature identifiability. Building on this foundation, the authors propose the Group Bias Adaptation (GBA) algorithm, which adaptively adjusts neural network bias parameters to enforce appropriate activation sparsity. Unlike traditional approaches that rely on ℓ1 regularization or TopK activation methods with fixed hyperparameters, GBA dynamically adapts bias parameters during training to achieve optimal sparsity levels. The algorithm provably recovers all monosemantic features when input data follows the proposed statistical model. Empirically, GBA is evaluated on LLMs with up to 1.5 billion parameters, demonstrating superior performance across reconstruction quality, activation sparsity, and feature consistency metrics compared to benchmark methods.

## Key Results
- GBA achieves superior performance on LLMs with up to 1.5 billion parameters compared to benchmark SAE methods
- First SAE algorithm with provable recovery guarantees for monosemantic features under the proposed statistical model
- Demonstrates improved reconstruction quality, activation sparsity, and feature consistency over traditional ℓ1 regularization and TopK activation approaches

## Why This Works (Mechanism)
GBA works by addressing the fundamental limitation of traditional SAE training methods: the need for fixed hyperparameters (like ℓ1 regularization strength or TopK threshold) that are difficult to tune and may not generalize across different model scales and data distributions. The algorithm adaptively adjusts bias parameters during training, allowing the model to learn optimal sparsity levels dynamically rather than relying on predetermined values. This adaptive mechanism ensures that features are activated appropriately based on their importance and frequency in the data, leading to better recovery of monosemantic features that are crucial for mechanistic interpretability.

## Foundational Learning

**Sparse Autoencoders (SAEs)**
- *Why needed*: SAEs are essential tools for feature extraction in LLMs, enabling the identification of interpretable concepts within neural representations
- *Quick check*: Verify that SAE architecture includes encoder, decoder, and sparsity-inducing mechanisms like ℓ1 regularization or TopK activation

**Polysemanticity vs Monosemanticity**
- *Why needed*: Understanding the distinction between features representing multiple concepts versus single concepts is crucial for interpretability
- *Quick check*: Confirm that the statistical model treats polysemantic features as mixtures of monosemantic components

**Feature Identifiability**
- *Why needed*: Establishing conditions under which true features can be uniquely recovered is fundamental to provable recovery guarantees
- *Quick check*: Verify that the theoretical framework defines clear identifiability conditions for monosemantic features

**Adaptive Bias Mechanisms**
- *Why needed*: Traditional fixed hyperparameters limit generalization; adaptive mechanisms enable dynamic adjustment to data characteristics
- *Quick check*: Confirm that GBA's bias adaptation is implemented through learnable parameters that update during training

## Architecture Onboarding

**Component Map**
Input Data -> Encoder Network -> GBA Bias Adaptation -> Sparse Feature Extraction -> Decoder Network -> Reconstruction Output

**Critical Path**
Data flows through encoder, undergoes bias adaptation in GBA module, produces sparse features, and passes through decoder for reconstruction. The GBA component is critical as it determines feature sparsity and ultimately feature recovery quality.

**Design Tradeoffs**
GBA trades computational overhead during training for improved feature recovery and reduced hyperparameter sensitivity. The adaptive mechanism requires additional parameters and computation compared to fixed hyperparameter approaches, but eliminates the need for extensive hyperparameter tuning and provides theoretical guarantees.

**Failure Signatures**
- Poor reconstruction quality indicates inadequate feature recovery
- Excessive sparsity suggests over-aggressive bias adaptation
- Insufficient sparsity indicates under-active bias adjustment
- Inconsistent feature patterns across similar inputs suggest identifiability issues

**3 First Experiments**
1. Compare GBA reconstruction loss against ℓ1 and TopK baselines on held-out data
2. Visualize activation patterns to verify appropriate sparsity levels across feature dimensions
3. Test feature consistency by measuring correlation of extracted features for semantically similar inputs

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical guarantees rely on a specific statistical model of polysemantic features that may not capture all real-world complexities
- Performance and scalability need validation on larger LLM architectures beyond 1.5 billion parameters
- Computational overhead of GBA compared to standard SAE training methods is not explicitly addressed

## Confidence

| Claim Area | Confidence Level |
|------------|------------------|
| Theoretical framework and identifiability proof | High |
| Empirical performance claims | Medium |
| Generalizability across model scales and architectures | Low |

## Next Checks
1. Test GBA on larger LLM architectures (10B+ parameters) to verify scalability of theoretical guarantees and empirical performance
2. Conduct ablation studies on the adaptive bias mechanism to quantify its contribution versus standard SAE training with tuned hyperparameters
3. Evaluate feature interpretability and downstream utility (e.g., circuit analysis, manipulation) to complement the reconstruction and sparsity metrics