---
ver: rpa2
title: A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm
  Selection in the Facility Layout Problem
arxiv_id: '2509.18054'
source_url: https://arxiv.org/abs/2509.18054
tags:
- problem
- algorithm
- knowledge
- search
- evidence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a Knowledge Graph-based Retrieval-Augmented\
  \ Generation (KG-RAG) framework for algorithm selection in the Facility Layout Problem\
  \ (FLP), an NP-hard optimization problem with complex multi-objective trade-offs.\
  \ The method constructs a domain-specific knowledge graph from literature, then\
  \ uses a multifaceted retrieval mechanism\u2014graph-based, vector-based, and cluster-based\u2014\
  to gather evidence, which is processed by a Large Language Model (LLM) to generate\
  \ explainable, data-driven recommendations."
---

# A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Facility Layout Problem

## Quick Facts
- arXiv ID: 2509.18054
- Source URL: https://arxiv.org/abs/2509.18054
- Reference count: 21
- Introduces KG-RAG framework for explainable algorithm selection in NP-hard FLP

## Executive Summary
This paper presents a Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) framework for algorithm selection in the Facility Layout Problem (FLP), an NP-hard optimization challenge with complex multi-objective trade-offs. The method constructs a domain-specific knowledge graph from literature and employs a multifaceted retrieval mechanism—graph-based, vector-based, and cluster-based—to gather evidence that a Large Language Model processes to generate explainable, data-driven recommendations. Evaluated on six FLP cases, the KG-RAG framework achieved an average reasoning score of 4.7/5, outperforming a baseline Gemini 1.5 Flash chatbot (3.3/5).

## Method Summary
The KG-RAG framework constructs a domain-specific knowledge graph from FLP literature, then uses hybrid retrieval (graph-based, vector-based, and cluster-based) to gather relevant evidence. This evidence is processed by a Large Language Model to generate explainable, data-driven algorithm recommendations for complex multi-objective FLP instances.

## Key Results
- KG-RAG framework achieved average reasoning score of 4.7/5 on six FLP cases
- Outperformed baseline Gemini 1.5 Flash chatbot (3.3/5) in algorithm selection reasoning
- Hybrid retrieval strategy enabled precise, traceable recommendations and reduced LLM hallucinations

## Why This Works (Mechanism)
The framework leverages structured knowledge representation through a domain-specific knowledge graph to ground LLM recommendations in verifiable evidence. The hybrid retrieval mechanism combines multiple evidence-gathering strategies to ensure comprehensive coverage of relevant literature, while the knowledge graph structure enables traceability and reduces hallucinations by constraining LLM output to documented algorithmic approaches and their characteristics.

## Foundational Learning
- **Knowledge Graph Construction**: Why needed - provides structured, interconnected representation of FLP algorithms and their properties; Quick check - verify graph contains at least 50 nodes representing distinct algorithms and relationships
- **Hybrid Retrieval Mechanism**: Why needed - ensures comprehensive evidence gathering across different data representations; Quick check - confirm all three retrieval methods (graph, vector, cluster) return non-empty results for test queries
- **Large Language Model Integration**: Why needed - transforms retrieved evidence into actionable, explainable recommendations; Quick check - validate LLM outputs contain references to specific graph nodes/edges

## Architecture Onboarding

**Component Map**: Knowledge Graph -> Hybrid Retriever -> LLM Processor -> Recommendation Generator

**Critical Path**: Literature Ingestion → KG Construction → Evidence Retrieval → LLM Processing → Algorithm Recommendation

**Design Tradeoffs**: The framework prioritizes explainability and traceability over raw recommendation speed, accepting computational overhead from hybrid retrieval to ensure comprehensive evidence coverage and reduced hallucinations.

**Failure Signatures**: Sparse retrieval results indicate inadequate KG coverage; LLM hallucinations suggest retrieval mechanism gaps or insufficient evidence grounding; poor reasoning scores indicate mismatch between retrieval quality and recommendation generation.

**First Experiments**:
1. Validate KG construction by testing retrieval of known algorithm relationships
2. Test hybrid retrieval performance on benchmark FLP queries
3. Compare LLM recommendations with expert-selected algorithms on simple test cases

## Open Questions the Paper Calls Out
None

## Limitations
- Small evaluation sample size (n=6 cases) limits generalizability across diverse FLP instances
- No baseline traditional algorithm selection method comparison to assess incremental value
- Absence of explicit hallucination rate measurements or comparison to baseline LLM

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Technical feasibility of KG construction and hybrid retrieval | High |
| Outperformance of baseline chatbot | Medium |
| Superior interpretability and traceability | Low |

## Next Checks
1. Expand evaluation to at least 20 diverse FLP cases with varying constraint types and sizes to assess robustness and generalizability
2. Compare KG-RAG recommendations against traditional algorithm selection methods (e.g., machine learning classifiers or expert systems) to quantify incremental value
3. Implement hallucination detection metrics (e.g., fact-checking against the KG) and compare KG-RAG's output accuracy against a baseline LLM without knowledge graph integration