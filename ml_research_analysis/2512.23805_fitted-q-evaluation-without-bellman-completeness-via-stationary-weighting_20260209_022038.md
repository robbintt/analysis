---
ver: rpa2
title: Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting
arxiv_id: '2512.23805'
source_url: https://arxiv.org/abs/2512.23805
tags:
- qinit
- stationary
- error
- bellman
- iteration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper identifies a fundamental norm mismatch in fitted Q-evaluation\
  \ (FQE): the Bellman operator is \u03B3-contractive under the stationary distribution\
  \ of the target policy, but standard FQE minimizes Bellman error under the behavior\
  \ distribution where no contraction holds. This mismatch explains why FQE can be\
  \ unstable under function approximation when Bellman completeness fails."
---

# Fitted Q Evaluation Without Bellman Completeness via Stationary Weighting

## Quick Facts
- **arXiv ID**: 2512.23805
- **Source URL**: https://arxiv.org/abs/2512.23805
- **Reference count**: 40
- **Primary result**: Stationary weighting in fitted Q-evaluation aligns the contraction geometry with the Bellman operator, preventing exponential divergence under function approximation when Bellman completeness fails.

## Executive Summary
This paper addresses a fundamental instability in fitted Q-evaluation (FQE) when function approximation is used without Bellman completeness. Standard FQE minimizes Bellman error under the behavior distribution, but the Bellman operator only contracts in the stationary distribution of the target policy. This norm mismatch causes exponential error growth and instability. The authors propose a simple solution: reweight each regression step using an estimate of the stationary density ratio. This stationary-weighted FQE aligns the optimization geometry with the true contraction, yielding geometric decay without requiring Bellman completeness or realizability. The method requires only a weaker orthogonality condition and provides finite-sample bounds scaling as (1-γ)⁻¹ times the critical radius.

## Method Summary
The method estimates the stationary density ratio w_μ = dμ/dνb using a DICE-style saddle-point formulation from offline data, then performs K iterations of weighted least-squares regression. Each iteration solves Q̂^(k+1) = argmin_{f∈F} Σ_i ŵ_μ(S_i,A_i)[Y_i^(k) - f(S_i,A_i)]² where Y_i^(k) = R_i + γ(πQ̂^(k))(S'_i). The stationary ratio aligns FQE with the L²(μ) geometry where the Bellman operator contracts, avoiding the geometric error blow-up of standard FQE under norm mismatch. The method requires only that a weighting function satisfying weighted Bellman projection orthogonality exists, which is strictly weaker than Bellman completeness.

## Key Results
- Stationary weighting restores geometric decay in Bellman error across iterations, preventing exponential divergence under severe norm mismatch.
- Finite-sample bound shows estimation error scales as (1-γ)⁻¹ times (critical radius + density ratio error + log term), avoiding geometric blow-up.
- Experiments on Baird's counterexample and random Garnet MDPs demonstrate stability where standard FQE becomes arbitrarily slow or unstable.
- The method requires only weighted Bellman projection orthogonality, strictly weaker than Bellman completeness or realizability.

## Why This Works (Mechanism)

### Mechanism 1: Contraction Geometry Alignment
Reweighting regression by the stationary density ratio aligns FQE with the L²(μ) norm where the Bellman operator T is γ-contractive. Standard FQE minimizes error in L²(νb) where T need not contract. By weighting samples as w_μ(s,a) = dμ/dνb, the regression effectively operates in L²(μ), restoring the contraction geometry. This requires only that the stationary distribution μ exists for (π, P) and has overlap with the behavior distribution νb.

### Mechanism 2: Inexact Picard Iteration Without Completeness
Under stationary weighting, the projected operator T_F = Π_F T is γ-contractive in L²(μ). Per-iteration statistical errors η_k propagate as γ^K ‖Q̂₀ - Q*F‖ + Σⱼ γ^(K-j) ηⱼ, entering additively with (1-γ)⁻¹ scaling rather than compounding multiplicatively as in standard FQE under norm mismatch. This requires the function class F to be convex and the weighting to satisfy orthogonality condition C3.

### Mechanism 3: Relaxed Admissibility via Orthogonality
The method requires only a weighting satisfying weighted Bellman projection orthogonality, strictly weaker than Bellman completeness. Condition C3 requires that the Bellman projection residual (TQ - Π_F TQ) be orthogonal to F under L²(w_μ νb). This is automatically satisfied by exact stationary ratios OR by any weighting under Bellman completeness. When neither holds exactly, approximate satisfaction still yields contraction-like behavior with error scaling in ε_Bell.

## Foundational Learning

- **Bellman Contraction under Stationary Distribution**: Why needed here: The entire theoretical contribution rests on understanding why T contracts in L²(μ) but not L²(νb). Quick check: Can you explain why the Bellman operator is contractive under πP's stationary distribution but not under an arbitrary behavior distribution?

- **Density Ratio Estimation for Stationary Distributions**: Why needed here: Implementation requires estimating w_μ = dμ/dνb from offline data; understanding DICE-style methods is essential. Quick check: What is the variational characterization of stationarity that enables saddle-point density ratio estimation?

- **Projected Bellman Operators and Completeness**: Why needed here: The paper's contribution is meaningful only if you understand why Bellman completeness is a standard assumption and when it fails. Quick check: Why does projection error compound across iterations when the function class is not Bellman-complete?

## Architecture Onboarding

- **Component map**: Density Ratio Estimator (DICE) → Weighted Regression Module → Bellman Target Constructor
- **Critical path**: Estimate ŵ_μ from D_n using min-max formulation, initialize Q̂⁽⁰⁾ ∈ F, for k = 0 to K-1: construct targets, solve weighted regression, repeat
- **Design tradeoffs**: Exact vs. estimated ratios (estimated add variance but method is robust), sample splitting vs. data efficiency (cross-fitting relaxes C6), shallow iteration vs. convergence (Theorem 2 shows γ^K decay)
- **Failure signatures**: Exponentially growing error across iterations (suggests severe norm mismatch), high variance in final estimates (check density ratio variance), slow convergence despite weighting (verify orthogonality condition)
- **First 3 experiments**: 1) Baird counterexample replication: implement linear FQE with/without stationary weighting, verify geometric decay restored; 2) Density ratio quality ablation: compare exact w_μ vs. DICE-estimated ŵ_μ, measure error correlation; 3) Discount sensitivity sweep: test γ ∈ {0.9, 0.95, 0.99}, verify phase transition in standard FQE is prevented

## Open Questions the Paper Calls Out
- **Control setting extension**: How to extend stationary weighting to the control setting with the Bellman optimality operator, which involves changing policies and complicates the definition of a fixed stationary distribution.
- **Variance inflation mitigation**: How to theoretically bound or empirically mitigate the variance inflation caused by upweighting rare state-action pairs in low-overlap regions.
- **Orthogonality condition sensitivity**: How the estimation error of the density ratio specifically impacts the satisfaction of the Weighted Bellman Projection Orthogonality condition (C3) in finite samples.

## Limitations
- Stationary-behavior overlap assumption (C1) is not directly verifiable from data without assumptions about the MDP dynamics, and severe coverage gaps could lead to unbounded variance.
- Convexity requirement (C2) limits applicability to certain function classes like neural networks without architectural constraints.
- While Condition C3 is theoretically weaker than Bellman completeness, practical verification of the orthogonality condition remains challenging without access to true Bellman residuals.

## Confidence
- **High confidence**: The geometric mechanism of norm mismatch causing exponential error growth is well-established and experimentally validated; the mathematical framework is rigorous.
- **Medium confidence**: Empirical demonstration that stationary weighting prevents divergence is convincing, though exact parameter choices are not fully specified.
- **Low confidence**: Practical implications of Condition C3 for real-world function classes are not fully explored; the paper assumes existence of admissible weighting but provides limited guidance on when this holds.

## Next Checks
1. **Robustness to Density Ratio Misspecification**: Implement with varying quality of density ratio estimates (from exact to highly noisy) on a simple MDP to quantify the tradeoff between variance from estimation error and bias from norm mismatch.

2. **Function Class Sensitivity**: Test the method on both convex (linear) and non-convex (neural network) function classes to verify whether the convexity assumption is truly necessary for convergence or merely simplifies analysis.

3. **Coverage Gap Stress Test**: Construct MDPs where the target policy's stationary distribution has regions with zero overlap under the behavior policy to identify the breaking point where stationary weighting fails and the method becomes unstable.