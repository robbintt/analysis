---
ver: rpa2
title: Fast Thinking for Large Language Models
arxiv_id: '2509.23633'
source_url: https://arxiv.org/abs/2509.23633
tags:
- reasoning
- arxiv
- tokens
- codebook
- thinking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Latent Codebooks for Fast Thinking (LC-FT),
  a framework that enables large language models to perform efficient reasoning by
  learning compact strategy priors from concise Chain-of-Thought supervision. At inference,
  the model conditions on a small set of continuous thinking vectors distilled from
  a latent codebook, avoiding the inefficiency of explicit multi-step reasoning.
---

# Fast Thinking for Large Language Models

## Quick Facts
- arXiv ID: 2509.23633
- Source URL: https://arxiv.org/abs/2509.23633
- Reference count: 40
- Introduces LC-FT framework enabling LLMs to perform efficient reasoning via compact strategy priors, achieving competitive accuracy with substantially shorter outputs

## Executive Summary
This work introduces Latent Codebooks for Fast Thinking (LC-FT), a framework that enables large language models to perform efficient reasoning by learning compact strategy priors from concise Chain-of-Thought supervision. At inference, the model conditions on a small set of continuous thinking vectors distilled from a latent codebook, avoiding the inefficiency of explicit multi-step reasoning. To further improve efficiency, GainRouter dynamically switches between fast codebook-guided inference and slow explicit reasoning, suppressing overthinking and reducing token usage. Experiments on mathematical reasoning and programming benchmarks show that LC-FT achieves competitive accuracy with substantially shorter outputs compared to baseline methods, while GainRouter provides a controllable accuracy–efficiency trade-off.

## Method Summary
LC-FT trains LLMs to use compact "thinking tokens" distilled from a latent codebook of strategy priors, enabling single-pass reasoning without explicit intermediate steps. The codebook is learned from concise rationales generated by a teacher model, with thinking tokens injected at a specific transformer layer (L=32) using LoRA for efficient adaptation. GainRouter dynamically routes between fast codebook-guided inference and slow explicit reasoning based on uncertainty estimates, optimizing the accuracy-efficiency trade-off. The framework is evaluated on mathematical reasoning (OlympiadBench) and programming (MBPP, APPS) benchmarks.

## Key Results
- LC-FT achieves competitive accuracy on mathematical reasoning benchmarks while reducing average token usage from ~19K to ~13K
- GainRouter matches full Qwen3-Thinking accuracy (73.3% on AIME) with 33% token reduction
- Codebook removal causes the largest accuracy drop in ablation studies, confirming its central role

## Why This Works (Mechanism)

### Mechanism 1: Codebook-Based Strategy Distillation
Concise reasoning rationales are compressed into a discrete codebook of reusable strategy priors, enabling single-pass inference without explicit intermediate tokens. During training, teacher-generated concise rationales are aligned with learnable thinking tokens via cosine similarity loss. At inference, K learnable queries attend over codebook entries via cross-attention, producing soft compositions of strategy prototypes injected at layer L. The refiner MLP denoises these before injection. The core assumption is that strategy-level reasoning patterns are finite and compressible; concise hints capture sufficient structure to guide decoding without full derivations.

### Mechanism 2: Layer-Localized Adaptation with Masked Injection
Thinking tokens are injected at specific transformer layer L, with prior layers frozen and post-L layers adapted via LoRA. This localizes strategy integration while preserving pretrained representations. Thinking tokens are masked before layer L and visible after; LoRA (rank r=8) is applied only to layers ≥L. This creates a sub-network specialized in consuming strategy priors without disrupting lower-level features. The core assumption is that intermediate layers provide sufficient semantic context for tokens to specialize, while later layers can integrate guidance without catastrophic forgetting.

### Mechanism 3: Uncertainty-Aware Dynamic Routing (GainRouter)
A lightweight router combining question-embedding uncertainty and codebook-attention entropy can adaptively escalate to explicit CoT only when fast-path failure risk is high. Router computes raw_logit from [question; aggregated thinking token] features, adjusts threshold via δθ(x) = β₁uₙ + β₂tanh(Δℓ_norm/τ) where uₙ is normalized attention entropy. Routes to slow thinking iff raw_logit ≥ θ + δθ. The core assumption is that attention entropy and predicted length difference correlate with problem difficulty and fast-path adequacy.

## Foundational Learning

- **Cross-attention for retrieval-augmented generation**: The codebook mechanism uses learnable queries Q to attend over discrete entries C, retrieving soft strategy compositions. Understanding scaled dot-product attention and query/key/value projection is essential.
  - Quick check question: Given Q ∈ R^(K×H) and C ∈ R^(M×H), what is the shape of attention weights A and output T?

- **LoRA (Low-Rank Adaptation)**: The framework applies LoRA only from injection layer L onward. Understanding how W' = W + BA (with A ∈ R^(r×d_in), B ∈ R^(d_out×r)) enables parameter-efficient fine-tuning is critical.
  - Quick check question: If the base weight W is frozen, how many trainable parameters does LoRA add for a 4096×4096 linear layer with rank r=8?

- **Entropy-based uncertainty estimation**: GainRouter uses normalized attention entropy uₙ = -1/log(K) Σ αᵢ log αᵢ as an uncertainty signal. Understanding how entropy relates to distribution concentration is necessary.
  - Quick check question: If attention weights are uniform (αᵢ = 1/K for all i), what is uₙ? What if one αⱼ = 1.0?

## Architecture Onboarding

- **Component map**: Teacher Model -> Concise Rationale Generator -> (x, r̃, y) Triplets -> Codebook C (M×H) -> Learnable Queries Q (K×H) -> Refiner MLP -> Injection Layer L -> LoRA Adapters (r=8) -> GainRouter -> Fast/Slow Decision

- **Critical path**: 1) Data construction: Teacher generates hint → Verify with student → Collect (x, r̃, y) triplets 2) Stage 1 training: Align thinking tokens with teacher rationale hidden states (frozen reference) 3) Stage 2 training: SFT with thinking tokens, LoRA unfrozen from L onward 4) Router training: Separate 150 epochs on paired fast/slow execution labels 5) Inference: Encode question → Retrieve thinking tokens → Inject at L → Generate (or route to slow if threshold exceeded)

- **Design tradeoffs**: 
  - Codebook size M: Larger M increases coverage but grows attention cost; M=512 is sweet spot
  - Number of thinking tokens K: Math benefits from more (K=48), code from fewer (K=16); task-dependent
  - Injection layer L: Too early = insufficient context; too late = insufficient integration depth; L=32 optimal for 4B model
  - Router threshold θ: Higher θ = more aggressive fast-path, lower accuracy; lower θ = more conservative, fewer token savings

- **Failure signatures**:
  - Diffuse codebook activations: High entropy, no sparse peaks → codebook not learning meaningful strategies
  - Catastrophic forgetting on held-out tasks: LoRA adapting too aggressively; check if earlier layers accidentally unfrozen
  - Router always selecting slow mode: θ too high or δθ miscalibrated; check entropy/length predictions
  - Longer generation than baseline: Thinking tokens adding noise; check refiner is applied

- **First 3 experiments**:
  1. Codebook activation visualization: On validation set, plot instance-wise attention over codebook entries; verify sparsity (Top-10 mass > 10/M) and task-consistent peaks
  2. Ablation at fixed L: Remove codebook, refiner, and LoRA independently; confirm codebook removal is largest drop
  3. Router calibration check: On held-out problems, compare router predictions vs. actual fast/slow success; plot accuracy-token frontier by varying θ

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- Framework effectiveness depends on quality and coverage of concise rationales from teacher model, with uncertainty about generalization to problems requiring novel reasoning strategies
- Limited analysis of codebook performance when task complexity exceeds codebook capacity, potentially causing degradation to "soft noise injection"
- Router mechanism relies on attention entropy and length differences that may not reliably predict fast-path failure across all problem types

## Confidence
**High Confidence**: Codebook mechanism can compress strategy priors and improve efficiency; layer-localized LoRA adaptation provides measurable benefits; GainRouter reduces token usage while maintaining accuracy on tested benchmarks

**Medium Confidence**: K=48 thinking tokens optimal for mathematical reasoning; M=512 codebook size optimal; L=32 injection layer universally optimal

**Low Confidence**: Framework generalizes to non-mathematical domains without modification; attention entropy reliably predicts fast-path adequacy across all problem types; codebook maintains effectiveness as problem complexity scales

## Next Checks
1. **Cross-Domain Generalization Test**: Apply LC-FT to non-mathematical domains (legal reasoning, scientific analysis, or common-sense reasoning) and measure codebook activation sparsity and task performance. Compare against domain-specific teacher models to assess whether the same codebook architecture generalizes or requires domain-specific adaptation.

2. **Stress Test for Codebook Capacity**: Systematically increase problem complexity and novelty in controlled experiments to identify when codebook coverage breaks down. Measure the relationship between problem structural complexity and codebook attention entropy, and identify the point where attention becomes uniformly distributed (indicating no useful strategy retrieval).

3. **Router Robustness Evaluation**: Create adversarial examples where attention entropy and length differences are uncorrelated with actual fast-path success. Test whether GainRouter develops systematic biases and evaluate its performance on problems requiring hybrid reasoning strategies that combine multiple reasoning patterns.