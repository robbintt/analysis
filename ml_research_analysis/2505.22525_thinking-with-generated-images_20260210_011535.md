---
ver: rpa2
title: Thinking with Generated Images
arxiv_id: '2505.22525'
source_url: https://arxiv.org/abs/2505.22525
tags:
- visual
- images
- generation
- vision
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Thinking with Generated Images, a novel approach
  enabling large multimodal models to generate intermediate visual thoughts during
  reasoning. The method allows models to spontaneously create and critique visual
  representations, rather than just processing fixed user-provided images.
---

# Thinking with Generated Images

## Quick Facts
- arXiv ID: 2505.22525
- Source URL: https://arxiv.org/abs/2505.22525
- Reference count: 40
- Primary result: 50% relative improvement in complex multi-object visual reasoning tasks

## Executive Summary
This paper introduces Thinking with Generated Images, a novel approach enabling large multimodal models to generate intermediate visual thoughts during reasoning. The method allows models to spontaneously create and critique visual representations, rather than just processing fixed user-provided images. The authors implement this through a native long-multimodal thought process that interleaves text and visual tokens, enabling models to decompose complex visual tasks into subgoals or generate self-critiques of their visual hypotheses.

Two mechanisms are demonstrated: vision generation with intermediate visual subgoals (where models break down multi-object prompts into separate images then integrate them) and vision generation with self-critique (where models analyze and refine their own visual outputs). The approach shows substantial improvements over baselines, achieving up to 50% relative improvement in handling complex multi-object scenarios. On GenEval benchmarks, the method improved performance from 38% to 57% in two-object generation tasks, while also demonstrating effectiveness in correcting and refining visual hypotheses through iterative self-critique.

## Method Summary
The authors propose a native long-multimodal thought process that interleaves text and visual tokens, enabling models to generate and reason about intermediate visual representations. The approach uses two key mechanisms: vision generation with intermediate visual subgoals, where models decompose complex multi-object prompts into separate images and then integrate them, and vision generation with self-critique, where models analyze and refine their own visual outputs. The method leverages long-context capabilities to maintain coherence across multiple reasoning steps and visual generations, allowing the model to break down complex visual reasoning into manageable subgoals or iteratively improve its outputs through self-critique.

## Key Results
- 50% relative improvement in handling complex multi-object visual reasoning scenarios
- Performance improvement from 38% to 57% accuracy on GenEval benchmarks for two-object generation tasks
- Demonstrated effectiveness in correcting and refining visual hypotheses through iterative self-critique

## Why This Works (Mechanism)
The approach works by enabling models to generate intermediate visual thoughts that serve as cognitive scaffolding for complex reasoning tasks. By interleaving text and visual tokens in a long-context framework, the model can maintain coherence across multiple reasoning steps while generating and analyzing visual representations. The self-critique mechanism allows the model to iteratively refine its outputs, similar to how humans might sketch multiple versions of an idea and evaluate each iteration. The decomposition of complex multi-object prompts into separate subgoal images enables the model to handle compositional complexity more effectively than attempting to generate all elements simultaneously.

## Foundational Learning

**Long-context multimodal modeling** - Understanding how to process interleaved text and visual tokens in extended sequences. Why needed: Enables maintaining coherence across multiple reasoning steps and visual generations. Quick check: Can the model maintain context consistency across 10+ interleaved visual and text tokens?

**Visual decomposition strategies** - Breaking down complex multi-object scenes into manageable subcomponents. Why needed: Allows handling compositional complexity that would be overwhelming in a single generation pass. Quick check: Can the model successfully identify and separate distinct objects or concepts in complex prompts?

**Iterative self-critique mechanisms** - Generating and evaluating self-assessments of visual outputs. Why needed: Enables refinement and improvement of generated images through multiple reasoning cycles. Quick check: Does the model's self-critique identify genuine issues and suggest improvements that lead to better final outputs?

## Architecture Onboarding

**Component map**: User Input -> Text Processing -> Vision Generation -> Self-Critique/Integration -> Refined Output

**Critical path**: The model first processes the textual prompt, generates intermediate visual thoughts, optionally performs self-critique on these visual outputs, then integrates the results into a final coherent output. The long-context mechanism maintains coherence across these steps.

**Design tradeoffs**: The approach trades computational efficiency for improved reasoning quality, as generating and processing multiple intermediate visual thoughts is more expensive than direct generation. The interleaving of text and visual tokens requires careful attention balancing to prevent the model from getting stuck in either modality.

**Failure signatures**: Common failure modes include getting stuck in local optima during self-critique cycles, failing to properly integrate multiple subgoal images, or losing coherence across long reasoning chains due to context limitations.

**First experiments**:
1. Test single-object generation with and without intermediate visual subgoals to isolate the benefit of the decomposition approach
2. Evaluate self-critique effectiveness by comparing outputs before and after critique cycles on identical initial generations
3. Measure coherence degradation over extended reasoning chains to identify context window limitations

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions in the provided content.

## Limitations
- Computational overhead of generating and processing multiple intermediate visual thoughts raises scalability concerns
- Self-critique mechanism may reinforce existing biases rather than genuinely improving reasoning quality
- Limited validation across diverse visual reasoning tasks beyond the presented benchmarks

## Confidence
- High confidence in the novel approach of interleaving text and visual tokens for multimodal reasoning
- Medium confidence in the reported 50% relative improvement and 38% to 57% accuracy gains, pending broader validation
- Medium confidence in the practical effectiveness of the self-critique mechanism, given potential reinforcement of biases

## Next Checks
1. Conduct cross-validation across multiple independent visual reasoning datasets to verify the robustness of the reported performance improvements
2. Perform ablation studies comparing the full intermediate visual thought process against simpler sequential generation approaches to isolate the specific contribution of the proposed methodology
3. Implement a blinded human evaluation study where experts assess whether the model's self-critiques genuinely improve visual reasoning quality or merely provide post-hoc rationalization of generated outputs