---
ver: rpa2
title: 'ADVOSYNTH: A Synthetic Multi-Advocate Dataset for Speaker Identification in
  Courtroom Scenarios'
arxiv_id: '2601.10315'
source_url: https://arxiv.org/abs/2601.10315
tags:
- speech
- speaker
- identification
- dataset
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Advosynth-500, a specialized synthetic speech
  dataset for speaker identification in courtroom scenarios. It features 100 audio
  files generated using Speech Llama Omni, representing 10 unique advocate identities
  engaged in legal arguments.
---

# ADVOSYNTH: A Synthetic Multi-Advocate Dataset for Speaker Identification in Courtroom Scenarios

## Quick Facts
- arXiv ID: 2601.10315
- Source URL: https://arxiv.org/abs/2601.10315
- Reference count: 13
- Introduces Advosynth-500: a synthetic speech dataset with 100 audio files across 10 advocate identities for speaker identification research

## Executive Summary
This paper presents Advosynth-500, a novel synthetic dataset designed to evaluate speaker identification systems in courtroom scenarios. The dataset features 100 audio files generated using Speech Llama Omni, representing 10 unique advocate identities engaged in legal arguments. Each advocate is assigned distinct vocal characteristics including pitch, timbre, speech rate, and assertiveness index to create realistic variability while maintaining speaker identity consistency. The work addresses the challenge of distinguishing between multiple synthetic voices with varying prosodic styles, providing a rigorous benchmark for testing closed-set classification performance in forensic-grade speaker identification research.

## Method Summary
Advosynth-500 was created by generating synthetic courtroom arguments using Speech Llama Omni, with each of the 10 advocate identities assigned unique vocal characteristics including pitch, timbre, speech rate, and assertiveness index. The dataset contains 100 audio files, each representing a distinct legal argument or courtroom exchange. The generation process deliberately introduces intra-speaker variability through controlled shifts in vocal performance while maintaining consistent identity markers, creating a challenging testbed for modern speaker identification systems. The closed-set classification framework evaluates system performance across varying argumentative contexts and prosodic styles.

## Key Results
- Advosynth-500 successfully creates synthetic courtroom scenarios with 10 distinct advocate identities across 100 audio files
- The dataset introduces controlled variability through assertiveness index and speech rate variations while maintaining speaker identity consistency
- Evaluation framework demonstrates the dataset's ability to test speaker identification systems under high-variability conditions found in legal settings

## Why This Works (Mechanism)
Advosynth-500 works by leveraging synthetic speech generation to create controlled yet realistic courtroom scenarios. The Speech Llama Omni model applies latent characteristic shifts to generate distinct advocate identities while maintaining consistent underlying parameters. By introducing prosodic variations through assertiveness indices and speech rate controls, the dataset creates meaningful intra-speaker variability that challenges identification systems. The closed-set classification framework provides a rigorous testing environment where systems must discriminate between carefully crafted synthetic voices that share the same base generative parameters but differ in assigned acoustic characteristics.

## Foundational Learning
- **Synthetic speech generation** - Why needed: Creates controlled dataset without privacy concerns; Quick check: Verify synthetic voices maintain consistent identity across varying contexts
- **Speaker embedding extractors** - Why needed: Core technology for identifying speakers in audio; Quick check: Test ECAPA-TDNN performance on synthetic vs. real data
- **Prosodic feature manipulation** - Why needed: Enables realistic vocal variation while preserving identity; Quick check: Validate assertiveness index correlates with perceived intensity
- **Closed-set classification framework** - Why needed: Provides standardized evaluation methodology; Quick check: Ensure classification accuracy meets forensic-grade requirements
- **Voice constancy under stress** - Why needed: Real courtroom scenarios involve varying emotional states; Quick check: Test identification accuracy across assertive vs. neutral speech

## Architecture Onboarding

**Component map:** Speech Llama Omni -> Synthetic generation -> Audio files (100) -> Speaker identification system -> Closed-set classification evaluation

**Critical path:** The generation process applies latent characteristic shifts to create distinct advocate identities, which are then evaluated through closed-set classification to measure identification accuracy under varying prosodic conditions.

**Design tradeoffs:** Synthetic data eliminates privacy concerns and enables precise control over variability, but may lack ecological validity compared to real courtroom recordings. The closed-set framework provides standardized evaluation but limits generalizability to open-set scenarios.

**Failure signatures:** Low classification accuracy may indicate either insufficient distinctiveness between synthetic identities or inadequate system robustness to prosodic variations. High false rejection rates suggest the assertiveness index and speech rate variations are introducing excessive intra-speaker variability.

**First experiments:**
1. Test ECAPA-TDNN performance on clean vs. overlapping speech segments
2. Evaluate classification accuracy across different assertiveness index levels
3. Compare identification performance on assertive rebuttals vs. rapid cross-examinations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can modern speaker embedding extractors (e.g., ECAPA-TDNN) capture fine-grained acoustic differences between identities generated by the same underlying model without the presence of natural biological variance?
- Basis in paper: [explicit] Section 2.3 states the dataset tests whether systems can distinguish identities based solely on "latent characteristic shifts" applied during the Speech Llama Omni generation process.
- Why unresolved: Traditional SID systems rely on biological vocal tract differences; it is unclear if they can effectively discriminate between synthetic voices that share the same base generative parameters.
- What evidence would resolve it: High classification accuracy on the closed-set task would demonstrate that synthetic identity markers are distinct enough to overcome the lack of biological variance.

### Open Question 2
- Question: To what extent can speaker identification systems demonstrate "voice constancy" when a single advocate's vocal performance undergoes significant phonetic shifts due to simulated stress or argument context?
- Basis in paper: [explicit] Section 3 posits that the dataset forces systems to prove they can recognize the same lawyer even when "vocal performance undergoes significant phonetic shifts between arguments."
- Why unresolved: The "Assertiveness Index" and speech rate variations intentionally introduce high intra-speaker variability, which historically confuses identification systems.
- What evidence would resolve it: Low false rejection rates for individual advocates across different argument types (e.g., measured rebuttals vs. rapid cross-examinations).

### Open Question 3
- Question: How robust are current forensic-grade identification systems when distinguishing between overlapping "adversarial interruptions" versus single-speaker segments in a synthetic environment?
- Basis in paper: [inferred] The Introduction notes that courtroom dialogue involves "adversarial interruptions" requiring models to distinguish between "spectral signatures that are temporarily merged," though the dataset's evaluation protocol focuses on standard closed-set identification.
- Why unresolved: The paper highlights overlapping speech as a key complexity, but the specific benchmark results for handling these merged signals versus clean segments are not detailed.
- What evidence would resolve it: A comparative evaluation of system performance on isolated advocate segments versus files containing simultaneous vocalizations.

## Limitations
- Synthetic nature may not fully capture real courtroom acoustic variability and environmental factors
- Closed-set classification framework limits generalizability to open-set scenarios with unknown speakers
- Relatively small scale (100 audio files across 10 speakers) may limit statistical robustness

## Confidence
- Dataset creation methodology and characteristics: High
- Relevance to speaker identification research: Medium
- Practical applicability to real courtroom scenarios: Low
- Comparative performance claims against existing benchmarks: Low

## Next Checks
1. Conduct cross-validation experiments using real courtroom audio recordings to assess the dataset's ecological validity and generalization capabilities
2. Expand the dataset with additional speakers and speech contexts while maintaining the synthetic generation framework to evaluate scalability
3. Implement and test open-set speaker identification approaches to determine performance beyond the closed-set framework