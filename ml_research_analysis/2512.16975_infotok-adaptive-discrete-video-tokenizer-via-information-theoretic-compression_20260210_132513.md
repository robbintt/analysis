---
ver: rpa2
title: 'InfoTok: Adaptive Discrete Video Tokenizer via Information-Theoretic Compression'
arxiv_id: '2512.16975'
source_url: https://arxiv.org/abs/2512.16975
tags:
- video
- adaptive
- token
- compression
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# InfoTok: Adaptive Discrete Video Tokenizer via Information-Theoretic Compression

## Quick Facts
- arXiv ID: 2512.16975
- Source URL: https://arxiv.org/abs/2512.16975
- Authors: Haotian Ye; Qiyuan He; Jiaqi Han; Puheng Li; Jiaojiao Fan; Zekun Hao; Fitsum Reda; Yogesh Balaji; Huayu Chen; Sheng Liu; Angela Yao; James Zou; Stefano Ermon; Haoxiang Wang; Ming-Yu Liu
- Reference count: 25
- Primary result: Achieves 1.5-2.0 dB PSNR improvement over fixed-rate baselines while maintaining 14.6% parameter overhead

## Executive Summary
InfoTok introduces an adaptive discrete video tokenizer that allocates variable token lengths based on each video's information complexity rather than using fixed compression rates. The method uses an ELBO-based router to estimate reconstruction difficulty and assign token budgets proportionally, then applies an adaptive compressor that preserves the most information-rich tokens while redistributing information from masked positions. This approach achieves state-of-the-art compression efficiency on standard video benchmarks while maintaining high reconstruction quality.

## Method Summary
InfoTok builds on the Cosmos Discrete Video Tokenizer framework, adding three key components: an ELBO-based router that estimates token length requirements, an adaptive compressor that selectively preserves high-information tokens, and a decompressor that reconstructs from variable-length sequences. The router computes ELBO values through an additional decoder pass, assigns token budgets proportionally to estimated information content, and the compressor creates binary masks to preserve the most critical tokens. The system uses FSQ quantization with a 64K codebook and trains end-to-end with reconstruction loss.

## Key Results
- Achieves 1.5-2.0 dB PSNR improvement over ElasticTok at BPP16=0.56 on TokenBench
- Maintains 14.6% parameter overhead for adaptive compression modules
- Reduces inference NFEs from ~11 (ElasticTok binary search) to ~2 (InfoTok)
- Binary mask storage overhead of ~5% of total tokens

## Why This Works (Mechanism)

### Mechanism 1: ELBO-based Token Budget Allocation
Video token sequences should have variable lengths proportional to information content, not fixed lengths. An ELBO-based router estimates each video's reconstruction difficulty via Evidence Lower Bound, then assigns token budget proportional to estimated information complexity: `N_x ∝ β × ELBO(x)/E[ELBO(x)]`. The core assumption is that ELBO correlates sufficiently with true log-likelihood that it can guide token allocation; the gap between ELBO and log p(x) is approximately uniform across videos.

### Mechanism 2: Information-Preserving Token Masking
Within a video, tokens with lowest per-token information content can be discarded first with minimal reconstruction impact. The adaptive compressor computes per-token ELBO contributions, creates a binary mask preserving the top N_x tokens by information content, and trains the compressor to redistribute information from masked positions to preserved ones. The core assumption is that information is locally redistributable—tokens with high information can absorb information from nearby low-information tokens without decoder retraining.

### Mechanism 3: Avoiding Uniform-Length Training Bias
Uniform-length training with random token budgets creates biased tokenizers that over-allocate tokens on average. Theoretical analysis shows uniform routers optimize a loss that doesn't penalize expected length, causing models to allocate ~2 tokens even when optimal is 1-3 tokens variable. The core assumption is that the data distribution has non-uniform complexity—a mix of "simple" frequent content and "complex" rare content.

## Foundational Learning

- **Shannon Source Coding Theorem**: Optimal code length equals negative log probability. Understanding this is essential to see why ELBO-based routing aims for theoretical optimality. Quick check: Given codebook size C=64 and three videos with probabilities 0.5, 0.25, 0.125, what are the optimal token lengths?

- **Evidence Lower Bound (ELBO) in VAEs**: The router uses ELBO as a tractable surrogate for intractable log-likelihood. Understanding ELBO = E[log p(x|z)] - KL(q||p) is essential to see why reconstruction error approximates it. Quick check: If KL divergence between approximate and true posterior is high, will ELBO under- or over-estimate log-likelihood?

- **Finite Scalar Quantization (FSQ)**: InfoTok uses FSQ for quantization rather than VQ-VAE style codebooks. Understanding FSQ's bounded scalar quantization helps interpret the codebook size calculations. Quick check: How does FSQ's approach differ from lookup-based VQ in terms of codebook storage and differentiability?

## Architecture Onboarding

- **Component map**: Encoder (E_φ) -> Router (ELBO estimator) -> Adaptive Compressor (M_ψ) -> Quantizer (Q) -> [storage] -> Dequantizer -> Decompressor (M_ψ⁻¹) -> Decoder (D_θ)
- **Critical path**: Encoder → Router (decoder pass for ELBO) → Adaptive Compressor → Quantizer → [storage] → Dequantizer → Decompressor → Decoder. The router's extra decoder pass is the key inference overhead (1 additional NFE vs. 11 for ElasticTok's binary search).
- **Design tradeoffs**: Extra decoder pass for ELBO estimation vs. search-based length selection (chosen: ELBO); binary mask overhead (~5% tokens) vs. fixed positional schemes (chosen: mask storage for flexibility); single β vs. multi-β ensemble training (InfoTok vs. InfoTok-Flex).
- **Failure signatures**: Systematic over-compression (simple videos fine, complex videos poor) → router E[ELBO] estimate stale; spatial inconsistency (objects partially reconstructed) → compressor mask too aggressive; training instability → clip minimum to 1/16 of N_max; slow inference → verify router isn't being called multiple times.
- **First 3 experiments**: 1) Router sanity check: Plot ELBO(x) vs. optimal N_x on TokenBench validation set, verify correlation > 0.8. 2) Compressor ablation: Compare R2L, Jump, ELBO-based masking at BPP16=0.56 on 100 videos, expect PSNR gap of 1.5-2.0 dB. 3) Overhead measurement: Measure wall-clock latency for Cosmos baseline, InfoTok, ElasticTok on 33-frame videos, expect ratios of 1:2:20.

## Open Questions the Paper Calls Out

### Open Question 1
How do InfoTok's adaptive token sequences impact the performance and efficiency of large-scale downstream video generation and understanding models? The authors state that "investigating how InfoTok's adaptive token sequences impact the performance and efficiency of large-scale generative or video-understanding models remains a key direction for future work." This remains unresolved because the study evaluates quality via reconstruction fidelity rather than end-to-end task performance, which was beyond scope due to computational constraints.

### Open Question 2
Can the computational overhead of the ELBO-based router be eliminated by estimating information complexity directly from encoder latent representations? The authors identify the extra decoder pass as a limitation and suggest that "further research could explore lighter-weight router mechanisms, such as estimating complexity directly from the encoder's latent representations." This remains unresolved because the current implementation requires a full decoder pass to approximate ELBO; the feasibility of a "latent-only" estimator remains unproven.

### Open Question 3
Can the InfoTok framework be effectively generalized to non-visual modalities such as audio or 3D data? The authors propose that "applying InfoTok to develop adaptive tokenizers for audio, 3D, or other structured data presents a promising direction for future research." This remains unresolved because while the theory is agnostic to modality, the experiments are strictly confined to video; specific challenges in audio (e.g., silence) or 3D (e.g., geometric sparsity) were not tested.

## Limitations
- ELBO correlation assumptions may break down for videos with complex spatial but simple temporal structure
- Information redistributability assumption has limited empirical validation for extreme cases
- Theoretical optimality proofs assume idealized conditions that don't hold in practice

## Confidence

- **High confidence**: Base reconstruction quality claims (PSNR~30, FVD~49 at BPP16=1.0) - measured on established benchmarks with clear methodology
- **Medium confidence**: Adaptive compression superiority (1.5-2.0 dB PSNR gain over ElasticTok) - consistent gains but rely on ELBO correlation assumptions
- **Low confidence**: Theoretical optimality claims - proofs assume perfect reconstruction and known E[ELBO] that don't hold in practice

## Next Checks

1. **ELBO correlation validation**: Measure Pearson correlation between router-assigned N_x and true optimal token counts (found via exhaustive search) on TokenBench validation set. Target correlation > 0.8 for theoretical claims to hold.

2. **Information redistributability test**: Create synthetic videos with spatially sparse high-information regions (e.g., small moving objects) and test whether the compressor preserves these regions when N_x is constrained. Compare against a baseline that uses fixed positional masking.

3. **Domain generalization stress test**: Evaluate InfoTok on video domains not represented in training (e.g., medical imaging, surveillance footage) to test whether the ELBO-ELBO correlation breaks down outside the training distribution.