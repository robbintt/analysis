---
ver: rpa2
title: Analyzing Shapley Additive Explanations to Understand Anomaly Detection Algorithm
  Behaviors and Their Complementarity
arxiv_id: '2602.00208'
source_url: https://arxiv.org/abs/2602.00208
tags:
- anomaly
- diversity
- ensemble
- detection
- scores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of selecting complementary models
  for unsupervised anomaly detection ensembles. The core idea is to use SHapley Additive
  exPlanations (SHAP) to characterize the decision mechanisms of anomaly detectors,
  measuring similarity through feature attribution patterns rather than raw outputs.
---

# Analyzing Shapley Additive Explanations to Understand Anomaly Detection Algorithm Behaviors and Their Complementarity

## Quick Facts
- arXiv ID: 2602.00208
- Source URL: https://arxiv.org/abs/2602.00208
- Reference count: 25
- Primary result: SHAP-based diversity metrics outperform traditional output-based metrics in anomaly detection ensemble selection across 16 datasets

## Executive Summary
This study introduces a novel approach to selecting complementary models for unsupervised anomaly detection ensembles by leveraging SHapley Additive exPlanations (SHAP). The key insight is that detector complementarity can be assessed through feature attribution patterns rather than raw output correlations. The methodology demonstrates that SHAP-based diversity metrics consistently outperform traditional output-based metrics in ensemble selection, with 12 of 16 datasets showing positive diversity coefficients. The research establishes that while individual model quality remains the dominant factor in ensemble performance, diversity plays a significant secondary role that can rival model quality on certain datasets.

## Method Summary
The research proposes using SHAP explanations to characterize decision mechanisms of anomaly detectors, measuring similarity through feature attribution patterns rather than raw outputs. The methodology involves generating SHAP explanations for each detector's decisions, then using these explanations to compute diversity metrics (ρPS and ρNDCG) that capture the divergence in feature importance across models. These SHAP-based metrics are compared against traditional output-based diversity measures (ρScores and Jaccard similarity) in ensemble selection tasks. The approach is validated across 16 datasets, including both synthetic and real-world (KDDCup99) data, using ensemble voting schemes to combine detector outputs.

## Key Results
- SHAP-based diversity metrics (ρPS and ρNDCG) consistently outperform traditional output-based metrics in ensemble selection
- 12 of 16 datasets showed positive diversity coefficients, confirming diversity's value as a performance booster
- For some datasets, diversity's impact on ensemble performance rivaled that of individual model quality
- Detectors with similar SHAP explanations tend to produce correlated anomaly scores and overlapping predictions

## Why This Works (Mechanism)
The effectiveness stems from SHAP explanations capturing the underlying decision logic of each anomaly detector rather than just their final outputs. When detectors rely on similar features or patterns to make decisions, their SHAP explanations will show correlated feature attributions, indicating potential redundancy. Conversely, detectors with divergent SHAP patterns are likely examining different aspects of the data, making them complementary. This feature-level analysis provides a more nuanced understanding of detector relationships than simple output correlation, as detectors can arrive at similar conclusions through different reasoning paths.

## Foundational Learning
- **SHAP explanations**: Method for attributing model predictions to input features, needed to understand what drives each detector's decisions; quick check: verify SHAP values sum to model output
- **Anomaly detection ensembles**: Combining multiple detectors to improve robustness, needed because no single detector excels on all data distributions; quick check: ensure ensemble performance exceeds best individual detector
- **Diversity metrics**: Measures of difference between models, needed to quantify complementarity beyond simple accuracy; quick check: diversity should be high when models disagree but both are correct
- **Unsupervised learning evaluation**: Using ground truth for validation, needed since anomaly detection lacks labeled anomalies in practice; quick check: ensure ground truth is representative of true anomaly distribution
- **Feature attribution similarity**: Comparing how models weight input features, needed to assess decision mechanism overlap; quick check: correlation of SHAP values should reflect functional similarity

## Architecture Onboarding

**Component Map**
Synthetic Data Generator -> Anomaly Detectors (multiple) -> SHAP Explainer -> Diversity Metrics (ρPS, ρNDCG, ρScores, J) -> Ensemble Selector -> Ensemble Model

**Critical Path**
Detector outputs → SHAP explanations → Feature attribution matrices → Diversity computation → Ensemble selection → Final predictions

**Design Tradeoffs**
Computational cost vs. selection accuracy (SHAP adds overhead but improves selection quality), synthetic vs. real data (synthetic allows controlled experiments but may not capture real-world complexity), individual performance vs. diversity (balancing high-performing but similar models against diverse but potentially weaker models)

**Failure Signatures**
Ensemble performance degradation when diversity metrics are too low (redundant detectors), poor individual detector performance overwhelming diversity benefits, SHAP explanations failing to capture detector behavior due to non-linear or complex decision boundaries

**3 First Experiments**
1. Compare ensemble performance using only highest-scoring individual detectors versus diversity-aware selection
2. Measure correlation between SHAP-based diversity metrics and actual ensemble accuracy across datasets
3. Evaluate whether adding a detector with high SHAP-based diversity improves ensemble performance despite lower individual accuracy

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Heavy reliance on synthetic datasets limits generalizability to real-world scenarios
- Computational overhead of SHAP explanations may be prohibitive for large-scale deployments
- Evaluation depends on ground truth availability, which may not always be feasible in practice

## Confidence

| Claim | Confidence |
|-------|------------|
| SHAP-based diversity metrics correlate with ensemble performance improvements | High |
| Relative effectiveness of SHAP-based vs. output-based metrics across all dataset types | Medium |
| Diversity's impact can rival individual model quality in certain cases | Medium |

## Next Checks
1. Test SHAP-based selection approach on exclusively real-world, production anomaly detection datasets
2. Conduct computational efficiency analysis comparing SHAP-based selection to traditional methods
3. Evaluate performance when ground truth labels are partially or completely unavailable