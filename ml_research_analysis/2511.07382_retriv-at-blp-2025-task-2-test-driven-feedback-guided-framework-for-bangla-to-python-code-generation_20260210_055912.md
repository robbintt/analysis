---
ver: rpa2
title: 'Retriv at BLP-2025 Task 2: Test-Driven Feedback-Guided Framework for Bangla-to-Python
  Code Generation'
arxiv_id: '2511.07382'
source_url: https://arxiv.org/abs/2511.07382
tags:
- code
- bangla
- test
- cases
- python
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors propose a test-driven, feedback-guided iterative refinement
  approach for Bangla-to-Python code generation, combining instruction prompting with
  a fine-tuned Qwen2.5-14B model. Their method generates code from Bangla instructions,
  tests it against unit tests, and iteratively refines failing outputs through three
  evaluation passes using test feedback.
---

# Retriv at BLP-2025 Task 2: Test-Driven Feedback-Guided Framework for Bangla-to-Python Code Generation

## Quick Facts
- arXiv ID: 2511.07382
- Source URL: https://arxiv.org/abs/2511.07382
- Reference count: 19
- Result: 2nd place in BLP-2025 with Pass@1 of 0.934

## Executive Summary
This work proposes a test-driven, feedback-guided iterative refinement approach for Bangla-to-Python code generation, combining instruction prompting with a fine-tuned Qwen2.5-14B model. The method translates Bangla instructions to English using test-case-aware prompting, generates code, and iteratively refines failing outputs through three evaluation passes using test feedback. This approach achieved 2nd place in the BLP-2025 shared task with a Pass@1 score of 0.934. The work addresses challenges in Bangla instruction understanding and Python code generation for low-resource languages, demonstrating that careful translation, efficient fine-tuning, and test-case-aware inference can yield state-of-the-art performance with open-weight models.

## Method Summary
The system employs a four-component pipeline: a test-case-aware translator converts Bangla instructions to English, a QLoRA-adapted Qwen2.5-14B model generates Python code, and a feedback orchestrator executes unit tests to guide iterative refinement. The translator includes test cases in prompts to ensure semantic alignment, while the fine-tuning process combines the limited BLP-2025 training data with DeepMind MBPP samples. The inference loop runs up to three passes with escalating temperature (0.1→0.3→0.5), using execution feedback to correct off-by-one errors, edge cases, and format mismatches. The entire pipeline runs on a single RTX 3090 Ti using 4-bit QLoRA fine-tuning with rank 128 and scaling factor 128.

## Key Results
- Achieved 2nd place in BLP-2025 shared task with Pass@1 score of 0.934
- Feedback-guided inference improved Pass@1 by 4.44% over fine-tuning alone (0.90→0.934)
- QLoRA fine-tuning raised Pass@1 from 0.81 to 0.90 on development set
- Most corrections addressed off-by-one errors, edge cases, and output format alignment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Including test cases in the translation prompt improves semantic fidelity of Bangla-to-English instruction translation.
- Mechanism: By presenting the translator LLM with both the Bangla instruction and its associated English test cases (assert statements), the model can infer the intended functional behavior. This context helps disambiguate Bangla phrasing and resolve idioms against the expected input/output logic, producing a more semantically aligned English prompt for the code generator.
- Core assumption: The structure and literal values in the test cases provide sufficient signal to ground the translation, and the translator model is capable of cross-lingual reasoning between Bangla and code.
- Evidence anchors:
  - [abstract] "This work...includes a test-case-aware translation step to ensure semantic alignment with expected input-output behavior."
  - [Section 4.2] "For each instruction, the full test suite was included in the prompt, allowing the translator to align the natural language description with the intended input/output behavior."
- Break condition: Fails when Bangla idioms or loanwords lack clear English equivalents (e.g., "প্রতিদ্বন্দ্বিতা" mistranslated as "competition" instead of "reciprocal"), leading to semantically incorrect code. The feedback loop may not recover from these fundamental translation errors.

### Mechanism 2
- Claim: Parameter-efficient fine-tuning via QLoRA on a small dataset can significantly improve code generation performance for a specific low-resource language task.
- Mechanism: A high-capacity base model (Qwen2.5-14B) with strong multilingual and code capabilities is adapted using low-rank updates (QLoRA). By training on a mix of the limited task-specific data (74 training samples, 400 dev samples) and a supplementary dataset (DeepMind MBPP), the model learns the specific mapping between translated English instructions and correct Python code for this benchmark, without full retraining.
- Core assumption: The base model's pre-existing knowledge is sufficiently robust that low-rank adaptation can capture the task-specific nuances, and the small fine-tuning dataset is representative of the test distribution.
- Evidence anchors:
  - [abstract] "combining instruction prompting with a test-driven, feedback-guided iterative refinement approach using a fine-tuned Qwen2.5-14B model."
  - [Section 6.3] "Fine-tuning Qwen2.5-Coder-14B with QLoRA yielded a notable improvement, raising Pass@1 from 0.81 to 0.90."
- Break condition: Fails when the fine-tuning data is too scarce or non-representative, leading to overfitting. Hardware constraints limit exploration of higher-performance techniques (full LoRA, larger models).

### Mechanism 3
- Claim: An iterative inference loop using execution feedback can correct a significant portion of initial code generation errors.
- Mechanism: The system generates initial code, executes it against provided unit tests with a timeout, and on failure, re-prompts the model with the full error trace. This loop runs for up to three passes with increasing sampling temperature (0.1 → 0.3 → 0.5), encouraging the model to explore different solution paths based on concrete error signals (e.g., assertion failures, runtime errors).
- Core assumption: The generated code is "close to correct" (e.g., off-by-one errors, edge cases) and the error trace provides actionable diagnostic information the model can interpret to make targeted fixes. The model has intrinsic debugging capability.
- Evidence anchors:
  - [abstract] "iteratively refines failing outputs through three evaluation passes using test feedback to guide each step."
  - [Section 6.4] "Most recoveries came from correcting off-by-one errors, handling edge cases, or aligning outputs with expected formats."
- Break condition: Fails when errors stem from fundamental reasoning gaps or mistranslations, which the feedback loop cannot resolve. Also fails when error traces are uninformative, offering no useful signal for correction.

## Foundational Learning

- Concept: **Test-Driven Development (TDD) for LLMs**
  - Why needed here: This is the core operating principle of the system. Understanding that tests are used not just for evaluation, but as executable specifications to guide generation and correction, is essential.
  - Quick check question: Can you explain the difference between using tests to evaluate a final answer versus using them to guide intermediate steps?

- Concept: **Parameter-Efficient Fine-Tuning (PEFT) / QLoRA**
  - Why needed here: The system uses QLoRA to adapt a 14B parameter model under severe memory constraints (single RTX 3090 Ti). Understanding the trade-offs (rank, scaling factor, quantization) is necessary to modify or debug the training pipeline.
  - Quick check question: If you increase the LoRA rank `r` from 128 to 256, what is the primary trade-off you are making?

- Concept: **Prompt Engineering for Code Generation & Debugging**
  - Why needed here: System performance hinges on carefully designed prompts for translation, few-shot examples, and the feedback/retry loop. The paper explicitly notes that "prompt design was crucial" and was iteratively refined.
  - Quick check question: Why would you include test cases in a translation prompt rather than just the source and target text?

## Architecture Onboarding

- Component map: Bangla Instruction → Translator (Qwen2.5-Coder-14B) → Generator (fine-tuned Qwen2.5-Coder-14B) → Tests → (if failing) Feedback Orchestrator → Generator (retry)

- Critical path: The inference-time feedback loop is the most critical and fragile path. A failure in test execution, trace parsing, or re-prompting will prevent error correction and will cap system performance at the baseline generation level.

- Design tradeoffs: **Compute vs. Accuracy.** The three-pass feedback loop improves Pass@1 significantly (+4.44% over fine-tuning alone) but triples inference latency and compute cost per query. **Precision vs. Resource Constraints.** Using QLoRA (4-bit quantization) enables training on a single consumer GPU but may sacrifice performance compared to full-parameter fine-tuning.

- Failure signatures:
  - **Semantic Drift:** Code runs but produces logically incorrect results. Signature: High assertion failure rate, often consistent across retry passes. Root cause: Translation error or flawed initial reasoning.
  - **Stuck in Loop:** Retry passes fail with the same error. Signature: Error trace is identical or uninformative across attempts. Root cause: Model cannot interpret the error or the error is fundamental (e.g., wrong algorithm).
  - **Timeout/Execution Errors:** Code fails to run or times out. Signature: Runtime errors in trace. Root cause: Syntax errors, infinite loops, or missing imports.

- First 3 experiments:
  1.  **Ablate the Feedback Loop:** Run inference with and without the 3-pass feedback mechanism to directly measure its isolated contribution to Pass@1 on the development set.
  2.  **Stress-Test Translation:** Manually inspect and categorize translation errors on a sample of failed cases to identify systematic failure modes (idioms, loanwords, ambiguous phrasing).
  3.  **Vary Feedback Parameters:** Test the impact of different temperature schedules (e.g., fixed 0.1 vs. increasing 0.1→0.5) and number of retry passes (1, 2, 3, 5) to find the optimal balance between correction rate and latency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can specialized translation mechanisms (e.g., domain-aware translators or bilingual code vocabularies) reduce semantic drift for idiomatic Bangla expressions in code generation tasks?
- Basis in paper: [explicit] The translation error analysis demonstrates that idiomatic terms like "প্রতিদ্বন্দ্বিতা" were mistranslated as "competition" instead of "reciprocal," causing incorrect code logic. The conclusion states that improving translation fidelity for idiomatic Bengali expressions "remains a key challenge."
- Why unresolved: Current LLM-based translation lacks domain-specific grounding for mathematical/programming semantics in Bangla, and test-case-aware prompting only partially mitigates this.
- What evidence would resolve it: A comparative study measuring semantic drift rates across different translation strategies (e.g., gloss-augmented prompting, fine-tuned translators on code-specific parallel corpora) on a curated set of idiomatic Bangla instructions.

### Open Question 2
- Question: What types of reasoning errors in code generation remain fundamentally uncorrectable through iterative test-feedback, and what alternative mechanisms could address them?
- Basis in paper: [explicit] Section 6.4 states that "failures caused by mistranslations or deeper reasoning gaps were rarely resolved, underscoring the limits of inference-time self-correction."
- Why unresolved: The feedback loop depends on error trace interpretability; when the root cause is semantic misunderstanding rather than syntax/logic bugs, the model cannot self-correct.
- What evidence would resolve it: A taxonomy of failure modes after feedback-guided retries, followed by experiments with alternative mechanisms (e.g., chain-of-thought reasoning before generation, retrieval-augmented specification clarification).

### Open Question 3
- Question: How much performance gain would full-precision LoRA or larger-parameter models (e.g., 32B, 70B) provide over QLoRA-adapted 14B models for Bangla-to-Python code generation?
- Basis in paper: [explicit] The limitations section notes: "Hardware constraints restricted us to QLoRA fine-tuning on a single GPU, which prevented exploration of full-precision LoRA or larger models that could offer additional improvements."
- Why unresolved: The authors could not test whether quantization or model scale limits the capture of nuanced mappings from translated instructions to executable code.
- What evidence would resolve it: Controlled experiments comparing QLoRA vs. full LoRA at 14B, and comparing 14B vs. larger models (32B, 70B) with identical training data and evaluation protocols.

### Open Question 4
- Question: How does the quality and structure of error feedback affect correction success rates in iterative code refinement for low-resource language inputs?
- Basis in paper: [inferred] The limitations section states: "The feedback-guided inference loop depended on the quality of error traces. When tracebacks did not identify issues, retries seldom led to meaningful corrections."
- Why unresolved: The paper does not analyze which error trace characteristics (verbosity, localizability, specificity) correlate with successful self-correction, nor whether structured feedback formats improve outcomes.
- What evidence would resolve it: An ablation study varying feedback formats (raw tracebacks vs. summarized vs. structured natural language) and measuring correction success rates per format type.

## Limitations

- **Translation Semantic Drift:** Idiomatic Bangla expressions (e.g., "প্রতিদ্বন্দ্বিতা") are mistranslated, causing fundamental logic errors that the feedback loop cannot correct.
- **Hardware Constraints:** Single-GPU training limited exploration of full-precision LoRA or larger models that could offer additional improvements.
- **Feedback Loop Limits:** Error traces lacking actionable information rarely lead to meaningful corrections, especially for mistranslation-induced failures.

## Confidence

- **High Confidence:** The iterative refinement mechanism's effectiveness (supported by strong evidence from related work like PyBangla and BanglaForge, which use similar self-correction approaches).
- **Medium Confidence:** The contribution of QLoRA fine-tuning to performance (supported by direct ablation showing improvement from 0.81 to 0.90 Pass@1, but the specific choice of hyperparameters and its optimality are not thoroughly explored).
- **Low Confidence:** The claim that the translator model can reliably infer semantic alignment from test cases alone (evidence is largely theoretical, and the paper acknowledges systematic failures in handling Bangla idioms).

## Next Checks

1. **Ablate the Feedback Loop:** Run inference with and without the 3-pass feedback mechanism on the development set to directly measure its isolated contribution to Pass@1 and assess whether the performance gain justifies the increased latency and compute cost.

2. **Stress-Test Translation Robustness:** Conduct a systematic analysis of translation failures by manually inspecting and categorizing errors on a sample of failed cases, focusing on idiomatic expressions, loanwords, and ambiguous phrasing to identify systematic failure modes not addressed by the feedback loop.

3. **Vary Feedback Parameters:** Experiment with different temperature schedules (e.g., fixed 0.1 vs. increasing 0.1→0.5) and numbers of retry passes (1, 2, 3, 5) to determine the optimal balance between correction rate, inference latency, and computational cost, and to test the limits of the feedback mechanism's effectiveness.