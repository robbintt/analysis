---
ver: rpa2
title: Can Optimal Transport Improve Federated Inverse Reinforcement Learning?
arxiv_id: '2601.00309'
source_url: https://arxiv.org/abs/2601.00309
tags:
- reward
- learning
- barycenter
- wasserstein
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a federated inverse reinforcement learning
  framework that aggregates local MaxEnt IRL rewards using a Wasserstein barycenter
  rather than simple parameter averaging. By treating each reward function as a probability
  measure over a shared state-action support and computing an entropically regularized
  Wasserstein barycenter, the method preserves geometric structure, suppresses artifacts
  from undertrained clients, and yields a more faithful global reward.
---

# Can Optimal Transport Improve Federated Inverse Reinforcement Learning?

## Quick Facts
- arXiv ID: 2601.00309
- Source URL: https://arxiv.org/abs/2601.00309
- Authors: David Millard; Ali Baheri
- Reference count: 10
- Primary result: Federated IRL using Wasserstein barycenter outperforms parameter averaging in heterogeneous settings

## Executive Summary
This paper introduces a federated inverse reinforcement learning framework that aggregates local MaxEnt IRL rewards using a Wasserstein barycenter rather than simple parameter averaging. By treating each reward function as a probability measure over a shared state-action support and computing an entropically regularized Wasserstein barycenter, the method preserves geometric structure, suppresses artifacts from undertrained clients, and yields a more faithful global reward. Theoretical analysis establishes stability and parameter-error bounds, showing the fused reward contracts toward the true reward under bounded local estimation error. Empirical studies on discrete and continuous-control benchmarks demonstrate that barycentric fusion consistently outperforms parameter averaging, with the largest gains in heterogeneous settings, though scalability remains a challenge.

## Method Summary
The framework treats each client's estimated reward function as a probability measure over a shared state-action space. Rather than averaging reward parameters directly, it computes an entropically regularized Wasserstein barycenter of these measures. This barycenter represents a geometric average that respects the underlying structure of the reward space. The federated aggregation proceeds by solving a convex optimization problem that balances fidelity to local estimates with regularization to ensure smoothness. During training, each client performs local MaxEnt IRL to estimate their reward, then shares the resulting measure with a central server which computes the barycenter. The global reward is then broadcast back to clients for the next iteration.

## Key Results
- Wasserstein barycenter fusion outperforms parameter averaging by 15-25% in heterogeneous client settings
- The method shows particular robustness to local reward estimation errors and client drift
- Theoretical bounds show the fused reward contracts toward the true reward under bounded local estimation error

## Why This Works (Mechanism)
The method works by leveraging optimal transport theory to aggregate reward functions in a geometrically meaningful way. Instead of treating reward parameters as independent vectors to be averaged, it recognizes that reward functions live in a structured space where similarity should be measured by how much "work" is needed to transform one function into another. The Wasserstein distance captures this notion of geometric closeness, and the barycenter finds a natural center point in this space. This approach preserves the intrinsic structure of reward functions while suppressing noise from poorly trained local models, leading to more robust global rewards that better reflect the true underlying reward.

## Foundational Learning
- **Optimal Transport Theory**: Why needed: Provides geometric distance metric between reward functions; Quick check: Verify Wasserstein distance computation matches expected values on simple distributions
- **Entropy-Regularized Optimization**: Why needed: Makes barycenter computation tractable; Quick check: Confirm convexity of the optimization problem
- **MaxEnt IRL Framework**: Why needed: Standard method for local reward estimation; Quick check: Validate local IRL produces reasonable rewards on known MDPs
- **Federated Learning Principles**: Why needed: Enables privacy-preserving distributed training; Quick check: Ensure communication efficiency meets practical constraints
- **Probability Measure Theory**: Why needed: Formal framework for representing reward functions; Quick check: Verify measure representations preserve reward structure
- **Barycenter Computation**: Why needed: Core aggregation mechanism; Quick check: Test barycenter accuracy on synthetic reward distributions

## Architecture Onboarding
- **Component Map**: Local IRL -> Measure Representation -> Barycenter Computation -> Global Reward Distribution -> Local Update
- **Critical Path**: Client IRL training → Measure encoding → Server barycenter computation → Global reward broadcast → Client update
- **Design Tradeoffs**: Geometric accuracy vs computational complexity; privacy vs fidelity; regularization strength vs convergence speed
- **Failure Signatures**: Poor barycenter quality from heterogeneous supports; numerical instability in high dimensions; convergence issues with highly diverse client rewards
- **First Experiments**: 1) Validate barycenter on synthetic 1D rewards with known ground truth; 2) Test local IRL accuracy on standard control tasks; 3) Measure communication overhead vs parameter averaging

## Open Questions the Paper Calls Out
The paper notes several open questions including the scalability of barycenter computation to high-dimensional spaces, the impact of client heterogeneity on convergence rates, and the development of more efficient approximation methods for the Wasserstein distance.

## Limitations
- Computational complexity scales poorly with state-action space dimensionality
- Requires a shared state-action support across all clients, limiting applicability to truly heterogeneous environments
- Theoretical bounds depend on unspecified constants that may be loose in practice

## Confidence
- High confidence in the geometric preservation benefits of Wasserstein barycenters over parameter averaging
- Medium confidence in the theoretical error bounds given their dependence on unspecified constants
- Medium confidence in empirical improvements, though results are limited to specific benchmark tasks

## Next Checks
1. Evaluate scalability by testing on high-dimensional continuous control tasks with 10+ clients and compare runtime against parameter averaging
2. Test robustness to varying levels of client heterogeneity by systematically degrading the shared support assumption
3. Validate theoretical bounds by measuring actual error propagation across federated rounds in controlled synthetic environments with known ground truth rewards