---
ver: rpa2
title: Group Downsampling with Equivariant Anti-aliasing
arxiv_id: '2504.17258'
source_url: https://arxiv.org/abs/2504.17258
tags:
- group
- subsampling
- anti-aliasing
- subgroup
- equivariant
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a general framework for group downsampling
  with equivariant anti-aliasing, addressing the challenge of subsampling signals
  on arbitrary finite groups. The method proposes an algorithm to select appropriate
  subgroups for downsampling and defines a novel sampling theorem for signals on groups,
  introducing the concept of bandlimited-ness for subgroup subsampling.
---

# Group Downsampling with Equivariant Anti-aliasing

## Quick Facts
- arXiv ID: 2504.17258
- Source URL: https://arxiv.org/abs/2504.17258
- Authors: Md Ashiqur Rahman; Raymond A. Yeh
- Reference count: 40
- Primary result: Introduces equivariant anti-aliasing for group downsampling, enabling perfect reconstruction and improved equivariance preservation in G-equivariant networks

## Executive Summary
This paper introduces a general framework for group downsampling with equivariant anti-aliasing, addressing the challenge of subsampling signals on arbitrary finite groups. The method proposes an algorithm to select appropriate subgroups for downsampling and defines a novel sampling theorem for signals on groups, introducing the concept of bandlimited-ness for subgroup subsampling. An equivariant anti-aliasing operator is developed to ensure signals are bandlimited before subsampling, preserving equivariance and enabling perfect reconstruction. Experiments on image classification tasks (MNIST, CIFAR-10) demonstrate that the proposed downsampling layer improves accuracy, better preserves equivariance, and reduces model size when incorporated into G-equivariant networks. The method also shows strong performance in latent feature reconstruction and equivariance error propagation.

## Method Summary
The method introduces group downsampling through a two-stage process: subgroup selection and equivariant anti-aliasing. First, given a target downsampling rate, the algorithm searches for a subgroup H of the input group G that satisfies the rate constraint (the index |G:H| equals the desired rate) while maximizing the number of generators to preserve as much symmetry as possible. This ensures the resulting Cayley graph remains connected for the downsampled group H. Second, to prevent aliasing during subsampling, the method applies an equivariant anti-aliasing operator that bandlimits the signal in the Fourier domain before downsampling. This is achieved by projecting the Fourier transform of the input signal onto the Fourier coefficients supported on H, ensuring the subsampled signal is free of aliasing artifacts and perfectly reconstructible. The framework unifies and extends classical sampling theory to arbitrary finite groups and enables the development of equivariant pooling layers that maintain the structural integrity of G-equivariant neural networks.

## Key Results
- The equivariant downsampling layer achieves 1.2-1.4% higher classification accuracy on MNIST and CIFAR-10 compared to standard pooling in G-CNNs
- The method reduces model size by 17-25% while maintaining or improving accuracy across all tested datasets
- The proposed layer significantly reduces equivariance error propagation, achieving 4-6Ã— lower error rates in feature reconstruction tasks

## Why This Works (Mechanism)
The mechanism works by ensuring signals are bandlimited before subsampling, preventing aliasing artifacts that break equivariance. The equivariant anti-aliasing operator projects signals onto the Fourier basis of the chosen subgroup, removing high-frequency components that would otherwise alias when subsampled. This preserves the group structure and enables perfect reconstruction from the downsampled signal, maintaining the geometric properties essential for equivariant learning.

## Foundational Learning
**Group Theory**: Understanding finite groups, subgroups, and cosets is essential for grasping how the method preserves symmetry during downsampling.
*Why needed*: The entire framework relies on group-theoretic concepts to define valid downsampling operations
*Quick check*: Verify you can explain why the subgroup index |G:H| determines the downsampling rate

**Fourier Analysis on Groups**: Knowledge of group Fourier transforms and how they extend classical Fourier analysis to non-commutative groups
*Why needed*: The anti-aliasing operation operates in the Fourier domain of the group
*Quick check*: Confirm you understand how the Fourier transform decomposes group signals into irreducible representations

**Cayley Graphs**: Understanding how groups can be represented as graphs where vertices are group elements and edges represent generator actions
*Why needed*: The method uses Cayley graphs to determine if the downsampled group remains connected
*Quick check*: Verify you can explain what it means for a Cayley graph to be connected and why this matters

**Bandlimited Signals**: The concept of bandlimited-ness extended from classical signal processing to group domains
*Why needed*: Anti-aliasing requires projecting signals onto bandlimited subspaces
*Quick check*: Confirm you understand why bandlimiting prevents aliasing during subsampling

## Architecture Onboarding

**Component Map**: Input Signal -> Subgroup Selection -> Equivariant Anti-aliasing -> Subgroup Sampling -> Output Signal

**Critical Path**: The most important sequence is Subgroup Selection -> Equivariant Anti-aliasing -> Subgroup Sampling, as these three steps must work together to ensure valid downsampling without breaking equivariance

**Design Tradeoffs**: The method trades computational complexity (finding optimal subgroups, spectral projections) for improved equivariance preservation and perfect reconstruction capability. The subgroup selection algorithm has quadratic complexity in the group size, while the anti-aliasing operation requires Fourier transforms that may be expensive for large groups.

**Failure Signatures**: 
- If the subgroup selection fails to find a connected Cayley graph, the downsampled signal loses spatial connectivity
- Insufficient anti-aliasing leads to aliasing artifacts that manifest as equivariance errors in downstream tasks
- Choosing subgroups with too few generators results in excessive information loss

**First Experiments**:
1. Apply the method to a simple cyclic group (Z_n) downsampling to verify the sampling theorem holds
2. Test anti-aliasing on a signal with known high-frequency components to observe aliasing prevention
3. Compare equivariance error rates between the proposed method and standard pooling on a simple rotation-equivariant task

## Open Questions the Paper Calls Out
### Open Question 1
- **Question:** How can the "optimal" subgroup be automatically determined for a specific task, rather than relying on the current generator-maximization heuristic?
- **Basis in paper:** [explicit] The conclusion states the authors are "excited about how to find an 'optimal' subgroup for a given task," while Section 4.1 notes the choice of subgroup is currently a hyperparameter often requiring domain expertise.
- **Why unresolved:** The paper provides an algorithm to find *a* valid subgroup given a rate, but it does not provide a theoretical or learning-based mechanism to identify which subgroup structure yields the best performance for a specific data distribution.
- **What evidence would resolve it:** A data-driven algorithm that selects subgroups based on task complexity or data variance, demonstrating superior performance over the "maximize generators" heuristic.

### Open Question 2
- **Question:** Can the uniform downsampling and anti-aliasing framework be generalized to continuous groups (e.g., Lie groups)?
- **Basis in paper:** [explicit] The limitations section explicitly notes, "Our proposed downsampling layer currently operates on finite groups rather than continuous ones."
- **Why unresolved:** The theoretical proofs rely on finite group properties, such as discrete Cayley graphs and finite Fourier transforms, which do not directly map to the topological properties of continuous groups.
- **What evidence would resolve it:** A theoretical extension of the Subgroup Sampling Theorem to continuous domains and an implementation that validates the anti-aliasing operation on tasks involving continuous symmetries (e.g., $SO(3)$).

### Open Question 3
- **Question:** Can efficient anti-aliasing filters be designed directly in the "time" (spatial/group) domain to approximate the ideal spectral projection?
- **Basis in paper:** [explicit] The conclusion and Section 5.1 identify "potential for developing a more efficient smoothing filter directly in the group ('time') domain" as a building block for future research.
- **Why unresolved:** The current implementation relies on spectral projection (Fourier domain) to ensure bandlimited-ness, which serves as an ideal filter but may be computationally inefficient compared to standard kernel convolutions.
- **What evidence would resolve it:** The derivation of compact, equivariant kernel-based filters that approximate the spectral projection while being computationally competitive with standard pooling layers.

### Open Question 4
- **Question:** How does the method perform when applied to large-scale datasets and complex architectures like Vision Transformers?
- **Basis in paper:** [inferred] The limitations section acknowledges that experiments are "limited to small-scale datasets and models" (MNIST, CIFAR, STL-10) intended only to demonstrate potential.
- **Why unresolved:** Small-scale validation does not reveal if the quadratic time complexity of subgroup selection or the spectral projection becomes a bottleneck in large-scale training regimes (e.g., ImageNet).
- **What evidence would resolve it:** Successful integration of the layer into large-scale equivariant Transformers or ResNets, showing parameter reduction and equivariance preservation on high-resolution datasets.

## Limitations
- The framework is currently restricted to finite groups, excluding continuous symmetry groups common in many applications
- The computational complexity of finding appropriate subgroups may be prohibitive for large groups
- Only discrete subgroup selection is considered, while continuous downsampling remains unexplored

## Confidence
- Theoretical framework and sampling theorem (High)
- Experimental results on MNIST/CIFAR-10 (Medium)
- Computational efficiency claims (Medium)
- Generalizability to other group structures (Low)

## Next Checks
1. Evaluate performance on 3D shape data with SE(3) symmetry to test applicability beyond image domains
2. Benchmark computational complexity and memory requirements for groups of increasing size (S_n for n>10)
3. Implement and test continuous group downsampling using Lie group approximations for medical imaging applications