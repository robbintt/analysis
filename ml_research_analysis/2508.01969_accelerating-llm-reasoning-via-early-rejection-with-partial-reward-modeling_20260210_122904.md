---
ver: rpa2
title: Accelerating LLM Reasoning via Early Rejection with Partial Reward Modeling
arxiv_id: '2508.01969'
source_url: https://arxiv.org/abs/2508.01969
tags:
- early
- rejection
- arxiv
- reward
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates accelerating large language model (LLM)
  reasoning by introducing early rejection using partial reward modeling. The key
  idea is that process reward models (PRMs), which traditionally score completed reasoning
  steps, can also provide useful quality signals when applied mid-generation to partial
  outputs.
---

# Accelerating LLM Reasoning via Early Rejection with Partial Reward Modeling

## Quick Facts
- arXiv ID: 2508.01969
- Source URL: https://arxiv.org/abs/2508.01969
- Reference count: 40
- Early rejection with partial PRM scores reduces inference FLOPs by 1.4×–9× while preserving accuracy on math reasoning tasks

## Executive Summary
This paper introduces a method to accelerate LLM reasoning inference by using partial reward modeling for early rejection during beam search. The key insight is that Process Reward Models (PRMs), which traditionally score completed reasoning steps, can provide useful quality signals when applied to partial outputs mid-generation. This enables the early rejection of low-quality reasoning trajectories before full generation, saving compute. The authors demonstrate that partial PRM scores at surprisingly short prefixes (32-64 tokens) are strongly predictive of final scores, enabling significant computational savings while maintaining or even improving accuracy across math reasoning benchmarks.

## Method Summary
The approach extends traditional PRM-guided beam search by scoring partial outputs at intermediate generation steps rather than only at completion. During beam search, the model generates a prefix of τ tokens (32, 64, or 128), scores these prefixes using a PRM, and keeps only the top N/M beams for completion. Each remaining beam is then completed to a full step and expanded into M new beams. This two-tiered batching approach (larger batch for prefix generation, smaller for completion) enables significant FLOP savings by avoiding full generation of low-quality beams. The method is theoretically grounded with a proof that the probability of incorrectly discarding the optimal beam decreases exponentially with prefix length.

## Key Results
- Early rejection reduces inference FLOPs by 1.4×–9× across math reasoning benchmarks (SAT-MATH, Math-500, AIME) with no accuracy loss
- Partial PRM scores at 32-64 tokens show strong correlation (Pearson >0.8) with final scores
- Lightweight PRMs (1.5B) can match or exceed larger ones (7B) while enabling greater compute savings
- The method achieves higher accuracy than baseline in exploratory settings while reducing compute

## Why This Works (Mechanism)
Process Reward Models can assess reasoning quality from partial outputs because mathematical reasoning often contains sufficient signal early in the solution process. By scoring incomplete reasoning steps, the system can identify and reject low-quality trajectories before they consume full computational resources. The two-tiered batching approach optimizes GPU utilization by generating prefixes in large batches (exploiting parallelism) while keeping completion batches smaller (reducing memory pressure). The exponential decay in optimal beam retention probability with prefix length provides theoretical justification for early rejection.

## Foundational Learning
- **Process Reward Models (PRMs)**: Models that score intermediate reasoning steps rather than just final answers; needed to assess quality of partial reasoning; quick check: verify PRM outputs meaningful scores for incomplete solutions
- **Beam search with early rejection**: Standard beam search modified to prune low-quality beams mid-generation; needed to reduce computational waste; quick check: measure rejection rate per generation step
- **Two-tiered batching**: Separate batch sizes for prefix generation and completion phases; needed to balance parallelism and memory efficiency; quick check: monitor GPU memory usage across both phases
- **Partial sequence scoring**: Techniques for evaluating incomplete reasoning without biasing against ongoing thought processes; needed for meaningful mid-generation assessment; quick check: compare partial vs complete PRM scores on validation set
- **Exponential decay of error probability**: Theoretical property showing optimal beam retention improves with prefix length; needed to justify early rejection strategy; quick check: plot retention probability vs prefix length
- **FLOP calculation methodology**: Framework for estimating computational savings from early rejection; needed to quantify efficiency gains; quick check: validate FLOP estimates against actual token counts

## Architecture Onboarding
**Component map**: Generator LLM -> PRM scorer -> Beam selector -> Prefix generator -> Completion generator

**Critical path**: For each beam → generate τ tokens → PRM score → keep top N/M → complete to full step → expand by M new beams → repeat

**Design tradeoffs**: Longer prefixes (τ=128) provide more accurate PRM scores but reduce compute savings; larger N preserves more beams but increases computation; lighter PRMs save memory but may be less accurate; two-tiered batching reduces OOM risk but adds implementation complexity

**Failure signatures**: Accuracy degradation indicates insufficient prefix length or overly aggressive rejection; minimal FLOP savings suggests PRM scores lack discriminative power or rejection threshold is too high; OOM errors indicate batch sizes need reduction

**First experiments**:
1. Implement vanilla PRM-guided beam search (Algorithm 2) and validate accuracy on SAT-MATH with Llama-3.2-3B-Instruct
2. Add early rejection (Algorithm 3) with τ=64, N=16, M=4 and compare accuracy and estimated FLOPs
3. Sweep τ∈{32,64,128} and N∈{4,16,64} to find optimal tradeoff between accuracy preservation and FLOP reduction

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis assumes perfect partial reward prediction, not accounting for PRM errors or distributional shifts
- Experimental validation limited to three math reasoning benchmarks; unclear if approach generalizes to other reasoning domains
- FLOP reduction calculations don't include PRM inference overhead or complete energy analysis including memory management costs

## Confidence
- High confidence: Early rejection with partial PRM scores reduces inference FLOPs while preserving accuracy
- Medium confidence: Partial PRM scores at 32-64 tokens are sufficient for accurate quality prediction
- Medium confidence: Lightweight PRMs can match larger ones while enabling greater compute savings

## Next Checks
1. Test generalization to non-math reasoning tasks: Apply the early rejection framework to code generation benchmarks (HumanEval, MBPP) or logical reasoning datasets to verify that the correlation between partial and final rewards holds across different reasoning domains.

2. Conduct energy efficiency analysis: Measure actual wall-clock time and energy consumption (joules per task) including PRM inference costs, two-tiered batching overhead, and GPU memory management, to validate the claimed computational savings beyond theoretical FLOP reduction.

3. Perform robustness analysis with noisy PRMs: Systematically degrade PRM quality through label noise injection or model compression to quantify how partial reward prediction errors affect optimal beam retention rates and the exponential decay property claimed in the theoretical analysis.