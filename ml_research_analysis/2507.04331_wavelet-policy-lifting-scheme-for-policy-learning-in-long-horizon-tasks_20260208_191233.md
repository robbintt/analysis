---
ver: rpa2
title: 'Wavelet Policy: Lifting Scheme for Policy Learning in Long-Horizon Tasks'
arxiv_id: '2507.04331'
source_url: https://arxiv.org/abs/2507.04331
tags:
- learning
- wavelet
- policy
- tasks
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Wavelet Policy, a novel policy learning framework
  that leverages wavelet analysis and lifting schemes to improve performance on long-horizon
  tasks. The key innovation is decomposing observation sequences into multi-scale
  frequency components using learnable wavelet transforms, which helps capture both
  global trends and fine-grained details simultaneously.
---

# Wavelet Policy: Lifting Scheme for Policy Learning in Long-Horizon Tasks

## Quick Facts
- arXiv ID: 2507.04331
- Source URL: https://arxiv.org/abs/2507.04331
- Reference count: 40
- Primary result: Learnable wavelet transforms improve long-horizon policy learning performance across 5 simulation tasks

## Executive Summary
This paper introduces Wavelet Policy, a novel framework for long-horizon policy learning that leverages wavelet analysis and lifting schemes. The approach decomposes observation sequences into multi-scale frequency components using learnable wavelet transforms, enabling the policy to capture both global trends and fine-grained details simultaneously. The method addresses challenges in long-term tasks by maintaining consistency over extended horizons while focusing on critical changes at finer time resolutions. Evaluated across five simulation environments including CARLA self-driving, Franka kitchen manipulation, and multi-robot collaboration tasks, Wavelet Policy demonstrated superior or comparable performance to baseline approaches.

## Method Summary
Wavelet Policy replaces standard transformer architectures with a lifting scheme-based structure that performs multi-scale frequency decomposition. The architecture uses an Analysis Block (Split-Predict-Update) to recursively decompose input sequences into approximation streams (low-frequency global trends) and detail streams (high-frequency local changes). These streams are converted to action space and reconstructed hierarchically through Synthesis Blocks that progressively integrate details into coarse predictions. The learnable wavelet transforms are implemented as causal dilated convolutions for Predict and Update steps, with cross-attention serving as the fusion mechanism. The method includes regularization losses to enforce wavelet properties and causality constraints.

## Key Results
- Outperformed baseline methods in CARLA driving task with success rate of 0.847 vs 0.832-0.839 for competitors
- Improved performance in multi-modal behavior generation compared to standard approaches
- Learnable wavelet transforms demonstrated superior performance to fixed wavelets (Haar, DB2) and non-causal convolutions
- Achieved higher success rates in Franka kitchen manipulation tasks (T1: 0.953, T2: 0.902, T3: 0.941, T4: 0.958)

## Why This Works (Mechanism)

### Mechanism 1: Multi-Scale Frequency Decomposition
The architecture separates observation sequences into low-frequency (global trends) and high-frequency (fine details) components using the lifting scheme. This allows the policy to maintain long-horizon consistency via low-frequency components while retaining responsiveness via high-frequency components. The approach assumes optimal action sequences can be predicted more reliably by processing global trends and local details independently, segregating "noise" into specific frequency bands.

### Mechanism 2: Learnable Lifting Filters
Instead of fixed, hand-crafted wavelets, the Predict and Update steps in the lifting scheme are instantiated as neural networks (causal dilated convolutions). This allows the network to learn optimal wavelet basis functions for the specific observation-action mapping during training, adapting to task-specific data distributions rather than relying on heuristic wavelet selection.

### Mechanism 3: Coarse-to-Fine Action Synthesis
Actions are generated by progressively adding details (residuals) to a coarse baseline, easing the learning process compared to predicting raw actions directly. The Synthesis Block reconstructs action sequences hierarchically, starting from the coarsest approximation and progressively integrating detail streams. This mimics residual learning where the network predicts corrections rather than absolute values.

## Foundational Learning

- **Concept: Lifting Scheme (Wavelets)**
  - Why needed here: Mathematical backbone that creates frequency separation without fixed filters
  - Quick check question: How does the "Update" step use the "Detail" signal to refine the "Approximation" signal in a standard lifting scheme?

- **Concept: Causal Dilated Convolution**
  - Why needed here: Critical for maintaining temporal causality - the architecture must not access future information
  - Quick check question: If a convolution has kernel size 3 and dilation 2, which input time steps does it access to predict the output at time $t$?

- **Concept: Cross-Attention Mechanisms**
  - Why needed here: Used as the "Fuser" to recombine coarse and fine streams in the synthesis process
  - Quick check question: In the "Fuser" block, which stream serves as the Query ($Q$) and which serves as the Key/Value ($K, V$) to ensure the coarse signal guides the fusion?

## Architecture Onboarding

- **Component map:** Observation -> Splitter (Identity) -> Analysis Blocks (P,U causal conv) -> Converters -> Synthesis Blocks ($\hat{U},\hat{P}$) + Fuser (cross-attention) -> Action sequence

- **Critical path:** The Approximation Stream ($s$) preserves long-horizon trends. If the causal moving average constraint or recursive update steps fail here, the entire policy loses temporal coherence.

- **Design tradeoffs:**
  - Redundant Lifting vs. Standard Down-sampling: Uses "redundant lifting" (copying data) to handle variable lengths and merge issues, at cost of increased intermediate dimensionality
  - Learnable vs. Fixed Wavelets: Learnable P/U nets offer flexibility but require specific loss constraints to prevent degeneration into generic non-wavelet CNN

- **Failure signatures:**
  - Causality Breach: Performance degradation similar to "Conv" in Table 5 (e.g., T1 drops from 0.953 to 0.494)
  - High Variance: If Detail stream overpowers Approximation stream, robot exhibits "jittery" or high-frequency twitching without making progress

- **First 3 experiments:**
  1. Causality Verification: Run ablation from Table 5 (Causal vs. Non-Causal Conv) on Kitchen T1 to verify causal mask implementation
  2. Reconstruction Sanity Check: Input known sine-wave sequence and verify perfect reconstruction without Converters (testing Perfect Reconstruction property)
  3. Wavelet Baseline: Compare learnable P/U nets against fixed Haar wavelets on Push-T task to reproduce delta shown in Table 6

## Open Questions the Paper Calls Out

- **Question 1:** How does Wavelet Policy perform when transferred to physical robotic hardware, particularly regarding robustness against real-world sensor noise and control latency?
  - Basis: Evaluation conducted exclusively in simulation environments without physical validation
  - Why unresolved: Simulation benchmarks don't capture real-world dynamics like actuator drift or visual artifacts
  - What evidence would resolve it: Success rates and stability metrics from deploying on physical Franka arms or autonomous vehicles

- **Question 2:** Do the learnable predict ($P$) and update ($U$) networks converge to classical wavelet basis functions, or do they learn task-specific time-frequency features lacking standard mathematical properties?
  - Basis: Paper shows superior performance to fixed wavelets but doesn't analyze resulting filter shapes or frequency responses
  - Why unresolved: Unclear if performance gain comes from "better" standard wavelets or overfitting to dataset artifacts
  - What evidence would resolve it: Visualization of learned impulse responses and frequency analysis compared to standard Daubechies or Haar wavelets

- **Question 3:** What are the computational trade-offs regarding inference latency and memory usage when increasing decomposition levels ($L$) for extremely long horizons?
  - Basis: Method proposes redundant lifting scheme but experiments don't report wall-clock times or memory footprints against baselines
  - Why unresolved: Multiple Transformers at every scale could introduce overhead negating benefits for real-time control
  - What evidence would resolve it: Complexity analysis comparing inference speed and GPU memory consumption as sequence length scales

## Limitations

- Critical hyperparameters including number of lifting scales, kernel sizes/dilation rates, and moving average window size are not specified, making direct reproduction challenging
- Claim of universal superiority of learnable wavelets over fixed wavelets lacks qualification about data requirements and training stability
- Performance benefits may depend heavily on the specific regularization loss weights (α, β) which are not thoroughly explored

## Confidence

- **High confidence:** Core mathematical framework of lifting scheme and its application to policy learning is sound and well-supported by signal processing theory
- **Medium confidence:** Empirical results showing performance improvements over baselines are convincing, though direct comparison limited by missing hyperparameter details
- **Low confidence:** Claim that learnable wavelets are universally superior to fixed wavelets without qualification about data requirements and training stability

## Next Checks

1. Implement and verify the causal masking mechanism by reproducing the Table 5 ablation showing performance degradation when causality is violated
2. Conduct hyperparameter sensitivity analysis on loss weights (α, β) for approximation and detail regularization terms to establish robustness bounds
3. Test architecture on simpler benchmark (e.g., Push-T) with fixed Haar wavelets to quantify performance gap and determine whether benefit justifies added complexity of learnable filters