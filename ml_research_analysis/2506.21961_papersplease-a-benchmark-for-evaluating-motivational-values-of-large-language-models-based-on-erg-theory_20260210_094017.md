---
ver: rpa2
title: 'PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language
  Models Based on ERG Theory'
arxiv_id: '2506.21961'
source_url: https://arxiv.org/abs/2506.21961
tags:
- llms
- social
- scenarios
- human
- moral
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces PapersPlease, a benchmark of 3,700 role-playing\
  \ immigration scenarios to evaluate how large language models (LLMs) prioritize\
  \ human needs based on ERG theory. The scenarios embed three motivational values\u2014\
  Existence, Relatedness, and Growth\u2014along with social identity cues like gender,\
  \ race, and religion."
---

# PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language Models Based on ERG Theory

## Quick Facts
- arXiv ID: 2506.21961
- Source URL: https://arxiv.org/abs/2506.21961
- Reference count: 9
- Primary result: PapersPlease benchmark reveals LLM biases in motivational prioritization and social identity

## Executive Summary
This paper introduces PapersPlease, a benchmark of 3,700 role-playing immigration scenarios designed to evaluate how large language models prioritize human needs based on ERG theory. The scenarios embed three motivational values—Existence, Relatedness, and Growth—along with social identity cues like gender, race, and religion. Six LLMs were evaluated under three settings: individual decisions, comparative prioritization, and social identity impact. Results show statistically significant differences in motivational prioritization across models, with some aligning more closely with ERG theory than others. Social identity cues influenced decisions, revealing biases against marginalized groups in certain models. The findings highlight the need for more nuanced evaluation of LLM alignment with human values and social fairness.

## Method Summary
PapersPlease consists of 3,700 immigration scenario questions where LLM agents must decide whether to admit applicants based on embedded motivational values (Existence, Relatedness, Growth) and social identity cues. The benchmark evaluates LLMs across three experimental settings: (1) individual decision-making tasks, (2) comparative prioritization between values, and (3) social identity impact assessment. Six different LLMs were tested using this framework to measure their alignment with ERG theory and identify potential biases in motivational reasoning.

## Key Results
- LLMs show statistically significant differences in how they prioritize Existence, Relatedness, and Growth values
- Some models align more closely with ERG theory than others in motivational decision-making
- Social identity cues (gender, race, religion) influenced LLM decisions, revealing biases against marginalized groups

## Why This Works (Mechanism)
PapersPlease works by embedding complex human motivational values within structured role-playing scenarios that require LLM agents to make decisions reflecting underlying psychological priorities. The immigration context provides a controlled environment where multiple motivational needs compete, allowing systematic measurement of how models weigh different value systems. By incorporating social identity markers, the benchmark reveals how these underlying value hierarchies interact with societal biases, exposing both motivational reasoning patterns and potential discrimination in model outputs.

## Foundational Learning
- ERG Theory: Existence, Relatedness, and Growth needs framework (why needed: provides theoretical foundation for measuring motivational values; quick check: verify understanding of how these three needs differ from Maslow's hierarchy)
- Role-playing evaluation methodology: Using simulated scenarios to assess model behavior (why needed: creates controlled conditions for measuring complex value judgments; quick check: understand how scenario design affects model responses)
- Social identity bias measurement: Quantifying how demographic markers influence decision outcomes (why needed: identifies potential discrimination patterns in LLM outputs; quick check: grasp statistical methods for detecting bias significance)

## Architecture Onboarding

**Component map:**
PapersPlease Benchmark -> Scenario Generation -> LLM Input -> Decision Output -> Value Scoring -> Statistical Analysis

**Critical path:**
Scenario Generation → LLM Input → Decision Output → Value Scoring → Statistical Analysis → Result Interpretation

**Design tradeoffs:**
- Scenario complexity vs. evaluation tractability: More nuanced scenarios provide richer data but increase analysis complexity
- Value explicitness vs. model reasoning: More explicit value cues may lead to less authentic motivational reasoning
- Social identity inclusion vs. ethical concerns: Including demographic markers reveals biases but raises questions about reinforcement

**Failure signatures:**
- Models consistently favoring one value regardless of context suggests poor motivational discrimination
- Uniform treatment across all social identities may indicate over-correction or lack of nuanced understanding
- Random or inconsistent value prioritization across similar scenarios suggests unreliable motivational reasoning

**First experiments:**
1. Run baseline evaluation with neutral scenarios lacking social identity cues to establish pure motivational patterns
2. Test model responses to scenarios with conflicting high-priority values to assess decision-making under pressure
3. Compare results across different prompt formulations to measure sensitivity to instruction framing

## Open Questions the Paper Calls Out
None

## Limitations
- ERG theory may not fully capture the complexity of human needs or LLM reasoning processes
- The 3,700 scenarios, while extensive, may not represent all possible motivational conflicts or social identity intersections
- Observed biases could be artifacts of training data or specific scenarios rather than inherent model properties

## Confidence

**Major claims:**
- LLM motivational prioritization differences: Medium
- Alignment with ERG theory varies across models: Medium  
- Social identity cues influence decisions: Medium

## Next Checks
1. Expand the benchmark to include scenarios based on alternative motivational theories (e.g., Maslow's hierarchy, Self-Determination Theory) to test robustness across frameworks
2. Conduct ablation studies by removing social identity cues from scenarios to quantify their specific contribution to observed biases
3. Test a broader set of LLMs, including those with different training paradigms (e.g., instruction-tuned, RLHF), to determine if the patterns hold across model families