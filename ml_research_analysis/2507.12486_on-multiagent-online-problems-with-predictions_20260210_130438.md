---
ver: rpa2
title: On multiagent online problems with predictions
arxiv_id: '2507.12486'
source_url: https://arxiv.org/abs/2507.12486
tags:
- algorithm
- competitive
- predictions
- algorithms
- case
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies competitive online games with predictions, introducing
  a two-predictor framework where agents use one predictor for their own future behavior
  and another for others' behavior. The main focus is on a multiagent ski-rental problem
  where agents can pool resources to buy a group license or rent individually.
---

# On multiagent online problems with predictions

## Quick Facts
- arXiv ID: 2507.12486
- Source URL: https://arxiv.org/abs/2507.12486
- Reference count: 34
- Key outcome: Introduces two-predictor framework for multiagent online games; proposes λ-parameterized algorithm with consistency-robustness trade-off; achieves (B+1)-competitive ratio without predictions, improving to as low as 1 with perfect others' predictions.

## Executive Summary
This paper studies competitive online games where agents have access to predictions about their own future behavior and others' behavior. The main focus is on a multiagent ski-rental problem where agents can pool resources to buy a group license or rent individually. The authors introduce a two-predictor framework that separates uncertainty about self behavior from uncertainty about others' behavior, enabling independent optimization of consistency-robustness trade-offs. They prove that without predictions or with pessimal predictors, the optimal competitive ratio is B+1, but with perfect others' predictions, optimal algorithms can achieve ratios as low as 1. The paper proposes a λ-parameterized algorithm that interpolates between optimal and predictor-following behavior, trading off consistency for robustness, and demonstrates through experiments that the algorithm performs reasonably well under random prediction noise.

## Method Summary
The paper studies a multiagent ski-rental problem where agents pool pledges to buy a group license (cost B) or rent individually at 1/day. Each agent uses two predictors: a self-predictor for own active time T and an others-predictor for aggregate opponent pledges. The λ-parameterized algorithm (Algorithm 2) computes two candidate purchase days r2 and r3 based on the predictors, buying on r2 if predicted active time exceeds threshold, otherwise on r3. The algorithm is proven to be (λ-1 + 1/λ · cOPT(p))-competitive, interpolating between robustness (λ=1) and consistency (λ→0). Experiments use B=100, T~Uniform[1,400], predictions bT=T+N(0,σ), and prices in [B-⌊zB⌋,B] with 1000 samples per σ value.

## Key Results
- Without predictions or with pessimal predictors, the optimal competitive ratio is B+1
- With perfect others' predictions, optimal algorithms depend on price sequences and can achieve ratios as low as 1
- The λ-parameterized algorithm interpolates between optimal and predictor-following behavior, trading off consistency for robustness, with λ-parameterized guarantees
- Experiments show the algorithm performs reasonably well under random prediction noise, similar to prior work

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A two-predictor framework decouples uncertainty about self behavior from uncertainty about others' behavior, enabling independent optimization of consistency-robustness trade-offs.
- Mechanism: Each agent maintains separate predictors—a self-predictor si: N → {0,1} for own stopping time and an others-predictor oi: N → Pf(Γ-i) for aggregate opponent actions. This factorization allows competitive analysis to treat "known varying prices" (when others' predictions are perfect) as a single-agent problem.
- Core assumption: Prediction errors are independent; self-mispredictions don't cascade into others-prediction errors.
- Evidence anchors:
  - [abstract] "We introduce a two predictor framework, that assumes that agents use one predictor for their future (self) behavior, and one for the behavior of the other players."
  - [Section 2.1] Formal definitions of si and oi as monotonically decreasing functions with finite-set predictions.
  - [corpus] Weak corpus evidence for this specific factorization; related work focuses on single-agent predictions or multiagent learning without explicit prediction separation.
- Break condition: Correlated prediction errors (e.g., if opponent behavior directly influences agent's stopping time through strategic coupling) violate the independence assumption.

### Mechanism 2
- Claim: When others' predictions are perfect, the multiagent problem reduces to single-agent ski-rental with known varying prices, where optimal buying days are characterized by minimizing Pr/OPTr ratios.
- Mechanism: Perfect others' predictions reveal the daily pledge deficit B - bp(k), giving known "buying prices" pt. The agent computes r1(p) = argmin(Pr/OPTr) and buys when self-predicted activity time exceeds threshold M*(p).
- Core assumption: Others' predictions correctly anticipate all opponent pledge amounts at each time step.
- Evidence anchors:
  - [Section 4] "Since the agent learns (via the others' predictor) what the other agents will pledge...it knows how much money it would need to contribute on any given day to make the group license feasible."
  - [Theorem 3] Formal characterization: cOPT(p) = min({Pr/r : r ≤ M*(p)} ∪ {QM*(p)/M*(p)}).
  - [corpus] Corpus papers on learning-augmented algorithms (e.g., AdaSwitch, Minimax-MDP) address prediction integration but not this specific reduction.
- Break condition: Adversarial or systematic errors in others' predictions break the reduction; the paper explicitly notes this limitation in Section 8.

### Mechanism 3
- Claim: The λ-parameterized algorithm (Algorithm 2) interpolates between robustness (λ=1, behaving as if predictions are useless) and consistency (λ→0, trusting predictions), with competitive ratio bounded by λ - 1 + (1/λ)cOPT(p).
- Mechanism: Compute r2 = first day ≥ ⌈(1-λ)(r0-1) + λr1⌉ minimizing Pr2 - λ·OPTr2. When self-predicted time bT ≥ M*(p), buy on day r2; otherwise buy on day r3 optimizing robustness. Lower λ shifts purchase earlier toward r0 (minimum price day).
- Core assumption: The convex combination (1-λ)(r0-1) + λr1 meaningfully trades off the two extremes; prices don't fluctuate so wildly that intermediate days are strictly worse than endpoints.
- Evidence anchors:
  - [Section 6, Algorithm 2] Explicit pseudocode for r2 and r3 computation.
  - [Theorem 6] Competitive ratio guarantee: cA(p,T;bT) ≤ λ - 1 + (1/λ)cOPT(p).
  - [Example 1] For fixed-price ski-rental, recovers identical (1+λ)-consistency as prior work [KPS18].
  - [corpus] Related algorithms (AdaSwitch) use switching mechanisms rather than convex interpolation.
- Break condition: Non-monotonic price sequences where intermediate days have arbitrarily worse Pr/OPTr than endpoints could violate the smooth trade-off; Lemma 5 partially addresses this but requires no "free days" before M*(p)+1.

## Foundational Learning

- Concept: Competitive analysis of online algorithms
  - Why needed here: The entire framework evaluates algorithms by worst-case ratio cost(ALG)/cost(OPT) rather than expected performance. Understanding that competitive ratio is a min-max guarantee (not average-case) is essential.
  - Quick check question: Why is the (B+1)-competitive algorithm optimal even though it sometimes pays much more than necessary?

- Concept: Consistency vs. robustness trade-off in learning-augmented algorithms
  - Why needed here: The λ parameter explicitly controls this trade-off. Without understanding that consistency measures performance under perfect predictions while robustness measures performance under adversarial errors, the algorithm design appears arbitrary.
  - Quick check question: If an algorithm is 1-consistent and γ-robust, what happens when predictions have 50% error?

- Concept: Ski-rental problem fundamentals
  - Why needed here: The multiagent extension inherits core structure from classical ski-rental. Knowing that the baseline optimal strategy is "rent until day B, then buy" provides the foundation for understanding how predictions modify this.
  - Quick check question: In classical ski-rental with buy price B, why can no deterministic algorithm beat competitive ratio e/(e-1)?

## Architecture Onboarding

- Component map:
  - Predictor module: Two sub-modules (self-predictor, others-predictor) generating bT (predicted active time) and bp(k) (predicted opponent pledges per day)
  - Decision engine: Takes predictions + current day k, computes r2(λ,p) and r3(λ,p) per Algorithm 2, outputs pledge amount (0 or B - bp(k) for rational algorithms)
  - Cost tracker: Monitors cumulative spending, detects license acquisition (when total pledges ≥ B)
  - λ-controller: Externally set parameter governing consistency-robustness trade-off

- Critical path:
  1. Initialize: Receive λ, initialize day counter k=1
  2. Query predictors: Get bT (self) and bp(k) (others for current day)
  3. Compute threshold: If Case (a) of Theorem 2 applies (bargain/free day exists), wait for it. Otherwise compute r2, r3
  4. Decision: If bT ≥ M*(p), pledge B - bp(k) on day r2. Else pledge on day r3
  5. Observe outcome: Learn if license acquired; if not, increment k and repeat

- Design tradeoffs:
  - Small λ: Better consistency (trusts predictions), worse robustness (vulnerable to prediction errors). Risk: large losses when self-predictor overestimates active time
  - Large λ: Better robustness, worse consistency. Safe but may miss collaboration opportunities
  - Assumption: The paper assumes deterministic, non-adaptive algorithms; extending to probabilistic or adaptive algorithms (noting future work in Section 9) would require different analysis

- Failure signatures:
  - Competitive ratio approaching B+1 despite predictions: Indicates λ too high or predictions highly erroneous
  - Unbounded competitive ratio (robustness failure): Occurs if f2(p)=∞ in Theorem 5 terms—algorithm never buys when self-predictor underestimates T
  - License never acquired despite repeated pledges: Others-predictor systematically overestimates opponent contributions

- First 3 experiments:
  1. Replicate Figure 1 baseline: Set B=100, T~Uniform[1,400], bT=T+N(0,σ), prices random in [B-⌊zB⌋,B]. Plot average competitive ratio vs. σ for λ∈{0.2,1.0}, z∈{0,0.5,1.0}. Validate that noise tolerance degrades gracefully.
  2. Adversarial others test: Generate price sequences designed to maximize Pr/OPTr at intermediate days (non-monotonic prices). Test whether Lemma 2's monotonicity still holds approximately.
  3. Strategic coupling test: Introduce correlation between self and others' prediction errors (e.g., both overestimate when others actually pledge more). Measure deviation from theoretical bounds; this directly tests the independence assumption in Mechanism 1.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can a meaningful error parameter be defined for the others' predictor (sequence of prices) to allow for the analysis of intermediate regimes between perfect and pessimal predictions?
- Basis in paper: [explicit] Page 8 states, "The major limitation of our results is the lack of an intermediate regime of error for the others’ predictor. The difficult issue is how to define a meaningful 'error parameter' for a sequence of prices Pi."
- Why unresolved: The current theoretical framework and experimental setup only handle the binary extremes of perfect or pessimal others' predictions, unlike the self-predictor which allows for a noise parameter $\mu$.
- What evidence would resolve it: A formal error metric quantifying the deviation between predicted and actual aggregate pledges, alongside an algorithm with competitive bounds that degrade smoothly as this error increases.

### Open Question 2
- Question: How can a formal notion of competitive ratio equilibria with predictions be defined and characterized in this multiagent setting?
- Basis in paper: [explicit] Page 9 notes, "In subsequent work we build upon these results by defining a notion of equilibria with predictions," and Page 3 states, "We defer, however, a formal treatment of equilibria with predictions to subsequent work."
- Why unresolved: The paper focuses on the single-agent perspective of best-responding to others' behaviors, but has not yet modeled the game-theoretic stability or fixed points of strategy profiles where every agent uses such predictors.
- What evidence would resolve it: A formal definition of equilibrium for competitive online games with predictions and an analysis of whether the proposed algorithms constitute such an equilibrium.

### Open Question 3
- Question: Does the two-predictor framework remain robust if predictions are adaptive and depend on previous game history?
- Basis in paper: [explicit] Page 9 lists "allowing predictions to be adaptive (i.e. depend on previous interactions) is an open problem."
- Why unresolved: The current model assumes predictors provide advice based on future states without explicitly modeling a feedback loop where the prediction algorithm learns from the outcomes of previous game rounds.
- What evidence would resolve it: An analysis of convergence or stability in a repeated game setting where the predictors update their strategies based on past agent utilities or actions.

### Open Question 4
- Question: Can the deterministic competitive ratio guarantees for multiagent ski-rental be improved or replicated using probabilistic algorithms?
- Basis in paper: [explicit] Page 9 states, "Our results deal with deterministic algorithms. Extending the results to probabilistic ones is an interesting challenge."
- Why unresolved: The proofs provided rely on deterministic threshold functions and worst-case analysis; the structure of optimal randomized strategies in the two-predictor model is unknown.
- What evidence would resolve it: A competitive analysis of a randomized algorithm showing either improved ratios or equal robustness with better consistency compared to the deterministic $\lambda$-parameterized algorithm.

## Limitations

- The independence assumption between self and others' prediction errors is fundamental but largely untested and may not hold in strategic settings
- The choice of λ = 0.2 as the representative consistency-oriented setting appears arbitrary without sensitivity analysis
- Experimental results are limited to one noise model (Gaussian) and specific parameter settings without ablation studies
- No formal treatment of equilibria with predictions is provided, limiting game-theoretic understanding

## Confidence

- Mechanism 1 (two-predictor framework): Medium - The theoretical decomposition is sound, but independence assumption lacks empirical validation
- Mechanism 2 (reduction to single-agent when others' predictions perfect): High - Formal proof provided with clear mathematical characterization
- Mechanism 3 (λ-parameterized interpolation): Medium - Theoretical guarantees established, but practical sensitivity to λ choice unclear
- Experimental results: Low-Medium - Limited to one noise model and specific parameter settings; lack of ablation studies

## Next Checks

1. Test correlated prediction errors by introducing strategic coupling between self and others' predictors, measuring degradation of theoretical bounds
2. Perform systematic λ-sensitivity analysis across multiple price distributions to determine optimal λ values for different scenarios
3. Implement alternative prediction error models (systematic bias, structural errors) beyond Gaussian noise to assess algorithm robustness