---
ver: rpa2
title: 'BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese
  Medicine'
arxiv_id: '2510.17415'
source_url: https://arxiv.org/abs/2510.17415
tags:
- bencao
- reasoning
- language
- clinical
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BenCao, a ChatGPT-based multimodal assistant
  for Traditional Chinese Medicine (TCM) that addresses the challenge of applying
  large language models to TCM's holistic and multimodal diagnostic reasoning. BenCao
  is developed through natural language instruction tuning rather than parameter retraining,
  integrating over 1,000 classical and modern TCM texts, a scenario-based instruction
  framework, chain-of-thought simulation for interpretable reasoning, and expert feedback
  refinement from licensed TCM practitioners.
---

# BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese Medicine

## Quick Facts
- arXiv ID: 2510.17415
- Source URL: https://arxiv.org/abs/2510.17415
- Reference count: 20
- BenCao achieves superior accuracy compared to general-domain and TCM-domain models in diagnostics, herb recognition, and constitution classification

## Executive Summary
BenCao is a ChatGPT-based multimodal assistant for Traditional Chinese Medicine (TCM) that addresses the challenge of applying large language models to TCM's holistic and multimodal diagnostic reasoning. The system is developed through natural language instruction tuning rather than parameter retraining, integrating over 1,000 classical and modern TCM texts. It connects to external APIs for tongue-image classification and multimodal database retrieval, enabling dynamic access to diagnostic resources.

The model achieved superior accuracy compared to general-domain and TCM-domain models, particularly in diagnostics, herb recognition, and constitution classification. BenCao was deployed on the OpenAI GPTs Store, accessed by nearly 1,000 users globally, demonstrating its practical applicability and feasibility as a scalable pathway for real-world deployment of TCM-domain LLMs.

## Method Summary
BenCao was developed through natural language instruction tuning of a base model rather than parameter retraining. The approach integrated over 1,000 classical and modern TCM texts into a scenario-based instruction framework. Chain-of-thought simulation was implemented for interpretable reasoning, and the system was refined through expert feedback from licensed TCM practitioners. External APIs were connected for tongue-image classification and multimodal database retrieval to enable dynamic access to diagnostic resources.

## Key Results
- Superior accuracy compared to general-domain and TCM-domain models in TCM diagnostics
- Strong performance in herb recognition and constitution classification tasks
- Successful deployment on OpenAI GPTs Store with nearly 1,000 global users

## Why This Works (Mechanism)
BenCao's effectiveness stems from its instruction-tuning approach that preserves the base model's capabilities while adapting to TCM-specific knowledge domains. The integration of chain-of-thought simulation enables interpretable reasoning pathways for complex TCM diagnostics. Expert feedback refinement ensures clinical accuracy and relevance, while multimodal API integration extends the system's diagnostic capabilities beyond text-based analysis.

## Foundational Learning

**Instruction Tuning**: Why needed - Adapts pre-trained models to specific tasks without full retraining; Quick check - Verify fine-tuning preserves base capabilities while improving task-specific performance

**Chain-of-Thought Reasoning**: Why needed - Provides interpretable reasoning pathways for complex diagnostic tasks; Quick check - Validate that intermediate reasoning steps align with established TCM diagnostic principles

**Multimodal Integration**: Why needed - TCM diagnostics often involve multiple data types (text, images, patient data); Quick check - Test API response reliability and latency under varying conditions

**Expert Feedback Refinement**: Why needed - Ensures clinical accuracy and practical utility in real-world TCM applications; Quick check - Validate refinements through blinded practitioner evaluation

## Architecture Onboarding

**Component Map**: User Input -> Instruction Tuned LLM -> External API Services (Tongue Classification, Database Retrieval) -> Expert Feedback Module -> Output Generation

**Critical Path**: User query → LLM processing → API calls (if multimodal) → Response generation → Expert validation (training phase)

**Design Tradeoffs**: Instruction tuning vs. full parameter retraining balances adaptation with preserving base model capabilities; external API integration provides flexibility but introduces dependencies and potential latency issues

**Failure Signatures**: Inaccurate diagnoses when API services are unavailable; reduced performance on tasks outside training scope; potential hallucinations in response to novel queries

**First Experiments**:
1. Baseline accuracy testing on internal TCM diagnostic benchmarks
2. API integration testing for tongue image classification reliability
3. User experience evaluation with licensed TCM practitioners

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Evaluation framework relies on custom datasets that may not fully represent real-world clinical complexity
- Performance claims based on internal testing rather than independent validation
- Deployment occurred in limited-access setting that may not reflect broader clinical or commercial scalability

## Confidence

**High confidence**: Technical implementation approach (instruction tuning methodology, integration of external APIs, expert feedback refinement) is sound and well-documented

**Medium confidence**: Performance claims relative to baseline models, as these are based on internally developed benchmarks without independent verification

**Medium confidence**: Clinical applicability assessments, given the limited deployment scope and absence of formal clinical validation studies

## Next Checks

1. Independent replication of benchmark results using external datasets and standardized evaluation protocols
2. User studies with licensed TCM practitioners to assess diagnostic accuracy and practical utility in controlled clinical scenarios
3. Systematic evaluation of multimodal response latency and reliability under varying network conditions and API availability scenarios