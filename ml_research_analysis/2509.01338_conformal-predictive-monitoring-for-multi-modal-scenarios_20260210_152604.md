---
ver: rpa2
title: Conformal Predictive Monitoring for Multi-Modal Scenarios
arxiv_id: '2509.01338'
source_url: https://arxiv.org/abs/2509.01338
tags:
- mode
- trajectories
- robustness
- prediction
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GenQPM, a method for quantitative predictive
  monitoring (QPM) of stochastic systems with multi-modal dynamics. GenQPM combines
  score-based diffusion models with conformal inference to generate mode-specific
  prediction intervals for STL robustness values.
---

# Conformal Predictive Monitoring for Multi-Modal Scenarios

## Quick Facts
- arXiv ID: 2509.01338
- Source URL: https://arxiv.org/abs/2509.01338
- Reference count: 37
- Primary result: GenQPM achieves up to 50% narrower prediction intervals than mode-agnostic baselines while maintaining 90% coverage guarantees

## Executive Summary
This paper introduces GenQPM, a method for quantitative predictive monitoring (QPM) of stochastic systems with multi-modal dynamics. GenQPM combines score-based diffusion models with conformal inference to generate mode-specific prediction intervals for STL robustness values. The method first learns a generative model of system dynamics, then classifies trajectories into modes, and finally applies conformalized quantile regression to produce statistically valid, mode-specific intervals. Evaluated on four case studies (navigation, crossroad, and multi-agent scenarios), GenQPM achieves up to 50% narrower prediction intervals than mode-agnostic baselines while maintaining 90% coverage guarantees. The approach also provides interpretable insights into safety-critical system behavior.

## Method Summary
GenQPM is a method for quantitative predictive monitoring that generates mode-specific prediction intervals for STL robustness values. The approach uses a score-based diffusion model to learn the conditional distribution of trajectories given initial states, classifies these trajectories into dynamical modes, and applies conformalized quantile regression to produce statistically valid intervals per mode. At test time, given a new initial state, GenQPM samples trajectories from the generative model, classifies them into modes, computes STL robustness values, and returns calibrated prediction intervals that guarantee coverage while being significantly narrower than mode-agnostic baselines.

## Key Results
- GenQPM achieves up to 50% narrower prediction intervals than mode-agnostic baselines while maintaining 90% coverage guarantees
- The method provides interpretable insights into safety-critical system behavior through mode-specific analysis
- Four case studies demonstrate effectiveness: navigation scenarios, crossroad scenarios, and multi-agent systems

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Mode-specific prediction intervals can be significantly narrower than mode-agnostic baselines while maintaining coverage guarantees.
- **Mechanism:** Partitioning trajectories by dynamical mode before applying conformalized quantile regression (CQR) localizes uncertainty within homogeneous behavioral clusters rather than spanning the full multi-modal distribution. The generative model samples trajectories conditioned on the current state; these are classified into modes, and separate quantile intervals are computed per mode. Conformal calibration via nonconformity scores ensures each mode-specific interval achieves ≥ 1−α coverage conditional on the mode.
- **Core assumption:** Trajectories within a mode have similar robustness values (lower intra-mode variance than inter-mode variance), and the calibration set contains sufficient samples per mode.
- **Evidence anchors:** [abstract] "GenQPM achieves up to 50% narrower prediction intervals than mode-agnostic baselines while maintaining 90% coverage guarantees." [Section 4.1, Eq. 5] "P r⃗ s∼⃗S(Robϕ(⃗ s) ∈ CP I ϕ,mode(⃗ s(0)) | M(⃗ s) = mode) ≥ 1 − α"

### Mechanism 2
- **Claim:** Diffusion models provide sample access to the conditional trajectory distribution, enabling empirical quantile estimation without direct quantile regression training.
- **Mechanism:** Score-based diffusion models learn to denoise trajectories through a reverse process, yielding a generative model pθ(⃗s|⃗s(0)). At test time, sampling K trajectories per initial state and computing STL robustness over these samples provides an empirical distribution from which quantiles are extracted. This decouples property-specific learning from dynamics learning: the generative model is trained once; changing the STL property only requires recomputing robustness on existing samples.
- **Core assumption:** The diffusion model approximates the true conditional distribution well enough that empirical quantiles of sampled robustness values converge to true quantiles.
- **Evidence anchors:** [Section 4.1] "The surrogate generates multiple possible realizations for each calibration state (step 2.b). For each mode ∈ {1, . . . , G}, we compute the STL robustness of the surrogate trajectories mapped to mode by the mode predictor M (step 2.c) and use these values to extract the empirical quantiles."

### Mechanism 3
- **Claim:** Class-conditional conformal inference guarantees per-mode coverage even when mode frequencies are imbalanced.
- **Mechanism:** By constructing separate calibration sets D(mode)_c for each mode and computing mode-specific critical scores τ^ϕ,mode via CQR, the framework provides conditional guarantees. The law of total probability (Eq. 6) ensures marginal coverage ≥ 1−α across all modes. Rare modes receive wider intervals (higher τ) to compensate for fewer calibration samples, maintaining validity.
- **Core assumption:** Exchangeability holds within each mode-conditional calibration set. The mode predictor M is consistent between calibration and test (or ground-truth labels are available).
- **Evidence anchors:** [Section 4.1, Remark 1] "Deviations from the target coverage level of 1 − α when evaluating the approximate mode predictor against a labeled test set. This occurs because the calibration data (classified by the approximate predictor) and the test data (classified by ground truth labels) lack exchangeability."

## Foundational Learning

- **Concept: Signal Temporal Logic (STL) robustness semantics**
  - **Why needed here:** STL provides quantitative satisfaction degrees (robustness) rather than binary outcomes, enabling interval predictions. The robustness function Rob_ϕ(⃗s, t) maps trajectories to real values where positive = satisfaction, negative = violation.
  - **Quick check question:** Given a trajectory ⃗s and formula ϕ = G[0,10](x > 0), can you compute the robustness? (Answer: min_{t∈[0,10]} x(t); negative if any x(t) ≤ 0).

- **Concept: Conformal prediction and exchangeability**
  - **Why needed here:** Conformal inference provides distribution-free coverage guarantees (Eq. 4) under exchangeability. Understanding nonconformity scores and calibration quantiles is essential to implement CQR correctly.
  - **Quick check question:** If calibration and test data are not exchangeable (e.g., distribution shift), what happens to the coverage guarantee? (Answer: Guarantee is void; coverage may be below 1−α).

- **Concept: Diffusion model sampling and denoising**
  - **Why needed here:** The method relies on generating trajectory samples from the learned diffusion model. Understanding the reverse process and conditional generation is necessary to implement and debug the surrogate.
  - **Quick check question:** In a DDPM, what does the neural network ϵ_θ predict during training? (Answer: The noise ϵ added at each forward step; sampling iteratively denoises from pure noise).

## Architecture Onboarding

- **Component map:** Diffusion model -> Mode predictor -> STL robustness evaluator -> Quantile extractor -> CQR calibrator -> Runtime monitor
- **Critical path:** Diffusion model training -> calibration set construction -> mode-specific calibration score computation (Algorithm 1, steps 1–2). This must complete before deployment. Runtime (step 3) involves only sampling, robustness computation, and interval lookup.
- **Design tradeoffs:**
  - **Mode-conditional vs. mode-agnostic generative model:** A mode-conditional model p_θ(⃗s|⃗s(0), mode) ensures balanced sampling but requires retraining when modes change. The paper uses unconditional generation + filtering (more flexible but may produce unbalanced samples).
  - **Exact vs. approximate mode predictor:** Exact predictors guarantee coverage; approximate predictors may violate exchangeability but are necessary when ground-truth labels are unavailable.
  - **Larger K (samples per state) vs. computation time:** More samples improve quantile estimates but increase latency.
- **Failure signatures:**
  - **Infinite-width intervals:** Indicates the generative model fails to produce trajectories for a mode; underrepresented mode in calibration set.
  - **Coverage below 1−α for specific mode:** Likely exchangeability violation (approximate mode predictor) or insufficient calibration samples.
  - **All intervals overlapping and wide:** Modes are not well-separated; consider redefining mode labels or using different features for classification.
- **First 3 experiments:**
  1. **Reproduce Signal case study:** Train diffusion model on 1D trajectories with three equilibria. Compute mode-specific intervals for ϕ = F[0,22]G[0,22](⃗s ≥ 17.5). Verify coverage ≈ 90% per mode and interval widths narrower than mode-agnostic baseline.
  2. **Ablate mode predictor accuracy:** Train a classifier with varying training set sizes (100%, 50%, 10% of labels). Measure coverage degradation as predictor quality decreases to quantify sensitivity to exchangeability violations.
  3. **Stress-test rare modes:** In Navigation scenario, artificially subsample trajectories from modes 1 and 4 to < 5% of dataset. Observe interval width inflation and coverage; test whether guidance strategies mitigate the issue.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can guidance strategies effectively mitigate unbalanced trajectory generation in GenQPM without requiring the retraining of the underlying diffusion model?
- **Basis in paper:** [explicit] The paper states, "Alternatively, one can use guidance strategies... to impose soft constraints over the generation of trajectories that are likely to belong to the desired mode and with no need to even retrain the model."
- **Why unresolved:** While suggested as a solution to the "unbalanced generation" problem where certain modes are under-sampled, the authors do not implement or evaluate this approach in the experimental results, relying instead on the base generative process.
- **What evidence would resolve it:** A comparative study showing that guided generation maintains mode-specific coverage guarantees while reducing the variance of trajectory counts across modes compared to the baseline method.

### Open Question 2
- **Question:** How can mode-conditional coverage guarantees be mathematically ensured when the mode classifier is approximate rather than exact?
- **Basis in paper:** [explicit] Remark 1 notes that "experiments may reveal deviations from the target coverage level... when evaluating the approximate mode predictor against a labeled test set. This occurs because the calibration data... and the test data... lack exchangeability."
- **Why unresolved:** The paper demonstrates that approximate predictors can fail (producing infinite width intervals for rare modes), but it does not propose a theoretical correction to restore the exchangeability assumption required for conformal guarantees.
- **What evidence would resolve it:** A modified conformal inference mechanism that accounts for classifier uncertainty or a proof that specific regularization techniques for the mode predictor restore conditional validity.

### Open Question 3
- **Question:** Can adaptive conformal inference techniques replace the manual updating of calibration sets to handle distribution shifts in dynamic multi-agent environments?
- **Basis in paper:** [explicit] Footnote 5 states, "While there are other ways to address distribution shifts in CP, we choose to update the calibration datasets to obtain coverage guarantees over the shifted distribution."
- **Why unresolved:** The current approach requires periodically rebuilding calibration sets when new agents appear, which may be computationally intensive. The authors acknowledge alternatives exist but do not explore them.
- **What evidence would resolve it:** Experiments in the multi-agent crossroad scenario showing that an adaptive conformal method (e.g., adaptive risk levels) maintains valid coverage during agent transitions without explicit recalibration.

## Limitations
- The method requires periodic rebuilding of calibration sets when new agents appear in multi-agent scenarios, which can be computationally intensive
- Rare modes may receive infinite-width intervals if underrepresented in the training data, though guidance strategies are proposed but not evaluated
- Approximate mode predictors can violate exchangeability assumptions, leading to coverage guarantees being voided

## Confidence

- **High:** The core theoretical guarantee (per-mode coverage ≥ 1−α) and the mechanism of mode-specific interval efficiency are well-founded in the literature on conformal prediction
- **Medium:** The empirical demonstration of 50% narrower intervals is convincing but dependent on the specific case studies and may not generalize to all multi-modal systems
- **Low:** The sensitivity of the method to poor mode separation or rare modes is acknowledged but not thoroughly explored; the proposed guidance strategy is mentioned but not validated

## Next Checks

1. **Robustness to mode predictor quality:** Systematically vary the accuracy of the mode predictor (e.g., by training on fewer labeled samples) and measure the degradation in per-mode coverage to quantify the exchangeability violation
2. **Performance on a new case study:** Apply GenQPM to a synthetic or real-world case study with well-separated modes (e.g., a thermostat with heating/cooling/idle states) to test generalizability
3. **Stress-test rare mode handling:** In a case study with imbalanced mode frequencies, compare the proposed guidance strategy for unbalanced generation against a simple mode-conditional generative model to evaluate efficiency gains