---
ver: rpa2
title: Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors
arxiv_id: '2507.17577'
source_url: https://arxiv.org/abs/2507.17577
tags:
- attack
- queries
- sign-opt
- prior-opt
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a novel approach to improve the efficiency\
  \ of hard-label adversarial attacks by incorporating transfer-based priors from\
  \ surrogate models into the gradient estimation process. The authors reformulate\
  \ the attack as a continuous optimization problem by minimizing the \u2113p-norm\
  \ distance to the adversarial region along a ray direction."
---

# Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors

## Quick Facts
- **arXiv ID:** 2507.17577
- **Source URL:** https://arxiv.org/abs/2507.17577
- **Authors:** Chen Ma; Xinjie Xu; Shuyu Cheng; Qi Xuan
- **Reference count:** 40
- **One-line primary result:** Proposes Prior-OPT and Prior-Sign-OPT algorithms that incorporate transfer-based priors from surrogate models to significantly improve query efficiency of hard-label adversarial attacks on ImageNet and CIFAR-10.

## Executive Summary
This paper addresses the fundamental challenge of hard-label black-box adversarial attacks, where the attacker can only query the target model's predictions without access to its gradients. The authors reformulate the attack as a continuous optimization problem using ray search, which iteratively searches for the optimal perturbation direction. By incorporating transfer-based priors from surrogate models, the proposed algorithms estimate gradients more accurately, achieving significantly better query efficiency compared to existing methods. Extensive experiments on ImageNet and CIFAR-10 datasets demonstrate that the proposed approach outperforms 11 state-of-the-art methods.

## Method Summary
The paper proposes a novel approach to improve hard-label adversarial attacks by reformulating the attack as a continuous optimization problem. The method minimizes the ℓp-norm distance to the adversarial region along a ray direction using a gradient estimation procedure that incorporates transfer-based priors from surrogate models. Two algorithms are introduced: Prior-Sign-OPT, which applies a sign-based estimator to all vectors, and Prior-OPT, which uses finite differences for priors and sign-based estimation for random vectors. The approach leverages the structural similarity between surrogate and target models to guide the gradient estimation process, reducing variance and improving query efficiency.

## Key Results
- Prior-OPT achieves significant improvements in query efficiency compared to 11 state-of-the-art methods on ImageNet and CIFAR-10 datasets.
- The method demonstrates 10-50% reduction in mean ℓ2 distortion across various query budgets compared to baseline approaches.
- Theoretical analysis proves that the proposed gradient estimators achieve better cosine similarity with the true gradient than existing Sign-OPT methods.
- The approach maintains high attack success rates while requiring fewer queries to the target model.

## Why This Works (Mechanism)

### Mechanism 1: Subspace Projection with Transfer-based Priors
The attack estimates the gradient $\nabla g(\theta)$ by restricting the search to a subspace $S$ spanned by transfer-based priors (surrogate gradients) and random directions. By computing the optimal projection onto this subspace, the estimator leverages structural similarity between models to guide the search direction, reducing variance. The method achieves higher expected cosine similarity with the true gradient compared to random sampling alone.

### Mechanism 2: Differential Estimation Strategy (Prior-OPT)
Prior-OPT treats priors and random vectors differently during coefficient estimation. It uses precise finite-difference methods for priors (via binary search) while applying the cheaper sign-based estimator only to random orthogonal vectors. This recognizes that priors are high-value information requiring precise weighting, whereas random vectors are noisy samples where directional sign is sufficient.

### Mechanism 3: Surrogate Gradient Equivalence
The gradient of a surrogate loss function $h(\theta, \lambda)$ at the decision boundary is proportional to the true gradient of the distance function $g(\theta)$. The Implicit Function Theorem shows that the gradient of a differentiable surrogate loss at the boundary radius $\lambda_0$ points in the same direction as $\nabla g(\theta)$, allowing standard backpropagation on the surrogate model to obtain transfer-based priors without querying the target model for gradient steps.

## Foundational Learning

- **Concept: Ray Search Formulation**
  - **Why needed here:** The entire paper reframes the discrete hard-label attack into a continuous optimization problem (Eq. 3) searching for a direction $\theta$. Without understanding that we are optimizing a "radius" function $g(\theta)$, the mechanism of gradient estimation makes little sense.
  - **Quick check question:** How does the objective function $g(\theta)$ differ from the standard classification loss used in white-box attacks?

- **Concept: Zeroth-Order (ZO) Optimization & Sign Trick**
  - **Why needed here:** The paper improves upon "Sign-OPT," which relies on estimating gradients using only function value signs. Understanding that $\text{sign}(g(\theta + \sigma u) - g(\theta))$ is a biased, low-query-cost estimator is essential to see why Prior-OPT introduces finite differences for priors.
  - **Quick check question:** Why does the "sign trick" reduce query complexity compared to standard finite differences, and what is the trade-off in accuracy?

- **Concept: Transferability in Adversarial Attacks**
  - **Why needed here:** The method relies on "transfer-based priors." Learners must understand that gradients calculated on one model (surrogate) often correlate with the gradients of another (target) to see why $\alpha_i$ (cosine similarity) is the critical metric for success.
  - **Quick check question:** If two models have orthogonal gradients ($\alpha=0$), would using one as a prior for the other help or hinder a gradient-based attack?

## Architecture Onboarding

- **Component map:** Surrogate Module -> Query Module -> Orthogonalization Unit -> Estimator (Prior-OPT) -> Optimizer
- **Critical path:** 1. Input current direction $\theta$. 2. Surrogate computes Prior $k$ (Gradient of $h$). 3. Generate Random vectors $r$. 4. Gram-Schmidt $\{k, r\} \to \{p, u\}$ (Orthogonal basis). 5. Query Target to get $g(\theta + \sigma p)$ (Expensive) and signs for $u$ (Cheap). 6. Construct $v^*$ and update $\theta \leftarrow \theta - \eta v^*$.
- **Design tradeoffs:**
  - Prior-Sign-OPT vs. Prior-OPT: Prior-Sign-OPT is faster per iteration but noisier. Prior-OPT uses more queries per iteration but achieves higher theoretical cosine similarity $E[\gamma]$.
  - Single vs. Multiple Priors: Adding more surrogate models improves performance if they provide diverse gradients, but increases the query cost of the binary search phase in Prior-OPT.
- **Failure signatures:**
  - Stagnation: Distortion stops decreasing despite high query counts. Diagnosis: Surrogate model is too different (low $\alpha$), causing the "prior" to be orthogonal to the true optimal direction.
  - Query Exhaustion: Budget depleted before convergence. Diagnosis: Binary search precision $\beta$ is set too high for Prior-OPT.
- **First 3 experiments:**
  1. Ablation on Prior Quality: Measure attack success rate vs. query count when using a surrogate with high architectural similarity vs. low similarity.
  2. Estimator Comparison: Plot convergence curves for Sign-OPT, Prior-Sign-OPT, and Prior-OPT on a fixed target to visualize the trade-off between query-per-iteration and convergence speed.
  3. Scalability Test: Attack a Large Vision-Language Model (e.g., CLIP) using ImageNet surrogates to verify if the "transfer-based prior" holds across fundamentally different training paradigms.

## Open Questions the Paper Calls Out
- How can the performance of Prior-OPT and Prior-Sign-OPT be optimized specifically for lower-resolution datasets like CIFAR-10?
- Can the selection of surrogate models be automated or optimized dynamically based on estimated alignment with the target model?
- Can the wall-clock time overhead of Prior-OPT be reduced while maintaining its query efficiency?

## Limitations
- The method's effectiveness critically depends on the transferability of surrogate gradients to the target model, which may degrade when attacking models with substantially different architectures.
- The computational overhead of maintaining multiple surrogate models and computing their gradients could be prohibitive in resource-constrained scenarios.
- The paper demonstrates success on image classification tasks but does not validate the approach on other domains where gradient transferability might be weaker.

## Confidence
- **High Confidence:** The core mathematical framework for subspace projection and the theoretical analysis of cosine similarity bounds are well-founded.
- **Medium Confidence:** The experimental results showing significant improvements over state-of-the-art methods on ImageNet and CIFAR-10 appear robust.
- **Medium Confidence:** The assumption that surrogate gradients provide meaningful priors relies on the transferability hypothesis, which holds for similar model architectures but may not generalize to more divergent model families.

## Next Checks
1. **Transferability Stress Test:** Systematically evaluate the method's performance when using surrogates with varying degrees of architectural similarity to the target to quantify the impact of gradient transferability on attack success.
2. **Cross-Domain Validation:** Apply the proposed approach to non-image domains such as text classification or tabular data to verify whether transfer-based priors remain effective when model architectures and input representations differ substantially from the image domain.
3. **Query Complexity Analysis:** Conduct a detailed ablation study measuring the trade-off between the number of priors used and the overall query efficiency, particularly focusing on the computational overhead introduced by maintaining and updating multiple surrogate models during the attack process.