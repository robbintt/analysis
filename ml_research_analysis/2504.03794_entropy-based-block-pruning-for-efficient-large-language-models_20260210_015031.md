---
ver: rpa2
title: Entropy-Based Block Pruning for Efficient Large Language Models
arxiv_id: '2504.03794'
source_url: https://arxiv.org/abs/2504.03794
tags:
- pruning
- entropy
- arxiv
- layers
- block
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EntroDrop, an entropy-based block pruning strategy
  for efficient large language model deployment. The method leverages the observation
  that entropy of hidden representations decreases in early layers but increases progressively
  in later layers, suggesting entropy serves as an effective measure of information
  richness within computation blocks.
---

# Entropy-Based Block Pruning for Efficient Large Language Models
## Quick Facts
- arXiv ID: 2504.03794
- Source URL: https://arxiv.org/abs/2504.03794
- Reference count: 12
- Key outcome: EntroDrop achieves 37.5% layer reduction on Llama3.1-8B while retaining >95% performance

## Executive Summary
EntroDrop introduces an entropy-based block pruning strategy that exploits the observation that hidden representation entropy decreases in early layers but increases progressively in later layers of large language models. Unlike geometric-based methods like cosine similarity, entropy directly quantifies uncertainty and information content within computation blocks, making it an effective measure for identifying redundant operations. The approach identifies and prunes blocks with minimal entropy increase while preserving model performance, demonstrating superior efficiency over existing methods.

The method shows consistent effectiveness across different models and datasets, with comprehensive sensitivity analysis confirming the robustness of bucket-based and KNN-based entropy estimation approaches over alternatives. Experiments on Llama3.1-8B demonstrate pruning 12 attention layers (37.5% of total) while maintaining over 95% of original performance, establishing entropy as a reliable metric for block-level pruning decisions.

## Method Summary
EntroDrop leverages entropy as a measure of information richness within transformer blocks to identify pruning opportunities. The method observes that entropy patterns in hidden representations follow a specific progression across layers - decreasing in early layers and increasing in later layers - suggesting entropy captures the accumulation of information processing. By estimating entropy for different blocks and identifying those contributing minimal information gain, EntroDrop systematically removes redundant computations while preserving model accuracy. The approach employs robust entropy estimation through bucket-based and KNN-based methods, with sensitivity analysis confirming their effectiveness over alternative estimation techniques.

## Key Results
- Pruned 12 attention layers (37.5% of total) from Llama3.1-8B while retaining >95% performance
- Outperforms cosine similarity-based pruning methods in reducing model size while maintaining accuracy
- Demonstrates consistent effectiveness across different models and datasets
- Entropy estimation sensitivity analysis confirms robustness of bucket-based and KNN-based approaches

## Why This Works (Mechanism)
EntroDrop works by exploiting the fundamental property that information content in neural network representations can be quantified through entropy. Unlike cosine similarity which measures geometric relationships between vectors, entropy directly captures the uncertainty and richness of information within computation blocks. The method identifies that transformer blocks exhibit predictable entropy patterns across layers - early layers show decreasing entropy as they extract basic features, while later layers show increasing entropy as they accumulate complex representations. By pruning blocks with minimal entropy contribution, the method removes redundant computations that don't significantly impact the model's information processing capacity.

## Foundational Learning
- **Entropy in information theory**: Measures uncertainty in probability distributions; needed to quantify information content in hidden representations; quick check: verify entropy calculations on simple distributions
- **Transformer block architecture**: Understanding self-attention and feed-forward components; needed to identify computation blocks for pruning; quick check: trace information flow through a single transformer block
- **Hidden representation analysis**: Examining activation patterns across layers; needed to observe entropy progression; quick check: visualize entropy changes across layer depth
- **Cosine similarity metrics**: Baseline geometric comparison method; needed for benchmarking against existing pruning approaches; quick check: implement cosine similarity calculation for vector pairs
- **KNN-based estimation**: Non-parametric density estimation technique; needed for robust entropy calculation; quick check: verify KNN density estimates on synthetic data
- **Bucket-based discretization**: Entropy estimation through histogram binning; needed for computational efficiency; quick check: compare entropy estimates across different bucket sizes

## Architecture Onboarding
- **Component map**: Input -> Embedding Layer -> Transformer Blocks -> Entropy Estimation Module -> Pruning Decision Module -> Output
- **Critical path**: Forward pass through transformer blocks where entropy is calculated and compared against pruning thresholds
- **Design tradeoffs**: Accuracy vs. efficiency tradeoff in entropy estimation (bucket-based vs. KNN-based), computational overhead of entropy calculation vs. pruning gains
- **Failure signatures**: Over-pruning leading to performance collapse, entropy estimation errors causing incorrect pruning decisions, sensitivity to input distribution shifts
- **First experiments**: 1) Verify entropy progression patterns across layers on a small model, 2) Compare entropy-based vs. cosine similarity pruning on a validation set, 3) Test sensitivity of different entropy estimation methods

## Open Questions the Paper Calls Out
None

## Limitations
- Generalization across diverse model architectures beyond Transformer-based LLMs remains unverified
- Lack of comprehensive ablation studies examining entropy estimation methods under varying computational constraints
- No evaluation of robustness to adversarial inputs or distribution shifts affecting entropy measurements

## Confidence
- **Core claim (entropy as effective information richness measure)**: Medium
- **Superiority over cosine similarity methods**: Medium
- **Cross-architecture generalizability**: Low
- **Robustness to adversarial/distribution shifts**: Low

## Next Checks
1. Test entropy-based pruning across multiple model architectures including convolutional networks and recurrent models to establish cross-architecture generalizability

2. Conduct comprehensive ablation studies comparing different entropy estimation methods under varying computational budgets and latency constraints to identify optimal trade-offs for different deployment scenarios

3. Evaluate the method's robustness to adversarial examples and distribution shifts to ensure consistent performance in real-world applications with varying input characteristics