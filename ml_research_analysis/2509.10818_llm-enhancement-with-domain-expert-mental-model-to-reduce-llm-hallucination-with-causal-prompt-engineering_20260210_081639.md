---
ver: rpa2
title: LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination
  with Causal Prompt Engineering
arxiv_id: '2509.10818'
source_url: https://arxiv.org/abs/2509.10818
tags:
- questions
- expert
- have
- generalized
- mental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a method to mitigate hallucinations in large
  language models (LLMs) by incorporating domain expert mental models (EMMs) through
  causal prompt engineering. The approach uses monotone Boolean and k-valued functions
  to create computationally tractable expert models via optimized human-machine dialogue,
  structured in four steps: factor identification, hierarchical structuring, generalized
  model specification, and detailed model generation.'
---

# LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering

## Quick Facts
- arXiv ID: 2509.10818
- Source URL: https://arxiv.org/abs/2509.10818
- Reference count: 21
- Combines domain expert mental models with LLM through causal prompt engineering to reduce hallucinations

## Executive Summary
This paper presents a novel approach to reducing hallucinations in large language models (LLMs) by integrating domain expert mental models (EMMs) through causal prompt engineering. The method employs monotone Boolean and k-valued functions to create computationally tractable expert models via optimized human-machine dialogue. The approach is structured in four systematic steps: factor identification, hierarchical structuring, generalized model specification, and detailed model generation. Case studies in proposal evaluation, cybersecurity design, and healthcare decisions demonstrate significant reductions in the number of questions needed from domain experts while maintaining accuracy, with one example reducing 1,048,576 scenarios to just 11 questions.

## Method Summary
The methodology combines domain expert knowledge with LLM capabilities through a structured four-step process. First, key factors influencing decisions are identified through dialogue with domain experts. Second, these factors are organized hierarchically to capture relationships and dependencies. Third, generalized models are specified using monotone Boolean and k-valued functions. Finally, detailed models are generated through optimized human-machine dialogue. The approach uses causal prompt engineering to integrate these expert mental models into the LLM framework, creating a system that can reason about complex domain-specific decisions while maintaining interpretability and reducing the likelihood of hallucination.

## Key Results
- Reduced expert questioning from 1,048,576 scenarios to 11 questions in a 20-factor proposal decision task
- Demonstrated effectiveness across three domains: proposal evaluation, cybersecurity design, and healthcare decisions
- Outperformed traditional aggregation logic while providing interpretable, explainable decision support
- Showed computational efficiency gains through optimized human-machine dialogue

## Why This Works (Mechanism)
The method works by encoding domain expert mental models as formal structures (monotone Boolean and k-valued functions) that can be efficiently queried and integrated with LLM reasoning. By structuring expert knowledge hierarchically and using causal prompt engineering, the approach creates a computational framework that constrains LLM outputs to domain-consistent reasoning paths. This reduces the space of possible responses and provides interpretable decision logic that can be composed for complex problems.

## Foundational Learning
- **Domain Expert Mental Models (EMMs)**: Formal representations of expert reasoning patterns; needed to provide structured domain knowledge that constrains LLM outputs
- **Monotone Boolean Functions**: Functions where increasing inputs leads to increasing outputs; needed for efficient representation of monotonic domain relationships
- **K-valued Functions**: Generalization of Boolean functions allowing multiple truth values; needed to capture more nuanced domain relationships
- **Causal Prompt Engineering**: Technique for structuring prompts to guide LLM reasoning; needed to integrate formal models with LLM capabilities
- **Hierarchical Factor Structuring**: Organizing decision factors in dependency hierarchies; needed to capture complex relationships between domain variables

## Architecture Onboarding
- **Component Map**: Domain Expert → Factor Identification → Hierarchical Structuring → Generalized Model Specification → Detailed Model Generation → Causal Prompt Engineering → LLM Output
- **Critical Path**: The four-step expert model development process (factor identification → hierarchical structuring → generalized specification → detailed generation) is the critical path for creating effective EMM integration
- **Design Tradeoffs**: Formal model expressiveness vs. computational tractability; number of expert questions vs. model accuracy; model complexity vs. interpretability
- **Failure Signatures**: Poor factor identification leading to incomplete models; incorrect hierarchical structuring causing reasoning errors; oversimplification in generalized specification reducing accuracy
- **First Experiments**: 1) Test factor identification accuracy with domain experts; 2) Validate hierarchical structuring captures key dependencies; 3) Evaluate generalized model specification against expert reasoning

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Limited generalizability across diverse domains and decision types remains uncertain
- Complex domain expertise involving subjective judgment may not be fully representable through Boolean and k-valued functions
- Potential biases introduced by the model specification process itself may create blind spots

## Confidence
- High confidence in computational efficiency gains and reduction in expert questions needed
- Medium confidence in hallucination reduction effectiveness based on limited case studies
- Low confidence in generalizability across diverse domains without further testing

## Next Checks
1. Test the method across at least five additional diverse domains (e.g., legal reasoning, financial analysis, creative design) to assess generalizability
2. Conduct a comparative study measuring actual hallucination rates between LLM outputs with and without EMM integration across different task types
3. Evaluate the method's performance with different LLM architectures (e.g., GPT-4, Claude, open-source models) to determine architectural dependencies