---
ver: rpa2
title: Towards Understanding Feature Learning in Parameter Transfer
arxiv_id: '2509.22056'
source_url: https://arxiv.org/abs/2509.22056
tags:
- inequality
- transfer
- lemma
- learning
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides the first theoretical analysis of training
  dynamics in parameter transfer, proving the existence of negative transfer. The
  authors analyze a setting where both upstream and downstream models are two-layer
  ReLU CNNs, characterizing how inherited parameters act as carriers of universal
  knowledge between source and target tasks.
---

# Towards Understanding Feature Learning in Parameter Transfer

## Quick Facts
- arXiv ID: 2509.22056
- Source URL: https://arxiv.org/abs/2509.22056
- Reference count: 40
- First theoretical analysis proving existence of negative transfer in parameter transfer

## Executive Summary
This paper provides the first theoretical analysis of training dynamics in parameter transfer learning, proving the existence of negative transfer between upstream and downstream tasks. The authors analyze a setting where both models are two-layer ReLU CNNs, characterizing how inherited parameters act as carriers of universal knowledge. The work reveals three crucial factors influencing transfer effectiveness: the norm of universal knowledge shared between tasks, the training sample size in the source task, and the noise level in the source task. Numerical experiments validate these findings across synthetic and real-world datasets using modern architectures.

## Method Summary
The paper analyzes parameter transfer between two-layer ReLU CNNs using synthetic data generation with controlled signal and noise components. The method tracks training dynamics through signal-noise decomposition, proving phase transition phenomena based on the quantity Γ = α²N₁||u||²₂/(σ²p,1σ²p,2d). Experiments sweep across source task sample size, noise level, and universal signal strength. Real-world validation uses CIFAR-10/100 with ResNet, VGG, and ViT architectures, comparing parameter transfer against random initialization baselines.

## Key Results
- Three crucial factors influence parameter transfer: universal knowledge norm, source sample size, and source task noise level
- Phase transition phenomenon: near-optimal test error when Γ exceeds threshold, significant degradation otherwise
- Negative transfer occurs when universal signal is much weaker than task-specific signal, causing inherited weights to magnify task-specific noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inherited parameters act as carriers of universal knowledge between tasks
- Mechanism: The upstream model learns a weight decomposition where the coefficient γ on the universal signal u (shared across tasks) is proportional to N₁||u||²₂/(σ²p,1d log T). When transferred, these pre-trained coefficients provide a "head start" on the downstream task, requiring less data to achieve near-optimal test error. The quantity Γ = α²N₁||u||²₂/(σ²p,1σ²p,2d) determines transfer effectiveness.
- Core assumption: Tasks share a non-zero universal signal component u that is orthogonal to task-specific signals.
- Evidence anchors:
  - [abstract] "characterize how the inherited parameters act as carriers of universal knowledge"
  - [Theorem 4.2] Test error bound depends on α²N₁||u||⁴₂/σ⁴p,1 term
  - [corpus] "Transfer Learning in Infinite Width Feature Learning Networks" - theoretical analysis of transfer with feature learning in both pretraining and downstream phases
- Break condition: When ||u||₂ → 0 (no shared signal), or N₁ → 0 (insufficient upstream data), or σ²p,1 → ∞ (excessive upstream noise), the benefit vanishes.

### Mechanism 2
- Claim: Parameter transfer succeeds through balanced signal-to-noise ratio in learned weights
- Mechanism: The analysis tracks signal learning coefficients (γ for universal signal, γ₁/γ₂ for task-specific) versus noise memorization coefficients (ρᵢ for each training sample's noise ξᵢ). Lemma A.1 shows signal learning grows as O(xₜ) while noise memorization grows as O(N·xₜ). For generalization, the ratio γ/(Σρᵢ/m) must be sufficiently large—this requires N||u||⁴₂/(σ⁴d) to exceed a threshold.
- Core assumption: Noise vectors are approximately orthogonal to signal vectors and to each other (Gaussian in orthogonal subspace).
- Evidence anchors:
  - [Lemma A.1, A.2] Bounds on signal learning (γ) and noise memorization (ρ) dynamics in both systems
  - [Theorem 4.2 vs 4.3] Comparing transfer vs scratch training shows the inherited γ term adds to effective signal strength
  - [corpus] Corpus lacks directly comparable signal-noise decomposition analysis
- Break condition: When dimension d is too large relative to N||u||⁴/σ⁴, noise memorization dominates signal learning.

### Mechanism 3
- Claim: Negative transfer occurs when transferred weights have excessive task-specific components
- Mechanism: When ||u||₂ << ||v₂||₂ (universal signal much weaker than task-specific signal), upstream weights develop large γ₁ (Task 1-specific) but small γ (universal). These over-amplified task-specific weights transfer poorly—Per Proposition 4.4(2), the transferred weight norms become "excessively large" and "magnify task-specific noise" on the downstream task rather than enhancing the weak shared signal.
- Core assumption: The condition ||u+v₂||²₂/||u||²₂ ≥ αN₁σ²p,2/(N₂σ²p,1) ≥ C₄ signals task mismatch.
- Evidence anchors:
  - [Proposition 4.4(2)] Explicit condition for negative transfer: when task-specific >> universal signal
  - [Page 3] "the weight norm learned from the upstream model becomes excessively large... magnify task-specific noise"
  - [corpus] "Optimizing Specific and Shared Parameters" discusses separating task-specific from shared parameters in PETL
- Break condition: When universal and task-specific signals have comparable norms, or when downstream N₂ is large enough to overcome inherited noise.

## Foundational Learning

- **Concept**: Gradient descent dynamics in over-parameterized neural networks
  - Why needed here: The entire analysis tracks how coefficients evolve during training; must understand that in over-param regimes, different weight components evolve semi-independently
  - Quick check question: Can you explain why increasing width m helps with concentration but doesn't change the fundamental signal-noise tradeoff?

- **Concept**: Feature learning regime vs lazy training (NTK regime)
  - Why needed here: The paper explicitly uses small initialization σ₀ to stay in feature learning regime where weights move substantially from initialization (avoiding NTK's linear approximation)
  - Quick check question: Why does the condition σ₀ = O((σₚd/√n)^(-1)) ensure we're not in lazy training?

- **Concept**: Generalization bounds via signal-to-noise ratio
  - Why needed here: Test error depends fundamentally on whether learned signal strength overwhelms memorized noise; this is the core of benign overfitting analysis
  - Quick check question: In Theorem 4.2, what happens to test error when d scales up while keeping N, ||u||, σ fixed?

## Architecture Onboarding

- **Component map**:
  - Upstream model (Task 1): 2-layer ReLU CNN with m filters, trained on N₁ samples
  - Downstream model (Task 2): Same architecture, inherits α·m filters from upstream, reinitializes (1-α)·m filters
  - Weight decomposition: w = w₀ + γ·û + γ₁·v̂₁ + γ₂·v̂₂ + Σᵢ ρᵢξ̂ᵢ (signal + noise components)
  - Transfer algorithm: Copy first αm weights, random init the rest

- **Critical path**:
  1. Generate synthetic data per Definitions 3.1-3.2 with controlled ||u||, ||v||, σₚ
  2. Train upstream model for T* epochs, track coefficient evolution
  3. Transfer weights to downstream, train on Task 2 data
  4. Measure test error, verify phase transition at Γ threshold

- **Design tradeoffs**:
  - Inheritance ratio α: Higher α transfers more knowledge but also more potential noise
  - Upstream sample size N₁: More data improves universal signal learning but increases compute cost
  - Dimension d: Lower d favors generalization but reduces model capacity

- **Failure signatures**:
  - Test error > 10% when Γ is below threshold (weak transfer)
  - Test error worse than scratch training when ||u|| << ||v₂|| (negative transfer)
  - Training loss doesn't converge when learning rate η is too large (violates Condition 4.1)

- **First 3 experiments**:
  1. Ablate N₁ with fixed ||u||, σₚ: Plot test accuracy vs epochs for N₁∈{100,200,500,1000}—should see monotonically improving curves
  2. Ablate ||u|| with fixed N₁, σₚ: Vary universal signal strength while keeping ||u+v₂|| fixed—when ||u||=0, verify negative transfer occurs
  3. Phase boundary detection: Create heatmap of test accuracy over (||u||, d) grid; truncate at threshold to visualize the sharp transition predicted by Theorem 4.2

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the theoretical analysis of training dynamics in parameter transfer be rigorously extended to deep neural networks with more than two layers?
- **Basis in paper**: [explicit] Section 7 states that extending the analysis to deep neural networks "remains for future research" and involves understanding "more intricate dynamical systems."
- **Why unresolved**: The current theoretical framework relies on the specific signal-noise decomposition and dynamics available in two-layer ReLU CNNs (Lemma B.2).
- **What evidence would resolve it**: A formal proof showing that the dynamics of inherited parameters in multi-layer networks exhibit similar phase transitions or convergence properties to the shallow models analyzed here.

### Open Question 2
- **Question**: How does the introduction of regularization techniques theoretically influence the selection and transfer of weights compared to random parameter reuse?
- **Basis in paper**: [explicit] Section 7 notes it is an "open and important question" to develop a framework to understand how regularization guides weight selection, rather than the random transfer method analyzed in the paper.
- **Why unresolved**: The current work analyzes a setting where an $\alpha$-proportion of weights is randomly sampled/inherited, leaving the impact of selective transfer theoretically underexplored.
- **What evidence would resolve it**: Theoretical bounds characterizing how specific regularization methods improve the "effectiveness" of the inherited parameters by filtering out task-specific noise or over-amplified weights.

### Open Question 3
- **Question**: Do the conditions for negative and positive transfer remain sharp when the assumption of orthogonality between signal and noise patches is removed?
- **Basis in paper**: [inferred] Page 4 states the orthogonality assumption "simplifies the analysis" and claims it can be extended to general cases, but this extension is not proven or included in the main results.
- **Why unresolved**: Real-world data often involves correlated signal and noise components, which could alter the interaction between universal knowledge and task-specific noise described in Theorem 4.2.
- **What evidence would resolve it**: Theoretical proofs or rigorous simulations showing that the phase transition conditions (based on $\Gamma$ and $\alpha$) hold even when noise has a non-trivial correlation with the signal vectors.

## Limitations
- Theoretical analysis relies heavily on two-layer ReLU CNN architecture and synthetic data generation
- Phase transition results depend on specific parameter scalings that may be sensitive to implementation details
- Assumes orthogonal signal components and Gaussian noise, which may not hold in real-world scenarios

## Confidence
- **High Confidence**: The existence of negative transfer and the role of universal knowledge sharing (supported by Theorem 4.2, Proposition 4.4, and validated across synthetic and real experiments)
- **Medium Confidence**: The precise phase transition thresholds and generalization bounds (theoretical results rely on strong assumptions about data structure)
- **Low Confidence**: The exact numerical values of constants in Theorem 4.2 and the generalization to architectures beyond 2-layer CNNs

## Next Checks
1. **Architecture Generalization Test**: Replicate the synthetic experiments with 3-4 layer CNNs and ResNets to verify whether the phase transition phenomenon persists across architectures. Measure how the threshold Γ scales with network depth.

2. **Noise Structure Sensitivity**: Generate synthetic data where noise vectors are not perfectly orthogonal to signal vectors (e.g., correlated noise) and measure how this affects the generalization bounds. Compare the observed degradation to theoretical predictions.

3. **Real-world Task Mismatch**: Design transfer experiments between semantically dissimilar tasks (e.g., ImageNet→text classification) to test the negative transfer conditions. Quantify the relationship between task dissimilarity and transfer performance degradation.