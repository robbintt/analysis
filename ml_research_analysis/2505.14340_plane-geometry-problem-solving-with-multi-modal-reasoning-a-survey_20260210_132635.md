---
ver: rpa2
title: 'Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey'
arxiv_id: '2505.14340'
source_url: https://arxiv.org/abs/2505.14340
tags:
- zhang
- pgps
- chen
- reasoning
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey systematically categorizes plane geometry problem solving
  (PGPS) methods into an encoder-decoder framework, detailing encoder and decoder
  architectures and their output formats. PGPS is defined as inferring unknown geometric
  properties from diagram-text pairs, with common tasks including direct-answer, multiple-choice,
  and reasoning-step construction.
---

# Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey

## Quick Facts
- arXiv ID: 2505.14340
- Source URL: https://arxiv.org/abs/2505.14340
- Reference count: 30
- Primary result: Comprehensive survey categorizing PGPS methods and identifying key challenges like hallucinations and benchmark limitations

## Executive Summary
This survey provides a systematic framework for understanding plane geometry problem solving (PGPS) methods, which aim to infer unknown geometric properties from diagram-text pairs. The authors categorize PGPS approaches into encoder-decoder architectures, detailing how different models process visual and textual information to solve geometry problems. The survey identifies two major challenges: hallucinations in diagram perception where models frequently misperceive geometric primitives and relations, and benchmark limitations including data leakage and unrealistic synthetic diagram styles. Future directions emphasize improving visual prompting techniques and developing more comprehensive benchmarks that better reflect real-world multi-modal reasoning scenarios.

## Method Summary
The survey establishes an encoder-decoder framework for PGPS, where encoders process diagram-text pairs and decoders generate solutions. Encoder outputs are classified as either formal-language descriptions or embedding vectors, while decoder outputs include theorem sequences, logic programs, or natural-language descriptions. The framework systematically categorizes existing methods based on their architectural choices and output formats. Common PGPS tasks include direct-answer problems, multiple-choice questions, and step-by-step reasoning construction. The survey analyzes how different approaches handle geometric primitives (points, lines, circles) and relations (parallelism, perpendicularity, angle measurements) within this unified framework.

## Key Results
- PGPS methods systematically categorized using encoder-decoder framework with formal-language and embedding vector outputs
- Hallucinations in diagram perception identified as critical challenge where models misperceive geometric primitives and relations
- Benchmark limitations highlighted including data leakage and synthetic diagram styles that don't reflect realistic scenarios

## Why This Works (Mechanism)
The encoder-decoder framework provides a unified taxonomy that captures the diverse approaches to PGPS, enabling systematic comparison and identification of architectural patterns. By separating diagram processing (encoder) from solution generation (decoder), the framework reveals how different models handle the inherent complexity of geometric reasoning. The categorization of outputs as formal-language versus embedding vectors explains why some approaches struggle with hallucinationsâ€”formal-language encoders may miss subtle visual cues while embedding-based approaches may fail to capture precise geometric relationships. This mechanistic understanding guides the identification of specific failure modes and future improvement directions.

## Foundational Learning
**Geometric primitives**: Basic elements like points, lines, circles that form the building blocks of plane geometry. Needed to understand what models must perceive and reason about. Quick check: Can identify all primitives in a simple diagram.
**Geometric relations**: Properties like parallelism, perpendicularity, angle measurements that connect primitives. Essential for understanding geometric constraints and theorems. Quick check: Can verify a given relation is correct in a diagram.
**Formal geometry languages**: Symbolic representations like TGDL or GeoLogic that encode geometric facts. Provide structured, unambiguous representations for geometric reasoning. Quick check: Can translate a simple diagram into formal language.
**Multi-modal fusion**: Techniques for combining visual and textual information. Critical for PGPS where both diagram interpretation and problem text are essential. Quick check: Can explain how a model combines image features with text embeddings.

## Architecture Onboarding

**Component map**: Diagram-Text Input -> Encoder (Formal/Embedding) -> Decoder (Theorem/Logic/NL) -> Solution Output

**Critical path**: The encoder-decoder pipeline represents the core reasoning flow, where diagram perception directly impacts solution quality. Hallucinations typically originate in the encoder stage when geometric primitives are misperceived.

**Design tradeoffs**: Formal-language encoders provide precise representations but may miss visual nuances; embedding encoders capture visual details but may lose geometric precision. Decoders face tradeoffs between explicit theorem sequencing (interpretable but rigid) versus logic programming (flexible but harder to verify).

**Failure signatures**: Hallucinations manifest as incorrect identification of primitives (missing circles, misidentifying line types) and relations (false parallelisms, wrong angle measures). Benchmark issues appear as suspiciously high performance on synthetic data or failure on realistic diagrams.

**First experiments**: 
1. Test encoder accuracy on primitive identification across different diagram styles
2. Evaluate decoder performance on simple vs. complex geometric relationships
3. Compare formal-language and embedding-based approaches on identical problem sets

## Open Questions the Paper Calls Out
- How can visual prompting techniques be effectively integrated to reduce hallucinations in diagram perception?
- What architectural improvements can better capture subtle geometric relationships that current models miss?
- How can benchmarks be designed to avoid synthetic diagram limitations and ensure genuine multi-modal reasoning evaluation?

## Limitations
- Hallucinations in diagram perception remain a fundamental challenge that current methods cannot adequately address
- Benchmark datasets suffer from data leakage and synthetic diagram styles that don't reflect real-world complexity
- Limited evaluation on realistic, diverse diagram styles that would better test true multi-modal reasoning capabilities

## Confidence

High: The survey's systematic categorization of PGPS methods using the encoder-decoder framework is well-founded and provides clear architectural insights. The identification of hallucinations as a critical challenge is supported by extensive literature review. The framework accurately captures the state-of-the-art approaches and their limitations.

Medium: The proposed solutions for future directions (visual prompting, better benchmarks) are reasonable but not yet validated. The survey relies on existing literature which may have unreported limitations or biases.

Low: Specific quantitative claims about hallucination rates or benchmark performance are not provided, as the survey focuses on qualitative categorization rather than empirical evaluation.

## Next Checks

1. Implement and test visual prompting techniques on a standard PGPS benchmark to quantify hallucination reduction
2. Create a diverse diagram dataset with varying styles (hand-drawn, textbook, realistic) to evaluate robustness
3. Compare formal-language and embedding-based encoders on their ability to capture subtle geometric relationships in complex diagrams