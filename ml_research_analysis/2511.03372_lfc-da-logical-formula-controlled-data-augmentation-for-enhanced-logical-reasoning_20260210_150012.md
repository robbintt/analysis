---
ver: rpa2
title: 'LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical
  Reasoning'
arxiv_id: '2511.03372'
source_url: https://arxiv.org/abs/2511.03372
tags:
- logical
- reasoning
- data
- rule
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LFC-DA is a symbolic-logic-controlled data augmentation framework
  for improving logical reasoning in language models. It converts natural language
  into propositional logic formulas, explores logical variants using a bounded state-space
  search, and verbalizes them back into natural language.
---

# LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning

## Quick Facts
- **arXiv ID**: 2511.03372
- **Source URL**: https://arxiv.org/abs/2511.03372
- **Reference count**: 8
- **Primary result**: Achieves 59.70% accuracy on ReClor test set and 40.1% on LogiQA test set using symbolic-logic-controlled data augmentation.

## Executive Summary
LFC-DA is a symbolic-logic-controlled data augmentation framework designed to improve logical reasoning capabilities in language models. The method converts natural language statements into propositional logic formulas, explores logical variants through bounded state-space search using a rule library, and verbalizes them back into natural language with contrastive labels. Experiments on ReClor and LogiQA datasets show that models fine-tuned with LFC-DA-generated data outperform baselines, with particularly strong performance on harder reasoning subsets. The approach ensures logical rigor, diversity, and interpretability in augmented data while addressing limitations of traditional data augmentation methods.

## Method Summary
The framework operates through three main stages: formalization, state-space exploration, and verbalization. Natural language statements are parsed using Stanza to extract logical focus and convert to propositional formulas. A DFS-bounded search over a rule library generates correct and error states, with labels propagated based on equivalence, implication, or derivation relationships. The generated formulas are then verbalized back to natural language using LLM prompts with stylistic templates for diversity. The system employs two-stage training: contrastive pretraining on synthetic data followed by fine-tuning on downstream tasks using RoBERTa-Large. The approach addresses logical reasoning enhancement through symbolic control while maintaining interpretability and diversity in augmented data.

## Key Results
- Achieves 59.70% accuracy on ReClor test set and 40.1% on LogiQA test set
- Demonstrates 47.14% accuracy on ReClor TEST-H (hard reasoning subset)
- Outperforms baselines significantly on harder reasoning subsets while maintaining logical rigor

## Why This Works (Mechanism)
The framework works by maintaining logical rigor throughout the augmentation process. By converting natural language to formal logic, exploring valid transformations through bounded search, and converting back to natural language with contrastive labeling, it ensures that augmented data preserves logical relationships. The use of error rules creates challenging negative examples that improve model robustness. The two-stage training approach first builds contrastive understanding on synthetic data before fine-tuning on real examples, allowing models to learn logical relationships systematically.

## Foundational Learning

**Propositional Logic**: Boolean logic using variables and connectives (AND, OR, NOT, IMPLIES). Why needed: Forms the symbolic representation for reasoning. Quick check: Can convert "If A then B" to "A → B".

**State-Space Search**: DFS exploration of formula transformations within depth bounds. Why needed: Systematically generates logical variants while controlling complexity. Quick check: Verify bounded search doesn't generate infinite variants.

**Contrastive Learning**: Training with positive/negative pairs based on logical relationships. Why needed: Improves model ability to distinguish correct from incorrect reasoning. Quick check: Check label consistency across inference paths.

**Formalization Pipeline**: Stanza-based parsing to extract logical focus and convert to formulas. Why needed: Bridges natural language to symbolic representation. Quick check: Validate 9 seed statements convert correctly to formulas.

## Architecture Onboarding

**Component Map**: NL Input -> Stanza Parser -> Logic Converter -> Rule Library -> DFS Search -> Formula Generator -> LLM Verbalizer -> Contrastive Pairs -> RoBERTa Trainer

**Critical Path**: Stanza parsing → propositional formula conversion → DFS state-space search → LLM verbalization → contrastive training → downstream fine-tuning

**Design Tradeoffs**: Bounded DFS depth vs. formula diversity (D_max controls complexity); manual rule library vs. automated discovery (current manual approach ensures correctness but limits scalability).

**Failure Signatures**: Over-generation of trivial variants (insufficient pruning); incorrect label propagation (error rules contaminating correct paths); LLM hallucination deviating from formulas (verbalization quality issues).

**Three First Experiments**:
1. Implement minimal rule set (12-20 rules) and verify generation of diverse variants from 9 seed statements
2. Use GPT-4 to verbalize formulas and validate logical equivalence via Stanza parsing
3. Systematically vary D_max to measure impact on diversity and downstream performance

## Open Questions the Paper Calls Out

**Open Question 1**: How can the framework handle complex sentence structures like nested conditionals or long-distance dependencies? The current Stanza-based parsing is limited to simple sentences, and the paper suggests integrating DRT-based or Boxer-based semantic parsers for multi-clause structures.

**Open Question 2**: Can the system be extended to support modal or probabilistic logic for representing uncertainty and necessity? The paper proposes exploring modal operators (possibly, necessarily) beyond standard propositional logic to handle natural language uncertainty.

**Open Question 3**: Can the logical rule library be discovered and expanded automatically to reduce manual maintenance? The paper identifies automating rule discovery through inference sample analysis as a way to reduce the maintenance burden of the current manual 99-rule library.

## Limitations
- The complete 99-rule library specification is not provided, with only ~12 rules illustrated
- Exact LLM prompt templates and 7 stylistic templates are unspecified
- DFS depth bound D_max and pruning thresholds lack numerical specification
- Training hyperparameters for both pretraining and fine-tuning stages are not provided

## Confidence
- **High Confidence**: Core methodology (formalization → search → verbalization → training) is clearly described and logically sound
- **Medium Confidence**: Reported performance improvements are plausible but exact replication depends on unspecified implementation details
- **Low Confidence**: Completeness of 99-rule library, specific error rules, and LLM templates are insufficient for perfect reproduction

## Next Checks
1. Implement minimal working rule set and verify generation of diverse, non-trivial variants from 9 seed statements with proper duplicate elimination
2. Use GPT-4 with reconstructed prompts to verbalize formulas and validate logical equivalence via Stanza parsing with agreement rate measurement
3. Systematically vary D_max (3, 5, 7, 10) to measure impact on formula diversity and downstream performance on ReClor validation subset