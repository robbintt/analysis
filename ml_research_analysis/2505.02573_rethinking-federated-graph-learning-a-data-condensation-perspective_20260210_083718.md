---
ver: rpa2
title: 'Rethinking Federated Graph Learning: A Data Condensation Perspective'
arxiv_id: '2505.02573'
source_url: https://arxiv.org/abs/2505.02573
tags:
- graph
- condensed
- subgraph
- federated
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of federated graph learning
  (FGL) where existing methods relying on model parameters or gradients struggle with
  subgraph heterogeneity and introduce privacy risks. The authors propose FedGM, a
  novel paradigm using condensed graphs as optimization carriers instead of traditional
  model parameters.
---

# Rethinking Federated Graph Learning: A Data Condensation Perspective

## Quick Facts
- arXiv ID: 2505.02573
- Source URL: https://arxiv.org/abs/2505.02573
- Reference count: 15
- Key outcome: FedGM achieves up to 4.3% performance improvement over FedAvg and 4.1% over Fed-PUB, with average accuracy of 74.56%

## Executive Summary
This paper introduces FedGM, a novel federated graph learning paradigm that addresses the limitations of existing methods by using condensed graphs as optimization carriers instead of traditional model parameters or gradients. The approach tackles subgraph heterogeneity and privacy risks through a two-stage process where clients perform local subgraph condensation via gradient matching and upload condensed subgraphs to a central server. The server then optimizes these condensed features using class-wise gradients from real subgraphs to improve their quality. Extensive experiments across six datasets demonstrate that FedGM consistently outperforms state-of-the-art baselines while reducing communication costs through a single transmission round.

## Method Summary
FedGM operates through a two-stage condensation process. First, clients locally condense their subgraphs using gradient matching techniques, preserving essential information while reducing data volume. These condensed subgraphs are then uploaded to the server in a single communication round. The server performs class-wise gradient optimization on the received condensed features, iteratively improving their quality to enhance downstream GNN performance. This approach effectively bypasses the limitations of traditional federated graph learning methods that struggle with subgraph heterogeneity and introduce privacy risks through direct gradient sharing.

## Key Results
- FedGM achieves up to 4.3% performance improvement over FedAvg on tested datasets
- The method outperforms Fed-PUB by 4.1% on average across all experiments
- FedGM demonstrates robust performance across different client numbers and condensation ratios while maintaining lower communication costs

## Why This Works (Mechanism)
The effectiveness of FedGM stems from its innovative use of condensed graphs as optimization carriers, which preserves essential structural and feature information while reducing communication overhead. By avoiding direct sharing of model parameters or raw gradients, the method mitigates privacy risks inherent in traditional federated learning approaches. The gradient matching process ensures that condensed subgraphs maintain fidelity to the original data distribution, while the server-side class-wise optimization further enhances the quality of these condensed representations, leading to improved GNN performance.

## Foundational Learning
- **Graph Neural Networks (GNNs)**: Neural networks designed to operate on graph-structured data, crucial for processing relational information
  - Why needed: FGL requires effective processing of graph data across distributed clients
  - Quick check: Verify that GNN architectures can handle the condensed graph representations

- **Federated Learning**: Machine learning approach where model training occurs across decentralized devices without sharing raw data
  - Why needed: The paper addresses challenges specific to federated graph learning scenarios
  - Quick check: Confirm that the condensation approach maintains federated learning privacy guarantees

- **Gradient Matching**: Optimization technique that aligns gradients of different models or data representations
  - Why needed: Essential for creating high-quality condensed subgraphs that preserve learning objectives
  - Quick check: Validate that gradient matching preserves important feature relationships

- **Subgraph Heterogeneity**: Variability in graph structure and features across different clients or datasets
  - Why needed: Major challenge in federated graph learning that FedGM specifically addresses
  - Quick check: Test FedGM's robustness across diverse graph structures

## Architecture Onboarding

**Component Map:** Client subgraph → Gradient matching → Condensed subgraph → Server optimization → Enhanced condensed features → GNN training

**Critical Path:** The two-stage process (local condensation followed by server-side optimization) forms the critical path, where each stage builds upon the previous one to progressively improve the quality of the condensed representations.

**Design Tradeoffs:** The method trades computational overhead on the server side (for optimizing condensed features) against reduced client-side computation and communication costs. This design prioritizes privacy and efficiency over raw computational simplicity.

**Failure Signatures:** Poor gradient matching could lead to loss of critical structural information in condensed subgraphs. Insufficient server-side optimization might result in suboptimal condensed feature quality. Communication bottlenecks could occur if condensation ratios are not properly tuned.

**3 First Experiments to Run:**
1. Baseline comparison: Run FedGM against FedAvg and Fed-PUB on Cora dataset to verify performance improvements
2. Condensation ratio analysis: Test different condensation ratios to find optimal balance between information preservation and communication efficiency
3. Client number sensitivity: Evaluate FedGM's performance across varying numbers of clients (2, 4, 8, 16) to assess scalability

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Generalization to heterogeneous graphs with diverse edge types remains uncertain
- Scalability to industrial-scale graphs with millions of nodes is not thoroughly explored
- Privacy guarantees are claimed but not formally quantified or analyzed

## Confidence
- Performance claims: High
- Methodology description: High
- Scalability analysis: Medium
- Privacy guarantees: Low

## Next Checks
1. Scale-up validation: Test FedGM on large-scale heterogeneous graphs (e.g., OGB datasets) to assess computational overhead and memory requirements during condensation and optimization phases.

2. Privacy quantification: Implement formal privacy analysis using metrics like gradient inversion risk and differential privacy guarantees to validate the claimed privacy improvements over gradient-based methods.

3. Ablation study: Conduct systematic ablation studies to isolate the contributions of gradient matching and class-wise optimization components, and test the necessity of the two-stage condensation process.