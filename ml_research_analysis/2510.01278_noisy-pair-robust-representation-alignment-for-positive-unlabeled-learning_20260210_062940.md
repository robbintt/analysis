---
ver: rpa2
title: Noisy-Pair Robust Representation Alignment for Positive-Unlabeled Learning
arxiv_id: '2510.01278'
source_url: https://arxiv.org/abs/2510.01278
tags:
- learning
- data
- representations
- methods
- representation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of learning discriminative representations
  in Positive-Unlabeled (PU) learning, where only positive-labeled and unlabeled data
  are available. The key bottleneck is the unreliable supervision from PU data, which
  introduces noisy pairs and hinders effective representation learning.
---

# Noisy-Pair Robust Representation Alignment for Positive-Unlabeled Learning

## Quick Facts
- arXiv ID: 2510.01278
- Source URL: https://arxiv.org/abs/2510.01278
- Reference count: 40
- One-line primary result: NcPU achieves state-of-the-art performance in Positive-Unlabeled learning without requiring auxiliary negatives or pre-estimated parameters.

## Executive Summary
This paper addresses the challenge of learning discriminative representations in Positive-Unlabeled (PU) learning, where only positive-labeled and unlabeled data are available. The key bottleneck is unreliable supervision from PU data, which introduces noisy pairs and hinders effective representation learning. To address this, the authors propose NcPU, a non-contrastive PU learning framework that combines a noisy-pair robust supervised non-contrastive loss (NoiSNCL) with a phantom label disambiguation (PLD) scheme. NoiSNCL aligns intra-class representations while tolerating noisy pairs, and PLD refines supervision through regret-based label updates. Theoretically, these components benefit each other within an Expectation-Maximization framework. Empirically, NcPU achieves substantial improvements over state-of-the-art PU methods across diverse datasets, including CIFAR-10/100, STL-10, and remote sensing datasets (ABCD, xBD), without requiring auxiliary negatives or pre-estimated parameters. Notably, NcPU achieves performance comparable to its supervised counterpart, highlighting its effectiveness and real-world applicability.

## Method Summary
NcPU is a non-contrastive PU learning framework that addresses noisy supervision by combining NoiSNCL (a noisy-pair robust supervised non-contrastive loss) with PLD (phantom label disambiguation). The method uses an online encoder and a momentum-updated target encoder, with a linear classifier on top. Pseudo-labels are assigned to unlabeled data using class prototypes, refined through a regret-based update mechanism (PhantomGate) that injects conservative negative supervision. The total loss combines NoiSNCL for representation alignment and cross-entropy for label disambiguation, trained for 1300 epochs with SGD and cosine learning rate decay.

## Key Results
- NcPU achieves state-of-the-art performance on CIFAR-10/100, STL-10, and remote sensing datasets (ABCD, xBD) in PU learning settings.
- The method matches the performance of fully supervised learning baselines without requiring auxiliary negative samples or pre-estimated class priors.
- Ablation studies demonstrate the effectiveness of both the NoiSNCL loss and the PhantomGate mechanism in improving PU learning performance.

## Why This Works (Mechanism)

### Mechanism 1: Gradient Reweighting via Loss Transformation
The proposed NoiSNCL loss suppresses the influence of incorrectly paired samples (noisy pairs) on gradient updates relative to standard supervised non-contrastive loss. Standard supervised non-contrastive loss produces larger gradient magnitudes for mislabeled pairs than for correctly paired samples. NoiSNCL, defined as $\tilde{L}_r(x_i, x_j) = 2\sqrt{1 - \langle\tilde{q}_i, \tilde{k}_j\rangle\mathbb{1}\{y_i=y_j\}}$, inverts this relationship, ensuring clean pairs drive representation learning.

### Mechanism 2: Regret-Based Conservative Negative Supervision (PhantomGate)
PhantomGate prevents the trivial solution where all unlabeled data is classified as positive by injecting explicit negative supervision via regret-based label updates. It initially assigns a confident negative label if predictions are confident, then allows the pseudo target to be updated starting from this point if later predictions become uncertain, using a self-adaptive threshold that starts low and increases over time.

### Mechanism 3: Iterative Refinement via EM Framework
NoiSNCL and PLD form an iterative optimization loop interpretable as an Expectation-Maximization (EM) algorithm. In the E-step, pseudo-labels are assigned based on classifier predictions. In the M-step, minimizing NoiSNCL tightens clusters around class means. Better representations improve pseudo-label accuracy, and more accurate pseudo-labels reduce noise in NoiSNCL pairs.

## Foundational Learning

- **Concept: Positive-Unlabeled (PU) Learning**
  - Why needed here: This is the core problem setting. Understanding that you only have labeled positive and unlabeled data is essential to grasp why standard supervised learning fails.
  - Quick check question: If you trained a standard binary classifier on positive-labeled and unlabeled data (treating unlabeled as negative), what type of error would it systematically make?

- **Concept: Contrastive vs. Non-Contrastive Representation Learning**
  - Why needed here: NcPU uses a *non-contrastive* loss. Understanding the difference—contrastive uses positive (pull) and negative (push) pairs, non-contrastive primarily aligns positive pairs—is key to the paper's noise-robustness claim.
  - Quick check question: Why might a loss that only pulls same-class samples together be more robust to some mislabeled pairs than a loss that also actively pushes apart different-class samples?

- **Concept: Expectation-Maximization (EM) Algorithm**
  - Why needed here: The paper frames its iterative learning process as an EM algorithm. Knowing the basic E-step (estimate latent variables) and M-step (optimize parameters) helps understand why the two components work together.
  - Quick check question: In the context of this paper, what plays the role of the latent variable in the E-step?

## Architecture Onboarding

- **Component map:**
  - Online encoder g (with projection/prediction head) -> Classifier f -> PLD module -> Loss aggregator -> Momentum-updated target encoder g'

- **Critical path:**
  1. Generate two augmented views. Get online embedding q, target embedding k, and classifier prediction f(x).
  2. Update prototypes. Compute candidate pseudo-target s'. Apply PhantomGate: if confident negative (f₁(x) ≥ τ), set s = [0,1]ᵀ; else s = s'. Update threshold τ.
  3. Compute L̃ᵣ on same-class pairs (from s). Compute L_c between f(x) and s.
  4. Update online network, momentum-update target network.

- **Design tradeoffs:**
  - Non-contrastive vs. Contrastive: Avoids explicit negative pairs for robustness to noise, but may enforce uniformity less strongly (cross-entropy loss likely prevents collapse).
  - PhantomGate: Regret-based update recovers from early errors vs. simpler hard filtering which permanently discards samples.
  - Hyperparameters: Robust to momentum (α, β, γ), sensitive to loss weight (wᵣ) and update speed (β).

- **Failure signatures:**
  - Trivial Solution (All Positives): Model collapses to predicting positive. Check PhantomGate/SAT implementation.
  - Feature Collapse: All representations map to a single point. Check target network update and classifier loss.
  - Noisy Pair Domination: Poor class separation. Verify NoiSNCL loss formula and pair construction.

- **First 3 experiments:**
  1. Reproduce baseline comparison: Run NcPU vs. nnPU/DistPU on CIFAR-10/100 with 1000 labeled positives.
  2. Ablate NoiSNCL: Train nnPU with/without NoiSNCL to isolate the gradient reweighting effect.
  3. Visualize features: Extract encoder features on test set and plot t-SNE to qualitatively assess cluster separability vs. baselines.

## Open Questions the Paper Calls Out

- **Open Question 1**
  - Question: Can the NcPU framework be effectively extended to data modalities beyond image classification, such as natural language processing or time-series analysis?
  - Basis in paper: [explicit] The conclusion states, "we expect future research to extend this framework beyond image classification."
  - Why unresolved: All empirical evaluations in the study are restricted to image datasets (CIFAR, STL-10, and satellite imagery), leaving the generalizability of the representation alignment to other data structures unproven.
  - What evidence would resolve it: Experiments applying NcPU to benchmark datasets in text classification or audio recognition tasks, demonstrating performance comparable to or exceeding existing PU learning methods in those domains.

- **Open Question 2**
  - Question: Is the proposed NoiSNCL mechanism applicable to other weakly supervised learning paradigms, such as semi-supervised or partial label learning?
  - Basis in paper: [explicit] The conclusion suggests the framework "holds promise for broader applications in more weakly supervised learning scenarios."
  - Why unresolved: The paper focuses exclusively on Positive-Unlabeled (PU) learning, and while the theory generalizes, no experiments were conducted to validate its efficacy in semi-supervised or partial label settings.
  - What evidence would resolve it: Successful integration of the NoiSNCL loss into semi-supervised learning (SSL) pipelines, showing improved robustness to noisy pseudo-labels compared to standard contrastive losses.

- **Open Question 3**
  - Question: What are the theoretical convergence guarantees regarding the training instability occasionally observed in NcPU without entropy regularization?
  - Basis in paper: [inferred] The appendix notes that the model "may occasionally exhibit instability during training with a very small probability," which is currently mitigated by an entropy regularization term rather than a structural fix.
  - Why unresolved: The paper identifies the symptom and a patch but does not analyze the specific conditions or loss surface features that cause this instability.
  - What evidence would resolve it: A theoretical analysis of the loss landscape or gradient dynamics identifying the source of instability, or a modified loss function that guarantees convergence without auxiliary regularization terms.

## Limitations

- The reliance on class prototypes and confidence-based thresholds in PLD may be sensitive to dataset characteristics like class imbalance or noisy pseudo-labels in early training.
- The self-adaptive threshold mechanism lacks explicit empirical validation of its effectiveness.
- The assumption of von Mises-Fisher distributions and uniform class priors in the theoretical analysis may not hold universally.

## Confidence

- **NoiSNCL effectiveness**: High - Strong theoretical grounding and empirical validation across multiple datasets.
- **PhantomGate mechanism**: Medium - Effective in preventing trivial solutions but lacks explicit validation of the regret-based update mechanism.
- **EM framework interpretation**: Medium - Theoretically sound but relies on assumptions about data distribution that may not always hold.
- **Hyperparameter robustness**: Medium - Method shows robustness to momentum hyperparameters but sensitivity to loss weight and update speed requires careful tuning.

## Next Checks

1. Perform ablation studies on the self-adaptive threshold to quantify its impact on PLD performance.
2. Evaluate NcPU on highly imbalanced PU datasets to test the robustness of the prototype-based approach.
3. Conduct experiments with different backbone architectures to assess the scalability and generalizability of the method.