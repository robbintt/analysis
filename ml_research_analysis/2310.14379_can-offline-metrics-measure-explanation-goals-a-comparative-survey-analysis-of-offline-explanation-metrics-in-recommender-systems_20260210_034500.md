---
ver: rpa2
title: Can Offline Metrics Measure Explanation Goals? A Comparative Survey Analysis
  of Offline Explanation Metrics in Recommender Systems
arxiv_id: '2310.14379'
source_url: https://arxiv.org/abs/2310.14379
tags:
- explanation
- explanations
- metrics
- offline
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Offline evaluation of explanations in recommender systems is difficult\
  \ because explanation goals are subjective. We surveyed 103 papers and found that\
  \ explanations are mostly evaluated with anecdotal examples or metrics that don\u2019\
  t correlate with user perception."
---

# Can Offline Metrics Measure Explanation Goals? A Comparative Survey Analysis of Offline Explanation Metrics in Recommender Systems

## Quick Facts
- **arXiv ID**: 2310.14379
- **Source URL**: https://arxiv.org/abs/2310.14379
- **Reference count**: 40
- **Key outcome**: Proposed offline path metrics measuring attribute popularity, diversity, and interacted-item recency that show measurable correlation with user perception of explanation quality, while revealing trade-offs between diversity and popularity in explanation paths

## Executive Summary
This study investigates whether offline metrics can effectively measure explanation goals in recommender systems. Through a comprehensive survey of 103 papers, the authors found that current explanation evaluation practices rely heavily on anecdotal examples or metrics that do not correlate with user perception. To address this gap, they proposed novel offline path metrics that measure attribute popularity, diversity, and interacted-item recency. Experiments across six algorithms and two datasets demonstrated that these metrics can reflect user perception of explanation goals. A user study with 55 participants revealed that engagement is sensitive to perceived diversity, while transparency, trust, and persuasiveness are influenced by both perceived popularity and diversity.

## Method Summary
The authors conducted a two-phase study. First, they surveyed 103 papers to analyze current practices in explanation evaluation, identifying gaps between offline metrics and user perception. Second, they proposed and evaluated novel offline path metrics that measure attribute popularity, diversity, and interacted-item recency. These metrics were tested across six recommendation algorithms and two datasets, followed by an online user study with 55 participants to validate the correlation between offline metrics and perceived explanation quality. The study employed statistical analysis to assess the relationships between offline metrics, perceived metrics, and user experience dimensions.

## Key Results
- Current explanation evaluation practices predominantly use anecdotal examples or metrics that do not correlate with user perception
- Proposed offline path metrics show measurable correlation with user perception of explanation quality
- Diversity and popularity in explanation paths exhibit a trade-off relationship
- User engagement is primarily sensitive to perceived diversity, while transparency, trust, and persuasiveness are influenced by both perceived popularity and diversity

## Why This Works (Mechanism)
The proposed offline path metrics work by quantifying key aspects of explanation quality that align with user perception. The popularity metric captures how well explanations reflect common user preferences, while diversity measures the variety of attributes used in explanations. The interacted-item recency component ensures explanations remain relevant to recent user behavior. By combining these elements into path-based metrics, the approach captures the dynamic nature of explanations as users interact with recommended items, providing a more holistic evaluation framework that bridges the gap between offline evaluation and user experience.

## Foundational Learning

**Explanation Goals**: The objectives explanations should achieve (transparency, trust, persuasiveness, engagement). Why needed: To establish evaluation criteria that align with user needs. Quick check: Does the metric capture the intended user experience dimension?

**Offline Path Metrics**: Quantitative measures of explanation quality computed without user interaction, focusing on attribute patterns in recommendation paths. Why needed: To enable scalable evaluation without costly user studies. Quick check: Does the metric correlate with user perception across different algorithms?

**Perceived Metrics**: User-reported assessments of explanation quality based on actual interaction with the system. Why needed: To validate that offline metrics capture what matters to users. Quick check: Are the correlations between offline and perceived metrics statistically significant?

## Architecture Onboarding

**Component Map**: Offline Path Metrics -> User Perception -> Explanation Goals

**Critical Path**: Recommendation algorithm generates explanations -> Offline metrics extract path features (popularity, diversity, recency) -> User study validates correlation between metrics and perceived quality -> Refinement of metrics based on feedback

**Design Tradeoffs**: The study balances between computational efficiency of offline metrics and their ability to capture nuanced user experience. A key tradeoff is between metric simplicity (easier to compute) and comprehensiveness (better capturing user perception). The authors chose to implement three core metrics rather than a single complex measure to maintain interpretability while covering multiple explanation goals.

**Failure Signatures**: Poor correlation between offline metrics and user perception suggests the metrics are missing key aspects of explanation quality. If diversity metrics show no impact on engagement, this may indicate explanations are not effectively communicating item differences. High popularity but low trust scores suggest explanations may feel generic or untrustworthy despite aligning with common preferences.

**First 3 Experiments**:
1. Compute popularity and diversity metrics across different recommendation algorithms and assess their correlation
2. Conduct user study to measure perceived popularity and diversity, then correlate with offline metrics
3. Test the impact of varying explanation path diversity on user engagement metrics

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the findings suggest several areas for future research, including expanding the scope of explanation goals beyond transparency, trust, persuasiveness, and engagement, and developing more sophisticated offline metrics that capture additional dimensions of explanation quality.

## Limitations
- Small sample sizes in both literature survey (103 papers) and user study (55 participants) may limit generalizability
- Offline path metrics tested on only two datasets and six algorithms, constraining broader applicability
- Moderate effect sizes in correlations between offline metrics and user perception suggest incomplete capture of user experience nuances
- Focus on specific explanation goals may not address the full spectrum of potential explanation objectives in recommender systems

## Confidence

**High**: The finding that anecdotal examples and misaligned metrics dominate current explanation evaluation practices

**Medium**: The proposed offline path metrics showing measurable correlation with user perception

**Medium**: The trade-off relationship between diversity and popularity in explanation paths

**Medium**: The differential sensitivity of user experience dimensions to perceived diversity and popularity

## Next Checks

1. Replicate the user study with a larger, more diverse participant pool across different demographic segments and cultural backgrounds
2. Test the offline path metrics on additional datasets and algorithm types, particularly including non-traditional recommendation approaches
3. Conduct longitudinal studies to examine how user perception of explanation quality evolves over repeated interactions with the system