---
ver: rpa2
title: Graph Concept Bottleneck Models
arxiv_id: '2508.14255'
source_url: https://arxiv.org/abs/2508.14255
tags:
- concept
- graph
- uni00000013
- uni00000011
- concepts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Graph Concept Bottleneck Models (Graph CBMs),
  a novel framework that incorporates latent concept graphs to model interactions
  among concepts in Concept Bottleneck Models. By using Graph Neural Networks and
  contrastive learning, Graph CBMs capture intrinsic concept relationships that existing
  CBMs overlook.
---

# Graph Concept Bottleneck Models

## Quick Facts
- arXiv ID: 2508.14255
- Source URL: https://arxiv.org/abs/2508.14255
- Reference count: 40
- Graph Concept Bottleneck Models achieve 1-2% accuracy improvements over state-of-the-art CBMs in image classification

## Executive Summary
Graph Concept Bottleneck Models (Graph CBMs) introduce a novel framework that leverages latent concept graphs to model interactions among concepts in Concept Bottleneck Models (CBMs). By incorporating Graph Neural Networks (GNNs) and contrastive learning, Graph CBMs capture intrinsic concept relationships that existing CBMs overlook, leading to improved performance across multiple image classification datasets. The method achieves consistent accuracy improvements of 1-2% compared to state-of-the-art baselines while providing interpretable concept relationships.

## Method Summary
Graph CBMs extend traditional CBMs by introducing a latent concept graph structure that models interactions among concepts using GNNs. The framework employs contrastive learning to optimize concept embeddings and uses both label-free and concept-supervised training approaches. The method is designed to be model-agnostic, working with various backbone architectures while learning interpretable concept relationships that can match or recover ground-truth concept graphs.

## Key Results
- Achieves 1-2% accuracy improvements over state-of-the-art CBMs on image classification tasks
- Consistently outperforms baselines across five datasets: CUB, Flower102, HAM10000, CIFAR-10/100
- Learned concept graphs match or recover ground-truth concept graphs while providing interpretable relationships

## Why This Works (Mechanism)
Graph CBMs work by capturing latent concept relationships that traditional CBMs miss. The GNN component models concept interactions as a graph structure, allowing for information propagation between related concepts. Contrastive learning optimizes concept embeddings by pulling similar concepts closer while pushing dissimilar ones apart. This dual approach of structural modeling and embedding optimization enables the model to learn more meaningful concept representations that improve downstream prediction accuracy.

## Foundational Learning

**Graph Neural Networks**: Neural networks that operate on graph-structured data
- Why needed: To model interactions between concepts as a graph structure
- Quick check: Can propagate information between related concepts

**Contrastive Learning**: Learning method that pulls similar examples together while pushing dissimilar ones apart
- Why needed: To optimize concept embeddings by learning meaningful relationships
- Quick check: Improves embedding quality for downstream tasks

**Concept Bottleneck Models**: Models that use intermediate concept predictions for final classification
- Why needed: Provides interpretable intermediate representations
- Quick check: Enables concept-level intervention and debugging

## Architecture Onboarding

**Component Map**: Input -> Backbone Network -> Concept Extractor -> GNN Concept Graph -> Concept Predictor -> Output

**Critical Path**: The concept graph learning and contrastive optimization represent the core innovations that differentiate Graph CBMs from traditional CBMs.

**Design Tradeoffs**: Balances interpretability (concept-level predictions) with performance (GNN-based concept interactions) and flexibility (model-agnostic approach).

**Failure Signatures**: Poor concept graph structure learning may lead to degraded performance; contrastive learning instability could affect embedding quality.

**First Experiments**:
1. Test on CUB dataset with label-free training to validate core concept learning
2. Evaluate concept graph recovery on Flower102 with ground-truth concept labels
3. Compare against standard CBM on CIFAR-10 with concept-supervised training

## Open Questions the Paper Calls Out
None

## Limitations
- Primarily tested on image classification tasks, limiting domain generalizability
- Scalability to very large concept graphs and high-dimensional spaces not thoroughly explored
- Limited qualitative analysis of discovered concept relationships and interpretability

## Confidence
**High Confidence**: Core methodology and accuracy improvements are well-established
**Medium Confidence**: Interpretability claims and intervention task effectiveness need more validation
**Medium Confidence**: Generalization across architectures demonstrated but not extensively validated

## Next Checks
1. Evaluate Graph CBMs on non-image datasets (text classification, tabular data) to test cross-domain applicability
2. Test scalability on larger concept graphs (100+ concepts) and high-dimensional concept spaces
3. Conduct thorough ablation studies to quantify individual contributions of GNNs, contrastive learning, and concept graph structure