---
ver: rpa2
title: Sparse components distinguish visual pathways & their alignment to neural networks
arxiv_id: '2510.08858'
source_url: https://arxiv.org/abs/2510.08858
tags:
- components
- alignment
- visual
- neural
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The ventral, dorsal, and lateral streams in human visual cortex
  are thought to process visual information along distinct computational pathways,
  yet deep neural networks trained on a single task capture all three pathways similarly
  well. This inconsistency was addressed by applying a sparse decomposition approach
  to identify dominant components in each stream.
---

# Sparse components distinguish visual pathways & their alignment to neural networks

## Quick Facts
- arXiv ID: 2510.08858
- Source URL: https://arxiv.org/abs/2510.08858
- Reference count: 36
- Sparse decomposition reveals distinct response profiles across ventral, dorsal, and lateral visual streams

## Executive Summary
This study addresses a puzzling inconsistency in visual neuroscience: while the ventral, dorsal, and lateral streams in human visual cortex are thought to process visual information along distinct computational pathways, deep neural networks trained on a single task capture all three pathways similarly well. The authors resolve this by applying a sparse decomposition approach to identify dominant components in each stream, revealing distinct response profiles and introducing a new measure (Sparse Component Alignment) that can detect differential alignment between neural networks and different visual pathways.

The results show that while standard alignment metrics cannot distinguish DNN alignment with different visual streams due to their rotational invariance, the SCA measure reveals significant differences: DNNs are substantially more aligned with the ventral stream than with the lateral or dorsal streams. This suggests that current DNNs share similar tuning properties with the ventral stream, while highlighting the need for different modeling approaches to capture lateral and dorsal stream computations.

## Method Summary
The researchers applied sparse non-negative matrix factorization to fMRI responses from ventral, dorsal, and lateral visual streams, decomposing each into 25 dominant components. They then evaluated DNN alignment using both standard representational similarity metrics and their newly introduced Sparse Component Alignment (SCA) measure. The SCA metric was specifically designed to preserve sensitivity to neural tuning axes while assessing representational alignment. They tested multiple DNN architectures and compared alignment scores against untrained baseline networks.

## Key Results
- Ventral stream components showed selectivity for faces, scenes, bodies, food, and text
- Lateral stream components were selective for group interactions, implied motion, hand actions, and reach-spaces
- SCA revealed ventral stream alignment scores of 0.187 versus 0.047 and 0.058 for lateral and dorsal streams respectively, with standard metrics showing no differences

## Why This Works (Mechanism)
The sparse decomposition approach successfully isolates functionally distinct neural response patterns that standard metrics average over. By decomposing neural responses into sparse components, the method preserves the specific tuning properties of different visual pathways. The SCA metric works by maintaining sensitivity to the direction of neural tuning axes while assessing representational alignment, overcoming the rotational invariance limitation of standard measures.

## Foundational Learning

1. **Visual stream specialization** - The ventral stream processes object identity, the dorsal stream processes spatial information and action, and the lateral stream processes social and interactive content. Needed to understand why different DNNs might align differently with each stream.

2. **Sparse non-negative matrix factorization** - A decomposition technique that identifies dominant components in neural data while enforcing sparsity constraints. Needed to isolate functionally distinct response patterns from mixed neural signals.

3. **Representational alignment metrics** - Measures like RSA that compare representational geometries between neural and artificial systems. Needed as baseline comparison for the new SCA metric.

4. **Rotational invariance** - A property of standard alignment metrics that makes them insensitive to the direction of neural tuning axes. Needed to understand why traditional metrics fail to detect stream-specific differences.

5. **fMRI response decomposition** - The process of breaking down complex neural responses into interpretable components. Needed to identify which stimulus categories drive different visual pathways.

6. **Neural tuning curves** - The response profiles of neurons to different stimulus features. Needed to understand how sparse components capture specific computational properties.

## Architecture Onboarding

Component map: fMRI data -> Sparse decomposition -> Component profiles -> SCA computation -> DNN comparison

Critical path: The sparse decomposition step is critical as it isolates functionally distinct components that standard analysis would miss. Without this step, the differential alignment between DNNs and visual streams would remain invisible.

Design tradeoffs: The choice of 25 components per stream represents a balance between capturing sufficient variance while maintaining interpretability. Too few components might miss important distinctions, while too many could overfit and reduce generalizability.

Failure signatures: If the sparse components don't show clear stimulus selectivity or if SCA scores don't differ meaningfully from standard metrics, this would suggest the decomposition method isn't capturing functionally relevant distinctions.

First experiments:
1. Test whether different DNN architectures show similar differential alignment patterns
2. Validate SCA scores by comparing with known ground truth alignments in simpler systems
3. Test robustness of results to different numbers of sparse components

## Open Questions the Paper Calls Out
None

## Limitations
- Sparse components may reflect decomposition artifacts rather than true functional distinctions
- The causal relationship between components and computational pathways is not directly tested
- Alignment differences could reflect architectural biases rather than fundamental computational differences

## Confidence
- High: SCA metric's ability to detect differential alignment invisible to standard metrics
- Medium: Interpretation that ventral stream alignment is significantly stronger than lateral/dorsal alignment
- Low: Biological significance of specific stimulus categories associated with each stream's components

## Next Checks
1. Test whether sparse component distinctions persist across different DNN architectures and training regimes
2. Conduct causal manipulation studies where specific components are selectively enhanced or suppressed
3. Validate SCA metric against known neural recordings with established ground truth alignment relationships