---
ver: rpa2
title: 'Agnostic Learning under Targeted Poisoning: Optimal Rates and the Role of
  Randomness'
arxiv_id: '2506.03075'
source_url: https://arxiv.org/abs/2506.03075
tags:
- poisoning
- learning
- learner
- distribution
- sample
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies instance-targeted poisoning attacks in the\
  \ agnostic learning setting, where an adversary corrupts a fraction of the training\
  \ data to cause failure on a specific test point. In the realizable setting, prior\
  \ work showed optimal error scales as \u0398(d\u03B7), where d is the VC dimension."
---

# Agnostic Learning under Targeted Poisoning: Optimal Rates and the Role of Randomness

## Quick Facts
- arXiv ID: 2506.03075
- Source URL: https://arxiv.org/abs/2506.03075
- Authors: Bogdan Chornomaz; Yonatan Koren; Shay Moran; Tom Waknine
- Reference count: 12
- Primary result: In the agnostic setting, optimal excess error under targeted poisoning is Θ̃(√dη)

## Executive Summary
This paper resolves the open problem of optimal error rates in agnostic learning under targeted poisoning attacks. While realizable learning achieves optimal error Θ(dη), deterministic learners in the agnostic setting can be driven to near-perfect error with minimal poisoning budgets. The authors establish that randomized learners achieve excess error Θ̃(√dη), which is optimal even when the adversary observes the learner's random bits (public randomness).

The key insight is that randomization fundamentally changes the attack surface. Deterministic learners are vulnerable to targeted attacks that exploit worst-case data distributions, while randomized learners average over hypotheses to achieve robustness. The paper provides matching upper and lower bounds, demonstrating that √dη is the fundamental limit for agnostic learning under poisoning, regardless of the adversary's knowledge of the learner's randomness.

## Method Summary
The upper bound is achieved through a randomized learner that samples hypotheses with probability proportional to exp(-λ·empirical loss), leveraging connections to differential privacy and multiplicative weights algorithms. This exponential weighting scheme creates a smooth distribution over hypotheses that resists targeted attacks. The lower bound construction uses the poisoned coin guessing problem, showing that an adversary can force error Ω(√η) even for simple hypothesis classes. This lower bound is extended to VC classes via a direct-sum argument, demonstrating that the √dη scaling is tight.

## Key Results
- Deterministic learners in agnostic setting can be driven to error approaching 1 with small poisoning budgets
- Randomized learners achieve optimal excess error Θ̃(√dη) under targeted poisoning
- These bounds hold even with public randomness (adversary observes learner's random bits)
- The excess error cannot fall below √dη infinitely often for any fixed distribution

## Why This Works (Mechanism)
The mechanism relies on randomization creating uncertainty for the adversary. In deterministic learning, the adversary can precisely target the specific hypothesis that will be output. With randomized learners, the adversary must poison against a distribution over hypotheses, forcing a trade-off between attack effectiveness and poisoning budget. The exponential weighting scheme ensures that hypotheses with lower empirical loss receive higher sampling probability, while still maintaining sufficient diversity to resist targeted corruption.

## Foundational Learning
- VC dimension (why needed: characterizes hypothesis class complexity; quick check: verify d for specific classes)
- Agnostic learning (why needed: models real-world noise; quick check: confirm noise rate η)
- Differential privacy (why needed: connects to robust learning; quick check: check privacy parameters)
- Multiplicative weights algorithm (why needed: provides robust hypothesis sampling; quick check: verify convergence rates)
- Poisoned coin guessing (why needed: establishes lower bound technique; quick check: confirm Ω(√η) bound)
- Direct-sum arguments (why needed: extends lower bounds to VC classes; quick check: verify decomposition)

## Architecture Onboarding

Component map: Data -> Poisoned Data -> Randomized Learner -> Hypothesis Distribution -> Test Point Prediction

Critical path: The learner observes poisoned training data, samples hypotheses from exponential distribution over empirical losses, and outputs a randomized classifier. The adversary observes training data and learner's random bits, then optimally poisons to maximize error on target test point.

Design tradeoffs: The paper chooses exponential weighting over alternatives like uniform sampling or Bayesian approaches because it provides provable robustness guarantees. This comes at the cost of computational complexity in sampling from the distribution.

Failure signatures: Excess error scaling as dη (instead of √dη) indicates deterministic learning. Error scaling worse than √dη suggests either suboptimal randomization or overly powerful adversary.

First experiments:
1. Implement deterministic vs randomized learners on simple VC classes (intervals, rectangles) under targeted poisoning
2. Empirically verify √dη scaling across different VC dimensions and poisoning rates
3. Test robustness of exponential weighting scheme against various adversary strategies

## Open Questions the Paper Calls Out
Major uncertainties remain around the tightness of the Θ̃(√dη) bounds in various distributional regimes. The upper bound relies on a specific exponential sampling scheme, but it's unclear whether this is optimal across all VC classes or if alternative randomized learners could achieve better rates. The lower bound construction using poisoned coin guessing extends to VC classes via a direct-sum argument, but the tightness of this extension for complex hypothesis spaces needs further verification.

## Limitations
- The assumption of public randomness (adversary observing learner's random bits) may not hold in practical settings
- Analysis focuses on excess error rather than other robustness measures like margin-based guarantees
- The exponential sampling scheme may be computationally expensive for complex hypothesis spaces

## Confidence

| Claim | Confidence |
|-------|------------|
| Optimal excess error rate Θ̃(√dη) | High |
| Public randomness resilience | Medium |
| VC class generalization via direct-sum | Medium |

## Next Checks
1. Implement the exponential sampling learner algorithm and test empirically across different VC classes (intervals, rectangles, linear separators) to verify the √dη scaling holds in practice
2. Analyze whether alternative randomized learning algorithms (beyond the exponential weighting scheme) can achieve the same or better bounds
3. Extend the poisoned coin guessing lower bound analysis to specific VC classes like linear separators in higher dimensions to check if the direct-sum argument introduces any looseness