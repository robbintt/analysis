---
ver: rpa2
title: 'BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented
  Generation on Complex Documents'
arxiv_id: '2512.03413'
source_url: https://arxiv.org/abs/2512.03413
tags:
- arxiv
- document
- query
- retrieval
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BookRAG, a novel retrieval-augmented generation
  approach designed for complex documents with hierarchical structures. BookRAG constructs
  a document-native BookIndex that integrates a hierarchical tree structure derived
  from document layout with a knowledge graph capturing fine-grained entity relations,
  linking them via a Graph-Tree Link.
---

# BookRAG: A Hierarchical Structure-aware Index-based Approach for Retrieval-Augmented Generation on Complex Documents

## Quick Facts
- **arXiv ID:** 2512.03413
- **Source URL:** https://arxiv.org/abs/2512.03413
- **Reference count:** 40
- **Primary result:** 43.8% Exact Match on MMLongBench, outperforming baselines

## Executive Summary
BookRAG is a novel retrieval-augmented generation approach designed for complex documents with hierarchical structures. It constructs a document-native BookIndex that integrates a hierarchical tree structure derived from document layout with a knowledge graph capturing fine-grained entity relations. An agent-based retrieval method dynamically classifies queries and generates tailored retrieval workflows inspired by Information Foraging Theory. Extensive experiments demonstrate BookRAG significantly outperforms state-of-the-art baselines while maintaining competitive efficiency.

## Method Summary
BookRAG introduces a hierarchical structure-aware index for retrieval-augmented generation on complex documents. The core innovation is the BookIndex, which combines a tree structure from document layout with a knowledge graph of entity relations, linked through a Graph-Tree Link. The system uses an agent-based retrieval approach that classifies queries and generates tailored workflows based on Information Foraging Theory. The approach includes entity resolution using a gradient-based method with Qwen models, and operator-based retrieval with Formulator, Selector, Reasoner, and Synthesizer components.

## Key Results
- Achieves 43.8% Exact Match on MMLongBench benchmark
- Achieves 61.0% on M3DocVQA benchmark
- Achieves 55.2% accuracy on Qasper benchmark

## Why This Works (Mechanism)
BookRAG leverages document structure through hierarchical indexing and entity relations. By combining layout-derived tree structures with knowledge graphs, it captures both document organization and semantic relationships. The agent-based retrieval dynamically adapts to query complexity, using Information Foraging Theory to guide evidence selection. This structure-aware approach enables more precise retrieval than flat indexing methods, particularly for complex, multi-hop questions in long documents.

## Foundational Learning
- **MinerU Layout Parsing**: Extracts structured layout blocks from PDFs. *Why needed:* Converts unstructured documents into analyzable components. *Quick check:* Verify extracted blocks cover ground-truth sections.
- **Information Foraging Theory**: Guides evidence selection in retrieval workflows. *Why needed:* Provides theoretical framework for optimal information gathering. *Quick check:* Confirm agent selects relevant blocks based on "information scent."
- **Entity Resolution with Gradient Detection**: Links entities across document sections. *Why needed:* Creates connected knowledge graph from fragmented mentions. *Quick check:* Monitor gradient threshold sensitivity on entity linking accuracy.
- **Hierarchical Document Tree**: Organizes content by layout levels. *Why needed:* Preserves document structure for context-aware retrieval. *Quick check:* Validate tree depth matches document complexity.
- **Knowledge Graph Construction**: Captures entity relationships. *Why needed:* Enables multi-hop reasoning across document sections. *Quick check:* Measure graph density and connectivity metrics.

## Architecture Onboarding

**Component map:** MinerU -> Tree/KG Construction -> Entity Resolution -> Agent-based Retrieval -> Generation

**Critical path:** Query Classification -> Operator Selection (Selector/Reasoner/Synthesizer) -> Evidence Retrieval -> Answer Generation

**Design tradeoffs:** Structure preservation vs. retrieval speed; fine-grained entity relations vs. graph complexity; dynamic workflow vs. computational overhead

**Failure signatures:** Parsing Loss (0 recall if block missed), Over-decomposition (unnecessary multi-hop plans), Entity Fragmentation (disconnected graph components)

**3 first experiments:**
1. Validate Section Filtering and Entity Extraction prompts on sample PDFs to ensure MinerU blocks map to plausible tree/KG
2. Test Algorithm 1 entity resolution with varying top_k and gradient thresholds to identify optimal settings
3. Run full pipeline on MMLongBench subset, measuring EM, retrieval recall, and per-query latency

## Open Questions the Paper Calls Out
None

## Limitations
- Performance critically depends on quality of Section Filtering and Entity Extraction prompts, which are not fully specified
- Retrieval recall assumes perfect document parsing; MinerU failures directly zero out block recall
- Efficiency claims lack concrete wall-clock or memory metrics for comparison

## Confidence

| Claim | Confidence Level |
|---|---|
| Retrieval workflow design and empirical gains | High |
| BookIndex integration of tree/KG structures | Medium |
| Efficiency parity with baselines | Low |

## Next Checks
1. Reconstruct and validate Section Filtering and Entity Extraction prompts on sample PDFs
2. Run Algorithm 1 entity resolution with varying top_k values (5, 10, 20) and gradient thresholds
3. Execute full BookRAG pipeline on MMLongBench subset, measuring EM, retrieval recall, and per-query latency