---
ver: rpa2
title: Contrastive and Multi-Task Learning on Noisy Brain Signals with Nonlinear Dynamical
  Signatures
arxiv_id: '2601.08549'
source_url: https://arxiv.org/abs/2601.08549
tags:
- learning
- contrastive
- loss
- classification
- chaos
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a two-stage multitask learning framework for
  EEG analysis that combines denoising, dynamical modeling, and contrastive representation
  learning. A denoising autoencoder suppresses artifacts and stabilizes temporal dynamics,
  while a multitask Transformer jointly performs motor imagery classification, chaotic/non-chaotic
  regime discrimination via Lyapunov exponents, and self-supervised contrastive learning
  with NT-Xent loss.
---

# Contrastive and Multi-Task Learning on Noisy Brain Signals with Nonlinear Dynamical Signatures

## Quick Facts
- arXiv ID: 2601.08549
- Source URL: https://arxiv.org/abs/2601.08549
- Reference count: 40
- This work introduces a two-stage multitask learning framework for EEG analysis that combines denoising, dynamical modeling, and contrastive representation learning, improving robustness and generalization for motor imagery classification.

## Executive Summary
This paper presents a two-stage multitask learning framework for EEG analysis that integrates denoising, dynamical systems theory, and self-supervised learning. The approach first trains a denoising autoencoder to suppress artifacts and stabilize temporal dynamics, then uses a multitask Transformer to jointly perform motor imagery classification, chaotic/non-chaotic regime discrimination via Lyapunov exponents, and self-supervised contrastive learning. The architecture leverages a convolutional backbone and Transformer encoder to capture spatial-temporal structure and dynamical signatures. Empirical results show the framework improves robustness and generalization, outperforming strong baselines and state-of-the-art methods on motor imagery EEG decoding tasks.

## Method Summary
The framework employs a two-stage training approach. Stage 1 uses a Denoising Autoencoder (DAE) with SmoothL1Loss and SpectralLoss to remove artifacts from raw EEG signals. Stage 2 trains a multitask Transformer with three heads: motor imagery classification (CE loss), chaos detection (BCE loss using Lyapunov exponent-derived labels), and contrastive learning (NT-Xent loss with EEG-specific augmentations). The model is trained on BCI2000 and BNCI Horizon 2020 datasets with leave-one-subject-out validation, achieving improved robustness across datasets through the staged design that separates noise reduction from higher-level feature learning.

## Key Results
- The full model achieves balanced performance gains across classification and dynamical characterization tasks, outperforming strong baselines and state-of-the-art methods on motor imagery EEG decoding tasks
- Ablation studies confirm the complementary contributions of denoising, dynamical features, and self-supervised learning
- Empirical results show improved robustness and generalization compared to existing approaches

## Why This Works (Mechanism)

### Mechanism 1
Separating denoising (Stage 1) from discriminative learning (Stage 2) reduces optimization interference between reconstruction and classification objectives. A Denoising Autoencoder (DAE) first learns to suppress artifacts (eye blinks, muscle activity, environmental noise) using a weighted combination of SmoothL1Loss and SpectralLoss. The cleaned signals then feed into the multitask Transformer, which never sees raw corrupted inputs. This architectural separation prevents gradients from downstream tasks from corrupting the denoising basis.

### Mechanism 2
Using Lyapunov exponent-based chaos/non-chaos labels as auxiliary supervision forces the shared encoder to learn representations sensitive to nonlinear brain dynamics, improving downstream MI classification. Chaos labels are derived via two unsupervised pipelines: RNN-based full Lyapunov spectrum estimation using clipped shPLRNNs with Generalized Teacher Forcing, and energy-based tagging using spectral and permutation entropy clustering. The chaos detection head provides gradient signals that encourage the encoder to capture dynamical structure, not just spectral power.

### Mechanism 3
Self-supervised contrastive learning with EEG-specific augmentations produces noise-invariant representations that transfer across subjects and sessions. Each trial is augmented twice (jitter, scaling, time masking, channel dropout) to create positive pairs. The NT-Xent loss pulls embeddings of paired views together while pushing apart embeddings from different trials. This encourages the encoder to learn features invariant to electrode variability, transient dropouts, and amplitude fluctuations while preserving task-relevant dynamics.

## Foundational Learning

- **Denoising Autoencoders**
  - Why needed here: DAEs learn to reconstruct clean signals from corrupted inputs without requiring paired clean/noisy labels. Essential for Stage 1 preprocessing where ground-truth clean EEG is unavailable.
  - Quick check question: Can you explain why the DAE uses a combination of SmoothL1Loss and SpectralLoss rather than simple MSE?

- **Lyapunov Exponents and Dynamical Systems**
  - Why needed here: The paper uses maximum Lyapunov exponent sign to classify chaotic vs. non-chaotic dynamics. Understanding this requires grasping how LEs quantify sensitivity to initial conditions and attractor geometry.
  - Quick check question: Given the definition λmax = lim(T→∞) (1/T) log(||Π JT-k||), what does a positive λmax imply about nearby trajectories?

- **Contrastive Learning and NT-Xent Loss**
  - Why needed here: Self-supervised representation learning via NT-Xent is the third training objective. Understanding how positive/negative pairs are formed and how the temperature parameter affects optimization is critical.
  - Quick check question: Why does the paper use τ=0.5, and what happens to the loss gradient if τ is set too low vs. too high?

## Architecture Onboarding

- **Component map**: Raw EEG tensor (B×C×T) → MinMax normalization → DAE (1D Conv encoder-decoder) → CNN backbone (2 conv1d) → Transformer encoder (2-4 layers) → 3 task heads (MI classification, chaos detection, contrastive projection)

- **Critical path**: 
  1. Pre-train DAE for 150 epochs (unsupervised, reconstruction loss only)
  2. Freeze DAE, train full MTL model for 200-250 epochs with joint loss: Ltotal = λc·Lclass + λd·LLE-based + λs·Lcontrastive
  3. Loss weights: CE=1.0, Chaos=0.6, Contrastive=0.3 (tunable based on task priority)

- **Design tradeoffs**:
  - Full Contrastive (4 augmentations) vs. Light Contrastive (2 augmentations): Full provides more invariance but may suppress dynamical nuance; Light improves MI at slight cost to chaos detection
  - Two-stage vs. end-to-end: Separation improves stability but prevents joint optimization of denoising and task objectives
  - CNN-Transformer hybrid: CNN captures local spatial features efficiently; Transformer models long-range temporal dependencies but increases compute

- **Failure signatures**:
  - Low chaos detection accuracy with high MI accuracy: Augmentations may be destroying dynamical structure—reduce masking/dropout
  - DAE reconstruction loss plateaus early: Check SNR distribution; if already high-SNR, DAE provides diminishing returns
  - Contrastive loss dominates (MI/chaos accuracy drops): Increase λc and λd relative to λs

- **First 3 experiments**:
  1. Ablation by component: Train models with each component removed (w/o DAE, w/o contrastive, w/o chaos task) to quantify individual contributions
  2. Augmentation sensitivity: Compare Full Contrastive vs. Light Contrastive vs. no contrastive on both MI and chaos tasks
  3. Cross-dataset transfer: Train on BCI2000 (64 channels, 160 Hz), evaluate on BNCI Horizon 2020 (22 channels, 250 Hz) with and without DAE

## Open Questions the Paper Calls Out

### Open Question 1
Can expanding the classification to include finer dynamical regimes (periodic, quasi-periodic, no attractor) improve performance over the binary chaotic/non-chaotic labels? The current study aggregates all non-chaotic dynamics into a single class to simplify the task.

### Open Question 2
Can Graph Neural Networks (GNNs) improve spatial modeling of EEG channels compared to the current CNN backbone? The existing architecture relies exclusively on 1D convolutions for spatial feature extraction.

### Open Question 3
What explainable AI techniques can effectively map the learned representations to physiological markers? The limitations section notes the deep learning model lacks interpretability, highlighting a need for transparency in clinical applications.

## Limitations

- The validity of using short-term Lyapunov exponent estimates from noisy EEG segments remains unvalidated; finite-time estimation error could inject noise into the auxiliary supervision signal
- Limited external generalization testing - while the staged denoising approach is theoretically sound, empirical validation across diverse EEG datasets and clinical applications is needed
- The optimal balance between denoising strength and preservation of task-relevant dynamics (e.g., muscle artifacts that may correlate with motor imagery intensity) is not systematically explored

## Confidence

- **High Confidence**: The staged two-step training approach (denoising followed by discriminative learning) is well-established in signal processing and addresses known optimization interference issues
- **Medium Confidence**: The integration of dynamical systems theory (Lyapunov exponents) with deep learning is novel and theoretically justified, but practical effectiveness depends on estimation reliability
- **Medium Confidence**: Contrastive learning with EEG-specific augmentations is supported by corpus evidence, but the specific augmentation choices and their impact on dynamical signatures require further validation

## Next Checks

1. **Ablation study with task-relevant artifacts**: Train with controlled amounts of muscle artifact preservation to determine the optimal denoising threshold where signal preservation meets noise reduction
2. **Lyapunov estimation robustness test**: Compare chaos detection performance using different estimation windows (2s vs 4s vs 6s) and multiple estimation methods to quantify finite-time error impact
3. **Cross-dataset transfer with clinical EEG**: Evaluate the framework on clinical EEG datasets (epilepsy, sleep disorders) to test generalization beyond motor imagery paradigms and validate denoising effectiveness in noisier real-world conditions