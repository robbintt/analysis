---
ver: rpa2
title: 'Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language
  Navigation'
arxiv_id: '2512.08186'
source_url: https://arxiv.org/abs/2512.08186
tags:
- navigation
- goal
- system
- pixel
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces DualVLN, the first dual-system VLN foundation
  model that decouples high-level reasoning from low-level control. System 2, a VLM-based
  global planner, "grounds slowly" by predicting mid-term pixel goals via image-grounded
  reasoning.
---

# Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation

## Quick Facts
- arXiv ID: 2512.08186
- Source URL: https://arxiv.org/abs/2512.08186
- Authors: Meng Wei; Chenyang Wan; Jiaqi Peng; Xiqian Yu; Yuqiang Yang; Delin Feng; Wenzhe Cai; Chenming Zhu; Tai Wang; Jiangmiao Pang; Xihui Liu
- Reference count: 14
- Primary result: First dual-system VLN foundation model that decouples high-level reasoning from low-level control, achieving state-of-the-art results on VLN-CE and VLN-PE benchmarks

## Executive Summary
This work introduces DualVLN, a novel dual-system foundation model for vision-and-language navigation that separates high-level reasoning from low-level control. The model employs System 2, a VLM-based global planner that performs image-grounded reasoning to predict mid-term pixel goals, and System 1, a lightweight diffusion-based policy that generates smooth trajectories conditioned on these pixel goals. This architecture enables robust real-time control, adaptive obstacle avoidance, and long-horizon planning while achieving state-of-the-art performance on standard VLN benchmarks and demonstrating strong generalization across diverse real-world scenarios and robot platforms.

## Method Summary
DualVLN implements a dual-system approach inspired by cognitive systems theory, where System 2 (the "slow" component) handles high-level reasoning and planning, while System 1 (the "fast" component) manages real-time control and execution. System 2 utilizes a vision-language model to analyze the environment and predict mid-term pixel goals through image-grounded reasoning, providing strategic guidance for navigation tasks. System 1 employs a lightweight diffusion-based policy that takes these pixel goals and latent features as input to generate smooth, collision-free trajectories in real-time. This decoupling allows the model to leverage the strategic capabilities of large VLMs while maintaining the responsiveness required for physical robot control, resulting in improved performance on both planning and execution aspects of vision-and-language navigation.

## Key Results
- Achieves state-of-the-art performance on VLN-CE and VLN-PE benchmarks
- Demonstrates strong generalization across diverse real-world scenarios and robot platforms
- Enables robust real-time control with adaptive obstacle avoidance
- Successfully handles long-horizon planning tasks through the dual-system architecture

## Why This Works (Mechanism)
The dual-system architecture works by leveraging complementary strengths of different computational approaches. System 2's VLM-based reasoning provides strategic, context-aware planning that considers the full environment and task requirements, while System 1's diffusion-based policy offers rapid, reactive control that can adapt to immediate obstacles and changes. The mid-term pixel goals act as a bridge between these systems, translating high-level strategic intentions into concrete, actionable targets for low-level control. This separation of concerns allows each system to excel at its specialized function without being constrained by the limitations of the other, resulting in better overall performance than monolithic approaches that must balance competing demands within a single model.

## Foundational Learning

**Vision-Language Models (VLMs)**: Pre-trained models that can process both visual and textual information, enabling reasoning about environments and tasks. Needed for System 2's global planning capabilities; quick check: verify the VLM can accurately interpret complex scene descriptions.

**Diffusion-based Policies**: Generative models that iteratively refine trajectories through denoising processes, providing smooth and natural motion patterns. Needed for System 1's real-time control; quick check: ensure generated trajectories avoid collisions and maintain stability.

**Pixel Goal Prediction**: The process of identifying specific spatial targets in image space that guide navigation. Needed to bridge high-level planning and low-level control; quick check: validate pixel goals align with task objectives and are reachable.

**Dual-System Cognitive Architecture**: A framework separating deliberative reasoning from reactive control, inspired by human cognitive systems. Needed to balance strategic planning with real-time responsiveness; quick check: verify the systems coordinate effectively without conflicting commands.

## Architecture Onboarding

**Component Map**: VLM (System 2) -> Pixel Goal Prediction -> Diffusion Policy (System 1) -> Robot Control

**Critical Path**: Language instruction → VLM reasoning → Mid-term pixel goal → Latent feature extraction → Diffusion trajectory generation → Robot actuation

**Design Tradeoffs**: The primary tradeoff involves the computational overhead of System 2's VLM processing versus the benefits of strategic planning. While System 2 provides superior guidance, it introduces latency that could impact real-time performance. The architecture mitigates this by having System 1 handle immediate control while System 2 updates guidance at a slower rate.

**Failure Signatures**: System 2 failures manifest as poor strategic guidance leading to inefficient paths or task failures. System 1 failures appear as unstable trajectories, collision with obstacles, or inability to follow pixel goals accurately. Communication failures between systems result in mismatched planning and execution.

**3 First Experiments**:
1. Test individual components in isolation: evaluate VLM goal prediction accuracy and diffusion policy trajectory quality separately
2. Validate system coordination: run simple navigation tasks with known solutions to verify the slow-fast coordination mechanism
3. Assess real-time performance: measure control latency and stability under varying computational loads

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Heavy reliance on pre-trained VLM components that may have domain-specific biases or limited availability
- Computational overhead from System 2's VLM processing may constrain real-time deployment in resource-limited scenarios
- Assumption that mid-term pixel goals provide sufficient guidance may break down in highly dynamic environments requiring immediate obstacle avoidance
- Limited validation across different robot platforms and sensor configurations beyond reported benchmarks

## Confidence

**High Confidence Claims**:
- DualVLN being the first dual-system VLN foundation model
- State-of-the-art results on VLN-CE and VLN-PE benchmarks

**Medium Confidence Claims**:
- Strong generalization across diverse real-world scenarios
- Robust real-time control capability
- Adaptive obstacle avoidance performance

## Next Checks

1. Evaluate DualVLN's performance when deployed on robots with different sensor configurations (e.g., varying camera resolutions, LiDAR integration) to assess cross-platform generalization.

2. Conduct ablation studies comparing DualVLN against single-system baselines that use similar VLM components but without the dual-system architecture to isolate the contribution of the decoupling approach.

3. Test the model in highly dynamic environments with moving obstacles and rapidly changing conditions to evaluate the robustness of the slow-fast coordination mechanism.