---
ver: rpa2
title: On VLMs for Diverse Tasks in Multimodal Meme Classification
arxiv_id: '2505.20937'
source_url: https://arxiv.org/abs/2505.20937
tags:
- meme
- vlms
- memes
- text
- understanding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study systematically evaluates vision-language models (VLMs)
  for meme classification tasks, including sarcasm, offensiveness, and sentiment detection.
  Three experimental strategies are explored: diverse prompting (zero/few-shot with
  chain-of-thought), LoRA fine-tuning, and a novel approach combining VLM-generated
  explanations with LLM fine-tuning.'
---

# On VLMs for Diverse Tasks in Multimodal Meme Classification

## Quick Facts
- arXiv ID: 2505.20937
- Source URL: https://arxiv.org/abs/2505.20937
- Reference count: 35
- Three experimental strategies outperform direct VLM fine-tuning for meme classification tasks

## Executive Summary
This study systematically evaluates vision-language models (VLMs) for meme classification tasks including sarcasm, offensiveness, and sentiment detection. Three experimental strategies are explored: diverse prompting (zero/few-shot with chain-of-thought), LoRA fine-tuning, and a novel approach combining VLM-generated explanations with LLM fine-tuning. VLMs struggle with nuanced content like sarcasm and offensiveness, but prompting strategies improve performance, especially with three-step CoT. LoRA fine-tuning shows limited gains, while the CoVExFiL approach yields significant improvements—26.24% for sentiment, 8.34% for sarcasm, and 3.52% for offensiveness—by leveraging VLM explanations to fine-tune smaller LLMs. Overall, structured prompting and explanation-based fine-tuning outperform direct VLM adaptation, highlighting their effectiveness for complex meme understanding.

## Method Summary
The study evaluates VLMs across three experimental strategies for meme classification. First, diverse prompting strategies including zero-shot, few-shot, and chain-of-thought (CoT) prompting are tested with and without explanations. Second, LoRA fine-tuning is applied to VLMs to adapt them to meme classification tasks. Third, a novel approach called CoVExFiL (Chain-of-Thought Explanation Fine-tuning) is introduced, which uses VLMs to generate explanations for memes, then fine-tunes smaller LLMs on these explanations. The evaluation covers three tasks: sentiment detection, sarcasm detection, and offensiveness classification. Performance is measured using standard metrics, with particular attention to the effectiveness of each approach across different tasks.

## Key Results
- CoVExFiL approach achieves 26.24% improvement for sentiment, 8.34% for sarcasm, and 3.52% for offensiveness over baseline VLM performance
- Three-step chain-of-thought prompting shows consistent improvements across all tasks compared to direct prompting
- LoRA fine-tuning demonstrates limited effectiveness for meme classification compared to explanation-based fine-tuning
- VLMs show inherent difficulty with nuanced content like sarcasm and offensiveness even with adaptation

## Why This Works (Mechanism)
VLMs struggle with nuanced meme content because they lack specialized training for multimodal humor, sarcasm, and cultural context that memes require. The CoVExFiL approach works by leveraging VLMs' strong visual understanding while compensating for their classification weaknesses through structured explanation generation. When VLMs generate explanations for memes, they decompose complex visual-linguistic relationships into interpretable reasoning chains. These explanations serve as rich training signals for smaller LLMs, which can specialize in classification without the computational overhead of full VLM fine-tuning. The chain-of-thought prompting further enhances this by forcing VLMs to articulate their reasoning process, revealing implicit knowledge that can be captured in the fine-tuning data. This two-stage approach effectively transfers multimodal understanding from large VLMs to more efficient models specialized for the classification task.

## Foundational Learning
- **Vision-Language Models (VLMs)**: Neural architectures that process both visual and textual inputs simultaneously, trained on large-scale multimodal datasets. Why needed: VLMs provide the foundational multimodal understanding required to interpret memes that combine images and text. Quick check: Verify the VLM can correctly describe meme content without classification labels.
- **Chain-of-Thought Prompting**: A prompting technique that guides models through step-by-step reasoning by including intermediate reasoning steps in the prompt. Why needed: CoT helps VLMs break down complex meme interpretation into manageable reasoning steps. Quick check: Compare single-step vs multi-step reasoning performance on simple meme classification.
- **LoRA Fine-tuning**: A parameter-efficient fine-tuning method that adds low-rank adapters to pre-trained models instead of full fine-tuning. Why needed: LoRA enables adaptation of large VLMs without the computational cost of full fine-tuning. Quick check: Measure parameter changes and performance impact of LoRA vs full fine-tuning.
- **Explanation Generation**: The process of generating natural language explanations for model predictions or content understanding. Why needed: Explanations bridge the gap between VLM understanding and classification by making implicit reasoning explicit. Quick check: Evaluate explanation quality using human judges on coherence and relevance.
- **Multimodal Classification**: The task of categorizing content that contains both visual and textual components. Why needed: Memes require understanding both modalities simultaneously for accurate classification. Quick check: Test classification performance on unimodal vs multimodal meme variants.
- **Model Distillation**: The process of transferring knowledge from a large model to a smaller, more efficient model. Why needed: CoVExFiL uses VLMs as teachers to train smaller, specialized LLMs for classification. Quick check: Compare student model performance with and without teacher explanations.

## Architecture Onboarding

**Component Map:** VLM (image + text) -> Explanation Generator -> LLM (text-only) -> Classifier

**Critical Path:** Meme input → VLM processing → Explanation generation → LLM fine-tuning → Classification output

**Design Tradeoffs:** 
- VLM-based fine-tuning requires fewer components but struggles with nuanced tasks
- CoVExFiL adds explanation generation overhead but achieves superior performance
- LoRA offers parameter efficiency but limited task adaptation
- Smaller LLMs reduce computational cost at inference but require quality explanations

**Failure Signatures:**
- Poor explanations lead to degraded LLM performance
- VLM misunderstanding of cultural context propagates through explanations
- Over-reliance on textual modality misses visual humor cues
- Chain-of-thought prompting may introduce spurious reasoning paths

**First Experiments:**
1. Test zero-shot VLM performance on each classification task to establish baseline capability
2. Implement three-step CoT prompting and measure performance gains over direct prompting
3. Generate explanations for a subset of memes and evaluate their quality and relevance to classification

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Results based on single multimodal dataset without comparison to other meme classification benchmarks, limiting generalizability
- Explanation generation introduces dependency on VLM quality which may vary across models and domains
- Study does not address potential biases in VLM-generated explanations that could propagate to fine-tuned LLM
- Computational cost of generating explanations for fine-tuning is not discussed for practical deployment considerations

## Confidence

**Confidence in the claim that structured prompting improves VLM performance:** **High** - Supported by consistent improvements across multiple tasks and strategies.

**Confidence in the claim that CoVExFiL significantly outperforms other approaches:** **Medium** - While statistically supported within this study, the single-dataset limitation reduces external validity.

**Confidence in the claim that VLMs inherently struggle with nuanced content:** **Medium** - The observation is reasonable but would benefit from comparison with human performance baselines and testing across diverse datasets.

## Next Checks

1. Test CoVExFiL approach on at least two additional meme classification datasets with different characteristics to assess generalizability.

2. Compare explanation quality and bias across different VLM models to determine robustness of the CoVExFiL pipeline.

3. Conduct ablation studies removing the explanation generation step to quantify its specific contribution versus fine-tuning the LLM directly on meme features.