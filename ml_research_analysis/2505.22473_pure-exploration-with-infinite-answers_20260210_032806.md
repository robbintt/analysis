---
ver: rpa2
title: Pure Exploration with Infinite Answers
arxiv_id: '2505.22473'
source_url: https://arxiv.org/abs/2505.22473
tags:
- lemma
- such
- then
- exists
- proof
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies pure exploration problems where the set of correct
  answers is infinite, such as regressing continuous functions of bandit means. Existing
  methods like Sticky Track-and-Stop fail in this setting due to fundamental topological
  challenges when multiple correct answers exist.
---

# Pure Exploration with Infinite Answers
## Quick Facts
- arXiv ID: 2505.22473
- Source URL: https://arxiv.org/abs/2505.22473
- Authors: Riccardo Poiani; Martino Bernasconi; Andrea Celli
- Reference count: 40
- The paper introduces Sticky-Sequence Track-and-Stop for pure exploration with infinite correct answers, achieving asymptotic optimality by tracking convergent answer sequences rather than sticking to single answers.

## Executive Summary
This paper addresses pure exploration problems where the set of correct answers is infinite, such as regressing continuous functions of bandit means. Traditional methods like Sticky Track-and-Stop fail in this setting due to topological challenges when multiple correct answers exist. The authors introduce a novel framework called Sticky-Sequence Track-and-Stop that achieves asymptotic optimality by tracking a sequence of answers that converges to some correct answer, rather than attempting to identify a specific correct answer. The key insight is that convergence of the answer sequence, not identification of a particular correct answer, is sufficient for optimality.

## Method Summary
The paper introduces Sticky-Sequence Track-and-Stop, a framework that modifies the traditional Track-and-Stop algorithm to handle infinite answer spaces. Instead of maintaining a single "sticky" answer, the algorithm tracks a sequence of answers that converges to some correct answer in the set. The method works by continuously updating the target answer based on accumulated evidence while maintaining the theoretical guarantees needed for asymptotic optimality. The algorithm operates by partitioning the answer space and tracking which partition contains correct answers, then refining this partition over time to converge to a specific correct answer.

## Key Results
- Proves asymptotic optimality for pure exploration with infinite correct answers by tracking convergent answer sequences
- Shows that convergence of the answer sequence, rather than identification of a specific correct answer, suffices for optimality
- Provides convergence guarantees for various answer space topologies including compact spaces
- Demonstrates how to implement convergent selection rules in practice for continuous-function regression problems

## Why This Works (Mechanism)
The mechanism works by shifting the objective from identifying a specific correct answer to ensuring that the sequence of answers tracked by the algorithm converges to some correct answer. This is achieved through a partition-based approach where the answer space is progressively refined. The algorithm maintains theoretical guarantees by ensuring that the confidence bounds on the bandit means shrink appropriately over time, which in turn ensures that the tracked answer sequence converges to a correct answer. The key innovation is recognizing that for pure exploration with infinite answers, asymptotic optimality can be achieved without ever definitively identifying which specific correct answer is being targeted.

## Foundational Learning
**Topological spaces** - Needed to rigorously define convergence of answer sequences in infinite answer spaces. Quick check: Verify the answer space is Hausdorff and second-countable for standard convergence results.

**Bandit theory fundamentals** - Required for understanding the Track-and-Stop framework and its optimality guarantees. Quick check: Confirm understanding of Chernoff information and its role in optimal allocation.

**Asymptotic analysis** - Essential for proving the asymptotic optimality of the algorithm. Quick check: Verify that the regret grows sublinearly with time.

## Architecture Onboarding
**Component map**: Answer Space Partitioner -> Confidence Bound Calculator -> Answer Sequence Tracker -> Allocation Optimizer

**Critical path**: The algorithm iteratively refines partitions of the answer space, calculates confidence bounds on bandit means, updates the tracked answer sequence, and optimizes arm allocation based on current estimates.

**Design tradeoffs**: The method trades off the complexity of tracking multiple potential answers against the impossibility of sticking to a single answer in infinite answer spaces. This increases computational overhead but enables handling of problems where traditional methods fail.

**Failure signatures**: The algorithm may fail to converge if the answer space has disconnected components of correct answers, or if the topological structure prevents the tracked sequence from converging to any correct answer.

**First experiments**:
1. Implement on a simple 1D function regression problem with multiple correct answers
2. Test convergence behavior on answer spaces with disconnected correct answer components
3. Compare performance against Sticky Track-and-Stop on problems where both methods apply

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the limitations section implicitly suggests several areas for future work, including non-asymptotic bounds, handling of complex topological structures, and empirical validation of the practical implementation.

## Limitations
- Assumes the answer space is compact and that tracked sequences converge to correct answers
- Does not address scenarios with isolated multiple correct answers or complex topological structures
- Provides only asymptotic convergence guarantees without finite-sample bounds
- Lacks empirical validation of practical implementation details

## Confidence
**Theoretical framework and convergence guarantees**: High - The mathematical arguments build on established bandit theory and appear sound.
**Practical implementability**: Medium - The selection rule is described but lacks empirical validation.
**Asymptotic optimality**: High - The proof structure follows standard bandit analysis techniques.

## Next Checks
1. Implement the convergent selection rule on benchmark continuous-function regression problems and compare against baseline methods.
2. Test the algorithm on answer spaces with multiple disconnected correct answers to verify convergence behavior.
3. Conduct empirical analysis of computational complexity as the dimension of the answer space increases.