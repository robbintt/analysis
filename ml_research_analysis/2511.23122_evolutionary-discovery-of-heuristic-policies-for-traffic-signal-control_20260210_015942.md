---
ver: rpa2
title: Evolutionary Discovery of Heuristic Policies for Traffic Signal Control
arxiv_id: '2511.23122'
source_url: https://arxiv.org/abs/2511.23122
tags:
- traffic
- signal
- control
- policy
- tpet
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces TPET, a framework that uses LLMs as an evolution
  engine to discover specialized heuristic policies for traffic signal control. The
  core idea is to leverage LLMs not as online actors but as discoverers of structured,
  lightweight policies through an evolutionary process guided by two key modules:
  Structured State Abstraction (SSA), which converts numerical traffic data into interpretable
  temporal-logical facts, and Credit Assignment Feedback (CAF), which provides actionable
  critiques by tracing micro-decisions to macro-outcomes.'
---

# Evolutionary Discovery of Heuristic Policies for Traffic Signal Control

## Quick Facts
- arXiv ID: 2511.23122
- Source URL: https://arxiv.org/abs/2511.23122
- Authors: Ruibing Wang; Shuhan Guo; Zeen Li; Zhen Wang; Quanming Yao
- Reference count: 24
- Primary result: TPET framework discovers LLM-guided heuristic policies that outperform both classic heuristics and online LLM actors on real-world traffic datasets

## Executive Summary
TPET introduces a novel framework that leverages Large Language Models as evolution engines to discover specialized heuristic policies for traffic signal control. Rather than using LLMs as online actors, TPET employs them to guide an evolutionary search process that generates interpretable, lightweight policies optimized for specific traffic environments. The framework combines Structured State Abstraction (SSA) for converting numerical traffic data into interpretable temporal-logical facts with Credit Assignment Feedback (CAF) for providing actionable critiques that trace micro-decisions to macro-outcomes. Experiments on Jinan and Hangzhou datasets demonstrate state-of-the-art performance in terms of travel time, queue length, and wait time metrics.

## Method Summary
The TPET framework uses LLMs as an evolution engine to discover specialized heuristic policies for traffic signal control through a structured evolutionary process. The core innovation lies in using LLMs not as online decision-makers but as policy discoverers, guided by two key modules: Structured State Abstraction (SSA) and Credit Assignment Feedback (CAF). SSA transforms raw numerical traffic data into interpretable temporal-logical facts, while CAF provides actionable critiques by tracing micro-decisions to macro-outcomes. The discovered policies are optimized for specific traffic environments and run with millisecond latency. The evolutionary process iteratively generates and evaluates candidate policies, with LLM critiques informing selection and mutation steps to converge on high-performing solutions.

## Key Results
- Achieves state-of-the-art performance on real-world datasets (Jinan, Hangzhou), outperforming classic heuristics like MaxPressure
- Superior performance across key metrics: Average Travel Time, Average Queue Length, and Average Wait Time
- Demonstrates exceptional stability and robustness compared to online LLM actor approaches
- Discovered policies execute with millisecond latency, making them suitable for real-time deployment

## Why This Works (Mechanism)
The framework succeeds by reframing LLMs as discovery engines rather than online actors. By leveraging LLMs' reasoning capabilities in an offline evolutionary search, TPET can explore the policy space more effectively than traditional optimization methods. The Structured State Abstraction module converts complex numerical traffic data into interpretable temporal-logical facts that LLMs can reason about more effectively. The Credit Assignment Feedback module provides actionable critiques that connect individual traffic signal decisions to overall system performance, enabling more targeted policy improvements during the evolutionary process.

## Foundational Learning

**Structured State Abstraction (SSA)**: Converts numerical traffic data into interpretable temporal-logical facts
- Why needed: LLMs struggle with raw numerical optimization; structured facts enable better reasoning
- Quick check: Verify SSA preserves critical traffic patterns while creating interpretable representations

**Credit Assignment Feedback (CAF)**: Traces micro-decisions to macro-outcomes for actionable critiques
- Why needed: Links individual signal timing decisions to overall system performance metrics
- Quick check: Confirm CAF can identify causal relationships between decisions and outcomes

**Evolutionary Policy Discovery**: Iterative generation and evaluation of candidate policies
- Why needed: Explores policy space more effectively than gradient-based methods for discrete decision rules
- Quick check: Measure diversity and convergence of evolved policy populations

## Architecture Onboarding

**Component map**: SSA -> Evolutionary Search -> CAF -> Policy Selection -> Deployment
**Critical path**: Raw traffic data → SSA → Evolutionary search generation → CAF critique → Policy refinement → Evaluation → Deployment
**Design tradeoffs**: Offline discovery vs. online learning, interpretability vs. performance, generality vs. specialization
**Failure signatures**: 
- Poor performance on unseen traffic patterns
- Policy degradation over time as traffic patterns evolve
- Computational bottlenecks in evolutionary search for large networks
**First experiments to run**:
1. Ablation study removing SSA to quantify its contribution to performance
2. Comparison with pure LLM-based online actors on identical datasets
3. Stress test with extreme traffic conditions not present in training data

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several critical areas require investigation:
- Generalizability of discovered policies beyond tested datasets and traffic patterns
- Potential bias introduced by LLM training data and reasoning capabilities
- Performance in dramatically different traffic contexts or geographic regions
- Computational overhead and scalability to larger networks

## Limitations
- Performance claims primarily validated on two real-world datasets (Jinan, Hangzhou), limiting generalizability
- Potential bias from LLM's training data affecting policy discovery process
- Limited characterization of computational overhead for evolutionary search process
- Unclear performance in dramatically different traffic contexts or geographic regions

## Confidence

**High confidence**: Technical novelty of combining LLMs with evolutionary search for policy discovery in traffic signal control
**Medium confidence**: Performance improvements pending independent replication on diverse datasets
**Medium confidence**: Stability and robustness claims dependent on specific test environments
**Low confidence**: Scalability assessments due to limited discussion of computational requirements

## Next Checks

1. Independent replication of the framework on at least three additional traffic datasets from different cities with varying traffic patterns, intersection configurations, and cultural driving behaviors
2. Ablation studies to quantify the contribution of each component (SSA, CAF, evolutionary search) to overall performance, including comparisons with alternative state abstraction and credit assignment methods
3. Long-term deployment simulation studies to assess policy degradation, adaptation requirements, and maintenance overhead over extended periods with changing traffic patterns