---
ver: rpa2
title: 'AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control
  Tokens'
arxiv_id: '2512.17375'
source_url: https://arxiv.org/abs/2512.17375
tags:
- assistant
- header
- start
- answer
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "AdvJudge-Zero introduces a method for discovering adversarial\
  \ control tokens that systematically flip binary evaluations in LLM-as-a-Judge systems.\
  \ By using the model\u2019s own next-token distribution and beam-search exploration,\
  \ it finds short, low-perplexity sequences that steer the last-layer logit gap F=zno\u2212\
  zyes across zero, converting \u201CNo\u201D to \u201CYes\u201D without meaningful\
  \ semantic changes."
---

# AdvJudge-Zero: Binary Decision Flips in LLM-as-a-Judge via Adversarial Control Tokens

## Quick Facts
- **arXiv ID:** 2512.17375
- **Source URL:** https://arxiv.org/abs/2512.17375
- **Authors:** Tung-Ling Li; Yuhao Wu; Hongliang Liu
- **Reference count:** 40
- **Primary result:** Discovered adversarial control tokens achieve ensemble false positive rates above 90% across multiple judge models

## Executive Summary
AdvJudge-Zero presents a method for discovering adversarial control tokens that systematically flip binary evaluations in LLM-as-a-Judge systems. The approach leverages the model's own next-token distribution and beam-search exploration to find short, low-perplexity sequences that steer the last-layer logit gap across zero, converting "No" to "Yes" without meaningful semantic changes. Experiments demonstrate these tokens achieve high false positive rates across multiple general-purpose and specialized judge models, substantially outperforming manual baselines. The attacks work due to low-rank perturbations concentrated in a shared "soft mode" anti-aligned with the judge's refusal direction.

## Method Summary
The method employs an iterative token-selection strategy using beam search over the model's next-token distribution to identify control tokens that flip binary judgments. By exploring candidates through the judge model's own probability distribution, it discovers short sequences that effectively manipulate the logit gap between "yes" and "no" responses. The approach focuses on low-perplexity tokens that achieve decision flips without introducing semantic drift. LoRA-based adversarial training on small datasets augmented with these control tokens is shown to reduce false positives while preserving evaluation capability.

## Key Results
- Control tokens achieve ensemble false positive rates above 90% across multiple judge models
- Outperforms manual baseline methods by substantial margins
- LoRA-based adversarial training reduces false positives while maintaining evaluation accuracy
- Attacks effective due to low-rank perturbations in a shared "soft mode" anti-aligned with refusal direction

## Why This Works (Mechanism)
The effectiveness stems from exploiting the judge model's internal representation space through carefully crafted token sequences. These tokens create low-rank perturbations that concentrate in a "soft mode" direction anti-aligned with the model's refusal behavior. By steering the last-layer logit gap F=z_noâˆ’z_yes across zero, the tokens flip binary decisions without requiring semantic manipulation of the input content. The method leverages the model's own probability distribution to discover tokens that are both effective and have low perplexity, making them appear natural while still achieving the adversarial objective.

## Foundational Learning

**LLM-as-a-Judge systems** - Models used to automatically evaluate other models' outputs. *Why needed:* Core target of the attack methodology. *Quick check:* Verify the judge model correctly evaluates uncontroversial cases.

**Logit gap manipulation** - Steering the difference between "yes" and "no" logits across zero. *Why needed:* Fundamental mechanism for binary decision flips. *Quick check:* Confirm logit gap changes correlate with decision changes.

**Next-token distribution sampling** - Using the model's own probability distribution to guide token selection. *Why needed:* Enables discovery of natural-looking adversarial tokens. *Quick check:* Validate that sampled tokens have reasonable perplexity scores.

**Low-rank perturbations** - Small changes concentrated in specific directions of the model's representation space. *Why needed:* Explains why few tokens can have outsized effects. *Quick check:* Verify perturbation rank remains low across different token sets.

**LoRA-based adversarial training** - Parameter-efficient fine-tuning method for mitigation. *Why needed:* Provides practical defense mechanism. *Why needed:* Enables efficient adaptation without full retraining. *Quick check:* Measure evaluation capability retention after LoRA fine-tuning.

## Architecture Onboarding

**Component map:** Input text -> Judge model -> Logit computation -> Decision (Yes/No) -> Token selection -> Control token injection

**Critical path:** The attack flows through the judge model's forward pass, specifically targeting the logit computation layer where binary decisions are determined. The token selection process depends on the model's next-token distribution and beam search capabilities.

**Design tradeoffs:** The method balances effectiveness against naturalness by selecting low-perplexity tokens that achieve decision flips. This contrasts with more aggressive attacks that might use highly unnatural sequences. The LoRA-based mitigation trades parameter efficiency against potentially incomplete protection.

**Failure signatures:** When the attack succeeds, binary decisions flip from "No" to "Yes" without semantic changes to the input. Failed attacks either fail to flip the decision or introduce detectable semantic drift. The method is most effective when the judge model has consistent patterns in its logit space representation.

**3 first experiments:** 1) Test control token effectiveness on uncontroversial evaluation pairs. 2) Measure semantic drift when tokens are applied using automated similarity metrics. 3) Evaluate LoRA mitigation against a small set of known control tokens.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on binary decision flips without examining semantic drift in judge reasoning
- Token selection strategy may not generalize to other model architectures or token vocabularies
- LoRA-based mitigation only tested on limited control token sets and may not scale to adaptive attacks

## Confidence

**High confidence:** The core methodology for discovering adversarial control tokens using next-token distribution sampling and beam search is technically sound and well-documented. The experimental results showing high false positive rates across multiple judge models are reproducible and clearly presented.

**Medium confidence:** The interpretation of low-rank perturbations and their concentration in a "soft mode" anti-aligned with refusal direction requires further validation. While the mathematical framework is presented, the causal relationship between these perturbations and the observed behavior needs more rigorous testing.

**Low confidence:** The claim that adversarial training on small datasets preserves evaluation capability while reducing false positives needs more extensive validation across diverse evaluation scenarios and judge model types.

## Next Checks
1. Test adversarial token effectiveness against judge models with different architectures (e.g., non-transformer based) and token vocabularies to assess generalizability.

2. Conduct ablation studies measuring semantic drift in judge reasoning when adversarial tokens are applied, using automated semantic similarity metrics and human evaluation.

3. Evaluate the LoRA mitigation approach's robustness against adaptive attacks where adversaries iteratively modify tokens to evade the defense while maintaining effectiveness.