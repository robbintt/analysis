---
ver: rpa2
title: Learning Mixtures of Linear Dynamical Systems (MoLDS) via Hybrid Tensor-EM
  Method
arxiv_id: '2510.06091'
source_url: https://arxiv.org/abs/2510.06091
tags:
- molds
- tensor
- parameters
- mixture
- component
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a hybrid Tensor-EM method for learning Mixtures
  of Linear Dynamical Systems (MoLDS) that combines global tensor-based initialization
  with local EM refinement. The method addresses the challenge of identifying multiple
  distinct LDS components from heterogeneous time-series data, particularly in neural
  recordings where different conditions exhibit varying dynamics.
---

# Learning Mixtures of Linear Dynamical Systems (MoLDS) via Hybrid Tensor-EM Method

## Quick Facts
- arXiv ID: 2510.06091
- Source URL: https://arxiv.org/abs/2510.06091
- Authors: Lulu Gong; Shreya Saxena
- Reference count: 40
- Proposes hybrid Tensor-EM method for learning MoLDS that combines global tensor-based initialization with local EM refinement

## Executive Summary
This paper introduces a hybrid Tensor-EM method for learning Mixtures of Linear Dynamical Systems (MoLDS) from heterogeneous time-series data. The approach addresses the challenge of identifying multiple distinct LDS components in neural recordings where different conditions exhibit varying dynamics. By combining global tensor-based initialization using Simultaneous Matrix Diagonalization (SMD) with local EM refinement via Kalman Filter-Smoother, the method achieves more reliable parameter recovery than either approach alone. The technique is demonstrated on both synthetic data and real neural recordings from primate somatosensory and premotor cortex, successfully identifying distinct dynamical clusters corresponding to different movement directions in an unsupervised manner.

## Method Summary
The hybrid Tensor-EM method combines global initialization through Simultaneous Matrix Diagonalization with local refinement via Expectation-Maximization. The global stage uses tensor decompositions to obtain consistent initial estimates of mixture weights and system parameters across all conditions. This initialization is then refined using the EM algorithm with Kalman Filter-Smoother for state estimation, allowing recovery of noise parameters and improved parameter estimates. The method leverages the computational efficiency of tensor methods for global structure discovery while maintaining the local optimization strength of EM, addressing the limitations of both pure tensor methods (which struggle with noise and small datasets) and randomly initialized EM (which can get trapped in local optima).

## Key Results
- Tensor-EM achieves more reliable recovery and improved robustness compared to pure tensor methods or randomly initialized EM on synthetic data
- Successfully identifies distinct dynamical clusters corresponding to different movement directions in primate neural recordings
- Matches the performance of supervised LDS fits while operating in a fully unsupervised manner

## Why This Works (Mechanism)
The method works by combining the global optimization strength of tensor methods with the local refinement capabilities of EM. The tensor-based initialization provides globally consistent estimates that avoid poor local optima, while the subsequent EM refinement allows for accurate recovery of noise parameters and fine-tuning of system dynamics. This hybrid approach leverages the computational efficiency of tensor methods for large-scale structure discovery while maintaining the statistical efficiency of EM for parameter estimation under noise.

## Foundational Learning
- **Linear Dynamical Systems**: State-space models where observations are generated from latent linear dynamics with Gaussian noise. Needed to understand the basic building block of MoLDS.
- **Expectation-Maximization Algorithm**: Iterative optimization method for maximum likelihood estimation with latent variables. Critical for refining parameter estimates in MoLDS.
- **Tensor Decompositions**: Mathematical operations that generalize matrix factorizations to higher dimensions. Enables global initialization by uncovering latent structure across multiple conditions.
- **Simultaneous Matrix Diagonalization**: Technique for jointly diagonalizing multiple matrices to extract common subspaces. Provides globally consistent parameter estimates across conditions.
- **Kalman Filtering/Smoother**: Recursive state estimation algorithms for linear Gaussian state-space models. Essential for the E-step in EM refinement.

## Architecture Onboarding

Component Map: Tensor Decomposition -> SMD Initialization -> Kalman Filter-Smoother EM -> Parameter Refinement

Critical Path: The method follows a sequential pipeline where tensor decomposition provides initial parameter estimates, followed by SMD for global consistency, then EM refinement with Kalman smoothing for final parameter recovery.

Design Tradeoffs: The hybrid approach trades computational complexity for robustness - tensor methods provide global structure but are sensitive to noise, while EM provides local refinement but needs good initialization. The combination balances these competing needs.

Failure Signatures: Poor initialization from tensor decomposition can propagate through the entire pipeline, leading to convergence to suboptimal local optima. Highly overlapping dynamical components may be difficult to separate even with good initialization.

Three First Experiments:
1. Validate tensor decomposition quality on synthetic data with known parameters
2. Test SMD initialization consistency across multiple conditions
3. Evaluate Kalman smoother accuracy for state estimation in high-noise regimes

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Assumes linear dynamics within each component, which may not capture complex nonlinear neural phenomena
- Performance heavily depends on quality of initial SMD decomposition, which may struggle with highly overlapping or similar dynamical components
- Applicability to high-dimensional neural recordings with thousands of neurons remains untested

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Recovery of ground-truth parameters from synthetic data | High |
| Biological interpretability of identified clusters | Medium |
| Method's ability to handle large-scale neural recordings | Low |

## Next Checks
1. Systematic evaluation of Tensor-EM performance across varying signal-to-noise ratios and component overlap in synthetic data to establish robustness bounds
2. Comparison of identified dynamical clusters with independent neural activity measures or pharmacological manipulations to validate biological relevance
3. Application to multi-region neural recordings to assess the method's ability to capture coordinated dynamics across brain areas