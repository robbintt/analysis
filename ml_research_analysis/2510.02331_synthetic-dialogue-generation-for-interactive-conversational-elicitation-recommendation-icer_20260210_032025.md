---
ver: rpa2
title: Synthetic Dialogue Generation for Interactive Conversational Elicitation &
  Recommendation (ICER)
arxiv_id: '2510.02331'
source_url: https://arxiv.org/abs/2510.02331
tags:
- user
- agent
- like
- more
- movies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents ICER (Interactive Conversational Elicitation
  & Recommendation), a methodology for generating synthetic dialogue data for conversational
  recommender systems. ICER combines a user behavior simulator with LM-prompting to
  create natural, preference-consistent dialogues.
---

# Synthetic Dialogue Generation for Interactive Conversational Elicitation & Recommendation (ICER)

## Quick Facts
- arXiv ID: 2510.02331
- Source URL: https://arxiv.org/abs/2510.02331
- Reference count: 40
- ICER generates synthetic dialogue data for conversational recommender systems with high fluency (99.4%), naturalness (99.1%), and consistency (97.8%)

## Executive Summary
ICER (Interactive Conversational Elicitation & Recommendation) is a novel methodology for generating synthetic dialogue data to train conversational recommender systems. The approach combines a user behavior simulator with large language model prompting to create natural, preference-consistent dialogues. Evaluated on the MD-DICER dataset of 100K movie recommendation dialogues, ICER outperforms templatized alternatives in human evaluations and achieves strong performance in automated preference elicitation tasks.

## Method Summary
ICER generates synthetic dialogue data by combining a user behavior simulator with large language model prompting. The user simulator generates preference-consistent responses based on underlying preference profiles, while the LM generates system responses. This approach creates natural dialogues that maintain preference consistency throughout the conversation. The methodology was evaluated using MD-DICER, a dataset of 100K movie recommendation dialogues, where ICER-generated dialogues were compared against templatized alternatives and used to prompt language models for preference elicitation tasks.

## Key Results
- Human raters found ICER-generated dialogues highly fluent (99.4%), natural (99.1%), and consistent (97.8%)
- LM prompts using ICER dialogues achieved 61.3% accuracy and 0.793 NDCG in recommending items aligned with user preferences
- ICER outperformed baselines using text profiles alone or unconstrained dialogue generation

## Why This Works (Mechanism)
ICER works by explicitly modeling user preferences and behavior patterns during dialogue generation. The user behavior simulator ensures that responses remain consistent with underlying preferences throughout the conversation, while the LM generates natural, contextually appropriate system responses. This combination creates synthetic dialogues that are both preference-consistent and natural-sounding, addressing the key challenge of generating high-quality training data for conversational recommenders without requiring extensive human annotation.

## Foundational Learning

**User Behavior Simulation**: Modeling how users express preferences and respond to recommendations in conversation. Needed because realistic user behavior is essential for generating training data that captures real-world interaction patterns. Quick check: Does the simulator capture diverse preference expression styles?

**Preference Consistency Tracking**: Maintaining awareness of expressed preferences throughout dialogue turns. Needed because inconsistent preference expression breaks the training value of synthetic data. Quick check: Are preference changes justified and tracked across conversation turns?

**Language Model Prompting**: Using generated dialogues to prompt LMs for downstream tasks. Needed because the quality of synthetic dialogues directly impacts the performance of LMs trained on them. Quick check: Does prompting with ICER dialogues improve recommendation accuracy versus other data sources?

## Architecture Onboarding

**Component Map**: User Simulator -> LM Prompt Generator -> Preference Tracker -> Dialogue Output

**Critical Path**: The user behavior simulator generates preference-consistent responses, which are combined with LM-generated system responses. The preference tracker ensures consistency across turns, and the final output is a complete dialogue suitable for training conversational recommenders.

**Design Tradeoffs**: ICER prioritizes preference consistency over unconstrained natural generation, accepting slightly less diverse responses to ensure training value. The approach trades off some naturalness for the critical requirement that dialogues must maintain consistent preference expression.

**Failure Signatures**: Generated dialogues may become repetitive if the user simulator over-constrains responses, or may drift from preferences if the consistency tracking fails. Poor performance on preference elicitation tasks indicates issues with either the synthetic data quality or the prompting strategy.

**3 First Experiments**:
1. Generate 100 dialogues with varying preference complexity levels to test consistency tracking
2. Compare human ratings of ICER dialogues against baselines for fluency and naturalness
3. Evaluate LM performance on preference elicitation using ICER dialogues versus text profiles

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused on movie domain, generalizability to other domains unverified
- Human ratings may not fully capture real-world conversational dynamics
- Automated evaluation metrics depend on specific setup and may not generalize

## Confidence

**High Confidence**:
- Fluency and naturalness of ICER-generated dialogues (supported by human evaluations)

**Medium Confidence**:
- ICER outperforms baselines in preference elicitation (dependent on evaluation setup)

**Low Confidence**:
- Generalizability beyond movie domain (not empirically validated)

## Next Checks

1. Test ICER on multiple domains (e.g., music, restaurants) to assess generalizability and performance consistency
2. Conduct bias analysis on the synthetic dialogues to identify and mitigate potential over-representation of certain preferences or styles
3. Evaluate the long-term effectiveness of ICER-generated data in training real-world conversational recommender systems through deployment studies