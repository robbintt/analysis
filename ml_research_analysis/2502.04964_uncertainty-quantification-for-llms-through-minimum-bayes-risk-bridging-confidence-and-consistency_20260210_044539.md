---
ver: rpa2
title: 'Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence
  and Consistency'
arxiv_id: '2502.04964'
source_url: https://arxiv.org/abs/2502.04964
tags:
- uncertainty
- semantic
- methods
- cocoam
- consistency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new family of uncertainty quantification
  methods for large language models (LLMs) called CoCoA, which integrates model confidence
  with output consistency. The core idea is to treat uncertainty as a minimum Bayes
  risk problem, combining token-level confidence scores with semantic similarity between
  multiple sampled outputs.
---

# Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency

## Quick Facts
- **arXiv ID**: 2502.04964
- **Source URL**: https://arxiv.org/abs/2502.04964
- **Reference count**: 40
- **One-line primary result**: A new family of UQ methods called CoCoA integrates model confidence with output consistency, showing sizable PRR improvements over state-of-the-art methods.

## Executive Summary
This paper proposes a novel approach to uncertainty quantification (UQ) for large language models (LLMs) that bridges the gap between model confidence and output consistency. The core innovation is the CoCoA framework, which treats uncertainty as a minimum Bayes risk problem by multiplicatively combining sequence-level confidence scores with semantic similarity between multiple sampled outputs. This integration addresses limitations of existing UQ methods that rely solely on token probabilities or output consistency. The paper introduces CoCoA Light, a lightweight variant that approximates consistency using a learned function, eliminating the need for repeated sampling and dramatically reducing inference cost. Experiments across question answering, summarization, and machine translation tasks demonstrate consistent improvements in prediction rejection ratio (PRR) over state-of-the-art uncertainty quantification methods.

## Method Summary
The CoCoA framework computes uncertainty as the product of a base confidence score and a consistency term: \(U_{CoCoA}(y^*|x) = u(y^*|x) \cdot \hat{U}_{cons}(y^*|x)\). The base confidence \(u(y^*|x)\) can be negative log-probability, perplexity, or mean token entropy, while \(\hat{U}_{cons}\) measures the average dissimilarity of the greedy output to M sampled outputs using a semantic similarity function (typically a RoBERTa cross-encoder). CoCoA Light approximates the consistency term with a lightweight MLP trained on LLM embeddings from held-out data, reducing inference from O(M) LLM generations to a single forward pass. The framework is theoretically grounded in Minimum Bayes Risk decoding, providing a principled unification of information-based and consistency-based UQ approaches.

## Key Results
- CoCoA variants consistently achieve the highest PRR scores across all three task types (QA, summarization, NMT) and multiple model sizes
- CoCoA Light variants match the performance of full CoCoA while reducing inference cost by eliminating repeated sampling
- The multiplicative combination of confidence and consistency outperforms both additive formulations and individual components
- Ablation studies confirm the importance of both confidence and consistency terms, with the multiplicative form showing consistent superiority

## Why This Works (Mechanism)

### Mechanism 1: Multiplicative Integration of Confidence and Consistency
- Claim: A multiplicative combination of sequence-level confidence and sample-focused semantic consistency yields more reliable uncertainty estimates than either component alone or additive combinations.
- Evidence: Ablation experiments in Appendix C.2 show multiplicative CoCoA consistently outperforms AdditiveCoCoA and FullSampleCoCoA across all tasks.

### Mechanism 2: Minimum Bayes Risk (MBR) Theoretic Grounding
- Claim: Formulating UQ through MBR provides a principled framework that unifies and improves upon existing methods.
- Evidence: Section 2.2 shows how MBR-based uncertainty is applicable even with single sequences, and how existing methods can be seen as particular forms under a generalized framework.

### Mechanism 3: Efficient Approximation via CoCoA Light
- Claim: The sampling-based consistency term can be accurately approximated by a lightweight neural network trained on unlabeled data.
- Evidence: Section 5.2, Table 1 shows CoCoA Light variants achieve PRR scores very close to their full-sampling counterparts while dramatically reducing inference cost.

## Foundational Learning

- **Minimum Bayes Risk (MBR) Decoding**: Understanding that MBR seeks the output with the lowest expected loss against all possible outputs is key to grasping why \(U_{CoCoA}\) is formulated as a risk. Quick check: In the MBR formula \(y^* = \arg\min_{y \in \mathcal{Y}} R(y|x)\), what does the risk function \(R(y|x)\) represent?
- **Semantic Textual Similarity**: The consistency component relies on computing similarity scores between text sequences. Quick check: What are two different approaches mentioned in the paper for computing semantic similarity between two generated sequences?
- **Uncertainty Quantification (UQ) in NLP**: The paper addresses estimating when LLM outputs are unreliable. Quick check: Name one information-based UQ method and one consistency-based UQ method used as baselines in the paper.

## Architecture Onboarding

- **Component map**: Base LLM -> Sampler (optional) -> Confidence Calculator -> Similarity Function -> Consistency Aggregator -> CoCoA Combiner -> (Optional) Auxiliary MLP
- **Critical path**:
  1. Prompt \(x\) is fed to the Base LLM
  2. Confidence Calculator computes \(u(y^*|x)\) for greedy output \(y^*\)
  3. *If full CoCoA*: Sampler produces M samples, Similarity Function scores each against \(y^*\), Consistency Aggregator computes \(\hat{U}_{cons}\)
  4. *If CoCoA Light*: Auxiliary MLP takes embedding of \(y^*\) and outputs \(\hat{U}^L_{cons}\)
  5. CoCoA Combiner produces final uncertainty score \(\hat{U}_{CoCoA}\)

- **Design tradeoffs**:
  - Accuracy vs. Cost: Full CoCoA requires O(M) LLM generations; CoCoA Light reduces to single forward pass
  - Similarity Function Choice: Cross-encoders are more accurate but slower than bi-encoders
  - Base Uncertainty Choice: SP, PPL, and MTE show different performance characteristics

- **Failure signatures**:
  - High uncertainty for consistently correct answers: Poorly calibrated base LLM or too strict similarity function
  - Low uncertainty for inconsistent incorrect answers: Too lenient similarity function or insufficient sampling diversity
  - CoCoA Light underperforms significantly: Unrepresentative training data or poor embedding layer choice

- **First 3 experiments**:
  1. Implement and run CoCoA_PPL and CoCoA_PPL_Light on a small QA dataset, comparing PRR and latency against baselines
  2. Ablate similarity function by swapping cross-encoder for NLI-based or lexical overlap similarity
  3. Test trained CoCoA Light MLP on a different domain (e.g., QA to summarization) without retraining

## Open Questions the Paper Calls Out
- How can semantic similarity functions be adapted for non-text domains like code generation or commonsense reasoning?
- Can the framework be modified to handle open-ended tasks where output diversity is a feature rather than noise?
- Do adaptive sampling strategies improve efficiency compared to uniform Monte Carlo sampling?

## Limitations
- The theoretical link between the chosen pairwise loss form and true task-specific utility remains heuristic rather than rigorously derived
- CoCoA Light's transferability limits are untested on out-of-distribution tasks or different LLM architectures
- Performance sensitivity to similarity function choice requires task-dependent empirical testing

## Confidence
- **High Confidence**: CoCoA outperforms all baselines on PRR; multiplicative combination is superior; CoCoA Light matches full CoCoA performance
- **Medium Confidence**: MBR grounding meaningfully unifies UQ approaches; the specific formulation is optimal; learned consistency approximation is robust
- **Low Confidence**: Which mechanism component drives specific improvements; generalization to extremely long-form generation; multilingual performance

## Next Checks
1. Systematically evaluate CoCoA with different similarity functions (cross-encoder, NLI, ROUGE, embedding-based) across all task types, measuring both PRR performance and computational overhead
2. Train CoCoA Light MLPs on one task domain (e.g., QA) and evaluate on completely different domains (e.g., NMT, summarization) without domain-specific fine-tuning
3. Conduct proper calibration analysis by computing Expected Calibration Error (ECE) and reliability diagrams for CoCoA vs. baselines to validate whether higher PRR corresponds to better uncertainty calibration