---
ver: rpa2
title: Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet
  with the CGRA4ML Framework
arxiv_id: '2510.22243'
source_url: https://arxiv.org/abs/2510.22243
tags:
- cgra4ml
- lmiinet
- accuracy
- segmentation
- fpga
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a quantized LMIINet semantic segmentation model
  implemented on FPGA for autonomous driving. By leveraging the CGRA4ML framework
  and quantization-aware training, the network achieves 90% pixel accuracy and 45%
  mIoU on Cityscapes with 50.1 ms latency at 20 FPS on ZCU104.
---

# Real-Time Semantic Segmentation on FPGA for Autonomous Vehicles Using LMIINet with the CGRA4ML Framework

## Quick Facts
- arXiv ID: 2510.22243
- Source URL: https://arxiv.org/abs/2510.22243
- Reference count: 11
- 45% mIoU, 90% pixel accuracy on Cityscapes at 20 FPS on ZCU104

## Executive Summary
This work presents a quantized LMIINet semantic segmentation model implemented on FPGA for autonomous driving. By leveraging the CGRA4ML framework and quantization-aware training, the network achieves 90% pixel accuracy and 45% mIoU on Cityscapes with 50.1 ms latency at 20 FPS on ZCU104. The approach balances accuracy and efficiency through hardware-aware modifications including depthwise convolutions, simplified skip connections, and memory-efficient attention modules. Results demonstrate FPGA's advantages over GPUs in power efficiency while maintaining competitive accuracy for real-time edge deployment. The implementation serves as a foundation for future optimization and ASIC migration paths.

## Method Summary
The method employs a modified LMIINet architecture with quantization-aware training (QAT) using 8-bit precision weights and activations. The network uses depthwise separable convolutions and simplified attention modules to reduce computational complexity. The CGRA4ML framework maps the network onto a 16×96 PE array at 200 MHz on ZCU104 FPGA, with streaming data flow between layers to handle intermediate feature maps. Training follows a four-phase schedule with specific decoder freezing/unfreezing and auxiliary loss configurations to optimize the quantized model for the hardware constraints.

## Key Results
- 45% mIoU and 90% pixel accuracy on Cityscapes validation set
- 50.1 ms latency enabling 20 FPS real-time performance
- High LUT (90%) and FF (43%) utilization on ZCU104 FPGA
- Order-of-magnitude power efficiency improvement over GPU alternatives

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Quantization-Aware Training (QAT) with 8-bit precision enables efficient FPGA deployment while maintaining accuracy comparable to floating-point baselines.
- **Mechanism:** By simulating quantization effects (noise/clamping) during the forward pass of training, the model learns weights that are robust to the reduced dynamic range of INT8 fixed-point arithmetic. This reduces the memory footprint by 4× and allows the use of efficient DSP slices for fixed-point MAC operations rather than resource-heavy floating-point units.
- **Core assumption:** The 8-bit precision is sufficient to represent the feature space of the segmentation task without catastrophic information loss.
- **Evidence anchors:**
  - [abstract] "reducing memory footprint by a factor of four while enabling efficient fixed-point computations."
  - [section III.C] "quantized LMIINet was trained... using Quantization-Aware Training (QAT) with 8-bit activations and weights... effectively preserved accuracy."
  - [corpus] Weak direct link; neighboring papers focus on general acceleration.
- **Break condition:** If validation loss diverges significantly from the floating-point baseline during QAT, or if layer outputs saturate (all zeros/max values) upon hardware deployment, the bit-width or dynamic range assumptions are invalid.

### Mechanism 2
- **Claim:** Architectural substitution of complex attention mechanisms with hardware-friendly approximations preserves global context modeling while fitting spatial acceleration constraints.
- **Mechanism:** The standard Transformer attention is replaced by a simplified Flattened Local Attention Module (FLAM) using dilated convolutions. This converts the memory-bound matrix multiplication of attention into streaming convolutional operations that can be spatially mapped and pipelined on the FPGA fabric.
- **Core assumption:** The dilated convolution approximation captures sufficient global context to replace the full attention mechanism for this specific segmentation task.
- **Evidence anchors:**
  - [section III.A.3] "Replaced complex multi-head attention with simplified Flattened Local Attention Module (FLAM) using dilated convolutions."
  - [abstract] "hardware-aware modifications including... memory-efficient attention modules."
  - [corpus] Weak link; "Real-Time Semantic Segmentation of Aerial Images" uses U-Net, differing architecture.
- **Break condition:** If qualitative results show loss of scene-wide consistency (e.g., mixing road/sidewalk labels in large uniform areas), the attention approximation is too weak.

### Mechanism 3
- **Claim:** Off-chip memory utilization for skip connections via CGRA4ML enables deeper network support than purely on-chip HLS approaches.
- **Mechanism:** Unlike HLS4ML (cited in text as requiring all weights on-chip), CGRA4ML streams layer data and explicitly manages off-chip memory for intermediate feature maps (skip connections). This overcomes the BRAM capacity limits of the ZCU104, allowing the implementation of a deeper LMIINet encoder-decoder structure at the cost of memory bandwidth latency.
- **Core assumption:** The latency of accessing off-chip memory for skip connections can be hidden by the coarse-grained reconfigurable array's dataflow or fits within the 50ms real-time budget.
- **Evidence anchors:**
  - [section II.B] "CGRA4ML employs a coarse-grained reconfigurable array that allows layers to stream data off-chip... enabling support for larger and more complex networks."
  - [section I.A] "Streaming between layers eliminates intermediate host-device transfers."
  - [corpus] Implicitly supported by "FPGA-Enabled Machine Learning Applications..." noting FPGA utility for large data.
- **Break condition:** If latency spikes unpredictably due to memory contention or AXI bus saturation, the streaming dataflow assumption fails.

## Foundational Learning

- **Concept: Quantization-Aware Training (QAT)**
  - **Why needed here:** Standard FP32 models often fail when naively quantized to INT8. QAT is the specific technique used to adapt LMIINet to the FPGA's fixed-point arithmetic.
  - **Quick check question:** Can you explain the difference between "fake quantization" nodes in QAT and post-training quantization?

- **Concept: Depthwise Separable Convolutions**
  - **Why needed here:** This is a core operation in LMIINet's LFIB module, selected to reduce parameters and computational complexity for the edge device.
  - **Quick check question:** How does a depthwise separable convolution differ from a standard convolution in terms of MAC count and channel mixing?

- **Concept: Coarse-Grained Reconfigurable Array (CGRA)**
  - **Why needed here:** This is the underlying architectural paradigm of the CGRA4ML framework used to map the network, distinct from standard single-thread HLS or GPU SIMT execution.
  - **Quick check question:** How does a CGRA's spatial dataflow differ from the temporal instruction execution of a standard CPU?

## Architecture Onboarding

- **Component map:** Cityscapes Image (2048×1024) -> Preprocessor (Crop/Flip) -> LMIINet (Encoder: Depthwise/Asymmetric Conv -> LFIB -> Simplified FLAM -> Decoder) -> CGRA4ML Framework (Python API) -> RTL Generator (SystemVerilog) -> Simulation (Verilator) -> Synthesis (Vivado) -> ZCU104 Bitstream.

- **Critical path:** The mapping of the modified LMIINet layer definitions into the CGRA4ML configuration. This involves ensuring all layer dimensions (channels, kernel sizes) match the supported CGRA operations (e.g., converting complex upsampling to nearest-neighbor).

- **Design tradeoffs:**
  - **Resource vs. Accuracy:** The design uses high LUT/FF utilization (~90%/43%) to maintain 45% mIoU. This is contrasted with ENetHQ (low resource, low accuracy) in the paper.
  - **Latency vs. Complexity:** Simplifying the Transformer attention to dilated convs reduces computational complexity, ensuring the 50ms latency target is met, potentially at the cost of global context accuracy.

- **Failure signatures:**
  - **Simulation instability:** "Simulation instability" mentioned in Future Work regarding clock speed; check timing slack.
  - **Accuracy drop:** If mIoU drops far below 45%, check if the "skip connection" offloading to DRAM is causing data corruption or bandwidth starvation.
  - **Resource overflow:** If synthesis fails, the filter counts [24, 48, 96, 128] may need further reduction.

- **First 3 experiments:**
  1. **Reproduce Verilator Simulation:** Run the provided SystemVerilog through Verilator to verify the ~50ms latency cycle count (approx 10M cycles at 200MHz) layer-by-layer as per Table II.
  2. **Layer Ablation Study:** Remove the simplified FLAM (Transformer) block and measure the mIoU drop on the validation set to quantify the specific contribution of the attention mechanism in the quantized model.
  3. **Memory Profiling:** Measure the actual off-chip memory bandwidth utilization during inference to validate the assumption that streaming skip connections do not saturate the AXI bus.

## Open Questions the Paper Calls Out

- **Open Question 1:** Would native hardware support for upsample2d and other missing decoder operations in CGRA4ML significantly improve segmentation accuracy or reduce latency compared to current software workarounds?
  - **Basis in paper:** [explicit] "Currently, the Coarse-Grained Reconfigurable Array for Machine Learning (CGRA4ML) framework lacks support for certain layers, such as 2D upsampling (upsample2d), which impacts decoder performance. Adding this functionality would enhance the decoder and overall segmentation quality."
  - **Why unresolved:** The current implementation uses approximations or workarounds for unsupported layers, but the quantitative impact on mIoU and latency remains unmeasured.
  - **What evidence would resolve it:** Implementing native upsample2d support in CGRA4ML and comparing mIoU, latency, and resource utilization against the current modified decoder.

- **Open Question 2:** What is the actual power consumption of the LMIINet FPGA implementation, and how does it compare quantitatively to GPU baselines in watts-per-inference?
  - **Basis in paper:** [inferred] The paper states power consumption is "inferred from utilization and clock frequency" and claims "order-of-magnitude reduction in power" versus GPU's ~225W TDP, but no direct power measurements are reported.
  - **Why unresolved:** The paper claims power efficiency advantages but provides only inferred estimates rather than measured power draw during inference.
  - **What evidence would resolve it:** On-board power measurement using ZCU104's built-in power sensors or external power monitoring during real-time inference, reported in watts and W/inference.

- **Open Question 3:** Can the approach scale to multi-camera or stereo configurations while maintaining deterministic per-stream latency and real-time throughput?
  - **Basis in paper:** [explicit] "Our LMIINet mapping maintains timing for 20 FPS monocular feeds; scaling to multi-camera or stereo can exploit CGRA4ML's reconfiguration to time-multiplex layers while maintaining deterministic per-stream deadlines."
  - **Why unresolved:** Multi-camera scaling is proposed but not demonstrated; time-multiplexing behavior under multiple streams is untested.
  - **What evidence would resolve it:** Implementing time-multiplexed multi-stream inference and measuring per-camera latency, throughput, and resource contention under realistic multi-camera workloads.

- **Open Question 4:** What accuracy gains could be achieved by implementing the omitted block-based operations (channel shuffle, learnable channel coefficients) that were not included in the current architecture?
  - **Basis in paper:** [explicit] "Block-based operations such as channel shuffle and learnable channel coefficients were not implemented in the current LMIINet architecture. Integrating these features could improve feature extraction and local/global feature interaction, potentially leading to higher segmentation accuracy."
  - **Why unresolved:** These operations were simplified or removed for hardware compatibility, but their accuracy impact was not quantified.
  - **What evidence would resolve it:** Implementing these operations in CGRA4ML or via alternative hardware mappings and comparing mIoU and pixel accuracy against the baseline.

## Limitations
- 45% mIoU significantly below floating-point baselines (70%+ mIoU on Cityscapes), indicating substantial accuracy-efficiency tradeoffs
- Missing architectural details for modified LMIINet components (LFIB, FLAM, CAB) not fully tabulated
- Simulation instability reported at higher clock frequencies, indicating potential timing closure issues
- No direct power measurements reported, only inferred estimates from utilization and clock frequency

## Confidence
- **High Confidence:** The FPGA deployment framework using CGRA4ML and the 8-bit quantization approach with QKeras are well-established methods with clear technical specifications in the paper.
- **Medium Confidence:** The architectural modifications (depthwise convolutions, simplified attention) are described adequately, but the exact implementation details of the modified modules require further clarification.
- **Low Confidence:** The absolute performance numbers (45% mIoU) are difficult to independently verify without access to the complete model configuration and training scripts.

## Next Checks
1. **Complete Architectural Documentation:** Request or reconstruct the full layer-by-layer configuration of the modified LMIINet, including exact channel counts, dilation rates, and skip connection dimensions for each block.
2. **CGRA4ML Toolchain Verification:** Obtain and validate the specific CGRA4ML configuration files and mapping parameters used for the LMIINet deployment, including PE utilization settings and memory tiling parameters.
3. **Independent Accuracy Validation:** Reproduce the training pipeline with the exact QAT schedule and augmentations to verify the 45% mIoU result on the Cityscapes validation set before FPGA deployment.