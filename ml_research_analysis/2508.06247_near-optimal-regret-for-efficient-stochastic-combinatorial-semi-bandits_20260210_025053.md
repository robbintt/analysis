---
ver: rpa2
title: Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits
arxiv_id: '2508.06247'
source_url: https://arxiv.org/abs/2508.06247
tags:
- uni00000013
- regret
- cmoss
- cucb
- uni00000014
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational-efficiency versus regret-optimality
  trade-off in stochastic combinatorial multi-armed bandits (CMAB). While existing
  UCB-based methods like CUCB suffer from an extra log T factor in regret and adversarial
  methods like EXP3.M and HYBRID are computationally expensive, the authors propose
  CMOSS (Combinatorial Minimax Optimal Strategy in the Stochastic setting).
---

# Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits

## Quick Facts
- arXiv ID: 2508.06247
- Source URL: https://arxiv.org/abs/2508.06247
- Reference count: 40
- Primary result: CMOSS achieves optimal regret O((log k)√(kmT)) for semi-bandit feedback, eliminating log T dependency of UCB-based methods

## Executive Summary
This paper resolves a fundamental trade-off in stochastic combinatorial multi-armed bandits (CMAB) between computational efficiency and regret optimality. While existing UCB-based methods like CUCB suffer from an extra log T factor in regret and adversarial methods like EXP3.M and HYBRID are computationally expensive, the authors propose CMOSS (Combinatorial Minimax Optimal Strategy in the Stochastic setting). CMOSS is a computationally efficient algorithm that achieves an instance-independent regret of O((log k)√(kmT)) when k ≤ m/2 and O((m-k)√(log k log(m-k)T)) when k > m/2 under semi-bandit feedback, eliminating the log T dependency and matching established lower bounds up to logarithmic terms. The method extends to cascading feedback with a regret of O((log k/p*)√(kmT)) for k ≤ m/2 and O((m-k)/p*√(log k log(m-k)T)) for k > m/2, where p* is the minimal probability of observing all base arms.

## Method Summary
CMOSS maintains empirical means μ̂_i and selects actions via argmax_A r(A, μ̄), where μ̄ are empirical estimates. The confidence radius is ρ_i = √(1/T_i × ln+(1/(δT_i))) with ln+(x)=ln(max{1,x)), differing from CUCB's √(3 ln t / 2T_i). The algorithm uses a fixed δ=0.00001 and initializes μ̂_i=1 for all arms. For semi-bandit feedback, the algorithm updates empirical means incrementally after each round. The method achieves optimal regret by carefully balancing exploration and exploitation through the confidence bounds, avoiding the log T dependency that plagues UCB-based approaches while maintaining computational efficiency through the combinatorial oracle.

## Key Results
- CMOSS achieves regret O((log k)√(kmT)) for k ≤ m/2 and O((m-k)√(log k log(m-k)T)) for k > m/2 under semi-bandit feedback
- The method eliminates the log T dependency present in CUCB while maintaining computational efficiency
- Experiments on synthetic and Yelp datasets show CMOSS consistently outperforms CUCB, EXP3.M, and HYBRID in both regret and runtime efficiency
- CMOSS extends to cascading feedback with regret O((log k/p*)√(kmT)) for k ≤ m/2

## Why This Works (Mechanism)
The algorithm achieves optimal regret by using a carefully designed confidence radius that depends on the number of pulls T_i rather than the global time step t. This allows CMOSS to avoid the log T penalty that accumulates in UCB-based methods while still maintaining sufficient exploration. The confidence bounds are calibrated to ensure that the algorithm explores arms that could potentially be optimal while exploiting the arms that have been sufficiently sampled.

## Foundational Learning
- Stochastic CMAB with semi-bandit feedback: Required for understanding the problem setting where rewards are stochastic and feedback reveals the reward of each selected arm
- Confidence bounds in bandit algorithms: Critical for balancing exploration and exploitation; CMOSS uses ρ_i = √(1/T_i × ln+(1/(δT_i))) instead of traditional UCB bounds
- Combinatorial optimization oracle: Needed to efficiently find the best action given empirical estimates; typically involves selecting top-k arms
- Regret lower bounds: Important for establishing optimality; CMOSS matches the lower bound up to logarithmic factors

## Architecture Onboarding
Component map: CMOSS -> Empirical means μ̂_i -> Confidence bounds ρ_i -> Combinatorial oracle -> Action selection
Critical path: Update empirical means → Compute confidence bounds → Solve combinatorial optimization → Select action → Observe feedback
Design tradeoffs: CMOSS trades off the log T factor in CUCB for computational efficiency by using T_i-dependent confidence bounds rather than t-dependent ones
Failure signatures: Incorrect confidence radius calculation leading to either insufficient exploration or excessive exploitation; combinatorial oracle not returning optimal actions
First experiments: 1) Verify confidence radius calculation with edge cases (T_i=0, small T_i); 2) Test CMOSS on synthetic data with known optimal actions; 3) Compare regret curves against theoretical predictions

## Open Questions the Paper Calls Out
None

## Limitations
- The exact implementation of the combinatorial oracle is not specified, which could affect practical performance
- Only one Yelp dataset is used for real-world experiments, limiting generalizability
- No statistical significance testing is provided for experimental comparisons

## Confidence
- Theoretical claims: High - rigorous proofs match established lower bounds
- Experimental reproducibility: Medium - missing combinatorial oracle details and random seeds for synthetic experiments
- Practical runtime claims: Medium - lacks detailed profiling and statistical validation

## Next Checks
1. Implement the combinatorial oracle and test CMOSS on synthetic data with multiple seeds to verify reproducibility
2. Verify confidence radius calculation and initialization details match the paper's specifications
3. Run controlled experiments comparing CMOSS against CUCB and EXP3.M with reported parameters and report statistical significance of performance differences