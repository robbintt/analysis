---
ver: rpa2
title: Can Large Models Teach Student Models to Solve Mathematical Problems Like Human
  Beings? A Reasoning Distillation Method via Multi-LoRA Interaction
arxiv_id: '2508.13037'
source_url: https://arxiv.org/abs/2508.13037
tags:
- system
- reasoning
- knowledge
- mathematical
- lorid
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LoRID, a multi-LoRA interaction method for
  mathematical reasoning distillation from LLMs to SLMs. The method is inspired by
  the human learning process, which involves acquiring knowledge and then applying
  it through practice.
---

# Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction

## Quick Facts
- arXiv ID: 2508.13037
- Source URL: https://arxiv.org/abs/2508.13037
- Authors: Xinhe Li; Jiajun Liu; Peng Wang
- Reference count: 4
- Primary result: State-of-the-art accuracy on GSM8K and MATH datasets using multi-LoRA interaction

## Executive Summary
This paper proposes LoRID, a multi-LoRA interaction method for mathematical reasoning distillation from large language models (LLMs) to small language models (SLMs). Inspired by human dual-process thinking (System 1 and System 2), the method decomposes mathematical reasoning into intuitive and deep thinking components, each handled by separate LoRA adapters. The approach achieves state-of-the-art performance on GSM8K and MATH datasets, outperforming the second-best method by significant margins across five different base models.

## Method Summary
LoRID consists of four stages: knowledge augmentation, System 1 thinking (Intuitive Reasoner), System 2 thinking (Knowledge Generator and Deep Reasoner), and multi-LoRA interaction. First, a teacher LLM generates knowledge-enhanced datasets by extracting general rules from problem-solution pairs. The Intuitive Reasoner is trained to directly generate Chain-of-Thoughts for problem-solving. The System 2 component splits into a Knowledge Generator that outputs only knowledge and a Deep Reasoner that uses that knowledge for reasoning. During inference, the method iteratively runs both reasoning paths until their outputs are consistent, acting as a self-correction mechanism.

## Key Results
- Achieves state-of-the-art performance on GSM8K and MATH datasets
- Outperforms the second-best method by 2.3%, 16.1%, 2.4%, 12.3%, and 1.8% accuracy across five base models on GSM8K
- Demonstrates the effectiveness of dual-process decomposition for mathematical reasoning in SLMs

## Why This Works (Mechanism)

### Mechanism 1: Dual-Process Decomposition
The architecture splits mathematical reasoning into separate "Intuitive" (System 1) and "Deep" (System 2) processes, which may improve robustness compared to single-path fine-tuning. By training separate LoRA blocks for distinct cognitive loads, the model reduces the burden of simultaneously learning retrieval and reasoning. The core assumption is that mathematical reasoning can be effectively decoupled into "knowledge acquisition" and "logical application."

### Mechanism 2: Consistency-Based Stabilization
The system uses a "Multi-LoRA Interaction" loop that runs inference on both the Intuitive Reasoner and the Deep Reasoner. If answers diverge, the system iterates (re-sampling), acting as a self-correction mechanism that filters out stochastic errors affecting only one path. This assumes errors in System 1 and System 2 are sufficiently distinct that they rarely produce the same wrong answer simultaneously.

### Mechanism 3: Explicit Knowledge Distillation
Training SLMs on explicitly generated "knowledge" (general rules) alongside specific solutions improves generalization over training on solutions alone. The teacher LLM summarizes general rules needed to solve specific instances, forcing the student model to learn this intermediate representation. This assumes the teacher LLM can reliably extract generalizable, high-quality knowledge text from specific problem instances.

## Foundational Learning

- **Low-Rank Adaptation (LoRA)**
  - Why needed: The architecture relies on training three distinct adapters (IR, KG, DR) on a single frozen base model. Understanding how LoRA weights are merged or swapped during inference is critical for the "Multi-LoRA Interaction" phase.
  - Quick check: Can you explain how a LoRA adapter modifies the weights of a base model without changing the base weights themselves?

- **Chain-of-Thought (CoT) Distillation**
  - Why needed: The "System 1" component is essentially a standard CoT distillation. You must understand this baseline to measure the value added by the System 2 components.
  - Quick check: Why is distilling the reasoning steps (CoT) generally more effective for math than distilling only the final answer?

- **Dual-Process Theory (System 1 vs. System 2)**
  - Why needed: The entire method is a computational analogy of this psychological framework. Understanding the difference between fast/intuitive and slow/deliberate thinking helps in debugging the specific behaviors of the IR vs. DR modules.
  - Quick check: In the context of this paper, which module handles the "learning" phase and which handles the "practicing" phase?

## Architecture Onboarding

- **Component map:** Base Model -> LoRA Block 1 (IR) -> LoRA Block 2 (KG) -> LoRA Block 3 (DR)

- **Critical path:**
  1. Data Prep: Use GPT-4 to generate the "Knowledge" field for your training set
  2. Training: Train all 3 LoRA adapters on the base model
     - Train IR on (Q -> R+A)
     - Train KG on (Q -> Knowledge)
     - Train DR on (Q+Knowledge -> R+A)
  3. Inference: Run the Multi-LoRA loop. Compare answers from IR and DR; loop if mismatch

- **Design tradeoffs:**
  - Inference Latency vs. Accuracy: The iterative loop drastically increases inference cost. The threshold t (set to 20) controls this cap.
  - LoRA Rank: The paper uses a very high rank (512) compared to standard LoRA (typically 8-64), increasing parameter count but seemingly necessary for the complexity of math reasoning.

- **Failure signatures:**
  - Infinite Loop: IR and DR consistently disagree on ambiguous problems (hits iteration threshold t)
  - Degenerate Knowledge: KG outputs generic statements (e.g., "Read carefully") that provide no signal to DR
  - Catastrophic Forgetting: If LoRA ranks are too high or training is too long, the model may lose general linguistic capabilities

- **First 3 experiments:**
  1. Sanity Check (IR Only): Train and evaluate only the Intuitive Reasoner to establish a baseline performance on GSM8K
  2. Quality Assurance (KG): Manually inspect 50 samples of the GPT-4 generated "Knowledge" to ensure it is actually general knowledge and not just a copy of the solution
  3. Ablation (Interaction): Run the full LoRID system with iteration threshold t=1 vs. t=20 to quantify the performance gain specifically attributed to the consensus loop

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can reinforcement learning be applied during the training phase to simulate the interaction between knowledge and reasoning, thereby reducing the inference overhead?
- Basis in paper: The authors state in the conclusion: "We will apply the idea of interaction between knowledge and reasoning during the training phase to reduce the inference overhead of models, such as introducing reinforcement learning."
- Why unresolved: The current LoRID method relies on iterative inference (checking consistency between System 1 and System 2), which increases latency compared to single-pass models.
- What evidence would resolve it: A modified LoRID training objective using RL that achieves comparable accuracy to the iterative inference method but with a single forward pass.

### Open Question 2
- Question: Can the integration of external tools (e.g., code compilers) into the multi-LoRA interaction loop improve performance on calculation-heavy datasets?
- Basis in paper: The conclusion proposes to "use external tools (e.g., compilers) in our approach so that the knowledge generator, reasoning generator, and code generator can verify each other."
- Why unresolved: The current study deliberately excludes tool-use to focus on reasoning capabilities, but acknowledges limitations on calculation-intensive tasks like MATH.
- What evidence would resolve it: Experimental results showing that a "Code Generator" LoRA interacting with the existing modules improves accuracy on the MATH dataset compared to the current baseline.

### Open Question 3
- Question: Do the Intuitive Reasoner (System 1) and Deep Reasoner (System 2) exhibit distinct preferences for specific problem types or difficulties?
- Basis in paper: The discussion section notes: "We speculate that System 1 is better suited for handling problems based on experience and intuition, while System 2 is more suitable for problems grounded in reasoning and logic... this will be explored in future work."
- Why unresolved: While the paper shows improved performance from their interaction, it does not analyze which system is more likely to solve specific categories of problems correctly.
- What evidence would resolve it: A detailed breakdown of problem types where System 1 succeeds but System 2 fails (and vice versa), or a dynamic routing mechanism based on these preferences that outperforms the consistency check.

## Limitations
- The knowledge augmentation stage depends heavily on the quality of the teacher LLM's extracted knowledge, which is not validated in the paper
- The iterative consensus mechanism's convergence properties are unclear - it's uncertain whether the system truly finds correct answers or simply converges to the same (possibly incorrect) answer through repetition
- The high LoRA rank (512) used for mathematical reasoning differs significantly from standard ranks (8-64), suggesting the method may not generalize well to other domains without substantial hyperparameter tuning

## Confidence

- **High Confidence:** The dual-process decomposition architecture and its implementation details (LoRA training procedures, temperature settings) are clearly specified and reproducible
- **Medium Confidence:** The empirical results showing state-of-the-art performance on GSM8K and MATH datasets are well-documented, though the comparison methodology could be more rigorous
- **Low Confidence:** The effectiveness of the knowledge distillation component depends heavily on the quality of the teacher LLM's generated knowledge, which is not independently verified in the paper

## Next Checks
1. **Knowledge Quality Audit:** Manually evaluate 100 samples of the GPT-4 generated "knowledge" for both GSM8K and MATH datasets to verify that the knowledge is genuinely generalizable and not simply restating the problem or solution
2. **Convergence Analysis:** Track the distribution of iteration counts across test samples. If the majority require the full 20 iterations to converge, this suggests the consensus mechanism may be ineffective rather than beneficial
3. **Ablation on Knowledge Distillation:** Train a baseline model using only Chain-of-Thought distillation (System 1) and compare its performance to LoRID on both GSM8K and MATH to isolate the contribution of the knowledge generation component