---
ver: rpa2
title: Per-parameter Task Arithmetic for Unlearning in Large Language Models
arxiv_id: '2601.22030'
source_url: https://arxiv.org/abs/2601.22030
tags:
- unlearning
- perta
- task
- full
- forget
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses over-forgetting in large language model unlearning
  when using task arithmetic. The core method, Per-parameter Task Arithmetic (PerTA),
  introduces per-parameter scaling weights to the task vector based on gradients or
  Fisher information, balancing unlearning and retention.
---

# Per-parameter Task Arithmetic for Unlearning in Large Language Models

## Quick Facts
- **arXiv ID:** 2601.22030
- **Source URL:** https://arxiv.org/abs/2601.22030
- **Reference count:** 40
- **Primary result:** Per-parameter scaling of task vectors outperforms vanilla task arithmetic in LLM unlearning, balancing over-forgetting and under-forgetting across multiple benchmarks.

## Executive Summary
This paper addresses over-forgetting in large language model unlearning when using task arithmetic by introducing Per-parameter Task Arithmetic (PerTA). The core innovation is applying per-parameter scaling weights to the task vector based on gradients or Fisher information, which selectively preserves parameters critical for retention while unlearning the forget set. Extensive experiments on TOFU and MUSE benchmarks show PerTA consistently outperforms vanilla task vectors and surpasses several training-based unlearning methods in both forgetting effectiveness and model utility, while maintaining high time efficiency.

## Method Summary
PerTA computes per-parameter scaling weights by comparing gradient magnitudes from forget and retain sets on the original pretrained model. The method uses either gradient-based weights (PerTA-grad) or Fisher-information-based weights (PerTA-fisher) to create element-wise scaling of the task vector. This scaling mitigates over-forgetting by reducing the task vector magnitude for parameters important to the retain set. The approach maintains task arithmetic's efficiency by using one-time gradient computation rather than iterative optimization, requiring only two additional forward-backward passes beyond standard task arithmetic.

## Key Results
- PerTA consistently outperforms vanilla task vectors across TOFU and MUSE benchmarks
- PerTA-fisher achieves sharper separation of weights (closer to 0 or 1) compared to PerTA-grad
- Using only 20% of forget/retain samples for gradient estimation yields comparable results to full dataset
- PerTA achieves better trade-offs between forgetting quality and model utility than multiple training-based baselines

## Why This Works (Mechanism)

### Mechanism 1
Per-parameter scaling mitigates over-forgetting by selectively preserving parameters critical for retention. Each weight quantifies the relative importance of a parameter for forgetting versus retention, with values near 1 allowing full unlearning and values near 0 preserving the parameter. This addresses the uniform-weight problem where over-forgetting occurs because the negated TV aligns with retain-gradient ascent for many parameters.

### Mechanism 2
Squared gradients (Fisher diagonal) amplify discriminability between forget-critical and retain-critical parameters compared to linear gradients. The τ=2 operation in Fisher-based weights pushes weights toward 0 or 1 faster than τ=1, creating cleaner separation where parameters either get full TV magnitude or near-zero.

### Mechanism 3
One-time gradient computation on the original pretrained model provides sufficient importance estimates without expensive optimization. Using θ_0 as a neutral initialization avoids bias toward forget or retain knowledge, and gradient estimates are stable enough without iterative refinement.

## Foundational Learning

- **Concept: Task Vectors** - Understanding that TV = θ_finetuned - θ_original is prerequisite for grasping why scaling matters. Quick check: Given a model before and after fine-tuning, can you compute the task vector and explain what operation would "reverse" the fine-tuning?

- **Concept: Fisher Information Matrix (diagonal approximation)** - PerTA-fisher uses diagonal FIM as sensitivity measure; understanding why F_ii ≈ (∂L/∂θ_i)² clarifies the squaring operation's origin. Quick check: Why does the diagonal of FIM measure parameter sensitivity, and what does a high diagonal value indicate about a parameter?

- **Concept: Gradient-based importance/saliency** - PerTA-grad relies on |∇L| as importance signal; distinguishing this from other importance measures grounds the design choice. Quick check: For a given parameter, if |∇L(D_f)| = 0.01 and |∇L(D_r)| = 0.1, what weight would PerTA-grad assign (approximately)?

## Architecture Onboarding

- **Component map:** θ_0 (Origin model) -> θ_fgt (FgtOnly model) -> TV (Task Vector) -> W (Weight matrix) -> θ_final (Final model)

- **Critical path:** 1) Fine-tune θ_0 on D_f → θ_fgt, 2) Compute single-batch gradients: g_f = ∇L(D_f; θ_0), g_r = ∇L(D_r; θ_0), 3) Estimate W via Eq.(4) or Eq.(5), 4) Apply: θ_final = θ_full + W ⊙ (-TV)

- **Design tradeoffs:** PerTA-grad vs PerTA-fisher (grad is more stable; Fisher provides sharper separation), θ_0 vs θ_full for gradient estimation (paper shows negligible difference), sample efficiency (20% yields comparable results)

- **Failure signatures:** Over-forgetting persists (check if W values are too high), under-forgetting (check if W values cluster near 0), high variance results (PerTA-fisher may be over-sensitive), gibberish outputs on forget set (expected behavior - unlearning aims for retain-only model distribution)

- **First 3 experiments:** 1) Run vanilla TV (W=1) and uniform-weighted TV (W=0.5) on a small forget set; confirm over-forgetting pattern, 2) Implement both W_grad and W_fisher on TOFU 5% split; compare FQ and MU metrics, 3) Estimate W using 20%, 50%, 100% of retain set; plot metric degradation

## Open Questions the Paper Calls Out

### Open Question 1
Can a theoretically optimal or learnable function for f_oprt be identified to improve upon the heuristic gradient and Fisher information weighting schemes? The paper empirically tests linear and squared relationships but does not derive a theoretical optimum or explore learned functions.

### Open Question 2
Can computational overhead be significantly reduced by selectively pruning or fixing task vector updates in middle layers without sacrificing unlearning performance? Visualizations indicated middle layers were less extreme in their weights, suggesting potential for optimization.

### Open Question 3
Can PerTA be adapted to induce specific refusal behaviors ("I don't know") rather than simply minimizing likelihood of generating correct forgotten information? The current method approximates a "retain-only" model which may hallucinate false answers rather than refusing to answer.

## Limitations

- Reliance on gradient magnitudes as importance proxies may fail when forget/retain sets share significant feature overlap
- The claim that Fisher-based weights create "cleaner separation" lacks ablation studies showing when this advantage manifests in practice
- Method's efficiency claims rest on assumption that single-pass gradient estimation provides sufficient accuracy, which isn't thoroughly explored

## Confidence

- **High confidence:** Mathematical formulation of PerTA weights and their implementation are sound
- **Medium confidence:** Empirical superiority of PerTA over baselines on standard benchmarks
- **Low confidence:** Generalization of improvements to datasets with different distributional properties or when forget/retain sets have high semantic overlap

## Next Checks

1. **Distribution shift test:** Apply PerTA to a scenario where forget/retain sets have significant semantic overlap to stress-test gradient-based importance estimates
2. **Sample efficiency boundary:** Systematically measure metric degradation as fraction of forget/retain samples used for gradient estimation drops below 20%
3. **Correlation analysis:** Quantify correlation between forget and retain gradients across parameters to empirically validate when PerTA provides meaningful improvement over uniform weighting