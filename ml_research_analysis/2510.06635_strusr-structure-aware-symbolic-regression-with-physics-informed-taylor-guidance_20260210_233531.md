---
ver: rpa2
title: 'StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance'
arxiv_id: '2510.06635'
source_url: https://arxiv.org/abs/2510.06635
tags:
- symbolic
- structural
- taylor
- physical
- regression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents StruSR, a structure-aware symbolic regression
  framework that leverages trained Physics-Informed Neural Networks (PINNs) to extract
  locally structured physical priors from time series data. The core idea involves
  performing local Taylor expansions on PINN outputs to obtain derivative-based structural
  information that guides symbolic expression evolution.
---

# StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance

## Quick Facts
- arXiv ID: 2510.06635
- Source URL: https://arxiv.org/abs/2510.06635
- Reference count: 40
- Achieves lower Mean Absolute Error (MAE) than competing methods like RAG-SR, NetGP, HD-TLGP, and PhySO on structurally complex PDE systems including Poisson2D/3D, Wave2D, and Heat2D

## Executive Summary
StruSR is a structure-aware symbolic regression framework that leverages trained Physics-Informed Neural Networks (PINNs) to extract locally structured physical priors from time series data. The method performs local Taylor expansions on PINN outputs to obtain derivative-based structural information that guides symbolic expression evolution through genetic programming. By introducing a masking-based attribution mechanism to quantify subtree contributions and a hybrid fitness function that jointly minimizes physics residuals and Taylor coefficient mismatch, StruSR improves convergence speed, structural fidelity, and expression interpretability compared to conventional baselines across 3D problems.

## Method Summary
StruSR operates by first training PINNs on PDE systems to approximate the underlying physical dynamics. The method then extracts K=5 order Taylor expansions at collocation points to obtain derivative-based structural information. A genetic programming framework evolves symbolic expressions guided by subtree sensitivity scores computed via masking (replacing subtrees with constant 1), which quantify each subtree's contribution to structural alignment and physical residual reduction. The hybrid fitness function F(f) = L_phys + λ·L_Taylor combines physics residuals with Taylor coefficient mismatch. Sensitivity-guided crossover and mutation operations use softmax distributions over subtrees based on their computed sensitivity, iterating until convergence across 10 independent runs per benchmark.

## Key Results
- StruSR achieves lower MAE values than competing methods (RAG-SR, NetGP, HD-TLGP, PhySO) on structurally complex problems like Poisson2D/3D, Wave2D, and Heat2D
- The framework demonstrates consistent accuracy improvements across 3D problems compared to traditional symbolic regression approaches
- StruSR shows enhanced convergence speed and structural fidelity while maintaining expression interpretability

## Why This Works (Mechanism)
StruSR works by extracting derivative-based structural information from trained PINNs through Taylor expansions, which captures the local functional relationships between variables. This structural prior is then used to guide genetic programming evolution by computing subtree sensitivity scores that quantify each component's contribution to both physics residual reduction and structural alignment. The masking-based attribution mechanism allows the algorithm to identify and prioritize subtrees that contribute most to the overall expression quality, steering mutation and crossover operations toward more promising regions of the search space.

## Foundational Learning
**Taylor Expansion for Structural Priors**: Approximates function behavior using derivatives at specific points to capture local structure - needed for extracting PINN-based guidance for symbolic evolution; quick check: verify Taylor coefficients match analytical derivatives for known functions.
**Genetic Programming with Sensitivity Guidance**: Evolutionary algorithm that uses subtree importance scores to direct search - needed to efficiently navigate expression space while preserving useful structural patterns; quick check: confirm sensitivity scores correlate with expression quality improvements.
**Physics-Informed Neural Networks**: Neural networks trained to satisfy PDEs and boundary conditions - needed to provide high-quality structural priors through learned physical relationships; quick check: ensure PINN residual loss converges below acceptable threshold.
**Hybrid Fitness Functions**: Joint optimization combining multiple objectives (physics residuals + structural alignment) - needed to balance expression accuracy with structural fidelity to learned priors; quick check: verify both fitness components decrease across generations.
**Subtree Masking Attribution**: Attribution method that evaluates component importance by replacing with constants - needed to quantify individual subtree contributions to overall expression quality; quick check: test on simple expressions where ground truth attribution is known.

## Architecture Onboarding
**Component Map**: PINN Training -> Taylor Expansion -> GP Initialization -> Sensitivity Computation -> Guided Evolution -> Expression Output
**Critical Path**: The most critical sequence is PINN training quality → Taylor coefficient extraction accuracy → sensitivity computation reliability → GP convergence behavior
**Design Tradeoffs**: Fixed Taylor order K=5 balances expressiveness against derivative noise, but may miss complex patterns; sensitivity-guided evolution improves efficiency but depends on proper hyperparameter tuning of λ and β
**Failure Signatures**: PINN convergence failure manifests as poor structural guidance; inadequate sensitivity computation shows as high variance across runs; structural misalignment appears as overly complex expressions with poor fitness scores
**First Experiments**: 1) Train PINN on simple 1D advection equation and verify Taylor coefficient extraction; 2) Run GP with known ground truth expression to validate sensitivity computation; 3) Test sensitivity-guided evolution on benchmark problem with controlled noise levels

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does StruSR perform under noisy data conditions where the trained PINN provides imperfect structural guidance?
- Basis in paper: [inferred] The paper evaluates on benchmark PDE systems with deterministic conditions but does not test robustness to noise in training data or PINN approximation errors.
- Why unresolved: PINN quality directly impacts Taylor coefficient extraction; noisy data could degrade both the physics-informed priors and subsequent symbolic evolution.
- What evidence would resolve it: Experiments measuring MAE and structural fidelity when Gaussian noise is added to training data, with analysis of how noise propagates through PINN training to Taylor expansion accuracy.

### Open Question 2
- Question: Can the Taylor expansion order K be adaptively selected based on problem complexity rather than fixed at K=5?
- Basis in paper: [explicit] "We set the Taylor expansion order K=5 to balance expressiveness and numerical stability: lower orders may underfit local structure, while higher orders are prone to derivative noise and overfitting."
- Why unresolved: The fixed K=5 represents a heuristic tradeoff; optimal order likely varies across PDE types, dimensionality, and solution smoothness.
- What evidence would resolve it: Systematic ablation across different K values for each benchmark, combined with analysis of derivative noise accumulation and correlation with solution complexity metrics.

### Open Question 3
- Question: How sensitive is StruSR to the quality and architecture of the underlying PINN used for structural prior extraction?
- Basis in paper: [inferred] The framework depends on "a trained PINN model u(x)" but does not analyze how PINN training quality, network depth, or architecture choices affect Taylor coefficient reliability and downstream symbolic regression performance.
- Why unresolved: Poorly converged or underparameterized PINNs could provide misleading structural guidance, causing StruSR to converge to physically incorrect expressions.
- What evidence would resolve it: Experiments varying PINN architectures (depth, width, activation functions) and training regimes, measuring correlation between PINN residual loss and final StruSR expression accuracy.

## Limitations
- Method relies heavily on accurate Taylor coefficient extraction from PINNs, which could be sensitive to training quality and collocation point density
- Fixed Taylor expansion order K=5 may not capture all relevant structural patterns for highly nonlinear PDEs
- Masking-based sensitivity computation assumes subtree independence, which may not hold for expressions with strong coupling between terms
- Effectiveness depends on proper hyperparameter tuning of λ and β, which are not specified

## Confidence
High confidence in overall framework design and reported accuracy improvements on standard benchmarks
Medium confidence in claimed interpretability benefits, as these are more qualitative and harder to quantify
Low confidence in performance guarantees on completely novel PDE systems outside the tested benchmark suite

## Next Checks
1) Test sensitivity of StruSR to PINN training quality by deliberately varying collocation point density and observing expression recovery accuracy
2) Validate masking-based sensitivity computation by comparing it against alternative attribution methods like integrated gradients on benchmark problems
3) Assess generalization to out-of-distribution PDEs by applying StruSR to equations with different functional forms than the training set (e.g., Burgers' equation, Allen-Cahn)