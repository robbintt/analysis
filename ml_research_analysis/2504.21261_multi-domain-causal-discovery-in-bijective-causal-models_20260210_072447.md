---
ver: rpa2
title: Multi-Domain Causal Discovery in Bijective Causal Models
arxiv_id: '2504.21261'
source_url: https://arxiv.org/abs/2504.21261
tags:
- causal
- variables
- random
- discovery
- variable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles causal structure discovery in multi-domain settings
  where causal mechanisms are invariant but noise distributions may vary. The authors
  introduce "bijective generation mechanisms" (BGM) as a unifying framework for various
  noise models including additive noise, LiNGAM, post-nonlinear, and location-scale
  models.
---

# Multi-Domain Causal Discovery in Bijective Causal Models

## Quick Facts
- **arXiv ID**: 2504.21261
- **Source URL**: https://arxiv.org/abs/2504.21261
- **Authors**: Kasra Jalaldoust; Saber Salehkaleybar; Negar Kiyavash
- **Reference count**: 17
- **Key outcome**: Introduces Bijective Generation Mechanisms (BGM) for multi-domain causal discovery, achieving 82% accuracy in bivariate cases and 20% higher F1-score than baselines in multivariate settings

## Executive Summary
This paper addresses causal structure discovery in multi-domain settings where causal mechanisms remain invariant but noise distributions vary across domains. The authors introduce "bijective generation mechanisms" (BGM) as a unifying framework encompassing various noise models including additive noise, LiNGAM, post-nonlinear, and location-scale models. Under BGM, they derive necessary conditions for causal directions using a novel "density-vectorization" technique that captures distributional differences across domains. Their method outperforms existing approaches like ICP, NLICP, LiNGAM, and CD-NOD, particularly in scenarios with heterogeneous noise distributions.

## Method Summary
The method estimates conditional densities $p(Y|X)$ for each domain, then constructs a normalized vector of these densities for each data point across domains. This creates a "special random variable" that, under the correct causal direction, should be independent of the cause. Statistical independence tests (HSIC) are used to reject invalid causal directions. For multivariate cases, the algorithm employs heuristics (H1: union of non-rejected subsets, H2: max p-value given parent set size) to recover parent sets. The approach requires accurate non-parametric estimation of conditional densities and sufficient heterogeneity between domains.

## Key Results
- Achieves 82% accuracy in bivariate causal direction identification
- Outperforms ICP, NLICP, LiNGAM, and CD-NOD by 20% higher F1-score in multivariate parent set recovery
- Validated on synthetic data (heteroscedastic noise models) and real-world datasets (CollegeDistance, Adult datasets)
- Demonstrates robustness to various noise models under the BGM framework

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Causal direction can be inferred by testing the "similarity" of conditional distributions across domains when mechanisms are invariant but noise varies.
- **Mechanism**: BGM ensures the function mapping noise $E$ to effect $Y$ is bijective and differentiable for any cause $X=x$. This creates pairwise similarity between conditional distributions $Y|X=x$ across domains, captured through diffeomorphisms. The density-vectorization technique constructs a "special random variable" $\Psi$ that must be independent of $X$ under the correct causal direction.
- **Core assumption**: Markovianity (causal sufficiency/no confounders), positivity across domains, and the BGM property (bijective and differentiable noise-to-effect mapping).
- **Evidence anchors**: [abstract] BGM ensures bijective and differentiable functional relation; [section 3.1, Proposition 1] Assumption 1 holds iff pairwise similarity; [corpus] Skewness-Robust Causal Discovery discusses similar constraints in noise models.
- **Break condition**: If distributions don't change between domains, density-vectorization collapses to constant, rendering independence test uninformative.

### Mechanism 2
- **Claim**: Violation of independence between cause $X$ and "special random variable" $\Gamma_{X \to Y}$ implies $X$ is not the parent of $Y$.
- **Mechanism**: Algorithm estimates conditional densities $p^i_{Y|X}$ for each domain, constructs normalized density vectors $\gamma$, and tests if $\gamma$ is independent of $x$. Dependence detection (low p-value) leads to rejection of $X \to Y$ hypothesis.
- **Core assumption**: Accurate conditional density estimation and valid independence test (HSIC).
- **Evidence anchors**: [section 3.1, Theorem 1] causal diagram $X \to Y$ can be rejected if $\Gamma_{X \to Y} \not\perp X$; [section 4.1] describes sampling of $\Gamma$; [corpus] Causal Effect Identification supports leveraging multi-domain heterogeneity.
- **Break condition**: Inaccurate density estimation (small samples or high dimensionality) creates noisy $\gamma$, leading to spurious rejections or failures to reject.

### Mechanism 3
- **Claim**: "Union of non-rejected subsets" heuristic (H1) recovers parent set in multivariate settings.
- **Mechanism**: Iterates through subsets $S$ of adjacent nodes, tests if $\Gamma_{S \to V} \perp V$. If independence holds (p-value $> c$), $S$ is flagged as candidate parent set. Final output is union of all candidates.
- **Core assumption**: Independence test soundness guarantees exclusion of true non-parents, though completeness isn't theoretically guaranteed.
- **Evidence anchors**: [section 4.2] H1: return $\hat{PA} := \bigcup_{S \subset A: L(S) > c} S$; [section 5.1] H1 achieves 82% accuracy; [corpus] weak evidence regarding this specific heuristic in related literature.
- **Break condition**: Combinatorial explosion with large adjacent variable sets $A$.

## Foundational Learning

- **Concept**: Structural Causal Models (SCM) & Markovianity
  - **Why needed here**: The paper operates on $Y = f(X, E)$ where $X$ and $E$ are independent (Markovianity). Without this, the "similarity" of conditional distributions doesn't hold.
  - **Quick check question**: Can you explain why the independence of noise $E$ and cause $X$ is required to derive the density transformation properties in Section 3?

- **Concept**: Diffeomorphisms (Bijective & Differentiable mappings)
  - **Why needed here**: Core theoretical contribution relies on $f(x, \cdot)$ being a diffeomorphism. This ensures probability densities can be transformed deterministically across domains, enabling density-vectorization.
  - **Quick check question**: Does standard Additive Noise Model (ANM), $Y = X + E$, satisfy the diffeomorphism assumption required by BGM?

- **Concept**: Kernel-based Independence Tests (e.g., HSIC)
  - **Why needed here**: Practical implementation relies on testing independence of derived "special random variable" and cause. Authors use HSIC test to operationalize theoretical condition.
  - **Quick check question**: In algorithm, do we reject causal direction if HSIC test returns high p-value or low p-value?

## Architecture Onboarding

- **Component map**: Density Estimator -> Vectorization Engine -> Independence Tester -> Parent Aggregator
- **Critical path**: Accurate non-parametric estimation of conditional densities $p^i_{Y|X}$. Errors here propagate directly to vectorization step, invalidating independence test.
- **Design tradeoffs**:
  - **H1 vs H2**: H1 guarantees true parent set containment (high recall) but may include false positives. H2 more precise with known parent set size but requires more hyperparameter tuning.
  - **Density Estimation**: High-fidelity estimation requires large samples ($n=1000$ for bivariate, $10000$ for multivariate in experiments).
- **Failure signatures**:
  - **Uniform Vectorization**: If $\gamma$ vectors cluster near uniform distribution, domain heterogeneity is insufficient.
  - **High Variance in Low-Data Regimes**: Small $N$ leads to erratic density estimates and inconsistent parent set discovery.
- **First 3 experiments**:
  1. **Bivariate Synthetic Validation**: Generate data using heteroscedastic model $Y = \alpha X + (\beta |X| + 1)E$ across 2 domains. Verify method rejects anti-causal direction $Y \to X$.
  2. **Sensitivity to Domain Shift**: Run algorithm on datasets with progressively reduced difference between domain parameters ($\mu_1, \mu_2$) to find breaking point where identification fails.
  3. **Multivariate Scalability**: Test H1 heuristic on 5-node graph with varying parent set sizes to measure F1-score degradation as graph complexity increases.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Is the identity of special random variables ($\Psi_A^I = \Psi_B^I$) a sufficient condition for similarity of original variables ($A \sim B$)?
- **Basis in paper**: [explicit] Authors state in footnote regarding Proposition 2: "We conjecture that $\Psi_A^I = \Psi_B^I$ is a sufficient condition for A and B to be similar. We could not generate any counter-examples, but could not prove the statement either."
- **Why unresolved**: Currently only proven as necessary indicator of similarity; sufficiency remains unproven.
- **What evidence would resolve it**: Formal mathematical proof or identification of specific counter-example.

### Open Question 2
- **Question**: What are the necessary faithfulness assumptions required to ensure completeness of the proposed discovery algorithm?
- **Basis in paper**: [explicit] Section 5.3 states algorithm guarantees soundness but doesn't claim completeness, and "discussion of necessary faithfulness assumptions remains an open question."
- **Why unresolved**: Current theory doesn't ensure all invalid causal directions are rejected, only that valid ones aren't incorrectly rejected.
- **What evidence would resolve it**: Deriving specific conditions under which algorithm is guaranteed to identify all non-parents.

### Open Question 3
- **Question**: Can results for multi-domain causal discovery be extended to non-stationary time-series and sequential decision-making settings?
- **Basis in paper**: [explicit] Conclusion explicitly lists "extension of results to non-stationary time-series and applications in sequential decision-making" as future work.
- **Why unresolved**: Current framework assumes i.i.d. samples across domains and doesn't account for temporal dependencies or sequential interventions.
- **What evidence would resolve it**: Adaptation of BGM framework and statistical tests that handle time-series data.

## Limitations

- Performance degrades sharply when domain heterogeneity is insufficient, though quantitative bounds on required distributional differences aren't provided
- Method's performance relies heavily on large sample sizes ($n=10000$) for multivariate settings, which may not be realistic in many applications
- Threshold $c$ for independence testing is tuned empirically but not systematically specified, creating reproducibility concerns

## Confidence

- **High Confidence**: Theoretical framework under BGM assumptions is sound (Mechanism 1 and 2). Independence test correctly identifies when $X \to Y$ can be rejected given accurate density estimation.
- **Medium Confidence**: H1 heuristic for multivariate parent set recovery works empirically (82% accuracy) but lacks theoretical guarantees for completeness beyond containment.
- **Low Confidence**: Performance claims in high-dimensional settings rely heavily on large sample sizes ($n=10000$) that may not be realistic in many applications.

## Next Checks

1. **Domain Heterogeneity Threshold**: Systematically vary difference between domain parameters ($\mu_1, \mu_2$) in synthetic experiments to quantify minimum distributional shift required for reliable causal direction identification.
2. **Density Estimation Sensitivity**: Compare results using different conditional density estimation methods (Gaussian kernels, splines, neural networks) to assess robustness to density estimation step.
3. **Scalability Benchmark**: Evaluate H1 on graphs with 10+ nodes to measure computational complexity growth and F1-score degradation as number of subsets to evaluate increases exponentially.