---
ver: rpa2
title: Test-time Diverse Reasoning by Riemannian Activation Steering
arxiv_id: '2511.08305'
source_url: https://arxiv.org/abs/2511.08305
tags:
- diversity
- reasoning
- steering
- problem
- vectors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SPREAD, an unsupervised activation steering
  framework designed to improve reasoning diversity in language models during best-of-N
  sampling. The method intervenes in hidden activations at test time by computing
  steering vectors that maximize the volume spanned by intervened activation subsets,
  formulated as a Riemannian optimization problem over the product of spheres.
---

# Test-time Diverse Reasoning by Riemannian Activation Steering

## Quick Facts
- arXiv ID: 2511.08305
- Source URL: https://arxiv.org/abs/2511.08305
- Reference count: 40
- Introduces SPREAD, an unsupervised activation steering framework that improves reasoning diversity in language models during best-of-N sampling

## Executive Summary
SPREAD is an unsupervised activation steering framework designed to enhance reasoning diversity in language models during test-time generation. The method intervenes in hidden activations at synchronization anchors by computing steering vectors that maximize the volume spanned by intervened activation subsets, formulated as a Riemannian optimization problem over the product of spheres. Experiments on mathematical reasoning benchmarks demonstrate that SPREAD consistently outperforms temperature sampling in both generative diversity (unique solution count and diversity scores) and solution accuracy (Pass@N), while maintaining computational efficiency with under 1.8 seconds of overhead even for large hidden dimensions.

## Method Summary
SPREAD intervenes in hidden activations during language model generation by computing steering vectors that maximize the volume spanned by intervened activation subsets. The method treats the steering problem as Riemannian optimization over the product of spheres, using block-coordinate descent with well-tuned learning rates to efficiently compute steering vectors at synchronization anchors. Unlike previous activation steering approaches that require additional neural architectures or focus on a single task, SPREAD works as an unsupervised, generalizable framework that operates at test time without modifying the base model architecture. The steering vectors are computed to encourage diversity in the hidden activation space, with the hypothesis that this promotes diversity in reasoning paths.

## Key Results
- SPREAD consistently outperforms temperature sampling in generative diversity metrics (unique solutions and diversity scores) across AIME24, MATH500, and OlympiadBench datasets
- SPREAD achieves higher Pass@N accuracy compared to temperature sampling, with improvements of several percentage points in most conditions
- The method remains computationally efficient, requiring under 1.8 seconds of overhead even for large hidden dimensions

## Why This Works (Mechanism)
SPREAD works by intervening in the hidden activation space of language models during generation, steering the model toward diverse reasoning paths through geometric manipulation of activation volumes. By maximizing the volume spanned by intervened activation subsets using Riemannian optimization, the method encourages exploration of different regions in the activation space, which correlates with different reasoning trajectories. The block-coordinate descent approach with well-tuned learning rates enables efficient computation of steering vectors at synchronization anchors without requiring additional neural architectures or extensive training.

## Foundational Learning
- Riemannian optimization on product of spheres: Required for steering vector computation; quick check: verify that the optimization problem formulation correctly handles the spherical constraints
- Block-coordinate descent for high-dimensional optimization: Enables efficient steering vector computation; quick check: confirm convergence properties and learning rate sensitivity
- Synchronization anchor selection in sequence generation: Critical for timing interventions; quick check: validate that anchor positions capture meaningful intermediate reasoning states
- Volume maximization as diversity proxy: Links geometric properties to reasoning diversity; quick check: correlate volume changes with diversity metric improvements

## Architecture Onboarding

Component map: Base LM -> Hidden activation extraction -> Riemannian optimization -> Steering vector computation -> Activation intervention -> Generation

Critical path: The core pipeline involves extracting hidden states at synchronization anchors, computing steering vectors through Riemannian block-coordinate descent, applying the steering vectors to the activations, and continuing generation. The most computationally intensive step is the log-determinant computation for volume maximization, which is optimized through the Riemannian formulation.

Design tradeoffs: SPREAD trades off computational overhead at synchronization anchors against improved diversity and accuracy. The method requires additional computation during inference but avoids the need for task-specific fine-tuning or architectural modifications. The choice of synchronization anchor frequency represents a key tradeoff between computational cost and diversity gains.

Failure signatures: If steering vectors fail to improve diversity, the model may produce identical or highly similar solutions across samples. Poor learning rate selection in the block-coordinate descent can lead to suboptimal steering vectors or convergence issues. Inappropriate synchronization anchor placement may result in interventions that don't capture meaningful reasoning transitions.

Three first experiments:
1. Verify that steering vectors computed through Riemannian optimization actually increase the volume spanned by activation subsets compared to random steering
2. Test the sensitivity of diversity improvements to different synchronization anchor frequencies and positions
3. Compare the computational overhead of SPREAD against the quality gains in both diversity and accuracy metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does promoting hidden activation diversity reliably induce reasoning path diversity across different domains and tasks?
- Basis in paper: "While there may be strong correlations between the activations and the reasoning paths, there is unfortunately no one-to-one equivalence between them. Thus, admittedly, promoting diversity of the hidden activations does not necessarily lead to diversity in the reasoning paths."
- Why unresolved: The paper acknowledges this fundamental uncertainty but validates the approach only on mathematical reasoning tasks. The causal link between activation geometry and reasoning diversity remains theoretically unclear.
- What evidence would resolve it: Systematic experiments across non-mathematical domains (e.g., code generation, logical reasoning) with analysis correlating activation volume changes to actual reasoning path variations.

### Open Question 2
- Question: What are the optimal strategies for selecting synchronization anchor positions and their frequency during generation?
- Basis in paper: The paper uses fixed positions τ ∈ {100, 600, 1100, 1600} without systematic ablation or justification of this design choice.
- Why unresolved: Different anchor frequencies could trade off computational cost against diversity gains, and adaptive anchor placement might improve performance.
- What evidence would resolve it: Ablation studies varying anchor frequency, spacing, and adaptiveness; analysis of how intervention timing affects downstream generation diversity.

### Open Question 3
- Question: How does SPREAD scale to larger language models (e.g., 7B+ parameters) and does the computational efficiency advantage persist?
- Basis in paper: Experiments are limited to 1.5B parameter models (Qwen2.5-1.5B and Qwen2.5-Math-1.5B-Instruct). Scalability claims are based on synthetic experiments, not real model inference.
- Why unresolved: Larger models may have different activation space properties; the log-determinant computation scales with dimension and could become a bottleneck.
- What evidence would resolve it: Empirical evaluation on larger models (7B, 13B, 70B) measuring both Pass@N improvements and wall-clock inference time overhead

## Limitations
- The method's effectiveness is currently demonstrated only on mathematical reasoning tasks, leaving generalization to other domains uncertain
- The causal relationship between activation diversity and reasoning path diversity remains theoretically unclear despite experimental validation
- Computational overhead, while manageable for 1.5B models, may become prohibitive for larger models or more frequent synchronization anchors

## Confidence
- Diversity improvements: Medium - consistent across experiments but domain-limited
- Accuracy gains: Medium - variable by dataset, requires careful interpretation against temperature sampling comparisons
- Computational efficiency: High - well-supported by timing measurements and synthetic scaling experiments

## Next Checks
1. Test SPREAD on non-mathematical reasoning benchmarks (e.g., logical puzzles, commonsense reasoning datasets) to assess cross-domain generalization
2. Compare against hybrid sampling strategies that combine temperature scaling with activation steering to isolate SPREAD's unique contributions
3. Evaluate the sensitivity of steering vector quality to different synchronization anchor frequencies and hidden layer selections to optimize the trade-off between diversity and computational overhead