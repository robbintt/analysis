---
ver: rpa2
title: Who is Helping Whom? Analyzing Inter-dependencies to Evaluate Cooperation in
  Human-AI Teaming
arxiv_id: '2502.06976'
source_url: https://arxiv.org/abs/2502.06976
tags:
- agents
- task
- agent
- reward
- cooperation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitation of task reward as a sole metric
  for evaluating cooperation in human-AI teaming, especially in zero-shot cooperation
  scenarios. The authors propose a new domain-agnostic metric called constructive
  interdependence, which measures how much agents rely on each other's actions to
  achieve shared goals by analyzing action interactions in a STRIPS formalism.
---

# Who is Helping Whom? Analyzing Inter-dependencies to Evaluate Cooperation in Human-AI Teaming

## Quick Facts
- arXiv ID: 2502.06976
- Source URL: https://arxiv.org/abs/2502.06976
- Reference count: 40
- Primary result: Task reward alone fails to measure cooperation; constructive interdependence metric reveals non-cooperative behavior in zero-shot cooperation agents despite high task performance.

## Executive Summary
This paper addresses the fundamental limitation of using task reward as the sole metric for evaluating cooperation in human-AI teaming, particularly in zero-shot cooperation (ZSC) scenarios. The authors propose a domain-agnostic metric called constructive interdependence that measures how much agents rely on each other's actions to achieve shared goals by analyzing action interactions in a STRIPS formalism. Through experiments in the Overcooked domain, they demonstrate that high task rewards do not correlate with cooperative behavior—agents achieve good performance but exhibit low constructive interdependence. Human participants frequently initiate cooperative interactions, but agents often reject them, revealing a critical gap between performance and true collaboration.

## Method Summary
The method converts trajectories to symbolic traces using a Mapping Module that translates states into STRIPS propositions, then analyzes these traces with an Analysis Module to detect interdependencies. An interdependence is defined when one agent's action effects satisfy another agent's action preconditions. The system classifies interdependencies as constructive (goal-reaching and non-looping) or non-constructive. The metric is evaluated by pairing state-of-the-art ZSC agents with humans and learned human models, measuring both constructive and non-constructive interdependencies alongside task reward.

## Key Results
- Agents achieve high task reward but consistently low constructive interdependence in non-required cooperation settings
- Human participants initiate cooperative interactions that agents frequently reject (70-100% rejection rates)
- Task reward correlates with constructive interdependence in required cooperation (r=0.81) but not in non-required cooperation (r=0.19)
- Preliminary experiments show that incorporating the metric into training improves cooperation without harming task performance

## Why This Works (Mechanism)

### Mechanism 1: STRIPS-Based Interdependence Detection
- Claim: Constructive interdependence can be detected by identifying when one agent's action effects satisfy another agent's action preconditions in a symbolic representation.
- Mechanism: The system maps Markov game states to STRIPS propositions and tracks action transitions (preconditions → effects). When agent j's action adds a proposition that agent i's subsequent action requires as a precondition, this forms an interdependent pair. The interdependence is classified as "constructive" if: (1) the associated object reaches a goal state (goal-reaching), and (2) the object doesn't return to the giver in the same state (non-looping).
- Core assumption: Cooperative behavior can be formalized through symbolic action dependencies rather than just outcome metrics.
- Evidence anchors:
  - [section] "We define Interdependence as a pair of actions (a^{t0+k}_i, a^{t0}_j) such that add(a^{t0}_j) ⊆ pre(a^{t0+k}_i)"
  - [section] "An interdependence Int is a Constructive Interdependence, if it is a Goal Reaching Interdependence and a Non-looping Interdependence."
  - [corpus] Weak direct corpus support; related work (Wu et al.) uses CCM for low-level dynamics, not symbolic dependencies.
- Break condition: If the domain cannot be represented symbolically (no clear preconditions/effects), or if actions have probabilistic effects that obscure causal attribution.

### Mechanism 2: Reward-Cooperation Decoupling in Non-RC Settings
- Claim: In non-required cooperation settings, task reward fails to capture whether agents genuinely coordinate because agents can optimize reward independently.
- Mechanism: The "shadowed equilibrium problem" causes agents to converge to non-cooperative equilibria during training because cooperative strategies are rarely explored. In Non-RC domains like Counter Circuit, one agent can complete the task alone. When paired with cooperative humans who initiate interdependencies, ZSC agents reject these attempts (70-100% rejection rates) yet still achieve high task reward because the human compensates.
- Core assumption: High task performance in Non-RC settings can mask coordination failures.
- Evidence anchors:
  - [abstract] "our results reveal that these agents often fail to induce cooperation, as evidenced by consistently low interdependence across teams"
  - [section] Table 1b shows COLE rejects 88.88% of triggered interdependencies; FCP/HSP reject 100%
  - [section] "Pearson r=0.81 (p<0.001) in RC settings vs. r=0.19 in Non-RC settings"
  - [corpus] Related work (Zhang et al. 2016) introduced RC/Non-RC distinction; corpus supports reward insufficiency concern.
- Break condition: If humans stop compensating for non-cooperative agents, or if the task strictly requires coordination (RC settings), reward and cooperation would correlate.

### Mechanism 3: Teaming Reward Augmentation
- Claim: Adding constructive interdependence as a training signal can induce cooperative behavior without degrading task performance.
- Mechanism: Modified reward: r_modified = r_task + α × r_teaming, where r_teaming is measured by constructive interdependencies. Preliminary experiments (Fig. 3) show agents trained with modified reward consistently increase teaming reward while task reward remains comparable to baseline.
- Core assumption: Interdependence count serves as a learnable signal that shapes exploration toward cooperative equilibria.
- Evidence anchors:
  - [section] "preliminary experiments showing that incorporating this metric into training improves cooperation without harming task performance"
  - [section] Fig. 3 shows training curves for FCP, MEP, HSP with modified vs. original reward
  - [corpus] No direct corpus validation; this is presented as preliminary within the paper itself.
- Break condition: If α is too high, agents may optimize for interdependence at the cost of task efficiency; if interdependencies are sparse, the signal may be too weak for learning.

## Foundational Learning

- Concept: STRIPS Planning Formalism
  - Why needed here: The entire metric depends on representing actions as (preconditions, add-effects, delete-effects) tuples to detect when one agent enables another.
  - Quick check question: Given action "place onion on counter," can you identify its preconditions and effects?

- Concept: Required vs. Non-Required Cooperation
  - Why needed here: The paper's central claim depends on understanding why reward-cooperation correlation differs between RC and Non-RC settings.
  - Quick check question: In Overcooked, why can Counter Circuit be completed solo while Forced Coordination cannot?

- Concept: Shadowed Equilibrium Problem
  - Why needed here: Explains why ZSC agents trained on task reward alone fail to discover cooperative strategies even when they exist.
  - Quick check question: Why might self-play training never explore passing-onion strategies if solo completion works?

## Architecture Onboarding

- Component map: Mapping Module -> Analysis Module -> Evaluation Pipeline
- Critical path:
  1. Define domain predicates and action-to-STRIPS mapping
  2. Collect trajectory data from agent-partner gameplay
  3. Run Mapping Module → produces grounded symbolic trace
  4. Run Analysis Module → produces interdependence counts and classifications
  5. Correlate with task reward to assess reward-cooperation alignment

- Design tradeoffs:
  - Symbolic vs. learned representations: STRIPS requires manual predicate definition but provides interpretability
  - Post-hoc vs. online analysis: Current system is post-hoc; real-time integration would require faster processing
  - Constructive threshold: Non-looping requirement may filter out legitimate multi-pass coordination

- Failure signatures:
  - Int_cons = 0 with high task reward → agent operates independently (Non-RC warning)
  - High Int_non-cons → agents interfere or redundantly coordinate
  - High %P_not-trig-acc → agent ignores partner's cooperative overtures

- First 3 experiments:
  1. Validate mapping module: Run on known Overcooked trajectories and verify interdependence counts match manual analysis
  2. Baseline correlation test: Compare reward-Int_cons correlation in RC vs. Non-RC layouts with existing ZSC agents
  3. Training integration pilot: Train a simple PPO agent with r_modified (α=0.3) and compare Int_cons trajectory against r_task-only baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the constructive interdependence metric be expanded to quantify pooled and team-based interdependencies, in addition to the currently supported sequential and reciprocal forms?
- Basis in paper: [explicit] The conclusion states: "Future work would include broadening this metric to include other kinds of interdependencies and cooperative behaviors."
- Why unresolved: The current implementation focuses specifically on sequential and reciprocal interdependencies where one agent's action effect satisfies another's precondition.
- What evidence would resolve it: A formalization of "pooled" interdependence (simultaneous independent contributions) within the STRIPS-based metric and its validation in a domain requiring such coordination.

### Open Question 2
- Question: Does using constructive interdependence as an intrinsic reward signal reliably resolve the "shadowed equilibrium problem" in diverse Non-Required Cooperation (Non-RC) domains?
- Basis in paper: [explicit] The authors identify the shadowed equilibrium problem as a cause for non-cooperative behavior in Non-RC settings and list using the metric as a reward signal as a specific research direction to address this.
- Why unresolved: The paper only provides "preliminary experiments" showing the metric can be added to training, but does not fully explore if this prevents agents from converging to non-cooperative equilibria in varied layouts.
- What evidence would resolve it: Comprehensive training experiments showing that agents rewarded for interdependence consistently discover and maintain cooperative strategies in Non-RC layouts where standard reward maximization fails.

### Open Question 3
- Question: To what extent does the requirement for a symbolic STRIPS mapping limit the scalability of this metric to complex, continuous, or high-dimensional environments?
- Basis in paper: [inferred] The method relies on a mapping module to convert states into symbolic propositions ($F: S \rightarrow 2^P$); while claimed as domain-agnostic, this assumes the existence of a clean symbolic abstraction.
- Why unresolved: The paper demonstrates the metric on grid-world tasks (Overcooked, Search & Rescue) where discrete symbolic states are easily defined, leaving performance in less structured domains untested.
- What evidence would resolve it: Successful application of the metric in a continuous control or vision-based domain, potentially using learned symbolic abstractions.

## Limitations

- The metric relies on manual domain-specific predicate definitions, limiting domain generality despite claims of being "domain-agnostic"
- The human study (n=36) provides qualitative insights but lacks statistical power for strong behavioral conclusions
- The training augmentation results are preliminary, showing only short-term effects over 5M timesteps without demonstrating long-term stability or generalization

## Confidence

- **High confidence:** The core observation that task reward fails to correlate with cooperation in non-required cooperation settings is well-supported by both theoretical reasoning (shadowed equilibrium problem) and empirical evidence (Table 1b showing high rejection rates)
- **Medium confidence:** The constructive interdependence metric provides a useful signal for cooperation quality, though its reliance on manual symbolic grounding introduces potential subjectivity and limits scalability
- **Low confidence:** The claim that incorporating the metric into training reliably improves cooperation is based on preliminary experiments without thorough ablation studies or long-term validation

## Next Checks

1. **Ablation study on α parameter:** Systematically vary the teaming reward weight (α) to identify the optimal balance between task performance and cooperation, including tests for whether excessive focus on interdependence degrades task efficiency

2. **Cross-domain generalization test:** Apply the metric to a different symbolic planning domain (e.g., Blocks World or Taxi) to evaluate whether the same patterns of reward-cooperation decoupling emerge and whether manual predicate definition remains tractable

3. **Human compensation threshold:** Design an experiment where human participants are instructed to stop compensating for non-cooperative agents in Non-RC settings, measuring whether task reward then correlates with interdependence and whether agents adapt their behavior