---
ver: rpa2
title: 'Do Not Change Me: On Transferring Entities Without Modification in Neural
  Machine Translation -- a Multilingual Perspective'
arxiv_id: '2505.06010'
source_url: https://arxiv.org/abs/2505.06010
tags:
- language
- translation
- entities
- entity
- category
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates the ability of popular neural machine\
  \ translation (NMT) models to preserve non-translatable entities\u2014such as URLs,\
  \ emails, and emojis\u2014during translation. A new multilingual dataset of 36,000\
  \ sentences across English, German, Polish, and Ukrainian is introduced, covering\
  \ nine entity categories."
---

# Do Not Change Me: On Transferring Entities Without Modification in Neural Machine Translation -- a Multilingual Perspective

## Quick Facts
- arXiv ID: 2505.06010
- Source URL: https://arxiv.org/abs/2505.06010
- Reference count: 17
- Primary result: EuroLLM 9B and Google Translate achieve highest entity preservation accuracy (~95.9% and ~93.3% respectively) across 9 entity categories in multilingual translation.

## Executive Summary
This study evaluates the ability of eight neural machine translation (NMT) models to preserve non-translatable entities—including URLs, emails, emojis, and social media handles—during translation across four languages (English, German, Polish, Ukrainian). The authors introduce a synthetic dataset of 36,000 sentences and evaluate model performance using exact match accuracy and Levenshtein distance metrics. EuroLLM 9B and Google Translate demonstrate superior entity preservation (over 93% accuracy), while models without byte-level tokenization struggle particularly with emojis. The study finds that model size and tokenization granularity significantly impact entity transfer accuracy, with prompt engineering providing additional improvements for LLMs.

## Method Summary
The study evaluates eight NMT models—including Google Translate, EuroLLM 9B, MADLAD 7B, and several OPUS variants—on a synthetic dataset of 36,000 sentences across English, German, Polish, and Ukrainian. Sentences are generated using Gemma 2 9B IT with controlled sampling parameters and filtered for language quality. The evaluation covers nine entity categories (emails, URLs, phone numbers, emojis, IBANs, IPs, ISBNs, social handlers, alphanumeric sequences) using regex extraction. Entity preservation is measured through exact match accuracy and Levenshtein distance, with translation quality validated using CometKiwi. The dataset and evaluation code are publicly available.

## Key Results
- EuroLLM 9B achieves the highest overall accuracy at 95.9%, followed by Google Translate at 93.3%
- OPUS models perform worst with 45.7% average accuracy
- Emojis are the most challenging category, with near-zero accuracy for models without byte-level tokenization
- Model size positively correlates with transfer accuracy (EuroLLM 9B outperforms 1.7B version by 6+ percentage points)
- Prompt engineering improves EuroLLM accuracy by 1-6 percentage points
- No correlation between sentence length and transfer accuracy; longer entities increase error likelihood in some models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-grained tokenization improves entity transfer accuracy by enabling better pattern recognition at the sub-character level.
- Mechanism: Models that tokenize entities into smaller subtokens (e.g., individual digits/characters) can learn generalizable patterns for entity structure, whereas coarse tokenizers must memorize specific token combinations.
- Core assumption: The relationship between tokenization granularity and accuracy is causal, not merely correlational with other architectural differences.
- Evidence anchors:
  - [section 6]: EuroLLM tokenizes an ISBN number into 30 tokens while OPUS generates only 12 tokens
  - [section 6]: Spearman's correlation between accuracy and average entity subtoken count is rs = 0.3929 (non-significant, p = 0.395)
  - [corpus]: Weak direct evidence—corpus neighbors focus on distillation and augmentation, not tokenization strategies
- Break condition: If a model with coarse tokenization but substantially more parameters matches fine-grained tokenizer performance, the mechanism may be scale-driven rather than tokenization-driven.

### Mechanism 2
- Claim: Model scale positively correlates with entity preservation, likely through improved contextual understanding and pattern generalization.
- Mechanism: Larger models have greater capacity to learn implicit entity boundary detection and copy operations from training data containing diverse entity types.
- Core assumption: Scale provides capacity for entity-specific learning rather than emergent behavior from general language competence.
- Evidence anchors:
  - [abstract]: "model size positively correlates with transfer accuracy"
  - [section 6]: "EuroLLM 9B beats the 1.7B version in the case of every category, with the average accuracy more than 6 percentage points higher"
  - [corpus]: Corpus evidence is weak—no direct studies on scale vs. entity preservation were found among neighbors
- Break condition: If smaller models with explicit entity-copying mechanisms outperform larger baselines, scale is not the primary driver.

### Mechanism 3
- Claim: Byte-level or character-level tokenization is necessary for emoji preservation; vocabulary-based tokenizers fail catastrophically.
- Mechanism: Emojis exist outside standard vocabularies; without byte-level fallback, models cannot represent them and either omit or substitute.
- Core assumption: The near-zero accuracy on emojis for specific models is due to tokenizer limitations rather than training data sparsity.
- Evidence anchors:
  - [section 6]: "The low scores for emojis are due to the lack of model's support for byte-level tokenization"
  - [Table 2]: OPUS (0.02%), MBART (2.1%), SeamlessM4T (0.67%), NLLB (5.3%), M2M100 (4.18%) emoji accuracy vs. EuroLLM 9B (96.78%) and Google Translate (98.59%)
  - [corpus]: No direct corpus evidence on byte-level tokenization and emoji handling
- Break condition: If retraining vocabulary-based models with augmented emoji data improves performance, training data—not tokenization—may be the bottleneck.

## Foundational Learning

- Concept: **Subword tokenization (BPE/SentencePiece)**
  - Why needed here: Understanding why models split entities differently requires knowing how byte-pair encoding builds vocabularies and handles out-of-vocabulary sequences
  - Quick check question: Given the vocabulary ["th", "e", "is", "book"], how would "thisbook" be tokenized?

- Concept: **Levenshtein distance**
  - Why needed here: The paper uses edit distance to quantify entity corruption severity; understanding this metric is essential for interpreting error distributions
  - Quick check question: What is the Levenshtein distance between "@john_doe" and "@john-do"?

- Concept: **Copy mechanisms in sequence-to-sequence models**
  - Why needed here: Entity preservation implicitly relies on copying; understanding attention-based copy operations helps diagnose why models modify entities
  - Quick check question: In a transformer decoder, what attention pattern would indicate copying a source token verbatim?

## Architecture Onboarding

- Component map: Tokenizer layer -> Encoder -> Decoder cross-attention -> Output projection

- Critical path: Source entity → tokenizer splitting → encoder representation → cross-attention alignment → decoder generation → output tokenization. Errors can compound at tokenization (emojis), attention (omissions), or generation (partial translations).

- Design tradeoffs:
  - Fine-grained tokenization improves entity handling but increases sequence length and compute
  - Larger models improve accuracy but require more inference resources
  - Explicit prompt engineering (focused prompts) adds inference overhead but improves accuracy by 1-6 percentage points per Table 5

- Failure signatures:
  - **Omission**: Entity absent in output (most common for emojis in non-byte-level models; 85.84% of mBART no-match errors are emoji-related)
  - **Partial translation**: Entity components translated (e.g., "@klimatyzacja" → "@airconditioning" in Table 10)
  - **Character modification**: Minor edits (IBAN/social handlers most common for Lev=1 errors per Table 6)
  - **Truncation**: Long entities cut off (correlation 0.61-0.82 between entity length and error likelihood for OPUS/mBART per Table 7)

- First 3 experiments:
  1. **Tokenizer audit**: Pass 100 entities per category through each candidate model's tokenizer; measure average subtoken count and flag any that produce UNK tokens or single-token compression of long entities
  2. **Category stratification test**: Translate held-out sentences per category; compute per-category accuracy and Levenshtein distribution to identify systematic failures before deployment
  3. **Prompt ablation**: Compare generic vs. entity-focused prompts on a 500-sentence sample; quantify accuracy gain vs. token overhead to determine if prompt engineering is cost-effective for your latency budget

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent do language-specific formatting variations (e.g., date formats like DD/MM/YYYY vs. MM/DD/YYYY) impact entity transfer accuracy compared to the strictly non-modifiable entities analyzed?
- Basis in paper: [explicit] The authors explicitly exclude dates and numbers from the dataset because "their formats may vary depending on the language," leaving this category unexplored (Section 3)
- Why unresolved: The study restricted its scope to entities requiring exact character-for-character copies, ignoring entities that require structural transformation rather than direct transfer
- What evidence would resolve it: An evaluation of model performance on a dataset containing dates, currencies, and measurements where the "correct" target involves format conversion rather than direct copying

### Open Question 2
- Question: Does the explicit inclusion of byte-level tokenization causally improve the transfer accuracy of complex entities like emojis and social handles across different model architectures?
- Basis in paper: [inferred] The authors attribute low emoji scores in models like OPUS and NLLB to the "lack of model's support for byte-level tokenization" (Section 6), but they do not isolate this variable
- Why unresolved: The study compares heterogeneous models (different sizes, training data, and architectures), making it impossible to isolate tokenizer type as the definitive cause of failure
- What evidence would resolve it: An ablation study comparing the same model architecture trained with and without byte-level fallback tokenization on the specific emoji and URL categories

### Open Question 3
- Question: Do the high error rates for social handles and alphanumeric sequences in synthetic sentences persist in natural text where entities may be semantically ambiguous or code-mixed?
- Basis in paper: [inferred] The dataset is generated synthetically by an LLM (Section 3.1), and the authors note in Appendix C that the "test set is synthetic," limiting generalization to real-world noise
- Why unresolved: Synthetic sentences typically feature clear grammatical structures and distinct entity placement, potentially overestimating model performance compared to messy, real-world data
- What evidence would resolve it: A comparative evaluation using naturally occurring text (e.g., social media posts) containing the same entity categories to verify if the transfer accuracy holds

## Limitations

- Dataset Representativeness: The synthetic dataset may not fully capture real-world text diversity and complexity, potentially limiting external validity
- Tokenizer Granularity and Scale Conflation: The study cannot definitively separate tokenization granularity effects from model scale effects due to weak statistical correlation (rs = 0.3929, p = 0.395)
- Model-Specific Implementation Details: Critical implementation details for all models (model identifiers, library versions, inference hyperparameters) are not fully specified, potentially impacting reproducibility

## Confidence

- **High Confidence**: EuroLLM 9B and Google Translate outperform other models in entity transfer accuracy; correlation between entity length and error likelihood for specific models
- **Medium Confidence**: Model size positively correlates with transfer accuracy, though causation is not definitively proven
- **Low Confidence**: Byte-level tokenization is the sole reason for poor emoji handling in vocabulary-based models (training data sparsity not ruled out)

## Next Checks

1. **Controlled Tokenizer Experiment**: Conduct a controlled experiment where a single NMT model architecture is paired with multiple tokenizers of varying granularity to isolate tokenization effects from model scale and architecture

2. **Real-World Dataset Validation**: Replicate the evaluation on a dataset of real-world sentences containing entities from sources like web crawls, social media, or technical documentation to test external validity

3. **Prompt Engineering Cost-Benefit Analysis**: Systematically vary prompt length and specificity across a larger set of sentences to quantify the accuracy gain per additional token and determine optimal tradeoff between entity preservation and inference cost