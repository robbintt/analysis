---
ver: rpa2
title: Predicting Clinical Outcomes with Waveform LSTMs
arxiv_id: '2503.10925'
source_url: https://arxiv.org/abs/2503.10925
tags:
- data
- mortality
- clinical
- waveform
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated the potential of leveraging clinical waveform
  data to improve prediction accuracy on the benchmark task of in-hospital mortality
  risk in the ICU. The authors combined features derived from high-frequency waveform
  data with traditional clinical features and applied logistic regression, a standard
  LSTM, and a channel-wise LSTM to predict in-hospital mortality.
---

# Predicting Clinical Outcomes with Waveform LSTMs

## Quick Facts
- **arXiv ID:** 2503.10925
- **Source URL:** https://arxiv.org/abs/2503.10925
- **Reference count:** 28
- **Primary result:** Waveform features improve ICU mortality prediction with 4.09% ROC-AUC gain for LSTM models

## Executive Summary
This study evaluated leveraging high-frequency waveform data to improve in-hospital mortality prediction in ICU patients. The authors combined traditional clinical features with features extracted from heart rate waveforms and applied logistic regression and LSTM models. Results showed that incorporating waveform features improved prediction accuracy, with LSTM models achieving a 4.09% relative improvement in ROC-AUC over baselines. The work demonstrates that waveform data captures temporal physiological dynamics that discrete clinical features miss, particularly benefiting deep learning models that can model sequential dependencies.

## Method Summary
The methodology used MIMIC-III clinical database and waveform matched subset to predict in-hospital mortality. Heart rate signals were preprocessed with smoothing and anti-aliasing filters, then upsampled to 1Hz. Twelve statistical and signal-based features were extracted from each patient's ECG data. Three models were trained: logistic regression, standard LSTM, and channel-wise LSTM. The LSTM models merged sequential clinical data with waveform features through a dense layer. Class imbalance (7:3 alive-to-deceased ratio) was addressed using Adaptive Semi-Unsupervised Weighted Oversampling (ASUWO). Performance was evaluated using ROC-AUC and AUC-PR metrics.

## Key Results
- Logistic regression with waveform features achieved ROC-AUC of 0.849, a 0.12% relative improvement over baseline
- Standard LSTM with waveform features achieved ROC-AUC of 0.899, a 4.09% relative improvement
- Standard LSTM showed substantial 31.75% improvement on AUC-PR metric
- Channel-wise LSTM architecture did not outperform standard LSTM on ROC-AUC

## Why This Works (Mechanism)

### Mechanism 1
High-frequency waveform data captures temporal physiological dynamics that discrete clinical features miss. Heart rate signals provide granular information about physiological state evolution within the first 48 hours of ICU admission. Statistical features (min, max, range, skewness, kurtosis, standard deviation, variance, mode) and signal-based features (averaged power, power spectral density) condense this temporal information into discriminative representations. Core assumption: Heart rate variability and distribution characteristics contain prognostic signal for mortality risk that supplements traditional clinical variables.

### Mechanism 2
LSTMs benefit more from waveform features than logistic regression because they can model sequential dependencies. The standard LSTM processes time-series clinical data while receiving condensed waveform features through a dense hidden layer. This architecture allows the model to learn interactions between temporal clinical patterns and waveform-derived representations jointly through a final dense layer. Core assumption: Waveform features contain sequential or interaction patterns with clinical time-series that require non-linear modeling to exploit.

### Mechanism 3
Addressing class imbalance through resampling improves model calibration on the minority (deceased) class. The dataset has a 7:3 ratio of alive to deceased patients. The authors applied Adaptive Semi-Unsupervised Weighted Oversampling (ASUWO) to balance the dataset, which may particularly benefit precision-recall performance. Core assumption: The original class distribution leads to models that underpredict mortality risk; resampling restores discriminative ability for the minority class.

## Foundational Learning

- **Power Spectral Density (PSD) and frequency-domain features**: Why needed here: Signal-based features like PSD are computed from heart rate signals to capture energy distribution across frequencies, which may reflect autonomic nervous system function. Quick check question: Can you explain why PSD might capture different information than time-domain statistics like mean or variance?

- **Class imbalance handling in binary classification**: Why needed here: With a 7:3 alive-to-deceased ratio, models may optimize for majority class accuracy; understanding oversampling vs. loss weighting is critical. Quick check question: What is the difference between oversampling the minority class and using class-weighted loss?

- **LSTM architectures for multimodal time-series fusion**: Why needed here: The architecture merges sequential clinical data with static waveform-derived features; understanding where and how to fuse modalities affects model capacity. Quick check question: Why might fusing modalities at a late layer (after LSTM processing) vs. early concatenation lead to different learned representations?

## Architecture Onboarding

- **Component map**: Data ingestion -> Signal preprocessing -> Feature extraction -> Class balancing -> Model branches (LSTM + Dense) -> Fusion -> Final prediction
- **Critical path**: Waveform preprocessing → feature extraction → oversampling → multimodal fusion training. Errors in signal preprocessing (e.g., incorrect upsampling) propagate through all downstream steps.
- **Design tradeoffs**: Feature engineering vs. end-to-end learning: Authors chose to condense waveforms into 12 features rather than feed raw signals, trading temporal resolution for computational tractability. Single waveform vs. multi-channel: Focusing on ECG (13.2% patient coverage) limits generalizability but simplifies initial development.
- **Failure signatures**: ROC-AUC improves but AUC-PR stagnates: Model may be better at ranking but not calibrated for the minority class. Channel-wise LSTM underperforms standard LSTM on ROC-AUC: Architectural complexity may not match data structure. Large gap between training and validation performance: Potential overfitting to oversampled minority class.
- **First 3 experiments**:
  1. Baseline replication: Reproduce Harutyunyan et al. logistic regression and LSTM baselines on clinical features only to establish reference metrics.
  2. Ablation on waveform features: Train models with subsets of the 12 features to identify which (statistical vs. signal-based) contribute most to gains.
  3. Temporal segmentation test: Extract features from multiple time windows (e.g., hours 0-24, 24-48) rather than aggregate 48-hour window to test whether temporal granularity improves prediction.

## Open Questions the Paper Calls Out

### Open Question 1
Does extracting statistical features from segmented time windows preserve temporal information and improve performance over aggregate whole-series extraction? The authors state that extracting features from the ECG time series "as a whole" loses the "temporal nature" and suggest calculating features on "multiple segmentations" as a natural extension. This remains unresolved because the current methodology flattens the time series into a single set of statistical features for the entire 48-hour window, discarding the chronological evolution of the patient's condition. A comparative study evaluating model performance when features are extracted from sliding windows versus the current aggregate approach would resolve this question.

### Open Question 2
Can applying this methodology to additional waveform channels increase patient coverage while maintaining or improving prediction accuracy? The study was limited to ECG signals (covering 13.2% of patients) and explicitly proposes "applying this methodology to additional waveform channels" to improve coverage and performance. This remains unresolved because the reliance on a single waveform type restricts the model's applicability to the small subset of the MIMIC-III database with high-quality ECG records. Experiments integrating other available waveforms, such as arterial blood pressure or photoplethysmogram, for patients missing ECG data would resolve this question.

### Open Question 3
Can the performance gains observed in this specific dataset be replicated in a general ICU population not dominated by cardiovascular diseases? The paper notes that nearly 90% of the "Matched Subset" used for analysis suffers from cardiovascular diseases and are in the Coronary Care Unit (CCU). The authors assume results can be extended to the whole database based on age distribution, but do not validate performance on non-cardiac patients. This remains unresolved because the high predictive power of heart rate features may be specific to the cardiac nature of the conditions in the dataset, potentially limiting generalizability to other ICU populations. Evaluating the model's discrimination (ROC-AUC) specifically on a test set of non-cardiac ICU patients would resolve this question.

## Limitations

- Only 13.2% of patients had ECG waveform data, limiting generalizability
- Waveform feature extraction reduces rich temporal signals to static summaries, potentially losing predictive information
- Channel-wise LSTM architecture showed no benefit over standard LSTM, raising questions about architectural assumptions

## Confidence

- **High**: LSTM models improve prediction over baseline logistic regression when using waveform features
- **Medium**: Statistical and signal-based features from heart rate signals capture clinically relevant information
- **Medium**: Class imbalance handling through ASUWO improves precision-recall performance

## Next Checks

1. **Feature importance analysis**: Conduct ablation studies to identify which of the 12 waveform features contribute most to model performance, distinguishing between statistical and signal-based features
2. **Temporal granularity test**: Compare performance when extracting features from multiple time windows (0-24h, 24-48h) versus aggregated 48-hour window to assess whether temporal resolution matters
3. **End-to-end comparison**: Implement a baseline model that processes raw waveform signals directly through temporal models (CNN-LSTM or attention-based architectures) to quantify information loss from feature engineering