---
ver: rpa2
title: Enhanced Generative Machine Listener
arxiv_id: '2509.21463'
source_url: https://arxiv.org/abs/2509.21463
tags:
- audio
- quality
- proposed
- mushra
- gmlv2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GMLv2, a reference-based audio quality metric
  that uses a Beta distribution-based loss to predict MUSHRA scores, addressing the
  need for accurate and scalable perceptual audio quality assessment. By replacing
  the Gaussian loss of GMLv1 with a Beta distribution, GMLv2 naturally models bounded
  MUSHRA scores and captures perceptual uncertainty, enabling better generalization
  across diverse audio content and codecs, including neural audio codecs (NACs).
---

# Enhanced Generative Machine Listener

## Quick Facts
- **arXiv ID**: 2509.21463
- **Source URL**: https://arxiv.org/abs/2509.21463
- **Authors**: Vishnu Raj; Gouthaman KV; Shiv Gehlot; Lars Villemoes; Arijit Biswas
- **Reference count**: 0
- **Primary result**: GMLv2 achieves Rp > 0.92 and Rs > 0.92 on eight test sets, outperforming PEAQ and ViSQOL

## Executive Summary
This paper introduces GMLv2, a reference-based audio quality metric that uses a Beta distribution-based loss to predict MUSHRA scores, addressing the need for accurate and scalable perceptual audio quality assessment. By replacing the Gaussian loss of GMLv1 with a Beta distribution, GMLv2 naturally models bounded MUSHRA scores and captures perceptual uncertainty, enabling better generalization across diverse audio content and codecs, including neural audio codecs (NACs). The model employs a Gammatone filterbank for feature extraction and a modified Inception-based architecture. Evaluated against PEAQ and ViSQOL, GMLv2 consistently achieves higher Pearson and Spearman correlations (Rp > 0.92) and lower outlier ratios across eight test sets, demonstrating superior robustness and accuracy in predicting human perceptual ratings.

## Method Summary
GMLv2 uses Gammatone spectrograms (80ms window, 20ms hop, 32 channels, 50Hz lowest frequency) to extract features from both reference and degraded audio signals. The model processes these features through a modified Inception-based backbone and outputs Beta distribution parameters (α, β) to model the bounded MUSHRA score range [0,100]. The Beta negative log-likelihood loss encourages predictions to match the true MUSHRA score distribution while maintaining unimodal outputs through softplus+1 constraints. The model is trained on 82,191 audio pairs from Dolby internal tests using traditional codecs (AAC, HE-AAC, AC-4) and neural audio codecs (Encodec, DAC, MDCTNet). Performance is evaluated using Pearson correlation (Rp), Spearman correlation (Rs), and Outlier Ratio (OR) at 95% confidence interval.

## Key Results
- GMLv2 achieves Rp > 0.92 and Rs > 0.92 across eight test sets, exceeding the 0.92 correlation threshold
- Outlier Ratio (OR) remains below 0.1 across all test sets, indicating high prediction accuracy
- GMLv2 outperforms PEAQ and ViSQOL on unseen test sets, demonstrating superior generalization to diverse audio content and codecs
- The Beta distribution loss improves robustness compared to GMLv1's Gaussian loss, particularly for NACs and high-fidelity audio

## Why This Works (Mechanism)
The Beta distribution is ideal for modeling MUSHRA scores because it naturally captures the bounded nature of perceptual ratings (0-100) and represents listener uncertainty. Unlike Gaussian distributions, Beta distributions can model skewed distributions and maintain unimodality when constrained properly (α>1, β>1). This allows GMLv2 to better represent the variability in human judgments while preventing degenerate bimodal predictions that can occur with unconstrained outputs.

## Foundational Learning
- **Gammatone filterbanks**: Auditory-inspired feature extraction that mimics human cochlear processing. Why needed: Captures perceptually relevant audio features. Quick check: Verify filterbank response matches human hearing sensitivity curves.
- **Beta distribution**: Probability distribution bounded in [0,1] that can model uncertainty. Why needed: Naturally represents MUSHRA score distribution. Quick check: Confirm α,β > 1 ensures unimodal output.
- **Inception architecture**: CNN variant with parallel convolutional layers of different sizes. Why needed: Extracts multi-scale temporal features. Quick check: Verify receptive fields capture relevant audio patterns.
- **Negative log-likelihood loss**: Training objective that maximizes likelihood of correct predictions. Why needed: Properly handles probabilistic outputs. Quick check: Monitor loss convergence during training.
- **Pearson/Spearman correlations**: Statistical measures of linear/monotonic relationships. Why needed: Quantify model accuracy vs human ratings. Quick check: Compute correlations on validation set.
- **Outlier Ratio**: Percentage of predictions outside confidence interval. Why needed: Measures prediction reliability. Quick check: Track OR during validation.

## Architecture Onboarding

**Component map**: Audio signals -> Gammatone filterbank -> Spectrogram preprocessing -> Inception backbone -> Beta parameters (α,β) -> MUSHRA prediction

**Critical path**: The feature extraction and Beta distribution modeling are critical. Gammatone filterbanks must produce consistent spectrograms, and Beta parameters must maintain α,β > 1 to ensure proper distribution.

**Design tradeoffs**: Beta loss provides better modeling of bounded scores but adds complexity over Gaussian loss. The Inception architecture offers multi-scale feature extraction but increases parameter count. Gammatone features capture perceptual relevance but require careful parameter tuning.

**Failure signatures**: 
- α or β values ≤1 cause improper Beta distributions
- Low correlations indicate feature extraction or model capacity issues
- High Outlier Ratio suggests poor generalization to certain audio types

**First experiments**:
1. Verify Gammatone filterbank produces correct spectrogram dimensions (6 channels × 32 frequency bands)
2. Train on small synthetic dataset to validate Beta parameter constraints and loss implementation
3. Test correlation metrics on held-out validation set before full training

## Open Questions the Paper Calls Out
None

## Limitations
- Proprietary training data (82,191 pairs) from Dolby internal tests unavailable for independent verification
- Exact Inception architecture configuration not fully specified in paper
- No ablation study isolating Beta loss contribution from other architectural changes
- Claims of superiority over GMLv1 cannot be independently verified without access to the original model

## Confidence
- **High confidence**: GMLv2 architecture and Beta loss implementation are clearly specified and reproducible
- **Medium confidence**: Performance claims are methodologically sound but rely on inaccessible proprietary data
- **Low confidence**: Claims of superiority over GMLv1 cannot be independently verified without the original model

## Next Checks
1. Reconstruct the Inception architecture from [15,12] citations and verify input/output dimensions match the paper's specifications
2. Train a GMLv1 baseline using the Gaussian loss (σ-based) with identical data augmentation to isolate Beta loss effects
3. Test GMLv2 on publicly available MUSHRA datasets (e.g., LIVE Audio) to assess generalization beyond the original test sets