---
ver: rpa2
title: Attribution analysis of legal language as used by LLM
arxiv_id: '2501.17330'
source_url: https://arxiv.org/abs/2501.17330
tags:
- legal
- attribution
- figure
- examples
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper investigates how different large language models (LLMs)
  perform on legal text classification tasks and uses attribution methods to understand
  their behavior. Three models are compared: BERT (generic), legalBERT (fine-tuned
  on legal texts), and customLegalBERT (trained from scratch on legal texts).'
---

# Attribution analysis of legal language as used by LLM

## Quick Facts
- arXiv ID: 2501.17330
- Source URL: https://arxiv.org/abs/2501.17330
- Authors: Richard K. Belew
- Reference count: 24
- Key outcome: Attribution methods reveal model performance differences are largely influenced by tokenizer behavior and exposure to legal corpora

## Executive Summary
This paper investigates how different large language models (LLMs) perform on legal text classification tasks using attribution analysis to understand their behavior. Three models are compared: BERT (generic), legalBERT (fine-tuned on legal texts), and customLegalBERT (trained from scratch on legal texts). The study uses two datasets - overrule (binary classification) and casehold (multiple choice) - to evaluate model performance and token importance. Attribution methods reveal significant differences in how models handle legal-specific tokens, with tokenizer behavior and exposure to legal corpora playing crucial roles in performance.

## Method Summary
The study employs attribution analysis techniques to examine how different LLMs process legal text. Three models (BERT, legalBERT, customLegalBERT) are tested on two legal classification tasks using standard evaluation metrics. Attribution scores are calculated to determine token importance and identify patterns in model behavior. The analysis focuses on understanding how model architecture and training data influence performance on legal language tasks, particularly examining the role of legal-specific tokens and tokenizer behavior.

## Key Results
- All models perform well on the overrule binary classification task, but attribution scores vary significantly
- For the casehold multiple choice task, models show more distinct differences in performance and attribution patterns
- Attribution analysis reveals that tokenizer behavior and exposure to legal corpora are key factors in model performance differences

## Why This Works (Mechanism)
The attribution analysis works by examining how models assign importance to different tokens in legal text, revealing that performance differences stem from how models handle legal-specific terminology and tokenization patterns. The mechanism relies on comparing attribution scores across different model architectures and training approaches to identify which aspects of legal language processing are most influential.

## Foundational Learning
- Tokenization and its impact on model performance: why needed - legal language contains domain-specific terms requiring special handling; quick check - compare attribution scores for legal vs. generic tokens
- Attribution methods in NLP: why needed - to understand model decision-making; quick check - validate attribution scores correlate with known linguistic features
- Legal language characteristics: why needed - to identify domain-specific patterns; quick check - analyze frequency of legal-specific tokens in attribution analysis

## Architecture Onboarding
- Component map: Data -> Tokenizer -> Model Architecture -> Attribution Analysis -> Performance Evaluation
- Critical path: Training data selection -> Model architecture choice -> Token attribution analysis -> Performance comparison
- Design tradeoffs: Generic vs. domain-specific training data, model complexity vs. interpretability
- Failure signatures: Poor attribution analysis may mask model weaknesses, over-reliance on tokenizer behavior
- First experiments: 1) Compare attribution scores for legal vs. generic tokens, 2) Analyze performance differences between models on legal-specific vs. generic tasks, 3) Test attribution analysis sensitivity to different legal corpora

## Open Questions the Paper Calls Out
None

## Limitations
- The study relies on publicly available datasets which may not fully represent legal language diversity
- Attribution methods cannot definitively establish causal relationships between token importance and model decisions
- Comparison between models with different training corpora introduces confounding factors

## Confidence
- Model performance differences based on tokenizer behavior: Medium confidence
- Legal corpus exposure impact: Medium confidence
- Connection to known legal language features: Low confidence

## Next Checks
1. Conduct ablation studies removing legal-specific tokens to isolate their impact on model performance and attribution patterns
2. Test models on additional legal datasets with varying levels of domain specificity to validate generalizability of findings
3. Implement controlled experiments comparing models with identical architectures but different training corpus sizes and compositions