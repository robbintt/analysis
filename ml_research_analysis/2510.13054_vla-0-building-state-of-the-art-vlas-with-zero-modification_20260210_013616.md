---
ver: rpa2
title: 'VLA-0: Building State-of-the-Art VLAs with Zero Modification'
arxiv_id: '2510.13054'
source_url: https://arxiv.org/abs/2510.13054
tags:
- action
- vla-0
- arxiv
- vlas
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "VLA-0 demonstrates that a simple VLA design, which represents\
  \ actions directly as text without modifying the VLM architecture, can achieve state-of-the-art\
  \ performance. On the LIBERO benchmark, VLA-0 outperforms all existing methods trained\
  \ on the same robotic data, including \u03C00.5-KI, OpenVLA-OFT, and SmolVLA, achieving\
  \ a 94.7% average success rate."
---

# VLA-0: Building State-of-the-Art VLAs with Zero Modification

## Quick Facts
- **arXiv ID:** 2510.13054
- **Source URL:** https://arxiv.org/abs/2510.13054
- **Reference count:** 25
- **Primary result:** VLA-0 achieves 94.7% average success rate on LIBERO benchmark, outperforming all existing methods trained on the same robotic data including π0.5-KI, OpenVLA-OFT, and SmolVLA.

## Executive Summary
VLA-0 demonstrates that a simple VLA design, which represents actions directly as text without modifying the VLM architecture, can achieve state-of-the-art performance. On the LIBERO benchmark, VLA-0 outperforms all existing methods trained on the same robotic data, including π0.5-KI, OpenVLA-OFT, and SmolVLA, achieving a 94.7% average success rate. Without large-scale robotics-specific training, it also surpasses methods trained on extensive robotic datasets, such as π0.5-KI, π0, GR00T-N1, and MolmoAct. These results translate to real-world tasks, where VLA-0 outperforms SmolVLA, a model pre-trained on large-scale real data, by 12.5 percentage points.

## Method Summary
VLA-0 converts a VLM into a VLA by prompting it to predict robot actions as space-separated integers, without modifying the VLM architecture or vocabulary. The method involves normalizing continuous actions to integers in [0, 1000], formatting them as space-separated strings, and using masked action augmentation during training to prevent auto-completion behavior. The model is fine-tuned with cross-entropy loss on the action tokens, and inference uses action chunking with temporal ensembling to average predictions across timesteps for more stable execution.

## Key Results
- VLA-0 achieves 94.7% average success rate on LIBERO benchmark
- Without large-scale robotics-specific training, VLA-0 surpasses methods trained on extensive robotic datasets
- In real-world tasks, VLA-0 outperforms SmolVLA (pre-trained on large-scale real data) by 12.5 percentage points
- Ablation studies show temporal ensembling provides the largest gain (+2.0 points) followed by masked augmentation (+1.2 points)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representing continuous actions as space-separated integer text preserves pretrained VLM representations while enabling arbitrary action resolution.
- Mechanism: Normalizing continuous action values to a fixed integer range (e.g., [0, 1000]) and prompting the VLM to generate these as text tokens. This bypasses the resolution-vocabulary tradeoff in discrete token VLAs and avoids architectural complexity of generative action heads.
- Core assumption: The pretrained VLM has sufficient numerical reasoning capability to predict coordinate-like sequences when properly prompted and fine-tuned.
- Evidence anchors:
  - [abstract] "VLA-0 prompts the base VLM to directly predict action coordinates as space-separated integers... preserves the VLM's pretrained language understanding while enabling arbitrary action resolution."
  - [section III.B] "Notably, unlike discrete token-based VLAs, this approach allows for arbitrary resolution without altering the model's vocabulary."
- Break condition: If action resolution requirements exceed the VLM's token-level precision, performance may degrade without increased integer range.

### Mechanism 2
- Claim: Masked action augmentation during training forces the VLM to ground action predictions in visual observations rather than numerical auto-completion.
- Mechanism: During training, randomly mask characters in the target action string. This prevents the autoregressive model from learning to predict subsequent tokens primarily from preceding numerical patterns, compelling it to condition more strongly on visual input and task instruction.
- Core assumption: VLMs have a strong tendency toward text pattern completion that can override visual grounding if not explicitly disrupted.
- Evidence anchors:
  - [abstract] "masked action augmentation during training (randomly masking action text to prevent auto-completion)"
  - [section III.B] "This procedure forces the VLM to reason about the action based on the visual observation and instruction, rather than simply relying on auto-completing a numerical sequence."
  - [section V, Table II] Ablation shows -1.2 point performance drop when masking is removed.
- Break condition: If masking rate is too high, the model may fail to learn action sequence structure; if too low, auto-completion bias persists.

### Mechanism 3
- Claim: Action ensembling across temporal predictions reduces variance and improves execution stability.
- Mechanism: At each timestep t, the model predicts a sequence of n future actions. The action executed at timestep t is the average of n predictions: the current prediction, plus predictions from t-1 (second in its sequence), through t-n+1.
- Core assumption: Action predictions are noisy but unbiased; averaging reduces high-frequency jitter without systematic drift.
- Evidence anchors:
  - [abstract] "action ensembling at inference (averaging predictions from multiple timesteps)"
  - [section III.B] "We average these n predictions to produce the final, more stable action at time step t."
  - [section V, Table II] Ablation shows -2.0 point performance drop without ensembling—the largest single contributor.
- Break condition: If the task requires rapid reactive behavior, ensembling introduces temporal lag from stale predictions.

## Foundational Learning

- Concept: **Autoregressive language modeling and its completion biases**
  - Why needed here: Understanding why masked augmentation is necessary requires recognizing that LLMs/VLMs are trained to predict likely next tokens, which can cause numerical sequence auto-completion independent of visual context.
  - Quick check question: Given the sequence "4 12 98 3", what would a language model predict next without visual input, and why is this problematic for robot control?

- Concept: **Action chunking / temporal action prediction**
  - Why needed here: VLA-0 predicts H timesteps of actions simultaneously, and ensembling requires understanding how overlapping predictions from different timesteps are combined.
  - Quick check question: If a model predicts 16 timesteps of actions at each inference, how many predictions are available for the action at timestep t=10?

- Concept: **VLM fine-tuning vs. architecture modification**
  - Why needed here: The paper's central claim depends on understanding the distinction between fine-tuning an existing VLM (VLA-0) versus adding action heads, custom tokens, or architectural components.
  - Quick check question: What are the tradeoffs between repurposing existing vocabulary tokens for actions versus adding new tokens to the vocabulary?

## Architecture Onboarding

- Component map: Base VLM -> Action normalization layer -> Training augmentation -> Inference ensemble
- Critical path:
  1. Dataset preparation: Normalize all actions to integer range, format as space-separated strings
  2. Fine-tuning: Full fine-tuning of base VLM with cross-entropy loss on action tokens, applying masked augmentation
  3. Inference: Generate action sequences, ensemble with buffered predictions, denormalize to continuous space

- Design tradeoffs:
  - **Resolution vs. token budget**: Higher integer ranges (e.g., 4000) increase precision but require more tokens; paper finds 1000 sufficient for LIBERO
  - **Ensemble size vs. latency**: Larger n improves stability but increases memory (paper uses n=8 in simulation, n=1 in real-world due to constraints)
  - **Image tiling vs. separate inputs**: Paper finds no performance difference; choose based on implementation convenience

- Failure signatures:
  - **Auto-completion behavior**: Model generates plausible-looking but visually ungrounded numerical sequences → indicates insufficient masking or too little visual fine-tuning
  - **Jittery execution**: High variance between consecutive timesteps → ensembling not applied or ensemble size too small
  - **Out-of-range actions**: Generated integers exceed normalization bounds → check prompt formatting or increase range

- First 3 experiments:
  1. **Baseline reproduction**: Train VLA-0 on a single LIBERO task without masking or ensembling to establish the naive text-as-action baseline.
  2. **Ablation sweep**: Systematically add masked augmentation, then ensembling, measuring the delta from each (expecting ~+1.2 and ~+2.0 respectively).
  3. **Resolution sensitivity**: Test action resolution values [100, 250, 1000, 4000] on a precision-sensitive task to validate the 1000 default.

## Open Questions the Paper Calls Out

- **Open Question 1**: How would VLA-0 perform when trained with large-scale action data, compared to models like π0 and GR00T-N1 that benefit from such pretraining?
  - Basis in paper: [explicit] The conclusion states: "A key area to explore is how VLA-0 would perform when trained with large-scale action data."
  - Why unresolved: The authors deliberately focused on in-domain training only, leaving large-scale pretraining unexplored.
  - What evidence would resolve it: Train VLA-0 on large-scale robotic datasets (e.g., Droid, RT-X) and benchmark against pretrained baselines.

- **Open Question 2**: Can inference speed be improved through quantization and distillation while maintaining VLA-0's performance advantages?
  - Basis in paper: [explicit] The conclusion states: "Another area of investigation would be to improve inference speed of VLA-0 using optimization techniques like quantization and distillation."
  - Why unresolved: Current 4 Hz inference on a 5090 GPU may be insufficient for high-frequency control loops; optimization techniques were not explored.
  - What evidence would resolve it: Apply INT8/INT4 quantization or knowledge distillation and measure speed-accuracy tradeoffs.

- **Open Question 3**: Does the text-as-action approach scale effectively to larger VLM backbones (7B+ parameters), and does scaling yield diminishing returns?
  - Basis in paper: [inferred] The paper only evaluates Qwen-VL-2.5-3B, leaving unclear whether larger models would amplify or diminish the benefits of the simple formulation.
  - Why unresolved: The relationship between model scale and text-based action prediction quality remains uncharacterized.
  - What evidence would resolve it: Train VLA-0 variants with 7B and 70B backbones on identical data and compare performance.

## Limitations

- Evaluation scope is primarily constrained to a single benchmark (LIBERO) and limited set of real-world tasks (7 tasks from SO-100 dataset)
- Real-world experiments lack statistical power with only 50 episodes per task and no variance measures
- Action representation mechanism has resolution limitations with the 1000 normalization range lacking theoretical grounding for higher precision needs

## Confidence

- **High Confidence**: VLA-0 achieves state-of-the-art performance on LIBERO benchmark when trained on the same data; the action representation mechanism works as described; temporal ensembling improves performance
- **Medium Confidence**: VLA-0 outperforms models trained on extensive robotics data without large-scale training; masked action augmentation is necessary for grounding; the approach generalizes to real-world tasks
- **Low Confidence**: Claims about "simplicity being sufficient" for high performance; the specific normalization range (1000) being optimal for all robotics tasks; the approach's robustness to different robot morphologies and action spaces

## Next Checks

1. **Cross-dataset generalization test**: Evaluate VLA-0 on MetaWorld or RoboCup@Home benchmarks to verify that the LIBERO performance translates to diverse manipulation tasks and different action spaces.

2. **Statistical significance verification**: Run 200+ episodes per task in real-world experiments with proper variance reporting to establish confidence intervals and determine if performance differences are statistically significant.

3. **Resolution sensitivity analysis**: Systematically test VLA-0 with different normalization ranges (100, 250, 1000, 4000) on a precision-critical task to empirically validate the 1000 default and identify failure modes when higher resolution is required.