---
ver: rpa2
title: 'Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM
  Evaluators'
arxiv_id: '2509.03647'
source_url: https://arxiv.org/abs/2509.03647
tags:
- self-preference
- steering
- arxiv
- bias
- summary
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates self-preference bias in large language models
  used as evaluators, where models tend to favor their own outputs over those of others.
  The authors introduce a dataset that distinguishes between illegitimate self-preference
  (bias), legitimate self-preference (correct preference), and unbiased agreement
  using ensemble "gold" judges.
---

# Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators

## Quick Facts
- arXiv ID: 2509.03647
- Source URL: https://arxiv.org/abs/2509.03647
- Reference count: 20
- The paper introduces steering vectors that reduce illegitimate self-preference by up to 97% without retraining.

## Executive Summary
This paper investigates self-preference bias in large language models used as evaluators, where models tend to favor their own outputs over those of others. The authors introduce a dataset that distinguishes between illegitimate self-preference (bias), legitimate self-preference (correct preference), and unbiased agreement using ensemble "gold" judges. They construct steering vectors using two methods: Contrastive Activation Addition (CAA) and an optimization-based approach. These vectors are applied at inference time to mitigate self-preference bias without retraining. The results show that steering vectors can reduce illegitimate self-preference by up to 97%, significantly outperforming prompting and Direct Preference Optimization (DPO) baselines. However, the vectors show instability in preserving legitimate self-preference and unbiased agreement, suggesting that self-preference may be represented non-linearly or with multiple directions in activation space.

## Method Summary
The method constructs steering vectors to mitigate self-preference bias in LLM evaluators through two approaches: Contrastive Activation Addition (CAA) and optimization-based learning. Using the XSUM dataset with 1,000 articles, summaries are generated by Llama-3.1-8B-Instruct (judge J) and GPT-3.5 (comparison K). Gold labels are established via ensemble voting from Phi-4, DeepSeek V3, and Claude 3.5-Sonnet. The examples are partitioned into three categories: illegitimate self-preference (J chooses self, gold prefers K), legitimate self-preference (both prefer J), and unbiased agreement (both prefer K). CAA computes steering vectors as the mean activation difference between biased and unbiased examples at layer 14, while optimization minimizes a contrastive loss over the residual stream. Vectors are applied at inference with multipliers (0.5 for CAA, 0.1 for optimization) to measure effectiveness (flip rate on illegitimate bias) and stability (flip rate on legitimate bias and agreement).

## Key Results
- Steering vectors reduced illegitimate self-preference by up to 97% compared to baselines
- CAA and optimization methods outperformed both prompting (0% effectiveness) and DPO (49% effectiveness)
- Vectors showed instability on legitimate self-preference (87-93% flip rate) and unbiased agreement, suggesting self-preference spans multiple or nonlinear directions in activation space

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Contrastive Activation Addition (CAA) isolates a self-preference direction in residual stream activations by averaging differences between biased and unbiased evaluation contexts.
- **Mechanism:** Given positive examples (unbiased completions) and negative examples (biased completions), CAA computes v_CAA = mean(h_L(p+, c+)) - mean(h_L(p-, c-)) at layer L. This vector is then added to activations during inference with a multiplier, shifting behavior toward the unbiased direction.
- **Core assumption:** Self-preference bias manifests as a consistent linear direction in activation space that can be extracted via contrastive pairs.
- **Evidence anchors:**
  - [abstract] "We construct steering vectors using two methods: Contrastive Activation Addition (CAA) and an optimization-based approach."
  - [Section 2.2.1] Defines CAA formula using activations at last 10 token positions across all layers.
  - [corpus] Limited direct corpus support for CAA specifically on self-preference; "Shifting Perspectives: Steering Vectors for Robust Bias Mitigation" applies similar steering to social biases but not self-preference specifically.
- **Break condition:** If biased and unbiased examples don't share a consistent activation difference (i.e., self-preference is represented differently across contexts), the averaged vector will be noisy or ineffective.

### Mechanism 2
- **Claim:** Optimization-based steering learns an additive vector via gradient descent that explicitly maximizes probability of the unbiased choice while minimizing probability of the biased choice.
- **Mechanism:** A contrastive loss L = -log P(Y+|X; h) - log(1 - P(Y-|X; h)) is minimized over steering vector h, where Y+ is the gold-standard completion and Y- is the model's original biased choice. This creates a stronger directional signal than CAA's implicit averaging.
- **Core assumption:** The loss landscape admits a vector that simultaneously promotes unbiased responses and suppresses biased ones without affecting unrelated behaviors.
- **Evidence anchors:**
  - [Section 2.2.2] "We optimize a vector at layers 14, 15, and 16 as those performed the best on our evaluations."
  - [Section 3] "optimization-based steering performs comparably to CAA with far fewer examples."
  - [corpus] No direct corpus validation; optimization-based steering for self-preference appears novel to this work.
- **Break condition:** If the contrastive objective conflicts with other model objectives (e.g., general reasoning), the learned vector may cause distributional collapse or degradation on legitimate evaluations.

### Mechanism 3
- **Claim:** Self-preference bias has a partially linear but incompletely captured representation, explaining high effectiveness (97% flip rate) on illegitimate bias but instability on legitimate self-preference and unbiased agreement.
- **Mechanism:** The steering vector successfully captures directions associated with unjustified self-favoritism but inadvertently affects adjacent concepts (justified self-preference, agreement behavior), suggesting these share overlapping or nonlinear subspaces.
- **Core assumption:** Illegitimate self-preference, legitimate self-preference, and unbiased agreement are not cleanly separable in activation space under current steering methods.
- **Evidence anchors:**
  - [abstract] "steering vectors are unstable on legitimate self-preference and unbiased agreement, implying self-preference spans multiple or nonlinear directions."
  - [Section 3] "CAA-constructed vectors in particular demonstrate little modulation indicated by their high flip rates in legitimate self preference and low flip rates in unbiased agreement."
  - [corpus] "Beyond the Surface: Measuring Self-Preference in LLM Judgments" confirms self-preference exists but doesn't address its activation geometry; "Are LLM Evaluators Really Narcissists?" questions whether self-preference is cleanly separable from other confounds.
- **Break condition:** If the three categories (illegitimate, legitimate, agreement) share a single linear direction with different magnitudes, then careful calibration could separate them; if they are truly nonlinear or multi-directional, single-vector approaches will remain unstable.

## Foundational Learning

- **Concept:** Residual stream and layer-wise activations in transformer models
  - **Why needed here:** Steering vectors operate by adding to residual stream activations at specific layers; understanding where information flows is essential for effective intervention.
  - **Quick check question:** If you add a vector at layer 14, which downstream computations does it affect?

- **Concept:** Contrastive representation learning
  - **Why needed here:** Both CAA and optimization methods rely on contrasting positive/negative examples to isolate behavioral directions; the quality of contrastive pairs determines steering precision.
  - **Quick check question:** What happens to your steering vector if your positive and negative examples differ in confounding attributes (e.g., length, style) beyond the target behavior?

- **Concept:** Linear vs. nonlinear feature representations in neural networks
  - **Why needed here:** The paper's central tension—high effectiveness on one category but instability on others—hinges on whether self-preference is linearly separable or requires nonlinear disentanglement.
  - **Quick check question:** If a behavior is represented across multiple directions, what happens when you steer along only one?

## Architecture Onboarding

- **Component map:**
  - Gold judge ensemble (G = {G1, G2, G3}) -> Judge model (J) -> Comparison model (K) -> Steering vector construction (CAA/optimization) -> Inference-time hook (applies vector at layer L)

- **Critical path:**
  1. Generate summaries from J and K on XSUM articles.
  2. Collect gold labels via ensemble majority vote.
  3. Partition examples into illegitimate self-preference, legitimate self-preference, unbiased agreement.
  4. Extract positive/negative pairs for steering vector construction.
  5. Train/extract steering vectors.
  6. Apply at inference and measure flip rates across three categories.

- **Design tradeoffs:**
  - CAA vs. optimization: CAA requires more examples but is simpler; optimization is data-efficient but risks overfitting to training distribution.
  - Layer selection: Earlier layers capture more general features; later layers are task-specific. Authors chose layers 14-16 empirically.
  - Multiplier calibration: Higher multipliers increase flip rates but also instability on legitimate cases.

- **Failure signatures:**
  - High flip rate on legitimate self-preference (>20%): steering vector is too aggressive or captures quality signal alongside bias.
  - Low flip rate on illegitimate self-preference (<50%): contrastive pairs are noisy, or self-preference direction is not consistently represented.
  - Positional bias interference: CAA struggled with ordering effects in pairwise setting; if flip rates vary by summary order, this is the culprit.

- **First 3 experiments:**
  1. **Reproduce bias partition:** On a 100-article subset, verify that the gold judge ensemble produces stable ground truth (inter-annotator agreement >0.8) before steering.
  2. **Layer sweep:** Apply CAA vectors at layers 8, 12, 14, 16, 20 and measure flip rates across all three categories to confirm layer 14-16 is optimal.
  3. **Multiplier calibration curve:** For optimization steering, plot flip rates (bias, agreement, legitimate self-preference) against multipliers [0.05, 0.1, 0.2, 0.3] to identify Pareto frontier where bias flip is maximized and legitimate flip is minimized.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Is the instability of steering vectors on legitimate self-preference caused by non-linear or multi-directional representations in the residual stream?
- **Basis in paper:** [explicit] The authors state that failure to preserve legitimate self-preference "implies self-preference spans multiple or nonlinear directions."
- **Why unresolved:** The study employed linear methods (CAA and optimization) which successfully reduced bias but could not isolate the specific direction of unjustified bias from valid quality preferences.
- **What evidence would resolve it:** Mechanistic interpretability analysis mapping the activation space to reveal if distinct linear directions exist for legitimate vs. illegitimate self-preference.

### Open Question 2
- **Question:** Can individual evaluations replace pairwise comparisons to effectively isolate self-preference bias without confounding ordering effects?
- **Basis in paper:** [explicit] The authors note that "ordering bias... obstructed our signal" and suggest future work "should incorporate individual rather than pairwise evaluations."
- **Why unresolved:** The pairwise setting introduced positional bias that confounded the construction of steering vectors, particularly affecting stability on legitimate preferences.
- **What evidence would resolve it:** A comparative study constructing steering vectors using single-response grading prompts versus the current pairwise setup.

### Open Question 3
- **Question:** Do self-preference steering vectors transfer effectively to non-summarization domains such as code generation?
- **Basis in paper:** [inferred] The paper focuses on XSUM (summarization) and mentions only "preliminary investigations" into other domains (Appendix E), leaving generalization uncertain.
- **Why unresolved:** The activation directions for self-preference in summarization may differ from those in logical or coding tasks (APPS dataset).
- **What evidence would resolve it:** Testing the steerability of self-preference on the APPS dataset using vectors derived from the XSUM experiments.

## Limitations
- Steering vectors show instability on legitimate self-preference and unbiased agreement, suggesting self-preference may not be cleanly separable in activation space
- The method relies on pairwise comparisons which introduce positional bias that interferes with vector construction
- Generalization beyond the XSUM summarization task to other evaluation domains remains uncertain

## Confidence
- **High confidence:** The experimental methodology for constructing and evaluating steering vectors is clearly specified and reproducible
- **Medium confidence:** The characterization of self-preference as spanning multiple or nonlinear directions in activation space is supported by empirical results but requires further theoretical grounding
- **Medium confidence:** The generalizability of findings beyond the XSUM summarization task to other evaluation scenarios remains to be established

## Next Checks
1. **Layer-wise sensitivity analysis**: Systematically test steering vectors at layers 8, 12, 14, 16, and 20 to determine if the optimal layers (14-16) generalize across different model architectures and tasks.

2. **Category boundary validation**: Conduct ablation studies where positive/negative examples are filtered to remove any overlap between legitimate and illegitimate self-preference cases, verifying whether the instability stems from contaminated training data.

3. **Multi-vector approach exploration**: Test whether combining multiple steering vectors (one per behavioral category) provides better separation between illegitimate self-preference, legitimate self-preference, and unbiased agreement than single-vector approaches.