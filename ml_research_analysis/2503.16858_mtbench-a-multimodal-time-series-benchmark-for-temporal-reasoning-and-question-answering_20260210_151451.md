---
ver: rpa2
title: 'MTBench: A Multimodal Time Series Benchmark for Temporal Reasoning and Question
  Answering'
arxiv_id: '2503.16858'
source_url: https://arxiv.org/abs/2503.16858
tags:
- data
- stock
- news
- time-series
- weather
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MTBench introduces a large-scale benchmark for evaluating large
  language models on multimodal time series reasoning across financial and weather
  domains. It provides paired time series and textual data to assess models' ability
  to jointly interpret numerical trends and contextual narratives through diverse
  tasks including forecasting, trend analysis, technical indicator prediction, and
  news-driven question answering.
---

# MTBench: A Multimodal Time Series Benchmark for Temporal Reasoning and Question Answering

## Quick Facts
- arXiv ID: 2503.16858
- Source URL: https://arxiv.org/abs/2503.16858
- Authors: Jialin Chen; Aosong Feng; Ziyu Zhao; Juan Garza; Gaukhar Nurbek; Cheng Qin; Ali Maatouk; Leandros Tassiulas; Yifeng Gao; Rex Ying
- Reference count: 40
- Primary result: Incorporates textual information improves forecasting accuracy by up to 9.78% in finance and 6.63% in weather

## Executive Summary
MTBench introduces a large-scale benchmark for evaluating large language models on multimodal time series reasoning across financial and weather domains. It provides paired time series and textual data to assess models' ability to jointly interpret numerical trends and contextual narratives through diverse tasks including forecasting, trend analysis, technical indicator prediction, and news-driven question answering. Experiments show that incorporating textual information improves forecasting accuracy by up to 9.78% in finance and 6.63% in weather, while LLMs struggle with long-term dependencies and effective multimodal fusion, particularly in short-term financial correlation prediction where significant negative correlations are present.

## Method Summary
MTBench provides a benchmark with 20,000 financial news-stock pairs (May 2021–Sept 2023) and 2,000 weather pairs from 50 US stations (2003–2020) with GHCN-H temperature data and Storm Events Database reports. The benchmark includes two settings: short-term (7-day input → 1-day output) and long-term (30-day/14-day input → 7-day/3-day output). Tasks span forecasting (MAE, MAPE, MSE), trend classification (accuracy), technical indicator prediction (MSE, MAE), and news-driven question answering (accuracy). Zero-shot evaluation is conducted on GPT-4o, Claude-Sonnet-3.5, Gemini-2.0-Flash, LLaMA 3.1-8B, DeepSeek-Chat, and OpenAI-o1 with temperature settings varying by task type (0.7 for finance, 0.5 for weather regression, 0.2 for weather classification).

## Key Results
- Incorporating textual information improves forecasting accuracy by up to 9.78% in finance and 6.63% in weather
- LLMs exhibit systematic bias toward predicting moderate positive correlation regardless of ground truth
- Long-term stock correlation prediction (30-day) is less challenging than short-term (7-day) prediction

## Why This Works (Mechanism)

### Mechanism 1: Cross-Modal Contextual Enhancement
Textual narratives provide causal context that disambiguates numerical patterns. In finance, market movements are news-driven; in weather, physical laws dominate, making text less impactful. This explains why multimodal advantage is more pronounced in stock forecasting (9.78%) than temperature prediction (6.63%).

### Mechanism 2: Sentiment-Trend Reconciliation for Directional Correction
LLMs can leverage textual sentiment to override historical numerical trends when news signals contradict past patterns. For example, positive news about a $27.6M order can counter a downward trend, shifting predictions from -4% to +2%~+4%.

### Mechanism 3: Temporal Horizon Modulates Correlation Stability
Short-term stock-news correlations are harder to predict than long-term correlations due to market noise and transient reactions. Long-term (30-day) correlations stabilize as transient noise averages out and structural factors dominate.

## Foundational Learning

- **Concept: Multimodal Alignment (Time-Series + Text)**
  - Why needed: MTBench requires joint reasoning over numerical sequences and narrative context. Misaligned pairs (20% of consistent dataset) test whether models can identify contradictory signals.
  - Quick check: Given a stock declining 10% over 7 days and positive earnings news, should the model predict continuation or reversal?

- **Concept: Technical Indicator Derivation**
  - Why needed: Tasks include predicting MACD and Bollinger Bands, which require multi-step numerical computation from forecasted sequences, not just raw value prediction.
  - Quick check: Can the model compute MACD (12-day EMA minus 26-day EMA) from a 30-day price forecast?

- **Concept: Correlation vs. Causation Disentanglement**
  - Why needed: Correlation prediction tasks explicitly test whether models can distinguish news sentiment influence from coincidental price movements.
  - Quick check: If news sentiment is positive but stock falls due to macro factors, what correlation label should be assigned?

## Architecture Onboarding

- **Component map:** Time-series encoder -> Context fusion with text -> Task-specific prediction -> Length-constrained output generation
- **Critical path:** Time-series tokenization → Context fusion with text → Task-specific prediction → Length-constrained output generation
- **Design tradeoffs:** Longer input windows (30-day) improve trend capture but increase output length inconsistency; Text integration improves accuracy but introduces noise risk (misaligned dataset); Lower temperature (0.2) improves classification consistency but may reduce reasoning diversity
- **Failure signatures:** Output length mismatch (models generate 22 instead of 24 hourly predictions); Correlation bias (systematic prediction of moderate positive correlation); Retrospective degradation (text harms past-trend classification)
- **First 3 experiments:** 1) Run GPT-4o on time-series-only forecasting for 7-day stock input to verify MAE ≈ 1.687 and output length compliance; 2) Compare TS-only vs. TS+Text on short-term stock trend classification to confirm 25-40% accuracy range; 3) Test on 7-day correlation prediction task and check confusion matrix for systematic bias toward "moderate positive" predictions

## Open Questions the Paper Calls Out

- **Open Question 1:** What specific architectural enhancements or fine-tuning strategies are required to improve the temporal reasoning and cross-modal synthesis capabilities of LLMs beyond current off-the-shelf models?
- **Open Question 2:** How does the multimodal temporal reasoning performance observed in financial and weather domains generalize to domains with different temporal dynamics, such as healthcare or social sciences?
- **Open Question 3:** How can LLMs be refined to overcome the systematic bias toward predicting "moderate positive correlation" and accurately capture significant negative correlations in short-term financial contexts?
- **Open Question 4:** What specific refinements in model training or prompting are necessary to ensure LLMs strictly adhere to output length constraints in time-series forecasting?

## Limitations

- The dataset construction process introduces uncertainties, particularly around stock price data sources and annotation pipelines
- Systematic model bias toward moderate positive correlation predictions suggests fundamental limitations in multimodal fusion capabilities
- The "misaligned" dataset contains 20% of pairs where text contradicts time-series trends, but the generation methodology for these contradictions is unclear

## Confidence

- **High Confidence:** Improvement from multimodal integration (9.78% in finance, 6.63% in weather) and superiority of long-term over short-term correlation prediction are directly measured
- **Medium Confidence:** Mechanism explaining why finance benefits more than weather from text integration relies on assumptions about news-driven versus physics-driven domains
- **Low Confidence:** Systematic negative correlation prediction failure across all models suggests either fundamental limitation or dataset artifacts

## Next Checks

1. **Correlation Label Validation:** Re-examine ground truth correlation labels for 500 samples to verify negative correlations exist and labeling methodology correctly captures news-sentiment to price relationships
2. **Model Architecture Ablation:** Test explicit multimodal fusion architectures beyond implicit LLM cross-attention to improve correlation prediction performance
3. **Temporal Effect Analysis:** Conduct finer-grained temporal analysis of news impact at multiple horizons (1-day, 3-day, 7-day, 30-day) to validate stability improvement in longer-term predictions