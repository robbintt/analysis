---
ver: rpa2
title: Data Unlearning in Diffusion Models
arxiv_id: '2503.01034'
source_url: https://arxiv.org/abs/2503.01034
tags:
- unlearning
- siss
- diffusion
- data
- conference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of data unlearning in diffusion
  models, which is the efficient removal of specific training datapoints from these
  models. The core method, called Subtracted Importance Sampled Scores (SISS), is
  a new loss function that combines the objectives of naive deletion and NegGrad,
  utilizing importance sampling for computational efficiency.
---

# Data Unlearning in Diffusion Models

## Quick Facts
- arXiv ID: 2503.01034
- Source URL: https://arxiv.org/abs/2503.01034
- Reference count: 40
- Primary result: SISS achieves Pareto-optimal unlearning on diffusion models by combining naive deletion and NegGrad objectives via importance sampling

## Executive Summary
This paper introduces Subtracted Importance Sampled Scores (SISS), a method for data unlearning in diffusion models that efficiently removes specific training datapoints while preserving model quality. The core innovation is a weighted combination of naive deletion and NegGrad objectives using importance sampling for computational efficiency. The method achieves Pareto optimality between unlearning strength and generation quality, successfully removing memorization from Stable Diffusion models on nearly 90% of tested prompts while maintaining high generation quality on image datasets.

## Method Summary
SISS addresses data unlearning in diffusion models by decomposing the naive deletion objective into competing terms for retention and forgetting, then balancing them through a weighted combination. The method uses importance sampling via a defensive mixture distribution to reduce computational cost by half while maintaining unbiased gradient estimates. A key innovation is gradient clipping that limits the NegGrad term's influence to approximately 10% of the retention term's gradient norm, preventing quality collapse. The approach is evaluated on CelebA-HQ, MNIST T-Shirt, and Stable Diffusion v1.4, demonstrating effective unlearning while preserving generation quality.

## Key Results
- On CelebA-HQ, SISS cut SSCD similarity metric by over half while maintaining high model quality (FID < 35)
- On MNIST T-Shirt, SISS increased exact likelihood by a factor of 8 compared to baselines
- On Stable Diffusion, SISS successfully mitigated memorization on nearly 90% of the prompts tested, reducing memorized sample count to 0/16 while maintaining CLIP-IQA ≥0.35

## Why This Works (Mechanism)

### Mechanism 1: Dual-Objective Loss Decomposition
SISS achieves Pareto-optimal unlearning by algebraically splitting the naive deletion objective into competing terms for preservation and forgetting. The decomposition creates inherent tension that, when balanced, prevents the quality collapse seen in pure NegGrad or the slow unlearning of pure naive deletion.

### Mechanism 2: Defensive Mixture Importance Sampling
Importance sampling via a defensive mixture distribution (qλ = (1-λ)q(·|x) + λq(·|a)) reduces forward-pass compute by half while preserving unbiased gradient estimates. The defensive mixture bounds importance weights, improving numerical stability during optimization.

### Mechanism 3: Superfactor-Weighted NegGrad with Gradient Clipping
Amplifying the NegGrad term via superfactor s while clipping its gradient norm to ~10% of the retention term's norm ensures unlearning without quality collapse. This interpolation between naive deletion and aggressive unlearning maintains descent on the retention objective while incorporating forgetting.

## Foundational Learning

- **DDPM Forward/Reverse Process**: Understanding how noisy states xt are constructed from clean data x0 via q(xt|x0) is prerequisite to manipulating the loss terms. Quick check: Given x0 and t, can you write q(xt|x0) and explain why ϵθ(xt,t) recovers noise ϵ?

- **Importance Sampling**: SISS reduces compute by sampling from qλ and reweighting. Quick check: If sampling from qλ instead of p, what condition must the importance weight satisfy for unbiased estimation?

- **Gradient Ascent for Unlearning (NegGrad)**: The NegGrad component maximizes loss on A for forgetting. Quick check: Why does gradient ascent on LA(θ) cause increasingly incoherent outputs over many steps?

## Architecture Onboarding

- Component map:
Pretrained Diffusion Model (ϵθ)
        │
        ├── Retention Set X\A (keep) ──┐
        │                              │
        └── Unlearning Set A (forget) ─┤
                                       ▼
                              Sample (x, a) pair
                                       │
                                       ▼
                          Sample mt ~ qλ(·|x,a)
                                       │
                                       ▼
                    Compute importance weights: w_keep, w_forget
                                       │
                                       ▼
                    Compute dual loss: w_keep·L_keep - s·w_forget·L_forget
                                       │
                                       ▼
                    Clip NegGrad grad norm to ~10% of retention grad
                                       │
                                       ▼
                              Adam optimizer step
                                       │
                                       ▼
                        Fine-tuned ϵθ' (unlearned)

- Critical path:
  1. Prepare datasets: retention set (X\A) and unlearning set (A)
  2. For each batch: sample (x, a) pairs uniformly
  3. Sample single noisy state mt from mixture qλ (λ=0.5 recommended)
  4. Compute importance-weighted dual loss (Eq. 8)
  5. Backpropagate, clip NegGrad component gradient norm, step optimizer
  6. Monitor FID/IS (quality) and SSCD/NLL/sampling rate (unlearning)

- Design tradeoffs:
  - λ=0.5 vs. λ=0 or λ=1: λ=0.5 balances variance but requires both terms; λ=0 or λ=1 degenerate to naive deletion or NegGrad
  - Superfactor s: Higher s accelerates unlearning but risks quality collapse; clipping to 10% gradient norm is heuristic
  - With vs. without importance sampling: SISS (No IS) requires two forward passes but avoids importance weight instability

- Failure signatures:
  - FID spikes above 100: NegGrad term dominating; reduce s or enforce stricter clipping
  - SSCD/NLL unchanged after 50+ steps: λ near 0 or unlearning set gradient vanishingly small
  - Numerical instability (NaN/Inf): Importance weights exploding at extreme timesteps

- First 3 experiments:
  1. **CelebA-HQ single-face unlearning**: Select 1 celebrity from training set, run SISS (λ=0.5, s tuned to 10% gradient norm) for 60 steps. Verify SSCD drops >0.3 while FID stays <35.
  2. **Ablation on λ**: On MNIST T-Shirt, sweep λ ∈ {0, 0.25, 0.5, 0.75, 1.0} with fixed s. Confirm λ=0 yields no NLL increase, λ=1 collapses IS, λ=0.5 is Pareto-optimal.
  3. **Stable Diffusion memorization mitigation**: Select 5 prompts from Webster (2023), create partially-memorized variants, synthetically generate X\A via k-means classification. Run SISS and verify memorized sample count drops to 0/16 while CLIP-IQA ≥0.35.

## Open Questions the Paper Calls Out

### Open Question 1
Can the manual prompt modification step be automated to allow unlearning of fully memorized concepts in text-conditional models? The current method requires manual token manipulation to generate diverse synthetic data for the retention term, preventing scaling to large sets of fully memorized prompts.

### Open Question 2
Does the SISS method maintain its Pareto optimality when applied to high-dimensional modalities other than images, such as audio or video? The paper lists analyzing data unlearning on other data modalities as a specific future direction.

### Open Question 3
How sensitive is the method to the quality of the synthetically generated dataset X \ A used for the retention term? For Stable Diffusion, the authors generated a synthetic dataset for X \ A using k-means clustering because the actual training data was unavailable, raising questions about reliance on approximation quality.

## Limitations
- Performance on conditional diffusion models beyond Stable Diffusion is unexplored, limiting generalization claims
- The gradient clipping heuristic (10% norm ratio) is empirically effective but not theoretically derived
- Reliance on synthetic datasets via k-means classification for Stable Diffusion may not reflect real-world unlearning scenarios

## Confidence

- **SISS Mechanism**: Medium confidence - Dual-objective decomposition is algebraically sound but Pareto optimality validation is limited to three datasets
- **Importance Sampling Efficiency**: Medium confidence - Theoretical guarantees exist but variance reduction benefits across timesteps need validation
- **Quality-Unlearning Trade-off**: High confidence - Extensive ablation studies demonstrate clear Pareto-optimal behavior on all tested datasets
- **Stable Diffusion Generalization**: Low confidence - Results are promising but based on synthetic data generation rather than real user prompts

## Next Checks

1. **Variance Analysis**: Systematically measure importance weight variance across timesteps (t=0 to t=T) during SISS training to validate the defensive mixture's effectiveness claims.

2. **Architecture Transfer**: Apply SISS to conditional diffusion models beyond Stable Diffusion (e.g., Imagen, DALL-E) to test generalization across architectures and conditioning mechanisms.

3. **Real-World Prompt Unlearning**: Replace synthetic k-means generated datasets with real user prompts containing sensitive content, measuring both unlearning effectiveness and generation quality on authentic data distributions.