---
ver: rpa2
title: Solving the Min-Max Multiple Traveling Salesmen Problem via Learning-Based
  Path Generation and Optimal Splitting
arxiv_id: '2508.17087'
source_url: https://arxiv.org/abs/2508.17087
tags:
- path
- problem
- splitting
- algorithm
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the Min-Max Multiple Traveling Salesmen Problem
  (m3-TSP), an NP-hard problem that aims to coordinate tours for multiple salesmen
  such that the length of the longest tour is minimized. The authors propose a novel
  two-stage framework named Generate-and-Split (GaS), which integrates reinforcement
  learning (RL) with an optimal splitting algorithm in a joint training process.
---

# Solving the Min-Max Multiple Traveling Salesmen Problem via Learning-Based Path Generation and Optimal Splitting

## Quick Facts
- **arXiv ID:** 2508.17087
- **Source URL:** https://arxiv.org/abs/2508.17087
- **Reference count:** 40
- **Primary result:** Novel two-stage framework (GaS) integrates RL with optimal splitting, outperforming learning-based baselines on m³-TSP with statistical significance (p < 0.05) and superior OOD transferability (90.7%).

## Executive Summary
This paper addresses the Min-Max Multiple Traveling Salesmen Problem (m³-TSP), an NP-hard problem that aims to coordinate tours for multiple salesmen such that the length of the longest tour is minimized. The authors propose a novel two-stage framework named Generate-and-Split (GaS), which integrates reinforcement learning (RL) with an optimal splitting algorithm in a joint training process. The key innovation is the use of an LSTM-enhanced decoder to address partial observability in the RL component. The proposed framework significantly outperforms existing learning-based approaches, achieving statistically significant performance improvements (p < 0.05) and demonstrating better transferability in 90.7% of out-of-distribution data.

## Method Summary
The GaS framework decomposes the m³-TSP into two stages: (1) a learning-based path generator that produces a single continuous tour, and (2) an optimal splitting algorithm that partitions this tour into balanced sub-tours. The path generator is trained via REINFORCE with a reward derived from the splitter's output. The framework uses an LSTM-enhanced decoder to handle partial observability, allowing the policy to condition on historical observations rather than just the current state. The splitter uses binary search with a greedy check to guarantee optimal partitioning in Euclidean space, running in O(n log ĉ/ϵ) time. The encoder uses GAT layers with separate embeddings for depot, cities, and scale, while the decoder uses 8-head attention with masking. Training employs data augmentation and Adam optimizer.

## Key Results
- The GaS framework outperforms learning-based baselines (DRL, GNN, SplitNet) with statistical significance (p < 0.05).
- Achieves superior transferability on out-of-distribution data (Rotation, Gaussian, Explosion) in 90.7% of cases.
- Demonstrates better scalability and generalization compared to classical solvers like LKH3 for moderate problem sizes.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decomposing the m³-TSP into path generation (learning-based) and path splitting (algorithmic) lowers the effective search complexity for the neural network.
- **Mechanism:** The framework isolates the navigation component (NP-complete) for the RL agent while offloading the partitioning component to a deterministic, near-linear time splitting algorithm. By guaranteeing optimal splitting for any given path in Euclidean space, the RL agent is relieved of learning partition boundaries, allowing it to focus solely on node sequencing.
- **Core assumption:** The problem space adheres to Euclidean geometry, satisfying the triangle inequality required for the "Greedy Check" (proof in Appendix A.1) to guarantee optimality.
- **Evidence anchors:**
  - [abstract] "...guarantees optimal splitting in Euclidean space for any given path."
  - [section 3.3] "...splitting algorithm that can approximate the optimal solution with an approximation ratio of 1 + ϵ... time complexity of O(n log ĉ/ϵ)."
  - [corpus] Related work (SplitNet) confirms that sequence splitting is a viable decomposition strategy for m³-TSP.
- **Break condition:** If edge weights do not satisfy the triangle inequality (e.g., non-Euclidean distances or time-dependent travel times), the "Greedy Check" may fail to guarantee optimal splitting, potentially degrading the quality of the reward signal.

### Mechanism 2
- **Claim:** An LSTM-enhanced decoder mitigates the partial observability inherent in generating a full path before knowing the split points.
- **Mechanism:** Since the agent generates a single continuous path for all salesmen without knowing where the subsequent algorithmic "split" will occur, the true state (e.g., "how many cities until the current salesman's tour is effectively full?") is hidden. The LSTM maintains a hidden state $h_t$ updated incrementally at each step, allowing the policy $\pi_\theta(a_t|s_{1:t})$ to condition on the history of observations rather than just the current snapshot.
- **Core assumption:** Assumption: The hidden state of the LSTM can effectively compress the necessary historical context (sequence of previous cities) to approximate the latent "workload balance" required for the min-max objective.
- **Evidence anchors:**
  - [abstract] "...adopt an LSTM-enhanced model architecture to address partial observability."
  - [section 3.1.1] "This situates the challenges of partial observation in the framework of RL... essential information... is not accessible."
  - [corpus] Missing specific corpus evidence for LSTM in m³-TSP decoders specifically, though standard in POMDPs.
- **Break condition:** If the path length ($n$) becomes excessive, the LSTM may suffer from vanishing gradients or failure to retain early state information, leading to sub-optimal "early" decisions that the splitter cannot fix.

### Mechanism 3
- **Claim:** Integrating the splitting algorithm into the training loop provides a dense, task-aligned reward signal that shapes the path generator toward globally balanced tours.
- **Mechanism:** Unlike two-stage methods that train components in isolation, this framework calculates the reward as the negative min-max cost of the *split* tours (Algorithm 2 output). The policy gradient (REINFORCE) uses this scalar cost to update the path generator, effectively backpropagating the "split quality" into the "generation quality."
- **Core assumption:** The optimal splitting algorithm provides a smooth enough landscape for the policy gradient to navigate; small changes in the generated path lead to meaningful changes in the min-max cost.
- **Evidence anchors:**
  - [section 3.4] Equation 4 shows the gradient objective depends on $L(z')$, the cost derived from the splitting algorithm.
  - [abstract] "...integrates reinforcement learning (RL) with an optimal splitting algorithm in a joint training process."
- **Break condition:** If the splitting algorithm's output is highly sensitive to minor path perturbations (discontinuous reward landscape), the variance of the policy gradient may become too high for stable convergence.

## Foundational Learning

- **Concept:** Partially Observable Markov Decision Process (POMDP)
  - **Why needed here:** The agent must make sequential decisions (which city to visit next) without knowing the full state (the future split points/workload distribution). Modeling this as a POMDP justifies the use of recurrent architectures (LSTM) rather than simple feed-forward networks.
  - **Quick check question:** Can the agent determine the optimal next city solely by looking at the current city and unvisited set, or does it need to remember "how far" it has traveled in the current sequence?

- **Concept:** Policy Gradient (REINFORCE)
  - **Why needed here:** The paper uses a reinforcement learning approach rather than supervised learning (which requires optimal labels). REINFORCE allows the model to learn from the scalar reward (tour cost) directly.
  - **Quick check question:** How does the model update its weights if there is no "ground truth" path to mimic? (Answer: It adjusts probabilities of paths that yielded lower costs).

- **Concept:** The Triangle Inequality (in Euclidean Space)
  - **Why needed here:** This is strictly required for the "Greedy Check" (Algorithm 1) to prove that a feasible split exists for a given threshold $c_m$.
  - **Quick check question:** If going from A -> B -> C is longer than A -> C directly, does the splitting algorithm still guarantee optimality? (Answer: No, the proof in Appendix A.1 fails).

## Architecture Onboarding

- **Component map:** Encoder (2D coordinates + scale) -> Node Embeddings + Graph Embedding -> LSTM Decoder (context + history) -> Action probabilities -> Path sequence -> Optimal Splitter (Binary Search + Greedy Check) -> Min-Max Tour Cost -> REINFORCE Update

- **Critical path:** The interaction between the **LSTM hidden state** and the **Splitter's binary search**. The LSTM must produce a path sequence such that when the Splitter (Algorithm 2) cuts it, the resulting segments are balanced. If the LSTM fails to capture history, the Splitter will produce a high cost, but the gradient signal may be too weak to correct the specific "early" decision that caused the imbalance.

- **Design tradeoffs:**
  - **Serial vs. Parallel:** The LSTM decoder enforces serial path generation (slower inference than parallel decoders), but it is necessary to handle the sequential history requirement.
  - **Deterministic vs. Learned Splitting:** The authors chose a deterministic $O(n \log \dots)$ algorithm over a learned splitter (like SplitNet). This guarantees optimal partitioning for a fixed path but restricts the framework to Euclidean-compatible distance metrics.

- **Failure signatures:**
  - **Mode Collapse:** The agent generates the same path regardless of node positions (check variance of output paths).
  - **Greedy Behavior:** The path generator visits nearest neighbors exclusively, ignoring the global distribution needed for balanced splitting (check if paths are "zig-zagging" or clustering too early).
  - **LSTM Forgetting:** In large $n$ scenarios (e.g., $n=100$), the agent makes poor decisions at the end of the sequence (check performance delta between first and last 10% of city selections).

- **First 3 experiments:**
  1. **Sanity Check (Splitter):** Implement Algorithm 2 (Binary Search + Greedy Check) independently. Feed it a random permutation of cities and verify it finds a valid split. Feed it a sorted line of points and verify the split is even.
  2. **Ablation (LSTM):** Replace the LSTM decoder with a standard MLP/Attention decoder (as mentioned in Section 4.5 "w/o LSTM"). Train on small $n=20$ and compare convergence speed and final cost.
  3. **Transferability Test (Scale):** Train on $n=50$, test directly on $n=100$ (without fine-tuning). Compare the performance drop against the baseline (Eqt/Dpn) to verify the "Scale Embedding" efficacy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the integration of algorithmic priors with end-to-end learning in the GaS framework be effectively generalized to other combinatorial optimization problems beyond the m3-TSP?
- Basis in paper: [explicit] The authors state in the Conclusion that they "plan to apply it to other combinatorial optimization problems in our future work."
- Why unresolved: While the framework is modular, the specific interaction between the LSTM-based path generator and the splitting algorithm is tailored to the structure of the m3-TSP.
- What evidence would resolve it: Successful application of the GaS framework to distinct NP-hard problems (e.g., Vehicle Routing with Time Windows) requiring similar decomposition strategies.

### Open Question 2
- Question: How does the GaS framework perform in non-Euclidean spaces or graphs with asymmetric edge costs, where the optimal splitting algorithm's theoretical guarantees may not hold?
- Basis in paper: [inferred] The Appendix proof relies on the triangle inequality property of Euclidean distances, and the method explicitly defines the problem in Euclidean space (Page 2) to ensure the splitting algorithm is optimal.
- Why unresolved: The greedy check and splitting efficiency depend on metric properties that are not guaranteed in general graph structures or real-world road networks.
- What evidence would resolve it: Experimental results on asymmetric TSP instances or non-metric graphs showing whether the greedy splitting strategy remains robust or fails.

### Open Question 3
- Question: Can the performance gap between the learning-based GaS framework and classical solvers (like LKH3) be closed for instances with a small number of salesmen ($m$)?
- Basis in paper: [inferred] The authors note on Page 5 that "when $m$ is small... existing learning-based approaches still lag behind search-based methods like LKH3," indicating a specific failure mode for the proposed method.
- Why unresolved: The paper highlights this regression toward classical TSP difficulty but does not modify the architecture to specifically address the "small $m$" scenario.
- What evidence would resolve it: Ablation studies or architectural modifications that improve performance specifically in the small $m$ regime to match LKH3 quality.

## Limitations
- The framework's optimality guarantee for splitting depends on Euclidean geometry and the triangle inequality, limiting applicability to non-metric spaces.
- Performance on instances with a small number of salesmen ($m$) remains inferior to classical search-based solvers like LKH3.
- The LSTM decoder's sequential nature may become a bottleneck for very large problem instances due to vanishing gradients.

## Confidence
- **High confidence** in the framework's core mechanism (RL + optimal splitting) and its ability to outperform learning-based baselines on standard m³-TSP instances, given the statistical significance (p < 0.05) and the deterministic optimality of the splitter.
- **Medium confidence** in the generalizability claims, as transferability results depend on specific OOD test sets (Rotation, Gaussian, Explosion) not fully detailed in the paper.
- **Medium confidence** in the LSTM's necessity for handling partial observability, supported by the ablation study but lacking extensive empirical comparison to alternative architectures.

## Next Checks
1. **Ablation study on GAT architecture:** Test different configurations (number of heads, normalization, dropout) to identify the minimal sufficient design for competitive performance.
2. **Baseline sensitivity analysis:** Experiment with per-instance vs per-batch baseline computation to quantify impact on training stability and final performance.
3. **OOD transferability robustness:** Evaluate the framework on additional OOD distributions (e.g., clustered, non-uniform) beyond the three specified in the paper to test the limits of its generalizability.