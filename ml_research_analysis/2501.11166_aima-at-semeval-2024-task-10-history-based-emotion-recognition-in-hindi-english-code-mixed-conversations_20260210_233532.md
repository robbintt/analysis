---
ver: rpa2
title: 'AIMA at SemEval-2024 Task 10: History-Based Emotion Recognition in Hindi-English
  Code-Mixed Conversations'
arxiv_id: '2501.11166'
source_url: https://arxiv.org/abs/2501.11166
tags:
- emotion
- sentence
- previous
- current
- code-mixed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of Emotion Recognition in Conversation
  (ERC) for code-mixed Hindi-English dialogues. The authors propose a translation-based
  approach that first converts code-mixed text to Hindi using transliteration, then
  translates to English using SeamlessM4T, enabling the use of monolingual emotion
  recognition models.
---

# AIMA at SemEval-2024 Task 10: History-Based Emotion Recognition in Hindi-English Code-Mixed Conversations

## Quick Facts
- arXiv ID: 2501.11166
- Source URL: https://arxiv.org/abs/2501.11166
- Reference count: 9
- The team achieved a weighted F1-score of 0.4080 on the test set, outperforming baseline models including GPT-3.5 Turbo (0.2662) and fine-tuned sentence emotion recognition (0.3683).

## Executive Summary
This paper tackles the challenge of Emotion Recognition in Conversation (ERC) for code-mixed Hindi-English dialogues, which presents unique difficulties due to the mixed linguistic nature of the text. The authors propose a translation-based approach that first transliterates code-mixed text to Hindi, then translates to English using SeamlessM4T, enabling the use of established monolingual emotion recognition models. Their ensemble method combines four distinct base models incorporating historical context, sequential information, and attention mechanisms, achieving superior performance compared to existing baselines.

## Method Summary
The authors develop a two-stage translation pipeline to convert code-mixed Hindi-English text into English, using Google Translate API for Hindi-to-English translation. Four base models are trained: two incorporating historical context (preceding and succeeding utterances), one using GRU for sequential information, and one employing multi-head attention mechanisms. The final ensemble model aggregates predictions from all four architectures using majority voting. The approach leverages pretrained models including BERT, RoBERTa, and GPT variants, fine-tuned on translated emotion datasets. Evaluation is conducted on the SemEval-2024 Task 10 dataset using weighted F1-score as the primary metric.

## Key Results
- Ensemble model achieves weighted F1-score of 0.4080 on test set
- Outperforms GPT-3.5 Turbo baseline (0.2662 F1) by 53% relative improvement
- Surpasses fine-tuned sentence emotion recognition baseline (0.3683 F1) by 11% relative improvement
- Demonstrates effectiveness of incorporating both preceding and succeeding utterance contexts

## Why This Works (Mechanism)
The translation-based approach works by transforming the code-mixed Hindi-English text into a form that can be processed by established monolingual emotion recognition models. By leveraging the sequential nature of conversations through GRU layers and incorporating historical context via attention mechanisms, the model captures the dynamic evolution of emotions throughout the dialogue. The ensemble approach combines complementary strengths of different architectures, with majority voting providing robustness against individual model failures.

## Foundational Learning
- **Code-Mixed Text Processing**: Why needed - Code-mixed text contains elements from multiple languages that standard NLP models struggle with; quick check - Verify translation accuracy of mixed-language samples
- **Historical Context in ERC**: Why needed - Emotions evolve through conversation turns; quick check - Compare performance with and without context window
- **Ensemble Methods**: Why needed - Different models capture different aspects of emotional patterns; quick check - Analyze variance in individual model predictions
- **Attention Mechanisms**: Why needed - Focus on relevant parts of conversation for emotion detection; quick check - Visualize attention weights on sample conversations
- **GRU for Sequential Information**: Why needed - Capture temporal dependencies in emotional expression; quick check - Compare with Transformer-based sequential models
- **Translation Quality Impact**: Why needed - Translation errors can propagate to emotion recognition; quick check - Conduct human evaluation of translated samples

## Architecture Onboarding

**Component Map:**
Code-mixed text -> Transliteration -> Hindi translation -> English translation -> Base model 1 (BERT with context) -> Base model 2 (RoBERTa with context) -> Base model 3 (GRU sequential) -> Base model 4 (Multi-head attention) -> Ensemble voting -> Final prediction

**Critical Path:**
The critical path involves the translation pipeline followed by the ensemble of four base models. Translation quality directly impacts all downstream models, while the ensemble voting mechanism provides the final emotion classification.

**Design Tradeoffs:**
- Translation introduces potential semantic loss but enables use of powerful monolingual models
- Ensemble provides robustness but increases computational cost
- Historical context improves accuracy but requires more memory for longer conversations
- Majority voting is simple but doesn't account for model confidence differences

**Failure Signatures:**
- Poor translation quality manifests as consistently low F1-scores across all base models
- Model bias toward frequent emotions appears as skewed confusion matrix
- Context window too small results in poor handling of emotion transitions
- Overfitting to training data shows high training accuracy but poor validation/test performance

**3 First Experiments:**
1. Test translation pipeline on held-out code-mixed samples to measure semantic preservation
2. Run ablation study removing historical context to quantify its contribution
3. Compare ensemble voting with weighted voting based on individual model confidence scores

## Open Questions the Paper Calls Out
None

## Limitations
- Translation pipeline may introduce noise and semantic distortions in code-mixed text
- Majority voting mechanism doesn't optimally weight predictions from models with varying confidence levels
- Assumption that translation preserves emotional semantics lacks empirical validation

## Confidence

**High Confidence:**
- Experimental setup and baseline comparisons are clearly described
- Reproducible methodology for ensemble approach is provided

**Medium Confidence:**
- Reported F1-score improvement over baselines is convincing
- Robustness of translation pipeline remains uncertain without validation

**Low Confidence:**
- Assumption that translation preserves emotional semantics in code-mixed text lacks empirical support

## Next Checks
1. Conduct human evaluation study to assess translation quality and emotional preservation when converting code-mixed Hindi-English text to Hindi and then to English
2. Perform ablation studies to determine individual contributions of historical context, sequential GRU layers, and multi-head attention mechanisms to ensemble performance
3. Test model performance on out-of-domain code-mixed conversations to evaluate generalization beyond SemEval-2024 Task 10 dataset