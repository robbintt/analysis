---
ver: rpa2
title: 'Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from
  Corrupted Datasets'
arxiv_id: '2510.01479'
source_url: https://arxiv.org/abs/2510.01479
tags:
- learning
- poisoning
- clean
- contamination
- weighted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of learning robust control policies
  from offline datasets contaminated by adversarial poisoning, system errors, or low-quality
  samples. The proposed Density-Ratio Weighted Behavioral Cloning (Weighted BC) method
  uses a small, verified clean reference set to estimate trajectory-level density
  ratios via a binary discriminator, which are then clipped and used as weights in
  the BC objective to prioritize clean expert behavior while down-weighting or discarding
  corrupted data.
---

# Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from Corrupted Datasets

## Quick Facts
- **arXiv ID**: 2510.01479
- **Source URL**: https://arxiv.org/abs/2510.01479
- **Reference count**: 39
- **Primary result**: Achieves near-optimal performance even with 100% data contamination by leveraging density-ratio weighting with a small verified reference set

## Executive Summary
This paper tackles the critical challenge of learning robust control policies from offline datasets contaminated by adversarial attacks, system errors, or low-quality samples. The proposed Density-Ratio Weighted Behavioral Cloning (Weighted BC) method uses a small, verified clean reference set to estimate trajectory-level density ratios via a binary discriminator, which are then clipped and used as weights in the BC objective to prioritize clean expert behavior while down-weighting corrupted data. The approach demonstrates strong theoretical guarantees and significant empirical improvements over baselines across various contamination scenarios.

## Method Summary
The proposed method employs density-ratio weighting to distinguish clean expert trajectories from corrupted ones in offline datasets. A small verified reference set of clean expert trajectories is used to train a binary discriminator that estimates trajectory-level density ratios. These ratios are then clipped and incorporated as weights in the behavioral cloning objective, effectively prioritizing clean data during policy learning. The method includes theoretical convergence guarantees showing that the learned policy converges to the clean expert policy with finite-sample bounds independent of contamination rate. The approach is evaluated on D4RL continuous control benchmarks across different contamination scenarios including adversarial attacks, system errors, and low-quality samples.

## Key Results
- Achieves near-optimal performance with up to 100% data contamination using only a small verified reference set
- Outperforms baselines (BC, BCQ, BRAC) by up to 200% in extreme contamination scenarios
- Maintains over 80% performance up to 60% contamination across all poisoning types

## Why This Works (Mechanism)
The method works by leveraging a small clean reference set to estimate density ratios that distinguish clean expert behavior from corrupted samples. The density-ratio weighted objective naturally down-weights or discards corrupted trajectories during training, allowing the policy to learn primarily from high-quality expert behavior. The clipping mechanism prevents extreme weights from destabilizing training while preserving the signal from the reference set. The theoretical framework ensures convergence to the clean expert policy despite high contamination rates.

## Foundational Learning
- **Behavioral Cloning**: Why needed - baseline imitation learning approach; Quick check - standard supervised learning of expert demonstrations
- **Density Ratio Estimation**: Why needed - distinguishes clean from corrupted data; Quick check - binary classifier trained on reference vs. contaminated data
- **Adversarial Training**: Why needed - handles poisoned datasets; Quick check - robustness to intentionally corrupted inputs
- **Off-policy Learning**: Why needed - learns from fixed datasets; Quick check - no environment interaction required
- **Trajectory-level Weighting**: Why needed - considers full trajectory quality; Quick check - weights based on entire trajectory rather than individual transitions

## Architecture Onboarding

**Component Map**: Reference Set -> Density Ratio Estimator -> Weight Clipping -> Weighted BC Objective -> Policy

**Critical Path**: The method depends critically on having a small, verified clean reference set that accurately represents expert behavior. The density ratio estimator must effectively distinguish clean from corrupted trajectories, and the weight clipping must balance robustness with maintaining useful signal.

**Design Tradeoffs**: 
- Reference set size vs. accuracy: Smaller reference sets reduce data requirements but may provide noisier density ratio estimates
- Clipping threshold selection: Aggressive clipping increases robustness but may discard useful information from borderline cases
- Trajectory vs. transition weighting: Trajectory-level weighting is more robust but requires more computation

**Failure Signatures**:
- Poor density ratio estimates when reference set is unrepresentative of true expert behavior
- Suboptimal performance when contamination is highly structured or reference set is too small
- Sensitivity to clipping threshold selection in boundary contamination cases

**3 First Experiments**:
1. Test with varying reference set sizes (1%, 5%, 10% of total data) to find optimal balance
2. Evaluate different clipping thresholds (0.1, 0.5, 1.0) on contamination robustness
3. Compare trajectory-level vs. transition-level weighting on structured contamination

## Open Questions the Paper Calls Out
The paper acknowledges that the method's effectiveness depends on having access to a small, verified clean reference set, which may not always be available in real-world applications. The assumption that the reference set is representative of true expert behavior may not hold in all scenarios. Additionally, while the method shows strong performance on D4RL benchmarks, its effectiveness on more diverse real-world robotics or control tasks remains to be validated.

## Limitations
- Requires a small, verified clean reference set which may not be available in all applications
- Performance depends on the reference set being representative of true expert behavior
- Results primarily validated on D4RL benchmarks, which may not capture full real-world diversity
- Density ratio clipping introduces a hyperparameter that requires careful tuning

## Confidence

**Theoretical guarantees**: High - Provides finite-sample bounds and convergence proofs with clear assumptions
**Empirical results**: Medium - Strong performance on standardized benchmarks but limited real-world validation
**Practical applicability**: Medium to Low - Relies on availability of clean reference set and careful hyperparameter tuning

## Next Checks
1. Test the method on real-world robotics datasets or non-D4RL benchmarks to assess generalizability beyond standardized environments
2. Evaluate the sensitivity of the density ratio clipping threshold to different contamination types and ratios through systematic ablation studies
3. Investigate the method's performance when the reference set is imperfect or biased, simulating more realistic scenarios where clean data is scarce or unrepresentative