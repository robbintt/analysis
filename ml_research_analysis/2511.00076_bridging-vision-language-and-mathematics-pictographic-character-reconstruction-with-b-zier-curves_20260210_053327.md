---
ver: rpa2
title: "Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction\
  \ with B\xE9zier Curves"
arxiv_id: '2511.00076'
source_url: https://arxiv.org/abs/2511.00076
tags:
- visual
- geometric
- zier
- character
- curves
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of enabling Vision-Language\
  \ Models (VLMs) to interpret and reconstruct the geometric structure of visual forms,\
  \ moving beyond semantic recognition to programmatic understanding. The authors\
  \ introduce a novel task: programmatic character reconstruction, where a VLM acts\
  \ as a \"visual decompiler\" to translate raster images of characters into executable\
  \ programs composed of B\xE9zier curves."
---

# Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with Bézier Curves

## Quick Facts
- **arXiv ID**: 2511.00076
- **Source URL**: https://arxiv.org/abs/2511.00076
- **Reference count**: 29
- **Primary result**: VLMs can be trained to interpret visual forms as executable Bézier curve programs, achieving superior geometric reconstruction of Chinese characters compared to GPT-4o

## Executive Summary
This paper addresses the challenge of enabling Vision-Language Models to interpret and reconstruct the geometric structure of visual forms, moving beyond semantic recognition to programmatic understanding. The authors introduce a novel task: programmatic character reconstruction, where a VLM acts as a "visual decompiler" to translate raster images of characters into executable programs composed of Bézier curves. The core method involves representing each character as a sequence of Bézier curve strokes and training the model with an explicit Cartesian coordinate system overlaid on the input images to aid spatial grounding. The approach demonstrates superior performance compared to strong zero-shot baselines like GPT-4o, achieving higher geometric reconstruction scores across standard and stylistic Chinese fonts. Most notably, the model exhibits remarkable zero-shot generalization, successfully reconstructing ancient Oracle Bone Script characters despite being trained only on modern Chinese characters, providing evidence of learning an abstract and transferable geometric grammar.

## Method Summary
The approach trains a Vision-Language Model to reconstruct characters as sequences of Bézier curves by providing explicit Cartesian coordinate overlays during training. Each Chinese character is decomposed into stroke sequences, with each stroke represented as a Bézier curve parameterized by control points. The model learns to parse raster images and output executable code that, when rendered, reconstructs the original character geometry. The explicit coordinate system provides spatial grounding, helping the model learn the geometric relationships between strokes. Training data consists of modern Chinese characters rendered in various fonts, with the model learning to generalize the underlying geometric principles rather than memorizing specific renderings.

## Key Results
- Model outperforms GPT-4o in geometric reconstruction of Chinese characters using Bézier curve programs
- Zero-shot generalization successfully reconstructs