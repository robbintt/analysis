---
ver: rpa2
title: Language Models' Factuality Depends on the Language of Inquiry
arxiv_id: '2502.17955'
source_url: https://arxiv.org/abs/2502.17955
tags:
- factual
- knowledge
- language
- languages
- recall
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper demonstrates that multilingual language models exhibit\
  \ significant inconsistencies in factual knowledge retrieval across languages, often\
  \ failing to transfer knowledge between languages despite possessing correct information\
  \ in one language. To systematically analyze this limitation, the authors introduce\
  \ a benchmark of 10,000 country-related facts across 13 languages and propose three\
  \ novel metrics\u2014Factual Recall Score, Knowledge Transferability Score, and\
  \ Cross-Lingual Factual Knowledge Transferability Score\u2014to quantify factual\
  \ recall and knowledge transferability."
---

# Language Models' Factuality Depends on the Language of Inquiry

## Quick Facts
- arXiv ID: 2502.17955
- Source URL: https://arxiv.org/abs/2502.17955
- Reference count: 40
- Primary result: Multilingual LMs show significant factual knowledge inconsistencies across languages, failing to transfer knowledge despite possessing correct information in one language

## Executive Summary
This paper reveals that multilingual language models exhibit substantial inconsistencies in factual knowledge retrieval across languages, even when possessing correct information in one language. The authors introduce a systematic benchmark of 10,000 country-related facts across 13 languages and propose three novel metrics to quantify factual recall and knowledge transferability. Their experiments demonstrate that models struggle to transfer knowledge between languages despite strong performance within individual languages, with the gap widening from high-resource to low-resource languages.

## Method Summary
The study introduces a benchmark of 805 country-related factual questions translated into 13 languages (English, Chinese, French, Japanese, Hindi, Russian, Arabic, Greek, Nepali, Ukrainian, Turkish, Swahili, Thai). The authors evaluate 14 multilingual models across three tasks: Factual Recall (802 examples), In-Context Recall (156 examples), and Counter-Factual Context Adherence (1404 examples). Models are evaluated at temperature=0 with max_tokens=128, using Qwen-2.5-72B-Inst as LLM judge with max_tokens=256. Three metrics are computed: Factual Recall Score (FRS) measuring recall accuracy, Knowledge Transferability Score (KTS) quantifying consistency of error rates across languages, and X-FaKT Score (harmonic mean of FRS and KTS) for overall performance.

## Key Results
- Models correctly identify country-specific facts in the associated language but fail to transfer this knowledge to other languages
- Performance declines from high-resource to low-resource languages, with Latin-script low-resource languages (Swahili, Turkish) outperforming expectations
- Larger models show better cross-lingual factual knowledge handling, with Llama-3-70B achieving X-FaKT = 0.848 vs Llama-3.2-1B = 0.336
- Strong inverse relationship between factual recall and counterfactual context adherence, raising questions about balancing factual knowledge with hypothetical reasoning

## Why This Works (Mechanism)

### Mechanism 1: Associative Knowledge Encoding
Factual knowledge is stored in language-specific representations tied to the linguistic context in which entities appear in training data. When queries match the training language-context pairing (e.g., asking about Saudi entities in Arabic), models retrieve from well-aligned representations. Non-associative queries require cross-lingual transfer that current architectures do not consistently support.

### Mechanism 2: Script-Based Transfer Scaffolding
Languages sharing scripts benefit from representation overlap that facilitates cross-lingual factual retrieval. Models leverage shared orthographic features to transfer patterns, with Latin-script low-resource languages (Swahili, Turkish) outperforming expectations by "piggybacking" on English representations.

### Mechanism 3: Scale-Dependent Cross-Lingual Binding
Larger models develop more robust cross-lingual factual representations, improving transfer consistency. Increased parameter count allows more overlapping multilingual representations and better alignment of factual knowledge across language subspaces.

## Foundational Learning

- **Associative vs Non-Associative Knowledge**: Core distinction in evaluation framework determining whether query language matches fact's cultural-linguistic context. Quick check: If you ask about Mount Fuji in Swahili, is this associative or non-associative knowledge?

- **Harmonic Mean for Composite Metrics**: X-FaKT uses harmonic mean of FRS and KTS to penalize imbalanced performance. Quick check: Why would arithmetic mean be inappropriate for combining FRS=0.9 and KTS=0.3?

- **Counterfactual Context Adherence**: Trade-off between factual recall and instruction-following; models resist contradicting their knowledge even when explicitly instructed. Quick check: If a model is told "Paris is in Germany" and must answer based on that context, what conflict arises?

## Architecture Onboarding

- **Component map**: Multilingual tokenization (shared vocabulary across languages) -> Factual knowledge representations (distributed across layers) -> Evaluation pipeline (LLM-as-judge with controlled prompts)
- **Critical path**: Translate benchmark queries to 13 languages -> Query target models at temperature=0 -> Evaluate with language-aware scoring -> Compute FRS, KTS, X-FaKT
- **Design tradeoffs**: Benchmark scope vs coverage (country-related facts are narrow but controlled); evaluator selection (LLM evaluators risk contaminating evaluation with their own factual knowledge); language grouping (coarse high/medium/low-resource categories)
- **Failure signatures**: High FRS + Low KTS (strong recall but language-locked knowledge); high counterfactual error rate (model overrides explicit context with internal knowledge); evaluator bias (LLM judge "corrects" counterfactual responses against ground truth)
- **First 3 experiments**: Baseline X-FaKT across model scales; script ablation comparing Greek vs Turkish on shared factual domains; counterfactual sensitivity probe measuring error rate divergence between well-known vs obscure entities

## Open Questions the Paper Calls Out

**Calibrated Multilingualism**: How can language models be developed to autonomously recognize and leverage language-specific factual reliability? The paper identifies this as a necessity for future AI systems but does not propose specific architectural changes or training methodologies to implement it.

**Recall-Context Trade-off**: Can architectural modifications resolve the trade-off between strong factual recall and the ability to adhere to counterfactual instructions? The study quantifies the trade-off but does not determine if this is an inherent conflict in current learning mechanisms or a solvable alignment issue.

**Domain Generalization**: Do the observed cross-lingual knowledge transfer failures persist in non-geographic domains such as science, abstract concepts, or culture? The benchmark is restricted to country-specific entities, leaving unclear if the "language-specific silos" phenomenon applies to knowledge that is not inherently geographically bound.

## Limitations

- Language selection bias: 13 languages may not represent full spectrum of script families and resource levels needed to generalize findings
- Evaluator knowledge contamination: LLM evaluators can override counterfactual ground truths with their internal knowledge, introducing systematic bias
- Factual knowledge scope: Country-related facts represent a narrow domain that may not transfer to other knowledge types

## Confidence

**High confidence**: Associative vs non-associative distinction and its measurable impact on recall accuracy (confirmed by t-tests across all models with p < 0.05); scale-dependent performance improvements in X-FaKT scores show clear, consistent patterns.

**Medium confidence**: Script-based transfer scaffolding mechanism, supported by error pattern analysis and anecdotal evidence, but lacking direct experimental manipulation of script variables.

**Low confidence**: Counterfactual context adherence results, where evaluator bias was explicitly documented as problematic, making the true baseline for context-following behavior uncertain.

## Next Checks

1. **Script transfer ablation study**: Design experiments that isolate script effects by testing factual recall on languages with identical cultural associations but different scripts (e.g., Hindi vs Marathi) versus languages with different cultural associations but same script (e.g., Swahili vs Turkish).

2. **Cross-domain knowledge transferability**: Replicate the benchmark methodology using factual knowledge from domains outside country-related information (e.g., scientific facts, historical events) to test whether the associative knowledge mechanism generalizes across knowledge types.

3. **Evaluator bias control**: Implement a blinded evaluation protocol where evaluators are either (a) explicitly trained to follow counterfactual ground truth regardless of their own knowledge, or (b) use non-LLM evaluation methods to establish baseline context adherence rates free from internal knowledge contamination.