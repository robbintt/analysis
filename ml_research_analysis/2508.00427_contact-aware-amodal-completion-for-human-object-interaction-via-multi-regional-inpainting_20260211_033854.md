---
ver: rpa2
title: Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional
  Inpainting
arxiv_id: '2508.00427'
source_url: https://arxiv.org/abs/2508.00427
tags:
- amodal
- completion
- inpainting
- object
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a contact-aware amodal completion method
  for human-object interaction (HOI) scenarios using multi-regional inpainting. The
  approach identifies occluded regions by combining convex hull operations with contact
  point information, dividing them into primary and secondary regions.
---

# Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting

## Quick Facts
- arXiv ID: 2508.00427
- Source URL: https://arxiv.org/abs/2508.00427
- Authors: Seunggeun Chi; Enna Sachdeva; Pin-Hao Huang; Kwonjoon Lee
- Reference count: 40
- Primary result: Significant CLIP score and mIoU improvements for amodal completion in human-object interaction scenarios.

## Executive Summary
This paper introduces a contact-aware amodal completion method for human-object interaction (HOI) scenarios using multi-regional inpainting. The approach identifies occluded regions by combining convex hull operations with contact point information, dividing them into primary and secondary regions. A novel multi-regional inpainting technique is then applied within a diffusion model, using differentiated denoising strategies across regions to enhance accuracy and realism. The method does not require additional training and remains robust without ground-truth contact annotations. Experimental results show significant improvements in both CLIP score and mIoU compared to existing methods. The approach also supports downstream applications like 3D reconstruction and novel-view synthesis.

## Method Summary
The method uses pre-trained Stable Diffusion-v2 inpainting with no additional training. It identifies occlusion regions via contact-aware convex hull geometry, then applies differentiated denoising: coarse structure is generated in the primary region, followed by refinement across both primary and secondary regions. The approach works with or without ground-truth contact annotations by using VLM-based contact estimation.

## Key Results
- CLIP score improvement over baselines on BEHAVE and InterCap datasets
- mIoU improvement demonstrating better mask overlap with ground truth
- VLM-based contact estimation maintains performance without ground-truth annotations
- Successful application to downstream 3D reconstruction and novel-view synthesis

## Why This Works (Mechanism)

### Mechanism 1
Constraining inpainting via contact-aware convex hull prevents over-extension of generated geometry. The system calculates occlusion boundary by dilating human-object segmentation mask intersection, then computes convex hull around this boundary combined with contact points. This defines a primary region that restricts diffusion model to high-probability occlusion areas.

Core assumption: Occluded object parts lie within convex hull defined by visible object boundary and contact points with human.

Evidence anchors: [Section 4.2.1] defines primary mask as intersection of occluder mask and contact-aware convex hull; [Table 2] shows "Convex hull w/ contact" outperforms "Human mask" (76.11% vs 69.98% mIoU).

### Mechanism 2
Differentiated denoising strategies establish coarse structure before refining details. The inpainting process splits into two timesteps using strength parameter r: high noise applied only to primary region to generate coarse structure, then mask expands to include secondary region with lower noise to blend details.

Core assumption: Diffusion models establish global structure in early timesteps and local details in later timesteps.

Evidence anchors: [Section 4.2.2] Eq. 8 formalizes split process; [Figure 6] visualizes how varying r shifts focus between regions.

### Mechanism 3
VLM-estimated contact points maintain performance without ground-truth annotations. Instead of GT contact maps, the system uses VLM to describe interaction, maps text to SMPL joint IDs, projects these 3D joints to 2D, and uses these as proxy contact points.

Core assumption: Modern VLMs can accurately identify interacting limbs, and SMPL models can map these limbs to 2D space sufficiently well to approximate contact geometry.

Evidence anchors: [Table 7] shows "Multi-HMR + VLM" achieves 77.64% mIoU, comparable to GT contact performance.

## Foundational Learning

- **Concept**: Amodal Completion
  - Why needed: Core task - inferring whole shape of object from partial visibility, requiring imagination of geometry hidden behind other objects.
  - Quick check: How does this differ from standard image inpainting? (Answer: Requires shape inference of specific occluded entities rather than just texture synthesis).

- **Concept**: Diffusion Inpainting & Strength Parameter (r)
  - Why needed: Method relies on manipulating noise schedule; strength parameter r controls balance between preserving original image vs. hallucinating new content.
  - Quick check: If r=1.0, what happens to masked region? (Answer: Overwritten with pure noise and regenerated from scratch).

- **Concept**: SMPL Body Model
  - Why needed: System uses SMPL to provide physical prior for human topology; understanding 3D mesh projection to 2D is required to see how contact points are estimated.
  - Quick check: Why is 3D body topology useful for 2D inpainting task? (Answer: Provides physical constraints on where occlusions can occur relative to human body).

## Architecture Onboarding

- **Component map**: Input Processor -> Contact Estimator -> Region Geometry -> Inpainting Engine
- **Critical path**: Region Geometry logic is most fragile; if convex hull calculation is too loose, primary region becomes too large and contact-aware benefit is lost.
- **Design tradeoffs**:
  - r=0.0 vs r=1.0: Low r prioritizes structure/primary region (best for light occlusion); high r allows more creative generation in secondary regions (best for heavy occlusion); default r=0.5 is heuristic balance.
  - GT vs VLM Contacts: GT ensures high accuracy but limits application; VLM allows general use but risks hallucinations.
- **Failure signatures**:
  - Over-extension: Object generated outside human bounds -> likely convex hull calculation error or r too high.
  - Missing Parts: Heavy occlusion not filled -> likely r too low (insufficient denoising steps).
  - Orientation Errors: Object facing wrong way -> diffusion model hallucination (ambiguous visual cues).
- **First 3 experiments**:
  1. Sanity Check - Region Ablation: Run naive outpainting vs primary region only on single image; verify naive outpainting hallucinates incorrect geometry.
  2. Hyperparameter Sweep: Run batch evaluation on BEHAVE varying r (0.1, 0.5, 0.9); plot mIoU vs Occlusion Ratio to validate optimal r depends on occlusion level.
  3. Contact Robustness: Input image with synthetic noise added to contact points; measure degradation in mIoU to quantify sensitivity to VLM/HMR estimation pipeline.

## Open Questions the Paper Calls Out

### Open Question 1
Can the contact-aware convex hull strategy be effectively extended to generalize to complex scenes involving multiple humans and objects? The current approach assumes a single human-object pair and would need redefinition for overlapping interactions.

### Open Question 2
How can the pipeline be modified to ensure temporal consistency for video-based human-object interactions? Current single-image processing results in flickering due to stochastic diffusion generation.

### Open Question 3
Is it possible to dynamically determine the optimal inpainting strength parameter (r) based on estimated occlusion ratio rather than using fixed heuristic? Current r=0.5 is compromise when occlusion ratio is unknown.

### Open Question 4
To what extent does reliance on pre-trained Stable Diffusion priors limit reconstruction of rare or object classes not well-represented in training data? Method may struggle with out-of-distribution object categories.

## Limitations

- Limited generalization to scenarios with multiple subjects occluding each other
- Lack of temporal consistency for video applications due to stochastic diffusion
- Potential struggle with objects not seen during Stable Diffusion training
- Possible failure with highly concave objects or when contact points are ambiguous

## Confidence

- **High Confidence**: Overall methodology clearly described; experimental results directly measurable; ablation studies convincing.
- **Medium Confidence**: Differentiated denoising mechanism logically sound but lacks ablation studies on r parameter and step count; claims about generalization without training plausible but robustness to diverse objects not fully explored.
- **Low Confidence**: Failure cases for heavy occlusions or highly concave objects not deeply analyzed; limitations mentioned but not quantified.

## Next Checks

1. **Occlusion Ratio Ablation**: Run method on BEHAVE images with occlusion ratios 10-30%, 30-50%, and 50-70%; plot mIoU vs occlusion ratio for different r values (0.3, 0.5, 0.7) to validate optimal r depends on occlusion level.

2. **Contact Point Sensitivity**: Generate synthetic contact point noise (random jitter of 5-20 pixels); measure degradation in mIoU to quantify robustness of VLM + HMR pipeline and identify noise threshold at which convex hull mechanism fails.

3. **Generalization to Unseen Objects**: Test method on dataset with object categories not present in training data; measure whether CLIP score and mIoU degrade to indicate overfitting to specific object types.