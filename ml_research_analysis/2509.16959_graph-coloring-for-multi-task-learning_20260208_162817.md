---
ver: rpa2
title: Graph Coloring for Multi-Task Learning
arxiv_id: '2509.16959'
source_url: https://arxiv.org/abs/2509.16959
tags:
- tasks
- task
- son-goku
- step
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SON-GOKU, a scheduler that addresses gradient
  interference in multi-task learning (MTL) by partitioning tasks into low-conflict
  groups and updating one group at a time. The method constructs a conflict graph
  from gradient interference estimates and applies greedy graph coloring to form compatible
  task groups.
---

# Graph Coloring for Multi-Task Learning

## Quick Facts
- **arXiv ID:** 2509.16959
- **Source URL:** https://arxiv.org/abs/2509.16959
- **Authors:** Santosh Patapati
- **Reference count:** 40
- **Primary result:** SON-GOKU scheduler improves MTL performance by 10-20% on CIFAR-10 and 7% on MM-IMDb through conflict-aware task grouping.

## Executive Summary
This paper introduces SON-GOKU, a scheduler that addresses gradient interference in multi-task learning (MTL) by partitioning tasks into low-conflict groups and updating one group at a time. The method constructs a conflict graph from gradient interference estimates and applies greedy graph coloring to form compatible task groups. Experiments on six diverse datasets (including NYUv2, CIFAR-10, A V-MNIST, MM-IMDb, and two stock prediction tasks) demonstrate consistent improvements over strong baselines and state-of-the-art MTL optimizers. SON-GOKU achieves performance gains of 10-20% on CIFAR-10 and 7% on MM-IMDb compared to uniform weighting baselines, while also showing improvements in regression tasks on NYUv2. The method is particularly effective when combined with existing approaches like PCGrad and AdaTask, showing synergy between scheduling and gradient manipulation. Theoretical analysis provides guarantees on descent, convergence, and graph partition recovery, with empirical validation showing the scheduler adapts well to evolving task relationships throughout training.

## Method Summary
SON-GOKU is an interference-aware scheduler for MTL that operates in four steps: (1) Estimate pairwise gradient interference using EMA-smoothed gradients, (2) Build a conflict graph where edges connect task pairs with cosine similarity below threshold -τ, (3) Apply Welsh-Powell greedy coloring to partition tasks into non-conflicting groups, and (4) Cycle through color classes, updating one group per training step. The scheduler periodically refreshes the conflict graph every R steps to adapt to evolving task relationships. The approach guarantees descent preservation when groups satisfy τ-compatibility, where all pairwise gradient cosines within a group exceed -τ. The method requires O(Kd) storage for EMA gradients and O(K²r) computation per refresh for cosine similarity, though sketching reduces this to O(Kr) with approximation error.

## Key Results
- Achieves 10-20% accuracy improvement on CIFAR-10 MTL benchmark compared to uniform weighting baseline
- Delivers 7% accuracy gain on MM-IMDb dataset while reducing optimizer tuning effort
- Demonstrates consistent improvements across regression tasks (NYUv2 mIoU), classification tasks (A V-MNIST), and financial prediction tasks
- Shows synergy with existing methods: SON-GOKU + PCGrad outperforms both individual approaches
- Maintains robustness across hyperparameter variations, particularly showing consistent performance across different refresh periods R

## Why This Works (Mechanism)

### Mechanism 1: τ-Compatibility Preserves Descent Direction
- Claim: Grouping tasks whose pairwise gradient cosine similarity exceeds a threshold −τ ensures the aggregated update cannot flip to ascent.
- Mechanism: When all pairs (i,j) in active set S satisfy ⟨g_i, g_j⟩ ≥ −τ‖g_i‖‖g_j‖, the polarization identity yields ‖∑g_k‖² ≥ (1−τ(|S|−1))∑‖g_k‖². Cancellation is bounded by τ and group size.
- Core assumption: Gradients within a group are approximately pairwise aligned (τ-compatibility), and τ(|S|−1) < 1.
- Evidence anchors:
  - [Section 5.1]: Proves the descent preservation inequality under τ-compatibility.
  - [Appendix E]: Full derivation via polarization identity and Cauchy-Schwarz.
  - [corpus]: Weak direct evidence; related work on conflict-resolved gradients (PINNs co-design paper) supports direction-preservation intuition but not the specific τ-bound.
- Break condition: If τ is too large or groups are too large, τ(|S|−1) may approach 1, weakening the guarantee; noisy cosine estimates may misclassify pairs.

### Mechanism 2: Graph Coloring Enforces Non-Conflicting Groups
- Claim: Greedy graph coloring on the conflict graph produces groups where no internal edge exists, guaranteeing tasks with ρ_ij > τ never co-occur in an update.
- Mechanism: Build graph G_τ = (T, E_τ) where edges connect conflicting pairs (ρ_ij > τ). Welsh-Powell coloring uses at most Δ+1 colors (Δ = max degree), so every task is updated at least once per Δ+1 steps (bounded staleness).
- Core assumption: The conflict graph accurately reflects true task interference; Δ is small (sparse conflicts).
- Evidence anchors:
  - [Section 4.3]: Describes Welsh-Powell greedy coloring and Δ+1 bound.
  - [Appendix G–H]: Proves bounded staleness and color-count guarantee.
  - [corpus]: Neural algorithmic reasoning paper on approximate k-coloring provides indirect support for coloring as a scheduling primitive, but not MTL-specific.
- Break condition: If the conflict graph is dense (Δ ≈ K), many colors are needed, reducing per-group update frequency and potentially slowing convergence.

### Mechanism 3: Dynamic Recoloring Tracks Evolving Interference
- Claim: Periodically recomputing the conflict graph from EMA-smoothed gradients allows the scheduler to adapt as task relationships drift during training.
- Mechanism: Every R steps, refresh EMA vectors {˜g_k}, recompute pairwise cosines, rebuild G_τ, and recolor. EMA (β parameter) averages noise while remaining responsive to drift.
- Core assumption: Task interference changes slowly enough within a refresh window that the graph remains useful; EMA effective sample size n_eff is sufficient for stable cosine estimation.
- Evidence anchors:
  - [Section 4.4]: Describes periodic schedule refresh and warm-up/annealing of τ.
  - [Appendix B.4–B.5]: Proves that EMA cosines concentrate around population cosines with margin γ, enabling exact edge recovery.
  - [corpus]: No direct corpus evidence on dynamic MTL recoloring; indirect support from asynchronous federated optimization paper on handling stale/drifted updates.
- Break condition: If R is too large, the graph becomes stale; if R is too small or β is too low, cosine estimates are noisy and grouping unstable.

## Foundational Learning

- **Multi-task gradient interference**:
  - Why needed here: The entire method is built on detecting and avoiding conflicting gradients; you must understand why negative cosine similarity harms joint optimization.
  - Quick check question: If two task gradients have cosine −0.8, what happens if you sum them and take a step?

- **Graph coloring and chromatic number**:
  - Why needed here: The scheduler uses coloring to partition tasks; understanding that χ(G) ≤ Δ+1 explains why sparse conflicts yield few groups.
  - Quick check question: Given a graph with maximum degree 3, what's the upper bound on colors needed for a proper coloring?

- **Exponential moving averages for gradient estimation**:
  - Why needed here: EMA smooths noisy per-step gradients to produce stable conflict estimates; the effective sample size n_eff determines estimation quality.
  - Quick check question: If β=0.9, approximately how many recent steps contribute meaningfully to the EMA?

## Architecture Onboarding

- **Component map**: EMA Gradient Buffers -> Conflict Graph Builder -> Graph Colorer -> Scheduler -> Refresh Controller

- **Critical path**: EMA update → cosine matrix (O(K²r) with sketching) → threshold to graph → greedy color → schedule step. Refresh cost is amortized as O(Kr(d+K)/R) per step.

- **Design tradeoffs**:
  - **τ (conflict threshold)**: Larger τ → sparser graph → fewer groups → more tasks per step but higher within-group conflict. Smaller τ → more groups → smaller updates but cleaner direction.
  - **R (refresh period)**: Larger R → lower overhead but potentially stale grouping. Smaller R → more responsive but higher compute cost.
  - **r (sketch width)**: Smaller r → faster cosine computation but higher approximation error; must satisfy r ≥ Θ(γ⁻² log K) to preserve threshold decisions.

- **Failure signatures**:
  - *Too many colors (m ≈ K)*: Conflict graph too dense; τ may be too strict or tasks genuinely conflict. Consider increasing τ or accepting some interference.
  - *Unstable grouping across refreshes*: R too small or β too low; increase EMA smoothing or refresh period.
  - *No improvement over uniform baseline*: Conflicts may be negligible (large backbone, few tasks); scheduler naturally reduces to joint training in this case.

- **First 3 experiments**:
  1. **Sanity check on synthetic 2-task setup**: Manually set gradients with known cosine (e.g., −0.5), verify scheduler separates them into different groups and that descent bound holds numerically.
  2. **Ablation on refresh period R**: Run on a benchmark (e.g., NYUv2 subset) with R ∈ {4, 16, 64, 256}. Plot validation loss vs. R and wall-clock time to identify Pareto frontier.
  3. **Combine with existing optimizer**: Run SON-GOKU + PCGrad vs. PCGrad alone on CIFAR-10 MTL setup. Confirm synergy: scheduler separates major conflicts, PCGrad handles residual within-group interference.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the formal concentration guarantees for alternative task affinity measures (e.g., TAG's lookahead loss) when integrated into SON-GOKU's scheduling pipeline?
- Basis in paper: [explicit] Appendix P.1.4 states: "Deriving a formal concentration result for TAG's affinity would be an interesting extension for future works."
- Why unresolved: The paper proves graph recovery guarantees only for EMA-based cosine similarity, not for richer affinity measures that directly measure loss-level transfer effects.
- What evidence would resolve it: A formal proof showing concentration bounds for TAG-style lookahead loss around population affinities, with sample complexity analysis similar to Appendix B.

### Open Question 2
- Question: Why does optimizer-algorithm alignment differ between classification and regression tasks (AdaTask excels on classification; PCGrad excels on regression)?
- Basis in paper: [explicit] Section 7.3.1 notes this empirical pattern and offers hypotheses about gradient variance and smoothness, but provides no definitive explanation.
- Why unresolved: The observed synergy between scheduler and specific optimizers is documented but the underlying mechanism remains conjectural.
- What evidence would resolve it: Controlled experiments varying gradient variance/smoothness properties independently of task type, or theoretical analysis linking gradient statistics to optimizer-scheduler interactions.

### Open Question 3
- Question: How does SON-GOKU's performance scale with the number of tasks (K), particularly for K >> 40?
- Basis in paper: [inferred] Experiments use 4–8 tasks primarily; timing tests go to K=40. Appendix R.1.5 discusses persistent interference in high-capacity models with many tasks but lacks empirical validation at large K.
- Why unresolved: The O(K²r/R) amortized complexity suggests scaling challenges, but empirical performance degradation patterns at large K are uncharacterized.
- What evidence would resolve it: Experiments on benchmarks with 50–100+ tasks showing whether grouping quality and final performance degrade gracefully or catastrophically.

### Open Question 4
- Question: What are principled methods for automatically selecting the conflict threshold τ* and refresh period R for new problem domains?
- Basis in paper: [inferred] Appendix O discusses heuristics (annealing R, adapting based on edge-flip rates) but provides no closed-form or learning-based selection criteria validated across domains.
- Why unresolved: Current approach relies on manual tuning; the relationship between task properties (noise, drift rate, K) and optimal hyperparameters remains unquantified.
- What evidence would resolve it: A meta-learning or validation-based framework for hyperparameter selection, with experiments showing generalization across dataset families.

## Limitations

- **Computational overhead**: Each refresh requires O(K²r) operations for cosine similarity computation, which becomes significant for large K, though sketching reduces this to O(Kr) with approximation error.
- **Parameter sensitivity**: Performance depends critically on τ, R, and β values, with the paper providing limited guidance on parameter selection beyond specific experimental values.
- **Sparse conflict assumption**: The method assumes τ-compatibility can effectively partition tasks; in scenarios with high interference density, the scheduler may degrade to single-task updates, losing MTL benefits.

## Confidence

- **High confidence**: The descent preservation guarantee under τ-compatibility (Mechanism 1) is mathematically rigorous with complete proofs in Section 5.1 and Appendix E. The Welsh-Powell coloring bounds (Δ+1 colors) are well-established in graph theory with proof in Appendix G-H.
- **Medium confidence**: The theoretical analysis of EMA concentration for exact graph recovery (Appendix B.4-B.5) provides guarantees, but real-world gradient noise and non-stationarity may affect practical performance. The synergy with PCGrad and AdaTask is demonstrated empirically but lacks theoretical explanation.
- **Low confidence**: The choice of τ* and R remains largely heuristic, with the paper providing limited guidance on parameter selection beyond specific experimental values.

## Next Checks

1. **Extreme interference test**: Create a synthetic MTL problem with deliberately high gradient conflicts (e.g., 90% of task pairs have negative cosine similarity). Evaluate whether SON-GOKU gracefully degrades or catastrophically fails, and compare against naive uniform sampling.

2. **Scaling experiment**: Test SON-GOKU on a high-task-count MTL problem (K=20-50) to assess computational overhead and scheduling effectiveness. Measure the ratio of coloring time to total training time and the evolution of color count (m) over training.

3. **Ablation on gradient estimation**: Replace EMA with alternative estimators (running average, instantaneous gradients, or exponential forgetting with different β values). Quantify the impact on task grouping stability and overall MTL performance to validate the EMA design choice.