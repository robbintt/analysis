---
ver: rpa2
title: Meta-information Guided Cross-domain Synergistic Diffusion Model for Low-dose
  PET Reconstruction
arxiv_id: '2512.22237'
source_url: https://arxiv.org/abs/2512.22237
tags:
- image
- reconstruction
- diffusion
- mig-dm
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of low-dose PET imaging, which
  is crucial for reducing patient radiation exposure but suffers from noise interference,
  reduced contrast, and difficulty preserving physiological details. The proposed
  method, MiG-DM (Meta-information Guided Cross-domain Synergistic Diffusion Model),
  integrates comprehensive cross-modal priors to generate high-quality PET images.
---

# Meta-information Guided Cross-domain Synergistic Diffusion Model for Low-dose PET Reconstruction

## Quick Facts
- arXiv ID: 2512.22237
- Source URL: https://arxiv.org/abs/2512.22237
- Authors: Mengxiao Geng; Ran Hong; Xiaoling Xu; Bingxuan Li; Qiegen Liu
- Reference count: 40
- Primary result: MiG-DM achieves PSNR of 46.15 dB and SSIM of 0.9884 at dose reduction factor 20 on UDPET dataset

## Executive Summary
This paper addresses low-dose PET reconstruction by introducing a diffusion model that integrates clinical meta-information and cross-domain processing. The proposed MiG-DM system combines a meta-information encoder that transforms patient parameters into semantic prompts with a dual-domain architecture that processes both projection and image data. Through a cascade of two diffusion models connected by a resampling step, the method achieves superior PET image quality with significant dose reduction while preserving physiological details.

## Method Summary
MiG-DM employs a meta-information encoding module that transforms clinical parameters from DICOM headers into semantic prompts using a CLIP-inspired dual-encoder architecture with LoRA fine-tuning. A cross-domain architecture processes both projection-domain sinogram features through a Sinogram Adapter and image-domain features through a U-Net backbone. Two cascaded diffusion models (SD1 and SD2) are connected via a resampling step that balances structural fidelity from projection priors with semantic accuracy from meta-information guidance.

## Key Results
- Achieves PSNR of 46.15 dB and SSIM of 0.9884 on UDPET dataset at DRF=20
- Outperforms state-of-the-art methods in enhancing PET image quality and preserving physiological details
- Demonstrates stable clinical metrics (ΔSUVmax, TBR, CR) across varying dose levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Injecting clinical meta-information (patient weight, dose, SUV) via text prompts improves physiological detail preservation in reconstruction
- Mechanism: Dual-encoder architecture aligns text-based meta-information with PET image features using contrastive learning, with conditioning features guiding diffusion model via cross-attention
- Core assumption: Textual meta-parameters contain sufficient signal to resolve functional-semantic ambiguities in low-dose images
- Evidence anchors: Abstract states meta-information enables cross-modal alignment; Section III.B describes MI-encoder with LoRA module; Limited direct evidence in corpus
- Break condition: If meta-parameters are uncorrelated with local image noise distribution, conditioning may act as noise rather than signal

### Mechanism 2
- Claim: Fusing projection-domain (sinogram) features with image-domain features enhances global physical consistency
- Mechanism: Sinogram Adapter processes raw sinograms to extract global structural features, transformed via Cross-Domain Synergistic Mapper into image-domain features added to primary diffusion model
- Core assumption: Local convolution operations in projection domain induce global effects in image domain, providing physics knowledge missed by image-domain-only models
- Evidence anchors: Section III.A states local operations induce global effects; Section III.C describes projection-domain guidance in final four encoder stages; ID 13854 supports diffusion priors in sparse reconstruction
- Break condition: If CDSM transformation fails to align projection features with image feature resolutions, addition may introduce artifacts

### Mechanism 3
- Claim: Cascade of two diffusion models connected by resampling step balances structural fidelity and semantic accuracy
- Mechanism: SD1 establishes physical structure guided by sinogram priors, output re-noised to timestep N as starting point for SD2 guided by meta-information
- Core assumption: Structural information decays at different rate than semantic information during diffusion forward process, allowing optimal trade-off point N* to exist
- Evidence anchors: Section III.C describes SD1/SD2 cascade with resampling step; Table VI shows SD1-to-SD2 cascade outperforms reverse order
- Break condition: If N is too low, SD2 lacks canvas for semantic details; if too high, structural integrity from SD1 is destroyed

## Foundational Learning

**Conditional Diffusion Models (DDPM/cDDPM)**
- Why needed here: Entire reconstruction relies on reversing noise process conditioned on data and priors; understanding how to inject conditions is essential
- Quick check question: How does the model modify reverse denoising step ε_θ(x_t, t) to accept condition c (e.g., text embedding)?

**Contrastive Language-Image Pre-training (CLIP)**
- Why needed here: Basis for MI-Encoder; understanding how to align distinct modalities via cosine similarity is essential
- Quick check question: In contrastive loss L_Con, how does temperature parameter τ affect separation of embeddings?

**PET Sinogram Physics**
- Why needed here: Implementing SinoA requires understanding sinogram represents Radon transform lines of response, distinct from image domain
- Quick check question: Why does local change in sinogram domain correspond to global "streak" or structural change in reconstructed image domain?

## Architecture Onboarding

**Component map:**
MI-Encoder (ViT/Transformer + LoRA) -> SRM (U-Net) -> SinoA/CDSM -> SD1 (U-Net with F_s addition) -> Resample -> SD2 (U-Net with F_MI cross-attention)

**Critical path:**
1. Train/Fine-tune MI-Encoder on Prompt-Image pairs
2. Train SRM on Sinogram pairs  
3. Train SD1 with frozen SinoA features on Image pairs
4. Connect via Resample: x̂_SD1 → add noise → x_N → SD2

**Design tradeoffs:**
- LoRA Rank (r=4): Paper claims small rank works, but verify convergence; higher rank might overfit to text encoding
- Resample Step (N=50): Critical hyperparameter; paper analytically derives optimal N, but dataset-dependent in practice

**Failure signatures:**
- "Washed out" images: Resample N too high (N ≈ T), losing structural conditioning from SD1
- Artifacts in anatomy: SinoA misalignment; projection domain features conflicting with image features in SD1 encoder
- Semantic Hallucination: MI-Encoder misaligning prompts, causing SD2 to "correct" non-existent pathologies

**First 3 experiments:**
1. Baseline Alignment Check: Validate MI-Encoder alignment accuracy before training diffusion model; if prompt-to-image matching is random, stop
2. Ablation on Resample N: Run sweep N ∈ [5, 50, 150] on single patient slice; confirm PSNR peaks near 50 as claimed
3. SinoA Injection Test: Compare SD1 with/without F_s addition; if MSE does not drop, check CDSM feature scaling

## Open Questions the Paper Calls Out
- How does performance generalize to multi-institutional datasets with distinct scanner geometries and varying radiotracers beyond 18F-FDG?
- Can optimal resampling timestep N be derived dynamically per image rather than set as fixed global hyperparameter?
- Does slice-by-slice 2D reconstruction lead to z-axis discontinuities, and would 3D implementation improve volumetric consistency?

## Limitations
- Clinical relevance of cross-attention conditioning on textual meta-information not validated on patient outcomes; SUV stability analysis is preliminary
- CDSM adapter architecture lacks full specification, creating reproducibility risk
- Optimal resampling timestep N=50 is analytically derived but dataset-specific; performance may degrade on different PET scanners

## Confidence
- **High:** Architecture components (U-Net backbones, CLIP-style encoders) are well-established in diffusion literature
- **Medium:** Cross-domain integration via CDSM is novel and theoretically justified, but empirical validation limited to single dataset
- **Low:** Clinical impact claims (preserving physiological details) based on standard metrics without radiologist validation or patient outcome correlation

## Next Checks
1. Test MI-encoder alignment accuracy on held-out patient data before training diffusion models; require >80% prompt-image matching accuracy
2. Sweep resampling timestep N across range [40, 50, 60, 70] on clinical dataset to verify PSNR stability
3. Perform radiologist review of MiG-DM outputs vs. LD-PET and ground truth to assess preservation of anatomical landmarks and lesion conspicuity