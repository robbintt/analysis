---
ver: rpa2
title: 'Dual Mechanisms of Value Expression: Intrinsic vs. Prompted Values in Large
  Language Models'
arxiv_id: '2509.24319'
source_url: https://arxiv.org/abs/2509.24319
tags:
- value
- prompt
- intr
- prompted
- intrinsic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper systematically examines the two distinct mechanisms\
  \ by which large language models express human values\u2014intrinsic expression,\
  \ reflecting inherent values learned during training, and prompted expression, elicited\
  \ through explicit instructions. By analyzing value representations at both the\
  \ vector level (using difference-in-means methods) and the neuron level (identifying\
  \ MLP neurons that drive value expression), the authors reveal that while these\
  \ mechanisms share substantial common components crucial for inducing value expression,\
  \ they also possess unique components with distinct functional roles."
---

# Dual Mechanisms of Value Expression: Intrinsic vs. Prompted Values in Large Language Models

## Quick Facts
- **arXiv ID**: 2509.24319
- **Source URL**: https://arxiv.org/abs/2509.24319
- **Reference count**: 40
- **Primary result**: Large language models express human values through two distinct mechanisms—intrinsic (learned during training) and prompted (elicited via instructions)—with shared components encoding value semantics and unique components driving diversity vs. compliance tradeoffs

## Executive Summary
This paper reveals that large language models express human values through two distinct mechanisms: intrinsic expression reflecting values learned during training, and prompted expression elicited through explicit instructions. Using difference-in-means vector extraction and MLP neuron analysis, the authors identify shared components that encode the circular structure of Schwartz's basic human values, while unique components drive either lexical diversity (intrinsic) or instruction compliance (prompted). The findings demonstrate that while both mechanisms are necessary for effective value expression, they serve complementary functions—intrinsic mechanisms enable more natural and diverse value expression, whereas prompted mechanisms offer stronger steerability and instruction-following capabilities, even in safety-critical tasks like jailbreaking.

## Method Summary
The authors analyze value expression mechanisms by generating paired responses (intrinsic: empty prompt; prompted: value-targeting system prompts) for 26,334 value-relevant queries. They extract value vectors via difference-in-means on token-averaged residual activations, then identify value neurons by projecting MLP output weights onto the 2D subspace spanned by intrinsic and prompted vectors. SVD decomposition separates shared components (encoding value semantics and Schwartz's circular structure) from unique components (promoting diversity vs. compliance). Steering experiments apply these vectors or amplify relevant neurons to validate causal effects on value expression, diversity, and instruction-following.

## Key Results
- Shared components across intrinsic and prompted mechanisms recover Schwartz's theoretical circular structure of human values (R² = 0.725)
- Intrinsic-unique components promote lexical diversity, increasing distinct-n, entropy, and EAD scores in generated responses
- Prompted-unique components function as a general compliance channel, dramatically increasing jailbreak success rates (97.2% → 97.2% AdvBench, 23.8% → 90.4% HarmBench)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Shared components encode the core semantic structure of human values, capturing Schwartz's circular relationships among universal values
- **Mechanism**: SVD decomposition of value vectors extracts the first singular vector as the shared axis, which recovers the theoretical structure where similar values cluster and opposing values separate
- **Core assumption**: Value semantics are linearly represented in activation space; difference-in-means vectors capture meaningful semantic directions
- **Evidence anchors**: Figure 8 shows PCA of shared value axes recovering Schwartz's structure (72.5% variance in first two PCs); Procrustes analysis confirms R² = 0.725
- **Break condition**: If shared components fail to recover Schwartz's structure under Procrustes analysis or show no geometric organization across random initializations

### Mechanism 2
- **Claim**: Intrinsic-unique components promote lexical diversity by activating on broader contextual cues and increasing logits for wider vocabulary
- **Mechanism**: Intrinsic-unique neurons respond to contextual features co-occurring with values in natural language rather than explicit keywords, inducing higher-entropy distributions at the final layer
- **Core assumption**: Intrinsic mechanism reflects pretraining on diverse, instruction-free text where values appear in varied linguistic contexts
- **Evidence anchors**: Table 2 shows intrinsic steering has higher Distinct-n, Entropy, and EAD scores; Figure 9 shows higher logit entropy; neuron explanations show broader contextual activation
- **Break condition**: If intrinsic-unique steering reduces rather than increases lexical diversity metrics or shows narrow keyword activation

### Mechanism 3
- **Claim**: Prompted-unique components strengthen instruction compliance across tasks, functioning as a general "compliance channel"
- **Mechanism**: The delta vector (prompted minus intrinsic) shows consistent direction across all ten values (mean cosine similarity 0.476), amplifying attention to explicit instructions and promoting prompt-related keyword repetition
- **Core assumption**: Prompted-unique direction encodes instruction-following capacity developed during alignment training
- **Evidence anchors**: Table 25/26 show jailbreak ASR increases dramatically with steering; delta vector accounts for 48%-68% of variance across values
- **Break condition**: If prompted-unique steering fails to improve instruction compliance or shows value-specific rather than consistent direction

## Foundational Learning

- **Concept: Linear Representation Hypothesis**
  - **Why needed here**: The entire methodology assumes value semantics are encoded as linear directions in activation space
  - **Quick check question**: Can you explain why a linear probe trained on residual stream activations might capture semantic concepts, and why this might or might not imply causality?

- **Concept: Difference-in-Means Vector Extraction**
  - **Why needed here**: Core method constructs value vectors by subtracting mean activations of "value unexpressed" from "value expressed" responses
  - **Quick check question**: What does the difference-in-means vector represent geometrically, and why might it outperform logistic regression probes for steering?

- **Concept: MLP Neuron Decomposition in Transformers**
  - **Why needed here**: Value neurons are identified by projecting MLP output weight vectors onto value subspaces
  - **Quick check question**: Given the residual update formula Δx = Σᵢ σ(⟨x, w_in,i⟩)w_out,i, how can you determine which neurons contribute most to a specific direction?

## Architecture Onboarding

- **Component map**: Value vectors (difference-in-means from residual stream) -> Value neurons (MLP output weights projecting onto value subspace) -> Shared/unique decomposition (SVD-based factorization by angle to axes)

- **Critical path**: 1) Generate paired intrinsic/prompted responses 2) Classify as expressed/unexpressed via LLM evaluator 3) Extract value vectors via difference-in-means 4) Identify value neurons via SVD decomposition 5) Decompose into shared/unique components 6) Validate via steering experiments

- **Design tradeoffs**: Steerability vs. diversity (prompted offers stronger control but reduced diversity), intervention strength vs. capability degradation (higher coefficients improve expression but risk MMLU drop), token averaging vs. positional specificity (full-response averaging works best)

- **Failure signatures**: Keyword overfitting (repetitive value-specific terms), geometric collapse (shared axes fail to recover Schwartz's structure), jailbreak vulnerability (dramatic ASR increase), cross-lingual degradation (steering effectiveness drops)

- **First 3 experiments**: 1) Basic steering validation with α ∈ [1,10] across layers 0-14 measuring PVQ improvement vs. MMLU degradation 2) Neuron amplification test comparing shared/intrinsic-unique/prompted-unique neurons at β = 7.0 3) Compliance channel probe applying mean delta vector to jailbreaking task measuring ASR@9

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Do intrinsic-unique and prompted-unique components emerge strictly from pre-training versus instruction-tuning dynamics, or do they evolve continuously throughout training?
- **Basis**: Appendix O hypothesizes pre-training vs. RLHF origins but provides no causal evidence
- **Why unresolved**: Study analyzes fully trained models, offering only post-hoc theoretical interpretations
- **What evidence would resolve it**: Training runs with periodic checkpoint analysis to observe when separation between shared and unique components stabilizes

### Open Question 2
- **Question**: Does prompted-unique compliance channel merely modulate existing capabilities or drive acquisition of new skills?
- **Basis**: Appendix K shows compliance improvement within capability but not constraint-following where base model struggles
- **Why unresolved**: Demonstrates style/instruction following but leaves boundary between "expression modulation" and "capability enhancement" open
- **What evidence would resolve it**: Applying prompted-unique vector to tasks outside model's pre-training distribution to measure capability transfer

### Open Question 3
- **Question**: Are shared/unique geometric components artifacts of difference-in-means extraction method or robust under alternative techniques?
- **Basis**: Section 2 and 3.1 select difference-in-means over SAEs/linear probes without validating method invariance
- **Why unresolved**: Different extraction methods might produce orthogonal "shared" subspaces
- **What evidence would resolve it**: Comparing decomposition stability when vectors are extracted using SAEs, linear probes, or contrastive methods

## Limitations
- Data and methodology constraints limit generalizability (unreleased full dataset, 30° angle threshold arbitrariness)
- Causal attribution challenges remain unresolved (ablations not performed, compliance interpretation plausible but unproven)
- Safety implications introduce ethical constraints (jailbreak vulnerability reveals compliance-safety tradeoff)

## Confidence
- **High confidence**: Shared components recover Schwartz's circular structure, intrinsic mechanisms promote lexical diversity, prompted mechanisms strengthen instruction compliance
- **Medium confidence**: Two-mechanism framework is well-supported but may oversimplify, neuron-level decomposition is methodologically sound but implementation-dependent
- **Low confidence**: Cross-lingual generalization claims and precise functional roles of intrinsic-unique vs. prompted-unique neurons

## Next Checks
1. **Ablation study for causal validation**: Systematically ablate top-100 neurons in each category (shared, intrinsic-unique, prompted-unique) for one value and measure impact on steering effectiveness and baseline expression

2. **Alternative representation baseline**: Compare difference-in-means approach against logistic regression probes on same classification task, measuring both steering effectiveness and interpretability via input saliency maps

3. **Safety intervention test**: Apply prompted-unique steering to model with known safety training and measure not just jailbreak success rates but also recovery of safety alignment when steering is removed, quantifying persistence and reversibility of compliance override