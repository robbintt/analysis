---
ver: rpa2
title: Large Causal Models from Large Language Models
arxiv_id: '2512.07796'
source_url: https://arxiv.org/abs/2512.07796
tags:
- causal
- democritus
- graph
- manifold
- topic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DEMOCRITUS, a system that builds large causal
  models (LCMs) by leveraging large language models (LLMs) to extract and organize
  causal claims across diverse domains. Unlike traditional narrow domain causal inference,
  DEMOCRITUS uses an LLM to propose topics, generate causal questions, and extract
  plausible causal statements, then structures these into relational causal triples
  and embeds them into manifolds using a Geometric Transformer.
---

# Large Causal Models from Large Language Models

## Quick Facts
- arXiv ID: 2512.07796
- Source URL: https://arxiv.org/abs/2512.07796
- Reference count: 9
- Primary result: DEMOCRITUS builds large causal models by extracting LLM-generated causal claims and embedding them into structured manifolds using a Geometric Transformer

## Executive Summary
This paper introduces DEMOCRITUS, a system that constructs large causal models (LCMs) by leveraging LLMs to extract and organize causal claims across diverse domains. Unlike traditional narrow domain causal inference, DEMOCRITUS uses an LLM to propose topics, generate causal questions, and extract plausible causal statements, then structures these into relational causal triples and embeds them into manifolds using a Geometric Transformer. The system produces interpretable local and global causal models across domains like economics, biology, and archaeology. Experiments show that without the Geometric Transformer, UMAP embeddings are unstructured "hairballs," but with GT, coherent domain clusters and causal structures emerge. DEMOCRITUS is not validated against numerical data but provides a hypothesis space for further investigation.

## Method Summary
DEMODICTUS is a six-module pipeline that builds large causal models by extracting causal knowledge from LLMs and embedding it into structured manifolds. It starts with a breadth-first topic expansion using LLM prompting, then generates causal questions and statements per topic. These statements are parsed into relational triples forming a multi-relational graph, which is processed by a Geometric Transformer with higher-order message passing (including triangle-level aggregation). The resulting node embeddings are reduced via UMAP to produce interpretable 2D/3D manifolds showing domain clusters and causal structure. The system currently relies entirely on LLM outputs without validation against ground truth data.

## Key Results
- DEMOCRITUS produces interpretable causal manifolds across economics, biology, and archaeology domains
- Geometric Transformer creates coherent domain clusters; without GT, UMAP produces unstructured "hairballs"
- LLM calls dominate computation (99.9% runtime); GT+UMAP is computationally trivial (~45s for 7k topics)
- False causal claims tend to remain peripheral in the manifold structure

## Why This Works (Mechanism)

### Mechanism 1
LLMs can generate structured causal knowledge fragments when prompted with domain expertise roles. A high-quality LLM (Qwen3-Next-80B-A3B-Instruct) is prompted in stages to: (1) propose domain subtopics via breadth-first expansion, (2) generate causal questions, (3) articulate causal statements in "X causes Y" format. This converts latent LLM knowledge into explicit textual fragments. Core assumption: The LLM's training data contains sufficient causal knowledge about the target domains, and this knowledge is retrievable via targeted prompting.

### Mechanism 2
Extracting relational triples and constructing multi-relational graphs preserves causal structure across thousands of statements. Causal statements are parsed into (subject, relation, object) triples with typed relations (causes, increases, reduces, leads to). These form a directed multi-relational graph where nodes are variable phrases and edges carry relation types and domain labels. Core assumption: OpenIE-style triple extraction reliably captures the causal semantics intended in the LLM's statements.

### Mechanism 3
Geometric Transformer (GT) with higher-order message passing creates coherent manifold structure from otherwise unstructured causal graphs. GT performs message passing along edges (1-simplices) and triangles (2-simplices). Nodes receive aggregated messages from neighbors weighted by relation type and domain. This smooths inconsistencies and captures higher-order causal chains. UMAP then produces 2D/3D visualizations. Core assumption: Higher-order motifs (triangles) in causal graphs encode meaningful transitive structure that standard edge-based GNNs miss.

## Foundational Learning

- **Message passing neural networks (MPNNs) on graphs**
  - Why needed here: GT extends standard MPNNs by adding triangle-level (2-simplex) aggregation. Understanding basic graph neural networks is prerequisite.
  - Quick check question: Can you explain how node embeddings are updated by aggregating neighbor information in a standard GNN?

- **Simplicial complexes and higher-order topology**
  - Why needed here: The paper frames causal graphs as simplicial sets with edges as 1-simplices and triangles as 2-simplices. GT operates on this structure.
  - Quick check question: What is a k-simplex, and how does a 2-simplex differ from a triangle in a standard graph?

- **UMAP dimensionality reduction**
  - Why needed here: The final manifold visualization uses UMAP on GT embeddings. Understanding manifold assumptions (local connectivity preservation) helps interpret results.
  - Quick check question: How does UMAP balance preserving local versus global structure compared to t-SNE?

## Architecture Onboarding

- **Component map**: Topic graph (LLM BFS expansion) → JSONL topic hierarchy → Causal questions/statements (LLM) → JSONL causal texts → Triple extraction → Multi-relational directed graph → Geometric Transformer + UMAP → Manifold embeddings → Topos slice storage

- **Critical path**: Modules 1-3 are LLM-bound (99.9% of compute time per Table 3). Module 5 (GT+UMAP) is computationally trivial (~45s for 7k topics). Scaling requires optimizing LLM calls, not GT.

- **Design tradeoffs**:
  - BFS depth vs. cost: Depth 5 with 7k topics takes ~16 hours (Table 3). Depth 2 with 100 topics takes ~4 minutes.
  - Active vs. exhaustive: Paper proposes utility-guided expansion (Section 11) but current implementation uses naive BFS.
  - GT complexity: Adding triangle channels improves structure detection (Table 2: 100% vs 54.87% on triangle detection) but increases implementation complexity.

- **Failure signatures**:
  - "Hairball" UMAP output → GT not applied or incorrectly configured
  - Sparse graphs with isolated components → LLM undergenerating or triple extraction failing
  - No domain clustering → Domain labels not propagated through pipeline
  - Excessive runtime → LLM calls unbounded; need topic caps or active selection

- **First 3 experiments**:
  1. Replicate baseline comparison: Run Modules 1-4 only, apply UMAP directly. Confirm "hairball" output matches Figure 12. Then add GT (Module 5) and verify structured output.
  2. Scale test with depth limits: Compare depth-2 (100 topics) vs depth-3 (500 topics) on a single domain. Measure graph statistics (node count, edge count, connected components) and manifold coherence.
  3. Noise injection test: Add 5-10% reversed causal statements to a clean slice. Measure whether false claims remain peripheral (low-degree nodes) as claimed in Section 10.4.

## Open Questions the Paper Calls Out

### Open Question 1
How stable are the generated causal graphs and manifold embeddings across repeated runs of the DEMOCRITUS pipeline with identical configurations? While the authors expect low variance, they note that quantitative metrics have not yet been reported.

### Open Question 2
Is the global causal structure robust to the injection of factually incorrect or conflicting causal statements ("hallucinations")? The system relies on LLMs which can hallucinate; the authors hypothesize that false claims remain on the "low-degree fringe" but have not yet quantified this effect.

### Open Question 3
Can the qualitative causal claims extracted by DEMOCRITUS be validated against numerical data to estimate effect sizes? The current system is purely a hypothesis generation tool that structures textual claims without verifying identifiability or causal correctness against observational or experimental datasets.

## Limitations

- DEMOCRITUS does not validate extracted causal claims against ground truth data or established scientific literature
- The full Geometric Transformer architecture is deferred to a forthcoming paper, leaving implementation details incomplete
- The paper does not address how to handle contradictory causal claims that may arise from different domains or sources

## Confidence

- **High confidence**: The basic pipeline architecture (LLM → triples → GT + UMAP) is clearly specified and the qualitative improvement in manifold structure is demonstrated
- **Medium confidence**: The claim that LLM training data contains sufficient causal knowledge for diverse domains is plausible but untested
- **Low confidence**: The system's ability to produce scientifically valid causal models without validation against empirical data or established causal discovery methods

## Next Checks

1. **Cross-domain consistency test**: Select a domain with established causal knowledge (e.g., economics) and compare DEMOCRITUS output against known causal relationships. Measure precision and recall of correctly identified causal links.

2. **Ablation study on GT components**: Systematically disable edge-only vs. triangle-only vs. combined message passing in GT. Quantify impact on manifold coherence metrics (intra-cluster variance, silhouette score) across different graph densities.

3. **Temporal stability analysis**: Run DEMOCRITUS monthly on the same seed topics. Measure stability of emerging causal clusters and identify which domains show high volatility vs. consistency in their causal structures.