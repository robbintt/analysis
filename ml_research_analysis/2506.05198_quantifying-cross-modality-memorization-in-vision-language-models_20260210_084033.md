---
ver: rpa2
title: Quantifying Cross-Modality Memorization in Vision-Language Models
arxiv_id: '2506.05198'
source_url: https://arxiv.org/abs/2506.05198
tags:
- training
- image
- data
- description
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates cross-modality memorization in vision-language
  models, focusing on how factual knowledge learned in one modality transfers to another.
  The authors introduce a synthetic persona dataset to systematically study knowledge
  transfer between text and image domains.
---

# Quantifying Cross-Modality Memorization in Vision-Language Models

## Quick Facts
- arXiv ID: 2506.05198
- Source URL: https://arxiv.org/abs/2506.05198
- Authors: Yuxin Wen; Yangsibo Huang; Tom Goldstein; Ravi Kumar; Badih Ghazi; Chiyuan Zhang
- Reference count: 16
- Primary result: Significant performance gap exists between source and target modalities in cross-modal knowledge transfer, with image-to-text transfer more effective than text-to-image

## Executive Summary
This paper investigates how factual knowledge learned in one modality (text or image) transfers to another in vision-language models. The authors introduce a synthetic persona dataset to systematically study knowledge transfer between modalities, revealing that models struggle to transfer knowledge effectively across modalities. The research identifies a significant performance gap between source and target modalities, demonstrates challenges in cross-modal unlearning, and proposes data augmentation with in-distribution synthetic image-text pairs as an effective mitigation strategy.

## Method Summary
The authors created a synthetic persona dataset containing factual knowledge about generated characters, then trained vision-language models on single modalities (either text-only or image-only) before evaluating their ability to transfer this knowledge to the other modality. They systematically varied the modality of training data and tested cross-modal performance, comparing transfer effectiveness in both directions. The study also examined cross-modal unlearning challenges and tested data augmentation strategies using synthetic image-text pairs with varying degrees of distribution alignment.

## Key Results
- Significant performance gap exists between source and target modalities, with image-to-text transfer proving more effective than text-to-image transfer
- Vision-language models exhibit challenges with cross-modal unlearning, making it difficult to selectively remove knowledge across modalities
- Models suffer from the "multi-hop curse," struggling with knowledge that requires multiple reasoning steps across modalities
- In-distribution synthetic image-text pairs effectively improve cross-modal transferability, while out-of-distribution data proves less effective

## Why This Works (Mechanism)
The effectiveness of cross-modal knowledge transfer depends on the alignment between the learned representations in different modalities and the nature of the knowledge being transferred. The synthetic persona dataset allows controlled study of how models map factual knowledge between text and image representations. The multi-hop curse suggests that complex reasoning chains spanning multiple modalities create compounding errors that degrade performance.

## Foundational Learning

**Cross-modal representation learning**: Understanding how models encode and align information across different modalities is essential for analyzing transfer effectiveness. Quick check: Verify that the model's embedding spaces show reasonable alignment between text and image representations.

**Knowledge memorization vs. reasoning**: Distinguishing between memorized facts and derived knowledge helps explain why certain types of information transfer more effectively than others. Quick check: Compare performance on directly memorized facts versus those requiring inference.

**Data distribution alignment**: The effectiveness of augmentation strategies depends on how well synthetic data matches the distribution of naturally occurring data. Quick check: Measure statistical similarity between synthetic and real data distributions.

## Architecture Onboarding

**Component map**: Synthetic data generator -> Vision-language model (pre-trained or from scratch) -> Cross-modal evaluation pipeline -> Unlearning assessment module

**Critical path**: Data generation → Model training on single modality → Cross-modal evaluation → Analysis of transfer gaps → Unlearning experiments → Augmentation testing

**Design tradeoffs**: The synthetic dataset enables controlled experiments but may not fully capture the complexity of real-world data distributions. The single-modality training approach isolates transfer effects but may miss benefits of joint training.

**Failure signatures**: Poor cross-modal transfer indicates insufficient alignment between modality representations. Ineffective unlearning suggests persistent cross-modal dependencies. Multi-hop reasoning failures point to limitations in compositional knowledge representation.

**First experiments**:
1. Train model on synthetic text personas only, then evaluate image-based knowledge retrieval
2. Apply cross-modal unlearning to remove specific persona facts, then test persistence across modalities
3. Augment training with in-distribution synthetic image-text pairs and measure transfer improvement

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Synthetic evaluation setup may not generalize to real-world vision-language models trained on naturally occurring image-text pairs
- Cross-modal unlearning experiments are limited in scope and don't explore alternative unlearning techniques
- The study focuses primarily on factual knowledge transfer, potentially overlooking other forms of cross-modal information processing

## Confidence

| Claim | Confidence |
|-------|------------|
| Significant performance gap between source and target modalities | High |
| Cross-modal unlearning is challenging | Medium |
| Vision-language models suffer from the multi-hop curse | Medium |
| In-distribution synthetic image-text pairs improve cross-modal transferability | High |
| Out-of-distribution data augmentation is less effective | High |

## Next Checks
1. Replicate key findings using naturally occurring image-text pairs from real-world datasets to assess generalizability beyond synthetic data
2. Test cross-modal unlearning effectiveness across different model architectures and unlearning techniques
3. Evaluate the proposed in-distribution augmentation strategy's impact on models trained on natural data rather than synthetic personas