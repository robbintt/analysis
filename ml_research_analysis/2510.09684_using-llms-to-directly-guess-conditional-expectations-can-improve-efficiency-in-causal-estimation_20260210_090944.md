---
ver: rpa2
title: Using LLMs to Directly Guess Conditional Expectations Can Improve Efficiency
  in Causal Estimation
arxiv_id: '2510.09684'
source_url: https://arxiv.org/abs/2510.09684
tags:
- causal
- estimation
- embeddings
- final
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using LLM-generated predictions to improve
  causal estimation efficiency in double machine learning (DML). The key challenge
  is estimating conditional expectation functions when high-dimensional confounders
  (e.g., text and image data) make nonparametric learning difficult.
---

# Using LLMs to Directly Guess Conditional Expectations Can Improve Efficiency in Causal Estimation

## Quick Facts
- arXiv ID: 2510.09684
- Source URL: https://arxiv.org/abs/2510.09684
- Reference count: 11
- Primary result: LLM predictions incorporated into double machine learning reduce RMSE and standard errors for causal effect estimation

## Executive Summary
This paper proposes using LLM-generated predictions to improve causal estimation efficiency in double machine learning (DML) when dealing with high-dimensional confounders like text and image data. The key insight is that LLMs can leverage historical knowledge and reasoning to predict outcomes and treatments, serving as valid predictors alongside embeddings to improve nuisance function estimation. In an eBay jewelry auction case study (n=333), incorporating LLM guesses reduced RMSE for log price prediction from 0.889 to 0.736 and decreased robust standard errors by approximately 32% (from 0.248 to 0.168). The approach particularly benefits settings where traditional embedding-based methods struggle with curse-of-dimensionality problems, as LLMs can reason about intermediate latent variables like gold melt value that correlate with outcomes.

## Method Summary
The authors integrate LLM predictions into double machine learning by using the LLM's output as an additional predictor alongside embeddings for estimating conditional expectation functions. This approach leverages the LLM's ability to reason about intermediate latent variables based on historical knowledge, which can be particularly valuable when high-dimensional confounders make nonparametric learning difficult. The LLM predictions are treated as valid predictors that can improve the efficiency of nuisance function estimation in the DML framework, potentially overcoming dimensionality challenges that typically plague traditional embedding-based approaches.

## Key Results
- RMSE for predicting log prices decreased from 0.889 to 0.736 when including LLM guesses
- Robust standard errors for causal effect estimate decreased by approximately 32% (from 0.248 to 0.168)
- Neither estimate was statistically significant in the eBay jewelry auction case study
- LLM predictions leveraged reasoning about intermediate latent variables like gold melt value

## Why This Works (Mechanism)
The method works by leveraging LLMs' unique ability to access and reason about historical knowledge and intermediate latent variables that correlate with outcomes. Traditional embedding approaches struggle with high-dimensional confounders due to curse-of-dimensionality problems in nonparametric learning. LLMs can bridge this gap by providing predictions based on their training data and reasoning capabilities, effectively serving as an external knowledge source that complements the embeddings. This additional signal helps improve the estimation of conditional expectation functions, which are critical components in causal inference frameworks like double machine learning.

## Foundational Learning
- Double Machine Learning (DML): A causal inference framework that uses machine learning to estimate nuisance functions while maintaining valid inference; needed because it provides the causal estimation framework where LLM predictions can be incorporated
- Conditional Expectation Functions: Functions that map covariates to expected outcomes; quick check: can be estimated nonparametrically but become difficult with high-dimensional confounders
- Curse of Dimensionality: The phenomenon where the volume of the feature space grows exponentially with dimensionality, making estimation increasingly difficult; quick check: manifests when traditional embedding methods fail to capture complex relationships
- Nuisance Functions: Functions in causal inference that need to be estimated but are not the primary target of inference; quick check: typically include outcome and propensity score models in treatment effect estimation

## Architecture Onboarding
Component map: LLM predictions -> Nuisance function estimation -> Double ML framework -> Causal effect estimation

Critical path: The LLM generates predictions based on historical knowledge → These predictions are incorporated as predictors alongside embeddings → Nuisance functions are estimated using both LLM predictions and embeddings → Double ML framework uses these estimates to compute causal effects with improved efficiency

Design tradeoffs: Using LLM predictions provides access to historical knowledge but introduces potential bias from model-specific reasoning patterns; embeddings capture direct feature information but suffer from dimensionality issues; combining both approaches balances these strengths and weaknesses

Failure signatures: If LLM predictions are systematically biased or inconsistent across model versions, they could introduce bias into the causal estimates; if the LLM lacks relevant domain knowledge, the predictions may add noise rather than signal; overfitting to the specific LLM model version could reduce generalizability

First experiments: 1) Test whether LLM predictions improve nuisance function estimation in synthetic data with known ground truth; 2) Compare performance across different LLM model versions to assess robustness; 3) Evaluate sensitivity to different prompting strategies and their impact on causal estimate stability

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions beyond those related to generalizability and implementation considerations discussed in the limitations section.

## Limitations
- Results based on single case study (n=333 eBay jewelry auctions) limiting generalizability assessment
- Effectiveness depends heavily on LLM's access to relevant historical knowledge, which may not exist for all causal inference problems
- Improvements could stem from LLM capturing domain-specific patterns rather than addressing dimensionality directly
- Medium confidence in LLM predictions as valid predictors due to potential bias from model version inconsistencies

## Confidence
- LLM predictions improve nuisance function estimation: Medium
- Improvements generalize across domains: Low (based on single case study)
- Method addresses curse-of-dimensionality directly: Medium (alternative explanations possible)
- LLM predictions serve as valid predictors: Medium (bias concerns acknowledged)

## Next Checks
1. Test the approach across multiple domains with different types of high-dimensional confounders to assess generalizability beyond the eBay jewelry auction context
2. Conduct sensitivity analyses to determine how robust the results are to different LLM model versions and prompting strategies
3. Evaluate whether improvements in nuisance function estimation translate to meaningful differences in downstream decision-making or policy recommendations in practical applications