---
ver: rpa2
title: Protein Language Model Zero-Shot Fitness Predictions are Improved by Inference-only
  Dropout
arxiv_id: '2506.14793'
source_url: https://arxiv.org/abs/2506.14793
tags:
- dropout
- fitness
- protein
- zero-shot
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a simple method to improve zero-shot protein
  fitness prediction by injecting dropout layers at inference time into pretrained
  Protein Language Models (PLMs) like ESM2. By adding dropout between the embedding
  and transformer layers and averaging outputs via Monte-Carlo dropout, the approach
  increases model calibration and performance without retraining.
---

# Protein Language Model Zero-Shot Fitness Predictions are Improved by Inference-only Dropout

## Quick Facts
- arXiv ID: 2506.14793
- Source URL: https://arxiv.org/abs/2506.14793
- Reference count: 1
- Key result: Inference-time dropout averaging improves zero-shot protein fitness prediction across model sizes without retraining

## Executive Summary
This paper introduces a simple yet effective method to improve zero-shot protein fitness prediction by injecting dropout layers at inference time into pretrained Protein Language Models (PLMs) like ESM2. By averaging outputs via Monte-Carlo dropout between the embedding and transformer layers, the approach increases model calibration and performance without retraining. Tested on a subset of the ProteinGym DMS dataset across 50 protein families, the method consistently improves Spearman rank correlation coefficients for fitness prediction, with a dropout rate of 0.1 showing optimal results across model sizes (35M, 150M, 15B parameters).

## Method Summary
The method involves injecting a dropout layer between the embedding and transformer layers of a pretrained PLM, then running multiple forward passes (Monte-Carlo dropout) with different dropout masks. The outputs are averaged to produce a more stable fitness proxy. This approach is applied to ESM2 models of various sizes (35M, 150M, 15B parameters) on protein fitness prediction tasks from the ProteinGym dataset, comparing performance with and without dropout layers.

## Key Results
- ESM2 models with inference-only dropout consistently achieve higher Spearman rank correlation coefficients (SRCC) for fitness prediction across 50 protein families
- Optimal dropout rate found to be 0.1, improving performance without excessive variance
- Larger models (15B parameters) require dropout in early transformer layers in addition to embedding dropout for optimal performance
- Improvements most pronounced for smaller models, suggesting dropout helps mitigate overconfidence in limited-parameter architectures

## Why This Works (Mechanism)

### Mechanism 1: Monte-Carlo Dropout Averaging
Averaging stochastic forward passes through an injected dropout layer improves zero-shot fitness prediction quality by inserting dropout between embedding and transformer layers, running 100 forward passes per sequence, and averaging the output log-probabilities to produce a more stable fitness proxy.

### Mechanism 2: Entropy as Out-of-Domain Proxy
The sum-of-log-probabilities scoring function acts as a proxy for model entropy and out-of-domain detection, where OOD inputs produce higher-entropy output distributions (more uniform token probabilities), yielding higher summed log-probabilities; if fitness correlates with OOD-ness, this proxy aligns with fitness.

### Mechanism 3: Model Calibration Without Retraining
Inference-time dropout improves model calibration even when the original PLM was not trained with dropout by approximating a Bayesian ensemble through Monte-Carlo sampling, smoothing overconfident predictions and better reflecting true uncertainty.

## Foundational Learning

- **Monte-Carlo Dropout (Gal & Ghahramani, 2016)**
  - Why needed: Understand how dropout at inference time approximates Bayesian uncertainty estimation through ensemble-like averaging
  - Quick check question: Why does averaging multiple stochastic forward passes produce better uncertainty estimates than a single deterministic pass?

- **Zero-Shot Fitness Prediction in PLMs**
  - Why needed: Grasp how masked language models trained on protein sequences can predict fitness without task-specific supervision
  - Quick check question: How does the log-probability of a mutated sequence relate to its predicted fitness compared to wildtype?

- **Model Calibration**
  - Why needed: Understand what it means for predicted probabilities to be well-calibrated and why this matters for downstream ranking tasks
  - Quick check question: If a model assigns 70% confidence to a set of predictions, what should their actual accuracy be if the model is well-calibrated?

## Architecture Onboarding

- **Component map:**
  Input sequence (amino acids) → Tokenizer → Integer tokens → Embedding layer → Vector representations → [INJECTED] Dropout layer (p=0.1) → Transformer blocks (N layers) → Output head → Log-probability matrix (seq_len × vocab_size) → Scoring function S(L) = Σᵢⱼ Lᵢⱼ → Scalar fitness proxy → [REPEAT 100× with different dropout masks] → Average fitness proxies → Final prediction

- **Critical path:**
  1. Load pretrained ESM2 (any size; paper tested 35M, 150M, 15B)
  2. Inject dropout=0.1 between embedding and first transformer block
  3. For 15B model: additionally inject dropout into first third of transformer layers
  4. For each mutated sequence: run 100 forward passes, average log-prob sums
  5. Rank sequences by averaged fitness proxy; compute Spearman correlation vs. ground truth

- **Design tradeoffs:**
  - **Dropout location:** Embedding-only suffices for small models (35M); larger models require transformer-layer dropout (computationally costlier)
  - **Dropout rate:** Paper finds 0.1 optimal; higher rates increase variance without proportional gain
  - **MC samples:** 100 samples used; fewer samples reduce cost but increase estimator variance
  - **Scoring function:** Simple sum-of-logs used; wildtype-relative scoring (Hsu et al. 2022) could improve but adds complexity

- **Failure signatures:**
  - No SRCC improvement: Check dropout rate (>0.2 may degrade), verify dropout is active at inference (not just training mode)
  - Large model underperforms small model: Likely missing transformer-layer dropout injection
  - High variance across MC samples: May indicate dropout rate too high or model instability on that protein family

- **First 3 experiments:**
  1. Replicate 35M result: Run ESM2-35M on 10 ProteinGym families with/without dropout=0.1 at embedding; verify median SRCC improvement
  2. Ablate dropout placement: Compare embedding-only vs. embedding + first-5-transformer-layers dropout on ESM2-150M
  3. Sensitivity analysis: Sweep dropout rates [0.0, 0.05, 0.1, 0.15, 0.2] and MC samples [10, 25, 50, 100, 200] on 5 families to characterize compute-accuracy frontier

## Open Questions the Paper Calls Out

### Open Question 1
Does inference-only dropout improve zero-shot fitness predictions when using scoring functions that account for wildtype sequence likelihoods (e.g., log-likelihood ratios) rather than simple probability sums? The authors note they used a "simplistic scoring function" and suggest future work can consider more appropriate scoring functions that quantify probability changes relative to the wildtype.

### Open Question 2
Is the observed improvement in fitness prediction explicitly driven by improved model calibration, or does the dropout noise primarily regularize feature variance? The authors state they hypothesize the increase in performance is due to this form of dropout-averaging increasing model calibration, but they do not provide calibration metrics to confirm this mechanism.

### Open Question 3
Is the inference-only dropout method effective across other Protein Language Model architectures (e.g., MSA-transformers like MSA-1b) that rely on multiple sequence alignments rather than single sequences? The experimental scope is limited entirely to the ESM2 model suite, and the method's applicability to other major PLM architectures remains untested.

### Open Question 4
Why does Monte-Carlo dropout improve performance on models that were trained without dropout, effectively violating the standard Bayesian approximation theory? The paper notes the method works "even when the model was not trained with dropouts," which theoretically contradicts the standard Gal & Ghahramani (2016) approximation requiring dropout during training.

## Limitations

- Mechanism remains partially speculative with unclear relationship between dropout variance, entropy, and fitness correlation
- OOD-proxy hypothesis relies on the assumption that fitness correlates with sequence properties making inputs appear out-of-domain, which may not hold universally
- Direct calibration metrics (ECE, reliability diagrams) were not reported to empirically validate the calibration improvement hypothesis

## Confidence

- **High confidence**: The empirical observation that dropout averaging improves Spearman correlation (SRCC) across multiple model sizes and protein families
- **Medium confidence**: The interpretation that this improvement stems from better model calibration, though direct metrics were not reported
- **Low confidence**: The proposed mechanism linking dropout variance to entropy-based OOD detection and subsequent fitness correlation

## Next Checks

1. **Direct calibration analysis**: Measure Expected Calibration Error (ECE) and reliability diagrams for predictions with/without dropout across protein families to verify the calibration hypothesis independently of fitness correlation.

2. **Ablation on scoring function**: Replace the sum-of-log-probabilities scoring with a wildtype-relative scoring function (as in Hsu et al. 2022) while maintaining dropout inference to isolate whether improvements stem from the scoring method or dropout averaging.

3. **Cross-family transferability**: Test whether dropout layers pretrained on one protein family transfer to improve zero-shot prediction on held-out families, which would validate the generality of the calibration improvement beyond specific training distribution alignment.