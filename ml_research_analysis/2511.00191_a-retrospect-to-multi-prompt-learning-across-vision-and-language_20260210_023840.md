---
ver: rpa2
title: A Retrospect to Multi-prompt Learning across Vision and Language
arxiv_id: '2511.00191'
source_url: https://arxiv.org/abs/2511.00191
tags:
- learning
- prompt
- empl
- multi-prompt
- coop
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a principled retrospect for vision-language
  multi-prompt learning by extending the constant modality gap phenomenon to learnable
  prompts and justifying the superiority of multi-prompt augmentation for vision-language
  transfer, both empirically and theoretically. The authors propose an Energy-based
  Multi-prompt Learning (EMPL) approach that generates multiple prompt embeddings
  by drawing instances from an energy-based distribution implicitly defined by Vision-Language
  Models (VLMs).
---

# A Retrospect to Multi-prompt Learning across Vision and Language

## Quick Facts
- **arXiv ID:** 2511.00191
- **Source URL:** https://arxiv.org/abs/2511.00191
- **Reference count:** 40
- **Primary result:** Energy-based multi-prompt learning achieves superior base-to-new generalization and cross-domain transfer while maintaining parameter efficiency

## Executive Summary
This paper provides a principled retrospect for vision-language multi-prompt learning by extending the constant modality gap phenomenon to learnable prompts and justifying the superiority of multi-prompt augmentation for vision-language transfer, both empirically and theoretically. The authors propose an Energy-based Multi-prompt Learning (EMPL) approach that generates multiple prompt embeddings by drawing instances from an energy-based distribution implicitly defined by Vision-Language Models (VLMs). This method achieves a balance between in-domain and out-of-domain open-vocabulary generalization while being parameter-efficient. Comprehensive experiments demonstrate the effectiveness of EMPL across three tasks: base-to-new generalization, cross-domain generalization, and cross-dataset transfer learning. The approach consistently outperforms single-prompt baselines and enhances multi-prompt methods, particularly in improving generalization to unseen classes while maintaining strong performance on in-domain data.

## Method Summary
EMPL extends vision-language prompt learning by introducing energy-based prompt generation via Stochastic Gradient Langevin Dynamics (SGLD) sampling. The method optimizes learnable context vectors while maintaining a frozen CLIP backbone, using an energy function that balances in-domain classification accuracy with exploration of unseen classes. During training, prompts are sampled from an energy-based distribution defined over image-prompt pairs, with the meta-learning objective encouraging both accurate base-class predictions and uncertainty modeling for out-of-domain concepts. The approach operates in an open-vocabulary meta-learning framework where each batch includes both observed and strategically sampled unseen words to enhance generalization.

## Key Results
- EMPL achieves 71.76% harmonic mean on base-to-new generalization, significantly outperforming single-prompt baselines (CoOp: 64.77%) and multi-prompt methods (ProDA: 69.51%)
- On cross-domain generalization, EMPL improves performance on ImageNet-A from 27.36% to 29.66% and ImageNet-R from 57.60% to 59.25%
- For cross-dataset transfer, EMPL enhances ProDA's performance from 49.21% to 51.60% on average across 10 target datasets
- Ablation studies show λ=0.1 optimally balances base-class accuracy and new-class generalization, with performance degrading at extreme values

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multi-prompt augmentation reduces the constant modality gap between visual and textual embeddings more effectively than single-prompt learning.
- **Mechanism:** CLIP's contrastive optimization creates a measurable geometric separation ("modality gap") between image and text embeddings. Prompt learning implicitly reduces this gap. Adding multiple learnable prompt templates further closes the gap by providing diverse "viewpoints" for aligning cross-modal representations, improving transfer without requiring more training data.
- **Core assumption:** The constant modality gap phenomenon observed in fixed CLIP embeddings extends predictably to soft, learnable prompt embeddings.
- **Evidence anchors:**
  - [abstract] "We extend the recent constant modality gap phenomenon to learnable prompts and then, justify the superiority of vision-language transfer with multi-prompt augmentation, empirically and theoretically."
  - [Page 4, Figure 2] Shows magnitude and direction of individual/class modality gaps decreasing as prompts scale from CLIP → CoOp → ProDA(x4).
  - [corpus] No direct corroboration found; corpus papers focus on multi-prompt ensembling strategies but not the modality gap mechanism specifically.
- **Break condition:** If modality gap variance increases significantly with prompt count (violating "constant" approximation), the theoretical justification weakens.

### Mechanism 2
- **Claim:** Single-prompt learning suffers from cross-modal non-identifiability—a theoretical limitation where images with mutually exclusive concepts cannot be distinguished via a single shared prompt template.
- **Mechanism:** When a single prompt template $v$ is optimized under constant modality gap constraints, the embedding geometry forces $f(x_j)$ far from $h_v(c_1)$ for images sharing some concepts but differing in others. The single template "collapses" distinguishing information. Multi-prompt strategies alleviate this by providing multiple embedding pathways that capture diverse semantic aspects.
- **Core assumption:** The constant modality gap holds at both individual and class levels during prompt optimization.
- **Evidence anchors:**
  - [Page 3-4, Propositions 1 & 2] Formal statements of individual-level and population-level cross-modal non-identifiability.
  - [Page 4] Example: A single prompt cannot distinguish "man riding horse" from "horses and cows near river" when querying by exclusive concepts "man" vs "cow."
  - [corpus] Corpus papers describe multi-prompt benefits empirically (ensemble diversity, adaptive debiasing) but do not provide this theoretical non-identifiability framing.
- **Break condition:** If real-world prompt learning violates the constant gap assumption (e.g., high variance in gap direction), the non-identifiability proof may not hold.

### Mechanism 3
- **Claim:** Energy-based prompt generation via SGLD sampling balances in-domain accuracy with out-of-domain (open-vocabulary) generalization.
- **Mechanism:** EMPL defines an energy function $E_\phi(X, H)$ over image-prompt pairs derived from contrastive scores. Prompts are sampled via Stochastic Gradient Langevin Dynamics (SGLD) from $p^{(EBM)}_\phi(H|X)$. The meta-learning objective (Eq. 8) minimizes standard classification loss while maximizing uncertainty over unseen classes $U_i$—encouraging the model to assign low energy to in-domain pairs and high energy (exploration) to out-of-domain concepts.
- **Core assumption:** The EBM formulation accurately captures the joint image-prompt distribution, and SGLD converges to useful samples within practical iteration limits.
- **Evidence anchors:**
  - [Page 5, Eq. 6-9] Formal definition of energy-based conditional prompt distribution and SGLD sampling equations.
  - [Page 5, Proposition 3] Proves that optimization encourages negative correlation between in-domain pairs $p(X,H|T_i)$ and unseen-class distributions $p_\phi(X,H|U_i)$.
  - [corpus] "ΔEnergy" (arXiv:2510.11296) independently uses energy-based optimization for VLM alignment, providing partial corroboration for energy-based approaches in this domain.
- **Break condition:** If SGLD samples are low-quality (e.g., mode collapse, slow mixing), prompt diversity degrades, and the in-domain/out-of-domain balance fails.

## Foundational Learning

- **Concept: Contrastive Language-Image Pre-training (CLIP)**
  - **Why needed here:** EMPL builds directly on CLIP's dual-encoder architecture and contrastive objective. Understanding how image encoder $f$ and text encoder $h$ produce aligned embeddings is prerequisite.
  - **Quick check question:** Can you explain why CLIP uses cosine similarity and a softmax temperature $\gamma$ in its prediction probability (Eq. 1)?

- **Concept: Soft Prompt Learning (CoOp/CoCoOp)**
  - **Why needed here:** EMPL extends single-prompt methods (CoOp) and multi-prompt methods (ProDA). You need to understand how learnable context vectors $v = \{v_1, ..., v_m\}$ replace hand-crafted templates.
  - **Quick check question:** How does CoOp's learnable context differ from CoCoOp's image-conditional prompt generation, and why does CoCoOp improve generalization?

- **Concept: Energy-Based Models (EBMs) and SGLD**
  - **Why needed here:** EMPL's core innovation is reformulating prompt generation as sampling from an EBM. Understanding energy functions, unnormalized densities, and Langevin dynamics is essential.
  - **Quick check question:** Why does SGLD add Gaussian noise $\epsilon \sim N(0, I)$ at each sampling step, and how does step size $\alpha$ affect sample quality?

## Architecture Onboarding

- **Component map:** Input Image x → Visual Encoder f (frozen) → Feature f(x) → Contrastive Score P_φ(X, H)[c] → Meta-Learning Objective (Eq. 8) → Learnable Context φ. Open Vocabulary V → Text Encoder h (frozen) → Class Embeddings h(c; V). Energy Function E_φ(X, H; T_i) ← Learnable Context φ ← SGLD Sampler (generates H_φ).

- **Critical path:**
  1. Initialize learnable context vectors $\phi$ (from CoOp or ProDA checkpoint)
  2. For each task $T_i$ with observed classes $V_i$ and sampled unseen words $U_i$:
     - Forward pass: Compute contrastive scores for image-prompt pairs
     - SGLD sampling: Generate $H_\phi$ via iterative gradient + noise updates (Eq. 9)
     - Compute loss: Standard cross-entropy on $V_i$ + energy term on $U_i$ weighted by $\lambda$
  3. Backprop through $\phi$ only; encoders remain frozen

- **Design tradeoffs:**
  - **$\lambda$ (energy weight):** Higher $\lambda$ → more exploration of unseen classes → better new-class generalization but potential base-class degradation (see Fig. 6)
  - **# of SGLD steps:** More steps → better sample quality but 2-3x inference time overhead
  - **Transformer layers for SGLD:** Applying SGLD to low-level layers increases computation without performance gain (Table 4 recommends 2 layers)
  - **# of prompts:** Performance improves with more prompt samples but with diminishing returns (Fig. 7)

- **Failure signatures:**
  - **Overfitting to base classes:** New-class accuracy drops → increase $\lambda$ or $K-K'$ (unseen words per batch)
  - **Slow inference:** >3x CoOp training time is expected; if higher, check SGLD step count and layer position
  - **Mode collapse in prompts:** All sampled prompts converge to similar embeddings → check SGLD noise scale and step size $\alpha$

- **First 3 experiments:**
  1. **Sanity check:** Reproduce CoOp baseline on ImageNet base-to-new split, then add EMPL with $\lambda=0.1$ and verify ~+7% new-class improvement (Table 1).
  2. **Hyperparameter sweep:** On DTD dataset, sweep $\lambda \in \{0.01, 0.1, 1.0\}$ and unseen words per batch $\in \{1, 2, 4, 8\}$; plot harmonic mean vs. each (reference Fig. 6).
  3. **Cross-domain validation:** Train on ImageNet, evaluate on ImageNet-Sketch and ImageNet-A. Confirm EMPL variants outperform base methods on 7/8 shift scenarios (Table 2).

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the computational overhead of the SGLD-based sampling process in EMPL be reduced to facilitate real-time inference without compromising the balance between in-domain and out-of-domain generalization?
  - **Basis in paper:** [explicit] The authors explicitly list "Reducing the inference cost" as a "crucial issue," noting that EMPL requires triple the training time and double the inference prompts compared to baselines.
  - **Why unresolved:** The stochastic sampling (SGLD) requires multiple iterative steps (Eq. 9) to draw prompts from the energy-based distribution, creating a bottleneck that the current implementation does not optimize.
  - **What evidence would resolve it:** A distilled or one-step sampling variant that matches the Harmonic Mean performance of the current multi-step SGLD approach on the base-to-new generalization benchmark.

- **Open Question 2:** What are the specific theoretical links between the "non-identifiability" issue in single prompts and the learnability or convergence guarantees of multi-prompt learning models?
  - **Basis in paper:** [explicit] The conclusion states that while the paper raises the "first theoretic concern," the field still requires "more sophisticated analytical studies with respect to learnability and optimization theories."
  - **Why unresolved:** The paper provides a theoretical proof for the existence of the non-identifiability issue (Prop 1 & 2) but relies largely on empirical observation to show that multi-prompt augmentation resolves it, without formal convergence guarantees.
  - **What evidence would resolve it:** A formal theoretical framework proving that the energy-based multi-prompt objective (Eq. 8) guarantees the avoidance of non-identifiable solutions during optimization.

- **Open Question 3:** How can the diversity of generated prompts be explicitly quantified and regularized to ensure robustness against the "cross-modal non-identifiability" issue?
  - **Basis in paper:** [explicit] The authors state in the conclusion that "prompt diversity is the key" and suggest that "research on the topic related with the prompt diversity is also inspiring."
  - **Why unresolved:** EMPL generates prompts via an energy-based distribution implicitly, but the paper does not introduce a specific mechanism or metric to enforce or measure diversity among the sampled prompt embeddings.
  - **What evidence would resolve it:** Introducing a diversity metric (e.g., inter-prompt distance) into the loss function and demonstrating a correlation between higher metric scores and improved performance on mutually exclusive concept discrimination.

## Limitations

- The constant modality gap assumption may not hold for learnable prompts, potentially weakening the theoretical foundation of the non-identifiability proofs
- SGLD sampling parameters (step size, noise scale, iterations) are not fully specified, creating uncertainty in reproducibility
- The open-vocabulary meta-learning framework lacks detailed implementation guidance for constructing unseen class sets and vocabulary composition

## Confidence

- **High confidence:** The energy-based multi-prompt generation approach (Mechanism 3) is well-supported by ablation studies and achieves consistent performance gains across three distinct generalization tasks
- **Medium confidence:** The theoretical framework around cross-modal non-identifiability (Mechanism 2) is mathematically rigorous but depends heavily on the constant modality gap assumption
- **Medium confidence:** The extension of the constant modality gap phenomenon to learnable prompts (Mechanism 1) is observed empirically but lacks independent validation

## Next Checks

1. **Modality gap validation:** Measure the variance and directional consistency of modality gaps across different prompt scales (CoOp → ProDA → EMPL) on a held-out dataset to verify the "constant" approximation holds
2. **SGLD sampling quality:** Track prompt embedding diversity metrics (e.g., pairwise cosine similarity, entropy of prompt distributions) during training to ensure SGLD samples maintain meaningful variation rather than collapsing
3. **Cross-vocabulary generalization:** Test EMPL's performance when unseen class sets (U_i) are constructed from entirely different semantic domains than the base classes to validate true open-vocabulary capability beyond simple domain shifts