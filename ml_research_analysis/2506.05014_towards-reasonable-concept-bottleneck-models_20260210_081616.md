---
ver: rpa2
title: Towards Reasonable Concept Bottleneck Models
arxiv_id: '2506.05014'
source_url: https://arxiv.org/abs/2506.05014
tags:
- concept
- concepts
- task
- side-channel
- cream
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces CREAM, a Concept Bottleneck Model that enforces\
  \ expert-defined concept-concept (C-C) and concept-to-task (C\u2192Y) relationships\
  \ through a reasoning graph, while incorporating a regularized side-channel to handle\
  \ incomplete concepts. The method improves interpretability by explicitly modeling\
  \ concept dependencies and easing interventions, and mitigates concept leakage without\
  \ sacrificing performance."
---

# Towards Reasonable Concept Bottleneck Models

## Quick Facts
- arXiv ID: 2506.05014
- Source URL: https://arxiv.org/abs/2506.05014
- Reference count: 40
- Key outcome: CREAM achieves task accuracy on par with black-box models and superior concept importance scores (CCI > 0.5) across iFMNIST, cFMNIST, CUB, and CelebA datasets.

## Executive Summary
This paper introduces CREAM, a Concept Bottleneck Model that enforces expert-defined concept-concept (C-C) and concept-to-task (C→Y) relationships through a reasoning graph, while incorporating a regularized side-channel to handle incomplete concepts. The method improves interpretability by explicitly modeling concept dependencies and easing interventions, and mitigates concept leakage without sacrificing performance. Experiments show that CREAM achieves task accuracy on par with black-box models and superior concept importance scores (CCI > 0.5) across iFMNIST, cFMNIST, CUB, and CelebA datasets. Interventions on directly connected concepts significantly improve task accuracy, and structured reasoning further reduces unintended information flow.

## Method Summary
CREAM uses a representation splitter to divide backbone features into concept-specific (z_C) and side-channel (z_Y) components, trained jointly with a structured reasoning graph (StrNN) that enforces expert-defined C-C and C→Y relationships. The model incorporates dropout on the side-channel to regularize it and prevent dominance, with masking matrices derived from adjacency graphs A_C and A_Y. Mutual exclusivity groups use softmax, while other concepts use sigmoid. The approach aims to maintain high task accuracy while ensuring concepts are meaningful (CCI > 0.5) and reducing concept leakage.

## Key Results
- CREAM achieves task accuracy comparable to black-box models (e.g., iFMNIST ACC_Y ~95%)
- Concept Channel Importance (CCI) exceeds 0.5 for all datasets, indicating meaningful concept use
- Concept leakage eliminated with C→Y masking; side-channel regularization reduces unintended information flow

## Why This Works (Mechanism)
CREAM enforces explicit concept dependencies through a reasoning graph, preventing information bypassing via concept leakage. The regularized side-channel handles incomplete concepts without dominating, ensuring CCI > 0.5. Structured masking (StrNN) and adjacency matrices ensure concepts are used as intended by the expert-defined graph, improving interpretability and intervention effectiveness.

## Foundational Learning
- **Concept Bottleneck Models**: Models that first predict interpretable concepts before the task label. *Why needed*: Enables interpretability and targeted interventions. *Quick check*: Verify concept predictions are binary and correspond to human-interpretable attributes.
- **Concept Leakage**: When models bypass concept bottlenecks and use raw features for task prediction. *Why needed*: Reduces interpretability benefits. *Quick check*: Compare ACC_Y to C_true→Y baseline; leakage if ACC_Y > baseline.
- **Mutual Exclusivity**: Concepts that cannot be true simultaneously (e.g., color categories). *Why needed*: Ensures valid concept predictions. *Quick check*: Verify softmax is applied over correct mutex groups per dataset.
- **Structured Reasoning Graphs (StrNN)**: Neural networks with masking to enforce graph-structured dependencies. *Why needed*: Encodes expert-defined concept relationships. *Quick check*: Confirm adjacency matrices A_C and A_Y match intended graph structures.
- **Concept Channel Importance (CCI)**: Metric quantifying concept contribution to task prediction. *Why needed*: Validates meaningful concept use. *Quick check*: Compute CCI ≥ 0.5 indicates concepts are important.

## Architecture Onboarding

**Component Map**: Backbone (CNN/ResNet) → Representation Splitter → z_C (concept exogenous) + z_Y (side-channel) → StrNN (masked) → Concept/Task Predictions

**Critical Path**: Backbone features → Representation splitter (z_C, z_Y) → StrNN blocks (C-C and C→Y) → Sigmoid/Softmax outputs → Joint loss (L_Y + λ·L_C)

**Design Tradeoffs**: Depth d=0 (masked linear) works best for simplicity and performance; dropout p tuned to balance side-channel regularization (p≈0.75+ for incomplete concepts); λ=1 balances task and concept losses.

**Failure Signatures**: CCI < 0.5 indicates side-channel dominance (increase dropout p); ACC_Y > C_true→Y baseline indicates concept leakage (verify C→Y masking); CUB concept accuracy drops suggest misaligned adjacency constraints.

**3 First Experiments**:
1. **FMNIST sanity check**: Train CREAM on iFMNIST with d=0, p=0.9; verify ACC_Y ~95% and CCI > 0.5.
2. **Concept leakage test**: Compare ACC_Y with/without C→Y masking on any dataset; leakage if ACC_Y drops significantly.
3. **Side-channel dominance**: Vary dropout p (0.5 to 0.95) on iFMNIST; plot CCI vs p to find threshold where CCI > 0.5.

## Open Questions the Paper Calls Out
None

## Limitations
- Exact adjacency matrix construction rules for CUB (bidirected edges, attribute connections) are described qualitatively but not enumerated, potentially affecting faithful reproduction.
- FMNIST CNN architecture details (kernel sizes, channel counts) are unspecified beyond "two convolutional layers," requiring assumptions.
- Mutual exclusivity group memberships must be inferred from graphs, introducing potential misalignment.
- CCI computation implementation details (SAGE) are mentioned but not fully specified, making precise replication uncertain.

## Confidence
- **High Confidence**: Task accuracy comparisons to black-box models, overall CCI > 0.5 trends, and concept leakage elimination via C→Y masking.
- **Medium Confidence**: Specific hyperparameter values (dropout p, learning rates) and StrNN masking effectiveness, as these depend on exact adjacency matrices and side-channel dimensions.
- **Low Confidence**: Exact CCI values and intervention efficiency scores, due to unspecified implementation details in the SAGE computation and adjacency matrix construction.

## Next Checks
1. Verify adjacency matrix construction for CUB by cross-checking concept relationships against provided qualitative descriptions; ensure bidirected edges are correctly implemented within/between attribute types.
2. Confirm FMNIST CNN architecture by testing multiple reasonable configurations (e.g., 3×3 kernels, 32/64 channels) and selecting the one matching reported ACC_Y.
3. Validate CCI computation by implementing SAGE with the specified convergence threshold and imputation strategy, then comparing against reported values for a subset of datasets.