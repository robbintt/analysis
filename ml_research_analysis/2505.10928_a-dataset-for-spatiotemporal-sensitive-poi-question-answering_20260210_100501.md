---
ver: rpa2
title: A Dataset for Spatiotemporal-Sensitive POI Question Answering
arxiv_id: '2505.10928'
source_url: https://arxiv.org/abs/2505.10928
tags:
- dataset
- data
- spatiotemporal
- answer
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces POI-QA, a novel spatiotemporal-sensitive QA
  dataset designed to address the lack of spatiotemporal reasoning evaluation benchmarks.
  Constructed from vehicle trajectory data and POI information, the dataset includes
  over 5 million bilingual QA pairs across four difficulty levels.
---

# A Dataset for Spatiotemporal-Sensitive POI Question Answering

## Quick Facts
- arXiv ID: 2505.10928
- Source URL: https://arxiv.org/abs/2505.10928
- Reference count: 40
- A novel spatiotemporal-sensitive QA dataset with over 5 million bilingual QA pairs constructed from vehicle trajectory data

## Executive Summary
This paper introduces POI-QA, a novel spatiotemporal-sensitive QA dataset designed to address the lack of evaluation benchmarks for spatiotemporal reasoning in question answering systems. The dataset is constructed from real vehicle trajectory data combined with POI information, resulting in over 5 million bilingual QA pairs across four difficulty levels. The dataset evaluates models' ability to reason about spatiotemporal relationships between Points of Interest (POIs) and serves as a benchmark for advancing spatiotemporal-sensitive algorithms. The work highlights significant performance gaps between current state-of-the-art LLMs and human performance, demonstrating persistent limitations in spatiotemporal reasoning capabilities.

## Method Summary
The POI-QA dataset is constructed from real vehicle trajectory data collected in an urban environment, combined with POI information to create spatiotemporal-sensitive question-answer pairs. The dataset includes four difficulty levels ranging from simple POI identification to complex temporal-spatial reasoning tasks. Each QA pair is bilingual (Chinese and English), making it accessible for cross-lingual evaluation. The dataset covers various spatiotemporal reasoning scenarios including temporal relationships between POIs, spatial distributions, and combined spatiotemporal constraints. The construction process ensures diversity in question types while maintaining consistency in difficulty progression across the four levels.

## Key Results
- State-of-the-art LLMs achieve HR@10 of only 0.41 on the easiest POI-QA task, compared to human performance of 0.56
- Performance degrades significantly on higher difficulty levels, demonstrating persistent spatiotemporal reasoning limitations
- The dataset serves as a challenging benchmark for advancing spatiotemporal-sensitive QA algorithms

## Why This Works (Mechanism)
The dataset's effectiveness stems from its grounding in real-world trajectory data, which captures authentic spatiotemporal patterns and relationships between POIs. By leveraging actual vehicle movement data, the dataset ensures that questions reflect genuine spatiotemporal reasoning challenges rather than artificial constructs. The four-tier difficulty structure systematically evaluates different aspects of spatiotemporal reasoning, from basic spatial relationships to complex temporal-spatial dependencies. The bilingual nature of the dataset also enables evaluation of language-specific spatiotemporal reasoning capabilities and cross-lingual transfer.

## Foundational Learning
- **Spatiotemporal reasoning**: Understanding how spatial and temporal dimensions interact in real-world scenarios - needed to evaluate models' ability to process time and space simultaneously; quick check: can models track POI relationships across different time periods
- **Trajectory analysis**: Processing sequential spatial data to extract meaningful patterns - needed to create realistic spatiotemporal relationships; quick check: can models identify common routes and temporal patterns from movement data
- **Bilingual QA evaluation**: Assessing model performance across language contexts - needed to ensure cross-lingual generalization; quick check: does model performance vary significantly between Chinese and English versions
- **Difficulty progression assessment**: Evaluating reasoning complexity across levels - needed to identify specific limitations at different reasoning depths; quick check: can models handle increasing temporal and spatial constraints

## Architecture Onboarding

Component map: Trajectory Data -> POI Information -> QA Pair Generation -> Difficulty Classification -> Dataset Assembly

Critical path: The core pipeline involves collecting vehicle trajectory data, mapping it to POI locations, generating QA pairs based on spatiotemporal relationships, classifying difficulty levels, and assembling the final bilingual dataset. The difficulty classification module is critical as it determines the four-tier structure that enables systematic evaluation of reasoning capabilities.

Design tradeoffs: The dataset prioritizes real-world authenticity over synthetic control, accepting potential biases from the specific urban environment studied. The bilingual approach increases accessibility but may introduce language-specific reasoning patterns that don't generalize universally. The focus on vehicular contexts provides rich spatiotemporal data but may limit applicability to other domains.

Failure signatures: Models typically fail by confusing temporal sequences, misidentifying spatial relationships, or conflating POI attributes. Common errors include treating spatiotemporal relationships as independent spatial or temporal problems rather than integrated reasoning tasks. Performance drops sharply on higher difficulty levels where temporal and spatial reasoning must be combined.

First experiments:
1. Evaluate model performance across all four difficulty levels to establish baseline capabilities
2. Compare cross-lingual performance between Chinese and English QA pairs
3. Analyze error patterns to identify specific spatiotemporal reasoning weaknesses

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset domain specificity to vehicular contexts may limit generalizability to broader spatiotemporal reasoning tasks
- Reliance on Chinese driving patterns and urban layouts could affect cross-cultural applicability
- Evaluation metrics (HR@1 and HR@10) provide limited insight into the nature and quality of incorrect answers

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Dataset Construction and Scale | High |
| Performance Gap Claims | Medium |
| Generalizability Claims | Low |

## Next Checks

1. Conduct cross-cultural validation by testing the dataset with trajectory data from different geographical regions and transportation modes to assess generalizability.

2. Implement detailed error analysis on LLM responses to understand specific failure modes in spatiotemporal reasoning beyond aggregate HR metrics.

3. Design ablation studies comparing model performance on spatiotemporal reasoning tasks with and without access to explicit temporal/spatial features to isolate the impact of these elements on performance.