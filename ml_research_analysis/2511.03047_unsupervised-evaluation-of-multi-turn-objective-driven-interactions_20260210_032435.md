---
ver: rpa2
title: Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions
arxiv_id: '2511.03047'
source_url: https://arxiv.org/abs/2511.03047
tags:
- user
- chat
- assistant
- insurance
- turn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces the first set of unsupervised metrics for
  evaluating multi-turn, objective-driven interactions between humans and AI agents.
  The authors propose three metrics: LLM-guided clustering for labeling user goals,
  a completion detection method based on predicting end tokens in interactions, and
  response tree analysis to quantify LLM uncertainty.'
---

# Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions

## Quick Facts
- arXiv ID: 2511.03047
- Source URL: https://arxiv.org/abs/2511.03047
- Authors: Emi Soroka; Tanmay Chopra; Krish Desai; Sanjay Lall
- Reference count: 40
- Primary result: Introduces first set of unsupervised metrics for evaluating multi-turn, objective-driven human-AI interactions

## Executive Summary
This paper introduces the first set of unsupervised metrics for evaluating multi-turn, objective-driven interactions between humans and AI agents. The authors propose three metrics: LLM-guided clustering for labeling user goals, a completion detection method based on predicting end tokens in interactions, and response tree analysis to quantify LLM uncertainty. Their approach leverages statistical properties of unlabeled data and fine-tuned LLMs to adapt to distributional shifts without relying on human-generated ideal responses or LLM judges. The method achieves high accuracy (up to 0.99 F1-score) on task-specific datasets and outperforms a 70B LLM judge using only 8B fine-tuned models.

## Method Summary
The method introduces three unsupervised evaluation techniques for multi-turn interactions. First, LLM-guided clustering uses an LLM to generate goal summaries, embeds them, applies k-means clustering, then iteratively merges clusters using LLM decisions based on positive/negative examples. Second, completion detection fine-tunes an 8B model with LoRA adapters on domain data augmented with end tags to predict whether interactions are complete. Third, response tree analysis recursively generates all possible LLM responses above a probability threshold to quantify uncertainty through leaf count and maximum log-probability metrics.

## Key Results
- Fine-tuned 8B model achieves 0.98 F1-score on SQL+OS+KB completion detection vs 0.96 for 70B LLM judge
- LLM-guided clustering achieves high stability on single-topic datasets with up to 0.99 F1-score
- Response tree analysis reveals highest uncertainty on specialized datasets like KB+OS+SQL, indicating potential for error detection

## Why This Works (Mechanism)

### Mechanism 1: LLM-Guided Clustering for Goal Labeling
Unlabeled multi-turn interactions can be clustered into interpretable goal categories without prior knowledge of label taxonomy by generating free-form goal summaries via LLM, embedding them, applying k-means for initial over-clustering, then using an LLM to label clusters using positive/negative examples and iteratively merge similar clusters based on cosine similarity.

### Mechanism 2: Completion Detection via Fine-Tuned Distribution Modeling
A fine-tuned 8B model can detect incomplete interactions by modeling the conditional distribution P(next response | conversation prefix) using an end-tag signal, where fine-tuning on domain data with completed interactions augmented with a special end tag allows the model to distinguish complete from incomplete interactions at inference time.

### Mechanism 3: Response Tree for Uncertainty Quantification
The empirical distribution of possible LLM responses can be approximated as a tree, where branch count and log-probability signal response uncertainty without ground-truth labels by recursively generating all response branches where token probabilities exceed a threshold and counting leaf nodes and tracking maximum log-probability.

## Foundational Learning

- **LoRA (Low-Rank Adaptation) Fine-Tuning**: Enables domain adaptation for 8B models to approximate D' distributions without full fine-tuning, critical for cost-effective completion detection. Quick check: Given a base LLaMA3-8B model, what information would you need to decide if LoRA rank-8 adapters are sufficient for your domain shift?

- **Embedding Space Clustering (k-means on semantic vectors)**: Goal labeling requires converting unstructured text to vectors where semantic similarity maps to geometric proximity. Quick check: If two goal summaries have cosine similarity 0.85 but belong to different clusters, what might this indicate about your k_1 initialization?

- **Conditional Probability Distribution P(R|P) in LLMs**: Completion detection and response trees both model the LLM as approximating a token sequence distribution rather than a deterministic function. Quick check: Why does sampling the most probable response (greedy decoding) differ from characterizing the full distribution for uncertainty estimation?

## Architecture Onboarding

- **Component map**: Raw interactions → [LLM Summarizer] → Goal summaries → [Embedding Model] → Vectors → [k-means + LLM Merger] → Cluster labels
- **Critical path**: Completion detection (Mechanism 2) has highest ROI—it requires LoRA fine-tuning but delivers direct actionable signal (incomplete vs. complete). Start here before response trees.

- **Design tradeoffs**: k_1 (initial cluster count): Overestimate increases Phase 1 compute but improves label discovery; paper doesn't specify optimal ratio to expected clusters; α (branch threshold): Lower = more complete tree but higher compute; paper uses α without reporting value; Fine-tuning data size: Insurance (190 samples) underperforms WebShop (175 samples), suggesting task complexity matters more than raw count

- **Failure signatures**: Clustering: High cluster count instability across runs → likely multi-topic dataset, consider hierarchical clustering; Completion: Model outputs ungrammatical end tags → LoRA undertrained or base model too weak (paper notes this on 8B); Response trees: Correlation between leaf count and conversation length → α threshold too permissive

- **First 3 experiments**: (1) Fine-tune LoRA on 50% of your domain data with end tags, evaluate on held-out 50% using truncation to simulate incomplete interactions. Compare against 70B judge on same split; (2) Run Algorithm 1 twice on same data with shuffled order; compute confusion matrix between runs. If diagonal is weak, reduce k_1 or improve summarization prompt with domain context; (3) For interactions where completion detector disagrees with ground truth, generate response trees. Hypothesis: false positives (labeled complete but actually incomplete) should show higher leaf counts than true positives.

## Open Questions the Paper Calls Out
- How does fine-tuning dataset size affect the model's performance on completion labeling?
- Can statistical guarantees be established for the response tree's approximation of conditional response distributions?
- Can the completion detection method be extended to handle interactions where goals are satisfied in the first turn with subsequent follow-up questions?
- Can training strategies incorporate the entire response