---
ver: rpa2
title: Audio Super-Resolution with Latent Bridge Models
arxiv_id: '2509.17609'
source_url: https://arxiv.org/abs/2509.17609
tags:
- audio
- speech
- arxiv
- latent
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: AudioLBM is a latent bridge model for audio super-resolution that
  directly compresses waveforms into a continuous latent space and learns a latent-to-latent
  generation process from low-resolution to high-resolution. This approach fully exploits
  informative prior information in the LR waveform, unlike prior spectrogram-based
  methods that synthesize missing content from uninformative Gaussian noise.
---

# Audio Super-Resolution with Latent Bridge Models

## Quick Facts
- arXiv ID: 2509.17609
- Source URL: https://arxiv.org/abs/2509.17609
- Reference count: 40
- Primary result: AudioLBM achieves state-of-the-art audio super-resolution with 21.5% average LSD improvement and 3.05% ViSQOL gain on any-to-48 kHz tasks.

## Executive Summary
AudioLBM is a latent bridge model for audio super-resolution that directly compresses waveforms into a continuous latent space and learns a latent-to-latent generation process from low-resolution to high-resolution. This approach fully exploits informative prior information in the LR waveform, unlike prior spectrogram-based methods that synthesize missing content from uninformative Gaussian noise. To overcome limited HR training data, AudioLBM incorporates frequency-awareness by conditioning on prior and target sampling rates, enabling explicit any-to-any upsampling learning. For scaling beyond 48 kHz, cascaded LBMs with prior augmentation strategies reduce cascading errors, enabling the first high-quality 96 kHz and 192 kHz audio SR.

## Method Summary
AudioLBM uses a waveform VAE to compress audio into a latent space, then applies a Latent Bridge Model (LBM) - a diffusion transformer - to learn the mapping from LR to HR latents. The key innovation is using the LR latent as an informative prior instead of Gaussian noise, combined with frequency-aware conditioning for any-to-any upsampling. For cascaded SR beyond 48 kHz, deterministic degradation (filtering + latent blurring) is applied during training to simulate and correct cascading errors. The model is trained on mixed speech, audio, and music corpora with dynamic low-pass filtering for LR data generation.

## Key Results
- 21.5% average LSD improvement on any-to-48 kHz tasks
- 3.05% ViSQOL gain compared to prior methods
- First high-quality 96 kHz and 192 kHz audio super-resolution
- State-of-the-art objective and perceptual quality across speech, sound, and music domains

## Why This Works (Mechanism)

### Mechanism 1: Latent-to-Latent Bridge Priors
- **Claim:** Replacing Gaussian noise prior with LR latent improves generation by preserving informative content.
- **Mechanism:** Uses Schrödinger Bridge to interpolate between LR and HR latent distributions, treating LR signal as "Dirac prior" for shorter trajectory.
- **Core assumption:** Compressed LR latent contains sufficient structural information to guide HR recovery.
- **Evidence:** Abstract and Section 3.1 support bridge models replacing Gaussian prior with Dirac prior.

### Mechanism 2: Frequency-Aware Conditioning
- **Claim:** Explicit conditioning on source/target sampling rates enables single "any-to-any" model.
- **Mechanism:** Takes quantized target frequency and continuous prior frequency as tokens, creating continuous function over sampling rates.
- **Core assumption:** Optimal transformation path depends on specific frequency gap.
- **Evidence:** Abstract and Section 3.2 support any-to-any upsampling learning.

### Mechanism 3: Deterministic Prior Augmentation for Cascading
- **Claim:** Deterministic degradation simulates distribution mismatch to prevent error accumulation in cascaded SR.
- **Mechanism:** Applies low-pass filtering and Gaussian blurring to output of previous stage during training of next stage.
- **Core assumption:** Errors are systematic and can be approximated by deterministic operations.
- **Evidence:** Abstract and Section 3.3 support prior augmentation reducing cascading errors.

## Foundational Learning

- **Concept: Schrödinger Bridge / Diffusion Bridges**
  - **Why needed:** Core mathematical replacement for standard diffusion; transport problem between two data distributions.
  - **Quick check:** Does model predict noise ε or data x₀? (Paper notes ε prediction works better in latent space).

- **Concept: Variational Autoencoders (VAEs) for Audio**
  - **Why needed:** System operates in learned latent space; understand compression ratio vs. reconstruction fidelity trade-off.
  - **Quick check:** Why suggest lowering KL weight compared to standard generative VAEs?

- **Concept: Bandwidth Extension & Aliasing**
  - **Why needed:** Audio SR is about synthesizing spectral content above Nyquist frequency; understand low-pass filtering for training pairs.
  - **Quick check:** Why is "effective bandwidth" detection necessary during inference but not just training?

## Architecture Onboarding

- **Component map:** Input Audio → Curvature-aware Frequency Detection → VAE Encoder → Add Frequency/Time Embeddings → DiT Bridge Process (Iterative Sampling) → VAE Decoder → Output Audio

- **Critical path:** Input Audio → Curvature-aware Frequency Detection → VAE Encoder → Add Frequency/Time Embeddings → DiT Bridge Process (Iterative Sampling) → VAE Decoder → Output Audio

- **Design tradeoffs:**
  - **Latent Space:** Waveform-VAE vs. Mel-spectrogram; avoids "removed areas" issue of spectrogram inpainting
  - **KL Regularization:** Reduces KL weight to prioritize reconstruction detail; Bridge model handles generation distribution
  - **Cascade Augmentation:** Random noise vs. Deterministic blur; blur matches deterministic nature of bridge prior

- **Failure signatures:**
  - High-frequency hallucination: Indicates overfitting to artifacts; mitigate via strict f_target ≤ f_eff filtering
  - Over-smoothing: If VAE compression too high or blur augmentation too aggressive
  - Spectral discontinuity: If bridge steps insufficient or scheduler misconfigured

- **First 3 experiments:**
  1. VAE Reconstruction Baseline: Measure LSD/SSIM of VAE alone on 48kHz audio
  2. Ablation on Conditioning: Train "fixed" vs. "frequency-aware" model on mixed-resolution data
  3. Cascading Error Injection: Test 48→96kHz model using ground-truth vs. generated 48kHz inputs (with/without augmentation)

## Open Questions the Paper Calls Out

- **Open Question 1:** Can latent-to-latent bridge formulation be adapted for non-audio modalities like images/video?
  - **Basis:** [explicit] Conclusion states plans to extend to image, video, or time series
  - **Why unresolved:** Architecture and loss functions specialized for audio waveforms; unclear if Dirac prior strategy generalizes
  - **What evidence would resolve it:** Successful application to image/video super-resolution benchmarks with fidelity and convergence comparison

- **Open Question 2:** Can framework handle multiple audio restoration tasks (denoising, inpainting) simultaneously with super-resolution?
  - **Basis:** [explicit] Conclusion outlines plans to generalize to broader restoration tasks
  - **Why unresolved:** Current method conditioned on frequencies for bandwidth extension; needs flexible conditioning for degradation-agnostic restoration
  - **What evidence would resolve it:** Single model trained on mixture of degradation types outperforming specialized baselines

- **Open Question 3:** Can iterative sampling be distilled into one-step/few-step generator to match GAN efficiency?
  - **Basis:** [inferred] Appendix E.3 notes RTF 0.369 vs 0.009 for GAN-based approaches
  - **Why unresolved:** Quality/speed trade-off inherent to SDE-based bridge models; unclear if high-fidelity trajectory can be collapsed without losing benefits
  - **What evidence would resolve it:** Consistency distillation demonstrating GAN-level RTF < 0.05 with < 5% loss in ViSQOL/SigMOS

## Limitations
- VAE architecture details not fully specified beyond high-level parameters
- Exact composition of internal datasets for 48/96/192 kHz evaluation not disclosed
- Cascading augmentation strategy introduces complexity that may limit generalization

## Confidence
- **High Confidence:** Core mechanism of using LR latent as informative prior (Mechanism 1) is well-supported
- **Medium Confidence:** Frequency-aware conditioning (Mechanism 2) shows strong gains but bandwidth detection robustness needs testing
- **Medium Confidence:** Cascading augmentation (Mechanism 3) demonstrates effectiveness but deterministic blurring may not generalize

## Next Checks
1. **VAE Reconstruction Baseline Validation:** Measure upper bound by evaluating VAE reconstruction quality (LSD/SSIM) on 48kHz audio alone
2. **Frequency Conditioning Ablation:** Train and compare fixed-factor vs. frequency-aware model using mixed-resolution training data
3. **Cascading Error Analysis:** Test 48→96kHz model using both ground-truth and generated 48kHz inputs (with/without augmentation) to quantify cascading error reduction