---
ver: rpa2
title: 'Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal
  Grounding'
arxiv_id: '2510.20244'
source_url: https://arxiv.org/abs/2510.20244
tags:
- phrase
- video
- should
- token
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitation in video temporal grounding
  models that overly rely on sentence-level [EOS] token representations, underutilizing
  word-level semantic cues critical for fine-grained localization. The authors propose
  DualGround, a dual-branch architecture that explicitly disentangles global sentence-level
  and localized phrase-level semantics through structured phrase modeling.
---

# Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding

## Quick Facts
- arXiv ID: 2510.20244
- Source URL: https://arxiv.org/abs/2510.20244
- Reference count: 40
- Key outcome: DualGround achieves state-of-the-art performance on video temporal grounding by explicitly separating global sentence-level and localized phrase-level semantics through a dual-branch architecture, improving R1@0.7 by up to 2.98% and mAP by 0.66% on QVHighlights.

## Executive Summary
This paper addresses the limitation in video temporal grounding models that overly rely on sentence-level [EOS] token representations, underutilizing word-level semantic cues critical for fine-grained localization. The authors propose DualGround, a dual-branch architecture that explicitly disentangles global sentence-level and localized phrase-level semantics through structured phrase modeling. By clustering contextually coherent words into phrases and applying separate cross-modal attention strategies, the model balances coarse global alignment with fine-grained local interactions. DualGround achieves state-of-the-art performance on both moment retrieval and highlight detection tasks, demonstrating consistent gains across different backbones and datasets.

## Method Summary
DualGround implements a dual-branch architecture with sentence-level and phrase-level paths. The sentence path routes the [EOS] token through Adaptive Cross Attention with dummy tokens, while the phrase path clusters word tokens into N phrases using a Recurrent Phrase Generator and Slot Attention refinement. The model fuses outputs via element-wise addition, applies temporal pyramid convolutions, and trains with combined losses (MR/HD losses + DQA orthogonality + EOS reconstruction). The architecture requires frozen pretrained video-text encoders, fixed phrase count per dataset, and careful attention regularization to prevent semantic collapse.

## Key Results
- DualGround improves R1@0.7 by 2.98% on QVHighlights and 1.61% on Charades-STA over strong baselines
- The model achieves consistent mAP improvements of 0.66% on QVHighlights and 0.31% on Charades-STA
- DualGround shows robustness across different backbones (CLIP, InternVideo2) and task types (moment retrieval, highlight detection)

## Why This Works (Mechanism)

### Mechanism 1: Semantic Disentanglement via Dual-Branch Routing
Separating global sentence-level semantics from local phrase-level semantics prevents the dominant [EOS] signal from masking nuanced word-level cues during cross-modal attention. The architecture routes the [EOS] token through a dedicated sentence-level path while clustering word tokens into phrase units in a parallel phrase-level path, enabling both coarse global alignment and fine-grained local interactions.

### Mechanism 2: Structured Phrase Clustering for Context Abstraction
Clustering contextually coherent words into fixed semantic units provides a more robust interface for video-text alignment than individual word tokens. A Recurrent Phrase Generator initializes phrase clusters based on word correlations and global context, refined via Slot Attention to force competitive allocation of word semantics to specific slots, abstracting "red jacket" into a single query vector.

### Mechanism 3: Attention Regulation via Dummy Tokens and Orthogonality Constraints
Regulating attention flow with dummy sink tokens and orthogonality losses stabilizes training and enforces distinct semantic roles for text tokens. Dummy tokens absorb attention from irrelevant video clips, ensuring the [EOS] token only attends to highly relevant content, while Distinct Query Attention loss forces phrase slots to be semantically orthogonal, preventing collapse.

## Foundational Learning

**Concept: Slot Attention**
*Why needed here:* The paper utilizes Slot Attention to iteratively refine phrase representations. Understanding how "slots" compete for input features (words) via iterative attention is crucial to grasping how the model forms discrete phrase clusters.
*Quick check question:* How does the iterative nature of Slot Attention differ from a standard clustering algorithm like K-Means in the context of gradient flow?

**Concept: Cross-Modal Attention (Transformer)**
*Why needed here:* The core operation involves video clip features attending to text features. One must understand Q (Query), K (Key), and V (Value) to see how the model routes "sentence-level" vs "phrase-level" information differently.
*Quick check question:* In the context of this paper, which modality serves as the Query and which serves as the Key/Value in the Adaptive Cross Attention mechanism?

**Concept: The [EOS] Token Role in VLMs**
*Why needed here:* The paper's primary motivation is the "over-reliance" on the [EOS] token in models like CLIP. Learners need to understand that in many Transformers, the [CLS] or [EOS] token is trained to represent the whole input.
*Quick check question:* Why might a single [EOS] vector fail to distinguish between "A man in a red jacket" and "A man in a blue jacket" despite both sentences having identical grammatical structure?

## Architecture Onboarding

**Component map:**
Feature Extractors (CLIP/InternVideo2) -> Sentence Path ([EOS] + Dummy Tokens -> ACA) + Phrase Path (Words -> RPG -> Slot Attention -> Phrase-Clip Context) -> Fusion (Addition) -> Temporal Pyramid (1D Convs) -> Prediction Heads

**Critical path:**
The performance gain hinges on the Phrase Path's ability to generate distinct clusters. If the RPG and Slot Attention produce redundant phrase embeddings, the model reverts to the behavior of the baseline (global-only). The flow is: Word Correlation Analysis -> Slot Competition -> Fine-grained Visual Alignment.

**Design tradeoffs:**
- Fixed Phrase Count (N): The model fixes the number of phrases (N=3 or 4), simplifying batching but risking over-segmenting short queries or under-segmenting long ones.
- Additive Fusion: The paper selects simple addition over gating or concatenation, being computationally cheaper but assuming the sentence and phrase features are already scaled and aligned in the latent space.

**Failure signatures:**
- Attention Collapse: If DQA loss is removed, visualizations would show all phrase clusters highlighting the same video regions (semantic redundancy).
- EOS Dominance: If the Phrase Path gradient is too weak, the model ignores the complex phrase computations and outputs predictions identical to an EOS-only baseline.
- Over-segmentation: With large N, phrases might become single words, losing the "contextual coherence" benefit described in the paper.

**First 3 experiments:**
1. Token Ablation Sanity Check: Run inference using only the EOS path vs. only the Phrase path vs. Full model on a small validation set to verify the "complementary" nature of the branches.
2. Hyperparameter Sensitivity (N): Tune the number of phrase segments (N) on a validation set. The paper suggests optimal N depends on query length.
3. Attention Visualization: Visualize the "Phrase-to-Word" attention map to ensure phrases are actually grouping contextually (e.g., grouping "red" and "jacket") rather than random words.

## Open Questions the Paper Calls Out

**Open Question 1:** Can the phrase segmentation mechanism be made adaptive to automatically determine the optimal number of phrases per individual query, rather than requiring dataset-level manual tuning? The authors identify this as promising directions for future research since the current model assumes a fixed number of phrases per query.

**Open Question 2:** How would incorporating audio features into the dual-branch architecture affect temporal grounding performance, and should audio be integrated at the sentence-level path, phrase-level path, or both? The authors note the model does not leverage audio features and identify extension to audio signals for richer multimodal grounding as future work.

**Open Question 3:** Will the observed [EOS] token over-reliance in current VTG models intensify or diminish as vision-language foundation models scale to larger text encoder capacities? The paper finds that InternVideo2 (4096-dim embeddings) shows stronger [EOS]-only performance than CLIP (512-dim), suggesting higher-capacity [EOS] tokens may exacerbate word-token underutilization without architectural intervention.

**Open Question 4:** Can a learned, query-conditioned fusion mechanism for combining sentence-level and phrase-level representations outperform the simple element-wise addition strategy currently used? The ablation on fusion methods shows similar performance across strategies, but the relative importance of paths likely varies by query type and temporal segment.

## Limitations
- The dual-branch design introduces significant complexity that may not generalize well to domains with shorter, less structured queries.
- The model requires pre-specifying the number of phrases (N=3 or 4), representing a fundamental architectural limitation that lacks adaptive mechanisms.
- The model relies heavily on frozen pretrained feature extractors, creating a potential bottleneck constrained by the quality and domain alignment of these features.

## Confidence

**High Confidence (7/10):** The core architectural design - separating global sentence-level and local phrase-level semantics through dual routing - is well-supported by ablation studies and achieves consistent improvements across multiple datasets and backbones.

**Medium Confidence (5/10):** The specific implementation details, particularly the Slot Attention refinement mechanism and phrase clustering approach, show effectiveness but lack direct comparison to alternative clustering or attention mechanisms.

**Low Confidence (3/10):** The generalization claims beyond the tested datasets are weakly supported. The paper doesn't explore performance on queries with different linguistic structures or in multilingual settings.

## Next Checks

1. **Cross-Domain Generalization Test:** Evaluate DualGround on a dataset with distinctly different video content (e.g., cooking tutorials or sports) to assess whether the dual-branch architecture generalizes beyond the current test domains.

2. **Phrase Count Sensitivity Analysis:** Systematically vary N across a wider range (1-10) on validation sets to identify optimal phrase counts for different query length distributions, rather than the binary comparison shown in current ablation studies.

3. **Component Ablation Isolation:** Run experiments isolating each regularization component (dummy tokens, DQA loss) to determine their individual contributions to performance gains, separating architectural effects from training regularization effects.