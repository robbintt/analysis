---
ver: rpa2
title: 'PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided
  Embedding Projection'
arxiv_id: '2507.08979'
source_url: https://arxiv.org/abs/2507.08979
tags:
- uni00000013
- prism
- spurious
- bias
- uni00000011
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'PRISM addresses the problem of spurious biases in vision-language
  models (VLMs) like CLIP by leveraging large language models (LLMs) to dynamically
  identify bias attributes and learning a debiasing projection in the embedding space.
  The method operates in two stages: first, an LLM generates scene descriptions containing
  spurious correlations based on class prompts; second, a novel contrastive-style
  latent space debiasing loss (LD) learns a projection that minimizes spurious correlations
  while preserving semantic alignment between image and text embeddings.'
---

# PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided Embedding Projection

## Quick Facts
- arXiv ID: 2507.08979
- Source URL: https://arxiv.org/abs/2507.08979
- Authors: Mahdiyar Molahasani; Azadeh Motamedi; Michael Greenspan; Il-Min Kim; Ali Etemad
- Reference count: 36
- Primary result: Achieves state-of-the-art worst-group accuracy (84.2% on Waterbirds, 84.0% on CelebA) without predefined bias categories or external data

## Executive Summary
PRISM introduces a novel approach to reducing spurious implicit biases in vision-language models (VLMs) by leveraging large language models (LLMs) to identify bias attributes dynamically. The method operates in two stages: LLM-generated scene descriptions reveal spurious correlations based on class prompts, followed by a contrastive-style latent space debiasing loss that learns a projection minimizing these correlations while preserving semantic alignment. PRISM is task-agnostic and requires no predefined bias categories or external data, addressing a key limitation of existing debiasing methods.

## Method Summary
PRISM addresses spurious biases in VLMs through a two-stage architecture. In Stage 1, an LLM generates scene descriptions containing potential spurious correlations based on class prompts, identifying bias attributes that may correlate with target classes. In Stage 2, a novel contrastive-style latent space debiasing loss (LD) learns a projection that minimizes these spurious correlations while preserving semantic alignment between image and text embeddings. The method operates entirely in the embedding space of pre-trained VLMs without requiring external data or predefined bias categories, making it both data-free and task-agnostic.

## Key Results
- Achieves highest worst-group accuracy among data-free debiasing methods: 84.2% on Waterbirds dataset
- Achieves 84.0% worst-group accuracy on CelebA dataset
- Maintains overall accuracy while improving worst-group performance

## Why This Works (Mechanism)
PRISM works by leveraging LLMs to dynamically identify spurious correlations that might not be apparent to human annotators. The LLM-generated scene descriptions provide a comprehensive view of potential biases by describing various contexts and attributes associated with each class. The contrastive debiasing loss then learns to project embeddings into a space where these spurious correlations are minimized while maintaining the essential semantic relationships between images and text. This approach effectively separates bias-related features from class-relevant features in the embedding space.

## Foundational Learning

**Vision-Language Models (VLMs)**: Neural networks that learn joint representations of images and text through contrastive learning. Why needed: Understanding how VLMs encode semantic relationships is crucial for identifying where spurious correlations emerge. Quick check: Verify that embeddings from different modalities (image vs. text) align in the same latent space.

**Latent Space Debiasing**: Modifying the embedding space to reduce unwanted correlations while preserving task-relevant information. Why needed: Direct modification of model weights can be computationally expensive and may degrade performance. Quick check: Ensure debiased embeddings maintain semantic similarity to original embeddings for unbiased samples.

**Contrastive Learning**: Learning representations by comparing similar and dissimilar pairs. Why needed: Contrastive objectives provide a natural framework for distinguishing between bias-related and class-relevant features. Quick check: Verify that positive pairs (matching image-text) remain closer than negative pairs after debiasing.

## Architecture Onboarding

**Component Map**: LLM prompt generation -> Scene description extraction -> Embedding space projection learning -> Debiased VLM output

**Critical Path**: Stage 1 LLM generation → Stage 2 LD loss optimization → Final debiased embeddings

**Design Tradeoffs**: PRISM trades computational overhead during projection learning for improved fairness without external data requirements. The method requires careful prompt engineering for the LLM and hyperparameter tuning for the debiasing loss.

**Failure Signatures**: Poor performance may manifest as: (1) insufficient bias identification by LLM leading to incomplete debiasing, (2) over-aggressive debiasing that degrades overall accuracy, or (3) failure to generalize to novel bias types not captured in LLM training data.

**First Experiments**:
1. Verify that LLM-generated descriptions capture known spurious correlations in the dataset
2. Measure embedding similarity before and after projection to ensure semantic preservation
3. Test worst-group accuracy improvement on a small validation set before full training

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends on LLM's ability to identify comprehensive bias attributes, potentially missing novel biases
- Computational scalability to state-of-the-art VLMs with billions of parameters remains untested
- Fundamental dependence on LLM quality for bias identification creates potential blind spots

## Confidence
**High Confidence**: PRISM effectively reduces spurious correlations in tested scenarios; two-stage architecture is sound; achieves SOTA worst-group accuracy among data-free approaches

**Medium Confidence**: True task-agnostic nature (depends on LLM coverage of relevant biases); semantic alignment preservation (practical significance of remaining degradation uncharacterized)

**Low Confidence**: General applicability to any vision-language task without modification; computational efficiency claims (not directly measured)

## Next Checks
1. Evaluate PRISM on datasets containing biases not represented in the LLM's training corpus to assess robustness to novel spurious correlations
2. Test PRISM on larger VLMs (e.g., CLIP models with more than 1 billion parameters) to measure computational overhead and verify performance at scale
3. Assess long-term stability of debiasing projection as VLMs are updated or new data distributions emerge in production environments