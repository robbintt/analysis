---
ver: rpa2
title: Aligning Learning and Endogenous Decision-Making
arxiv_id: '2507.00851'
source_url: https://arxiv.org/abs/2507.00851
tags:
- learning
- decision
- problem
- endogenous
- demand
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an end-to-end learning framework for decision-making
  under endogenous uncertainty, where the random variable depends on the decision
  itself. The authors propose training a model to predict uncertainty in a way that
  aligns with the downstream optimization task, using a task-based loss function.
---

# Aligning Learning and Endogenous Decision-Making

## Quick Facts
- arXiv ID: 2507.00851
- Source URL: https://arxiv.org/abs/2507.00851
- Reference count: 3
- Primary result: Task-based learning framework for endogenous uncertainty with robust optimization and two-stage information-gathering extensions

## Executive Summary
This paper introduces an end-to-end learning framework for decision-making under endogenous uncertainty, where the random variable depends on the decision itself. The authors propose training a model to predict uncertainty in a way that aligns with the downstream optimization task, using a task-based loss function. They further develop a robust optimization variant that constructs an uncertainty set of models consistent with the data and optimizes decisions to protect against worst-case predictions. Theoretical guarantees show the robust approach can capture near-optimal decisions with high probability as a function of data size. The framework is also extended to two-stage information-gathering problems, where an initial decision reveals information about random variables before making subsequent predictions and decisions.

## Method Summary
The method trains ML models using a task-based loss function that directly optimizes for downstream decision quality rather than prediction accuracy. For endogenous uncertainty problems, the framework minimizes the squared difference between realized costs and predicted costs under the model. The robust variant constructs an uncertainty set of plausible models and optimizes for worst-case predictions within that set. For two-stage problems, the framework unifies information-gathering (choosing which random variable to observe) with subsequent decision-making. The approach offers both exact mixed-integer optimization formulations for piecewise linear costs and sampling-based stochastic gradient descent methods for larger-scale problems.

## Key Results
- Task-based loss function outperforms standard MSE prediction for non-linear cost functions
- Robust optimization variant provides safety guarantees by optimizing against worst-case models in the uncertainty set
- Two-stage information-gathering extension successfully learns to select informative observations
- Computational experiments show consistent performance improvements over traditional two-stage methods
- Theoretical guarantees show the robust approach captures near-optimal decisions with high probability as data size increases

## Why This Works (Mechanism)

### Mechanism 1
Training a predictor using a task-based loss function (rather than prediction error) may yield better downstream decisions when the cost function is non-linear with respect to the uncertainty. Standard two-stage methods minimize Mean Squared Error (MSE), forcing the model to predict the conditional mean $E[z|v,x]$. However, for non-linear cost functions $c(v,z)$, $E[c(v,z)] \neq c(v, E[z])$ (due to Jensen's Inequality). By defining the loss as the squared difference between the realized cost and the cost of the prediction, the model is incentivized to predict a statistic of the uncertainty that preserves the expected cost, effectively aligning the learning objective with the decision quality.

### Mechanism 2
Constructing an uncertainty set of plausible models and optimizing for the worst-case prediction within that set can protect against over-optimistic decisions in sparse data regimes. Instead of relying on a single "best" model, the framework defines an uncertainty set containing all models with similar task-based error. The optimization selects a decision that maximizes the objective under the worst-performing valid model in the set. This mitigates the risk of selecting actions that appear optimal under one specific model but fail under equally plausible alternatives (model misspecification).

### Mechanism 3
Framing information-gathering as a two-stage endogenous problem allows the model to learn the intrinsic value of information for downstream optimization. In the information-gathering setting, the first-stage decision influences the information state available for the second-stage prediction. By treating the first-stage prediction of the cost as a function of the information-gathering decision (endogenous uncertainty), the framework learns to select observations not just to reduce entropy, but specifically to improve the subsequent decision.

## Foundational Learning

### End-to-End (E2E) Learning / "Smart Predict-then-Optimize"
Why needed here: The core contribution is an E2E framework for endogenous uncertainty. Understanding the standard E2E paradigm (integrating prediction and optimization) is required to see why the endogenous case requires a specialized loss function rather than standard gradient propagation.
Quick check question: Can you explain why minimizing prediction error (MSE) does not necessarily minimize decision error in a pricing problem with non-linear revenue functions?

### Robust Optimization (Uncertainty Sets)
Why needed here: The paper proposes a robust variant that defines an uncertainty set of models. Understanding concepts like "uncertainty sets," "worst-case analysis," and "regularization" is required to implement the cutting-plane algorithm and the inner maximization loop.
Quick check question: How does the definition of the uncertainty set $U_\epsilon$ in Eq. 13 differ from standard regularization techniques like L2 weight decay?

### Stochastic Gradient Descent (SGD) & Mixed-Integer Optimization (MIO)
Why needed here: The paper offers two solution methods: an exact MIO formulation for piecewise linear costs and a sampling-based SGD approach. Understanding the trade-off between the exactness of MIO and the scalability of SGD is crucial for selecting the right solver.
Quick check question: Why does the non-convexity of the task loss necessitate either mixed-integer variables or a sampling-based initialization strategy?

## Architecture Onboarding

### Component map:
Data Layer -> Predictor -> Task-Loss Calculator -> Robust Solver (conditional)

### Critical path:
1. Define Cost Function: Ensure $c(v, z)$ is implemented and differentiable w.r.t $z$
2. Implement Task Loss: Construct training loop to minimize $\sum (c(v_{hist}, f(x_{hist}, v_{hist})) - c_{realized})^2$
3. Solve Outer Problem (Inference): For new $x$, solve $\min_v c(v, f(x,v))$ (or robust max-min version)

### Design tradeoffs:
- Exactness vs. Speed: Use MIP formulation for exact solutions on small data/piecewise-linear costs; use sampling-based method for large-scale neural networks
- Robustness Parameter ($\epsilon$): High $\epsilon$ guarantees safety (lower bound) but may sacrifice expected reward (conservatism). Must be tuned using validation set

### Failure signatures:
- Optimization Collapse: Predictor learns to output constant values that trivially minimize cost variance
- Out-of-Sample Drift: Model fails to predict costs for counterfactual decisions far from training data
- Over-Conservatism: Robust method sacrifices too much expected reward with large $\epsilon$

### First 3 experiments:
1. Sanity Check (Pricing): Replicate "Two curves, same MSE" example to verify Task-Loss distinguishes between revenue-optimizing and demand-mean-predicting models
2. Robustness Calibration: Run robust optimization on Assortment problem with varying noise levels to verify lower bound maintenance
3. Information Gathering Logic: Test 2-stage electricity scheduling on synthetic data where polling variable A is strictly more valuable than variable B

## Open Questions the Paper Calls Out
- Can theoretical optimality guarantees or performance bounds be established for the sampling-based learning approaches, which currently lack such proofs?
- How can the robust optimization framework guarantee global optimality when the inner function is non-convex with respect to the decision?
- Do the generalization bounds and robustness guarantees proven for the base framework extend to the two-stage information-gathering setting?

## Limitations
- Theoretical guarantees rely heavily on i.i.d. data generation and hypothesis class richness assumptions that may not hold in practice
- No framework for detecting or handling model misspecification when true function is outside chosen model class
- Practical value of robust optimization depends heavily on proper uncertainty set calibration requiring extensive cross-validation

## Confidence

### High Confidence:
- Task-based loss outperforms MSE for non-linear cost functions (Mechanism 1)

### Medium Confidence:
- Robust optimization framework's theoretical guarantees (Mechanism 2)
- Two-stage information-gathering extension (Mechanism 3)

## Next Checks
1. Test framework on synthetic data where true model is NOT in hypothesis class F to measure performance degradation
2. Implement cross-validation procedure for selecting robustness parameter ε and verify optimal ε identification across different problem instances
3. Benchmark exact MIP formulation against sampling-based SGD on large datasets (N > 10,000) and higher-dimensional problems (d > 50) to document computational trade-offs