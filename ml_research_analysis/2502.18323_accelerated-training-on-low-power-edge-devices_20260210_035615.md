---
ver: rpa2
title: Accelerated Training on Low-Power Edge Devices
arxiv_id: '2502.18323'
source_url: https://arxiv.org/abs/2502.18323
tags:
- training
- power
- batch
- time
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of accelerating training on low-power
  edge devices by jointly optimizing system (GPU frequency) and application (batch
  size) parameters under power constraints. The proposed method uses offline profiling
  to measure power and time for different configurations, and estimates batch size
  efficiency on a server using a proxy dataset.
---

# Accelerated Training on Low-Power Edge Devices
## Quick Facts
- arXiv ID: 2502.18323
- Source URL: https://arxiv.org/abs/2502.18323
- Authors: Mohamed Aboelenien Ahmed; Kilian Pfeiffer; Heba Khdr; Osama Abboud; Ramin Khalili; Jörg Henkel
- Reference count: 12
- Primary result: 2.4× reduction in training time compared to baselines on Jetson Nano/TX2NX

## Executive Summary
This paper addresses the challenge of accelerating training on low-power edge devices by jointly optimizing system (GPU frequency) and application (batch size) parameters under power constraints. The proposed method uses offline profiling to measure power and time for different configurations, and estimates batch size efficiency on a server using a proxy dataset. This enables runtime selection of optimal GPU frequency and batch size combinations that minimize total training time to accuracy. Experimental results on Nvidia Jetson Nano and TX2NX show significant improvements: 2.4× reduction in training time compared to baselines, substantial energy savings, and robustness to proxy dataset selection. The approach achieves near-optimal performance across various models including CNNs and transformers without sacrificing model accuracy.

## Method Summary
The approach jointly optimizes GPU frequency and batch size for training on low-power edge devices. It involves offline profiling of power consumption and execution time across different GPU frequencies and batch sizes using a proxy dataset on a server. The method estimates batch size efficiency on the edge device by measuring the slope of training accuracy versus batch size. At runtime, it selects the optimal combination of GPU frequency and batch size that minimizes total training time to accuracy under power constraints. The optimization framework considers both the training time and energy consumption, enabling significant improvements in training efficiency while maintaining model accuracy.

## Key Results
- 2.4× reduction in training time compared to baselines on Jetson Nano and TX2NX devices
- Substantial energy savings achieved through joint optimization of GPU frequency and batch size
- Robust performance across various models including CNNs and transformers
- Near-optimal performance achieved without sacrificing model accuracy

## Why This Works (Mechanism)
The method works by exploiting the relationship between GPU frequency, batch size, power consumption, and training efficiency. By profiling these parameters offline on a proxy dataset, the system can predict optimal configurations for new training tasks on the target edge device. The joint optimization approach considers both the computational efficiency (through batch size selection) and power efficiency (through GPU frequency scaling), leading to significant improvements in training time and energy consumption compared to using default or single-parameter optimization approaches.

## Foundational Learning
- GPU frequency scaling: Understanding how GPU clock speeds affect power consumption and performance is crucial for optimizing training efficiency. Quick check: Verify power consumption measurements at different GPU frequencies.
- Batch size optimization: The relationship between batch size, training accuracy, and computational efficiency must be understood to maximize throughput. Quick check: Validate accuracy vs. batch size curves on target device.
- Power-constrained optimization: The method must balance performance gains against power consumption limits typical of edge devices. Quick check: Confirm power budget constraints are respected in all configurations.
- Proxy dataset selection: The choice of proxy dataset affects the accuracy of offline profiling and subsequent optimization. Quick check: Test robustness across different proxy dataset selections.
- Runtime configuration selection: The ability to quickly select optimal configurations at runtime is essential for practical deployment. Quick check: Measure configuration selection latency.

## Architecture Onboarding
- Component map: Proxy Dataset -> Offline Profiler -> Efficiency Model -> Runtime Optimizer -> Edge Device
- Critical path: The critical path involves profiling on proxy dataset, building efficiency models, and runtime configuration selection. Optimization of this path directly impacts overall training time reduction.
- Design tradeoffs: The method trades off between profiling overhead and runtime efficiency gains. More extensive offline profiling can lead to better runtime performance but increases preparation time.
- Failure signatures: Poor proxy dataset selection or inaccurate efficiency models can lead to suboptimal configurations. Monitoring training accuracy and power consumption can help detect these failures.
- First experiments: 1) Profile power and time across GPU frequencies and batch sizes on proxy dataset, 2) Validate efficiency model predictions against actual measurements on target device, 3) Test runtime configuration selection on simple training tasks.

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- The method relies heavily on offline profiling and proxy dataset selection, with limited discussion of requirements for proxy dataset representativeness across different model architectures and data distributions.
- Experiments are limited to specific Nvidia Jetson devices and a narrow set of model types (CNNs and transformers), constraining generalizability to other edge hardware and model families.
- The confidence in broader applicability claims is medium, as robustness to proxy dataset selection is demonstrated but not extensively validated across diverse scenarios.

## Confidence
- High confidence in experimental results on tested Jetson Nano/TX2NX hardware
- Medium confidence in proxy dataset selection methodology
- Medium-High confidence in core optimization approach for tested models
- Medium confidence in broader applicability to other edge devices and model types

## Next Checks
1. Test the methodology across a broader range of edge devices with different GPU architectures to assess hardware generalization.
2. Validate the approach with more diverse model families (e.g., graph neural networks, recurrent networks) and data types beyond images and text.
3. Conduct ablation studies to quantify the individual contributions of GPU frequency optimization versus batch size selection to the overall performance gains.