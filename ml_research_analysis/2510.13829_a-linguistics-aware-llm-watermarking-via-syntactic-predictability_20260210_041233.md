---
ver: rpa2
title: A Linguistics-Aware LLM Watermarking via Syntactic Predictability
arxiv_id: '2510.13829'
source_url: https://arxiv.org/abs/2510.13829
tags:
- stela
- watermark
- language
- detection
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces STELA, a novel watermarking method that aligns
  watermark strength with linguistic degrees of freedom using POS n-gram-based syntactic
  predictability. Unlike prior approaches that require model logits for detection,
  STELA dynamically modulates watermark insertion and detection based on grammatical
  flexibility, weakening signals in constrained contexts to preserve quality and strengthening
  them where linguistic choices are abundant to enhance detectability.
---

# A Linguistics-Aware LLM Watermarking via Syntactic Predictability

## Quick Facts
- arXiv ID: 2510.13829
- Source URL: https://arxiv.org/abs/2510.13829
- Reference count: 40
- Primary result: Novel watermarking method that aligns signal strength with linguistic degrees of freedom, achieving TPR@5%FPR up to 0.996 while maintaining text quality

## Executive Summary
This paper introduces STELA, a watermarking method that dynamically modulates watermark strength based on linguistic indeterminacy measured via POS n-gram entropy. Unlike prior approaches requiring model logits for detection, STELA adapts both insertion and detection to grammatical flexibility—weakening signals in constrained contexts to preserve quality and strengthening them where linguistic choices are abundant to enhance detectability. Evaluated across three typologically distinct languages (English, Chinese, Korean) using three different LLMs, STELA achieves superior watermark detection performance while maintaining text quality comparable to leading baselines, enabling model-free, publicly verifiable detection.

## Method Summary
STELA operates by pre-computing a lookup table of normalized conditional entropy (λ) for POS n-gram contexts from reference corpora, then using this to adaptively modulate watermark insertion strength and detection weighting. During generation, each token's green-list bias is scaled by λ(c_t) where c_t is the preceding POS context. During detection, each token's contribution to the weighted z-score is also scaled by λ(c_t), concentrating signal in high-indeterminacy contexts while preserving quality in constrained ones.

## Key Results
- Achieves TPR@5%FPR up to 0.996 across English, Chinese, and Korean
- Maintains text quality comparable to baselines (measured via perplexity)
- Enables public verifiability without requiring model logits
- Generalizes across three different LLM architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linguistic indeterminacy, measured via POS n-gram entropy, provides a model-independent signal for modulating watermark strength without degrading text quality.
- Mechanism: At generation step t, the preceding k-1 POS tags form context c_t. Conditional entropy H(P(π_t|c_t)) is computed from human-written corpora and normalized by log(K_ct), yielding λ(c_t) ∈ [0,1] where values near 1 indicate high syntactic freedom.
- Core assumption: POS n-gram statistics from reference corpora reliably predict grammatical flexibility at generation time across domains.
- Evidence anchors:
  - [abstract] "STELA dynamically modulates the signal using part-of-speech (POS) n-gram–modeled linguistic indeterminacy"
  - [section 4.1, equations 4-5] Formal definition of conditional Shannon entropy and normalized indeterminacy measure
  - [corpus] Weak corpus evidence; related work on syntax probing in LLMs supports that syntactic structure is recoverable from model activations
- Break condition: If generated text domain diverges substantially from reference corpus, λ lookup may misestimate grammatical constraints.

### Mechanism 2
- Claim: Adaptive watermark insertion—biasing green-list tokens proportionally to linguistic indeterminacy—preserves text quality while concentrating detectable signal in syntactically flexible positions.
- Mechanism: Replace static bias δ with δ'_t = δ × λ(c_t). Apply strong bias in high-indeterminacy contexts, weak or negligible bias in low-indeterminacy contexts.
- Core assumption: The model's original logits already favor grammatically appropriate tokens in constrained contexts; reducing bias there does not significantly alter output distribution.
- Evidence anchors:
  - [abstract] "weakening it in grammatically constrained contexts to preserve quality and strengthen it in contexts with greater linguistic flexibility to enhance detectability"
  - [section 4.2, equation 6-7] Adaptive bias formula and logit modification
  - [corpus] Related watermarking work documents trade-offs between adversarial resistance and linguistic quality
- Break condition: If base strength δ is incorrectly calibrated for a language, the adaptive signal may be too weak or too strong.

### Mechanism 3
- Claim: Weighted detection scoring, where each token's contribution to the z-score is weighted by its linguistic indeterminacy, improves detection sensitivity while maintaining public verifiability.
- Mechanism: Compute weighted z-score z' = (Σw_t·I(x_t ∈ V_G,t) - γΣw_t) / √(γ(1-γ)Σw²_t), where w_t = λ(c_t).
- Core assumption: The watermark signal is stronger in high-indeterminacy contexts (due to adaptive insertion), so weighting detection accordingly amplifies signal-to-noise ratio.
- Evidence anchors:
  - [abstract] "Our detector operates without access to any model logits, thus facilitating publicly verifiable detection"
  - [section 4.3, equation 9] Weighted z-score formulation
  - [corpus] PVMark addresses public verifiability concerns in LLM watermarking
- Break condition: If POS tagging errors occur during detection, the weighted score may misallocate contributions.

## Foundational Learning

- Concept: **Shannon entropy and conditional entropy**
  - Why needed here: The core signal λ(c_t) is defined as normalized conditional entropy of POS tags. Understanding entropy as a measure of uncertainty is essential to interpret why high-entropy contexts receive stronger watermarks.
  - Quick check question: Given a context where 3 POS tags occur with probabilities [0.8, 0.15, 0.05], is the conditional entropy higher or lower than a context where 3 tags occur with probabilities [0.33, 0.33, 0.34]?

- Concept: **KGW (Kirchenbauer et al.) watermarking scheme**
  - Why needed here: STELA builds on KGW's green/red list partitioning and logit biasing. The detection framework (z-test on green token counts) is modified but not replaced.
  - Quick check question: In KGW, if γ=0.5 and T=100 tokens, what is the expected number of green tokens under the null hypothesis?

- Concept: **Typological linguistics (analytic, isolating, agglutinative)**
  - Why needed here: The paper calibrates POS context length k based on language typology (k=2 for English, k=4 for Chinese/Korean).
  - Quick check question: Why would an agglutinative language like Korean benefit from a larger POS context window than an analytic language like English?

## Architecture Onboarding

- Component map: Reference corpora → POS tagger → POS n-gram frequency counts → conditional entropy H(P(π|c)) → normalized λ lookup table → Insertion module (adaptive bias) → Detection module (weighted z-score) → Calibration layer (language-specific δ)

- Critical path:
  1. Pre-compute λ tables from high-quality human-written corpora before any watermarking
  2. During generation: POS-tag preceding tokens → lookup λ → modulate bias → sample
  3. During detection: POS-tag text → lookup λ for each token → compute weighted z-score → compare to threshold

- Design tradeoffs:
  - POS context length k: Smaller k reduces data sparsity but may miss longer-range dependencies; larger k captures more syntax but requires more training data
  - Tagset granularity: UD tagsets are cross-lingual but coarser; language-specific tagsets provide finer distinctions, improving λ precision
  - Base strength calibration: Fixed δ per language ensures fair comparison but may not generalize to all domains

- Failure signatures:
  - Low TPR despite watermarked text: Check POS tagger errors corrupting context reconstruction; verify λ table coverage
  - High perplexity (quality degradation): δ may be over-calibrated; inspect whether high-bias tokens are concentrated in constrained contexts
  - Detection fails cross-domain: λ table may be mismatched to target domain; consider domain-adaptive estimation

- First 3 experiments:
  1. Validate λ signal correlation: Compute λ for held-out corpus and verify high-λ contexts correspond to higher token entropy in model outputs
  2. Ablate adaptive insertion vs. detection: Run STELA with adaptive insertion only (uniform detection), then detection only (uniform insertion)
  3. Stress-test tagger robustness: Inject synthetic POS tagging errors at increasing rates and measure TPR degradation

## Open Questions the Paper Calls Out

1. **POS tagging error robustness**: How robust is STELA's detection performance when subjected to varying rates of Part-of-Speech (POS) tagging errors? The paper explicitly notes that tagging errors during detection may distort contextual reconstruction and lead to missed watermark signals, calling for future work on robustness against inaccuracies.

2. **Domain mismatch impact**: To what extent does a domain mismatch between the reference corpus and the generation task degrade STELA's weighting efficacy? The authors state that when the domain of the training corpora diverges substantially from that of the generated text, the resulting weighting scheme may become suboptimal.

3. **Semantic and stylistic quality**: Does STELA preserve semantic coherence and stylistic naturalness better than perplexity-matched baselines? The authors admit their assessment relies solely on perplexity, which may not fully capture grammatical correctness, stylistic naturalness, or semantic coherence.

## Limitations

- POS tagging pipeline introduces a single point of failure—detection accuracy directly couples to tagger quality
- Static λ lookup tables derived from general web corpora may perform poorly on specialized domains
- Sample sizes (500 generations per condition) may not capture rare failure modes
- Focus on syntactic flexibility via POS entropy may miss other dimensions of linguistic indeterminacy

## Confidence

**High confidence**: The core mechanism of modulating watermark strength via POS-based linguistic indeterminacy is theoretically sound and well-supported by the entropy formulation. The mathematical framework for adaptive insertion and weighted detection is internally consistent.

**Medium confidence**: The empirical evaluation demonstrates strong performance across three languages, but the sample sizes and evaluation conditions are limited. The claim that STELA generalizes across models and languages is supported but not extensively validated across diverse domains.

**Low confidence**: The calibration procedure for δ per language assumes a stable relationship between mean λ and effective watermark strength that may not hold across all domains or models. The sensitivity of detection performance to POS tagging errors is not quantified.

## Next Checks

1. **Tagger robustness evaluation**: Systematically inject POS tagging errors at controlled rates (5%, 10%, 20%) into detection inputs and measure TPR degradation to quantify practical sensitivity to tagger quality.

2. **Domain transfer validation**: Generate watermarked text from specialized domains (scientific papers, code, legal documents) and evaluate detection performance using λ tables trained on general web corpora to measure performance drop.

3. **Cross-model generalization stress test**: Apply STELA detection across model pairs not seen during development (e.g., detect Llama-3.2 watermarks using Qwen-3 trained λ tables and vice versa) to evaluate whether the λ-based approach truly generalizes.