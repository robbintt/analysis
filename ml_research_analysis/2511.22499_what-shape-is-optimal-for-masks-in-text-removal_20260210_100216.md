---
ver: rpa2
title: What Shape Is Optimal for Masks in Text Removal?
arxiv_id: '2511.22499'
source_url: https://arxiv.org/abs/2511.22499
tags:
- mask
- text
- image
- masks
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of text removal from complex
  document images with dense text, an area with limited research compared to simple
  scene text removal. The authors developed a benchmark dataset consisting of 95 document
  images with rich text and high OCR difficulty, along with manually processed text-removed
  outputs.
---

# What Shape Is Optimal for Masks in Text Removal?

## Quick Facts
- arXiv ID: 2511.22499
- Source URL: https://arxiv.org/abs/2511.22499
- Authors: Hyakka Nakada; Marika Kubota
- Reference count: 40
- Primary result: Character-wise masks with slight enlargement (scale factor ~1.37) are optimal for text removal from dense document images

## Executive Summary
This paper addresses the challenge of text removal from complex document images with dense text, an area with limited research compared to simple scene text removal. The authors developed a benchmark dataset of 95 document images with rich text and high OCR difficulty, along with manually processed text-removed outputs. They found that text removal performance is highly sensitive to mask profile variations, indicating the need for precise mask design. To address this, they proposed a method to model flexible mask profiles using superellipse-based shapes and learn their parameters via Bayesian optimization. Experiments showed that optimizing mask profiles significantly improved text removal performance, measured by Frechet Inception Distance (FID) scores. The best-performing masks were character-wise with slight enlargement, outperforming pixel-level stroke-based masks.

## Method Summary
The authors developed two mask generation approaches: Type-1 uses OCR-based bounding boxes transformed into superellipse masks with parameters for chunk size, scale, and roundness; Type-2 uses SAEN stroke detection with morphological transformations. Both mask types are parameterized and optimized via Bayesian optimization (Optuna GPSampler, 100 iterations) targeting FID improvement. The optimization searches parameter spaces including chunk size (0-2), scale (1.0-1.5), roundness (0.0-1.0) for Type-1, and threshold, dilation/erosion times, and kernel size for Type-2. Images are resized to 512×512 and evaluated using LaMa inpainting against manually created ground truth text-removed images.

## Key Results
- Text removal performance varies dramatically with mask profile, with FID scores ranging from 135.95 to 40.54 across different configurations
- Character-wise masks with slight enlargement (scale factor ~1.37) outperform both tight-fitting and over-enlarged masks
- Rectangular masks (roundness=0) provide more reliable performance than elliptical alternatives
- Type-1 (OCR-based) masks outperform Type-2 (stroke-based) masks, likely due to SAEN's failure on small-font characters

## Why This Works (Mechanism)

### Mechanism 1
Text-removal accuracy is highly sensitive to mask profile variations, making precise mask design essential for dense document images. Inpainting models trained for general robustness still exhibit significant FID variance when mask profiles change from paragraph-wise to character-wise, or when scale factors shift. The model's context aggregation mechanism appears to struggle with boundary artifacts when masks fragment background regions excessively.

### Mechanism 2
Character-wise masks with slight enlargement (scale factor ~1.37) outperform tight-fitting and over-enlarged masks. Slightly enlarged masks provide sufficient context buffer around character boundaries, allowing the inpainting model to synthesize cohesive background textures while avoiding the "brick-like marks" that arise from fragmented or excessively large masked regions.

### Mechanism 3
Rectangular masks (roundness=0) provide more reliable performance than elliptical or superellipse alternatives for text removal. Rectangular masks align with document grid structures and avoid irregular contour artifacts that may confuse inpainting models trained primarily on rectangular mask distributions.

## Foundational Learning

- **Concept: Superellipse parametric representation**
  - Why needed: The paper uses superellipses to continuously parameterize mask shapes from rectangles to ellipses using the order parameter
  - Quick check: Can you write the superellipse equation and explain what shape results when s_order = 2 versus s_order → ∞?

- **Concept: Bayesian optimization for black-box functions**
  - Why needed: The optimization loop uses Optuna's GPSampler to search mask parameter space efficiently given expensive evaluation costs
  - Quick check: Why is Bayesian optimization preferred over grid search when each evaluation requires running an inpainting model?

- **Concept: Fréchet Inception Distance (FID) as image quality metric**
  - Why needed: The paper uses FID as its single-objective optimization target for comparing text removal quality
  - Quick check: What are the limitations of FID when computed on small sample sizes (<10,000 images)?

## Architecture Onboarding

- **Component map**: OCR bounding box extraction → superellipse transformation (scale, roundness, chunk) → mask image → LaMa inpainting → FID evaluation → surrogate model update
- **Critical path**: OCR bounding box extraction → mask parameter application → inpainting execution → FID computation. Errors in OCR detection cascade through the entire pipeline.
- **Design tradeoffs**: Type-1 vs Type-2: Type-1 (OCR-based) is more reproducible for manual masking but requires accurate OCR; Type-2 (stroke-based) handles complex contours but fails on small-font characters. FID-only optimization: Faster convergence but ignores other quality metrics. Sample size: 95-image benchmark is below FID's recommended 10,000+ sample threshold.
- **Failure signatures**: "Brick-like marks" remaining after removal → mask scale too small. Background content erased unintentionally → mask scale too large or SAEN threshold too low. Patch-like incomplete masks on small fonts → SAEN detection failure.
- **First 3 experiments**: 1) Reproduce vulnerability analysis: Sample grid of mask parameters on 5-10 benchmark images and verify FID variance exceeds 2x between best/worst configurations. 2) Validate optimal scale factor: Run Bayesian optimization on held-out document subset to confirm ~1.3-1.4 scale range generalizes. 3) Test OCR quality sensitivity: Inject controlled noise into bounding box coordinates and measure FID degradation to quantify robustness requirements.

## Open Questions the Paper Calls Out

### Open Question 1
Does incorporating rotation parameters into mask optimization improve text removal performance for non-axis-aligned document images? The authors state, "One drawback of our method is that we did not care for the rotation of bounding boxes," and hypothesize that applying Bayesian optimization to rotated boxes would improve FID scores. Experiments optimizing a rotation parameter within the superellipse mask model, demonstrating improved FID scores on rotated document subsets, would resolve this.

### Open Question 2
How does the optimal mask profile change when optimizing for alternative evaluation metrics like CMMD or multi-objective targets such as processing speed? The authors suggest that "Using an improved metric such as CMMD would also improve text-removal performance" and propose "multi-objective optimization" for balancing quality and speed. Optimization runs using CMMD or latency-aware objective functions, compared against the current FID-optimized character-wise masks, would resolve this.

### Open Question 3
Does the superiority of bounding-box masks (Type-1) over pixel-level strokes (Type-2) persist when using more advanced stroke extraction models? The authors note that "the profile of the optimized masks can vary depending on which text-removal model is targeted" and attributed Type-2 failures to SAEN extraction errors on small fonts. Re-evaluating the mask types using a fine-tuned or superior stroke extraction model to isolate the impact of mask base quality would resolve this.

## Limitations
- The 95-image benchmark falls below FID's recommended sample size threshold, potentially introducing metric variance
- Exclusive focus on FID optimization may overlook other quality dimensions captured by MAE, PSNR, or SSIM
- Findings are specific to document images with dense text; performance may differ substantially for documents with sparse text, handwritten content, or complex scene backgrounds

## Confidence

**High**: The vulnerability of text removal performance to mask profile variations is well-supported by quantitative FID differences across parameter ranges

**Medium**: The identification of character-wise masks with slight enlargement as optimal is based on robust optimization but may not generalize to all document types

**Low**: The finding that rectangular masks outperform elliptical alternatives lacks strong theoretical grounding and may be an artifact of model training bias

## Next Checks

1. Reproduce the vulnerability analysis by sampling a comprehensive grid of mask parameters across 5-10 benchmark images to verify that FID variance exceeds 2x between best and worst configurations
2. Test OCR quality sensitivity by injecting controlled noise into bounding box coordinates and measuring FID degradation to quantify robustness requirements
3. Evaluate the generalization of optimal mask profiles to different document types (sparse text, handwritten, scene backgrounds) to identify domain-specific variations in optimal parameters