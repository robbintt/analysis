---
ver: rpa2
title: 'BlendFL: Blended Federated Learning for Handling Multimodal Data Heterogeneity'
arxiv_id: '2510.13266'
source_url: https://arxiv.org/abs/2510.13266
tags:
- data
- blendfl
- learning
- local
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces BlendFL, a federated learning framework\
  \ that seamlessly integrates horizontal and vertical federated learning to address\
  \ multimodal data heterogeneity in real-world collaborative learning scenarios.\
  \ BlendFL enables clients with varying data fragmentation\u2014paired, fragmented,\
  \ or partial\u2014to participate without restrictions, overcoming limitations of\
  \ traditional FL frameworks."
---

# BlendFL: Blended Federated Learning for Handling Multimodal Data Heterogeneity

## Quick Facts
- arXiv ID: 2510.13266
- Source URL: https://arxiv.org/abs/2510.13266
- Reference count: 30
- This paper introduces BlendFL, a federated learning framework that seamlessly integrates horizontal and vertical federated learning to address multimodal data heterogeneity in real-world collaborative learning scenarios.

## Executive Summary
This paper introduces BlendFL, a federated learning framework that seamlessly integrates horizontal and vertical federated learning to address multimodal data heterogeneity in real-world collaborative learning scenarios. BlendFL enables clients with varying data fragmentation—paired, fragmented, or partial—to participate without restrictions, overcoming limitations of traditional FL frameworks. It introduces BlendAvg, a weighted model aggregation strategy that prioritizes updates based on local model performance rather than data volume, and supports decentralized inference for reduced latency and server dependency. Evaluated on a large-scale real-world clinical dataset (MIMIC-IV, MIMIC-CXR) and a multimodal benchmark (S-MNIST), BlendFL consistently outperformed seven state-of-the-art baselines across three classification tasks, achieving superior performance in both multimodal and unimodal settings. Ablation studies demonstrated faster convergence compared to traditional approaches, highlighting BlendFL's potential for privacy-preserving collaborative learning in domains like healthcare and finance.

## Method Summary
BlendFL synchronously combines horizontal and vertical federated learning to handle heterogeneous data fragmentation across clients. The framework processes three data types per epoch: partial data trains local unimodal models via HFL principles; fragmented data leverages VFL through server-side feature aggregation using Private Set Intersection for patient matching; paired data trains local multimodal models. All models are aggregated via BlendAvg, which weights contributions based on validation performance improvement rather than data volume, and redistributed. The framework supports decentralized inference, enabling clients to make predictions locally without server communication post-training.

## Key Results
- Outperformed seven state-of-the-art baselines on MIMIC-IV/MIMIC-CXR and S-MNIST benchmarks
- Achieved superior performance in both multimodal and unimodal settings across three classification tasks
- Demonstrated up to 46% faster convergence compared to traditional approaches in ablation studies

## Why This Works (Mechanism)

### Mechanism 1
BlendFL enables collaborative training across clients with heterogeneous data fragmentation (paired, fragmented, or partial) by synchronously combining horizontal and vertical federated learning paradigms. The framework processes three data types within each epoch: (1) partial data trains local unimodal models via HFL principles; (2) fragmented data leverages VFL through server-side feature aggregation using Private Set Intersection for patient matching; (3) paired data trains local multimodal models. All models are aggregated via BlendAvg and redistributed. Core assumption: Clients can align samples across institutions via a shared private identifier database or privacy-preserving technique such as Private Set Intersection (PSI) before VFL training. Break condition: If PSI fails or sample overlap is negligible across clients, VFL pathway contributes minimally; system degrades to HFL-only mode.

### Mechanism 2
BlendAvg accelerates convergence and improves final performance by weighting model contributions based on validation performance improvement rather than data volume. For each local model, compute Δᵢ = Aᵢ - Aglobal (improvement vs. prior global model). Discard models with Δᵢ ≤ 0. Normalize weights: ωᵢ = Δᵢ / ΣΔᵢ. Aggregate: Wblended = Σ(ωᵢ × Wᵢ). This creates a performance-gated, proportional contribution system. Core assumption: A representative validation set exists at the server and reliably reflects generalization; models overfitting to local data but failing on validation are automatically down-weighted. Break condition: If validation set is unrepresentative or adversarially manipulated, weight assignments become unreliable; degraded or biased global model results.

### Mechanism 3
Decentralized inference enables clients to perform local predictions without server communication post-training, reducing latency and dependency. Each client maintains local unimodal encoders (fᴬ, fᴮ) and classifiers (gᴬ, gᴮ, gᴹ) that are updated from blended global models after each epoch. At inference, clients compute predictions locally using available modalities: unimodal (ŷ = g(h)) or multimodal (ŷᴹ = gᴹ(hᴬ, hᴮ)). Core assumption: Local model architectures remain consistent across training and inference; modalities available at inference match those available during training. Break condition: If client hardware cannot support full model inference locally, decentralized inference is impractical; fallback to server-based inference required.

## Foundational Learning

- **Horizontal Federated Learning (HFL)**: Why needed here: BlendFL's HFL pathway requires understanding how FedAvg aggregates models from clients with identical feature spaces but different samples. Quick check question: Can you explain why FedAvg weights by data volume and what non-IID data does to convergence?

- **Vertical Federated Learning (VFL) / Split Learning**: Why needed here: BlendFL's VFL pathway uses server-side feature aggregation and gradient decoupling—concepts from SplitNN architectures. Quick check question: How does SplitNN handle backward passes without sharing raw data, and what communication overhead does this introduce?

- **Multimodal Fusion Architectures**: Why needed here: BlendFL trains modality-specific encoders plus fusion classifiers; understanding late fusion vs. early fusion is critical for architecture choices. Quick check question: Given separate encoders fᴬ and fᴮ, how would you design gᴹ to combine their outputs—concatenation, attention, or gating?

## Architecture Onboarding

- **Component map**: Client-side: local datasets Dᵢ (partial/fragmented/paired), unimodal encoders (fᴬ, fᴮ), unimodal classifiers (gᴬ, gᴮ), multimodal classifier (gᴹ if paired data exists); Server-side: aggregation server (BlendAvg), VFL fusion classifier (gᵐᵥ), validation dataset for performance weighting; Communication: feature exchange (fragmented data → server), gradient return (server → clients), model parameter exchange (clients ↔ aggregation server)

- **Critical path**: 1. Initialize uniform encoders/classifiers across all clients; 2. Per epoch: local partial training → VFL forward/backward on fragmented data → local paired training → BlendAvg aggregation → global model distribution; 3. Repeat until convergence metric reached

- **Design tradeoffs**: More local epochs before update → faster convergence (up to 46% speedup per Figure 2) but higher staleness risk; Larger validation set → more reliable BlendAvg weights but requires more data sharing (privacy concern); Assumption: PSI overhead for patient matching in VFL pathway is acceptable; alternative is skipping VFL for clients with negligible overlap

- **Failure signatures**: Model performance plateaus early → likely validation set too small or unrepresentative for BlendAvg; VFL pathway contributes nothing → check sample overlap via PSI; if near zero, VFL is disabled; Unimodal models diverge from multimodal → verify encoder consistency across clients; architecture mismatch breaks aggregation

- **First 3 experiments**: 1. Baseline replication: Implement FedAvg on single modality (EHR or CXR) to establish HFL-only performance; verify reproduction of Table I/II baseline numbers; 2. BlendAvg ablation: Replace BlendAvg with FedAvg in BlendFL; measure convergence epochs to target AUROC (0.98 on S-MNIST); quantify speedup; 3. Data distribution stress test: Vary paired/partial ratio (90/10 to 10/90 per Figure 3); plot performance curves for BlendFL vs. FedAvg vs. SplitNN to validate robustness claims

## Open Questions the Paper Calls Out
None

## Limitations
- Framework's reliance on Private Set Intersection for client alignment in VFL is not validated for high-dimensional multimodal feature spaces
- BlendAvg assumes a representative validation set exists at the server, but privacy constraints and sample representativeness in real-world healthcare settings are not addressed
- Convergence speedup claims depend on hyperparameter choices (local epochs, learning rate) that are not fully specified

## Confidence

- BlendFL's core mechanism (integrating HFL/VFL with BlendAvg): Medium
- Decentralized inference reducing latency: Medium
- Performance improvements over baselines: High
- Convergence speedup claims: Low

## Next Checks
1. Reproduce FedAvg baseline on single modality (EHR or CXR) to establish HFL-only performance and verify baseline AUROC/AUPRC match reported values
2. Implement BlendAvg ablation by replacing it with FedAvg in BlendFL; measure epochs to reach target AUROC 0.98 on S-MNIST and compare convergence speedup
3. Stress test data distribution by varying paired/partial ratio (90/10 to 10/90) and plotting performance curves for BlendFL vs. FedAvg vs. SplitNN to validate robustness claims