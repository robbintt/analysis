---
ver: rpa2
title: Off-Policy Evaluation Under Nonignorable Missing Data
arxiv_id: '2507.06961'
source_url: https://arxiv.org/abs/2507.06961
tags:
- data
- dropout
- missing
- value
- missingness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates off-policy evaluation (OPE) under monotone
  missing data. It demonstrates that the standard OPE estimator remains consistent
  under ignorable missingness but becomes biased under nonignorable (informative)
  missingness.
---

# Off-Policy Evaluation Under Nonignorable Missing Data

## Quick Facts
- arXiv ID: 2507.06961
- Source URL: https://arxiv.org/abs/2507.06961
- Reference count: 40
- This paper demonstrates that standard OPE estimators are biased under nonignorable missingness and proposes an IPW correction that restores consistency.

## Executive Summary
This paper addresses off-policy evaluation (OPE) in Markov decision processes (MDPs) where transition data is missing not at random (MNAR). Under ignorable (MAR) missingness, standard OPE estimators remain consistent, but under MNAR missingness, they become biased because the missingness depends on unobserved future rewards. The authors propose an inverse probability weighting (IPW) estimator that incorporates the probability of observing complete transition quadruples. They also establish statistical inference for the proposed estimator, providing confidence intervals to quantify estimation uncertainty. The method is validated through theoretical analysis and numerical experiments on both simulation and real-world sepsis data from the MIMIC-III database.

## Method Summary
The proposed method consists of two main estimators: a complete-case (CC) estimator for ignorable missingness and an inverse probability weighted (IPW) estimator for nonignorable missingness. For the IPW approach, the method first estimates a dropout propensity using either parametric or semi-parametric estimation with a shadow variable. The Q-function is approximated using B-spline basis functions, and the value is estimated by solving a weighted Bellman equation. For inference, the asymptotic variance is estimated using a sandwich estimator. The shadow variable approach enables identification of the dropout propensity even when missingness depends on unobserved outcomes.

## Key Results
- Standard OPE estimators remain unbiased under ignorable (MAR) missingness but become biased under nonignorable (MNAR) missingness
- The proposed IPW estimator with dropout propensity weighting restores consistency under MNAR
- Statistical inference is established with confidence intervals that achieve nominal coverage rates
- The method outperforms standard approaches in simulation studies and real-world sepsis data applications

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Standard OPE remains consistent if missingness is ignorable (MAR) but produces biased estimates if missingness is nonignorable (MNAR).
- **Mechanism:** Under MAR, the dropout probability depends only on observed history, allowing unobserved data to be effectively "random" conditional on the past. Under MNAR, dropout depends on unobserved future reward/state, causing standard estimators to systematically over/under-weight specific outcomes.
- **Core assumption:** Assumption A.1 (MDP regularity conditions) and missingness definitions (4.1 vs 4.2)
- **Evidence anchors:** Abstract confirms unbiasedness under ignorable missingness but bias under nonignorable missingness; Theorem 4.5 proves CC estimator consistency under MAR but potential bias under MNAR.

### Mechanism 2
- **Claim:** Incorporating an IPW term based on the probability of observing the transition restores consistency under MNAR.
- **Mechanism:** By weighting every observed transition quadruple by the inverse of its probability of being observed, the estimator re-balances the distribution to account for selectively dropped data.
- **Core assumption:** Assumption A.2(b) (Positivity) and correct specification of the dropout model
- **Evidence anchors:** Section 4.2 proposes IPW estimator; Theorem 4.6 proves consistency as n→∞ or T→∞.

### Mechanism 3
- **Claim:** A "shadow variable" allows identification and estimation of dropout propensity even when missingness depends on unobserved outcomes.
- **Mechanism:** A shadow variable Z correlated with the unobserved outcome but conditionally independent of the missingness indicator given the outcome enables solving an estimating equation to find dropout parameters without observing missing data.
- **Core assumption:** Assumption A.2(c) (Existence of valid shadow variable)
- **Evidence anchors:** Definition 4.8 defines shadow variable; Appendix B.3 discusses domain knowledge requirements for identifying such variables.

### Break condition:
- If dropout propensity approaches 1, weights explode causing infinite variance
- If shadow variable is invalid (correlated with missingness independently of outcome), identifiability fails and bias remains

## Foundational Learning

- **Concept: Missing Data Mechanisms (MAR vs. MNAR)**
  - **Why needed here:** Core problem definition - understanding that "informative" missingness biases standard results motivates the complex IPW estimator
  - **Quick check question:** If a patient drops out of a clinical trial because they die (outcome), is this MAR or MNAR? (Answer: MNAR)

- **Concept: Inverse Probability Weighting (IPW)**
  - **Why needed here:** Mathematical tool used to correct bias - understanding that 1/P(observed) up-weights rare observed events to match true population distribution
  - **Quick check question:** If a specific transition has 50% chance of dropping out, what weight should observed instance receive? (Answer: 1/(1-0.5) = 2)

- **Concept: Sieve Basis Function Approximation**
  - **Why needed here:** Authors use B-splines to approximate Q-function in continuous state space - necessary for implementing value estimation step
  - **Quick check question:** Why does number of basis functions L need to grow with sample size n? (Answer: To reduce approximation error as more data becomes available)

## Architecture Onboarding

- **Component map:** Incomplete trajectories -> Shadow Variable Module -> Propensity Estimator -> IPW Value Estimator -> Inference Module

- **Critical path:** Propensity Estimator is the bottleneck - if ψ is wrong due to bad shadow variable or optimization failure, weights are wrong and final value estimate remains biased

- **Design tradeoffs:**
  - Parametric vs Semi-parametric Propensity: Parametric is faster but risks misspecification; Semi-parametric is flexible but computationally heavier
  - Basis Function Complexity (L): High L fits better but increases variance and computational cost

- **Failure signatures:**
  - High Variance/Instability: Observed weights w become extremely large (implies estimated propensity λ ≈ 1)
  - Non-convergence: GMM optimization for ψ fails to find root (implies invalid shadow variable or poor initialization)

- **First 3 experiments:**
  1. Ignorable (MAR) Sanity Check: Generate MAR dropout data, verify CC estimator performs similarly to IPW (checking IPW doesn't hurt performance on easy data)
  2. Nonignorable (MNAR) Stress Test: Generate data where dropout correlates with high rewards, show CC underestimates/overestimates value while IPW corrects it
  3. Shadow Variable Ablation: Use invalid shadow variable and observe if IPW estimator fails to converge or returns biased results

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the proposed IPW-based correction for nonignorable missingness be adapted for off-policy policy learning (optimization) rather than just evaluation?
- **Basis in paper:** [explicit] Summary section states, "Additionally, we believe that extending this work to learning optimal policies from offline data with nonignorable missingness presents an intriguing direction for future research."
- **Why unresolved:** Paper focuses strictly on evaluation (OPE) and proving consistency/inference for value function, but does not derive algorithms for policy improvement under MNAR
- **What evidence would resolve it:** Theoretical framework or algorithm demonstrating consistency for policy gradients or Q-learning updates using estimated propensity weights under MNAR

### Open Question 2
- **Question:** How can the framework be generalized to handle intermittent (non-monotone) missingness patterns where data can be missing and then reappear?
- **Basis in paper:** [explicit] Appendix F.1 states, "Moreover, the idea of IPW adjustment can potentially be extended to handle intermittent missingness... We leave this for future investigation."
- **Why unresolved:** Current theoretical proofs rely on monotone missingness assumption (once missing, always missing) to define dropout propensity and response indicators
- **What evidence would resolve it:** Consistent estimator and asymptotic analysis for OPE where response indicator η_{i,t} is not a decreasing sequence

### Open Question 3
- **Question:** How can the validity of a candidate shadow variable be empirically tested or validated when domain knowledge is insufficient?
- **Basis in paper:** [inferred] Appendix B.3 notes that if shadow variable conditions are only partially satisfied, likelihood is non-identifiable, and advises sensitivity analysis
- **Why unresolved:** Paper defines necessary conditions for shadow variable but relies on "subject-matter knowledge" for selection; no statistical test provided to verify independence conditions from data alone
- **What evidence would resolve it:** Statistical test or robust estimation method that remains consistent even under minor violations of shadow variable assumption

## Limitations

- Method critically depends on existence of valid shadow variable, which may not be readily available in many real-world applications
- Semi-parametric estimation approach introduces additional tuning parameters (bandwidth selection) that can affect convergence and bias
- When estimated dropout propensity approaches 1, inverse weights become unstable, potentially leading to high-variance estimates despite theoretical consistency

## Confidence

- **High confidence:** Standard OPE estimator bias under nonignorable missingness (well-established in missing data literature)
- **Medium confidence:** Shadow variable identification and estimation (relies heavily on domain knowledge and structural assumptions)
- **Medium confidence:** Asymptotic inference results (assumes large sample sizes and correct model specification)
- **Low confidence:** Performance under extreme missingness rates (weights can become unstable when dropout probability is high)

## Next Checks

1. **Shadow variable robustness test:** Systematically evaluate estimator performance using shadow variables of varying quality (valid, partially correlated, invalid) to quantify sensitivity to Assumption A.2(c) violations.

2. **Propensity estimation stability:** Measure variance and bias of dropout propensity estimates ψ across multiple datasets and initializations to assess robustness of GMM optimization procedure.

3. **Finite-sample coverage verification:** Beyond asymptotic analysis, conduct experiments at smaller sample sizes (n=100, T=5) to verify whether confidence intervals maintain nominal coverage, particularly under nonignorable missingness conditions.