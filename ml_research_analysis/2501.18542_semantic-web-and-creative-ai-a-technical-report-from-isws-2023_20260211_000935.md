---
ver: rpa2
title: Semantic Web and Creative AI -- A Technical Report from ISWS 2023
arxiv_id: '2501.18542'
source_url: https://arxiv.org/abs/2501.18542
tags:
- knowledge
- prompt
- page
- data
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents PICASSO, a decentralized framework using semantic
  web and blockchain technologies to protect artists' rights over AI-generated art.
  The approach integrates Solid pods for secure data storage, blockchain for immutable
  ownership transactions, and an RDF ontology (Klingology) for semantic search of
  prompts and artworks.
---

# Semantic Web and Creative AI -- A Technical Report from ISWS 2023

## Quick Facts
- arXiv ID: 2501.18542
- Source URL: https://arxiv.org/abs/2501.18542
- Reference count: 0
- Primary result: PICASSO framework combines Solid Pods, blockchain, and semantic web to protect artists' rights over AI-generated art

## Executive Summary
This technical report from the 2023 ISWS summer school presents PICASSO, a decentralized framework that uses semantic web and blockchain technologies to protect artists' rights over AI-generated art. The system integrates Solid pods for secure data storage, blockchain for immutable ownership transactions, and an RDF ontology (Klingology) for semantic search of prompts and artworks. Artists retain full control through decentralized storage and smart contracts, enabling secure buying/selling in a self-governed marketplace. The framework ensures privacy, copyright protection, and transparency while empowering artist collectives to own both prompts and generated outputs.

## Method Summary
The report synthesizes research from multiple teams working on semantic web applications for creative AI. Key methodologies include developing decentralized architectures for digital rights management, testing knowledge injection techniques for language models, and evaluating automated knowledge graph generation. The work combines theoretical framework development with empirical experimentation across different model sizes and knowledge representation approaches.

## Key Results
- PICASSO architecture enables decentralized ownership tracking of AI-generated art using Solid Pods and blockchain
- Knowledge injection of symbolic triples consistently degrades performance of smaller language models on creative tasks
- LLM-based knowledge graph generation requires schema constraints to prevent vocabulary drift and hallucination

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decentralized data storage (Solid Pods) combined with immutable ledgers (Blockchain) can provide a functional architecture for digital rights management of AI-generated art.
- **Mechanism:** The architecture separates the *storage of the asset and metadata* (hosted in a Solid Pod with ODRL access control) from the *record of ownership transfer* (stored as an immutable hash on a Blockchain smart contract). The "Klingology" ontology links the prompt, the art, and the artist semantically.
- **Core assumption:** Artists possess the technical capability or support to manage WebIDs and Solid Pods; the legal system will recognize a blockchain transaction hash as proof of provenance.
- **Evidence anchors:**
  - [abstract]: Mentions "Solid pods for secure data storage, blockchain for immutable ownership transactions."
  - [section 4.5]: Describes the PICASSO architecture where the "Web Interface... prepares the data... and continues the execution by registering the operation on the blockchain."
  - [corpus]: The paper "Analysing semantic data storage in Distributed Ledger Technologies for Data Spaces" supports the viability of combining DLT with semantic storage, though specific implementation details for art markets are nascent.
- **Break condition:** If the off-chain metadata (in the Solid Pod) is altered without updating the on-chain hash, or if the user loses access to their WebID/private keys, the link between the artist and the work breaks.

### Mechanism 2
- **Claim:** Injecting unstructured symbolic knowledge (e.g., NERC and WSD triples) into prompts for smaller Language Models (SLMs) may degrade performance on creative tasks like story completion rather than improve it.
- **Mechanism:** The proposed mechanism involves extracting Named Entities and WordNet definitions (triples) and appending them to the prompt to "ground" the model. However, in the reported experiment, this added "noise" that confused the SLM, whereas Large Language Models (LLMs) like GPT-3.5 performed near-perfectly without this injection.
- **Core assumption:** The specific format of the injected triples (e.g., `Sam has_label People`) is processable by the model as useful context rather than distraction.
- **Evidence anchors:**
  - [abstract]: Notes "LLMs have demonstrated their potential... However, several challenges remain... hallucination, information retrieval."
  - [section 3.7]: "The injection of knowledge always and consistently caused a significant decrease in performance... specifically for the Flan-Alpaca-Base model."
  - [corpus]: "Engineering RAG Systems for Real-World Applications" suggests RAG is a standard solution, making the *negative* finding of this paper (that simple injection hurts SLMs) a significant conditional caveat.
- **Break condition:** This negative result implies the mechanism breaks if the knowledge retrieval is not curated or if the target model is too small to disambiguate the injected text from the narrative task.

### Mechanism 3
- **Claim:** LLMs can automate the construction of Knowledge Graphs (KGs) from unstructured text if provided with domain-specific schema constraints (e.g., SHACL shapes) to prevent "hallucinated" vocabulary.
- **Mechanism:** An LLM (like GPT-3.5) processes text to generate RDF triples. Without constraints, the LLM invents its own ontology (ZTG - Zero-shot Triple Generation). The KUBA framework (Chapter 6) proposes adding a "Human Agent" or "Reasoning Refinement" step to align these triples with a user-defined schema.
- **Core assumption:** The LLM's pre-training data contains sufficient semantic understanding of the target domain to map text to the specific schema provided in the prompt.
- **Evidence anchors:**
  - [abstract]: Mentions "potential of LLMs as support tools for knowledge engineering."
  - [section 6.6]: Notes that "vocabulary is self-generated when applying LLM... leading to potential complexities in KG integration."
  - [corpus]: The paper "Food Data in the Semantic Web" reinforces the value of KGs for structuring domain data, but relies on established ontologies; the mechanism here is the *generation* of that data via LLM.
- **Break condition:** If the input text is outside the LLM's training window (e.g., very recent news) or uses highly specialized jargon, the triple extraction accuracy drops, resulting in a disconnected or empty graph.

## Foundational Learning

- **Concept: Solid (Social Linked Data)**
  - **Why needed here:** PICASSO relies on Solid Pods as the primary storage mechanism for art metadata to ensure data sovereignty.
  - **Quick check question:** Can you explain why storing data in a "Pod" controlled by the user differs from storing it on a centralized server like AWS S3?

- **Concept: RDF Triples & SPARQL**
  - **Why needed here:** The "Klingology" ontology and the Music KG (Harmory) are built on RDF; SPARQL is used to query these structures to feed generators.
  - **Quick check question:** How would you write a simple triple representing "Artist X created Image Y"?

- **Concept: Prompt Engineering & Knowledge Injection**
  - **Why needed here:** Several chapters (3, 6, 10) test how adding context (triples, definitions) to a prompt affects the LLM's output.
  - **Quick check question:** What is the difference between "Zero-shot" prompting and providing "few-shot" examples with schema templates?

## Architecture Onboarding

- **Component map:**
  - Web Interface -> Controller -> Generative AI -> Solid Pod (for storage) + Blockchain (for ownership) + Klingology (ontology)

- **Critical path:**
  1. **Ingestion:** Artist inputs prompt -> Controller calls Generative AI.
  2. **Semantic Enrichment:** Art + Prompt are serialized into RDF using Klingology ontology.
  3. **Storage:** RDF/Art stored in Artist's Solid Pod (Access Control applied).
  4. **Anchoring:** Hash of the transaction/RDF is recorded on the Blockchain via Smart Contract.
  5. **Sale:** Buyer requests access -> Payment triggers Smart Contract -> ODRL rules in Solid Pod updated for Buyer.

- **Design tradeoffs:**
  - *Privacy vs. Verifiability:* The system stores actual data in private Solid Pods (Privacy) vs. storing only hashes on the public Blockchain (Verifiability). Full data on-chain is too expensive/public; full data off-chain without anchoring lacks immutable provenance.
  - *Automation vs. Quality:* In KUBA (Ch 6), using LLMs for Zero-shot Triple Generation is faster but prone to errors/hallucination compared to Human-in-the-loop refinement.

- **Failure signatures:**
  - **SPARQL Syntax Errors:** When using Seq2Seq models to translate natural language to SPARQL (Ch 1), the model often fails to generate valid `WHERE` clauses.
  - **Knowledge Injection Noise:** In Story Completion (Ch 3), injecting WSD triples causes accuracy to drop (e.g., from 0.78 to 0.67 in Base models).
  - **Vocabulary Drift:** In KG generation (Ch 6), the LLM creates new predicates not defined in the target ontology, making the graph disjointed.

- **First 3 experiments:**
  1. **PICASSO Workflow Test:** Execute a "create" transaction. Verify that the RDF is generated correctly, the file appears in the mock Solid Pod, and a transaction hash is returned.
  2. **SPARQL Translation Validity:** Test the Seq2Seq model from Chapter 1 with "technical" music prompts. Calculate the percentage of generated SPARQL queries that execute without syntax errors.
  3. **Story Completion Injection:** Replicate the Chapter 3 experiment. Run Flan-Alpaca-Base on ROCStories with and without WordNet triples to verify if the injection consistently degrades accuracy as reported.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does incorporating relevant knowledge from KGs enhance or impair the ability of LMs to generate plausible story completions?
- Basis in paper: [explicit] Chapter 3 reports that knowledge injection (NERC and WSD triples) consistently caused a significant decrease in performance on story completion tasks for smaller LMs, contrary to the authors' hypothesis.
- Why unresolved: The experiments showed knowledge injection introduced noise, but the authors note that the type of knowledge (linguistic vs. factual/commonsense) and amount may be critical factors not yet investigated.
- What evidence would resolve it: Experiments varying knowledge types (commonsense, factual, linguistic) and amounts, across multiple story completion datasets and model sizes.

### Open Question 2
- Question: To what extent can generative AI be used for knowledge graph completion, specifically for missing images in Wikidata?
- Basis in paper: [explicit] Chapter 7 asks RQ1: "To what extent can the output of generative AI be used for knowledge graph completion?" but concludes that current image similarity metrics (UQI) fail to capture semantic content adequately.
- Why unresolved: The evaluation could not determine if prompt enrichment improves generated image quality for KG completion purposes; human evaluation is planned but not yet conducted.
- What evidence would resolve it: Human evaluation studies comparing ground-truth Wikidata images with AI-generated images across different prompt strategies, measuring semantic accuracy and recognizability.

### Open Question 3
- Question: What is the quality of knowledge graphs automatically generated by LLMs for drug indications with medical context?
- Basis in paper: [explicit] Chapter 10 states RQ C ("What is the quality of the generated knowledge graph?") but marks it as "remains unanswered" in the conclusions.
- Why unresolved: While the framework extracts more contextual information than manual curation (75% vs 62% of sentences), quality validation against expert-annotated gold standards is incomplete.
- What evidence would resolve it: Precision/recall analysis against expert-annotated drug indication KGs, clinical expert evaluation of therapeutic intent accuracy, and validation of extracted medical contexts.

### Open Question 4
- Question: Can tacit knowledge (e.g., sarcasm detection, physical skills) be effectively formalized and verbalized using LLMs?
- Basis in paper: [explicit] Chapter 9 asks RQ2 ("Can tacit knowledge be formalized?") and RQ3 ("Can ChatGPT improve the verbalization of tacit knowledge?") after experiments showing ChatGPT underperforms specialized models on sarcasm and struggles to teach physical skills via text alone.
- Why unresolved: Experiments indicate sensory feedback and human interaction are required for tacit knowledge transfer, but hybrid approaches (AR, metaverse) remain untested.
- What evidence would resolve it: Comparative studies of LLM-only vs. hybrid multimodal systems on tacit knowledge tasks, measuring learning outcomes and transfer effectiveness.

## Limitations

- Legal validity of blockchain hashes as proof of artistic ownership remains unproven in current copyright frameworks
- Technical complexity of WebID and Solid Pod management may limit artist adoption
- Knowledge injection mechanisms require careful curation to avoid performance degradation

## Confidence

- **High confidence:** The negative finding that knowledge injection degrades SLM performance
- **Medium confidence:** The PICASSO architectural framework design
- **Low confidence:** The legal enforceability of blockchain-based art ownership transfers and the assumption of artist technical capability

## Next Checks

1. **Legal Feasibility Assessment:** Conduct interviews with intellectual property lawyers to evaluate whether blockchain transaction hashes would be admissible as proof of ownership in current copyright dispute resolution processes across major jurisdictions.

2. **User Experience Pilot:** Implement a minimal working prototype of PICASSO with 10-15 artists of varying technical backgrounds to measure actual adoption barriers, time-to-onboard, and identify specific usability pain points in the WebID/Pod management workflow.

3. **Knowledge Injection Boundary Testing:** Systematically vary the amount and type of injected symbolic knowledge (NERC vs. WSD vs. both) across multiple model sizes (SLM, LLM, and frontier models) on story completion tasks to map the precise conditions under which injection helps versus harms performance.