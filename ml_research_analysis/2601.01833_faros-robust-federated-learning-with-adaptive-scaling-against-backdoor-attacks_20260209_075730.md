---
ver: rpa2
title: 'FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks'
arxiv_id: '2601.01833'
source_url: https://arxiv.org/abs/2601.01833
tags:
- backdoor
- learning
- attacks
- clients
- gradients
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses backdoor attacks in federated learning (FL),
  where malicious clients aim to inject stealthy triggers into the global model to
  manipulate predictions on specific inputs while maintaining normal performance on
  benign data. The core method, FAROS, introduces two key components: Adaptive Differential
  Scaling (ADS) and Robust Core-set Computing (RCC).'
---

# FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks

## Quick Facts
- arXiv ID: 2601.01833
- Source URL: https://arxiv.org/abs/2601.01833
- Reference count: 40
- Primary result: Achieves 4.42% ASR against Edge-case PGD attacks on CIFAR-10 while maintaining main task accuracy

## Executive Summary
FAROS addresses backdoor attacks in federated learning by introducing two complementary mechanisms: Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). ADS dynamically adjusts defense sensitivity based on gradient dispersion, while RCC mitigates single-point-of-failure risks by computing the centroid of a core set of high-confidence clients. The framework demonstrates superior performance against state-of-the-art backdoor attacks across various datasets and non-IID settings, achieving lower attack success rates while maintaining main task accuracy.

## Method Summary
FAROS is a defense framework for federated learning that operates in two stages. First, it applies Adaptive Differential Scaling (ADS) to gradients, using a dynamic scaling factor based on the dispersion of cosine distances between client updates. Second, it employs Robust Core-set Computing (RCC) to select a core set of mutually similar clients and uses their centroid as a reference point to filter out malicious clients. The system assumes honest clients constitute the majority and that malicious updates can be detected through their dissimilarity from the benign core set. FAROS is evaluated on CIFAR-10 and EMNIST datasets with Dirichlet-distributed non-IID partitions, demonstrating effectiveness against various backdoor attacks including Model Replacement, Constrain-and-scale, and Edge-case PGD.

## Key Results
- Reduces ASR from 6.02% to 4.42% against Edge-case PGD attacks on CIFAR-10
- Maintains main task accuracy while defending against backdoor attacks
- Shows strong generalizability across different non-IID settings and client numbers
- Computational overhead of approximately 14.1% compared to standard FedAvg

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Differential Scaling (ADS)
- **Claim:** Dynamically adjusting gradient scaling based on statistical dispersion improves detection of stealthy attacks compared to fixed scaling.
- **Mechanism:** Computes dispersion metric $D_t$ (variance of cosine distances) and maps it to scaling factor $\phi_t$ using exponential decay. Low dispersion triggers aggressive scaling to amplify subtle differences, while high dispersion reduces scaling to avoid misclassifying benign outliers.
- **Core assumption:** Low gradient dispersion correlates with stealthy backdoor attacks, while high dispersion correlates with data heterogeneity or overt attacks.
- **Break condition:** Fails if sophisticated attacks generate high-dispersion gradients or if benign heterogeneity produces very low dispersion, causing over-amplification of noise.

### Mechanism 2: Robust Core-set Computing (RCC)
- **Claim:** Using centroid of a core set of similar clients is more stable than single-anchor clustering for filtering malicious updates.
- **Mechanism:** Calculates pairwise cosine distances for all clients, selects top-$l$ with minimum sum of distances (most central group), computes their centroid, and uses it as benign baseline for filtering.
- **Core assumption:** Majority of clients are honest and significantly more similar to each other than to malicious clients.
- **Break condition:** Fails if malicious clients form large colluding Sybil cluster mimicking benign majority, shifting core set centroid to malicious reference point.

### Mechanism 3: Amplification-Segregation Synergy
- **Claim:** ADS creates separation in feature space while RCC provides stable vantage point to measure that separation.
- **Mechanism:** ADS distorts gradient space geometry to "stretch" anomalies, then RCC operates on stretched space using core set centroid to identify stretched (malicious) vectors.
- **Core assumption:** Scaling transformation preserves benign core cohesion while sufficiently distancing malicious cluster.
- **Break condition:** If ADS scaling is too aggressive, it may shatter benign core set cohesion, causing RCC to select incorrect centroid.

## Foundational Learning

- **Cosine Similarity & Distance:**
  - **Why needed here:** Fundamental metric for entire defense - calculates dispersion ($D_t$) in ADS and selects core set/filter clients in RCC.
  - **Quick check question:** If two gradients have identical directions but different magnitudes, what is their cosine similarity? (Answer: 1.0)

- **Federated Averaging (FedAvg):**
  - **Why needed here:** FAROS is defense wrapper around standard FedAvg; must understand how FedAvg aggregates updates ($g_{agg}$) to see how FAROS modifies this process.
  - **Quick check question:** In standard FedAvg, how does single malicious client's update affect global model compared to benign one if they have equal weight? (Answer: Same magnitude of influence)

- **Backdoor Attacks (Triggers vs. Untargeted Poisoning):**
  - **Why needed here:** Defense specifically tuned for "stealthy" backdoor attacks where model performs well on main tasks (high ACC) but fails on triggered inputs (high ASR).
  - **Quick check question:** Why is maintaining high Main Task Accuracy (ACC) critical constraint for backdoor defense? (Answer: Attacker goal is to maintain normal performance while injecting backdoor)

## Architecture Onboarding

- **Component map:** Raw gradients $g_t^i$ → Normalization → ADS (Calculate $D_t$ → Set $\phi_t$ → Apply Scaling) → RCC (Calculate distances → Select core set → Calculate centroid) → Filtering (Select top-$m$ closest) → Aggregated gradient $g_{agg}$

- **Critical path:** Sequential logic flow from `Calculate $D_t$` → `Set $\phi_t$` → `Apply Scaling` → `Find Core-set Centroid` must be correct. Errors in $D_t$ calculation cascade into incorrect scaling.

- **Design tradeoffs:**
  - **Core-set size ($l$):** Too small risks single-point failure; too large risks including malicious clients shifting centroid
  - **Max scaling ($\phi_{max}$):** High values increase sensitivity to stealthy attacks but risk amplifying benign heterogeneity noise
  - **Overhead:** Adds ~14.1% runtime overhead compared to FedAvg

- **Failure signatures:**
  - **High ASR:** Defense failed to filter - check if $D_t$ consistently high (causing low scaling) or malicious clients clustered tightly (poisoning core set)
  - **Low ACC:** Defense filtered too aggressively - check if $D_t$ consistently low (causing high scaling) or data heterogeneity misidentified as attack

- **First 3 experiments:**
  1. **Baseline Verification:** Reproduce CIFAR-10 comparison in Table 1 - compare FAROS against "Scope" using "Edge-case PGD" attack to verify ASR drop (6.02% → 4.42%)
  2. **Ablation Study:** Run "Only ADS" and "Only RCC" configurations (Table 2) to validate synergy claim - confirm "Only RCC" performs poorly against Edge-case PGD
  3. **Heterogeneity Stress Test:** Reproduce Figure 2 by varying Dirichlet concentration parameter $q$ - verify FAROS maintains ACC better than Scope as $q$ decreases

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can Reinforcement Learning (RL) optimize the scaling factor in Adaptive Differential Scaling (ADS) more effectively than current exponential decay heuristic?
- **Basis in paper:** Authors explicitly state in conclusion aim to "explore more advanced dynamic adjustment strategies for the ADS. This may include introduction of Reinforcement Learning (RL) to determine optimal scaling factor."
- **Why unresolved:** Current ADS relies on predefined exponential decay function that may not be optimal mapping for all attack vectors or data distributions.
- **What evidence would resolve it:** Empirical results comparing convergence speed and defense robustness of RL-based ADS agent against current heuristic across varying non-IID settings and attack intensities.

### Open Question 2
- **Question:** How can FAROS be integrated with privacy-preserving technologies like Differential Privacy (DP) or Homomorphic Encryption (HE) without compromising defense robustness?
- **Basis in paper:** Conclusion outlines future direction to "investigate how to combine our robustness mechanisms with techniques such as Differential Privacy (DP) and Homomorphic Encryption (HE)."
- **Why unresolved:** Current framework focuses solely on integrity while DP and HE introduce noise or computational constraints that could interfere with gradient dispersion calculations essential to ADS.
- **What evidence would resolve it:** Analysis of trade-offs between DP noise and ADS dispersion sensitivity, or prototype implementation demonstrating defense remains effective under encrypted gradients.

### Open Question 3
- **Question:** How robust is FAROS when assumption that honest clients constitute majority ($k-c > k/2$) is violated by sophisticated Sybil attack?
- **Basis in paper:** System setting explicitly assumes "honest clients constitute the majority in the selected subset." RCC selects core-set based on "highest mutual similarity" which would likely identify malicious majority as "benign" core if assumption broken.
- **Why unresolved:** Paper evaluates robustness against backdoor attacks but doesn't test breaking point when malicious clients outnumber honest ones.
- **What evidence would resolve it:** Experimental simulations where malicious client fraction exceeds 50%, specifically testing if RCC mistakenly calculates malicious cluster centroid as trusted benchmark.

## Limitations

- Evaluation relies on specific attack implementations and hyperparameter configurations not fully specified in paper
- Fundamental assumption that benign clients form coherent core set may fail in highly non-IID scenarios
- Computational overhead scaling with client count beyond tested 200-client setup not fully characterized
- Defense performance against adaptive attacks specifically targeting dispersion-based detection not evaluated

## Confidence

**Medium confidence** - While experimental results show promising ASR reductions (6.02% → 4.42%), evaluation relies on specific attack implementations and hyperparameter configurations not fully specified. The fundamental assumption that benign clients form coherent core set may fail in highly non-IID scenarios or with sophisticated colluding attacks.

## Next Checks

1. Test FAROS against white-box adaptive attacker that manipulates gradient dispersion to evade ADS detection while maintaining backdoor effectiveness
2. Evaluate defense performance across broader range of non-IID distributions (varying Dirichlet parameters beyond q=0.4) to assess core-set stability
3. Measure FAROS computational overhead and memory usage with 500+ clients to verify linear scaling claims