---
ver: rpa2
title: 'FactAppeal: Identifying Epistemic Factual Appeals in News Media'
arxiv_id: '2510.10627'
source_url: https://arxiv.org/abs/2510.10627
tags:
- source
- appeal
- epistemic
- factual
- fact
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces FactAppeal, a dataset of 3,226 annotated news
  sentences aimed at identifying factual claims and their epistemic appeals to external
  sources. Unlike prior work that focuses on claim verification, FactAppeal provides
  fine-grained span-level annotations capturing the type of source (e.g., expert,
  witness), method of appeal (direct or indirect quotation), and other attributes.
---

# FactAppeal: Identifying Epistemic Factual Appeals in News Media

## Quick Facts
- arXiv ID: 2510.10627
- Source URL: https://arxiv.org/abs/2510.10627
- Reference count: 16
- Primary result: Introduces FactAppeal dataset with 3,226 annotated news sentences for identifying factual claims and epistemic source appeals

## Executive Summary
FactAppeal introduces a novel dataset of 3,226 English news sentences annotated for epistemic factual appeals, capturing not just factual claims but how they gain credibility through external sources. Unlike prior work focused on claim verification, FactAppeal provides fine-grained span-level annotations identifying factual statements, source mentions, and their characteristics including source type (expert, witness, official, etc.) and quotation method (direct/indirect). The dataset enables modeling of how credibility is linguistically signaled in news reporting. Experiments compare encoder-only models (RoBERTa, DeBERTa v3, ModernBERT) with generative decoder models (Gemma 2 2B/9B, Llama 3.1 8B, Mistral 7B) in the 2B-9B parameter range, with Gemma 2 9B achieving the best performance at 0.73 macro-F1, demonstrating that generative models can effectively capture epistemic appeal structures.

## Method Summary
The FactAppeal dataset contains 3,226 English news sentences from 2020-2022, split 70/15/15 for train/dev/test. Annotations use XML-style tags at span-level to identify factual claims (Fact_Appeal/Fact_No_Appeal), sources, source attributes, recipients, and temporal/spatial information. Two modeling approaches are compared: encoder models using token-level multi-label classification with focal loss, and decoder models using sequence-to-sequence generation producing XML-tagged outputs with QLoRA fine-tuning. Models are evaluated using word-level precision, recall, and macro-averaged F1 across 18 tag categories. The best-performing model, Gemma 2 9B, achieves 0.73 macro-F1.

## Key Results
- Gemma 2 9B achieves 0.73 macro-F1, outperforming encoder baselines (RoBERTa 0.70, DeBERTa v3 0.69, ModernBERT 0.54)
- Generative decoder models show modest but consistent advantage over encoder models for this structured prediction task
- Performance varies significantly across tag categories, with rare tags like Witness showing lower F1 scores
- Unnamed sources perform worse than named sources across all models
- XML generation formulation enables models to capture joint dependencies among claim spans, source spans, and attributes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Span-level annotations of source types and quotation methods enable models to capture the epistemic justification structure behind factual claims.
- Mechanism: By explicitly delimiting which text spans constitute claims versus source attributions—and labeling source characteristics (Expert, Witness, Official, etc.) and quotation style (Direct/Indirect)—models learn to disentangle claim content from evidentiary support, recognizing how credibility is signaled linguistically.
- Core assumption: Epistemic credibility in news follows identifiable, consistent patterns involving source mentions and quotation structures.
- Evidence anchors:
  - [abstract] "FactAppeal contains span-level annotations which identify factual statements and mentions of sources on which they rely. Moreover, the annotations include fine-grained characteristics of factual appeals such as the type of source (e.g. Active Participant, Witness, Expert, Direct Evidence)... attribution to the source via direct or indirect quotation."
  - [section 3.1] "Span-level tags are a key advantage of FactAppeal, allowing differentiating factual appeals, facts without appeals and non-factual components in a single text, as well as identifying multiple epistemic sources. Tags of different types may also be nested."
  - [corpus] Related work on factual appeals in partisan news ("You're Not Gonna Believe This") addresses epistemic strategies but does not validate this specific span-annotation mechanism; corpus evidence is indirect.
- Break condition: If epistemic appeal patterns vary substantially across languages, cultures, or time periods such that annotations from 2020–2022 English news do not generalize.

### Mechanism 2
- Claim: Formulating epistemic appeal identification as a sequence-to-sequence XML generation task allows decoder models to outperform token-level multi-label classification by encoder models.
- Mechanism: Generative LLMs trained to output XML-tagged sentences from raw inputs can capture joint dependencies among claim spans, source spans, and attributes within a unified structured output, whereas encoder models treat each label independently at the token level.
- Core assumption: The XML tagging format is learnable by 2B–9B parameter decoders, and this formulation captures cross-label dependencies better than independent token classifiers.
- Evidence anchors:
  - [abstract] "Our best performing model, based on Gemma 2 9B, achieves a macro-F1 score of 0.73."
  - [section 5] "In this setting, annotations are represented as XML-style tags... Models are trained to produce the annotated sentence given the raw sentence." Table 2 shows Gemma 2 9B (0.73) exceeding RoBERTa (0.70), DeBERTa v3 (0.69), and ModernBERT (0.54).
  - [corpus] "Evaluating open-source Large Language Models for automated fact-checking" explores LLMs for verification but does not test this XML generation mechanism; corpus evidence is weak.
- Break condition: If performance gains are primarily due to model scale rather than the generative formulation, or if XML formatting proves brittle for longer documents or complex nested structures.

### Mechanism 3
- Claim: A two-dimensional typology of sources—by proximity to events (internal/external) and by human/non-human status—enables structured modeling of distinct epistemic justification logics.
- Mechanism: Categories such as Active Participant, Witness, Official, Expert, Direct Evidence, Expert Document, and News Report operationalize how credibility is conferred—internal sources via firsthand contact, external sources via specialized expertise—providing models with distinguishable patterns to learn.
- Core assumption: These categories are linguistically distinguishable and meaningfully map onto epistemic strategies used in news reporting.
- Evidence anchors:
  - [section 3.3] "As shown in Figure 1, our typology classifies sources according to two fundamental dimensions: (1) proximity to the event (internal vs. external) and (2) whether the source is human or non-human."
  - [section 3.3] "The distinction between internal and external sources also reflects two modes or logics of epistemology—a common-wisdom logic preferring those with direct relations to the matter at hand, as opposed to an expertise-based logic preferring 'detached' experts."
  - [corpus] No direct corpus evidence validates this specific two-dimensional typology; prior work on source attribution exists but does not confirm this structure.
- Break condition: If source types are frequently ambiguous or context-dependent, or if the internal/external distinction fails to capture real-world complexity (e.g., experts with direct involvement).

## Foundational Learning
- Concept: Epistemic Appeal
  - Why needed here: Central to the paper's task; distinguishes factual claims supported by external authority from unsupported claims or non-factual statements.
  - Quick check question: Given a news sentence quoting a climate scientist about temperature data, can you identify which span is the factual claim and which is the epistemic source?

- Concept: Span-Level Annotation
  - Why needed here: The dataset's granularity requires marking precise text boundaries for claims, sources, and attributes so models learn where each begins and ends.
  - Quick check question: In "Dr. Smith, a virologist, said the virus spreads through airborne particles," which spans would you tag as Source, Source_Attribute, and Fact_Appeal?

- Concept: Sequence-to-Sequence Fine-Tuning with QLoRA
  - Why needed here: The generative approach uses QLoRA fine-tuning for efficient training of decoder models to produce structured XML outputs.
  - Quick check question: How does masking input prompt tokens from loss calculation affect training in a seq2seq setup?

## Architecture Onboarding
- Component map:
  Input: Raw news sentence → Encoder path: RoBERTa/DeBERTa/ModernBERT → Token-level multi-label classification (18 labels) with focal loss → Output: 18 tag predictions per token
  Input: Raw news sentence → Decoder path: Gemma 2 (2B/9B), Llama 3.1 8B, Mistral 7B → Seq2seq generation (raw → XML-tagged sentence) with QLoRA (4-bit, r=256, alpha=256) → Output: XML-tagged sentence with nested spans

- Critical path:
  1. Data prep: Convert span annotations to multi-label token tags (encoder) or XML-tagged strings (decoder)
  2. Model selection: Gemma 2 9B is current top performer (macro-F1 0.73)
  3. Fine-tuning: QLoRA for 3 epochs (decoders) or up to 12 epochs with focal loss (encoders)
  4. Evaluation: Word-level precision/recall/F1 per tag; macro-average across 18 tags

- Design tradeoffs:
  - Encoder vs. Decoder: Encoders are faster and simpler; decoders better capture structured output dependencies but require more resources. Paper shows decoders marginally outperform encoders at 2B–9B scale.
  - Sentence vs. document context: Current dataset is sentence-level; extending to paragraphs/articles could capture richer epistemic structures but increases annotation and modeling complexity.
  - XML output format: Chosen for readability and nesting; may require post-processing for downstream applications.

- Failure signatures:
  - Confusion between Fact_Appeal and Fact_No_Appeal when a source is mentioned without being invoked as epistemic authority (e.g., merely reporting a quote)
  - Poor performance on rare tags (e.g., ModernBERT F1=0.10 for Witness vs. Gemma 2 9B F1=0.57), indicating sensitivity to class imbalance
  - Lower F1 for unnamed sources versus named sources across all models

- First 3 experiments:
  1. Replicate encoder baseline: Fine-tune RoBERTa base with focal loss on token-level multi-label task; verify macro-F1 ≈ 0.70
  2. Match top decoder result: Fine-tune Gemma 2 9B with QLoRA on XML generation; target macro-F1 ≈ 0.73
  3. Ablate model scale: Fine-tune Gemma 2 2B under identical conditions to quantify performance drop; expect macro-F1 ≈ 0.60

## Open Questions the Paper Calls Out
- **Context Expansion**: How does expanding the annotation context from single sentences to paragraphs or entire articles affect model performance on epistemic appeal identification? The authors suggest this could provide more comprehensive modeling of relationships.
- **Source-Claim Linking**: Does explicitly linking specific sources to their corresponding claims improve performance in sentences containing multiple appeals? Current annotations don't capture these relationships explicitly.
- **Cross-Domain Generalization**: Can models trained on FactAppeal generalize to epistemic appeals in social media content or non-English languages? The authors identify this as a key limitation given the English news focus.

## Limitations
- Dataset generalizability: Covers only English news from 2020-2022; performance on other languages or time periods is untested
- Annotation subjectivity: Human judgment in span boundaries and source type assignments, though IAA values are reasonable
- Model architecture dependence: Generative formulation's superiority may depend on specific model families and scales tested

## Confidence
- **High Confidence**: Dataset creation, annotation schema, and task definition are well-documented and reproducible
- **Medium Confidence**: Comparative results between encoder and decoder models are internally consistent but may not generalize to all encoder/decoder pairs
- **Low Confidence**: Claims about the superiority of the XML generation formulation or the two-dimensional source typology lack strong external validation

## Next Checks
1. **Cross-lingual transfer**: Fine-tune Gemma 2 9B on FactAppeal and evaluate on a parallel epistemic appeal dataset in another language (e.g., ClaimPT for Portuguese) to test schema portability
2. **Temporal robustness**: Train on early 2020s data and test on recent news to measure degradation, isolating whether epistemic appeal patterns are stable or shift over time
3. **Encoder-decoder ablation**: Compare Gemma 2 9B (XML generation) to the same model with a token-level multi-label head under identical training conditions to isolate the contribution of the generative formulation versus model capacity