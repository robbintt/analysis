---
ver: rpa2
title: 'Towards Generalized Routing: Model and Agent Orchestration for Adaptive and
  Efficient Inference'
arxiv_id: '2509.07571'
source_url: https://arxiv.org/abs/2509.07571
tags:
- uni00000003
- uni00000048
- uni00000051
- uni00000057
- uni00000044
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'MoMA (Mixture of Models and Agents) is a generalized routing framework
  that dynamically selects the most suitable large language model (LLM) or agent for
  diverse user queries, achieving optimal performance-cost trade-offs. It employs
  a two-layer routing strategy: first using semantic similarity to identify relevant
  agent categories, then leveraging a context-aware finite state machine with token
  logits masking for precise agent selection.'
---

# Towards Generalized Routing: Model and Agent Orchestration for Adaptive and Efficient Inference

## Quick Facts
- **arXiv ID:** 2509.07571
- **Source URL:** https://arxiv.org/abs/2509.07571
- **Reference count:** 13
- **Primary result:** MoMA achieves comparable performance to the strongest single model (qwen3-235b-a22b) while reducing cost by 31.46% across three benchmarks.

## Executive Summary
MoMA (Mixture of Models and Agents) introduces a generalized routing framework that dynamically selects the most suitable large language model (LLM) or agent for diverse user queries, achieving optimal performance-cost trade-offs. It employs a two-layer routing strategy: first using semantic similarity to identify relevant agent categories, then leveraging a context-aware finite state machine with token logits masking for precise agent selection. For LLM routing, MoMA constructs a large-scale capability-profiling dataset and trains a MoE-based router using pairwise preference signals from a judge model. The router selects the best-performing LLM based on a score-cost Pareto frontier. Evaluated across three benchmarks (AIME2024, LiveCodeBench, SimpleQA) with 12 LLMs, MoMA achieves comparable performance to the strongest single model (qwen3-235b-a22b) while reducing cost by 31.46%. Its adaptive, scalable design supports diverse model pools and is deployed in real-world applications.

## Method Summary
MoMA's routing framework operates in two tiers: an LLM router that selects between multiple models based on capability profiling, and an agent router that chooses specialized tools for specific tasks. The LLM router uses a Qwen-3 encoder feeding into a Mixture-of-Experts (MoE) head trained on pairwise preference signals generated by a judge model. Selection follows a Pareto-optimal score-cost frontier using TOPSIS. The agent router employs a two-layer strategy: semantic similarity matching to agent categories, followed by context-aware finite state machine (FSM) selection with token logits masking. The system was trained on a dataset of 2.25M queries spanning domains like math, coding, and writing, with model capabilities profiled through pairwise comparisons.

## Key Results
- MoMA achieves 43.3 average score at 6.306 cost (auto-routing) vs. 70.1 at 10.04 cost for performance-priority, demonstrating effective tradeoff control
- Compared to strongest single model (qwen3-235b-a22b), MoMA achieves comparable performance while reducing cost by 31.46%
- Successfully routes across three benchmarks (AIME2024, LiveCodeBench, SimpleQA) with 12 different LLMs

## Why This Works (Mechanism)

### Mechanism 1: MoE-Based Router with Pairwise Preference Learning
- Claim: A mixture-of-experts router trained on pairwise preference signals can predict relative LLM performance more accurately than direct classification.
- Mechanism: The router encodes queries through an LLM encoder, routes to top-k experts via a gating network, and outputs M-dimensional performance scores. Training uses pairwise comparison quadruples [qi, ma, mb, wi] where wi captures 5-level preference (equal/strong win/loss). The loss function (Equation 5) optimizes categorical cross-entropy over predicted win probabilities using a dynamic threshold θ to distinguish strong vs. weak preferences.
- Core assumption: Judge model (LLM-as-judge) evaluations generalize to real user preferences; relative rankings transfer across query distributions.
- Evidence anchors:
  - [abstract]: "trains a MoE-based router using pairwise preference signals from a judge model"
  - [Section 4.1.2-4.1.3]: Describes quadruple construction and probability modeling with Equations 1-5
  - [corpus]: Contrastive learning approaches (Adaptive Minds, CASTER) similarly leverage relative signals rather than absolute labels, supporting this design choice
- Break condition: Judge model exhibits systematic bias toward specific model families; training distribution diverges significantly from production queries

### Mechanism 2: Score-Cost Pareto Frontier with TOPSIS Selection
- Claim: Constructing a Pareto frontier from predicted scores and known costs enables principled performance-cost tradeoffs.
- Mechanism: For each query, the router produces scores for all candidate LLMs. Combined with pre-computed costs (FLOPS or pricing), Pareto-optimal models are identified. TOPSIS (Equations 8-11) computes relative closeness to ideal point (0 cost, 1 score) with configurable weights wc/ws for user preferences (cost-priority, performance-priority, auto-routing).
- Core assumption: Cost and score have consistent inverse relationship; Pareto structure exists and is learnable.
- Evidence anchors:
  - [Section 4.1.4]: Full formalization of Pareto frontier construction and TOPSIS selection
  - [Table 3]: Auto-routing achieves 43.3 avg score at 6.306 cost vs. performance-priority's 70.1 at 10.04 cost—demonstrating tradeoff control
  - [corpus]: Adaptive LLM Routing under Budget Constraints addresses similar budget-aware selection; corpus shows this is an active research direction
- Break condition: Actual inference costs vary unpredictably (e.g., variable-length outputs); user utility function is non-monotonic in cost/score

### Mechanism 3: Hierarchical Agent Routing with Token Logits Masking
- Claim: A two-layer routing strategy with context-aware FSM prevents context explosion and ensures only valid agents are selectable.
- Mechanism: Layer 1 uses SBERT embeddings to match queries to top-k agent categories via cosine similarity. Layer 2 employs a finite state machine where states represent intent combinations (e.g., "TRAVEL AND FOOD"). Token logits for unavailable agents are masked to -∞ before softmax, ensuring the LLM can only output valid agent names. KV-cache prefetching avoids redundant routing.
- Core assumption: Agent categories are sufficiently discriminative; state transitions capture meaningful intent combinations.
- Evidence anchors:
  - [Section 4.2]: Describes divide-and-conquer strategy and logits masking
  - [Appendix A.2]: Full FSM formalization with atomic/composite states and hybrid rule-semantic transitions
  - [corpus]: Agentic Lybic uses FSM-based architecture; CASTER addresses context-aware routing—confirming FSM approaches in multi-agent orchestration
- Break condition: Agent pool grows beyond state machine expressiveness; novel intent combinations require frequent FSM re-engineering

## Foundational Learning

- Concept: **LLM-as-a-Judge Evaluation**
  - Why needed here: The router's training data relies on judge model comparisons to generate preference labels. Understanding judge bias, calibration, and failure modes is critical for assessing router quality.
  - Quick check question: Given two model responses, can you articulate what dimensions the judge evaluates and what systematic biases might affect its choices?

- Concept: **Pareto Optimality in Multi-Objective Optimization**
  - Why needed here: The score-cost tradeoff mechanism assumes understanding of dominated solutions and frontier construction. Without this, TOPSIS selection appears arbitrary.
  - Quick check question: For a set of (cost, score) pairs, can you manually identify which points are Pareto-optimal and explain why?

- Concept: **Finite State Machine Design for Intent Modeling**
  - Why needed here: The agent routing layer models user intent as FSM states. Understanding state explosion, composite states, and transition design is necessary for extending the agent pool.
  - Quick check question: Given 5 atomic intents (e.g., TRAVEL, FOOD, SHOPPING), how many composite states are theoretically possible, and which would you prioritize implementing?

## Architecture Onboarding

- Component map:
  - **LLM Router**: Encoder (Qwen-3) → MoE Head (gating + experts) → Score Vector → Pareto Builder → TOPSIS Selector → Optimal LLM
  - **Agent Router**: Query Embedding → Category Retrieval (cosine similarity) → FSM State Resolution → Candidate Filtering → Token Masking → LLM Final Decision → Agent Invocation
  - **Training Pipeline**: Dataset (2.25M queries) → Pairwise Comparison → Judge Evaluation → Quadruple Construction → MoE Router Training
  - **Inference Optimization**: KV-Cache Prefetching → Cache Hit Check → Full Routing (if miss)

- Critical path: Training data quality → Judge evaluation reliability → Router score accuracy → Pareto frontier validity → TOPSIS selection. Weak judge signals propagate through the entire system.

- Design tradeoffs:
  - **MoE vs. SFT Classification**: MoE requires pairwise data but handles ambiguous task boundaries better; SFT needs clean labels (Table 1 comparison)
  - **Performance vs. Cost weights**: Auto-routing trades ~38% performance for ~60% cost reduction vs. performance-priority (Table 3)
  - **Category granularity in agent routing**: More categories improve precision but increase first-layer routing complexity

- Failure signatures:
  - Router always selects same few models: Likely training data imbalance or collapsed expert specialization
  - Agent selection hallucinates non-existent agents: Logits masking not applied correctly or FSM state mismatched to category
  - Cost unexpectedly high despite cost-priority: Pareto frontier may be sparse for certain query types; TOPSIS weights may be misconfigured

- First 3 experiments:
  1. **Router calibration check**: Run router on held-out queries with known ground-truth model rankings; compare predicted scores to actual performance using Spearman correlation
  2. **Pareto frontier visualization**: For 100 diverse queries, plot (cost, predicted_score) for all models; verify frontier points are non-dominated and frontier shape is reasonable
  3. **Agent FSM state coverage audit**: Log all FSM state transitions over 1000 production queries; identify if certain composite states are never reached (indicating over-engineering) or if unknown states are attempted (indicating coverage gaps)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can capability profiling effectively distinguish between LLMs that originate from similar domains or have overlapping performance characteristics?
- Basis in paper: [explicit] The authors state on Page 2 that "it is far from trivial to characterize the LLM profile, especially when facing LLMs from similar domains."
- Why unresolved: The paper constructs a large dataset to profile capabilities but does not detail a specific mechanism to decouple performance signals for models with highly correlated strengths.
- What evidence would resolve it: An ablation study showing routing accuracy specifically for pairs of models with high capability overlap (e.g., two distinct code-specialized models).

### Open Question 2
- Question: How can the routing framework maintain precise intent-agent matching as the ecosystem expands and functional boundaries blur?
- Basis in paper: [explicit] Page 2 highlights that "the expansion of the agent ecosystem complicates precise intent-agent matching due to increasing functional overlaps."
- Why unresolved: While a context-aware state machine is proposed, the experiments only validate the system on a limited set of benchmarks and agents, leaving the "blurry boundary" problem in massive ecosystems untested.
- What evidence would resolve it: Evaluation of routing accuracy in a simulated environment with hundreds of agents featuring deliberately ambiguous or overlapping functional descriptions.

### Open Question 3
- Question: How does the reliance on "LLM-as-a-judge" for preference data impact the router's robustness against the judge model's inherent biases?
- Basis in paper: [inferred] The paper utilizes pairwise preference signals from a judge model (Page 6) to train the router, but acknowledges in Appendix A.4 that other approaches suffer from "judge bias risks."
- Why unresolved: It is unclear if the MoMA router propagates the specific preferences or hallucinations of the judge model (Gemini 2.5) rather than learning objective ground-truth capabilities.
- What evidence would resolve it: A comparison of router performance when trained on preference data generated by different "judge" models to measure variance.

### Open Question 4
- Question: What are the latency scaling limits of the context-aware finite state machine (FSM) when the agent pool grows significantly larger?
- Basis in paper: [inferred] The paper claims the FSM is efficient (Page 8) and was tested with "over 20 expert agents" (Page 14), but provides no theoretical or empirical analysis of latency as the state space expands.
- Why unresolved: The complexity of state transitions and dynamic masking in an FSM could become a bottleneck if the number of agents increases by an order of magnitude.
- What evidence would resolve it: Latency benchmarks measuring the time-to-route as the number of available agents increases from tens to hundreds.

## Limitations
- The router's performance depends heavily on the quality and representativeness of the judge model's evaluations
- FSM-based agent routing may face scalability challenges as agent ecosystems grow beyond current testing scope
- Cost predictions assume static pricing models, which may not reflect variable-length inference costs in practice

## Confidence
- **Router architecture and MoE design**: High - well-specified with clear equations and implementation details
- **Judge model reliability**: Medium - acknowledges bias risks but doesn't extensively validate against ground truth
- **FSM scalability**: Low - claims efficiency but lacks empirical analysis of scaling behavior

## Next Checks
1. **Router calibration validation**: Compare router-predicted scores against actual model performance on held-out queries using Spearman correlation
2. **Pareto frontier sanity check**: Visualize (cost, predicted_score) plots for diverse queries to verify non-dominated frontier structure
3. **FSM state coverage audit**: Log FSM transitions over production queries to identify coverage gaps or over-engineered states