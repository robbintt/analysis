---
ver: rpa2
title: 'EAvatar: Expression-Aware Head Avatar Reconstruction with Generative Geometry
  Priors'
arxiv_id: '2508.13537'
source_url: https://arxiv.org/abs/2508.13537
tags:
- gaussian
- reconstruction
- head
- geometry
- avatar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EAvatar, a novel 3D head avatar reconstruction
  framework based on 3D Gaussian Splatting (3DGS) that addresses limitations in capturing
  fine-grained facial expressions and preserving local texture continuity. The method
  introduces a controllable Gaussian mechanism that identifies key Gaussians with
  large expression-induced deformation and propagates their influence to neighboring
  Gaussians using distance-weighted interpolation, enabling accurate modeling of local
  deformations and fine-scale texture transitions.
---

# EAvatar: Expression-Aware Head Avatar Reconstruction with Generative Geometry Priors

## Quick Facts
- **arXiv ID:** 2508.13537
- **Source URL:** https://arxiv.org/abs/2508.13537
- **Authors:** Shikun Zhang; Cunjian Chen; Yiqun Wang; Qiuhong Ke; Yong Li
- **Reference count:** 40
- **Primary result:** PSNR of 25.07 on self-reenactment tasks with 32 FPS rendering speed

## Executive Summary
EAvatar introduces a novel 3D head avatar reconstruction framework that addresses key limitations in capturing fine-grained facial expressions and preserving local texture continuity. The method leverages 3D Gaussian Splatting with a controllable Gaussian mechanism that identifies key Gaussians with large expression-induced deformation and propagates their influence to neighboring Gaussians using distance-weighted interpolation. Additionally, EAvatar employs a deformation-aware Gaussian splitting strategy that adaptively duplicates Gaussians in highly deformable regions to enhance geometric expressiveness, and uses high-quality 3D priors from pretrained generative models to provide structural guidance that improves convergence stability and shape accuracy during training.

## Method Summary
EAvatar operates in a two-stage pipeline: Stage I optimizes an SDF-based geometry with DMTet extraction guided by a generative prior mesh, while Stage II performs dynamic Gaussian optimization with controllable mechanisms. The framework introduces a sparse expression control mechanism that propagates deformation from high-motion "Control Gaussians" to neighbors, a deformation-aware splitting strategy that allocates representation capacity based on motion magnitude, and leverages generative priors to stabilize early optimization. The method uses 3DMM parameters as driving signals and achieves real-time rendering at 32 FPS on RTX 3090 hardware.

## Key Results
- Achieves PSNR of 25.07 on self-reenactment tasks, outperforming state-of-the-art methods
- Renders at 32 FPS on RTX 3090, enabling real-time applications
- Shows significant improvements in preserving high-frequency details and expression transferability
- Demonstrates better handling of fine-grained facial expressions and local texture continuity

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The sparse expression control mechanism improves local texture continuity by propagating deformation from high-motion "Control Gaussians" to their neighbors.
- **Mechanism:** The framework first identifies Control Gaussians where expression-induced displacement exceeds a threshold. Instead of moving these points in isolation, it calculates a weighted displacement for neighboring Gaussians based on spatial proximity. This propagates motion to surrounding areas, enforcing local geometric consistency.
- **Core assumption:** Assumes that facial deformation is spatially smooth; neighbors of a highly displaced point should move in sympathy to prevent texture tearing or blurring.
- **Evidence anchors:**
  - [Abstract]: "...propagates their influence to neighboring Gaussians using distance-weighted interpolation..."
  - [Section 3.2]: "This neighborhood-aware adjustment... promotes smoother local deformations while preserving sharp details..."
  - [Corpus]: Corpus papers like *CAG-Avatar* explore similar localized control, validating the move away from global deformation.

### Mechanism 2
- **Claim:** The deformation-aware splitting strategy enhances geometric expressiveness in highly dynamic regions by allocating representation capacity based on motion magnitude.
- **Mechanism:** Standard 3DGS often splits Gaussians based on opacity or screen-space gradients. EAvatar introduces a splitting trigger based on displacement magnitude. When a Gaussian moves significantly, it is duplicated to increase local density, allowing the model to resolve complex geometries that appear during motion.
- **Core assumption:** Assumes that high displacement correlates with geometric complexity that requires higher sampling density to render accurately.
- **Evidence anchors:**
  - [Abstract]: "...employs a deformation-aware Gaussian splitting strategy that adaptively duplicates Gaussians..."
  - [Section 4.5.3]: "...by tracking significant changes in Gaussian attributes, our method effectively adapts to local deformations..."
  - [Corpus]: Weak direct evidence; standard splitting strategies in 3DGS literature focus on screen coverage.

### Mechanism 3
- **Claim:** Using a mesh generated by a large-scale pretrained model as a structural prior stabilizes the early optimization of the implicit geometry (SDF).
- **Mechanism:** The framework generates a high-quality prior mesh from a single image using a generative model. It aligns this mesh to the predicted SDF-derived mesh and constrains the training using a global alignment loss. This prevents the SDF from collapsing or drifting before the Gaussian stage begins.
- **Core assumption:** Assumes the generative prior is sufficiently accurate and identity-specific to serve as a "ground truth" anchor for global structure.
- **Evidence anchors:**
  - [Abstract]: "...leverages high-quality 3D priors... to provide structural guidance that improves convergence stability..."
  - [Section 3.3]: "...loss is robust to local noise and significantly improves early-stage geometric stability."
  - [Corpus]: Papers like *LHM* and *Object Reconstruction under Occlusion* support the general efficacy of generative priors for handling ambiguity.

## Foundational Learning

- **Concept: 3D Gaussian Splatting (3DGS)**
  - **Why needed here:** This is the underlying representation. You must understand how 3D Gaussians (position, covariance, opacity, color) are rasterized to grasp how "splitting" or "control" affects the final image.
  - **Quick check question:** How does adjusting the covariance (scale/rotation) of a Gaussian affect its footprint on the image plane?

- **Concept: Signed Distance Functions (SDF) & DMTet**
  - **Why needed here:** EAvatar uses a two-stage pipeline where Stage 1 optimizes an SDF which is meshed via DMTet to initialize the Gaussians.
  - **Quick check question:** Why might an SDF be preferred over a density field (NeRF) for extracting a surface mesh for avatar initialization?

- **Concept: 3D Morphable Models (3DMM)**
  - **Why needed here:** The framework uses 3DMM parameters as the driving signals for the deformation network.
  - **Quick check question:** What are the limitations of using 3DMM expression coefficients to drive highly localized deformations (e.g., lip rolling)?

## Architecture Onboarding

- **Component map:** Multi-view images + 3DMM tracking data -> Stage I (Generative Prior Mesh -> SDF Network -> DMTet -> Mesh Alignment Loss) -> Stage II (Initialize Gaussians from Stage I mesh -> Deformation MLP -> Control Gaussian Selection -> Splitting Strategy -> Rasterizer)

- **Critical path:** The **Generative Prior Alignment** (Stage I). If the prior mesh is misaligned or the loss is too weak, the subsequent Gaussian stage initializes from poor geometry, leading to unstable optimization. The **Control Threshold (τ)** is the second critical hyperparameter, determining which Gaussians drive the animation.

- **Design tradeoffs:**
  - **Prior Strength:** A strong prior stabilizes training but risks losing identity-specific quirks; a weak prior maintains freedom but risks geometric drift.
  - **Control Threshold:** A lower τ selects more Control Gaussians, potentially over-smoothing the face; a higher τ restricts control to extreme motions, potentially missing subtle lip details.

- **Failure signatures:**
  - **"Blobby" features:** Control threshold is too high, or interpolation radius is too small, leaving non-control regions static.
  - **Teeth/Mouth artifacts:** Splitting strategy failing to trigger inside the mouth cavity due to occlusion or initialization gaps.
  - **Generic face shape:** L_mesh loss weight is too high, overpowering the image reconstruction loss.

- **First 3 experiments:**
  1. **Ablate the Control Mechanism:** Run Stage II without the propagation step to verify that local texture discontinuities appear, confirming the mechanism's utility for fine details.
  2. **Tune Control Threshold:** Sweep τ (e.g., 0.15 vs. 0.30 vs. 0.40) on a validation sequence with subtle vs. extreme expressions to find the optimal balance between noise and detail.
  3. **Visualize Initialization:** Render the mesh from Stage I with and without the generative prior to qualitatively inspect structural stability before training the expensive Gaussian stage.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the control and splitting thresholds (τ and τ_split) be made adaptive to identity or expression intensity rather than fixed?
- Basis in paper: Section 4.5.4 states thresholds were "fixed throughout all evaluations" based on early-stage experiments, acknowledging that lower values over-propagate and higher values miss details.
- Why unresolved: The paper establishes a trade-off but does not propose a mechanism to dynamically determine optimal thresholds for diverse facial geometries or unseen extreme motions.
- What evidence would resolve it: A comparative study showing an adaptive thresholding heuristic outperforming fixed values across a dataset with high variance in facial feature amplitude.

### Open Question 2
- Question: How does the framework's performance degrade when the generative geometry prior provides an inaccurate or biased structural initialization?
- Basis in paper: Section 3.3 relies on a high-quality mesh from a pretrained model to "stabilize optimization," but does not analyze failure cases where the prior might hallucinate geometry inconsistent with the subject.
- Why unresolved: The method assumes the prior offers "reliable facial geometry"; it is untested whether the global alignment loss forces the optimization into a local minimum constrained by a poor prior.
- What evidence would resolve it: Ablation experiments using noisy or intentionally incorrect prior meshes to measure the convergence speed and final reconstruction error rates.

### Open Question 3
- Question: Does the reliance on a mesh-based generative prior limit the reconstruction of highly dynamic non-facial attributes, such as loose hair or accessories?
- Basis in paper: Section 3.3 notes the prior mesh provides structural guidance, but generative models are typically trained on canonical face/head topologies.
- Why unresolved: While Gaussian splitting handles local details, the initial structural stage might bias the avatar against out-of-distribution elements not represented in the generative prior's latent space.
- What evidence would resolve it: Qualitative and quantitative evaluation on subjects with significant non-facial occlusions or dynamic hair elements compared to prior-agnostic baselines.

## Limitations
- **Parameter Sensitivity:** Performance depends critically on fixed control and splitting thresholds that may not generalize across datasets or subjects.
- **Distribution Bias:** Generative prior may not generalize well to underrepresented facial features, potentially forcing reconstructions toward an "average" face.
- **Computational Complexity:** Two-stage training process requires significant computational resources with 500,000 iterations in Stage II alone.

## Confidence
- **High Confidence:** Core mechanisms (control point propagation, deformation-aware splitting, prior-based initialization) are technically sound and supported by experimental results.
- **Medium Confidence:** Specific parameter choices and their impact on different facial regions are not thoroughly validated across diverse expression ranges and identities.
- **Low Confidence:** Claims about generalization to unseen identities and expressions beyond the NeRSemble dataset remain untested.

## Next Checks
1. **Cross-Identity Generalization:** Test EAvatar on identities completely unseen during prior generation and training to evaluate whether the control mechanism maintains fidelity across diverse facial features.
2. **Parameter Sensitivity Analysis:** Conduct systematic sweeps of τ and τ_split across different expression intensities (subtle vs. extreme) to identify optimal ranges and failure modes.
3. **Occlusion Robustness:** Evaluate performance when input views are missing or when facial regions are self-occluded, measuring degradation in control Gaussian selection accuracy and resulting reconstruction quality.