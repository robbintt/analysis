---
ver: rpa2
title: 'DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework'
arxiv_id: '2602.00996'
source_url: https://arxiv.org/abs/2602.00996
tags:
- table
- agent
- answer
- reasoning
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DeALOG is a decentralized multi-agent reasoning framework for complex
  question answering across tables, text, and images. It replaces centralized planning
  with log-mediated collaboration among specialized agents (Table, Context, Visual,
  Summarizing, Verification) that communicate via a shared natural-language log.
---

# DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework
## Quick Facts
- arXiv ID: 2602.00996
- Source URL: https://arxiv.org/abs/2602.00996
- Authors: Abhijit Chakraborty; Ashish Raj Shekhar; Shiven Agarwal; Vivek Gupta
- Reference count: 20
- Primary result: Decentralized multi-agent reasoning framework with log-mediated collaboration achieves state-of-the-art performance on multi-modal QA benchmarks

## Executive Summary
DeALOG introduces a decentralized multi-agent reasoning framework for complex question answering across tables, text, and images. Instead of centralized planning, specialized agents (Table, Context, Visual, Summarizing, Verification) collaborate through a shared natural-language log, enabling distributed error detection and correction. The framework achieves state-of-the-art or competitive accuracy on six benchmarks (FeTaQA, FinQA, TAT-QA, WikiTableQuestions, MMQA, CRT-QA) under matched model capacity, demonstrating the effectiveness of log-mediated collaboration for multi-modal reasoning tasks.

## Method Summary
DeALOG replaces centralized reasoning with a decentralized multi-agent system where specialized agents communicate through a shared natural-language log. Each agent focuses on specific data modalities or reasoning tasks: Table Agent handles structured data, Context Agent processes unstructured text, Visual Agent interprets images, Summarizing Agent distills information, and Verification Agent validates answers. Agents iteratively contribute to and read from the log, allowing for distributed error detection and correction without central control. This approach enables transparency in reasoning chains and improves accuracy on complex multi-modal questions by leveraging specialized expertise across different data types.

## Key Results
- Achieves state-of-the-art performance on FinQA benchmark (80% accuracy)
- Competitive results across six diverse QA benchmarks (FeTaQA, TAT-QA, WikiTableQuestions, MMQA, CRT-QA)
- Strong zero-shot performance demonstrating framework robustness
- Shared log and verification components critical for accuracy and error correction

## Why This Works (Mechanism)
The log-mediated communication enables asynchronous collaboration where agents can independently contribute insights and corrections without waiting for centralized coordination. This distributed approach allows for parallel processing of different data modalities while maintaining coherent reasoning chains. The verification agent provides critical error detection by cross-checking proposed answers against evidence in the log, catching mistakes that might propagate in sequential reasoning systems. The natural language format of the shared log ensures interpretability and allows agents to build upon each other's work through explicit references and justifications.

## Foundational Learning
**Multi-modal Question Answering**: Why needed - Modern QA requires processing diverse data types (tables, text, images); Quick check - Can system handle questions requiring simultaneous table and image interpretation?

**Agent Specialization**: Why needed - Different data modalities require distinct processing capabilities; Quick check - Are agent outputs consistent with their specialized domains?

**Decentralized Collaboration**: Why needed - Centralized planning creates bottlenecks and single points of failure; Quick check - Does the system maintain accuracy without central coordination?

**Natural Language Mediation**: Why needed - Enables interpretable reasoning chains and cross-agent communication; Quick check - Can humans follow the reasoning log to understand answer derivation?

**Error Detection and Correction**: Why needed - Complex reasoning chains accumulate errors that need systematic identification; Quick check - Does verification agent catch common error patterns?

## Architecture Onboarding
**Component Map**: Input -> [Table Agent, Context Agent, Visual Agent] -> Log -> [Summarizing Agent, Verification Agent] -> Output

**Critical Path**: Question → Agent specialization → Log contribution → Verification → Answer generation

**Design Tradeoffs**: Decentralized vs. centralized control (latency vs. coordination), natural language log (interpretability vs. efficiency), specialized vs. generalist agents (accuracy vs. flexibility)

**Failure Signatures**: Incomplete log entries, conflicting agent interpretations, verification rejections, modality-specific processing failures

**First Experiments**: 1) Single-agent performance comparison, 2) Log ablation study (with/without verification), 3) Cross-modality error propagation analysis

## Open Questions the Paper Calls Out
None identified in provided content.

## Limitations
- Experimental validation limited to question-answering benchmarks, leaving uncertainty about performance in other multi-modal reasoning tasks
- Log-mediated communication introduces potential latency and coordination overhead that was not thoroughly characterized
- Verification agent effectiveness relies on quality of cross-checking mechanisms, but specific decision thresholds and handling of ambiguous cases are not fully detailed

## Confidence
- High confidence in core architectural contribution and basic functionality of log-mediated multi-agent system
- Medium confidence in claimed performance improvements due to limited ablation studies and baseline comparisons
- Medium confidence in scalability assertions, as evaluation focuses on benchmarks rather than real-world deployment scenarios

## Next Checks
1. Conduct extensive ablation studies to quantify individual contributions of each agent type and log-mediated communication mechanism
2. Evaluate framework performance and computational overhead on larger-scale, real-world multi-modal reasoning tasks beyond standard benchmarks
3. Implement and test robustness metrics for verification agent's decision-making process, including error detection rates and handling of ambiguous or conflicting evidence