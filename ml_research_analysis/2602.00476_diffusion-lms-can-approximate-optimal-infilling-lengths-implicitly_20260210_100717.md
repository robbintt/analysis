---
ver: rpa2
title: Diffusion LMs Can Approximate Optimal Infilling Lengths Implicitly
arxiv_id: '2602.00476'
source_url: https://arxiv.org/abs/2602.00476
tags:
- length
- infilling
- confidence
- diffusion
- oracle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies a fundamental limitation in diffusion language
  models (DLMs) for infilling tasks: their sensitivity to pre-specified mask lengths.
  The authors discover two key statistical phenomena in first-step denoising confidence:
  an Oracle Peak that emerges near the ground-truth length and a systematic Length
  Bias that obscures this signal.'
---

# Diffusion LMs Can Approximate Optimal Infilling Lengths Implicitly

## Quick Facts
- **arXiv ID**: 2602.00476
- **Source URL**: https://arxiv.org/abs/2602.00476
- **Reference count**: 33
- **Primary result**: Training-free CAL method achieves up to 47.7% improvement in Pass@1 for code infilling by estimating optimal mask lengths through calibrated confidence-based hill-climbing

## Executive Summary
This paper identifies a fundamental limitation in diffusion language models (DLMs) for infilling tasks: their sensitivity to pre-specified mask lengths. The authors discover two key statistical phenomena in first-step denoising confidence: an Oracle Peak that emerges near the ground-truth length and a systematic Length Bias that obscures this signal. They propose CAL (Calibrated Adaptive Length), a training-free method that leverages calibrated confidence to approximate optimal infilling lengths through bidirectional hill-climbing search before formal decoding. Empirical results demonstrate significant improvements: up to 47.7% increase in Pass@1 over fixed-length baselines and 40.5% over chat-based adaptive methods in code infilling, with BLEU-2 and ROUGE-L gains up to 8.5% and 9.9% in text infilling. The method works across multiple DLMs and domains without requiring specialized training, decoupling infilling performance from rigid mask length requirements.

## Method Summary
The authors propose CAL (Calibrated Adaptive Length), a training-free method that estimates optimal infilling lengths by analyzing first-step denoising confidence scores. The approach works by first detecting an Oracle Peak near the ground-truth length through statistical analysis of calibrated confidence scores, then performing bidirectional hill-climbing search to approximate this optimal length. Unlike previous adaptive methods that require chat-based interaction or specialized training, CAL operates on a single forward pass through the DLM, making it computationally efficient while maintaining strong performance across different model architectures and domains.

## Key Results
- Up to 47.7% increase in Pass@1 over fixed-length baselines and 40.5% over chat-based adaptive methods in code infilling
- BLEU-2 and ROUGE-L improvements up to 8.5% and 9.9% in text infilling tasks
- Method works across multiple DLMs (DiffuSLM, DiffuSE, diffupix2) without requiring specialized training
- Decouples infilling performance from rigid mask length requirements

## Why This Works (Mechanism)
The method exploits two discovered phenomena in DLM denoising behavior: an Oracle Peak that appears near ground-truth lengths in calibrated confidence scores, and a systematic Length Bias that affects these scores. By leveraging confidence calibration, CAL can detect when a model is approaching optimal length decisions, then uses bidirectional hill-climbing to converge on the best length before formal decoding begins.

## Foundational Learning
- **Diffusion Language Models**: Why needed - Understanding DLM architecture and denoising process is essential for grasping how confidence scores relate to generation quality; Quick check - Review the forward and reverse diffusion processes in DLMs
- **Confidence Calibration**: Why needed - Calibrated confidence scores are the core signal CAL uses to detect optimal lengths; Quick check - Understand temperature scaling and other calibration methods
- **Infilling Tasks**: Why needed - The specific challenges of predicting content for masked regions in text/code; Quick check - Review metrics like BLEU, ROUGE, and Pass@1 for evaluating infilling quality
- **Hill-Climbing Search**: Why needed - The optimization strategy CAL uses to find optimal lengths; Quick check - Understand basic search algorithms and convergence properties
- **Statistical Analysis of Model Behavior**: Why needed - Detecting Oracle Peak requires understanding how confidence scores behave statistically; Quick check - Review methods for analyzing peaks and biases in score distributions

## Architecture Onboarding
**Component Map**: Input text with masks -> CAL length estimator -> DLM with calibrated confidence -> Bidirectional hill-climbing search -> Optimal length selection -> DLM decoding

**Critical Path**: CAL method operates as a pre-processing step that estimates optimal mask lengths before DLM decoding begins, requiring only first-step confidence scores from a single forward pass

**Design Tradeoffs**: CAL trades additional inference time for improved quality by decoupling length estimation from decoding, avoiding the need for specialized training or chat-based interaction while requiring calibration of confidence scores

**Failure Signatures**: Method may struggle when Oracle Peak is too subtle to detect reliably, when confidence calibration fails, or when optimal lengths exhibit multimodal distributions that confuse the hill-climbing search

**3 First Experiments**:
1. Verify Oracle Peak detection on a simple synthetic dataset with known ground-truth lengths
2. Test bidirectional hill-climbing convergence on a single DLM with varying initial mask lengths
3. Compare calibrated vs uncalibrated confidence scores for peak detection accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focuses on text and code domains, potentially limiting generalizability to other content types
- Additional inference time required due to hill-climbing search process, though computational overhead is not thoroughly characterized
- Assumes calibrated confidence scores reliably indicate denoising quality, which may not hold across different model scales or training configurations

## Confidence
**High Confidence**: DLM sensitivity to mask lengths significantly impacts infilling quality; Oracle Peak and Length Bias phenomena are well-supported by experiments

**Medium Confidence**: CAL effectiveness across different DLMs and domains, though evaluation scope is limited; calibrated confidence reliably identifies optimal lengths

**Low Confidence**: Theoretical basis for why calibrated confidence correlates with denoising quality across different model architectures

## Next Checks
1. **Cross-domain Generalization**: Evaluate CAL on non-text/code domains (e.g., structured data, multilingual text, or specialized technical domains) to assess robustness across diverse content types

2. **Computational Overhead Analysis**: Systematically measure and compare the inference time and computational cost of CAL against fixed-length baselines across different model sizes and search parameters

3. **Ablation on Confidence Calibration**: Test CAL variants that use uncalibrated confidence scores or alternative quality metrics to determine the necessity and impact of calibration in the method