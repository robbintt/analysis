---
ver: rpa2
title: 'Learning to Debug: LLM-Organized Knowledge Trees for Solving RTL Assertion
  Failures'
arxiv_id: '2511.17833'
source_url: https://arxiv.org/abs/2511.17833
tags:
- knowledge
- node
- tree
- retrieval
- debugging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: GROVE addresses RTL assertion-failure debugging by learning and
  organizing reusable debugging expertise into an LLM-managed hierarchical knowledge
  tree. The tree evolves through a gradient-free, parallel training loop where an
  LLM proposes atomic JSON edits to add validated knowledge items, each equipped with
  explicit applicability conditions.
---

# Learning to Debug: LLM-Organized Knowledge Trees for Solving RTL Assertion Failures

## Quick Facts
- arXiv ID: 2511.17833
- Source URL: https://arxiv.org/abs/2511.17833
- Authors: Yunsheng Bai; Haoxing Ren
- Reference count: 40
- Key outcome: GROVE achieves +12.0% pass@1 and +6.6% pass@5 improvements on RTL assertion-failure debugging

## Executive Summary
GROVE introduces a novel approach to RTL assertion-failure debugging by organizing reusable debugging expertise into an LLM-managed hierarchical knowledge tree. The system learns through a parallel training loop where an LLM proposes atomic JSON edits to add validated knowledge items, each equipped with explicit applicability conditions. At test time, a budget-aware iterative zoom mechanism retrieves relevant knowledge items to guide the base LLM's fix proposals. When evaluated on the SVA-EVAL benchmark, GROVE demonstrates significant improvements over baseline approaches, validating the effectiveness of structured knowledge evolution for scalable RTL debugging.

## Method Summary
GROVE addresses the challenge of RTL assertion-failure debugging by creating a hierarchical knowledge tree that stores reusable debugging expertise. The system operates through a parallel training loop where an LLM proposes atomic JSON edits to add new knowledge items to the tree, each with explicit applicability conditions. These proposed items are validated against ground-truth fixes before being incorporated. During debugging, the system uses a budget-aware iterative zoom mechanism to retrieve a small set of relevant knowledge items from the tree, which then guide the base LLM in proposing fixes for specific assertion failures. This approach combines the generalization capabilities of LLMs with the precision of structured knowledge representation.

## Key Results
- Absolute improvement of +12.0% pass@1 on RTL assertion-failure debugging
- Absolute improvement of +6.6% pass@5 on RTL assertion-failure debugging
- Demonstrates effectiveness of LLM-managed hierarchical knowledge trees for RTL debugging

## Why This Works (Mechanism)
The approach works by combining the pattern recognition capabilities of LLMs with structured knowledge representation. By organizing debugging expertise into a hierarchical tree with explicit applicability conditions, the system can efficiently retrieve relevant knowledge items for specific debugging scenarios. The parallel training loop allows for scalable knowledge acquisition, while the budget-aware iterative zoom ensures that only the most relevant items are used during inference. This structured approach addresses the limitations of purely end-to-end LLM solutions, which may struggle with the precision and scalability required for complex RTL debugging tasks.

## Foundational Learning
- **RTL Assertion Semantics**: Understanding SystemVerilog Assertions (SVA) syntax and semantics is crucial for interpreting assertion failures and proposed fixes. Quick check: Can identify assertion violation causes from failure messages.
- **Knowledge Tree Structure**: The hierarchical organization of debugging expertise with explicit applicability conditions enables efficient retrieval and reuse. Quick check: Can explain how tree traversal optimizes knowledge selection.
- **Parallel Knowledge Acquisition**: The gradient-free training loop allows multiple knowledge items to be proposed and validated simultaneously, improving scalability. Quick check: Can describe how parallel validation prevents knowledge conflicts.
- **Budget-Aware Retrieval**: The iterative zoom mechanism balances retrieval precision with computational cost by limiting the number of knowledge items used. Quick check: Can demonstrate how budget constraints affect retrieval quality.

## Architecture Onboarding

**Component Map**
LLM Proposer -> Knowledge Tree (Hierarchical) -> Budget-Aware Iterative Zoom -> Base LLM Fix Generator -> Validator

**Critical Path**
1. LLM proposes atomic JSON edits to add knowledge items
2. Items are validated against ground-truth fixes
3. Validated items are incorporated into the knowledge tree
4. During inference, iterative zoom retrieves relevant items
5. Retrieved items guide base LLM's fix proposals

**Design Tradeoffs**
- Structured JSON representation vs. natural language flexibility
- Parallel training efficiency vs. potential knowledge redundancy
- Explicit applicability conditions vs. implicit semantic understanding
- Budget constraints vs. retrieval completeness

**Failure Signatures**
- Knowledge tree becomes too large, slowing retrieval
- Applicability conditions too restrictive, limiting knowledge reuse
- Parallel training creates conflicting or redundant knowledge items
- Budget constraints prevent retrieval of necessary knowledge items

**First 3 Experiments**
1. Compare GROVE's performance against pure LLM baselines on SVA-EVAL benchmark
2. Ablation study on budget parameter impact on debugging accuracy
3. Cross-domain validation on RTL assertion failures from multiple design houses

## Open Questions the Paper Calls Out
None

## Limitations
- Dependency on human-defined JSON edit rules and applicability conditions may limit scalability to complex scenarios
- Validation loop requires ground-truth fixes, which may not be available in industrial settings
- Parallel training assumes independent knowledge-item creation will lead to coherent global tree structures

## Confidence

| Claim | Confidence |
|-------|------------|
| Performance improvements on SVA-EVAL (+12.0% pass@1, +6.6% pass@5) | High |
| Generalizability to industrial RTL debugging | Medium |
| Long-term tree evolution effectiveness | Medium |
| Budget-aware iterative zoom mechanism | Medium |

## Next Checks
1. Conduct cross-domain validation by testing GROVE on RTL assertion failures from multiple design houses with varying coding styles and assertion patterns
2. Implement a human-in-the-loop study where experienced hardware engineers evaluate the interpretability and actionability of retrieved knowledge items during debugging sessions
3. Perform a longitudinal study tracking knowledge tree quality and debugging performance over multiple training iterations to identify potential degradation patterns or knowledge drift