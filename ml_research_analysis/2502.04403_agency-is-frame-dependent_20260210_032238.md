---
ver: rpa2
title: Agency Is Frame-Dependent
arxiv_id: '2502.04403'
source_url: https://arxiv.org/abs/2502.04403
tags:
- agency
- system
- reference
- learning
- frame-dependent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the long-standing puzzle of defining and measuring
  agency in systems, particularly the challenge of determining whether systems like
  rocks, thermostats, or robots possess agency. The authors argue that agency is fundamentally
  frame-dependent, meaning any measurement of a system's agency must be made relative
  to a reference frame.
---

# Agency Is Frame-Dependent

## Quick Facts
- arXiv ID: 2502.04403
- Source URL: https://arxiv.org/abs/2502.04403
- Reference count: 3
- Primary result: Agency is fundamentally frame-dependent, requiring reference frames for any measurement

## Executive Summary
This paper argues that agency is not an objective property of systems but rather a frame-dependent attribution that requires explicit reference frame commitments. The authors demonstrate that each of the four essential properties of agency - individuality, source of action, goal-directedness, and adaptivity - cannot be determined without arbitrary choices that collectively form a reference frame. Using philosophical arguments and connections to existing work in reinforcement learning and causal modeling, they show that determining whether systems like rocks, thermostats, or robots possess agency requires observer-imposed commitments about boundaries, causal variables, meaningful goals, and adaptive changes.

## Method Summary
The paper presents a philosophical analysis rather than empirical experiments. It builds on Barandiaran et al.'s (2009) four essential properties of agency and argues that each property requires arbitrary commitments. The authors cite existing formal work (Jiang 2019 on agent-environment boundaries, Kenton et al. 2023 on causal discovery, Ziebart 2008 on maximum entropy IRL) to support their claims but provide no code, algorithms, or quantitative experiments. The method is conceptual argumentation supported by thought experiments and theoretical citations.

## Key Results
- Each of Barandiaran et al.'s four agency properties requires arbitrary commitments
- Agency measurements must be made relative to a reference frame
- The observer's choice of boundary, causal variables, goal principles, and adaptivity reference class determines agency attribution
- No objective, frame-independent measurement of agency exists

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Agency attribution requires explicit boundary selection, and different boundaries yield different agent-internal quantities.
- Mechanism: The observer chooses where to draw the agent-environment boundary (e.g., which neural network layers, whether tools are included). This choice determines what counts as internal state vs. environment, thereby changing optimal policies and Bellman error.
- Core assumption: Boundaries are observer-imposed rather than uniquely correct.
- Evidence anchors:
  - [abstract] "Any measurement of a system's agency must be made relative to a reference frame."
  - [section] "Jiang (2019) considers the example of a model-free learning algorithm... the boundary we choose to draw could include the pseudo-random number generator and all layers of this network, or only include the last few layers."
  - [corpus] Weak direct evidence; neighbor papers focus on RL methods, not frame-dependence.
- Break condition: If a system has a unique, objectively identifiable boundary (e.g., physical containment with no ambiguity), frame-dependence via individuality would not apply.

### Mechanism 2
- Claim: Whether a system is the "source of its own action" depends on the choice of causal variables in the model.
- Mechanism: Causal attribution requires selecting which variables appear in the model. Different selections can identify vs. refute the presence of an agent as the origin of action.
- Core assumption: Causal models require upstream variable choices that are not uniquely determined by the physical system.
- Evidence anchors:
  - [abstract] Not explicitly mentioned; inferred from main claim.
  - [section] "Kenton et al. (2023) recently develop a causal account... the difficulty, as Kenton et al. note, is that reaching a conclusion about the source of action in a causal model rests entirely on the choice of causal variables."
  - [corpus] No direct corpus support; neighbor papers do not address causal agency frames.
- Break condition: If causal variables were uniquely determined by physical facts (no degrees of freedom in modeling), source-of-action frame-dependence would collapse.

### Mechanism 3
- Claim: Distinguishing "meaningful" from trivial goal-directedness requires external principles; otherwise, any input-output system can be interpreted as goal-directed.
- Mechanism: Reward is under-determined by behavior—the zero reward function is always consistent with any behavior. Principles such as maximum entropy or simplicity biases constrain the space of viable goals, but these are arbitrary commitments forming part of the frame.
- Core assumption: Goal attribution is interpretive, not directly observable.
- Evidence anchors:
  - [abstract] "Each of the essential properties of agency proposed by Barandiaran et al. (2009)... are themselves frame-dependent."
  - [section] "Every input-output system can be well-explained in terms of goal-directedness... a rock can be viewed as having the goal of rolling down a hill."
  - [corpus] Weak; corpus focuses on RL techniques, not philosophical frames.
- Break condition: If behavior uniquely determined goals (no under-determination), normativity would not require external frame commitments.

### Mechanism 4
- Claim: Adaptivity is relative to a reference class; the same system can be adaptive under one frame and non-adaptive under another.
- Mechanism: A fixed policy (same action for same input) can be viewed as adaptive (changes behavior across experiences) or non-adaptive (static function) depending on what changes count as meaningful.
- Core assumption: What counts as a "meaningful change in behavior" is not inherent to the system.
- Evidence anchors:
  - [abstract] Not explicit; follows from frame-dependence thesis.
  - [section] "Zadeh (1963) suggests... 'every system is adaptive with respect to [something]... what matters is not whether [the system] is adaptive or not, but what... it is adaptive [to].'"
  - [corpus] No relevant corpus evidence.
- Break condition: If there were an objective, non-arbitrary definition of which behavior changes constitute adaptivity, this frame-dependence would not apply.

## Foundational Learning

- Concept: Agent-environment boundary in RL
  - Why needed here: The paper's core argument starts with boundary selection as the first frame-dependent commitment. Understanding that RL formalisms require an a priori split between agent and environment is essential.
  - Quick check question: Can you identify two different valid ways to draw the boundary for a robot with an onboard camera and external compute server?

- Concept: Inverse reinforcement learning and reward under-determination
  - Why needed here: The normativity argument rests on the fact that behavior alone does not uniquely determine goals. This is a classic result in IRL.
  - Quick check question: Why is the zero reward function consistent with any observed behavior?

- Concept: Intentional stance vs. design stance (Dennett)
  - Why needed here: The paper connects frame selection to Dennett's stances. Understanding that "agent" is an explanatory lens helps ground why frames are choices, not discoveries.
  - Quick check question: When is it useful to treat a thermostat as having beliefs and desires?

## Architecture Onboarding

- Component map: A reference frame consists of four commitments: (1) a boundary specification (e.g., Markov blanket, graph cut), (2) a set of causal variables for source-of-action attribution, (3) a principle for isolating meaningful goals (e.g., maximum entropy, Occam's razor), and (4) a reference class for what counts as adaptive change.

- Critical path: First, explicitly declare each of the four frame commitments before attributing agency. Second, test whether agency conclusions change under plausible alternative frames. Third, document which frame-selection principle (e.g., explanatory power) justifies the chosen frame.

- Design tradeoffs: Stronger constraints on goals (e.g., strict simplicity) reduce frame variability but may exclude legitimate agents. Broader adaptivity definitions capture more systems but risk trivializing agency. The paper does not prescribe which frame to choose—only that a choice is required.

- Failure signatures: If agency conclusions shift dramatically under minor frame perturbations (e.g., moving boundary one layer in a neural network), the system's agency attribution is fragile to frame choice. If no frame yields goal-directedness under any reasonable principle, the system likely lacks agency in any meaningful sense.

- First 3 experiments:
  1. Take an RL agent with a multi-layer network; systematically vary the boundary (last layer only vs. full network vs. including RNG) and measure changes to optimal policy and Bellman error as per Jiang (2019).
  2. For a fixed behavioral trajectory, apply multiple goal-recovery principles (zero reward, maximum entropy, simplicity-biased) and verify that different goals are recovered, demonstrating normativity frame-dependence.
  3. Define two adaptivity reference classes (any output change vs. only state-dependent policy changes) for the same policy; confirm that adaptivity classification differs across frames.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can agent reference frames be given a precise mathematical formalization, and what mathematical structures (e.g., graph cuts, Markov blankets) best capture the four required commitments?
- Basis in paper: [explicit] "A precise mathematical construction of reference frames is a natural next step for further research... We stop short of presenting a rigorous mathematical definition of reference frames, as well as a formal proof of the frame-dependence of agency."
- Why unresolved: The paper provides only philosophical arguments; the authors explicitly flag formalization as future work.
- What evidence would resolve it: A formal definition of reference frames with proofs showing frame-dependence affects agency measurements.

### Open Question 2
- Question: What defensible principles can guide reference frame selection, and how do different selection principles affect conclusions about agency?
- Basis in paper: [explicit] "How do we choose an appropriate reference frame? It is unclear which frame-selection principles are defensible, and what implications these principles carry for our study of agents."
- Why unresolved: The paper introduces frame-dependence but does not propose or compare frame-selection criteria.
- What evidence would resolve it: A taxonomy of frame-selection principles with analysis of their theoretical consequences.

### Open Question 3
- Question: Does intelligence require agency, and does agency require intelligence? How does frame-dependence complicate this relationship?
- Basis in paper: [explicit] "The relationship between intelligence and agency is not yet well understood. For instance, does intelligence require agency, and vice versa?"
- Why unresolved: The connection between intelligence and agency remains under-explored, and frame-dependence introduces additional complexity.
- What evidence would resolve it: Theoretical analysis or empirical studies linking intelligence metrics to agency measurements across different reference frames.

## Limitations

- The core argument rests on philosophical reasoning rather than empirical validation
- No formal mathematical definitions of reference frames are provided
- No formal proof of frame-dependence; only philosophical arguments and citations to related results
- The adaptivity frame-dependence claim relies on a single philosophical citation without formal development

## Confidence

- **High confidence**: Boundary dependence (Mechanism 1) - directly supported by existing RL literature and formal results
- **Medium confidence**: Causal variable dependence (Mechanism 2) - philosophical argument is sound but lacks empirical validation
- **Medium confidence**: Goal under-determination (Mechanism 3) - consistent with IRL literature, but normativity framing is novel
- **Low confidence**: Adaptivity frame-dependence (Mechanism 4) - relies on a single philosophical citation without formal development

## Next Checks

1. **Boundary perturbation test**: Systematically vary agent-environment boundaries in a concrete RL system (e.g., a multi-layer network) and measure how optimal policies and Bellman errors change. This would provide empirical validation of the boundary dependence claim.

2. **Goal attribution diversity test**: Apply multiple goal-recovery principles (zero reward, maximum entropy, simplicity-biased) to the same behavioral trajectory and verify that different, sometimes trivial goals are recovered. This would demonstrate the under-determination of goals by behavior.

3. **Frame stability analysis**: For a given system, document whether agency attributions remain stable under reasonable frame perturbations. If small changes in boundary, causal variables, or goal principles lead to dramatic changes in agency classification, this would support the frame-dependence thesis.