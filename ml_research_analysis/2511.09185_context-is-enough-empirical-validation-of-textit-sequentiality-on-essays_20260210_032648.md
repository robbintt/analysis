---
ver: rpa2
title: 'Context is Enough: Empirical Validation of $\textit{Sequentiality}$ on Essays'
arxiv_id: '2511.09185'
source_url: https://arxiv.org/abs/2511.09185
tags:
- essay
- sequentiality
- features
- contextual
- flow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study validates that narrative flow in essays is better captured
  by the contextual term of sequentiality rather than the original topic-inclusive
  formulation. Using trait-annotated essay datasets (ASAP++ and ELLIPSE), the contextual
  term (NLLC) showed superior alignment with human assessments of Organization and
  Cohesion compared to both topic-only and full sequentiality measures.
---

# Context is Enough: Empirical Validation of $\textit{Sequentiality}$ on Essays

## Quick Facts
- arXiv ID: 2511.09185
- Source URL: https://arxiv.org/abs/2511.09185
- Reference count: 24
- Primary result: Contextual sequentiality (NLLC) outperforms topic-inclusive formulations for capturing narrative flow in essays

## Executive Summary
This study validates that narrative flow in essays is better captured by the contextual term of sequentiality rather than the original topic-inclusive formulation. Using trait-annotated essay datasets (ASAP++ and ELLIPSE), the contextual term (NLLC) showed superior alignment with human assessments of Organization and Cohesion compared to both topic-only and full sequentiality measures. While zero-shot LLM prompting achieved higher direct trait prediction accuracy, the contextual term provided the greatest performance boost when combined with standard linguistic features, outperforming both topic-only and original sequentiality formulations.

## Method Summary
The study employed a comparative evaluation framework across two trait-annotated essay datasets (ASAP++ and ELLIPSE). The research team implemented and tested three sequentiality formulations: topic-only, original (topic-inclusive), and contextual (NLLC). Zero-shot LLM prompting was used for direct trait prediction, while sequentiality features were integrated with standard linguistic features for comparative analysis. Human assessment alignment was measured against Organization and Cohesion traits, and performance was evaluated through automated essay scoring metrics.

## Key Results
- Contextual sequentiality (NLLC) demonstrated superior alignment with human assessments of Organization and Cohesion compared to alternative formulations
- The contextual term provided the greatest performance boost when combined with standard linguistic features for automated essay scoring
- Original topic-inclusive sequentiality formulation was less effective than the contextual-only approach for capturing narrative flow

## Why This Works (Mechanism)
The contextual term captures sentence-to-sentence flow more effectively by focusing on local linguistic patterns rather than topic continuity. This approach better represents the narrative progression that humans intuitively assess when evaluating essay organization. The contextual formulation isolates the sequential relationships between sentences, which appears to be the primary driver of perceived coherence, while the topic component adds noise rather than signal.

## Foundational Learning
- **Sequentiality metrics**: Needed to quantify narrative flow; quick check: verify mathematical formulation matches intended semantic capture
- **Contextual vs. topic modeling**: Required to isolate flow patterns from topical coherence; quick check: ensure contextual term is truly topic-agnostic
- **Zero-shot LLM prompting**: Enables baseline trait prediction without task-specific training; quick check: confirm prompt engineering follows best practices
- **Feature integration in essay scoring**: Combines linguistic and discourse-level features; quick check: validate feature independence assumptions
- **Human trait annotation alignment**: Establishes ground truth for evaluation; quick check: assess inter-rater reliability scores
- **Dataset curation for trait annotation**: Critical for valid evaluation; quick check: verify annotation schema matches target traits

## Architecture Onboarding

**Component Map:**
LLM zero-shot prompting -> Direct trait prediction -> NLLC contextual sequentiality -> Combined linguistic features -> Automated essay scoring pipeline

**Critical Path:**
Zero-shot LLM prediction (baseline) -> NLLC contextual term extraction -> Feature integration -> Trait prediction comparison

**Design Tradeoffs:**
Zero-shot vs. fine-tuned approaches; contextual-only vs. topic-inclusive formulations; computational efficiency vs. feature richness

**Failure Signatures:**
Poor alignment with human Organization/Coh Cohesion scores; minimal performance improvement when combining with linguistic features; contextual term not outperforming topic-only baseline

**First Experiments:**
1. Replicate zero-shot LLM prompting baseline on ASAP++ dataset
2. Implement NLLC contextual term extraction pipeline
3. Compare combined feature performance against individual sequentiality formulations

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Validation constrained to specific datasets (ASAP++ and ELLIPSE) limited to argumentative essay genres
- Reliance on zero-shot LLM prompting without systematic comparison to fine-tuned approaches
- Uncertainty whether performance gains translate to meaningful improvements in downstream educational applications

## Confidence

**Major Claim Clusters Confidence Labels:**
- **High Confidence**: The contextual sequentiality term (NLLC) demonstrates superior alignment with human assessments of Organization and Cohesion compared to alternative formulations
- **Medium Confidence**: The contextual term provides the greatest performance boost when combined with standard linguistic features for automated essay scoring
- **Medium Confidence**: The original topic-inclusive sequentiality formulation is less effective than the contextual-only approach for capturing narrative flow

## Next Checks

1. Test the contextual sequentiality approach across diverse essay genres (narrative, descriptive, persuasive) and educational levels to establish generalizability beyond the current argumentative essay datasets

2. Conduct ablation studies systematically removing different components of the linguistic feature set to isolate the specific contribution of contextual sequentiality versus other features

3. Implement fine-tuned LLM approaches using contextual sequentiality features to determine whether zero-shot prompting underestimates the potential performance gains achievable with this representation