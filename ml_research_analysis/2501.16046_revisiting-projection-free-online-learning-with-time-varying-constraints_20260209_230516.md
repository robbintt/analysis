---
ver: rpa2
title: Revisiting Projection-Free Online Learning with Time-Varying Constraints
arxiv_id: '2501.16046'
source_url: https://arxiv.org/abs/2501.16046
tags:
- convex
- regret
- online
- bound
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies online convex optimization with time-varying
  constraints, where projection operations onto the feasible domain are computationally
  expensive. The authors propose projection-free methods based on constructing composite
  surrogate losses using Lyapunov functions and applying parameter-free variants of
  the online Frank-Wolfe algorithm.
---

# Revisiting Projection-Free Online Learning with Time-Varying Constraints

## Quick Facts
- arXiv ID: 2501.16046
- Source URL: https://arxiv.org/abs/2501.16046
- Reference count: 40
- Primary result: Achieves O(T^{3/4}) regret and O(T^{3/4} log T) CCV for general convex losses; O(T^{2/3}) regret and O(T^{5/6}) CCV for strongly convex losses in projection-free online COCO with time-varying constraints

## Executive Summary
This paper addresses online convex optimization with time-varying constraints where projection operations are computationally expensive. The authors propose projection-free methods based on constructing composite surrogate losses using Lyapunov functions and applying parameter-free variants of the online Frank-Wolfe algorithm. The approach decouples regret and constraint violation guarantees through Lyapunov drift analysis. For general convex losses, the method achieves O(T^{3/4}) regret and O(T^{3/4} log T) cumulative constraint violation bounds, improving upon previous results. The methods are also extended to the bandit setting with similar theoretical guarantees, validated through experiments on real-world datasets.

## Method Summary
The paper proposes four algorithms (OFW-TVC, SCOFW-TVC, BFW-TVC, SCBFW-TVC) for projection-free online convex optimization with time-varying constraints. The core approach constructs composite surrogate losses using Lyapunov functions to transform constrained optimization into unconstrained surrogate loss minimization. The method uses Online Frank-Wolfe as the projection-free primitive, enhanced with a doubling trick for parameter-free optimization without knowing total constraint violation in advance. For the bandit setting, a one-point gradient estimator with blocking technique extends the approach. Key parameters include β = (2^6 G D)^{-1}, γ = 1, and specific learning rate schedules. The methods are evaluated on online matrix completion tasks using MovieLens 100k (full-info) and Film Trust (bandit) datasets.

## Key Results
- Achieves O(T^{3/4}) regret and O(T^{3/4} log T) CCV for general convex losses, improving upon previous results
- Establishes novel O(T^{2/3}) regret and O(T^{5/6}) CCV bounds for strongly convex losses
- Extends projection-free methods to bandit setting with similar theoretical guarantees
- Experimental validation on MovieLens and Film Trust datasets demonstrates effectiveness compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
Transforming constrained optimization into unconstrained surrogate loss minimization decouples the regret and constraint violation guarantees. The algorithm constructs a composite surrogate loss $\tilde{f}_t(x) = \gamma \beta f_t(x) + \Phi'(\beta Q_t) \beta g^+_t(x)$. By minimizing the regret of this surrogate loss, the method implicitly minimizes the original regret $Regret_T$ while controlling the cumulative constraint violation $Q_T$ through the properties of the Lyapunov function $\Phi$. Core assumption: Loss functions $f_t$ and constraint functions $g_t$ are convex (or strongly convex), and the relationship defined in (7) holds, allowing surrogate regret to upper-bound the true objectives. Break condition: If the surrogate loss weighting parameter $\beta$ is set incorrectly relative to the total time horizon $T$, the decoupling inequality (7) may fail to control the constraint violation term $\Phi(\beta Q_T)$.

### Mechanism 2
A doubling trick on the gradient norm bound enables parameter-free optimization without knowing the total constraint violation $Q_T$ in advance. Since the surrogate loss gradient depends on $Q_T$ (unknown at time $t$), the algorithm estimates the gradient norm bound $\tilde{G}$. If the current estimate is violated, it doubles $\tilde{G}$ and restarts the learning rate schedule. This allows the Online Frank-Wolfe (OFW) step to adapt to the scale of the gradients dynamically. Core assumption: The number of restarts (doubling events) is logarithmic and does not dominate the computational cost or regret accumulation. Break condition: If the gradient norms grow exponentially faster than anticipated, the algorithm restarts too frequently, potentially degrading the regret bound from $O(T^{3/4})$ to linear $O(T)$.

### Mechanism 3
One-point gradient estimation allows the extension of projection-free methods to the bandit setting with only a logarithmic degradation in bounds. In the bandit setting, gradients are unavailable. The method uses a perturbed point $x_t + \delta u_t$ to construct an unbiased gradient estimator $\tilde{\nabla}_t$. A blocking technique updates decisions only after accumulating $K$ samples to reduce variance, preserving the sub-linear regret guarantees. Core assumption: The loss function is Lipschitz and accessible via point queries; the perturbation $\delta$ is small enough to stay within a shrunk feasible set $K_\delta$. Break condition: If the smoothing parameter $\delta$ decays too slowly or the block size $K$ is too small, variance from the estimator may violate the Lipschitz assumptions required for the regret bounds.

## Foundational Learning

- **Concept: Online Frank-Wolfe (Conditional Gradient Method)**
  - Why needed here: This is the "projection-free" primitive. Instead of projecting onto the complex constraint set $K$ (which is slow), it solves a linear optimization problem over $K$ at each step.
  - Quick check question: Can you explain why solving $\min_{x \in K} \langle \nabla, x \rangle$ is generally faster than projecting onto a complex convex set $K$?

- **Concept: Lyapunov Drift (Drift-Plus-Penalty)**
  - Why needed here: This provides the theoretical handle on time-varying constraints. It formalizes the intuition that if you keep the "drift" (change in accumulated violation) small while optimizing the loss, the system remains stable.
  - Quick check question: How does minimizing "Drift + Penalty" differ from simply satisfying constraints at every individual step?

- **Concept: Doubling Trick**
  - Why needed here: Standard Online Learning often requires knowing the total time $T$ or problem constants to set learning rates. This technique allows the algorithm to guess these parameters and double the guess if proven wrong, preserving theoretical guarantees without initial knowledge.
  - Quick check question: Why does restarting the learning process when a parameter estimate is too low not ruin the overall regret bound?

## Architecture Onboarding

- **Component map:**
  Input Layer -> Surrogate Constructor -> Parameter-Free Optimizer -> Linear Optimization Oracle -> Update

- **Critical path:**
  1. Receive loss/constraint $\to$ Update cumulative violation $Q_t$.
  2. Construct surrogate gradient $\nabla \tilde{f}_t$.
  3. **Check Doubling Condition:** Is current estimate $\tilde{G}_k$ valid? If not, double and reset.
  4. **Linear Optimization Oracle:** Solve $v_t = \text{argmin}_{x \in K} \langle \nabla, x \rangle$.
  5. **Update:** $x_{t+1} = x_t + \sigma_t (v_t - x_t)$.

- **Design tradeoffs:**
  - Lyapunov Choice: Use Exponential $\Phi$ (better for general convex Regret/CCV) vs. Quadratic $\Phi$ (better for strongly convex Regret, looser CCV).
  - Bandit Block Size: Larger blocks reduce variance but slow down reaction speed to environmental changes.

- **Failure signatures:**
  - Exploding Regret: If the doubling loop triggers every iteration, check the Lipschitz constant assumption $G$.
  - Stuck at Boundary: If the decision $x_t$ hits the boundary of $K$ and oscillates, the step size $\sigma_t$ or penalty weight $\beta$ may be too aggressive.

- **First 3 experiments:**
  1. **Sanity Check (Online Matrix Completion):** Replicate the MovieLens experiment (Sec. 5) to verify that OFW-TVC achieves lower cumulative cost and constraint violation than the OPDP and LPM baselines.
  2. **Constraint Stress Test:** Artificially scale the constraint functions $g_t$ to be very large. Observe if the algorithm correctly doubles the gradient estimate $\tilde{G}_k$ and maintains the $O(T^{3/4})$ trend.
  3. **Bandit Ablation:** In the bandit setting, vary the block size $K$. Show that too small $K$ increases variance (worse regret) while too large $K$ lags behind the optimal trajectory.

## Open Questions the Paper Calls Out

### Open Question 1
Can alternative Lyapunov functions be designed to improve the cumulative constraint violation (CCV) bound for strongly convex losses to match the regret bound of $O(T^{2/3})$? Basis in paper: The authors state in the "Conclusion and Future Work" section that the current $O(T^{5/6})$ CCV bound for strongly convex losses may be due to the "impropriety of the quadratic Lyapunov function" and leave the choice of "more powerful functions" as future work. Why unresolved: The current quadratic Lyapunov function creates a trade-off where improving regret to $O(T^{2/3})$ results in a looser CCV bound compared to the general convex case. What evidence would resolve it: A theoretical analysis demonstrating an $O(T^{2/3})$ bound for both regret and CCV using a non-quadratic Lyapunov construction.

### Open Question 2
Are the theoretical bounds for projection-free online convex optimization with time-varying constraints tight, or do fundamental lower bounds exist? Basis in paper: The paper establishes improved upper bounds ($O(T^{3/4})$ for general, $O(T^{2/3})$ for strongly convex), but does not discuss whether these rates are optimal or if there is a fundamental limit to convergence in this setting. Why unresolved: Establishing optimality requires proving matching lower bounds, which is outside the scope of the current algorithmic contributions. What evidence would resolve it: A formal derivation of matching lower bounds for regret and CCV in the projection-free setting, or an algorithm that achieves even lower rates.

### Open Question 3
Can theoretical guarantees be improved if the time-varying constraint functions are also strongly convex? Basis in paper: Theorems 2 and 4 explicitly assume loss functions are strongly convex while constraint functions remain general convex, suggesting the current analysis does not exploit strong convexity in constraints to tighten bounds. Why unresolved: The surrogate loss construction and Lyapunov analysis are currently tuned for the specific asymmetry of strong losses and general constraints. What evidence would resolve it: A modified analysis that leverages the strong convexity of constraints to achieve bounds superior to $O(T^{2/3})$ regret and $O(T^{5/6})$ CCV.

## Limitations
- Theoretical analysis relies heavily on Lyapunov drift arguments assuming continuous convexity and Lipschitz smoothness
- Doubling trick mechanism introduces computational overhead that could become prohibitive if gradient norms grow rapidly
- Experimental validation is limited to synthetic constraint generation and specific matrix completion tasks, lacking stress testing on highly non-stationary or adversarial constraint sequences

## Confidence

- **High Confidence:** The core mechanism of using Lyapunov-based surrogate losses to decouple regret and constraint violation (Mechanism 1) is well-established in the literature and the theoretical framework is sound.
- **Medium Confidence:** The parameter-free doubling trick approach (Mechanism 2) follows established techniques but the interaction between the doubling schedule and the specific OFW regret bounds requires careful tracking of constants.
- **Medium Confidence:** The bandit extension (Mechanism 3) is theoretically plausible but the blocking technique's effectiveness in the projection-free setting is less established compared to standard bandit convex optimization.

## Next Checks

1. **Gradient Norm Sensitivity Test:** Run OFW-TVC on an artificial sequence where ||∇f_t|| grows exponentially. Verify that the doubling mechanism triggers appropriately and that the regret remains sublinear rather than degrading to O(T).

2. **Lyapunov Function Ablation:** Compare Exponential vs. Quadratic Lyapunov functions on a strongly convex instance. Measure whether the Quadratic version indeed provides better regret at the cost of worse constraint violation, as theory predicts.

3. **Bandit Variance Analysis:** In the bandit setting, run BFW-TVC with varying block sizes K. Plot the variance of the gradient estimator versus K and correlate with empirical regret to identify the optimal trade-off point empirically.