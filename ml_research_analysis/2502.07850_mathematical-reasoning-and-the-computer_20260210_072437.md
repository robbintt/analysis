---
ver: rpa2
title: Mathematical reasoning and the computer
arxiv_id: '2502.07850'
source_url: https://arxiv.org/abs/2502.07850
tags:
- which
- have
- proof
- mathematics
- theorem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This article provides an overview of how computers are changing
  mathematics beyond just computation. It discusses three main areas: neural networks
  helping mathematicians discover new theorems and counterexamples (such as predicting
  knot signatures and Kazhdan-Lusztig polynomials), automated and interactive theorem
  provers verifying complex mathematical results (including the four-color theorem
  and modern research-level proofs), and large language models like ChatGPT engaging
  with mathematical problems (though currently limited by tendency to make false assertions).'
---

# Mathematical reasoning and the computer

## Quick Facts
- arXiv ID: 2502.07850
- Source URL: https://arxiv.org/abs/2502.07850
- Reference count: 5
- This article surveys how computers are changing mathematics beyond computation through neural networks, theorem provers, and language models.

## Executive Summary
This article examines three main ways computers are transforming mathematical research: neural networks discovering new theorems and counterexamples, automated and interactive theorem provers verifying complex proofs, and large language models engaging with mathematical problems. The author demonstrates how neural networks trained on mathematical data can identify patterns leading to new theorems, such as relationships between knot invariants and Kazhdan-Lusztig polynomials. Interactive theorem provers like Lean are shown to verify results and simplify proofs, while large language models are more effective when generating formal code rather than natural language proofs. The field is rapidly evolving with increasing mathematician involvement.

## Method Summary
The article surveys three computational approaches to mathematical reasoning. For neural networks, the method involves training models on tables of mathematical objects and their properties, then analyzing which inputs drive predictions to identify potential theorems. For interactive theorem provers, the approach requires translating informal proofs into formal languages like Lean, where each step must be verified against axioms. For language models, the technique involves generating formal code (Lean tactics) that can be automatically checked for correctness rather than producing natural language proofs. The paper provides concrete examples including knot theory applications, verification of the four-color theorem, and LLM-generated Lean code.

## Key Results
- Neural networks successfully predicted mathematical invariants (knot signatures, Kazhdan-Lusztig polynomials) leading to proven theorems
- Interactive theorem provers verified complex results like the four-color theorem and simplified existing proofs
- Large language models show promise generating formal Lean code but struggle with natural language proof accuracy
- These computational tools are increasingly adopted by mathematicians, though true research-level reasoning remains challenging

## Why This Works (Mechanism)

### Mechanism 1: Neural Networks as Pattern Detectors for Mathematical Relationships
Neural networks trained on input-output pairs of mathematical objects can identify correlations suggesting novel theorems. When a network accurately predicts an output from inputs, analysis of parameters reveals which inputs are most important, providing clues for human mathematicians to prove formal relationships. This works when the mathematical structure is amenable to function approximation and contains learnable patterns.

### Mechanism 2: Formalization in ITPs for Verified and Simplified Proofs
Translating proofs into Interactive Theorem Provers forces rigor and can simplify arguments. The ITP checks each step against axioms, exposing gaps in informal proofs and revealing unnecessary dependencies. This mechanism succeeds when mathematical theories can be expressed in the formal system's logic.

### Mechanism 3: LLMs as Code Generators for Verifiable Proofs
Large Language Models are more useful when generating formal code in languages like Lean rather than natural language. The ITP executes this code, automatically verifying correctness. This approach succeeds when the LLM can generate syntactically and logically sound formal code at useful rates.

## Foundational Learning

- **Concept**: First-Order Logic & Axiomatic Systems
  - Why needed here: To understand how ITPs and ATPs work based on axioms and inference rules
  - Quick check question: Can you explain why `(ab)^-1 = b^-1 * a^-1` needs to be proven from group axioms rather than assumed?

- **Concept**: Function Approximation & Generalization
  - Why needed here: Core to neural network approaches - understanding the trade-off between memorizing training data and generalizing to new data
  - Quick check question: If a neural network achieves 100% accuracy on training data for predicting primality, why might it fail on new numbers?

- **Concept**: Tokens and Probabilistic Sequences
  - Why needed here: Explains how LLMs work through probabilistic token prediction rather than logical derivation
  - Quick check question: Why is an LLM more likely to produce syntactically correct Lean tactic than semantically correct one if trained on syntax over proof strategies?

## Architecture Onboarding

- **Component map**: Data Source -> Model/Engine -> Human in the Loop
- **Critical path**: Define question with available data -> Train neural network and analyze representation -> Human formalizes candidate into conjecture and develops proof -> (Optional) Formalize proof in ITP
- **Design tradeoffs**: ITP proofs are verifiable but time-consuming; natural language proofs are fast but unverifiable; LLMs generating Lean code attempt to bridge this gap
- **Failure signatures**: Neural network low accuracy on validation data; ITP formalization stalls due to undefined concepts; LLM generates logically false steps in natural language or fails to compile code
- **First 3 experiments**:
  1. Use Mathlib documentation to write formal proof of `a + b = b + a` in Lean
  2. Ask LLM to prove a theorem outside its training data in natural language vs. Lean code, identifying logical errors
  3. Generate synthetic dataset for known function, train neural network, and attempt to interpret learned weights

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can an AI system achieve a gold medal in the International Mathematics Olympiad (IMO)?
- Basis in paper: The paper identifies the "IMO Grand Challenge" as a key milestone
- Why unresolved: Current systems perform at strong schoolchild level, and translating natural language problems into formal logic without leaking information remains difficult
- What evidence would resolve it: A system successfully scoring gold medal on unseen IMO problem sets

### Open Question 2
- Question: Can the time required to formalize mathematics in ITPs be reduced to match paper proof speed?
- Basis in paper: The author asks how to decrease formalization time and notes it's currently far more time-consuming
- Why unresolved: Significant human effort still required to translate mathematical intuition into formal code
- What evidence would resolve it: Development of automated tools allowing "real-time" formalization of research-level results

### Open Question 3
- Question: Can LLMs be trained to reliably generate correct proofs in formal languages rather than natural language?
- Basis in paper: The paper notes LLMs "happily assert false statements," suggesting need to train on ITP code
- Why unresolved: Generating compilable code that leaves "no stone unturned" is harder than generating plausible text
- What evidence would resolve it: LLMs consistently generating proofs that pass ITP kernel verification

### Open Question 4
- Question: Does complexity of formalizing geometric arguments differ significantly from arithmetic arguments?
- Basis in paper: The author asks whether formalising geometry takes longer than formalising arithmetic
- Why unresolved: Geometric proofs rely heavily on visual intuition, presenting unique challenges for text-based formal systems
- What evidence would resolve it: Comparative study of formalization times for equivalent-complexity theorems in geometry vs. number theory

## Limitations

- The article provides a broad survey rather than detailed technical analysis, lacking quantitative benchmarks for neural network approaches and LLM performance
- All approaches still require substantial human intervention, but the paper doesn't quantify the human effort required relative to traditional methods
- Success in specific domains (knot theory, representation theory) may depend on specific properties that don't generalize across mathematics

## Confidence

- **High Confidence**: Basic description of how each approach works (neural networks for pattern detection, ITPs for formal verification, LLMs for code generation) is accurate and well-established
- **Medium Confidence**: Claim that these tools are "changing the way humans do mathematics" is supported by specific examples but lacks broader quantitative evidence
- **Medium Confidence**: Assertion that LLMs "struggle with accuracy" when generating natural language proofs is consistent with known limitations

## Next Checks

1. Obtain or generate specific performance metrics (accuracy rates, success probabilities, human effort measurements) for each approach to move from anecdotal evidence to systematic evaluation

2. Test whether the neural network approach can successfully identify patterns in a simple mathematical domain (e.g., polynomial relationships) where underlying patterns are known

3. Compare time and expertise required for traditional proof development, formal proof development without computational tools, and proof development using described computational approaches to quantify efficiency gains