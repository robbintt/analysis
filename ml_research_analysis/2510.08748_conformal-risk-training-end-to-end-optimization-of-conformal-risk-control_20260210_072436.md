---
ver: rpa2
title: 'Conformal Risk Training: End-to-End Optimization of Conformal Risk Control'
arxiv_id: '2510.08748'
source_url: https://arxiv.org/abs/2510.08748
tags:
- risk
- conformal
- control
- training
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces conformal risk training, a method for end-to-end
  optimization of conformal risk control that extends beyond standard expected loss
  to handle general optimized certainty equivalent (OCE) risks, including conditional
  value-at-risk (CVaR). The approach differentiates through conformal risk control
  during model training, enabling provable risk guarantees while improving average-case
  performance compared to post-hoc methods.
---

# Conformal Risk Training: End-to-End Optimization of Conformal Risk Control

## Quick Facts
- arXiv ID: 2510.08748
- Source URL: https://arxiv.org/abs/2510.08748
- Authors: Christopher Yeh; Nicolas Christianson; Adam Wierman; Yisong Yue
- Reference count: 40
- Primary result: End-to-end training method for conformal risk control that improves average-case performance while maintaining provable risk guarantees

## Executive Summary
This paper introduces conformal risk training, a method for end-to-end optimization of conformal risk control that extends beyond standard expected loss to handle general optimized certainty equivalent (OCE) risks, including conditional value-at-risk (CVaR). The approach differentiates through conformal risk control during model training, enabling provable risk guarantees while improving average-case performance compared to post-hoc methods. The method is demonstrated on two applications: controlling false negative rates in tumor image segmentation (reducing false positive rates by 23-42% while maintaining risk bounds) and controlling financial tail risk in battery storage operations (achieving 7.2-22.6% improvement in task performance over post-hoc baselines). The framework generalizes conformal training and provides closed-form gradient expressions under mild conditions, making it broadly applicable to high-stakes applications requiring both risk guarantees and strong average performance.

## Method Summary
Conformal risk training is a bi-level optimization approach that differentiates through conformal risk control during model training. The method splits each minibatch into calibration and prediction sets, uses the calibration set to compute a risk-controlling parameter λ(θ) via bisection search (Algorithm 1), then updates model parameters θ using gradients through the risk control procedure. For OCE risks like CVaR, a monotone transformation of the loss function preserves the key property required for standard CRC procedures. The framework provides closed-form gradient expressions in two key cases: piecewise constant losses with strictly decreasing task losses, or convex losses with strictly convex/monotone task losses. This end-to-end approach reduces the conservativeness of post-hoc calibration while maintaining provable risk guarantees.

## Key Results
- Tumor segmentation: Reduces false positive rates by 23-42% while maintaining false negative rate bounds at α=0.01 and α=0.05
- Battery storage: Achieves 7.2-22.6% improvement in mean profit compared to post-hoc baselines while controlling CVaR at target α
- Statistical efficiency: Larger calibration sets reduce bound conservatism, enabling less conservative λ selection and improved task utility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimized Certainty-Equivalent (OCE) risks, including CVaR, can be controlled using a monotone transformation of the original loss function, extending Conformal Risk Control (CRC).
- Mechanism: The method transforms the loss function $L_i(\lambda)$ using an OCE disutility function $\phi$ (specifically $\tilde{L}_{i,t}(\lambda) = t + \phi(L_i(\lambda) - t)$). This transformed function $\tilde{h}_t(\lambda)$ is shown to be nondecreasing in $\lambda$, preserving the key property required for the standard CRC procedure to find a risk-controlling parameter $\hat{\lambda}$.
- Core assumption: The risk measure $R$ belongs to the OCE family, and the original loss functions $L_i$ are monotone and exchangeable.
- Evidence anchors: [abstract] "a broad class of risk measures which includes as special cases the expected loss... and common tail risks like the conditional value-at-risk (CVaR)." [Section 3, Theorem 1] "For every $\lambda \in \hat{\Lambda}_t$, $R[L_{N+1}(\lambda)] \le \alpha$." [corpus] Related work like "Conformal Tail Risk Control for Large Language Model Alignment" confirms the importance of controlling tail risks in LLMs, a domain where this method could be applied.
- Break condition: The assumption that the OCE risk control problem is feasible (Assumption 4: $R[L_{N+1}(\lambda_{min})] \le \alpha$) is violated, or the loss functions $L_i$ are not monotone.

### Mechanism 2
- Claim: End-to-end training of the model parameters $\theta$ alongside the risk control parameter $\lambda$ improves average-case utility while maintaining risk guarantees.
- Mechanism: Conformal risk training differentiates through the risk control procedure (specifically the computation of $\lambda(\theta)$) to compute the gradient $d\ell/d\theta$ of a task loss $\ell$. This allows the model to learn features that minimize the downstream task loss while remaining within the risk constraint, reducing the conservativeness of post-hoc calibration.
- Core assumption: The gradient $d\lambda(\theta)/d\theta$ can be computed. The paper proves this is possible in two key cases: (i) piecewise constant losses with strictly decreasing task losses, or (ii) convex losses with strictly convex/monotone task losses.
- Evidence anchors: [abstract] "introduces 'conformal risk training,' an end-to-end approach that differentiates through conformal OCE risk control during model training." [Section 4.1, Theorem 3 (Informal)] "we may obtain a closed-form expression for $d\lambda/d\theta(\theta)$ in the following two cases..." [corpus] Evidence is weak. The provided corpus summaries focus on post-hoc CRC in various domains and do not detail end-to-end training mechanisms for risk control.
- Break condition: The relationship between the model parameters $\theta$ and the risk-controlling parameter $\lambda(\theta)$ is not differentiable or cannot be expressed in a closed form that allows for gradient propagation.

### Mechanism 3
- Claim: Using a larger calibration set leads to a tighter bound on risk and improved task performance.
- Mechanism: The risk bound formula $\tilde{h}_t(\lambda)$ includes a term $(1/(N+1))\tilde{B}_t(\lambda)$. As the calibration set size $N$ increases, the influence of the conservative upper bound $B$ diminishes. This allows the algorithm to select a larger, less conservative value for $\lambda$, which in turn improves the task utility $\ell$.
- Core assumption: The calibration data points are exchangeable and drawn from the same distribution as the test data.
- Evidence anchors: [Section A, Paragraph under Figure 5] "Increasing N reduces the effect of the upper bound B and enables choosing larger (less conservative) $\lambda$." [Figure 5] Shows empirical results where a larger calibration set size reduces task loss and achieves a tighter CVaR bound. [corpus] Evidence is weak. The provided corpus does not analyze the effect of calibration set size on bound tightness.
- Break condition: The calibration set is not representative of the test distribution, violating the exchangeability assumption.

## Foundational Learning

### Concept: Conformal Risk Control (CRC)
- Why needed here: This is the baseline framework. CRC is a post-hoc method that provides finite-sample, distribution-free guarantees on the expected value of a bounded, monotone loss function. The paper extends this to OCE risks and makes it end-to-end trainable.
- Quick check question: Given a calibration dataset of 100 loss values, how do you find a threshold $\lambda$ to ensure the false negative rate on a new test image is less than 5%?

### Concept: Optimized Certainty-Equivalent (OCE) Risks & CVaR
- Why needed here: The paper's key theoretical contribution is generalizing CRC from expected loss to the OCE family of risk measures. Conditional Value-at-Risk (CVaR) is a crucial OCE measure for controlling tail risk, which is essential in high-stakes domains like finance and medicine.
- Quick check question: What is the CVaR at a 95% confidence level for a set of potential losses? How does it differ from the expected loss?

### Concept: Bi-level Optimization
- Why needed here: Conformal risk training is framed as a bi-level optimization problem. The inner loop finds the optimal risk-controlling parameter $\lambda(\theta)$ for the current model parameters $\theta$, and the outer loop updates $\theta$ to minimize a task loss using the gradient through the inner loop's solution.
- Quick check question: In a bi-level problem where the inner problem is to find a threshold $\lambda$ subject to a constraint $\tilde{h}_t(\theta, \lambda) \le \alpha$, how would you compute the gradient of the outer objective with respect to $\theta$?

## Architecture Onboarding

### Component map
Model f_θ -> CORC module -> Risk-controlling parameter λ -> Task loss computation -> Gradient computation through CORC -> Parameter update

### Critical path
1. **Model Forward Pass:** Batch data → f_θ → model outputs
2. **Risk Calibration (Inner Loop):** Split batch into pseudo-calibration and prediction sets. Use calibration set to compute λ(θ) using CORC.
3. **Task Loss Computation:** Compute task loss ℓ on prediction set using λ(θ).
4. **Gradient Computation (Outer Loop):** Compute gradient of task loss w.r.t. θ, including the term from differentiating through λ(θ).
5. **Parameter Update:** Update θ using the computed gradient.

### Design tradeoffs
- **Risk Guarantee vs. Task Performance:** Selecting a very low risk level α provides a stronger guarantee but may be too conservative, leading to poorer average task performance.
- **Calibration Set Size vs. Training Efficiency:** Using a larger calibration set (or full-batch calibration) tightens the bound but increases computational overhead per training step.
- **Gradient Approximation:** The paper mentions approximating gradients for the tumor segmentation task by averaging over pixels with similar model outputs to reduce variance. This introduces a trade-off between gradient accuracy and computational stability.

### Failure signatures
- **Risk Control Failure:** The empirical risk on the test set exceeds the target α. This could be due to a violation of the exchangeability assumption between the calibration and test sets.
- **Performance Degradation:** Task performance (e.g., FPR) does not improve or gets worse compared to post-hoc CRC. This might indicate a poor choice of hyperparameter t or a non-differentiable interaction in the inner loop.
- **Training Instability:** Gradients dλ/dθ have high variance, leading to unstable updates. This is addressed in the paper's experimental details for segmentation.

### First 3 experiments
1. **Replicate Tumor Segmentation (Table 2):** Train a PraNet model using conformal risk training to control the False Negative Rate (FNR). Compare the FPR and FNR against a post-hoc CRC baseline at different α thresholds (e.g., 0.01, 0.05). *Expected outcome:* FNR should be controlled at α, and FPR should be significantly lower than the post-hoc baseline.
2. **Replicate Battery Storage (Figure 2):** Train an MLP to predict electricity prices and make battery control decisions. Use conformal risk training to control the CVaR of financial losses at different quantile levels δ (0.9, 0.95). *Expected outcome:* CVaR should be controlled at target α, and mean profit should be higher than the post-hoc baseline.
3. **Hyperparameter Sensitivity (Table 1 & 3):** Test the sensitivity of the method to the choice of the hyperparameter t in the CVaR disutility function. Train models with perturbed values of t and measure the impact on task loss and CVaR risk. *Expected outcome:* Performance should be relatively insensitive to small changes in t around the optimal value.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what general conditions does the gradient $d\lambda/d\theta$ exist for the conformal risk training bi-level optimization problem?
- Basis: [explicit] The authors state in Section 6: "For conformal risk training, while we derive the exact gradient in some common cases, we do not provide a complete characterization of when the gradient exists."
- Why unresolved: Theorem 3 provides closed-form expressions only for specific cases (e.g., piecewise constant or strictly convex losses), leaving the differentiability for general loss functions unproven.
- What evidence would resolve it: A theoretical derivation specifying the necessary and sufficient conditions on the loss function $L$ and cost function $\ell$ for the gradient to exist almost everywhere.

### Open Question 2
- Question: Can the Conformal OCE Risk Control (CORC) framework be extended to general coherent or distortion risk measures that lie outside the Optimized Certainty-Equivalent (OCE) family?
- Basis: [explicit] Section 6 suggests future work should "consider generalizations of CRC to other families of risk measures such as distortion... or coherent risk measures."
- Why unresolved: The current method relies on the specific variational representation of OCE risks (infimum over $t$) to maintain the monotonicity required for conformal bounds; it is unclear if other coherent measures lack this structure.
- What evidence would resolve it: A proof of risk control for a non-OCE coherent risk measure (e.g., a specific distortion risk measure not expressible as OCE) within the conformal training framework.

### Open Question 3
- Question: How tight are the finite-sample bounds provided by conformal OCE risk control, and how does the introduction of the hyperparameter $t$ affect the statistical efficiency?
- Basis: [explicit] Section 6 notes that future work may "examine the tightness of the conformal OCE risk control bound."
- Why unresolved: While the paper proves the validity of the bounds, it does not analyze the gap between the CORC bound and the true risk or how the choice of $t$ impacts the resulting set size or conservatism.
- What evidence would resolve it: A theoretical analysis of the convergence rates or bound widths relative to the optimal risk level $\alpha$ as sample size $N$ increases.

## Limitations
- The generalizability of closed-form gradient expressions to complex, non-convex loss landscapes remains unclear.
- Computational overhead of end-to-end training versus post-hoc calibration is not explicitly quantified.
- Sensitivity to hyperparameter $t$ in the OCE disutility function is not fully characterized across all problem domains.

## Confidence
- **High confidence**: The theoretical framework extending CRC to OCE risks and the core mechanism of differentiating through the risk control procedure. The empirical results for both tumor segmentation and battery storage applications are well-documented.
- **Medium confidence**: The practical utility of end-to-end training versus post-hoc methods across diverse domains. While results are promising, the computational cost-benefit trade-off needs broader validation.
- **Low confidence**: The scalability of the approach to very large models and datasets, particularly regarding variance reduction techniques and the stability of gradient computation through the inner optimization loop.

## Next Checks
1. **Robustness to Dataset Shifts**: Test the method's performance under various forms of dataset shift (e.g., covariate shift, prior probability shift) to evaluate the exchangeability assumption's practical implications.
2. **Computational Efficiency Benchmark**: Conduct a comprehensive benchmark comparing the wall-clock training time and memory usage of conformal risk training against post-hoc CRC across different model architectures and dataset sizes.
3. **Gradient Stability Analysis**: Systematically analyze the variance and stability of the gradients $d\lambda/d\theta$ under different training conditions (batch sizes, learning rates, model architectures) to identify potential failure modes and mitigation strategies.