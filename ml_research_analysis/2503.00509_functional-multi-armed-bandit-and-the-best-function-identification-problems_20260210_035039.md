---
ver: rpa2
title: Functional multi-armed bandit and the best function identification problems
arxiv_id: '2503.00509'
source_url: https://arxiv.org/abs/2503.00509
tags:
- problem
- algorithm
- function
- optimization
- regret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces two new problem classes: the functional
  multi-armed bandit (FMAB) and the best function identification (BFI) problems. These
  problems generalize the classic multi-armed bandit framework by treating each arm
  as an unknown black-box function rather than a random variable with a fixed reward
  distribution.'
---

# Functional multi-armed bandit and the best function identification problems

## Quick Facts
- arXiv ID: 2503.00509
- Source URL: https://arxiv.org/abs/2503.00509
- Authors: Yuriy Dorn; Aleksandr Katrutsa; Ilgam Latypov; Anastasiia Soboleva
- Reference count: 40
- Primary result: Introduces FMAB and BFI problems, proposing F-LCB algorithm with regret bounds based on base optimizer convergence rates

## Executive Summary
This paper introduces two new problem classes that generalize multi-armed bandits by treating each arm as an unknown black-box function. The Functional Multi-Armed Bandit (FMAB) problem aims to minimize cumulative regret while identifying the best function, while the Best Function Identification (BFI) problem focuses on finding the optimal function within a given accuracy. The authors propose the F-LCB algorithm that uses convergence rates of base optimization methods as confidence intervals to guide exploration-exploitation trade-offs. The approach is validated through extensive experiments on synthetic functions and a real-world CIFAR10 image classification task.

## Method Summary
The F-LCB algorithm treats each function as a bandit arm and uses the convergence rate of a base optimization method as a confidence interval to estimate the lower bound of each function's optimal value. At each round, the algorithm selects the function with the smallest lower confidence bound (LCB) for optimization. For FMAB, the algorithm minimizes cumulative regret by balancing exploration of suboptimal functions with exploitation of currently promising ones. For BFI, the algorithm identifies the best function by pulling each arm sufficiently many times based on its convergence rate. The method assumes access to first-order oracles and uses different base optimizers (AGD, SGMTA, SAGD) depending on function smoothness.

## Key Results
- Proves regret upper bounds for both deterministic and stochastic FMAB settings based on base optimizer convergence rates
- Establishes lower bound on iterations required for ε-accurate BFI in deterministic case
- Demonstrates effective identification of optimal function among several neural network architectures on CIFAR10 task
- Shows F-LCB outperforms early-stopping baseline by 2× in identification speed while maintaining similar final accuracy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** F-LCB reduces functional bandit problems to classical optimization by treating convergence bounds as confidence intervals
- **Mechanism:** Computes Lower Confidence Bound (LCB) for each function using base optimizer's convergence rate, selecting function with smallest LCB to balance exploration and exploitation
- **Core assumption:** Each base optimization algorithm has a known convergence rate gi(k, δ) such that f(xk) - f* ≤ gi(k, δ) holds with probability ≥ 1-δ
- **Evidence anchors:** Section 3 describes treating convergence rates as confidence intervals; Section 3 references seminal paper [30] for confidence-bound principles

### Mechanism 2
- **Claim:** Regret decomposition separates exploration cost from optimization quality
- **Mechanism:** Total regret decomposes into exploration regret from suboptimal arm pulls and optimization regret from imperfect minimization within each arm
- **Core assumption:** Functions are convex over convex domains (deterministic) or satisfy boundedness with noise assumptions (stochastic)
- **Evidence anchors:** Theorem 1 shows regret aggregates base optimizer convergence; Table 1 demonstrates different regret rates for different function classes

### Mechanism 3
- **Claim:** BFI achieves ε-accuracy with sample complexity proportional to inverse convergence rates
- **Mechanism:** Pulls each arm i at least g⁻¹i(max[fi* - f* - ε/2, ε/2]) times, stopping exploration once LCB values certify functions cannot be ε-better than current best
- **Core assumption:** Deterministic oracles provide exact values; stochastic case requires clean-event analysis with union bounds
- **Evidence anchors:** Theorem 2 establishes sample complexity; Section 4.4 shows 9±0.5 minutes identification time on CIFAR10 vs 19±0.8 minutes for baseline

## Foundational Learning

- **Concept: Upper Confidence Bound (UCB) algorithms**
  - **Why needed here:** F-LCB adapts UCB philosophy from discrete bandits to continuous optimization, replacing Hoeffding bounds with convergence rates
  - **Quick check question:** Can you explain why UCB selects argmax(μ̂ + c·√(log t/n)) and how this changes when "variance" is replaced by "optimization uncertainty"?

- **Concept: First-order oracle complexity and convergence rates**
  - **Why needed here:** Paper assumes familiarity with rates like O(1/k²) for AGD, O(1/√k) for subgradient methods
  - **Quick check question:** What convergence rate does Nesterov's accelerated gradient descent achieve for smooth convex functions, and what information does a first-order oracle provide?

- **Concept: Regret minimization framework**
  - **Why needed here:** Both FMAB (cumulative regret) and BFI (simple regret) formulations require understanding difference between online performance and final recommendation quality
  - **Quick check question:** What is the difference between RO(T) = Σt[it(xt,it) - f*] and RB(T) = fJT* - f*, and when would you prefer one formulation over the other?

## Architecture Onboarding

- **Component map:** FMAB Problem -> K functions fi: Di → R -> Oracles Oi -> Base optimizers Ai with convergence rates gi(k, δ) -> F-LCB controller -> LCB tracker -> Arm selector -> Budget allocator

- **Critical path:**
  1. Initialization: Choose base optimizer Ai for each function class
  2. Warm-start: Run one iteration of each Ai to get initial LCB estimates
  3. Main loop (t=1 to T): Select it = argmini LCBi, execute one step of Ait, update LCBit using convergence bound
  4. Output: Return best function (BFI) or cumulative actions (FMAB)

- **Design tradeoffs:**
  - Base optimizer choice: Faster convergence (AGD: O(1/k²)) reduces regret but assumes smoothness
  - Confidence parameter δ: Smaller δ gives tighter bounds but increases additive term in stochastic regret
  - Batch size for neural networks: Each "arm pull" runs multiple optimization steps (40 in CIFAR10); larger batches give cleaner LCB estimates

- **Failure signatures:**
  - Non-convex landscapes: LCB bounds become heuristic; may over-explore poor local minima
  - Corrupted oracles: Noise violating sub-exponential assumption breaks clean-event analysis
  - Identical minima: When fi* ≈ fj*, algorithm wastes budget distinguishing near-equivalent functions
  - Dimension mismatch: Different domains Di can have different dimensions ni

- **First 3 experiments:**
  1. Sanity check on synthetic convex functions: Replicate Figure 1 with K=3 smooth convex functions; verify F-LCB concentrates pulls on f1 (smallest minimum) and regret plateaus
  2. Noise robustness test: Run Figure 3 setup with varying gradient noise levels (σ ∈ {0.5, 1.0, 2.0, 4.0}); plot regret degradation
  3. Architecture search validation: Replicate CIFAR10 experiment with 3 models on subset; confirm F-LCB identifies ResNet18 with ≥2× speedup over early stopping baseline

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical guarantees rely on provable convergence rates that may not hold for non-convex neural network optimization
- Approach assumes each function has well-defined global optimum and convex landscape, limiting applicability to problems with multiple local minima
- Heuristic bounds (g(t) = 4·fi(x1,i)/√t) used for practical implementation lack formal justification

## Confidence
- **High confidence:** Regret decomposition mechanism and basic F-LCB framework for convex function classes
- **Medium confidence:** BFI sample complexity bounds and stochastic case analysis
- **Low confidence:** CIFAR10 experimental results showing architectural superiority, as these depend on heuristic convergence rates

## Next Checks
1. Replicate the synthetic smooth convex experiment (Figure 1) with K=3 functions and verify that F-LCB achieves >90% optimal arm concentration in the final 50 iterations
2. Test the algorithm's robustness to gradient noise by running the non-smooth experiment (Figure 3) with increasing noise levels (σ=0.5, 1.0, 2.0, 4.0) and measuring the regret degradation curve
3. Validate the CIFAR10 architecture search by implementing the 5 model classes with exact layer configurations and confirming that F-LCB identifies ResNet18 at least 2× faster than an early-stopping baseline while maintaining similar final accuracy