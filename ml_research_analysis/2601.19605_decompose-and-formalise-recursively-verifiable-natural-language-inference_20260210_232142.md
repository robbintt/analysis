---
ver: rpa2
title: 'Decompose-and-Formalise: Recursively Verifiable Natural Language Inference'
arxiv_id: '2601.19605'
source_url: https://arxiv.org/abs/2601.19605
tags:
- refinement
- tree
- logical
- reasoning
- autoformalisation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a method to improve natural language inference\
  \ (NLI) by using theorem provers to verify explanations step-by-step. The key idea\
  \ is to break down complex explanations into simpler parts (atomic decomposition),\
  \ automatically translate them into formal logic (autoformalisation with \u03B8\
  -substitution), and then check each part with a theorem prover."
---

# Decompose-and-Formalise: Recursively Verifiable Natural Language Inference

## Quick Facts
- arXiv ID: 2601.19605
- Source URL: https://arxiv.org/abs/2601.19605
- Authors: Xin Quan; Marco Valentino; Louise A. Dennis; André Freitas
- Reference count: 40
- Primary result: Improves verified explanation accuracy by up to 48.9% across four datasets

## Executive Summary
This paper introduces a method to improve natural language inference (NLI) by using theorem provers to verify explanations step-by-step. The key idea is to break down complex explanations into simpler parts (atomic decomposition), automatically translate them into formal logic (autoformalisation with θ-substitution), and then check each part with a theorem prover. If a part fails verification, only that part is refined instead of redoing the entire explanation. The approach improves the accuracy of verified explanations across four datasets by up to 48.9%, reduces the number of refinement iterations, and runs faster than previous methods while keeping NLI accuracy high.

## Method Summary
The framework constructs entailment trees that justify inferences, decomposes them into atomic propositions, autoformalises them into Isabelle/HOL theories using a staged θ-substitution approach, and recursively verifies the tree bottom-up. When verification fails, it uses prover diagnostics to guide localized refinement of only the implicated nodes rather than regenerating the entire explanation. This iterative process continues until the full tree is verified or a timeout occurs.

## Key Results
- Improves verified explanation accuracy by up to 48.9% across four datasets (ProofWriter, FOLIO, EntailmentBank, StrategyQA)
- Reduces the number of refinement iterations needed compared to baseline approaches
- Runs faster than previous methods while maintaining high NLI accuracy
- Shows significant improvement in proof-depth alignment with gold reasoning chains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing complex sentences into atomic propositions before formalisation reduces autoformatisation errors and enables localized failure diagnosis.
- Mechanism: Atomic decomposition splits premises and intermediate conclusions into fine-grained, entailment-preserving atoms (e.g., "Rosa is the daughter of a person" and "The person is responsible for oversight"). This reduces the search space for autoformalisation and localises proof failures to specific sub-claims. When verification fails at a node, only the implicated atoms need refinement rather than regenerating the entire explanation.
- Core assumption: The decomposition operator D(·) is entailment-preserving (φ ⊨ a for all a ∈ D(φ)), which is enforced via an NLI classifier filter at threshold 0.9.
- Evidence anchors:
  - [abstract] "break down complex explanations into simpler parts (atomic decomposition)... If a part fails verification, only that part is refined instead of redoing the entire explanation."
  - [section 3.2] Defines atomic decomposition with entailment-preserving requirement and NLI-based filtering.
  - [corpus] Related work on stepwise NLI (MorphNLI, FMR 0.532) supports incremental transformation approaches.
- Break condition: When decomposition introduces atoms that are not strictly entailed (semantic drift), or when filtering threshold is too permissive, downstream verification may fail due to spurious sub-claims.

### Mechanism 2
- Claim: Multi-step θ-substitution autoformalisation improves semantic faithfulness by enforcing consistent argument-role bindings through staged template instantiation.
- Mechanism: Rather than monolithic NL-to-logic translation, θ-substitution applies three sequential substitutions to an abstract template: (1) Entity substitution maps generic predicates to specific entities; (2) Event substitution introduces event predicates; (3) Role substitution adds Neo-Davidsonian semantic roles (agent, patient). This makes role commitments explicit and systematically repairable.
- Core assumption: The event-based logical form (Neo-Davidsonian semantics) can adequately represent the argument structure of natural language sentences without losing critical information.
- Evidence anchors:
  - [abstract] "autoformalisation with θ-substitution" and "enforce consistent argument-role bindings."
  - [section 3.3, Example 3.1] Details the three-step substitution process with concrete example.
  - [corpus] Corpus evidence is weak—no directly comparable θ-substitution implementations found in neighbors.
- Break condition: When sentences contain phenomena not representable in the event-based form (e.g., complex modality, temporality, coreference chains), the staged substitutions may produce syntactically valid but semantically misaligned formulas.

### Mechanism 3
- Claim: Bottom-up recursive verification with localized refinement reduces refinement drift and computational cost by isolating failures to specific tree nodes.
- Mechanism: The entailment tree is verified from leaves upward. When a subtree root fails verification, prover diagnostics identify implicated explanation nodes, and only those nodes are refined. This avoids global regeneration and stabilises longer-horizon reasoning. Verified subtrees are promoted as support for parent levels.
- Core assumption: Prover diagnostics can be reliably mapped back to responsible NL spans or steps, and LLMs can perform meaningful local repairs conditioned on this feedback.
- Evidence anchors:
  - [abstract] "verifies the tree bottom-up to isolate failures to specific nodes... performs local diagnostic-guided refinement instead of regenerating the whole explanation."
  - [section 3.4, Algorithm 1] Formalizes recursive VerifySubtree procedure with localized retry logic.
  - [corpus] Related work on proof-guided refinement (Faithful-Refiner, FMR 0.516) provides precedent for prover-in-the-loop approaches.
- Break condition: When initial entailment trees omit critical intermediate conclusions or introduce misleading proof plans, bottom-up checking may localise failures but not recover the globally correct chain without substantial restructuring.

## Foundational Learning

- Concept: First-order logic (FOL) and theorem proving basics (syntax, semantics, unification, resolution).
  - Why needed here: The framework targets Isabelle/HOL theories; understanding FOL structure is prerequisite to debugging autoformalisation errors and interpreting prover diagnostics.
  - Quick check question: Given an axiom "∀x. P(x) → Q(x)" and fact "P(a)", can you derive "Q(a)"? What would a failed proof attempt suggest?

- Concept: Neo-Davidsonian event semantics (event variables, thematic roles like Agent/Patient, predicate modification).
  - Why needed here: θ-substitution uses this representation; fluency is required to trace how natural language sentences map to logical forms and identify role-binding errors.
  - Quick check question: How would you represent "John baked a cake" in Neo-Davidsonian form? Identify the event variable and role predicates.

- Concept: Entailment trees and proof depth (tree structure, leaf/premise nodes, internal/conclusion nodes, depth as reasoning hops).
  - Why needed here: The framework constructs, verifies, and refines entailment trees; understanding tree topology is essential for localizing failures and interpreting proof-depth alignment results.
  - Quick check question: In an entailment tree with premises P1, P2 and hypothesis H, what does it mean if the tree depth is 3? Sketch a possible structure.

## Architecture Onboarding

- Component map: Entailment Tree Constructor -> Atomic Decomposer -> θ-Substitution Autoformaliser -> Recursive Verifier -> Localized Refiner

- Critical path: Tree construction → atomic decomposition → θ-substitution → recursive verification (loop: failure → localize → refine → re-autoformalise → re-verify) → final verified certificate

- Design tradeoffs:
  - Granularity vs. overhead: Finer atomic decomposition improves localisation but increases LLM calls and autoformalisation steps.
  - Faithfulness vs. prover-compatibility: Richer logical forms capture more semantics but may introduce type/scope errors that block proofs.
  - Local vs. global repair: Localized refinement is efficient but may not recover from fundamentally flawed tree structures.

- Failure signatures:
  - Syntax errors in Isabelle/HOL: Malformed binders, type mismatches—directly surfaced by prover.
  - Quantifier/variable errors: Well-typed formulas with wrong scope or role bindings—require semantic analysis.
  - Refinement drift: Used proof depth undershoots gold depth (Figure 4)—signals over-compression of reasoning steps.
  - Verification timeout: Deep trees or complex theories may exceed prover resource limits.

- First 3 experiments:
  1. Ablation on atomic decomposition: Run LLM-TP Tree with and without atomic decomposition on a 50-instance subset of FOLIO. Measure change in refinement iterations and final verification rate. Expect 0.3–0.5 iteration reduction per instance.
  2. θ-substitution error analysis: Sample 20 failed autoformalisations from EntailmentBank. Categorize errors (syntax/implication/quantifier/variable) and identify which substitution step introduced each error. Target: isolate most failure-prone stage.
  3. Proof-depth alignment test: On ProofWriter depth-5 instances, compare used proof depth vs. gold depth for LLM-TP Tree vs. Explanation-Refiner. Quantify drift (deviation from y=x line) and correlate with verification success.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the robustness of entailment-tree construction and diagnostic localisation be improved to handle cases where the initial tree structure is misleading?
- Basis in paper: [explicit] Section 7 (Conclusion) states future work will "improve the robustness of entailment-tree construction and diagnostic localisation."
- Why unresolved: The current method relies on the LLM's initial tree proposal; if critical intermediate conclusions are omitted, bottom-up verification may fail to recover the correct chain without global restructuring.
- What evidence would resolve it: Error analysis quantifying the frequency of structural tree errors versus autoformalisation errors in complex, naturalistic datasets.

### Open Question 2
- Question: Can a formal convergence guarantee be established for the iterative local refinement loop?
- Basis in paper: [explicit] Section "Limitations" explicitly notes the system "does not provide a formal convergence guarantee to the minimal or unique refined explanation."
- Why unresolved: The refinement process depends on stochastic LLM outputs guided by prover diagnostics, which introduces the risk of non-termination or failure to find a minimal solution.
- What evidence would resolve it: Theoretical analysis of the algorithm's termination properties or empirical evidence demonstrating convergence rates across diverse reasoning depths.

### Open Question 3
- Question: To what extent can the computational cost of verification be reduced by reusing verified subtrees across different inference problems?
- Basis in paper: [explicit] Section 7 (Conclusion) lists future work to "further reduce verification cost through better reuse of verified subtrees."
- Why unresolved: While atomic decomposition reduces local complexity, the framework still incurs non-trivial compute costs from repeated LLM calls and prover invocations that might be redundant across similar queries.
- What evidence would resolve it: Implementation of a subtree caching mechanism and benchmarks comparing runtime and verification rates with and without reuse.

## Limitations

- The framework's effectiveness depends on the initial entailment tree structure being reasonably accurate; fundamentally flawed trees may not be recoverable through localized refinement alone.
- The θ-substitution approach may struggle with linguistic phenomena that cannot be adequately captured in the event-based logical form, such as complex modality or coreference chains.
- The framework does not provide formal convergence guarantees for the iterative refinement process, raising concerns about potential non-termination or failure to find minimal solutions.

## Confidence

- High: The claim that atomic decomposition reduces refinement iterations is supported by ablation results showing 48.9% improvement in verified explanations.
- Medium: The assertion that θ-substitution improves semantic faithfulness is plausible given the staged approach, but lacks direct comparative evidence against monolithic translation methods.
- Low: The claim that localized refinement reduces computational cost is based on runtime comparisons, but the paper does not isolate the contribution of localization from other optimizations.

## Next Checks

1. θ-substitution completeness test: Manually annotate 50 natural language sentences from FOLIO for phenomena like modality, coreference, and temporality. Measure the percentage that can be fully represented in the event-based logical form after θ-substitution.

2. Diagnostic mapping validation: For 20 failed proof attempts, trace the prover diagnostics back to the implicated NL spans. Measure the accuracy of this mapping and its impact on refinement success.

3. Global vs. local repair comparison: On a subset of EntailmentBank, compare the final verification rate and proof depth alignment of LLM-TP Tree with localized refinement vs. a variant that performs global regeneration after each failure.