---
ver: rpa2
title: A Comparative Study of Large Language Models and Human Personality Traits
arxiv_id: '2505.14845'
source_url: https://arxiv.org/abs/2505.14845
tags:
- personality
- human
- measurement
- variant
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the personality traits of Large Language
  Models (LLMs) and their differences from human personality. Three empirical studies
  were conducted using a behavior-based approach, employing human personality scales
  adapted for LLMs.
---

# A Comparative Study of Large Language Models and Human Personality Traits

## Quick Facts
- arXiv ID: 2505.14845
- Source URL: https://arxiv.org/abs/2505.14845
- Reference count: 40
- Primary result: LLMs show higher variability and input-sensitivity than humans, lacking long-term stability in personality traits

## Executive Summary
This study investigates the personality traits of Large Language Models (LLMs) and their differences from human personality through three empirical studies using a behavior-based approach. The research employs human personality scales adapted for LLMs to examine test-retest stability, cross-variant consistency, and personality retention during role-playing. Key findings reveal that LLMs demonstrate significantly higher variability and input-sensitivity compared to humans, leading to the proposal of a "Distributed Personality Framework for LLMs" that conceptualizes LLM traits as dynamic and context-dependent rather than stable characteristics.

The study's results challenge traditional notions of personality assessment when applied to AI systems, showing that LLM responses are highly sensitive to prompt wording and parameter settings rather than reflecting consistent internal traits. This has important implications for understanding human-AI interaction and suggests that LLM personality expression is fluid and externally driven rather than representing inherent characteristics of the models themselves.

## Method Summary
The research employed a behavior-based approach using three adapted human personality scales to assess LLM personality traits across different experimental conditions. Study 1 examined test-retest stability by measuring LLM responses to the same personality items across multiple sessions. Study 2 analyzed cross-variant consistency by comparing responses across different LLM variants to the same items. Study 3 explored personality retention during role-playing by examining how LLM traits changed when prompted to adopt different personas. The methodology focused on quantitative analysis of response patterns and variability measures.

## Key Results
- LLMs show significantly higher variability and input-sensitivity than humans, lacking long-term stability in personality expression
- LLM responses demonstrate high sensitivity to item wording with low internal consistency compared to human responses
- LLM personality traits are shaped by prompt and parameter settings, showing fluid and externally dependent patterns rather than stable internal characteristics

## Why This Works (Mechanism)
The study's approach works because it directly compares LLM behavior to established human personality assessment methods while recognizing the fundamental differences in how these systems process and respond to stimuli. By using adapted human personality scales, the research creates a measurable framework for quantifying personality-like responses in LLMs, allowing for systematic comparison of stability, consistency, and context-dependence between human and artificial systems.

## Foundational Learning
1. **Personality assessment frameworks**: Understanding human personality measurement (e.g., Big Five, MBTI) is essential for adapting these tools to AI systems and establishing baseline comparisons.
2. **Behavior-based measurement approaches**: Recognizing that personality can be assessed through observable responses rather than assuming internal states is crucial for studying non-human entities.
3. **Test-retest reliability concepts**: Knowledge of statistical methods for measuring stability and consistency over time provides the foundation for evaluating LLM personality stability.
4. **Item response theory**: Understanding how different wordings of questions can affect responses is critical for interpreting cross-variant consistency results.
5. **Prompt engineering principles**: Recognizing how different prompts and parameters influence LLM outputs is fundamental to understanding the distributed nature of LLM personality expression.
6. **Statistical variability measures**: Familiarity with measures of consistency and stability (e.g., Cronbach's alpha, correlation coefficients) is necessary for quantifying differences between human and LLM responses.

## Architecture Onboarding

**Component Map**: Human Personality Scales → LLM Input Prompts → LLM Response Patterns → Statistical Analysis → Personality Framework

**Critical Path**: The research follows a sequential path from adapting existing personality measurement tools, applying them to LLM inputs, collecting response data, performing statistical analysis on response patterns, and developing new frameworks based on observed differences.

**Design Tradeoffs**: The study trades the complexity of developing entirely new LLM-specific personality measures for the advantage of using established, validated human personality scales as a comparative baseline. This allows for direct comparison but may miss unique aspects of LLM personality expression.

**Failure Signatures**: If results showed high consistency across LLM variants or strong test-retest stability, it would suggest either that LLMs possess stable internal personality traits or that the measurement tools are not sensitive enough to detect the distributed nature of LLM responses.

**First Experiments**:
1. Replicate the test-retest study with a larger sample of LLM variants to confirm the input-sensitivity finding
2. Conduct a cross-linguistic analysis to determine if item wording sensitivity extends to language variations
3. Test personality retention during role-playing across different domains (creative writing, technical assistance, etc.)

## Open Questions the Paper Calls Out
None

## Limitations
- The behavior-based approach may not capture the full complexity of LLM personality expression, particularly for models with different underlying mechanisms
- Findings may not generalize across different LLM architectures and training regimes due to the limited range of variants tested
- The use of adapted human personality scales raises questions about validity and appropriateness for non-human entities
- The study does not address potential long-term changes in LLM personality traits due to ongoing training or fine-tuning processes

## Confidence
**High confidence**: LLMs show higher variability and input-sensitivity than humans (Study 1 results are well-supported by empirical data)

**Medium confidence**: LLM responses are highly sensitive to item wording with low internal consistency compared to humans (plausible but influenced by specific scales and limited LLM variants tested)

**Low confidence**: LLM traits are shaped by prompt and parameter settings during role-playing (based on single study, may not generalize to all architectures)

## Next Checks
1. Conduct a replication study using a wider range of LLM architectures (transformer-based, recurrent neural networks, hybrid models) to assess generalizability of the "Distributed Personality Framework for LLMs"

2. Perform a longitudinal study tracking changes in LLM personality traits over time, including periods of active training and fine-tuning, to better understand stability and evolution of these traits

3. Develop and validate LLM-specific personality scales based on unique characteristics of these models rather than adapting human personality measures, to ensure more accurate assessments of LLM personality traits