---
ver: rpa2
title: 'CAViAR: Critic-Augmented Video Agentic Reasoning'
arxiv_id: '2509.07680'
source_url: https://arxiv.org/abs/2509.07680
tags:
- video
- answer
- segment
- final
- when
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CAViAR introduces an agentic reasoning framework that leverages
  existing video perception models to solve complex video reasoning tasks. It uses
  a reasoning agent to iteratively compose video modules into executable programs,
  adapting its strategy based on intermediate results rather than following a fixed
  procedure.
---

# CAViAR: Critic-Augmented Video Agentic Reasoning

## Quick Facts
- arXiv ID: 2509.07680
- Source URL: https://arxiv.org/abs/2509.07680
- Reference count: 40
- Primary result: 62.0% accuracy on LVBench, 13% absolute improvement over state-of-the-art

## Executive Summary
CAViAR introduces an agentic reasoning framework that leverages existing video perception models to solve complex video reasoning tasks. The system uses a reasoning agent to iteratively compose video modules into executable programs, adapting its strategy based on intermediate results rather than following a fixed procedure. A natural-language critic selects the most promising reasoning trace from multiple sampled strategies based on examples of successful and unsuccessful sequences. This approach achieves strong performance on multiple datasets, demonstrating significant improvements over existing methods for video understanding and reasoning tasks.

## Method Summary
CAViAR employs a two-component system consisting of a reasoning agent and a natural-language critic. The reasoning agent samples multiple reasoning traces by composing video perception modules into executable programs, adapting its strategy based on intermediate results. The critic then evaluates these traces using learned patterns from successful and unsuccessful reasoning sequences to select the most promising approach. This agent-critic framework allows CAViAR to handle complex video reasoning tasks that require multiple steps and adaptive decision-making, rather than relying on a single predetermined program.

## Key Results
- Achieves 62.0% accuracy on LVBench, representing a 13% absolute improvement over state-of-the-art
- Demonstrates 77.2% accuracy on Neptune, improving even over direct inference with ASR
- Attains 32.3% mIOU on ActivityNet-RTL, showing 9+ point improvement over baselines

## Why This Works (Mechanism)
The agentic reasoning framework works by breaking down complex video reasoning tasks into executable programs composed of existing video perception modules. Rather than attempting to solve the entire task with a single model, CAViAR iteratively builds and evaluates different reasoning strategies. The key innovation is the natural-language critic, which learns to distinguish between successful and unsuccessful reasoning traces based on intermediate results and final outcomes. This allows the system to select the most promising approach from multiple sampled strategies, effectively mitigating errors that would occur if following a single incorrect reasoning path.

## Foundational Learning
- **Video perception modules**: Pre-trained models for tasks like object detection, action recognition, and scene understanding. Needed because building specialized models for every reasoning task is impractical.
- **Reasoning traces**: Sequences of module compositions that form executable programs. Quick check: verify that each trace can be compiled into valid program code.
- **Natural-language critics**: Models trained to evaluate reasoning quality based on examples. Needed to select the best approach from multiple candidates. Quick check: test critic's ability to distinguish successful from failed traces on validation data.
- **Agent-based sampling**: Stochastic generation of multiple reasoning strategies. Needed because deterministic approaches fail on complex tasks. Quick check: measure diversity of sampled traces across multiple runs.

## Architecture Onboarding
- **Component map**: Reasoning Agent -> Multiple Traces -> Natural-Language Critic -> Selected Trace -> Video Perception Modules -> Final Output
- **Critical path**: Agent samples traces → Critic evaluates traces → Best trace executes through perception modules
- **Design tradeoffs**: Multiple traces improve accuracy but increase computation; critic adds complexity but prevents catastrophic failures
- **Failure signatures**: Single-program approaches fail when initial module assumptions are incorrect; agent-critic combination recovers by trying alternative strategies
- **First experiments**: 1) Test agent sampling with fixed critic, 2) Evaluate critic on synthetic success/failure examples, 3) Measure performance degradation when removing critic component

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- Performance constrained by underlying video perception model capabilities
- Computational overhead from generating and evaluating multiple reasoning traces
- Training data composition may bias the critic's evaluation criteria
- Significant performance gaps remain on the most challenging video reasoning tasks

## Confidence
- High confidence in experimental methodology and baseline comparisons
- Medium confidence in generalization claims due to limited dataset coverage
- Medium confidence in critic effectiveness based on ablation studies

## Next Checks
1. Evaluate CAViAR's robustness when individual perception modules produce noisy or incorrect outputs
2. Test the approach on additional video reasoning datasets beyond those mentioned in the paper
3. Conduct ablation studies on the critic's training data size and composition sensitivity