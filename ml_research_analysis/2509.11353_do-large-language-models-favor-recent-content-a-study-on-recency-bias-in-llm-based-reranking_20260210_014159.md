---
ver: rpa2
title: Do Large Language Models Favor Recent Content? A Study on Recency Bias in LLM-Based
  Reranking
arxiv_id: '2509.11353'
source_url: https://arxiv.org/abs/2509.11353
tags:
- language
- llms
- relevance
- bias
- large
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether large language models (LLMs) exhibit
  recency bias when used as rerankers in information retrieval. The authors inject
  artificial publication dates into search result passages and observe how seven LLMs
  reorder them.
---

# Do Large Language Models Favor Recent Content? A Study on Recency Bias in LLM-Based Reranking

## Quick Facts
- arXiv ID: 2509.11353
- Source URL: https://arxiv.org/abs/2509.11353
- Reference count: 40
- LLMs systematically promote newer-looking content in reranking, shifting mean publication year forward by up to 4.78 years

## Executive Summary
This study systematically investigates whether large language models exhibit recency bias when used as rerankers in information retrieval. The authors inject artificial publication dates into search result passages and observe how seven different LLMs reorder them. Results demonstrate that all tested models consistently promote newer-looking content, with the largest models only partially attenuating the effect. Pairwise preference experiments confirm that recency cues can reverse up to 25% of baseline judgments between equally relevant passages. The findings provide quantitative evidence of pervasive recency bias in LLM-based reranking and underscore the need for bias-mitigation strategies.

## Method Summary
The authors conducted controlled experiments using seven different LLMs as rerankers for search results. They artificially injected publication dates into passage metadata and observed how models reordered results based on these temporal cues. The study measured both the magnitude of rank shifts (up to 95 positions) and the systematic preference for newer content across multiple model sizes. Pairwise preference experiments were used to validate the consistency of recency bias effects on relevance judgments.

## Key Results
- All seven tested LLMs systematically promote newer-looking content in search results
- Recency bias shifts mean publication year of top-10 results forward by up to 4.78 years
- Individual items can move as many as 95 ranks due to recency cues
- Even largest models attenuate but don't eliminate the bias
- Recency cues reverse up to 25% of baseline relevance judgments in pairwise comparisons

## Why This Works (Mechanism)
The paper does not explicitly explain the underlying mechanism for why LLMs exhibit recency bias. However, the observed pattern suggests that models may have learned implicit associations between newer content and higher quality or relevance from their training data, where recent information often correlates with up-to-date knowledge and current events.

## Foundational Learning
The paper does not discuss foundational learning principles or how recency bias relates to fundamental aspects of language model training. This section could be expanded to explore whether recency bias emerges from specific training data distributions or architectural features that make recent information more salient to models.

## Architecture Onboarding
The paper does not provide details about architecture-specific factors that might influence recency bias. This section could address how different model sizes, architectures, or training approaches might affect the strength and persistence of recency bias in reranking tasks.

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions for future research. Potential open questions could include: How does recency bias vary across different domains or query types? Can targeted fine-tuning reduce recency bias without harming overall performance? What are the long-term implications of recency-biased reranking for information access and knowledge preservation?

## Limitations
- Synthetic date-injection method may not fully capture real-world recency signals
- Focus on passage-level reranking may not generalize to document-level or mixed-query contexts
- Controlled environment limits understanding of how recency bias interacts with other ranking factors in deployed systems
- Limited exploration of how recency bias might vary across different domains or query types
- Does not investigate potential mitigation strategies for addressing recency bias

## Confidence
- Systematic recency bias observed across all tested LLMs: High
- Quantitative impact on ranking quality: High
- External validity of synthetic date injection: Medium
- Generalizability to production systems: Medium

## Next Checks
1. Test recency bias effects using naturally dated content from real-world corpora to assess ecological validity of synthetic date injection
2. Evaluate bias persistence across different query types (navigational, informational, temporal) and document formats
3. Measure downstream impact on end-user satisfaction and task completion when recency-biased rerankers are deployed in production systems
4. Investigate domain-specific variations in recency bias strength and impact
5. Explore potential mitigation strategies such as debiasing fine-tuning or architectural modifications