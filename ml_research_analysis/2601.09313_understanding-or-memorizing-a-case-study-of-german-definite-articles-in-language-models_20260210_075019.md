---
ver: rpa2
title: Understanding or Memorizing? A Case Study of German Definite Articles in Language
  Models
arxiv_id: '2601.09313'
source_url: https://arxiv.org/abs/2601.09313
tags:
- article
- gfem
- neut
- masc
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study examines whether German definite articles in language\
  \ models reflect abstract grammatical rules or surface-level memorization. Using\
  \ GRADIEND, a gradient-based interpretability method, the authors learn parameter\
  \ update directions for specific article transitions (e.g., der\u2192die) across\
  \ different gender-case combinations."
---

# Understanding or Memorizing? A Case Study of German Definite Articles in Language Models

## Quick Facts
- arXiv ID: 2601.09313
- Source URL: https://arxiv.org/abs/2601.09313
- Authors: Jonathan Drechsel; Erisa Bytyqi; Steffen Herbold
- Reference count: 40
- Key outcome: German definite articles in language models reflect both abstract grammatical rules and surface-level memorization, with spillover effects across grammatically distinct contexts sharing the same article forms.

## Executive Summary
This study investigates whether German definite articles in language models reflect abstract grammatical rules or surface-level memorization. Using GRADIEND, a gradient-based interpretability method, the authors learn parameter update directions for specific article transitions across different gender-case combinations. They find that applying these learned updates affects article probabilities not just in the trained cell but also in unrelated gender-case settings, with substantial overlap among the most affected neurons across settings. While some generalization along grammatical dimensions is observed, the results also show spillover effects that contradict a purely rule-based encoding. This indicates that models at least partly rely on memorized associations rather than abstract grammatical rules.

## Method Summary
The authors use GRADIEND, a gradient-based interpretability method, to learn parameter update directions that transform article predictions from one grammatical context to another. They construct gender-case datasets from German Wikipedia, train GRADIEND models on 12 gender-case combinations, and apply learned updates to evaluate probability changes across contexts. The analysis focuses on whether updates trained on one context affect other contexts sharing surface articles but differing in grammatical features, testing the hypothesis that models use either abstract rules or surface memorization.

## Key Results
- GRADIEND interventions cause probability shifts not only in trained cells but also in unrelated gender-case settings sharing surface articles
- Substantial overlap exists among the most affected neurons across different GRADIEND models
- Some generalization along grammatical dimensions occurs, but spillover effects contradict purely rule-based encoding
- Larger models (LLaMA) show less spillover, suggesting a tentative scaling trend toward more structured representations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Language models encode German definite articles via partially shared parameter subspaces rather than fully disentangled grammatical variables.
- **Mechanism:** GRADIEND learns a scalar bottleneck direction that, when decoded and applied as a parameter update, shifts article probabilities. The fact that updates trained on one gender-case cell affect unrelated cells sharing the same surface article indicates that the model does not maintain clean separations between grammatical contexts.
- **Core assumption:** Gradient directions that produce behavioral change reveal causally relevant parameter subspaces; overlap in top-k affected weights implies shared computational mechanisms.
- **Evidence anchors:**
  - [abstract] "updates learned for a specific gender-case article transition frequently affect unrelated gender-case settings, with substantial overlap among the most affected neurons across settings"
  - [Section 5.3] Heatmaps show probability shifts in cells not predicted by rule-based generalization (e.g., P(der) changes on DFEM_DAT when training on GFEM,MASC_NOM)
  - [corpus] No direct corpus evidence; mechanism inferred from model-internal analysis
- **Break condition:** If models were using abstract grammatical rules, updates trained on (MASC, NOM) → (FEM, NOM) should not systematically affect (FEM, DAT) predictions that share surface article "der."

### Mechanism 2
- **Claim:** German article prediction relies on surface-article associations that spill over across grammatically distinct contexts.
- **Mechanism:** The "spillover" pattern occurs because models associate article tokens (der, die, das) with contextual patterns without fully binding them to abstract (gender, case) variables. An intervention targeting "der→die" affects all cells containing "der" as source, regardless of grammatical relationship.
- **Core assumption:** Syncretism in German (same article appearing in multiple gender-case combinations) creates a testable ambiguity; rule-based encoding would disambiguate via context, surface-based encoding would not.
- **Evidence anchors:**
  - [Section 1] "der appears as nominative masculine and as dative/genitive feminine... This ambiguity lets us test whether article behavior reflects rule-based generalization or context-specific memorization"
  - [Section 5.3, Figure 6] Probability shifts partially match "spillover" predictions rather than clean "generalized rule" patterns
  - [corpus] Neighbor papers on grammatical gender bias (arXiv:2508.03199) suggest grammatical features influence model behavior, but not necessarily via rule-based representations
- **Break condition:** If strict rule-encoding held, interventions would propagate only along grammatical dimensions (same gender across cases, or same case across genders), not along surface-article identity.

### Mechanism 3
- **Claim:** Larger models may exhibit less surface-level spillover, suggesting a tentative scaling trend toward more structured representations.
- **Mechanism:** As model capacity increases, the cost of maintaining disentangled representations decreases relative to the benefit of generalization. LLaMA (3.2B) shows weaker spillover effects than smaller encoder-only models.
- **Core assumption:** Scaling trends observed in a limited size range (109M–3.2B parameters) may extrapolate, though this is not conclusively demonstrated.
- **Evidence anchors:**
  - [Section 5.5] "We also observe a tentative size trend: larger models (LLaMA) show less spillover"
  - [Section 5.2] LLaMA's encoded-value distributions show less stable separation than encoder-only models, but this may reflect the auxiliary MLM head rather than fundamental representation differences
  - [corpus] Weak external evidence; scaling behavior for grammatical representations remains understudied
- **Break condition:** This is explicitly tentative in the paper; confident claims would require systematic scaling experiments beyond the 6 models tested.

## Foundational Learning

- **Concept:** German article paradigm and syncretism
  - **Why needed here:** The entire analysis depends on understanding that German definite articles form a 3×4 gender×case grid where multiple cells share surface forms (e.g., "der" = MASC.NOM = FEM.DAT = FEM.GEN).
  - **Quick check question:** Can you explain why "der→die" transitions occur in multiple grammatically distinct contexts?

- **Concept:** Gradient-based interpretability and counterfactual interventions
  - **Why needed here:** GRADIEND operates by learning to reconstruct gradient differences between factual and alternative targets, then applying decoded directions as parameter updates.
  - **Quick check question:** Why does using alternative-target gradients (∇A) rather than factual gradients (∇F) stabilize training for high-confidence predictions?

- **Concept:** Top-k weight overlap as a similarity metric
  - **Why needed here:** The paper quantifies mechanism sharing by computing intersection over union of the 1,000 largest-magnitude decoder weights across GRADIEND variants.
  - **Quick check question:** What does high overlap between GRADIEND models trained on different transitions imply about the underlying representations?

## Architecture Onboarding

- **Component map:**
  Base LM -> GRADIEND encoder -> scalar bottleneck h -> GRADIEND decoder -> parameter update direction

- **Critical path:**
  1. Construct gender-case datasets by filtering German Wikipedia with spaCy annotations
  2. For each transition (z_1 ↔ z_2), train GRADIEND with swapped targets on z_1, z_2 and identity pairs on remaining 10 cells
  3. Select intervention strength α* under 99% LMS-preservation constraint on D_NEUTRAL
  4. Evaluate probability changes across all 12 gender-case cells

- **Design tradeoffs:**
  - **LMS preservation vs. effect magnitude:** Conservative α selection yields small probability shifts (<1%) but ensures changes reflect targeted mechanisms rather than broad degradation
  - **k=1000 for overlap analysis:** Chosen as stable operating point in transition-dominated regime; smaller k is noisy, larger k includes weakly-informative weights
  - **Decoder-only auxiliary head:** Necessary for bidirectional conditioning but introduces training variance not present in encoder-only models

- **Failure signatures:**
  - GRADIEND fails to separate transition directions (h clusters near zero for all inputs) → check gradient scale, increase learning rate
  - Interventions cause LMS collapse before observable article shifts → α range too aggressive or GRADIEND overfit to training cells
  - Identity pairs map to non-zero h → encoder not learning do-not-change constraint; verify dataset construction

- **First 3 experiments:**
  1. Replicate GFEM,MASC_NOM training on GermanBERT; verify encoded-value distributions match Figure 3 (separated transition directions, centered identity pairs)
  2. Apply decoded update at increasing α values; confirm probability shifts appear before 99% LMS threshold
  3. Compute Top-1000 overlap between GFEM,MASC_NOM and GFEM_NOM,DAT; verify >70% intersection as reported in Table 5

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the degree of memorization vs. rule-based encoding decrease systematically with model scale?
- Basis in paper: [explicit] "We evaluate only a limited model scale range (up to ∼3B parameters). Larger models or models trained with substantially different data mixtures or objectives may encode grammatical information differently, and scaling trends cannot be confidently concluded from our setup."
- Why unresolved: Only one large model (LLaMA 3.2B) was tested, and while it showed less spillover, the limited scale range prevents confident conclusions.
- What evidence would resolve it: Systematic evaluation across a wider range of model sizes (e.g., 7B, 13B, 70B) using identical GRADIEND methodology.

### Open Question 2
- Question: Do the findings generalize to other morphosyntactic phenomena beyond German definite articles?
- Basis in paper: [explicit] "We focus exclusively on German definite singular articles, a small and highly regular closed-class system... the findings may not transfer to other morphosyntactic phenomena (e.g., adjective agreement, verb inflection, or freer word order) or to other languages."
- Why unresolved: The study deliberately constrained scope to one controlled paradigm for interpretability.
- What evidence would resolve it: Applying GRADIEND to adjective agreement, verb inflection, and cross-linguistically to languages with different morphological complexity.

### Open Question 3
- Question: What is the exact nature of the hybrid mechanism between pure memorization and rule-based encoding?
- Basis in paper: [inferred] The paper argues against purely rule-based encoding (H2) and supports partial memorization (H1), but doesn't characterize how the two mechanisms interact or coexist.
- Why unresolved: The binary hypothesis framework doesn't capture intermediate or hybrid mechanisms.
- What evidence would resolve it: Fine-grained analysis of which contexts/nouns trigger memorization vs. rule-like behavior, potentially using sparse autoencoders to decompose the shared parameter subspace.

### Open Question 4
- Question: How do the observed probability shifts translate to downstream generation behavior?
- Basis in paper: [explicit] "Our evaluation focuses on controlled probability shifts and parameter overlap rather than downstream generation behavior."
- Why unresolved: Interventions were evaluated on masked prediction tasks, not on actual text generation.
- What evidence would resolve it: Evaluating GRADIEND-modified models on open-ended generation tasks measuring grammatical accuracy and article consistency.

## Limitations

- Limited generalizability to other languages and morphosyntactic phenomena beyond German definite articles
- Small sample size of models (6) and languages (1) constrains broader conclusions
- Small effect sizes (<1% probability shifts) raise questions about practical significance
- Arbitrary choice of 1,000 weights for overlap analysis may influence conclusions about shared mechanisms

## Confidence

**High Confidence:** The observation that GRADIEND interventions produce spillover effects across grammatically distinct contexts with shared surface articles.

**Medium Confidence:** The claim that models at least partly rely on memorized associations rather than abstract grammatical rules.

**Low Confidence:** The tentative scaling trend suggesting larger models show less surface-level spillover.

## Next Checks

1. **Cross-linguistic validation:** Apply GRADIEND to Romance languages (e.g., French or Italian) with different article systems and syncretism patterns to test whether spillover effects generalize beyond German's specific gender-case matrix.

2. **Effect size sensitivity analysis:** Systematically vary intervention strength α beyond the 99% LMS-preservation constraint to determine whether larger perturbations reveal clearer distinctions between surface-based and rule-based encoding.

3. **Out-of-distribution generalization test:** Evaluate whether GRADIEND models trained on in-domain Wikipedia data transfer to low-resource or domain-shifted German corpora (e.g., social media or technical writing) to assess the robustness of learned parameter update directions.