---
ver: rpa2
title: Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion
arxiv_id: '2512.11997'
source_url: https://arxiv.org/abs/2512.11997
tags:
- knowledge
- detection
- anomaly
- logs
- entries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EnrichLog is a training-free, entry-based log anomaly detection
  framework that enriches raw log entries with both corpus- and sample-specific contextual
  knowledge using retrieval-augmented generation (RAG). The method addresses the challenge
  of ambiguous log templates by providing instance-level reasoning and historical
  examples to guide classification.
---

# Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion

## Quick Facts
- arXiv ID: 2512.11997
- Source URL: https://arxiv.org/abs/2512.11997
- Reference count: 40
- Primary result: Achieved 99.37% F1 on BGL dataset with Mistral-7B

## Executive Summary
EnrichLog is a training-free log anomaly detection framework that enriches raw log entries with contextual knowledge using retrieval-augmented generation. The method addresses the challenge of ambiguous log templates by providing instance-level reasoning and historical examples to guide classification. Evaluated on four large-scale system log datasets, EnrichLog consistently outperforms five baseline methods, achieving high F1-scores while maintaining efficiency through a two-step inference strategy.

## Method Summary
EnrichLog uses a two-step inference approach: a lightweight first step filters confidently normal logs using a base LLM, while a second RAG-based step processes potential anomalies with enriched context. The framework enriches raw log entries with both corpus- and sample-specific contextual knowledge, addressing the challenge of ambiguous log templates where normal and anomalous logs share identical structures. Knowledge is generated offline through corpus summarization and sample-specific reasoning, stored in a vector database, and retrieved during inference to improve classification accuracy.

## Key Results
- Achieved 99.37% F1 on BGL dataset with Mistral-7B
- 100% F1 on Thunderbird dataset with Mistral-7B
- Outperformed five baseline methods across all four benchmark datasets
- Two-step approach reduced computational cost by filtering 85% of logs on Mistral-7B

## Why This Works (Mechanism)

### Mechanism 1: Sample-Specific Knowledge Enrichment for Ambiguity Resolution
- Claim: Providing reasoning about individual log entries resolves ambiguities where normal and anomalous logs share identical templates.
- Mechanism: An enrichment LLM generates concise explanations (Ke) for why specific log entries are classified as normal or anomalous, emphasizing variable components that templates discard.
- Core assumption: Discriminative information distinguishing normal from anomalous logs within the same template resides in the raw variable text.
- Evidence anchors: [abstract] "EnrichLog incorporates contextual information, including historical examples and reasoning derived from the corpus"; [section 5.7, Table 6] On ambiguous BGL templates, EnrichLog* achieves 92.12 F1 vs 87.37 for RAGLog.

### Mechanism 2: Two-Step Cascaded Inference for Efficiency
- Claim: A lightweight first pass filtering confidently normal logs preserves accuracy while reducing computational cost.
- Mechanism: Step 1 uses a base LLM with only raw log text; only uncertain or anomalous predictions proceed to Step 2's full RAG pipeline.
- Core assumption: Pretrained LLMs inherently exhibit high recall on log anomaly detection, reliably filtering true negatives even without external knowledge.
- Evidence anchors: [abstract] "a lightweight first step filters confidently normal logs, while a second RAG-based step processes potential anomalies"; [section 5.8, Table 7] Mistral-7B routes only 15% of logs to the slower second step.

### Mechanism 3: Distilled Corpus Knowledge for Context Injection
- Claim: Condensing corpus documentation into concise summaries improves sample-specific enrichment more effectively than raw documents.
- Mechanism: An LLM generates a brief "takeaway" (Kc) from corpus documentation; this distilled knowledge guides subsequent sample-level reasoning generation (Ke).
- Core assumption: Open-source models struggle with long, unstructured documents; concise summaries focus attention on decision-critical signals.
- Evidence anchors: [section 3.1.1, Eq. 1] Kc = Θ(C) defines corpus knowledge generation; [section 5.4, Table 3] "Concise takeaway" achieves 99.37 F1 vs 87.22 for "Full" corpus on Mistral-7B.

## Foundational Learning

- **Log Parsing and Template Ambiguity**
  - Why needed here: EnrichLog addresses the failure mode where syntax-based parsers cluster both normal and anomalous logs into identical templates, losing discriminative variable information.
  - Quick check question: Given logs "machine check enable......0" (normal) and "machine check interrupt" (anomaly) both mapped to template "machine check <*>", why would a template-only classifier fail?

- **Retrieval-Augmented Generation (RAG)**
  - Why needed here: LLMs lack domain-specific log knowledge; RAG injects relevant historical context at inference time without retraining.
  - Quick check question: What is the difference between Ke (sample-specific enrichment knowledge) and Kh (historical samples), and which contributes more to accuracy gains?

- **Confidence-Based Cascading**
  - Why needed here: The two-step approach uses LLM confidence scores derived from output logits to decide whether expensive RAG processing is necessary.
  - Quick check question: Using Equation 5, how is confidence computed from logits, and what happens if confidence exceeds the threshold in Step 1 of the two-step pipeline?

## Architecture Onboarding

- **Component map**: Log Parser (Drain) -> Log Selector -> Enrichment LLM -> Vector Database -> Retrieval Model -> Generator LLM

- **Critical path**:
  1. **Offline**: Parse historical logs -> select representatives -> generate Kc -> generate Ke per template -> store Ke + Kh in vector DB
  2. **Online (one-step)**: Query log -> retrieve top-K relevant Ke/Kh -> LLM generates label with context
  3. **Online (two-step)**: Query log -> base LLM predicts -> if high-confidence normal: skip; else: retrieve Ke/Kh -> LLM refines prediction

- **Design tradeoffs**:
  - Parser choice: Drain (344 templates, 99.37 F1) vs Spell (659 templates, 97.23 F1) - fewer, higher-quality clusters improve enrichment
  - Enrichment model: Commercial (GPT-5 mini) vs local (Llama-8B) - stronger enrichment yields better Ke quality at higher cost
  - Quantization: INT4 provides 28-60% speedup with 0.3-2.0 F1 drop
  - One-step vs two-step: Two-step benefits larger models (Mistral-7B: 15% reach step 2); smaller models (Qwen-4B: 91% reach step 2) see less gain

- **Failure signatures**:
  - Zero F1 with certain baselines on specific datasets indicates retrieval returning irrelevant or misleading knowledge
  - Near-100% recall with near-zero precision in base models signals systematic bias toward "anomaly" without external context
  - Llama-1B achieving 0.0 F1 on BGL/Thunderbird with EnrichLog indicates context window limitations

- **First 3 experiments**:
  1. Reproduce baseline vs EnrichLog comparison on BGL (2,000-sample test set) with Mistral-7B - expect ~99.37 F1 to validate setup
  2. Ablate knowledge sources: Base only -> Base+Kh -> Base+Ke -> Base+Kh+Ke - expect Ke to provide larger gains than Kh alone
  3. Profile two-step efficiency: measure percentage of logs proceeding to Step 2 and total latency - expect Mistral-7B to filter ~85% of logs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can retrieval mechanisms be augmented with system-specific signals to distinguish anomalies accurately when a single knowledge base serves multiple heterogeneous systems?
- Basis in paper: [explicit] The authors state that "Detecting anomalies across systems remains a key challenge" and explicitly propose "Developing retrieval mechanisms that incorporate system-specific signals" as a direction for future work.
- Why unresolved: EnrichLog currently retrieves context based solely on log event similarity, ignoring the fact that identical logs may have different severity levels or implications in different systems.
- What evidence would resolve it: A retrieval framework that fuses log content with system metadata (e.g., architecture, service type), demonstrating improved precision in multi-system evaluations.

### Open Question 2
- Question: How can fixed in-domain knowledge be integrated to effectively classify completely unseen log entries where the current RAG approach retrieves irrelevant context?
- Basis in paper: [explicit] The discussion notes that "completely unseen logs may retrieve irrelevant knowledge" and concludes there is "still scope for incorporating fixed in-domain knowledge to enhance baseline accuracy."
- Why unresolved: The current reliance on vector similarity for retrieval fails when new log templates have no semantic overlap with the historical knowledge base.
- What evidence would resolve it: A hybrid architecture combining RAG with static rule-based or parametric domain knowledge that maintains high F1-scores on zero-shot log templates.

### Open Question 3
- Question: How does the propagation of hallucinated or incorrect reasoning in the sample-specific knowledge ($K_e$) affect the robustness of the final anomaly detection?
- Basis in paper: [inferred] The framework relies on a "Generator LLM" to create sample-specific enrichment; inferred from the variability in enrichment model performance shown in Table 2 and the lack of verification for the generated reasoning.
- Why unresolved: If the LLM generating the knowledge base produces plausible but incorrect reasoning, the RAG mechanism will retrieve and amplify these errors during detection.
- What evidence would resolve it: An ablation study introducing synthetic noise or incorrect reasoning into the knowledge base to measure the downstream detection model's error rate.

## Limitations
- Knowledge enrichment generation prompts are not disclosed, making exact reproduction difficult
- Generalizability to logs without clear corpus-level anomaly descriptions remains untested
- Two-step efficiency gains heavily depend on base LLM recall characteristics that may vary across domains

## Confidence
- **High Confidence**: The empirical results showing EnrichLog outperforming baselines across all four datasets (99.37% F1 on BGL, 100% on Thunderbird with Mistral-7B)
- **Medium Confidence**: The mechanism claims about knowledge enrichment resolving template ambiguity - supported by comparative results but not directly proven through controlled ablation
- **Low Confidence**: The efficiency claims regarding the two-step cascade - limited quantitative analysis of latency and resource usage across different model sizes

## Next Checks
1. **Ablation Study Replication**: Replicate the ablation study with Base only → Base+Kh → Base+Ke → Base+Kh+Ke on BGL dataset to verify that Ke provides the largest accuracy gains and to quantify the relative contribution of each knowledge source

2. **Cross-Domain Generalization**: Test EnrichLog on a dataset without clear corpus-level anomaly documentation (e.g., application logs or custom enterprise logs) to evaluate whether the knowledge enrichment approach generalizes beyond the studied system logs

3. **Retrieval Quality Analysis**: Measure retrieval precision@K for both Ke and Kh across different log templates, particularly for ambiguous templates, to quantify whether the claimed knowledge enrichment is actually improving the retrieved context quality