---
ver: rpa2
title: 'FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace'
arxiv_id: '2509.03890'
source_url: https://arxiv.org/abs/2509.03890
tags:
- agent
- user
- fama
- marketplace
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FaMA, an LLM-powered agentic assistant for
  Consumer-to-Consumer (C2C) marketplaces. The system addresses the complexity and
  friction users face when navigating traditional marketplace GUIs by offering a conversational
  entry point that automates key workflows for both buyers and sellers.
---

# FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace

## Quick Facts
- arXiv ID: 2509.03890
- Source URL: https://arxiv.org/abs/2509.03890
- Reference count: 16
- Primary result: 98% task success rate, up to 2x speedup over manual app use

## Executive Summary
This paper introduces FaMA, an LLM-powered agentic assistant for Consumer-to-Consumer (C2C) marketplaces. The system addresses the complexity and friction users face when navigating traditional marketplace GUIs by offering a conversational entry point that automates key workflows for both buyers and sellers. Using a ReAct-based LLM with tool calling, a scratchpad memory for multi-step tasks, and specialized tools for listing management, search, messaging, and knowledge retrieval, FaMA enables natural language interactions. Experiments show a 98% task success rate and up to 2x speedup in user interaction time compared to manual app use. This work presents the first comprehensive AI agent for C2C e-commerce that unifies conversational access and automation across the buyer and seller journey.

## Method Summary
FaMA uses Llama-4-Maverick-17B-128E-Instruct as its reasoning engine with ReAct prompting, operating in single-step interactive mode where each action requires user confirmation. The system maintains scratchpad memory (chronological Thought-Action-Observation triplets), ephemeral dialog history, and Listings Information Memory that pre-loads seller inventory. Tool interfaces include Listing Operation Tools, Inventory Search Tools, Messaging Tools, and RAG retrieval. Evaluation uses an LLM-based user simulator at temperature 1.0 on a synthetic dataset of 100 marketplace listings, measuring task success rate (completed within 5 steps) and optimality rate (completed in minimum steps).

## Key Results
- Achieved 98% task success rate across inventory search, listing renewal, and bulk message reply tasks
- Delivered up to 2x speedup in user interaction time compared to manual app use
- Maintained >84% task optimality rate, completing tasks in minimum required steps

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ReAct-based reasoning combined with single-step human confirmation enables safe, accurate task execution for high-stakes marketplace operations.
- Mechanism: The LLM generates explicit Thought-Action-Observation triplets using Chain-of-Thought prompting, but pauses after each action for user confirmation before execution. This prevents autonomous errors on state-changing operations (sending messages, modifying listings).
- Core assumption: Users will meaningfully review proposed actions, and the LLM's reasoning is sufficiently accurate that confirmations are not mere formalities.
- Evidence anchors:
  - [abstract]: "Using a ReAct-based LLM with tool calling, a scratchpad memory for multi-step tasks"
  - [section 3.1]: "In a key difference from the standard ReAct agent, where the thought-action-observation cycle runs autonomously until task completion, FaMA operates in a single-step interactive mode... many operations involve critical state changes to a user's account, making explicit user consent essential."
  - [corpus]: ToolACE-MT (arxiv 2508.12685) addresses multi-turn agentic interactions but does not specifically examine human-in-the-loop confirmation patterns; corpus evidence on this mechanism is weak.
- Break condition: Users habitually approve without reading; LLM consistently proposes plausible-but-wrong actions that pass casual review.

### Mechanism 2
- Claim: Scratchpad memory enables goal coherence across multi-turn conversations by providing explicit intermediate state.
- Mechanism: A chronological log of Thought-Action-Observation triplets is prepended to each new user input, re-contextualizing the LLM with its prior reasoning and actions. This replaces implicit context reliance with explicit state tracking.
- Core assumption: The token window can accommodate accumulated scratchpad content without degrading response quality, and the LLM correctly parses its own prior outputs.
- Evidence anchors:
  - [abstract]: "scratchpad memory for multi-step tasks"
  - [section 3.2]: "This historical log is prepended to the user's latest input before being passed to the LLM... enabling FaMA to seamlessly continue complex, multi-step dialogues, ensuring goal coherence without repeating work."
  - [corpus]: Scratchpad technique originates from Nye et al. 2021 (cited by paper); no direct corpus validation in marketplace-specific contexts.
- Break condition: Long tasks exceed context window; accumulated scratchpad noise (redundant or confusing entries) degrades reasoning quality.

### Mechanism 3
- Claim: Listing Information Memory enables natural language disambiguation of user inventory without requiring exact IDs.
- Mechanism: At session start, the agent retrieves all seller listing metadata (title, description, ID) and injects it into context. When users refer to items descriptively ("my Meta Quest 2"), the LLM matches against this structured data to resolve the correct listing ID.
- Core assumption: The user's natural language description is sufficiently distinctive among their listings, and listing metadata is accurate and current.
- Evidence anchors:
  - [section 3.2]: "FaMA utilizes a dedicated Listings Information Memory... When a seller refers to a listing during the chat, the LLM can find the listing that matches the user's description."
  - [section 4.1]: "The 100% success rate on the Renew Listing task also indicates that the agent can effectively distinguish the correct item from the 100 listings stored in the Listings Information Memory."
  - [corpus]: No direct corpus evidence on this specific disambiguation technique; related work (e.g., domain-aware embeddings for C2C search, arxiv 2512.21021) focuses on retrieval, not inventory resolution.
- Break condition: Users have many similar listings (e.g., "blue shirt" appears multiple times); descriptions are ambiguous or use non-standard terminology.

## Foundational Learning

- **ReAct Prompting Paradigm**:
  - Why needed here: FaMA's entire reasoning loop depends on interleaving Thought, Action, and Observation. Without understanding this pattern, the scratchpad and tool-calling flow will be opaque.
  - Quick check question: Can you trace one complete Thought-Action-Observation cycle for the request "Renew my expiring listings"?

- **Tool Calling / Function Calling**:
  - Why needed here: The agent's value proposition is executing real marketplace operations. You must understand how the LLM outputs structured tool invocations and how the system executes them.
  - Quick check question: Given user input "Show me used iPhone 13 under $200," what tool would be called and what parameters would be extracted?

- **Session-Based vs Persistent Memory Tradeoffs**:
  - Why needed here: FaMA intentionally uses ephemeral dialogue history for privacy but retains scratchpad within sessions. Understanding this distinction is critical for debugging state issues.
  - Quick check question: If a user returns after inactivity timeout, what context is preserved and what is lost?

## Architecture Onboarding

- **Component map**:
  Input Layer -> ASR module for voice transcription -> Reasoning Core -> Memory Layer -> Tool Layer -> Output

- **Critical path**:
  1. User input (text or voice → ASR)
  2. Context assembly: scratchpad history + dialog history + listings info (if seller) + system prompt
  3. LLM generates Thought and proposed Action
  4. Present action to user for confirmation
  5. On confirmation: execute tool call via marketplace API
  6. Observation returned → appended to scratchpad
  7. Response to user; loop continues if task incomplete

- **Design tradeoffs**:
  - Single-step confirmation vs autonomous execution: safer but higher friction
  - Ephemeral dialog history vs persistent memory: privacy-preserving but loses cross-session context
  - Full listing injection vs on-demand retrieval: faster disambiguation but consumes context tokens
  - RAG as optional tool vs always-on knowledge: reduces unnecessary retrieval but requires accurate intent detection

- **Failure signatures**:
  - Tool selection errors: LLM calls wrong tool for intent (e.g., search instead of listing update)
  - Parameter extraction failures: Missing required fields (price, listing ID)
  - Context overflow: Scratchpad + listings exceed token limit, causing truncation or degraded reasoning
  - Ambiguous references: Multiple listings match description; agent picks wrong one
  - Stale listings info: User sold item but session still has old data; renewal fails

- **First 3 experiments**:
  1. Replicate the automated evaluation pipeline with a user simulator on a synthetic dataset; verify 98% task success rate on search, renew, and bulk reply tasks.
  2. Conduct ablation on scratchpad: disable it and measure task success rate degradation on multi-step tasks (renew listing, bulk reply).
  3. Test listing disambiguation stress case: seed inventory with 10+ similar items (e.g., multiple "blue chairs") and measure resolution accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the high degree of homology between the user simulator and the agent inflate the reported task success metrics?
- Basis in paper: [inferred] Section 4.1 states that "both the user simulator and FaMA were powered by the same Llama-4-Maverick-17B-128E-Instruct model."
- Why unresolved: "Self-play" evaluation (using the same model for user and agent) may lack the ambiguity and variability of real human speech, potentially yielding an inflated 98% success rate that does not reflect performance with actual users.
- What evidence would resolve it: A comparative evaluation using human subjects or a diverse set of distinct proprietary models to simulate user queries.

### Open Question 2
- Question: Does the reported 2x speedup generalize to novice users, given that the timing study was conducted by the authors?
- Basis in paper: [inferred] Section 4.2 notes, "As experienced users of the Facebook Marketplace, we timed the process," introducing a confounding variable of author expertise.
- Why unresolved: Authors possess optimized workflows for both the app and the agent; average users may face higher learning curves with the agent or different efficiency bottlenecks not captured by expert timing.
- What evidence would resolve it: A randomized controlled trial (RCT) measuring the interaction times of non-author, novice users performing the same tasks.

### Open Question 3
- Question: How does the agent's performance degrade as the user's inventory size exceeds the LLM's context window?
- Basis in paper: [inferred] Section 3.2 describes injecting details for "all of the seller’s listings" into the prompt, while Section 4.1 only tests a synthetic dataset of 100 listings.
- Why unresolved: The architecture relies on fitting the entire inventory into the context. For power sellers with thousands of items, this context may truncate or cause the LLM to "lose" information, potentially breaking the listing resolution capability.
- What evidence would resolve it: Stress tests measuring listing identification accuracy and latency as inventory counts scale from 100 to 5,000+ items.

## Limitations
- Evaluation relies on synthetic data and LLM-based user simulator rather than real user testing
- Proprietary marketplace APIs prevent independent verification of tool implementations
- Context window constraints may limit scalability for sellers with extensive inventories

## Confidence

- **High Confidence**: The architectural components (ReAct reasoning, scratchpad memory, tool calling) are well-established patterns in the literature and their implementation details are clearly described.
- **Medium Confidence**: The 98% task success rate and 2x speedup metrics are plausible given the evaluation methodology, but require independent verification with real users and diverse marketplace scenarios.
- **Low Confidence**: The generalizability of results to different marketplace platforms, languages, and user demographics remains unknown due to the synthetic nature of the evaluation dataset.

## Next Checks

1. **Real User Testing**: Deploy FaMA with actual C2C marketplace users across diverse demographics and measure task completion rates, user satisfaction, and time savings compared to the paper's synthetic evaluation.
2. **Context Window Stress Test**: Systematically evaluate FaMA's performance with sellers having varying listing counts (10, 50, 100, 200+) to identify the exact context window limits and degradation points.
3. **Error Recovery Analysis**: Document and analyze failure cases where the agent makes incorrect tool calls or misidentifies listings, then measure how effectively the confirmation step catches and prevents these errors in practice.