---
ver: rpa2
title: Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders
arxiv_id: '2505.01134'
source_url: https://arxiv.org/abs/2505.01134
tags:
- modalities
- distributions
- consensus
- generative
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoDE (Consensus of Dependent Experts), a
  novel method for aggregating multimodal distributions in variational autoencoders
  (VAEs) that accounts for dependence between modalities. Unlike existing approaches
  like Product of Experts (PoE) and Mixture of Experts (MoE) that assume independence,
  CoDE leverages Bayesian inference through the experts' error of estimation to capture
  correlations between modalities.
---

# Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders

## Quick Facts
- **arXiv ID:** 2505.01134
- **Source URL:** https://arxiv.org/abs/2505.01134
- **Reference count:** 40
- **Primary result:** CoDE-VAE achieves better generative quality and log-likelihood than PoE and MoE baselines while avoiding sub-sampling artifacts

## Executive Summary
This paper introduces CoDE (Consensus of Dependent Experts), a novel method for aggregating multimodal distributions in variational autoencoders that accounts for dependence between modalities. Unlike existing approaches like Product of Experts (PoE) and Mixture of Experts (MoE) that assume independence, CoDE leverages Bayesian inference through the experts' error of estimation to capture correlations between modalities. The authors develop CoDE-VAE, a multimodal VAE that optimizes each Evidence Lower Bound (ELBO) term associated with different modality subsets by learning their contribution weights. This approach eliminates the need for sub-sampling techniques that harm performance in existing methods.

## Method Summary
CoDE-VAE implements a consensus mechanism for aggregating expert distributions that accounts for stochastic dependence between modalities. The method constructs a full covariance matrix for the error of estimation rather than assuming independence, allowing it to recover variance information that PoE methods typically underestimate. During training, the model evaluates all subsets of modalities (power set) rather than sub-sampling, computing a weighted ELBO where each subset's contribution is determined by its information content (via entropy maximization). The consensus distribution parameters are derived through Bayesian posterior inference, with the correlation parameter cross-validated rather than learned end-to-end.

## Key Results
- CoDE-VAE achieves superior log-likelihood estimation compared to PoE and MoE baselines on MNIST-SVHN-Text, PolyMNIST, and CUB datasets
- The method reduces the generative quality gap as the number of modalities increases, reaching unimodal VAE quality with 4-5 modalities
- CoDE-VAE shows classification accuracy comparable to or better than existing multimodal VAEs while maintaining better generative coherence
- Ablation studies confirm the benefits of modeling dependence between expert distributions and learning contribution weights for each ELBO term

## Why This Works (Mechanism)

### Mechanism 1: Bayesian Consensus via Error Covariance
Modeling the stochastic dependence between expert distributions via their estimation errors prevents the variance underestimation common in Product of Experts methods. Instead of assuming independence (diagonal covariance), CoDE constructs a full covariance matrix $\Sigma_k$ for the error of estimation. The consensus distribution $q(z|X_k)$ is derived as a Bayesian posterior $N(A^{-1}B, A^{-1})$, where the off-diagonal elements of $\Sigma_k$ (controlled by correlation $\rho$) modulate the influence of overlapping information between modalities.

### Mechanism 2: Learned ELBO Contribution via Entropy Maximization
Dynamically learning the weight $\pi_k$ for each subset's ELBO term improves optimization compared to static, equal weighting. The model introduces a weighted ELBO where weights $\pi_k$ are learned via entropy maximization. Subsets with lower uncertainty (smaller trace of $\Sigma_k$) or higher cardinality learn to contribute more to the gradient update.

### Mechanism 3: Avoidance of Sub-sampling Artifacts
Evaluating all subsets $X_k \in P(X)$ during training eliminates the generative quality gap caused by stochastic sub-sampling used in Mixture of Experts approaches. CoDE-VAE sums the ELBOs of all subset combinations rather than sampling a subset per batch, forcing the model to maintain high fidelity for every modality combination.

## Foundational Learning

- **Concept:** Product of Experts (PoE) vs. Mixture of Experts (MoE)
  - **Why needed here:** The paper positions itself as a direct solution to the limitations of these two standard aggregation methods (overconfident variances in PoE, sub-sampling artifacts in MoE).
  - **Quick check question:** How does multiplying densities (PoE) affect the variance of the resulting distribution compared to averaging them (MoE)?

- **Concept:** Bayesian Posterior Inference with Gaussian Likelihoods
  - **Why needed here:** The core contribution (Lemma 2) derives the consensus distribution by treating expert estimates as data observed from a Gaussian likelihood.
  - **Quick check question:** If you treat expert means $\mu$ as "data" with known covariance $\Sigma$, what is the posterior mean of the true parameter $\theta$ given a flat prior?

- **Concept:** The Powerset $P(X)$ in Multimodal Learning
  - **Why needed here:** The architecture explicitly iterates over the powerset of modalities to handle missing data scenarios without sub-sampling.
  - **Quick check question:** For 3 modalities, how many subsets (including the full set but excluding the empty set) must the model evaluate during training?

## Architecture Onboarding

- **Component map:**
  - $M$ unimodal encoders -> Covariance Builder -> Consensus Calculator -> ELBO Aggregator -> $M$ decoders
  - Encoder(s) output $\mu_i, \sigma_i^2$ for each modality
  - Covariance Builder constructs sparse block-diagonal matrix $\Sigma_k$ for a specific subset
  - Consensus Calculator implements Lemma 2 ($A^{-1}B$, $A^{-1}$) to compute parameters of $q(z|X_k)$
  - ELBO Aggregator weights reconstruction and KL terms using learned weights $\pi_k$
  - Decoder(s) reconstruct modalities from aggregated latent $z$

- **Critical path:**
  1. Encoding individual modalities into $\mu_i, \sigma_i^2$
  2. **Crucial Step:** Efficient inversion of $\Sigma_k$ for all subsets
  3. Computing the weighted sum of ELBOs

- **Design tradeoffs:**
  - **Exhaustive vs. Efficient:** The model computes ELBO for all subsets ($2^M - 1$ terms), improving robustness to missing modalities but limiting scalability compared to sub-sampling methods
  - **Fixed $\rho$:** The correlation parameter is cross-validated rather than learned end-to-end, which may require re-tuning for new datasets

- **Failure signatures:**
  - **Singular Matrix:** If $\sigma_i^2$ collapses to zero or $\rho=1$ for identical experts, $\Sigma_k$ may become non-invertible
  - **Mode Collapse:** If $\pi_k$ collapses to favor only the full-set subset, the model effectively ignores partial missing-modal scenarios

- **First 3 experiments:**
  1. **Bimodal Correlation Check:** Train on MNIST-SVHN with $\rho \in [0, 0.9]$ to verify that $\rho > 0$ reduces variance underestimation error compared to PoE baseline
  2. **Modality Dropout Robustness:** Ablate modality subsets at test time and measure generative coherence
  3. **Scaling Test:** Profile memory and time usage with $M=4$ vs $M=5$ to identify breaking point of $O(2^M)$ complexity

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Computational cost scales as $O(2^M)$ due to exhaustive subset evaluation, restricting practical application to relatively small numbers of modalities (M â‰¤ 5-6)
- Assumption of Gaussian error distributions may not hold for all modality types, particularly discrete or highly non-Gaussian data
- Fixed correlation parameter $\rho$ cross-validated rather than learned end-to-end could limit adaptability to dataset-specific dependencies

## Confidence
- **High confidence**: Claims about improved generative quality compared to PoE and MoE baselines, and avoiding sub-sampling artifacts
- **Medium confidence**: Claims about Bayesian consensus mechanism and learned ELBO weighting improving optimization
- **Low confidence**: Generalization to very high-dimensional modalities or >10 total modalities, and robustness to extreme missingness patterns

## Next Checks
1. **Scaling Experiment**: Systematically measure training time, memory usage, and test-time performance as M increases from 3 to 8 modalities on PolyMNIST
2. **Robustness to Noisy Modalities**: Introduce progressively corrupted versions of one modality and measure how CoDE-VAE's learned weights and consensus quality degrade compared to PoE/MoE baselines
3. **Correlation Parameter Sensitivity**: Re-run MNIST-SVHN experiment with $\rho$ values spanning [0, 0.95] in fine increments to map sensitivity of Hellinger distance and FID to this hyperparameter