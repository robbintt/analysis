---
ver: rpa2
title: 'The Warmup Dilemma: How Learning Rate Strategies Impact Speech-to-Text Model
  Convergence'
arxiv_id: '2505.23420'
source_url: https://arxiv.org/abs/2505.23420
tags:
- warmup
- training
- exponential
- convergence
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the impact of learning rate warmup strategies
  on the convergence of large-scale speech-to-text models. While the double linear
  warmup introduced by OWSM helped training converge, its effectiveness had not been
  compared with other policies nor its impact on final model quality been investigated.
---

# The Warmup Dilemma: How Learning Rate Strategies Impact Speech-to-Text Model Convergence

## Quick Facts
- **arXiv ID:** 2505.23420
- **Source URL:** https://arxiv.org/abs/2505.23420
- **Reference count:** 13
- **Primary result:** Large-scale S2T training with complex Transformer variants demands sub-exponential warmup to avoid divergence, and warmup phase learning rate does not impact final model quality

## Executive Summary
This paper investigates how different learning rate warmup strategies affect the convergence of large-scale speech-to-text models. The authors train a 878M-parameter Conformer model on 150k hours of speech data, comparing piecewise-linear, polynomial, and exponential warmup policies. They discover that complex Transformer variants like Conformer and Branchformer require sub-exponential warmup schedules to prevent training divergence. While higher learning rates during the warmup phase accelerate early convergence, they find no improvement in final model performance, challenging assumptions about warmup strategy importance.

## Method Summary
The authors conduct systematic experiments training a large-scale Conformer model (878M parameters) on a 150k-hour speech corpus. They compare three learning rate warmup strategies: piecewise-linear (double linear warmup from OWSM), polynomial, and exponential. The study examines how different warmup policies impact training stability, convergence speed, and final model quality. Experiments systematically vary warmup duration and peak learning rate to understand their effects on training dynamics and model performance.

## Key Results
- Complex Transformer variants (Conformer, Branchformer) require sub-exponential warmup to avoid training divergence in large-scale settings
- Higher learning rates during the warmup phase accelerate early convergence but do not improve final model quality
- The double linear warmup strategy introduced by OWSM effectively enables convergence, but its superiority over other policies varies by context

## Why This Works (Mechanism)
The effectiveness of sub-exponential warmup policies stems from their ability to provide stable initial training dynamics for complex Transformer architectures. Large-scale models with many parameters are particularly sensitive to initial learning rate choices, as aggressive exponential warmup can cause parameter updates that destabilize the training process. Sub-exponential schedules allow for gradual adaptation of model parameters to the optimization landscape, preventing divergence while maintaining sufficient learning signal during the critical early training phase.

## Foundational Learning
- **Learning rate warmup strategies** - Different mathematical formulations (linear, polynomial, exponential) for gradually increasing learning rate from small initial values to peak values during early training phases
  - Why needed: Prevents training instability by avoiding large gradient updates when parameters are randomly initialized
  - Quick check: Verify that warmup schedule is properly normalized to reach peak learning rate at the correct iteration

- **Conformer architecture** - Hybrid model combining self-attention and convolution layers for speech processing
  - Why needed: Represents state-of-the-art in speech-to-text modeling, making warmup strategy investigation practically relevant
  - Quick check: Confirm model depth and width match experimental specifications

- **Large-scale training dynamics** - Behavior of optimization algorithms when training models on massive datasets with many parameters
  - Why needed: Training stability and convergence characteristics change significantly at scale compared to smaller models
  - Quick check: Monitor training loss curves for signs of divergence or instability

## Architecture Onboarding

**Component Map:** Dataset -> Preprocessing -> Model (Conformer) -> Warmup Policy -> Optimizer -> Training Loop -> Evaluation

**Critical Path:** The interaction between warmup policy selection and optimizer state initialization represents the critical path for training stability. The warmup strategy directly influences the initial parameter updates, which cascade through the entire training process and determine whether the model converges successfully.

**Design Tradeoffs:** The primary tradeoff involves balancing early training stability against convergence speed. More aggressive warmup policies (exponential) may converge faster but risk divergence, while conservative policies (linear) ensure stability but potentially require longer training times. The choice depends on the specific model architecture and dataset characteristics.

**Failure Signatures:** Training divergence manifests as exploding gradients, NaN loss values, or monotonically increasing training loss after initially decreasing. These failures typically occur within the first few thousand iterations when using inappropriate warmup strategies for complex Transformer architectures.

**First Experiments:**
1. Implement piecewise-linear warmup and verify baseline convergence on small dataset
2. Test polynomial warmup with varying exponents to identify stability threshold
3. Compare training dynamics of exponential vs. sub-exponential warmup on medium-sized model

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Experimental scope limited to Conformer architectures on single large-scale speech corpus (150k hours)
- Focus on convergence dynamics without investigating long-term stability or robustness implications
- Evaluation criteria centered on standard performance metrics without exploring model calibration or generalization effects
- No investigation of interaction between warmup strategies and other training hyperparameters

## Confidence

**High confidence:** Sub-exponential warmup prevents divergence in large-scale Conformer training
**Medium confidence:** Warmup phase learning rate does not impact final model quality (single-dataset experiments)
**Medium confidence:** Generalizability of warmup policy recommendations to other complex Transformer variants

## Next Checks

1. Replicate experiments across diverse speech datasets (varying in size, domain, and acoustic conditions) to verify robustness of warmup policy recommendations
2. Test the identified optimal warmup strategies on alternative S2T architectures (e.g., wav2vec 2.0, HuBERT, or RNN-T models) to establish broader applicability
3. Conduct ablation studies examining the interaction between warmup strategies and other critical training hyperparameters (weight decay, gradient clipping, batch size) to identify potential confounding effects