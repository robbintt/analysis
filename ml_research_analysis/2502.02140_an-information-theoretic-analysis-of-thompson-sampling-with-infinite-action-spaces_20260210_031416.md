---
ver: rpa2
title: An Information-Theoretic Analysis of Thompson Sampling with Infinite Action
  Spaces
arxiv_id: '2502.02140'
source_url: https://arxiv.org/abs/2502.02140
tags:
- action
- regret
- sampling
- thompson
- bandit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends the information-theoretic analysis of Thompson
  Sampling (TS) to bandit problems with infinite or continuous action and parameter
  spaces. Building on Russo and Van Roy's framework, the authors adapt the rate-distortion
  approach of Dong and Van Roy to handle continuous settings.
---

# An Information-Theoretic Analysis of Thompson Sampling with Infinite Action Spaces

## Quick Facts
- arXiv ID: 2502.02140
- Source URL: https://arxiv.org/abs/2502.02140
- Reference count: 17
- Extends rate-distortion analysis of Thompson Sampling to infinite action spaces, recovering O(d√T log T) regret for linear bandits

## Executive Summary
This paper extends the information-theoretic analysis of Thompson Sampling to bandit problems with infinite or continuous action and parameter spaces. Building on Russo and Van Roy's framework, the authors adapt the rate-distortion approach of Dong and Van Roy to handle continuous settings. The key innovation is constructing a one-step compressed Thompson Sampling that depends on a quantized version of the optimal action rather than the parameter, allowing the analysis to work with infinite action spaces. For Lipschitz continuous reward functions, the regret bound scales with the covering number of the action space, measuring its complexity. Applied to d-dimensional linear bandits with bounded actions, the analysis recovers the near-optimal rate of O(d√T log T), improving constants inside the logarithm compared to prior work.

## Method Summary
The paper extends Thompson Sampling to infinite action spaces by adapting the rate-distortion framework. Standard TS samples parameters from the posterior and plays the optimal action. The authors construct a one-step compressed version that depends on a quantized version of the optimal action, using a partition of the action space where reward variation within each partition is bounded by ε. Proposition 1 establishes the existence of a sampling function φ_t that simultaneously bounds regret and controls information gain. For Lipschitz continuous rewards, the regret bound scales with the covering number N(A,ρ,ε), which measures the complexity of the action space. In the d-dimensional linear bandit case with bounded actions, this recovers O(d√T log T) regret.

## Key Results
- Extends rate-distortion analysis of Thompson Sampling to infinite action spaces
- For Lipschitz rewards, achieves regret bound √(Γ̃T · log(N(A,ρ,ε))) + LεT
- Applied to d-dimensional linear bandits, recovers O(d√T log T) regret with improved constants

## Why This Works (Mechanism)
The paper extends Thompson Sampling analysis to infinite action spaces by using a rate-distortion approach that quantizes the optimal action rather than the parameter. This construction allows the analysis to handle continuous settings while maintaining the information-theoretic guarantees. The key insight is that by constructing a partition of the action space where reward variation within each partition is bounded, the regret can be controlled while still allowing for efficient sampling. Proposition 1 proves the existence of a compressed sampling function that achieves both low regret and low information gain, enabling the information-theoretic bounds.

## Foundational Learning

**Thompson Sampling**: Bayesian approach to bandit problems where actions are sampled from posterior distributions; needed to establish baseline algorithm; quick check: verify posterior sampling works for continuous parameters.

**Rate-distortion theory**: Framework for analyzing the trade-off between compression and distortion; needed to extend TS analysis to infinite spaces; quick check: understand how quantization affects regret bounds.

**Covering numbers**: Measure of complexity for metric spaces; needed to quantify the difficulty of infinite action spaces; quick check: compute N(A,ρ,ε) for simple action space geometries.

**Information gain**: Measures reduction in uncertainty about parameters; needed to bound regret via information-theoretic arguments; quick check: verify H(Θ_t | A_1,...,A_t) decreases appropriately.

## Architecture Onboarding

**Component map**: TS (Algorithm 1) -> Partition construction -> Sampling function φ_t -> Regret bound

**Critical path**: Construct partition {A_k} of action space → Define quantized optimal action → Apply Proposition 1 to construct φ_t → Bound regret via information-theoretic analysis

**Design tradeoffs**: Using quantized optimal action vs. quantized parameter; balancing partition granularity (ε) against regret bounds; handling non-constructive existence proofs vs. practical implementation

**Failure signatures**: Posterior becomes degenerate in continuous spaces; regret doesn't scale as expected for small T; exponential growth of covering numbers with dimension

**3 first experiments**: 1) Implement standard TS for linear bandit with continuous actions; 2) Compute covering numbers for unit ball action space; 3) Estimate empirical regret vs. theoretical bound

## Open Questions the Paper Calls Out
None

## Limitations
- Proposition 1 is non-constructive, proving existence without providing implementation details
- Theoretical results are asymptotic and may not capture finite-time behavior
- Covering number dependence may be prohibitive in high-dimensional action spaces

## Confidence
**Main theoretical claims**: High - rigorous information-theoretic arguments with solid foundation in prior work
**Practical applicability**: Medium - lack of empirical validation and constructive algorithms limits practical implementation

## Next Checks
1. Implement and test the theoretical bounds on synthetic linear bandit problems with varying dimensions d and time horizons T to empirically verify the O(d√T log T) scaling
2. Compare empirical regret against the theoretical bound √(Γ̃T · log(N(A,ρ,ε))) + LεT for different action space geometries and covering constructions
3. Test sensitivity to the choice of ε in the partition construction and its impact on the regret-information trade-off