---
ver: rpa2
title: 'GLEAN: Generalized Category Discovery with Diverse and Quality-Enhanced LLM
  Feedback'
arxiv_id: '2502.18414'
source_url: https://arxiv.org/abs/2502.18414
tags:
- category
- feedback
- data
- performance
- categories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'GLEAN introduces a unified framework for generalized category
  discovery that actively learns from diverse and quality-enhanced LLM feedback. The
  method addresses key challenges in GCD by leveraging three types of LLM feedback:
  (1) improving instance-level contrastive features through similar instance selection,
  (2) generating interpretable category descriptions, and (3) aligning uncertain instances
  with LLM-selected category descriptions.'
---

# GLEAN: Generalized Category Discovery with Diverse and Quality-Enhanced LLM Feedback

## Quick Facts
- arXiv ID: 2502.18414
- Source URL: https://arxiv.org/abs/2502.18414
- Authors: Henry Peng Zou; Siffi Singh; Yi Nian; Jianfeng He; Jason Cai; Saab Mansour; Hang Su
- Reference count: 40
- Primary result: Outperforms state-of-the-art GCD models across diverse datasets, metrics, and supervision settings

## Executive Summary
GLEAN introduces a unified framework for generalized category discovery that actively learns from diverse and quality-enhanced LLM feedback. The method addresses key challenges in GCD by leveraging three types of LLM feedback: improving instance-level contrastive features through similar instance selection, generating interpretable category descriptions, and aligning uncertain instances with LLM-selected category descriptions. Extensive experiments show GLEAN outperforms state-of-the-art models across diverse datasets, metrics, and supervision settings. On BANKING with 25% known category ratio, GLEAN achieves 76.98% ACC, 66.00% ARI, and 85.62% NMI, significantly surpassing baselines. The framework demonstrates robustness across different known category ratios and datasets, with particular effectiveness on challenging domains.

## Method Summary
GLEAN employs a BERT-base-uncased encoder with a projection head to extract 128-dimensional features from text data. The method uses K-Means clustering with Student's t-distribution to compute soft assignments and identify high-entropy ambiguous samples. Three LLM feedback mechanisms are employed: similar instance selection via contrastive learning, category characterization for interpretable descriptions, and pseudo-category selection for alignment. Quality enhancement includes in-context demonstrations and confidence-based filtering of LLM responses. The training objective combines cross-entropy loss, neighborhood contrastive loss, and alignment loss with a tunable weight λ. The framework iterates through five cycles of ambiguous data mining and LLM feedback acquisition.

## Key Results
- On BANKING with 25% known category ratio, GLEAN achieves 76.98% ACC, 66.00% ARI, and 85.62% NMI
- Each feedback mechanism contributes positively: removing Cluster-Instance feedback drops ACC by 3.23%, removing Instance-Instance drops it by 2.33%
- Quality enhancement pipeline improves similar instance selection accuracy from 0.423 to 0.530 and category selection from 0.517 to 0.859
- GLEAN outperforms state-of-the-art models across diverse datasets and supervision settings

## Why This Works (Mechanism)

### Mechanism 1: Entropy-Based Ambiguous Data Mining + LLM-Guided Contrastive Learning
Targeting high-uncertainty instances for LLM feedback provides higher signal-to-noise improvement than random sampling. Compute entropy from soft cluster assignments via Student's t-distribution, select top-v highest entropy samples, query LLM for similar instances among candidates from nearest clusters, and use LLM-selected positive in neighborhood contrastive loss. Core assumption: LLM semantic similarity judgments on ambiguous cases transfer to better embedding space structure. Break condition: When LLM feedback accuracy approaches random baseline (Table 3 shows naive LLM at 0.487 vs random 0.056).

### Mechanism 2: Cluster-Instance Semantic Alignment via Category Descriptions
Aligning instance embeddings with semantically-rich category descriptions bridges embedding space to label space more effectively than instance-instance relationships alone. Select top-k samples nearest to each K-Means centroid, LLM generates category name+description, for each ambiguous instance LLM selects most similar category from candidates, and contrastive loss aligns instance embedding to selected category embedding. Core assumption: LLM-generated category descriptions capture meaningful semantic structure correlating with ground-truth categories. Break condition: When category descriptions are noisy or overlapping; Table 13 shows gpt-4 with 100 representatives achieves only 0.61 SeMatching score.

### Mechanism 3: Quality Enhancement Pipeline (In-Context Demonstrations + Confidence Filtering)
Naive LLM prompting yields insufficient feedback quality; in-context demonstrations and confidence-based filtering substantially improve reliability. Include demonstrations from known categories in prompt, request LLM confidence output, and filter low-confidence responses before using in training. Core assumption: LLM confidence correlates with feedback correctness. Break condition: When filtering removes too many samples or when demonstrations introduce domain mismatch.

## Foundational Learning

- Concept: Contrastive Learning (SupCon, SimCLR-style neighborhood contrastive)
  - Why needed here: Core representation learning method; GLEAN builds on neighborhood contrastive loss (Eq. 4)
  - Quick check question: Can you explain why pulling positive pairs closer while pushing all in-batch negatives apart creates cluster-friendly embeddings?

- Concept: Clustering Evaluation Metrics (ACC, ARI, NMI)
  - Why needed here: GCD evaluation requires understanding what each metric captures—ACC measures cluster-to-label alignment, ARI captures pairwise consistency, NMI measures mutual information
  - Quick check question: Why is ACC insufficient alone, and what does ARI add for evaluating clustering quality?

- Concept: Active Learning (uncertainty sampling)
  - Why needed here: GLEAN uses entropy-based selection which is an uncertainty-based active learning strategy
  - Quick check question: What are the tradeoffs between uncertainty-based and diversity-based sample selection for LLM query budgets?

## Architecture Onboarding

- Component map:
  Text Encoder (BERT-base-uncased) -> Features via [CLS] token (768-d) -> Projection Head (2-layer MLP) -> Contrastive Features (128-d) -> K-Means Clustering -> Soft Assignments via Student's t-distribution -> Entropy Calculation -> Ambiguous Data Mining -> Query Set Q (top-v by entropy) -> LLM Interface -> Three feedback types: (1) Similar Instance Selection, (2) Category Characterization, (3) Pseudo Category Selection -> Training: L = L_ce + L_ncl + λL_align

- Critical path:
  1. Pre-training on all data with CE + MLM losses
  2. Feature extraction -> K-Means clustering
  3. Entropy-based ambiguous data selection (top 500 samples)
  4. LLM feedback acquisition for all three types
  5. Joint training with combined loss
  6. Update query set every 5 epochs, repeat 5 times total

- Design tradeoffs:
  - Query sample count (v=500): More queries improve performance but saturate on challenging datasets (Figure 4)
  - Alignment weight (λ=0.05–0.1): λ=1.0 causes sharp ACC drop (Table 9: 89.64->82.49 on CLINC)
  - Representatives for category characterization (10): More improves coverage but may reduce semantic matching coherence
  - LLM choice: gpt-4o-mini offers best cost-performance balance ($0.15/$0.6 per 1M tokens, Table 5)

- Failure signatures:
  - Performance saturates with more queries -> dataset difficulty or LLM overwhelmed by candidate options
  - Sharp drop with high λ -> overfitting to LLM descriptions at expense of data-driven features
  - Category characterization coverage <50% -> insufficient representatives or poor sampling strategy (Table 11: random sampling achieves only 0.19–0.26 coverage vs 0.47–0.65 for nearest-to-center)

- First 3 experiments:
  1. Baseline reproduction: Run GLEAN with default hyperparameters on BANKING with 25% KCR, verify ~77% ACC matches reported results
  2. Ablation by feedback type: Remove Cluster-Instance feedback to quantify its contribution (expect ~3% ACC drop per Table 4)
  3. LLM cost-performance tradeoff: Compare gpt-4o-mini vs DeepSeek-V3 on same dataset split to validate open-source viability (Table 5)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can GLEAN be effectively adapted for vision and multimodal generalized category discovery using Multimodal LLMs?
- **Basis in paper:** [explicit] The authors state in the Limitations section, "In the future, we plan to extend it to vision and multimodal domains, exploring learning from multimodal large language models."
- **Why unresolved:** The current framework and experiments are restricted to textual data, utilizing text encoders and text-based LLM prompts.
- **What evidence would resolve it:** Successful application of the framework to image or video benchmarks (e.g., CIFAR, ImageNet) using vision-language models to generate category descriptions and select similar visual instances.

### Open Question 2
- **Question:** How robust is GLEAN when the total number of categories (K) is unknown or misestimated?
- **Basis in paper:** [inferred] Section 3.1 states, "The total number of categories K is regarded as a known prior," which assumes perfect knowledge of the cluster count.
- **Why unresolved:** Real-world open-world scenarios rarely provide the exact number of novel categories; incorrect K values could invalidate the category characterization and alignment steps.
- **What evidence would resolve it:** Sensitivity analysis showing performance degradation when K is over- or under-estimated by various margins, or an extension that dynamically estimates K.

### Open Question 3
- **Question:** To what extent does confidently incorrect LLM feedback (hallucinations) propagate errors into the contrastive learning process?
- **Basis in paper:** [inferred] The method relies on filtering and confidence scores (Section 5.1), but assumes high-confidence LLM outputs are correct for alignment.
- **Why unresolved:** If the LLM confidently hallucinates a category description or selects a dissimilar instance, the contrastive loss may reinforce incorrect embeddings.
- **What evidence would resolve it:** Experiments injecting synthetic noise into the LLM feedback loop to measure the model's resilience to confident but false supervision signals.

## Limitations
- Core uncertainty about LLM feedback reliability due to variable calibration across models and domains
- Generalizability concerns as framework effectiveness on non-text domains remains untested
- Resource intensity requiring multiple LLM API queries per training cycle, making it computationally expensive

## Confidence

**High Confidence Claims:**
- GLEAN outperforms state-of-the-art GCD models across multiple datasets and metrics
- Quality enhancement pipeline substantially improves LLM feedback accuracy
- Each of the three feedback mechanisms contributes positively to overall performance

**Medium Confidence Claims:**
- Entropy-based ambiguous data mining selects higher-value samples than random sampling
- Category characterization improves clustering through semantic alignment
- The 500-query sample size provides optimal performance-cost tradeoff

**Low Confidence Claims:**
- Open-source LLM alternatives match or exceed commercial models
- The method generalizes well to unseen domain types
- The quality enhancement approach works across diverse LLM models

## Next Checks
1. Cross-Domain Robustness Test: Apply GLEAN to non-text GCD tasks (e.g., image classification with known/unknown categories) to validate framework generalizability beyond text domains.
2. LLM Model Dependency Analysis: Systematically vary LLM models (gpt-4, Claude, open-source alternatives) and quantify performance degradation to establish framework robustness against LLM choice.
3. Budget Sensitivity Analysis: Conduct experiments varying LLM query budgets (100, 250, 500, 1000 samples) across multiple datasets to establish precise performance-cost tradeoffs and identify saturation points.