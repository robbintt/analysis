---
ver: rpa2
title: Linear Bandits with Non-i.i.d. Noise
arxiv_id: '2505.20017'
source_url: https://arxiv.org/abs/2505.20017
tags:
- regret
- noise
- mixing
- dence
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the linear stochastic bandit problem with non-i.i.d.
  observation noise that satisfies a mixing sub-Gaussianity condition.
---

# Linear Bandits with Non-i.i.d. Noise

## Quick Facts
- arXiv ID: 2505.20017
- Source URL: https://arxiv.org/abs/2505.20017
- Reference count: 32
- Primary result: UCB algorithm (Mixing-LinUCB) with regret bounds that recover standard rates up to mixing time $\tau$ for geometrically mixing noise, and match standard rates for algebraically mixing noise as mixing rate increases

## Executive Summary
This paper addresses the linear stochastic bandit problem with non-i.i.d. observation noise satisfying mixing sub-Gaussianity conditions. The authors develop a novel confidence sequence construction using delayed feedback to handle dependencies in the noise, leading to a UCB algorithm (Mixing-LinUCB) that introduces delays to mitigate overfitting to recent correlated observations. The theoretical framework provides regret bounds expressed in terms of the decay rate of mixing coefficients, showing that standard bandit rates can be recovered up to factors depending on the mixing time.

## Method Summary
The authors propose a UCB algorithm that handles non-i.i.d. noise by introducing delayed feedback mechanisms. The key innovation is a confidence sequence construction that accounts for mixing dependencies in the observation noise, building on the online-to-confidence-sets framework from Abélès et al. (2025). The algorithm uses delayed observations to avoid overfitting to recent correlated data points, with the delay mechanism specifically designed to work with both geometric and algebraic mixing rates. The theoretical analysis shows that the regret bounds depend on the mixing coefficients' decay rates, with geometric mixing yielding $O(\tau)$ factors and algebraic mixing recovering standard rates as the mixing rate increases.

## Key Results
- For geometrically mixing noise with rate $\phi_d = Ce^{-d/\tau}$, regret is $O(\tau p \sqrt{T} (\log T)^{3/2} + \tau \log T \sqrt{pT \log T})$
- For algebraically mixing noise with rate $\phi_d = Cd^{-r}$ where $r>1$, regret is $O(CBT^{1/(1+r)} + CT^{(3+r)/(2(1+r))})$
- Both regret bounds recover standard bandit rates (up to logarithmic factors) as mixing rates improve
- The mixing time $\tau$ appears as a multiplicative factor in the regret bound for geometric mixing

## Why This Works (Mechanism)
The paper leverages the mixing property of the noise process to construct valid confidence sequences despite dependencies. By introducing delays in the feedback, the algorithm effectively decorrelates recent observations, allowing the use of concentration inequalities that would otherwise require independence. The mixing assumption ensures that observations become approximately independent after a certain time lag, which the delay mechanism exploits to maintain statistical validity while adapting to the dependent structure of the noise.

## Foundational Learning

**Mixing Conditions**: Mathematical formalization of how quickly dependencies decay in time series data
*Why needed*: Provides the theoretical foundation for handling non-i.i.d. noise
*Quick check*: Verify $\phi_d \to 0$ as $d \to \infty$ for proposed mixing rates

**Confidence Sequences**: Time-uniform concentration bounds that hold simultaneously over all time periods
*Why needed*: Essential for bandit algorithms that need to maintain uncertainty quantification throughout execution
*Quick check*: Confirm coverage probability remains valid under mixing assumptions

**Delayed Feedback**: Technique where observations are not immediately incorporated into the algorithm's state
*Why needed*: Allows decorrelation of dependent observations to apply concentration bounds
*Quick check*: Verify delay length scales appropriately with mixing coefficients

## Architecture Onboarding

Component map: Mixing Process -> Delayed Observations -> Confidence Sequence Construction -> UCB Selection -> Arm Pulls -> Observations

Critical path: Arm selection requires current confidence bounds, which depend on delayed observations and mixing parameter estimates. The mixing parameter estimation must be sufficiently accurate for the confidence sequence construction to be valid.

Design tradeoffs: Longer delays provide better decorrelation but reduce adaptivity and increase computational overhead. The choice of mixing rate model (geometric vs algebraic) affects both regret bounds and practical performance. Balancing delay length against mixing time is crucial for optimal performance.

Failure signatures: If mixing assumptions are violated, confidence bounds may become invalid leading to over-exploration. Incorrect mixing rate estimation can cause suboptimal delay choices, either excessive delays (reduced performance) or insufficient delays (invalid confidence bounds).

First experiments:
1. Validate regret bounds on synthetic data with known geometric mixing properties
2. Test algorithm sensitivity to mis-specified mixing parameters
3. Compare performance against standard LinUCB on data with controlled dependencies

## Open Questions the Paper Calls Out
None

## Limitations
- Mixing conditions may be too restrictive for many real-world applications with complex noise dependencies
- Delay mechanisms could be computationally expensive and reduce algorithm adaptivity
- Lack of empirical validation makes practical effectiveness uncertain
- Mixing parameters are typically unknown in practice and difficult to estimate

## Confidence
Theoretical regret bounds under mixing assumptions: High
Practical effectiveness of delay mechanism: Medium
Applicability to real-world scenarios: Low

## Next Checks
1. Empirical validation on synthetic datasets with controlled mixing properties to verify theoretical regret bounds
2. Testing the algorithm on real-world sequential decision-making problems where noise dependencies are known to exist
3. Investigation of the algorithm's sensitivity to mis-specified mixing parameters in practical settings