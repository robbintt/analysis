---
ver: rpa2
title: Bayesian Joint Additive Factor Models for Multiview Learning
arxiv_id: '2406.00778'
source_url: https://arxiv.org/abs/2406.00778
tags:
- factor
- factors
- data
- bayesian
- shared
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces two Bayesian factor regression models for
  integrating multiview data to improve prediction of outcomes. The baseline Joint
  Factor Regression (JFR) uses a single set of latent factors across all views, while
  Joint Additive Factor Regression (JAFAR) decomposes variation into shared and view-specific
  components.
---

# Bayesian Joint Additive Factor Models for Multiview Learning

## Quick Facts
- arXiv ID: 2406.00778
- Source URL: https://arxiv.org/abs/2406.00778
- Reference count: 40
- Primary result: JAFAR achieves similar predictive accuracy to JFR with ~55% faster computation and explicit separation of shared and view-specific latent factors

## Executive Summary
This paper introduces two Bayesian factor regression models for integrating multiview data to improve prediction of outcomes. The baseline Joint Factor Regression (JFR) uses a single set of latent factors across all views, while Joint Additive Factor Regression (JAFAR) decomposes variation into shared and view-specific components. To ensure identifiability of the shared components in JAFAR, the authors develop dependent cumulative shrinkage process (D-CUSP) priors that adaptively learn the number of factors and prevent misallocation of view-specific factors to shared ones. Both methods outperform state-of-the-art competitors in predicting time-to-labor onset from immunome, metabolome, and proteome data.

## Method Summary
The paper proposes two Bayesian factor regression models: JFR uses a single latent factor set with independent CUSP priors, while JAFAR explicitly separates shared factors (ηi) from view-specific factors (ϕmi) using dependent CUSP (D-CUSP) priors. The D-CUSP includes an adaptation step that drops factor columns active in fewer than two views to ensure identifiability. For extreme large-p-small-n scenarios, tempered CUSP updates control rank overestimation. The models are fit via Gibbs sampling with post-processing using Multiview Varimax and MatchAlign to resolve rotational ambiguity. Copula extensions enable non-Gaussian data modeling.

## Key Results
- JAFAR achieves similar predictive accuracy to JFR but with ~55% faster computation through explicit separation of shared and view-specific factors
- D-CUSP priors correctly identify shared factors while NAIVE and FULL-D alternatives misallocate view-specific factors to the shared component
- Both methods outperform existing competitors in predicting time-to-labor onset from multiview omics data (immunome, metabolome, proteome)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: JAFAR achieves similar predictive accuracy to JFR with ~55% faster computation by explicitly separating shared and view-specific latent factors.
- Mechanism: The additive decomposition (ηi for shared, ϕmi for view-specific) allows joint sampling of loadings at cost O(Σpm·(K+Km)³) instead of O(Σpm·(K+ΣKm)³), exploiting structured sparsity in the precision matrix. The cached precision matrix further reduces factor sampling from O(n·K³) to O(K³ + n·K²).
- Core assumption: The data-generating process contains separable shared and view-specific latent factors; misspecification here would reduce gains.
- Evidence anchors:
  - [abstract] "JAFAR achieves similar accuracy to JFR but with 55% faster computation and greater interpretability through explicit separation of shared and view-specific factors."
  - [section 2.3, page 6] "Let us assume again that the overall rank in JFR is equal to K+ΣKm from JAFAR... joint updates can be performed at a total cost O(Σpm·(K+Km)³) in JAFAR."
  - [corpus] Weak direct corpus support for computational efficiency claims in factor models; neighboring papers focus on representation learning rather than computational optimization.
- Break condition: If most variation is truly shared across views with minimal view-specific signal, the overhead of additive decomposition may not justify its cost; if n >> p, matrix inversion costs dominate differently.

### Mechanism 2
- Claim: The D-CUSP prior ensures correct separation of shared and view-specific factors by assigning zero prior probability to configurations where nominally shared factors are active in fewer than two views.
- Mechanism: D-CUSP induces dependence across views through the adaptation step, which drops columns where Σm 1(ζmh > h) < 2. This prevents view-specific factors from being misallocated to the shared component (Λ), which would inflate K and harm interpretability. NAIVE and FULL-D alternatives either misallocate factors or overestimate shared rank.
- Core assumption: The true data structure has genuinely shared factors affecting ≥2 views; the spike variance (τ²∞ = 0.005) is small enough to distinguish inactive from active loadings.
- Evidence anchors:
  - [abstract] "To ensure identifiability of the shared components in JAFAR, the authors develop dependent cumulative shrinkage process (D-CUSP) priors that adaptively learn the number of factors and prevent misallocation of view-specific factors to shared ones."
  - [section 3.1, Table 1, page 9] Under NAIVE prior, "~50% of study-specific factors [are assigned] to the shared component"; FULL-D "overestimates the shared rank even more severely"; D-CUSP produces "self-consistent estimates."
  - [corpus] No direct corpus evidence on D-CUSP or factor allocation mechanisms; this is a novel contribution.
- Break condition: If view-specific and shared factors have similar loading magnitudes, the spike/slab separation may fail; if the true number of shared factors is very large relative to view dimensions, the adaptation step may become unstable.

### Mechanism 3
- Claim: Tempered CUSP updates (JFR-T, JAFAR-T) control rank overestimation in extreme large-p-small-n settings by reducing the effective sample size in factor activity updates from pm to min(n, pm).
- Mechanism: In standard CUSP, the likelihood term ∆logf(Λm•h) grows linearly with pm, overwhelming the prior contribution logωmℓ and causing K > n. Tempering rescales this by Tm = min(n,pm)/pm, acting as a fractional posterior that maintains adaptivity while preventing the curse of dimensionality.
- Core assumption: The true latent rank should be bounded by sample size n for interpretability; the tempering coefficient does not introduce unacceptable bias.
- Evidence anchors:
  - [section 2.3.1, page 7] "In Section 4, we consider a dataset in such a regime, where JFR and JAFAR achieve competitive accuracy but infer a relatively high number of factors... greater than n."
  - [section 4, Table 2, page 11] JAFAR-T reduces inferred total factors from 78.8 to 39.0 (JFR) and 57.2 to 25.9 (JAFAR) while maintaining predictive accuracy (MSE 3.21→3.24 for JAFAR-T).
  - [corpus] No corpus papers address tempered Bayesian inference for factor models in extreme dimensions.
- Break condition: If n is moderate relative to p, tempering is unnecessary and may underfit; if the true underlying structure genuinely has K > n meaningful factors, tempering will prune useful signal.

## Foundational Learning

- **Concept: Spike-and-slab priors with cumulative shrinkage (CUSP)**
  - Why needed here: CUSP adaptively learns the number of factors by progressively increasing shrinkage on later columns via stick-breaking weights π(Λ)mh = 1 - Σωml. Understanding this is essential for interpreting factor activity indicators (ζmh) and the adaptation step.
  - Quick check question: If π(Λ)m3 = 0.8 and π(Λ)m4 = 0.3, which factor column has higher prior probability of being active, and what does this imply about the expected total number of factors?

- **Concept: Identifiability in additive factor models**
  - Why needed here: JAFAR's decomposition ηi + Σϕmi suffers from non-identifiability beyond standard rotational ambiguity—a view-specific factor could be absorbed into the shared component with sparse loadings. D-CUSP addresses this via the constraint that shared factors must be active in ≥2 views.
  - Quick check question: Why can't we distinguish between (a) a view-specific factor ϕ1i and (b) a "shared" factor ηi that only loads on view 1, based on covariance alone?

- **Concept: Copula factor models for non-Gaussian data**
  - Why needed here: The multi-omics application has >30% of features with Shapiro statistics <0.95. The copula extension transforms marginals via F⁻¹j(Φ(zij)) while preserving the factor structure on latent zi, decoupling dependence learning from marginal estimation.
  - Quick check question: If feature xj has a heavy-tailed marginal distribution, how does the copula approach prevent this from distorting the learned latent factors?

## Architecture Onboarding

- **Component map:**
  - JFR layer: Single factor set ηi ∈ ℝK, shared loadings Λm ∈ ℝ^(pm×K), response coefficients θ ∈ ℝ^K
  - JAFAR layer: Adds view-specific factors ϕmi ∈ ℝ^Km with loadings Γm ∈ ℝ^(pm×Km) and response coefficients θm ∈ ℝ^Km
  - I-CUSP prior: Independent CUSP on each Λm, controls total rank via stick-breaking (νmh ~ Be(1, α))
  - D-CUSP prior: Dependent version with adaptation step that drops columns active in <2 views
  - Gibbs sampler: 7-step cycle (loadings, variances, factors, spike/slab memberships, stick-breaking elements, hyper-variances, adaptation)
  - Multiview MatchAlign: Post-processing with modified Varimax criterion Σm V(Λm, R) to resolve rotational ambiguity while respecting view structure
  - Copula extension: Deterministic preprocessing via empirical CDF transformation before factor model

- **Critical path:**
  1. Standardize features and response (required for CUSP)
  2. Set hyperparameters: α(Λ)m, α(Γ)m based on expected factor counts (E[K] ≈ α·√M per Appendix A); default τ²∞ = 0.005, a(L)m = 0.5, b(L)m = 0.1
  3. Initialize with conservative upper bounds: K_MAX, {Km_MAX}m
  4. Run Gibbs sampler with adaptation step (t_adapt = 200, d0 = -0.5, d1 = -5×10⁻⁴)
  5. Apply Multiview Varimax followed by MatchAlign post-processing to aligned samples
  6. For extreme p >> n: enable tempering with Tm = min(n,pm)/pm

- **Design tradeoffs:**
  - JFR vs JAFAR: JFR is simpler (single factor set) but computationally heavier; JAFAR is faster and more interpretable but requires D-CUSP to work correctly—use JAFAR when M ≥ 2 and views have heterogeneous signal-to-noise ratios
  - Tempered vs untempered: Untempered for balanced n/p ratios; tempered when p >> 100n to prevent K > n
  - NAIVE vs D-CUSP: NAIVE is faster per iteration but produces inconsistent factor allocation—never use in production

- **Failure signatures:**
  - K inferred >> n: Likely in extreme p >> n without tempering; enable JAFAR-T or JFR-T
  - High Λone-only count (>0): D-CUSP not properly configured; check adaptation step implementation
  - Slow mixing (low ESS): Check joint sampling of [Λmj•, Γmj•] is implemented; sequential updates harm mixing
  - Poor out-of-sample coverage: May indicate overfitting; increase burn-in or check tempering
  - Covariance reconstruction error dominated by off-diagonal blocks: Shared factors may be under-identified; increase α(Λ)m

- **First 3 experiments:**
  1. **Reproduction sanity check**: Run JFR and JAFAR on simulated data from Appendix F with known K_true = 4 shared and {9,10,11} view-specific factors; verify D-CUSP recovers these counts (±1-2) and NAIVE misallocates. Report Λone-only metric.
  2. **Scalability benchmark**: On your target data dimensions (pm, n, M), time 1000 iterations of JFR vs JAFAR with K_MAX = min(50, n/2). If JAFAR speedup <30%, investigate implementation of joint loadings sampling.
  3. **Tempering threshold**: On a p = 5000, n = 50 subset of your data, compare untempered JAFAR (K inferred) vs JAFAR-T (K inferred). If untempered K > 2×n, tempering is likely necessary for your full dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the theoretical properties and optimal selection criteria for the tempering coefficient $T_m$ in the tempered CUSP prior?
- Basis in paper: [explicit] Appendix D states: "The choice of tempering function may have important implications for both theoretical properties and practical performance. We emphasize that this topic warrants a more rigorous and systematic investigation, but defer it to future work."
- Why unresolved: The authors propose a heuristic tempering factor $T_m = \min(n,p_m)/p_m$ to mitigate the curse of dimensionality but lack formal proofs regarding posterior consistency or optimality for this specific choice.
- What evidence would resolve it: Theoretical proofs of convergence rates for the tempered posterior or simulation studies demonstrating the sensitivity of rank estimation to different functional forms of $T_m$.

### Open Question 2
- Question: How can the JAFAR framework be extended to handle longitudinal or time-series multiview data?
- Basis in paper: [inferred] Section 4 mentions the motivating data consists of "repeated measurements during the last 100 days of pregnancy," but the analysis was simplified to a "cross-sectional sub-dataset by considering only the first measurement." The model currently assumes i.i.d. observations.
- Why unresolved: The current joint additive factor structure does not model temporal dynamics or autocorrelation, potentially losing predictive information present in the repeated measures of the original dataset.
- What evidence would resolve it: An extension of the model incorporating dynamic latent factors and an application study showing improved prediction using the full longitudinal dataset compared to the cross-sectional baseline.

### Open Question 3
- Question: How does the computational complexity scale in scenarios with large sample sizes ($N \gg P$) rather than large feature dimensions?
- Basis in paper: [inferred] Section 2.3 discusses computational costs and focuses on the "extreme large-p-small-n" scenario. The cost is $O(n \cdot (\dots)^2)$, implying that while linear in $N$, it may become prohibitive for massive sample sizes typical of modern electronic health records.
- Why unresolved: The paper validates the method on a small dataset ($n=53$) and simulations up to $n=200$, leaving the scalability to "big data" regimes uncertain.
- What evidence would resolve it: Benchmarking the Gibbs sampler's runtime and mixing efficiency on datasets with $N > 10,000$, or the development of variational inference alternatives to improve scalability.

## Limitations

- The D-CUSP prior's effectiveness relies on correct specification of adaptation parameters (d0, d1) and spike variance τ²∞ = 0.005, which may not generalize across all data structures
- The tempered CUSP approach introduces additional hyperparameters whose impact on inference quality is not fully characterized
- The copula extension assumes monotonic relationships and may not capture complex dependence structures in non-Gaussian data

## Confidence

- **High confidence**: Computational efficiency gains of JAFAR over JFR (55% faster) are well-supported by theoretical complexity analysis and timing results
- **Medium confidence**: Predictive accuracy improvements are demonstrated but rely on specific data characteristics (omics with shared biological pathways)
- **Medium confidence**: D-CUSP identifiability claims are supported by simulation studies but limited to the specific simulation design presented

## Next Checks

1. Test D-CUSP on synthetic data where the true shared factor structure is known but involves weak loadings or high-dimensional view-specific noise
2. Benchmark tempered vs untempered versions across a grid of p/n ratios to identify the exact threshold where tempering becomes beneficial
3. Apply the copula extension to non-omics datasets with known non-Gaussian marginals to assess robustness of the marginal transformation approach