---
ver: rpa2
title: 'TRINITY: An Evolved LLM Coordinator'
arxiv_id: '2512.04695'
source_url: https://arxiv.org/abs/2512.04695
tags:
- agent
- coordinator
- selection
- head
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces TRINITY, a lightweight coordinator that\
  \ orchestrates multiple large language models (LLMs) without modifying their weights.\
  \ The coordinator, consisting of a compact language model (0.6B parameters) and\
  \ a small head (10K parameters), assigns one of three roles\u2014Thinker, Worker,\
  \ or Verifier\u2014to selected LLMs across multiple turns."
---

# TRINITY: An Evolved LLM Coordinator

## Quick Facts
- arXiv ID: 2512.04695
- Source URL: https://arxiv.org/abs/2512.04695
- Reference count: 40
- Key outcome: Introduces TRINITY, a lightweight coordinator that orchestrates multiple LLMs without modifying weights, achieving 86.2% on LiveCodeBench

## Executive Summary
TRINITY is a lightweight coordinator that orchestrates multiple large language models through a compact language model (0.6B parameters) and a small head (10K parameters). It assigns one of three roles—Thinker, Worker, or Verifier—to selected LLMs across multiple turns, optimized via separable Covariance Matrix Adaptation Evolution Strategy (sep-CMA-ES). The system achieves state-of-the-art performance, setting a new record of 86.2% on LiveCodeBench while consistently outperforming individual models and existing multi-agent methods across coding, math, reasoning, and domain knowledge tasks.

## Method Summary
TRINITY coordinates multiple LLMs by extracting penultimate-token hidden states from a compact Qwen3-0.6B coordinator, projecting them through a ~10K parameter linear head to produce agent and role selection logits. The system implements a tri-role decomposition where Thinker produces high-level plans, Worker executes concrete steps, and Verifier evaluates solution soundness. Optimization is performed using sep-CMA-ES with diagonal covariance, sampling parameter perturbations independently per dimension under block-ε-separability assumptions. The coordinator is trained on MATH500, MMLU, RLPR, and LiveCodeBench V1, achieving 86.2% pass@1 accuracy on LiveCodeBench V6.

## Key Results
- Sets new state-of-the-art record of 86.2% on LiveCodeBench
- Consistently outperforms individual models and existing multi-agent methods across coding, math, reasoning, and domain knowledge tasks
- Demonstrates robust zero-shot transfer to unseen tasks while maintaining performance
- Shows sep-CMA-ES provides advantages over reinforcement learning and random search under high dimensionality and tight evaluation budgets

## Why This Works (Mechanism)

### Mechanism 1: Hidden State Representations as Contextual Coordination Signals
The coordinator SLM processes the full conversation transcript and outputs hidden states. The penultimate token's hidden state (which attends over the entire sequence via self-attention) is extracted and projected by a ~10K parameter linear head to produce agent-selection and role-selection logits. This decouples contextual understanding (SLM) from decision-making (head). The core assumption is that the SLM's representation space is linearly separable by task type and agent capability requirements.

### Mechanism 2: Tri-Role Decomposition for Structured Multi-Turn Reasoning
At each turn, the coordinator selects one agent and assigns one role: Thinker produces high-level plans/decompositions; Worker executes concrete steps (calculations, code, derivations); Verifier evaluates solution soundness and signals termination upon acceptance. This creates a cyclical planning-execution-verification loop. The core assumption is that complex reasoning tasks benefit from explicit decomposition into planning, execution, and verification phases.

### Mechanism 3: Block-ε-Separability Enables Efficient Sep-CMA-ES Optimization
Sep-CMA-ES maintains only a diagonal covariance matrix, sampling parameter perturbations independently per dimension. Under block-ε-separability (weak inter-block couplings), this exploits concentrated within-block signal while avoiding ill-conditioned gradients from noisy global returns. Theory shows linear improvement per iteration vs. logarithmic for random search. The core assumption is that the optimization landscape satisfies block-ε-separability with weak inter-block parameter correlations.

## Foundational Learning

- **Hidden state representations in Transformers**: Why needed: The coordinator extracts penultimate-token hidden states as its primary signal; understanding what these encode is essential. Quick check: Why does the penultimate token's hidden state typically carry richer semantic context than the final token in a Transformer decoder?

- **Covariance Matrix Adaptation Evolution Strategy (CMA-ES)**: Why needed: The paper uses sep-CMA-ES as the core optimizer; understanding its mechanics and the diagonal approximation is critical. Quick check: What information does the covariance matrix in CMA-ES capture, and what is lost when using only the diagonal (separable) variant?

- **Multi-agent coordination patterns**: Why needed: TRINITY orchestrates multiple LLMs with learned role assignments; distinguishing static vs. adaptive coordination helps understand design choices. Quick check: What is the difference between test-time routing (selecting one agent per query) and multi-turn scaffolding (sequential agent invocations)?

## Architecture Onboarding

- **Component map**: Query arrives → SLM encodes full context → Extract penultimate hidden state → Head projects to logits → Sample or argmax selects (agent, role) pair → Message processor injects role prompt → Selected LLM generates response → Response appended to transcript → Loop until Verifier accepts or max turns reached

- **Critical path**: 1. Query arrives → SLM encodes full context → Extract penultimate hidden state 2. Head projects to logits → Sample or argmax selects (agent, role) pair 3. Message processor injects role prompt → Selected LLM generates response 4. Response appended to transcript → Loop until Verifier accepts or max turns reached

- **Design tradeoffs**: Linear head is most reliable; block-diagonal-10 uses 10x fewer parameters with moderate drop (Table 3); Penultimate token essential; last token (often EOS) causes >10 point collapse (Table 2); Singular value fine-tuning provides consistent gains (~2-6 points across tasks); removes need for full fine-tuning

- **Failure signatures**: Uniform agent selection across tasks indicates sep-CMA-ES not converging; check replication count and budget; Early termination on complex problems suggests Verifier accepting too readily; may need calibration or role prompt adjustment; Performance collapse on new domains indicates zero-shot transfer failure; check hidden state separability for new task types; REINFORCE-style high variance confirms need for derivative-free optimization

- **First 3 experiments**: 1. Head architecture sweep: Compare linear, low-rank, sparse, and block-diagonal heads on a held-out task to map the parameter-efficiency frontier 2. Hidden state separability visualization: Extract penultimate hidden states on a mixed-task batch, apply t-SNE/PCA, and verify task-type clusters form; correlate SVM accuracy with downstream performance 3. Optimizer comparison under matched budget: Run sep-CMA-ES, REINFORCE, and random search with identical evaluation budgets; plot expected reward vs. iteration to observe convergence differences

## Open Questions the Paper Calls Out

1. Can the TRINITY coordination framework be extended to grounded execution tasks involving non-textual tools such as code interpreters and external APIs?

2. Does the efficiency of the separable Covariance Matrix Adaptation Evolution Strategy (sep-CMA-ES) hold in regimes with dense rewards or significantly larger evaluation budgets compared to the binary, budget-tight setting analyzed?

3. How does the coordinator's performance and the representation space's separability degrade as the pool of LLMs scales beyond the seven agents tested?

## Limitations

- The core assumption that penultimate-token hidden states provide sufficient task-discriminative signal rests on linear separability, which may fail for novel task types outside the learned representation space

- The reported performance gains from sep-CMA-ES are compelling but don't systematically explore hyperparameter sensitivity, particularly population size, replication count, and covariance adaptation rates

- While TRINITY shows robust zero-shot transfer, the evaluation covers a limited scope of task types, and performance on tasks requiring fundamentally different reasoning patterns remains untested

## Confidence

- **High Confidence**: The empirical demonstration that sep-CMA-ES outperforms REINFORCE and random search under tight evaluation budgets is well-supported by controlled comparisons

- **Medium Confidence**: The theoretical mechanism of block-ε-separability enabling efficient diagonal covariance optimization is sound, but the extent to which the coordination objective satisfies this property in practice is not fully characterized

- **Low Confidence**: The specific parameter choices (SLM size, head architecture, optimizer settings) appear to work well in the reported regime, but their optimality or robustness to scaling is unclear

## Next Checks

1. **Representation Space Robustness Test**: Extract penultimate hidden states for a diverse set of out-of-distribution tasks and analyze linear separability via SVM classification accuracy and t-SNE clustering quality

2. **Optimizer Configuration Sweep**: Systematically vary sep-CMA-ES hyperparameters (population size, replication count, step-size, covariance adaptation rates) across a range of coordination problems

3. **Role Decomposition Flexibility Experiment**: Replace the fixed tri-role assignment with a learned role schema where the number and definitions of roles are discovered through optimization