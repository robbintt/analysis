---
ver: rpa2
title: Counterfactual Strategies for Markov Decision Processes
arxiv_id: '2505.09412'
source_url: https://arxiv.org/abs/2505.09412
tags:
- counterfactual
- strategy
- strategies
- distance
- probability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces counterfactual strategies for Markov Decision
  Processes (MDPs) to explain how minimal changes to a strategy can lead to different
  outcomes in sequential decision-making tasks. The authors formalize counterfactual
  strategies as solutions to non-linear optimization problems, minimizing strategy
  distance while ensuring reachability probability below a threshold.
---

# Counterfactual Strategies for Markov Decision Processes

## Quick Facts
- arXiv ID: 2505.09412
- Source URL: https://arxiv.org/abs/2505.09412
- Reference count: 24
- This paper introduces counterfactual strategies for Markov Decision Processes (MDPs) to explain how minimal changes to a strategy can lead to different outcomes in sequential decision-making tasks.

## Executive Summary
This paper introduces counterfactual strategies for Markov Decision Processes (MDPs) to explain how minimal changes to a strategy can lead to different outcomes in sequential decision-making tasks. The authors formalize counterfactual strategies as solutions to non-linear optimization problems, minimizing strategy distance while ensuring reachability probability below a threshold. They extend the approach to generate diverse counterfactual strategies optimized for diversity. Experiments on four real-world datasets demonstrate that counterfactual strategies can be computed efficiently for MDPs with thousands of states and tens of thousands of transitions, and that diverse strategies provide novel recourse possibilities while remaining close to the initial strategy.

## Method Summary
The method encodes counterfactual strategies as solutions to non-linear optimization problems, specifically Mixed Integer Quadratically Constrained Quadratic Programs (MIQCQP). The approach uses variables for action probabilities and reachability probabilities, minimizing a distance metric subject to reachability constraints. The core constraint implements the Bellman equation, creating a quadratic term that results in the non-convex formulation. The framework is extended to generate diverse counterfactual strategies by maximizing the determinant of a distance matrix. The method is evaluated on four real-world datasets using stochastic automata learning to construct MDPs from event logs.

## Key Results
- Counterfactual strategies can be computed efficiently for MDPs with thousands of states and tens of thousands of transitions
- Diverse strategies provide novel recourse possibilities while remaining close to the initial strategy
- The middle range of reachability thresholds (0.17 < γ ≤ 0.33) presents the greatest computational challenge

## Why This Works (Mechanism)

### Mechanism 1
Sequential decision-making recourse can be formalized as a non-convex optimization problem over strategy distributions. The method encodes a counterfactual strategy by creating variables for action probabilities and reachability probabilities, minimizing a distance metric subject to reachability probability below a threshold. The core constraint enforces the Bellman equation, creating a quadratic term that results in a Mixed Integer Quadratically Constrained Quadratic Problem (MIQCQP). The system dynamics must be known and stationary, and the undesired outcome must be reachable.

### Mechanism 2
Sparsity and proximity are enforced by a composite distance metric involving discrete and continuous norms. The objective function minimizes a weighted sum: r₀·d₀ + r₁·d₁ + r∞·d∞, where d₀ counts states with changed actions, and d₁/d∞ measure average and maximal distribution shifts. This ensures the counterfactual is small in scope (few states changed) and magnitude (small probability changes). Users prefer strategies that deviate minimally from current behavior and require changes in as few decision points as possible.

### Mechanism 3
Diversity of recourse options is generated by maximizing the determinant of a distance matrix. The method iteratively solves the optimization problem, modifying the objective function to include a diversity term that pushes new solutions away from previously generated strategies in vector space. High diversity, defined by pairwise distance between strategies, correlates with user utility and distinct recourse paths. The diversity weight λ controls the tradeoff between diversity and proximity to the initial strategy.

## Foundational Learning

- **Concept**: Markov Decision Processes (MDPs) as Strategy Holders
  - **Why needed here**: Unlike static classifiers, this paper explains policies in probabilistic environments. A strategy maps states to distributions over actions, not just a single action.
  - **Quick check question**: If a strategy is deterministic, does p_sa still need to be encoded as a variable, or can it be a constant?

- **Concept**: Non-Convex Optimization (MIQCQP)
  - **Why needed here**: The paper proves the problem is non-convex. Solvers might find local optima. Understanding why it is non-convex (the product of strategy variable p_sa and reachability variable p_s') is crucial for debugging solver behavior.
  - **Quick check question**: Why does Constraint 7 (p_s = ... · p_s') make the optimization problem quadratic and potentially non-convex?

- **Concept**: Reachability Probability
  - **Why needed here**: The core validity constraint is Pr^σ'(s_0, t) ≤ γ. This is a derived property of the induced Markov Chain M_σ', not a direct input.
  - **Quick check question**: Does a counterfactual strategy require the probability of the undesired state to be 0, or just below a threshold γ?

## Architecture Onboarding

- **Component map**: Data Preprocessor -> Strategy Encoder -> Constraint Builder -> Solver Engine -> Diversity Manager
- **Critical path**: The middle γ range (0.17 < γ ≤ 0.33) presents the greatest computational challenge—strict enough to require complex changes, but loose enough to explore a vast non-convex landscape.
- **Design tradeoffs**:
  - L0 Norm (Sparsity) vs. Speed: Including integer variable i_s increases solver complexity compared to purely continuous metrics
  - Diversity vs. Proximity: High λ generates novel strategies but increases distance from initial behavior
  - Model Size vs. Feasibility: Models >10,000 states frequently timed out
- **Failure signatures**:
  - Inf. (Infeasible): Threshold γ is physically impossible to reach given MDP structure
  - T.O. (Timeout): Occurs in large models or difficult γ ranges; non-convex search space is too large
  - Trivial Solution: γ is too high; initial strategy already satisfies condition
- **First 3 experiments**:
  1. Baseline Runtime: Run BPIC12 across all γ values to verify "runtime peak" in middle sextiles
  2. Scaling Limit: Run MSSD10 vs MSSD30 to quantify relationship between state count and runtime
  3. Diversity vs. Novelty: Generate 3 diverse strategies for GrepS dataset and calculate "fraction of novel state-action pairs"

## Open Questions the Paper Calls Out

- Can approximation techniques, such as linearization, significantly reduce the computation time for counterfactual strategies while maintaining solution quality?
- How can counterfactual strategies be synthesized for environments where the system adapts to the user's changes?
- Do the generated counterfactual strategies constitute realistic recourse behaviors for human users?

## Limitations
- The non-convex MIQCQP formulation may not guarantee global optimality
- Computational scalability is constrained with timeouts on large models for intermediate γ values
- The diversity mechanism lacks extensive empirical validation in the MDP context

## Confidence
- **High**: The formulation of counterfactual strategies as MIQCQP problems with Bellman constraints is technically sound
- **Medium**: The experimental results demonstrate feasibility but are limited to specific datasets and parameter settings
- **Low**: The claim that diverse strategies provide "novel recourse possibilities" lacks rigorous user studies or downstream impact analysis

## Next Checks
1. **Scalability Test**: Run MSSD10 vs MSSD30 models to quantify the relationship between state count and mean runtime
2. **Diversity Verification**: Generate 3 diverse strategies for the GrepS dataset and calculate the "fraction of novel state-action pairs"
3. **Robustness Check**: Test the framework on datasets with different characteristics to assess generalizability beyond the current four datasets