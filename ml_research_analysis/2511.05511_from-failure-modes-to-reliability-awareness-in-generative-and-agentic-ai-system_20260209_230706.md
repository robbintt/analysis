---
ver: rpa2
title: From Failure Modes to Reliability Awareness in Generative and Agentic AI System
arxiv_id: '2511.05511'
source_url: https://arxiv.org/abs/2511.05511
tags:
- reliability
- layer
- systems
- awareness
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This chapter develops a structured approach for understanding and
  improving reliability in generative and agentic AI systems. It introduces an 11-layer
  failure stack to trace vulnerabilities from hardware and power through data, models,
  and applications up to reasoning and multi-agent coordination.
---

# From Failure Modes to Reliability Awareness in Generative and Agentic AI System

## Quick Facts
- arXiv ID: 2511.05511
- Source URL: https://arxiv.org/abs/2511.05511
- Reference count: 4
- Introduces 11-layer failure stack and awareness mapping methodology for AI reliability

## Executive Summary
This chapter presents a comprehensive framework for understanding and improving reliability in generative and agentic AI systems through an 11-layer failure stack and awareness mapping methodology. The framework traces vulnerabilities from hardware and power through data, models, and applications up to reasoning and multi-agent coordination, demonstrating how failures propagate across layers. By integrating with Dependability-Centred Asset Management (DCAM), the approach provides both diagnostic tools and implementation roadmaps for building trustworthy AI systems in mission-critical domains.

## Method Summary
The methodology combines a structured failure analysis framework with organizational maturity assessment tools. The 11-layer failure stack provides a systematic approach to identifying vulnerabilities across the AI technology stack, while awareness mapping offers a quantitative measure of reliability risk recognition. The framework is validated through case vignettes from transportation, energy, healthcare, and manufacturing sectors, demonstrating layer-specific and cross-layer failure patterns. The integration with DCAM provides a practical pathway for implementing reliability improvements in operational settings.

## Key Results
- Proposes an 11-layer failure stack spanning hardware to multi-agent coordination for comprehensive reliability analysis
- Introduces awareness mapping as a maturity-oriented tool to quantify organizational recognition of AI reliability risks
- Demonstrates framework applicability through industry-specific case studies across transportation, energy, healthcare, and manufacturing
- Establishes theoretical link between reliability awareness and Dependability-Centred Asset Management practices

## Why This Works (Mechanism)
The framework works by providing a structured lens for identifying and analyzing failure modes across the entire AI technology stack. The 11-layer approach captures both technical vulnerabilities and organizational awareness gaps, while the cascading failure analysis reveals how problems propagate between layers. This systematic visibility enables targeted interventions and organizational learning, creating a foundation for building more reliable AI systems through improved design, deployment, and operational practices.

## Foundational Learning
- 11-layer failure stack architecture: Essential for systematic vulnerability identification across AI systems; quick check: map each layer to specific failure modes in your domain
- Cascading failure mechanisms: Critical for understanding how local failures propagate through interconnected layers; quick check: trace failure propagation paths in recent incidents
- Awareness mapping methodology: Key for measuring organizational reliability maturity; quick check: assess current awareness levels against proposed maturity scale
- DCAM integration principles: Important for connecting reliability frameworks to asset management practices; quick check: evaluate existing DCAM implementation in your organization
- Multi-agent coordination reliability: Vital for understanding complex system interactions; quick check: identify coordination failures in current multi-agent deployments
- Layer boundary definitions: Necessary for consistent failure analysis; quick check: verify layer boundaries align with your system architecture

## Architecture Onboarding
Component map: Hardware -> Power -> Data Infrastructure -> Model Architecture -> Training Process -> Deployment Infrastructure -> Application Logic -> User Interface -> Monitoring Systems -> Reasoning Components -> Multi-agent Coordination
Critical path: Model Architecture -> Training Process -> Deployment Infrastructure -> Application Logic -> Monitoring Systems
Design tradeoffs: Granularity vs. comprehensiveness, theoretical completeness vs. practical applicability, technical vs. organizational focus
Failure signatures: Hardware failures manifest as system crashes, data failures as model degradation, coordination failures as inconsistent behavior
First experiments: 1) Map current AI system to 11-layer stack, 2) Conduct awareness survey across stakeholder groups, 3) Trace failure propagation in recent incidents

## Open Questions the Paper Calls Out
None

## Limitations
- Lacks empirical validation across diverse real-world AI deployments
- Relies heavily on subjective assessment scales without established validation metrics
- Case vignettes may represent curated scenarios rather than representative system failures

## Confidence
11-layer failure stack validity: Medium confidence
Awareness mapping effectiveness: Low confidence
DCAM integration benefits: Medium confidence

## Next Checks
1. Conduct systematic failure mode analysis across 10+ real-world AI deployments spanning different industries to verify whether the 11-layer stack captures actual failure patterns and whether additional layers or different granularities would be more appropriate.

2. Implement the awareness mapping tool with multiple independent assessors on the same AI systems to establish inter-rater reliability scores and validate that the maturity quantification correlates with actual system reliability outcomes.

3. Design and execute a longitudinal study comparing AI system reliability outcomes between organizations using the awareness mapping framework versus those using conventional reliability assessment methods, measuring both technical metrics and organizational learning effects.