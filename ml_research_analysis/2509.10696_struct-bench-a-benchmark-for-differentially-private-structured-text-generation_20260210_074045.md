---
ver: rpa2
title: 'Struct-Bench: A Benchmark for Differentially Private Structured Text Generation'
arxiv_id: '2509.10696'
source_url: https://arxiv.org/abs/2509.10696
tags:
- data
- synthetic
- dataset
- query
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Struct-Bench, a benchmark for evaluating
  differentially private synthetic data generation for structured text datasets containing
  natural language. The key innovation is using context-free grammars (CFGs) to represent
  dataset structure and extract structural and semantic attributes for evaluation.
---

# Struct-Bench: A Benchmark for Differentially Private Structured Text Generation

## Quick Facts
- arXiv ID: 2509.10696
- Source URL: https://arxiv.org/abs/2509.10696
- Authors: Shuaiqi Wang, Vikas Raunak, Arturs Backurs, Victor Reis, Pei Zhou, Sihao Chen, Longqi Yang, Zinan Lin, Sergey Yekhanin, Giulia Fante
- Reference count: 40
- Primary result: CFG-based benchmark reveals existing DP synthetic text generators struggle with structural properties while maintaining semantic quality; PE enhancements achieve up to 94% CFG compliance

## Executive Summary
This paper introduces Struct-Bench, a comprehensive benchmark for evaluating differentially private synthetic data generation on structured text datasets containing natural language. The framework uses context-free grammars (CFGs) to represent dataset structure and extract structural and semantic attributes for evaluation. The authors evaluate four DP synthetic data generation methods across seven diverse datasets and demonstrate that no single metric fully describes synthetic data quality. They propose algorithmic improvements to Private Evolution (PE), including LLM-assisted reformatting and node extraction with auto-generation, achieving significant improvements in structural compliance (up to 94% CFG Pass Rate) while maintaining or improving semantic metrics.

## Method Summary
Struct-Bench requires users to define their dataset structure as a Context-Free Grammar (CFG), which specifies different categories of nodes and relations between them. The framework evaluates synthetic data through three metric categories: (1) Structural metrics including CFG Pass Rate, Key Node Dependency distances, and Attribute Match distances; (2) Non-structural metrics including KNN-Precision and KNN-Recall for semantic similarity; and (3) Downstream task accuracy. The authors evaluate four DP synthetic data generation methods (Private Evolution, DP Fine-Tuning, Instruction Following, and their enhanced PE variant) across seven datasets including ShareGPT, ICLR reviews, Water, Arena, Adult, and two synthetic datasets. Privacy budgets range from ε=1 to ε=4 with δ=0, using GPT-2 for training-based methods and GPT-4o for API-based PE/IF.

## Key Results
- Existing DP synthetic data generation methods struggle to capture structural properties while maintaining semantic quality
- Private Evolution with LLM-assisted reformatting and node extraction achieves up to 94% CFG compliance
- No single metric fully describes synthetic data quality; high CFG-PR can coexist with low semantic metrics
- Enhanced PE shows significant improvement over vanilla PE across both structural and semantic metrics

## Why This Works (Mechanism)

### Mechanism 1: CFG-Based Structural Parsing and Node Extraction
- Claim: Context-Free Grammars can systematically represent and validate structural properties of datasets containing natural language fields.
- Mechanism: Users define a CFG specifying production rules for dataset structure (e.g., ShareGPT: `conversation → query response`, where `query → "HUMAN:␣" query_text`). Struct-Bench parses each synthetic sample using this CFG, extracts a parse tree, and identifies key nodes specified by the user. The CFG Pass Rate (CFG-PR) is then computed as the fraction of samples that parse successfully.
- Core assumption: The structural dependencies of the dataset are known (public schema) and can be expressed as a CFG; semantic dependencies are not encoded as hard constraints but assessed separately.
- Evidence anchors:
  - [abstract] "The Struct-Bench framework requires users to provide a representation of their dataset structure as a Context-Free Grammar (CFG)."
  - [Section 2, Dataset Representation] "Such relations are captured in Struct-Bench by a context-free grammar (CFG), which specifies different categories of nodes and the relations between them."
  - [Section 2.1, CFG-PR] "CFG Pass Rate (CFG-PR): This measures the fraction of samples in the synthetic dataset D′ that parse correctly under the CFG."
  - [corpus] Related work on DP synthetic text generation (e.g., arXiv:2510.10990, 2510.06719) does not propose alternative formalisms for structure representation, suggesting CFG is the current standard approach.
- Break condition: If the dataset's structural dependencies are context-sensitive (requiring semantic information to determine valid structures), a CFG will be insufficient and may either over-accept invalid samples or reject valid ones.

### Mechanism 2: Distributional Distance Metrics for Semantic and Structural Fidelity
- Claim: Distributional distance metrics applied to node-level and sample-level attributes can quantify how well synthetic data matches private data across both structural and semantic dimensions.
- Mechanism: Struct-Bench computes three metric families: (1) KND measures the Wasserstein-2 distance between distributions of semantic dependencies (e.g., cosine similarity of query-response embeddings) in private vs. synthetic data; (2) AM computes Wasserstein-2 (numeric) or total variation (categorical) distance for attributes like token length, topic, intent; (3) KNN-Precision/Recall measure per-sample semantic similarity without structural assumptions. These provide complementary signals—high precision with low CFG-PR indicates structurally invalid but semantically plausible samples.
- Core assumption: Embedding-based similarity (e.g., cosine similarity of node embeddings) is a reasonable proxy for semantic dependency; distributional distances correlate with downstream utility.
- Evidence anchors:
  - [Section 2.1, KND] "KND measures the distributional distance of node pair dependencies... For a key node pair (Oi, Oj), let Ci,j be the cosine similarity between their embeddings."
  - [Section 3.3] "No single metric fully describes synthetic data quality... some metrics can be high, while others remain low (e.g., see CFG-PR and KNN-Recall in Fig. 2)."
  - [corpus] arXiv:2403.00932 uses similar embedding-based metrics for DP knowledge distillation via synthetic text, supporting the general validity of distributional metrics for text quality.
- Break condition: If node embeddings fail to capture task-relevant semantics (e.g., domain-specific jargon not represented in general embeddings), KND and KNN metrics may give misleadingly high scores for semantically poor synthetic data.

### Mechanism 3: Private Evolution Enhanced with CFG-Aware Post-Processing
- Claim: Augmenting the Private Evolution (PE) algorithm with CFG-aware reformatting and node extraction improves both structural compliance and semantic diversity without additional privacy cost.
- Mechanism: Standard PE iteratively (1) generates candidate samples via Random API, (2) constructs a DP voting histogram based on nearest-neighbor selection from private data, (3) perturbs high-vote samples via Variation API (blank-filling). The enhanced version adds: (a) LLM-assisted reformatting after voting to fix CFG-invalid samples (e.g., adding missing "HUMAN:"/"GPT:" tokens), and (b) node extraction where specific node types (e.g., queries) are preserved via blank-filling while others (e.g., responses) are auto-generated conditionally, reducing semantic constraints. By the post-processing property of DP, these modifications do not consume additional privacy budget.
- Core assumption: The reformatting LLM and auto-generation LLM do not leak private information (treated as public post-processing); the foundation model has sufficient instruction-following capability to perform targeted reformatting.
- Evidence anchors:
  - [Section 4, Solution 1] "LLM-Assisted reformatting can improve CFG compliance... we introduce a reformatting feature to the Random and Variation APIs by prompting LLMs to explicitly check and reformat CFG-invalid samples."
  - [Section 4, Solution 2] "Node extraction & auto-generation can improve semantic diversity... we propose a variant of PE that extracts specific nodes for blank-filling and then allows the language model to auto-generate the remaining nodes."
  - [Figure 9] Shows combination achieving ~94% CFG-PR while maintaining or improving semantic metrics.
  - [corpus] arXiv:2510.10990 proposes "Secret-Protected Evolution" extending PE with secret tokens, suggesting ongoing innovation in PE variants.
- Break condition: If the reformatting LLM introduces systematic semantic errors (e.g., incorrectly splitting queries and responses), structural compliance may improve but semantic quality degrades. The paper notes this risk (Figure 5 shows semantically flawed reformatting).

## Foundational Learning

- **Context-Free Grammars (CFGs)**
  - Why needed here: Struct-Bench requires users to define dataset structure as a CFG to enable parsing, node extraction, and structural validation. Understanding production rules, parse trees, and the limitations of CFGs (vs. context-sensitive grammars) is essential for correctly representing dataset constraints.
  - Quick check question: Given a dataset of multi-turn dialogues where each turn must alternate between "USER:" and "ASSISTANT:", can you write production rules that enforce this alternation?

- **Differential Privacy (DP) Basics**
  - Why needed here: The entire benchmark is designed for evaluating DP synthetic data generators. Understanding the (ε, δ)-DP definition, privacy budget composition, and the post-processing property (which allows CFG-aware enhancements without additional privacy cost) is necessary to interpret results and design valid improvements.
  - Quick check question: If a synthetic data generator satisfies (ε=4, δ=0)-DP, what does this guarantee about the relationship between the output distribution and any single training sample?

- **Distributional Distance Metrics (Wasserstein, Total Variation)**
  - Why needed here: Struct-Bench uses Wasserstein-2 distance for KND and numeric attributes, and total variation for categorical attributes. Understanding when each is appropriate and how to interpret the scores is critical for diagnosing synthetic data quality.
  - Quick check question: For a categorical attribute with values {A, B, C}, if the private data distribution is [0.5, 0.3, 0.2] and synthetic is [0.4, 0.4, 0.2], what is the total variation distance?

## Architecture Onboarding

- **Component map:**
  - Real dataset D (private) -> CFG parser -> Parse trees and node attributes -> Metric Layer -> Multi-dimensional score report
  - Synthetic dataset D′ (generated) -> CFG parser -> Parse trees and node attributes -> Metric Layer -> Multi-dimensional score report
  - Metric Layer: Computes CFG-PR, KND, AM, KNN-Precision/Recall, Downstream Accuracy

- **Critical path:**
  1. Define CFG for your target dataset (one-time, can be partially automated via LLMs per footnote 1)
  2. Identify key nodes whose dependencies matter for your use case
  3. Run your DP synthetic generator to produce D′
  4. Apply Struct-Bench evaluation pipeline to compute all metrics
  5. Diagnose failure modes (e.g., low CFG-PR → reformatting; low KNN-Recall → node extraction)

- **Design tradeoffs:**
  - CFG vs. CSG: CFGs are simpler to specify but cannot encode semantic dependencies (addressed via KND metric instead); CSGs would be more expressive but require significantly more domain expertise
  - Reformatting before vs. after voting: Before voting may bias selection toward structurally valid but semantically flawed samples; after voting preserves semantic quality but requires post-hoc fixes
  - Which nodes to extract: Extracting queries improves diversity more than extracting responses (queries constrain topic space); choice depends on which node type drives semantic variation in your domain

- **Failure signatures:**
  - CFG-PR = 0 but KNN-Precision > 0.5: Generator produces semantically plausible samples that completely violate structural constraints (common with DP fine-tuning)
  - High CFG-PR, near-zero KNN-Recall: Generator captures structure but collapses semantic diversity (common with PE on tabular/synthetic datasets per Figure 2)
  - High KNN-Precision, low KNN-Recall: Generator produces high-quality samples but misses the diversity of the private distribution (PE tends toward this)

- **First 3 experiments:**
  1. **Baseline establishment**: Run Struct-Bench on your dataset with Instruction Following (IF, ε=0) using GPT-4o to establish an upper bound on structural compliance achievable without private data signals. Compare against your DP generator.
  2. **Ablation on PE enhancements**: If using PE, run three variants—vanilla PE, PE+Reformat-after-voting, PE+NodeExtraction (extracting the node type that drives semantic diversity in your domain). Compare across CFG-PR, KNN-Recall, and your primary downstream metric.
  3. **Metric sensitivity analysis**: Vary privacy budget ε ∈ {1, 2, 4} and plot the tradeoff curves between CFG-PR and KNN-Recall. Identify which metric degrades faster under tighter privacy—this reveals whether your generator prioritizes structure or semantics under constraint.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a differentially private synthetic data generation method be designed that simultaneously achieves high performance across all structural, semantic, and statistical metrics defined in Struct-Bench?
- Basis in paper: [explicit] The authors state in the conclusion that the "algorithm design... pave[s] the way to propose a method that outperforms on all evaluation metrics, which we leave as a future work."
- Why unresolved: Current baselines exhibit a trade-off; for example, Private Evolution often struggles to capture semantic diversity (low KNN-Recall) while maintaining structural validity, and DP-Fine-Tuning often fails to learn structure entirely.
- What evidence would resolve it: An algorithm that maintains a high CFG Pass Rate (e.g., >90%) and high KNN-Recall concurrently across the diverse datasets in the benchmark.

### Open Question 2
- Question: Can the evaluation metrics developed for Struct-Bench, particularly Key Node Dependency (KND), be effectively adapted to benchmark non-private synthetic data generation tasks?
- Basis in paper: [explicit] The authors note that while they focus on DP data, "the metrics in Struct-Bench could be helpful for benchmarking non-private synthetic data as well, and we leave it to future work."
- Why unresolved: Non-private synthetic data is often designed to deviate from real data (e.g., conditional generation), whereas Struct-Bench currently measures similarity to a specific private dataset.
- What evidence would resolve it: A study applying Struct-Bench metrics to standard non-private NLG benchmarks (like GEM) to validate their discriminative power outside the DP setting.

### Open Question 3
- Question: To what extent does the reliance on Context-Free Grammars (CFGs) limit the ability to strictly enforce semantic dependencies compared to using Context-Sensitive Grammars (CSGs)?
- Basis in paper: [inferred] The paper explicitly mentions that while CSGs are more expressive and can capture semantic dependencies, they were excluded from the framework because specifying them requires "significantly more domain knowledge" and is "burdensome."
- Why unresolved: It is unclear if the statistical approximation used by the Key Node Dependency (KND) metric fully compensates for the loss of hard constraints that CSGs would provide.
- What evidence would resolve it: A comparative analysis evaluating the precision of KND versus a CSG-based parser on a subset of synthetic samples with complex logical inter-node relationships.

## Limitations

- CFGs cannot capture semantic dependencies, relying on statistical metrics (KND) as an approximation rather than hard constraints
- LLM post-processing for reformatting may introduce semantic errors while fixing structure, creating a trade-off
- Embedding-based distributional metrics assume that general-purpose embeddings capture task-relevant semantic quality

## Confidence

- **High Confidence**: CFG-based structural parsing, baseline PE algorithm correctness, privacy budget accounting (post-processing property)
- **Medium Confidence**: Semantic validity of LLM reformatting, embedding-based distributional metrics, task-specific downstream utility claims
- **Low Confidence**: Generalizability of CFG specifications across arbitrary natural language datasets, robustness of metrics to adversarial synthetic data, privacy guarantees of post-processed LLM transformations

## Next Checks

1. **CFG Specification Robustness**: Test the CFG-based parsing on a dataset where structural constraints are context-sensitive (e.g., requiring semantic information to determine valid structures). Measure whether CFG-PR accurately rejects invalid samples without over-rejecting valid ones.

2. **Reformatting LLM Error Analysis**: Run the LLM reformatting on a held-out validation set and manually annotate the frequency and type of semantic errors introduced (e.g., incorrect query-response splitting, added hallucinated content). Compare error rates across different prompt templates.

3. **Metric Correlation with Task Utility**: Select 3-5 diverse downstream tasks and compute the Pearson/Spearman correlation between Struct-Bench metric scores (especially KND, KNN-Recall) and actual task performance. Identify which metric(s) best predict downstream utility across tasks.