---
ver: rpa2
title: 'STORY2GAME: Generating (Almost) Everything in an Interactive Fiction Game'
arxiv_id: '2505.03547'
source_url: https://arxiv.org/abs/2505.03547
tags:
- actions
- story
- action
- game
- player
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: STORY2GAME addresses the challenge of generating interactive fiction
  games from scratch using LLMs, where traditional approaches constrain stories to
  predefined actions. The system first generates a story with actions annotated with
  preconditions and effects, then builds a minimal text game engine to execute those
  actions.
---

# STORY2GAME: Generating (Almost) Everything in an Interactive Fiction Game

## Quick Facts
- arXiv ID: 2505.03547
- Source URL: https://arxiv.org/abs/2505.03547
- Reference count: 31
- System generates interactive fiction games from scratch using LLMs, achieving 80% compilation success and 60% semantic coherence for dynamic actions

## Executive Summary
STORY2GAME addresses the challenge of generating interactive fiction games from scratch using LLMs, where traditional approaches constrain stories to predefined actions. The system first generates a story with actions annotated with preconditions and effects, then builds a minimal text game engine to execute those actions. For player creativity, it dynamically generates new actions on-the-fly, inferring necessary objects, attributes, and dependencies from player input. Action generation succeeds 80% of the time compilation-wise, with 60% achieving semantic coherence matching human expectations. The approach enables emergent gameplay while keeping interactions grounded in the game world state, allowing players to explore stories beyond scripted paths.

## Method Summary
The system uses LLMs to generate stories with annotated actions (preconditions/effects), then compiles these into a minimal text game engine. When players attempt unscripted actions, the system dynamically generates them with inferred preconditions, creates missing objects/attributes, and propagates attribute changes to existing actions through retroactive precondition updates. Recursive preceding event generation (depth-limited to 1) creates prerequisite action chains for complex player inputs.

## Key Results
- Action generation succeeds 80% of the time compilation-wise
- 60% of dynamically generated actions achieve semantic coherence matching human expectations
- Dynamic action generation enables emergent gameplay beyond scripted paths

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Annotating story actions with preconditions and effects enables LLMs to generate executable game engine code that maintains world state consistency.
- Mechanism: The system prompts an LLM to generate stories where each action is annotated with (1) fundamental preconditions (location, inventory checks), (2) additional preconditions (custom attributes), and (3) effects (movement, attribute changes, object creation/deletion). These annotations are then translated directly into conditional checks and state mutations in the game engine.
- Core assumption: LLMs can reliably infer commonsense preconditions and effects for narrative actions in a structured format suitable for code generation.
- Evidence anchors:
  - [abstract] "The key to successful action generation is to use LLM-generated preconditions and effects of actions in the stories as guides for what aspects of the game state must be tracked and changed by the game engine when a player performs an action."
  - [Section III-A] "Preconditions are statements about the state of the world that must be true for an action to be executable. Effects are statements about how the state of the world will be different if an action is executed."
  - [corpus] Limited direct corpus support; related work (Starling, Word2World) generates interactive content but relies on predefined action schemas rather than dynamic precondition-effect inference.
- Break condition: If the LLM fails to identify critical preconditions (e.g., forgetting that "unlock chest" requires a key), the generated code allows logically incoherent actions, breaking game state integrity.

### Mechanism 2
- Claim: Dynamic action generation with retroactive attribute propagation allows players to execute unscripted actions while maintaining world coherence.
- Mechanism: When a player attempts an action not in the story, the system (1) generates the action with inferred preconditions/effects, (2) creates missing objects/attributes with defaults, and critically (3) iterates through existing actions involving affected objects to determine if the new attribute requires retroactive precondition additions.
- Core assumption: New attributes introduced by player actions are relevant to existing actions in predictable ways that an LLM can identify.
- Evidence anchors:
  - [abstract] "Dynamic action generation may require on-the-fly updates to the game engine's state representation and revision of previously generated actions."
  - [Section IV] "If the new action results in the creation of a new attribute for an object, we iterate through the other actions that involve said object. We then ask the LLM to determine whether this new attribute is relevant to each prior existing action."
  - [corpus] Weak corpus support; neighbor papers focus on content generation rather than retroactive state consistency maintenance.
- Break condition: If attribute propagation misses relevant existing actions (e.g., adding "broken" attribute to a bucket but not updating "fill bucket" to check it), semantic coherence degrades.

### Mechanism 3
- Claim: Recursive preceding event generation creates emergent side quests that ground player creativity in achievable action chains.
- Mechanism: When dynamic actions require preceding events that don't exist, the system recursively generates those prerequisite actions (limited to depth 1), forcing players to complete chains rather than jumping to story conclusions.
- Core assumption: Players accept procedurally generated prerequisite chains as meaningful gameplay rather than arbitrary barriers.
- Evidence anchors:
  - [Section IV] "Whenever preceding events are indicated as a precondition for a new action, we check to see if the preceding events exist. If not, we recursively create these preceding events as actions using an identical process as before. We limit the depth of preceding events to one."
  - [Section IV] "These actions may in turn require other actions, and the player will effectively be 'off script' and forging their own emergent story."
  - [corpus] Emergent narrative frameworks (Kriegel & Aylett 2008, cited in paper) provide theoretical grounding but limited empirical validation.
- Break condition: Recursive generation could create impossible or circular dependencies, blocking story progress entirely.

## Foundational Learning

- **Concept: Precondition-Effect Planning Representation**
  - Why needed here: The entire system depends on understanding how actions change world state. Preconditions define when actions are valid; effects define state transitions.
  - Quick check question: Given "player opens locked door with key," what are two preconditions and one effect?

- **Concept: Graph-Based World State Representation**
  - Why needed here: The game engine represents all entities (rooms, items, characters) as nodes with attributes; actions traverse and modify this graph.
  - Quick check question: How would you represent "player has key in inventory, key is in forest room" as node relationships?

- **Concept: LLM Structured Output Prompting**
  - Why needed here: The system requires LLMs to output preconditions/effects in consistent JSON-like formats for programmatic translation to code.
  - Quick check question: What output format constraints would you specify to ensure reliable parsing of action annotations?

## Architecture Onboarding

- **Component map:** Story Generator (GPT-4o-mini) -> World Generator -> Action Code Generator -> Runtime Engine -> Dynamic Action Generator

- **Critical path:** Story with annotations -> World graph instantiation -> Action code compilation -> Interactive play with dynamic generation fallback

- **Design tradeoffs:**
  - Minimal engine vs. Inform7 compatibility: Authors chose minimal custom engine over Inform7 for flexibility, sacrificing rich built-in verb semantics
  - Depth-1 recursion limit: Prevents infinite cascades but may create incomplete prerequisite chains
  - No room attributes: Prevents "destroyed room" exploits but blocks actions like "illuminate forest" (noted as semantic failure source)

- **Failure signatures:**
  - Object misidentification: "Key" vs. "Metallic Key" compilation failures (~3-7% of actions)
  - Room property actions: Actions targeting room attributes fail semantically (architecture limitation)
  - Attribute propagation gaps: New attributes not added to relevant existing actions

- **First 3 experiments:**
  1. Replicate compilation success measurement: Generate 10 stories per length bucket, run automated precondition-satisfaction tests, verify reported 93-97% per-action success rates.
  2. Test semantic coherence on dynamic actions: Generate 30 novel verb-object pairs, manually inspect whether effects match commonsense expectations (target ~60% match rate).
  3. Stress-test attribute propagation: Introduce "break" action on key objects, verify whether lock/unlock actions retroactively receive broken-key preconditions.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited semantic coherence: 60% success rate indicates substantial quality issues in dynamic action generation
- Architecture constraints: Cannot handle room attributes, blocking actions like "illuminate forest"
- Incomplete prerequisite chains: Depth-1 recursion limit may create impossible or circular dependencies

## Confidence
- **High confidence**: Compilation success rates (93-97%) - directly measurable through automated testing of precondition satisfaction
- **Medium confidence**: Dynamic action generation success (80% compilation) - relies on automated testing but semantic coherence remains uncertain
- **Low confidence**: Semantic coherence assessment - based on manual evaluation of 30 dynamic actions without systematic failure analysis

## Next Checks
1. Conduct systematic failure analysis of dynamic action semantic coherence: Evaluate 100 novel player actions, categorize failure types (impossible actions, irrelevant effects, missing preconditions), and compare against LLM-generated semantic expectations to identify systematic patterns.

2. Test attribute propagation completeness: Introduce breaking actions on objects, verify whether all relevant existing actions (including those involving the object indirectly) correctly incorporate the new attribute in their preconditions, measuring propagation coverage rates.

3. Stress-test recursive generation limits: Systematically attempt dynamic actions requiring 2+ levels of preceding events, measure whether generated prerequisite chains are complete, achievable, and coherent, or whether they create impossible or circular dependencies.