---
ver: rpa2
title: 'Energy-Driven Steering: Reducing False Refusals in Large Language Models'
arxiv_id: '2510.08646'
source_url: https://arxiv.org/abs/2510.08646
tags:
- energy
- steering
- arxiv
- safety
- 'false'
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of reducing false refusals in
  large language models (LLMs) while maintaining safety alignment. The proposed Energy-Driven
  Steering (EDS) framework uses a lightweight, externally trained Energy-Based Model
  (EBM) to dynamically steer LLM internal activations during inference.
---

# Energy-Driven Steering: Reducing False Refusals in Large Language Models

## Quick Facts
- arXiv ID: 2510.08646
- Source URL: https://arxiv.org/abs/2510.08646
- Reference count: 40
- EDS substantially reduces false refusal rates while maintaining safety and capabilities

## Executive Summary
This paper addresses the challenge of reducing false refusals in large language models (LLMs) while maintaining safety alignment. The proposed Energy-Driven Steering (EDS) framework uses a lightweight, externally trained Energy-Based Model (EBM) to dynamically steer LLM internal activations during inference. The EBM learns an energy landscape where undesirable behaviors (false refusals and jailbreaks) have high energy while desirable behaviors (helpful responses and safe rejections) have low energy. By applying gradient-based steering, EDS redirects hidden states away from refusal-prone regions without modifying model weights. Experiments across multiple models show EDS substantially reduces false refusal rates while maintaining baseline safety performance and general capabilities.

## Method Summary
EDS employs a contrastively-trained 4-layer MLP EBM to assign energy values to LLM hidden states. The EBM is trained on activations extracted from frozen base models using CARES-21K dataset, where responses are classified via heuristic C(X,Y) into desirable/undesirable categories. At inference, EDS computes gradients of the energy function with respect to hidden states and applies gradient descent updates (h' = h - η·∇E(h)) at selected layers to steer toward low-energy (desirable) regions. The method requires minimal computational overhead and maintains model weights frozen throughout.

## Key Results
- EDS reduces false refusal rates substantially: ORB-H compliance improves from 57.3% to 82.6%
- Maintains safety performance on JailbreakBench and HarmBench
- Preserves general capabilities on MMLU, ARC, and MATH benchmarks
- Computational overhead is minimal compared to base models

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A contrastively-trained Energy-Based Model (EBM) creates a discriminative landscape that separates desirable from undesirable hidden states more precisely than linear ablation methods.
- **Mechanism:** The EBM is trained via InfoNCE loss to assign low energy to desirable states (compliant responses to benign prompts, refusals to harmful ones) and high energy to undesirable states (false refusals, jailbreaks). This yields a non-linear energy boundary that contours complex activation clusters.
- **Core assumption:** LLM hidden states for "desirable" vs "undesirable" behaviors form separable clusters in activation space that a learned MLP can discriminate.
- **Evidence anchors:**
  - [abstract]: "trained a lightweight, external Energy-Based Model (EBM) to assign high energy to undesirable (false refusal or jailbreak) states and low energy to desirable (helpful response or safe reject) ones"
  - [section 4.2]: InfoNCE loss forces E_θ(h_good) << E_θ(h_bad)
  - [corpus]: COSMIC and SafeSteer papers confirm refusal directions exist in activation space; corpus lacks direct EBM comparisons, suggesting novelty.
- **Break condition:** If desirable and undesirable states overlap substantially in hidden space (linearly inseparable even with MLPs), the energy landscape cannot provide clean gradients for steering.

### Mechanism 2
- **Claim:** Real-time gradient descent on the EBM energy surface moves hidden states toward low-energy (desirable) regions, altering token probabilities without modifying model weights.
- **Mechanism:** At each generation step, compute ∇_h E_θ(h_t) and update h'_t = h_t - η·∇_h E_θ(h_t). The modified hidden state passes to the LM head, shifting logits toward compliant continuations.
- **Core assumption:** The gradient direction reliably points away from refusal-prone regions and does not overshoot into harmful territory.
- **Evidence anchors:**
  - [abstract]: "use the gradient of the energy function to dynamically steer the LLM's hidden states to low energy regions"
  - [section 4.3]: Eq. 10-12 show the update rule and logit approximation via Taylor expansion
  - [corpus]: Refusal Steering (arXiv:2512.16602) uses similar activation steering but with LLM-as-judge scoring; confirms steering viability.
- **Break condition:** If η is too large, overcorrection may push benign queries toward harmful responses; if too small, false refusals persist. Ablation (Fig. 4) confirms sensitivity.

### Mechanism 3
- **Claim:** Context-aware training data construction enables the EBM to distinguish justified refusals (to harmful prompts) from false refusals (to benign prompts).
- **Mechanism:** Equations 5-6 define D_good and D_bad not by response type alone, but by (prompt type, response type) pairs: refusals to harmful prompts are "good"; compliant responses to harmful prompts are "bad."
- **Core assumption:** A heuristic classifier C(X, Y) can reliably label training examples without substantial noise.
- **Evidence anchors:**
  - [section 4.1]: "This context-aware data separation is crucial for training an EBM that can distinguish between justified and unjustified refusals"
  - [appendix B]: CARES-21K dataset used with harmful_level labels for sampling
  - [corpus]: Related work on over-refusal (XSB, OR-Bench) confirms context-sensitive labeling matters; no direct evidence on classifier error rates.
- **Break condition:** If the classifier mislabels a significant fraction of examples, the EBM learns a corrupted energy landscape.

## Foundational Learning

- **Concept: Energy-Based Models (EBMs)**
  - **Why needed here:** EDS uses an EBM to define a scalar energy over hidden states; understanding that low energy ≈ high probability of desirable behavior is essential.
  - **Quick check question:** Given E(h₁) = 2.0 and E(h₂) = 5.0, which hidden state is more likely "desirable" under a trained EBM?

- **Concept: Contrastive Learning / InfoNCE Loss**
  - **Why needed here:** The EBM is trained to pull positive (good) samples closer in energy and push negative (bad) samples apart.
  - **Quick check question:** In InfoNCE loss, what happens to E_θ(h⁺) as training converges—does it increase or decrease?

- **Concept: Activation Steering**
  - **Why needed here:** EDS is an inference-time intervention method; it does not modify model weights but perturbs activations.
  - **Quick check question:** If you apply h' = h + αv where v is a steering vector, what happens if α is set too high?

- **Concept: Gibbs-Boltzmann Distribution**
  - **Why needed here:** The paper links energy to probability via p(h) ∝ exp(-E_θ(h)/τ), formalizing why energy minimization is principled.
  - **Quick check question:** As energy E(h) decreases, what happens to the probability p(h)?

## Architecture Onboarding

- **Component map:** Frozen base LLM -> Heuristic classifier C(X,Y) -> EBM (4-layer MLP) -> Steering module -> Updated hidden states -> LM head

- **Critical path:**
  1. Collect prompts → generate responses → classify → extract hidden states → populate D_good/D_bad
  2. Train EBM per layer with InfoNCE loss; validate and select top-k layers
  3. At inference, for each token: compute h_t → compute ∇_h E_θ → update to h'_t → generate next token

- **Design tradeoffs:**
  - **Layer selection:** More layers → finer control but higher overhead; paper uses 12-20 layers depending on model
  - **Steering coefficient η:** Larger η → stronger correction but risk of overshooting; optimal range 0.1-1.0 model-dependent
  - **Gradient steps per token:** More steps → better energy minimization but latency increases; 3-12 steps used

- **Failure signatures:**
  - **Overcorrection:** Benign prompts trigger harmful responses (safety degradation) → η too high or EBM mistrained
  - **Undercorrection:** False refusals persist → η too low, wrong layers selected, or classifier noise
  - **Capability drop:** MMLU/ARC scores fall → steering perturbs representations needed for reasoning
  - **Latency spike:** Inference time doubles → too many layers or gradient steps

- **First 3 experiments:**
  1. **Reproduce ORB-H compliance improvement** on Llama-3.1-8B-IT with default η=0.1, 15 layers, 3 gradient steps; target ≥80% CR
  2. **Ablate steering coefficient:** Sweep η ∈ {0.05, 0.1, 0.2, 0.5, 0.95} and plot ORB-H CR vs. JBB CR vs. MMLU; identify Pareto frontier
  3. **Layer sensitivity test:** Train EBMs for all layers, then intervene on subsets (top-3, top-10, top-15, all); measure how layer count affects false refusal reduction vs. overhead

## Open Questions the Paper Calls Out
None

## Limitations
- **Contextual Generalization Gap:** The EBM is trained on a balanced CARES-21K dataset but the paper does not validate on out-of-distribution benign prompts.
- **Heuristic Classifier Noise:** The refusal classification heuristic (C(X, Y)) is not fully specified, potentially introducing noise into the EBM training.
- **Safety-Response Tradeoff:** The paper reports maintained safety on benchmarks but does not quantify whether the intervention introduces new failure modes.

## Confidence

**High Confidence (Evidence Strong):**
- EDS reduces false refusal rates significantly (ORB-H: 57.3% → 82.6% CR)
- EBM training methodology is clearly specified (InfoNCE, 4-layer MLP, τ=0.10)
- Steering implementation (gradient-based activation update) is mathematically sound

**Medium Confidence (Evidence Moderate):**
- Computational efficiency claims (minimal overhead) - only reported relative to base models
- Safety maintenance on benchmarks - no detailed analysis of potential new vulnerabilities
- Layer selection rationale - validation protocol not fully specified

**Low Confidence (Evidence Weak):**
- Generalization to unseen prompt distributions
- Impact on nuanced refusal scenarios (e.g., mixed-safety prompts)
- Long-term stability of EBM energy landscape across model updates

## Next Checks
1. **Out-of-Distribution Robustness Test**: Evaluate EDS on benign prompts from datasets not overlapping with CARES-21K (e.g., RealToxicityPrompts filtered for harmless examples) to measure false refusal rates on unseen benign distributions.

2. **Safety Boundary Stress Test**: Systematically test EDS on prompts that contain subtle harmful cues within otherwise benign contexts to identify if the EBM over-corrects toward harmful compliance.

3. **Gradient Step Sensitivity Analysis**: Conduct a fine-grained ablation (η ∈ {0.05, 0.1, 0.15, 0.2, 0.3}) across multiple benign and harmful prompt sets to identify the precise threshold where overcorrection begins.