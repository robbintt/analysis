---
ver: rpa2
title: 'AI''s Blind Spots: Geographic Knowledge and Diversity Deficit in Generated
  Urban Scenario'
arxiv_id: '2506.16898'
source_url: https://arxiv.org/abs/2506.16898
tags:
- geographic
- image
- diffusion
- urban
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study evaluates the geographic knowledge and biases of two\
  \ state-of-the-art diffusion models (FLUX 1-schnell and Stable Diffusion 3.5) by\
  \ generating 150 images each for all 50 US states, their capitals, and the USA as\
  \ a whole. Using DINO-v2 ViT-S/14 embeddings and Fr\xE9chet Inception Distance (FID),\
  \ the analysis shows that models encode meaningful geographic knowledge, with states\
  \ and capitals clustering according to real-world regional patterns."
---

# AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario

## Quick Facts
- **arXiv ID:** 2506.16898
- **Source URL:** https://arxiv.org/abs/2506.16898
- **Reference count:** 17
- **Primary result:** State-of-the-art diffusion models encode regional geographic knowledge but display metropolitan bias and misgenerate small capitals with European-sounding names when prompted for "USA"

## Executive Summary
This study evaluates the geographic knowledge and biases of FLUX 1-schnell and Stable Diffusion 3.5 by generating 150 images each for all 50 US states, their capitals, and the USA as a whole. Using DINO-v2 embeddings and FID distance, the analysis reveals that both models encode meaningful geographic knowledge with states clustering by real-world regions. However, when prompted for "USA," both models display a strong metropolitan bias, producing dense urban imagery that underrepresents rural states. Additionally, small capitals with European-sounding names are systematically misgenerated as European cityscapes.

## Method Summary
The researchers generated 15,150 images per model using fixed prompts "A photorealistic high-resolution street-view photo of {LOCATION}" for 101 locations (50 states, 50 capitals, "USA"). Images were preprocessed and converted to 384-dimensional DINO-v2 embeddings, then pairwise Fréchet Inception Distance (FID) was calculated to create distance matrices. Hierarchical clustering analysis visualized geographic groupings, and FIDs between states/capitals and "USA" images quantified representation bias.

## Key Results
- Both models encode meaningful geographic knowledge, with states clustering according to real-world regional patterns
- When prompted for "USA," models exhibit strong metropolitan bias, producing dense urban imagery that underrepresents rural states
- Small capitals with European-sounding names (Frankfort, Pierre, Montpelier, Dover, Olympia) are systematically misgenerated as European cityscapes

## Why This Works (Mechanism)

### Mechanism 1: Geographic Coherence Encoding
- **Claim:** Diffusion models implicitly encode regional geographic coherence, mapping textual geographic entities to distinct visual clusters that mirror real-world spatial proximity.
- **Mechanism:** The model learns joint text-image representations during pre-training. When prompted with specific locations, the model retrieves visual features associated with high-probability training images for those locations. These visual features form clusters where geographically proximate locations have low FID, implying the model has internalized a "latent map" of regional architectural and landscape styles.
- **Core assumption:** The visual features extracted by DINO-v2 ViT-S/14 reliably capture semantic urban characteristics that differentiate geographic regions.
- **Evidence anchors:** Abstract states "states and capitals clustering according to real-world regional patterns"; section 3.1 shows "both models exhibit clear tendencies to group geographically proximate regions"; SounDiT corpus supports AI models can map geo-contextual inputs to geographically specific visual outputs.

### Mechanism 2: Metropolitan Prototype Bias
- **Claim:** Generic national prompts trigger a "metropolitan prototype bias," causing the model to synthesize a narrow subset of high-density urban imagery while suppressing rural or small-town features.
- **Mechanism:** The token "USA" in the training corpus is hypothesized to co-occur most frequently with images of major metropolitan areas in high-quality web data. During inference, the diffusion process converges on the mode of the highest probability distribution—dense skylines and street views—treating the "USA" concept as synonymous with "major US city."
- **Core assumption:** The frequency and quality of image-text pairs in the training data are heavily skewed toward major metropolitan centers, establishing a strong prior for "urban" imagery when geographic conditioning is abstract.
- **Evidence anchors:** Abstract states "prompt the models to generate an image for 'United States'... the models exhibit a strong representative bias toward metropolis-like areas"; section 3.3 shows "models systematically represent the generic USA through dense, urban environments."

### Mechanism 3: Entity Disambiguation Failure
- **Claim:** Entity disambiguation for low-frequency or semantically ambiguous place names defaults to high-frequency linguistic associations, resulting in "toponymic hallucination."
- **Mechanism:** Small capitals with names sharing linguistic roots with prominent international locations lack sufficient unique visual training data to form a strong specific prior. The model's attention mechanism appears to latch onto the more globally prominent entity rather than the specific US town.
- **Core assumption:** The text-encoder cross-attention layers prioritize token-features from the dominant global entity in the training distribution over the specific, under-represented local entity.
- **Evidence anchors:** Abstract states "models systematically misgenerate small capitals with European-sounding names, defaulting to European cityscapes"; section 3.2 shows "tendency results in visual outputs that group together, reflecting shared architectural elements typical of Old World urban environments."

## Foundational Learning

- **Concept: Fréchet Inception Distance (FID)**
  - **Why needed here:** FID is the primary metric used to quantify the "distance" between visual concepts. Understanding that lower FID implies visual similarity (same cluster) and higher FID implies divergence (misgeneration or bias) is essential to interpret the results.
  - **Quick check question:** If "USA" images have a low FID with "New York" but a high FID with "Alaska," what does that imply about the model's internal concept of "USA"?

- **Concept: Visual Embeddings (DINO-v2)**
  - **Why needed here:** The paper relies on DINO-v2 to convert raw pixels into semantic vectors. One must grasp that these vectors represent high-level features (building style, density) rather than just pixel colors, enabling the clustering of "Mountain West" states.
  - **Quick check question:** Why is a pre-trained vision transformer (like DINO-v2) used instead of raw pixel comparison to measure geographic similarity?

- **Concept: Diffusion Sampling & Priors**
  - **Why needed here:** The "metropolitan bias" is a result of the model's learned prior distribution. Understanding that diffusion models sample from a learned probability distribution helps explain why generic prompts result in "average" or "stereotypical" outputs rather than diverse samplings.
  - **Quick check question:** Why might a model generate a dense cityscape for the prompt "USA" even if it "knows" what rural Alabama looks like?

## Architecture Onboarding

- **Component map:** Generators (FLUX 1-schnell & SD 3.5-L) -> DINO-v2 ViT-S/14 Encoder -> FID Calculator -> Distance Matrix -> Hierarchical Clustering
- **Critical path:**
  1. Batch generation (150 images x 101 locations)
  2. Pre-processing (Resize 256 -> Center Crop 224 -> Normalize)
  3. Embedding extraction (DINO-v2)
  4. Distribution calculation (Mean vector & Covariance matrix per location)
  5. Distance Matrix computation (Pairwise FID)
  6. Hierarchical Clustering (to visualize regional groupings)

- **Design tradeoffs:**
  - **Prompt Specificity:** The authors used minimal prompts to probe "inherent" knowledge. Adding "USA" to "Frankfort" might fix errors but would mask the model's disambiguation weaknesses.
  - **Model Speed vs. Fidelity:** Using FLUX "schnell" (fast inference) vs SD 3.5-Large (higher fidelity) to check if speed optimizations degrade geographic nuance (results show both fail similarly on small capitals).

- **Failure signatures:**
  - **Semantic Drift:** High FID between a small capital and its geographic neighbors combined with low FID to geographically distant regions (e.g., Pierre clustering with European cities).
  - **Prototype Collapse:** Visual homogeneity in "USA" outputs where distinct features of rural states are absent in the aggregate distribution.

- **First 3 experiments:**
  1. **Disambiguation Stress Test:** Rerun generation for the "problem" capitals (Frankfort, Pierre, etc.) using the prompt "Frankfort, Kentucky" to measure the performance gap caused by entity ambiguity.
  2. **Rural Prototype Injection:** Generate images for "Rural USA" vs. "Urban USA" and compare their FIDs to the specific states to see if the model possesses a "rural" concept it simply fails to associate with the "USA" token.
  3. **Cross-Model Consistency:** Calculate the FID between FLUX and SD 3.5 outputs for the same location to determine if their "latent maps" align or if they learn different geographic representations.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do the observed metropolitan biases and entity-disambiguation failures persist when evaluating geographic knowledge on a global scale outside of the United States?
- **Basis in paper:** [explicit] The conclusion states, "Future research will extend this work toward global generalisation," explicitly marking this as a necessary next step.
- **Why unresolved:** The current study restricts its scope exclusively to the 50 US states and their capitals, leaving the models' behavior in less-represented or differently-represented global regions unknown.
- **What evidence would resolve it:** A replication of the methodology applied to a diverse set of global regions, specifically comparing data-rich (e.g., Western Europe) and data-poor (e.g., Global South) regions.

### Open Question 2
- **Question:** Can dynamic prompting strategies effectively force the models to utilize their latent geographic knowledge to represent underrepresented rural areas?
- **Basis in paper:** [explicit] The authors conclude that future work should "develop dynamic prompting strategies that actively elevate underrepresented geographies."
- **Why unresolved:** The study demonstrated that the models *possess* knowledge of rural areas (when prompted specifically) but fail to use it when prompted generically ("USA"); it did not test methods to bridge this gap.
- **What evidence would resolve it:** Experiments using modified, detailed prompts for generic entities (e.g., "USA, rural landscape") showing increased FID divergence from metropolitan clusters and successful generation of non-urban features.

### Open Question 3
- **Question:** Is the systematic misgeneration of small capitals with European-sounding names primarily driven by text-encoder ambiguity or by a visual bias towards European architecture in the training data?
- **Basis in paper:** [inferred] The paper identifies "entity-disambiguation issues" (e.g., Frankfort, Devon) resulting in European-style imagery but does not isolate whether the error occurs in understanding the prompt (semantic) or retrieving visual features (data distribution).
- **Why unresolved:** The methodology evaluates the final image output and clustering distance but does not perform ablation studies on the text encoders or cross-attention maps to pinpoint the failure source.
- **What evidence would resolve it:** An analysis of the text-encoder embeddings for ambiguous place names to see if they map closer to their US or European counterparts, or intervention studies where prompts are disambiguated with geographic coordinates.

## Limitations

- The study relies on minimal, generic prompts without additional geographic context, which may artificially inflate observed representation biases
- The research only examines two diffusion models and uses a single image embedding method (DINO-v2), limiting generalizability
- The experimental choice to avoid disambiguation (e.g., not adding "USA" to state capitals) may reflect prompt engineering limitations rather than fundamental model deficiencies

## Confidence

- **High Confidence:** The finding that both models encode meaningful geographic knowledge, with states clustering by real-world regions
- **Medium Confidence:** The metropolitan bias when prompting for "USA" - while clearly demonstrated through FID analysis, this could partly reflect training data distribution
- **Medium Confidence:** The European misgeneration of small capitals with European-sounding names - while clustering evidence is strong, the paper doesn't test whether explicit geographic context would eliminate this bias

## Next Checks

1. **Disambiguation Test:** Regenerate the 5 problematic capitals (Frankfort, Pierre, Montpelier, Dover, Olympia) with explicit geographic context ("Frankfort, Kentucky, USA") and compare FID distances to measure the performance gap caused by entity ambiguity.

2. **Rural Prototype Validation:** Generate images for "Rural USA" and "Urban USA" separately, then compute their FIDs to individual states to determine if the model possesses distinct rural/urban concepts that are simply not associated with the "USA" token.

3. **Cross-Model Geographic Alignment:** Calculate pairwise FID between FLUX and SD 3.5 outputs for the same locations to assess whether these models learn consistent geographic representations or develop different "mental maps" of the United States.