---
ver: rpa2
title: Scaling sparse feature circuit finding for in-context learning
arxiv_id: '2504.13756'
source_url: https://arxiv.org/abs/2504.13756
tags:
- task
- features
- feature
- learning
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates that sparse autoencoders (SAEs) can effectively
  analyze the in-context learning (ICL) mechanism in large language models. The authors
  develop a Task Vector Cleaning (TVC) algorithm to decompose task vectors into interpretable
  SAE features, identifying task-execution features that causally induce task performance.
---

# Scaling sparse feature circuit finding for in-context learning

## Quick Facts
- arXiv ID: 2504.13756
- Source URL: https://arxiv.org/abs/2504.13756
- Authors: Dmitrii Kharlapenko; Stepan Shabalin; Fazl Barez; Arthur Conmy; Neel Nanda
- Reference count: 40
- This work demonstrates that sparse autoencoders (SAEs) can effectively analyze the in-context learning (ICL) mechanism in large language models, scaling circuit analysis to models 30 times larger than previously studied.

## Executive Summary
This work demonstrates that sparse autoencoders (SAEs) can effectively analyze the in-context learning (ICL) mechanism in large language models. The authors develop a Task Vector Cleaning (TVC) algorithm to decompose task vectors into interpretable SAE features, identifying task-execution features that causally induce task performance. They adapt the Sparse Feature Circuits (SFC) methodology to the larger Gemma-1 2B model, discovering task-detection features that identify required tasks from earlier prompt information. The analysis reveals that attention heads and MLPs process information from task-detection features to activate appropriate task-execution features, demonstrating the interdependence of these components in the ICL circuit.

## Method Summary
The authors develop a Task Vector Cleaning (TVC) algorithm that decomposes task vectors into interpretable SAE features by identifying the minimal set of features needed to accurately predict task vectors. They apply this to both task-execution and task-detection circuits in the Gemma-1 2B model. For task-execution, they identify features that causally induce task performance by steering these features and measuring performance changes. For task-detection, they identify features that capture information from earlier in the prompt about what task is needed. They then apply Sparse Feature Circuits methodology to map out how information flows from task-detection features through attention heads and MLPs to activate appropriate task-execution features.

## Key Results
- Successfully scaled circuit analysis to 2B parameter models, 30x larger than previous SAE-based analyses
- Identified task-execution features that causally induce task performance with strong positive steering effects
- Discovered task-detection features that identify required tasks from earlier prompt information
- Mapped information flow showing attention heads and MLPs process task-detection features to activate task-execution features

## Why This Works (Mechanism)
The approach works because sparse autoencoders can decompose high-dimensional task vectors into interpretable feature components. The TVC algorithm identifies which features are minimally necessary for task performance, distinguishing causal contributors from correlated but non-essential features. By steering these identified features and measuring performance changes, the authors establish causal relationships between specific features and task outcomes. The SFC methodology then traces how information propagates through the model's components, revealing the mechanistic pathway from task detection to execution.

## Foundational Learning

**Sparse Autoencoders (SAEs)**: Neural networks trained to reconstruct input data using sparse feature activations. Why needed: To decompose complex task vectors into interpretable components. Quick check: Verify that SAE reconstruction error is low while maintaining feature sparsity.

**Task Vector Cleaning (TVC)**: Algorithm that identifies minimal feature sets needed to predict task vectors. Why needed: To distinguish causal features from correlated but non-essential ones. Quick check: Confirm that cleaned task vectors maintain high correlation with original vectors while using fewer features.

**Causal Steering**: Method of intervening on specific features and measuring downstream effects. Why needed: To establish causal relationships between features and task performance. Quick check: Verify that steering task-execution features produces measurable performance changes while steering unrelated features does not.

**Feature Circuits**: Pathways through which information flows between features via model components. Why needed: To map mechanistic pathways from task detection to execution. Quick check: Confirm that attention heads and MLPs show significant information flow between task-detection and task-execution features.

**Indirect Effect (IE) Correlation**: Metric measuring how well component interventions approximate total causal effects. Why needed: To validate that identified circuits capture the true mechanistic pathway. Quick check: Verify high IE correlation in later layers where the model processes task information.

## Architecture Onboarding

**Component Map**: Task Detection Features -> Attention Heads/MLPs -> Task Execution Features -> Task Performance

**Critical Path**: Information flows from prompt context through task-detection features in early layers, processed by attention heads and MLPs, to activate appropriate task-execution features in later layers that directly determine performance.

**Design Tradeoffs**: SAE sparsity vs. reconstruction accuracy (tighter sparsity preserves interpretability but may lose information), feature intervention strength vs. model stability (stronger interventions show clearer effects but may destabilize predictions), task complexity vs. circuit clarity (simpler tasks yield clearer circuits but may miss complex mechanisms).

**Failure Signatures**: Low IE correlation indicates circuit identification failure; weak detection-execution connections suggest missing intermediate processing; inconsistent feature interpretability across tasks indicates pretraining data distribution effects.

**First Experiments**:
1. Apply TVC to a new task type to verify feature identification generalizes beyond the original task set
2. Perform targeted interventions on identified task-detection features and measure effects on downstream task-execution feature activation
3. Vary SAE sparsity hyperparameter and measure impact on feature interpretability and circuit identification quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do certain tasks (e.g., person-profession, present-simple-gerund) show unusually weak detection-execution connections compared to other tasks?
- Basis in paper: "Two tasks diverged from this pattern: person profession and present simple gerund showed unusually weak detection-execution connections, suggesting a need for deeper investigation." (Section 4.2)
- Why unresolved: The paper documents this anomaly but does not hypothesize or test causes; the discovery is presented as surprising.
- What evidence would resolve it: Systematic analysis comparing these tasks' SAE feature distributions, pretraining data frequencies, and circuit structures against well-connected tasks.

### Open Question 2
- Question: What causes the lower quality of indirect effect (IE) approximations in earlier model layers during SFC analysis?
- Basis in paper: "This may be due to the quality of our trained SAEs, the increased task complexity, or token type-wise aggregation, and warrants further investigation." (Appendix E.2)
- Why unresolved: The paper identifies degraded IE approximation quality before layer 6 but does not disentangle three proposed causes.
- What evidence would resolve it: Ablation experiments varying SAE training quality, task complexity levels, and aggregation strategies independently to isolate the factor affecting IE correlation.

### Open Question 3
- Question: Is the clarity of identified task features correlated with task frequency in pretraining data?
- Basis in paper: "We find more clear task features for some tasks than others but do not consider whether this is linked to how common a task is in pretraining data." (Appendix H)
- Why unresolved: The authors observe variability in feature interpretability across tasks but leave the pretraining distribution hypothesis untested.
- What evidence would resolve it: Correlating quantitative measures of feature clarity (e.g., activation sparsity, steering specificity) with estimated pretraining corpus frequencies for each task type.

## Limitations
- Analysis is constrained to a single 2B parameter model (Gemma-1) and synthetic tasks, limiting generalizability
- Sparse autoencoder features may miss subtle interactions or emergent properties in larger models
- Task Vector Cleaning assumes clean decomposition of task vectors, which may not hold for all ICL phenomena

## Confidence
- High Confidence: The methodology for scaling SAE analysis to larger models is sound
- Medium Confidence: Causal interpretations of feature interactions require further validation
- Low Confidence: Claims about general applicability to real-world ICL remain speculative

## Next Checks
1. Apply TVC and SFC methodology to models with different architectures (Llama, Mistral) and sizes (10B+ parameters)
2. Test feature identification on non-synthetic ICL tasks (few-shot classification on real datasets)
3. Implement targeted interventions on task-detection features and measure downstream effects on task-execution activation and performance