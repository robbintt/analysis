---
ver: rpa2
title: 'Gender Trouble in Language Models: An Empirical Audit Guided by Gender Performativity
  Theory'
arxiv_id: '2505.14080'
source_url: https://arxiv.org/abs/2505.14080
tags:
- gender
- language
- gendered
- woman
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study audited 16 language models to examine how they encode
  gender, revealing that larger models reinforce narrow, binary gender constructs
  tied to biological sex, while marginalizing transgender and gender-diverse identities.
  The authors operationalized gender studies insights on performativity and pathologization,
  testing associations between gender, sex, and illness.
---

# Gender Trouble in Language Models: An Empirical Audit Guided by Gender Performativity Theory

## Quick Facts
- arXiv ID: 2505.14080
- Source URL: https://arxiv.org/abs/2505.14080
- Reference count: 40
- Larger models reinforce binary gender constructs tied to biological sex while marginalizing transgender identities

## Executive Summary
This study audits 16 language models to examine how they encode gender, revealing that larger models reinforce narrow, binary gender constructs tied to biological sex, while marginalizing transgender and gender-diverse identities. The authors operationalize gender studies insights on performativity and pathologization, testing associations between gender, sex, and illness. Results show stronger sex-gender conflation in larger models, erasure of non-binary identities, and systematic pathologization of transgender and gender-diverse terms as mental illness. The authors argue current model audits overlook upstream conceptual harms and call for theory-informed evaluation and debiasing strategies that engage social scientists to address broader, systemic gender biases in language models.

## Method Summary
The authors conducted an empirical audit of 16 language models using two primary experimental paradigms: the Masked Language Modeling (MLM) task and the Sentence Completion Test (SCT). They operationalized Judith Butler's theory of gender performativity by testing associations between gender identities and their stereotypical contexts (performative norms), as well as associations between gender and illness (pathologization). The audit measured Log Probability Ratios (LPRs) to quantify model biases, testing how models complete sentences with gender terms in contexts that should be neutral, gender-specific, or pathological. The study focused exclusively on English-language models and corpora to ensure comparability across experiments.

## Key Results
- Larger models show stronger conflation between gender and biological sex, with 100B+ parameter models exhibiting the most severe binary gender constructs
- Non-binary and transgender identities are systematically pathologized, with these terms more frequently associated with mental illness concepts than binary gender terms
- The audit reveals that standard bias mitigation techniques like RLHF may amplify rather than reduce these harmful associations by reinforcing normative gender concepts present in training data

## Why This Works (Mechanism)
The study's theoretical framework connects gender performativity theory to measurable model behaviors, demonstrating how language models encode and reproduce societal gender norms. By treating gender as performative rather than essential, the authors show how models learn to associate gender with stereotypical contexts and pathologize non-normative identities. The mechanism operates through the models' training on corpora that reflect existing societal biases, with larger models capturing more subtle and pervasive patterns of gender-normativity and pathologization.

## Foundational Learning
- Gender Performativity Theory: Understanding gender as constituted through repeated performances rather than fixed identity; needed to frame how models encode gender as stereotypical behaviors rather than diverse identities. Quick check: Can identify how Butler's theory differs from essentialist views of gender.
- Log Probability Ratio (LPR) methodology: Statistical measure comparing likelihood of different word completions; needed to quantify gender associations in model outputs. Quick check: Can calculate LPRs for simple gender associations.
- Masked Language Modeling (MLM): Task where models predict masked words in sentences; needed as primary experimental paradigm for measuring gender associations. Quick check: Understand how MLM differs from autoregressive generation.
- Sentence Completion Test (SCT): Structured prompts requiring models to complete gendered statements; needed to test specific gender-related hypotheses. Quick check: Can design SCT prompts that test gender stereotypes.
- Pathologization: Process of associating non-normative identities with illness or deviance; needed to understand how models marginalize transgender identities. Quick check: Can identify examples of pathologization in medical literature.

## Architecture Onboarding
- Component map: MLM task -> LPR calculation -> Statistical analysis -> Bias quantification
- Critical path: Experimental design (gender terms selection) -> Model testing (MLM/SCT) -> Data collection (LPRs) -> Analysis (statistical tests) -> Interpretation (bias assessment)
- Design tradeoffs: Monolingual focus ensures comparability but limits generalizability; operationalizing complex theory through word associations may oversimplify nuanced concepts
- Failure signatures: Models showing equal LPRs for all gender terms suggest inadequate gender modeling; extremely high LPRs for pathologizing associations indicate severe bias
- First experiments: 1) Test simple gender-stereotype associations (he/she as doctors/nurses), 2) Compare LPRs for binary vs non-binary gender terms in neutral contexts, 3) Measure pathologization LPRs for transgender terms vs binary terms

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How do gender-sex associations manifest in non-English language models?
- Basis in paper: The authors note their monolingual focus prevents claims about other languages where gender constructs differ significantly.
- Why unresolved: The study restricted experiments to English to ensure comparability.
- What evidence would resolve it: Replicating the audit methodology on multilingual or non-English models.

### Open Question 2
- Question: Does Reinforcement Learning with Human Feedback (RLHF) mitigate or exacerbate the pathologization of gender-diverse identities?
- Basis in paper: The authors argue RLHF might reinforce "folk understanding" if clickworkers hold normative gender concepts.
- Why unresolved: The study focused on pre-trained base models rather than aligned versions.
- What evidence would resolve it: Comparing Genderâ€“Illness LPRs between base models and their RLHF-aligned counterparts.

### Open Question 3
- Question: Do the measured pathologizing associations in base models translate to diagnostic errors in clinical downstream tasks?
- Basis in paper: The authors caution against deployment in healthcare because "these downstream risks are still poorly understood."
- Why unresolved: The audit measured model probabilities rather than performance in real-world applications.
- What evidence would resolve it: Empirical testing of diagnostic overshadowing rates for gender-diverse profiles in simulated clinical LLM applications.

## Limitations
- The study's monolingual focus on English limits generalizability to other linguistic and cultural contexts where gender constructs may differ significantly
- The operationalization of complex gender theory through word association tasks may oversimplify nuanced concepts of gender identity and performativity
- The sample size of 16 models, while substantial, could be expanded to include more diverse model architectures and training approaches

## Confidence
- Claims about sex-gender conflation in larger models: High
- Claims about erasure of non-binary identities: Medium
- Claims about pathologization of transgender identities: High
- Claims about RLHF potentially amplifying bias: Medium
- Theoretical framing and recommendations: Medium to High

## Next Checks
1. Replicate the study with multilingual models and non-English corpora to assess cultural generalizability of findings
2. Expand the set of gender-diverse and non-binary terms tested to ensure comprehensive coverage of gender identities beyond current scope
3. Conduct qualitative analyses of model outputs to complement quantitative measures and better understand nuances of gender representation and harm