---
ver: rpa2
title: Data Model Design for Explainable Machine Learning-based Electricity Applications
arxiv_id: '2505.23607'
source_url: https://arxiv.org/abs/2505.23607
tags:
- data
- features
- energy
- feature
- consumption
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the need for structured data modeling in machine
  learning-based electricity applications by proposing a taxonomy that categorizes
  features into domain-specific, contextual, and behavioral groups. The taxonomy guides
  the development of comprehensive feature sets for training interpretable machine
  learning models, such as linear regression, XGBoost, MLP, Prophet, and N-BEATS,
  in household electricity forecasting.
---

# Data Model Design for Explainable Machine Learning-based Electricity Applications

## Quick Facts
- arXiv ID: 2505.23607
- Source URL: https://arxiv.org/abs/2505.23607
- Reference count: 40
- One-line primary result: Taxonomy-based feature engineering improves household electricity forecasting accuracy by up to 23% MPE reduction compared to raw time series data

## Executive Summary
This paper addresses the challenge of structured data modeling for machine learning-based electricity applications by proposing a comprehensive taxonomy for feature categorization. The taxonomy divides features into domain-specific, contextual, and behavioral groups, providing a systematic framework for developing interpretable ML models in household electricity forecasting. The approach is evaluated across three openly available datasets using both traditional ML models (linear regression, XGBoost, MLP) and time series models (Prophet, N-BEATS), demonstrating significant improvements in forecasting accuracy.

The study shows that feature engineering guided by the proposed taxonomy significantly enhances model performance, with domain-specific features contributing most to accuracy improvements. The research validates the taxonomy's effectiveness through rigorous evaluation using metrics like mean percentage error (MPE) and mean squared error (MSE), establishing a foundation for explainable ML applications in the electricity domain.

## Method Summary
The paper introduces a taxonomy-based approach to feature engineering for explainable machine learning in electricity applications. The methodology involves categorizing features into three groups: domain-specific (related to electricity consumption patterns), contextual (environmental and temporal factors), and behavioral (user activity patterns). This structured taxonomy guides the development of comprehensive feature sets for training interpretable ML models. The approach is evaluated on household electricity forecasting using three datasets (UCI Household, HUE, and REFIT) and compares multiple models including linear regression, XGBoost, MLP, Prophet, and N-BEATS. Performance is measured using MPE and MSE metrics to assess the impact of taxonomy-guided feature engineering on forecasting accuracy.

## Key Results
- Feature engineering guided by taxonomy achieves up to 23% MPE reduction compared to raw time series data
- Domain-specific features contribute most significantly to model performance improvements
- Sub-metering data enhances behavioral feature extraction, further improving forecasting accuracy

## Why This Works (Mechanism)
The taxonomy provides a structured framework that captures the multifaceted nature of electricity consumption patterns by systematically incorporating relevant feature categories. By organizing features into domain-specific, contextual, and behavioral groups, the approach ensures comprehensive representation of factors influencing electricity usage. This systematic feature engineering enables models to better capture underlying patterns in household electricity consumption, leading to improved forecasting accuracy. The taxonomy also facilitates model interpretability by providing clear feature categorization, making it easier to understand model decisions and identify key drivers of electricity consumption patterns.

## Foundational Learning

**Feature Engineering**: The systematic process of creating new features from raw data to improve model performance. Needed to capture complex relationships in electricity consumption patterns that raw data alone cannot represent. Quick check: Can you identify at least three ways to transform timestamp data into meaningful features?

**Taxonomy Design**: The hierarchical classification system for organizing features into meaningful categories. Required to provide structure and ensure comprehensive coverage of relevant factors affecting electricity consumption. Quick check: Does your taxonomy cover all three dimensions: domain knowledge, temporal context, and user behavior?

**Model Interpretability**: The degree to which a human can understand the cause of a decision made by a machine learning model. Essential for explainable ML applications in critical domains like electricity where decisions impact resource allocation and policy. Quick check: Can you trace model predictions back to specific feature categories and explain their influence?

## Architecture Onboarding

**Component Map**: Raw electricity consumption data -> Feature extraction (domain-specific, contextual, behavioral) -> Model training (linear regression, XGBoost, MLP, Prophet, N-BEATS) -> Performance evaluation (MPE, MSE) -> Interpretability analysis

**Critical Path**: Feature engineering using taxonomy -> Model training with engineered features -> Performance evaluation -> Interpretability validation

**Design Tradeoffs**: The taxonomy approach balances comprehensiveness with interpretability, potentially sacrificing some predictive power compared to black-box models. The use of multiple model types provides robustness but increases computational complexity. Feature engineering adds preprocessing overhead but improves model performance and interpretability.

**Failure Signatures**: Poor performance may indicate inadequate feature coverage in the taxonomy, insufficient domain knowledge incorporation, or inappropriate feature transformations. Interpretability issues may arise from overly complex feature interactions or inadequate documentation of feature derivation processes.

**First Experiments**:
1. Compare baseline model performance using raw time series data versus taxonomy-guided feature engineering
2. Conduct ablation studies to quantify individual contributions of each feature category (domain-specific, contextual, behavioral)
3. Test taxonomy effectiveness across different household types and consumption patterns to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to household electricity forecasting, limiting generalizability to grid-level or commercial applications
- Performance improvements are dataset-dependent and may not transfer across different geographical or climate conditions
- Explainability claims are based on model interpretability rather than causal inference or uncertainty quantification

## Confidence

**Taxonomy design and feature categorization**: High - The structured approach is well-defined and methodologically sound
**Performance improvements on tested datasets**: Medium - Results are statistically significant but may not generalize across different electricity applications
**Explainability claims**: Low - Limited discussion of interpretability mechanisms and their practical utility

## Next Checks

1. Test the taxonomy on grid-level load forecasting datasets and commercial/industrial electricity consumption patterns to evaluate generalizability
2. Compare performance against state-of-the-art transformer-based time series models like Informer or Autoformer to assess competitiveness
3. Conduct ablation studies to quantify the marginal contribution of each feature category (domain-specific, contextual, behavioral) across different model types and datasets