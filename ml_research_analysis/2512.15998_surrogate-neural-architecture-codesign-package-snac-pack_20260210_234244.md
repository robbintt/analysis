---
ver: rpa2
title: Surrogate Neural Architecture Codesign Package (SNAC-Pack)
arxiv_id: '2512.15998'
source_url: https://arxiv.org/abs/2512.15998
tags:
- search
- architecture
- snac-pack
- accuracy
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SNAC-Pack is an integrated framework that automates neural network
  design for FPGA deployment by combining multi-stage Neural Architecture Codesign
  with a fast resource estimation surrogate model. It enables multi-objective optimization
  across accuracy, FPGA resource utilization, and latency without requiring synthesis
  for each candidate model.
---

# Surrogate Neural Architecture Codesign Package (SNAC-Pack)

## Quick Facts
- arXiv ID: 2512.15998
- Source URL: https://arxiv.org/abs/2512.15998
- Reference count: 22
- Surrogate resource estimation enables multi-objective neural architecture search for FPGA deployment without full synthesis

## Executive Summary
SNAC-Pack is an integrated framework that automates neural network design for FPGA deployment by combining multi-stage Neural Architecture Codesign with a fast resource estimation surrogate model. It enables multi-objective optimization across accuracy, FPGA resource utilization, and latency without requiring synthesis for each candidate model. Applied to a jet classification task in high-energy physics, SNAC-Pack achieved 63.84% accuracy with resource estimation, matching baseline accuracy while maintaining comparable resource utilization to models optimized using traditional BOPs metrics. The framework demonstrates the potential of hardware-aware neural architecture search for resource-constrained deployments and provides an open-source tool for automating efficient FPGA-accelerated model design.

## Method Summary
SNAC-Pack combines multi-stage Neural Architecture Codesign (NAC) with the rule4ml surrogate model to automate FPGA-optimized neural network design. The framework uses a two-stage approach: global search explores architectural space using NSGA-II optimization with surrogate resource estimation, while local search applies quantization-aware training and iterative pruning to refine selected architectures. The global search evaluates 500 candidate architectures using 5 epochs each, optimizing for accuracy, estimated FPGA resources (DSP, LUT, FF, BRAM), and latency. The local search applies 10 iterations of 20% magnitude pruning with 8-bit quantization. Final models are synthesized using hls4ml for Xilinx Virtex UltraScale+ VU13P FPGAs.

## Key Results
- Achieved 63.84% accuracy on 5-class jet classification matching baseline performance
- Surrogate estimation enabled exploration of 500 architectures without synthesis
- Produced comparable FPGA resource utilization to BOPs-optimized baseline models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Surrogate resource estimation accelerates architecture search by avoiding full synthesis for each candidate.
- Mechanism: The rule4ml surrogate model predicts FPGA resource utilization (BRAM, DSP, FF, LUT) and latency metrics from architectural specifications, enabling rapid evaluation during search. This replaces the traditional approach where each candidate requires time-intensive HLS synthesis.
- Core assumption: The surrogate model's predictions correlate sufficiently with actual synthesized resource usage to guide search toward truly optimal architectures.
- Evidence anchors:
  - [abstract] "enabling multi-objective optimization across accuracy, FPGA resource utilization, and latency without requiring time-intensive synthesis for each candidate model"
  - [section 3] "With NAC integration, the global search stage begins with a user-defined search space... Any combination of the metrics estimated by rule4ml, BOPs, and accuracy can be used as objectives in the search"
  - [corpus] Related work on surrogate models (HLSpredict, GNN-based prediction) supports viability of this approach, though corpus lacks direct validation of rule4ml accuracy
- Break condition: If surrogate predictions diverge significantly from actual synthesis results (as suggested by latency discrepancy in Table 3), the search may converge to suboptimal architectures.

### Mechanism 2
- Claim: Multi-objective evolutionary search with NSGA-II produces a Pareto front balancing accuracy, resources, and latency simultaneously.
- Mechanism: NSGA-II explores the architectural search space using non-dominated sorting to maintain a diverse set of solutions representing trade-offs between competing objectives, rather than optimizing a single proxy metric like BOPs.
- Core assumption: The search space defined by layer counts, hidden units, activations, and regularization contains architectures that satisfy all constraints simultaneously.
- Evidence anchors:
  - [section 3] "A multi-objective search algorithm then explores this space, samples candidate architectures, and performs evaluation"
  - [section 4] "The global search uses the Non-dominated Sorting Generic Algorithm II (NSGA-II), exploring a search space of varying number of layers, hidden units per layer, activations, and batch normalization"
  - [corpus] Neural Architecture Codesign paper [1] establishes the multi-stage NAS foundation; corpus confirms NAS methods can discover efficient architectures
- Break condition: If the Pareto front is sparse or contains no solutions meeting minimum accuracy thresholds, the search fails to find viable candidates.

### Mechanism 3
- Claim: Two-stage codesign (global search → local search) separates architecture discovery from precision optimization.
- Mechanism: Global search identifies promising architectural patterns using fast surrogate feedback. Local search then applies quantization-aware training (QAT) and iterative magnitude pruning to refine the selected architecture for hardware efficiency.
- Core assumption: Architecture-level decisions and precision/sparsity decisions can be decoupled without significant loss of optimality.
- Evidence anchors:
  - [section 2] "NAC is a multi-stage NAS, consisting of a global and local search... local search performs model compression, including quantization-aware-training (QAT) and pruning"
  - [section 4] "For local search, each selected architecture has a 5 epoch warm-up, followed by 10 iterations of iterative magnitude pruning, each 10 epochs, with 20% pruned per iteration, with QAT at 8-bit precision"
  - [corpus] NAC paper [1] validates this approach; hls4ml ecosystem provides QAT tools for FPGA deployment
- Break condition: If pruning or quantization destroys accuracy, the two-stage assumption fails; architectures may need joint optimization.

## Foundational Learning

- Concept: **FPGA Resource Types (DSP, LUT, FF, BRAM)**
  - Why needed here: SNAC-Pack optimizes against these specific hardware constraints; understanding what each resource provides (DSP for arithmetic, BRAM for storage, LUT/FF for logic) is essential for interpreting optimization results.
  - Quick check question: Which FPGA resource would a large dense matrix multiplication primarily consume?

- Concept: **Quantization-Aware Training (QAT)**
  - Why needed here: Local search applies QAT to reduce precision from floating-point to fixed-point (8-bit in experiments); this differs from post-training quantization and affects accuracy.
  - Quick check question: Why does QAT typically preserve accuracy better than quantizing a pre-trained model without retraining?

- Concept: **Pareto Optimality and Multi-Objective Optimization**
  - Why needed here: The framework produces Pareto fronts showing trade-offs; selecting an architecture requires understanding which solutions are non-dominated across objectives.
  - Quick check question: On a Pareto front of accuracy vs. resource usage, what does it mean for one architecture to "dominate" another?

## Architecture Onboarding

- Component map:
  User Search Space Definition -> Global Search (NSGA-II + rule4ml surrogate) -> Pareto Front -> User Selection -> Local Search (QAT + Iterative Pruning) -> hls4ml Synthesis -> FPGA Bitstream

- Critical path:
  1. Define search space (Table 1 provides starting template)
  2. Configure objectives (accuracy + estimated resources + clock cycles)
  3. Run global search (500 trials, 5 epochs each in experiments)
  4. Filter Pareto front by accuracy threshold (≥0.638 in experiments)
  5. Apply local search with pruning schedule (10 iterations, 20% per iteration)
  6. Synthesize with hls4ml and validate against predictions

- Design tradeoffs:
  - More search trials/epochs → better coverage but longer runtime
  - Stricter accuracy threshold → fewer candidates for local search
  - Aggressive pruning → smaller model but potential accuracy loss
  - Surrogate vs. BOPs optimization: surrogate provides latency awareness but may misestimate absolute resource usage (Table 3 shows SNAC-Pack model has higher latency than baseline)

- Failure signatures:
  - Surrogate predicts low resources but synthesis reports high usage → surrogate model may be inaccurate for specific architecture patterns
  - Pareto front contains only low-accuracy solutions → search space may be misconfigured or constraints too strict
  - Pruning collapses accuracy → model may be over-pruned; reduce pruning ratio or add recovery epochs

- First 3 experiments:
  1. **Reproduce jet classification baseline**: Run SNAC-Pack with the exact configuration from Table 1, compare Pareto front to Figures 1-3, validate that synthesized model matches reported accuracy (~63.84%) and resource usage.
  2. **Surrogate accuracy validation**: Select 10 architectures from global search, synthesize all with hls4ml, compare actual vs. predicted resource usage to quantify surrogate error (especially for latency, where Table 3 shows discrepancy).
  3. **Objective ablation**: Run three searches optimizing for (a) accuracy only, (b) accuracy + BOPs (baseline NAC), (c) accuracy + surrogate resources (SNAC-Pack). Compare synthesized results to isolate the contribution of hardware-aware objectives.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can incorporating surrogate models trained on larger, more diverse datasets improve the accuracy of resource estimation sufficiently to outperform traditional BOPs-based optimization?
- Basis in paper: [explicit] The conclusion states that "incorporating additional surrogate models trained on large datasets in future work can be an enhancement... [so that] the estimation of resources can be refined."
- Why unresolved: The current study found SNAC-Pack performed comparably to, but not strictly better than, the BOPs-optimized NAC model in terms of final synthesized metrics.
- What evidence would resolve it: A future study demonstrating that an updated SNAC-Pack framework utilizing a refined surrogate model discovers architectures with lower actual latency and resource usage than those found via BOPs optimization.

### Open Question 2
- Question: To what extent does the current resource estimation model contribute to the discrepancy between estimated clock cycles and actual synthesized latency?
- Basis in paper: [inferred] The paper notes that while the SNAC-Pack model matched other metrics, it "can improve in terms of latency" (140ns vs 125ns for NAC), stating this is an "indicator of a need to improve the estimation of resources themselves."
- Why unresolved: The framework optimizes for estimated metrics, but the resulting optimal model exhibited higher latency than the baseline, suggesting the surrogate may not accurately capture the complex relationship between architecture and final timing.
- What evidence would resolve it: A correlation analysis comparing rule4ml latency predictions against post-synthesis timing reports across the entire search space to identify systematic underestimation biases.

### Open Question 3
- Question: Is the SNAC-Pack framework effective for neural architectures beyond Multi-Layer Perceptrons (MLPs), such as Convolutional or Recurrent Neural Networks?
- Basis in paper: [inferred] The implementation section restricts the demonstration to a specific MLP search space for jet classification, leaving the applicability to other layer types unverified.
- Why unresolved: While the underlying tools (NAC, rule4ml) are designed generally, the paper's experimental validation is limited to MLPs with specific hyperparameters (layers, units, activations).
- What evidence would resolve it: Successful application of SNAC-Pack to a CNN or RNN-based task, demonstrating comparable accuracy and resource estimation capabilities.

## Limitations

- Surrogate model shows latency underestimation compared to actual synthesis results (140ns vs 125ns for baseline)
- Limited generalizability beyond 8-particle jet classification dataset
- Two-stage approach assumes architecture and precision optimizations can be effectively decoupled
- Search space restricted to MLPs, excluding potentially more efficient architectures

## Confidence

- **High Confidence**: Multi-stage NAC framework integration with rule4ml surrogate for fast resource estimation
- **Medium Confidence**: Pareto-optimal solutions achieving 63.84% accuracy
- **Low Confidence**: Surrogate model's absolute accuracy for FPGA resource prediction

## Next Checks

1. **Surrogate Accuracy Benchmark**: Synthesize 20 random architectures from the global search Pareto front and compare rule4ml-predicted vs. hls4ml-measured resource usage across all four FPGA resources (DSP, LUT, FF, BRAM) and latency metrics to establish prediction error bounds.

2. **Search Space Generalization**: Apply SNAC-Pack to a different physics classification task (e.g., particle identification or energy regression) using the same search space to test whether architectural patterns transfer across problems or require task-specific tuning.

3. **Two-Stage Decoupling Validation**: Modify the local search to include joint optimization of architecture and quantization during global search (single-stage approach), then compare Pareto fronts to the published two-stage results to quantify the impact of the decoupling assumption.