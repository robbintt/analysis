---
ver: rpa2
title: Prediction of Lane Change Intentions of Human Drivers using an LSTM, a CNN
  and a Transformer
arxiv_id: '2507.08365'
source_url: https://arxiv.org/abs/2507.08365
tags:
- prediction
- lstm
- which
- time
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of predicting lane change intentions
  of human drivers in highway scenarios. The goal is to classify whether a target
  vehicle will perform a lane change maneuver (left or right) or maintain its lane
  within a future time interval, rather than at a specific instant.
---

# Prediction of Lane Change Intentions of Human Drivers using an LSTM, a CNN and a Transformer

## Quick Facts
- arXiv ID: 2507.08365
- Source URL: https://arxiv.org/abs/2507.08365
- Reference count: 32
- Primary result: Transformer networks achieved best overall performance (82.79%-96.73% accuracy) for lane change prediction

## Executive Summary
This paper addresses the challenge of predicting lane change intentions of human drivers on highways. The authors propose three machine learning approaches - LSTM, CNN, and Transformer networks - to classify whether a target vehicle will perform a left lane change, right lane change, or maintain its lane within a future time interval. Using the highD dataset of naturalistic vehicle trajectories, they systematically compare these architectures across different observation windows and prediction horizons. The Transformer-based approach (TN 2) consistently outperformed the other architectures, achieving up to 96.73% accuracy, though the study also revealed that right lane changes are harder to predict than left lane changes, especially at longer prediction horizons.

## Method Summary
The authors formulate lane change prediction as a 3-class classification problem using naturalistic driving data from the highD dataset. They designed their models to predict lane changes within a time interval rather than at a specific instant, extracting features from both the target vehicle and up to 8 surrounding vehicles. The input consists of 36 features including position, velocity, and relative distances/velocities, sampled at 25Hz. Three architectures were implemented: LSTM (2 stacked layers), CNN (2 convolutional layers with batch normalization), and Transformer (1 encoder layer with 16 attention heads). The models were trained using balanced data across lane keeping, left lane changes, and right lane changes, with random prediction times within the target interval to improve generalization. Performance was evaluated across twelve configurations varying observation window (1-3s) and maximum prediction time (3-6s).

## Key Results
- Transformer networks (TN 2) achieved the best overall performance, with accuracies ranging from 82.79% to 96.73% across different input configurations
- TN 2 consistently outperformed both LSTM and CNN architectures in most tested scenarios, though CNN 3 came close in several cases
- Right lane changes were systematically harder to predict than left lane changes, with F1 scores for RLC deteriorating faster than LLC as prediction time increased
- Longer prediction horizons (5-6s) showed significant accuracy degradation, suggesting 3-4s as a practical compromise
- Models showed overfitting measured by train-test accuracy gap (∆acc), with TN 2 demonstrating better generalization than CNN 3 and LSTM 2

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Predicting lane changes within a time interval rather than at a fixed instant produces models that generalize across varying temporal distances to the maneuver.
- Mechanism: During training, each lane change sample is assigned a random prediction time ∆tp uniformly distributed between 0 and ∆tp,MAX. This forces the model to recognize behavioral precursors at any point within the interval rather than memorizing patterns at a specific time-to-lane-change.
- Core assumption: Driver intention manifests through gradual behavioral signals rather than appearing abruptly at a deterministic time before the maneuver.
- Evidence anchors:
  - [abstract]: "few concentrated on predicting maneuvers within a set time interval compared to predicting at a set prediction time... the latter might reveal itself more versatile"
  - [section II.C, Fig. 2]: Explicit description of random ∆tp extraction and its effect on training data generation
  - [corpus]: Limited direct comparison available; arxiv:2509.17354 also uses interval-based prediction but does not systematically compare to fixed-time approaches
- Break condition: When ∆tp,MAX exceeds the temporal window where consistent behavioral precursors exist (paper shows degradation starting ~2-3s before LC instant)

### Mechanism 2
- Claim: Transformer's multi-head attention captures temporal relationships across the observation window more effectively than sequential or convolutional processing.
- Mechanism: The attention mechanism computes pairwise relationships between all timesteps simultaneously via query-key-value projections. Multiple heads (16 in TN 2) learn different temporal pattern subspaces—one head may track lateral drift, another may monitor relative velocity changes to surrounding vehicles. The positional encoding preserves temporal order information.
- Core assumption: Lane change precursors involve complex, non-local temporal dependencies that benefit from direct access to all timesteps.
- Evidence anchors:
  - [section III.C]: "The key idea of TNs is to find relationships between the elements of an input sequence and exploit this information"
  - [section IV.E, Fig. 12-14]: TN 2 consistently shows lower ∆acc (train-test gap) than CNN 3 and LSTM 2, indicating better generalization
  - [corpus]: arxiv:2509.17354 confirms Transformer-based methods show promise for lane-change prediction
- Break condition: When observation window is too short for meaningful temporal relationships; paper tested down to 1s with some success but longer windows did not consistently help

### Mechanism 3
- Claim: Encoding the kinematic state of up to 8 surrounding vehicles provides essential context for inferring lane change motivation.
- Mechanism: The 36-feature input vector includes the target vehicle's position and velocity plus relative distances and velocities to surrounding vehicles (preceding, following, left preceding, left alongside, left following, right preceding, right alongside, right following). This captures gap-seeking behavior and interaction dynamics that pure ego-vehicle kinematics cannot.
- Core assumption: Lane changes are motivated by traffic context—drivers seek gaps, optimize speed, or respond to surrounding vehicle behavior.
- Evidence anchors:
  - [section II.A, Fig. 1]: Diagram showing 8 surrounding vehicles tracked for each target
  - [section II.D, Table I]: Feature list explicitly includes lateral/longitudinal distance and velocity of surrounding vehicles relative to target
  - [corpus]: arxiv:2509.22550 emphasizes heterogeneous cooperation in mixed-traffic environments as critical for lane change decisions
- Break condition: When surrounding vehicle data is missing, occluded, or noisy—this scenario is not tested in the paper but represents a real-world limitation

## Foundational Learning

- Concept: **Sequence-to-label classification**
  - Why needed here: Understanding how LSTM, CNN, and Transformer architectures map variable-length time series to discrete class labels is fundamental to selecting and debugging models.
  - Quick check question: Given a 3-second observation window at 25Hz, what is the shape of the input tensor before embedding?

- Concept: **Class imbalance handling**
  - Why needed here: Lane keeping naturally occurs more frequently than lane changes; the paper explicitly balances training data by limiting LK samples to match LLC+RLC count.
  - Quick check question: If you trained on unbalanced data with 90% LK samples and achieved 90% accuracy, why might this be misleading?

- Concept: **Overfitting quantification via train-test gap**
  - Why needed here: The ∆acc metric (training accuracy minus test accuracy) directly measures overfitting; TN 2 showed consistently lower ∆acc than CNN 3 and LSTM 2.
  - Quick check question: If training accuracy is 99% and test accuracy is 82%, what specific regularization techniques might you try?

## Architecture Onboarding

- Component map:
  Input: 36 features × n timesteps → TN 2: Linear embedding (36→16) → Sinusoidal positional encoding → Encoder (1 layer, 16 heads, FF width 128) → Linear classifier → 3-class softmax
  CNN 3: 1D Conv (18 filters, kernel 2, stride 1) → BatchNorm → ReLU → MaxPool → Conv → FC (64→32) → Softmax
  LSTM 2: 2 stacked LSTM layers (hidden dim 2 each) → FC → Softmax

- Critical path:
  1. Coordinate transformation: Account for driving direction by inverting sign of features (Eq. 1-8)
  2. Trajectory extraction: Sample LC segments with random ∆tp ∈ [0, ∆tp,MAX]; sample one LK segment per trajectory
  3. Class balancing: Limit LK training samples to sum of LLC and RLC counts
  4. Train/val/test split: 60/20/20 with fixed seeds for reproducibility

- Design tradeoffs:
  - ∆tp,MAX: Higher values (5-6s) enable earlier warnings but accuracy drops significantly (96.73%→82.79% for TN 2); paper recommends 3-4s as practical compromise
  - ∆to: Longer observation windows did not consistently improve results; CNN 3 performed slightly better with shorter windows (1s)
  - Model complexity: TN 3 (4 encoder layers) underperformed TN 2 (1 layer), suggesting over-parameterization risk

- Failure signatures:
  - Right lane changes (RLC) systematically underperform left lane changes (LLC) at longer prediction horizons (see F1,RLC vs F1,LLC in Tables VII-IX)
  - Performance degradation begins ~2-3s before LC instant regardless of model architecture
  - Confusion matrices show misclassification primarily between LC↔LK, not LLC↔RLC

- First 3 experiments:
  1. Replicate TN 2 (∆to=2s, ∆tp,MAX=3s) on highD dataset; target accuracy ~96.7% with ∆acc <1%
  2. Ablation study: Remove surrounding vehicle features (use only 4 ego-vehicle features); quantify accuracy drop to assess context contribution
  3. Cross-dataset validation: Train on highD, test on NGSIM or different highD recording locations to assess generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the underlying causes for the discrepancy in prediction difficulty between Right Lane Changes (RLCs) and Left Lane Changes (LLCs), particularly at longer prediction horizons?
- Basis in paper: [Explicit] The Conclusion states the authors wish to "investigate the reasons of the difference in performance for LLCs and RLCs," while the Results section notes that F1 scores for RLCs deteriorate faster than LLCs as prediction time increases.
- Why unresolved: The authors hypothesize that the difference may be due to variances in traffic density between "fast" and "slow" lanes or differences in maneuver execution times, but they do not perform the necessary statistical analysis to confirm these theories.
- What evidence would resolve it: A detailed analysis of the correlation between prediction errors and specific traffic density metrics, or a comparison of the temporal execution profiles of RLCs versus LLCs in the dataset.

### Open Question 2
- Question: How robust are the proposed Transformer and CNN architectures when applied to driving scenarios and datasets different from the German highways captured in highD?
- Basis in paper: [Explicit] The Conclusion explicitly recommends testing "our algorithms on an array of different datasets to better understand how they would react to different situations."
- Why unresolved: The entire study is confined to the highD dataset. It is unknown if the models rely on dataset-specific biases (e.g., German lane discipline) or if the findings regarding Transformer superiority generalize to urban or US highway environments.
- What evidence would resolve it: Benchmarking the trained TN 2 and CNN 3 models on alternative naturalistic trajectory datasets (e.g., NGSIM, Waymo, or inD) without retraining, or by evaluating performance after fine-tuning on such data.

### Open Question 3
- Question: To what extent does the integration of interval-based lane change prediction improve safety, comfort, and energy efficiency in Level 4 automated driving motion planning?
- Basis in paper: [Explicit] The Conclusion states the authors would "like to implement the prediction of lane change intention in L4 vehicle motion planning algorithms to test their performance with respect to safety, comfort and energy efficiency."
- Why unresolved: The current work evaluates the models solely on classification metrics (Accuracy, F1) in an offline environment. The impact of these predictions on the dynamic behavior of an autonomous vehicle remains unquantified.
- What evidence would resolve it: Closed-loop simulation results or real-world testing data comparing the key performance indicators (collision rates, acceleration jerk, energy consumption) of an L4 planner equipped with this predictor versus a baseline planner.

### Open Question 4
- Question: What is the effect of the random uniform sampling of prediction times (∆tp) on the model's ability to generalize compared to fixed-time prediction approaches?
- Basis in paper: [Inferred] The authors argue that predicting within a time interval is more "versatile" than predicting at a set instant, but they do not empirically compare their interval-based training method against the fixed-time baseline methods they cite to prove superior robustness.
- Why unresolved: While the method produces high accuracy, it is unclear if the uniform sampling of prediction times introduces noise or if it truly prevents the "blind spots" associated with fixed-time models as claimed.
- What evidence would resolve it: A comparative study where the same architecture is trained using the interval method versus a fixed-time method, evaluated on a test set containing specific, critical time steps (e.g., 1s, 2s, 3s before the maneuver).

## Limitations
- The study is confined to German highway data from the highD dataset, limiting generalizability to other driving environments
- Missing vehicle handling is not explicitly specified, creating uncertainty about edge case performance
- The conclusion that longer observation windows don't improve accuracy is based on a narrow window range (1-3s) and may not generalize

## Confidence
- **High confidence**: Transformer superiority over LSTM/CNN for lane change prediction within the tested configuration space (∆to=2s, ∆tp,MAX=3s-4s)
- **Medium confidence**: The claim that interval-based prediction generalizes better than fixed-time prediction; limited comparative data exists in the corpus
- **Medium confidence**: The assertion that RLC prediction is inherently harder than LLC; while demonstrated, the paper doesn't explore underlying causal factors
- **Low confidence**: The finding that longer observation windows don't improve accuracy; this conclusion is based on a narrow window range and may not generalize

## Next Checks
1. **Surroundings ablation study**: Train models using only ego-vehicle kinematics (4 features vs 36) to quantify the contribution of traffic context to prediction accuracy
2. **Cross-dataset validation**: Test trained models on NGSIM or different highD recording locations to assess generalization beyond the training distribution
3. **Edge case robustness test**: Systematically evaluate model performance when surrounding vehicle data is missing or occluded, simulating real-world sensor limitations