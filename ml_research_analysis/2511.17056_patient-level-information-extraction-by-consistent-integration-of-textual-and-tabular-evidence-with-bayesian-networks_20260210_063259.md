---
ver: rpa2
title: Patient-level Information Extraction by Consistent Integration of Textual and
  Tabular Evidence with Bayesian Networks
arxiv_id: '2511.17056'
source_url: https://arxiv.org/abs/2511.17056
tags:
- text
- training
- evidence
- tabular
- change
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a method for patient-level information extraction
  that integrates structured tabular EHR data with unstructured clinical notes. The
  approach uses an expert-informed Bayesian network to model tabular evidence and
  neural text classifiers to extract symptom information from clinical notes.
---

# Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks

## Quick Facts
- **arXiv ID**: 2511.17056
- **Source URL**: https://arxiv.org/abs/2511.17056
- **Reference count**: 40
- **Primary result**: Multimodal Bayesian network integration outperforms text-only extraction on EHR symptom extraction task

## Executive Summary
This work introduces a method for patient-level information extraction that integrates structured tabular EHR data with unstructured clinical notes. The approach uses an expert-informed Bayesian network to model tabular evidence and neural text classifiers to extract symptom information from clinical notes. Virtual evidence and a consistency node probabilistically combine predictions from both modalities, improving calibration and handling missing or contradictory information. On the SimSUM dataset, the combined model significantly outperforms text-only and multimodal baselines in average precision and Brier score, especially for symptoms with limited mention in clinical notes.

## Method Summary
The method combines Bayesian network modeling of tabular EHR features with neural text classification of clinical notes. An expert-informed Bayesian network models dependencies between tabular features and symptoms, providing calibrated probabilities. Neural text classifiers extract symptom mentions from clinical notes. The two modalities are integrated using virtual evidence nodes that inject text classifier predictions into the Bayesian network, and a consistency node that probabilistically reconciles conflicting evidence. This architecture handles missing data naturally and provides interpretable probabilistic outputs while improving performance particularly for symptoms under-represented in clinical text.

## Key Results
- Combined multimodal model outperforms text-only baseline on SimSUM dataset (average precision: 0.83 vs 0.75)
- Significant improvements in Brier score (0.14 vs 0.19) indicating better probability calibration
- Largest gains observed for symptoms with minimal clinical note mentions, demonstrating value of tabular integration

## Why This Works (Mechanism)
The approach works by leveraging complementary information sources: structured tabular data provides reliable but potentially incomplete symptom indicators, while unstructured clinical notes capture nuanced clinical observations but may miss systematic patterns. The Bayesian network captures domain knowledge about relationships between features and symptoms, while neural classifiers excel at extracting symptom mentions from text. Virtual evidence nodes allow text predictions to inform the probabilistic model without retraining, and the consistency node resolves contradictions by weighing evidence reliability. This integration exploits both modalities' strengths while mitigating their individual weaknesses.

## Foundational Learning
- **Bayesian networks**: Probabilistic graphical models representing dependencies between variables; needed for modeling complex relationships between tabular features and symptoms; quick check: verify structure encodes known clinical relationships
- **Virtual evidence**: Technique for incorporating external evidence into Bayesian networks without modifying structure; needed to integrate text classifier outputs; quick check: confirm proper implementation of likelihood ratios
- **Neural text classification**: Deep learning models for extracting structured information from unstructured text; needed for symptom extraction from clinical notes; quick check: validate classification accuracy on held-out notes
- **Multimodal integration**: Combining predictions from different data modalities; needed to leverage complementary information sources; quick check: assess calibration of combined probabilities
- **Brier score**: Proper scoring rule for evaluating probabilistic predictions; needed to measure calibration quality; quick check: compare against other metrics like log loss
- **Expert-informed modeling**: Incorporating domain knowledge into model structure; needed for medical applications where data may be limited; quick check: validate structure with clinical experts

## Architecture Onboarding

**Component Map**: Neural text classifiers -> Virtual evidence nodes -> Consistency node -> Bayesian network -> Symptom predictions

**Critical Path**: Clinical notes → Text classifiers → Virtual evidence → Consistency node → Bayesian network inference → Symptom probability estimates

**Design Tradeoffs**: The approach trades computational efficiency during inference (Bayesian network inference can be slower than simple fusion) for improved calibration and interpretability. Using expert-informed Bayesian networks rather than learned structures reduces data requirements but may miss unexpected relationships. The virtual evidence approach allows independent training of text classifiers but prevents joint optimization.

**Failure Signatures**: Poor performance when clinical notes and tabular data provide contradictory evidence that the consistency node cannot resolve. Degradation when Bayesian network structure misses important dependencies. Suboptimal results when text classifiers are poorly calibrated or when tabular features are highly noisy.

**First Experiments**: 1) Ablation study removing consistency node to measure its impact on handling contradictions, 2) Evaluation on real clinical data to assess synthetic dataset limitations, 3) Sensitivity analysis varying the reliability parameters of virtual evidence nodes.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on synthetic SimSUM dataset may not capture real-world clinical data complexity and quality issues
- Simplified Bayesian network structure may miss important dependencies between symptoms and features
- Neural text classifiers trained independently from tabular model, missing joint optimization opportunities
- Validation of contradiction resolution limited to simulated contradictions rather than authentic clinical disagreements

## Confidence
- **High confidence** in the core technical approach combining Bayesian networks with neural text classifiers for multimodal integration
- **Medium confidence** in the generalizability of results to real clinical data, given synthetic dataset limitations
- **Medium confidence** in the robustness across training sizes, as evaluation was limited to the SimSUM environment

## Next Checks
1. **Real-world validation**: Evaluate the approach on authentic EHR datasets with verified ground truth to assess performance degradation and identify domain-specific challenges not present in synthetic data.

2. **Error analysis granularity**: Conduct detailed analysis of which symptom types benefit most from multimodal integration and identify failure modes when clinical notes contradict tabular data.

3. **Scalability testing**: Assess computational efficiency and prediction quality when scaling to larger numbers of symptoms and features, particularly the Bayesian network inference time with increased complexity.