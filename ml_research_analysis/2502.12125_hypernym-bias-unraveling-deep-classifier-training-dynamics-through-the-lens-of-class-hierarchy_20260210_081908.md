---
ver: rpa2
title: 'Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the Lens
  of Class Hierarchy'
arxiv_id: '2502.12125'
source_url: https://arxiv.org/abs/2502.12125
tags:
- training
- hypernym
- label
- neural
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how deep neural networks learn hierarchical
  class relationships during training. The authors propose a novel framework to track
  the evolution of feature manifolds, revealing that networks tend to learn higher-level
  (hypernym) categories early in training and more specific (hyponym) categories later.
---

# Hypernym Bias: Unraveling Deep Classifier Training Dynamics through the Lens of Class Hierarchy

## Quick Facts
- arXiv ID: 2502.12125
- Source URL: https://arxiv.org/abs/2502.12125
- Reference count: 40
- Primary result: Deep networks learn higher-level (hypernym) categories significantly faster than specific (hyponym) categories during training

## Executive Summary
This paper introduces the concept of "hypernym bias" in deep neural network training, demonstrating that classifiers tend to learn broader, more abstract category representations before mastering specific, detailed classifications. Through systematic experiments across multiple architectures (ResNet, ViT, MobileNet) and datasets, the authors show that hypernym classification accuracy consistently converges faster than hyponym accuracy. The study provides novel metrics to quantify this phenomenon and establishes connections to neural collapse theory, suggesting that hierarchical learning patterns bridge the gap between early and late-stage training dynamics.

## Method Summary
The authors propose a framework for tracking feature manifold evolution during deep network training by leveraging the hierarchical structure of class labels. They construct dual label spaces - hypernym (parent) and hyponym (child) categories - from existing taxonomies, then train networks on these label sets in parallel. By monitoring accuracy metrics across training epochs for both label spaces, they quantify the temporal difference in learning rates between abstract and specific concepts. The methodology includes introducing relative accuracy and relative gain metrics to measure hypernym bias, along with careful experimental controls across different architectures and datasets to validate the robustness of the observed phenomenon.

## Key Results
- Hypernym classification accuracy converges 2-3x faster than hyponym accuracy across all tested architectures
- The relative accuracy metric shows consistent hypernym bias regardless of network depth or vision transformer vs CNN architecture
- Neural collapse properties (e.g., within-class compactness) manifest earlier in hypernym label spaces compared to hyponym spaces

## Why This Works (Mechanism)
The paper suggests that hypernym bias emerges from the optimization landscape's geometry, where broader decision boundaries are easier to establish early in training before fine-grained distinctions are learned. This hierarchical learning pattern may reflect the natural semantic structure of visual concepts, where abstract category membership is determined by simpler, more robust features than specific subclass distinctions. The connection to neural collapse indicates that this phenomenon is tied to fundamental properties of how deep networks organize feature representations during training.

## Foundational Learning
- Neural Collapse: Understanding when and how feature representations become linearly separable
  - Why needed: Provides theoretical framework for interpreting training dynamics
  - Quick check: Verify within-class and between-class covariance matrices at different training stages

- Hierarchical Classification: Relationship between parent and child categories in label taxonomy
  - Why needed: Enables construction of dual-label experiments
  - Quick check: Ensure taxonomic consistency and absence of cyclic dependencies

- Manifold Learning: How feature spaces evolve during training
  - Why needed: Core to understanding hypernym bias mechanism
  - Quick check: Track feature distribution statistics across epochs

## Architecture Onboarding

Component Map:
Input Images -> Backbone Network -> Classifier Head -> Hypernym/Hyponym Output Layers

Critical Path:
Data augmentation → Feature extraction → Classification → Accuracy computation for both label spaces → Relative metrics calculation

Design Tradeoffs:
- Computational cost: Running dual-label training doubles memory requirements
- Label quality: Depends on accuracy of existing taxonomies
- Granularity choice: Selecting appropriate hypernym/hyponym pairs affects results

Failure Signatures:
- If taxonomies are inconsistent, relative metrics become meaningless
- Imbalanced class distributions can mask true hypernym bias
- Early stopping before convergence prevents observing full phenomenon

First Experiments:
1. Train ResNet-50 on ImageNet with hypernym/hyponym labels to establish baseline
2. Replicate with ViT to test architecture independence
3. Vary learning rates to examine optimization sensitivity

## Open Questions the Paper Calls Out
The paper identifies several areas for future research, including extending the analysis to non-visual domains like natural language processing and speech recognition, investigating whether self-supervised learning exhibits similar hierarchical learning patterns, and exploring potential applications in curriculum learning and few-shot classification where understanding the natural order of concept acquisition could be beneficial.

## Limitations
- Empirical focus without strong theoretical foundation for why hypernym bias occurs
- Limited to ImageNet-style taxonomies, raising generalization concerns
- Potential confounding from class imbalance and semantic similarity not fully addressed

## Confidence
- Hypernym bias observation: High
- Metrics validity: Medium
- Neural collapse connection: Low-Medium
- Generalization across domains: Low

## Next Checks
1. Replicate experiments on non-image domains (text, speech) with hierarchical label structures to test domain generalization
2. Conduct ablation studies varying class imbalance ratios and semantic similarity thresholds to isolate hypernym bias from confounding factors
3. Implement theoretical analysis connecting optimization dynamics to the observed temporal ordering of hypernym vs hyponym learning