---
ver: rpa2
title: Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution
arxiv_id: '2506.14529'
source_url: https://arxiv.org/abs/2506.14529
tags:
- knowledge
- graph
- llmnet
- agent
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLMNet is a system that automates GNN design using large language
  models and knowledge-guided evolution. It constructs two knowledge bases (prior
  and experimental) and employs specialized agents with retrieval-augmented generation
  to design GNN architectures.
---

# Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution

## Quick Facts
- arXiv ID: 2506.14529
- Source URL: https://arxiv.org/abs/2506.14529
- Reference count: 6
- Primary result: LLMNet outperforms GNN baselines and AutoML methods across 12 datasets using knowledge-guided evolution

## Executive Summary
LLMNet is a system that automates GNN architecture design using large language models and knowledge-guided evolution. It constructs two knowledge bases (prior and experimental) and employs specialized agents with retrieval-augmented generation to design GNN architectures. The system achieves superior performance on twelve datasets across three graph learning tasks, demonstrating that knowledge base integration significantly enhances LLMNet's ability to understand tasks and design effective models.

## Method Summary
LLMNet employs a multi-agent pipeline with two knowledge bases (prior and experimental) built through two-level extraction. The system uses RAG retrieval with all-MiniLM-L6-v2 embeddings and cosine similarity for post-ranking. Four specialized agents work in sequence: Planning Agent (task planning and revision), Data Agent (feature engineering), Configuration Agent (search space setup), and Evaluation Agent (fine-tuning and validation). The system dynamically updates its experimental knowledge base after each run, enabling continuous learning and improvement across tasks including node classification, graph classification, and link prediction.

## Key Results
- Achieves superior performance across 12 datasets compared to GCN, GraphSAGE, AutoML methods, and LLM-only approaches
- Demonstrates significant average ranking improvements across node classification, graph classification, and link prediction tasks
- Knowledge base integration enhances LLMNet's task understanding and model design effectiveness

## Why This Works (Mechanism)
The knowledge-guided evolution mechanism works by combining prior knowledge from established sources with experimental results from previous runs. The two-level extraction process creates comprehensive knowledge bases that enable RAG retrieval to provide relevant context for each agent's decision-making. This integration allows LLMNet to leverage both established GNN design principles and task-specific insights, leading to more effective architecture configurations than approaches relying solely on LLMs or traditional AutoML methods.

## Foundational Learning
- GNN architecture design: Understanding graph neural network components and design choices is essential for configuring effective models
  - Why needed: Core to the system's ability to generate and evaluate GNN architectures
  - Quick check: Can identify key GNN components (message passing, aggregation, update functions)

- Knowledge base construction: Two-level extraction process for building comprehensive knowledge repositories
  - Why needed: Enables RAG retrieval to provide relevant context for agent decision-making
  - Quick check: Can extract both summarized documents and fine-grained task-specific details

- Multi-agent coordination: Specialized agents working in sequence with knowledge base queries
  - Why needed: Ensures systematic approach to GNN design with appropriate expertise at each stage
  - Quick check: Each agent performs its designated function and queries knowledge base appropriately

## Architecture Onboarding

**Component Map:** Knowledge Bases -> RAG Retrieval -> Multi-Agent Pipeline -> GNN Generation -> Evaluation -> Knowledge Update

**Critical Path:** Planning Agent -> Configuration Agent -> Evaluation Agent -> Knowledge Update

**Design Tradeoffs:**
- Static vs dynamic knowledge bases: LLMNet uses dynamic updating for continuous learning
- LLM-only vs knowledge-guided: Knowledge integration provides superior performance
- Automated vs manual design: Fully automated approach requires robust error handling

**Failure Signatures:**
- RAG retrieves irrelevant knowledge: Poor task understanding and suboptimal GNN designs
- Generated GNN code fails: Pipeline breakdown requiring manual intervention
- Performance degradation without knowledge updates: Loss of learning from experimental results

**First Experiments:**
1. Test RAG retrieval with PyG documentation to verify retrieval relevance and quality
2. Run minimal two-agent system (planning + configuration) to test GNN code generation pipeline
3. Compare LLMNet performance with and without knowledge base updates on single dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Specific LLM model and API used for agents remain unspecified
- Exact prompts for each agent and GNN architecture representation methods are not detailed
- Retrieval hyperparameters (k value, post-ranking algorithm) lack specification
- Training hyperparameters for generated GNNs are not provided

## Confidence
- High: Superior performance on benchmark datasets, knowledge base integration benefits
- Medium: Knowledge-guided evolution mechanism effectiveness
- Low: Specific implementation details for agents and retrieval

## Next Checks
1. Implement RAG retrieval with all-MiniLM-L6-v2 and test on PyG documentation to verify retrieval relevance and quality
2. Build a minimal two-agent system (planning + configuration) to test GNN code generation and execution pipeline
3. Run a small-scale experiment comparing LLMNet with and without knowledge base updates to verify the dynamic learning mechanism