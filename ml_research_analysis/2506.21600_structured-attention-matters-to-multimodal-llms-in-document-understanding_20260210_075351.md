---
ver: rpa2
title: Structured Attention Matters to Multimodal LLMs in Document Understanding
arxiv_id: '2506.21600'
source_url: https://arxiv.org/abs/2506.21600
tags:
- text
- structured
- mllms
- attention
- document
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how input format influences multimodal
  large language models (MLLMs) performance in document understanding. The authors
  discovered that unstructured OCR text often degrades MLLM performance due to attention
  dispersion and loss of structural information.
---

# Structured Attention Matters to Multimodal LLMs in Document Understanding

## Quick Facts
- **arXiv ID:** 2506.21600
- **Source URL:** https://arxiv.org/abs/2506.21600
- **Reference count:** 10
- **Primary result:** Structured text encoding using LaTeX paradigm improves MLLM document understanding accuracy by up to 11.8% on four benchmarks

## Executive Summary
This paper investigates how input format influences multimodal large language models' performance in document understanding tasks. The authors discover that unstructured OCR text degrades MLLM performance due to attention dispersion and loss of structural information, while their proposed structure-preserving approach using LaTeX-based encoding maintains hierarchical organization and spatial relationships. Their analysis reveals that structured text induces structured attention patterns that direct models to focus on semantically meaningful regions while reducing attention waste. Experiments on four document understanding benchmarks demonstrate significant accuracy improvements without requiring architectural modifications or additional training.

## Method Summary
The authors propose a novel structure-preserving approach that encodes document elements using the LaTeX paradigm to maintain hierarchical organization and spatial relationships. Unlike standard OCR which produces unstructured text, this method preserves the document's visual structure by encoding elements in a format that reflects their logical relationships and positions. The approach leverages the hierarchical nature of LaTeX to represent document structure, enabling MLLMs to process text with maintained spatial and semantic relationships. The method is evaluated across multiple MLLM architectures and document understanding benchmarks, showing consistent improvements over both image-only and image-with-unstructured-OCR baselines.

## Key Results
- Structured text encoding improves MLLM accuracy by up to 11.8% on certain datasets and models
- MLLMs with structured text and images outperform both image-only and image-with-unstructured-OCR approaches
- Attention analysis shows structured text induces structured attention patterns on both textual and visual content
- Improvements achieved without requiring architectural modifications or additional training

## Why This Works (Mechanism)
The paper demonstrates that structured text encoding preserves document hierarchy and spatial relationships that are lost in standard OCR processing. This preservation enables MLLMs to maintain semantic coherence in their attention patterns, directing focus to meaningful document regions rather than dispersing attention across unstructured text. The LaTeX-based encoding scheme provides a standardized way to represent document structure that MLLMs can leverage for better understanding, effectively reducing attention waste and improving the alignment between visual and textual information processing.

## Foundational Learning
- **Document structure preservation:** Why needed - OCR typically loses hierarchical relationships between document elements; Quick check - Compare attention patterns between structured and unstructured text inputs
- **LaTeX encoding paradigm:** Why needed - Provides standardized hierarchical representation of document elements; Quick check - Verify encoding preserves spatial relationships through visual inspection
- **Multimodal attention mechanisms:** Why needed - Understanding how MLLMs process combined visual and textual inputs; Quick check - Analyze attention weight distributions across different input formats
- **Document understanding benchmarks:** Why needed - Standardized evaluation across diverse document types and tasks; Quick check - Validate benchmark relevance to real-world document processing scenarios
- **Spatial relationship encoding:** Why needed - Critical for maintaining semantic coherence in document layout; Quick check - Test performance on documents with varying layout complexities
- **Attention pattern analysis:** Why needed - Reveals how input structure affects model processing; Quick check - Compare attention maps between structured and unstructured inputs

## Architecture Onboarding
- **Component map:** Document image -> OCR processing -> Structured text encoding (LaTeX) -> MLLM input fusion -> Attention mechanism -> Output generation
- **Critical path:** Image + Structured text → Attention mechanism → Semantic understanding → Answer generation
- **Design tradeoffs:** Structure preservation vs. encoding complexity, generalization across document types vs. encoding specificity, computational overhead vs. performance gains
- **Failure signatures:** Attention dispersion in unstructured text, loss of semantic relationships, degraded performance on layout-dependent questions, increased computational overhead
- **First experiment 1:** Compare attention patterns between structured and unstructured text inputs on simple document layouts
- **First experiment 2:** Test structured text encoding across different MLLM architectures with varying model sizes
- **First experiment 3:** Evaluate performance degradation when removing hierarchical structure from LaTeX encoding while maintaining spatial relationships

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Effectiveness may be constrained by the specific LaTeX-based encoding scheme chosen
- Focus on document QA tasks may not capture full range of multimodal document processing challenges
- Attention pattern analysis shows correlation but not causal relationships with performance
- Computational overhead of structured text generation versus standard OCR is not thoroughly examined

## Confidence
- **High confidence:** Empirical results showing performance improvements with structured text are well-supported by experimental data across multiple benchmarks and model types
- **Medium confidence:** Interpretation of attention patterns and their relationship to semantic understanding relies on correlation rather than direct causation
- **Medium confidence:** Claim that structured attention is key to performance improvements is supported but could benefit from ablation studies

## Next Checks
1. Conduct ablation studies to isolate the contribution of hierarchical structure versus other aspects of the structured text encoding, testing variations that preserve spatial relationships without full LaTeX hierarchy
2. Test the approach across additional document types (e.g., invoices, forms, mixed-language documents) and tasks (e.g., information extraction, document classification) to assess generalizability beyond the current QA-focused evaluation
3. Perform a detailed efficiency analysis comparing computational costs of structured text generation versus performance gains, including timing studies and memory usage comparisons across different document lengths and complexities