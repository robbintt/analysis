---
ver: rpa2
title: Biomedical Hypothesis Explainability with Graph-Based Context Retrieval
arxiv_id: '2511.05498'
source_url: https://arxiv.org/abs/2511.05498
tags:
- biomedical
- context
- hypothesis
- retrieval
- explainability
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study presents HGCR, a graph-based biomedical hypothesis explainability
  framework that combines semantic path retrieval with large language models (LLMs).
  The system constructs dynamic biomedical co-occurrence graphs from MEDLINE literature
  and retrieves semantic paths between concept pairs, using them as context for LLM-generated
  explanations.
---

# Biomedical Hypothesis Explainability with Graph-Based Context Retrieval

## Quick Facts
- arXiv ID: 2511.05498
- Source URL: https://arxiv.org/abs/2511.05498
- Reference count: 32
- Presents HGCR framework combining semantic path retrieval from co-occurrence graphs with LLM explanations, validated by iterative feedback using AGATHA

## Executive Summary
This study introduces HGCR, a graph-based framework for explainable biomedical hypothesis generation. HGCR constructs dynamic co-occurrence graphs from MEDLINE literature and retrieves semantic paths between concept pairs to serve as structured context for LLM-generated explanations. A novel feedback loop iteratively refines these explanations by validating extracted predicates against AGATHA, correcting unsupported claims. The system demonstrates superior lexical and semantic similarity to future reference abstracts compared to baseline retrieval-augmented generation systems, with the feedback mechanism significantly reducing error rates in generated explanations.

## Method Summary
HGCR builds a temporal co-occurrence graph from MEDLINE using UMLS CUIs, where edges represent concept co-occurrences with PMID metadata. For source-target pairs, it retrieves and ranks semantic paths (limited to length 4) using a cross-attention model trained with contrastive loss to distinguish positive paths (intermediate nodes in future references) from corrupted/hard negatives. Top-ranked paths and associated abstracts form context for LLM generation. A feedback loop extracts predicates via SemRep, validates them with AGATHA, and iteratively refines explanations by replacing context abstracts for flagged sentences until convergence or maximum iterations.

## Key Results
- HGCR-based explanations achieve higher lexical and semantic similarity to future reference abstracts compared to baseline RAG systems
- Feedback loop reduces error rates by validating LLM-generated predicates against AGATHA, correcting unsupported claims
- Path ranking model achieves micro AUC 0.895 and macro AUC 0.932 using MedCPT + AGATHA encoders

## Why This Works (Mechanism)

### Mechanism 1
If semantic paths are retrieved from a co-occurrence graph and used as context, LLM explanations show higher semantic similarity to future reference abstracts compared to flat-document retrieval. HGCR constructs a dynamic biomedical co-occurrence graph from MEDLINE (nodes = UMLS CUIs, edges = co-occurrences in abstracts). For a source–target pair, it samples and ranks semantic paths using a cross-attention model that integrates path embeddings with context (abstract) embeddings. Top-ranked paths and their associated literature are fed to the LLM as structured context. Core assumption: Paths whose intermediate nodes appear in future literature about the source–target pair are more likely to encode valid mechanistic reasoning trajectories.

### Mechanism 2
If an iterative feedback loop validates LLM-generated predicates against an external hypothesis generation system (AGATHA), the error rate of unsupported claims in explanations decreases. After LLM generation, SemRep extracts subject–verb–object predicates normalized to UMLS CUIs. Each predicate is evaluated by AGATHA (direct match or plausibility ranking). Predicates failing validation are flagged as "rework" sentences. The system replaces the most similar PMID in the current context with a new candidate and regenerates the explanation, iterating until convergence or a maximum number of iterations. Core assumption: AGATHA's semantic network and plausibility scores reliably distinguish scientifically plausible from implausible biomedical relationships.

### Mechanism 3
If path-context pairs are ranked using a cross-attention model trained with contrastive loss to distinguish positive paths from corrupted/hard negatives, higher-ranked paths yield explanations with better alignment to future literature. The HGCR model encodes paths (concept embeddings) and context (abstract embeddings). Self-attention over context is followed by cross-attention (context as query, path as key/value) to produce a joint representation. A margin ranking loss encourages higher scores for positive paths (intermediate nodes in future references) versus negatives. At inference, paths are ranked by this score. Core assumption: The contrastive training objective forces the model to learn alignment between structured path semantics and unstructured textual evidence that generalizes to unseen biomedical relationships.

## Foundational Learning

- **Retrieval-Augmented Generation (RAG)**
  - Why needed here: LLMs alone hallucinate biomedical facts; RAG provides external, literature-grounded context to constrain generation.
  - Quick check question: In a biomedical QA setting, how would adding MEDLINE abstracts as context affect the factual accuracy of an LLM's answer compared to parametric-only generation?

- **Knowledge Graphs in Biomedicine**
  - Why needed here: HGCR's co-occurrence graph structures UMLS concepts and their relationships, enabling multi-hop path retrieval for mechanistic explanations.
  - Quick check question: Given a co-occurrence graph where edge (A, B) exists if A and B appear in the same abstract, how might this differ from a curated knowledge graph with explicit predicate types (e.g., "treats", "inhibits")?

- **Iterative Refinement with External Validators**
  - Why needed here: LLM outputs may contain unsupported claims; coupling with a domain-specific validator (AGATHA) enables automated correction.
  - Quick check question: If AGATHA flags a predicate as implausible but the predicate is actually a novel, valid hypothesis, what mechanisms could prevent over-correction?

## Architecture Onboarding

- **Component map:**
  Graph Builder -> Path Retriever (HGCR Model) -> LLM Generator -> Feedback Loop (SemRep -> AGATHA -> Context Replacement -> Regeneration)

- **Critical path:**
  Graph construction (offline) -> Path retrieval for query (m_i, m_j) -> LLM generation -> Predicate extraction/validation -> Context update (if rework) -> Repeat until convergence or max iterations

- **Design tradeoffs:**
  - Path length vs. computational cost: Limiting to length-4 paths reduces complexity but may miss longer mechanistic chains
  - Context size (k): Ablation shows k=7 balances semantic similarity gains with token budget; larger k improves similarity but increases latency
  - Feedback iterations: Cap at 5 to prevent infinite loops; some queries (35/318 for Phi-4) do not converge

- **Failure signatures:**
  - High error rate (>0.05) after feedback loop indicates AGATHA validation gaps or persistent hallucinations
  - Low MedCPT/SciNCL similarity to future references suggests path retrieval or context alignment is poor
  - Non-convergence in feedback loop may signal contradictory evidence or insufficient replacement candidates

- **First 3 experiments:**
  1. Graph Construction Validation: Sample source–target pairs with known relationships from 2022+ literature; verify that positive paths (intermediate nodes in future abstracts) are retrievable from G_{t-1}
  2. Path Ranking Ablation: Compare HGCR (MedCPT + AGATHA encoders) against variants with different encoders (SapBERT, PubMedNCL) using micro/macro AUC and AP on held-out queries
  3. Feedback Loop Stress Test: Run the full pipeline on queries with intentionally corrupted context; measure error rate reduction and convergence iterations per LLM (Phi-4, Llama-3.1 8B, Llama-3.3 70B)

## Open Questions the Paper Calls Out

### Open Question 1
How can feedback loop heuristics be redesigned to prevent the reinforcement of context drift or bias amplification during iterative refinement? The authors state that the feedback loop context update rule "relies on local similarity-based heuristics, which may reinforce context drift or amplify biases introduced by early generation errors." This is unresolved because the current mechanism selects replacement abstracts based on local cosine similarity to a flagged sentence, potentially creating a feedback loop that diverges from the broader scientific consensus or original hypothesis intent. Evidence that would resolve this includes error analysis tracking the semantic deviation of context across iterations, or development of a global optimization constraint that penalizes divergence from the source-target relationship.

### Open Question 2
How can evaluation frameworks effectively isolate the contribution of retrieved context from the parametric knowledge of pre-trained LLMs in temporal hypothesis generation? The authors note that "constructing the evaluation dataset with non-overlapping knowledge cutoffs between LLMs and recent scientific discoveries is not quite feasible," making it difficult to determine if correctness scores stem from the system or the LLM's internal memory. This is unresolved because high correctness scores for non-retrieval models suggest that LLMs may have "seen" the test set references during pre-training, confounding the measurement of the retrieval system's true efficacy. Evidence that would resolve this includes a benchmark using embargoed or synthetic data created after the strict training cutoff of the LLMs, ensuring zero data leakage.

### Open Question 3
To what extent does the computational constraint on path length (limit 4) impact the retrieval of valid mechanistic explanations for complex biomedical relationships? The methodology states that paths are "limit[ed] to length 4 due to computational constraints," but the paper does not analyze if valid "future reference" paths exist at depths of 5 or greater that were excluded. This is unresolved because it is unclear if the restriction to shortest paths of length ≤4 biases the system towards simpler, potentially less novel associations while missing deeper, multi-hop mechanisms. Evidence that would resolve this includes an ablation study measuring the retrieval performance (Recall@k) and computational cost when allowing path lengths of 5, 6, and 7 on a subset of complex queries.

## Limitations

- Graph construction sparsity: The co-occurrence graph relies on MEDLINE abstracts and UMLS CUIs, which may miss relationships not explicitly mentioned or poorly covered by MetaMap/SemRep
- AGATHA validation scope: The feedback loop assumes AGATHA's plausibility scores reliably filter unsupported claims, but AGATHA's knowledge may not capture truly novel hypotheses
- Generalizability to other domains: The system is tuned for biomedical hypothesis generation with specific encoders (MedCPT, AGATHA) and performance in other scientific domains is untested

## Confidence

- **High:** Graph-based path retrieval improves semantic similarity to future literature compared to flat-document retrieval
- **Medium:** Feedback loop reduces unsupported predicate error rates (demonstrated empirically, but dependent on AGATHA's completeness)
- **Low:** The system's design principles generalize robustly beyond the biomedical domain or specific ontological constraints

## Next Checks

1. Graph sparsity stress test: Sample source–target pairs from the Dyport benchmark with known relationships; measure path retrieval rates and identify bottlenecks in co-occurrence graph coverage

2. AGATHA validator ablation: Run the feedback loop with AGATHA disabled or replaced by a random validator; compare error rate reduction to quantify AGATHA's specific contribution

3. Multi-domain adaptation: Retrain the HGCR model on a non-biomedical scientific corpus (e.g., arXiv physics/chemistry) with analogous ontological structures; evaluate path ranking and explanation quality to test domain transfer