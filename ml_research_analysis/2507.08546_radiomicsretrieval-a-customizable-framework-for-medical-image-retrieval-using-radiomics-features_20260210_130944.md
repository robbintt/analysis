---
ver: rpa2
title: 'RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using
  Radiomics Features'
arxiv_id: '2507.08546'
source_url: https://arxiv.org/abs/2507.08546
tags:
- image
- radiomics
- tumor
- features
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RadiomicsRetrieval is a 3D medical image retrieval framework that
  combines radiomics features with deep learning embeddings for tumor-level retrieval.
  It uses promptable segmentation models (e.g., SAM) to extract tumor-specific embeddings,
  which are aligned with radiomics features via contrastive learning and enriched
  with anatomical positional embeddings (APE).
---

# RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features

## Quick Facts
- **arXiv ID:** 2507.08546
- **Source URL:** https://arxiv.org/abs/2507.08546
- **Reference count:** 33
- **Primary result:** Combines radiomics features with deep learning embeddings for tumor-level 3D medical image retrieval, achieving high precision and correlation scores on lung CT and brain MRI datasets.

## Executive Summary
RadiomicsRetrieval is a 3D medical image retrieval framework that integrates radiomics features with deep learning embeddings for tumor-specific retrieval. The system uses promptable segmentation models (e.g., SAM) to extract tumor embeddings, which are aligned with radiomics features via contrastive learning and enriched with anatomical positional embeddings (APE). It supports flexible querying by image, location, or partial radiomics features, requiring only minimal user prompts. Extensive experiments on lung CT and brain MRI datasets demonstrate that radiomics features significantly enhance retrieval specificity, while APE provides essential global anatomical context for location-based searches.

## Method Summary
The framework employs a parallel architecture with two encoding paths: one for image embeddings (using SAM-Med3D backbone) and one for radiomics features (using TransTab encoder). Anatomical positional embeddings (APE) are generated based on the modality (CT abdominal/thoracic or MRI). Tumor segmentation is performed using promptable models with 1-10 point prompts per tumor. The system uses joint optimization with Dice and CE loss for segmentation, InfoNCE loss for contrastive alignment, and CE loss for classification. Training employs a multi-positive contrastive setup with batch size 80 (40 tumors × 2 random crops/prompts), freezing SAM-Med3D and APE while fine-tuning only the lightweight decoder and radiomics encoder.

## Key Results
- Location-based retrieval precision@5 reached 0.9117 (BRATS) and 0.9115 (NSCLC) with multimodal approach using APE
- Radiomics-based queries achieved correlation scores up to 0.9663 for BRATS Top-5
- APE provides essential global anatomical context for location-based searches
- Framework supports flexible querying by image, location, or partial radiomics features with minimal user input

## Why This Works (Mechanism)
The framework leverages radiomics features' ability to capture quantitative tumor characteristics (shape, texture, histogram) while deep learning embeddings capture semantic tumor appearance. Anatomical positional embeddings provide essential global context for location-based retrieval, addressing the limitation of local tumor features alone. The multimodal approach combines these complementary information sources through contrastive learning, allowing the system to match tumors based on both appearance and quantitative features while maintaining spatial awareness.

## Foundational Learning
- **Contrastive Learning**: Needed to align image and radiomics feature embeddings in shared space; quick check: verify positive pairs are different views of same tumor
- **Anatomical Positional Embeddings (APE)**: Required for providing global anatomical context in location-based retrieval; quick check: validate APE maps match anatomical regions
- **Radiomics Feature Extraction**: Essential for capturing quantitative tumor characteristics; quick check: confirm 72 features (Shape, Histogram, Texture) are correctly extracted
- **Promptable Segmentation**: Enables flexible tumor extraction with minimal user input; quick check: test single-point prompt effectiveness

## Architecture Onboarding

**Component Map:** SAM-Med3D -> Image Encoder -> Lightweight Decoder $D_{multi}$ <-> TransTab Encoder -> Radiomics Features

**Critical Path:** Tumor Prompt → SAM-Med3D Segmentation → Image Embedding → $D_{multi}$ Decoder → Contrastive Alignment → Retrieval

**Design Tradeoffs:** Multimodal approach increases specificity but requires modality-specific APE models and complex training; lightweight decoder balances performance with computational efficiency

**Failure Signatures:** 
- GPU OOM with batch size 80 and $128^3$ volumes
- Contrastive collapse with random retrieval accuracy
- Misalignment between image and radiomics embeddings

**3 First Experiments:**
1. Test single-point prompt effectiveness on tumor segmentation accuracy
2. Validate contrastive learning with known positive/negative pairs
3. Evaluate retrieval performance with and without APE for location-based queries

## Open Questions the Paper Calls Out
None

## Limitations
- Performance depends heavily on availability of pretrained SAM-Med3D models and APE generators
- APE models are modality-specific, raising questions about cross-domain applicability
- Choice of 72 radiomics features not extensively validated beyond correlation metrics
- Lightweight decoder architecture underspecified, making exact replication challenging

## Confidence
- **High Confidence:** Core retrieval methodology and effectiveness on both BraTS and NSCLC datasets
- **Medium Confidence:** Reported performance metrics, dependent on precise hyperparameter tuning
- **Low Confidence:** Clinical utility claims and generalizability to other modalities

## Next Checks
1. Systematically vary learning rates (1e-4 to 5e-4), batch sizes, and temperature parameters to assess stability of reported performance metrics
2. Evaluate retrieval performance using APE models trained on different anatomical regions to quantify impact of anatomical context
3. Compare retrieval accuracy using different subsets of the 72 radiomics features to identify most contributing features