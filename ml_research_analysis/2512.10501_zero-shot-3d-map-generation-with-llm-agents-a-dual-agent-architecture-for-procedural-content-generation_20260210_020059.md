---
ver: rpa2
title: 'Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for
  Procedural Content Generation'
arxiv_id: '2512.10501'
source_url: https://arxiv.org/abs/2512.10501
tags:
- actor
- generation
- critic
- language
- architecture
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a training-free dual-agent architecture that
  enables off-the-shelf large language models to control complex procedural content
  generation (PCG) tools without fine-tuning. The system pairs an Actor agent, which
  interprets natural language prompts and generates initial parameter configurations,
  with a Critic agent, which evaluates these proposals against API documentation and
  usage examples.
---

# Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation

## Quick Facts
- arXiv ID: 2512.10501
- Source URL: https://arxiv.org/abs/2512.10501
- Reference count: 40
- A training-free dual-agent architecture enables off-the-shelf LLMs to control complex PCG tools without fine-tuning

## Executive Summary
This work introduces a novel dual-agent architecture that enables off-the-shelf large language models to perform zero-shot 3D map generation by leveraging procedural content generation tools. The system pairs an Actor agent that interprets natural language prompts with a Critic agent that evaluates proposals against API documentation. Through iterative dialogic refinement, the agents progressively align generated content with user intent while ensuring functional correctness. Experiments demonstrate a 20% higher success rate compared to single-agent baselines and reduced need for human follow-up prompts.

## Method Summary
The dual-agent architecture employs a training-free approach where an Actor agent generates initial parameter configurations from natural language prompts, while a Critic agent evaluates these proposals against API documentation and usage examples. The agents engage in iterative dialogic refinement to progressively align generated content with user intent while maintaining functional correctness. Static documentation injection and in-context reasoning bridge the semantic gap between abstract instructions and rigid tool parameters, enabling effective control of complex PCG tools without task-specific training.

## Key Results
- Achieves 20% higher success rate compared to single-agent baselines
- Reduces need for human follow-up prompts
- Demonstrates effective zero-shot learning for complex PCG tasks

## Why This Works (Mechanism)
The dual-agent system works by leveraging complementary roles: the Actor interprets natural language and proposes solutions, while the Critic ensures technical validity against documentation. The iterative dialogic refinement process allows for progressive alignment between user intent and technical requirements. Static documentation injection provides the necessary context for off-the-shelf LLMs to understand specific tool parameters without fine-tuning.

## Foundational Learning
- **Procedural Content Generation (PCG)**: Algorithmic creation of game content; needed for understanding the target application domain; quick check: verify tool can generate diverse map layouts
- **Dual-agent architecture**: System with two specialized agents working in tandem; needed for separating interpretation from validation; quick check: ensure clear role distinction between agents
- **In-context learning**: LLM ability to learn from provided examples without fine-tuning; needed for training-free approach; quick check: verify LLMs can follow documentation examples
- **Dialogic refinement**: Iterative back-and-forth between agents; needed for progressive improvement; quick check: measure convergence speed and quality gains
- **Static documentation injection**: Providing tool documentation as context; needed for technical correctness; quick check: validate documentation comprehensiveness

## Architecture Onboarding

Component map: Natural Language Prompt -> Actor Agent -> Parameter Proposal -> Critic Agent -> API Validation -> 3D Map Output

Critical path: Prompt Interpretation → Parameter Generation → Documentation Validation → Output Generation

Design tradeoffs: Training-free approach vs. potential performance limitations; single vs. dual-agent complexity; computational overhead of iterative refinement vs. human prompt reduction

Failure signatures: Actor agent misinterpretation of prompts; Critic agent inability to validate against complex documentation; convergence failure in dialogic refinement; documentation injection causing context overload

First experiments to run:
1. Test basic Actor agent on simple prompt-tool pairs to establish baseline interpretation capability
2. Validate Critic agent's ability to accurately evaluate proposals against sample API documentation
3. Run end-to-end dual-agent pipeline on constrained 3D map generation tasks to measure iterative improvement

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Performance improvement of 20% was evaluated on specific 3D map generation tasks without detailed disclosure of benchmark complexity or diversity
- Reliance on static documentation injection may not hold for tools requiring specialized domain knowledge
- Computational overhead and potential convergence issues in iterative dialogic refinement were not thoroughly characterized

## Confidence
- Dual-agent architecture effectiveness: Medium - Validated on limited task set with promising but not definitive results
- Training-free approach viability: Medium - Depends heavily on documentation quality and LLM capabilities
- Reduction in human follow-up prompts: High - Direct empirical observation reported

## Next Checks
1. Test the framework across 5+ diverse PCG tools with varying API complexity to assess generalizability beyond 3D map generation
2. Measure computational overhead and dialogic convergence rates across different task complexities to quantify efficiency trade-offs
3. Conduct user studies comparing output quality and iteration counts against both single-agent baselines and human experts across multiple domains