---
ver: rpa2
title: Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts
arxiv_id: '2510.24817'
source_url: https://arxiv.org/abs/2510.24817
tags:
- synthetic
- data
- transcripts
- aphasia
- sample
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study developed two synthetic transcript generation methods
  for aphasic speech: a procedural approach and an LLM-based approach using Mistral
  7b Instruct and Llama 3.1 8b. Both methods generated transcripts across four aphasia
  severity levels (Mild, Moderate, Severe, Very Severe) for the Cat Rescue picture
  description task.'
---

# Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts

## Quick Facts
- arXiv ID: 2510.24817
- Source URL: https://arxiv.org/abs/2510.24817
- Reference count: 0
- LLM-based synthetic data, particularly with Mistral 7b Instruct, can effectively simulate aphasic language characteristics for training and evaluation purposes.

## Executive Summary
This study develops two methods for generating synthetic aphasia transcripts: a procedural augmentation approach and an LLM-based approach using Mistral 7b Instruct and Llama 3.1 8b. Both methods generate transcripts across four aphasia severity levels (Mild, Moderate, Severe, Very Severe) for the Cat Rescue picture description task. The LLM method, particularly with Mistral 7b Instruct, best captures realistic linguistic degradation patterns, showing appropriate directional changes in NDW, word count, and word length across severity levels compared to human-elicited transcripts. The study concludes that LLM-based synthetic data can effectively simulate aphasic language characteristics for training and evaluation purposes.

## Method Summary
The study employs two synthetic transcript generation methods for aphasic speech. The procedural approach applies probabilistic augmentation operators (word dropping, filler insertion, paraphasia substitution) to base sentences with severity-dependent probabilities. The LLM-based approach uses Mistral 7b Instruct and Llama 3.1 8b with severity-specific prompt templates to generate transcripts. Both methods produce transcripts across four severity levels (Mild, Moderate, Severe, Very Severe) for the Cat Rescue picture description task. The procedural method achieves moderate lexical diversity (TTR ~0.64) with 34.99 average words per transcript, while Mistral 7b Instruct shows higher lexical diversity (TTR ~0.71) with 72.84 average words.

## Key Results
- Mistral 7b Instruct best captures key aspects of linguistic degradation observed in aphasia, showing realistic directional changes in NDW, word count, and word length across severity levels.
- Procedural method achieves moderate lexical diversity (TTR ~0.64) with 34.99 average words per transcript.
- Mistral 7b Instruct shows higher lexical diversity (TTR ~0.71) with 72.84 average words per transcript.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Probabilistic augmentation operators applied to base sentences can simulate graded aphasic speech characteristics across severity levels.
- Mechanism: Three augmentation operators (word dropping, filler insertion, paraphasia substitution) are stochastically applied to base sentences with severity-dependent probabilities (P_σ: A → [0,1]). Higher severity levels increase augmentation probability, producing progressively degraded linguistic output.
- Core assumption: Aphasic speech can be approximated by independent application of three discrete transformation types on fluent source text.
- Evidence anchors:
  - [abstract] "The methods generate transcripts across four severity levels (Mild, Moderate, Severe, Very Severe) through word dropping, filler insertion, and paraphasia substitution."
  - [section: Method] "Individual augmentation values are configurable with values ranging from 0.0 (no augmentation) to 1.0 (full augmentation)... higher values increase the frequency of omissions, disfluencies, and lexical errors."
  - [corpus] Related work "Component-Level Lesioning of Language Models" (FMR=0.63) explores systematic manipulation for aphasia simulation, suggesting mechanistic approaches are actively researched.
- Break condition: If augmentation operators produce linguistically implausible combinations (e.g., semantic substitutions that violate sentence-level meaning beyond clinical patterns), the simulation fails ecological validity.

### Mechanism 2
- Claim: Instruction-tuned LLMs with severity-specific prompt templates can generate aphasic-like transcripts that capture directional linguistic degradation patterns.
- Mechanism: System prompts encode severity-specific language architectures (e.g., "Telegraphic style. Short phrases. Missing function words" for Severe). User prompts specify the Cat Rescue task. Temperature=0.7 and top_p=0.9 allow controlled variability while maintaining plausibility.
- Core assumption: LLMs' learned representations of disordered speech from pre-training data can be elicited via prompt engineering without fine-tuning.
- Evidence anchors:
  - [abstract] "Mistral 7b Instruct best captures key aspects of linguistic degradation observed in aphasia, showing realistic directional changes in NDW, word count, and word length."
  - [section: Machine Learning Method] "Coupled with the non-determinism inherent to an LLM, the generated transcripts ideally represent diversity of severe aphasia."
  - [corpus] "Generating Completions for Broca's Aphasic Sentences Using Large Language Models" (FMR=0.63) supports LLM applicability to aphasia simulation tasks.
- Break condition: If prompt templates fail to constrain output length or lexical complexity appropriately (as observed with Llama 3.1 8b showing TTR=0.94 for Very Severe—opposite of expected pattern), the mechanism produces clinically invalid output.

### Mechanism 3
- Claim: Lexical richness metrics (TTR, NDW, word count, word length) provide sufficient signal to validate synthetic transcript fidelity against human benchmarks.
- Mechanism: Compare synthetic output distributions to human-elicited transcripts across severity levels. Valid simulation should show: (1) NDW decreasing with severity, (2) word count decreasing with severity, (3) TTR changes consistent with vocabulary constriction patterns.
- Core assumption: Aggregate lexical statistics capture clinically meaningful variation; SLP-perceived realism would correlate with these metrics.
- Evidence anchors:
  - [abstract] "Mistral 7b Instruct showed higher lexical diversity (TTR ~0.71) with 72.84 average words... showing appropriate directional changes in NDW, word count, and word length across severity levels."
  - [section: Post Hoc Comparison] "Synthetic B demonstrates moderate ecological fidelity, capturing the correct direction from mild severity through to very severe for NDW, word count, and word length."
  - [corpus] "Practical Machine Learning for Aphasic Discourse Analysis" (FMR=0.61) uses discourse informativeness measures, but no direct corpus validation of synthetic data quality metrics exists.
- Break condition: If lexical metrics diverge from human patterns (e.g., Synthetic C showing increasing TTR with severity), the validation framework itself may be insufficient or the generation method fundamentally misaligned.

## Foundational Learning

- Concept: Type-Token Ratio (TTR) and lexical diversity
  - Why needed here: TTR quantifies vocabulary variation (unique words / total words). Aphasic speech typically shows reduced lexical diversity at higher severities. The paper relies on TTR to compare synthetic vs. human transcripts.
  - Quick check question: If a transcript contains 50 total words with 35 unique types, what is the TTR? (Answer: 0.70)

- Concept: Aphasia severity classification and linguistic correlates
  - Why needed here: The four-tier severity system (Mild, Moderate, Severe, Very Severe) drives augmentation probabilities and prompt engineering. Understanding expected linguistic patterns per severity is essential for validating output.
  - Quick check question: Which severity level would most likely exhibit "telegraphic style" with missing function words? (Answer: Severe)

- Concept: Correct Information Units (CIUs)
  - Why needed here: CIUs measure communicative informativeness—words that are intelligible, accurate, relevant, and informative. The procedural method computes CIUs programmatically (though not clinically validated) as metadata for downstream training.
  - Quick check question: Would filled pauses ("um," "uh") count as CIUs? (Answer: No—they're excluded as disfluencies)

## Architecture Onboarding

- Component map:
procedural_generator.py → [base sentences] → [augmentation engine: drop/filler/para] → [severity configs] → JSONL output
llm_generator.py → [prompt templates] → [Mistral/Llama inference] → [severity-specific prompts] → JSONL/CSV output
transcript_analysis.py → [lexical richness calc: TTR, NDW, LD] → validation metrics

- Critical path: Prompt template engineering → Model inference → Lexical validation → Human transcript comparison. The prompt templates are the highest-leverage component; small changes produce large output differences.

- Design tradeoffs:
  - Procedural method: Deterministic, reproducible, computationally cheap (~34 words/transcript) but limited diversity (hardcoded fillers, templates).
  - LLM method: Higher diversity and ecological fidelity (~73-117 words/transcript) but stochastic, requires GPU, model-dependent quality variance (Mistral >> Llama for this task).
  - Tradeoff: Procedural offers control; LLM offers realism.

- Failure signatures:
  - Synthetic C pattern: TTR *increases* with severity (0.61→0.94), word count stays high (99 for Very Severe), NDW increases—indicates prompt fails to constrain lexical production.
  - Procedural low diversity: All transcripts within a severity level appear similar due to small filler/protected word sets.
  - CIU inflation: Programmatic CIU calculation does not infer context; reported CIU% values (~90%+) are unreliable placeholders.

- First 3 experiments:
  1. Reproduce Mistral 7b Instruct generation with provided prompt templates. Compare TTR/NDW values against Table 2 to validate environment setup.
  2. Ablate prompt templates: Run Mistral with identical prompts across severities (hold language architecture constant). Measure whether severity differentiation collapses, isolating prompt contribution.
  3. Hybrid validation: Generate 100 procedural transcripts and 100 Mistral transcripts for a single severity level. Have 2 SLPs rate realism blind to source. Determine whether lexical metrics correlate with human judgment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do trained Speech-Language Pathologists (SLPs) rate the realism and clinical usefulness of LLM-generated synthetic aphasia transcripts across severity levels?
- Basis in paper: [explicit] The abstract states "future work should plan to...have SLPs assess the realism and usefulness of the synthetic transcripts."
- Why unresolved: The current study relied on automated lexical metrics (TTR, NDW, word count) rather than expert clinical evaluation; SLP interpretation was confined to a small sample size (n=2).
- What evidence would resolve it: A systematic evaluation where SLPs blinded to transcript origin rate synthetic vs. human-elicited transcripts on clinical realism markers (e.g., paraphasia authenticity, disfluency patterns, informativeness).

### Open Question 2
- Question: Can fine-tuning LLMs on real aphasic discourse improve the ecological validity and semantic-lexical realism of synthetic transcript generation?
- Basis in paper: [explicit] The abstract and future work section both recommend to "fine-tune models for better aphasic representation" and "augmenting ML model training or fine-tuning with synthetic data."
- Why unresolved: This study used off-the-shelf instruction-tuned models (Mistral 7b, Llama 3.1 8b) without domain-specific fine-tuning; the procedural method showed only "partial ecological validity."
- What evidence would resolve it: Comparative study of base vs. aphasia-fine-tuned LLMs, measuring alignment with human transcript patterns across additional linguistic dimensions (e.g., syntactic complexity, semantic coherence).

### Open Question 3
- Question: To what extent are ML systems trained on synthetic aphasia transcripts vulnerable to model inversion attacks that could reconstruct original training data?
- Basis in paper: [explicit] "We suggest future work investigate to what extent it might be possible to execute model inversion attacks against ML systems applied to clinical aphasia tasks."
- Why unresolved: While synthetic data is theorized to mitigate privacy concerns, the security implications have not been empirically tested in clinical aphasia applications.
- What evidence would resolve it: Penetration testing on models trained with synthetic aphasia data to assess whether original patient data patterns can be reconstructed or inferred.

### Open Question 4
- Question: Can synthetic transcript generation methods generalize to other discourse tasks (narrative storytelling, procedural descriptions) and underrepresented languages?
- Basis in paper: [explicit] Future work section states: "expand synthetic data generation to other tasks such as Narrative (Cinderella) and Procedural (make a PBJ sandwich)" and "test synthetic transcript generation for languages with poor, or no, representation."
- Why unresolved: Current methods are "tightly coupled to Cat Rescue picture descriptions"; task-specific prompts and procedural rules may not transfer directly.
- What evidence would resolve it: Applying the same generation methods to additional AphasiaBank tasks and low-resource languages, then comparing lexical fidelity metrics against available human benchmarks.

## Limitations
- The procedural method's augmentation probabilities (Pσ) are not explicitly specified, making exact replication difficult.
- The CIU calculation, while presented as a feature, is acknowledged as non-clinically reliable, undermining claims about transcript informativeness.
- Validation relies entirely on lexical metrics (TTR, NDW, word count) rather than SLP judgment or discourse-level analysis, which may miss clinically relevant patterns.

## Confidence

- **High confidence**: Mistral 7b Instruct outperforms procedural and Llama methods on directional lexical degradation patterns (NDW, word count, word length decrease appropriately with severity).
- **Medium confidence**: Lexical diversity metrics (TTR) capture meaningful variation in aphasic speech simulation, given consistent patterns across severity levels for Mistral.
- **Low confidence**: The CIU metrics provide useful validation, given their acknowledged unreliability and absence of clinical validation.

## Next Checks

1. **Human validation experiment**: Have 3-5 SLPs rate 50 synthetic transcripts (balanced across methods and severity levels) for aphasic realism on a 5-point Likert scale. Compare ratings with lexical metrics to assess ecological validity.

2. **Prompt sensitivity analysis**: Systematically vary prompt templates (language architecture, length constraints) for one severity level and measure impact on lexical metrics. This isolates prompt contribution to method performance differences.

3. **Discourse-level validation**: Analyze synthetic transcripts for discourse features (topic coherence, informativeness, syntactic complexity) beyond lexical metrics. Compare with human transcripts to assess whether statistical similarity translates to functional equivalence.