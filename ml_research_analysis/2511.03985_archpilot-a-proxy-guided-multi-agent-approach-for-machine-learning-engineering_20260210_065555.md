---
ver: rpa2
title: 'ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering'
arxiv_id: '2511.03985'
source_url: https://arxiv.org/abs/2511.03985
tags:
- proxy
- search
- training
- agent
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "ArchPilot addresses the high computational cost of LLM-based ML\
  \ engineering by introducing a three-agent system that separates architecture generation,\
  \ proxy-based evaluation, and search orchestration. The method uses a Monte Carlo\
  \ Tree Search controller that selects candidates using proxy metrics\u2014such as\
  \ one-epoch validation and feature-dropout validation\u2014weighted adaptively through\
  \ ridge-regularized least squares."
---

# ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering

## Quick Facts
- **arXiv ID:** 2511.03985
- **Source URL:** https://arxiv.org/abs/2511.03985
- **Reference count:** 4
- **Key outcome:** ArchPilot achieves valid submission rate of 0.893 and mean normalized ranking of 0.6149 on MLE-Bench, outperforming AIDE (0.787, 0.6953) and ML-Master (0.867, 0.6535)

## Executive Summary
ArchPilot addresses the high computational cost of LLM-based machine learning engineering by introducing a three-agent system that separates architecture generation, proxy-based evaluation, and search orchestration. The method uses Monte Carlo Tree Search with proxy metrics weighted adaptively through ridge-regularized least squares, enabling efficient exploration of the architecture space while minimizing expensive full training runs. Experiments on MLE-Bench show significant improvements, particularly on high-difficulty tasks, with a valid submission rate of 0.893 and mean normalized ranking of 0.6149.

## Method Summary
ArchPilot is a three-agent system for automated neural architecture search that replaces expensive full training runs with proxy-guided evaluation. The Orchestration Agent runs MCTS with UCT selection and manages memory, the Generation Agent handles code drafting, improvement, and debugging, while the Evaluation Agent executes multiple cheap proxies and optimizes their weights. The system uses one-epoch validation, noisy validation, and feature-dropout validation as initial proxies, aggregated via weighted sum with weights fitted by ridge-regularized least squares. When proxy weights diverge significantly, the tree restarts to prevent stale statistics from misdirecting search.

## Key Results
- ArchPilot achieves valid submission rate of 0.893 and mean normalized ranking of 0.6149 on MLE-Bench
- Outperforms AIDE (0.787, 0.6953) and ML-Master (0.867, 0.6535) across all metrics
- Largest performance gains observed on high-difficulty tasks
- Multi-proxy evaluation reduces compute cost while maintaining solution quality correlation

## Why This Works (Mechanism)

### Mechanism 1
Multi-proxy evaluation with adaptive reweighting reduces compute cost while maintaining solution quality correlation. The Evaluation Agent computes multiple cheap proxies, aligns them directionally, and aggregates via normalized weighted sum. As ground-truth labels accumulate, ridge-regularized least squares refits weights, projected onto the probability simplex with a hard-zero policy for failed proxies. Core assumption: proxy signals maintain sufficient correlation with true performance to guide early-stage search.

### Mechanism 2
Separating orchestration, generation, and evaluation into specialized agents improves search efficiency over monolithic LLM loops. Each agent operates on distinct subproblems with specialized prompts and context. Core assumption: the decomposition aligns with natural task boundaries in ML engineering; specialized agents outperform a single generalist LLM under budget constraints.

### Mechanism 3
Tree restart upon weight updates prevents stale UCT statistics from misdirecting search. When refitted weights diverge beyond L1 threshold ε, OA triggers restart: all node scores are recomputed with new aggregator, visit counts reset, and exploration reseeds from top-k verified nodes. Core assumption: early proxy weights are unreliable; periodic realignment improves cumulative search quality without discarding too much exploration progress.

## Foundational Learning

- **Concept:** Monte Carlo Tree Search with UCT
  - **Why needed here:** MCTS is the core search algorithm; understanding UCT's exploration-exploitation trade-off is essential for tuning C and interpreting node selection.
  - **Quick check question:** Given node visits Nv=10, parent visits Nparent=100, and Qv/Nv=0.5, what is the UCT value for C=1.0?

- **Concept:** Ridge regression with simplex projection
  - **Why needed here:** Proxy weight optimization uses ridge-regularized least squares followed by Euclidean projection onto the probability simplex.
  - **Quick check question:** Why does the projection step matter after solving the unconstrained ridge problem?

- **Concept:** Zero-cost and low-cost NAS proxies
  - **Why needed here:** The three initial proxies (one-epoch, noisy, feature-dropout) build on prior NAS proxy literature; understanding their failure modes informs debugging.
  - **Quick check question:** What is the trade-off between one-epoch validation and feature-dropout validation in terms of compute cost vs. signal robustness?

## Architecture Onboarding

- **Component map:**
  - Orchestration Agent: MCTS controller (selection/expansion/verification/backpropagation), short-term memory (journal), long-term memory (historical bests), budget enforcer, restart trigger
  - Generation Agent: Draft mode (initial pipeline), Improve mode (atomic modification), Debug mode (minimal fix)
  - Evaluation Agent: Proxy training executor, proxy registry (3 initial functions), weight optimizer (ridge + simplex + hard-zero), full-training escalator

- **Critical path:**
  1. OA selects node via UCT → 2. OA invokes GA with context → 3. GA returns draft/improve/debug script → 4. EA executes proxy training → 5. EA returns aggregated score → 6. OA backpropagates reward → 7. If weight update threshold exceeded, OA restarts tree

- **Design tradeoffs:**
  - Proxy fidelity vs. compute: more proxies increase evaluation cost but may improve correlation
  - Restart threshold ε: lower values increase restart frequency (fresh alignment but lost exploration); higher values risk stale statistics
  - Budget allocation between proxy and full training: aggressive proxy reliance saves compute but may miss calibration opportunities

- **Failure signatures:**
  - Excessive sentinel emissions: proxy functions incompatible with task architecture
  - Stagnant UCT values: weights may be overfitted to small labeled set; consider increasing k before refit
  - Zero valid submissions under tight budget: proxy mode disabled too early; check budget-threshold logic

- **First 3 experiments:**
  1. **Proxy ablation:** Run with single proxy vs. multi-proxy to isolate contribution of aggregation; expect degraded ranking without aggregation
  2. **Restart threshold sweep:** Test ε ∈ {0.01, 0.05, 0.1} on medium-difficulty tasks; monitor cumulative ranking and restart count
  3. **Budget scaling:** Validate Figure 2 curves on a held-out subset; confirm that high-difficulty tasks show largest ArchPilot advantage

## Open Questions the Paper Calls Out
- Can principled methods for partial tree reuse prevent the loss of promising but underexplored nodes during restarts?
- Does meta-learning initial proxy weights across tasks accelerate search convergence compared to uniform initialization?
- How can the system maintain proxy reliability in highly noisy or sparse data regimes where current weight fitting is unstable?
- Does the "hard-zero policy" for handling proxy failures inadvertently prune informative evaluation signals?

## Limitations
- Performance depends on the stability of weight fitting, which may be less reliable in highly noisy or sparse data regimes
- Tree restart mechanism can occasionally discard promising but underexplored nodes when the scoring rule shifts dramatically
- Current implementation resets visit counts and reseeds from top-k nodes, potentially wasting compute spent on branches that were valid but unexplored

## Confidence
- Multi-agent decomposition effectiveness: **High** (supported by both experiments and related work like AgenticSciML)
- Proxy weight optimization via ridge regression: **Medium** (theoretically grounded but proxy correlation assumptions untested)
- Tree restart upon weight divergence: **Low** (mechanism described but not empirically validated; no corpus evidence)

## Next Checks
1. Conduct systematic ablation of individual proxies to quantify each proxy's contribution to ranking improvement
2. Measure correlation stability between proxy scores and ground-truth performance across different dataset sizes
3. Test partial-tree restart strategies versus full restarts to optimize exploration-exploitation balance