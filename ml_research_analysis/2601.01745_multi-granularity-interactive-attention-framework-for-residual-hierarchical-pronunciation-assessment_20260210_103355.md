---
ver: rpa2
title: Multi-granularity Interactive Attention Framework for Residual Hierarchical
  Pronunciation Assessment
arxiv_id: '2601.01745'
source_url: https://arxiv.org/abs/2601.01745
tags:
- pronunciation
- attention
- granularity
- word
- interactive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel residual hierarchical interactive multi-aspect
  multi-granularity pronunciation assessment framework, HIA, which addresses the issue
  of insufficient bidirectional interaction between different granularity levels in
  existing methods. The core idea is to design an interactive attention module that
  leverages attention mechanisms to achieve dynamic bidirectional interaction, effectively
  capturing linguistic features at each granularity while integrating correlations
  between different granularity levels.
---

# Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment

## Quick Facts
- **arXiv ID:** 2601.01745
- **Source URL:** https://arxiv.org/abs/2601.01745
- **Reference count:** 11
- **Primary result:** HIA achieves state-of-the-art performance on speechocean762 dataset with phoneme accuracy PCC of 0.657, word stress PCC of 0.436, word total PCC of 0.628, and utterance total PCC of 0.764

## Executive Summary
This paper proposes HIA, a residual hierarchical interactive multi-aspect multi-granularity pronunciation assessment framework that addresses the insufficient bidirectional interaction between different granularity levels in existing methods. The framework introduces an Interactive Attention Module that leverages attention mechanisms to achieve dynamic bidirectional interaction across phoneme, word, and utterance levels. Additionally, a residual hierarchical structure is employed to alleviate feature forgetting when modeling acoustic hierarchies. Extensive experiments on the speechocean762 dataset demonstrate that HIA outperforms state-of-the-art methods on all metrics.

## Method Summary
The HIA framework processes 84-dimensional Goodness of Pronunciation (GOP) features extracted from a Librispeech acoustic model, along with canonical phoneme embeddings and positional embeddings. A 3-layer Transformer encoder generates acoustic embeddings, which are then processed by an Interactive Attention Module that concatenates learnable query vectors from all three granularities and applies self-attention to capture correlations. Cross-attention maps interaction features back to the acoustic embedding space. The framework employs residual connections at each granularity level to preserve initial acoustic representations, and propagates predicted scores from lower to higher granularity levels through hierarchical score passing.

## Key Results
- Achieves state-of-the-art performance on speechocean762 dataset across all metrics
- Phoneme accuracy PCC of 0.657 outperforms existing methods by significant margin
- Word stress PCC of 0.436 shows substantial improvement over previous approaches
- Utterance total PCC of 0.764 demonstrates strong overall pronunciation assessment capability

## Why This Works (Mechanism)

### Mechanism 1: Bidirectional Interactive Attention for Cross-Granularity Correlation
The bidirectional information exchange between phoneme, word, and utterance levels improves pronunciation assessment by enabling both bottom-up and top-down information flow. This captures correlations between different granularities more effectively than unidirectional approaches, particularly benefiting word stress prediction where context from higher levels is crucial.

### Mechanism 2: Residual Connections to Mitigate Feature Forgetting
Direct injection of initial acoustic embeddings into each granularity's scoring module preserves fine-grained features that would otherwise be lost in deep hierarchical processing. This creates skip pathways that bypass intermediate transformations, maintaining important acoustic information throughout the hierarchy.

### Mechanism 3: Hierarchical Score Passing Between Adjacent Granularities
Propagating predicted scores from lower to higher granularity levels provides explicit quality signals that improve higher-level assessments. This compositional approach recognizes that pronunciation quality at higher granularities depends on constituent lower-granularity quality.

## Foundational Learning

- **Goodness of Pronunciation (GOP) Features:** Why needed: Model input is 84-dimensional GOP vectors (LPP + LPR) from pre-trained ASR acoustic model. Quick check: Can you explain why GOP features include both log posterior probabilities (LPP) and log posterior ratios (LPR) against all phonemes?

- **Self-Attention vs. Cross-Attention:** Why needed: Interactive Attention Module uses self-attention for granularity interaction and cross-attention for mapping back to acoustic space. Quick check: In cross-attention step (Eq. 6), what serves as queries and what serves as keys/values?

- **Forced Alignment and Phone Segmentation:** Why needed: GOP extraction requires knowing which frames correspond to which phonemes. Quick check: How does the model obtain phone boundaries, and what happens if alignment is poor?

## Architecture Onboarding

- **Component map:** Audio → ASR model (GOP extraction + forced alignment) → GOP features → Transformer encoder → Interactive Attention → Hierarchical scoring with residual connections
- **Critical path:** GOP features (84-dim) + canonical phoneme embeddings + positional embeddings → summed → Transformer encoder (3 layers, 48-dim, 1 head) → Interactive Attention Module → Residual hierarchical modeling → Conv1D + regression heads
- **Design tradeoffs:** Single attention head (1 head outperformed 2-4 heads due to limited data), embedding dimension 48 (smaller than typical to prevent overfitting), 1-D conv (1 layer optimal; deeper convs hurt performance on this dataset size)
- **Failure signatures:** Word stress PCC <0.35 (check word-level interactive attention head integration), large train/validation gap (likely overfitting; reduce embedding size or add dropout), utterance completeness unusually low (expected due to dataset bias)
- **First 3 experiments:** 1) Reproduce ablation from Table 2 by removing interactive attention heads one at a time, 2) Correlation analysis by computing PCC between all score types in your data, 3) Baseline comparison by training parallel multi-task model without hierarchical score passing and interactive attention

## Open Questions the Paper Calls Out

- **Can HIA's performance be further improved by training on larger datasets that support higher model capacity?** The current study is constrained by speechocean762 dataset size, preventing successful training of deeper or wider architectures that might capture more complex pronunciation patterns.

- **Is the proposed framework effective for open-response pronunciation assessment scenarios?** The model relies on canonical phoneme embeddings and text alignment structures typical of read-aloud tasks; it is unclear if the hierarchy holds when text is not pre-specified.

- **Can the Interactive Attention Module be adapted for ASR-free or self-supervised learning frameworks?** The methodology relies explicitly on GOP features derived from an ASR acoustic model; it is unknown if the residual hierarchical structure and attention module are compatible with continuous SSL representations.

## Limitations

- The framework's effectiveness depends heavily on specific dataset characteristics, particularly the strong correlation between lower and higher granularity scores which may not hold for all pronunciation assessment scenarios.
- Optimal hyperparameters were tuned specifically for this dataset size (5000 utterances) and may not generalize to larger datasets.
- The GOP feature extraction pipeline relies on Librispeech ASR model alignment quality, which could introduce systematic errors if alignments are poor.

## Confidence

- **High confidence:** Bidirectional interactive attention mechanism improves word stress prediction (PCC increase from 0.335 to 0.429 with word-level heads)
- **Medium confidence:** Residual connections meaningfully reduce feature forgetting (PCC drop of 0.054 on utterance total when removed)
- **Medium confidence:** Hierarchical score passing contributes to overall performance (PCC drop of 0.062 on word stress when removed)

## Next Checks

1. Test the interactive attention mechanism on datasets with weaker inter-granularity correlations to verify robustness beyond the speechocean762 corpus
2. Implement ablation studies to quantify the relative contribution of each mechanism (interactive attention, residual connections, hierarchical score passing) on new pronunciation datasets
3. Evaluate model performance degradation when forced alignment quality varies, to assess sensitivity to GOP feature extraction pipeline