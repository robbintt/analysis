---
ver: rpa2
title: 'Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model
  Capabilities'
arxiv_id: '2505.06507'
source_url: https://arxiv.org/abs/2505.06507
tags:
- cadquery
- language
- arxiv
- command
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a new paradigm for CAD generation by directly\
  \ producing executable CadQuery code from natural language, bypassing intermediate\
  \ command sequences. The authors build a large-scale dataset of 170,000 text\u2013\
  CadQuery pairs by annotating the Text2CAD dataset with executable Python-based CAD\
  \ scripts."
---

# Text-to-CadQuery: A New Paradigm for CAD Generation with Scalable Large Model Capabilities

## Quick Facts
- arXiv ID: 2505.06507
- Source URL: https://arxiv.org/abs/2505.06507
- Reference count: 40
- Authors: Haoyang Xie; Feng Ju
- Key outcome: Direct generation of executable CadQuery code from natural language with 69.3% top-1 exact match and 48.6% Chamfer Distance reduction

## Executive Summary
This paper introduces a new paradigm for CAD generation by directly producing executable CadQuery code from natural language, bypassing intermediate command sequences. The authors build a large-scale dataset of 170,000 text–CadQuery pairs by annotating the Text2CAD dataset with executable Python-based CAD scripts. They fine-tune six pretrained models ranging from 124M to 7B parameters and observe consistent scaling improvements in generation accuracy.

## Method Summary
The authors propose a direct-to-code approach for text-to-CAD generation, training models to output executable CadQuery scripts rather than intermediate representations. They created a large-scale dataset by converting 170,000 Text2CAD descriptions into CadQuery code, then fine-tuned six transformer models of varying sizes. The approach leverages existing large language models and demonstrates that scaling model size leads to improved generation accuracy and geometric fidelity.

## Key Results
- Top-1 exact match accuracy improved from 58.8% to 69.3%
- Chamfer Distance reduced by 48.6% compared to previous methods
- Consistent scaling improvements observed across model sizes from 124M to 7B parameters

## Why This Works (Mechanism)
The direct generation of executable CadQuery code eliminates intermediate representations that can introduce errors and ambiguity. By training on a large corpus of text-to-code pairs, the model learns the semantic mapping between natural language descriptions and CAD operations. The scaling behavior demonstrates that larger models better capture the complex relationships between language and geometric operations.

## Foundational Learning
- CadQuery/Python CAD operations: Needed for understanding the target output format; quick check: verify familiarity with basic CadQuery primitives and transformations
- Transformer-based sequence generation: Essential for modeling the autoregressive generation process; quick check: review encoder-decoder architecture fundamentals
- Chamfer Distance metric: Critical for evaluating geometric accuracy; quick check: understand the distance calculation between point clouds
- Scaling laws in language models: Important for interpreting the performance improvements; quick check: review how model capacity affects downstream task performance

## Architecture Onboarding
**Component map:** Natural Language Prompt -> Transformer Model -> CadQuery Code -> 3D Model
**Critical path:** Text input → Encoding → Code generation → Execution → Geometric validation
**Design tradeoffs:** Direct code generation vs. intermediate representations; model size vs. computational cost
**Failure signatures:** Syntax errors in generated code, geometric mismatches, missing operations
**First experiments:** 1) Generate simple geometric shapes from basic prompts; 2) Test code execution on a validation set; 3) Measure Chamfer Distance for simple geometries

## Open Questions the Paper Calls Out
None identified in the provided information.

## Limitations
- Limited semantic coverage of the 170,000 training examples for real-world CAD diversity
- Zero-shot performance of 21.1% raises questions about model understanding vs. memorization
- Reliance on fixed CadQuery operations may limit generalizability to custom CAD workflows
- Evaluation focuses only on single-object tasks, not multi-component designs

## Confidence
- Scaling claims: Medium confidence (limited model sizes tested)
- Performance metrics: Medium confidence (narrow evaluation scope)
- Real-world applicability: Low confidence (no user studies or out-of-distribution testing)

## Next Checks
1. Test model robustness on a held-out set of complex, multi-part CAD descriptions not present in the training corpus.
2. Conduct user studies comparing generated CadQuery scripts against manual expert workflows for practical design tasks.
3. Evaluate cross-domain generalization by fine-tuning on a different CAD kernel (e.g., OpenSCAD) and measuring transfer performance.