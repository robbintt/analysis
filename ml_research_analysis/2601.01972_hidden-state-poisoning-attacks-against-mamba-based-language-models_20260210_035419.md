---
ver: rpa2
title: Hidden State Poisoning Attacks against Mamba-based Language Models
arxiv_id: '2601.01972'
source_url: https://arxiv.org/abs/2601.01972
tags:
- trigger
- arxiv
- mamba
- state
- hispa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Hidden State Poisoning Attacks (HiSPAs),
  a novel adversarial attack vector that exploits the recurrent state dynamics of
  Mamba-based language models. HiSPAs use carefully crafted short input phrases to
  irreversibly overwrite information stored in the model's hidden states, causing
  severe performance degradation on information retrieval tasks.
---

# Hidden State Poisoning Attacks against Mamba-based Language Models

## Quick Facts
- arXiv ID: 2601.01972
- Source URL: https://arxiv.org/abs/2601.01972
- Reference count: 28
- Key outcome: Hidden State Poisoning Attacks (HiSPAs) exploit Mamba's recurrent state dynamics to cause severe information retrieval degradation through carefully crafted short input phrases

## Executive Summary
This paper introduces Hidden State Poisoning Attacks (HiSPAs), a novel adversarial attack vector that exploits the recurrent state dynamics of Mamba-based language models. HiSPAs use carefully crafted short input phrases to irreversibly overwrite information stored in the model's hidden states, causing severe performance degradation on information retrieval tasks. The authors demonstrate that even a large 52B hybrid SSM-Transformer model (Jamba) collapses under optimized HiSPA triggers, while pure Transformers remain unaffected. Through ROBENCH-25, a benchmark for long-context information retrieval, the research shows that HiSPAs can amplify Prompt Injection Attack effectiveness in hybrid models. Interpretability analysis reveals that activation norms in specific middle layers (blocks 28-37) strongly correlate with model failure, suggesting potential detection mechanisms. The findings highlight critical security vulnerabilities in SSM architectures and underscore the need for robust evaluation frameworks before deployment.

## Method Summary
HiSPAs leverage the selective state spaces mechanism (SSM) in Mamba-based models by injecting carefully crafted short phrases that irreversibly corrupt hidden state representations. The attack works by exploiting the recurrent state dynamics where information accumulates over context length. Through optimization techniques, attackers generate trigger phrases that, when inserted into input, cause the model to lose access to previously stored information. The method uses a two-stage approach: first generating candidate triggers through gradient-based optimization, then validating their effectiveness on information retrieval tasks. The attack specifically targets the memory-dependent characteristics of SSM layers while avoiding detection by remaining short and contextually plausible.

## Key Results
- A 52B hybrid SSM-Transformer model (Jamba) collapses under optimized HiSPA triggers during information retrieval tasks
- Pure Transformer models remain unaffected by HiSPAs, demonstrating architecture-specific vulnerability
- HiSPAs amplify Prompt Injection Attack effectiveness in hybrid models by corrupting state representations
- Activation norm analysis in middle layers (blocks 28-37) strongly correlates with model failure, enabling potential detection
- ROBENCH-25 benchmark reveals severe performance degradation on long-context information retrieval

## Why This Works (Mechanism)
HiSPAs exploit the fundamental architecture of Mamba-based models where information is stored in selective state spaces that accumulate context over time. The attack crafts input phrases that, when processed, create destructive interference patterns in the hidden states. These triggers leverage the recurrent nature of SSM layers to permanently overwrite or corrupt previously stored information, effectively causing amnesia for specific content. The mechanism takes advantage of how SSM layers selectively update their state representations, allowing carefully designed inputs to hijack this process and inject harmful patterns that persist throughout processing.

## Foundational Learning
- Selective State Spaces Mechanism: Why needed - Understanding how Mamba stores and updates information differently from Transformers. Quick check - Verify how state updates differ from standard attention mechanisms.
- Recurrent State Dynamics: Why needed - The attack exploits temporal accumulation of information in SSM layers. Quick check - Trace how information flows through recurrent states across context.
- Hybrid Architecture Vulnerabilities: Why needed - The attack specifically targets hybrid models combining SSM and Transformer components. Quick check - Identify which architectural components are most susceptible.
- Gradient-based Optimization for Adversarial Examples: Why needed - HiSPAs use optimization to generate effective trigger phrases. Quick check - Understand the optimization objective and constraints.
- Information Retrieval in Long Context: Why needed - The benchmark measures how well models retain information over extended sequences. Quick check - Examine how retrieval performance degrades under attack.

## Architecture Onboarding

Component Map:
Input -> Embedding Layer -> SSM Blocks (Selective State Spaces) -> Transformer Blocks -> Output Layer

Critical Path:
The attack targets the SSM blocks where state accumulation occurs. Information flows through embedding, gets processed by SSM layers where the hidden state corruption happens, then passes through Transformer blocks before output. The critical vulnerability lies in the interaction between SSM state updates and input embeddings.

Design Tradeoffs:
Mamba trades computational efficiency for memory-dependent processing, which creates the attack surface. The selective mechanism that makes SSM efficient also makes it vulnerable to state overwriting. Hybrid models gain efficiency but inherit this security weakness.

Failure Signatures:
- Sudden performance collapse on information retrieval tasks
- Activation norm spikes in middle layers (blocks 28-37)
- Inability to retrieve previously stored information despite correct context length
- Consistent failure patterns across multiple retrieval queries after trigger injection

First Experiments:
1. Test trigger effectiveness on pure SSM model (without Transformer components) to isolate vulnerability source
2. Measure activation norm changes across all layers when triggers are applied to identify exact failure points
3. Evaluate attack transferability between different Mamba-based architectures to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Limited comparison with other attack methods, making it difficult to assess HiSPA's relative effectiveness in the broader adversarial landscape
- Evaluation focuses primarily on information retrieval tasks, leaving open questions about performance degradation in reasoning, generation, and safety-critical domains
- Interpretability findings show correlation between middle layer activations and model failure but lack mechanistic explanation for how HiSPAs overwrite hidden states
- Study uses specific hybrid architecture (Jamba) and custom benchmark (ROBENCH-25), raising questions about generalizability across different SSM architectures and real-world scenarios

## Confidence
High: HiSPAs as an effective attack vector against Mamba-based models, demonstrated through empirical results showing severe performance degradation in controlled experiments

Medium: Pure Transformer models remain unaffected by HiSPAs, based on single hybrid model comparison that may not generalize across all architectural variations

Medium: Interpretability findings regarding middle layer activations (blocks 28-37) as indicators of model failure, given these are correlational observations without mechanistic explanation

## Next Checks
1. Test HiSPAs against diverse Mamba-based architectures beyond Jamba hybrid model, including pure SSM models and different hybrid configurations, to establish broader applicability

2. Conduct ablation studies to determine whether observed effects are specific to HiSPAs or could be achieved through other adversarial techniques, establishing HiSPA's unique contribution to attack landscape

3. Evaluate HiSPA effectiveness across multiple task domains beyond information retrieval, including reasoning tasks, code generation, and safety-critical applications, to understand full scope of vulnerability