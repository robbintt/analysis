---
ver: rpa2
title: 'The WHY in Business Processes: Unification of Causal Process Models'
arxiv_id: '2505.22871'
source_url: https://arxiv.org/abs/2505.22871
tags:
- causal
- process
- execution
- each
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of unifying multiple causal process
  models from event logs with missing data and alternating causal conditions across
  variants. The core method extends causal process graphs with gating mechanisms (AND,
  OR, XOR, and exhaustive OR gateways) to capture alternative execution paths and
  explicitly represent alternating causal relationships.
---

# The WHY in Business Processes: Unification of Causal Process Models

## Quick Facts
- arXiv ID: 2505.22871
- Source URL: https://arxiv.org/abs/2505.22871
- Reference count: 40
- Primary result: Unified causal process models with gating mechanisms (AND, OR, XOR, ORE) capture alternating causal relationships across variants with cubic polynomial scalability

## Executive Summary
This paper addresses the challenge of unifying multiple causal process models discovered from event logs with missing data and alternating causal conditions. The authors extend causal process graphs with explicit gating mechanisms (AND, OR, XOR, and exhaustive OR gateways) to capture alternative execution paths and represent alternating causal relationships. By partitioning event logs to handle missing data, applying causal discovery within each partition, and then unifying results through a matrix-based algorithm, the method produces unified causal execution graphs that are both sound and complete.

## Method Summary
The method extends causal process graphs with gating mechanisms to unify multiple causal process models from event logs. It first partitions the log into subsets with identical activity sets, applies causal discovery (LiNGAM) within each partition with noise filtering, converts each causal graph to a matrix representation, and then unifies these matrices using an algorithm that classifies rows into gateway types. The final unified causal execution graph captures all individual causal dependencies while explicitly representing alternating execution conditions.

## Key Results
- Demonstrated scalability with computation times ranging from 0.26 to 118.89 seconds across five datasets
- Cubic polynomial relationships between activity count and computation time (R² values: .9209-.9781)
- Soundness and completeness verified through correctness checks
- Evaluated on three open datasets (Road Traffic Fines, Sepsis, BPIC12) and two proprietary datasets (Helpdesk, CROMA)

## Why This Works (Mechanism)
The approach works by explicitly representing causal relationships through extended causal execution graphs with logical gateways. By partitioning logs to isolate variants and applying causal discovery within each partition, it avoids missing data issues. The unification algorithm then identifies logical relationships (AND, OR, XOR, ORE) from the matrix representation of multiple causal graphs, creating a single model that preserves all individual causal dependencies while capturing alternative execution paths through alternating causal conditions.

## Foundational Learning

- **Concept: Causal Discovery (CD) from Observational Data**
    - Why needed here: The entire method builds upon a causal model of a business process discovered from observational data (timestamps), not given a priori
    - Quick check question: How does the algorithm distinguish causality from mere correlation or temporal precedence?

- **Concept: Directed Acyclic Graphs (DAGs)**
    - Why needed here: The fundamental data structure for both the input and unified models is a DAG; causal discovery and unification both operate on this structure
    - Quick check question: Why are cycles prohibited in the causal execution graphs used in this framework?

- **Concept: Process Variants and Partitions**
    - Why needed here: The core problem addressed is unifying models from different variants of a process; understanding variant vs. partition distinction is key to the method's data-handling strategy
    - Quick check question: What is the primary reason for grouping multiple variants into a single partition before running causal discovery?

## Architecture Onboarding

- **Component Map:**
    - Input event log → Log Partitioner → Partitioned logs → Causal Discovery Engine → Causal Execution graphs → Graph-to-Matrix Transformer → Unified matrix → Unification Core → Annotated matrix → Graph Constructor → Unified U-CX graph

- **Critical Path:**
    1. Partitioning: Incorrect partitioning (failing to separate traces with known confounders) is the primary failure mode
    2. Unification: The correctness of the final model depends entirely on the Unification Core correctly identifying logical relationships from the matrix rows

- **Design Tradeoffs:**
    - Naïve Union vs. Unified Model: Simple union of nodes and edges is semantically ambiguous; unified model's complexity is the trade-off for explicit, correct causal logic
    - Simplification: Optional simplification step can produce more compact logical expressions but may be difficult to visualize with standard BPMN-like gateway notation

- **Failure Signatures:**
    - Spurious Gateways: Appearance of ORC or XORC gateway that doesn't reflect true process variation, likely due to noise in input data
    - Dense/Unreadable Graph: Unified graph too complex to interpret, potentially caused by too many variants with highly divergent causal structures
    - Bias from Missing Data: If Assumption 1 is violated and a confounder exists within a partition, causal discovery will produce biased CX graph

- **First 3 Experiments:**
    1. Unit Test on Synthetic Log: Create small synthetic log with two clear variants (e.g., A→B→C and A→C), run full pipeline, verify output graph correctly identifies single gateway from A that splits to B and C
    2. Scalability Benchmark: Run method on provided open datasets, measure runtime for each partition and total unification time, confirm cubic polynomial complexity relative to number of activities
    3. Correctness Validation: Implement check script that takes generated U-CX graph and set of input CX graphs, automatically verify soundness (all edges in U-CX exist in at least one input) and completeness (all input edges preserved in U-CX)

## Open Questions the Paper Calls Out

- **Open Question 1:** How can large language models (LLMs) be leveraged for logic simplification using few-shot learning to balance compactness and completeness in unified causal graphs?
    - Basis in paper: [explicit] The conclusion states future work could "explore leveraging large language models for simplification using few-shot learning and user-rated outputs"
    - Why unresolved: Existing logic simplification algorithms (like Quine-McCluskey) can yield expressions with negation and constants, which current graphical notation cannot represent
    - What evidence would resolve it: Implemented LLM-based framework that successfully simplifies complex logical expressions into valid graph structures comparable to or better than algorithmic baselines

- **Open Question 2:** How can the current causal execution graph notation be extended to incorporate literals such as negation and logical "1"s derived from logic simplification?
    - Basis in paper: [explicit] The authors note that the simplification step yields literals that are "not expressible with our current graph notation," marking this as an open question
    - Why unresolved: The diamond-based gateway notation was designed to capture alternating flows (AND/OR/XOR) but lacks semantics to visualize negation of a causal path or a tautology
    - What evidence would resolve it: Formal extension of U-CX graph definition and visual syntax that includes new node or edge types for logical negation and constants

- **Open Question 3:** How can the U-CX model be extended to display causal edge coefficients while maintaining visual usability in dense process maps?
    - Basis in paper: [explicit] The paper mentions that while the model could serve as foundation for C-Nets, "incorporating additional literals... could enhance clarity but may also lead to dense visualizations"
    - Why unresolved: Current visual representation focuses on existence of causal dependencies; adding quantitative weights alongside new gateway logic risks visual clutter
    - What evidence would resolve it: User study or visualization metric demonstrating that added quantitative information can be displayed without significantly reducing readability of process map

## Limitations

- The approach inherits biases and errors from the underlying causal discovery step, which assumes non-Gaussian noise and linear relationships that may not hold in all business process contexts
- Proprietary datasets (Helpdesk and CROMA) cannot be independently verified, limiting reproducibility of those results
- Method shows exponential growth in memory requirements for the unification matrix as the number of partitions increases, potentially limiting applicability to extremely large event logs

## Confidence

**High Confidence**: The core mathematical framework for unification (matrix construction, row classification into gateway types) appears sound based on proofs provided; scalability results showing cubic polynomial growth in computation time are well-supported by empirical data across five datasets

**Medium Confidence**: Correctness of unified models depends critically on quality of individual causal discovery results; since method inherits any biases or errors from CD step, and CD in observational data is inherently challenging, overall reliability is somewhat reduced; simplification step's effectiveness and correctness are not fully evaluated

**Low Confidence**: Noise threshold parameter θ is not well-specified, making it difficult to reproduce results without extensive parameter tuning; handling of cycles or non-DAG structures is not discussed, though method assumes acyclic causal graphs

## Next Checks

1. **Parameter Sensitivity Analysis**: Systematically vary the noise threshold θ across multiple orders of magnitude on public datasets and measure impact on gateway classification accuracy and runtime

2. **Cross-Validation on Synthetic Data**: Generate synthetic event logs with known causal structures and alternating conditions, then verify that unified models correctly recover these structures across multiple random seeds

3. **Edge Case Robustness**: Test the method on event logs containing known confounders that violate Assumption 1 to quantify degradation in unified model quality and identify early warning signs of violation