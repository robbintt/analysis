---
ver: rpa2
title: 'The American Ghost in the Machine: How language models align culturally and
  the effects of cultural prompting'
arxiv_id: '2512.12488'
source_url: https://arxiv.org/abs/2512.12488
tags:
- cultural
- importance
- please
- gpt-4
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the cultural alignment of popular large
  language models (LLMs) and tests whether cultural prompting can effectively shift
  their alignment to match different countries. Using Hofstede's cultural dimensions
  and the VSM13 International Survey, the authors evaluated eight models (DeepSeek-V3/V3.1,
  GPT-4/4.1/5, Claude Opus 4, Llama 3.1, Mistral Large) across six countries (China,
  France, India, Iran, Japan, United States).
---

# The American Ghost in the Machine: How language models align culturally and the effects of cultural prompting

## Quick Facts
- arXiv ID: 2512.12488
- Source URL: https://arxiv.org/abs/2512.12488
- Reference count: 40
- Most models exhibit US alignment by default, but cultural prompting can effectively shift alignment to target countries

## Executive Summary
This study investigates cultural alignment of popular large language models (LLMs) using Hofstede's cultural dimensions and tests whether cultural prompting can shift their alignment to match different countries. The authors evaluated eight models across six countries, finding that without cultural prompting, most models showed strong alignment with the United States regardless of developer origin. Cultural prompting successfully improved alignment for seven of eight models, with DeepSeek-V3.1 showing the largest improvement (30.87% decrease in dimension distance). GPT-4 achieved the lowest overall distance after prompting. The findings demonstrate that cultural prompting is an effective and scalable method for adapting LLMs to different cultural contexts, though models struggled particularly with Japan and China.

## Method Summary
The study used Hofstede's cultural dimensions (PDI, IDV, MAS, UAI, LTO, IVR) measured through the VSM13 International Survey (24 questions). Eight LLMs were tested with and without cultural system prompts ("You are an average person from [country]") across six countries (China, France, India, Iran, Japan, US). For each model-country pair, 50 responses were collected per question at maximum temperature with ascending seeds. Hofstede's equations (Table 1) converted mean responses to dimension scores, which were compared to real-world country baselines to calculate total distance as the sum of absolute differences across all six dimensions.

## Key Results
- Without prompting, most models strongly aligned with the United States regardless of developer origin
- DeepSeek models (Chinese company) showed the poorest alignment with China (>40 points/dimension average distance)
- Cultural prompting improved alignment for 7/8 models, with DeepSeek-V3.1 showing 30.87% improvement
- GPT-4 achieved the lowest total distance after cultural prompting
- All models struggled to align with Japan and China despite two models originating from DeepSeek

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cultural prompting shifts model outputs toward target cultural values by activating culture-specific response patterns latent in training data.
- Mechanism: System prompts prime the model to weight learned representations of that culture more heavily during generation, reducing aggregate distance to target cultural dimensions.
- Core assumption: The model has sufficient exposure to target culture patterns during pretraining to retrieve and simulate them when cued.
- Evidence anchors:
  - [abstract] "When culturally prompted, seven of the eight models shifted closer to the expected culture."
  - [section 3.2] "DeepSeek-V3.1 showed the most significant improvement (30.87% reduction in total distance across dimensions)."
  - [corpus] Related work (Tao et al. 2024, Kwok et al. 2024) showed initial promise for cultural prompting, but with limited population sizes.
- Break condition: If the target culture is underrepresented in training data, prompting fails—models default to dominant training distribution (US).

### Mechanism 2
- Claim: Default US alignment emerges from WEIRD-skewed training corpora, not model developer geography.
- Mechanism: Training data dominated by Western, educated, industrialized, rich, democratic content embeds US cultural priors into model weights; these priors express themselves when no cultural prompt is provided.
- Core assumption: Cultural priors are not overwritten by fine-tuning or RLHF unless explicitly targeted.
- Evidence anchors:
  - [abstract] "Most models exhibited a strong alignment with the United States, while showing weaker or inconsistent alignment with other cultures."
  - [section 3.1] "Models from the Chinese company DeepSeek aligned furthest from China's real-world dimension values, with an average distance of over 40 points per dimension."
  - [corpus] Demszky et al. (2023) documented LLM training data bias toward WEIRD societies.
- Break condition: If training data were rebalanced across cultures, default alignment would shift accordingly—this is not tested in the paper.

### Mechanism 3
- Claim: Cultural prompting effectiveness varies asymmetrically across cultures due to differential representation and semantic entanglement with US culture.
- Mechanism: Cultures more frequently co-occurring with English-language content (India, Iran) have more extractable representations; cultures less present or more semantically distant (China, Japan, France) yield weaker or counterproductive shifts.
- Core assumption: The model's internal representation of a culture is proportional to its frequency and salience in training data.
- Evidence anchors:
  - [section 3.2] "Each individual model aligned closer to the United States than France when culturally prompting for France... highlighting the United States as a dominant culture in the West."
  - [section 3.2] "All models struggled to align with Japan and China, despite two models originating from the Chinese company DeepSeek."
  - [corpus] Pava et al. (2025) noted models struggle with less popular languages; Masoud et al. (2025) found similar issues with Arab cultures.
- Break condition: Cultures with strong anti-American semantic associations may resist alignment via simple prompting.

## Foundational Learning

- **Hofstede's Cultural Dimensions (PDI, IDV, MAS, UAI, LTO, IVR)**
  - Why needed here: This is the measurement framework used to quantify cultural alignment. Each dimension (e.g., Individuality, Power Distance) is calculated from VSM13 survey responses.
  - Quick check question: If a population scores high on Power Distance Index, does it expect more or less hierarchical workplace relationships?

- **WEIRD Bias in Training Data**
  - Why needed here: Explains why default model outputs skew US-aligned regardless of developer origin.
  - Quick check question: Name two consequences of training LLMs predominantly on English-language, Western internet content.

- **System Prompts vs. In-Context Learning**
  - Why needed here: Cultural prompting is implemented via system prompts; understanding how prompts steer behavior without weight changes is essential.
  - Quick check question: Does changing a system prompt modify model weights, or does it only affect the current generation context?

## Architecture Onboarding

- **Component map:**
  VSM13 survey questions (24 Likert-scale items, adapted for LLMs) -> System prompts (cultural persona specification) -> Target LLM (8 models tested) -> Hofstede dimension formulas (Table 1) -> Absolute distance calculation to real-world country baselines

- **Critical path:**
  1. Define cultural prompt template for each country (6 countries + null condition)
  2. For each model-country pair, administer 24 VSM13 questions × 50 responses (temperature=max for variability)
  3. Compute mean responses (m01–m24) per population
  4. Apply Hofstede equations (Table 1) with normalization constants (Table 8)
  5. Calculate total distance to each country's baseline dimensions (sum of absolute differences)

- **Design tradeoffs:**
  - **Temperature=max:** Ensures response variability simulating human population spread, but increases noise. Lower temperature would yield more consistent but less realistic "populations."
  - **Population size=50:** Follows Hofstede's minimum recommendation; larger samples would improve precision but increase cost.
  - **English-only prompting:** Avoids language-switching confounds but may underutilize multilingual model capabilities for non-English cultures.

- **Failure signatures:**
  - **Negative prompting effect:** Llama 3.1 increased total distance by 27.33% with cultural prompting—prompting degraded alignment.
  - **France paradox:** Llama 3.1 aligned closer to the United States than France when culturally prompting for France, highlighting the United States as a dominant culture in the West.
  - **Origin-destination mismatch:** DeepSeek models (Chinese company) showed worst China alignment (>40 points/dimension average distance).
  - **Low dimension range:** Mistral Large had lowest average dimension range (34.15) and achieved no strong alignments—suggests limited cultural expressivity.

- **First 3 experiments:**
  1. **Reproduce null-condition baseline:** Run all 8 models with no cultural prompt on the 24 VSM13 questions (n=50 each), compute dimension scores, verify US alignment pattern.
  2. **Single-country prompting test:** Apply India cultural prompt to GPT-4 and DeepSeek-V3.1 (top performers), measure distance reduction vs. null condition.
  3. **Failure-case investigation:** Run France cultural prompt on 3 models, compute distances to both France and US baselines to confirm the "US pull" effect reported in Table 2.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why did cultural prompting for France result in worse alignment with French cultural dimensions, instead shifting models closer to United States dimensions?
- Basis in paper: [explicit] The Results section notes that culturally prompting for France produced "surprising results"—total distance increased 13.63% (from 1,310.12 to 1,488.7), yet "each individual model aligned closer to the United States than France when culturally prompting for France," highlighting "the United States as a dominant culture in the West."
- Why unresolved: The authors describe this finding as unexpected but do not investigate underlying mechanisms or test whether this extends to other Western European cultures.
- What evidence would resolve it: Testing cultural prompting in French language; analyzing training data composition for French vs. English cultural content; testing other Western European countries to determine if this is France-specific.

### Open Question 2
- Question: What factors explain why Llama 3.1 is the only model that responded negatively to cultural prompting, shifting further from target cultures in five of six cases?
- Basis in paper: [explicit] The paper reports that "Llama 3.1 shifted further away from the prompted culture in five of six cases, leading to an increase of 27.33% in total distance and marking cultural prompting as largely ineffective for this model."
- Why unresolved: While documented, the paper does not investigate architectural, training, or fine-tuning differences that might cause Llama 3.1's anomalous behavior compared to other models.
- What evidence would resolve it: Comparative analysis of Llama 3.1's architecture and training methodology against models that responded positively; controlled ablation studies on specific training factors.

### Open Question 3
- Question: To what extent would larger population sizes and expanded country coverage alter the measured cultural alignment patterns of LLMs?
- Basis in paper: [explicit] The Limitations section states: "The population size used in this work is based on... Hofstede... recommendation for a value of 50 responses. However, most of the populations surveyed in his work had population sizes averaging in the hundreds... This work should be continued with larger population sizes and more countries to solidify and expand our understanding."
- Why unresolved: Using minimum recommended sample sizes and only six countries may limit precision and generalizability of findings about model alignment.
- What evidence would resolve it: Replication with hundreds of responses per model-country pair across all countries in Hofstede's VSM13 dataset, comparing results to current findings.

### Open Question 4
- Question: Does the inability of Chinese-developed models (DeepSeek) to align with Chinese cultural dimensions stem primarily from English-dominant training data composition?
- Basis in paper: [inferred] The paper concludes that "the alignment of each model reflects the inherent biases in the training data and not the country of origin for the model" based on DeepSeek's poor China alignment, but provides no direct analysis of training data composition.
- Why evidence would resolve it: Analysis of training corpora showing language distribution and cultural content origins; experiments with models trained on explicitly culturally-diverse datasets.

## Limitations

- Sample size of 50 responses per model-country pair follows Hofstede's minimum recommendations but may be insufficient for precise cultural measurement
- English-only prompting approach may systematically disadvantage non-Western cultures and limit multilingual model capabilities
- The France paradox remains unexplained, suggesting fundamental limitations in the cultural prompting approach or complex semantic entanglements between Western cultures
- Only six countries were tested, limiting generalizability to other cultural contexts

## Confidence

**High Confidence:**
- Cultural prompting improves alignment for most models (supported by quantitative results across 7/8 models)
- US cultural dominance in default model outputs (consistently observed across all tested models)
- DeepSeek models' poor alignment with China despite Chinese origin (quantified with >40 points/dimension average distance)

**Medium Confidence:**
- Cultural prompting effectiveness varies by culture (supported by comparative results but mechanism not fully explained)
- Negative prompting effect for Llama 3.1 (single anomalous result requiring replication)
- France paradox observations (qualitative pattern observed but not explained)

**Low Confidence:**
- Generalizability beyond the six tested countries (only six cultures examined)
- Long-term stability of cultural prompting effects (single-shot evaluation)
- Optimal prompting strategies for different cultural contexts (single prompt template tested)

## Next Checks

1. **Replicate the France paradox effect**: Run cultural prompting for France on 3+ models and explicitly compute distances to both France and US baselines to verify whether the "US pull" effect is reproducible and quantifiable.

2. **Vary population size**: Repeat the DeepSeek-V3.1 + India cultural prompt experiment with n=25 and n=100 responses to assess whether the 30.87% improvement is robust to sample size changes or an artifact of the chosen n=50.

3. **Test multilingual prompting**: For models with multilingual capabilities, repeat the China cultural prompt experiment using Chinese-language prompts to determine whether the poor China alignment is due to English-only prompting limitations.