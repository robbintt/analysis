---
ver: rpa2
title: 'Dynamic-KGQA: A Scalable Framework for Generating Adaptive Question Answering
  Datasets'
arxiv_id: '2503.05049'
source_url: https://arxiv.org/abs/2503.05049
tags:
- arxiv
- question
- answer
- knowledge
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Dynamic-KGQA is a scalable framework for generating adaptive QA
  datasets from knowledge graphs to mitigate data contamination risks in LLM evaluation.
  It extracts thematic subgraphs from seed texts, uses LLMs to generate QA pairs with
  controlled variability, and employs LLM-as-a-Judge for quality verification.
---

# Dynamic-KGQA: A Scalable Framework for Generating Adaptive Question Answering Datasets

## Quick Facts
- arXiv ID: 2503.05049
- Source URL: https://arxiv.org/abs/2503.05049
- Authors: Preetam Prabhu Srikar Dammu; Himanshu Naidu; Chirag Shah
- Reference count: 40
- Generates contamination-resistant KGQA datasets using dynamic subgraph extraction and LLM-as-a-Judge validation

## Executive Summary
Dynamic-KGQA is a framework that generates adaptive question-answering datasets from knowledge graphs to address data contamination risks in LLM evaluation. The system extracts thematic subgraphs from seed texts, generates QA pairs using LLMs with controlled variability, and employs a panel of diverse LLMs to verify quality through unanimous consensus. Evaluated on YAGO 4.5, the framework produces 200K QA pairs with balanced topic distribution and statistical consistency across dynamic runs, showing reduced memorization effects compared to older datasets.

## Method Summary
Dynamic-KGQA extracts subgraphs from YAGO 4.5 knowledge graph using Steiner Tree algorithms to create minimal connected structures from seed entities found in Wiki-40B texts. QA pairs are generated using Claude 3.5 Sonnet with temperature-based variability and triple reordering for diversity. Quality verification employs three distinct LLM judges (Command-R, Mistral Small, Amazon Nova Lite) requiring unanimous agreement on logical structure, non-redundancy, answer support, and adequacy. The framework produces compact subgraphs for each QA pair while maintaining topic distribution consistency across dynamic runs.

## Key Results
- Generates 200K QA pairs with balanced topic distribution across 6 domains (sports, science, finance, technology, politics, entertainment)
- Statistical tests confirm topic consistency across dynamic runs (χ² p > 0.05, Cramer's V < 0.03)
- LLM baselines show lower scores than on older datasets, suggesting reduced memorization effects
- Produces compact subgraphs (avg. 14.1 nodes, 23.1 edges) that support multi-hop reasoning questions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Dynamic-KGQA mitigates data contamination by generating unique dataset variants on every execution while preserving the underlying topic distribution.
- **Mechanism:** The framework extracts a subgraph and serializes it into triples. It then introduces controlled randomness via two parameters: temperature (T) for the LLM and a triple reordering seed (R). By shuffling the order of facts before generation, the LLM produces distinct lexical formulations and reasoning paths ("paraphrased" or "unique" pairs) for the same semantic content.
- **Core assumption:** LLMs memorize static sequences of text rather than the underlying generative logic of a subgraph; therefore, varying the input order and stochastic sampling sufficiently breaks memorization without altering the semantic topic.
- **Evidence anchors:**
  - [abstract] "Dynamic-KGQA generates a new dataset variant on every run while preserving the underlying distribution..."
  - [section 3.3] Eq. 12 defines `DynamicQA` as a function of `Reorder(G', R)` and `GenerateQA(..., T)`.
  - [section 5] Table 4 shows <0.01% identical pairs across runs, with χ² tests confirming no significant distribution shift (p > 0.05).

### Mechanism 2
- **Claim:** The framework ensures high-quality reasoning by enforcing a "consensus filter" using a panel of diverse LLMs acting as judges.
- **Mechanism:** Instead of relying on a single evaluation model, Dynamic-KGQA routes generated QA pairs to three distinct models (Cohere Command-R, Mistral Small, Amazon Nova Lite). A pair is retained only if all three models unanimously validate it against four criteria: logical structure, non-redundancy, answer support, and adequacy.
- **Core assumption:** Uncorrelated errors across different model architectures are rare; therefore, unanimous agreement implies a higher probability of objective correctness than single-model evaluation.
- **Evidence anchors:**
  - [section 3.5] "All LLM-as-a-Judge models must reach unanimous agreement... any disagreement results in the QA pair being discarded."
  - [section 2] Cites Zheng et al. [76] and Gilardi et al. [17] to support the reliability of LLM-as-a-Judge for objective tasks.

### Mechanism 3
- **Claim:** The use of Steiner Tree extraction localizes reasoning and prevents "reasoning drift" by isolating a minimal, coherent subgraph.
- **Mechanism:** Starting from seed entities, the system expands to a 1-hop neighborhood. It then applies a Steiner Tree approximation algorithm to prune this down to the minimal set of triples connecting the seeds. This constrains the LLM's generation process to relevant facts, reducing hallucinations triggered by noisy or irrelevant graph regions.
- **Core assumption:** The minimal connected subgraph contains all necessary evidence to form a valid multi-hop question; any triple outside this tree is noise.
- **Evidence anchors:**
  - [section 3.1.4] "Steiner tree extraction refines the graph to a minimal, coherent structure while filtering noise."
  - [figure 2] Visualizes the pruning of "Idea Factory" and "Silicon Studio" nodes to maintain connectivity between "Sega" and "Hideki Kamiya".

## Foundational Learning

- **Concept:** **Steiner Trees vs. Neighborhood Expansion**
  - **Why needed here:** You must distinguish between "getting all neighbors" (which adds noise) and "finding the minimal connecting path" (which preserves signal). This is the core filtering logic of the framework.
  - **Quick check question:** If you have entities A and C connected via B, does a Steiner Tree include node D which is connected only to A but not to C? (Answer: Generally no, unless D is a seed/terminal node).

- **Concept:** **LLM-as-a-Judge (Consensus Strategies)**
  - **Why needed here:** The framework relies on automated validation rather than human review. Understanding that "unanimous agreement" filters for high precision (at the cost of recall/samples) is critical for interpreting the dataset's characteristics.
  - **Quick check question:** If Model A says "Keep" and Model B says "Discard", what is the final output for that QA pair? (Answer: Discarded).

- **Concept:** **Statistical Consistency (Chi-Square Test)**
  - **Why needed here:** The paper claims the dataset is "dynamic but consistent." This relies on proving that while samples change, the *topic distribution* (e.g., Sports vs. Science) does not shift significantly between runs.
  - **Quick check question:** A p-value of 0.65 in a Chi-Square test comparing Run 1 and Run 2 distributions implies what? (Answer: Fail to reject the null hypothesis; distributions are likely consistent).

## Architecture Onboarding

- **Component map:** Wiki-40B seed texts -> Entity Linker -> 1-Hop Expander -> Steiner Tree Pruner -> LLM Generator (Claude 3.5) -> Shuffler + Temperature Controller -> 3-Judge Panel (Command-R, Mistral Small, Nova Lite) -> Unanimity Gate

- **Critical path:** The Steiner Tree extraction. If this produces a disconnected graph or one that is too sparse, the downstream LLM will have no "path" to traverse, resulting in invalid single-hop or hallucinated questions.

- **Design tradeoffs:**
  - **Precision vs. Scale:** The unanimous consensus requirement (3 judges) ensures high data quality but significantly increases compute cost and reduces dataset yield (many samples are dropped).
  - **Dynamism vs. Consistency:** High temperature (T=0.8) creates diverse questions but risks straying from the subgraph logic. The paper tries to balance this with low-T verification and structural grounding.

- **Failure signatures:**
  - **Empty Output:** The Steiner Tree returned a disconnected graph, or the Judges were too strict.
  - **Trivial Questions:** The subgraph extraction failed to prune 1-hop neighbors, leaving the LLM to ask simple lookup questions instead of multi-hop reasoning ones.
  - **Schema Mismatch:** YAGO 4.5 URIs not found in the Wiki-40B seed text entities.

- **First 3 experiments:**
  1. **Consistency Check:** Run the generation pipeline 3 times on the same 100 seed texts. Calculate the intersection of generated questions (should be near 0) and the variance of topic labels (should be low) to verify the "Dynamic" claim.
  2. **Judge Ablation:** Compare dataset yield when using only 1 Judge vs. the 3-Judge consensus to quantify the "cost" of the unanimity constraint.
  3. **Subgraph Stress Test:** Manually inspect generated questions from subgraphs of size <5 triples vs. >20 triples to see if the "multi-hop" prompt requirement fails on small graphs.

## Open Questions the Paper Calls Out

- **Question 1:** How does fine-tuning on the static training splits of Dynamic-KGQA affect model performance on dynamic test variants compared to few-shot prompting?
  - **Basis:** The authors explicitly state in the Limitations section that "many alternative configurations remain unexplored" and that "further experimentation, including fine-tuning... is necessary" due to computational constraints.
  - **Why unresolved:** The reported baselines rely solely on standard prompting (IO) and Chain-of-Thought (CoT) strategies. The potential for models to learn the underlying knowledge graph structure or reasoning patterns via fine-tuning remains untested.
  - **What evidence would resolve it:** A comparative study benchmarking the performance of fine-tuned open-source models (e.g., Llama 3) against few-shot baselines specifically on the dynamic variants of the test set.

- **Question 2:** Can agent-based KGQA methods like Think-on-Graph (ToG) be effectively adapted to the YAGO 4.5 schema to close the performance gap observed against Freebase-based benchmarks?
  - **Basis:** Page 7 notes that the "gap between ToG and LLM-only performance is smaller than reported" likely due to ToG being designed for Freebase. The authors explicitly "leave further exploration of knowledge integration techniques, prompt optimizations, and model tuning for future work."
  - **Why unresolved:** The current lower performance of ToG on Dynamic-KGQA may reflect schema incompatibility (Freebase vs. YAGO) rather than a failure of the reasoning method itself.
  - **What evidence would resolve it:** Experiments re-evaluating ToG or similar agents using prompt templates and tools specifically optimized for the YAGO 4.5 ontology.

- **Question 3:** Does the "LLM-as-a-Judge" verification pipeline introduce systematic blind spots that fail to detect subtle hallucinations in the generated QA pairs?
  - **Basis:** The methodology (Section 3.5) relies entirely on a panel of LLMs to verify logical structure and answer support. However, the Limitations section acknowledges that these models are "prone to errors, including hallucinations," raising concerns about the validity of using LLMs to evaluate LLM-generated content without human ground truth.
  - **Why unresolved:** The paper asserts the dataset is high-quality based on automated metrics but lacks a human evaluation study to validate the accuracy of the automated judges.
  - **What evidence would resolve it:** A human annotation study comparing the error rates of the LLM-judge panel against human experts for a statistically significant sample of the generated dataset.

## Limitations
- The entity linking method from Wiki-40B seed texts to YAGO 4.5 URIs is unspecified, creating potential reproducibility gaps
- The LLM-as-Judge unanimity requirement may create high rejection rates that significantly impact dataset yield and computational efficiency
- The statistical consistency tests demonstrate topic stability but don't validate semantic equivalence of generated questions

## Confidence
- **High Confidence**: The subgraph extraction mechanism (Steiner Tree) and its role in preventing reasoning drift is well-supported by the algorithmic description and visualization
- **Medium Confidence**: The LLM-as-Judge consensus mechanism is theoretically sound but lacks empirical validation of individual judge biases or the impact of relaxing unanimity requirements
- **Medium Confidence**: The temperature-based variability mechanism appears robust given the statistical tests, though the actual semantic diversity of generated questions warrants deeper analysis

## Next Checks
1. **Entity Linking Validation**: Implement and evaluate different entity linking approaches (e.g., fuzzy matching, neural linker) to quantify their impact on subgraph quality and downstream QA generation
2. **Judge Panel Ablation Study**: Systematically vary the number of LLM judges (1 vs. 2 vs. 3) and agreement thresholds (unanimous vs. majority) to quantify the precision-recall tradeoff and compute cost implications
3. **Semantic Diversity Analysis**: Beyond topic distribution, analyze the semantic similarity of questions generated from the same subgraph under different temperatures to validate true variability vs. superficial lexical changes