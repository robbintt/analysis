---
ver: rpa2
title: 'From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory
  of Mind in Multimodal Large Language Models'
arxiv_id: '2506.14224'
source_url: https://arxiv.org/abs/2506.14224
tags:
- belief
- agent
- room
- tasks
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes GridToM, a multimodal ToM dataset based on
  a 2D grid world, enabling comprehensive evaluation of multimodal large language
  models (MLLMs) on Theory of Mind (ToM) tasks. Unlike existing unimodal or video-based
  datasets, GridToM provides controllable perceptual information from multiple perspectives
  and includes both first-order and second-order belief tasks.
---

# From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models

## Quick Facts
- arXiv ID: 2506.14224
- Source URL: https://arxiv.org/abs/2506.14224
- Reference count: 30
- Proposes GridToM, a multimodal ToM dataset based on a 2D grid world for comprehensive evaluation of MLLMs

## Executive Summary
This paper addresses the challenge of evaluating and enhancing Theory of Mind (ToM) capabilities in multimodal large language models (MLLMs). The authors introduce GridToM, a novel multimodal ToM dataset built on a 2D grid world that provides controllable perceptual information from multiple perspectives. Unlike existing datasets that are either unimodal or based on real-world videos, GridToM enables systematic evaluation of both first-order and second-order belief tasks. The study conducts interpretability-driven analysis to understand how MLLMs process cognitive information across different perspectives and proposes a training-free intervention method that significantly improves ToM performance by adjusting attention activations.

## Method Summary
The researchers developed GridToM, a controlled 2D grid world environment where agents can have different perceptual viewpoints and belief states about objects and other agents. The dataset includes scenarios with varying levels of cognitive complexity, from simple first-order beliefs to more complex second-order beliefs. Through comprehensive experiments, the authors analyzed how attention mechanisms in MLLMs distinguish between cognitive information from different perspectives. Based on these insights, they proposed a training-free intervention method that modifies attention activations to enhance ToM reasoning capabilities. The approach focuses on improving the model's ability to separate and reason about different belief states without requiring additional training data or fine-tuning.

## Key Results
- GridToM enables comprehensive evaluation of MLLMs on both first-order and second-order belief tasks
- Attention heads in MLLMs can distinguish cognitive information across different perspectives
- Training-free intervention method significantly improves ToM performance through attention activation adjustments
- Enhanced ToM reasoning demonstrated in both first-order and second-order belief tasks

## Why This Works (Mechanism)
The approach works by leveraging the inherent attention mechanisms in MLLMs to separate and process cognitive information from different perspectives. The GridToM dataset provides controlled scenarios where perceptual information and belief states can be systematically varied, allowing the model to learn to distinguish between what different agents can perceive. The intervention method builds on this by adjusting attention activations to better align with the cognitive separation needed for ToM reasoning. This training-free approach is effective because it works with the existing attention mechanisms rather than requiring architectural modifications or additional training.

## Foundational Learning
- **Theory of Mind (ToM)**: The ability to attribute mental states to others and understand that others have beliefs, desires, and intentions different from one's own. Why needed: Essential for understanding social interactions and reasoning about others' behavior.
- **Multimodal Large Language Models (MLLMs)**: AI models that can process and integrate information from multiple modalities (text, images, etc.). Why needed: ToM often requires combining visual and textual information about social situations.
- **Attention Mechanisms**: Neural network components that weigh the importance of different inputs when processing information. Why needed: Critical for understanding how models process and separate different perspectives in ToM tasks.
- **First-order vs Second-order Beliefs**: First-order beliefs are about what someone believes, while second-order beliefs are about what someone believes about what another person believes. Why needed: Represents different levels of cognitive complexity in ToM reasoning.
- **Controlled Environment Design**: Creating systematic test scenarios with known variables. Why needed: Allows for precise measurement of model performance and isolation of specific cognitive capabilities.
- **Interpretability Analysis**: Methods for understanding how neural networks process information internally. Why needed: Essential for identifying how models separate and process cognitive information across perspectives.

## Architecture Onboarding

**Component Map**: GridToM Environment -> MLLM Input Processing -> Attention Mechanism Analysis -> Intervention Application -> ToM Performance Evaluation

**Critical Path**: The most critical path involves the attention mechanism analysis and intervention application. Understanding how attention heads separate cognitive information is fundamental to the proposed enhancement method.

**Design Tradeoffs**: The approach trades computational efficiency (training-free intervention) for potential limitations in handling more complex real-world scenarios. The controlled grid world provides precision but may not fully capture real-world complexity.

**Failure Signatures**: Models may fail to properly separate perspectives when belief states become too complex, or when perceptual information is ambiguous. The intervention method may show diminishing returns on models with fundamentally different attention architectures.

**First Experiments**:
1. Test attention head activations across different belief complexity levels in GridToM
2. Apply intervention method to a baseline MLLM and measure performance changes
3. Compare first-order and second-order belief task performance before and after intervention

## Open Questions the Paper Calls Out
None

## Limitations
- Grid-world scenarios may not fully generalize to real-world ToM reasoning complexity
- Intervention method effectiveness may vary across different MLLM architectures
- Limited evaluation of long-term temporal reasoning beyond immediate belief states
- Potential overfitting to the GridToM dataset structure

## Confidence
- **High**: GridToM dataset creation and evaluation framework
- **Medium**: Interpretability analysis of attention mechanisms for cognitive information separation
- **Medium-Low**: Effectiveness and generalizability of training-free intervention method

## Next Checks
1. Test the intervention method across multiple MLLM architectures beyond those initially evaluated to assess generalizability
2. Conduct ablation studies to isolate which components of the intervention method contribute most to performance gains
3. Evaluate the method's effectiveness on real-world multimodal datasets and scenarios beyond the controlled grid-world environment