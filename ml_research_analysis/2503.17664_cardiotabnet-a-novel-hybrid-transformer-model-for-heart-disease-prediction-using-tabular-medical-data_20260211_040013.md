---
ver: rpa2
title: 'CardioTabNet: A Novel Hybrid Transformer Model for Heart Disease Prediction
  using Tabular Medical Data'
arxiv_id: '2503.17664'
source_url: https://arxiv.org/abs/2503.17664
tags:
- data
- heart
- disease
- feature
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CardioTabNet, a novel hybrid transformer model, is introduced for
  heart disease prediction using tabular medical data. The model employs tab transformer
  to extract high-quality feature spaces from clinical cardiovascular data, leveraging
  the strengths of self-attention mechanisms for improved understanding of feature
  interactions.
---

# CardioTabNet: A Novel Hybrid Transformer Model for Heart Disease Prediction using Tabular Medical Data

## Quick Facts
- arXiv ID: 2503.17664
- Source URL: https://arxiv.org/abs/2503.17664
- Reference count: 0
- CardioTabNet achieves 94.1% average accuracy and 95.0% AUC on heart disease prediction

## Executive Summary
CardioTabNet introduces a hybrid transformer model that combines tab transformer feature extraction with classical machine learning classifiers for heart disease prediction. The model processes tabular medical data by first using a tab transformer to extract contextual embeddings from categorical features, then ranks these features using Random Forest importance, and finally trains classical ML models on the selected features. The approach demonstrates superior performance compared to previous studies, achieving 94.1% accuracy and 95.0% AUC on the IEEE Data Port Heart Disease dataset.

## Method Summary
The methodology involves preprocessing tabular medical data through z-score outlier filtering and StandardScaler normalization, followed by SMOTE oversampling to balance classes. A tab transformer extracts contextual embeddings from categorical features using self-attention mechanisms, which are then concatenated with normalized numerical features. Random Forest ranking selects the top 10 features from the transformer outputs, which are used to train ten classical ML models. Hyperparameter tuning via Optuna is applied to the ExtraTree classifier, which emerges as the top performer. The final model is evaluated using 5-fold cross-validation on the IEEE Data Port Heart Disease dataset.

## Key Results
- CardioTabNet achieves an average accuracy rate of 94.1% and AUC of 95.0% on the IEEE Data Port Heart Disease dataset
- The hyper-tuned ExtraTree classifier with n_estimators=176 and max_depth=19 outperforms nine other classical ML models
- Feature ranking via Random Forest identifies 10 most informative features from transformer-extracted embeddings for final classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Tab transformer's self-attention captures feature interactions that improve downstream classifier performance.
- Mechanism: Categorical features are embedded, processed through multi-head self-attention layers, and concatenated with numerical features to produce contextual embeddings.
- Core assumption: Complex feature interactions in cardiovascular data benefit from learned attention patterns rather than manual feature engineering.
- Evidence anchors: [abstract] "Tab transformer to extract feature space which carries strong understanding of clinical cardiovascular data" [section 3.8] "self-attention mechanism facilitates contextual embeddings by allowing each input embedding to attend to others"

### Mechanism 2
- Claim: Random Forest ranking selects the most informative features from transformer embeddings.
- Mechanism: After transformer extraction, RF feature importance scores rank features; top 10 are retained for classifier training.
- Core assumption: Feature importance from RF on learned embeddings aligns with true predictive signal for heart disease.
- Evidence anchors: [abstract] "Feature ranking is conducted using a Random Forest algorithm" [section 4.1] "a Random Forest Model was utilized to rank the extracted features... demonstrated superior performance... The selection process focused on identifying the top 10 features"

### Mechanism 3
- Claim: An ensemble of classical ML models, with hyper-tuned ExtraTree as the top performer, provides robust classification on transformer-derived features.
- Mechanism: Ten classical models are trained; ExtraTree is selected and further optimized via Optuna for final prediction.
- Core assumption: Classical models on high-quality embeddings outperform end-to-end transformer classifiers for this tabular dataset size.
- Evidence anchors: [abstract] "ten classical machine-learning models were trained on the selected features... top-performing model, a hyper-tuned ExtraTree classifier, achieves an average accuracy rate of 94.1%" [section 4.3.1] "optimal hyperparameters... 'n_estimators' set to 176, 'max_depth' set to 19... average accuracy of 94.089%"

## Foundational Learning

- Concept: Self-attention in transformers
  - Why needed here: Core to how tab transformer creates contextual embeddings from categorical features.
  - Quick check question: Given Q, K, V matrices, can you compute the attention output A·V where A = softmax(QK^T/√k)?

- Concept: Feature importance via Random Forest
  - Why needed here: Used to rank and select the top 10 features from transformer outputs.
  - Quick check question: How does RF compute feature importance (mean decrease in impurity vs. permutation importance), and which did the paper use?

- Concept: SMOTE for class imbalance
  - Why needed here: Balances the training data before model training (503→503 per class).
  - Quick check question: Explain how SMOTE generates synthetic samples; what is the risk of overfitting to synthetic data?

## Architecture Onboarding

- Component map: Data preprocessing -> Tab transformer extraction -> Random Forest ranking -> Classical ML training -> Optuna tuning -> 5-fold evaluation
- Critical path: Preprocessing → Tab transformer extraction → RF ranking → ExtraTree + Optuna tuning → 5-fold evaluation. The transformer and ranking steps are prerequisites for final classifier training.
- Design tradeoffs:
  - Hybrid vs. end-to-end: Uses transformer for representation only, not final classification—trains faster, easier to interpret, but may underutilize transformer capacity.
  - Top-10 feature selection: Reduces overfitting risk but may discard useful signal; threshold is heuristic, not tuned.
  - Dataset size: 1190 instances is modest; transformer may be under-constrained compared to classical models.
- Failure signatures:
  - Transformer overfitting: Training loss decreases but validation accuracy plateaus early (fold accuracy range 88.95–90.12% post-extraction suggests mild variance).
  - Ranking instability: Different random seeds yield different top-10 features (paper does not report stability analysis).
  - Tuning overfit: Optuna search on small dataset may overfit hyperparameters to specific folds.
- First 3 experiments:
  1. Reproduce tab transformer extraction on IEEE Data Port split; verify top-10 features match paper's Figure 4.
  2. Ablation: Train ExtraTree on raw features (no transformer) vs. transformer-extracted features; quantify gain from attention mechanism.
  3. Generalization test: Apply trained CardioTabNet pipeline to a different cardiovascular tabular dataset (e.g., Cleveland only) without retraining transformer; assess accuracy drop.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CardioTabNet's predictive performance scale when applied to large-scale, heterogeneous populations compared to the modest 1,190-instance dataset used in this study?
- Basis in paper: [explicit] The authors explicitly identify the "relatively modest size of the dataset" as a limitation, noting it may hinder the model's ability to "generalize to a broader and more heterogeneous population."
- Why unresolved: The current study validates the model only on a specific aggregated dataset, which does not meet the criteria for "large-scale" data necessary to confirm robust generalizability.
- What evidence would resolve it: Performance metrics (accuracy, AUC) derived from training and testing the model on expanded datasets comprising larger and more demographically diverse populations.

### Open Question 2
- Question: Can the model's generalization capabilities be further enhanced by training on a custom dataset specifically tailored for cardiovascular diseases rather than aggregating pre-existing open-source datasets?
- Basis in paper: [explicit] The authors state in the Future Work section that they plan to "collect a custom dataset tailored specifically for cardiovascular diseases," hypothesizing it will lead to "more comprehensive model training."
- Why unresolved: The current model is trained on a combination of five older datasets (Hungarian, Cleveland, etc.), which may lack specific features found in a purpose-built collection.
- What evidence would resolve it: A comparative study showing improved performance or robustness when the model is retrained on the proposed custom dataset versus the current IEEE Data Port dataset.

### Open Question 3
- Question: Is the proposed CardioTabNet framework robust and effective when deployed in real-world clinical scenarios for early-stage detection?
- Basis in paper: [explicit] The authors list a future objective to have "CardioTabNet... further validated in real-world scenarios for robustness and effectiveness."
- Why unresolved: The current results are derived from offline statistical analysis and cross-validation on retrospective data, not from prospective clinical application.
- What evidence would resolve it: Results from clinical trials or deployments where the tool is used by healthcare professionals for actual patient risk assessment.

### Open Question 4
- Question: Can the tab transformer component of CardioTabNet effectively minimize feature engineering requirements and handle ambiguity when applied to diverse biological data types beyond tabular cardiovascular records?
- Basis in paper: [explicit] The authors propose that "for future studies, tab transformer can be applied to different biological data" to minimize reliance on extensive feature engineering and handle ambiguity.
- Why unresolved: The study confines its methodology to tabular medical data for heart disease, leaving the transferability of the attention mechanism to other biological domains untested.
- What evidence would resolve it: Successful application and performance evaluation of the architecture on other biological data types, such as genomics or proteomics, with reduced manual feature engineering.

## Limitations
- The study relies on a single dataset without external validation, limiting generalizability claims.
- The top-10 feature selection threshold appears heuristic rather than optimized, potentially discarding useful information.
- No ablation studies are provided to isolate the contribution of each component in the hybrid architecture.

## Confidence
- Confidence in claimed mechanisms: Medium - neighbor studies use similar datasets but different architectures, and no ablation studies are provided
- Confidence in reported metrics: High - detailed methodology provided with specific hyperparameters and evaluation procedures
- Confidence in generalization: Low - single dataset validation and modest sample size (1,190 instances) limit broader applicability claims

## Next Checks
1. Perform ablation studies comparing ExtraTree performance on raw features vs. transformer-extracted features to quantify the attention mechanism's contribution.
2. Test model generalization on a separate cardiovascular dataset (e.g., Cleveland dataset) without retraining the transformer to assess domain transfer capability.
3. Conduct feature ranking stability analysis across multiple random seeds to verify that the top-10 features are consistently selected and contribute meaningfully to predictions.