---
ver: rpa2
title: Model Discovery with Grammatical Evolution. An Experiment with Prime Numbers
arxiv_id: '2505.12440'
source_url: https://arxiv.org/abs/2505.12440
tags:
- evolution
- function
- grammatical
- experiment
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents an experiment using Grammatical Evolution\
  \ (GE) to approximate the prime-counting function \u03C0(x), which lacks an exact\
  \ analytical formula due to the irregular distribution of prime numbers. The study\
  \ employs a Context-Free Grammar to evolve mathematical expressions that best approximate\
  \ \u03C0(x) using example data and mean squared error as the fitness function."
---

# Model Discovery with Grammatical Evolution. An Experiment with Prime Numbers

## Quick Facts
- arXiv ID: 2505.12440
- Source URL: https://arxiv.org/abs/2505.12440
- Reference count: 12
- This paper presents an experiment using Grammatical Evolution to approximate the prime-counting function π(x), which lacks an exact analytical formula due to the irregular distribution of prime numbers.

## Executive Summary
This study demonstrates Grammatical Evolution's capability to discover approximate analytical models for functions where exact formulas are unknown. Using a Context-Free Grammar to constrain the search space, the experiment evolves mathematical expressions that approximate the prime-counting function π(x) based on example data and mean squared error as the fitness function. The evolved functions visually resemble π(x) but show systematic discrepancies in precise values, achieving reasonable efficiency with 143.7 seconds of evolution time.

## Method Summary
The experiment employs Grammatical Evolution (GE) with PonyGE2 to evolve mathematical expressions approximating π(x). A C++ program generates 1000 prime numbers (2-7919) formatted as input-output pairs. The GE system uses a Context-Free Grammar defining arithmetic operations (+, -, *, /, sqrt), trigonometric functions (sin, tanh), exponential and logarithmic functions, and decimal constants. Evolution proceeds through genotype-to-phenotype mapping where binary strings translate to valid mathematical expressions via grammar production rules. The fitness function evaluates mean squared error between evolved expressions and actual π(x) values.

## Key Results
- Evolved expressions visually match π(x) shape but show systematic numerical errors (e.g., f(100)=26.0574 vs actual 25; f(1400)=222.801 vs actual 222)
- Evolution completed in 143.7 seconds using 1000 data points from primes 2-7919
- Multiple GE runs produced functions with nested operations demonstrating GE's ability to discover complex mathematical relationships
- Accuracy could be improved by expanding search space or increasing dataset size

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Context-Free Grammars constrain the search space to syntactically valid mathematical expressions, improving search efficiency.
- Mechanism: GE performs genotype-to-phenotype mapping where binary strings translate through grammar production rules. The CFG defines allowable operations and constants, ensuring all evolved expressions are executable.
- Core assumption: The target function can be approximated by compositions of the grammar-specified operations.
- Evidence anchors: [abstract] "Such models are transparent, concise, and have readable components and structure." [section 2] "GE is an evolutionary algorithm that utilizes additional knowledge, provided as a Context-Free Grammar (CFG), to perform genotype-phenotype mapping, allowing limiting the search space and simultaneously increasing the search efficiency."

### Mechanism 2
- Claim: Mean squared error as a fitness function drives evolutionary selection toward numerically accurate approximations.
- Mechanism: Each candidate expression is evaluated against the training dataset. Lower MSE indicates better fit. Selection pressure favors expressions with lower error, propagating effective substructures through crossover and mutation.
- Core assumption: The training data distribution is representative of the target function's behavior across the domain of interest.
- Evidence anchors: [section 2] "A series of experiments... aimed to construct models that seek to unveil the π(x) function, based on example data and mean squared error (MSE) as the fitness function." [section 3, Table 1] Quantitative results show evolved f2(100)=26.0574 vs. actual π(100)=25.

### Mechanism 3
- Claim: Derivation tree depth correlates with expression complexity, creating a tension between accuracy and interpretability.
- Mechanism: Longer evolution and larger grammars allow deeper derivation trees with more nested operations, potentially improving fit but reducing transparency. The paper notes this tradeoff explicitly.
- Core assumption: Interpretability value decreases faster than accuracy improves with increased complexity.
- Evidence anchors: [section 3] "A challenge arises in the complexity of the evolved formulas, characterized by numerous nested operations." [section 3] "The complexity issue can be addressed, for example, by imposing stricter constraints on the depth of the derivation tree. However, this approach may affect the accuracy of the results."

## Foundational Learning

- Concept: **Context-Free Grammars (CFGs)**
  - Why needed here: CFGs define the syntax of valid mathematical expressions. Understanding production rules is essential for modifying the grammar to include domain-specific operations.
  - Quick check question: Given the grammar rule `<e> ::= np.sin(<e>) | x`, what expressions can be generated in exactly 3 derivation steps?

- Concept: **Genetic Algorithm Fundamentals (selection, crossover, mutation)**
  - Why needed here: GE builds on standard GA machinery. Understanding how fitness-based selection and genetic operators work explains why multiple runs produce different solutions.
  - Quick check question: If two parent expressions are `x + sqrt(x)` and `sin(x) * 2`, describe one possible crossover offspring.

- Concept: **Symbolic Regression vs. Parametric Regression**
  - Why needed here: Unlike fitting coefficients in a fixed model, symbolic regression searches both structure and parameters. This distinction explains why GE can discover unexpected formula forms.
  - Quick check question: Why might symbolic regression outperform polynomial regression when the true relationship involves logarithmic terms?

## Architecture Onboarding

- Component map:
  - Dataset generator (C++ program) -> PonyGE2 engine (Python) -> Grammar definition file -> Parameters file -> Fitness evaluator -> Output module

- Critical path:
  1. Define CFG reflecting hypothesized mathematical operations relevant to the problem
  2. Prepare dataset in PonyGE2-compatible format (text file with input-output columns)
  3. Configure evolution parameters (population size, generations, selection method)
  4. Run evolution; monitor convergence via fitness progression
  5. Extract and validate best expression on held-out data

- Design tradeoffs:
  - Grammar breadth vs. convergence speed: More operations increase search space but may enable better approximations
  - Tree depth limit vs. accuracy: Deeper trees allow complex expressions but risk overfitting and illegibility
  - Dataset size vs. computational cost: Larger datasets improve generalization but increase evaluation time per generation
  - Generations vs. diminishing returns: Paper achieved results in 143.7 seconds; longer runs may yield marginal gains

- Failure signatures:
  - Constant or near-constant outputs: Grammar may lack operations that can express the target relationship
  - Extremely long expressions with poor fit: Grammar too permissive; consider pruning unused productions
  - Good training fit, poor test fit: Overfitting; reduce tree depth or increase dataset size
  - Syntax errors in evolved expressions: Bug in grammar definition; verify all productions are complete

- First 3 experiments:
  1. **Baseline replication**: Reproduce the paper's grammar and dataset; verify you obtain similar MSE and execution time (~140-160 seconds).
  2. **Grammar ablation**: Remove one operation class (e.g., all trigonometric functions) and measure impact on final MSE and convergence speed.
  3. **Dataset scaling**: Double the dataset to 2000 primes and observe whether approximation error decreases proportionally.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can expanding the search space or increasing dataset size systematically improve GE approximation accuracy for π(x)?
- Basis in paper: [explicit] Authors state "accuracy improvements could be achieved by expanding the search space or increasing the dataset size" and "supplying a larger dataset might help maintain the function shape across a broader range of values."
- Why unresolved: The experiment used only 1000 data points without systematic variation of search space parameters or dataset size.
- What evidence would resolve it: Controlled experiments varying dataset size (e.g., 1000 to 10000 points) and search space configuration, measuring resulting MSE changes.

### Open Question 2
- Question: Can grammatical evolution scale to discover models for multi-variable relationships?
- Basis in paper: [explicit] Section 4 states: "further research may focus on... examining relationships involving multiple independent variables and one or more dependent variables, with a constant focus on enhancing accuracy."
- Why unresolved: The current experiment addressed only single-variable function approximation.
- What evidence would resolve it: Successful application of GE to benchmark multi-variable regression problems with known analytical ground truth.

### Open Question 3
- Question: What is the quantitative trade-off between derivation tree depth constraints and approximation accuracy?
- Basis in paper: [inferred] Authors note complexity "can be addressed... by imposing stricter constraints on the depth of the derivation tree. However, this approach may affect the accuracy of the results" without quantifying this trade-off experimentally.
- Why unresolved: No experiments varying depth constraints were conducted to measure the accuracy penalty.
- What evidence would resolve it: Systematic experiments varying maximum tree depth while tracking both MSE and formula complexity metrics.

## Limitations
- Critical GE hyperparameters (population size, generations, mutation rates, tree depth) are unspecified, preventing exact reproduction
- Evolved expressions show systematic numerical discrepancies from actual π(x) values despite visual similarity
- No evaluation of generalization beyond training data range (primes ≤7919)

## Confidence
- High confidence: GE successfully evolves syntactically valid mathematical expressions; framework operates as described
- Medium confidence: Approximation quality improvements are achievable through dataset expansion or grammar modification; evolution process efficiency is reasonable
- Low confidence: Exact hyperparameter settings needed to replicate 143.7-second runtime and specific evolved expressions

## Next Checks
1. **Hyperparameter Sensitivity Analysis**: Systematically vary population size (100, 500, 1000), generations (100, 500, 1000), and tree depth (5, 10, 15) to identify settings that reproduce paper's runtime and accuracy characteristics.

2. **Grammar Expressiveness Test**: Add exponential and logarithmic operations systematically, measuring impact on MSE at key points (x=100, x=1400, x=1000). Document whether discrepancies decrease proportionally.

3. **Dataset Scaling Experiment**: Double training data to 2000 primes (extend range to ~15,000 or increase density) and measure changes in evolved expression complexity and approximation accuracy across the full domain.