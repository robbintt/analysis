---
ver: rpa2
title: 'ContinualFlow: Learning and Unlearning with Neural Flow Matching'
arxiv_id: '2506.18747'
source_url: https://arxiv.org/abs/2506.18747
tags:
- uni00000013
- uni00000011
- unlearning
- uni00000003
- uni00000018
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We introduce ContinualFlow, a principled framework for targeted
  unlearning in generative models via Flow Matching. Our method leverages an energy-based
  reweighting loss to softly subtract undesired regions of the data distribution without
  retraining from scratch or requiring direct access to the samples to be unlearned.
---

# ContinualFlow: Learning and Unlearning with Neural Flow Matching

## Quick Facts
- arXiv ID: 2506.18747
- Source URL: https://arxiv.org/abs/2506.18747
- Reference count: 25
- Primary result: A principled framework for targeted unlearning in generative models via Flow Matching using energy-based reweighting

## Executive Summary
ContinualFlow introduces a novel approach to targeted unlearning in generative models by leveraging Flow Matching with energy-based reweighting. The framework enables models to remove the influence of specific data without retraining from scratch or requiring direct access to the samples to be forgotten. By using energy functions as proxies, the method softly subtracts undesired regions of the data distribution while maintaining training efficiency. The approach is theoretically grounded with proofs showing gradient equivalence to explicit distribution transport and validated across 2D and image domains.

## Method Summary
ContinualFlow modifies the standard Conditional Flow Matching objective by introducing an energy-based reweighting loss. The method constructs a surrogate target distribution where forget set mass is reduced through sigmoid-weighted importance sampling. A pre-trained velocity field model is updated using samples from the current model distribution, with weights determined by an energy function that scores samples based on their likelihood of belonging to the forget set. The framework proves that this reweighting induces gradients equivalent to Flow Matching toward a soft mass-subtracted target, enabling effective unlearning without direct access to forget samples.

## Key Results
- Achieves unlearning performance comparable to retraining baselines while maintaining training efficiency
- Successfully removes targeted data distributions without access to forget set samples
- Demonstrates theoretical guarantees through gradient equivalence proofs to explicit distribution transport
- Validated on 2D synthetic datasets and real image datasets including MNIST and CIFAR-10

## Why This Works (Mechanism)

### Mechanism 1: Soft Mass Subtraction via Importance Reweighting
- Claim: Reweighting the CFM objective by a function inversely proportional to the probability of forget samples induces learning toward a target distribution with reduced forget set mass
- Mechanism: Constructs surrogate target distribution $\tilde{q}_1(x) \propto q_0(x) \cdot \sigma(-\lambda F(x))$ and weights CFM loss by $\sigma(-\lambda F(x_1))$
- Core assumption: Energy function $F(x)$ correlates strongly with log-density of forget data
- Evidence anchors: Abstract states leverages energy-based reweighting loss; Section 4.1 defines reweighted surrogate; Related work supports energy-based generative training
- Break condition: If energy function assigns low scores to retain samples, flow degrades fidelity for retained data

### Mechanism 2: Proxy-Guided Unlearning without Sample Access
- Claim: Classifier distinguishing forget data serves as proxy energy function enabling unlearning without explicit forget samples
- Mechanism: Interprets probabilistic binary classifier $C(x)$ via Bayes-optimality to estimate density ratio; uses logit score $F(x) = -\log[C(x)/(1-C(x))]$ as energy
- Core assumption: Proxy classifier generalizes sufficiently to generative model's latent space
- Evidence anchors: Section 3.2 discusses proxy functions; Appendix B.2 derives classifier-to-energy conversion; Related work validates energy constraints in flows
- Break condition: If proxy classifier is overfitted or misaligned, energy guidance steers flow incorrectly

### Mechanism 3: Gradient Equivalence to Explicit Distribution Transport
- Claim: ERFM loss provides gradients mathematically equivalent to standard CFM targeting mass-subtracted distribution
- Mechanism: Theorem 4.1 proves expectation of weighted loss aligns with gradient of CFM loss targeting $\tilde{q}_1$
- Core assumption: Base distribution $q_0$ has sufficient coverage to sample retained regions
- Evidence anchors: Abstract states induces gradients equivalent to Flow Matching; Appendix B.1 provides full derivation; Related work discusses potential flows and density homotopy
- Break condition: If suppression factor $\lambda$ is too large, sigmoid approximates step function causing high variance gradients

## Foundational Learning

- **Conditional Flow Matching (CFM)**: Baseline framework modified by ContinualFlow; understand velocity network $v_\theta$ and interpolation path $\psi_t(x_0, x_1)$ to grasp reweighting modifications
  - Quick check: Given $x_0$ and $x_1$, how is target conditional velocity $u_t(x|x_0, x_1)$ derived in standard CFM?

- **Energy-Based Models (EBMs)**: Framework relies on viewing unlearning as navigating energy landscape; understand $F(x)$ represents negative log-probability
  - Quick check: In Boltzmann distribution $p(x) \propto \exp(-F(x))$, does high energy $F(x)$ imply high or low probability density?

- **Importance Sampling**: Core theoretical contribution frames reweighting as importance sampling estimator; understand how weighting samples changes effective target distribution
  - Quick check: If you weight samples from distribution $p$ by function $w(x)$, what is effective distribution you're sampling from if weights are unnormalized probabilities?

## Architecture Onboarding

- **Component map**: Velocity Network ($v_\theta$) -> Energy Function ($F$) -> ODE Solver -> Pre-trained Generator ($G_{\theta_{old}}$)
- **Critical path**:
  1. Sample pairs $(x_0, x_1)$ from current model distribution ($q_0$)
  2. Calculate energy-based weights $w = \sigma(-\lambda F(x_1))$
  3. Construct interpolation $x_t$ and target velocity $x_1 - x_0$
  4. Compute weighted MSE loss between predicted velocity and target velocity
  5. Update velocity network
- **Design tradeoffs**:
  - Sensitivity ($\lambda$): High $\lambda$ aggressively suppresses forget set but risks catastrophic forgetting or flow collapse; low $\lambda$ preserves fidelity but may leak forget data
  - Proxy vs. Explicit Energy: Training classifier (proxy) is more flexible but introduces approximation error compared to hand-crafted energies
- **Failure signatures**:
  - Mode Collapse: Flow maps all noise vectors to single point (usually happens if $\lambda$ is too high)
  - Adversarial Leakage: Model generates semantically forget data but lies inside classifier decision boundary (low energy)
  - Trajectory Explosion: Velocity field becomes unbounded if reweighting creates disjointed gradient signals
- **First 3 experiments**:
  1. 2D Circles/Moons: Train flow on 2D dataset, define hand-crafted energy mask ($F(x) > 0$ for $r>1$), visualize if trajectories bend away from masked region
  2. MNIST Even/Odd: Train on all digits, train classifier to distinguish Even/Odd, use classifier logit as energy to unlearn Odd digits, check accuracy on Even digits
  3. Reversibility Test: After unlearning "Odd" digits, invert energy ($F \to -F$) and re-run unlearning loop, verify if model recovers Odd digits testing reversibility claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can energy functions be learned or constructed to faithfully align with unknown forget distributions without requiring explicit forget samples?
- Basis in paper: Future Work states "A key challenge is learning energy functions that faithfully align with the forget distribution, as this alignment affects unlearning performance"
- Why unresolved: Paper assumes access to proxy energy functions but doesn't address learning them when forget distribution is truly unknown
- What evidence would resolve it: Experiments showing methods for learning energy functions from indirect signals with quantitative evaluation of alignment quality

### Open Question 2
- Question: Can energy-based unlearning extend beyond class-level and binary proxies to semantic, geometric, or fine-grained concept formulations?
- Basis in paper: Future Work states "Beyond class-level or binary proxies, extending to semantic, or geometric formulations is a promising direction"
- Why unresolved: Current experiments only remove entire classes; framework untested on nuanced unlearning targets
- What evidence would resolve it: Demonstrations of semantic unlearning with appropriate energy function designs and retention/forgetting metrics

### Open Question 3
- Question: Does compositional combination of multiple energy functions maintain unlearning effectiveness without causing generalization erosion in continual or multi-stage unlearning scenarios?
- Basis in paper: Future Work states "compositionality of energy functions can support modular objectives, particularly in continual and multi-stage unlearning"
- Why unresolved: Paper demonstrates invertibility but doesn't evaluate sequential unlearning where multiple energy functions are applied iteratively
- What evidence would resolve it: Experiments with sequential unlearning requests using composed energy functions, measuring retention accuracy and MMD across multiple stages

## Limitations
- Empirical robustness untested when forget distribution is multi-modal or contains semantic ambiguity
- Method's behavior in high-dimensional latent spaces (VAEs, diffusion models) not demonstrated
- Framework's computational efficiency relative to retraining lacks quantitative comparison in terms of wall-clock time or GPU-hours

## Confidence
- **High**: Theoretical gradient equivalence (Theorem 4.1) and soft mass-subtraction mechanism via importance reweighting are mathematically sound
- **Medium**: Proxy-guided unlearning approach validated on synthetic 2D datasets and MNIST, but real-world image datasets show mixed results
- **Low**: Claim that framework "maintains training efficiency" lacks quantitative comparison to retraining benchmarks

## Next Checks
1. **Adversarial Leakage Test**: Train classifier to distinguish forget/retain samples from unlearned model's outputs, measure whether semantic forget data leaks via adversarial examples near classifier boundary
2. **Multi-Modal Forget Set**: Extend 2D experiments to unlearning multi-modal distribution (e.g., two disconnected moons), verify flow correctly subtracts both modes without collapsing retained data
3. **Proxy Generalization Stress Test**: Train energy proxy on subset of forget data, evaluate unlearning performance on held-out forget subset, quantify drop in forget rate as proxy training data decreases