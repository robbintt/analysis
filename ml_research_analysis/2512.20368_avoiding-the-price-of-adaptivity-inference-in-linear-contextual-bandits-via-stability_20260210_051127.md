---
ver: rpa2
title: 'Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via
  Stability'
arxiv_id: '2512.20368'
source_url: https://arxiv.org/abs/2512.20368
tags:
- lemma
- confidence
- page
- have
- theorem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of statistical inference in
  linear contextual bandits, where the adaptive, non-i.i.d. nature of data complicates
  the construction of valid confidence intervals.
---

# Avoiding the Price of Adaptivity: Inference in Linear Contextual Bandits via Stability

## Quick Facts
- arXiv ID: 2512.20368
- Source URL: https://arxiv.org/abs/2512.20368
- Reference count: 40
- This paper proposes a regularized EXP4 algorithm that achieves stable inference for linear contextual bandits without incurring the typical $\sqrt{d \log T}$ price of adaptivity.

## Executive Summary
This paper addresses the challenge of statistical inference in linear contextual bandits, where the adaptive, non-i.i.d. nature of data complicates the construction of valid confidence intervals. The authors propose a regularized variant of the EXP4 algorithm designed to enforce stability—a key structural property ensuring that the empirical feature covariance concentrates around a deterministic limit. Under this stability condition, the ordinary least-squares estimator satisfies a central limit theorem, enabling asymptotically valid Wald-type confidence intervals without incurring the typical $\sqrt{d \log T}$ inflation known as the price of adaptivity. The proposed algorithm achieves regret guarantees that are minimax optimal up to logarithmic factors, demonstrating that stability and statistical efficiency can coexist.

## Method Summary
The authors propose a regularized EXP4 algorithm that enforces stability through entropy regularization and exploration. The algorithm maintains weights over K base experts, updating them via mirror descent with an entropy-based mirror map and a penalty term R(w) = Σ_k w_k(log w_k + log(1/ε) - 1). The algorithm ensures weights stay in the ε-simplex (w_k ≥ ε > 0), forcing the average weight vector to converge to a deterministic fixed point. This convergence guarantees stability—the empirical feature covariance concentrates around a deterministic limit—which enables OLS estimators to satisfy a central limit theorem. The authors also introduce a ridge regression variant to handle finite-sample singularity of the design matrix.

## Key Results
- Regularized EXP4 achieves O(√(TK log(KT))) regret, matching the minimax rate up to logarithmic factors
- Under stability, OLS estimators satisfy a CLT with Kolmogorov distance bounded by Ψ(γ_T)^{1/3} where Ψ(γ_T) = O(1/√T)
- Wald-type confidence intervals achieve nominal coverage asymptotically without √d log T inflation
- Ridge regression variant preserves CLT with bias term vanishing at rate λ_rid/√T

## Why This Works (Mechanism)

### Mechanism 1: Stability Condition Restores Classical Inference
When the empirical feature covariance concentrates around a deterministic limit, OLS estimators satisfy a central limit theorem even under adaptive sampling. Stability requires Σ*_T^{-1} S_T → I where Σ*_T is non-random and S_T is the observed design matrix. This converts dependent adaptively-collected data into a structure amenable to martingale CLT analysis, yielding asymptotic normality without √d log T inflation.

### Mechanism 2: Entropy Regularization Enforces Weight Convergence
The entropy-based penalty forces average weight vectors to converge to a deterministic fixed point w*_T. The composite objective min_w{⟨g̅*, w⟩ + λR(w)} combined with the ε-simplex constraint creates strong convexity, driving E[∥w̅_T - w*_T∥_1] ≤ Ψ(γ_T) where Ψ decays as γ_T increases.

### Mechanism 3: Ridge Extension Handles Finite-Sample Singularity
Replacing OLS with ridge regression (λ_rid ≪ √T) preserves the CLT while handling ill-conditioned design matrices. The bias term J_1(T) from ridge scales as λ_rid/√T, while the variance term inherits the same Ψ(γ_T) convergence rate.

## Foundational Learning

- **Martingale Difference Sequences**: The noise terms ε_t form an MDS conditioned on F_{t-1}, enabling the quantitative martingale CLT that bounds Kolmogorov distance to standard normal. Quick check: If noise had serial correlation (E[ε_t | F_{t-1}] ≠ 0), would the CLT still hold for the ridge estimator?

- **Bregman Divergence and Mirror Descent**: The EXP4 weight updates use entropy-induced mirror maps. Understanding D_ϕ(x, y) is necessary to derive the weight convergence bound. Quick check: Why does the ε-simplex constraint ∆_ε (rather than ∆_K) ensure that importance-weighted gradients remain well-defined?

- **Price of Adaptivity in Bandits**: Provides the baseline comparison: without stability, confidence intervals require √d log T inflation. This motivates why stability is worth achieving. Quick check: The APS confidence interval width grows as √d log T. For d=100 and T=10^6, what is the approximate inflation factor over Wald?

## Architecture Onboarding

- **Component map**: Context x_t → [K Expert Policies π_k] → Mixture Q_t = Σ_k w_t,k π_k → Sample a_t ~ Q_t → Observe loss ℓ_t → Importance-weighted gradient: ĝ_t,k = ℓ_t · π_k(a_t|x_t) / Q_t(a_t|x_t) → Mirror descent update: w^{+}_{t+1} = w_t ⊙ exp(-ηĝ_t - λ[∇R(w_t) + c_R]) → Project to ∆_ε → w_{t+1}

- **Critical path**: Weight convergence (equation 33) → design matrix stability (equation 41) → CLT validity (Theorem 1). If weight convergence fails (λ too small), the entire inference pipeline breaks.

- **Design tradeoffs**: Higher λ (larger γ_T) gives faster weight convergence (smaller Ψ) but higher regret term γ_T log(KT)/√T. Smaller ε means less exploration uniformity, potentially better regret but higher variance in gradient estimates. Step size η must balance gradient variance vs. convergence speed.

- **Failure signatures**: Under-coverage at small T (if T < 500 or γ_T too small, Ψ(γ_T) dominates and Wald intervals under-cover). Exponential tail failure (if min eigenvalue of any Σ_k is near zero, d·exp(-(λ*_L)²/32) term becomes non-negligible). Ridge bias domination (if λ_rid grows with T faster than √T, the bias term dominates and coverage degrades).

- **First 3 experiments**: 1) Track E[∥w̅_T - w*_T∥_1] across T ∈ {500, 1000, 3000, 5000} with fixed γ_T = √log T. Verify decay matches Ψ(γ_T) prediction. 2) Measure Wald coverage at α=0.05 for T ∈ {500, 1000, 3000, 5000}. Confirm asymptotic validity (lim coverage = 0.95). 3) Fix T=3000, vary λ_rid ∈ {0, 1/T, 1/√T, √T/T}. Plot Kolmogorov distance to normal vs. λ_rid. Verify break point near λ_rid ≈ √T.

## Open Questions the Paper Calls Out

### Open Question 1
Can the stability condition and associated stability–regret tradeoffs be extended to settings where the feature dimension grows with the time horizon? The current theoretical analysis relies on a fixed feature dimension d, and the behavior may differ fundamentally in high-dimensional asymptotic regimes.

### Open Question 2
Is it possible to establish the Lai–Wei stability condition and valid inference when the context distribution is fully adaptive rather than i.i.d.? The current proofs rely on contexts being i.i.d. samples from a fixed distribution P_X.

### Open Question 3
Can similar stability guarantees and minimax optimal regret be achieved by regularizing other mirror-descent based adversarial bandit algorithms, such as Tsallis-INF or OFTRL? The stability properties of these algorithms are not well understood.

## Limitations

- The paper assumes i.i.d. contexts, which is unrealistic in many adaptive experimentation settings where contexts may depend on previous actions.
- The stability analysis relies on K fixed base experts; performance with learned or adaptive expert sets is unclear.
- While the ridge bias term vanishes asymptotically, finite-sample performance requires careful λ_rid tuning not fully characterized.

## Confidence

- High: Stability condition leads to CLT for OLS estimator (Theorem 3, Lemma 9)
- Medium: Ridge extension preserves CLT with vanishing bias (Corollary 1)
- Medium: CATE inference application is valid under stated assumptions
- Low: Empirical validation limited to small-scale simulations (K≤10, T≤5000)

## Next Checks

1. Test coverage properties under non-i.i.d. contexts (e.g., slowly drifting or adversarially chosen contexts)
2. Evaluate performance when base experts are themselves learned through meta-learning
3. Quantify the price of adaptivity for ridge estimator at finite T across different λ_rid choices