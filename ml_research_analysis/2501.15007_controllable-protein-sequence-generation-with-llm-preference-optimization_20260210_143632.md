---
ver: rpa2
title: Controllable Protein Sequence Generation with LLM Preference Optimization
arxiv_id: '2501.15007'
source_url: https://arxiv.org/abs/2501.15007
tags:
- protein
- generation
- optimization
- sequences
- preference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CtrlProt, a controllable protein design method
  using multi-listwise preference optimization. The key idea is to finetune a protein
  LLM with prefixes for specific attributes and then optimize using a preference framework
  that evaluates generated proteins on structural stability (via Rosetta energy) and
  functionality (via structural similarity to training proteins).
---

# Controllable Protein Sequence Generation with LLM Preference Optimization

## Quick Facts
- arXiv ID: 2501.15007
- Source URL: https://arxiv.org/abs/2501.15007
- Authors: Xiangyu Liu; Yi Liu; Silei Chen; Wei Hu
- Reference count: 12
- Key outcome: CtrlProt achieves state-of-the-art results on controllable protein generation, outperforming baselines like ESM-2, EvoDiff, and ProGen2 on metrics including CLS-score, TM-score, RMSD, and pLDDT for single and multi-attribute protein design tasks.

## Executive Summary
This paper introduces CtrlProt, a method for controllable protein sequence generation that combines prefix-tuning with multi-listwise preference optimization. The approach addresses the challenge of generating proteins that are both functionally relevant and structurally stable by using attribute-specific prefixes during supervised finetuning, then applying preference optimization that evaluates candidates on both Rosetta energy (stability) and structural similarity to training proteins (functionality). CtrlProt achieves significant improvements over baselines on six protein attributes, demonstrating the effectiveness of combining attribute conditioning with preference-based refinement.

## Method Summary
CtrlProt consists of two main stages: first, a protein LLM (ProtGPT2) is finetuned with attribute-specific prefixes via supervised learning to generate sequences associated with particular functional properties. Second, a preference optimization framework selects high-quality candidate sequences by combining stability scores (Rosetta energy) and functionality scores (structural similarity), then uses a multi-listwise ranking approach with cumulative distribution functions to focus updates on sequence pairs with larger quality differences. The method also extends to multi-attribute generation by concatenating attribute prefixes, avoiding the need for scarce multi-label training data.

## Key Results
- CtrlProt achieves state-of-the-art performance on controllable protein generation tasks, with CLS-scores reaching 79.5-83.8 across six attributes
- The method outperforms baselines (ESM-2, EvoDiff, ProGen2) on TM-score (up to 0.942 for metal ion binding) and pLDDT (up to 83.8)
- Multi-attribute generation shows improved performance over single-attribute baselines without mode collapse, maintaining diversity (inter-output similarity ~3.38%)
- Ablation studies demonstrate that both the CDF-based ranking and dual-metric evaluation contribute significantly to performance gains

## Why This Works (Mechanism)

### Mechanism 1: Prefix-Tuning for Attribute-Specific Generation
- **Claim:** Prefix-tuning conditions a frozen protein LLM to generate sequences associated with specific functional attributes without overfitting to limited training data.
- **Mechanism:** Learnable prefix tokens are prepended to input sequences during supervised finetuning. These soft prompts are optimized via negative log-likelihood while base model weights remain static, preserving pre-trained structural knowledge while steering generation toward attribute-relevant regions of sequence space.
- **Core assumption:** The pre-trained protein LLM has internalized sufficient structural semantics that prefix tokens can activate attribute-specific patterns without full weight updates.
- **Evidence anchors:**
  - [abstract] "We finetune a protein LLM with a new multi-listwise preference optimization strategy"
  - [Methods, Supervised Finetuning] "We use prefix-tuning for supervised finetuning on the attribute A... to avoid the overfitting caused by limited data"
  - [corpus] Related work "Controllable protein design through Feynman-Kac steering" uses alternative steering mechanisms, suggesting prefix conditioning is one viable path but not uniquely proven
- **Break condition:** If training data per attribute falls below a critical threshold, prefix-tuning alone may still generate functionally irrelevant or unstable proteins, necessitating preference optimization.

### Mechanism 2: Multi-Listwise Preference Optimization with Ranking-Based Regularization
- **Claim:** Incorporating ranking information via cumulative distribution functions (CDFs) focuses gradient updates on sequence pairs with larger quality differences, improving optimization efficiency.
- **Mechanism:** For each candidate sequence, quality scores ρ(yi) = G(yi, γi) + G(yi, τi) combine stability and functionality. The CDF F(γi) from a beta distribution fit provides rank information, weighted as G(yi, γi) = F(γi)(2γi − 1). The loss adds regularization term α(ρ(yw) − ρ(yl)), amplifying gradients for pairs with large quality gaps while dampening updates for near-equal pairs.
- **Core assumption:** Protein sequence quality is meaningfully rankable, and pairs with larger differences provide more informative training signal.
- **Evidence anchors:**
  - [abstract] "multi-listwise preference optimization strategy to improve generation quality"
  - [Methods, Multi-listwise DPO] "It is natural to incorporate ranking information into DPO, making the process more attentive to pairs with significant differences"
  - [Table 2] Ablation shows full CtrlProt outperforms standard DPO (CLS 79.5 vs 76.4) and Lipo-λ (79.5 vs 74.4), suggesting the CDF-based ranking provides advantage over alternative listwise methods
- **Break condition:** If candidate sequences cluster tightly in quality space (few large-difference pairs), the CDF-based weighting may not provide sufficient gradient contrast.

### Mechanism 3: Dual-Metric Quality Assessment (Stability + Functionality)
- **Claim:** Combining physics-based stability scoring with structure-encoded functionality similarity enables preference optimization to improve both properties simultaneously.
- **Mechanism:** Stability score γi normalizes per-residue Rosetta energy to [0,1]. Functionality score τi averages cosine similarity between the candidate's ProteinMPNN-encoded structure and training set structures. Preference pairs are selected only when both scores favor the same sequence, ensuring multi-objective improvement.
- **Core assumption:** Rosetta energy correlates with actual folding stability, and structural similarity to training proteins indicates functional relevance.
- **Evidence anchors:**
  - [abstract] "evaluates generated proteins on structural stability (via Rosetta energy) and functionality (via structural similarity to training proteins)"
  - [Table 2] Removing γ drops pLDDT from 73.9 to 70.2; removing τ drops TM-score from 77.7 to 66.2, indicating each metric contributes to its target property
  - [corpus] Related work "Improving Protein Sequence Design through Designability Preference Optimization" similarly uses designability metrics, suggesting this is an active exploration area without consensus on optimal metrics
- **Break condition:** If Rosetta energy or structural encoder representations fail to capture the target functional property (e.g., binding affinity depends on dynamics not captured in static structures), optimization may not transfer to real-world functionality.

## Foundational Learning

- **Concept: Direct Preference Optimization (DPO)**
  - **Why needed here:** CtrlProt builds on DPO, eliminating the need for a separate reward model while aligning generation with quality preferences.
  - **Quick check question:** Can you explain why DPO's rearrangement of the KL-constrained reward objective allows direct policy optimization without RL?

- **Concept: Rosetta Energy Function**
  - **Why needed here:** The stability metric depends on understanding how conformational energy relates to foldability and why lower scores indicate more stable structures.
  - **Quick check question:** What physical interactions does the Rosetta ref2015 weight configuration include, and why is per-residue normalization necessary for comparing proteins of different lengths?

- **Concept: Prefix-Tuning / Soft Prompting**
  - **Why needed here:** The method uses prefix-tuning rather than full finetuning; understanding parameter-efficient adaptation is essential for implementation.
  - **Quick check question:** How do prefix tokens differ from discrete prompt engineering, and why might they be more effective for low-data regimes?

## Architecture Onboarding

- **Component map:** UniProtKB/AlphaFold -> attribute-specific sequence sets -> Prefix-Tuning Stage (ProtGPT2 + learnable prefix) -> Candidate Generation -> Quality Evaluation (Rosetta + ProteinMPNN) -> Preference Dataset Construction -> Multi-Listwise DPO
- **Critical path:** Prefix-tuning -> candidate generation (expensive: requires structure prediction) -> Rosetta scoring (expensive: physics simulation) -> preference optimization. The pipeline is sequential; bottlenecks are structure prediction and Rosetta computation.
- **Design tradeoffs:**
  - **Candidate pool size:** More candidates improve preference pair quality but increase compute (Rosetta is O(n) expensive)
  - **α regularization weight:** Paper uses 0.05; too high may over-emphasize large-gap pairs, too low reduces ranking benefit
  - **Single vs. multi-attribute training:** Multi-attribute requires only prefix concatenation + re-optimization, avoiding scarce multi-label data, but may not capture attribute interactions
- **Failure signatures:**
  - **Mode collapse:** Inter-output similarity spikes (Table 3 shows CtrlProt at 3.38% vs PrefixProt 3.12%—slight increase but acceptable)
  - **Training set overfitting:** Training set similarity exceeds natural protein baseline (2.53%); CtrlProt achieves 2.55%, indicating minimal overfitting
  - **Preference optimization divergence:** Loss increases or generated sequences become degenerate; check α and β hyperparameters
- **First 3 experiments:**
  1. **Reproduce single-attribute prefix-tuning baseline:** Finetune ProtGPT2 with 100-token prefix on metal ion binding data (10k sequences), generate 500 candidates, compute TM-score and pLDDT to verify baseline matches reported ~67.9 TM-score, 70.8 pLDDT
  2. **Validate preference dataset construction pipeline:** Generate 1000 candidates, compute γi and τi, verify pair selection yields ~5000 valid preference pairs as reported; inspect score distributions for expected beta-like shape
  3. **Ablate ranking regularization:** Compare full CtrlProt (α=0.05) against α=0 (standard DPO) on one attribute; expect ~3-4 point CLS-score gap as in Table 2

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the precision of controllable generation be improved for complex or conflicting attribute combinations where current prefix-concatenation methods struggle?
- **Basis in paper:** [explicit] The Conclusion states, "achieving more precise and programmable generation for certain attribute combinations remains a challenge. We hope to continue exploring this in future work."
- **Why unresolved:** The current approach relies on simple prefix concatenation and preference optimization, which may not fully model the intricate biological interactions or trade-offs required when combining specific attributes.
- **What evidence would resolve it:** A demonstration of high-accuracy generation on attribute pairs that currently yield low CLS-scores or conflicting structural properties.

### Open Question 2
- **Question:** To what extent do the high in silico scores (Rosetta energy, structural similarity) correlate with actual biological stability and functionality in vitro?
- **Basis in paper:** [inferred] The method optimizes proxies for stability (Rosetta energy) and functionality (ProteinMPNN similarity), but provides no wet-lab validation.
- **Why unresolved:** Computational metrics are imperfect approximations of complex biological realities; a protein that scores well on Rosetta or TM-score may still misfold or lack function in a biological environment.
- **What evidence would resolve it:** Experimental results showing that generated proteins express correctly and perform the intended function (e.g., binding assays) at rates comparable to natural proteins.

### Open Question 3
- **Question:** Does defining functionality based on structural similarity to the training set restrict the model's ability to discover novel protein folds?
- **Basis in paper:** [inferred] The functionality metric $\tau$ is calculated using the cosine similarity between the generated protein's structural representation and those in the training set.
- **Why unresolved:** Explicitly optimizing for similarity to existing training structures creates a bias toward known folds, potentially penalizing structurally novel sequences that could perform the same function.
- **What evidence would resolve it:** Identification of generated proteins with low structural similarity (low TM-score) to the training set that still exhibit high functional activity in experimental assays.

## Limitations

- **Scalability constraints:** The pipeline requires expensive structure prediction and Rosetta energy calculations for each candidate sequence, creating computational bottlenecks that could limit practical deployment.
- **Metric reliability assumptions:** The method relies on Rosetta energy and structural similarity as proxies for stability and functionality, which may not perfectly capture real-world protein behavior or account for dynamic interactions.
- **Data scarcity sensitivity:** Performance on attributes with fewer than 10,000 training sequences isn't reported, and the approach may not generalize well to rare functional properties without additional regularization.

## Confidence

**High confidence:** The architectural design combining prefix-tuning with multi-listwise preference optimization is internally consistent and the ablation studies provide strong evidence that both components contribute meaningfully to performance gains.

**Medium confidence:** The claim that CDF-based ranking improves optimization efficiency over standard DPO is supported by CLS-score differences but could benefit from more extensive hyperparameter sensitivity analysis.

**Low confidence:** The generalization to truly novel protein functions not represented in training data remains untested, as the paper demonstrates state-of-the-art results on predefined attributes but doesn't address discovery of entirely new functional sequences.

## Next Checks

1. **Ablation of ranking regularization:** Systematically vary α from 0 to 0.2 in increments of 0.05 and measure CLS-score, TM-score, and pLDDT for metal ion binding and RNA binding to quantify sensitivity to the ranking component.

2. **Computational resource profiling:** Measure time and resource requirements for each pipeline stage on a representative attribute, reporting total cost per generated protein and identifying the actual bottleneck in the workflow.

3. **Out-of-distribution functional testing:** Apply the multi-attribute prefix approach to a novel protein function (e.g., DNA-binding proteins not in the training set) and measure whether generated sequences show improved structural stability and any detectable functional similarity to known DNA-binding proteins.