---
ver: rpa2
title: 'Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage
  Framework for Long Chain-of-Thought Synthesis and Selection'
arxiv_id: '2512.18956'
source_url: https://arxiv.org/abs/2512.18956
tags:
- reasoning
- think
- multimodal
- answer
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving multimodal large
  reasoning models (MLRMs) by proposing a three-stage synthesis-selection framework
  called SynSelect for generating high-quality long Chain-of-Thought (CoT) data. The
  method leverages multiple heterogeneous MLRMs to produce diverse reasoning paths,
  applies instance-level and batch-level selection strategies to filter optimal CoTs,
  and refines the dataset for effective supervised fine-tuning.
---

# Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection

## Quick Facts
- **arXiv ID:** 2512.18956
- **Source URL:** https://arxiv.org/abs/2512.18956
- **Reference count:** 40
- **Primary result:** SynSelect framework improves multimodal reasoning performance by up to 2% on complex tasks

## Executive Summary
This paper addresses the critical challenge of generating high-quality long Chain-of-Thought (CoT) data for training multimodal large reasoning models (MLRMs). The authors propose SynSelect, a three-stage framework that synthesizes diverse reasoning paths using multiple heterogeneous MLRMs and applies instance-level and batch-level selection strategies to filter optimal CoTs. The approach demonstrates significant performance gains on multimodal benchmarks and shows promise for self-improvement through iterative refinement.

## Method Summary
The SynSelect framework operates through three distinct stages to generate and refine multimodal reasoning data. First, it employs multiple heterogeneous MLRMs to synthesize diverse Chain-of-Thought reasoning paths for given multimodal tasks. Second, it applies instance-level selection to filter individual CoTs based on quality metrics, followed by batch-level selection to optimize the overall dataset composition. Finally, the refined dataset is used for supervised fine-tuning of target MLRMs, with optional reinforcement learning post-training to further enhance performance.

## Key Results
- Models trained on SynSelect-generated data achieve up to 2% performance improvement on complex multimodal reasoning tasks
- Framework demonstrates strong scalability and computational efficiency
- Self-improvement capability through iterative bootstrap refinement shows promising results

## Why This Works (Mechanism)
The effectiveness of SynSelect stems from leveraging diversity in the synthesis stage to capture multiple reasoning approaches, followed by rigorous selection to ensure only high-quality CoTs are retained. By using heterogeneous MLRMs for initial generation, the framework captures a broader range of reasoning patterns than single-model approaches. The two-tier selection process ensures both individual CoT quality and overall dataset coherence, addressing the challenge of filtering useful reasoning traces from potentially noisy multimodal inputs.

## Foundational Learning
- **Multimodal Reasoning Models (MLRMs)**: AI models that process and reason across multiple input modalities (vision, text, audio)
  - *Why needed:* Modern reasoning tasks often require integrating information from diverse sources
  - *Quick check:* Can the model process and correlate visual and textual information simultaneously?

- **Chain-of-Thought (CoT) Reasoning**: Intermediate reasoning steps that break down complex problems into manageable components
  - *Why needed:* Long CoTs provide transparency and enable better error diagnosis in multimodal reasoning
  - *Quick check:* Does the reasoning path logically connect inputs to final outputs through verifiable steps?

- **Heterogeneous Model Ensembles**: Using multiple models with different architectures or training histories
  - *Why needed:* Captures diverse reasoning patterns that single models might miss
  - *Quick check:* Do different models produce substantially different but valid reasoning paths for the same task?

## Architecture Onboarding

**Component Map:**
Multiple MLRMs -> Synthesis Stage -> Instance Selection -> Batch Selection -> Refined Dataset -> Supervised Fine-Tuning -> Target MLRM

**Critical Path:**
The most critical sequence is: Synthesis (diverse CoT generation) → Instance Selection (quality filtering) → Batch Selection (dataset optimization) → Supervised Fine-Tuning (model training)

**Design Tradeoffs:**
- Diversity vs. Quality: More heterogeneous models increase reasoning diversity but may introduce noise
- Selection Granularity: Instance-level selection ensures individual quality but may miss dataset-level patterns
- Computational Cost: Multiple synthesis passes increase upfront cost but reduce downstream training requirements

**Failure Signatures:**
- Overfitting to source model biases if synthesis stage lacks sufficient diversity
- Quality degradation if selection thresholds are too permissive
- Performance plateau if bootstrap refinement amplifies existing errors

**First 3 Experiments:**
1. Ablation study comparing single-model vs. multi-model synthesis performance
2. Sensitivity analysis of selection threshold parameters on final model accuracy
3. Cross-domain transfer evaluation to test generalization beyond benchmark tasks

## Open Questions the Paper Calls Out
The paper acknowledges several open questions regarding the long-term stability of iterative bootstrap refinement and the framework's effectiveness on real-world multimodal tasks beyond standardized benchmarks.

## Limitations
- Potential amplification of hallucinations or systematic errors through iterative refinement
- Limited analysis of quality degradation when scaling to vastly larger or more diverse datasets
- Reliance on source model capabilities may introduce inherent biases

## Confidence

**High Confidence:**
- Core three-stage methodology is clearly described and experimentally validated
- 2% performance improvement on complex reasoning tasks is reproducible and well-supported

**Medium Confidence:**
- Claims about self-improvement through iterative refinement require further validation
- Scalability assertions need more extensive testing beyond computational efficiency

**Low Confidence:**
- N/A

## Next Checks
1. Conduct ablation studies to quantify individual contributions of synthesis and selection stages
2. Test framework robustness on multimodal tasks outside standard benchmarks
3. Evaluate long-term stability and potential error amplification after multiple bootstrap iterations