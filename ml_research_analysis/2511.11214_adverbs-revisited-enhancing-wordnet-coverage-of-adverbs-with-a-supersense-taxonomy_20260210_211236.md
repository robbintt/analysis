---
ver: rpa2
title: 'Adverbs Revisited: Enhancing WordNet Coverage of Adverbs with a Supersense
  Taxonomy'
arxiv_id: '2511.11214'
source_url: https://arxiv.org/abs/2511.11214
tags:
- adverbs
- wordnet
- semantic
- adverb
- sense
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the underrepresentation of adverbs in WordNet
  by proposing a linguistically grounded supersense taxonomy. The authors developed
  a semi-automatic annotation pipeline that combines contextualized embeddings and
  large language models with expert validation to classify and expand adverb coverage.
---

# Adverbs Revisited: Enhancing WordNet Coverage of Adverbs with a Supersense Taxonomy

## Quick Facts
- **arXiv ID**: 2511.11214
- **Source URL**: https://arxiv.org/abs/2511.11214
- **Reference count**: 30
- **Primary result**: Introduces a linguistically grounded supersense taxonomy that expands WordNet's adverb coverage by 418 new synsets through semi-automatic annotation

## Executive Summary
This paper addresses the significant underrepresentation of adverbs in WordNet by proposing a supersense taxonomy that provides structural clarity to what has traditionally been a "wastebasket" category. The authors developed a semi-automatic pipeline combining contextualized embeddings, large language models, and expert validation to classify and expand adverb coverage. A pilot study demonstrated substantial inter-annotator agreement (Cohen's kappa = 0.67), validating the taxonomy's practical applicability. The method successfully uncovers adverb senses that were previously collapsed or missing, improving WordNet's semantic granularity for downstream NLP applications.

## Method Summary
The approach extracts adverb usages from large corpora (OpenSubtitles, Fineweb-edu) and generates contextual embeddings using XL-Lexeme. Pairwise cosine distances between these embeddings are calculated, followed by agglomerative clustering with a threshold of 0.4 to identify distinct sense clusters. Low-entropy sentences are selected as prototypical examples using XLM-RoBERTa, and LLM-generated definitions are synthesized. Human annotators then validate and refine the output, integrating the results into the Open English WordNet (OEWN) format. The system focuses on unambiguous adverb forms (excluding words like "fast" that can be both adjectives and adverbs) to ensure high precision in the automatic stage.

## Key Results
- Identified 418 new adverb synsets not previously in WordNet
- Achieved substantial inter-annotator agreement (kappa = 0.67) for the taxonomy
- Organized adverbs across eight semantic categories: manner, degree, spatial, temporal, domain, speaker-oriented, frequency, focus, conjunctive, and subject-oriented
- Successfully separates polysemous usages (e.g., "stupidly" as manner vs. subject-oriented) into distinct groups

## Why This Works (Mechanism)

### Mechanism 1: Contextualized Embeddings for Sense Discovery
Unsupervised clustering of contextualized embeddings effectively isolates distinct adverb senses that are collapsed in standard lexical databases. The pipeline extracts adverb usages and feeds them into XL-Lexeme to generate contextual embeddings, then applies agglomerative clustering (threshold=0.4) to separate polysemous usages into distinct groups, allowing discovery of senses absent from WordNet. The geometric distance in embedding space correlates with lexicographically valid sense boundaries, though the single threshold may not generalize across all adverb categories.

### Mechanism 2: Linguistically Grounded Supersense Taxonomy
A linguistically grounded supersense taxonomy resolves the "wastebasket" problem of the `adv.all` category by replacing WordNet's flat structure with a 10-category hierarchy. This explicitly encodes the scope of modification, allowing downstream models to distinguish between adverbs modifying events (manner) versus those modifying propositions (speaker-oriented). The proposed supersenses are designed to be mutually exclusive and exhaustive, though edge cases exist where adverbs fit multiple categories simultaneously.

### Mechanism 3: Low-Entropy Sentence Selection
Low-entropy sentence selection acts as a proxy for prototypicality, ensuring generated definitions and examples are cleaner than raw corpus data. The system masks target adverbs and uses XLM-RoBERTa to estimate entropy, selecting sentences with lower uncertainty as "prototypical" examples. This filters out idiosyncratic contexts before human validation, though the correlation between model confidence and human judgments of lexical prototypicality requires external validation.

## Foundational Learning

- **Concept: Supersense Taxonomy**
  - **Why needed here**: Standard WordNet lacks hierarchy for adverbs; understanding supersenses (broad semantic domains) is required to grasp how this paper imposes structure on the "wastebasket" class
  - **Quick check question**: Can you explain why "briefly" might belong to a different supersense than "unfortunately"?

- **Concept: Inter-Annotator Agreement (Cohen's Kappa)**
  - **Why needed here**: The paper claims validity based on Kappa = 0.67; you must know that 0.67 indicates "substantial agreement" but is not perfect, implying the taxonomy has edge cases
  - **Quick check question**: Does a Kappa of 0.67 imply the taxonomy is objectively correct, or merely that humans can apply it consistently?

- **Concept: Contextualized Embeddings & Clustering**
  - **Why needed here**: The core expansion mechanism relies on XL-Lexeme embeddings and agglomerative clustering; "sense" here is defined by vector proximity, not just dictionary entries
  - **Quick check question**: If two usages of "hard" (e.g., "working hard" vs. "hard border") have high cosine similarity, would the pipeline correctly identify them as distinct senses?

## Architecture Onboarding

- **Component map**: Input (OpenSubtitles/Fineweb-edu corpora) -> Filter (regex/dictionary for -ly adverbs) -> Encoder (XL-Lexeme contextual embeddings) -> Clusterer (Agglomerative Clustering, threshold 0.4) -> Ranker (XLM-RoBERTa entropy-based selection) -> Synthesizer (LLM definition generation) -> Validator (Human annotators)

- **Critical path**: The clustering threshold is the most sensitive parameter; set too low, and you miss polysemy (false negative senses); set too high, and you split single senses into redundant fragments (false positives), increasing manual cleanup load

- **Design tradeoffs**:
  - Precision vs. Recall: Excludes ambiguous forms (e.g., "fast") to ensure high precision in automatic stage, sacrificing lexical coverage of high-frequency items
  - Automation vs. Lexicographic Quality: Relies on LLMs for bootstrapping definitions to save time, accepting risk of "hallucinated" or inconsistent glosses requiring manual reversal

- **Failure signatures**:
  - Over-clustering: Synsets appearing with near-identical definitions or overlapping lemmas
  - Definition Drift: LLM-generated glosses describing sentence context rather than word's inherent meaning
  - Category Collapse: High volume of errors in subject-oriented vs speaker-oriented distinction, relying on subtle syntactic cues

- **First 3 experiments**:
  1. Threshold Sensitivity Analysis: Re-run clustering on 100 adverbs with thresholds from 0.3 to 0.6 to quantify trade-off between sense fragmentation and sense conflation
  2. Edge-Case Annotation: Sample instances classified as ARGM-ADV in PropBank and measure how new taxonomy distributes them
  3. Definition Validity Check: Blind comparison of LLM-generated vs expert-written glosses for 418 new synsets to identify systematic semantic distortions

## Open Questions the Paper Calls Out
None

## Limitations
- Clustering threshold of 0.4 may not optimally balance sense granularity across all adverb categories, requiring context-specific thresholds
- LLM-generated definitions were manually corrected but extent of semantic drift or hallucination in automated stage remains unquantified
- Distinction between speaker-oriented and subject-oriented adverbs relies on subtle syntactic cues that may not generalize across all contexts

## Confidence

- **High Confidence**: Method successfully identifies 418 new adverb synsets absent from WordNet, validated through human annotation with substantial inter-annotator agreement (kappa = 0.67)
- **Medium Confidence**: Supersense taxonomy effectively reduces "wastebasket" problem of `adv.all`, though edge cases exist where adverbs fit multiple categories simultaneously
- **Medium Confidence**: Low-entropy sentence selection improves prototype quality, but correlation between model confidence and human-annotated prototypicality requires external validation

## Next Checks

1. **Threshold Sensitivity Analysis**: Re-run clustering on 100 sample adverbs with thresholds from 0.3 to 0.6 to quantify trade-off between false positive sense fragmentation and false negative sense conflation
2. **Definition Quality Audit**: Conduct blind comparison of LLM-generated versus expert-written definitions for the 418 new synsets to identify systematic semantic distortions in automated generation process
3. **Cross-Linguistic Transfer**: Test the supersense taxonomy on a parallel corpus of adverbs in another language (e.g., Italian) to assess whether the 10-category hierarchy captures universal semantic distinctions or is English-specific