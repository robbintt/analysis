---
ver: rpa2
title: 'Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic
  Retinopathy'
arxiv_id: '2509.13234'
source_url: https://arxiv.org/abs/2509.13234
tags:
- medgemma
- gpt-4o
- idrid
- retinopathy
- assistance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study evaluated multimodal large language models (MLLMs)
  for diabetic retinopathy detection and as simulators of clinical AI assistance.
  Two models were tested on IDRiD and Messidor-2 datasets: GPT-4o and MedGemma.'
---

# Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy

## Quick Facts
- **arXiv ID**: 2509.13234
- **Source URL**: https://arxiv.org/abs/2509.13234
- **Reference count**: 23
- **Primary result**: MedGemma outperformed GPT-4o in diabetic retinopathy detection, with higher AUROC (0.95 vs 0.75-0.78) and sensitivity (0.92-0.95 vs 0.40-0.50), while both models adjusted predictions based on simulated AI inputs.

## Executive Summary
This study evaluates multimodal large language models (MLLMs) for diabetic retinopathy detection and as simulators of clinical AI assistance. Two models were tested on IDRiD and Messidor-2 datasets: GPT-4o and MedGemma. MedGemma demonstrated superior baseline performance with higher sensitivity and AUROC, while GPT-4o showed near-perfect specificity but lower sensitivity. Both models adjusted predictions based on simulated AI inputs, with MedGemma showing greater stability when faced with incorrect guidance. The study also demonstrated AI-to-AI collaboration, where GPT-4o achieved strong results when guided by MedGemma's descriptive outputs, even without direct image access. These findings suggest MLLMs could improve DR screening pipelines and serve as scalable simulators for studying clinical AI assistance across varying output configurations.

## Method Summary
The study employed a comprehensive evaluation framework using two multimodal LLMs (GPT-4o and MedGemma) on established diabetic retinopathy datasets (IDRiD and Messidor-2). The models were tested across multiple configurations: baseline image analysis, simulated AI assistance (where models received varying quality AI outputs), and AI-to-AI collaboration (where GPT-4o analyzed images while receiving descriptive outputs from MedGemma). Performance was measured using standard metrics including AUROC, sensitivity, specificity, and F1-score. The study also simulated scenarios where AI assistance provided correct, partially correct, or incorrect outputs to assess model robustness. Due to API limitations, GPT-4o could not process images in the AI-to-AI collaboration setup, requiring it to rely solely on textual descriptions from MedGemma.

## Key Results
- MedGemma achieved higher baseline performance than GPT-4o with AUROC of 0.95 vs 0.75-0.78 and sensitivity of 0.92-0.95 vs 0.40-0.50
- Both models adjusted predictions based on simulated AI assistance, but GPT-4o's performance collapsed with incorrect inputs while MedGemma remained more stable
- In AI-to-AI collaboration, GPT-4o achieved strong results (AUROC up to 0.96) when guided by MedGemma's descriptive outputs, despite not having direct image access

## Why This Works (Mechanism)
The study demonstrates that MLLMs can effectively interpret both visual and textual medical information, allowing them to function as both diagnostic tools and simulators of clinical AI assistance. MedGemma's superior performance likely stems from its specialized medical training and more stable inference patterns when presented with varying quality inputs. The AI-to-AI collaboration framework works because descriptive outputs from one model can effectively guide another model's analysis, suggesting that information compression and explanation generation are key mechanisms for successful clinical AI assistance. The models' ability to adjust predictions based on AI input quality indicates they can calibrate their confidence and decision-making based on external guidance, mimicking how human clinicians might incorporate AI recommendations.

## Foundational Learning
- **Multimodal LLMs for medical imaging**: These models combine visual perception with language understanding to analyze medical images and generate clinical interpretations. Why needed: Traditional AI models lack the ability to explain their reasoning or interact with other AI systems. Quick check: Can the model correctly identify and describe medical findings in images while maintaining diagnostic accuracy?
- **Simulated clinical AI assistance**: Models are tested with varying quality AI outputs to evaluate their robustness and adaptability. Why needed: Real-world clinical settings involve imperfect AI guidance that clinicians must interpret. Quick check: Does model performance degrade gracefully with incorrect AI input, or does it catastrophically fail?
- **AI-to-AI collaboration frameworks**: One model provides descriptive outputs while another performs analysis, testing information transfer efficiency. Why needed: This mimics real clinical workflows where multiple AI systems must work together. Quick check: Can the receiving model maintain diagnostic accuracy using only textual descriptions from the first model?
- **Model calibration and confidence**: The ability of models to adjust their certainty based on external input quality. Why needed: Clinical decisions require appropriate confidence levels, especially when incorporating AI recommendations. Quick check: Does the model's confidence score appropriately reflect the quality of the AI input it received?
- **Explainable AI outputs in medical contexts**: The importance of generating descriptive, interpretable outputs for clinical decision support. Why needed: Clinicians need to understand AI reasoning to trust and effectively use recommendations. Quick check: Are the generated descriptions clinically accurate and actionable for human reviewers?

## Architecture Onboarding

**Component Map**: Image -> MLLM1 (Analysis) -> Descriptive Output -> MLLM2 (Final Assessment) -> Clinical Recommendation

**Critical Path**: The primary workflow involves image input → multimodal analysis → confidence scoring → output generation. For AI-to-AI collaboration, the path becomes image → MLLM1 → descriptive text → MLLM2 → final output, demonstrating that effective information compression can substitute for direct image access.

**Design Tradeoffs**: The study balanced model complexity (GPT-4o's broader capabilities vs MedGemma's specialized training) against performance stability. Using descriptive outputs instead of direct image access reduces computational requirements but may lose fine-grained visual details. The choice to simulate AI assistance rather than use real clinical workflows enables controlled testing but may not capture all real-world complexities.

**Failure Signatures**: GPT-4o shows catastrophic performance degradation when given incorrect AI inputs, suggesting it may over-rely on external guidance. Both models demonstrate sensitivity to dataset size and composition, with small test sets potentially inflating performance metrics. The API limitation preventing GPT-4o from processing images in collaboration mode reveals infrastructure dependencies that could affect deployment.

**Three First Experiments**:
1. Test both models on a larger, more diverse DR dataset (minimum 500 images per severity grade) to validate performance scalability and generalizability
2. Implement a human-in-the-loop evaluation where ophthalmologists interact with MLLM outputs in simulated screening workflows to measure trust and decision-making impact
3. Conduct ablation studies on the descriptive output quality, varying levels of detail to determine the optimal balance between information density and interpretability

## Open Questions the Paper Calls Out
None

## Limitations
- Small sample sizes in test datasets (Messidor-2 contains only 120 images) may limit generalizability
- Simulated AI assistance scenarios may overestimate real-world performance compared to actual clinical workflows
- GPT-4o's inability to process images in AI-to-AI collaboration setup due to API limitations means results may not reflect true multimodal capabilities

## Confidence

**High confidence**: The comparative performance metrics between MedGemma and GPT-4o on IDRiD and Messidor-2 datasets are reliable given the standardized evaluation approach. The observation that MedGemma outperforms GPT-4o in sensitivity while maintaining strong specificity is well-supported by the data.

**Medium confidence**: The claim that MLLMs can effectively simulate clinical AI assistance is plausible but requires real-world validation. The AI-to-AI collaboration results showing GPT-4o's improved performance when guided by MedGemma's descriptive outputs are promising but may not generalize to actual clinical scenarios where human clinicians are involved.

**Low confidence**: The assertion that open, lightweight models like MedGemma will be especially valuable in low-resource settings lacks evidence about deployment feasibility, computational requirements, or integration with existing screening infrastructure. The potential for descriptive outputs to enhance clinician trust is speculative without user studies or real-world implementation data.

## Next Checks

1. Replicate the study using larger, more diverse DR datasets with at least 500 images per severity grade to confirm performance metrics and stability across different population distributions

2. Conduct a prospective clinical validation where human ophthalmologists interact with MLLM outputs in simulated screening workflows, measuring diagnostic accuracy, trust calibration, and workflow efficiency compared to standard care

3. Test the AI-to-AI collaboration framework with both models having actual image access (resolving GPT-4o's API limitation) and evaluate performance when models provide varying levels of explanatory detail to determine optimal output configurations for clinical utility