---
ver: rpa2
title: Medical Vision Language Models as Policies for Robotic Surgery
arxiv_id: '2510.06064'
source_url: https://arxiv.org/abs/2510.06064
tags:
- medflamingo
- robotic
- surgical
- visual
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Vision-based Proximal Policy Optimization (PPO) struggles with
  visual observation-based robotic laparoscopic surgical tasks due to the high-dimensional
  nature of visual input, the sparsity of rewards in surgical environments, and the
  difficulty of extracting task-relevant features from raw visual data. We introduce
  a simple approach integrating MedFlamingo, a medical domain-specific Vision-Language
  Model, with PPO.
---

# Medical Vision Language Models as Policies for Robotic Surgery

## Quick Facts
- arXiv ID: 2510.06064
- Source URL: https://arxiv.org/abs/2510.06064
- Reference count: 26
- Primary result: MedFlamingo PPO achieves 70%+ success rates in laparoscopic surgical tasks

## Executive Summary
Vision-based reinforcement learning struggles with robotic surgical tasks due to high-dimensional visual inputs, sparse rewards, and difficulty extracting task-relevant features from raw endoscopic images. This work introduces a simple yet effective approach that integrates MedFlamingo, a medical domain-specific Vision-Language Model, with Proximal Policy Optimization (PPO). The method processes task observations and instructions once per episode to generate high-level planning tokens, combining medical expertise with real-time visual feedback. Evaluated across five diverse laparoscopic surgery tasks in the LapGym simulator, MedFlamingo PPO outperforms both standard vision-based PPO and OpenFlamingo PPO baselines, achieving task success rates exceeding 70% with improvements ranging from 66.67% to 1114.29% over baselines.

## Method Summary
The proposed method addresses the challenges of vision-based PPO in surgical environments by integrating a medical vision-language model into the policy learning framework. MedFlamingo, a domain-specific model, processes the initial task observation and instruction once per episode to generate high-level planning tokens that guide the policy throughout execution. This approach leverages the model's medical expertise to create structured, semantically meaningful representations that are more suitable for surgical decision-making than raw visual inputs. The planning tokens are then used in conjunction with real-time visual feedback from the endoscope during policy execution. The system is evaluated on five diverse laparoscopic surgery tasks in the LapGym simulator, comparing performance against standard vision-based PPO and OpenFlamingo PPO baselines.

## Key Results
- MedFlamingo PPO achieves task success rates exceeding 70% across all five laparoscopic surgery environments
- The method converges faster than both standard vision-based PPO and OpenFlamingo PPO baselines
- Performance improvements range from 66.67% to 1114.29% compared to baseline methods

## Why This Works (Mechanism)
The integration of medical vision-language models addresses the fundamental challenge of extracting semantically meaningful information from high-dimensional visual inputs in surgical contexts. By processing task observations and instructions once per episode to generate high-level planning tokens, the method effectively bridges the gap between raw visual data and task-relevant surgical knowledge. This episodic planning approach allows the policy to leverage specialized medical expertise while maintaining the flexibility to respond to real-time visual feedback during execution.

## Foundational Learning
- **Proximal Policy Optimization (PPO)**: Why needed - provides stable policy gradient updates for continuous control tasks; Quick check - monotonic improvement in policy performance during training
- **Vision-Language Models (VLMs)**: Why needed - extract semantic meaning from visual observations; Quick check - successful generation of relevant planning tokens from task descriptions
- **Reinforcement Learning in Surgery**: Why needed - enables autonomous decision-making in complex, high-stakes environments; Quick check - consistent task completion across diverse surgical scenarios
- **Episodic Planning**: Why needed - balances computational efficiency with task-relevant guidance; Quick check - sustained performance improvements across multiple episodes
- **Medical Domain Knowledge Integration**: Why needed - provides task-specific expertise for surgical decision-making; Quick check - improved success rates compared to general-purpose models

## Architecture Onboarding

**Component Map:** Task Observation & Instruction -> MedFlamingo VLM -> Planning Tokens -> PPO Policy -> Action Output -> Environment -> Visual Feedback -> PPO Policy (continuous loop)

**Critical Path:** Initial observation and instruction processing through MedFlamingo to generate planning tokens, which are then combined with real-time visual feedback by the PPO policy to produce actions

**Design Tradeoffs:** Episodic planning tokens vs. continuous replanning - balances computational efficiency with adaptability to changing surgical conditions

**Failure Signatures:** Poor token generation from MedFlamingo leading to irrelevant guidance; PPO policy unable to effectively integrate planning tokens with visual feedback; Sim-to-real transfer failures for physical surgical robots

**First Experiments:**
1. Test token generation quality with varied medical task descriptions and observations
2. Evaluate PPO policy performance with synthetic planning tokens vs. MedFlamingo-generated tokens
3. Measure impact of planning token frequency (episode-based vs. continuous) on task success rates

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to five tasks within a single simulated environment (LapGym)
- No validation on physical surgical robots or in clinically diverse settings
- Episodic planning approach may not generalize to dynamic surgical scenarios requiring real-time replanning

## Confidence
- **High Confidence**: MedFlamingo PPO achieves higher success rates than baseline PPO methods across tested environments
- **Medium Confidence**: The episodic planning token approach effectively combines medical expertise with visual feedback
- **Low Confidence**: The method's performance would generalize to real surgical settings or more complex multi-step procedures

## Next Checks
1. Test the approach on a physical surgical robot platform with real endoscopic camera input to assess sim-to-real transfer
2. Evaluate performance across a broader range of surgical task complexities and longer horizon scenarios requiring adaptive replanning
3. Conduct ablation studies comparing different vision-language model architectures and planning frequencies to isolate contribution of key components