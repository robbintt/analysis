---
ver: rpa2
title: Multimodal Federated Learning With Missing Modalities through Feature Imputation
  Network
arxiv_id: '2505.20232'
source_url: https://arxiv.org/abs/2505.20232
tags:
- multimodal
- data
- feature
- imputation
- missing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses missing modalities in multimodal federated
  learning for healthcare, where some clients only have one type of data (e.g., only
  X-ray images, no text reports). Existing methods either use zero/uniform filling
  or generative models to impute missing data, but these can be biased or computationally
  expensive.
---

# Multimodal Federated Learning With Missing Modalities through Feature Imputation Network

## Quick Facts
- arXiv ID: 2505.20232
- Source URL: https://arxiv.org/abs/2505.20232
- Reference count: 27
- Key outcome: Lightweight feature imputation network outperforms zero-filling, uniform-filling, and generative model baselines in multimodal federated learning with missing modalities

## Executive Summary
This paper addresses the challenge of missing modalities in multimodal federated learning, particularly in healthcare settings where different clients may have access to different types of data (e.g., some with only X-ray images, others with both images and text reports). The authors propose a Feature Imputation Network (FIN) that reconstructs low-dimensional feature representations of missing modalities conditioned on available ones, rather than generating high-dimensional raw data. This approach is computationally efficient and avoids the biases associated with naive imputation methods.

The proposed method demonstrates consistent improvements over existing baselines across multiple datasets including MIMIC-CXR, NIH Open-I, and CheXpert, achieving up to 86.16% AUC compared to 79.8% for zero-filling and 77.32% for a generative model baseline. The approach is particularly effective in heterogeneous client settings and offers significant computational advantages, with approximately 10x less communication cost and 1000x less computation per inference compared to generative models.

## Method Summary
The paper proposes a Feature Imputation Network (FIN) that learns to reconstruct missing modality features by conditioning on available modalities. Instead of generating raw high-dimensional data as done by generative models, FIN operates in the feature space, reconstructing low-dimensional feature vectors (typically a few hundred dimensions) from one modality based on the other. This makes the approach more efficient and less error-prone than high-dimensional generative models. The method is designed to work in both homogeneous and heterogeneous federated learning settings where some clients may have only one type of modality while others have multiple.

## Key Results
- Achieved 86.16% AUC in homogeneous setup with 8 image-only and 2 multimodal clients, outperforming zero-filling (79.8%) and R2Gen (77.32%)
- Demonstrated approximately 10x less communication cost and 1000x less computation per inference compared to generative models
- Consistent improvements across multiple datasets including MIMIC-CXR, NIH Open-I, and CheXpert in both homogeneous and heterogeneous client settings

## Why This Works (Mechanism)
The approach works by learning to reconstruct missing modality features in a low-dimensional space rather than generating high-dimensional raw data. By focusing on feature-level imputation rather than data-level generation, the method avoids the computational complexity and potential errors associated with generating high-dimensional medical images or text reports. The conditioning on available modalities allows the network to learn meaningful correlations between different data types, enabling accurate reconstruction of missing features. This feature-level approach is more efficient because it operates on compressed representations that capture the essential information needed for downstream tasks.

## Foundational Learning
- **Federated Learning**: Distributed machine learning where clients train models locally without sharing raw data; needed to enable privacy-preserving learning across healthcare institutions with different data types
- **Multimodal Learning**: Joint processing of multiple data types (e.g., images and text); needed to leverage complementary information from different modalities for improved performance
- **Feature Imputation**: Reconstructing missing feature representations rather than raw data; needed to avoid the computational burden and potential errors of generating high-dimensional data
- **Conditional Reconstruction**: Learning to generate features based on available modalities; needed to capture the relationships between different data types
- **Low-dimensional Representations**: Working in compressed feature space rather than raw data space; needed to improve computational efficiency and reduce error propagation

## Architecture Onboarding

**Component Map**: Input Modality A -> Feature Extractor A -> FIN -> Reconstructed Features B -> Downstream Task; Input Modality B -> Feature Extractor B -> Downstream Task

**Critical Path**: The critical path involves extracting features from available modalities, passing them through the FIN to reconstruct missing modality features, and then combining all features for the downstream task. The FIN acts as a bridge between modalities, learning the conditional distribution of one modality's features given the other.

**Design Tradeoffs**: The main tradeoff is between reconstruction accuracy and computational efficiency. Operating in feature space rather than raw data space significantly reduces computational cost but may lose some fine-grained information. The method trades off the ability to generate realistic raw data (as generative models do) for more efficient and potentially more reliable feature reconstruction.

**Failure Signatures**: The method may fail when the relationship between modalities is weak or when there is significant domain shift between clients. Poor performance could indicate that the FIN is not learning meaningful correlations between modalities, or that the feature representations are not sufficiently informative for reconstruction. In heterogeneous settings with many different combinations of available modalities, the method may struggle to learn effective reconstruction patterns.

**First Experiments**:
1. Test FIN performance with varying numbers of attention heads and layer depths to identify optimal architecture
2. Evaluate reconstruction quality using metrics like feature similarity (e.g., cosine similarity) between reconstructed and actual features
3. Compare computational costs across different imputation methods on the same hardware to validate efficiency claims

## Open Questions the Paper Calls Out
None

## Limitations
- Lack of detailed architectural specifications for the Feature Imputation Network makes it difficult to assess generalizability
- Heterogeneous client settings only consider cases with some single-modality and some multi-modality clients, not varying numbers of modalities per client
- Computational efficiency claims rely on comparisons with only one generative baseline without exploring the full spectrum of imputation methods

## Confidence
- **High confidence**: The core problem statement and motivation are well-articulated, and experimental results showing improvements over baselines are credible
- **Medium confidence**: The proposed method's superiority over generative models is demonstrated, but specific architectural choices and their impact on performance remain unclear
- **Medium confidence**: Computational efficiency claims are supported by comparison with R2Gen, but analysis could be more comprehensive

## Next Checks
1. Conduct ablation studies to determine sensitivity of FIN architecture to hyperparameters such as latent dimension size, number of attention heads, and layer depth
2. Extend experiments to heterogeneous settings with varying numbers of modalities per client to assess robustness across more diverse scenarios
3. Compare against additional imputation baselines beyond R2Gen, including simple statistical methods and other feature-level imputation approaches, to establish relative performance of proposed method