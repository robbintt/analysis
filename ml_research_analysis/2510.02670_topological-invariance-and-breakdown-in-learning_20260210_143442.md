---
ver: rpa2
title: Topological Invariance and Breakdown in Learning
arxiv_id: '2510.02670'
source_url: https://arxiv.org/abs/2510.02670
tags:
- learning
- topological
- topology
- neural
- neurons
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes that permutation-equivariant learning rules,\
  \ including SGD, Adam, and others, induce a bi-Lipschitz mapping between neurons\
  \ during training, which constrains the topology of the neuron distribution. A key\
  \ finding is the identification of a topological critical point \u03B7 = 1/K in\
  \ the learning rate, where K is the smoothness parameter of the loss landscape."
---

# Topological Invariance and Breakdown in Learning

## Quick Facts
- arXiv ID: 2510.02670
- Source URL: https://arxiv.org/abs/2510.02670
- Authors: Yongyi Yang; Tomaso Poggio; Isaac Chuang; Liu Ziyin
- Reference count: 33
- This paper establishes that permutation-equivariant learning rules induce a bi-Lipschitz mapping between neurons during training, creating a topological critical point in the learning rate that determines whether topology is preserved or simplified.

## Executive Summary
This paper introduces a topological framework for understanding how neural networks learn by proving that permutation-equivariant learning rules (like SGD and Adam) constrain the topology of the neuron distribution. The key insight is that learning dynamics can be classified into two regimes based on a critical learning rate threshold $\eta^* = 1/K$, where $K$ is the smoothness parameter of the loss landscape. Below this threshold, the learning process preserves all topological structures through homeomorphisms, while above it, topological simplification occurs, reducing model expressivity. This creates a two-phase learning dynamic with profound implications for understanding optimization in deep learning.

## Method Summary
The authors establish that permutation-equivariant learning rules induce a bi-Lipschitz mapping between neuron states during training. They prove that when the learning rate satisfies $\eta K < 1$, this mapping is a homeomorphism that preserves topological invariants like Betti numbers. The critical threshold $\eta^* = 1/K$ marks a phase transition where the mapping becomes a quotient map, allowing topological simplification through neuron merging. The theory is validated empirically by tracking Betti numbers during training with different learning rates, showing that small learning rates maintain topology while large learning rates allow topological changes.

## Key Results
- Learning rules satisfying permutation equivariance and $K$-continuity induce bi-Lipschitz mappings between neurons when $\eta K < 1$
- A critical learning rate $\eta^* = 1/K$ marks a phase transition between topology-preserving and topology-simplifying learning regimes
- Small learning rates maintain topological invariants (Betti numbers) while large learning rates allow topological changes during training
- The theory applies universally across architectures and loss functions that satisfy the stated properties

## Why This Works (Mechanism)

### Mechanism 1: Bi-Lipschitz Topological Preservation
- Claim: If the learning rate $\eta$ is below a critical threshold ($\eta < 1/K$), the training dynamics preserve the topological structure of the neuron manifold.
- Mechanism: Permutation-equivariant rules enforce that neurons with identical parameters receive identical updates. Combined with the $K$-continuity of the loss landscape, this induces a bi-Lipschitz mapping between neuron states at time $t$ and $t+1$. This mapping acts as a homeomorphism, preventing distinct neurons from merging or splitting, thereby preserving topological invariants.
- Core assumption: The update rule satisfies equivariance (P1) and $K$-continuity (P2-K), and the learning rate satisfies $\eta K < 1$.
- Break condition: The mechanism fails if the loss landscape is not sufficiently smooth ($K$ is undefined/infinite) or if the update rule violates permutation equivariance.

### Mechanism 2: Critical Phase Transition (Topological Critical Point)
- Claim: The learning rate threshold $\eta^* = 1/K$ marks a phase transition where learning shifts from preserving topology to allowing simplification.
- Mechanism: At $\eta^* = 1/K$, the lower bound constraining neuron distances becomes vacuous. The mapping $\hat{U}$ ceases to be a bijection and becomes a continuous surjection, allowing the "gluing" or merging of distinct neuron regions, effectively simplifying the neuron manifold's topology.
- Core assumption: $K$ represents the smoothness parameter (approximated by the largest eigenvalue of the Hessian $\lambda_{max}$).
- Break condition: The theoretical $\eta^*$ relies on a global or local $K$ estimate; if $K$ fluctuates wildly during training, the precise transition point becomes dynamic rather than static.

### Mechanism 3: Topological Simplification as Capacity Reduction
- Claim: Learning with large step sizes ($\eta > \eta^*$) reduces model expressivity by simplifying the neuron manifold topology.
- Mechanism: When the update mapping allows neuron merging (surjective behavior), the effective parameter count decreases as distinct parameter vectors collapse. This moves the system towards symmetric states, which acts as an implicit regularization or simplification process.
- Core assumption: Neurons are defined as parameter subsets permutable by the learning rule; merging them reduces functional expressivity.
- Break condition: If the loss landscape requires complex topological structures to represent the target function, large learning rates might over-simplify the model, preventing convergence to the optimal solution.

## Foundational Learning

- Concept: **Permutation Equivariance**
  - Why needed here: It is the fundamental symmetry property required to prove that learning rules induce well-defined maps on neuron sets.
  - Quick check question: Does the loss function or architecture remain invariant if I swap the indices and weights of two neurons in a layer?

- Concept: **Bi-Lipschitz Mappings**
  - Why needed here: This mathematical property describes how the update rule controls distances between neurons, bridging optimization dynamics and topological preservation.
  - Quick check question: Does the distance between two points in the space change by a bounded factor after a transformation?

- Concept: **Topological Invariants (Betti Numbers)**
  - Why needed here: These are the observable quantities used to empirically validate whether topology was preserved or simplified during training.
  - Quick check question: If I deform a shape without tearing or gluing, do the number of holes in it change? (Answer: No).

## Architecture Onboarding

- Component map: Neurons (w,a) -> Update Rule U (SGD/Adam) -> Smoothness K (Hessian max eigenvalue) -> Critical Point η* = 1/K

- Critical path: Estimate landscape smoothness K → Set learning rate η relative to 1/K → Determine if topology is preserved (η < 1/K) or simplified (η > 1/K)

- Design tradeoffs:
  - Small η (< 1/K): Ensures stable, topology-preserving optimization. Tradeoff: May fail to merge redundant neurons or simplify the model, potentially requiring more capacity than necessary.
  - Large η (> 1/K): Allows topological simplification and neuron merging. Tradeoff: Reduces effective expressivity; risks "coarsening" the manifold too aggressively (over-regularization).
  - Architecture Independence: Theory applies to any permutable layer (FC, Conv, Attention) but relies on smoothness assumptions.

- Failure signatures:
  - Unexpected Merging (Small η): If neurons merge unexpectedly, check if the local curvature K has spiked, effectively lowering η* below your fixed η.
  - Loss of Expressivity (Large η): If performance caps prematurely, the large η may be forcing the model into a simplified topological configuration that cannot represent the task.
  - Edge of Stability: Training hovering at the boundary where ηK ≈ 1 indicates the system is oscillating between preserving and breaking topology.

- First 3 experiments:
  1. Visual Validation (2D): Initialize neurons on a manifold with known topology. Train with small vs. large η and visualize if the "holes" are preserved or filled.
  2. Quantitative Tracking: Train a standard MLP on MNIST. Calculate and plot Betti numbers over time for both small and large learning rates to observe the predicted invariance vs. simplification.
  3. Critical Point Verification: Estimate the Hessian max eigenvalue K during training. Adjust η dynamically to keep η < 1/K (preserving mode) vs η > 1/K (simplifying mode) and measure the resulting impact on effective parameter count and accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the learning dynamics in the topological breakdown regime (η > η*) be theoretically described?
- Basis in paper: The authors state that "it remains an open problem of how to describe the learning processes in the topological breakdown regime."
- Why unresolved: Conventional theories like NTK and mean-field approximations rely on topological invariance, which fails when the learning rate exceeds the critical point η*.
- What evidence would resolve it: A formal dynamical framework that models learning when the neuron manifold undergoes simplification rather than homeomorphism.

### Open Question 2
- Question: Can this framework lead to a generalized mean-field theory for deep learning?
- Basis in paper: The paper notes this "could lead to the most general type of mean-field theory for deep learning, which we leave as a future direction."
- Why unresolved: While the paper establishes that smooth learning induces diffeomorphisms suitable for mean-field analysis, the actual derivation of such a general theory is not provided.
- What evidence would resolve it: The derivation of Vlasov-type equations for the infinite-width limit that explicitly incorporate the proven topological constraints.

### Open Question 3
- Question: Do the predicted topological phase transitions occur in large-scale, state-of-the-art neural networks?
- Basis in paper: The authors explicitly list as a limitation that the work "does not test the predictions on large-scale experiments."
- Why unresolved: Empirical validation was restricted to low-dimensional visualization and simple tasks (MNIST), leaving the theory's applicability to billions-parameter models unverified.
- What evidence would resolve it: Tracking topological invariants during the training of large architectures (e.g., Transformers) to observe the critical point η*.

## Limitations
- The theory depends critically on the smoothness parameter K being well-defined and stable throughout training, which may not hold in practice due to varying landscape curvature.
- The framework requires permutation-equivariant update rules, excluding certain modern architectures and optimization variants that don't satisfy this symmetry property.
- Computing topological invariants like Betti numbers for high-dimensional neuron spaces is computationally challenging and may introduce measurement error.

## Confidence
- High Confidence: The bi-Lipschitz mapping mechanism and its connection to homeomorphism preservation.
- Medium Confidence: The existence and precise location of the critical phase transition, given the global K assumption and dynamic landscape effects.
- Low-Medium Confidence: The claim that topological simplification directly reduces model expressivity, requiring more empirical validation.

## Next Checks
1. **Dynamic Critical Point Tracking**: Monitor the Hessian maximum eigenvalue λ_max during training and compare the theoretical η* = 1/K with observed topological changes to reveal if the critical point is static or dynamic.

2. **Architecture-Specific Testing**: Validate the theory on architectures with varying degrees of permutation equivariance (fully connected vs. convolutional vs. attention layers) to quantify the scope of applicability.

3. **Expressivity Impact Measurement**: Systematically vary η relative to 1/K and measure not just topological changes but also downstream task performance and effective parameter utilization to directly test the claim about expressivity reduction.