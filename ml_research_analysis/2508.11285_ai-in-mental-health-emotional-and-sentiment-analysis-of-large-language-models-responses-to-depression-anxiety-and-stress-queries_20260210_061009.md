---
ver: rpa2
title: 'AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models''
  Responses to Depression, Anxiety, and Stress Queries'
arxiv_id: '2508.11285'
source_url: https://arxiv.org/abs/2508.11285
tags:
- health
- mental
- emotional
- sentiment
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study analyzed emotional and sentiment patterns in responses
  from eight large language models (LLMs) to mental health queries about depression,
  anxiety, and stress. A total of 2,880 responses were collected and scored using
  advanced NLP tools for sentiment and emotions.
---

# AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries

## Quick Facts
- **arXiv ID:** 2508.11285
- **Source URL:** https://arxiv.org/abs/2508.11285
- **Reference count:** 40
- **Primary result:** LLM emotional profiles vary widely, with model selection crucial for mental health applications.

## Executive Summary
This study systematically analyzed emotional and sentiment patterns in responses from eight large language models to mental health queries about depression, anxiety, and stress. Using advanced NLP tools, researchers quantified 2,880 responses across sentiment categories and 21 distinct emotions, revealing significant variation in emotional profiles between models. The analysis found optimism, fear, and sadness as dominant emotional expressions, with model choice having substantial impact on the emotional tone of responses. The research highlights the critical importance of carefully selecting appropriate LLMs for mental health applications to ensure supportive and clinically appropriate user interactions.

## Method Summary
The research employed a comprehensive experimental design involving 20 mental health questions across three conditions (depression, anxiety, stress) and six demographic framings, generating 360 unique prompt variations. These prompts were submitted to eight different LLMs (Claude Sonnet, Copilot, Gemini Pro, GPT-4o, GPT-4o mini, Llama 3.1-405B, Mixtral 8x7b, Perplexity) via API interfaces using default parameters. The resulting 2,880 responses underwent sentiment analysis using Twitter-roBERTa-base and emotion classification through two distinct models trained on emotion datasets. Statistical analysis, including Mann-Whitney U tests, compared emotional scores between models and conditions to identify significant patterns and variations in LLM emotional responses.

## Key Results
- Optimism, fear, and sadness were the dominant emotional expressions across all model responses
- Llama model showed highest optimism and joy scores, while Mixtral expressed most negative emotions like disapproval and annoyance
- Anxiety prompts triggered highest fear scores (0.974), depression prompted highest sadness (0.686) and negative sentiment, while stress queries elicited highest optimism (0.755)
- Model choice significantly influenced emotional tone more than demographic framing, which showed only marginal effects

## Why This Works (Mechanism)
The study's methodology leverages established NLP sentiment analysis and emotion detection tools to systematically quantify LLM responses. By using multiple models (Twitter-roBERTa for sentiment and emotion-specific classifiers), the research captures both broad sentiment categories and nuanced emotional expressions. The factorial design with 360 prompt variations ensures comprehensive coverage of mental health scenarios and demographic contexts. The statistical approach using Mann-Whitney U tests allows for robust comparison of emotional profiles across different models and conditions, identifying significant patterns that would not be apparent through casual observation.

## Foundational Learning
- **Sentiment Analysis:** Understanding how automated tools classify text as positive, neutral, or negative; needed to quantify emotional tone in LLM responses; quick check: verify model accuracy on benchmark datasets.
- **Emotion Detection:** Knowledge of models that identify specific emotions like optimism, fear, sadness from text; needed to capture nuanced emotional expressions beyond basic sentiment; quick check: compare emotion scores across multiple models.
- **Factorial Experimental Design:** Creating systematic combinations of variables (questions, conditions, demographics); needed to comprehensively test LLM responses across diverse scenarios; quick check: validate prompt matrix completeness.
- **API-based LLM Evaluation:** Using cloud APIs to query multiple models consistently; needed to generate comparable response sets across different LLM architectures; quick check: confirm API parameter consistency.
- **Statistical Comparison Methods:** Applying Mann-Whitney U tests for non-parametric comparisons; needed to identify significant differences in emotional profiles; quick check: verify statistical assumptions are met.
- **Mental Health Prompt Engineering:** Crafting appropriate queries for sensitive topics; needed to elicit meaningful responses while avoiding safety filter triggers; quick check: test prompts with human evaluators.

## Architecture Onboarding

**Component Map:** Prompt Generator -> LLM API Calls -> Response Collection -> Sentiment Analysis Pipeline -> Emotion Classification Pipeline -> Statistical Analysis

**Critical Path:** The essential workflow flows from prompt generation through API calls to response collection, then simultaneously through sentiment analysis and emotion classification pipelines before reaching statistical comparison. Any failure in API calls or analysis pipelines will halt the entire process.

**Design Tradeoffs:** The study prioritized breadth (8 models, 360 prompts) over depth (single response per prompt), trading detailed analysis of individual interactions for broader comparative insights. Using default API parameters simplified implementation but introduced potential variability between model versions.

**Failure Signatures:** API refusals appear as truncated or missing responses, skewing sentiment toward neutral/negative. Emotion model mismatches manifest as missing or inconsistent emotion scores across similar responses. Statistical test failures indicate non-normal distributions requiring alternative analysis methods.

**Three First Experiments:**
1. Test prompt generation with a small subset (10 questions Ã— 3 conditions) to verify demographic framing implementation.
2. Run a pilot with 2-3 models using 50 prompts to validate sentiment analysis pipeline accuracy and API response formats.
3. Compare emotion scores from both classification models on a validation set to identify alignment issues.

## Open Questions the Paper Calls Out
- **Long-term User Impact:** Do specific LLM emotional profiles causally impact long-term user mental health outcomes? This remains unresolved as the study provides only cross-sectional analysis without measuring psychological effects over time.
- **Intersectional Demographics:** How do intersectional demographic identities influence LLM emotional responses compared to single-factor profiles? The current study analyzed categories in isolation but did not test combined identities where bias might emerge.
- **Human vs. Automated Evaluation:** To what extent do automated sentiment analysis tools align with human clinical evaluation of empathy and appropriateness? The study relied on NLP tools but noted that human evaluation would provide crucial validation.

## Limitations
- Ambiguity in "default parameters" specification for proprietary models creates reproducibility challenges
- Lack of specific model checkpoints for GoEmotions classifier introduces potential variance in emotion scoring
- Safety filter activations and response refusals could systematically bias sentiment scores
- Marginal demographic effects suggest insufficient statistical power to detect meaningful interactions

## Confidence
- **High Confidence:** Comparative ranking of models by emotional profiles and differential responses to specific conditions
- **Medium Confidence:** Specific intensity scores for emotions and sentiment categories within the methodology
- **Low Confidence:** Absence of demographic framing effects and precise GoEmotions label mapping cannot be fully verified

## Next Checks
1. **Parameter Verification Test:** Re-run a subset of 100 prompts across all 8 models using explicitly documented parameters and compare emotional score distributions to identify parameter sensitivity.
2. **Model Version Consistency Check:** Document and compare exact model versions for all proprietary APIs at time of reproduction to assess version drift impact on sentiment and emotion scores.
3. **Safety Filter Impact Assessment:** Systematically measure and report frequency of safety refusals or filtered responses across models and conditions to quantify potential bias in emotional profile analysis.