---
ver: rpa2
title: 'Imbalances in Neurosymbolic Learning: Characterization and Mitigating Strategies'
arxiv_id: '2407.10000'
source_url: https://arxiv.org/abs/2407.10000
tags:
- learning
- label
- training
- labels
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies a neurosymbolic learning problem where the gold
  labels are hidden, and only the result of applying a symbolic component to the gold
  labels is available. The paper addresses the problem of characterizing and mitigating
  learning imbalances (class-specific risks) in this setting.
---

# Imbalances in Neurosymbolic Learning: Characterization and Mitigating Strategies

## Quick Facts
- arXiv ID: 2407.10000
- Source URL: https://arxiv.org/abs/2407.10000
- Reference count: 40
- This paper studies neurosymbolic learning with hidden gold labels, providing theoretical analysis and mitigation strategies for learning imbalances caused by symbolic components.

## Executive Summary
This paper addresses neurosymbolic learning (NESY) where gold labels are hidden and only the result of applying a symbolic component to these labels is available. The authors characterize how symbolic functions can create learning imbalances beyond data imbalances, introducing theoretical error bounds that reveal the symbolic component's impact on class-specific risks. They propose two mitigation strategies: a training-time approach using linear programming to enforce marginal constraints on pseudolabels, and a testing-time approach using robust semi-constrained optimal transport to adjust predictions. The techniques demonstrate up to 14% performance improvements across various benchmarks including MAX-M, SUM-M, HWF-M, and Smallest Parent tasks.

## Method Summary
The paper introduces a neurosymbolic learning framework where a neural network is trained using only weak supervision from a symbolic function applied to hidden gold labels. The method consists of three components: (1) Algorithm 1 estimates the marginal distribution of hidden labels by solving polynomial equations defined by the symbolic function using cross-entropy minimization, (2) a training-time mitigation technique uses linear programming to assign pseudolabels that satisfy both symbolic constraints and estimated marginal distributions, and (3) a testing-time mitigation technique employs robust semi-constrained optimal transport (CAROT) to adjust model predictions toward the estimated marginal distribution. The approach is evaluated against strong baselines across multiple NESY benchmarks with significant performance gains.

## Key Results
- Theoretical error bounds reveal that symbolic components can create learning imbalances independent of data distribution
- Algorithm 1 successfully estimates hidden label marginals with cross-entropy minimization
- LP-based training-time mitigation improves performance by up to 14% on MAX-M, SUM-M, HWF-M, and Smallest Parent benchmarks
- CAROT testing-time adjustment provides robust performance even with imperfect marginal estimates
- The techniques outperform standard semantic loss baselines across all evaluated tasks

## Why This Works (Mechanism)

### Mechanism 1
The symbolic component $\sigma$ acts as a causal driver of learning imbalances, potentially creating "hard" classes even when underlying data is uniformly distributed. The authors formulate class-specific risk as a function of partial risk and $\sigma$, showing through non-linear program analysis that $\sigma$ can induce varying difficulties for different classes regardless of data frequency.

### Mechanism 2
The marginal distribution of hidden labels can be recovered from weak supervision by solving polynomial equations defined by the symbolic function. The probability of a weak label $p_j$ is a polynomial of hidden marginals $r$, and Algorithm 1 inverts this relationship using cross-entropy minimization over softmax reparameterization to project noisy weak label counts onto the closest feasible hidden distribution.

### Mechanism 3
Imposing marginal constraints on pseudolabels via Linear Programming mitigates learning skew during training. The system converts symbolic pre-images to linear constraints via Tseytin transformation and solves an LP to find pseudolabels that minimize divergence from model scores while adhering to estimated marginal distribution and symbolic logic.

## Foundational Learning

- **Concept: Neurosymbolic Composition ($\sigma \circ f$)**
  - Why needed here: The entire paper hinges on training a neural network using only the output of a symbolic program applied to its predictions, creating an information bottleneck that standard loss functions cannot handle.
  - Quick check question: If you have a perfect image classifier for digits, but only receive "Max(3, 5) = 5" as feedback, how do you backpropagate error to the specific image of the '3'?

- **Concept: Long-Tailed Learning / Class Imbalance**
  - Why needed here: The paper defines "learning imbalances" as differences in class-specific risks, requiring understanding that standard accuracy is inadequate when symbolic components cause neglect of minority or "hard" classes.
  - Quick check question: Does high average accuracy guarantee the model hasn't failed completely on a specific sub-class?

- **Concept: Optimal Transport (OT)**
  - Why needed here: The testing-time mitigation strategy uses robust semi-constrained optimal transport to view classification as moving probability mass to match target distribution with minimal cost.
  - Quick check question: If you need to adjust model output probabilities to match a known prior without changing weights, what tool allows efficient probability mass "transportation"?

## Architecture Onboarding

- **Component map:** Data Loader -> Neural Backbone -> Marginal Estimator (Alg 1) -> LP Solver (Training) -> CAROT (Testing)
- **Critical path:** Marginal Estimator → LP Solver. If marginal estimation fails (high KL divergence), LP constraints enforcing estimates will bias pseudolabels incorrectly, degrading performance.
- **Design tradeoffs:** LP approach is computationally heavier than Semantic Loss but provides explicit class balance control; CAROT is lighter but sensitive to marginal estimation errors.
- **Failure signatures:** Performance collapse if symbolic functions create shortcuts; marginal divergence if estimation returns uniform distribution when true distribution is skewed.
- **First 3 experiments:**
  1. Sanity Check (MAX-M): Train MNIST classifier on "Max of two digits" using standard Scallop, plot per-class accuracy to confirm '0' is hardest class.
  2. Marginal Recovery: Run Algorithm 1 on SUM-M dataset with known skewed distribution, compare estimated marginals against ground truth.
  3. Mitigation Ablation: Apply LP training technique to MAX-M setup, measure accuracy lift on '0' class specifically, compare against CAROT adjustment.

## Open Questions the Paper Calls Out
- Can robustness of testing-time mitigation techniques like CAROT be improved to handle significant errors in estimated marginal distributions?
- How can the LP formulation for training-time mitigation be solved efficiently for problems with large pre-images without approximations?
- How do strong correlations among input instances affect theoretical error bounds and performance of imbalance mitigation strategies?

## Limitations
- Marginal estimation is sensitive to sample size and imbalance ratio, potentially failing in high-imbalance settings
- LP-based training-time mitigation becomes computationally intractable for large symbolic pre-images
- Current theory assumes i.i.d. instances within input vectors, limiting applicability to correlated data

## Confidence
- High: Theoretical characterization of symbolic component impact on learning imbalances
- Medium: Effectiveness of marginal estimation across all benchmarks
- Medium: Training-time LP mitigation performance improvements
- High: Testing-time CAROT mitigation robustness

## Next Checks
1. Evaluate Algorithm 1's marginal estimation accuracy across varying imbalance ratios (ρ=1, 10, 50, 70) on SUM-M to quantify breakdown points.
2. Measure LP solver runtime and memory usage for symbolic functions of increasing complexity (MAX-M with M=2,3,4,5) to identify practical limits.
3. Compare training-time LP mitigation vs. testing-time CAROT across benchmarks to quantify trade-off between computational cost and performance gain.