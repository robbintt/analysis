---
ver: rpa2
title: 'Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of
  Public Domain Texts'
arxiv_id: '2510.24541'
source_url: https://arxiv.org/abs/2510.24541
tags:
- korean
- corpus
- language
- modern
- hangul
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the Open Korean Historical Corpus, a large-scale,
  openly licensed dataset spanning 1,300 years and 6 languages, including Middle Korean,
  Early Modern Korean, Modern Korean, North Korean, Classical Chinese, and Japanese,
  as well as under-represented writing systems like Idu and Hanja-Hangul mixed script.
  The corpus contains 18 million documents and 5 billion tokens from 19 sources.
---

# Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts

## Quick Facts
- arXiv ID: 2510.24541
- Source URL: https://arxiv.org/abs/2510.24541
- Reference count: 0
- Contains 18 million documents spanning 1,300 years across 6 languages and writing systems

## Executive Summary
This work presents the Open Korean Historical Corpus, a comprehensive collection of public domain Korean texts spanning 1,300 years across six languages and writing systems. The corpus includes Middle Korean, Early Modern Korean, Modern Korean, North Korean, Classical Chinese, and Japanese, along with under-represented systems like Idu and Hanja-Hangul mixed script. With 18 million documents and 5 billion tokens from 19 sources, the corpus enables diachronic analysis of Korean language evolution. The resource is designed to support historical NLP research and provide insights into linguistic transitions over multiple centuries.

## Method Summary
The corpus was compiled through aggregation of 19 distinct public domain sources, including government archives, digital libraries, and academic collections. Documents were processed through automated language detection and script identification systems. The corpus includes multiple writing systems that evolved over time, from Classical Chinese to modern Hangul. Temporal coverage varies significantly across sources, with some periods and scripts better represented than others. The dataset was constructed with attention to licensing requirements to ensure all materials remain openly accessible for research purposes.

## Key Results
- Idu usage peaked in the 1860s before declining sharply after the 1894 Kabo Reform
- The transition from Hanja to Hangul was rapid, starting around 1890, with Hangul exceeding 93% of characters by 1980
- North Korean lexical divergence causes modern tokenizers to produce up to 51 times higher out-of-vocabulary rates

## Why This Works (Mechanism)
The corpus leverages the natural evolution of Korean writing systems over centuries, capturing linguistic transitions as they occurred. The automated language detection and script identification systems enable large-scale processing of heterogeneous historical materials. By including under-represented writing systems like Idu and Hanja-Hangul mixed script, the corpus provides comprehensive coverage of Korean's orthographic history. The open licensing model ensures accessibility for long-term research and enables reproducibility of historical NLP analyses.

## Foundational Learning

**Diachronic corpus analysis** - Understanding how language changes over time through systematic comparison of documents from different periods. *Why needed:* Provides temporal context for linguistic evolution. *Quick check:* Verify temporal distribution of documents across centuries.

**Multi-script document processing** - Handling texts written in multiple writing systems within the same language family. *Why needed:* Korean historical texts use various scripts that co-existed. *Quick check:* Test script detection accuracy on mixed-script samples.

**Historical NLP methodology** - Applying natural language processing techniques to non-contemporary texts with different orthographic conventions. *Why needed:* Standard NLP tools may not work on historical materials. *Quick check:* Compare tokenizer performance on modern vs historical Korean.

## Architecture Onboarding

**Component map:** Document sources -> Language detection -> Script identification -> Temporal alignment -> Tokenization -> Statistical analysis

**Critical path:** The temporal analysis pipeline relies on accurate document dating and script identification to establish reliable diachronic patterns. Errors in either component propagate to downstream analyses.

**Design tradeoffs:** The corpus prioritizes breadth of temporal and script coverage over depth in any single period. This enables broad diachronic analysis but may limit detailed study of specific historical moments.

**Failure signatures:** Inconsistent script detection produces misleading temporal patterns. Missing metadata from certain periods creates gaps in continuous analysis. Automated alignment errors between multi-script versions introduce noise.

**First experiments:** 1) Sample document alignment verification across centuries, 2) Script detection accuracy testing on mixed-script samples, 3) OOV rate calculation comparison using South vs North Korean tokenizers

## Open Questions the Paper Calls Out
None

## Limitations
- Automated document alignment process for multi-script texts introduces unknown error rates, particularly for Idu and Hanja-Hangul mixed scripts
- Metadata coverage is highly uneven, with Classical Chinese and Japanese texts having limited temporal distribution
- Token frequency calculations rely on language detection that may misclassify North Korean texts

## Confidence

**Corpus scale and composition:** High - document counts and source listings are verifiable
**Idu decline pattern:** Medium - temporal pattern appears robust but source concentration in 1860s raises questions about representativeness  
**Hanja-to-Hangul transition timeline:** Medium - aligns with historical records but depends on accurate script detection
**North Korean OOV rates:** Low - methodology untested, potential confounding factors not addressed

## Next Checks
1. Conduct manual verification of document alignment accuracy for Idu and Hanja-Hangul mixed script texts by sampling 100 documents across different centuries
2. Replicate OOV rate calculations using tokenizers specifically trained on North Korean data to control for training bias
3. Analyze metadata completeness for Classical Chinese and Japanese sources to determine if temporal patterns reflect actual usage or collection bias