---
ver: rpa2
title: Feature Ranking in Credit-Risk with Qudit-Based Networks
arxiv_id: '2511.19150'
source_url: https://arxiv.org/abs/2511.19150
tags:
- quantum
- interpretability
- feature
- features
- qudit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a qudit-based quantum neural network (QNN)
  for interpretable credit risk assessment, addressing the challenge of balancing
  predictive accuracy with transparency in financial decision-making. The proposed
  model employs a single qudit and encodes both input features and trainable parameters
  within a unified unitary evolution generated by the full su(d) algebra, enabling
  compact circuit design and intrinsic feature importance attribution through learned
  weight magnitudes.
---

# Feature Ranking in Credit-Risk with Qudit-Based Networks

## Quick Facts
- arXiv ID: 2511.19150
- Source URL: https://arxiv.org/abs/2511.19150
- Reference count: 0
- A qudit-based QNN achieved 0.667 macro F1-score on credit risk data while maintaining strong interpretability

## Executive Summary
This study introduces a qudit-based quantum neural network for interpretable credit risk assessment that balances predictive accuracy with transparency. The model uses a single qudit encoding both features and parameters within a unified unitary evolution, enabling compact circuit design and intrinsic feature importance attribution. Benchmarked on a real-world imbalanced credit dataset from Taiwan, the QNN achieved competitive performance while providing clear feature rankings aligned with classical interpretable models.

## Method Summary
The proposed qudit-based QNN employs a single qudit system where both input features and trainable parameters are encoded within a unified unitary evolution generated by the full su(d) algebra. This architecture enables compact circuit design while maintaining interpretability through learned weight magnitudes that directly indicate feature importance. The model was trained on a real-world imbalanced credit risk dataset and compared against classical baselines including logistic regression, random forest, and neural network models. A feature-poisoning test was conducted to evaluate robustness under corrupted input conditions.

## Key Results
- Achieved 0.667 macro-averaged F1-score, closely matching NN baseline and outperforming LR (0.601) and RF (0.647)
- Feature importance ranking showed strong alignment with logistic regression (edit distance of 20.9)
- Required significantly fewer parameters (384 vs 3,927 for RF) while maintaining moderate interpretability (WIS=0.853)
- Maintained F1-score of 0.632 under feature poisoning with Gaussian noise corruption

## Why This Works (Mechanism)
The qudit-based QNN works by encoding both input features and trainable parameters within a single qudit's unitary evolution, generated by the full su(d) algebra. This unified encoding enables the model to learn intrinsic feature importance through the magnitudes of the learned weights, providing interpretability without sacrificing predictive capability. The compact circuit design reduces parameter count while the single-qudit approach ensures that feature importance attribution remains clear and direct.

## Foundational Learning
- **Quantum neural networks**: Quantum circuits adapted for machine learning tasks; needed for leveraging quantum advantages in pattern recognition; quick check: verify basic QNN forward pass implementation
- **Qudit systems**: d-level quantum systems beyond qubits; needed for higher-dimensional feature encoding; quick check: confirm unitary evolution follows su(d) algebra
- **Feature importance attribution**: Methods for determining which input features most influence predictions; needed for interpretable credit risk decisions; quick check: validate feature ranking consistency across runs
- **Imbalanced classification**: Handling datasets where class distributions are skewed; needed for realistic credit risk scenarios; quick check: verify macro-averaged metrics are appropriate
- **Interpretability metrics**: Quantitative measures of model transparency; needed to compare QNN against classical interpretable models; quick check: confirm WIS calculation methodology

## Architecture Onboarding

Component Map:
Input features -> Qudit encoding -> Unitary evolution (su(d) algebra) -> Measurement -> Output probabilities

Critical Path:
Feature encoding → Unitary transformation → Measurement → Probability calculation → Classification decision

Design Tradeoffs:
- Single qudit enables interpretability but may limit pattern complexity capture
- Unified encoding reduces parameters but requires careful weight initialization
- Compact circuits improve efficiency but may sacrifice some representational power

Failure Signatures:
- Poor convergence indicates inadequate feature scaling or learning rate issues
- Unstable feature rankings suggest insufficient training data or model capacity
- Low robustness to feature poisoning indicates weak generalization

First Experiments:
1. Verify basic forward pass produces reasonable probability distributions
2. Test feature ranking stability across multiple training runs
3. Evaluate performance on synthetic balanced dataset to establish baseline capability

## Open Questions the Paper Calls Out
None

## Limitations
- Dataset size and composition details not fully disclosed, limiting generalizability assessment
- Single qudit approach may restrict capacity to capture complex, high-dimensional patterns
- Robustness test only examined Gaussian noise corruption, not real-world adversarial scenarios

## Confidence

High confidence:
- Reported performance metrics (F1-scores, feature importance alignment) are well-supported by methodology

Medium confidence:
- Interpretability claims require further validation across different datasets and credit risk contexts
- Robustness assessment under feature poisoning needs broader testing scenarios

## Next Checks
1. Test the qudit QNN on multiple credit risk datasets with varying sizes and class distributions to evaluate generalizability
2. Implement adversarial attack simulations beyond Gaussian noise to assess security against real-world threats
3. Compare computational efficiency and parameter efficiency against classical models across different hardware implementations