---
ver: rpa2
title: 'PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation'
arxiv_id: '2511.18570'
source_url: https://arxiv.org/abs/2511.18570
tags:
- material
- physical
- friction
- uncertainty
- property
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PhysGS, a method that extends 3D Gaussian
  Splatting with Bayesian inference to estimate physical properties such as friction,
  hardness, stiffness, density, and mass directly from RGB images and vision-language
  priors. The approach treats each Gaussian primitive as a probabilistic entity, updating
  material and property beliefs using Dirichlet-Categorical and Normal-Inverse-Gamma
  posteriors that integrate multi-view, confidence-weighted evidence.
---

# PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation

## Quick Facts
- arXiv ID: 2511.18570
- Source URL: https://arxiv.org/abs/2511.18570
- Reference count: 40
- Primary result: Improves mass estimation accuracy by up to 22.8% over baselines using Bayesian Gaussian Splatting with vision-language priors

## Executive Summary
PhysGS introduces a Bayesian framework that extends 3D Gaussian Splatting to estimate physical properties like friction, hardness, stiffness, density, and mass directly from RGB images. The method treats each Gaussian primitive as a probabilistic entity, updating material and property beliefs using Dirichlet-Categorical and Normal-Inverse-Gamma posteriors that integrate multi-view, confidence-weighted evidence from vision-language models. This approach produces both dense per-point property fields and object-level aggregates while quantifying aleatoric and epistemic uncertainty. Evaluated across multiple datasets, PhysGS demonstrates significant improvements in physical property estimation accuracy while providing uncertainty-aware predictions that reflect segmentation quality and environmental complexity.

## Method Summary
PhysGS builds on 3D Gaussian Splatting by incorporating Bayesian inference to estimate physical properties. The pipeline uses SAM for hierarchical segmentation, a VLM (GPT-5) to predict material labels and properties with confidence scores, and Dirichlet-Categorical/NIG posteriors to fuse multi-view evidence. The method maintains running accumulators for efficient online updates without storing raw observations, enabling both per-point property fields and object-level aggregates. Aleatoric and epistemic uncertainty components are explicitly modeled, providing calibrated confidence measures that reflect both inherent material variability and knowledge gaps.

## Key Results
- Mass estimation accuracy improved by up to 22.8% over deterministic baselines
- Shore hardness error reduced by up to 61.2% on real-world datasets
- Kinetic friction error decreased by up to 18.1% compared to NeRF2Physics
- Uncertainty-aware predictions show strong correlation between high uncertainty and segmentation failures in cluttered environments

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Bayesian Posterior Refinement
Treating each Gaussian primitive as a probabilistic entity with iteratively refined posteriors improves physical property estimation over deterministic single-view predictions. A Dirichlet-Categorical model handles discrete material labels while a Normal-Inverse-Gamma prior governs continuous property distributions. As multi-view observations arrive, posterior parameters update in closed form via conjugate updates, accumulating confidence-weighted evidence without storing raw observations.

### Mechanism 2: Confidence-Weighted Multi-View Fusion
Fusing observations across views using running moments reduces estimation variance compared to single-view or unweighted averaging. Accumulators track total weight, first moment, and second moment per material class, enabling online, incremental updates with O(1) memory per property. The confidence from the VLM weights each observation's contribution.

### Mechanism 3: Aleatoric-Epistemic Uncertainty Decomposition
Decomposing total predictive uncertainty into aleatoric (inherent noise) and epistemic (knowledge gap) components enables calibrated confidence signaling and reveals segmentation quality issues. The NIG posterior yields closed-form uncertainty components: aleatoric = E[σ²_i], epistemic = Var[μ_i] = E[σ²_i]/κ̃_i. As evidence accumulates, epistemic uncertainty shrinks while aleatoric remains bounded by inherent material variability.

## Foundational Learning

- **3D Gaussian Splatting Fundamentals**
  - Why needed: PhysGS builds directly on 3DGS primitives; understanding how Gaussians are optimized for radiance fields is prerequisite to extending them with property fields.
  - Quick check: Can you explain how 3DGS renders an image from a set of Gaussian primitives via alpha compositing?

- **Conjugate Bayesian Inference (Dirichlet-Categorical, Normal-Inverse-Gamma)**
  - Why needed: The entire property estimation pipeline relies on conjugate priors for closed-form updates; without this, you cannot understand the accumulation equations or uncertainty decomposition.
  - Quick check: Given a Dirichlet prior with parameters α and a set of categorical observations, how do you compute the posterior predictive probability?

- **Aleatoric vs. Epistemic Uncertainty**
  - Why needed: PhysGS explicitly models both; distinguishing them is essential for interpreting uncertainty maps and diagnosing failure modes.
  - Quick check: Which type of uncertainty should decrease as you collect more high-confidence observations?

## Architecture Onboarding

- **Component map:** SAM segmentation -> VLM prompting -> Bayesian accumulator -> 3DGS reconstruction -> Uncertainty renderer
- **Critical path:** Multi-view images -> SAM segmentation -> VLM prompting -> Bayesian fusion -> 3DGS property field. Errors in SAM propagate directly to VLM and increase downstream uncertainty.
- **Design tradeoffs:** VLM choice (GPT-5 vs GPT-4V) balances reasoning strength vs inference cost; more views reduce epistemic uncertainty but require more VLM calls; finer segmentation improves material separation but increases VLM queries.
- **Failure signatures:** High epistemic uncertainty in uniform regions indicates VLM view-inconsistency; high aleatoric uncertainty in homogeneous regions suggests material variability; noisy property field boundaries indicate SAM mask leakage.
- **First 3 experiments:**
  1. Reproduce ABO-500 mass estimation: Train on 300 objects, validate on 100. Compare ADE/APE against NeRF2Physics. Verify Bayesian update reduces APE by ~20%+.
  2. Uncertainty calibration check: On validation set, bin predictions by total uncertainty; compute actual error rate per bin. Well-calibrated model should show monotonically increasing error with uncertainty.
  3. Ablate VLM confidence weighting: Run pipeline with all p_m = 1.0 (uniform weighting). Expect ADE degradation of ~5-10% based on Table 2 ablation patterns.

## Open Questions the Paper Calls Out

### Open Question 1
Can VLM-guided segmentation refinement or confidence-based mask filtering significantly reduce predictive uncertainty in cluttered outdoor environments? The paper explicitly states future work may incorporate these techniques to automatically reject low-quality masks, as current SAM segmentation often fails in dense clutter.

### Open Question 2
How robust is the Bayesian posterior convergence when the VLM provides systematically biased or hallucinated property priors? While the method relies on VLMs for material labels and property estimates, the paper does not analyze failure modes where the VLM is confidently incorrect.

### Open Question 3
Can the framework be adapted for real-time, online physical property estimation during active robotic manipulation? The current implementation trains 3DGS for 20,000 iterations using pre-collected multi-view datasets, but robotics applications require streaming, online estimation.

## Limitations

- VLM reliability and confidence calibration are critical; systematic miscalibration would break Bayesian weighting
- Outdoor generalization relies on SAM's ability to segment complex scenes; performance degrades with clutter and lighting variation
- Prior hyperparameters for Dirichlet/NIG posteriors are unspecified, potentially affecting convergence and uncertainty estimates

## Confidence

- Mass estimation accuracy gains (≥22.8% vs baselines): High confidence
- Uncertainty decomposition validity: Medium confidence
- Multi-view Bayesian fusion effectiveness: Medium confidence

## Next Checks

1. **Prior sensitivity analysis:** Sweep α^(0), (τ, κ, α, β) values and measure impact on mass estimation ADE/APE and uncertainty calibration curves
2. **VLM confidence calibration test:** On held-out validation set, bin predictions by p_m and compute actual accuracy per bin; check for monotonic error-uncertainty relationship
3. **View independence verification:** Measure correlation between property estimates from overlapping vs. non-overlapping camera views; quantify fusion gains as function of view diversity