---
ver: rpa2
title: 'ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical
  Retrieval'
arxiv_id: '2505.08130'
source_url: https://arxiv.org/abs/2505.08130
tags:
- aloha
- retrieval
- search
- system
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors developed ALOHA, a multilingual agent for university
  orientation that uses hierarchical retrieval to address challenges in providing
  campus-specific information. The system leverages large language models enhanced
  with structured and unstructured document retrieval, intent classification, and
  machine translation to serve users in multiple languages.
---

# ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval

## Quick Facts
- arXiv ID: 2505.08130
- Source URL: https://arxiv.org/abs/2505.08130
- Authors: Mingxu Tao; Bowen Tang; Mingxuan Ma; Yining Zhang; Hourun Li; Feifan Wen; Hao Ma; Jia Yang
- Reference count: 9
- Primary result: 94% accuracy in Chinese queries, 87% in English, 78% in French for university orientation

## Executive Summary
ALOHA is a multilingual agent designed for university orientation that addresses the challenge of providing accurate, campus-specific information across multiple languages. The system leverages hierarchical retrieval to route queries through different document types based on intent classification, enabling efficient access to both structured and unstructured campus information. By combining large language models with intent-guided document routing, query translation, and external tool integration, ALOHA achieves high accuracy across Chinese, English, and French queries. The system has been deployed at Peking University, serving over 12,000 users and demonstrating strong performance in correctness, timeliness, and user-friendliness compared to commercial alternatives.

## Method Summary
ALOHA implements a RAG-based architecture with hierarchical retrieval for university orientation. The system first detects query language using FastText, translates non-Chinese queries to Chinese, and classifies intent using a fine-tuned Qwen2-1.5B model enhanced with Heuristic Intent Classification (HIC). Based on intent, queries are routed to specific document subsets or undergo sequential retrieval through concepts, QA pairs, and web pages. Retrieved evidence is reranked and passed to GPT-4o for generation, with responses translated back to the original language. The system integrates external tools for maps and classroom availability, and has been deployed at Peking University with over 12,000 users served.

## Key Results
- Achieved 94% accuracy for Chinese queries, 87% for English, and 78% for French in human evaluation
- Outperformed commercial chatbots and search engines on university-specific queries
- Served over 12,000 users in deployment at Peking University

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Retrieval with Intent-Guided Document Routing
User queries are classified into 11 intent categories and routed to corresponding semi-structured document subsets. For other queries, the system searches sequentially through concepts → QA pairs → web pages, stopping when quality evidence is found (reranking score ≥ 0.1). This improves accuracy by constraining search space before retrieval begins.

### Mechanism 2: Heuristic Intent Classification (HIC)
Before classification, cosine similarity between input query and training queries is computed using BGE-m3 embeddings. The classifier predicts only from the top-50 most similar training examples' intent classes. This filtering improves classification accuracy from 94.1% to 96.3% for Qwen2-1.5B-finetuned.

### Mechanism 3: Query Translation for Cross-Lingual Retrieval
Non-Chinese queries are translated to Chinese using NLLB before retrieval, since documents are Chinese. Retrieved evidence and generated response are translated back to the original language. This enables cross-lingual retrieval but introduces error propagation risk from mistranslation.

## Foundational Learning

- **Retrieval-Augmented Generation (RAG)**: ALOHA's core architecture is RAG-based; understanding how retrieved evidence grounds LLM generation is essential. Quick check: Can you explain why providing retrieved documents in the prompt reduces hallucination compared to pure LLM generation?

- **Dense Retrieval and Reranking**: ALOHA uses BGE-m3 for embeddings, ElasticSearch for retrieval, and bge-reranker-v2-m3 for reranking. Quick check: What is the difference between bi-encoder retrieval and cross-encoder reranking in terms of accuracy vs latency tradeoffs?

- **Intent Classification with Constrained Decoding**: HIC constrains classifier output space via similarity-based filtering. Quick check: How would you implement top-k neighbor filtering to constrain a classifier's output distribution?

## Architecture Onboarding

- **Component map**: FastText (language ID) → NLLB (translation) → Qwen2-1.5B-finetuned + HIC (intent classification) → LTP-4 (parsing) → BGE-m3 (embeddings) → ElasticSearch (dense retrieval) → bge-reranker-v2-m3 (reranking) over concepts, QA pairs, web pages → GPT-4o (generation with evidence + tool planning) → NLLB (back-translation) → External APIs (maps, classroom availability)

- **Critical path**: Query → Language ID → Translation → Intent Classification → Document Store Selection → Retrieval → Reranking → LLM Generation → Tool Invocation → Response Translation

- **Design tradeoffs**: Sequential retrieval reduces false positives but may miss relevant evidence; translating all queries to Chinese improves recall but introduces translation error risk; using small model for intent classification is efficient but requires finetuning data and HIC augmentation

- **Failure signatures**: Intent classification errors → wrong document subset; translation errors on named entities → wrong documents retrieved; reranking threshold too strict → no evidence retrieved; outdated documents → stale information used

- **First 3 experiments**: 1) Ablate HIC: compare intent classification accuracy with and without top-k neighbor filtering; 2) Translation error analysis: correlate translation quality with retrieval accuracy for 50 non-Chinese queries; 3) Retrieval threshold sensitivity: vary reranking threshold (0.05, 0.1, 0.2) and measure precision@k vs recall@k

## Open Questions the Paper Calls Out

### Open Question 1
How can the multilingual pipeline be improved to handle cross-lingual misalignments in named entities? The paper describes a specific failure where "School of Electronic and Computer Engineering" mistranslated, leading to incorrect location retrieval. This remains unresolved due to machine translation introducing errors when location names lack aligned literal meanings. Evidence would come from incorporating cross-lingual entity linking or multilingual knowledge graph that improves accuracy for non-Chinese entity queries.

### Open Question 2
Can the updating mechanism for the document store be fully automated to handle format inconsistencies? The paper states that format inconsistencies in web pages prevent automatic replacement of outdated pages. This requires manual intervention or lacks a robust mechanism to automatically swap out outdated content when source website structure changes. Evidence would come from an algorithm capable of semantic diffing or schema matching that successfully identifies and replaces outdated documents without human supervision.

### Open Question 3
To what extent does Heuristic Intent Classification (HIC) generalize to domains outside of university administration? The intent classification relies on 11 specific classes derived from university reimbursement and schedule queries. While effective in this domain, it's unclear if HIC functions effectively in domains with more fluid or overlapping intent categories. Evidence would come from evaluation results in different settings (e.g., corporate HR or hospital administration) using the same HIC methodology.

## Limitations

- Translation error propagation risk from named entity misalignment, particularly for non-Chinese entity names
- Manual intervention required for updating document store due to format inconsistencies across different periods
- Limited generalizability of intent classification approach to domains beyond university administration

## Confidence

- Hierarchical retrieval architecture and intent classification mechanism: High confidence
- Human evaluation results: Medium confidence
- Translation error impact: Low confidence

## Next Checks

1. Implement ablation study comparing HIC vs baseline intent classification on held-out test set with 10-fold cross-validation to quantify generalization limits.

2. Conduct systematic analysis of 100+ translated queries measuring correlation between translation quality (human-rated) and retrieval accuracy to quantify error propagation risk.

3. Test reranking threshold sensitivity across different query distributions to identify optimal stopping criteria that balance precision and recall.