---
ver: rpa2
title: 'Similarity Field Theory: A Mathematical Framework for Intelligence'
arxiv_id: '2509.18218'
source_url: https://arxiv.org/abs/2509.18218
tags:
- similarity
- field
- theory
- fiber
- entities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Similarity Field Theory (SFT) reframes intelligence as a geometric\
  \ property of evolving similarity structures. It defines a directed similarity field\
  \ S: U\xD7U\u2192[0,1] with reflexivity, treats entities as members of concepts\
  \ via threshold-based fibers F\u03B1(K), and models system evolution as a sequence\
  \ of states."
---

# Similarity Field Theory: A Mathematical Framework for Intelligence

## Quick Facts
- arXiv ID: 2509.18218
- Source URL: https://arxiv.org/abs/2509.18218
- Reference count: 19
- Defines intelligence as preservation of similarity fibers under generative operators

## Executive Summary
Similarity Field Theory reframes intelligence as a geometric property of evolving similarity structures. It defines a directed similarity field S: U×U→[0,1] with reflexivity, treats entities as members of concepts via threshold-based fibers Fα(K), and models system evolution as a sequence of states. Intelligence is defined operationally: a generative operator G is intelligent with respect to concept K if it produces new entities that also belong to the fiber of K. SFT proves two foundational theorems—(i) asymmetry blocks mutual inclusion across cross-referenced thresholds, and (ii) stability requires either an anchor coordinate or asymptotic confinement to a target level. The framework unifies interpretability, learning, and creativity as preservation and composition of conceptual fibers, offering a principled lens for analyzing neural networks and language models as calibrated similarity fields.

## Method Summary
The theory constructs a directed similarity field S mapping entity pairs to [0,1] with reflexive properties, then defines fibers Fα(K) as sets of entities similar enough to concept K at threshold α. System evolution proceeds through state sequences where each state is a pair of similarity field and entity set. Intelligence is operationalized via a generative operator G that, when applied to entities in a fiber, produces outputs also within that fiber. The framework proves structural theorems about stability and incompatibility, then applies these to neural networks by interpreting neurons as elements of the entity set and proposing calibrated activations to satisfy the theory's requirements.

## Key Results
- Proves that asymmetric similarity metrics prevent mutual agreement when entities cross-reference thresholds
- Establishes stability conditions requiring either an anchor coordinate or asymptotic confinement to a target level
- Unifies interpretability, learning, and creativity as preservation and composition of conceptual fibers

## Why This Works (Mechanism)
The theory works by treating intelligence as a geometric property of similarity structures rather than behavioral outcomes. By defining a reflexive similarity field and threshold-based fibers, it creates a mathematical space where conceptual membership can be precisely defined. The generative operator framework then captures intelligence as the ability to navigate and preserve these geometric structures. The theorems on asymmetry and stability provide fundamental constraints that explain why certain cognitive tasks succeed or fail, while the calibration approach offers a path to apply the theory to existing neural architectures.

## Foundational Learning
- Directed similarity field S: U×U→[0,1]: Needed to create a mathematical space where entity relationships can be quantified and compared. Quick check: Verify reflexivity and directionality properties hold for your similarity measure.
- Threshold-based fibers Fα(K): Needed to define crisp membership in fuzzy concepts. Quick check: Plot entity similarity distributions to choose meaningful thresholds.
- Generative operator G: Needed to operationalize intelligence as preservation of structure. Quick check: Test whether outputs of G applied to fiber members remain in the fiber.
- Calibration function φ: Needed to map unbounded neural activations to the theory's unit interval. Quick check: Verify semantic similarity is preserved after calibration across network layers.
- State evolution sequence: Needed to model learning and adaptation over time. Quick check: Track fiber stability across state transitions.

## Architecture Onboarding

Component map: Similarity field S -> Thresholds α -> Fibers Fα(K) -> Generative operator G -> Intelligence measure

Critical path: The core pipeline flows from defining the similarity field, through threshold selection and fiber computation, to applying the generative operator and measuring intelligence via fiber preservation. Each component depends on the previous one being well-defined and mathematically consistent.

Design tradeoffs: The theory trades empirical flexibility for mathematical rigor. While the similarity field axioms provide strong guarantees, they may exclude meaningful similarity measures that violate reflexivity or directionality. The threshold-based approach creates crisp boundaries but may oversimplify fuzzy concept boundaries. Calibration requirements add computational overhead but enable application to existing neural architectures.

Failure signatures: If fibers become empty or contain only trivial entities, the concept may be too strict or the similarity measure too weak. Asymmetric similarity fields that violate the incompatibility theorem will show negotiation deadlocks. Poor calibration functions that distort ordinal relationships will break the composition of similarity fields.

Three first experiments:
1. Construct a toy dataset where similarity is defined via learned embeddings, compute fibers for a target concept, and empirically verify whether a generative model produces outputs within the fiber while preserving asymmetry.
2. Analyze a pre-trained language model by extracting contextual similarity matrices between tokens, define threshold-based fibers for a semantic concept, and test whether model-generated continuations remain in the fiber.
3. Implement a synthetic evolution experiment where a directed similarity field changes over time; track whether stability theorems hold when adding/removing an anchor concept or constraining evolution to a target similarity level.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can geometric fiber-recovery algorithms identify interpretable concepts in neural networks more effectively than linear probes?
- Basis in paper: Section 6 states that "recovering... inputs in this fiber amounts to recovering what the neuron 'means'" and frames interpretability as this geometric decomposition task.
- Why unresolved: The paper proposes the theoretical mapping between neurons and concept fibers but provides no empirical comparison of fiber-based recovery against standard interpretability baselines.
- What evidence would resolve it: A benchmark comparing SFT-based fiber reconstruction against methods like sparse autoencoders or probing classifiers on datasets with known ground-truth concepts.

### Open Question 2
- Question: What calibration function $\phi$ maps unbounded neural activations to $[0,1]$ while preserving the similarity field's relational structure?
- Basis in paper: Section 6 defines "calibrated activation $a \sim \phi(a)$" to force neural outputs into the theory's unit interval, but offers no specific functional form.
- Why unresolved: The theory's axioms (e.g., reflexivity) rely on the range $[0,1]$; if the calibration distorts ordinal relationships, the "composition of similarity fields" view collapses.
- What evidence would resolve it: Empirical analysis of calibration techniques (e.g., temperature scaling, isotonic regression) showing that semantic similarity is preserved post-calibration across diverse network layers.

### Open Question 3
- Question: Do multi-agent AI systems exhibit negotiation deadlocks predicted by the Incompatibility Theorem when using asymmetric similarity metrics?
- Basis in paper: Section 3.2 applies Theorem 1 to a "stylized negotiation setting," suggesting asymmetry creates a "forced imbalance" where mutual agreement is mathematically impossible under cross-referenced thresholds.
- Why unresolved: The paper proves the mathematical impossibility of mutual inclusion but does not demonstrate if this structural constraint actually causes failure modes in LLM-agent interactions.
- What evidence would resolve it: Multi-agent simulations where agents set acceptance thresholds based on the opponent's perceived value, verifying if agreement fails exactly when asymmetry levels violate the theorem's conditions.

## Limitations
- The similarity field S is defined without grounding to measurable observables, making empirical validation non-trivial
- No benchmark experiments or empirical tests are provided to validate the theoretical claims
- The abstraction gap between mathematical formalism and real-world neural network behavior remains unbridged

## Confidence
- Intelligence as fiber preservation: High confidence in mathematical consistency, Low confidence in external validity
- Asymmetry theorem: High confidence in proof logic, Low confidence in real-world applicability
- Stability requirements: Medium confidence in coherence, Low confidence without empirical demonstrations

## Next Checks
1. Construct a toy dataset (e.g., MNIST) where similarity is defined via learned embeddings, compute fibers for a target concept (e.g., "digit 7"), and empirically verify whether a generative model produces outputs within the fiber while preserving asymmetry.
2. Analyze a pre-trained language model by extracting contextual similarity matrices between tokens, define threshold-based fibers for a semantic concept (e.g., "legal"), and test whether model-generated continuations remain in the fiber.
3. Implement a synthetic evolution experiment where a directed similarity field changes over time; track whether stability theorems hold when adding/removing an anchor concept or constraining evolution to a target similarity level.