---
ver: rpa2
title: Inferring Implicit Goals Across Differing Task Models
arxiv_id: '2501.17704'
source_url: https://arxiv.org/abs/2501.17704
tags:
- state
- query
- states
- implicit
- subgoals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of identifying and achieving\
  \ implicit user subgoals when an agent\u2019s model of the task differs from the\
  \ user\u2019s understanding. The method identifies bottleneck states in the user\u2019\
  s model as candidates for implicit subgoals and introduces a querying strategy to\
  \ minimize the number of queries needed to find a policy that satisfies the user\u2019\
  s underlying goals."
---

# Inferring Implicit Goals Across Differing Task Models

## Quick Facts
- arXiv ID: 2501.17704
- Source URL: https://arxiv.org/abs/2501.17704
- Reference count: 3
- Primary result: Achieves 22-41% query reductions in 4×4 grid environments by identifying bottleneck states as implicit subgoal candidates

## Executive Summary
This paper addresses the challenge of identifying and achieving implicit user subgoals when an agent's model of the task differs from the user's understanding. The method identifies bottleneck states in the user's model as candidates for implicit subgoals and introduces a querying strategy to minimize the number of queries needed to find a policy that satisfies the user's underlying goals. The approach uses determinization to identify bottleneck states and formulates the querying process as an MDP. Empirical evaluations on benchmark MDP problems demonstrate that the method effectively infers implicit subgoals and achieves significant reductions in the number of queries compared to querying all bottleneck states.

## Method Summary
The method works by first identifying bottleneck states in determinized versions of potential human models, then testing these as implicit subgoal candidates through a penalty-based MDP formulation. It constructs a query MDP where states represent known and unknown subgoals, with actions corresponding to querying unclassified bottlenecks. The system solves this query MDP to find an optimal querying strategy, using a pruning optimization that first checks non-achievable bottlenecks. The approach guarantees finding a policy that achieves all implicit subgoals while minimizing query count through exact MDP planning.

## Key Results
- 22-41% query reduction in 4×4 grid environments compared to baseline
- 71.9% query reduction in 8×8 grids with pruning optimization
- Method correctly identifies implicit subgoals across Maze, Four-Rooms, PuddleWorld, and RockWorld environments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bottleneck states in the human's model serve as candidate implicit subgoals because users omit stating requirements they believe are inevitable.
- Mechanism: Determinization preserves bottleneck states across stochastic models. For each potential human model M_H, convert to determinized form δ(M_H) where stochastic transitions become separate deterministic actions. Then test each state by creating a modified MDP that penalizes visiting that state while rewarding goal achievement—if V*(s₀) > 0, the state is avoidable and thus not a bottleneck.
- Core assumption: Implicit subgoals are a subset of bottleneck states in the human's model; users don't specify what they consider unavoidable.
- Break condition: If implicit goals can exist outside bottleneck states (e.g., optional preferences the user forgot to mention), this mechanism will miss them.

### Mechanism 2
- Claim: Querying can be formulated as an MDP where optimal policies minimize expected query cost while guaranteeing goal achievement.
- Mechanism: Construct query MDP M_Q where states are (K_I, K_¬I)—known implicit subgoals and known non-subgoals. Actions query unclassified bottlenecks. Transitions model oracle responses. Absorbing states trigger when K_I is achievable or provably unachievable. The Bellman equations encode the recursive expected cost, so solving M_Q yields an optimal query ordering.
- Core assumption: The oracle can reliably classify whether a state is an implicit subgoal; query cost dominates secondary objectives.
- Break condition: If oracle responses are noisy or adversarial, the transition model in M_Q becomes misspecified, potentially leading to suboptimal or incorrect query sequences.

### Mechanism 3
- Claim: Pruning non-achievable bottlenecks before solving the query MDP yields an optimal meta-policy with reduced computational cost.
- Mechanism: First identify bottlenecks unreachable in M_R (the robot's model). Query these immediately—if they're implicit subgoals, the task is impossible regardless of other queries. Then solve the pruned MDP containing only potentially achievable bottlenecks. Proposition 6 proves this meta-policy is optimal because querying non-achievable states always has expected cost ≤ querying achievable ones (at least one guaranteed future query is avoided).
- Core assumption: Non-achievable bottlenecks can be identified efficiently; early termination when K_I ⊄ any achievable set doesn't discard viable solutions.
- Break condition: If achievability testing is computationally infeasible (large state spaces, complex constraints), the pruning step may dominate runtime, negating query savings.

## Foundational Learning

- **Markov Decision Processes (MDPs) and goal-reaching traces**
  - Why needed here: The entire framework models tasks as goal-based MDPs; understanding V^π, optimal policies, and trace probabilities is essential for bottleneck detection and subgoal achievement testing.
  - Quick check question: Given an MDP with sparse rewards only at goal states, what does V^π(s) represent and how does it relate to goal-reaching probability?

- **All-outcome determinization**
  - Why needed here: Propositions 1-3 rely on converting stochastic transitions to deterministic actions to enumerate and test bottleneck states finitely.
  - Quick check question: If M has 3 states and action a has transitions T(s₁, a, s₂) = 0.7 and T(s₁, a, s₃) = 0.3, what actions exist in δ(M) for state s₁?

- **MDP policy optimization (value iteration, policy iteration)**
  - Why needed here: Testing bottleneck states and solving the query MDP both require computing optimal policies over modified MDPs.
  - Quick check question: Why does the reward structure in M_sᵢ (negative for visiting sᵢ, positive for goals) allow testing whether sᵢ is a bottleneck?

## Architecture Onboarding

- Component map: Bottleneck Finder -> Achievability Checker -> Maximal Subset Generator -> Query MDP Solver -> Pruning Module
- Critical path: Bottleneck identification (Proposition 3 testing) → Maximal subset enumeration (Algorithm 1) → Query MDP construction and solve → Execute query policy via oracle interaction
- Design tradeoffs:
  - Exact vs. approximate: Paper pursues optimal query strategies; approximate methods could trade query optimality for faster computation
  - Full enumeration vs. sampling: Listing all determinized models ensures completeness but may be infeasible for large action spaces
  - Query cost model: Paper assumes uniform high cost; real settings may have context-dependent costs
- Failure signatures:
  - Empty I: All bottleneck subsets unachievable—indicates fundamental model mismatch; system should report impossibility
  - Query loop: M_Q doesn't terminate—check absorbing state conditions; ensure K_I ⊆ some I′ is correctly tested
  - Timeout in bottleneck finding: High obstacle density caused 27.4s bottleneck times; consider early termination or parallelization
- First 3 experiments:
  1. Implement Proposition 3 bottleneck detection on a 4×4 Maze with 2 determinized human models. Verify identified bottlenecks match manual analysis of required waypoints.
  2. For a given M_R and 3-candidate subgoal set, implement Proposition 4's expanded MDP. Confirm CheckAchievability returns correct results for subsets {s₁}, {s₂}, {s₁, s₂} where s₁ is reachable but {s₁, s₂} is not.
  3. Build M_Q for |B| = 5, 8, 12 bottleneck states. Measure solve time and compare query counts from optimal policy vs. baseline "query-all" strategy on Four-Rooms environment.

## Open Questions the Paper Calls Out

- **User study validation**: How does the querying strategy perform in realistic human-robot interaction scenarios regarding cognitive load and user tolerance for interruptions? The paper calls for user studies to measure objective task success and subjective metrics (e.g., cognitive load, frustration) when users are queried by the agent in real-time.

- **Approximate solver scalability**: Can approximate solvers maintain the query optimality of the current exact method while significantly reducing computational overhead in larger state spaces? The paper notes pruning times increase drastically (e.g., to ~325 seconds for 8×8 grids), suggesting the exact MDP solution approach may not scale efficiently to complex domains.

- **External knowledge integration**: How can external knowledge sources, such as pre-trained large language models (LLMs), be utilized to better initialize user model hypotheses and reduce the querying burden? The authors suggest using LLMs to filter or weight candidate user models based on natural language input, potentially resulting in a lower average query count compared to the purely structural approach.

## Limitations
- Reliance on bottleneck states may miss optional preferences the user considers avoidable but forgot to mention
- Query MDP optimality assumes an oracle with perfect classification ability, which may not hold in real deployments
- Computational costs scale exponentially with bottleneck count, making the approach potentially infeasible for complex domains

## Confidence

- **High confidence**: The core mechanism of using bottleneck states as implicit subgoal candidates is well-grounded in MDP theory and the determinization process is mathematically sound
- **Medium confidence**: The query MDP formulation and optimality proofs are rigorous, but practical performance depends heavily on oracle reliability and computational tractability
- **Low confidence**: The claim that pruning non-achievable bottlenecks always reduces expected query cost needs empirical validation across diverse task structures

## Next Checks

1. **Bottleneck coverage validation**: Create a synthetic environment where implicit subgoals include both unavoidable bottlenecks and avoidable preferences. Test whether the method correctly identifies all bottlenecks but misses avoidable preferences, quantifying the recall gap.

2. **Oracle noise sensitivity**: Implement a noisy oracle that occasionally misclassifies implicit subgoals. Measure how query optimality degrades and whether the method can recover from erroneous classifications.

3. **Scalability benchmark**: Run the complete pipeline on an 8×8 PuddleWorld with varying obstacle densities (0.05, 0.1, 0.15) and measure bottleneck identification time, subset enumeration time, and query MDP solve time to identify practical limits.