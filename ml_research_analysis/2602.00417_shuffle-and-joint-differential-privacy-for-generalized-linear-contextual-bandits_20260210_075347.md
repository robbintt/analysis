---
ver: rpa2
title: Shuffle and Joint Differential Privacy for Generalized Linear Contextual Bandits
arxiv_id: '2602.00417'
source_url: https://arxiv.org/abs/2602.00417
tags:
- theorem
- privacy
- lemma
- algorithm
- bandits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first algorithms for generalized linear
  contextual bandits under shuffle differential privacy and joint differential privacy.
  Prior private contextual bandits were limited to linear reward models, which admit
  closed-form estimators.
---

# Shuffle and Joint Differential Privacy for Generalized Linear Contextual Bandits

## Quick Facts
- arXiv ID: 2602.00417
- Source URL: https://arxiv.org/abs/2602.00417
- Authors: Sahasrajit Sarmasarkar
- Reference count: 40
- Key outcome: First algorithms for GLM contextual bandits under shuffle-DP and joint-DP, removing κ-dependence from regret's dominant √T term

## Executive Summary
This paper introduces the first algorithms for generalized linear contextual bandits under shuffle differential privacy and joint differential privacy. Unlike prior work limited to linear reward models, these algorithms handle GLMs where no closed-form estimators exist, requiring private convex optimization and careful tracking of privacy across evolving design matrices. The shuffle-DP algorithm achieves $\tilde{O}(d^{3/2}\sqrt{T}/\sqrt{\varepsilon})$ regret for stochastic contexts, while the joint-DP algorithm achieves $\tilde{O}(d\sqrt{T}/\sqrt{\varepsilon})$ regret for adversarial contexts, both removing dependence on the instance-specific parameter $\kappa$ from the dominant $\sqrt{T}$ term.

## Method Summary
The paper presents two algorithms: Algorithm 1 for stochastic contexts using shuffle-DP, and Algorithm 2 for adversarial contexts using joint-DP. Both use G-optimal design for exploration, arm elimination via UCB/LCB, and private convex optimization (PGD) for parameter estimation. The shuffle-DP algorithm batches contexts and uses local randomizers with a shuffler, while the joint-DP algorithm employs a binary-tree mechanism for continual release of design matrices. Key innovations include handling non-monotonic design matrices through maximum determinant tracking, and decomposing privacy loss across the binary tree structure.

## Key Results
- Shuffle-DP algorithm achieves $\tilde{O}(d^{3/2}\sqrt{T}/\sqrt{\varepsilon})$ regret for stochastic contexts
- Joint-DP algorithm achieves $\tilde{O}(d\sqrt{T}/\sqrt{\varepsilon})$ regret for adversarial contexts
- Both algorithms remove κ-dependence from the dominant √T term, avoiding exponential dependence on dimension
- Experimental results on synthetic probit and logistic bandits validate theoretical guarantees and show competitive performance against baselines

## Why This Works (Mechanism)

### Mechanism 1: Private Convex Optimization Integration
Private convex optimization can be integrated into bandit estimation without destroying confidence bounds if optimization error is properly bounded. The shuffle-private PGD optimizer is called on regularized negative log-likelihood, with optimization error ν contributing only O(√ν) to the confidence radius. The optimizer runs for ε²B²k/(d·log³(Bkd/δ)) iterations with step size η = 2S/(RS√T).

### Mechanism 2: Modified Switching Criterion for Noisy Matrices
Policy switching based on design matrix determinants works even when matrices are noisy and non-monotone by comparing against the running maximum. The binary-tree mechanism adds independent Gaussian noise to each node, making design matrices non-monotone. The modified switching criterion triggers when max_{s≤t} det(H_s) has doubled rather than when current det(H_t) doubles, preserving the O(d log T) bound on switches.

### Mechanism 3: Data-Dependent Switching Times Through Likelihood-Ratio Decomposition
Data-dependent switching times can be private through likelihood-ratio decomposition across the binary tree structure. The exploration index set To depends on contexts and noisy design matrices. Privacy is proven by decomposing log-likelihood ratios across the binary tree: only nodes whose subtrees contain the differing index contribute, and there are at most log T such nodes.

## Foundational Learning

- **Concept: Differential Privacy (ε, δ-DP)**
  - Why needed: All algorithms must satisfy either shuffle-DP or joint-DP; understanding the privacy guarantee is essential for parameter calibration
  - Quick check: Given ε = 1, δ = 0.01, can you explain why adding N(0, 2 log(1.25/δ)/ε²) noise to a query with sensitivity 1 satisfies (ε, δ)-DP?

- **Concept: Generalized Linear Models (GLMs) and the κ parameter**
  - Why needed: The entire paper addresses GLM bandits; κ captures the non-linearity of the link function and can be exponential in dimension (e.g., κ = Θ(e^S) for logistic regression)
  - Quick check: For logistic regression with bounded parameter ||θ*|| ≤ S, why does κ scale as e^S, and how does this affect confidence widths?

- **Concept: Binary Tree Mechanism for Continual Release**
  - Why needed: Algorithm 2 uses this to release design matrices V and H_t at every round under joint-DP
  - Quick check: If you have a stream of d×d matrices over T rounds, how many tree nodes does each matrix update affect, and why does this matter for privacy?

## Architecture Onboarding

- **Component map:**
  - Local Randomizer (R₁, R₂): Users encode their data (rewards, outer products) into bit sequences
  - Shuffler (S): Uniformly permutes all messages before forwarding to analyzer
  - Analyzer (A₁, A₂): Aggregates shuffled messages, debiases, outputs private estimates
  - Binary Tree (B_V, B_H): Maintains prefix sums with Gaussian noise at each node for continual release
  - Private Optimizer (PGD): Runs shuffle-private gradient descent for parameter estimation
  - Switching Logic: Two criteria—exploration (Criterion I: uncertainty threshold) and exploitation (Criterion II: determinant doubling)

- **Critical path:**
  1. Warm-up batch (B₁): Build initial V via G-optimal design + shuffled summation → compute θ̂₁ via PGD
  2. Subsequent batches/rounds: Arm scaling (Eq. 11), elimination (UCB/LCB), G-optimal design → update H_k/V → PGD for θ̂_k/θ̂_τ
  3. Privacy accounting: (ε/2, δ/2) for covariance estimation + (ε/2, δ/2) for parameter estimation = (ε, δ) total

- **Design tradeoffs:**
  - Shuffle-DP vs. Joint-DP: Shuffle-DP requires stochastic contexts and batching (less adaptive); Joint-DP allows adversarial contexts but requires per-round binary-tree updates (higher complexity)
  - Batch size vs. privacy noise: Larger batches reduce noise relative to signal but reduce adaptivity; γ and λ (Eqs. 8-9) must balance these
  - G-optimal design vs. distributional optimal design: G-optimal incurs √d factor but is compatible with privacy constraints; distributional optimal design (from [8]) is not easily privatized

- **Failure signatures:**
  - Regret degrades with κ: If arm scaling (Eq. 11-12) is incorrect, κ appears in dominant √T term → check that θ̂₁ is accurate enough for β(x) computation
  - Too many policy switches: If λ_min is too small, switching criterion triggers constantly → verify λ ≥ 20dR log T + σ_noise·(√d + 6√(log(...)))
  - Privacy violation: If count1 or count2 exceed cutoffs, optimizer calls exceed privacy budget → check that switching bounds (Lemma O.4) hold empirically

- **First 3 experiments:**
  1. **Baseline comparison (synthetic probit/logistic, d=3-5, K=20, T=5000):** Replicate Table 2; verify κ-independence by varying S ∈ {2, 2.5, 3} and confirming stable regret across κ values. Compare against GLM-UCB, GLOC, RS-GLinUCB.
  2. **Ablation on privacy parameters:** Fix d=5, T=5000, vary ε ∈ {2, 4, 6, 8}; plot regret vs. ε. Verify that gap to non-private baseline (RS-GLinUCB) scales as ~1/√ε as claimed.
  3. **Switching count validation:** Run Algorithm 2 for T=10000, log the number of Criterion I and II switches. Verify that |To| ≤ 8dR²κγ² log T (empirically) and Criterion II switches ≤ d log²(2 + 2TL²/(λd)).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the privacy-dependent term in joint-DP GLM bandits be tightened from Õ(d^{3/4}√T/√ε) to match the lower bound of Ω(d√T/ε)?
- Basis: Remark 6.3 explicitly identifies this gap
- Why unresolved: The gap stems from analysis techniques in the binary-tree mechanism
- What evidence would resolve it: An algorithm achieving Õ(d√T/ε) regret under joint-DP for GLMs, or a refined lower bound

### Open Question 2
- Question: Can distributional optimal design be adapted to differential privacy constraints to eliminate the √d overhead in shuffle-DP regret?
- Basis: Remark 4.4 states the authors "could not compute [distributional optimal design] under differential privacy constraints"
- Why unresolved: Privacy mechanisms interfere with the optimization required for computing distributional optimal designs
- What evidence would resolve it: A shuffle-DP algorithm achieving Õ(d√T/√ε) regret for stochastic contexts

### Open Question 3
- Question: What are the matching lower bounds for shuffle-DP and joint-DP generalized linear contextual bandits?
- Basis: The Conclusion states "Future work will focus on... establishing matching lower bounds for this privacy setting"
- Why unresolved: The paper provides lower bounds but they may not be tight across all parameter regimes
- What evidence would resolve it: Proofs of matching lower bounds that coincide with upper bounds for both privacy models

### Open Question 4
- Question: Can pure (ε, 0)-differential privacy be achieved for GLM contextual bandits with sublinear regret?
- Basis: The paper addresses only (ε, δ)-approximate DP; pure DP is not discussed
- Why unresolved: The techniques (Gaussian noise, binary-tree mechanisms) inherently require δ > 0
- What evidence would resolve it: An algorithm achieving (ε, 0)-DP with Õ(√T) regret, or a lower bound showing linear regret is unavoidable under pure DP

## Limitations

- The shuffle-DP algorithm requires stochastic contexts, limiting applicability to scenarios where contexts can be collected in batches
- The joint-DP algorithm's regret bound has a privacy-dependent term of Õ(d^{3/4}√T/√ε) that doesn't match the lower bound of Ω(d√T/ε)
- The implementation requires careful calibration of numerous hyperparameters (λ, γ, β, etc.) whose theoretical values may be conservative

## Confidence

- **Shuffle-DP algorithm (Algorithm 1):** High confidence - the mechanism is well-established and the analysis follows standard privacy accounting
- **Joint-DP algorithm (Algorithm 2):** Medium confidence - the binary-tree mechanism and non-monotone switching analysis are novel and more complex
- **Regret bounds:** High confidence - the proofs are detailed and the bounds match known lower bounds up to logarithmic factors
- **Experimental results:** Medium confidence - the experiments validate theoretical claims but are limited to synthetic data

## Next Checks

1. Implement Algorithm 2 with binary-tree mechanism and verify that the running maximum determinant criterion correctly handles non-monotonic design matrices
2. Track count1 and count2 during algorithm execution to ensure they stay below the theoretical thresholds and privacy budget is not violated
3. Verify κ-independence empirically by running experiments with different values of S and confirming that regret scales consistently across different κ values