---
ver: rpa2
title: 'You Only Measure Once: On Designing Single-Shot Quantum Machine Learning Models'
arxiv_id: '2509.20090'
source_url: https://arxiv.org/abs/2509.20090
tags:
- quantum
- yomo
- inference
- shot
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces You Only Measure Once (Yomo), a quantum machine
  learning (QML) framework that achieves accurate inference with dramatically fewer
  measurements, down to the single-shot regime. Yomo replaces Pauli expectation-value
  outputs with a probability aggregation mechanism and introduces loss functions that
  encourage sharp predictions.
---

# You Only Measure Once: On Designing Single-Shot Quantum Machine Learning Models

## Quick Facts
- arXiv ID: 2509.20090
- Source URL: https://arxiv.org/abs/2509.20090
- Reference count: 40
- Single-shot QML inference with probability aggregation; 90.52% MNIST accuracy at 1 shot.

## Executive Summary
This paper introduces You Only Measure Once (Yomo), a quantum machine learning framework that enables accurate inference with dramatically fewer measurements—down to the single-shot regime. Yomo replaces standard Pauli expectation-value outputs with a probability aggregation mechanism and loss functions that encourage sharp predictions. Theoretical analysis shows Yomo avoids shot-scaling limitations inherent to expectation-based models, and experiments on MNIST and CIFAR-10 confirm it consistently outperforms baselines across different shot budgets and under depolarizing noise simulations. Yomo reduces both financial and computational costs of deploying QML and lowers barriers to practical adoption.

## Method Summary
Yomo transforms the output of quantum circuits from Pauli expectation values to aggregated probabilities, enabling single-shot inference. It introduces tailored loss functions that incentivize predictions with high confidence (sharp probability distributions). The framework is designed to sidestep the exponential shot cost required by traditional expectation-value-based QML models, relying on theoretical arguments about shot scalability. Experiments demonstrate that Yomo maintains competitive accuracy with minimal measurements, even under simulated noise, and is robust across multiple datasets.

## Key Results
- Yomo achieves single-shot inference with 90.52% accuracy on MNIST.
- Outperforms baseline QML models across varied shot budgets and under depolarizing noise.
- Demonstrates shot-scaling advantages and reduced computational/ financial costs for QML deployment.

## Why This Works (Mechanism)
Yomo sidesteps shot-scaling limitations by replacing expectation-value outputs with probability aggregation, which requires only a single measurement. The loss functions are designed to favor models that make confident, sharp predictions, which are more robust to measurement noise and variance. By avoiding the need to estimate expectation values (which require many shots), Yomo dramatically reduces the number of measurements required for inference without sacrificing accuracy.

## Foundational Learning

**Quantum Expectation Values**
- Why needed: Basis for traditional QML model outputs; understanding why they require many shots.
- Quick check: Confirm the formula for estimating expectation values and associated shot scaling.

**Probability Aggregation**
- Why needed: Yomo’s core innovation; enables single-shot inference.
- Quick check: Verify that probabilities can be computed from a single measurement outcome.

**Sharpness-Inducing Loss Functions**
- Why needed: Encourages models to make confident predictions, improving robustness to noise.
- Quick check: Ensure loss gradients promote peaked probability distributions.

## Architecture Onboarding

**Component Map**
Quantum Circuit -> Probability Aggregation -> Sharpness-Inducing Loss Function

**Critical Path**
1. Prepare quantum state via parameterized circuit
2. Measure qubits (single shot)
3. Aggregate measurement outcomes into probabilities
4. Apply loss function; backpropagate for training

**Design Tradeoffs**
- Single-shot vs. accuracy: Yomo favors reduced shot count, but may face accuracy limits on complex datasets.
- Noise robustness: Probability aggregation helps, but real hardware noise is not fully characterized.

**Failure Signatures**
- Degraded accuracy on complex datasets due to limited expressive power.
- Overfitting to training data when model becomes too confident.

**3 First Experiments**
1. Train Yomo on MNIST with 1, 10, and 100 shots; compare to expectation-based baselines.
2. Simulate depolarizing noise; assess robustness at different shot counts.
3. Vary model depth; measure impact on single-shot accuracy and sharpness.

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains rely on synthetic noise models, not calibrated hardware errors.
- MNIST accuracy (90.52% at 1 shot) still lags behind classical deep-learning baselines.
- Theoretical arguments about shot-scalability are asymptotic; finite-sample error bounds are not provided.

## Confidence

**High**
- Single-shot inference mechanism works in controlled simulation environments; loss function design is theoretically grounded.

**Medium**
- Performance improvements over baseline QML models hold across simulated shot budgets but may narrow on noisy hardware.

**Low**
- Extrapolation to large-scale, high-dimensional datasets and full physical qubit systems is speculative.

## Next Checks
1. Benchmark Yomo on a physical quantum processor under calibrated noise to confirm robustness outside simulation.
2. Test generalization to datasets with higher complexity (e.g., CIFAR-10 full, ImageNet subsets) to assess scalability.
3. Compare shot-efficiency against adaptive measurement strategies to quantify relative gains in practical settings.