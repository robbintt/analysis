---
ver: rpa2
title: Anchored Langevin Algorithms
arxiv_id: '2509.19455'
source_url: https://arxiv.org/abs/2509.19455
tags:
- langevin
- anchored
- distribution
- algorithms
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces anchored Langevin algorithms to address limitations
  of standard Langevin-based MCMC methods, which struggle with non-differentiable
  log-densities and heavy-tailed distributions. The key idea is to replace the original
  potential with a smooth reference potential and modify the Langevin diffusion through
  multiplicative scaling, allowing gradient-based updates even when the true potential
  is non-differentiable or exhibits sublinear growth.
---

# Anchored Langevin Algorithms

## Quick Facts
- **arXiv ID:** 2509.19455
- **Source URL:** https://arxiv.org/abs/2509.19455
- **Reference count:** 18
- **Primary result:** Anchors replace non-differentiable potentials with smooth surrogates, enabling gradient-based sampling for heavy-tailed and non-smooth distributions

## Executive Summary
Anchored Langevin algorithms address fundamental limitations of standard Langevin-based MCMC methods, which struggle with non-differentiable log-densities and heavy-tailed distributions. The key innovation replaces the original potential with a smooth reference potential and modifies the Langevin diffusion through multiplicative scaling, allowing gradient-based updates even when the true potential is non-differentiable or exhibits sublinear growth. The authors establish non-asymptotic convergence guarantees in the 2-Wasserstein distance to the target distribution and provide an equivalent formulation via a random time change of the Langevin diffusion.

## Method Summary
The anchored Langevin algorithm modifies the standard overdamped Langevin SDE by introducing a reference potential U₀ and state-dependent drift and diffusion coefficients. For a target distribution π(x) ∝ exp(-U(x)), the anchored dynamics use b(x) = -∇U₀(x)·exp(U(x)-U₀(x)) as drift and σ(x) = exp((U(x)-U₀(x))/2) as diffusion. This preserves π as the invariant distribution while enabling gradient-based sampling. For non-smooth potentials, Gaussian smoothing approximates U₀(x) = E[g(x+μξ)] with Monte Carlo gradient estimation. The method accommodates both non-smooth potentials and heavy-tailed distributions through appropriate choices of U₀.

## Key Results
- Establishes non-asymptotic convergence guarantees in 2-Wasserstein distance to target distributions
- Demonstrates effectiveness on Laplace distributions, Bayesian logistic regression with non-smooth regularizers, and heavy-tailed distributions
- Shows anchored Langevin algorithms outperform standard overdamped Langevin algorithms in challenging settings
- Provides explicit bounds on discretization error and parameter requirements for Gaussian smoothing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Replacing non-differentiable potentials with smooth surrogates enables gradient-based sampling while preserving the correct stationary distribution
- Mechanism: The anchored SDE uses ∇U₀(x)·e^{(U−U₀)(x)} as drift and e^{(U−U₀)(x)/2} as diffusion. The multiplicative correction terms exactly compensate for the discrepancy between U and U₀, so π∝e^{−U(x)} remains the invariant distribution
- Core assumption: U₀ uniformly approximates U (i.e., sup|U−U₀|<∞); U₀∈C²; Assumption 1's drift condition holds
- Evidence anchors: [abstract] "The method replaces the original potential with a smooth reference potential and modifies the Langevin diffusion via multiplicative scaling"; [Page 7, Eq. (6)-(7)] Defines b(x) and σ(x) explicitly; Theorem 2 proves π is the unique invariant measure under Assumption 1

### Mechanism 2
- Claim: State-dependent diffusion scaling enables sampling from heavy-tailed distributions where standard Langevin fails
- Mechanism: For heavy-tailed targets with U(x)=o(‖x‖), standard Langevin's drift −∇U(x) grows sublinearly while diffusion remains constant, causing poor tail exploration. The anchored SDE's state-dependent σ(x)∝e^{(U−U₀)/2} adaptively amplifies noise in regions where U−U₀ is large, correcting the exploration imbalance
- Core assumption: The reference U₀ is chosen so that (8) holds: [d−⟨x,∇U₀⟩]e^{(U−U₀)} ≤ −c₀‖x‖²⁺ʳ + c₁ for some c₀,c₁>0, r>−1
- Evidence anchors: [Page 8, Theorem 3] Shows anchored SDE can sample heavy-tailed Gibbs distributions with exponential convergence; Example 1 covers multivariate Student-t; [Page 6, Lines 5-8] "Exponential convergence (4) does not hold for U(x)=‖x‖^γ with γ∈(0,1)... Therefore, it is not expected that one can use SDE (1) to simulate heavy-tailed distribution"

### Mechanism 3
- Claim: Gaussian smoothing of non-smooth components g(x) with Monte Carlo gradient estimation preserves convergence when smoothing parameter μ and sample size N are appropriately chosen
- Mechanism: For U=f+g with smooth f and non-smooth g, define g₀(x)=E_ξ[g(x+μξ)]. The gradient ∇g₀(x)=(1/μ)E[ξ̂g(x+μξ̂)] is estimated via N Monte Carlo samples. The smoothing error is bounded (Lemma 18, 19), and under Assumptions 16-17, the discretized dynamics converge to π with explicit Wasserstein bounds (Theorem 30)
- Core assumption: g is K-Lipschitz and γ-weakly convex (Assumption 16); f is L_f-smooth and m_f-strongly convex (Assumption 17); smoothing parameter μ≤1/(6K√d), sample size N≥(4√2A₁/mμ)⁴
- Evidence anchors: [Page 17-20, Theorem 26, Lemma 27, Theorem 30] Provide explicit bounds on E[‖b̃−b‖²] and W₂(ν̃ₖ,π) in terms of μ, N, η; [Page 21-28, Sections 6.1-6.4] Numerical validation on Laplace distributions, Bayesian logistic regression with non-smooth regularizers, ReLU networks, and heavy-tailed sampling

## Foundational Learning

- **Concept: Langevin dynamics and ULA**
  - Why needed here: The paper modifies the standard overdamped Langevin SDE dX_t = −∇U(X_t)dt + √2 dW_t; understanding ULA's discretization x_{k+1} = x_k − η∇U(x_k) + √(2η)ξ_{k+1} is prerequisite
  - Quick check question: Can you explain why standard ULA fails when ∇U is undefined or when U(x)=o(‖x‖)?

- **Concept: Poincaré inequality and Wasserstein distance**
  - Why needed here: Convergence is analyzed in 2-Wasserstein distance (Theorem 14); χ² convergence (Proposition 7) requires π to satisfy a Poincaré inequality
  - Quick check question: What is the relationship between Poincaré constants and convergence rates in Langevin algorithms?

- **Concept: Gaussian smoothing and Moreau-Yoshida envelope**
  - Why needed here: The paper uses Gaussian smoothing to approximate non-smooth potentials; Section 2 discusses alternative proximal methods based on MYE
  - Quick check question: How does Gaussian smoothing g₀(x)=E[g(x+μξ)] differ from the Moreau-Yoshida envelope U_λ(x)=inf_z{U(z)+(1/2λ)‖x−z‖²}?

## Architecture Onboarding

- **Component map:**
  - Target potential U (non-differentiable or heavy-tailed)
  - Reference potential U₀ (Gaussian-smoothed or analytical)
  - Drift computation: b(x) = −∇U₀(x)·exp(U(x)−U₀(x))
  - Diffusion coefficient: σ(x) = exp((U(x)−U₀(x))/2)
  - Monte Carlo estimator: Approximates U₀ and ∇U₀ using N samples
  - Euler-Maruyama discretization: x_{k+1} = x_k + ηb(x_k) + √(2η)σ(x_k)ξ_{k+1}

- **Critical path:**
  1. Characterize target U: Identify non-smooth components g and smooth components f
  2. Construct U₀: Either g₀(x)=E[g(x+μξ)] with appropriate μ, or choose U₀=log q(x) matching tail structure
  3. Tune parameters: μ (smoothing), N (Monte Carlo samples), η (stepsize) per Corollary 31 bounds
  4. Run discretization: Iterate Eq. (16) or Algorithm 1 until convergence

- **Design tradeoffs:**
  - **Smoothing parameter μ**: Smaller μ reduces bias (Lemma 18) but requires smaller stepsize η≤mμ²/[4e^{6Kμ√d}(4μ²L_f²+8K²d)] and larger N
  - **Monte Carlo samples N**: Larger N reduces variance in gradient estimates but increases per-iteration cost
  - **Reference potential choice**: Gaussian smoothing is general but expensive; analytical U₀ (e.g., β log q(x) for Student-t) is cheaper but requires problem-specific design
  - **Stepsize η**: Must satisfy (24) for non-asymptotic guarantees; larger η speeds mixing but increases discretization error

- **Failure signatures:**
  - **Divergence or slow mixing**: Check if Assumption 1 or Assumption 12 conditions are violated; U₀ may be poorly matched to U
  - **High variance in estimates**: Increase N or reduce μ; check Lipschitz constant K of g
  - **Bias in stationary distribution**: Verify U₀→U uniformly as μ→0; for non-smooth g, ensure smoothing is applied correctly
  - **Heavy-tailed sampling failure**: Standard ULA on U₀ (without anchored correction) will converge to wrong target

- **First 3 experiments:**
  1. **Sanity check on Laplace distribution**: Implement Algorithm 1 with U(x)=√2|x|, U₀ from Gaussian smoothing. Compare W₂ distance to true Laplace vs. baseline ULA on U₀. Verify anchored LD achieves lower asymptotic error (replicate Figure 1)
  2. **Parameter sensitivity study**: On a 2D Laplace target, sweep μ∈{0.01,0.1,0.5}, N∈{10,100,500}, η∈{0.01,0.1}. Measure convergence rate and asymptotic W₂. Confirm Corollary 31's qualitative predictions (smaller μ requires smaller η, larger N)
  3. **Heavy-tailed validation**: Sample from multivariate Student-t (ν=3, d=10) using U₀(x)=β log(1+‖x‖²/ν) per Example 2. Compare to standard ULA and document mixing time improvement. Check that condition d+ν>2+d·κ(Σ) is satisfied for your scale matrix Σ

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are principled methods for automatically selecting the optimal reference potential $U_0$ for a given target distribution?
- Basis in paper: [inferred] The paper demonstrates that appropriate choices of $U_0$ (e.g., $\beta\log q(x)$ for Student-t in Example 1) are crucial, but provides no general framework for selecting $U_0$ beyond specific examples
- Why unresolved: The choice of $U_0$ affects both convergence rates and practical performance, yet the paper only gives ad-hoc constructions for specific distributions
- What evidence would resolve it: An algorithm or theoretical criterion that, given a target potential $U$, produces a reference $U_0$ satisfying Assumption 1 while optimizing convergence speed

### Open Question 2
- Question: Can a Metropolis-adjusted version of anchored Langevin algorithms be developed with improved convergence guarantees?
- Basis in paper: [inferred] The paper develops only unadjusted variants, while noting that standard ULA has Metropolis-adjusted versions with better asymptotic properties
- Why unresolved: Metropolis-Hastings corrections typically require computing acceptance ratios, but the state-dependent diffusion coefficient $\sigma(x)$ in the anchored SDE complicates standard adjustment procedures
- What evidence would resolve it: A Metropolis-adjusted algorithm with non-asymptotic convergence analysis, showing improved bias guarantees compared to the unadjusted version

### Open Question 3
- Question: Can stochastic gradient variants of anchored Langevin algorithms be developed for large-scale applications?
- Basis in paper: [inferred] The paper uses full gradient computations (e.g., in Algorithm 1), which may be prohibitive for large datasets
- Why unresolved: The state-dependent noise structure and the multiplicative scaling in the anchored SDE create additional challenges for stochastic gradient analysis beyond standard ULA
- What evidence would resolve it: A stochastic gradient anchored Langevin algorithm with non-asymptotic bounds depending on mini-batch size and data-dependent quantities

### Open Question 4
- Question: How does the computational overhead of Monte Carlo expectations in Gaussian smoothing (Algorithm 1) scale with dimension, and can this be reduced?
- Basis in paper: [explicit] The paper notes on page 16 that "we will use Monte Carlo simulations to approximate these expectations" and provides bounds depending on $N$ in Theorem 26 and Corollary 31, with complexity $N^{-1/4}$ appearing in the error bounds
- Why unresolved: High-dimensional sampling requires many Monte Carlo samples, and the dimension-dependent constants in bounds (49)-(52) grow with $d$
- What evidence would resolve it: Alternative smoothing approaches or variance reduction techniques that achieve comparable accuracy with fewer samples, or theoretical lower bounds showing this overhead is unavoidable

## Limitations
- The anchored Langevin framework depends critically on the choice of reference potential U₀; poor approximations can cause numerical instability
- Monte Carlo gradient estimation introduces bias and variance that scale unfavorably with dimension d
- Theoretical guarantees assume bounded |U-U₀| and sufficient smoothness of U₀, which may be violated in practice for complex potentials

## Confidence
- **High confidence**: The mechanism by which multiplicative correction terms preserve the target invariant distribution (Mechanism 1)
- **Medium confidence**: The effectiveness of state-dependent diffusion for heavy-tailed sampling (Mechanism 2)
- **Medium confidence**: The Gaussian smoothing approach for non-smooth potentials (Mechanism 3)

## Next Checks
1. **Numerical stability verification**: Implement anchored Langevin for Laplace distribution with varying smoothing parameters μ and monitor the magnitude of exp(U-U₀) terms to identify numerical overflow thresholds
2. **Dimensional scaling study**: Systematically evaluate the W₂ convergence rates of anchored Langevin versus standard ULA as dimension d increases from 2 to 50 for both non-smooth and heavy-tailed targets
3. **Alternative reference potentials**: Compare Gaussian smoothing U₀ against analytical references like log-quadratic functions for Student-t distributions to quantify the tradeoff between computational cost and sampling efficiency