---
ver: rpa2
title: 'Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts'
arxiv_id: '2509.21743'
source_url: https://arxiv.org/abs/2509.21743
tags:
- reasoning
- arxiv
- tokens
- efficient
- thought
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new framework called Retrieval-of-Thought
  (RoT) to improve the efficiency of large reasoning models by reusing prior reasoning
  steps. RoT builds a structured thought graph that stores individual reasoning steps
  as nodes, then uses metadata filtering and reward-guided traversal to dynamically
  assemble problem-specific templates at inference time.
---

# Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts

## Quick Facts
- arXiv ID: 2509.21743
- Source URL: https://arxiv.org/abs/2509.21743
- Reference count: 40
- Large reasoning models can achieve comparable or higher accuracy than baselines while reducing output tokens by up to 40%, inference latency by up to 82%, and cost by 59%

## Executive Summary
This paper introduces Retrieval-of-Thought (RoT), a framework that improves reasoning efficiency in large language models by reusing prior reasoning steps. RoT constructs a structured thought graph where individual reasoning steps are stored as nodes, then uses metadata filtering and reward-guided traversal to dynamically assemble problem-specific templates during inference. The approach addresses the inefficiency of current reasoning models that repeatedly generate lengthy thought processes for similar problems. Experiments on mathematical reasoning benchmarks demonstrate that RoT+TI achieves comparable or superior accuracy to baselines while significantly reducing computational costs and improving reasoning stability.

## Method Summary
RoT builds a thought graph structure where each reasoning step from previous problems becomes a node, creating a reusable knowledge base of reasoning patterns. During inference, the framework uses metadata filtering to identify relevant thought segments based on problem characteristics, then employs reward-guided traversal to navigate through the thought graph and assemble an optimal reasoning template. The template-guided inference (TI) component ensures that assembled thoughts follow coherent reasoning paths while maintaining accuracy. This approach contrasts with traditional chain-of-thought methods that generate reasoning from scratch for each problem, instead leveraging previously successful reasoning patterns to reduce computational overhead.

## Key Results
- RoT+TI achieves comparable or higher accuracy than Chain-of-Thought and retrieval-augmented baselines on AIME and AMC benchmarks
- Reduces output tokens by up to 40% compared to traditional reasoning approaches
- Cuts inference latency by up to 82% and operational cost by 59%
- Decreases path switching by up to 81.8%, indicating more stable reasoning trajectories

## Why This Works (Mechanism)
RoT works by breaking down the reasoning process into discrete, reusable steps that can be stored, retrieved, and reassembled. The thought graph structure captures the intermediate reasoning states that large language models typically regenerate for each problem. By indexing these steps with metadata about problem types and characteristics, RoT can quickly identify relevant reasoning patterns for new problems. The reward-guided traversal then assembles these patterns into coherent reasoning templates that maintain logical flow while avoiding redundant computation. This approach exploits the fact that many reasoning problems share common substructures and solution patterns, making reuse of prior reasoning steps both feasible and beneficial.

## Foundational Learning

**Thought Graph Structure**
- Why needed: Provides organized storage for reusable reasoning steps across problems
- Quick check: Verify that graph nodes correctly capture atomic reasoning steps and maintain logical relationships

**Metadata Filtering**
- Why needed: Enables efficient identification of relevant reasoning patterns based on problem characteristics
- Quick check: Test filtering accuracy across diverse problem types and verify relevance of retrieved thoughts

**Reward-Guided Traversal**
- Why needed: Ensures assembled reasoning templates follow coherent and effective reasoning paths
- Quick check: Validate that traversal produces logically consistent reasoning sequences that lead to correct solutions

## Architecture Onboarding

**Component Map**
Thought Graph -> Metadata Filter -> Reward-Guided Traversal -> Template Assembly -> Inference Engine

**Critical Path**
The critical path involves metadata filtering to identify candidate thoughts, reward-guided traversal to navigate the thought graph and assemble templates, followed by template-guided inference to solve new problems. Performance bottlenecks could occur in graph search complexity or filtering accuracy.

**Design Tradeoffs**
The framework trades storage overhead for computational efficiency, requiring substantial memory to store the thought graph but reducing inference costs. The metadata annotation process introduces human effort but enables more precise retrieval. The reward-guided traversal adds complexity but provides better template quality than simple retrieval.

**Failure Signatures**
Performance degradation occurs when metadata filtering retrieves irrelevant thoughts, when the thought graph lacks appropriate patterns for novel problem types, or when reward-guided traversal produces incoherent reasoning sequences. Sparse thought graphs or poor metadata quality can severely impact effectiveness.

**First 3 Experiments to Run**
1. Benchmark metadata filtering accuracy across different problem categories
2. Measure reasoning accuracy degradation as thought graph size increases
3. Compare inference costs between RoT and baseline approaches on held-out problems

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation is limited to mathematical reasoning benchmarks without testing generalization to other domains like commonsense reasoning or scientific problem-solving
- Token reduction metrics rely on assumed token costs rather than measured implementation costs
- Cost savings calculation assumes uniform token pricing without accounting for potential differences in reasoning step complexity

## Confidence

**Major Claim Clusters:**
- **Efficiency improvements (token reduction, latency, cost)**: Medium confidence - Results are impressive but based on controlled benchmarks without real-world deployment validation
- **Reasoning stability (path switching reduction)**: Medium confidence - Metric is novel but correlation with actual reasoning quality remains unclear
- **Template assembly effectiveness**: Low confidence - The mechanism is described abstractly without ablation studies isolating its contribution from other factors

## Next Checks
1. Conduct cross-domain evaluation testing RoT on non-mathematical reasoning tasks (legal reasoning, scientific problem-solving, or commonsense QA) to assess generalizability
2. Implement a cost analysis using actual API pricing and measured token usage to verify the 59% cost reduction claim
3. Perform ablation studies removing the reward-guided traversal component to quantify its specific contribution to efficiency gains versus the structured thought graph alone