---
ver: rpa2
title: Generating Samples to Probe Trained Models
arxiv_id: '2502.06658'
source_url: https://arxiv.org/abs/2502.06658
tags:
- data
- samples
- distribution
- generated
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel framework for probing trained machine
  learning models by generating synthetic data samples that reveal model behavior
  across various scenarios. The method constructs probing functions that act as loss
  functions on the data space, enabling the generation of samples for specific queries
  such as prediction-risky, parameter-sensitive, or model-contrastive instances.
---

# Generating Samples to Probe Trained Models

## Quick Facts
- arXiv ID: 2502.06658
- Source URL: https://arxiv.org/abs/2502.06658
- Reference count: 40
- Primary result: Novel framework generates synthetic samples to probe ML models, revealing behavior across diverse scenarios including model disagreement, risky predictions, and counterfactual analysis.

## Executive Summary
This paper introduces a framework for probing trained machine learning models by generating synthetic data samples that reveal model behavior across various scenarios. The method constructs probing functions that act as loss functions on the data space, enabling the generation of samples for specific queries such as prediction-risky, parameter-sensitive, or model-contrastive instances. The framework is demonstrated across diverse datasets and tasks, including tabular data classification, regression, and high-dimensional image generation. Key outcomes include the ability to identify model disagreement regions between different architectures, generate uncertain samples near decision boundaries, and explore counterfactual scenarios for fairness analysis.

## Method Summary
The method trains base models (MLP, CNN, Logistic Regression, XGBoost, SVM) on various datasets, then constructs probing functions based on query types. Samples are drawn from a Gibbs distribution using Metropolis Adjusted Langevin Algorithm (MALA), with VAE latent space used for image data. The objective balances model compatibility with exploration through the formulation argmin_p[E_p[G] - τH(p)], yielding p*(x) ∝ exp(-G(x)/τ). Probing functions include prediction-risky (entropy maximization), model-contrasting (disagreement maximization), and counterfactual (target class flipping with regularization).

## Key Results
- Successfully identifies model disagreement regions between CNN and MLP architectures on MNIST, revealing CNN's reliance on color cues
- Generates prediction-risky samples near decision boundaries across multiple datasets, visualizing uncertainty regions
- Creates counterfactual samples that flip model predictions while maintaining data plausibility through VAE constraints
- Scales to high-dimensional image data using pretrained autoencoders, maintaining sample realism

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A semantic query about a model can be converted into a probability distribution over the data space, where high-density regions correspond to data points that answer the query.
- **Mechanism:** The user defines a "probing function" $G(x)$ which assigns a low scalar value to desirable data points (e.g., low loss). This function is treated as an energy potential. By solving the Bayesian Learning Problem (BLP) to minimize $\mathbb{E}[G] - \tau H(p)$, the framework derives a Gibbs-Boltzmann distribution $p^*(x) \propto e^{-G(x)/\tau}$. This density concentrates probability mass on inputs that satisfy the query.
- **Core assumption:** The geometry of the loss landscape $G(x)$ correlates with the semantic concept being probed (e.g., "risky" inputs have specific loss signatures).
- **Evidence anchors:**
  - [abstract]: "...construct a loss function on the data space that balances model compatibility with exploration, then sample from the resulting Gibbs distribution..."
  - [section 2]: "The distribution $p^*(x) \propto e^{-1/\tau G(x)}$ is its global solution, balancing the expectation term’s effect... with the entropy term’s effect."
  - [corpus]: Corpus evidence for this specific probing mechanism is weak; neighbors focus on generative modeling or LLM probing rather than this specific energy-based framework.
- **Break condition:** If $G(x)$ is poorly specified (e.g., flat gradients or local minima disconnecting valid regions), the resulting distribution may fail to capture the intended semantic features.

### Mechanism 2
- **Claim:** Langevin dynamics allows for the efficient discovery of these query-satisfying data points without requiring an explicit analytic form of the distribution.
- **Mechanism:** The framework employs the Metropolis-Adjusted Langevin Algorithm (MALA). This acts as a "noisy gradient descent" where samples are proposed by moving along the gradient $\nabla G(x)$ (to lower energy) plus stochastic noise (to explore). A Metropolis-Hastings correction step ensures the samples converge exactly to the target Gibbs distribution.
- **Core assumption:** The gradient $\nabla G(x)$ is informative and computable (or approximatable) for the model in question.
- **Evidence anchors:**
  - [section 2]: "In this work, we used Metropolis Adjusted Langevin Algorithm (MALA) to sample directly from the Gibbs-Boltzmann distribution... This method is a kind of noisy gradient descent..."
  - [appendix c]: "...simulating the Langevin dynamics, which is a Stochastic Differential Equation (SDE)..."
  - [corpus]: Corpus validation for MALA in this specific context is absent; neighbors discuss other generative architectures like Neural ODEs.
- **Break condition:** If the model is non-differentiable (e.g., tree-based models) and gradient approximation (smoothing) fails, MALA reduces to a random walk, losing efficiency.

### Mechanism 3
- **Claim:** Restricting the sampling process to the latent space of a Variational Autoencoder (VAE) ensures generated samples remain on the "data manifold" (i.e., look realistic).
- **Mechanism:** Instead of sampling in the high-dimensional raw input space $\mathcal{X}$, the method optimizes $G(\phi(z))$ in a lower-dimensional latent space $\mathcal{Z}$. The VAE decoder $\phi$ acts as a constraint, mapping latent vectors back to realistic images. This prevents the optimization from finding adversarial or noisy inputs that satisfy the math but fail visual semantics.
- **Core assumption:** The VAE decoder accurately captures the structure of valid inputs.
- **Evidence anchors:**
  - [section 2]: "Using a pre-trained VAE decoder reflects a plausible image requirement, if imposed."
  - [section 3]: "In case of image data... $\phi$ can be taken as the trained decoder module from a VAE."
  - [corpus]: Neighbors like "On the Edge of Memorization in Diffusion Models" discuss manifold learning but do not explicitly validate this specific VAE-probing coupling.
- **Break condition:** If the VAE decoder has "holes" in its latent space or produces blurry reconstructions, the generated samples may be unrealistic or fail to faithfully represent the model's true input domain.

## Foundational Learning

- **Concept: Gibbs-Boltzmann Distribution**
  - **Why needed here:** This is the mathematical bridge connecting an arbitrary loss function (energy) to a probability distribution. Without this, one cannot frame the probing task as a sampling problem.
  - **Quick check question:** How does the temperature parameter $\tau$ affect the sharpness of the distribution relative to the energy function $G(x)$?

- **Concept: Langevin Dynamics**
  - **Why needed here:** This provides the algorithm for actually drawing samples from the distribution. It connects the theoretical distribution to a practical iterative update rule using gradients.
  - **Quick check question:** Why is the noise term necessary in the Langevin equation if we are trying to minimize a loss?

- **Concept: Bayesian Learning Problem (BLP)**
  - **Why needed here:** The paper frames the search for data as a "dual" to the search for parameters. Understanding this variational perspective (minimizing expected loss plus entropy) explains why exploration is guaranteed.
  - **Quick check question:** In the objective $\mathbb{E}[G] - \tau H(p)$, what is the role of the entropy term $H(p)$?

## Architecture Onboarding

- **Component map:** Trained Model ($f(\theta)$) -> Probing Function ($G(x)$) -> Manifold Constraint (Optional VAE Decoder) -> Sampler (MALA)

- **Critical path:**
  1. Define the query (e.g., "find risky samples")
  2. Construct $G(x)$ (e.g., $-\text{Entropy}(f(x))$)
  3. Initialize $x_0$ (randomly or near an anchor)
  4. Run MALA iterations ($x_{t+1} = x_t - \eta \nabla G + \text{noise}$; accept/reject)

- **Design tradeoffs:**
  - **Temperature $\tau$:** High $\tau$ increases diversity (exploration) but lowers specificity (exploitation); low $\tau$ finds local minima of $G$ aggressively
  - **Smoothing for Trees:** For non-differentiable models (RF, XGBoost), one must approximate gradients via smoothing, trading off computational speed for gradient precision

- **Failure signatures:**
  - **Mode Collapse:** Samples converge to a single point (likely $\tau$ too low or step size too large)
  - **Unrealistic Artifacts:** Valid math solutions that look like static/noise (indicates missing or poor VAE constraint)
  - **Random Walk:** Gradients are zero or uninformative (common in tree ensembles without smoothing)

- **First 3 experiments:**
  1. **Linear Regression Sanity Check:** Verify the analytic solution for $p^*(x)$ matches the sampled distribution using a simple linear model on synthetic data (See Appendix A)
  2. **Visualizing Boundaries:** Train an SVM on the "two circles" dataset and generate "prediction-risky" samples to visualize the decision boundary ring (See Figure 2b)
  3. **MNIST Contrast:** Train a CNN and an MLP on digits. Generate samples that maximize disagreement between them to see where their inductive biases diverge (See Figure 4)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can implicit constraints among features (e.g., monotonic relationships) be incorporated into the probing framework to ensure generated samples remain realistic and interpretable?
- **Basis in paper:** [explicit] Conclusion states: "Incorporating implicit constraints among features (e.g., monotonic relationships) could enable the generation of samples that accurately represent the dataset and enhance their interpretability and reliability."
- **Why unresolved:** Current formulation uses regularization terms and VAE latent space constraints, but does not explicitly encode domain-specific feature relationships that preserve semantic validity of generated samples.
- **What evidence would resolve it:** Demonstration of constrained sampling on datasets with known monotonic features (e.g., age-income relationships), showing generated samples satisfy constraints while still probing model behavior effectively.

### Open Question 2
- **Question:** What principled methods exist for selecting the temperature parameter τ across different probing scenarios and model types?
- **Basis in paper:** [inferred] The temperature τ controls the exploration-exploitation trade-off in the Gibbs distribution, but the paper only notes it "determines the balance" without providing selection criteria beyond empirical tuning.
- **Why unresolved:** Different probing scenarios (model-contrasting vs. prediction-risky vs. parameter-sensitive) may require different τ values, and the paper provides no systematic guidance for selection.
- **What evidence would resolve it:** Systematic study of how generated sample quality varies with τ across scenarios, potentially yielding automated selection heuristics or validation metrics.

### Open Question 3
- **Question:** How does the smoothing parameter σ affect sample quality and convergence when probing tree-based models with approximate gradients?
- **Basis in paper:** [inferred] Section C.2 proposes smoothing G_s^(m) for tree-based models with locally flat loss surfaces, but the choice of σ remains ad hoc and its impact on sample quality is uncharacterized.
- **Why unresolved:** Larger σ provides "wider horizon" for proposals but may blur decision boundaries; smaller σ reduces proposal effectiveness. The trade-off is acknowledged but not analyzed.
- **What evidence would resolve it:** Ablation study varying σ on tree-based model experiments, measuring convergence speed, acceptance rates, and semantic validity of generated samples.

### Open Question 4
- **Question:** How do domain experts evaluate the usefulness and actionability of generated probing samples in real-world applications?
- **Basis in paper:** [explicit] Conclusion states: "Applying our framework in various application areas with domain experts could also illuminate different usability aspects."
- **Why unresolved:** The paper demonstrates technical feasibility on benchmark datasets but does not include domain expert evaluation of whether generated samples provide actionable insights (e.g., in credit risk or healthcare settings).
- **What evidence would resolve it:** User study with domain experts assessing generated samples for interpretability, actionability, and alignment with domain knowledge in their respective fields.

## Limitations

- **Gradient dependency:** Framework requires smooth gradient information, limiting applicability to non-differentiable models without approximation
- **Temperature sensitivity:** Critical hyperparameter τ lacks principled selection criteria and significantly impacts sample quality
- **VAE constraint reliability:** Generated sample realism depends on VAE decoder quality and may fail for complex data distributions
- **Qualitative validation:** Limited quantitative metrics for assessing probing effectiveness and sample quality

## Confidence

- **High Confidence:** The core mathematical framework linking probing functions to Gibbs distributions is well-established and correctly derived
- **Medium Confidence:** MALA sampling implementation and convergence properties for this specific application
- **Medium Confidence:** VAE manifold constraint effectiveness for ensuring realistic samples
- **Low Confidence:** Quantitative assessment of probing quality and generalization to diverse model architectures

## Next Checks

1. **Quantitative Probing Metrics:** Implement KL divergence or Wasserstein distance measures to compare generated samples against validation sets for specific probing objectives

2. **Gradient Smoothing Sensitivity:** Systematically vary the smoothing parameter σ for tree-based models and measure impact on sample quality and computational efficiency

3. **Temperature Sweep Analysis:** Conduct ablation studies across temperature values to identify optimal exploration-exploitation tradeoff for different probing functions