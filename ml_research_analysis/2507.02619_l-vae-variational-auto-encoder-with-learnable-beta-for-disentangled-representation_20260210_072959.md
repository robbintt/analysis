---
ver: rpa2
title: 'L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation'
arxiv_id: '2507.02619'
source_url: https://arxiv.org/abs/2507.02619
tags:
- loss
- l-vae
- disentanglement
- learning
- reconstruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Learnable VAE (L-VAE), which learns the\
  \ hyperparameter \u03B2 of \u03B2-VAE automatically during training. The proposed\
  \ method dynamically adjusts the weights of the reconstruction loss and KL divergence\
  \ terms in the loss function using a multi-task learning approach."
---

# L-VAE: Variational Auto-Encoder with Learnable Beta for Disentangled Representation

## Quick Facts
- arXiv ID: 2507.02619
- Source URL: https://arxiv.org/abs/2507.02619
- Authors: Hazal Mogultay Ozcan; Sinan Kalkan; Fatos T. Yarman-Vural
- Reference count: 40
- Primary result: L-VAE learns β automatically during training, outperforming or matching state-of-the-art disentanglement methods without manual hyperparameter tuning

## Executive Summary
This paper introduces Learnable VAE (L-VAE), a method that automatically learns the hyperparameter β of β-VAE during training using a multi-task learning approach. The proposed method dynamically adjusts the weights of reconstruction loss and KL divergence terms in the loss function, addressing the challenge of manually tuning β which requires extensive hyperparameter search and may lead to suboptimal disentanglement or reconstruction quality. L-VAE demonstrates consistent performance across multiple datasets including dSprites, MPI3D, Falcor3D, Isaac3D, and CelebA, providing a simple and efficient solution for learning disentangled representations without manual hyperparameter tuning.

## Method Summary
L-VAE modifies the standard β-VAE architecture by introducing a learnable β parameter that is updated during training through a multi-task learning framework. Instead of fixing β as a hyperparameter, L-VAE treats it as a trainable variable that dynamically balances the reconstruction loss and KL divergence terms in the VAE objective function. The method employs a separate learning mechanism that adjusts β based on the current state of the encoder and decoder, allowing the model to adapt the disentanglement-reconstruction trade-off throughout training. This approach eliminates the need for extensive hyperparameter search while maintaining or improving disentanglement quality compared to fixed-β methods.

## Key Results
- L-VAE consistently outperforms or matches state-of-the-art disentanglement methods across dSprites, MPI3D, Falcor3D, and Isaac3D datasets
- The learned β values are consistent with empirical findings that β < 1 can sometimes yield better disentanglement
- Qualitative experiments on CelebA confirm successful disentanglement of facial attributes
- The method provides a simple solution for learning disentangled representations without manual hyperparameter tuning

## Why This Works (Mechanism)
L-VAE works by treating the β parameter as a learnable variable rather than a fixed hyperparameter. During training, the model simultaneously learns the encoder, decoder, and β parameter through a multi-task learning approach. The β parameter controls the trade-off between reconstruction fidelity and latent space regularization, and by making it adaptive, L-VAE can find optimal values for different data distributions and training stages. This dynamic adjustment allows the model to start with β values that prioritize reconstruction and gradually shift toward stronger regularization as the latent representation becomes more structured, leading to better disentanglement without manual intervention.

## Foundational Learning

Variational Autoencoders (VAEs): Generative models that learn latent representations by maximizing the evidence lower bound (ELBO), which consists of reconstruction loss and KL divergence terms.

β-VAE: A variant of VAE that introduces a hyperparameter β to control the trade-off between reconstruction quality and latent space regularization, with β > 1 typically encouraging stronger disentanglement.

Disentanglement: The property where each latent dimension corresponds to a single, interpretable factor of variation in the data, making the representation more semantically meaningful and controllable.

Multi-task learning: A training approach where multiple objectives are optimized simultaneously, allowing the model to learn shared representations while optimizing different task-specific parameters.

Why needed: Understanding these concepts is essential for grasping how L-VAE improves upon traditional VAEs by making β adaptive rather than fixed, and how this impacts the quality of learned representations.

Quick check: Verify understanding by explaining how changing β affects the balance between reconstruction accuracy and latent space structure in standard β-VAEs.

## Architecture Onboarding

Component map: Input data -> Encoder -> Latent representation (with learnable β) -> Decoder -> Reconstructed output, with separate optimization paths for β and model parameters

Critical path: The forward pass through encoder-decoder with dynamic β weighting, and the backward pass that updates both model parameters and β simultaneously

Design tradeoffs: Learnable β eliminates manual tuning but adds complexity to training; dynamic adjustment may improve final performance but could introduce instability during early training phases

Failure signatures: Poor disentanglement may occur if β converges to extreme values (near 0 or very large); training instability may arise if β updates are too aggressive

First experiments: 1) Test L-VAE on simple dSprites dataset to verify basic functionality, 2) Compare learned β values across different datasets to check consistency, 3) Perform ablation study with fixed β values to quantify improvement from learnability

## Open Questions the Paper Calls Out
None

## Limitations
- Empirical validation is primarily benchmark-based with limited ablation studies on architectural sensitivity
- Results rely on standard disentanglement metrics which have known limitations in fully capturing true disentanglement quality
- Computational overhead introduced by learnable β mechanism during training is not addressed
- Limited evaluation on complex real-world datasets beyond controlled benchmark environments

## Confidence

Core claim that L-VAE effectively learns β without manual tuning: High
- Supported by quantitative results across multiple datasets
- Qualitative visualizations demonstrate successful disentanglement

Claim that learned β values align with empirical findings (β < 1 can yield better disentanglement): Medium
- Observation is presented but not deeply analyzed
- Limited discussion of why this pattern emerges

Generalizability to complex real-world datasets: Low
- Current evaluation focuses on relatively controlled benchmark environments
- Performance on more diverse, real-world data remains untested

## Next Checks

1. Conduct extensive ablation studies varying network architectures, latent dimensions, and dataset complexities to test the robustness of learned β values

2. Evaluate L-VAE on more diverse and complex real-world datasets (e.g., ImageNet, 3D Shapes) to assess generalizability beyond controlled benchmarks

3. Compare the computational efficiency and convergence behavior of L-VAE against fixed-β baselines to quantify any trade-offs introduced by the learnable mechanism