---
ver: rpa2
title: Controllable Concept Bottleneck Models
arxiv_id: '2601.00451'
source_url: https://arxiv.org/abs/2601.00451
tags:
- concept
- dadd
- data
- predictor
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Controllable Concept Bottleneck Models (CCBMs)\
  \ to address the static nature of existing Concept Bottleneck Models (CBMs). CCBMs\
  \ enable efficient, post-hoc editing across three granularities\u2014concept-label-level,\
  \ concept-level, and data-level\u2014using influence functions and Kronecker-Factored\
  \ Approximate Curvature (EK-FAC) acceleration."
---

# Controllable Concept Bottleneck Models

## Quick Facts
- **arXiv ID:** 2601.00451
- **Source URL:** https://arxiv.org/abs/2601.00451
- **Reference count:** 40
- **Primary result:** CCBMs enable efficient, post-hoc editing of CBMs without retraining, achieving near-retraining performance with >100x speedup.

## Executive Summary
This paper introduces Controllable Concept Bottleneck Models (CCBMs) to address the static nature of existing Concept Bottleneck Models (CBMs). CCBMs enable efficient, post-hoc editing across three granularities—concept-label-level, concept-level, and data-level—using influence functions and Kronecker-Factored Approximate Curvature (EK-FAC) acceleration. The method supports both data unlearning and incremental learning, eliminating the need for costly full retraining. Experiments on OAI, CUB, CelebA, and Derm7pt datasets show that CCBMs achieve near-retraining performance while reducing update times by over 100×. Theoretical bounds and privacy analysis confirm the method's accuracy and effectiveness in erasing data influence. CCBMs thus provide a scalable, interpretable, and sustainable framework for dynamic AI model maintenance.

## Method Summary
CCBMs extend standard CBMs by enabling post-hoc editing without retraining. The framework uses influence functions to compute closed-form parameter updates for the concept predictor and label predictor separately. EK-FAC accelerates the Hessian inversion for high-dimensional concept predictors. The method supports three editing granularities: concept-label-level (flipping annotations), concept-level (adding/removing concepts), and data-level (unlearning/incremental learning). Experiments validate the approach on four datasets, showing near-retraining performance with significant speedups.

## Key Results
- CCBMs achieve near-retraining F1 scores (within 0.5%) while reducing update times by over 100×.
- The method successfully handles concept-label flips, concept removals, and data unlearning with minimal performance degradation.
- Privacy analysis confirms effective data removal, with reduced membership inference attack (RMIA) scores for removed data.

## Why This Works (Mechanism)

### Mechanism 1: Closed-Form Parameter Update via Influence Functions
The method leverages influence functions to estimate parameter changes caused by up-weighting or down-weighting specific data points or concepts. It computes the gradient of the loss with respect to the edit and scales it by the inverse Hessian matrix to find the nearest optimal point. This approximation is valid under twice-differentiable, locally convex loss functions.

### Mechanism 2: Sequential Two-Stage Decoupling
CCBMs treat the CBM as a two-stage pipeline. First, it edits the concept predictor to correct concept annotations or remove concepts. Second, it estimates the retrained label predictor by calculating the "concept drift"—the difference in gradients caused by feeding the new concept predictions into the label predictor versus the old ones.

### Mechanism 3: EK-FAC for Scalable Hessian Approximation
The computational cost of inverting the Hessian for high-dimensional concept predictors is reduced by approximating it as a block-diagonal Kronecker-factored matrix. This allows efficient computation in eigen-space with a damping term to ensure positive definiteness.

## Foundational Learning

- **Concept: Concept Bottleneck Models (CBMs)**
  - **Why needed here:** CCBMs are a modification of standard CBMs. Understanding the explicit decoupling into "Input → Concept" and "Concept → Label" is crucial to see why a two-stage editing strategy is necessary.
  - **Quick check:** Can you explain why changing a "concept" annotation in the training set requires updating both the concept predictor (to map inputs correctly) and the label predictor (to understand the new concept distribution)?

- **Concept: Influence Functions**
  - **Why needed here:** This is the mathematical engine of the paper. Understanding the derivation of parameter changes from the gradient and Hessian is crucial for interpreting the "closed-form" update equations.
  - **Quick check:** If we up-weight the loss of a specific data point by ε, does the influence function tell us the direction to move parameters to minimize that point's error, or the final optimal parameters? (Answer: It approximates the direction/magnitude of change).

- **Concept: Machine Unlearning (Privacy)**
  - **Why needed here:** Data-level removal (unlearning) is a key application. Understanding the goal—making the model behave as if it never saw the data—is necessary to evaluate the privacy claims (RMIA scores).
  - **Quick check:** In the context of unlearning, what does it mean for the "membership inference attack" (RMIA) score to decrease for a removed sample?

## Architecture Onboarding

- **Component map:**
  - Concept Predictor (g): ResNet-18 backbone mapping image x to concept vector c
  - Label Predictor (f): Single linear layer mapping concept vector c to class label y
  - EK-FAC Cache: Pre-computed eigenvectors and eigenvalues for the concept predictor's Fisher matrix
  - Edit Set (S_e, M, G): Indices identifying specific data points, concepts, or concept-labels to modify

- **Critical path:**
  1. Initialization: Train standard CBM and compute/stash the EK-FAC factors for the concept predictor
  2. Edit Identification: Identify the target (e.g., flip concept label c_w^r)
  3. Concept Update: Compute the gradient of the edited loss and apply the EK-FAC inverse to update g
  4. Label Update: Compute the "drift" gradient and update f using the inverse Hessian

- **Design tradeoffs:**
  - Exactness vs. Speed: CCBM is an approximation; Retraining is exact but slow (100x slower)
  - Concept Fidelity: Using linear f aids interpretability and editability but may lower baseline performance

- **Failure signatures:**
  - Error Accumulation: Sequential editing may cause the model to drift away from the retraining ground truth
  - Privacy Leakage: If the unlearning term A_unlearn is insufficient, removed members may still be distinguishable via RMIA
  - Dimension Mismatch: In concept removal, failing to properly map dimensions will cause shape errors

- **First 3 experiments:**
  1. Concept-Label Flip: Randomly select 3% of data, flip a concept label, run CCBM Algorithm 1, and compare F1 score against retrained model
  2. Concept Ablation (Interpretability): Remove top-10 "most influential" concepts and verify significant performance drop
  3. Privacy Validation (Unlearning): Remove user data, then run Membership Inference Attack (RMIA) to confirm statistical indistinguishability

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the computational overhead of Hessian inversion be optimized for extremely large-scale foundation models (e.g., billions of parameters) where EK-FAC may be insufficient?
- **Basis in paper:** Section 17.1 states that "For extremely large-scale foundation models with billions of parameters, further optimization or sparse approximations may be necessary."
- **Why unresolved:** While EK-FAC accelerates the process, the memory and computation still scale with parameter dimensions, making real-time updates potentially infeasible for massive architectures.
- **What evidence would resolve it:** A demonstration of CCBM applied to a Large Language Model (>7B parameters) using a new sparse approximation method that maintains F1 fidelity without memory overflow.

### Open Question 2
- **Question:** Does the dimensional mapping strategy for concept removal generalize effectively to concept insertion (dimensional expansion) without destabilizing the existing concept space?
- **Basis in paper:** Section 4.2 notes, "For convenience, in this paper, we only consider concept removal; our method can directly extend to concept insertion."
- **Why unresolved:** The paper provides no empirical validation or algorithmic details for insertion, and adding dimensions may introduce optimization challenges not present in removal.
- **What evidence would resolve it:** Experimental results comparing CCBM-based concept insertion against full retraining on a dataset requiring evolving ontologies (e.g., medical taxonomy updates).

### Open Question 3
- **Question:** What are the theoretical and empirical divergence bounds between CCBM and retraining under aggressive, non-convex sequential editing?
- **Basis in paper:** Section 17.1 acknowledges the "approximation error in non-convex settings," noting that large magnitude edits might deviate from the exact solution, despite stability in 10-round tests.
- **Why unresolved:** The paper empirically validates stability for up to 10 rounds but does not characterize the "breaking point" where the first-order approximation fails in highly non-convex regions.
- **What evidence would resolve it:** Theoretical error bounds defined by edit magnitude or empirical analysis of model drift over 50+ sequential editing rounds on a non-convex dataset.

## Limitations
- The method's accuracy depends on the validity of the influence function approximation, which may break down for large-scale edits or highly non-convex loss landscapes.
- Sequential editing may accumulate approximation errors over time, potentially causing model drift from the retrained ground truth.
- The exact hyperparameter values (damping parameters, learning rates, split ratios) are not fully specified, which could impact reproducibility.

## Confidence

- **High Confidence:** The core mathematical framework (influence functions, two-stage editing, EK-FAC acceleration) is well-defined and theoretically grounded. The 100x speedup over retraining is a robust claim.
- **Medium Confidence:** The performance claims (near-retraining F1 scores) are supported by experiments but may vary with dataset complexity and edit magnitude.
- **Low Confidence:** The long-term stability of sequential edits and the method's robustness to highly non-linear label predictors are less certain.

## Next Checks

1. **Hyperparameter Sensitivity:** Systematically vary the damping parameter λ in EK-FAC and learning rates to determine their impact on update stability and final performance.
2. **Edit Magnitude Scaling:** Test the method with progressively larger edit sets (e.g., 5%, 10%, 20% of data) to identify the threshold where influence function approximation breaks down.
3. **Label Predictor Complexity:** Replace the linear label predictor with a small MLP and evaluate if the closed-form updates remain efficient and accurate, or if back-propagation through the unrolled graph becomes necessary.