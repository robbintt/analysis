---
ver: rpa2
title: Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource
  Languages
arxiv_id: '2602.01162'
source_url: https://arxiv.org/abs/2602.01162
tags:
- languages
- typological
- language
- divergence
- sinhala
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses systematic translation errors in LLMs when
  translating into low-resource, typologically divergent languages by proposing a
  framework that leverages linguistic typology for candidate reranking without parallel
  training data. The framework represents languages through structured profiles across
  16 typological dimensions, calculates divergence scores, and applies a dual-layer
  evaluation combining semantic constraints and typological compliance scoring.
---

# Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages

## Quick Facts
- arXiv ID: 2602.01162
- Source URL: https://arxiv.org/abs/2602.01162
- Reference count: 23
- LLM translation errors in low-resource languages are reduced by leveraging typological profiles for candidate reranking without parallel data

## Executive Summary
This study addresses systematic translation errors in large language models when translating into low-resource languages with divergent typologies from English. The proposed framework leverages linguistic typology to guide candidate reranking without requiring parallel training data. By representing languages through structured profiles across 16 typological dimensions and calculating divergence scores, the system identifies and corrects structural mismatches through a dual-layer evaluation combining semantic constraints and typological compliance scoring. Experimental results across nine language pairs demonstrate strong correlation between intervention rates and typological distance from English, with intervention precision ranging from 28.15% to 86.26% depending on language type.

## Method Summary
The framework operates by first creating typological profiles for source and target languages across 16 dimensions including word order, case marking, and verb agreement. These profiles are used to calculate a language divergence score that quantifies structural differences. During translation, the system generates multiple candidate translations using an LLM, then applies a dual-layer evaluation: first filtering candidates that violate semantic constraints, then scoring remaining candidates based on their compliance with the target language's typological profile. The best-scoring candidate is selected as the final translation. This approach requires no parallel corpora, making it particularly suitable for low-resource language pairs where such data is unavailable.

## Key Results
- Strong correlation (r=0.87) between intervention rates and typological distance from English across nine language pairs
- Intervention precision ranges from 28.15% (Hindi) to 86.26% (Marathi) depending on language type
- Systematic relationship between typological divergence, intervention rates, and UMF compliance scores
- Highest gains observed in Marathi (63.6% intervention rate) and Nepali (43.7% intervention rate)

## Why This Works (Mechanism)
The framework succeeds by explicitly modeling the structural differences between source and target languages through typological profiles, rather than relying solely on statistical patterns from training data. By quantifying these differences as divergence scores and using them to guide candidate selection, the system can identify when an LLM's default translation pattern (often biased toward English-like structures) needs correction. The dual-layer evaluation ensures both semantic validity and typological appropriateness, addressing the specific challenge that LLMs often struggle with languages that have fundamentally different grammatical structures from English.

## Foundational Learning
**Typological Dimensions**: Why needed - To quantify structural differences between languages; Quick check - Verify 16 dimensions cover major typological features like word order, case, and agreement
**Language Divergence Score**: Why needed - To predict which language pairs will need intervention; Quick check - Confirm correlation with observed error rates
**Dual-Layer Evaluation**: Why needed - To ensure both semantic and structural correctness; Quick check - Test filtering effectiveness on semantically invalid candidates
**Zero-Shot Evaluation**: Why needed - To work without parallel corpora; Quick check - Validate UMF metric captures semantic errors without references
**UMF Scoring**: Why needed - To measure semantic equivalence without references; Quick check - Compare UMF scores with human judgments on sample translations

## Architecture Onboarding

**Component Map**: Source Text -> LLM Beam Generation -> Semantic Filter -> Typological Compliance Scorer -> Best Candidate Selection -> Final Translation

**Critical Path**: The evaluation pipeline is critical: generating multiple candidates, applying semantic constraints to filter invalid options, then scoring remaining candidates based on typological compliance. The typological compliance scoring is the key differentiator from standard reranking approaches.

**Design Tradeoffs**: Zero-shot evaluation enables low-resource application but sacrifices direct quality measurement against references. Static typological profiles provide consistency but may miss language variation. Post-generation reranking is simpler than guided decoding but cannot generate novel structures.

**Failure Signatures**: High intervention rates with low precision indicate over-correction or inappropriate stylistic changes. Low intervention rates with high error rates suggest insufficient sensitivity to typological differences. Poor performance on morphologically rich languages indicates inadequate handling of feature interactions.

**3 First Experiments**:
1. Validate typological profile accuracy by comparing predicted divergence scores with actual translation error patterns
2. Test intervention precision by having linguists verify whether corrections are linguistically necessary vs stylistic
3. Measure correlation between UMF scores and human judgments of translation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does integrating typological constraints earlier in the generation process (e.g., guided decoding) yield better structural compliance than post-hoc candidate reranking?
- Basis in paper: [explicit] The authors state in Section 6.5 that the study is limited to "post-generation reranking" and propose exploring whether "applying guidance before or during generation reduces the need for aggressive reranking."
- Why unresolved: The current black-box reranking approach is limited to selecting from existing candidates; it cannot generate novel structures that were absent from the initial beam, potentially capping the maximum achievable structural correctness.
- What evidence would resolve it: A controlled comparison evaluating UMF applied during generation (via constrained decoding) versus the current reranking implementation on the same set of typologically divergent language pairs.

### Open Question 2
- Question: How can the framework distinguish between mandatory structural corrections and optional stylistic preferences to prevent over-normalization?
- Basis in paper: [explicit] Section 6.3 notes that "Several observed improvements correspond to stylistic or register-level preferences rather than clear linguistic corrections," complicating claims of structural improvement.
- Why unresolved: The current scoring mechanism may assign high scores to candidates that are merely formal or idiomatic rather than grammatically obligatory, potentially leading to unnecessary interventions that alter the register inappropriately.
- What evidence would resolve it: The development and validation of a tiered evaluation protocol that explicitly separates "grammatical obligation" from "stylistic optimization" scores for intervention events.

### Open Question 3
- Question: Can modeling hierarchical dependencies between features (e.g., case-verb agreement interactions) improve the low Gain-Risk ratios observed in morphologically dense languages?
- Basis in paper: [explicit] Section 6.1 argues that current profiles lack "interactional constraints" and "hierarchical relationships," which causes the "sensitivity without sufficient resolution" observed in languages like Sinhala and Tamil (Section 5.4).
- Why unresolved: The framework currently treats typological dimensions largely as independent signals; however, in agglutinative languages, features like case marking and verb agreement often interact, meaning errors in one may depend on the other.
- What evidence would resolve it: An ablation study in morphologically rich languages comparing the current flat feature scoring against a dependency-aware model to measure changes in Intervention Precision.

## Limitations
- Framework effectiveness for Indo-Aryan languages may not generalize to other language families or typological systems
- Zero-shot evaluation without parallel corpora limits ability to measure absolute translation quality improvements
- Static typological profiles may not capture language variation, dialectal differences, or evolving linguistic features

## Confidence
*High confidence*: The methodological framework for typological profiling and divergence calculation is well-grounded in established linguistic theory. The correlation between intervention rates and typological distance is statistically robust across the nine language pairs tested.

*Medium confidence*: The effectiveness of the dual-layer evaluation system (semantic constraints + typological compliance scoring) shows consistent patterns but may be sensitive to parameter tuning and the specific construction of candidate sets. The generalizability of findings to other low-resource language pairs remains to be validated.

*Low confidence*: The absolute quality of translations cannot be fully assessed without parallel reference data, making it difficult to quantify the actual impact on end-user translation quality. The relationship between typological distance and translation difficulty may be more complex than the linear correlations observed.

## Next Checks
1. **Cross-linguistic validation**: Test the framework on additional low-resource languages from different families (e.g., Turkic, Dravidian, or Niger-Congo) to assess generalizability beyond Indo-Aryan languages and validate the typological distance-error relationship across diverse linguistic typologies.

2. **Dynamic typological profiling**: Implement a system for updating typological profiles based on translation outputs and error patterns to capture language variation and evolving linguistic features, rather than relying solely on static database entries.

3. **Human evaluation correlation**: Conduct comprehensive human evaluations comparing LLM translations with and without the proposed reranking framework, correlating human judgments with UMF scores and intervention rates to validate the metric's effectiveness in capturing translation quality.