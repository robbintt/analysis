---
ver: rpa2
title: AI Based Font Pair Suggestion Modelling For Graphic Design
arxiv_id: '2501.10969'
source_url: https://arxiv.org/abs/2501.10969
tags:
- font
- fonts
- category
- design
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of recommending contextually
  relevant and novel font pairs (heading and subheading) for AI-generated designs
  in Microsoft Designer, particularly when scaling to over 3000 fonts and diverse
  user intents. The proposed method involves creating font visual embeddings using
  a Vision Transformer (ViT) model, developing a font stroke width algorithm, establishing
  a font category-to-font mapping dataset, generating LLM-based category utilization
  descriptions, and employing a lightweight, low-latency Mini LM V2 model for recommending
  font pairs.
---

# AI Based Font Pair Suggestion Modelling For Graphic Design

## Quick Facts
- arXiv ID: 2501.10969
- Source URL: https://arxiv.org/abs/2501.10969
- Reference count: 12
- Key outcome: Proposed model achieves 3.78/5 relevance score and 1.5% kept rate improvement over rule-based system in Microsoft Designer

## Executive Summary
This paper addresses the challenge of recommending contextually relevant font pairs (heading and subheading) for AI-generated designs in Microsoft Designer, particularly when scaling to over 3000 fonts and diverse user intents. The proposed method combines semantic category retrieval using a lightweight language model with visual embedding similarity computed via a Vision Transformer to generate aesthetically compatible font pairs. A weighted scoring mechanism, nearest neighbor approach, and stratified sampling are used to rank font pairs and introduce novelty while maintaining relevance.

## Method Summary
The method involves generating LLM-based category descriptions, embedding them using MiniLM-L6-v2, and retrieving top categories via KNN for user prompts. Visual embeddings are created using ViT-Large on rendered font mnemonic images, while a custom stroke width algorithm ensures subheading strokes are thinner than headings. Font pairs are ranked using category overlap and selected via stratified sampling to balance relevance and novelty. The system operates under strict latency constraints (<100ms) for real-time deployment.

## Key Results
- MiniLM-L6-v2 achieved a subjective relevance score of 3.78/5 from internal judges on 141 custom prompts
- A/B test showed a 1.5% increase in kept rate compared to the rule-based system
- The model is currently deployed in the Design Creator mini app of Microsoft Designer

## Why This Works (Mechanism)

### Mechanism 1
Semantic alignment between user intent and font categories via shared embedding space enables contextual font retrieval at scale. User prompts and expert-defined font category descriptions are both encoded into the same MiniLM-L6-v2 embedding space. Cosine similarity via KNN retrieves the top 3 matching categories, converting natural language intent into typographic semantic clusters.

### Mechanism 2
Visual embedding similarity with a balanced-contrast distance function produces aesthetically compatible heading/subheading font pairs. Vision Transformer (ViT-Large) generates visual embeddings from rendered mnemonic images for each font. A custom distance function balances similarity and contrast between heading and subheading candidates, while a stroke width algorithm ensures subheading strokes are thinner than heading strokes.

### Mechanism 3
Stratified sampling across category overlaps introduces controlled novelty while maintaining relevance. Fonts are ranked by category overlap (fonts tagged with multiple retrieved categories rank higher). Stratified sampling then draws candidates from each category stratum, preventing dominance by any single font family and ensuring diverse outputs across repeated requests.

## Foundational Learning

- **Vision Transformers (ViT) for visual embeddings**
  - Why needed here: Converts rendered font images into dense vector representations capturing visual style attributes for similarity computation.
  - Quick check question: Can you explain why ViT processes images as sequences of patches rather than using convolutional feature hierarchies?

- **Sentence embeddings and cosine similarity retrieval**
  - Why needed here: Enables mapping user prompts to font category descriptions in a shared latent space for semantic matching.
  - Quick check question: Given two sentence embeddings, how would you compute their cosine similarity, and what does a value of 0.85 vs. 0.45 imply?

- **Knowledge distillation and model compression**
  - Why needed here: MiniLM-L6-v2 was chosen over larger models to achieve sub-100ms latency for real-time recommendations.
  - Quick check question: Why does a 6-layer distilled model trade off some accuracy for significant latency gains compared to a 12-layer or 109M parameter model?

## Architecture Onboarding

- **Component map:** Category Embedding Store -> Font Visual Embedding Store -> Stroke Width Index -> Runtime Pipeline
- **Critical path:** User prompt embedding -> category retrieval (KNN) -> heading font ranking -> subheading pairing. Latency budget: <100ms total; KNN and embedding inference dominate.
- **Design tradeoffs:** MiniLM-L6-v2 (3.78/5 subjective score, 16M params) vs. e5-base-v2 (3.80/5, 109M params) vs. GPT-3.5 (4.51/5, 175B params, ~2s latency). Chose MiniLM for latency-relevance balance.
- **Failure signatures:** GPT-3.5 hallucinated font categories and exhibited clustering bias toward dominant categories; rule-based predecessor failed to scale beyond manual mappings; SimCSE underperformed on domain-specific prompts.
- **First 3 experiments:** 1) Category retrieval validation: Run 141 custom prompts through MiniLM-L6-v2, retrieve top-3 categories, have internal judges score relevance (1-5). Target: >3.5 average. 2) Latency profiling: Instrument end-to-end pipeline; isolate KNN lookup, embedding inference, and pairing logic. Confirm sub-100ms p95. 3) A/B test against rule-based baseline: Deploy to 10% traffic (1:1 split), measure kept rate over 2 weeks. Look for >1% relative improvement with statistical significance before broader rollout.

## Open Questions the Paper Calls Out

### Open Question 1
Can knowledge distillation techniques be refined to close the performance gap between lightweight models (MiniLM) and Large Language Models (GPT-3.5) for font category retrieval? The authors note that GPT-3.5 achieved a significantly higher subjective relevance score (4.51) compared to the deployed MiniLM model (3.78), but was rejected solely due to latency constraints. What evidence would resolve it: A deployment of a distilled model that achieves a subjective score >4.0 while maintaining the sub-100ms latency requirement.

### Open Question 2
Do the relevance scores determined by internal product managers generalize to professional designers or the broader user population? The subjective evaluation relied on a "team of 3 product managers" rather than a diverse group of typography experts or external users. What evidence would resolve it: A comparative study showing a high correlation (e.g., Spearman > 0.8) between the internal judges' scores and those of external professional typographers.

### Open Question 3
How does the recommendation algorithm perform in long-form content contexts compared to the short-form graphic designs it was evaluated on? The conclusion states the model could be the "model of choice for font recommendation across different Microsoft applications such as Microsoft Word, Power Point," but the A/B testing was restricted to the Design Creator mini app. What evidence would resolve it: A/B test results measuring user satisfaction and document completion rates when the model is applied to long-form document editing tasks.

## Limitations
- Subjective evaluation relies on internal judges rather than end users, which may not fully capture user preferences in real-world usage
- The balanced-contrast distance function for font pairing is mentioned but not fully specified, limiting reproducibility
- The methodology depends heavily on the quality of GPT-3.5-generated category descriptions and their expert refinement, but the specific nature of these refinements is not documented

## Confidence
**High Confidence (4/5):** The core architectural approach combining semantic category retrieval with visual embedding similarity is well-justified and aligns with established practices in multimodal recommendation systems.

**Medium Confidence (3/5):** The A/B test results showing a 1.5% kept rate improvement are promising but require further validation. The subjective relevance scores (3.78/5 for MiniLM) indicate acceptable performance but leave room for improvement.

**Low Confidence (2/5):** The specific implementation details of the balanced-contrast distance function and stroke width algorithm are not fully specified, making it difficult to assess their exact contribution to performance.

## Next Checks
1. **User Experience Validation:** Conduct a large-scale A/B test with actual end users rather than internal judges, measuring not just kept rate but also user satisfaction scores, time-to-design completion, and repeat usage patterns over a 4-week period.

2. **Ablation Study:** Systematically disable individual components (category retrieval, visual embeddings, stroke width constraints, novelty sampling) to quantify their independent contributions to performance, identifying which elements provide the most value.

3. **Cross-Domain Generalization:** Test the model on non-design contexts such as presentation slides, social media posts, and marketing materials to assess robustness across different typographic requirements and user expectations.