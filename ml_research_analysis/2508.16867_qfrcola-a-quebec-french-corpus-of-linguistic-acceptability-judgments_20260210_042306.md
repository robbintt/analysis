---
ver: rpa2
title: 'QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments'
arxiv_id: '2508.16867'
source_url: https://arxiv.org/abs/2508.16867
tags:
- linguistic
- language
- french
- acceptability
- qfrcola
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces QFrCoLA, the Quebec-French Corpus of Linguistic
  Acceptability Judgments, comprising 25,153 in-domain and 2,675 out-of-domain normative
  sentences. It is the first large-scale French acceptability dataset and the second
  largest in any language.
---

# QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments

## Quick Facts
- **arXiv ID**: 2508.16867
- **Source URL**: https://arxiv.org/abs/2508.16867
- **Reference count**: 13
- **Primary result**: Introduces QFrCoLA, the first large-scale French acceptability dataset, and benchmarks seven language models across eight languages, finding that fine-tuned transformers outperform zero-shot LLMs on linguistic acceptability judgments.

## Executive Summary
This paper introduces QFrCoLA, the Quebec-French Corpus of Linguistic Acceptability Judgments, comprising 25,153 in-domain and 2,675 out-of-domain normative sentences. It is the first large-scale French acceptability dataset and the second largest in any language. The study benchmarks seven language models across eight languages, including French. Results show that fine-tuned Transformer-based language models are strong baselines for most languages. However, zero-shot large language models perform poorly on the task, even those optimized for French. For the QFrCoLA benchmark, fine-tuned models outperformed other methods tested. The findings also indicate that pre-trained cross-lingual models do not appear to have acquired Quebec French linguistic judgment capabilities during pre-training. Overall, QFrCoLA proves to be a challenging dataset suitable for benchmarking language models on linguistic acceptability judgments.

## Method Summary
The study introduces QFrCoLA, a binary classification dataset for Quebec French linguistic acceptability judgments, constructed from expert linguistic norms. Models are fine-tuned using `camembert-base` with weighted balanced loss, AdamW optimizer (lr=3e-5, weight_decay=1e-2), batch size 32, and sequence length 64. Training runs for 4 epochs with early stopping on dev accuracy, averaged over 10 seeds (42-51). Performance is evaluated using accuracy and Matthews Correlation Coefficient (MCC) on in-domain test sets, out-of-domain hold-out sets, and per-category breakdowns (syntax, morphology, semantic, anglicism).

## Key Results
- Fine-tuned transformer models achieve 82.92% accuracy on QFrCoLA test vs 69.49% baseline
- Zero-shot LLMs perform poorly, with French-optimized Lucie achieving only 58.18% accuracy
- Cross-lingual models underperform monolingual BERT (69.91% vs 82.92%) with high variance
- Out-of-domain generalization shows ~20% accuracy drop from 82.92% to 62.69% on France French hold-out
- Anglicism category yields lowest performance (~74%) compared to syntax (~88%)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuned monolingual transformer models effectively learn linguistic acceptability patterns from normative grammar data.
- Mechanism: Pre-trained transformers encode implicit syntactic representations from large-scale pre-training; fine-tuning on labeled acceptability data aligns these representations with explicit grammatical judgments through supervised learning on binary cross-entropy loss.
- Core assumption: Pre-trained representations contain sufficient syntactic knowledge that can be repurposed for grammaticality classification.
- Evidence anchors:
  - [abstract]: "fine-tuned transformer-based models outperform zero-shot LLMs on the task"
  - [section 5.1, Table 7]: Fine-tuned BERT achieves 82.92% accuracy on QFrCoLA test vs 69.49% baseline
  - [corpus]: Related CoLA-style datasets show similar transformer effectiveness; neighbor paper "QFrBLiMP" extends this to minimal pairs
- Break condition: Performance drops substantially on out-of-domain data (Section 5.2: ~20% accuracy drop from 82.92% to 62.69% on OOD hold-out)

### Mechanism 2
- Claim: Zero-shot LLMs (including French-optimized ones) fail to perform linguistic acceptability judgment without task-specific training.
- Mechanism: LLMs are optimized for next-token prediction and instruction-following objectives during pre-training, which does not inherently encode explicit grammaticality assessment capabilities; without fine-tuning, they cannot reliably map sentence representations to binary acceptability labels.
- Core assumption: Linguistic acceptability judgment requires explicit supervision or specialized training beyond general language modeling objectives.
- Evidence anchors:
  - [abstract]: "zero-shot binary classification large language models perform poorly on the task"
  - [section 5.1, Table 7]: All zero-shot LLMs achieve MCC scores near 0; Lucie (French-optimized) performs below baseline (58.18% vs 69.49%)
  - [corpus]: Weak direct corpus evidence—limited comparable studies on zero-shot acceptability in French dialects
- Break condition: Instruct variants improve over base models but remain far below fine-tuned baselines (Section 5.1: Mistral-I 63.61% vs BERT 82.92%)

### Mechanism 3
- Claim: Cross-lingual models fail to transfer linguistic judgment capabilities to Quebec French despite shared grammatical foundations.
- Mechanism: Cross-lingual models may learn surface-level multilingual patterns but lack deep syntactic representations for specific dialectal variants; Quebec French differs from France French in specific normative rules (e.g., feminization patterns).
- Core assumption: Linguistic acceptability requires dialect-specific syntactic knowledge that doesn't fully transfer across related language variants.
- Evidence anchors:
  - [abstract]: "pre-trained cross-lingual LLMs selected for our experimentation do not seem to have acquired linguistic judgment capabilities during their pre-training for Quebec French"
  - [section 3.1.2]: Quebec and France French differ (e.g., "auteure" vs "autrice" for feminization)
  - [section 5.1, Table 7]: Cross-lingual RoBERTa underperforms monolingual BERT (69.91% vs 82.92%); high variance suggests instability
  - [corpus]: Neighbor paper "Low-Resource Dialect Adaptation" suggests continual pre-training may help dialect adaptation
- Break condition: Fine-tuned cross-lingual models show high variance and don't outperform monolingual approaches (±14.61 std deviation)

## Foundational Learning

- **Concept: Out-of-Domain (OOD) Generalization**
  - Why needed here: Critical for evaluating whether models learn generalizable linguistic rules or overfit to training distribution (Section 5.2 shows 22% accuracy drop on OOD)
  - Quick check question: Can you explain why a model might achieve 82% on test data but only 62% on OOD hold-out data?

- **Concept: Matthews Correlation Coefficient (MCC)**
  - Why needed here: Standard accuracy is misleading for imbalanced binary classification; MCC accounts for class imbalance and provides a more reliable performance metric
  - Quick check question: Why might accuracy alone be insufficient when acceptable sentences comprise ~70% of the dataset?

- **Concept: Minimal Pairs vs. Binary Classification Paradigms**
  - Why needed here: Paper contrasts two acceptability evaluation approaches; understanding this distinction is essential for interpreting benchmark design choices (Section 2.2)
  - Quick check question: What is the difference between presenting a model with paired sentences (minimal pairs) versus independent sentences (binary classification)?

## Architecture Onboarding

- **Component map:**
  - Input: French sentences (max 64 tokens, tokenized via CamemBERT tokenizer)
  - Encoder: CamemBERT-base (monolingual French transformer)
  - Classification head: Binary output (acceptable/unacceptable)
  - Training: AdamW optimizer, weighted balanced loss, 4 epochs
  - Evaluation: Accuracy + MCC on dev/test/OOD splits

- **Critical path:**
  1. Sentence → CamemBERT tokenizer (no lowercasing)
  2. Tokenized input → Transformer encoder (12 layers)
  3. [CLS] token representation → Binary classifier
  4. Weighted cross-entropy loss → Backpropagation
  5. Early stopping on dev accuracy

- **Design tradeoffs:**
  - In-domain (Quebec French BDL) vs. OOD (France French Académie): More challenging OOD but risks normative disagreements
  - Category imbalance: Morphology ~43% of data (Table 3) may bias evaluation
  - Monolingual vs. cross-lingual: Monolingual outperforms but requires language-specific training

- **Failure signatures:**
  - High train/test performance but OOD collapse: Overfitting to training distribution
  - Near-zero MCC with moderate accuracy: Model exploiting class imbalance (predicting majority class)
  - Anglicism category worst performance: Training data contamination hypothesis (Section 5.2)

- **First 3 experiments:**
  1. **Baseline verification:** Train CamemBERT on QFrCoLA train split, tune on dev, report test accuracy and MCC. Expect ~82-83% accuracy per Table 7.
  2. **OOD robustness check:** Evaluate trained model on OOD hold-out set (France French). Expect ~20% accuracy drop per Table 9.
  3. **Category analysis:** Evaluate per-category performance (syntax, morphology, semantic, anglicism). Expect anglicism category to underperform per Table 8.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can generating complementary grammatical/ungrammatical sentence pairs from QFrCoLA establish an effective French minimal pair benchmark for probing LMs?
- Basis: [explicit] The authors state: "In our future works, we plan to... generate the complementary grammatical or ungrammatical sentence of each sentence in the dataset to create the first French minimal pair benchmark dataset."
- Why unresolved: The current QFrCoLA dataset is a binary classification corpus, not a minimal pair resource; the conversion has not yet been performed.
- What evidence would resolve it: The release of a derived French minimal pair dataset and benchmarks showing model sensitivity to specific linguistic phenomena.

### Open Question 2
- Question: What specific linguistic patterns characterize the errors made by large language models when performing zero-shot acceptability judgments on Quebec French?
- Basis: [explicit] The authors note in their future work section: "we would also like to explore the linguistic phenomena errors generated by the LLM qualitatively."
- Why unresolved: The current study evaluates quantitative performance (accuracy/MCC) but does not include a qualitative analysis of the failure modes.
- What evidence would resolve it: A qualitative study categorizing the types of grammatical errors missed or hallucinated by zero-shot LLMs on the QFrCoLA test set.

### Open Question 3
- Question: Does the prevalence of anglicisms in web-based pre-training data causally degrade model performance on the "Anglicism" category in QFrCoLA?
- Basis: [inferred] The authors hypothesize that the lowest performance on the "Anglicism" category is due to the occurrence of anglicisms in the LLMs' training datasets, but they do not test this directly.
- Why unresolved: While the authors propose that anglicisms in training data confuse the normative judgment, this remains a hypothesis without ablation studies on the training data.
- What evidence would resolve it: Experiments comparing models pre-trained on filtered (low-anglicism) vs. unfiltered corpora, or an analysis of attention weights when processing Anglicism examples.

## Limitations

- Strong domain-specific performance with substantial accuracy drop on out-of-domain France French data suggests potential overfitting to Quebec French patterns
- Poor performance of zero-shot LLMs indicates current transformers require explicit task-specific training for acceptability judgments
- Dataset construction from expert linguistic judgments may introduce normative biases that don't reflect natural language use patterns

## Confidence

**High Confidence**:
- Fine-tuned transformer models outperform zero-shot approaches on linguistic acceptability classification
- Cross-lingual models fail to transfer acceptability judgment capabilities to Quebec French
- Out-of-domain generalization remains a significant challenge for current approaches

**Medium Confidence**:
- Quebec French acceptability patterns differ sufficiently from France French to require dialect-specific training
- The anglicism category represents the most challenging linguistic phenomenon for current models
- Binary classification remains the most practical evaluation paradigm for acceptability judgments

**Low Confidence**:
- The specific weighting scheme used for balanced loss significantly impacts final performance
- The relationship between minimal pairs and binary classification paradigms for acceptability judgment
- Whether continual pre-training would enable cross-lingual models to acquire dialect-specific acceptability patterns

## Next Checks

1. **OOD Generalization Analysis**: Conduct systematic error analysis comparing in-domain vs. out-of-domain failures to identify whether models fail on specific linguistic phenomena (e.g., syntax vs. morphology) or particular sentence types, helping determine if the performance gap reflects genuine dialect differences or overfitting to training distribution.

2. **Cross-Lingual Transfer Experiment**: Fine-tune a cross-lingual model on Quebec French acceptability data, then evaluate on France French data to determine if task-specific training can overcome the apparent lack of dialect-specific acceptability knowledge in pre-trained cross-lingual models.

3. **Minimal Pairs vs. Binary Classification Comparison**: Implement both evaluation paradigms on the QFrCoLA dataset to empirically compare their effectiveness and determine whether the choice of paradigm influences model performance or the types of linguistic phenomena that are most challenging to classify.