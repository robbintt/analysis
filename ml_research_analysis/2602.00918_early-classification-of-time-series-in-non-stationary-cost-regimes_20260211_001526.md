---
ver: rpa2
title: Early Classification of Time Series in Non-Stationary Cost Regimes
arxiv_id: '2602.00918'
source_url: https://arxiv.org/abs/2602.00918
tags:
- cost
- time
- ects
- costs
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses Early Classification of Time Series (ECTS)
  under non-stationary cost regimes, where misclassification and decision delay costs
  change over time. Most existing ECTS methods assume fixed, known costs, but in practice,
  these costs can drift or be stochastic, leading to mismatches between training and
  deployment objectives.
---

# Early Classification of Time Series in Non-Stationary Cost Regimes

## Quick Facts
- arXiv ID: 2602.00918
- Source URL: https://arxiv.org/abs/2602.00918
- Authors: Aurélien Renault; Alexis Bondu; Antoine Cornuéjols; Vincent Lemaire
- Reference count: 30
- Primary result: Online adaptation of ECTS triggering models improves robustness to cost drift, with RL-based approaches showing strongest performance

## Executive Summary
This paper addresses Early Classification of Time Series (ECTS) under non-stationary cost regimes where misclassification and decision delay costs change over time. The authors adapt several representative ECTS approaches to an online learning setting, focusing on separable methods that update only the triggering model while keeping the classifier fixed. They propose online adaptations including bandit-based and RL-based approaches, and evaluate them under controlled cost drift scenarios using synthetic data. Results show that online learning improves robustness to cost drift, with RL-based strategies exhibiting strong and stable performance across varying cost regimes.

## Method Summary
The method involves training a fixed classifier (20 MiniROCKET estimators + isotonic calibration) offline, then deploying it with an adaptive triggering model. During deployment, the trigger updates online based on observed costs while the classifier remains unchanged. The authors implement four cost drift scenarios: abrupt and periodic drifts in both constant and stochastic cost settings. They evaluate five online adaptation methods: probability threshold with decay, HUCB1 bandit, sliding-window HUCB1, Alert RL-based trigger, and Deep-Calimera deep regressor. The evaluation uses prequential protocol with batch size 16, measuring cumulative regret and hold-out average cost.

## Key Results
- Online adaptation improves ECTS performance under cost drift, with forgetting mechanisms being essential for tracking non-stationarity
- RL-based triggers (Alert) provide strong and stable performance across all cost drift scenarios and stochasticity levels
- Methods without forgetting mechanisms (basic Proba-Threshold, HUCB1) fail to adapt under cost drift
- Deep-Calimera achieves lower costs when delayed updates are feasible, but Alert performs better when instant updates are required

## Why This Works (Mechanism)

### Mechanism 1
Online adaptation of the triggering model can recover ECTS performance when deployment-time costs drift from training-time assumptions. Separable ECTS methods decouple classification from triggering, allowing updates only to the trigger during deployment using observed losses. This is computationally efficient and reflects that cost drift primarily affects when to decide, not what class to predict. Core assumption: classifier probability estimates remain calibrated under deployment conditions.

### Mechanism 2
Forgetting mechanisms are essential for adapting to non-stationary costs; methods with full memory fail to track drift. Methods like decay-Proba-Threshold and SW-HUCB1 explicitly downweight or discard old observations. Exponential decay prioritizes recent cost realizations; sliding windows limit statistics to recent instances. This allows the trigger to adjust when the cost balance changes over time. Core assumption: cost non-stationarity follows a temporal pattern where recent observations are more representative.

### Mechanism 3
RL-based triggers (Alert) provide strong, stable performance across cost drift and stochasticity because they optimize non-myopically and support instant updates. Alert uses a DQN to learn a stopping policy, updating Q-values during deployment with exploration. The RL formulation naturally handles the sequential decision structure. Core assumption: the state representation (classifier probabilities + time index) captures sufficient information for the trigger to generalize across cost regimes.

## Foundational Learning

- **Time-dependent loss functions** (Cm + Cd·t): ECTS explicitly trades off accuracy vs. earliness. Understanding that L(ŷ, y, t) = Cm(ŷ|y) + Cd(t) is foundational to interpreting all results.
  - Quick check: If Cd(t) increases faster, should the trigger decide earlier or later?

- **Multi-armed bandits and exploration-exploitation**: Bandit-based triggers treat threshold selection as an arm selection problem. UCB balances exploring suboptimal thresholds vs. exploiting the best-known one.
  - Quick check: Why would a bandit algorithm ever choose an arm that has performed poorly in the past?

- **Reinforcement learning for sequential decision-making**: Alert frames ECTS as a Markov Decision Process where each time step involves "wait" or "predict" action. Understanding Q-learning, exploration (ε), and reward shaping is essential.
  - Quick check: In Alert, what happens if ε = 0 during deployment?

## Architecture Onboarding

- **Component map**: Classifier -> Classifier probabilities -> Triggering model -> Decision ("wait" or "predict") -> True label + costs -> Trigger update
- **Critical path**: 1) Train classifier offline with nominal costs. 2) Train trigger offline using same data. 3) Deploy: classifier produces probabilities; trigger decides. 4) After prediction, observe true label and realized costs; update trigger.
- **Design tradeoffs**: Delayed vs. instant updates (Deep-Calimera requires full series, Alert updates immediately); Forgetting rate (high decay/windows track drift faster but are noisier); Exploration during deployment (essential for adaptation but incurs short-term cost).
- **Failure signatures**: Trigger never fires (threshold too high); Trigger fires immediately (threshold too low); Performance degrades over time (method lacks forgetting mechanism).
- **First 3 experiments**: 1) Replicate AC D scenario: train with α=0.8, deploy with α=0.4. Compare no adapt vs. decay-Proba-Threshold vs. Alert. 2) Ablate forgetting: compare HUCB1 vs. SW-HUCB1 on PV D. 3) Stress test stochastic costs: deploy under AC S with high variance. Compare Alert vs. Deep-Calimera.

## Open Questions the Paper Calls Out

- Can online ECTS methods maintain robustness when cost non-stationarity co-occurs with data distribution shifts or concept drift?
- How do online adaptations perform on real-world ECTS datasets with naturally occurring cost non-stationarity?
- Can end-to-end ECTS methods be adapted for online cost adaptation while remaining competitive with separable approaches?
- Does the assumption that cost drift primarily affects decision timing rather than class discrimination hold across diverse applications?

## Limitations

- The study explicitly excludes input distribution shifts, focusing only on cost drift despite real-world deployments likely facing both simultaneously.
- All experiments use synthetic MNIST-1D data rather than real-world time series benchmarks where cost structures are naturally occurring.
- The paper restricts to separable methods, leaving open whether end-to-end ECTS methods can be effectively adapted for online cost learning.

## Confidence

- **High confidence**: The core finding that online adaptation improves ECTS performance under cost drift, and that forgetting mechanisms are essential for tracking non-stationarity.
- **Medium confidence**: The relative ranking of adaptation methods across different drift scenarios, particularly the superiority of RL-based approaches.
- **Medium confidence**: The conclusion that separable methods (trigger-only adaptation) are viable, though this is supported by theoretical reasoning rather than extensive empirical comparison with joint adaptation.

## Next Checks

1. **State sufficiency test**: Systematically ablate Alert's state representation (remove time index, use raw probabilities, add classifier uncertainty) to determine minimum sufficient information for adaptation.

2. **Concept drift stress test**: Evaluate the same online adaptation methods when both cost parameters and input distributions drift simultaneously, to identify failure thresholds.

3. **Exploration cost quantification**: Measure the cumulative regret impact of different exploration schedules during deployment, particularly comparing ε-greedy decay rates across cost drift intensities.