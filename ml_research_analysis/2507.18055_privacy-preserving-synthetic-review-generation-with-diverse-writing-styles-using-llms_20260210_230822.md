---
ver: rpa2
title: Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles
  Using LLMs
arxiv_id: '2507.18055'
source_url: https://arxiv.org/abs/2507.18055
tags:
- reviews
- diversity
- synthetic
- review
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study develops a systematic framework for assessing the diversity\
  \ and privacy risks of synthetic product reviews generated by large language models.\
  \ It introduces a comprehensive set of metrics\u2014including lexical richness (distinctiveness\
  \ and entropy across n-grams), semantic diversity (via MST-based review embedding\
  \ analysis), sentiment alignment with ratings, and privacy risks (via named entity/nominal\
  \ mention counts and user-level stylistic outlier detection)."
---

# Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs

## Quick Facts
- arXiv ID: 2507.18055
- Source URL: https://arxiv.org/abs/2507.18055
- Reference count: 39
- Key outcome: A prompt-based optimization pipeline that iteratively refines LLM-generated synthetic reviews significantly improves lexical and semantic diversity while managing privacy risks through metric-guided instruction stacking

## Executive Summary
This study develops a systematic framework for assessing and improving the diversity and privacy of synthetic product reviews generated by large language models. Through comprehensive evaluation metrics including lexical richness, semantic dispersion via MST analysis, sentiment alignment, and privacy risks, the research identifies that baseline LLM outputs often lack diversity and introduce elevated privacy concerns. A novel prompt optimization pipeline addresses these issues through iterative refinement based on metric failures, achieving substantial improvements in diversity while maintaining user stylometric uniqueness.

## Method Summary
The methodology employs a metric-driven approach to synthetic review generation using LLMs. It combines lexical diversity metrics (n-gram distinctiveness and entropy), semantic diversity analysis (MST edge length on Word2Vec embeddings), sentiment alignment scoring, and privacy risk assessment (named entity counts and stylometric outlier detection). The optimization pipeline generates review batches, evaluates them across six dimensions, and iteratively refines prompts by stacking targeted instructions from predefined pools based on metric failures, with a sliding window limiting each metric's instructions to three.

## Key Results
- Baseline LLM outputs show low lexical diversity (Lr scores often below 0.1) and poor semantic dispersion with MST edge lengths as low as 0.000043
- The adaptive prompt optimization pipeline significantly improves diversity metrics, achieving MST edge lengths of 0.000914 and maintaining high semantic uniqueness ratios
- Privacy risks increase with more expressive prompts (Level 2), but the optimization approach reduces entity mentions while preserving diversity gains

## Why This Works (Mechanism)

### Mechanism 1
Iterative, metric-guided prompt refinement improves semantic and lexical diversity beyond static prompting by creating a feedback loop where specific corrective instructions are added when metrics fail. This targeted approach outperforms holistic "be diverse" instructions by decomposing diversity into measurable components. Evidence shows Level 3 adaptive prompting achieved N-gram Lr scores of 0.0781-0.2091 compared to 0.0027-0.0539 for baseline approaches.

### Mechanism 2
Minimum Spanning Tree analysis captures structural semantic diversity that simple distinctness ratios miss by measuring the average semantic distance between connected reviews in embedding space. Higher MST edge lengths indicate reviews are less similar to their nearest neighbors. The approach achieved MST edge length of 0.000914 with adaptive prompting versus 0.000043 for static prompts, demonstrating substantially greater semantic dispersion.

### Mechanism 3
Two-tier stylistic outlier detection identifies users at heightened re-identification risk without falsely flagging coherent subgroups by combining global z-score filtering with local nearest-neighbor distance checks. This prevents misclassifying minority groups as outliers simply because they're distant from the general population. Users must be both globally distant (z-score below threshold) and locally isolated (no nearby stylistic match) to be flagged as true privacy risks.

## Foundational Learning

- **N-gram lexical analysis (unigrams through pentagrams)**: Why needed - to quantify vocabulary richness and structural variability at multiple phrase levels. Quick check - If a dataset has Lr=0.01 for unigrams but Lr=0.95 for pentagrams, what does this tell you about repetition patterns?

- **Z-score normalization for outlier detection**: Why needed - to filter users based on relative position in the distribution rather than arbitrary absolute values. Quick check - Why use z-scores rather than raw percentile cutoffs when identifying globally distant users?

- **Cosine similarity/distance on embeddings**: Why needed - as the foundation for all semantic diversity and stylistic profiling metrics. Quick check - Two reviews have cosine distance of 0.05. Is this "close" or "far"? What additional context do you need?

## Architecture Onboarding

- **Component map**: Preprocessing (stopword removal → Word2Vec training → sentence averaging) → Diversity metrics (N-gram Lr/Hn, Semantic Ratio + MST, Dsen) → Privacy metrics (entity extraction, stylometric outlier detection) → Prompt optimization (base prompt → generation → metric evaluation → instruction selection → stacked prompt → regenerate)

- **Critical path**: Define base prompt with domain constraints → Generate batch (e.g., 1000 reviews) → Run all 6 metric evaluations → For each failed metric, pull instruction from pool → Stack instructions into next prompt (max 3 per metric) → Accumulate outputs; never discard batches

- **Design tradeoffs**: Dataset-specific Word2Vec vs. pre-trained embeddings captures domain semantics but requires sufficient corpus size; sliding window of 3 instructions per metric prevents prompt bloat but may lose important prior guidance; global/local thresholds for outlier detection balance false positives against missed risks

- **Failure signatures**: Semantic Ratio = 1.0 but low MST edge length indicates no exact duplicates but clustered reviews; high entity density in short reviews often indicates false positives from capitalization heuristics; Level 2 prompts increase realism but also privacy risks through more personal references

- **First 3 experiments**: Baseline calibration - generate synthetic reviews with Level 1 prompt and compute all metrics against real Amazon data; Metric sensitivity analysis - vary one prompt constraint and observe metric responses; Privacy-diversity tradeoff mapping - compare Level 2 vs Level 3 prompts on lexical/semantic improvements against entity counts and outlier rates

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- The Word2Vec embedding approach may inadequately capture semantic nuances of short, informal review text with domain-specific jargon and misspellings
- Privacy assessment focuses on named entities and stylistic outliers but may miss topic-based re-identification or temporal patterns
- Stylometric outlier detection assumes stable user writing patterns without accounting for deliberate style variation or context differences

## Confidence

- **High confidence**: Lexical diversity metrics (distinctiveness ratios, entropy) have well-established theoretical foundations in information theory and are straightforward to compute
- **Medium confidence**: Semantic diversity measurements using MST analysis depend heavily on embedding quality, though the methodology is sound
- **Low confidence**: Privacy risk assessment through stylistic outlier detection relies on multiple assumptions about user behavior and embedding effectiveness, with no attacker model specification

## Next Checks

1. **Embedding robustness test**: Generate synthetic reviews using different embedding methods (Sentence-BERT, average GloVe) and compare semantic diversity metrics to determine if Word2Vec-specific artifacts are driving results

2. **Privacy risk ground truth validation**: Conduct a human evaluation study where participants attempt to identify reviewers from synthetic reviews flagged as outliers versus non-outliers

3. **Cross-domain generalization**: Apply the complete evaluation pipeline to synthetic reviews for a different product category (e.g., books instead of electronics) to assess metric generalization across domains with different writing styles