---
ver: rpa2
title: 'JiraiBench: A Bilingual Benchmark for Evaluating Large Language Models'' Detection
  of Human Self-Destructive Behavior Content in Jirai Community'
arxiv_id: '2503.21679'
source_url: https://arxiv.org/abs/2503.21679
tags:
- content
- japanese
- chinese
- social
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces JiraiBench, the first bilingual benchmark
  for evaluating large language models' effectiveness in detecting self-destructive
  content across Chinese and Japanese social media communities. The benchmark focuses
  on the transnational "Jirai" subculture encompassing drug overdose, eating disorders,
  and self-harm behaviors.
---

# JiraiBench: A Bilingual Benchmark for Evaluating Large Language Models' Detection of Human Self-Destructive Behavior Content in Jirai Community

## Quick Facts
- **arXiv ID**: 2503.21679
- **Source URL**: https://arxiv.org/abs/2503.21679
- **Reference count**: 40
- **Primary result**: First bilingual benchmark evaluating LLMs' detection of self-destructive behaviors in Chinese and Japanese social media, revealing that Japanese prompts outperform Chinese prompts on Chinese content.

## Executive Summary
JiraiBench introduces a novel bilingual benchmark for evaluating large language models' effectiveness in detecting self-destructive behaviors across Chinese and Japanese social media communities. The benchmark focuses on the transnational "Jirai" subculture, encompassing drug overdose, eating disorders, and self-harm behaviors. Through comprehensive experiments across four state-of-the-art models, the study reveals significant performance variations based on instructional language, with Japanese prompts unexpectedly outperforming Chinese prompts when processing Chinese content. This emergent cross-cultural transfer suggests that cultural proximity can sometimes outweigh linguistic similarity in detection tasks, challenging conventional assumptions about language matching in cross-lingual NLP tasks.

## Method Summary
The benchmark was constructed using 10,419 Chinese posts from Sina Weibo and 5,000 Japanese posts from X (Twitter), collected via keyword-based search using specialized lexicons. Six annotators (3 per language) applied a multi-label annotation protocol labeling three categories: Drug Misuse (DM), Eating Disorders (ED), and Non-Suicidal Self-Injury (NSSI), with each category labeled 0 (unrelated), 1 (first-person expression), or 2 (third-party description). The inter-annotator Fleiss' Kappa ranged from 0.68-0.78. Baseline evaluation used Llama-3.1-8B, Qwen-2.5-7B, and DeepSeek-v3 in zero-shot and two-shot settings with Chinese, Japanese, and English prompts. Fine-tuning employed LoRA on 3,000 Chinese samples with Chinese prompts, using 3 epochs on 4Ã— NVIDIA A6000 GPUs with per-device batch size 5 and gradient accumulation 10.

## Key Results
- Japanese instruction prompts significantly outperformed Chinese prompts when detecting risky health behaviors in Chinese content
- Zero-shot prompting consistently outperformed two-shot prompting across most model configurations
- Cross-lingual transfer was demonstrated: fine-tuning on Chinese data yielded measurable performance gains on Japanese RHB detection without Japanese training data
- Safety alignment emerged as a critical confounding factor, with GPT-4o consistently refusing to perform classification tasks

## Why This Works (Mechanism)

### Mechanism 1: Cultural Framing Activation
Japanese prompts activate nuanced cultural schemata associated with RHB discourse more effectively than native Chinese prompts, even when processing Chinese content. This suggests LLMs encode culturally-situated knowledge that can be selectively accessed via culturally-aligned prompting, directing attention toward subtle behavioral markers. The effect may diminish if content lacks strong cultural framing or if model safety tuning suppresses related tokens.

### Mechanism 2: Task-Relevant Representation Transfer
Fine-tuning on Chinese RHB data aligns model representations for the task of RHB detection, which transfers to Japanese due to shared cultural context (Jirai subculture) and linguistic features. The task-relevant features learned during fine-tuning are partially language-agnostic within culturally-shared domains. Transfer effectiveness likely degrades with greater linguistic/cultural distance between source and target languages.

### Mechanism 3: Zero-shot Generalization Advantage
Zero-shot approaches outperform few-shot methods because providing few-shot examples may constrain model attention to narrow behavioral patterns, causing interference that harms generalization to the diverse, nuanced, and metaphorical expressions found in real Jirai community posts. The model may overfit to specific patterns during inference when given limited examples.

## Foundational Learning

**Cross-Cultural Transfer in LLMs**: Why needed: The paper's central, counterintuitive finding relies on understanding that model performance isn't purely a function of language matching. Quick check: If an LLM performs better on Spanish text when prompted in Italian rather than Spanish, what are two possible non-linguistic reasons?

**Instruction Tuning & Safety Alignment**: Why needed: The paper notes GPT-4o's refusal to classify RHB content and discusses how safety tuning can suppress tokens. Quick check: Why might a model with strong safety alignment perform worse on a benchmark designed to detect harmful content, compared to a base model?

**Parameter-Efficient Fine-Tuning (PEFT/LoRA)**: Why needed: The paper uses LoRA to create JiraiLLM-Qwen. Understanding PEFT is necessary to replicate or extend this work. Quick check: What is the primary advantage of using LoRA over full fine-tuning for adapting a large model to a specialized task like RHB detection?

## Architecture Onboarding

**Component map**: Data Collection & Cleaning pipeline -> Multi-label Annotation Protocol -> Prompt Template Library -> Model Evaluation Harness -> LoRA Fine-tuning Module

**Critical path**: 1. Define annotation schema -> 2. Collect and clean raw data -> 3. Expert annotation with QA -> 4. Benchmark baseline models with varied prompts -> 5. Fine-tune on source language data -> 6. Evaluate transfer to target language

**Design tradeoffs**:
- **Prompt Language vs. Content Language**: Choosing optimal prompt language involves tradeoff between linguistic clarity and cultural activation; paper suggests prioritizing cultural origin for this domain
- **Zero-shot vs. Few-shot**: Investing in few-shot example engineering vs. relying on zero-shot; paper's evidence suggests zero-shot may be more robust here
- **Data Annotation Depth**: Simple binary vs. nuanced scale (0/1/2 for first-person); latter increases cost but provides critical context for intervention

**Failure signatures**:
- Low Macro-F1 on First-Person (Label 1): Model fails to detect most critical posts for intervention
- High Performance Disparity Between Languages: Poor cross-lingual transfer, indicating overfitting to source language
- Model Refusals: High refusal rate indicates model's safety alignment is too broad, blocking legitimate research

**First 3 experiments**:
1. **Baseline Reproduction**: Run four paper models on subset of JiraiBench using Chinese, Japanese, and English prompts to verify "Japanese prompt advantage" on Chinese content
2. **Ablation: Cultural vs. Orthographic Transfer**: Replicate Kanji-stripping experiment to confirm if performance holds with phonetic (kana-only) Japanese prompts
3. **Fine-tuning Transfer Test**: LoRA fine-tune Qwen-2.5-7B on small subset (500 samples) of Chinese data and immediately evaluate on Japanese test set to measure zero-shot cross-lingual transfer gain

## Open Questions the Paper Calls Out

**Open Question 1**: Does the cross-cultural transfer phenomenon generalize to transnational subcultures outside the Sinosphere? The paper suggests future work should expand benchmark datasets to include additional languages and cultural contexts, but JiraiBench is restricted to Chinese and Japanese which share logographic roots and specific "Jirai" cultural history.

**Open Question 2**: To what extent are results influenced by model safety alignment suppressing culturally specific "risky" tokens? The paper observes that safety tuning and censorship mechanisms emerge as critical confounding factors, but does not isolate whether Japanese prompts escape censorship mechanisms that would otherwise flag Chinese content.

**Open Question 3**: How can evaluation of closed-source models be standardized when safety guardrails block legitimate research on sensitive topics? The paper highlights the limitation where GPT-4o consistently refused to perform classification tasks, creating a blind spot in evaluation, and calls for development of secure, research-specific API modes.

## Limitations

- The benchmark's focus on a single transnational phenomenon (Jirai subculture) limits external validity and generalizability to other cultural contexts
- Dataset construction lacks public availability of raw data and keyword lexicons, making independent verification difficult
- Experimental design compares only four model families, all from Chinese tech companies, which may introduce systematic bias

## Confidence

**High Confidence**: Benchmark construction methodology and finding that zero-shot prompting outperforms two-shot prompting are robust within tested models and prompt designs.

**Medium Confidence**: Cross-cultural transfer effect is well-documented within benchmark but requires replication with different models and cultural contexts to establish generalizability.

**Low Confidence**: Claims about mechanism underlying cross-cultural transfer remain speculative without neuroscientific or cognitive evidence; assertion that cultural proximity can "sometimes outweigh linguistic similarity" is based on single experimental context.

## Next Checks

1. **Replication with Independent Data Sources**: Construct parallel JiraiBench using different data collection methods (Reddit communities, Discord servers) and verify if Japanese prompts maintain advantage over Chinese prompts.

2. **Cross-Cultural Generalization Test**: Apply same experimental protocol to different transnational cultural phenomenon (K-pop fan culture or global environmental movements) to determine if cross-cultural transfer effects persist across domains.

3. **Safety Alignment Ablation Study**: Systematically test spectrum of models with varying degrees of safety tuning to quantify how safety alignment impacts RHB detection performance.