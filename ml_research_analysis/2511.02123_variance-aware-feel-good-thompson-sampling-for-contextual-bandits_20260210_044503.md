---
ver: rpa2
title: Variance-Aware Feel-Good Thompson Sampling for Contextual Bandits
arxiv_id: '2511.02123'
source_url: https://arxiv.org/abs/2511.02123
tags:
- regret
- bandits
- contextual
- linear
- holds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FGTS-VA, a variance-aware Thompson Sampling
  algorithm for contextual bandits with general reward functions. The algorithm extends
  Feel-Good Thompson Sampling (FGTS) by incorporating variance-dependent weights and
  a new feel-good exploration term in the posterior distribution.
---

# Variance-Aware Feel-Good Thompson Sampling for Contextual Bandits

## Quick Facts
- arXiv ID: 2511.02123
- Source URL: https://arxiv.org/abs/2511.02123
- Authors: Xuheng Li; Quanquan Gu
- Reference count: 40
- Primary result: FGTS-VA achieves O(sqrt(dc · log|F| · Λ + dc)) regret bound, matching optimal linear contextual bandit performance

## Executive Summary
This paper introduces FGTS-VA, a variance-aware Thompson Sampling algorithm for contextual bandits with general reward functions. The algorithm extends Feel-Good Thompson Sampling by incorporating variance-dependent weights and a new feel-good exploration term in the posterior distribution. The key innovation is the generalized decoupling coefficient, which measures model space complexity and relates to the Eluder dimension. FGTS-VA achieves near-optimal regret bounds while adapting to variance, making it the first FGTS-based approach that handles general reward functions optimally without requiring horizon knowledge.

## Method Summary
FGTS-VA extends traditional Thompson Sampling by introducing variance-dependent weights and a generalized decoupling coefficient that measures model space complexity. The algorithm maintains a posterior distribution over the model space F and uses this to generate samples for arm selection. The key innovation is the incorporation of variance information through weighted sampling, where the weights depend on both the model complexity (measured by the generalized decoupling coefficient) and the observed variance. This allows the algorithm to balance exploration and exploitation more effectively than previous approaches, particularly in settings with high variance or complex model spaces.

## Key Results
- FGTS-VA achieves regret bound of O(sqrt(dc · log|F| · Λ + dc)), where dc is the generalized decoupling coefficient
- For linear contextual bandits, the algorithm matches the optimal bound of O(d sqrt(Λ + d))
- The algorithm improves upon previous variance-aware methods by handling general reward functions optimally without horizon knowledge

## Why This Works (Mechanism)
The algorithm works by incorporating variance information directly into the Thompson Sampling framework through weighted posterior sampling. The generalized decoupling coefficient acts as a complexity measure that allows the algorithm to adapt its exploration strategy based on the difficulty of the model space. By weighting samples according to both model complexity and observed variance, FGTS-VA can make more informed decisions about which arms to explore, leading to improved regret bounds compared to variance-agnostic approaches.

## Foundational Learning

1. **Generalized Decoupling Coefficient**: Measures model space complexity in terms of the Eluder dimension; needed to quantify how difficult it is to distinguish between different models in F. Quick check: Verify that dc(F) ≤ d·log|F| for linear models.

2. **Variance-Dependent Weights**: Weights that incorporate observed variance into the sampling process; needed to balance exploration and exploitation based on uncertainty. Quick check: Confirm that weights decrease as variance increases for well-performing arms.

3. **Feel-Good Exploration**: A mechanism that encourages exploration of uncertain arms; needed to prevent premature convergence to suboptimal arms. Quick check: Ensure exploration bonus scales appropriately with uncertainty estimates.

## Architecture Onboarding

Component map: Context -> Model Space F -> Posterior Distribution -> Variance-Weighted Sampling -> Arm Selection

Critical path: The algorithm maintains a posterior distribution over the model space, samples from this distribution using variance-dependent weights, and selects arms based on these samples. The generalized decoupling coefficient is computed once per round to adjust the exploration-exploitation tradeoff.

Design tradeoffs: The algorithm trades computational complexity (due to variance calculations and generalized decoupling coefficient computation) for improved regret bounds. This makes it particularly suitable for applications where sample efficiency is critical.

Failure signatures: Poor performance may occur when the model space F is extremely large (exponential in dimensionality) or when variance estimates are noisy, leading to suboptimal weighting of samples.

First experiments:
1. Test FGTS-VA on a simple linear contextual bandit problem with known optimal solution
2. Compare regret against standard Thompson Sampling on a synthetic problem with high variance
3. Evaluate computational overhead by measuring wall-clock time on problems of increasing dimensionality

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Computational overhead from variance-dependent weights and generalized decoupling coefficient calculation
- Performance unclear in high-dimensional settings where model space F is extremely large
- Assumes access to computationally efficient posterior sampling mechanism

## Confidence

| Claim | Confidence |
|-------|------------|
| Regret bound optimality | High |
| General reward function handling | Medium |
| Variance adaptation improvements | Medium |

## Next Checks

1. Implement FGTS-VA on standard benchmark datasets (e.g., Yahoo! Front Page Dataset) and compare wall-clock time against existing Thompson Sampling variants
2. Test the algorithm's performance in high-dimensional sparse settings where |F| is exponentially large
3. Validate the practical impact of the variance-dependent weights by comparing against a variance-agnostic variant of FGTS-VA