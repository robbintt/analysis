---
ver: rpa2
title: 'MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing'
arxiv_id: '2511.19963'
source_url: https://arxiv.org/abs/2511.19963
tags:
- image
- vision
- sequence
- arxiv
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: MambaEye is a size-agnostic visual encoder based on a pure Mamba2
  backbone that preserves causal sequential processing. It uses relative move embeddings
  to encode spatial shifts between consecutive patches, enabling translation invariance
  and flexibility with arbitrary image resolutions and scanning patterns.
---

# MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing

## Quick Facts
- **arXiv ID:** 2511.19963
- **Source URL:** https://arxiv.org/abs/2511.19963
- **Reference count:** 39
- **Primary result:** MambaEye achieves competitive ImageNet-1K performance (75.0% top-1 at 512², 66.7% at 1536²) with linear time and memory complexity using only random patch sampling.

## Executive Summary
MambaEye introduces a size-agnostic visual encoder based on a pure Mamba2 backbone that preserves causal sequential processing. It uses relative move embeddings to encode spatial shifts between consecutive patches, enabling translation invariance and flexibility with arbitrary image resolutions and scanning patterns. A novel diffusion-inspired loss provides dense, step-wise supervision, training the model to build confidence as it gathers more visual evidence. MambaEye achieves competitive ImageNet-1K performance while maintaining linear time and memory complexity.

## Method Summary
MambaEye processes images by sampling random 16×16 patches from arbitrary resolutions, encoding each patch along with its spatial displacement from the previous patch using sinusoidal relative move embeddings. The concatenated vector passes through a projection MLP and a unidirectional Mamba2 backbone, which maintains a causal recurrent state. Predictions are made at every step, with supervision provided by a diffusion-inspired loss that linearly interpolates between a uniform prior and the target label based on the fraction of image area covered so far. The model is pre-trained for 300 epochs and fine-tuned for 30 epochs on ImageNet-1K.

## Key Results
- Achieves 75.0% top-1 accuracy at 512² resolution and 66.7% at 1536² resolution using only random patch sampling
- Maintains linear time and memory complexity with recurrent inference enabling constant-memory processing
- Outperforms previous Mamba-based encoders at extreme resolutions (1536²) despite simpler architecture
- Peak performance occurs at mid-range resolutions (384²–640²), with some degradation at extremes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion-inspired loss improves accuracy and calibration by providing dense, step-wise supervision tied to information accumulation.
- Mechanism: At each step, target is linearly interpolated between a uniform prior and the one-hot label using the information ratio (fraction of image covered so far), forcing the model to express calibrated confidence as more patches are seen.
- Core assumption: Optimal predictions should reflect the amount of visual evidence observed up to each step.
- Evidence anchors:
  - [abstract] "diffusion-inspired loss provides dense, step-wise supervision, training the model to build confidence as it gathers more visual evidence."
  - [section 3.4] $p^{(t)}_{scheduled} = (1 - r_t)\cdot p_{prior} + r_t\cdot p_{target}$ and mean CE over the sequence.
  - [corpus] Weak direct evidence; related work focuses on sequentiality or efficiency but not step-wise supervision losses of this form.
- Break condition: If CE without step-wise scheduling matches or exceeds accuracy/calibration, the mechanism may not be necessary.

### Mechanism 2
- Claim: Relative move embeddings support translation invariance and size-agnostic processing for arbitrary scanning patterns.
- Mechanism: Encode spatial displacement $(\Delta x, \Delta y)$ between consecutive patches with sinusoidal embeddings rather than absolute positions, letting the model generalize across resolutions and scan orders.
- Core assumption: Spatial context between successive patches is sufficient for image-level understanding without absolute coordinates.
- Evidence anchors:
  - [abstract] "relative move embedding ... encodes the spatial shift between consecutive patches ... making the model inherently adaptable to arbitrary image resolutions and scanning patterns."
  - [section 3.2] Move embedding is a sinusoidal encoding of relative coordinate change; $m_0$ is zero.
  - [corpus] No strong corpus support; neighbors focus on tokenization/attention, not move embeddings for visual scanning.
- Break condition: If deterministic scans significantly outperform random sampling, or if performance collapses under unseen resolutions, the invariance claim may be overstated.

### Mechanism 3
- Claim: Pure unidirectional Mamba2 backbone enables linear time complexity and constant-memory inference while preserving a causal recurrent state for predictions at any step.
- Mechanism: Unidirectional SSM maintains a hidden state updated each step; recurrent inference yields O(1) memory per step and O(T) time for T patches, allowing early emission of predictions.
- Core assumption: A causally accumulated hidden state can summarize visual information effectively without bidirectional context.
- Evidence anchors:
  - [abstract] "strictly unidirectional approach preserves the inherent causality of State Space Models ... maintaining linear time and memory complexity relative to the number of patches."
  - [section 3.3] Recurrent mode: $(z^{i+1}_t, h^{i+1}_t) = f^i_{\text{mamba, recurrent}}(z^i_t, h^{i+1}_{t-1})$; parallel mode for training.
  - [corpus] HydraRec and Scalable Sequential Recommendation emphasize efficient attention under memory/latency constraints, supporting the efficiency motivation but not Mamba-specific causality.
- Break condition: If bidirectional variants consistently outperform unidirectional processing at comparable compute, or if hidden state degrades over very long sequences, the mechanism may be insufficient.

## Foundational Learning
- **State Space Models (SSMs)**: Why needed here: MambaEye builds on Mamba2, which discretizes continuous-time SSM dynamics into efficient recurrent updates. Quick check: Explain how an SSM maps a 1D input to an output via a latent state.
- **Sinusoidal Position Embeddings**: Why needed here: Used for move embeddings to encode spatial shifts between patches. Quick check: Why might sinusoidal embeddings favor translation invariance?
- **Diffusion Models / Flow Matching**: Why needed here: The loss is inspired by iterative denoising/flow-based schedules to interpolate between prior and target distributions. Quick check: What role does a schedule play in guiding model confidence over time?

## Architecture Onboarding
- **Component map**: Patch extraction → Move embedding → Projection MLP → Mamba2 Backbone → Classification Head → Loss
- **Critical path**: Patch extraction → Move embedding → Projection → Backbone (sequential) → Classification head → Loss
- **Design tradeoffs**:
  - Unidirectional vs bidirectional: preserves causality and constant-memory inference, potentially at the cost of global context
  - Random patch sampling vs deterministic scans: supports size-agnostic behavior; works best with relative move embeddings and diffusion-inspired loss
- **Failure signatures**:
  - Accuracy oscillations under raster/zigzag scans due to large spatial jumps disrupting causal state
  - Saturation or drop at very long sequences if the information-ratio schedule is misaligned
  - Lower peak accuracy vs bidirectional or fractal-scan baselines at moderate resolutions
- **First 3 experiments**:
  1. Ablate diffusion-inspired loss vs standard CE on the same architecture; measure accuracy and calibration across resolutions
  2. Replace relative move embeddings with absolute positional embeddings; assess impact on resolution flexibility and scan-pattern robustness
  3. Profile memory and latency for parallel vs recurrent inference at increasing sequence lengths (T=1024, 4096, 8192); verify linear scaling

## Open Questions the Paper Calls Out
- **Question**: Can a learned, adaptive scanning policy outperform the naive random patch sampling used in MambaEye?
- **Basis**: The authors state in the Limitations section: "the most significant future step is to replace random patch sampling with a learned, adaptive scanning policy, bringing the model’s efficiency closer to that of human vision."
- **Why unresolved**: The current work relies exclusively on random sampling to demonstrate size agnosticism, leaving the potential performance gains from an intelligent, content-aware scanning mechanism unexplored.
- **What evidence would resolve it**: A comparative study benchmarking MambaEye equipped with a reinforcement learning or attention-based scanning agent against the random sampling baseline on ImageNet-1K.

- **Question**: Can the relative move embedding mechanism be effectively adapted for high-dimensional data such as video or 3D volumes?
- **Basis**: The authors identify a key future direction as "a systematic study of generalization... to higher dimensional data like video or 3D volumes, which could be supported by adapting the move embedding with higher dimension."
- **Why unresolved**: The current implementation only encodes 2D spatial shifts ($\Delta x, \Delta y$). It is unclear if the translation invariance inductive bias scales efficiently to the temporal dimension or 3D spatial axes without excessive complexity.
- **What evidence would resolve it**: Extending the move embedding to include a time delta ($\Delta t$) or depth coordinate ($\Delta z$) and evaluating the model's performance on standard video classification or 3D medical imaging datasets.

- **Question**: What is the root cause of the performance collapse observed when using deterministic scanning patterns (raster/zigzag) with this specific architecture?
- **Basis**: Table 5 shows that deterministic scans (e.g., Horizontal Raster) yield drastically lower accuracy (6.0%) compared to random sampling (66.7%) at high resolutions. The authors hypothesize that "spatially incoherent moves" disrupt the causal state, but this mechanism is not fully isolated or proven.
- **Why unresolved**: While the authors suggest that large jumps in raster scans disrupt the causal state, the severity of the degradation suggests a fundamental sensitivity in the unidirectional Mamba2 backbone that requires deeper mechanistic analysis.
- **What evidence would resolve it**: An ablation study analyzing the hidden state dynamics during deterministic vs. random scans, specifically measuring state saturation or information loss during the "wrap-around" transitions of a raster scan.

- **Question**: Is MambaEye’s unidirectional architecture compatible with hierarchical structures like H-Net?
- **Basis**: The authors note: "It will be worth it to understand MambaEye’s unidirectional architecture and its general compatibility with other complex structures like H-Net could yield further improvements."
- **Why unresolved**: The paper utilizes a flat, sequential processing pipeline. Compatibility with hierarchical models (which require multi-scale feature extraction) is uncertain because MambaEye lacks the standard pooling or strided convolution layers found in most hierarchical vision backbones.
- **What evidence would resolve it**: Implementing a modified MambaEye block within an H-Net framework and evaluating if the causal, recurrent nature of the SSM conflicts with the hierarchical down-sampling and up-sampling operations.

## Limitations
- **Random Patch Sampling Dependency**: The model's size-agnostic performance heavily relies on random patch sampling, which may be suboptimal for real-world applications requiring structured scans.
- **Incomplete Architectural Specification**: Key Mamba2 hyperparameters and exact sinusoidal encoding formulas are not specified, making exact reproduction difficult.
- **Limited Cross-Resolution Generalization**: Peak accuracy is achieved at mid-range resolutions (384²–640²), with degradation at extremes suggesting limits to the size-agnostic claim.

## Confidence
- **High Confidence**: The claims about linear time and memory complexity for the unidirectional Mamba2 backbone are well-grounded and align with established SSM theory.
- **Medium Confidence**: The size-agnostic performance claims are plausible given the architecture, but depend on untested factors and show some degradation at extreme resolutions.
- **Low Confidence**: The innovation and impact of the diffusion-inspired loss are the least supported, with insufficient ablation studies to isolate its contribution.

## Next Checks
1. **Ablation of Diffusion-Inspired Loss**: Retrain MambaEye using standard cross-entropy loss at all resolutions. Measure if accuracy and calibration drop significantly (>4-5 point loss).
2. **Move Embedding Variants**: Replace relative move embeddings with absolute positional embeddings. Test if resolution flexibility and scan-pattern robustness degrade, especially under deterministic scanning patterns.
3. **Scalability Profile**: Measure memory and latency at increasing sequence lengths (T=1024, 4096, 8192) for both parallel and recurrent inference modes. Verify that linear scaling holds in practice and that recurrent inference is truly constant-memory.