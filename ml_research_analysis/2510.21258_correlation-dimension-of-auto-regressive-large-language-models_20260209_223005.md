---
ver: rpa2
title: Correlation Dimension of Auto-Regressive Large Language Models
arxiv_id: '2510.21258'
source_url: https://arxiv.org/abs/2510.21258
tags:
- correlation
- dimension
- language
- text
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces correlation dimension, a fractal-geometric
  measure, to quantify the long-range structural complexity of text as perceived by
  autoregressive language models. The method computes recurrences in sequences of
  next-token log-probability vectors, capturing hierarchical recurrence structures
  that bridge local and global textual properties.
---

# Correlation Dimension of Auto-Regressive Large Language Models

## Quick Facts
- arXiv ID: 2510.21258
- Source URL: https://arxiv.org/abs/2510.21258
- Reference count: 40
- Primary result: Introduces correlation dimension to quantify long-range structural complexity of text as perceived by autoregressive LLMs, revealing three training phases, detecting degeneration modes, and indicating hallucination tendencies.

## Executive Summary
This paper introduces correlation dimension, a fractal-geometric measure, to quantify the long-range structural complexity of text as perceived by autoregressive language models. The method computes recurrences in sequences of next-token log-probability vectors, capturing hierarchical recurrence structures that bridge local and global textual properties. Experiments reveal three distinct training phases in LLMs, show context-dependent complexity, indicate hallucination tendencies, and detect multiple degeneration modes (repetition, incoherence, blandness) beyond perplexity. Correlation dimension is computationally efficient, robust to 4-bit quantization, and applicable across architectures like Transformer and Mamba.

## Method Summary
The method extracts next-token log-probability vectors from autoregressive models, computes pairwise Euclidean distances, and counts pairs within distance thresholds to obtain the correlation integral S(ε). The correlation dimension is estimated as the slope of log S(ε) vs log ε in the valid range [20/(N(N−1)), 1.0]. For long sequences, a moving-window approach with fixed context is used; for short sequences, unlimited context. Vocabulary reduction via modulo projection (v≈10,000) provides ~10× speedup with minimal accuracy loss. The method requires FP32 precision for distance computation even with quantized models.

## Key Results
- Correlation dimension reveals three distinct training phases: initial bigram learning, long-range dependency emergence, and context compression
- Dimension ~6.5 for natural language, drops to ~2 for repetitive patterns, and varies with context dependence
- Models with dimension <5.0 consistently hallucinate on knowledge-intensive texts
- Detects degeneration modes (repetition, incoherence, blandness) that perplexity misses

## Why This Works (Mechanism)

### Mechanism 1: Log-Probability Recurrence Structures Capture Hierarchical Text Complexity
- Claim: Correlation dimension computed from next-token log-probability vectors reveals self-similar recurrence patterns that bridge local token-level predictions and global textual structure.
- Mechanism: The method computes Euclidean distances between log-probability vectors x_t across time, counting pairs within threshold ε (correlation integral S(ε)). Self-similar systems exhibit power-law scaling S(ε) ∝ ε^d, where d is the correlation dimension. This captures "textual skips" — if states x_s and x_t are close, the segment between them could theoretically be omitted without significantly altering generation.
- Core assumption: Next-token probability vectors alone encode sufficient long-term structural information; time-delayed embeddings offer negligible improvement (validated empirically in Appendix E).
- Evidence anchors:
  - [abstract] "captures the hierarchical recurrence structure of language, bridging local and global properties"
  - [Section 3, Definition 1] Formal correlation integral definition; Figure 1(d) shows consistent dimension ~7 across Transformer and Mamba architectures
  - [corpus] Weak direct support; "Geometry-induced Regularization" paper discusses local geometry in neural networks but doesn't address recurrence-based measures
- Break condition: If log-probability vectors become dominated by noise (e.g., extremely rare tokens with unstable probabilities), dimension estimates diverge; vocabulary reduction (Appendix B.2) mitigates this.

### Mechanism 2: Three-Phase Training Dynamics Reveal Nonlinear Generalization
- Claim: Pre-training exhibits three distinct phases detectable via correlation dimension but invisible to perplexity.
- Mechanism: (1) Initial rapid dimension drop as models learn bigram-level structures; (2) dimension increase as longer-range dependencies emerge; (3) gradual decline via context compression indicating improved generalization. Smaller models (Pythia-14M, 160M) show inverted third phase with sudden dimension increase correlating with in-context learning failure.
- Core assumption: The three-phase pattern generalizes beyond the Pythia family where early checkpoints were available; other models only showed the third phase.
- Evidence anchors:
  - [abstract] "reveals three distinct phases during pretraining"
  - [Section 4.3, Figure 5] Clear three-stage evolution for Pythia; Figure 5(b) shows correlation between dimension spike and ICL accuracy drop
  - [corpus] No direct corpus support for training phase detection mechanisms
- Break condition: Models with insufficient capacity skip the beneficial third phase; dimension spike near training end signals generalization failure.

### Mechanism 3: Dimensional Collapse Signals Degeneration and Hallucination
- Claim: Text degeneration (repetition, incoherence, blandness) manifests as collapse from high-dimensional trajectories to low-dimensional attractors; hallucination correlates with lower dimension on knowledge-intensive text.
- Mechanism: Normal text maintains dimension ~6.5; repetitive patterns collapse to ~2; incoherent/bland text shows intermediate drops. Models recalling factual knowledge engage long-range dependencies (high dimension), while hallucination relies on format-level imitation (low dimension).
- Core assumption: The hallucination-dimension relationship observed on "process-theism" generalizes to other knowledge-intensive contexts.
- Evidence anchors:
  - [abstract] "reliably detects multiple forms of degeneration in generated text"
  - [Section 4.4, Table 1] Models with dimension <5.0 hallucinated; Section 5.2, Table 4 shows statistically significant dimension drops (p < 0.01) for all degeneration types
  - [corpus] No corpus support for hallucination detection via geometric measures
- Break condition: Numerical errors at very small ε thresholds for highly repetitive patterns; restrict ε range (Appendix A).

## Foundational Learning

- Concept: **Correlation dimension from chaos theory**
  - Why needed here: Core mathematical foundation — quantifies how recurrence frequency scales with distance threshold in phase space reconstructions
  - Quick check question: Given S(ε) ∝ ε^d with S(0.01) = 100 and S(0.1) = 1000, what is d? (Answer: log(10)/log(10) = 1)

- Concept: **Takens' embedding theorem and sufficiency of partial observations**
  - Why needed here: Explains why single-step log-probabilities suffice without time-delayed embeddings; Appendix E validates empirically
  - Quick check question: Why might next-token probabilities alone encode long-range structure? (Hint: knowledge distillation literature)

- Concept: **LLM autoregressive probability distributions**
  - Why needed here: Understanding what log-probability vectors represent — distributions over vocabulary conditioned on context
  - Quick check question: What is x_t(ω) in Equation 3, and why use log-space?

## Architecture Onboarding

- Component map:
  1. Log-probability extraction: Hook into model's forward pass to capture P_θ(ω_t|ω_{<t}) for all ω ∈ Ω
  2. Distance computation: Pairwise Euclidean distances between log-prob vectors; use fused kernel (Algorithm 1) to avoid O(N²) memory
  3. Correlation integral: Count pairs within each threshold ε; accumulate counts via atomic operations
  4. Dimension estimation: Linear regression on log S(ε) vs log ε over valid range [20/N(N-1), η]

- Critical path:
  1. Ensure FP32 precision for distance computation even with quantized models (Section 6, Appendix B.3)
  2. Apply vocabulary reduction ψ_v: R^Ω → R^v (v ≈ 10,000) using modulo-based projection (Equation 5)
  3. Use moving-window approach for long sequences exceeding context limits; full-context for short sequences

- Design tradeoffs:
  - Context length: Longer context → initial dimension increase → convergence; very short context → bigram approximation (dimension ~3)
  - Vocabulary reduction: v=10,000 gives ~10× speedup with <2% dimension error; v<1,000 introduces bias
  - Sequence length: N < 500 requires adjusting η parameter to maintain sufficient slope estimation range

- Failure signatures:
  - Dimension > 10: Likely random/shuffled text or model failure on long-range structure
  - Dimension < 2 on normal text: Check for numerical precision issues at small ε; restrict range
  - Large dimension variance across similar texts: Check model quantization or context truncation inconsistencies

- First 3 experiments:
  1. Validation on SEP dataset: Compute dimension for 3+ articles using a pretrained model (e.g., Qwen2.5-7B); verify values cluster near 6.5
  2. Repetition detection: Generate explicit repetitive patterns ("01", "ab"); confirm dimension drops to ~2
  3. Training checkpoint analysis: If checkpoint access available, plot dimension vs perplexity across training; verify three-phase pattern

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the formal theoretical guarantees for correlation dimension estimation from finite sequences, and how do estimation biases scale with sequence length and vocabulary size?
- Basis in paper: [explicit] The conclusion states "Future work includes formal analysis of estimation properties."
- Why unresolved: The paper provides only empirical convergence observations (Section 3.2) without formal analysis of when and why estimation stabilizes.
- What evidence would resolve it: Theoretical bounds on estimation error; systematic experiments varying sequence length, vocabulary size, and dimension.

### Open Question 2
- Question: Can correlation dimension be extended to conditional generation settings and multi-modal models (e.g., vision-language models)?
- Basis in paper: [explicit] The conclusion explicitly identifies "extensions to conditional or multi-modal settings" as future work.
- Why unresolved: Current method assumes autoregressive text-only generation; conditional settings introduce additional state variables.
- What evidence would resolve it: Successful application to conditional text generation (prompted tasks) and multi-modal domains with interpretable dimension values.

### Open Question 3
- Question: Why does natural language exhibit a correlation dimension of approximately 6.5 across diverse languages and model architectures?
- Basis in paper: [inferred] Section 3.2 and Appendix C.2 report consistent ~6.5 values across 8 languages and multiple architectures, but no theoretical explanation is offered.
- Why unresolved: The universality suggests a fundamental property of natural language structure, but the underlying mechanism remains unclear.
- What evidence would resolve it: Theoretical analysis linking linguistic hierarchy depth, syntax tree properties, or information-theoretic measures to the 6.5 value.

### Open Question 4
- Question: What causes the three-stage evolution pattern during pretraining, and why do smaller models fail to reach the third compression stage?
- Basis in paper: [inferred] Section 4.3 documents this pattern but does not explain the mechanism behind stage transitions or why smaller models show sudden dimension increases instead of compression.
- Why unresolved: The correlation with in-context learning degradation is observed but not causally explained.
- What evidence would resolve it: Layer-wise analysis during training; experiments controlling model capacity and data scale to isolate causal factors.

## Limitations

- Hallucination detection claims rest on a single case study with "process-theism" text, raising concerns about overfitting to specific knowledge-intensive domains.
- The three-phase training dynamics were only observed in Pythia models with early checkpoint access; the pattern may not generalize to other architectures.
- The method relies on next-token probability distributions as sufficient observables, but this assumption lacks theoretical grounding from chaos theory literature.

## Confidence

**High Confidence**: The computational method for correlation dimension is well-defined and reproducible. Claims about degeneration detection (repetition, incoherence, blandness) are supported by statistically significant results across multiple model families and degeneration types. The method's computational efficiency and robustness to 4-bit quantization are empirically validated.

**Medium Confidence**: The three-phase training dynamics claim requires broader validation beyond Pythia models. The hypothesis that correlation dimension captures hierarchical text complexity through log-probability recurrence structures is mechanistically plausible but lacks rigorous mathematical justification. Context-dependent complexity findings show promising results but need larger-scale validation.

**Low Confidence**: Hallucination detection claims based on single-domain case studies lack sufficient evidence. The generalizability of the ~6.5 dimension value for natural language across all languages and domains remains unproven. Claims about dimension's superiority over perplexity for detecting degeneration modes need more systematic comparison.

## Next Checks

1. **Cross-linguistic validation**: Compute correlation dimension for 10+ languages across different language families (e.g., Indo-European, Sino-Tibetan, Afro-Asiatic) using multilingual models like mBERT or XGLM. Verify whether dimension values consistently cluster around 6.5 or show systematic variations by language type, and test whether the dimension remains stable across translation equivalents.

2. **Hallucination detection generalization**: Create a systematic hallucination benchmark with 50+ knowledge-intensive prompts spanning diverse domains (scientific, historical, technical). Generate responses from multiple models with varying hallucination propensities, annotate ground truth factual accuracy, and test whether correlation dimension below threshold 5.0 consistently predicts hallucination across all domains and model families.

3. **Time-delayed embedding comparison**: Implement the proposed time-delayed embedding approach and systematically compare correlation dimension estimates against the single-step method across 100+ diverse texts. Quantify the difference in dimension values and test whether the improvement in capturing long-range dependencies justifies the increased computational cost, particularly for texts with known complex hierarchical structures.