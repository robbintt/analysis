---
ver: rpa2
title: 'Large Language Models for Combinatorial Optimization: A Systematic Review'
arxiv_id: '2507.03637'
source_url: https://arxiv.org/abs/2507.03637
tags:
- optimization
- llms
- arxiv
- problem
- research
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic review consolidates current research on using large
  language models (LLMs) for combinatorial optimization (CO). It analyzes 103 studies
  across problem modeling, solution methods, validation, and benchmarking.
---

# Large Language Models for Combinatorial Optimization: A Systematic Review

## Quick Facts
- **arXiv ID:** 2507.03637
- **Source URL:** https://arxiv.org/abs/2507.03637
- **Reference count:** 40
- **Key outcome:** This systematic review consolidates current research on using large language models (LLMs) for combinatorial optimization (CO), analyzing 103 studies across problem modeling, solution methods, validation, and benchmarking.

## Executive Summary
This systematic review provides a comprehensive analysis of how large language models are being applied to combinatorial optimization problems. Through a PRISMA 2020 methodology, the authors identified 103 studies from an initial corpus of 2,044 records, focusing on applications published between 2016-2024. The review reveals that LLMs are primarily used for code generation (36 studies) and solution generation (28 studies), with significant focus on linear and mixed-integer programming formulations and routing problems. Popular LLM architectures include GPT-4, LLaMA 2, and Claude, while benchmark datasets like NL4Opt and ComplexOR are widely adopted.

## Method Summary
The study employed a systematic literature review methodology using PRISMA 2020 guidelines, conducting database searches on Scopus and Google Scholar with 14 specific queries. After removing duplicates (488 records) and applying screening criteria, 103 studies were selected for full-text analysis. The review categorized papers by task type (modeling, solution generation), LLM architecture, and application domains, while also examining evaluation methods and benchmarking practices.

## Key Results
- LLMs are most commonly applied to code generation (36 studies) and solution generation (28 studies) tasks
- LP/MILP formulations dominate the problem space with 38 studies, followed by routing problems (28 studies)
- GPT-4, LLaMA 2, and Claude are the most frequently used LLM architectures
- Benchmark datasets NL4Opt and ComplexOR are the primary evaluation platforms

## Why This Works (Mechanism)

### Mechanism 1: Semantic Mapping via Intermediate Formalisms
LLMs automate problem modeling by translating Natural Language descriptions into formal mathematical representations (e.g., LP, MILP) or solver code. The LLM utilizes pre-trained semantic knowledge to identify entities and constraints in text, mapping them to domain-specific languages like Pyomo or MiniZinc. This works because the LLM predicts the formulation of the problem, not the numerical solution. Fails when problem descriptions are ambiguous or contain logical contradictions that the LLM hallucinates over.

### Mechanism 2: Evolutionary Heuristic Discovery (Reflective Search)
LLMs can act as mutation and crossover operators within Evolutionary Algorithms to iteratively discover high-performance heuristics. Instead of human-designed heuristics, the LLM generates code for a heuristic (e.g., scoring function for TSP), executes it, evaluates fitness, and uses the result as context to generate improved versions. Breaks if the LLM fixates on local optima or if generated code consistently fails to compile.

### Mechanism 3: Constraint Satisfaction via Self-Validation
LLMs can improve solution feasibility by acting as validation agents that diagnose infeasible constraints in mixed-integer models. The LLM analyzes constraints and infeasible solver status, using semantic understanding to trace logical conflicts and suggest relaxations or repairs. Fails when interaction is not conversational or requires deep mathematical proof beyond the LLM's context window.

## Foundational Learning

- **Concept: Combinatorial Optimization Paradigms (LP/MILP/CP)**
  - Why needed: Review identifies majority of studies focus on LP and MILP. Engineers must distinguish between linear relaxations and discrete constraints to select right solver.
  - Quick check: Can you explain why a scheduling problem typically requires Integer Linear Programming (ILP) rather than simple Linear Programming (LP)?

- **Concept: Prompt Engineering for Code Generation**
  - Why needed: Effectiveness of Mechanism 1 depends on LLM receiving structured instructions specifying target language and output format.
  - Quick check: How would you modify a prompt to ensure an LLM generates Pyomo code rather than textual description?

- **Concept: Evaluation Metrics (Optimality Gap vs. Feasibility)**
  - Why needed: LLM-generated solutions often lack optimality guarantees. Engineers must rely on metrics like optimality gap relative to benchmark.
  - Quick check: If an LLM generates feasible solution with 15% optimality gap, is it considered success or failure for NP-hard problems?

## Architecture Onboarding

- **Component map:** Input Layer (NL Problem Description) -> Translation Agent (LLM: GPT-4o, LLaMA 3) -> Entity Recognition and Model Formulation -> Execution Engine (Solver: OR-Tools, Gurobi) -> Feedback Loop (Optimality Gap/Feasibility Report)

- **Critical path:**
  1. Prompt Construction: Constrain LLM to output code rather than text
  2. Code Execution: Run LLM-generated code in sandboxed environment
  3. Validation: Check for runtime errors and constraint violations before objective value

- **Design tradeoffs:**
  - Closed vs. Open Source Models: GPT-4 (closed) offers better reasoning for complex formulations; LLaMA (open) allows fine-tuning on domain-specific optimization data
  - Direct Solution vs. Code Gen: Direct solution generation is faster but prone to hallucination; code generation is slower but leverages traditional solver robustness

- **Failure signatures:**
  - Syntactic Hallucination: LLM generates code importing non-existent libraries
  - Semantic Drift: Generated model satisfies constraints but optimizes wrong objective function
  - Solver Timeout: Formulation correct but computationally explosive

- **First 3 experiments:**
  1. Baseline Translation: Input simple LP problem into GPT-4o, ask for Pyomo code, measure compilation success rate
  2. Reflexive Debugging: Provide logically inconsistent problem description, ask LLM to identify conflicting constraints
  3. Heuristic Evolution: Implement evolutionary loop where LLM generates TSP heuristic and iteratively improves based on tour length

## Open Questions the Paper Calls Out

- How can standardized evaluation protocols and metrics be developed to robustly assess LLM performance on Combinatorial Optimization Problems given variations in problem representations and lack of known optimal solutions?
- To what extent can LLMs enhance metaheuristic frameworks by dynamically adjusting search strategies or expanding local search neighborhoods based on real-time optimization state?
- How can autonomous, multi-agent LLM systems be effectively designed and utilized for Combinatorial Optimization, and do they offer significant advantages over single-LLM approaches?
- What methodological frameworks can establish transparency and replicability of research findings derived from closed-source, proprietary LLMs?

## Limitations

- Coverage limited by publication bias with most studies from preprint servers and journals, potentially missing industry implementations
- Temporal limitations: search cutoff (January 2025) excludes rapid post-2024 developments in LLM capabilities
- Methodological heterogeneity across included studies makes direct performance comparison challenging due to varying evaluation metrics and problem formulations

## Confidence

- **High confidence:** Mapping of LLM applications to combinatorial optimization tasks (code generation, solution generation) based on clear frequency counts
- **Medium confidence:** Architectural analysis (GPT-4, LLaMA 2 prevalence) due to potential search bias toward well-documented models
- **Low confidence:** Generalization of solution quality claims as most studies use problem-specific benchmarks rather than standardized evaluation frameworks

## Next Checks

1. Replicate classification of random sample (n=10) of 103 studies to verify task categorization accuracy
2. Execute generated code from representative studies on NL4Opt benchmark to validate code generation mechanism
3. Compare optimality gaps across studies using standardized metrics to assess validity of performance claims in Section 6.2.1