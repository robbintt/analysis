---
ver: rpa2
title: Mitigating Visual Hallucinations via Semantic Curriculum Preference Optimization
  in MLLMs
arxiv_id: '2509.24491'
source_url: https://arxiv.org/abs/2509.24491
tags:
- preference
- visual
- curriculum
- alignment
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper proposes SCPO, a novel framework for mitigating visual
  hallucinations in multimodal large language models (MLLMs). SCPO addresses the limitations
  of existing preference optimization methods by introducing three key innovations:
  a semantic curriculum preference pairs dataset that provides fine-grained semantic
  contrasts organized by difficulty, a symmetric and bidirectional optimization objective
  that enforces robust vision-language alignment, and a dynamic curriculum-based training
  strategy with iterative reference model updates.'
---

# Mitigating Visual Hallucinations via Semantic Curriculum Preference Optimization in MLLMs

## Quick Facts
- **arXiv ID**: 2509.24491
- **Source URL**: https://arxiv.org/abs/2509.24491
- **Reference count**: 40
- **Primary result**: SCPO framework reduces visual hallucinations by up to 62.9% while preserving general capabilities in MLLMs

## Executive Summary
This paper introduces SCPO (Semantic Curriculum Preference Optimization), a novel framework designed to address visual hallucinations in multimodal large language models (MLLMs). The method tackles the fundamental challenge of maintaining robust vision-language alignment while preventing the generation of factually incorrect or fabricated visual content. SCPO introduces a curriculum-based approach that progressively refines model preferences through semantically organized training data, achieving state-of-the-art performance on hallucination benchmarks across multiple model scales.

## Method Summary
SCPO addresses visual hallucinations through a three-pronged approach: (1) a semantic curriculum preference pairs dataset that provides fine-grained semantic contrasts organized by difficulty levels, (2) a symmetric and bidirectional optimization objective that enforces robust vision-language alignment, and (3) a dynamic curriculum-based training strategy with iterative reference model updates. The framework operates by training models to distinguish between semantically similar but factually distinct visual-text pairs, gradually increasing complexity as training progresses. This curriculum-based approach allows models to develop nuanced understanding of visual semantics while maintaining general multimodal capabilities.

## Key Results
- Reduces hallucination rates by up to 62.9% across multiple model scales
- Demonstrates state-of-the-art performance on hallucination benchmarks
- Improves factuality without compromising overall model performance on generalized benchmarks

## Why This Works (Mechanism)
SCPO works by creating a structured learning environment where models learn to distinguish between semantically similar but factually different visual-text pairs. The curriculum approach ensures models first master basic semantic distinctions before tackling more complex ones, building robust vision-language alignment progressively. The bidirectional optimization enforces consistency in both directions of semantic understanding, preventing the model from developing directional biases that could lead to hallucinations.

## Foundational Learning
- **Multimodal alignment**: Understanding how vision and language modalities integrate in MLLMs
- **Preference optimization**: Learning how models can be trained to prefer certain outputs over others
- **Curriculum learning**: The strategy of ordering training examples by difficulty
- **Semantic contrast**: The ability to distinguish between similar but distinct semantic meanings
- **Bidirectional optimization**: Training objectives that work in both directions of the model's reasoning

## Architecture Onboarding

**Component Map**
Semantic Curriculum Dataset -> Bidirectional Optimization Engine -> Dynamic Curriculum Manager -> Iterative Reference Model Updates

**Critical Path**
Data preparation → Curriculum difficulty assessment → Bidirectional optimization → Reference model update → Performance evaluation

**Design Tradeoffs**
- Computational overhead vs. hallucination reduction
- Curriculum complexity vs. training stability
- Bidirectional enforcement vs. training efficiency

**Failure Signatures**
- Curriculum collapse (all examples become equally difficult)
- Optimization instability (oscillating performance)
- Reference model drift (iterative updates diverge)

**First 3 Experiments**
1. Test baseline hallucination rates on standard MLLM without SCPO
2. Evaluate semantic curriculum effectiveness on a small model scale
3. Measure bidirectional optimization impact on vision-language alignment

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses primarily on benchmark datasets rather than real-world deployment scenarios
- Semantic curriculum preference pairs dataset not publicly released for independent verification
- Computational overhead during inference not thoroughly investigated
- Long-term stability of iterative reference model updates remains unclear

## Confidence

**High Confidence**: Core methodology is technically sound with consistent improvements across model scales

**Medium Confidence**: Claims about preserving general capabilities are supported but could use broader evaluation

**Low Confidence**: "State-of-the-art" claims are somewhat overstated as they focus on hallucination-specific metrics

## Next Checks
1. Conduct long-term stability analysis extending iterative reference model updates across 2-3x current training duration
2. Perform comprehensive ablation study on semantic curriculum components to quantify individual contributions
3. Implement real-world deployment test using SCPO-enhanced models on live, user-generated multimodal content