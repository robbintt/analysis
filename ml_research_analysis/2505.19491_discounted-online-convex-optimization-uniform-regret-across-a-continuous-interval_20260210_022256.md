---
ver: rpa2
title: 'Discounted Online Convex Optimization: Uniform Regret Across a Continuous
  Interval'
arxiv_id: '2505.19491'
source_url: https://arxiv.org/abs/2505.19491
tags:
- discounted
- regret
- discount
- algorithm
- factor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses discounted online convex optimization (OCO)\
  \ where the learner must minimize a loss function while forgetting past data through\
  \ a discount factor \u03BB. The challenge is to develop an algorithm that adapts\
  \ to an unknown discount factor \u03BB across a continuous interval [1-1/\u03C4\
  , 1-1/T], where \u03C4 is a minimal window length and T is the total number of rounds."
---

# Discounted Online Convex Optimization: Uniform Regret Across a Continuous Interval

## Quick Facts
- arXiv ID: 2505.19491
- Source URL: https://arxiv.org/abs/2505.19491
- Reference count: 9
- Primary result: Achieves O(√log T / (1-λ)) uniform discounted regret across continuous interval [1-1/τ, 1-1/T] without knowing λ

## Executive Summary
This paper addresses discounted online convex optimization where the learner must minimize loss while forgetting past data through a discount factor λ. The key challenge is adapting to an unknown discount factor λ across a continuous interval [1-1/τ, 1-1/T]. The authors propose a meta-expert framework that discretizes the discount factor interval and uses a sequential aggregation method called Discounted-Normal-Predictor with conservative updating (DNP-cu). This enables combining experts optimized for different discount factors, achieving uniform O(√log T / (1-λ)) discounted regret across all λ in the interval simultaneously.

## Method Summary
The method uses a geometric discretization of the continuous discount factor interval [1-1/τ, 1-1/T] into N+1 values λi = 1 - 2^(i-1)/T. For each λi, an OGD instance with optimal step size ηi = (D/G)√(2^i/T) is created. These experts are sequentially aggregated using DNP-cu, where each Combiner Bi aggregates Bi-1 and OGD instance Ai. The key insight is that DNP-cu can provide guarantees when combining experts with different discount factors, enabling adaptation to the unknown λ. The algorithm maintains O(log T) parallel instances and achieves uniform regret bounds through a convex combination argument.

## Key Results
- Achieves O(√log T / (1-λ)) uniform discounted regret across all λ ∈ [1-1/τ, 1-1/T]
- Overcomes limitations of standard meta-expert methods that require unified performance measures
- Provides √log T overhead factor compared to knowing λ in advance
- Requires minimal window size τ ≥ max{16e, 32 log T} for theoretical guarantees

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** OGD with constant step size achieves optimal λ-discounted regret when λ is known
- **Mechanism:** The update wt+1 = ΠW[wt − η∇ft(wt)] with step size η = D√(2(1−λ))/G balances accumulated weighted error against geometric decay of past gradients
- **Core assumption:** Convex loss functions, bounded gradients (||∇ft(w)|| ≤ G), bounded domain diameter (||w−w'|| ≤ D)
- **Evidence anchors:**
  - [Section 3.1, Theorem 1]: "OGD satisfies Σλ^(T−t)ft(wt) − Σλ^(T−t)ft(w) ≤ DG√(2/√(1−λ))"
  - [Page 11, Proof]: Shows step size η = D√(2(1−λ))/G achieves optimal bound
  - [Corpus]: Paper 65956 on "Time-Varying Optimization for Streaming Data" discusses temporal weighting but doesn't address unknown discount factors

### Mechanism 2
- **Claim:** DNP-cu can aggregate two experts operating under different discount factors λ1 and λ2, provided λ1 ≥ λ2
- **Mechanism:** DNP-cu maintains discounted deviation xt = Σρ^(t−1−j)bj and outputs confidence g(xt). When operating with discount factor ρ, DNP-cu provides guarantees for any η ≥ ρ
- **Core assumption:** Bit sequence bt = (ft(wt,1) − ft(wt,2))/(GD) ∈ [−1,1], and ordering constraint λ1 > λk for all subsequent aggregations
- **Evidence anchors:**
  - [Page 8, Theorem 2, Eq. 13]: "Ση^(T−t)g(xt)bt ≥ −Z/(2(1−η)) for any η ≥ ρ"
  - [Page 9, Section 3.2]: Shows how to combine two OGD algorithms with λ1, λ2 using DNP-cu with ρ = λ2
  - [Corpus]: Paper 41073 on "hierarchical VAW forecaster with discounting" uses similar hierarchical aggregation but for online regression, not OCO with unknown λ

### Mechanism 3
- **Claim:** Sequential aggregation of N = ⌈log2(T/τ)⌉ OGD instances achieves uniform discounted regret across all λ ∈ [1−1/τ, 1−1/T]
- **Mechanism:** Geometric series discretization S = {1−1/T, 1−2/T, ..., 1−2^N/T} enables sequential aggregation where each Combiner Bi aggregates Bi−1 and OGD instance Ai with matching λi
- **Core assumption:** Minimal window size τ ≥ max{16e, 32 log(1/Z)} ensures DNP-cu preconditions are satisfied
- **Evidence anchors:**
  - [Page 10, Theorem 3]: "SOGG achieves O(√(log T/(1−λ))) for all λ ∈ [1−1/τ, 1−1/T]"
  - [Page 14, Lemma 2]: "λ1-smoothed average is a convex combination of λ2-smoothed average for λ1 > λ2"
  - [Corpus]: Paper 1600 on "OCO with Memory" addresses related temporal dependencies but through predictions, not discount factor adaptation

## Foundational Learning

- **Concept: Discounted Regret**
  - Why needed here: Standard static regret fails in non-stationary environments where past data becomes obsolete. Discounted regret weights recent losses exponentially more, enabling graceful forgetting with effective window size ≈ 1/(1−λ)
  - Quick check question: Given λ = 0.95, what fraction of total weight do the most recent 20 rounds receive compared to all 100 rounds? (Answer: Σ_{t=81}^{100} 0.95^(100−t) / Σ_{t=1}^{100} 0.95^(100−t) ≈ 0.64)

- **Concept: Meta-Expert Framework Limitations**
  - Why needed here: Standard adaptive methods (Hedge, Fixed-Share) require all experts and meta-algorithm to operate under unified performance measures. Discounted regret with unknown λ creates fundamental mismatch—each expert optimized for different λ operates under different evaluation criteria
  - Quick check question: Why can't Hedge combine experts minimizing λ1-discounted regret and λ2-discounted regret directly? (Answer: Hedge's analysis requires a shared loss sequence; discounted losses with different λ values are incomparable without normalization.)

- **Concept: Conservative Updating Rule**
  - Why needed here: DNP-cu's update rule only incorporates bt when |xt| < U(n) or g(xt)bt < 0 (low confidence or incorrect prediction). This prevents deviation xt from growing unboundedly under discounted payoffs, which is essential for maintaining O(Z/(1−ρ)) meta-regret
  - Quick check question: Under what condition does DNP-cu skip incorporating bt into the deviation update? (Answer: When |xt| ≥ U(n) AND g(xt)bt ≥ 0, meaning high confidence and correct prediction.)

## Architecture Onboarding

- **Component map:**
  - OGD Expert Ai -> Combiner Bi -> Combiner Bi+1 -> ... -> Final output wt

- **Critical path:**
  1. Initialize N + 1 = ⌈log2(T/τ)⌉ + 1 OGD instances with geometric step sizes
  2. Initialize N + 1 Combiner instances in descending discount factor order (λ1 > λ2 > ... > λN+1)
  3. At each round t: sequentially activate B1, B2, ..., BN+1, passing loss ft to each OGD expert and bit ℓt,i = (ft(vt,i−1) − ft(wt,i))/(GD) to each DNP-cu
  4. Output final prediction wt = vt,N+1
  5. Verify minimal window constraint: τ ≥ max{16e, 32 log T}

- **Design tradeoffs:**
  - **Number of experts N vs. regret overhead**: More experts (larger N) provide finer granularity on λ but increase aggregation overhead to O(GD(N+1)Z/(1−λ)). Paper sets N ≈ log(T/τ) as optimal
  - **Z parameter vs. regret bound**: Smaller Z reduces the Z/(2(1−η)) term but increases U(n) threshold. Z = 1/T balances these
  - **Discretization scheme vs. continuous coverage**: Geometric spacing (2^(i−1)/T) provides O(2) coverage ratio between adjacent λ values, ensuring the Lemma 2 extension works

- **Failure signatures:**
  - **Excessive memory growth**: Each DNP-cu maintains xt requiring O(log T) memory per instance. If N scales with T rather than log T, memory becomes O(T)
  - **Ordering violation**: If Combiners are initialized in ascending λ order (λ1 < λ2 < ...), the key inequality λi > λk for k > i fails, breaking Theorem 2's application
  - **Insufficient τ**: If τ < max{16e, 32 log T}, DNP-cu's n = 1/(1−λN+1) = T/2^N falls below required thresholds, invalidating regret guarantees
  - **Unbounded deviation**: If conservative updating is disabled (always use xt+1 = ρxt + bt), xt can grow to O(T), breaking the O(Z/(1−ρ)) meta-regret bound

- **First 3 experiments:**
  1. **Validation on known λ**: Implement OGD with optimal step size for fixed λ ∈ {0.9, 0.95, 0.99} on synthetic convex losses. Verify regret matches Theorem 1's O(1/√(1−λ)) bound empirically by plotting regret vs. (1−λ)^(-1/2)
  2. **SOGD on unknown λ**: Implement full SOGD with τ = 100, T = 10,000. For each ground-truth λ ∈ {0.9, 0.95, 0.99, 0.995}, compare SOGD's regret against oracle OGD that knows λ. Verify the O(√log T) overhead factor
  3. **Ablation on expert ordering**: Swap Combiner order to ascending λ. Measure regret degradation—expect violation of cross-discount guarantees when λ1 < λk for downstream aggregations. This confirms the ordering mechanism

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Is the additional $\sqrt{\log T}$ factor in the regret bound necessary for adapting to an unknown discount factor?
- **Basis in paper:** [Inferred] Theorem 3 achieves an $O(\sqrt{\log T / (1-\lambda)})$ bound, whereas Theorem 1 achieves $O(1/\sqrt{1-\lambda})$ with prior knowledge. The authors acknowledge this gap as the "cost of adaptivity" but do not establish if it is tight
- **Why unresolved:** The paper provides upper bounds but no lower bounds for the uniform regret setting
- **What evidence would resolve it:** A lower bound proof showing $\Omega(\sqrt{\log T})$ is required, or a new algorithm closing the gap

### Open Question 2
- **Question:** Can this uniform regret guarantee be extended to unknown, time-varying discount factors?
- **Basis in paper:** [Inferred] The Introduction highlights that prior work (Zhang et al., 2024) handled time-varying factors but required prior knowledge. This paper solves the unknown case for fixed factors, leaving the intersection of these challenges open
- **Why unresolved:** The current analysis relies on the discount factor remaining fixed to ensure consistency across the sequential aggregation of experts
- **What evidence would resolve it:** An analysis of DNP-cu or a new meta-algorithm that tracks the best expert under shifting discount regimes

### Open Question 3
- **Question:** Is it possible to achieve uniform regret without maintaining $O(\log T)$ parallel algorithm instances?
- **Basis in paper:** [Inferred] Section 3.2 and Algorithm 4 require discretizing the discount interval and maintaining $N = \lceil \log_2(T/\tau) \rceil$ OGD instances, which increases computational overhead
- **Why unresolved:** The paper relies on a meta-expert framework, which typically necessitates such discretization
- **What evidence would resolve it:** A single-instance algorithm or a method with $O(1)$ complexity that adapts continuously to the effective window size

## Limitations

- The O(√log T) overhead factor, while theoretically optimal for continuous intervals, can be significant for moderate T values
- Requires careful calibration of the confidence threshold U(n) and conservative updating parameters in DNP-cu
- Assumes bounded gradients and convex loss functions, which may not hold in all practical settings
- The geometric discretization scheme provides O(2) coverage between adjacent λ values, potentially leaving gaps in coverage

## Confidence

- **Mechanism 1 (OGD with known λ): High** - Well-established result in online convex optimization literature
- **Mechanism 2 (DNP-cu cross-discount aggregation): Medium** - Theoretical foundation sound but practical implementation requires precise calibration
- **Mechanism 3 (Sequential aggregation achieving uniform regret): High** - Proof follows logically from geometric discretization and convex combination argument

## Next Checks

1. **Numerical Stability Validation**: Implement the confidence function g(x) and verify it produces bounded outputs for the expected range of x values encountered during aggregation. Test with extreme cases where x/√n becomes large to ensure erf(x/√(8n)) doesn't cause numerical overflow.

2. **Ordering Constraint Verification**: Create a synthetic experiment where Combiners are deliberately initialized in ascending λ order (violating the required λ1 > λ2 > ... constraint). Measure the regret degradation compared to the correct descending order to empirically confirm the importance of the ordering mechanism.

3. **Coverage Gap Analysis**: For a specific discretization with N = 5 experts, compute the exact λ values covered and identify any λ ∈ [1−1/τ, 1−1/T] that falls between adjacent geometric points. Measure the approximation error when using the nearest expert's regret bound for these uncovered λ values.