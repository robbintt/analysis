---
ver: rpa2
title: Precipitation nowcasting of satellite data using physically-aligned neural
  networks
arxiv_id: '2511.05471'
source_url: https://arxiv.org/abs/2511.05471
tags:
- tupann
- precipitation
- nowcasting
- data
- satellite
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces TUPANN, a satellite-only precipitation nowcasting
  model that uses physically aligned learning. Unlike most deep learning models for
  nowcasting, TUPANN explicitly decomposes the forecasting task into motion inference,
  latent dynamics evolution, and advection.
---

# Precipitation nowcasting of satellite data using physically-aligned neural networks

## Quick Facts
- arXiv ID: 2511.05471
- Source URL: https://arxiv.org/abs/2511.05471
- Reference count: 17
- Introduces TUPANN, a satellite-only precipitation nowcasting model using physically aligned learning

## Executive Summary
This work presents TUPANN, a precipitation nowcasting model that operates solely on satellite data without requiring ground-based observations or numerical weather prediction inputs. Unlike typical deep learning approaches, TUPANN explicitly decomposes the forecasting task into motion inference, latent dynamics evolution, and advection. The model employs a variational encoder-decoder supervised by optical flow to infer motion and intensity fields, a lead-time-conditioned MaxViT transformer to evolve latent states, and a differentiable advection operator to reconstruct future frames. Evaluated across four climate regimes at 10-180 minute lead times and thresholds of 4-64 mm/h, TUPANN achieves the best or second-best CSI and HSS scores in most settings, with pronounced gains at higher thresholds. The approach produces smooth, interpretable motion fields aligned with numerical optical flow and runs in near real time.

## Method Summary
TUPANN uses physically aligned learning to forecast precipitation from satellite data by decomposing the task into three components: motion inference, latent dynamics evolution, and advection. The model employs a variational encoder-decoder architecture trained with optical flow supervision to infer motion and intensity fields from satellite imagery. A lead-time-conditioned MaxViT transformer processes these latent representations to evolve them forward in time, while a differentiable advection operator reconstructs future precipitation frames. The model is evaluated on GOES-16 and IMERG satellite data across four cities (Rio de Janeiro, Manaus, Miami, La Paz) at various lead times and precipitation thresholds. Cross-city experiments assess generalizability, while multi-city training examines transfer learning capabilities.

## Key Results
- TUPANN achieves best or second-best CSI and HSS scores across most cities, thresholds, and lead times
- Model shows pronounced performance gains at higher precipitation thresholds (4-64 mm/h) compared to existing methods
- Cross-city experiments show modest degradation, while multi-city training improves performance
- Produces smooth, interpretable motion fields aligned with numerical optical flow
- Operates in near real-time with 4-minute latency

## Why This Works (Mechanism)
TUPANN's success stems from its explicit decomposition of the precipitation forecasting problem into physically meaningful components rather than treating it as a pure pattern recognition task. By separating motion inference from intensity evolution and advection, the model can learn interpretable representations that align with physical processes. The optical flow supervision ensures that motion fields capture realistic atmospheric dynamics, while the MaxViT transformer can focus on learning lead-time-dependent intensity changes without simultaneously learning advection. This physical alignment allows the model to generalize better across different geographic regions and precipitation regimes, as evidenced by its performance in diverse climate settings and cross-city experiments.

## Foundational Learning
- **Optical flow estimation**: Used to supervise motion field learning; needed because direct intensity prediction would obscure the advection process; quick check: compare learned flow fields against ground truth numerical optical flow
- **MaxViT transformer architecture**: Enables lead-time-conditioned processing of latent states; needed to capture complex temporal dependencies beyond simple persistence; quick check: ablate transformer vs. simpler recurrent alternatives
- **Differentiable advection operators**: Allows gradient-based training through the spatial transformation; needed because hard-wiring advection would prevent learning intensity evolution; quick check: compare against non-differentiable baseline
- **Variational inference**: Provides uncertainty quantification and regularizes the latent space; needed because precipitation forecasting involves inherent stochasticity; quick check: assess posterior collapse in ablation studies
- **Multi-scale feature extraction**: Captures both large-scale patterns and local details; needed because precipitation systems operate at multiple spatial scales; quick check: evaluate performance with different input resolutions

## Architecture Onboarding

**Component Map**: Satellite images -> Variational Encoder-Decoder (with optical flow loss) -> Motion and Intensity Latent Fields -> MaxViT Transformer (lead-time conditioned) -> Differentiable Advection -> Future Precipitation Frames

**Critical Path**: The most critical sequence is Satellite Images → Variational Encoder → Motion Field → Differentiable Advection → Future Precipitation, as errors in motion estimation directly propagate through advection to future frames.

**Design Tradeoffs**: The model trades off explicit physical modeling (requiring more complex architecture) against pure data-driven approaches (which may be simpler but less interpretable). The optical flow supervision adds computational overhead but produces more physically meaningful motion fields. The MaxViT transformer increases parameter count but enables better lead-time conditioning.

**Failure Signatures**: Model may fail during rapid convective development where intensity changes don't follow advection patterns. Optical flow supervision may produce incorrect motion estimates during occlusion or emergence of precipitation features. The transformer may struggle with very long lead times where temporal dependencies become too complex.

**First Experiments**:
1. Evaluate TUPANN on a simple synthetic dataset with known advection patterns to validate the motion inference component
2. Compare performance against a baseline that uses direct intensity prediction without motion decomposition
3. Test cross-city generalization by training on one city and evaluating on another with similar but distinct climate characteristics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can TUPANN generalize to other geostationary satellites (Himawari, Meteosat) without significant retraining?
- Basis in paper: [explicit] "The architecture should be retrained and validated on other geostationary satellites (e.g., Himawari, Meteosat) to ensure generalization across platforms."
- Why unresolved: The model was only evaluated on GOES-16 data; different satellites have different spatial resolutions, latency, and retrieval algorithms that may affect the learned motion and intensity representations.
- What evidence would resolve it: CSI/HSS scores from TUPANN trained and evaluated on Himawari or Meteosat precipitation products, compared against the same baselines used in this study.

### Open Question 2
- Question: How can adversarial training be stabilized to simultaneously improve visual realism and quantitative skill metrics?
- Basis in paper: [explicit] "GAN-based enhancements improve visual realism but degrade or inconsistently affect skill metrics; stabilizing adversarial training and assessing perceptual quality remain open challenges."
- Why unresolved: GAN-TUPANN showed mixed results—improving low-threshold CSI in Rio but degrading performance in Miami and other cities, indicating instability in the adversarial training objective.
- What evidence would resolve it: A modified GAN loss or training procedure that consistently improves or maintains CSI across all thresholds and regions while producing sharper predictions.

### Open Question 3
- Question: What additional physical covariates could improve motion field estimation for complex convective dynamics?
- Basis in paper: [explicit] "The optical-flow supervision requires additional computation and may not perfectly capture complex convection dynamics; using the proposed scheme with additional covariates could yield further improvements under a more detailed physical modeling."
- Why unresolved: Current optical flow methods assume pixel intensity conservation, which may not hold during rapid convective development or dissipation where intensity changes independently of advection.
- What evidence would resolve it: Ablation experiments incorporating cloud-top temperature, humidity profiles, or vertical velocity as additional inputs, showing improved motion field accuracy and forecast skill for convective events.

## Limitations
- Evaluation limited to four urban areas, potentially limiting generalizability to other geographic regions and precipitation regimes
- Cross-city performance degradation suggests sensitivity to local climate patterns not fully addressed
- Physical alignment approach relies on optical flow estimates that may introduce errors in complex weather scenarios
- Performance at lower precipitation thresholds remains comparable to existing methods, with advantages primarily at higher thresholds

## Confidence
- **High confidence** in TUPANN's performance superiority at higher precipitation thresholds (4-64 mm/h) and lead times of 10-180 minutes based on CSI and HSS metrics
- **Medium confidence** in the physical interpretability of motion fields and the real-time capability claims, as these were demonstrated but not extensively validated across diverse scenarios
- **Medium confidence** in the transferability results, as cross-city performance showed degradation but multi-city training improved results, suggesting partial transferability

## Next Checks
1. Evaluate TUPANN's performance on additional geographic regions with diverse precipitation patterns, particularly in mountainous and coastal areas not represented in the current study
2. Test the model's ability to capture extreme precipitation events (above 64 mm/h) and assess performance during rapid weather transitions
3. Conduct computational efficiency analysis for global operational deployment, including memory usage, inference time, and required hardware specifications for real-time processing