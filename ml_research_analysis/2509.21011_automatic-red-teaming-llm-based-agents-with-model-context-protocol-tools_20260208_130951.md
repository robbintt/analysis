---
ver: rpa2
title: Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools
arxiv_id: '2509.21011'
source_url: https://arxiv.org/abs/2509.21011
tags:
- tool
- malicious
- tools
- agents
- description
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AutoMalTool, an automated red teaming framework
  that generates malicious MCP tools to evaluate LLM-based agent security. The framework
  employs a multi-agent system to craft tools that can manipulate agent behavior while
  evading detection.
---

# Automatic Red Teaming LLM-based Agents with Model Context Protocol Tools

## Quick Facts
- arXiv ID: 2509.21011
- Source URL: https://arxiv.org/abs/2509.21011
- Reference count: 40
- Primary result: Multi-agent framework achieves 85% tool generation success and 35.3% effectiveness against LLM agents while evading detection 88-97% of the time

## Executive Summary
AutoMalTool is an automated red teaming framework that generates malicious Model Context Protocol (MCP) tools to evaluate security of LLM-based agents. The framework employs a multi-agent system that iteratively refines tool descriptions to achieve both attack effectiveness and detection evasion. It successfully generates tools that manipulate agent behavior through parameter injection and output misinterpretation while maintaining a low generation cost of $0.03 per tool.

## Method Summary
AutoMalTool uses a four-agent pipeline built on LangGraph to generate malicious MCP tools from benign packages. The Initial Generator creates plausible tasks and malicious behaviors, the Oracle detects prompt injection attempts, the Effectiveness Evaluator tests tools in simulated agents, and the Tool Optimizer refines descriptions based on feedback. The system modifies only tool metadata (name, description, input schema) using static code analysis while preserving executable functionality. The iterative loop runs up to N=10 optimization iterations, with DeepSeek V3.1 for Oracle/Evaluator and Claude Sonnet 4 for optimization.

## Key Results
- Generation Success Rate: 85% across 53 tools from three MCP servers
- Effective Success Rate: 35.3% against mainstream agents (Claude Desktop, Cline)
- Evasion Rate: 88-97% against MCP-Scan and A.I.G detection tools
- Cost efficiency: ~$0.03 per generated tool, ~200 seconds per tool

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-agent iterative refinement improves both attack effectiveness and detection evasion.
- Mechanism: The Oracle detects whether a malicious tool description will be flagged; the Effectiveness Evaluator tests behavior in a simulated agent; the Tool Optimizer uses failure feedback to refine descriptions. This creates a closed optimization loop that addresses both objectives sequentially.
- Core assumption: LLM-based evaluators can meaningfully predict real-world detection and agent behavior.
- Evidence anchors:
  - [abstract] "multi-agent system to craft tools that can manipulate agent behavior while evading detection"
  - [Section III-B] Algorithm 1 shows the while-loop with Oracle check → Effectiveness evaluation → optimization
  - [corpus] MCP-ITP (2511.15998) proposes related automated tool poisoning but without the multi-agent feedback structure
- Break condition: If the Oracle's detection predictions diverge significantly from actual detection tools (MCP-Scan, A.I.G), optimization will follow incorrect gradients.

### Mechanism 2
- Claim: Confining modifications to tool metadata preserves code functionality while enabling prompt injection.
- Mechanism: AutoMalTool modifies only the tool name, description, and input schema—never the executable code. A static analysis-based modifier updates the package while maintaining syntax correctness.
- Core assumption: LLM-based agents rely primarily on metadata for tool selection, parameter grounding, and result interpretation.
- Evidence anchors:
  - [abstract] "generates malicious MCP tools" via "tool poisoning attacks"
  - [Section I] "our framework processes only the metadata of MCP tools... when handled by the agents"
  - [corpus] MCP Security Bench (2510.15994) confirms MCP enlarges attack surface via "natural-language metadata"
- Break condition: If agents validate tool behavior against code execution rather than metadata descriptions, metadata-only attacks become detectable.

### Mechanism 3
- Claim: Semantic rephrasing circumvents LLM safety alignment during optimization.
- Mechanism: The Tool Optimizer frames malicious behavior as "intended legitimate functionality" and claims false positives from security scanners. It uses professional language, contextual guidance, and best-practices framing to mask injection intent.
- Core assumption: LLM safety training is sensitive to explicit malicious framing but permeable to contextually-justified rephrasing.
- Evidence anchors:
  - [Section III-F] "the Tool Optimizer asserts that the described malicious behavior is, in fact, the tool's intended legitimate functionality"
  - [Listing 6] "this appears to be a false positive as the tool serves legitimate purposes"
  - [corpus] AJAR (2601.10971) addresses adaptive jailbreaks but focuses on text attacks rather than tool-metadata injection
- Break condition: If safety classifiers are trained specifically on rephrased-injection patterns, this circumvention fails.

## Foundational Learning

- **Concept: Model Context Protocol (MCP)**
  - Why needed here: MCP is the standardized protocol connecting LLM-based agents to external tools/resources. Understanding its three components (Host, Client, Server) and the Tool/Resources/Prompts blocks is essential for grasping where metadata injection occurs.
  - Quick check question: In MCP architecture, which component exposes tool metadata that AutoMalTool modifies?

- **Concept: Tool Usage Workflow in LLM Agents**
  - Why needed here: AutoMalTool targets specific stages: parameter grounding (incorrect parameter invocation) and result interpretation (output misinterpretation). The three-stage workflow (tool selection → parameter grounding → result interpretation) defines the attack surface.
  - Quick check question: Which workflow stage does "incorrect parameter invocation" target?

- **Concept: Prompt Injection via Tool Metadata**
  - Why needed here: Unlike direct prompt injection, tool poisoning embeds malicious instructions in tool descriptions that are implicitly trusted by the agent during tool selection and invocation.
  - Quick check question: Why does modifying only tool metadata (not code) suffice for tool poisoning attacks?

## Architecture Onboarding

- **Component map:**
  - Initial Generator → Oracle → Effectiveness Evaluator → Tool Optimizer → Tool Packer
  - Benign MCP package → Tool extraction → Task generation → Malicious behavior + description generation → Oracle check → Simulated agent test → Tool Optimizer refinement → Package and output

- **Critical path:**
  1. Benign MCP package → Tool extraction
  2. Task generation → Malicious behavior + description generation
  3. Oracle check (if malicious → optimize for evasion)
  4. Simulated agent test (if fails → optimize for effectiveness)
  5. Package and output (on success or max iterations N=10)

- **Design tradeoffs:**
  - Temperature settings: 0.0 for Oracle/Evaluator (consistency) vs. 0.3 for Generator/Optimizer (diversity)
  - Only metadata modified: preserves functionality but limits attack surface to description-based injection
  - Black-box assumption: no knowledge of target agent internals; relies on simulated agent proxy

- **Failure signatures:**
  - High GSR but low ESR: tools evade detection but don't trigger malicious behavior in real agents
  - Oracle evasion but Effectiveness failure: rephrasing removed injection semantics
  - More iterations for Filesystem MCP: domain complexity increases optimization difficulty

- **First 3 experiments:**
  1. Run AutoMalTool on a single tool from Alpaca MCP Server with verbose logging to trace Oracle→Evaluator→Optimizer loop; count iterations and inspect intermediate descriptions.
  2. Compare ESR between incorrect parameter invocation vs. output misinterpretation on Claude Desktop to validate the complexity differential claimed (Table II).
  3. Test generated tools against MCP-Scan and A.I.G to reproduce evasion rates; analyze false-negative cases where tools were flagged.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can adversarial training using AutoMalTool-generated malicious MCP tools effectively improve LLM-based agent robustness against tool poisoning attacks?
- Basis in paper: [explicit] Section V-A states: "One promising approach is the incorporation of adversarial training techniques... AutoMalTool can serve as a valuable red teaming tool for generating malicious training examples."
- Why unresolved: The authors propose this direction but do not implement or evaluate adversarial training.
- What evidence would resolve it: A study training agents on both benign and AutoMalTool-generated malicious MCP tools, then measuring ESR reduction.

### Open Question 2
- Question: What detection methods can reliably identify malicious MCP tools that employ semantic rephrasing and special Unicode tokens to evade detection?
- Basis in paper: [explicit] Section V-A notes the need for "more robust detection methods specifically designed to identify malicious MCP servers" given 88–97% evasion rates against MCP-Scan and A.I.G.
- Why unresolved: Current static-analysis and LLM-based detectors are ineffective; behavior-based or anomaly-detection approaches are suggested but untested.
- What evidence would resolve it: Development and benchmarking of new detectors achieving <20% evasion rates against AutoMalTool outputs.

### Open Question 3
- Question: Why does increased model sophistication (e.g., GPT-5 vs. GPT-4.1) not correlate with improved resistance to tool poisoning attacks?
- Basis in paper: [inferred] Section IV-B observes GPT-4.1 exhibits greater robustness than GPT-5-chat-latest, but no causal explanation is provided.
- Why unresolved: The finding is empirical; the underlying mechanisms (training data, alignment procedures, architectural differences) remain unexplored.
- What evidence would resolve it: Controlled ablation studies isolating training corpus, alignment techniques, and architecture across model versions.

### Open Question 4
- Question: Can malicious MCP tools be designed to induce unauthorized system access, sensitive information exfiltration, or cross-tool shadowing attacks beyond parameter and output manipulation?
- Basis in paper: [explicit] Section V-A lists these attack vectors as warranting "further exploration in future research."
- Why unresolved: AutoMalTool only supports incorrect parameter invocation and output results misinterpretation; other behaviors remain unaddressed.
- What evidence would resolve it: Extending AutoMalTool to generate these attack types and measuring success rates against target agents.

## Limitations

- The framework's performance depends heavily on the Oracle's detection accuracy and Effectiveness Evaluator's simulation fidelity, which may diverge from real-world conditions.
- Metadata-only attacks may miss more sophisticated code-level vulnerabilities that could be exploited in MCP tool poisoning.
- Evaluation is limited to three MCP servers and two target agents, limiting generalizability across the broader MCP ecosystem.

## Confidence

**High Confidence**: Generation Success Rate (85%) and Evasion Rate (88-97%) measurements are based on systematic testing across multiple tools and detection systems, with clear methodology and reproducible results.

**Medium Confidence**: Effective Success Rate (35.3%) measurements are more uncertain due to the challenges in automating real agent testing and the potential gap between simulated and actual agent behavior. The effectiveness measurements depend heavily on the Quality of the simulated agent proxy.

**Low Confidence**: The claim that semantic rephrasing reliably circumvents LLM safety alignment is based on current detection capabilities but may become ineffective as safety training evolves to address these specific patterns.

## Next Checks

1. **Cross-Platform Validation**: Test generated tools against additional MCP servers (beyond the three evaluated) and additional target agents to assess generalizability of the 85% GSR and 35.3% ESR claims.

2. **Real vs. Simulated Agent Gap Analysis**: Compare ESR measurements from the simulated agent versus actual target agents across a stratified sample of tools to quantify the fidelity of the Effectiveness Evaluator proxy and identify systematic discrepancies.

3. **Detection Evasion Robustness**: Evaluate tool evasion rates against additional detection tools beyond MCP-Scan and A.I.G, including commercial security scanners, to determine if the 88-97% evasion rate holds across different detection methodologies and rule sets.