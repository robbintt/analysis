---
ver: rpa2
title: 'Profit Mirage: Revisiting Information Leakage in LLM-based Financial Agents'
arxiv_id: '2510.07920'
source_url: https://arxiv.org/abs/2510.07920
tags:
- leakage
- market
- data
- financial
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper systematically identifies and quantifies the "profit
  mirage" phenomenon in LLM-based financial agents, where dazzling back-tested returns
  evaporate when models are forced to trade on genuinely unknown data due to information
  leakage from training data. The authors introduce four experimental dimensions to
  measure this leakage: temporal generalization tests, counterfactual evaluations,
  memorization audits (FinLeak-Bench), and fine-tuning impact studies.'
---

# Profit Mirage: Revisiting Information Leakage in LLM-based Financial Agents

## Quick Facts
- **arXiv ID:** 2510.07920
- **Source URL:** https://arxiv.org/abs/2510.07920
- **Reference count:** 40
- **Primary result:** FactFin achieves out-of-sample Sharpe ratios 1.4× higher than baselines, with 31.91% improvement in total return and 22.74% improvement in Sharpe ratio while reducing information leakage.

## Executive Summary
This paper systematically identifies and quantifies the "profit mirage" phenomenon in LLM-based financial agents, where impressive back-tested returns evaporate when models are forced to trade on genuinely unknown data due to information leakage from training data. The authors introduce four experimental dimensions to measure this leakage and propose FactFin, a counterfactual framework that uses LLMs as strategy generators rather than direct decision-makers. FactFin achieves significantly better out-of-sample performance across six assets by integrating Strategy Code Generator, Retrieval-Augmented Generation, Monte Carlo Tree Search, and Counterfactual Simulator components.

## Method Summary
The authors develop FactFin, a framework that mitigates information leakage in LLM-based financial agents by using the LLM as a strategy code generator rather than a direct decision-maker. The system integrates RAG for feature extraction, MCTS for strategy optimization, and a Counterfactual Simulator for leakage auditing. The framework is tested across six assets using temporal generalization tests, counterfactual evaluations, and memorization audits to quantify information leakage.

## Key Results
- FactFin achieves out-of-sample Sharpe ratios 1.4× higher than baselines
- Average improvements of 31.91% in total return, 22.74% in Sharpe ratio, and 9.23% in maximum drawdown across six assets
- Significantly reduces information leakage as measured by prediction consistency and input dependency metrics

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Counterfactual perturbation compels LLM-based agents to rely on current inputs rather than memorized historical patterns.
- **Core assumption:** High prediction consistency across counterfactual scenarios indicates memorization, and minimizing this consistency leads to genuine input-driven reasoning.
- **Evidence anchors:** Abstract states FactFin "applies counterfactual perturbations to compel LLM-based agents to learn causal drivers"; Section 3.6 explains CS perturbation process.
- **Break condition:** If high prediction consistency is sometimes due to robust causal rules rather than memorization, minimizing it could weaken valid strategies.

### Mechanism 2
- **Claim:** Using LLM as strategy code generator isolates trading logic from model's internal knowledge base.
- **Core assumption:** Code generation is less susceptible to data leakage than direct prediction.
- **Evidence anchors:** Abstract introduces FactFin as using "LLMs as strategy generators rather than direct decision-makers"; Sections 3.1-3.3 detail SCG component.
- **Break condition:** If LLM encodes memorized patterns directly into generated code (e.g., `if date == '2022-03-15': buy`).

### Mechanism 3
- **Claim:** Integrating RAG and MCTS provides structured context and systematic optimization.
- **Core assumption:** Retrieved information is genuinely novel and MCTS search finds robust strategies.
- **Evidence anchors:** Abstract lists RAG and MCTS as core components; Sections 3.4-3.5 explain their roles.
- **Break condition:** If RAG retrieves memorized information or MCTS overfits to evaluation datasets.

## Foundational Learning

**Concept: Information Leakage in Machine Learning**
- Why needed here: Central to understanding the "profit mirage" problem where models inappropriately use training data during inference.
- Quick check question: Why would a model achieve 99% accuracy on back-test but fail completely on future data if not for data leakage?

**Concept: Counterfactual Reasoning**
- Why needed here: Core diagnostic and corrective tool - creating "what if" scenarios to test if model reasoning or reciting.
- Quick check question: If model predicts "buy" and you give counterfactual input where company announced bankruptcy, what should prediction change to if reasoning?

**Concept: LLM-as-an-Agent Framework**
- Why needed here: FactFin uses LLM as component within larger system, not standalone oracle.
- Quick check question: In standard LLM chat, output is final answer. In FactFin, what is LLM's primary output and what happens next?

## Architecture Onboarding

**Component map:** Market Data → RAG (Factorization) → SCG (Initial Code Generation) → MCTS (Performance Optimization) → CS (Leakage Minimization & Final Selection) → Trade Execution

**Critical path:** The complete pipeline transforms raw market data through factor extraction, code generation, optimization, and final leakage minimization before executing trades.

**Design tradeoffs:**
- Performance vs. Leakage Mitigation: CS optimization explicitly trades raw performance against lower leakage metrics
- Compute Cost vs. Robustness: MCTS and counterfactual simulations are computationally expensive
- LLM Role: Limits LLM to code generation for controllability and auditability

**Failure signatures:**
- High Prediction Consistency (PC > 0.7): Strategy likely overfitting to historical patterns
- Strategy Code Contains Hardcoded Dates/Values: SCG bypassed intent and memorized specific events
- MCTS Fails to Converge: Search space too large or reward signal too noisy

**First 3 experiments:**
1. Leakage Audit of Baseline: Run standard LLM-based agent through Counterfactual Simulator to establish baseline metrics
2. Ablation Study on SCG: Run FactFin pipeline using only SCG component to demonstrate code generation alone is insufficient
3. End-to-End FactFin Run: Run full pipeline and compare leakage metrics and performance against experiments 1 and 2

## Open Questions the Paper Calls Out

**Open Question 1**
- **Question:** Can FactFin maintain performance advantage in high-frequency or latency-sensitive trading environments given computational overhead?
- **Basis in paper:** Framework relies on complex loop of SCG, RAG, MCTS, and Counterfactual Simulation implying significant inference latency
- **Why unresolved:** Paper evaluates profitability but doesn't report computational efficiency, latency, or operational costs
- **What evidence would resolve it:** Latency benchmarks and analysis of trade-off between MCTS depth and financial performance

**Open Question 2**
- **Question:** How robust is leakage mitigation strategy during extreme "black swan" market regimes or structural breaks?
- **Basis in paper:** Authors selected historical periods with "comparable market conditions" potentially leaving volatile regime performance untested
- **Why unresolved:** Unclear if "causal drivers" learned remain valid when market correlations shift dramatically during crises
- **What evidence would resolve it:** Out-of-sample back-testing on historical periods with high volatility or market crashes

**Open Question 3**
- **Question:** Do counterfactual perturbation methods preserve complex statistical relationships enough to ensure learned "causal drivers" are valid?
- **Basis in paper:** Section 3.6 claims perturbations "preserve statistical relationships" but this claim is not empirically validated
- **Why unresolved:** If perturbation methods destroy subtle correlations or introduce artifacts, strategies may learn spurious patterns
- **What evidence would resolve it:** Statistical analysis comparing correlation matrices of original vs. counterfactual datasets

## Limitations
- **Leakage Metrics Validity:** Reliance on PC, CI, IDS as proxies for harmful memorization lacks empirical validation
- **Counterfactual Scope:** May incorrectly penalize valid strategies that leverage real market regularities
- **Generalization:** Results limited to six assets without testing across diverse market regimes

## Confidence
- **High Confidence:** Core finding that LLM agents suffer from information leakage and achieve worse out-of-sample performance
- **Medium Confidence:** Proposed leakage metrics and specific weighting in counterfactual loss function are reasonable but not rigorously validated
- **Low Confidence:** Claim of "1.4× higher Sharpe ratios" lacks statistical validation with confidence intervals or significance testing

## Next Checks
1. **Cross-Asset Generalization Test:** Run FactFin on 20+ diverse assets across different sectors/geographies, comparing out-of-sample performance with confidence intervals and statistical significance testing.

2. **Leakage Metric Ablation:** Systematically remove each leakage metric (PC, CI, IDS) from counterfactual loss function and retrain FactFin to determine which metrics contribute to leakage reduction versus potential harm.

3. **Real-Time Deployment Simulation:** Implement rolling window backtest where FactFin generates new strategies monthly in real-time simulation, measuring computational latency, strategy turnover costs, and performance degradation from static backtest results.