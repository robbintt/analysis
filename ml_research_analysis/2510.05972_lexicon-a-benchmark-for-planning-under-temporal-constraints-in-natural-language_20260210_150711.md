---
ver: rpa2
title: 'LexiCon: a Benchmark for Planning under Temporal Constraints in Natural Language'
arxiv_id: '2510.05972'
source_url: https://arxiv.org/abs/2510.05972
tags:
- planning
- constraints
- plan
- problem
- room
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LEXICON is a benchmark for evaluating large language models on
  planning tasks with temporal constraints specified in natural language. The system
  generates constrained planning problems by automatically introducing temporal constraints
  into existing planning domains, then translates these problems into natural language
  for LLM evaluation.
---

# LexiCon: a Benchmark for Planning under Temporal Constraints in Natural Language

## Quick Facts
- **arXiv ID:** 2510.05972
- **Source URL:** https://arxiv.org/abs/2510.05972
- **Reference count:** 40
- **Primary result:** LEXICON enables principled evaluation of LLM planning under temporal constraints, showing reasoning models perform well on simple problems but degrade sharply as constraint complexity increases.

## Executive Summary
LEXICON is a benchmark designed to evaluate Large Language Models on optimal planning tasks with temporal constraints specified in natural language. The system automatically generates constrained planning problems by introducing temporal constraints into existing PDDL domains, then translates these into natural language for LLM evaluation. LEXICON includes automated verification to check plan validity and optimality. Experiments demonstrate that reasoning models like OpenAI o3, DeepSeek R1, and GPT-5 perform well on problems with few constraints but their performance deteriorates sharply as constraint complexity increases. The benchmark is significantly faster than LLM-based planning and provides a principled way to assess LLM planning capabilities under constraints.

## Method Summary
LEXICON generates constrained planning problems by automatically introducing temporal constraints into existing planning domains defined in PDDL3.0. The generator synthesizes these problems, compiles them using LiftedTCORE, and solves for ground-truth optimal cost using SymK. The problems are then translated to natural language for LLM evaluation. LLMs are prompted with the NL problem and a system role, generating plans that are mapped back to PDDL and verified against the compiled problem. The benchmark includes automated verification to check if LLM-generated plans are valid and optimal, measuring both validity rate and optimal planning accuracy. LEXICON is designed to be extensible, allowing new environments to be added without rewriting core code.

## Key Results
- Reasoning models (o3, DeepSeek R1, GPT-5) achieve high validity rates on problems with 1-2 constraints but performance deteriorates sharply as constraint count increases
- LEXICON is significantly faster than LLM-based planning, enabling real-time evaluation of planning capabilities
- Strong correlation exists between reasoning tokens and optimal cost, though models often find valid but suboptimal plans
- State hallucination and constraint violation are the primary failure modes, with models frequently ignoring "Always" conditions or attempting invalid actions

## Why This Works (Mechanism)
LEXICON works by providing a systematic framework that bridges symbolic planning with natural language understanding. The automated generation and translation of constrained problems ensures consistent evaluation across different models and domains. The verification system provides objective feedback on plan validity and optimality, enabling precise measurement of LLM capabilities. The extensible architecture allows the benchmark to evolve with new domains and constraint types while maintaining comparability across evaluations.

## Foundational Learning
- **PDDL3.0 temporal constraints** - Why needed: Core language for specifying temporal requirements in planning problems; quick check: Can you identify "Always" vs "Sometime" constraint types in a sample problem
- **LiftedTCORE compilation** - Why needed: Translates temporal constraints into solvable ground problems; quick check: Understand that compilation transforms qualitative constraints into quantitative constraints for solvers
- **SymK optimal planning** - Why needed: Provides ground-truth optimal costs for validation; quick check: Can you explain why optimal cost is needed for correlation analysis
- **LLM plan verification** - Why needed: Ensures generated plans meet both goal requirements and temporal constraints; quick check: Can you describe how state simulation validates action preconditions
- **Constraint complexity scaling** - Why needed: Measures how performance degrades with problem difficulty; quick check: Can you explain why 3+ constraints cause sharp performance drops
- **Natural language translation** - Why needed: Bridges symbolic planning notation with LLM input format; quick check: Can you identify key elements that must be preserved in translation

## Architecture Onboarding

**Component Map:** PDDL Domains → Constraint Generator → LiftedTCORE Compiler → SymK Solver → NL Translator → LLM → Plan Mapper → Verifier

**Critical Path:** Problem Generation → Compilation → Ground Truth Solution → NL Translation → LLM Evaluation → Plan Verification

**Design Tradeoffs:** LEXICON prioritizes extensibility and automated verification over raw speed, accepting slower generation times (1-100 seconds) to ensure constraint satisfaction and comparability across domains. The choice to use existing PDDL3.0 infrastructure enables broad domain coverage but limits support to discrete, fully observable environments.

**Failure Signatures:** State hallucination manifests as invalid actions where preconditions aren't met; constraint violation appears when plans achieve goals but ignore "Always" or "Sometime" requirements; suboptimal planning occurs when models find valid but non-optimal solutions, especially evident when reasoning tokens don't correlate with optimal cost.

**First Experiments:**
1. Generate a single constrained problem using `python3 generate_benchmark.py blocksworld 42 1 1` and verify the output PDDL and NL files
2. Run the verifier on a known valid plan using `python3 verify_plan.py blocksworld/valid_plan.pddl` to confirm the verification pipeline works
3. Configure the evaluation script for a single problem with a publicly available model (e.g., Claude 3.5 Sonnet) to test the complete LLM evaluation pipeline

## Open Questions the Paper Calls Out
- How does LLM performance degrade when transitioning from fully observable deterministic environments to partially observable environments with uncertain observations?
- Can LLMs effectively plan under constraints applied to continuous states and specific actions, rather than solely discrete state-trajectory constraints?
- Can the LEXICON architecture be optimized to support parallel episode execution to reduce the bottleneck in large-scale evaluation?
- Do LLMs fail to find optimal plans because they lack the ability to maintain multiple simultaneous search paths (structured search)?

## Limitations
- Access to proprietary models (GPT-5, o3) may be restricted, limiting exact reproduction of reported performance metrics
- The benchmark currently supports only discrete, fully observable environments, excluding partially observable or continuous domains
- Episode generation is significantly slower (1-100 seconds) due to sequential constraint satisfaction logic, limiting scalability
- Current constraint types are limited to qualitative state-trajectory constraints, excluding action-specific or continuous variable constraints

## Confidence
- **High confidence**: Claims about LEXICON's extensibility and automated problem generation are well-supported by implementation details
- **Medium confidence**: Claims regarding LLM performance deterioration with increasing constraints are based on experimental results but may vary with model access
- **Low confidence**: Absolute performance comparisons between proprietary models (GPT-5 vs o3) are difficult to verify without guaranteed access

## Next Checks
1. Verify API access to all evaluated models (GPT-5, o3, DeepSeek R1) and document any configuration differences from the paper's setup
2. Run a smaller-scale experiment using publicly available reasoning models to verify the pattern of performance deterioration with increasing constraints
3. Systematically vary constraint numbers (1-5) and measure validity rate and optimal planning accuracy to validate the reported correlation between reasoning tokens and optimal cost