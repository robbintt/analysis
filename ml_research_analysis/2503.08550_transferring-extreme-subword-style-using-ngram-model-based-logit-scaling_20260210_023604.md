---
ver: rpa2
title: Transferring Extreme Subword Style Using Ngram Model-Based Logit Scaling
arxiv_id: '2503.08550'
source_url: https://arxiv.org/abs/2503.08550
tags:
- style
- prompt
- ngram
- subword
- scaled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a novel ngram model-based logit scaling method
  to transfer extreme subword stylistic variation to large language models at inference
  time. The core idea is to combine next-token predictions from a pretrained LLM with
  scaled ngram model predictions, where the scaling factor f controls the degree of
  style transfer.
---

# Transferring Extreme Subword Style Using Ngram Model-Based Logit Scaling

## Quick Facts
- arXiv ID: 2503.08550
- Source URL: https://arxiv.org/abs/2503.08550
- Authors: Craig Messner; Tom Lippincott
- Reference count: 40
- Primary result: Successfully transfers extreme subword stylistic variation to LLMs at inference time using ngram-based logit scaling

## Executive Summary
This paper presents a novel method for transferring extreme subword stylistic variation from 19th century American authors to large language models using ngram model-based logit scaling. The approach combines next-token predictions from a pretrained LLM with scaled ngram model predictions, where the scaling factor f controls the degree of style transfer. Experiments demonstrate that sampling with scaled Mistral-Instruct-7B logits successfully transfers subword styles from authors like Joel Chandler Harris and Finley Peter Dunne, with generated text perplexity approaching target text perplexity. The method proves effective for transferring extreme orthographic variations while maintaining fluency, outperforming control prompts and greedy decoding approaches.

## Method Summary
The method involves training n=4 ngram models on wordpiece-tokenized target corpora (Remus, Julius, Todd from Project Gutenberg) and using these to scale LLM logits during inference. For each vocabulary token, a scaling vector S = -f × log(p_n) is computed from the ngram probability p_n, where f is a tunable weight from {0,1,2}. This scaling is added to the LLM's raw logits before softmax and sampling. The method uses stupid backoff across ngram orders (4→3→2→1) when higher-order context is unavailable. Optimal scaling weights are selected by plotting abs(PPL_target - gPPL()) against rPPL(), choosing weights that minimize both metrics.

## Key Results
- Successfully transfers extreme subword styles from 19th century American authors to Mistral-Instruct-7B
- Optimal scaling weights are style-specific and require hyperparameter search per target
- Sampling with scaled logits outperforms greedy decoding and control prompts for style transfer
- Generated text perplexity approaches target author perplexity while maintaining fluency

## Why This Works (Mechanism)

### Mechanism 1: Ngram Logit Scaling as Style Injection
Scaling factors derived from ngram model probabilities, when added to LLM logits before softmax, bias next-token selection toward author-specific subword patterns without requiring weight updates. The method computes S = -f × log(p_n) for each token and adds it to LLM logits, with higher f increasing ngram influence. This works because ngram models trained on single-author corpora capture statistically distinctive subword constructions underrepresented in the LLM's prior.

### Mechanism 2: Stupid Backoff for Vocabulary Coverage
A backoff hierarchy across ngram orders (4→3→2→1) ensures scaling can be applied even when higher-order ngram statistics are sparse in small corpora. The method queries M4 first, falls back to M3 if no prediction exists, then M2, then M1. This adapts stupid backoff to the logit-scaling context, ensuring coverage even with limited training data.

### Mechanism 3: Dual-Perplexity Optimization for Scaling Selection
Simultaneously tracking gPPL() (generation perplexity under base GPT-2) and rPPL() (perplexity under ngram-interpolated GPT-2) enables principled selection of optimal scaling weights. The method plots abs(PPL_target - gPPL()) against rPPL() and selects weights from the bottom-left region where both metrics are minimized. This ensures style transfer success while maintaining fluency.

## Foundational Learning

- **Concept: Ngram Language Models**
  - Why needed: The method repurposes ngram models as "statistical experts" on author-specific subword patterns; understanding p(w_n | w_{n-1}, ..., w_{n-k}) is essential.
  - Quick check: Given the sequence "wuz a man in", what probability would a Julius-trained bigram model assign to "dis" vs. "the" as the next token?

- **Concept: Logits, Softmax, and Sampling**
  - Why needed: The intervention happens pre-softmax at the logit level; understanding how additive scaling affects the final probability distribution is non-negotiable.
  - Quick check: If an LLM assigns logits [5.0, 3.0, 1.0] to tokens [A, B, C] and you add scaling vector [-2.0, 0.0, 4.0], which token's probability increases most after softmax?

- **Concept: Perplexity as Model Fit**
  - Why needed: The entire evaluation framework relies on perplexity as a proxy for style match and fluency; misinterpreting perplexity will lead to incorrect conclusions.
  - Quick check: A generated text has gPPL() = 120 while the target author's PPL() = 110 and standard English PPL() = 40. Does this suggest successful transfer? Why or why not?

## Architecture Onboarding

- **Component map:** Target Corpus → Ngram Models {M4, M3, M2, M1} → Story Prompt → LLM (Mistral/Llama) → Raw Logits → Scaling Vector S (from ngram backoff) → Scaled Logits → Softmax → Sampling → Generated Text → GPT-2 Evaluation → gPPL(), rPPL()

- **Critical path:**
  1. Wordpiece-tokenize target corpus (same tokenizer as LLM)
  2. Train {4,3,2,1}-gram models with backoff
  3. For each generation step: query ngram models → compute S → add to LLM logits → sample
  4. Evaluate generated text against gPPL()/rPPL() criteria

- **Design tradeoffs:**
  - Sampling vs. Greedy: Paper shows greedy decoding fails to reach target PPL() (Table 7); sampling is required for style transfer
  - Model choice: Mistral-7B outperforms Llama-3.2-3B, suggesting pretraining/data differences matter (Table 8)
  - Weight selection: Style-specific optimal weights (e.g., Todd requires different weights than Julius due to less extreme orthographic variation)

- **Failure signatures:**
  - gPPL() stays near baseline (~17-40) despite scaling → style not transferring (greedy decoding shows this)
  - rPPL() extremely high (>200) → generation is chaotic, scaling too aggressive
  - Generated text contains novel but implausible subword sequences → ngram model overfitting or corpus too small

- **First 3 experiments:**
  1. Baseline check: Generate unscaled text from Mistral with control prompts; verify gPPL() ≈ 17-23 (no transfer) per Table 2
  2. Single-weight sweep: Fix weight tuple [1,1,1,1], generate 10 samples per target author, compute gPPL()/rPPL() to confirm the method does anything at all
  3. Grid search: Test all 16 weight combinations from {0,1,2}^4 on one target (e.g., Julius), plot abs(PPL-PPL) vs rPPL, identify optimal region per Figure 1 pattern

## Open Questions the Paper Calls Out

### Open Question 1
Can this method effectively transfer subword style in languages with complex morphology or non-Latin scripts? The current experiments are restricted to English corpora, leaving the method's efficacy on languages with different orthographic or morphological structures unknown. The paper explicitly states it has only been applied to 19th-century US literature and may fail to transfer variations found in "other eras, nationalities, and in particular, languages."

### Open Question 2
How does the specific subword tokenization algorithm influence the granularity and success of the style transfer? The paper notes the method depends on the pretrained LLM's tokenization system, which could "omit some elements of subword style" if learned boundaries do not align with stylistic markers. The paper utilizes specific models (Mistral/Llama) but does not analyze how different tokenizers might segment the "extreme" subword features differently.

### Open Question 3
Can the selection of optimal scaling weights be automated to replace the current graphical determination method? The paper lists "increasing the precision of our method for determining scaling optimality" as a direction for further work. Currently, the authors determine the "weight set of best fit" by manually plotting abs(PPL() - gPPL()) against rPPL(), which is imprecise and manual.

## Limitations
- Method relies on small single-author corpora (14K-20K words), raising concerns about statistical reliability and potential overfitting
- Evaluation framework uses perplexity as proxy for style transfer, which conflates multiple factors beyond subword variation
- Optimal scaling weights are style-specific, limiting generalizability and requiring extensive hyperparameter search per target style

## Confidence

**High Confidence**: The core mechanism of ngram logit scaling is well-specified and reproducible. The formulation S = -f × log(p_n) and stupid backoff implementation are clearly described with explicit equations and procedural steps.

**Medium Confidence**: The experimental results demonstrating style transfer effectiveness, while showing clear differences between conditions (greedy vs sampling, different scaling weights), rely on a single evaluation metric (perplexity) and limited qualitative assessment. The claim that generated text successfully transfers extreme subword styles is supported but could benefit from human perceptual validation.

**Low Confidence**: The assertion that this method transfers "extreme subword style" is difficult to verify independently due to the subjective nature of what constitutes successful stylistic transfer beyond perplexity matching. The paper provides limited qualitative examples and no perceptual studies.

## Next Checks

**Validation Check 1: Human Perceptual Study**
Conduct a blind human evaluation where participants rate the stylistic similarity between generated text and target author samples. Compare ratings across different scaling weights and against baseline conditions. This would directly validate whether perplexity matching correlates with perceived stylistic fidelity.

**Validation Check 2: Cross-Style Transferability**
Test the method on a diverse set of orthographic styles beyond 19th century American dialect (e.g., Shakespearean English, modern internet slang, technical jargon). Measure whether scaling weights transfer across styles or if each requires independent optimization, and quantify the generalizability of learned scaling factors.

**Validation Check 3: Ablation on Corpus Size**
Systematically vary the size of the target corpus used for ngram training (e.g., using 10%, 25%, 50%, 100% of available text) and measure the impact on style transfer quality and optimal scaling weight selection. This would establish minimum corpus requirements and identify potential overfitting issues with small training sets.