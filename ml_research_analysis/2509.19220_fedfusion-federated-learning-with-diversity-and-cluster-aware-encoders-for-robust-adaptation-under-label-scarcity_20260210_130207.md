---
ver: rpa2
title: 'FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for
  Robust Adaptation under Label Scarcity'
arxiv_id: '2509.19220'
source_url: https://arxiv.org/abs/2509.19220
tags:
- clients
- learning
- client
- federated
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "FedFusion tackles heterogeneous feature spaces and label scarcity\
  \ in federated learning by combining personalised diversity-aware encoders (DivEn,\
  \ DivEn-mix, DivEn-c) with similarity-weighted classifier aggregation and a two-step\
  \ domain adaptation pipeline (pretext training \u2192 confidence-filtered pseudo-label\
  \ fine-tuning). It enables teacher-guided learner updates without sharing raw data,\
  \ preserving privacy and local specialisation."
---

# FedFusion: Federated Learning with Diversity- and Cluster-Aware Encoders for Robust Adaptation under Label Scarcity

## Quick Facts
- arXiv ID: 2509.19220
- Source URL: https://arxiv.org/abs/2509.19220
- Reference count: 31
- Primary result: Achieves up to 84% accuracy on tabular tasks and 98% on imaging tasks under heterogeneous feature spaces and label scarcity

## Executive Summary
FedFusion addresses heterogeneous feature spaces and label scarcity in federated learning by combining personalised diversity-aware encoders with similarity-weighted classifier aggregation and a two-step domain adaptation pipeline. The method enables teacher-guided learner updates without sharing raw data, preserving privacy while maintaining local specialisation. Across tabular and imaging benchmarks under various non-IID and label-scarce regimes, FedFusion outperforms state-of-the-art baselines in accuracy, robustness, and fairness while maintaining comparable communication and computation budgets.

## Method Summary
FedFusion employs three main mechanisms: (1) similarity-weighted classifier aggregation where each client maintains a personalised encoder tuned to its local feature subset, with a regularisation term pulling the local classifier toward a similarity-weighted aggregate; (2) feature-space clustering for encoder aggregation, where clients are pre-clustered by feature-set similarity and encoders are aggregated within clusters before similarity-weighted classifier sharing; and (3) a two-step self-supervised pretext training followed by confidence-filtered pseudo-label fine-tuning, where rotation prediction serves as the pretext task and unlabelled clients update only the classifier head in the fine-tuning phase to prevent encoder drift. The framework includes a negative-transfer guard that reverts to threshold parameters if accuracy drops below baseline.

## Key Results
- Achieves up to 84% accuracy on tabular tasks (Obesity, Heart Disease, Lifestyle) with heterogeneous feature distributions
- Achieves up to 98% accuracy on imaging tasks (Digits-Five, Chest X-rays) under label scarcity
- Demonstrates superior performance across IID, non-IID, and label-scarce regimes compared to Coral, Auto-enc, class-agg, FADA, and FedKA baselines

## Why This Works (Mechanism)

### Mechanism 1: Similarity-Weighted Classifier Aggregation with Personalised Encoders (DivEn)
Each client maintains a personalised encoder E_i tuned to its local feature subset S_i and data D_i. The server computes a client-specific global classifier θ^CG_i via softmax-weighted averaging of peer classifiers based on cosine similarity of latent representations z_i = E_i(x, θ^E_i). During local training, a regularisation term λ||θ^C_i - θ^CG_i||² pulls the local classifier toward the similarity-weighted aggregate while preserving encoder diversity. The core assumption is that latent representation similarity correlates with transferability of classifier knowledge across clients with different feature subsets.

### Mechanism 2: Feature-Space Clustering for Encoder Aggregation (DivEn-c)
Clients are clustered via KMeans on binary feature-subset vectors (Jaccard similarity), recursively refined until intra-cluster similarity exceeds a threshold (e.g., 80%). A representative client per cluster performs encoder hyperparameter optimisation; all cluster members inherit this encoder. Intra-cluster aggregation (size-weighted) occurs before similarity-weighted classifier sharing. The core assumption is that clients with similar feature subsets benefit from shared encoder architecture/weights, with cluster boundaries being stable and meaningful.

### Mechanism 3: Two-Step Self-Supervised Pretext → Confidence-Filtered Pseudo-Label Fine-Tuning
Step 1: Labelled clients train encoder E + task head M via supervised loss; unlabelled clients train E + pretext head P (rotation prediction). Only encoder weights are aggregated. Step 2: Global E+M is distributed; unlabelled clients accept pseudo-labels only when max(q_b) ≥ τ, optimizing filtered cross-entropy. To limit drift, fully unlabelled clients update only θ^m (classifier) in Step 2, freezing θ^e. The core assumption is that pretext task (rotation) yields representations transferable to target task, and pseudo-label confidence threshold τ reliably filters noise.

## Foundational Learning

- **Concept: Federated Averaging (FedAvg)**
  - Why needed here: FedFusion extends FedAvg's aggregation to similarity-weighted and cluster-aware variants; understanding baseline convergence behaviour is prerequisite.
  - Quick check question: Can you explain why FedAvg's convergence bound degrades under non-IID data heterogeneity?

- **Concept: Self-Supervised Pretext Tasks**
  - Why needed here: The two-step pipeline uses rotation prediction as a pretext task to learn domain-invariant features without labels.
  - Quick check question: Why would predicting image rotation angles produce features useful for medical classification tasks?

- **Concept: Semi-Supervised Learning with Pseudo-Labels**
  - Why needed here: Step 2 uses FixMatch-style confidence filtering to train unlabelled clients safely.
  - Quick check question: What is the trade-off between a high pseudo-label confidence threshold τ (e.g., 0.95) vs. a lower one (e.g., 0.5)?

## Architecture Onboarding

- **Component map:** Client side: Personalised encoder E_i, shared classifier head, local training loop with similarity regulariser, pretext head P (unlabelled), task head M (labelled). Server side: Similarity matrix computation (cosine on latents), softmax-weighted classifier aggregation, cluster assignment (DivEn-c), encoder aggregation (size-weighted), negative-transfer guard. Two-step pipeline controller: Step 1 (pretext/supervised mix, aggregate θ^e only) → Step 2 (distribute E+M, fine-tune with pseudo-labels, aggregate θ^e and θ^m).

- **Critical path:** Initial round: Clients train for E_init epochs, store threshold_acc and threshold_params. Server computes latent similarity matrix, constructs client-specific global classifiers θ^CG_i. Subsequent rounds: Local training with L_i = CE(y, ŷ) + λ||θ^C_i - θ^CG_i||². Final check: If acc^R_i < threshold_acc_i, revert and retrain briefly (negative-transfer guard).

- **Design tradeoffs:** DivEn vs. DivEn-mix: DivEn regularises toward global classifier; DivEn-mix hard-resets θ^C_i ← θ^CG_i each round. Paper shows DivEn better with fewer features per client; DivEn-mix better with more features. λ (regulariser weight): Larger λ enforces classifier alignment but increases residual term R_sim in convergence bound. τ (pseudo-label threshold): Higher τ reduces noise but fewer unlabelled samples contribute. Encoder drift control: Design choice to freeze θ^e for unlabelled clients in Step 2 is a safety mechanism; may limit adaptation to target domain.

- **Failure signatures:** Dominance by data-rich clients: Symptom—minority clients show no improvement or degradation. Check similarity matrix for near-uniform weights favouring large clients. Negative transfer: Symptom—post-aggregation accuracy drops below threshold_acc. Negative-transfer guard should trigger; investigate feature overlap and cluster assignments. Encoder drift (unlabelled clients): Symptom—diverging latent distributions across rounds. Check if Step 2 encoder freezing is enabled; verify pseudo-label confidence distribution. Cluster fragmentation (DivEn-c): Symptom—many singleton clusters, no aggregation benefit. Check min_sim threshold and silhouette scores.

- **First 3 experiments:** 1. Baseline comparison (DivEn vs. DivEn-mix vs. DivEn-c) on feature-scarce tabular data: Use Obesity dataset with 8-feature and 12-feature scenarios; measure per-client accuracy and MAE. Expect DivEn to outperform at 8 features, DivEn-mix/DivEn-c at 12+ features. 2. Ablation of pseudo-label threshold τ on imaging domain adaptation: Run Digits-Five with τ ∈ {0.7, 0.8, 0.9, 0.95}; track accuracy, pseudo-label acceptance rate, and convergence speed. 3. Negative-transfer guard validation: Introduce adversarial client with orthogonal features; verify guard triggers and prevents degradation. Measure threshold_acc triggers per client across rounds.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does FedFusion's performance and convergence behavior change when extended to dynamic client participation and asynchronous communication protocols?
- Basis in paper: [explicit] The Conclusion explicitly lists "dynamic client participation and asynchronous communication protocols" as a primary direction for future research to support real-world deployment.
- Why unresolved: The current framework evaluation assumes synchronous rounds and static client availability, which is often impractical in cross-device settings.
- What evidence would resolve it: Empirical results from simulations with stochastic client dropouts and asynchronous update aggregation, showing convergence bounds and accuracy retention compared to the synchronous baseline.

### Open Question 2
- Question: Can explainable AI (XAI) mechanisms be integrated into the FedFusion pipeline to enhance interpretability in high-stakes domains like healthcare without compromising privacy or efficiency?
- Basis in paper: [explicit] The Conclusion identifies the "integration with explainable AI mechanisms" as necessary for applying the method in healthcare, given the importance of model transparency.
- Why unresolved: The paper focuses on accuracy and efficiency; adding XAI typically introduces computational overhead or requires access to raw data/gradients, which conflicts with the privacy constraints of FL.
- What evidence would resolve it: A modified FedFusion architecture incorporating a privacy-preserving XAI module (e.g., gradient-based interpreters) with a demonstrated trade-off analysis between interpretability fidelity and computation/privacy loss.

### Open Question 3
- Question: What is the optimal strategy for encoder updates during the fine-tuning phase for fully unlabelled clients to balance encoder drift against knowledge transfer?
- Basis in paper: [inferred] Section III.B.2.b notes that freezing the encoder (θ_e) for unlabelled clients is a "design choice that can be adapted," suggesting the current freezing strategy might be suboptimal.
- Why unresolved: Freezing prevents drift from noisy pseudo-labels but may hinder the encoder's ability to adapt to the target domain; updating it risks negative transfer.
- What evidence would resolve it: An ablation study comparing "frozen," "fully updated," and "partially updated" encoder strategies for unlabelled clients, measuring domain adaptation accuracy and representation stability.

### Open Question 4
- Question: How robust is the DivEn-c clustering mechanism when intra-cluster feature overlap is sparse or the similarity threshold is misconfigured?
- Basis in paper: [inferred] Section III.A.1 sets a specific threshold (e.g., 80%) for clustering and recursively splits clusters, but does not evaluate sensitivity to this hyperparameter or extreme sparsity.
- Why unresolved: The method relies on feature-based clustering to aggregate encoders; if the threshold is too high or overlap is minimal, clients may be isolated into singletons, reducing the method to local training.
- What evidence would resolve it: Sensitivity analysis of DivEn-c accuracy across a range of similarity thresholds and synthetic datasets with controlled feature-sparsity levels.

## Limitations

- Critical hyperparameters (learning rates, batch sizes, regularization weights) are not reported in the paper, making exact reproduction difficult.
- The effectiveness of the two-step pipeline is highly dependent on the pseudo-label confidence threshold τ, which is not empirically swept in the presented results.
- The clustering methodology for DivEn-c uses silhouette and elbow methods without specifying exact implementation parameters or sensitivity to threshold choices.

## Confidence

- **High Confidence:** The similarity-weighted classifier aggregation mechanism (DivEn) is well-supported by theoretical convergence analysis showing residual terms scale with cosine similarity. The negative-transfer guard implementation is explicitly described and validated.
- **Medium Confidence:** The feature-space clustering approach (DivEn-c) shows promise but depends heavily on cluster quality and stability assumptions that are not extensively validated across different data distributions.
- **Low Confidence:** The two-step self-supervised pipeline's effectiveness is demonstrated but the sensitivity to pretext task choice and pseudo-label threshold calibration is not thoroughly explored.

## Next Checks

1. **Hyperparameter sensitivity analysis:** Systematically vary λ (regularization weight) and τ (pseudo-label threshold) to establish robustness bounds and identify optimal operating regions.
2. **Cluster quality validation:** Compute and report cluster silhouette scores, intra-cluster feature similarity distributions, and singleton cluster rates across different K values to quantify clustering effectiveness.
3. **Negative transfer stress test:** Introduce increasingly dissimilar feature spaces (including orthogonal features) to rigorously test the negative-transfer guard's detection and mitigation capabilities.