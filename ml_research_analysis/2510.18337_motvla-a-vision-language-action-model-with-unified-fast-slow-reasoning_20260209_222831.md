---
ver: rpa2
title: 'MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning'
arxiv_id: '2510.18337'
source_url: https://arxiv.org/abs/2510.18337
tags:
- reasoning
- motvla
- expert
- action
- fast
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MoTVLA, a vision-language-action model that
  integrates fast and slow reasoning into a single architecture for robotic manipulation.
  It combines a pre-trained generalist transformer with a domain expert that shares
  global attention to generate task-specific motion decompositions efficiently.
---

# MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning

## Quick Facts
- **arXiv ID:** 2510.18337
- **Source URL:** https://arxiv.org/abs/2510.18337
- **Reference count:** 21
- **Primary result:** MoTVLA achieves up to 81% success rate in robotic manipulation tasks with fast inference (9 Hz) and strong language steerability, outperforming baselines like π0.5 and GR-MG.

## Executive Summary
MoTVLA is a Vision-Language-Action model that unifies fast and slow reasoning for robotic manipulation. It combines a pre-trained generalist transformer with a domain expert that shares global attention to generate task-specific motion decompositions efficiently. The model conditions a diffusion-based action policy on these decomposed motions, enabling faster execution while preserving language steerability. MoTVLA achieves superior performance in both reasoning benchmarks and robotic manipulation tasks, demonstrating strong zero-shot generalization even with distractions.

## Method Summary
MoTVLA employs a Mixture-of-Transformers architecture with two parallel Qwen2.5-7B transformers (generalist and domain expert) sharing a unified global self-attention mechanism. The domain expert generates motion decompositions via token-wise prediction for fast reasoning, while the generalist handles slow reasoning (dialogue/semantic planning) with frozen parameters to prevent catastrophic forgetting. A Diffusion Transformer (DiT) action expert is conditioned on visual observations, robot configuration, and the domain expert's hidden states to generate language-steered action trajectories. The model is trained in two stages: first fine-tuning the domain expert on motion VQA data, then training the diffusion policy on robotic trajectories.

## Key Results
- Achieves up to 81% success rate in simulation-based robotic manipulation tasks
- Demonstrates 9 Hz inference speed vs. <1 Hz for π0.5_KI baseline
- Shows strong zero-shot generalization with distractions (up to 60% success)
- Outperforms baselines like π0.5 and GR-MG in both reasoning (high BLEU, token accuracy) and action execution

## Why This Works (Mechanism)

### Mechanism 1: Knowledge Sharing via Global Attention
MoTVLA preserves pre-trained general intelligence while efficiently acquiring domain-specific reasoning through shared global attention between a generalist and a domain expert transformer. Two parallel transformers share a unified global self-attention mechanism, allowing modality-specific QKVs to attend across both experts. This enables knowledge transfer from the pre-trained generalist to the domain expert without modifying generalist parameters, avoiding catastrophic forgetting.

### Mechanism 2: Fast Reasoning via Token-wise Prediction
Fast reasoning generates motion decompositions in a single forward pass using token-wise prediction, significantly reducing inference latency compared to autoregressive next-token prediction. The domain expert uses bidirectional attention and generates all tokens in parallel rather than sequentially. The hidden states from this single forward pass directly encode the decomposed motion instruction, which conditions the action expert.

### Mechanism 3: Conditioning Diffusion Policy on Decomposed Motion
Conditioning the diffusion policy on the generated motion decomposition representation improves language steerability and task success rates by explicitly grounding action generation in an interpretable, language-aligned plan. The action expert (a DiT) is conditioned on visual observations, robot configuration, and crucially, the motion decomposition hidden state from the domain expert. This conditions the denoising process on a semantic plan (e.g., "Pick up the red cube"), aligning actions with the language instruction.

## Foundational Learning

- **Mixture-of-Experts / Mixture-of-Transformers**: Why needed: MoTVLA's core architecture is a Mixture-of-Transformers. Understanding how multiple transformer experts can be combined, specifically how parameters are shared or separated, is critical. Quick check: How does MoT differ from simply training two separate models?

- **Diffusion Models for Policy Learning (Diffusion Policy)**: Why needed: The action expert is a DiT trained via diffusion. Understanding the noise-denoise process and conditioning is essential. Quick check: What is the loss function used to train the denoising network? (See Eq. 5)

- **Autoregressive vs. Non-Autoregressive (Token-wise) Generation**: Why needed: The core distinction between slow (autoregressive) and fast (token-wise) reasoning in MoTVLA. Quick check: Why is token-wise prediction faster than next-token prediction?

## Architecture Onboarding

- **Component map:** Input (Image + Text + Learnable Queries) → Tokenization → [Generalist & Domain Expert] → Shared Global Attention → Output Logits (Slow Reasoning) / Hidden States (Fast Reasoning) → DiT (Action Expert) → Action Trajectory

- **Critical path:** Input (Image + Text + Learnable Queries) → Tokenization → [Generalist & Domain Expert] → Shared Global Attention → Output Logits (Slow Reasoning) / Hidden States (Fast Reasoning) → DiT (Action Expert) → Action Trajectory

- **Design tradeoffs:** Performance vs. Efficiency: Two 7B models increase parameter count and VRAM usage (MoTVLA-14B) compared to a single model. The paper notes a 1B variant for speed but requires pre-training. Reasoning Accuracy vs. Speed: Token-wise fast reasoning is faster but may be less accurate for complex tasks than slow reasoning.

- **Failure signatures:** Reasoning Hallucination: Domain expert generates incorrect or impossible motion steps. The diffusion policy will execute the wrong action. Catastrophic Forgetting (Ablation): If the generalist is fine-tuned, it loses general intelligence. The MoT architecture prevents this. Precision Failure: The Peg-in-Hole task has a relatively low success rate (40%), suggesting the method may struggle with high-precision contact tasks where the motion decomposition abstraction is insufficient.

- **First 3 experiments:** 1. Inference Latency Test: Measure tokens/sec for fast reasoning vs. slow reasoning. Compare against baseline VLMs. 2. Reasoning Ablation: Train a variant where the domain expert is randomly initialized (no knowledge sharing). Verify failure on motion decomposition tasks, as shown in Table 3. 3. Language Steerability Test: Provide ambiguous instructions (e.g., "Sort rubbish") and compare task success against a baseline that treats all objects as targets.

## Open Questions the Paper Calls Out

### Open Question 1
Can the MoTVLA architecture be effectively miniaturized to smaller parameter sizes (e.g., 0.5B) without losing general intelligence, thereby avoiding the prohibitive multi-stage pre-training currently required for small models? The conclusion notes that while inference speed improves at 0.5B scale, "pre-training a 0.5B model to acquire general intelligence remains highly challenging."

### Open Question 2
Does jointly pre-training the action expert with the reasoning backbone on large-scale open-sourced robotics datasets resolve the "strong reasoning but insufficient execution" failures observed in long-horizon tasks? The authors identify that "relatively limited amount of data available for training the action expert sometimes leads to... failures on long-horizon tasks," and suggest this joint pre-training as a future direction.

### Open Question 3
Is the architectural constraint requiring the generalist and domain expert to share the same model size (doubling parameters) fundamental to the shared global attention mechanism? Section 3.1 notes, "the current design requires the generalist and domain expert to share the same model size," which results in the reasoning backbone containing twice the parameters of the generalist alone.

### Open Question 4
Can the reliance on manually annotated motion decompositions be replaced by automated extraction from existing datasets without degrading policy accuracy? The authors note the "workload of collecting and annotating such data [motion decompositions] in-house is prohibitively large," limiting the action expert training data to only 1,050 trajectories.

## Limitations

- **Architectural Complexity and Resource Demands:** The dual-7B architecture (MoTVLA-14B) significantly increases computational requirements and memory footprint compared to single-model baselines.

- **Generalization Boundaries:** While zero-shot generalization is demonstrated with distractions, the approach's robustness to novel task distributions, out-of-distribution objects, or substantially different environments is not explored.

- **High-Precision Task Limitations:** The Peg-in-Hole task shows notably lower success rates (40%) compared to other tasks (up to 81%), suggesting the motion decomposition abstraction may be insufficient for contact-rich, high-precision manipulation tasks.

## Confidence

- **Mechanism 1 (Knowledge Sharing):** High - The architecture and training procedure are clearly specified, and the shared attention mechanism is the core innovation preventing catastrophic forgetting.
- **Mechanism 2 (Fast Reasoning):** High - Token-wise prediction vs. autoregressive generation is well-established; the 9 Hz vs <1 Hz performance difference is empirically demonstrated.
- **Mechanism 3 (Diffusion Conditioning):** Medium - While the conditioning mechanism is clear, the quality and hallucination resistance of generated motion decompositions depends heavily on the domain expert's reasoning accuracy.

## Next Checks

1. **Hallucination Robustness Test:** Systematically inject synthetic hallucinations into domain expert outputs (e.g., wrong object names, impossible motion steps) and measure the diffusion policy's ability to recover or fail gracefully, quantifying the sensitivity of action execution to reasoning errors.

2. **Catastrophic Forgetting Verification:** Train an ablation variant where the generalist is fine-tuned (no MoT architecture) and benchmark its performance on general VQA datasets (e.g., MMMU) before and after robotic training to empirically confirm knowledge preservation.

3. **Scaling Analysis:** Evaluate MoTVLA-1B (pre-trained variant) on the same tasks to determine whether the performance-efficiency tradeoff remains favorable at smaller scales, and whether pre-training is essential for smaller models to achieve reasonable performance.