---
ver: rpa2
title: 'TED++: Submanifold-Aware Backdoor Detection via Layerwise Tubular-Neighbourhood
  Screening'
arxiv_id: '2510.14299'
source_url: https://arxiv.org/abs/2510.14299
tags:
- backdoor
- attacks
- samples
- uni00000013
- validation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TED++ introduces a submanifold-aware framework to detect backdoor
  attacks by constructing tubular neighbourhoods around class submanifolds and applying
  locally adaptive ranking to identify off-manifold activations. This method addresses
  the limitations of previous defences that rely on ambient-space distances, which
  can fail to detect subtle backdoor anomalies when clean examples are scarce.
---

# TED++: Submanifold-Aware Backdoor Detection via Layerwise Tubular-Neighbourhood Screening

## Quick Facts
- arXiv ID: 2510.14299
- Source URL: https://arxiv.org/abs/2510.14299
- Reference count: 40
- Key outcome: TED++ introduces a submanifold-aware framework to detect backdoor attacks by constructing tubular neighbourhoods around class submanifolds and applying locally adaptive ranking to identify off-manifold activations. This method addresses the limitations of previous defences that rely on ambient-space distances, which can fail to detect subtle backdoor anomalies when clean examples are scarce. TED++ estimates the local thickness of each class's hidden-feature manifold from clean activations and assigns worst-case ranks to any activation outside this tube, capturing deviations from the evolving class submanifolds. Extensive experiments on CIFAR-10, GTSRB, and TinyImageNet demonstrate that TED++ achieves state-of-the-art detection performance under both adaptive attacks and limited-data scenarios, with gains up to 14% in AUROC over the next-best method, even with as few as five held-out examples per class.

## Executive Summary
TED++ addresses the challenge of detecting backdoor attacks in deep neural networks, particularly when clean validation data is limited. The method constructs tubular neighbourhoods around class submanifolds in the hidden-feature space and uses Locally Adaptive Ranking (LAR) to identify activations that drift off these manifolds. By aggregating LAR-adjusted ranks across layers and applying PCA-based anomaly detection, TED++ captures subtle backdoor-induced path deviations that ambient-space nearest-neighbor methods miss. Experiments show state-of-the-art detection performance with significant gains in AUROC, even with minimal validation samples per class.

## Method Summary
TED++ is a two-stage framework for input-level backdoor detection. First, it estimates a tube radius τ_ℓ for each layer by measuring the maximum distance among the nearest neighbors within each class from clean validation activations. It then applies Locally Adaptive Ranking (LAR), which assigns the worst possible rank to any activation outside its class's tube, otherwise retaining the natural nearest-neighbor rank. Second, it forms a rank trajectory across all layers for each input and applies PCA to the clean validation trajectories. Inputs with high reconstruction error relative to this PCA model are flagged as poisoned. This approach leverages the manifold hypothesis to detect off-manifold activations while remaining robust to limited clean validation data.

## Key Results
- Achieves up to 14% higher AUROC compared to the next-best method (IBD-PSC) on CIFAR-10 with only 5 validation samples per class.
- Maintains strong performance under adaptive attacks (Ada-Blend, TaCT) where previous methods degrade significantly.
- Demonstrates graceful degradation when up to 40% of validation classes are missing, using Nearest-Neighbor Label Flipping to handle absent classes.
- Robust to extreme data scarcity, with minimal performance drop even when only 2 clean validation samples per class are available.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Constructing tubular neighborhoods around class submanifolds enables detection of off-manifold poisoned activations that ambient-space nearest-neighbor methods miss.
- Mechanism: For each layer ℓ, TED++ estimates a tube radius τℓ from clean validation activations using the maximum pairwise distance among ⌈mβ⌉ nearest neighbors within each class. Any activation whose distance to its nearest class-c neighbor exceeds τℓ lies outside the tube and is flagged as anomalous.
- Core assumption: Clean class activations lie on or near smooth low-dimensional submanifolds (manifold hypothesis), while poisoned activations drift off these submanifolds during intermediate layers before reconverging in ambient space.
- Evidence anchors:
  - [abstract] "TED++ begins by constructing a tubular neighbourhood around each class's hidden-feature manifold, estimating its local 'thickness' from a handful of clean activations."
  - [Section 3.3] "Around each submanifold M^(ℓ)_c, define a tubular neighbourhood of radius τℓ... We choose τℓ so that H^(ℓ)_c ⊂ T^(ℓ)_c(τℓ)."
  - [corpus] Related work (TED-LaST, UniGuard) also exploits trajectory dynamics but without explicit tube constraints; corpus lacks direct validation of tube-based geometry.
- Break condition: If clean validation samples themselves lie far from the true submanifold (e.g., extreme label noise or adversarial contamination), tube radius estimates become inflated, allowing poisoned samples to remain undetected inside overly wide tubes.

### Mechanism 2
- Claim: Locally Adaptive Ranking (LAR) penalizes off-tube activations more severely than raw nearest-neighbor ranks, amplifying the signal from subtle manifold departures.
- Mechanism: Standard nearest-neighbor ranking computes Rℓ(x) as the index of the first same-class validation neighbor. LAR modifies this: if the closest class-c validation activation lies outside the tube (distance > τℓ), force Rℓ(x) = |V| (worst possible rank); otherwise, retain the natural rank.
- Core assumption: Off-tube distance is a stronger indicator of malicious perturbation than relative neighbor ordering within the tube.
- Evidence anchors:
  - [abstract] "It then applies Locally Adaptive Ranking (LAR) to detect any activation that drifts outside the admissible tube."
  - [Section 3.4] "By forcing off-tube activations to take the worst-case rank, LAR sharply increases sensitivity to true off-manifold (backdoor) perturbations while leaving on-tube variations unpenalised."
  - [Figure 2] Visualizes LAR assigning worst ranks (199) to poisoned samples outside the tube while clean samples retain rank 0.
  - [corpus] No corpus papers explicitly use LAR; related detection methods (IBD-PSC, SCALE-UP) rely on entropy or prediction consistency rather than geometry-aware ranking.
- Break condition: If poisoned activations happen to fall inside the estimated tube (e.g., adaptive attacks that minimize off-manifold drift), LAR provides no advantage over standard ranking.

### Mechanism 3
- Claim: Aggregating LAR-adjusted ranks across layers into a trajectory and detecting anomalies via PCA reconstruction error captures coherent backdoor-induced path deviations.
- Mechanism: Each input x yields a rank trajectory R(x) = [R₁(x), ..., R_L(x)]. PCA is fit on clean validation trajectories; at test time, inputs with high reconstruction error (indicating they deviate from the learned normal subspace) are flagged as poisoned.
- Core assumption: Clean trajectories occupy a low-dimensional subspace with structured fluctuations, while poisoned trajectories exhibit anomalous patterns that do not reconstruct well from clean principal components.
- Evidence anchors:
  - [abstract] "By aggregating these LAR-adjusted ranks across all layers, TED++ captures how faithfully an input remains on the evolving class submanifolds."
  - [Section 3.5] "Under the tube-constrained manifold hypothesis, clean-input trajectories occupy a low-dimensional subspace in R^L... We collect these rank trajectories from all clean validation samples and fit a PCA model to capture their principal modes."
  - [corpus] TED-LaST extends trajectory-based detection with adaptive defenses; UniGuard uses trajectory analysis for unified adversarial/backdoor detection—consistent with trajectory-based anomaly detection being a viable signal.
- Break condition: If poisoned trajectories happen to lie within the PCA subspace learned from clean data (e.g., attacks that produce rank sequences similar to clean inputs), reconstruction error will be low and detection fails.

## Foundational Learning

- Concept: **Manifold hypothesis and tubular neighborhoods**
  - Why needed here: TED++ models class activations as lying on low-dimensional submanifolds; understanding tube geometry (radius estimation, distance-to-manifold) is essential for grasping why ambient-space ranks fail and how tube-constrained ranks succeed.
  - Quick check question: Given a set of points approximating a 1D curve in 3D space, how would you estimate the "thickness" of a tube around that curve using only a finite sample?

- Concept: **Distance concentration in high-dimensional spaces**
  - Why needed here: The paper attributes TED's failure to distance concentration—where nearest and farthest neighbors become nearly equidistant in high dimensions—making raw ranks uninformative. Recognizing this phenomenon explains why tube constraints are necessary.
  - Quick check question: In a 1000-dimensional space, why might a poisoned point that has drifted off-manifold still appear as a "nearest neighbor" to a clean validation point?

- Concept: **PCA for anomaly detection**
  - Why needed here: TED++ uses PCA on rank trajectories to define a "normal" subspace; high reconstruction error signals anomalous (poisoned) inputs. Understanding reconstruction-based anomaly detection clarifies the final detection step.
  - Quick check question: If you fit PCA on clean trajectories with K principal components, what does a high reconstruction error for a test trajectory indicate about its relationship to the clean data?

## Architecture Onboarding

- Component map:
  - Input -> Stage 1 (Ranking Computation) -> Stage 2 (Input Detection) -> Output
  - Input: Test sample x, validation sets {V_c} per class, pre-trained DNN with L layers
  - Stage 1: Layer-wise activation extraction h^(ℓ)(x); tube radius estimation τ_ℓ; LAR to assign Rℓ(x)
  - Stage 2: Trajectory formation R(x); PCA model fit on clean trajectories; reconstruction error computation; thresholding
  - Output: Binary label (clean/poisoned) per input

- Critical path:
  1. Tube radius estimation depends critically on having ≥2 clean validation samples per class (τℓ cannot be computed with fewer).
  2. LAR's effectiveness hinges on τℓ accurately capturing the local spread of clean activations; too tight → false positives; too loose → false negatives.
  3. PCA threshold θ determines the false-positive/false-negative trade-off; must be calibrated on held-out clean validation data.

- Design tradeoffs:
  - **β (neighbor percentile factor)**: Controls tube thickness. Paper finds 0.5 ≤ β ≤ 0.9 optimal; higher β risks including outliers, lower β makes tubes overly tight (Fig. 3).
  - **Number of validation samples m**: TED++ remains robust down to m=2 per class (Table 5), unlike TED which degrades rapidly. More samples improve tube estimation but increase setup cost.
  - **Number of layers L**: Using all layers captures full trajectory but increases computation; paper uses standard ResNet-18 blocks without further selection guidance.

- Failure signatures:
  - **Missing validation classes (ρ > 0)**: If a class has <2 validation samples, TED++ uses Nearest-Neighbor Label Flipping (Alg. 2) to map inputs to available classes. Performance degrades gracefully up to ρ=0.4 (Table 6).
  - **Adaptive attacks minimizing off-tube drift**: If attackers craft triggers that keep poisoned activations within estimated tubes, LAR provides no signal. Paper does not evaluate this scenario explicitly.
  - **Extremely deep networks**: Paper acknowledges computational cost may become prohibitive; inference time is ~0.02s/sample for ResNet-18 (Fig. 5).

- First 3 experiments:
  1. **Reproduce core result (Table 2/3)**: Run TED++ vs. TED vs. IBD-PSC on CIFAR-10 with m=5 validation samples/class across BadNets, Blend, and Trojan attacks. Verify AUROC gap (TED++ should achieve ~0.95+ vs. TED's ~0.60–0.80 on challenging attacks).
  2. **Ablate tube radius estimation**: Replace τℓ with (a) fixed global threshold, (b) percentile-based threshold without per-class adaptation, (c) oracle threshold using all clean data. Measure impact on AUROC to confirm the importance of local tube estimation.
  3. **Stress-test missing validation classes**: Reproduce Table 6 by varying ρ from 0 to 0.4 on CIFAR-10 with m=5. Verify graceful degradation and identify the attack types most sensitive to missing classes.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the computational efficiency of rank-based metrics in TED++ be optimized for extremely deep neural networks without sacrificing detection robustness?
  - **Basis in paper**: [explicit] The authors acknowledge a practical limitation where "computational cost of rank-based metrics can become high" in deep networks and call for future research into "innovative approaches" to mitigate this.
  - **Why unresolved**: The current experiments focus on ResNet-18; the per-sample inference cost and rank complexity may scale poorly with network depth and embedding dimension.
  - **Evidence to resolve**: Demonstration of TED++ maintaining real-time inference speeds on very deep architectures (e.g., ResNet-101 or larger) while retaining high AUROC.

- **Open Question 2**: Can the submanifold-aware framework be generalized to non-CNN architectures, specifically Vision Transformers (ViT)?
  - **Basis in paper**: [inferred] The paper relies on the "topological evolution dynamics" of standard convolution–BN–ReLU blocks, and all experiments are conducted exclusively on ResNet-18.
  - **Why unresolved**: The geometric properties of feature manifolds in attention-based mechanisms (ViT) may differ significantly from CNNs, potentially affecting the tube-radius estimation.
  - **Evidence to resolve**: Evaluation of TED++ on standard datasets using a ViT backbone, showing comparable separation between on-tube and off-tube activations.

- **Open Question 3**: Can the method be adapted to function effectively with fewer than two clean validation samples per class, such as in a one-shot or unsupervised setting?
  - **Basis in paper**: [explicit] The threat model explicitly assumes defenders have "at least two validation samples per class," and the method fails if this condition is not met.
  - **Why unresolved**: The ablation study on missing classes (ρ) assumes existing classes still have sufficient samples; the minimal data requirement for tube estimation remains unexplored.
  - **Evidence to resolve**: A modification of the tube estimation protocol that uses synthetic or statistical approximations to succeed with only one sample per class.

- **Open Question 4**: Can an adaptive attack be constructed to explicitly optimize the trigger to remain within the estimated tubular neighbourhood, thereby bypassing LAR?
  - **Basis in paper**: [inferred] While the paper tests "adaptive attacks" (e.g., Ada-Blend), these are existing attacks; none are specifically designed to minimize the "off-tube" drift detected by the LAR mechanism.
  - **Why unresolved**: The defense relies on the assumption that poisoned trajectories drift off-manifold; a targeted attack might find an adversarial path that stays within the tube τ_ℓ.
  - **Evidence to resolve**: formulation of a "Tube-Aware" attack that constrains the optimization loss to minimize the distance d(z, M_c^(ℓ)).

## Limitations
- **Tube radius estimation sensitivity**: Performance degrades if clean validation samples are noisy or contaminated, as tube radius estimates become unreliable.
- **Computational scalability**: Rank-based metrics and layer-wise processing may become prohibitive for very deep networks beyond ResNet-18.
- **Adaptive attack vulnerability**: The method assumes poisoned activations drift off-manifold; adaptive attacks specifically designed to minimize off-tube drift are not evaluated.

## Confidence
- **High confidence** in the core mechanism of tube-constrained manifold hypothesis and LAR-based rank modification—the mathematical framework is clearly defined and the geometric intuition is well-supported.
- **Medium confidence** in generalization performance—while results show strong AUROC gains on benchmark datasets, the experiments are limited to specific architectures (ResNet-18) and attack types; real-world deployment may encounter different failure modes.
- **Low confidence** in robustness against adaptive attacks that minimize off-manifold drift—the paper does not provide explicit evaluation of this scenario, which is critical for assessing practical security guarantees.

## Next Checks
1. **Test tube radius sensitivity**: Systematically vary β from 0.1 to 0.9 and measure impact on detection performance, particularly focusing on false positive/negative trade-offs when clean validation samples are minimal (m=2 per class).
2. **Evaluate adaptive attack resistance**: Design and implement attacks that specifically minimize off-manifold drift (e.g., optimize poisoned activations to remain within estimated tubes τ_ℓ) and measure TED++'s detection performance compared to baselines.
3. **Scale to deeper architectures**: Apply TED++ to ResNet-50 or deeper models on TinyImageNet, measuring both detection performance and computational overhead to assess scalability limits.