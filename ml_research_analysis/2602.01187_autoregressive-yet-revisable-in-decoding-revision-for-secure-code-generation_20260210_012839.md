---
ver: rpa2
title: 'Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation'
arxiv_id: '2602.01187'
source_url: https://arxiv.org/abs/2602.01187
tags:
- revision
- code
- generation
- stream
- decoding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Stream of Revision, a decoding framework
  that internalizes just-in-time revision into autoregressive code generation. By
  embedding special action tokens for vulnerability detection, localization, and patching,
  the model can backtrack and edit its own history within a single forward pass, avoiding
  the latency and token overhead of external repair agents.
---

# Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation
## Quick Facts
- arXiv ID: 2602.01187
- Source URL: https://arxiv.org/abs/2602.01187
- Reference count: 40
- Autoregressive model with in-decoding revision achieves 45.2% security pass rate on CyberSecEval 2 C/C++ while preserving coding utility

## Executive Summary
This paper introduces Stream of Revision, a decoding framework that internalizes just-in-time revision into autoregressive code generation. By embedding special action tokens for vulnerability detection, localization, and patching, the model can backtrack and edit its own history within a single forward pass, avoiding the latency and token overhead of external repair agents. The approach was aligned on real-world CVE pairs using a minimal set of examples (around 1,000), enabling the model to learn structured security revision patterns. Evaluation on CyberSecEval 2 shows significant improvements in secure code generation for C/C++ while preserving general coding utility, with zero-shot transfer to other languages. Stream of Revision also outperforms agentic repair baselines in efficiency and maintains high syntactic validity, demonstrating that runtime revision is both effective and practical.

## Method Summary
Stream of Revision augments autoregressive code generation with special action tokens (`<|backtracking|>`, `<|OLD|>`, `<|/OLD|>`, `<|NEW|>`, `<|/NEW|>`) that enable in-decoding vulnerability detection, localization, and patching. The model learns to emit these tokens at appropriate points during generation, allowing it to revise its own output without external intervention. Training uses CVE pairs filtered to strict samples (single function, single hunk) mixed with general C/C++ instructions, with special token embeddings initialized from semantic descriptions. Constrained decoding ensures valid localization, and a deterministic renderer applies patches atomically. The framework achieves significant security improvements while maintaining general coding performance.

## Key Results
- Security Pass Rate on CyberSecEval 2 C/C++ improves from 18.5% to 45.2%
- Pass@1 on HumanEval remains at 51.8%, preserving general coding utility
- 20.5% average token savings compared to agentic repair baselines
- Zero-shot transfer to other languages demonstrated with no additional training

## Why This Works (Mechanism)
Stream of Revision works by embedding revision capabilities directly into the autoregressive generation process. The model learns to identify vulnerabilities in its own output and correct them in real-time using structured action tokens. This approach eliminates the latency and complexity of external repair agents while maintaining the efficiency of single-pass generation. The use of constrained decoding ensures valid localization, and the minimal training data requirement (around 1,000 examples) makes the approach practical. By learning revision patterns from real CVE pairs, the model develops the ability to recognize and fix common security vulnerabilities during generation rather than after completion.

## Foundational Learning
- **CVE pair processing**: Extracting vulnerable and patched code spans from security advisories is essential for training revision capabilities. Quick check: Verify that extracted diffs contain exactly one function modification and one hunk.
- **Semantic token initialization**: Initializing special token embeddings using description semantics prevents training collapse and ensures meaningful revision actions. Quick check: Confirm that token embeddings are weighted averages of their description embeddings before training.
- **Constrained decoding**: Enforcing substring localization constraints prevents hallucinated vulnerable spans and maintains generation validity. Quick check: Validate that 100% of generated localization spans are valid substrings of the prefix code.
- **Mixed training objectives**: Combining security revision data with general coding instructions preserves overall coding utility while teaching security patterns. Quick check: Monitor HumanEval scores to ensure they don't degrade during security-focused training.
- **Single-pass revision**: Learning to revise within a single forward pass eliminates the need for external agents and reduces latency. Quick check: Measure token savings compared to two-stage generation plus repair approaches.

## Architecture Onboarding
- **Component map**: Input specifications -> Autoregressive decoder -> Special action tokens -> Constrained localization -> Atomic patch application -> Output code
- **Critical path**: Code generation -> Vulnerability detection -> Localization span prediction -> Patch generation -> Backtracking and replacement
- **Design tradeoffs**: Single-pass revision vs. external repair agents (latency vs. flexibility), minimal training data vs. comprehensive coverage, constrained decoding vs. generation freedom
- **Failure signatures**: Model collapse (no triggering or constant triggering), hallucinated localization spans, excessive triggering from noisy data, semantic drift from synthetic specifications
- **First experiments**: 1) Train on strict CVE pairs only and evaluate security gains, 2) Test zero-shot transfer to Python/Java security benchmarks, 3) Compare token efficiency against agentic repair baselines

## Open Questions the Paper Calls Out
None

## Limitations
- The approach relies on synthetic security-neutral specifications that may introduce distributional shifts not fully characterized
- Zero-shot transfer claims, while promising, have not been extensively validated across diverse languages and domains
- The method's effectiveness depends on the availability of CVE pairs with clear single-function/single-hunk diffs, which may not represent the full complexity of real-world vulnerable code

## Confidence
- High confidence: The core mechanism of in-decoding revision with special tokens is technically sound and the implementation details are well-specified
- Medium confidence: The security improvements on CyberSecEval 2 are demonstrated but depend on the quality of synthetic data generation
- Medium confidence: Zero-shot transfer claims are promising but not extensively validated across diverse languages and domains
- Low confidence: Long-term generalization beyond the specific CVE distribution used for training has not been established

## Next Checks
1. Evaluate zero-shot transfer to non-C-family languages (e.g., Python, Java) on security benchmarks to validate cross-language generalization claims
2. Conduct ablation studies on synthetic data quality by comparing security gains when using different teacher models for specification generation
3. Test robustness to more complex vulnerability patterns (multi-function, multi-hunk) to assess limitations of the strict sample filtering approach