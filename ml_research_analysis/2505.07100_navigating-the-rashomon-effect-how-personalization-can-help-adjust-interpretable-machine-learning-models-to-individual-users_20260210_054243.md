---
ver: rpa2
title: 'Navigating the Rashomon Effect: How Personalization Can Help Adjust Interpretable
  Machine Learning Models to Individual Users'
arxiv_id: '2505.07100'
source_url: https://arxiv.org/abs/2505.07100
tags:
- interpretable
- personalization
- users
- interpretability
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether intrinsically interpretable machine
  learning models can be personalized while maintaining their key advantage of faithful
  representations. The researchers developed a personalization approach that leverages
  the Rashomon effect - the existence of multiple models with similar predictive performance
  but different visual representations.
---

# Navigating the Rashomon Effect: How Personalization Can Help Adjust Interpretable Machine Learning Models to Individual Users

## Quick Facts
- arXiv ID: 2505.07100
- Source URL: https://arxiv.org/abs/2505.07100
- Reference count: 0
- Personalization of interpretable models maintains faithful representations while accommodating individual user preferences

## Executive Summary
This study investigates whether intrinsically interpretable machine learning models can be personalized while maintaining their key advantage of faithful representations. The researchers developed a personalization approach that leverages the Rashomon effect - the existence of multiple models with similar predictive performance but different visual representations. Using contextual bandits, they personalized Generalized Additive Models (GAMs) for 108 participants in an online experiment. The personalization led to 44 distinct model configurations among 53 users in the treatment group, demonstrating that users developed distinct preferences for different model characteristics.

## Method Summary
The researchers developed a personalization approach for intrinsically interpretable machine learning models that leverages the Rashomon effect. They used contextual bandits to personalize Generalized Additive Models (GAMs) by adjusting three parameters: the number of splines (1-5), span size (0.25-0.75), and feature subset (top 3-6 features). The study conducted an online experiment with 108 participants using the COMPAS recidivism prediction dataset. Participants interacted with either personalized models (treatment group, n=53) or non-personalized models (control group, n=55). The contextual bandit algorithm used a softmax-based exploration strategy to recommend model configurations based on users' past interactions, balancing exploration of new configurations with exploitation of known preferences.

## Key Results
- Personalization led to 44 distinct model configurations among 53 users in the treatment group
- No significant differences in insight quality or user perception between personalized and non-personalized groups
- Interpretability remained high across both personalized and non-personalized groups

## Why This Works (Mechanism)
The approach works by leveraging the Rashomon effect, where multiple models with similar predictive performance exist but have different visual representations. By using contextual bandits, the system can learn individual user preferences for different model characteristics (splines, span size, feature subsets) while maintaining faithful representations. The personalization algorithm balances exploration of new configurations with exploitation of known preferences, allowing users to discover configurations that best suit their needs without sacrificing interpretability.

## Foundational Learning
- **Rashomon Effect**: Multiple models with similar performance but different visual representations exist
  - Why needed: Enables personalization while maintaining predictive accuracy
  - Quick check: Can we find multiple models with similar performance but different visual structures?
- **Contextual Bandits**: Reinforcement learning approach for sequential decision-making with context
  - Why needed: Enables adaptive personalization based on user interactions
  - Quick check: Does the algorithm improve recommendation accuracy over time?
- **Generalized Additive Models (GAMs)**: Interpretable models where predictions are sums of smooth functions of features
  - Why needed: Provide inherent interpretability that can be personalized
  - Quick check: Are model components visually distinguishable and meaningful to users?
- **Faithful Representations**: Model visualizations that accurately reflect the underlying model behavior
  - Why needed: Ensures personalization doesn't compromise interpretability
  - Quick check: Do personalized models maintain accurate visual representations?

## Architecture Onboarding
- **Component Map**: User Interface -> GAM Model Configuration -> Contextual Bandit Algorithm -> Model Performance Evaluation -> User Feedback
- **Critical Path**: User interaction → Contextual bandit recommendation → Model configuration → Performance evaluation → User feedback
- **Design Tradeoffs**: Personalization complexity vs. interpretability maintenance; exploration vs. exploitation balance
- **Failure Signatures**: Users unable to find preferred configurations; interpretability degradation; poor performance despite personalization
- **First Experiments**: 1) Test personalization with single parameter adjustment; 2) Evaluate user preference consistency across sessions; 3) Measure impact of different exploration rates

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Sample of 108 participants may not represent diverse user populations
- Personalization approach focused on GAM models and may not translate to other interpretable model families
- Study context (recidivism prediction) may limit applicability to domains with different stakes or user expertise requirements

## Confidence
- High: Personalization leads to diverse model configurations (44 distinct configurations among 53 users)
- High: Interpretability maintained with no significant differences in insight quality between groups
- Medium: Whether personalization preferences would persist across different prediction tasks or datasets
- Medium: Real-world deployment challenges with contextual bandit parameter tuning

## Next Checks
1. Replicate the personalization approach across multiple domains (e.g., healthcare, finance) to test generalizability of user preference patterns
2. Conduct longitudinal studies to examine whether personalization preferences remain stable over time and with increased model exposure
3. Test the personalization framework with other intrinsically interpretable model families (e.g., decision trees, rule-based models) to assess framework flexibility