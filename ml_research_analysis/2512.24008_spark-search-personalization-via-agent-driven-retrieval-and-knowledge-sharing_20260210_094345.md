---
ver: rpa2
title: 'SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing'
arxiv_id: '2512.24008'
source_url: https://arxiv.org/abs/2512.24008
tags:
- memory
- spark
- retrieval
- personalization
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SPARK introduces a multi-agent architecture for personalized search
  that dynamically routes queries to specialized persona agents, each with dedicated
  long- and short-term memory stores. The system uses a Persona Coordinator to select
  appropriate agents and coordination protocols (independent, relay, or debate) based
  on query context and predicted difficulty.
---

# SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing

## Quick Facts
- arXiv ID: 2512.24008
- Source URL: https://arxiv.org/abs/2512.24008
- Reference count: 40
- Primary result: Multi-agent architecture with dynamic persona routing, cognitive-inspired memory layers, and structured coordination protocols for personalized search

## Executive Summary
SPARK introduces a multi-agent architecture for personalized search that dynamically routes queries to specialized persona agents, each with dedicated long- and short-term memory stores. The system uses a Persona Coordinator to select appropriate agents and coordination protocols (independent, relay, or debate) based on query context and predicted difficulty. Drawing on cognitive architecture principles, SPARK separates working, episodic, and semantic memory to distinguish transient context from persistent user preferences. The framework employs adaptive routing via contextual bandits, structured agent collaboration, and Reciprocal Rank Fusion for result aggregation. Evaluation hypotheses and metrics are proposed to assess coordination efficiency, personalization quality, cognitive load distribution, and diversity. The design addresses personalization drift, privacy risks, and filter bubbles through memory safeguards and diversity-aware objectives.

## Method Summary
SPARK implements a multi-agent system where queries are routed to specialized persona agents through a coordination layer. The Persona Coordinator uses contextual bandit routing to select agents based on query-session embeddings and persona embeddings, activating top-k agents via softmax scoring. Each agent executes a RAG loop combining external web retrieval with internal memory retrieval across working, episodic, and semantic memory stores. Three coordination protocols—independent specialists, relay chains, and constrained debate—are selected based on query complexity. An arbiter fuses ranked lists using Reciprocal Rank Fusion and ensures grounding with citations. The system employs adaptive routing, structured agent collaboration, and cognitive-inspired memory separation to balance personalization quality with efficiency and diversity.

## Key Results
- Dynamic persona routing with contextual bandits enables context-sensitive agent selection
- Cognitive-inspired memory separation (working/episodic/semantic) distinguishes transient context from persistent preferences
- Structured coordination protocols (independent/relay/debate) improve answer quality on complex queries
- Reciprocal Rank Fusion with intent-aware diversity optimization counters filter bubble effects

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic persona routing may improve personalization quality by matching specialized agents to query characteristics.
- Mechanism: The Persona Coordinator computes a stochastic routing distribution over agents using query-session embeddings and persona embeddings, activating top-k agents via softmax scoring. This replaces static routing with context-sensitive agent selection.
- Core assumption: Query-persona alignment correlates with retrieval utility gains.
- Evidence anchors:
  - [abstract] "Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents"
  - [Section 3] Formal routing equation: w_t(π) = softmax(W·φ(q_t, c_t)·ψ(π))
  - [corpus] "Beyond Static Evaluation" paper notes static benchmarks fail to reflect evolving user needs (FMR=0.53), supporting the motivation for dynamic routing—but does not validate SPARK's specific approach.
- Break condition: If routing confidence falls below threshold θ or query complexity is low, the system falls back to independent specialists (Algorithm 2), limiting overhead on simple queries.

### Mechanism 2
- Claim: Layered memory separation (working/episodic/semantic) is hypothesized to reduce context bloat while preserving personalization fidelity.
- Mechanism: Working memory (M_s) holds transient step-relevant state; episodic memory (M_e) stores recent interaction traces for session continuity; semantic memory (M_sem) encodes stable long-term preferences. Agents retrieve from both external corpora (D_web) and internal memory (D_mem) during RAG.
- Core assumption: Cognitive-inspired memory separation yields efficiency/fidelity tradeoffs that mirror human cognitive architectures (Baddeley, ACT-R).
- Evidence anchors:
  - [abstract] "layered memory" and "cognitive-inspired memory (working, episodic, semantic)"
  - [Section 4.1] "This separation is motivated by cognitive science findings that specialized memory buffers improve both efficiency and fidelity"
  - [corpus] MERMAID paper (FMR=0.47) demonstrates memory-enhanced retrieval for veracity assessment, suggesting memory-augmented retrieval is a viable pattern—but SPARK's specific tripartite design remains unvalidated.
- Break condition: If episodic memory is removed (ablation condition), the system should show degraded session-level utility, indicating reliance on short-term context.

### Mechanism 3
- Claim: Structured coordination protocols (independent/relay/debate) may improve answer quality on complex queries through specialized reasoning patterns.
- Mechanism: Independent specialists fuse results in parallel (low overhead); relay chains enable sequential refinement π₁→π₂→...→π_m (compositional queries); constrained debate uses adversarial critique rounds with judge oversight (ambiguous/high-stakes queries). A contextual bandit selects protocols based on predicted query difficulty.
- Core assumption: Protocol-task alignment exists and can be learned from delayed reward signals (clicks, dwell time, satisfaction).
- Evidence anchors:
  - [abstract] "coordinated via relay, debate, or independent specialist modes"
  - [Section 4.4] Trade-off analysis: "Independent specialists maximize efficiency but may miss cross-agent refinement. Debate yields most rigorously vetted answers but at highest cost."
  - [corpus] "The Spark Effect" paper (FMR=0.53, h-index=41) shows persona-conditioned LLM agents can increase creative diversity—suggesting persona-based coordination has precedent, though not in search personalization specifically.
- Break condition: If debate protocol is disabled, complex query accuracy may drop; if bandit exploration is disabled, the system risks overfitting to historical patterns and missing task drift.

## Foundational Learning

- Concept: **Contextual Bandits for Adaptive Routing**
  - Why needed here: The Persona Coordinator uses contextual bandits (LinUCB, Thompson Sampling) to balance exploration (trying new agent/protocol combinations) vs. exploitation (using historically effective choices). Understanding the exploration-exploitation tradeoff is essential for tuning routing policies.
  - Quick check question: Given a query with low historical data, should the bandit favor exploration or exploitation? How does the reward signal (clicks, dwell time) influence this decision?

- Concept: **Retrieval-Augmented Generation (RAG) with Internal and External Retrieval**
  - Why needed here: Each persona agent executes a RAG loop combining external web retrieval (D_web) with internal memory retrieval (D_mem). Understanding how to ground LLM outputs in retrieved evidence—and how to fuse multi-source evidence—is core to agent execution.
  - Quick check question: If D_web returns conflicting documents with D_mem, how should the agent weigh and reconcile these sources in its reasoning trace?

- Concept: **Reciprocal Rank Fusion (RRF) and Intent-Aware Diversity (ERR-IA)**
  - Why needed here: The Arbiter fuses ranked lists from multiple agents using RRF by default, with optional learned fusion. ERR-IA is used to optimize for intent coverage, counteracting filter bubble effects from over-personalization.
  - Quick check question: How does RRF handle agents with uncalibrated score distributions? What happens to diversity if personalization signals dominate the fusion objective?

## Architecture Onboarding

- Component map:
  Query → Persona Coordinator (routing + protocol selection) → Activated Agents (parallel/relay/debate) → Individual RAG loops (D_web + D_mem retrieval) → Per-agent rankings + notes → Arbiter (fusion + synthesis) → Final answer with citations

- Critical path:
  Query → Persona Coordinator (routing + protocol selection) → Activated Agents (parallel/relay/debate) → Individual RAG loops (D_web + D_mem retrieval) → Per-agent rankings + notes → Arbiter (fusion + synthesis) → Final answer with citations

- Design tradeoffs:
  - **Independent vs. Debate protocols**: Independent minimizes latency (k≤2 agents for low-complexity queries) but may miss cross-agent refinement; debate improves factual accuracy on ambiguous queries but incurs 3-5x latency cost
  - **Memory separation vs. unified context**: Separating working/episodic/semantic memory reduces context bloat (H3) but adds retrieval complexity and consistency overhead
  - **Bandit exploration vs. stability**: Exploration enables adaptation to task drift within 3-5 interactions but introduces short-term variance in routing quality
  - **Personalization vs. diversity**: ERR-IA optimization for intent coverage may reduce immediate relevance gains from personalized ranking

- Failure signatures:
  - **Coordination overhead on simple queries**: Latency spikes, token consumption exceeds single-agent baseline → suggests gating mechanism failed to bypass multi-agent orchestration
  - **Personalization drift**: Semantic memory overfits to transient session behavior (e.g., one-off research topic contaminates long-term profile) → indicates decay-based weighting or confidence thresholds for memory updates are misconfigured
  - **Filter bubble formation**: Result diversity drops over time, ERR-IA scores decline → diversity objectives not properly integrated into routing/fusion
  - **Memory extraction vulnerability**: Adversarial prompts retrieve stored personal data → suggests RBAC, encryption-at-rest, or scope-limited inter-agent communication not enforced
  - **Knowledge divergence**: Base model parameters contradict evolving user-specific memory → indicates unlearning/consistency mechanisms not triggered

- First 3 experiments:
  1. **Protocol ablation on TREC Session Track**: Run independent, relay, and debate protocols on sessions of varying complexity; measure nDCG@k, latency, and token consumption per protocol. Hypothesis: debate improves accuracy on complex sessions but matches independent on simple sessions only at higher cost.
  2. **Memory layer ablation**: Disable episodic memory (M_e) and measure session-level utility degradation vs. full memory. Hypothesis: removing episodic memory reduces continuity across multi-turn sessions without affecting single-query performance.
  3. **Bandit vs. static routing comparison**: Deploy contextual bandit routing against a static routing baseline in simulated cold-start conditions; measure interactions needed to reach parity with warmed profiles. Hypothesis: bandit routing adapts to task drift within 3-5 interactions, static routing fails to detect drift.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific query complexity conditions does constrained debate between agents yield net positive utility per token compared to independent specialist execution, and can a reliable predictor of this threshold be learned?
- Basis in paper: [explicit] The authors hypothesize (H1) that "for low-complexity queries, independent specialist protocols with k ≤ 2 active personas will yield higher utility per token than constrained debate," while "for complex queries... a single round of constrained debate should improve accuracy."
- Why unresolved: The paper proposes the hypothesis but presents no empirical results; the gating mechanism using predicted difficulty and novelty remains unvalidated.
- What evidence would resolve it: Controlled experiments across TREC Session Track and MS MARCO datasets measuring utility-per-token ratios between protocols, with query difficulty labels and learned threshold boundaries.

### Open Question 2
- Question: How can semantic memory distinguish transient task-driven behavior from stable preference changes without requiring excessive user intervention or manual pruning?
- Basis in paper: [explicit] The paper identifies "personalization drift—where transient user behavior is mistaken for stable preference" and notes that "a user researching an unrelated topic for a short-term task may inadvertently skew their long-term profile."
- Why unresolved: Proposed mitigations (decay-based weighting, repeated evidence requirements) are described conceptually but not empirically tested for their effectiveness in preventing drift.
- What evidence would resolve it: Longitudinal user studies tracking profile stability metrics under different memory update policies, measuring false positive rates for preference inference.

### Open Question 3
- Question: What architectural safeguards effectively prevent memory extraction attacks in multi-agent systems with shared persistent memory while maintaining retrieval utility?
- Basis in paper: [explicit] The authors cite "memory extraction attacks, where carefully crafted conversational queries progressively siphon stored personal data from long-term memory" and acknowledge SPARK's memory design "inherently stores potentially sensitive data."
- Why unresolved: Proposed mitigations (encryption-at-rest, scope-restricted retrieval, differential privacy) remain untested in the multi-agent coordination context.
- What evidence would resolve it: Red-team adversarial audits measuring attack success rates under different safeguard configurations, alongside utility metrics for legitimate retrieval tasks.

## Limitations
- Memory subsystem update policies and inter-layer consistency mechanisms are not fully detailed
- Contextual bandit exploration-exploitation schedule and reward signal design lack specification
- Specific implementations of persona embeddings and protocol selection thresholds remain underspecified
- Memory extraction vulnerability and personalization drift mitigation strategies are conceptual rather than tested

## Confidence
- **High confidence**: Cognitive architecture principles and coordination protocols are well-motivated by existing literature
- **Medium confidence**: Adaptive routing via contextual bandits is theoretically sound but practically dependent on reward signal quality
- **Low confidence**: Specific implementations of key components (persona embeddings, memory updates, protocol thresholds) remain underspecified

## Next Checks
1. **Protocol efficacy ablation study**: Implement and test independent, relay, and debate protocols on TREC Session Track sessions of varying complexity, measuring nDCG@k, latency, and token consumption per protocol to validate the claimed trade-offs.

2. **Memory layer dependency test**: Disable episodic memory (M_e) in a controlled experiment and measure session-level utility degradation versus full memory to quantify the contribution of short-term context continuity.

3. **Cold-start bandit adaptation**: Deploy contextual bandit routing against a static routing baseline in simulated cold-start conditions, measuring the number of interactions needed to reach parity with warmed profiles and testing the hypothesis that bandit routing adapts to task drift within 3-5 interactions.