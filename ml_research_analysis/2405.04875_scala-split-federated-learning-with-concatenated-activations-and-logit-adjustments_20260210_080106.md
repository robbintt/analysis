---
ver: rpa2
title: 'SCALA: Split Federated Learning with Concatenated Activations and Logit Adjustments'
arxiv_id: '2405.04875'
source_url: https://arxiv.org/abs/2405.04875
tags:
- label
- learning
- local
- client
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes SCALA (Split Federated Learning with Concatenated
  Activations and Logit Adjustments) to address label distribution skew in split federated
  learning (SFL). SCALA tackles two types of skew: local (data heterogeneity across
  clients) and global (due to partial client participation).'
---

# SCALA: Split Federated Learning with Concatenated Activations and Logit Adjustments

## Quick Facts
- **arXiv ID:** 2405.04875
- **Source URL:** https://arxiv.org/abs/2405.04875
- **Reference count:** 40
- **Primary result:** SCALA achieves up to 91.25% accuracy on CIFAR-10 under severe label skew conditions in split federated learning.

## Executive Summary
This paper introduces SCALA (Split Federated Learning with Concatenated Activations and Logit Adjustments) to address label distribution skew in split federated learning (SFL). The method tackles both local skew (data heterogeneity across clients) and global skew (due to partial client participation) by centrally training the server-side model using concatenated activations from client-side models, while applying logit adjustments to loss functions to handle long-tailed label distributions. Theoretical analysis shows SCALA achieves sublinear convergence and effectively reduces gradient dissimilarity. Experiments demonstrate significant improvements in accuracy compared to baseline methods across multiple datasets.

## Method Summary
SCALA modifies the standard SFL pipeline by having the server concatenate activations from participating clients into a unified batch for centralized training. This addresses local label distribution skew by forming a "virtual centralized" dataset. The method applies logit adjustments to the loss function, subtracting the log-prior of each label to enhance recognition of low-frequency labels in the long-tailed concatenated batch. After local client updates, server-side models are updated centrally on concatenated activations with adjusted logits, while gradients backpropagated to clients are computed using client-specific label distributions. The process iterates with model aggregation after local steps.

## Key Results
- Achieves up to 91.25% accuracy on CIFAR-10 under severe label skew conditions
- Demonstrates improved per-class accuracy for rare classes compared to baselines
- Shows that deeper split points (more server-side layers) yield higher accuracy and faster convergence
- Reduces gradient dissimilarity between clients, accelerating convergence

## Why This Works (Mechanism)

### Mechanism 1: Union of Class Support via Concatenation
Concatenating activations from participating clients allows the server-side model to train on a unified batch that mitigates local label distribution skew. Instead of training separate server-side heads for each client or aggregating models blindly, the server concatenates activations into a single batch, forming a "virtual centralized" dataset. This ensures the server sees a broader union of classes than any single client possesses, assuming features extracted by client-side models for the same class are semantically aligned enough to be processed by a shared server-side head.

### Mechanism 2: Logit Adjustment for Long-Tailed Recognition
The method modifies the softmax cross-entropy by subtracting the log-prior of the label from the logits. This calibrates the misclassification error, preventing the model from overfitting to frequent classes in the skewed concatenated batch. The server accurately estimates the label distribution of the concatenated activations, and this distribution correlates with the global skew. This adjustment enhances recognition of low-frequency labels at the cost of high-frequency accuracy.

### Mechanism 3: Gradient Dissimilarity Reduction
Increasing the number of server-side layers reduces the gradient dissimilarity caused by data heterogeneity, accelerating convergence. By moving the cut-layer deeper (offloading more layers to the server), the centralized training on concatenated activations handles the "difficult" decision boundary formation, leaving only feature extraction to the heterogeneous clients. This assumes the server has sufficient computational capacity to handle the deeper model segments.

## Foundational Learning

- **Concept: Split Federated Learning (SFL)**
  - Why needed here: SCALA modifies the standard SFL pipeline. You must understand that SFL combines Split Learning (SL) offloading with Federated Learning (FL) aggregation.
  - Quick check question: In standard SFL, does the server update its model using aggregated gradients or direct backpropagation? (SCALA changes this to direct backprop on concatenated data).

- **Concept: Label Distribution Skew (Local vs. Global)**
  - Why needed here: SCALA treats these differently. Local skew (missing classes on clients) is solved by concatenation. Global skew (long-tail across clients) is solved by logit adjustment.
  - Quick check question: If 90% of clients hold only "Cat" data, is this local or global skew? (It is local heterogeneity, but SCALA assumes a mix of clients exists to form the union).

- **Concept: Logit Adjustment / Class-Balanced Loss**
  - Why needed here: Understanding that standard Cross-Entropy biases toward frequent classes. Logit adjustment is a specific mathematical intervention to counter this.
  - Quick check question: Why subtract the log-prior instead of weighting the loss? (Logit adjustment modifies the classifier's decision boundary directly, often shown to be more effective for long-tail data).

## Architecture Onboarding

- **Component map:** Client-side model (feature extractor) -> Activation Uploader -> Server (concatenates activations, trains classifier) -> Logit Adjustment -> Gradient Downloader -> Client-side model update -> Aggregator

- **Critical path:**
  1. Clients compute activations $A_k$ and labels $Y_k$
  2. Server concatenates $\{A_k\} \to A$ and $\{Y_k\} \to Y$
  3. Server performs centralized update on $w_s$ using Logit-Adjusted Loss
  4. Server computes gradients for $A_k$ and sends back to clients
  5. Clients update $w_c$ locally
  6. Server aggregates updated $w_c$ from all clients (FedAvg step)

- **Design tradeoffs:**
  - Communication vs. Accuracy: SCALA transmits activations every local iteration, increasing bandwidth compared to standard FL, but reduces computation on clients
  - Split Depth: Deeper server-side models improve convergence but increase server load and communication size

- **Failure signatures:**
  - Convergence Collapse: If the split point is too shallow and data is highly non-IID, gradient dissimilarity may persist
  - Long-Tail Failure: If using SCALA without logit adjustment, the model may still bias toward the majority class in the concatenated batch

- **First 3 experiments:**
  1. **Ablation Study:** Train SplitFedV1 vs. CA-SFL (no logit) vs. SCALA on CIFAR-10 with $\alpha=2$ to isolate the gain from concatenation vs. logit adjustment
  2. **Participation Sensitivity:** Vary participation ratio $\rho \in [5\%, 50\%]$ to verify robustness to global label skew
  3. **Split Point Analysis:** Test different split points (S1 vs S4) on AlexNet to validate the theoretical link between server-side depth and gradient dissimilarity

## Open Questions the Paper Calls Out

### Open Question 1
Can activation compression mechanisms be integrated into SCALA to reduce communication overhead without degrading the efficacy of logit adjustments? The authors explicitly state that designing "activation compression schemes" is a valuable direction because SCALA relies on frequent exchanges of intermediate activations. The paper demonstrates that logit adjustment efficacy relies on the "holistic view" provided by concatenated activations; compression might distort this view.

### Open Question 2
How can SCALA be modified to secure the transmission of labels, which currently poses a privacy leakage risk? The Conclusion lists the requirement to transmit labels as the first limitation, noting that incorporating privacy-preserving mechanisms is a promising direction. The central server requires ground-truth labels $Y_k$ to calculate the loss and perform logit adjustments, creating a privacy vulnerability distinct from feature leakage.

### Open Question 3
Can the trade-off between robustness to model inversion attacks and classification accuracy in Privacy-Enhanced SCALA (SCALA-PE) be further optimized? In Section 5.7, the authors show that while SCALA-PE resists attacks, accuracy drops (e.g., from 67.35% to 65.50% on CIFAR-100). The introduction of inversion-aware regularization and bottleneck layers necessarily restricts feature information to confuse attackers, which may conflict with the feature richness needed for logit adjustment.

## Limitations

- **Communication Overhead:** SCALA transmits activations every local iteration, increasing bandwidth requirements compared to standard federated learning approaches
- **Privacy Concerns:** The method requires transmitting ground-truth labels to the server, creating a privacy leakage risk not present in standard SFL
- **Theoretical Assumptions:** The convergence guarantees rely on assumptions about bounded gradient dissimilarity that may not hold under extreme data heterogeneity

## Confidence

- **Concatenation + Logit Adjustment Improves Accuracy:** High confidence (consistent across all datasets and skew levels)
- **Deeper Split Points Improve Convergence:** Medium confidence (supported by Fig. 7 but limited to two architectures)
- **Theoretical Convergence Guarantees:** Low confidence (theoretical bounds provided but limited empirical validation)

## Next Checks

1. **Bandwidth Analysis:** Measure actual communication costs (activation sizes, transmission frequency) versus standard FL baselines under different participation ratios
2. **Gradient Dissimilarity Validation:** Track and visualize gradient dissimilarity metrics during training to empirically verify the theoretical claims about deeper split points
3. **Calibration Assessment:** Evaluate model calibration (e.g., Expected Calibration Error) to determine if accuracy gains for rare classes come at the cost of confidence miscalibration