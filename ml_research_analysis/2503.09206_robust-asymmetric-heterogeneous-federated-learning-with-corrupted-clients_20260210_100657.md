---
ver: rpa2
title: Robust Asymmetric Heterogeneous Federated Learning with Corrupted Clients
arxiv_id: '2503.09206'
source_url: https://arxiv.org/abs/2503.09206
tags:
- data
- learning
- clients
- local
- corruption
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a robust federated learning framework, RAHFL,
  to handle model heterogeneity and data corruption in federated learning. It proposes
  a diversity-enhanced supervised contrastive learning strategy that leverages complex
  augmented data for improved robustness, and an asymmetric heterogeneous federated
  learning approach that allows selective knowledge transfer to avoid incorporating
  low-quality information from underperforming clients.
---

# Robust Asymmetric Heterogeneous Federated Learning with Corrupted Clients

## Quick Facts
- **arXiv ID**: 2503.09206
- **Source URL**: https://arxiv.org/abs/2503.09206
- **Reference count**: 40
- **One-line result**: RAHFL achieves up to 9% higher accuracy than state-of-the-art methods on corrupted CIFAR-10 data in heterogeneous federated learning settings.

## Executive Summary
This paper introduces RAHFL, a robust federated learning framework designed to handle both model heterogeneity and data corruption in federated learning. The framework employs a diversity-enhanced supervised contrastive learning strategy (DCL) that leverages complex augmented data to improve corruption robustness, and an asymmetric heterogeneous federated learning approach (AsymHFL) that enables selective knowledge transfer between clients based on performance rankings. Experiments demonstrate that RAHFL significantly outperforms existing methods on corrupted CIFAR-10 datasets, maintaining superior accuracy even with numerous heterogeneous clients.

## Method Summary
RAHFL operates in two phases: local learning and collaborative learning. During local learning, each client applies DCL using mixed data augmentation to generate simple and complex views of images, combining cross-entropy loss with consistency regularization via Jensen-Shannon divergence and supervised contrastive loss. The collaborative phase employs AsymHFL, where clients transfer knowledge selectively through KL divergence on a public unlabeled dataset, with transfer direction determined by a binary matrix based on comparative accuracy rankings. The framework handles heterogeneous model architectures by allowing one-way knowledge flow from higher-performing to lower-performing clients, preventing contamination from corrupted or underperforming models.

## Key Results
- RAHFL achieves up to 9% higher accuracy than state-of-the-art methods on corrupted CIFAR-10 data
- In heterogeneous settings (ξ=0.5), AsymHFL improves average accuracy by 16.19% (clean) and 16.43% (corrupted)
- RAHFL maintains superior performance with numerous clients, scaling effectively beyond 4 clients
- DCL component improves corrupted data performance from 74.37% to 77.43% compared to standard supervised contrastive learning

## Why This Works (Mechanism)

### Mechanism 1: Diversity-Enhanced Supervised Contrastive Learning for Local Corruption Robustness
The DCL component generates simple and complex augmented views, using simple augmentations as intermediaries to align similarity distributions via KL divergence regularization. This extracts diverse corruption-invariant features while preserving discriminability, improving resilience to unseen corruption patterns without degrading clean-data performance.

### Mechanism 2: Asymmetric Knowledge Transfer for Corrupted-Client Isolation
AsymHFL constructs a binary knowledge transfer matrix based on comparative model accuracy on a held-out test set. If client p's accuracy ≤ client q's accuracy, client p learns from q (Mpq = 1), but not vice versa. This creates a directed acyclic flow of information from more robust to less robust models, preventing high-performing clients from being contaminated by low-quality updates.

### Mechanism 3: JSD Consistency Loss for Augmentation Stability
The framework enforces output consistency across multiple augmentation levels using Jensen-Shannon Divergence between output distributions. This prevents overfitting to specific distortion patterns while maintaining semantic discrimination, ensuring the model doesn't become overly sensitive to augmentation-specific features.

## Foundational Learning

- **Concept: Supervised Contrastive Learning**
  - **Why needed here:** DCL extends standard SupCon by handling complex augmentations indirectly. Understanding how SupCon pulls same-class samples together and pushes different-class samples apart is essential for grasping the regularization strategy.
  - **Quick check question:** Given a batch with two images of the same class and five of different classes, can you compute the supervised contrastive loss and explain which pairs are positive vs. negative?

- **Concept: Knowledge Distillation via Output Distributions**
  - **Why needed here:** AsymHFL transfers knowledge through KL divergence between soft label distributions on public data. Understanding why this works for heterogeneous models is crucial.
  - **Quick check question:** Why can a ResNet-10 and a MobileNet-v2 communicate effectively through their softmax outputs on the same input, even though their intermediate representations are incompatible?

- **Concept: Mixed Data Augmentation (AugMix-style)**
  - **Why needed here:** The random mixed augmentation strategy chains and weighs multiple operations. Understanding how this generates diverse corruption-like patterns is necessary to see why it builds robustness.
  - **Quick check question:** If augmentation set A = {rotation, color jitter, blur}, and you sample three sequences with Dirichlet weights, how does the resulting mixed image differ from applying a single augmentation?

## Architecture Onboarding

- **Component map:**
  RAHFL Framework -> Local Learning Phase (per-client, Tl epochs) -> Collaborative Learning Phase (global, Tc rounds)

- **Critical path:**
  1. Pre-train each local model on private data (40 epochs)
  2. For each collaborative round tc ∈ [1, Tc]:
     - Local update: Apply DCL with mixed augmentation for Tl epochs
     - Broadcast: Each client computes output distribution on D0
     - Rank: Server evaluates all models on test split xt
     - Construct M: Binary matrix based on accuracy comparisons
     - Transfer: Each client minimizes KL loss to higher-performing peers
  3. Return final local models {θ1, ..., θK}

- **Design tradeoffs:**
  - Public dataset size (N0): Larger D0 improves transfer quality but increases communication/computation
  - Knowledge transfer matrix update frequency (Tf): More frequent updates yield higher accuracy but require per-round evaluation
  - Corruption rate estimation: Method assumes known corruption rates; deployment requires inference
  - Heterogeneity vs. homogeneity gain: AsymHFL provides value even in homogeneous settings but overhead may not justify use with identical clean data

- **Failure signatures:**
  - Test accuracy plateaus below baseline: Check if AsymHFL is overly restrictive or D0 is unrepresentative
  - Corrupted test performance degrades with DCL: Examine augmentation severity or disable complex augmentation
  - Convergence oscillation: Verify knowledge transfer matrix M is recomputed each round
  - Non-IID performance collapse: Check Dirichlet concentration parameter β; lower β may require adjusting λ or local epochs

- **First 3 experiments:**
  1. Baseline sanity check: Run RAHFL with ξ=0 (clean data), all components enabled. Verify clean test accuracy ~84-87% matches Table 5.
  2. Ablation isolation: Disable DCL (set γ=0) and run with ξ=0.5 corruption. Confirm performance drops to ~80% (Table 2, "AsymHFL + Aug" row).
  3. Matrix update sensitivity: Compare Tf ∈ {1, 3, 5} with ξ=1 corruption. Expect ~1.6% accuracy drop from Tf=1 to Tf=5.

## Open Questions the Paper Calls Out

### Open Question 1
Can the RAHFL framework be adapted to eliminate the dependency on an auxiliary unlabeled public dataset while maintaining robust heterogeneous communication? The authors explicitly identify reliance on public data as a limitation for real-world scenarios where such data may not be available.

### Open Question 2
How can the computational overhead of DCL and frequent knowledge transfer matrix updates be reduced for resource-constrained edge devices? The framework introduces additional computational processes that limit applicability on weak devices.

### Open Question 3
Is the asymmetric transfer strategy robust if the generic test dataset used to calculate performance rankings is not representative of the private data distributions? In real-world federated environments, a clean, representative validation set may not be accessible to the server or clients.

### Open Question 4
How does the fixed weighting of consistency (μ) and regularization (γ) losses impact the framework's ability to handle varying levels of corruption severity across different clients? Fixed weights imply static trade-off between classification, consistency, and contrastive learning.

## Limitations

- Evaluation relies on controlled synthetic corruption rates rather than real-world contamination patterns
- Effectiveness assumes strong correlation between validation accuracy and corruption robustness, which may not hold across architectures
- Public dataset D0 introduces potential domain shift when transferring knowledge to CIFAR-10 tasks
- Performance gains come at increased computational overhead from dual augmentation pipelines

## Confidence

- **High confidence**: Core ablation results showing DCL improves corrupted-data performance (Table 4: 77.43% vs 74.37% baseline)
- **High confidence**: AsymHFL's accuracy improvements under heterogeneity (Tables 2-3: 16%+ gains)
- **Medium confidence**: Claims about robustness to unknown corruption patterns
- **Medium confidence**: Generalization of asymmetric transfer benefits to larger client pools (>4)

## Next Checks

1. **Domain Shift Validation**: Replace CIFAR-100 public dataset with CIFAR-10 subset to test whether transfer quality degrades when source and target domains align

2. **Architecture Diversity Stress Test**: Extend experiments to 8-12 heterogeneous clients with varying capacities (including very small/mobile models) to verify asymmetric benefits persist

3. **Real-World Contamination Test**: Apply RAHFL to a federated dataset with naturally occurring label noise or sensor corruption (e.g., human activity recognition with accelerometer artifacts) to validate synthetic corruption transferability