---
ver: rpa2
title: Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer
  Reasoning
arxiv_id: '2508.18395'
source_url: https://arxiv.org/abs/2508.18395
tags:
- answer
- tasks
- tokens
- token
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Latent Self-Consistency (LSC) introduces a universal consistency-selection
  method that works effectively across both short-answer and long-answer reasoning
  tasks. By learning compact semantic representations through learnable summary tokens
  and supervised contrastive learning, LSC achieves near-perfect consistency scores
  (averaging 97.8% on short-answer and 92.4% on long-answer tasks) while adding at
  most 0.9% inference-time overhead.
---

# Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning

## Quick Facts
- arXiv ID: 2508.18395
- Source URL: https://arxiv.org/abs/2508.18395
- Authors: Jungsuk Oh; Jay-Yoon Lee
- Reference count: 40
- Primary result: Introduces LSC - a universal consistency-selection method achieving 97.8% short-form and 92.4% long-form consistency scores with <1% inference overhead

## Executive Summary
Latent Self-Consistency (LSC) introduces a universal consistency-selection method that works effectively across both short-answer and long-answer reasoning tasks. By learning compact semantic representations through learnable summary tokens and supervised contrastive learning, LSC achieves near-perfect consistency scores while adding at most 0.9% inference-time overhead. The method matches Self-Consistency performance on short-answer benchmarks and outperforms existing approaches on long-answer tasks including code generation and summarization, all without requiring changes to model architecture or format-dependent tuning. LSC also provides well-calibrated confidence estimates across diverse task types, maintaining low expected calibration error comparable to traditional Self-Consistency on short-form tasks while extending reliable calibration to long-form generation.

## Method Summary
LSC learns compact semantic representations for responses using learnable summary tokens appended after each response's EOS token. These K=6 special tokens are processed through a lightweight forward pass that reuses the KV cache from generation, with their mean-pooled hidden states forming a compact embedding. Summary token embeddings are trained via supervised contrastive learning to pull same-answer responses together and push different-answer responses apart, while the base LLM remains frozen. During inference, LSC samples N=10 candidates per question, computes pairwise cosine similarities between their embeddings, and uses exponentially weighted scores to identify the majority-set representative. The method achieves high consistency (averaging 97.8% on short-answer and 92.4% on long-answer tasks) with minimal inference overhead.

## Key Results
- Achieves 97.8% average consistency on short-answer tasks (GSM8K: 99.7%, MATH: 99.7%, TriviaQA: 96.0%)
- Maintains 92.4% average consistency on long-answer tasks (TruthfulQA: 92.6%, MMLU: 92.4%, Summ.: 92.3%, Code: 91.5%)
- Adds at most 0.9% inference-time overhead compared to vanilla decoding
- Provides well-calibrated confidence estimates with low expected calibration error across both answer formats
- Outperforms existing approaches on long-answer tasks while matching Self-Consistency performance on short-answer benchmarks

## Why This Works (Mechanism)

### Mechanism 1: Post-Generation Semantic Embedding via Summary Tokens
- Appending learnable tokens after the EOS token and computing their final-layer representations captures response semantics more reliably than using existing EOS tokens or external encoders.
- Summary tokens are processed through a lightweight forward pass that reuses the KV cache from generation. Mean-pooled hidden states from K=6 tokens form a compact embedding z_i.
- These embeddings are trained via supervised contrastive learning to pull same-answer responses together and push different-answer responses apart.
- Core assumption: The base LLM's frozen representations contain sufficient semantic signal that lightweight learned probes can extract consistency-relevant features without modifying model weights.

### Mechanism 2: Exponential Weighted Similarity Suppresses Outliers
- Exponentially weighted cosine similarity scores identify the majority-set representative more robustly than arithmetic mean or surface-level overlap metrics.
- For each response i, compute w_i = (1/(N-1)) × Σ_{j≠i} exp(S_ij / τ') where S_ij is cosine similarity and τ'=0.5.
- Exponential weighting down-weights low-similarity pairs, so w_i reflects primarily the majority cluster rather than the global centroid.
- Core assumption: True majority responses form a tighter semantic cluster than outlier responses; the similarity structure reveals cluster boundaries.

### Mechanism 3: Calibration Through Consistency Scores
- LSC's consistency scores provide well-calibrated confidence estimates that correlate with correctness across both short- and long-form tasks.
- The aggregated similarity score w_i serves as a confidence proxy. High w_i indicates strong semantic agreement among candidates, which correlates with higher accuracy.
- Expected Calibration Error (ECE) measurements show LSC matches Self-Consistency on short-form tasks while extending reliable calibration to long-form.
- Core assumption: Majority agreement correlates with correctness—a foundational premise inherited from Self-Consistency.

## Foundational Learning

- **KV Cache Reuse in Transformers**
  - Why needed here: LSC's efficiency hinges on reusing cached key-value pairs from generation when processing summary tokens, avoiding full re-computation.
  - Quick check question: Can you explain why appending tokens to an existing sequence with KV cache is O(K×d) rather than O((L+K)×d) where L is sequence length?

- **Supervised Contrastive Learning**
  - Why needed here: The training objective pulls same-label embeddings together and pushes different-label embeddings apart, creating the semantic clustering structure.
  - Quick check question: Given a batch with responses [A₁, A₂, B₁] where A and B are different answers, which pairs are positive and which are negative in the SCL loss?

- **Self-Consistency / Majority Voting**
  - Why needed here: LSC generalizes Self-Consistency's core insight—that repeated sampling and majority selection improves reliability—from short-form to all formats.
  - Quick check question: Why does exact string matching fail for semantically equivalent but lexically different long-form responses?

## Architecture Onboarding

- **Component map**: Candidate Generator -> Summary Token Appender -> Embedding Extractor -> Consistency Scorer -> Selector
- **Critical path**: Response generation → Summary token forward pass → Similarity computation → Score aggregation → Selection. The summary token pass is the only added inference step; it processes only K tokens per response.
- **Design tradeoffs**:
  - K (summary tokens): Paper uses K=6. More tokens increase representational capacity but add computation. Ablation shows limited sensitivity.
  - Pooling strategy: Mean pooling outperforms last-token—use mean.
  - Dynamic Top-K: Helps for small majority sets but can degrade on complex open-ended tasks at high N. Consider task-dependent enabling.
  - Training data balance: 50:50 short:long ratio. Paper notes Qwen's higher accuracy yielded fewer training samples due to filtering—adapt thresholds if base model is very strong.
- **Failure signatures**:
  - Low consistency scores across all responses: No clear majority; consider fallback to vanilla or USC.
  - High consistency but low accuracy on validation: Majority agreement not correlating with truth—task may be unsuitable for consistency-based selection.
  - Sharp drop in Dynamic Top-K at high N: Over-fragmentation in open-ended responses; disable Dynamic Top-K or reduce N.
- **First 3 experiments**:
  1. Reproduce Table 4 consistency scores: Train summary tokens on the paper's dataset mix, evaluate consistency on GSM8K and TruthfulQA. Target: >95% short-form, >90% long-form.
  2. Ablate pooling strategy: Compare mean vs. last-token pooling on MATH. Expect ~2-3 percentage point gap.
  3. Measure inference overhead: Profile the summary token forward pass on 10 candidates with LLaMA3.1-8B. Target: <1% overhead over vanilla decoding.

## Open Questions the Paper Calls Out

- **Adaptive filtering thresholds**: Future work could explore adaptive filtering thresholds or alternative sampling methods to better leverage high-performing models while maintaining training diversity, noting that Qwen3 yielded only 1,520 examples versus 2,670 for LLaMA3 due to filtering constraints.

- **Dynamic Top-K performance degradation**: The paper notes notable performance drop in the Dynamic TopK variant when the number of responses reaches 20 for TruthfulQA consistency, attributed to ambiguous boundaries during majority detection in open-ended settings.

- **Question format classification**: GPT-4o-mini achieved only 14% recognition on conceptual "What"-prefixed questions, suggesting classification is itself a challenging classification problem that may prevent effective method routing.

- **Training data distribution sensitivity**: The paper uses a fixed 50:50 short/long training ratio but does not ablate this choice, leaving open whether optimal balance varies by application.

## Limitations

- Task dependency of Dynamic Top-K: Effectiveness highly varies by task type, helping on MATH but degrading on open-ended tasks at high N.
- Generalization across domains: Performance relies on majority agreement correlating with correctness, which may fail on misconception-based or creative tasks.
- Training data balance sensitivity: Method may be sensitive to response quality distribution in training data, as evidenced by Qwen3 yielding fewer samples than LLaMA3.

## Confidence

- **High Confidence**: Efficiency claims (inference overhead <1%), consistency score improvements across benchmarks, core mechanism of using learnable summary tokens.
- **Medium Confidence**: Well-calibrated confidence estimates across formats, comparison with Self-Consistency on TruthfulQA.
- **Low Confidence**: Dynamic Top-K being generally beneficial, robustness across arbitrary long-form generation tasks without tuning.

## Next Checks

1. Evaluate LSC's ECE on a broader set of tasks including those where consensus does not correlate with truth to establish the full calibration spectrum.

2. Develop and validate a principled criterion for when to enable Dynamic Top-K across multiple tasks to determine if it consistently identifies beneficial settings.

3. Systematically vary the short/long ratio in training data and measure the impact on consistency scores and accuracy across both short-form and long-form benchmarks.