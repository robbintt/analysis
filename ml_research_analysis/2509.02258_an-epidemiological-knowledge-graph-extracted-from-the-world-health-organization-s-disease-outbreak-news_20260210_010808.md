---
ver: rpa2
title: An Epidemiological Knowledge Graph extracted from the World Health Organization's
  Disease Outbreak News
arxiv_id: '2509.02258'
source_url: https://arxiv.org/abs/2509.02258
tags:
- data
- disease
- outbreak
- information
- extracted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study develops a daily-updated knowledge graph (eKG) of epidemiological\
  \ data extracted from WHO Disease Outbreak News using an ensemble of large language\
  \ models (LLMs). The ensemble approach\u2014combining Mistral-7B-OpenOrca, Zephyr-7B-Beta,\
  \ and Meta-Llama-3-70B-Instruct\u2014achieves superior performance in extracting\
  \ disease names, countries, dates, cases, and deaths compared to individual models\
  \ and commercial alternatives."
---

# An Epidemiological Knowledge Graph extracted from the World Health Organization's Disease Outbreak News

## Quick Facts
- **arXiv ID:** 2509.02258
- **Source URL:** https://arxiv.org/abs/2509.02258
- **Reference count:** 40
- **Key result:** Ensemble of 3 LLMs extracts structured epidemiological entities from WHO Disease Outbreak News with F1 > 0.85 for key fields.

## Executive Summary
This study develops a daily-updated knowledge graph (eKG) of epidemiological data extracted from WHO Disease Outbreak News using an ensemble of large language models (LLMs). The ensemble approach—combining Mistral-7B-OpenOrca, Zephyr-7B-Beta, and Meta-Llama-3-70B-Instruct—achieves superior performance in extracting disease names, countries, dates, cases, and deaths compared to individual models and commercial alternatives. Evaluated against a gold-standard subset of the Incident Database, the ensemble attains an F1 score of 0.851 for disease extraction, 0.962 for country extraction, 0.869 for case counts, and 0.658 for dates. The resulting eKG contains approximately 2.9K outbreak events with ~26K triples, offering a FAIR, interoperable resource for public health research and surveillance.

## Method Summary
The study extracts structured epidemiological entities (disease, country, date, cases, deaths) from unstructured WHO Disease Outbreak News (DONs) text to construct an epidemiological Knowledge Graph (eKG). An ensemble of three LLMs (Mistral-7B-OpenOrca, Zephyr-7B-Beta, Meta-Llama-3-70B-Instruct) processes each report, with documents over 8K tokens first summarized using a specific prompt. Entity extraction uses a JSON-output prompt for each model, followed by synonym grouping using WordNet and Sentence Transformers (BioBERT/all-mpnet-base-v2 with 0.8 similarity threshold) and majority voting. The ensemble is evaluated against a 171-sample gold-standard subset of the Incident Database, targeting F1 > 0.88 for country/date extraction.

## Key Results
- Ensemble achieves F1 scores of 0.851 (disease), 0.962 (country), 0.869 (cases), and 0.658 (dates) on gold-standard validation
- Outperforms individual models and commercial LLMs in all evaluated entity types
- Creates eKG with ~2.9K outbreak events containing ~26K structured triples
- Demonstrates superior performance particularly for country and disease name extraction

## Why This Works (Mechanism)
The ensemble approach combines complementary strengths of three different LLM architectures, reducing individual model biases and errors. By using majority voting on semantically clustered entities, the system achieves higher precision and recall than any single model. The specific prompt engineering and preprocessing steps (summarization for long documents) help standardize input and improve consistency across diverse outbreak report formats.

## Foundational Learning
- **LLM ensemble methods**: Why needed - to combine complementary strengths of different models; Quick check - compare performance of ensemble vs individual models
- **Semantic similarity clustering**: Why needed - to group synonyms like "USA" and "United States"; Quick check - verify clustering with test pairs at threshold 0.8
- **JSON extraction from LLMs**: Why needed - to enable structured data output; Quick check - test LLM with provided prompt and verify JSON parsing
- **Majority voting aggregation**: Why needed - to reduce individual model errors; Quick check - implement voting logic and test with synthetic ensemble outputs
- **Prompt engineering for entity extraction**: Why needed - to guide LLMs to extract specific structured information; Quick check - test prompt with sample DONs and verify output format
- **FAIR principles in knowledge graphs**: Why needed - to ensure interoperability and reusability; Quick check - verify RDF serialization and schema compliance

## Architecture Onboarding

**Component map:**
DONs text -> Summarization (if >8K tokens) -> Three LLMs in parallel -> JSON parsing -> Semantic clustering -> Majority voting -> eKG triples

**Critical path:**
Text preprocessing → LLM inference → JSON parsing → Entity clustering → Voting aggregation → Knowledge graph construction

**Design tradeoffs:**
- **LLM selection**: Chose diverse open-source models over single commercial API for cost control and transparency
- **8K token threshold**: Balances computational cost of summarization against potential loss of detail
- **0.8 similarity threshold**: Heuristic choice for clustering; may need adjustment for different entity types
- **Majority voting**: Simple aggregation method that works well but may miss nuanced cases

**Failure signatures:**
- JSON parsing errors from inconsistent LLM outputs
- Entity fragmentation when synonyms aren't properly clustered
- Date extraction failures with diverse temporal expressions
- Summarization quality degradation for complex outbreak narratives

**Exactly 3 first experiments:**
1. Test JSON parsing robustness with raw LLM outputs to identify formatting inconsistencies
2. Verify semantic clustering by testing with known synonym pairs at 0.8 threshold
3. Evaluate summarization quality on sample long documents to ensure key information retention

## Open Questions the Paper Calls Out
- What is the specific performance accuracy of the LLM ensemble for extracting mortality (death) counts?
- Is the semantic similarity threshold of 0.8 optimal for clustering disease and country synonyms?
- How does the extraction pipeline distinguish between "potential" and "confirmed" cases in early-stage outbreak reports?

## Limitations
- Validation set of 171 samples may be too small for complex epidemiological entity extraction
- Date extraction performance (F1=0.658) remains notably lower than other entity types
- Specific LLM configuration parameters (temperature, top_p) not fully detailed for reproducibility
- 0.8 similarity threshold is heuristic without sensitivity analysis across entity types

## Confidence
- **High confidence:** Ensemble methodology advantage; FAIR and interoperable eKG nature; daily update capability
- **Medium confidence:** Absolute performance metrics, particularly date extraction and generalizability to other data sources
- **Low confidence:** Optimal LLM configuration parameters; robustness of 0.8 similarity threshold across diverse outbreak report styles

## Next Checks
1. **Validation Set Expansion:** Test ensemble on larger, independently annotated WHO DONs set to confirm F1 scores, especially for date extraction (target F1 > 0.7)
2. **Hyperparameter Sensitivity:** Systematically vary LLM generation parameters (temperature, top_p) and entity similarity threshold (0.7-0.9) to identify optimal settings
3. **Cross-Source Generalization:** Apply ensemble to different epidemiological data source (e.g., ProMED-mail reports) to evaluate portability and identify necessary adaptations