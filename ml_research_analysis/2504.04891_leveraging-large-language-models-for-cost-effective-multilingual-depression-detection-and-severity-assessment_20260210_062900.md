---
ver: rpa2
title: Leveraging Large Language Models for Cost-Effective, Multilingual Depression
  Detection and Severity Assessment
arxiv_id: '2504.04891'
source_url: https://arxiv.org/abs/2504.04891
tags:
- depression
- detection
- performance
- dataset
- deepseek
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates four large language models for depression
  detection using clinical interview data, finding that DeepSeek-V3 is the most cost-effective
  and reliable model, achieving an AUC of 0.83 in English and 0.98 in Chinese, while
  reducing costs by over 90% compared to GPT-4o. Zero-shot learning with DeepSeek-V3
  performs comparably to few-shot approaches, supporting its practical deployment.
---

# Leveraging Large Language Models for Cost-Effective, Multilingual Depression Detection and Severity Assessment

## Quick Facts
- arXiv ID: 2504.04891
- Source URL: https://arxiv.org/abs/2504.04891
- Authors: Longdi Xian; Jianzhang Ni; Mingzhu Wang
- Reference count: 10
- Primary result: DeepSeek-V3 achieves AUC of 0.83 in English and 0.98 in Chinese for depression detection while reducing costs by over 90% compared to GPT-4o

## Executive Summary
This study evaluates four large language models for depression detection using clinical interview data, finding that DeepSeek-V3 is the most cost-effective and reliable model. The research demonstrates strong performance in both English and Chinese languages, with DeepSeek-V3 achieving an AUC of 0.83 in English and 0.98 in Chinese while reducing costs by over 90% compared to GPT-4o. Zero-shot learning with DeepSeek-V3 performs comparably to few-shot approaches, supporting its practical deployment for scalable, multilingual depression screening.

However, the model struggles with depression severity classification, particularly for mild depression, showing sensitivity as low as 0.01. It maintains robust AUCs (0.95–0.97) when detecting depression amid other mental disorders. These findings highlight DeepSeek-V3's strong potential for scalable, multilingual depression screening but underscore the need for refinement in severity assessment and clinical validation.

## Method Summary
The study evaluates four large language models (GPT-4o, GPT-4o-mini, DeepSeek-V3, and Claude-3-Haiku) for depression detection using the DAIC-WOZ dataset, which contains clinical interviews from both English and Chinese speakers. The researchers compared zero-shot and few-shot learning approaches across multiple depression detection tasks: binary classification (depression vs. non-depression), severity classification (mild, moderate, severe), and detection amid other mental disorders. Model performance was assessed using AUC, accuracy, sensitivity, and specificity metrics, with cost-effectiveness analysis comparing token usage across models.

## Key Results
- DeepSeek-V3 achieves AUC of 0.83 in English and 0.98 in Chinese for depression detection
- Zero-shot learning with DeepSeek-V3 performs comparably to few-shot approaches
- DeepSeek-V3 reduces costs by over 90% compared to GPT-4o while maintaining superior performance
- Model shows sensitivity as low as 0.01 for mild depression severity classification
- Maintains robust AUCs (0.95–0.97) when detecting depression amid other mental disorders

## Why This Works (Mechanism)
The success of DeepSeek-V3 stems from its ability to process and interpret nuanced language patterns in clinical interviews, capturing the subtle linguistic markers associated with depression. The model's architecture enables it to understand context and emotional content across languages, while its cost-effectiveness comes from optimized tokenization and inference efficiency. The zero-shot capability suggests the model has strong pre-training on relevant linguistic patterns, allowing it to generalize without task-specific fine-tuning.

## Foundational Learning

### Large Language Model Prompt Engineering
- **Why needed**: Enables effective task specification without model retraining
- **Quick check**: Test prompt variations on validation set before deployment

### Cross-lingual Model Evaluation
- **Why needed**: Validates model performance across different languages and cultural contexts
- **Quick check**: Compare performance metrics across language-specific subsets

### Clinical Interview Data Processing
- **Why needed**: Transforms unstructured interview transcripts into analyzable features
- **Quick check**: Verify transcript preprocessing maintains conversational context

## Architecture Onboarding

### Component Map
Raw Clinical Interview Data -> LLM Processing Pipeline -> Depression Detection Output -> Performance Metrics

### Critical Path
Interview transcript → Tokenization → LLM inference → Depression classification → AUC calculation

### Design Tradeoffs
Cost vs. performance: DeepSeek-V3 vs. GPT-4o shows 90% cost reduction with maintained/superior accuracy
Zero-shot vs. few-shot: Comparable performance suggests reduced data requirements and faster deployment

### Failure Signatures
Poor mild depression detection (sensitivity 0.01) indicates model bias toward moderate/severe cases
Language performance gap (0.83 vs 0.98 AUC) suggests potential cultural/linguistic modeling limitations

### First 3 Experiments
1. Validate zero-shot performance on external clinical interview datasets
2. Test severity classification with balanced mild depression samples
3. Evaluate model performance across different interview formats (structured vs. unstructured)

## Open Questions the Paper Calls Out
None

## Limitations
- Validation conducted on single dataset (DAIC-WOZ), limiting external validity
- Struggles with mild depression detection, showing sensitivity as low as 0.01
- Lacks comparison with established depression detection tools and clinical workflow integration

## Confidence

### High Confidence
- Depression detection performance (AUC 0.83 English, 0.98 Chinese)
- Cost-effectiveness claims (90% reduction vs GPT-4o)

### Medium Confidence
- Zero-shot learning equivalence to few-shot approaches
- Performance with co-occurring disorders

### Low Confidence
- Severity classification accuracy, particularly for mild depression

## Next Checks
1. External validation on independent datasets with diverse populations and interview formats
2. Clinical validation measuring real-world impact on detection rates and patient outcomes
3. Comparative evaluation against established depression screening tools and assessment of false positive/negative consequences