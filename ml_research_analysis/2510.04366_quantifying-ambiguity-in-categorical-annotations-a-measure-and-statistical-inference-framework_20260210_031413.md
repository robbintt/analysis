---
ver: rpa2
title: 'Quantifying Ambiguity in Categorical Annotations: A Measure and Statistical
  Inference Framework'
arxiv_id: '2510.04366'
source_url: https://arxiv.org/abs/2510.04366
tags:
- ambiguity
- distribution
- probability
- measure
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel scalar measure, amb(q), to quantify\
  \ aleatoric uncertainty in categorical soft labels. The measure extends quadratic\
  \ entropy by asymmetrically incorporating an explicit \u201Ccan\u2019t solve\u201D\
  \ category, separating uncertainty from class-level indistinguishability versus\
  \ task unresolvability."
---

# Quantifying Ambiguity in Categorical Annotations: A Measure and Statistical Inference Framework

## Quick Facts
- arXiv ID: 2510.04366
- Source URL: https://arxiv.org/abs/2510.04366
- Reference count: 40
- Novel scalar measure amb(q) quantifies aleatoric uncertainty in categorical soft labels

## Executive Summary
This paper introduces amb(q), a novel scalar measure that quantifies aleatoric uncertainty in categorical soft labels by extending quadratic entropy to asymmetrically incorporate an explicit "can't solve" category. The measure is interpretable as a probability value representing the likelihood of label disagreement or abstention. The authors develop a Bayesian Dirichlet-multinomial inference framework providing closed-form expressions for posterior mean and variance, enabling practitioners to disentangle aleatoric from epistemic uncertainty and apply the measure to data curation, benchmark stratification, and active learning workflows.

## Method Summary
The method introduces amb(q) = 1 - (1/(1-q_cs)) × Σq²_k for q_cs < 1, extending quadratic entropy by asymmetrically treating abstention as a special category. A Dirichlet-multinomial conjugate model enables Bayesian inference with closed-form expressions for E(amb(q)) and Var(amb(q)). The framework assumes annotators draw from identical Cat(q) distributions, allowing amb(q) to represent the probability of label disagreement or explicit abstention. The approach provides both point estimates and credible intervals for ambiguity quantification.

## Key Results
- Introduces amb(q) measure that extends quadratic entropy to handle explicit "can't solve" category
- Develops closed-form Bayesian inference framework for posterior mean and variance of amb(q)
- Demonstrates practical utility for data curation, benchmark stratification, and active learning workflows
- Compares against literature baseline and illustrates tradeoffs between interpretability and uniform distribution handling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The ambiguity measure amb(q) quantifies the probability that two independent annotators disagree or one explicitly abstains.
- Mechanism: The measure computes P(Y₁ ≠ Y₂ | Y₂ ≠ cs) where cs is a "can't solve" option, extending quadratic entropy by asymmetrically treating abstention. For a probability vector q, amb(q) = 1 - (1/(1-q_cs)) × Σq²_k when q_cs < 1. This directly maps response distributions to a [0,1] interpretable probability.
- Core assumption: Annotators operate as statistically indistinguishable operators drawing from Cat(q).
- Evidence anchors: [abstract] "Derived from the probability of a label flip or explicit abstention and is interpretable as a probability value." [section 2] Equation (5) provides the formal definition; the label-flip interpretation is explicit in the natural language definition. [corpus] Weak direct validation; related work (e.g., speech emotion ambiguity scaling) supports the premise that categorical annotations are inherently ambiguous, but does not validate this specific functional form.
- Break condition: If annotators are systematically heterogeneous (e.g., expertise-dependent), the assumption of identical Cat(q) behavior invalidates the measure's interpretability.

### Mechanism 2
- Claim: A Dirichlet-multinomial conjugate model provides closed-form expressions for posterior mean and variance of amb(q).
- Mechanism: Given observed counts n and a prior Dir(α₀), the posterior p(q|y) = Dir(α₀ + n) is sampled or integrated analytically. Expected ambiguity E(amb(q)) = 1 - [α₀(α₀-α_cs+1)]⁻¹ × Σα_k(α_k+1) and variance Var(amb) = R + (S-1)×[1-E(amb)]² (with R, S defined in Eq. 20-21).
- Core assumption: The Dirichlet prior adequately captures prior beliefs about label distributions.
- Evidence anchors: [abstract] "Bayesian Dirichlet-multinomial inference framework, providing closed-form expressions for the expected value and variance." [section 3.2] Equations (14) and (22) provide complete derivations; Section 3.5 numerically validates posterior shapes against sampling-based approximations. [corpus] No direct external validation; related work on entropy estimation (Nemenman et al.) cautions about prior sensitivity in similar settings.
- Break condition: If the true label distribution has strong correlations between categories (violating Dirichlet assumptions), the posterior will be misspecified.

### Mechanism 3
- Claim: Epistemic uncertainty (sampling variability) and aleatoric uncertainty (intrinsic ambiguity) are disentangled via the posterior distribution.
- Mechanism: Aleatoric uncertainty is captured by the point value amb(q); epistemic uncertainty is captured by the posterior spread. With sparse annotations, posteriors are wide (high epistemic); with large samples, posteriors concentrate around the aleatoric value.
- Core assumption: Finite-sample variability adequately represents epistemic uncertainty.
- Evidence anchors: [abstract] "Disentangle aleatoric from epistemic uncertainty." [section 3.4] Figure 6 shows how prior choice affects posterior uncertainty; Section 3.5 illustrates posterior concentration with increasing sample size. [corpus] Weak; uncertainty-aware ML frameworks (e.g., dislocation plasticity prediction) conceptually align but don't validate this specific decomposition.
- Break condition: If model misspecification (e.g., ignoring annotator heterogeneity) contributes significantly to epistemic uncertainty, the decomposition conflates multiple sources.

## Foundational Learning

- Concept: **Quadratic Entropy / Gini Impurity**
  - Why needed here: The amb(q) measure is an extension of quadratic entropy (1 - Σp²_k), which quantifies the probability that two random draws differ.
  - Quick check question: For a distribution p = (0.5, 0.5), what is the quadratic entropy? (Answer: 1 - 0.5 = 0.5)

- Concept: **Dirichlet-Multinomial Conjugacy**
  - Why needed here: Enables closed-form Bayesian updates for categorical probability vectors, which is the core of the inference framework.
  - Quick check question: If the prior is Dir(1, 1, 1) and you observe counts (2, 0, 1), what is the posterior? (Answer: Dir(3, 1, 2))

- Concept: **Aleatoric vs. Epistemic Uncertainty**
  - Why needed here: The paper's central goal is to separate task-inherent ambiguity (aleatoric) from uncertainty due to limited samples (epistemic).
  - Quick check question: Does flipping more coins reduce the aleatoric uncertainty of a coin flip? (Answer: No; it only reduces epistemic uncertainty about the bias.)

## Architecture Onboarding

- Component map: Input counts n -> Prior Dir(α₀) -> Posterior Dir(α₀ + n) -> Output E(amb(q)) and Var(amb(q))

- Critical path:
  1. Collect annotations, ensure "can't solve" is an explicit option in the annotation UI
  2. Choose prior (default: Dir(1, ..., 1))
  3. Compute posterior parameters α = α₀ + n
  4. Calculate E(amb(q)) via Eq. (14) and Var(amb(q)) via Eq. (22)
  5. Optionally, sample from Dir(α) to approximate full posterior if non-analytic measures (e.g., amb₀) are needed

- Design tradeoffs:
  - Standard (amb) vs. Modified (amb_mod): amb has a direct probability interpretation but underweights uniform distributions; amb_mod normalizes to [0,1] range but can inflate values quickly
  - Bayesian vs. plug-in: Plug-in estimators are biased low (Section 3.3) but simpler; Bayesian estimators account for epistemic uncertainty but require prior specification
  - Prior choice: Smaller β increases prior uncertainty (Figure 6); β = 1 is a compromise but not universally optimal

- Failure signatures:
  - High n_cs with low total n: Posterior variance explodes; signals need for more annotations
  - Bimodal posterior: May indicate misspecified prior or heterogeneous annotator populations
  - Plug-in estimate ≪ posterior mean: Strong bias signal; prefer Bayesian estimates for small samples

- First 3 experiments:
  1. Synthetic validation: Generate known q vectors, draw multinomial samples, verify that posterior mean converges to true amb(q) as n increases, and that 95% credible intervals have correct coverage
  2. Prior sensitivity analysis: On a fixed dataset, vary β ∈ {0.5, 1.0, 2.0} and report how E(amb(q)) and posterior width change; flag if conclusions flip
  3. Real-world pilot: Apply to an existing crowdsourced dataset with "can't solve" responses (or add this option in a small re-annotation), compute ambiguity scores, and correlate with downstream metrics (e.g., model confidence, annotation time) to assess practical utility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What prior distributions over probability vectors yield better-calibrated ambiguity posteriors than the uniform Dirichlet, particularly for sparse annotation settings?
- Basis in paper: [explicit] Section 3.4: "we explicitly acknowledge that improved priors or more elaborate inference techniques are promising directions for future work."
- Why unresolved: The uniform Dirichlet prior induces non-uniform ambiguity priors that may bias estimates, especially with few annotations. No principled method for selecting β was established.
- What evidence would resolve it: Empirical calibration studies comparing alternative priors (e.g., empirical Bayes, hierarchical) against ground-truth ambiguity across annotation sample sizes.

### Open Question 2
- Question: How can the ambiguity measure framework be extended to model annotator-specific heterogeneity while retaining closed-form inference?
- Basis in paper: [explicit] Discussion: "Richer approaches (e.g., hierarchical Bayesian, latent-rater, or annotator-embedding models) can capture these effects...but lie beyond the scope of this paper."
- Why unresolved: The current model assumes annotators are "statistically indistinguishable," ignoring systematic rater biases or expertise differences that affect soft label distributions.
- What evidence would resolve it: Derivation of moment expressions for a hierarchical Dirichlet model, or demonstration that posterior mean/variance approximations remain tractable under annotator embeddings.

### Open Question 3
- Question: Can an optimal normalization scheme be derived that achieves both probability-valued interpretability and maximal ambiguity for uniform distributions?
- Basis in paper: [inferred] Table 1 documents tradeoffs: amb has clear interpretation but isn't maximal for uniform distributions; ˜amb is maximal but "provides too large ambiguity values too quickly."
- Why unresolved: The two variants represent different philosophical choices (label flip probability vs. normalized label flip) without a formal criterion for choosing between them.
- What evidence would resolve it: Axiomatic analysis identifying desirable properties, or empirical study correlating each variant with downstream task performance across domains.

### Open Question 4
- Question: How should annotation protocol design (UI, instructions, quality controls) balance "can't solve" utilization against strategic over-use by annotators?
- Basis in paper: [explicit] Discussion notes abstention "may necessitate modest UI changes and calibration; strategic over-use can be mitigated with standard quality controls."
- Why unresolved: The paper provides no guidance on what abstention rates indicate healthy vs. problematic annotation practices, or how to set protocol parameters.
- What evidence would resolve it: Controlled experiments varying abstention option framing and measuring resulting soft label distributions against gold-standard ambiguity assessments.

## Limitations
- Assumes annotators are statistically indistinguishable, which may not hold for heterogeneous annotator populations
- Prior sensitivity analysis is limited, with no principled method for selecting Dirichlet hyperparameters
- Limited empirical validation of the aleatoric/epistemic uncertainty decomposition

## Confidence

- **High**: Mathematical derivation of amb(q) and its closed-form Bayesian inference framework. The equations and proofs are internally consistent and follow established statistical principles.
- **Medium**: Interpretation of amb(q) as a probability of disagreement/abstention, and its practical utility for data curation and active learning. These claims are supported by numerical examples but lack extensive empirical validation.
- **Low**: Assumption of statistically indistinguishable annotators. This is a foundational assumption that is not empirically validated and could significantly impact the measure's interpretability.

## Next Checks

1. **Annotator Heterogeneity Test**: Apply the framework to a dataset with known annotator characteristics (e.g., expert vs. novice annotations). Measure whether amb(q) correlates with annotator expertise or if it captures additional sources of uncertainty. If amb(q) is systematically biased for heterogeneous annotators, this would indicate a limitation of the current approach.

2. **Prior Sensitivity Analysis**: On a fixed dataset, systematically vary the Dirichlet prior hyperparameters (e.g., β ∈ {0.5, 1.0, 2.0, 5.0}) and report how E(amb(q)) and posterior width change. Flag if conclusions about data ambiguity flip based on prior choice, which would indicate sensitivity to prior specification.

3. **Coverage Validation**: Generate synthetic data with known q vectors and draw multinomial samples. Verify that 95% credible intervals from the Bayesian framework have correct coverage (i.e., contain the true amb(q) in approximately 95% of simulations) as sample size increases. This would validate the inferential validity of the uncertainty estimates.