---
ver: rpa2
title: A Theoretical Study on Bridging Internal Probability and Self-Consistency for
  LLM Reasoning
arxiv_id: '2510.15444'
source_url: https://arxiv.org/abs/2510.15444
tags:
- reasoning
- error
- confidence
- methods
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a theoretical framework for analyzing sampling-based
  test-time scaling methods in LLM reasoning. The framework decomposes reasoning error
  into estimation error and model error, enabling analysis of two representative methods:
  self-consistency and perplexity.'
---

# A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning

## Quick Facts
- **arXiv ID:** 2510.15444
- **Source URL:** https://arxiv.org/abs/2510.15444
- **Reference count:** 40
- **Primary result:** RPC achieves reasoning performance comparable to self-consistency while reducing sampling costs by 50% and providing more reliable confidence estimates.

## Executive Summary
This paper presents a theoretical framework for analyzing sampling-based test-time scaling methods in LLM reasoning. The framework decomposes reasoning error into estimation error and model error, enabling analysis of two representative methods: self-consistency and perplexity. The analysis reveals that self-consistency suffers from slow estimation error convergence, while perplexity exhibits large model error and degradation issues. To address these limitations, the authors propose RPC (Reasoning-pruning Perplexity Consistency), which combines internal LLM probabilities with self-consistency and prunes low-probability reasoning paths. Theoretical analysis shows RPC achieves both fast estimation error convergence and low model error. Empirical results on seven benchmark datasets demonstrate that RPC achieves reasoning performance comparable to self-consistency while reducing sampling costs by 50% and providing more reliable confidence estimates.

## Method Summary
RPC combines internal LLM probabilities with self-consistency through a three-step process: (1) sample n reasoning paths with internal token log-probabilities, (2) fit a mixture of two Weibull distributions to path probabilities and prune paths with PHigh < 0.5 or probability below the truncated mean, and (3) aggregate retained paths by answer using probability-weighted consistency. The method leverages perplexity-related internal probabilities to achieve exponential convergence of estimation error while preserving the consistency benefits of self-consistency, with automatic pruning reducing both estimation error and model error.

## Key Results
- RPC achieves reasoning performance comparable to self-consistency while reducing sampling costs by 50%
- RPC provides more reliable confidence estimates than existing methods
- Theoretical analysis shows RPC achieves both fast estimation error convergence and low model error

## Why This Works (Mechanism)

### Mechanism 1: Error Decomposition Framework
- Claim: Decomposing reasoning error into estimation error and model error enables principled analysis of sampling-based methods.
- Mechanism: The framework separates variance from sampling (estimation error) from the LLM's inherent reasoning capability (model error), allowing targeted optimization of each component.
- Core assumption: LLM sampling can be modeled as sampling from a Bernoulli distribution.
- Evidence anchors:
  - [abstract] "framework decomposes reasoning error into estimation error and model error"
  - [section 2.2.1, Proposition 1] Shows formal decomposition: E = Estimation Error + Model Error, with cross term vanishing for unbiased estimators
  - [corpus] Limited direct corpus support; this theoretical framing appears novel in this paper
- Break condition: If sampling is heavily biased (not Bernoulli-like), variance estimates may not hold.

### Mechanism 2: Perplexity Consistency (PC)
- Claim: Integrating internal LLM probabilities into self-consistency achieves exponential convergence of estimation error while preserving low model error.
- Mechanism: PC aggregates probabilities across reasoning paths mapped to the same answer: ĥp(PC)(ŷ|x) = Σ I[g(t̃)=ŷ]p(t̃|x), combining PPL's fast convergence with SC's consistency function.
- Core assumption: Each sampled reasoning path is distinct; probabilities are non-negligible for correct paths.
- Evidence anchors:
  - [abstract] "boosting the convergence rate of estimation error from linear to exponential"
  - [section 3.1, Theorem 4] Formal proof showing convergence rate α^n·p(ŷ|x) where α = 1 - p(ŷ|x)/k
  - [corpus] Neighbor "Optimal Self-Consistency" explores similar efficiency improvements but via different mechanisms
- Break condition: When p(ŷ|x)→0, convergence degrades to linear (Remark 6).

### Mechanism 3: Reasoning Pruning (RP)
- Claim: Removing low-probability reasoning paths prevents estimation error degradation and reduces model error.
- Mechanism: RP models the probability distribution as a mixture of two Weibull distributions, identifies high-probability regions via PHigh(x), and removes paths with PHigh < 0.5.
- Core assumption: Correct reasoning paths cluster in high-probability regions; threshold τ ≈ p(y|x) is learnable from distribution shape.
- Evidence anchors:
  - [abstract] "prunes low-probability reasoning paths"
  - [section 3.2, Theorem 7] Proves optimal error reduction with probability ≥ 1 - exp(-2k̂·k²(1-τ/(1-α))²)
  - [corpus] Corpus papers don't directly address pruning; this appears as a novel contribution
- Break condition: If probability distribution is unimodal or highly skewed, Weibull mixture may misclassify paths.

## Foundational Learning

- Concept: **Monte Carlo Estimation and Convergence Rates**
  - Why needed here: Understanding why self-consistency has O(1/n) linear convergence vs. exponential alternatives is essential for grasping RPC's efficiency gains.
  - Quick check question: Can you explain why averaging n Bernoulli samples yields variance proportional to 1/n?

- Concept: **Perplexity as Probability Aggregation**
  - Why needed here: The paper uses perplexity-related internal probabilities p(t|x) as confidence estimates; distinguishing this from traditional perplexity (geometric mean) is critical.
  - Quick check question: How does perplexity differ from raw token probability, and why might they serve different diagnostic purposes?

- Concept: **Mixture Models for Threshold Selection**
  - Why needed here: RP uses Weibull mixture models to automatically determine pruning thresholds without manual tuning.
  - Quick check question: Why might a two-component mixture be appropriate for separating high/low probability regions in LLM outputs?

## Architecture Onboarding

- Component map: Sampled Paths → Reasoning Pruning (Weibull mixture → filter) → Perplexity Consistency (aggregate by answer) → Best-of-N Selection

- Critical path:
  1. Sample n reasoning paths with internal probabilities
  2. Fit Weibull mixture to probability distribution
  3. Compute PHigh for each path; retain if PHigh > 0.5 OR probability ≥ mean
  4. Aggregate retained paths by answer via PC formula
  5. Select answer with highest confidence

- Design tradeoffs:
  - Computational overhead: RP adds O(k(m²+n)) for distribution fitting; negligible vs. LLM inference time
  - Robustness vs. adaptivity: Automatic threshold avoids hyperparameter tuning but assumes bimodal distribution structure
  - Sample diversity: Higher temperatures improve RPC performance but degrade SC (estimation error increases)

- Failure signatures:
  - Degradation under low probabilities: If p(ŷ|x)≈0 for all paths, PC convergence slows to linear
  - Pruning over-aggression: If mixture misidentifies threshold, valid paths may be discarded
  - Sparse unique answers: If k=1 (single path per answer), PC reduces to PPL with its higher model error

- First 3 experiments:
  1. **Convergence validation**: Plot accuracy vs. sample size (n=1,2,4,8,16,32,64) comparing SC, PPL, PC, and RPC on MATH dataset to verify exponential vs. linear convergence claims.
  2. **Ablation study**: Test PC alone (without RP) to isolate contribution of probability-weighted aggregation vs. pruning; expect PC to show faster convergence but possible degradation on low-probability cases.
  3. **Cross-task generalization**: Apply RPC to code generation (HumanEval/MBPP) using semantic equivalence as consistency function to validate beyond mathematical reasoning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the theoretical insights from the RPC framework be utilized to directly improve the training process of LLMs rather than only post-hoc inference methods?
- Basis in paper: [explicit] The authors state in Appendix E: "it remains an open question how to utilize our insights to improve the training process of LLMs."
- Why unresolved: The current method is post-hoc and does not modify LLM architecture or training; performance gains are moderate compared to training-based approaches.
- What evidence would resolve it: Demonstrating that integrating RPC principles into training objectives improves reasoning performance beyond post-hoc application.

### Open Question 2
- Question: What sampling strategies can maximize reasoning path diversity to achieve better convergence rates as suggested by the theoretical framework?
- Basis in paper: [explicit] The authors note: "Our theoretical results indicate that better convergence requires an effective sampling strategy to sample sufficiently diverse reasoning paths, which is not deeply investigated in this paper."
- Why unresolved: The current work uses standard sampling without systematic exploration of diversity-aware strategies.
- What evidence would resolve it: Comparing diversity-driven sampling methods against standard approaches while measuring convergence rates and accuracy.

### Open Question 3
- Question: Can the theoretical framework be extended to analyze other advanced test-time scaling methods beyond self-consistency and perplexity?
- Basis in paper: [explicit] Limitation 1 states: "in this paper, we only focus on the analysis on two typical methods as well as RPC."
- Why unresolved: The framework's generality to other methods remains unverified.
- What evidence would resolve it: Applying the error decomposition framework to methods like ESC, BoN with reward models, or search-based approaches.

## Limitations

- The theoretical framework relies on modeling LLM sampling as Bernoulli trials, which may not fully capture the complex dependencies in real reasoning paths.
- Empirical validation is limited to 7 datasets, primarily focused on mathematical reasoning and code generation, with less coverage of other reasoning types.
- The pruning mechanism's automatic threshold selection depends on accurate Weibull mixture fitting, but the paper doesn't extensively validate robustness when fitting fails or when the true distribution deviates from the assumed mixture model.

## Confidence

**High Confidence** in the error decomposition framework (Section 2.2) - The mathematical formulation is rigorous and the decomposition into estimation and model error is well-established in statistical theory.

**Medium Confidence** in RPC's empirical performance claims - While the 50% sampling cost reduction is demonstrated, the generalization to other model families and reasoning tasks beyond the tested benchmarks requires further validation.

**Low Confidence** in the Weibull mixture model assumptions - The theoretical justification for why LLM probability distributions should follow this specific structure is not fully established, and alternative distribution assumptions could yield different pruning behaviors.

## Next Checks

1. **Distribution validation study**: Systematically evaluate whether the actual probability distributions of LLM reasoning paths across multiple model families follow the assumed Weibull mixture structure. This would involve fitting the mixture model to real data and testing goodness-of-fit metrics to validate the theoretical foundation of the pruning mechanism.

2. **Robustness to pruning failures**: Design experiments where Weibull fitting is deliberately degraded (limited samples, initialization failures) to test RPC's fallback behavior and assess whether the Truncated Mean safeguard adequately prevents catastrophic performance drops when automatic thresholding fails.

3. **Cross-domain generalization**: Apply RPC to reasoning tasks outside math and code (e.g., commonsense reasoning, multi-hop QA, or social reasoning) to evaluate whether the theoretical advantages in estimation error convergence and model error reduction translate to these qualitatively different reasoning domains.