---
ver: rpa2
title: Inferring Implicit Goals Across Differing Task Models
arxiv_id: '2501.17704'
source_url: https://arxiv.org/abs/2501.17704
tags:
- state
- query
- states
- implicit
- subgoals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the challenge of identifying and achieving\
  \ implicit user subgoals when an agent\u2019s model of the task differs from the\
  \ user\u2019s understanding. The method identifies bottleneck states in the user\u2019\
  s model as candidates for implicit subgoals and introduces a querying strategy to\
  \ minimize the number of queries needed to find a policy that satisfies the user\u2019\
  s underlying goals."
---

# Inferring Implicit Goals Across Differing Task Models

## Quick Facts
- arXiv ID: 2501.17704
- Source URL: https://arxiv.org/abs/2501.17704
- Reference count: 3
- Key outcome: This paper addresses the challenge of identifying and achieving implicit user subgoals when an agent's model of the task differs from the user's understanding. The method identifies bottleneck states in the user's model as candidates for implicit subgoals and introduces a querying strategy to minimize the number of queries needed to find a policy that satisfies the user's underlying goals. The approach uses determinization to identify bottleneck states and formulates the querying process as an MDP. Empirical evaluations on benchmark MDP problems (Maze, Four-Rooms, PuddleWorld, RockWorld) demonstrate that the method effectively infers implicit subgoals and achieves significant reductions in the number of queries compared to querying all bottleneck states. For example, in 4×4 grids, Strategic Query achieved 22-41% query reductions across environments.

## Executive Summary
This paper tackles the problem of identifying implicit subgoals in user tasks when the robot's task model differs from the user's understanding. The method identifies bottleneck states in the user's model as candidates for implicit subgoals and introduces an optimal querying strategy to minimize the number of queries needed to determine which bottlenecks are actual subgoals. The approach uses determinization to identify bottleneck states and formulates the querying process as an MDP, achieving significant query reductions compared to baseline methods across benchmark environments.

## Method Summary
The method addresses the challenge of identifying and achieving implicit user subgoals when an agent's model of the task differs from the user's understanding. It identifies bottleneck states in the user's model as candidates for implicit subgoals using determinization to convert stochastic MDPs into finite sets of deterministic models. The querying process is formulated as an MDP where states represent current knowledge about which bottlenecks are subgoals. The method employs a pruning strategy to eliminate non-achievable subgoals before solving the query MDP, and implements a meta-policy that queries non-achievable bottlenecks first, followed by optimal queries from the pruned MDP. Empirical evaluations on benchmark MDP problems demonstrate significant reductions in query counts compared to querying all bottleneck states.

## Key Results
- Query counts reduced from 3.7-4.8 (Query-All) to 2.0-3.3 queries, achieving reductions of 22-41% in 4×4 grids
- Across 4×4 environments: 22.0% reduction in Four Rooms, 41.0% in Maze, 32.0% in PuddleWorld, 37.9% in RockWorld
- Scalability demonstrated with query reductions up to 71.9% in 8×8 grids despite increased computational cost
- Statistical significance (p < 0.001) achieved for 4×4 Four Rooms, though significance drops at larger grid sizes

## Why This Works (Mechanism)

### Mechanism 1: Bottleneck Preservation Through Determinization
- Claim: Bottleneck states in stochastic MDPs can be identified by analyzing determinized versions without loss of accuracy.
- Mechanism: The method converts stochastic transitions into separate deterministic actions (all-outcome determinization). For each candidate state, it creates a modified MDP that penalizes visiting that state. If the optimal value V*(s₀) > 0, a goal-reaching path exists without that state—meaning it's not a bottleneck. This reduces an infinite set of possible human models to a finite set of determinized models.
- Core assumption: Bottleneck states are preserved across determinization (Proposition 1).
- Evidence anchors:
  - [abstract]: "Our method identifies bottleneck states and uses them as candidates for potential implicit subgoals."
  - [section 4, Proposition 1]: "Given a model M and its determinization δ(M), a state s is a bottleneck state for M if and only if it is a bottleneck state in δ(M)."
  - [corpus]: Weak direct evidence; related work on underspecification exists but doesn't validate this specific mechanism.
- Break condition: When stochastic dynamics create bottlenecks that don't appear in any single determinized outcome (e.g., probabilistic narrow passages).

### Mechanism 2: Augmented State Tracking for Subgoal Achievement
- Claim: Verifying whether a policy achieves multiple subgoals reduces to standard MDP planning with an augmented state space.
- Mechanism: The method constructs M̂_S by expanding the state space to track which subgoals have been visited (|Ŝ_S| = |S| × 2^|Ŝ|). Each state includes binary features indicating prior subgoal visits. Transitions update these features, and rewards only activate when reaching goal states with all subgoal features true. This transforms the problem into finding a policy whose traces satisfy all subgoal constraints.
- Core assumption: The subgoal set is finite and the augmented MDP remains tractable.
- Evidence anchors:
  - [abstract]: "The proposed method identifies bottleneck states across multiple potential user models and employs a query-based approach to determine which bottlenecks are actually implicit subgoals."
  - [section 4, Proposition 4]: "If there exists a policy π that achieves the subgoal set, then there exists a policy π̂, such that all goal reaching trace for π̂ exits at the goal state copies where all the features for subgoals are true."
  - [corpus]: No direct validation; Theory of Mind papers suggest similar augmented representations but in different frameworks.
- Break condition: When the subgoal set grows large enough that |S| × 2^|Ŝ| becomes computationally intractable.

### Mechanism 3: Optimal Query Selection via Meta-MDP
- Claim: Minimizing expected query cost maps to solving a meta-level MDP where states represent current knowledge about subgoals.
- Mechanism: The query MDP M_Q has states (K_I, K_¬I) representing known implicit subgoals and known non-subgoals. Actions query individual bottlenecks; transitions model oracle responses. Absorbing states trigger when current knowledge guarantees achievability (subset of maximal achievable set) or unachievability (known subgoals impossible). The method prunes non-achievable bottlenecks first (Proposition 6), reducing state space exponentially before solving the pruned MDP.
- Core assumption: Equal probability for positive/negative oracle responses; query cost dominates secondary objectives.
- Evidence anchors:
  - [abstract]: "The key innovation is an optimal query strategy that minimizes the number of queries needed... formulated as a meta-MDP problem."
  - [section 4, Definition 4]: "The optimal query at any point would correspond to the one that minimizes the expected value."
  - [section 6, Results]: "Query counts reduced from 3.7-4.8 (Query-All) to 2.0-3.3 queries, achieving reductions of 22-41%."
  - [corpus]: Indirect support from active learning literature, but no direct empirical validation of meta-MDP query optimization.
- Break condition: When bottleneck count exceeds tractability for MDP solvers; when oracle response probabilities are highly skewed (violating equal-likelihood assumption).

## Foundational Learning

- **Concept: Markov Decision Processes (MDPs) and Optimal Policies**
  - Why needed here: The entire framework formalizes tasks as MDPs M = ⟨S, A, T, s₀, γ, SG⟩. Understanding value functions V^π, optimal policies, and goal-reaching traces is prerequisite to grasping bottleneck detection and query optimization.
  - Quick check question: Given an MDP with states {A, B, C}, where C is the goal and only action from A leads to B with probability 0.5 and C with probability 0.5, what is the bottleneck state?

- **Concept: Goal-Reaching Traces and Path Necessity**
  - Why needed here: Bottleneck states are defined via traces—sequences of state-action pairs with non-zero probability reaching the goal. The probability P_G(s|π) of reaching the goal under policy π underpins the formal definition of bottlenecks as states visited in *every* valid trace.
  - Quick check question: If a state appears in 90% of goal-reaching traces for all policies, is it a bottleneck by Definition 1? (Answer: No—it must appear in all traces.)

- **Concept: Discounted Infinite-Horizon Planning**
  - Why needed here: The method uses discounted MDPs (γ ∈ [0,1)) for both task planning and query MDPs. The query MDP sets γ high "so as not to overlook the cost of future queries too much," creating a secondary objective favoring shorter traces.
  - Quick check question: Why does a high discount factor (γ ≈ 1) in the query MDP make the agent consider future query costs more carefully?

## Architecture Onboarding

- **Component map:**
  1. Model Input Layer: Robot model M_R (known), set of potential human models M_H (possibly infinite)
  2. Determinization Module: Converts stochastic M_H to finite set δ(M_H) via all-outcome determinization
  3. Bottleneck Detector: For each δ(M_H), tests each state s_i via modified MDP M_{s_i} with visit penalty; V*(s₀) > 0 ⇒ not bottleneck
  4. Achievability Analyzer: Algorithm 1 generates maximal achievable subsets I using recursive search with pruning; tests achievability via augmented MDP M̂_S
  5. Query MDP Builder: Constructs M_Q with state space 2^B × 2^B, prunes non-achievable states per Proposition 6
  6. Query Executor: Solves pruned MDP, executes policy Π_Q; queries non-achievable states first, then follows optimal strategy
  7. Task Policy Generator: Once subgoals confirmed, generates final policy via M̂_S with verified subgoal set

- **Critical path:**
  1. Determinization (seconds for small grids; ~1.7-1.8s bottleneck finding for 10 human models)
  2. Bottleneck identification across all determinized models (Proposition 3 testing loop)
  3. Maximal subset generation (Algorithm 1; exponential in bottleneck count)
  4. Query MDP construction and solving (meta-level planning)
  5. Query execution until absorbing state reached
  6. Final task policy computation with confirmed subgoals

- **Design tradeoffs:**
  - **Exact vs. approximate**: Paper implements exact methods; future work suggests approximate alternatives for scalability
  - **Query minimization vs. policy quality**: Secondary objective (shorter traces) never overrides query cost minimization (|C^Q| > p_{I_max})
  - **Pre-computation vs. runtime**: Pruning non-achievable states upfront (Proposition 6) shifts cost to preprocessing but reduces meta-MDP size exponentially
  - **Obstacle density tolerance**: 10% obstacles tractable (~4-9s total); 15% causes significant slowdown (13-50s), suggesting threshold effects

- **Failure signatures:**
  - **Scalability cliff**: At 8×8 grids with many human models, pruning times reach ~308-325s; watch for exponential growth in bottleneck count
  - **Statistical significance loss**: 4×4 Four Rooms shows p < 0.001; 6×6 drops to p = 0.411, indicating variance increases with grid size
  - **High obstacle density**: 15% obstacles cause 7-27s bottleneck finding vs. ~1.8s at 10%
  - **Model count sensitivity**: Stable across 5-20 human models at low obstacle density, but no validation beyond this range

- **First 3 experiments:**
  1. **Reproduce 4×4 baseline**: Run Four Rooms with 10 human models, 10% obstacle density, verify ~22-41% query reduction vs. Query-All; confirm p < 0.001 significance
  2. **Stress test obstacle density**: Fix grid size at 6×6, vary obstacle density from 0.05 to 0.20; plot bottleneck finding time and total runtime to identify breaking point
  3. **Validate pruning optimality**: Implement both full M_Q and pruned M̂_Q for identical problem instances; verify Proposition 6 by confirming equal query counts and different solve times

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the proposed method perform with real human users in realistic, everyday scenarios, and are users willing to accept more queries if it meaningfully improves agent behavior?
  - Basis in paper: [explicit] The Discussion section states: "one of the immediate next steps would be to run user studies... in realistic and everyday scenarios, possibly a robotic one, with significant population size" and "one could test whether people would be open to more queries if it significantly improves the agent efficiency."
  - Why unresolved: All evaluations in Section 6 use simulated benchmark environments (Maze, Four-Rooms, PuddleWorld, RockWorld) with synthetic human models rather than actual human participants.
  - What evidence would resolve it: User study results measuring query acceptance rates, cognitive load, and task satisfaction when humans interact with the system in embodied robotic or realistic planning scenarios.

- **Open Question 2**: Can approximate methods maintain solution quality while improving scalability to larger or continuous state spaces?
  - Basis in paper: [explicit] The Discussion section notes: "This paper also focuses on the exact method that identifies optimal solutions. It would be interesting to see if we could leverage approximate methods."
  - Why unresolved: The current approach requires solving multiple MDPs (including a meta-query MDP with state space exponential in bottleneck count), and pruning times increased substantially with grid size (from ~2-3 seconds for 4×4 to ~308-325 seconds for 8×8 grids).
  - What evidence would resolve it: Comparative evaluation showing approximate query strategies achieving near-optimal query counts with bounded suboptimality guarantees and reduced computational overhead.

- **Open Question 3**: How can the set of potential human models MH be acquired in practice without requiring explicit enumeration of transition functions?
  - Basis in paper: [inferred] The paper assumes "We are given a set of potential user models MH corresponding to different transition functions," acknowledging this set could be infinite. While the paper handles this via determinization, obtaining these models from human users in real applications remains unaddressed.
  - Why unresolved: The methodology section provides no mechanism for eliciting or learning the candidate human models from user interaction, observation, or domain knowledge.
  - What evidence would resolve it: A method for generating candidate models from limited user demonstrations, natural language descriptions, or domain priors, validated on human-specified tasks.

- **Open Question 4**: Can pre-trained large language models serve as knowledge sources to improve inference about user implicit subgoals?
  - Basis in paper: [explicit] The Discussion section states: "It would also be interesting to see if we could use other knowledge sources like pre-trained large language models, to get more information about user knowledge and preferences."
  - Why unresolved: The current method relies solely on structural properties (bottleneck states) derived from MDP transition functions, without incorporating semantic or commonsense knowledge about human expectations.
  - What evidence would resolve it: Integration of LLM-based priors for predicting likely implicit subgoals given task descriptions, showing reduced query counts or improved goal alignment.

## Limitations

- Bottleneck preservation through determinization lacks empirical validation beyond controlled environments
- Performance degrades significantly at higher obstacle densities (15% causes 7-27× slowdown vs 10%)
- Equal-probability assumption for oracle responses may not hold in real-world scenarios
- Exponential growth in state space for Algorithm 1 limits practical applicability beyond small bottleneck sets

## Confidence

- **High confidence**: Bottleneck detection mechanism (Proposition 3) and its empirical validation across four environments
- **Medium confidence**: Query MDP optimization effectiveness (Proposition 6) given statistical significance varies by grid size
- **Medium confidence**: Determinization preserving bottlenecks (Proposition 1) based on theoretical proof but limited empirical stress testing
- **Low confidence**: Scalability claims beyond 8×8 grids and 20 human models given computational bottlenecks observed

## Next Checks

1. **Bottleneck preservation stress test**: Systematically vary stochasticity in transition functions across determinization; measure false positive/negative rates in bottleneck detection compared to ground truth in highly stochastic environments

2. **Obstacle density threshold validation**: Fix 8×8 grid, sweep obstacle density from 0.05 to 0.20; plot bottleneck finding time, total runtime, and query reduction to identify precise breaking points

3. **Oracle response bias robustness**: Implement query MDP with skewed response probabilities (e.g., 70% positive vs 30% negative); compare optimal query policies and expected query counts to equal-probability baseline