---
ver: rpa2
title: An unscented Kalman filter method for real time input-parameter-state estimation
arxiv_id: '2511.02717'
source_url: https://arxiv.org/abs/2511.02717
tags:
- input
- system
- estimation
- identi
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an unscented Kalman filter for real-time
  estimation of unknown inputs, parameters, and states in structural systems. The
  method uses two-stage input estimation within each time step, first predicting the
  input from dynamic states and parameters, then refining it using updated measurements.
---

# An unscented Kalman filter method for real time input-parameter-state estimation

## Quick Facts
- arXiv ID: 2511.02717
- Source URL: https://arxiv.org/abs/2511.02717
- Authors: Marios Impraimakis; Andrew W. Smyth
- Reference count: 24
- Key outcome: This paper introduces an unscented Kalman filter for real-time estimation of unknown inputs, parameters, and states in structural systems.

## Executive Summary
This paper presents an unscented Kalman filter (UKF) method for real-time joint estimation of unknown input forces, structural parameters, and dynamic states in structural systems. The method employs a two-stage input estimation process within each time step, first predicting the input from dynamic states and parameters, then refining it using updated measurements. A key contribution is the theoretical demonstration that systems with at least one known input (zero or non-zero) can be uniquely identified, unlike classical output-only parameter identification methods. The approach is validated on both linear and nonlinear systems, showing satisfactory convergence of input, state, and parameter estimates.

## Method Summary
The method extends the standard UKF by augmenting the state vector with system parameters, allowing joint estimation of displacements, velocities, parameters, and unknown inputs. A two-stage input estimation process is implemented: first estimating the input using predicted states and parameters via the equation of motion, then refining the estimate after the Kalman correction step updates states and parameters with measurements. Sigma points are generated from the augmented state to capture the posterior distribution through the unscented transform. The method requires at least one known input (zero or non-zero) at a degree of freedom for system identifiability, as proven through perturbation analysis. Covariance matrices Q (process noise) and R (measurement noise) must be properly calibrated for convergence.

## Key Results
- The two-stage input estimation approach successfully tracks both linear and nonlinear system inputs in real-time
- Systems with at least one known input DOF can be uniquely identified, while completely unknown input systems cannot
- Displacement, velocity, and acceleration measurements provide the most reliable estimation results
- Proper calibration of Q and R covariance matrices is critical for convergence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage input estimation within each time step improves accuracy by refining the input estimate after measurement correction.
- Mechanism: First, the unknown input is estimated using predicted (a priori) states and parameters via the equation of motion: ue_k ≈ G(ẍm_k, ẋp_k, xp_k, ...). After the Kalman correction step updates states and parameters with measurements, the input is re-estimated: ue_k ≈ G(ẍm_k, ẋk, xk, ...). Known input rows are overwritten with actual values at both stages.
- Core assumption: The equation of motion G(•) correctly relates accelerations, velocities, displacements, parameters, and input; measurement noise and input-derived noise can be combined into augmented measurement noise.
- Evidence anchors:
  - [abstract] "The unknown input is estimated in two stages within each time step. Firstly, the predicted dynamic states and the system parameters provide an estimation of the input. Secondly, the corrected with measurements states and parameters provide a final estimation."
  - [section 3, Table 1B] Pseudo-code explicitly shows two separate G(•) calls—one before and one after the measurement update step.
  - [corpus] No direct corpus comparison to single-stage approaches; related papers focus on adaptive covariance tuning rather than input estimation architecture.
- Break condition: If the structural model G(•) is misspecified or parameters diverge significantly, both input estimates become unreliable.

### Mechanism 2
- Claim: At least one known input (zero or non-zero) is required for unique system identifiability in time-domain estimation.
- Mechanism: Perturbation analysis shows that for systems with entirely unknown inputs, multiple erroneous parameter-input combinations can satisfy the equation of motion identically (creating "equivalent inputs"). A known input at one DOF breaks this degeneracy because the equivalent input at that DOF would contradict the known value, forcing correct parameter identification.
- Core assumption: The system is MDOF with at least one DOF having a known (measured or specified) input value; single-DOF systems with unknown input are not identifiable in the time domain.
- Evidence anchors:
  - [abstract] "it is demonstrated using the perturbation analysis that, a system with at least a zero or a non-zero known input can potentially be uniquely identified"
  - [section 4] Detailed mathematical derivation showing ∆cẋ(t) + ∆kx(t) = ∆u(t) equivalence for SDOF (non-identifiable) and how known zero input at DOF 1 resolves identifiability for 2-DOF systems.
  - [corpus] No corpus papers directly address this identifiability analysis.
- Break condition: If all inputs are truly unknown with no known values at any DOF, the system has infinite solutions and cannot be uniquely identified.

### Mechanism 3
- Claim: Augmenting the state vector with parameters enables joint estimation without requiring Jacobian derivatives or least-squares sub-procedures.
- Mechanism: The state vector z(t) = [x(t), ẋ(t), θθθ]^T includes both dynamic states and parameters. Sigma points are generated from this augmented state, propagated through the nonlinear process model F(•), and the unscented transform approximates the posterior distribution. Parameters evolve as random walk states driven by process noise.
- Core assumption: Process and measurement noise are approximately Gaussian; parameters vary slowly relative to dynamic states; sigma point spread (α, κ, λ) captures the relevant nonlinearity.
- Evidence anchors:
  - [section 2] "The state vector z(t) = [x(t), ẋ(t), θθθ]T includes the parameters of the system θθθ apart from the dynamic states"
  - [Table 1A/B] Complete pseudo-code showing sigma point generation, propagation, and correction steps for augmented state.
  - [corpus] "Adaptive Neural Unscented Kalman Filter" and "DeepUKF-VIN" corroborate UKF effectiveness for nonlinear estimation with adaptive covariance mechanisms.
- Break condition: Highly non-Gaussian noise, extreme nonlinearities, or incorrect covariance calibration (Q, R) causes filter divergence or convergence to wrong values.

## Foundational Learning

- Concept: **State-space representation with augmented parameters**
  - Why needed here: The method treats parameters as additional states in the state vector, requiring understanding of how to formulate process equations where parameters have no physical dynamics but are updated through the filter.
  - Quick check question: If parameters θ have no governing differential equation, how do they evolve in the process model, and what role does process noise play?

- Concept: **Unscented transform and sigma point weights**
  - Why needed here: The UKF approximates probability distributions through deterministic sampling (sigma points) rather than linearization.
  - Quick check question: For an L-dimensional augmented state vector, how many sigma points are generated, and which weight (V^m_0 vs. V^c_0) is used for mean vs. covariance calculation?

- Concept: **Covariance matrix tuning (Q and R)**
  - Why needed here: The paper explicitly states that proper calibration of Q and R is critical for convergence; incorrect values cause divergence or slow convergence.
  - Quick check question: If the process noise covariance Q is set too small relative to true process uncertainty, what behavior will the filter exhibit?

## Architecture Onboarding

- Component map:
  1. State augmenter: Constructs z = [x, ẋ, θ]^T combining displacements, velocities, and parameters
  2. Sigma point generator: Creates 2L+1 sigma points using (z, P, λ) with scaling parameter λ = α²(L+κ) - L
  3. Process propagator F(•): Integrates dynamics using previous input estimate
  4. First input estimator G(•): Computes ue_k from predicted states via equation of motion
  5. Known input replacer: Overwrites specified rows of ue_k with known zero/non-zero values
  6. Measurement predictor h(•): Maps sigma points to expected measurements
  7. Kalman corrector: Computes gain K = Ps·Pm⁻¹ and updates z, P
  8. Second input estimator G(•): Refines ue_k using corrected states
  9. Covariance updater: Applies Joseph form P = Pp - K·Pm·K^T

- Critical path:
  Initialize (z₀, P₀, ue₀) → [Loop: Generate sigma points → Predict via F(•) using ue_{k-1} → First input estimation → Replace known inputs → Predict measurements → Correct with measurements → Second input estimation → Replace known inputs → Update covariance] → Repeat

- Design tradeoffs:
  - Full vs. partial state measurement: Displacement+velocity+acceleration recommended; acceleration-only is unreliable (drift, non-unique convergence); at least two dynamic states per DOF may work with data fusion
  - Covariance magnitude: Q ~ 10⁻⁹, R ~ 10⁻³ to 10⁻⁵ used in examples; larger values slow convergence, smaller values risk divergence
  - Sigma point parameters: α ∈ [10⁻⁴, 1] controls spread; β incorporates prior distribution knowledge

- Failure signatures:
  - Continuous error growth in input/state estimates: Acceleration-only measurement configuration (Fig. 7)
  - Convergence to different values on repeated runs: Insufficient measurement information or identifiability issues
  - Parameter divergence: Q too small or R too large for the actual noise levels
  - Nonlinear parameter non-convergence: Insufficient excitation of nonlinear response modes

- First 3 experiments:
  1. Linear 3-DOF with known zero inputs at DOFs 1-2: Implement IPS-UKF on the exact system from Section 5.1 with full state measurements at 100 Hz. Target: all 6 parameters (c₁, c₂, c₃, k₁, k₂, k₃) converge within 10-15 seconds of the 100N pulse event.
  2. Measurement configuration sweep: Run the linear system with three configurations: (a) full states, (b) velocity+acceleration only, (c) acceleration only. Document convergence time, final parameter error, and input estimation RMSE for each.
  3. Covariance grid search: For the nonlinear 2-DOF Duffing system, systematically test Q ∈ {10⁻⁷, 10⁻⁹, 10⁻¹¹} and R ∈ {10⁻³, 10⁻⁵, 10⁻⁷}. Identify which combinations produce stable convergence within 30 seconds vs. divergence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a physically meaningful, systematic procedure be developed for calibrating the process and measurement covariance matrices to ensure convergence?
- Basis in paper: [explicit] The authors state that "proper calibration is outside the scope of this work" while noting that "proper calibration of covariance matrices is critical for convergence."
- Why unresolved: The paper relies on ad-hoc, constant values for the covariance matrices (Q and R) to achieve convergence, lacking a theoretical or automated adjustment mechanism.
- What evidence would resolve it: An adaptive algorithm or theoretical framework that relates physical system uncertainties to the required matrix parameters, validated across different noise levels.

### Open Question 2
- Question: Is it possible to uniquely identify system parameters and inputs when zero known input information (zero or non-zero) is available at any degree of freedom?
- Basis in paper: [explicit] The authors use perturbation analysis to show identifiability requires "at least a zero or a non-zero known input," noting that without this, an "equivalent 'input'" can satisfy the equation of motion for erroneous parameters.
- Why unresolved: The mathematical proof of uniqueness relies on the existence of the known input to eliminate the "erroneous parts" of the estimation; the paper does not present a solution for the completely unknown input case.
- What evidence would resolve it: A modification of the IPS-UKF method or a new theoretical proof demonstrating unique identifiability in the complete absence of input measurements.

### Open Question 3
- Question: How can the methodology be stabilized to handle acceleration-only measurements, which currently result in misleading and diverging estimates?
- Basis in paper: [inferred] The sensitivity analysis reveals that for the acceleration-only case, "convergence to different values or even divergence happens," and the error trend is continuously higher.
- Why unresolved: The authors note that "loss of the drift information will endanger the identification procedure," and the proposed data fusion suggestion was not implemented or verified for this specific failure case.
- What evidence would resolve it: Successful numerical validation where estimates converge to true values using only acceleration data, potentially through integration with a specific data fusion technique.

## Limitations

- The method requires at least one known input DOF for system identifiability, limiting applicability in completely unknown input scenarios
- Proper calibration of covariance matrices Q and R is critical but lacks a systematic procedure
- Acceleration-only measurements can lead to unreliable estimates with growing error or non-unique convergence

## Confidence

- **High Confidence**: The two-stage input estimation mechanism (Mechanism 1) is clearly described with explicit pseudo-code and validated on both linear and nonlinear systems.
- **Medium Confidence**: The identifiability analysis (Mechanism 2) is mathematically sound but only demonstrated for simple SDOF and 2-DOF systems; extension to complex MDOF structures requires further validation.
- **Medium Confidence**: The augmented state UKF approach (Mechanism 3) is standard methodology, but specific covariance calibration values and sigma point parameters are not fully specified for all test cases.

## Next Checks

1. Cross-validation on multi-DOF systems: Test the IPS-UKF on a 5-DOF linear system with mixed known/unknown inputs to verify the identifiability claims extend beyond 2-DOF cases.
2. Noise sensitivity analysis: Systematically vary the measurement noise-to-signal ratio from 1% to 20% to quantify the filter's robustness and identify the practical limits of the 5% noise assumption.
3. Input-only identification test: Implement the filter on a system with all inputs unknown (no known values at any DOF) to experimentally confirm the theoretical prediction of non-identifiability.