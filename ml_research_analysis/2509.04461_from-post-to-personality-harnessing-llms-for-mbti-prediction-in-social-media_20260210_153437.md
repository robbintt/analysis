---
ver: rpa2
title: 'From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media'
arxiv_id: '2509.04461'
source_url: https://arxiv.org/abs/2509.04461
tags:
- mbti
- personality
- social
- posts
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes PostToPersonality (P2P), a novel LLM-based
  framework for predicting Myers-Briggs Type Indicator (MBTI) personality types from
  social media posts. P2P addresses two key challenges in MBTI prediction: LLM hallucination
  and class imbalance in training data.'
---

# From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media

## Quick Facts
- arXiv ID: 2509.04461
- Source URL: https://arxiv.org/abs/2509.04461
- Reference count: 40
- This paper proposes PostToPersonality (P2P), a novel LLM-based framework for predicting Myers-Briggs Type Indicator (MBTI) personality types from social media posts.

## Executive Summary
This paper introduces PostToPersonality (P2P), a dual-LLM framework that predicts MBTI personality types from social media posts by combining feature extraction with retrieval-augmented generation. The system addresses two key challenges in MBTI prediction: LLM hallucination and class imbalance in training data. P2P uses a fine-tuned local LLM to generate psychological assessments from posts, then leverages a vector database to retrieve semantically similar examples that guide an online LLM's final prediction through in-context learning. The framework also applies synthetic minority oversampling (SMOTE) to handle the imbalanced MBTI dataset, where certain personality types like ESFJ and ESTJ are underrepresented.

## Method Summary
The P2P framework uses a dual-LLM architecture combining a fine-tuned local LLM (DeepSeek-R1-8B) for feature extraction with a Retrieval-Augmented Generation (RAG) mechanism and online LLM prediction (DeepSeek-V3). The local LLM is fine-tuned using synthetic minority oversampling to handle imbalanced MBTI data, generating textual psychological assessments from user posts. A vector database containing Sentence-BERT embeddings of training posts and local LLM features enables RAG retrieval of top-k similar examples. The online LLM uses these retrieved demonstrations as in-context learning examples to predict the final MBTI type. The system is trained on the PersonalityCafe dataset (8,675 users, 50 posts per user) with class imbalance addressed through SMOTE applied to hidden states of the local LLM.

## Key Results
- P2P outperforms 10 ML/DL baselines by an average of 8.2% in accuracy
- P2P achieves 20.17% improvement in F1-score compared to baselines
- P2P shows 4.1% improvement in AUC over competing approaches
- Case studies demonstrate P2P's ability to capture personality characteristics from social media posts

## Why This Works (Mechanism)

### Mechanism 1: Retrieval-Grounded In-Context Learning (RAG)
Grounding the online LLM's prediction in semantically similar "post-personality" demonstrations reduces hallucination and improves prediction stability. Instead of predicting MBTI from raw text alone, the system queries a vector database (FAISS) for the top-k historically similar posts. These examples serve as "demonstrations" in the prompt, allowing the online LLM to leverage in-context learning to map linguistic patterns to personality types based on precedents rather than parametric memory alone. The core assumption is that semantic similarity of posts correlates with shared personality traits, and the LLM can effectively generalize from these few-shot examples.

### Mechanism 2: Latent Space Interpolation for Minority Classes (SMOTE)
Applying Synthetic Minority Over-sampling Technique (SMOTE) to the local LLM's hidden states helps the model generalize to underrepresented MBTI types (e.g., ESFJ, ESTJ). Rather than duplicating rare samples, the framework synthesizes new embeddings by linearly interpolating between a minority sample and its neighbors in the latent space. This forces the decision boundary to be less aggressive toward minority classes during fine-tuning. The core assumption is that linear interpolation in the hidden state space of an LLM yields semantically valid and useful "synthetic" personality features.

### Mechanism 3: Dual-LLM Specialization (Extraction vs. Reasoning)
Decoupling the task into "feature extraction" (local model) and "final reasoning" (online model) allows for domain-specific adaptation without the cost of full fine-tuning for reasoning. The local LLM (DeepSeek-R1-8B) is fine-tuned strictly to generate textual assessments describing the user's psychology. The online LLM (DeepSeek-V3) consumes these structured features + original text + retrieved examples to perform the final classification. This isolates the "understanding" of psychology from the "logic" of MBTI classification. The core assumption is that the online LLM possesses sufficiently general reasoning capabilities to synthesize disparate inputs without task-specific fine-tuning.

## Foundational Learning

- **Concept: In-Context Learning (ICL) with RAG**
  - Why needed here: The system relies on the online LLM's ability to "learn" from the retrieved examples in the prompt without weight updates. Understanding ICL is critical to debugging why specific retrieved examples change the output.
  - Quick check question: If you remove the retrieved examples ($k=0$), do you expect the model's accuracy to drop because of "forgetting" personality facts, or because it loses the specific pattern-matching context?

- **Concept: Class Imbalance & Long-Tail Distributions**
  - Why needed here: The paper notes that INFP is the most frequent type, while ESFJ/ESTJ are rare. Without SMOTE, a standard classifier would maximize accuracy by simply predicting the majority class (INFP) for everyone.
  - Quick check question: Why is accuracy a poor standalone metric for this dataset? (Hint: If 50% of users are INFP, a dummy classifier achieves 50% accuracy.)

- **Concept: Parameter-Efficient Fine-Tuning (PEFT) / QA-LoRA**
  - Why needed here: The local LLM is a massive model (8B parameters). You need to understand why we use LoRA (Low-Rank Adaptation) to fine-tune it efficiently on limited GPU memory rather than full fine-tuning.
  - Quick check question: What happens to the "knowledge" of the local LLM if you over-fit the LoRA adapters on the small MBTI dataset? (Hint: Catastrophic forgetting of general language features.)

## Architecture Onboarding

- **Component map:** Input (User posts) -> Local Encoder (DeepSeek-R1-8B fine-tuned with QA-LoRA + SMOTE) -> Vector DB (FAISS index) -> RAG Retriever (Sentence-BERT embeddings) -> Prompt Constructor (Assembles original text + features + retrieved demos) -> Online Reasoner (DeepSeek-V3 API) -> Output (4-letter MBTI code)

- **Critical path:** The dependency chain is strictly serial: Local Inference → RAG Lookup → Online Inference. Latency is dominated by the two LLM calls. If the Local Encoder fails or outputs garbage, the RAG lookup retrieves wrong neighbors, and the Online Reasoner receives poisoned context, leading to a cascade failure.

- **Design tradeoffs:**
  - Dual-LLM vs. Single-LLM: Higher cost/latency for potentially higher accuracy (specialization)
  - SMOTE in Latent Space vs. Data Augmentation: SMOTE is computationally cheaper than generating synthetic text with an LLM, but assumes the latent space is smooth
  - RAG vs. Long-Context: RAG limits context window usage to relevant $k$ shots, but risks missing signals if the retrieval metric fails to capture personality similarity

- **Failure signatures:**
  - Stereotyping: The Case Study shows the model predicting INFP because of "Art" keywords, missing the INTJ ground truth, indicating reliance on surface-level semantic associations
  - Low-Confidence Retrieval: If the RAG system returns examples with low similarity scores, the prompt may confuse the online LLM
  - API Inconsistency: The online model (DS-V3) is a black box; updates to the API could change reasoning behavior, breaking the pipeline without code changes

- **First 3 experiments:**
  1. Zero-Context Baseline: Run the pipeline with $k=0$ (RAG disabled) and Local LLM features disabled. Compare against the full P2P to isolate the contribution of the retrieval/augmentation.
  2. Minority Class Stress Test: Filter the test set for the 4 least common MBTI types. Measure F1-score with SMOTE enabled vs. disabled to prove the imbalance handling is functional.
  3. Feature Ablation: Run the online LLM with *only* the original posts (no generated features) vs. *only* generated features (no posts). This determines if the Local LLM is actually extracting useful signal or just acting as a distractor.

## Open Questions the Paper Calls Out
None

## Limitations
- The SMOTE implementation on LLM hidden states remains underspecified, with unclear integration into the QA-LoRA fine-tuning pipeline
- The dual-LLM architecture's performance gains over single-model alternatives are not conclusively demonstrated through ablation studies
- Reliance on a proprietary online LLM (DeepSeek-V3) as a black box introduces API dependency risks and prevents complete replication

## Confidence

- **High Confidence:** The experimental methodology (dataset preparation, baseline selection, evaluation metrics) is clearly specified and reproducible. The claim that P2P outperforms baselines by stated margins is well-supported by the reported results.
- **Medium Confidence:** The theoretical mechanism of using RAG with in-context learning to reduce hallucination is plausible and supported by the results, though the exact conditions under which retrieval examples improve prediction versus introducing noise are not fully characterized.
- **Low Confidence:** The specific implementation details for SMOTE on LLM hidden states and the integration of synthetic samples into the QA-LoRA training loop are insufficient for exact reproduction.

## Next Checks

1. **Zero-Context Control Test:** Run the complete P2P pipeline with k=0 (RAG disabled) and Local LLM features disabled. This isolates whether the reported performance gains come from the retrieval mechanism or the online LLM's inherent capabilities.

2. **Minority Class Stress Test:** Filter the test set to include only the 4 least common MBTI types (ESFJ, ESTJ, ENFJ, ENTJ). Measure F1-scores with and without SMOTE to verify the class imbalance handling is functional rather than theoretical.

3. **Latent Space Validation:** Extract and visualize the local LLM's hidden states before and after SMOTE augmentation. Verify that synthetic samples fall within semantically meaningful regions of the embedding space rather than introducing noise that degrades performance.