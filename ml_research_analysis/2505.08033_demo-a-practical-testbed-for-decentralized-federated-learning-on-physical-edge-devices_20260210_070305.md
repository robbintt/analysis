---
ver: rpa2
title: 'Demo: A Practical Testbed for Decentralized Federated Learning on Physical
  Edge Devices'
arxiv_id: '2505.08033'
source_url: https://arxiv.org/abs/2505.08033
tags:
- training
- testbed
- devices
- learning
- physical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of evaluating decentralized federated
  learning (DFL) on resource-constrained edge devices by building a physical testbed
  using heterogeneous hardware like Raspberry Pi and Jetson Nano. The testbed extends
  the NEBULA DFL platform with real-time power monitoring via JT-TC66C USB multimeters,
  enabling energy-aware experimentation.
---

# Demo: A Practical Testbed for Decentralized Federated Learning on Physical Edge Devices

## Quick Facts
- arXiv ID: 2505.08033
- Source URL: https://arxiv.org/abs/2505.08033
- Reference count: 7
- Primary result: Physical DFL testbed shows denser topologies yield higher F1-scores (~82%) while consuming more energy; hardware constraints slow training but maintain comparable final accuracy to virtualized setups.

## Executive Summary
This paper presents a physical testbed for decentralized federated learning (DFL) using heterogeneous edge devices (Raspberry Pi 4 and Jetson Nano) to evaluate model performance, energy efficiency, and communication overhead under real hardware constraints. The testbed extends the NEBULA DFL platform with real-time power monitoring via USB multimeters, enabling energy-aware experimentation. Experiments with MNIST and FashionMNIST datasets across multiple communication topologies demonstrate that fully connected networks yield the best model F1-scores (81-82%), while sparser topologies perform worse but use less bandwidth and energy. The physical deployments achieve performance comparable to virtualized baselines, validating the testbed's realism for DFL research under hardware constraints.

## Method Summary
The testbed uses 4 heterogeneous edge devices (3x Raspberry Pi 4 with mixed memory, 1x Jetson Nano) interconnected via Ethernet, running the NEBULA DFL platform modified with HTTP-based configuration and metric reporting. Nodes train an MLP using FedAvg over 10 rounds with 1 local epoch per round on IID-partitioned MNIST and FashionMNIST datasets. Five communication topologies (fully connected, star, ring, random, and virtualized baseline) are tested, with power consumption measured via JT-TC66C USB multimeters. The controller coordinates configuration distribution and metric collection, while nodes establish TCP connections for peer-to-peer model exchange according to the specified topology.

## Key Results
- Denser communication topologies improve model convergence: fully connected topology achieved F1-scores of 81-82% versus lower, more variable scores for sparser topologies.
- Physical hardware constraints slow training but maintain comparable final accuracy to virtualized baselines.
- Power consumption ranges from 3-3.5W per device with total energy use of 1250-1400J per run, varying by topology density.
- CPU utilization remains moderate at 25-29% across devices during training.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Denser communication topologies improve model convergence in DFL under the tested conditions.
- Mechanism: Fully connected topologies enable each node to aggregate model updates from all peers per round, reducing the variance of gradient estimates and accelerating consensus toward a performant shared model.
- Core assumption: The observed F1-score improvements stem primarily from connectivity density rather than confounding factors such as dataset simplicity or model architecture.
- Evidence anchors:
  - [abstract] "model performance is influenced by the communication topology, with denser topologies leading to better outcomes in DFL settings"
  - [section] "the fully connected topology consistently achieved the highest average F1-scores (81–82%) on both MNIST and Fashion-MNIST datasets. In contrast, sparser topologies like ring and random exhibited more variability and generally lower average performance"
  - [corpus] Related work on topology optimization for DFL (arXiv:2508.08278) supports the broader claim that topology structure affects convergence, though formal convergence proofs are not provided in this demo paper.
- Break condition: If non-IID data distributions are introduced or peer count scales significantly, denser topologies may incur communication bottlenecks that degrade practical performance despite theoretical convergence advantages.

### Mechanism 2
- Claim: Physical hardware constraints produce detectable differences in training time and energy profiles compared to virtualized environments, while maintaining comparable final model quality.
- Mechanism: Resource-constrained devices (limited CPU cycles, memory bandwidth, and no GPU on Raspberry Pi) slow per-round computation, but the FedAvg aggregation rule operates independently of hardware speed; thus model convergence trajectories remain similar given sufficient rounds.
- Core assumption: The FedAvg hyperparameters (10 rounds, 1 local epoch) were sufficient for convergence on these simple datasets; more complex tasks may expose divergence between physical and virtualized outcomes.
- Evidence anchors:
  - [section] "The virtualized scenario matched physical F1-scores but completed training significantly faster, highlighting the computational limits of edge devices"
  - [section] "Power consumption followed similar patterns, ranging from 3 to 3.5 watts, and total energy use varied between 1251 and 1404 joules"
  - [corpus] Corpus papers on heterogeneity-aware DFL (arXiv:2508.08278) acknowledge device heterogeneity impacts but do not contradict the finding that final accuracy can match virtualized baselines under controlled conditions.
- Break condition: If local training epochs increase or model size grows substantially, memory pressure on 2GB RAM devices may cause out-of-memory failures or significant slowdowns not observed in this demo.

### Mechanism 3
- Claim: Removing the central server and relying on peer-to-peer model exchange eliminates a single point of failure while introducing topology-dependent communication overhead.
- Mechanism: Each node maintains TCP connections to its topological neighbors and transmits model updates directly; aggregation is performed locally using received peer models without central coordination.
- Core assumption: The local Ethernet network provides reliable, low-latency connectivity; wireless or intermittent links would likely change overhead and convergence characteristics.
- Evidence anchors:
  - [abstract] "DFL eliminates reliance on a central server, mitigating the single point of failure inherent in the traditional FL paradigm"
  - [section] "Nodes then establish TCP connections with their neighbors and begin decentralized training"
  - [section] "Bandwidth usage aligned with topological structure: fully connected and star topologies generated higher traffic per node, while ring and random topologies maintained lower and more localized communication overhead"
  - [corpus] Corpus evidence on DFL deployments (arXiv:2503.11828) discusses scalability benefits of decentralization but does not provide comparative failure-rate data.
- Break condition: If a node fails or disconnects mid-training, the current implementation lacks explicit fault-tolerance mechanisms; ring topologies would be particularly vulnerable to disconnection.

## Foundational Learning

- Concept: **Federated Averaging (FedAvg)**
  - Why needed here: The testbed uses FedAvg as the core aggregation algorithm; understanding how local gradients are combined is essential for interpreting why topology density affects convergence.
  - Quick check question: Can you explain why FedAvg's weighted averaging of local models enables convergence without sharing raw data?

- Concept: **Graph Topology Properties (degree, connectivity)**
  - Why needed here: The experiments vary topology as the independent variable; grasping how degree distribution and path length affect information diffusion is critical for analyzing results.
  - Quick check question: In a 4-node ring topology, how many hops does it take for a model update from one node to influence all others?

- Concept: **Edge Device Resource Constraints**
  - Why needed here: The testbed's value proposition is realistic resource measurement; knowing typical CPU, memory, and power envelopes for devices like Raspberry Pi helps contextualize the reported metrics.
  - Quick check question: Why might a 2GB RAM Raspberry Pi show higher memory utilization percentages than a 4GB model running the same workload?

## Architecture Onboarding

- Component map:
  Controller -> Nodes (3x RPi4, 1x Jetson Nano) -> NEBULA DFL Platform -> Power Monitoring (JT-TC66C multimeters) -> Frontend

- Critical path:
  1. Frontend sends configuration → Controller
  2. Controller creates bootstrap and distributes config to each node via HTTP
  3. Each node's HTTP server receives config, then terminates to free the port
  4. Nodes establish TCP connections with topology-defined neighbors
  5. Training loop: local training → model sharing with neighbors → aggregation → repeat
  6. Nodes periodically send metrics to Controller; power meters log consumption
  7. At scenario end, energy summaries transmitted and displayed

- Design tradeoffs:
  - HTTP for configuration vs. TCP for training: HTTP simplifies bootstrapping but is not used for high-frequency model exchange; TCP reduces overhead during training.
  - Dual power reporting (real-time + batch): Enables live monitoring without disrupting training, but adds minor complexity to node-side logging.
  - Heterogeneous device mix: Realistic for edge scenarios but introduces variable per-round latency; Jetson Nano's GPU is underutilized with the simple MLP used.

- Failure signatures:
  - Node fails to receive configuration: Check HTTP server status and port availability on target device.
  - Training stalls mid-round: Verify TCP connectivity between neighbors; check for network partition especially in ring/random topologies.
  - Energy data missing: Confirm JT-TC66C multimeter USB connection and driver recognition.
  - Memory errors on 2GB Raspberry Pi: Reduce batch size or model dimensions; monitor RAM usage via controller metrics.

- First 3 experiments:
  1. **Baseline replication**: Run fully connected topology on MNIST with default FedAvg settings (10 rounds, 1 local epoch); verify F1-score approximately 82% and compare power draw across device types.
  2. **Topology ablation**: Repeat with ring topology on same dataset; observe F1-score drop and reduced network traffic per node; confirm correlation between connectivity density and convergence.
  3. **Dataset complexity test**: Run FashionMNIST on fully connected topology; note whether F1-score remains similar (~81%) and whether power/energy profiles change due to increased gradient computation complexity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does testbed performance and energy consumption scale with larger federations (e.g., 20+ devices) and more complex topologies?
- Basis in paper: [explicit] "Future extensions include scaling to larger federations, exploring more advanced topologies"
- Why unresolved: Current experiments were limited to 4 devices and four basic topologies (fully connected, star, ring, random).
- What evidence would resolve it: Experiments with 20+ heterogeneous devices measuring convergence time, F1-scores, and energy consumption across varying topological complexities.

### Open Question 2
- Question: How does non-IID data distribution affect model convergence and energy efficiency in this physical DFL testbed?
- Basis in paper: [inferred] "all datasets were partitioned independently and identically distributed (IID)" — non-IID scenarios, common in real-world deployments, were not tested.
- Why unresolved: Only IID data partitions were evaluated, leaving performance under realistic data heterogeneity unknown.
- What evidence would resolve it: Comparative experiments using Dirichlet-distributed or pathological non-IID partitions with metrics on convergence rounds and energy overhead.

### Open Question 3
- Question: How does DFL performance degrade under realistic wireless network conditions with variable latency, packet loss, and intermittent connectivity?
- Basis in paper: [inferred] Devices were "interconnected via a local Ethernet network" — controlled conditions that do not reflect wireless edge deployment challenges.
- Why unresolved: Local Ethernet provides stable connectivity; real-world edge scenarios face unreliable wireless links.
- What evidence would resolve it: Experiments over WiFi or cellular connections with injected latency, jitter, and packet loss measuring model accuracy degradation and retransmission energy costs.

### Open Question 4
- Question: Can alternative aggregation algorithms beyond FedAvg improve energy efficiency or reduce convergence time on resource-constrained devices?
- Basis in paper: [inferred] "the FedAvg algorithm was trained over 10 federation rounds" — only one aggregation method was evaluated.
- Why unresolved: FedAvg may not be optimal for decentralized, heterogeneous, energy-constrained settings.
- What evidence would resolve it: Comparative study of algorithms (e.g., FedProx, Scaffold, decentralized Gossip averaging) measuring rounds-to-convergence and joules-per-percentage-accuracy-gained.

## Limitations

- Small-scale experiments with only 4 devices limit scalability insights for larger federations.
- Simple datasets (MNIST/FashionMNIST) and shallow MLP models may not generalize to complex real-world tasks.
- No explicit fault-tolerance mechanisms for node failures, particularly critical in ring and random topologies.
- Power monitoring is limited to single-device readings rather than per-round energy accounting for individual aggregation steps.

## Confidence

- **High confidence**: Denser communication topologies improve model F1-scores in DFL under the tested conditions (fully connected → ~82% vs. sparser → lower, more variable).
- **Medium confidence**: Physical deployments achieve comparable final model quality to virtualized baselines despite slower training due to hardware constraints; energy consumption is measurable and topology-dependent.
- **Low confidence**: The testbed's results will directly translate to larger, more heterogeneous deployments or more complex ML models without significant modification.

## Next Checks

1. Replicate the fully connected MNIST experiment and verify F1-score ~82% and power draw ~3.3W on comparable hardware.
2. Introduce a node failure during training in ring topology to test fault tolerance and observe convergence behavior.
3. Scale to 8-12 nodes with heterogeneous compute capabilities to assess whether energy and bandwidth scaling patterns observed at 4 nodes hold.