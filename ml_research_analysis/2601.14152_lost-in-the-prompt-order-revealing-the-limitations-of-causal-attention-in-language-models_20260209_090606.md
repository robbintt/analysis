---
ver: rpa2
title: 'Lost in the Prompt Order: Revealing the Limitations of Causal Attention in
  Language Models'
arxiv_id: '2601.14152'
source_url: https://arxiv.org/abs/2601.14152
tags:
- context
- qwen2
- option
- average
- llama-3
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates why large language models (LLMs) show
  a significant performance gap (over 14%) between two prompt structures in multiple-choice
  question answering: placing context before questions and options (CQO) versus the
  reverse order (QOC). Through systematic experiments, the authors rule out training
  bias and memory failure as causes and identify causal attention as the core mechanism:
  in QOC, the causal mask prevents option tokens from attending to the context, creating
  an information bottleneck where context becomes invisible to options.'
---

# Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models

## Quick Facts
- arXiv ID: 2601.14152
- Source URL: https://arxiv.org/abs/2601.14152
- Authors: Hyunjong Ok; Jaeho Lee
- Reference count: 33
- Primary result: Decoder-only LLMs show 14.72% accuracy gap between context-before-questions (CQO) and questions-before-context (QOC) prompt orderings in MCQA tasks

## Executive Summary
This paper identifies a fundamental limitation in causal attention mechanisms that creates significant performance gaps in large language models based on prompt ordering. Through systematic experiments across 21 models and four benchmarks, the authors demonstrate that decoder-only architectures show a 14.72% accuracy drop when options appear before context (QOC) compared to the reverse order (CQO). The core finding reveals that causal masking prevents option tokens from attending to context in QOC prompts, creating an information bottleneck where context becomes invisible to options during forward pass computation. The authors validate this mechanism through architecture comparisons, attention analysis, and targeted interventions that partially restore QOC performance.

## Method Summary
The study evaluates four multiple-choice question answering benchmarks (LogiQA, SciQ, RACE-M, RACE-H) using likelihood-based scoring on decoder-only models (LLaMA, Qwen, Gemma) and encoder variants (BERT, RoBERTa, ALBERT, Flan-T5). Two prompt formats are compared: CQO (Context → Question → Options) and QOC (Question → Options → Context). Accuracy is computed by extracting logits for option tokens, applying softmax, and predicting the argmax. Additional analyses include gradient×input attribution for context utilization quantification, activation patching to test information flow, and attention pruning to validate causal pathways.

## Key Results
- Decoder-only models show 14.72% accuracy gap between CQO and QOC orderings
- Encoder-only models show near-zero gap (0.02%), confirming bidirectional attention eliminates ordering sensitivity
- Context attribution ratio is 2.4× higher in CQO (0.797) vs QOC (0.335)
- QOC performance matches no-context baseline (QOC: 54.5%, QO: 52.8%)
- Option repetition intervention improves QOC accuracy by 8.2%
- Activation patching middle-to-late layers increases QOC accuracy by 6.0%

## Why This Works (Mechanism)

### Mechanism 1: Causal Attention Masking Creates Information Bottleneck
- Claim: In QOC prompts, the causal attention mask prevents option tokens from attending to context, creating an information bottleneck.
- Mechanism: Decoder-only transformers use a causal mask where each token can only attend to preceding tokens. When options appear before context (QOC ordering), option representations are computed without any context information. Later tokens cannot retroactively update earlier hidden states—they can only read them.
- Core assumption: Accurate answer selection requires option representations to integrate contextual evidence during forward pass.
- Evidence anchors:
  - [abstract]: "in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options"
  - [section 3.3, Figure 5a]: "decoder-only models show a 14.72% gap, encoder-decoder models (Flan-T5) show 2.30%, and encoder-only models (BERT, RoBERTa, ALBERT) show a near-zero gap (0.02%)"
  - [corpus]: Weak direct support—related papers discuss order sensitivity generally but don't validate this specific causal masking mechanism for MCQA.
- Break condition: If causal masking is removed (bidirectional attention), the gap should disappear; if context is removed from QOC, performance should not change.

### Mechanism 2: Context-Conditioned Option Representations Are Causally Sufficient
- Claim: Providing context-aware option representations can partially restore QOC performance.
- Mechanism: Activation patching replaces QOC option hidden states with CQO representations (computed with context access). When patched at middle-to-late layers, this provides the model with context-conditioned option information it otherwise lacks.
- Core assumption: Middle-to-late layers are where context-option integration primarily occurs.
- Evidence anchors:
  - [section 4]: "This increases QOC accuracy by 6.0 points on average, with larger gains for models exhibiting larger baseline gaps"
  - [section 4]: "We patch only option tokens (not context or question) to isolate the mechanism"
  - [corpus]: No direct corpus validation for this specific intervention.
- Break condition: Patching early layers should show minimal improvement; patching context or question tokens should not help.

### Mechanism 3: Option-to-Context Attention Pathway Is Causally Necessary
- Claim: The attention pathway from options to context is essential for accurate MCQA performance.
- Mechanism: Artificially blocking option-to-context attention in CQO (attention pruning) simulates the QOC constraint, causing performance to drop dramatically, confirming this pathway's necessity.
- Core assumption: The direct attention pathway is the primary route for context integration (not indirect routes through question tokens).
- Evidence anchors:
  - [section 4]: "CQO accuracy drops from 69.26% to 42.46% (−26.8), with consistent decreases across model families (Qwen: 28.1%, LLaMA: 25.3%, Gemma: 26.9%)"
  - [table 10]: Detailed per-model degradation confirms the pattern across architectures.
  - [corpus]: "Masking Matters" paper supports importance of attention mask design for spatial reasoning tasks.
- Break condition: Pruning other attention pathways (e.g., option-to-question) should not cause equivalent degradation.

## Foundational Learning

- Concept: Causal vs. Bidirectional Attention
  - Why needed here: This architectural difference explains the entire CQO-QOC gap phenomenon.
  - Quick check question: In a decoder-only transformer with 10 tokens, can token 5 attend to token 7?

- Concept: Hidden State Computation and Information Flow
  - Why needed here: Understanding when and how representations are computed explains why patching middle-to-late layers works.
  - Quick check question: For a 24-layer model, which layer range does the paper target for activation patching?

- Concept: Gradient×Input Attribution
  - Why needed here: The paper uses this method to quantify how much context tokens contribute to predictions under different orderings.
  - Quick check question: What does a context attribution ratio of 0.797 (CQO) vs. 0.335 (QOC) indicate about context utilization?

## Architecture Onboarding

- Component map:
  - Decoder-only (LLaMA, Qwen, Gemma): Causal mask → options cannot see future context → 14.72% gap
  - Encoder-decoder (Flan-T5): Bidirectional encoder → full context visibility → 2.30% gap
  - Encoder-only (BERT, RoBERTa, ALBERT): Fully bidirectional → no ordering constraint → 0.02% gap

- Critical path:
  Prompt ordering → Token positions → Causal mask application → Hidden state computation → Context-option integration → Final prediction
  (In QOC, step 4 completes before context is seen, breaking step 5)

- Design tradeoffs:
  - Causal attention: Enables autoregressive generation but creates prompt-order sensitivity
  - Bidirectional attention: Eliminates ordering sensitivity but incompatible with standard text generation
  - Encoder-decoder: Compromise—bidirectional understanding with causal decoding

- Failure signatures:
  - CQO-QOC accuracy gap >14% in MCQA tasks
  - Context attribution ratio ~2.4× higher in CQO vs QOC
  - QOC performance matches "no context" baseline (QOC: 54.5%, QO: 52.8%)
  - High option recall in both orderings (~94%), ruling out memory failure
  - Gap increases with longer contexts (LogiQA: 6.2% → RACE-H: 20.8%)

- First 3 experiments:
  1. Measure CQO vs QOC gap on your task—if >10%, causal attention is likely the bottleneck
  2. Run context ablation: compare QOC against QO (no context)—if similar, context is not being utilized
  3. Try option repetition (QOCO pattern): append options after context—if +5-8% improvement, confirms attention pathway is recoverable

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the CQO-QOC performance gap scale invariantly to models larger than 9B parameters, or does it diminish/increase with scale?
- Basis in paper: [explicit] The authors note in the Limitations section that "we evaluate models up to 9B parameters due to computational constraints" and that the consistent gap across 21 models "suggests that this behavior is intrinsic to the causal decoder design rather than a scale-dependent artifact," but this hypothesis remains untested at larger scales.
- Why unresolved: Computational constraints limited experiments to models ≤9B parameters; the claim about scale-independence is inferred rather than empirically validated.
- What evidence would resolve it: Systematic evaluation of the CQO-QOC gap across larger decoder-only models (e.g., 30B, 70B, 100B+ parameters) from the same model families.

### Open Question 2
- Question: Does the causal attention bottleneck affect other task formats beyond four-option MCQA, such as free-form QA, multi-document reasoning, or generation tasks with post-hoc context?
- Basis in paper: [explicit] The authors state "our evaluations are primarily focused on MCQA tasks with four-option formats" and "we believe our findings regarding the information bottleneck are likely applicable to broader QA formats where context placement varies," but this generalization is not empirically tested.
- Why unresolved: The experimental scope was deliberately narrowed to MCQA; no results are provided for other task types where context-option ordering could matter.
- What evidence would resolve it: Experiments testing prompt order effects on tasks like open-ended reading comprehension, summarization with context appended, or multi-hop reasoning where evidence must be integrated across ordered blocks.

### Open Question 3
- Question: Can architectural modifications to decoder-only models (e.g., bidirectional attention over prompt prefixes, hybrid attention patterns) fully eliminate the CQO-QOC gap without sacrificing generation capabilities?
- Basis in paper: [inferred] The interventions tested (activation patching: +6.0%, option repetition: +8.2%) only partially close the gap. The paper identifies causal attention as the root cause but does not propose or test architectural solutions that fundamentally alter the attention mechanism.
- Why unresolved: The paper demonstrates the mechanism and partial mitigations, but does not explore whether decoder architectures can be modified to support bidirectional context integration during prompt encoding.
- What evidence would resolve it: Evaluation of decoder variants with modified attention patterns (e.g., prefix bidirectional attention, sliding window with lookahead) on both the CQO-QOC gap and standard language modeling benchmarks.

### Open Question 4
- Question: Why does the correct answer's position modulate the gap severity, with option D showing the smallest drop (9.9%) compared to earlier positions (19–22%)?
- Basis in paper: [explicit] Table 1b reports that "earlier answer positions suffer greater accuracy drops than later ones in QOC, as later options are near the context." However, this proximity explanation is stated but not mechanistically validated.
- Why unresolved: The paper offers a qualitative explanation (token proximity) but does not provide attention analysis or intervention results specifically targeting the position effect.
- What evidence would resolve it: Layer-wise attention analysis comparing how early vs. late option tokens differentially leverage the final answer token's access to context, combined with controlled experiments varying option-count and spacing.

## Limitations

- Training data contamination: Possibility that QOC-style prompts exist in pretraining corpora, though authors rule out training bias
- Attribution method limitations: Gradient×input attribution has known limitations and implementation sensitivities
- Intervention specificity: Exact implementation details for activation patching are underspecified (middle-to-late layer range)

## Confidence

**High Confidence (90-95%)**:
- The existence of a 14%+ accuracy gap between CQO and QOC orderings in decoder-only models
- The causal attention mask as the primary mechanism preventing option-context integration in QOC
- The near-zero gap in encoder-only models (0.02%) confirming bidirectional attention eliminates the ordering sensitivity

**Medium Confidence (60-75%)**:
- The claim that causal masking creates an "information bottleneck" rather than just a representational difference
- The effectiveness of middle-to-late layer activation patching as evidence for context-option integration timing
- The attribution ratios (0.797 vs 0.335) as definitive proof of differential context utilization

**Low Confidence (30-50%)**:
- The generalizability of findings to non-MCQA tasks or different prompt structures
- The absence of training bias effects despite not analyzing pretraining data distributions
- The specificity of the 12-23 layer range for patching interventions

## Next Checks

1. **Pretraining Data Analysis**: Conduct an analysis of the pretraining corpora to quantify the prevalence of QOC-style prompt structures. This would involve searching for question-option-context patterns in the training data and correlating their frequency with the observed accuracy gaps across different models.

2. **Cross-Task Replication**: Test the CQO-QOC ordering sensitivity on non-MCQA tasks that require similar context-option integration, such as open-ended QA where options are generated rather than selected, or multi-step reasoning tasks where intermediate conclusions serve as "options." This would validate whether causal attention masking is a general limitation or specific to MCQA.

3. **Alternative Attribution Validation**: Replicate the context attribution analysis using multiple attribution methods (e.g., Integrated Gradients, SHAP, Layer-wise Relevance Propagation) to verify that the 2.4× higher context utilization in CQO is robust across methods and not an artifact of the gradient×input approach.