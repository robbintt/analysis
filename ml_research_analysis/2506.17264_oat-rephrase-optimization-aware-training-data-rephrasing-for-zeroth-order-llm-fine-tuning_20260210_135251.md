---
ver: rpa2
title: 'OAT-Rephrase: Optimization-Aware Training Data Rephrasing for Zeroth-Order
  LLM Fine-Tuning'
arxiv_id: '2506.17264'
source_url: https://arxiv.org/abs/2506.17264
tags:
- data
- template
- prompt
- original
- oat-rephrase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OAT-Rephrase, a novel optimization-aware
  training data rephrasing strategy for zeroth-order LLM fine-tuning. The method uses
  an LLM to rewrite training instances by analyzing the MeZO paper, then validates
  rephrasings with a semantic judge to ensure logical consistency.
---

# OAT-Rephrase: Optimization-Aware Training Data Rephrasing for Zeroth-Order LLM Fine-Tuning

## Quick Facts
- **arXiv ID**: 2506.17264
- **Source URL**: https://arxiv.org/abs/2506.17264
- **Reference count**: 35
- **Key result**: OAT-Rephrase improves zeroth-order LLM fine-tuning accuracy by 1.86 points on average, with gains up to 5.3 points.

## Executive Summary
OAT-Rephrase introduces a novel optimization-aware training data rephrasing strategy to improve zeroth-order (ZO) LLM fine-tuning. The method uses an LLM to rewrite training instances by analyzing the MeZO paper, then validates rephrasings with a semantic judge to ensure logical consistency. Evaluated across five classification tasks and three LLM architectures, OAT-Rephrase consistently improves MeZO fine-tuning performance—often matching or surpassing first-order methods. Rewriter accuracy remains above 96% across datasets. The approach demonstrates that targeted data rephrasing can significantly enhance zeroth-order optimization efficiency and generalization across models.

## Method Summary
OAT-Rephrase employs a dual-stage pipeline where an LLM rewriter, informed by the MeZO paper, rephrases training instances to reduce loss landscape variance for ZO optimization. A separate LLM judge validates semantic and logical consistency between original and rephrased pairs, with a rejection gate ensuring only semantically preserved examples enter the synthetic corpus. The rephrased dataset is then used to fine-tune LLMs using the MeZO optimizer, with results showing consistent accuracy improvements across multiple model architectures.

## Key Results
- OAT-Rephrase improves MeZO fine-tuning accuracy by 1.86 points on average across five tasks
- Gains up to 5.3 points observed on individual tasks, with 96%+ rewriter accuracy
- Performance matches or exceeds first-order methods in many cases
- Generalizes across Llama-3.2-1B, Llama-3.2-3B, and Mistral-7B-v0.1 architectures

## Why This Works (Mechanism)

### Mechanism 1: Reduction of Loss Landscape Variance for ZO Optimization
The paper hypothesizes that rephrasing training data using an LLM informed by MeZO optimization dynamics leads to smoother loss surfaces. ZO methods estimate gradients using finite-difference approaches, which are highly sensitive to noise. Ambiguous phrasing can cause fluctuating loss values across random perturbations, leading to unstable gradient estimates. OAT-Rephrase aims to reduce unnecessary variance in the loss landscape, providing cleaner directional signals for the ZO optimizer.

### Mechanism 2: Rejection Gate for Semantic Preservation
The dual-stage pipeline with an LLM-based judge is necessary to prevent rephrasing from changing fundamental semantics of the task. Without this gate, the rewriter could inadvertently alter core meaning or logical structure, corrupting the training signal. The judge explicitly verifies semantic equivalence and logical consistency, filtering out examples where rephrasing introduces task drift or label corruption.

### Mechanism 3: Cross-Model Generalization of Optimized Data Representations
A dataset rephrased once to be more amenable to ZO optimization provides consistent performance gains across multiple different LLM architectures. This suggests the rephrasing encodes task semantics in a broadly "ZO-friendly" way, creating a representation that generalizes and makes the optimization landscape less treacherous regardless of specific parameter initialization.

## Foundational Learning

- **Concept: Zeroth-Order (ZO) Optimization**
  - Why needed here: This is the core alternative training paradigm the paper is built around. Understanding how it estimates gradients using only forward passes is essential to appreciate why reducing variance in the loss landscape is critical.
  - Quick check question: How does a ZO optimizer like MeZO estimate the gradient for a given parameter update step without using backpropagation?

- **Concept: Gradient Estimate Variance**
  - Why needed here: The paper's central thesis is that rephrasing data reduces the variance of the loss function, which directly helps ZO methods. Understanding that high variance leads to slow/unstable convergence is key to understanding the problem OAT-Rephrase solves.
  - Quick check question: In stochastic optimization, what is the expected effect of high variance in the gradient estimate on the convergence path of the model?

- **Concept: Semantic Preservation in Data Augmentation**
  - Why needed here: A major component of the proposed architecture is the "semantic judge." Understanding the trade-off between data modification and preserving core meaning is essential to grasp why this is a non-trivial problem requiring a gated pipeline.
  - Quick check question: When an LLM rewrites a training example, what are two key semantic properties that must be preserved to ensure the task remains the same?

## Architecture Onboarding

- **Component map**: GPT-4o Rewriter -> GPT-4o Judge -> Rejection Gate -> Synthetic Corpus -> MeZO Optimizer -> Target LLM

- **Critical path**:
  1. Develop and refine the Rewriter Prompt Template (5-phase process) to ensure it understands ZO dynamics
  2. Develop and refine the Judge Prompt Template (iterative process) until it achieves ~90% accuracy against human labels
  3. Run the Rewriter over the entire training set
  4. Run the Judge on every original-rephrased pair
  5. The Rejection Gate constructs the final Synthetic Corpus
  6. Use this corpus to fine-tune the target LLM with the MeZO optimizer

- **Design tradeoffs**:
  - Gated vs. Ungated Pipeline: The paper argues the Judge/Rejection Gate is necessary to prevent semantic drift. Removing it would be simpler and cheaper but risks corrupting the dataset.
  - Rewriter Model Choice: The paper uses GPT-4o for rewriting. Using a smaller, cheaper model might reduce costs but could fail to produce high-quality, optimization-aware rephrasings.
  - One-time vs. Per-Model Rephrasing: The paper demonstrates that a single rephrased corpus generalizes across models. The tradeoff is the upfront computational cost versus the flexibility of per-model optimization.

- **Failure signatures**:
  - Low Rewriter Accuracy: The Judge rejects most rewrites, leaving the synthetic corpus mostly unchanged
  - Semantic Drift: Downstream performance changes, but human review shows rephrased examples have lost the original meaning or have a different correct answer
  - Zero Gain: OAT-Rephrased data shows no improvement over the original data, suggesting the rephrasing did not meaningfully alter the loss landscape for ZO

- **First 3 experiments**:
  1. Ablation on the Rejection Gate: Train MeZO on the synthetic corpus with and without the Judge/Rejection Gate. Compare performance to quantify the contribution of semantic preservation.
  2. Hyperparameter Sensitivity: Does the OAT-Rephrase benefit hold across different ZO perturbation magnitudes (δ) and learning rates, or is it only effective for a specific hyperparameter configuration?
  3. Cross-Optimizer Validation: The paper shows mixed results for first-order (FO) methods. Conduct a focused experiment comparing MeZO, AdamW (Full), and AdamW (LoRA) on both Original and OAT-Rephrase data for a single model to precisely measure the gap-closing effect.

## Open Questions the Paper Calls Out

- **Question**: Does OAT-Rephrase improve zeroth-order fine-tuning for generative tasks (e.g., summarization, translation) or only classification?
  - Basis in paper: The authors state they "benchmark OAT-Rephrase on five English classification tasks" (Section 4.1) and the method relies on "binary and multi-class classification tasks" (Section 3.1, Phase 3)
  - Why unresolved: The prompt engineering and judge validation are designed around discrete class labels and logical consistency, which may not directly transfer to the continuous output spaces or distinct evaluation metrics of generation tasks
  - What evidence would resolve it: Experiments applying OAT-Rephrase to standard generative benchmarks (e.g., XSUM, WMT) using MeZO, reporting metrics like ROUGE or BLEU

- **Question**: Does optimization-aware rephrasing quantitatively smooth the loss landscape and reduce gradient variance?
  - Basis in paper: The paper hypothesizes that rephrasing yields "smoother and more optimizable loss surfaces" (Section 2.2), but validates the method solely through final test accuracy (Section 4)
  - Why unresolved: While accuracy gains are shown, the theoretical mechanism—that the rephrased text specifically reduces the high variance of ZO gradient estimates—is claimed but not empirically visualized or measured
  - What evidence would resolve it: Analysis comparing the gradient variance and loss landscape sharpness between models trained on Original vs. OAT-Rephrase data

- **Question**: Can the manual, multi-phase prompt engineering process be automated or replaced by smaller open-source models?
  - Basis in paper: The rewriter relies on GPT-4o (Section 3.1) and the prompt template design involves a manual 5-phase process including "manually inspect" and "manually design" steps (Section 3.1, Phases 3 & 3.2)
  - Why unresolved: The reliance on a proprietary SOTA model (GPT-4o) and human-in-the-loop prompt refinement raises cost and scalability concerns, potentially limiting accessibility for resource-constrained users
  - What evidence would resolve it: An ablation study showing if smaller open-weight rewriters or automated prompt optimization techniques can achieve comparable rewriter accuracy without manual phases

## Limitations
- Evaluation focuses primarily on MeZO fine-tuning; generalization to other zeroth-order optimizers remains unclear
- Semantic preservation relies on LLM-based judgment rather than human evaluation at scale
- Results demonstrated on three model sizes (1B-7B parameters) may not generalize to larger or multimodal models

## Confidence
- **High Confidence**: The core claim that OAT-Rephrase improves MeZO fine-tuning performance (1.86 average accuracy gain) is well-supported by consistent results across five tasks and three models
- **Medium Confidence**: The mechanism explaining gains (reduced loss landscape variance) is theoretically sound but lacks direct empirical validation through variance analysis
- **Medium Confidence**: The semantic preservation claim relies on automated LLM judgment rather than human verification at scale

## Next Checks
1. **Variance Analysis**: Quantify and compare the variance of loss landscape estimates between original and OAT-Rephrase data to directly test the proposed mechanism
2. **Human Evaluation**: Conduct systematic human review of a sample of rephrased examples to verify semantic preservation and detect potential task drift
3. **Cross-Optimizer Validation**: Test OAT-Rephrase with alternative zeroth-order optimizers (e.g., AGZO, KerZOO) to assess generalizability beyond MeZO