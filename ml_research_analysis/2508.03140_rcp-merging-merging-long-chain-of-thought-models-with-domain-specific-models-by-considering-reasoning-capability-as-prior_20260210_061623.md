---
ver: rpa2
title: 'RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models
  by Considering Reasoning Capability as Prior'
arxiv_id: '2508.03140'
source_url: https://arxiv.org/abs/2508.03140
tags:
- reasoning
- merging
- task
- rcp-merging
- eosinoplus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RCP-Merging addresses the challenge of merging domain-specific
  models with long chain-of-thought reasoning models without degrading reasoning capability.
  The method introduces a reasoning preservation indicator that treats reasoning model
  weights as a prior, using Fisher Information Matrix gradients to constrain updates
  and preserve long CoT capability.
---

# RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior

## Quick Facts
- **arXiv ID**: 2508.03140
- **Source URL**: https://arxiv.org/abs/2508.03140
- **Reference count**: 22
- **Key outcome**: RCP-Merging improves domain task performance by 9.5% in BioMedicine and 9.2% in Finance over state-of-the-art methods while maintaining long CoT reasoning capability and reducing gibberish rate to 14.3%.

## Executive Summary
RCP-Merging addresses the challenge of merging domain-specific models with long chain-of-thought reasoning models without degrading reasoning capability. The method introduces a reasoning preservation indicator that treats reasoning model weights as a prior, using Fisher Information Matrix gradients to constrain updates and preserve long CoT capability. It combines this with domain knowledge sensitivity to identify crucial domain-specific parameters. Extensive experiments on Qwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models show RCP-Merging achieves superior domain performance while maintaining reasoning ability and producing stable outputs.

## Method Summary
RCP-Merging treats reasoning model weights as a Bayesian prior to preserve long chain-of-thought capabilities during domain-specific model merging. The method computes a Reasoning Preservation Indicator using Fisher Information Matrix gradients to quantify parameter importance for reasoning tasks, contrasting this with Domain Knowledge Sensitivity to identify weights safe for domain updates. A majority-vote masking mechanism filters domain-specific weight updates to prevent output collapse and gibberish generation. The approach optimizes the Maximum A Posteriori estimate, incorporating reasoning regularization into the merging objective to maintain both domain performance and reasoning capabilities.

## Key Results
- Improves domain task performance by 9.5% in BioMedicine and 9.2% in Finance over state-of-the-art methods
- Maintains long CoT reasoning capability while achieving superior domain performance
- Produces stable outputs with only 14.3% average gibberish rate compared to 82.3-99.7% for baseline methods

## Why This Works (Mechanism)

### Mechanism 1: Reasoning Capability as a Bayesian Prior
The method prevents degradation of long CoT capabilities by treating the reasoning model's weights as a stable Bayesian prior rather than just another task vector to be averaged. The framework optimizes for the Maximum A Posteriori (MAP) estimate, minimizing a loss function that includes a regularization term derived from the reasoning model. This term penalizes deviations from the reasoning model's weights proportional to their importance (sensitivity). The reasoning model's parameters $\theta_r$ represent a valid prior distribution for the merged model, and the local curvature of the loss landscape (approximated by Fisher Information) accurately reflects parameter importance for reasoning tasks.

### Mechanism 2: Disentangling Domain Gradients from Reasoning Sensitivity
Standard gradient-based merging fails because domain-specific gradients do not capture the multi-step deduction requirements of long CoT. RCP-Merging calculates a Reasoning Preservation Indicator ($p$) using the FIM on reasoning calibration data, quantifying how much a specific weight change harms reasoning capability. It contrasts this with Domain Knowledge Sensitivity ($S$), which measures domain importance. By optimizing $C = S + \lambda \cdot p$, the system identifies weights that are "safe" to update for domain knowledge because they have low reasoning sensitivity.

### Mechanism 3: Majority-Vote Masking for Stability
Applying a binary mask based on a majority vote across calibration samples prevents output collapse (gibberish) better than soft-weighting or magnitude pruning. The method computes the constraint metric $C$ for every data sample in the calibration set. A weight update is accepted only if the majority of samples agree that the update is beneficial (negative conflict score). This creates a binary mask $M$ that filters the domain task vector before merging.

## Foundational Learning

- **Concept: Fisher Information Matrix (FIM)**
  - Why needed here: FIM is the mathematical engine of the "Reasoning Preservation Indicator." You cannot understand *why* the model keeps its reasoning ability without understanding that FIM approximates the "importance" of a weight by measuring how much the loss function curves (changes) when that weight is perturbed.
  - Quick check question: If the FIM value for a specific weight is extremely high, does the RCP-Merging algorithm encourage or discourage changing that weight? (Answer: Discourage, as it incurs a high penalty in the optimization objective).

- **Concept: Task Arithmetic / Task Vectors**
  - Why needed here: This is the baseline operation ($\theta_{merged} = \theta_{pre} + \delta$). RCP-Merging is a modification of this strategy; it does not train a new model from scratch but adds "vectors of knowledge" to a base model.
  - Quick check question: In standard Task Arithmetic, how is the task vector $\delta$ calculated? (Answer: $\delta = \theta_{fine-tuned} - \theta_{pretrained}$).

- **Concept: Catastrophic Forgetting & Interference**
  - Why needed here: The paper frames the problem specifically as avoiding "gibberish output" and "reasoning capability degradation"—classic symptoms of catastrophic forgetting where new knowledge (domain) overwrites old skills (reasoning).
  - Quick check question: Why does RCP-Merging use a separate "Reasoning Calibration Dataset" instead of just using the domain dataset to calculate gradients? (Answer: Because domain gradients track domain loss, not reasoning preservation; using only domain data would miss the "forgetting" of reasoning skills).

## Architecture Onboarding

- **Component map**: Base Model ($\theta_{pre}$) <- Domain Model ($\theta_t$) + Reasoning Model ($\theta_r$) -> Merged Model ($\theta_{merged}$)
- **Critical path**: $\theta_t \rightarrow \delta_t \rightarrow S^t \rightarrow C \rightarrow M \rightarrow \theta_{merged}$
- **Design tradeoffs**: Uses diagonal FIM approximation for computational feasibility vs. potential loss of parameter correlation information; employs majority vote for stability vs. possible exclusion of valuable domain knowledge
- **Failure signatures**: High gibberish rate (>50%) indicates insufficient reasoning preservation; domain performance doesn't improve suggests mask is too restrictive
- **First experiments**:
  1. Load Qwen2.5-7B base, Meditron3-Qwen2.5-7B domain, and DeepSeek-R1-Distill-Qwen-7B reasoning models; prepare 100-500 calibration samples each for domain and reasoning tasks
  2. Compute gradients on calibration data for both models; calculate Domain Sensitivity and Reasoning Preservation Indicator per parameter using diagonal Fisher approximation
  3. Set λ_r = 0.3; generate binary mask via majority vote across calibration samples; apply mask to filter domain task vector and merge with full reasoning task vector

## Open Questions the Paper Calls Out
- No open questions explicitly called out in the paper.

## Limitations
- Performance heavily depends on quality and representativeness of calibration datasets, with unspecified sample sizes and selection criteria
- Uses diagonal Fisher Information Matrix approximation, potentially missing important parameter correlations critical for complex reasoning tasks
- Manual hyperparameter tuning required for λ_r, limiting scalability across different model sizes and architectures

## Confidence
- **High Confidence**: The core mechanism of using Fisher Information to identify reasoning-critical parameters is mathematically sound and supported by experimental results showing reduced gibberish rates
- **Medium Confidence**: The reported domain performance improvements are substantial but may be sensitive to specific model combinations and calibration datasets used
- **Low Confidence**: Long-term stability of merged models beyond reported evaluation period is not assessed, leaving uncertainty about reasoning capability degradation over time

## Next Checks
1. **Calibration Dataset Ablation**: Test RCP-Merging performance across varying calibration dataset sizes (10, 50, 100, 500 samples) and compositions to establish sensitivity and minimum requirements
2. **Fisher Matrix Approximation Comparison**: Implement full Fisher Information Matrix computation (not diagonal approximation) on a subset of experiments to quantify impact of diagonal assumption on reasoning preservation
3. **Cross-Domain Transferability**: Apply RCP-Merging to merge reasoning model with domain models from entirely different domains (e.g., legal, mathematical) to test whether reasoning preservation mechanism generalizes beyond tested BioMedicine and Finance domains