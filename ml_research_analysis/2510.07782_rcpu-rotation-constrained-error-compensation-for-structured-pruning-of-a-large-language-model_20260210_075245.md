---
ver: rpa2
title: 'RCPU: Rotation-Constrained Error Compensation for Structured Pruning of a
  Large Language Model'
arxiv_id: '2510.07782'
source_url: https://arxiv.org/abs/2510.07782
tags:
- pruning
- compensation
- language
- output
- rcpu
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes RCPU, a rotation-constrained error compensation
  method for structured pruning of large language models (LLMs). The method addresses
  the challenge of reducing model size while maintaining performance, particularly
  under limited calibration data.
---

# RCPU: Rotation-Constrained Error Compensation for Structured Pruning of a Large Language Model

## Quick Facts
- arXiv ID: 2510.07782
- Source URL: https://arxiv.org/abs/2510.07782
- Reference count: 3
- Key outcome: RCPU consistently outperforms existing structured pruning baselines on LLaMA-7B across various pruning ratios, achieving better perplexity and task accuracy with minimal computational overhead.

## Executive Summary
This paper proposes RCPU, a rotation-constrained error compensation method for structured pruning of large language models (LLMs). The method addresses the challenge of reducing model size while maintaining performance, particularly under limited calibration data. RCPU applies a rotation matrix to realign the pruned subspace with original outputs, preserving geometric properties like norms and inner products. The method combines this with a variance-aware importance score that prioritizes retaining columns contributing to principal output directions. Experiments on LLaMA-7B demonstrate that RCPU consistently outperforms existing baselines (WANDA-sp and FLAP) across various pruning ratios, achieving better perplexity and task accuracy on language understanding benchmarks. The approach adds minimal computational overhead and requires no additional architectural changes, making it practically applicable for large-scale deployments.

## Method Summary
RCPU performs structured column pruning on LLaMA-7B by first computing variance-aware importance scores for each column in projection matrices. The scores combine weight norms, input activation norms, and input variance across calibration tokens. Top-k columns are retained while others are pruned. Error compensation is then applied via rotation-constrained alignment: the method solves an Orthogonal Procrustes problem to find the optimal rotation matrix that realigns pruned outputs with original outputs, computed via SVD. This compensation is applied to both attention output projection (o_proj) and MLP down-projection (down_proj) layers. The method requires only 128 calibration samples and no fine-tuning, making it efficient for large-scale deployment.

## Key Results
- RCPU achieves lower perplexity than WANDA-sp and FLAP baselines at 10%, 20%, and 30% pruning ratios on LLaMA-7B
- Zero-shot task accuracy on 7 language understanding benchmarks (BoolQ, PIQA, HellaSwag, WinoGrande, ARC-easy, ARC-challenge, OpenBookQA) consistently improves with RCPU compensation
- Compensation at o_proj layers provides greater benefit than down_proj layers due to earlier error correction in the forward pass
- Rotation-only compensation performs nearly as well as rotation-plus-scaling, with minimal benefit from adding scaling factors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Constraining the post-pruning update to an orthogonal rotation preserves output geometry while realigning the retained subspace to original outputs, reducing overfitting under limited calibration data.
- Mechanism: The method formulates error compensation as an Orthogonal Procrustes problem: min_{Q^T Q=I} ||Y - QZ||_F^2, where Y is the original output and Z is the pruned output. The closed-form solution Q* = UV^T is obtained via SVD of M = YZ^T = UΣV^T. This reduces degrees of freedom from d²_out to O(d_out), improving statistical stability compared to unconstrained least-squares.
- Core assumption: The retained subspace after pruning still carries most of the useful signal; errors are primarily rotational misalignments rather than irrecoverable information loss.
- Evidence anchors:
  - [abstract] "This constrained update preserves the geometry of output representations (i.e., norms and inner products) and simultaneously re-aligns the pruned subspace with the original outputs."
  - [Section 3.1] "By restricting the update to rotation... this avoids the arbitrary scaling and shear distortions that an unconstrained least-squares fit may introduce under limited calibration."
  - [corpus] Weak direct corpus evidence for rotation-constrained compensation specifically; related work (Olica, SliceGPT) uses orthogonal decompositions but for different objectives.
- Break condition: If pruned columns contribute irreversibly to output variance that cannot be recovered by rotating the retained subspace, rotation compensation alone will fail to restore performance.

### Mechanism 2
- Claim: A variance-aware importance score preferentially retains input dimensions that contribute strongly to principal output directions, enhancing the effectiveness of subsequent rotation-constrained compensation.
- Mechanism: The score γ_j = ||W[:,j]|| · ||X[j,:]|| · Var(X[j,:]) extends WANDA-sp by adding an input variance term. High-variance dimensions are hypothesized to align with dominant output directions. The score is computed per-column, and top-k columns are retained.
- Core assumption: Input dimensions with larger variance across calibration tokens contribute more to principal output directions and are harder to recover if pruned.
- Evidence anchors:
  - [abstract] "Since input dimensions with large variance strongly affect these principal directions, we design a variance-aware importance score that ensures such dimensions are preferentially kept."
  - [Section 3.2] "The variance term emphasizes columns whose activations fluctuate across calibration tokens, which are more likely to align with dominant output directions."
  - [Figure 2b] Shows variance-aware scoring outperforms WANDA-sp scoring across pruning ratios when combined with rotation compensation.
  - [corpus] Sample-aware Adaptive Structured Pruning and related methods also emphasize calibration sample variability for importance scoring, though formulations differ.
- Break condition: If calibration data is unrepresentative of the true input distribution, variance estimates may be misleading, causing retention of unimportant columns or pruning of critical ones.

### Mechanism 3
- Claim: Applying rotation compensation to both attention output projection (o_proj) and MLP down-projection (down_proj) yields complementary error reduction, with o_proj compensation providing greater gains due to its upstream position.
- Mechanism: Compensation is applied greedily and layerwise. Updating o_proj corrects misalignment before it propagates into MLP inputs. Updating down_proj corrects errors within the MLP. Both together yield largest improvement.
- Core assumption: Errors at o_proj and down_proj are complementary and partially independent; early correction reduces cumulative error propagation.
- Evidence anchors:
  - [Section 4.4.1] "Updating o_proj is consistently more effective than updating down_proj... Correcting the orientation earlier at o_proj provides the MLP with already aligned features."
  - [Table 3] Shows PPL at 30% pruning: no compensation (21.94), o_proj only (18.91), down_proj only (20.22), both (18.35).
  - [corpus] No direct corpus evidence on layer-specific compensation effectiveness.
- Break condition: If errors compound nonlinearly across layers, greedy layerwise compensation may not capture cross-layer interactions; joint optimization could be required.

## Foundational Learning

- Concept: Orthogonal Procrustes Problem
  - Why needed here: Core mathematical formulation for rotation-constrained alignment between pruned and original outputs.
  - Quick check question: Given two matrices A and B, can you derive the optimal rotation Q that minimizes ||A - QB||_F via SVD?

- Concept: Structured Pruning vs. Unstructured Pruning
  - Why needed here: Distinguishes column/row removal (reduces parameter count, memory) from sparsification (requires sparse kernels for speedup).
  - Quick check question: Why does structured pruning directly reduce memory footprint while unstructured pruning does not?

- Concept: Calibration Data and Overfitting in Post-Training Compression
  - Why needed here: Motivates the rotation constraint; unconstrained least-squares overfits when calibration samples N << parameters.
  - Quick check question: What happens to the condition number of Z Z^T when N is small relative to d_out?

## Architecture Onboarding

- Component map:
  Calibration Data → Input Activations (X), Original Outputs (Y)
         ↓
  Variance-Aware Scoring (γ_j) → Column Selection (keep K, drop D)
         ↓
  Form Pruned Output Z = W_K X_K
         ↓
  Orthogonal Procrustes: M = Y Z^T → SVD → Q* = UV^T
         ↓
  Update Weights: W_K ← Q* W_K (or s* Q* W_K with scaling)
         ↓
  Replace weight matrix with compact version (remove dropped columns)

- Critical path: Variance-aware scoring → column selection → SVD of Y Z^T → rotation update. Errors in scoring propagate; poor column choices cannot be fixed by rotation.

- Design tradeoffs:
  - Rotation-only vs. Rotation+Scaling: Scaling adds minimal benefit (Table 1); rotation already aligns dominant directions.
  - Target layers: o_proj only vs. down_proj only vs. both; both is best, but o_proj alone captures most gains.
  - Pruning ratio vs. accuracy: Higher ratios (30%) show larger RCPU advantage over baselines but absolute degradation remains substantial (PPL 12.4 → 18.35).

- Failure signatures:
  - Calibration data too small or unrepresentative → variance estimates unreliable → poor column selection.
  - Pruned columns contain irrecoverable directional information → rotation cannot compensate (break condition for Mechanism 1).
  - SVD numerical instability when Y Z^T is ill-conditioned → consider regularization or pseudo-inverse fallback.
  - Least-squares compensation (unconstrained) degrades performance under limited calibration (Figure 2 confirms this pattern).

- First 3 experiments:
  1. Reproduce Table 1 on LLaMA-7B: Compare WANDA-sp, FLAP, RCPU (Rot.), RCPU (Rot.+Scale) at 10%, 20%, 30% pruning on WikiText-2 PPL.
  2. Ablation on scoring: Run RCPU with WANDA-sp scoring vs. variance-aware scoring (Figure 2 replication) to isolate scoring contribution.
  3. Layer targeting ablation: Apply RCPU to o_proj only, down_proj only, and both (Table 3 replication) to confirm o_proj priority.

## Open Questions the Paper Calls Out
None

## Limitations
- The method's effectiveness is tightly coupled to the representativeness and size of the calibration dataset, with only 128 samples used in experiments
- The rotation compensation assumes pruned subspace retains sufficient signal; if pruning removes irrecoverable directional information, performance cannot be fully restored
- The greedy, layerwise application of compensation does not account for potential cross-layer interactions or cumulative error propagation

## Confidence

- **High Confidence**: The core mathematical formulation of the Orthogonal Procrustes problem for rotation-constrained alignment is sound and well-established. The experimental results showing consistent outperformance over baselines (WANDA-sp, FLAP) on LLaMA-7B across multiple metrics (PPL, zero-shot accuracy) are replicable given the specified setup.

- **Medium Confidence**: The design choice to prioritize o_proj compensation over down_proj is supported by the ablation results, but the underlying reason (early correction of misalignment) is inferred rather than directly proven. The claim that rotation compensation outperforms unconstrained least-squares under limited calibration is supported by Figure 2 but lacks direct comparison with other constrained methods.

- **Low Confidence**: The claim that variance-aware scoring is superior to WANDA-sp scoring is based on Figure 2, but the specific implementation details (e.g., exact formula, normalization) are not fully specified in the paper. The generalizability of the method to other LLM architectures (e.g., GPT-2, OPT) or modalities (vision, multimodal) is untested.

## Next Checks

1. **Reproduce Table 1 Ablation**: Run RCPU on LLaMA-7B with pruning ratios of 10%, 20%, and 30% on WikiText-2. Compare the final PPL and zero-shot task accuracy against the reported values for WANDA-sp, FLAP, RCPU (Rot.), and RCPU (Rot.+Scale). This will verify the core claim of consistent outperformance.

2. **Calibration Data Sensitivity Test**: Repeat the RCPU experiment (30% pruning) with different calibration dataset sizes (e.g., 64, 256, 512 samples) and evaluate the impact on PPL and task accuracy. This will quantify the method's robustness to calibration data limitations and identify potential overfitting thresholds.

3. **Unconstrained Least-Squares Baseline**: Implement an unconstrained least-squares error compensation method (minimizing ||Y - W_K X_K||_F^2) for the same pruning ratios and compare its performance to RCPU. This will directly validate the claim that rotation constraints are superior under limited calibration data.