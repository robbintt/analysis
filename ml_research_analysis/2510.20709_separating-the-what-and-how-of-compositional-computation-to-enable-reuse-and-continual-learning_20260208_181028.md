---
ver: rpa2
title: Separating the what and how of compositional computation to enable reuse and
  continual learning
arxiv_id: '2510.20709'
source_url: https://arxiv.org/abs/2510.20709
tags:
- task
- tasks
- learning
- trials
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a two-system framework for continual learning
  of compositional cognitive tasks. The key idea is to separate the "what" (task structure
  inference) from the "how" (computation implementation) by using a probabilistic
  task model to infer computational contexts and an RNN whose components are dynamically
  composed according to these contexts.
---

# Separating the what and how of compositional computation to enable reuse and continual learning

## Quick Facts
- **arXiv ID:** 2510.20709
- **Source URL:** https://arxiv.org/abs/2510.20709
- **Reference count:** 40
- **Primary result:** Two-system RNN framework achieves continual learning of 6 neuroscience tasks without catastrophic forgetting by separating task structure inference from computation implementation

## Executive Summary
This paper introduces a two-system framework for continual learning of compositional cognitive tasks. The approach separates the "what" (task structure inference) from the "how" (computation implementation) by using a probabilistic task model to infer computational contexts and an RNN whose components are dynamically composed according to these contexts. The method successfully learns six neuroscience tasks sequentially while maintaining high performance across all tasks, demonstrating both forward and backward transfer learning through compositional generalization.

## Method Summary
The framework uses an online learning algorithm to infer latent task epochs from input-output sequences and gates low-rank RNN components accordingly. The "what" system is a probabilistic task model that parses input-output streams into discrete latent epochs using an online Expectation-Maximization algorithm. The "how" system is an RNN with low-rank recurrent weights that are dynamically composed based on the inferred contexts. This explicit compositional structure enables continual learning without catastrophic forgetting by localizing weight updates to specific components active during each epoch.

## Key Results
- The model achieves superior performance compared to baselines like EWC and OWP on sequential task learning
- Demonstrates both forward and backward transfer learning through shared latent vocabulary
- Can rapidly generalize to new tasks by recombining learned components without catastrophic forgetting
- Successfully learns six neuroscience tasks (DelayPro/Anti, MemoryPro/Anti, DMPro/Anti) sequentially

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Explicit separation of task inference ("what") from execution ("how") isolates learning updates, reducing interference between sequential tasks.
- **Mechanism:** A probabilistic task model parses input-output streams into discrete latent epochs using online EM algorithm. These inferred contexts gate RNN weights, partitioning learning updates by context.
- **Core assumption:** Tasks share compositional structure built from finite vocabulary of reusable discrete epochs.
- **Evidence anchors:** Abstract states separation of "what" and "how"; Section 4.2 shows contextual inference enables continual learning without catastrophic forgetting.
- **Break condition:** If tasks don't share reusable sub-structures, system reverts to learning each task from scratch.

### Mechanism 2
- **Claim:** Context-gated low-rank RNNs enable parameter isolation without architectural rigidity.
- **Mechanism:** RNN uses low-rank matrices for recurrent weights, with effective weight being linear combination of components weighted by context probability.
- **Core assumption:** Target computations can be approximated by low-dimensional dynamical systems.
- **Evidence anchors:** Abstract mentions RNN components dynamically composed according to contexts; Section 4.1 describes effective network weights as weighted sum of low-rank components.
- **Break condition:** If intrinsic dimensionality of task dynamics exceeds component rank, model fails to learn.

### Mechanism 3
- **Claim:** Shared latent vocabulary enables backward transfer and rapid compositional generalization.
- **Mechanism:** Task model builds global vocabulary of epochs across all tasks, enabling reuse of existing RNN components for familiar epochs in new tasks.
- **Core assumption:** Inference system correctly identifies identical epochs across different tasks.
- **Evidence anchors:** Abstract mentions rapid generalization by recombining learned components; Section 4.3 shows loss of previous tasks continues to decrease after switching to new task.
- **Break condition:** If observation models for distinct states are identical, inference cannot distinguish them and may merge states.

## Foundational Learning

- **Concept:** Hidden Markov Models (HMMs) and EM Algorithm
  - **Why needed here:** The "what" system is essentially an HMM variant inferring latent states from observations using EM algorithm.
  - **Quick check question:** How does the "forward-backward" algorithm compute posterior probability of latent state at time $t$ given full sequence?

- **Concept:** Low-Rank Matrix Factorization in RNNs
  - **Why needed here:** The "how" system uses sum of low-rank factors instead of full-rank recurrent matrix to force learning of efficient context-specific dynamics.
  - **Quick check question:** If recurrent weight matrix $W$ is rank $r \ll N$, what does this imply about dimensionality of dynamic flow?

- **Concept:** Catastrophic Forgetting
  - **Why needed here:** This is primary failure mode the paper addresses - understanding why standard SGD updates overwrite weights relevant to previous tasks.
  - **Quick check question:** In standard RNN trained sequentially on Task A then Task B, why does performance on Task A degrade?

## Architecture Onboarding

- **Component map:** Data → Task Model (Inference) → Context Belief $p(z)$ → RNN Weight Composition → RNN Dynamics → Output
- **Critical path:** Input-output streams → HMM inference → Context gating signal → Low-rank RNN weight composition → Output generation
- **Design tradeoffs:**
  - **Interpretability vs. End-to-End Training:** System not trained end-to-end via backpropagation through inference model. "What" system uses classical statistical learning (EM), improving interpretability but potentially limiting optimization efficiency.
  - **Observation Ambiguity:** If two distinct computational epochs generate statistically identical observations, Task Model cannot distinguish them without external labels or feedback.
- **Failure signatures:**
  - **State Collapse:** Task Model merges distinct epochs into one cluster, causing RNN to attempt non-linear mappings with single linear sub-component.
  - **Inference Lag:** During test-time inference, model may briefly misidentify context at epoch boundaries, causing transient output errors.
- **First 3 experiments:**
  1. **Epoch Segmentation Check:** Train Task Model alone on single task sequence. Visualize inferred posterior $p(z_t)$ against ground truth epoch boundaries to verify EM convergence.
  2. **Ablation on Context Gating:** Train RNN on two sequential tasks. Compare performance when $p(z)$ is provided by Task Model vs. random/shuffled $p(z)$ to confirm context information drives continual learning.
  3. **Compositional Generalization Test:** Train on Tasks A, B, and C. Introduce Task D using novel sequence of known epochs. Freeze RNN weights and train only Task Model parameters for Task D. Verify if system solves D immediately.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can feedback signals from downstream RNN, such as prediction errors, resolve ambiguity of distinct computational contexts that share identical observation models?
- **Basis:** Section 5 states a possible extension would be to incorporate feedback from RNN to task model, as large errors could provide valuable information when contexts are difficult to distinguish based on external observations alone.
- **Why unresolved:** Current architecture relies solely on input-output pairs for inference, causing it to merge distinct internal states if their external statistics are identical.
- **What evidence would resolve it:** Demonstrating that modified architecture with error feedback can successfully disambiguate and maintain separate representations for observationally identical epochs.

### Open Question 2
- **Question:** Does assuming continuous latent variable for trial conditions ($x$) improve model's ability to capture richer tasks and scalability under complex stimulus distributions?
- **Basis:** Section 5 notes assuming continuous $x$ may allow model to capture richer tasks and improve scalability under complex stimulus distributions.
- **Why unresolved:** Current implementation models $x$ as discrete variable to simplify analysis via look-up table of means, limiting granularity of stimulus representations.
- **What evidence would resolve it:** Extending mathematical formulation to continuous $x$ and showing improved performance on tasks with high-dimensional, continuous input features.

### Open Question 3
- **Question:** Can non-parametric methods be adapted to this framework to infer unfamiliar epochs in principled manner while maintaining consistency of latent factor $x$ across epochs?
- **Basis:** Section 5 identifies challenge of extending existing algorithms to case where epoch emissions are controlled by latent factor $x$ that needs to be consistent across epochs.
- **Why unresolved:** While non-parametric methods typically handle infinite components, extending them to maintain specific cross-epoch dependencies of $x$ required by generative model remains unsolved.
- **What evidence would resolve it:** Developing non-parametric online learning algorithm for task model that correctly enforces $x$ consistency and testing it on open-ended task streams.

## Limitations

- **Compositional assumption dependency:** Method's effectiveness depends heavily on assumption that tasks share reusable sub-structures (epochs). If tasks aren't truly compositional, efficiency benefits disappear.
- **Sensitivity to initialization and thresholds:** Online EM algorithm's performance is sensitive to initialization and threshold parameters not fully specified in paper, particularly K-means matching heuristics for incremental epoch discovery.
- **Low-rank assumption constraints:** Method assumes tasks can be modeled as low-rank dynamical systems, which may not hold for all cognitive computations.

## Confidence

- **High confidence:** Separation of task inference from execution provides valid mechanism for reducing interference between sequential tasks. Experimental results showing performance on six neuroscience tasks without catastrophic forgetting are convincing.
- **Medium confidence:** Compositional generalization claims are supported but could be strengthened with more systematic testing across diverse task compositions beyond six neuroscience tasks.
- **Medium confidence:** Backward transfer results are promising but paper doesn't fully explore scenarios where shared components might conflict or degrade previous task performance.

## Next Checks

1. Test system's performance when tasks are not truly compositional - modify task generator to create tasks without shared sub-structures and verify if method still provides benefits over standard RNN training.

2. Conduct systematic ablation studies varying rank of RNN components to determine how dimensionality constraints affect learning capacity across different task complexities.

3. Implement cross-validation framework where system learns multiple random sequences of six tasks to verify performance improvements are not task-specific artifacts but generalize across task orderings.