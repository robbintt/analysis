---
ver: rpa2
title: Learning Parametric Distributions from Samples and Preferences
arxiv_id: '2505.23557'
source_url: https://arxiv.org/abs/2505.23557
tags:
- preferences
- preference
- learning
- have
- distributions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies when preference feedback improves parameter
  estimation for continuous parametric distributions. The authors show that preference-based
  M-estimators achieve lower asymptotic variance than sample-only M-estimators, with
  further improvement for deterministic preferences.
---

# Learning Parametric Distributions from Samples and Preferences

## Quick Facts
- **arXiv ID:** 2505.23557
- **Source URL:** https://arxiv.org/abs/2505.23557
- **Reference count:** 40
- **Primary result:** Preference feedback improves parameter estimation for continuous distributions, with deterministic preferences achieving O(1/n) convergence versus O(1/√n) for sample-only methods.

## Executive Summary
This paper establishes theoretical conditions under which preference feedback improves parameter estimation for continuous parametric distributions. The authors prove that adding preference feedback to maximum likelihood estimation reduces asymptotic variance, and that deterministic preferences enable accelerated O(1/n) convergence rates by creating hard constraints on the parameter space. They introduce a constrained estimator (DP MLE) that achieves this acceleration and prove it is minimax optimal up to dimension-dependent constants. Empirical results confirm DP MLE consistently outperforms sample-only methods, especially in high dimensions.

## Method Summary
The method combines standard maximum likelihood estimation with preference feedback through constrained optimization. For stochastic preferences, the SP MLE adds a logistic loss term to the negative log-likelihood. For deterministic preferences, the DP MLE solves the same objective subject to hard constraints defined by preference consistency. The constraint set Cn is constructed from n deterministic preference triplets and forms a convex polytope. For Gaussian distributions with known covariance, Cn is explicitly computable as linear constraints, enabling efficient quadratic programming. The estimator achieves O(1/n) rates by exploiting the geometry of this feasible set rather than relying on asymptotic normality.

## Key Results
- Preference-based M-estimators achieve strictly lower asymptotic variance than sample-only MLE when preference gradients span all directions
- Deterministic preferences enable O(1/n) estimation error rates versus O(1/√n) for standard M-estimators
- The DP MLE estimator achieves the best-of-both-worlds rate of O(min{d^(3/2)/n, √d/n})
- A matching lower bound of Ω(1/n) confirms the acceleration is minimax optimal up to dimension-dependent constants

## Why This Works (Mechanism)

### Mechanism 1: Stochastic Preference M-Estimation Reduces Asymptotic Variance
- **Claim:** Adding preference feedback to MLE yields strictly better asymptotic covariance than sample-only MLE.
- **Mechanism:** The preference term contributes a positive semi-definite matrix ∆SPθ⋆ to the Fisher information matrix. Since I(qθ⋆,hsto) = I(p⊗2θ⋆) + ∆SPθ⋆, the inverse covariance decreases.
- **Core assumption:** Preference gradients ∇θ⋆ℓθ⋆ span all directions with non-zero probability.
- **Break condition:** If preference gradients vanish on most samples, variance improvement collapses.

### Mechanism 2: Deterministic Preferences Impose Hard Constraints on Parameter Space
- **Claim:** Deterministic preference labels define a convex feasible set Cn that constrains parameter estimation, enabling O(1/n) convergence.
- **Mechanism:** Each deterministic preference creates a half-space constraint. The intersection yields Cn, a convex polytope containing θ⋆. The estimator minimizes log-likelihood within Cn.
- **Core assumption:** Linearization validity and informative preferences assumptions.
- **Break condition:** If preferences are not deterministic, the feasible set Cn becomes empty or meaningless.

### Mechanism 3: Minimum-of-Samples Aggregation Yields O(1/n) Shrinkage
- **Claim:** The diameter of feasible set Cn shrinks as O(1/n) due to positive density of informative samples near the constraint boundary.
- **Mechanism:** The maximal deviation is bounded by the minimum of n random variables. When these have positive density at zero, the minimum scales as log(1/δ)/n with probability 1−δ.
- **Core assumption:** Positive density at zero for all directions.
- **Break condition:** If density vanishes at boundary, convergence slows below O(1/n).

## Foundational Learning

- **Concept: M-estimation and asymptotic normality**
  - **Why needed here:** All variance comparisons rely on standard M-estimator theory where √n(θ̂n − θ⋆) converges to a normal distribution with Fisher information covariance.
  - **Quick check question:** Can you explain why Fisher information I(pθ) appears in the asymptotic variance of MLE?

- **Concept: Convex polytope intersection and feasibility**
  - **Why needed here:** The feasible set Cn is the intersection of half-spaces defined by deterministic preferences; understanding its geometry is essential for implementing DP MLE.
  - **Quick check question:** Given n half-space constraints in ℝk, what is the worst-case complexity of finding a point in their intersection?

- **Concept: Order statistics and minimum convergence rates**
  - **Why needed here:** The O(1/n) rate emerges from properties of minima of random variables with positive density at a boundary—a standard result in extreme value theory.
  - **Quick check question:** For n i.i.d. Uniform(0,1) samples, what is the expected value of the minimum?

## Architecture Onboarding

- **Component map:**
  - SO MLE: Baseline sample-only estimator using negative log-likelihood
  - SP MLE: Stochastic preference MLE with logistic loss term
  - SPdet MLE: Deterministic preference MLE with noiseless labels
  - Cn constraint set: Convex polytope {θ | ∀i, Ziℓθ(Xi,Yi) ≥ 0}
  - DP MLE: Deterministic preference MLE minimizing log-likelihood within Cn
  - Arbitrary Estimator (AE): Any θ̂ ∈ Cn achieving O(1/n) rate

- **Critical path:**
  1. Verify distribution family satisfies all assumptions (Gaussian with known covariance, Laplace with known scale)
  2. Confirm preference model uses log-probability reward: rθ = log pθ
  3. Construct constraint set Cn from n deterministic preference triplets
  4. Solve constrained optimization for DP MLE using quadratic programming (Gaussian) or LP solver

- **Design tradeoffs:**
  - SP MLE vs DP MLE: SP handles noisy preferences but achieves only Θ(1/√n); DP requires deterministic labels but achieves O(1/n)
  - AE vs DP MLE: Any feasible point in Cn achieves O(1/n) rate, but DP MLE minimizes worst-case error constants by staying near MLE
  - Assumption strictness: Assumptions 4.4–4.7 are restrictive and verified only for Gaussian/Laplace

- **Failure signatures:**
  - Empty Cn: If preferences are inconsistent or misspecified, no θ satisfies all constraints
  - Cn too large: If preference gradients vanish, diameter does not shrink at O(1/n)
  - High-dimensional degradation: When d ≳ √n, the covering number N(γ) dominates and O(1/n) rate requires n ≫ d³/²

- **First 3 experiments:**
  1. **Univariate Gaussian validation:** Sample n=100–10⁴ pairs from N(θ⋆, 1), compute SO MLE, SP MLE, and DP MLE; plot estimation error ∥θ̂ − θ⋆∥ vs n to confirm O(1/√n) vs O(1/n) scaling
  2. **Constraint set geometry visualization:** For d=2 Gaussian, visualize polytope Cn for small n (n=10, 20, 50) to confirm shrinkage toward θ⋆; measure diameter empirically
  3. **Dimension scaling test:** For d ∈ {1, 5, 10, 20}, fix n=10⁴ and compare estimation error of DP MLE vs SO MLE; verify DP MLE degrades gracefully as d increases but still outperforms SO MLE

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the dimensionality gap between the upper bound O(Aθ⋆ k/n) and lower bound Ω(αF(k)√k/n) be closed for deterministic preference-based estimation?
- **Basis in paper:** [explicit] "Even for the simple case of Gaussian distributions where Aθ⋆ = αF(d), there is a dimensionality gap. Closing this gap is an important direction for future work."
- **Why unresolved:** Current analysis leaves a √k factor discrepancy between bounds; unclear if tighter analysis or fundamentally better estimators are needed.
- **What evidence would resolve it:** Either a refined upper bound matching the lower bound, or a modified estimator achieving improved dimension dependence, or a refined lower bound.

### Open Question 2
- **Question:** How do preference-based estimators perform for discrete distributions, and does the O(1/n) acceleration still hold?
- **Basis in paper:** [explicit] "A key challenge for future work is to quantify the benefits of preference-based estimation for discrete distributions."
- **Why unresolved:** For small support distributions, preference feedback may only localize the parameter within a simplex subset, leading to diminishing information gains as sample size increases.
- **What evidence would resolve it:** Analysis establishing rates for discrete distributions (e.g., categorical) showing whether accelerated rates are achievable or characterizing the gap from continuous case.

### Open Question 3
- **Question:** Can alternative preference functions beyond log-probability gaps satisfy the required assumptions and achieve similar acceleration?
- **Basis in paper:** [explicit] "Exploring alternative preference functions beyond the log-probability gap could extend the applicability of our results."
- **Why unresolved:** Current analysis relies on restrictive assumptions satisfied mainly by log-probability rewards for Gaussian/Laplace; other reward structures remain uncharacterized.
- **What evidence would resolve it:** Identifying broader classes of preference functions satisfying key assumptions, or developing modified analysis for alternative reward structures.

### Open Question 4
- **Question:** How can the constraint set geometry of Cn be better exploited to design estimators that improve upon DP MLE?
- **Basis in paper:** [explicit] "A finer analysis of beyond-M-estimators and their constraint set geometry would allow to better quantify the properties of DP MLE, and provide insights for designing improved estimators."
- **Why unresolved:** Empirical results show center-based estimators outperform DP MLE in some regimes; theoretical understanding of why certain points in Cn yield better estimates is lacking.
- **What evidence would resolve it:** Theoretical characterization of optimal selection strategies within Cn, or new estimators with provably better constants than DP MLE.

## Limitations
- The theoretical framework requires restrictive assumptions verified only for Gaussian and Laplace distributions
- The O(1/n) rate guarantee breaks down when preference gradients vanish or when preferences contain even small stochastic noise
- The constraint set Cn becomes computationally intractable for high-dimensional problems due to exponential growth in covering numbers

## Confidence
- **High Confidence:** The variance reduction mechanism for stochastic preferences (SP MLE vs SO MLE) is mathematically rigorous and empirically verified across distribution families
- **Medium Confidence:** The O(1/n) rate for deterministic preferences is theoretically sound but requires very strong assumptions verified only for Gaussian and Laplace cases
- **Low Confidence:** The minimax optimality proof assumes exact deterministic preferences and may not extend to realistic noisy preference settings

## Next Checks
1. **Noisy Preference Robustness:** Test DP MLE performance with ε-noise in preference labels (Zi = sign(ℓθ⋆ + ε·noise)) to quantify degradation from theoretical O(1/n) rate
2. **Non-Gaussian Distribution Testing:** Apply the framework to exponential and logistic distributions to identify which assumptions break first and characterize resulting rate degradations
3. **Constraint Set Complexity Analysis:** For d=10-50 dimensions, measure the computational complexity of maintaining and optimizing over Cn as n grows, comparing exact polytope methods vs approximate projections