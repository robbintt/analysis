---
ver: rpa2
title: Enhancing Customer Service Chatbots with Context-Aware NLU through Selective
  Attention and Multi-task Learning
arxiv_id: '2506.01781'
source_url: https://arxiv.org/abs/2506.01781
tags:
- context
- intent
- order
- user
- customer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses intent classification in customer service
  chatbots, where user queries are often ambiguous and context from order history
  can help resolve intent. The authors propose a context-aware model that uses a novel
  selective attention module to dynamically weigh context features based on both query
  and context, and a multi-task learning (MTL) framework to jointly predict explicit
  (utterance) and latent (conversation) intents.
---

# Enhancing Customer Service Chatbots with Context-Aware NLU through Selective Attention and Multi-task Learning

## Quick Facts
- arXiv ID: 2506.01781
- Source URL: https://arxiv.org/abs/2506.01781
- Authors: Subhadip Nandi; Neeraj Agrawal; Anshika Singh; Priyanka Bhatt
- Reference count: 9
- Primary result: MTL-CNLU-SAWC achieves 90.92% top-2 accuracy, improving over query-only baseline by 4.8% and over state-of-the-art context-aware models by 3.5%

## Executive Summary
This paper introduces a context-aware NLU model for customer service chatbots that addresses ambiguous user queries through selective attention and multi-task learning. The model combines user utterances with order history features to predict both explicit (utterance) and latent (conversation) intents. A novel selective attention module dynamically weights context features based on query content, while a dual-head architecture jointly trains on two label types derived from user utterances and agent conversations. The approach achieves state-of-the-art performance and was deployed in Walmart's customer care system, reducing human agent escalations and saving nearly $1M annually.

## Method Summary
The proposed MTL-CNLU-SAWC model uses a shared BERT encoder to process user utterances, then combines them with handcrafted context features (21 total) derived from order history through a selective attention mechanism. Two separate classification heads predict explicit intent (59 classes) from the utterance and latent intent (35 classes) from context. The attention module applies weights only when the utterance predicts a "flow" intent; otherwise, raw context is used for latent intent prediction. The model is trained end-to-end using multi-task learning with a combined loss function, achieving 90.92% top-2 accuracy on a dataset of 100K training examples.

## Key Results
- MTL-CNLU-SAWC achieves 90.92% top-2 accuracy, outperforming query-only baseline by 4.8% and state-of-the-art context-aware models by 3.5%
- Selective attention and multi-task learning framework improves latent intent prediction from 88.38% to 89.90% top-2 score
- Handcrafted context features significantly impact performance, with ablation showing up to 1.5% accuracy drop when key features are removed
- Deployed in Walmart's customer care system, reducing human agent escalations and saving nearly $1M annually

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Selective attention enables the model to conditionally rely on context features based on whether the predicted utterance intent belongs to a defined workflow.
- **Mechanism:** An attention module computes weights using both query and context embeddings (Equation 2-3). These weights are applied element-wise to the context vector *only* when the utterance head predicts a flow intent; otherwise, raw context is passed directly (Algorithm 1). This prevents irrelevant query information from overriding contextual signals for non-flow utterances like "hello there."
- **Core assumption:** Explicit intent type (flow vs. non-flow) is a reliable signal for whether query semantics should influence latent intent prediction.
- **Evidence anchors:**
  - [abstract] "A novel selective attention module is used to extract relevant context features."
  - [section 2.6.2] "For all utterances where the explicit intent corresponds to a non-flow intent, the latent intent prediction should depend solely on the context vector."
  - [corpus] No direct corpus validation of selective attention for intent classification; related work focuses on RAG and emotion-sensitive LLMs, not conditional attention mechanisms.
- **Break condition:** If utterance intent classification is noisy or flow/non-flow boundaries are poorly defined, selective gating may propagate errors to latent intent prediction.

### Mechanism 2
- **Claim:** Multi-task learning with dual label types improves latent intent prediction by providing supervisory signal from agent conversations during training.
- **Mechanism:** Two classification heads share a BERT backbone but maintain separate query-context combining modules. The utterance head predicts explicit intent from user query; the conversation head predicts latent intent using context. Combined loss (Equation 5) jointly updates all parameters, with λ controlling conversation loss weight.
- **Core assumption:** Conversation labels derived from agent interactions serve as reliable proxies for context-grounded intent when utterance labels are ambiguous.
- **Evidence anchors:**
  - [abstract] "We have also proposed a multi-task learning paradigm for the effective utilization of different label types."
  - [section 2.4] "The subsequent user-agent conversation serves as a proxy for the user's context."
  - [Table 4] MTL-CNLU achieves 89.90% top-2 score vs. 88.38% for single-head CAWC.
- **Break condition:** If conversation labels are unavailable at inference time but were heavily relied upon during training, the model may overfit to supervisory signals it cannot access during deployment.

### Mechanism 3
- **Claim:** Handcrafted features derived from transaction history provide disambiguating signals that raw text cannot convey.
- **Mechanism:** Binary features (e.g., "are any items left to be delivered"), categorical features (e.g., order fulfillment type), and numerical features (e.g., time since order placement) are constructed from raw transaction data, normalized, and embedded where appropriate. Ablation shows removal of key features drops accuracy substantially.
- **Core assumption:** Transaction state directly maps to user intent; for example, overdue items imply "order late" intent regardless of utterance phrasing.
- **Evidence anchors:**
  - [section 2.1] "Feature 'are any items left to be delivered' is created by comparing the number of ordered and delivered items."
  - [Table 6] Removing "are any items left to be delivered" drops top-1 accuracy from 81.48% to 79.86%.
  - [corpus] Weak corpus support; related papers do not evaluate handcrafted transaction features for intent classification.
- **Break condition:** If transaction data is incomplete, delayed, or inconsistent with actual order state, context features will mislead rather than clarify.

## Foundational Learning

- **Concept: Attention mechanisms for feature weighting**
  - Why needed here: The model must dynamically prioritize context features based on query content; static concatenation fails to capture feature relevance.
  - Quick check question: Can you explain why element-wise multiplication of attention weights suppresses irrelevant context dimensions?

- **Concept: Multi-task learning with shared representations**
  - Why needed here: Explicit and latent intent prediction share underlying semantic understanding but require different output mappings.
  - Quick check question: What happens to shared BERT parameters if one task's loss dominates the combined loss?

- **Concept: Label noise and proxy supervision**
  - Why needed here: Utterance-only labels are insufficient for ambiguous queries; conversation labels provide a noisy but informative alternative signal.
  - Quick check question: How would you detect if conversation labels systematically differ from true user intent?

## Architecture Onboarding

- **Component map:** BERT encoder (shared) -> Context preprocessing (normalization/embedding) -> Attention module (conditional) -> Dual-head MTL architecture (utterance + conversation heads) -> Combined loss backprop
- **Critical path:** Transaction data -> feature engineering -> context vector -> attention weighting (conditional) -> dual-head prediction -> combined loss -> backprop through shared BERT
- **Design tradeoffs:**
  - Separate vs. shared query-context modules: Separate modules performed better (Table 7) but increase parameter count
  - Flow/non-flow gating: Improves latent intent for non-flow utterances but adds inference dependency on utterance head accuracy
  - λ weighting: Set to 1; higher values may overfit to conversation labels at expense of utterance accuracy
- **Failure signatures:**
  - Latent intent mispredicts when utterance is generic ("hello there") and context is overdue → model defaults to training correlation rather than current context
  - Shared query-context module causes 4% drop in top-2 score (Table 7)
  - Missing context features reduce accuracy by ~1.5% (Table 6)
- **First 3 experiments:**
  1. **Establish baseline:** Train query-only BERT+MLP on utterance labels; record top-2 accuracy and confusion matrix for ambiguous utterances
  2. **Validate attention contribution:** Compare CAWC (attention-weighted context) against simple concatenation; measure improvement on examples where utterance and conversation labels differ
  3. **Ablate selective gating:** Disable the flow/non-flow condition (always apply attention) and compare latent intent F1; expect degradation on non-flow utterances with overdue context

## Open Questions the Paper Calls Out

- **Open Question 1:** Can incorporating customer website and app interaction data (e.g., help pages visited) as context improve the resolution of ambiguous queries?
  - Basis in paper: [explicit] Section 8 (Future Work) identifies "customer's website/app interaction data" as a valuable but untapped source of context information
  - Why unresolved: The current study limited context features to customer transaction history (order status, delivery details) and did not integrate behavioral data from digital touchpoints
  - What evidence would resolve it: A comparative study where clickstream or navigation history features are added to the context vector, measuring the change in Top-2 accuracy

- **Open Question 2:** Does utilizing conversation history from previous customer sessions enhance the model's ability to predict latent intents?
  - Basis in paper: [explicit] Section 8 (Future Work) lists "conversations of the customer with human agent/chatbot from an earlier session" as a future source of context
  - Why unresolved: The proposed MTL-CNLU-SAWC model treats each interaction instance independently, relying only on the current utterance and transactional state
  - What evidence would resolve it: A modified architecture that encodes historical dialogue states and demonstrates improved performance on follow-up queries where the intent is implicit

- **Open Question 3:** Is the performance gain derived from handcrafted context features replicable using end-to-end learning on raw transaction logs?
  - Basis in paper: [inferred] The methodology relies heavily on manual feature engineering (Table 2), and the ablation study (Table 6) confirms specific handcrafted flags (e.g., "are any items left to be delivered") drive accuracy
  - Why unresolved: The paper does not determine if the model could automatically discover these patterns from raw data, which is necessary for generalizing to domains where feature engineering is infeasible
  - What evidence would resolve it: A benchmark comparing the current model against an architecture that ingests raw temporal transaction sequences (e.g., via a Transformer encoder) without pre-computed features

## Limitations
- Selective attention effectiveness depends on accurate utterance intent classification, which may fail in noisy real-world deployments
- Handcrafted context features are domain-specific and require manual engineering, limiting generalizability
- Model requires both utterance and conversation labels during training, which may not be available in all deployment scenarios

## Confidence
- Selective attention effectiveness: Medium
- Multi-task learning improvement: Medium
- Handcrafted feature contribution: Medium
- Deployment impact claims: Low (business metrics not independently verified)

## Next Checks
1. Measure latent intent accuracy degradation when utterance head predictions are artificially corrupted with increasing noise levels
2. Cross-validate conversation labels against a held-out set of true user intents annotated by human experts
3. Replicate ablation studies on a different customer service dataset to test handcrafted feature portability