---
ver: rpa2
title: 'Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future
  Directions'
arxiv_id: '2510.25445'
source_url: https://arxiv.org/abs/2510.25445
tags:
- agentic
- neural
- systems
- symbolic
- paradigm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey addresses the fragmented understanding of Agentic AI,
  where modern neural systems are often incorrectly conflated with outdated symbolic
  models. To resolve this, the authors introduce a dual-paradigm framework distinguishing
  the Symbolic/Classical lineage (algorithmic planning, persistent state) from the
  Neural/Generative lineage (stochastic generation, prompt-driven orchestration).
---

# Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions

## Quick Facts
- arXiv ID: 2510.25445
- Source URL: https://arxiv.org/abs/2510.25445
- Authors: Mohamad Abou Ali; Fadi Dornaika
- Reference count: 40
- Key outcome: Introduces a dual-paradigm framework distinguishing Symbolic/Classical (algorithmic planning, persistent state) from Neural/Generative (stochastic generation, prompt-driven orchestration) Agentic AI, analyzing 90 studies to reveal paradigm-specific governance gaps, application patterns, and future integration needs.

## Executive Summary
This survey addresses the fragmented understanding of Agentic AI by systematically reviewing 90 studies (2018–2025) to establish a dual-paradigm framework. It distinguishes between Symbolic/Classical agents (based on BDI, MDPs, PPAR loops) and Neural/Generative agents (based on LLM orchestration, RAG, and prompt pipelines). Through PRISMA-based methodology, the authors reveal that paradigm choice is strategic: symbolic systems dominate safety-critical domains like healthcare, while neural systems prevail in adaptive, data-rich environments like finance. The survey identifies critical gaps including governance imbalance (overemphasis on neural ethics), evaluation deficiencies (lack of paradigm-specific benchmarks), and the need for intentional neuro-symbolic integration.

## Method Summary
The authors conducted a PRISMA 2020 systematic literature review across six databases (IEEE Xplore, ACM DL, arXiv, SpringerLink, ScienceDirect, Google Scholar) using keywords like "Agentic AI", "LLM agent", "BDI agent", and "Prompt chaining" for the period January 2018 to March 2025. From an initial pool of 157 papers, they identified 78 core studies plus 12 supplemental seminal works. The review employed thematic synthesis with qualitative coding to map architectures to the proposed Symbolic/Classical vs. Neural/Generative paradigm framework, resulting in detailed taxonomies of architectures, applications, and governance challenges.

## Key Results
- Dual-paradigm framework successfully classifies modern Agentic AI into distinct Symbolic (BDI, MDP-based) and Neural (LLM-driven, prompt-based) lineages
- Paradigm choice is strategic: symbolic systems dominate safety-critical domains (healthcare) while neural systems prevail in adaptive, data-rich environments (finance)
- Significant governance gap exists for symbolic systems, with current ethical research focusing overwhelmingly on neural alignment challenges
- Neuro-symbolic integration emerges as the critical frontier for creating systems that are both adaptable and reliable

## Why This Works (Mechanism)

### Mechanism 1: Paradigm-Constraint Alignment
- **Claim:** Deploying Agentic AI successfully depends on aligning the architectural paradigm (Symbolic vs. Neural) with domain-specific constraints such as safety criticality and data fluidity.
- **Mechanism:** Symbolic systems enforce rigid, verifiable logic suited for static, high-stakes rules (e.g., clinical protocols), whereas Neural systems leverage stochastic generation to navigate ambiguous, data-rich environments where explicit rules are insufficient.
- **Core assumption:** Application constraints dictate architectural fitness; no single architecture is universally superior.
- **Evidence anchors:** [abstract] "paradigm choice is strategic: symbolic systems dominate safety-critical domains... while neural systems prevail in adaptive, data-rich environments" [Section 5] Demonstrates this split in healthcare (symbolic) vs. finance (neural).

### Mechanism 2: Prompt-Driven Orchestration (Neural Paradigm)
- **Claim:** Neural agents achieve agency not through internal cognitive models, but via external orchestration of LLMs using prompts and context windows.
- **Mechanism:** Frameworks like LangChain or AutoGen manage state and tool use by feeding history and instructions into a generative model's context window. The "reasoning" is a byproduct of statistical token prediction, not symbolic logic traversal.
- **Core assumption:** LLMs serve as sufficient statistical reasoning engines when properly constrained by retrieval (RAG) and tool definitions.
- **Evidence anchors:** [Section 2.3] Describes the "LLM Substrate" and the shift from explicit programming to generative pipelines. [Section 4.5] Contrasts "Emergent Conversation" (Neural) with "Algorithmic Contracts" (Symbolic).

### Mechanism 3: Neuro-Symbolic Governance Layering
- **Claim:** Effective governance requires paradigm-specific mechanisms rather than monolithic policies.
- **Mechanism:** Reliability is enforced by auditing logical rules in symbolic systems and monitoring training data/prompts in neural systems. Hybrid systems require dual-layer oversight: verifying the symbolic guardrails while monitoring the neural outputs for drift.
- **Core assumption:** Accountability frameworks (e.g., liability laws) can be technically mapped to specific architectural components.
- **Evidence anchors:** [Section 7] Table 9 details distinct mitigation strategies for Symbolic vs. Neural challenges. [Section 8] Identifies the "governance gap" where symbolic systems lack modern auditing frameworks.

## Foundational Learning

- **Concept: Belief-Desire-Intention (BDI) vs. PPAR Loops**
  - **Why needed here:** The paper argues that modern "Neural" agents are often incorrectly retrofitted into these "Symbolic" frameworks. Understanding the distinction prevents architectural mismatch.
  - **Quick check question:** Is the system executing a hard-coded plan (Symbolic) or generating the next step based on a context window (Neural)?

- **Concept: Markov Decision Processes (MDPs)**
  - **Why needed here:** These form the theoretical bedrock of the Symbolic lineage described in the paper. Understanding them explains why symbolic agents struggle with partial observability (POMDPs) and scalability.
  - **Quick check question:** Can the agent theoretically know the full state of the environment, or must it infer a "belief state"?

- **Concept: Context Window & Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** In the Neural paradigm, this is the functional equivalent of "memory" and "knowledge." The paper frames RAG as the bridge for neural agents to access verified data.
  - **Quick check question:** How does the agent access external facts—via explicit database queries (Symbolic) or vector similarity search (Neural)?

## Architecture Onboarding

- **Component map:**
  - Substrate: LLM (e.g., GPT-4, Llama) for reasoning; or Rule Engine (e.g., Drools) for logic
  - Orchestrator: Frameworks like LangChain/AutoGen (Neural) or BDI implementations (Symbolic)
  - Tools: APIs (deterministic functions) called by the agent
  - Memory: Vector Stores (Neural) or Knowledge Graphs (Symbolic)

- **Critical path:**
  1. **Paradigm Selection:** Assess domain risk vs. adaptability needs
  2. **Orchestration Design:** Define agent roles (single vs. multi-agent) and communication protocols (conversational vs. algorithmic)
  3. **Governance Injection:** Embed safety layers (symbolic constraints or constitutional prompts)

- **Design tradeoffs:**
  - **Verifiability vs. Adaptability:** You generally trade one for the other
  - **Latency:** Symbolic systems are typically faster/more predictable; Neural systems have variable inference times
  - **Development Speed:** Neural agents are faster to prototype (prompting) but harder to debug; Symbolic agents require upfront rule engineering

- **Failure signatures:**
  - **Hallucination:** (Neural) Confidently stating false facts; often caused by retrieval failure or context overload
  - **Edge-case Brittleness:** (Symbolic) Total failure when encountering a situation not covered by explicit rules
  - **Goal Drift:** (Hybrid) The neural component finds a "shortcut" that satisfies the symbolic reward function but violates the intent

- **First 3 experiments:**
  1. **Paradigm Audit:** Take an existing "AI Agent" and classify it using the paper's dual-paradigm framework. Identify if "conceptual retrofitting" is occurring
  2. **Constraint Testing:** Build a simple neural agent (e.g., LangChain) for a task requiring strict adherence to a rule (e.g., "do not reveal internal data"). Test if it fails where a symbolic rule would succeed
  3. **Hybrid Mockup:** Design a system where a neural agent synthesizes data, but a symbolic agent validates the output against a set of rules before execution

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the neural and symbolic paradigms be intentionally integrated to create hybrid architectures that simultaneously possess the adaptability of generative models and the verifiability of algorithmic logic?
- **Basis in paper:** [explicit] The paper concludes that the future of Agentic AI lies in "intentional integration" and identifies "Neuro-Symbolic Integration as the Keystone" in Section 9. It explicitly calls for research into coupling neural networks for perception with symbolic engines for reasoning.
- **Why unresolved:** The paper argues that the two paradigms operate on "fundamentally incompatible" mechanics—stochastic generation versus algorithmic deliberation—making seamless integration difficult without forcing one paradigm to conform to the other's constraints.
- **What evidence would resolve it:** The development of standardized middleware or protocols that allow neural agents to query symbolic reasoners for validation in real-time without breaking the flow of orchestration.

### Open Question 2
- **Question:** What specific governance frameworks and liability models are required for purely symbolic systems, given the identified deficit in modern research on this topic?
- **Basis in paper:** [explicit] The abstract and Section 7 identify a "significant deficit in governance models for symbolic systems" and a "governance imbalance," noting that current ethical research focuses overwhelmingly on the neural paradigm.
- **Why unresolved:** The paper notes that while symbolic systems are deployed in safety-critical domains, the focus of AI safety has shifted almost entirely to neural alignment (e.g., prompt injection), leaving the unique logical risks of symbolic systems under-addressed.
- **What evidence would resolve it:** The establishment of audit trails specifically designed for decision logic in symbolic agents, distinct from the context-logging mechanisms used for neural agents.

### Open Question 3
- **Question:** How can evaluation benchmarks be redesigned to account for paradigm-specific failure modes, specifically distinguishing between logical brittleness in symbolic systems and hallucination in neural systems?
- **Basis in paper:** [explicit] Section 8 (Table 11) lists "Evaluation & Benchmarks" as a major gap, noting that applying the standards of one paradigm to the other is flawed. It calls for "paradigm-specific benchmarks" to test logical soundness vs. prompt resilience.
- **Why unresolved:** Current benchmarks (like AgentBench) often fail to test for "subtle misalignments" in neural agents or the "failure predictability" of symbolic agents because they treat agency as a monolithic capability.
- **What evidence would resolve it:** The adoption of dual-track evaluation suites where symbolic systems are stress-tested for edge-case reasoning and neural systems are tested for consistency across rephrasings and cost efficiency.

### Open Question 4
- **Question:** What architectural innovations are required to overcome the "inherent statelessness" of LLM-based neural agents to enable long-term, cumulative learning and memory?
- **Basis in paper:** [explicit] Table 11 and Section 4.4 highlight "Long-term Autonomy & Memory" as a critical gap, noting that current LLM agents suffer from "severe amnesia" across sessions due to context window limitations.
- **Why unresolved:** While symbolic systems maintain a persistent state, they struggle to learn from new data; conversely, neural systems are generative but lack a durable mechanism to retain knowledge or context over extended periods without massive context windows.
- **What evidence would resolve it:** The creation of external, structured memory architectures that agents can reliably read from and write to, effectively injecting the "persistent memory" of symbolic AI into neural frameworks.

## Limitations

- The dual-paradigm framework may oversimplify the diversity of modern agentic systems that blend symbolic and neural elements in complex ways not captured by strict classification
- Governance recommendations for hybrid systems remain largely theoretical with limited empirical validation of practical implementation
- The survey may reflect publication bias rather than actual deployment patterns in claiming paradigm preferences for specific domains

## Confidence

- **High confidence:** The systematic review methodology (PRISMA) and classification of core theoretical foundations (BDI, MDPs, PPAR) are methodologically sound and well-supported
- **Medium confidence:** The paradigm-specific application mapping (healthcare vs. finance) is plausible but may reflect publication bias rather than actual deployment patterns
- **Low confidence:** The proposed governance framework's practical effectiveness remains untested, as most cited examples are conceptual rather than implemented case studies

## Next Checks

1. **Taxonomy Verification:** Apply the survey's dual-paradigm classification to 10 recently published agentic AI systems and compare results with the original survey's classifications
2. **Application Mapping Audit:** Survey industry practitioners to verify whether the claimed paradigm preferences (symbolic for safety-critical, neural for adaptive domains) align with actual deployment choices
3. **Governance Framework Testing:** Identify existing regulatory frameworks for agentic AI and assess whether they naturally align with the survey's proposed paradigm-specific mechanisms