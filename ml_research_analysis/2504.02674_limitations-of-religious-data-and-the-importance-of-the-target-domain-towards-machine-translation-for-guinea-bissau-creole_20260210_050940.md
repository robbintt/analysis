---
ver: rpa2
title: 'Limitations of Religious Data and the Importance of the Target Domain: Towards
  Machine Translation for Guinea-Bissau Creole'
arxiv_id: '2504.02674'
source_url: https://arxiv.org/abs/2504.02674
tags:
- bible
- data
- sentences
- kiriol
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a new dataset for Guinea-Bissau Creole (Kiriol)
  with ~40,000 parallel sentences in Kiriol, English, and Portuguese, primarily from
  religious texts (Bible, Jehovah's Witnesses) plus 1,000 general-domain dictionary
  sentences. Training from-scratch transformer models, they find that adding even
  300 target-domain dictionary sentences to religious training data substantially
  improves BLEU scores (up to 6.7 points) on general-domain test sets.
---

# Limitations of Religious Data and the Importance of the Target Domain: Towards Machine Translation for Guinea-Bissau Creole

## Quick Facts
- **arXiv ID**: 2504.02674
- **Source URL**: https://arxiv.org/abs/2504.02674
- **Reference count**: 33
- **Key outcome**: Adding just 300-600 target-domain sentences to religious training data improves BLEU scores by 4-7 points on general-domain test sets for Guinea-Bissau Creole translation

## Executive Summary
This study introduces a new dataset for Guinea-Bissau Creole (Kiriol) with approximately 40,000 parallel sentences across Kiriol, English, and Portuguese, primarily from religious texts supplemented with 1,000 general-domain dictionary sentences. The researchers find that adding small amounts of target-domain parallel data to abundant religious training data substantially improves translation performance on out-of-domain test sets, with 600 sentences oversampled 5x producing the best results. Portuguese-to-Kiriol models outperform other language pairs, likely due to lexical overlap and morphological simplicity of Kiriol. Shared embeddings improve performance most for Portuguese-Kiriol pairs. Despite BLEU gains, human evaluation shows translation quality remains low, highlighting the need for more comprehensive data collection and evaluation strategies for low-resource languages.

## Method Summary
The researchers constructed a new parallel corpus for Guinea-Bissau Creole by aligning Bible verses (29,876 sentences), Jehovah's Witnesses texts (7,099 sentences), and a bilingual dictionary (1,603 sentences + 1,983 lexical items). They trained encoder-decoder transformer models from scratch using the Eole toolkit with BPE tokenisation (10k vocab), Adam optimizer with Noam decay, and early stopping on validation BLEU. Experiments varied data composition (religious-only vs. religious+target-domain), tokeniser configuration (shared vs. separate), and embedding sharing strategies. The primary evaluation metric was BLEU score on a held-out domain-general test set of 1,000 dictionary sentences, with human evaluation providing supplementary fluency/accuracy assessments.

## Key Results
- Adding 300-600 target-domain dictionary sentences to religious training data improves BLEU scores by 4-7 points on general-domain test sets
- Portuguese-to-Kiriol models significantly outperform Kiriol-to-Portuguese and Kiriol-to-English/Eng-to-Kiriol models
- Shared embeddings improve performance most for Portuguese-Kiriol pairs (high lexical overlap) compared to Kiriol-English pairs (low lexical overlap)
- Separate tokenisers perform as well as or slightly better than combined tokenisers for Kiriol, suggesting morphological simplicity disadvantages Kiriol in combined tokenisers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding small amounts of target-domain parallel data to religious training data substantially improves translation performance on out-of-domain test sets.
- Mechanism: Target-domain sentences provide lexical distribution and syntactic patterns that religious texts lack, enabling the model to align vocabulary and structures relevant to general-purpose translation. Oversampling this small data (5x) amplifies its signal without requiring large-scale collection.
- Core assumption: The domain gap between religious texts and general usage is primarily lexical and structural rather than fundamental grammatical incompatibility.
- Evidence anchors:
  - [abstract] "Adding even 300 sentences from the target domain when training substantially improves the translation performance, highlighting the importance and need for data collection for low-resource languages, even on a small-scale."
  - [section 5.2] "Adding 600 sentences oversampled 5 times produces best results on the test set... indicating that very small amounts of target domain data can be of high utility."
  - [corpus] Related work on low-resource MT (e.g., Kpelle corpus construction) similarly shows religious texts plus modest domain-specific data improve functional MT, though domain transfer strategies vary.
- Break condition: If the target domain requires vocabulary or pragmatic patterns entirely absent from both religious and small domain samples (e.g., technical jargon, contemporary slang), performance gains will plateau.

### Mechanism 2
- Claim: Morphological asymmetry between language pairs causes tokenisation inefficiency that disadvantages the morphologically simpler language when using combined tokenisers.
- Mechanism: Combined BPE tokenisers allocate vocabulary space proportionally to unique subword units. Morphologically complex languages (Portuguese with rich inflection) occupy more vocabulary slots with language-specific tokens, leaving fewer slots for the simpler language (Kiriol). This increases fertility (tokens per word) and degrades representation quality for the simpler language.
- Core assumption: Fertility differences directly impact downstream MT quality by reducing effective model capacity for the disadvantaged language.
- Evidence anchors:
  - [section 5.3.1] "When the tokenisers are applied to the Kiriol data, the separate tokenisers are as good as, or slightly better than, the combined ones... the Kiriol data is somehow disadvantaged in the combined tokeniser setup."
  - [section 5.3.1] Stemming experiment: "When we train combined tokenisers on the parallel data for Kiriol and stemmed English, and Kiriol and stemmed Portuguese, we indeed find that the fertility improves slightly for Kiriol."
  - [corpus] Limited direct corpus evidence on creole-lexifier tokenisation; related work on morphological complexity in MT (e.g., Mager et al.) discusses similar issues for polysynthetic languages.
- Break condition: If vocabulary size is sufficiently large relative to corpus size, or if languages share enough lexical tokens, the disadvantage may be negligible.

### Mechanism 3
- Claim: Shared embedding layers improve MT performance more for language pairs with high lexical overlap than for pairs with low overlap.
- Mechanism: Lexically overlapping tokens can share representation space, allowing the model to transfer learned embeddings across languages. For Kiriol-Portuguese (high overlap due to creole-lexifier relationship), shared embeddings provide meaningful cross-lingual signal. For Kiriol-English (low overlap), the benefit is smaller.
- Core assumption: The embedding layer is a primary bottleneck for low-resource MT, and cross-lingual embedding sharing provides more benefit than separate language-specific capacity.
- Evidence anchors:
  - [section 5.3.1] "There is a much higher degree of overlap between the Kiriol and Portuguese vocabularies than between the Kiriol and English vocabularies... 1,119 overlapping tokens vs. 689 at 10k vocab size."
  - [section 5.3.2] "Portuguese-Kiriol models show the greatest improvements [with shared embeddings]... We tentatively take this as further evidence that lexical overlap between Kiriol and Portuguese is impacting model training."
  - [corpus] Corpus evidence on creole-lexifier lexical overlap is consistent (e.g., Haitian-French MT studies), but embedding-sharing mechanisms specifically are underexplored.
- Break condition: If languages have high overlap but divergent semantics for cognates (false friends), shared embeddings may introduce noise.

## Foundational Learning

- Concept: **Domain Adaptation via Data Mixing**
  - Why needed here: The core finding is that mixing small target-domain data with abundant source-domain (religious) data improves cross-domain generalization. Understanding domain shift (vocabulary, register, topical distribution) explains why this works.
  - Quick check question: If you have 30k religious sentences and 300 medical sentences, would naive mixing (3% medical) be optimal, or should you oversample the medical data?

- Concept: **BPE Tokenization and Fertility**
  - Why needed here: The paper identifies morphological complexity as affecting tokenisation efficiency. You need to understand how BPE allocates vocabulary slots and how fertility (tokens/word) impacts model capacity.
  - Quick check question: Language A has 50k unique word types; Language B has 10k. How would a shared 10k-vocab BPE tokeniser likely distribute slots between them?

- Concept: **Creole Language Characteristics**
  - Why needed here: Creoles typically have morphological simplicity and lexical overlap with lexifier languages. This paper exploits these properties for Kiriol-Portuguese; understanding creole linguistics helps generalize findings.
  - Quick check question: Why might a creole-lexifier language pair benefit more from shared embeddings than a creole-nonlexifier pair?

## Architecture Onboarding

- Component map:
  - Dataset construction (Bible/WT alignment + dictionary extraction) -> Test/validation split (1,000 dict for test, 500 Bible + 500 WT for validation) -> Tokeniser training (BPE on training data only, shared or separate) -> Model training (from-scratch Transformer with specified data mix) -> Evaluation (BLEU on domain-general test set)

- Critical path:
  1. Dataset construction → Bible/WT alignment (religious) + dictionary extraction (general domain)
  2. Test/validation split → 1,000 dictionary sentences for test (out-of-domain), 1,000 Bible+WT for validation
  3. Tokeniser training → BPE on training data only (shared or separate)
  4. Model training → from-scratch Transformer with specified data mix
  5. Evaluation → BLEU on domain-general test set

- Design tradeoffs:
  - **Shared vs. separate tokenisers**: Shared improves efficiency for high-overlap pairs (Kiriol-Portuguese) but may disadvantage morphologically simpler languages in low-overlap pairs
  - **Shared vs. separate embeddings**: Shared embeddings help lexical-overlap pairs; separate may help when languages diverge
  - **Oversampling target-domain data**: 5x oversampling of 600 dictionary sentences worked best; 10x showed diminishing returns, suggesting overfitting risk
  - **Religious data selection**: Bible+WT combination outperformed selective sampling strategies (OT vs. NT, length-based filtering)

- Failure signatures:
  - **High variance across seeds**: Standard errors are large (often 1-3 BLEU), especially for small training sets; run multiple seeds
  - **Poor performance with religious-only training**: BLEU ~4.23 average on domain-general test, indicating domain mismatch
  - **Separate embeddings with high lexical overlap**: Models failed to train reliably; required outlier seed removal

- First 3 experiments:
  1. **Baseline religious-only**: Train Bible+WT only on all four language directions (Kir-Eng, Eng-Kir, Kir-Por, Por-Kir) with 5 seeds each. Expect ~4 BLEU on domain-general test.
  2. **Target-domain augmentation**: Add 300 then 600 dictionary sentences to Bible+WT, oversampling 5x. Expect BLEU increase of 4-7 points.
  3. **Tokeniser/embedding ablation**: For Por-Kir and Kir-Eng, compare shared vs. separate tokenisers and shared vs. separate embeddings at 10k vocab. Expect shared embeddings to help Por-Kir more than Kir-Eng.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can tokenisation strategies be specifically designed to benefit creole-lexifier translation scenarios by better allocating vocabulary space to morphologically simpler creole languages?
- Basis in paper: [explicit] The authors explicitly state "exploring tokenisation strategies that specifically benefit creole-lexifier translation scenarios" as a future research avenue, noting that current combined tokenisers disadvantage morphologically simpler Kiriol when paired with more complex languages.
- Why unresolved: The paper demonstrates the problem (Kiriol gets less vocabulary space in combined tokenisers) but only tests stemming as a partial solution; no creole-optimised tokenisation methods are proposed or evaluated.
- What evidence would resolve it: Development and evaluation of novel tokenisation approaches (e.g., vocabulary allocation balancing, morphological-aware BPE) showing improved fertility scores and BLEU for creole languages paired with their lexifiers.

### Open Question 2
- Question: How does lexical overlap between creoles and lexifier languages impact attention patterns in transformer models during translation?
- Basis in paper: [explicit] The authors explicitly call for "investigating how lexical overlap impacts other areas of model training outside of tokenisation and learning the embedding space; for example, by exploring patterns in attention mapping over input sentences."
- Why unresolved: The paper establishes that lexical overlap affects tokenisation and embedding performance but does not examine internal model mechanisms like attention distributions.
- What evidence would resolve it: Attention visualization and analysis comparing Kiriol-Portuguese vs. Kiriol-English models, correlating attention patterns with translation quality and lexical overlap regions.

### Open Question 3
- Question: How well do findings about shared embeddings and lexical overlap benefits generalise to other creole-lexifier language pairs beyond Kiriol-Portuguese?
- Basis in paper: [explicit] The authors state in their limitations: "our investigations explore how the characteristics and relatedness of Kiriol and Portuguese impacts MT model training and performance, but these findings may not generalise to different creole-lexifier pairs."
- Why unresolved: Results are specific to one creole language and its lexifier; the degree to which morphological and lexical relationships transfer to other creoles (e.g., Haitian-French, Jamaican-English) is unknown.
- What evidence would resolve it: Replication of the tokenisation and shared embedding experiments across multiple diverse creole-lexifier pairs with varying degrees of lexical overlap and morphological complexity.

### Open Question 4
- Question: Do improvements in BLEU scores from adding small amounts of target-domain data correspond to meaningful improvements in human-perceived translation quality at low performance levels?
- Basis in paper: [inferred] The human validation experiment showed minimal differences between models with and without target-domain data despite substantial BLEU improvements, and the authors note "the quality of translations produced by models both with and without small amounts of target-domain data is still too low to show meaningful improvements in a human judgement task."
- Why unresolved: The disconnect between BLEU gains (4.23 to 11.9) and human ratings suggests low BLEU scores may not correlate with perceptible quality improvements, but the study had limited human evaluation scope.
- What evidence would resolve it: Large-scale human evaluation studies across models with varying low BLEU scores, using multiple evaluation metrics and tasks to establish correlation thresholds.

## Limitations

- **Dataset accessibility**: The primary dataset is not publicly available and requires license agreement with the lead author, making independent verification difficult.
- **Generalizability of domain transfer**: Findings may not generalize to other domain pairs or low-resource languages with different characteristics.
- **Human evaluation reliability**: Translation quality remains low despite BLEU improvements, suggesting automated metrics may not capture practical usability.

## Confidence

- **High confidence**: The core finding that small amounts of target-domain data improve domain transfer performance is well-supported by experimental results and aligns with established domain adaptation principles in MT.
- **Medium confidence**: The mechanisms explaining why Portuguese-Kiriol pairs benefit more from shared embeddings (lexical overlap) and why separate tokenisers help morphologically simple languages are plausible but rely on indirect evidence and assumptions about tokenisation efficiency.
- **Low confidence**: The human evaluation findings and their implications for practical translation quality are concerning but under-specified, making it difficult to assess the real-world utility of the models beyond BLEU scores.

## Next Checks

1. **Reproduce tokenisation efficiency findings**: Train separate and combined BPE tokenisers on Kiriol-English and Kiriol-Portuguese data with controlled vocabulary sizes, then measure fertility (tokens per word) for each language to verify the morphological complexity hypothesis.
2. **Test domain transfer generalizability**: Apply the same 300-600 sentence target-domain augmentation strategy to a different low-resource language pair with different domain gaps (e.g., religious-to-medical or religious-to-technical) to assess whether the magnitude of improvement generalizes.
3. **Validate human evaluation methodology**: Request the human evaluation rubric and sample translations from the authors, then conduct an independent human evaluation on the same test set to verify the low quality assessment and understand what aspects of translation quality remain problematic despite BLEU improvements.