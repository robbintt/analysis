---
ver: rpa2
title: 'Higher-Order Feature Attribution: Bridging Statistics, Explainable AI, and
  Topological Signal Processing'
arxiv_id: '2510.06165'
source_url: https://arxiv.org/abs/2510.06165
tags:
- attributions
- feature
- attribution
- order
- signal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a theory of higher-order feature attribution
  by composing Integrated Gradients operators. The approach extends beyond first-order
  attributions to capture feature interactions, with theoretical connections to statistics
  and topological signal processing.
---

# Higher-Order Feature Attribution: Bridging Statistics, Explainable AI, and Topological Signal Processing

## Quick Facts
- arXiv ID: 2510.06165
- Source URL: https://arxiv.org/abs/2510.06165
- Reference count: 0
- Key outcome: Introduces higher-order feature attribution by composing Integrated Gradients operators, capturing feature interactions and connecting to statistics and topological signal processing

## Executive Summary
This paper introduces a theory of higher-order feature attribution by composing Integrated Gradients operators to capture feature interactions beyond first-order attributions. The framework extends Integrated Gradients to higher orders through operator composition, providing a principled algebraic foundation for multi-order explanations. Higher-order attributions are naturally represented as graph signals or simplicial complex structures, establishing connections to topological signal processing. Experiments validate the method's ability to recover ground-truth interaction structures in synthetic data and reveal joint feature contributions in real-world real estate valuation data, generalizing Integrated Hessians and providing a unifying perspective across statistics, XAI, and topological methods.

## Method Summary
The approach computes higher-order feature attributions by composing Integrated Gradients operators, extending beyond first-order attributions to capture feature interactions. The method represents higher-order attributions as graph signals where node attributes capture first-order effects and edge weights capture pairwise interactions. For second-order attributions, the framework uses either Hessian-based formulas or direct operator composition. The approach is validated on synthetic data with known ground-truth interaction structures (a function combining multiplicative and additive terms) and real estate valuation data using a GLM with quadratic inputs. The marginalization property ensures that summing second-order attributions over features recovers first-order attributions, providing a consistency check.

## Key Results
- Higher-order attributions successfully recover ground-truth interaction structures in synthetic experiments with 8 features
- Second-order attributions reveal joint feature contributions in real estate data beyond what first-order attributions capture
- The framework naturally represents attributions as graph signals and simplicial complexes, bridging to topological signal processing
- Marginalization property (summing second-order over features recovers first-order) is numerically verified

## Why This Works (Mechanism)
The approach works by leveraging the compositional structure of Integrated Gradients, where higher-order attributions emerge from repeated application of the first-order operator. This algebraic structure allows systematic extension to arbitrary orders while maintaining theoretical properties like completeness and marginalization. The connection to topological signal processing emerges naturally because higher-order attributions inherently capture interactions that can be represented as edges (pairwise) or simplices (higher-order) in geometric structures.

## Foundational Learning
- Integrated Gradients composition: Higher-order attributions arise from repeated application of IG operators; needed to understand how first-order explanations can be systematically extended
- Marginalization property: Summing second-order attributions over features recovers first-order attributions; needed to verify consistency across attribution orders
- Topological representation: Attributions as graph signals or simplicial complexes; needed to bridge XAI with topological data analysis
- Attribution operator algebra: AᵢAⱼf(x) notation for composition; needed to formalize higher-order computation
- Quick check: Verify Σⱼaᵢⱼ ≈ aᵢ for second-order attributions on synthetic data

## Architecture Onboarding
- Component map: Data → Model → First-order IG → Second-order (Hessian/composition) → Topological representation
- Critical path: Model fitting → First-order attribution computation → Higher-order attribution composition → Visualization/interpretation
- Design tradeoffs: Operator composition vs. direct Hessian computation (accuracy vs. implementation complexity)
- Failure signatures: Marginalization property violation indicates numerical issues; poor interaction recovery suggests model underfitting
- First experiments: 1) Verify IG implementation matches known results on simple functions; 2) Check marginalization property numerically; 3) Compare second-order methods (Hessian vs. composition) on synthetic data

## Open Questions the Paper Calls Out
- Can operator theories analogous to the IG-based framework be developed for other feature attribution methods such as Shapley values or LIME?
- What are the relative advantages and disadvantages of different topological representations for visualizing higher-order attributions?
- How does computational cost scale with feature dimensionality and model complexity?
- How sensitive are higher-order attributions to baseline reference point choice?

## Limitations
- Limited to differentiable models where Integrated Gradients is well-defined, potentially excluding tree-based methods
- Real estate experiment uses GLM with quadratic features rather than truly black-box models
- Topological signal processing connections are conceptual rather than empirically validated in experiments
- Computational complexity grows combinatorially with feature dimensionality for higher orders

## Confidence
- High confidence in mathematical framework and algebraic properties
- Medium confidence in synthetic experiment results given controlled conditions and clear ground truth
- Medium confidence in real estate experiment interpretation due to GLM assumptions

## Next Checks
1. Test framework on non-smooth models (e.g., random forests) to assess differentiability requirements
2. Implement alternative baseline points to evaluate baseline sensitivity of higher-order attributions
3. Validate topological signal processing claims by computing persistence diagrams from attribution complexes on real data