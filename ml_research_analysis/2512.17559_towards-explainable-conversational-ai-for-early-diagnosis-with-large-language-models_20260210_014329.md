---
ver: rpa2
title: Towards Explainable Conversational AI for Early Diagnosis with Large Language
  Models
arxiv_id: '2512.17559'
source_url: https://arxiv.org/abs/2512.17559
tags:
- system
- diagnostic
- symptoms
- accuracy
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses limitations in current AI diagnostic systems
  by introducing an explainable conversational diagnostic chatbot powered by GPT-4o,
  Retrieval-Augmented Generation (RAG), and Chain-of-Thought prompting. The system
  dynamically extracts and normalizes patient symptoms, prioritizes diagnoses through
  similarity matching, and adapts follow-up questions based on symptom context.
---

# Towards Explainable Conversational AI for Early Diagnosis with Large Language Models

## Quick Facts
- **arXiv ID:** 2512.17559
- **Source URL:** https://arxiv.org/abs/2512.17559
- **Reference count:** 8
- **Primary result:** LLM-based diagnostic chatbot achieves 90% Top-1 and 100% Top-3 accuracy

## Executive Summary
This paper addresses limitations in current AI diagnostic systems by introducing an explainable conversational diagnostic chatbot powered by GPT-4o, Retrieval-Augmented Generation (RAG), and Chain-of-Thought prompting. The system dynamically extracts and normalizes patient symptoms, prioritizes diagnoses through similarity matching, and adapts follow-up questions based on symptom context. Evaluation against traditional ML models (Naive Bayes, Logistic Regression, SVM, Random Forest, KNN) demonstrated superior performance, with the LLM-based system achieving 90% Top-1 accuracy and 100% Top-3 accuracy. These results indicate the model's ability to reliably present the correct diagnosis within the top three predictions, offering a promising outlook for more transparent, interactive, and clinically relevant AI in healthcare.

## Method Summary
The proposed system integrates GPT-4o with RAG and Chain-of-Thought prompting to create an explainable conversational diagnostic chatbot. The architecture dynamically extracts and normalizes patient symptoms, uses similarity matching to prioritize potential diagnoses, and adapts follow-up questions based on symptom context. The system was evaluated against traditional ML models including Naive Bayes, Logistic Regression, SVM, Random Forest, and KNN, demonstrating superior performance metrics. The explainable nature of the system allows for transparency in the diagnostic reasoning process, addressing a key limitation of traditional black-box AI diagnostic tools.

## Key Results
- Achieved 90% Top-1 accuracy in diagnosis prediction
- Achieved 100% Top-3 accuracy in diagnosis prediction
- Outperformed traditional ML models (Naive Bayes, Logistic Regression, SVM, Random Forest, KNN)

## Why This Works (Mechanism)
The system leverages GPT-4o's natural language understanding capabilities combined with RAG for accessing relevant medical knowledge, while Chain-of-Thought prompting enables transparent reasoning. The dynamic symptom extraction and normalization process allows the system to handle varied patient expressions of symptoms, while the adaptive questioning mechanism ensures comprehensive symptom coverage. The similarity matching approach effectively prioritizes the most likely diagnoses based on the patient's reported symptoms, making the diagnostic process both accurate and interpretable.

## Foundational Learning

### RAG (Retrieval-Augmented Generation)
- **Why needed:** To access and incorporate relevant medical knowledge beyond the model's training data
- **Quick check:** Can the system retrieve and use external medical information during conversations?

### Chain-of-Thought Prompting
- **Why needed:** To make the reasoning process transparent and traceable
- **Quick check:** Does the system provide step-by-step explanations for its diagnostic conclusions?

### Dynamic Symptom Normalization
- **Why needed:** To handle varied patient expressions and synonyms for medical symptoms
- **Quick check:** Can the system recognize "stomach ache" and "abdominal pain" as equivalent symptoms?

## Architecture Onboarding

### Component Map
Patient Input -> Symptom Extraction & Normalization -> Knowledge Retrieval (RAG) -> Diagnostic Reasoning (CoT) -> Diagnosis & Explanation -> Adaptive Follow-up Questions

### Critical Path
The critical path for diagnosis involves symptom extraction and normalization, followed by knowledge retrieval through RAG, diagnostic reasoning via Chain-of-Thought, and final diagnosis generation with explanations.

### Design Tradeoffs
- **LLM choice (GPT-4o):** High performance but expensive and potentially less accessible than smaller models
- **RAG integration:** Improves accuracy but adds complexity and latency
- **Explainability focus:** Enhances trust but may reduce conversational naturalness

### Failure Signatures
- Symptom normalization failures when patients use highly colloquial language
- Knowledge retrieval gaps when RAG fails to find relevant medical information
- Over-reliance on symptom patterns that may not account for rare conditions

### First 3 Experiments to Run
1. Test system accuracy across different patient communication styles (formal vs. informal)
2. Evaluate explanation quality through healthcare professional review
3. Measure response time impact of RAG integration on conversational flow

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Evaluation based on traditional ML models rather than existing conversational diagnostic systems
- No assessment of performance across diverse demographic groups or cultural contexts
- Reliance on GPT-4o raises concerns about cost and accessibility in clinical settings

## Confidence

| Claim | Confidence |
|-------|------------|
| Technical performance metrics (accuracy) | High |
| System architecture effectiveness | High |
| Clinical utility and explainability | Medium |
| Generalizability across populations | Low |

## Next Checks
1. Conduct comparative evaluation against existing commercial conversational diagnostic tools to establish relative performance and practical advantages.
2. Perform user study with healthcare professionals to assess quality, clarity, and clinical utility of generated explanations.
3. Test system's robustness across diverse patient populations, including different languages, cultural contexts, and socioeconomic backgrounds to identify potential bias or performance gaps.