---
ver: rpa2
title: 'Translation via Annotation: A Computational Study of Translating Classical
  Chinese into Japanese'
arxiv_id: '2511.05239'
source_url: https://arxiv.org/abs/2511.05239
tags:
- chinese
- characters
- classical
- japanese
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a computational approach to translating Classical
  Chinese into Japanese using a modern NLP framework. It models the traditional Kundoku
  annotation system as sequence tagging tasks, where Kaeriten marks dictate character
  reordering and Okurigana marks add grammatical information.
---

# Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese

## Quick Facts
- arXiv ID: 2511.05239
- Source URL: https://arxiv.org/abs/2511.05239
- Reference count: 32
- Primary result: Novel computational approach for translating Classical Chinese to Japanese using Kundoku annotation system as sequence tagging tasks

## Executive Summary
This paper presents a computational framework for translating Classical Chinese into Japanese by modeling the traditional Kundoku annotation system as sequence tagging tasks. The approach addresses the low-resource challenge of classical text translation by constructing a new dataset from digitized open-source translations and introducing an LLM-based annotation pipeline validated by pushdown automata. The method demonstrates comparable machine translation performance to existing models while outperforming large language models on character ordering accuracy, particularly for the complex Kaeriten marks that dictate character reordering.

## Method Summary
The proposed method models the Kundoku annotation system as sequence tagging tasks where Kaeriten marks indicate character reordering and Okurigana marks add grammatical information. To address the low-resource nature of classical text translation, the authors construct a new dataset from digitized open-source translations and introduce an LLM-based annotation pipeline. The pipeline is validated using a pushdown automaton that ensures annotation correctness. The framework incorporates auxiliary Chinese NLP tasks to enhance model performance, with the authors finding that two auxiliary tasks provide optimal results. The approach is evaluated against both traditional machine translation models and large language models, demonstrating particular strength in handling the complex character reordering required by Kaeriten marks.

## Key Results
- The method achieves comparable machine translation performance to existing models while outperforming LLMs on character ordering accuracy
- Incorporating two auxiliary Chinese NLP tasks provides optimal performance enhancement
- The LLM-based annotation pipeline validated by pushdown automata produces accurate Kundoku annotations, particularly excelling at Kaeriten marks where LLMs typically struggle
- The approach serves as a valuable supplement to LLMs for generating accurate Kundoku annotations

## Why This Works (Mechanism)
The method works by breaking down the complex task of classical text translation into manageable sequence tagging components that mirror the traditional Kundoku annotation process. By treating character reordering (Kaeriten) and grammatical addition (Okurigana) as distinct tagging tasks, the model can learn specialized patterns for each annotation type. The pushdown automaton validation ensures structural correctness of annotations before they are used in translation, creating a reliable pipeline even with limited training data. The incorporation of auxiliary Chinese NLP tasks provides additional linguistic context that helps the model better understand classical Chinese syntax and semantics, leading to more accurate Japanese translations.

## Foundational Learning

**Kundoku Annotation System**: Traditional method of reading Chinese texts in Japanese by adding diacritical marks and grammatical elements. Why needed: Understanding this system is crucial as it forms the basis of the computational approach. Quick check: Verify that the model correctly handles both Kaeriten (reordering marks) and Okurigana (grammatical marks) as separate annotation types.

**Pushdown Automata**: Computational models that use a stack to recognize context-free languages and nested structures. Why needed: Used to validate the structural correctness of Kundoku annotations. Quick check: Ensure the automaton correctly validates nested and sequential annotation patterns.

**Sequence Tagging**: NLP task of assigning labels to individual elements in a sequence. Why needed: The core mechanism for modeling Kundoku annotations computationally. Quick check: Confirm that the tagging accuracy for each annotation type (Kaeriten and Okurigana) is above acceptable thresholds.

## Architecture Onboarding

**Component Map**: Classical Chinese text -> Kundoku Annotation Pipeline (LLM + Pushdown Validator) -> Sequence Tagging Model (with Auxiliary Tasks) -> Japanese Translation

**Critical Path**: The most critical path is from Kundoku Annotation Pipeline through Sequence Tagging Model to final translation, as errors in annotation directly impact translation quality, particularly for character ordering.

**Design Tradeoffs**: The approach trades the complexity of end-to-end neural translation for a more interpretable, rule-validated pipeline. This sacrifices some potential performance gains from end-to-end learning but provides better control over the complex reordering process and enables validation of intermediate steps.

**Failure Signatures**: Poor performance on texts with complex nested structures or rare annotation patterns, degradation when auxiliary tasks are not well-aligned with the source text characteristics, and potential overfitting to the specific dataset construction method.

**First Experiments**:
1. Validate pushdown automaton correctness on a diverse set of Kundoku annotations from different classical texts
2. Test sequence tagging performance on held-out annotation types not seen during training
3. Evaluate translation quality on a blind test set with varying levels of structural complexity

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Dataset construction relies on digitized open-source translations, potentially introducing selection bias and limiting representation of diverse Classical Chinese styles
- Focus on sentence-level translation without addressing discourse-level phenomena or contextual dependencies across longer passages
- Performance comparisons against LLMs use specific evaluation metrics that may not capture all aspects of translation quality relevant to classical text interpretation

## Confidence

**High confidence**: Technical feasibility of modeling Kundoku as sequence tagging tasks, and demonstration that auxiliary Chinese NLP tasks improve performance

**Medium confidence**: Comparative performance against LLMs, particularly the claim of superior character ordering accuracy

**Medium confidence**: Effectiveness of LLM-based annotation pipeline validated by pushdown automata

## Next Checks
1. Conduct a human evaluation study with classical Japanese scholars to assess semantic fidelity and readability of translated texts, particularly focusing on nuanced cases where LLMs showed lower character ordering accuracy
2. Test the model's performance on Classical Chinese texts from different historical periods and literary genres to evaluate generalization beyond the current dataset
3. Implement a cross-validation study varying the number of auxiliary tasks (beyond the two-task optimum) to determine whether the claimed optimal point is robust across different experimental conditions