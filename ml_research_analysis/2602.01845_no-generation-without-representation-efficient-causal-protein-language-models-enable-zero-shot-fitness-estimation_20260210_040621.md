---
ver: rpa2
title: 'No Generation without Representation: Efficient Causal Protein Language Models
  Enable Zero-Shot Fitness Estimation'
arxiv_id: '2602.01845'
source_url: https://arxiv.org/abs/2602.01845
tags:
- proust
- protein
- language
- https
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Proust is a 309M-parameter causal protein language model that achieves
  masked language model (MLM) level performance on protein fitness prediction while
  retaining generation capabilities. It uses architectural innovations adapted from
  large language models, including grouped-query attention with shared K/V projections,
  cross-layer value residuals, and depthwise causal convolutions.
---

# No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation

## Quick Facts
- **arXiv ID:** 2602.01845
- **Source URL:** https://arxiv.org/abs/2602.01845
- **Reference count:** 40
- **Primary result:** Causal protein language model achieves MLM-level fitness prediction with 50-200× less compute

## Executive Summary
Proust is a 309M-parameter causal protein language model that achieves masked language model (MLM) level performance on protein fitness prediction while retaining generation capabilities. It uses architectural innovations adapted from large language models, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman ρ=0.390 on ProteinGym substitutions, competitive with MLMs requiring 50–200× more compute, and sets state-of-the-art performance on indels. It also approaches structure-aware methods on viral fitness benchmarks using sequence alone. Interpretability analysis reveals that per-position entropy variance predicts when retrieval augmentation helps, offering guidance for test-time compute allocation. Code and weights are publicly available.

## Method Summary
Proust uses a 309M-parameter causal architecture with 24 layers, 1024 hidden size, and GQA-S2 attention (16 query heads, 2 KV heads with shared projections). Key innovations include depthwise causal convolutions (Canon layers) at three positions per layer, cross-layer value residuals from layer 0, and key offset for induction heads. The model uses Muon optimizer with Newton-Schulz orthogonalization for attention/FFN (LR 0.015) and AdamW for embeddings (LR 4.5e-4). Training runs for 62,474 steps on 33B tokens from UniRef50 and specialty databases, achieving 10.85 validation perplexity. The 21-token vocabulary (20 amino acids + EOS) supports sequences up to 16,384 aa.

## Key Results
- Achieves Spearman ρ=0.390 on ProteinGym substitutions, competitive with MLMs requiring 50–200× more compute
- Sets state-of-the-art performance on indels (ρ=0.521) among causal models
- Approaches structure-aware methods on viral fitness benchmarks using sequence alone
- Entropy variance predicts retrieval augmentation utility (ρ=−0.40 correlation)

## Why This Works (Mechanism)

### Mechanism 1: GQA-S2 Attention with Shared K/V Projections
Sharing K and V projection weights reduces KV cache while maintaining representational capacity by reallocating parameters to larger head dimensions. A single linear projection produces both K and V, with head dimension splitting into 96 NoPE (content-matching) and 32 RoPE (position-matching) dimensions. RoPE applied to both K and V creates absolute position encoding, which VO-RoPE converts back to relative position encoding. This design assumes content and position matching are separable operations that interfere when mixed in all dimensions.

### Mechanism 2: Canon Layers for Local Pattern Recognition
Depthwise causal convolutions enable single-layer motif recognition that would otherwise require two attention layers. Canon layers add 1D convolutions (kernel size 4) at three positions—before attention (Canon-A), before FFN (Canon-C), and within FFN after up-projection (Canon-D). Combined with key offset (shifting NoPE keys forward by one position), queries at position t can match bigram patterns in a single layer. This assumes local dependencies (e.g., Gly-X-Y collagen repeats, CxxC zinc fingers) are more efficiently captured via convolution than through multi-layer attention constructions.

### Mechanism 3: Entropy Variance as Retrieval Need Predictor
The standard deviation of per-position logit lens entropy predicts whether retrieval augmentation will improve or harm predictions. Low entropy variance (uniform uncertainty across positions) indicates the model lacks confident predictions anywhere—external homologs help. High entropy variance (concentrated uncertainty) indicates the model already knows which positions matter—retrieval may overwrite correct predictions. This assumes entropy distribution reflects model calibration about which positions carry functional signal.

## Foundational Learning

- **Concept: Masked vs. Causal Language Modeling Objectives**
  - Why needed: Proust's core claim is that causal models can match masked model fitness prediction; understanding this distinction is essential to evaluate what's being claimed.
  - Quick check: Can you explain why MLMs require L forward passes to score a length-L sequence, while CLMs require only one?

- **Concept: KV Cache and Memory Scaling in Attention**
  - Why needed: GQA-S2's design rationale depends on understanding how standard attention memory scales with sequence length and head count.
  - Quick check: Given 16 query heads and 2 KV heads, what fraction of KV cache memory does Proust use compared to standard multi-head attention with 16 heads?

- **Concept: Logit Lens Interpretability**
  - Why needed: The entropy-based retrieval prediction mechanism depends on projecting intermediate hidden states through the output head.
  - Quick check: What does the U-shaped prediction accuracy curve across layers suggest about where contextual features vs. final predictions are computed?

## Architecture Onboarding

- **Component map:** Input → Embedding → [Canon-A → Attention with Value Residuals → Canon-C → FFN (with Canon-D)] × 24 layers → Output Head

- **Critical path:** Token embedding → RMSNorm → first residual stream → per-layer: Canon-A convolution → attention (with value residual from layer 0, key offset) → Canon-C → FFN with Canon-D → unembedding to 21 vocab tokens

- **Design tradeoffs:** Canon layers improve motif recognition but reduced MFU from 29% to 19% (naive implementation; fused kernels could recover this); shared K/V projections increase head dimension but couple position and content representations; causal objective enables generation but each position only sees leftward context

- **Failure signatures:** Training instability (check Muon learning rate and sandwich normalization scaling); poor indel performance (verify autoregressive scoring); low attention to distant positions (may indicate over-regularizing Canon layers)

- **First 3 experiments:** 1) Ablate Canon layers to measure impact on ProteinGym indels and MFU; 2) Validate entropy-retrieval correlation on held-out assays; 3) Scale test with 50M proxy to verify learning rate transfer via Muon's spectral scaling

## Open Questions the Paper Calls Out

- **Open Question 1:** Will scaling Proust to 1–3B parameters close the performance gap with MLMs on stability assays while maintaining the FLOP advantage?
- **Open Question 2:** What is the optimal warmup schedule for the Muon optimizer with Newton-Schulz orthogonalization in protein language models?
- **Open Question 3:** Does pretraining Proust on concatenated homolog sequences improve retrieval-augmented fitness prediction?

## Limitations

- The 40 B200 GPU-hour training budget may not fully explore the architectural design space before optimization
- The entropy-retrieval correlation (ρ=−0.40) is statistically significant but moderate, suggesting the retrieval gating heuristic will misclassify non-trivial fractions of cases
- The 16,384 max length limitation may bias fitness prediction for longer proteins

## Confidence

- **High confidence:** Causal protein LMs achieve MLM-level fitness prediction on ProteinGym substitutions; GQA-S2 with shared K/V reduces KV cache proportionally to head count reduction; value residuals improve early-layer attention; autoregressive scoring enables zero-shot indel prediction
- **Medium confidence:** Entropy variance predicts retrieval augmentation utility; Canon layers enable efficient local motif recognition; Proust approaches structure-aware methods on viral fitness; training efficiency gains are real but require fused kernel optimization
- **Low confidence:** The entropy-retrieval correlation generalizes beyond tested assays; Canon layers' MFU reduction is acceptable for production use; the 16,384 max length limitation doesn't bias fitness prediction; the 21-token vocabulary captures all necessary sequence variation

## Next Checks

1. **Ablation study of architectural innovations:** Train Proust variants without Canon layers, without shared K/V projections, and without value residuals on ProteinGym. Measure performance deltas and MFU changes to isolate which mechanisms drive the 0.390 substitution performance.

2. **Entropy-retrieval correlation validation:** On held-out viral fitness assays, compute per-position entropy standard deviation and measure retrieval augmentation delta. Verify the ρ=−0.40 correlation holds and test whether the entropy threshold (0.1) optimally separates "retrieval helps" from "retrieval hurts" cases.

3. **Generalization stress test:** Evaluate Proust on protein fitness landscapes not represented in the training corpus (e.g., thermostability, solubility, or pH tolerance) to determine whether causal modeling advantages extend beyond the ProteinGym distribution.