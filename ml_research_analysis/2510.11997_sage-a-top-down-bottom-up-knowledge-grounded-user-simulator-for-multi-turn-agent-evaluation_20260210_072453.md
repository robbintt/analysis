---
ver: rpa2
title: 'SAGE: A Top-Down Bottom-Up Knowledge-Grounded User Simulator for Multi-turn
  AGent Evaluation'
arxiv_id: '2510.11997'
source_url: https://arxiv.org/abs/2510.11997
tags:
- agent
- user
- knowledge
- evaluation
- product
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SAGE is a knowledge-grounded user simulation framework for multi-turn
  agent evaluation. It combines top-down principles (e.g., ideal customer profiles)
  with bottom-up knowledge (e.g., product catalogs, FAQs) to generate realistic user
  interactions.
---

# SAGE: A Top-Down Bottom-Up Knowledge-Grounded User Simulator for Multi-turn AGent Evaluation

## Quick Facts
- arXiv ID: 2510.11997
- Source URL: https://arxiv.org/abs/2510.11997
- Authors: Ryan Shea; Yunan Lu; Liang Qiu; Zhou Yu
- Reference count: 40
- Primary result: Combines top-down principles with bottom-up knowledge to generate more diverse, human-like interactions and identify 25-33% more agent errors than existing methods

## Executive Summary
SAGE is a knowledge-grounded user simulation framework designed for multi-turn agent evaluation. It integrates top-down principles such as ideal customer profiles with bottom-up knowledge from product catalogs and FAQs to generate realistic user interactions. The framework demonstrates significant improvements in lexical diversity, simulator fidelity, and error identification rates while maintaining robustness across different LLMs. By effectively uncovering both retrieval and response quality issues in agents, SAGE provides a comprehensive approach to evaluating and improving conversational AI systems.

## Method Summary
SAGE operates as a dual-layer simulation framework that combines structured top-down principles with unstructured bottom-up knowledge sources. The system first defines user personas and interaction goals using ideal customer profiles, then grounds these interactions in real-world knowledge from product catalogs, FAQs, and similar resources. During simulation, SAGE generates multi-turn dialogues by balancing user intent with available knowledge, creating more authentic and diverse interactions. The framework employs a hybrid approach where top-down constraints guide the overall interaction structure while bottom-up knowledge provides specific content and responses, resulting in simulations that better reflect real-world user behavior patterns.

## Key Results
- Identifies 25-33% more agent errors compared to existing simulation methods
- Demonstrates improved lexical diversity in generated interactions
- Shows robustness across multiple different LLM configurations
- Effectively uncovers both retrieval and response quality issues in agents

## Why This Works (Mechanism)
SAGE works by bridging the gap between idealized user models and real-world knowledge constraints. The top-down layer provides structural guidance and user intent modeling through ideal customer profiles, ensuring interactions follow logical patterns and goals. The bottom-up layer grounds these interactions in actual domain knowledge, making responses contextually relevant and realistic. This dual approach creates a more authentic simulation environment where agents must handle both the complexity of user behavior and the specificity of domain knowledge, leading to more comprehensive evaluation of agent capabilities.

## Foundational Learning
- Knowledge-grounded dialogue generation: Why needed - to create realistic interactions; Quick check - verify knowledge sources are comprehensive and up-to-date
- Multi-turn user simulation: Why needed - to evaluate long-term agent performance; Quick check - ensure dialogue coherence across multiple turns
- Error identification in conversational agents: Why needed - to improve agent reliability; Quick check - validate error categories are comprehensive
- LLM-based simulation: Why needed - for scalable and flexible simulation; Quick check - test across multiple model configurations
- Top-down user modeling: Why needed - to maintain interaction structure; Quick check - verify persona consistency
- Bottom-up knowledge integration: Why needed - to ensure content relevance; Quick check - validate knowledge source coverage

## Architecture Onboarding

Component map: User Persona Definition -> Knowledge Base Integration -> Dialogue Generation -> Error Analysis -> Feedback Loop

Critical path: The system begins with defining user personas and interaction goals, then integrates these with domain-specific knowledge sources. Dialogue generation combines these elements to produce realistic multi-turn interactions, which are then analyzed for agent errors. The feedback loop allows for iterative refinement of both user models and knowledge bases.

Design tradeoffs: The framework balances between the structure provided by top-down principles and the flexibility offered by bottom-up knowledge. This tradeoff allows for both consistency in user behavior patterns and adaptability to specific domain contexts. The reliance on external knowledge sources introduces dependency on data quality but enables more realistic interactions.

Failure signatures: Common failures include knowledge base incompleteness leading to unrealistic responses, persona definition mismatches causing incoherent interactions, and LLM limitations affecting dialogue quality. The system may also struggle with rapidly changing knowledge domains or highly specialized technical content.

First experiments:
1. Test dialogue generation with a simple product catalog and basic customer profile
2. Evaluate error identification rates using a controlled set of known agent failures
3. Measure lexical diversity improvements compared to baseline simulation methods

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy reliance on accuracy and completeness of external knowledge sources
- Focus primarily on task-oriented dialogues, limiting applicability to open-ended conversations
- Error identification improvements need independent verification across different agent types
- Lexical diversity metrics may not fully capture semantic quality and coherence

## Confidence
High: The core framework combining top-down principles with bottom-up knowledge for user simulation is technically sound and well-documented. The methodology for knowledge-grounded response generation is clearly articulated.

Medium: The quantitative improvements in error identification and lexical diversity are supported by experiments, but the real-world applicability and generalizability across different domains need further validation.

Low: The long-term effectiveness of the framework in dynamic environments where knowledge sources frequently change, and its ability to simulate complex user behaviors beyond simple task completion scenarios.

## Next Checks
1. Conduct cross-domain evaluation of SAGE across at least three different industries (e.g., retail, healthcare, banking) to assess generalizability
2. Implement A/B testing with human evaluators to compare agent performance when trained with and without SAGE-generated data
3. Test framework robustness by simulating scenarios with incomplete or outdated knowledge sources to evaluate degradation in simulation quality