---
ver: rpa2
title: 'HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological
  Evolution'
arxiv_id: '2509.00189'
source_url: https://arxiv.org/abs/2509.00189
tags:
- agent
- feedback
- task
- tool
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HiVA introduces a novel multi-agent framework that evolves both
  agent semantics and collaboration topology from a singleton, enabling adaptive intelligence
  in complex tasks. By unifying Semantic-Topological Evolution (STEV) with textual
  gradients as discrete-domain surrogates for backpropagation, HiVA jointly optimizes
  agent behaviors and their interaction structures through a dynamic computational
  graph.
---

# HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological Evolution

## Quick Facts
- arXiv ID: 2509.00189
- Source URL: https://arxiv.org/abs/2509.00189
- Reference count: 38
- Key outcome: 5-10% accuracy improvements over state-of-the-art baselines across mathematical, long-context, programmatic, and textual reasoning tasks

## Executive Summary
HiVA introduces a novel multi-agent framework that evolves both agent semantics and collaboration topology from a singleton, enabling adaptive intelligence in complex tasks. By unifying Semantic-Topological Evolution (STEV) with textual gradients as discrete-domain surrogates for backpropagation, HiVA jointly optimizes agent behaviors and their interaction structures through a dynamic computational graph. Experiments across mathematical, long-context, programmatic, and textual reasoning tasks demonstrate improvements of 5-10% in accuracy over state-of-the-art baselines, with enhanced resource efficiency in agentic environments. Qualitative analyses and ablation studies confirm the necessity of co-evolving semantics and topology for optimal performance. HiVA establishes a scalable, self-organizing approach to multi-agent coordination, offering a foundation for future advances in autonomous task execution.

## Method Summary
HiVA employs a self-organizing multi-agent system that co-evolves agent semantics (prompts, tools) and collaboration topology from a singleton agent using textual gradients as surrogate gradients for backpropagation in discrete agent graphs. The framework operates through a KABB routing mechanism with Thompson Sampling to construct task-specific subgraphs, followed by a coordinated update loop that applies forward instruction generation, backward feedback parsing, and semantic/topological evolution. The system processes diverse benchmarks including MATH, GSM-8K, HotpotQA, HumanEval, MMLU, BBH, and GAIA, with 10 optimization iterations per task using Qwen-2.5-72B-Instruct-Turbo backbone and temperature-controlled inference.

## Key Results
- Achieves 5-10% accuracy improvements over state-of-the-art baselines across multiple benchmark tasks
- Demonstrates enhanced resource efficiency with optimized agent count and tool usage in GAIA evaluation
- Shows superior performance in complex reasoning tasks including mathematical problem-solving, long-context processing, and programmatic generation

## Why This Works (Mechanism)
HiVA's effectiveness stems from its unified approach to semantic and topological evolution, allowing agents to adapt both their internal capabilities and external collaboration patterns simultaneously. The use of textual gradients as surrogate backpropagation enables discrete agent graphs to learn from environmental feedback, while the KABB routing mechanism ensures efficient task decomposition through Thompson Sampling-based knowledge aggregation. This co-evolutionary process creates emergent agent specializations that are dynamically optimized for specific task requirements, leading to improved accuracy and efficiency compared to static multi-agent architectures.

## Foundational Learning
- **Textual Gradient Generation**: Converts raw environment feedback into structured update commands for agent evolution; needed because discrete agent graphs lack native gradient propagation, quick check: verify gradient parser produces consistent updates across similar failure patterns
- **Thompson Sampling in KABB**: Balances exploration and exploitation in agent routing decisions; required for efficient knowledge aggregation in dynamic agent networks, quick check: monitor routing entropy over optimization iterations
- **Knowledge Graph Construction**: Represents agent capabilities and task requirements as interconnected nodes with weighted edges; essential for semantic-topological distance calculations, quick check: validate graph connectivity after each STEV iteration

## Architecture Onboarding
- **Component Map**: Singleton Agent -> KABB Router -> Forward Pass (Task Execution) -> Backward Pass (Gradient Generation) -> Coordinated Update (Semantic + Topological Evolution) -> Repair Topology
- **Critical Path**: Forward execution through KABB-selected subgraph → Aggregator output → Environment feedback → Textual gradient generation → Semantic/topological updates → Topology repair
- **Design Tradeoffs**: Dynamic agent creation vs. computational overhead; sparse routing vs. potential information loss; textual gradients vs. precision of numerical gradients
- **Failure Signatures**: Aggregator deadlock on conflicting parallel outputs; local optimum trapping from ambiguous textual gradients; excessive API costs from degraded routing
- **First Experiments**: 1) Test textual gradient parser on MATH problem failures, 2) Benchmark KABB routing efficiency with varying Thompson Sampling parameters, 3) Measure topology evolution stability across 10 STEV iterations

## Open Questions the Paper Calls Out
None

## Limitations
- Heavy dependence on textual gradients introduces uncertainty about gradient quality and propagation efficiency
- Limited ablation studies and absence of head-to-head comparisons with recent multi-agent architectures
- Proprietary cost-efficiency scoring requires independent validation

## Confidence
- **High Confidence**: Core STEV algorithm architecture and theoretical foundation in combining semantic evolution with topological restructuring
- **Medium Confidence**: Reported accuracy improvements across benchmark tasks, methodology reproducible but depends on unspecified implementation details
- **Low Confidence**: Cost-efficiency claims for GAIA, particularly the Cost × 100/Accuracy metric, require independent validation

## Next Checks
1. Implement complete TGP templates and validate on MATH subset, comparing generated gradients against expected semantic/topological changes
2. Create standardized knowledge graph construction pipeline using public benchmarks, measure ωk weight optimization impact on STEV performance
3. Independently measure API costs and execution times for HiVA vs. baselines on GAIA tasks, verify Cost × 100/Accuracy metric accuracy