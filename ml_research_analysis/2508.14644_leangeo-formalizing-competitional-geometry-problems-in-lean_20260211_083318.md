---
ver: rpa2
title: 'LeanGeo: Formalizing Competitional Geometry problems in Lean'
arxiv_id: '2508.14644'
source_url: https://arxiv.org/abs/2508.14644
tags:
- euclid
- apply
- theorem
- have
- proof
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce LeanGeo, a formal geometry system within
  Lean 4 that bridges competition-level geometric reasoning with broader mathematical
  domains. LeanGeo provides a comprehensive theorem library covering foundational
  to IMO-level geometry, enabling rigorous proof verification and seamless integration
  with Mathlib.
---

# LeanGeo: Formalizing Competitional Geometry problems in Lean

## Quick Facts
- arXiv ID: 2508.14644
- Source URL: https://arxiv.org/abs/2508.14644
- Reference count: 40
- Primary result: Introduces LeanGeo, a Lean 4 formal geometry system with 260 theorems and a 122-problem benchmark, evaluating LLMs on competition-level geometry proofs.

## Executive Summary
LeanGeo bridges competition-level geometric reasoning with broader mathematical domains by providing a comprehensive theorem library and benchmark within Lean 4. The system covers foundational to IMO-level geometry, enabling rigorous proof verification and seamless integration with Mathlib. Evaluations on state-of-the-art LLMs reveal partial success with low success rates, highlighting limitations in handling complex geometric proofs. Initial reinforcement learning experiments using synthetic data and targeted theorem prompting show improved performance, demonstrating LeanGeo's potential for advancing automated geometry theorem proving.

## Method Summary
LeanGeo formalizes competition-level geometry problems in Lean 4, providing a theorem library of 260 theorems and a benchmark (LeanGeo-Bench) of 122 problems from various sources. Synthetic training data is generated using Gemini 2.5 Pro, with SFT on correct proofs followed by RL on invalid-proof prompts using the Kimi k1.5 pipeline. The instilling method involves prompting with 10 randomly sampled theorems to improve proof generation.

## Key Results
- LeanGeo-Bench contains 122 problems across multiple competition levels
- Synthetic data generation yields 89% syntactically valid statements and 14% fully verified proofs
- RL training with instilling improves success rates on LeanGeo-Bench
- State-of-the-art LLMs show partial success with low pass@k rates on complex geometric proofs

## Why This Works (Mechanism)
LeanGeo leverages Lean 4's formal verification capabilities and Mathlib integration to create a rigorous environment for geometry theorem proving. The system's strength lies in its comprehensive theorem library and benchmark, which provide a standardized evaluation framework. The RL approach with synthetic data and instilling prompts enables iterative improvement in proof generation, addressing the complexity of competition-level geometry problems.

## Foundational Learning

**Lean 4 Theorem Proving**
*Why needed:* Provides the formal verification framework for geometry proofs
*Quick check:* Verify Lean 4 installation and basic theorem proving functionality

**Synthetic Data Generation**
*Why needed:* Creates training data for RL when real competition data is limited
*Quick check:* Generate sample synthetic theorem-proof pairs and verify syntax

**Reinforcement Learning for Proof Generation**
*Why needed:* Enables iterative improvement in proof generation through feedback
*Quick check:* Implement simple RL loop with synthetic data and evaluate performance

## Architecture Onboarding

**Component Map:** Gemini 2.5 Pro -> Synthetic Data Generator -> Lean Compiler -> RL Pipeline (Kimi k1.5) -> LeanGeo-Bench Evaluator

**Critical Path:** Synthetic data generation → SFT training → RL instilling → LeanGeo-Bench evaluation

**Design Tradeoffs:** Comprehensive theorem library vs. computational overhead; synthetic data volume vs. verification quality; instilling prompt complexity vs. generalization

**Failure Signatures:** LeanSMT proof reconstruction failures; CVC5 solver timeouts; low synthetic data verification rates; poor RL performance on complex problems

**First Experiments:**
1. Verify LeanSMT integration by running esmt on cached axiom proofs
2. Generate pilot synthetic dataset and measure verification rates
3. Conduct small-scale RL experiment with placeholder hyperparameters

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- RL hyperparameters and prompt templates are not fully specified, affecting reproducibility
- LeanSMT integration may fail on complex proofs, limiting training data quality
- CVC5 solver scalability issues on point-heavy problems may cause timeouts
- Moderate citation overlap with related work suggests potential gaps in benchmarking

## Confidence
**High confidence:** Methodology and benchmark structure are clearly described and reproducible
**Medium confidence:** Synthetic data generation success rates may vary with different LLMs
**Low confidence:** Exact RL hyperparameters and prompt templates are missing

## Next Checks
1. Verify LeanSMT integration by running esmt on cached axiom proofs and identifying failure patterns
2. Generate pilot synthetic dataset using Gemini 2.5 Pro and measure verification rates
3. Conduct small-scale RL experiment with placeholder hyperparameters to establish baseline performance