---
ver: rpa2
title: Experience-based Knowledge Correction for Robust Planning in Minecraft
arxiv_id: '2505.24157'
source_url: https://arxiv.org/abs/2505.24157
tags:
- item
- items
- iron
- xenon
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'XENON is an LLM-based agent that robustly learns planning knowledge
  from experience in Minecraft by algorithmically correcting flawed priors rather
  than relying on LLM self-correction. It combines two mechanisms: Adaptive Dependency
  Graph, which revises item dependencies using successful experiences, and Failure-aware
  Action Memory, which corrects action knowledge using failures.'
---

# Experience-based Knowledge Correction for Robust Planning in Minecraft

## Quick Facts
- arXiv ID: 2505.24157
- Source URL: https://arxiv.org/abs/2505.24157
- Reference count: 40
- Primary result: XENON achieves up to 0.74 success rate on Minecraft benchmarks using a 7B open-weight LLM, surpassing agents using larger proprietary models like GPT-4

## Executive Summary
XENON is an LLM-based agent that robustly learns planning knowledge from experience in Minecraft by algorithmically correcting flawed priors rather than relying on LLM self-correction. It addresses the challenge of learning complex item dependencies and action knowledge from limited guidance by combining two mechanisms: Adaptive Dependency Graph for revising item dependencies using successful experiences, and Failure-aware Action Memory for correcting action knowledge using failures. This approach enables XENON to disambiguate failure causes and acquire complex dependencies despite limited guidance, significantly outperforming prior agents in both knowledge learning and long-horizon planning across multiple Minecraft benchmarks.

## Method Summary
XENON employs a dual-mechanism approach to experience-based knowledge correction. The Adaptive Dependency Graph learns item dependencies through successful experiences, using an experience graph to store failed experiences and guide dependency revisions. The Failure-aware Action Memory corrects action knowledge by analyzing failures and updating knowledge accordingly. These mechanisms work together to enable the agent to learn from both successes and failures, disambiguate causes of failure, and acquire complex dependencies without requiring extensive human guidance or large proprietary models.

## Key Results
- Achieves up to 0.74 success rate on diverse Minecraft goals
- Significantly outperforms prior agents in knowledge learning and long-horizon planning
- Surpasses agents using much larger proprietary models like GPT-4 while using only a 7B open-weight LLM

## Why This Works (Mechanism)
The approach works by systematically correcting flawed priors through algorithmic mechanisms rather than relying on LLM self-correction capabilities. By explicitly learning from both successful and failed experiences, the system can disambiguate failure causes and acquire complex dependencies that would be difficult to learn through traditional reinforcement learning or direct LLM prompting alone.

## Foundational Learning

**Item Dependency Learning** - Why needed: Minecraft requires understanding complex item relationships (e.g., crafting recipes). Quick check: Can the agent correctly identify prerequisite items for complex crafting tasks?

**Failure Analysis** - Why needed: Disambiguating why plans fail is crucial for robust planning. Quick check: Does the agent correctly identify whether failures are due to missing items, incorrect actions, or plan structure?

**Experience Graph Construction** - Why needed: Organizing experiences to guide future learning. Quick check: Can the system efficiently retrieve relevant past experiences when encountering similar situations?

## Architecture Onboarding

**Component Map:** LLM Planner -> Adaptive Dependency Graph -> Action Selector -> Environment -> Experience Store

**Critical Path:** The system follows this sequence: 1) LLM generates plan, 2) Adaptive Dependency Graph validates and corrects item dependencies, 3) Action Memory verifies and corrects actions, 4) Agent executes in environment, 5) Experience is stored and used to update knowledge bases.

**Design Tradeoffs:** The system trades computational overhead for more robust planning through explicit knowledge correction rather than relying solely on LLM capabilities. This adds complexity but enables better generalization from limited experiences.

**Failure Signatures:** Common failures include: 1) Incorrect item dependencies due to incomplete experience, 2) Action sequence errors from insufficient knowledge, 3) Plan structure issues from flawed planning assumptions.

**First Experiments:** 1) Test knowledge correction on simple crafting tasks with known dependencies, 2) Evaluate failure disambiguation on tasks with multiple potential failure points, 3) Assess learning from mixed success/failure trajectories on complex multi-step goals.

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses exclusively on Minecraft environments, raising questions about generalization to other domains
- Does not provide systematic ablation studies isolating individual contributions of the two main components
- Knowledge acquisition process depends on successful experiences but doesn't clearly address how the system handles catastrophic failures or learning stalls

## Confidence

**Major Uncertainties and Limitations**
The paper presents a novel approach to experience-based knowledge correction in Minecraft, but several limitations affect confidence in the results. The evaluation focuses exclusively on Minecraft environments, raising questions about generalization to other domains. The study does not provide systematic ablation studies isolating the individual contributions of the Adaptive Dependency Graph and Failure-aware Action Memory components. Additionally, the knowledge acquisition process appears to depend on successful experiences, but the paper does not clearly address how the system handles catastrophic failures or when learning might stall.

**Confidence Labels for Major Claims**
*High Confidence:* The core mechanism of algorithmically correcting flawed priors through experience is well-supported by the experimental results, particularly the consistent improvement over baseline approaches in the Minecraft benchmarks.

*Medium Confidence:* Claims about XENON's ability to disambiguate failure causes and acquire complex dependencies are supported by results but lack detailed analysis of failure modes and edge cases that would strengthen these conclusions.

*Low Confidence:* The assertion that XENON "surpasses agents using much larger proprietary models" is based on limited comparison points and does not account for potential differences in training resources, fine-tuning approaches, or access to external tools.

## Next Checks
1. Conduct systematic ablation studies to quantify the individual contributions of Adaptive Dependency Graph and Failure-aware Action Memory components to overall performance.

2. Test XENON's generalization capabilities on non-Minecraft domains or environments with different action spaces and dependency structures to assess transferability.

3. Perform extensive failure mode analysis to understand how the system handles edge cases, catastrophic failures, and situations where learning might plateau or become stuck.