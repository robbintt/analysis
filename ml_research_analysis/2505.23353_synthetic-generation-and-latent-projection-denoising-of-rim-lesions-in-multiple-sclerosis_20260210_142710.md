---
ver: rpa2
title: Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple
  Sclerosis
arxiv_id: '2505.23353'
source_url: https://arxiv.org/abs/2505.23353
tags:
- lesions
- lesion
- synthetic
- data
- united
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the class imbalance problem in detecting paramagnetic
  rim lesions in multiple sclerosis by developing a synthetic data generation framework.
  The authors propose using a generative adversarial network (StyleGAN2-ADA) to synthesize
  quantitative susceptibility maps of rim lesions and introduce a novel latent projection
  denoising approach to transform ambiguous lesions into unambiguous training samples.
---

# Synthetic Generation and Latent Projection Denoising of Rim Lesions in Multiple Sclerosis

## Quick Facts
- arXiv ID: 2505.23353
- Source URL: https://arxiv.org/abs/2505.23353
- Reference count: 40
- This study addresses class imbalance in detecting paramagnetic rim lesions in multiple sclerosis by developing a synthetic data generation framework that increases the minority class by 68% through denoising and achieves improved classifier performance with accuracy of 0.87, precision of 0.91, and sensitivity of 0.95.

## Executive Summary
This study addresses the critical challenge of detecting paramagnetic rim lesions (PRLs) in multiple sclerosis, which are rare but diagnostically significant structures visible only in quantitative susceptibility mapping (QSM). The authors propose a novel framework combining synthetic data generation with a "latent projection denoising" approach to overcome severe class imbalance. By training a StyleGAN2-ADA model exclusively on unambiguous rim lesions and projecting ambiguous cases into this learned latent space, they create high-quality synthetic training data that substantially improves classifier performance. The method also extends to generating multi-contrast maps including T2FLAIR and segmentation masks, demonstrating both technical innovation and clinical utility.

## Method Summary
The framework consists of three main components: synthetic data generation, latent projection denoising, and multi-contrast generation. First, StyleGAN2-ADA is trained on 200 unambiguous rim lesions to create a generator capable of producing synthetic QSM patches. Second, ambiguous lesions (where raters disagree) are projected into the generator's latent space using perceptual loss optimization, creating "denoised" versions that resolve visual uncertainty. Finally, a conditional extension generates correlated T2FLAIR and segmentation masks alongside QSM. The augmented dataset (real + synthetic + denoised) is used to train a 6-layer CNN classifier, achieving significant performance improvements over traditional augmentation methods like SMOTE and affine transformations.

## Key Results
- Classifier performance with synthetic data: Accuracy 0.87, Precision 0.91, Sensitivity 0.95
- Class augmentation: Denoising increased minority class by 68% through converting ambiguous to unambiguous training samples
- Synthetic quality: FID of 34.0 achieved with 25,000 synthetic rim lesions generated from 200 training samples
- Multi-contrast generation: Successfully synthesized QSM, T2FLAIR, and probabilistic segmentation masks that correctly identify paramagnetic rims

## Why This Works (Mechanism)

### Mechanism 1
Training a generative model exclusively on unambiguous minority class samples creates a structured latent manifold that prioritizes task-relevant features over noise. By restricting the training pool of StyleGAN2-ADA to "rim" lesions where two experts agree, the generator learns to map latent vectors to images containing specific biological signatures of paramagnetic rims (e.g., hypointense cores). When the manifold is well-formed, random sampling yields high-fidelity synthetic samples that expand the minority class without duplicating exact training instances.

### Mechanism 2
Latent projection transforms ambiguous or "noisy" labeled samples into unambiguous training data by forcing their feature representation onto the learned "clean" manifold. An ambiguous lesion image is inverted into the latent space of the generator trained on clean data. By optimizing for perceptual similarity while constraining the solution to the generator's weights, the system finds the closest "clean" latent vector. When decoded, this vector produces a denoised image that retains the structural anatomy of the original but resolves ambiguous features to match the manifold's logic.

### Mechanism 3
Multi-contrast generation leverages the high SNR of susceptibility maps (QSM) to synthesize correlated lower-contrast modalities (T2FLAIR), improving segmentation utility. The generator learns the joint probability distribution of QSM, T2FLAIR, and segmentation masks. Because QSM provides the unique contrast for the paramagnetic rim, generating this channel first anchors the spatial features. The network then hallucinates the corresponding T2FLAIR appearance and probabilistic mask based on learned biological priors of how iron rims appear in different sequences.

## Foundational Learning

- **Concept:** Quantitative Susceptibility Mapping (QSM) vs. Standard MRI
  - **Why needed here:** Unlike T1/T2, QSM is the only modality that visualizes the paramagnetic iron rim. Without understanding this, the motivation for a specialized GAN is lost.
  - **Quick check question:** Why would a standard T2FLAIR-trained model fail to detect rim lesions?

- **Concept:** Class Imbalance & ADA (Adaptive Discriminator Augmentation)
  - **Why needed here:** Rim lesions are rare (3-10%). Standard GANs overfit instantly on small datasets; understanding ADA is crucial to grasp how the authors stabilized training with only ~200 real samples.
  - **Quick check question:** What happens to a standard GAN discriminator if trained on a tiny dataset without adaptive augmentation?

- **Concept:** GAN Inversion (Latent Projection)
  - **Why needed here:** The core innovation (denoising) relies on mapping a real image back into the generator's latent space. You must understand this is an optimization process, not a direct feedforward pass.
  - **Quick check question:** How does the network find the latent vector for a specific real lesion image?

## Architecture Onboarding

- **Component map:** StyleGAN2-ADA Generator -> Latent Projection Optimizer -> Decoder -> Synthetic/Denoised Lesions -> 6-Layer CNN Classifier
- **Critical path:**
  1. Data Prep: Curate "Unambiguous" vs. "Ambiguous" sets based on rater agreement
  2. Manifold Creation: Train StyleGAN2-ADA on "Unambiguous" rims only
  3. Denoising: Project "Ambiguous" rims → Latent W → Decode to "Denoised" rims
  4. Augmentation: Mix Real + Synthetic + Denoised rims
  5. Detection: Train final classifier on the augmented set
- **Design tradeoffs:**
  - *Curated vs. Raw Training:* Training the GAN only on agreed-upon (unambiguous) rims improves synthesis quality but reduces the initial training pool size
  - *Real vs. Synthetic Ratio:* The paper notes that optimal rebalancing fractions are an open question; adding too much synthetic data risks distribution drift
- **Failure signatures:**
  - **Hyperintense Hallucinations:** Generator creating rims where no structure exists (checked via radiologist review)
  - **Over-smoothing:** The denoising projection removing the lesion rim entirely if the "ambiguous" input is too dissimilar to the manifold
  - **High FID:** If FID does not drop, the synthetic data is statistically unrealistic and will likely degrade classifier performance
- **First 3 experiments:**
  1. **Manifold Validation:** Train ADA-GAN on unambiguous rims and compute FID against a held-out test set to ensure the synthetic distribution matches reality (Target: FID ~34 as per Table 2)
  2. **Projection Sanity Check:** Take a known "unambiguous" rim, add artificial noise/degradation, and attempt to recover it via latent projection. Visually confirm if the rim is restored
  3. **Ablation on Denoising:** Train three classifiers: (A) Real only, (B) Real + Standard Synthetic, (C) Real + Denoised Ambiguous. Compare sensitivity to verify that "Denoised" samples provide superior signal for the minority class

## Open Questions the Paper Calls Out

- **Optimal ratio of synthetic to real training data:** The authors state in Section 5.2 that "Future investigation may focus on the optimal fraction of synthetic training data for the rim lesion detection problem." The current study only evaluated performance using a fixed augmentation of 100 synthetic lesions, leaving the optimal balance between real and synthetic data undetermined.

- **Latent projection into conditional latent space:** Section 5.1 notes that "Future investigation may focus on latent projection denoising into the conditional latent space, which demonstrated improved convergence during training." While the conditional model achieved a lower FID, the denoising experiments were conducted exclusively using the unconditional generator.

- **Generalization to 3D and longitudinal data:** The authors suggest in Section 5.4 that "future work should focus on addressing the need for additional training data required for such applications" regarding higher dimensions. The current implementation operates on 2D slices, whereas clinical diagnosis often requires full 3D volumetric context.

## Limitations

- The central innovation—using latent projection to "denoise" ambiguous labels—relies heavily on the assumption that label ambiguity stems from visual uncertainty rather than fundamental disagreement about pathology, with no quantitative validation that projected samples are indeed closer to the "true" pathology.

- The classifier architecture is underspecified, making it difficult to assess whether performance gains are due to the augmentation strategy or architectural advantages.

- The framework's effectiveness depends on the quality and diversity of the unambiguous training set; if this set contains label errors or insufficient biological diversity, the generator will output unvaried or hallucinated features.

## Confidence

- **High Confidence:** The GAN synthesis pipeline (StyleGAN2-ADA training on unambiguous rims) and associated FID metrics are well-documented and reproducible
- **Medium Confidence:** The denoising mechanism via latent projection is theoretically sound, but lacks quantitative validation that it actually resolves label ambiguity rather than introducing artifacts
- **Low Confidence:** The classifier architecture details are insufficient for faithful reproduction, creating uncertainty about whether the reported performance improvements are robust across implementations

## Next Checks

1. **Label Consistency Validation:** Conduct a radiologist study comparing original ambiguous lesions to their denoised projections to verify that projection resolves, rather than obscures, the pathology.

2. **Ablation on Architecture:** Implement the 6-layer CNN classifier from scratch with full architectural specifications and verify that the reported performance (0.87 accuracy, 0.91 precision, 0.95 sensitivity) is reproducible.

3. **Distribution Drift Analysis:** Generate synthetic samples and compute both FID and KL divergence against the real distribution to quantify potential mode collapse or hallucination that could degrade classifier performance over time.