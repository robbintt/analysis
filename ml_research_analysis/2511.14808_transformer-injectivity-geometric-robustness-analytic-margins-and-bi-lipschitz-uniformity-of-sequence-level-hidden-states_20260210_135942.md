---
ver: rpa2
title: Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz
  Uniformity of Sequence-Level Hidden States
arxiv_id: '2511.14808'
source_url: https://arxiv.org/abs/2511.14808
tags:
- arxiv
- injective
- prompt
- injectivity
- co-lipschitz
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We study injectivity and geometric robustness of last-token hidden
  states in decoder-only Transformers. Under real-analytic assumptions, we prove that
  last-token maps are generically injective on finite prompt sets, with a collision
  discriminant and open dense injective stratum at each layer.
---

# Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States

## Quick Facts
- arXiv ID: 2511.14808
- Source URL: https://arxiv.org/abs/2511.14808
- Authors: Mikael von Strauss
- Reference count: 11
- Primary result: Decoder-only Transformers are generically injective on finite prompt sets under real-analytic assumptions, with empirical geometric robustness measurable via layerwise separation margins and co-Lipschitz constants.

## Executive Summary
This paper establishes theoretical foundations for injectivity of last-token hidden states in decoder-only Transformers and provides empirical diagnostics for geometric robustness. Under real-analytic assumptions, the parameter space contains a collision discriminant of measure zero, making injectivity generic. The paper introduces layerwise separation margins and co-Lipschitz constants estimated from nearest-neighbor statistics on large prompt sets, showing that pretrained LLaMA-3 and Qwen models exhibit no exact collisions in 8-bit quantization while 4-bit quantization induces small numbers of collisions concentrated in deeper layers.

## Method Summary
The method involves extracting last-token hidden states from pretrained decoder-only Transformers across all layers for a large prompt corpus (10^5 texts from IMDB reviews and C4 subset, tokenized with truncation at 1024 tokens). Layerwise diagnostics are computed including worst-percentile (q=1%) nearest-neighbor separation margins, co-Lipschitz constants as worst-percentile ratios of representation distance to Hamming distance, and normalized versions by mean norm. Uniform per-layer activation quantization at 8-bit and 4-bit is applied using max-range scaling. For training dynamics, a small GPT-2 model is trained from scratch and metrics are tracked at checkpoints. Uncertainty is estimated via 200 bootstrap resamples.

## Key Results
- Theoretical proof that decoder-only Transformers are generically injective on finite prompt sets with open dense injective stratum at each layer
- Empirical demonstration of no exact collisions in 8-bit quantization across LLaMA-3 and Qwen models, with 4-bit quantization inducing collisions concentrated in deeper layers
- Layerwise metrics remain stable across layers and model scales, though worst-percentile co-Lipschitz constants shrink with longer contexts and under aggressive quantization
- Training trajectory on small GPT-2 shows stable metrics along optimization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Under real-analytic assumptions, decoder-only Transformers are generically injective on finite prompt sets.
- Mechanism: The parameter space contains a collision discriminant Δ^ℓ (union of analytic zero-sets where distinct prompts collide). Since real-analytic functions either vanish identically or have zero-sets of measure zero, Δ^ℓ has Lebesgue measure zero. The complement U^ℓ = Θ \ Δ^ℓ is open and dense, meaning almost all parameter configurations yield injective maps.
- Core assumption: Architecture components (activations, LayerNorm, softmax, attention) are real-analytic or piecewise real-analytic in parameters.
- Evidence anchors:
  - [abstract]: "for each layer ℓ we define a collision discriminant Δ^ℓ ⊂ Θ and injective stratum U^ℓ = Θ \ Δ^ℓ, and prove a dichotomy—either the model is nowhere injective on the set, or U^ℓ is open and dense"
  - [section 2.1, Definition 2.5-2.6]: Formal construction of discriminant and stratum
  - [corpus]: Nikolaou et al. (2025) "Language Models are Injective and Hence Invertible" establishes the base result this paper extends
- Break condition: If architecture uses non-analytic operations (hard thresholding, discrete routing) that violate real-analytic assumptions, the measure-zero argument fails.

### Mechanism 2
- Claim: Generic injectivity persists along smooth training trajectories with probability one.
- Mechanism: If initialization θ₀ has an absolutely continuous distribution and optimizer updates are non-singular (preimages of null sets are null), then θ_t remains absolutely continuous for all finite t. Since discriminants have measure zero, P(θ_t ∈ Δ^ℓ) = 0 at each step.
- Core assumption: Optimizer is smooth GD/SGD/Adam without hard projections, clipping, or quantization of parameters.
- Evidence anchors:
  - [abstract]: "Under mild non-singularity assumptions on the optimizer and an absolutely continuous initialization, generic injectivity persists along smooth training trajectories"
  - [section 2.4, Theorem 2.13]: Formal persistence theorem with proof
  - [corpus]: No directly comparable persistence results in neighbor corpus; this is a novel contribution
- Break condition: Aggressive gradient clipping, weight quantization, or projection steps destroy non-singularity guarantees.

### Mechanism 3
- Claim: The robust injectivity radius equals half the separation margin; quantization induces collisions when perturbation exceeds this threshold.
- Mechanism: For finite prompt set S with margin m(F) = min_{s≠s̃} ||F(s) - F(s̃)||, any r-perturbation with r < m(F)/2 preserves injectivity. Uniform quantization with step δ moves representations by at most √d·δ/2, so collision onset occurs near δ ≈ m(F)/√d.
- Core assumption: Prompt set is finite; margin can be accurately estimated from samples.
- Evidence anchors:
  - [section 2.3, Theorem 2.11]: "rinj(F) = ½m(F)"
  - [section 3.4.4]: "4-bit quantization induces a small number of collisions concentrated in deeper layers"
  - [corpus]: Corpus lacks comparable quantization-margin analysis for Transformers
- Break condition: Margin estimates from finite samples may not reflect true margin on full prompt space; empirical thresholds are approximate.

## Foundational Learning

- Concept: **Real-analytic functions**
  - Why needed here: The core injectivity proof relies on the property that real-analytic functions either vanish identically or have zero-sets of measure zero. Without this, the "measure-zero discriminant" argument collapses.
  - Quick check question: Can you explain why ReLU (piecewise linear) requires a different treatment than GELU (analytic) for these proofs?

- Concept: **Absolute continuity of measures**
  - Why needed here: The persistence theorem requires that parameter distributions remain absolutely continuous through training. This connects optimization dynamics to measure-theoretic guarantees.
  - Quick check question: Why does absolute continuity matter for proving P(θ_t ∈ Δ^ℓ) = 0?

- Concept: **Co-Lipschitz (lower Lipschitz) constants**
  - Why needed here: These quantify how much representations contract relative to input changes. The metric α̂ measures minimum movement per Hamming distance unit, capturing worst-case "distance to collision."
  - Quick check question: If α̂ = 0.001 and two prompts differ by 5 tokens, what's the minimum representation distance?

## Architecture Onboarding

- Component map:
  - Prompt → Tokenizer → Forward pass → Extract last-token hidden state at layer ℓ → Compute pairwise distances → Estimate margin (nearest-neighbor) and co-Lipschitz (pair ratios) → Track across layers/quantization/training

- Critical path: Prompt → Tokenizer → Forward pass → Extract last-token hidden state at layer ℓ → Compute pairwise distances → Estimate margin (nearest-neighbor) and co-Lipschitz (pair ratios) → Track across layers/quantization/training

- Design tradeoffs:
  - Raw vs normalized metrics: Raw captures robustness to fixed-scale noise; normalized reveals intrinsic geometry
  - Percentile choice: Lower q (1%) catches hardest pairs but noisier; higher q more stable but misses edge cases
  - Quantization bitwidth: 8-bit preserves injectivity empirically; 4-bit induces collisions in deeper layers

- Failure signatures:
  - Exact collisions (bitwise identical representations) indicate injectivity violation
  - Near-collision rates spike in deeper layers under 4-bit quantization
  - Co-Lipschitz constants shrink with longer contexts and aggressive quantization

- First 3 experiments:
  1. **Layerwise margin profiling**: Run forward pass on 10K diverse prompts; extract hidden states at all layers; compute 1% worst-percentile nearest-neighbor margins and normalized versions. Expect: raw margins grow with depth (norm inflation), normalized remain roughly flat.
  2. **Quantization stress test**: Apply uniform 4-bit and 8-bit activation quantization per-layer; count exact collisions and compare to theoretical threshold δ < m(F)/√d. Expect: 8-bit collision-free; 4-bit collisions concentrated in final third of layers.
  3. **Context length sweep**: Fix model, vary prompt length K ∈ {32, 64, 128, 256, 512}; track last-layer co-Lipschitz estimates. Expect: longer contexts → smaller worst-percentile co-Lipschitz (more contractive regime).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the quantitative relationship between separation margins/co-Lipschitz constants and the empirical success rate of supervised inversion attacks or privacy extraction methods?
- Basis in paper: [explicit] "Establishing quantitative links between these diagnostics and the empirical performance of supervised inverters or privacy attacks is an interesting direction for future work."
- Why unresolved: The paper establishes geometric diagnostics as preconditions for invertibility but does not validate whether they predict actual attack success.
- What evidence would resolve it: Correlations between margin/co-Lipschitz estimates and reconstruction accuracy across multiple inversion methods on the same model/prompt distribution.

### Open Question 2
- Question: Does generic injectivity persist when training involves non-smooth operations such as gradient clipping, weight projections, or low-precision quantized updates?
- Basis in paper: [explicit] "When aggressive clipping, projection steps, or discrete quantization are used inside the optimizer, the persistence guarantee may fail, and understanding injectivity in those regimes remains an open problem."
- Why unresolved: The persistence theorem assumes smooth, non-singular updates; practical training often violates these assumptions.
- What evidence would resolve it: Empirical tracking of collision rates and margins along training trajectories with mixed-precision or clipped gradients.

### Open Question 3
- Question: Can the analytic injectivity framework be extended to ReLU-based architectures using o-minimal or piecewise-polynomial analysis?
- Basis in paper: [explicit] "For piecewise-polynomial choices such as ReLU, an analogous treatment can be obtained in the framework of definable sets in an o-minimal structure, but we do not develop that extension here."
- Why unresolved: Real-analytic assumptions exclude ReLU, yet many deployed models use ReLU/SwiGLU.
- What evidence would resolve it: Formal proof of generic injectivity for ReLU transformers, or counterexamples showing systematic collisions.

### Open Question 4
- Question: How do alternative input geometries (e.g., learned embedding distances) compare to Hamming distance in capturing meaningful co-Lipschitz behavior?
- Basis in paper: [explicit] "Exploring such alternative input metrics is an interesting direction for future work."
- Why unresolved: Hamming distance is natural for injectivity on discrete tokens but may not reflect semantic similarity.
- What evidence would resolve it: Comparative analysis of co-Lipschitz constants under embedding-based metrics vs. Hamming distance on controlled semantic perturbations.

## Limitations

- Analytic assumption fragility: The core measure-zero discriminant argument hinges on all architectural components being real-analytic in parameters, which is assumed but not explicitly verified for each component.
- Training trajectory persistence: The proof assumes smooth, non-singular optimizer dynamics, but modern training uses mixed-precision arithmetic and gradient clipping that may violate these assumptions.
- Empirical margin estimation: Worst-percentile margins computed from finite prompt sets are subject to sampling uncertainty, particularly for tail percentiles (q=1%).

## Confidence

**High confidence**: Layerwise margin and co-Lipschitz trends (stable normalized metrics, deeper-layer concentration of 4-bit collisions), absence of collisions in 8-bit quantization across multiple models.

**Medium confidence**: Quantitative claims about exact collision counts and margin magnitudes, persistence of injectivity along training trajectories, theoretical framework applicability to modern Transformer variants.

**Low confidence**: Absolute thresholds for practical injectivity (e.g., specific 4-bit collision counts), extrapolation of small-model training dynamics to large-scale training, robustness to architectural modifications.

## Next Checks

1. **Analytic component verification**: Systematically verify real-analyticity of all Transformer components (attention, MLP, normalization) across the full parameter space. Identify and characterize any non-analytic operations that could invalidate the discriminant measure-zero argument.

2. **Numerical training artifact analysis**: Extend training trajectory experiments to multiple model scales with controlled variations in optimization (different learning rate schedules, precision settings, gradient clipping). Compare empirical injectivity persistence against theoretical guarantees under different numerical regimes.

3. **Margin estimation uncertainty quantification**: Implement rigorous bootstrap uncertainty estimates for worst-percentile margins. Compare empirical margins against theoretical lower bounds derived from prompt set properties (diameter, distribution). Test sensitivity to prompt set size and diversity.