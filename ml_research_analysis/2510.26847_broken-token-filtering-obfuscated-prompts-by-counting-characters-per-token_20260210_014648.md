---
ver: rpa2
title: 'Broken-Token: Filtering Obfuscated Prompts by Counting Characters-Per-Token'
arxiv_id: '2510.26847'
source_url: https://arxiv.org/abs/2510.26847
tags:
- prompt
- text
- prompts
- dataset
- obfuscated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CPT-Filtering, a model-agnostic, computationally
  negligible guardrail technique for detecting obfuscated jailbreak prompts by measuring
  characters-per-token (CPT) in Byte-Pair Encoded text. The core idea exploits the
  observation that out-of-distribution encodings use significantly more, shorter tokens
  than natural language, making them detectable via a simple CPT threshold.
---

# Broken-Token: Filtering Obfuscated Prompts by Counting Characters-Per-Token
## Quick Facts
- arXiv ID: 2510.26847
- Source URL: https://arxiv.org/abs/2510.26847
- Reference count: 40
- Primary result: Near-perfect detection (>99.4% F1) of obfuscated jailbreak prompts using characters-per-token (CPT) thresholds

## Executive Summary
This paper introduces CPT-Filtering, a simple yet highly effective guardrail technique for detecting obfuscated jailbreak prompts in LLMs. The method exploits the observation that obfuscation schemes like Base64, Binary, Caesar Cipher, Leetspeak, and Reversed Text produce significantly more, shorter tokens compared to natural language text. By computing characters-per-token (CPT) and comparing against tokenizer-specific thresholds, CPT-Filtering achieves near-perfect accuracy while being computationally negligible—ideal for real-time inference and data curation.

## Method Summary
CPT-Filtering computes the ratio of total characters to token count (CPT) for a given prompt using various tokenizers (Qwen-3, GPT-4o, Llama-3.2, Gemma-3). The core insight is that obfuscated text, due to its encoding schemes, uses many more short tokens than natural language, creating a clear statistical separation. Optimal CPT thresholds are determined per tokenizer via precision-recall curve optimization. The method also handles mixed inputs using a sliding window approach and distinguishes obfuscated text from non-alphanumeric languages by employing monolingual tokenizers.

## Key Results
- CPT-Filtering achieves >99.4% F1-score in detecting obfuscated prompts across five encoding schemes
- Works effectively even for short prompts (~3 tokens)
- Outperforms perplexity-based methods in both accuracy and computational cost
- Successfully distinguishes obfuscated text from non-alphanumeric languages using monolingual tokenizers

## Why This Works (Mechanism)
The method exploits the fundamental difference in how tokenizers handle natural language versus encoded text. Obfuscation schemes break down text into many more, shorter tokens because the encoded characters don't form meaningful word units. This creates a clear statistical separation in CPT values between obfuscated and natural text, making detection possible with simple threshold-based classification.

## Foundational Learning
- **Byte-Pair Encoding (BPE)**: Why needed - Understanding how tokenizers segment text is crucial for grasping why CPT differs between obfuscated and natural text. Quick check - Verify that natural language has lower token counts than obfuscated text for the same character length.
- **Characters-per-Token (CPT) metric**: Why needed - The core detection metric that quantifies the token efficiency difference. Quick check - Compute CPT for sample natural vs. obfuscated text to observe the separation.
- **Sliding window detection**: Why needed - Enables detection of mixed obfuscated/benign text where global CPT might be misleading. Quick check - Apply window-based CPT to a prompt with both clean and obfuscated sections.

## Architecture Onboarding
- **Component map**: Text -> Tokenizer -> Tokenization -> CPT Calculation -> Threshold Comparison -> Detection
- **Critical path**: Input text → Tokenization → CPT computation → Threshold comparison → Binary classification
- **Design tradeoffs**: Simple threshold vs. more complex ML models (simplicity and speed vs. potential edge case handling)
- **Failure signatures**: Short prompts (<3 tokens) produce noisy estimates; non-alphanumeric languages trigger false positives; mixed content may require windowing
- **Three first experiments**: 1) Compute CPT distributions for original vs. obfuscated prompts to verify separation, 2) Determine optimal CPT threshold via precision-recall curves, 3) Apply sliding window to mixed input detection

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation uses in-sample threshold optimization rather than out-of-sample validation, raising overfitting concerns
- Limited to English prompts and five specific obfuscation methods, unclear generalization to other languages or novel encoding schemes
- Sliding window implementation details for mixed inputs lack comprehensive specification

## Confidence
- **High Confidence**: The core observation about CPT distribution separation is well-supported with near-perfect detection accuracy for pure obfuscated text across multiple tokenizers
- **Medium Confidence**: Effectiveness of sliding window detection for mixed inputs and language distinction using monolingual tokenizers is demonstrated but lacks edge case analysis
- **Low Confidence**: Computational efficiency claims relative to perplexity-based methods lack direct empirical validation

## Next Checks
1. Perform k-fold cross-validation on the obfuscation dataset to assess whether CPT thresholds maintain performance when derived from held-out data
2. Apply CPT-Filtering to prompts obfuscated with methods not in the original five (e.g., Base32, custom substitution ciphers) and to non-English languages
3. Conduct controlled runtime experiments comparing CPT-Filtering against perplexity-based detection on identical hardware, measuring inference latency and resource utilization