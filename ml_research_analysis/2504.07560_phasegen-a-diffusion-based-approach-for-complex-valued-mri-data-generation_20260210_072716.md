---
ver: rpa2
title: 'PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data Generation'
arxiv_id: '2504.07560'
source_url: https://arxiv.org/abs/2504.07560
tags:
- data
- phase
- complex-valued
- diffusion
- trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PhaseGen, a novel complex-valued diffusion
  model that generates synthetic MRI raw data (k-Space) conditioned on magnitude images.
  The method addresses the scarcity of complex-valued MRI datasets by leveraging the
  abundant magnitude image data to create artificial phase information, enabling pretraining
  for models requiring k-Space data.
---

# PhaseGen: A Diffusion-Based Approach for Complex-Valued MRI Data Generation

## Quick Facts
- arXiv ID: 2504.07560
- Source URL: https://arxiv.org/abs/2504.07560
- Reference count: 0
- Primary result: Synthetic k-space generation improves skull-stripping from 41.1% to 80.1% Dice Similarity Coefficient

## Executive Summary
PhaseGen introduces a novel approach to address the scarcity of complex-valued MRI datasets by generating synthetic k-space data (raw MRI frequency domain data) conditioned on readily available magnitude images. The method employs a complex-valued diffusion model that directly processes complex numbers, preserving both magnitude and phase information throughout the generation process. This approach enables researchers to leverage vast amounts of magnitude image data to create artificial phase information, significantly improving downstream tasks like skull-stripping and MRI reconstruction. The model is trained on clinical MRI raw data and evaluated on two tasks: skull-stripping in k-Space and MRI reconstruction using the FastMRI dataset, demonstrating substantial performance improvements over magnitude-only baselines.

## Method Summary
PhaseGen is a conditional diffusion model that generates synthetic complex-valued MRI k-Space data by learning to create anatomically plausible phase information from magnitude images. The model employs a complex-valued neural network architecture that processes data directly in the complex domain, preserving the inherent phase-magnitude relationships. During training, the model learns from real k-space data pairs (magnitude and phase), while at inference it generates synthetic k-space by conditioning on new magnitude images and sampling from a complex noise distribution. The diffusion process adds noise primarily to the phase while keeping the magnitude constant through a conditioning channel. The reverse process then learns to denoise, generating synthetic phase consistent with the conditioned magnitude. The generated k-space can be used to pretrain downstream models, which are then fine-tuned on limited real data for improved generalization.

## Key Results
- Skull-stripping Dice Similarity Coefficient improves from 41.1% to 80.1% when using synthetic phase data
- MRI reconstruction quality improves with hybrid training (1-20% real data + synthetic data) achieving comparable performance to models trained on 100% real data
- The model successfully generates anatomically plausible phase patterns that enhance downstream diagnostic tasks
- PhaseGen demonstrates effectiveness across different MRI contrasts (T1-weighted sequences) and field strengths (1.5T and 3T)

## Why This Works (Mechanism)

### Mechanism 1: Conditional Phase Generation via Diffusion
- Claim: A diffusion model can generate anatomically plausible phase information when conditioned on magnitude images, allowing synthetic k-space creation.
- Mechanism: The model performs a forward diffusion process that adds complex-valued noise to the phase while preserving the input magnitude via a separate, constant conditioning channel. The reverse process learns to denoise, generating a synthetic phase consistent with the conditioned magnitude.
- Core assumption: Magnitude and phase in MRI share learnable latent structural dependencies that can be modeled by a neural network.
- Evidence anchors:
  - [abstract] "PhaseGen... generates synthetic MRI raw data (k-Space) conditioned on magnitude images."
  - [section III.C] "With the magnitude already being present in the data, we only want to generate a corresponding phase."
  - [corpus] Weak direct evidence; related corpus papers focus on reconstruction priors, not conditional phase generation.
- Break condition: If the model were given full acquisition parameters (e.g., coil sensitivity maps) as input, the phase generation would be more physically grounded but less generalizable to datasets lacking such metadata.

### Mechanism 2: Complex-Valued Neural Network (CVNN) Processing
- Claim: Processing complex data directly in a CVNN preserves phase-magnitude relationships more effectively than splitting into real/imaginary channels.
- Mechanism: The network's weights and activations are complex numbers, and operations (e.g., convolutions) use complex algebra. This allows the model to operate on the unified complex representation, learning joint features rather than treating phase and magnitude as independent streams.
- Core assumption: Assumption: Phase and magnitude are coupled; a unified complex representation is a more efficient and accurate way for a neural network to model their relationship.
- Evidence anchors:
  - [abstract] "...employs a complex-valued neural network architecture that directly processes complex numbers, preserving both magnitude and phase information throughout the diffusion process."
  - [section III.B] "Complex valued neural networks (CVNNs)... are designed to work with data that has both real and imaginary components... allowing them to capture the phase information inherent in the data."
  - [corpus] Concepts align with corpus papers discussing complex-valued signal processing (e.g., "Holographic Transformers").
- Break condition: If phase and magnitude were truly independent for a given task, a standard real-valued network with two input channels would achieve equivalent performance.

### Mechanism 3: Synthetic Data Pretraining for Real-World Generalization
- Claim: Pretraining on synthetic k-space data generated from abundant magnitude images enables models to generalize to real k-space data, especially when fine-tuned with limited real examples.
- Mechanism: The diffusion model learns a distribution of possible phases for a given magnitude. Pretraining a downstream model on this synthetic distribution allows it to learn robust, transferable features. Fine-tuning on even small amounts of real data then adapts the model to the specific characteristics of real-world acquisition physics.
- Core assumption: Assumption: The synthetic phase distribution learned by the model sufficiently covers the manifold of real phase variations.
- Evidence anchors:
  - [abstract] "...training with synthetic phase data significantly improves generalization for skull-stripping on real-world data... from 41.1% to 80.1%."
  - [section V] "When training with a mix of real and synthetic data, the model achieves performance comparable to one trained entirely on original-phase data while using only 15–20% real data."
  - [corpus] Corpus evidence is weak for this exact transfer learning mechanism.
- Break condition: If the synthetic phase deviates systematically from the physics of real phase (e.g., lacking specific artifacts), pretraining could induce negative transfer.

## Foundational Learning

- **Concept: k-Space and Fourier Transform**
  - Why needed here: The paper operates entirely in the frequency domain (k-space). Understanding that k-space is the Fourier transform of the image and that complex values in k-space encode both magnitude and phase is fundamental.
  - Quick check question: If you take the inverse Fourier transform of a PhaseGen-generated k-space sample, what should you expect to see in the image domain?

- **Concept: Diffusion Models**
  - Why needed here: PhaseGen is a diffusion model. You must grasp the core concept: a forward process that gradually corrupts data with noise, and a reverse process that learns to denoise it step-by-step.
  - Quick check question: In the reverse diffusion process, what does the neural network learn to predict at each timestep?

- **Concept: Complex Numbers in MRI**
  - Why needed here: The central problem is that clinical MRI discards phase. Understanding that phase carries biophysical information (e.g., about susceptibility, motion) explains why generating it synthetically is valuable.
  - Quick check question: Why might a phase image appear to have low-frequency anatomical structure, yet be considered "noise" by a human observer?

## Architecture Onboarding

- **Component map:** Magnitude image + Complex noise → Complex-Valued Residual U-Net → Synthetic complex image → FFT → Synthetic k-Space

- **Critical path:**
  1. Train the diffusion model on real k-space data (pairs of magnitude and phase).
  2. At inference, input a new magnitude image and sample from the complex noise distribution `N_z`.
  3. Run the denoising loop for T steps. In each step, the U-Net predicts the noise, conditioned on the fixed magnitude image.
  4. The final output is a synthetic slice with generated phase. Transform to k-space for downstream use.
  5. Pretrain a downstream model (e.g., for skull-stripping) on this synthetic k-space dataset.
  6. Fine-tune the downstream model on a small amount of real k-space data.

- **Design tradeoffs:**
  - **CVNN vs. Real/Imaginary Split:** Using a CVNN is more principled for complex data but requires custom layers and is harder to debug. Splitting into two channels is simpler but may lose phase-magnitude couplings.
  - **Synthetic vs. Real Data:** Training on synthetic data enables scaling but may introduce distribution shift. The paper demonstrates that a hybrid approach (15-20% real) mitigates this.
  - **Inference Cost:** The paper notes ~10 seconds per slice. Generating large synthetic datasets is computationally expensive.

- **Failure signatures:**
  - **Generated phase is uniform/random:** The model is not conditioning on the magnitude. Check if the magnitude channel is correctly concatenated and processed by the U-Net.
  - **Downstream model shows no improvement:** The synthetic phase may lack the specific features the downstream task requires. A naive phase baseline may be too simple; ensure the comparison is fair.
  - **Training instabilities (NaNs):** Complex-valued operations can be numerically unstable. Ensure the implementation of complex layers (e.g., batch norm, activations) is robust.

- **First 3 experiments:**
  1. **Reproduce the skull-stripping baseline:** Train a segmentation model using only magnitude data (no phase) and evaluate on real k-space to establish a lower bound (expected ~40% DSC, per Table I).
  2. **Validate phase generation quality:** Generate a small batch of synthetic k-space and visualize both the image-domain magnitude and phase. Check for anatomical consistency in the phase (e.g., following tissue boundaries), as shown in Fig. 3.
  3. **Run a hybrid-data reconstruction experiment:** Train a reconstruction model with 1% real data + 99% PhaseGen data, and compare its SSIM/PSNR to a model trained on 1% real data alone (Table III provides the expected gains).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the PhaseGen framework be effectively extended to generate multi-coil k-Space data with associated sensitivity maps?
- Basis in paper: [explicit] The authors identify the current limitation to single-coil data and explicitly state that "Future work will focus on the training of a model on multi-coil data."
- Why unresolved: The current architecture processes single complex values per pixel, whereas multi-coil data requires modeling inter-channel correlations and spatially varying coil sensitivities.
- What evidence would resolve it: Successful training of a multi-coil variant and evaluation of downstream reconstruction metrics against existing multi-coil baselines.

### Open Question 2
- Question: Can the inference latency be reduced to facilitate the generation of large-scale datasets without sacrificing phase quality?
- Basis in paper: [explicit] The discussion notes that "an inference time of roughly 10 seconds per slice... is still time consuming" as a primary limitation.
- Why unresolved: The standard diffusion sampling process requires many sequential iterations, making the generation of thousands of samples computationally expensive.
- What evidence would resolve it: Implementation of accelerated sampling techniques (e.g., DDIM, consistency models) that maintain the Dice Similarity Coefficient and SSIM improvements while significantly reducing seconds per slice.

### Open Question 3
- Question: Does the synthetic phase information capture sufficient physical realism to benefit tasks reliant on precise phase properties, such as quantitative susceptibility mapping?
- Basis in paper: [inferred] The paper notes the generated phase differs from the original due to missing factors like coil sensitivity, yet improves segmentation; however, it is unclear if this "phase" is physically meaningful or merely a statistical aid for convolutional networks.
- Why unresolved: Validating physical accuracy is difficult because the model is conditioned only on magnitude images, forcing it to hallucinate phase based on learned priors rather than physics.
- What evidence would resolve it: Quantitative analysis comparing generated phase maps against physical simulations or testing the model on phase-dependent diagnostic tasks beyond segmentation.

## Limitations
- The model currently only supports single-coil data, limiting its applicability to modern multi-coil MRI acquisitions
- Inference latency of ~10 seconds per slice makes generating large synthetic datasets computationally expensive
- The approach has only been validated on 2D data, with 3D extension mentioned as future work but not demonstrated
- The physical realism of the generated phase for tasks requiring precise phase information remains uncertain

## Confidence

**High Confidence:** The PhaseGen architecture and its ability to generate anatomically plausible phase information when conditioned on magnitude images (supported by visual examples and quantitative skull-stripping results)

**Medium Confidence:** The generalization benefits for downstream tasks (the hybrid training approach shows promise, but the exact contribution of synthetic vs. real data needs more systematic ablation)

**Low Confidence:** Claims about the method's applicability to clinical diagnostics, as the paper focuses on proof-of-concept tasks rather than actual clinical workflows

## Next Checks

1. **Phase Distribution Validation:** Generate synthetic k-space samples and compare phase histograms, FFT patterns, and anatomical consistency against real phase data to verify the model captures realistic phase distributions

2. **Contrast Generalization Test:** Train and evaluate PhaseGen on T2-weighted and FLAIR sequences to determine if the magnitude-to-phase mapping generalizes across MRI contrasts

3. **Clinical Task Transfer:** Apply the pretrained models to an actual clinical diagnostic task (e.g., tumor segmentation or lesion detection) rather than just skull-stripping to assess real-world utility