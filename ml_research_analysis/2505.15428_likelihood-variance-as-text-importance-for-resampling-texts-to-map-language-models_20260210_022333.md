---
ver: rpa2
title: Likelihood Variance as Text Importance for Resampling Texts to Map Language
  Models
arxiv_id: '2505.15428'
source_url: https://arxiv.org/abs/2505.15428
tags:
- texts
- error
- sampling
- resampling
- uniform
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the high computational cost of constructing a
  language model map by proposing a resampling method that selects important texts
  based on the variance of log-likelihoods across models. This approach significantly
  reduces the number of required texts while preserving KL divergence estimation accuracy.
---

# Likelihood Variance as Text Importance for Resampling Texts to Map Language Models

## Quick Facts
- arXiv ID: 2505.15428
- Source URL: https://arxiv.org/abs/2505.15428
- Reference count: 40
- Key outcome: Reduces texts needed for language model mapping by ~50% using variance-based importance sampling while preserving KL divergence estimation accuracy

## Executive Summary
This paper addresses the high computational cost of constructing language model maps by proposing a resampling method that selects important texts based on the variance of log-likelihoods across models. The approach significantly reduces the number of required texts while preserving KL divergence estimation accuracy. Experiments show that the method achieves comparable performance to uniform sampling with about half as many texts (e.g., 2,202 vs. 6,320 unique texts), and also enables efficient incorporation of new models into existing maps. The method scales well and maintains robustness in downstream performance prediction.

## Method Summary
The method computes log-likelihoods for K models on N texts, then double-centers the resulting matrix to enable KL divergence approximation via squared Euclidean distance. Texts are resampled with probabilities proportional to their log-likelihood variance across models (LS) or the fourth moment of log-likelihood differences (KL), with importance weights correcting for sampling bias. The weighted distances between models are then used to construct the model map, achieving comparable accuracy to uniform sampling while requiring fewer unique texts.

## Key Results
- Resampling method reduces unique texts needed from 6,320 to 2,202 for comparable KL divergence estimation error
- LS sampling outperforms KL sampling slightly for relative error metrics while being simpler to compute
- All methods converge to similar downstream task prediction performance (r ≈ 0.92-0.93) when sufficient texts are used
- Method enables efficient addition of new models to existing maps with minimal additional computation

## Why This Works (Mechanism)

### Mechanism 1: Variance-based Text Importance Scoring
- Claim: Texts with higher variance in log-likelihoods across models are more informative for distinguishing model relationships.
- Mechanism: The double-centered log-likelihood matrix Q encodes model-text interactions. Column norms ∥Q(s)∥² equal the variance of log-likelihoods for text xs across all K models. Sampling probability πs ∝ ∥Q(s)∥² preferentially selects texts where models disagree most.
- Core assumption: High-variance texts capture the principal dimensions of model differentiation needed for accurate distance estimation.
- Evidence anchors:
  - [abstract] "selects important texts with weights proportional to the variance of log-likelihoods across models for each text"
  - [section 3.1] "The squared norm ∥Q(s)∥² corresponds to the variance of the log-likelihoods for text xs across models."
  - [corpus] Limited direct corpus support; related work on importance sampling exists but variance-as-importance for model mapping is novel.
- Break condition: If all texts have uniform variance across models (e.g., identical model family), the method degrades to uniform sampling without benefits.

### Mechanism 2: Weighted Resampling with Importance Correction
- Claim: Non-uniform resampling requires explicit reweighting to produce unbiased distance estimates.
- Mechanism: When text xut is resampled c(ut) times with probability πut, the weight wut = c(ut)/(n·πut) corrects the sampling bias. The squared Euclidean distance uses these weights: ∥eqi - eqj∥²wd = Σt [c(ut)/(n·πut)](eqi(xut) - eqj(xut))².
- Core assumption: The weighted estimator remains unbiased (E[êgij] = gij) under the specified importance weights.
- Evidence anchors:
  - [section 3.2] "the column L(ut) corresponding to the resampled text xut is weighted by wut = c(ut)/nπut"
  - [appendix C, Lemma 1] Proves E[êgij] = gij for the weighted estimator.
  - [corpus] Importance sampling literature supports this correction approach generally.
- Break condition: If weights become unstable (very small πut with large c(ut)), variance explodes and estimates degrade.

### Mechanism 3: KL Divergence via Squared Euclidean Distance
- Claim: KL divergence between language models can be approximated by squared Euclidean distance of double-centered log-likelihood vectors.
- Mechanism: Given log-likelihood matrix L, double-centering produces Q where each row qi is a model coordinate. The distance ∥qi - qj∥²/N estimates 2·KL(pi, pj), enabling comparison across architectures.
- Core assumption: Log-likelihoods on a finite text sample provide sufficient statistics for model comparison.
- Evidence anchors:
  - [section 2.1] "2 KL(pi, pj) ≈ ∥qi - qj∥²/N"
  - [section 4.1] Scaling ensures comparability across different dimensionalities.
  - [corpus] Prior work (Oyama et al., 2025) establishes this relationship; this paper builds on it.
- Break condition: If text sample is unrepresentative of the population, distances reflect sampling artifacts rather than true model relationships.

## Foundational Learning

- Concept: **Double-centering of matrices**
  - Why needed here: Transforms raw log-likelihoods into coordinates where Euclidean distance approximates KL divergence.
  - Quick check question: Given matrix M, can you compute row means, column means, and the grand mean to produce a centered matrix?

- Concept: **KL divergence and its properties**
  - Why needed here: The target quantity being estimated; understanding its asymmetry and relationship to log-likelihoods is essential.
  - Quick check question: Why must KL(pi||pj) ≠ KL(pj||pi), and how does double-centering address this?

- Concept: **Bootstrap estimation of sampling error**
  - Why needed here: The paper decomposes total error into sampling error (DN vs. population) and resampling error (D̃n vs. DN).
  - Quick check question: How would you estimate the variance of an estimator when the population distribution is unknown?

## Architecture Onboarding

- Component map:
  1. Log-likelihood computation: Compute L ∈ R^(K×N) for K models over N texts
  2. Double-centering: Transform L → Q via row/column mean subtraction
  3. Importance scoring: Compute πs ∝ ∥Q^(s)∥² (LS) or πs ∝ √Σ(qi(xs)-qj(xs))⁴ (KL)
  4. Resampling: Sample n texts with replacement using importance probabilities
  5. Weighted distance: Compute ∥êqi - êqj∥²wd with importance weights
  6. Map visualization: t-SNE projection with alignment via Orthogonal Procrustes

- Critical path: Log-likelihood computation (most expensive) → double-centering → importance scoring → resampling → distance matrix. The resampling step reduces downstream costs by ~50%.

- Design tradeoffs:
  - LS sampling: Simpler, marginally better for relative error; KL sampling: Better for absolute squared error
  - Smaller n: Faster but fewer unique texts (d), higher variance; larger n: More unique texts, diminishing returns
  - Paper recommends LS due to comparable performance and simplicity

- Failure signatures:
  - If d ≪ K (fewer texts than models), regression prediction degrades (r drops sharply below d ≈ 1000)
  - If new models have very different architectures than existing ones, importance weights from old models may be suboptimal
  - Weight instability when πs → 0 for some texts

- First 3 experiments:
  1. Reproduce error vs. d curves: Implement uniform, LS, and KL sampling; verify that LS/KL achieve comparable error to uniform with ~half the unique texts (target: d ≈ 2200 for LS matches d ≈ 5000 uniform)
  2. Map stability test: Run 100 resampling trials per method; compute standard deviational ellipses; confirm LS with d=2200 has similar ellipse sizes to uniform with d=6320
  3. Downstream prediction: Train ridge regression on resampled coordinates to predict benchmark scores; verify all methods converge to r ≈ 0.92-0.93 by d ≈ 1000, with minimal difference between methods at high d

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the proposed resampling method when applied to text datasets with different distributions or domains compared to the Pile corpus used in this study?
- Basis in paper: [explicit] The authors state in the Limitations section that "data sampling remains unexplored" and future investigation is required to determine applicability to datasets other than the specific $D_N$ used.
- Why unresolved: The experiments rely exclusively on a specific subset of the Pile dataset, leaving the method's efficacy on diverse or out-of-distribution corpora unverified.
- What evidence would resolve it: Experiments reconstructing model maps using resampled texts from varied domains (e.g., code, multilingual corpora, or domain-specific text) and comparing the estimation errors against the current baseline.

### Open Question 2
- Question: Why do the improvements in KL divergence estimation accuracy from LS and KL sampling fail to translate into better performance on downstream task prediction?
- Basis in paper: [explicit] The Limitations section notes that while the methods outperform uniform sampling in divergence estimation, "the difference disappeared in downstream performance prediction" and warrants further investigation.
- Why unresolved: The paper empirically observes this decoupling between map accuracy and downstream utility but does not provide a theoretical explanation for why preserving KL divergence via importance sampling does not benefit predictive tasks.
- What evidence would resolve it: An analysis of the feature subspaces spanned by the resampled texts versus uniformly sampled texts to identify what information is preserved or lost relative to the specific requirements of downstream benchmarks.

### Open Question 3
- Question: How does the efficiency of the resampling method for incorporating new models vary with the number and architectural types of models being added?
- Basis in paper: [explicit] The authors admit they "did not include a detailed discussion on the number or types of the new models added" in their experiments on expanding existing maps.
- Why unresolved: The study only demonstrates the addition of 120 new models to a set of 898, leaving the method's scalability and stability untested for adding larger or more diverse batches of models.
- What evidence would resolve it: Ablation studies that systematically vary the volume and architectural diversity of new models added to the map to observe any degradation in placement accuracy or resampling efficiency.

## Limitations
- Computational intensity of initial log-likelihood matrix computation scales linearly with models and texts
- Effectiveness depends on log-likelihood variances meaningfully capturing model relationships
- Double-centering approach relies on finite text sample being representative of population distribution
- Method assumes models can be meaningfully compared through log-likelihoods on the same text corpus

## Confidence
**High Confidence**:
- Variance-of-log-likelihoods mechanism for identifying important texts is well-grounded
- Weighted resampling approach with importance weights correctly addresses sampling bias
- Empirical results showing ~50% reduction in required texts are robust

**Medium Confidence**:
- Relationship between squared Euclidean distance and KL divergence is established but approximation quality depends on sample
- Choice between LS and KL sampling methods is justified empirically but may be dataset-dependent

## Next Checks
1. **Stability analysis across diverse model families**: Test the method on model populations with varying architectural diversity to verify variance-based importance scoring remains effective.
2. **Ablation study on double-centering precision**: Quantify the impact of numerical precision in double-centering on final distance estimates, particularly for models with similar log-likelihood profiles.
3. **Population representativeness validation**: Systematically vary the source text distribution to measure sensitivity of KL divergence estimates to the underlying text population.