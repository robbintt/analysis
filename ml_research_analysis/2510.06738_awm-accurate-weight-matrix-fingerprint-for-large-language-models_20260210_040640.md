---
ver: rpa2
title: 'AWM: Accurate Weight-Matrix Fingerprint for Large Language Models'
arxiv_id: '2510.06738'
source_url: https://arxiv.org/abs/2510.06738
tags:
- language
- arxiv
- large
- matrices
- manipulations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting whether a suspect
  LLM is trained from scratch or derived from an existing base model, even after extensive
  post-training modifications like fine-tuning, continued pretraining, reinforcement
  learning, pruning, and multi-modal adaptation. The authors propose AWM, a training-free
  fingerprinting method based on weight matrices that leverages the Linear Assignment
  Problem (LAP) and unbiased Centered Kernel Alignment (CKA) similarity to neutralize
  the effects of parameter manipulations.
---

# AWM: Accurate Weight-Matrix Fingerprint for Large Language Models

## Quick Facts
- arXiv ID: 2510.06738
- Source URL: https://arxiv.org/abs/2510.06738
- Reference count: 40
- Authors: Boyi Zeng; Lin Chen; Ziwei He; Xinbing Wang; Zhouhan Lin
- Primary result: Training-free fingerprinting method that achieves perfect classification (AUC=1.0, TPR@1%FPR=1.0) against post-training modifications

## Executive Summary
This paper introduces AWM (Accurate Weight-Matrix), a novel training-free fingerprinting method for detecting whether a suspect large language model (LLM) is derived from an existing base model. AWM addresses the challenge of model provenance detection in the face of extensive post-training modifications including fine-tuning, continued pretraining, reinforcement learning, pruning, and multi-modal adaptation. The method leverages weight matrix similarity using Linear Assignment Problem (LAP) and unbiased Centered Kernel Alignment (CKA) to create robust fingerprints that remain effective even after parameter manipulations.

The proposed method demonstrates exceptional performance on a comprehensive testbed of 60 positive and 90 negative model pairs, achieving perfect scores across all classification metrics while maintaining computational efficiency at approximately 30 seconds on an NVIDIA 3090 GPU. AWM's ability to neutralize the effects of various post-training modifications while preserving the core fingerprint makes it a significant advancement in LLM provenance detection.

## Method Summary
AWM operates by analyzing weight matrices of LLMs to create robust fingerprints that remain invariant to common post-training modifications. The method employs the Linear Assignment Problem (LAP) to establish optimal matching between weight matrices, followed by unbiased Centered Kernel Alignment (CKA) similarity calculation to measure fingerprint similarity. This two-step process effectively neutralizes the impact of parameter manipulations while preserving the essential characteristics that indicate model ancestry. The training-free nature of AWM allows for immediate application without requiring access to the original training data or process, making it practical for real-world deployment scenarios where base model provenance needs to be verified after various forms of adaptation or modification.

## Key Results
- Achieves perfect classification performance (AUC=1.0, pAUC=1.0, TPR@1%FPR=1.0) on 60 positive and 90 negative model pairs
- Maintains effectiveness across 9 different post-training manipulation categories including fine-tuning, pruning, and multi-modal adaptation
- Completes fingerprinting analysis within 30 seconds on NVIDIA 3090 GPU hardware
- Demonstrates near-zero false positive rate while maintaining perfect true positive detection

## Why This Works (Mechanism)
AWM works by exploiting the fundamental observation that weight matrices retain core structural similarities even after extensive post-training modifications. The Linear Assignment Problem (LAP) optimally matches corresponding weight matrices between models, accounting for potential permutations or reorganizations that may occur during training. The unbiased CKA similarity then quantifies the structural alignment between these matched matrices, creating a robust fingerprint that captures the essential architectural and learned features that persist through various forms of parameter manipulation. This approach effectively separates the invariant structural properties that indicate model ancestry from the variable aspects that change during post-training adaptation.

## Foundational Learning

**Linear Assignment Problem (LAP)**: An optimization technique for finding the optimal assignment between two sets of elements. Why needed: To establish optimal matching between weight matrices that may have been permuted during training. Quick check: Verify that LAP produces consistent matchings across repeated runs with the same input matrices.

**Centered Kernel Alignment (CKA)**: A similarity metric that measures the alignment between representations in different spaces. Why needed: To quantify structural similarity between weight matrices while being invariant to certain transformations. Quick check: Confirm CKA values are bounded between 0 and 1 and increase monotonically with structural similarity.

**Weight Matrix Analysis**: The study of patterns and structures within neural network weight matrices. Why needed: To identify invariant features that persist through post-training modifications. Quick check: Verify that weight matrix statistics (e.g., spectral properties) remain relatively stable across different fine-tuning runs.

**Training-free Fingerprinting**: Methods that detect model relationships without requiring access to training data or process. Why needed: To enable practical deployment in scenarios where original training information is unavailable. Quick check: Ensure the method produces consistent results without any training phase or calibration.

## Architecture Onboarding

Component Map: Input Models → Weight Matrix Extraction → LAP Matching → CKA Similarity → Fingerprint Score → Classification

Critical Path: The core workflow involves extracting weight matrices from both suspect and base models, applying LAP to establish optimal matching, computing unbiased CKA similarity between matched matrices, and aggregating these similarities into a final fingerprint score for classification. This sequence must be executed in order as each step depends on the output of the previous one.

Design Tradeoffs: The method trades some sensitivity to fine-grained parameter differences for robustness to post-training modifications. While this may miss subtle variations introduced by training, it ensures the fingerprint remains effective even after extensive parameter manipulations. The choice of LAP and unbiased CKA represents a balance between computational efficiency and similarity measurement accuracy.

Failure Signatures: The method may fail when post-training modifications are so extensive that fundamental weight matrix structures are completely altered, or when adversarial techniques specifically target the LAP and CKA components. Additionally, models with fundamentally different architectures may produce misleading similarity scores despite no direct lineage relationship.

First Experiments:
1. Compare CKA similarity distributions between known related and unrelated model pairs to establish baseline performance
2. Test LAP matching consistency across multiple runs with the same model pairs
3. Evaluate fingerprint stability under controlled parameter perturbations (e.g., random weight noise at different magnitudes)

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation covers only 7 base models and 9 post-training manipulation types, potentially limiting generalizability
- Computational efficiency claims based on single hardware configuration (NVIDIA 3090) may not hold for larger models
- Perfect classification scores in limited testbed warrant cautious interpretation regarding real-world performance
- Method's effectiveness against novel or more extensive post-training techniques not included in evaluation remains unknown

## Confidence

**High confidence**: AWM's effectiveness against the specific post-training categories tested in the evaluation
**Medium confidence**: Computational efficiency claims and general robustness to parameter manipulations
**Low confidence**: Generalization to unseen post-training techniques and adversarial scenarios designed to evade fingerprinting

## Next Checks
1. Test AWM against larger and more diverse model architectures beyond the 7 base models evaluated
2. Evaluate resistance to adversarial fine-tuning techniques specifically designed to fool fingerprinting methods
3. Validate computational efficiency across different GPU architectures and with larger parameter counts