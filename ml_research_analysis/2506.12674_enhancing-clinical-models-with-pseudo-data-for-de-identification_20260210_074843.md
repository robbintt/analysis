---
ver: rpa2
title: Enhancing Clinical Models with Pseudo Data for De-identification
arxiv_id: '2506.12674'
source_url: https://arxiv.org/abs/2506.12674
tags:
- pseudo
- masked
- roberta
- dataset
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the impact of training large language models
  on de-identified clinical text containing masked protected health information. The
  authors hypothesize that masked tokens negatively affect model performance and propose
  pretraining on pseudo datasets where masked entities are replaced with realistic
  generated text.
---

# Enhancing Clinical Models with Pseudo Data for De-identification

## Quick Facts
- arXiv ID: 2506.12674
- Source URL: https://arxiv.org/abs/2506.12674
- Reference count: 13
- Primary result: Pseudo-pretrained models achieved 99.883 F1 vs. 99.848 for masked models on clinical de-identification

## Executive Summary
This study investigates whether pretraining large language models on de-identified clinical text with masked protected health information (PHI) negatively impacts downstream entity recognition performance. The authors hypothesize that masked tokens create low-entropy learning signals that degrade model representations, and propose replacing masked PHI with realistic pseudo-text during pretraining. Using MIMIC-III clinical notes, they generate pseudo datasets where masked entities are replaced with samples from gazetteers and generators, then continue pretraining RoBERTa and XLM-RoBERTa models on both masked and pseudo datasets before fine-tuning for de-identification on the i2b2 corpus.

Results demonstrate that models pretrained on pseudo data significantly outperform those trained on masked data, with the best pseudo RoBERTa large model achieving 99.883 F1 (vs. 99.848 for masked) and surpassing previous baselines by 1.5 F1 points. XLM-RoBERTa pseudo models show consistent improvements across labels, while RoBERTa large pseudo models exhibited some degradation in location and name classification. The study provides empirical evidence that low-entropy masked tokens in de-identified corpora negatively impact entity recognition, and that pseudo data replacement can mitigate this effect, though dataset quality sensitivity remains a concern.

## Method Summary
The authors created a pseudo database containing names, locations, dates, and medical identifiers, then generated pseudo datasets from MIMIC-III clinical notes by replacing masked PHI tokens with realistic generated text. They continue-trained RoBERTa and XLM-Roberta (base and large variants) on both masked and pseudo datasets for 6 epochs, then fine-tuned these checkpoints on the i2b2 de-identification corpus. Models were evaluated using micro/weighted/macro F1 metrics with 23 original labels re-categorized to 8 HIPAA labels for comparison with prior work. The pseudo generation process used regex parsing of MIMIC-III notes, gazetteer sampling for known entity types, and GatorTron LLM inference for unknown tags.

## Key Results
- Best pseudo RoBERTa large model achieved 99.883 F1 vs. 99.848 for masked model
- Pseudo pretraining surpassed previous baselines by 1.5 F1 points
- XLM-RoBERTa pseudo models showed consistent improvements across labels
- RoBERTa large pseudo models had degradation in LOCATION (+36 false positives) and NAME (+24 false positives) classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Masked PHI tokens create low-entropy learning signals that degrade model representations for downstream entity recognition tasks.
- Mechanism: De-identification masks like `[**Doctor Last Name**]` are repetitive and syntactically uniform across the corpus (11.2M tokens, 6% of MIMIC-III), causing the model to saturate on mask syntax rather than learning meaningful entity representations. Replacing with realistic pseudo-text increases token entropy and provides richer contextual patterns.
- Core assumption: The performance gap stems from low entropy in masked token distributions rather than from the de-identification process itself.
- Evidence anchors: Authors hypothesize named entities lack necessary entropy and saturate over redacted tokens; masked model fill-mask outputs include asterisks and brackets while pseudo model produces realistic clinical text like "Dr. Jones."

### Mechanism 2
- Claim: Pseudo data improves transfer learning by aligning pretraining distribution closer to unredacted clinical text.
- Mechanism: The pseudo dataset (585M tokens) approximates statistical properties of real clinical notes. Fine-tuning from pseudo-pretrained checkpoints thus requires smaller distributional shifts than from masked checkpoints.
- Core assumption: Pseudo-generated entities approximate the distribution of real PHI well enough to improve entity boundary and type learning.
- Evidence anchors: Best pseudo model achieved 99.883 F1 vs. 99.848 masked, surpassing previous baselines by 1.5 F1 points; XLM-RoBERTa pseudo models showed consistent improvements across labels.

### Mechanism 3
- Claim: Multilingual pretraining (XLM-RoBERTa) provides robustness to pseudo data quality variation and low-entropy tokens.
- Mechanism: Exposure to diverse name/location patterns across languages creates representations that better handle pseudo data with varying realism. XLM-Roberta showed consistent pseudo > masked improvements; monolingual RoBERTa large showed degradation on LOCATION and NAME.
- Core assumption: Linguistic diversity in multilingual training creates more robust named entity representations that transfer to clinical PHI.
- Evidence anchors: XLM-RoBERTa pseudo models consistently outperform masked models; authors attribute this to exposure to foreign names, locations and romance languages; RoBERTa large pseudo had degradation with confusion between medical terms and hospitals.

## Foundational Learning

- **Concept: MLM Pretraining vs. De-identification Masking**
  - Why needed here: The paper explicitly distinguishes BERT-style [MASK] tokens (self-supervised learning) from de-identification masks like `[**Name**]` (privacy protection). Confusion between these would misinterpret the intervention.
  - Quick check question: Explain why `[MASK]` in BERT pretraining serves a different purpose than `[**Name**]` in MIMIC-III, and why replacing the latter might improve downstream performance.

- **Concept: Transfer Learning with Continued Pretraining**
  - Why needed here: The method continues pretraining RoBERTa/XLM-RoBERTa checkpoints on clinical pseudo data before fine-tuning, rather than fine-tuning directly from general-domain checkpoints.
  - Quick check question: Why would additional pretraining on pseudo clinical notes improve de-identification performance compared to fine-tuning from vanilla RoBERTa?

- **Concept: Named Entity Recognition as Token Classification**
  - Why needed here: De-identification is framed as sequence labeling where each token receives a PHI label, using a linear layer over transformer outputs.
  - Quick check question: How does token-level classification handle multi-token entities, and what post-processing might be needed?

## Architecture Onboarding

- **Component map**:
  - Pseudo database: Lists of hospitals (4,826), first names (28,516), last names (162,252), companies (500), universities (2,074), US states (51)—sourced from census data and public lists
  - Data generators: 30+ generators mapping tags to either database sampling or random generation; ambiguous tags use GatorTron LLM inference
  - Pretraining: RoBERTa/XLM-Roberta (base/large) continued for 6 epochs, LR 2×10⁻⁵, max sequence length 1024, batch sizes 5–20
  - Fine-tuning: Linear classification head, LR 7×10⁻⁶, dropout 10%, 20 epochs with early stopping on validation loss
  - Evaluation: i2b2 23-label schema → re-categorize to 8 HIPAA labels for comparison with prior work

- **Critical path**:
  1. Parse MIMIC-III notes with ScispaCy → extract masked tokens via regex → map to generator tags
  2. For each masked token, invoke appropriate generator (database sample or random generation); LLM fallback for ambiguous cases
  3. Continue pretrain from RoBERTa/XLM-Roberta checkpoints on pseudo dataset (and separately on masked for ablation)
  4. Fine-tune on i2b2 de-identification corpus with stratified 80/20 train/validation split
  5. Evaluate weighted/micro/macro F1; analyze per-label confusion matrices

- **Design tradeoffs**:
  - Pseudo realism vs. coverage: Hospital list has only 7.2% overlap with i2b2 test hospitals—broader lists may improve LOCATION but could introduce noise
  - Model size vs. consistency: RoBERTa large achieves highest overall F1 but degrades on LOCATION/NAME; XLM-Roberta large more consistent across labels
  - Generator fidelity: Random numeric IDs are realistic but don't preserve format variation (e.g., age morphology like "40's" not handled)

- **Failure signatures**:
  - LOCATION false positives: RoBERTa large pseudo +36 vs. masked; medical terms (Medtronic, TSH) misclassified as HOSPITAL
  - NAME false positives: RoBERTa large pseudo +24 vs. masked; confusion between PATIENT and DOCTOR names
  - Medical eponym confusion: Pseudo RoBERTa large mislabels "Gleason" (scoring system) as NAME; masked model correctly classifies as non-PHI
  - Low pseudo-test overlap: 7.2% hospital overlap correlates with LOCATION degradation in monolingual models

- **First 3 experiments**:
  1. **Pseudo vs. masked ablation**: Train RoBERTa base on identical data differing only in mask vs. pseudo replacement; measure statistical significance (Result: 99.848 vs. 99.847 F1, McNemar p=0.7, not significant—base models show minimal difference).
  2. **Entity-type breakdown by model family**: For XLM-Roberta large, compare per-label F1 between masked and pseudo to identify which entity types benefit most (Result: pseudo improves PROFESSION +1.4, LOCATION +0.3, NAME +0.2; masked wins only on AGE).
  3. **Pseudo database coverage audit**: Compute overlap between pseudo hospital list and i2b2 test hospitals; correlate with false positive rates to diagnose quality sensitivity (Result: 7.2% overlap associated with +36 LOCATION false positives in RoBERTa large pseudo).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does pseudo data pretraining consistently improve performance across diverse clinical NLP tasks beyond de-identification, such as named entity recognition, relation extraction, or clinical outcome prediction?
- Basis in paper: [explicit] The authors state: "We believe that other tasks, such as named entity recognition and entity linking, are also negatively affected for the same reasons" (Section 1), but only evaluate on de-identification.
- Why unresolved: Only the de-identification task was empirically tested; the claim about other tasks remains a hypothesis.
- What evidence would resolve it: Fine-tuning and evaluating pseudo vs. masked pretrained models on additional clinical NLP benchmarks (e.g., i2b2 2010 relations, clinical NER datasets) with comparative F1 scores.

### Open Question 2
- Question: Why does pseudo data pretraining benefit XLM-Roberta models more consistently than RoBERTa models, particularly for location and name labels?
- Basis in paper: [explicit] The authors observe: "Our hypothesis that pseudo models outperform masked models holds for XLM-Roberta but not RoBERTa large" (Section 7) and attribute XLM-Roberta's robustness to "exposure to foreign names, locations and romance languages" (Section 7).
- Why unresolved: The explanation is post-hoc; no controlled experiments isolate the mechanism behind this architecture-specific sensitivity.
- What evidence would resolve it: Ablation studies varying pseudo data diversity and entropy while controlling for model architecture, plus analysis of embedding space properties across model types.

### Open Question 3
- Question: What is the minimum quality threshold for pseudo data to yield downstream performance improvements, and how does the overlap between pseudo data distributions and evaluation data affect results?
- Basis in paper: [inferred] The authors found only 7.2% overlap between pseudo hospital names and i2b2 test hospitals, yet this was the second most replaced type (Section 7), and pseudo RoBERTa large showed location degradation. This suggests quality matters but the threshold is unknown.
- Why unresolved: The paper demonstrates that poor-quality pseudo data can hurt performance but does not systematically vary quality or measure the relationship between pseudo-evaluation overlap and performance gains.
- What evidence would resolve it: Controlled experiments with pseudo databases of varying sizes, diversity, and overlap with evaluation data, measuring downstream F1 as a function of these parameters.

### Open Question 4
- Question: Does pseudo data pretraining similarly benefit modern decoder-only large language models (LLMs) when fine-tuned for clinical de-identification or other clinical tasks?
- Basis in paper: [explicit] The authors note: "Subsequent work includes self-supervised training LLMs on our datasets and supervised fine-tuning new clinical task models from the pretrained checkpoints" (Section 8).
- Why unresolved: All experiments used encoder-only models (RoBERTa, XLM-Roberta); decoder architectures were not tested despite their current dominance.
- What evidence would resolve it: Pretraining modern LLMs (e.g., Llama, Mistral variants) on pseudo vs. masked clinical data and evaluating on clinical NLP benchmarks.

## Limitations
- Model-family dependent effects: Pseudo data helps XLM-Roberta consistently but can degrade RoBERTa large performance on specific entity types
- Pseudo data quality sensitivity: Poor pseudo realism (e.g., low hospital list overlap) can cause performance degradation
- Limited evaluation scope: Only tested on de-identification task, though authors hypothesize broader applicability

## Confidence
- **High Confidence**: That masked tokens reduce entity recognition performance compared to pseudo data (robust across multiple model families and evaluation metrics)
- **Medium Confidence**: That multilingual pretraining (XLM-Roberta) provides robustness to pseudo data quality variation (observed consistently but mechanism not fully validated)
- **Low Confidence**: That pseudo data distributional alignment is the primary mechanism for improvement (plausible but competing explanations like token entropy increases exist)

## Next Checks
1. **Entity-type ablation study**: Generate separate pseudo datasets for each PHI category with varying quality levels; measure which entity types show performance degradation when pseudo realism drops
2. **Masked vs. pseudo entropy analysis**: Compute token-level entropy distributions for masked tokens versus pseudo replacements across MIMIC-III; correlate entropy variance with downstream F1 improvements per label
3. **Pseudo-database coverage audit**: Expand the hospital list to achieve >50% overlap with i2b2 test set; retrain RoBERTa large pseudo model and measure LOCATION false positive changes to isolate coverage effects