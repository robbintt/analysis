---
ver: rpa2
title: 'FM-FoG: A Real-Time Foundation Model-based Wearable System for Freezing-of-Gait
  Mitigation'
arxiv_id: '2509.24176'
source_url: https://arxiv.org/abs/2509.24176
tags:
- data
- detection
- https
- fm-fog
- sensor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FM-FoG, a real-time foundation model-based
  wearable system for freezing-of-gait (FoG) detection in Parkinson's disease patients.
  The system addresses the challenge of detecting FoG episodes without requiring patient-specific
  training data by combining self-supervised pretraining on diverse IMU datasets with
  sensor context integration.
---

# FM-FoG: A Real-Time Foundation Model-based Wearable System for Freezing-of-Gait Mitigation

## Quick Facts
- **arXiv ID:** 2509.24176
- **Source URL:** https://arxiv.org/abs/2509.24176
- **Reference count:** 40
- **Primary result:** FM-FoG achieves 98.5% F1-score in detecting FoG episodes in unseen Parkinson's disease patients

## Executive Summary
FM-FoG introduces a real-time wearable system that detects freezing-of-gait (FoG) episodes in Parkinson's disease patients without requiring patient-specific training data. The system combines self-supervised pretraining on diverse IMU datasets with sensor context integration to achieve cross-patient generalization. A hierarchical architecture uses a lightweight CNN-LSTM classifier to trigger a computationally intensive foundation model only during ambulatory activities, extending battery life by up to 72% while maintaining sub-20ms intervention latency. Evaluated on 23 PD patients, FM-FoG substantially outperforms existing methods including Gait-Guard and time-series foundation models.

## Method Summary
The system uses a two-stage architecture: a lightweight CNN-LSTM classifier continuously monitors IMU data from ankle-mounted sensors to detect ambulatory states, triggering a foundation model only when standing or walking is detected. The foundation model, based on a 6-layer transformer with sensor context embeddings, performs self-supervised masked reconstruction on diverse IMU datasets before fine-tuning on FoG labels. The approach combines frequency harmonization via cubic-spline interpolation, per-subject normalization, and location embeddings to handle sensor placement variability. Both models are pre-loaded in memory on a smartphone to ensure real-time performance.

## Key Results
- FM-FoG achieves 98.5% F1-score detecting FoG episodes in unseen patients
- Outperforms existing methods: Gait-Guard (90.9% F1), MOMENT (85.9% F1), TimesFM-500M (84.1% F1)
- Extends battery life by up to 72% through selective model activation
- Maintains sub-20ms intervention latency on Google Pixel 8a smartphone

## Why This Works (Mechanism)

### Mechanism 1: Event-Triggered Architecture
A lightweight CNN-LSTM classifier runs continuously to detect "FoG-relevant" states (standing/walking), activating the computationally intensive Foundation Model only when needed. This exploits that FoG doesn't occur while sitting or lying down, extending battery life by up to 72%.

### Mechanism 2: Sensor Context Integration
The model concatenates learnable "location embeddings" (e.g., ankle vs. lower back) with raw IMU data, allowing the transformer to contextualize movement patterns based on sensor placement. This prevents overfitting to specific sensor noise and enables cross-patient generalization.

### Mechanism 3: Frequency Harmonization
All datasets are standardized to 100Hz using cubic-spline interpolation, preserving critical temporal features while preventing the model from treating sampling rate as a distinguishing feature. Performance drops from 98.5% to 91.2% F1 without this step.

## Foundational Learning

- **Concept: Masked Autoencoding (Self-Supervised Learning)**
  - Why needed: Learns general gait representations without scarce, expert-annotated FoG labels
  - Quick check: Can you explain why masking 30% of a time-series and forcing reconstruction helps detect anomalies it has never seen?

- **Concept: Event-Triggered Architecture**
  - Why needed: Balances computational demands of Transformers with battery constraints of mobile devices
  - Quick check: How do you calculate energy savings if the heavy model is only active 30% of the time?

- **Concept: IMU Data Heterogeneity**
  - Why needed: Understanding sensor placement and sampling rate variations explains why context integration and resampling are necessary
  - Quick check: Why can't you train on ankle data and expect it to work immediately on wrist data without context integration?

## Architecture Onboarding

- **Component map:** UltiGesture Ankle Sensor (IMU) -> Bluetooth -> Smartphone App -> CNN-LSTM Trigger -> (If Active) -> Transformer Foundation Model -> Haptic Vibration (PDVibe3)

- **Critical path:**
  1. Ensure 100Hz data stream stability
  2. Apply exact preprocessing (resampling/normalization) matching pretraining
  3. Gate FM activation through trigger model

- **Design tradeoffs:**
  - Memory vs. Latency: Both models permanently loaded in memory (112MB) to avoid file I/O delays, ensuring <20ms latency but increasing RAM footprint
  - Generalization vs. Specificity: Generalizes to new patients but requires complex preprocessing compared to simple threshold-based detectors

- **Failure signatures:**
  - High Battery Drain: Continuous walking eliminates battery savings
  - False Negatives on Startup: Missed walking onset prevents FM activation
  - Drift: Sensor calibration drift distorts normalization

- **First 3 experiments:**
  1. Ablate Context: Run inference using wrong location embedding to test context mechanism sensitivity
  2. Stress Test Latency: Measure time from trigger activation to FM output on Pixel 8a under load
  3. Data Limit Test: Retrain using "N=1" or "N=3" patient splits to determine minimum viable data requirement

## Open Questions the Paper Calls Out

- **Explainable AI Integration:** How can interpretable AI techniques be integrated for clinical decision-making? The model currently operates as a black box, and future research should focus on attention visualization methods to identify which patterns trigger predictions.

- **Real-World Performance:** How does performance vary during longitudinal, continuous monitoring in daily living versus controlled clinical settings? Current evaluation relies on controlled protocols that may not capture full symptom variability and environmental noise present in patients' daily lives.

- **Individual Adaptation:** Can the foundation model adapt to individual patient patterns over time without compromising cross-patient generalization? Implementing continuous personalization risks catastrophic forgetting or loss of generalization while tracking disease progression.

## Limitations
- VCU FoG-IMU dataset is not publicly available, preventing independent validation of the 98.5% F1-score
- CNN-LSTM trigger architecture details are underspecified beyond basic layer configurations
- Minimum viable dataset size for acceptable performance remains unclear from ablation studies

## Confidence

**High Confidence:** Event-triggered architecture's battery optimization (72% extension claim supported by detailed analysis); sensor context integration impact on generalization (demonstrated through systematic ablation); preprocessing pipeline including frequency harmonization (explicitly specified with performance metrics).

**Medium Confidence:** Self-supervised pretraining approach (theoretically sound but generalization cannot be fully validated without test dataset access); real-time deployment latency claims (supported by deployment details but require independent measurement).

**Low Confidence:** Clinical significance of 98.5% F1-score (depends entirely on quality and representativeness of unavailable test dataset); method comparisons (may be affected by unspecified differences in dataset composition or evaluation protocols).

## Next Checks
1. **Dataset Access Verification:** Contact authors to determine if VCU FoG-IMU dataset can be shared or identify alternative public datasets for reproducing cross-patient generalization results.

2. **Trigger Model Specification:** Request complete architectural details for CNN-LSTM trigger model including exact layer dimensions, activation functions, and training hyperparameters.

3. **Real-World Deployment Testing:** Conduct independent latency measurements on Google Pixel 8a hardware to verify <20ms intervention latency claim under various load conditions including battery state and background processes.