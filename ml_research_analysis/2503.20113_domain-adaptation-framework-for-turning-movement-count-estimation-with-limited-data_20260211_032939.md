---
ver: rpa2
title: Domain Adaptation Framework for Turning Movement Count Estimation with Limited
  Data
arxiv_id: '2503.20113'
source_url: https://arxiv.org/abs/2503.20113
tags:
- data
- domain
- traffic
- movement
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a domain adaptation (DA) framework for estimating
  turning movement counts (TMCs) at intersections using traffic controller event-based
  data, road infrastructure data, and point-of-interest (POI) data. The framework
  addresses data scarcity by leveraging labeled source domain data and generating
  synthetic data using Gaussian Mixture Models (GMM) to substitute for unavailable
  labeled target domain data.
---

# Domain Adaptation Framework for Turning Movement Count Estimation with Limited Data

## Quick Facts
- **arXiv ID:** 2503.20113
- **Source URL:** https://arxiv.org/abs/2503.20113
- **Reference count:** 12
- **Primary result:** Achieves lowest MAE and RMSE values for turning movement count estimation using domain adaptation with synthetic data generation

## Executive Summary
This study introduces a domain adaptation framework for estimating turning movement counts (TMCs) at intersections using traffic controller event-based data, road infrastructure data, and point-of-interest (POI) data. The framework addresses data scarcity by leveraging labeled source domain data and generating synthetic data using Gaussian Mixture Models (GMM) to substitute for unavailable labeled target domain data. A novel Gradient Boosting with Balanced Weighting (GBBW) model is employed to estimate TMCs, prioritizing relevant information by assigning higher weights to similar data instances. Evaluated on 30 intersections in Tucson, Arizona, the framework achieved the lowest Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) values compared to state-of-the-art models, with MAE of 12.29 for left-turn, 34.39 for through, and 16.17 for right-turn movements, and RMSE of 15.73 for left-turn, 43.90 for through, and 20.08 for right-turn movements.

## Method Summary
The framework uses a three-stage approach: first, Lasso Regression selects significant features from traffic controller event data, infrastructure data, and POI data; second, Information-theoretic metric learning (ITML) identifies source instances most similar to unlabeled target data, and a Gaussian Mixture Model (GMM) generates synthetic labeled data to substitute for missing target labels; third, Gradient Boosting with Balanced Weighting (GBBW) estimates TMCs by training on both source data and synthetic data, with adaptive weighting to prioritize relevant instances. The method was validated using leave-one-intersection-out cross-validation across 30 intersections in Tucson, Arizona.

## Key Results
- Lowest MAE and RMSE values compared to state-of-the-art models for TMC estimation
- MAE of 12.29 for left-turn, 34.39 for through, and 16.17 for right-turn movements
- RMSE of 15.73 for left-turn, 43.90 for through, and 20.08 for right-turn movements

## Why This Works (Mechanism)

### Mechanism 1: Statistical Substitution via Synthetic Data Generation
The framework addresses the absence of labeled data in the target domain by generating a synthetic proxy that statistically approximates target conditions. The Information-theoretic Metric Learning (ITML) algorithm identifies source instances most similar to the unlabeled target data. A Gaussian Mixture Model (GMM) then learns the distribution of these matched source instances and generates synthetic labeled samples to serve as a stand-in for the missing labeled target data required for fine-tuning.

### Mechanism 2: Gradient Boosting with Balanced Weighting (GBBW)
Performance improves because the model dynamically prioritizes source instances that are most relevant to the target intersection's characteristics. The GBBW extends standard Gradient Boosting by integrating a weighting parameter ($\alpha$). It calculates pseudo-residuals for both the source and the synthetic target data. By assigning higher loss weights to source instances that resemble the synthetic target data, the regressor is forced to learn boundaries that are generalizable to the target domain, rather than overfitting to the bulk of the source data.

### Mechanism 3: Feature Space Alignment
Effective transfer is contingent on reducing the complexity of the input space to only those features that maintain stable predictive power across intersections. Lasso Regression (L1 regularization) aggressively shrinks coefficients of irrelevant features to zero. This removes noise and retains transferable features. ITML then learns a Mahalanobis distance metric that pulls these feature distributions of the source and target closer together.

## Foundational Learning

- **Concept:** **Domain Adaptation vs. Transfer Learning**
  - **Why needed here:** To understand why the authors cannot simply train on one intersection and test on another (covariate shift). You must grasp that DA specifically seeks to align the feature distributions ($P(X)$) of the source and target.
  - **Quick check question:** Why does the paper use ITML and GMM instead of just training a generic XGBoost model on all 29 source intersections?

- **Concept:** **Metric Learning (Mahalanobis Distance)**
  - **Why needed here:** The ITML component is the "brain" that decides what constitutes a "similar" traffic pattern. Understanding that it learns a distance metric (matrix $A$) rather than using raw Euclidean distance is vital for debugging matching failures.
  - **Quick check question:** How does the Mahalanobis distance used in ITML differ from a standard Euclidean distance in terms of handling correlated features like "green time" and "detector counts"?

- **Concept:** **Synthetic Data Generation (GMM)**
  - **Why needed here:** The paper relies on GMM to "invent" training data for the target.
  - **Quick check question:** Why is a Gaussian Mixture Model suitable for traffic data compared to a single Gaussian distribution? (Hint: Think of distinct traffic states like "peak" vs. "off-peak").

## Architecture Onboarding

- **Component map:** Input Layer (Traffic Event Logs + Infrastructure Data + POI Data) -> Pre-Processor (Lasso Regression) -> Domain Matcher (ITML) -> Augmentor (GMM) -> Estimator (GBBW)
- **Critical path:** The accuracy of the final TMC estimate relies most heavily on the ITML matching step. If the matched source data does not actually resemble the target, the GMM will generate garbage data, and the GBBW will optimize for the wrong distribution.
- **Design tradeoffs:**
  - Complexity vs. Stability: Increasing GMM components allows for capturing complex traffic modes but risks overfitting to noise. The paper settles on 2-5 components.
  - Alpha ($\alpha$) Sensitivity: The weighting parameter $\alpha$ controls the source/target balance. The study shows a "safe zone" between 0 and 0.9, with catastrophic failure at 1.0.
- **Failure signatures:**
  - High RMSE on "Through" movements: Expect this to be the hardest to estimate due to higher volume variance compared to Left/Right turns.
  - Performance Spikes: If validation error fluctuates wildly, check the alpha parameter or the volume of synthetic samples, as the model may be overfitting to the synthetic target.
- **First 3 experiments:**
  1. Baseline Sanity Check: Replicate the "Through Movement" estimation using standard XGBoost vs. the proposed ITMLGMM-GBBW on a single intersection to verify the claimed MAE reduction.
  2. Ablation on Alpha: Run the framework with $\alpha=0$, $\alpha=0.5$, and $\alpha=0.9$ to reproduce the performance curve and confirm the model degrades at the boundaries.
  3. Feature Audit: Inspect the Lasso output to verify that "Through movement detector occupancy time" is indeed the dominant feature for Through movements before trusting the model's interpretability.

## Open Questions the Paper Calls Out
- How do external factors like weather conditions, traffic incidents, and special events impact the TMC estimation accuracy of the proposed framework?
- Can the framework maintain high estimation accuracy during off-peak hours and weekends?
- Is the domain adaptation framework effective for cross-city knowledge transfer where source and target domains differ significantly in driver behavior or infrastructure standards?

## Limitations
- The framework's reliance on domain adaptation assumes sufficient similarity between source and target intersections, which may not hold for geographically or functionally diverse networks
- The ITML algorithm's performance depends heavily on the quality of similar/dissimilar pair generation, which is not fully specified in the methodology
- The synthetic data generation approach may introduce artifacts if the GMM components poorly capture real traffic distribution multimodality

## Confidence
- **High Confidence:** Core DA framework design and overall performance improvements (MAE/RMSE reductions)
- **Medium Confidence:** Specific hyperparameter choices (GMM components, alpha values) and their optimal ranges
- **Low Confidence:** ITML implementation details and synthetic data quality validation

## Next Checks
1. Test ITML convergence stability across different initialization methods and constraint specifications
2. Evaluate synthetic data quality by comparing generated distributions against held-out real target data
3. Conduct ablation studies on feature importance rankings to verify Lasso selection robustness