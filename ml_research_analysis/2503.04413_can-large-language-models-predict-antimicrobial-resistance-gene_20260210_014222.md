---
ver: rpa2
title: Can Large Language Models Predict Antimicrobial Resistance Gene?
arxiv_id: '2503.04413'
source_url: https://arxiv.org/abs/2503.04413
tags:
- sequence
- language
- sequences
- resistance
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study shows that generative large language models can effectively
  classify DNA sequences for antimicrobial resistance prediction, offering flexibility
  comparable to or better than traditional encoder-based models. Experiments with
  models like LLaMA 3.1 and ChatGPT 4-mini revealed that performance improves when
  supplementary text (e.g., BLASTn search results) is provided alongside DNA sequences,
  with accuracy increasing from near zero to over 93% after fine-tuning.
---

# Can Large Language Models Predict Antimicrobial Resistance Gene?

## Quick Facts
- **arXiv ID**: 2503.04413
- **Source URL**: https://arxiv.org/abs/2503.04413
- **Reference count**: 9
- **Primary result**: Generative LLMs can classify DNA sequences for AMR prediction with accuracy over 93% after fine-tuning and improved with BLASTn context

## Executive Summary
This study demonstrates that generative large language models can effectively classify DNA sequences for antimicrobial resistance prediction, offering flexibility comparable to or better than traditional encoder-based models. Experiments with models like LLaMA 3.1 and ChatGPT 4-mini revealed that performance improves when supplementary text (e.g., BLASTn search results) is provided alongside DNA sequences, with accuracy increasing from near zero to over 93% after fine-tuning. Generative models also handled cases where the same sequence had different labels, demonstrating adaptability to diverse labeling environments.

## Method Summary
The study evaluates generative LLMs (LLaMA 3.1 8B, ChatGPT 4-mini, Claude 3.5) on AMR DNA classification using three approaches: base prompting, retrieval-augmented prompting with BLASTn context, and LoRA fine-tuning. Models were tested on MEGARes and CARD databases, with accuracy, F1, and unclassified rates as metrics. Prompt templates required models to select drug classes from lists, and label extraction from verbose outputs used an auxiliary model. The study compared results against encoder models like DNABERT and explored cross-dataset generalization.

## Key Results
- Accuracy improved from near 0% to over 93% after LoRA fine-tuning on AMR datasets
- BLASTn context augmentation significantly reduced unclassified rates (e.g., from 97% to 73% for LLaMA 3.1)
- Generative models handled cases with multiple or unseen labels better than fixed-output encoders
- Cross-dataset performance showed 0.23-0.50 accuracy on unseen labels without retraining

## Why This Works (Mechanism)

### Mechanism 1: Context-Augmented In-Context Learning via BLASTn Retrieval
Providing retrieved similar sequences and their annotations as textual context enables generative LLMs to classify DNA sequences without parameter updates. The BLASTn search results include gene names, alignment lengths, e-values, and sequence matches. The generative model attends to this structured text alongside the query sequence, leveraging semantic patterns between described gene functions and resistance classes to predict labels.

### Mechanism 2: Parameter-Efficient Fine-Tuning via LoRA
Low-Rank Adaptation enables domain adaptation of general-purpose LLMs to DNA classification with minimal parameter updates. LoRA freezes pretrained weights and injects trainable low-rank decomposition matrices into attention layers. This allows the model to learn DNA sequence-to-label mappings while preserving general language capabilities.

### Mechanism 3: Label Flexibility via Generative Output Space
Decoder-based generative models handle multi-label and unseen label scenarios better than fixed-output encoder classifiers. Encoder models output fixed-dimensional logits over predefined classes. Generative models produce tokens that can express any label in the prompt vocabulary, including novel combinations or hierarchically different labels.

## Foundational Learning

- **K-mer vs. BPE Tokenization for DNA**
  - Why needed here: The paper compares encoder models (DNABERT uses k-mers; DNABERT-2 uses BPE) against generative LLMs that process DNA as character strings. Understanding tokenization helps diagnose why base models fail without context.
  - Quick check question: How would "ATGCGAT" be tokenized differently under 3-mer sliding windows vs. BPE trained on genomic data?

- **Encoder-Only vs. Decoder-Only Transformer Architectures**
  - Why needed here: The paper explicitly contrasts BERT-style encoders with GPT-style decoders. Encoders produce contextualized embeddings for classification heads; decoders generate tokens autoregressively.
  - Quick check question: Why can a decoder model output a previously unseen label without retraining, while an encoder classifier cannot?

- **Retrieval-Augmented Generation (RAG) Pattern**
  - Why needed here: The BLASTn + prompt approach is a form of RAG. Understanding retrieval, reranking, and context window management is essential for reproducing results.
  - Quick check question: If BLASTn returns 50 results but your context window only fits 5, what criteria would you use to select which to include?

## Architecture Onboarding

- **Component map:** DNA sequence input -> BLASTn retrieval module -> Prompt constructor -> Generative LLM -> Optional LoRA fine-tuning adapter -> Output parser

- **Critical path:**
  1. Set up BLASTn database (MEGARes/CARD) and query interface
  2. Design prompt template (see Appendix A.1, A.2 for examples)
  3. Run zero-shot baseline to measure unclassified rate
  4. Add BLASTn context and measure improvement
  5. If F1 < 0.7, proceed to LoRA fine-tuning with labeled data

- **Design tradeoffs:**
  - Base model size vs. latency: 8B-4bit quantized LLaMA is faster but requires fine-tuning; Claude 3.5 API has better zero-shot but no fine-tuning control
  - BLASTn K value: More results improve context but consume tokens; fewer may miss critical matches
  - Fine-tuning data: MEGARes and CARD have different label ontologies—choose based on deployment target

- **Failure signatures:**
  - 100% unclassified rate -> model refusing to predict (insufficient context or prompt unclear)
  - High accuracy but low recall -> model over-selecting majority class
  - Parse failures -> verbose outputs not matching extraction logic; implement robust label extraction

- **First 3 experiments:**
  1. Zero-shot baseline: Prompt with DNA sequence only, measure unclassified rate and F1. Expect near-zero for ChatGPT 4-mini, per Table 2.
  2. Retrieval augmentation: Add top-5 BLASTn results to prompt, compare F1 improvement. Target: accuracy jump from ~0.0 to ~0.78 as reported.
  3. LoRA fine-tuning: Fine-tune LLaMA 3.1 8B-4bit on MEGARes labels, evaluate on held-out test set and cross-dataset on CARD labels. Target: F1 ~0.51 on in-distribution, ~0.23 on cross-dataset.

## Open Questions the Paper Calls Out

- How does generative LLM performance on DNA sequence classification scale when expanding beyond antimicrobial resistance genes to a wider range of DNA sequences and gene categories?
- How can the accuracy and reliability of extracting structured class labels from verbose generative model outputs be systematically improved?
- What mechanisms enable generative LLMs to effectively integrate textual BLASTn metadata with raw DNA sequences to improve classification accuracy?
- How do generative LLMs compare specifically to Nucleotide Transformer on antimicrobial resistance gene classification under identical experimental conditions?

## Limitations

- Label extraction method from model outputs is not fully specified, creating uncertainty about true accuracy of zero-shot baselines
- Performance gains from BLASTn context depend heavily on database quality and may not transfer to novel sequences with few database matches
- Cross-dataset generalization was only tested between MEGARes and CARD with different label ontologies

## Confidence

- **High confidence**: Fine-tuning results showing accuracy improvements from near-zero to >93% are well-supported by experimental design
- **Medium confidence**: Retrieval-augmented learning mechanism is plausible but exact contribution of BLASTn context vs prompt engineering is not isolated
- **Medium confidence**: Claim about superior handling of multiple/unseen labels is supported by cross-dataset results but would benefit from more systematic testing

## Next Checks

1. **Label extraction validation**: Implement and test multiple label extraction methods (regex, classification model, threshold-based selection) on the same zero-shot outputs to quantify the impact of extraction uncertainty on reported metrics.

2. **Cross-dataset generalization stress test**: Systematically evaluate the fine-tuned models on 3-5 additional AMR databases with different label ontologies to quantify true generalization capabilities beyond the single CARD→MEGARes comparison.

3. **BLASTn context ablation study**: Compare performance using (a) BLASTn context, (b) randomly sampled similar sequences without AMR labels, and (c) synthetic context to isolate the contribution of retrieved metadata versus the attention mechanism itself.