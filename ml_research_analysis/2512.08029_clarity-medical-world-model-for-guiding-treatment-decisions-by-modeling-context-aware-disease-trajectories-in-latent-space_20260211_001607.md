---
ver: rpa2
title: 'CLARITY: Medical World Model for Guiding Treatment Decisions by Modeling Context-Aware
  Disease Trajectories in Latent Space'
arxiv_id: '2512.08029'
source_url: https://arxiv.org/abs/2512.08029
tags:
- survival
- latent
- clinical
- clarity
- treatment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLARITY is a medical world model that forecasts disease evolution
  directly within a structured latent space, explicitly integrating temporal and clinical
  contexts to model treatment-conditioned progression as interpretable trajectories.
  By avoiding diffusion-based reconstruction and instead focusing on latent-space
  transitions, CLARITY captures physiologically meaningful changes while reducing
  computational cost.
---

# CLARITY: Medical World Model for Guiding Treatment Decisions by Modeling Context-Aware Disease Trajectories in Latent Space

## Quick Facts
- arXiv ID: 2512.08029
- Source URL: https://arxiv.org/abs/2512.08029
- Authors: Tianxingjian Ding; Yuanhao Zou; Chen Chen; Mubarak Shah; Yu Tian
- Reference count: 40
- Outperforms recent MeWM by 12% and all other medical-specific large language models, achieving 55.6% F1-score

## Executive Summary
CLARITY is a medical world model that forecasts disease evolution directly within a structured latent space, explicitly integrating temporal and clinical contexts to model treatment-conditioned progression as interpretable trajectories. By avoiding diffusion-based reconstruction and instead focusing on latent-space transitions, CLARITY captures physiologically meaningful changes while reducing computational cost. It links predictions to decisions via an inverse survival evaluation, enabling iterative therapy refinement. On the MU-Glioma-Post dataset, CLARITY outperforms recent MeWM by 12% and surpasses all other medical-specific large language models, achieving 55.6% F1-score.

## Method Summary
CLARITY operates as a four-component system: a frozen MRI encoder (BrainIAC) maps images to latent space, a therapy agent (GPT-4o) proposes treatments from clinical context, an Actor module (4-layer Transformer) predicts post-treatment latent states conditioned on temporal and clinical embeddings, and a survival predictor (cross-attention) estimates risk scores. The model is trained end-to-end with combined losses (L1 latent reconstruction, soft-label contrastive, Cox, Brier) and uses an iterative feedback loop (K=3 iterations) where survival predictions refine subsequent therapy proposals. Training uses MU-Glioma-Post (203 patients, 654 MRIs) and UCSF-ALPTDG datasets with joint optimization across all components.

## Key Results
- Outperforms recent MeWM by 12% and all other medical-specific large language models, achieving 55.6% F1-score
- Achieves C-index of 0.7856 on survival prediction task
- Demonstrates diminishing returns in iterative refinement beyond K=3 iterations (F1 55.6% at K=3 vs 55.4% at K=4)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Modeling disease progression as smooth trajectories in a structured latent space preserves physiological dynamics better than stochastic pixel-space diffusion
- **Mechanism**: The architecture bypasses high-cost, stochastic denoising steps typical of diffusion models. Instead, it uses a Transformer-based predictor to forecast the differential between pre- and post-treatment latent states ($\hat{z}_{post} - z_{pre}$). This ensures temporal consistency and reduces artifacts
- **Core assumption**: The latent space captures sufficient physiological information to model disease evolution without requiring pixel-perfect image reconstruction at every step
- **Evidence anchors**:
  - [abstract] "avoiding diffusion-based reconstruction and instead focusing on latent-space transitions, CLARITY captures physiologically meaningful changes while reducing computational cost"
  - [section 1] "inherent stochastic sampling disrupts temporal consistency and causal reasoning... emphasis on appearance reconstruction over learning physiologically meaningful transitions"
  - [corpus] "Pre to Post-Treatment Glioblastoma MRI Prediction using a Latent Diffusion Model" (Contrast: This paper explicitly avoids the diffusion approach cited in neighbor literature)

### Mechanism 2
- **Claim**: Explicitly encoding temporal intervals ($\Delta t$) and multimodal clinical context (genomics, demographics) enables patient-specific trajectory forecasting rather than population-level averaging
- **Mechanism**: The model injects continuous time embeddings (sinusoidal encoding) and serialized clinical text embeddings into the Actor module. This conditions the latent transition, allowing the model to differentiate short-term treatment response from long-term evolution based on individual biological profiles
- **Core assumption**: Standard text encoders (e.g., MedGemma) can effectively serialize complex genomic and clinical histories into vectors that align with imaging latent spaces
- **Evidence anchors**:
  - [section 3.3] "encode the time gap $\Delta t$ using sinusoidal embeddings... This encoding provides the Post-Treatment Latent Predictor with explicit temporal awareness"
  - [section 4.5] Table 2 shows adding Clinical Context improves Recall (43.6% $\to$ 52.8%), validating that biological signals guide faithful simulations
  - [corpus] "Generative Modeling of Clinical Time Series..." supports the difficulty of irregular sampling which this mechanism addresses

### Mechanism 3
- **Claim**: An iterative feedback loop connecting survival predictions back to a therapy proposal agent creates a "prediction-to-decision" system that outperforms single-pass inference
- **Mechanism**: The "Inverse Survival Evaluation" loop works as follows: 1) MLLM proposes therapies; 2) Actor predicts risk scores; 3) Risk scores are fed back as context to the MLLM to refine the next set of proposals. This iteratively minimizes the predicted risk score
- **Core assumption**: The MLLM (GPT-4o) can interpret numeric risk feedback and adhere to safety constraints $\Omega$ to navigate the action space effectively without formal gradient-based optimization
- **Evidence anchors**:
  - [abstract] "links predictions to decisions via an inverse survival evaluation, enabling iterative therapy refinement"
  - [section 3.5] "Step 3 & 4... results of risk score are then be integrated into the current accumulated survival feedback... for $\pi_{MLLM}$ to refine subsequent therapy generation"
  - [section 4.5] Table 3 shows performance peaking at Iteration 3 (F1 55.6%) vs Iteration 1 (53.1%)

## Foundational Learning

- **Concept**: **Survival Analysis (Cox Proportional Hazards)**
  - **Why needed here**: The model is supervised not by classification labels, but by survival times and event indicators. Understanding how the Cox partial likelihood loss ranks risk is essential to debug the "Survival Predictor"
  - **Quick check question**: How does the model handle "censored" data (patients who left the study before an event occurred)?

- **Concept**: **Latent Space Dynamics (World Models)**
  - **Why needed here**: Unlike autoencoders that reconstruct inputs, this model predicts *future* latent states. You must understand how to train a model to predict $\hat{z}_{t+1}$ given $z_t$ and action $a$, without decoding to pixels during the roll-out
  - **Quick check question**: What is the advantage of predicting the *residual* ($\Delta z$) versus predicting the absolute state directly?

- **Concept**: **Soft-Label Contrastive Learning**
  - **Why needed here**: The paper uses a contrastive loss based on the semantic similarity of treatment text embeddings, not hard positive/negative pairs. This structures the latent space so similar treatments result in similar trajectories
  - **Quick check question**: Why use KL divergence between text-similarity distributions and latent-similarity distributions rather than a simple Triplet Loss?

## Architecture Onboarding

- **Component map**: MRI Encoder (BrainIAC) -> Therapy Agent (GPT-4o) -> Actor (Transformer) -> Survival Predictor (Cross-Attn)
- **Critical path**: The inference bottleneck is the **Inverse Evaluation Loop** (Section 3.5). The system is not a single feed-forward pass; it requires $K=3$ iterations of [MLLM Proposal $\to$ Actor Scoring $\to$ Feedback Update]. Latency depends largely on the MLLM API calls
- **Design tradeoffs**:
  - **Latent vs. Pixel**: The paper trades pixel-level interpretability (visualizing tumor shrinkage explicitly) for computational speed (sub-second vs. 38s for diffusion) and physiological consistency
  - **Hard vs. Soft Constraints**: Safety rules $\Omega$ are enforced via prompt engineering and rule-based filtering in the loop, rather than being hard-coded into the network weights
- **Failure signatures**:
  - **Latent Drift**: If the L1 loss on $\hat{z}_{post}$ is high, the predicted trajectory may leave the valid latent distribution, making the survival score noise
  - **Safety Violation**: If the MLLM "hallucinates" a clinically incompatible drug mix that passes the rule-based filter $\Omega$
  - **Flat Feedback**: If the Actor outputs similar risk scores for all proposed therapies, the feedback loop provides no gradient for the MLLM to improve
- **First 3 experiments**:
  1. **Sanity Check - Latent Validity**: Train the Post-Treatment Predictor on fixed time steps. Verify that $\hat{z}_{post}$ minimizes L1 loss against ground truth latents before adding the survival head
  2. **Ablation - Context**: Run the model with zeroed-out temporal embeddings ($\Delta t = 0$) vs. full sinusoidal encoding to quantify the "Temporal Context" gain reported in Table 2
  3. **Loop Limit Test**: Run the Inverse Evaluation for $K=1$ to $K=5$ steps. Plot the Risk Score vs. $K$ to verify the "diminishing returns" at $K=4$ mentioned in Section 4.5

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How robust is CLARITY when deployed across external clinical centers with varying imaging protocols, scanner manufacturers, and patient demographics?
- **Basis in paper**: [explicit] The authors state in the Limitations section that the model is trained on two specific glioma cohorts and that "performance on new clinical centers, imaging protocols, or patient demographics is not yet validated"
- **Why unresolved**: The paper evaluates on MU-Glioma-Post and UCSF-ALPTDG, but domain shift remains a known barrier for medical AI, and the specific architectural sensitivity to MRI protocol variations was not tested
- **What evidence would resolve it**: Zero-shot or fine-tuned evaluation results on out-of-distribution glioma datasets (e.g., different hospitals or MRI sequences) showing stable F1-scores and C-index performance

### Open Question 2
- **Question**: Can the reliance on manually defined safety constraints ($\Omega$) be replaced or augmented by learned safety mechanisms to prevent sub-optimal or invalid therapy proposals?
- **Basis in paper**: [explicit] The authors note that "The policy agent ($\pi_{LLM}$) is constrained by a predefined set of medical rules ($\Omega$). An incomplete $\Omega$ could lead to sub-optimal or invalid therapy proposals"
- **Why unresolved**: The current framework depends on hard-coded rules to ensure clinical validity; if this rulebase is incomplete, the model lacks an intrinsic "medical common sense" to reject dangerous combinations autonomously
- **What evidence would resolve it**: Ablation studies removing specific rules to see if the model learns to reject invalid therapies via the survival predictor or latent space alone, or the integration of a learned safety layer that outperforms the static rulebase

### Open Question 3
- **Question**: Does the Inverse Survival Evaluation loop guarantee convergence to a global optimum for treatment selection, or does it suffer from instability in complex multi-combination spaces?
- **Basis in paper**: [inferred] Table 3 shows that increasing the iteration number from $K=3$ to $K=4$ results in a performance drop (F1 55.6% $\to$ 55.4%), which the authors attribute to "diminishing returns" or "noise"
- **Why unresolved**: This suggests the feedback loop may not stably refine proposals indefinitely, potentially oscillating or drifting when exploring the treatment space beyond a few iterations
- **What evidence would resolve it**: Analysis of the loss landscape or trajectory of the risk scores over many iterations ($K>5$) to determine if the drop is statistical noise or a sign of optimization instability

## Limitations
- The model is evaluated only on glioma datasets, limiting generalizability to other cancer types
- The iterative therapy refinement loop depends heavily on GPT-4o's capabilities and safety constraints that are not fully specified
- The latent space dynamics, while efficient, sacrifice pixel-level interpretability of tumor changes

## Confidence
- **High confidence**: The architectural design choices (latent space modeling, temporal context encoding, iterative feedback loop) are well-specified and logically coherent
- **Medium confidence**: Performance metrics are convincing but limited to single cancer type; the safety constraint framework Ω lacks complete specification
- **Low confidence**: The generalization potential to other disease domains and the robustness of the iterative loop under different MLLM implementations remain uncertain

## Next Checks
1. **Cross-domain validation**: Test the model architecture on a non-glioma oncology dataset (e.g., lung or breast cancer) to assess generalizability beyond the current MU-Glioma-Post dataset
2. **Safety constraint stress test**: Systematically evaluate the inverse survival loop with deliberately problematic therapy proposals to verify that the constraint framework Ω effectively prevents clinically unsafe recommendations
3. **Latent space interpretability audit**: Perform controlled experiments varying treatment parameters to verify that the latent trajectories correspond to known biological responses (e.g., confirming that aggressive treatments produce larger latent shifts)