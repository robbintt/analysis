---
ver: rpa2
title: 'From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation'
arxiv_id: '2511.12832'
source_url: https://arxiv.org/abs/2511.12832
tags:
- steer
- support
- disclosure
- baseline
- politeness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of instilling nuanced, human-like
  emotional expression in large language models (LLMs), which is critical for socially
  sensitive applications like mental health support and negotiation. The proposed
  method, STAR (Steering via Attribution and Representation), uses attribution patching
  to identify key intervention points in the model and applies contrastive activation
  vectors to steer LLM behavior toward desired emotional traits.
---

# From Passive to Persuasive: Steering Emotional Nuance in Human-AI Negotiation

## Quick Facts
- arXiv ID: 2511.12832
- Source URL: https://arxiv.org/abs/2511.12832
- Reference count: 30
- Introduces STAR method to steer LLM emotional nuance via attribution patching and contrastive activation vectors

## Executive Summary
This paper tackles the challenge of imbuing large language models with nuanced, human-like emotional expressionâ€”crucial for applications like mental health support and negotiation. The proposed STAR (Steering via Attribution and Representation) method leverages attribution patching to identify intervention points in LLMs, then applies contrastive activation vectors to steer emotional traits. Evaluated on emotional support and negotiation tasks, STAR significantly enhances positive sentiment, empathy-related language, and first-person pronoun usage while maintaining fluency. The approach outperforms baselines and shows generalization across conversational settings.

## Method Summary
STAR combines attribution patching and contrastive activation vectors to steer LLM behavior toward desired emotional traits. Attribution patching identifies key intervention points in the model, while contrastive activation vectors guide the steering process. This targeted activation steering enhances emotional characteristics in LLM outputs, particularly for tasks requiring empathy and nuanced expression. The method is designed to maintain fluency and coherence while altering emotional tone.

## Key Results
- Targeted activation steering significantly enhances emotional characteristics, including positive sentiment and empathy-related keywords
- Increases first-person pronoun usage, indicating more personal and engaging responses
- Outperforms baseline approaches in emotional support and negotiation tasks while maintaining fluency and coherence

## Why This Works (Mechanism)
STAR works by identifying critical intervention points in LLMs using attribution patching, then applying contrastive activation vectors to steer the model's emotional expression. This approach allows precise control over emotional nuance without disrupting the model's overall fluency. By focusing on attribution-based interventions, the method can effectively target specific emotional traits, such as empathy or positivity, in generated text.

## Foundational Learning
- **Attribution Patching**: Identifies key model components responsible for specific behaviors; needed to pinpoint intervention points for emotional steering
  - Quick check: Verify attribution scores align with expected emotional outputs
- **Contrastive Activation Vectors**: Guide model behavior toward desired traits by contrasting positive and negative examples
  - Quick check: Confirm vectors effectively shift model outputs toward target emotions
- **Emotional Trait Classification**: Categorizes emotional expressions (e.g., empathy, positivity) to define steering targets
  - Quick check: Validate classification accuracy on benchmark datasets
- **Fluency Preservation**: Ensures steered outputs remain coherent and natural-sounding
  - Quick check: Use perplexity or human evaluation to assess output quality
- **Generalization Across Tasks**: Tests method's effectiveness beyond initial evaluation domains
  - Quick check: Apply STAR to new conversational settings (e.g., conflict resolution)

## Architecture Onboarding

### Component Map
STAR -> Attribution Patching -> Intervention Points -> Contrastive Activation Vectors -> Steered Outputs

### Critical Path
1. Identify intervention points via attribution patching
2. Generate contrastive activation vectors
3. Apply vectors to steer model outputs
4. Evaluate emotional and fluency metrics

### Design Tradeoffs
- **Precision vs. Generalization**: Fine-grained intervention points may limit cross-domain applicability
- **Computational Overhead**: Attribution patching and vector generation add processing time
- **Emotional Specificity vs. Flexibility**: Highly targeted steering may reduce adaptability to new contexts

### Failure Signatures
- Loss of fluency or coherence in steered outputs
- Inconsistent emotional expression across turns
- Overfitting to specific emotional traits, reducing versatility

### First Experiments to Run
1. Validate attribution patching accuracy on a held-out dataset
2. Test contrastive vector effectiveness in steering a simple sentiment task
3. Measure fluency impact using perplexity and human evaluation

## Open Questions the Paper Calls Out
None

## Limitations
- Robustness and generalizability across diverse emotional contexts and domains remain uncertain
- Reliance on attribution patching and contrastive vectors may introduce computational overhead and fragility
- Limited qualitative assessment of nuanced conversational dynamics and potential biases

## Confidence

| Claim | Label |
|-------|-------|
| Effective steering of emotional traits in targeted tasks | High |
| Maintenance of fluency and coherence | Medium |
| Generalizability across diverse emotional contexts | Low |

## Next Checks
1. Test STAR's performance on a broader range of conversational tasks beyond emotional support and negotiation, including conflict resolution and casual dialogue, to assess robustness.
2. Evaluate the method's effectiveness across multiple LLM architectures (e.g., different transformer sizes or fine-tuned variants) to confirm intervention point universality.
3. Conduct a detailed qualitative analysis of conversational dynamics, including edge cases and potential biases introduced by emotional steering, to ensure safe and ethical deployment.