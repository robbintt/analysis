---
ver: rpa2
title: An LLM-Guided Tutoring System for Social Skills Training
arxiv_id: '2501.09870'
source_url: https://arxiv.org/abs/2501.09870
tags:
- skills
- training
- social
- scenarios
- student
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GLOSS, a framework using large language models
  to create an instructor-in-the-loop tutoring system for social skills training.
  The system enables instructors to dynamically design realistic scenarios without
  technical skills, allows students to practice through conversational simulations
  with immediate feedback, and provides visualization tools for delayed feedback.
---

# An LLM-Guided Tutoring System for Social Skills Training

## Quick Facts
- arXiv ID: 2501.09870
- Source URL: https://arxiv.org/abs/2501.09870
- Reference count: 6
- Primary result: Framework enabling instructor-LLM co-creation of social skills training scenarios with dynamic branching and immediate feedback

## Executive Summary
This paper introduces GLOSS, a framework using large language models to create an instructor-in-the-loop tutoring system for social skills training. The system enables instructors to dynamically design realistic scenarios without technical skills, allows students to practice through conversational simulations with immediate feedback, and provides visualization tools for delayed feedback. Unlike traditional intelligent tutoring systems, GLOSS supports both scripted and open-ended interactions, automatically generating new scenario branches when needed. The framework aims to bridge the gap between classroom training and real-world social skill application by providing interactive, adaptive environments for students to rehearse challenging interpersonal situations.

## Method Summary
The paper presents GLOSS as a framework architecture for social skills training that leverages large language models for both content generation and real-time adaptation. The system separates content authoring (handled by instructors with LLM assistance) from content delivery (handled by the conversational simulator). Instructors create scenarios using a narrative graph structure where nodes represent interaction states and edges represent response-dependent transitions. The LLM assists in generating dialogue, suggesting branches, or creating entire scenarios from prompts. During student sessions, the system dynamically generates new branches when student responses don't match existing options, and provides immediate feedback through a separate LLM prompt evaluation. The architecture includes a front-end builder for scenario creation, a narrative graph store, a conversational simulator, a feedback generator, and an analysis tool for performance visualization.

## Key Results
- GLOSS enables instructors to create and edit social skills training scenarios without technical expertise through LLM-assisted co-creation
- The system supports both scripted dialogue (for consistency) and open-ended interactions (for realism) within the same framework
- Dynamic branch generation allows the system to handle unexpected student responses while maintaining pedagogical relevance
- Dual feedback modalities (immediate LLM evaluation and delayed visualization) support both real-time skill correction and reflective learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instructor-LLM co-creation reduces content authoring barriers while preserving pedagogical control.
- Mechanism: The front-end builder provides a narrative graph interface where instructors define nodes (scenarios) and edges (transitions), while the LLM assists by generating dialogue, suggesting branches, or creating entire scenarios from prompts. This separates domain expertise (instructor) from content generation labor (LLM).
- Core assumption: Instructors can effectively evaluate and refine LLM-generated content without technical training.
- Evidence anchors:
  - [abstract]: "instructors can easily co-create scenarios with a large language model without technical skills"
  - [section]: "Instructors can choose to use a pre-built template with scripted dialogue, create a scenario from scratch, generate a scenario using a prompt to an LLM, or combine these methods."
  - [corpus]: Related paper "Building Knowledge from Interactions" addresses LLM-based adaptive tutoring architectures, suggesting this pattern has emerging precedent, though no direct comparison studies exist.
- Break condition: If LLM-generated scenarios consistently misalign with learning objectives and instructors lack efficient correction tools, the co-creation benefit collapses into rework overhead.

### Mechanism 2
- Claim: Real-time branch generation enables handling of unexpected student responses without exhaustive pre-scripting.
- Mechanism: When a student's response doesn't match existing graph transitions, the LLM interprets the response intent and dynamically generates new nodes/edges. This preserves conversational flow while maintaining narrative coherence with the original scenario.
- Core assumption: LLM intent classification and branch generation are sufficiently accurate to maintain pedagogical relevance in real-time.
- Evidence anchors:
  - [abstract]: "the system generates new scenario branches in real time when existing options do not fit the student's response"
  - [section]: "These new transitions are added to the narrative graph by the LLM based on the intent of the user's response."
  - [corpus]: GENEVA paper (Leandro et al. 2024, cited in paper) demonstrates LLM-generated branching narratives, providing precedent but not validation for training contexts.
- Break condition: If dynamically generated branches drift from learning objectives or produce inconsistent character behavior, student trust and training value degrade.

### Mechanism 3
- Claim: Dual feedback modalities (immediate + delayed visualization) support both real-time skill correction and reflective learning.
- Mechanism: An independent LLM prompt evaluates student responses during simulation for immediate feedback. Separately, the analysis tool visualizes the student's path through the narrative graph, enabling post-hoc review by both student and instructor for iterative scenario refinement.
- Core assumption: Immediate LLM feedback is sufficiently accurate and actionable for students to adjust responses mid-conversation.
- Evidence anchors:
  - [abstract]: "provide immediate feedback, and visualize performance for both students and instructors"
  - [section]: "Feedback on the student's response is provided through an LLM using an independent prompt" and "The analysis tool visualizes a user's training conversation by illustrating their path through the narrative graph, serving as a mechanism to provide delayed feedback"
  - [corpus]: Weak direct evidence—corpus lacks comparative studies on immediate vs. delayed feedback in LLM tutoring systems.
- Break condition: If feedback quality is inconsistent (e.g., vague or incorrect suggestions), students may develop maladaptive strategies or disengage.

## Foundational Learning

- Concept: **Narrative Graph Structure**
  - Why needed here: GLOSS represents scenarios as directed graphs where nodes = scenarios/states and edges = response-dependent transitions. Understanding this is essential for authoring, debugging, and extending scenarios.
  - Quick check question: Given a customer service scenario with 3 possible user responses per interaction, how many nodes exist at depth 2 if all paths are unique?

- Concept: **Social Skills Training (SST) Components**
  - Why needed here: GLOSS implements behavioral SST methods (instruction, modeling, rehearsal, feedback, reinforcement). Recognizing these helps align system capabilities with pedagogical goals.
  - Quick check question: Which SST component does the conversational simulator primarily deliver, and which does the analysis tool support?

- Concept: **LLM Prompt Isolation for Feedback**
  - Why needed here: GLOSS uses an "independent prompt" for feedback generation, separating roleplay generation from evaluation. This architectural choice affects latency, cost, and feedback consistency.
  - Quick check question: Why might using the same LLM call for both dialogue generation and feedback evaluation create coherence problems?

## Architecture Onboarding

- Component map:
  - Front-end Builder -> Narrative Graph Store -> Conversational Simulator -> Student Interface
  - Conversational Simulator -> Feedback Generator -> Student Interface
  - Analysis Tool <- Narrative Graph Store <- Conversational Simulator

- Critical path:
  1. Instructor creates/loads scenario via Front-end Builder → stored as Narrative Graph
  2. Student initiates session → Conversational Simulator loads graph
  3. Student responds → Simulator matches response to existing edge OR triggers LLM branch generation
  4. Feedback Generator evaluates response → returns immediate feedback to student
  5. Session ends → Analysis Tool renders path for delayed review

- Design tradeoffs:
  - **Strict vs. flexible dialogue**: Scripted dialogue ensures consistency but limits realism; open-ended LLM generation increases authenticity but risks objective drift
  - **Pre-scripted vs. dynamic branches**: Exhaustive pre-scripting guarantees quality but doesn't scale; dynamic generation scales but requires guardrails
  - **Single vs. dual LLM calls**: Combined generation+feedback reduces latency/cost; separation improves feedback independence

- Failure signatures:
  - **Branch explosion**: Unconstrained dynamic generation creates unwieldy graphs—monitor node count growth per session
  - **Feedback-action mismatch**: If feedback doesn't align with available response options, students experience confusion
  - **Avatar inconsistency**: Character responses contradicting prior turns indicate prompt engineering or context window issues

- First 3 experiments:
  1. **Baseline branch accuracy test**: Present 20 student responses to the system; measure percentage correctly matched to existing edges vs. triggering unnecessary new branch generation. Target: >80% correct classification.
  2. **Feedback quality human evaluation**: Have 3 instructors blind-rate LLM-generated immediate feedback on 15 student responses for accuracy, actionability, and tone. Establish inter-rater reliability before drawing conclusions.
  3. **Instructor authoring time comparison**: Measure time to create equivalent scenarios using (a) template-only, (b) LLM-assisted generation, (c) manual from scratch. N=5 instructors, counterbalanced order. This establishes the productivity claim empirically.

## Open Questions the Paper Calls Out
None

## Limitations
- The paper presents GLOSS as a novel framework without providing empirical validation of its core mechanisms
- Critical uncertainties remain about LLM-generated branch accuracy, instructor authoring efficiency gains, and the pedagogical effectiveness of immediate feedback
- The separation of feedback generation into an "independent prompt" is theoretically sound but unvalidated in this context

## Confidence
- **High confidence**: The architectural feasibility of instructor-LLM co-creation for narrative graph construction (based on established patterns in related work)
- **Medium confidence**: The technical viability of real-time branch generation for unexpected responses (supported by precedent but not validated for training contexts)
- **Low confidence**: The effectiveness of immediate LLM feedback for skill acquisition (lacks comparative studies or empirical validation)

## Next Checks
1. **Branch generation accuracy validation**: Test whether LLM-generated branches maintain pedagogical consistency with original scenarios across 100+ diverse student responses
2. **Instructor productivity measurement**: Conduct controlled study comparing scenario creation time between template-only, LLM-assisted, and manual approaches with 10+ instructors
3. **Feedback quality assessment**: Implement blind evaluation protocol where 5+ instructors rate LLM feedback quality against human-generated feedback across 50+ student responses, measuring inter-rater reliability and effect size