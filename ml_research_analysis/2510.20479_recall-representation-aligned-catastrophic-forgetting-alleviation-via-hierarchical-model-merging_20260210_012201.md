---
ver: rpa2
title: 'RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical
  Model Merging'
arxiv_id: '2510.20479'
source_url: https://arxiv.org/abs/2510.20479
tags:
- merging
- task
- recall
- knowledge
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RECALL, a data-free model merging framework
  that leverages layer-wise hidden representations to mitigate catastrophic forgetting
  during continual learning. By extracting and aligning intermediate representations
  over clustered typical samples, RECALL computes adaptive, layer-specific merging
  weights that preserve domain-general features in shallow layers while enabling task-specific
  adaptation in deeper layers.
---

# RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging

## Quick Facts
- arXiv ID: 2510.20479
- Source URL: https://arxiv.org/abs/2510.20479
- Reference count: 22
- Primary result: Achieves up to 7.86% average performance gains on unseen tasks across five NLP tasks

## Executive Summary
RECALL addresses catastrophic forgetting in continual learning through a novel data-free model merging framework. By leveraging layer-wise hidden representations extracted from clustered typical samples, RECALL computes adaptive, layer-specific merging weights that balance domain-general feature preservation with task-specific adaptation. The framework demonstrates consistent superiority over state-of-the-art baselines across multiple NLP tasks, showing particular strength in generalization to unseen tasks while maintaining knowledge retention.

## Method Summary
RECALL introduces a hierarchical model merging approach that operates without access to original training data. The method extracts intermediate representations from model checkpoints, clusters typical samples to identify representative patterns, and computes layer-specific merging weights based on representation alignment. Shallow layers retain domain-general features while deeper layers adapt to task-specific requirements, creating a balanced model that mitigates catastrophic forgetting across sequential learning tasks.

## Key Results
- Outperforms state-of-the-art baselines in knowledge retention and generalization
- Achieves average performance gains of up to 7.86% on unseen tasks
- Demonstrates scalability and effectiveness in multi-domain settings
- Robust performance in sequential fine-tuning without task labels or historical data

## Why This Works (Mechanism)
RECALL's effectiveness stems from its representation-aligned merging strategy that operates at the intermediate feature level rather than just the parameter level. By analyzing hidden representations across layers, the framework identifies which features are domain-general versus task-specific, allowing for intelligent weight allocation during merging. This hierarchical approach ensures that fundamental representations learned in early layers are preserved while enabling adaptation in deeper layers where task-specific features are encoded.

## Foundational Learning

**Representation Alignment**: Why needed - To identify which features should be preserved versus adapted across different model checkpoints; Quick check - Verify that aligned representations maintain semantic similarity across domains.

**Layer-wise Analysis**: Why needed - Different layers capture different levels of abstraction requiring distinct merging strategies; Quick check - Confirm that shallow layer representations are more domain-general than deep layer representations.

**Clustered Typical Sampling**: Why needed - To extract representative patterns without requiring full dataset access; Quick check - Ensure clusters capture meaningful variation across the task space.

## Architecture Onboarding

**Component Map**: Data-free representation extraction -> Sample clustering -> Layer-wise representation alignment -> Adaptive weight computation -> Hierarchical model merging

**Critical Path**: The representation alignment step is critical, as it directly determines the merging weights and ultimately the quality of the final model.

**Design Tradeoffs**: Balances between preserving domain-general knowledge (favoring shallow layers) and enabling task-specific adaptation (favoring deep layers), requiring careful weight calibration.

**Failure Signatures**: Poor clustering of typical samples leads to misaligned representations, resulting in suboptimal merging weights and degraded model performance.

**First Experiments**:
1. Test representation alignment quality across different layer depths
2. Evaluate clustering effectiveness with varying numbers of typical samples
3. Validate merging weight sensitivity to different alignment thresholds

## Open Questions the Paper Calls Out
The paper acknowledges uncertainty regarding the true data-free nature of the approach, specifically whether the "clustered typical samples" constitute implicit data sampling. The scalability of the hierarchical merging strategy for extremely large architectures and heterogeneous task modalities remains an open question requiring further investigation.

## Limitations
- Unclear whether the approach truly operates in data-free scenarios
- Hierarchical merging may face scalability challenges with very large model architectures
- Limited validation across non-NLP domains and heterogeneous task types

## Confidence

**High confidence**: Experimental results showing consistent performance improvements across five NLP tasks with average gains up to 7.86% on unseen tasks.

**Medium confidence**: Claims about preserving domain-general features in shallow layers while enabling task-specific adaptation in deeper layers, though supported by methodology, could benefit from more detailed feature space analysis.

**Low confidence**: Assertions about scalability and robustness in sequential fine-tuning without task labels require further validation, particularly for heterogeneous task distributions and non-NLP applications.

## Next Checks

1. Test RECALL's performance in truly data-free scenarios where no access to any training data is available, evaluating whether clustered typical samples can generate meaningful representations without implicit data sampling.

2. Conduct ablation studies on different layer configurations and merging strategies to determine optimal hierarchical structures for various task combinations and model architectures.

3. Validate RECALL's effectiveness across different domains (computer vision, speech processing) and task types (classification, generation, structured prediction) to assess generalizability beyond the presented NLP tasks.