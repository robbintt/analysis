---
ver: rpa2
title: A Unifying View of Coverage in Linear Off-Policy Evaluation
arxiv_id: '2601.19030'
source_url: https://arxiv.org/abs/2601.19030
tags:
- coverage
- linear
- which
- where
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a novel finite-sample analysis of LSTDQ, a
  canonical algorithm for off-policy evaluation (OPE) in linear function approximation.
  The key contribution is a new coverage parameter called "feature-dynamics coverage"
  that addresses limitations of previous definitions and unifies understanding across
  different settings.
---

# A Unifying View of Coverage in Linear Off-Policy Evaluation

## Quick Facts
- arXiv ID: 2601.19030
- Source URL: https://arxiv.org/abs/2601.19030
- Reference count: 40
- Primary result: New finite-sample analysis of LSTDQ with feature-dynamics coverage parameter that unifies understanding across tabular, abstraction, and linear settings

## Executive Summary
This paper provides a novel finite-sample analysis of LSTDQ, a canonical algorithm for off-policy evaluation (OPE) in linear function approximation. The key contribution is a new coverage parameter called "feature-dynamics coverage" that addresses limitations of previous definitions and unifies understanding across different settings. The authors show that LSTDQ's error bounds depend on this parameter, which can be interpreted as linear coverage in an induced dynamical system for feature evolution. The analysis subsumes special cases like state abstractions and recovers standard linear coverage under Bellman completeness, finally providing a unified framework for understanding coverage in linear OPE. The paper also establishes dimension-free error bounds and connects the coverage parameter to marginalized importance sampling methods.

## Method Summary
The paper analyzes LSTDQ for OPE under linear realizability, where the algorithm estimates matrices Σ̂, Σ̂_cr, Â, and b̂ from data to compute θ̂_lstd = Â^{-1}b̂. The key innovation is introducing the feature-dynamics coverage parameter C^π_φ, which measures the linear coverage of the feature evolution process under the target policy. This parameter replaces traditional concentrability measures and provides dimension-free error bounds. The analysis uses an instrumental variables interpretation to show that LSTDQ's error depends on C^π_φ rather than the minimum eigenvalue of A, which addresses fundamental limitations of previous analyses.

## Key Results
- Introduces feature-dynamics coverage C^π_φ as a unifying coverage parameter that subsumes tabular, abstraction, and linear coverage notions
- Provides dimension-free error bounds for LSTDQ using C^π_φ that scale with 1/n rather than 1/√(n)
- Establishes population and empirical bounds for LSTDQ error that depend on C^π_φ rather than σ_min(A)
- Shows that C^π_φ simplifies to standard linear coverage under Bellman completeness

## Why This Works (Mechanism)
The paper works by reframing the LSTDQ analysis through an instrumental variables lens. Instead of directly analyzing the error in estimating Q^π under the Bellman operator T^π, the authors analyze the error in estimating a compressed version B^π that acts on features. This decoupling allows them to show that the error depends on the coverage of the feature evolution process rather than the raw state-action space. The key insight is that C^π_φ measures how well the data distribution supports the feature trajectories induced by the target policy in the compressed dynamics, providing a more natural and interpretable coverage measure for linear OPE.

## Foundational Learning
- **Concept: Discounted Occupancy Measure (μ^π)**
  - Why needed here: The core problem of OPE is to estimate the value J(π), which is an expectation under the target policy's discounted occupancy measure. Understanding how μ^π relates to the data distribution μ_D is fundamental to the concept of coverage.
  - Quick check question: If a policy visits states not seen in the data, what happens to the density ratio μ^π / μ_D and, consequently, to standard coverage parameters?

- **Concept: Bellman Operator and Fixed Point**
  - Why needed here: LSTDQ is designed to find the fixed point of the Bellman operator T^π. The algorithm's mechanics and the realizability assumption are framed in terms of this operator. The distinction between analyzing error under T^π vs. a compressed B^π is the paper's central contribution.
  - Quick check question: The LSTDQ solution Q̂_lstd is an approximation of Q^π. What is the formal relationship between Q^π and T^π?

- **Concept: Instrumental Variables (IV)**
  - Why needed here: The authors derive their key bound using an IV interpretation of LSTDQ, where φ(s,a) instruments the temporal difference feature. Grasping this analogy is key to understanding how they decouple the analysis from the problematic σ_min(A).
  - Quick check question: In a regression Y = Xβ + ε, what problem does an instrumental variable Z solve, and how does this map to the LSTDQ setting where Y is the reward and X contains the random next-state feature?

## Architecture Onboarding
- **Component map**: Data generation -> Moment estimation (Σ̂, Σ̂_cr, Â, b̂) -> Matrix inversion (Â^{-1}b̂) -> Value estimation (φ₀^⊤ θ̂_lstd) -> Coverage parameter computation (C^π_φ)
- **Critical path**: Data generation -> Moment estimation (Σ̂, Σ̂_cr, Â, b̂) -> Matrix inversion (Â^{-1}b̂) -> Value estimation (φ₀^⊤ θ̂_lstd). The critical analysis path involves connecting the initial feature φ₀ through the inverse matrix A^{-1} to form the coverage parameter C^π_φ.
- **Design tradeoffs**:
  - Realizability vs. Completeness: The analysis works under the minimal assumption of realizability, providing a more general guarantee but with a more complex coverage parameter C^π_φ. Bellman completeness simplifies C^π_φ to a more interpretable form but is a stronger assumption.
  - Population vs. Empirical Bound: Theorem 1 (population) offers a dimension-free main term but requires a burn-in period. Theorem 2 (empirical) has no burn-in but scales with dimension d.
- **Failure signatures**:
  - Non-invertible Â matrix: The algorithm fails. The guarantee becomes vacuous (C^π_φ = ∞).
  - Poor Feature Dynamics: If the induced linear system B^π is unstable (ρ(B^π) ≥ 1/γ), the theoretical guarantee may be meaningless, even if the algorithm produces a value.
  - Distribution Shift: The coverage parameter C^π_φ will be large if the target policy's feature path in the compressed dynamics is not well-supported by the data covariance Σ.
- **First 3 experiments**:
  1. Tabular MDP Verification: Run LSTDQ on a small tabular MDP where features are one-hot vectors. Compute both the new C^π_φ and the known aggregated concentrability. Verify they are numerically identical, confirming the theory's subsumption of the tabular case.
  2. Bellman Completeness Check: Use a linear MDP where completeness holds. Compare the empirical coverage C^π_φ computed from data against the standard linear coverage (φ^π)^⊤ Σ^{-1} φ^π. Their close agreement would validate the unification claim under strong assumptions.
  3. Scale Invariance Test: Run LSTDQ with two different feature scalings (e.g., φ and 2φ). Observe that while σ_min(A) changes, the final OPE error and the computed C^π_φ remain consistent, demonstrating the new parameter's improved properties.

## Open Questions the Paper Calls Out
- Can Bellman Residual Minimization (BRM) error bounds be improved to dimension-free "directional bounds" for general non-linear function classes? This is interesting because current BRM bounds act as function-estimation guarantees dependent on the class complexity (log|F|) because the concentration event is independent of the initial state. A directional bound for return estimation would avoid this dependence.
- Can the dependence on 1/λ_min(Σ) in the population bounds be tightened to leverage-score-type conditions? While the paper removes the dependence on 1/σ_min(A), the rates still depend on 1/λ_min(Σ), "though we expect that this can be further tightened to leverage-score-type conditions."
- Can the feature-dynamics coverage parameter be used to establish unified sample-efficient guarantees for offline policy optimization (learning) in the linear setting? The paper resolves this for evaluation, leaving the extension to policy optimization—which involves searching over a space of policies—unaddressed.

## Limitations
- The theoretical framework assumes access to population moments or large-sample estimates, which may not hold in practice with limited data.
- The feature-dynamics coverage parameter C^π_φ requires inverting the matrix A, which can be ill-conditioned or singular in finite samples.
- The analysis assumes linear realizability of Q^π, which may not hold in complex domains.
- While the paper claims unification across settings, empirical validation on real-world domains is absent.

## Confidence
- **High Confidence**: The theoretical derivation connecting LSTDQ error bounds to the feature-dynamics coverage parameter is mathematically rigorous and sound. The subsumption of existing coverage notions (tabular, state abstraction, Bellman completeness) under this unified framework is correctly established.
- **Medium Confidence**: The interpretation of C^π_φ as "linear coverage in an induced dynamical system" is conceptually compelling but requires careful verification in practice, as computing this parameter involves estimating population quantities that may be challenging with finite data.
- **Low Confidence**: Claims about the practical utility of this new coverage parameter for algorithm design and data collection strategies remain speculative without empirical validation.

## Next Checks
1. Implement the feature-dynamics coverage computation on a tabular MDP and verify numerical agreement with known aggregated concentrability measures.
2. Test the sensitivity of C^π_φ to feature scaling and compare against traditional concentrability measures to validate improved scale-invariance properties.
3. Conduct experiments on domains where Bellman completeness holds and empirically verify that C^π_φ simplifies to the standard linear coverage form.