---
ver: rpa2
title: Foundations of Top-$k$ Decoding For Language Models
arxiv_id: '2505.19371'
source_url: https://arxiv.org/abs/2505.19371
tags:
- decoding
- bregman
- dual
- primal
- top-k
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper develops a theoretical foundation for top-k decoding\
  \ in language models, viewing decoding as the recovery of sparse probability distributions.\
  \ The authors propose a framework based on minimizing Bregman divergences with \u2113\
  0 regularization, considering both primal and dual formulations."
---

# Foundations of Top-$k$ Decoding For Language Models

## Quick Facts
- arXiv ID: 2505.19371
- Source URL: https://arxiv.org/abs/2505.19371
- Reference count: 40
- This paper develops a theoretical foundation for top-k decoding in language models, viewing decoding as the recovery of sparse probability distributions.

## Executive Summary
This paper provides a theoretical framework for top-k decoding in language models by formulating it as the recovery of sparse probability distributions. The authors show that under mild technical assumptions, the optimal decoding strategies are greedy and the loss function is discretely convex in k, enabling efficient binary search for the optimal k. The framework generalizes top-k decoding and identifies new decoding strategies with distinct behaviors, providing a principled approach to token selection in language model inference.

## Method Summary
The authors propose a framework based on minimizing Bregman divergences with ℓ0 regularization, considering both primal and dual formulations. They show that under mild technical assumptions, the optimal decoding strategies are greedy (selecting top-k probabilities) and the loss function is discretely convex in k, enabling efficient binary search for the optimal k. The framework generalizes top-k decoding and identifies new decoding strategies with distinct behaviors.

## Key Results
- Optimal decoding strategies are greedy (selecting top-k probabilities)
- Loss function is discretely convex in k, enabling efficient binary search
- α-Bregman decoding shows particularly strong results at higher temperatures

## Why This Works (Mechanism)
The theoretical framework treats language model decoding as a sparse probability distribution recovery problem. By formulating this as minimizing Bregman divergences with ℓ0 regularization, the authors establish conditions under which greedy selection of top-k tokens becomes optimal. The discretely convex nature of the loss function in k allows for efficient optimization, explaining why top-k decoding performs well in practice.

## Foundational Learning
1. **Bregman Divergences**: Measures of difference between probability distributions that are crucial for the theoretical analysis. Why needed: Provides the loss function for measuring reconstruction error. Quick check: Verify that common choices like KL divergence satisfy required properties.
2. **ℓ0 Regularization**: Penalty on the number of non-zero elements in the probability distribution. Why needed: Encourages sparsity in token selection. Quick check: Confirm that this regularization leads to discrete optimization problems.
3. **Discrete Convexity**: Property of the loss function with respect to k that enables efficient optimization. Why needed: Allows binary search for optimal k values. Quick check: Test convexity properties on sample probability distributions.
4. **Primal-Dual Formulations**: Mathematical frameworks for optimization problems. Why needed: Enables different perspectives on the decoding problem. Quick check: Verify equivalence between primal and dual solutions.

## Architecture Onboarding

Component Map: Language Model Output -> Probability Distribution -> Bregman Divergence + ℓ0 Regularization -> Top-k Selection -> Token Sampling

Critical Path: The critical path involves computing the probability distribution from the language model, applying the Bregman divergence and regularization, selecting the top-k tokens, and then sampling from this restricted distribution.

Design Tradeoffs: The main tradeoff is between exploration (sampling from a larger set of tokens) and exploitation (selecting only the most probable tokens). The choice of Bregman divergence and regularization strength determines where the method falls on this spectrum.

Failure Signatures: Poor performance may occur when the probability distribution cannot be well-approximated by its top-k elements, particularly in cases with many similarly likely tokens or when the language model's confidence is distributed across many tokens.

First Experiments:
1. Compare top-k decoding with α-Bregman decoding across different temperature settings
2. Test the binary search optimization for finding optimal k values on various probability distributions
3. Evaluate the framework's performance on different types of language model outputs (low confidence vs high confidence)

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- The framework assumes the probability distribution can be well-approximated by its top-k elements
- The theoretical analysis relies on specific properties of Bregman divergences and ℓ0 regularization
- Experimental validation is limited to open-ended text generation and mathematical problem solving

## Confidence
- Optimal greedy strategies: Medium
- Discretely convex loss function: Medium
- Experimental performance claims: Medium
- Temperature-dependent performance: Medium

## Next Checks
1. Test proposed decoding strategies across a broader range of NLP tasks, including structured prediction and conditional generation
2. Analyze the impact of varying regularization parameter and temperature jointly to understand their interaction
3. Conduct ablation studies to isolate contributions of Bregman divergence choice, regularization strength, and top-k selection mechanism