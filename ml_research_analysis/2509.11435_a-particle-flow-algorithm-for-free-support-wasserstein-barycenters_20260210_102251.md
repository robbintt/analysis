---
ver: rpa2
title: A Particle-Flow Algorithm for Free-Support Wasserstein Barycenters
arxiv_id: '2509.11435'
source_url: https://arxiv.org/abs/2509.11435
tags:
- barycenter
- wasserstein
- support
- gradient
- optimal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a particle-flow algorithm for computing Wasserstein
  barycenters with free support, avoiding entropic regularization by leveraging the
  formal Riemannian geometry of Wasserstein space. The method updates barycenter atoms
  as particles advected by averaged optimal-transport displacements, using barycentric
  projections of optimal transport plans in place of Monge maps when the latter do
  not exist.
---

# A Particle-Flow Algorithm for Free-Support Wasserstein Barycenters

## Quick Facts
- **arXiv ID:** 2509.11435
- **Source URL:** https://arxiv.org/abs/2509.11435
- **Reference count:** 8
- **Primary result:** A particle-flow algorithm for computing Wasserstein barycenters with free support, avoiding entropic regularization by leveraging the formal Riemannian geometry of Wasserstein space.

## Executive Summary
This paper introduces a particle-flow algorithm for computing Wasserstein barycenters with free support, avoiding entropic regularization by leveraging the formal Riemannian geometry of Wasserstein space. The method updates barycenter atoms as particles advected by averaged optimal-transport displacements, using barycentric projections of optimal transport plans in place of Monge maps when the latter do not exist. Theoretical guarantees include consistency of barycentric projections, monotone descent and convergence to stationary points, stability with respect to perturbations of inputs, and resolution consistency as the number of atoms increases. Empirical studies on averaging distributions, Bayesian posterior aggregation, image prototypes and classification, and large-scale clustering demonstrate accuracy and scalability, positioning the approach as a principled alternative to both linear programming and regularized solvers.

## Method Summary
The algorithm computes free-support Wasserstein barycenters by treating the space of probability measures as a Riemannian manifold and performing gradient descent. It initializes barycenter support via k-means on pooled input supports, then iteratively solves discrete optimal transport (OT) problems to obtain optimal plans between the current barycenter and each input measure. Barycentric projections of these plans serve as displacement fields for the particles, which are updated via an explicit Euler step on the averaged displacement field. The method uses exact OT solvers (not Sinkhorn) and updates support points to minimize the sum of squared Wasserstein distances without entropic regularization.

## Key Results
- Proposes a particle-flow algorithm for Wasserstein barycenters that avoids entropic regularization while maintaining computational feasibility
- Provides theoretical guarantees including consistency of barycentric projections, monotone descent, convergence to stationary points, and stability with respect to input perturbations
- Demonstrates empirical accuracy and scalability across applications including Bayesian posterior aggregation, image classification, and large-scale clustering
- Positions the approach as a principled alternative to both linear programming and regularized solvers

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The algorithm decreases the barycenter objective by treating the space of probability measures as a Riemannian manifold and performing gradient descent.
- **Mechanism:** The method leverages Otto calculus (Section 2.2), where the gradient of the squared Wasserstein distance $W_2^2(\mu, \nu)$ corresponds to the negative logarithmic map, $-\log_\mu(\nu)$. By iteratively moving the barycenter estimate in the direction of the weighted sum of transport maps to input measures, the scheme approximates a geodesic convex optimization.
- **Core assumption:** The objective function is smooth enough for gradient descent logic to apply, and the iterates remain in a compact subset of the Wasserstein space.
- **Evidence anchors:** [abstract]: "follows the formal Riemannian geometry of Wasserstein space... Riemannian gradient descent approach." [Section 3.1]: Revisits gradient descent using the Riemannian gradient $\text{grad}_\mu F_\nu(\mu) = -2\log_\mu(\nu)$. [Corpus]: The paper "Computing Wasserstein Barycenters through Gradient Flows" provides external context for this optimization landscape.
- **Break condition:** If the input measures are not in $P_2(\mathbb{R}^d)$ (finite second moments) or the step size $\eta > 1/2$, the descent property is not guaranteed.

### Mechanism 2
- **Claim:** Using barycentric projections of optimal transport plans provides a valid surrogate for the derivative when deterministic Monge maps do not exist.
- **Mechanism:** For discrete empirical measures, a unique transport map rarely exists. The algorithm solves for an optimal plan $\hat{\Gamma}$ (a coupling matrix) and computes a barycentric projection $T_n(z_i) = \frac{1}{v_i} \sum_j \hat{\Gamma}_{i,j} x_{n,j}$ (Section 3.2.2). This serves as the "velocity field" for the particle $z_i$.
- **Core assumption:** The optimal transport plans are locally unique and vary smoothly (Lipschitz) with respect to the support points, avoiding discontinuities in the gradient approximation.
- **Evidence anchors:** [abstract]: "barycentric projections of optimal transport plans used in place of Monge maps." [Section 3.2.2]: Defines the surrogate displacement $\tilde{\log}_{\bar{\mu}}^{(n)}(z_i) := T_n(z_i) - z_i$. [Corpus]: Related works on "Differentially Private Wasserstein Barycenters" also rely on similar projection mechanics, validating the robustness of this approximation.
- **Break condition:** If the optimal plan $\hat{\Gamma}$ is not unique (e.g., degenerate cost matrices), the barycentric projection may oscillate or fail to approximate a consistent gradient.

### Mechanism 3
- **Claim:** Advecting particles via an explicit Euler step on the averaged displacement field converges to a stationary point.
- **Mechanism:** The support points (atoms) $z_i$ are updated via $z_i^{(k+1)} = (1-2\eta)z_i^{(k)} + 2\eta \sum \pi_n T_n^{(k)}(z_i^{(k)})$. With step size $\eta=1/2$, this simplifies to moving each particle to the weighted average of its projections (Section 3.2.3).
- **Core assumption:** The sequence of transport plans remains stable, and the initialization is sufficiently close to the basin of attraction (the problem is non-convex).
- **Evidence anchors:** [Section 3.2.3]: Explicit update rule using the weighted average of barycentric projections. [Theorem 4.2]: Proves convergence to stationary points under Lipschitz assumptions on the projection.
- **Break condition:** The mechanism finds a *stationary* point, not necessarily the global minimum. Poor initialization (e.g., far from the union of input supports) can lead to suboptimal local minima.

## Foundational Learning

- **Concept: Kantorovich vs. Monge Formulations**
  - **Why needed here:** The paper relies on the Kantorovich formulation (plans/couplings) because the Monge formulation (deterministic maps) generally fails for discrete measures of unequal mass.
  - **Quick check question:** Why does the algorithm compute a coupling matrix $\Gamma$ instead of a function $T$ directly?

- **Concept: Otto Calculus (Riemannian Geometry of $P_2$)**
  - **Why needed here:** This provides the theoretical justification for the "gradient" direction. It explains why $T(x) - x$ acts as a tangent vector (logarithmic map) pointing "downhill."
  - **Quick check question:** In Otto's view, what mathematical object represents the direction of steepest descent for the squared Wasserstein distance?

- **Concept: Barycentric Projection**
  - **Why needed here:** This is the specific operator used to convert a "many-to-many" transport plan into a deterministic displacement vector for a single particle.
  - **Quick check question:** If a particle $z$ splits its mass 30/70 to targets $x_1$ and $x_2$, where does the barycentric projection point?

## Architecture Onboarding

- **Component map:** Input measures -> Discrete OT Solver -> Barycentric Projector -> Particle Integrator
- **Critical path:** The OT Solver is the computational bottleneck. Each iteration requires solving $N$ separate linear programs between the current barycenter and the input measures.
- **Design tradeoffs:**
  - Unregularized vs. Regularized: This method avoids entropic regularization (like Sinkhorn), preserving "sharp features" but sacrificing the GPU-efficiency of matrix-scaling algorithms.
  - Particle Count ($m$): Higher $m$ increases resolution but slows the OT solver (complexity depends on $m \times m_n$).
- **Failure signatures:**
  - Oscillation: Caused by non-unique optimal plans; the gradient approximation fluctuates between iterations.
  - Mode Collapse: Initialization far from data support may result in a degenerate barycenter (single point) if the gradient vanishes prematurely.
- **First 3 experiments:**
  1. **Gaussian Barycenters (Simulation):** Verify accuracy by comparing the empirical barycenter of Gaussians against the closed-form "Oracle" solution to quantify discretization error.
  2. **Bayesian Posterior Aggregation (WASP):** Test on Bayesian Linear Regression to see if the barycenter of subset posteriors recovers the full-data posterior mean and covariance.
  3. **MNIST Prototypes:** Visualize the "particle flow" on images to confirm that the unregularized method captures sharp geometric features (digit strokes) without the blurring caused by entropic regularization.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can non-asymptotic error bounds be established that disentangle the effects of discretization, barycentric projection bias, and sampling noise to provide rigorous guidance for selecting the barycenter support size?
- **Basis in paper:** [explicit] Section 6 states that "non-asymptotic bounds that disentangle discretization, projection, and sampling errors would provide practical guidance for choosing decent support sizes."
- **Why unresolved:** The paper proves asymptotic consistency (Theorem 4.5) and stability (Proposition 4.4), but does not derive explicit rates or inequalities quantifying the trade-offs involved in choosing the number of atoms $m$ for finite samples.
- **What evidence would resolve it:** Derivation of a high-probability upper bound for the error $W_2(\bar{\mu}_m, \bar{\mu}^*)$ expressed as a function of the support size $m$, number of input measures $N$, and sample sizes $m_n$.

### Open Question 2
- **Question:** Can the stability guarantees for the barycenter functional (Proposition 4.4) be extended to measures with unbounded support using only finite second moment conditions?
- **Basis in paper:** [explicit] Section 4.3 notes regarding the compact support assumption: "We conjecture that this gives the same type of stability guarantee without requiring bounded support" by bounding differences in terms of second moments.
- **Why unresolved:** The current proof relies on the diameter of a compact ball ($4R\delta$), which becomes unbounded if the support is not restricted; a proof using second moments requires different inequalities.
- **What evidence would resolve it:** A proof showing that $|F_{\nu}(\bar{\mu}) - F_{\mu}(\bar{\mu})| \leq C \cdot \delta$ (or similar) holds under the assumption that the input measures have uniformly bounded second moments rather than compact support.

### Open Question 3
- **Question:** Can the particle-flow algorithm be adapted to compute the Wasserstein median, thereby eliminating the computational bottleneck of nested barycenter computations found in current iteratively reweighted least squares (IRLS) approaches?
- **Basis in paper:** [explicit] Section 6 identifies as a direction for future work applying the approach to "computation of the Wasserstein median... which could eliminate the nested use of barycenter computation within the iteratively reweighted least squares framework."
- **Why unresolved:** The current algorithm minimizes the sum of *squared* Wasserstein distances; the median requires minimizing the sum of distances, which changes the Riemannian gradient structure and flow dynamics.
- **What evidence would resolve it:** A modified particle-flow algorithm designed for the $\ell_1$-type median objective that demonstrably converges to the Wasserstein median without requiring an inner loop of barycenter calculations.

### Open Question 4
- **Question:** Can the proposed particle-flow updates be unrolled as a differentiable layer within deep learning architectures to perform distributional pooling or prototype learning?
- **Basis in paper:** [explicit] Section 6 suggests "unrolling a finite number of our updates yields a barycenter layer for end-to-end training as a distributional pooling or prototype module."
- **Why unresolved:** The current work focuses on the algorithm as a standalone solver; integrating it requires defining explicit backpropagation rules through the discrete optimal transport solver and the particle update steps.
- **What evidence would resolve it:** Implementation of the algorithm as a PyTorch/TensorFlow layer and demonstration of its utility in a downstream task (e.g., prototype classification) where gradients flow through the barycenter computation.

## Limitations
- Computational complexity scales poorly with the number of particles and input measures, as each iteration requires solving multiple exact optimal transport problems
- The algorithm's convergence guarantees depend on Lipschitz continuity of barycentric projections, but the paper does not quantify the rate or establish bounds on how initialization affects convergence to global optima
- The stability analysis assumes local uniqueness of optimal transport plans, but degenerate cost matrices can lead to non-unique plans and oscillating barycentric projections

## Confidence
- **High confidence:** Monotone descent property under Î· < 1/2 and Lipschitz assumptions; consistency results for barycentric projections; resolution consistency as m increases
- **Medium confidence:** Stability with respect to perturbations; convergence to stationary points (guaranteed but without rate)
- **Low confidence:** Global optimality claims; exact computational complexity for large-scale problems

## Next Checks
1. **Convergence Rate Analysis:** Empirically measure how initialization affects convergence speed and final objective value across multiple runs to quantify the basin of attraction size
2. **Scalability Benchmark:** Compare runtime and memory usage against regularized methods (Sinkhorn) on datasets with increasing numbers of atoms and input measures to identify the crossover point where exact OT becomes prohibitive
3. **Degeneracy Stress Test:** Construct synthetic examples with near-degenerate cost matrices to verify whether the algorithm maintains stability or exhibits the predicted oscillations in barycentric projections