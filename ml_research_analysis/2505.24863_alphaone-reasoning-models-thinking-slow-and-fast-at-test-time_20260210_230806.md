---
ver: rpa2
title: 'AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time'
arxiv_id: '2505.24863'
source_url: https://arxiv.org/abs/2505.24863
tags:
- thinking
- reasoning
- slow
- moment
- phase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "AlphaOne introduces a universal framework for modulating reasoning\
  \ progress in large reasoning models (LRMs) by introducing an \u03B1 moment that\
  \ scales the thinking phase by \u03B1\xD7. Within the pre-\u03B1 moment phase, it\
  \ dynamically schedules slow thinking transitions via Bernoulli sampling of reasoning\
  \ transition tokens, and after the \u03B1 moment, it deterministically terminates\
  \ slow thinking with the end-of-thinking token to foster fast reasoning."
---

# AlphaOne: Reasoning Models Thinking Slow and Fast at Test Time

## Quick Facts
- arXiv ID: 2505.24863
- Source URL: https://arxiv.org/abs/2505.24863
- Reference count: 40
- Key outcome: AlphaOne achieves +6.15% accuracy and 14% token reduction compared to baselines

## Executive Summary
AlphaOne introduces a universal framework for modulating reasoning progress in large reasoning models by introducing an α moment that scales the thinking phase. The framework dynamically schedules slow thinking transitions via Bernoulli sampling of reasoning transition tokens before the α moment, then deterministically terminates slow thinking after the α moment to foster fast reasoning. This approach unifies and generalizes monotonic scaling methods by enabling flexible and dense slow-to-fast reasoning modulation across diverse reasoning tasks.

## Method Summary
AlphaOne proposes a novel framework that modulates reasoning speed in large reasoning models through an α moment mechanism. The approach divides the reasoning process into pre-α and post-α phases, where the pre-α phase uses Bernoulli sampling to dynamically schedule slow thinking transitions, while the post-α phase employs deterministic termination of slow thinking with an end-of-thinking token. This framework generalizes existing monotonic scaling methods by providing flexible control over the transition from slow to fast reasoning, enabling improved efficiency without sacrificing reasoning capability.

## Key Results
- Achieves +6.15% accuracy improvement over baseline methods
- Reduces token usage by 14% compared to traditional approaches
- Demonstrates superior reasoning capability across mathematical, coding, and scientific benchmarks

## Why This Works (Mechanism)
The α moment mechanism works by creating a structured transition between slow and fast reasoning phases. During the pre-α phase, Bernoulli sampling introduces stochasticity in transition timing, allowing the model to explore different reasoning depths. The post-α phase enforces deterministic termination, ensuring computational efficiency. This dual-phase approach balances thorough reasoning with practical efficiency constraints, addressing the fundamental trade-off between reasoning quality and computational cost in large reasoning models.

## Foundational Learning

**Large Reasoning Models (LRMs)** - Neural architectures designed for complex reasoning tasks requiring multi-step inference. Needed to understand the target application domain; quick check: verify model architecture supports reasoning token generation.

**Bernoulli Sampling** - Probabilistic method for scheduling transitions between reasoning phases. Required for introducing controlled stochasticity; quick check: confirm sampling probability parameters are properly calibrated.

**α Moment Scaling** - Mechanism for scaling thinking duration by factor α. Central to the framework's functionality; quick check: validate α parameter selection impacts reasoning quality as expected.

**Slow-to-Fast Reasoning Transition** - Controlled shift from detailed to rapid reasoning. Core concept enabling efficiency gains; quick check: measure transition smoothness across different reasoning task complexities.

**End-of-Thinking Token** - Special token triggering deterministic reasoning termination. Essential for post-α phase control; quick check: verify token recognition and proper termination behavior.

## Architecture Onboarding

**Component Map:** Input -> Reasoning Token Generator -> Bernoulli Scheduler -> α Moment Detector -> Fast Reasoning Module -> Output

**Critical Path:** Input → Reasoning Token Generation → Bernoulli Sampling → α Moment Detection → Deterministic Termination → Output Generation

**Design Tradeoffs:** The framework balances reasoning depth (controlled by α) against computational efficiency. Higher α values provide more thorough reasoning but reduce efficiency gains. The Bernoulli sampling introduces controlled randomness that may affect reproducibility but enables better exploration of reasoning paths.

**Failure Signatures:** Poor α parameter selection can lead to either insufficient reasoning depth or excessive computation. Improper Bernoulli sampling calibration may cause unpredictable reasoning patterns. Missing or misrecognized end-of-thinking tokens can result in incomplete reasoning termination.

**First 3 Experiments:**
1. Validate basic α moment detection across different reasoning task types
2. Test Bernoulli sampling calibration with varying probability parameters
3. Measure efficiency gains with different α values on simple reasoning benchmarks

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on performance improvements without thoroughly examining potential degradation in reasoning quality when forcing premature termination of slow thinking
- Bernoulli sampling approach may introduce unpredictable reasoning patterns that could affect reliability in critical applications
- Framework's generalization across diverse reasoning tasks and model architectures needs further validation

## Confidence
- **High confidence** in technical framework description and mathematical formulation of α moment mechanism
- **Medium confidence** in claimed performance improvements (+6.15% accuracy, 14% token reduction) due to potential variations in implementation and evaluation protocols
- **Low confidence** in framework's universal applicability across all reasoning domains due to limited evaluation scope

## Next Checks
1. Conduct extensive ablation studies varying the α parameter across different reasoning task types to identify optimal scaling factors for each domain and validate claimed improvements are not task-specific
2. Implement comprehensive qualitative analysis of reasoning quality degradation when forcing early termination of slow thinking, comparing outputs with and without α moment constraints on complex reasoning tasks
3. Test framework performance on multi-modal reasoning tasks and domain-specific applications beyond current mathematical, coding, and scientific benchmarks to assess true universality