---
ver: rpa2
title: Detection and Measurement of Hailstones with Multimodal Large Language Models
arxiv_id: '2510.06008'
source_url: https://arxiv.org/abs/2510.06008
tags:
- hail
- hailstones
- size
- hailstone
- reference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that pretrained multimodal large language
  models can accurately estimate hailstone diameters from social media images without
  fine-tuning. Using a dataset of 474 hailstone images from documented Austrian events
  (2-11 cm diameter range), the researchers compared four state-of-the-art MLLMs using
  two prompting strategies.
---

# Detection and Measurement of Hailstones with Multimodal Large Language Models

## Quick Facts
- **arXiv ID:** 2510.06008
- **Source URL:** https://arxiv.org/abs/2510.06008
- **Reference count:** 19
- **Primary result:** GPT-4o with two-stage prompting achieved 1.12 cm MAE on hailstone diameter estimation from social media images

## Executive Summary
This study demonstrates that pretrained multimodal large language models can accurately estimate hailstone diameters from social media images without fine-tuning. Using a dataset of 474 hailstone images from documented Austrian events (2-11 cm diameter range), the researchers compared four state-of-the-art MLLMs using two prompting strategies. The two-stage prompting approach, which first identifies reference objects before size estimation, reduced mean absolute error by 18.6% compared to single-stage prompts. The best-performing model, GPT-4o with two-stage prompting, achieved a mean absolute error of 1.12 cm and correlation of 0.71 with ground truth measurements. The presence of reference objects, particularly human hands, significantly improved accuracy (0.75 cm MAE) compared to images without clear scale cues (1.73 cm MAE). While all models exhibited systematic underestimation, these off-the-shelf models show promise for complementing traditional hail sensors by extracting quantitative measurements from crowd-sourced imagery, enabling faster and more detailed assessments of severe weather events.

## Method Summary
The researchers used 474 hailstone images from the European Severe Storms Laboratory database (Austria, Jan 2022-Sep 2024) with diameters ranging from 2-11 cm. Four MLLMs (GPT-4o, GPT-4o-mini, Claude-Sonnet 4, Gemini 2.5 Flash Lite) were accessed via LiteLLM API with a 100-token limit. Two prompting strategies were compared: P1 (direct estimation) and P2 (two-stage: first identify reference object, then estimate size). Images were manually annotated for reference objects (hand, coin, ruler, unspecified) and viewing distance. Responses were parsed for the first numeric value, rounded to 0.5 cm, and compared against ground truth measurements to calculate MAE, RMSE, bias, and correlation.

## Key Results
- Two-stage prompting reduced MAE by 18.6% compared to single-stage prompts (P2: 1.18 cm average vs P1: 1.45 cm average)
- GPT-4o with two-stage prompting achieved the best performance: MAE=1.12 cm, correlation=0.71
- Hand reference objects yielded 0.75 cm MAE, compared to 1.73 cm MAE for images without clear scale cues
- All models exhibited systematic underestimation (bias ranging from -0.49 to -1.63 cm)

## Why This Works (Mechanism)

### Mechanism 1: Two-Stage Prompting Decomposition
Decomposing the measurement task into reference object identification followed by size estimation reduces mean absolute error by 18.6% compared to direct single-prompt approaches. The two-stage prompt forces explicit intermediate reasoning—the model first classifies what scale reference exists, then conditionally applies domain knowledge about that object's typical dimensions. This activates chain-of-thought reasoning that grounds the estimation in retrieved world knowledge rather than uncalibrated visual hemorrhage.

### Mechanism 2: Reference Object Scale Calibration
The presence of familiar reference objects, particularly human hands, improves accuracy by ~2.3× (0.75 cm vs 1.73 cm MAE) compared to images without scale cues. MLLMs leverage learned priors about common object sizes from vision-language pre-training. Hands dominate because they co-occur frequently with objects in training data and have low intra-class size variance across adult populations, enabling reliable scale transfer.

### Mechanism 3: Systematic Underestimation Bias
All evaluated MLLMs exhibit consistent negative bias (~-0.7 to -1.63 cm), suggesting shared limitations in depth inference from monocular 2D inputs. Without explicit depth cues or stereo information, models appear to apply conservative priors when visual ambiguity exists—defaulting toward smaller estimates when 3D-to-2D projection relationships are uncertain.

## Foundational Learning

- **Concept: Zero-Shot Visual Reasoning**
  - **Why needed here:** The entire approach relies on MLLMs performing measurement without task-specific fine-tuning. Understanding zero-shot capabilities and limitations explains why off-the-shelf models work and where they fail.
  - **Quick check question:** Can you explain why a model trained on image-caption pairs might generalize to measuring objects it was never explicitly trained to measure?

- **Concept: Chain-of-Thought Prompting**
  - **Why needed here:** The P2 strategy is a form of chain-of-thought reasoning—forcing intermediate reference classification before final estimation. Understanding CoT principles helps generalize this approach to other measurement tasks.
  - **Quick check question:** How does explicitly asking a model to "think step by step" change its internal computation compared to direct prompting?

- **Concept: Visual Grounding and Spatial Priors**
  - **Why needed here:** The mechanism depends on models having learned spatial relationships and object sizes from pre-training. Understanding visual grounding clarifies why hands work better than rulers and why distant hailstones cause failures.
  - **Quick check question:** Why might a model that has seen millions of hand photographs still fail to estimate size when the hand is at an unusual angle?

## Architecture Onboarding

- **Component map:** Social Media / Image Sources → Image Ingestion & Validation → Reference Object Classifier (P2 Step 1) → Size Estimator (P2 Step 2 / P1) → Response Parser & Validator → Ground Truth Labels (ESWD) → Error Analysis: MAE, RMSE, Bias, Correlation

- **Critical path:**
  1. Image quality filtering (remove non-hail, damaged, or inaccessible images)
  2. Reference object detection (P2 Step 1) → returns classification: "hand" | "coin" | "ruler" | "unspecified"
  3. Conditional prompt selection based on reference type (P2 Step 2 has variants for each object class)
  4. Numeric extraction from model output (handle verbose responses; use first number found)
  5. Bias correction (optional post-processing: add ~0.7cm to counter systematic underestimation)

- **Design tradeoffs:**
  - **P1 vs P2:** P1 is simpler (single API call) but P2 reduces MAE by 18.6% and misses by 93% (289→20). Recommendation: Use P2 for production; P1 only for latency-critical applications.
  - **Model selection:** GPT-4o achieves best accuracy (MAE=1.12cm, r=0.71) but is most expensive. GPT-4o-mini shows lowest bias (-0.49cm) with competitive MAE (1.20cm). Recommendation: GPT-4o for research/accuracy-critical; GPT-4o-mini for operational deployment.
  - **Reference requirements:** Filtering for hand-only images improves MAE to 0.75cm but discards 43% of data. Recommendation: Accept all images but weight estimates by reference quality.

- **Failure signatures:**
  - **Non-numeric responses:** GPT-4o P1 had 160 misses; models sometimes "reason" instead of outputting numbers. Mitigation: Robust parsing extracting first float; fallback prompts.
  - **Encoding failures:** Claude API failed on 6 images. Mitigation: Pre-validate image encoding; implement retry with alternative models.
  - **Distance-related failures:** "Majority of response misses are caused by distant hailstones." Mitigation: Add distance estimation step; flag low-confidence predictions.
  - **Underestimation bias:** All models underestimate by 0.49-1.63cm. Mitigation: Apply domain-specific bias correction in post-processing.

- **First 3 experiments:**
  1. **Baseline replication:** Run P1 vs P2 on held-out subset (n=50) to validate 18.6% MAE reduction; measure latency difference.
  2. **Reference object ablation:** Compare accuracy across reference types (hand vs coin vs ruler vs none) on stratified samples (n=25 each); test if providing explicit reference dimensions in prompt improves accuracy for rare objects.
  3. **Bias correction calibration:** Fit linear correction (predicted + bias = actual) on training split; evaluate whether simple additive correction (+0.7cm) or model-specific corrections reduce MAE on test split.

## Open Questions the Paper Calls Out

- **Can an automated pipeline effectively harvest and filter real-time social media imagery for integration into meteorological nowcasting systems?**
  - **Basis in paper:** The abstract and conclusion state that "automated real-time image harvesting from social media... remains an open task" and is the "most critical next step" for operational use.
  - **Why unresolved:** The current study relied on a static, retrospectively collected dataset (ESWD) rather than live data streams, leaving the technical challenge of real-time acquisition and filtering unsolved.
  - **What evidence would resolve it:** A functional system demonstration that ingests live social media feeds during a storm event and produces timely, accurate hail measurements.

- **Do MLLM-based estimation accuracies generalize to hail events in geographic regions with different environmental conditions and social media conventions?**
  - **Basis in paper:** The "Limitations and Future Directions" section notes the dataset is restricted to Austria (2022–2024), which may "limit the generalizability of our findings to regions with different environmental conditions."
  - **Why unresolved:** Visual contexts (backgrounds, lighting) and common reference objects (e.g., specific coin currencies or product packaging) may vary significantly by region, potentially affecting the models' zero-shot performance.
  - **What evidence would resolve it:** Evaluation of the proposed models on crowd-sourced hail datasets from diverse geographic locations (e.g., North America or Asia) showing comparable Mean Absolute Error rates.

- **Can geometric priors or perspective correction techniques effectively mitigate the systematic underestimation bias observed in MLLM size estimations?**
  - **Basis in paper:** The conclusion identifies a consistent negative bias across all models (average -0.7 cm) and explicitly suggests exploring "geometric priors or perspective correction techniques" as future work to address this.
  - **Why unresolved:** The current prompting strategies (P1 and P2) utilize semantic reasoning but lack explicit geometric spatial understanding, leading to consistent size underestimation.
  - **What evidence would resolve it:** A modified processing pipeline incorporating geometric corrections that significantly reduces the negative bias (closer to 0.0 cm) without increasing the variance of estimates.

## Limitations

- **Dataset representativeness:** The study uses Austrian hail events from 2022-2024 with diameters 2-11 cm, which may limit generalizability to other regions or hailstone size distributions.
- **Prompt formulation specificity:** The exact P2 step-2 prompt variants for different reference objects are not fully specified in the paper, creating uncertainty about optimal prompt design.
- **Systematic bias without correction:** While the paper identifies consistent underestimation (-0.49 to -1.63 cm), it doesn't evaluate post-processing calibration to mitigate this bias.

## Confidence

- **High confidence:** Two-stage prompting reduces MAE by 18.6% compared to single-stage (supported by section IV Results: "P2 prompting variants reduced MAE on average by 18.6%")
- **High confidence:** Reference objects improve accuracy (hand: 0.75 cm MAE vs no reference: 1.73 cm MAE) [abstract and Table III]
- **Medium confidence:** GPT-4o achieves best accuracy (MAE=1.12 cm, r=0.71) - based on single evaluation run without reported variance
- **Medium confidence:** Systematic underestimation reflects architectural limitations - observed across all models but mechanism not definitively proven

## Next Checks

1. **Ablation study:** Test P2 step-2 prompt variants by systematically varying the conditional instructions for each reference object type to isolate the contribution of prompt specificity to the 18.6% improvement.
2. **Bias correction evaluation:** Implement and test simple additive bias correction (+0.7cm) and model-specific corrections on held-out data to quantify improvement in MAE and correlation.
3. **Geographic generalization:** Apply the same methodology to hailstone images from non-European datasets (US storm reports, Australian hail events) to assess cross-regional performance and potential cultural/climatic variations in model accuracy.