---
ver: rpa2
title: What Shape Is Optimal for Masks in Text Removal?
arxiv_id: '2511.22499'
source_url: https://arxiv.org/abs/2511.22499
tags:
- mask
- text
- image
- masks
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of text removal from complex
  document images with dense text, an area with limited research compared to simple
  scene text removal. The authors developed a benchmark dataset consisting of 95 document
  images with rich text and high OCR difficulty, along with manually processed text-removed
  outputs.
---

# What Shape Is Optimal for Masks in Text Removal?

## Quick Facts
- **arXiv ID:** 2511.22499
- **Source URL:** https://arxiv.org/abs/2511.22499
- **Authors:** Hyakka Nakada; Marika Kubota
- **Reference count:** 40
- **Primary result:** Character-wise masks with slight enlargement outperform pixel-level stroke-based masks for text removal in complex document images.

## Executive Summary
This study addresses the challenge of text removal from complex document images with dense text, an area with limited research compared to simple scene text removal. The authors developed a benchmark dataset consisting of 95 document images with rich text and high OCR difficulty, along with manually processed text-removed outputs. They found that text removal performance is highly sensitive to mask profile variations, indicating the need for precise mask design. To address this, they proposed a method to model flexible mask profiles using superellipse-based shapes and learn their parameters via Bayesian optimization. Experiments showed that optimizing mask profiles significantly improved text removal performance, measured by Frechet Inception Distance (FID) scores.

## Method Summary
The authors developed a comprehensive approach to optimize mask profiles for text removal in document images. They created a benchmark dataset of 95 complex document images with dense text and manually removed text from these images to serve as ground truth. The proposed method models mask profiles using superellipse shapes, which are parameterized by scale and roundness parameters. These parameters are learned through Bayesian optimization, which searches for the optimal mask profile that minimizes the FID score between the generated text-removed image and the ground truth. The framework evaluates different mask types including character-wise, word-wise, and stroke-level masks, comparing their performance across various document images.

## Key Results
- Character-wise masks with slight enlargement (scale ~1.37) achieved the best FID scores compared to word-wise and stroke-level masks
- Mask profile optimization through Bayesian optimization significantly improved text removal performance
- The optimal mask parameters were found to be sensitive to the specific document images and text characteristics

## Why This Works (Mechanism)
The effectiveness of the proposed method stems from its ability to precisely model the mask profile that best suits the text removal task. By using superellipse shapes, the method can flexibly adjust the mask profile to match the characteristics of the text in document images. The Bayesian optimization framework systematically searches through the parameter space to find the optimal mask profile that minimizes the FID score. This approach is particularly effective because it accounts for the complex nature of document images where text density and layout vary significantly.

## Foundational Learning
- **Superellipse parameterization**: Understanding how to represent mask shapes using mathematical functions with controllable scale and roundness parameters. This is needed to create flexible mask profiles that can adapt to different text characteristics. Quick check: Verify that changing the roundness parameter actually changes the mask shape from rectangular to circular.
- **Bayesian optimization for mask learning**: Grasping the optimization framework that searches for optimal mask parameters based on FID scores. This is needed to systematically find the best mask profile without exhaustive grid search. Quick check: Confirm that the optimization converges to a consistent solution across multiple runs.
- **Frechet Inception Distance (FID)**: Understanding the metric used to evaluate text removal quality by comparing distributions of generated and ground truth images. This is needed to quantify the effectiveness of different mask profiles. Quick check: Verify that lower FID scores correspond to visually better text removal results.

## Architecture Onboarding

**Component Map:** OCR Engine -> Mask Generator -> Inpainting Model -> FID Evaluator -> Bayesian Optimizer

**Critical Path:** OCR detection → Mask profile generation → Image inpainting → FID score calculation → Parameter update

**Design Tradeoffs:** The study uses superellipse shapes for mask profiles, which provide flexibility but may not capture all possible mask geometries. The choice of FID as the optimization metric prioritizes statistical similarity over perceptual quality.

**Failure Signatures:** Poor text removal performance when mask profiles are too small (incomplete text coverage) or too large (excessive background removal). High FID scores indicate unsuccessful text removal or generation of artifacts.

**First Experiments:**
1. Compare FID scores for different superellipse roundness parameters (e.g., 0.5, 1.0, 2.0) on a single document image
2. Test character-wise vs word-wise masks on documents with varying text densities
3. Evaluate the impact of OCR confidence threshold on mask quality and subsequent text removal performance

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Does parameterizing mask profiles to include rotation angles for bounding boxes significantly improve text-removal performance on rotated document images?
- Basis in paper: Section VI states, "One drawback of our method is that we did not care for the rotation of bounding boxes... If Bayesian optimization is applied to masks along rotated boxes, FID scores are expected to improve."
- Why unresolved: The current Type-1 model relies on axis-aligned bounding boxes, which limits optimization accuracy for the rotated text common in practical document images.
- What evidence would resolve it: Extending the parameter space to include orientation and running Bayesian optimization on a dataset containing rotated text to compare resulting FID scores.

### Open Question 2
- Question: How does the optimal mask profile change when optimizing for alternative metrics like CMMD or multi-objective constraints (e.g., latency vs. quality) instead of FID?
- Basis in paper: Section VI suggests, "optimization with other metrics instead of FID is an interesting study. Using an improved metric such as CMMD would also improve... performance."
- Why unresolved: The study optimized exclusively for FID; however, FID may have known biases, and practical applications often require balancing generation quality with processing speed.
- What evidence would resolve it: Re-running the optimization pipeline using CMMD or a cost function combining FID with inference time, and analyzing shifts in the optimal scale and roundness parameters.

### Open Question 3
- Question: Do the optimal mask parameters (scale ~1.37, character-wise) transfer effectively to different generative inpainting architectures beyond the specific model (LaMa) tested?
- Basis in paper: Section V-C notes, "Note that the profile of the optimized masks can vary depending on which text-removal model is targeted."
- Why unresolved: The findings are based on a specific inpainting network; it is unclear if the "slightly larger than font size" heuristic is a universal property or an artifact of the specific model's training data.
- What evidence would resolve it: Applying the identified optimal mask parameters to other state-of-the-art inpainting models (e.g., diffusion-based) and measuring the performance delta against their own optimized parameters.

## Limitations
- The study focuses exclusively on text removal scenarios and may not generalize to other inpainting tasks such as object removal or image restoration.
- The benchmark dataset, while specifically designed for this task with 95 images, is relatively small and may not capture the full diversity of document layouts and text characteristics encountered in real-world applications.
- The use of FID as the primary evaluation metric has known limitations in assessing perceptual quality, and the study does not incorporate human perceptual studies to validate the quantitative findings.

## Confidence
- **Text removal performance is highly sensitive to mask profile variations**: High confidence. The experimental results consistently demonstrate significant FID score differences across mask types and parameters.
- **Character-wise masks with slight enlargement outperform pixel-level stroke-based masks**: High confidence. Multiple experiments and comparisons support this conclusion with substantial performance gaps.
- **Superellipse-based shapes can effectively model flexible mask profiles**: Medium confidence. While the optimization framework shows promise, the specific choice of superellipse may not be optimal for all document types.

## Next Checks
1. Test the proposed mask optimization framework on additional document types and layouts not represented in the current benchmark dataset to assess generalizability.
2. Conduct human perceptual studies to validate that FID improvements correspond to noticeable quality improvements in text removal outputs.
3. Evaluate the approach with alternative mask shape parameterizations beyond superellipses to determine if even better performance is achievable.