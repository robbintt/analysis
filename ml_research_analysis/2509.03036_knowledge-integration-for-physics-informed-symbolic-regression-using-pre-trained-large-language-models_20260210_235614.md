---
ver: rpa2
title: Knowledge Integration for Physics-informed Symbolic Regression Using Pre-trained
  Large Language Models
arxiv_id: '2509.03036'
source_url: https://arxiv.org/abs/2509.03036
tags:
- symbolic
- regression
- arxiv
- data
- gplearn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces an LLM-integrated symbolic regression framework\
  \ that embeds domain knowledge into the search process by adding an LLM-based plausibility\
  \ score to the loss function. Evaluated across three physical scenarios (free fall,\
  \ harmonic motion, damped waves), three SR algorithms (DEAP, gplearn, PySR), and\
  \ three LLMs (Mistral, Llama 2, Falcon), the method consistently improves accuracy,\
  \ with PySR + Mistral achieving the highest R\xB2 scores (up to 0.99) and lowest\
  \ MAE (down to 0.03)."
---

# Knowledge Integration for Physics-informed Symbolic Regression Using Pre-trained Large Language Models

## Quick Facts
- arXiv ID: 2509.03036
- Source URL: https://arxiv.org/abs/2509.03036
- Reference count: 40
- One-line primary result: LLM-guided symbolic regression consistently outperforms baseline SR in accuracy and noise robustness across three physical scenarios and three SR algorithms.

## Executive Summary
This study introduces an LLM-integrated symbolic regression framework that embeds domain knowledge into the search process by adding an LLM-based plausibility score to the loss function. Evaluated across three physical scenarios (free fall, harmonic motion, damped waves), three SR algorithms (DEAP, gplearn, PySR), and three LLMs (Mistral, Llama 2, Falcon), the method consistently improves accuracy, with PySR + Mistral achieving the highest R² scores (up to 0.99) and lowest MAE (down to 0.03). Prompt engineering significantly boosts performance, especially with ground-truth equations or detailed experiment descriptions. The approach also enhances noise robustness, with the LLM-integrated model outperforming baseline SR in high-noise conditions. Overall, LLM guidance enables more physically meaningful, interpretable, and accurate symbolic models.

## Method Summary
The framework modifies standard symbolic regression by integrating a pre-trained LLM into the loss function. For each candidate equation, the LLM evaluates its physical plausibility based on dimensional consistency, simplicity, and semantic similarity to known physical laws. The total loss becomes a weighted sum of data error, equation complexity, and the LLM's plausibility score. The system iterates through SR generations, using the LLM to guide the search toward equations that are both data-fitting and physically meaningful. Three SR algorithms (DEAP, gplearn, PySR) and three 7B parameter LLMs (Mistral, Llama 2, Falcon) are evaluated on synthetic physics datasets with varying noise levels.

## Key Results
- PySR + Mistral achieved R² scores up to 0.99 and MAE as low as 0.03 on synthetic physics datasets
- LLM integration improved noise robustness, maintaining higher performance than baseline SR under 5% noise conditions
- Prompt engineering significantly enhanced results, with full context prompts outperforming minimal context by 0.05-0.15 R² points
- The framework consistently discovered more accurate equations across all three physical scenarios (free fall, harmonic motion, damped waves)

## Why This Works (Mechanism)

### Mechanism 1: LLM as a Semantic Regularizer in the Loss Function
Embedding an LLM-based plausibility score into the loss function biases the symbolic regression search toward physically meaningful equations, reducing the effective search space. The framework modifies the standard loss function $L$ to include a term $c$ (Equation 1), representing the LLM's evaluation of dimensional consistency, simplicity, and physical realism. During the genetic algorithm's selection phase, equations that fit data but violate physical laws (e.g., dimension mismatch) receive a high penalty from the LLM term, lowering their fitness score relative to valid equations.

### Mechanism 2: Context-Induced Knowledge Activation
Performance improves when prompts contain detailed variable descriptions and experimental context because this activates specific domain knowledge clusters within the LLM. By moving from Prompt A (no context) to Prompt H (full context), the user shifts the LLM's attention mechanism. Mentioning "dropping ball" or "damped wave" primes the model to retrieve specific kinematic or electromagnetic formulas from its pre-training, allowing it to judge "physical realism" more accurately than in a vacuum.

### Mechanism 3: Structural Filtering of Noise-Induced Artifacts
LLM integration improves noise robustness by filtering out complex, overfitted expressions that statistically fit noisy data but structurally violate physical simplicity. Standard SR minimizes error ($e$); in high-noise regimes, this often leads to overly complex trees (overfitting). The LLM term $c$ explicitly penalizes low "simplicity" and low "physical realism" scores, effectively acting as a structural Occam's razor that favors simpler, robust equations even when complex ones have slightly lower MSE.

## Foundational Learning

- **Concept: Genetic Programming (GP) for SR**
  - Why needed here: The proposed method modifies the fitness function of GP algorithms (PySR, DEAP). Understanding that these algorithms evolve "populations" of equation trees via selection/mutation is required to see where the LLM "plugs in."
  - Quick check question: How does changing the fitness function affect the "survival" of an equation tree in a GP iteration?

- **Concept: In-Context Learning / Prompt Engineering**
  - Why needed here: The system relies on "few-shot" prompts to extract scores from the LLM. You must understand that the LLM is not retrained, but guided by the prompt structure (Role, Metrics, Examples).
  - Quick check question: Why does setting the LLM temperature to zero matter for the reproducibility of the loss function?

- **Concept: Multi-Objective Optimization**
  - Why needed here: The loss function $L$ balances fitting data ($e$), complexity ($s$), and physical plausibility ($c$).
  - Quick check question: If $w_3$ (LLM weight) is set too high relative to $w_1$ (data error), what is the risk for the resulting equation?

## Architecture Onboarding

- **Component map:** Data Generator -> SR Engine -> Prompt Constructor -> LLM Scorer -> Loss Aggregator -> SR Engine (loop)
- **Critical path:** The loop between the SR Engine proposing a candidate and the LLM Scorer evaluating it. Latency in the LLM inference will directly throttle the SR evolution speed.
- **Design tradeoffs:**
  - Local (7B) vs. API LLMs: The authors chose local models (Mistral/Llama) for privacy and cost, but accept potentially lower reasoning capability compared to GPT-4 class models.
  - Prompt Complexity: Richer prompts yield better scores but consume more context window and inference time.
- **Failure signatures:**
  - Non-termination: LLM returns a string that cannot be parsed into the list `[float, float, float, string]`, breaking the loss calculation.
  - Flat Loss: LLM gives identical scores to all equations (e.g., constant 0.5), removing the gradient pressure.
  - Metric Conflict: MSE improves but the LLM score degrades significantly, causing the optimization to oscillate.
- **First 3 experiments:**
  1. Baseline Validation: Run PySR on the "Dropping Ball" dataset with the LLM term disabled (baseline) vs. enabled to verify the performance gap.
  2. Prompt Sensitivity Test: Isolate Prompt E (Variable descriptions + Experiment description) vs. Prompt A (No context) on the Simple Harmonic Motion dataset to measure the delta in R².
  3. Noise Stress Test: Inject 5% Gaussian noise into the "Damped Wave" features and targets to confirm that the LLM-integrated model maintains a higher Tree Score than the baseline.

## Open Questions the Paper Calls Out
- Can the LLM-integrated framework maintain its performance advantages when applied to real-world experimental data rather than synthetic in silico datasets?
- Do more powerful, cloud-hosted LLMs (e.g., GPT-4) provide significantly better guidance for symbolic regression compared to the local 7B models tested?
- Does the LLM's plausibility score genuinely reflect physical realism, or does it bias the search toward syntactic simplicity?

## Limitations
- Computational cost and practical feasibility due to potentially frequent LLM calls during evolution
- Results based on synthetic data may not generalize to complex, high-dimensional real-world datasets
- Performance entirely dependent on pre-trained knowledge and prompt engineering quality

## Confidence
- **High Confidence:** The core finding that LLM integration improves symbolic regression accuracy on synthetic physics problems
- **Medium Confidence:** The claim that detailed prompt engineering significantly boosts performance
- **Low Confidence:** The scalability and efficiency of the method for large-scale or real-world problems

## Next Checks
1. Compute a runtime profile to measure time per generation for LLM-integrated vs baseline runs and test strategies to reduce LLM call frequency
2. Test the best-performing configuration (PySR + Mistral) on a small real-world physics dataset to assess generalization
3. Analyze the "physical meaningfulness" of discovered equations by manually inspecting final equations for correct units and structural similarity to ground-truth