---
ver: rpa2
title: 'Mapping on a Budget: Optimizing Spatial Data Collection for ML'
arxiv_id: '2509.03749'
source_url: https://arxiv.org/abs/2509.03749
tags:
- data
- sampling
- training
- satml
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the first framework to optimize spatial data
  collection for satellite imagery ML models under budget and cost constraints. The
  key idea is to select training samples that maximize proxy utility functions balancing
  dataset size and representativeness, rather than raw performance metrics.
---

# Mapping on a Budget: Optimizing Spatial Data Collection for ML
## Quick Facts
- arXiv ID: 2509.03749
- Source URL: https://arxiv.org/abs/2509.03749
- Reference count: 13
- Primary result: Framework optimizing spatial sample selection for satellite imagery ML under budget constraints outperforms baselines in 8/9 experiments

## Executive Summary
This paper introduces the first framework to optimize spatial data collection for satellite imagery machine learning models under budget and cost constraints. The key innovation is selecting training samples that maximize proxy utility functions balancing dataset size and representativeness, rather than raw performance metrics. The framework was tested across three real-world datasets covering agriculture, ecology, and socioeconomic prediction tasks, demonstrating significant performance improvements over baseline sampling strategies. The approach provides actionable guidance for real-world applications like agricultural monitoring in resource-constrained settings.

## Method Summary
The framework optimizes spatial sample selection by defining proxy utility functions that balance dataset size and representativeness. Unlike traditional approaches that maximize raw performance metrics, this method uses utility functions to evaluate training datasets before model training. The approach considers different cost structures for sample collection methods and incorporates both size-based and representation-based metrics. Experiments were conducted on three diverse satellite imagery datasets, comparing the proposed method against standard baselines like cluster and random sampling.

## Key Results
- The proposed method outperforms baseline sampling strategies in 8 out of 9 experimental settings
- Representation-based utilities, particularly image-based metrics, consistently rank training datasets better than size-only or administrative-based metrics
- Statistically significant gains in R2 performance were observed across multiple tasks
- The framework demonstrates practical utility for real-world applications like agricultural monitoring in Togo

## Why This Works (Mechanism)
The framework works by optimizing sample selection based on proxy utility functions rather than direct performance metrics. This approach addresses the fundamental challenge that traditional methods optimize for performance but cannot be computed during data collection. By using utility functions that balance size and representativeness, the method can evaluate potential training datasets before model training, enabling budget-constrained optimization. The representation-based utilities capture spatial and visual diversity more effectively than simple size metrics, leading to better model performance.

## Foundational Learning
- **Proxy utility functions**: Mathematical constructs that approximate dataset quality without requiring full model training; needed to evaluate samples during collection, quick check: verify utility correlates with actual performance
- **Representation-based sampling**: Methods that ensure collected samples capture spatial and visual diversity; needed to avoid biased training data, quick check: compare sample diversity metrics
- **Budget-constrained optimization**: Mathematical framework for maximizing utility under financial constraints; needed for practical deployment, quick check: validate cost estimates match actual collection expenses
- **Spatial autocorrelation**: The tendency for nearby locations to have similar characteristics; needed to avoid oversampling redundant information, quick check: measure sample independence

## Architecture Onboarding
**Component map**: Data sources -> Proxy utility functions -> Optimization algorithm -> Sample selection -> Model training
**Critical path**: The optimization algorithm that selects samples based on utility functions is the core innovation, as it enables budget-constrained collection decisions
**Design tradeoffs**: Balancing computational efficiency of utility calculations against accuracy of representation metrics; simpler metrics are faster but may miss important spatial patterns
**Failure signatures**: Poor performance when cost models are inaccurate, when utility functions poorly correlate with actual performance, or when spatial autocorrelation is ignored
**First experiments**: 1) Compare utility function predictions against actual model performance, 2) Test sensitivity to different cost structures, 3) Evaluate robustness across different geographic regions

## Open Questions the Paper Calls Out
None

## Limitations
- Results primarily focus on regression tasks with specific target variables, limiting generalizability to classification problems
- The budget optimization framework assumes linear cost relationships that may not reflect real-world non-linear logistical costs
- Magnitude of performance improvements varies considerably across tasks, with some datasets showing only marginal gains over baselines

## Confidence
- **High confidence** in the core methodological framework and its general applicability to satellite imagery tasks
- **Medium confidence** in the relative ranking of proxy utility functions, as results show some task-dependent variability
- **Medium confidence** in budget efficiency claims, given the simplified cost model

## Next Checks
1. Test the framework on classification tasks and diverse geographic regions beyond the current study areas
2. Validate the linear cost assumption with real-world field collection cost data across different scales
3. Conduct ablation studies to quantify the contribution of each proxy utility component (size vs. representativeness)