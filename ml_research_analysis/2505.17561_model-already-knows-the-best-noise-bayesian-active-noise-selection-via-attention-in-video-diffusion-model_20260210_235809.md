---
ver: rpa2
title: 'Model Already Knows the Best Noise: Bayesian Active Noise Selection via Attention
  in Video Diffusion Model'
arxiv_id: '2505.17561'
source_url: https://arxiv.org/abs/2505.17561
tags:
- bansa
- noise
- score
- attention
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The choice of initial noise seed significantly impacts the quality
  and prompt alignment of video diffusion models, with different seeds for the same
  prompt leading to drastically different generations. While existing methods rely
  on external noise priors like frequency filters or inter-frame smoothing, they often
  overlook internal model signals that indicate which noise seeds are inherently preferable.
---

# Model Already Knows the Best Noise: Bayesian Active Noise Selection via Attention in Video Diffusion Model

## Quick Facts
- arXiv ID: 2505.17561
- Source URL: https://arxiv.org/abs/2505.17561
- Authors: Kwanyoung Kim; Sanghyun Kim
- Reference count: 40
- Primary result: Attention-based uncertainty quantification (BANSA) selects high-quality initial noise seeds for video diffusion, improving VBench scores with only 8-13% inference overhead.

## Executive Summary
The choice of initial noise seed significantly impacts video diffusion model outputs, yet existing methods rely on external priors while ignoring internal model signals. This paper proposes ANSE (Active Noise Selection for Generation), which selects optimal noise seeds by quantifying attention-based uncertainty through BANSA (Bayesian Active Noise Selection via Attention). By measuring entropy disagreement across stochastic attention samples, BANSA estimates model confidence and consistency at the first denoising step. Experiments on CogVideoX-2B and 5B demonstrate improved video quality and temporal coherence with minimal inference time increase.

## Method Summary
ANSE operates by generating a pool of candidate noise seeds (M=10), computing attention-based uncertainty scores using Bernoulli-masked stochastic sampling (K=10 samples, p=0.2 mask probability) at the first denoising step only, then selecting the seed with minimum BANSA score. The method leverages layer-wise attention entropy to estimate epistemic uncertainty, with truncated attention layers (d*=14 for 2B, d*=19 for 5B) maintaining sufficient correlation with full-model uncertainty. This approach avoids expensive multi-pass uncertainty estimation while capturing the dominant trajectory divergence induced by initial noise.

## Key Results
- ANSE improves video quality and temporal coherence on CogVideoX-2B and 5B
- Inference overhead is only 8% for 2B and 13% for 5B models
- BANSA-E (Bernoulli masking) outperforms Dropout-based and standard entropy methods
- Single-step uncertainty estimation is sufficient, with marginal gains from multi-step averaging

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Entropy disagreement in attention maps serves as a proxy for initial noise quality, where lower disagreement correlates with higher generation fidelity.
- **Mechanism:** BANSA adapts Bayesian Active Learning by Disagreement (BALD) to the generative attention space, quantifying epistemic uncertainty through the difference between entropy of mean attention and mean of individual attention entropies.
- **Core assumption:** Attention map stability under stochastic perturbation is predictive of final video's semantic alignment and temporal coherence.
- **Evidence anchors:** Abstract definition of BANSA, Table 4 validation, correlation analysis in Section 3.1.
- **Break condition:** If attention layers do not capture semantic alignment (e.g., models driven by convolutions rather than cross-attention), the correlation between attention entropy and output quality will likely break.

### Mechanism 2
- **Claim:** Uncertainty estimation at the first denoising step is sufficient for noise selection, avoiding full trajectory analysis cost.
- **Mechanism:** Video diffusion models are highly sensitive to initial noise ($z_T$), with "bad" seeds inducing immediate attention uncertainty at $t=T$. Restricting BANSA calculation to this timestep captures dominant trajectory divergence.
- **Core assumption:** Noise-induced uncertainty is manifest and measurable at diffusion start ($t=T$) and persists throughout generation.
- **Evidence anchors:** Abstract's mention of single-step score estimation, Section 4 efficiency analysis, Table 6 comparison of 1-step vs. multi-step averaging.
- **Break condition:** If models rely heavily on late-stage semantic refinement ("semantic annealing"), early-step attention uncertainty might not correlate with final quality.

### Mechanism 3
- **Claim:** Bernoulli masking approximates multi-pass uncertainty estimation efficiently within single forward pass.
- **Mechanism:** Instead of Monte Carlo Dropout requiring $K$ separate passes, binary masks $\{0, 1\}$ applied to attention scores ($QK^\top$) before softmax force the model to attend to different token subsets, simulating disagreement.
- **Core assumption:** Masking attention scores provides statistically similar perturbation to Bayesian posterior sampling as dropout or ensemble methods.
- **Evidence anchors:** Section 3.2 Eq. 7 defining masked attention, Table 2 showing Bernoulli BANSA outperforms Dropout and standard Entropy.
- **Break condition:** If mask probability $p$ is too high (sparse/degenerate attention) or too low (insufficient perturbation), the method breaks.

## Foundational Learning

- **Concept:** Bayesian Active Learning by Disagreement (BALD)
  - **Why needed here:** BANSA is direct adaptation of BALD; understanding that BALD maximizes mutual information between model parameters and prediction is crucial for grasping the acquisition function.
  - **Quick check question:** How does BALD distinguish between data uncertainty (noise) and model uncertainty (epistemic uncertainty)?

- **Concept:** Tweedie's Formula / Denoising Score Matching
  - **Why needed here:** The paper operates within Latent Diffusion Model framework; understanding that $\epsilon_\theta$ predicts noise to recover $z_0$ explains why initial noise $z_T$ is critical to trajectory.
  - **Quick check question:** In DDIM update rule, how does predicted noise $\epsilon_\theta$ relate to estimated clean latent $\hat{z}_0$?

- **Concept:** Attention Entropy
  - **Why needed here:** The metric relies on row-wise entropy of attention maps; understanding that high entropy implies "confused" or distributed focus while low entropy implies confident, sharp focus is essential.
  - **Quick check question:** Does the paper suggest high attention entropy (diffuse focus) or low attention entropy (sharp focus) leads to better video generation?

## Architecture Onboarding

- **Component map:** Text Prompt $c$ + Noise Pool $Z$ (size $M=10$) -> Feature Extraction (one DDIM step) -> Perturbation Module (Bernoulli masks on attention layers 1 to $d^*$) -> Scoring (BANSA-E calculation) -> Selection (argmin(BANSA)) -> Generator (full 50-step DDIM)

- **Critical path:** The correlation analysis between early layers and full-layer uncertainty (Section 3.3). Before deployment on new model, you must run correlation analysis to find cutoff layer $d^*$ (e.g., layer 14 for 2B, 19 for 5B) to ensure truncated score validity.

- **Design tradeoffs:**
  - **Pool Size ($M$):** Higher $M$ finds better seeds but linearly increases overhead; paper finds saturation at $M=10$
  - **Ensemble Size ($K$):** Higher $K$ stabilizes uncertainty estimate; paper uses $K=10$
  - **Perturbation Method:** Bernoulli masking chosen over Dropout for better attention structure adherence and efficiency (Table 2)

- **Failure signatures:**
  - **"Confident but Wrong":** Low BANSA scores guarantee model confidence, not ground truth quality; paper notes failure cases where model is consistently confident about semantically incorrect generations (Figure 7)
  - **Architectural Mismatch:** If applying to models without standard attention mechanisms (e.g., recurrent structures), BANSA metric cannot be computed

- **First 3 experiments:**
  1. **Layer Correlation Check:** Replicate Figure 5 on target model; generate 100 videos, calculate BANSA for all layers, plot correlation to find minimal layers maintaining ≥0.7 correlation with full model
  2. **Ablation on Acquisition Function:** Compare "Random Selection" vs. "Entropy Only" vs. "BANSA (Dropout)" vs. "BANSA (Bernoulli)" on small prompt set (50 prompts) to verify Bernoulli BANSA provides best VBench scores (replicating Table 2)
  3. **Inference Time Profiling:** Measure exact latency of "selection phase" (scoring $M$ seeds) vs. "generation phase" to confirm <15% overhead target on your hardware

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does combining ANSE with external noise priors (e.g., FreeInit) yield cumulative improvements in video coherence?
- **Basis in paper:** Authors state "ANSE is orthogonal and can be combined with these methods for further gains" regarding frequency-based priors
- **Why unresolved:** Paper only evaluates ANSE in isolation against baselines, omitting hybrid experiments due to re-implementation costs
- **What evidence would resolve it:** Quantitative VBench results from pipeline applying ANSE selection followed by FreeInit refinement

### Open Question 2
- **Question:** To what extent does BANSA uncertainty correlate with human subjective perception of "naturalness" versus model confidence?
- **Basis in paper:** Authors acknowledge failure cases where "low BANSA scores... can produce unnatural generations" and note gap between uncertainty and aesthetic quality
- **Why unresolved:** BANSA measures model consistency, which doesn't guarantee semantic correctness or visual appeal
- **What evidence would resolve it:** Human evaluation study correlating BANSA scores with user ratings on semantic alignment and aesthetic quality

### Open Question 3
- **Question:** Is BANSA effectiveness dependent on CogVideoX's specific transformer-based architecture?
- **Basis in paper:** Method validated exclusively on CogVideoX-2B and 5B, leaving performance on UNet-based or other transformer video diffusion architectures unknown
- **Why unresolved:** Attention behaviors and layer-wise uncertainty may manifest differently in alternative backbones
- **What evidence would resolve it:** Experiments applying ANSE to diverse architectures like AnimateDiff or Open-Sora

## Limitations

- The method's reliance on attention entropy as proxy for generation quality may not generalize to diffusion models with different architectural priorities or training objectives
- Low BANSA scores guarantee model confidence rather than ground truth quality, potentially selecting consistently confident but semantically incorrect generations
- The approach assumes attention maps meaningfully capture semantic alignment, which may not hold for models where generation is driven primarily by convolutions or other mechanisms

## Confidence

- **High Confidence:** Bernoulli masking approximation's efficiency gains and validation that selecting seeds with low BANSA scores improves VBench metrics are well-supported by empirical results (Tables 2 and 4)
- **Medium Confidence:** Layer correlation analysis showing truncated attention layers maintain quality correlation is promising but may require recalibration for different model architectures or scales
- **Medium Confidence:** Assumption that single-step uncertainty estimation is sufficient for noise selection is supported by marginal gains from multi-step averaging (Table 6), but may not hold for models with late-stage semantic refinement

## Next Checks

1. **Architecture-Specific Calibration:** Replicate layer correlation analysis (Figure 5) on target model to identify minimal subset of attention layers maintaining ≥0.7 correlation with full-layer uncertainty

2. **Domain Transfer Validation:** Test BANSA selection on prompts outside VBench benchmark to assess generalization to diverse video generation tasks and semantic domains

3. **Failure Mode Analysis:** Systematically generate examples where low BANSA seeds produce confident but semantically incorrect outputs to characterize "confident but wrong" failure mode and its prevalence across prompt types