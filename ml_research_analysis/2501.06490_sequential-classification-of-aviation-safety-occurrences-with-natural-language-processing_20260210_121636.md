---
ver: rpa2
title: Sequential Classification of Aviation Safety Occurrences with Natural Language
  Processing
arxiv_id: '2501.06490'
source_url: https://arxiv.org/abs/2501.06490
tags:
- aviation
- safety
- learning
- deep
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explores the application of Natural Language Processing
  (NLP) and deep learning models to classify aviation safety occurrences based on
  textual narratives. The research addresses the challenge of analyzing unstructured
  text narratives from aviation incident/accident reports to infer the damage level
  caused to aircraft.
---

# Sequential Classification of Aviation Safety Occurrences with Natural Language Processing

## Quick Facts
- arXiv ID: 2501.06490
- Source URL: https://arxiv.org/abs/2501.06490
- Reference count: 32
- Primary result: NLP and deep learning models achieved >87.9% accuracy in classifying aviation damage levels from unstructured narrative text

## Executive Summary
This study investigates the use of Natural Language Processing and deep learning models to classify aviation safety occurrences based on textual narratives. The research focuses on inferring aircraft damage levels from unstructured text in NTSB reports using various RNN architectures. The models successfully classified damage into four categories with high accuracy and balanced precision/recall metrics, demonstrating the potential of NLP techniques in aviation safety decision-making.

## Method Summary
The study used 16,919 NTSB aviation incident/accident reports (2005-2020) containing 'analysis Narrative' and 'damage Level' fields. Text was preprocessed using spaCy for tokenization, stop-word removal, and lemmatization, then tokenized and padded to 2,000 tokens with a 100,000-word vocabulary. Multiple deep learning models were evaluated including LSTM, BLSTM, GRU, and sRNN, both individually and in joint configurations. Models were trained using 80/20 train-test splits with Adam optimizer, and performance was assessed using accuracy, precision, recall, and F1-score metrics.

## Key Results
- All models achieved accuracy above 87.9% with precision >80%, recall >88%, and F1 scores >85%
- sRNN slightly outperformed others in recall (90%) and accuracy (90%), while LSTM showed better precision (87%)
- Joint sRNN-LSTM model demonstrated the best overall performance with balanced precision (88%) and recall (89%)
- Severe class imbalance present (15,163 substantial vs 152 none) but models maintained reasonable minority class performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequential neural architectures can infer damage level from unstructured aviation narratives by capturing temporal dependencies in event descriptions.
- Mechanism: RNN variants process tokenized text sequences through hidden states that preserve contextual relationships across narrative events. Embedding layers transform words into dense vectors; recurrent layers aggregate sequential information; softmax outputs class probabilities.
- Core assumption: Damage severity correlates with linguistic patterns and event sequences in narratives.
- Evidence anchors: Models achieved 87.9-90% accuracy; sRNN slightly outperformed others; similar LSTM approaches validated in prior aviation safety work.

### Mechanism 2
- Claim: Joint RNN architectures combining multiple recurrent layer types improve classification by leveraging complementary representational strengths.
- Mechanism: Stacking different RNN types allows earlier layers to capture simpler sequential patterns while deeper layers model longer-range dependencies.
- Core assumption: Different RNN architectures encode distinct useful features; their combination yields richer representations.
- Evidence anchors: sRNN-LSTM achieved 89% accuracy with balanced precision (88%) and recall (89%); 3-way joint models showed diminishing returns.

### Mechanism 3
- Claim: Preprocessing transforms human-authored incident narratives into fixed-length vector representations suitable for classification.
- Mechanism: Tokenization maps words to indices; vocabulary capped at 100,000; sequences padded/truncated to length 2,000; stop-words and special characters removed via spaCy.
- Core assumption: Key predictive information survives aggressive truncation/padding and stop-word removal.
- Evidence anchors: Preprocessing achieved consistent 2000-token sequences; class distribution shows severe imbalance (substantial dominates).

## Foundational Learning

- Concept: Recurrent Neural Networks and gating mechanisms (LSTM/GRU)
  - Why needed here: Core architecture relies on understanding how hidden states propagate information and how gating mitigates vanishing gradients.
  - Quick check question: Can you explain why BLSTM processes sequences bidirectionally and what additional information this captures compared to unidirectional LSTM?

- Concept: Word embeddings and sequence vectorization
  - Why needed here: Converting raw text to learnable representations is foundational.
  - Quick check question: What happens to out-of-vocabulary words under a fixed 100,000-word vocabulary, and how does padding to length 2,000 affect gradient flow?

- Concept: Multi-class classification metrics (precision, recall, F1, accuracy)
  - Why needed here: Paper reports all four metrics with class imbalance present.
  - Quick check question: Given the class distribution (15,163 substantial vs. 152 none), why might high accuracy coexist with poor performance on minority classes?

## Architecture Onboarding

- Component map: Raw NTSB narrative text + damage label -> spaCy preprocessing -> Keras Tokenizer -> pad/truncate to 2000 -> embedding layer (vocab=100K) -> RNN layer(s) -> Dense layer -> SoftMax -> class prediction

- Critical path: Data quality check -> Tokenization alignment -> Embedding initialization -> RNN configuration -> Class imbalance handling

- Design tradeoffs:
  - sRNN: Faster, fewer parameters, best recall (90%) and accuracy (90%)
  - LSTM: More parameters, better long-term memory, best precision (87%)
  - Joint models: Higher capacity but increased training time and overfitting risk
  - Sequence length 2,000: Captures most narratives but truncates longer reports

- Failure signatures:
  - High accuracy but near-zero recall on minority classes -> majority class bias
  - Validation accuracy diverges from training -> overfitting
  - Random-guess-level performance (25%) -> tokenization or label encoding failure
  - Slow convergence -> learning rate issues or vanishing gradients

- First 3 experiments:
  1. Baseline replication: Implement single sRNN and LSTM models to match reported accuracy (~88-90%)
  2. Class imbalance mitigation: Add class weights or oversample minority classes
  3. Ablation on sequence length and vocabulary: Test seq_len ∈ {500, 1000, 2000, 3000} and vocab ∈ {50K, 100K, 150K}

## Open Questions the Paper Calls Out
None

## Limitations
- Model architecture details remain unspecified (embedding dimensions, RNN hidden sizes)
- Class imbalance handling is not explicitly addressed despite severe skew
- Joint model configurations lack detail on how architectures are combined
- Preprocessing choices lack comparative analysis against alternatives

## Confidence

- **High Confidence**: Deep learning models can classify aviation damage levels from text with reasonable accuracy (>87.9%)
- **Medium Confidence**: sRNN and sRNN-LSTM architectures slightly outperform others
- **Low Confidence**: The specific preprocessing pipeline is optimal for this task

## Next Checks

1. Reproduce baseline metrics with fixed random seeds across multiple runs
2. Analyze class-wise performance using confusion matrices to verify minority class recall
3. Ablate preprocessing parameters by testing different sequence lengths and vocabulary sizes to identify information loss impacts