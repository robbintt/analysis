---
ver: rpa2
title: Feature Selection Empowered BERT for Detection of Hate Speech with Vocabulary
  Augmentation
arxiv_id: '2512.02141'
source_url: https://arxiv.org/abs/2512.02141
tags:
- bert
- hate
- speech
- training
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the challenge of efficiently detecting hate\
  \ speech on social media, where evolving slang and obfuscated terms complicate model\
  \ training. It proposes a data-efficient BERT fine-tuning approach that combines\
  \ TF-IDF-based sample selection (retaining 75% of the most informative examples)\
  \ with vocabulary augmentation (adding hate-related slang to BERT\u2019s tokenizer)."
---

# Feature Selection Empowered BERT for Detection of Hate Speech with Vocabulary Augmentation

## Quick Facts
- arXiv ID: 2512.02141
- Source URL: https://arxiv.org/abs/2512.02141
- Authors: Pritish N. Desai; Tanay Kewalramani; Srimanta Mandal
- Reference count: 18
- Primary result: TF-IDF-based sample selection + vocabulary augmentation maintains or improves hate speech detection accuracy while reducing training time by up to 50%

## Executive Summary
This paper addresses the challenge of efficiently detecting hate speech on social media, where evolving slang and obfuscated terms complicate model training. It proposes a data-efficient BERT fine-tuning approach that combines TF-IDF-based sample selection (retaining 75% of the most informative examples) with vocabulary augmentation (adding hate-related slang to BERT's tokenizer). Experiments on the Davidson dataset show that this method matches or slightly improves classification performance while reducing training time by up to 50%, demonstrating both scalability and robustness for adaptive hate speech moderation.

## Method Summary
The approach involves two key modifications to standard BERT fine-tuning. First, a TF-IDF-based sample selection mechanism ranks tweets by aggregate term importance scores, retaining only the top 75% most informative examples while filtering out redundant or noisy samples. Second, the tokenizer is augmented with domain-specific hate-related slang and lexical variants commonly found in abusive contexts, extending BERT's 30k-token vocabulary with a few dozen additional terms. The extended embedding layer allows the model to learn representations for these slang terms during fine-tuning without requiring full retraining.

## Key Results
- TF-IDF Top 75% filtering achieves 0.9667 accuracy vs. 0.9627 baseline, with 27% training time reduction
- Vocabulary augmentation provides consistent performance gains across all filtering levels
- Moderate filtering (~75%-70%) preserves or slightly improves classification performance
- Accuracy drops significantly below 65% retention, indicating loss of linguistic diversity

## Why This Works (Mechanism)

### Mechanism 1: TF-IDF Sample Selection
TF-IDF-based filtering retains informative examples by ranking tweets according to aggregate TF-IDF scores. High-scoring tweets contain distinctive terms (rare across corpus but frequent locally) that are more discriminative for classification than generic content. The approach assumes low-scoring tweets contribute primarily noise or redundancy rather than rare but critical edge cases. Performance degrades when filtering below 65%, indicating eventual loss of linguistic diversity.

### Mechanism 2: Vocabulary Augmentation
Domain-specific slang is added to BERT's tokenizer to improve tokenization of obfuscated hate terms that would otherwise be subword-split. New tokens receive embeddings initialized from related existing tokens, allowing domain-specific representation learning during fine-tuning. The method assumes added terms are genuinely absent or poorly represented in BERT's vocabulary, with consistent accuracy drops observed when augmentation is removed.

### Mechanism 3: Combined Efficiency-Robustness
The dual approach concentrates learning on discriminative patterns: filtering reduces exposure to noisy samples while augmentation ensures key hate terms remain explicitly tokenized. This compensates for reduced linguistic diversity from filtering. However, augmentation cannot fully compensate for excessive filtering, with accuracy dropping at 50% retention despite vocabulary extension.

## Foundational Learning

- **TF-IDF (Term Frequency–Inverse Document Frequency)**: Core to data filtering mechanism; must understand how term importance is scored to interpret why certain tweets are retained. Quick check: Why would a tweet containing common words score lower than one with rare, domain-specific terms?

- **WordPiece tokenization and vocabulary limits**: BERT's fixed 30k-token vocabulary is central to the problem; understanding subword splitting explains why slang terms get fragmented. Quick check: What happens when BERT encounters a word not in its vocabulary?

- **Embedding layer extension in transformers**: Vocabulary augmentation requires adding tokens and initializing their embeddings without retraining the full model. Quick check: When adding new tokens to a pretrained tokenizer, which model components require modification?

## Architecture Onboarding

- **Component map**: Raw tweets → TF-IDF vectorization → Score aggregation → Top-k% selection → Extended BERT tokenizer → BERT-base fine-tuning → Classification output

- **Critical path**: 1) Compute TF-IDF matrix over full training corpus 2) Aggregate scores per tweet, rank, select threshold 3) Curate slang list from dataset + external lexicons 4) Extend tokenizer and resize embedding layer 5) Fine-tune on filtered data, evaluate on fixed test split

- **Design tradeoffs**: Higher filtering = faster training but risk of context loss (optimal: 75%); More vocabulary augmentation = better slang coverage but requires curation effort; Assumption: Binary classification simplifies task vs. multi-class

- **Failure signatures**: Accuracy drops below baseline when filtering exceeds ~35% reduction; No improvement from augmentation if added terms already exist in vocabulary; Class 0 (minority hate class) precision degrades first under excessive filtering

- **First 3 experiments**: 1) Replicate baseline: BERT on full Davidson dataset, record accuracy and training time 2) Ablate filtering only: Train on TF-IDF 75% subset without vocabulary augmentation 3) Ablate augmentation only: Train on full data with extended vocabulary

## Open Questions the Paper Calls Out
1. Does the 75% retention threshold generalize to other hate speech datasets with different noise profiles or class imbalances?
2. Do efficiency gains transfer to domain-specific transformers like HateBERT or newer architectures like RoBERTa?
3. How does manual slang curation compare to automated lexicon expansion for adapting to rapidly evolving online slang?

## Limitations
- Exact vocabulary terms added to BERT remain unspecified, creating reproducibility gaps
- Critical hyperparameters (learning rate, optimizer choice) are omitted from experimental setup
- Single dataset (Davidson) limits generalizability claims to other hate speech corpora

## Confidence
- **High confidence**: Filtering at ~75% retains performance while reducing training time (supported by quantitative results)
- **Medium confidence**: Vocabulary augmentation improves performance when filtering is applied (consistent gains, but exact term list unknown)
- **Low confidence**: Combined approach generalizes to other hate speech datasets (only Davidson tested)

## Next Checks
1. Replicate baseline accuracy and training time on full Davidson dataset (80-20 split) before applying any modifications
2. Perform ablation study: train on TF-IDF 75% subset without vocabulary augmentation to isolate filtering effect
3. Test on an independent hate speech dataset (e.g., HatEval or OLID) to assess cross-corpus generalization of the combined approach