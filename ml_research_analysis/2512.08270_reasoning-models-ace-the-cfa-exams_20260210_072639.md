---
ver: rpa2
title: Reasoning Models Ace the CFA Exams
arxiv_id: '2512.08270'
source_url: https://arxiv.org/abs/2512.08270
tags:
- level
- pass
- reasoning
- exams
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates state-of-the-art reasoning models on mock
  Chartered Financial Analyst (CFA) exams consisting of 980 questions across three
  levels. The study finds that recent models such as Gemini 3.0 Pro, GPT-5, and others
  consistently pass all three CFA levels, achieving near-perfect scores on Levels
  I and II.
---

# Reasoning Models Ace the CFA Exams

## Quick Facts
- arXiv ID: 2512.08270
- Source URL: https://arxiv.org/abs/2512.08270
- Authors: Jaisal Patel; Yunzhe Chen; Kaiwen He; Keyi Wang; David Li; Kairong Xiao; Xiao-Yang Liu
- Reference count: 40
- Primary result: Advanced reasoning models achieve near-perfect scores on CFA Level I and II mock exams, with Gemini 3.0 Pro scoring 97.6% and 92.0% on constructed responses

## Executive Summary
This study evaluates state-of-the-art reasoning models on mock Chartered Financial Analyst (CFA) exams consisting of 980 questions across three levels. The findings reveal that recent models such as Gemini 3.0 Pro and GPT-5 consistently pass all three CFA levels, with exceptional performance on Levels I and II. On Level III, Gemini 2.5 Pro achieves the highest MCQ score of 86.4%, while Gemini 3.0 Pro excels in constructed-response questions with 92.0%. The results demonstrate that current models have mastered the codified knowledge base required for Levels I and II, with advanced reasoning capabilities extending into the complex synthesis needed for Level III.

## Method Summary
The evaluation utilized mock CFA exams containing 980 questions distributed across all three exam levels. The study tested multiple reasoning models including Gemini 3.0 Pro, GPT-5, and Gemini 2.5 Pro on these standardized questions. Performance was measured through multiple-choice questions and constructed-response assessments, with particular attention to Level III's synthesis requirements. The methodology focused on standardized testing conditions to ensure consistent evaluation across different model architectures.

## Key Results
- Gemini 3.0 Pro achieves 97.6% on CFA Level I mock exam
- GPT-5 scores 94.3% on CFA Level II mock exam
- Gemini 2.5 Pro attains 86.4% on Level III multiple-choice questions, while Gemini 3.0 Pro achieves 92.0% on constructed-response questions

## Why This Works (Mechanism)
The exceptional performance of reasoning models on CFA exams demonstrates their ability to master codified financial knowledge and apply complex analytical frameworks. These models leverage advanced reasoning capabilities to synthesize information across multiple domains, particularly evident in their Level III performance where integration of concepts becomes critical. The success suggests that modern architectures have developed sophisticated understanding of financial principles, regulatory frameworks, and analytical methodologies required for professional certification.

## Foundational Learning

### Financial Analysis Concepts
- **Why needed**: Understanding financial statements, ratios, and valuation methods
- **Quick check**: Can the model explain the DuPont analysis framework

### Investment Management Principles
- **Why needed**: Portfolio theory, asset allocation, and risk management
- **Quick check**: Can the model differentiate between active and passive investment strategies

### Ethics and Professional Standards
- **Why needed**: CFA Institute Code of Ethics and Standards of Professional Conduct
- **Quick check**: Can the model identify violations of fiduciary duty

### Quantitative Methods
- **Why needed**: Statistical analysis, time series forecasting, and hypothesis testing
- **Quick check**: Can the model calculate and interpret correlation coefficients

## Architecture Onboarding

### Component Map
Reasoning engine -> Knowledge base -> Analysis module -> Response generator

### Critical Path
The critical path involves processing the question through the reasoning engine, accessing relevant knowledge, performing analysis, and generating the response. For constructed responses, additional synthesis and formatting steps are required.

### Design Tradeoffs
The models balance between specialized financial knowledge integration and general reasoning capabilities. Tradeoffs include computational efficiency versus comprehensive analysis depth, and the balance between memorized facts versus demonstrated understanding.

### Failure Signatures
Potential failure modes include over-reliance on pattern matching rather than genuine understanding, inability to handle novel question formats, and challenges with questions requiring real-world judgment beyond codified knowledge.

### First Experiments
1. Test models on intentionally modified questions to assess genuine understanding versus memorization
2. Compare performance on questions requiring cross-topic integration versus single-topic questions
3. Evaluate response quality through blinded human expert review

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation conducted on mock exams rather than actual CFA exam questions
- Proprietary nature of real CFA exams means mock questions may not fully capture exam complexity
- High scores raise questions about whether evaluation methodology was too permissive

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Models demonstrate strong performance on codified knowledge assessments (Levels I and II) | High |
| Models show advanced reasoning capabilities on Level III material | Medium |
| Claims about practical financial competence and real-world applicability | Low |

## Next Checks
1. Replicate evaluation using actual past CFA exam questions (where permitted) or independently verified mock exams from multiple providers
2. Conduct comparative analysis between model performance and actual CFA charterholders' performance on same exam questions
3. Design practical case studies testing models' ability to apply CFA-level knowledge to real-world financial scenarios beyond multiple-choice and constructed-response formats