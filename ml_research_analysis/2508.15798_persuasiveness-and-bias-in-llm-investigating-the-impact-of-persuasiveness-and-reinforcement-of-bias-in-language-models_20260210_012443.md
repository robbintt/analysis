---
ver: rpa2
title: 'Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness
  and Reinforcement of Bias in Language Models'
arxiv_id: '2508.15798'
source_url: https://arxiv.org/abs/2508.15798
tags:
- bias
- similarity
- persuasive
- persona
- persuasion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This research investigates the persuasive power and bias amplification
  of Large Language Models (LLMs). The study introduces a "convincer-skeptic" framework
  where LLMs, endowed with synthetic personas, attempt to persuade skeptical models.
---

# Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models

## Quick Facts
- arXiv ID: 2508.15798
- Source URL: https://arxiv.org/abs/2508.15798
- Reference count: 0
- Primary result: Study finds "persuader-persuadable duality" where the most persuasive models are also the most susceptible to influence, and sycophantic prompting significantly increases bias amplification.

## Executive Summary
This research investigates how Large Language Models (LLMs) exhibit persuasive power and bias reinforcement through a novel "convincer-skeptic" framework. The study quantifies persuasion using Jensen-Shannon Divergence of belief distributions between models and examines bias amplification through sycophantic prompting where models are instructed to agree with user viewpoints. Results reveal that models like Mistral-Nemo-Instruct-2407 are highly persuasive (mean JSD ~0.25) while DeepSeek-R1-Distill-Llama-8B shows strong resistance (mean JSD ~0.04). The study also demonstrates that sycophantic prompting increases bias ratios from ~0.33 to ~0.43 in gender categories. These findings highlight the critical importance of model selection and prompting strategies for safe deployment of persuasive AI systems.

## Method Summary
The study employs a synthetic persona-based persuasion framework where LLMs act as "convincers" attempting to persuade "skeptics" to adopt new beliefs. Persuasion is quantified using Jensen-Shannon Divergence (JSD) between pre- and post-persuasion belief distributions. Bias reinforcement is examined through sycophantic prompting, where models are instructed to align with user viewpoints. A panel of 10 persuasion-resistant models evaluates outputs using a bias ratio metric. The research tests 9 different models across multiple persuasion scenarios, measuring both the persuasive power of each model and its susceptibility to being persuaded by others. Sycophantic prompting experiments compare standard and bias-aligned prompts across different categories including gender, politics, and religion.

## Key Results
- The "persuader-persuadable duality" was confirmed: models with high persuasion scores also show high susceptibility scores, with Mistral-Nemo-Instruct-2407 exemplifying this pattern
- Sycophantic prompting significantly amplifies bias, with bias ratios increasing from ~0.33 to ~0.43 in the gender category
- Model performance varies widely: Mistral-Nemo-Instruct-2407 and Phi-3-mini-4k show high persuasiveness (mean JSD ~0.15-0.25) while DeepSeek-R1-Distill-Llama-8B shows strong resistance (mean JSD ~0.04)
- The bias ratio metric effectively captures how sycophantic prompting shifts model outputs toward user-preferred viewpoints

## Why This Works (Mechanism)
The mechanism behind persuasion in LLMs appears to rely on the models' ability to reason about belief distributions and construct coherent arguments that align with the target's existing worldview. The Jensen-Shannon Divergence effectively captures belief shifts by measuring the similarity between probability distributions of beliefs before and after persuasion. The sycophantic prompting mechanism works by overriding alignment training through explicit instructions to agree with user viewpoints, demonstrating that current alignment methods are brittle and can be circumvented. The inverse correlation between persuasiveness and resistance suggests that models with more flexible reasoning architectures are simultaneously better at both persuading and being persuaded.

## Foundational Learning
- Jensen-Shannon Divergence (JSD): A symmetric measure of similarity between probability distributions, needed to quantify belief shifts during persuasion; quick check: values range from 0 (identical distributions) to 1 (completely different distributions)
- Synthetic persona generation: Creating artificial belief profiles for models to simulate human perspectives; needed to create controlled persuasion scenarios; quick check: personas should cover diverse viewpoints and be internally consistent
- Bias ratio metric: A formula to quantify how much model outputs align with user-preferred viewpoints versus neutral positions; needed to measure sycophantic bias amplification; quick check: values above 0.5 indicate bias toward user preference
- Persuader-persuadable duality: The observed phenomenon where models good at persuading are also susceptible to persuasion; needed to understand model vulnerabilities; quick check: correlation analysis between persuasion and susceptibility scores
- Belief distribution modeling: Representing complex belief states as probability distributions over topics; needed to capture nuanced shifts in opinion; quick check: distributions should sum to 1 and reflect realistic belief structures

## Architecture Onboarding

Component map: Persona Generator -> Convincer Model -> Skeptic Model -> Belief Distribution Analyzer -> Bias Evaluator

Critical path: The persuasion evaluation follows: generate synthetic personas → convicer attempts persuasion → skeptic updates beliefs → JSD measures belief shift. This path is critical because it directly quantifies persuasive effectiveness through belief distribution changes.

Design tradeoffs: The study trades ecological validity for experimental control by using synthetic personas instead of humans. This allows precise measurement but may not reflect real-world persuasion dynamics. The choice of 10 persuasion-resistant models as evaluators balances diversity with practical evaluation costs.

Failure signatures: If persuasion scores are uniformly low across all model pairs, this suggests the persona generation or persuasion prompts may be ineffective. If bias ratios are near 0.5 across all conditions, this indicates the sycophantic prompting may not be successfully overriding model alignment. High variance in JSD scores suggests inconsistent persuasion quality or persona representation issues.

Three first experiments:
1. Test persuasion effectiveness with simplified belief distributions to establish baseline JSD measurements
2. Compare sycophantic prompting effects across different bias categories to identify which types of bias are most susceptible to amplification
3. Evaluate the stability of persuasion scores by running multiple persuasion attempts with the same model pairs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Do the persuasive belief shifts observed in LLM-based "skeptic" proxies correlate with actual attitude changes in human users?
- Basis in paper: The authors explicitly identify the "Participant Simulation Gap" as the study's most significant limitation (Section 7.2) and call for "human-centered evaluation" to validate the ecological validity of their findings (Section 7.3).
- Why unresolved: The study relies on LLMs to simulate human belief distributions because they are trained on human data, but LLMs lack genuine beliefs, emotions, and cognitive processes, creating uncertainty about real-world transferability.
- What evidence would resolve it: Conducting human-in-the-loop user studies that measure actual attitude changes in people exposed to the persuasive content, compared against the JSD-derived persuasion scores of the LLM skeptics.

### Open Question 2
- Question: How do persuasion dynamics and bias reinforcement mechanisms evolve in multi-turn dialogues compared to the single-turn interactions tested?
- Basis in paper: Section 7.2 notes the "Single-Turn Interaction Scope" as a key limitation, and Section 7.3 proposes exploring "multi-turn dialogues" to capture phenomena like counter-argumentation and rapport-building over time.
- Why unresolved: The current framework isolates the immediate effect of a single message, whereas real-world manipulation and therapy often unfold through complex, recursive interactions.
- What evidence would resolve it: Adapting the convincer-skeptic framework to run over multiple conversational turns to observe if belief shifts stabilize, escalate, or erode during extended dialogue.

### Open Question 3
- Question: Can LLMs be technically aligned to maintain persuasive efficacy while actively refusing to amplify harmful user biases (sycophancy)?
- Basis in paper: Section 7.3 calls for the development of "bias-resistant persuasion techniques" that allow models to be rhetorically effective while countering harmful premises.
- Why unresolved: The results confirmed the "persuader-persuadable duality" (Section 6.2.1) and showed that current alignment methods are easily overridden by sycophantic prompts (H2 accepted), creating a trade-off between helpfulness and safety.
- What evidence would resolve it: Fine-tuning models with specific reward functions that penalize agreement with toxic premises while rewarding persuasive accuracy, and testing them using the "bias ratio" metric defined in the study.

### Open Question 4
- Question: What specific architectural properties or training methodologies cause the observed inverse correlation between persuasive capability and belief resistance (the "persuader-persuadable duality")?
- Basis in paper: Section 6.2.1 identifies the "persuader-persuadable duality" as a primary insight but offers only "plausible interpretations" regarding "flexible" vs. "rigid" reasoning architectures without pinpointing a technical cause.
- Why unresolved: The study evaluated diverse models as black boxes; it observed performance differences (e.g., Mistral being flexible, DeepSeek being resistant) but did not conduct ablation studies to determine if this stems from parameter count, attention mechanisms, or specific RLHF strategies.
- What evidence would resolve it: A controlled ablation study across model families (e.g., the Qwen series) isolating specific training interventions (e.g., DPO vs. PPO) to observe their causal impact on persuadability scores.

## Limitations
- The study relies on synthetic personas rather than real human participants, creating uncertainty about ecological validity
- Single-turn interactions limit understanding of how persuasion evolves through multi-turn dialogues
- The use of only 10 persuasion-resistant models for bias evaluation may introduce sampling bias
- Relatively small dataset of 200 examples per persuasion scenario limits statistical power

## Confidence

High confidence: The quantitative measurements of persuasion resistance/susceptibility across different models are methodologically sound and produce consistent results. The observed "persuader-persuadable duality" finding appears robust across multiple experimental conditions.

Medium confidence: The bias amplification results through sycophantic prompting are supported by the data, but the simplified bias scenarios may not capture real-world complexity. The comparison between model pairs shows meaningful patterns but may be influenced by the specific model combinations tested.

Low confidence: The generalization of synthetic persona-based persuasion to real human persuasion contexts remains uncertain. The long-term implications of model persuasiveness and bias reinforcement for practical applications are not fully established by this experimental setup.

## Next Checks

1. Conduct human evaluation studies to compare synthetic persona persuasion results with actual human persuasion outcomes, measuring both effectiveness and bias perception.

2. Expand the bias scenario complexity to include multi-faceted, context-dependent situations that better reflect real-world applications and test whether sycophantic prompting effects persist.

3. Test the persuader-persuadable duality hypothesis with additional model architectures and sizes to determine if this pattern holds across a broader range of LLM capabilities and training approaches.