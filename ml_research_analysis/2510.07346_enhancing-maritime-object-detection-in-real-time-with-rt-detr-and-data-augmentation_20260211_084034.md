---
ver: rpa2
title: Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation
arxiv_id: '2510.07346'
source_url: https://arxiv.org/abs/2510.07346
tags:
- detection
- synthetic
- maritime
- real
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a real-time maritime object detection pipeline
  based on RT-DETR, enhanced with multi-scale feature fusion, uncertainty-guided query
  selection, and domain-aware synthetic augmentation. The method addresses the challenges
  of detecting small, low-contrast vessels in complex maritime environments using
  limited real RGB data.
---

# Enhancing Maritime Object Detection in Real-Time with RT-DETR and Data Augmentation

## Quick Facts
- arXiv ID: 2510.07346
- Source URL: https://arxiv.org/abs/2510.07346
- Reference count: 26
- Primary result: mAP@0.5 = 0.89, Precision = 0.92, Recall = 0.91, F1 = 0.90 on real maritime test set

## Executive Summary
This study presents a real-time maritime object detection pipeline based on RT-DETR, enhanced with multi-scale feature fusion, uncertainty-guided query selection, and domain-aware synthetic augmentation. The method addresses the challenges of detecting small, low-contrast vessels in complex maritime environments using limited real RGB data. Synthetic imagery is used during training to expand diversity, while strict evaluation is performed only on real test images to ensure unbiased generalization assessment. Component-level ablation reveals that each architectural module contributes positively, with fusion providing the largest gain. The full system achieves mAP@0.5 = 0.89, precision = 0.92, recall = 0.91, and F1 = 0.90 on a held-out real maritime test set, outperforming a baseline DETR model trained only on real data.

## Method Summary
The pipeline combines RT-DETR with multi-scale feature fusion, uncertainty-guided query selection, and domain-aware synthetic augmentation. Real and synthetic images from the TDSS-G1 dataset are processed through a hybrid encoder with intra-scale and cross-scale fusion modules. Encoder features are used to initialize decoder queries based on prediction uncertainty, focusing the model on reliable object proposals. During training, synthetic and real samples are weighted differently to reduce domain gap while maintaining diversity. The system is trained for 100 epochs using AdamW optimizer (lr=1e-4, cosine decay) with horizontal flip and random erasing augmentation, evaluating only on real images to ensure unbiased performance assessment.

## Key Results
- Full system achieves mAP@0.5 = 0.89 on real maritime test set
- Fusion module provides largest single gain (mAP@0.5 = 0.83 vs baseline 0.80)
- Query selection improves mAP@0.5 to 0.82
- Domain-aware weighting contributes to reaching mAP@0.89
- Precision = 0.92, Recall = 0.91, F1 = 0.90

## Why This Works (Mechanism)

### Mechanism 1: Multi-Scale Feature Fusion for Small Object Preservation
The hybrid encoder separates intra-scale interactions from cross-scale fusion, allowing fine-grained spatial details from early layers to combine with semantic context from deeper layers. This preserves vessel hull outlines and thin masts that standard single-scale transformers tend to blur. Small maritime targets generate detectable activations at some scale in the backbone; fusion makes these accessible to the decoder. Break condition: If vessels fall below the effective receptive field of the smallest feature map (e.g., <2–3 pixels at 640×640 input), fusion alone cannot recover them.

### Mechanism 2: Uncertainty-Guided Query Selection
The model scores encoder positions by classification confidence and uses top-K as initial object queries. This directs decoder attention toward semantically meaningful regions (potential vessels) rather than open water or horizon artifacts. High-confidence positions correlate with true object locations. Break condition: If the encoder is miscalibrated (e.g., consistently overconfident on wave patterns), query selection may amplify false positives.

### Mechanism 3: Domain-Aware Synthetic Weighting
Synthetic images are included in training but given lower effective weight than real images. This exposes the model to rare conditions (dusk, haze) without allowing synthetic artifacts to dominate gradient updates. Synthetic images share sufficient structural similarity with real maritime scenes for transferable features, despite domain shift in texture/lighting. Break condition: If synthetic images contain systematic artifacts (e.g., incorrect hull shapes, implausible reflections), weighting may not fully prevent negative transfer.

## Foundational Learning

- **Concept: Transformer Attention for Detection**
  - Why needed here: RT-DETR replaces anchor boxes and NMS with learned set prediction via cross-attention. Understanding how queries attend to encoder features is essential for debugging localization failures.
  - Quick check question: Can you explain why DETR uses Hungarian matching during training but not during inference?

- **Concept: Multi-Scale Feature Pyramids**
  - Why needed here: Maritime vessels span extreme scale ranges (distant hulls vs. nearby ships). Fusion across pyramid levels is the primary mechanism for handling this.
  - Quick check question: Given a 640×640 input and strides [8, 16, 32], what is the smallest detectable object size at each pyramid level?

- **Concept: Domain Adaptation via Synthetic Data**
  - Why needed here: The training set is 95% synthetic; understanding domain shift helps diagnose when synthetic diversity helps vs. hurts.
  - Quick check question: Why is it critical that validation and test sets contain *only* real images when training with synthetic augmentation?

## Architecture Onboarding

- **Component map:**
  Real + Synthetic Images → Data Augmentation → Backbone → Hybrid Encoder (Intra-scale + Cross-scale Fusion) → Uncertainty-Guided Query Selection → Decoder Layers → Set Prediction

- **Critical path:**
  1. Ensure YOLO→COCO annotation conversion is correct—bbox format mismatches are a common silent failure.
  2. Verify class rebalancing: minority classes should be augmented before training, not during evaluation.
  3. Confirm test set contains only real images—any synthetic leakage invalidates generalization claims.

- **Design tradeoffs:**
  - Speed vs. accuracy: Decoder layer count can be reduced at inference without retraining, but small-object recall may drop.
  - Synthetic diversity vs. domain gap: More synthetic data improves rare-condition coverage but increases risk of negative transfer if weighting is insufficient.
  - Fusion depth vs. latency: Additional cross-scale interactions improve small-object detection but add computation.

- **Failure signatures:**
  - False positives along horizon lines: Likely domain gap from synthetic images with incorrect sky/sea boundaries.
  - Missed distant vessels: Fusion may be insufficient; consider smaller input stride or higher-resolution input.
  - Class imbalance in per-class PR curves: Check if minority-class augmentation was applied correctly.

- **First 3 experiments:**
  1. **Baseline sanity check:** Train DETR on real-only data, evaluate on real test set. Should match Table 3 "Actual→Actual" row (mAP≈0.80).
  2. **Ablation by module:** Disable fusion, query selection, and weighting one at a time. Reproduce Table 4 to verify each component's contribution.
  3. **Synthetic ratio sweep:** Vary the synthetic:real weight ratio (e.g., 0.25, 0.5, 0.75, 1.0) and plot mAP. Identify the point where synthetic data stops helping and begins to hurt.

## Open Questions the Paper Calls Out

### Open Question 1
How can the pipeline be enhanced to reliably detect extremely small or distant vessels under low illumination conditions? The Conclusion states that "detecting extremely small or distant vessels under low illumination is still difficult" despite the overall success of the model. The current architectural enhancements and data augmentation strategies were insufficient to fully resolve the visual challenges presented by low-light extreme scenarios. Demonstrated improvement in recall and precision on a specific test subset of low-illumination, long-range imagery, potentially requiring specialized low-light image enhancement modules, would resolve this.

### Open Question 2
To what extent do residual domain gaps between synthetic and real data cause mislocalization or false positives near horizon lines? The Conclusion notes that "Domain gaps between synthetic and real data can lead to understated biases, occasionally causing mislocalization or false positives near horizon lines." While a "smart weight" strategy is used, the visual simulation of complex water dynamics and horizon interfaces in synthetic data still lacks perfect fidelity, leading to specific geometric errors. A failure mode analysis quantifying the correlation between horizon-line false positives and the ratio of synthetic data used during training would resolve this.

### Open Question 3
Does the reported performance (mAP=0.89) generalize to larger, more diverse maritime benchmarks given the limited size of the evaluation set? Section 4.1 reveals the test set contains only 50 images, and Section 4.2 mentions repeating tests with multiple seeds "to reduce randomness effects due to the small test set." High performance on a held-out set of 50 images may not capture the full variance of sea states, weather, and vessel types found in operational environments. Evaluation results on larger standard maritime datasets (e.g., Singapore Maritime Dataset) showing consistent performance metrics without retraining would resolve this.

## Limitations
- Exact RT-DETR variant and backbone configuration not specified, making exact replication difficult
- Domain-aware weighting mechanism lacks detailed implementation specifics
- Synthetic images generated using unspecified GAN models (ToDayGAN, HiDT, MWTG)
- Copy-paste augmentation parameters (placement logic, blending method) not detailed
- No statistical significance testing across multiple runs

## Confidence
- **High confidence**: Multi-scale feature fusion improves small object detection; query selection reduces false positives; class rebalancing improves per-class recall.
- **Medium confidence**: Synthetic data with domain-aware weighting improves generalization; reported mAP@0.5 = 0.89 is achievable with the described pipeline.
- **Low confidence**: Exact implementation details for uncertainty-guided query selection and synthetic weighting; statistical significance of performance improvements.

## Next Checks
1. **Domain gap analysis**: Retrain with varying synthetic:real weight ratios (0.25, 0.5, 0.75, 1.0) and plot mAP to identify the optimal ratio before negative transfer occurs.
2. **Component ablation replication**: Disable fusion, query selection, and weighting individually to reproduce Table 4 and verify each module's contribution.
3. **Synthetic leakage audit**: Confirm that no synthetic images are present in validation or test sets; retrain baseline on real-only data and evaluate on real test set to match the "Actual→Actual" row (mAP≈0.80).