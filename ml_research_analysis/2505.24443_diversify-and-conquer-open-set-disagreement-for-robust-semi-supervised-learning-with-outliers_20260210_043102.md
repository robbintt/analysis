---
ver: rpa2
title: 'Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning
  with Outliers'
arxiv_id: '2505.24443'
source_url: https://arxiv.org/abs/2505.24443
tags:
- outliers
- data
- open-set
- learning
- unlabeled
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of open-set semi-supervised learning
  (OSSL), where unlabeled data contains unknown classes (outliers) that can degrade
  model performance. The key insight is that multiple SSL models trained on unlabeled
  data exhibit different biases toward outliers, leading to prediction disagreements
  that can be leveraged for outlier detection.
---

# Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers

## Quick Facts
- arXiv ID: 2505.24443
- Source URL: https://arxiv.org/abs/2505.24443
- Authors: Heejo Kong; Sung-Jin Kim; Gunho Jung; Seong-Whan Lee
- Reference count: 40
- Achieves state-of-the-art performance on open-set semi-supervised learning benchmarks, with gains up to 11.7% in closed-set and 24.2% in open-set accuracy

## Executive Summary
This paper introduces the Diversify and Conquer (DAC) framework for open-set semi-supervised learning (OSSL), addressing the challenge of unknown classes (outliers) in unlabeled data. The core insight is that multiple SSL models exhibit different biases toward outliers, creating prediction disagreements that can be leveraged for outlier detection. DAC employs a multi-head architecture with shared feature extractor, where divergent heads are trained to produce diverse predictions through mutual information minimization. Consensus scores among these heads identify potential outliers, which are then downweighted in the SSL objective. The framework also incorporates open-set knowledge distillation to enhance feature extractor training.

## Method Summary
DAC introduces a multi-head architecture where each head is trained to maximize disagreement with others through mutual information minimization, while simultaneously learning to agree on inlier samples. The framework uses consensus scores among heads to identify potential outliers, which are then downweighted during training. Open-set knowledge distillation is applied to improve feature extractor learning. The method is evaluated across multiple benchmarks including CIFAR-10/100 and ImageNet-30, demonstrating superior performance compared to existing OSSL methods, particularly when labeled data is scarce.

## Key Results
- Achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet-30 benchmarks
- Outperforms existing OSSL methods by up to 11.7% in closed-set accuracy and 24.2% in open-set accuracy
- Demonstrates particular effectiveness when labeled data is scarce
- Shows robustness across varying outlier proportions and class numbers

## Why This Works (Mechanism)
The method exploits the natural divergence in how different models handle unknown classes. When trained on mixed inlier and outlier data, different SSL models develop distinct biases in their predictions for outliers. By explicitly encouraging this diversity through mutual information minimization while maintaining consensus on inliers, DAC creates a self-supervised outlier detection mechanism. The consensus scores then provide a reliable metric for identifying and downweighting outliers during training, preventing model contamination.

## Foundational Learning

**Semi-supervised Learning (SSL)**: Learning from both labeled and unlabeled data by leveraging consistency regularization and pseudo-labeling. Why needed: Forms the baseline framework that DAC builds upon. Quick check: Does the method maintain SSL performance on purely inlier datasets?

**Mutual Information Minimization**: Technique to encourage diversity between model heads by minimizing the statistical dependence between their predictions. Why needed: Drives the creation of diverse predictions essential for outlier detection. Quick check: Is the diversity mechanism sensitive to hyperparameter choices?

**Consensus-based Outlier Detection**: Using agreement scores among multiple models to identify anomalies. Why needed: Provides the mechanism for distinguishing inliers from outliers without explicit outlier labels. Quick check: How does consensus threshold affect false positive/negative rates?

**Knowledge Distillation**: Transferring knowledge from one model to another, often from ensemble to single model. Why needed: Enhances feature extractor learning by incorporating diverse head perspectives. Quick check: Does distillation improve convergence speed or final accuracy?

## Architecture Onboarding

**Component Map**: Input -> Shared Feature Extractor -> Multiple Diverse Heads -> Consensus Scoring -> Outlier Downweighting -> SSL Objective

**Critical Path**: The core pipeline flows from the shared feature extractor through diverse heads, with consensus scores feeding back to modify the SSL objective through outlier downweighting.

**Design Tradeoffs**: The multi-head architecture increases computational cost and memory usage versus single-head approaches, but gains robustness to outliers. The mutual information minimization requires careful hyperparameter tuning to balance diversity and consensus.

**Failure Signatures**: Performance degradation when outlier distribution is highly imbalanced, when the proportion of outliers is extremely low (consensus scores become unreliable), or when the feature extractor cannot adequately separate inliers from outliers.

**First Experiments**: 1) Ablation study removing diversity mechanism to quantify its contribution, 2) Testing with varying outlier proportions to assess robustness, 3) Comparing different diversity-inducing methods (e.g., adversarial training vs. mutual information minimization).

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability concerns with multi-head architecture, particularly computational overhead and memory usage
- Limited evaluation on highly imbalanced datasets or scenarios with extreme outlier proportions
- Sensitivity of mutual information minimization approach to hyperparameter choices not fully explored

## Confidence
- **High Confidence**: Core methodology of using prediction disagreements for outlier detection, empirical results showing improved performance over baselines, mathematical formulation of consensus and diversity objectives
- **Medium Confidence**: Generalization to real-world scenarios with severe class imbalance or dynamic outlier distributions, limited testing in practical settings
- **Low Confidence**: Specific choice of mutual information minimization as optimal diversity mechanism, whether alternatives might yield better or more efficient results

## Next Checks
1. **Ablation Study on Diversity Mechanisms**: Systematically compare mutual information minimization with alternative diversity-inducing approaches (e.g., adversarial training, orthogonal initialization, or prediction disagreement regularization) to quantify the specific contribution of the chosen method.

2. **Real-world Deployment Analysis**: Evaluate DAC on datasets with severe class imbalance, domain shift, or streaming data scenarios where outlier distributions change over time, to assess practical robustness beyond controlled benchmark settings.

3. **Resource Efficiency Evaluation**: Conduct detailed computational analysis comparing DAC with single-head SSL methods in terms of training time, memory usage, and inference latency, particularly for larger-scale datasets or edge deployment scenarios.