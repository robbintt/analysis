---
ver: rpa2
title: Dynamic Expert-Guided Model Averaging for Causal Discovery
arxiv_id: '2601.16715'
source_url: https://arxiv.org/abs/2601.16715
tags:
- noisy
- clean
- causal
- expert
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of combining multiple causal
  discovery algorithms in practical settings where data may violate assumptions and
  expert knowledge is valuable. The authors propose a novel expert-guided model averaging
  approach that dynamically requests expert knowledge to resolve disagreements between
  ensemble members.
---

# Dynamic Expert-Guided Model Averaging for Causal Discovery

## Quick Facts
- arXiv ID: 2601.16715
- Source URL: https://arxiv.org/abs/2601.16715
- Reference count: 40
- Primary result: Expert-guided model averaging improves causal discovery performance by dynamically incorporating expert knowledge to resolve algorithmic disagreements

## Executive Summary
This paper introduces a novel approach to causal discovery that leverages ensemble methods combined with dynamic expert guidance. The method treats causal discovery as a model averaging problem where multiple diverse algorithms are combined, and expert knowledge is queried only when algorithms disagree on edge presence or orientation. This approach addresses the practical challenge of combining multiple causal discovery algorithms in settings where data may violate assumptions and expert knowledge is valuable. The method demonstrates improved performance over baseline ensembles and individual algorithms, particularly when expert guidance is incorporated.

## Method Summary
The approach combines multiple causal discovery algorithms into an ensemble and uses a dynamic querying mechanism to incorporate expert knowledge when algorithms disagree. The method treats causal discovery as a model averaging problem, where edge presence and orientation are determined by consensus among ensemble members. When disagreements occur, the system queries an expert (either simulated or LLM-based) to resolve the discrepancy. This selective querying approach reduces the burden on experts while maintaining high accuracy. The method is flexible and can incorporate various types of experts and algorithms, making it adaptable to different domains and application contexts.

## Key Results
- Expert-guided averaging achieved 10-20% BSF improvements over baseline ensembles using a simulated expert with 80% correctness
- The method demonstrated better precision-recall trade-offs compared to individual algorithms or ensembles without expert guidance
- LLM-based experts showed comparable performance to simulated experts, validating practical applicability
- A linear relationship was observed between expert accuracy and method performance

## Why This Works (Mechanism)
The method works by treating causal discovery as an ensemble averaging problem where multiple algorithms provide different perspectives on causal relationships. When algorithms disagree, this indicates uncertainty in the causal structure, which is precisely when expert knowledge becomes most valuable. By querying experts only in cases of disagreement, the method efficiently leverages human expertise where automated methods struggle. The dynamic nature of the querying process ensures that experts are only consulted when necessary, making the approach practical for real-world applications where expert time is limited.

## Foundational Learning
- Causal discovery ensemble methods: Combining multiple algorithms provides complementary strengths and weaknesses, improving robustness to data violations. Quick check: Different algorithms make different assumptions about data distribution and causal structure.
- Expert-guided machine learning: Human expertise can resolve ambiguities that automated methods cannot, particularly in complex domains like healthcare. Quick check: Experts can identify causal relationships that violate algorithmic assumptions.
- Model averaging in machine learning: Aggregating multiple model predictions often outperforms individual models by reducing variance and bias. Quick check: Ensemble methods typically show improved generalization compared to single models.

## Architecture Onboarding

Component Map:
Algorithms (PC, GES, LiNGAM, etc.) -> Ensemble Aggregator -> Disagreement Detector -> Expert Query Module -> Final Causal Graph

Critical Path:
Algorithm outputs → Ensemble voting → Disagreement detection → Expert query (if needed) → Consensus building → Final causal structure

Design Tradeoffs:
The method trades increased computational complexity (expert queries) for improved accuracy. The selective querying approach minimizes expert burden but requires careful threshold setting for when to trigger expert consultation. The ensemble approach adds computational overhead but provides robustness to individual algorithm failures.

Failure Signatures:
- Poor performance when experts are consistently incorrect or biased
- High query rates indicating fundamental disagreement among algorithms
- Slow convergence when expert responses are delayed or inconsistent
- Degraded performance on highly complex causal structures

First 3 Experiments:
1. Compare ensemble performance with and without expert guidance on synthetic datasets with known ground truth
2. Vary expert accuracy levels (50% to 100%) to establish the relationship between expert quality and method performance
3. Test the method on noisy real-world datasets to evaluate robustness to data violations

## Open Questions the Paper Calls Out
The paper identifies several open questions regarding the practical implementation of expert-guided causal discovery. These include understanding the optimal strategies for expert selection and training, determining the best approaches for handling expert disagreements or inconsistencies, and developing methods for efficiently scaling the approach to larger causal graphs. The paper also notes the need for further investigation into how different types of expert knowledge (e.g., structural vs. quantitative) can be best incorporated into the causal discovery process.

## Limitations
- The approach requires access to reliable experts, whose quality may vary significantly in real-world applications
- The linear relationship between expert accuracy and method performance assumes independent and unbiased expert errors
- Computational overhead from expert queries and potential response delays are not fully characterized
- Performance on highly complex causal structures or severely violated assumptions remains unclear

## Confidence
- Expert-guided averaging improves performance over baseline ensembles: High
- Linear relationship between expert accuracy and method performance: Medium
- LLM-based experts can effectively substitute for simulated experts: Medium
- Method works well on both clean and noisy data: Medium
- Better precision-recall trade-offs compared to individual algorithms: Medium

## Next Checks
1. Test the method on real-world healthcare datasets with actual domain experts to validate performance in practical settings and assess the impact of expert response time delays.
2. Evaluate the method's robustness to expert bias by introducing systematic errors in expert judgments and measuring performance degradation.
3. Investigate the computational complexity and scalability of the approach when applied to larger causal graphs with hundreds of variables.