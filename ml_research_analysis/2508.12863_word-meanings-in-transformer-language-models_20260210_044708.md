---
ver: rpa2
title: Word Meanings in Transformer Language Models
arxiv_id: '2508.12863'
source_url: https://arxiv.org/abs/2508.12863
tags:
- clusters
- word
- information
- semantic
- cluster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper investigates whether static embeddings in transformer
  language models contain semantic information. The authors cluster the 768-dimensional
  static embeddings of RoBERTa-base (50,265 tokens) into 200 groups and analyze their
  sensitivity to five psycholinguistic measures: valence, concreteness, iconicity,
  taboo, and age of acquisition.'
---

# Word Meanings in Transformer Language Models

## Quick Facts
- arXiv ID: 2508.12863
- Source URL: https://arxiv.org/abs/2508.12863
- Authors: Jumbly Grindrod; Peter Grindrod
- Reference count: 6
- Primary result: Static embeddings in transformer models encode rich semantic information organized by psycholinguistic properties

## Executive Summary
This study investigates whether static embeddings in transformer language models contain semantic information beyond surface-level features. The authors cluster 768-dimensional static embeddings from RoBERTa-base (50,265 tokens) into 200 groups and analyze their sensitivity to five psycholinguistic measures. Manual inspection revealed semantically coherent clusters (colors, medical terms, occupations), while statistical tests showed 73 clusters were sensitive to at least one psycholinguistic attribute. The findings demonstrate that static embeddings serve as a "lexical store" of semantic information, refuting meaning eliminativist hypotheses about LLM processing.

## Method Summary
The methodology involves extracting RoBERTa-base static embeddings (50,265 Ã— 768 dimensions), applying k-means clustering with k=200, and testing cluster attribute distributions against population baselines. For each of five psycholinguistic attributes (valence, concreteness, iconicity, taboo, age of acquisition), the study computes multinomial log-probabilities and compares them against 100,000 random samples. Clusters are flagged as sensitive when their attribute distributions are statistically improbable under the null hypothesis of random sampling.

## Key Results
- 67 manually-identified clusters showed semantic coherence across diverse domains (colors, occupations, medical terms, familial relations)
- 73 of 200 clusters were sensitive to at least one psycholinguistic attribute
- Concreteness affected 60 clusters and age of acquisition affected 36 clusters
- The lexical store interpretation of static embeddings was supported, challenging meaning eliminativist views

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Static embeddings encode semantic information beyond surface-level features
- Mechanism: Pre-training associates invariant vector representations with tokens such that semantically related words occupy proximate regions in embedding space
- Core assumption: Clustering structure reflects learned semantic organization rather than artifacts
- Evidence: Manual inspection identified 67 clusters with semantic themes; corpus work suggests semantic encoding is active research
- Break condition: If clusters driven by syntactic/morphological features, semantic themes wouldn't emerge consistently

### Mechanism 2
- Claim: Psycholinguistic attributes correlate with embedding space organization
- Mechanism: Words sharing psycholinguistic properties cluster together, producing statistically improbable distributions under random sampling
- Core assumption: Attribute sensitivity indicates semantic encoding rather than spurious correlation
- Evidence: Cluster 172's valence distribution had log probability -354.667; 73 clusters sensitive to attributes
- Break condition: If sensitive clusters correlate via confounds (frequency, syllable count), semantic encoding claims weaken

### Mechanism 3
- Claim: Static embeddings function as a "lexical store" analogous to human mental lexicons
- Mechanism: Static embeddings pre-encode semantic content that contextualized embeddings subsequently modulate
- Core assumption: Distinction between static/contextualized embeddings maps onto word meaning vs. occasion-specific use
- Evidence: Study refutes meaning eliminativism; corpus work identifies concept-level vs. token-level processing
- Break condition: If semantic information in static embeddings is negligible compared to self-attention, lexical store analogy weakens

## Foundational Learning

- **Static vs. Contextualized Embeddings**
  - Why needed: Central question concerns information in static embeddings before contextualization
  - Quick check: Given the same word in two different sentences, which embedding type would differ between occurrences?

- **K-Means Clustering in High-Dimensional Spaces**
  - Why needed: Methodology depends on clustering 50,265 tokens in 768-dimensional space
  - Quick check: Why might k=200 clusters produce different semantic insights than k=20 or k=2000?

- **Null Hypothesis Significance Testing for Categorical Distributions**
  - Why needed: Study tests whether observed attribute distributions within clusters are improbable under random sampling
  - Quick check: If a cluster has only 5 annotated tokens for an attribute, what statistical problem arises?

## Architecture Onboarding

- Component map: RoBERTa-base (12-layer transformer) -> Static embeddings (input layer vectors) -> Contextualized embeddings (self-attention output) -> Positional embeddings (added before self-attention)

- Critical path: 1) Extract static embeddings from model.embeddings.word_embeddings.weight, 2) Apply k-means with k=200 to 768-dimensional vectors, 3) For each cluster compute attribute distribution and compare against population using log-probability test, 4) Validate significance via Monte Carlo sampling (100,000 random subsets)

- Design tradeoffs: K=200 balances granularity with statistical power; duplicates handled conservatively; attribute binning reduces sensitivity but improves tractability

- Failure signatures: Clusters with <10 annotated tokens produce unreliable estimates; small attribute lists increase sampling error; iconicity results may reflect surface feature confounds

- First 3 experiments: 1) Reproduce k-means clustering and inspect 5 random clusters for semantic coherence, 2) Test sensitivity to new psycholinguistic attribute (e.g., arousal) using same methodology, 3) Compare RoBERTa-base against different transformer (BERT-base or GPT-2)

## Open Questions the Paper Calls Out
None

## Limitations
- Manual cluster inspection introduces subjective bias despite objectivity efforts
- Small cluster sizes for certain attributes (particularly taboo) create sampling error vulnerabilities
- Deduplication strategy may systematically exclude valid semantic variants
- k=200 clustering choice represents arbitrary middle ground that could miss patterns at different granularities

## Confidence

- **High Confidence**: Static embeddings contain measurable semantic information beyond surface features
- **Medium Confidence**: 73 sensitive clusters demonstrate statistically significant psycholinguistic sensitivity
- **Medium Confidence**: Static embeddings function as a lexical store
- **Low Confidence**: K-means clustering optimally reveals semantic structure

## Next Checks
1. Test cluster stability across different k-means initializations and multiple random seeds
2. Apply methodology to non-transformer architectures (LSTMs, RNNs) to determine if semantic encoding is transformer-specific
3. Conduct formal inter-rater reliability study for manual cluster inspections