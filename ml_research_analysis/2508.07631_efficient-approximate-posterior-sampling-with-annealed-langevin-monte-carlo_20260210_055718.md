---
ver: rpa2
title: Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo
arxiv_id: '2508.07631'
source_url: https://arxiv.org/abs/2508.07631
tags:
- posterior
- sampling
- have
- prior
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies posterior sampling in the context of score-based
  generative models, where the goal is to sample from the posterior distribution p(x|y)
  given a prior p(x) and a measurement model p(y|x). The authors address the computational
  hardness of exact posterior sampling by introducing an approximate notion that simultaneously
  guarantees closeness to the posterior of a noised prior in KL divergence and to
  the true posterior in Fisher divergence.
---

# Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo

## Quick Facts
- arXiv ID: 2508.07631
- Source URL: https://arxiv.org/abs/2508.07631
- Reference count: 40
- This paper introduces Annealed Langevin Monte Carlo (ALMC), achieving polynomial-time approximate posterior sampling with simultaneous KL and Fisher divergence guarantees.

## Executive Summary
This paper addresses the computational hardness of exact posterior sampling by introducing an approximate notion that simultaneously guarantees closeness to the posterior of a noised prior in KL divergence and to the true posterior in Fisher divergence. The authors propose Annealed Langevin Monte Carlo (ALMC), which operates in two phases: a warm start using standard Langevin dynamics to get close to the posterior of a highly noised prior, followed by an annealing phase that progressively tracks the posterior of less noised priors using an annealed Langevin process. Under minimal assumptions, ALMC can sample from a distribution that is both close to the posterior of a noised prior and close to the true posterior, achieving polynomial-time guarantees.

## Method Summary
The Annealed Langevin Monte Carlo (ALMC) algorithm works by first running standard Langevin Monte Carlo (LMC) targeting a warm start distribution $\mu_\infty \propto \gamma e^{-R}$, which is strongly log-concave due to the convex measurement operator $R$. This warm start ensures the sampler aligns with the measurement while ignoring the prior. The algorithm then transitions to an annealing phase, tracking the path of posteriors $\mu_t \propto p_t e^{-R}$ from high noise to low noise using the prior score $\nabla \log p_t$ and likelihood gradient $-\nabla R$. The annealing rate is slowed by a factor of $\kappa$ relative to the natural reverse diffusion rate, allowing the sampler to track the shifting posterior distribution with bounded error. The algorithm stops at an early time $\tau$ to maintain theoretical guarantees.

## Key Results
- ALMC achieves polynomial-time guarantees for approximate posterior sampling with runtime O(κ^5/4)
- The method provides simultaneous guarantees: closeness to noised posterior in KL divergence and to true posterior in Fisher divergence
- The dual divergence relaxation avoids the cryptographic hardness of exact KL sampling while preventing mode collapse
- The algorithm works under minimal assumptions: Lipschitz scores, sub-Gaussian priors, and smooth convex likelihood

## Why This Works (Mechanism)

### Mechanism 1: Warm-Start Initialization via Log-Concave Likelihood
The algorithm first runs standard Langevin Monte Carlo (LMC) targeting $\mu_\infty \propto \gamma e^{-R}$, where $R$ is convex and smooth. This creates a strongly log-concave target that satisfies the Log-Sobolev Inequality, allowing LMC to converge in polynomial time. This warm start effectively "ignores" the complex prior structure initially to find a region consistent with the measurement.

### Mechanism 2: Dual Divergence Relaxation (KL for Global, Fisher for Local)
The algorithm relaxes the goal to simultaneously minimize KL divergence to a noised posterior and Fisher divergence to the true posterior. KL convergence ensures global correctness in density (proper mode weights), while Fisher convergence ensures local gradient consistency (shape of modes) without being sensitive to global density ratios.

### Mechanism 3: Rate-Controlled Annealing
The algorithm slows down the annealing process by a factor of $\kappa$, reducing the "velocity" term in the action integral and minimizing the accumulation of discretization error. This controlled rate ensures the law of the iterate $\rho_t$ does not lag too far behind the target $\mu_t$.

## Foundational Learning

- **Score-Based Generative Models (Diffusion Models)**
  - Why needed: The method relies on accessing $\nabla \log p_t(x)$ (the score) of the prior
  - Quick check: Given a score network $s_\theta(x, t)$ approximating $\nabla \log p_t(x)$, how does one derive the drift term for the reverse SDE?

- **Fisher Divergence vs. KL Divergence**
  - Why needed: The core theoretical contribution trades off these two metrics
  - Quick check: For a mixture of two Gaussians separated by a large distance, why might a sampler have low Fisher divergence but high KL divergence relative to the target?

- **Log-Sobolev Inequality (LSI)**
  - Why needed: The "Warm Start" phase efficiency depends entirely on the target satisfying LSI
  - Quick check: Why does the assumption that $R$ is convex ensure that the warm-start target $\mu_\infty \propto \gamma e^{-R}$ satisfies LSI?

## Architecture Onboarding

- **Component map:** Standard Gaussian $\gamma$ -> Warm Start LMC (target $\mu_\infty$) -> Annealed Langevin MC (track $\mu_t$ path) -> Sample at time $\tau$

- **Critical path:**
  1. Initialize: $X_0 \sim \mathcal{N}(0, I)$
  2. Warm Start: Run LMC on $X + \nabla R(X)$ until $X \sim \mu_{T_{ws}}$
  3. Anneal: For $t$ from $T_{ws} \to 0$: $X \leftarrow X + \delta(\nabla \log p_t(X) - \nabla R(X)) + \sqrt{2\delta}\eta$
  4. Output: The sample at the early stop time $\tau$

- **Design tradeoffs:**
  - Runtime vs. Accuracy: Increasing $\kappa$ improves tracking but linearly increases wall-clock time
  - Consistency vs. Tractability: Sampling exactly to $t=0$ in KL is intractable; must stop at noise level $\tau > 0$

- **Failure signatures:**
  - Mode Collapse: Low Fisher divergence but high KL divergence; samples match measurement but are not diverse
  - Measurement Inconsistency: High reconstruction error $\|Ax - y\|$

- **First 3 experiments:**
  1. **Sanity Check (Mixture of Gaussians):** Verify mode weights match theoretical posterior weights
  2. **Ablation on Warm Start:** Measure success rate without warm start phase
  3. **Linear Inverse Problem:** Apply to MNIST/CelebA with pre-trained score network

## Open Questions the Paper Calls Out

- **Can dual divergence guarantees extend to other posterior sampling frameworks?** The paper believes this type of guarantee is also possible with other popular posterior sampling frameworks like Split-Gibbs sampling, which can be interpreted as a different discrete path through the space of distributions.

- **Are there alternative annealing paths that provide better efficiency?** The paper suggests there may be other paths $\{\mu_t\}$ that allow us to sample from interpretable approximations to the true posterior, such as one that more closely aligns with DDPM rather than Annealed Langevin.

- **How does score estimation error affect theoretical guarantees?** The paper assumes exact prior scores for theoretical analysis, citing works on error propagation but explicitly excluding this analysis from current theoretical bounds.

## Limitations
- Theoretical guarantees depend on exact score access, not practical approximate scores
- Polynomial runtime bounds hide large constants that may dominate in high dimensions
- Unknown approximation errors when translating bounds to real-world pre-trained score networks

## Confidence
- **High confidence:** The algorithmic framework combining warm-start LMC with annealed dynamics is well-founded and mechanistically sound
- **Medium confidence:** The theoretical polynomial complexity bounds hold under stated assumptions, though constants remain unknown
- **Low confidence:** The practical performance gap between theory and implementation with approximate scores is unquantified

## Next Checks
1. **Concrete implementation:** Implement ALMC on a 2D synthetic mixture of Gaussians with analytic scores to verify warm-start prevents mode collapse
2. **Approximate score evaluation:** Test ALMC using a pre-trained diffusion model's score estimates on a linear inverse problem to quantify score approximation impact
3. **Runtime validation:** Measure actual iteration counts and compute time on MNIST/CelebA for varying κ to empirically verify O(κ^{5/4}) scaling