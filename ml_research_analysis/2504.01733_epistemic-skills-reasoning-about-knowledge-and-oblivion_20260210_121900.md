---
ver: rpa2
title: 'Epistemic Skills: Reasoning about Knowledge and Oblivion'
arxiv_id: '2504.01733'
source_url: https://arxiv.org/abs/2504.01733
tags:
- knowledge
- tail
- logic
- where
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a class of epistemic logics to model the
  dynamics of acquiring knowledge and descending into oblivion, using weighted models
  and "epistemic skills" as a metric for knowledge updates. Knowledge acquisition
  is represented as upskilling, while oblivion is modeled as downskilling.
---

# Epistemic Skills: Reasoning about Knowledge and Oblivion

## Quick Facts
- arXiv ID: 2504.01733
- Source URL: https://arxiv.org/abs/2504.01733
- Reference count: 20
- Primary result: Introduces weighted epistemic logics with epistemic skills to model knowledge acquisition and oblivion, analyzing computational complexity for various logics

## Executive Summary
This paper introduces a novel framework for modeling epistemic dynamics using weighted Kripke models where edges represent skills ineffective at distinguishing between possible worlds. The system uses "epistellic skills" as a metric for knowledge updates, where knowledge acquisition is represented as upskilling (adding skills) and oblivion as downskilling (removing skills). The framework enables exploration of knowability (potential to gain knowledge through upskilling) and forgettability (potential to lapse into oblivion through downskilling), while distinguishing between epistemic de re and de dicto expressions.

## Method Summary
The method involves implementing model checkers for weighted epistemic logic $\mathcal{L}_{CDEF+^{-}=\equiv\Box\blacksquare\Diamond}$ to evaluate the truth of epistemic formulas in finite models. The framework uses weighted Kripke models where edges represent ineffective skills, and knowledge is defined through capability functions that map agents to skill sets. Updates to knowledge are implemented as set-theoretic operations (union for upskilling, difference for downskilling) on these capability functions. The system supports common knowledge, group knowledge, and quantifying modalities for exploring potential knowledge states.

## Key Results
- Model checking is in P for logics without quantifying modalities and PSPACE complete with quantifiers
- Satisfiability is PSPACE complete for logics without common knowledge, update, or quantifying modalities
- Satisfiability is EXPTIME complete for logics with common knowledge
- The framework successfully models knowledge acquisition and oblivion through skill-based dynamics

## Why This Works (Mechanism)

### Mechanism 1: Inverted Indistinguishability via Skill Sets
The framework models knowledge by inverting the standard accessibility relation; instead of accessing worlds where an agent has a skill, the logic accesses worlds where the agent lacks the skills to distinguish them. Edges in the weighted model $E(w, u)$ represent the set of skills that are ineffective at distinguishing world $w$ from $u$. An agent $a$ knows $\phi$ at $w$ ($K_a \phi$) only if $\phi$ holds in all worlds $u$ where the agent's capability set $C(a)$ is a subset of these ineffective skills ($C(a) \subseteq E(w, u)$).

### Mechanism 2: Dynamic Capability Updates (Upskilling/Downskilling)
Knowledge acquisition (learning) and loss (forgetting) are mechanically driven by set-theoretic operations on the agent's capability function, rather than changing the topology of the world graph. The framework defines update modalities that locally modify the capability function $C$: upskilling ($ (+S)a $) modifies $C(a)$ to $C(a) \cup S$ (increasing discriminatory power), while downskilling ($ (-S)a $) modifies $C(a)$ to $C(a) \setminus S$ (decreasing discriminatory power).

### Mechanism 3: Quantifying Modalities for Knowability
The potential for knowledge (knowability) is formalized by quantifying over the existence of a specific skill set update that would result in a knowledge state. The logic introduces quantifiers $\boxplus_a$ (arbitrary upskilling) and $\boxminus_a$ (arbitrary downskilling). $\phi$ is "knowable" by agent $a$ if there exists some upskilling operation that results in $a$ knowing $\phi$ ($\neg \boxplus_a \neg K_a \phi$), shifting the complexity of model checking from P to PSPACE.

## Foundational Learning

- **Weighted Kripke Models**: Replaces binary accessibility with weighted edge function $E$ where weights represent ineffectiveness. Why needed: Understanding weights as "ineffective skills" is prerequisite to interpreting the model. Quick check: In $E(w, v) = \{s_1, s_2\}$, does agent with $\{s_1\}$ distinguish $w$ from $v$? (Answer: No).

- **Set-Theoretic Operations (Union/Difference)**: Dynamics implemented as $C(a) \cup S$ and $C(a) \setminus S$. Why needed: These operations drive learning/forgetting mechanics. Quick check: Agent with $\{1, 2\}$ undergoes $+ \{3\}$; new capability? (Answer: $\{1, 2, 3\}$).

- **De Re vs. De Dicto Distinction**: Distinguishes knowing that a fact is true (De Dicto) vs. knowing how to achieve a state via skills (De Re). Why needed: Crucial for interpreting the nuance of the "Knowability" operator. Quick check: Does $\boxplus_a K_a \phi$ represent knowing that $\phi$ is true or knowing how $\phi$ becomes true? (Answer: De Re - knowing how).

## Architecture Onboarding

- **Component map**: Frame $(W, E)$ -> Capability Function $C$ -> Valuation $\beta$ -> Update Operators
  - Frame $(W, E)$: Static environment with states $W$ and edge function $E(w,u)$ representing ineffective skills
  - Capability Function $C$: Agent state mapping agent ID → Skill Set
  - Valuation $\beta$: Ground truth mapping state → True Propositions
  - Update Operators: Control logic modifying $C$ without touching $E$

- **Critical path**:
  1. Data Abstraction: Convert dataset (attributes) into Weighted Kripke Frame $(W, E)$
  2. Initialization: Define initial Capability $C$ for relevant agents
  3. Query: Evaluate epistemic formulas by checking if $C(a)$ intersects with distinguishing skills on relevant edges

- **Design tradeoffs**:
  - Implicit vs. Explicit Skills: Implicit skills simplify language but require pre-computation; explicit skills allow dynamic reasoning but increase complexity
  - Complexity vs. Expressivity: Including quantifiers allows reasoning about "potential" knowledge but escalates model checking complexity from P to PSPACE

- **Failure signatures**:
  - Total Ignorance: $C(a) = \emptyset$ → agent cannot distinguish any worlds
  - Omniscience: $C(a) = \mathcal{S}$ → agent may know too much
  - Invalid Model: Non-symmetric $E$ breaks logic of "similarity"

- **First 3 experiments**:
  1. Solar System Replication: Implement abstraction from Section 2.3; verify Agent A ($C=\{1,2\}$) does not know $p$ at world $e$
  2. Upskilling Intervention: Apply $(+ \{3\})$ to Agent A; verify now knows $p$ at world $e$
  3. Quantifier Stress Test: Construct model where $\phi$ is "knowable"; benchmark model checking time to observe P to PSPACE shift

## Open Questions the Paper Calls Out

### Open Question 1
What is the computational complexity of the satisfiability problem for logics that include update modalities or quantifying modalities? The paper states this complexity remains an open question, with Table 4 listing these logics as "?".

### Open Question 2
Is the satisfiability problem decidable for the full logic $LCDEF+−=≡⊞⊟2$? Section 5 explicitly states this decidability remains unresolved.

### Open Question 3
Can a complete axiomatic system be developed for the full logic? The paper notes that while fragments have axiomatizations, a complete system for the full logic has yet to be developed.

## Limitations
- The quantifying modalities algorithm explicitly iterates over all subsets of skills, potentially leading to exponential blow-up despite PSPACE completeness claims
- Assumes skills are independent attributes that can be added/removed without affecting underlying state structure
- Practical implementation faces significant computational challenges for non-trivial skill sets

## Confidence

- **High confidence**: Core mechanism of inverted indistinguishability via skill sets is well-supported by formal definitions in Section 2.2
- **Medium confidence**: Dynamic capability updates are clearly defined but practical applicability depends on independence assumption for skills
- **Medium confidence**: Quantifying modalities are formally correct but practical implementation faces significant computational challenges

## Next Checks
1. Implement benchmark comparing theoretical PSPACE complexity of quantifier algorithm against practical runtimes for models with 2, 3, 4, 5 skills
2. Construct non-trivial example with skill dependencies (e.g., removing skill 1 implicitly removes skill 2) and test set-theoretic operations
3. Develop optimized version of Algorithm 3 using memoization or symbolic representation of skill sets, then compare performance against naive implementation on Solar System example