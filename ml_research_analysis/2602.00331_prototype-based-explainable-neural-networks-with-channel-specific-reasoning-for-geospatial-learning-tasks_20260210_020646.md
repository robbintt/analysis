---
ver: rpa2
title: Prototype-based Explainable Neural Networks with Channel-specific Reasoning
  for Geospatial Learning Tasks
arxiv_id: '2602.00331'
source_url: https://arxiv.org/abs/2602.00331
tags:
- prototypes
- prototype
- channel
- channels
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a prototype-based neural network method for
  explainable AI that uses channel-specific prototypes to interpret multi-channel
  geospatial data. The method learns separate prototypical patterns for each channel,
  allowing it to identify which channels and spatial regions drive predictions for
  individual instances and across the entire model.
---

# Prototype-based Explainable Neural Networks with Channel-specific Reasoning for Geospatial Learning Tasks

## Quick Facts
- arXiv ID: 2602.00331
- Source URL: https://arxiv.org/abs/2602.00331
- Authors: Anushka Narayanan; Karianne J. Bergen
- Reference count: 30
- Primary result: Channel-specific prototype-based neural networks achieve comparable accuracy to standard neural networks while providing interpretable explanations for multi-channel geospatial data.

## Executive Summary
This paper introduces a prototype-based neural network method designed for explainable AI in multi-channel geospatial learning tasks. The approach learns separate prototypical patterns for each channel, enabling the identification of which channels and spatial regions drive predictions. Applied to synthetic MNIST, MJO phase classification, and land-use classification, the method achieves accuracy comparable to standard neural networks while providing interpretable local and global explanations. The architecture's channel-specific reasoning allows it to identify patterns that vary across channels and regions, making it particularly effective for geospatial data where physical variables often operate independently.

## Method Summary
The method uses a shared encoder to process each channel separately, computing similarity scores against separate prototype banks for each channel. A three-stage training process with periodic projection ensures prototypes correspond to actual data instances. During projection, abstract prototype parameters are replaced by the latent vector of the most similar training patch, grounding explanations in reality. The final linear classification layer on top of similarity scores provides direct global and local feature attribution, with weights explicitly quantifying each channel's importance to predictions.

## Key Results
- Achieved 0.978 accuracy on synthetic MNIST with channel-specific prototypes versus 0.685 with joint prototypes
- Successfully identified channel-specific patterns in MJO phase classification aligned with scientific understanding
- Generated interpretable explanations from pre-trained encoders in land-use classification tasks
- Demonstrated ability to identify irrelevant channels through zero weights in the linear classification layer

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Isolating prototypes to specific channels enhances model transparency and accuracy when distinct physical variables drive predictions independently.
- Mechanism: The architecture splits input by channel before passing it through a shared encoder, computing similarity scores against separate prototype banks for each channel rather than forcing a single prototype to represent joint patterns.
- Core assumption: Task-relevant features are localized within specific channels or simple combinations thereof, rather than requiring complex, non-linear interactions across all channels simultaneously.
- Evidence anchors: [abstract] "identify separate, channel-specific prototypical characteristics... that inform how these features individually... influence model prediction"; [section 4.3.1] Demonstrates channel-specific model outperforms joint-prototype model (0.978 vs 0.685 accuracy) on synthetic task where labels are channel-dependent.

### Mechanism 2
- Claim: A three-stage training process with periodic projection ensures prototypes correspond to actual data instances, grounding the explanation in reality.
- Mechanism: The model trains in stages (learning, projection, fine-tuning). During projection, abstract prototype parameters are replaced by the latent vector of the most similar training patch (min L2 distance), ensuring the "prototype" visualizes as a real image region.
- Core assumption: The latent space is sufficiently smooth that the nearest training patch is a meaningful representative of the learned prototype concept.
- Evidence anchors: [section 2.2.3] "The stage 2 projection step ensures prototypes remain interpretable and visualizable by replacing the learned prototype parameter values with similar patches selected from training examples."

### Mechanism 3
- Claim: A linear classification layer on top of similarity scores provides direct global and local feature attribution.
- Mechanism: The final layer performs a weighted linear sum of the max-similarity scores from all channel prototypes. The weights ($W_H$) explicitly quantify the importance of each channel's prototype to the final class.
- Core assumption: The decision boundary can be approximated by a linear combination of prototype similarities.
- Evidence anchors: [section 2.1.3] "The model prediction is determined from a weighted combination of all of the computed prototype similarity values."

## Foundational Learning

- Concept: **Prototype-based Reasoning**
  - Why needed here: Standard neural networks map inputs to classes directly (black box). Prototype networks map inputs to "similarity with known examples" first, then to classes, making the reasoning ("this looks like that") explicit.
  - Quick check question: Can you explain why a standard CNN output is harder to audit than a prototype network output?

- Concept: **Multi-channel Geospatial Data**
  - Why needed here: Unlike RGB images (where channels combine to form a color), geospatial channels (e.g., temperature, wind, elevation) often represent independent physical variables. Treating them like RGB can obscure physical causality.
  - Quick check question: Why would a prototype learning a joint pattern across "Wind" and "Temperature" be harder to interpret than two separate prototypes?

- Concept: **Latent Space Projection**
  - Why needed here: Neural network layers operate in an abstract "latent space." To make sense of them, we must map these abstract points back to the original image pixels (receptive field).
  - Quick check question: If a prototype is not "projected" onto a training image, what format would it exist in, and would it be interpretable?

## Architecture Onboarding

- Component map: Input (X) → Split (X → [X₁,...,X_C]) → Shared Encoder (f) → Per-channel Prototypes (P_c) → Similarity (L2) → Max Pool → Concatenation → Linear Classifier → Prediction

- Critical path: The **Projection Step (Stage 2)** is the most distinct operation. It is not a standard backprop step; it is a hard assignment/replacement of weights derived from the training set statistics. If this fails (e.g., inefficient search), training stalls.

- Design tradeoffs:
  - **Shared vs. Separate Encoders**: The paper finds a **shared encoder** is sufficient and more efficient than separate encoders per channel (Supplement Section 1), trading parameter isolation for size reduction.
  - **Linear vs. MLP Head**: Using a linear layer for classification trades raw accuracy for global interpretability of weights (Section 2.1.3).

- Failure signatures:
  - **Phase Confusion**: In the MJO task, the model predicts adjacent phases (Section 5.3.1). This indicates the latent space clusters are continuous, not discrete, and the linear boundary struggles.
  - **Zero Weights**: If the linear layer assigns near-zero weights to all prototypes of a channel (Section 5.3.3), it signals that channel is irrelevant or the encoder failed to extract features.

- First 3 experiments:
  1. **Synthetic Validation**: Replicate the MNIST-style experiment (Section 4) where ground truth is explicitly channel-dependent to verify the model attends to the correct channel.
  2. **Noise Ablation**: Add a pure noise channel to the input (Section 5.3.3). Verify that the linear layer weights for this channel remain near zero.
  3. **Pre-trained Transfer**: Freeze a standard encoder (e.g., ResNet) and attempt to train only the prototype layers (Section 6.3.1) to test if meaningful prototypes can be extracted from existing black-box features.

## Open Questions the Paper Calls Out
The paper identifies several open questions for future research, including improving the efficiency of the prototype projection step for larger datasets through representative sub-sampling, developing systematic methodologies for tuning the weighting of cluster, separation, and diversity loss terms to ensure semantic clarity and consistency of generated prototypes, and augmenting the channel-specific prototype architecture to explicitly capture pattern intensity in addition to spatial location for improved classification of continuous phenomena like the MJO.

## Limitations
- The method's core assumption that task-relevant features are localized within specific channels may not hold for all geospatial tasks requiring complex interactions across channels.
- The projection step relies on the availability of similar training patches, which may not exist for idealized or rare patterns.
- The linear classification layer may struggle with highly non-linear decision boundaries common in complex geospatial phenomena.

## Confidence
- **High Confidence**: The mechanism of using channel-specific prototypes to enhance interpretability is well-supported by synthetic MNIST experiments showing clear performance differences between channel-specific and joint approaches.
- **Medium Confidence**: The three-stage training process with projection ensures prototype grounding in real data, though specific implementation details are not fully specified.
- **Low Confidence**: The claim that this approach works particularly well for tasks where relevant information varies across channels and regions is based on limited case studies and may not generalize to all geospatial domains.

## Next Checks
1. **Synthetic Channel-Dependency Test**: Replicate the MNIST-style experiment with explicit channel-dependent labels to verify the model correctly attends to the appropriate channel for different classes.
2. **Noise Channel Ablation**: Add a pure noise channel to the input data and verify that the linear classifier assigns near-zero weights to this irrelevant channel, demonstrating the model's ability to identify irrelevant information.
3. **Pre-trained Encoder Transfer**: Freeze a standard pre-trained encoder (e.g., ResNet) and attempt to train only the prototype layers to test whether meaningful prototypes can be extracted from existing black-box features.