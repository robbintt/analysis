---
ver: rpa2
title: 'FW-Shapley: Real-time Estimation of Weighted Shapley Values'
arxiv_id: '2503.06602'
source_url: https://arxiv.org/abs/2503.06602
tags:
- shapley
- values
- weighted
- data
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces FW-Shapley, a fast amortized method for computing
  weighted Shapley values in high-dimensional ML tasks. Weighted Shapley values generalize
  standard Shapley values by allowing different weights for subsets of different cardinalities,
  addressing suboptimal credit assignments in feature attribution and data valuation.
---

# FW-Shapley: Real-time Estimation of Weighted Shapley Values

## Quick Facts
- arXiv ID: 2503.06602
- Source URL: https://arxiv.org/abs/2503.06602
- Reference count: 0
- Introduces FW-Shapley, a fast amortized method for computing weighted Shapley values that outperforms FastSHAP by 27% in inclusion AUC on average

## Executive Summary
FW-Shapley addresses the computational challenge of calculating weighted Shapley values, which generalize standard Shapley values by allowing different weights for subsets of different cardinalities. This weighting mechanism improves credit assignment in feature attribution and data valuation tasks, but traditional computation requires exponential time. The paper introduces a learned estimator framework that eliminates the need for ground truth values during training, enabling real-time inference while maintaining theoretical soundness.

The method demonstrates significant practical improvements across multiple datasets including CIFAR10, SVHN, and FMNIST. FW-Shapley achieves 27% better performance than FastSHAP in feature attribution tasks and provides 14x speedup over KNN-Shapley for data valuation while maintaining comparable accuracy in noisy label detection. The approach represents a substantial advancement in making weighted Shapley value calculations practical for high-dimensional machine learning applications.

## Method Summary
The paper introduces FW-Shapley, a fast amortized method for computing weighted Shapley values that leverages a weighted least squares characterization to train a learned estimator without requiring ground truth values during training. The framework provides real-time inference capabilities while maintaining theoretical soundness, addressing the exponential computational complexity of traditional weighted Shapley value calculations.

## Key Results
- Outperforms FastSHAP by 27% in inclusion AUC on average for feature attribution tasks
- Achieves 14x faster computation than KNN-Shapley for data valuation while maintaining comparable accuracy
- Demonstrates effectiveness across CIFAR10, SVHN, and FMNIST datasets

## Why This Works (Mechanism)
The core mechanism relies on the weighted least squares characterization of weighted Shapley values, which enables training a learned estimator that can approximate these values efficiently. By avoiding the need for ground truth values during training, the framework can generalize across different tasks and datasets while maintaining computational efficiency.

## Foundational Learning
- Weighted Shapley values: Generalize standard Shapley values by allowing different weights for subsets of different cardinalities - needed for more nuanced credit assignment in ML tasks
- Amortized inference: Training a model to approximate expensive computations - needed to achieve real-time performance
- Least squares characterization: Mathematical framework for approximating Shapley values - needed to enable learned estimation without ground truth
- Data valuation: Assessing the contribution of individual data points to model performance - needed for dataset curation and quality assessment

## Architecture Onboarding

Component map: Input features -> Weighted LS estimator -> Shapley value approximation -> Feature attribution/Data valuation output

Critical path: The core innovation is training a neural network to approximate the weighted least squares solution for Shapley values, enabling amortized inference.

Design tradeoffs: Speed vs accuracy tradeoff - the learned estimator sacrifices some precision for orders of magnitude improvement in computation time.

Failure signatures: Approximation errors may compound in high-stakes applications requiring exact Shapley values; performance may degrade on datasets significantly different from training distribution.

First experiments:
1. Compare inclusion AUC on feature attribution across multiple datasets
2. Measure runtime performance against KNN-Shapley baseline
3. Evaluate noisy label detection accuracy for data valuation tasks

## Open Questions the Paper Calls Out
None

## Limitations
- Approximation error may be problematic in high-stakes applications requiring exact Shapley values
- Experimental scope limited to classification tasks on CIFAR10, SVHN, and FMNIST datasets
- Does not directly compare to other recent approximation methods for weighted Shapley values

## Confidence

**High**: The weighted least squares characterization and its use in training the estimator

**Medium**: The computational complexity claims and speed comparisons

**Medium**: The effectiveness improvements over FastSHAP in feature attribution

## Next Checks

1. Test FW-Shapley on diverse datasets including regression tasks and medical/industrial applications where exact Shapley values are typically required

2. Compare against other recent approximation methods (e.g., KernelSHAP variants, Monte Carlo approaches) under identical conditions

3. Conduct ablation studies to quantify the impact of the weighted vs unweighted formulations on downstream task performance