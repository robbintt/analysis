---
ver: rpa2
title: Identifiability Challenges in Sparse Linear Ordinary Differential Equations
arxiv_id: '2506.09816'
source_url: https://arxiv.org/abs/2506.09816
tags:
- system
- systems
- sparsity
- identifiability
- matrix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Sparse linear ODEs are theoretically unidentifiable with positive
  probability, contrary to the common belief that "linear ODEs are almost surely identifiable."
  We provide lower bounds on the probability of global unidentifiability, which increase
  sharply with sparsity and follow a threshold at p = 1 - ln(n)/n. This theoretical
  unidentifiability manifests in practice: when using state-of-the-art estimators
  (SINDy, NODEs) to learn sparse systems, reconstruction accuracy measured by normalized
  Hamming distance systematically degrades as sparsity increases.'
---

# Identifiability Challenges in Sparse Linear Ordinary Differential Equations

## Quick Facts
- arXiv ID: 2506.09816
- Source URL: https://arxiv.org/abs/2506.09816
- Reference count: 40
- Key outcome: Sparse linear ODEs are theoretically unidentifiable with positive probability, contrary to the common belief that "linear ODEs are almost surely identifiable."

## Executive Summary
This paper challenges the widely held assumption that linear ordinary differential equations are almost surely identifiable from data. The authors demonstrate that sparse linear ODEs exhibit fundamental identifiability problems with positive probability, establishing lower bounds on the probability of global unidentifiability that increase sharply with sparsity. A critical threshold emerges at p = 1 - ln(n)/n, beyond which identifiability deteriorates rapidly. The theoretical findings are validated empirically using state-of-the-art system identification methods (SINDy and NODEs), which show systematic degradation in reconstruction accuracy as sparsity increases, even when models fit observed trajectories well.

## Method Summary
The authors combine theoretical analysis with empirical validation to establish their results. Theoretically, they derive lower bounds on the probability of global unidentifiability for sparse linear ODEs, showing that this probability increases with the degree of sparsity. The analysis assumes exact sparsity patterns and noiseless data, focusing on linear systems without time-varying coefficients or external inputs. Empirically, they evaluate two popular system identification methods - SINDy (Sparse Identification of Nonlinear Dynamics) and NODEs (Neural Ordinary Differential Equations) - on sparse linear systems. They measure reconstruction accuracy using normalized Hamming distance to quantify how well learned models recover the true system matrix structure.

## Key Results
- Sparse linear ODEs are theoretically unidentifiable with positive probability, establishing that "linear ODEs are almost surely identifiable" is incorrect
- Lower bounds on global unidentifiability probability increase sharply with sparsity and follow a threshold at p = 1 - ln(n)/n
- State-of-the-art estimators (SINDy, NODEs) show systematic degradation in reconstruction accuracy as sparsity increases, measured by normalized Hamming distance

## Why This Works (Mechanism)
The fundamental issue arises from the mathematical structure of sparse linear ODEs. When a system matrix has many zero entries (high sparsity), different matrix configurations can produce identical or nearly identical output trajectories for a given set of initial conditions and observations. This creates a fundamental ambiguity in the inverse problem of system identification. The threshold at p = 1 - ln(n)/n represents a phase transition where the number of constraints provided by the data becomes insufficient relative to the number of free parameters in the sparse system matrix. Even when models fit the observed trajectories well, they may converge to incorrect sparsity patterns that happen to reproduce the training data but fail to capture the true underlying system structure.

## Foundational Learning

**Sparse system identification**: The process of learning differential equation models with many zero coefficients from data.
- Why needed: Essential for building interpretable models that reflect the true underlying physics with minimal complexity
- Quick check: Verify that the learned model has significantly fewer non-zero coefficients than a dense alternative while maintaining good predictive performance

**Normalized Hamming distance**: A metric measuring the fraction of differing entries between two binary matrices (true vs. learned sparsity patterns).
- Why needed: Provides a quantitative measure of how well the learned model recovers the true sparsity structure
- Quick check: Calculate the ratio of mismatched entries to total entries when comparing learned and true system matrices

**Identifiability in dynamical systems**: The property that a unique model can be determined from observed data.
- Why needed: Determines whether system identification methods can reliably recover the true underlying dynamics
- Quick check: Verify whether multiple distinct system matrices can produce identical output trajectories for the given observations

## Architecture Onboarding

**Component map**: Data observations -> System identification algorithm (SINDy/NODEs) -> Learned system matrix -> Performance evaluation (Hamming distance)
**Critical path**: Theoretical analysis of unidentifiability bounds → Empirical validation with SINDy and NODEs → Performance degradation observation
**Design tradeoffs**: Theoretical rigor (exact sparsity, noiseless data) vs. practical applicability (noisy real-world data, approximate sparsity)
**Failure signatures**: High Hamming distance despite low prediction error indicates structural misidentification; threshold behavior at p = 1 - ln(n)/n
**First experiments**:
1. Compare reconstruction accuracy across different sparsity levels while keeping system dimension fixed
2. Evaluate sensitivity to noise by adding Gaussian noise to observations at various SNR levels
3. Test whether structured sparsity patterns (banded matrices) improve identifiability compared to random sparsity

## Open Questions the Paper Calls Out
None

## Limitations
- Theoretical analysis assumes exact sparsity patterns and noiseless data, which may not reflect real-world conditions
- Focus on linear ODEs without time-varying coefficients or external inputs limits applicability to more complex systems
- Results depend on specific implementations and hyperparameter choices in empirical validation

## Confidence
- **High confidence** in theoretical framework and unidentifiability proofs due to rigorous mathematical analysis
- **Medium confidence** in empirical validation using SINDy and NODEs, as results depend on specific implementations
- **Low confidence** in practical implications for all real-world systems given idealized assumptions and limited scope

## Next Checks
1. Evaluate how measurement noise and process noise affect theoretical unidentifiability bounds and empirical reconstruction accuracy across varying SNR levels
2. Test additional system identification methods (sparse regression variants, Bayesian approaches) to determine if degradation with sparsity is method-specific or universal
3. Investigate identifiability under structured sparsity patterns (banded, block-diagonal) to assess whether domain knowledge about system structure can mitigate unidentifiability issues