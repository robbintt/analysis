---
ver: rpa2
title: Interpretable Probability Estimation with LLMs via Shapley Reconstruction
arxiv_id: '2601.09151'
source_url: https://arxiv.org/abs/2601.09151
tags:
- prism
- shapley
- probability
- value
- factor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of generating interpretable probability
  estimates using large language models (LLMs). The core method, PRISM (Probability
  Reconstruction via Shapley Measures), applies Shapley value theory to decompose
  LLM predictions into marginal contributions of individual factors.
---

# Interpretable Probability Estimation with LLMs via Shapley Reconstruction

## Quick Facts
- arXiv ID: 2601.09151
- Source URL: https://arxiv.org/abs/2601.09151
- Reference count: 27
- Primary result: PRISM improves LLM probability estimation accuracy and interpretability by decomposing predictions into Shapley-valued factor contributions.

## Executive Summary
This paper addresses the challenge of generating interpretable probability estimates from large language models (LLMs) by introducing PRISM (Probability Reconstruction via Shapley Measures). The method shifts from asking LLMs for absolute probabilities to computing relative differences in log-odds between scenarios with and without specific factors, given a shared context. By aggregating these marginal contributions using Shapley values, PRISM reconstructs a calibrated probability estimate while providing transparent attribution of each factor's influence. Experimental results across finance, healthcare, and agriculture datasets demonstrate consistent improvements in both predictive accuracy and interpretability compared to direct prompting and baseline methods.

## Method Summary
PRISM applies Shapley value theory to decompose LLM predictions into interpretable factor contributions. For a given prediction, it first establishes a baseline probability using a reference instance, then systematically evaluates the marginal contribution of each factor by comparing the LLM's output when the factor is present versus absent across multiple random background contexts. These contributions are aggregated in log-odds space using the Additivity property of Shapley values, and the final probability is reconstructed via the sigmoid function. The framework supports both tabular data (with automated value-to-text conversion and reference-based imputation) and unstructured text (with LLM-extracted factors), and includes optimizations like batched prompting to reduce computational overhead.

## Key Results
- PRISM consistently outperforms direct LLM prompting and baseline methods in predictive accuracy (AUROC, AUPRC, F1) across six datasets
- The method provides reliable factor-level interpretability through Shapley value attributions
- Results demonstrate robustness across diverse domains including finance, healthcare, and agriculture
- PRISM successfully captures non-linear factor interactions through contextual background sampling

## Why This Works (Mechanism)

### Mechanism 1: Shift to Comparative Logit Estimation
PRISM improves accuracy by asking LLMs to perform relative comparisons rather than absolute probability estimates. The framework calculates the difference in log-odds between scenarios with a specific factor present versus absent, given a shared background context. This leverages LLMs' demonstrated reliability on ranking and comparison tasks. Break condition: If the LLM fails to maintain logical consistency in relative comparisons, the advantage fails.

### Mechanism 2: Probability Reconstruction via Additivity
PRISM aggregates Shapley values to reconstruct calibrated probability estimates by leveraging the Additivity property of Shapley values. It estimates a base logit and marginal contributions of each factor in log-odds space, then sums these values and applies the sigmoid function. Core assumption: Log-odds space allows for linear decomposition of prediction factors. Break condition: Strong non-linear interactions may not be captured effectively with insufficient sampling.

### Mechanism 3: Contextual Attribution via Background Sampling
The framework captures context-dependent feature interactions by evaluating factors against random permutations of background sets. This averages a factor's effect across different contexts provided by other factors in the coalition. Core assumption: Marginal contribution of a factor depends on the coalition of other factors available. Break condition: Low sampling budget leads to high variance in Shapley value estimates.

## Foundational Learning

- **Concept:** Shapley Values (Game Theory)
  - **Why needed:** This is the mathematical core of PRISM. You must understand how to calculate "marginal contribution" of a player (factor) across all possible coalitions (background sets).
  - **Quick check:** If a factor increases probability in isolation but decreases it when combined with a second factor, does the Shapley value capture this interaction?

- **Concept:** Logits and the Sigmoid Function (σ)
  - **Why needed:** The paper operates in "log-odds" space rather than direct probability space. Understanding probabilities [0,1] mapped to unbounded logits (-∞, ∞) is essential for the aggregation step.
  - **Quick check:** Why must Shapley values be summed in logit space rather than summing raw probabilities directly?

- **Concept:** Reference Instances (Imputation)
  - **Why needed:** In tabular variant, "missing" features cannot be left blank without introducing bias. The method uses a "reference instance" to fill these gaps.
  - **Quick check:** In "Tabular-PRISM," what serves as the baseline state for features not included in the current background set S?

## Architecture Onboarding

- **Component map:** Factor Extractor -> Prompt Constructor -> LLM Oracle -> Logit Transformer -> Shapley Aggregator -> Reconstructor
- **Critical path:** The Permutation Sampling step is the bottleneck. Efficiently generating background sets and batching LLM queries is critical for performance.
- **Design tradeoffs:** Interpretability vs. Cost (high accuracy requires high sampling, increasing token cost/latency); Noise vs. Bias (single reference instance is efficient but introduces bias).
- **Failure signatures:** "Unknown" Bias (blanks misinterpreted as high-risk); Logit Saturation (extreme probabilities cause numerical instability).
- **First 3 experiments:**
  1. Baseline Comparison: Re-run Stroke Prediction comparing Direct Prompting vs. PRISM
  2. Sensitivity Analysis (K): Vary sampling budget on single instance to plot stability vs. cost
  3. Interaction Visualization: Replicate Figure 7 heatmaps to verify known interactions are captured

## Open Questions the Paper Calls Out

- **Few-shot extension:** How to extend PRISM to few-shot settings while preserving disentanglement of LLM's internal knowledge from provided demonstrations? [explicit] Authors state they "leave the exploration of few-shot prediction tasks to future work" because interpretation becomes complicated when distinguishing knowledge sources.
- **Computational efficiency:** Can computational efficiency be improved for real-time or large-scale decision-making? [explicit] Section 5 notes the "cost can be relatively high, making it practical only when evaluation size is not too large" due to query complexity Θ(mK).
- **Factor extraction stability:** To what extent does stochastic nature of automated factor extraction from unstructured text impact stability of final probability estimates? [inferred] Section 4.2 notes "factor extraction from a long report is highly stochastic," but variance introduced remains unquantified.

## Limitations
- Computational cost scales linearly with sampling budget K, limiting real-time applications
- Performance sensitive to quality of reference instance selection for tabular data imputation
- Extreme LLM outputs (near 0 or 1 probabilities) can cause numerical instability in logit space
- Non-linear factor interactions may not be fully captured with insufficient sampling

## Confidence
- **High Confidence:** Theoretical framework of using Shapley values for factor attribution and Additivity property for probability reconstruction
- **Medium Confidence:** Claim that LLMs are more reliable for comparative tasks than absolute probability estimation (lacks strong supporting evidence in corpus)
- **Medium Confidence:** Experimental results demonstrating PRISM's superior performance (exact model versions unclear)

## Next Checks
1. Re-run Stroke Prediction task to confirm performance gap between direct prompting and PRISM
2. Vary sampling budget K (1, 5, 10, 50) on single instance to quantify trade-off between computational cost and Shapley value stability
3. Replicate heatmap visualizations (Figure 7) to verify PRISM correctly identifies and weights known non-linear interactions between factors