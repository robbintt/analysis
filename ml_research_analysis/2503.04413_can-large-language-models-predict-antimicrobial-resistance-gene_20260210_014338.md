---
ver: rpa2
title: Can Large Language Models Predict Antimicrobial Resistance Gene?
arxiv_id: '2503.04413'
source_url: https://arxiv.org/abs/2503.04413
tags:
- sequence
- language
- sequences
- resistance
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study shows that generative large language models can effectively
  classify DNA sequences for antimicrobial resistance prediction, offering flexibility
  comparable to or better than traditional encoder-based models. Experiments with
  models like LLaMA 3.1 and ChatGPT 4-mini revealed that performance improves when
  supplementary text (e.g., BLASTn search results) is provided alongside DNA sequences,
  with accuracy increasing from near zero to over 93% after fine-tuning.
---

# Can Large Language Models Predict Antimicrobial Resistance Gene?

## Quick Facts
- **arXiv ID:** 2503.04413
- **Source URL:** https://arxiv.org/abs/2503.04413
- **Reference count:** 9
- **Primary result:** Generative LLMs can classify DNA sequences for AMR prediction with accuracy over 93% after fine-tuning, especially when supplemented with BLASTn search results.

## Executive Summary
This study investigates whether generative large language models (LLMs) can effectively classify DNA sequences for antimicrobial resistance (AMR) prediction. Through experiments with models like LLaMA 3.1 and ChatGPT 4-mini, the research demonstrates that LLM performance improves significantly when supplementary text (e.g., BLASTn search results) is provided alongside DNA sequences. Fine-tuning with LoRA adapters enables these models to achieve classification accuracy comparable to or better than traditional encoder-based models, while also handling cases where the same sequence has different labels. The results highlight the potential of LLMs for DNA sequence analysis, particularly when integrating additional contextual information.

## Method Summary
The study fine-tunes LLaMA 3.1 8B (4-bit quantized) and ChatGPT 4-mini using LoRA adapters to classify DNA sequences for AMR prediction into drug class categories. The approach compares three conditions: base model (zero-shot), base model with BLASTn search results as context, and LoRA-fine-tuned models. DNA sequences from MEGARes and CARD databases are used, with BLASTn results providing alignment data and gene names as supplementary context. Label extraction from model outputs is handled by a secondary mapping model. Performance is evaluated using accuracy, precision, recall, F1 score, and unclassified rate.

## Key Results
- Generative LLM accuracy increased from near zero to over 93% after LoRA fine-tuning with BLASTn context
- Models showed improved performance when supplementary BLASTn search results were provided alongside DNA sequences
- Generative models demonstrated flexibility in handling cases where the same sequence had different labels across datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Providing external context (BLASTn search results) alongside raw DNA sequences enables generative LLMs to classify antimicrobial resistance genes more effectively.
- **Mechanism:** Raw DNA sequences alone provide insufficient signal for general-purpose LLMs. BLASTn results add semantic context (gene names, alignment data, e-values) that bridges the gap between nucleotide patterns and functional labels, reducing the unclassified rate by over 80% in some models.
- **Core assumption:** LLMs can reason over structured metadata (like `sequence_title` and `e_value`) when embedded in text prompts to inform classification, even without domain-specific pre-training.
- **Evidence anchors:**
  - [abstract]: "...performance improves when supplementary text (e.g., BLASTn search results) is provided alongside DNA sequences, with accuracy increasing from near zero to over 93% after fine-tuning."
  - [section]: Table 2 shows ChatGPT4-mini accuracy rising from 0.00 to 0.7804 with BLASTn alone.
  - [corpus]: Weak/indirect – neighbor papers focus on DNA modeling and AMP classification but don't directly evaluate LLMs with external metadata integration.
- **Break condition:** If BLASTn data is noisy, incomplete, or mismatched to the target labels, the model's predictions may degrade or become inconsistent.

### Mechanism 2
- **Claim:** Low-Rank Adaptation (LoRA) fine-tuning enables general-purpose LLMs to reach classification accuracy comparable to specialized DNA encoder models.
- **Mechanism:** LoRA adds trainable low-rank matrices to the model's attention layers, allowing the model to adapt its representations to the AMR classification task without full parameter updates. This preserves general reasoning while learning task-specific patterns.
- **Core assumption:** The base LLM has sufficient representational capacity and generalization ability; only a small number of parameters need task-specific tuning.
- **Evidence anchors:**
  - [abstract]: "...accuracy increasing from near zero to over 93% after fine-tuning."
  - [section]: Table 2 shows fine-tuned ChatGPT4-mini achieving 0.9318 accuracy; Table 1 shows unclassified rates dropping to 0%.
  - [corpus]: No direct corpus support for LoRA on DNA tasks; most neighbors focus on encoder-based transformers or generative design, not adapter tuning.
- **Break condition:** If the fine-tuning dataset is small, imbalanced, or label definitions drift across sources, LoRA may overfit or fail to generalize.

### Mechanism 3
- **Claim:** Generative decoder-based LLMs can adapt to multi-label or conflicting label environments more flexibly than encoder-based models.
- **Mechanism:** Encoder classifiers typically map inputs to fixed label spaces through learned embeddings. Generative LLMs can process ambiguous or multiple labels through autoregressive text generation, allowing context-sensitive outputs.
- **Core assumption:** The model can resolve label conflicts through reasoning over prompt-provided context or learned associations during fine-tuning.
- **Evidence anchors:**
  - [abstract]: "Generative models also handled cases where the same sequence had different labels, demonstrating adaptability to diverse labeling environments."
  - [section]: Table 3 shows models fine-tuned on MEGARes labels achieving 23–50% accuracy on CARD labels, demonstrating cross-label transfer.
  - [corpus]: Neighbor paper "A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification" addresses multi-label challenges in AMPs, suggesting multi-label AMR is a recognized problem, but does not validate LLM flexibility.
- **Break condition:** If label definitions are contradictory or the model cannot disambiguate via prompt context, outputs may become incoherent or arbitrary.

## Foundational Learning

- **Concept: Transformer encoder vs. decoder architectures**
  - Why needed here: The study contrasts encoder-based models (DNABERT, Nucleotide Transformer) with decoder-based generative LLMs; understanding their differences is essential to interpret performance and flexibility claims.
  - Quick check question: Can you explain why a decoder model might handle variable-length textual context more flexibly than a fixed-embedding encoder?

- **Concept: BLASTn and sequence alignment**
  - Why needed here: BLASTn results are used as supplementary context for the LLM; understanding what e-values, alignment lengths, and sequence titles represent helps assess how much semantic signal is actually being added.
  - Quick check question: What does a low e-value in BLASTn indicate about the relationship between query and subject sequences?

- **Concept: Low-Rank Adaptation (LoRA) fine-tuning**
  - Why needed here: The study uses LoRA to adapt LLaMA and ChatGPT4-mini for AMR classification; understanding how LoRA modifies attention layers without full retraining clarifies why it's efficient and what its limitations are.
  - Quick check question: Why does LoRA reduce memory/compute costs compared to full fine-tuning, and what trade-off does it introduce?

## Architecture Onboarding

- **Component map:**
  - DNA sequences (raw nucleotides) + BLASTn metadata (sequence titles, e-values, alignment snippets) -> Prompt Builder -> Base LLM (LLaMA 3.1 8B-4bit, ChatGPT4-mini, Claude 3.5 Sonnet) -> LoRA Adapters (for fine-tuned runs) -> Output Parser -> Evaluation Module

- **Critical path:**
  1. Preprocess DNA sequences (uppercase, filter invalid entries)
  2. Run BLASTn searches and retrieve top-5 results per sequence
  3. Construct prompts with sequence + BLASTn context + label options
  4. Pass prompts through base or LoRA-fine-tuned LLM
  5. Extract labels from model outputs (direct or via mapping model)
  6. Compare predictions to ground truth; compute metrics

- **Design tradeoffs:**
  - BLASTn context vs. raw sequence only: Adding context improves accuracy but introduces dependency on external DB quality and increases prompt length
  - LoRA vs. full fine-tuning: LoRA is efficient but may underperform on highly specialized tasks or small datasets compared to full parameter updates
  - Fixed labels vs. flexible generation: Generative models can handle ambiguous/multiple labels but require robust output parsing; encoders provide deterministic outputs but lack flexibility
  - Model size: Larger models (Claude 3.5) perform better zero-shot; smaller quantized models (LLaMA 8B-4bit) require more fine-tuning to reach comparable performance

- **Failure signatures:**
  - High unclassified rate: Model returns verbose explanations without committing to a label; often seen in zero-shot runs without BLASTn context
  - Label extraction errors: Long, ambiguous outputs lead to incorrect or missed label mappings, inflating false negatives
  - Cross-dataset generalization drops: Models fine-tuned on MEGARes show reduced accuracy on CARD labels, indicating label-space mismatch
  - Prompt formatting issues: Malformed BLASTn context or missing label options cause the model to default to "insufficient evidence" responses

- **First 3 experiments:**
  1. Baseline classification: Run zero-shot prompts with DNA sequences only (no BLASTn, no fine-tuning) across all models; record unclassified rates and accuracy to establish lower bounds
  2. Context ablation: Add BLASTn results to prompts for the same sequences; measure accuracy and unclassified rate improvements to quantify context contribution
  3. LoRA fine-tuning validation: Fine-tune LLaMA 8B-4bit and ChatGPT4-mini on MEGARes labels using LoRA; evaluate on held-out test set and on CARD labels to assess within-distribution and cross-distribution generalization

## Open Questions the Paper Calls Out

- **Question:** How can label extraction from verbose LLM outputs be standardized to ensure consistent and accurate evaluation across different generative models?
  - Basis in paper: [explicit] "Extracting specific class labels from long texts was not a straightforward task... However, the evaluation may vary depending on the accuracy of this extraction model."
  - Why unresolved: The paper relied on a secondary model to map class labels from lengthy explanations, introducing potential measurement error that could affect reported accuracy metrics.
  - What evidence would resolve it: A benchmark comparison of multiple label extraction methods (e.g., frequency-based vs. parsing-based vs. classifier-based) showing inter-rater agreement and impact on final evaluation scores.

- **Question:** Will the performance gains from supplementary BLASTn information generalize to DNA sequences with fewer or no close database matches?
  - Basis in paper: [inferred] Performance improved dramatically when BLASTn results were provided, but BLASTn inherently finds similar sequences already in annotated databases—novel or divergent resistance genes may lack such matches.
  - Why unresolved: The study does not analyze performance stratified by BLASTn hit quality or e-value distribution, leaving unclear whether the approach works for truly novel sequences.
  - What evidence would resolve it: Experiments grouping test sequences by BLASTn hit similarity (e.g., high vs. low identity) and comparing accuracy across groups, plus evaluation on synthetic or intentionally mutated sequences.

- **Question:** How do generative LLMs compare numerically to encoder-based models like DNABERT and Nucleotide Transformer on identical AMR classification benchmarks?
  - Basis in paper: [inferred] The paper claims "comparable or potentially better predictions" but provides no direct head-to-head numerical comparison table against encoder-based baselines.
  - Why unresolved: Without controlled benchmarking on the same train/test splits, the relative advantage of generative models remains qualitative rather than quantitative.
  - What evidence would resolve it: A unified benchmark comparing LLaMA, ChatGPT, DNABERT-2, and Nucleotide Transformer on identical AMR datasets with matched preprocessing and evaluation protocols.

## Limitations

- The study lacks detailed specification of critical methodology components, particularly label extraction mechanisms and training hyperparameters
- Cross-dataset generalization results show meaningful performance drops, suggesting sensitivity to label space differences between MEGARes and CARD
- The approach relies heavily on BLASTn search results, which may not generalize to novel sequences without close database matches

## Confidence

- **High confidence:** Generative LLMs can achieve reasonable AMR classification accuracy when fine-tuned with LoRA, and BLASTn context improves performance from near-zero to over 90%
- **Medium confidence:** Generative models may handle ambiguous/multiple labels more flexibly than encoders, though the magnitude of this advantage needs further validation
- **Low confidence:** The precise mechanisms and potential biases in label extraction from verbose model outputs are not well understood due to underspecification

## Next Checks

1. Implement and test the label extraction model independently to verify it correctly maps verbose LLM outputs to discrete class labels, checking for systematic biases or missed labels
2. Fine-tune on MEGARes and evaluate on multiple held-out datasets (not just CARD) to assess generalization across different label ontologies and sequence distributions
3. Systematically vary the quality and quantity of BLASTn context (e.g., top 1 vs top 5 hits, different e-value thresholds) to quantify the contribution of external information versus the model's intrinsic sequence understanding