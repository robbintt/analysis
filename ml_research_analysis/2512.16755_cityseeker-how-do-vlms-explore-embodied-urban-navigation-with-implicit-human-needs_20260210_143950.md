---
ver: rpa2
title: 'CitySeeker: How Do VLMS Explore Embodied Urban Navigation With Implicit Human
  Needs?'
arxiv_id: '2512.16755'
source_url: https://arxiv.org/abs/2512.16755
tags:
- navigation
- mean
- spatial
- perspective
- find
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CitySeeker introduces the first benchmark for assessing how VLMs
  handle implicit human needs in embodied urban navigation. It features 6,440 trajectories
  across 8 cities with 7 task categories requiring spatial reasoning and commonsense
  inference.
---

# CitySeeker: How Do VLMS Explore Embodied Urban Navigation With Implicit Human Needs?

## Quick Facts
- arXiv ID: 2512.16755
- Source URL: https://arxiv.org/abs/2512.16755
- Authors: Siqi Wang; Chao Liang; Yunfan Gao; Erxin Yu; Sen Li; Yushi Li; Jing Li; Haofen Wang
- Reference count: 40
- Key outcome: CitySeeker introduces the first benchmark for assessing how VLMs handle implicit human needs in embodied urban navigation, revealing top VLMs achieve only 21.1% task completion with bottlenecks in long-horizon reasoning, spatial cognition, and memory.

## Executive Summary
CitySeeker addresses a critical gap in embodied AI by evaluating how vision-language models (VLMs) handle navigation tasks driven by implicit human needs in urban environments. Unlike traditional navigation benchmarks that provide explicit step-by-step instructions, CitySeeker requires VLMs to infer destinations from abstract human requests like "I'm thirsty" or "I need to relax." The benchmark features 6,440 trajectories across 8 major cities, testing VLMs' ability to translate semantic needs into visual search and spatial decisions.

The evaluation reveals VLMs struggle significantly with this task, with the best-performing model (Qwen2.5-VL-32B-Instruct) achieving only 21.1% task completion. Analysis identifies three key bottlenecks: long-horizon reasoning errors that accumulate over navigation sequences, spatial cognition limitations that prevent effective mental mapping, and memory constraints that hinder experience reuse. To address these challenges, the authors propose the BCR triad—backtracking mechanisms, spatial cognition enrichment, and memory-based retrieval—which improves performance but reveals the fundamental difficulty of aligning abstract human needs with concrete urban navigation.

## Method Summary
CitySeeker is a benchmark for evaluating VLMs in embodied urban navigation with implicit human needs. The dataset consists of 6,440 trajectories across 8 cities, where navigation tasks are driven by abstract human requests (e.g., "I need to recharge my phone") rather than explicit directions. The benchmark uses a zero-shot evaluation approach where VLMs must navigate through a graph of street-view panoramas to reach destinations matching the implicit needs. The navigation graph contains nodes every 20m with 41,128 panoramas and POI metadata. Evaluation metrics include Task Completion (TCE, TCP, TCC), nDTW for path quality, and SPL for success weighted by path length. The authors also propose BCR strategies (Backtracking, Cognition, Memory) to address identified bottlenecks and test these on a subset of 650 samples.

## Key Results
- Top VLMs achieve only 21.1% task completion on implicit need-driven navigation
- Backtracking mechanisms (B2/B3) improve task completion by 5-6 percentage points across models
- Memory-based retrieval (R1) achieves best task completion (26.9%) and dramatically improves path efficiency (nDTW from 337.1 to 136.6)
- Map-augmented navigation degrades performance (TCP drops from 21.1% to 7.6%) due to over-reliance on geometric path-following
- VLMs struggle particularly with latent POI inference and abstract demand categories

## Why This Works (Mechanism)

### Mechanism 1: Backtracking for Error Recovery
- **Claim:** Backtracking mechanisms can reduce cumulative navigation errors by reverting to trusted states when progress stalls or confidence drops.
- **Mechanism:** The agent monitors either internal confidence scores (B1) or objective topological distance to the goal (B2/B3). When average confidence over k steps falls below θ or distance increases monotonically for k steps, the agent reverts to a prior trusted node, optionally with corrective guidance.
- **Core assumption:** VLMs can produce actionable confidence scores or distance estimates; the underlying graph topology is known for B2/B3.
- **Evidence anchors:** Table 3 shows B2/B3 improve TCP across models (e.g., GPT-4o-Mini TCP 12.3%→18.2% with B3). [abstract] "key bottlenecks in error accumulation in long-horizon reasoning... To address these, we propose the BCR triad: backtracking mechanisms..."

### Mechanism 2: Spatial Cognition Enrichment via Structured Context
- **Claim:** Providing explicit spatial context (topology or relative positions) can improve global awareness and reduce fragmented decisions.
- **Mechanism:** Synthesize successful/erroneous trajectories from multiple VLMs into either (C1) a topological graph of nodes/edges or (C2) relative directional cues with distances; inject into VLM prompts.
- **Core assumption:** VLMs can parse and utilize structured spatial representations; GPT-4.1 can reliably synthesize trajectory insights.
- **Evidence anchors:** C1 improves TCP (GPT-4o-Mini 12.5%→17.2%); C2 mixed, sometimes reducing task completion for efficiency gains. [corpus] CityCube benchmark (FMR 0.57) emphasizes cross-view spatial reasoning in urban environments.

### Mechanism 3: Memory-Based Retrieval for Experience Reuse
- **Claim:** Graph-based memory retrieval can stabilize reasoning and improve both task completion and path efficiency.
- **Mechanism:** Store trajectories and metadata in Neo4j; retrieve local subgraphs via (R1) h-hop topological neighbors, (R2) Euclidean radius, or (R3) recent trajectory windows; inject into VLM context.
- **Core assumption:** Past trajectories contain reusable patterns; retrieval latency is acceptable within inference budget.
- **Evidence anchors:** R-series strategies yield best TCP (Qwen2.5-VL-32B reaches 26.9% with R1); R1 also dramatically improves path efficiency (GPT-4o-Mini nDTW 337.1→136.6). [corpus] UrbanNav (FMR 0.50) leverages web-scale human trajectories for urban navigation.

## Foundational Learning

- **Concept: Implicit-Need-Driven Navigation**
  - Why needed here: Core challenge in CitySeeker is translating abstract human needs (e.g., "I'm thirsty") into concrete visual search and spatial decisions.
  - Quick check question: Can you map "I need to recharge my phone" to a set of candidate POI categories without explicit mention?

- **Concept: Spatial Mental Models**
  - Why needed here: Humans navigate using cognitive maps; CitySeeker evaluates whether VLMs can develop analogous internal representations.
  - Quick check question: How would you mentally rotate a 2D map view to align with your current first-person heading?

- **Concept: Vision-Language Navigation (VLN) Paradigms**
  - Why needed here: CitySeeker extends VLN from explicit step-by-step instructions to goal-oriented reasoning with implicit needs.
  - Quick check question: What's the difference between "turn right at the fountain" (explicit) and "find somewhere romantic" (implicit)?

## Architecture Onboarding

- **Component map:** Street-view panoramas → Navigation graph (Neo4j) → ReAct agent loop (Observe→Think→Act→Reflect) → BCR strategy modules → Evaluation metrics

- **Critical path:**
  1. **Data Collection**: Fetch street-view panoramas from Google/Baidu Maps; build topology graph
  2. **Route Generation**: Map implicit queries to POI categories via templates; generate start-target pairs; compute shortest paths
  3. **Manual Validation**: Verify target visibility at endpoint; ensure no alternative POIs along path
  4. **Agent Evaluation**: Run VLMs in map-free setting; apply BCR strategies on mini-subset (650 samples) for preliminary analysis

- **Design tradeoffs:**
  - **Map-free vs map-augmented**: Map-free isolates intrinsic VLM reasoning; map-augmented improves path following but degrades task completion (TCP 21.1%→7.6%)
  - **B-series choice**: B1 requires no external signals but needs calibrated confidence; B2/B3 are more robust but require topology/goal info
  - **C-series choice**: C1 improves accuracy; C2 may favor efficiency but risks lower success rates
  - **R-series choice**: R1/R2 enable cross-round memory; R3 is lightweight intra-episode only

- **Failure signatures:**
  - **Oscillatory Detours**: Paths exceed optimal length by 40–60% due to fragmented context handling
  - **Looping Behavior**: Visiting same node multiple times (e.g., trajectory #63 in NYC)
  - **Trajectory Deviation**: Compounded errors at sequential decision points; high nDTW scatter at ~35 steps
  - **Over-reliance on Maps**: In map-augmented mode, VLMs ignore semantic discovery, fixating on geometric path

- **First 3 experiments:**
  1. **Baseline Performance Assessment**: Run target VLM on full 1,257-sample test set; compute TC (TCE/TCP/TCC), nDTW, SPL; identify worst-performing categories (e.g., Latent POI)
  2. **BCR Ablation on Mini-Subset**: Apply each BCR strategy (B1/B2/B3, C1/C2, R1/R2/R3) individually on 650-sample subset; compare TCP/nDTW changes
  3. **Combined Strategy Exploration**: Combine promising strategies (e.g., B2+C1+R3) on mini-subset; measure TCP boost (Qwen2.5-VL-32B: 19.9%→27.38%)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can VLMs effectively fuse abstract 2D map information with first-person visual observations to improve embodied navigation without losing semantic grounding?
- **Basis in paper:** [explicit] Appendix D states that providing a global map degraded task completion due to "poor cognition of 2D Map Geometry" and "Over-reliance," identifying this fusion as a "valuable direction for future research."
- **Why unresolved:** Current models fixate on geometric path-following ("map followers") and fail to align abstract directions with visual perspectives, often ignoring the semantic search required by implicit needs.
- **What evidence would resolve it:** A model architecture that demonstrates simultaneous improvements in both path efficiency (nDTW) and Task Completion (TCP) when provided with map context.

### Open Question 2
- **Question:** How can VLMs be trained to infer latent functional affordances of POIs (e.g., buying a SIM card at a convenience store) rather than relying solely on direct textual or visual matching?
- **Basis in paper:** [explicit] The Limitations section lists "Enhancing Commonsense and Affordance Reasoning" as a key future focus, noting models struggle with "non-obvious functions of POIs."
- **Why unresolved:** Current models lack the "real-world experience" to make flexible logical leaps about secondary POI functions, leading to "Underthinking" errors in abstract scenarios.
- **What evidence would resolve it:** Significant performance improvements in the "Latent POI" and "Abstract Demand" categories on the CitySeeker benchmark via new training methodologies.

### Open Question 3
- **Question:** What are the optimal mechanisms for combining Backtracking, Spatial Cognition Enrichment, and Memory-Based Retrieval (BCR) to achieve synergistic performance gains?
- **Basis in paper:** [inferred] While the paper proposes BCR, Appendix E.4 notes that combined strategies showed "a positive but not strictly additive effect," suggesting complex interactions that require exploration.
- **Why unresolved:** The interactions between cognitive tools like backtracking and memory retrieval are complex; simply stacking them may not yield proportional benefits.
- **What evidence would resolve it:** A study identifying specific interaction effects between BCR components and a framework that adaptively deploys them to maximize task success.

## Limitations

- Benchmark's geographic scope limited to 8 major metropolitan areas, potentially biasing results toward environments with abundant visual cues
- Zero-shot evaluation approach prevents assessment of whether VLMs can improve through navigation experience
- Medium confidence in BCR triad's effectiveness, particularly for spatial cognition enrichment which shows inconsistent results

## Confidence

**High Confidence**: VLMs struggle with embodied urban navigation involving implicit human needs (Qwen2.5-VL-32B-Instruct: 21.1% TCP)

**Medium Confidence**: The BCR triad can improve performance on the CitySeeker benchmark, though magnitude varies significantly by model

**Low Confidence**: Spatial cognition enrichment (C-series) reliably improves task completion, as C2 shows mixed results trading efficiency for success rates

## Next Checks

1. **Ablation Study of BCR Components**: Isolate each BCR mechanism's contribution by evaluating models with only B-series, only C-series, or only R-series enabled to reveal whether improvements are additive or create interference

2. **Geographic Diversity Stress Test**: Evaluate VLMs on navigation tasks from cities not represented in the training data (e.g., smaller cities, rural areas, or cities with different architectural styles) to test whether performance degradation stems from urban diversity or fundamental spatial reasoning limitations

3. **Confidence Calibration Analysis**: For B1 backtracking, systematically measure VLM confidence score calibration by comparing predicted confidence to actual success rates across different confidence thresholds to determine whether confidence scores are reliable enough for autonomous error recovery