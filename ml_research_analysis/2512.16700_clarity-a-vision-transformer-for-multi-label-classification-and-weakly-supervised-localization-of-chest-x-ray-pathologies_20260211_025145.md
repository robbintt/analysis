---
ver: rpa2
title: 'CLARiTy: A Vision Transformer for Multi-Label Classification and Weakly-Supervised
  Localization of Chest X-ray Pathologies'
arxiv_id: '2512.16700'
source_url: https://arxiv.org/abs/2512.16700
tags:
- classification
- localization
- class
- chest
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLARiTy is a vision transformer model for multi-label classification
  and weakly-supervised localization of chest X-ray pathologies. It uses multiple
  class-specific tokens, a SegmentCAM module for foreground segmentation and background
  suppression, and orthogonal class token regularization.
---

# CLARiTy: A Vision Transformer for Multi-Label Classification and Weakly-Supervised Localization of Chest X-ray Pathologies

## Quick Facts
- **arXiv ID:** 2512.16700
- **Source URL:** https://arxiv.org/abs/2512.16700
- **Reference count:** 40
- **Primary result:** CLARiTy-S-16-512 achieves Macro AUC 0.818 and state-of-the-art localization (Macro IoU Accuracy 0.318 at IoU=0.5), outperforming prior methods by 50.7% for small pathologies.

## Executive Summary
CLARiTy is a vision transformer model that achieves state-of-the-art performance for multi-label classification and weakly-supervised localization of chest X-ray pathologies. The model uses multiple class-specific tokens to generate discriminative attention maps, a SegmentCAM module with anatomical priors for foreground segmentation and background suppression, and orthogonal class token regularization. Trained on NIH ChestX-ray14, CLARiTy-S-16-512 demonstrates significant improvements in both classification accuracy and localization precision, particularly for small pathologies.

## Method Summary
CLARiTy extends the ViT-S-16 backbone with 14 class-specific tokens (one per pathology), attention pooling, and a SegmentCAM module. The model extracts class-to-patch attention maps from the final transformer layers and applies foreground segmentation using anatomical priors from TorchXRayVision. Three losses constrain heatmaps: mask proximity, mask confinement, and area constraints, while background activation suppression reduces noise. The final predictions average class token logits and foreground logits. Training uses DINO pretraining, AdamW optimizer, and distillation from ConvNeXtV2-B.

## Key Results
- CLARiTy-S-16-512 achieves Macro AUC of 0.818 on NIH ChestX-ray14
- State-of-the-art localization with Macro IoU Accuracy of 0.318 at IoU=0.5
- 50.7% improvement in IoU Accuracy for small pathologies compared to prior methods
- CLARiTy-S-16-224 offers competitive performance with 6× fewer FLOPS

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Multiple class-specific tokens enable more discriminative, class-specific attention maps than single-token ViTs.
- **Mechanism:** Each class token learns to attend to distinct image regions via the class-to-patch sub-matrix of transformer self-attention. The class-specific attention maps are computed by averaging across the final p=8 transformer layers, capturing pathology-specific features rather than generic representations.
- **Core assumption:** Pathologies occupy spatially distinct regions; class tokens can learn to specialize without explicit spatial supervision.
- **Evidence anchors:** [abstract] "CLARiTy employs multiple class-specific tokens to generate discriminative attention maps"; [section 3.2.1] Equation 1 defines class-specific attention averaging; Figure 2 illustrates class-to-patch extraction.

### Mechanism 2
- **Claim:** SegmentCAM's foreground segmentation with anatomical priors suppresses background noise, improving localization precision.
- **Mechanism:** Three losses constrain heatmaps: (1) mask proximity loss penalizes activations distant from anatomical foreground; (2) mask confinement loss penalizes background activations; (3) area constraint loss limits foreground size. Background activation suppression further reduces information retained in background logits via softplus ratio minimization.
- **Core assumption:** Anatomical segmentation priors (from TorchXRayVision + Grok-identified regions) reliably bound pathology locations.
- **Evidence anchors:** [abstract] "SegmentCAM module for foreground segmentation and background suppression using explicit anatomical priors"; [section 3.4-3.5] Equations 10-17 define proximity, confinement, area, and suppression losses.

### Mechanism 3
- **Claim:** Orthogonal class token loss combined with attention pooling improves localization over contrastive or GAP alternatives.
- **Mechanism:** OCT loss (Eq. 7) drives class tokens toward zero cosine similarity (orthogonality) rather than negative similarity. Attention pooling (Eq. 8-9) allows each embedding dimension to attend to different pathological features instead of requiring uniform activation across all dimensions as in GAP.
- **Core assumption:** Orthogonality (dissimilarity) is preferable to opposition; dimension-specific feature encoding aids localization.
- **Evidence anchors:** [abstract] "orthogonal class token regularization"; [section 4.5.5-4.5.6] Ablation shows OCT improves MSLI by 5.0% over CCT; attention pooling improves MSLI by 17.9% over GAP.

## Foundational Learning

- **Concept: Vision Transformer Self-Attention Mechanism**
  - **Why needed here:** Understanding how class-to-patch attention extracts spatial maps is essential before implementing multi-token designs.
  - **Quick check question:** Can you explain why ViT self-attention produces sparse attention maps compared to CNN feature maps?

- **Concept: Weakly-Supervised Localization via CAM**
  - **Why needed here:** CLARiTy extends CAM principles to transformers; understanding gradient-free vs gradient-based CAM clarifies design choices.
  - **Quick check question:** What is the fundamental difference between Grad-CAM and gradient-free CAM for localization?

- **Concept: Knowledge Distillation (TinyViT Method)**
  - **Why needed here:** CLARiTy uses ConvNeXtV2 teacher distillation for efficiency; understanding pre-computed logits and student training is prerequisite.
  - **Quick check question:** How does pre-computing teacher logits improve distillation efficiency?

## Architecture Onboarding

- **Component map:** ViT-S-16 backbone → 12 layers, 6 heads, 384-dim embeddings, 16-patch size → C=14 class tokens (one per pathology) + P patch tokens → Attention pooling module → class token logits ℓ^C → SegmentCAM module → heatmap head, feature head, classification head → foreground logits ℓ^f → Final inference: average of ℓ^C and ℓ^f

- **Critical path:** Input image (224×224 or 512×512) → patch embedding → concatenate C class tokens → Transformer blocks process tokens → Extract class-to-patch attention from final 8 layers → average → class-specific attention maps A → SegmentCAM: patch tokens → convolutional heads → heatmap H → threshold → foreground mask S_f → Fuse: Ξ = A ⊙ S_f (element-wise multiplication)

- **Design tradeoffs:**
  - 224 vs 512 resolution: 224 offers 6× fewer FLOPS (5.99G vs 37.84G) but 1.9% lower Macro AUC
  - OCT vs CCT: OCT better for localization (+5.0% MSLI), CCT marginally better for classification (+0.4% AUC)
  - SegmentCAM adds 24.7% parameters over backbone but critical for localization (+2.2% MSLI)

- **Failure signatures:**
  - Heatmaps scattered across non-pathological regions → check DINO pretraining loaded correctly (14.2% MSLI drop with ImageNet weights)
  - All classes attend to same region → verify OCT loss applied to final q=8 layers
  - Small pathologies missed → confirm resolution is 512×512; 224×224 may suppress small regions in foreground masks

- **First 3 experiments:**
  1. **Baseline sanity check:** Run CLARiTy-S-16-224 with all components enabled on NIH validation set; target Macro AUC ≥0.799, MSLI ≥0.35
  2. **Ablation — SegmentCAM losses:** Disable L_PRX, L_CNF, L_AC sequentially; expect MSLI drops per Table 6 (21.2% drop without both)
  3. **Resolution comparison:** Train identical configs at 224 vs 512; measure IoU Accuracy at T(IoU)=0.5 for small pathologies (nodule, mass) per Table 5

## Open Questions the Paper Calls Out

- **Open Question 1:** Does CLARiTy generalize to external chest X-ray datasets with differing label noise and population distributions, such as CheXpert or MIMIC-CXR?
  - **Basis in paper:** [explicit] The authors explicitly identify reliance on the NIH dataset as a limitation, stating that "external validation on datasets like CheXpert or MIMIC-CXR could confirm generalizability."
  - **Why unresolved:** The model was trained and evaluated exclusively on the official NIH split, which suffers from specific NLP-extracted label biases that may not align with other clinical environments.
  - **What evidence would resolve it:** Reporting Macro AUC and Macro IoU Accuracy results for CLARiTy when trained and tested on the CheXpert or MIMIC-CXR benchmarks.

- **Open Question 2:** Do the high-precision localization heatmaps produced by CLARiTy improve radiologists' ability to detect shortcut learning and biases in clinical practice?
  - **Basis in paper:** [explicit] The paper states that while heatmaps enhance explainability, "clinical validation by radiologists is needed to assess utility in bias detection."
  - **Why unresolved:** The study evaluates localization performance using Intersection over Union (IoU) against ground truth boxes, but it does not perform qualitative or quantitative user studies to validate the heatmaps' utility for human experts.
  - **What evidence would resolve it:** A reader study where radiologists diagnose cases using CLARiTy heatmaps versus standard Grad-CAM, specifically measuring their ability to identify spurious correlations or missed pathologies.

- **Open Question 3:** Can the multiple class-token architecture and SegmentCAM module be effectively adapted for 3D volumetric medical imaging tasks?
  - **Basis in paper:** [explicit] The authors suggest that "future work could extend CLARiTy to 3D CT scans" to broaden the method's applicability.
  - **Why unresolved:** The current ViT-S-16 backbone and attention mechanisms are optimized for 2D spatial inputs; scaling self-attention and the SegmentCAM background suppression to 3D volumes introduces significant computational and memory challenges.
  - **What evidence would resolve it:** A successful implementation of CLARiTy on a 3D dataset (e.g., LIDC-IDRI) demonstrating competitive localization performance without prohibitive computational costs.

## Limitations

- **Anatomical Prior Dependence:** The SegmentCAM module's effectiveness critically depends on the accuracy of anatomical segmentation masks from TorchXRayVision, which may not align perfectly with all pathology types.
- **Orthogonality vs Correlation Trade-off:** The orthogonal class token loss may harm performance for correlated pathologies that commonly co-occur in clinical practice.
- **Computational Cost vs Benefit:** The CLARiTy-S-16-512 variant achieves the best results but requires 6× more computational resources than the 224 variant.

## Confidence

- **High Confidence Claims:**
  - Multiple class-specific tokens improve discriminative attention maps compared to single-token designs
  - SegmentCAM with anatomical priors significantly improves localization precision
  - CLARiTy-S-16-512 achieves state-of-the-art Macro AUC of 0.818 on NIH ChestX-ray14

- **Medium Confidence Claims:**
  - OCT loss is superior to CCT for localization
  - Background suppression via L_BAS is essential for accurate localization
  - Attention pooling is superior to GAP for localization

- **Low Confidence Claims:**
  - Performance generalization to other medical imaging datasets
  - OCT loss benefits for highly correlated pathologies
  - Optimal values for SegmentCAM threshold t and bounding box thresholds ξ(c)

## Next Checks

1. **Ablation of Anatomical Prior Dependencies:** Train CLARiTy-S-16-512 with SegmentCAM but disable all anatomical prior-based losses (L_PRX, L_CNF, L_AC, L_BAS). Measure change in MSLI and IoU Accuracy for pathologies with poor anatomical alignment (e.g., hernia, mass).

2. **Correlation Sensitivity Analysis:** Train CLARiTy with OCT loss disabled (using CCT instead) and measure classification vs localization trade-off specifically for highly correlated pathology pairs (atelectasis/effusion, infiltration/pneumonia).

3. **Cross-Dataset Generalization:** Evaluate CLARiTy-S-16-224 on a different chest X-ray dataset (e.g., CheXpert or MIMIC-CXR) without retraining. Measure Macro AUC and MSLI to assess whether the architectural innovations provide benefits beyond the NIH ChestX-ray14 distribution.