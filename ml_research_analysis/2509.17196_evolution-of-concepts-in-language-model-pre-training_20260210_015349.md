---
ver: rpa2
title: Evolution of Concepts in Language Model Pre-Training
arxiv_id: '2509.17196'
source_url: https://arxiv.org/abs/2509.17196
tags:
- feature
- features
- training
- learning
- crosscoder
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel method for tracking feature evolution\
  \ during language model pre-training using crosscoders\u2014a variant of sparse\
  \ autoencoders adapted to analyze activations from multiple training snapshots.\
  \ By applying cross-snapshot crosscoders, the authors reveal that features exhibit\
  \ two distinct developmental patterns: initialization-dependent features existing\
  \ from random initialization, and emergent features forming primarily around step\
  \ 1000, with more complex patterns emerging later in training."
---

# Evolution of Concepts in Language Model Pre-Training

## Quick Facts
- **arXiv ID:** 2509.17196
- **Source URL:** https://arxiv.org/abs/2509.17196
- **Reference count:** 40
- **Primary result:** Novel method tracks feature evolution during language model pre-training using crosscoders

## Executive Summary
This paper introduces a novel method for tracking feature evolution during language model pre-training using crosscodersâ€”a variant of sparse autoencoders adapted to analyze activations from multiple training snapshots. By applying cross-snapshot crosscoders, the authors reveal that features exhibit two distinct developmental patterns: initialization-dependent features existing from random initialization, and emergent features forming primarily around step 1000, with more complex patterns emerging later in training. The authors demonstrate that decoder norms serve as effective proxies for feature evolution status and establish causal connections between feature evolution and downstream task performance through attribution-based circuit tracing.

## Method Summary
The method employs cross-snapshot crosscoders to track feature evolution across 32 Pythia model snapshots (160M and 6.9B scales). The crosscoder uses a shared encoder with snapshot-specific decoders, trained on activations from the middle layer of each snapshot using a JumpReLU activation with sparsity regularization. Decoder norms serve as quantitative proxies for feature presence and evolution, while integrated gradients enable causal attribution to downstream task performance. The analysis reveals a phase transition from statistical learning (fitting coarse n-gram patterns) to feature learning (forming distinct sparse features).

## Key Results
- Decoder norms in cross-snapshot crosscoders serve as quantitative proxies for feature evolution status
- Pre-training exhibits a phase transition from "statistical learning phase" to "feature learning phase" around step 1000
- Feature emergence timing aligns with functional requirements of downstream tasks, with simple features emerging first and complex features later

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decoder norms in cross-snapshot crosscoders serve as quantitative proxies for feature evolution status.
- **Mechanism:** The crosscoder loss function penalizes feature activations based on decoder magnitude. If a feature is semantically irrelevant at a specific training snapshot, the optimizer suppresses the decoder weight norm for that snapshot to near-zero to minimize sparsity loss while maintaining reconstruction fidelity.
- **Core assumption:** The linear decomposition accurately reflects the model's internal conceptual structure (monosemanticity).
- **Evidence anchors:** [section 3] "The decoder norm $\|W_{dec,i}^\theta\|$ directly reflects the strength and presence of feature $i$ at snapshot $\theta$."

### Mechanism 2
- **Claim:** Pre-training exhibits a phase transition from a "statistical learning phase" to a "feature learning phase."
- **Mechanism:** In early training (steps ~0-1000), loss drops are driven by the model fitting coarse statistical distributions (unigram/bigram frequencies) using dense, non-specialized representations. Once statistical patterns are memorized, the model shifts to forming distinct, sparse features in superposition.
- **Core assumption:** The rapid convergence of n-gram KL divergence implies a distinct learning regime separate from feature formation.
- **Evidence anchors:** [abstract] "We term a statistical learning phase and a feature learning phase."

### Mechanism 3
- **Claim:** Feature emergence timing aligns with the functional requirements of downstream tasks.
- **Mechanism:** Causal attribution (integrated gradients) links specific crosscoder features to task metrics. As training progresses, "simple" features emerge first while "complex" features emerge later, causing task performance to improve in stepwise fashion.
- **Core assumption:** Attribution patching via linear approximation accurately isolates the causal effect of specific features.
- **Evidence anchors:** [section 5] Ablation experiments show that removing top-ranked features disrupts task performance.

## Foundational Learning

- **Concept: Sparse Autoencoders (SAEs)**
  - **Why needed here:** The paper builds on SAEs to resolve superposition. You must understand that SAEs decompose activations into a sparse set of "features" (latent variables) to understand how crosscoders extend this to *time*.
  - **Quick check question:** Can you explain the trade-off between reconstruction loss and sparsity (L1/L0) in a standard SAE?

- **Concept: Superposition Hypothesis**
  - **Why needed here:** The paper argues that the transition to the "feature learning phase" involves representing features in superposition. You need to know that models represent more features than they have neurons by storing them non-orthogonally.
  - **Quick check question:** Why can't we simply read individual neurons to find concepts in a model in superposition?

- **Concept: Attribution Patching / Integrated Gradients**
  - **Why needed here:** Section 5 relies on these methods to establish *causality*. Understanding that gradients flow through the linear decomposition of the crosscoder is essential to validate the paper's claims about feature importance.
  - **Quick check question:** How does attribution patching differ from standard gradient-based saliency maps when analyzing clean vs. corrupted inputs?

## Architecture Onboarding

- **Component map:** Source (Pythia snapshots) -> Input (Middle layer activations) -> Encoder (Shared linear) -> Activation (JumpReLU) -> Decoders (Snapshot-specific linear)
- **Critical path:** The cross-snapshot alignment. The system forces the *same* latent feature index to reconstruct semantic concepts across different training steps.
- **Design tradeoffs:** Snapshot count vs. Memory (linear increase), Dictionary Size vs. Splitting (larger dictionaries risk temporal feature splitting)
- **Failure signatures:** Feature Death (features never activate), Misalignment (unrelated concepts forced into same feature), Optimization Instability (JumpReLU thresholds rising too fast)
- **First 3 experiments:**
  1. Train the crosscoder on 32 snapshots and verify "Explained Variance" is >85-90%
  2. Plot decoder norms of random features to verify "initialization vs. emergent" patterns around step 1000
  3. Identify top-activating feature for a simple task and ablate only that feature to verify task metric drops

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent do feature evolution patterns and the statistical-to-feature learning phase transition generalize across different model architectures, datasets, and post-training stages?
- Basis in paper: [explicit] Section 7 states the analysis is limited to the Pythia suite and asks, "the extent to which feature evolution patterns are consistent across diverse settings remains to be established."
- Why unresolved: The study relies on specific checkpoints from Pythia models, leaving the universality of the "initialization" vs. "emergent" feature dichotomy unproven for other architectures.
- What evidence would resolve it: Applying cross-snapshot crosscoders to diverse model families (e.g., Llama, Mistral), different data regimes, and fine-tuning processes to observe if the same temporal patterns hold.

### Open Question 2
- Question: Can this causal attribution framework scale to explain the formation of complex, high-level capabilities beyond simple syntactic tasks?
- Basis in paper: [explicit] Section 7 notes that the downstream tasks examined are "relatively simple," and scaling to "complex downstream tasks represents a natural direction for future work."
- Why unresolved: Current circuit tracing methodologies and the limited capabilities of the Pythia models constrain the ability to verify causal links for abstract reasoning or complex knowledge retrieval.
- What evidence would resolve it: Successful identification of feature circuits for complex tasks (e.g., multi-step reasoning or coding) that show clear causal relationships between feature formation and capability emergence.

### Open Question 3
- Question: How can crosscoders be adapted to capture continuous training dynamics without the memory constraints imposed by discrete snapshots?
- Basis in paper: [explicit] Section 7 highlights the "discrete snapshot requirement" where memory costs scale linearly with snapshot count, limiting observational granularity.
- Why unresolved: The current architecture requires pre-saved activations from discrete steps, potentially missing fine-grained evolution between steps or requiring prohibitive memory for high-resolution tracking.
- What evidence would resolve it: The development of an online or streaming crosscoder variant that can update feature dictionaries dynamically during training without storing all historical activations simultaneously.

## Limitations

- The crosscoder architecture assumes linear decomposability of neural representations, which may not hold for highly polysemantic features
- The 32-snapshot sampling strategy may miss critical transition points in feature emergence
- Attribution-based causality claims rely on linear approximations that may not capture full circuit interactions

## Confidence

- **High confidence**: Decoder norms as quantitative proxies for feature presence (supported by strong correlation with linear probe errors)
- **Medium confidence**: Phase transition from statistical to feature learning (consistent patterns across datasets but requires further validation)
- **Medium confidence**: Causal attribution to downstream task performance (ablation results are compelling but limited to single-layer features)

## Next Checks

1. Test crosscoder robustness across different layers and model scales to verify that feature evolution patterns are consistent rather than layer-specific artifacts
2. Implement ablation studies with more sophisticated non-linear attribution methods (e.g., path attribution) to validate the linear approximation assumptions
3. Extend analysis to multilingual models to determine whether observed phase transitions are universal or language-dependent