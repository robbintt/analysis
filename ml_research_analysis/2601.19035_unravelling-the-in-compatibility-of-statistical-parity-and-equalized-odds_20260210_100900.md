---
ver: rpa2
title: Unravelling the (In)compatibility of Statistical-Parity and Equalized-Odds
arxiv_id: '2601.19035'
source_url: https://arxiv.org/abs/2601.19035
tags:
- statistical-parity
- fairness
- groups
- measures
- equalized-odds
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the (in)compatibility of two statistical
  fairness measures, Statistical-Parity and Equalized-Odds, when there is base-rate
  imbalance among sensitive social groups in binary classification. Using a novel
  analytical approach, the authors show that enforcing both measures requires either
  having base-rate balance or adopting a random classifier.
---

# Unravelling the (In)compatibility of Statistical-Parity and Equalized-Odds

## Quick Facts
- arXiv ID: 2601.19035
- Source URL: https://arxiv.org/abs/2601.19035
- Reference count: 36
- One-line primary result: Statistical-Parity and Equalized-Odds are incompatible when base-rates differ across sensitive groups unless a random classifier is used.

## Executive Summary
This study investigates the theoretical incompatibility between two statistical fairness measures—Statistical-Parity and Equalized-Odds—in binary classification settings with base-rate imbalance across sensitive social groups. The authors develop a novel analytical framework showing that enforcing both measures simultaneously requires either base-rate balance or operation on the random classifier line (ROC chance line). Through graphical analysis on the FPR-TPR plane, they demonstrate that efficient classifiers performing well in terms of accuracy must make trade-offs between these fairness measures. The work highlights the critical importance of examining base-rate imbalance before relying on Statistical-Parity for assessing classifier fairness, as it may mask false prediction parity issues.

## Method Summary
The paper presents an analytical approach using a binary channel model with sensitive attribute S ∈ {0,1}, ground truth Y ∈ {0,1}, and predicted Ŷ ∈ {0,1}. Key metrics include base-rates p_s, posterior probabilities q_s, FPR_s, and TPR_s. The method derives linear performance lines in the FPR-TPR plane for each group using the relation q_s = p_s·TPR_s + (1−p_s)·FPR_s, showing these lines have slopes determined by 1−1/p_s. Theorem 1 proves that Statistical-Parity (q₀ = q₁) combined with Equalized-Odds (equal FPRs and TPRs across groups) requires either p₀ = p₁ or TPR* = FPR* (operation on ROC chance line). The analysis is illustrated through graphical representations showing trade-offs between fairness measures.

## Key Results
- Statistical-Parity and Equalized-Odds are mathematically incompatible when base-rates differ across groups unless the classifier operates on the ROC chance line (random classifier).
- Enforcing Statistical-Parity with base-rate imbalance forces Equalized-Odds lines to intersect at point (q*, q*), which lies on the TPR=FPR diagonal.
- The incompatibility can only be resolved by either achieving base-rate balance or accepting random classifier performance.
- Practical implication: practitioners must choose between fairness measures based on application context and available ground truth.

## Why This Works (Mechanism)

### Mechanism 1: Base-Rate Imbalance Creates Incompatibility
- Claim: When base-rates differ between protected and unprotected groups (p₀ ≠ p₁), satisfying both Statistical-Parity and Equalized-Odds simultaneously requires either base-rate equality or a random classifier.
- Mechanism: Mathematical derivation shows that Statistical-Parity (q₀ = q₁) combined with Equalized-Odds (equal FPRs and TPRs across groups) implies (p₀ - p₁)(TPR* - FPR*) = 0. This product equals zero only if either p₀ = p₁ OR TPR* = FPR* (operation on ROC chance line).
- Core assumption: Binary classification setting with two sensitive groups; objective labeling available for Equalized-Odds assessment.
- Evidence anchors:
  - [abstract] "enforcing both measures requires either having base-rate balance or adopting a random classifier"
  - [Section 4.1, Theorem 1] Derives condition: either p₀ = p₁ or TPR* = FPR*
  - [corpus] Weak direct support; related work [7] mentions incompatibility but uses different mathematical framework
- Break condition: When p₀ = p₁ (base-rate balance), both measures become compatible without requiring operation on the chance line.

### Mechanism 2: Linear Performance Lines on ROC Plane
- Claim: Statistical-Parity constraint creates parallel performance lines on the FPR-TPR plane, with slopes determined by group base-rates.
- Mechanism: From TPR_s = (1 - 1/p_s)FPR_s + q*/p_s, each base-rate p_s creates a family of parallel lines parameterized by q*. Different base-rates produce different slopes, causing L₀ and L₁ to intersect.
- Core assumption: Binary outcomes with measurable FPR, TPR, and posterior probabilities; single ROC curve applies to both groups.
- Evidence anchors:
  - [Section 4.2] "Relation (17) represents a system of parallel lines in the FPR−TPR plane, by varying the value of parameter q*"
  - [Figure 3, 4, 5] Visualize performance lines with different slopes for different base-rates
  - [corpus] Not directly addressed in corpus papers
- Break condition: When p₀ = p₁, lines L₀ and L₁ become parallel with identical slopes, eliminating intersection constraint.

### Mechanism 3: Intersection Point Lies on ROC Chance Line
- Claim: When Statistical-Parity is enforced with base-rate imbalance, the Equalized-Odds lines for different groups intersect at point (q*, q*), which lies on the TPR = FPR diagonal (random classifier line).
- Mechanism: Solving the system of linear equations L₀ and L₁ yields FPR* = q* and TPR* = q* at the intersection, meaning any operation point satisfying both fairness measures with different base-rates must perform no better than random guessing.
- Core assumption: Same ROC curve for both groups; classifier operates above chance line for useful prediction.
- Evidence anchors:
  - [Section 4.2, Theorem 2] "the Equalized-Odds lines for these groups cross each other at point (q*, q*)"
  - [Corollary 2] "the intersection point of the Equalized-Odds lines for these groups lie on the line TPR = FPR"
  - [corpus] Not directly addressed in corpus
- Break condition: If groups use different classifiers (different ROC curves), the intersection properties may differ from the single-classifier case.

## Foundational Learning

- Concept: Statistical-Parity (Demographic Parity)
  - Why needed here: This is the ground-truth-free fairness measure widely used in legal frameworks; it requires equal positive prediction rates across groups (q₀ = q₁) regardless of actual outcomes.
  - Quick check question: If a classifier predicts 30% positive outcomes for both protected and unprotected groups, does Statistical-Parity hold? (Answer: Yes, regardless of base-rates)

- Concept: Equalized-Odds (combining Predictive Equality and Equal Opportunity)
  - Why needed here: This ground-truth-dependent measure captures error rate parity; it requires FPR₁ = FPR₀ AND TPR₁ = TPR₀, ensuring false prediction parity across groups.
  - Quick check question: A classifier has FPR=0.2 for both groups but TPR=0.8 for group 0 and 0.6 for group 1. Does Equalized-Odds hold? (Answer: No—both FPR and TPR must be equal)

- Concept: Base-Rate (Prior Probability)
  - Why needed here: The proportion of actual positive outcomes in each group; base-rate imbalance (p₀ ≠ p₁) is the root cause of incompatibility between fairness measures.
  - Quick check question: If 100/1000 in group A and 300/1000 in group B have positive outcomes, are base-rates balanced? (Answer: No—p_A=0.1, p_B=0.3)

## Architecture Onboarding

- Component map:
  - Binary Channel Model (Figure 1): Ground truth Y → Classification → Prediction Ŷ, with sensitive attribute S
  - Performance Metrics per group s: FPR_s, TPR_s (= 1 - FNR_s), base-rate p_s, posterior probability q_s
  - Fairness Constraints: Statistical-Parity (q₀ = q₁), Equalized-Odds (FPR₁ = FPR₀ ∧ TPR₁ = TPR₀)
  - Analysis Plane: FPR-TPR space showing ROC curves and performance lines L₀, L₁ with slopes (1 - 1/p_s)

- Critical path:
  1. Measure base-rates p₀ and p₁ in deployment data before selecting fairness criteria
  2. If p₀ ≠ p₁, recognize Statistical-Parity and Equalized-Odds are incompatible for useful classifiers
  3. Select fairness criterion aligned with legal/ethical context (Statistical-Parity when no ground truth available; Equalized-Odds when false prediction parity matters)
  4. Plot performance lines on FPR-TPR plane to visualize trade-offs at chosen q*

- Design tradeoffs:
  - Statistical-Parity vs Equalized-Odds: Cannot satisfy both when base-rates differ unless classifier operates on chance line (useless)
  - Accuracy vs Fairness constraints: Enforcing both fairness measures forces random classifier performance
  - Group FPR balance vs Group TPR balance: Achieving Statistical-Parity with different base-rates necessitates unequal error rates between groups

- Failure signatures:
  - Enforcing Statistical-Parity without checking base-rate imbalance → hidden FPR/FNR inequalities (Case II in Figure 5a)
  - Using only ground-truth-free metrics → cannot detect error rate disparities
  - Achieving Equalized-Odds with base-rate imbalance → unequal q values, violating Statistical-Parity (Cases III, IV in Figure 5b,c)

- First 3 experiments:
  1. Compute base-rates p₀ and p₁ in deployment data; if ratio exceeds ~1.5, document incompatibility risk
  2. Plot lines L₀ and L₁ for current q* values on FPR-TPR plane; verify intersection lies on TPR=FPR line
  3. Test classifier at different thresholds per group; measure FPR, TPR disparities when Statistical-Parity is enforced to quantify the fairness trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the incompatibility relationships between Statistical-Parity and Equalized-Odds generalize to non-binary classification scenarios where sensitive attributes and/or target attributes are categorical, or where the target is a soft output (e.g., risk scores)?
- Basis in paper: [explicit] The conclusion states: "One direction is to extend the results to non-binary classification scenarios where the sensitive attribute and/or the target attribute is categorical or the target attribute is a soft output."
- Why unresolved: The current analysis is confined to binary classification with binary sensitive groups, limiting applicability to more complex real-world scenarios.
- What evidence would resolve it: Formal derivation of incompatibility conditions for multi-class or soft-output settings, potentially extending the graphical trade-off representation.

### Open Question 2
- Question: What principled guidelines can be developed for practitioners to make context-appropriate trade-offs between Statistical-Parity and Equalized-Odds when base-rate imbalance exists?
- Basis in paper: [explicit] The conclusion states: "As another direction, guidelines can be developed for making trade-offs between Statistical-Parity and Equalized-Odds measures."
- Why unresolved: The paper demonstrates that trade-offs are necessary but does not prescribe how to navigate them in specific application contexts.
- What evidence would resolve it: Domain-specific frameworks or decision aids that map application characteristics (e.g., severity of false positives vs. false negatives) to recommended fairness measure prioritization.

### Open Question 3
- Question: What incompatibility forms exist among other statistical fairness measures beyond the Statistical-Parity/Equalized-Odds and Equalized-Odds/Predictive-Parity pairs studied thus far?
- Basis in paper: [explicit] The conclusion states the work "motivate[s] further research on and specification of the incompatibility forms that exist among other statistical fairness measures."
- Why unresolved: The broader landscape of pairwise or multi-way incompatibilities among fairness metrics remains unmapped.
- What evidence would resolve it: Systematic analysis cataloging which combinations of statistical fairness measures can or cannot be simultaneously satisfied under various base-rate conditions.

## Limitations

- The analysis is limited to binary classification settings and may not generalize to multi-class or continuous prediction scenarios.
- The framework assumes a single classifier applies to both groups, which may not hold in practice where different models or thresholds could be used per group.
- The graphical representations are illustrative rather than based on empirical data, limiting practical validation of the incompatibility predictions.

## Confidence

- Medium: The core incompatibility result is theoretically sound under the specified assumptions, but real-world applicability depends on whether these assumptions hold in practice.

## Next Checks

1. Apply the framework to a real-world dataset with known base-rate imbalance (e.g., COMPAS recidivism data) to empirically verify the incompatibility predictions.
2. Test whether alternative classifier configurations (per-group classifiers) can achieve both fairness measures without requiring operation on the chance line.
3. Examine how measurement uncertainty in base-rates and classification metrics affects the predicted incompatibility regions in the FPR-TPR plane.