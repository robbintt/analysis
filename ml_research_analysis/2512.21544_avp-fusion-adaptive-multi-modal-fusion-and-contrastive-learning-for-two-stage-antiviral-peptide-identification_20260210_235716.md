---
ver: rpa2
title: 'AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage
  Antiviral Peptide Identification'
arxiv_id: '2512.21544'
source_url: https://arxiv.org/abs/2512.21544
tags:
- learning
- feature
- sequence
- prediction
- peptides
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AVP-Fusion, a two-stage deep learning framework
  for antiviral peptide (AVP) identification and subclass prediction. It addresses
  the limitations of existing methods in capturing sequence dependencies and handling
  hard-to-classify samples by integrating adaptive feature fusion and contrastive
  learning.
---

# AVP-Fusion: Adaptive Multi-Modal Fusion and Contrastive Learning for Two-Stage Antiviral Peptide Identification

## Quick Facts
- **arXiv ID:** 2512.21544
- **Source URL:** https://arxiv.org/abs/2512.21544
- **Reference count:** 40
- **Primary result:** AVP-Fusion achieves state-of-the-art performance with accuracy 0.9531 and MCC 0.9064 for AVP identification.

## Executive Summary
AVP-Fusion is a two-stage deep learning framework for antiviral peptide (AVP) identification and subclass prediction. It addresses limitations in existing methods by integrating adaptive feature fusion and contrastive learning to capture sequence dependencies and handle hard-to-classify samples. The model combines 10 distinct descriptors with an Adaptive Gating Mechanism to dynamically regulate feature weights based on sequence context. Using biologically informed mutation and Online Hard Example Mining, AVP-Fusion achieves superior performance on benchmark datasets and enables precise subclass prediction even under limited sample sizes.

## Method Summary
AVP-Fusion implements a dual-channel encoder combining 1D-CNN (local motifs) and BiLSTM (global dependencies), fused through an Adaptive Gating Network that learns class-specific weight distributions. The framework uses ESM-2 embeddings plus 10 traditional descriptors as input features. Training employs Focal Loss for classification, contrastive loss with OHEM for boundary sharpening, and consistency loss for regularization. Stage 1 performs binary AVP classification, then transfers learned representations to Stage 2 for subclass prediction across six viral families and eight specific viruses. The model uses BLOSUM62-guided augmentation and achieves high performance through this multi-modal, biologically-informed approach.

## Key Results
- Stage 1 binary classification achieves accuracy of 0.9531 and MCC of 0.9064
- Outperforms existing state-of-the-art methods on benchmark datasets
- Stage 2 subclass prediction works effectively under limited sample sizes
- Robust performance across six viral families and eight specific viruses

## Why This Works (Mechanism)

### Mechanism 1: Context-Adaptive Feature Gating
If the model dynamically weights local versus global features based on sequence characteristics, it may better resolve heterogeneity between distinct peptide families than static concatenation. An Adaptive Gating Network computes scalar weight (λ) to blend CNN outputs (local motifs) and BiLSTM outputs (global dependencies). The network learns to favor global context (BiLSTM) for functional AVPs and local motifs (CNN) for non-AVPs, creating conditional feature paths. Core assumption: distinct classes rely on fundamentally different sequence structural signatures. Evidence: gating weight distributions show distinct patterns for AVP vs non-AVP samples. Break condition: if λ converges to constant value for all inputs, adaptive mechanism has failed.

### Mechanism 2: Boundary Sharpening via Hard Negative Mining
If training actively identifies and separates "hard" negative samples (non-AVPs similar to AVPs), the decision boundary becomes more robust against ambiguous samples. The model uses prototype-based Online Hard Example Mining strategy with dynamic negative queue selecting samples with high similarity to positive prototype as "hard negatives." Contrastive loss explicitly pushes these specific negatives away while pulling augmented positives closer. Core assumption: random negative sampling is insufficient because most negatives are trivially easy to classify; model gains more from struggling with edge cases. Evidence: similarity of hard negative pairs decays sharply during training. Break condition: if "hard" negatives are mislabeled positives, this mechanism will degrade performance by pushing valid classes apart.

### Mechanism 3: Biologically Informed Data Augmentation
If data augmentation respects evolutionary constraints, generated synthetic samples expand decision manifold without introducing semantic noise. Instead of random mutation, model uses "second-best" strategy guided by BLOSUM62 substitution matrix, selecting most evolutionarily plausible substitution for given residue. This simulates realistic variants rather than random noise. Core assumption: evolutionary plausibility correlates strongly with maintaining antiviral activity. Evidence: augmented samples cluster tightly around originals while random mutation leads to divergence. Break condition: if "second-best" substitution alters critical active site residue, augmentation would erroneously generate positive pair for non-functional peptide.

## Foundational Learning

- **Concept: Contrastive Learning (InfoNCE Loss)**
  - **Why needed here:** Model relies on pulling positive pairs (original + augmented) together and pushing negative pairs apart in embedding space.
  - **Quick check question:** Can you explain how temperature parameter τ affects "softness" of classification boundary in contrastive loss?

- **Concept: Long Short-Term Memory (LSTM) vs. CNN Inductive Biases**
  - **Why needed here:** Core fusion mechanism depends on CNN branch capturing local motifs while BiLSTM captures long-range sequence dependencies.
  - **Quick check question:** Why would BiLSTM potentially outperform CNN on identifying functional domain defined by distant residue interactions?

- **Concept: Transfer Learning in Small-Data Regimes**
  - **Why needed here:** Stage 2 operates on small datasets (<200 samples). Success depends on pre-training on larger Stage 1 dataset.
  - **Quick check question:** Why do we freeze or use lower learning rate for pre-trained encoder weights during fine-tuning stage?

## Architecture Onboarding

- **Component map:** ESM-2 Embeddings + 10 Handcrafted Descriptors -> Parallel 1D-CNN + BiLSTM -> Adaptive Gating Network -> Focal Loss + Contrastive Loss + Consistency Loss
- **Critical path:** Adaptive Gating Network is central integration point. Model fails if gate cannot learn distinct policies for distinct classes. OHEM Queue maintenance is most complex training logic.
- **Design tradeoffs:**
  - Complexity vs. Robustness: Multi-loss setup requires tuning three hyperparameters but handles class imbalance better
  - ESM-2 vs. Speed: Pre-trained 150M parameter LLM provides strong features but increases inference overhead
- **Failure signatures:**
  - Mode Collapse (Gate): If λ stays near 0.5, model isn't learning to differentiate local vs. global utility
  - Queue Contamination: If OHEM negative queue not flushed/updated correctly, model trains on stale/irrelevant hard negatives
  - Over-regularization: Excessive consistency loss may smooth decision boundary too much, failing to separate difficult subclasses
- **First 3 experiments:**
  1. Gate Distribution Visualization: Plot histogram of λ values for AVP vs Non-AVP test sets to verify bimodal behavior
  2. Ablation on OHEM: Compare performance with OHEM vs random negative sampling to quantify boundary sharpening effect
  3. Transfer Efficiency Test: Train Stage 2 models from scratch vs fine-tuning from Stage 1 on small subclass to prove transfer learning hypothesis

## Open Questions the Paper Calls Out

- **Open Question 1:** Does incorporating AlphaFold-predicted 3D structural features enhance AVP-Fusion's predictive accuracy for functional subclasses compared to 1D sequence data alone? The conclusion states future work will focus on integrating 3D structural information to further refine efficiency and applicability. Current model relies exclusively on 1D sequence data which may miss spatial conformational details critical for specific viral binding. Evidence would require comparative study showing statistically significant improvement in MCC for subclass predictions using 3D vs 1D data.

- **Open Question 2:** Can uncertainty-based sampling strategies replace or complement current Online Hard Example Mining approach to improve model efficiency? Authors explicitly identify exploring uncertainty-based sampling as future direction to refine screening efficiency. Current OHEM mines hard negatives based on feature similarity to positive prototypes but does not explicitly quantify model uncertainty which could better flag ambiguous, out-of-distribution samples. Evidence would require experiments demonstrating uncertainty-driven active learning loop achieves higher accuracy with fewer training iterations or samples than current OHEM static queue method.

- **Open Question 3:** How robust is AVP-Fusion when predicting AVPs for novel viral families or emerging variants not represented in 14 specific subclasses used for training? Paper notes data scarcity for specific virus types constrains performance and validates only on pre-defined families. While transfer learning helps with limited data, model's ability to generalize to phylogenetically distant or newly emerged viruses remains untested. Evidence would require testing on hold-out dataset of AVPs targeting viral families completely excluded from training and fine-tuning phases.

## Limitations
- Architecture details lack precise specifications for CNN kernel sizes, filter counts, BiLSTM hidden dimensions, and MLP classifier topology
- Hyperparameter values including OHEM queue sizes, number of hard negatives, temperature parameter, loss weights, batch size, and dropout rates are not provided
- Evaluation reproducibility concerns due to unspecified preprocessing pipeline, CD-HIT thresholds, and negative sampling methodology

## Confidence

**High Confidence (8/10):** Adaptive gating mechanism's core concept well-supported by empirical evidence showing distinct weight distributions for AVP vs non-AVP classes. Visualization of λ values provides strong validation.

**Medium Confidence (6/10):** OHEM-based contrastive learning approach shows promising results in boundary sharpening but lacks ablation studies comparing different negative sampling strategies to quantify exact contribution.

**Medium Confidence (6/10):** Biologically-informed augmentation using BLOSUM62 is theoretically sound but claim that "second-best" mutations preserve biochemical properties requires more rigorous validation regarding active site preservation.

## Next Checks

1. **Gate Distribution Verification:** Plot histogram of adaptive gating weights (λ) for AVP vs non-AVP test sets to confirm bimodal distribution pattern shown in paper's Figure 5.

2. **OHEM Contribution Quantification:** Implement and compare model performance with OHEM versus random negative sampling on same benchmark to measure precise impact on decision boundary sharpness.

3. **Active Site Mutation Analysis:** For BLOSUM62 augmentation strategy, analyze whether generated mutations near known active sites maintain or disrupt predicted functional properties using domain-specific tools.