---
ver: rpa2
title: 'Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment
  Mechanism of Large Speech Language Models'
arxiv_id: '2510.12116'
source_url: https://arxiv.org/abs/2510.12116
tags:
- speech
- alignment
- text
- similarity
- modality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the modality gap in Large Speech Language
  Models (LSLMs), defined as the performance disparity between speech and text inputs.
  Through systematic experimentation, the authors analyze speech-text alignment at
  both coarse-grained (sequence-level) and fine-grained (token-level) representations.
---

# Understanding the Modality Gap: An Empirical Study on the Speech-Text Alignment Mechanism of Large Speech Language Models

## Quick Facts
- arXiv ID: 2510.12116
- Source URL: https://arxiv.org/abs/2510.12116
- Reference count: 32
- This study provides the first systematic empirical analysis of the modality gap and alignment mechanisms in Large Speech Language Models

## Executive Summary
This study investigates the modality gap in Large Speech Language Models (LSLMs), defined as the performance disparity between speech and text inputs. Through systematic experimentation, the authors analyze speech-text alignment at both coarse-grained (sequence-level) and fine-grained (token-level) representations. At the sequence level, they find that deeper layers increasingly align speech and text representations in direction while diverging in magnitude, with representation similarity strongly correlating with the modality gap. At the token level, they observe spontaneous monotonic alignment patterns and introduce the Alignment Path Score to quantify token-level alignment quality. Targeted interventions using angle projection and length normalization on critical tokens demonstrate potential to improve speech input performance, particularly for challenging cases.

## Method Summary
The study employs a systematic approach to analyze speech-text alignment in LSLMs. Researchers first define the modality gap as the performance difference between speech and text inputs. They then conduct experiments to examine alignment at sequence level through representation similarity analysis and at token level through attention analysis and alignment path scoring. The authors implement targeted interventions including angle projection and length normalization on speech embeddings, then evaluate their impact on model performance. Experiments are conducted on the CosyVoice dataset using single-turn dialogue tasks, with analyses spanning multiple model layers to understand how alignment evolves through the network.

## Key Results
- Deeper layers show increasing directional alignment but magnitude divergence between speech and text representations
- Representation similarity strongly correlates with modality gap across layers
- Token-level analysis reveals spontaneous monotonic alignment patterns
- Targeted interventions (angle projection) improve speech performance in 6/8 settings
- Alignment Path Score (APS) effectively quantifies token-level alignment quality

## Why This Works (Mechanism)
The mechanism underlying the modality gap appears to stem from fundamental differences in how speech and text inputs are processed through the network. As representations flow through deeper layers, speech and text embeddings increasingly align in direction (indicating semantic convergence) but diverge in magnitude (suggesting modality-specific scaling differences). This creates a situation where the representations point in similar directions but have different lengths, potentially causing the model to treat them differently during downstream processing. The spontaneous monotonic alignment at the token level suggests that LSLMs develop internal alignment mechanisms even without explicit training supervision, with the Alignment Path Score capturing how consistently tokens maintain their relative positions across modalities.

## Foundational Learning
- **Modality Gap**: The performance disparity between speech and text inputs in LSLMs. Why needed: Establishes the core problem being investigated. Quick check: Compare model accuracy on parallel speech vs. text inputs.
- **Representation Similarity Analysis**: Measures cosine similarity between speech and text embeddings across layers. Why needed: Quantifies how well modalities align at different depths. Quick check: Plot similarity curves across layers for both modalities.
- **Token-Level Alignment**: Examines whether corresponding tokens in speech and text maintain consistent relative positions. Why needed: Reveals fine-grained alignment patterns beyond sequence-level analysis. Quick check: Verify monotonic alignment exists in clean data before applying APS.
- **Alignment Path Score (APS)**: A metric quantifying token-level alignment quality based on monotonic paths. Why needed: Provides a quantitative measure of fine-grained alignment. Quick check: Test APS sensitivity to known alignment perturbations.
- **Targeted Interventions**: Application of angle projection and length normalization to speech embeddings. Why needed: Tests whether observed misalignment patterns can be corrected. Quick check: Apply interventions to clearly misaligned cases first.

## Architecture Onboarding
- **Component Map**: Input → Encoder/Decoder → Multi-head Attention → Feed-Forward → LayerNorm → Output
- **Critical Path**: Speech/Text Input → Embedding Layer → Multiple Transformer Layers → Final Representation → Task-specific Head
- **Design Tradeoffs**: Implicit alignment vs. explicit alignment training; single-model vs. modality-specific models; intervention during training vs. inference
- **Failure Signatures**: High modality gap despite high sequence-level similarity; inconsistent token alignment despite good sequence alignment; performance degradation with length normalization
- **First Experiments**: 1) Baseline modality gap measurement on clean data, 2) Layer-wise representation similarity analysis, 3) APS calculation on critical tokens

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the intervention strategies (angle projection, length normalization) be effectively integrated into the training process rather than applied post-hoc at inference time?
- Basis in paper: [explicit] The authors state in Limitations: "An important direction is to integrate these insights into training to explicitly optimize cross-modal consistency and improve speech-input performance."
- Why unresolved: Current interventions are applied only during inference as analytical probes. The paper demonstrates correlation between alignment quality and performance but does not test whether optimizing APS during training improves the modality gap.
- What evidence would resolve it: Training experiments that incorporate APS or angle-based regularization as a loss component, comparing resulting modality gaps against baseline training.

### Open Question 2
- Question: Why does length normalization consistently degrade performance while angle projection improves it, despite both being derived from the same observed alignment patterns?
- Basis in paper: [inferred] Table 1 shows angle projection improves performance in 6/8 settings, while length normalization improves only 1/8. The paper does not explain this asymmetry despite both interventions targeting identified misalignment issues.
- Why unresolved: The paper observes directional convergence alongside magnitude divergence but does not explain why normalizing magnitude is harmful. This suggests magnitude differences may carry important modality-specific information rather than being pure noise.
- What evidence would resolve it: Ablation studies analyzing what information is encoded in speech vs. text embedding magnitudes; tests with selective magnitude preservation.

### Open Question 3
- Question: Do the observed alignment patterns and modality gap mechanisms generalize to real-world noisy speech, multi-turn conversations, and languages beyond English?
- Basis in paper: [explicit] The authors acknowledge in Limitations: "Our evaluation centers on English, single-turn dialogue with synthetic speech, which may limit the applicability of the findings to other languages, multi-turn conversations, and noisy real-world inputs."
- Why unresolved: All experiments use synthetic speech from CosyVoice and single-turn dialogues. Real speech contains noise, disfluencies, and prosodic variations that may affect alignment quality differently.
- What evidence would resolve it: Replication of experiments on noisy speech corpora (e.g., real conversational data), multilingual benchmarks, and multi-turn dialogue tasks.

## Limitations
- Focus on a single LSLM architecture limits generalizability across different model families
- Analysis relies primarily on cosine similarity and projection-based metrics, potentially missing other aspects of semantic correspondence
- Targeted interventions show promise but scalability and practical implementation remain unexplored

## Confidence
- **High**: Existence and characterization of the modality gap; sequence-level alignment patterns across layers
- **Medium**: Token-level alignment analysis; effectiveness of targeted interventions
- **Low**: Broader applicability of Alignment Path Score as a universal metric

## Next Checks
1. Replicate the analysis across multiple LSLM architectures (including both encoder-decoder and decoder-only models) to assess generalizability of the findings
2. Conduct ablation studies to isolate the contribution of specific architectural components (such as positional embeddings and attention mechanisms) to the observed modality gap
3. Evaluate the practical impact of the proposed interventions on downstream tasks across diverse domains and languages to assess real-world applicability