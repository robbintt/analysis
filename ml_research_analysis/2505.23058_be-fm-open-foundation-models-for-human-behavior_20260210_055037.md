---
ver: rpa2
title: 'Be.FM: Open Foundation Models for Human Behavior'
arxiv_id: '2505.23058'
source_url: https://arxiv.org/abs/2505.23058
tags:
- behavioral
- data
- behavior
- sharing
- confidence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Be.FM is a family of foundation models designed to model human
  behavior by fine-tuning large language models on diverse behavioral datasets. It
  aims to predict and simulate behaviors, infer subject characteristics, generate
  contextual insights, and apply behavioral science knowledge.
---

# Be.FM: Open Foundation Models for Human Behavior

## Quick Facts
- arXiv ID: 2505.23058
- Source URL: https://arxiv.org/abs/2505.23058
- Reference count: 40
- Key outcome: Be.FM outperforms general-purpose LLMs on behavioral science tasks including economic game prediction, personality trait inference, and complex problem-solving

## Executive Summary
Be.FM is a family of foundation models designed to model human behavior by fine-tuning large language models on diverse behavioral datasets. It aims to predict and simulate behaviors, infer subject characteristics, generate contextual insights, and apply behavioral science knowledge. Evaluated on tasks like economic game behavior prediction, Big Five personality trait inference, demographic prediction, context inference in experiments, and complex problem-solving (IEO), Be.FM outperforms general-purpose LLMs and commercial models on most benchmarks. It shows improved alignment with human behavior distributions and better individual-level predictions, demonstrating the potential of behavioral foundation models to advance behavioral science research and applications.

## Method Summary
Be.FM fine-tunes LLaMA-3.1-8B-Instruct and LLaMA-3.1-70B-Instruct using SFT+LoRA across all layers with 8-bit quantization for the larger model. The training uses LlamaFactory with hyperparameters including batch size 1, gradient accumulation of 8, learning rate 1e-4, cosine scheduler, warmup 0.1, and 3 epochs in bf16 precision. Data is formatted via Alpaca template and includes literature data from 2,703 AER publications (3.1M tokens), experimental data from 68,779 subjects across 5 economic games (82,057 observations), and survey data from 17,667 subjects on Big Five personality traits.

## Key Results
- Outperforms general-purpose LLMs on economic game behavior prediction with lower Wasserstein distance metrics
- Achieves significant improvements in Big Five personality trait prediction (Spearman's correlation 0.10-0.24 vs baseline 0.04)
- Solves IEO economics problems with higher accuracy than baseline models
- Demonstrates better alignment with human behavior distributions across multiple behavioral tasks

## Why This Works (Mechanism)
The success of Be.FM stems from domain-specific fine-tuning on behavioral datasets rather than general pretraining. By training on economic game data, personality surveys, and behavioral science literature, the model learns the distributional patterns and contextual nuances specific to human decision-making. The SFT+LoRA approach allows efficient adaptation while preserving the base model's capabilities. The diverse data sources provide complementary perspectives: literature for theoretical frameworks, experiments for observed behaviors, and surveys for individual characteristics.

## Foundational Learning
- Wasserstein distance: Metric for distribution alignment; needed to measure how well model predictions match real human behavior distributions; quick check: compare histogram shapes between predictions and ground truth
- Spearman's correlation: Rank-based correlation metric; needed for personality prediction where absolute values matter less than relative rankings; quick check: correlation > 0.10 indicates significant prediction ability
- LoRA fine-tuning: Parameter-efficient adaptation method; needed to customize large models without full fine-tuning costs; quick check: observe training stability and convergence

## Architecture Onboarding
- Component map: Data Preprocessing -> Alpaca Formatting -> SFT+LoRA Fine-tuning -> Evaluation
- Critical path: Data acquisition → preprocessing/formatting → fine-tuning → evaluation on held-out test sets
- Design tradeoffs: Model size vs. computational efficiency (8B vs 70B), full fine-tuning vs. LoRA parameter efficiency, proprietary vs. open datasets
- Failure signatures: Poor distribution alignment indicates prompt formatting issues; low correlation in personality prediction suggests insufficient behavioral signal in training data
- First experiments: 1) Fine-tune on single economic game and compare Wasserstein distance; 2) Train personality prediction on subset of Big Five data; 3) Test IEO problem-solving on small sample

## Open Questions the Paper Calls Out
None

## Limitations
- Proprietary MobLab experimental data requires platform access, limiting reproducibility
- Unspecified LoRA hyperparameters (rank, alpha, dropout) may affect performance
- Model weights availability uncertain with placeholder link for access

## Confidence
- High confidence: Distribution alignment metrics (Wasserstein distance), economic game prediction accuracy
- Medium confidence: Personality trait prediction improvements, IEO problem-solving performance
- Low confidence: General behavioral simulation capabilities, long-term model utility without access to proprietary training data

## Next Checks
1. Attempt to reproduce the Wasserstein distance metric on public economic game datasets (e.g., public ultimatum game datasets) to verify distribution alignment claims without MobLab data
2. Replicate the Big Five personality prediction pipeline using the open Kaggle dataset to validate the 0.10-0.24 Spearman correlation improvements against general LLMs
3. Request access to the AER workflow dataset or equivalent behavioral science literature corpus to test the workflow reasoning task (300 papers) independently