---
ver: rpa2
title: 'DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence'
arxiv_id: '2511.10404'
source_url: https://arxiv.org/abs/2511.10404
tags:
- entity
- delicate
- historical
- entities
- wikidata
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "DELICATE addresses Entity Linking in historical Italian by combining\
  \ a BERT-based bi-encoder for candidate retrieval with a Gradient-Boosted Trees\
  \ (GBTs) classifier that incorporates Wikidata\u2019s entity type and temporal information.\
  \ This neuro-symbolic approach outperforms both neural baselines (BLINK IT A, mGENRE)\
  \ and LLM-based variants (BLINK IT A-LLM) on ENEIDE, achieving up to 72.67% micro-accuracy\
  \ and 69.07 F1 on end-to-end EL."
---

# DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence

## Quick Facts
- arXiv ID: 2511.10404
- Source URL: https://arxiv.org/abs/2511.10404
- Reference count: 33
- Primary result: 72.67% micro-accuracy on ENEIDE historical Italian entity linking

## Executive Summary
DELICATE introduces a neuro-symbolic approach to entity linking for historical Italian documents by combining a BERT-based bi-encoder for candidate retrieval with a Gradient-Boosted Trees classifier that leverages Wikidata's entity type and temporal information. The system achieves state-of-the-art performance on the ENEIDE benchmark, outperforming both neural baselines and LLM-based approaches with up to 72.67% micro-accuracy. The method demonstrates strong generalization to out-of-domain historical data without additional fine-tuning, while providing more interpretable and confidence-calibrated predictions than purely neural systems.

## Method Summary
The DELICATE system uses a two-stage architecture: first, a frozen BERT-based bi-encoder retrieves candidate entities from Wikidata, then a Gradient-Boosted Trees classifier re-ranks these candidates using features including entity types and temporal information extracted from Wikidata. This neuro-symbolic approach combines neural retrieval efficiency with symbolic reasoning about entity properties, allowing the system to incorporate structured knowledge about entity categories and historical timelines into the disambiguation process.

## Key Results
- Achieves 72.67% micro-accuracy and 69.07 F1 on end-to-end EL for historical Italian documents
- Outperforms neural baselines (BLINK IT A, mGENRE) and LLM-based variants (BLINK IT A-LLM) on ENEIDE
- Generalizes to MHERCL-ITA dataset with 58.78% accuracy without fine-tuning
- Provides confidence-calibrated predictions through interpretable feature-based re-ranking

## Why This Works (Mechanism)
The neuro-symbolic approach works by combining the retrieval efficiency of neural embeddings with the interpretability and structured reasoning capabilities of symbolic features. The BERT-based bi-encoder provides semantic similarity matching for candidate retrieval, while the GBT classifier can explicitly reason about entity types and temporal evidence that are particularly important for historical documents where entity disambiguation often depends on period-specific context and categorical constraints.

## Foundational Learning
- **BERT bi-encoder architecture**: Needed for efficient candidate retrieval using semantic embeddings; quick check: frozen weights should maintain consistent similarity scores across document batches
- **Gradient-Boosted Trees**: Needed for interpretable re-ranking using structured features; quick check: feature importance scores should highlight temporal and type features for historical entities
- **Wikidata entity types**: Needed for categorical constraints in entity linking; quick check: type hierarchies should align with historical entity categorizations
- **Temporal evidence extraction**: Needed for period-specific disambiguation in historical documents; quick check: temporal features should correlate with disambiguation accuracy improvements
- **Entity linking evaluation metrics**: Needed to assess both retrieval and disambiguation performance; quick check: micro-accuracy and F1 should show consistent improvements across test sets

## Architecture Onboarding
**Component Map:** Document mentions -> BERT bi-encoder -> Candidate retrieval -> GBT re-ranker -> Final entity prediction

**Critical Path:** Document mention encoding → Candidate entity encoding → Semantic similarity scoring → Feature extraction (types, temporal) → GBT classification → Entity selection

**Design Tradeoffs:** Uses frozen bi-encoder weights for computational efficiency vs. potential performance gains from fine-tuning; balances neural retrieval with symbolic reasoning vs. end-to-end neural approaches

**Failure Signatures:** Poor performance on entities with sparse Wikidata coverage; degradation when temporal features are noisy or missing; reduced accuracy for entities spanning multiple historical periods

**First Experiments:**
1. Compare candidate retrieval precision with and without frozen bi-encoder weights
2. Evaluate feature importance scores to validate temporal and type feature contributions
3. Test performance degradation when Wikidata temporal information is removed

## Open Questions the Paper Calls Out
None

## Limitations
- Limited to Italian-language historical documents, raising cross-linguistic generalizability concerns
- Relies on Wikidata coverage and quality for entity types and temporal evidence
- Computational efficiency claims assume frozen bi-encoder weights remain optimal across different historical corpora
- Confidence calibration improvements need more rigorous quantification beyond end-to-end metrics

## Confidence
- **High Confidence**: Experimental methodology and baseline comparisons are sound with statistically significant improvements
- **Medium Confidence**: Generalizability claims supported but need testing across more diverse historical periods and document types
- **Medium Confidence**: Interpretability benefits demonstrated but could be more rigorously quantified through user studies

## Next Checks
1. Test DELICATE on multilingual historical corpora to verify cross-linguistic robustness
2. Conduct ablation studies removing temporal and entity type features to quantify individual contributions
3. Evaluate performance across different historical periods (medieval vs. modern Italian) to assess temporal generalizability