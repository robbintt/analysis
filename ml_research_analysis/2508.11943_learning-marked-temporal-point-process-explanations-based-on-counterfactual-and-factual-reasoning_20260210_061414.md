---
ver: rpa2
title: Learning Marked Temporal Point Process Explanations based on Counterfactual
  and Factual Reasoning
arxiv_id: '2508.11943'
source_url: https://arxiv.org/abs/2508.11943
tags:
- explanation
- mtpp
- counterfactual
- events
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of explaining predictions made
  by neural network-based Marked Temporal Point Process (MTPP) models, which are widely
  used in high-stakes applications. The key challenge is to identify the minimal and
  rational subset of historical events that explain why the model outputs a particular
  prediction, ensuring that the prediction accuracy based on this subset matches that
  of the full history while being better than the complement subset.
---

# Learning Marked Temporal Point Process Explanations based on Counterfactual and Factual Reasoning

## Quick Facts
- arXiv ID: 2508.11943
- Source URL: https://arxiv.org/abs/2508.11943
- Reference count: 40
- This paper proposes CFF, a learning-based method for generating counterfactual and factual explanations for MTPP predictions, achieving 6-10× faster processing than baselines while maintaining superior explanation quality.

## Executive Summary
This paper addresses the critical challenge of explaining predictions made by neural network-based Marked Temporal Point Process (MTPP) models. MTPP models are widely used in high-stakes applications such as social network analysis and healthcare monitoring, where understanding model predictions is essential for trust and accountability. The authors define the explanation problem as identifying the minimal and rational subset of historical events that can reproduce the model's prediction while being better than any complement subset. They propose a novel method called Counterfactual and Factual Explainer for MTPP (CFF) that combines both counterfactual and factual reasoning to avoid the irrational explanations that arise when using either approach alone.

The CFF method employs an encoder-decoder transformer architecture with a fully connected layer and the Gumbel-softmax trick for differentiable event sampling. The method optimizes parameters to select the fewest historical events by minimizing a surrogate hinge loss under counterfactual and factual constraints. Extensive experiments on three real-world datasets (Retweet, StackOverflow, and Yelp) demonstrate that CFF outperforms baseline methods in both explanation quality (measured by Optimal Transport Distance) and processing efficiency. The explanations generated by CFF consistently show better predictive capability than random subsets of the same length and align with common sense reasoning, particularly in identifying influential users in retweet activities.

## Method Summary
The authors propose CFF, a learning-based method that generates counterfactual and factual explanations for MTPP predictions by selecting a minimal subset of historical events. The method uses an encoder-decoder transformer architecture combined with Gumbel-softmax for differentiable sampling of events. CFF optimizes parameters to minimize a surrogate hinge loss under counterfactual and factual constraints, ensuring that the selected subset maintains predictive performance while being minimal. The method is evaluated on three real-world datasets and shows superior performance compared to baseline methods in both explanation quality and processing efficiency.

## Key Results
- CFF outperforms baseline methods (Greedy Search and Random Removal) in explanation quality measured by Optimal Transport Distance
- CFF achieves 6-10× faster processing efficiency compared to baseline methods
- Explanations generated by CFF consistently demonstrate better predictive capability than random subsets of the same length and align with common sense reasoning

## Why This Works (Mechanism)
The method works by combining counterfactual and factual reasoning to identify minimal subsets of historical events that explain model predictions. The counterfactual component ensures that the selected subset can reproduce the original prediction, while the factual component ensures that this subset performs better than any complement subset. By using differentiable sampling through Gumbel-softmax and optimizing a surrogate hinge loss, the method can efficiently learn to select the most relevant events while maintaining the required constraints.

## Foundational Learning
- Marked Temporal Point Processes: Why needed - to model event sequences with categorical marks; Quick check - verify understanding of intensity functions and conditional distributions
- Counterfactual Reasoning: Why needed - to ensure explanations can reproduce original predictions; Quick check - test ability to identify minimal changes that alter predictions
- Factual Reasoning: Why needed - to ensure explanations are better than random subsets; Quick check - verify that selected subsets outperform complement subsets
- Gumbel-softmax Trick: Why needed - for differentiable sampling of discrete events; Quick check - confirm understanding of temperature parameters and sampling process
- Optimal Transport Distance: Why needed - to measure explanation quality; Quick check - understand how this metric compares event distributions

## Architecture Onboarding

**Component Map:** Input events -> Encoder Transformer -> Gumbel-softmax sampling -> Decoder Transformer -> Fully connected layer -> Output explanation

**Critical Path:** The critical path involves encoding historical events, differentiable sampling of event subsets using Gumbel-softmax, decoding the selected subset, and predicting outcomes to evaluate explanation quality against counterfactual and factual constraints.

**Design Tradeoffs:** The method trades off between explanation minimality and predictive accuracy, using surrogate hinge loss to balance these competing objectives. The choice of transformer architecture provides strong representation learning but increases computational complexity.

**Failure Signatures:** Potential failures include selecting irrelevant events that satisfy constraints but lack interpretability, overfitting to specific dataset patterns, and inability to find minimal subsets that maintain predictive performance.

**First Experiments:**
1. Test CFF on synthetic MTPP data with known ground truth explanations
2. Evaluate explanation stability under different temperature settings in Gumbel-softmax
3. Compare CFF explanations with human-generated explanations on a subset of predictions

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on surrogate hinge loss optimization may not perfectly capture counterfactual and factual constraints
- Limited evaluation on only three real-world datasets raises concerns about generalizability
- Assumption that minimal subsets can always be found that maintain predictive performance may not hold for all MTPP models

## Confidence
- High confidence in the core methodological contribution of combining counterfactual and factual reasoning for MTPP explanations
- Medium confidence in the empirical performance claims given the limited dataset diversity
- Medium confidence in the efficiency improvements due to lack of comparison with other optimization-based explanation methods

## Next Checks
1. Test CFF on additional temporal point process datasets including those with different event patterns and scales to assess generalizability
2. Compare CFF's explanations with human-generated explanations on the same prediction tasks to evaluate alignment with human reasoning
3. Implement an ablation study removing either the counterfactual or factual components to quantify their individual contributions to explanation quality