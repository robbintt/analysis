---
ver: rpa2
title: 'MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use'
arxiv_id: '2502.15872'
source_url: https://arxiv.org/abs/2502.15872
tags:
- plan
- search
- step
- plans
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces MutaGReP, a method that searches for repository-grounded
  plans to help language models use codebases more effectively. It formulates plan
  search as neural tree search, where plans are mutated and grounded in the codebase
  using a symbol retriever.
---

# MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use

## Quick Facts
- arXiv ID: 2502.15872
- Source URL: https://arxiv.org/abs/2502.15872
- Reference count: 23
- MutaGReP plans use <5% of context window but match GPT-4o on LongCodeArena

## Executive Summary
MutaGReP introduces an execution-free approach to code-use tasks that searches for repository-grounded plans without generating code during the search phase. The method formulates plan search as neural tree search, where initial plans are mutated and grounded in the codebase using a symbol retriever. On LongCodeArena, MutaGReP demonstrates that plans using less than 5% of the context window can match the performance of GPT-4o with full repository context, enabling smaller models like Qwen 2.5 Coder 32B to achieve similar results.

## Method Summary
MutaGReP addresses code-use tasks by generating symbolic plans rather than full code. The approach begins with an initial plan generated from user intent, then mutates this plan through a tree search process. During search, plans are grounded in the repository using a symbol retriever that maps plan intents to actual codebase symbols. The method uses a diversity scorer to ensure plans are distinct and a Likert scorer to judge feasibility. After the search completes, the grounded plan is executed to generate the final code, achieving results comparable to models with full repository context while using significantly less memory.

## Key Results
- Plans use less than 5% of the context window but match GPT-4o performance on LongCodeArena
- Smaller models (Qwen 2.5 Coder 32B) match GPT-4o performance when using MutaGReP plans
- MutaGReP plans enable progress on the hardest tasks in the benchmark

## Why This Works (Mechanism)
MutaGReP works by separating the planning phase from execution, allowing for efficient search over symbolic plans rather than full code generation. The neural tree search framework enables systematic exploration of plan variations while the symbol retriever grounds abstract plans in concrete repository elements. This separation allows the method to leverage repository knowledge without the computational cost of full code generation during search, making it feasible to find high-quality plans within limited context windows.

## Foundational Learning
- Neural tree search: Why needed? To systematically explore plan variations; Quick check: Does the search cover diverse plan structures?
- Symbol grounding: Why needed? To map abstract plans to concrete repository elements; Quick check: Are retrieved symbols semantically relevant to plan intents?
- Execution-free search: Why needed? To reduce computational cost during planning; Quick check: Does execution-free planning maintain plan quality compared to execution-guided approaches?

## Architecture Onboarding
- Component map: User intent -> Initial plan generation -> Neural tree search -> Symbol retrieval -> Plan mutation -> Diversity scoring -> Likert scoring -> Final execution
- Critical path: User intent → Initial plan generation → Neural tree search → Symbol retrieval → Final execution
- Design tradeoffs: Execution-free vs. execution-guided search (efficiency vs. correctness verification)
- Failure signatures: Poor plan quality due to inadequate symbol retrieval or suboptimal mutation strategies
- First experiments: 1) Ablation of diversity scorer impact on plan coverage, 2) Comparison of different mutation strategies, 3) Analysis of symbol retrieval accuracy across repository types

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- Evaluation limited to LongCodeArena benchmark, generalizability to other tasks unclear
- Neural tree search may face scalability challenges with larger codebases
- Plan quality heavily dependent on symbol retriever and mutation strategy effectiveness

## Confidence
High confidence in MutaGReP's effectiveness for reducing context window usage while maintaining LongCodeArena performance
Medium confidence in enabling smaller models to match GPT-4o's performance on this specific benchmark
Low confidence in generalizability to other code-related tasks without further validation

## Next Checks
1. Evaluate MutaGReP on additional code-related benchmarks beyond LongCodeArena to assess generalizability
2. Test scalability of MutaGReP with larger codebases and more complex planning scenarios
3. Conduct robustness analysis of symbol retriever and mutation strategies across diverse code contexts and repositories