---
ver: rpa2
title: 'PoeTone: A Framework for Constrained Generation of Structured Chinese Songci
  with LLMs'
arxiv_id: '2508.02515'
source_url: https://arxiv.org/abs/2508.02515
tags:
- songci
- generation
- chinese
- formal
- cipai
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating high-quality Songci,
  a structured Chinese classical poetry form, by leveraging large language models
  (LLMs) under strict formal constraints. The authors introduce PoeTone, a comprehensive
  evaluation framework that assesses Songci generation across multiple dimensions,
  including formal conformity, automated quality assessment, human evaluation, and
  classification-based probing.
---

# PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs

## Quick Facts
- arXiv ID: 2508.02515
- Source URL: https://arxiv.org/abs/2508.02515
- Reference count: 7
- Key outcome: Proposes PoeTone evaluation framework and Generate-Critic fine-tuning pipeline for Songci generation, achieving up to 5.88% improvement in formal conformity using rule-based feedback without human annotation.

## Executive Summary
This paper addresses the challenge of generating high-quality Songci, a structured Chinese classical poetry form, by leveraging large language models (LLMs) under strict formal constraints. The authors introduce PoeTone, a comprehensive evaluation framework that assesses Songci generation across multiple dimensions, including formal conformity, automated quality assessment, human evaluation, and classification-based probing. They benchmark 18 LLMs—3 proprietary and 15 open-source—across five prompting strategies, revealing that proprietary models like ERNIE 4.5 Turbo and GPT-4o outperform open-source models in adhering to Songci constraints. To further improve constrained generation, they propose a Generate-Critic framework that uses rule-based feedback to fine-tune three open-source LLMs, achieving up to 5.88% improvement in formal conformity. The study offers new insights into LLM capabilities for culturally significant and formally constrained literary generation.

## Method Summary
The PoeTone framework evaluates Songci generation through formal conformity scoring, automated quality assessment, human evaluation, and classification-based probing. The Generate-Critic pipeline uses Best-of-N rejection sampling: for each prompt, generate N candidates, score with a rule-based critic, select the highest-scoring sample, and construct a supervised fine-tuning dataset. LoRA-based SFT fine-tunes open-source models on curated high-quality pairs. The formal conformity scorer evaluates structure (line and character counts), tonal patterns (平/仄), and rhyme scheme compliance against 20 Cipai templates using weighted scoring (structure=0.4, tonal=0.3, rhyme=0.3).

## Key Results
- Proprietary models (ERNIE 4.5 Turbo, GPT-4o) outperform open-source models on formal conformity across all five prompting strategies
- Generate-Critic fine-tuning achieves up to 5.88% improvement in formal conformity for open-source models without human annotation
- One-shot and zero-shot prompting work best for proprietary models, while instruction and CoT prompting improve open-source model performance
- Qwen3-32B achieves the highest score (68.55%) among open-source models under one-shot prompting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Rule-based formal conformity scoring provides deterministic, reproducible evaluation for constrained generation
- Mechanism: Weighted scoring function (wS=0.4, wT=0.3, wR=0.3) computes normalized scores for structure, tonal pattern, and rhyme scheme compliance against Cipai variants
- Core assumption: Modern Mandarin pronunciation approximates classical tonal categories sufficiently for automated verification
- Evidence anchors:
  - [abstract]: "includes: (i) a formal conformity score, (ii) automated quality assessment using LLMs, (iii) human evaluation, and (iv) classification-based probing tasks"
  - [section 3, page 3]: "The score is computed automatically using a rule-checking script that evaluates each generated Songci along three dimensions"
- Break condition: If character-level tone dictionaries are incomplete or if classical vs. modern tonal drift exceeds approximation tolerance, scoring reliability degrades

### Mechanism 2
- Claim: Best-of-N rejection sampling with rule-based critic feedback improves formal conformity without human annotation
- Mechanism: Generator produces N candidates per prompt; Critic scores each; highest-scoring sample selected for supervised fine-tuning dataset
- Core assumption: Base model's distribution contains valid candidates at sufficient frequency for rejection sampling to surface them
- Evidence anchors:
  - [abstract]: "we fine-tune three lightweight open-source LLMs via supervised fine-tuning (SFT), resulting in improvements of up to 5.88% in formal conformity"
  - [section 4, page 6]: "For each prompt pi in the prompt set P, we use the base model's policy πθbase to generate N candidate Songci"
- Break condition: If N is too small or base model lacks sufficient domain knowledge, rejection sampling yields marginal gains or overfits to narrow patterns

### Mechanism 3
- Claim: Proprietary models with Chinese-optimized pretraining outperform open-source models due to better tokenizer alignment and domain exposure
- Mechanism: ERNIE 4.5 Turbo (Chinese-optimized knowledge graphs) and Qwen family (character-aware tokenization) achieve higher conformity than English-centric models
- Core assumption: Tokenizer design and pretraining corpus composition, not just scale, determine constrained generation capability
- Evidence anchors:
  - [section 3, page 4]: "English-centric tokenization may limit performance on Chinese text"
  - [section 4, page 5]: "Qwen3-32B as the strongest, achieving a best score of 68.55% under the One-shot prompt"
- Break condition: If evaluation benchmark overfits to specific Cipai patterns or if tokenization advantage doesn't generalize to unseen constraints

## Foundational Learning

- Concept: Cipai (词牌) templates define fixed metrical schemas for Songci
  - Why needed here: Understanding that each Cipai specifies line count, character count per line, tonal positions, and rhyme locations—all must be simultaneously satisfied
  - Quick check question: Given a 2-stanza Cipai with 58 total characters across specific line lengths, can you map where tonal constraints apply vs. where they're optional (zhōng)?

- Concept: Tonal categories in Chinese (平/仄) and rhyme group membership
  - Why needed here: The conformity scorer depends on mapping characters to píng (level) or zè (oblique) and to rhyme groups from classical dictionaries like Cilin Zhengyun
  - Quick check question: If two characters share the same modern Mandarin final but belong to different classical rhyme groups, will the rhyme score penalize this?

- Concept: Best-of-N rejection sampling for training data curation
  - Why needed here: The Generate-Critic pipeline uses rejection sampling to build high-quality SFT datasets without human labeling
  - Quick check question: If N=8 candidates yield scores [0.45, 0.52, 0.48, 0.51, 0.49, 0.47, 0.50, 0.53], which sample enters the training set?

## Architecture Onboarding

- Component map:
  - Cipai Metadata Store -> Conformity Scorer -> Generator (πθ) -> Critic (C) -> Best-of-N Selector -> SFT Dataset Builder -> LoRA Fine-tuner

- Critical path:
  1. Load Cipai metadata and canonical corpus
  2. Generate N candidates per (Cipai, theme) prompt using base model
  3. Score each candidate against target Cipai variant (best-fit matching)
  4. Select highest-scoring candidate per prompt
  5. Construct Dbest dataset
  6. Run LoRA SFT (rank=16, α=32, lr=5e-5, 3 epochs)

- Design tradeoffs:
  - Rule-based vs. neural critic: Deterministic, interpretable scoring vs. potential for nuanced aesthetic judgment—paper chooses rule-based for reliability
  - Best-of-N vs. RL: Simpler implementation, no reward model training vs. potential for more efficient optimization—paper uses BoN for annotation-free setup
  - Modern vs. classical tones: Practical automation vs. historical accuracy—paper acknowledges approximation limitation

- Failure signatures:
  - Zero conformity improvement: Base model distribution lacks valid samples → increase N or use stronger base model
  - High conformity, low poetic quality: Over-constraining on form degrades expression → balance conformity weight with quality metrics
  - Instruction/CoT prompt degradation: Longer reasoning context dilutes constraint adherence → verify prompt formatting doesn't truncate constraints

- First 3 experiments:
  1. Baseline conformity audit: Generate 10 samples per Cipai with zero-shot prompting across 3 model families; compute conformity breakdown (structure/tonal/rhyme) to identify weakest dimension
  2. N-value sensitivity test: Run Generate-Critic with N∈{4, 8, 16, 32} on Qwen3-8B for 5 Cipai; plot conformity gain vs. N to find saturation point
  3. Prompt strategy ablation: Compare zero-shot, one-shot, and instruction prompts on ERNIE 4.5 Turbo; validate paper's finding that proprietary models perform best with minimal guidance

## Open Questions the Paper Calls Out
None

## Limitations
- The formal conformity scoring depends on modern Mandarin pronunciation as a proxy for classical tonal categories, with no quantification of approximation error
- Evaluation covers only 20 Cipai templates, limiting generalizability to Songci's broader repertoire
- Prompt templates and theme annotations are not fully specified, limiting reproducibility across domains

## Confidence
- **High confidence**: Proprietary models demonstrate superior formal conformity due to Chinese-optimized tokenization and pretraining
- **Medium confidence**: Generate-Critic framework produces measurable improvements (up to 5.88%) in formal conformity without human annotation
- **Low confidence**: Instruction and CoT prompting universally improve open-source performance may be dataset-specific

## Next Checks
1. **Pronunciation drift validation**: Re-run the formal conformity scorer on a subset of Cipai using a reconstructed Middle Chinese pronunciation dictionary versus modern Mandarin, measuring the systematic score difference to quantify approximation error bounds

2. **N-value saturation analysis**: Execute Generate-Critic fine-tuning with N ∈ {4, 8, 16, 32, 64} on Qwen3-8B across 5 representative Cipai, plotting conformity improvement versus computational cost to identify diminishing returns and optimal trade-offs

3. **Out-of-distribution Cipai transfer**: Test the best-performing fine-tuned models on 10 Cipai templates not included in the original evaluation set (particularly single-stanza or irregular-length variants), measuring whether conformity gains generalize beyond the training distribution