---
ver: rpa2
title: Analyzing Cost-Sensitive Surrogate Losses via $\mathcal{H}$-calibration
arxiv_id: '2502.19522'
source_url: https://arxiv.org/abs/2502.19522
tags:
- loss
- cost-sensitive
- cross-entropy
- embeddings
- surrogate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes whether cost-sensitive surrogate losses or
  cost-agnostic ones (e.g., cross-entropy) should be used to train machine learning
  models for cost-sensitive classification tasks. Through the lens of H-calibration,
  the authors show that cost-sensitive surrogates can strictly outperform their cost-agnostic
  counterparts when learning small models under common distributional assumptions.
---

# Analyzing Cost-Sensitive Surrogate Losses via $\mathcal{H}$-calibration

## Quick Facts
- arXiv ID: 2502.19522
- Source URL: https://arxiv.org/abs/2502.19522
- Authors: Sanket Shah; Milind Tambe; Jessie Finocchiaro
- Reference count: 40
- Key outcome: Cost-sensitive surrogates strictly outperform cost-agnostic ones for small models under common distributional assumptions

## Executive Summary
This paper analyzes whether cost-sensitive surrogate losses or cost-agnostic ones (e.g., cross-entropy) should be used to train machine learning models for cost-sensitive classification tasks. Through the lens of H-calibration, the authors show that cost-sensitive surrogates can strictly outperform their cost-agnostic counterparts when learning small models under common distributional assumptions. The work provides both theoretical guarantees and empirical validation supporting the use of cost-sensitive surrogates in practice.

## Method Summary
The authors analyze cost-sensitive classification through the framework of H-calibration, which studies the consistency of surrogate losses with respect to the true cost-sensitive loss. They prove that cost-sensitive surrogates from the Embeddings framework are H-consistent under distributional assumptions that are common in practice, while cost-agnostic surrogates like cross-entropy with post-processing are not. The analysis leverages polyhedral structure and the Hoffman constant to establish bounds on surrogate regret. Empirically, they evaluate multiple surrogate losses on three UCI datasets, comparing cost-sensitive surrogates against cost-agnostic ones with post-processing.

## Key Results
- Cost-sensitive surrogates from the Embeddings framework are H-consistent under common distributional assumptions
- Cost-agnostic surrogates like cross-entropy combined with thresholding are not H-consistent for cost-sensitive classification
- On three UCI datasets, cost-sensitive surrogates consistently outperform cost-agnostic surrogates in terms of cost-sensitive loss
- The theoretical predictions hold empirically across different dataset characteristics and model sizes

## Why This Works (Mechanism)
The paper establishes that cost-sensitive surrogates can achieve H-consistency (proper learning) under distributional assumptions where cost-agnostic surrogates cannot. This occurs because the polyhedral structure of cost-sensitive surrogates allows for better control of the surrogate regret through the Hoffman constant, while smooth surrogates lack this property. The mechanism relies on the relationship between the surrogate's ability to be minimized over the hypothesis class and the target loss's minimizability.

## Foundational Learning

**H-calibration**: A framework for analyzing surrogate loss consistency with respect to the true loss. Needed to rigorously compare different surrogate losses beyond traditional consistency. Quick check: Can the surrogate be minimized to achieve optimal performance on the true loss?

**Embeddings framework**: A construction for building convex surrogates for discrete losses. Needed to generate cost-sensitive surrogates with desirable theoretical properties. Quick check: Does the surrogate have polyhedral structure?

**Hoffman constant**: A geometric constant that bounds the distance between a point and a polyhedron. Needed to establish quantitative bounds on surrogate regret. Quick check: Is the Hoffman constant bounded for the given hypothesis class and surrogate?

## Architecture Onboarding

**Component map**: Hypothesis class $\mathcal{H}$ -> Cost-sensitive loss $L_{cs}$ -> True loss $\ell$ -> Prediction risk $R$

**Critical path**: The theoretical guarantee follows the path: polyhedral structure -> Hoffman constant bound -> surrogate regret bound -> H-consistency

**Design tradeoffs**: Cost-sensitive surrogates require more careful construction and may have higher computational cost than cost-agnostic ones, but provide better theoretical guarantees and empirical performance for small models

**Failure signatures**: If distributional assumptions are violated (e.g., target not minimizable over $\mathcal{H}$), H-consistency may not hold. Smooth surrogates cannot achieve the same guarantees as polyhedral ones.

**3 first experiments**:
1. Verify H-consistency on synthetic data where distributional assumptions are guaranteed to hold
2. Test sensitivity to distributional violations by introducing noise that breaks minimizability assumptions
3. Compare computational complexity of polyhedral vs smooth surrogates on larger datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can $\mathcal{H}$-consistency guarantees for cost-sensitive surrogates be extended beyond the polyhedral Embeddings framework to smooth surrogate losses?
- Basis in paper: "Characterizing which cost-sensitive surrogates these results extend to, notably which smooth surrogates, remains an interesting open problem that involves extending their results leveraging polyhedral surrogate structure."
- Why unresolved: The current proofs leverage polyhedral structure (piecewise linear and convex losses), using the Hoffman constant to bound surrogate regret. Smooth losses lack this structure.
- What evidence would resolve it: A proof technique using indirect property elicitation and refinement that does not require polyhedral assumptions, or a counterexample showing smooth surrogates cannot be $\mathcal{H}$-consistent.

### Open Question 2
- Question: Why do cross-entropy-based losses outperform Embeddings on the Diabetes dataset despite theoretical predictions?
- Basis in paper: "For the diabetes dataset, all the cross-entropy-based models seem to do better than Embeddings. While it is unclear why this is the case, we hypothesize that it has to do with the smoothness of CE loss, but leave further exploration to future work."
- Why unresolved: The empirical finding contradicts theoretical expectations. The hypothesis about smoothness is untested.
- What evidence would resolve it: Controlled experiments varying loss smoothness while holding other factors constant, or analysis of the Diabetes dataset's distributional properties relative to the minimizability assumptions.

### Open Question 3
- Question: Can $\mathcal{H}$-consistency be proven for distributions $P \in Q_{\ell,\mathcal{H}} \setminus Q_{L,\mathcal{H}}$ where the target is minimizable but the surrogate is not?
- Basis in paper: "We would ideally like to show something strongerâ€”for any distribution $P \in Q_{\ell,\mathcal{H}}$, minimizing some surrogate loss $L_{cs}$ will lead to the optimal classifier $h^*$ for the target problem."
- Why unresolved: Current results require both the surrogate and target losses to be $P$-minimizable over $\mathcal{H}$.
- What evidence would resolve it: A proof showing consistency holds without surrogate minimizability, or a constructive counterexample where the target is minimizable and the surrogate is not, yet consistency fails.

## Limitations
- Focus on small models may not generalize to large-scale deep learning applications
- Theoretical assumptions about distributional properties may not hold in all practical scenarios
- Empirical validation limited to three UCI datasets, which may not be representative of modern machine learning tasks

## Confidence

**Theoretical claims about H-calibration**: High
**Empirical superiority of cost-sensitive surrogates**: Medium
**Generalizability to large models and modern datasets**: Low

## Next Checks

1. Test the proposed approach on large-scale deep learning models and modern benchmark datasets
2. Investigate performance under distributional assumptions that may be violated in practice
3. Compare against other established methods for cost-sensitive classification in real-world applications