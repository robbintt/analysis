---
ver: rpa2
title: Proxy-Anchor and EVT-Driven Continual Learning Method for Generalized Category
  Discovery
arxiv_id: '2504.08550'
source_url: https://arxiv.org/abs/2504.08550
tags:
- learning
- novel
- categories
- proxy
- continual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes CATEGORIZER, a novel method for continual
  generalized category discovery that integrates Extreme Value Theory (EVT) with proxy
  anchors to address three core challenges: novelty detection, category discovery,
  and continual learning. The method employs EVT to define probability of inclusion
  functions around proxies for unknown sample rejection, introduces a novel EVT-based
  loss function that enhances learned representations compared to deep metric learning
  methods, and uses EVT to reduce model size by discarding redundant proxies discovered
  during clustering.'
---

# Proxy-Anchor and EVT-Driven Continual Learning Method for Generalized Category Discovery

## Quick Facts
- arXiv ID: 2504.08550
- Source URL: https://arxiv.org/abs/2504.08550
- Reference count: 29
- Authors: Alireza Fathalizadeh; Roozbeh Razavi-Far
- Primary result: CATEGORIZER achieves state-of-the-art performance in continual generalized category discovery by integrating EVT with proxy anchors for novelty detection and representation enhancement

## Executive Summary
This paper proposes CATEGORIZER, a novel method for continual generalized category discovery that integrates Extreme Value Theory (EVT) with proxy anchors to address three core challenges: novelty detection, category discovery, and continual learning. The method employs EVT to define probability of inclusion functions around proxies for unknown sample rejection, introduces a novel EVT-based loss function that enhances learned representations compared to deep metric learning methods, and uses EVT to reduce model size by discarding redundant proxies discovered during clustering. To prevent catastrophic forgetting, the approach incorporates experience replay and knowledge distillation. Experiments on fine-grained datasets (birds, indoor scenes, cars, dogs) demonstrate that CATEGORIZER outperforms state-of-the-art methods across multiple metrics including clustering accuracy (Mall, Mo), forgetting (Mf), and novel category discovery (Md).

## Method Summary
CATEGORIZER operates in two stages: initial pretraining followed by continual learning. During initial pretraining, a ResNet-18 backbone is trained using Proxy Anchor loss, then EVT is applied to fit Weibull distributions around proxies using τ=500 nearest opposite-class samples. The model is fine-tuned using an EVT-based loss function that incorporates Weibull parameters. In the continual learning stage, unknown samples are detected using a probability of inclusion threshold (ϵ=0.75), clustered with Affinity Propagation, and new proxies are initialized at cluster centroids. The model is updated using a combined loss of Proxy Anchor, feature replay, and knowledge distillation for 10 epochs, followed by model reduction to remove redundant proxies.

## Key Results
- CATEGORIZER outperforms state-of-the-art methods on CUB-200, MIT67, Stanford Dogs, and Stanford Cars datasets
- EVT-based loss function improves clustering accuracy metrics (Mall, Mo) and novel category discovery (Md) compared to baseline proxy anchor approaches
- Model reduction successfully decreases estimated categories from 285→231 (CUB) and 134→81 (MIT) while maintaining performance
- The method shows particular strength in discovering new categories while maintaining performance on known classes

## Why This Works (Mechanism)

### Mechanism 1: EVT-based Probability of Inclusion for Novelty Detection
- Claim: Weibull-fitted inclusion boundaries around proxy anchors enable principled separation of known vs. unknown samples
- Mechanism: For each proxy p, the method identifies the τ nearest samples from other classes and fits a Weibull distribution to their distances. The resulting probability of inclusion function Ψ(p, z; κ, λ) = e^(-(s(p,z)/λ)^κ) provides a calibrated score for whether a sample falls within a proxy's boundary
- Core assumption: The tail distribution of inter-class distances follows a Weibull distribution; class manifolds are sufficiently compact and separable
- Break condition: When novel classes significantly overlap with known class boundaries in embedding space, or when τ is set too small/large relative to class density

### Mechanism 2: EVT-Derived Loss Function for Representation Enhancement
- Claim: The proposed evt loss improves embedding quality beyond standard proxy-anchor loss by incorporating Weibull-fitted margins directly into training
- Mechanism: After initial PA pretraining, Weibull parameters are estimated per-proxy. The evt loss then fine-tunes the model by maximizing inclusion probability for positive proxies while minimizing it for negative ones
- Core assumption: Fine-tuning on EVT-informed loss does not collapse representations; Weibull parameters remain reasonably stable during fine-tuning
- Break condition: When τ neighbors are unrepresentative of true boundary distribution (e.g., heavy class imbalance), or when fine-tuning epochs are excessive

### Mechanism 3: Greedy Set Cover for Redundant Proxy Pruning
- Claim: EVT-based proxy coverage analysis reduces over-clustering by merging redundant category estimates
- Mechanism: After clustering and proxy initialization, each proxy's Weibull distribution is tested against all other proxies. If Ψ(p_i, p_j) ≥ ζ (very high threshold near 1), p_j is considered "covered" by p_i. A greedy set cover algorithm then selects the minimum proxy subset ensuring all are covered
- Core assumption: Proxies from the same semantic category converge proximally in embedding space after initial training; over-clustering creates near-duplicate proxies
- Break condition: When ζ is set too low (aggressive merging of distinct categories) or too high (insufficient pruning); when novel categories are genuinely fine-grained

## Foundational Learning

- **Deep Metric Learning (Proxy Anchors)**: Why needed here - The method builds on proxy-anchor loss as its base representation learning objective; understanding data-to-proxy relationships is essential for interpreting evt loss modifications
  - Quick check question: Can you explain how proxy-anchor loss differs from contrastive loss in handling class-level vs. pair-level relationships?

- **Extreme Value Theory (Weibull Distribution)**: Why needed here - Core novelty - understanding why tail distributions model decision boundaries requires EVT intuition (modeling extreme deviations from class centers)
  - Quick check question: Why would extreme (tail) distances from a class proxy, rather than average distances, be appropriate for modeling unknown rejection boundaries?

- **Continual Learning (Catastrophic Forgetting)**: Why needed here - Experience replay and knowledge distillation are standard anti-forgetting mechanisms; understanding the stability-plasticity trade-off clarifies why Mo can degrade as Md improves
  - Quick check question: What is the fundamental tension between replay-based stability and new-category plasticity in the CGCD setting?

## Architecture Onboarding

- **Component map**: Feature Extractor F^t -> Proxy Set P^t -> EVT Module -> Classifier C^t -> Clustering -> Anti-Forgetting
- **Critical path**: Initial stage: PA pretrain (60 epochs) → EVT fitting → evt loss fine-tune (60 epochs) → Per time step: Novelty detection (split known/unknown) → Cluster unknown → Initialize new proxies → Joint training (PA + replay + distillation, 10 epochs) → Refit EVT → Model reduction
- **Design tradeoffs**: evt loss improves Md but may increase Mf on some datasets (Table 4: Dogs shows Mo drop with evt loss alone); model reduction improves Mo but risks merging genuinely distinct fine-grained categories if ζ mis-set; 10-epoch limit in continual stage prevents overfitting but may undertrain on harder novel categories
- **Failure signatures**: Over-clustering - Affinity propagation estimates 2×+ actual categories; mitigated by reduction but not eliminated; Feature collapse - Extended training in continual stage collapses novel class embeddings (Dogs, Cars in Figure 3); High forgetting - If replay/diplomacy underweighted, Mo drops sharply despite evt loss benefits
- **First 3 experiments**: 1) Ablate evt loss: Run initial stage with PA-only vs. PA→evt fine-tuning; measure Recall@K on held-out known classes to isolate representation quality gains; 2) Sweep τ and ϵ: Validate low-sensitivity claim (Tables 1-2) on a validation split before full runs; confirm robustness across dataset scales; 3) Stress-test model reduction: Construct a synthetic dataset with known fine-grained subclasses; verify reduction doesn't merge distinct categories at ζ=0.999

## Open Questions the Paper Calls Out

- **Open Question 1**: Can integrating the evt loss during the continual learning stage improve performance compared to using it only during initial training?
  - Basis in paper: [explicit] The conclusion states: "In future work, we plan to integrate the evt loss during the continual learning stage of the framework"
  - Why unresolved: The evt loss currently only fine-tunes the initial model; its effect during continual updates with newly discovered proxies remains untested
  - What evidence would resolve it: Experiments applying evt loss during continual learning, comparing Mall, Mo, Md, and Mf metrics against the current two-stage approach

- **Open Question 2**: Would alternative clustering algorithms reduce over-estimation of novel categories without requiring post-hoc model reduction?
  - Basis in paper: [explicit] The conclusion states: "we will investigate other clustering methods to be used in the discovery step"
  - Why unresolved: Affinity propagation causes over-clustering (e.g., estimating 285 categories vs. 200 actual on CUB), which is corrected via greedy set cover reduction - adding computational overhead
  - What evidence would resolve it: Comparative study of clustering methods (DBSCAN, spectral clustering, etc.) measuring estimated category count accuracy and downstream Md performance

- **Open Question 3**: What causes the feature collapse of newly discovered classes during extended training, and can it be prevented?
  - Basis in paper: [inferred] Figure 3 shows that "training beyond this point significantly degrade the performance on novel categories in some datasets (Dogs, Cars)," leading to an arbitrary 10-epoch limit
  - Why unresolved: The paper empirically limits epochs but does not diagnose why extended training harms novel category representations
  - What evidence would resolve it: Analysis of embedding space dynamics during training, or experiments with regularization techniques to prevent collapse

## Limitations
- EVT-based novelty detection relies on strong assumptions about Weibull tail distributions in embedding space; performance may degrade when novel categories significantly overlap with known classes or when class manifolds have irregular geometries
- The τ=500 neighbor selection for Weibull fitting and ζ=0.999 reduction threshold were not systematically validated across datasets, creating potential fragility in hyperparameter sensitivity
- Model reduction via greedy set cover lacks external validation - no comparison with alternative merging strategies or ablation studies on reduction impact

## Confidence
- **High**: The core continual learning framework (replay + distillation) is well-established; the baseline proxy-anchor pretraining results are reproducible
- **Medium**: EVT-based loss function improvements are demonstrated within the paper but lack external benchmarking against deep metric learning baselines
- **Medium**: Clustering accuracy metrics (Mo, Md, Mf) show consistent improvements, but the affinity propagation over-clustering issue remains partially unaddressed

## Next Checks
1. Conduct ablation study on EVT fine-tuning: compare 60-epoch PA→evt vs. PA-only pretraining on held-out validation sets to isolate representation quality gains
2. Systematically sweep τ (neighbor count) and ϵ (novelty threshold) on validation splits across all four datasets to confirm low-sensitivity claims
3. Construct synthetic fine-grained dataset with known subclasses to test whether greedy set cover at ζ=0.999 merges genuinely distinct categories