---
ver: rpa2
title: Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by the
  Thermodynamics of an Ideal Gas?
arxiv_id: '2511.07308'
source_url: https://arxiv.org/abs/2511.07308
tags:
- fixed
- training
- learning
- stationary
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work develops a thermodynamic framework to describe the stationary
  distributions of stochastic gradient descent (SGD) with weight decay for scale-invariant
  neural networks. It draws analogies between training hyperparameters (learning rate,
  weight decay) and thermodynamic variables (temperature, pressure, volume), and establishes
  that SGD dynamics under these settings follow ideal gas laws.
---

# Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by the Thermodynamics of an Ideal Gas?

## Quick Facts
- arXiv ID: 2511.07308
- Source URL: https://arxiv.org/abs/2511.07308
- Reference count: 40
- This work develops a thermodynamic framework to describe the stationary distributions of stochastic gradient descent (SGD) with weight decay for scale-invariant neural networks.

## Executive Summary
This work establishes a rigorous thermodynamic framework to describe the stationary distributions of stochastic gradient descent (SGD) with weight decay for scale-invariant neural networks. The authors draw formal analogies between training hyperparameters (learning rate, weight decay) and thermodynamic variables (temperature, pressure, volume), demonstrating that under scale invariance, SGD dynamics follow ideal gas laws. Using an isotropic noise model, they prove this thermodynamic analogy mathematically and validate it through simulations. When extended to practical neural network training, the framework accurately predicts changes in stationary entropy with varying hyperparameters, providing a principled foundation for interpreting neural network training dynamics.

## Method Summary
The authors develop a thermodynamic framework for SGD training by establishing analogies between hyperparameter tuning and thermodynamic principles. They prove that for scale-invariant networks, the stationary distribution of SGD with weight decay follows ideal gas laws, with learning rate corresponding to temperature, weight decay to pressure, and parameter norm to volume. Using a simplified isotropic noise model, they derive rigorous mathematical relationships and validate these through simulation. The framework is then extended to practical neural network training, where empirical results show strong alignment between predicted and observed stationary entropy changes across different hyperparameter configurations.

## Key Results
- Rigorous mathematical proof that SGD dynamics for scale-invariant networks follow ideal gas laws under isotropic noise approximation
- Empirical validation showing predicted stationary entropy changes match experimental observations across different learning rates and weight decay values
- Framework provides principled foundation for interpreting hyperparameter effects on neural network training dynamics

## Why This Works (Mechanism)
The thermodynamic analogy works because scale-invariant neural networks exhibit special properties where parameter updates maintain certain invariant relationships. Under the isotropic noise approximation, the stochastic gradient noise behaves like thermal fluctuations in a gas, while weight decay acts as an external pressure constraint. The learning rate controls the "temperature" of the system, determining the magnitude of parameter exploration. These relationships create formal mathematical mappings between training dynamics and thermodynamic variables, allowing standard thermodynamic laws to describe the evolution of the parameter distribution during training.

## Foundational Learning
- Scale invariance in neural networks: Why needed - Understanding this property is crucial as it enables the thermodynamic analogy; Quick check - Verify that network outputs remain unchanged when parameters are scaled by a constant factor
- Stationary distribution of SGD: Why needed - This represents the equilibrium state that the thermodynamic framework describes; Quick check - Confirm that the parameter distribution converges to a stable form under constant hyperparameters
- Isotropic noise approximation: Why needed - This simplification makes the mathematical derivation tractable while capturing essential SGD behavior; Quick check - Verify that gradient noise has approximately equal variance in all directions
- Ideal gas laws in thermodynamics: Why needed - These provide the mathematical foundation for relating training hyperparameters to thermodynamic variables; Quick check - Confirm that pressure × volume = constant × temperature relationship holds in the training context
- Entropy in neural network training: Why needed - Stationary entropy measures the spread of the parameter distribution and relates to generalization; Quick check - Observe that higher entropy corresponds to broader parameter exploration

## Architecture Onboarding
Component map: SGD optimizer -> Parameter updates -> Stationary distribution -> Entropy calculation
Critical path: Learning rate and weight decay settings → SGD dynamics → Parameter distribution evolution → Stationary entropy
Design tradeoffs: The isotropic noise approximation simplifies analysis but may not capture all aspects of real SGD noise structure
Failure signatures: Deviations from ideal gas behavior indicate breakdown of scale invariance assumptions or non-isotropic noise effects
First experiments: 1) Vary learning rate while keeping weight decay constant and measure entropy changes; 2) Vary weight decay while keeping learning rate constant and measure entropy changes; 3) Test framework predictions on non-scale-invariant architectures

## Open Questions the Paper Calls Out
None

## Limitations
- The thermodynamic analogy is rigorously established only for simplified isotropic noise models and specific scale-invariant architectures
- Extension to realistic neural network training relies on empirical validation rather than theoretical guarantees
- The relationship between stationary entropy and generalization performance is not explored

## Confidence
Theoretical foundation for scale-invariant networks: High
Extension to practical neural networks: Medium
Framework as principled foundation for hyperparameter tuning: Medium-Low

## Next Checks
1. Test the framework's predictions on non-scale-invariant architectures (e.g., convolutional networks, transformers) and compare with empirical training dynamics
2. Validate the framework under different optimization algorithms (e.g., Adam, SGD with momentum) and learning rate schedules
3. Investigate the relationship between predicted stationary entropy and actual generalization performance across different hyperparameter settings