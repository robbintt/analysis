---
ver: rpa2
title: 'SurrogateSHAP: Training-Free Contributor Attribution for Text-to-Image (T2I)
  Models'
arxiv_id: '2601.22276'
source_url: https://arxiv.org/abs/2601.22276
tags:
- surrogateshap
- score
- attribution
- data
- proxy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SurrogateSHAP introduces a training-free framework for attributing
  model properties to data contributors in text-to-image diffusion models. It bypasses
  the computational burden of retraining by defining a proxy game that evaluates coalition
  utility through inference from a pretrained model, and improves Shapley estimation
  efficiency by fitting a gradient-boosted tree surrogate and computing Shapley values
  analytically via TreeSHAP.
---

# SurrogateSHAP: Training-Free Contributor Attribution for Text-to-Image (T2I) Models

## Quick Facts
- arXiv ID: 2601.22276
- Source URL: https://arxiv.org/abs/2601.22276
- Reference count: 40
- SurrogateSHAP achieves up to 51% LDS for FID and 44% for aesthetic score, while being up to 23× faster than retraining

## Executive Summary
SurrogateSHAP introduces a training-free framework for attributing model properties to data contributors in text-to-image diffusion models. It bypasses the computational burden of retraining by defining a proxy game that evaluates coalition utility through inference from a pretrained model, and improves Shapley estimation efficiency by fitting a gradient-boosted tree surrogate and computing Shapley values analytically via TreeSHAP. Evaluated across three diverse tasks—CIFAR-20 (image quality), ArtBench Post-Impressionism (aesthetics), and Fashion Product (diversity)—SurrogateSHAP consistently outperforms existing methods, achieving up to 51% LDS for FID and 44% for aesthetic score, while being up to 23× faster than retraining. Counterfactual analyses confirm its accuracy in identifying influential contributors, and a clinical case study demonstrates its effectiveness in auditing biased data sources. SurrogateSHAP provides a scalable, efficient, and reliable approach to data contributor attribution, enabling fairer data marketplaces and safer AI deployment.

## Method Summary
SurrogateSHAP addresses contributor attribution for text-to-image diffusion models by defining a proxy game that evaluates coalition utility without retraining. The method defines a proxy utility function using mixture sampling from a pretrained model, where each coalition's utility is computed by generating images conditioned on contributors' prompts and aggregating their outputs. A gradient-boosted tree surrogate is trained on sampled coalition utilities, and Shapley values are computed analytically using TreeSHAP. This approach avoids expensive retraining while maintaining attribution accuracy, validated across three diverse datasets: CIFAR-20 for image quality, ArtBench Post-Impressionism for aesthetics, and Fashion Product for diversity.

## Key Results
- SurrogateSHAP achieves up to 51% LDS for FID and 44% for aesthetic score compared to baseline methods
- Runtime improvements of up to 23× faster than traditional retraining-based attribution
- Counterfactual analyses confirm accurate identification of influential contributors across all three datasets
- Clinical case study demonstrates effectiveness in auditing biased data sources

## Why This Works (Mechanism)
SurrogateSHAP works by replacing expensive retraining with a proxy game that approximates coalition utilities through conditional generation from a pretrained model. The key insight is that the marginal contribution of a contributor can be evaluated by mixing their conditional distributions with others, without needing to retrain the model. By fitting a surrogate model to coalition utilities and computing Shapley values analytically, the method achieves both efficiency and accuracy. The proxy game's fidelity is validated through representation drift checks and counterfactual analyses.

## Foundational Learning

**Shapley Values** - Measure marginal contribution of each player in cooperative games. Needed to quantify individual contributor influence. Quick check: Verify additivity and symmetry properties hold for your coalition utilities.

**TreeSHAP** - Efficient algorithm for computing exact Shapley values on tree-based models. Needed for scalable attribution computation. Quick check: Ensure your surrogate model is a valid tree ensemble before applying TreeSHAP.

**Conditional Generation** - Generating images conditioned on specific prompt tokens. Needed to implement the proxy mixture sampling. Quick check: Verify conditional generation preserves contributor style without catastrophic forgetting.

**Proxy Game Theory** - Using proxy utilities to approximate true game values. Needed to avoid expensive retraining. Quick check: Measure representation drift between proxy and target distributions.

**Gradient Boosted Trees** - Ensemble method for fitting surrogate models. Needed for accurate utility approximation. Quick check: Monitor MSE on held-out coalitions during surrogate training.

## Architecture Onboarding

**Component Map:** Pretrained Model -> Proxy Game -> Coalition Sampling -> XGBoost Surrogate -> TreeSHAP -> Shapley Values

**Critical Path:** Coalition utility computation → XGBoost surrogate fitting → TreeSHAP attribution

**Design Tradeoffs:** Efficiency vs. proxy fidelity - SurrogateSHAP trades some accuracy for 23× speedup, but maintains sufficient fidelity for practical attribution.

**Failure Signatures:** Large proxy-retraining gap (>10% LDS difference), unstable Shapley values across random seeds, surrogate underfitting (high held-out MSE).

**First Experiments:** 1) Validate proxy game fidelity on small CIFAR-20 subset, 2) Test XGBoost surrogate fitting on synthetic coalition utilities, 3) Compare TreeSHAP vs. sampling-based Shapley on simple tree ensembles.

## Open Questions the Paper Calls Out

**Open Question 1:** How does the proxy game's fidelity degrade when the utility functional (e.g., FID) violates the global Lipschitz continuity assumption required for the theoretical error bound?

**Open Question 2:** Can SurrogateSHAP be adapted to attribute influence to data contributors when their data cannot be identified via explicit prompt metadata?

**Open Question 3:** How does the approximation gap change when the "retraining" process involves substantial unlearning or catastrophic forgetting?

**Open Question 4:** Does the use of LoRA fine-tuning as a ground-truth proxy for "retraining" in large-scale models skew the evaluation of attribution accuracy compared to full parameter retraining?

## Limitations
- Proxy game fidelity depends on pretrained model's ability to preserve contributor styles without domain shift
- Aesthetic predictor is treated as a black box with no assessment of robustness or biases
- Three datasets, while diverse, are limited in scale and domain coverage
- Clinical case study presented as proof of concept without independent validation

## Confidence
High: Core computational claims (LDS gains, runtime reduction, Shapley attribution correctness via TreeSHAP)
Medium: Proxy game's fidelity to full retraining and clinical audit conclusions
Low: Aesthetic predictor's reliability and robustness

## Next Checks
1. Perform ablation studies on coalition sampling size M and Shapley kernel parameters to quantify impact on attribution stability and runtime
2. Systematically evaluate the proxy game's accuracy across coalition sizes by comparing proxy-retraining gaps on held-out contributor subsets
3. Independently audit the aesthetic predictor's outputs on the ArtBench dataset to assess robustness and potential confounding factors