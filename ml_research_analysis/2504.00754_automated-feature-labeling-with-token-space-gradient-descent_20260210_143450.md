---
ver: rpa2
title: Automated Feature Labeling with Token-Space Gradient Descent
arxiv_id: '2504.00754'
source_url: https://arxiv.org/abs/2504.00754
tags:
- feature
- tokens
- text
- label
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a gradient descent-based approach to feature
  labeling in mechanistic interpretability. Instead of using language models to generate
  hypotheses about feature meanings, the method directly optimizes label representations
  in token-space by treating a language model as a binary classifier that predicts
  feature activations.
---

# Automated Feature Labeling with Token-Space Gradient Descent

## Quick Facts
- arXiv ID: 2504.00754
- Source URL: https://arxiv.org/abs/2504.00754
- Reference count: 8
- Primary result: Gradient descent-based approach successfully converges to interpretable single-token labels for synthetic features across diverse domains

## Executive Summary
This paper introduces a novel gradient descent-based approach to feature labeling in mechanistic interpretability, addressing the challenge of automatically discovering human-interpretable labels for features extracted by Sparse Autoencoders. Instead of relying on language models to generate hypotheses about feature meanings, the method directly optimizes label representations in token-space by treating a language model as a binary classifier that predicts feature activations. The approach formulates label discovery as a multi-objective optimization problem balancing prediction accuracy, entropy minimization, and linguistic naturalness. Experiments on synthetic features demonstrate successful convergence to interpretable single-token labels including "animal," "mamm," "中文" (Chinese), and "number" after 300-500 training steps.

## Method Summary
The method optimizes a learnable logit vector v (dimension d_vocab) initialized as a model parameter, converting it to a probability distribution p via softmax. This probability distribution is projected into embedding space via e = Ep (weighted sum of all token embeddings using the model's embedding matrix E), creating a "superposition" of tokens during optimization. A frozen language model (Llama-3-8B-Instruct) acts as a binary classifier, receiving structured prompts with text-token pairs and the current label embedding. The model outputs a probability that the token matches the concept, compared against ground-truth feature activations via binary cross-entropy loss. Entropy loss pushes the distribution toward single-token concentration, while KL-divergence loss encourages linguistic naturalness by penalizing unlikely tokens. The entire pipeline is differentiable, allowing gradients to flow back through the LLM to update the label logits.

## Key Results
- Successfully converged to interpretable single-token labels for synthetic features across diverse domains
- Identified tokens like "animal," "mamm," "中文" (Chinese), and "number" after 300-500 training steps
- Demonstrated effectiveness on features including animal detection, mammal classification, Chinese text identification, and number recognition
- Showed sensitivity to hyperparameter tuning and data balance requirements

## Why This Works (Mechanism)

### Mechanism 1: Token-Space Superposition Optimization
Optimizing a probability distribution over tokens enables gradient-based search through discrete label space by creating a weighted superposition of all token embeddings during optimization. The softmax/entropy regularization then pushes this diffuse distribution toward concentration on a single token, with gradients flowing back from classification loss through the embedding matrix.

### Mechanism 2: Binary Classification as Differentiable Evaluation
Framing label evaluation as a binary classification task (Does this token match the concept?) creates a differentiable proxy for human interpretability. The language model's probability output is compared against ground-truth feature activations via binary cross-entropy, with gradients flowing back to update the label probability distribution.

### Mechanism 3: Multi-Objective Regularization
Entropy minimization forces convergence to single tokens while KL-divergence regularization encourages linguistic naturalness by penalizing unlikely tokens. This combination balances the competing objectives of accurate prediction, single-token concentration, and use of common, meaningful tokens.

## Foundational Learning

**Concept: Sparse Autoencoders (SAEs) & Feature Extraction**
- Why needed: This method labels features discovered by SAEs, which decompose model activations into interpretable "features" with binary activations per token
- Quick check: Can you explain what an SAE is and what kind of output it produces for a given text sequence?

**Concept: Gradient Descent in Input/Embedding Space**
- Why needed: The core technique optimizes input representations, not model weights; understanding gradient flow through frozen models is essential
- Quick check: If you freeze all model weights and compute loss based on output logits, how would you update an input embedding vector to minimize that loss?

**Concept: Discrete vs. Continuous Optimization**
- Why needed: The method bridges discrete token selection and continuous optimization; understanding why gradients can't flow through one-hot token indices clarifies the superposition approach
- Quick check: Why is standard gradient descent not directly applicable to selecting a single token from a vocabulary, and what is a common relaxation technique to make it differentiable?

## Architecture Onboarding

**Component map:** Data Loader -> Label Parameters -> Label Embedder -> Frozen LLM -> Binary Classifier -> Multi-Objective Loss

**Critical path:** Data Batch -> Prompt Construction with current Label Embedding -> Frozen LLM Forward Pass -> Extract "0"/"1" Logits -> Compute L_acc -> Compute L_ent and L_kl on label probabilities -> Backprop to Label Parameters

**Design tradeoffs:** Single-token constraint limits expressiveness but simplifies optimization; frozen evaluator removes training needs but limits labeling to concepts the model can classify; token-space optimization constrains solutions to valid tokens but may limit representational space

**Failure signatures:** Convergence to superposition (λ_ent too low); convergence to nonsensical tokens (λ_kl too low); convergence to broader categories (insufficient negative examples); stagnation (evaluator model cannot classify feature)

**First 3 experiments:** 1) Reproduce synthetic feature result with animal text dataset; 2) Ablate loss terms to quantify regularization contributions; 3) Test data balance impact on mammal feature convergence

## Open Questions the Paper Calls Out

**Open Question 1:** Can the approach generalize to optimize multi-token labels? The paper notes many feature descriptions cannot be captured by single tokens and suggests generalizing to optimize multiple token positions simultaneously.

**Open Question 2:** Does a universal hyperparameter set exist that works across diverse feature types without case-by-case tuning? The paper did not perform systematic hyperparameter searches to identify broadly applicable settings.

**Open Question 3:** How does the method perform on real SAE features compared to synthetic features? The paper only tested synthetic features with binary activations, noting real SAE activations take continuous values.

**Open Question 4:** Does gradient-based labeling provide robustness advantages over LLM-based labeling for safety-critical interpretability? The paper speculates this approach could be more robust to misaligned LLMs but provides no experimental validation.

## Limitations

- Gradient computation through LLM lacks implementation details, making faithful reproduction challenging
- Method fundamentally constrained by evaluator model's capabilities, failing on features beyond model competence
- Requires careful hyperparameter tuning that may not generalize across feature types
- Single-token constraint limits expressiveness for complex concepts requiring multi-word descriptions

## Confidence

**High Confidence:** Core conceptual framework and mechanism explanations are clearly articulated and supported by experimental results on synthetic features.

**Medium Confidence:** Experimental results demonstrating successful convergence, though lacking ablation studies and systematic failure case analysis.

**Low Confidence:** Gradient computation implementation details and specific optimizer/training loop configuration are omitted.

## Next Checks

1. **Gradient Flow Verification:** Implement minimal pipeline with small transparent model to verify gradients actually flow from binary classification loss back through embedding layer to update label logits.

2. **Loss Term Ablation Study:** Systematically remove entropy and KL-divergence terms while keeping accuracy loss constant on simple synthetic feature to quantify each regularizer's contribution.

3. **Data Balance Impact Test:** Reproduce mammal feature experiment with three conditions (imbalanced, balanced with negatives, extremely unbalanced) to validate sampling strategy's critical importance.