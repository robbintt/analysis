---
ver: rpa2
title: Evolving Interpretable Constitutions for Multi-Agent Coordination
arxiv_id: '2602.00755'
source_url: https://arxiv.org/abs/2602.00755
tags:
- agents
- agent
- social
- constitution
- multi-agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of aligning AI agents in multi-agent
  settings, where traditional Constitutional AI approaches based on static principles
  may fail due to emergent social dynamics. The authors propose Constitutional Evolution,
  a framework that uses LLM-guided evolutionary search to automatically discover effective
  behavioral norms without updating model weights.
---

# Evolving Interpretable Constitutions for Multi-Agent Coordination

## Quick Facts
- arXiv ID: 2602.00755
- Source URL: https://arxiv.org/abs/2602.00755
- Authors: Ujwal Kumar; Alice Saito; Hershraj Niranjani; Rayan Yessou; Phan Xuan Tan
- Reference count: 40
- One-line primary result: Evolved constitutions significantly outperform human-designed and LLM-generated baselines by discovering implicit coordination norms that eliminate conflict while minimizing communication.

## Executive Summary
This paper introduces Constitutional Evolution, a framework for automatically discovering effective behavioral norms for multi-agent coordination using LLM-guided evolutionary search. The method treats constitutions as optimizable objects and searches for rule sets that maximize societal stability in a competitive grid-world simulation. The evolved constitution C* achieves a Societal Stability Score of 0.556±0.008, representing a 123% improvement over human-designed baselines and 67% over one-shot LLM-generated constitutions. Notably, C* discovers that implicit coordination through consistent behavior outperforms explicit messaging, reducing communication by 98.6% while eliminating conflict entirely.

## Method Summary
The framework evolves constitutions using a multi-island evolutionary search with LLM-based mutation. Six LLM agents operate in a 6×6 grid-world with competitive elimination pressure, where the lowest contributor is removed every 10 turns. Constitutions are treated as priority-ordered operational rules rather than abstract principles. The search uses three parallel populations that evolve independently and periodically migrate their top performers. Each candidate constitution is evaluated through K=2 simulation runs to compute a Societal Stability Score, and the best constitution is validated with N=10 runs. The LLM mutation operator (using GPT-OSS-120B at temperature 1.0) proposes rule modifications based on behavioral logs and performance feedback.

## Key Results
- Evolved constitution C* achieves Societal Stability Score of 0.556±0.008, 123% improvement over HHH baseline and 67% over LLM-Generated
- C* eliminates conflict entirely while reducing communication to 0.9% of social actions (vs 62.2% for HHH)
- Implicit coordination through consistent behavior outperforms explicit messaging in competitive multi-agent settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Priority-ordered operational rules outperform abstract principles by reducing decision ambiguity.
- Mechanism: Concrete rules (e.g., "Deposit First") map directly to executable actions, eliminating the need for agents to infer contextually-appropriate behavior. Strict priority ordering resolves conflicts deterministically—when carrying resources, Rule 1 takes precedence over movement or communication.
- Core assumption: LLM agents follow explicit priority ordering when multiple rules apply; rule interpretability is consistent across runs.
- Evidence anchors:
  - [abstract]: "evolved constitution C* achieves S = 0.556±0.008... eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination"
  - [Section 5.2]: "HHH's 'Be Helpful' requires agents to infer what helpfulness means in context, leading to inconsistent interpretations and high variance (σ = 0.05). C*'s 'Deposit First' maps directly to an executable action, reducing variance to σ = 0.01."
  - [corpus]: C3AI paper addresses constitution crafting but does not establish operational specificity as a causal mechanism; corpus evidence is weak here.
- Break condition: If agents fail to follow priority ordering (e.g., temperature too high), or if rules become too specific to generalize across states, variance increases and performance degrades.

### Mechanism 2
- Claim: Implicit coordination through consistent behavior replaces explicit communication.
- Mechanism: When all agents share identical behavioral rules, their actions become predictable to teammates. An agent observing a teammate carrying wood can infer they will deposit immediately without needing a broadcast. This eliminates the "communication trap" where agents waste turns on low-value messaging.
- Core assumption: Shared constitutions produce sufficiently deterministic behavior that agents can model teammates' future actions.
- Evidence anchors:
  - [abstract]: "discover[ed] that implicit coordination through consistent behavior outperforms explicit messaging"
  - [Section 5.1]: "When all agents follow the same priority-ordered rules, their actions become predictable to teammates. An agent observing a teammate carrying wood can infer they will deposit immediately (Rule 1), without explicit communication."
  - [corpus]: "The Role of Social Learning and Collective Norm Formation" (FMR=0.54) studies norm emergence but does not isolate implicit vs. explicit coordination as a mechanism.
- Break condition: If environmental stochasticity or partial observability prevents agents from inferring teammate states, implicit coordination fails and communication becomes necessary.

### Mechanism 3
- Claim: Multi-island evolutionary search escapes local optima through parallel exploration and periodic migration.
- Mechanism: Three independent populations evolve in parallel, exploring different constitutional strategies. Every 5 iterations, the top 20% migrate between islands, propagating successful innovations while maintaining diversity. Single-island runs can converge to suboptimal "communication traps."
- Core assumption: Effective constitutional rules are compositional—partial solutions from different islands can combine into better wholes.
- Evidence anchors:
  - [Section 3.3.2]: "Three independent populations evolve in parallel... every 5 iterations, the top 20% of each population migrates to neighboring islands"
  - [Table 19]: Single-island Run 3 achieved only S=0.255 (stuck in communication trap), while multi-island Run 4 achieved S=0.577
  - [corpus]: No direct corpus evidence for multi-island architecture in constitutional evolution; this appears novel.
- Break condition: If migration rate is too high (e.g., 50%), populations converge prematurely; if too low, islands cannot share innovations.

## Foundational Learning

- **Constitutional AI (CAI)**:
  - Why needed here: The paper extends CAI from single-agent to multi-agent settings; understanding the baseline helps grasp why static principles fail under emergent social dynamics.
  - Quick check question: Can you explain why "be helpful" provides insufficient guidance when agents face trade-offs between self-preservation and collective welfare?

- **Genetic Programming / Evolutionary Search**:
  - Why needed here: The core method treats constitutions as evolvable programs; understanding mutation, selection, and fitness landscapes is essential.
  - Quick check question: What is the role of the fitness function in guiding which constitutional rules survive?

- **Multi-Agent Social Dilemmas**:
  - Why needed here: The Overseer mechanic creates a relative fitness landscape where harming competitors is strategically rational; this parallels sequential social dilemmas in MARL.
  - Quick check question: Why does the elimination mechanic create pressure for both within-team competition and cross-team coordination?

## Architecture Onboarding

- **Component map**:
  OpenEvolve -> LLM-based mutation operator
  Multi-Agent Simulation -> 6×6 grid-world with 6 agents, 40 turns, resource gathering, and Overseer elimination
  Stability Score Function -> S = max(0, 0.5×P + 0.3×V − 0.2×C) aggregating productivity, survival, and conflict
  MAP-Elites Archive -> 8×8 grid indexed by rule complexity and stability score for diversity maintenance

- **Critical path**:
  1. Initialize C₀ (baseline constitution)
  2. Run K=2 simulations per candidate → compute Ŝ
  3. LLM proposes mutations based on behavioral logs and score feedback
  4. Selection: 30% elite, 60% exploitation, 10% exploration
  5. Migration every 5 iterations (if multi-island)
  6. Return C* with highest validation score (N=10 runs)

- **Design tradeoffs**:
  - K=2 during evolution vs. K=10 for validation (speed vs. statistical robustness)
  - Temperature 1.0 maintains exploration but increases variance; lower temperatures cause stagnation
  - Simplified 6×6 grid enables controlled analysis but limits generalization claims

- **Failure signatures**:
  - Communication trap: social actions >50%, productivity <30% (agents talk instead of act)
  - Hoarding: agents gather but delay depositing, reducing contribution scores
  - Premature convergence: all islands converge to similar suboptimal constitutions (migration rate too high)

- **First 3 experiments**:
  1. Reproduce HHH baseline vs. C* comparison on 10 runs each; verify S = 0.249±0.05 vs. 0.556±0.008
  2. Ablate single-island vs. multi-island: run 3 seeds each and confirm multi-island variance reduction
  3. Test rule ablation: remove "Deposit First" from C* and measure productivity drop; estimate mechanism contribution

## Open Questions the Paper Calls Out
None

## Limitations
- Core results based on single grid-world simulation, limiting generalizability to richer environments
- Reliance on hypothetical GPT-OSS-120B model introduces uncertainty about performance with available open models
- Does not address how evolved constitutions transfer across different agent architectures or scales

## Confidence
- **High confidence**: Evolved constitutions significantly outperform human-designed and one-shot LLM baselines on the defined stability metric (123% improvement over HHH, 67% over LLM-Generated); the elimination of conflict and drastic reduction in communication (98.6%) are well-supported by simulation data.
- **Medium confidence**: The proposed mechanisms (priority ordering, implicit coordination, multi-island search) explain the results within the studied environment, but their necessity and sufficiency for broader multi-agent coordination remain untested.
- **Low confidence**: Claims of discovering "fundamental cooperative norms" or that the method generalizes to real-world multi-agent systems are speculative; the experimental scope is narrow and the transferability of evolved constitutions is unproven.

## Next Checks
1. **Ablation of constitutional mechanisms**: Remove the "Deposit First" rule from C* and measure the drop in productivity and stability score. Run 10 independent trials to estimate the specific contribution of priority ordering to overall performance.

2. **Generalization to heterogeneous agent populations**: Apply the best evolved constitution C* to a new simulation where agent teams have asymmetric goals or capabilities. Run 10 trials and compare stability scores to both HHH and LLM-Generated baselines in this new setting.

3. **Scalability test**: Scale the simulation to larger grids (e.g., 10×10) and more agents (e.g., 12 agents, 4 teams) while maintaining the same elimination mechanic. Use the same constitution C* and baselines; run 10 trials each. Measure whether evolved constitutions still outperform baselines as coordination complexity increases.