---
ver: rpa2
title: 'Flow Matching Meets Biology and Life Science: A Survey'
arxiv_id: '2507.17731'
source_url: https://arxiv.org/abs/2507.17731
tags:
- flow
- matching
- generation
- generative
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey presents the first comprehensive review of flow matching
  (FM) in biology and life sciences. FM offers a continuous probability flow framework
  for generative modeling, avoiding stochastic diffusion steps.
---

# Flow Matching Meets Biology and Life Science: A Survey

## Quick Facts
- arXiv ID: 2507.17731
- Source URL: https://arxiv.org/abs/2507.17731
- Reference count: 40
- First comprehensive review of flow matching applications in biology and life sciences

## Executive Summary
This survey presents the first comprehensive review of flow matching (FM) applications in biology and life sciences. FM offers a continuous probability flow framework for generative modeling, avoiding the stochastic diffusion steps of traditional diffusion models. The paper systematically categorizes FM applications across biological sequence modeling, molecule generation and design, and protein generation, highlighting the method's advantages in efficiency, geometric awareness, and conditioning capabilities for biological data generation tasks.

The survey identifies key methodological variants including conditional FM for guided generation, rectified FM for straighter probability paths, and non-Euclidean FM for curved manifolds. It covers applications spanning DNA/RNA sequence generation, 3D molecule generation with SE(3)-equivariant models, protein backbone generation and co-design, bio-image generation, spatial transcriptomics, and neural activity modeling. The authors also discuss future directions including discrete sequence generation, small molecule design with physical priors, and protein dynamics modeling.

## Method Summary
Flow matching provides a continuous probability flow framework that avoids stochastic diffusion steps used in traditional diffusion models. Instead of gradually adding noise and learning denoising steps, FM learns a deterministic path from a simple base distribution to the target data distribution. The method uses ordinary differential equations (ODEs) to define the probability flow, enabling efficient training and sampling. Key variants include conditional FM for guided generation, rectified FM for straighter probability paths, and non-Euclidean FM for curved manifolds. These approaches leverage the continuous nature of probability flows to handle geometric structures in biological data while maintaining computational efficiency compared to diffusion models.

## Key Results
- FM methods enable efficient DNA and RNA generation through approaches like Fisher Flow and Dirichlet Flow
- SE(3)-equivariant and optimal transport-based FM models improve 3D molecule generation efficiency and validity
- Protein generation benefits from FM through backbone generation, co-design, and docking prediction capabilities
- FM's continuous, geometry-aware, and conditioning capabilities make it promising for diverse biological applications including bio-image generation and spatial transcriptomics

## Why This Works (Mechanism)
Flow matching works by learning deterministic probability flows instead of stochastic denoising processes. The continuous nature of the flow allows for more efficient training and sampling compared to diffusion models, which require many iterative denoising steps. By using ODEs to define the probability transformation, FM can incorporate geometric priors and handle complex manifold structures inherent in biological data. The conditioning capabilities enable guided generation for specific biological tasks, while the absence of stochasticity during sampling provides deterministic outputs with reduced variance.

## Foundational Learning

**Ordinary Differential Equations (ODEs)** - Mathematical framework for defining continuous probability flows; needed to understand how FM transforms distributions continuously; quick check: verify ODE solvers work correctly for simple probability transformations

**Probability Flow Theory** - Formal framework for continuous data generation; needed to understand the mathematical foundation of FM; quick check: confirm probability conservation along the flow paths

**Geometric Deep Learning** - Methods for handling non-Euclidean data structures; needed for FM applications on molecular and protein structures; quick check: validate equivariance properties on rotated/mirrored structures

**Conditional Generation** - Framework for guided data synthesis; needed for task-specific biological applications; quick check: test conditioning stability across different prompts

**Optimal Transport** - Mathematical framework for measuring distribution distances; needed for understanding FM objectives; quick check: verify transport cost minimization during training

## Architecture Onboarding

Component map: Base distribution -> ODE Solver -> Probability Flow Network -> Target distribution

Critical path: Training involves minimizing flow matching objectives through ODE-based likelihood estimation, while sampling uses the learned flow to transform base samples to target data

Design tradeoffs: FM offers faster sampling than diffusion models but requires careful ODE solver configuration; geometric variants add computational overhead but enable better handling of molecular structures

Failure signatures: Training instability from stiff ODEs, poor conditioning leading to mode collapse, geometric incompatibility causing invalid molecular structures

First experiments:
1. Train a basic FM model on simple synthetic distributions to verify ODE solver integration
2. Compare sampling speed and quality between FM and diffusion models on small molecule datasets
3. Test conditional FM on protein sequence generation with known structural constraints

## Open Questions the Paper Calls Out
None

## Limitations
- Claims of being "first comprehensive review" lack validation through systematic literature review methodology
- Several emerging applications like spatial transcriptomics have limited methodological detail and few concrete examples
- Assessment of FM advantages over competing models relies on comparisons with relatively recent alternatives without temporal benchmarking

## Confidence

High confidence in: The categorization of FM applications into biological sequence modeling, molecule generation, and protein generation; The identification of key methodological variants (conditional FM, rectified FM, non-Euclidean FM); The characterization of FM's continuous probability flow framework advantages

Medium confidence in: The completeness of the dataset coverage across all biological applications; The comparative assessment of FM versus diffusion models in biological contexts

Low confidence in: The depth of technical implementation details for emerging applications like spatial transcriptomics; The long-term trajectory predictions for FM in life sciences

## Next Checks

1. Conduct a systematic citation analysis to verify the claim of being the first comprehensive survey and identify any potentially overlooked foundational papers

2. Implement and benchmark at least one FM method from each application category (biological sequences, molecules, proteins) against state-of-the-art diffusion models using standardized biological benchmarks

3. Survey practitioners in computational biology to assess practical adoption barriers and real-world performance differences between FM and alternative generative approaches