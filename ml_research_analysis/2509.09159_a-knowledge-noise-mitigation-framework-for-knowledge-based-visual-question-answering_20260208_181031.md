---
ver: rpa2
title: A Knowledge Noise Mitigation Framework for Knowledge-based Visual Question
  Answering
arxiv_id: '2509.09159'
source_url: https://arxiv.org/abs/2509.09159
tags:
- knowledge
- question
- llms
- visual
- answering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces KF-VQA, a training-free framework that addresses
  knowledge redundancy and noise in knowledge-based visual question answering (KB-VQA).
  The method improves knowledge retrieval by constructing low-noise queries from essential
  image-question content, uses VLMs and LLMs to filter redundant segments from retrieved
  knowledge, and employs selective knowledge integration based on model confidence.
---

# A Knowledge Noise Mitigation Framework for Knowledge-based Visual Question Answering

## Quick Facts
- arXiv ID: 2509.09159
- Source URL: https://arxiv.org/abs/2509.09159
- Reference count: 23
- State-of-the-art performance: 63.2% on OK-VQA, 60.9% on A-OKVQA

## Executive Summary
This paper introduces KF-VQA, a training-free framework that addresses knowledge redundancy and noise in knowledge-based visual question answering (KB-VQA). The method improves knowledge retrieval by constructing low-noise queries from essential image-question content, uses VLMs and LLMs to filter redundant segments from retrieved knowledge, and employs selective knowledge integration based on model confidence. KF-VQA achieves state-of-the-art performance on OK-VQA (63.2%) and A-OKVQA (60.9%) datasets, outperforming both training-based and training-free baselines. The framework demonstrates that reducing knowledge noise through selective integration and fine-grained filtering significantly improves KB-VQA accuracy without requiring model training.

## Method Summary
KF-VQA operates through a three-stage pipeline: First, a frozen VLM extracts keywords from the image-question pair to create a low-noise query that enhances retrieval relevance. Second, retrieved knowledge documents are processed through a two-step filtering mechanism where the LLM identifies relevant segments based on visual details extracted by the VLM. Third, the model integrates external knowledge only when its confidence in the answer falls below a threshold, reducing the negative impact of residual noise. The framework uses Llama3.2-11B-Vision for visual processing, Llama3-8B for reasoning, and Contriever for knowledge retrieval, achieving state-of-the-art results without any training on the target datasets.

## Key Results
- KF-VQA achieves 63.2% accuracy on OK-VQA, outperforming training-based SKSQA (62.2%) and training-free RELIC (57.1%)
- KF-VQA achieves 60.9% accuracy on A-OKVQA, surpassing SKSQA (60.7%) and RELIC (55.5%)
- Each component contributes to performance: LNQ improves from 61.5% to 62.4%, and SKI provides additional gains over KRF alone

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Concise queries containing only essential content from image-question pairs improve knowledge retrieval relevance compared to verbose queries.
- **Mechanism:** A frozen VLM extracts keywords summarizing the image-question pair. These keywords are concatenated with the original question to form a low-noise query (Equation 1: k = VLM(P1, v, q), then ql = [q; k]). This focused query guides the retriever toward documents containing answer-critical information rather than tangentially related content.
- **Core assumption:** VLMs can reliably identify which visual and textual elements are essential for knowledge retrieval, and keyword-based queries map more directly to relevant documents than descriptive captions.
- **Evidence anchors:**
  - [abstract]: "creating low-noise queries that enhance the retrieval of highly relevant knowledge"
  - [section]: Page 2, Section III.A describes the keyword extraction process and retrieval scoring
  - [corpus]: Paper 77863 discusses retrieval quality challenges in KB-VQA; Paper 80203 addresses question-focused filtering for knowledge retrieval
- **Break condition:** If VLM keyword extraction omits critical visual attributes or includes irrelevant terms, retrieval quality degrades. The paper does not analyze keyword extraction error rates or failure modes.

### Mechanism 2
- **Claim:** Fine-grained filtering of retrieved knowledge documents using visual details reduces noise and improves answer quality.
- **Mechanism:** The LLM transforms the original question into a visual perception question (Equation 3: qv = LLM(P2, q)). The VLM answers this visual question to extract fine-grained image details (Equation 4: av = VLM(v, qv)). The LLM then identifies relevant segments from retrieved documents based on the question and visual details (Equation 5: Ks = LLM(P3, Kd, q, av)).
- **Core assumption:** Visual details extracted by VLMs, when combined with LLM reasoning, can identify which segments of retrieved documents are answer-beneficial. This assumes the two-stage decomposition (visual extraction → segment selection) is more effective than direct document filtering.
- **Evidence anchors:**
  - [abstract]: "prompt large models to identify and extract answer-beneficial segments from knowledge"
  - [section]: Page 3, Section III.B and ablation study (Table III) show filtering improves accuracy from 61.5% to 62.4%
  - [corpus]: Paper 77863 explicitly addresses "Multimodal Processing, Retrieval and Filtering" in KB-VQA
- **Break condition:** If the visual perception question transformation fails to capture question-relevant visual attributes, or if the LLM cannot reliably identify beneficial segments, noise persists. The paper does not quantify filtering precision/recall.

### Mechanism 3
- **Claim:** Incorporating external knowledge only when the model lacks confidence in its answer reduces negative effects of residual noise.
- **Mechanism:** The LLM first attempts to answer using implicit knowledge. Confidence is computed from the aggregated log probabilities of the output sequence (Equation 6: s = e^f(y)). If confidence falls below threshold τ, filtered knowledge segments are integrated for a second reasoning pass (Equation 7). This mimics human intuition: seek help only when uncertain.
- **Core assumption:** Confidence scores derived from output probabilities accurately reflect when the model's implicit knowledge is insufficient or unreliable. This assumes probability calibration correlates with answer correctness.
- **Evidence anchors:**
  - [abstract]: "selective knowledge integration based on model confidence"
  - [section]: Page 3, Section III.C and hyperparameter analysis (Figure 3c) show optimal threshold τ = 0.8
  - [corpus]: Limited direct coverage; related work focuses on retrieval/filtering rather than confidence-based selective integration
- **Break condition:** If confidence scores are poorly calibrated (high confidence in wrong answers, low confidence in correct ones), selective integration may withhold helpful knowledge or introduce noise at wrong times. The paper does not analyze calibration quality.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** KF-VQA is fundamentally a RAG architecture applied to multimodal QA. Understanding how retrieval quality affects generation is essential.
  - **Quick check question:** Given a user query, how would you determine if retrieved documents are helping or hurting answer quality?

- **Concept: Confidence Calibration in LLMs**
  - **Why needed here:** The selective integration strategy depends on model confidence being a reliable signal for knowledge need.
  - **Quick check question:** If an LLM assigns 90% probability to an incorrect answer, what does this tell you about using confidence for decision-making?

- **Concept: Multimodal Representation Alignment**
  - **Why needed here:** The framework relies on VLMs extracting visual details that align with the LLM's reasoning needs across modalities.
  - **Quick check question:** When a VLM describes an image as "a red sports car" but the question asks about "manufacturing year," where is the representation gap?

## Architecture Onboarding

- **Component map:**
  ```
  Image-Question Pair → Frozen VLM → Keywords (k) + Visual Details (av) → Low-noise Query → ql = [question; keywords] → Retriever (Contriever) → Retrieved Documents → Frozen LLM (Filter) → Filtered Segments (Ks) → Confidence Check → If s ≤ τ: integrate Ks → Frozen LLM (Reasoning) → Final Answer
  ```

- **Critical path:** Image-question → VLM keyword extraction → Query construction → Retrieval → VLM visual detail extraction → LLM segment filtering → Confidence check → Conditional knowledge integration → Answer

- **Design tradeoffs:**
  - **Keyword extraction vs. full captions:** Keywords reduce noise but may omit critical context. The paper does not compare against caption-based retrieval.
  - **Fixed threshold τ = 0.8 vs. adaptive thresholds:** Simpler but may not generalize across question types or domains.
  - **Training-free vs. trainable filters:** No fine-tuning cost but cannot adapt to specific knowledge base characteristics.

- **Failure signatures:**
  - **Low retrieval relevance:** Retrieved documents contain little answer-relevant information → ablation shows this hurts more than no knowledge (Baseline 60.4% < LLM-only 61.3%)
  - **Over-filtering:** Setting h (segment count) too low excludes helpful knowledge → performance plateaus or drops
  - **Poor confidence calibration:** If τ is set too high, noise enters reasoning; if too low, helpful knowledge is withheld

- **First 3 experiments:**
  1. **Reproduce ablation study** (Table III) to validate each component's contribution: test Baseline → +LNQ → +KRF → +SKI on OK-VQA validation split
  2. **Confidence calibration analysis:** Plot model confidence vs. answer correctness to assess whether τ = 0.8 is appropriate or if calibration correction is needed
  3. **Error analysis by question type:** Categorize failures into retrieval errors, filtering errors, and reasoning errors to identify which mechanism is the bottleneck

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the methodology raises several important areas for future research, particularly around the robustness of confidence-based knowledge integration and the generalizability of the training-free approach across different model architectures and knowledge bases.

## Limitations
- The framework relies heavily on prompt engineering without analyzing robustness when prompts fail or how keyword quality affects retrieval
- The training-free approach cannot adapt to dataset-specific characteristics that supervised fine-tuning might capture
- Evaluation is limited to two datasets with a single knowledge base (Google Search), restricting generalizability claims

## Confidence
- **High confidence:** The ablation study results showing incremental improvements from each component (LNQ, KRF, SKI) and the overall state-of-the-art performance on OK-VQA and A-OKVQA are reproducible based on the methodology described.
- **Medium confidence:** The claim that keyword-based queries improve retrieval relevance over verbose queries is supported by the ablation but lacks direct retrieval quality metrics or comparison against caption-based alternatives.
- **Medium confidence:** The confidence threshold τ=0.8 is selected via hyperparameter analysis, but without calibration plots or analysis of false positive/negative rates, the optimality and robustness of this choice remain uncertain.

## Next Checks
1. **Perform confidence calibration analysis** by plotting model confidence vs. answer correctness to verify that τ=0.8 corresponds to optimal accuracy and to assess whether calibration correction is needed.
2. **Analyze retrieval quality** by measuring document-relevance metrics (e.g., precision@k, recall@k) for keyword-based vs. caption-based queries to validate the low-noise query hypothesis.
3. **Conduct error analysis by failure mode** to categorize mistakes into retrieval errors, filtering errors, and reasoning errors, identifying which component is the primary bottleneck in the pipeline.