---
ver: rpa2
title: Nearly Instance-Optimal Parameter Recovery from Many Trajectories via Hellinger
  Localization
arxiv_id: '2510.06434'
source_url: https://arxiv.org/abs/2510.06434
tags:
- have
- logp
- learning
- where
- hence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies parameter recovery in multi-trajectory settings,
  where data consists of many independent realizations of a time-indexed stochastic
  process. The authors introduce the Hellinger localization framework, a general approach
  for maximum likelihood estimation that leverages both trajectory-level and parameter-level
  information to achieve instance-optimal rates scaling with the full data budget.
---

# Nearly Instance-Optimal Parameter Recovery from Many Trajectories via Hellinger Localization

## Quick Facts
- **arXiv ID:** 2510.06434
- **Source URL:** https://arxiv.org/abs/2510.06434
- **Reference count:** 40
- **Primary result:** Hellinger localization framework achieves instance-optimal parameter recovery rates from many independent trajectories, even for non-mixing processes

## Executive Summary
This paper introduces a general framework for parameter recovery from multiple independent trajectories of a time-indexed stochastic process. The Hellinger localization approach combines trajectory-level concentration bounds with parameter-level regularity to achieve rates that scale with the full data budget (mT) rather than being limited by single-trajectory constraints. Unlike standard approaches that rely on mixing or stationarity assumptions, this method works for non-stationary and non-mixing processes by leveraging the independence across trajectories. The framework is instantiated across four case studies, demonstrating significant improvements over standard reduction techniques.

## Method Summary
The method constructs a discretized Maximum Likelihood Estimator (MLE) over a covering of the parameter space using max Fisher Information divergence. It first bounds the squared Hellinger distance between the estimated and true path measures via a reduction to i.i.d. learning, achieving concentration at rate O(log(m)/m). Then, using local regularity of the score function and Hessian, it converts this distribution-level bound to a parameter-level bound weighted by the trajectory Fisher Information matrix. This two-step process enables instance-optimal scaling O(1/sqrt(mT)) without requiring mixing or stationarity assumptions on the trajectory process.

## Key Results
- Achieves instance-optimal parameter recovery rates scaling as O(1/sqrt(mT)) for general multi-trajectory settings
- Works for non-stationary and non-mixing processes, demonstrated on mixture of Markov chains
- Provides near-optimal rates for dependent linear regression with non-Gaussian noise and non-monotonic sinusoidal GLMs
- Shows linear-attention sequence models can recover parameters with near-optimal scaling

## Why This Works (Mechanism)

### Mechanism 1
The framework achieves nearly instance-optimal rates by using a discretized Maximum Likelihood Estimator (MLE) to bound the Hellinger distance, which then translates to parameter error via local regularity. The method constructs a minimal covering of the parameter space in max FI-divergence and maximizes the likelihood over this discrete set. By using Theorem 3.6, it bounds the squared Hellinger distance $d^2_H(\hat{\theta}^{\epsilon}_{m,T}, \theta^\star)$ by $O(\log(m)/m)$, avoiding requirements for $\alpha$-mixing or stationarity of the trajectory process.

### Mechanism 2
Squared Hellinger distance is locally equivalent to the Fisher Information weighted metric, enabling instance-optimal variance scaling. Proposition 3.9 performs a second-order Taylor expansion showing that in a local radius around the true parameter, $d^2_H(\theta_0, \theta_1) \approx \frac{1}{4}\|\theta_0 - \theta_1\|^2_{I_2(\theta_0, \theta_1)}$. This bridges the distribution-level bound to a parameter-level bound with the correct $1/(mT)$ scaling, serving as the Riemannian metric tensor that transforms the Euclidean parameter difference into a statistical distance.

### Mechanism 3
The framework enables learning from multiple trajectories even when individual trajectories are non-mixing or non-stationary. The analysis decouples the trajectory dependency: while the single-trajectory Fisher Information captures sequential dependency $z_{1:T}$, the concentration bounds rely on the number of independent trajectories $m$. This allows recovering parameters for processes like mixtures of Markov chains which fail $\alpha$-mixing conditions, leveraging the i.i.d. assumption across trajectories rather than within trajectories.

## Foundational Learning

**Concept: Hellinger Distance ($d_H$**
- Why needed here: It is the primary metric used to measure the difference between the estimated distribution and the true distribution before converting to parameter error
- Quick check question: Why use Hellinger distance instead of Total Variation for this discretized MLE analysis? (Answer: Hellinger is better suited for the log-concavity and metric entropy arguments in Theorem 3.6)

**Concept: Fisher Information Matrix ($I(\theta)$**
- Why needed here: It defines the "instance-optimal" scaling of the error. The final parameter bounds are weighted by the inverse of this matrix, ensuring the rate depends on local curvature
- Quick check question: In the local expansion of Hellinger distance (Prop 3.9), what role does the Fisher Information play? (Answer: It serves as the Riemannian metric tensor, transforming the Euclidean parameter difference into a statistical distance)

**Concept: Log-concavity**
- Why needed here: It determines the sample complexity of trajectories $m$. Log-concave models allow $m \sim polylog(T)$, while non-log-concave models require $m \sim T$
- Quick check question: How does the assumption of log-concavity improve the bound on the minimum number of trajectories $m$ required for Theorem 3.6? (Answer: It removes the linear dependence on $T$ in the $m$ requirement)

## Architecture Onboarding

**Component map:** Input: $m$ trajectories of length $T$ -> Discretized MLE $\hat{\theta}^{\epsilon}_{m,T}$ over max FI-covering -> Step 1 (Concentration): Apply Thm 3.6 to bound Hellinger distance $d_H$ -> Step 2 (Localization): Check conditions (moment bounds $B_1, B_2$) for Prop 3.9 -> Step 3 (Expansion): Convert Hellinger bound to Fisher-weighted parameter bound -> Output: Parameter estimate $\hat{\theta}$ with rate $O(1/\sqrt{mT})$

**Critical path:** The conversion from Step 1 to Step 3 relies on satisfying the local radius condition (Eq 3.22). If $m$ is too small, the estimate falls outside the region where Hellinger $\approx$ Fisher metric, and the instance-optimal rate breaks.

**Design tradeoffs:** Using a discretized MLE (covering) simplifies the analysis compared to exact MLE but introduces $\varepsilon$-approximation terms. Log-concave assumptions provide better $m$ requirements at the cost of restrictiveness.

**Failure signatures:**
- **Non-identifiable:** If the Fisher Information matrix is singular, the parameter cannot be recovered
- **Insufficient Trajectories:** If $m \ll T$, the estimate may not localize, causing the bound to revert to the non-instance-optimal $O(1/\sqrt{m})$ rate
- **Model Complexity:** If the model's metric entropy grows too rapidly, the covering number becomes intractable

**First 3 experiments:**
1. **Mixture of Markov Chains:** Validate on a non-$\alpha$-mixing process (Section 4.1). Check if the method recovers parameters where single-trajectory methods fail
2. **Dependent Regression (Non-Gaussian):** Test on noise distributions that are non-Gaussian and possibly non-sub-Gaussian (Section 4.2)
3. **Sinusoidal GLM:** Verify the "local identifiability" (Hellinger $\approx$ Fisher) holds for a non-monotonic activation function (Section 4.3)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the Hellinger localization framework be extended to provide non-asymptotic rates for linear dynamical systems with spectral radius strictly greater than 1 without relying on mixing or stability assumptions?
- **Basis in paper:** Section 5 (a) states that a limitation is that it "places un-necessary requirements on the regularity of the trajectory process... which rules out e.g., recovering linear dynamical systems with spectral radius > 1"
- **Why unresolved:** The current analysis relies on bounding covering numbers and Hellinger distances that become unstable or degenerate when trajectory states grow exponentially (unstable systems)
- **What evidence would resolve it:** A proof demonstrating that the discretized MLE achieves the instance-optimal rate $\|\hat{\theta}_{m,T} - \theta^\star\|^2_{\bar{I}(\theta^\star)} \lesssim \frac{d}{mT}$ for a linear system where the state matrix $A$ has $\|A\| > 1$

### Open Question 2
- **Question:** Is the linear dependence on $T$ in the trajectory requirement $m$ for non-log-concave families fundamental, or can it be improved to $m \gtrsim \text{polylog}(T)$?
- **Basis in paper:** Section 5 (b) notes that for non-log-concave families, the requirement scales as $m \gtrsim T \cdot \text{polylog}(T)$, compared to $m \gtrsim \text{polylog}(T)$ for log-concave families
- **Why unresolved:** The proof technique for non-concave likelihoods currently necessitates the linear scaling in $T$ to ensure localization
- **What evidence would resolve it:** A generalized proof using local geodesic convexity of the squared Hellinger distance that achieves $m \gtrsim \text{polylog}(T)$ for a non-log-concave distribution class, or a counter-example showing the linear dependency is necessary

### Open Question 3
- **Question:** Can the polynomial dependence on dimension $d$ in the trajectory requirement $m \gtrsim d^{11} T$ for the sinusoidal GLM model be significantly reduced?
- **Basis in paper:** Section 4.3 discussion regarding Theorem 4.17 states: "We suspect that the $m \gtrsim \tilde{\Omega}(d^{11})$ requirement is sub-optimal and can be further improved with a more refined analysis"
- **Why unresolved:** The high polynomial power ($11$) arises from accumulating constants in the bounds for $B_1$ and $B_2$ (moment bounds) and the lower bound on the Fisher Information matrix
- **What evidence would resolve it:** A refined analysis of the Fisher Information matrix lower bound and score function moments for sinusoidal activations that yields a requirement scaling as $m \gtrsim d^k T$ for some $k < 11$

## Limitations
- The framework requires the discretized MLE to lie within a local radius of validity for Fisher-Hellinger equivalence, which may fail for highly non-regular models
- The analysis depends on computing or bounding the Fisher Information and metric entropy, which can be challenging for complex sequential models
- The instance-optimal rates for specific models rely on verifying model-specific conditions (log-concavity, identifiability)

## Confidence

**High Confidence:** The reduction from Hellinger distance to Fisher-weighted parameter error (Mechanism 2) is mathematically rigorous and well-established in the statistical literature. The core concentration bounds (Theorem 3.6) follow standard techniques.

**Medium Confidence:** The extension to non-mixing and non-stationary processes (Mechanism 3) is valid in principle, but the practical implications depend heavily on the specific structure of the dependency and whether the trajectory-level i.i.d. assumption is realistic in applications.

**Medium Confidence:** The instance-optimal rates for specific models (Mechanism 1) rely on verifying model-specific conditions (log-concavity, identifiability). While the framework is general, actual rate improvements depend on these conditions being satisfied.

## Next Checks

1. Verify the local regularity conditions ($B_1, B_2$ bounds) for the sinusoidal GLM case study, particularly given the non-monotonic activation function
2. Check the metric entropy bounds used in the covering number arguments for the dependent linear regression with heavy-tailed noise
3. Test the framework's performance on a simple non-mixing Markov chain where standard single-trajectory methods are provably inconsistent, to validate the multi-trajectory advantage