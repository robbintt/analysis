---
ver: rpa2
title: 'Mitigating Language Barriers in Education: Developing Multilingual Digital
  Learning Materials with Machine Translation'
arxiv_id: '2509.09473'
source_url: https://arxiv.org/abs/2509.09473
tags:
- translation
- czech
- exercises
- evaluation
- educational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The EdUKate project addresses language barriers in Czech education
  by translating 9,000 interactive exercises from Czech into Ukrainian, English, and
  German using machine translation. The project developed a domain-adapted Czech-Ukrainian
  MT system specifically for educational content, incorporating formatted text processing
  and specialized terminology handling.
---

# Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation

## Quick Facts
- arXiv ID: 2509.09473
- Source URL: https://arxiv.org/abs/2509.09473
- Reference count: 3
- Primary result: Domain-adapted MT system achieves chrF 63.1 and human score 7.80/10 for translating 9,000 Czech educational exercises into Ukrainian, English, and German

## Executive Summary
The EdUKate project addresses language barriers in Czech education by developing a domain-adapted machine translation system specifically for educational content. The project translated 9,000 interactive exercises from Czech into Ukrainian, English, and German using a neural MT system with block backtranslation and custom formatting preservation. A survey of Czech teachers revealed significant challenges with non-Czech-speaking students, with 71% attending Czech lessons instead of other subjects. The best-adapted system achieved an average human evaluation score of 7.80/10, with automatic chrF score of 63.1, though terminology translation remains a primary challenge.

## Method Summary
The project developed a domain-adapted Czech-Ukrainian MT system using neural translation with block backtranslation, trained on educational materials from the Škola s náhledem portal. The system incorporated formatted text processing through word alignment for HTML/XML tags and specialized terminology handling. The methodology involved fine-tuning a base Charles Translator (CUBBITT architecture) on in-domain parallel data and additional monolingual data. The adapted system was evaluated on 396 manually translated exercises using both automatic chrF scoring and human evaluation on a 0-10 scale. The translation pipeline was integrated into an API server for Fraus Publishing's educational portal.

## Key Results
- Survey data shows 71% of non-Czech-speaking students attend Czech language lessons instead of other subjects
- Adapted MT system achieved chrF score of 63.1 and human evaluation score of 7.80/10
- Terminology translation, particularly in biology and natural sciences, identified as primary challenge requiring further improvement

## Why This Works (Mechanism)

### Mechanism 1: Domain-Specific Adaptation via In-Domain Training Data
- Claim: Neural MT systems trained on general-purpose data underperform on educational content; domain adaptation improves translation quality for subject-specific terminology.
- Mechanism: The system was fine-tuned on educational materials from the Škola s náhledem portal, incorporating monolingual and parallel training data alongside "translationese tuning." This exposes the model to the lexical distribution and structural patterns of educational exercises.
- Core assumption: The adapted model retains general translation capability while gaining domain-specific accuracy.
- Evidence anchors:
  - [abstract]: "system, based on neural translation and block backtranslation, was tailored for educational terminology and formatted content"
  - [section 2.2.2]: "To ensure higher translation quality for domain-specific content, it is necessary to adapt translation models to the characteristics of the given domain"
  - [corpus]: Weak direct corpus support for domain adaptation specifically; related work (Multilingual Performance Biases of LLMs in Education) confirms language/distribution-specific performance variance but does not validate this exact adaptation method.
- Break condition: If the target domain vocabulary diverges significantly from available in-domain training data (e.g., newly coined scientific terms), lexical error rates may remain high.

### Mechanism 2: Direct Language Pair Translation (Non-Pivot Architecture)
- Claim: Direct Czech–Ukrainian translation avoids error propagation introduced by pivoting through English.
- Mechanism: Charles Translator uses a direct translation architecture between Czech and Ukrainian without intermediate English representation, reducing compounded errors in grammatical categories (e.g., case, gender agreement).
- Core assumption: Direct-pair models can achieve sufficient data coverage; quality loss from pivot architectures is measurably significant.
- Evidence anchors:
  - [abstract]: "domain-adapted Czech–Ukrainian machine translation system"
  - [section 2.2.2]: "Unlike the common commercial translators that pivot the translation over English, Charles Translator translates directly and is thus not prone to some types of errors, especially in certain grammatical categories"
  - [corpus]: No direct corpus validation of the pivot-vs-direct comparison for this language pair.
- Break condition: If parallel data for the direct pair is sparse relative to English-pivot paths, direct models may underperform on rare constructions.

### Mechanism 3: Formatted Content Preservation via Word Alignment
- Claim: Educational exercises with embedded formatting (HTML/XML tags, interactive elements) can be translated while preserving structural integrity using alignment-based tag placement.
- Mechanism: A word alignment tool determines insertion points for formatting tags (bold, italics, structural markers) within translated output. This is integrated into the API server.
- Core assumption: Word alignment quality is sufficiently robust to handle the short, fragmented text segments common in exercises.
- Evidence anchors:
  - [abstract]: "special attention to processing formatted content such as XML and PDF"
  - [section 2.2.2]: "This functionality is built into the API server... relies on a word alignment tool that determines where to insert formatting tags"
  - [corpus]: No corpus papers directly validate formatted-content translation pipelines for MT.
- Break condition: Alignment errors on short segments or misaligned multi-word expressions may cause misplaced tags, breaking exercise functionality.

## Foundational Learning

- Concept: **Neural Machine Translation (NMT) and Attention Mechanisms**
  - Why needed here: Understanding encoder-decoder architectures and attention is prerequisite to grasping Block Backtranslation and domain adaptation.
  - Quick check question: Can you explain how an attention mechanism differs from fixed-context encoding in sequence-to-sequence models?

- Concept: **Machine Translation Evaluation Metrics (chrF, Human Scoring)**
  - Why needed here: The project relies on both automatic (chrF) and human (0–10 scale) evaluation; interpreting these scores is essential for assessing improvement claims.
  - Quick check question: What are the limitations of chrF compared to human evaluation in detecting semantic translation errors?

- Concept: **Domain Adaptation in NLP**
  - Why needed here: The core innovation involves adapting a general MT system to educational content; understanding fine-tuning vs. in-domain pretraining is critical.
  - Quick check question: What is the difference between continuing pretraining on in-domain data versus fine-tuning on parallel in-domain data?

## Architecture Onboarding

- Component map:
  - Source exercises -> Charles Translator (CHT) -> Word alignment-based formatting -> API server -> Educational portal
  - Evaluation pipeline: chrF automatic scoring + human annotation + error analysis

- Critical path:
  1. Filter exercises (exclude crossword, syllable-based, grammar-specific)
  2. Fine-tune CHT model on educational parallel data with translationese tuning
  3. Integrate word alignment for XML/HTML tag preservation
  4. Deploy through API server for portal integration
  5. Evaluate using chrF and human scoring

- Design tradeoffs:
  - Direct translation vs. pivot architecture (complexity vs. data availability)
  - Custom formatting preservation vs. standard MT output (functionality vs. simplicity)
  - Domain adaptation vs. general-purpose MT (quality vs. coverage)

- Failure signatures:
  - Broken XML structure indicating formatting alignment errors
  - Consistent terminology mistranslation suggesting insufficient domain adaptation
  - Low chrF scores indicating fundamental translation quality issues

- First experiments:
  1. Test formatting preservation on 10 sample exercises with complex HTML structures
  2. Evaluate terminology accuracy on 50 biology/chemistry terms
  3. Compare direct vs. pivot translation quality on 100 parallel sentences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the integration of external terminological sources effectively eliminate the lexical errors currently observed in the domain-adapted machine translation output?
- Basis in paper: [explicit] The authors state, "We are currently implementing specific methods (e.g. adding external terminological sources) to eliminate this issue," referring to the frequent mistranslation of specialized terminology.
- Why unresolved: The paper identifies the lexical error rate as the primary deficiency and proposes a specific mitigation strategy, but the results of this implementation have not yet been evaluated or reported.
- What evidence would resolve it: A comparative evaluation showing a reduction in terminology errors in the system fine-tuned with external terminological data versus the current "Adapted CHT 2024" baseline.

### Open Question 2
- Question: Do large language model (LLM)-based translation methods provide a measurable improvement in translation quality over the current neural machine translation system for this domain?
- Basis in paper: [explicit] The conclusion notes, "We are also experimenting with the latest LLM-based methods to see if translation quality can be further improved."
- Why unresolved: The authors explicitly frame this as an ongoing experiment ("to see if"), indicating that the efficacy of LLMs for this specific Czech–Ukrainian educational use case is currently unknown.
- What evidence would resolve it: Automatic (chrF) and human evaluation scores comparing the current best system against an LLM-based baseline using the same test dataset.

### Open Question 3
- Question: Does the implementation of single-word translation tooltips enhance the learning experience for non-native students compared to full-text toggling?
- Basis in paper: [inferred] The pilot testing results note that "users would welcome the possibility to display the translation of just a single word within the other language (tool tip)," but the feature has not yet been developed or tested.
- Why unresolved: While user preference is stated, the actual impact of this specific interaction design on comprehension and workflow in the educational portal remains unverified.
- What evidence would resolve it: Usability studies or A/B testing comparing student performance and user satisfaction between the current "toggle" interface and the proposed "tooltip" interface.

## Limitations
- Limited test set size (396 exercises) may not capture full diversity of educational content
- Domain adaptation methodology relies on undisclosed volumes of additional training data
- Focus on Czech-Ukrainian pair may not generalize to other language families
- Impact on actual student learning outcomes has not been measured

## Confidence

**High Confidence (8-10/10):** The survey data on teacher experiences with non-Czech-speaking students (71% attending Czech lessons instead of other subjects) is directly collected and methodologically sound. The basic functionality of the translated exercises has been verified through pilot testing with teachers.

**Medium Confidence (5-7/10):** The MT system evaluation scores (chrF 63.1, human 7.80/10) are reliable within the tested domain, but the limited test set size and specific subject focus (biology, chemistry, geography) may not represent overall educational content quality. The formatting preservation mechanism is technically described but lacks extensive validation.

**Low Confidence (1-4/10):** The generalizability of the domain adaptation approach to other educational contexts or language pairs remains unproven. The impact of translation quality on actual student learning outcomes has not been measured.

## Next Checks
1. **Terminology Coverage Validation**: Systematically evaluate the MT system's performance on a broader range of scientific and technical terminology across all school subjects to identify vocabulary gaps and their frequency in typical educational content.

2. **Cross-Language Generalizability Test**: Apply the domain adaptation methodology to a different language pair (e.g., English-Spanish) using comparable educational resources to determine if the approach transfers successfully across linguistic families.

3. **Learning Outcome Assessment**: Conduct a controlled study measuring whether students using the translated materials achieve comparable learning outcomes to those using native-language materials, controlling for baseline proficiency and subject matter.