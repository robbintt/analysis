---
ver: rpa2
title: Exploring the Feasibility of End-to-End Large Language Model as a Compiler
arxiv_id: '2511.04132'
source_url: https://arxiv.org/abs/2511.04132
tags:
- code
- llms
- compilation
- assembly
- compiler
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores using end-to-end Large Language Models (LLMs)
  as compilers, directly transforming source code into assembly code. To evaluate
  this concept, the authors created CompilerEval, a dataset and framework with 20
  test cases across domains like linear algebra and image processing, and evaluated
  four mainstream LLMs (GPT-4o, Claude-3.5-Sonnet, Gemini-2.0-Flash-Exp, LLaMA-3.1-405B)
  against traditional compilers (gcc, clang).
---

# Exploring the Feasibility of End-to-End Large Language Model as a Compiler

## Quick Facts
- arXiv ID: 2511.04132
- Source URL: https://arxiv.org/abs/2511.04132
- Reference count: 40
- Primary result: LLMs show basic compilation abilities but achieve low success rates, with reasoning methods and prompt engineering significantly improving output quality

## Executive Summary
This paper investigates whether end-to-end Large Language Models can serve as compilers, directly translating source code to assembly without intermediate representations. The authors created CompilerEval, a dataset with 20 test cases across domains like linear algebra and image processing, and evaluated four mainstream LLMs against traditional compilers. Results show that while LLMs possess basic compilation capabilities, success rates remain low for complex programs. The study identifies RISC-V and ARM architectures as more LLM-friendly than x86 due to simpler instruction sets, and demonstrates that reasoning methods and targeted prompt engineering can significantly enhance compilation quality.

## Method Summary
The evaluation uses CompilerEval, a framework containing 20 C kernel definitions and main programs. LLMs (GPT-4o, Claude-3.5-Sonnet, Gemini-2.0, LLaMA-3.1-405B) generate assembly code from C source via prompts, which is then wrapped in templates, compiled using gcc/clang, and executed. Success is measured by semantic correctness (Success@1), executable sample count, and correctness rate. The study applies targeted prompt engineering based on error types and reasoning methods (GPT-o1) to improve results, comparing performance across x86, ARM, and RISC-V architectures.

## Key Results
- LLMs achieve basic assembly code generation but with low compilation success rates, successfully compiling only simple programs
- RISC-V and ARM architectures show better performance than x86, attributed to simpler instruction sets
- Prompt engineering and reasoning methods (GPT-o1) significantly improve compilation quality, with GPT-o1 showing over 30 percentage point improvements on specific kernels
- Major failure modes include "Segmentation Fault" and "Instruction Error," primarily from stack management and register binding issues

## Why This Works (Mechanism)

### Mechanism 1: Direct Source-to-Assembly Mapping
LLMs treat compilation as a translation task, mapping high-level abstractions directly to hardware instructions based on probabilistic patterns learned during pre-training. The model internalizes syntax rules and hardware specifications to generate valid instruction sequences without explicit grammar or optimization passes. Performance varies by instruction set complexity, with RISC-V's fixed-length instructions being easier to generate than x86's variable-length format.

### Mechanism 2: Reasoning-Driven Compilation
Incorporating reasoning methods like Chain-of-Thought significantly improves success rates by generating intermediate planning steps before final assembly output. This simulates register allocation and control flow analysis, decomposing the compilation problem into intermediate reasoning steps similar to "System 2" thinking in mathematical reasoning. GPT-o1's reasoning capabilities demonstrated over 30 percentage point improvements on specific kernels.

### Mechanism 3: Error-Sensitive Prompt Engineering
Targeted prompt refinement suppresses specific error modes by injecting explicit constraints into prompts based on common failure signatures. The model attends to negative constraints and adjusts its generation policy in zero-shot or few-shot settings. Claude showed the largest improvement of 7.5 percentage points through prompt optimization, though effectiveness varies by model architecture.

## Foundational Learning

- **Instruction Set Architecture (ISA) Complexity**: Understanding CISC vs. RISC differences is critical as the paper attributes performance differences to instruction set complexity. *Quick check*: Can you explain why a variable-length instruction set (like x86) might be harder for an LLM to generate than a fixed-length one (like RISC-V)?

- **Compilation Success Metrics (Success@1)**: The paper redefines accuracy as semantic correctness rather than text similarity. *Quick check*: If an LLM generates assembly that assembles but produces the wrong output, does it count toward "Executable Samples Count"? (Answer: Yes, but it lowers the "Correctness Rate").

- **Context Window vs. Code Length**: RISC-V code length sometimes exceeds context limits, preventing complete generation. *Quick check*: How does the trade-off between code density (CISC) and instruction simplicity (RISC) interact with the LLM's token limit?

## Architecture Onboarding

- **Component map**: Source Code -> LLM (Compiler) -> Raw Assembly -> Assembler/Linker (gcc/clang) -> Executable -> Execution Result
- **Critical path**: Generating function prologue/epilogue and stack management correctly, as "Segmentation Fault" and "Instruction Error" are top failure modes
- **Design tradeoffs**: Generalist vs. specialist models, context allocation between prompt and source code, reasoning latency vs. compilation speed
- **Failure signatures**: Compilation Errors ("Unrecognized Character," "Invalid Register Usage"), Runtime Execution Errors ("Segmentation Fault"), Semantic Errors ("Wrong Result")
- **First 3 experiments**: 1) Baseline Test: Run CompilerEval "Hello World" on GPT-4 vs. Claude on x86; 2) Cross-Architecture Validity: Compile same kernel for RISC-V vs. x86; 3) Prompt Stress Test: Provoke "Invalid Register Usage" errors and apply paper's prompt constraints

## Open Questions the Paper Calls Out

- **Open Question 1**: How can LaaC models be trained or optimized to simultaneously satisfy compilation accuracy, computational cost, and context length constraints? (Explicit in Section V.B)
- **Open Question 2**: How can LaaC infrastructure effectively decouple core LLM from language/hardware specifications to support many-to-many mappings without retraining? (Explicit in Section V.B)
- **Open Question 3**: How can LaaC collaborate effectively with debuggers to generate accurate debug information and provide intelligent troubleshooting? (Explicit in Section V.B)

## Limitations
- Reliance on proprietary LLM APIs with unclear exact prompt formulations limits reproducibility
- Success rates are context-dependent on specific kernel complexity and may not generalize to arbitrary source code
- Critical prompt engineering details and reasoning method implementations remain underspecified

## Confidence

- **High Confidence**: LLMs possess basic assembly code generation capabilities but struggle with compilation success rates (well-supported empirical results)
- **Medium Confidence**: RISC-V and ARM yield better LLM performance than x86 due to simpler instruction sets (supported but requires deeper analysis)
- **Low Confidence**: Effectiveness of reasoning methods and specific prompt engineering improvements (reported but lacks implementation transparency)

## Next Checks

1. **Prompt Template Reconstruction**: Attempt to reconstruct exact prompt formulations used for error-specific optimization by reverse-engineering from reported error type improvements and testing against CompilerEval framework

2. **Cross-Architecture Scaling Analysis**: Systematically vary code complexity and instruction set density across x86, ARM, and RISC-V to quantify relationship between ISA complexity and LLM compilation success rates

3. **Reasoning Method Isolation**: Design controlled experiments to isolate whether GPT-o1 improvements are due to native reasoning capabilities or specific chain-of-thought prompt engineering applicable to other models