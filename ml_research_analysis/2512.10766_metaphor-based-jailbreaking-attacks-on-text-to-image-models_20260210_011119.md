---
ver: rpa2
title: Metaphor-based Jailbreaking Attacks on Text-to-Image Models
arxiv_id: '2512.10766'
source_url: https://arxiv.org/abs/2512.10766
tags:
- adversarial
- sensitive
- attack
- prompts
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces MJA, a metaphor-based jailbreaking method
  for text-to-image models that generates adversarial prompts by combining metaphorical
  descriptions with contextual cues. It employs a three-agent LLM framework to retrieve
  metaphors, match contexts, and generate diverse prompts, then optimizes selection
  using a surrogate model and Bayesian acquisition strategy.
---

# Metaphor-based Jailbreaking Attacks on Text-to-Image Models

## Quick Facts
- arXiv ID: 2512.10766
- Source URL: https://arxiv.org/abs/2512.10766
- Authors: Chenyu Zhang; Yiwen Ma; Lanjun Wang; Wenhui Li; Yi Tu; An-An Liu
- Reference count: 40
- Key outcome: MJA achieves 0.98 bypass rate and 0.76 attack success rate on SD1.4 across all defense settings

## Executive Summary
This paper introduces MJA, a metaphor-based jailbreaking method for text-to-image models that generates adversarial prompts by combining metaphorical descriptions with contextual cues. It employs a three-agent LLM framework to retrieve metaphors, match contexts, and generate diverse prompts, then optimizes selection using a surrogate model and Bayesian acquisition strategy. Evaluated on Stable Diffusion and other models with eight external and seven internal defenses, MJA achieves a 0.98 bypass rate and 0.76 attack success rate, outperforming six baselines while requiring fewer queries. The method also shows strong cross-model transferability.

## Method Summary
MJA consists of two modules: a Multi-Agent LLM Generation (MLAG) module and an Adversarial Prompt Optimization (APO) module. MLAG uses three specialized LLM agents—Metaphor Agent, Context Agent, and Prompt Agent—to generate metaphor-based adversarial prompts. The Metaphor Agent retrieves imagery-based metaphors from a CLIP-based example retrieval tool, the Context Agent generates artistic style descriptors to guide interpretation, and the Prompt Agent synthesizes these into diverse candidate prompts. APO employs Gaussian Process Regression with Expected Improvement acquisition to select optimal prompts with minimal queries, starting from a small observation set of 5 samples and iteratively querying the target model until success or query limit.

## Key Results
- MJA achieves average BR=0.98 and ASR-C=0.76 on SD1.4 across all defense settings
- Outperforms six baselines with fewer queries (typically 3-8 vs 19±19 for iterative approaches)
- Demonstrates strong cross-model transferability (0.60-0.66 ASR-C when transferring from SD1.4 to other models)
- Metaphor-based approach shows superior effectiveness compared to token-level substitutions and pseudoword methods

## Why This Works (Mechanism)

### Mechanism 1: Metaphor-Based Semantic Obfuscation
By replacing sensitive words with imagery-based descriptions (e.g., "naked" → "translucent medium, like a wet glass sculpture"), prompts bypass keyword-based and semantic classifiers that rely on explicit sensitive token patterns. T2I models, trained on large-scale text-image corpora, retain capacity to infer implicit semantics from figurative language.

### Mechanism 2: Contextual Grounding for Semantic Disambiguation
Artistic style contexts amplify metaphor effectiveness by providing interpretive framing cues. The Context Agent generates style descriptors (e.g., Gothic, desaturated textures) that constrain how the T2I model interprets the metaphor, reducing ambiguity in the metaphor-to-concept mapping.

### Mechanism 3: Bayesian Surrogate for Query-Efficient Selection
A Gaussian Process Regression surrogate with Expected Improvement acquisition reduces query count while maintaining high attack success. The surrogate predicts attack outcomes from limited observations, balancing exploitation of high-predicted-success candidates and exploration of uncertain regions.

## Foundational Learning

- **Concept: Gaussian Process Regression**
  - Why needed here: Core of APO module; provides uncertainty-aware predictions for attack success from limited observations
  - Quick check question: Given 5 labeled samples in a 49-candidate pool, how does GP quantify prediction uncertainty vs. a simple neural classifier?

- **Concept: Multi-Agent LLM Coordination**
  - Why needed here: MLAG decomposes prompt generation into three specialized subtasks with shared memory
  - Quick check question: Why separate metaphor retrieval and context matching into distinct agents rather than a single prompt?

- **Concept: Acquisition Functions in Bayesian Optimization**
  - Why needed here: EI acquisition balances exploiting high-predicted-success candidates and exploring uncertain regions
  - Quick check question: How does EI differ from pure exploitation (greedy selection) in terms of query efficiency?

## Architecture Onboarding

- **Component map:** CLIP ViT-L/14 -> Example Retrieval Tool -> Metaphor Agent -> Context Agent -> Prompt Agent -> APO Module -> T2I Model API
- **Critical path:** Sensitive prompt → CLIP retrieval of task examples → Metaphor Agent generates N=7 metaphors → Context Agent generates M=7 contexts per metaphor → Prompt Agent produces 49 candidates → Random split into observation (N_obs=5) and candidate sets → GP training on observation set → EI selects next candidate → Query T2I model → Update sets and iterate
- **Design tradeoffs:** N_obs=5 balances efficiency and effectiveness; threshold τ=0.26 set based on Sneaky baseline; N=7 metaphors and M=7 contexts provide good coverage without excessive overhead
- **Failure signatures:** High PPL (>1000) indicates unnatural prompts; low BR with high ASR-C suggests semantic filter evasion but keyword detection failure; high query variance indicates surrogate model overfitting
- **First 3 experiments:** 1) Reproduce baseline comparison on SD1.4; 2) Ablate context component to measure impact; 3) Test transferability from SD1.4 to SDXL

## Open Questions the Paper Calls Out

1. How can defense mechanisms be designed to detect metaphor-based adversarial prompts without relying on training data distributions that fail to generalize to unseen metaphors?
2. Can concept-erasure techniques be evolved to close the semantic vulnerabilities that allow metaphorical descriptions to reconstruct erased concepts?
3. Does scaling the capability of the unaligned LLM used for generation significantly correlate with the success or semantic consistency of the jailbreak?

## Limitations

- Defense robustness gap: Evaluated against static, pre-trained defenses rather than adaptive systems
- Generalization uncertainty: Significant performance drop on DALL·E 3 suggests model-specific limitations
- LLM dependency vulnerability: Effectiveness relies heavily on metaphor generation quality of specific unaligned LLM

## Confidence

**High Confidence Claims:**
- Three-agent LLM framework can generate diverse metaphor-based prompts that evade keyword-based detection
- Gaussian Process Regression with Expected Improvement acquisition reduces query counts
- Metaphor-based approaches outperform token-level substitutions and pseudoword methods

**Medium Confidence Claims:**
- Metaphor-based obfuscation will remain effective as T2I models and defenses evolve
- 0.26 similarity threshold provides optimal balance between semantic fidelity and evasion
- Cross-model transferability at 0.60-0.66 levels represents practical utility

**Low Confidence Claims:**
- MJA's effectiveness generalizes to all major T2I models beyond those tested
- Current defense mechanisms represent state-of-the-art for metaphor-based attack detection
- Query efficiency gains scale to larger search spaces

## Next Checks

1. **Adaptive Defense Testing:** Implement a defense that updates detection based on observed metaphor patterns; measure how quickly MJA's effectiveness degrades against this evolving defense
2. **Metaphor Transferability Analysis:** Systematically vary the unaligned LLM model while keeping all other components constant; quantify how metaphor generation quality affects BR and ASR-C
3. **Semantic Drift Evaluation:** Generate prompts using MJA, then measure how prompt effectiveness changes over time as target T2I model undergoes fine-tuning; track BR and ASR-C degradation curves