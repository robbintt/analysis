---
ver: rpa2
title: A Causal Adjustment Module for Debiasing Scene Graph Generation
arxiv_id: '2503.17862'
source_url: https://arxiv.org/abs/2503.17862
tags:
- object
- causal
- relationships
- adjustment
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the long-tail problem in Scene Graph Generation
  (SGG), where models tend to predict tail relationships as head ones. While existing
  debiasing methods attribute this bias solely to the long-tail distribution of relationships,
  this paper identifies the skewed distributions of objects and object pairs as deeper
  underlying causes.
---

# A Causal Adjustment Module for Debiasing Scene Graph Generation

## Quick Facts
- **arXiv ID:** 2503.17862
- **Source URL:** https://arxiv.org/abs/2503.17862
- **Reference count:** 40
- **Primary result:** Achieves state-of-the-art mean recall rates and significantly improves zero-shot recall through triplet-level adjustment factors

## Executive Summary
This paper addresses the long-tail problem in Scene Graph Generation (SGG) by identifying that bias stems not just from skewed relationship distributions, but also from the skewed distributions of objects and object pairs. The authors propose a Mediator-based Causal Chain Model (MCCM) and a Causal Adjustment Module (CAModule) that generate triplet-level adjustment factors to correct biased predictions. Experiments across multiple backbones and benchmarks demonstrate superior performance, particularly in zero-shot relationship composition.

## Method Summary
The method uses a pre-trained Faster R-CNN detector with frozen weights and SGG classifiers (MotifsNet, VCTree, or Transformer). CAModule is a lightweight Transformer-based network that takes statistical distributions (Object O, Co-occurrence C, Pair P, Relationship R) and batch indices to output triplet-level adjustment factors. These factors multiply the baseline logits during training to correct for distribution bias. The module uses co-occurrence as a mediator between objects and pairs, and employs GloVe-based similarity inference to extend adjustment coverage to zero-shot relationships.

## Key Results
- Achieves state-of-the-art mean recall (mR@K) rates across VG150, GQA, and OI V6 benchmarks
- Significantly improves zero-shot recall (zR@K) by composing zero-shot relationships through object similarity inference
- Outperforms baseline methods by approximately 20% in mR@50/100 metrics

## Why This Works (Mechanism)

### Mechanism 1
Triplet-level logit adjustment corrects bias more effectively than relationship-level adjustment because bias varies significantly across object pairs even within the same relationship class. CAModule generates a unique adjustment factor $\tilde{a}_{ijk}$ for every specific subject-object-predicate combination, modeling the Average Treatment Effect (ATE) by intervening on the object pair distribution conditioned on specific objects and relationship.

### Mechanism 2
Introducing a co-occurrence mediator ($C$) between object distribution ($O$) and pair distribution ($P$) isolates the causal influence of "being a plausible pair" from mere object frequency. MCCM restructures the causal graph from $O \to P$ to $O \to C \to P$, calculating co-occurrence probability to down-weight implausible but frequent-seeming pairs during adjustment factor generation.

### Mechanism 3
Optimizing the object pair distribution $P$ via attribute-based inference enables composition of "zero-shot" relationships not present in training. The system infers plausible but unobserved pairs using Rule 1 and Rule 2, calculating object similarity using Euclidean distance and Cosine similarity of GloVe features to extend adjustment factor coverage.

## Foundational Learning

- **Concept: Structural Causal Models (SCM)**
  - **Why needed:** The paper formulates SGG as a causal system ($O \to C \to P \to R$), requiring understanding of Directed Acyclic Graphs (DAGs) and intervention vs. correlation
  - **Quick check:** Can you explain why $O \to P$ might imply a different correlation than $O \to C \to P$?

- **Concept: Logit Adjustment (vs. Re-weighting)**
  - **Why needed:** CAModule operates on logits (pre-softmax scores) rather than the loss function, requiring understanding of how additive/multiplicative factors on logits shift probability distributions
  - **Quick check:** If you multiply the logit of a tail class by a factor $>1$, does the probability of head classes increase, decrease, or stay the same?

- **Concept: Long-Tail Distribution in Vision**
  - **Why needed:** The motivation stems from "head" predicates (frequent, generic) dominating "tail" predicates (rare, informative), requiring understanding of Mean Recall (mR@K) vs. Recall (R@K)
  - **Quick check:** Why might a model with high R@K still be considered a failure for a "debiasing" task?

## Architecture Onboarding

- **Component map:** Detector (Faster R-CNN) -> Classifier (MotifsNet/VCTree) -> Stats Extractor -> CAModule -> Inference Logic
- **Critical path:** Extraction of the co-occurrence matrix $C$ (Eq. 13) and correct indexing of these statistics during the training batch loop
- **Design tradeoffs:**
  - Triplet-level vs. Class-level: Creates larger lookup table (size $N_o \times N_o \times N_r$ implicitly) vs. simple class weighting (size $N_r$)
  - Explicit vs. Implicit Adjustment: CAModule learns adjustment in latent space (implicit) vs. traditional explicit formulas, allowing zero-shot compositionality but reducing interpretability
- **Failure signatures:**
  - Metric Divergence: If R@K drops drastically while mR@K rises, adjustment factors are likely too aggressive
  - Zero-shot Stagnation: If zR@K remains at baseline, check implementation of similarity inference rules and GloVe embedding loading
- **First 3 experiments:**
  1. Sanity Check: Run baseline MotifsNet on VG150, then integrate CAModule to verify mR@50/100 increases significantly (+20% improvement)
  2. Ablation on $C$: Run CAModule with mediator $C$ removed (direct $O \to P$) to check for mR@K degradation
  3. Hyperparameter sweep: Sweep $\alpha$ (weighting cosine vs. Euclidean) and $\beta$ (similarity threshold) on validation set to verify optimal values stabilize zR@K

## Open Questions the Paper Calls Out
None

## Limitations
- The triplet-level adjustment mechanism assumes bias manifests at the specific object-pair-predicate level rather than being reducible to relationship-level corrections
- The mediator-based causal chain assumes semantic co-occurrence provides independent information beyond object frequency, which may be redundant in balanced datasets
- The zero-shot inference rules assume semantic similarity (via GloVe) predicts functional relationship capability, which may fail when visually similar objects have divergent behaviors

## Confidence

- **High confidence:** Experimental superiority of CAModule over baselines on mR@K metrics (consistent +20%+ gains across multiple backbones and datasets)
- **Medium confidence:** Triplet-level adjustment mechanism's advantage over relationship-level adjustment (evidence is predicate-specific and may not generalize)
- **Medium confidence:** Mediator variable's contribution (no direct ablation showing performance without $C$ in isolation)
- **Low confidence:** Zero-shot inference rules' reliability across domains (weak corpus support, assumption-heavy)

## Next Checks

1. **Ablation study:** Implement and compare against a relationship-level adjustment baseline to verify triplet-level specificity provides measurable advantage
2. **Co-occurrence redundancy test:** Evaluate CAModule performance on a balanced dataset where object frequencies are uniform to test if mediator $C$ provides independent signal
3. **Cross-domain semantic transfer:** Test zero-shot inference rules on a dataset with different object semantics (e.g., indoor vs. outdoor scenes) to validate GloVe-based similarity assumptions