---
ver: rpa2
title: Understanding Generalization from Embedding Dimension and Distributional Convergence
arxiv_id: '2601.22756'
source_url: https://arxiv.org/abs/2601.22756
tags:
- generalization
- dimension
- embedding
- wasserstein
- intrinsic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how the geometry of learned representations
  controls generalization performance in deep neural networks. The authors develop
  a post-training generalization bound that explicitly depends on the intrinsic dimension
  of embeddings and the Lipschitz constant of the network, rather than on parameter
  counts or hypothesis class complexity.
---

# Understanding Generalization from Embedding Dimension and Distributional Convergence

## Quick Facts
- **arXiv ID:** 2601.22756
- **Source URL:** https://arxiv.org/abs/2601.22756
- **Reference count:** 40
- **Key outcome:** Post-training generalization bound linking population risk to intrinsic embedding dimension and Lipschitz sensitivity, validated across architectures.

## Executive Summary
This paper develops a post-training generalization bound that connects the population risk of a neural network to the intrinsic dimension of its learned embeddings and the Lipschitz sensitivity of its downstream mapping. Unlike traditional bounds that depend on parameter counts, this approach characterizes generalization through the geometry of representations. The theory predicts that lower intrinsic dimension embeddings lead to faster empirical-to-population convergence (via Wasserstein distance) and thus better generalization. Experiments on autoencoders, ResNets, Vision Transformers, and BERT across MNIST, CIFAR, ImageNet, and MNLI validate that final-layer intrinsic dimension is a strong empirical predictor of generalization performance.

## Method Summary
The authors establish a theoretical framework where population risk is bounded by intrinsic dimension (controlling Wasserstein convergence) and Lipschitz constants (controlling sensitivity). They validate this through experiments training various architectures on standard datasets, extracting embeddings from trained networks, and computing intrinsic dimensions using the Levina-Bickel MLE estimator. Wasserstein distances are computed via Sinkhorn approximation. The key experimental validation involves training autoencoders with varying bottleneck sizes on MNIST and measuring how intrinsic dimension affects the scaling law of Wasserstein distances as a function of sample size, comparing against the theoretical prediction that Wasserstein distance scales as n^(-1/d).

## Key Results
- Intrinsic dimension of final-layer embeddings is empirically correlated with generalization gap across multiple architectures and datasets.
- The theoretical prediction that Wasserstein distance scales as n^(-1/d) is validated experimentally on autoencoders with varying bottleneck dimensions.
- At the final layer, architectural sensitivity vanishes and the generalization bound is dominated by embedding dimension, explaining why final-layer intrinsic dimension is particularly predictive.

## Why This Works (Mechanism)
The theory works by decomposing population risk into two components: the convergence of empirical to population embedding distributions (measured by Wasserstein distance) and the sensitivity of the downstream mapping (measured by Lipschitz constants). Lower intrinsic dimension embeddings concentrate probability mass more efficiently, leading to faster convergence of empirical distributions to population distributions. This geometric property of representations directly translates to better generalization performance.

## Foundational Learning
- **Intrinsic Dimension (ID):** The minimum number of parameters needed to describe the data manifold.
  - *Why needed:* ID determines how quickly empirical embedding distributions converge to population distributions.
  - *Quick check:* Estimate ID using Levina-Bickel MLE; verify stability across different k values.

- **Wasserstein Distance:** A metric measuring the "earth mover's distance" between probability distributions.
  - *Why needed:* Provides a natural measure of convergence between empirical and population embedding distributions.
  - *Quick check:* Compute using Sinkhorn approximation; verify scaling with sample size.

- **Lipschitz Constant:** A measure of how sensitive a function is to input perturbations.
  - *Why needed:* Characterizes the sensitivity of the downstream mapping from embeddings to predictions.
  - *Quick check:* Approximate as product of spectral norms across layers.

## Architecture Onboarding

**Component Map:** Input -> Embedding Network -> Final Layer Embeddings -> Classification Head

**Critical Path:** Embedding network parameters → Final layer embeddings → Intrinsic dimension estimation → Generalization bound prediction

**Design Tradeoffs:** Traditional bounds focus on parameter count (VC dimension) vs. this approach focuses on representation geometry; parameter-efficient architectures may still have poor generalization if embeddings have high intrinsic dimension.

**Failure Signatures:** High intrinsic dimension estimates may indicate overfitting or inefficient representations; unstable Wasserstein estimates may indicate insufficient sample sizes or poor distribution separation.

**First Experiments:**
1. Train MLP autoencoder on MNIST with bottleneck dimension 64; extract embeddings and estimate intrinsic dimension.
2. Compute Sinkhorn Wasserstein distance between two disjoint subsets of embeddings (500 samples each).
3. Vary sample size n (100, 500, 1000) and plot log(Wasserstein) vs log(n) to verify n^(-1/d) scaling.

## Open Questions the Paper Calls Out
None

## Limitations
- The bound's applicability depends on successful empirical-to-population convergence, which may not hold for complex, high-dimensional data distributions.
- Intrinsic dimension estimation via MLE is sensitive to hyperparameter choices (k, neighborhood size) and can be unstable for certain datasets or architectures.
- The Lipschitz constant approximation (product of spectral norms) is a loose upper bound and may not accurately reflect true sensitivity in deep networks.

## Confidence
**Major Claims Assessment:**
- Theory linking intrinsic dimension to generalization: High confidence
- Empirical validation across architectures: Medium confidence
- Wasserstein scaling law prediction: Medium confidence

**Major Limitations:**
- Bound applicability depends on empirical-to-population convergence
- Intrinsic dimension estimation sensitivity to hyperparameters
- Loose Lipschitz constant approximations

## Next Checks
1. Replicate the Wasserstein scaling law experiments with varying k values for intrinsic dimension estimation and compare against theoretical predictions.
2. Perform ablation studies on the ResNet architecture modification (insertion point and dimensionality of intermediate layers) to assess impact on generalization and intrinsic dimension.
3. Test the generalization bound's predictive power on additional datasets and architectures, particularly those with known overfitting tendencies.