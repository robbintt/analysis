---
ver: rpa2
title: Mitigating Hallucinations in Large Vision-Language Models by Adaptively Constraining
  Information Flow
arxiv_id: '2502.20750'
source_url: https://arxiv.org/abs/2502.20750
tags:
- visual
- object
- information
- hallucinations
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of object hallucination in large
  vision-language models, where generated image descriptions contain objects not present
  in the input image. The authors propose AdaVIB, a method based on Variational Information
  Bottleneck (VIB), to mitigate this issue by constraining information flow and reducing
  overconfidence in irrelevant visual features.
---

# Mitigating Hallucinations in Large Vision-Language Models by Adaptively Constraining Information Flow

## Quick Facts
- arXiv ID: 2502.20750
- Source URL: https://arxiv.org/abs/2502.20750
- Authors: Jiaqi Bai; Hongcheng Guo; Zhongyuan Peng; Jian Yang; Zhoujun Li; Mohan Li; Zhihong Tian
- Reference count: 9
- Primary result: AdaVIB reduces object hallucinations by ~14.5% on MSCOCO compared to strong baselines while maintaining visual information

## Executive Summary
This paper addresses the critical problem of object hallucination in large vision-language models (LVLMs), where generated image descriptions contain objects not present in the input image. The authors propose AdaVIB, a method based on Variational Information Bottleneck (VIB), to mitigate this issue by constraining information flow and reducing overconfidence in irrelevant visual features. The approach adaptively controls injected noise based on the entropy of similarity distributions between soft visual tokens and LLM word embeddings. Evaluated on two object hallucination benchmarks across different model architectures, AdaVIB demonstrates consistent improvements, outperforming strong baselines like LURE by around 14.5% under both CHAIR S and CHAIR I metrics on MSCOCO.

## Method Summary
AdaVIB introduces stochastic noise into the vision-language projector using Variational Information Bottleneck to compress irrelevant visual information while preserving task-relevant features. The method consists of two linear heads producing mean (μ) and variance (Σ) parameters for Gaussian sampling, with the sampled features fed into a frozen LLM. The key innovation is an adaptive β parameter that modulates the strength of information compression based on the entropy of similarity distributions between visual tokens and word embeddings. Low entropy (sharp distribution) triggers high β for aggressive compression, while high entropy (smooth distribution) uses low β to preserve information. This adaptive mechanism addresses the overfitting problem where fine-tuned projectors develop overconfident mappings to spurious correlations, leading to hallucinations.

## Key Results
- AdaVIB reduces object hallucinations by ~14.5% on MSCOCO compared to LURE baseline under CHAIR S and CHAIR I metrics
- The method achieves consistent improvements across both MiniGPT4 and LLaVa-1.5 architectures
- Ablation studies show adaptive β provides ~5% improvement on MSCOCO and ~1.5% on POPE compared to fixed β
- VIB compression successfully reduces overconfidence in irrelevant visual features while maintaining relevant information

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Object hallucinations correlate with the smoothness of similarity distributions between visual tokens and LLM word embeddings—sharper distributions indicate overconfidence in irrelevant features.
- **Mechanism:** Overfitting on spurious correlations causes certain tokens to have disproportionately high similarity scores, making the model "overconfident" in these mappings and generating absent objects.
- **Core assumption:** Normalized dot product between visual tokens and word embeddings reliably captures feature relevance and overconfidence.
- **Evidence anchors:** Abstract confirms correlation; Figure 1 shows frozen FC produces smooth distribution with hallucination-free output vs. fine-tuned FC producing sharp distribution with hallucinations; "Vision-Language Introspection" confirms models trust linguistic priors over visual evidence.

### Mechanism 2
- **Claim:** Introducing stochastic noise via Variational Information Bottleneck compresses irrelevant visual information while preserving task-relevant features.
- **Mechanism:** VIB replaces deterministic projection with probabilistic sampling z = μ(v) + Σ(v) ⊙ ε, where the KL divergence term regularizes the projection to discard information that doesn't help predict the target.
- **Core assumption:** Irrelevant visual features contribute less to predicting correct descriptions than relevant ones, so minimizing mutual information I(v;z) while maximizing I(z;y) preferentially removes noise.
- **Evidence anchors:** Equation 5 formalizes VIB objective; Figure 4 shows KL loss decreases while similarity entropy increases during training, indicating progressive compression; no direct corpus evidence for VIB applied to hallucination.

### Mechanism 3
- **Claim:** Adaptively adjusting β per sample based on similarity distribution entropy provides better compression-prediction tradeoffs than fixed β.
- **Mechanism:** Low entropy (sharp distribution) → high β → strong compression; high entropy (smooth distribution) → low β → preserve more information. Formula: β ← −β · log(H / log(|V|)) modulates regularization strength based on per-sample overconfidence.
- **Core assumption:** Entropy of similarity distribution is a reliable proxy for "how much this sample needs compression."
- **Evidence anchors:** Equations 10-12 define entropy computation and adaptive β update; ablation shows removing adaptive β drops performance by ~5% on MSCOCO and ~1.5% on POPE; no corpus papers validate entropy-based adaptation.

## Foundational Learning

- **Concept: Variational Information Bottleneck (VIB)**
  - **Why needed here:** AdaVIB is built on VIB; understanding it is essential for reasoning about why noise injection helps and how to tune β.
  - **Quick check question:** Can you explain why minimizing I(v;z) while maximizing I(z;y) preferentially discards irrelevant information?

- **Concept: Reparameterization Trick**
  - **Why needed here:** The method uses z = μ + Σ ⊙ ε to backpropagate through stochastic sampling; understanding this is essential for implementation.
  - **Quick check question:** Why can't we directly backpropagate through a random sample z ~ p(z|v)?

- **Concept: KL Divergence Between Gaussians**
  - **Why needed here:** The compression term requires computing KL(Nθ || Nr) analytically; you need to verify the formula in Equation 8.
  - **Quick check question:** Why is the KL divergence asymmetric, and which direction should be used for regularization?

## Architecture Onboarding

- **Component map:** Input image → Vision Encoder → AdaVIB Projector (μ, Σ heads → sample z) → Concatenate with text → LLM → Output text
- **Critical path:** Vision Encoder outputs dense visual features v → AdaVIB Projector produces μ(v) and Σ(v) → sample z = μ + Σ ⊙ ε → Concatenate z with text embedding → Frozen LLM generates output text
- **Design tradeoffs:**
  - Higher β → more compression → fewer hallucinations but risk of underfitting
  - Fixed vs. adaptive β: Fixed is simpler but cannot handle sample-level variation; adaptive requires computing similarity against full vocabulary (expensive)
  - Training duration: 1 epoch to avoid overfitting; longer training may increase overconfidence
- **Failure signatures:**
  - Mode collapse: If Σ(v) collapses to near-zero, VIB degenerates to deterministic projection; check variance outputs
  - Excessive noise: If β too high, generated text becomes generic/unrelated to image; check CHAIR vs. caption quality
  - Entropy computation O(|V|): For large vocabularies, computing softmax over all tokens per sample is slow; may need approximation
- **First 3 experiments:**
  1. Reproduce frozen vs. fine-tuned projector comparison (Figure 1) to verify similarity distribution smoothness correlation on your own model checkpoint.
  2. Ablate adaptive β: Train with fixed β = 1e-7 vs. adaptive β; compare CHAIR scores and similarity entropy curves (replicate Figure 4).
  3. Stress test β sensitivity: Sweep β from 1e-9 to 1e-1 on held-out validation set (replicate Figure 5) to find optimal range for your specific LVLM backbone.

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- Reliance on single proxy metric (similarity distribution entropy) to determine compression needs, which may not generalize across architectures
- Computational overhead of O(|V|) similarity distribution computation for each sample could be prohibitive for large vocabularies
- Limited evaluation to two specific model architectures and two datasets, raising questions about broader generalization
- No direct evidence that method maintains relevant visual information while reducing hallucinations

## Confidence

**High Confidence:** Core mechanism of using VIB to reduce overconfidence in visual features is well-supported by theoretical foundations and empirical results. Correlation between similarity distribution sharpness and hallucination rates is clearly demonstrated.

**Medium Confidence:** Adaptive β mechanism shows strong empirical performance improvements, but assumption that entropy is optimal proxy for compression needs could benefit from further validation. Entropy computation is simple and intuitive, but alternatives might work equally well or better.

**Low Confidence:** Claim that AdaVIB "maintains relevant visual information" lacks direct evidence. Paper shows improved CHAIR scores but doesn't provide detailed ablation studies on how much relevant visual information is preserved versus discarded.

## Next Checks

1. **Vocabulary Size Sensitivity Analysis:** Systematically evaluate AdaVIB's performance across models with varying vocabulary sizes (30K vs. 50K vs. 100K tokens) to determine if entropy-based adaptive mechanism remains effective when similarity distribution computation becomes more expensive and potentially noisier.

2. **Cross-Architecture Generalization Test:** Apply AdaVIB to a completely different LVLM architecture (e.g., BLIP-2 with different vision encoder or convolutional vision backbone) and evaluate whether similarity distribution entropy remains a reliable indicator of hallucination propensity across architectural variations.

3. **Information Retention Quantification:** Design experiment measuring how much relevant visual information is preserved versus irrelevant information compressed by AdaVIB. This could involve controlled tests where ground truth captions contain both relevant and irrelevant objects, or using attention visualization to track which visual features influence final output.