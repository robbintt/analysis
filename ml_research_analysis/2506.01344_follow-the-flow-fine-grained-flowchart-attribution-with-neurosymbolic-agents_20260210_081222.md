---
ver: rpa2
title: 'Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents'
arxiv_id: '2506.01344'
source_url: https://arxiv.org/abs/2506.01344
tags:
- flowchart
- nodes
- node
- attribution
- flowpathagent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FlowPathAgent addresses the challenge of accurately interpreting
  flowcharts by introducing fine-grained flowchart attribution. It segments flowcharts,
  converts them into symbolic graphs, and employs a neurosymbolic agent to dynamically
  interact with the graph for generating attribution paths.
---

# Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents

## Quick Facts
- **arXiv ID**: 2506.01344
- **Source URL**: https://arxiv.org/abs/2506.01344
- **Reference count**: 40
- **Primary result**: FlowPathAgent outperforms strong baselines by 10-14% in accuracy on FlowExplainBench dataset

## Executive Summary
FlowPathAgent addresses the challenge of accurately interpreting flowcharts by introducing fine-grained flowchart attribution. The method segments flowcharts, converts them into symbolic graphs, and employs a neurosymbolic agent to dynamically interact with the graph for generating attribution paths. This approach bridges visual and symbolic representations, ensuring precise attribution of model responses to specific decision points. Experimental results on the FlowExplainBench dataset demonstrate significant performance gains over existing baselines in flowchart QA tasks.

## Method Summary
FlowPathAgent introduces a three-stage pipeline for fine-grained flowchart attribution. First, it uses FlowMask2Former for flowchart segmentation, extracting visual elements from flowchart images. Second, Flow2Mermaid VLM converts these segmented elements into symbolic graph representations. Third, a neurosymbolic agent dynamically interacts with this graph to generate attribution paths that trace how model responses are derived from specific flowchart decision points. The method addresses the challenge of visual hallucinations in flowchart QA by providing transparent attribution between visual inputs and symbolic reasoning.

## Key Results
- Outperforms strong baselines by 10-14% in accuracy on FlowExplainBench dataset
- Achieves significant reduction in visual hallucinations for flowchart QA tasks
- Demonstrates effective bridging between visual flowchart representations and symbolic graph structures

## Why This Works (Mechanism)
The approach works by creating a bidirectional bridge between visual and symbolic representations of flowcharts. The segmentation stage captures fine-grained visual elements, while the symbolic conversion preserves the logical structure of decision paths. The neurosymbolic agent can then traverse this graph structure to generate precise attribution paths, ensuring that model responses can be traced back to specific visual elements and decision points. This transparency addresses the common problem of black-box model behavior in flowchart interpretation.

## Foundational Learning
- **Flowchart segmentation with FlowMask2Former**: Needed to accurately extract visual elements from flowchart images; quick check: evaluate segmentation masks on varied flowchart styles
- **Symbolic graph conversion with Flow2Mermaid VLM**: Needed to transform visual elements into logical graph structures; quick check: verify graph topology matches original flowchart logic
- **Neurosymbolic agent dynamics**: Needed for intelligent traversal of symbolic graphs to generate attribution paths; quick check: trace agent paths against ground truth decision sequences
- **Visual-symbolic bridging**: Needed to connect visual inputs with logical reasoning outputs; quick check: validate attribution paths match visual decision points
- **Fine-grained attribution**: Needed to pinpoint specific visual elements responsible for model outputs; quick check: measure attribution precision on test cases
- **Dynamic interaction with graphs**: Needed for adaptive reasoning over flowchart structures; quick check: test agent performance on complex flowcharts with nested decisions

## Architecture Onboarding

**Component Map**: Flowchart Image -> FlowMask2Former (Segmentation) -> Flow2Mermaid VLM (Symbolic Conversion) -> Neurosymbolic Agent (Graph Interaction) -> Attribution Paths

**Critical Path**: The critical path flows from flowchart image through segmentation to symbolic conversion, then through the neurosymbolic agent for attribution generation. Each stage must succeed for the final attribution to be accurate.

**Design Tradeoffs**: The method trades computational complexity for accuracy and transparency. The three-stage pipeline adds overhead compared to direct image-to-text approaches, but provides fine-grained attribution. The reliance on synthetic training data (Mermaid flowcharts) enables controlled benchmarking but may limit real-world generalization.

**Failure Signatures**: Segmentation failures will propagate through the pipeline, causing incorrect symbolic representations. Ambiguous flowchart structures may lead to multiple valid attribution paths. The neurosymbolic agent may fail to find optimal paths in highly complex flowcharts with many decision branches.

**First 3 Experiments**:
1. Baseline comparison: Evaluate FlowPathAgent against existing flowchart QA methods on FlowExplainBench
2. Ablation study: Test performance with segmentation, symbolic conversion, or agent components removed
3. Attribution quality assessment: Manually verify that generated attribution paths correctly trace model responses to flowchart elements

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can FlowPathAgent be extended to handle hand-drawn flowcharts with similar attribution performance?
- Basis in paper: [explicit] Limitations section states "our benchmark... does not yet encompass all real-world variations, such as hand-drawn diagrams" and "scaling them for attribution remains an open area of research."
- Why unresolved: No existing high-quality hand-drawn flowchart QA datasets with attribution annotations; the synthetic training approach for FlowMask2Former may not generalize to hand-drawn variations.
- What evidence would resolve it: Evaluation on a hand-drawn flowchart attribution benchmark with human annotations, showing comparable F1 scores to FlowExplainBench results.

### Open Question 2
- Question: How can neurosymbolic attribution be adapted for dynamic or interactive flowcharts with sequential updates and conditional dependencies?
- Basis in paper: [explicit] Limitations section states "our approach is designed for static flowcharts, and extending it to dynamic or interactive systems presents an opportunity for further research."
- Why unresolved: Current graph representation assumes static structure; dynamic systems require handling evolving topologies and temporal state changes.
- What evidence would resolve it: A modified FlowPathAgent architecture that tracks temporal changes and maintains attribution consistency across flowchart modifications.

### Open Question 3
- Question: Would integrating reinforcement learning or self-supervised learning improve FlowPathAgent's adaptability across diverse flowchart formats?
- Basis in paper: [explicit] Limitations section suggests "integrating reinforcement learning or self-supervised learning techniques could enhance model adaptability and generalization."
- Why unresolved: Current supervised fine-tuning on FlowVQA may limit generalization to out-of-distribution flowchart styles not seen during training.
- What evidence would resolve it: Ablation studies comparing RL/self-supervised variants against the current SFT approach on held-out style variations.

### Open Question 4
- Question: How does FlowPathAgent's performance degrade when applied to flowcharts with non-standard visual conventions or ambiguous edge routing?
- Basis in paper: [inferred] The paper acknowledges flowcharts have "diverse notational conventions, implicit relationships, and misinferred steps," but FlowExplainBench uses Mermaid-generated flowcharts with standardized styling.
- Why unresolved: Real-world flowcharts may violate the visual patterns learned by FlowMask2Former and Flow2Mermaid VLM during synthetic training.
- What evidence would resolve it: Evaluation on flowcharts sourced from real business documentation, engineering diagrams, or informal sketches with non-Mermaid conventions.

## Limitations
- Relies heavily on accurate flowchart segmentation, which can be challenging for complex or poorly structured flowcharts
- Performance gains based on a single dataset (FlowExplainBench), raising questions about generalizability
- Neurosymbolic agent's dynamic interaction with the graph is not fully detailed in implementation
- Does not address potential biases in flowchart interpretation or scalability to extremely large flowcharts

## Confidence
- **High**: Performance improvement on FlowExplainBench dataset
- **Medium**: Effective bridging between visual and symbolic representations (limited by lack of implementation details)
- **Low**: Generalizability to other datasets and real-world applications

## Next Checks
1. Evaluate FlowPathAgent on multiple flowchart QA datasets to assess generalizability
2. Conduct ablation studies to determine the contribution of each component (segmentation, graph conversion, neurosymbolic agent) to overall performance
3. Test the method on flowcharts with varying complexity and structure to identify potential failure modes