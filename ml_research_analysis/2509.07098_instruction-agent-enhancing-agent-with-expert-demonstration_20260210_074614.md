---
ver: rpa2
title: 'Instruction Agent: Enhancing Agent with Expert Demonstration'
arxiv_id: '2509.07098'
source_url: https://arxiv.org/abs/2509.07098
tags:
- agent
- action
- agents
- tasks
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Instruction Agent, a GUI agent that leverages
  expert demonstrations to automate complex tasks that previous agents failed to complete.
  The agent extracts step-by-step instructions from a single human demonstration and
  executes them strictly, avoiding mistakes through built-in verifier and backtracker
  modules.
---

# Instruction Agent: Enhancing Agent with Expert Demonstration
## Quick Facts
- arXiv ID: 2509.07098
- Source URL: https://arxiv.org/abs/2509.07098
- Reference count: 15
- Primary result: Achieved 60% success rate on 20 challenging OSWorld tasks that top-ranked agents failed completely

## Executive Summary
Instruction Agent is a GUI automation system that leverages expert demonstrations to complete complex tasks that previous agents failed to accomplish. The agent extracts step-by-step instructions from a single human demonstration and executes them strictly, avoiding mistakes through built-in verifier and backtracker modules. The verifier checks if each action succeeds, while the backtracker recovers from errors by restoring previous states. On 20 challenging OSWorld tasks that all top-ranked agents failed, Instruction Agent achieved a 60% success rate, compared to 0% for competing agents.

## Method Summary
The system works by first capturing a human demonstration of the target task, then extracting sequential instructions from this demonstration. During execution, the agent follows these extracted instructions step-by-step while continuously verifying the success of each action. If the verifier detects a failure, the backtracker module restores the previous valid state and attempts alternative approaches. This strict adherence to demonstrated instructions combined with verification and recovery mechanisms allows the agent to avoid common pitfalls that cause other agents to fail on complex GUI tasks.

## Key Results
- Achieved 60% success rate on 20 challenging OSWorld tasks
- All top-ranked competing agents achieved 0% success on the same tasks
- Ablation studies showed verifier and backtracker modules were critical for performance

## Why This Works (Mechanism)
The system's effectiveness stems from its strict adherence to expert demonstrations combined with real-time verification and error recovery. By extracting precise step-by-step instructions from human demonstrations and executing them faithfully, the agent avoids the exploratory errors that plague other approaches. The verifier module provides continuous feedback about action success, while the backtracker enables recovery from failures without restarting the entire task. This creates a robust execution pipeline that can handle the complexity and variability of real-world GUI interactions.

## Foundational Learning
- **Instruction Extraction**: Converting human demonstrations into executable step sequences - needed for translating human expertise into machine-readable format; quick check: verify extracted instructions match demonstration steps
- **Action Verification**: Real-time validation of GUI interactions - needed to detect failures early and prevent cascading errors; quick check: confirm verifier correctly identifies both successful and failed actions
- **State Recovery**: Ability to restore previous valid states - needed for graceful error handling without task restart; quick check: test backtracker can restore to known good state after various failures
- **Strict Execution**: Following extracted instructions without deviation - needed to leverage expert knowledge reliably; quick check: verify agent doesn't deviate from extracted instruction sequence

## Architecture Onboarding
**Component Map:** User Demo -> Instruction Extractor -> Execution Engine -> GUI -> Verifier -> Backtracker -> State Manager

**Critical Path:** Instruction Extraction → Execution → Verification → (Conditional) Backtracking → State Recovery

**Design Tradeoffs:** The system prioritizes reliability over exploration by strictly following demonstrated instructions rather than learning from trial-and-error. This training-free approach trades potential performance improvements from reinforcement learning for immediate usability with expert demonstrations.

**Failure Signatures:** 
- Verifier failure: Action does not produce expected GUI state change
- Backtracker failure: Unable to restore previous valid state
- Execution failure: Instruction sequence cannot be completed as demonstrated

**First 3 Experiments:**
1. Test instruction extraction accuracy by comparing extracted steps against ground truth demonstration
2. Validate verifier module by intentionally triggering known failure conditions
3. Evaluate backtracker recovery by forcing failures at various execution points

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single benchmark (OSWorld) without broader GUI automation dataset comparisons
- Instruction extraction generalizability across different GUI types remains unverified
- Heavy dependence on demonstration quality without addressing ambiguous or incomplete demonstrations

## Confidence
High confidence in core methodology and OSWorld task performance
Medium confidence in generalizability claims due to limited benchmark scope
Low confidence in "training-free" characterization without clarification of instruction extraction requirements

## Next Checks
1. Test Instruction Agent on additional GUI automation benchmarks beyond OSWorld to assess generalizability across different application types and interaction patterns

2. Conduct ablation studies specifically isolating the instruction extraction component's performance to determine how much of the success depends on high-quality demonstrations versus the verifier/backtracker modules

3. Evaluate the system's performance with intentionally flawed or ambiguous demonstrations to understand its robustness and error recovery capabilities in realistic usage scenarios