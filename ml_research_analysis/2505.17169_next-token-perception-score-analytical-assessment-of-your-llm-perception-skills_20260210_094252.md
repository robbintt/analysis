---
ver: rpa2
title: 'Next Token Perception Score: Analytical Assessment of your LLM Perception
  Skills'
arxiv_id: '2505.17169'
source_url: https://arxiv.org/abs/2505.17169
tags:
- ntps
- downstream
- linear
- perception
- lora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the Next Token Perception Score (NTPS), a
  metric to measure the alignment between autoregressive pretraining and downstream
  perception tasks. The core idea is that representations learned for next-token prediction
  may not align well with the subspaces needed for perception tasks, and NTPS quantifies
  this misalignment by measuring the overlap between feature subspaces.
---

# Next Token Perception Score: Analytical Assessment of your LLM Perception Skills

## Quick Facts
- arXiv ID: 2505.17169
- Source URL: https://arxiv.org/abs/2505.17169
- Reference count: 40
- Primary result: NTPS measures alignment between autoregressive pretraining and perception tasks, correlating with linear probe accuracy and predicting LoRA gains.

## Executive Summary
This paper introduces the Next Token Perception Score (NTPS), a metric quantifying the alignment between autoregressive pretraining and downstream perception tasks by measuring subspace overlap between learned representations. Under a linear regime, the authors prove that NTPS bounds the excess loss when using autoregressive features for perception, providing theoretical justification for its predictive power. Empirically, NTPS strongly correlates with linear probe accuracy across diverse NLP datasets and models, and reliably predicts accuracy gains from LoRA fine-tuning—tasks with low NTPS benefit most from adaptation.

## Method Summary
NTPS is computed by extracting hidden states from a pretrained model, constructing covariance matrices from these representations, and solving two generalized eigenvalue problems to obtain perception and autoregressive subspaces (U and V). The metric is then calculated as the normalized Frobenius norm of the projection of U onto V's column space. The method requires collecting statistics over the training set, solving eigenvalue problems, and evaluating the overlap for various layer selections and subspace dimensions.

## Key Results
- NTPS correlates strongly with linear probe accuracy across 12 NLP datasets and eight models (270M-8B parameters).
- NTPS reliably predicts LoRA fine-tuning gains—lower NTPS indicates larger potential accuracy improvements.
- NTPS increases after LoRA fine-tuning, particularly in larger models, suggesting improved alignment with perception subspaces.

## Why This Works (Mechanism)

### Mechanism 1
A low NTPS score signals large potential gains from LoRA fine-tuning because it measures poor subspace overlap between autoregressive features and perception-task features. When overlap is low, frozen representations lack task-relevant directions that LoRA adaptation can introduce by rotating the subspace toward the perception objective.

### Mechanism 2
NTPS monotonically correlates with downstream linear-probe performance because, under the paper's linearized setting, the excess regression loss of using autoregressive features instead of perception features is bounded by 1 − NTPS. Higher overlap reduces this upper bound on excess loss, aligning with higher accuracy in practice.

### Mechanism 3
LoRA fine-tuning increases NTPS, especially in larger models, because LoRA updates the QKV projection matrices, modifying the representation subspace. These updates align the autoregressive subspace more closely with the perception subspace, raising NTPS.

## Foundational Learning

- **Generalized eigenvalue problem**: Required to derive perception and autoregressive subspaces (U and V) as top-k eigenvectors of specific problems. Quick check: Can you state the form of a generalized eigenvalue problem and explain why eigenvectors span an optimal subspace for a given objective?

- **Subspace projection and overlap**: NTPS is defined via an orthogonal projector onto V's column space and the Frobenius norm of the projection of U onto that subspace. Quick check: How would you interpret NTPS = 0.3 versus NTPS = 0.9 in terms of representational alignment?

- **LoRA (Low-Rank Adaptation)**: Used to test whether subspace alignment improves after adaptation. Quick check: What parameter count and rank does LoRA add per targeted projection layer?

## Architecture Onboarding

- **Component map**: Input tokenizer → LLM transformer → Extract mean token representation from final block → Compute covariance terms → Solve two generalized eigenproblems for U and V → Project U onto V → Compute NTPS via normalized Frobenius norm.

- **Critical path**: 
  1. Forward pass to collect hidden states at layer l.
  2. Build L1 and L2 selection matrices per sequence.
  3. Accumulate statistics over the dataset.
  4. Solve generalized eigenvalue problems.
  5. Compute NTPS using top-k directions.

- **Design tradeoffs**:
  - Layer selection: Earlier layers capture more syntactic structure; later layers more task-relevant semantics.
  - Subspace dimension k: Too small under-represents task information; too large introduces noise from irrelevant directions.
  - Current approach sweeps over layers and k without principled selection.

- **Failure signatures**:
  - NTPS near 0 with strong downstream performance suggests non-linear or attention-mediated transfer not captured by linear theory.
  - NTPS fails to predict LoRA gain if the model has already saturated alignment.
  - Small models show NTPS decrease post-LoRA, indicating capacity constraints breaking the alignment mechanism.

- **First 3 experiments**:
  1. Reproduce NTPS vs. linear-probe accuracy correlation on 3 of the 12 datasets and 2 model sizes; log Spearman r.
  2. Measure NTPS before and after LoRA adaptation for at least 2 datasets; verify the 71/96 trend direction.
  3. Test prediction: For a held-out dataset, rank models by NTPS and compare predicted LoRA-gain ordering to actual gain.

## Open Questions the Paper Calls Out

- **How can attention mechanisms be incorporated into NTPS to provide a more precise formulation for transformer-based models?** Current NTPS ignores attention mechanisms central to transformers, potentially limiting accuracy. A theoretical extension incorporating attention (e.g., linear attention) showing improved correlation would resolve this.

- **What is the principled strategy for selecting optimal NTPS configurations (layer, subspace dimension k) without exhaustive search?** Current approach requires computing NTPS across all layers and k values, then selecting the configuration with highest Spearman correlation—computationally expensive. A predictive model linking model architecture properties to optimal k and layer selection would help.

- **Why does NTPS decrease after LoRA fine-tuning in small models (OpenELM-270M/450M)?** Table 2 shows NTPS decreases in small models post-LoRA. Authors speculate these models sacrifice next-token prediction for higher downstream performance due to limited capability. Analysis of next-token prediction pre/post LoRA in small vs. large models would verify this trade-off.

- **Does NTPS generalize beyond classification tasks to generation, retrieval, or structured prediction?** All 12 downstream datasets are classification tasks. Perception subspaces for generative or retrieval tasks may have fundamentally different properties. Experiments on generation benchmarks, retrieval tasks, or structured prediction would test generalization.

## Limitations
- The theoretical bound in Theorem 2 is only proven for a linearized regime and may not hold for highly non-linear architectures.
- The mechanism linking NTPS to LoRA gains depends on the assumption that LoRA primarily acts by rotating the subspace toward perception directions.
- NTPS occasionally decreases after LoRA in small models, raising questions about the mechanism's universality.

## Confidence
- NTPS predicts LoRA gains: **Medium** - Strong inverse correlations per model, but weak external validation and occasional decrease in small models.
- NTPS correlates with linear probe accuracy: **High** - Statistically significant across models, but bound's practical informativeness not stressed.
- NTPS increases after LoRA: **Medium** - Compelling in larger models, but occasional decrease in small models.

## Next Checks
1. Replicate the NTPS vs. linear-probe accuracy correlation on three new datasets and two additional model sizes not in the original set; report Spearman r and compare to reported range.
2. For LoRA fine-tuning, measure NTPS before and after adaptation on two new datasets; verify that the 71/96 trend direction holds and that the magnitude of NTPS increase correlates with accuracy gain.
3. Test the prediction that ranking models by NTPS correctly orders them by LoRA gain on a held-out dataset; report rank correlation between predicted and actual gains.