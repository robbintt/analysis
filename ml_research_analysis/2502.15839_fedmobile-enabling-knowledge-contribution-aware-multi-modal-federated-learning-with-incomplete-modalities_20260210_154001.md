---
ver: rpa2
title: 'FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated Learning
  with Incomplete Modalities'
arxiv_id: '2502.15839'
source_url: https://arxiv.org/abs/2502.15839
tags:
- data
- multimodal
- learning
- modalities
- missing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes FedMobile, a knowledge contribution-aware multimodal
  federated learning framework that reconstructs missing modality features using cross-node
  feature information and selectively aggregates high-quality model updates. The key
  innovation is the use of knowledge distillation-driven cross-node modality reconstruction
  and a clustered Shapley value mechanism for generator contribution evaluation.
---

# FedMobile: Enabling Knowledge Contribution-aware Multi-modal Federated Learning with Incomplete Modalities

## Quick Facts
- arXiv ID: 2502.15839
- Source URL: https://arxiv.org/abs/2502.15839
- Authors: Yi Liu; Cong Wang; Xingliang Yuan
- Reference count: 40
- Primary result: Achieves up to 4.3% improvement over baselines when up to 90% of modality information is missing

## Executive Summary
FedMobile addresses the challenge of training multimodal models in federated settings where clients may have incomplete or missing modalities. The framework reconstructs missing modality features using cross-node information through knowledge distillation in a shared latent feature space, then selectively aggregates high-quality model updates using a clustered Shapley value mechanism. Experimental results demonstrate robust performance across five benchmark datasets, maintaining accuracy even with extreme modality incompleteness while keeping computational overhead comparable to standard federated learning approaches.

## Method Summary
FedMobile operates through a three-phase process: First, local clients train generators to reconstruct missing modality features by distilling knowledge from available modalities in a shared latent space using KL divergence minimization. Second, the server clusters client generators and computes Shapley values for cluster representatives to evaluate contribution quality. Third, the server aggregates both the global model and generators using contribution-aware weights that balance local performance with estimated global impact. This approach enables effective learning from incomplete modalities while preventing low-quality updates from degrading model performance.

## Key Results
- Maintains robust learning performance with up to 90% missing modality information
- Achieves up to 4.3% improvement over state-of-the-art baselines
- Keeps computational and communication overhead comparable to standard federated learning
- Validated across five multimodal benchmark datasets including USC-HAD, MM-IMU, HHAR, ADL, and ADM

## Why This Works (Mechanism)

### Mechanism 1
FedMobile reconstructs missing modalities in a shared latent feature space rather than input space, improving robustness through cross-node feature information. Local generators conditioned on random labels produce latent features optimized via KL divergence to align with features extracted from available modalities, enforcing a common feature subspace. This works when available modalities contain sufficient semantic information to approximate missing modality distributions, but fails if modalities are strictly independent.

### Mechanism 2
The framework uses Clustered Shapley Values to weight generator aggregation, filtering out low-quality feature reconstructions more effectively than simple averaging. By clustering client generators using K-means on generated features and computing SV only for cluster representatives using a proxy dataset, it reduces computational cost while maintaining fairness. This assumes K-means effectively groups generators by quality and the proxy dataset is representative, but may fail if the proxy distribution diverges significantly from real data.

### Mechanism 3
Global model aggregation weights combine local performance and estimated global contribution, improving convergence over standard FedAvg. The dynamic weight α_k for each node incorporates local accuracy and estimated improvement to the global model, approximated by local loss reduction. This assumes local loss reduction validly proxies global impact, but may fail in highly non-IID scenarios where local and global objectives conflict.

## Foundational Learning

- **Knowledge Distillation (Feature-based):** Understanding how student networks mimic teacher output distributions is crucial for grasping how missing data is "hallucinated" reliably. Quick check: Can you explain why minimizing KL divergence between generated and extracted feature distributions aligns modalities?

- **Shapley Value (Game Theory):** Essential for understanding how the system quantifies "fairness" and "value" of individual client contributions in a coalition. Quick check: Why is calculating exact Shapley Value typically infeasible for large federated networks, necessitating clustering approximation?

- **Multimodal Fusion:** Understanding how different sensor modalities are combined (concatenated or otherwise) is required to see why missing one branch breaks the pipeline. Quick check: How does concatenation fusion fail when one input tensor is missing or zero-filled?

## Architecture Onboarding

- **Component map:** Client: Local Feature Extractors → Local Generator → Local Predictor; Server: Global Model ← Shapley Evaluator ← Clustering Module ← Global Generator
- **Critical path:** 1) Local Train: Client trains Generator to match Feature Extractor outputs via Distillation Loss. 2) Cluster: Server runs K-means on client feature updates. 3) Evaluate: Server computes Shapley values on cluster representatives. 4) Aggregate: Server aggregates Generators and Global Model using contribution-aware weights.
- **Design tradeoffs:** Trades raw fidelity of input-space reconstruction for efficiency and privacy of latent-space reconstruction; adds server computational overhead to prevent low-quality updates from poisoning the model.
- **Failure signatures:** Mode Collapse (generator produces identical features for all inputs), Cluster Degeneration (K-means finds only one cluster), Divergence (global accuracy oscillates).
- **First 3 experiments:** 1) Sanity Check: Run FedMobile on USC-HAD dataset with 0% missing modalities to establish upper bound. 2) Ablation (SV): Disable Clustered SV module with 60% missing modalities to quantify contribution awareness value. 3) Robustness Test: Evaluate on ADM dataset with 90% missing modalities to compare against "Zero-padding" baseline and verify 4.3% gain.

## Open Questions the Paper Calls Out

### Open Question 1
To what extent do more complex generative architectures improve reconstruction fidelity compared to the standard MLP generator? The paper uses MLPs to minimize overhead but doesn't quantify accuracy gains from advanced generators like GANs. This remains unresolved as authors prioritized efficiency demonstration over exploring performance ceilings.

### Open Question 2
How does FedMobile behave when a specific modality is missing across all participating nodes (100% global missing)? The framework relies on a shared latent feature space and is tested up to 90% missing, but doesn't address the "cold-start" failure case where no ground-truth features exist for a modality. This requires testing graceful degradation or error handling.

### Open Question 3
What is the empirical vulnerability of reconstructed latent features to membership inference attacks? The paper claims privacy is preserved because "latent representations contain abstracted information" but provides no quantitative security analysis. This requires membership inference attacks on aggregated generator weights to determine if they reveal training data membership.

## Limitations

- Reliance on shared latent feature space assumption may fail when modalities are truly independent
- Clustering approximation for Shapley values introduces approximation error without sensitivity analysis
- Proxy dataset representativeness is assumed but not thoroughly validated across diverse data distributions

## Confidence

- **High Confidence:** Local generator training via KL divergence minimization is well-grounded in established knowledge distillation literature with sound mathematical formulation
- **Medium Confidence:** Clustered Shapley Value approach is theoretically valid but depends heavily on clustering quality and proxy dataset representativeness
- **Medium Confidence:** Aggregation weight formulation follows reasonable federated learning principles, but local loss reduction proxy may break in highly non-IID scenarios

## Next Checks

1. **Latent Space Correlation Test:** Systematically evaluate generator reconstruction quality across datasets with varying degrees of modality correlation, measuring KL divergence trends as correlation decreases.

2. **Proxy Dataset Sensitivity Analysis:** Test FedMobile's performance using proxy datasets with different distributions from true data, quantifying impact on Shapley value accuracy and final model performance.

3. **Cross-Modality Transfer Evaluation:** Evaluate whether generators trained on one type of missing modality can effectively reconstruct a different modality when both are missing, testing generality of latent feature subspace assumption.