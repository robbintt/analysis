---
ver: rpa2
title: 'Quantifying Symptom Causality in Clinical Decision Making: An Exploration
  Using CausaLM'
arxiv_id: '2503.19394'
source_url: https://arxiv.org/abs/2503.19394
tags:
- causal
- concept
- text
- medical
- symptoms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of quantifying the causal influence
  of symptoms on clinical diagnosis predictions, moving beyond correlation to provide
  a more robust and interpretable approach. The core method idea involves using the
  CausaLM framework to generate counterfactual text representations where a target
  symptom (e.g., "chest pain") is effectively "forgotten," allowing for the estimation
  of its causal effect on model predictions.
---

# Quantifying Symptom Causality in Clinical Decision Making: An Exploration Using CausaLM

## Quick Facts
- **arXiv ID**: 2503.19394
- **Source URL**: https://arxiv.org/abs/2503.19394
- **Reference count**: 7
- **Primary result**: TReATE successfully captures causal influence of symptoms on disease predictions, with significant shifts observed for diseases like Bronchitis and Anemia when "chest pain" is considered.

## Executive Summary
This work addresses the problem of quantifying the causal influence of symptoms on clinical diagnosis predictions, moving beyond correlation to provide a more robust and interpretable approach. The core method idea involves using the CausaLM framework to generate counterfactual text representations where a target symptom (e.g., "chest pain") is effectively "forgotten," allowing for the estimation of its causal effect on model predictions. This is achieved by employing Textual Representation-based Average Treatment Effect (TReATE) to measure the shift in disease probability distribution when the symptom is present versus absent. Results show that TReATE successfully captures the causal influence of symptoms on disease predictions, with significant shifts observed for diseases like Bronchitis and Anemia when "chest pain" is considered. This approach provides deeper insights into model decision-making and has the potential to inform more trustworthy and interpretable clinical decision support tools.

## Method Summary
The study quantifies causal influence of symptoms (specifically "chest pain") on diagnostic predictions using counterfactual text representations that "forget" target concepts. The approach uses the DDXPlus dataset (1,025,603 train / 134,530 test examples) with 49 disease classes. Treatment concept presence is flagged via keywords ("chest", "sterum"). The method employs TReATE for causal effect and CONEXP as correlation baseline. The training procedure involves fine-tuning BERT with an added TC head, gradient reversal layer (λ=6), and combined loss (MLM + NSP + CE), then freezing BERT-TC to train a linear layer with sparsemax activation for disease classification. Results are evaluated by comparing TReATE from BERT-CF vs. regular BERT baseline over 15,000 samples.

## Key Results
- TReATE successfully captures the causal influence of symptoms on disease predictions
- Significant causal shifts observed for diseases like Bronchitis and Anemia when "chest pain" is considered
- TReATE scores show disease-level differences from correlation baseline (CONEXP)

## Why This Works (Mechanism)
The method works by using CausaLM to create counterfactual representations where the target symptom is "forgotten" through adversarial training. The gradient reversal layer ensures the treatment concept (chest pain) cannot be reliably classified from the representations while preserving the ability to predict disease labels. This allows TReATE to estimate the causal effect by comparing disease predictions with and without the symptom information. The sparsemax activation in the final layer produces sparse disease probability distributions that better reflect the discrete nature of medical diagnoses.

## Foundational Learning
- **CausaLM framework**: Why needed - To generate counterfactual representations that remove specific concepts while preserving other information. Quick check - Verify TC classification loss remains near random (50%) after training.
- **TReATE (Textual Representation-based Average Treatment Effect)**: Why needed - To measure causal effect as the difference in expected outcomes between treatment and control groups at the representation level. Quick check - Confirm TReATE values are positive for diseases where symptom presence should increase likelihood.
- **Gradient reversal layer**: Why needed - To "unlearn" the target concept during training while maintaining other predictive capabilities. Quick check - Monitor TC loss to ensure it doesn't decrease significantly below baseline.
- **Sparsemax activation**: Why needed - To produce sparse probability distributions over discrete disease classes rather than diffuse softmax outputs. Quick check - Verify output entropy is lower than softmax would produce.
- **CONEXP (Conditional Expectation)**: Why needed - As a correlation baseline to distinguish causal effects from mere associations. Quick check - Compare CONEXP and TReATE values to identify cases where correlation ≠ causation.
- **Dialogue-format text preprocessing**: Why needed - To standardize clinical narratives into consistent input format for the model. Quick check - Ensure symptom keywords are consistently detected across different dialogue templates.

## Architecture Onboarding

**Component Map**: DDXPlus Dataset -> BERT-TC (fine-tuned with gradient reversal) -> BERT-CF (linear probe with sparsemax) -> TReATE/CONEXP computation

**Critical Path**: Data preprocessing → BERT-TC training with gradient reversal → BERT-CF training → TReATE computation → Disease-level analysis

**Design Tradeoffs**: The use of representation-level counterfactuals (rather than text-level modifications) offers computational efficiency but may miss nuanced semantic effects. The gradient reversal approach balances concept forgetting with disease prediction capability, but imperfect forgetting could bias causal estimates.

**Failure Signatures**: 
- TC loss decreases significantly below baseline (~0.5) → gradient reversal not working properly
- Softmax yields near-uniform disease distributions → sparsemax not correctly implemented or disease classes not well-separated
- TReATE values near zero across all diseases → either concept not properly "forgotten" or symptom has minimal causal influence

**First Experiments**:
1. Train BERT-TC and verify TC loss stabilizes around 0.5-0.6 while MLM/NSP loss decreases
2. Implement and validate sparsemax layer produces sparse outputs (low entropy) over 49 classes
3. Compute TReATE and CONEXP on small validation set to verify they produce different values for diseases where symptom should matter

## Open Questions the Paper Calls Out
- **Multiple concepts**: Can the CausaLM framework be extended to analyze multiple treatment concepts simultaneously, rather than isolating single symptoms? The current study only examined chest pain as a single treatment concept.
- **Forgetting fidelity**: How faithfully does the gradient reversal layer achieve complete concept "forgetting," and can residual concept information be detected in the counterfactual representations? The TC classification loss only increased from 0.627 to 0.53, suggesting imperfect forgetting.
- **Text-level vs. representation-level**: Would richer text-level counterfactual interventions yield different causal inferences compared to the representation-level manipulations used in this study? Representation-level manipulation may not capture how clinicians actually reason when symptoms are absent.
- **Cross-corpus robustness**: How robust are these causal inference methods across diverse clinical corpora from different healthcare systems and linguistic contexts? DDXPlus is synthetic and may not reflect real clinical note complexity.

## Limitations
- Reliance on keyword-based concept identification for treatment concept is brittle and may not capture symptom mentions reliably
- Missing specification of BERT variant (base vs. clinical/biomedical) which could affect performance
- No clinical validation step to verify causal estimates align with expert medical judgment

## Confidence
- **Methodology soundness**: Medium - The conceptual framework is sound but implementation details are incomplete
- **Causal claims**: Medium - Observed effects are plausible but not validated against clinical expertise
- **Reproducibility**: Low - Missing critical details on hyperparameters, preprocessing, and baseline training

## Next Checks
1. **Validate keyword-based symptom identification**: Test the keyword approach on a held-out sample with manual annotation to quantify recall and precision for symptom mentions
2. **Confirm sparsemax implementation and disease distribution**: Reproduce the BERT-CF model with sparsemax and verify disease output distributions match reported entropy and sparsity
3. **Replicate TReATE vs. CONEXP disease-level scores**: Rerun causal and correlational effect estimates on the same 15,000 samples to check consistency of disease-level TReATE values (e.g., Bronchitis ≈0.27)