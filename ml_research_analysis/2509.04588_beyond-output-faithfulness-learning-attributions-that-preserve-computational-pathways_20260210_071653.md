---
ver: rpa2
title: 'Beyond Output Faithfulness: Learning Attributions that Preserve Computational
  Pathways'
arxiv_id: '2509.04588'
source_url: https://arxiv.org/abs/2509.04588
tags:
- internal
- activation
- faithfulness
- layers
- external
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses a critical flaw in existing feature attribution
  methods: high scores on external faithfulness metrics like insertion and deletion
  can be achieved by explanations that exploit alternative computational pathways
  inconsistent with the model''s actual reasoning. To solve this, the authors propose
  Faithfulness-guided Ensemble Interpretation (FEI), which optimizes both external
  faithfulness through Ensemble Quantile Optimization (a differentiable formulation
  of insertion/deletion curves) and internal faithfulness through selective gradient
  clipping (which preserves activation patterns).'
---

# Beyond Output Faithfulness: Learning Attributions that Preserve Computational Pathways

## Quick Facts
- **arXiv ID**: 2509.04588
- **Source URL**: https://arxiv.org/abs/2509.04588
- **Reference count**: 40
- **Primary result**: Unconstrained optimization of insertion/deletion metrics can produce spurious attributions (92-98% on blank images) by exploiting alternative computational pathways; FEI achieves state-of-the-art external scores while maintaining low activation deviation.

## Executive Summary
This paper identifies a critical flaw in existing feature attribution methods: high scores on insertion and deletion metrics can be achieved through explanations that exploit alternative computational pathways inconsistent with the model's actual reasoning. The authors propose Faithfulness-guided Ensemble Interpretation (FEI), which jointly optimizes external faithfulness through Ensemble Quantile Optimization (a differentiable formulation of insertion/deletion curves) and internal faithfulness through selective gradient clipping that preserves activation patterns. Across VGG and ResNet on ImageNet and CUB-200-2011, FEI achieves state-of-the-art insertion/deletion scores while maintaining significantly lower activation deviation compared to unconstrained optimization. The key finding is that both external and internal faithfulness are essential—FEI_None attains the highest external scores but exhibits 6× higher activation deviation and produces spurious attributions on blank images, while constrained FEI variants achieve strong external performance with robust internal preservation.

## Method Summary
FEI jointly optimizes external faithfulness (insertion/deletion metrics) through Ensemble Quantile Optimization and internal faithfulness (activation preservation) through selective gradient clipping. EQO parameterizes retention maps for multiple quantile levels jointly, enforcing monotonic consistency via non-negative increments to approximate the full insertion/deletion curve. ClipGrad examines the relationship between gradient direction and activation deviation at each neuron, blocking updates that would push activations away from their original values. The method uses Adam optimizer for 100 iterations per quantile level with β=0.1 constraint, and aggregates attributions from all quantile levels. The framework is implemented as a differentiable module that can be applied to any CNN architecture.

## Key Results
- FEI variants achieve state-of-the-art insertion/deletion scores across VGG16 and ResNet50 on ImageNet and CUB-200-2011
- FEI_None attains highest insertion scores but exhibits 92-98% spurious attributions on blank images
- Constrained FEI variants maintain 0-0.4% spurious attribution rate while achieving top external scores
- FEI_VM achieves 6.6× lower MSE and 2× higher cosine similarity on VGG16 compared to FEI_None
- Late-layer-only clipping fails as early deviations cascade; early-layer constraints are essential

## Why This Works (Mechanism)

### Mechanism 1: External Metric Gaming via Alternative Pathways
Insertion/deletion metrics alone are insufficient because they can be maximized through alternative computational pathways that preserve output behavior while altering internal reasoning. An unconstrained optimizer discovers perturbations that reroute computation through different feature detectors, achieving equivalent outputs via distinct internal circuits. This is demonstrated by FEI_None, which attains the highest insertion scores while producing visually noisy artifacts and 92-98% spurious attributions on blank images. Large activation deviations indicate pathway switching rather than benign noise.

### Mechanism 2: Ensemble Quantile Optimization for Faithful Gradient Flow
Directly modeling the full insertion/deletion curve via differentiable ensemble quantiles provides richer, more stable gradients than single-step or surrogate approximations. Rather than approximating the metric with a single perturbation step or L1 sparsity prior, EQO parameterizes retention maps α_q for multiple quantile levels jointly, enforcing monotonic consistency via non-negative increments. This aligns the optimization objective with the actual evaluation metric, exposing pathway-switching behaviors that single-point approximations discard.

### Mechanism 3: Selective Gradient Clipping Prevents Pathway Divergence
Blocking activation-disrupting gradient updates preserves the original computational pathway without requiring explicit regularization penalties or per-layer hyperparameter tuning. ClipGrad examines the relationship between gradient direction and activation deviation at each neuron, clipping updates that push activations away from their original values. This is derived from a saliency-weighted L1 internal loss whose gradient simplifies to a universal clipping rule. Early-layer deviations cascade and amplify, making early-layer constraints essential.

## Foundational Learning

- **Insertion and Deletion Metrics**
  - Why needed here: The paper's central critique targets these metrics; understanding their definition is prerequisite to understanding why they can be gamed.
  - Quick check question: Given an attribution map M, what does a high insertion score (V_Ins) indicate about the relationship between highly-ranked features and model confidence?

- **Activation Patterns as Computational Proxies**
  - Why needed here: The paper uses layer-wise activation similarity as a tractable proxy for "computational pathway." Without this conceptual grounding, the internal faithfulness constraint appears arbitrary.
  - Quick check question: Why might large activation deviations in later layers be more concerning than deviations in early layers, according to the superposition hypothesis?

- **Gradient Clipping for Constrained Optimization**
  - Why needed here: ClipGrad is the technical mechanism enforcing internal faithfulness. Understanding how selective clipping differs from penalty-based regularization clarifies why it avoids hyperparameter instability.
  - Quick check question: In the VM variant, what condition causes the gradient to be set to zero for neuron i?

## Architecture Onboarding

- **Component map**: EQO Module -> Forward Pass Cache -> ClipGrad Layer -> Optimization Loop
- **Critical path**: 
  1. Initialize α_q_i = 0 for all quantiles
  2. For each quantile q_i ∈ {0.1, 0.3, 0.5, 0.7, 0.9}:
     - For t=1 to T iterations:
       - Compute perturbed input: x̃ = α ⊙ x + (1-α) ⊙ R
       - Forward pass → cache activations, compute L_ins = -ϕ(x̃) + L_con
       - Backward pass → ClipGrad modifies gradients at each conv layer
       - Update α
  3. Aggregate final M = Σ α_q_i
- **Design tradeoffs**:
  - VM vs. IBM: VM enforces strict bidirectional preservation (0.1% failure rate) but slightly lower external scores. IBM provides maximal flexibility (best insertion scores) by blocking only spurious activation of inactive neurons.
  - Sequential vs. multi-branch architectures: AVM causes catastrophic failure (93-95%) on sequential networks (VGG, AlexNet) due to activation accumulation, but succeeds (0.1%) on multi-branch (ResNet, GoogLeNet) where skip connections stabilize flow.
  - Early vs. late layer clipping: Constraining only later layers fails because early deviations cascade. Early-only (1-16) offers a practical compromise with slightly better external scores.
- **Failure signatures**:
  - High insertion + noisy artifacts + high spurious attribution rate: Unconstrained optimization (FEI_None) gaming the metric.
  - Sharp edge-emphasized attributions on sequential networks: AVM variant causing activation accumulation.
  - Collapsed insertion despite low deletion: Late-layer-only clipping; early deviations have already propagated.
- **First 3 experiments**:
  1. Run FEI_IBM on VGG16-ImageNet with cascading layer randomization; confirm attributions degrade from semantic to noise as layers are randomized.
  2. Apply all FEI variants plus baselines to blank inputs; verify FEI_None produces >90% spurious attributions while constrained variants stay <0.5%.
  3. On ResNet50, measure MSE and cosine similarity per layer; confirm gradient-based methods and FEI_None show elevated MSE starting from early layers, with dramatic divergence at Layer4.

## Open Questions the Paper Calls Out

- **Can the FEI framework be extended to Vision Transformers, and what would serve as an appropriate analogue to activation preservation?**
  - Basis: [explicit] "extending it to other architectures, such as Vision Transformers, is a key step; for ViTs, attention pattern alignment may serve as a natural analogue to pathway preservation"
  - Why unresolved: Current implementation focuses on CNNs with ReLU activations; ViTs have fundamentally different architectures with attention mechanisms rather than convolutional layers.
  - What evidence would resolve it: Implementation of FEI for ViTs using attention pattern alignment, demonstrating comparable internal-external faithfulness trade-offs.

- **What alternative internal metrics beyond activation preservation could better capture computational pathway consistency?**
  - Basis: [explicit] "Future work should explore alternative internal metrics (e.g., semantic detector activation) and formally analyze their trade-offs"
  - Why unresolved: Activation preservation is a practical proxy, but the paper does not establish whether it is optimal or how it compares to alternatives.
  - What evidence would resolve it: Systematic comparison of multiple internal metrics against ground-truth pathway interventions, or theoretical analysis bounding the relationship between each metric and true pathway consistency.

- **How should practitioners systematically select among ClipGrad variants (VM, IVM, AVM, IBM) for new architectures?**
  - Basis: [inferred] The paper shows AVM fails catastrophically on sequential networks but succeeds on multi-branch networks, yet offers only heuristic guidance.
  - Why unresolved: The architectural sensitivity analysis is empirical; no theoretical framework predicts which variant will succeed on a given architecture.
  - What evidence would resolve it: A formal characterization linking network properties to optimal constraint variant, validated across diverse architectures.

## Limitations

- The paper assumes activation deviation is a reliable proxy for "alternative computational pathways," but this may conflate benign noise with meaningful rerouting.
- While demonstrating that unconstrained optimization produces spurious attributions on blank images, the paper does not establish whether internal constraints might suppress legitimate alternative reasoning strategies.
- All experiments use CNN vision models; generalization to transformers or other architectures remains untested.

## Confidence

- **High Confidence**: The empirical finding that unconstrained FEI_None produces spurious attributions on blank images (92-98%) while constrained variants maintain 0-0.4% is directly measurable and reproducible.
- **Medium Confidence**: The claim that internal faithfulness constraints do not harm external performance is supported by the data, but the mechanism by which constraints prevent gaming versus simply regularizing optimization is not fully characterized.
- **Low Confidence**: The assertion that activation deviation directly measures "alternative computational pathways" requires additional validation. The paper provides correlational evidence but not causal proof.

## Next Checks

1. **Neuron Ablation Validation**: Select highly-attributed neurons in FEI_None explanations, ablate them, and measure whether output behavior changes despite preserved insertion scores. This would directly test whether alternative pathways exist.

2. **Constraint Sensitivity Analysis**: Systematically vary the ClipGrad threshold and β quantile constraint across a wider range. Map the full Pareto frontier between insertion/deletion scores and activation deviation.

3. **Cross-Architecture Generalization**: Apply FEI to a transformer-based vision model (e.g., ViT) and measure whether the same pattern of spurious attributions on blank images appears without constraints, and whether ClipGrad variants transfer effectively.