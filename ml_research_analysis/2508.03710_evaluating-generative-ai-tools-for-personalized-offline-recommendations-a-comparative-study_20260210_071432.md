---
ver: rpa2
title: 'Evaluating Generative AI Tools for Personalized Offline Recommendations: A
  Comparative Study'
arxiv_id: '2508.03710'
source_url: https://arxiv.org/abs/2508.03710
tags:
- user
- recommendations
- will
- software
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates the performance and user satisfaction of five
  generative AI tools (Gemini, Phi-4, Mistral, Qwen 2.5, and LLaMA 3.2) in generating
  personalized offline activity recommendations for software developers at risk of
  repetitive strain injury (RSI). Following the Goal/Question/Metric (GQM) paradigm,
  the study uses predefined user profiles and intervention scenarios to generate recommendations.
---

# Evaluating Generative AI Tools for Personalized Offline Recommendations: A Comparative Study

## Quick Facts
- arXiv ID: 2508.03710
- Source URL: https://arxiv.org/abs/2508.03710
- Reference count: 0
- One-line primary result: LLM performance correlates with user satisfaction in personalized offline recommendations for RSI-prone developers

## Executive Summary
This study evaluates five generative AI models (Gemini, Phi-4, Mistral, Qwen 2.5, and LLaMA 3.2) for generating personalized offline activity recommendations aimed at software developers at risk of repetitive strain injury. Using the Goal/Question/Metric paradigm with predefined user profiles and intervention scenarios, the research compares quantitative metrics (precision, recall, F1-score, MCC-score) against qualitative user satisfaction measures. The study involved 80 Computer Science students evaluating ten daily recommendations from each LLM. Results indicate a significant correlation between technical performance metrics and user satisfaction, with one model achieving notably higher F1-score and MCC-score while receiving superior user satisfaction ratings.

## Method Summary
The study employs a comparative evaluation framework following the Goal/Question/Metric (GQM) paradigm to assess five generative AI tools in personalized recommendation scenarios. Researchers created predefined user profiles representing software developers at risk of RSI and generated ten daily recommendations (five morning, five afternoon) for each LLM. Evaluation combined quantitative metrics (precision, recall, F1-score, MCC-score) with qualitative measures including facial expression analysis and System Usability Scale (SUS) surveys. The participant pool consisted of 80 final-year Computer Science students who evaluated the recommendations based on relevance and satisfaction levels.

## Key Results
- One LLM achieved significantly higher F1-score and MCC-score compared to other models
- Users reported higher satisfaction with recommendations from the top-performing LLM
- Results support the hypothesis that higher technical performance correlates with greater user satisfaction

## Why This Works (Mechanism)
The effectiveness stems from the alignment between technical recommendation accuracy and user-perceived relevance. When LLMs generate recommendations that match predefined user profiles and intervention scenarios with high precision and recall, users perceive these suggestions as more relevant and satisfying. The combination of quantitative performance metrics and qualitative satisfaction measures creates a comprehensive evaluation framework that captures both objective recommendation quality and subjective user experience.

## Foundational Learning
- Goal/Question/Metric (GQM) paradigm - why needed: provides structured framework for evaluating software engineering artifacts; quick check: ensure metrics align with stated goals
- Precision/Recall/F1-score - why needed: standard information retrieval metrics for recommendation systems; quick check: verify calculation formulas match evaluation context
- MCC-score (Matthews Correlation Coefficient) - why needed: balanced measure for binary classification even with class imbalance; quick check: confirm binary encoding of recommendation relevance
- Facial expression analysis - why needed: objective biometric measure of user satisfaction; quick check: validate facial analysis tool calibration
- System Usability Scale (SUS) - why needed: standardized questionnaire for subjective user satisfaction; quick check: ensure proper administration and scoring

## Architecture Onboarding
Component Map: User Profiles -> LLM Models -> Recommendation Generation -> Evaluation Metrics -> User Feedback
Critical Path: User profile definition → LLM recommendation generation → quantitative evaluation → qualitative satisfaction assessment → correlation analysis
Design Tradeoffs: Predefined profiles vs. real user data; controlled lab study vs. field deployment; technical metrics vs. subjective satisfaction
Failure Signatures: Low F1-score with high SUS suggests disconnect between technical quality and user perception; high technical metrics with low satisfaction indicates potential metric misalignment
First Experiments: 1) Baseline comparison using random recommendation generation; 2) Cross-validation with different user profile variations; 3) A/B testing with real-time feedback collection

## Open Questions the Paper Calls Out
None

## Limitations
- Findings may not generalize beyond Computer Science students to broader populations
- Self-reported satisfaction measures may introduce bias
- Predefined user profiles may not capture real-world complexity and diversity

## Confidence
- Quantitative performance metrics: High confidence
- User satisfaction correlations: Medium confidence
- Comparative LLM performance: Medium confidence
- Personalization effectiveness: Low confidence

## Next Checks
1. Conduct field studies with actual software developers experiencing RSI symptoms to validate lab-based findings in real-world settings
2. Expand evaluation to include diverse demographic groups and occupational backgrounds beyond Computer Science students
3. Implement A/B testing with real-time user feedback loops to assess long-term satisfaction and recommendation relevance over extended usage periods