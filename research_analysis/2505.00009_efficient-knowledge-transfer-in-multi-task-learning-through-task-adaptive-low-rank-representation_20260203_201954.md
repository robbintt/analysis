---
title: Efficient Knowledge Transfer in Multi-Task Learning through Task-Adaptive Low-Rank
  Representation
arxiv_id: '2505.00009'
source_url: https://arxiv.org/abs/2505.00009
generated_at: '2026-02-03T20:19:54'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Efficient Knowledge Transfer in Multi-Task Learning through Task-Adaptive Low-Rank Representation

*Xiao Zhang; Kangsheng Wang; Tianyu Hu; Huimin Ma*

---

> ### ðŸ“Š Quick Facts
> *   **Quality Score:** 8/10
> *   **Model Architecture:** Qwen Base
> *   **Total Tasks Evaluated:** 16 diverse tasks
> *   **Training Scope:** 8 source tasks (11.9K â€“ 4.1M samples)
> *   **Evaluation Scope:** 5 unseen tasks
> *   **Key Innovation:** Fast-slow weights mechanism & Zero-initialized attention
> *   **Citations:** 40

---

## Executive Summary

Current Multi-Task Learning (MTL) frameworks utilizing standard Prompt Tuning face a critical bottleneck: they struggle to effectively model task heterogeneity, leading to the phenomenon of "knowledge mixing" where task-specific nuances are overshadowed by shared information. This is particularly challenging because standard prompt tuning relies on keeping Pre-trained Language Model (PLM) parameters frozen to maintain parameter efficiency. Consequently, existing methods often fail to balance the retention of shared knowledge with the need for task-specific adaptation, limiting performance when dealing with highly diverse tasks.

The authors propose **Task-Adaptive Low-Rank Representation (TA-LoRA)**, a novel framework built upon the Qwen architecture that decouples shared knowledge from task-specific features using a fast-slow weights mechanism. TA-LoRA utilizes low-rank representations to manage task heterogeneity, designating "slow weights" to encode cross-task shared knowledge while employing "fast weights" to capture task-specific nuances, thereby preventing interference. Additionally, the method introduces a zero-initialized attention mechanism to ensure training stability during the warm-up phase and employs a hierarchical learning structure where general features are processed in early layers and task-specific features are prioritized in deeper layers (specifically layers 14, 21, and 28).

TA-LoRA achieved **State-of-the-Art (SOTA)** performance across 16 diverse tasks, demonstrating robustness in both full-data and few-shot learning scenarios. The model was trained on 8 source tasks with dataset sizes ranging from 11.9K to 4.1M samples and was successfully evaluated on 5 unseen tasks. Ablation studies utilizing cosine similarity analysis on the AFQMC dataset provided empirical evidence for the framework's design; results showed negligible initial similarity in base models (Layer 14: -0.0015%) that increased significantly in deeper layers during training, confirming that task-specific adaptation is effectively isolated to the network's later stages.

This research significantly advances the field of efficient MTL by demonstrating that superior performance can be achieved without the computational overhead of fine-tuning entire PLMs. By successfully overcoming the limitations of standard Prompt Tuning through the decoupling of fast and slow weights, TA-LoRA provides a scalable blueprint for handling task heterogeneity in resource-constrained environments.

---

## Key Findings

*   **State-of-the-Art Performance:** TA-LoRA achieved SOTA results across 16 diverse tasks, validating its effectiveness in both full-data and few-shot learning scenarios.
*   **Superior Heterogeneity Modeling:** The model effectively captures task heterogeneity using low-rank representations, successfully overcoming the limitations inherent in standard Prompt Tuning.
*   **High Parameter Efficiency:** By keeping Pre-trained Language Model (PLM) parameters frozen, the framework maintains high parameter efficiency.
*   **Training Stability:** The introduction of zero-initialized attention minimized disruption during the warm-up phase of training, leading to more stable convergence.

---

## Methodology

The proposed method, **Task-Adaptive Low-Rank Representation (TA-LoRA)**, is a Multi-Task Learning framework built upon Prompt Tuning. Its core components include:

*   **Low-Rank Representation:** Utilizes a low-rank structure to model task heterogeneity.
*   **Fast-Slow Weights Architecture:**
    *   **Slow Weight:** Encodes shared knowledge across all tasks.
    *   **Fast Weight:** Captures task-specific nuances to prevent knowledge mixing.
*   **Zero-Initialized Attention:** A specific mechanism employed to ensure training stability throughout the process.

---

## Technical Details

The paper presents TA-LoRA, which leverages low-rank representations to model task heterogeneity while overcoming limitations in standard Prompt Tuning.

**Architecture & Strategy**
*   **Parameter Efficiency:** The architecture maintains high efficiency by keeping Pre-trained Language Model (PLM) parameters frozen.
*   **Stability:** Employs a zero-initialized attention strategy to minimize disruption during the warm-up phase.
*   **Base Model:** Utilizes the **Qwen** base architecture.

**Hierarchical Learning Mechanism**
The model implements a hierarchical approach to knowledge disentanglement:
*   **Early Layers:** Focus on general shared knowledge.
*   **Deeper Layers (e.g., 14, 21, 28):** Prioritize task-specific features, effectively disentangling shared and task-specific knowledge.

---

## Contributions

1.  **Novel Framework:** Introduction of TA-LoRA, a new MTL framework that advances standard Prompt Tuning by capturing task heterogeneity through efficient low-rank representations.
2.  **Decoupling Mechanism:** Development of a fast-slow weights mechanism that decouples shared knowledge from task-specific nuances.
3.  **Stability Optimization:** Proposal of a zero-initialized attention mechanism to optimize training stability and protect the integrity of original prompts.

---

## Results

*   **Overall Performance:** Achieved State-of-the-Art (SOTA) performance across 16 diverse tasks, demonstrating robustness in both full-data and few-shot learning scenarios.
*   **Cosine Similarity Analysis (AFQMC Dataset):**
    *   Showed negligible initial similarity between base models (e.g., Layer 14: -0.0015%).
    *   Similarity increased significantly in deeper layers (14 and 28) during training.
    *   **Conclusion:** Confirms that task-specific adaptation occurs in later layers.
*   **Training & Evaluation Scope:**
    *   **Training:** Utilized 8 source tasks with data sizes ranging from 11.9K to 4.1M samples.
    *   **Evaluation:** Performed on 5 unseen tasks.

---

**References:** 40 citations