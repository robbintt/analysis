# Causal Estimation of Tokenisation Bias

*Pietro Lesci; Clara Meister; Thomas Hofmann; Andreas Vlachos; Tiago Pimentel*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **Citations** | 40 |
| **Magnitude of Bias** | Up to **17x** probability amplification |
| **Core Method** | Regression Discontinuity Design (RDD) |
| **Key Insight** | Tokenisation is a causal structural element, not a neutral preprocessor. |

---

> ### ðŸ’¡ Executive Summary
>
> This research addresses the fundamental yet often overlooked issue of "tokenisation bias," which arises because practical language models (LMs) are not invariant to the choice of tokenizer. While the theoretical goal of an LM is to model a consistent probability distribution over character-strings, current architectures approximate this by modeling subword-strings, introducing a mismatch based on tokeniser selection.
>
> This problem is critical because tokenisation is frequently treated as a neutral preprocessing step; however, this study demonstrates that it acts as a structural bottleneck where arbitrary vocabulary design choices can systematically skew the model's understanding and probability assignments, violating the principle of invariance for identical textual inputs.
>
> The paperâ€™s key innovation is the introduction of a causal inference framework to isolate and quantify the impact of specific vocabulary components. To overcome the challenge of estimating counterfactuals, the authors employ Regression Discontinuity Design (RDD). By framing vocabulary inclusion as a "treatment" within a Potential Outcomes Framework, the methodology exploits ranking cutoffs in tokenisation algorithms to calculate the Average Treatment Effect (ATE).
>
> The study identified "Probability Amplification," finding that the mere inclusion of a subword can increase the probability of its corresponding characters by up to **17 times**. These findings necessitate a reevaluation of how LMs are audited and designed, suggesting that future progress requires accounting for tokenisation as a primary driver of model behavior.

---

## Key Findings

*   **Definition of Tokenisation Bias:** The study formally defines tokenisation bias as the mismatch in probability distribution caused by tokeniser choice, noting that practical models are not invariant to this choice.
*   **Significant Probability Amplification:** The research reveals a startling magnitude of bias: the inclusion of a subword in a vocabulary can increase the probability of its corresponding characters by up to **17 times**.
*   **Consistency Across Architectures:** Experiments showed that tokenisation bias consistently affects model outputs across various model scales, vocabulary sizes, and tokenisation algorithms.
*   **Critical Design Choice:** The research identifies tokenisation as a critical design decision that substantially influences language modeling behavior, rather than a neutral preprocessing step.

## Methodology

The authors utilized a quasi-experimental approach to estimate causal effects from observational data:

*   **Causal Inference Framework:** The authors frame tokenisation bias as a causal effect to estimate the impact of including a subword in the vocabulary on character probabilities.
*   **Regression Discontinuity Design (RDD):** This method overcomes the limitation of models typically being trained with only one fixed tokeniser by approximating a controlled experiment.
*   **Exploitation of Ranking Cutoffs:** The methodology leverages ranking cutoffs in tokenisation algorithms. It compares outcomes of subwords just above and below the threshold to estimate the effect of inclusion versus exclusion.

## Contributions

*   **Formalization and Identification:** Provided a formal definition of tokenisation bias and identified the specific bias resulting from arbitrary vocabulary size cutoffs.
*   **Novel Application of Causal Methods:** Introduced the application of Regression Discontinuity Design (RDD) to NLP evaluation to rigorously isolate variables typically treated as static during training.
*   **Quantitative Benchmarking:** Offered the first quantifiable evidence on the magnitude of tokenisation bias, providing concrete metrics (e.g., 17x probability increase) for the field.

## Technical Details

The paper proposes a formal causal framework to quantify 'tokenisation bias', treating the tokeniser as a structural element that causally influences the probability distribution of a Language Model.

**Core Framework Definitions**
*   **Fundamental LM Goal:** A distribution over character-strings, approximated by modeling subword-strings.
*   **The Tokeniser (T):** Defined as a tuple comprising a vocabulary (**V**), a tokenisation function (**tau**), and a detokenisation function (**tau_hat**).

**Potential Outcomes Framework**
To address the inability to compare log-probabilities under different tokenisations, the authors utilize:
*   **Treatment ($W_v$):** Indicates if a subword is in the vocabulary.
*   **Outcome ($Y_W(v)$):** The expected log-probability of the associated character-string.
*   **Counterfactual Calculation:** The method calculates probabilities by comparing an observed model against one trained without a specific subword.
*   **Target Metric:** The Average Treatment Effect (ATE) across a population of subwords.

## Results

The primary metric defined is Tokenisation Bias, representing the causal effect of including a subword in the vocabulary.

*   **Probability Amplification:** The study found that the inclusion of a subword causes 'Probability Amplification,' increasing the probability of its corresponding characters by up to **17 times** compared to the counterfactual scenario where the subword is absent.
*   **Robustness:** This bias was shown to be consistent across various model scales, vocabulary sizes, and tokenisation algorithms.
*   **Violation of Invariance:** Qualitatively, the results demonstrate that tokenisation is not a neutral preprocessing step but a critical design decision that violates invariance. Models assign different probabilities to the same character string depending on how the tokeniser segments it.

---
**Analysis based on 40 citations.**