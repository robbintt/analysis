---
title: 'LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization
  via LLM Agents'
arxiv_id: '2505.21963'
source_url: https://arxiv.org/abs/2505.21963
generated_at: '2026-02-03T12:29:25'
quality_score: 9
citation_count: 39
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents

*Taro Yano; Yoichi Ishibashi; Masafumi Oyamada*

---

> ### ðŸ“Š Quick Facts
> | Metric | Detail |
> | :--- | :--- |
> | **Performance Gain** | +9.0 point increase in tool-use accuracy |
> | **Quality Score** | 9/10 |
> | **Core Innovation** | Autonomous, multi-agent post-training pipeline construction |
> | **Scaling Insight** | Data scaling enables cost-effective discovery; Model scaling introduces challenges |
> | **Citations** | 39 references |

---

## Executive Summary

Post-training large language models (LLMs) to achieve high performance on specific tasks involves a complex orchestration of stages, including Supervised Fine-Tuning (SFT), Preference Learning, and Model Merging. Currently, constructing these effective pipelines relies heavily on manual, human-driven experimentation. This approach is not only labor-intensive and time-consuming but also prone to human bias and cognitive limitations, often leading to suboptimal configurations. As the configuration space expands with new techniques and datasets, the inability to systematically and autonomously explore the interplay between these variables has become a significant bottleneck in developing state-of-the-art models.

The authors introduce **LaMDAgent**, a novel multi-agent framework that fully automates the end-to-end construction and optimization of LLM post-training pipelines. Technically, the system operates on a continuous four-step cycle: **Action Enumeration**, **Action Selection**, **Model Evaluation**, and **Memory Update**. The framework defines "Objects" (concrete models and datasets) and "Actions" (functions that transform objects, such as SFT or merging). It utilizes an LLM-based agent to select actions by decomposing the decision into Action Type Selection and Object Selection, guided by a text-based memory that summarizes historical trials. To ensure robust exploration, LaMDAgent incorporates bias mitigation strategies, such as exploration directives to prevent mode collapse, and normalizes multi-task metrics using a weighted sum approach.

LaMDAgent demonstrated significant efficacy, achieving a **9.0-point increase in tool-use accuracy** over baseline methods while successfully preserving instruction-following capabilities. Beyond performance gains, the framework discovered effective post-training strategies that are frequently overlooked during conventional manual exploration. A critical component of the study involved scaling law analysis, which revealed that scaling data size enables cost-effective pipeline discovery; optimal pipelines identified on smaller datasets transfer effectively to larger ones. Conversely, the study found that scaling model size introduces new challenges, as pipelines optimized for smaller models do not transfer seamlessly to larger models, complicating the exploration process at scale.

This research signifies a paradigm shift in LLM development by moving from human-in-the-loop tuning to autonomous, agent-driven optimization. LaMDAgent addresses a critical underexplored area in AI research, providing a systematic method to navigate the exponentially growing complexity of post-training configurations.

---

## Key Findings

*   **Performance Improvement:** LaMDAgent achieved a **9.0-point increase in tool-use accuracy** while successfully preserving instruction-following capabilities.
*   **Discovery of Novel Strategies:** The framework uncovered effective post-training strategies that are frequently overlooked during conventional human-driven exploration processes.
*   **Scaling Law Analysis:**
    *   **Data Size:** Scaling data size enables cost-effective pipeline discovery, as pipelines found on smaller datasets transfer effectively to larger ones.
    *   **Model Size:** Scaling model size introduces new challenges to the exploration process, implying that optimal pipelines for smaller models do not transfer as seamlessly as those discovered via data scaling.

---

## Methodology

LaMDAgent utilizes a **multi-agent framework** powered by Large Language Models to autonomously construct and optimize full post-training pipelines. The framework is designed to systematically explore the entire configuration space with minimal human intervention.

Key aspects of the methodology include:

*   **Comprehensive Exploration:** The system explores diverse model generation techniques, including Supervised Fine-Tuning (SFT), Preference Learning, and Model Merging.
*   **Configuration Space:** It searches through various datasets and hyperparameter configurations to find the optimal setup.
*   **Feedback Loops:** The process relies on **task-based feedback loops** to iteratively discover high-performing pipelines.

---

## Technical Details

### Architecture & Cycle
LaMDAgent operates on a continuous 4-step cycle to optimize the pipeline:

1.  **Action Enumeration:** Identifying potential operations (e.g., applying SFT to a specific dataset).
2.  **Action Selection:** Deciding which action to take next.
3.  **Model Evaluation:** Assessing the performance of the resulting model.
4.  **Memory Update:** Logging the results to inform future decisions.

### Core Components

*   **Objects & Actions:**
    *   **Objects:** Concrete models and datasets.
    *   **Actions:** Functions that map objects to models (e.g., training, merging).
*   **Memory System ($m_t$):** A text-based memory that summarizes past trials to guide the agent's future choices.
*   **Decomposed Selection:** Action Selection is split into two inference steps:
    1.  **Action Type Selection:** Choosing the type of operation.
    2.  **Object Selection:** Choosing the specific model or dataset to apply it to.

### Optimization Strategies

*   **Bias Mitigation:** The framework employs exploration directives to prevent mode collapse and specific instructions to counter selection bias against intermediate models.
*   **Scoring Metric:** Utilizes a weighted sum formula to normalize multi-task metrics:
    $$s_{multi} = \sum \alpha_k \cdot s^{single}_k$$
*   **Scaling Laws:**
    *   **Data Size Scaling:** Used to reduce computational costs during exploration.
    *   **Model Size Scaling:** Analyzed for efficiency, though found to be more challenging than data scaling.

---

## Contributions

*   **Autonomous Pipeline Optimization:** Introduction of LaMDAgent, a novel framework that addresses the underexplored challenge of automating the construction of complete post-training pipelines.
*   **Comprehensive Search Strategy:** A method for systematically exploring the complex interplay between various post-training stages, datasets, and hyperparameters using LLM-based agents.
*   **Insights into Computational Efficiency:** Empirical analysis of how scaling data and model sizes affects the computational cost and difficulty of pipeline exploration.

---

## Results

*   **Accuracy Gains:** LaMDAgent achieved a **9.0-point increase in tool-use accuracy** compared to baseline methods.
*   **Capability Preservation:** Successfully maintained instruction-following capabilities alongside improved tool usage.
*   **Strategic Discovery:** The agent identified novel post-training strategies often missed by human researchers.
*   **Scaling Efficiency:**
    *   **Data Scaling:** Confirmed as a viable strategy for cost-effective discovery; pipelines transfer well from small to large datasets.
    *   **Model Scaling:** Presented difficulties; optimal pipelines for smaller models failed to transfer seamlessly to larger models, highlighting a complexity in scaling up.