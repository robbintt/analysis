---
title: 'RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning
  over Graph'
arxiv_id: '2505.03173'
source_url: https://arxiv.org/abs/2505.03173
generated_at: '2026-02-03T13:21:54'
quality_score: 8
citation_count: 10
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning over Graph

*Sameer Malik; Moyuru Yamada; Ayush Singh; Dishank Aggarwal*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score**: 8/10
> *   **References**: 10 citations
> *   **Key Datasets**: NExT-QA, EgoSchema
> *   **Performance**: 61.8% (NExT-QA), 90.2% (EgoSchema)
> *   **Efficiency**: Retrieves only 5-10 frames
> *   **Context Optimization**: Avoids processing 200k+ tokens
> *   **Core Innovation**: Spatio-temporal graph memory + Compositional reasoning

---

## Executive Summary

Large Multi-modal Models (LMMs) face significant computational bottlenecks and context window limitations when processing long-duration videos, as converting raw video streams into tokens can result in sequences exceeding 200,000 tokens. Furthermore, existing methods struggle to maintain coherent tracking of entities and relationships over extended periods, often failing to answer complex queries that require multi-hop reasoning or cross-frame object tracking. This research addresses the critical gap in efficient, long-video comprehension, seeking a method that bypasses the need to process entire video archives while maintaining high fidelity in understanding complex spatial and temporal dynamics.

The authors introduce **RAVU (Retrieval Augmented Video Understanding)**, a novel framework that decouples memory storage from reasoning by transforming raw video inputs into a spatio-temporal graph. In this architecture, nodes represent objects annotated with textual descriptions, while edges represent interactions or events, effectively serving as a long-term memory store. The system decomposes complex queries into distinct reasoning steps and utilizes specific, pre-designed reasoning functionsâ€”such as searching for specific interactions or filtering object attributesâ€”to traverse this graph. This retrieval-augmented approach identifies and retrieves only the most relevant keyframes (typically 5-10), ensuring that the LMM is fed only the essential visual context required to generate an answer rather than the overwhelming volume of the original video.

RAVU achieves State-of-the-Art (SOTA) performance on the NExT-QA and EgoSchema datasets, quantifiably outperforming current baselines. Specifically, the model attains an accuracy of 61.8% on NExT-QA and 90.2% on EgoSchema. Notably, this high performance is accomplished with extreme efficiency, as the framework generates accurate answers by retrieving a highly limited subset of data. The results highlight the model's specific strength in complex cognitive tasks, demonstrating superior capability in multi-hop reasoning and robust object tracking compared to traditional approaches that process significantly more data.

The significance of RAVU lies in its validation that complex video understanding can be achieved effectively through intelligent compositional reasoning over structured graph representations rather than exhaustive visual processing. By bridging the gap in long-video comprehension for LMMs, this work provides a scalable solution to the inherent context window limitations and latency issues plaguing current video AI systems. The successful integration of spatio-temporal graphs with retrieval augmentation establishes a new paradigm for entity tracking and relational reasoning, likely influencing future research toward more memory-efficient and computationally feasible architectures for video analysis.

---

## Key Findings

*   **SOTA Performance:** RAVU outperforms current State-of-the-Art (SOTA) methods and baselines on NExT-QA and EgoSchema datasets.
*   **High Efficiency:** The framework achieves high performance while retrieving a limited number of frames (5-10).
*   **Overcoming Limitations:** The approach effectively overcomes the limitations of current Large Multi-modal Models (LMMs) in processing long-duration videos.
*   **Complex Reasoning:** RAVU is particularly effective at handling queries that require multi-hop reasoning and tracking objects across multiple frames.

---

## Methodology

The RAVU framework operates through a structured, four-step process designed to optimize video understanding:

*   **Graph Construction:**
    Constructs a spatio-temporal graph representation of the video to capture spatial and temporal relationships.

*   **Memory Mechanism:**
    Uses the graph as a long-term memory store to track objects and actions over time, avoiding redundant processing of raw streams.

*   **Query Decomposition:**
    Decomposes complex queries into a sequence of distinct reasoning steps to manage complexity.

*   **Graph-Based Retrieval:**
    Executes reasoning steps on the spatio-temporal graph to retrieve relevant key information efficiently.

---

## Technical Details

RAVU proposes a retrieval-augmented framework for long-duration video understanding that separates memory and reasoning processes to optimize computational efficiency.

**Architecture Overview**
*   **Spatio-Temporal Graph:** The architecture converts videos into a graph where nodes represent objects (with textual descriptions) and edges represent interactions or events.
*   **Long-Term Memory:** This graph serves as a long-term memory store generated once to avoid the computational bottleneck of processing raw video streams (e.g., avoiding sequences of 200k+ tokens).

**Reasoning & Retrieval Process**
*   **Query Processing:** The system decomposes queries into specific reasoning steps.
*   **Graph Traversal:** It utilizes pre-designed reasoning functions to traverse the graph for multi-hop reasoning and entity tracking.
*   **Context Selection:** Only relevant key frames (5-10) identified by the graph are retrieved and fed into a Large Multi-modal Model (LMM) for final answer generation.

---

## Results

RAVU delivers superior performance on benchmark datasets, proving that efficiency does not come at the cost of accuracy.

*   **Benchmark Dominance:** RAVU outperforms current State-of-the-Art (SOTA) methods on both the NExT-QA and EgoSchema datasets.
*   **Metric Achievement:** The model achieved **61.8% accuracy on NExT-QA** and **90.2% on EgoSchema**.
*   **Efficiency Validation:** The framework achieves high performance by retrieving a highly limited subset of data (5-10 frames), effectively addressing LMM context window limitations for long-duration videos.
*   **Complex Task Handling:** It demonstrates strong capabilities in complex reasoning tasks, specifically multi-hop reasoning and object tracking across time.

---

## Contributions

*   **Framework Introduction:** Introduction of RAVU (Retrieval Augmented Video Understanding), a new framework designed to bridge the gap in long-video comprehension for LMMs.
*   **Structural Integration:** Integration of compositional reasoning with a spatio-temporal graph structure to enable tracking of entities and relationships.
*   **Efficiency Demonstration:** Demonstration that complex video understanding can be achieved effectively using a significantly reduced set of retrieved frames.