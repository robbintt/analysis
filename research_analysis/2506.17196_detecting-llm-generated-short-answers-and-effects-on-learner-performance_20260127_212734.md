---
title: Detecting LLM-Generated Short Answers and Effects on Learner Performance
arxiv_id: '2506.17196'
source_url: https://arxiv.org/abs/2506.17196
generated_at: '2026-01-27T21:27:34'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Detecting LLM-Generated Short Answers and Effects on Learner Performance

*Conrad Borchers, Shivang Gupta, Generated Short, Ralph Abboud, Carnegie Mellon, Shambhavi Bhushan, Virtual Institute, Related Work, Learning Engineering, Learner Performance*

---

> ### ðŸ“Š Quick Facts
>
> | Metric | Detail |
> | :--- | :--- |
> | **Model Used** | Fine-tuned GPT-4o |
> | **Dataset Size** | 1,400â€“1,635 responses (534 students) |
> | **Target Text** | Short answers (< 100 words) |
> | **Top Accuracy** | **80%** (vs 70% baseline) |
> | **Top F1 Score** | **0.78** (vs 0.50 baseline) |
> | **Citations** | 40 |

---

## Executive Summary

The rapid integration of Large Language Models (LLMs) into higher education poses a significant threat to academic integrity, particularly regarding the detection of AI-generated content in formative assessments. General-purpose AI detectors are notoriously unreliable when analyzing short-answer responses (under 100 words), a format commonly used to gauge student understanding. This paper addresses the critical gap in accurate text classification for low-stakes, short-form content and investigates the broader pedagogical implications of LLM misuse, specifically examining how reliance on these tools correlates with learner performance on subsequent assessments.

The study introduces a detection framework architected around a fine-tuned GPT-4o model, specifically optimized to distinguish between human-written and GPT-4o-generated text. Technically, the approach employs a multimodal architecture that incorporates auxiliary behavioral indicators, including assessment scores, readability metrics, and response duration. This enriches the feature set used for classification, allowing the model to detect subtle patterns indicative of AI usage. The system was trained and evaluated on a rigorous dataset of approximately 1,635 responses from 534 college students, annotated via a strict codebook that defines LLM text as content produced without paraphrasing.

The fine-tuned GPT-4o model demonstrated robust performance, achieving an accuracy of 80% and an F1 score of 0.78. This represents a statistically significant improvement over the primary baseline, GPTZero, which achieved only 70% accuracy and a Macro F1 score of 0.50. Crucially, the proposed model achieved a lower False Positive Rate (FPR) than existing baselines, a critical metric for minimizing the unfair penalization of human students. In addition to detection efficacy, the analysis revealed a tangible impact on learning outcomes: learners suspected of LLM misuse were more than twice as likely to answer corresponding post-assessment questions correctly compared to those who did not misuse LLMs.

These findings hold substantial significance for the field of learning engineering and educational technology. By validating that transformer-based models, when augmented with behavioral data, can reliably detect AI involvement in short answers, the authors provide a technical path forward for institutions seeking to uphold assessment integrity. Furthermore, the statistically significant correlation between LLM use and higher post-test scores challenges educators to rethink assessment design, as it suggests that AI tools may currently boost short-term performance metrics, potentially masking gaps in genuine knowledge retention.

---

## Key Findings

*   **Superior Detection Rates:** The fine-tuned GPT-4o model significantly outperforms standard general-purpose detectors, specifically GPTZero, in the context of short educational texts.
*   **Performance Correlation:** There is a strong positive correlation between LLM misuse and immediate assessment performance; students flagged for AI usage were more than twice as likely to answer posttest questions correctly.
*   **Reliability in Short Texts:** The study successfully addresses the "low-stakes" detection gap, proving that reliable classification is possible even with texts under 100 words when using auxiliary behavioral data.
*   **Reduction in False Positives:** The proposed model achieves a lower False Positive Rate than baselines, mitigating the risk of unfairly accusing students who write legitimately.

---

## Technical Details

The technical framework is built upon a foundation of rigorous annotation and multimodal data integration.

*   **Core Architecture:**
    *   **Base Model:** Fine-tuned GPT-4o.
    *   **Optimization:** Specifically designed to differentiate between human-written and GPT-4o-generated text.

*   **Data & Annotation:**
    *   **Source:** 534 college students.
    *   **Volume:** 1,400â€“1,635 manually annotated responses.
    *   **Codebook:** Strict definition applied where LLM text is defined as content produced *without* paraphrasing.

*   **Feature Engineering (Auxiliary Indicators):**
    To enhance detection beyond text patterns, the model incorporates:
    *   Assessment scores
    *   Readability metrics
    *   Response duration

*   **Baselines for Comparison:**
    *   GPTZero
    *   OpenAI's AI Text Classifier
    *   RoBERTa

---

## Results

The evaluation of the model highlights distinct improvements over existing commercial and open-source solutions.

**Detection Performance:**
*   **Fine-tuned GPT-4o Model:**
    *   Accuracy: **80%**
    *   F1 Score: **0.78**
*   **GPTZero Baseline:**
    *   Accuracy: 70%
    *   Macro F1 Score: 0.50

**Learner Performance Analysis:**
*   Analysis of 1,635 responses showed that learners suspected of LLM misuse were **>2x as likely** to answer corresponding posttest questions correctly compared to learners who did not misuse LLMs.

---

## Document Metadata

*   **Quality Score:** 7/10
*   **References:** 40 citations