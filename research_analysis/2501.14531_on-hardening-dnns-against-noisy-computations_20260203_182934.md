---
title: On Hardening DNNs against Noisy Computations
arxiv_id: '2501.14531'
source_url: https://arxiv.org/abs/2501.14531
generated_at: '2026-02-03T18:29:34'
quality_score: 8
citation_count: 35
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# On Hardening DNNs against Noisy Computations

*Xiao Wang; Hendrik Borras; Bernhard Klein; Holger Fröning*

### Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 35 Citations |
| **Dataset** | CIFAR-10 |
| **Architectures** | LeNet-5, VGG-11, ResNet-18 |
| **Learning Rate** | $\eta = 0.01$ |
| **Primary Metric** | Midpoint Noise Level ($\mu$) |

---

> **Executive Summary**
>
> The proliferation of Deep Neural Networks (DNNs) demands high energy efficiency, driving significant interest in analog hardware accelerators. However, a critical bottleneck inhibits this adoption: analog computing substrates are inherently susceptible to computational noise, which significantly degrades inference accuracy. This paper addresses the challenge of "hardening" DNNs to tolerate this noise, a necessary step to validate the feasibility of using energy-efficient analog hardware for compute-intensive tasks without sacrificing model performance.
>
> The study introduces a rigorous comparative analysis of two primary training methodologies designed to mitigate noise sensitivity. The researchers evaluate Quantization-Aware Training (QAT) utilizing constant scaling factors to stabilize the network against noise. The core innovation lies in the detailed evaluation and comparison of "Noisy Training," a technique that injects synthetic noise into weights and activations during the training phase to mimic the specific non-idealities of analog inference.
>
> Experimental results demonstrate that **Noisy Training significantly outperforms standard QAT**. Most notably, LeNet-5 trained with noise injection achieved approximately a 6.5-fold increase in robustness, raising $\mu$ from 0.357 to 2.340. Furthermore, ResNet-18 demonstrated substantial resilience, maintaining a $\mu$ of 0.665 at $s=8$ before collapsing only at $s=10$. The findings establish Noisy Training as the superior approach for complex architectures, bridging the gap between theoretical DNN performance and practical hardware constraints.

---

## Key Findings

*   **Quantization-Aware Training (QAT) Efficacy:** QAT effectively increases DNN tolerance to computational noise, particularly when utilizing constant scaling factors.
*   **Superiority of Noisy Training:** Noisy training—which involves injecting noise during the training process to mimic inference conditions—outperforms standard quantization-aware training methods.
*   **Architecture Dependence:** The superiority of noisy training is particularly significant in complex neural architectures, making it the more effective approach for maintaining high accuracy in demanding models.

## Methodology

The researchers utilized an experimental comparative approach to evaluate noise mitigation strategies for DNNs. The study investigated two primary training methodologies:

1.  **Quantization-Aware Training (QAT):** Implementing quantization with constant scaling factors to harden the network against noise.
2.  **Noisy Training:** Injecting noise during the training phase to simulate the specific noise encountered during inference on analog hardware.

These methods were tested and compared across various network architectures to assess their impact on maintaining accuracy in the presence of noisy computations.

## Contributions

*   **Feasibility of Analog Hardware:** The work addresses the critical bottleneck of inherent noise in analog computing, validating methods that enable the use of energy-efficient analog hardware for compute-intensive DNN tasks.
*   **Comparative Analysis of Robustness Techniques:** It provides a direct comparison between quantization-based hardening and noise-injection training, offering insights into which methods best preserve accuracy.
*   **Optimization Strategy for Complex Architectures:** By identifying noisy training as the superior approach for complex networks, the study provides a clear pathway for deploying advanced, high-performance models on non-ideal, noise-prone hardware substrates.

## Technical Details

*   **Comparison Scope:** The paper compares Quantization-Aware Training (QAT) with dynamic and constant scaling strategies against Noisy Training (noise injected into weights and activations).
*   **Evaluation Metric:** The primary metric used is the Midpoint Noise Level ($\mu$).
*   **Hyperparameters:** Training was conducted with a learning rate of $\eta = 0.01$.
*   **Tested Architectures:** LeNet-5, VGG-11, and ResNet-18.
*   **Dataset:** CIFAR-10.

## Results

*   **VGG-11:** Traded accuracy for robustness with constant scaling, peaking at $\mu=0.222$ before collapsing at $s=3$.
*   **ResNet-18:** Improved robustness ($\mu=0.665$ at $s=8$) without immediate accuracy loss, collapsing only at $s=10$.
*   **Noisy Training (LeNet-5):** Significantly increased robustness, achieving a $\approx 6.5\times$ increase in $\mu$ (from 0.357 to 2.340).
*   **Pareto Analysis:** Noisy Training demonstrated a superior trade-off compared to standard QAT.

---

**References:** 35 citations