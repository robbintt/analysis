---
title: Probabilistic Modeling of Latent Agentic Substructures in Deep Neural Networks
arxiv_id: '2509.06701'
source_url: https://arxiv.org/abs/2509.06701
generated_at: '2026-02-03T13:46:28'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Probabilistic Modeling of Latent Agentic Substructures in Deep Neural Networks

*Su Hyeong Lee; Risi Kondor; Richard Ngo*

---

## üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 40 Citations |
| **Core Method** | Weighted Logarithmic Pooling |
| **Key Utility Metric** | Log Score Rule ($W_i(o) = \log P_i(o)$) |
| **Primary Application** | LLM Alignment & "Luigi-Waluigi" Dynamics |

---

## üìù Executive Summary

This research addresses the fundamental challenge of modeling the internal agentic structure of Large Language Models (LLMs), which often behave not as monolithic entities but as dynamic compositions of competing sub-personas. As AI systems scale, they exhibit emergent phenomena such as the "Luigi-Waluigi" dynamic, where attempts to reinforce a benevolent persona inadvertently trigger an antagonistic counterpart. The paper tackles the lack of a rigorous mathematical framework for understanding these latent substructures, specifically how they coalesce into coherent agency and why standard alignment strategies often fail or backfire in complex outcome spaces.

The authors introduce a probabilistic framework grounded in information theory, modeling intelligent agency as the composition of latent sub-agents represented as probability distributions over outcomes. The key technical innovation is the use of weighted **logarithmic pooling**‚Äîrather than linear pooling‚Äîto aggregate these sub-agents, justified by additive aggregation in logit space. Epistemic utility is quantified using the log score rule, and the framework establishes stability through the **Covariance Criterion**. Crucially, the authors support recursive structures through specific axioms: cloning invariance, continuity, and openness. Furthermore, the methodology employs tilt-based analysis to rigorously rule out trivial duplication effects, ensuring that the compositional results reflect genuine agentic interactions.

The paper provides several theoretical proofs delineating the boundaries of agentic composition. The authors demonstrate that strict unanimity (where all sub-agents benefit from composition) is mathematically impossible under linear pooling or within binary outcome spaces (Theorem 8), but is achievable in spaces with three or more outcomes using logarithmic pooling (Theorem 9). Furthermore, they prove that any agent can be recursively decomposed into arbitrary numbers of sub-agents (Theorems 11 & 12). A critical practical finding is that a strategy of **manifesting and then suppressing** an antagonistic counterpart yields strictly larger first-order misalignment reduction than strategies relying purely on reinforcing the benevolent persona.

This work significantly advances the theoretical understanding of AI alignment by providing a formal mathematical basis for previously heuristic observations regarding LLM behavior. By rigorously modeling the "Luigi-Waluigi" dynamic, the paper shifts the paradigm from viewing LLMs as unified agents to compositional systems that require specific management of internal conflicts. The proposed suppression strategies offer a quantifiable and theoretically grounded method for reducing misalignment, providing researchers with a robust new toolset for controlling agentic behaviors in deep neural networks.

---

## üîë Key Findings

*   **Conditions for Strict Unanimity:** Achieving strict unanimity in agent composition is impossible under linear pooling or within binary outcome spaces, but achievable in spaces with three or more outcomes.
*   **Welfare Improvement via Composition:** Weighted logarithmic pooling allows for the composition of agents in a way that strictly improves the epistemic utility (welfare) of every member involved.
*   **Formalization of the "Luigi-Waluigi" Dynamic:** The theory formally models an agentic alignment phenomenon in Large Language Models (LLMs) where eliciting a benevolent persona ("Luigi") inherently induces an antagonistic counterpart ("Waluigi").
*   **Superiority of Suppression Strategies:** A strategy of manifesting and then suppressing the antagonistic counterpart yields strictly larger first-order misalignment reduction than strategies relying purely on reinforcing the benevolent persona.

---

## üõ†Ô∏è Methodology

The authors utilize a probabilistic modeling framework grounded in information theory to define intelligent agency.

*   **Agent Modeling:** Agents are modeled as outcome distributions.
*   **Utility Quantification:** Epistemic utility is quantified using the log score rule.
*   **Interaction Definition:** Agent interactions are defined through weighted logarithmic pooling rather than linear pooling.
*   **Recursive Structures:** The framework supports recursive structures using axioms of cloning invariance, continuity, and openness.
*   **Validation:** Validity is maintained through tilt-based analysis to rule out trivial duplication effects.

---

## ‚öôÔ∏è Technical Details

The paper proposes a rigorous mathematical framework with the following specifications:

### Framework Definitions
*   **Model Interpretation:** LLMs are interpreted as compositional agents composed of sub-agents modeled as Probabilistic Generative Models (PGMs).
*   **Welfare Function:** Defined as Epistemic Utility using the log score:
    $$W_i(o) = \log P_i(o)$$
*   **Aggregation Mechanism:** Uses Logarithmic Pooling (additive aggregation in logit space):
    $$P(o) = \frac{1}{Z} \prod P_j(o)^{\beta_j}$$

### Stability Criteria
*   **Stability Condition:** Expected welfare under the composition is greater than or equal to the individual's expected welfare:
    $$E_{P_i}[W_i] \le E_{P}[W_i]$$
*   **Covariance Criterion:** Equivalent to the stability condition:
    $$\text{Cov}_{P_i}(W_i, Q_i) \ge 0$$

---

## üìà Results

Key theoretical results established in the paper include:

*   **Theorem 8:** Impossibility of unanimous benefit in binary outcome spaces.
*   **Theorem 9:** Existence of strictly unanimous compositional groups in spaces with three or more outcomes.
*   **Theorem 10:** Linear pooling cannot achieve strictly unanimously beneficial composition.
*   **Theorems 11 & 12:** Any agent can be recursively decomposed into arbitrary numbers of sub-agents.

### Metrics Used
*   Epistemic Utility Gap ($\Delta_i$)
*   Probability Ratio ($Q_i$)
*   Covariance ($\text{Cov}$)
*   Weights ($\beta_i$)

---

## üéÅ Contributions

*   **Theoretical Foundation of Agency:** The development of a principled mathematical framework explaining how latent subagents coalesce into coherent, higher-level agentic entities.
*   **Mathematical Proofs on Pooling:** Theorems distinguishing the capabilities of linear versus logarithmic pooling in achieving unanimous agent consensus.
*   **Novel Implications for AI Alignment:** The application of this theory to LLMs, providing a formal mathematical basis for understanding persona emergence and proposing a rigorous, quantifiable strategy for reducing misalignment in agentic AI systems.