# Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics

*René Heinrich; Lukas Rauch; Bernhard Sick; Christoph Scholz*

---

> ### **Quick Facts**
>
> *   **Clean Data Gain:** 10.5% relative improvement in cmAP
> *   **Architectures:** ConvNeXt vs. AudioProtoPNet
> *   **Framework:** TRADES-AWP with Asymmetric Loss
> *   **PRS Score:** Improved from 0.74 to 0.89 (ε=0.01)
> *   **TARS Score:** Improved from 0.27 to 0.65 (ε=0.1)
> *   **Domain:** Bird sound classification under distribution shift

---

### **Executive Summary**

This research addresses the critical challenge of generalization in bioacoustics, specifically in bird sound classification, where models frequently encounter substantial distribution shifts between training and testing environments. In real-world scenarios, variations in recording equipment, weather conditions, and background noise create significant discrepancies that standard models struggle to handle.

While adversarial training is traditionally employed strictly to improve robustness against malicious attacks, this paper investigates its potential to simultaneously enhance performance on clean, unperturbed data within these difficult, variable domains. The key technical innovation is the adaptation of a **TRADES-AWP (Adversarial Weight Perturbation)** framework tailored for multi-label classification using an **Asymmetric Loss function** to address label imbalance.

The study provides empirical evidence that adversarial training, particularly using output-space attacks, yields significant performance gains. This work validates adversarial training as a dual-purpose technique that effectively mitigates real-world distribution shifts while defending against security threats. By demonstrating that these benefits transfer to both black-box CNNs and transparent prototype-based networks, the research offers a robust strategy for deploying reliable machine learning systems in noisy, variable environments.

---

## Key Findings

*   **Dual Benefit of Adversarial Training:** The study demonstrated that adversarial training offers a simultaneous improvement in both generalization performance on clean data and robustness against adversarial attacks.
*   **Significant Performance Gain:** Utilizing adversarial training, particularly with output-space attacks, resulted in an **average relative improvement of 10.5%** on clean test data.
*   **Efficacy Under Distribution Shift:** The methods proved effective on a bird sound classification benchmark characterized by substantial distribution shifts caused by varying environmental conditions and recording methods.
*   **Prototype Stability:** For the interpretable model (AudioProtoPNet), the study confirmed that adversarial training could be assessed and applied while considering the stability of learned prototypes against targeted embedding-space attacks.

## Methodology

### Model Architectures
The research compared two distinct architectures:
*   A conventional **Convolutional Neural Network (ConvNeXt)**.
*   An inherently interpretable prototype-based model (**AudioProtoPNet**).

### Evaluation Domain
The approach was benchmarked on a challenging bioacoustics task (bird sound classification) specifically selected for its pronounced distribution shifts between training and test sets.

### Adversarial Strategies
Two primary adversarial training and evaluation strategies were investigated:
*   **Output-space attacks:** Designed to maximize the classification loss function.
*   **Embedding-space attacks:** Designed to maximize embedding dissimilarity.

### Robustness Assessment
The study used the defined attack types to evaluate model robustness and specifically analyzed the stability of prototypes within the AudioProtoPNet under targeted embedding-space attacks.

## Technical Details

*   **Framework:** Utilizes a **TRADES-AWP** framework adapted for multi-label classification.
*   **Loss Function:** Implements an **Asymmetric Loss function** to address label imbalance.
*   **Optimization:** The training objective is a minimax optimization problem involving adversarial weight perturbation and input perturbation.
*   **Threat Model:** White-box threat model with both untargeted and targeted attacks.
*   **Training Types:** Comparison of Output-space training (maximizing classification loss) vs. Embedding-space training (maximizing embedding dissimilarity).

## Contributions

*   **Unexplored Domain Investigation:** The paper addresses a critical gap in research by investigating how adversarial training impacts generalization under substantial data distribution shifts in audio classification, moving beyond the traditional focus on adversarial robustness alone.
*   **Validation of Robustness Techniques:** It provides empirical evidence that adversarial training—specifically via output-space attacks—is a viable strategy for handling real-world audio challenges where environmental and recording variations cause major data discrepancies.
*   **Cross-Architecture Applicability:** The work contributes insights into the applicability of adversarial training across different model paradigms, validating its effectiveness for both standard black-box CNNs and transparent, prototype-based networks.

## Results

*   **Clean Data Performance:** Output-space adversarial training resulted in a **relative 10.5% improvement** in Class Mean Average Precision (cmAP).
*   **Robustness (PRS):** For AudioProtoPNet, Output-space training improved the Performance Robustness Score (PRS) against untargeted attacks from **0.74 to 0.89** at epsilon=0.01.
*   **Prototype Stability (TARS):** Increased the Total Adversarial Robustness Score (TARS) for prototype stability against targeted attacks from **0.27 to 0.65** at epsilon=0.1.

---

**Quality Score:** 8/10  
**References:** 40 citations