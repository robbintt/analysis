---
title: 'ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools'
arxiv_id: '2508.03284'
source_url: https://arxiv.org/abs/2508.03284
generated_at: '2026-02-03T13:52:20'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools

*Shaofeng Yin; Ting Lei; Yang Liu*

---

> ### üìä Quick Facts
>
> *   **Dataset Volume:** 23,000 instances
> *   **Tool Diversity:** 10 multimodal tools across 7 task domains
> *   **Complexity:** Average inference length of 2.78 reasoning steps
> *   **Key Model:** 7B Large Foundation Models (LFMs)
> *   **Performance:** Surpasses GPT-3.5-turbo on OOD datasets
> *   **Quality Score:** 8/10

---

## üìù Executive Summary

Current tool-augmented Visual Question Answering (VQA) models struggle to maintain proficiency in complex, real-world multimodal environments that require multi-step reasoning. The primary limitation lies in existing datasets, which are often synthetic or overly simplistic, failing to capture the nuances of actual user interactions and the implicit logic required to chain tools together effectively.

To address this, the researchers introduce **ToolVQA**, a dataset of 23,000 instances, and **ToolEngine**, a novel data generation pipeline designed to create realistic tool-use trajectories. ToolEngine utilizes an Image-guided Depth-First Search (DFS) algorithm controlled by a ChatGPT-4o-latest agent to navigate a "complete tool graph." Crucially, the pipeline executes real tool calls rather than simulated outputs, ensuring the data includes real-world noise and logical validity.

The system further enhances reasoning quality through a dynamic in-context example matching mechanism (using LCS-based matching) that retrieves relevant human-in-the-loop examples. Empirical evaluations demonstrated that fine-tuning 7B Large Foundation Models (LFMs) on this dataset yields superior generalization capabilities, surpassing the performance of the large proprietary model GPT-3.5-turbo across various Out-of-Distribution (OOD) datasets.

---

## üîç Key Findings

*   **Bridging the Reality Gap:** Existing tool-augmented VQA models struggle with real-world proficiency. ToolVQA successfully bridges the gap between synthetic datasets and real user interactions by utilizing real-world visual contexts.
*   **Superior Generalization:** Fine-tuning 7B Large Foundation Models (LFMs) on ToolVQA enables them to surpass the performance of the large closed-source model **GPT-3.5-turbo** on various out-of-distribution (OOD) datasets.
*   **High Complexity:** The dataset features a high level of complexity, incorporating 10 multimodal tools across 7 task domains with an average inference length of **2.78 reasoning steps** per instance.
*   **Implicit Reasoning:** The dataset focuses on challenging implicit multi-step reasoning tasks, moving beyond simplified queries.

---

## üõ†Ô∏è Methodology

The researchers constructed the ToolVQA dataset using a novel data generation pipeline called **ToolEngine**. The core components of this methodology include:

1.  **Depth-First Search (DFS) Algorithm:** The pipeline utilizes a DFS algorithm to navigate potential tool usage paths.
2.  **Dynamic In-Context Matching:** A dynamic mechanism for matching in-context examples is employed to guide the generation process.
3.  **Human-Like Simulation:** This approach is designed specifically to simulate human-like tool-use reasoning, allowing for the generation of complex, implicit multi-step tasks rather than relying on simplified or synthetic queries.

---

## üåü Contributions

*   **ToolVQA Dataset:** A large-scale (23K instances) multimodal dataset designed to evaluate and improve tool-use capabilities in VQA, moving beyond synthetic scenarios to real-world visual contexts.
*   **ToolEngine Pipeline:** An innovative data generation framework that leverages DFS and dynamic in-context matching to create realistic, human-like reasoning traces for tool usage.
*   **Benchmark Advancement:** Establishment of a rigorous benchmark that covers 7 diverse task domains and 10 multimodal tools, providing a more comprehensive evaluation standard for multi-step reasoning in visual contexts.
*   **Model Performance Demonstration:** Empirical evidence showing that smaller (7B), fine-tuned open-source models can achieve state-of-the-art generalizability, outperforming large proprietary models like GPT-3.5-turbo on OOD tasks.

---

## ‚öôÔ∏è Technical Details

**Pipeline Architecture**
*   **Name:** ToolEngine
*   **Type:** Automated data synthesis pipeline for multi-step tool-use trajectories.
*   **Core Logic:** Image-guided Depth-First Search (DFS) on a 'complete tool graph'.

**Control & Execution**
*   **Controller:** Guided by a ChatGPT-4o-latest controller to generate tool names and arguments.
*   **Execution Method:** Utilizes **real tool calls** rather than simulated outputs.
*   **Environment:** Uses deployed tools with real-world noise to ensure trajectory validity by enforcing logical connections between steps.

**Context & Validity**
*   **Example Construction:** Real-World Example Construction (human-in-the-loop).
*   **Matching Algorithm:** LCS-based (Longest Common Subsequence) Example Matching to provide relevant context.

---

## üìà Results

*   **Dataset Specifications:** The ToolVQA dataset comprises **23,000 instances**.
*   **Reasoning Depth:** Average inference length of **2.78 reasoning steps** per instance.
*   **Scope:** Covers 10 multimodal tools across 7 task domains.
*   **Model Performance:** Fine-tuning 7B Large Foundation Models (LFMs) on this dataset enables them to surpass the performance of GPT-3.5-turbo and demonstrate strong generalization on Out-of-Distribution (OOD) datasets.

---

## üìë Meta Data

*   **Quality Score:** 8/10
*   **References:** 40 citations