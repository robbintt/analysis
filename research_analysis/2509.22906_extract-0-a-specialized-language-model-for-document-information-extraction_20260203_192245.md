---
title: 'Extract-0: A Specialized Language Model for Document Information Extraction'
arxiv_id: '2509.22906'
source_url: https://arxiv.org/abs/2509.22906
generated_at: '2026-02-03T19:22:45'
quality_score: 9
citation_count: 15
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Extract-0: A Specialized Language Model for Document Information Extraction

*Henrique Godoy*

---

> ### üìä Quick Facts
>
> | Metric | Detail |
> | :--- | :--- |
> | **Model Size** | 7 Billion Parameters |
> | **Base Architecture** | DeepSeek-R1-Distill-Qwen-7B |
> | **Weights Modified** | 0.53% (40.4M params) |
> | **Mean Reward** | 0.573 (vs. ~0.46 for frontier models) |
> | **Training Cost** | ~$196 |
> | **Training Samples** | 280,128 examples |
> | **Quality Score** | 9/10 |

---

## Executive Summary

The research addresses the inefficiency and suboptimal performance of massive, general-purpose Large Language Models (LLMs) when applied to Document Information Extraction (DIE). While state-of-the-art models like GPT-4 and o3 are frequently used for parsing unstructured text into structured data, they incur high computational costs and often struggle with the inherent ambiguity of extraction tasks. The paper highlights a critical gap: the pursuit of ever-larger general-purpose models overlooks the potential for smaller, specialized architectures to achieve superior accuracy on specific vertical tasks. Consequently, the industry lacks a cost-effective, high-precision solution for DIE that can handle diverse document types without the resource overhead of frontier models.

The core innovation is **Extract-0**, a 7-billion parameter model derived from DeepSeek-R1-Distill-Qwen-7B, trained via a specialized three-stage pipeline designed for high parameter efficiency and disambiguation. The methodology begins with a memory-preserving synthetic data generation pipeline that creates 280,128 diverse examples from sources like arXiv and PubMed. The model undergoes Supervised Fine-Tuning (SFT) using Low-Rank Adaptation (LoRA), freezing the majority of weights and modifying only 0.53% (40.4 million parameters) to reduce resource strain. Crucially, the pipeline concludes with a reinforcement learning phase employing Group Relative Policy Optimization (GRPO). This stage utilizes a novel reward function based on field-level semantic similarity‚Äîusing techniques like bipartite matching for lists and MiniLM cosine similarity for embeddings‚Äîto explicitly handle the nuances and ambiguities of extraction, ensuring the model outputs semantically accurate structured data.

Extract-0 demonstrated significant performance advantages over leading general-purpose frontier models on a benchmark of 1,000 held-out extraction tasks. With a Mean Reward of 0.573, Extract-0 outperformed GPT-4.1 (0.457), o3 (0.464), and GPT-4.1-2025 (0.459). These results were achieved with remarkable resource efficiency; the total training cost was approximately $196, and the model reached state-of-the-art performance by updating only 40.4 million parameters. The reinforcement learning phase proved particularly effective, resolving extraction ambiguities that typically hinder general-purpose models, while the use of LoRA with a rank of 16 and alpha of 32 validated that high performance does not require modifying the full parameter set of the base model.

This research challenges the prevailing industry narrative that scale is the primary driver of performance, establishing a new paradigm where task-specific optimization outperforms massive generalization. By demonstrating that a 7-billion parameter model can surpass GPT-4 class models in a complex domain like information extraction, the authors provide empirical evidence that specialized, smaller models are a viable and superior alternative for enterprise applications.

---

## üîë Key Findings

*   **Superior Performance over Larger Models:** Extract-0, a 7-billion parameter model, achieved a mean reward of **0.573** on a benchmark of 1,000 diverse document extraction tasks, significantly outperforming state-of-the-art general-purpose models like GPT-4.1 (0.457), o3 (0.464), and GPT-4.1-2025 (0.459).
*   **High Parameter Efficiency:** The model achieves this performance by modifying only **0.53%** of total weights (40.4 million out of 7.66 billion parameters) during fine-tuning, demonstrating that massive scale is not required for specialized tasks.
*   **Effective Ambiguity Handling:** The use of a reinforcement learning phase with a semantic similarity-based reward function successfully addressed the inherent ambiguity found in information extraction tasks.
*   **Resource-Effective Optimization:** The research validates that task-specific optimization using synthetic data and efficient training methods can surpass general-purpose systems while requiring substantially fewer computational resources.

---

## ‚öôÔ∏è Methodology

The training methodology follows a multi-stage pipeline designed for efficiency and performance:

1.  **Data Generation**
    *   Utilized a memory-preserving synthetic data generation pipeline.
    *   Created **280,128** training examples sourced from diverse document types.

2.  **Fine-Tuning**
    *   Conducted Supervised Fine-Tuning (SFT).
    *   Used **Low-Rank Adaptation (LoRA)**, a parameter-efficient technique that freezes the main model weights and trains a small number of adapter layers.

3.  **Reinforcement Learning**
    *   Final stage employed **Group Relative Policy Optimization (GRPO)**.
    *   Utilized a novel reward function based on semantic similarity to guide the model, specifically tailored to handle the nuances and ambiguities of extracting information from documents.

---

## üõ†Ô∏è Technical Details

*   **Base Model:** DeepSeek-R1-Distill-Qwen-7B
*   **Parameter Efficiency:**
    *   LoRA Rank: 16
    *   LoRA Alpha: 32
    *   Parameters Trained: 40.4 million (0.53% of total)
*   **Data Pipeline:**
    *   **Sources:** arXiv, PubMed, Wikipedia, FDA.
    *   **Architecture:** Memory-preserving, processes chunks sequentially within documents and parallel across documents.
    *   **Augmentation:** Tokens limited to 532‚Äì1900; cross-chunk probability of 0.7; preserves hierarchical schema structure.
*   **Reinforcement Learning Reward Function:**
    *   Based on field-level semantic similarity.
    *   **Lists:** Bipartite matching.
    *   **Embeddings:** MiniLM cosine similarity.
    *   **Scalars:** Relative difference.
    *   **Constraints:** Hard constraints for invalid JSON.
*   **Infrastructure:**
    *   Precision: bfloat16
    *   Batch Size: 16
    *   Features: Gradient checkpointing and label masking.

---

## üìà Results

*   **Benchmark Performance:** Extract-0 (7B) achieved a Mean Reward of **0.573** on 1,000 held-out tasks.
    *   *Comparison:* Outperformed GPT-4.1 (0.457), o3 (0.464), and GPT-4.1-2025 (0.459).
*   **Training Efficiency:**
    *   Utilized 280,128 examples derived from 281,128 augmented samples.
    *   **Total Cost:** $196.
    *   **Weights Modified:** Only 0.53% of total weights.
*   **Qualitative Outcome:** The reinforcement learning phase effectively resolved extraction ambiguity compared to general-purpose models.

---

## üìù Contributions

*   **Extract-0 Model Architecture:** Introduction of a highly specialized, 7-billion parameter language model that sets a new benchmark for document information extraction, proving that smaller, task-specific models can outperform massive general-purpose LLMs.
*   **Advanced Training Pipeline:** Development of a comprehensive training regime combining high-volume synthetic data generation, parameter-efficient fine-tuning (LoRA), and advanced reinforcement learning (GRPO).
*   **Novel Reward Mechanism:** The proposal and implementation of a semantic similarity-based reward function for reinforcement learning, offering a technical solution to the challenge of ambiguity in information extraction tasks.
*   **Cost-Efficiency Paradigm:** Empirical evidence supporting the shift toward specialized model optimization as a viable, high-performance alternative to the pursuit of ever-larger general-purpose models.

---

**Quality Score:** 9/10  
**References:** 15 citations