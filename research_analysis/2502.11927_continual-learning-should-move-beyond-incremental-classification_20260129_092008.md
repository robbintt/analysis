# Continual Learning Should Move Beyond Incremental Classification

*Rupert Mitchell; Antonio Alliegro; Raffaello Camoriano; Dustin Carrión-Ojeda; Antonio Carta; Georgia Chalvatzaki; Nikhil Churamani; Carlo D'Eramo; Samin Hamidi; Robin Hesse; Fabian Hinder; Roshni Ramanna Kamath; Vincenzo Lomonaco; Subarnaduti Paul; Francesca Pistilli; Tinne Tuytelaars; Gido M van de Ven; Kristian Kersting; Simone Schaub-Meyer; Martin Mundt*

***

> ### **Quick Facts**
> 
> *   **Quality Score:** 9/10
> *   **References:** 14 Citations
> *   **Key Datasets:** PASCAL VOC2012, Cityscapes, Active Vision Dataset
> *   **Performance Gap:** >15% mIoU drop in segmentation vs. Joint Training
> *   **Critical Finding:** Regularization methods drop to <20% mIoU in class-incremental segmentation.
> *   **Robotics Success:** Generative Replay maintains >60-80% performance vs. 0% for standard CL methods.

***

## Executive Summary

The field of Continual Learning (CL) is currently constrained by an over-reliance on incremental classification tasks, a focus that fails to generalize to complex, real-world applications. The authors argue that this narrow paradigm obscures fundamental limitations in existing methods when applied to dense prediction and robotics, where output spaces are structured rather than discrete. This stagnation matters because it prevents the deployment of adaptive AI systems in dynamic environments, such as autonomous navigation or continuous domain adaptation.

The paper identifies three specific impediments to progress: the lack of understanding regarding continuity, improper selection of spaces and metrics, and the reliance on learning objectives that are insufficient for tasks beyond simple classification. The key innovation lies in a formal critique and reorientation of the CL paradigm from disjoint discrete output spaces to structured, potentially overlapping spaces (e.g., segmentation masks).

Technical analysis reveals that standard regularization-based methods (e.g., Elastic Weight Consolidation, Synaptic Intelligence) fail in dense prediction tasks because they rely on identifying important parameters; in spatial features, parameter importance overlaps across tasks, causing these methods to underfit or catastrophically forget. To address this, the authors advocate for methodologies that formalize temporal dynamics and incorporate density estimation.

Empirical evaluations on segmentations and robotics tasks demonstrated the severe limitations of current state-of-the-art methods. Regularization methods plummeted to near-random performance, while standard CL algorithms failed completely in robotics scenarios. This paper serves as a critical call to action for the CL community to broaden its scope, establishing a roadmap for developing robust continual learning systems capable of handling complex, structured outputs.

***

## Key Findings

*   **Limitation of Current Focus:** The field of Continual Learning (CL) is overly constrained by a primary focus on incremental classification tasks.
*   **Failure in Diverse Scenarios:** Current CL approaches frequently fail when applied to complex, non-standard scenarios such as multi-target classification and robotics.
*   **Three Fundamental Challenges:** The paper identifies understanding continuity, selecting spaces and metrics, and defining learning objectives beyond simple classification as core impediments.
*   **Need for New Methodologies:** Advancing the field requires shifting to methods that formalize temporal dynamics and incorporate density estimation or generative objectives.

***

## Methodology

This paper utilizes a **position paper methodology**. It conducts a detailed analytical review of concrete examples—specifically in robotics, continuous domains, and concept learning—to demonstrate the limitations of existing paradigms. From this analysis, the authors derive theoretical challenges and formulate principled recommendations for future research directions.

***

## Technical Details

### Problem Formalization
*   **Paradigm Shift:** Critiques the standard incremental classification paradigm, proposing evaluations for complex, structured output spaces like semantic segmentation and robotics.
*   **Output Spaces:** Shifts focus from disjoint discrete output spaces to structured, potentially overlapping ones (e.g., segmentation masks).

### Analyzed Scenarios
1.  **Domain Incremental Semantic Segmentation**
2.  **Class Incremental Semantic Segmentation**
3.  **Active Vision/Robotics**

### Critique of Existing Methods
*   **Regularization-Based (e.g., EWC, SI):** Identified as strictly insufficient for dense prediction. Because spatial features require overlapping parameter importance across tasks, these methods either underfit or suffer from catastrophic forgetting.
*   **Replay-Based Methods:** Identified as strictly necessary for temporal stability.
    *   **Exemplar & Generative Replay:** Essential for maintaining performance.
    *   **Architecture:** Utilizes Variational Autoencoders (VAEs) paired with a segmentation head to generate pseudo-samples for rehearsal.

### Recommended Metrics
*   **Standard Metrics:** Insufficient (e.g., Average Accuracy).
*   **Proposed Metrics:**
    *   **Likelihood:** For generative approaches (density estimation).
    *   **Intersection-over-Union (IoU):** For dense prediction tasks to capture spatial consistency.

***

## Experimental Results

### Segmentation Performance (Class-Incremental)
*   **Datasets:** PASCAL VOC2012, Cityscapes.
*   **Metric:** Mean IoU.
*   **Regularization (EWC, SI):** Performed significantly worse than Joint Training, dropping to near-random performance (**<20% mIoU**) due to class expansion constraints.
*   **Comparison:** Replay strategies and simple fine-tuning outperformed regularization methods.
*   **Gap:** The performance gap between Ideal Joint Training and the best CL method was significantly larger in segmentation (**>15% mIoU drop**) compared to standard classification.

### Robotics Performance (ObjectGoal Navigation)
*   **Dataset:** Active Vision Dataset.
*   **Standard CL (EWC, LwF):** Experienced catastrophic failure with a **0% success rate**.
*   **Generative Replay:** Successfully maintained **>60-80%** of upper-bound performance.

### Quantitative Analysis
*   **Backward Transfer (BWT):** Regularization methods exhibited high negative BWT, while rehearsal methods approached zero BWT.

***

## Contributions

*   **Critical Reorientation of Scope:** Formally argues that the CL field must broaden its scope beyond incremental classification.
*   **Framework of Challenges:** Provides a structured breakdown of the field's hurdles into three specific categories regarding continuity, metric spaces, and learning objectives.
*   **Strategic Recommendations:** Offers concrete technical pathways for future research, specifically advocating for the formalization of temporal dynamics and the integration of density estimation.

***

**Paper Ratings**
*   **Quality Score:** 9/10
*   **References:** 14 citations