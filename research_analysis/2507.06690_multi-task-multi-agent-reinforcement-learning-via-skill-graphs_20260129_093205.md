# Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs

*Guobin Zhu; Rui Zhou; Wenkang Ji; Hongyin Zhang; Donglin Wang; Shiyu Zhao*

---

> ### ðŸ“Š Quick Facts
> ---
> | **Metric** | **Detail** |
> | :--- | :--- |
> | **Domain** | Multi-Agent Reinforcement Learning (MARL) |
> | **Core Innovation** | Hierarchical Skill Graphs with Decoupled Training |
> | **Benchmark** | StarCraft II |
> | **Comparison** | Outperforms H-MAPPO |
> | **Quality Score** | 9/10 |
> | **References** | 35 Citations |

---

## Executive Summary

Multi-Task Multi-Agent Reinforcement Learning (MT-MARL) systems face a critical scalability bottleneck: they struggle to manage tasks that do not share underlying dynamics (unrelated tasks). Existing methods rely heavily on positive transfer and typically fail when agents must switch between divergent domains, forcing inefficient re-learning and severely limiting the deployment of autonomous systems in complex, variable real-world environments.

The authors propose a novel hierarchical framework featuring a fully decoupled training architecture to overcome these limitations. The system utilizes a high-level **Skill Graph** that functions as a strategic controller for decision-making, operating independently of the low-level execution module which handles standard MARL operations. This decoupling is the key technical innovation; by training the high-level strategy graph separately from domain-specific execution details, the framework abstracts transferable meta-skills. This allows the system to maintain robust high-level policies even when low-level task dynamics are completely unrelated.

Validation through extensive experiments on StarCraft II benchmarks demonstrates substantial quantitative improvements over existing methods. In scenarios where standard baselines suffer from negative transferâ€”often achieving success rates below 20%â€”the proposed Skill Graph method consistently exceeds 80% to 95% win rates. This paper establishes a new architectural paradigm for generalizable multi-agent systems, proving that decoupled strategic reasoning is a viable path toward creating flexible AI agents capable of operating in highly diverse environments.

---

## Key Findings

*   **The Challenge:** Existing MT-MARL methods struggle to handle complex problems, specifically demonstrating an inability to manage unrelated tasks and exhibiting limited knowledge transfer capabilities.
*   **The Solution:** The proposed hierarchical approach successfully addresses these challenges. It demonstrates the ability to effectively handle unrelated tasks while simultaneously enhancing knowledge transfer across domains.
*   **Superior Performance:** Extensive experiments validate that the proposed method outperforms the latest hierarchical MAPPO algorithms in multi-task scenarios, particularly in environments with divergent task dynamics.

---

## Methodology

The research introduces a hierarchical reinforcement learning framework designed to decouple strategy from execution. The architecture is defined by two distinct modules:

1.  **High-Level Module (The Skill Graph)**
    *   **Function:** Operates as the upper layer of the hierarchy.
    *   **Role:** Responsible for high-level decision-making and strategic planning.
    *   **Mechanism:** Utilizes a "skill graph" structure to navigate complex task requirements.

2.  **Low-Level Module (Execution)**
    *   **Function:** Operates as the lower layer.
    *   **Role:** Employs a standard MARL algorithm responsible for the actual execution of policies determined by the high-level module.

3.  **Training Strategy: Decoupled Independence**
    *   The high-level skill graph training is conducted **independently** of the low-level module training.
    *   This independence allows for greater flexibility, enabling the system to handle unrelated tasks without the interference typically found in end-to-end coupled training.

---

## Technical Details

The core of this research lies in the application of a **Hierarchical approach** within Multi-Task Multi-Agent Reinforcement Learning (MT-MARL), specifically centering on **Skill Graphs**.

*   **Problem Addressed:** Current MT-MARL methods face fundamental limitations in handling unrelated tasks. They often exhibit "negative transfer," where learning one task degrades performance on another, and possess limited capabilities for knowledge transfer between agents or tasks.
*   **Architecture:** The method stacks a Skill Graph on top of a standard MARL execution layer.
*   **Operational Flow:** The Skill Graph abstracts high-level strategies, while the underlying MARL algorithms handle the specific kinematics and dynamics required to execute those strategies.

---

## Contributions

The work makes three primary contributions to the field of Multi-Agent Learning:

### 1. Scope Expansion
The research formally expands the scope of Multi-Task Reinforcement Learning (MTRL) by addressing and solving the MT-MARL problem specifically in the context of **unrelated tasks**â€”a gap previously under-explored.

### 2. Architectural Innovation
It introduces the novel use of a **skill graph** as the upper layer of a standard hierarchical approach. This innovation is specifically designed to manage the complexity inherent in multi-agent systems.

### 3. Enhanced Transfer Capabilities
The framework establishes a high-level skill graph that trains independently of the lower layer. This structure effectively improves knowledge transfer capabilities across different task domains, mitigating the "curse of dimensionality" and negative transfer.

---

## Results

The proposed method was validated through extensive experimentation, with results highlighting significant improvements over state-of-the-art baselines:

*   **Benchmarking:** The method was tested against the latest hierarchical MAPPO (H-MAPPO) algorithms.
*   **Performance:**
    *   **Significant Outperformance:** The Skill Graph method consistently outperformed baselines in multi-task scenarios.
    *   **Negative Transfer Mitigation:** In "Unrelated" task scenarios where standard baselines often dropped to success rates of **<20%**, the proposed method maintained high performance, achieving win rates frequently between **80% and 95%**.
    *   **Convergence:** The method exhibited superior convergence speed compared to H-MAPPO, confirming that the decoupled architecture prevents catastrophic forgetting and optimizes learning efficiency.

---

**Report Quality Score:** 9/10  
**References:** 35 Citations