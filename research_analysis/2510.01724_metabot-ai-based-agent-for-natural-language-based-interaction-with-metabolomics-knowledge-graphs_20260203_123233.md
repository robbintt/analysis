---
title: 'MetaboT: AI-based agent for natural language-based interaction with metabolomics
  knowledge graphs'
arxiv_id: '2510.01724'
source_url: https://arxiv.org/abs/2510.01724
generated_at: '2026-02-03T12:32:33'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MetaboT: AI-based agent for natural language-based interaction with metabolomics knowledge graphs

*Madina Bekbergenova; Lucas Pradi; Benjamin Navet; Emma Tysinger; Franck Michel; Matthieu Feraud; Yousouf Taghzouti; Yan Zhou Chen; Olivier Kirchhoffer; Florence Mehl; Martin Legrand; Tao Jiang; Marco Pagni; Soha Hassoun; Jean-Luc Wolfender; Wout Bittremieux; Fabien Gandon; Louis-FÃ©lix Nothias*

***

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 9/10
> *   **MetaboT Accuracy:** 83.67%
> *   **GPT-4o Baseline:** 8.16%
> *   **Performance Gain:** >75 percentage points
> *   **Evaluation Dataset:** 50 questions
> *   **Core Technology:** LangChain, LangGraph, SPARQL, Multi-Agent Systems

***

## Executive Summary

This paper addresses the critical accessibility barrier in metabolomics, where valuable scientific data is siloed within complex Knowledge Graphs (KGs) like the Experimental Natural Products Knowledge Graph (ENPKG). Extracting insights from these structured repositories typically requires specialized expertise in SPARQL query languages and a deep understanding of underlying ontologiesâ€”technical skills that many domain experts, such as biologists and chemists, lack. Consequently, the potential of these rich datasets remains underutilized, as standard Large Language Models (LLMs) struggle to accurately translate natural language intent into the precise syntax required for semantic web querying.

To bridge this gap, the authors developed MetaboT, a multi-agent AI system built on LangChain and LangGraph that utilizes a sequential decomposition of tasks to process complex queries. Unlike single-step LLM approaches, MetaboT orchestrates a workflow of specialized agents: an Entry Agent determines context, a Validator Agent checks relevance, a Supervisor Agent manages orchestration, a Knowledge Graph Agent performs entity extraction, and a SPARQL Agent generates and executes queries. A critical technical component of the architecture is the entity resolution engine, which maps natural language chemical names to standardized URIs or taxonomies, effectively translating unstructured user inputs into rigorous database commands.

The system was evaluated using a curated dataset of 50 complex questions, with performance measured by Query Accuracyâ€”the percentage of correctly generated and executable database queries. MetaboT achieved a robust 83.67% accuracy, dramatically outperforming the GPT-4o baseline, which achieved only 8.16% accuracy on the same tasks. This represents a performance improvement of over 75 percentage points, demonstrating that the multi-agent architecture is significantly more reliable than general-purpose LLMs for handling the technical complexities of metabolomics data retrieval.

The significance of this research lies in the democratization of metabolomics data, enabling domain experts to access and analyze structured information through conversational interfaces without requiring programming or semantic web expertise. Beyond its immediate utility, the work validates the efficacy of multi-agent architectures for scientific data retrieval, establishing a design pattern where LLM reasoning is combined with external semantic tools to ensure adherence to domain standards. By releasing the framework as an open-source tool, the authors provide a reusable blueprint that can be adapted to other specialized domains, potentially accelerating discovery across various fields of scientific research.

***

## Key Findings

*   **High Query Accuracy:** MetaboT achieved **83.67%** accuracy compared to **8.16%** for GPT-4o, significantly outperforming standard LLMs in generating database queries.
*   **Effective Multi-Agent Decomposition:** Breaking down complex tasks into discrete components managed by specialized agents is superior to single-step processing.
*   **Bridging the Technical Gap:** The system removes the need for users to understand SPARQL syntax or deep ontology structures, enabling conversational data retrieval.
*   **Robust Entity Resolution:** The architecture effectively handles entity extraction, converting chemical names to standardized URIs or taxonomies.

## Methodology

The researchers developed MetaboT, a multi-agent AI system using **LangChain** and **LangGraph**, operating on the Experimental Natural Products Knowledge Graph (ENPKG). The system processes queries through a sequential workflow involving specialized agents:

1.  **Entry Agent:** Context determination
2.  **Validator Agent:** Relevance check
3.  **Supervisor Agent:** Orchestration
4.  **Knowledge Graph Agent:** Entity extraction
5.  **SPARQL Agent:** Query generation and execution

Performance was evaluated using a curated dataset of 50 questions against a standard GPT-4o baseline.

## Technical Details

The system utilizes a **Multi-Agent System** architecture designed to handle complex natural language tasks. Key structural components include:

*   **Multi-Agent Decomposition:** Breaks down complex tasks into discrete components managed by specialized agents rather than a single-step process.
*   **Entity Resolution Engine:** Converts natural language chemical names into standardized URIs or taxonomies.
*   **Intermediary Interface:** Functions as a translator that converts natural language inputs into SPARQL database queries, abstracting away the need for users to understand syntax or deep ontology structures.

## Results

Evaluated using **Query Accuracy** (percentage of correctly generated database queries), the results demonstrated a substantial performance gap:

*   **MetaboT:** 83.67%
*   **Baseline (GPT-4o):** 8.16%

This represents a performance improvement of over **75 percentage points**.

## Contributions

*   **Democratization of Metabolomics Data Access:** Lowers technical barriers, allowing domain experts to access structured data without programming or semantic web expertise.
*   **Advancement in AI-Agent Architectures:** Validates the use of multi-agent systems for scientific data retrieval, showing improved accuracy through LLM integration with external tools.
*   **Open-Source Scientific Tool:** Provides a reusable framework and web interface with publicly released source code for adaptation to other domains.
*   **Integration of Semantic Technologies with LLMs:** Combines LLM reasoning with semantic web technologies (SPARQL, ontologies) to ensure alignment with domain-specific data standards.

***

**References:** 40 citations