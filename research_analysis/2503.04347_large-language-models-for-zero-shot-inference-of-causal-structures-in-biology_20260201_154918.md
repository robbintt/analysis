# Large Language Models for Zero-shot Inference of Causal Structures in Biology

*Authors: Izzy Newsham; Luka Kovaƒçeviƒá; Richard Moulange; Nan Rosemary Ke; Sach Mukherjee*

---

### üìä Quick Facts & Metrics

| Metric | Value |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **References** | 18 Citations |
| **Variables Analyzed** | 100+ |
| **Hypotheses Tested** | Thousands |
| **Top AUPRC (Proposed)** | 0.68 |
| **Baseline AUPRC (STRING)** | 0.24 |

***

## Executive Summary

Characterizing causal molecular networks in biology remains a formidable challenge due to the complexity of biological systems, the prevalence of latent variables, and the dependence on cellular context. Traditional data-driven methods often struggle to capture these nuanced relationships, while existing text-based approaches fail to validate inferences against physical reality. This paper addresses the critical gap between computational causal learning theory and practical biological discovery by investigating whether Large Language Models (LLMs) can reliably infer causal structures from scientific literature to map biological interactions, moving beyond simple textual coherence to establish genuine causal claims.

The authors introduce a novel framework for **Zero-Shot Causal Inference using Retrieval-Augmented Generation (RAG)**, positioning LLMs as "orchestration tools" that distill vast collections of scientific articles into structured causal graphs. Technically, the system models relationships as directed graphs utilizing ancestral semantics and transitive closure to ensure logical consistency. A key innovation is the evaluation methodology: rather than relying solely on text consistency, the authors validate LLM-generated causal claims against real-world interventional data. Ground truth is constructed from **Perturb-seq single-cell perturbation screens** that combine CRISPR-based gene editing with scRNA-seq, providing a rigorous gold standard for benchmarking against existing resources like the STRING database and other data-driven causal structure learning methods.

In experiments covering over one hundred biological variables and testing thousands of causal hypotheses, the study demonstrated that the proposed RAG-enhanced framework significantly outperforms established baselines. Quantitatively, the optimized LLM system achieved an **Area Under the Precision-Recall Curve (AUPRC) of 0.68**, a substantial improvement over the STRING database baseline, which recorded an AUPRC of only 0.24. Standard causal structure learning algorithms performed at near-random levels, with AUPRCs around 0.10. While the study found that larger models yielded the highest performance, results showed that smaller models could achieve competitive accuracy when configured with tailored retrieval-augmentation and specific prompting strategies, proving that configuration is more critical than the scaling of model parameters.

This research significantly advances the intersection of AI and science by establishing a rigorous, quantitative standard for assessing LLMs against experimental biological data. It validates the concept of using LLMs not merely as text generators, but as high-level reasoning engines capable of complex causal discovery and hypothesis generation. By bridging the gap between literature-based knowledge and experimental validation with concrete performance metrics, this approach provides a scalable blueprint for mapping molecular networks and offers a new, practical methodology for researchers leveraging AI to navigate the rapidly expanding volume of biological literature.

***

## Key Findings

*   **Small Model Efficacy:** Relatively small Large Language Models (LLMs) are capable of capturing meaningful aspects of causal structure in biological systems, provided they are correctly configured.
*   **Strategy Over Scale:** The successful inference of causal relationships relies heavily on **tailored retrieval-augmentation** and specific prompting strategies, rather than solely on model size.
*   **LLMs as Orchestrators:** The study supports the concept of LLMs acting as "orchestration tools" in biological discovery, capable of distilling complex scientific knowledge into formats suitable for downstream analysis.
*   **Handling Complexity:** The models were able to process large collections of scientific articles to generate inferences, even when faced with potentially conflicting information sources.

***

## Methodology

*   **Novel Framework:** The authors established a framework specifically designed to evaluate LLMs for zero-shot inference of causal relationships within biological contexts.
*   **Validation Strategy:** LLM-generated causal claims were systematically evaluated against **real-world interventional data**, rather than relying solely on textual consistency.
*   **Data Volume:** The study analyzed a significant volume of data, covering over one hundred biological variables and testing thousands of causal hypotheses.
*   **Optimization:** The methodology involved testing various prompting techniques and retrieval-augmentation strategies to optimize performance on causal inference tasks.

***

## Technical Details

*   **Core Approach:** Zero-Shot Causal Inference using Retrieval-Augmented Generation (RAG).
*   **LLM Function:** LLMs act as orchestration tools to distill literature into structured causal graphs.
*   **Success Factors:** Performance relies on tailored retrieval-augmentation and prompting strategies rather than scaling model parameters.
*   **Graph Modeling:**
    *   Relationships modeled as a directed graph.
    *   Utilizes ancestral semantics and transitive closure.
*   **Ground Truth Construction:**
    *   Source: Perturb-seq single-cell perturbation screens.
    *   Technology: CRISPR-based gene editing and scRNA-seq.
*   **Benchmarking:**
    *   Compared against the STRING database.
    *   Compared with data-driven Causal Structure Learning methods.

***

## Results

*   **Performance Viability:** The study finds that relatively small LLMs are capable of capturing meaningful biological causal structures with proper configuration.
*   **Critical Factors:** Retrieval-augmentation and prompting strategies are identified as critical success factors, outweighing the benefits of larger model sizes.
*   **Conflict Resolution:** Models demonstrate the ability to process large collections of scientific articles and generate inferences from conflicting sources.
*   **Biological Insights:** The approach enables the identification of upstream regulators and regulatory pathways.
*   **Validation Metrics:**
    *   **Optimized LLM System:** AUPRC of **0.68**.
    *   **STRING Database Baseline:** AUPRC of **0.24**.
    *   **Standard Causal Learning Algorithms:** AUPRC ~0.10 (near-random).
*   **Methodology:** Validation uses graph matching against edges derived from Perturb-seq experiments and comparison with the STRING database.

***

## Contributions

*   **Rigorous Assessment:** The paper presents a rigorous approach for assessing LLMs against experimental data, bridging the gap between causal learning theory and practical scientific discovery.
*   **Network Characterization:** It addresses the challenge of characterizing causal molecular networks‚Äîwhich are often mediated by latent variables and cellular context‚Äîby leveraging the encoded knowledge within LLMs.
*   **Broad Applicability:** The proposed approach to assessing LLMs using experimental data establishes a relevant methodology for a broad range of problems at the intersection of AI and science.