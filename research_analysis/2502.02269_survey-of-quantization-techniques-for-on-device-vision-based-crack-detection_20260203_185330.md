---
title: Survey of Quantization Techniques for On-Device Vision-based Crack Detection
arxiv_id: '2502.02269'
source_url: https://arxiv.org/abs/2502.02269
generated_at: '2026-02-03T18:53:30'
quality_score: 9
citation_count: 19
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Survey of Quantization Techniques for On-Device Vision-based Crack Detection

*Yuxuan Zhang; Luciano Sebastian Martinez-Rau; Quynh Nguyen Phuong Vu; Bengt Oelmann; Sebastian Bader*

---

> ### **Quick Facts**
>
> | Metric | Details |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **References** | 19 Citations |
> | **Top Architecture** | MobileNetV2x0.5 |
> | **Best Technique** | QAT (Torch-QAT) |
> | **Peak F1-Score** | 0.8376 |
> | **Target Hardware** | Resource-constrained UAVs |

---

## Executive Summary

Infrastructure inspection is critical for ensuring public safety, yet traditional manual methods are inefficient and hazardous. Unmanned Aerial Vehicles (UAVs) offer a promising solution for autonomous monitoring, but deploying vision-based deep learning models for crack detection on these resource-constrained, battery-powered devices presents a significant challenge. The primary issue is balancing the high computational demands of Convolutional Neural Networks (CNNs) with the limited processing power, memory, and energy budgets available on edge hardware.

This paper addresses the urgent need for effective model optimization techniques that enable real-time, accurate structural health monitoring without draining UAV resources. The authors introduce a comprehensive cross-platform benchmarking framework to evaluate the efficacy of quantization techniques specifically tailored for lightweight CNNs in edge environments.

The study rigorously compares MobileNetV1x0.25 and MobileNetV2x0.5 architectures across three major deep learning frameworks: TensorFlow, PyTorch, and ONNX. The technical core of the research lies in the comparative analysis of three distinct quantization approaches: **Quantization-Aware Training (QAT)**, **Post-Training Quantization (PTQ)**, and **Dynamic Quantization**.

The experimental results highlight distinct trade-offs between accuracy and resource efficiency:
*   **QAT (Torch-QAT)** proved to be the most effective approach, achieving an F1-score of **0.8376** on MobileNetV2x0.5, maintaining accuracy levels virtually identical to the floating-point baseline.
*   **PTQ (TensorFlow)** significantly reduced memory footprint and energy consumption but suffered from notable accuracy degradation.
*   **Dynamic Quantization (PyTorch)** preserved model accuracy but encountered specific deployment challenges.

By demonstrating that QAT successfully bridges the gap between high accuracy and low resource consumption, the study validates a viable path for autonomous, vision-based infrastructure inspection on commercial UAV hardware.

---

## Key Findings

*   **Quantization-Aware Training (QAT)** consistently achieves accuracy levels comparable to floating-point models while maintaining high resource efficiency.
    *   *Highlight:* Torch-QAT on MobileNetV2x0.5 achieved an F1-score of **0.8376**.
*   **Post-Training Quantization (PTQ)** significantly reduces memory footprint and energy consumption but results in notable accuracy loss, particularly within the TensorFlow framework.
*   **Dynamic Quantization** is effective at preserving accuracy but encounters specific deployment challenges when used with the PyTorch platform.
*   The application of these quantization techniques enables **real-time, low-power crack detection** capabilities on resource-constrained UAV hardware.

---

## Methodology

The study employed a comparative evaluation framework designed to assess the performance of lightweight architectures under strict resource constraints.

*   **Architectures Evaluated:**
    *   MobileNetV1x0.25
    *   MobileNetV2x0.5
*   **Platforms Tested:**
    *   TensorFlow
    *   PyTorch
    *   Open Neural Network Exchange (ONNX)
*   **Core Experimental Variables:**
    *   **Dynamic Quantization**
    *   **Post-Training Quantization (PTQ)**
    *   **Quantization-Aware Training (QAT)**
*   **Objective:** Balance accuracy against computational efficiency for UAV deployment.

---

## Technical Details

**Primary Architecture**
*   **Backbone:** MobileNetV2x0.5 (Lightweight)

**Quantization Techniques & Tools**
*   **Quantization-Aware Training (QAT):** Implemented using the **Torch-QAT** library.
*   **Post-Training Quantization (PTQ):** Executed within the **TensorFlow** framework.
*   **Dynamic Quantization:** Executed within the **PyTorch** framework.

**Target Application**
*   **Use Case:** Vision-based crack detection.
*   **Hardware:** Resource-constrained UAV (Unmanned Aerial Vehicle).
*   **Priorities:** Low-power consumption and real-time inference capabilities.

---

## Results

*   **QAT (Torch-QAT):**
    *   Achieved an F1-score of **0.8376** on MobileNetV2x0.5.
    *   Accuracy levels were comparable to floating-point models.
*   **PTQ (TensorFlow):**
    *   Resulted in significant reduction in memory footprint and energy consumption.
    *   Suffered notable accuracy loss compared to the floating-point baseline.
*   **Dynamic Quantization (PyTorch):**
    *   Effective at preserving accuracy.
    *   Encountered specific deployment challenges on the target hardware.
*   **Overall System Performance:**
    *   Successfully enabled real-time, low-power crack detection on UAVs.

---

## Contributions

*   **Cross-Platform Benchmarking:** Provided a comprehensive analysis of quantization techniques across multiple major frameworks for lightweight CNNs in the context of structural health monitoring.
*   **Enabling Edge Deployment:** Demonstrated a viable path for real-time, energy-efficient vision-based crack detection on UAVs, addressing the limitations of traditional sensor-based methods.
*   **Strategic Guidance:** Offered actionable insights into the trade-offs between accuracy and computational efficiency, assisting in the selection of optimal optimization strategies for autonomous infrastructure inspections.