# Test Time Adaptation Using Adaptive Quantile Recalibration

*Paria Mehrbod; Pedro Vianna; Geraldin Nanfack; Guy Wolf; Eugene Belilovsky*

***

> ### **Quick Facts**
> | Metric | Detail |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **References** | 40 Citations |
> | **Core Method** | Adaptive Quantile Recalibration (AQR) |
> | **Normalization Support** | BatchNorm, GroupNorm, LayerNorm |
> | **Key Datasets** | CIFAR-10-C, CIFAR-100-C, ImageNet-C |

***

## Executive Summary

Deep neural networks frequently suffer performance degradation when deployed in dynamic environments where test data distributions differ from training data, a phenomenon known as domain shift. While Test-Time Adaptation (TTA) aims to mitigate this by updating models during inference without expensive retraining, existing solutions face significant limitations. Many current methods rely on simplistic affine transformations that adjust only mean and variance, failing to capture the complex, non-Gaussian shapes of corrupted activation distributions. Furthermore, state-of-the-art techniques are often constrained to architectures utilizing Batch Normalization and exhibit instability when inference batch sizes fluctuate or are small, restricting their practical applicability in real-world, resource-constrained scenarios.

The researchers introduce **Adaptive Quantile Recalibration (AQR)**, a novel unsupervised TTA technique that shifts the focus from simple statistic updates to full distribution alignment. Technically, AQR modifies pre-activation distributions by aligning channel-wise quantiles between the target test data and pre-computed source statistics using a nonparametric, piecewise-linear transformation. This approach allows the model to capture the complete shape of the activation distribution rather than relying solely on moments. To ensure robustness against varying inference batch sizes—a common failure point for TTA—the method employs a tailored "Average Sample Tails" strategy. This stabilizes the estimation of distribution tails (the 0th and 100th percentiles) through sampling, significantly reducing bias in low-data scenarios.

AQR demonstrates consistent superiority over established baselines—including Not Adapted, SAR, TENT, and TTN—across CIFAR-10-C, CIFAR-100-C, and ImageNet-C, with performance gains becoming more pronounced at higher corruption severities. Specific ablation studies validate the method's design choices: the "Average Sample Tails" calibration achieved an accuracy of **33.7 ± 16.6%** (Batch Size 128) compared to **30.8 ± 16.3%** for standard implementation, while a naive clipping strategy degraded performance to approximately **3.4%**. Furthermore, the method proved versatile, maintaining robust performance across diverse architectures such as ResNet50, ViT Base, and ViT Small.

This work significantly broadens the scope of test-time adaptation by extending its viability beyond Batch Normalization to architectures utilizing GroupNorm and LayerNorm. Theoretically, AQR achieves zero Mean Squared Error (MSE) under assumptions of strictly increasing continuous activation and corruption transformations, providing a rigorous foundation for its efficacy. By offering a retraining-free solution that robustly handles complex distribution shifts and variable batch sizes, AQR addresses critical deployment challenges, enabling the practical use of deep learning models in unpredictable environments.

***

## Key Findings

*   **Superior Performance:** AQR consistently outperforms existing test-time adaptation baselines on CIFAR-10-C, CIFAR-100-C, and ImageNet-C.
*   **Batch Size Robustness:** The method demonstrates stability across varying batch sizes through a specialized tail calibration strategy.
*   **Architectural Versatility:** Successfully adapts models across different normalization architectures, including BatchNorm, GroupNorm, and LayerNorm.
*   **Rich Distribution Modeling:** Captures the full shape of complex activation distributions rather than relying solely on mean and variance approximations.

***

## Methodology

The researchers propose **Adaptive Quantile Recalibration (AQR)**, an unsupervised test-time adaptation technique designed to function without model retraining or prior knowledge of the target domain.

*   **Core Mechanism:** The method modifies pre-activation distributions by aligning quantiles on a channel-wise basis. It leverages source-domain statistics computed during the training phase.
*   **Stability Strategy:** To ensure robustness against varying batch sizes during inference, AQR employs a tailored **tail calibration strategy**. This is specifically designed to stabilize the estimation of distribution tails, which are typically volatile in small sample sizes.

***

## Technical Specifications

| Component | Description |
| :--- | :--- |
| **Transformation Type** | Nonparametric, piecewise-linear transformation based on quantiles. |
| **Theoretical Basis** | Achieves zero Mean Squared Error (MSE) under assumptions of strictly increasing continuous activation functions and strictly increasing corruption transformations. |
| **Percentiles Used** | Standard implementation utilizes **101 percentiles** ($p_0$ to $p_{100}$). |
| **Tail Handling** | Employs an "**Average Sample Tails**" strategy to approximate the 0th and 100th percentiles by sampling, effectively reducing bias in small batches. |
| **Compatibility** | Supports BatchNorm, GroupNorm, and LayerNorm architectures. |

***

## Results

### Benchmark Performance
AQR consistently outperformed baselines (Not Adapted, SAR, TENT, TTN) on **ImageNet-C (ResNet50)**. Notably, the accuracy gains increased significantly at higher corruption severities.

### Ablation Studies
*   **Tail Calibration:**
    *   *Average Sample Tails:* **33.7 ± 16.6%** accuracy (Batch Size 128).
    *   *Standard AQR:* **30.8 ± 16.3%** accuracy.
    *   *Clipping:* Significantly degraded performance to **~3.4%**.
*   **Granularity Analysis (Severity 3, Batch Size 128):**
    *   *101 Percentiles:* **53.92 ± 11.79%** accuracy.
    *   *11 Percentiles:* **46.37 ± 13.06%** accuracy.

### Architecture Robustness
The method demonstrated robustness across a variety of architectures, including:
*   ResNet50
*   ViT Base
*   ViT Small
*(Tested on CIFAR-10-C, CIFAR-100-C, and ImageNet-C)*

***

## Core Contributions

1.  **Novel Method Introduction:** Introduced AQR, a test-time adaptation method that shifts focus from simple statistic updates to full distribution alignment via channel-wise quantile recalibration.
2.  **Extended Compatibility:** Extended test-time adaptation capabilities beyond Batch Normalization to include GroupNorm and LayerNorm architectures.
3.  **Robustness Strategy:** Provided a robust tail calibration strategy ("Average Sample Tails") to ensure reliable adaptation even with fluctuating batch sizes.
4.  **Practical Deployment:** Demonstrated practical deployment feasibility as an effective, retraining-free solution for dynamic environments with unpredictable test distributions.