# Causal Reasoning Favors Encoders: On The Limits of Decoder-Only Models

*Amartya Roy; Elamparithy M; Kripabandhu Ghosh; Ponnurangam Kumaraguru; Adrian de Wynter*

---

### âš¡ Quick Facts

| Metric | Details |
| :--- | :--- |
**Quality Score** | 8/10 |
**Total Citations** | 40 |
**Training Volume** | 40,000 instances (Depth 0â€“7) |
**Max Evaluation Depth** | Depth 11 |
**Core Benchmark** | SimpleLogic (NL & Non-NL) |
**Architectures Compared** | Encoder (BERT), Encoder-Decoder (BART), Decoder-Only (GPT, Qwen, Claude) |

---

## Executive Summary

### ðŸš¨ Problem
The research addresses the critical limitations of current Decoder-only Large Language Models (LLMs) and In-Context Learning (ICL) in performing robust causal reasoning. While LLMs have shown competence in linguistic tasks, this paper highlights that ICL is insufficient for logical deduction because it overrelies on spurious lexical correlations and irrelevant input features rather than structural logic. The study questions the industry-wide shift toward Decoder-only architectures by investigating whether these models can truly generalize across distributional shiftsâ€”such as handling non-natural language or deeper logical proofsâ€”or if their performance is merely a byproduct of immense scale rather than architectural suitability.

### ðŸ’¡ Innovation
The key innovation is a theoretical framework distinguishing between **"Global Aggregation"** (characteristic of Encoders and Encoder-Decoders) and **"Recursive Aggregation"** (characteristic of Decoder-only models). The authors posit that Encoders project inputs into a latent space that enables simultaneous information integration, favoring single-pass logical deduction, whereas Decoders require step-by-step processing that introduces latency. To rigorously test this, the authors developed the **"SimpleLogic"** benchmark, consisting of 40,000 natural language samples and 3,600 Out-of-Distribution (OOD) non-natural language samples (random character tuples with zero vocabulary overlap). This benchmark strictly isolates multihop conjunctive reasoning capabilities from language proficiency, using a controlled proof-chain depth to evaluate performance independent of linguistic mastery.

### ðŸ“Š Results
Empirical results indicate that In-Context Learning is significantly less effective than fine-tuning for causal reasoning, frequently failing to ignore spurious features. Fine-tuned Encoder (BERT) and Encoder-Decoder (BART) models demonstrated superior generalization on OOD test sets, particularly in non-natural language environments and deeper logical proofs (depth up to 11), compared to standard Decoder-only models. While Decoder-only architectures were found to be notably brittle to distributional shifts at smaller scales, the study concedes that their accuracy and robustness can match or exceed Encoder models when utilized at "very large scales," performing well on binary label accuracy tasks involving local checks and composition.

### ðŸš€ Impact
This paper significantly influences the field by challenging the assumption that Decoder-only architectures are universally superior for all reasoning tasks. It provides concrete architectural guidance, suggesting that for cost-effective, robust causal reasoning in environments prone to distributional shifts, fine-tuned Encoder or Encoder-Decoder models are preferable to smaller Decoder-only models. The findings underscore that scaling is not the only path to logical robustness and reignite interest in non-decoder architectures for applications requiring strict adherence to logical structure over linguistic fluency.

---

## Key Findings

*   **Insufficiency of ICL:** In-Context Learning (ICL) is insufficient for causal reasoning tasks. It tends to overfocus on irrelevant input features and relies on spurious lexical relations rather than logical structure.
*   **Robustness of Encoders:** Fine-tuned Encoder and Encoder-Decoder models demonstrate significantly more robust generalization across distributional shifts compared to standard Decoder-only models.
*   **Brittleness of Decoders:** Decoder-only architectures are notably brittle to distributional shifts (such as moving from Natural Language to Non-Natural Language) at smaller scales.
*   **The Scale Factor:** The robustness and generalization capabilities of Decoder-only models can match or surpass Encoder models, but only when utilized at **very large scales**.

---

## Methodology

The study employed a rigorous comparative analysis across three distinct architectural classes:

1.  **Architectural Classes:** Encoder-only (e.g., BERT), Encoder-Decoder (e.g., BART), and Decoder-only (e.g., GPT, Qwen, Claude).
2.  **Benchmarking Strategy:** Researchers benchmarked the performance of **fine-tuned models** directly against **zero-shot** and **few-shot In-Context Learning (ICL)** strategies.
3.  **Evaluation Environments:** To strictly test reasoning capabilities, models were evaluated on causal reasoning tasks in two distinct environments:
    *   **Natural Language (NL):** Standard linguistic tasks.
    *   **Non-Natural Language (NNL):** Synthetic environments to isolate reasoning from linguistic fluency.
4.  **Objective:** The primary goal was to test multihop conjunctive reasoning capabilities and the models' resistance to spurious correlations.

---

## Technical Details

### Architectural Distinction
*   **Encoder (Global Aggregation):** Capable of simultaneous information integration, enabling single-pass logical deduction.
*   **Decoder-Only (Recursive Aggregation):** Requires step-by-step processing, introducing latency and potential susceptibility to error propagation in chains of thought.

### Dataset: SimpleLogic Benchmark
The study utilized a tailored benchmark comprised of tuples: *(facts, rules, query, explanation, label)*. Complexity is controlled by **Proof Chain depth**.

| Dataset Split | Sample Size | Description |
| :--- | :--- | :--- |
| **Training Set** | 40,000 | Natural language samples; Proof depth 0â€“7. |
| **OOD Test Set (NL)** | 3,600 | Out-of-Distribution Natural Language; Proof depth 0â€“11 (deeper reasoning). |
| **OOD Test Set (NNL)** | 3,600 | Non-Natural Language (random characters); Zero vocabulary overlap with training. |

### Models Evaluated
*   **Encoder:** BERT
*   **Encoder-Decoder:** BART
*   **Decoder-Only LLMs:** GPT, Qwen, Claude

### Evaluation Metrics
*   **Metric:** Binary label accuracy.
*   **Requirements:** Success depends on performing local checks, composition, and conjunctive control over the logic chain.

---

## Contributions

*   **Theoretical Framework:** Proposes that Encoder and Encoder-Decoder architectures are inherently better suited for multihop conjunctive reasoning due to their ability to project input into a latent space for single-pass deduction.
*   **Architectural Guidance:** Provides empirical evidence suggesting that fine-tuned Encoder or Encoder-Decoder models are preferable for cost-effective, robust causal reasoning, especially when facing distributional shifts.
*   **Identification of Limitations:** Clearly identifies the specific weaknesses of ICL and Decoder-only models, specifically highlighting their vulnerability to distributional shifts and reliance on lexical shortcuts.

---

### Reference Information
*   **Quality Score:** 8/10
*   **References:** 40 citations