---
title: A General Close-loop Predictive Coding Framework for Auditory Working Memory
arxiv_id: '2503.12506'
source_url: https://arxiv.org/abs/2503.12506
generated_at: '2026-02-03T13:52:37'
quality_score: 9
citation_count: 33
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# A General Close-loop Predictive Coding Framework for Auditory Working Memory

*Zhongju Yuan; Geraint Wiggins; Dick Botteldooren*

***

### ðŸ“Š Quick Facts

| Category | Details |
| :--- | :--- |
| **Core Concept** | Close-loop predictive coding for auditory working memory |
| **Evaluation** | ESC-50 (Environmental), LibriSpeech (Speech) |
| **Top Performance** | **0.923** Semantic Similarity (LibriSpeech) |
| **Audio Quality** | **0.845** STOI, **8.4 dB** SI-SDR (Online Mode) |
| **Innovation** | Bridges cognitive working memory with neural networks |
| **Citations** | 33 References |

***

## Executive Summary

This research addresses the critical gap in computational modeling between cognitive science and artificial intelligence, specifically regarding auditory working memory (AWM). While working memoryâ€”the brainâ€™s ability to temporarily store and manipulate information no longer present in the environmentâ€”is a foundational cognitive process, there are few neural network implementations capable of simulating this for auditory data. The lack of such models hinders the development of AI systems that can process and recall audio sequences with human-like fidelity, limiting applications in speech processing and environmental sound analysis.

The authors introduce a general framework rooted in a closed-loop predictive coding paradigm designed to perform short-term auditory signal memory tasks. Technically, the architecture operates in two distinct phases: a "**Write**" phase for memorization and a "**Read**" phase for recall. During the Write phase, the model is trained to minimize the Euclidean distance between input audio and reconstructed segments. The Read phase utilizes a closed-loop feedback mechanism with iterative hidden state updates, employing auto-regressive correction where the loss is calculated as the Euclidean distance between the stored segment and the most recently recalled segment. The framework further distinguishes between an "**Offline**" mode (standard feedforward processing) and an "**Online**" mode (iterative feedback), allowing for dynamic error correction during recall.

The proposed model was evaluated on the ESC-50 dataset (2,000 environmental sound samples) and a subset of LibriSpeech (180 clean speech samples) using Semantic Similarity (SS), Short-Time Objective Intelligibility (STOI), and Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) metrics. On the LibriSpeech dataset, the "Online" mode achieved a Semantic Similarity of **0.923**, significantly outperforming the "Offline" baseline of **0.881**. This improvement was corroborated by objective audio quality metrics: the Online mode achieved a **STOI** score of **0.845** and a **SI-SDR** of **8.4 dB**, compared to the Offline mode's **0.798** and **5.2 dB**, respectively. Similar trends were observed on the ESC-50 dataset, where the Online mode secured a Semantic Similarity of **0.897** versus the Offline mode's **0.862**, demonstrating the framework's efficacy in enhancing waveform accuracy and temporal alignment through iterative feedback.

This work significantly advances the field of auditory cognitive modeling by successfully bridging cognitive theories of working memory with practical neural network implementations. By validating the framework across diverse domainsâ€”specifically both environmental sounds and speechâ€”the authors demonstrate a level of generalizability previously lacking in the field. The quantitative superiority of the "Online" closed-loop mechanism over standard feedforward approaches highlights the importance of iterative error correction in auditory recall. This establishes the model as a versatile tool for future research, offering a robust architecture for simulating how biological systems might retain and manipulate auditory information, with potential implications for improving robustness in speech recognition and audio processing systems.

***

## Key Findings

*   **High Semantic Similarity:** The proposed framework achieved high semantic similarity in performance across both testing environments.
*   **Benchmark Success:** The model was successfully evaluated on two widely used benchmark datasets (ESC-50 and LibriSpeech).
*   **Domain Versatility:** The framework demonstrated efficacy in handling diverse auditory domains, specifically environmental sounds and speech.

***

## Methodology

The authors developed a general framework rooted in a close-loop predictive coding paradigm. The approach is designed to perform short auditory signal memory tasks, simulating the temporary storage and manipulation of information no longer present in the environment, with a focus on bridging cognitive processes (working memory) with neural network implementations.

***

## Technical Details

The framework utilizes a close-loop predictive coding architecture with iterative hidden state updates.

### Architecture & Phases

1.  **Write Phase (Memorization):**
    *   **Loss Function:** Euclidean distance between input audio and reconstructed segments.
2.  **Read Phase (Recall):**
    *   **Mechanism:** Close-loop feedback mechanism with auto-regressive correction.
    *   **Loss Function:** Euclidean distance between the stored segment and the most recently recalled segment.

### Operational Modes

*   **Offline Mode:** Standard feedforward processing.
*   **Online Mode:** Iterative feedback with close-loop error correction.

***

## Contributions

*   **Bridging the Gap:** Addressing a research gap by providing a neural network model for auditory working memory.
*   **Novel Application:** Introducing a novel, generalizable application of close-loop predictive coding to auditory processing tasks.
*   **Validation of Generality:** Validating the generality of the framework by successfully applying it to both environmental sounds and speech, demonstrating its versatility as a tool for auditory cognitive modeling.

***

## Results

The model was evaluated on the **ESC-50** dataset (2,000 environmental sound samples) and a subset of **LibriSpeech** (180 clean speech samples) using Semantic Similarity (SS) metrics based on state-of-the-art embeddings.

### Performance Comparison

| Dataset | Mode | Semantic Similarity | STOI | SI-SDR (dB) |
| :--- | :--- | :--- | :--- | :--- |
| **LibriSpeech** | **Online** | **0.923** | **0.845** | **8.4** |
| (Speech) | Offline | 0.881 | 0.798 | 5.2 |
| | | | | |
| **ESC-50** | **Online** | **0.897** | - | - |
| (Environmental) | Offline | 0.862 | - | - |

Analysis indicated that the **'Online'** (with close-loop) method significantly improved waveform accuracy and alignment compared to the 'Offline' method, demonstrating effectiveness across both environmental and speech domains.

***

**Quality Score:** 9/10  
**References:** 33 citations