---
title: 'Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration'
arxiv_id: '2507.0652'
source_url: https://arxiv.org/abs/2507.06520
generated_at: '2026-02-03T13:00:11'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration

*Xinyuan Song; Zeyu Wang; Siyi Wu; Tianyu Shi; Lynn Ai*

---

> ### ðŸ“Š Quick Facts
> 
> **Benchmark:** GAIA (466 queries)
> 
> *   **Overall Accuracy:** 24.1% (vs 15.0% baseline)
> *   **Level 3 Accuracy:** 18.0% (vs 8.0% baseline)
> *   **Latency Reduction:** 35 seconds (vs 52s baseline)
> *   **Cost Efficiency:** 0.22x normalized cost (~4.5x reduction)
> *   **Token Savings:** Reduced to one-sixth of baseline
> *   **Quality Score:** 9/10

---

## Executive Summary

### Problem
Current multi-agent systems face significant challenges in effectively coordinating heterogeneous AI agents for complex, real-world tasks. The primary difficulty lies in optimizing task dispatch to balance computational efficiency with accuracy, particularly within hybrid execution environments where synchronous and asynchronous operations must coexist. Furthermore, existing frameworks often lack robust mechanisms for error handling and observability, leading to high operational costs and latency. Addressing these orchestration bottlenecks is critical for advancing the capabilities of general-purpose AI assistants, as demonstrated by benchmarks like GAIA, which require seamless integration of diverse tools and resilient planning strategies.

### Innovation
The researchers introduce **Gradientsys**, a novel scheduling framework that leverages a centralized LLM Scheduler operating on the ReAct paradigm with a scratchpad for state tracking. The core technical innovation lies in its integration of the typed Model Context Protocol (MCP) and a dynamic Tool Registry, which enables an LLM-driven, one-to-many dispatch mechanism capable of parallel execution and capacity-aware scheduling. This architecture supports hybrid synchronous and asynchronous modes, allowing the system to dynamically adjust to capacity constraints while maintaining streaming execution for reduced latency. Additionally, the system incorporates a resilient retry-and-replan mechanism and real-time observability via Server-Sent Events (SSE) to ensure transparency and graceful failure handling.

### Results
Evaluated against MinionS-style baselines on the GAIA benchmark (466 queries), Gradientsys demonstrated substantial performance improvements across all key metrics. The framework achieved an Overall Accuracy of **24.1%** (a 60% relative increase over the 15.0% baseline) and significantly improved Level 3 Accuracy to **18.0%** (a 125% relative increase over the 8.0% baseline). Beyond accuracy, the system optimized resource utilization, reducing Average Latency to **35 seconds** compared to the baseline's 52 seconds and achieving a Normalized Cost of **0.22x**â€”representing approximately a 4.5x cost reduction. Token consumption was reduced to one-sixth of the baseline, with specific document processing tasks costing $0.08 compared to $0.50 for the baseline approach.

### Impact
Gradientsys establishes a new paradigm for multi-agent orchestration by demonstrating that LLM-powered schedulers can effectively manage complex workflows with superior efficiency and resilience. The successful implementation of typed MCP and ReAct orchestration validates the feasibility of using semantic understanding for dynamic resource allocation and error recovery in hybrid environments. By drastically reducing latency and API costs while improving success rates on rigorous benchmarks, this work provides a scalable blueprint for building next-generation general AI assistants. These findings suggest that intelligent scheduling is not merely a logistical necessity but a critical component for maximizing the performance and economic viability of autonomous agent systems.

---

## Key Findings

*   **Performance:** Gradientsys outperforms MinionS-style baselines on the GAIA general-assistant benchmark with higher task success rates.
*   **Efficiency:** The framework delivers results with significantly reduced latency and lower API costs.
*   **Orchestration:** The integration of an LLM-powered scheduler with a ReAct-based dynamic planning loop proves effective for coordinating complex agent tasks.
*   **Resilience:** The architecture successfully handles failures through a robust retry-and-replan mechanism in hybrid execution environments.

---

## Methodology

The researchers introduced **Gradientsys**, a framework centered on an LLM-powered scheduler that utilizes a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. The methodology focuses on:

*   **Intelligent Dispatch:** Enabling one-to-many task dispatch to facilitate the parallel execution of heterogeneous agents.
*   **Hybrid Execution:** Supporting both hybrid synchronous/asynchronous modes and capacity constraints.
*   **Validation:** The approach was validated through an architectural overview comparing metrics and empirical experiments on the GAIA benchmark.

---

## Technical Details

The system architecture is composed of several sophisticated components designed to handle dynamic agent workflows:

*   **Core Scheduling:**
    *   **Centralized LLM Scheduler:** Utilizes the ReAct paradigm.
    *   **State Tracking:** Implements a scratchpad mechanism to maintain context.

*   **Integration & Tools:**
    *   **Model Context Protocol (MCP):** Uses a typed protocol for tool integration.
    *   **Dynamic Tool Registry:** Handles metadata such as concurrency limits and cost.

*   **Execution Management:**
    *   **Hybrid Sync/Async Dispatcher:** Manages parallelism and load distribution.
    *   **Streaming Execution:** Optimized for reduced latency.
    *   **Context Management:** Utilizes summarization to handle context windows efficiently.

*   **Fault Tolerance:**
    *   **Retry-and-Replan:** A mechanism designed to gracefully handle failures.

*   **Observability:**
    *   **Server-Sent Events (SSE):** Provides real-time transparency into system operations.

---

## Contributions

*   **Framework Development:** Created a next-generation scheduling framework using typed MCP and ReAct orchestration to coordinate diverse AI agents.
*   **Dispatch Mechanism:** Introduced an LLM-driven one-to-many dispatch mechanism capable of parallel execution and capacity-aware scheduling.
*   **Observability:** Implemented enhanced observability using Server-Sent Events (SSE) to provide real-time transparency.
*   **System Design:** Designed a resilient system architecture incorporating retry-and-replan mechanisms for graceful failure handling.

---

## Results

The evaluation on the GAIA benchmark (466 queries) yielded the following comparisons against the baseline:

| Metric | Gradientsys | Baseline | Improvement |
| :--- | :--- | :--- | :--- |
| **Overall Accuracy** | 24.1% | 15.0% | +60% relative |
| **Level 3 Accuracy** | 18.0% | 8.0% | +125% relative |
| **Average Latency** | 35s | 52s | ~33% faster |
| **Normalized Cost** | 0.22x | 1.00x | ~4.5x reduction |
| **Document Processing Cost** | $0.08 | $0.50 | Significant savings |

---

**Quality Score:** 9/10  
**References:** 40 citations