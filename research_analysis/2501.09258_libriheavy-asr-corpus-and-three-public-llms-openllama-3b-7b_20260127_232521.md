---
title: LibriHeavy ASR corpus and three public LLMs, OpenLLaMA 3B & 7B
arxiv_id: '2501.09258'
source_url: https://arxiv.org/abs/2501.09258
generated_at: '2026-01-27T23:25:21'
quality_score: 6
citation_count: 36
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LibriHeavy ASR corpus and three public LLMs, OpenLLaMA 3B & 7B

*Martin Kocour, Xiaodan Zhuang, Adnan Haider, Takaaki Hori, Erik Mc*

> ### ðŸ“Œ Quick Facts
> *   **Dataset Scale:** ~50,000 hours of English speech (LibriHeavy)
> *   **Baseline Model:** Conformer Transducer
> *   **Evaluation Models:** OpenLLaMA (3B, 7B), LLaMA-13B
> *   **Best WER (Test-Clean):** 1.48% (using LLaMA-13B)
> *   **Key Innovation:** Delayed Fusion framework for efficient LLM integration
> *   **Report Quality Score:** 6/10

---

## Executive Summary

Current research in Automatic Speech Recognition (ASR) is constrained by the availability of large-scale training corpora. While industrial systems benefit from datasets comprising hundreds of thousands of hours, the largest public corpus, LibriSpeech, contains only 960 hours. This data scarcity prevents the open-source community from effectively training high-capacity models that adhere to scaling laws.

Additionally, integrating the semantic prowess of Large Language Models (LLMs) into ASR pipelines presents a significant engineering challenge. Standard fusion techniques often incur prohibitive computational costs and latency, rendering them impractical for real-time applications and creating a trade-off between accuracy and efficiency.

This work introduces **LibriHeavy**, a new open-source dataset comprising approximately 50,000 hours of English speech sourced from LibriVox audiobooks. To generate labels at this scale, the authors utilized a robust self-supervised model to produce high-quality pseudo-labels.

On the architectural front, the paper proposes a **Delayed Fusion framework** to incorporate public LLMs efficiently. This method decouples the heavy LLM computation from the acoustic decoding pass. By generating an N-best list of hypotheses using a Conformer Transducer acoustic model and subsequently rescoring them with an LLM, the system leverages semantic context for error correction.

The release of LibriHeavy addresses the data bottleneck in open-source ASR research, providing a dataset scale commensurate with industrial requirements. By validating Delayed Fusion across multiple public LLMs, the authors provide a reproducible methodology for enhancing ASR accuracy without sacrificing inference efficiency. This work establishes new state-of-the-art benchmarks for open-source models on LibriSpeech and proves that public LLMs can be effectively leveraged to close the performance gap between proprietary and community-developed speech recognition systems.

---

## Key Findings

*   **Data Bottleneck Solved:** The release of LibriHeavy (~50k hours) significantly bridges the gap between proprietary industrial datasets and public resources.
*   **Strong Baselines:** Training a Conformer Transducer solely on LibriHeavy achieves a Word Error Rate (WER) of **1.76%** on LibriSpeech test-clean and **3.95%** on test-other.
*   **Delayed Fusion Efficacy:** The proposed fusion method consistently reduces error rates across different model sizes without requiring the LLM to be active during the initial acoustic pass.
*   **Capacity Correlation:** There is a direct correlation between LLM parameter count and ASR accuracy; larger models provide better rescoring results.
*   **State-of-the-Art Performance:** Integrating LLaMA-13B achieved the lowest WER, setting new benchmarks for open-source ASR on standard test sets.

---

## Methodology

The research addresses ASR scaling and LLM integration through a two-pronged methodological approach:

1.  **Dataset Construction (LibriHeavy):**
    *   **Sourcing:** Approximately 50,000 hours of English speech were collected from LibriVox audiobooks.
    *   **Labeling:** A robust self-supervised learning model was employed to generate high-quality pseudo-labels for the massive audio corpus.

2.  **Delayed Fusion Framework:**
    *   **Decoupling:** The heavy computational load of the LLM is separated from the acoustic decoding process to reduce latency.
    *   **Acoustic Pass:** A Conformer Transducer acoustic model generates an N-best list of hypotheses.
    *   **LLM Rescoring:** The hypotheses are rescored using a Large Language Model (OpenLLaMA or LLaMA) to apply semantic context and correct errors.

---

## Contributions

*   **LibriHeavy Corpus:** Introduction of a large-scale, open-source English speech corpus that enables the training of high-capacity models in the public domain.
*   **Delayed Fusion Architecture:** A novel framework for integrating LLMs into ASR that balances accuracy with computational efficiency, making LLM-enhanced ASR more practical.
*   **Comprehensive Evaluation:** Validation of the proposed methodology using three distinct public LLMs (OpenLLaMA 3B, OpenLLaMA 7B, and LLaMA-13B), providing clear performance metrics for the community.

---

## Technical Details

**Core Components**
*   **Acoustic Model:** Conformer Transducer.
*   **Language Models:** OpenLLaMA (3B, 7B parameters), LLaMA-13B.
*   **Decoding Strategy:** N-best list generation followed by LLM rescoring.

**Process Flow**
1.  Audio input is processed by the Conformer Transducer.
2.  An N-best list of transcription hypotheses is generated.
3.  The LLM rescores the hypotheses based on semantic likelihood.
4.  The hypothesis with the optimal combined score is selected.

---

## Experimental Results

The study evaluated the Word Error Rate (WER) on the standard LibriSpeech benchmark sets. The application of Delayed Fusion yielded consistent error reductions across all model sizes.

### Performance Comparison (WER)

| Model Configuration | Test-Clean WER | Test-Other WER |
| :--- | :--- | :--- |
| **Baseline (Conformer Transducer)** | 1.76% | 3.95% |
| **+ OpenLLaMA 3B** | 1.61% | 3.69% |
| **+ OpenLLaMA 7B** | 1.53% | 3.56% |
| **+ LLaMA 13B** | **1.48%** | **3.48%** |

*Note: Results demonstrate consistent improvement in WER as LLM capacity increases.*

---

## Document Metadata

*   **References:** 36 Citations
*   **Analysis Quality Score:** 6/10