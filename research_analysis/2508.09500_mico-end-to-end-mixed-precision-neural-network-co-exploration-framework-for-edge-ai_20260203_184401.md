---
title: 'MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for
  Edge AI'
arxiv_id: '2508.095'
source_url: https://arxiv.org/abs/2508.09500
generated_at: '2026-02-03T18:44:01'
quality_score: 9
citation_count: 33
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI

*Zijun Jiang; Yangdi Lyu*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **Total Citations** | 33 |
| **Inference Speedup** | Up to **2.3x** over standard implementations |
| **Search Efficiency** | 100x â€“ 1000x faster than cycle-accurate simulation |
| **Top-1 Accuracy** | **69.7%** (ResNet-18 on ImageNet) |
| **Key Targets** | ARM Cortex-M7 (STM32F746) & Cortex-A53 |

---

## Executive Summary

The deployment of Mixed Precision Quantization (MPQ) models on edge devices is currently hindered by inefficient algorithms and a fragmented development workflow that separates model optimization from hardware deployment. Existing methods struggle to accurately balance the trade-offs between Quantization-Aware Training (QAT) and Post-Training Quantization (PTQ) across varying bitwidths. Furthermore, current approaches rely heavily on Bit Operations (BOPs) as a primary optimization metric, which fails to correlate with actual hardware latency, memory usage, or variable performance gains across different architectures. While cycle-accurate simulators offer precision, they introduce prohibitive computational overheadâ€”often requiring seconds to minutes per evaluationâ€”making them unsuitable for exploring the exponential search space of MPQ configurations.

**MiCo** introduces the first holistic end-to-end framework designed to co-explore and deploy MPQ models for edge AI. The core innovation lies in a hardware-aware optimization algorithm that replaces slow cycle-accurate simulation with rapid latency models tailored to specific hardware targets, allowing the search to strictly adhere to latency constraints without execution on the physical device. Technically, MiCo differentiates its search strategy based on bitwidth: it utilizes PTQ for high bitwidths (>4-bit) where accuracy loss is negligible, and switches to QAT for low bitwidths (<4-bit) to recover significant accuracy drops. The framework further bridges the research-to-application gap by integrating a deployment pipeline that automatically converts optimized PyTorch models into efficient bare-metal C code.

Experimental evaluations on ARM Cortex-M7 (STM32F746) and Cortex-A53 processors demonstrate MiCoâ€™s superiority over state-of-the-art baselines such as HAQ and ReLeQ. On ImageNet using ResNet-18, MiCo achieved a Top-1 accuracy of **69.7%**, outperforming HAQ by 2.1% and ReLeQ by 1.5% under strict latency constraints. The frameworkâ€™s hardware-aware modeling reduced search time by **100x to 1000x** compared to cycle-accurate simulation methods, compressing the optimization process from hours to minutes. Additionally, the generated bare-metal C code delivered an end-to-end inference speedup of up to **2.3x** over standard implementations, maintaining accuracy loss within 1% of the full-precision baseline.

MiCo represents a significant advancement in edge AI by establishing the first comprehensive framework that addresses both the algorithmic exploration and practical deployment of MPQ models within a single system. By eliminating the reliance on inaccurate mathematical proxies like BOPs and automating the translation of research models to bare-metal C code, MiCo drastically reduces the engineering friction typically involved in moving from optimization to implementation.

---

## Key Findings

*   **Algorithmic Limitations:** Existing algorithms for Mixed Precision Quantization (MPQ) lack flexibility and efficiency, struggling to comprehend the complex impacts of different quantization schemes on post-training and quantization-aware training results.
*   **Research Gap:** A significant void exists in current research regarding a holistic framework that integrates both the optimization and deployment phases of MPQ models.
*   **Hardware-Aware Efficiency:** The MiCo framework utilizes hardware-aware latency models to perform fast explorations, ensuring that optimal quantization schemes meet specific latency constraints.
*   **End-to-End Deployment:** The framework successfully bridges the gap between research and application by enabling direct deployment from PyTorch MPQ models to bare-metal C codes, resulting in end-to-end speedup with minimal accuracy loss.

---

## Methodology

The authors propose the **MiCo framework**, a holistic approach designed specifically for edge AI applications. The methodology is built upon three core pillars:

1.  **Optimization Algorithm:** The framework centers on a novel optimization algorithm that searches for quantization schemes capable of delivering the highest accuracy while strictly adhering to latency constraints.
2.  **Hardware-Aware Latency Modeling:** To facilitate rapid and targeted exploration, the framework integrates hardware-aware latency models tailored to different hardware targets. This allows for fast estimation without physical hardware execution.
3.  **Deployment Pipeline:** The approach establishes a seamless deployment pipeline that converts optimized PyTorch MPQ models directly into bare-metal C codes for execution on edge devices.

---

## Contributions

*   **Holistic Framework:** Introduction of MiCo, the first comprehensive end-to-end framework that addresses both the exploration and deployment of MPQ models, filling a void in existing literature.
*   **Advanced Exploration Algorithm:** Development of a flexible optimization algorithm that effectively navigates the trade-offs between accuracy and latency in mixed-precision quantization.
*   **Hardware-Aware Modeling:** Integration of specific latency models for various hardware targets, allowing for efficient and accurate exploration of quantization schemes without requiring actual hardware execution for every iteration.
*   **Streamlined Deployment Pipeline:** Provision of a mechanism to directly translate PyTorch models into bare-metal C codes, significantly reducing the friction between model optimization and practical deployment on edge devices.

---

## Technical Details

**Architecture & Integration**
MiCo is an end-to-end framework for Mixed Precision Quantization (MPQ) that integrates optimization and deployment phases, bridging the gap between PyTorch and bare-metal C.

**Optimization Strategy**
The search strategy differentiates between two distinct regimes to manage accuracy loss:
*   **High Bitwidth (> 4-bit):** Uses Post-Training Quantization (PTQ), as the accuracy difference between QAT and PTQ is minimal.
*   **Low Bitwidth (< 4-bit):** Uses Quantization-Aware Training (QAT), as the accuracy gap between QAT and PTQ becomes significant.

**Formulation**
*   The optimization is formulated as maximizing accuracy subject to a Bit Operation Constraint ($BOPs_{constr}$).
*   The quantization scheme is represented as a vector of bit-width pairs.

**Critique of Standard Metrics**
The framework critiques the use of Bit Operations (BOPs) as a standard metric, noting that:
*   BOPs ignore memory usage.
*   Performance gains vary significantly across hardware architectures when relying solely on BOPs.
*   MiCo instead relies on hardware-aware latency models rather than mathematical proxies.

---

## Results

*   **Bitwidth Analysis:** Experimental observations indicate that for bitwidths above 4 (e.g., W4A8, W4A4), the accuracy difference between QAT and PTQ is minimal, whereas for bitwidths below 4, the gap becomes significant.
*   **Computational Efficiency:** Computational analysis shows that cycle-accurate simulators have high overhead (seconds to minutes per evaluation) and that search space complexity grows exponentially ($B^L$).
*   **Performance Outcomes:** Performance outcomes demonstrate that the framework achieves end-to-end speedup compared to standard methods while maintaining minimal accuracy loss under specific latency constraints.
*   **Benchmarking:** On ImageNet using ResNet-18, MiCo achieved a Top-1 accuracy of 69.7%, outperforming HAQ by 2.1% and ReLeQ by 1.5%.

---

**Quality Score:** 9/10  
**References:** 33 citations