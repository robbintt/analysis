# Towards Trustworthy Wi-Fi Sensing: Systematic Evaluation of Deep Learning Model Robustness to Adversarial Attacks

*Shreevanth Krishnaa Gopalakrishnan; Stephen Hailes*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 7/10
> *   **References:** 40 Citations
> *   **Key Standard:** IEEE 802.11bf
> *   **Frequency Band:** 2.4 GHz
> *   **Data Modality:** 3D CSI Tensor
> *   **Threat Models:** White-box, Black-box, Universal Perturbations

---

## Executive Summary

**Problem**
This research addresses the critical absence of robust security evaluations within emerging IEEE 802.11bf (Wi-Fi Sensing) standards. As deep learning becomes the standard for interpreting Channel State Information (CSI) in human-centered applications, a significant vulnerability arises: while these models achieve high accuracy on benign data, their resilience against adversarial evasion attacks in physical deployments is largely unquantified. This knowledge gap poses severe risks to user safety and system reliability, as current literature focuses predominantly on theoretical performance rather than the security implications of real-world deployment.

**Innovation**
The authors introduce a systematic evaluation framework designed to benchmark the robustness of CSI-based deep learning models against diverse threat vectors, including white-box, black-box, and universal perturbations. Technically, the study contrasts compact temporal autoencoders with larger deep architectures to isolate the impact of model scale on security. A core innovation is the bridging of theoretical cybersecurity and physical reality; the authors map unconstrained feature-space attacks to physically realizable signal-space perturbations through a rigorous five-stage pipeline. This pipeline spans from PHY layer reception and Channel Frequency Response (CFR) calculation to pre-processing (denoising/normalization) and STFT/Doppler profile transformation, ensuring the analysis reflects the operational constraints of the complex CSI tensor ($H \in \mathbb{C}^{N_r \times N_t \times K}$) sampled at 1-10 kHz.

**Results**
Quantitative evaluation across three public datasets reveals distinct trade-offs between model size and security. Compact temporal autoencoders achieve baseline accuracy statistically comparable to larger deep architectures on clean data; however, these smaller models exhibit significantly higher vulnerability, demonstrating a substantially higher Attack Success Rate (ASR) under adversarial manipulation. The physical constraints of the signal layer play a vital defensive role: physically realizable signal-space perturbations yield a significantly lower ASR than theoretical unconstrained feature-space attacks. Finally, the implementation of adversarial training was validated as an effective defense, successfully improving Mean Robust Accuracy while incurring only a moderate, quantified decrease in clean data performance.

**Impact**
This work establishes a necessary quantitative baseline for CSI robustness, shifting the research focus from pure accuracy to the critical trade-offs between efficiency and security. By exposing the fragility of compact models and validating the efficacy of adversarial training under physical constraints, the authors provide concrete design principles for engineering trustworthy sensing systems. These insights are vital for the future development of IEEE 802.11bf-compliant devices, ensuring that commercial Wi-Fi sensing solutions are hardened against evasion attacks prior to deployment in critical security and healthcare environments.

---

## Key Findings

*   **Model Scale vs. Security:** Smaller models (specifically compact temporal autoencoders) offer performance comparable to larger deep architectures on clean data but are significantly more vulnerable to adversarial attacks.
*   **Physical vs. Theoretical Attacks:** Physically realizable signal-space perturbations significantly reduce attack success rates compared to theoretical unconstrained feature-space attacks.
*   **Defense Effectiveness:** Implementing adversarial training effectively mitigates vulnerabilities, improving mean robust accuracy with only a moderate decrease in clean data performance.

---

## Methodology

The authors developed a systematic evaluation framework to assess the robustness of Channel State Information (CSI) deep learning models. The study employs the following approach:

*   **Model Comparison:** Contrasts compact temporal autoencoder models against larger deep architectures to evaluate the influence of model scale.
*   **Threat Simulation:** Robustness was tested under diverse threat models, including:
    *   White-box attacks
    *   Black-box/Transfer attacks
    *   Universal perturbations
*   **Variable Analysis:** The experiments analyzed how robustness is influenced by model scale, training regime, and physical constraints.
*   **Validation:** The framework was validated across three public datasets.

---

## Technical Details

**System Architecture & Data**
*   **Input Data:** Utilizes a three-dimensional CSI Tensor ($H \in \mathbb{C}^{N_r \times N_t \times K}$) comprising amplitude attenuation and phase shift.
*   **Sampling Rate:** 1-10 kHz.
*   **Standards:** Operates under IEEE 802.11bf standards and 2.4 GHz Wi-Fi bandwidth constraints.

**Processing Pipeline**
A five-stage pipeline architecture is employed:
1.  **PHY Layer:** Wi-Fi packet reception.
2.  **Computation:** Channel Frequency Response (CFR) calculation.
3.  **Pre-processing:** Denoising and normalization.
4.  **Transformation:** STFT/Doppler profiles generation.
5.  **ML Model:** Inference using CNNs/RNNs (Evaluated models include Compact Temporal Autoencoders and larger deep architectures).

**Security Analysis**
*   **Attack Vector:** Focuses on Evasion attacks at the ML Model layer.
*   **Perturbation Types:** Feature-Space vs. Signal-Space perturbations.
*   **Defense Mechanism:** Adversarial Training.

---

## Contributions

*   **Baseline Establishment:** Provides quantitative baselines for estimating the robustness of CSI-based sensing systems, addressing a critical gap in security analysis.
*   **Design Principles:** Offers concrete design principles for creating secure and trustworthy human-centered sensing systems, specifically highlighting trade-offs between efficiency and security.
*   **Physical-Theoretical Bridge:** Bridges the gap between theoretical feature-space attacks and physically realizable signal-space perturbations to better inform real-world deployment.

---

## Results

*   **Clean Data Parity:** Compact temporal autoencoders show performance comparable to larger deep architectures on clean data, with statistically similar baseline accuracy.
*   **Vulnerability Gap:** Smaller models are significantly more vulnerable to adversarial attacks than their larger counterparts.
*   **ASR Reduction:** Physically realizable signal-space perturbations yield a significantly lower Attack Success Rate (ASR) than theoretical feature-space attacks.
*   **Training Efficacy:** Adversarial training effectively improves Mean Robust Accuracy while inducing only a moderate decrease in clean data performance.