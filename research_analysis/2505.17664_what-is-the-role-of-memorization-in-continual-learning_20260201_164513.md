# What is the role of memorization in Continual Learning?

*JÄ™drzej Kozal; Jan Wasilewski; Alif Ashrafee; Bartosz Krawczyk; MichaÅ‚ WoÅºniak*

---

> ### ðŸ“Š Quick Facts
>
 > * **Quality Score:** 9/10
 > * **Total Networks Trained:** >3,500
 > * **Datasets:** CIFAR10, CIFAR100, TinyImageNet
 > * **Architecture:** Reduced ResNet18
 > * **Learning Paradigm:** Class-Incremental Learning (CIL)
 > * **Estimator Variance:** <0.016
 > * **References:** 40 citations

---

## Executive Summary

**Problem**
This paper investigates the fundamental tension between generalization and memorization within the context of Continual Learning (CL), specifically addressing the challenge of catastrophic forgetting. While significant research has been dedicated to architectural mechanisms for preserving knowledge, less attention has been paid to *which* specific data samples should be retained in memory buffers to optimize performance. The authors argue that understanding the role of memorizationâ€”the phenomenon where a model learns to classify specific samples based on direct exposure rather than general featuresâ€”is critical for designing efficient replay strategies. This matters because current rehearsal-based methods often treat data samples uniformly, potentially overlooking the utility of samples that require high memorization versus those that contribute to robust feature learning.

**Innovation**
The key innovation is the introduction and operationalization of a "memorization proxy," derived from the Feldman definition of memorization, which quantifies the change in a model's classification probability for a sample when it is included versus excluded from the training set. To make this computationally feasible for large-scale CL, the authors developed an efficient estimator, $mem_k(i, A)$, using random subsets of training data with a ratio of $k/n=0.5$. The study involved rigorous statistical validation, training over 3,500 Reduced ResNet18 networks across CIFAR10, CIFAR100, and TinyImageNet datasets to ensure variance remained below $0.016$. This proxy was then integrated into Class-Incremental Learning (CIL) buffer policies, allowing the researchers to actively select data for retention based on its memorization characteristics.

**Results**
The experiments revealed a non-linear relationship between memorization and replay efficiency. Samples identified with high memorization scores were found to "forget" at a significantly accelerated rate compared to regular samples. However, the benefit of retaining these samples is heavily dependent on memory constraints: in low-memory regimes, prioritizing high-memorization samples degrades performance, whereas regular samples offer better stability. Conversely, as the replay buffer size increases, the utility of high-memorization samples rises, making their retention beneficial for achieving peak performance. Additionally, the study found a strong positive correlation between the number of classes and memorization levels; as the number of classes increases, models are forced to rely more on memorization to handle specific outliers or complex samples rather than learning generalized features.

**Impact**
This research significantly influences the field of Continual Learning by providing a theoretical and empirical framework for data selection in rehearsal methods. By clarifying the distinction between memorization and forgetting prevention, the authors challenge the notion that "hard" or frequently memorized samples should always be prioritized. Instead, they demonstrate that optimal buffer management must adapt to the memory regime, favoring generalizable samples in resource-constrained environments and incorporating memorized samples only when sufficient buffer space is available. This work paves the way for more intelligent, dynamic replay sampling algorithms that account for the intrinsic memorization difficulty of data points.

---

## Key Findings

*   **Accelerated Forgetting:** Samples identified with high memorization scores are forgotten at a faster rate compared to regular samples.
*   **Memory Regime Dependency:** While memorization is required to achieve peak performance, in low-memory regimes, prioritizing the retention of regular samples yields better results.
*   **Buffer Size Correlation:** The utility of high-memorization samples increases as the replay buffer size grows; retaining such samples is specifically beneficial when the buffer is large.

---

## Methodology

*   **Experimental Evaluation:** Designed extensive experiments to evaluate memorization effects in incremental learning scenarios.
*   **Proxy Development:** Introduced a "memorization proxy" to quantify or estimate the memorization characteristics of data samples.
*   **Buffer Policy Implementation:** Integrated the proxy into the buffer policy problem to guide which data to retain during incremental training.

---

## Core Contributions

*   **Conceptual Distinction:** Clarified the distinct differences between memorization and forgetting prevention in the context of continual learning.
*   **Operational Tooling:** Introduced a practical memorization proxy that can be utilized to measure memorization effects during model training.
*   **Strategy Optimization:** Demonstrated an active application of this proxy within buffer management, proving that selecting high-memorization samples is a viable strategy for improving performance in large memory buffer settings.

---

## Technical Details

*   **Memorization Definition:** Utilizes the Feldman [19] definition, calculated as the difference in classification probability when a sample is included versus excluded from training.
*   **Efficient Estimator:** Employs estimator $mem_k(i, A)$ using random subsets.
*   **Parameters:**
    *   Ratio $k/n = 0.5$
    *   Trains $u=250$ networks per split.
    *   Variance kept below $0.016$.
*   **Experimental Setup:**
    *   **Architecture:** Reduced ResNet18
    *   **Learning Scenario:** Class-Incremental Learning (CIL)
    *   **Datasets:** CIFAR100, CIFAR10, and TinyImageNet
    *   **Scale:** Over 3,500 neural networks trained for statistical validity.

---

## Experimental Results

Results indicate a direct positive correlation between the number of classes and memorization levels, with the number of classes exerting a stronger influence than the size of the dataset. With fixed model capacity, fewer classes enable tailored feature learning (reducing memorization), while more classes necessitate general features, leading to memorization of specific samples like outliers. Samples with high memorization scores are forgotten at a faster rate during incremental training, though this forgetting is mitigated by full data access. These trends were consistent across CIFAR100, TinyImageNet, and varying architectures.