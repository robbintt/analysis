---
title: Effect of Model Merging in Domain-Specific Ad-hoc Retrieval
arxiv_id: '2509.21966'
source_url: https://arxiv.org/abs/2509.21966
generated_at: '2026-02-03T18:28:20'
quality_score: 9
citation_count: 29
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Effect of Model Merging in Domain-Specific Ad-hoc Retrieval

*Taiga Sasaki; Takehiro Yamamoto; Hiroaki Ohshima; Sumio Fujita*

---

### ðŸ“Œ Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **References** | 29 Citations |
| **Architecture** | Bi-encoder (Mistral-7B) |
| **Method** | Linear Interpolation (Model Merging) |
| **Key Domains** | Medical, Japanese |
| **Primary Tool** | MergeKit |

---

## Executive Summary

Adapting large language models (LLMs) for domain-specific Information Retrieval (IR) is critical for achieving high accuracy in specialized fields like medicine or non-English languages. However, standard adaptation methods remain computationally prohibitive. Techniques such as Low-Rank Adaptation (LoRA) fine-tuning demand significant GPU resources and extensive labeled training data, creating barriers for organizations in low-resource environments or those requiring rapid deployment.

This paper addresses the challenge of effectively domain-adapting retrieval models while minimizing computational costs and data requirements. The authors propose a **resource-efficient adaptation strategy based on model merging via linear interpolation**, entirely eliminating the need for gradient-based fine-tuning.

The method merges a general-purpose source retrieval model (e.g., "e5-mistral-7b-instruct") with a domain-specific non-retrieval model (e.g., "BioMistral-7B"). The bi-encoder architectureâ€™s 32 layers are segmented into lower (1-16) and upper (17-32) segments. Independent hyperparameters ($\alpha_{lower}, \alpha_{upper}$) are optimized via grid search to control the interpolation strength for each segment. This allows the merged model to inherit domain knowledge while retaining structural retrieval capabilities, utilizing the source model's tokenizer and implemented via MergeKit.

Experiments across medical and Japanese domains demonstrated that merged models consistently outperformed the original source retrieval models. In full-data settings, these merged models achieved performance comparable to LoRA-fine-tuned baselines. Crucially, **in low-resource settings, the merging approach proved superior**, achieving statistically significant improvements in retrieval effectiveness across all tested metrics. This research establishes model merging as a viable, cost-effective alternative to fine-tuning for domain-specific IR.

---

## Key Findings

*   **Superior Effectiveness:** Model merging produces more effective domain-specific retrieval models compared to the original source retrieval model.
*   **Alternative to Fine-Tuning:** It serves as a practical alternative to LoRA fine-tuning with comparable utility but without the need for extensive training.
*   **Low-Resource Dominance:** The method is particularly effective in low-resource settings, outperforming or matching standard fine-tuning methods.
*   **Cross-Domain Validation:** Positive effects were validated across both medical and Japanese domains.

---

## Methodology

The study utilized a **linear interpolation approach** to merge the weights of a source retrieval model and a domain-specific non-retrieval model without requiring additional fine-tuning.

*   **Experimental Design:** Experiments were conducted in medical and Japanese domains.
*   **Baselines:** The merged model was compared against:
    *   The source retrieval model.
    *   A LoRA fine-tuned model.
*   **Settings:** Performance was evaluated under both full data and limited data (low-resource) settings.
*   **Optimization:** Grid search was used to find optimal interpolation parameters without any gradient updates.

---

## Technical Details

The paper proposes constructing domain-specific retrieval models using weight-level model merging via linear interpolation.

**Architecture & Models**
*   **Base Architecture:** Bi-encoder models based on **Mistral-7B** (32 layers).
*   **Source Retrieval Model:** `e5-mistral-7b-instruct`
*   **Domain-Specific Models:** `BioMistral-7B` (Medical), `japanese-stablelm-base-gamma-7b` (Japanese).

**Merging Strategy**
*   **Layer Segmentation:** The 32 layers are split into:
    *   **Lower Segment:** Layers 1â€“16
    *   **Upper Segment:** Layers 17â€“32
*   **Hyperparameters:** Independent parameters ("alpha_lower", "alpha_upper") are used for linear interpolation of weights in each segment.
*   **Implementation:** Utilizes **MergeKit**; inherits tokenizer weights from the retrieval model.

---

## Results

The study compared the Merged Model against the Source Retrieval Model and LoRA Fine-tuned Models across four datasets.

**Performance Improvements (NDCG@10)**

| Domain | Dataset | Source Model | Merged Model | Improvement |
| :--- | :--- | :--- | :--- | :--- |
| **Medical** | NFCorpus | 0.314 | **0.336** | +0.022 |
| **Medical** | SciFact | 0.667 | **0.686** | +0.019 |
| **Japanese** | MIRACL | 0.405 | **0.449** | +0.044 |
| **Japanese** | JQaRA | 0.509 | **0.540** | +0.031 |

**Key Outcomes**
*   **Full Data:** Merged models achieved performance comparable to LoRA-fine-tuned baselines.
*   **Low Resource:** The merged model outperformed standard fine-tuning methods on limited data (e.g., NFCorpus), demonstrating statistically significant improvements.

---

## Contributions

*   **Resource Efficiency:** Introduced a method for adapting retrieval models to specific domains without computationally expensive fine-tuning.
*   **Empirical Evidence:** Demonstrated the utility of model merging in Information Retrieval (IR), showing that combining a general retrieval model with a domain-specific non-retrieval model enhances performance.
*   **Scalability:** Provided a viable solution for domain-specific retrieval in data-scarce environments.

---

**Quality Score:** 9/10
**References:** 29 citations