---
title: Safe Deployment of Offline Reinforcement Learning via Input Convex Action Correction
arxiv_id: '2507.2264'
source_url: https://arxiv.org/abs/2507.22640
generated_at: '2026-02-03T12:48:00'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Safe Deployment of Offline Reinforcement Learning via Input Convex Action Correction

*Alex Durkin; Jasper Stolte; Matthew Jones; Raghuraman Pitchumani; Bei Li; Christian Michler; Mehmet Mercang√∂z*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Focus** | Offline Reinforcement Learning Safety |
| **Core Application** | Chemical Process Control (Exothermic Polymerization CSTR) |
| **Key Innovation** | Input Convex Action Correction (ICAC) |
| **Safety Layer** | Partially Input Convex Neural Networks (PICNNs) |
| **Validation Scenarios** | Reactor Startup, Grade Change Up/Down |
| **Online Exploration** | Zero |
| **Quality Score** | 8/10 |
| **Citations** | 40 |

---

## üìù Executive Summary

Offline Reinforcement Learning (RL) offers a compelling pathway to automating complex industrial systems, such as chemical process control, by deriving optimal policies from historical data without the hazards of online exploration. However, standard offline RL algorithms, including Behavior Cloning and Implicit Q-learning, face significant reliability hurdles when applied to high-stakes environments like exothermic polymerization Continuous Stirred-Tank Reactors (CSTRs). In these settings, conventional methods frequently exhibit steady-state offsets and degraded performance near operational setpoints. These limitations are critical barriers to deployment, as industrial applications demand unwavering stability and safety where even minor control deviations can lead to substantial operational risks.

To bridge the gap between offline training and safe online execution, the authors introduce Input Convex Action Correction (ICAC), a novel deployment-time safety layer. Technically, the method utilizes Partially Input Convex Neural Networks (PICNNs) to learn state-conditioned cost surfaces. During deployment, a pre-trained offline policy proposes an action which is evaluated by the PICNN; if the action is deemed unsafe, the layer performs a real-time, differentiable correction via gradient descent. This non-intrusive approach leverages the convexity properties of PICNNs to enforce safety constraints without requiring model retraining or interaction with the live environment.

The study evaluated the approach using a Gymnasium-compatible simulation of an exothermic polymerization CSTR, benchmarking against datasets generated from suboptimally tuned Proportional-Integral (PI) controllers featuring randomized tunings to ensure robustness. Quantitative results demonstrated that while standard offline RL algorithms failed due to significant steady-state offsets and elevated Integral Absolute Error (IAE), the integration of the ICAC safety layer effectively mitigated these issues. The proposed system outperformed traditional PI controllers across three complex, industrially relevant scenarios‚ÄîReactor Startup, Grade Change Down, and Grade Change Up‚Äîachieving robust stability and high-performance control with zero online exploration.

This research establishes a practical framework for the reliable application of data-driven automation in safety-critical industrial systems. By demonstrating that convex action correction can resolve the performance instabilities typical of offline RL, the authors provide a viable path to replacing heuristic controllers with high-performance RL policies in sectors where failure is unacceptable. The introduction of a specialized simulation environment and a reproducible dataset further supports the field by providing a standardized benchmark for future research into safe industrial control.

---

## üîë Key Findings

*   **Standard RL Limitations:** Standard offline Reinforcement Learning (RL) algorithms, specifically Behavior Cloning and Implicit Q-learning, struggle in chemical process control tasks, exhibiting steady-state offsets and degraded performance near setpoints.
*   **Performance Enhancement:** Integrating offline RL with the proposed convex action correction mechanism enables the system to outperform traditional control approaches while maintaining stability.
*   **Complex Scenario Handling:** The methodology successfully handles industrially relevant and complex operational scenarios, including reactor startup, grade change down, and grade change up.
*   **Safety Assurance:** The safety layer facilitates real-time, differentiable correction of actions using learned cost models, ensuring safety without requiring model retraining or interaction with the live environment.

---

## ‚öôÔ∏è Technical Details

The proposed approach centers around a deployment-time safety layer designed to bridge the gap between offline training and safe online execution.

*   **Core Mechanism:** Input Convex Action Correction (ICAC).
*   **Architecture:** Built on Partially Input Convex Neural Networks (**PICNNs**) which function as state-conditioned cost surfaces.
*   **Workflow:**
    1.  A pre-trained offline RL policy proposes an action.
    2.  The PICNN evaluates the proposed action against the current state.
    3.  If the action is deemed unsafe (high cost), the system corrects it via gradient descent.
*   **Key Properties:**
    *   **Differentiable:** Allows for gradient-based optimization.
    *   **Non-intrusive:** Can be wrapped around existing policies.
    *   **Constraint-free:** Does not require hard-coded constraints during training.
*   **Simulation Environment:** Continuous Stirred-Tank Reactor (CSTR) for exothermic polymerization.
*   **Data Source:** Offline datasets generated by suboptimally tuned PI controllers.

---

## üß™ Methodology

The study adopted a rigorous simulation and benchmarking strategy to validate the Input Convex Action Correction (ICAC) framework:

1.  **Environment Development:** A specialized, Gymnasium-compatible simulation of an exothermic polymerization Continuous Stirred-Tank Reactor (CSTR) was developed. This simulation accurately models nonlinear dynamics, reaction kinetics, energy balances, and operational constraints.
2.  **Dataset Generation:** Reproducible offline datasets were generated using Proportional-Integral (PI) controllers. To ensure robustness and realistic benchmarking, the PI controllers utilized randomized tunings.
3.  **Benchmarking:** Baseline algorithms, specifically Behavior Cloning and Implicit Q-learning, were evaluated against the proposed method to establish performance gaps.
4.  **Safety Implementation:** The novel deployment-time safety layer was implemented using Input Convex Neural Networks (PICNNs). These networks serve as learned cost models to perform gradient-based action correction in real-time.

---

## üìà Results

The evaluation of the ICAC framework yielded significant improvements over both standard RL algorithms and traditional control methods:

*   **Standard RL Failure:** Baseline algorithms like Behavior Cloning and Implicit Q-learning failed to maintain adequate control, primarily due to steady-state offsets and degraded performance near setpoints.
*   **Superior Stability:** The proposed method not only outperformed traditional PI controllers but did so while strictly maintaining stability.
*   **Scenario Validation:** The system was successfully validated across three complex operational scenarios:
    *   Reactor Startup
    *   Grade Change Down
    *   Grade Change Up
*   **Operational Safety:** The system ensured safety with **zero online exploration** and demonstrated the capability for real-time action correction.

---

## üöÄ Contributions

*   **Simulation Environment & Data:** Introduced a specialized, Gymnasium-compatible simulation environment and accompanying offline datasets for the exothermic polymerization CSTR, providing a new standard for testing.
*   **Safety Layer Innovation:** Developed a novel deployment-time safety layer that utilizes the convexity properties of PICNNs to correct policy actions in real-time, bridging the gap between offline training and safe online execution.
*   **Industrial Feasibility:** Demonstrated the practical feasibility of applying offline RL to critical industrial systems, proving that data-driven automation can be made reliable and safe through interpretable, convex corrections.

---

**References:** 40 Citations