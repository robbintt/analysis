---
title: Collaborative Agentic AI Needs Interoperability Across Ecosystems
arxiv_id: '2505.2155'
source_url: https://arxiv.org/abs/2505.21550
generated_at: '2026-02-03T13:24:40'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Collaborative Agentic AI Needs Interoperability Across Ecosystems

*Rishi Sharma; Martijn de Vos; Pradyumna Chari; Ramesh Raskar; Anne-Marie Kermarrec*

---

> ### üìã Quick Facts
> | Metric | Detail |
> | :--- | :--- |
> | **Document Type** | Position Paper |
> | **Core Focus** | Agentic AI Interoperability |
> | **Proposed Solution** | "Web of Agents" Framework |
> | **Key Components** | Messaging, Interaction, State, Discovery |
> | **Citations** | 40 |
> | **Quality Score** | 9/10 |

---

## Executive Summary

This research addresses the critical issue of **ecosystem fragmentation** currently hindering the advancement of collaborative agentic AI. As major technology firms introduce isolated protocols‚Äîsuch as Google‚Äôs A2A, Anthropic‚Äôs MCP, and IBM‚Äôs ACP‚ÄîAI agents are being developed in silos, unable to communicate or collaborate across different platforms. The authors warn that this trajectory is leading toward a fragmented digital landscape where vendor lock-in is the norm. This isolation matters deeply because it prevents the realization of web-scale collaboration and introduces significant security risks; specifically, the reliance on brittle translation layers to bridge these incompatible protocols expands the attack surface for potential exploits, similar to vulnerabilities observed in cross-blockchain bridges.

The paper introduces the **‚ÄúWeb of Agents,‚Äù** a decentralized architectural framework designed to establish minimal standards for interoperability across diverse agentic ecosystems. Technically, the solution is built upon four foundational pillars: agent-to-agent messaging, interaction interoperability, state management, and agent discovery. The innovation lies in the framework's pragmatic approach to standardization; rather than inventing entirely new protocols, it proposes leveraging existing web infrastructure and standards to support autonomous entities. This architecture distinguishes agentic workflows‚Äîwhich involve LLMs and tools for parallel, autonomous task execution‚Äîfrom simple request-response generative AI, providing the necessary structural foundation for agents to discover one another and manage state interactions securely without relying on custom, non-interoperable implementations.

As this is a position paper, the study does not present quantitative experimental results or performance metrics; instead, its primary outcome is the successful definition of a comprehensive architectural blueprint that resolves the identified gaps in current protocols. The authors demonstrate that the proposed four-component architecture can theoretically eliminate the operational inefficiencies associated with managing multiple, conflicting agent protocols. By mapping out the specific requirements for identity, communication, and discovery, the framework validates that a minimal set of standards is sufficient to support complex agentic workflows. This architectural analysis effectively highlights how removing the dependency on translation layers can reduce systemic security risks and operational overhead, providing a viable pathway for companies to avoid single-protocol commitments.

The significance of this work lies in its **urgent call to action** for the industry to prioritize standardization before fragmentation becomes an entrenched standard. The "Web of Agents" framework provides a strategic roadmap that could fundamentally influence the trajectory of agentic AI development, shifting the focus from proprietary walled gardens to an open, secure, and interoperable web. By advocating for the reuse of existing infrastructure, the authors offer a pragmatic path forward that lowers the barrier to adoption for developers and enterprises alike. Ultimately, this research underscores that interoperability is not merely a technical feature but a prerequisite for the future security, scalability, and widespread acceptance of collaborative AI systems.

---

## Key Findings

*   **Ecosystem Fragmentation Risk:** Current collaborative agentic AI solutions are developed in isolation, creating a trajectory toward fragmented and incompatible digital ecosystems.
*   **Interoperability as a Prerequisite:** The adoption of minimal standards and interoperability is identified as essential for enabling agentic AI to be open, secure, web-scale, and widely adopted.
*   **Proposed Architecture ("Web of Agents"):** A minimal architectural foundation has been devised to support interoperability, consisting of four specific components: agent-to-agent messaging, interaction interoperability, state management, and agent discovery.
*   **Pragmatic Standardization:** The proposed solution emphasizes a pragmatic approach by adopting existing standards and reusing current infrastructure rather than building entirely new protocols from scratch.
*   **Urgency for Action:** Immediate steps toward standardization are critical to establish interoperable systems before ecosystem fragmentation becomes the entrenched industry norm.

---

## Methodology

The authors utilize a **position paper methodology** to address systemic architectural challenges in the field of agentic AI. Rather than presenting experimental results, they:

1.  Identify a critical gap in current technological implementations (isolation vs. collaboration).
2.  Conceptualize a minimal architectural foundation ("Web of Agents") designed to bridge this gap.
3.  Adopt a strategy of leveraging existing standards and infrastructure to ensure practical feasibility and immediate applicability.

---

## Technical Architecture: The "Web of Agents"

The paper proposes a decentralized, interoperable architecture designed to prevent ecosystem fragmentation. The framework distinguishes **Agentic AI workflows** (autonomous entities using LLMs/tools for parallel invocation) from strict request-response Generative AI.

### Core Components
1.  **Agent-to-Agent Messaging:** The foundational layer for communication between autonomous entities.
2.  **Interaction Interoperability:** Standardizing how agents interact and understand each other's capabilities.
3.  **State Management:** Mechanisms for tracking the state of interactions and workflows across distributed agents.
4.  **Agent Discovery:** Protocols allowing agents to find and identify one another within the ecosystem.

### Current Landscape vs. Proposed Solution
*   **Current State:** Fragmented, with protocols like Google's A2A, Anthropic's MCP, and IBM's ACP creating silos.
*   **Gaps:** Lack of standard mechanisms for agent identity, communication, and discovery.
*   **Strategy:** Reuse existing web infrastructure; avoid brittle translation layers that expand attack surfaces (similar to cross-blockchain bridges).

---

## Contributions

*   **The "Web of Agents" Framework:** Definition of a comprehensive, minimal architectural foundation specifically designed to enable interoperability across diverse agentic AI ecosystems.
*   **Core Component Specification:** Identification and definition of the four requisite pillars for interoperable agents: agent-to-agent messaging, interaction interoperability, state management, and agent discovery.
*   **Strategic Roadmap:** Provision of a pragmatic path forward for the industry, advocating for the reuse of existing infrastructure to prevent the "lock-in" effects of fragmented ecosystems.
*   **Standardization Advocacy:** Establishment of the argument that minimal standards are a fundamental requirement for the future security and scalability of collaborative agentic AI.

---

## Results & Implications

**Qualitative Assessment:** The provided text is qualitative and does not present quantitative experimental results or performance metrics.

*   **Operational Inefficiencies:** Highlights significant inefficiencies for companies forced to commit to single protocols (e.g., A2A vs. MCP).
*   **Security Risks:** Identifies security risks associated with translation layers, noting they expand attack surfaces similar to cross-blockchain bridges.
*   **Theoretical Validation:** Demonstrates that a minimal set of standards is sufficient to support complex agentic workflows without relying on custom, non-interoperable implementations.

---

**Quality Score:** 9/10
**References:** 40 citations