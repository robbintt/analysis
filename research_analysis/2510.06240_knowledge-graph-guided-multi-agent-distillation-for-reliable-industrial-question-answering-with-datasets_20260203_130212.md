---
title: Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question
  Answering with Datasets
arxiv_id: '2510.0624'
source_url: https://arxiv.org/abs/2510.06240
generated_at: '2026-02-03T13:02:12'
quality_score: 8
citation_count: 0
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question Answering with Datasets

*Jiqun Pan; Zhenke Duan; Jiani Tu; Anzhi Cheng; Yanqing Wang*

---

> ### üìä Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Performance Gain:** +2.4% to +20.1% accuracy improvement
> *   **Method:** KG-MASD (Markov Decision Process formulation)
> *   **Target Environment:** Safety-critical industrial edge deployment
> *   **Key Innovation:** Knowledge Graph-guided verifiable reasoning

---

## üìù Executive Summary

Industrial fault diagnosis and question answering demand high precision and trustworthiness. Current state-of-the-art multi-agent Large Language Models (LLMs), while capable of sophisticated collaborative reasoning, face significant deployment barriers due to uncontrolled iterations and unverifiable outputs. These issues, combined with substantial computational overhead, make them unsuitable for edge deployment in safety-critical environments.

This paper introduces **Knowledge Graph-guided Multi-Agent System Distillation (KG-MASD)**, a novel framework that formulates the distillation process as a Markov Decision Process (MDP). The core innovation lies in integrating a knowledge graph as a verifiable structured prior, which enriches state representations and ensures reasoning convergence. By grounding collaborative reasoning in structured knowledge, KG-MASD generates high-confidence instruction-tuning data used to jointly distill reasoning depth and verifiability into lightweight student models.

Evaluations on an industrial QA dataset demonstrate substantial performance gains, with accuracy improvements ranging from **2.4% to 20.1%** compared to baseline models. This research successfully bridges the gap between complex multi-agent reasoning and practical, deployable AI, enabling trustworthy deployment on resource-constrained hardware without sacrificing safety or accuracy.

---

## üîç Key Findings

*   **Significant Accuracy Boost:** The proposed KG-MASD method improves accuracy by between **2.4% and 20.1%** compared to baseline models on an industrial QA dataset.
*   **Mitigation of Agent Limitations:** The approach successfully addresses specific multi-agent LLM flaws, specifically mitigating issues of uncontrolled iterations and unverifiable outputs.
*   **Effective Capability Transfer:** KG-MASD effectively transfers collaborative reasoning capabilities from complex multi-agent teacher models into compact student models suitable for edge deployment.
*   **Enhanced System Reliability:** The method significantly enhances system reliability, facilitating trustworthy AI deployment in safety-critical industrial environments.

---

## üß† Methodology

The authors propose **Knowledge Graph-guided Multi-Agent System Distillation (KG-MASD)**. The methodology centers on formulating the distillation process as a **Markov Decision Process (MDP)**.

*   **Integration of Knowledge Graphs:** A knowledge graph is utilized as a verifiable structured prior. This integration is critical for enriching state representations and ensuring the convergence of the reasoning process.
*   **Collaborative Reasoning + Knowledge Grounding:** By combining the collaborative nature of multi-agent systems with knowledge grounding, the system generates high-confidence instruction-tuning data.
*   **Joint Distillation:** This data is used to jointly distill both reasoning depth and verifiability into lightweight student models, ensuring they inherit the robustness of the larger system.

---

## ‚öôÔ∏è Technical Details

**Framework Architecture**
*   **Name:** KG-MASD (Knowledge Graph-Guided Multi-Agent Distillation)
*   **Teacher Model:** Complex Multi-Agent LLM
*   **Student Model:** Compact model optimized for edge deployment
*   **Optimization Goal:** Transfer reasoning capabilities while minimizing computational footprint

**Core Components**
1.  **MDP Formulation:** The distillation process is modeled as a Markov Decision Process to manage state transitions and decision-making.
2.  **Structured Knowledge Priors:** Knowledge graphs guide the process to address uncontrolled iterations.
3.  **Verifiability Mechanisms:** Specific focus on verifying outputs to counter hallucination risks inherent in standard LLMs.
4.  **Instruction-Tuning Data Generation:** Automatically generates high-quality data for training the student model.

---

## üöÄ Core Contributions

1.  **Bridging the Distillation Gap**
    Overcomes the limitations of conventional distillation methods that struggle to transfer collaborative reasoning capabilities from multi-agent systems to deployable student models.

2.  **Enhancing Verifiability**
    Introduces a mechanism to control uncontrolled iterations and verify outputs by incorporating structured knowledge priors. This is a critical advancement for high-risk industrial applications where trust is paramount.

3.  **Enabling Edge Deployment**
    Provides a framework for compressing the complex reasoning of multi-agent LLMs into compact models. This allows for edge deployment without sacrificing the depth of reasoning or the safety standards required for industrial fault diagnosis.

---

## üìà Performance Results

The evaluation of KG-MASD on an industrial QA dataset yielded the following outcomes:

*   **Accuracy Improvement:** Achieved a range of **2.4% to 20.1%** improvement over baseline models.
*   **Reliability Enhancement:** Results indicate significant enhancements in system reliability.
*   **Edge Suitability:** Confirmed suitability for edge deployment scenarios.
*   **Safety Compliance:** Validated safety standards for critical industrial environments.

---
**References:** 0 citations