---
title: Grammar Search for Multi-Agent Systems
arxiv_id: '2512.14079'
source_url: https://arxiv.org/abs/2512.14079
generated_at: '2026-02-03T13:23:07'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Grammar Search for Multi-Agent Systems

*Mayank Singh; Vikas Yadav; Shiva Krishna Reddy Malay; Shravan Nayak; Sai Rajeswar; Sathwik Tejaswi Madhusudhan; Eduardo Blanco*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Domains** | Mathematics, Question Answering |
| **Benchmarks** | MATH, AIME, MMLU-Pro, GPQA, ScienceQA |
| **Core Innovation** | Grammar Search (CFG) |
| **Syntactic Validity** | 100% (vs. failure in prior methods) |
| **References** | 40 citations |

---

## Executive Summary

Automating the design of effective Multi-Agent Systems (MASes) has traditionally been a manual, expensive, and inefficient engineering process. While recent attempts have utilized Large Language Models (LLMs) to automate this via free-form code generation, these approaches are fundamentally flawed. They suffer from high computational costs, function as uninterpretable "black boxes," and frequently produce syntactically invalid candidates that cannot be executed. This paper addresses these limitations by establishing a rigorous pathway for automated agent design that prioritizes reliability and cost-efficiency over unstructured generative flexibility.

The core innovation is **"Grammar Search,"** a structured framework that replaces unstructured LLM generation with a search space defined by a Context-Free Grammar (CFG). Technically, the authors decompose MAS architectures into reusable, composable components derived from base systems like Chain-of-Thought and Self-Refine. The grammar utilizes non-terminals based on input/output constraints (SISO, SIMO, MISO, MIMO) and terminals comprising reasoners, iterative processes, and aggregation methods. To navigate this space efficiently, the authors employ a **"Forced Sampling"** strategy. This approach tracks component sampling frequencies and prioritizes low-frequency components, ensuring fair exploration of the search space and guaranteeing that all generated candidates are syntactically correct without the need for expensive trial-and-error.

The proposed method was rigorously evaluated across mathematics and question answering domains using five standard benchmarks: MATH, AIME, MMLU-Pro, GPQA, and ScienceQA. Grammar Search outperformed prior LLM-based free-form search baselines on **4 out of the 5 benchmarks**, demonstrating superior performance despite its reduced generative flexibility. A critical quantitative improvement was the elimination of invalid candidates; whereas prior methods like ADAS suffered from high failure rates due to syntactic errors, Grammar Search achieved a **100% syntactic validity rate**. This structural correctness directly translated to cost savings, as the structured approach significantly reduced the computational overhead required to discover high-performing agents by avoiding the wasted resources associated with evaluating broken code.

This work significantly influences the field of automated agent design by demonstrating that structured exploration can empirically surpass the performance of flexible, generative LLM approaches. The authors reveal that high-performing systems do not require convoluted, unstructured code; rather, the most effective agents utilize simpler logic and modular components. The shift toward grammar-based search offers a pragmatic, interpretable alternative to black-box generation, enhancing both the operational efficiency and the modularity of resulting architectures.

---

## Key Findings

*   **Superior Performance:** The proposed structured method outperforms prior LLM-based free-form search approaches on **4 out of 5** benchmarks.
*   **Cross-Domain Validation:** Performance was validated across two distinct domains: mathematics and question answering.
*   **Cost Efficiency:** The framework achieves a more cost-efficient search process compared to generative LLM approaches.
*   **Efficiency over Flexibility:** Despite lacking the generative flexibility of LLMs during candidate generation, the method produces superior results.
*   **Interpretability:** The generated multi-agent systems are modular, interpretable, and utilize simpler logic than previous solutions.

---

## Methodology

The authors propose a structured framework for the automatic search of Multi-Agent Systems. Instead of relying on LLM-based free-form search over the code spaceâ€”which often leads to invalid code and high costsâ€”the method utilizes a **fixed set of simple, composable components** to explore the solution space. This approach shifts the paradigm from unstructured generation to a disciplined, grammatical search.

---

## Technical Details

The approach relies on a rigorous grammatical structure to define valid system architectures.

*   **Context-Free Grammar (CFG):** Used to define the search space of Multi-Agent Systems (MASes).
*   **Decomposition:** Systems are broken down into reusable components derived from base MASes such as:
    *   Chain-of-Thought (CoT)
    *   CoT-Self-Consistency (CoT-SC)
    *   Self-Refine
    *   Multi-Agent Debate
*   **Grammar Structure:**
    *   **Non-terminals:** Defined by input/output constraints (SISO, SIMO, MISO, MIMO).
    *   **Terminals:** Comprise reasoners, iterative processes, and aggregation methods.
*   **Search Algorithm (Forced Sampling):**
    *   Maintains component sampling counts.
    *   Clusters components by frequency.
    *   Prioritizes the sampling of **low-frequency components** to ensure fair representation and comprehensive exploration.

---

## Contributions

*   **Introduction of Grammar Search:** A shift from unstructured, generative search to a structured framework defined by simple, composable components.
*   **Performance Benchmarking:** Evidence that structured exploration can surpass the performance of flexible LLM-based generation in agentic AI tasks.
*   **Operational Improvements:** Advancement in the efficiency and interpretability of agent design, offering a cost-effective alternative to black-box LLM generation.

---

## Results

The method was evaluated on Mathematics and QA domains using datasets including **MATH, AIME, MMLU-Pro, and GPQA**.

*   **Benchmark Success:** Outperformed prior LLM-based free-form search approaches on 4 out of 5 benchmarks.
*   **Validity:** Guarantees syntactic correctness, resolving the issue of invalid candidates found in prior methods like ADAS (100% validity rate achieved).
*   **System Quality:** The resulting MASes are modular, interpretable, and utilize simpler logic.
*   **Cost:** Achieved a more cost-efficient search process by reducing wasted computation on broken code.