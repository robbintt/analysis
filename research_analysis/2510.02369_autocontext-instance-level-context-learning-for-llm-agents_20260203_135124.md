---
title: 'AutoContext: Instance-Level Context Learning for LLM Agents'
arxiv_id: '2510.02369'
source_url: https://arxiv.org/abs/2510.02369
generated_at: '2026-02-03T13:51:24'
quality_score: 9
citation_count: 32
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# AutoContext: Instance-Level Context Learning for LLM Agents

*Kuntai Cai; Juncheng Liu; Xianglin Yang; Zhaojie Niu; Xiaokui Xiao; Xing Chen*

***

> ### **Quick Facts**
> *   **Quality Score:** 9/10
> *   **References:** 32 citations
> *   **Benchmarks:** TextWorld, ALFWorld, Crafter, InterCode-Bash
> *   **Key Metric:** ReAct Agent Success Rate on TextWorld increased from **37%** to **95%** (a 157% relative improvement).
> *   **Core Innovation:** Decoupling environment exploration from task execution via a reusable Knowledge Graph.

***

### **Executive Summary**

Current Large Language Model (LLM) agents suffer from a critical lack of "instance-level context"—specific, concrete knowledge regarding environment structure and system configurations. Because existing architectures intertwine exploration with task execution, agents are forced to redundantly rediscover environmental facts for every new task. This inefficiency leads to excessive interaction steps and fragile decision-making processes, as the agent must simultaneously familiarize itself with the environment and attempt to solve the problem, often failing to generalize learned facts across different tasks within the same instance.

The paper introduces **AutoContext**, a novel framework that formally defines Instance-Level Context Learning (ILCL) as a POMDP to decouple environment exploration from task execution. Instead of dynamic exploration during runtime, AutoContext employs a one-off "Plan–Act–Extract Loop" to systematically map an environment. This process utilizes a "TODO Forest" data structure to manage exploration history and employs three distinct sub-agents: a Planner (proposing paths and resolving dependencies), an Actor (executing actions), and an Extractor (populating a Knowledge Graph with atomic triplet facts). Once this structured representation is built, off-the-shelf agents can directly query the Knowledge Graph to retrieve necessary context, bypassing the need for real-time environmental discovery.

AutoContext was evaluated across four benchmarks—TextWorld, ALFWorld, Crafter, and InterCode-Bash—using Success Rate and Interaction Steps as primary metrics. The method demonstrated substantial performance gains, most notably in TextWorld, where a ReAct agent’s success rate surged from 37% (baseline) to 95% when utilizing AutoContext. This represents a 58 percentage point improvement, or approximately a 157% relative increase in reliability. Additionally, the approach significantly reduced the number of interaction steps required, validating the efficiency of separating the learning phase from the execution phase.

This research highlights the importance of structured, reusable context in agentic systems, shifting the paradigm from reactive exploration to proactive knowledge acquisition. By demonstrating that instance-level context is a critical factor for enhancing both efficiency and reliability, AutoContext offers a blueprint for building more robust LLM agents. This work suggests that future agentic architectures should modularize environment familiarization, thereby reducing computational redundancy and enabling agents to operate with greater stability in complex, real-world environments.

***

## Key Findings

*   **Contextual Deficit:** Existing LLM agents lack "instance-level context" (specific facts like environment structure and system configurations), forcing them to repeatedly rediscover information for every new task.
*   **Inefficiency in Current Methods:** The necessity of intertwining exploration with task execution in current methods leads to redundant interactions and fragile decision-making.
*   **Benchmark Success:** The proposed method achieved substantial improvements across multiple benchmarks, including TextWorld, ALFWorld, Crafter, and InterCode-Bash.
*   **Performance Leap:** In a specific case study, the success rate of a ReAct agent on TextWorld jumped from **37% to 95%** when utilizing the proposed method.

## Methodology

AutoContext fundamentally separates the **exploration phase** from the **task-solving phase** to eliminate redundancy. The method operates as follows:

1.  **Systematic Exploration:** It performs a systematic, one-off exploration of an environment instance.
2.  **Knowledge Graph Construction:** The exploration phase builds a reusable knowledge graph containing concrete facts.
3.  **Direct Retrieval:** During task execution, off-the-shelf agents access the pre-constructed knowledge graph to retrieve necessary concrete facts directly, rather than engaging in dynamic exploration.

## Technical Details

The paper formalizes the approach as **Instance-Level Context Learning (ILCL)** and utilizes a specific architecture to achieve its goals.

*   **Formalization:**
    *   ILCL is formalized as a **Partially Observable Markov Decision Process (POMDP)** designed to learn specific, local facts about an environment instance independent of downstream tasks.

*   **Architecture (AutoContext):**
    *   Utilizes a **Plan–Act–Extract Loop** driven by a **TODO Forest** data structure.
    *   The **TODO Forest** represents exploration history as trees, operating in two modes:
        *   **Action Mode:** For granular environments.
        *   **Agent Mode:** For complex, long-horizon tasks.

*   **The Three Sub-Agents:**
    *   **Planner:** Proposes paths via action correction, dependency resolution, and pattern exploitation.
    *   **Actor:** Executes tasks and manages state restoration.
    *   **Extractor:** Updates the Knowledge Graph with atomic triplet facts based on a free-form schema.

*   **Output:** A structured, reusable **Knowledge Graph** that agents can query during execution.

## Results

The evaluation of AutoContext focused on efficiency and reliability across standard benchmarks.

**Evaluation Setup:**
*   **Benchmarks:** TextWorld, ALFWorld, Crafter, InterCode-Bash.
*   **Metrics:** Success Rate and Interaction Steps.

**Quantitative Outcomes:**
*   **TextWorld (ReAct Agent):**
    *   Baseline Success Rate: 37%
    *   AutoContext Success Rate: 95%
    *   **Improvement:** 58 percentage points (approx. 157% relative improvement).

**Qualitative Outcomes:**
*   **Decoupling:** The method replaces repeated agent-specific exploration with reusable instance context.
*   **Efficiency:** Successfully decouples environment familiarization from task execution, reducing redundancy and fragility.

## Contributions

*   **Framework Introduction:** Introduction of **AutoContext**, a novel framework designed to provide LLM agents with instance-level context, addressing a critical gap in current agent capabilities.
*   **Redundancy Elimination:** A mechanism that eliminates redundant exploration by creating a structured, reusable representation of environment facts (knowledge graphs).
*   **Empirical Validation:** Empirical evidence demonstrating that providing structured instance context is a critical factor for enhancing the efficiency and reliability of agentic systems.