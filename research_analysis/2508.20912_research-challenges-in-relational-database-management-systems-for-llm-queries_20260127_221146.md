---
title: Research Challenges in Relational Database Management Systems for LLM Queries
arxiv_id: '2508.20912'
source_url: https://arxiv.org/abs/2508.20912
generated_at: '2026-01-27T22:11:46'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Research Challenges in Relational Database Management Systems for LLM Queries

*Anurag Chakraborty, Sairaj Voruganti, Kerem Akillioglu*

---

#### üìä Quick Facts Sidebar
| **Metric** | **Detail** |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 40 Citations |
| **Test Hardware** | NVIDIA A100 80GB GPU |
| **Dataset** | Rotten Tomatoes (17,712 rows) |
| **Models Evaluated** | Meta LLaMA 3.1 (8B), OpenAI GPT-4o-mini |
| **Critical Bottleneck** | Loose coupling architecture vs. Tight integration |

---

### üìù Executive Summary

> This research addresses the critical inefficiencies and architectural limitations preventing the effective adoption of Large Language Models (LLMs) within Relational Database Management Systems (RDBMS). As organizations increasingly seek to execute "LLM queries"‚Äîqueries where database operations are augmented by LLM inference for tasks like text generation or semantic filtering‚Äîcurrent open-source solutions suffer from severe performance bottlenecks and functional fragility compared to enterprise offerings.
>
> The paper highlights that the prevailing "loose coupling" architecture, where the database simply calls an external model via API, fails to enforce structured outputs, manage resource utilization effectively, or optimize query planning. This matters because without resolving these core issues, scalable and reliable in-database AI workflows remain inaccessible to the broader developer community relying on open-source technology.
>
> The study's primary innovation lies in the formalization of "LLM queries" into five distinct patterns‚Äî**LLM Projection, LLM Filter, Multi-LLM Invocation, LLM Aggregation, and RAG**. Testing on an NVIDIA A100 80GB GPU revealed that open-source solutions are currently an **order of magnitude slower** than enterprise alternatives.
>
> The findings establish a mandate for a paradigm shift in how LLMs are integrated into database engines, arguing that surface-level optimizations are insufficient for scalable processing. By demonstrating that open-source systems currently struggle with basic reliability and performance, the paper sets the research agenda for "**tighter integration**" between LLMs and DBMS kernels.

---

### üîë Key Findings

*   **Performance Gap:** Current open-source solutions for LLM-invoked SQL integrations suffer from limited functionality and poor performance compared to enterprise offerings.
*   **Critical Bottlenecks:** Three specific hindrances were identified:
    1.  Enforcing structured outputs.
    2.  Optimizing resource utilization.
    3.  Improving query planning.
*   **Validation of Fixes:** Initial solutions implemented to address these bottlenecks resulted in measurable improvements in processing LLM-powered SQL queries.
*   **Architectural Need:** Scalable and efficient processing requires **tighter integration** between Large Language Models and Database Management Systems rather than loose coupling.

---

### üß™ Methodology

The researchers utilized a comparative evaluation framework involving **two open-source systems** and **one enterprise platform**. The evaluation process involved:

1.  **Stress-Testing:** Utilizing five representative queries to test functionality, performance, and scalability.
2.  **Analysis:** conducting a deep dive into system architecture to identify failure points.
3.  **Optimization:** Implementing and testing initial optimization solutions to validate findings regarding system architecture and performance bottlenecks.

---

### ‚öôÔ∏è Technical Details

**System Configuration**
*   **Models:**
    *   Meta LLaMA 3.1 (8B) (Local via Ollama or vLLM)
    *   OpenAI GPT-4o-mini (Via MotherDuck)
*   **Database Platforms:**
    *   PostgreSQL 16 with pgAI 0.8.0
    *   DuckDB v1.1.4 with FlockMTL v0.2.0
    *   MotherDuck (Enterprise)

**Query Patterns Evaluated**
*   **Q1:** LLM Projection
*   **Q2:** LLM Filter
*   **Q3:** Multi-LLM Invocation
*   **Q4:** LLM Aggregation
*   **Q5:** Retrieval-Augmented Generation (RAG)

**Architectural Modifications**
*   **FlockMTL:** Forced a batch size of 1 row to ensure JSON mapping reliability.
*   **vLLM:** Integrated with XGrammar for structured output enforcement.
*   **pgAI:** Implemented manual query plan optimization (filter/top-k pushdown) for RAG to prevent out-of-memory errors.

---

### üèÜ Contributions

*   **Definition & Taxonomy:** Formalized the definition of 'LLM queries' and pinpointed three specific obstacles preventing their effective adoption in open-source RDBMS.
*   **Benchmarking:** Provided a benchmark analysis comparing open-source against enterprise platforms using representative queries to illustrate current scalability limits.
*   **Research Roadmap:** Demonstrated through initial implementation that performance gains are achievable, establishing a research mandate for tighter integration between LLMs and database engines.

---

### üìà Results

**Test Environment**
*   **Hardware:** NVIDIA A100 80GB GPU
*   **Dataset:** Rotten Tomatoes (17,712 rows)

**Performance Metrics**
*   **Q1 Latency:**
    *   FlockMTL-vLLM: **342.4 minutes**
    *   pgAI-ollama: **719.5 minutes**
*   **Gap Analysis:** Open-source systems were found to be **an order of magnitude slower** than the enterprise system (MotherDuck).
*   **GPU Utilization:** Peaked at **95%** for FlockMTL with vLLM.

**Functional Success Rates**
| Platform | Q1 (Proj) | Q2 (Filter) | Q3 (Multi) | Q4 (Agg) | Q5 (RAG) |
| :--- | :---: | :---: | :---: | :---: | :---: |
| **MotherDuck** | ‚úÖ Pass | ‚úÖ Pass | ‚úÖ Pass | ‚úÖ Pass | ‚ùå Fail |
| **FlockMTL-vLLM** | ‚úÖ Pass | ‚úÖ Pass | ‚úÖ Pass | ‚ùå Fail | ‚ùå Fail |
| **pgAI** | ‚úÖ Pass | ‚ùå Fail | ‚ùå Fail | ‚ùå Fail | ‚úÖ Pass |

**Root Cause Analysis**
*   **Filter Failures:** Attributed to unstructured text outputs violating filter constraints.
*   **Aggregation Failures:** Caused by type mismatches (untyped blobs).
*   **RAG/System Failures:** Resulted from query planner issues causing expensive cross-joins and memory exhaustion.

---
*Quality Score: 8/10 | References: 40 citations*