---
title: Alignment-Aware Quantization for LLM Safety
arxiv_id: '2511.07842'
source_url: https://arxiv.org/abs/2511.07842
generated_at: '2026-02-03T18:51:15'
quality_score: 8
citation_count: 37
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Alignment-Aware Quantization for LLM Safety

*Sunghyun Wee; Suyoung Kim; Hyeonjin Kim; Kyomin Hwang; Nojun Kwak*

---

> ### üìä Quick Facts & Key Metrics
>
> *   **Target Compression:** 4-bit (W4A4)
> *   **Primary Innovation:** Alignment-Preserving Contrastive (APC) Loss
> *   **Data Requirement:** Standard calibration data only (No proprietary safety datasets needed)
> *   **Performance Highlight (LLaMA3.1-8B):**
>     *   **Safety Score:** 60.1 (vs. FP16 Baseline of 62.6)
>     *   **Perplexity:** 8.41 (Competitive with full precision)
>     *   **0-Shot Accuracy:** 65.54%

---

## üìë Executive Summary

This research addresses a critical vulnerability in current Post-Training Quantization (PTQ) methods for Large Language Models (LLMs): the degradation of safety alignment during compression. Standard PTQ techniques prioritize minimizing perplexity (PPL) to preserve linguistic fluency, but this singular focus often disrupts the safety alignment established through Reinforcement Learning from Human Feedback (RLHF). As models are compressed to extreme bit-widths to improve efficiency, they frequently regress to unaligned behaviors, generating unsafe outputs. This creates a significant barrier to deploying efficient models in production environments where trustworthiness is a non-negotiable requirement.

To resolve this issue, the authors introduce **Alignment-Aware Quantization (AAQ)**, a novel framework that integrates safety considerations directly into the quantization pipeline. The core technical innovation is the **Alignment-Preserving Contrastive (APC) Loss**, which utilizes a "pull-push" mechanism to guide optimization. The "Pull" component anchors the quantized model to the safe, fine-tuned reference using top-$k$ probabilities, while the "Push" component actively penalizes convergence toward the unsafe, pre-trained reference. AAQ optimizes learnable transformation matrices applied to weights and activations to reshape distributions for effective W4A4 compression. Crucially, this method requires only standard calibration data, eliminating the need for specialized, proprietary safety datasets.

Experimental validation on LLaMA3.1-8B, LLaMA2-7B, and Mistral-7B-v0.1 demonstrates that AAQ effectively maintains trustworthiness under W4A4 compression. On LLaMA3.1-8B, AAQ achieved a SafetyBench score of **60.1**, significantly outperforming the OSTQuant baseline (57.5) and approaching the full-precision FP16 baseline (62.6). In contrast, standard PTQ methods like GPTQ suffered catastrophic safety failures, with scores plummeting to approximately 35‚Äì38 and perplexity spiking to over 3000. Furthermore, AAQ maintained competitive general performance, achieving a perplexity of 8.41 and a 0-shot accuracy of 65.54 on LLaMA3.1-8B, indicating that safety recovery does not necessitate a sacrifice in model capability.

This work represents a paradigm shift in PTQ objectives, moving the field from a purely perplexity-based optimization to a multi-objective approach that explicitly accounts for alignment preservation. By demonstrating that high-performance 4-bit quantization does not require a loss in safety, the authors resolve a key trade-off between efficiency and trustworthiness. This advancement provides a practical deployment path for resource-efficient LLMs on edge devices, ensuring that models remain safe and aligned without requiring access to proprietary training data or complex retraining pipelines.

---

## üîç Key Findings

*   **Fundamental Flaw in Standard PTQ:** Conventional PTQ methods that prioritize low perplexity introduce significant safety vulnerabilities, often causing models to revert to unaligned behaviors.
*   **Safety Preservation via Contrastive Learning:** Introduces a Contrastive Loss mechanism capable of preserving safety alignment without the need for specialized or proprietary safety datasets.
*   **Data Efficiency:** Achieves robust safety alignment using only standard calibration data, making the method highly practical and accessible.
*   **Validation on Extreme Compression:** Successfully enables robust 4-bit (W4A4) quantization while maintaining high trustworthiness across diverse model families (LLaMA, Mistral).

---

## üõ†Ô∏è Methodology

### Alignment-Aware Quantization (AAQ)
AAQ is a novel Post-Training Quantization (PTQ) framework designed to integrate safety considerations directly into the quantization pipeline. Unlike traditional methods that focus solely on reconstruction error, AAQ explicitly optimizes for the retention of safety alignment established during RLHF.

### Alignment-Preserving Contrastive (APC) Loss
The core innovation of the paper, the APC loss, utilizes a "pull-push" mechanism to guide the quantization process:
*   **Pull Component:** Anchors the quantized model to mimic safe, instruction-tuned behavior.
*   **Push Component:** Forces the model to diverge from outputs characteristic of unaligned, pre-trained models.

### Integration with Standard PTQ
The method is designed to augment existing PTQ techniques. By adding the APC loss during the calibration phase, AAQ ensures that alignment is not sacrificed for the sake of computational efficiency, allowing for seamless integration into current compression workflows.

---

## ‚öôÔ∏è Technical Details

**Core Objective:**
Alignment-Aware Quantization (AAQ) optimizes learnable transformation matrices ($T$ and $T^{-1}$) applied to weights ($W$) and activations ($X$) to reshape distributions for quantization without full retraining. The transformation is formulated as:
$$Y = (WT)(T^{-1}X)$$

**Optimization Mechanism:**
The optimization is guided by the Alignment-Preserving Contrastive (APC) Loss, which employs a specific "pull-push" dynamic:

1.  **Pull Component ($L_{KL-top}$):** Anchors the quantized model to the fine-tuned (safe) reference by focusing on top-$k$ probabilities.
2.  **Push Component ($L_{cont-top}$):** Penalizes convergence toward the unsafe, pre-trained reference by utilizing indices of the largest behavioral difference.

**Operational Efficiency:**
The entire process operates on standard calibration data, removing the barrier of requiring specialized safety datasets for deployment.

---

## üìà Results

Experiments were conducted on **LLaMA3.1-8B**, **LLaMA2-7B**, and **Mistral-7B-v0.1** in a W4A4 setting.

### LLaMA3.1-8B Performance Comparison

| Metric | AAQ (Ours) | OSTQuant | GPTQ | FP16 Baseline |
| :--- | :--- | :--- | :--- | :--- |
| **Safety Score** | **60.1** | 57.5 | ~35-38 | 62.6 |
| **Perplexity (PPL)** | **8.41** | - | 3251.19 | - |
| **0-Shot Accuracy** | **65.54%** | - | - | - |

### Key Outcomes
*   **Safety Recovery:** AAQ consistently achieved the highest safety scores (SafetyBench) compared to baselines. Standard PTQ methods like GPTQ exhibited catastrophic failure in safety (scores ~35-38).
*   **Performance Stability:** Unlike GPTQ, which saw perplexity spike to over 3000, AAQ maintained a low perplexity (8.41), comparable to the full-precision baseline.
*   **Generalization:** AAQ successfully recovers safety alignment close to full-precision levels across multiple model architectures without sacrificing general performance capabilities.

---

## üöÄ Contributions

*   **Resolving the Safety-Efficiency Trade-off:** Demonstrates empirically that high-performance 4-bit quantization does not necessitate a loss in safety alignment.
*   **Paradigm Shift in PTQ Objectives:** Shifts the optimization focus from purely minimizing perplexity to a multi-objective approach that explicitly accounts for alignment preservation.
*   **Practical Deployment Path:** Enables W4A4 quantization that maintains safety without proprietary datasets, paving the way for real-world deployment of efficient, trustworthy LLMs on edge devices.

---

**Quality Score:** 8/10  
**References:** 37 citations