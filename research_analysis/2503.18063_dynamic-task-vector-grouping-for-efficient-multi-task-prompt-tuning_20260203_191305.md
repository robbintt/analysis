---
title: Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning
arxiv_id: '2503.18063'
source_url: https://arxiv.org/abs/2503.18063
generated_at: '2026-02-03T19:13:05'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Dynamic Task Vector Grouping for Efficient Multi-Task Prompt Tuning

*Pieyi Zhang; Richong Zhang; Zhijie Nie*

---

### üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Framework** | Dynamic Task Vector Grouping (DTVG) |
| **Strategy** | "Part For One" (Dynamic Subset Selection) |
| **Model Used** | T5-base (100 soft prompt tokens) |
| **Evaluation Scope** | 26 NLP Datasets (SuperGLUE subset highlighted) |
| **Quality Score** | 8/10 |
| **Citations** | 40 References |

---

## üìù Executive Summary

> **Overview:** Multi-task prompt tuning enhances Large Language Model (LLM) efficiency by transferring knowledge from source to target tasks. However, this process is often hindered by **"negative transfer,"** where irrelevant source tasks degrade target performance. Existing methods typically rely on static similarity metrics or suboptimal aggregation strategies (e.g., "All For One" or "One For One"), failing to account for the evolving nature of task representations during training.
>
> **Solution:** The authors introduce **Dynamic Task Vector Grouping (DTVG)**, a "Part For One" framework that optimizes knowledge transfer by dynamically selecting the most relevant subset of source tasks at each training iteration. The innovation lies in using **Task Prompt Vectors (TPVs)** for similarity measurement and a dual-metric strategy (target similarity + knowledge consistency) updated via a greedy heuristic.
>
> **Impact:** Validated on T5-base across 26 datasets, DTVG achieves state-of-the-art performance by effectively mitigating negative transfer. It establishes that task similarity is dynamic, providing a more reliable, parameter-efficient approach for deploying LLMs across diverse applications.

---

## üîë Key Findings

*   **Optimal Subset Selection:** The best transfer performance is achieved by selecting a specific combination of source tasks ("Part For One"), rather than relying on a single "high-similar" task ("One For One") or aggregating all available tasks ("All For One").
*   **Dynamic Nature of Similarity:** The similarity between source and target tasks is not static; it evolves dynamically during the fine-tuning process. Consequently, initial similarity measurements are insufficient for sustained performance.
*   **Efficacy of Task Vectors:** Measuring task similarity using **Task Prompt Vectors (TPVs)** is significantly more effective than relying on soft prompts.
*   **Superior Performance:** The proposed method successfully reduces negative transfer and achieves state-of-the-art results across 26 diverse NLP datasets.

---

## üß† Methodology

The authors propose the **Dynamic Task Vector Grouping (DTVG)** framework, designed to optimize source task selection and transfer. The methodology consists of three core components:

1.  **Task Vector-based Measurement**
    *   Calculates task similarity based on task vectors rather than soft prompts, providing a more robust metric for determining relationships between tasks.

2.  **Dual-Metric Grouping**
    *   Determines the optimal combination of source tasks using two specific metrics:
        *   **Target Similarity**
        *   **Knowledge Consistency**

3.  **Iterative Dynamic Updates**
    *   Continuously updates the group of selected source tasks at every iteration step of the fine-tuning process, adapting to the changing model state.

---

## ‚öôÔ∏è Technical Details

### Core Framework: "Part For One"
DTVG operates in two distinct stages to mitigate negative transfer:

*   **Stage I: Learning Task Prompt Vectors (TPVs)**
    *   Learns TPVs for all tasks.
    *   Calculates similarity based on the dot product of average token-wise vectors:
    $$ \frac{1}{r^2} (\sum v_{1i})^\top (\sum v_{2j}) $$

*   **Stage II: Iterative Source Task Grouping & Merging**
    *   **Source Task Grouping:** Maximizes *Target Similarity + Knowledge Consistency* via a greedy heuristic.
    *   **Multi-task Merging:** The prompt is constructed using the following formula:
    $$ P_{mix} = P_{init} + \alpha_t T_t + \sum_{s \in S'} \alpha_s T_s $$

---

## üìà Performance Results

Experiments were conducted using **T5-base** with 100 soft prompt tokens and 6 source tasks.

### SuperGLUE Subset Comparison

| Metric | TPV (Proposed) | Soft Prompt Tuning (PT) | SPoT |
| :--- | :---: | :---: | :---: |
| **Average Score** | **76.4** | 72.1 | 72.6 |
| **CB Dataset Score**| **92.9** | 82.1 | 78.6 |

### Key Observations
*   **Negative Transfer Mitigation:** While SPoT suffered from negative transfer on WSC and CB datasets, the TPV metric provided consistent positive transfer.
*   **Validation:** The results validate the efficacy of the "Part For One" approach over both "All For One" and "One For One" strategies.

---

## üèÜ Contributions

*   **Theoretical Insight:** Identified that task similarity is dynamic during training and that optimal multi-task prompt tuning requires a "middle-ground" approach to task selection.
*   **Methodological Innovation:** Introduced a novel mechanism combining task vector analysis with specific metrics (target similarity and knowledge consistency) to dynamically guide the transfer learning process.
*   **Empirical Validation:** Provided extensive experimental evidence across 26 NLP datasets demonstrating that dynamic grouping effectively mitigates negative transfer and sets a new performance benchmark.