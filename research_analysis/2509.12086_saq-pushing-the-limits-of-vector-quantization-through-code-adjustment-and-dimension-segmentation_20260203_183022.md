---
title: 'SAQ: Pushing the Limits of Vector Quantization through Code Adjustment and
  Dimension Segmentation'
arxiv_id: '2509.12086'
source_url: https://arxiv.org/abs/2509.12086
generated_at: '2026-02-03T18:30:22'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# SAQ: Pushing the Limits of Vector Quantization through Code Adjustment and Dimension Segmentation

*Hui Li; Shiyuan Deng; Xiao Yan; Xiangyu Zhi; James Cheng*

***

> ### ðŸ“Š Quick Facts
> **Error Reduction:** Up to **80%**
> **Speed Improvement:** Over **80x** faster encoding
> **Throughput Gain:** Up to **12.5x** higher
> **Recall Rate:** **95%**
> **Quality Score:** 9/10
> **References:** 40 Citations

***

## Executive Summary

This paper addresses the fundamental challenge of Vector Quantization (VQ) within Approximate Nearest Neighbor Search (ANNS), a critical bottleneck for high-dimensional data retrieval in modern applications such as search engines, recommender systems, and Retrieval-Augmented Generation (RAG) for Large Language Models (LLMs). The core issue lies in the trade-off between quantization accuracy and encoding efficiency; existing methods either suffer from high quantization error or rely on computationally expensive exhaustive enumeration to achieve low error. As the volume and dimensionality of vector data grow, minimizing relative error under strict space quotas without sacrificing processing speed has become a pressing necessity for scalable system design.

The authors introduce **SAQ** (Segmentation and Adjustment Quantization), a framework that optimizes VQ through a two-pronged methodology. The first component, **Dimension Segmentation**, partitions PCA-projected vectors along their dimensions and prioritizes leading segments with larger magnitudes. By utilizing a dynamic programming algorithm, SAQ dynamically allocates higher bit quotas to high-impact segments, maximizing accuracy. The second component, **Code Adjustment**, refines the quantization process by initially quantizing dimensions independently and then progressively optimizing the vectors using a coordinate-descent-like approach. This technique significantly reduces the time complexity associated with exhaustive search while maintaining high precision, further supported by SIMD implementations and distance bounds for efficient computation filtering.

SAQ demonstrates substantial performance improvements over classical methods (e.g., PQ, PCA) and state-of-the-art baselines (e.g., LVQ, Extended RaBitQ). In terms of accuracy, the framework achieves up to an 80% reduction in quantization error and a 5.4x improvement in overall accuracy compared to existing solutions. On the GIST dataset, SAQ maintained an average relative error of less than 20%, significantly outperforming baselines that exceeded this threshold. Crucially, these gains do not compromise efficiency; SAQ accelerates vector encoding speed by over 80x compared to Extended RaBitQ and delivers up to 12.5x higher query throughput while sustaining a 95% recall rate.

The significance of this research lies in its successful decoupling of encoding efficiency from quantization accuracy, effectively pushing the operational limits of vector quantization. By providing a scalable solution that balances high-speed encoding with superior precision, SAQ addresses a critical infrastructure need for latency-sensitive, data-intensive applications. This work sets a new benchmark for ANNS architectures and suggests that future systems can handle the massive vector datasets required by LLMs and real-time recommendation engines without incurring prohibitive storage or latency costs.

---

## Key Findings

*   **Significant Error Reduction:** SAQ achieves up to an **80% reduction** in quantization error compared to existing methods.
*   **Drastic Speed Improvement:** Accelerates vector encoding speed by over **80x** compared to Extended RabitQ.
*   **Superior Performance:** Demonstrates superiority over classical methods (e.g., PQ, PCA) and state-of-the-art approaches (e.g., LVQ, Extended RabitQ).
*   **Effective Trade-off Balance:** Successfully addresses the challenge of balancing encoding efficiency with quantization accuracy in Approximate Nearest Neighbor Search (ANNS).

---

## Methodology

The proposed SAQ framework utilizes a two-pronged approach involving **Segmentation and Adjustment**:

*   **Dimension Segmentation:**
    *   Partitions PCA-projected vectors into segments along their dimensions.
    *   Prioritizes leading dimension segments with larger magnitudes.
    *   Allocates higher bit quotas to high-impact segments.
    *   Utilizes a **dynamic programming algorithm** for optimal segmentation.

*   **Code Adjustment:**
    *   Initially quantizes each dimension independently.
    *   Refines quantized vectors progressively using a **coordinate-descent-like approach**.
    *   Designed to avoid the computational cost of exhaustive enumeration.

---

## Contributions

*   **Novel VQ Method:** Introduction of SAQ, a new Vector Quantization technique designed to improve ANNS for applications like search engines, recommender systems, and RAG for LLMs.
*   **Optimization of Bit Allocation:** A dimension segmentation technique that strategically allocates bits based on vector magnitude to maximize quantization accuracy.
*   **Algorithmic Efficiency:** The development of a code adjustment technique that significantly reduces encoding time complexity while maintaining high precision.

---

## Technical Details

### Problem Definition
The paper addresses Vector Quantization for Approximate Nearest Neighbor Search (ANNS), aiming to minimize relative error under space quotas.

### Baseline Architectures
*   **LVQ:** Uses mean-centering and local range division.
*   **RaBitQ:** Compresses to D-bit strings with random orthonormal projection and 1-bit codebooks.
*   **Extended RaBitQ:** Supports B-bit quantization with grid-based codebooks and pruned enumeration.

### SAQ Architecture & Innovations
*   **Core Innovations:** Code Adjustment and Dimension Segmentation.
*   **Distance Estimation:** Comprises a multi-stage distance estimator.
*   **Optimization:** Uses distance bounds for computation filtering and dynamic programming for bit allocation.
*   **Implementation:** Utilizes **SIMD implementations** for efficiency.
*   **Dimension Balancing:** Unlike dimension reduction methods, SAQ employs Dimension Balancing using random orthonormal projection.

---

## Results

*   **Overall Performance:** SAQ demonstrates significant improvements over baselines (Extended RaBitQ, LVQ, PQ, PCA), achieving up to an 80% reduction in quantization error and up to a **5.4x improvement in accuracy**.
*   **GIST Dataset:** SAQ achieves an average relative error of **less than 20%**, whereas baselines exceed 20%.
*   **Efficiency Metrics:**
    *   Accelerates vector encoding speed by over **80x** compared to Extended RaBitQ.
    *   Achieves up to **12.5x higher query throughput** while maintaining **95% recall**.

***

**References:** 40 citations