---
title: Detection of LLM-Paraphrased Code and Identification of the Responsible LLM
  Using Coding Style Features
arxiv_id: '2502.17749'
source_url: https://arxiv.org/abs/2502.17749
generated_at: '2026-01-27T21:50:32'
quality_score: 9
citation_count: 28
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

### üìã Quick Facts

| Metric | Value |
| :--- | :--- |
| **Proposed Method** | LPcodedec |
| **Dataset** | LPcode (21,355 samples) |
| **Languages Supported** | C, C++, Java, Python |
| **Detection Speedup** | 1,343x faster than baseline |
| **Identification Speedup** | 213x faster than baseline |
| **F1 Score Improvement (Detection)** | +2.64% |
| **F1 Score Improvement (ID)** | +15.17% |
| **Quality Score** | 9/10 |

***

# Detection of LLM-Paraphrased Code and Identification of the Responsible LLM Using Coding Style Features

*Authors: Hyundong Jin, Shinwoo Park, Sub Han (Yonsei University, Changwon National University)*

---

## üéØ Executive Summary

The proliferation of Large Language Models (LLMs) has introduced a sophisticated vector for software intellectual property theft: AI-assisted code paraphrasing. Malicious actors can now feed proprietary source code into LLMs to generate functionally equivalent but syntactically distinct versions, effectively bypassing traditional plagiarism detectors that rely on lexical similarity or structural overlap.

This paper addresses the critical gap in detecting these "LLM-paraphrased" derivatives. The core innovation is **LPcodedec**, a detection system that shifts the analytical focus from code semantics to **coding style**, specifically "Human Style" versus "LLM Style." The researchers hypothesized and validated that AI models introduce statistically significant divergences in naming consistency, code structure, and readability metrics.

To train and evaluate this approach, the team constructed the **'LPcode' dataset**, comprised of 21,355 samples across C, C++, Java, and Python. This dataset pairs human-written open-source code with paraphrased versions generated by specific models (ChatGPT, Gemini-Pro, WizardCoder, and DeepSeek-Coder).

**Performance Highlights:**
*   **Accuracy:** LPcodedec achieved an F1 score improvement of **+2.64%** for detection and **+15.17%** for identification compared to existing baselines.
*   **Efficiency:** The system demonstrated computational speedups of **1,343x** for detection tasks and **213x** for identification tasks.

This research establishes a new state-of-the-art standard for the detection of AI-generated code plagiarism, offering the community essential tools for code IP protection and forensic analysis.

---

## üîë Key Findings

*   **Stylistic Divergence:** Statistically significant differences in coding style exist between human-written and LLM-paraphrased code regarding naming consistency, structure, and readability.
*   **Superior Detection Accuracy:** The proposed method, **LPcodedec**, outperforms existing baselines with F1 score improvements of **2.64%** for paraphrase detection and **15.17%** for LLM identification.
*   **High Efficiency:** The solution achieves computational speedups of **1,343x** for detection tasks and **213x** for identification tasks compared to the best baselines.
*   **Feature Efficacy:** Coding style features are a robust mechanism for distinguishing between original code and LLM-generated paraphrases.

---

## üî¨ Technical Details

**Methodology:**
*   **Analytical Focus:** LPcodedec analyzes coding style features (naming consistency, code structure, readability metrics) rather than semantic or structural similarity.
*   **Objective:** It distinguishes between 'Human Style' and 'LLM Style'.

**Dataset Construction (LPcode):**
*   **Source Material:** Human code from GitHub repositories (created between Jan 1, 2019, and Jan 1, 2020).
*   **Licenses:** Filters for code with Apache, BSD, or MIT licenses.
*   **Generating Models:** Paraphrasing performed using ChatGPT, Gemini-Pro, WizardCoder, and DeepSeek-Coder.
*   **Languages:** Supports C, C++, Java, and Python.

**System Development:**
*   **Dual Task Capability:**
    1.  Determining if code is an LLM-paraphrased version of a human original.
    2.  Identifying the specific LLM responsible for the paraphrasing.

---

## üìä Results

**Performance Metrics:**
*   **Paraphrase Detection:** Improved F1 Score by **+2.64%**.
*   **LLM Identification:** Improved F1 Score by **+15.17%**.
*   **Detection Speed:** **1,343x** faster than the best existing baseline.
*   **Identification Speed:** **213x** faster than the best existing baseline.

**Dataset Composition (LPcode):**
*   **Total Samples:** 21,355
    *   Human-Written: 4,271
    *   LLM-Paraphrased: 17,084
*   **Language Breakdown:**
    *   Python: 9,675
    *   Java: 7,470
    *   C: 2,285
    *   C++: 1,925

---

## üõ†Ô∏è Methodology

1.  **Dataset Construction:** Researchers constructed the 'LPcode' dataset containing pairs of human-written proprietary code and their corresponding paraphrased versions generated by various LLMs.
2.  **Statistical Analysis:** A comparative analysis was performed to quantify and validate differences in coding style features (e.g., naming conventions, structure) between human and AI-generated code.
3.  **System Development:** Based on identified style features, 'LPcodedec' was developed to perform detection and attribution tasks.

---

## ‚ú® Contributions

*   **Problem Formalization:** The paper addresses the gap in research regarding LLM-assisted code paraphrasing by defining tasks for detecting paraphrased code and identifying the source model.
*   **Resource Provision:** The release of the **LPcode** dataset provides a valuable resource for the community to train and evaluate models on code attribution and IP protection.
*   **High-Performance Solution:** The introduction of **LPcodedec** establishes a new state-of-the-art standard for detecting code plagiarism via LLMs, offering a balance of high accuracy and extreme processing speed.

---

**References:** 28 citations | **Quality Score:** 9/10