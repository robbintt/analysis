---
title: 'From LLMs to Agents: A Comparative Evaluation of LLMs and LLM-based Agents
  in Security Patch Detection'
arxiv_id: '2511.08060'
source_url: https://arxiv.org/abs/2511.08060
generated_at: '2026-01-27T22:31:48'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# From LLMs to Agents: A Comparative Evaluation of LLMs and LLM-based Agents in Security Patch Detection

*Yao Wan, Junxiao Han, Song Han, Lingfeng Bao, Shuiguang Deng, Jianwei Yin, Zheng Yu, Jiakun Liu*

---

> **Quick Facts Sidebar**
>
> *   **Quality Score**: 8/10
> *   **Dataset**: PatchDB (35,000 patches: 12k security, 23k non-security)
> *   **Repositories**: 313 Open-source projects
> *   **Top Models Evaluated**: GPT-4o, Deepseek-R1, Llama-3.1-8b
> *   **Top Performer (Accuracy)**: Data-Augmented LLM
> *   **Top Performer (Precision/Lowest FPR)**: ReAct Agent
> *   **Key Trade-off**: Accuracy/Latency

---

## Executive Summary

Accurately identifying security patches in version control systems is vital for automated vulnerability management, yet it remains a challenge due to high false positive rates. This research demonstrates that while standalone Large Language Models (LLMs) possess advanced reasoning capabilities, they struggle with the context limitations required to distinguish between security fixes and standard bug repairs.

The paper introduces a transformative solution: an **LLM-based agent framework** utilizing a "Thought-Action-Observation" loop (ReAct paradigm). By equipping the model with tools—such as file readers, static analysis utilities, and web crawlers (e.g., 'Crawl' to access NVD)—the agent can actively investigate the code environment. This allows it to autonomously gather context, analyze commit histories, and verify findings, effectively overcoming the isolation of traditional LLM processing.

The evaluation on the PatchDB dataset (35,000 patches) reveals compelling trade-offs: **Data-Augmented LLM** achieved the highest overall accuracy, while the **ReAct Agent** delivered the lowest False Positive Rate (FPR), significantly outperforming traditional Deep Learning baselines like PatchRNN and GraphSPD. The study concludes that in the domain of security patch detection, agentic workflow design and environmental interaction are more critical to success than merely scaling the underlying model size.

---

## Key Findings

*   **Superiority of Agents:** LLM-based agents significantly outperform standalone LLMs in security patch detection, primarily because they can overcome context window limitations through tool usage.
*   **Environmental Interaction is Key:** The critical factor for an agent's success is the ability to interact with the environment (e.g., reading code diffs, checking commit history) rather than just the raw reasoning power of the LLM.
*   **Cost vs. Accuracy Trade-off:** While agents provide higher precision (lower FPR) and better handling of multi-file patches, they introduce substantially higher computational costs and latency compared to direct LLM inference.
*   **Architecture over Scale:** Increasing model size is less effective for this specific task than architecting an agentic system capable of perceiving the code environment.

---

## Methodology

The researchers employed a rigorous three-step approach to compare raw LLM capabilities against agentic workflows:

1.  **Framework Construction:** Built an LLM-based agent framework specifically for software engineering, equipping it with tools to access repositories, read files, and analyze patch diffs.
2.  **Comparative Evaluation:** Conducted a large-scale comparison between state-of-the-art proprietary LLMs (baselines) and the proposed LLM-based agents.
3.  **Benchmarking:** Utilized the **PatchDB** dataset, comprising real-world patches from open-source projects and CVE databases. Performance was measured based on:
    *   Accuracy in identifying security patches.
    *   Ability to distinguish between security and non-security bug fixes.

---

## Technical Details

### Dataset: PatchDB
The evaluation utilized the PatchDB dataset, aggregating data from 313 repositories:
*   **Security Patches:** 12,000
*   **Non-Security Patches:** 23,000
*   **Total:** 35,000 real-world patches

### Evaluated Approaches
The study compared three distinct methodological setups:

| Approach | Description | Strategy |
| :--- | :--- | :--- |
| **Plain LLM** | Baseline method using direct LLM interaction. | Single interaction with diff code and commit ID. |
| **Data-Aug LLM** | Enhanced baseline designed to improve data diversity. | Utilizes NVD-based, wild-based, and synthetic data augmentation (oversampling/code synthesis). |
| **ReAct Agent** | The proposed agentic workflow. | Uses a 'Thought-Action-Observation' loop with tools: `Get-diff-analysis`, `Get-message-analysis`, and `Crawl`. |

### Models & Baselines
*   **Commercial Models:** GPT-4o, GPT-4o-mini, Deepseek-R1.
*   **Open-Source Models:** Llama-3.1-8b, Gemma-3.
*   **Traditional Baselines:** PatchRNN (RNN-based), GraphSPD, RepoSPD (GNN-based).
*   **Prompting Strategies:** Chain-of-Thought and Few-Shot prompting.

---

## Results

*   **Accuracy Winner:** The **Data-Aug LLM** approach achieved the best overall classification accuracy among all evaluated methods.
*   **Precision Winner:** The **ReAct Agent** demonstrated the lowest False Positive Rate (FPR), significantly outperforming baseline methods in error reduction.
*   **Comparison with DL:** Compared to traditional Deep Learning methods (PatchRNN, GraphSPD), the proposed LLM-based methods achieved comparable accuracy but with substantially reduced FPR.
*   **Quantitative Analysis by Vulnerability Type:**
    *   **Information Exposure:** 926 and 267 instances
    *   **Input Validation:** 432 instances
    *   **Resource Management Errors:** 399 and 288 instances
    *   **Out-of-Bounds Read:** 261 instances
    *   **Authorization Management:** 240 instances

---

## Contributions

*   **First Large-Scale Comparison:** Provides the first comprehensive evaluation specifically focusing on the difference between raw LLMs and agentic workflows in security patch detection.
*   **Empirical Evidence on Architecture:** Offers evidence that designing agentic systems capable of tool usage is more effective than simply increasing model size for this domain.
*   **Community Resources:** Likely releases a dataset or evaluation framework to assist the community in further assessing LLM agents in automated program repair and security analysis.

---

**References:** 40 Citations