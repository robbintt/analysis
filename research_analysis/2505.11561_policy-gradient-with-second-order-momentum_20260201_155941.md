# Policy Gradient with Second Order Momentum

*Tianyu Sun*

---

### üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Algorithm** | PG-SOM (Policy Gradient with Second Order Momentum) |
| **Sample Efficiency** | Up to **2.1x** increase vs. baselines |
| **Variance** | Substantial reduction |
| **Memory Overhead** | **O(D)** (Linear) |
| **Key Innovation** | Diagonal Hessian preconditioning |
| **Quality Score** | 9/10 |

---

> ## üìù Executive Summary
>
> Policy gradient methods in reinforcement learning, particularly the "REINFORCE" algorithm, are notoriously hindered by high variance and pathological curvature in the optimization landscape. While second-order optimization methods theoretically address these issues by utilizing curvature information to precondition updates, they are often computationally prohibitive. Standard second-order approaches require calculating and storing large, dense matrices, such as the Fisher Information Matrix, resulting in quadratic memory complexity and high computational costs that make them impractical for high-dimensional policies.
>
> This paper introduces **Policy Gradient with Second Order Momentum (PG-SOM)**, a lightweight optimization scheme that integrates second-order momentum into policy gradients without the typical computational overhead. PG-SOM works by maintaining two exponentially weighted statistics: a first-order gradient average and a diagonal approximation of the Hessian. The method employs a second-order Runge-Kutta numerical technique to estimate this diagonal curvature, which is then used to precondition the gradient, adaptively rescaling parameters to stabilize ascent. Crucially, the authors establish that their diagonal Hessian estimator is unbiased and positive-definite under mild regularity assumptions, guaranteeing mathematically that the update direction is a descent direction in expectation.
>
> Empirically, PG-SOM demonstrates substantial performance gains across five standard continuous control benchmarks. The method achieves up to a **2.1x increase in sample efficiency** compared to baseline methods. Additionally, it realizes a significant reduction in variance relative to both first-order methods and Fisher-matrix baselines. A key practical advantage of PG-SOM is its efficiency; it provides these improvements with only linear memory overhead ($O(D)$ where $D$ is the number of parameters), proving that coarse second-order information is sufficient for superior optimization in this domain.
>
> **Significance:** This research challenges the assumption that full-matrix second-order calculations are necessary to gain the benefits of curvature-aware optimization. By demonstrating that a simple diagonal approximation can outperform complex baselines while offering theoretical guarantees, PG-SOM is a compelling candidate for scalable deep reinforcement learning systems.

---

## üîë Key Findings

*   **Boosted Sample Efficiency:** PG-SOM achieves up to a **2.1x increase** in sample efficiency compared to baseline methods on standard control benchmarks.
*   **Variance Reduction:** The method demonstrates a substantial reduction in variance when compared to both first-order methods and Fisher-matrix baselines.
*   **Theoretical Guarantees:** The diagonal Hessian estimator is proven to be **unbiased** and **positive-definite** under mild regularity assumptions. Consequently, the resulting update is mathematically guaranteed to be a descent direction in expectation.
*   **Computational Efficiency:** Significant practical gains are realized using only coarse second-order information, incurring a linear memory overhead of **D** for a policy with D parameters.

---

## üî¨ Methodology

PG-SOM is a lightweight second-order optimization scheme designed to augment the classical REINFORCE algorithm. Its core mechanics include:

1.  **Statistics Maintenance:** It maintains two exponentially weighted statistics:
    *   A first-order gradient average.
    *   A diagonal approximation of the Hessian.
2.  **Curvature Preconditioning:** The method utilizes the diagonal Hessian estimate (curvature estimate) to precondition the gradient.
3.  **Adaptive Rescaling:** By preconditioning the gradient, PG-SOM adaptively rescales each parameter, enabling faster and more stable ascent of the expected return.

---

## üìà Contributions

*   **Novel Optimization Scheme:** Proposed PG-SOM, a new method that integrates second-order momentum into policy gradients without the heavy computational cost typically associated with second-order methods.
*   **Rigorous Theoretical Foundation:** Established rigorous theoretical properties for the estimator, including proofs of:
    *   Unbiasedness
    *   Positive-definiteness
    *   Existence of a descent direction in expectation
*   **Empirical Validation:** Provided empirical evidence that coarse second-order information is sufficient to outperform standard first-order and Fisher-matrix baselines in terms of both stability and sample efficiency.

---

## ‚öôÔ∏è Technical Details

**Core Concept**
Policy Gradient with Second Order Momentum (PG-SOM) is a lightweight extension of REINFORCE. It utilizes a diagonal Hessian estimate as a pre-conditioner for adaptive momentum updates to address pathological curvature and variance.

**Theoretical Properties**
*   **Hessian Decomposition:** Theoretical lemmas provide a decomposition of the Hessian of the expected return.
*   **Independence:** Established score-function independence from the environment's transition kernel.
*   **Descent Direction:** The method guarantees a descent direction in expectation through an unbiased, positive-definite diagonal curvature estimator.

**Implementation & Complexity**
*   **Numerical Technique:** Employs a second-order Runge-Kutta numerical technique for gradient estimation.
*   **Memory Complexity:** Maintains linear memory complexity **O(D)** by storing only the diagonal Hessian, rather than dense matrices.

---

## üèÅ Empirical Results

PG-SOM was evaluated across five continuous control benchmarks, yielding the following results:

*   **Efficiency:** Demonstrated up to a **2.1x increase in sample efficiency** compared to baseline methods.
*   **Variance:** Achieved substantial variance reduction compared to first-order methods and Fisher-matrix baselines.
*   **Scalability:** The method scales efficiently with linear memory overhead O(D).
*   **Performance:** Showed improvements in both sample efficiency and final return across all tested benchmarks.

---

**Quality Score:** ‚≠ê 9/10  
**References:** 19 citations