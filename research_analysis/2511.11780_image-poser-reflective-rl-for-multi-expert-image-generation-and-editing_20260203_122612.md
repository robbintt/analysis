---
title: 'Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing'
arxiv_id: '2511.1178'
source_url: https://arxiv.org/abs/2511.11780
generated_at: '2026-02-03T12:26:12'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing

*Hossein Mohebbi; Mohammed Abdulrahman; Yanting Miao; Pascal Poupart; Suraj Kothawade*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Total Citations:** 40
> *   **Benchmark Improvement:** +12% on GenEval (vs. baselines)
> *   **Human Preference:** Preferred 68% of the time
> *   **Failure Threshold:** 3 attempts per operation
> *   **Core Architecture:** Reflective RL with Deep Q-Network (DQN)

---

> ### ðŸ“ Executive Summary
>
> Current text-to-image (T2I) generation models face significant limitations when processing complex, long-form prompts or executing sequential editing tasks that require multi-step reasoning. While single-shot models like FLUX.1 generate high-quality images, they often fail to accurately handle intricate spatial relations, precise object counting, or iterative modifications without human intervention. This paper addresses the fundamental constraint of static, monolithic generation pipelines, highlighting the critical need for a system capable of decomposing complex instructions and dynamically orchestrating specialized tools to achieve high-fidelity results.
>
> The authors introduce **Image-POSER**, a Reflective Reinforcement Learning (RL) framework that formulates image synthesis as a Markov Decision Process (MDP). The system utilizes a lightweight Deep Q-Network (DQN) agent to manage a "reflective loop" comprising four distinct stages: **Act** (selecting T2I or Image-to-Image experts), **Execute** (generating the image), **Critique** (evaluating the output via a Vision-Language Model), and **Plan** (decomposing prompts via an LLM). This architecture enables the agent to learn an orchestration policy that adaptively selects the optimal expert for the current sub-task.
>
> Image-POSER demonstrates superior performance over state-of-the-art single-shot baselines, including Gemini 2.5 Flash and FLUX.1, across key metrics of alignment, fidelity, and aesthetics. Specifically, the framework achieved a **12% improvement on the GenEval benchmark**. In human evaluations, the framework was preferred **68% of the time** over competing models. This research represents a significant advancement toward general-purpose visual assistants capable of reasoning and adaptive expert selection, establishing a new paradigm for agentic image generation.

---

## Key Findings

*   **Superior Performance:** Outperforms existing baselines (including Gemini 2.5 Flash and FLUX.1) in alignment, fidelity, and aesthetics.
*   **Human Preference:** Consistently preferred in human evaluations over competing models.
*   **Complex Prompt Handling:** Successfully executes long, compositional prompts that typically fail in single-shot models.
*   **Adaptive Pipelines:** Learns adaptive pipelines that combine the strengths of diverse pretrained visual models.

---

## Core Contributions

*   **Unified Framework:** Introduction of a unified framework for composition bridging single-shot models and complex creative workflows.
*   **RL Orchestration:** Demonstration that reinforcement learning enables autonomous decomposition and combination of distinct visual models.
*   **Visual Assistants:** Establishment of a significant step toward general-purpose visual assistants capable of reasoning and adaptive expert selection.

---

## Methodology

The researchers introduce **Image-POSER**, a reflective reinforcement learning framework that formulates image synthesis and editing as a Markov Decision Process. The methodology focuses on:

1.  **Expert Orchestration:** Utilizing a pool of pretrained models.
2.  **Dynamic Decomposition:** Breaking down long-form prompts into atomic commands.
3.  **Structured Supervision:** Using a Vision-Language Model (VLM) acting as a critic to provide feedback and rewards.

---

## Technical Architecture

The system employs a sophisticated technical stack to manage multi-step image generation:

*   **Algorithm:** Reflective Reinforcement Learning (RL) using a lightweight Deep Q-Network (DQN) agent.
*   **Problem Formulation:** Multi-expert image generation is treated as a sequential decision-making problem.

### The Reflective Loop
The system operates via a four-stage loop:
1.  **Act:** Selecting appropriate T2I or I2I experts.
2.  **Execute:** Generating the image using the selected expert.
3.  **Critique:** A VLM evaluates the output and provides feedback/rewards.
4.  **Plan:** An LLM extracts the next atomic command based on feedback.

### State & Action Management
*   **State Representation:** Utilizes text embeddings of both the current command and the remaining commands in the prompt.
*   **Dynamic Action Masking:** Ensures valid expert selection by dynamically masking unavailable or invalid actions.

### Task Management
*   **Dynamic Decomposition:** Automatically breaks complex tasks into sub-tasks.
*   **Retry Mechanisms:** Features a failure threshold of three attempts to ensure robustness.

---

## Evaluation Results

*   **Benchmark Success:** Achieved a 12% improvement on the GenEval benchmark compared to the strongest single-model baselines.
*   **Complex Task Mastery:** Successfully handles complex tasks such as:
    *   Accurate object counting.
    *   Complex spatial relations.
    *   Sequential editing (e.g., rotating objects, changing labels).
*   **Optimized Orchestration:** The learned policy proved more effective than heuristic methods (like Visual ChatGPT) and single-model RL approaches (like RLAIF) by optimizing the orchestration policy.

---

**Paper Quality Score:** 8/10
**References:** 40 citations