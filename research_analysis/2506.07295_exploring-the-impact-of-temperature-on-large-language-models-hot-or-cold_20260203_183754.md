---
title: Exploring the Impact of Temperature on Large Language Models:Hot or Cold?
arxiv_id: '2506.07295'
source_url: https://arxiv.org/abs/2506.07295
generated_at: '2026-02-03T18:37:54'
quality_score: 9
citation_count: 35
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Exploring the Impact of Temperature on Large Language Models: Hot or Cold?

*Lujun Li; Lama Sleem; Niccolo' Gentile; Geoffrey Nichil; Radu State*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 9/10 |
| **References** | 35 Citations |
| **Model Tiers Analyzed** | Small (1Bâ€“4B), Medium (6Bâ€“13B), Large (40Bâ€“80B) |
| **Temperature Range** | 0.0 to 4.0 |
| **Quantization Methods** | FP16 vs. 4-bit AWQ |
| **Key Innovation** | BERT-based Temperature Selector |

---

## Executive Summary

**Problem**
Temperature is a fundamental hyperparameter in Large Language Models (LLMs) that controls the randomness of text generation. However, the industry standard relies on static, "one-size-fits-all" values that fail to account for task-specific nuances and model scales. This paper addresses the critical gap in understanding how temperature interacts with semantic capabilities, highlighting that a static approach obscures the relationship between sampling randomness and model capacity. The authors argue that without a dynamic approach to inference optimization, the effective deployment of models across diverse applications is significantly limited.

**Innovation**
The authors introduce two key innovations: a novel **BERT-based temperature selector** and the formal concept of **"Mutation Temperature."** The BERT-based selector is designed to dynamically optimize inference by classifying input prompts and applying tailored sampling parameters in real-time, eliminating the need for manual tuning. Complementing this tool, the study formally defines Mutation Temperature as a specific threshold where performance characteristics shift. This concept provides a theoretical framework for analyzing how temperature sensitivity correlates with parameter scale, moving beyond empirical observation to a structured understanding of model stability.

**Results**
The study employed a rigorous methodology, categorizing open-source models into three tiers. Researchers evaluated temperature impacts across a range of 0 to 2 (extended to 4.0 for quantization comparisons) on datasets assessing six distinct semantic capabilities. Experimental results demonstrated that optimal temperature is highly non-linear; the proposed BERT-based selector significantly improved performance on SuperGLUE datasets for smaller models. Key findings reveal that Mutation Temperature scales with model size: while creativity in large models peaks at T=1.3 and In-Context Learning remains robust, Instruction Following requires T < 1.0 to avoid degradation. Furthermore, temperature effects remain consistent between FP16 and 4-bit quantized models despite a 10â€“20% absolute performance gap.

**Impact**
This research provides a new theoretical lens for model stability by decoupling randomness from model capacity, offering critical insights into how parameter scale influences temperature sensitivity. By validating the feasibility of deploying efficient 4-bit quantized models without necessitating changes to sampling strategies, the study presents a significant advantage for resource-constrained environments. Ultimately, this work enables the development of intelligent, adaptive inference systems that maximize performance through dynamic parameter selection, shifting the industry away from static configurations toward precision-tuned deployment.

---

## Key Findings

*   **Task-Dependent Effects:** Sampling temperature has distinct, non-uniform effects on different model capabilities, indicating that optimal temperature selection is complex and task-dependent.
*   **Performance Optimization:** The proposed BERT-based temperature selector can significantly improve the performance of small and medium models on SuperGLUE datasets.
*   **Quantization Consistency:** The effects of temperature on model behavior are consistent between FP16 precision inference and 4-bit quantized models.
*   **Mutation Temperature:** The 'Mutation Temperature' threshold increases alongside the size of the model.

---

## Methodology

The research employed a structured approach to evaluate temperature sensitivity across different model scales and precisions:

*   **Model Stratification:** Conducted statistical analyses on open-source models categorized into three tiers:
    *   **Small:** 1Bâ€“4B parameters
    *   **Medium:** 6Bâ€“13B parameters
    *   **Large:** 40Bâ€“80B parameters
*   **Evaluation Range:** Evaluated temperature impacts across a range of **0 to 2** on datasets designed to assess six distinct semantic capabilities.
*   **Quantization Analysis:** Extended the methodology to compare FP16 precision against 4-bit quantized models, evaluating temperature effects up to **4.0**.
*   **Dynamic Selection:** Developed and utilized a BERT-based selector to identify the optimal temperature for specific prompts dynamically.

---

## Contributions

*   **Systematic Evaluation:** Provides a comprehensive evaluation of how temperature modulates randomness and influences semantic understanding in LLMs.
*   **Automatic Selection Mechanism:** Introduces a novel, BERT-based mechanism for automatic temperature selection to optimize inference for specific prompts without manual tuning.
*   **Theoretical Framework:** Defines and characterizes **'Mutation Temperature,'** offering new insights into how model stability and temperature sensitivity correlate with parameter scale.

---

## Technical Details

**Formulas & Algorithms**
*   **Temperature Scaling:** Applied to logits before softmax using the formula:
    $$P_i = \frac{e^{y_i/T}}{\sum e^{y_j/T}}$$
*   **Selector Architecture:** Proposes a BERT-based Selector to classify input prompts and dynamically select optimal temperatures.

**Experimental Setup**
*   **Quantization:** 4-bit AWQ quantization.
*   **Inference Engine:** vLLM inference.
*   **Sampling Strategy:** Nucleus sampling (Top-P).

**Hyperparameters**
*   **Temperature Range:** 0.1 to 1.9 (Primary), up to 4.0 (Quantization comparison).
*   **Top-P:** 0.9
*   **Repetition Penalty:** 1.0
*   **Evaluation Model:** GPT-3.5-turbo-0125

---

## Results

**Optimal Temperature by Capability**
*   **Creativity:** Peaks at **T=1.3** for large models.
*   **Instruction Following:** Requires **T < 1.0** to avoid performance drops at a 'mutation temperature' that scales with model size.
*   **In-Context Learning:** Remains robust in large models across varying temperatures.
*   **Machine Translation:** Highly sensitive to temperature increases.

**Quantization & Stability**
*   **Consistency:** Optimal temperature settings remain consistent across 4-bit and FP16 quantization despite a 10â€“20% performance gap.

**Parameter Correlation**
*   **Top-K/Top-P/Repetition Penalty:** Generally have minimal impact on the temperature-performance curve (**p â‰ˆ 0.86â€“1.00**).
*   **Exception:** Top-P shows significant influence on **Creativity** tasks.