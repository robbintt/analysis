# Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction

*Changjun Li; Runqing Jiang; Zhuo Song; Pengpeng Yu; Ye Zhang; Yulan Guo*

***

### ðŸ“Š Quick Facts
> *   **Quality Score:** 8/10
> *   **References:** 40 Citations
> *   **Core Problem:** Accuracy loss in low-bit PTQ due to neglected cross-block dependencies.
> *   **Key Innovation:** Hessian-guided pack-wise reconstruction vs. traditional block-wise.
> *   **Performance Highlight (W3/A3):**
>     *   **ResNet-18:** 67.4% (+3.4% over BRECQ)
>     *   **MobileNetV2:** 60.2% (+2.7% over BRECQ)

***

## Executive Summary

Post-Training Quantization (PTQ) is critical for deploying large-scale neural networks on resource-constrained edge devices, as it enables compression without the prohibitive computational cost of end-to-end retraining. However, existing low-bit PTQ methodsâ€”specifically those relying on block-wise reconstructionâ€”encounter a severe bottleneck in aggressive compression scenarios. When targeting low-bit regimes such as W3/A3 (3-bit weights, 3-bit activations), these methods suffer significant accuracy degradation. This occurs because traditional approaches optimize blocks independently, failing to account for the intricate cross-block dependencies and interactions that are vital for preserving the model's inference capability.

To address this limitation, the authors propose **Pack-PTQ**, a framework that fundamentally shifts the optimization granularity from block-wise to **pack-wise reconstruction**. The core innovation involves a **Hessian-guided adaptive packing mechanism** that groups non-overlapping blocks into "packs." By leveraging Hessian informationâ€”specifically importance scores derived from model loss and output gradientsâ€”the algorithm captures cross-block dependencies that conventional methods miss. Furthermore, Pack-PTQ implements a pack-configured mixed-precision quantization strategy, assigning variable bit-widths to specific packs based on their sensitivity, thereby optimizing the trade-off between model compression and accuracy.

The research validates the efficacy of Pack-PTQ through rigorous experimentation on ImageNet for 2D image classification and 3D point cloud tasks. In the challenging W3/A3 setting, Pack-PTQ delivers substantial performance gains over state-of-the-art baselines. On ResNet-18, the framework achieved a Top-1 accuracy of **67.4%**, outperforming the previous SOTA method, BRECQ, by **3.4 percentage points**. Similarly, on MobileNetV2, Pack-PTQ reached **60.2%** accuracy, surpassing BRECQ by **2.7 percentage points**. The method also demonstrated consistent superiority over other leading techniques like Q-Drop and NoisyQuant across architectures including DeiT-T and Swin-S.

This work represents a methodological advancement in model compression by demonstrating that the preservation of cross-block dependencies is essential for high-accuracy, low-bit quantization. The successful application of this framework to both 2D and 3D visual tasks underscores its versatility and robustness across different data modalities. By establishing a new state-of-the-art for PTQ without requiring retraining and providing significant accuracy recovery in low-bit regimes, Pack-PTQ offers a highly practical solution for deploying efficient, high-performance models in real-world production environments.

***

## Key Findings

*   **Dependency Resolution:** Existing PTQ methods utilizing block-wise reconstruction suffer from significant accuracy drops in low-bit scenarios because they fail to account for **cross-block dependencies**.
*   **Pack-wise Innovation:** The proposed Pack-PTQ method successfully preserves cross-block dependencies by using a **Hessian-guided adaptive packing mechanism** that groups blocks into non-overlapping packs.
*   **Precision Optimization:** Implementing a mixed-precision quantization approach allows for the assignment of varied bit-widths to specific packs based on their unique sensitivity, enhancing overall model performance.
*   **Cross-Modal Superiority:** The method demonstrates superiority over current state-of-the-art PTQ techniques across both **2D image classification and 3D point cloud tasks**.

***

## Methodology

The research proposes **Pack-PTQ**, a Post-Training Quantization framework that functions without end-to-end retraining. The methodology consists of two primary phases:

1.  **Hessian-Guided Adaptive Packing**
    The algorithm partitions blocks into non-overlapping "packs" guided by Hessian information. This step is designed to capture the cross-block dependencies that are typically lost in standard block-wise approaches.
    
2.  **Pack-Configured Mixed-Precision Quantization**
    Different bit-widths are assigned to each pack based on their distinct sensitivity. This optimizes the trade-off between compression rates and model accuracy, ensuring that sensitive areas of the network retain higher precision.

***

## Contributions

*   **Structural Innovation in PTQ:** Introduced a shift from block-wise to pack-wise reconstruction, addressing the fundamental limitation of neglected cross-block dependencies in previous methods.
*   **Adaptive Grouping Mechanism:** Developed a specific Hessian-guided algorithm to create the optimal non-overlapping pack configuration for reconstruction.
*   **Optimized Compression Strategy:** Contributed a novel mixed-precision quantization strategy that leverages sensitivity analysis at the pack level rather than the channel or layer level.
*   **Cross-Modal Validation:** Demonstrated the versatility and robustness of the method by achieving state-of-the-art results on diverse vision tasks, including both 2D image and 3D point cloud classification.

***

## Technical Details

*   **Framework Objective:** Addresses accuracy degradation in low-bit scenarios (e.g., W3/A3) by optimizing reconstruction granularity.
*   **Core Strategy:** Shifts from block-wise to pack-wise reconstruction, clustering blocks into non-overlapping packs to handle cross-block dependencies.
*   **Packing Mechanism:** Utilizes a Hessian-guided adaptive packing mechanism grouping blocks based on importance scores (incorporating model loss, output gradients, and local loss).
*   **Quantization Type:** Implements **pack-based mixed-precision quantization** to assign varying bit-widths based on pack sensitivity.
*   **Quantization Scheme:** Uniform Affine Quantization applied to weights and activations.

***

## Results

Experiments were conducted on **ImageNet** and **3D point cloud** datasets using architectures like ResNet18, MobileNetV2, DeiT-T, and Swin-S, focusing on W3/A3 settings.

*   **Comparison Baselines:** Pack-PTQ outperformed baselines (*No Packing, Random Packing, Fixed-size Packing*) in Top-1 Accuracy across all tested architectures.
*   **Dependency Capture:** The results confirm that the Hessian-guided packing mechanism effectively captures cross-block dependencies for higher accuracy.
*   **SOTA Comparison:** The method claims superiority over state-of-the-art PTQ methods like **BRECQ, Q-Drop, NoisyQuant, and SPQ** in both 2D and 3D tasks.

***

### Performance Breakdown (W3/A3)

| Architecture | Metric | Result |
| :--- | :--- | :--- |
| **ResNet-18** | Top-1 Accuracy | **67.4%** (+3.4% vs BRECQ) |
| **MobileNetV2** | Top-1 Accuracy | **60.2%** (+2.7% vs BRECQ) |