---
title: Online Learning of HTN Methods for integrated LLM-HTN Planning
arxiv_id: '2511.12901'
source_url: https://arxiv.org/abs/2511.12901
generated_at: '2026-02-03T13:08:42'
quality_score: 9
citation_count: 6
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Online Learning of HTN Methods for integrated LLM-HTN Planning
*Yuesheng Xu; Hector Munoz-Avila*

> ### ðŸ“Š Quick Facts
> | Metric | Value |
> | :--- | :--- |
> | **Quality Score** | 9/10 |
> | **API Call Reduction (Logistics)** | ~90% |
> | **API Call Reduction (Search & Rescue)** | ~85% |
> | **Success Rate (Standard Logistics)** | 100% |
> | **Domains Tested** | Logistics Transportation, Search and Rescue |
> | **Citations** | 6 |

---

## Executive Summary

This research addresses the computational inefficiency and rigidity associated with integrating Large Language Models (LLMs) with Hierarchical Task Network (HTN) planning. While LLMs like ChatGPT can act as domain experts to fill gaps in a planner's knowledge base, relying on real-time API queries for every decomposition results in high latency, increased costs, and potential bottlenecks. The problem is particularly acute in the baseline ChatHTN planner, which queries the LLM for every task decomposition without retaining knowledge, leading to redundant operations. This work is significant because it seeks to enable autonomous agents to leverage the generative power of LLMs for knowledge acquisition while minimizing the dependency on expensive and slow external API calls, thereby moving toward more scalable and efficient neuro-symbolic systems.

The key innovation is an online method learner built upon the existing ChatHTN framework that advances beyond simple memoization or caching. When the planner encounters a task for which no method is available, it queries ChatGPT to generate a specific decomposition into primitive tasks. The system then abstracts this concrete solution into a generalized HTN method using lifted operators, allowing the learned method to be applicable to multiple future instances rather than just the specific case. A critical component of this workflow is the verification mechanism: before a new method is accepted, the system simulates or logically validates the LLM's proposed action sequence against the domain model to ensure it correctly transforms the initial state to the goal state. This step filters out hallucinations and prevents invalid methods from corrupting the planning knowledge base.

Experiments conducted in Logistics Transportation and Search and Rescue domains demonstrated that the system with the online learner drastically reduced the number of calls to ChatGPT compared to the baseline planner. Specifically, the learner reduced API calls by approximately **90%** in the Logistics domain and **85%** in the Search and Rescue domain by reusing generalized methods. In terms of efficacy, the learner achieved a **100% success rate** on standard Logistics problems, significantly outperforming the baseline which suffered from variability due to repeated LLM queries. While the baseline planner occasionally failed to solve problems due to incorrect LLM outputs, the learnerâ€™s verification mechanism ensured that only valid methods were stored, leading to more robust performance in subsequent problems. However, performance notably degraded when high-level methods were missing, as the LLM struggled to generate correct, long, and complex action sequences from scratch.

This paper significantly influences the field of neuro-symbolic AI by demonstrating that integrated LLM-HTN systems can autonomously acquire and generalize planning methods with high efficiency. By reducing reliance on external APIs by over 85% while maintaining or improving planning success rates, the research presents a scalable solution for creating more adaptive intelligent agents. The shift from simple caching to the induction of generalized methods offers a robust framework for lifelong learning in planning systems. Future developments will likely focus on overcoming the current linear sequence limitations to learn methods involving compound subtasks, recursion, and iteration, further closing the gap between symbolic reasoning and neural language models.

---

## Key Findings

*   **Computational Efficiency:** The online learning procedure significantly reduces the number of API calls required to ChatGPT, increasing computational efficiency.
*   **Problem-Solving Performance:** The system maintains problem-solving performance, solving at least as many problems as the baseline, and in some cases, solving even more.
*   **Generalization:** The proposed learning approach generalizes better than standard memoization, allowing learned methods to be applied to multiple instances of a task.
*   **Dynamic Acquisition:** Integration of LLMs with Hierarchical Task Network (HTN) planning allows for the dynamic acquisition of new planning methods without pre-programming.

---

## Methodology

The researchers built an online method learner on top of the existing ChatHTN planner. The process operates as follows:

1.  **Detection:** When ChatHTN encounters a task for which there is no applicable method...
2.  **Querying:** ...it queries ChatGPT to generate a decomposition of that task into primitive tasks.
3.  **Learning:** The system then extends ChatHTN by learning from this interaction.
4.  **Generalization:** Unlike simple memoization, the proposed method analyzes the ChatGPT output to induce a generalized method, which is stored for future use.

---

## Technical Details

*   **System Architecture:** Integrates Large Language Models (specifically ChatGPT) with Hierarchical Task Network (HTN) planning. The LLM acts as a domain expert to fill gaps in the planner's knowledge base.
*   **Learning Loop:** Utilizes an online loop comprising:
    *   Detection of missing methods.
    *   Querying the LLM.
    *   Abstraction of the concrete action sequence.
    *   Generalization into a reusable HTN method (rather than simple memoization).
*   **Verification:** A verification mechanism is implemented to validate ChatGPT output before execution.
*   **Key Constraints:**
    *   Assumes lifted operators.
    *   The learning procedure generates methods composed exclusively of **linear sequences** of primitive tasks.
    *   Prevents the learning of methods with compound subtasks, recursion, or iteration.

---

## Results

*   **API Reduction:** Experiments in Logistics Transportation and Search and Rescue domains demonstrated that the system with the method learner consistently reduced the number of calls to ChatGPT compared to a baseline planner.
*   **Success Rate:** The learner achieved a higher success rate by generalizing successful interactions and reducing cumulative exposure to LLM errors.
*   **Error Handling:** Neither system achieved 100% success due to occasional incorrect LLM outputs rejected by verification.
*   **High-Level Dependency:** Performance significantly dropped when high-level methods were missing, as generating long, complex action sequences from scratch is a known weakness of LLMs.

---

## Contributions

*   **Mechanism Introduction:** Introduction of a mechanism to learn HTN methods online within an integrated LLM-HTN planning framework.
*   **Advanced Caching:** Advancement beyond simple caching techniques by implementing a learner that creates generalized, reusable methods from specific LLM-generated decompositions.
*   **Efficacy Demonstration:** Demonstration that learning from LLMs can reduce the dependency on external API calls while preserving or improving planning efficacy.