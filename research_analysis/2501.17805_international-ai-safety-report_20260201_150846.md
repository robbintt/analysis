# International AI Safety Report

*Yoshua Bengio; SÃ¶ren Mindermann; Daniel Privitera; Tamay Besiroglu; Rishi Bommasani; Stephen Casper; Yejin Choi; Philip Fox; Ben Garfinkel; Danielle Goldfarb; Hoda Heidari; Anson Ho; Sayash Kapoor; Leila Khalatbari; Shayne Longpre; Sam Manning; Vasilios Mavroudis; Mantas Mazeika; Julian Michael; Jessica Newman; Kwan Yee Ng; Chinasa T. Okolo; Deborah Raji; Girish Sastry; Elizabeth Seger; Theodora Skeadas; Tobin South; Emma Strubell; Florian TramÃ¨r; Lucia Velasco; Nicole Wheeler; Daron Acemoglu; Olubayo Adekanmbi; David Dalrymple; Thomas G. Dietterich; Edward W. Felten; Pascale Fung; Pierre-Olivier Gourinchas; Fredrik Heintz; Geoffrey Hinton; Nick Jennings; Andreas Krause; Susan Leavy; Percy Liang; Teresa Ludermir; Vidushi Marda; Helen Margetts; John McDermid; Jane Munga; Arvind Narayanan; Alondra Nelson; Clara Neppel; Alice Oh; Gopal Ramchurn; Stuart Russell; Marietje Schaake; Bernhard SchÃ¶lkopf; Dawn Song; Alvaro Soto; Lee Tiedrich; GaÃ«l Varoquaux; Andrew Yao; Ya-Qin Zhang; Fahad Albalawi; Marwan Alserkal; Olubunmi Ajala; Guillaume Avrin; Christian Busch; AndrÃ© Carlos Ponce de Leon Ferreira de Carvalho; Bronwyn Fox; Amandeep Singh Gill; Ahmet Halit Hatip; Juha HeikkilÃ¤; Gill Jolly; Ziv Katzir; Hiroaki Kitano; Antonio KrÃ¼ger; Chris Johnson; Saif M. Khan; Kyoung Mu Lee; Dominic Vincent Ligot; Oleksii Molchanovskyi; Andrea Monti; Nusu Mwamanzi; Mona Nemer; Nuria Oliver; JosÃ© RamÃ³n LÃ³pez Portillo; Balaraman Ravindran; Raquel Pezoa Rivera; Hammam Riza; Crystal Rugege; CiarÃ¡n Seoighe; Jerry Sheehan; Haroon Sheikh; Denise Wong; Yi Zeng*

---

### ðŸ“‹ Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **Total References** | 40 Citations |
| **Expert Contributors** | 96â€“100 AI Experts |
| **Participating Nations** | 30 Nations |
| **International Bodies** | UN, OECD, EU |
| **Report Chapters** | 7 Main Chapters |
| **Civil Society Reviewers** | 19 Organizations |
| **AI Lab Reviewers** | 13 Major Labs |
| **Project Timeline** | May 2024 (Interim) â†’ Feb 2025 (Full) |

---

## Executive Summary

**Problem**
The report addresses the fragmented global understanding of the capabilities, risks, and safety mechanisms associated with advanced AI systems. As general-purpose AI evolves rapidlyâ€”demonstrating accelerated progress in complex domainsâ€”there is a critical disconnect between the pace of technical research and the capacity of governments, industry, and civil society to process and act on it. This information gap impedes effective governance and prevents the alignment of international standards necessary to mitigate both immediate and catastrophic risks. The urgency of this problem is highlighted by a formal mandate from nations at the AI Safety Summit in **Bletchley, UK**, underscoring the need for a unified scientific evidence base to support high-stakes policy decisions.

**Innovation**
The key innovation is the establishment of a rigorous, consensus-based scientific synthesis model designed to isolate objective technical assessment from political agendas. The initiative was led by Chair Yoshua Bengio and Scientific Lead SÃ¶ren Mindermann, supported by a writing group of over 30 researchers. The methodology utilized a multi-stakeholder nomination process involving 30 nations and major international bodies (UN, OECD, EU) but uniquely granted the Expert Advisory Panel full discretion over the final content, ensuring scientific independence. This structure was bolstered by a review ecosystem involving 19 civil society organizations and 13 major AI labs, effectively synthesizing diverse disciplinary perspectives into a single, coherent framework.

**Results**
The report successfully aggregated evidence from a cohort of 100 experts to produce a comprehensive seven-chapter assessment delivered across two phases: an Interim Report (May 2024) and a Full Report (February 2025). Rather than presenting raw benchmark scores, the synthesis offers qualitative conclusions regarding technical progress, finding that recently released models exhibit markedly better performance in tests of programming and scientific reasoning since late 2023. The project consolidated insights from 30 participating nations and three international bodies, establishing the first global synthesis of the current state of AI capabilities and risks.

**Impact**
This report serves as a foundational framework for the emerging field of international AI governance, establishing a viable model for large-scale scientific collaboration on high-stakes technologies. By unifying disparate technical and policy viewpoints, it aids in the alignment of global understanding regarding AI safety and sets a precedent for preserving scientific independence within politically charged environments. Its significance lies in moving the discourse from theoretical speculation to evidence-based policymaking, providing the standardized grounding required for nations and international bodies to effectively evaluate and manage the risks of advanced AI systems.

---

## Key Findings

*   **First International Synthesis:** The report constitutes the first international effort to synthesize the full scope of current evidence regarding the capabilities, risks, and safety of advanced AI systems.
*   **High-Level Political Mandate:** The initiative is driven by a formal mandate from nations attending the AI Safety Summit in Bletchley, UK, signaling high-level political prioritization.
*   **Diverse Expert Cohort:** The report aggregates insights from a large cohort of 100 AI experts, ensuring a representation of diverse perspectives and disciplines.
*   **Scientific Independence:** Experts retained full discretion over the report's content, ensuring scientific independence despite being nominated by 30 nations and major international bodies.

---

## Methodology

The research utilized a robust collaborative synthesis framework to ensure objectivity and comprehensiveness:

*   **Leadership Structure:** The process was led by a Chair and an Expert Advisory Panel.
*   **Multi-Stakeholder Selection:** Panelists were selected through a nomination process involving 30 nations, the United Nations (UN), the OECD, and the EU.
*   **Separation of Powers:** The design explicitly separated political influence from technical assessment by granting the expert group full discretion over the final content.

---

## Contributions

*   **Global Reference Document:** Establishes the first International AI Safety Report, serving as a primary global reference for the current state of evidence on advanced AI.
*   **Governance Model:** Demonstrates a viable model for international scientific collaboration in AI governance, bridging the gap between technical research and global policy.
*   **Unified Perspective:** Successfully unifies diverse disciplinary perspectives into a single coherent document, aiding in the alignment of global understanding regarding AI safety.

---

## Technical Details

**Governance & Structure**
*   **Approach:** Consensus-based scientific synthesis.
*   **Leadership:**
    *   *Chair:* Prof. Yoshua Bengio
    *   *Scientific Lead:* SÃ¶ren Mindermann
*   **Personnel:** Expert panel nominated by 30 nations; writing group comprised of 30+ researchers.

**Review & Independence**
*   **Independence Measures:** Process ensured independence from government influence.
*   **Reviewers:** Multi-stakeholder review involving 19 civil society organizations and 13 major AI labs.

**Lifecycle**
*   **Phase 1:** Interim Report (May 2024)
*   **Phase 2:** Full Report (Feb 2025)

**System Architecture**
*   Specific details regarding AI model architectures are not present in the text.

---

## Results

**Qualitative Assessments**
*   **Performance Trends:** The report qualitatively observes that new models have shown "markedly better performance at tests of programming and scientific reasoning" since late 2023.

**Quantitative Metrics**
*   Specific AI experimental results, such as benchmark scores or loss values, are not included in the text.
*   Key metrics relate to the scope of the report itself (see Quick Facts above).