# Robust Machine Unlearning for Quantized Neural Networks via Adaptive Gradient Reweighting with Similar Labels

*Yujia Tong; Yuze Wang; Jingling Yuan; Chuang Hu*

---

### ðŸ“Š Quick Facts

| **Aspect** | **Details** |
| :--- | :--- |
| **Proposed Framework** | Q-MUL (Machine Unlearning for Quantized Neural Networks) |
| **Core Innovation** | Similar Labels (SL) & Adaptive Gradient Reweighting (AGR) |
| **Model Architecture** | ResNet18 (PACT & DSQ 4w4a Quantization) |
| **Key Performance** | AG of 6.00 (CIFAR-100 PACT) vs 9.26 (SalUn baseline) |
| **Quality Score** | 9/10 |

---

## Executive Summary

### **Problem**
This research addresses the conflict between deploying efficient **Quantized Neural Networks (QNNs)** on edge devices and compliance with data privacy regulations requiring "machine unlearning." Standard approximate unlearning methods fail for QNNs due to discrete optimization spaces and constrained parameter manifolds, leading to noise amplification and training destabilization. The paper identifies two specific bottlenecks: noise from label mismatch and gradient imbalance between forgotten and retained data.

### **Innovation**
The authors propose **Q-MUL**, the first dedicated unlearning framework for quantized models. It introduces:
*   **Similar Labels (SL):** Replaces random noise labels with semantically consistent alternatives to minimize noise.
*   **Adaptive Gradient Reweighting (AGR):** Dynamically aligns parameter updates from forgotten data with retained data to correct training imbalances.

### **Results**
Extensive evaluations on CIFAR-10 and CIFAR-100 demonstrated Q-MUL's superiority. On CIFAR-100 (PACT), it achieved an **Average Gap (AG) of 6.00**, significantly outperforming baselines like Random Labels (7.93) and SalUn (9.26). The method also retains high utility, with a Retain Accuracy gap of only 10.17% and robust generalization to full-precision models.

### **Impact**
Q-MUL bridges the gap between privacy compliance and resource-constrained deployment. By establishing theoretical foundations for quantized model vulnerabilities, this work enables practical "right to be forgotten" implementations on edge devices, ensuring model compression does not compromise data governance.

---

## Key Findings

*   **Ineffectiveness of Standard MU:** Existing machine unlearning methods designed for full-precision models fail on quantized neural networks due to noise amplification and gradient imbalance.
*   **Root Causes:** The study identifies two primary limitations in quantized unlearning:
    *   Noise amplification caused by label mismatch.
    *   Gradient imbalance during the training process.
*   **Discrete Optimization Challenges:** The constrained parameter space inherent to quantized models exacerbates the difficulty of implementing data privacy regulations.
*   **Theoretical Validation:** Theoretical analysis confirms that aligning parameter update contributions and using semantically consistent labels are critical to mitigating vulnerabilities during unlearning.

---

## Methodology

The paper proposes **Q-MUL**, a framework specifically engineered to handle the discrete nature of quantized models. The methodology relies on two primary mechanisms:

1.  **Similar Labels (SL) Assignment:**
    *   Replaces traditional random label assignments (used to induce forgetting) with semantically consistent alternatives.
    *   **Goal:** To minimize noise injection during data processing.

2.  **Adaptive Gradient Reweighting (AGR):**
    *   A dynamic mechanism that aligns parameter update contributions from the "forget" set with those from the "retain" set.
    *   **Goal:** To address training imbalances and stabilize the unlearning process.

The approach is underpinned by a systematic theoretical analysis of the vulnerabilities specific to quantized models.

---

## Technical Details

*   **Framework Name:** Q-MUL (Machine Unlearning for Quantized Neural Networks)
*   **Target Model:** ResNet18 backbone
*   **Quantization Techniques:**
    *   PACT (Parameterized Clipping Activation for Quantization) - 4w4a
    *   DSQ (Differentiable Soft Quantization) - 4w4a
*   **Deployment Context:** Edge devices requiring low-bit optimization.
*   **Core Components:**
    *   **Similar Labels (SL):** Reduces noise by utilizing semantic consistency.
    *   **Adaptive Gradient Reweighting (AGR):** Balances gradient contributions to prevent the degradation of model utility.

---

## Contributions

*   **Novel Framework:** Introduction of Q-MUL, the first dedicated unlearning framework specifically engineered for quantized neural networks.
*   **Problem Identification:** Formal analysis of two fundamental limitations in quantized unlearning: label mismatch noise and gradient imbalance.
*   **Algorithm Development:** Development of the Similar Labels assignment and Adaptive Gradient Reweighting mechanisms.
*   **Theoretical Foundations:** Establishment of theoretical grounding regarding quantized model vulnerabilities to validate the proposed solutions.

---

## Performance & Results

Evaluations were conducted on **CIFAR-10** and **CIFAR-100** datasets using ResNet18 (4w4a).

### Quantitative Results

| **Dataset / Config** | **Metric** | **Q-MUL** | **Random Labels** | **SalUn** |
| :--- | :--- | :--- | :--- | :--- |
| **CIFAR-100 (PACT)** | Average Gap (AG) | **6.00** | 7.93 | 9.26 |
| | Retain Accuracy (RA) Gap | 10.17% | - | - |
| **CIFAR-100 (DSQ)** | Average Gap (AG) | **8.26** | - | - |
| | Test Accuracy (TA) Gap | 1.69% | - | - |
| **Full-Precision** | Average Gap (AG) | **5.46** | - | - |

### Ablation Studies
*   **Full Model (SL + AGR):** Achieved an AG of **3.11%**.
*   **Partial Models:** Performance degraded significantly when either Similar Labels (SL) or Adaptive Gradient Reweighting (AGR) were removed, confirming the necessity of both components.

---

**Quality Score:** 9/10  
**References:** 40 citations