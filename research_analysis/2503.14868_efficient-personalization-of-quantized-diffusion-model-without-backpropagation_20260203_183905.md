---
title: Efficient Personalization of Quantized Diffusion Model without Backpropagation
arxiv_id: '2503.14868'
source_url: https://arxiv.org/abs/2503.14868
generated_at: '2026-02-03T18:39:05'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Efficient Personalization of Quantized Diffusion Model without Backpropagation

*Hoigi Seo; Wongi Jeong; Kyungryeol Lee; Se Young Chun*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Method Name** | ZOODiP |
| **Core Technique** | Zeroth-Order Optimization + Subspace Gradient |
| **Memory Efficiency** | **8.2Ã—** reduction vs. DreamBooth |
| **VRAM Usage** | ~0.5 GB (vs. DreamBooth's 2.37 GB) |
| **Speed (n=1)** | 20.7 (vs. GF-TI's 4.94) |
| **Key Advantage** | Backpropagation-free training on quantized models |

---

## Executive Summary

Personalizing large-scale diffusion models, such as Stable Diffusion, typically requires fine-tuning techniques like DreamBooth or Textual Inversion. These methods rely on backpropagation to compute gradients, necessitating the storage of significant intermediate activations and optimizer states. This creates a substantial memory bottleneck that prohibits deployment on resource-constrained edge devices. While quantization offers a solution for reducing inference memory footprint, it generally complicates or prevents standard gradient-based training, as differentiating through discrete low-bit operators requires dequantization, which negates memory savings.

The authors introduce **ZOODiP**, a backpropagation-free framework designed to personalize quantized diffusion models using zeroth-order (ZO) optimization. Instead of calculating exact gradients via backpropagation, ZOODiP approximates gradients using only forward passes, thereby eliminating the need to store activations for backward computation. To address the inherent noise and instability of ZO optimization in few-shot scenarios, the paper proposes **"Subspace Gradient" (SG)**, a technique that projects noisy gradient estimates onto a lower-dimensional subspace constructed from the history of token updates. Additionally, the method employs **"Partial Uniform Timestep Sampling" (PUTS)** to strategically select effective diffusion timesteps, further stabilizing the training of pseudo-tokens within the quantized model.

ZOODiP demonstrates significant efficiency improvements while maintaining competitive generation quality. The method reduces training memory demand by up to **8.2Ã—** compared to DreamBooth, requiring approximately **0.5 GB of VRAM** versus DreamBooth's **2.37 GB**. In terms of speed, ZOODiP significantly outperforms GF-TI, achieving a speed metric of **20.7 (n=1)** compared to GF-TI's 4.94. Regarding output fidelity, the model achieves comparable CLIP-Text and CLIP-Image alignment scores to prior state-of-the-art methods. Ablation studies confirm that the combination of Subspace Gradient and PUTS is essential, yielding the best performance with a CLIP-I score of 0.759.

This research represents a critical step toward enabling on-device personalization of generative AI models. By removing the dependency on backpropagation and gradient storage, ZOODiP allows for the fine-tuning of diffusion models on consumer-grade hardware and edge devices without sacrificing the memory benefits of quantization. This capability facilitates privacy-preserving, local customization of AI models, opening new possibilities for mobile applications and embedded systems that require high-quality image generation without reliance on cloud-based computing resources.

---

## Key Findings

*   **Performance Parity:** Achieves comparable performance in image and text alignment scores to prior personalization methods using only forward passes.
*   **Memory Efficiency:** Training memory demand is reduced by up to **8.2Ã—**.
*   **Quantization Compatibility:** Successfully personalizes Stable Diffusion models without requiring dequantization or backpropagation.
*   **Noise Handling:** Zeroth-order optimization, when paired with the proposed subspace projection, effectively handles the noise limitations inherent in training with a single or few images.

---

## Methodology

The proposed method operates through a distinct pipeline designed to minimize memory overhead while maximizing personalization capabilities:

*   **Quantized Base Model:** Utilizes a quantized diffusion model personalized via Textual Inversion without dequantization to maintain a low memory footprint.
*   **Zeroth-Order Optimization:** Leverages zeroth-order optimization on personalization tokens instead of traditional gradient-based algorithms to eliminate the need to store gradients and activations.
*   **Gradient Denoising:** Addresses noise in gradient estimation by projecting it onto a subspace constructed from the history of token updates.
*   **Timestep Strategy:** Implements a **Partial Uniform Timestep Sampling (PUTS)** strategy to select effective diffusion timesteps, ensuring efficient training.

---

## Technical Details

**Method Name:** ZOODiP

**Core Mechanism:**
*   Utilizes **Zeroth-Order (ZO) optimization** to personalize diffusion models through forward passes without backpropagation or dequantization.
*   Optimizes token embeddings (pseudo-tokens) within a quantized Stable Diffusion model.

**Key Components:**
1.  **Subspace Gradient (SG):** Projects out noisy gradient dimensions based on parameter trajectory using history data.
2.  **Partial Uniform Timestep Sampling (PUTS):** Samples only within effective timestep sections to improve stability.

**Objective:**
*   Minimize the difference between generated and reference images while aligning with text prompts on memory-constrained devices.

**Implementation:**
*   Profiling conducted using PyTorch profiler and `nvidia-smi`.
*   Hyperparameters $\tau$ and $\nu$ control trajectory-based projection.

---

## Performance Results

**Memory Usage:**
*   **ZOODiP:** ~0.5 GB VRAM
*   **DreamBooth:** 2.37 GB VRAM
*   **Reduction:** 8.2Ã—

**Training Speed:**
*   **ZOODiP (n=1):** 20.7
*   **ZOODiP (n=2):** 16.1
*   **GF-TI:** 4.94
*   *Note: Higher is better.*

**Alignment & Quality:**
*   Achieves comparable CLIP-Text and CLIP-Image scores to DreamBooth and Textual Inversion.

**Ablation Studies:**
*   The full method (**SG + PUTS**) achieved the best performance:
    *   **CLIP-I:** 0.759
    *   **DINO:** 0.569
*   **Optimal Hyperparameters:** $\tau=128, \nu=10^{-3}$ yielded a CLIP-I score of 0.759.

---

## Core Contributions

*   **Memory-Efficient Fine-Tuning:** Addresses the critical bottleneck of memory usage for edge device applications.
*   **Backpropagation-Free Framework:** Removes the dependency on backpropagation and gradient storage during fine-tuning.
*   **Subspace Gradient Technique:** Stabilizes zeroth-order optimization for few-shot personalization tasks by utilizing historical token data.

---

*Document Quality Score: 8/10 | References: 40 citations*