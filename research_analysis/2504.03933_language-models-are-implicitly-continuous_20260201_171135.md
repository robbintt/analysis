# Language Models Are Implicitly Continuous

*Samuele Marro; Davide Evangelista; X. Angelo Huang; Emanuele La Malfa; Michele Lombardi; Michael Wooldridge*

---

> ### ‚ö° Quick Facts
> *   **Quality Score:** 9/10
> *   **Total Citations:** 40
> *   **Models Analyzed:** Llama2, Llama3, Phi-3, Gemma, Gemma2, Mistral
> *   **Key Innovation:** Continuous Causal Transformer (CCT) Framework
> *   **Core Implication:** LLMs process language as continuous functions, differing fundamentally from discrete human reasoning.

---

## üìë Executive Summary

This paper addresses the fundamental discrepancy between the **discrete nature of language tokens** and the **continuous mathematical operations** of Large Language Models (LLMs). While LLMs are trained on discrete symbols, the authors investigate whether the underlying computation is strictly symbolic or if it behaves as a continuous function approximator. This distinction is critical for mechanistic interpretability, as it determines whether researchers should view models as manipulating discrete symbols or performing geometric operations in a latent continuous space.

The key innovation is the **Continuous Causal Transformer (CCT)**, a formal framework that generalizes the standard Transformer architecture to operate over continuous time and space domains without requiring modifications to pre-trained weights. Technically, CCT models discrete inputs as stepwise constant functions defined over specific time intervals, replacing the standard discrete attention summation with a continuous integral mechanism. The framework introduces a duration parameter ($d_s$) to control time continuity and allows processing at non-integer time-steps, effectively decoupling the model's processing rate from the discrete token sequence. Additionally, CCT supports "Space Continuity," which processes linearly interpolated vector embeddings (at varying magnitudes $\alpha \in [0,1]$) between standard vocabulary points, treating the discrete vocabulary as a discretization of a latent continuous manifold.

**Quantitative Results:**
Experiments applied the CCT framework to prominent models including Llama2-13B, Llama3-8B, Phi-3-Medium, Gemma (1 & 2), and Mistral-7B. To measure "Implicit Continuity," the authors tracked Perplexity (PPL) degradation and Kullback-Leibler (KL) Divergence.
*   **Time Continuity:** Perplexity remained bounded and degraded smoothly rather than abruptly as the duration parameter expanded.
*   **Space Continuity:** Linear interpolation of embeddings yielded KL divergence values significantly **below 0.1 nats** (orders of magnitude lower than random baselines which exceeded 5.0 nats), confirming that interpolated inputs produce coherent semantic shifts.

These findings signify a paradigm shift, suggesting that top-tier LLMs function as **universal approximators of continuous functions** rather than discrete symbolic engines. This challenges the traditional alignment of model processing with human-like discrete language handling. For engineering and safety, this provides a critical new lens for analyzing adversarial robustness, revealing that model outputs can be manipulated smoothly through continuous perturbations.

---

## üîë Key Findings

*   **Implicit Continuous Representation:** Transformer-based language models implicitly learn to represent sentences as continuous-time functions over a continuous input space.
*   **Universal Phenomenon:** This phenomenon of implicit continuity is present in most state-of-the-art LLMs, including **Llama2, Llama3, Phi3, Gemma, Gemma2, and Mistral**.
*   **Divergence from Human Reasoning:** The way LLMs process language fundamentally differs from human reasoning, which typically treats language as discrete.
*   **Challenge to Discrete Interpretation:** The results challenge the traditional interpretation that LLMs understand language through discrete mechanisms, suggesting a continuous underlying mechanism instead.

---

## üõ†Ô∏è Methodology

The authors formally extended the Transformer architecture to capture and model the nuances of time and space continuity in both input and output spaces. This theoretical extension facilitated the analysis of how existing models implicitly represent data without requiring the modification of pre-trained weights.

---

## üìä Contributions

| **Area** | **Description** |
| :--- | :--- |
| **Formal Architectural Extension** | Provided a formal extension of the Transformer framework that accounts for time and space continuity. |
| **Empirical Generalization** | Demonstrated that the implicit learning of continuous functions is a universal characteristic across a wide range of top-tier LLMs. |
| **Paradigm Shift in Interpretation** | Challenged the standard discrete understanding of language processing, proposing that models "reason" differently from human cognition. |
| **Cross-Disciplinary Implications** | Highlighted significant implications for linguistics and engineering. |

---

## ‚öôÔ∏è Technical Details: The Continuous Causal Transformer (CCT)

The paper proposes the **CCT framework**, which generalizes discrete Transformers to handle continuous inputs.

### Core Concepts
*   **Underlying Function:** Models language as a discretization of an underlying continuous function **x(t)**.
*   **Input Representation:** Treats inputs as stepwise constant functions with defined time intervals and a continuous duration variable (**$d_s$**).
*   **Continuous Attention:** Replaces discrete summation with integrals to allow for continuous processing.

### Architecture Features
1.  **Time Continuity:**
    *   Introduction of a duration parameter ($d_s$).
    *   Supports non-integer time-step processing.
    *   Decouples processing rate from the discrete token sequence.

2.  **Space Continuity:**
    *   Allows the processing of interpolated vectors outside the discrete vocabulary.
    *   Treats the vocabulary as a discretization of a latent continuous manifold.

---

## üß™ Experimental Results

Experiments applying CCT to major models revealed **'implicit continuity'**, demonstrating that these models successfully process inputs varying in time and space continuity despite being trained on discrete data.

*   **Duration Dependency:** Model outputs are strongly dependent on the duration parameter.
*   **Coherent Semantics:** Interpolated embeddings yield distinct, coherent semantic meanings.
*   **Conclusion:** Results suggest LLMs rely on continuous function approximation rather than discrete symbolic manipulation.