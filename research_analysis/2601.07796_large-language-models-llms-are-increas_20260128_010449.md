---
title: Large language models (LLMs) are increas-
arxiv_id: '2601.07796'
source_url: https://arxiv.org/abs/2601.07796
generated_at: '2026-01-28T01:04:49'
quality_score: 9
citation_count: 5
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Large language models (LLMs) are increas-

*Trusted Internet, Political Issues, New Media, Kokil Jaidka, National University, Shaz Furniturewala, Learning Through, Gerard Christopher*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Dataset Size** | 397 Human-LLM Conversations |
| **Methodology** | Mediation & Moderation Analysis |
| **Platform** | Arthos (Experimental Chatbot) |
| **Domain** | Socio-political Issues |
| **Quality Score** | 9/10 |

---

## Executive Summary

This research addresses a critical gap in understanding how Large Language Models (LLMs) facilitate learning in complex, subjective domains like socio-political issues. It challenges the standard assumption that high-quality LLM explanations automatically result in user comprehension. Instead, the authors distinguish between the mere transmission of information and the actual psychological acquisition of knowledge versus confidence, investigating how specific internal mechanisms and user traits drive these outcomes.

The studyâ€™s key innovation is reframing AI-assisted learning as a dynamic **"interactional achievement"** rather than a static information transfer. Technically, the researchers utilized "Arthos," an experimental chatbot, to capture and analyze 397 human-LLM conversations. They employed a rigorous statistical framework combining mediation and moderation analysis to map causal pathways. This approach empirically separated the impact of LLM explanatory richness on distinct user statesâ€”cognitive engagement and reflective insightâ€”while modeling how user traits, specifically political efficacy, moderate these effects.

The analysis revealed distinct psychological pathways for different learning outcomes. While LLM explanatory richness drives user confidence, this relationship is only "partially" mediated by reflective insight. In contrast, knowledge gains are found to be "entirely" mediated by cognitive engagement. Furthermore, political efficacy served as a critical boundary condition; learning benefits were concentrated among high-efficacy users. These findings necessitate a design paradigm shift: future AI educational tools must adapt explanatory behavior in real-time to align with the user's engagement state and capacity to manage uncertainty.

---

## Key Findings

*   **Distinct Learning Pathways:** LLM explanatory richness impacts confidence and knowledge differently; it supports confidence partially by fostering reflective insight, whereas its effect on knowledge gain operates entirely through cognitive engagement.
*   **Role of Political Efficacy:** The learning benefits of LLM interactions are not uniform but are highly conditional on the user's political efficacy, specifically impacting high-efficacy users more significantly.
*   **Mechanisms of Confidence:** Confidence gains are driven by high-efficacy users' ability to experience and actively resolve uncertainty during the conversation.
*   **Mechanisms of Knowledge:** Knowledge gains are dependent on high-efficacy users leveraging extended interactions, with longer conversations providing the most benefit to reflective users.
*   **Interaction vs. Quality:** Effective learning is identified as an "interactional achievement" resulting from the dynamic between user and model, rather than a guaranteed outcome of high-quality LLM explanations alone.

---

## Methodology

The study analyzed **397 human-LLM conversations** centered on socio-political issues. Researchers examined linguistic and interactional features from both the LLM and human participants to characterize the dialogue dynamics.

To understand the underlying mechanics, the study employed:
*   **Mediation Analysis:** To uncover the mechanisms (reflective insight, cognitive engagement) linking features to outcomes.
*   **Moderation Analysis:** To assess how these effects vary based on user traits (specifically political efficacy) and interaction length.

---

## Technical Details

*   **System Architecture:**
    *   **Arthos:** An experimental chatbot system designed to elicit extended political dialogue and measure explanation quality, user engagement, and learning outcomes.
*   **Data Source:**
    *   A dataset of 397 human-LLM conversations on socio-political issues, linking dialogue logs to demographics and learning outcomes.
*   **Statistical Framework:**
    *   Multivariate analysis utilizing mediation and moderation strategies.
*   **Key Variables Analyzed:**
    *   **LLM Feature:** Explanatory Richness.
    *   **User States:** Cognitive engagement, reflective insight, uncertainty resolution.
    *   **User Trait:** Political efficacy.

---

## Results

Mediation analysis indicates that LLM explanatory richness **partially affects user confidence** through reflective insight, while knowledge gains are **entirely mediated** by cognitive engagement.

Moderation analysis reveals that learning benefits depend on political efficacy:
*   **High-efficacy users** gain confidence by resolving uncertainty.
*   **High-efficacy users** gain knowledge through extended interactions (longer conversations), particularly benefiting reflective users within this group.

The study concludes that learning is an 'interactional achievement' resulting from the dynamic between user and model.

---

## Contributions

*   **Theoretical Reframing:** Shifts the understanding of AI-assisted learning from a static transmission of information to a dynamic "interactional achievement" requiring specific user behaviors.
*   **Mechanistic Insight:** Provides empirical evidence separating the psychological drivers of knowledge gain (cognitive engagement) from confidence gain (reflective insight) in AI-mediated learning.
*   **Identification of Boundary Conditions:** Highlights that the effectiveness of LLM explanations is bound by user-specific factors, such as political efficacy and the capacity to manage uncertainty.
*   **Design Implications for Human-AI Systems:** Underscores the necessity of designing AI interactive systems that adapt LLM explanatory behavior to align with the user's current engagement state to maximize learning efficacy.

---

**References:** 5 citations
**Quality Score:** 9/10