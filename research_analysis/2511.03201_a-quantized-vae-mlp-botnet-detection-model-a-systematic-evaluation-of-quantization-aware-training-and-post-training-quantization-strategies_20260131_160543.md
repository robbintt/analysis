# A Quantized VAE-MLP Botnet Detection Model: A Systematic Evaluation of Quantization-Aware Training and Post-Training Quantization Strategies

*Hassan Wasswa; Hussein Abbass; Timothy Lynar*

---

### üìã Quick Facts

| Metric | Baseline | PTQ (Post-Training) | QAT (Quantization-Aware) |
| :--- | :--- | :--- | :--- |
| **Inference Speedup** | 1x | **6x** (~4¬µs) | 2.35x (~10¬µs) |
| **Model Size Reduction** | 0.43 MB | 21x (0.021 MB) | **24x** (0.017 MB) |
| **Accuracy (CICIoT2022)** | 0.9980 | **0.9971** | 0.9683 |
| **Accuracy (N-BaIoT)** | 0.9853 | **0.9853** | Not specified (F1: 0.9233) |
| **Best For** | General Use | **Speed + Accuracy Balance** | Storage Optimization |

---

## üìë Executive Summary

The rapid proliferation of Internet of Things (IoT) devices has significantly expanded the attack surface for botnets, creating an urgent need for robust detection mechanisms capable of operating directly on the edge. However, deploying effective Deep Learning (DL) based detection on resource-constrained IoT hardware presents a formidable challenge; standard models typically possess high computational complexity and large memory footprints that exceed the capabilities of embedded systems.

This research addresses the critical trade-off between maintaining high detection accuracy and achieving the storage and inference efficiency required for real-time operation on these low-power devices. The authors introduce a lightweight hybrid framework combining a Variational Autoencoder (VAE) with a Multilayer Perceptron (MLP).

**Core Technical Approach:**
The system utilizes a VAE to compress high-dimensional network traffic‚Äîextracted via CICFlowMeter into 84-feature vectors‚Äîdown to compact 8-dimensional latent representations, which are then classified by the MLP. The study systematically evaluates two optimization strategies: Quantization-Aware Training (QAT) and Post-Training Quantization (PTQ), validated against the N-BaIoT and CICIoT2022 datasets.

**Conclusion:**
Experimental results demonstrate that **PTQ consistently outperforms QAT** in preserving detection accuracy while delivering superior inference speeds. On the larger CICIoT2022 dataset, PTQ suffered negligible accuracy loss, while QAT resulted in a substantial decline. The findings clearly delineate the trade-offs: PTQ enables a 6x increase in inference speed without sacrificing detection accuracy (ideal for real-time threat response), while QAT offers the greatest storage efficiency at the cost of performance. This work establishes the feasibility of sophisticated, real-time anomaly detection on low-power IoT hardware.

---

## üîë Key Findings

*   **Accuracy Retention:** Post-Training Quantization (PTQ) maintained detection accuracy significantly better than Quantization-Aware Training (QAT). PTQ incurred only a marginal accuracy reduction, whereas QAT resulted in a noticeable decline.
*   **Performance Gains (PTQ):** PTQ achieved a **6x inference speedup** (~4¬µs) and a **21x reduction** in model size compared to the unquantized baseline.
*   **Performance Gains (QAT):** QAT achieved a 3x speedup and a **24x size reduction**, offering the smallest footprint but at the cost of detection accuracy.
*   **IoT Feasibility:** Quantization is demonstrated to be a practical solution for deploying botnet detection models on resource-constrained IoT devices, facilitating decentralized security architectures.

---

## üõ†Ô∏è Methodology

The study proposes a **VAE-MLP framework** designed to optimize efficiency without sacrificing security. The process involves the following steps:

1.  **Data Preprocessing:** Network traffic (.pcap files) is converted into NetFlow instances. Feature extraction is performed using CICFlowMeter, generating an **84-feature vector** for each instance.
2.  **Dimensionality Reduction:** A Variational Autoencoder (VAE) pre-encodes the high-dimensional 84-feature data into compact **8-dimensional latent vectors**.
3.  **Classification:** A Multilayer Perceptron (MLP) classifier processes the latent vectors to detect botnet traffic.
4.  **Evaluation:** Two compression strategies were compared:
    *   **Quantization-Aware Training (QAT):** The model learns to accommodate quantization errors during the training phase.
    *   **Post-Training Quantization (PTQ):** A pre-trained model is quantized after the training process is complete.
5.  **Metrics:** Models were assessed based on detection performance (Accuracy, F1-Score), storage efficiency (Model Size), and inference latency.

---

## ‚öôÔ∏è Technical Details

*   **System Architecture:** Hybrid model combining a Variational Autoencoder (VAE) for feature compression/anomaly detection and a Multilayer Perceptron (MLP) for classification.
*   **Input Data:** 84-feature vectors extracted via CICFlowMeter.
*   **Bottleneck:** Data compressed to 8-dimensional latent vectors.
*   **Datasets:**
    *   **N-BaIoT:** IoT botnet traffic data.
    *   **CICIoT2022:** Large-scale dataset containing over 3.2 million NetFlow instances.
*   **Strategies Evaluated:**
    *   QAT (Quantization-Aware Training)
    *   PTQ (Post-Training Quantization)

---

## üìä Results

### Detection Performance
*   **N-BaIoT Dataset:**
    *   **PTQ:** Matched the unquantized baseline accuracy (**0.9853**) with a high F1-score (**0.9297**).
    *   **QAT:** Showed slight degradation with an F1-score of **0.9233**.
*   **CICIoT2022 Dataset:**
    *   **Baseline:** Accuracy 0.9980; F1 0.9941.
    *   **PTQ:** Negligible performance loss. Accuracy **0.9971**; F1 **0.9948**.
    *   **QAT:** Significant accuracy drop to **0.9683**.

### Latency and Storage Efficiency
*   **Inference Latency:**
    *   **Baseline:** ~23.8¬µs
    *   **PTQ:** ~4¬µs (**~6x speedup**)
    *   **QAT:** ~10¬µs (**~2.35x speedup**)
*   **Model Size:**
    *   **Baseline:** ~0.43 MB
    *   **Compressed:** ~0.017‚Äì0.021 MB (**20‚Äì25x reduction**)

---

## üìù Contributions

*   **Lightweight Architecture:** Introduction of a lightweight VAE-MLP model designed to reduce dimensionality to 8-dimensional vectors for efficient classification on IoT devices.
*   **Systematic Analysis:** A comprehensive comparative analysis of QAT versus PTQ trade-offs specifically within the context of IoT botnet detection.
*   **Empirical Feasibility Data:** Provision of empirical data quantifying compression benefits (up to 24x size reduction and 6x speedup) to establish the feasibility of deep learning-based anomaly detection on edge hardware.