---
title: 'LLM as an Algorithmist: Enhancing Anomaly Detectors via Programmatic Synthesis'
arxiv_id: '2510.03904'
source_url: https://arxiv.org/abs/2510.03904
generated_at: '2026-01-28T00:11:58'
quality_score: 9
citation_count: 12
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LLM as an Algorithmist: Enhancing Anomaly Detectors via Programmatic Synthesis

*Dandan Guo, Monash University, Hongyuan Zha, Jilin University, Jinmeng Li, He Zhao, Mingchen Zhuge, Yi Chang, Artificial Intelligence, Hangting Ye*

---

### ðŸ“Š Quick Facts

| Metric | Details |
| :--- | :--- |
| **Framework Name** | LLM-DAS (LLM-Guided Detector-Aware Anomaly Synthesis) |
| **Benchmarks Used** | 36 Tabular Datasets (ODDS and ADBench) |
| **Top Performance Gain** | **84.49%** relative increase in AUC-PR for OCSVM |
| **Source Detectors Enhanced** | PCA, IForest, OCSVM, ECOD, DRL |
| **Core Innovation** | Programmatic Synthesis (LLM as "Algorithmist") |
| **Privacy Rating** | **High** (LLM generates code, not processes raw data) |
| **Compute Efficiency** | Low (10% synthesis ratio; uses API + RTX 4090) |

---

## Executive Summary

Traditional anomaly detection models often suffer from **"logical blind spots"**â€”inherent weaknesses in their algorithms that prevent them from identifying subtle or complex anomalies, particularly in heterogeneous tabular data. While Large Language Models (LLMs) offer advanced reasoning capabilities, directly deploying them to process raw data introduces significant **privacy risks** and **high computational costs**.

This paper introduces **LLM-DAS**, a novel framework that repurposes the LLM as an *"algorithmist"* rather than a data processor. Through a programmatic synthesis approach, the LLM analyzes the logical vulnerabilities of specific source detectors and generates executable Python code to synthesize "hard" anomaly samples tailored to those weaknesses. This two-stage pipeline ensures raw data never leaves the local environment, transforming the task from a one-class to a two-class binary classification problem.

In evaluations across 36 benchmarks, LLM-DAS consistently enhanced performance, notably achieving an **84.49% relative increase** in AUC-PR for One-Class SVM. The framework bridges LLM reasoning with classic anomaly detection in a privacy-preserving, scalable manner, positioning LLMs as meta-designers that enhance algorithmic performance through programmatic logic rather than direct data processing.

---

## Methodology

The research introduces **LLM-DAS**, utilizing a **Programmatic Synthesis** approach. This represents a paradigm shift in how LLMs interact with security data:

*   **Role Reassignment:** The LLM acts as an **algorithm designer** (algorithmist) rather than a data processor.
*   **Objective:** To analyze detector vulnerabilities and generate detector-specific Python code.
*   **Process:** The generated code is used to synthesize anomaly samples, which are then used for data augmentation to improve the detector's discriminative power.

---

## Technical Details

### Core Architecture: LLM-DAS
The framework shifts the LLM's role to reason about high-level logic, ensuring **privacy** and **reusability**. It transforms the problem definition:
*   **From:** One-class classification
*   **To:** Two-class binary classification (by patching 'logical blind spots' with synthetic 'hard' anomalies)

### The Two-Stage Pipeline

#### Stage 1: Detector-Aware Code Generation
The LLM generates executable Python code tailored to specific detector types.
*   **Inputs:**
    *   Prompts containing detector descriptions.
    *   Objective specifications utilizing symbolic interfaces.
    *   Generation requirements.
*   **Output:** Custom code designed to exploit specific weaknesses in the target detector.

#### Stage 2: Anomaly Instantiation & Training
The generated code is executed locally to enhance the dataset.
*   **Execution:** The code runs on training data to create synthetic anomalies.
*   **Augmentation:** The original dataset is augmented with these "hard" samples.
*   **Training:** An enhanced binary classifier (default: **RandomForest**) is trained on the augmented data.

---

## Key Findings

*   **Consistent Enhancement:** The framework improved performance on **36 Tabular Anomaly Detection benchmarks**.
*   **Blind Spot Patching:** Effectively patches logical blind spots by generating hard-to-detect anomalies that source detectors would otherwise miss.
*   **Privacy Preservation:** Ensures data privacy by leveraging LLMs as algorithm designers rather than data processors (raw data is never sent to the LLM).
*   **Task Transformation:** Successfully transforms the anomaly detection task into a more robust two-class classification task.
*   **Heterogeneity Mitigation:** Effectively mitigates issues caused by data heterogeneity.

---

## Contributions

*   **Novel Framework:** Introduces the **LLM-DAS** framework, bridging the gap between LLM reasoning capabilities and classic anomaly detection algorithms.
*   **Privacy-Safe Architecture:** Proposes an architecture that strictly prevents LLM access to raw data, addressing a major bottleneck in security-sensitive applications.
*   **Generalizable Strategy:** Develops a universal strategy for patching logical blind spots in existing detectors across diverse datasets and detector types.

---

## Results

Experiments conducted on **36 tabular datasets** (ODDS and ADBench) demonstrated the robustness of the LLM-DAS framework:

*   **Source Detector Improvement:** LLM-DAS consistently enhanced source detectors (**PCA, IForest, OCSVM, ECOD, DRL**) in both **AUC-PR** and **AUC-ROC** metrics.
*   **OCSVM Breakthrough:**
    *   Achieved an **absolute AUC-PR improvement of 0.0723**.
    *   Represents an **84.49% relative increase**.
    *   Gains observed on **25 out of 36** datasets.
*   **Statistical Significance:** The improvements were statistically significant with **p < 0.05**.
*   **Benchmark Superiority:** Outperformed specialized models (AnoLLM-135M, AnoLLM-360M) and traditional baselines (DeepSVDD, AutoEncoder, LOF, KNN).
*   **Efficiency:** Achieved superior results with lower computational costs (using Gemini-2.5-Pro API and RTX 4090 at a 10% synthesis ratio).

---

**Quality Score:** 9/10
**References:** 12 citations