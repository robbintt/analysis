---
title: LLM training jobs
arxiv_id: '2505.00342'
source_url: https://arxiv.org/abs/2505.00342
generated_at: '2026-01-27T21:30:10'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LLM training jobs

*Yujie Huang, Rui Ren, Zhihan Jiang, Guangba Yu, Yulun Wu, Wenwei Gu, Yichen Li, Cong Feng*

***

### ðŸ“‘ Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 40 Citations |
| **Target System** | Platform-X (Production) |
| **Scale Analyzed** | 2,880 GPUs |
| **Identification Speed** | < 1 Minute |
| **PP Pair Accuracy** | 100% Precision & Recall |

***

## Executive Summary

Managing large-scale LLM training clusters presents a critical operational challenge: platform operators lack visibility into how logical jobs map to physical hardware resources. Current systems provide "black-box" opacity, meaning operators cannot understand internal execution states or reconstruct the logical topology of distributed workloads. This hinders the ability to diagnose performance bottlenecks or utilize resources efficiently, leading to significant wasted compute costs in environments where every GPU-hour is expensive.

**LLMPrism** addresses this by providing "white-box" visibility through non-intrusive network telemetry analysis that reverse-engineers job structures. The system employs a Disjoint-set data structure (Union-Find) with topology-aware merging using Jaccard Similarity to cluster GPUs into distinct jobs. Crucially, it utilizes **Bayesian Online Change-point Detection (BOCD)** for precise temporal step division, allowing it to partition communication timelines and distinguish between Data Parallelism (synchronized bursts) and Pipeline Parallelism (stable flows).

Evaluated on **Platform-X**, a production environment with 2,880 GPUs, LLMPrism demonstrated high accuracy and operational efficiency. It achieved **100% precision and recall** in identifying Pipeline Parallelism pairs, proving that coarse-grained network data is sufficient for fine-grained inference. The system is capable of identifying newly launched jobs and reconstructing their execution timelines within a one-minute window. By leveraging efficient linear-time algorithms for step division, LLMPrism maintains negligible diagnostic overhead, ensuring monitoring does not compete with training tasks.

## Key Findings

*   **High-Precision Identification:** The system achieved **100% accuracy and recall** in identifying Pipeline Parallelism (PP) pairs in a live production environment.
*   **Operational Agility:** Job identification is rapid, with the system operating within a **one-minute time window**, allowing for near real-time monitoring.
*   **Observability Without Intrusion:** LLMPrism successfully bridges the observability gap without requiring changes to underlying training frameworks or modifying application code.
*   **Cost Efficiency:** The approach uses efficient linear-time algorithms for step division, ensuring that the diagnostic process does not compete with training tasks for compute resources.

## Technical Details

The core of **LLMPrism** is its ability to provide white-box visibility into black-box platforms using network telemetry. The technical architecture relies on several specific algorithms and data structures:

### Core Architecture
*   **Data Structure:** Utilizes a **Disjoint-set data structure (Union-Find)** for managing GPU clusters.
*   **Clustering Method:** Implements topology-aware merging using **Jaccard Similarity** for efficient GPU clustering and job recognition.

### Parallelism Strategy Identification
The system distinguishes between different parallelism strategies through a multi-step process:
1.  **Temporal Partitioning:** Uses **Bayesian Online Change-point Detection (BOCD)** to partition communication timelines into steps.
2.  **Differentiation:** Uses distinct flow size counting to distinguish between:
    *   **Data Parallelism (DP):** Identified by synchronized bursts.
    *   **Pipeline Parallelism (PP):** Identified by stable flows.
3.  **Refinement:** Employs graph-based **Depth-First Search (DFS)** to refine the inferences.

### Configuration
*   **BOCD Threshold:** Set at **0.95**.
*   **Algorithmic Complexity:** Utilizes an efficient linear-time algorithm for step division to minimize overhead.
*   **Reconstruction:** Training Timeline Reconstruction is achieved by applying BOCD to intervals between DP communication flows.

## Evaluation Results

The system was rigorously evaluated on **Platform-X**, a large-scale production environment containing **2,880 GPUs**. The evaluation confirmed that the system is capable of handling large-scale data while maintaining high performance standards:

*   **Accuracy:** 100% accuracy in identifying PP pairs.
*   **Recall:** 100% recall in identifying PP pairs.
*   **Latency:** Identification and reconstruction completed within one minute.
*   **Overhead:** Negligible performance impact on the training jobs due to the use of linear-time algorithms.