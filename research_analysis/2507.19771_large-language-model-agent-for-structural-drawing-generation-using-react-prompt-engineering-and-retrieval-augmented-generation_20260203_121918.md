---
title: Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt
  Engineering and Retrieval Augmented Generation
arxiv_id: '2507.19771'
source_url: https://arxiv.org/abs/2507.19771
generated_at: '2026-02-03T12:19:18'
quality_score: 7
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation

*Xin Zhang; Lissette Iturburu; Juan Nicolas Villamizar; Xiaoyu Liu; Manuel Salmeron; Shirley J. Dyke; Julio Ramirez*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 7/10 |
| **References** | 40 Citations |
| **Core Technology** | LLM Agent, ReAct Prompting, RAG |
| **Target Software** | AutoCAD (via `pyautocad`, `win32com`) |
| **Key Constraint** | GPT-4 Turbo 4096 token limit |

---

## Executive Summary

**Problem**
Structural drawing generation in civil and mechanical engineering remains a predominantly manual, labor-intensive process that creates a bottleneck between conceptual design and final documentation. Engineers must translate high-level design intent into rigid, standardized technical drawings within environments like AutoCAD, a task that is repetitive and prone to human error. This paper addresses the critical need to automate this translation, aiming to reduce the substantial time and effort required for drafting while enabling a more seamless iterative design process.

**Innovation**
The authors introduce a specialized LLM agent that utilizes a multi-stage generative architecture (LLM1 through LLM6) based on ReAct prompt engineering to decompose the drawing process into specific sub-tasks: classification, information extraction, missing data identification, workspace settings, JSON structuring, and Python code generation. A key technical innovation is the integration of Retrieval-Augmented Generation (RAG), which queries external databases to inject domain-specific facts, such as standardized steel beam sections, directly into the generation process. The system executes this generated code using Python libraries `pyautocad` and `win32com` to interface directly with AutoCAD, ensuring that natural language inputs are converted into precise, executable technical drawings while managing output constraints through logic that splits complex tasks into sequential sub-steps.

**Results**
Validation through case studies demonstrated the system's ability to accurately translate varied natural language descriptions into executable Python code without manual drafting. The agent successfully handled complex geometric calculations, including determining vertices for concrete beam hooks and radii, and accurately retrieved standardized sections such as 'HP360x174' from external databases. The integration of RAG was shown to significantly enhance reliability by mitigating hallucinations compared to standard LLM outputs. Furthermore, the system proved robust against technical constraints, effectively navigating GPT-4 Turboâ€™s 4096-token output limit by implementing task fragmentation to ensure the generation of complete drawings.

**Impact**
This research bridges the gap between conceptual natural language descriptions and standardized technical documentation, setting a precedent for hybrid AI in safety-critical engineering domains. By demonstrating that LLM agents can reliably generate code for engineering applications when augmented with external knowledge, the paper validates a novel approach to automating technical workflows. This shift toward intent-based modeling promises substantial reductions in manual workload and facilitates rapid design iteration, marking a significant evolution in how engineers interact with design software by freeing professionals to focus on higher-level decision-making.

---

## Key Findings

*   **Effective Translation of Natural Language to Code:** The LLM agent successfully understands varied natural language descriptions and converts them into executable code for AutoCAD, generating structural drawings without manual drafting.
*   **Enhanced Accuracy via RAG:** The integration of Retrieval-Augmented Generation (RAG) utilizing external facts significantly improves the accuracy and reliability of the generated drawings compared to standard LLM outputs.
*   **Significant Workload Reduction:** The method substantially reduces the labor-intensive and time-consuming workload associated with traditional manual structural drawing production.
*   **Facilitation of Iterative Design:** The approach streamlines the iterative process for engineers, allowing for a simplified way to express and visualize design ideas directly from text descriptions.

---

## Methodology

**Core Architecture**
The method utilizes a generative AI framework centered on a Large Language Model (LLM) agent.

**Information Augmentation**
It employs Retrieval-Augmented Generation (RAG) to incorporate externally-sourced facts, ensuring the model possesses the necessary domain-specific knowledge for accuracy.

**Process Flow**
1.  **Input:** Processing of varied natural language descriptions of structural elements.
2.  **Extraction:** The system extracts necessary technical information from the text.
3.  **Generation:** The agent automatically generates code compatible with AutoCAD.
4.  **Output:** Production of the final structural drawing (including views, scales, and annotations) within the AutoCAD environment.

---

## Technical Details

The system utilizes a sophisticated multi-stage pipeline to handle the complexity of engineering drawings:

*   **Multi-Stage LLM Pipeline:** Utilizes LLM1 through LLM6 to decompose drawing generation into distinct sub-tasks:
    *   Classification
    *   Information extraction
    *   Missing data identification
    *   Workspace settings
    *   JSON structuring
    *   Python code generation
*   **Retrieval-Augmented Generation (RAG):** Retrieves pre-defined `.dwg` files for standardized sections (e.g., steel beams) to ensure compliance with engineering standards.
*   **Implementation Stack:**
    *   Target Software: AutoCAD
    *   Libraries: `pyautocad` and `win32com`
*   **Constraint Management:**
    *   **Token Limits:** Manages GPT-4's 4096 output token limit by generating complex drawings in split sub-steps.
    *   **Calculation Logic:** Includes internal logic for coordinate calculation and default parameterization.

---

## Contributions

*   **Novel Application of AI Agents:** Introduction of a specialized LLM agent designed specifically for the domain of structural drawing generation, moving beyond general-purpose text generation.
*   **Automation of Technical Documentation:** Bridging the gap between conceptual natural language descriptions and standardized technical documentation (AutoCAD code), automating a critical but laborious step in civil and mechanical engineering.
*   **Reliability through Hybrid AI:** Demonstrating the effective use of RAG within engineering workflows to mitigate hallucinations and enhance the factual reliability of generative models when applied to strict technical standards.

---

## Results

*   **Code Generation:** The system successfully translated natural language descriptions into executable Python code for AutoCAD, enabling the generation of structural drawings without manual drafting.
*   **Accuracy Improvement:** The integration of RAG significantly improved accuracy and reliability compared to standard LLM outputs.
*   **Efficiency:** The method demonstrated substantial reductions in labor-intensive workload and facilitated streamlined design iteration.
*   **Case Study Success:**
    *   Processed inputs for concrete beam geometry (calculating vertices for hooks and radii).
    *   Queried databases for standardized steel beam sections (e.g., 'HP360x174').
*   **Constraint Handling:** A key constraint observed was the GPT-4 Turbo output limit of 4096 tokens, which the system successfully navigated through task fragmentation.