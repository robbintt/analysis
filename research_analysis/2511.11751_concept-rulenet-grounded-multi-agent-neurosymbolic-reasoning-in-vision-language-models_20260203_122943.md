---
title: 'Concept-RuleNet: Grounded Multi-Agent Neurosymbolic Reasoning in Vision Language
  Models'
arxiv_id: '2511.11751'
source_url: https://arxiv.org/abs/2511.11751
generated_at: '2026-02-03T12:29:43'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Concept-RuleNet: Grounded Multi-Agent Neurosymbolic Reasoning in Vision Language Models

*Sanchit Sinha; Guangzhi Xiong; Zhenghao He; Aidong Zhang*

---

> ### ðŸ“Š Quick Facts
>
> *   **Performance Improvement:** +5% average over SOTA neurosymbolic baselines.
> *   **Reliability Gain:** Up to 50% reduction in hallucinated symbols.
> *   **Model Architecture:** Multi-agent system separating System-1 (VLMs) and System-2 (LLMs).
> *   **Key Innovation:** Shannon Entropy minimization for grounding.
> *   **Benchmarks:** 5 datasets including BloodMNIST, DermaMNIST, and satellite imagery.
> *   **Quality Score:** 9/10

---

## Executive Summary

Current neurosymbolic frameworks in Vision Language Models (VLMs) suffer from weak grounding, where symbolic reasoning components are not strictly anchored to the visual data within images. This disconnect leads to "hallucinated" symbols in reasoning rules and introduces label bias, where models rely on linguistic priors rather than actual image statistics. This issue is particularly critical in high-stakes, low-data domains such as medical imaging, where reliability and interpretability are paramount but current black-box neural models lack transparency.

The authors introduce **Concept-RuleNet (CRN)**, a multi-agent neurosymbolic framework that separates "System-1" perception (VLMs) from "System-2" reasoning (LLMs) through a rigorous four-stage pipeline. The core innovation is a grounding mechanism that first mines discriminative visual concepts directly from images and then conditions symbol discovery on these concepts using Shannon Entropy minimization ($H(S|x) < H(S)$). This ensures that symbols are derived from real image statistics rather than text labels. A symbolic agent (GPT-4o-mini) then composes these grounded symbols into executable first-order rules, which are verified by a vision agent (LLaVA) before final inference. An advanced extension, **CRN++**, further refines this by incorporating counterfactual reasoning and a Mixed Normal Form logic (combining DNF and CNF) to handle complex logical structures.

Concept-RuleNet outperformed state-of-the-art neurosymbolic baselines by an average of 5% across five diverse benchmarks, including medical datasets (BloodMNIST, DermaMNIST) and satellite imagery (UC-Merced, WHU). The framework demonstrated superior reliability by reducing the occurrence of hallucinated symbols within reasoning rules by up to 50%. In specific failure case analyses, such as the 'Basophil' class in BloodMNIST, ungrounded models scored only 0.48, whereas CRNâ€™s visually anchored approach significantly improved performance by mitigating reliance on spurious correlations.

This research establishes a new standard for integrating interpretable symbolic reasoning with black-box neural perception without sacrificing predictive accuracy. By successfully mitigating label bias and hallucinations through direct visual concept mining, Concept-RuleNet provides a robust architecture for trustworthy AI. The findings are particularly significant for the medical imaging field, demonstrating that neurosymbolic approaches can be effectively applied to complex, underrepresented domains where data scarcity and the need for explainable diagnostics are major hurdles.

---

## Key Findings

*   **Superior Performance:** The Concept-RuleNet system outperforms state-of-the-art neurosymbolic baselines by an average of **5%** across five benchmarks.
*   **Enhanced Reliability:** The approach reduces the occurrence of hallucinated symbols within reasoning rules by up to **50%**, significantly enhancing trustworthiness.
*   **Complex Domain Mastery:** The framework proved effective on complex domains, specifically **medical-imaging benchmarks** (e.g., BloodMNIST) and underrepresented natural-image datasets (e.g., satellite imagery).
*   **Mitigation of Label Bias:** By conditioning symbol discovery on visual concepts, the system successfully anchors reasoning in real image statistics, preventing reliance on linguistic priors.

---

## Methodology

The authors propose **Concept-RuleNet**, a multi-agent neurosymbolic system designed to integrate visual grounding with interpretable reasoning through a four-stage pipeline:

1.  **Multimodal Concept Generation:**
    Discriminative visual concepts are mined directly from a subset of training images to establish a visual vocabulary.
2.  **Grounded Symbol Discovery:**
    Visual concepts condition the discovery of symbols to anchor them in real image statistics, ensuring they are visually grounded rather than textually inferred.
3.  **Rule Composition:**
    A Large Language Model (LLM) composes grounded symbols into executable first-order rules, creating the logic structure for reasoning.
4.  **Vision Verification & Inference:**
    A vision verifier quantifies symbol presence to trigger rule execution alongside black-box neural models, ensuring the final prediction aligns with visual evidence.

---

## Contributions

*   **Addressing Weak Grounding:** The research reinstates strong visual grounding in neurosymbolic frameworks by utilizing direct concept mining from images.
*   **Label Bias Mitigation:** It utilizes visual concepts to condition symbol discovery, anchoring the generation process in actual visual data statistics rather than linguistic correlations.
*   **Transparent Architecture:** The paper introduces a transparent multi-agent architecture that combines black-box perception with interpretable symbolic reasoning without sacrificing predictive accuracy.
*   **High-Stakes Application:** The work contributes evidence that neurosymbolic approaches can be successfully applied to high-stakes, low-data domains such as medical imaging.

---

## Technical Details

### Core Framework: Concept-RuleNet (CRN)
*   **Type:** Multi-Agent Neurosymbolic System.
*   **Architecture:** Separates **'System-1'** (Vision Language Models for visual grounding) and **'System-2'** (LLMs for symbolic reasoning).
*   **Grounding Mechanism:** Relies on **Shannon Entropy minimization** ($H(S|x) < H(S)$) to reduce uncertainty and mitigate label bias.

### Advanced Extension: Concept-RuleNet++
*   **Features:** Introduces counterfactual reasoning and a Mixed Normal Form logic (combining DNF and CNF).
*   **Rule Representation:** $l = \{\{\{\tilde{s}_i, s_i\}\} \to y\}$.

### Implementation & Configuration
*   **Visual Agent ($A_V$):**
    *   Uses **LLaVA-Med** for medical datasets.
    *   Uses **LLaVA-1.6** for real-world datasets.
*   **Symbolic Agent:** Uses **GPT-4o-mini**.
*   **Hyperparameters:**
    *   Temperature: 0.2
    *   Initial premise symbols: $N=5$

---

## Results

### Performance Metrics
*   Outperforms state-of-the-art neurosymbolic baselines by an average of **5%** across five benchmarks.

### Reliability
*   Achieved a reduction in hallucinated symbols by up to **50%**.

### Failure Case Analysis
*   **BloodMNIST ('Basophil'):** Ungrounded model scored 0.48, highlighting the failure of non-grounded approaches on specific classes.

### Evaluation Datasets (5 Total)
1.  BloodMNIST
2.  DermaMNIST
3.  UC-Merced Satellite Land Use
4.  WHU
5.  iNaturalist-21

### Benchmarked Models
*   InstructBLIP-XXL
*   LLaVA-1.5
*   LLaVA-1.6
*   LLaVA-Med

---

**Quality Score:** 9/10  
**References:** 40 citations