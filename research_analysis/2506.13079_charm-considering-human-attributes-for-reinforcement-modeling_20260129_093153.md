# CHARM: Considering Human Attributes for Reinforcement Modeling

*Qidi Fang; Hang Yu; Shijie Fang; Jindan Huang; Qiuyu Chen; Reuben M. Aronson; Elaine S. Short*

---

### ðŸ“Š Quick Facts

| Metric | Value |
| :--- | :--- |
| **Study Participants** | 46 |
| **Total Data Points** | 4,655 |
| **Validation Method** | 10-fold Cross-Validation |
| **Key Improvement** | Statistically significant ($p < 0.001$) |
| **Quality Score** | 8/10 |
| **Attributes Modeled** | 6 (Trust, Experience, Education, etc.) |

---

## ðŸ“ Executive Summary

> Reinforcement Learning from Human Feedback (RLHF) traditionally treats the human teacher as a standardized oracle, assuming feedback is derived solely from task performance or state estimation. This paper addresses the critical limitation that current models fail to account for the variability of human teachers, ignoring how individual characteristics such as prior experience, personality, and educational background influence feedback patterns.

This oversight matters because it results in reward models that misunderstand the intent or grading leniency of specific users, leading to suboptimal policy learning and inefficiencies in human-robot interaction.

The key innovation is **CHARM** (**C**onsidering **H**uman **A**ttributes for **R**einforcement **M**odeling), a predictive framework that integrates standard task statistics with six specific human attribute domains: *Trust in Robot, Robot Experience, Educational Background, Teaching Experience, Teaching Style, and Personality*. Technically, the model employs a weighted loss function to handle imbalanced data and applies a Box-Cox transformation to analyze feedback delay.

The study is grounded in an exploratory experiment involving 46 participants performing long-horizon tasks, generating a dataset that fuses demographic and psychometric data with sequential action metrics to train a more nuanced oracle for predicting human feedback. Validated using 10-fold cross-validation on 4,655 data points, CHARM demonstrated statistically significant superiority ($p < 0.001$) over baseline models that relied exclusively on task statistics across both five-point and binary feedback scales.

While the correlation between feedback values and task rewards was moderate (0.563), the inclusion of human attributes yielded tangible improvements in predictive accuracy. Among the attributes, **Robot Experience** and **Educational Background** were identified as the strongest predictors of feedback accuracy. Additionally, the study found that predicting feedback delay using only task statistics was inherently difficult, achieving an RÂ² score of only 0.19 and an MSE of 0.30.

This research establishes the empirical necessity of shifting from task-centric to user-centric reward modeling in RLHF. By demonstrating that human attributes are significant covariates in feedback generation, the authors challenge the "one-size-fits-all" assumption of current oracle models. The release of an accompanying open-source dataset and source code provides a vital resource for the community, enabling further research into personalized reinforcement learning. Ultimately, CHARM paves the way for robots that can adapt to the specific teaching styles and biases of their human partners, improving the robustness and reliability of interactive learning systems.

---

## ðŸ”‘ Key Findings

*   **Human Correlation:** Human feedback patterns are correlated not only with task statistics but also with specific human characteristics like prior robot experience and educational background.
*   **Predictive Superiority:** Models that incorporate human characteristics demonstrate a higher capability to predict human feedback values compared to models relying exclusively on task statistics.
*   **Empirical Evidence:** The study provides empirical evidence that specific attributes of human teachers significantly influence the feedback patterns used in Reinforcement Learning from Human Feedback (RLHF).
*   **Key Predictors:** Robot Experience and Educational Background showed the most noticeable correlations with feedback accuracy, while no substantial linear correlation was found between attributes and feedback delay.

---

## ðŸ› ï¸ Methodology

The research utilized an exploratory study design with the following parameters:

*   **Participants:** 46 individuals recruited in a public space setting.
*   **Tasks:** Participants performed two distinct "long horizon" tasks to collect feedback over extended sequences.
*   **Analysis:** The researchers analyzed correlations between three distinct data streams:
    1.  Feedback patterns
    2.  Task statistics (e.g., rewards)
    3.  Demographic/Educational data

The goal was to validate whether the inclusion of human attributes provided predictive improvements over task performance metrics alone.

---

## âš™ï¸ Technical Details

**The CHARM Model Framework**

CHARM acts as a reinforcement learning oracle designed to predict human feedback values. It operates by combining task statistics with **six specific human attribute domains**:

1.  **Trust in Robot**
2.  **Robot Experience**
3.  **Educational Background**
4.  **Teaching Experience**
5.  **Teaching Style**
6.  **Personality**

**Model Configuration & Training**

*   **Baseline Comparison:** CHARM was compared against a baseline model utilizing only task statistics.
*   **Data Imbalance Handling:** The approach employs a weighted loss function to manage imbalanced feedback data.
*   **Data Transformation:** A Box-Cox transformation is applied to handle delay data.
*   **Output Scales:** Feedback is predicted on both:
    *   A five-point scale (-2 to +2)
    *   A binary scale
*   **Validation Protocol:** 10-fold cross-validation (90% training, 10% validation) on 4,655 data points with a new random seed per fold.

---

## ðŸ“ˆ Results

| Metric | Result | Notes |
| :--- | :--- | :--- |
| **Feedback/Reward Correlation** | 0.563 | Moderate positive correlation. |
| **Delay Prediction (Task Stats Only)** | MSE: 0.30 | Indicates difficulty in predicting delay without attributes. |
| **Delay Prediction (Task Stats Only)** | RÂ²: 0.19 | Low explanatory power. |
| **5-Point Scale Baseline (Random)** | 20% | |
| **Binary Scale Baseline (Random)** | 50% | |
| **Statistical Significance** | $p < 0.001$ | CHARM outperformed the task-statistics-only baseline significantly. |

*   **Top Attributes:** Robot Experience and Educational Background were the strongest predictors for feedback accuracy and absolute difference.

---

## ðŸš€ Contributions

*   **Closing the Gap:** The paper addresses a gap in prior work by closely investigating the specific effects of human teacher characteristics on feedback patterns rather than just acknowledging their existence.
*   **CHARM Concept:** Introduces the framework that modeling human feedback can be optimized by integrating human attributes alongside task performance metrics.
*   **Open Source Resources:** The authors contribute an open-source dataset of human feedback and characteristics, as well as source code for data collection and prediction algorithms.

---

**References:** 40 citations