---
title: 'LIFT: Interpretable truck driving risk prediction with literature-informed
  fine-tuned LLMs'
arxiv_id: '2510.22333'
source_url: https://arxiv.org/abs/2510.22333
generated_at: '2026-01-27T23:36:51'
quality_score: 9
citation_count: 15
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LIFT: Interpretable truck driving risk prediction with literature-informed fine-tuned LLMs

*Ke Zhangb (Civil Engineering), Yuansheng Liana, Meng Lia (Traffic Management), Yuelong Sud (Public Security), Yunxuan Lic (Tsinghua University), Xiao Hua*

> ### üìä Quick Facts
> *   **Recall Improvement:** 26.7%
> *   **F1-Score Improvement:** 10.1%
> *   **Knowledge Base:** 299 domain-specific papers
> *   **Validation:** PERMANOVA statistical testing
> *   **Quality Score:** 9/10

---

## Executive Summary

This research addresses the critical challenge of applying Large Language Models (LLMs) to traffic safety, specifically in predicting truck driving risks, while overcoming the inherent "black box" limitation that typically obscures model reasoning. In high-stakes environments like commercial trucking, accurate prediction is insufficient without transparent explanations of the causative factors. Existing models often fail to provide reliable, domain-specific insights, limiting their utility for safety management and operational decision-making.

The key innovation is the **LIFT (Literature-informed Fine-tuned LLMs)** framework, a novel architecture designed to ground LLMs in domain-specific scientific knowledge to enhance both accuracy and interpretability. Technically, the system operates through three interconnected components: a Literature Processing Pipeline that synthesizes findings from 299 domain papers into a structured knowledge base; an LLM-driven Inference Core that is fine-tuned on real-world data to predict risks and generate explanations; and a Result Evaluator that quantifies performance.

LIFT demonstrated superior predictive performance compared to benchmark models, achieving a significant **26.7% improvement in recall** and a **10.1% increase in the F1-score**. Beyond prediction, the framework exhibited robust interpretability, maintaining consistency across various data sampling conditions. Experiments validated that the integration of the 299-paper knowledge base is essential, as it is the primary driver of the model's ability to explain variable importance. Furthermore, the risky scenarios identified by the framework were statistically confirmed through PERMANOVA tests, verifying the reliability of the model's generated insights.

---

## üîë Key Findings

*   **Superior Predictive Performance:** The LIFT LLM achieved a **26.7% improvement in recall** and a **10.1% improvement in F1-score** compared to benchmark models.
*   **Robust Interpretability:** The framework demonstrated consistent and robust interpretability across various data sampling conditions, addressing the "black box" nature of standard LLMs.
*   **Statistical Verification:** Identified potential risky scenarios were statistically verified using **PERMANOVA tests**.
*   **Literature Validation:** The efficacy of literature integration was validated, proving that a knowledge base derived from **299 domain papers** is essential for enhancing model interpretability and variable importance analysis.

---

## üöÄ Contributions

The research introduces several significant advancements to the field of interpretable AI and traffic safety:

1.  **Novel Framework for Interpretable AI:** Introduces the LIFT framework as a novel solution addressing the 'black box' nature of LLMs in traffic safety applications.
2.  **Validation of Literature-Guided AI:** Demonstrates that grounding LLMs in scientific literature enhances both performance and the reliability of variable importance analysis.
3.  **Advancement in Data-Driven Discovery:** Advances knowledge discovery by showing that fine-tuned LLMs can identify complex, risky variable interactions in truck driving operations that go beyond simple prediction tasks.

---

## üõ†Ô∏è Technical Details

**Framework Architecture**
*   **Name:** LIFT (Literature-informed Fine-tuned LLMs)
*   **Core Function:** Utilizes fine-tuned Large Language Models for truck driving risk prediction.

**Key Components**
1.  **Literature Processing Pipeline:** Filters and summarizes domain-specific literature to construct a structured knowledge base.
2.  **LLM-driven Inference Core:** Predicts truck driving risk and provides explanations; fine-tuned on real-world data.
3.  **Result Evaluator:** Quantitatively assesses prediction performance metrics (e.g., recall, F1-score) and the qualitative interpretability of outputs.

**Methods & Mechanisms**
*   **Domain Adaptation:** Integrates a knowledge base derived from 299 domain-specific papers through literature-informed fine-tuning.
*   **Contextual Linking:** Identifies specific potential risky scenarios, linking predictions directly to driving contexts.
*   **Statistical Analysis:** Employs **PERMANOVA (Permutational Multivariate Analysis of Variance)** tests for statistical verification of risk clusters.

---

## üìà Results

*   **Performance Metrics:** Achieved a 26.7% increase in recall and a 10.1% increase in F1-score compared to benchmark models.
*   **Interpretability Consistency:** Demonstrated consistent interpretability across various data sampling conditions.
*   **Literature Necessity:** Experimental results validated that the integration of the 299-paper knowledge base is essential for interpretability.
*   **Scenario Verification:** Identified risky scenarios were statistically confirmed via PERMANOVA tests.

---
**References:** 15 citations