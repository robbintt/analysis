# Multilingual and Multi-Accent Jailbreaking of Audio LLMs

*Jaechul Roh; Virat Shejwalkar; Amir Houmansadr*

---

> ### ðŸ“Š Quick Facts
> *   **JSR Increase:** Up to **57.25 percentage points** via acoustic perturbations.
> *   **Attack Efficacy:** Multilingual audio achieves **3.1x** higher success rates than text-only attacks.
> *   **Dataset Scale:** **102,720** audio files generated across 5 languages.
> *   **Quality Score:** 9/10
> *   **References:** 40 citations

---

## Executive Summary

This research addresses a critical security gap in Large Audio Language Models (LALMs), which are increasingly deployed for multimodal interaction but remain vulnerable to sophisticated exploitation techniques. While text-based jailbreaking is well-understood, the security implications of audio modalityâ€”specifically regarding linguistic and acoustic variationsâ€”have been largely unexplored.

The study highlights that multilingual and multi-accent inputs create severe vulnerabilities. The complex interaction between acoustic perturbations and cross-lingual phonetics allows adversaries to bypass safety filters more effectively than standard text prompts, posing a significant risk as multimodal LLMs are inherently more susceptible to compromise via non-English audio inputs.

The paper introduces **'Multi-AudioJail,'** the first systematic framework designed to exploit audio-specific vulnerabilities through a black-box, two-stage attack mechanism. Evaluations on state-of-the-art models revealed alarming vulnerabilities, with the combination of acoustic perturbations and cross-lingual phonetics increasing Jailbreak Success Rates (JSR) by up to **57.25 percentage points**. By releasing a unique dataset and demonstrating the superior efficacy of audio over text-based attacks, this work urges the AI security community to develop robust cross-modal defenses.

---

## Key Findings

*   **Severe Security Vulnerabilities:** Linguistic and acoustic variations in multilingual and multi-accent inputs expose critical weaknesses in current LALM defenses.
*   **Phonetic & Acoustic Interaction:** The interaction between acoustic perturbations and cross-lingual phonetics can increase Jailbreak Success Rates (JSR) by up to **57.25 percentage points**.
*   **Multimodal Risk:** Multimodal LLMs are inherently more vulnerable than unimodal systems, often compromised via non-English audio inputs.
*   **Superior Attack Vector:** Multilingual audio-only attacks achieve **3.1x** higher success rates compared to traditional text-only attacks.

---

## Methodology

The researchers utilized **'Multi-AudioJail,'** the first systematic framework designed to exploit audio vulnerabilities. The methodology consists of two main components:

1.  **Novel Dataset Creation:** A dataset of adversarially perturbed multilingual and multi-accent audio jailbreaking prompts was developed to stress-test model inputs.
2.  **Hierarchical Evaluation:** A specialized pipeline was empirically designed to analyze how specific acoustic properties interact with phonetics to degrade safety guardrails.

---

## Technical Details

### Framework: MULTI-AUDIO JAIL
A **black-box two-stage attack mechanism** comprising:

#### Stage 1: Synthesis
*   **Volume:** Generated **102,720 audio files**.
*   **Source:** 520 harmful instructions sourced from *AdvBench*.
*   **Languages:** Translated into 5 languages (German, Italian, Spanish, French, Portuguese).
*   **Generation Tool:** TTSMaker.
*   **Accent Variations:** Featured both Natural and Synthetic accents.

#### Stage 2: Perturbation
Applies signal-level acoustic transformations to simulate environmental distortions and bypass safety filters:
*   **Reverberation:** Using Impulse Response convolution.
*   **Effects:** Whisper effects and Echo effects.

### Evaluation Metrics
*   **Jailbreak Success Rate (JSR):** Measured by Llama Guard 3.
*   **Word Error Rate (WER):** Measured by Whisper-large-v3.
*   **SQA Accuracy:** Measured by Llama-3.1-8B.

---

## Results

Targeted models included Qwen2-Audio, DiVA-llama-3-v0-8b, MERaLiON-AudioLLM, MiniCPM-o-2.6, and Ultravox-v0.4.1.

*   **Relative Performance:** Multilingual audio-only attacks were **3.1x** more successful than text-only attacks.
*   **Model-Specific JSRs:**
    *   **MERaLiON-AudioLLM-Whisper-SEA-LION:** 5.19%
    *   **Qwen2-Audio:** 3.27%
    *   **Ultravox-v0.4.1-Llama-3.1-8B:** 3.08%
    *   **MiniCPM-o-2.6:** 2.31%
    *   **DiVA-llama-3-v0-8b:** 1.73%

---

## Contributions

*   **First Systematic Exposure:** The study is the first to systematically expose and quantify how multilingual and multi-accent inputs serve as potent attack vectors against Large Audio Language Models (LALMs).
*   **Dataset Release:** It contributes the release of a unique dataset of adversarially perturbed audio prompts to the research community.
*   **Defense Advocacy:** By demonstrating the superior efficacy of audio and cross-lingual attacks over text-based ones, it urges the community to shift toward developing cross-modal defenses.

---

*Report generated based on 40 references.*