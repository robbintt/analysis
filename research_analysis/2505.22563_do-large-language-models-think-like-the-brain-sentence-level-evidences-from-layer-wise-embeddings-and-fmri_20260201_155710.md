# Do Large Language Models Think Like the Brain? Sentence-Level Evidences from Layer-Wise Embeddings and fMRI

*Yu Lei; Xingyang Ge; Yi Zhang; Yiming Yang; Bolei Ma*

---

> ### **Quick Facts**
>
> *   **Quality Score**: 9/10
> *   **Citations**: 24
> *   **Models Analyzed**: 14 (including Llama-3.1, Qwen2.5, Mistral, Gemma-2, GLM-4, BERT)
> *   **Methodology**: fMRI & Layer-wise Embeddings
> *   **Focus**: Sentence-level neural mechanisms & Naturalistic narrative processing
> *   **Key Statistical Finding**: Instruction-tuned models outperform base counterparts ($p = 0.03125$)

---

## Executive Summary

This research investigates whether the representational architecture of Large Language Models (LLMs) genuinely mirrors the hierarchical processing of the human brain or if observed similarities are merely artifacts of parameter scaling. It seeks to resolve the debate over computational parallels between artificial and biological intelligence by determining if performance improvements in LLMs correspond to a deeper alignment with neural processing dynamics.

The key innovation is a rigorous, layer-wise comparative analysis mapping internal LLM embeddings against fMRI data captured during auditory narrative processing, with a specific emphasis on sentence-level neural mechanisms. By analyzing 14 diverse LLMs and employing standard neuroimaging regression techniques to map model layers directly to Regions of Interest within the Fedorenko language network, the study isolates where artificial representations align with biological cognition.

The analysis yielded precise data showing that semantic alignment peaks at intermediate LLM layers rather than final outputs, with instruction-tuned models significantly outperforming base counterparts. Top-performing models included Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct. Furthermore, distinct hemispheric lateralization patterns were identified, showing Left dominance in Posterior Temporal and Inferior Frontal Gyrus, and Right dominance in Anterior Temporal and Middle Frontal Gyrus.

These findings demonstrate that advancements in LLM performance drive the evolution of representational hierarchies that closely mimic human brain dynamics. By establishing instruction-tuned LLMs as effective computational models for human language processing, this research provides a validated framework for using artificial systems to study and simulate biological intelligence.

---

## Key Findings

*   **Evolution Toward Brain-Like Hierarchies**: Improvements in the overall performance of LLMs drive the evolution of their representational architectures toward structures that resemble the hierarchy of the human brain.
*   **High-Level Semantic Correspondence**: The strongest functional and anatomical correspondence between LLMs and the human brain occurs at higher semantic abstraction levels.
*   **Layer-Specific Correlation**: Specific layers within LLM representations can be identified that correlate significantly with activations in distinct brain regions during sentence comprehension.
*   **Hierarchical Alignment**: There is a demonstrable alignment between the hierarchical embeddings of LLMs and the dynamic neural responses observed in the human brain during naturalistic narrative processing.

---

## Methodology

The study employed a rigorous comparative framework between biological and artificial intelligence systems:

*   **Data Source**: Utilized fMRI data from participants exposed to a naturalistic narrative story.
*   **Model Selection**: Compared neural data against hierarchical embeddings extracted from **14 publicly available LLMs**.
*   **Scope**: Focused specifically on **sentence-level** neural mechanisms.
*   **Prediction Modeling**: Researchers constructed sentence-level neural prediction models to systematically compare layer-wise representations in LLMs with dynamic brain neural responses.
*   **Correlation Analysis**: The method involved identifying specific model layers that showed the most significant correlation with activations in various brain regions.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **Models Analyzed** | 14 LLMs (Llama-3.1, Qwen2.5, Mistral, Gemma-2, GLM-4, BERT, etc.) |
| **Stimuli** | Auditory naturalistic narrative sentences |
| **Signal Acquisition** | fMRI BOLD signals |
| **Data Preprocessing** | General Linear Model (GLM) with Least-Squares Separate (LS-S) approach to model target sentences independently and resolve temporal mismatches |
| **Mapping Technique** | **Ridge Regression** used to map LLM embeddings to voxel-wise fMRI time series |
| **Regions of Interest (ROIs)** | 12 ROIs from Fedorenko et al. (2010) language network: IFG, MFG, AntTemp, PostTemp, AngG, and IFGorb (both hemispheres) |
| **Evaluation Metric** | Correlation analysis between predicted and actual brain activity |

---

## Results

The study produced statistically significant results regarding model architecture and neural alignment:

*   **Performance Peaks**: Peak predictive performance was observed at **intermediate LLM layers** rather than the final output layer.
*   **Instruction Tuning Impact**: Instruction-tuned models significantly outperformed base counterparts ($p = 0.03125$).
*   **Top Performers**: The highest-ranking models included **Llama-3.1-8B-Instruct**, **DeepSeek-R1-Distill-Qwen-7B**, and **Qwen2.5-7B-Instruct**.
*   **Hemispheric Lateralization**:
    *   **Left Dominance**: Observed in Posterior Temporal ($p = 0.007$) and Inferior Frontal Gyrus ($p = 0.025$).
    *   **Right Dominance**: Observed in Anterior Temporal ($p = 0.001$) and Middle Frontal Gyrus ($p = 0.005$).
*   **Prefrontal Trends**: Lateralization in prefrontal regions showed a positive trend with model performance:
    *   IFG: $r = 0.54, p = 0.055$
    *    MFG: $r = 0.50, p = 0.084$

---

## Contributions

*   **Computational Similarities**: Advances the understanding of the computational similarities between artificial and biological intelligence, specifically how LLM representations align with human language processing.
*   **Scaling vs. Architecture**: Provides critical insight into the debate over whether brain-like patterns in LLMs emerge merely from scaling up models or from a deeper alignment with the architecture of human language processing.
*   **Future Research Framework**: Highlights the potential of using LLMs as effective models for studying and simulating human language processing mechanisms.