---
title: 'Large Language Models in the Travel Domain: An Industrial Experience'
arxiv_id: '2507.2291'
source_url: https://arxiv.org/abs/2507.22910
generated_at: '2026-02-03T18:43:19'
quality_score: 9
citation_count: 33
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Large Language Models in the Travel Domain: An Industrial Experience

*Sergio Di Meglio; Aniello Somma; Luigi Libero Lucio Starace; Fabio Scippacercola; Giancarlo SperlÃ¬; Sergio Di Martino*

---

> ### ðŸ“Š Quick Facts & Metrics
>
> **Model Performance Comparison**
>
> | Metric | Mixtral 8x7B (Prompted) | Mistral 7B (Fine-tuned) |
> | :--- | :--- | :--- |
> | **Completeness** | 99.6% | 93% |
> | **Precision** | 98.8% | 96% |
> | **Hallucination Rate** | 1.2% | 4% |
> | **Avg. Word Count** | 249 words | 277 words |
> | **VRAM Usage** | 50 GB | 5 GB |
> | **Operational Cost** | $1.61/hour | $0.16/hour |
>
> **Quality Score:** 9/10  
> **References:** 33 Citations

---

## Executive Summary

This research addresses the critical operational challenge of maintaining data consistency and accuracy within the online travel booking industry, specifically regarding the automated generation of accommodation descriptions. As platforms like CALEIDOHOTELS scale, ensuring homogeneity in property listings while minimizing hallucinations becomes increasingly difficult for manual content management. The paper highlights the necessity of reliable automated solutions, noting that inconsistent or fabricated details degrade user trust and operational efficiency. This problem is particularly pertinent as organizations seek to integrate Large Language Models (LLMs) into production environments without sacrificing reliability.

The core innovation is a rigorous industrial case study comparing two distinct deployment strategies within a live reservation system. The study contrasts a Mixture-of-Experts architecture, Mixtral 8x7B, utilizing advanced prompt engineering, against a smaller decoder-only transformer, Mistral 7B, optimized via QLoRA fine-tuning on a proprietary travel dataset. This technical setup isolates the performance differences between relying on the inherent knowledge capacity of a large model versus the domain-specific customization of a smaller, resource-efficient model, providing a novel framework for assessing trade-offs in a real-world production environment.

The study reveals a significant performance disparity favoring the larger, prompted model. Mixtral 8x7B achieved superior qualitative metrics, recording 99.6% completeness and 98.8% precision, alongside a markedly lower hallucination rate of 1.2%. In comparison, the fine-tuned Mistral 7B achieved 93% completeness and 96% precision, with a hallucination rate of 4%. Furthermore, the larger model produced more concise outputs, averaging 249 words versus 277 words. However, these quality gains come at a steep computational cost; Mixtral 8x7B required 50GB of VRAM and incurred operational costs of $1.61 per hour, whereas Mistral 7B required only 5GB of VRAM and cost $0.16 per hour.

The significance of this paper lies in its empirical evidence guiding the industrial deployment of LLMs, offering a clear cost-benefit analysis for technical decision-makers. It demonstrates that while fine-tuning smaller models is resource-efficient, it may not bridge the quality gap achievable by leveraging larger models with sophisticated prompting. This insight compels the industry to weigh the value of precision and reduced hallucinations against the infrastructure costs of serving large models. Consequently, the study serves as a benchmark for future implementations in the travel domain, influencing how organizations balance output quality against operational expenditure.

---

## Methodology

Researchers conducted an industrial case study by integrating Large Language Models into the CALEIDOHOTELS property reservation platform. The study evaluated two distinct configurations:

1.  **Mistral 7B:** A smaller model fine-tuned using QLoRA (Quantized Low-Rank Adaptation).
2.  **Mixtral 8x7B:** A larger model utilized via prompt engineering with a refined system prompt.

The models were assessed on their ability to generate consistent accommodation descriptions while minimizing hallucinations. Evaluation metrics included:
*   Completeness
*   Precision
*   Hallucination rates
*   Content length
*   VRAM usage
*   Operational costs

---

## Technical Details

The study compares two Large Language Model strategies in the travel domain, highlighting architectural and deployment differences.

### Configuration A: Mixtral 8x7B
*   **Architecture:** Mixture of Experts (MoE).
*   **Strategy:** Utilized via prompt engineering with a refined system prompt.
*   **Strength:** Leverages high inherent knowledge capacity.

### Configuration B: Mistral 7B
*   **Architecture:** Smaller decoder-only transformer.
*   **Strategy:** Fine-tuning on a travel-specific dataset using QLoRA.
*   **Strength:** Domain-specific customization with high resource efficiency.

---

## Key Findings

The comparison between the two models yielded significant insights regarding the trade-off between quality and cost:

*   **Quality Superiority of Mixtral 8x7B:** The larger model significantly outperformed the fine-tuned smaller model across all quality metrics. It achieved a 99.6% completeness rate and 98.8% precision, with a very low hallucination rate of 1.2%.
*   **Resource Intensity:** The superior quality of Mixtral 8x7B comes with high computational demands. It required **50GB of VRAM** and cost **$1.61/hour** to operate.
*   **Efficiency of Mistral 7B:** The fine-tuned Mistral 7B was far more efficient, requiring only **5GB of VRAM** and costing **$0.16/hour** (10x cheaper).
*   **Performance Gaps:** While Mistral 7B achieved respectable scores (93% completeness, 96% precision), it suffered from a higher hallucination rate (4%) compared to Mixtral.
*   **Conciseness:** Mixtral 8x7B generated more concise descriptions (249 words) compared to Mistral 7B (277 words).
*   **Strategy Implications:** The study highlighted a distinct performance gap between a fine-tuned smaller model and a larger model utilizing prompt engineering, suggesting that prompt engineering on larger models may yield higher quality than fine-tuning smaller ones, albeit at a higher cost.

---

## Contributions

*   **Practical Industry Case Study:** Provides a real-world demonstration of LLM effectiveness in enhancing data consistency within online booking platforms (CALEIDOHOTELS).
*   **Cost-Benefit Analysis:** Offers critical insights into the trade-offs between output quality (precision, reduced hallucinations) and resource efficiency (VRAM, operational cost).
*   **Deployment Strategy Evidence:** Contributes empirical evidence regarding the efficacy of different deployment strategiesâ€”specifically fine-tuning versus advanced promptingâ€”in reducing hallucinations and improving data homogeneity.