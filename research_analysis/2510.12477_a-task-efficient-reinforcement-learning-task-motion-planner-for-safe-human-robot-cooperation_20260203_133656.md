---
title: A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot
  Cooperation
arxiv_id: '2510.12477'
source_url: https://arxiv.org/abs/2510.12477
generated_at: '2026-02-03T13:36:56'
quality_score: 8
citation_count: 34
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation

*Gaoyuan Liu; Joris de Winter; Kelly Merckaert; Denis Steckelmacher; Ann Nowe; Bram Vanderborght*

---

### ðŸ“Š Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Quality Score** | 8/10 |
| **References** | 34 Citations |
| **Collision Response** | $2.5 \times 10^{-5}$ seconds ($25 \mu s$) |
| **Optimization** | "Dense checking to avoid dense replanning" |
| **Architecture** | Hierarchical TAMP (RL + re-RRT*) |

---

## Executive Summary

### Problem
This research addresses the critical challenge of balancing **safety** and **efficiency** in Human-Robot Cooperation (HRC) within dynamic environments where human motions are inherently uncertain. Traditional Task and Motion Planning (TAMP) methods frequently rely on hard-coded strategies that struggle to adapt to real-time human movement, resulting in excessive computational loads due to constant replanning and frequent task failures. This problem is significant because inefficient planning not only wastes system resources but also creates "backup motions" that reduce overall task reliability and can compromise the seamless integration of robots into human-centric workspaces.

### Innovation
The authors propose a novel **hierarchical framework** that bridges high-level decision-making with low-level execution using a hybrid Reinforcement Learning (RL) approach. The system comprises two distinct layers: an **RL Task Planner** that operates at a high level to select statistically safe task sequences (formulated as an MDP) in the 2D Cartesian plane, and an **Interactive Motion Planner** that handles execution using an extension of RRT* (re-RRT*) and the Flexible Collision Library (FCL). A key technical feature is the closed-loop interaction where the motion planner provides feedback on human arm motion and invalid paths, enabling the RL agent to proactively learn and avoid dangerous states. This architecture utilizes a "dense checking to avoid dense replanning" strategy, monitoring collisions densely while minimizing trajectory regeneration.

### Results
Validation through both simulation and real-world experiments confirmed the frameworkâ€™s superiority over hard-coded TAMP methods. Technical benchmarks indicated that the collision checking function achieved a response time of **$2.5 \times 10^{-5}$ seconds ($25 \mu s$)**. The study also identified a critical trade-off in planning frequencies: increasing frequency (10â€“50 Hz) led to longer trajectory lengths and higher failure ratios, while lower frequencies caused unsafe motion delays. Ultimately, the system demonstrated a marked reduction in the total number of replanning requests and a significant decrease in the frequency of repeating failed goal commands, validating its ability to maintain task efficiency in dynamic settings.

### Impact
This work significantly advances the field of robotics by resolving the persistent trade-off between safety and computational efficiency in collaborative environments. By reducing the computational overhead associated with frequent replanning, the framework makes real-time, adaptive HRC more feasible for practical deployment. The successful integration of RL for high-level task planning with reactive motion control establishes a new paradigm for minimizing backup motions and goal failures. This research provides a robust foundation for future developments in industrial and assistive robotics, where adaptability to human presence is paramount for safe and efficient operation.

---

## Key Findings

*   **Adaptability:** The proposed framework successfully reacts to uncertain human motions at both the joint and task levels, demonstrating high adaptability in dynamic environments.
*   **Reliability Improvement:** The system significantly reduces the frequency of repeating failed goal commands, directly improving overall task reliability.
*   **Computational Efficiency:** There is a marked reduction in the total number of replanning requests, which alleviates computational load compared to traditional methods.
*   **Experimental Validation:** Validation in both simulation and real-world experiments confirmed the superiority of the framework over hard-coded task-motion planning methods.

---

## Methodology

The researchers utilized a hybrid Reinforcement Learning (RL) planning framework composed of two distinct but interacting layers:

1.  **RL Task Planner (High Level):**
    *   Selects statistically safe and efficient task sequences.
    *   Utilizes feedback from the motion planner to learn and avoid dangerous tasks over time.
2.  **Interactive Motion Planner (Execution Level):**
    *   Ensures collision-free paths during execution.
    *   Detects human arm motions in real-time.
    *   Deploys new paths only when the previous path becomes invalid, rather than replanning continuously.

---

## Contributions

*   **Resolution of the Safety-Efficiency Trade-off:** Introduces a system that minimizes backup motions and goal failures, effectively balancing the need for safety with the requirement for efficiency.
*   **Hierarchical Integration:** Implements a novel architecture that bridges high-level RL decision-making with low-level reactive motion planning.
*   **Reduction of Computational Overhead:** Decreases the computational load associated with frequent motion replanning through an RL agent that proactively avoids dangerous states.

---

## Technical Details

The proposed framework is a hierarchical Task and Motion Planning (TAMP) system for Human-Robot Cooperation (HRC) featuring a two-module design.

### System Architecture
| Component | Functionality |
| :--- | :--- |
| **Interactive Motion Planner** | Operates at the low-level execution layer. Uses `re-RRT*` (extension of RRT*) and the Flexible Collision Library (`FCL`). |
| **RL Task Planner** | Operates at the high-level layer. Formulates the problem as a Markov Decision Process (MDP). Outputs commands in the 2D Cartesian plane to drive the robot end-effector. |

### Key Strategies
*   **Dense Checking to Avoid Dense Replanning:** A strategy designed to manage collisions and trajectory validity by monitoring collisions densely while minimizing trajectory regeneration.

---

## Results

*   **Performance Benchmark:** The collision checking function achieved a response time of **$2.5 \times 10^{-5}$ seconds ($25 \mu s$)**.
*   **Planning Frequency Trade-offs:**
    *   **High Frequency (10â€“50 Hz):** Increases trajectory length due to direction changes and increases the failure ratio due to insufficient time for valid solutions.
    *   **Low Frequency:** Causes severe motion delay, negatively impacting safety.
*   **Operational Success:** The system demonstrated a marked reduction in replanning requests and a significant reduction in repeating failed goal commands, validating its superiority over hard-coded TAMP methods in both simulation and real-world experiments.