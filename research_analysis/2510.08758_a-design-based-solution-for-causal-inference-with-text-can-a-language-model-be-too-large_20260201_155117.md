# A Design-based Solution for Causal Inference with Text: Can a Language Model Be Too Large?

*Graham Tierney; Srikar Katta; Christopher Bail; Sunshine Hillygus; Alexander Volfovsky*

***

> ### 
> This paper addresses a critical vulnerability in applying Large Language Models (LLMs) to causal inference: the risk of **overlap bias** induced by representation learning that encodes the treatment variable, destroying common support. The authors propose a design-based experimental solution using a semi-synthetic dataset with rigorously controlled latent confounding to establish a known ground truth Average Treatment Effect (ATE). Quantitative evaluation reveals that LLM-based estimators consistently underperformed due to induced positivity violations, whereas simple **Bag-of-Words Inverse Propensity Weighting (BoW IPW)** proved superior. This research challenges the assumption that scaling up model size inherently improves performance in causal tasks, demonstrating that simpler models can outperform massive LLMs by avoiding the treatment-encoding paradox.

> ### 
> *   **Quality Score:** 7/10
> *   **Total Citations:** 17
> *   **Top Performing Method:** BoW IPW
> *   **Primary Application:** Political Communication Analysis
> *   **Core Problem Addressed:** Positivity Violations / Overlap Bias

***

## Key Findings

*   **Risk of Overlap Bias in LLMs:** Recent deep learning methods using Large Language Models (LLMs) to learn latent representations of text risk inducing overlap bias by encoding the treatment itself within the representation.
*   **Performance of Simpler Models:** In the context of this specific experiment, LLM-based causal inference methods performed worse than simple bag-of-words models when using real text and outcomes.
*   **Efficiency of Design-Based Solutions:** The proposed experimental design successfully handles latent confounding and allows for the unbiased estimation of treatment effects without relying on post-hoc adjustments.
*   **Substantive Impact on Persuasion:** The study isolated the specific causal effect of expressing humility in political communication, finding it offers new insights into the persuasiveness of political statements.

## Methodology

The authors introduce a novel experimental design-based solution rather than relying on post-hoc statistical adjustments. This approach is designed to handle **latent confounding** (where linguistic properties like anger and profanity are interlinked) and specifically avoids the overlap issue caused when models encode the treatment variable.

The methodology was applied and validated within a concrete experiment evaluating the persuasiveness of linguistic humility in political communication.

## Technical Details

The paper addresses 'overlap bias' in LLMs for causal inference caused by the encoding of the treatment variable into text representations.

*   **Solution Approach:** A design-based experimental approach using a semi-synthetic dataset with real text where latent confounding is controlled via a human-rated 'respectfulness' feature (0-100).
*   **Estimators Evaluated:**
    *   *Naive:* Difference in Means, Topic Adjustment
    *   *Bag-of-Words (BoW):* Outcome Regression (OR), IPW, Augmented IPW (AIPW) using cross-fitted random forests.
    *   *LLM:* TextCause, Treatment Ignorant.
*   **Modifications:** Modifications to LLM methods included **Winsorizing** and **Trimming** to constrain propensity scores.
*   **Preprocessing:** Data preprocessing involved dichotomizing 5-point Likert scales and generating 100 replicas for robustness.

## Results

Evaluation used ground truth ATE established via Proposition 4.1.

*   **Baseline Confounding Scenario:** Most estimators correctly identified null effects, though TextCause failed on the 'aggressive' outcome.
*   **Amplified Confounding Scenario:**
    *   **Naive Models:** Produced significant errors.
    *   **BoW IPW:** Consistently estimated within true ATE confidence bands.
    *   **LLM Estimators:** Failed due to induced positivity violations, as the LLMs encoded the treatment variable within the embedding space, preventing overlap.
*   **Superior Method:** BoW IPW was identified as the superior method, outperforming LLM-based estimators.

## Contributions

*   **Methodological Innovation:** Provides a new experimental design framework for causal inference with text that avoids the limitations of current representation learning approaches.
*   **Critique of LLM Scaling:** Offers evidence that increasing model size (using LLMs) is not inherently beneficial for causal inference with text, as they may underperform simpler models due to treatment encoding.
*   **Advancement of Social Science Research:** Delivers substantive empirical evidence regarding the causal effects of linguistic properties (specifically humility) in political rhetoric, benefiting social media analysis, policy-making, and communication studies.

---
*Report generated based on 17 citations and a quality assessment of 7/10.*