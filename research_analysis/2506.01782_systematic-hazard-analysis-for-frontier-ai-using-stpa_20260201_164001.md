# Systematic Hazard Analysis for Frontier AI using STPA
*Simon Mylius*

> ### **Quick Facts**
> * **Quality Score:** 9/10
> * **Citations:** 40
> * **Methodology:** Systems-Theoretic Process Analysis (STPA)
> * **Validation:** Google Pilot Study (2 Engineers, 5 Months)
> * **Key Focus:** Frontier AI Safety & Hazard Identification

---

## Executive Summary

Current safety assurance for frontier AI systems relies heavily on unstructured governance frameworks such as capability thresholds and model evaluations. While established, these methods often fail to address complex, emergent risks because they focus on simple component failures rather than hazardous system-level interactions. Consequently, they miss hidden causal factors, making it difficult to establish robust safety assurances for highly capable AI systems.

This paper introduces Systems-Theoretic Process Analysis (STPA), a rigorous safety engineering framework adapted specifically for frontier AI. Grounded in the threat model detailed in "A Sketch of an AI Control Safety Case," the methodology employs a four-stage technical process: defining losses and hazards; modeling control loops between controllers and the controlled process; identifying Unsafe Control Actions (UCAs); and detailing specific loss scenarios. This structured emphasis on system-level interactions—such as input filtering and red-teaming—provides broader traceability than ad-hoc methods and facilitates partial automation using Large Language Models (LLMs).

Validation of STPA’s efficacy was demonstrated through a pilot project at Google, where two part-time engineers applied the methodology to service reliability issues over five months. The analysis identified critical architectural defects that would likely have prevented at least four major incidents. Qualitative results indicate that STPA provides a deeper and more accurate understanding of causal factors than current unstructured methods, enabling the creation of more defensible safety cases.

---

## Key Findings

*   **Hidden Causal Factor Identification:** STPA successfully identifies causal factors that are typically missed by unstructured hazard analysis methodologies.
*   **Governance Complementarity:** The framework does not replace but rather complements existing AI governance techniques, specifically capability thresholds and model evaluations.
*   **Scalability via Automation:** The structured nature of STPA enables the use of Large Language Models (LLMs) to conduct parts of the analysis, significantly enhancing scalability.

---

## Technical Details

The paper proposes **Systems-Theoretic Process Analysis (STPA)** as a hazard analysis methodology specifically tailored for frontier AI systems. Unlike traditional methods that focus on simple component failures, STPA emphasizes **emergent properties** and **component interactions**.

The architecture follows a sequential four-stage process:

1.  **Loss and Hazard Identification:** Defining specific outcomes to avoid and hazardous system states.
2.  **Control Structure Modeling:** Identifying controllers, controlled processes, and mapping feedback loops.
3.  **Unsafe Control Action (UCA) Identification:** Determining how specific control actions become unsafe.
4.  **Loss Scenario Development:** Identifying causal factors leading to UCAs.

**Implementation Specifics:**
*   **Scope Emphasis:** The application prioritizes the **System Level** (peripheral processes like input filtering and red-teaming) over the internal model level.
*   **Integration:** The methodology integrates directly with safety case development to support top-level safety claims.

---

## Methodology

The study utilizes STPA as its core framework, specifically mapping controllers and feedback loops within the AI system. It applies this framework to the threat model outlined in *"A Sketch of an AI Control Safety Case"*.

The process involves:
*   Deriving **'Unsafe Control Actions'** (UCAs).
*   Analyzing **'Loss Scenarios'** that result from unmitigated actions.

---

## Contributions

*   **Bridging Disciplines:** The paper bridges the gap between safety engineering and AI by introducing a rigorous engineering approach to hazard identification.
*   **Enhanced Assurance:** It enhances safety assurance by broadening the scope of analysis and improving traceability.
*   **Operational Efficiency:** By suggesting that structured methodologies like STPA can be partially automated using LLMs, the paper proposes a way to reduce reliance on scarce human experts.

---

## Results

A **Google pilot study** applied STPA to service reliability issues utilizing 2 engineers working part-time over a period of 5 months.

*   **Incident Prevention:** The analysis identified defects that would likely have prevented **at least 4 major incidents**.
*   **Qualitative Assessment:** Results suggest that while current frontier AI approaches rely on unstructured methods (like workshops), STPA provides a deeper and more accurate understanding of causal factors.
*   **Safety Cases:** This deeper understanding enables higher assurance levels in safety cases compared to existing methods.