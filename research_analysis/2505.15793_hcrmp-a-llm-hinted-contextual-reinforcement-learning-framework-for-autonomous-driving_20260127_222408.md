---
title: 'HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous
  Driving'
arxiv_id: '2505.15793'
source_url: https://arxiv.org/abs/2505.15793
generated_at: '2026-01-27T22:24:08'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# HCRMP: A LLM-Hinted Contextual Reinforcement Learning Framework for Autonomous Driving

*Large Language, Tongji University, Hanming Deng, Guizhe Jin, Ran Yu, Zhuoren Li, Huanxi Wen, Time Research, Zhiwen Chen, Bo Leng*

---

### üìä Quick Facts

| Metric | Value |
| :--- | :--- |
| **Task Success Rate** | 80.3% |
| **Collision Rate Reduction** | 11.4% |
| **LLM Non-Hallucination Rate** | ~57.95% |
| **Action Space** | Continuous (Beta Distribution) |
| **Quality Score** | 9/10 |
| **Citations** | 40 |

---

## üìã Executive Summary

The integration of Large Language Models (LLMs) into Reinforcement Learning (RL) for autonomous driving faces critical barriers, including a high propensity for LLM hallucinations (with only a ~57.95% non-hallucination rate) and frequency mismatch between discrete language generation and continuous vehicle control. These issues pose significant safety risks when relying on LLMs to generate driving policies directly, particularly in real-time applications requiring low latency.

This paper introduces **HCRMP**, a weakly coupled framework proposing a novel 'LLM-Hinted RL' paradigm. In this approach, the LLM functions solely as a semantic hint generator for state augmentation rather than a direct policy controller. The architecture consists of three core modules: the **Augmented Semantic Representation (ASR)** module; the **Contextual Stability Anchor (CSA)**, which utilizes external knowledge and Multi-Critic networks to generate reliability weights; and the **Semantic Cache Module (SCM)**, which employs Top-K embedding search to synchronize low-frequency LLM guidance with high-frequency RL control loops.

Empirical validation in the CARLA simulator demonstrates HCRMP's efficacy, achieving an **80.3% task success rate** and reducing collision rates by **11.4%** under safety-critical conditions. When benchmarked against *HighwayLLM* and *LearningFlow*, HCRMP exhibited lower vulnerability to hallucinations and output instability, proving its ability to leverage semantic insights without succumbing to semantic errors.

The significance of this research lies in its paradigm shift from direct LLM control to a hinted, reliability-focused architecture that effectively mitigates hallucination risks in safety-critical environments.

---

## üîë Key Findings

*   **High Task Success Rate:** The proposed HCRMP framework achieved a robust task success rate of **80.3%** within the CARLA simulator environment.
*   **Improved Safety:** Under safety-critical conditions, the framework successfully reduced the collision rate by **11.4%**.
*   **LLM Hallucination Risks:** Analysis of the Gemini-2.5-Pro LLM revealed a non-hallucination rate of only approximately **57.95%** on driving-related tasks, highlighting the danger of direct LLM control.
*   **Independence Drives Reliability:** Maintaining relative independence between the LLM and the RL agent is identified as a crucial factor in counteracting potential hallucinations.
*   **Superior Robustness:** Compared to baselines like *HighwayLLM* and *LearningFlow*, HCRMP demonstrates significantly lower vulnerability to LLM output fluctuations.

---

## üß¨ Methodology

The paper proposes an **LLM-Hinted Contextual Reinforcement Learning** paradigm designed to leverage the semantic reasoning of LLMs while mitigating their reliability issues.

*   **Core Concept:** The LLM is used **solely to generate semantic hints** for state augmentation rather than direct control policies.
*   **Architecture:** The HCRMP framework is built upon three core modules designed to bridge the gap between semantic understanding and continuous control:
    1.  **Augmented Semantic Representation Module:** Extends the state space to include high-level semantic context.
    2.  **Contextual Stability Anchor Module:** Enhances reliability by utilizing a knowledge base to weigh the utility of LLM hints.
    3.  **Semantic Cache Module:** Integrates low-frequency LLM guidance with high-frequency RL control loops to ensure smooth operation.

---

## ‚öôÔ∏è Technical Details

**Framework Type:** Weakly Coupled LLM-Hinted Contextual Reinforcement Learning.

**Core Modules:**
*   **Augmented Semantic Representation (ASR):** Responsible for hierarchical scenario reasoning and state augmentation.
*   **Contextual Stability Anchor (CSA):** Utilizes external knowledge and a Multi-Critic network to generate distinct weights for Safety, Efficiency, and Comfort.
*   **Semantic Cache Module (SCM):** Uses Top-K embedding search to bridge the frequency gap between slow LLM guidance and fast RL control.

**System Modeling:**
*   **Environment:** Modeled as a Markov Decision Process (MDP).
*   **Policy:** Deep Neural Network (DNN).
*   **Action Spaces:** Continuous controls for throttle/brake and steering.
*   **Constraints:** Actions are constrained to the range `[-1, +1]` and sampled from a **Beta distribution**.

---

## üìà Results

The performance of HCRMP was evaluated using extensive experiments in the CARLA simulator and analysis of underlying LLM capabilities.

*   **Benchmark Performance:**
    *   **Task Success Rate:** 80.3%
    *   **Collision Rate Reduction:** 11.4% (specifically noted under safety-critical conditions).
*   **LLM Reliability Analysis:**
    *   Analysis of the *Gemini-2.5-Pro* model showed a non-hallucination rate of **~57.95%** on driving tasks.
*   **Comparative Analysis:**
    *   Against *HighwayLLM* and *LearningFlow*, HCRMP showed:
        *   Lower vulnerability to LLM hallucinations.
        *   Greater resilience against output fluctuations.

---

## üöÄ Contributions

1.  **Paradigm Shift:** Introduces the novel 'LLM-Hinted RL' paradigm, specifically addressing hallucination problems by maintaining relative independence between the LLM and the RL agent.
2.  **Architectural Innovation:** Designs the HCRMP framework to specifically address frequency mismatch and reliability issues inherent in continuous control loops.
3.  **Validation of Robustness:** Provides empirical evidence demonstrating that an RL agent capable of learning to filter and utilize LLM hints achieves superior safety and performance metrics compared to direct integration methods.