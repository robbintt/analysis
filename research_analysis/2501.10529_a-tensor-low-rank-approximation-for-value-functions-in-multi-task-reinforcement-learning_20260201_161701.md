# A Tensor Low-Rank Approximation for Value Functions in Multi-Task Reinforcement Learning
*Sergio Rozada; Santiago Paternain; Juan Andres Bazerque; Antonio G. Marques*

***

> ### ðŸ“Š Quick Facts
> *   **Algorithm:** S-TLR-Q (Shared Tensor Low-Rank Q-learning)
> *   **Focus:** Multi-Task Reinforcement Learning (MT-RL) & Tensor Decomposition
> *   **Primary Validation:** Inverted Pendulum & Wireless Communications
> *   **Quality Score:** 6/10
> *   **References:** 31 Citations

***

## Executive Summary

This research addresses the critical bottleneck of data inefficiency in Multi-Task Reinforcement Learning (MT-RL), specifically within tabular settings prevalent in physical control systems. Acquiring the massive datasets required for independent reinforcement learning is often impractical in real-world scenarios. While multi-task learning mitigates this by transferring knowledge, existing approaches typically rely on the explicit pre-definition of task relationships or clustering, which is difficult to scale.

This paper targets the dual challenges of removing manual task specification and reducing high sample complexity. The core innovation is the introduction of **S-TLR-Q** (Shared Tensor Low-Rank Q-learning), a framework that models Q-functions across multiple tasks as a unified, higher-order "Q-tensor". By imposing a low-rank constraint on this aggregated tensor, the method establishes an implicit algebraic inductive bias for task relatedness without external supervision.

Technically, the algorithm utilizes stochastic optimization to simultaneously decompose this tensor into latent components and task-specific coefficients. This joint optimization scheme allows updates from one task to propagate across the system, automatically inferring similarities from the data structure. Validated across Inverted Pendulum control and wireless communication setups, S-TLR-Q achieved faster convergence and reduced sample complexity compared to independent learning methods. By successfully removing the requirement for manual task relationship specification, this research significantly lowers the barrier for applying MT-RL to complex engineering problems where data acquisition is naturally constrained.

***

## Key Findings

*   **Implicit Similarity Learning:** The proposed low-rank tensor approach successfully enforces task similarity without requiring explicit definitions or prescriptions of which tasks are related.
*   **Data Efficiency:** The method enables the inference of task similarities and optimization of the Q-tensor using significantly reduced amounts of data.
*   **Broad Applicability:** The efficiency of the approach was validated in diverse scenarios, ranging from a classic benchmark environment (inverted pendulums) to a practical application (wireless communication devices).
*   **Action Correlation:** The research confirms that closely related tasks require similar actions, which is effectively captured by the low-rank structure.

***

## Methodology

The research approach shifts traditional RL paradigms by utilizing tensor algebra to solve multi-task problems.

*   **Problem Formulation:** Multi-task RL in a tabular scenario is modeled as the optimization of a higher-order tensor structure composed of Q-functions collected across different tasks.
*   **Constraint Application:** A low-rank condition is imposed on the aggregated Q-tensor. This mathematical constraint serves as a proxy for task relatedness, enforcing that the data lies in a lower-dimensional subspace.
*   **Optimization Process:** The method utilizes stochastic optimization to simultaneously learn the Q-tensor and infer task relationships from the data structure, rather than relying on pre-defined task clusters.

***

## Technical Details

### Algorithm: S-TLR-Q (Shared Tensor Low-Rank Q-learning)

The S-TLR-Q framework centers on representing Q-functions via a "Q-tensor" to implicitly enforce task similarity.

*   **Core Structure:**
    *   Utilizes a tensor low-rank representation for Q-functions.
    *   Updates distinct components (`Q1`, `Q2`, `Q3`) and task-specific coefficients (`Qm`) through a joint multi-task optimization scheme.
    *   **Cross-Task Influence:** Updates in one task affect all others via the tensor decomposition.

*   **Initialization & Parameters:**
    *   Components are initialized via `Uniform(0, 1)`.
    *   Updates utilize a learning rate `Î·(n)` and parameter `Ïµ` according to specific equations (6a-c, 9a-c).
    *   The process runs for a predefined number of iterations `N`.

*   **Baselines for Comparison:**
    *   Independent LR-Q
    *   Shared C-LR-Q

***

## Results

Experiments were conducted primarily on the **Inverted Pendulum** control problem and secondarily on a **Wireless Communications** setup.

### 1. Inverted Pendulum Experiment
*   **Setup:** Stabilization of an underactuated pendulum across `M=4` tasks with varying mass (`g=[0.01, 0.1, 0.5, 1.0]`) and length (`d=[1.0, 1.0, 0.5, 0.5]`).
*   **Metrics:** Convergence speed, sample complexity, and policy structural similarity.
*   **Outcomes:**
    *   Optimal policies were found to share similar structures (e.g., sign correlation between torque and angular velocity).
    *   Low-mass tasks stabilized faster, while large-mass tasks required greater torque.
    *   S-TLR-Q successfully inferred task similarities to optimize the Q-tensor with reduced data.

### 2. Wireless Communications Experiment
*   **Context:** Multi-user power control problem comprising `M=64` distinct interference tasks.
*   **Outcomes:** The approach optimized the network sum-rate effectively, maintaining near-optimal performance with significantly fewer samples than independent learning.

***

## Contributions

*   **Tensor-Based RL Framework:** Introduction of a novel higher-order tensor structure for representing Q-functions across multiple tasks, shifting away from traditional vector or matrix views.
*   **Unsupervised Task Similarity:** A mechanism to capture the notion of task similarity implicitly through low-rank approximation, removing the burden of manual task relationship specification.
*   **Physical World Viability:** Addressing the data acquisition bottleneck in RL for physical environments by leveraging multi-task learning (MTL) to reduce the need for massive datasets.

***

**References:** 31 citations | **Quality Score:** 6/10