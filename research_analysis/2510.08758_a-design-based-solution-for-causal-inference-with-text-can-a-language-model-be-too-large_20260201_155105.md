# A Design-based Solution for Causal Inference with Text: Can a Language Model Be Too Large?

*Graham Tierney; Srikar Katta; Christopher Bail; Sunshine Hillygus; Alexander Volfovsky*

---

> ### üìä Quick Facts
>
> *   **Quality Score:** 8/10
> *   **References:** 17 citations
> *   **Primary Metric:** Average Treatment Effect (ATE)
> *   **Target Variable:** Intellectual Humility (IH) in text
> *   **Key Insight:** High-performing LLMs risk overlap bias by encoding the treatment variable.
> *   **Best Performer:** Bag-of-Words (BoW) IPW models

---

## üìë Executive Summary

This research addresses the critical challenge of performing causal inference when text is the treatment variable, specifically the difficulty of isolating causal effects from latent confounders embedded within the text. As Large Language Models (LLMs) have become the standard for text representation, this paper exposes a fundamental vulnerability in their application to causal tasks: deep learning methods risk "overlap bias" by encoding the treatment variable itself rather than just the latent confounders. This occurs because LLM embeddings are often too effective at capturing semantic distinctions, creating distinct, non-overlapping latent regions between treated and control groups that invalidate standard causal adjustment techniques.

The authors introduce a novel design-based framework engineered to theoretically avoid overlap bias and control for latent confounders without relying on post-hoc statistical adjustments. Technically, the approach utilizes a semi-synthetic data generation process using real survey responses, generating 100 replicas of binary outcomes under both baseline and amplified confounding scenarios to establish a Ground Truth via a design-based estimator. The framework was validated by evaluating the causal impact of Intellectual Humility (IH) in political communication, comparing the proposed design against naive estimators (Difference-in-Means), traditional Bag-of-Words (BoW) models using cross-fitted random forests, and LLM-based methods like TextCause and Treatment Ignorant (TI).

The study found that simpler, traditional methods significantly outperformed deep learning approaches in recovering true causal effects. Under Baseline Confounding, naive methods and BoW models correctly identified null effects, whereas the LLM-based TextCause model failed. Under Amplified Confounding, naive methods failed due to omitted variable bias; however, BoW Inverse Probability Weighting (IPW) estimates consistently fell within the true Average Treatment Effect (ATE) confidence bands. Conversely, LLM-based estimators (TI, even with Winsorizing and Trimming applied to propensity scores) failed to estimate the true ATE. The LLM embeddings encoded the treatment variable, inducing overlap bias and causing estimators to drift outside the true confidence bands.

This paper significantly influences the field by empirically challenging the assumption that larger, more complex models are inherently better for causal discovery. It provides technical evidence that in causal inference tasks, the representational power of LLMs can be a liability, making Bag-of-Words models more robust against encoding treatment information.

---

## üîë Key Findings

*   **LLM Limitations:** LLM-based methods for causal inference performed worse than simple bag-of-words models when applied to real text and outcomes.
*   **Overlap Bias Risk:** Deep learning methods adapted for causal inference in text risk 'overlap bias' by encoding the treatment itself rather than just latent confounders.
*   **Humility & Persuasion:** The study successfully isolated the causal effect of expressing humility in political communication, finding it influences perceived persuasiveness.
*   **Design Over Post-Hoc:** The proposed experimental design effectively handles latent confounding and avoids overlap issues, unlike post-hoc adjustments.

---

## ‚öôÔ∏è Technical Details

*   **Problem Focus:** Causal inference with text as treatment; specifically targeting Intellectual Humility (IH).
*   **Confounder:** Addresses latent confounding via 'respectfulness'.
*   **Data Generation:**
    *   Semi-synthetic process using real survey responses.
    *   Created **100 replicas** of binary outcomes.
    *   Scenarios: Baseline and Amplified confounding.
*   **Estimators Evaluated:**
    *   *Naive:* Difference-in-Means, Topic Adjustment.
    *   *Traditional:* Bag-of-Words (BoW) using cross-fitted random forests (Outcome Regression, IPW, AIPW).
    *   *Deep Learning:* TextCause, Treatment Ignorant (TI).
*   **Data Handling:**
    *   Winsorizing and Trimming applied to TI models to handle extreme propensity scores.
    *   Scores constrained to the **[0.1, 0.9]** range.

---

## üìâ Results

The primary evaluation metric was the Average Treatment Effect (ATE), with Ground Truth established by the 2.5‚Äì97.5 percentiles of a design-based estimator.

### Scenario A: Baseline Confounding
*   **Naive Methods:** Correctly identified the null effect.
*   **Bag-of-Words:** Performed well.
*   **LLMs:** **TextCause failed** to identify the null effect.

### Scenario B: Amplified Confounding
*   **Naive Methods:** Failed due to omitted variable bias.
*   **Bag-of-Words:** IPW estimates consistently fell within the true ATE confidence bands.
*   **LLMs:** Both **TI and TextCause failed**. LM embeddings encoded the treatment variable, creating distinct latent regions for treated and control groups, which induced overlap bias.

---

## üöÄ Contributions

*   **Framework:** A design-based framework for text-based causal inference that theoretically avoids overlap bias and controls for latent confounders without post-hoc adjustments.
*   **Critique:** A technical critique of LLMs, offering empirical evidence that simpler models (BoW) may be more robust against encoding treatment information in causal tasks.
*   **Communication Insights:** Substantive findings regarding the specific causal impact of humility on persuasiveness in political communication.

---

**Quality Score:** 8/10  
**References:** 17 citations