---
title: 'Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence
  Policy Optimization'
arxiv_id: '2510.22477'
source_url: https://arxiv.org/abs/2510.22477
generated_at: '2026-02-03T13:19:13'
quality_score: 8
citation_count: 0
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization

*Yijia Fan; Jusheng Zhang; Jing Yang; Keze Wang*

---

> ### ðŸ“Š Quick Facts
>
> *   **Performance:** Achieved State-of-the-Art (SOTA) results on **7** reasoning benchmarks.
> *   **Cost Efficiency:** Reduced communication overhead by nearly **50%**.
> *   **Core Algorithm:** Group Sequence Policy Optimization (GSPO).
> *   **Emergent Behavior:** Developed "Strategic Silence" (communicating only when necessary).
> *   **Rating:** **8/10**

---

## Executive Summary

This research addresses the critical bottleneck of prohibitive communication costs in Large Language Model (LLM)-based Multi-Agent Systems (MAS). In existing "free-for-all" architectures, agents often communicate excessively, leading to high token consumption, increased latency, and economic inefficiency. This verbosity limits the scalability and practical viability of deploying multi-agent systems for complex reasoning tasks, as the computational overhead of communication often outweighs the benefits of collaboration.

The authors introduce **Agent-GSPO**, a novel framework built upon the Group Sequence Policy Optimization (GSPO) algorithm. Unlike standard approaches that treat communication as a byproduct of the task, GSPO utilizes sequence-level reinforcement learning to directly optimize for "token economy." The core technical innovation lies in a communication-aware reward function that explicitly penalizes verbosity while maximizing task performance. By training agents to minimize unnecessary communication tokens without sacrificing accuracy, the algorithm achieves stable and memory-efficient convergence, effectively teaching agents the economic value of information.

Agent-GSPO achieved new state-of-the-art results across seven specific reasoning benchmarks: **GSM8K, MATH, HumanEval, MBPP, StrategyQA, Sports Understanding, and Checkmate**. Crucially, this superior performance was delivered while drastically reducing resource usage; the framework successfully cut communication overhead by **nearly 50%** compared to existing methods. This demonstrates that the framework not only outperforms baselines in reasoning capability but does so with substantially greater economic efficiency.

The significance of this work lies in establishing a practical blueprint for creating multi-agent systems that are both scalable and economically viable. Beyond raw metrics, the training process yielded an emergent behavior known as "strategic silence," where agents learned to autonomously withhold communication unless it was strictly necessary to solve the task. By proving that high performance does not require high communication bandwidth, Agent-GSPO shifts the optimization focus for MAS from purely accuracy-based metrics to efficiency-aware objectives, paving the way for the deployment of complex, multi-agent architectures in resource-constrained or cost-sensitive commercial environments.

---

## Key Findings

*   **State-of-the-Art Performance:** Agent-GSPO achieved new SOTA results across seven different reasoning benchmarks.
*   **Significant Cost Reduction:** The framework delivers superior performance while consuming only a fraction of the tokens (communication overhead) required by existing methods.
*   **Emergent Communication Strategies:** The training process led to the development of "strategic silence," where agents learn to communicate only when necessary.
*   **Algorithmic Efficiency:** The Group Sequence Policy Optimization (GSPO) algorithm was proven to be both stable and memory-efficient during training.

---

## Methodology

The researchers introduced **Agent-GSPO**, a framework built upon the Group Sequence Policy Optimization (GSPO) algorithm. The methodology utilizes sequence-level reinforcement learning to directly optimize for token economy. Specifically, the agents are trained using a communication-aware reward function that explicitly penalizes verbosity, thereby incentivizing agents to minimize unnecessary communication while maximizing task performance.

---

## Contributions

*   **Novel Framework and Algorithm:** Introduction of Agent-GSPO and the GSPO algorithm, providing a new stable and memory-efficient tool for training multi-agent systems (MAS).
*   **Economic Viability:** Addressing the critical bottleneck of prohibitive communication costs in "free-for-all" MAS by shifting the optimization focus to token economy.
*   **Blueprint for Scalability:** Establishing a practical blueprint for creating multi-agent systems that are both scalable and economically viable, demonstrating that high performance does not require high communication bandwidth.

---

## Technical Details

*   **Core Algorithm:** Group Sequence Policy Optimization (GSPO).
*   **Learning Paradigm:** Sequence-level Reinforcement Learning (RL).
*   **Optimization Target:** Direct optimization for "token economy" rather than treating communication as a secondary byproduct.
*   **Reward Mechanism:** Implementation of a communication-aware reward function that balances task performance maximization against verbosity penalties.
*   **Training Characteristics:** The approach is designed to ensure memory efficiency and convergence stability during the training phase.

---

## Results

*   **Benchmark Performance:** Attained state-of-the-art performance on seven distinct reasoning benchmarks (GSM8K, MATH, HumanEval, MBPP, StrategyQA, Sports Understanding, and Checkmate).
*   **Token Efficiency:** Successfully reduced communication overhead by nearly 50% compared to existing baseline methods.
*   **Resource Utilization:** Demonstrated that superior reasoning capabilities can be achieved with substantially lower economic and computational costs.

---

**Document Statistics**
*   **Quality Score:** 8/10
*   **References:** 0 citations