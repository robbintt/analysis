---
title: 'LLM-Sketch: Enhancing Network Sketches with LLM'
arxiv_id: '2502.07495'
source_url: https://arxiv.org/abs/2502.07495
generated_at: '2026-01-27T22:58:55'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LLM-Sketch: Enhancing Network Sketches with LLM

*Yannan Hu, Zhongguancun Laboratory, Enhancing Network, Zongwei Lv, Yuanpeng Li, Zhejiang University, Peking University, Zhen Xu*

---

### üìä Quick Facts

| Metric | Detail |
| :--- | :--- |
| **Accuracy Improvement** | 7.5√ó vs. state-of-the-art |
| **Memory Overhead** | No additional penalty |
| **Core Technology** | Fine-tuned BERT-like LLM |
| **Architecture** | Two-tier (Heavy/Light Parts) |
| **Validation Tasks** | Flow Size, Heavy Hitter (HH), Hierarchical Heavy Hitter (HHH) |

---

## üöÄ Executive Summary

Traditional network stream mining faces a fundamental trade-off between memory constraints and measurement accuracy. Standard sketching algorithms rely on static hashing and randomization, treating packet headers merely as flow identifiers (e.g., 5-tuples) and ignoring the semantic information available in other header fields. Previous efforts to integrate machine learning into these structures have been stymied by high training costs and an inability to adapt to dynamic network patterns. Consequently, there is a need for a solution that maintains high-precision flow size estimation within the strict memory limits of high-speed network devices.

**LLM-Sketch** introduces a framework that integrates a fine-tuned BERT-like Large Language Model (LLM) into a hierarchical two-tier data structure. The architecture decouples memory management by utilizing a "heavy part" (Key-Value table) for large flows and a "light part" (optimized Count-Min Sketch with 8-bit counters) for small flows. The core innovation lies in using the LLM as a semantic classifier to analyze non-flow-ID packet header fields, extracting features to predict flow sizes. This model guides routing decisions: when new flows arrive and space is constrained, the LLM infers the flow's potential size to determine whether it should be stored in the heavy part, directed to the light part, or trigger an eviction. By conditionally invoking the LLM only during insertion and eviction events, the system attempts to mitigate the inherent inference latency costs associated with deep learning models.

In benchmark evaluations against state-of-the-art methods, LLM-Sketch achieved up to a **7.5√ó improvement** in estimation precision across three primary tasks: Flow Size Queries ($n(f)$), Heavy Hitter (HH) Queries, and Hierarchical Heavy Hitter (HHH) Queries. Significantly, this performance gain was realized without incurring additional memory overhead, maintaining a footprint comparable to existing sketches. The system successfully validated that semantic features from packet headers could be leveraged to reduce error rates more effectively than randomization-based approaches.

This research demonstrates the viability of incorporating Large Language Models into resource-constrained streaming data architectures, moving beyond reliance on static flow keys. By validating that non-flow-ID header fields contain highly predictive signals for network traffic, the authors establish a new direction for semantic-aware traffic analysis. LLM-Sketch bridges the gap between deep learning capabilities and practical network systems, offering a solution to the historical challenges of training costs and adaptivity that have limited machine learning in network telemetry.

---

## üîë Key Findings

*   **Significant Accuracy Boost:** LLM-Sketch achieves a **7.5√ó improvement** in accuracy compared to state-of-the-art methods.
*   **Effective Feature Utilization:** Information contained in packet header fields beyond flow IDs can be effectively utilized to infer flow sizes.
*   **Memory Efficiency:** The proposed system improves accuracy without a corresponding penalty on memory overhead.
*   **LLM Viability:** Fine-tuned Large Language Models (LLMs) can reliably estimate flow sizes within the context of network stream mining.

---

## üõ†Ô∏è Methodology

The research methodology relies on a hybrid approach combining advanced data structures with deep learning inference:

*   **Data Structure:** A two-tier data structure separates the recording of 'large flows' and 'small flows' to optimize memory usage.
*   **Inference Engine:** The system employs **fine-tuned Large Language Models (LLMs)** as the core inference engine to estimate flow sizes.
*   **Feature Analysis:** Unlike traditional methods, the model analyzes a broader set of features from packet headers, specifically fields other than flow IDs.
*   **Validation:** The methodology was validated against existing benchmarks using three representative network stream mining tasks.

---

## ‚öôÔ∏è Technical Details

### System Architecture
The system utilizes a hierarchical architecture designed to handle different flow magnitudes efficiently:

*   **Heavy Part:** A Key-Value table consisting of $w_h$ buckets and $d_h$ cells. This is reserved for large flows.
*   **Light Part:** An optimized Count-Min Sketch utilizing 8-bit counters. This handles small flows.

### Operational Logic
The LLM-Sketch operates through a specific packet routing and decision-making process:

1.  **Classification:** Employs a fine-tuned LLM (BERT-like) as a flow classifier to predict if a flow will become large based on packet headers.
2.  **Mapping:** Packets are mapped to buckets.
    *   If the flow exists, its counter is incremented.
    *   If it is a new flow and space is available, it is inserted.
3.  **Contention Handling (Bucket Full):** When the bucket is full, the LLM predicts the flow size.
    *   **Predicted 'Large':** The minimum size flow is evicted to the light part.
    *   **Predicted 'Small':** The packet goes directly to the light part.
4.  **Querying:** Queries check the heavy part first before falling back to the light part.

---

## üìÅ Contributions

*   **Framework Introduction:** Introduced the **LLM-Sketch framework**, a novel sketching solution that integrates Large Language Models into network data structures. This approach overcomes the high training costs and adaptivity issues of previous methods.
*   **Feature Validation:** Established the value of using **non-flow-ID header fields** for flow size inference.
*   **Resource Optimization:** Optimized the **resource-accuracy trade-off** by decoupling large and small flows into a two-tier structure to balance memory constraints with high-precision measurements.

---

## üìà Results

*   **Accuracy:** Achieved a **7.5√ó improvement** in accuracy compared to state-of-the-art methods.
*   **Memory:** Maintained memory efficiency without overhead penalties.
*   **Reliability:** The system reliably estimates flow sizes using packet header information.
*   **Metrics:** Defines metrics for:
    *   Flow Size Queries ($n(f)$)
    *   Heavy Hitter (HH) Queries
    *   Hierarchical Heavy Hitter (HHH) Queries

---

**Quality Score:** 8/10  
**References:** 40 citations