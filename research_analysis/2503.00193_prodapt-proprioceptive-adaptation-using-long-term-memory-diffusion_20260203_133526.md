---
title: 'ProDapt: Proprioceptive Adaptation using Long-term Memory Diffusion'
arxiv_id: '2503.00193'
source_url: https://arxiv.org/abs/2503.00193
generated_at: '2026-02-03T13:35:26'
quality_score: 9
citation_count: 32
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# ProDapt: Proprioceptive Adaptation using Long-term Memory Diffusion

*Federico Pizarro Bejarano; Bryson Jones; Daniel Pastor Moreno; Joseph Bowkett; Paul G. Backes; Angela P. Schoellig*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 9/10
> *   **Hardware Platform:** UR10e Robotic Arm
> *   **Key Innovation:** Keypoint Manager (Long-term Memory)
> *   **Inference Time:** < 0.1s (Real-time capable)
> *   **Top Performance:** 80% success rate (Elbow task) vs. 0% for baselines
> *   **References:** 32 citations

---

## Executive Summary

### Problem
Robotic manipulation and navigation traditionally rely heavily on exteroceptive sensors, such as cameras or LiDAR, to perceive the environment and avoid obstacles. However, in high-stakes domains like space exploration, underwater operations, and military scenarios, visual feedback is often unreliable, degraded, or entirely unavailable due to harsh conditions. This paper addresses the critical challenge of enabling robots to complete complex tasks using only proprioceptive dataâ€”internal joint torques and positionsâ€”without any visual input. The authors establish that while reactive short-term policies are insufficient for these tasks, there is a lack of effective methods for integrating long-term interaction history into control policies to compensate for the absence of sight.

### Innovation
The authors introduce **ProDapt**, a novel imitation learning framework that modifies diffusion models to operate effectively using solely proprioceptive information. The core technical innovation is the integration of a "Keypoint Manager," a long-term memory mechanism that filters continuous proprioceptive measurements to detect and store unique obstacle contacts as specific "keypoints." Unlike standard approaches that rely on a sliding window of recent observations, ProDapt utilizes these stored historical keypoints as explicit conditional inputs to a denoising diffusion probabilistic model (DDPM). This architecture allows the robot to maintain a memory of past interactions with the environment, enabling a receding-horizon control policy that adapts its trajectory based on a history of tactile events rather than real-time visual feedback.

### Results
The framework was validated on a `UR10e` robotic arm across four distinct environments (Clear, Wall, Bucket, Elbow) in both simulation and the real world. ProDapt demonstrated a decisive advantage over standard diffusion baselines with varying observation horizons. In the most complex "Elbow" task, ProDapt achieved an **80% success rate**, compared to a **0% success rate** for all baseline models. It also outperformed baselines in the "Bucket" task and exhibited superior generalization to real-world scenarios, where low-horizon baselines failed significantly. Operationally, ProDapt completed tasks faster by avoiding the "diagonal drift" heuristic common in other methods and met strict real-time constraints (<0.1s inference time), whereas testing baselines with observation horizons exceeding 50 was computationally infeasible.

### Impact
This research significantly advances the field of sensor-deprived robotics by proving that long-term memory is a strict requirement for task completion when exteroceptive feedback is absent. ProDapt provides a robust solution for operating in environments where visual sensors are likely to fail or are impractical, thereby expanding the operational envelope of autonomous systems. By demonstrating that complex manipulation can be achieved through touch and internal state alone, this work paves the way for more reliable robots in critical applications such as satellite repair, deep-sea infrastructure maintenance, and search-and-rescue missions in visually obscured conditions.

---

## Key Findings

*   **Proprioceptive Success:** The study demonstrates that robots can successfully complete complex tasks using only proprioceptive data without exteroceptive sensors.
*   **Memory Necessity:** Long-term memory is strictly necessary for task completion in the absence of visual environmental feedback.
*   **Harsh Environment Robustness:** The approach provides superior robustness for harsh environments such as space, military, and underwater applications.
*   **Validation:** The proposed method was validated using a `UR10e` robotic arm in both simulated and real-world experiments.

---

## Methodology

The framework utilizes diffusion models for imitation learning, modified to operate without reliance on visual or exteroceptive inputs. It incorporates a long-term memory mechanism to track the history of interactions between the robot and the environment.

*   **Core Strategy:** Identifying **'keypoints'**â€”specific essential past observations or contactsâ€”which are stored and maintained as active inputs to the policy.
*   **Evaluation:** The methodology was evaluated on a `UR10e` robotic arm in both simulation and real-world setups.

---

## Technical Details

| Component | Description |
| :--- | :--- |
| **Policy Architecture** | Diffusion-based control policy conditioned on a long-term memory mechanism (Keypoint Manager). |
| **Input Data** | Navigation using only proprioceptive data (Torque/Position). |
| **Memory Mechanism** | The **Keypoint Manager** filters proprioceptive measurements to detect and store unique obstacle contacts as 'keypoints,' serving as explicit long-term memory. |
| **Core Model** | Utilizes a Denoising Diffusion Probabilistic Model (`DDPM`) with a receding-horizon approach to generate actions based on previous observations and selected keypoints. |
| **Hardware Specs** | Validated on a `UR10e` arm with a custom 3D-printed cylindrical end-effector (for increased torque sensitivity) and includes force limiting for safety. |

---

## Results

The system was tested in four environments (Clear, Wall, Bucket, Elbow) against diffusion baselines with varying observation horizons (3, 6, 20, 50) on Intel NUC Extreme hardware.

*   **Elbow Task Performance:** ProDapt achieved an **80% success rate** compared to **0%** for all baselines.
*   **Bucket Task:** ProDapt outperformed baselines significantly.
*   **Real-World Generalization:** ProDapt generalized well to real-world scenarios, whereas low-horizon baselines performed significantly worse in reality.
*   **Speed & Efficiency:** ProDapt completed tasks faster than baselines in all real-world setups, avoiding the 'diagonal drift' heuristic seen in baselines.
*   **Computational Feasibility:**
    *   **ProDapt:** Inference time comparable to low-horizon baselines (meeting the <0.1s real-time constraint).
    *   **Baselines:** Testing with observation horizons >50 was infeasible due to computation time.

---

## Contributions

1.  **Novel Method:** Introduction of **ProDapt**, enabling imitation learning via diffusion models to adapt using solely proprioceptive information.
2.  **Technical Advancement:** Integration of historical context into the diffusion process through the identification and maintenance of 'keypoints.'
3.  **Domain Solution:** A robust operational solution for sensor-deprived environments, addressing challenges in high-risk domains like space, underwater, and military operations.