# Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings

*Tianzhi He; Farrokh Jazizadeh*

---

> ### ðŸ“Š Quick Facts Sidebar
>
> *   **Quality Score**: 8/10
> *   **Total Observations**: 480
> *   **Academic Citations**: 40
> *   **Test Scope**: 4 Buildings, 120 User Queries
> *   **Top Performance**: 97% (Memory Tasks)
> *   **Lowest Performance**: 49% (Cost Estimation)
> *   **Statistical Validation**: ANOVA Tests Passed

---

## Executive Summary

This paper addresses the challenge of making complex Building Energy Management Systems (BEMS) more accessible and intuitive for non-expert users. Traditional systems often lack the interface capabilities necessary for effective human interaction, creating a barrier to optimizing energy usage in smart environments. By leveraging Large Language Models (LLMs), the research aims to bridge the gap between high-dimensional building data and user-friendly operation, enabling energy management through natural language. This matters because improving human-centered interaction is essential for increasing user adoption and realizing the full energy-saving potential of smart buildings.

The key innovation is a closed-loop, context-aware framework that integrates LLMs directly into BEMS using a tool-calling paradigm. The system architecture is composed of three modules: Perception (sensing data), Central Control (LLM-driven reasoning), and Action (actuation and user feedback). Technically, the agent employs a Code Interpreter for data processing, utilizes Intent Classification to categorize user queries into six primary and twenty-four secondary categories, and uses Chain-of-Thought (CoT) planning to execute dynamic modeling tools such as Linear Regression, ARIMA, and Moving Average. This allows the system to autonomously interpret natural language, visualize data, and control devices based on real-time context.

The prototype was evaluated against 120 user queries across four real-world residential datasets, totaling 480 observations. Performance varied significantly by task complexity: operational tasks achieved high accuracy with 97% for memory tasks and 86% for device control. Analytical tasks showed moderate success, with 77% accuracy in energy analysis and 74% in scheduling, but notably lower performance in cost estimation at 49%. The agent preferred simpler models for prediction, utilizing Linear Regression six times compared to two uses each for ARIMA and Moving Average. Additionally, ANOVA tests confirmed the statistical generalizability of the results across different building types and seasons, though a trade-off between response accuracy and computational efficiency was identified.

This research significantly influences the field by establishing a standardized benchmarking methodology for LLM-based agents in the energy domain, moving the industry toward formal assessment protocols rather than ad-hoc evaluations. By rigorously defining current capabilities and limitationsâ€”such as the specific difficulty agents face with cost estimationâ€”the study provides a clear roadmap for future development. These findings validate the viability of LLMs for human-building interaction while highlighting critical technical gaps, offering a foundational baseline for researchers and engineers aiming to deploy reliable, context-aware AI solutions in smart building infrastructure.

---

## Key Findings

*   **High Performance in Operational Tasks**: The agent demonstrated exceptional reliability in memory tasks and device control, achieving **97%** and **86%** accuracy, respectively.
*   **Moderate Success in Analytical Tasks**: Performance dipped in complex analytical areas:
    *   Scheduling: **74%** accuracy
    *   Energy Analysis: **77%** accuracy
    *   Cost Estimation: **49%** accuracy (a significant identified weakness)
*   **Statistical Generalizability**: Results were validated using ANOVA tests, confirming that the system's performance is generalizable across diverse real-world datasets.
*   **Efficiency-Accuracy Trade-off**: The study identified a critical trade-off between the response accuracy of the LLM and the computational efficiency of the system, a key consideration for real-time applications.

---

## Methodology

The study employed a structured three-module conceptual framework to test the viability of LLMs in energy systems:

1.  **Framework Architecture**
    *   **Perception**: Responsible for sensing environmental and system data.
    *   **Central Control**: Utilized LLMs for analytics, reasoning, and decision-making.
    *   **Action**: Handled actuation of devices and user interaction loops.

2.  **Evaluation Protocol**
    *   **Dataset**: 120 user queries tested against four distinct real-world residential energy datasets.
    *   **Metrics**: Performance was measured using multi-dimensional metrics, including:
        *   Latency
        *   Functionality
        *   Capability
        *   Accuracy
        *   Cost-effectiveness
    *   **Validation**: Statistical significance of the results was validated via ANOVA tests.

---

## Technical Details

The system architecture is built upon a sophisticated tool-calling paradigm designed to bridge natural language with building operations.

**Architecture & Workflow**
*   **Intent Classification**: Utilizes a hierarchy of 6 Primary and 24 Secondary categories to understand user requests.
*   **Planning**: Implements Chain-of-Thought (CoT) planning strategies.
*   **Execution**: Features Dynamic Modeling capabilities to handle time-series data and forecasting.

**Tooling Ecosystem**
The agent relies on a specific set of tools to interact with the building environment:
*   **Code Interpreter**: Processes data and generates visualizations.
*   **Simulated Smart Device API**: Interfaces with the digital twin of the building.
*   **Device Action Functions**:
    *   `ActionDeviceSync`
    *   `ActionDeviceQuery`
    *   `ActionDeviceExecute`

**Model Preferences**
*   **Linear Regression**: Most frequently used (6 instances).
*   **ARIMA**: Used sparingly (2 instances).
*   **Moving Average**: Used sparingly (2 instances).

**Evaluation Environment**
*   **Testbeds**: 4 distinct buildings.
*   **Logging**: All interactions were logged in Markdown files for traceability and analysis.

---

## Results

The evaluation comprised 480 observations across four buildings, with datasets ranging from 2,880 to 2,976 data points. The results highlight a distinct correlation between task complexity and accuracy:

| Task Category | Accuracy | Notes |
| :--- | :--- | :--- |
| **Memory Tasks** | 97% | Highest performing category. |
| **Device Control** | 86% | Strong operational performance. |
| **Energy Analysis** | 77% | Moderate success in analytical reasoning. |
| **Scheduling** | 74% | Moderate success in planning tasks. |
| **Cost Estimation** | 49% | Significant struggle with financial calculations. |

*   **Model Usage**: The agent consistently favored simpler models (Linear Regression) over complex ones for predictions to balance the efficiency-accuracy trade-off.
*   **Generalizability**: ANOVA tests confirmed that the results hold statistical significance across different building types and seasonal variations.

---

## Contributions

This research provides three pivotal contributions to the field of smart building energy management:

1.  **Context-Aware Framework**: Introduced a novel closed-loop framework that integrates LLMs into Building Energy Management Systems (BEMS). This enables context-aware natural language interaction, moving beyond rigid command interfaces.
2.  **Benchmarking Standardization**: Established a formalized assessment methodology specifically for LLM-based agents in the energy domain. This includes defined metrics and protocols for statistical testing, moving the field away from ad-hoc evaluations.
3.  **Identification of Research Gaps**: Clearly delineated current capabilities and limitations (e.g., the specific difficulty of cost estimation). This transparency provides a necessary roadmap for future research and development.

---

**References:** 40 citations