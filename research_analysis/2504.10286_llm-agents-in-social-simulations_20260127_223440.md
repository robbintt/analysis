---
title: LLM agents in social simulations
arxiv_id: '2504.10286'
source_url: https://arxiv.org/abs/2504.10286
generated_at: '2026-01-27T22:34:40'
quality_score: 7
citation_count: 13
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# LLM Agents in Social Simulations

*Yiming Zhu, Gareth Tyson, Pan Hui, Yupeng He, The Hong Kong University, Ul Haq, The Chirper, Social Network*

---

### ðŸ“Š Quick Facts

| Metric | **LLM Agents (Chirper.ai)** | **Human Users (Mastodon)** |
| :--- | :--- | :--- |
| **Population** | 65,856 Agents | 177,355 Users |
| **Total Content** | 7.7 Million (Posts + Comments) | 16.1 Million Posts |
| **Top Language** | English (69.39%) | English (52.62%) |
| **Data Period** | N/A (Snapshot) | Jan 1 â€“ Dec 31, 2024 |
| **Collection Method** | Python Selenium / BFS | Mastodon API |

---

## Executive Summary

This research addresses the critical validation gap regarding whether Large Language Model (LLM) agents can accurately serve as proxies for human behavior in social simulations. As LLM-driven agents increasingly populate digital environments to study sociology and collective behavior, it is vital to determine if their interactions and network formation mirror organic human processes. The paper confronts the issue that without rigorous empirical comparison, theories derived from AI-driven simulations may be fundamentally flawed, potentially misrepresenting the evolution and dynamics of real-world social networks.

The key innovation is the execution of a large-scale, head-to-head empirical analysis between an LLM-driven network and a human-driven one. Technically, the study establishes a benchmark by comparing **Chirper.ai** (an autonomous agent environment) against **Mastodon** (a human-centric social network). Data collection utilized Python Selenium WebDriver with a Breadth-First Search strategy, initiating from 41,689 seed agents to harvest 65,856 agent profiles and interactions. This contrasted with Mastodon data retrieved via API (spanning January to December 2024).

The analysis of over 7.7 million agent submissions against 16 million posts revealed distinct behavioral and structural divergences. Linguistically, LLM agents displayed a significant skew toward English, Japanese, and Chinese, while notably underutilized German and Spanish. Crucially, the study uncovered significant differences in **social network structures**, demonstrating that the topology, clustering, and evolution of agent networks deviate fundamentally from human norms.

This work provides a foundational benchmark for future research into collective behavior within AI-populated networks. By highlighting specific limitations and deviations in LLM decision-making and network structural evolution, the findings challenge the assumption that artificial agents perfectly mimic human social dynamics.

---

## Key Findings

*   **Distinct Behavioral Differences:** Clear divergences were identified between LLM agents and human users regarding posting behaviors, the nature of abusive content, and the formation of social network structures.
*   **Agent Profiling Baseline:** The study provides a comprehensive profile of how LLM agents function autonomously within the simulated Chirper.ai environment.
*   **Simulation vs. Reality Gap:** Findings highlight a significant divergence between LLM-driven simulations and organic human-driven networks, offering critical insights into the potential future evolution of social networks populated by AI.

---

## Methodology

The researchers conducted a large-scale comparative analysis between **LLM-driven data** from Chirper.ai and **human-driven data** from Mastodon.

The study examined specific dimensions including:
1.  **Posting Patterns:** Frequency, timing, and composition.
2.  **Abusive Content:** Prevalence and typologies of toxic language.
3.  **Network Structure:** Topological characteristics and clustering.

The approach focused on contrasting the autonomous outputs of agents against the organic behaviors of human users to validate the use of LLMs in sociological research.

---

## Technical Details

### Data Acquisition
*   **Chirper.ai (LLM Source):**
    *   **Tools:** Python Selenium WebDriver.
    *   **Strategy:** Breadth-First Search (BFS).
    *   **Scope:** Started from 41,689 seed agents, expanding via following, follower, and commenting links.
    *   **Data Points:** Agent profiles, posts, comments, and auto-generated backstories.
*   **Mastodon (Human Baseline):**
    *   **Tools:** Mastodon API (`/api/v1/timelines/public`).
    *   **Scope:** Data retrieved from `mastodon.social` spanning January 1, 2024, to December 31, 2024.
    *   **Processing:** Pre-processing included removing URLs, hashtags, mentions, and emojis.
*   **Analysis Tools:** Perspective API utilized for language detection and toxicology analysis.

### Agent Architecture
*   **Models:** Utilizes open-source LLMs, image generation models, and text-to-speech models.
*   **Initialization:** Agents are initialized by human prompts.
*   **Autonomy:** Once initialized, agents autonomously generate complex backstories.
*   **Interaction:** Agents operate within a community-based reward system.

---

## Results

### Dataset Scale
*   **Chirper.ai:** 65,856 agents, 1,486,356 posts, 6,296,779 comments (>7.7 million total submissions).
*   **Mastodon:** 177,355 users, 16,141,453 posts.

### Language Distribution
*   **English:** 69.39% (LLM) vs. 52.62% (Human).
*   **Japanese:** 18.49% (LLM) vs. 4.24% (Human).
*   **Chinese:** 8.43% (LLM) vs. N/A (Human).
*   **German:** 1.08% (LLM) vs. 6.65% (Human).
*   **Spanish:** 0.58% (LLM) vs. 5.20% (Human).

### Behavioral Analysis
*   **Submission Composition:** Distinct differences found in length, emoji usage, and hashtag frequency.
*   **Privacy:** LLM agents disclosed more personal information than human users.
*   **Abusive Content:** The prevalence and typologies of abusive content generated by agents differed markedly from human baselines.

---

## Contributions

*   **Bridging the Empirical Gap:** Provides research that directly compares LLM-driven social networks with human-driven networks, a previously underexplored area.
*   **Benchmark Establishment:** Establishes a large-scale benchmark (Chirper.ai vs. Mastodon) for future research into collective behavior in AI-populated networks.
*   **Understanding Limitations:** Enhances the understanding of LLM agent limitations by empirically contrasting their decision-making and outputs against real-world human data.

---

**Quality Score:** 7/10
**References:** 13 citations