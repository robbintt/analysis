---
title: On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems
arxiv_id: '2510.04311'
source_url: https://arxiv.org/abs/2510.04311
generated_at: '2026-01-27T21:10:32'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# On the Importance of Task Complexity in Evaluating LLM-Based Multi-Agent Systems

*Bohan Tang, Keyue Jiang, Xiaowen Dong, Huidong Liang*

***

> ### ðŸ“Š Quick Facts
> | Metric | Detail |
> | :--- | :--- |
> | **Quality Score** | 8/10 |
> | **References** | 40 Citations |
> | **Core Comparison** | LLM-MAS (Multi-Agent) vs. LLM-SAS (Single-Agent) |
> | **Key Variables** | Depth ($d$), Width ($w$) |
> | **Paradigm Studied** | Multi-Agent Debate |

***

## Executive Summary

The rapid proliferation of LLM-based multi-agent systems (LLM-MAS) has outpaced a rigorous understanding of their advantages over traditional single-agent systems (LLM-SAS). Current research is hindered by vague definitions of "task complexity," leading to inconsistent benchmarking and a lack of principled design guidelines. This paper addresses this gap by establishing a formal framework to characterize tasks, moving beyond qualitative descriptions to determine precisely when and why multi-agent architectures provide superior performance.

The authors introduce a theoretical 2D framework that decomposes task complexity into two distinct dimensions: **Depth ($d$)**, defined as the length of sequential reasoning required, and **Width ($w$)**, defined as the diversity of capabilities or micro-operations per step. Using a formalism where the per-step success rate is $s(w) \triangleq \prod_{j=1}^w q_j$, the study evaluates systems across both discriminative tasks (e.g., logical reasoning) and generative tasks (e.g., mathematical reasoning and creative writing). The LLM-MAS is implemented using a Multi-Agent Debate paradigm, where agents engage in iterative argumentation across multiple turns and a distinct Aggregator Agent synthesizes the final output.

Empirical evaluation, benchmarked mathematically via Relative Performance Gain (RPG), demonstrates that LLM-MAS advantages are not uniform but highly dependent on complexity dimensions. The study finds that while 'Width' correlates with improved performance, these gains eventually saturate due to diminishing returns. In contrast, 'Depth' is the decisive factor for unbounded performance gains; LLM-MAS significantly outperforms LLM-SAS in tasks requiring extensive sequential reasoning (e.g., Math Reasoning). The authors further provide a cost-benefit analysis of computational resources, concluding that the high token overhead of multi-agent debate is justified primarily for high-depth tasks, whereas for low-complexity or width-heavy tasks, the inference cost of LLM-MAS outweighs the marginal efficiency gains.

This work provides a foundational theoretical basis for the design of future AI architectures, shifting the field from ad-hoc system construction to complexity-aware engineering. By establishing that multi-agent systems should be prioritized specifically for deep, sequential reasoning tasks, the study offers a clear heuristic for resource allocation and system selection. Additionally, the proposed complexity dimensions establish a new standard for benchmarking, enabling researchers to create more granular and meaningful evaluations of LLM capabilities.

***

## Key Findings

*   **Complexity Correlation:** The advantage of LLM-based Multi-Agent Systems (LLM-MAS) over Single-Agent Systems (LLM-SAS) increases as task complexity rises.
*   **Dominance of Depth:** Task 'depth' (length of sequential reasoning) has a more pronounced positive effect on LLM-MAS performance compared to other factors.
*   **Role of Width:** Task 'width' (diversity of capabilities) also correlates with improved LLM-MAS performance, though less significantly than depth.
*   **General Superiority:** Both theoretical analysis and empirical evaluation confirm that LLM-MAS generally outperform LLM-SAS in tasks requiring extensive sequential reasoning.

***

## Methodology

The researchers employed a combination of theoretical modeling and empirical testing to isolate the effects of task complexity:

1.  **Theoretical Framework:** Development of a framework characterizing task complexity based on two dimensions:
    *   **Depth:** Reasoning length.
    *   **Width:** Capability diversity.
2.  **System Focus:** Theoretical examination focused on **Multi-Agent Debate systems** as a representative class of LLM-MAS.
3.  **Empirical Evaluation:** Testing was conducted on both discriminative and generative tasks. Researchers systematically varied the depth and width parameters to isolate their specific effects on performance.

***

## Technical Details

### System Definitions
*   **LLM-SAS:** A single isolated Large Language Model.
*   **LLM-MAS:** A Multi-Agent system utilizing the **Debate paradigm**, where agents argue over multiple turns and a distinct **Aggregator Agent** synthesizes the final answer.

### The 2D Task Complexity Framework
The study formalizes task complexity using the following parameters:

*   **Depth ($d$):** The number of sequential steps in a task.
*   **Width ($w$):** The range of capabilities or micro-operations required per step.

### Formalism
*   **Per-step Success Rate:** Defined as the product of capability success rates ($q_j$):
    $$ s(w) \triangleq \prod_{j=1}^w q_j $$
*   **Task Definition:** A task is treated as a sequence of steps:
    $$T = \{s(w)\}_{t=1}^d$$

### Application Examples
*   **Math Reasoning:** Viewed through the lens of steps (depth) vs. operators (width).
*   **Creative Writing:** Viewed through sentences (depth) vs. keyword diversity (width).

***

## Results

The primary metric used was the **Relative Performance Gain** of LLM-MAS over LLM-SAS, evaluated on Math Reasoning and Creative Writing tasks.

*   **Complexity Dependence:** The advantage of LLM-MAS increases with task complexity.
*   **Depth vs. Width:**
    *   **Depth:** Has a more pronounced positive effect on performance gains. Theoretical analysis suggests **unbounded gains** from increased depth.
    *   **Width:** Improves performance but eventually saturates (diminishing returns).
*   **Theoretical Confirmation:** Mathematical proof confirms that depth is the decisive factor for maximizing the performance gap between multi-agent and single-agent systems.

***

## Contributions

*   **Structured Definition:** Introduction of a structured, theoretical definition of task complexity, moving beyond vague descriptions to measurable dimensions of depth and width.
*   **Clarification of Utility:** Empirical and theoretical clarification that defines *when* LLM-MAS are specifically beneficial relative to single-agent systems.
*   **Foundational Guidance:** Establishment of a principled foundation intended to guide the design of future LLM-MAS methods and the creation of more effective benchmarks.