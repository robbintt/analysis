# The AI Agent Index

*Stephen Casper; Luke Bailey; Rosco Hunter; Carson Ezell; Emma CabalÃ©; Michael Gerovitch; Stewart Slocum; Kevin Wei; Nikola Jurkovic; Ariba Khan; Phillip J. K. Christoffersen; A. Pinar Ozisik; Rakshit Trivedi; Dylan Hadfield-Menell; Noam Kolt*

---

> ### ðŸ“Š Quick Facts & Key Metrics
>
> *   **Total Systems Analyzed:** 67
> *   **Dominant Geography:** USA
> *   **Developer Split:** 73.1% Industry / 26.9% Academia
> *   **Primary Applications:** Software Engineering (37.3%) & Computer Use (37.3%)
> *   **Code Availability:** 49.3%
> *   **Safety Transparency Gap:**
>     *   19.4% have public safety policies
>     *   7.5% publish internal safety evaluations
>     *   9.0% publish external safety evaluations

---

## Executive Summary

The rapid deployment of **agentic AI systems**â€”designed to plan and execute complex tasks with minimal human interventionâ€”has outpaced the development of standardized documentation and monitoring frameworks. Currently, no structured mechanism exists for cataloging these systems or their technical architectures, intended use cases, and safety protocols. This creates a critical **transparency gap**: while developers are generally forthcoming about capabilities and application domains, they frequently obscure risk management practices and safety protocols.

As these systems become increasingly autonomous, the lack of a unified reporting framework hinders the ability of the technical community to evaluate risks, benchmark progress, and ensure responsible deployment.

To address this, the authors introduce the **AI Agent Index**, the first public database dedicated to documenting deployed agentic systems. The core innovation is a standardized taxonomic framework that classifies agents across four specific dimensions:

1.  **Developer Type** (Academic/Industry)
2.  **Application Domain**
3.  **Openness** (code/documentation availability)
4.  **Safety Transparency**

The methodology relies on a **tripartite structure** to aggregate data from public sources and direct developer correspondence, analyzing:
*   **System Components:** Base models, reasoning implementation, and tool usage.
*   **Application Domains:** Specific use cases.
*   **Risk Management:** Evaluations and guardrails.

By establishing strict functional inclusion criteria that require autonomous planning and executionâ€”while excluding basic customer service botsâ€”the Index avoids anthropomorphic definitions and focuses purely on functional transparency.

### Analysis Results
An empirical analysis of **67 indexed systems** reveals significant trends:
*   **Geography & Sector:** The United States is the dominant development hub. Industry developers comprise **73.1%** of the sample compared to **26.9%** from academia.
*   **Domains:** Application domains are heavily concentrated in the digital sphere, with **37.3%** of agents specializing in Software Engineering and **37.3%** in Computer Use. Robotics and Research lag at **6.0%** each.
*   **Transparency Data:** A stark disparity exists in safety reporting. While **49.3%** of systems release code and **70.1%** release documentation, only **19.4%** provide public safety policies. Furthermore, only **7.5%** publish internal safety evaluations and **9.0%** publish external evaluations, a level of disclosure driven almost exclusively by large labs.

This research establishes a foundational benchmark for the assessment of autonomous AI systems, shifting the industry focus toward functional transparency and standardized reporting. By empirically quantifying the gap between capability disclosures and safety rigor, the AI Agent Index serves as a vital tool for regulators, researchers, and developers to monitor the state of agentic deployment and identify potential safety blind spots.

---

## Key Findings

*   **Lack of Framework:** There is currently no existing structured framework for documenting the technical components, intended uses, and safety features of agentic AI systems.
*   **Information Asymmetry:** Developers generally provide ample information regarding the capabilities and application domains of their agentic systems.
*   **Transparency Gap:** There is a significant transparency gap, with developers providing limited information regarding safety protocols and risk management practices.
*   **Rising Deployment:** Agentic AI systems are increasingly being deployed by leading AI developers and startups to plan and execute complex tasks with minimal human intervention.

---

## Methodology

The authors established the **'AI Agent Index,'** a public database created by identifying systems that meet specific inclusion criteria for being 'agentic.'

**Documentation Process:**
The process relies on a **tripartite structured framework**, gathering data from publicly available sources and direct correspondence with developers to classify:
1.  **System Components:** Base models, reasoning implementation, and tool usage.
2.  **Application Domains:** Specific use cases.
3.  **Risk Management:** Evaluation results, guardrails, and other safety features.

---

## Technical Details

The paper presents a taxonomic framework and indexing methodology for analyzing existing agentic AI systems rather than a novel model architecture.

*   **Inclusion Criteria:** Requires systems capable of planning and executing complex tasks with minimal human intervention. Explicitly excludes customer service bots.
*   **Categorization Schema:** Relies on four dimensions:
    *   **Developer Type:** Academic vs. Industry.
    *   **Application Domain:** Universal, Research, Robotics, Software/Computer Use.
    *   **Openness:** Availability of code and documentation.
    *   **Safety Transparency:** Availability of policies and tests.
*   **Philosophical Approach:** The methodology avoids philosophical redefinitions, focusing on functional transparency due to anthropomorphism risks.

---

## Contributions

1.  **Creation of the AI Agent Index:** The introduction of the first public database dedicated to documenting currently deployed agentic AI systems.
2.  **Standardized Taxonomy:** The development of a structured framework for categorizing and comparing agentic systems based on their technical architecture, applications, and safety profiles.
3.  **Transparency Benchmarking:** Empirical evidence highlighting the disparity in industry transparency, specifically the contrast between the high availability of capability information versus the scarcity of safety and risk management documentation.

---

## Quality Assessment & References

**Quality Score:** 8/10  
**References:** 34 citations