# Difference Views for Visual Graph Query Building

*Benedikt Kantz; Stefan Lengauer; Peter Waldert; Tobias Schreck*

---

> ### **Quick Facts**
>
> *   **System Name:** OnSET (Ontology and Semantic Exploration Toolkit)
> *   **Quality Score:** 8/10
> *   **References:** 37 Citations
> *   **Core Technology:** SPARQL, Knowledge Graphs, Natural Language Interface (NLI)
> *   **Evaluation Type:** Qualitative Case Studies
> *   **Key Feature:** "Difference Views" for iterative query evolution

---

## Executive Summary

Iterative Knowledge Graph (KG) querying creates substantial cognitive friction for domain experts attempting explorative search, as the user's information goal evolves over time. The core issue lies not in the complexity of SPARQL syntax alone, but in the user's inability to mentally track the "delta"—the specific structural and data changes—between sequential query modifications. Traditional tools obscure the impact of adding or removing constraints, forcing users to maintain a mental model of the query state across steps without clear visual feedback on how these alterations shift the underlying result set. This lack of transparency in query evolution significantly raises the barrier to entry for non-experts attempting to perform rigorous semantic web analysis.

The paper introduces **OnSET** (Ontology and Semantic Exploration Toolkit), a visual interface that replaces static syntax display with "difference views" to illuminate query progression. Technically, the system models queries as prototypical graphs (`G_p`) based on Basic Graph Patterns (BGP) and computes set differences between states to identify added, deleted, shared, and modified nodes, encoding these changes via distinct visual cues (e.g., green for additions, red for deletions). To bridge the gap between visual manipulation and natural language, OnSET employs a tightly constrained three-step Natural Language Interface (NLI): first retrieving semantically similar ontology items via embeddings, then building a restrictive schema to bound the Large Language Model (LM) output, and finally applying post-processing corrections. This architecture allows users to generate query edits via natural language, visually validate the resulting changes, and commit them only after verification.

Rather than relying on quantitative performance metrics, the evaluation relies on detailed case studies to demonstrate the system's utility on concrete tasks. A primary use case involved the analysis of Olympic historical data, where the system successfully supported value-wise attribute fetching, specifically visualizing the distribution of participant birthdates. The system demonstrated the ability to communicate query impact by contrasting aggregate statistical trends with shifts in individual instance granularity. While the paper notes the absence of traditional quantitative metrics (such as task completion times), the case studies provided empirical evidence that the constrained NLI architecture effectively mitigates LM hallucinations; users were able to visually identify and reject schema-inconsistent suggestions before they corrupted the query flow, validating the system's robustness in real-world domain-specific scenarios.

This research advances visual analytics by shifting the paradigm from static query representation to the dynamic visualization of query evolution. By formally defining a method to contrast query states and integrating a guarded natural language interface, OnSET establishes a blueprint for future hybrid human-AI systems that balance the flexibility of natural input with the precision required for semantic data retrieval. The work has significant implications for lowering the technical barrier to Knowledge Graph exploration, enabling domain experts to conduct sophisticated, iterative analyses without requiring deep mastery of SPARQL or the cognitive overhead of tracking complex query states manually.

---

## Key Findings

*   **Iterative Support:** The visual querying interface effectively supports iterative query building by focusing on 'difference views' that highlight evolution and changes between steps.
*   **NLI Integration:** Integrating a Natural Language Interface (NLI) into the difference view allows users to better formulate evolving information needs.
*   **Result Communication:** Communicating result changes through contrasts in result distribution and individual instances provides a clearer understanding of query impact.
*   **Broad Applicability:** Case studies demonstrate the system's applicability across various ontologies for general and domain-specific analysis.

---

## Methodology

The authors developed a visual querying interface for iterative Knowledge Graph querying using SPARQL. The methodology centers on the concept of using "graph differences" to visualize changes between query steps.

*   **Hybrid Approach:** The approach integrates a natural language interface directly within the difference view.
*   **Comparative Visualization:** It employs a comparative result view to visualize differences in result sets.
*   **Evaluation:** The system was evaluated through case studies involving different ontologies and usage scenarios to assess utility in explorative search and domain-specific analysis.

---

## Contributions

*   **Novel Interface:** A visual querying interface that utilizes 'graph differences' to communicate changes between iterative query steps.
*   **Hybrid Interaction:** A hybrid interaction model combining visual query building with an embedded natural language interface.
*   **Result Visualization:** A technique that contrasts differences in result distribution and individual instances.
*   **Empirical Evidence:** Validation via case studies demonstrating the system's utility for explorative search.

---

## Technical Details

**System Name**
OnSET (Ontology and Semantic Exploration Toolkit)

**Core Concept**
Uses "difference views" to visualize the evolution of queries and result sets during iterative, exploratory search in Knowledge Graphs (KGs).

**Graph Representation (`G_p`)**
*   Based on the Basic Graph Pattern (BGP) and defined as a prototypical graph `G_p := (N_p, E_p)`.
*   **Function:** Serves as a blueprint for retrieved instances.
*   **Nodes (`N_proto`):** Instances of classes `C`.
*   **Edges (`E_proto`):** Links of type `L` constrained by the ontology `subtypeof` hierarchy.
*   **Sub-queries (`S N_proto`):** Extensions of nodes including `constraint(p, cond.)` or `value(p)`.

**Difference Graph Computation**
*   Compares a left (`G_proto,l`) and right (`G_proto,r`) graph state.
*   Calculates set differences using serial numerical identifiers:
    *   **Added Nodes:** `N_proto,add`
    *   **Deleted Nodes:** `N_proto,del`
    *   **Shared Nodes:** `N_proto,shared`
*   Identifies modified sub-queries on shared nodes using a `is_changed(s)` operator, creating a set `S N_proto,shared,chg`.

**Visualization & Heuristics**
*   **Visual Encoding:** Highlights added nodes in **green** and deleted nodes in **red** (colorblind mode available).
*   **Result Set Overview** uses heuristics for visualization types:
    1.  **1 Attribute:** Histogram (if continuous) or discrete bar chart.
    2.  **2 Attributes:** Scatter plot (standard) or Heatmap (if too many data points).
    *   Charts compare distributions between result sets of different query steps.

**Natural Language Interface (NLI) Architecture**
A 3-step process:
1.  **Retrieval:** LM generates embeddings of the user query to retrieve `k` semantically similar classes/links from the ontology.
2.  **Constraint:** A highly constrained schema is built from retrieved items to restrict LM output to valid ontology types.
3.  **Correction:** Post-processing fixes graph consistency issues (e.g., adding missing nodes, reversing link directions).

**Interaction Flow**
LM-suggested changes are displayed in the difference view for user validation (accept/reject) before committing to the SPARQL query.

---

## Results

The provided sections do not contain a dedicated "Experiments" or "Evaluation" section with quantitative performance metrics (e.g., accuracy, latency, user study N-sizes). However, qualitative findings and application scenarios include:

*   **Demonstrated Applicability:** Case studies showed the system works across various ontologies for both general and domain-specific analysis.
*   **Exploratory Search Support:** The system successfully handles iterative query building where the final information goal is not defined at the start.
*   **Handling LM Errors:** The architecture effectively mitigates hallucinations and incorrect suggestions by allowing users to review changes in the difference view before applying them.
*   **Example Use Case:** An analysis of Olympic data was successfully used to demonstrate the visualization of value-wise attribute fetching (specifically birthdate distributions of participants).
*   **Absence of Quantitative Data:** The provided sections do not report specific metrics regarding query translation accuracy, time complexity, user task completion rates, or statistical significance of the improvements over existing tools.