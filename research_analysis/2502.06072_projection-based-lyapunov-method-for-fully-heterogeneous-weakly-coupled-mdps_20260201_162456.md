# Projection-based Lyapunov method for fully heterogeneous weakly-coupled MDPs
*Xiangcheng Zhang; Yige Hong; Weina Wang*

> ### **Quick Facts**
> - **Quality Score:** 9/10
> - **References:** 40 Citations
> - **Optimality Gap:** $O(1/\sqrt{N})$
> - **Core Method:** Projection-based Lyapunov Functions
> - **Problem Class:** Fully Heterogeneous Average-Reward WCMDPs

---

## Executive Summary

This research addresses the optimization of large-scale decision-making systems modeled as Weakly-Coupled Markov Decision Processes (WCMDPs) characterized by full heterogeneity. Unlike traditional methods that rely on homogeneity or structural uniformity among subsystems to ensure tractability, this work targets real-world applications—such as network resource allocation and logistics—where system components, or "arms," possess distinct transition kernels, reward functions, and cost profiles. The core problem involves maximizing the long-run average reward across an infinite horizon while satisfying shared global budget constraints that couple these independent arms. This formulation resolves a critical challenge in stochastic control: balancing system-wide performance with resource limitations in environments where total heterogeneity renders the joint state space computationally intractable.

The key innovation is the development of a projection-based Lyapunov method designed to certify convergence and stability within these high-dimensional, heterogeneous environments. Technically, the method projects the high-dimensional system state—represented as an $N \times |S|$ matrix—onto a lower-dimensional empirical distribution of states across the population. This projection abstracts away specific individual identities, allowing the authors to rigorously analyze system drift and Lyapunov stability despite the lack of uniformity among the arms. To strictly enforce global budget constraints ($\sum_{i \in [N]} c_{k,i} \le \alpha_k N$) without requiring homogeneity, the framework incorporates a "null" action into the action space; this action incurs zero costs and yields zero rewards, serving as a rigorous mechanism to guarantee feasibility by switching arms to a dormant state when projected costs approach their limits.

The study's primary theoretical contribution is the establishment of asymptotic optimality for fully heterogeneous average-reward WCMDPs, marking the first proof of its kind for this problem class. The authors demonstrate that the proposed algorithm achieves an optimality gap of $O(1/\sqrt{N})$ for the long-run average reward per arm as the number of arms ($N$) approaches infinity. Crucially, the analysis confirms that the approach effectively mitigates the curse of dimensionality. By anchoring computational complexity to the size of the shared state and action spaces rather than the number of arms ($N$), the method remains theoretically viable and scalable even as the system expands to thousands of independent entities.

This work significantly advances the field of stochastic control and reinforcement learning by bridging the gap between theoretical tractability and practical, diverse applications. By proving that asymptotic optimality is achievable without restrictive homogeneity assumptions, the authors enable future researchers to model complex systems as they actually exist: diverse and independent. The introduction of projection-based Lyapunov functions provides the research community with a powerful new analytical toolset for certifying convergence in multi-agent stochastic systems, paving the way for more robust, realistic, and scalable decision-making frameworks in complex engineering and operational environments.

---

## Key Findings

*   **Heterogeneity Management:** Addresses full heterogeneity in large-scale WCMDPs with distinct parameters.
*   **Asymptotic Optimality:** Achieves an $O(1/\sqrt{N})$ optimality gap for long-run average reward.
*   **Curse of Dimensionality Mitigation:** Remains effective despite the curse of dimensionality.
*   **First-of-its-Kind Result:** Establishes the first asymptotic optimality result for fully heterogeneous average-reward WCMDPs.

## Methodology

The primary methodological innovation is the construction of **projection-based Lyapunov functions** to mathematically certify the convergence of rewards and costs to an optimal region. This approach verifies system stability and performance in fully heterogeneous settings by projecting high-dimensional system states onto lower-dimensional empirical distributions, allowing for rigorous analysis without homogeneous assumptions.

## Contributions

*   **Bridging the Research Gap:** Addresses the fundamental challenge of fully heterogeneous settings in real-world large-scale decision-making.
*   **Theoretical Advancement:** Proves that asymptotic optimality is achievable in fully heterogeneous average-reward WCMDPs.
*   **Novel Technique:** Introduces projection-based Lyapunov functions as a new tool for certifying convergence in complex, heterogeneous stochastic systems.

## Technical Details

**System Model**
*   **Framework:** Weakly-Coupled Markov Decision Process (WCMDP).
*   **Composition:** $N$ independent arms (subproblems) in a fully heterogeneous setting.
*   **Arm Definition:** Each arm $i$ is defined by a tuple $M_i = (S, A, P_i, r_i, (c_{k,i})_{k \in [K]})$.
    *   **Heterogeneity:** Distinct transition kernels $P_i$, reward functions $r_i$, and cost functions $c_{k,i}$.
    *   **Homogeneity:** Shared finite state and action spaces.
*   **Dynamics:** Independent across arms conditioned on actions.

**Constraints & Feasibility**
*   **Global Constraint:** $\sum_{i \in [N]} c_{k,i}(s_i, a_i) \le \alpha_k N$ where $\alpha_k > 0$.
*   **Feasibility Mechanism:** A 'null' action that incurs zero costs is provided to guarantee feasibility.

**State Representation**
*   **System State ($S_t$):** Represented as a tuple of all arm states or as an $N \times |S|$ matrix ($X_t$).

**Objective**
*   **Goal:** Maximizes the long-run average reward per arm over an infinite horizon.
*   **Technique:** Utilizes projection-based Lyapunov functions to certify convergence.

## Results

The provided text focuses on abstract and theoretical setup rather than specific numerical experimental results. However, the following theoretical metrics and performance guarantees are claimed:

*   **Optimality Gap:** The method achieves an $O(1/\sqrt{N})$ gap for the long-run average reward per arm as $N \to \infty$.
*   **Convergence:** Rewards and costs are certified to converge to an optimal region.
*   **Scalability:** The analysis asserts that the approach overcomes the curse of dimensionality in fully heterogeneous settings.
*   **Benchmarking:** Establishes the first asymptotic optimality result for fully heterogeneous average-reward WCMDPs.