---
title: Source Coverage and Citation Bias in LLM-based vs. Traditional Search Engines
arxiv_id: '2512.09483'
source_url: https://arxiv.org/abs/2512.09483
generated_at: '2026-01-27T21:11:56'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Source Coverage and Citation Bias in LLM-based vs. Traditional Search Engines

*Qiming Ye, Zifan Peng, Peixian Zhang â€” The Hong Kong University*

---

> ### ðŸ“Š Quick Facts & Metrics
>
> *   **Study Scale:** 55,936 queries analyzed
> *   **Engines Compared:** 6 LLM-based (Copilot, Perplexity, ChatGPT, etc.) vs. 2 Traditional (Google, Bing)
> *   **Domain Diversity:** 37% of cited domains in LLM-SEs are unique
> *   **Data Collection Period:** July 16 â€“ August 10, 2025
> *   **Quality Score:** 9/10

---

## Executive Summary

The integration of Large Language Models (LLMs) into search architectures marks a fundamental shift in information retrieval, transitioning from traditional ranked lists of hyperlinks to synthesized, generative answers. This paper addresses the critical gap in empirical understanding regarding how these new LLM-based Search Engines (LLM-SEs) compare to Traditional Search Engines (TSEs) in terms of source diversity, citation integrity, and safety.

As users increasingly rely on AI-generated summaries, it is essential to determine whether these systems provide broader, less biased access to information, or if they introduce novel forms of opacity and systemic risk that existing evaluation frameworks fail to capture. The researchers conducted one of the first large-scale, quantitative comparative studies between six LLM-SEs and two dominant TSEs. The study contrasts the generative pipelines of LLM-SEs (Retrieval-Augmented Generation) with the traditional indexing and link-ranking outputs of standard engines.

The analysis reveals a significant trade-off: while LLM-SEs demonstrate substantially broader source coverageâ€”with 37% of cited domains being unique to LLM-SEsâ€”they fail to outperform traditional engines in critical quality dimensions. Specifically, the data indicates that LLM-SEs do not show statistically significant improvements in credibility, political neutrality, or safety compared to TSEs. Furthermore, the summarization native to LLM-SEs inherently results in reduced citation transparency relative to the explicit link-listing format of traditional search engines. This research serves as a foundational benchmark, highlighting that LLM-SEs exchange transparency for diversity, and underscores the urgent need for updated evaluation standards.

---

## Key Findings

*   **Greater Domain Diversity:** LLM-based Search Engines (LLM-SEs) cite domain resources with significantly greater diversity than Traditional Search Engines (TSEs). Notably, **37% of cited domains are unique to LLM-SEs** and do not appear on the first pages of TSEs.
*   **No Quality Outperformance:** Despite architectural novelty, LLM-SEs **do not outperform** TSEs in critical quality dimensions such as credibility, political neutrality, and safety.
*   **Reduced Transparency:** The summarization approach of LLM-SEs often results in **limited citation transparency** compared to the traditional link-listing format, making it more difficult for users to verify information.

---

## Research Contributions

*   **Quantitative Benchmarking:** Provided one of the first large-scale comparative analyses quantifying the disparity in source coverage between LLM-SEs and TSEs.
*   **Identification of Systemic Risks:** Highlighted that the novelty of LLM-SEs does not inherently solve issues of bias, credibility, or safety.
*   **Explainability of Source Selection:** Offered insights into the selection criteria and features that drive how LLM-SEs choose specific sources.
*   **Stakeholder Guidance:** Delivered actionable recommendations for end-users, website owners, and developers.

---

## Technical Details

### System Architecture Comparison

| Feature | LLM-based Search Engines (LLM-SEs) | Traditional Search Engines (TSEs) |
| :--- | :--- | :--- |
| **Core Mechanism** | Retrieval-Augmented Generation (RAG) | Crawlers & Indexers |
| **Prompting** | "Least-to-Most Prompting" | N/A |
| **Pipeline** | Decomposition $\rightarrow$ Retrieval (Local/Web) $\rightarrow$ Ranking $\rightarrow$ Synthesis | Crawling $\rightarrow$ Inverted Index $\rightarrow$ Ranking (PageRank, E-E-A-T) |
| **Output** | Synthesized answers with inline citations | Ranked list of links |

### Methodology & Data Collection
The researchers utilized a combination of comparative performance testing and feature-based analysis.

*   **Data Collection Tool:** DrissionPage (in incognito mode).
*   **Query Corpus Generation:**
    *   **Keyword Extraction:** Sourced from Google Trends (7,519 keywords) and X (5,593 keywords).
    *   **Query Expansion:** Generated via Google Search and Google AI Mode (37,931 and 2,612 queries respectively).
    *   **Controversial Augmentation:** Utilized Quora dataset to generate 2,281 controversial queries.

---

## Statistical Results

### Dataset Volume
*   **TSE First-Page URLs:**
    *   Google: 481,565
    *   Bing: 218,122
*   **LLM-SE User-Facing Citations:**
    *   Copilot Search: 1,029,015
    *   Google AI Mode: 414,524
    *   Perplexity: 280,699
    *   ChatGPT: 206,590
    *   Gemini: 182,541
    *   Grok: 62,420

### Primary Findings Analysis
The comprehensive dataset confirms that while LLM-SEs access a wider breadth of information (37% unique domains), this does not correlate with higher reliability. The study found no statistical evidence that LLM-SEs offer superior neutrality or safety, and the synthesized nature of the answers frequently obscures source provenance compared to traditional blue-link results.

---

**References:** 40 citations