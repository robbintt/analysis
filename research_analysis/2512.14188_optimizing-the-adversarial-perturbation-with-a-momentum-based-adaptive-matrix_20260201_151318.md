# Optimizing the Adversarial Perturbation with a Momentum-based Adaptive Matrix

*Wei Tao; Sheng Long; Xin Liu; Wei Li; Qing Tao*

***

### üìä Quick Facts

| Metric | Details |
| :--- | :--- |
| **Proposed Method** | AdaMI (Adaptive Momentum-based Iterative attack) |
| **Key Improvement** | Resolves non-convergence in MI-FGSM; Enhances transferability |
| **Regret Bound** | $O(1/\sqrt{T})$ (Optimal for convex problems) |
| **Datasets Tested** | CTSRD, ImageNet |
| **Best Performance Gain** | +8.4% (CTSRD: Res34 $\to$ VGG16) |
| **Quality Score** | 8/10 |

***

## üìù Executive Summary

This research addresses the fundamental instability and non-convergence issues associated with current momentum-based adversarial attack methods, most notably MI-FGSM. While momentum is widely employed to enhance adversarial transferability‚Äîthe ability of an attack to generalize from a surrogate model to an unknown target model‚Äîexisting implementations suffer from theoretical limitations regarding optimization stability. Specifically, the authors identify that standard methods like PGD and MI-FGSM rely heavily on sign-function scaling and fixed step-size strategies derived solely from the current gradient, leading to unreliable convergence. This instability limits the effectiveness of black-box attacks, making it critical to develop an optimization framework that ensures both robust attack generation and theoretical convergence.

The paper introduces **AdaMI** (Adaptive Momentum-based Iterative attack), a novel algorithm that fundamentally reformulates the generation of adversarial examples as a convex optimization problem linked to first-order adaptive optimizers like AdaGrad. The key technical innovation is the replacement of the standard sign function with a "momentum-based adaptive matrix" to scale perturbations. Unlike AdaGrad, which uses the square of the gradient, AdaMI calculates the adaptive matrix using the square of the momentum vector. The algorithm updates the adversarial example using this matrix to normalize the step size, coupled with a time-varying step size ($\alpha_t = \alpha / \sqrt{t}$). This approach theoretically guarantees optimal convergence for convex problems with a regret bound of $O(1/\sqrt{T})$, resolving the stability issues prevalent in previous methods.

Experimental evaluation on the CTSRD and ImageNet datasets demonstrates that AdaMI consistently outperforms state-of-the-art baselines‚Äîincluding MI-FGSM, NI, and VMI‚Äîby enhancing both transferability and stability. In tests on the CTSRD dataset (transfer from ResNet34 to VGG16), AdaMI increased the attack success rate from **23.9% to 32.3%**. Similar significant gains were observed on ImageNet; for example, when attacking VGG16, the success rate improved from **47.2% to 51.5%**, and against the Swin Transformer architecture, it rose from **25.9% to 28.0%**. These results confirm that the proposed adaptive technique provides superior performance across both CNN and Transformer architectures without compromising the imperceptibility of the perturbations.

The significance of this work lies in its successful bridging of theoretical optimization principles with practical adversarial attack strategies. By establishing the mathematical equivalence between PGD, Projected Gradient, and AdaGrad, and subsequently extending this to a momentum-based context, the authors provide a rigorous theoretical foundation for analyzing attack mechanisms. The introduction of the momentum-based adaptive matrix serves as a versatile, generalizable technique that advances the state-of-the-art in black-box attacks, offering researchers a more stable and mathematically sound tool for evaluating the robustness of deep neural networks.

***

## üîç Key Findings

*   **Theoretical Reformulation of PGD:**
    PGD is identified as a specific reformulation of the projected gradient method that determines step-size using only the current gradient. Furthermore, when coupled with a conventional adaptive matrix of accumulated gradients, PGD becomes equivalent to AdaGrad.
*   **Resolution of Non-Convergence:**
    The prevalent momentum-based attack method MI-FGSM suffers from non-convergence issues. The proposed method, **AdaMI**, is proven to attain optimal convergence for convex problems, thereby addressing this stability limitation.
*   **Enhanced Transferability and Stability:**
    The momentum-based adaptive matrix proposed in the study acts as a general technique that boosts adversarial transferability across different networks compared to state-of-the-art methods, while simultaneously maintaining better stability and imperceptibility.

## üõ† Methodology

The study employs a rigorous analytical approach to develop a more robust attack algorithm:

1.  **Optimization Framework:**
    The authors formulate the generation of adversarial examples as an optimization problem, analyzing standard gradient-based (PGD) and momentum-based (MI-FGSM) attacks through this lens.
2.  **Critique of Scaling:**
    The method critiques the universal use of the **sign function** in existing attacks for scaling perturbations, highlighting theoretical optimization concerns regarding fixed step-sizes.
3.  **AdaMI Development:**
    Motivated by the link between adaptive matrices and standard optimizers (specifically AdaGrad), the authors propose a novel **'momentum-based adaptive matrix'** to scale perturbations. This new method, AdaMI, replaces standard sign-function scaling with this matrix to optimize the perturbation process.

## ‚ú® Contributions

*   **Theoretical Insight on Attack Mechanisms:**
    The paper provides a theoretical bridge between adversarial attack algorithms and first-order optimization methods, specifically revealing the mathematical equivalences between PGD, Projected Gradient, and AdaGrad.
*   **Novel Attack Algorithm (AdaMI):**
    Introduction of AdaMI, a novel momentum-based attack that utilizes a unique momentum-based adaptive matrix instead of the traditional sign function for perturbation scaling.
*   **Optimization Stability:**
    A contribution to the theoretical stability of adversarial attacks by providing proof that AdaMI achieves optimal convergence in convex settings, resolving the instability found in predecessors like MI-FGSM.
*   **Generalizable Performance Improvement:**
    The introduction of a versatile technique that significantly improves adversarial transferability across various network architectures without sacrificing the imperceptibility of the perturbations.

## ‚öôÔ∏è Technical Details

*   **AdaMI (Adaptive Momentum-based Iterative attack):**
    Introduced to address non-convergence issues in momentum-based methods by establishing PGD as a reformulation of AdaGrad.
*   **Adaptive Matrix Calculation:**
    Proposes a unique adaptive matrix update using the **square of the momentum vector** instead of the gradient.
*   **Update Rule:**
    $$x^{adv}_{t+1} = P_Q(x^{adv}_t + \alpha_t \hat{V}^{-1/2}_{t+1} g_{t+1})$$
    *   Includes a decaying momentum parameter.
    *   Utilizes a time-varying step-size: $\alpha_t = \alpha / \sqrt{t}$.
*   **Convergence Guarantee:**
    Theoretically achieves a regret bound of **$O(1/\sqrt{T})$** and guarantees convergence for convex problems.

## üìà Results

Experimental validation on CTSRD and ImageNet confirms superior performance:

### CTSRD Dataset (Source: Res34 $\to$ Target: VGG16)
*   **Success Rate Improved:** 23.9% $\to$ **32.3%**

### ImageNet Dataset (Transfer Success)
*   **Target: VGG16**
    *   Improved from 47.2% $\to$ **51.5%**
*   **Target: Swin-T (Transformer)**
    *   Improved from 25.9% $\to$ **28.0%**
*   **General Performance:**
    *  The 'Ada' technique generally provided competitive or superior performance compared to standard momentum-based attacks across both CNN and Transformer architectures.

***

**References:** 40 citations | **Quality Score:** 8/10