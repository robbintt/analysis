---
title: Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference
  to Disentangled Tuning
arxiv_id: '2602.00994'
source_url: https://arxiv.org/abs/2602.00994
generated_at: '2026-02-03T12:40:01'
quality_score: 8
citation_count: 37
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# Reasoning and Tool-use Compete in Agentic RL: From Quantifying Interference to Disentangled Tuning

*Yu Li; Mingyang Yi; Xiuyu Li; Ju Fan; Fuxin Jiang; Binbin Chen; Peng Li; Jie Song; Tieying Zhang*

---

> ### üìä Quick Facts
>
> *   **Performance Gain:** +6.35% average improvement over baselines.
> *   **Interference Rate:** 57.70% of questions affected (HotpotQA).
> *   **Key Framework:** DART (Disentangled Agentic Reasoning Tuning).
> *   **Core Mechanism:** Disjoint LoRA subspaces (Rank 8 each).
> *   **Models Tested:** Qwen2.5-3B, Qwen2.5-7B-Instruct.
> *   **Quality Score:** 8/10
> *   **Citations:** 37

---

## üìù Executive Summary

This research addresses a fundamental flaw in the prevailing **Agentic Reinforcement Learning (ARL)** paradigm, where a single shared model is typically trained to handle both reasoning and tool-use capabilities. The authors demonstrate that this joint training approach suffers from significant **"training interference,"** where the optimization of one capability actively degrades the other. This problem matters because it limits the effectiveness of Large Language Model (LLM)-based agents; despite the assumption that shared parameters foster generalization, the reality is that reasoning and tool-use behaviors induce conflicting gradient directions ($g^{(r)}$ and $g^{(a)}$), resulting in sub-optimal performance for both tasks.

The paper introduces a two-pronged technical innovation to diagnose and resolve this interference:
1.  **LEAS (Linear Effect Analysis System):** A diagnostic framework that quantifies interference by calculating interaction coefficients ($\lambda_{q23}$) across various model variants, with negative values confirming the detrimental interaction.
2.  **DART (Disentangled Agentic Reasoning Tuning):** Resolves the conflict by decoupling parameter updates using two disjoint Low-Rank Adaptation (LoRA) subspaces (rank 8 each) within a single backbone model.

Empirical results validate that interference is the dominant mode of interaction. The DART framework proved highly effective, achieving an average performance improvement of **6.35%** over standard joint training baselines. Notably, DART matched the performance upper bound of a complex multi-agent system using only a single, disentangled model. This work significantly influences the field by challenging the assumption that shared parameters are inherently beneficial, providing a new, more effective optimization direction for future research in LLM agents.

---

## üîë Key Findings

*   **Existence of Training Interference:** Joint training on a single shared model is flawed, with quantitative evidence revealing significant interference between reasoning and tool-use behaviors.
*   **Gradient Misalignment:** Reasoning and tool-use capabilities induce misaligned gradient directions that actively undermine joint optimization effectiveness.
*   **Efficacy of Decoupling:** Explicitly decoupling parameter updates for reasoning and tool-use leads to superior performance compared to standard joint training methods.
*   **Performance Benchmarks:** The proposed DART framework achieves an average performance improvement of 6.35% over baseline methods and matches multi-agent system performance using a single model.

---

## üî¨ Methodology

The researchers employed a **Linear Effect Attribution System (LEAS)** to systematically investigate and quantify interference between reasoning and tool-use behaviors within shared model parameters. They conducted an in-depth analysis of gradient directions during training to empirically demonstrate misalignment.

To address the identified interference, they developed the **Disentangled Action Reasoning Tuning (DART)** framework. This solution utilizes separate low-rank adaptation (LoRA) modules to explicitly decouple parameter updates for reasoning and tool-use, allowing for distinct optimization paths within a single model.

---

## ‚öôÔ∏è Technical Details

*   **LEAS (Linear Effect Analysis System):**
    *   A diagnostic framework using a design matrix from six model variants.
    *   Calculates interaction coefficients ($\lambda_{q23}$).
    *   **Indicator:** Negative values indicate interference between reasoning and tool-use.
*   **Gradient Misalignment Theory:**
    *   Suggests joint training fails due to conflicting update directions.
    *   Contrasts reasoning gradients ($g^{(r)}$) and tool-use gradients ($g^{(a)}$).
*   **DART (Disentangled Agentic Reasoning Tuning):**
    *   **Mechanism:** Decouples parameter updates using two disjoint LoRA subspaces.
    *   **Configuration:** Rank 8 for each subspace.
    *   **Structure:** Maintains a single backbone model while contrasting with shared-parameter baselines.

---

## üèÜ Contributions

*   **Empirical Validation:** Provides the first systematic empirical examination challenging the prevalent ARL paradigm that shared parameters for reasoning and tool-use are inherently beneficial.
*   **Diagnostic Tool:** Introduces LEAS as a novel mechanism to detect and quantify specific training interference caused by competing objectives in agentive systems.
*   **Architectural Innovation:** Presents DART, a simple yet efficient framework that resolves interference problems through architectural decoupling, offering a more effective tuning strategy for LLM-based agents.
*   **Efficiency Breakthrough:** Demonstrates that high performance comparable to complex multi-agent systems can be achieved within a single, disentangled model architecture.

---

## üìà Results

*   **Interference Dominance:** Experiments reveal that interference is the dominant mode of interaction, occurring in **57.70%** of questions for Qwen2.5-3B on HotpotQA.
*   **Performance Gain:** DART achieves an average performance improvement of **6.35%** over standard joint training baselines.
*   **Multi-Agent Parity:** Matches the performance of a 2-Agent upper bound using independent models, but within a single model architecture.
*   **Benchmark Scores (Qwen2.5-7B-Instruct):**
    *   **NQ:** 42.0
    *   **TriviaQA:** 41.9
    *   **PopQA:** 38.9
    *   **HotpotQA:** 39.6
*   **Ablation Studies:** Confirm that DART's benefits stem from disentanglement rather than increased parameter count.

---

**Quality Score:** 8/10 | **References:** 37 citations