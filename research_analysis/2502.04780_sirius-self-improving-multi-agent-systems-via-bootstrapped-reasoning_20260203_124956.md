---
title: 'SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning'
arxiv_id: '2502.0478'
source_url: https://arxiv.org/abs/2502.04780
generated_at: '2026-02-03T12:49:56'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning

*Wanjia Zhao; Mert Yuksekgonul; Shirley Wu; James Zou*

---

> ### ðŸ“Š Quick Facts
>
> *   **Performance Gain:** 2.86% â€“ 21.88% improvement on reasoning and biomedical QA tasks.
> *   **Base Models:** Fine-tuning performed on GPT-3.5 and GPT-4o-mini.
> *   **Core Mechanism:** Bootstrapped Reasoning & Experience Library.
> *   **Key Metric:** Successfully negotiated optimal price (50) in Buyer-Seller Game vs. sub-50 for base models.
> *   **Quality Score:** 9/10
> *   **Citations:** 40

---

## Executive Summary

**Problem**
Current multi-agent systems powered by Large Language Models (LLMs) suffer from an over-reliance on fragile, manually designed prompts and heuristics. A critical bottleneck is the scarcity of high-quality training data required to develop specialized agents capable of complex reasoning. Without specialized datasets, agents cannot effectively learn from interactions or adapt to dynamic, high-stakes environments.

**Innovation**
The authors introduce **SiriuS**, a self-improving optimization framework utilizing a "Bootstrapped Reasoning" pipeline to generate its own training data. The system constructs an "experience library" that retains reasoning steps leading to success. Crucially, it employs a library augmentation procedure to identify and repair unsuccessful trajectories, converting failures into viable training examples. This data fine-tunes base LLMs (GPT-3.5, GPT-4o-mini), enabling continuous self-correction and self-play.

**Results**
SiriuS demonstrated substantial gains across reasoning and competitive negotiation tasks.
*   **QA Benchmarks:** 2.86% to 21.88% improvement in Reasoning & Biomedical QA.
*   **Buyer-Seller Game:** SiriuS agents consistently negotiated the optimal price of 50, whereas base models sold below this threshold.
*   **Ultimatum & Resource Games:** SiriuS secured higher win rates, payoffs, and utility shares.
*   **Robustness:** The system maintained performance during distribution shifts (e.g., resources increasing from 100 to 1000).

**Impact**
This work significantly reduces reliance on static prompt engineering and human-curated data. By validating a mechanism where agents bootstrap improvement from both success and repaired failure, SiriuS establishes a scalable pathway for developing specialized AI agents. This approach has broad implications for deploying autonomous, adaptive multi-agent systems in environments where training data is traditionally scarce or expensive.

---

## Key Findings

*   **Performance Boost:** Achieved a performance improvement ranging from **2.86% to 21.88%** on reasoning and biomedical Question Answering (QA) tasks.
*   **Enhanced Negotiation:** Successfully enhanced agent negotiation capabilities in competitive settings, securing higher utility and win rates.
*   **Data Scarcity Solution:** Effectively addressed the challenge of acquiring suitable training data for specialized agents by generating high-quality reasoning trajectories.
*   **Reusability:** Produces reusable data that can be utilized for future self-correction and self-play enhancement.

---

## Methodology

The authors propose **SiriuS**, a self-improving, reasoning-driven optimization framework designed for multi-agent systems powered by Large Language Models (LLMs). The methodology centers on two core processes:

1.  **Experience Library Construction:** The system builds a library of high-quality reasoning trajectories by selectively retaining specific reasoning steps that lead to successful outcomes.
2.  **Library Augmentation:** A refinement procedure is utilized to analyze and repair unsuccessful trajectories. By converting these failures into useful training examples, the system maximizes the utility of every interaction.

---

## Technical Details

*   **Pipeline:** Utilizes a **'Bootstrapped Reasoning'** pipeline to generate high-quality reasoning trajectories for training data.
*   **Base Models:** Employs fine-tuning on base Large Language Models, specifically **GPT-3.5** and **GPT-4o-mini**, to create specialized agents.
*   **Architecture:** Features a **self-improvement loop** that produces reusable data designed for self-correction and self-play enhancement.
*   **Generalization:** The pipeline is designed to generalize across varying resource configurations. It trains on specific settings and tests on **out-of-distribution (OOD)** configurations to verify robustness.

---

## Results

### General Performance
*   **Reasoning & Biomedical QA:** Achieved a performance improvement of **2.86% to 21.88%**.

### Game-Theoretic Scenarios
*   **Resource Exchange Game:**
    *   The SiriuS agent (Player 2) demonstrated significant improvements in win rate and payoff.
    *   Maintained strong performance in out-of-distribution tests.
*   **Multi-Turn Ultimatum Game:**
    *   SiriuS (Player 1) secured a higher share of the split against various opponents.
    *   Maintained utility gains when resources increased from 100 to 1000.
*   **Buyer-Seller Game:**
    *   The SiriuS Seller consistently negotiated the **optimal price of 50** (compared to base models selling below 50).
    *   Showed significant improvement under adjusted thresholds.

---

## Contributions

*   **Novel Framework:** Introduction of a new optimization framework that reduces reliance on fragile, manually designed prompts and heuristics in multi-agent systems.
*   **Data Solution:** A solution to the critical challenge of acquiring training data for specialized agents through the use of bootstrapped reasoning and experience libraries.
*   **Repair Mechanism:** The development of a mechanism to not only capture successful reasoning steps but also actively refine and repair unsuccessful trajectories for data augmentation.

---
**Quality Score:** 9/10 | **References:** 40 citations