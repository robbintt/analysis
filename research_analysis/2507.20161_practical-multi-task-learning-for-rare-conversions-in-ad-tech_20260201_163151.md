# Practical Multi-Task Learning for Rare Conversions in Ad Tech

*Yuval Dishi; Ophir Friedler; Yonatan Karni; Natalia Silberstein; Yulia Stolin*

***

> ### ðŸ“ Executive Summary
>
> This research addresses the challenge of predicting rare conversion events in large-scale advertising systems, where standard single-task models fail due to severe class imbalance. The authors introduce a **Multi-Task Learning (MTL)** framework based on a Deep & Cross (DCN) network that decouples rare and frequent event learning through a gating mechanism with shared-bottom representation and task-specific towers.
>
> A key innovation is the **inference optimization** that strips down the trained model to only the component handling rare events for production, maintaining low latency while preserving training benefits. The approach demonstrated significant improvements: **+4.08% lift in Relative Information Gain (RIG)** and **+0.69% lift in AUC** offline, and a **2% reduction in Cost per Action (CPA)** with increased conversion volume in production A/B testing. This work successfully operationalizes theoretical MTL advantages within industrial ad tech constraints.

***

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Total Citations:** 19
> *   **Architecture:** Deep & Cross (DCN) Network
> *   **Primary Use Case:** pCVR Estimation
> *   **Key Offline Gain:** +0.69% AUC Lift
> *   **Key Online Gain:** 2% CPA Reduction
> *   **Deployment Status:** Full Production

***

## Key Findings

*   **Rare Event Mastery:** The Multi-Task Learning approach significantly improved prediction capabilities for rare conversion events (occurring at a frequency of <1%).
*   **Offline Performance:** Achieved a **0.69% lift in Area Under the Curve (AUC)** during offline evaluation.
*   **Online Efficiency:** Demonstrated a **2% reduction in Cost per Action (CPA)** during production A/B testing.
*   **Operational Success:** The model successfully transitioned from the testing phase to full production deployment.

## Methodology

The proposed approach uses a data-driven strategy to handle class imbalance:

*   **Categorization:** Conversion events are categorized into **'rare'** or **'frequent'** types based on historical statistical data.
*   **Framework:** It employs a Multi-Task Learning framework featuring:
    *   **Shared Representations:** To learn robust features from all available signals.
    *   **Task-Specific Towers:** Separate towers for specific conversion types, allowing the model to balance generalization with specialization.

## Technical Details

*   **Core Architecture:** Utilizes a **Deep & Cross (DCN)** network implemented in Keras/TensorFlow for pCVR (post-Click Conversion Rate) estimation.
*   **MTL Structure:** Features a **shared-bottom** architecture with two task-specific towers:
    *   **Soft Conversions:** Represents frequent events.
    *   **Hard Conversions:** Represents rare events.
*   **Task Definition:** Definitions are data-driven, utilizing a **time-decayed historical CVR threshold** ($\theta$).
*   **Loss Function:** Training employs a weighted sum of task-specific losses (weights optimized at 0.5, 0.5).
*   **Inference Optimization:**
    *   To maintain serving efficiency, an **'inference model'** is used.
    *   This model retains only the **Hard branch** (rare events) while removing the Soft branch and high-level shared layers, reducing latency.
*   **Traffic Routing:** Routing is stabilized using historical CVR, advertiser type, and conversion category to mitigate daily performance fluctuations.

## Results

**Offline Evaluation**
*   Evaluated on hundreds of millions of records.
*   Balanced loss weights (0.5, 0.5) provided a **+1.17% RIG gain** over the Hard-only baseline.
*   Adding 4 shared layers yielded an additional **+0.21% RIG**.
*   Compared to the single-task production baseline, the final model achieved:
    *   **+4.08% lift in RIG**
    *   **+0.69% lift in AUC**

**Online A/B Testing**
*   Demonstrated a **2% reduction in Cost per Action (CPA)**.
*   Consistent increases in conversion volume were observed across:
    *   Median segments
    *   Spend-Weighted Geometric Mean
    *   High-Impact advertiser segments

## Contributions

1.  **Class Imbalance Solution:** Provides a practical solution for mitigating class imbalance when predicting rare events in large-scale advertising systems.
2.  **Hybrid Architecture:** Introduces a hybrid MTL architecture that balances shared feature learning with task-specific specialization.
3.  **Empirical Validation:** Offers empirical validation that bridges theoretical modeling with industrial application, demonstrating consistent offline and online gains.