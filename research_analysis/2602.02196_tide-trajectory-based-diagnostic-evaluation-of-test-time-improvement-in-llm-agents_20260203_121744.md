---
title: 'TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM
  Agents'
arxiv_id: '2602.02196'
source_url: https://arxiv.org/abs/2602.02196
generated_at: '2026-02-03T12:17:44'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents

*Hang Yan; Xinyu Che; Fangzhi Xu; Qiushi Sun; Zichen Ding; Kanzhi Cheng; Jian Zhang; Tao Qin; Jun Liu; Qika Lin*

---

> ### ðŸ“Š Quick Facts
> ---
> *   **Quality Score:** 8/10
> *   **Citations:** 40
> *   **Framework:** TIDE (Test-time Improvement Diagnostic Evaluation)
> *   **Core Metric:** Area Under Variation (AUV)
> *   **Scope:** 5 Environments, 14 Models
> *   **Key Insight:** Interaction dynamics > Internal reasoning scale

---

## Executive Summary

Current research on Large Language Model (LLM) agents focuses heavily on scaling internal reasoning capabilities, often overlooking the critical role of interaction dynamics between the agent and the environment. This paper addresses the significant limitation that existing evaluation metrics, such as Success Rate (SR), are static and fail to capture the temporal dynamics of Test-Time Improvement (TTI)â€”the ability of an agent to improve performance through iterative interaction.

The authors identify that performance limitations are frequently caused by recursive looping behaviors and burdensome accumulated memory, issues that remain invisible under traditional evaluation. Without a framework to measure task optimization efficiency, behavior adaptation, and working memory utility, the mechanisms driving successful TTI are poorly understood, hindering the development of robust autonomous agents.

The authors introduce **TIDE** (Test-time Improvement Diagnostic Evaluation), a novel, agent-agnostic, and environment-agnostic diagnostic framework designed to evaluate the temporal dynamics of agent performance. Technically, TIDE formalizes agent-environment interaction as a Partially Observable Markov Decision Process (POMDP) and decomposes TTI into three distinct dimensions: task optimization efficiency, behavioral adaptation, and working memory utility.

The core technical contribution of the framework is the **"Area Under Variation" (AUV)** metric. AUV quantifies optimization efficiency by calculating the normalized integral area under the variation curve $P_t$ (the cumulative proportion of tasks solved by turn $t$), providing a granular view of how quickly and effectively an agent converges on a solution compared to a simple binary success metric.

The framework was validated through extensive experiments across five diverse environments using 14 models categorized as 'Non-thinking' and 'Thinking'. The results demonstrated that AUV provides critical insights that Success Rate (SR) often misses. This research significantly shifts the paradigm for LLM agent development by redirecting focus from merely scaling internal reasoning parameters to optimizing agent-environment interaction dynamics.

---

## Key Findings

*   **Interaction Dynamics:** Improving agent performance cannot be achieved solely by scaling internal reasoning; it requires the explicit optimization of interaction dynamics between the agent and the environment.
*   **Performance Bottlenecks:** Limitations in Test-Time Improvement (TTI) are primarily driven by recursive looping behaviors and burdensome accumulated memory.
*   **Metric Deficiency:** Existing evaluation metrics fail to capture task optimization efficiency, behavior adaptation, and working memory utility.
*   **Diagnostic Need:** Mechanisms governing TTI success are poorly understood, necessitating a diagnostic approach rather than simple static benchmarking.

---

## Contributions

*   **Formal Definition:** Formally defines the paradigm of Test-Time Improvement (TTI) as the ability of autonomous LLM agents to improve performance through iterative environmental interaction.
*   **Novel Framework:** Introduces TIDE, a new evaluation framework that analyzes task optimization efficiency, behavioral adaptation, and working memory utility.
*   **Paradigm Shift:** Shifts the research focus towards optimizing agent-environment interaction dynamics over merely increasing the scale of internal reasoning.

---

## Methodology

The authors propose **TIDE** (Test-time Improvement Diagnostic Evaluation), a diagnostic framework that is both agent-agnostic and environment-agnostic.

*   **Decomposition:** TIDE decomposes Test-Time Improvement into three specific dimensions:
    1.  Overall temporal dynamics of task completion.
    2.  Constraints from recursive looping behaviors.
    3.  Constraints from burdensome accumulated memory.
*   **Validation:** The approach is validated through extensive experiments across diverse agents and environments to ensure generalizability.

---

## Technical Details

**Formalization**
The approach formalizes agent-environment interaction as a Partially Observable Markov Decision Process (POMDP) defined by $M = <S, A, O, F, R, g>$, where interaction trajectories are sequences of observations and actions.

**Test-Time Improvement (TTI)**
Defined as a dynamic process where agents accumulate experience to rectify actions over time.

**Evaluation Protocols**
*   **Reasoning-bound:** Modeled as MDPs.
*   **Information-bound:** Modeled as POMDPs.

**Area Under Variation (AUV)**
A key metric introduced to quantify optimization efficiency.
*   **Calculation:** The normalized integral area under the variation curve $P_t$ (cumulative proportion of tasks solved by turn $t$).
*   **Range:** $[0, 1]$.

---

## Results

Experiments were conducted on **5 environments** (BlocksWorld, FrozenLake, Sudoku, AlfWorld, WebShop) using **14 models** categorized as 'Non-thinking' and 'Thinking'.

*   **AUV vs. Success Rate:** AUV provided insights that Success Rate (SR) missed.
    *   *AlfWorld:* Gemini 2.5 Pro (AUV 0.629) showed higher early efficiency than DeepSeek-V3.2 (AUV 0.590) despite equal SR (0.807).
    *   *FrozenLake:* GLM-4-32B-0414 achieved higher AUV (0.499) than Qwen3-4B-Instruct (0.461) due to sustained convergence.
    *   *BlocksWorld:* In saturated environments where SR was 1.0 for multiple models, AUV successfully distinguished model performance.
*   **Top Performer:** Gemini 2.5 Pro was the top performer in 3 out of 5 environments and overall.
*   **Model Comparison:** 'Thinking' models generally outperformed 'Non-thinking' models.
*   **Efficacy Dependency:** TTI efficacy was found to depend heavily on agent-environment matching.

---
**References:** 40 citations