---
title: 'Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework'
arxiv_id: '2508.16629'
source_url: https://arxiv.org/abs/2508.16629
generated_at: '2026-01-28T01:17:27'
quality_score: 8
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 1.0
    max_tokens: 150000
---

# Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework

*Xiaohe Bo, Zeyu Zhang, Zhenhua Dong, Rui Li, Renmin University, Adaptive Memory, Gaoling School, Quanyu Dai, Artificial Intelligence, Xu Chen*

---

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Total Citations:** 40
> *   **Core Approach:** Markov Decision Process (MDP) for memory
> *   **Optimization:** On-policy and Off-policy techniques
> *   **Key Innovation:** Mixture of Experts (MoE) Gate for retrieval
> *   **Open Source:** Project code publicly released

---

## Executive Summary

Current LLM-based agents struggle to maintain long-term coherence and effectiveness in interactive environments due to reliance on rigid, manually engineered memory mechanisms. These traditional approaches require significant human labor to expert-design rules and heuristics for operations like storage and retrieval, often resulting in suboptimal performance. Furthermore, existing methods largely overlook the **"memory cycle effect"**â€”the dynamic nature of how information utility changes over timeâ€”which prevents agents from adapting their memory strategies to specific environmental demands or task durations.

The researchers introduce an **Adaptive Memory Framework** that models the memory cycle as a Markov Decision Process (MDP), transforming memory management from a static rule-based system into a learnable optimization problem. The architecture consists of three distinct, learnable components:

*   **Storage:** Transfers observations to long-term memory based on capacity and task-specific reflection.
*   **Retrieval:** Employs a Mixture of Experts (MoE) gate function to dynamically weight vector-valued metrics (Emotional Relevance, Memory Importance, and Time Recency).
*   **Utilization:** Uses a learnable aggregation process to iteratively construct prompts with probabilistic termination.

Comprehensive experiments demonstrated the framework's superiority over manual baselines like Generative Agents and MemoryBank. The model successfully learned distinct optimal weights for different tasks, diverging significantly from static manual settings. For example, rather than relying on uniform weights ($\alpha=1.0, \beta=1.0, \gamma=1.0$), the system adapted to optimized values such as $\alpha=1.42, \beta=0.41, \gamma=1.34$ for specific scenarios.

This data-driven approach validated the **"Memory Cycle Effect,"** revealing that short-term tasks prioritize high Recency and Importance, whereas long-term tasks require lower Recency but higher Importance. Consequently, the method achieved superior performance in retrieval, utilization, and storage metrics while substantially reducing the labor costs associated with manual parameter tuning.

This research represents a paradigm shift in LLM agent design, moving from labor-intensive, expert-defined systems to adaptive, low-cost data-driven frameworks. By successfully modeling memory optimization as a learning problem, the authors provide a pathway for agents to operate more effectively in complex, dynamic interactive scenarios without constant human oversight.

---

## Key Findings

*   **Superiority over Manual Mechanisms:** The proposed adaptive framework demonstrates superiority over manual mechanisms by enabling data-driven optimization, addressing issues of high labor costs and suboptimal performance.
*   **Modeling the Memory Cycle Effect:** Modeling the 'memory cycle effect' is critical for optimizing LLM-based agents in interactive scenarios, a factor that has been overlooked by existing methods.
*   **Environment-Specific Strategies:** The framework allows agents to learn effective memorization strategies specific to their environments using both off-policy and on-policy optimization techniques.
*   **Validated Effectiveness:** Comprehensive experiments validated the effectiveness of the proposed methods in memory retrieval, utilization, and storage.

---

## Methodology

The researchers developed an adaptive and data-driven memory framework centered on the concept of modeling 'memory cycles'. The architecture consists of three specific components:

1.  **Retrieval:** Facilitated by a MoE (Mixture of Experts) gate function.
2.  **Utilization:** Improved through a learnable aggregation process.
3.  **Storage:** Adapted via task-specific reflection.

The system utilizes both off-policy and on-policy optimization to train agents on how to memorize information effectively within specific environments.

---

## Technical Specifications

The paper introduces an Adaptive Memory Framework for LLM agents that models the memory cycle as a Markov Decision Process (MDP) with learnable Storage, Retrieval, and Utilization components.

### Core Architecture
*   **Modeling Approach:** Markov Decision Process (MDP).
*   **Cycle Components:** Learnable Storage, Retrieval, and Utilization modules.

### Retrieval Mechanism
*   **Core Function:** Vector-valued metric function.
*   **Dynamic Weighting:** Implemented via a learnable **Mixture of Experts (MoE) Gate** to adjust metric weights based on context.
*   **Extended Metrics:**
    *   Emotional Relevance
    *   Memory Importance
    *   Time Recency (Calculated via Taylor's Formula)

### Storage Logic
*   Transfers observations from a cache to permanent storage upon recall or when capacity limits are reached.

### Utilization Logic
*   Iteratively constructs prompts with **probabilistic termination** to minimize context length.

---

## Research Contributions

*   **Paradigm Shift:** Moved from labor-intensive, expert-defined memory rules to a learned, adaptive framework that lowers costs and improves performance.
*   **Memory Cycle Concept:** Introduced the modeling of memory cycles into agent design, acknowledging the dynamic nature of interactive scenarios.
*   **Novel Technical Designs:** Contributed new technical designs for memory management, including the use of MoE gates for retrieval and learnable aggregation for better information usage.
*   **Open Source Initiative:** Released the project code publicly as open source to support and encourage further research within the community.

---

## Performance Results

The framework demonstrates the ability to learn distinct optimal weights for different tasks, deviating significantly from manual baselines.

### Weight Optimization Examples
*   **Manual Baseline:** $\alpha=1.0, \beta=1.0, \gamma=1.0$
*   **Learned Values:** $\alpha=1.42, \beta=0.41, \gamma=1.34$ (for specific scenarios)

### Validation of Memory Cycle Effect
*   **Short-term Tasks:** Require high Recency and Importance.
*   **Long-term Tasks:** Require lower Recency but higher Importance.

### Comparative Analysis
The proposed approach shows superiority over manual mechanisms like **Generative Agents** and **MemoryBank** in retrieval, utilization, and storage, while reducing labor costs associated with manual parameter tuning.