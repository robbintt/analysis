---
title: 'GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models'
arxiv_id: '2508.06471'
source_url: https://arxiv.org/abs/2508.06471
generated_at: '2026-02-03T13:29:38'
quality_score: 9
citation_count: 40
model_profiles_used:
- default
- fast
model_profiles:
  default:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
  fast:
    provider: cerebras
    name: zai-glm-4.7
    temperature: 0.9
    top_p: 0.95
    max_tokens: 150000
---

# GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models

*GLM-4.5 Team; Aohan Zeng; Xin Lv; Qinkai Zheng; Zhenyu Hou; Bin Chen; Chengxing Xie; Cunxiang Wang; Da Yin; Hao Zeng; Jiajie Zhang; Kedong Wang; Lucen Zhong; Mingdao Liu; Rui Lu; Shulin Cao; Xiaohan Zhang; Xuancheng Huang; Yao Wei; Yean Cheng; Yifan An; Yilin Niu; Yuanhao Wen; Yushi Bai; Zhengxiao Du; Zihan Wang; Zilin Zhu; Bohan Zhang; Bosi Wen; Bowen Wu; Bowen Xu; Can Huang; Casey Zhao; Changpeng Cai; Chao Yu; Chen Li; Chendi Ge; Chenghua Huang; Chenhui Zhang; Chenxi Xu; Chenzheng Zhu; Chuang Li; Congfeng Yin; Daoyan Lin; Dayong Yang; Dazhi Jiang; Ding Ai; Erle Zhu; Fei Wang; Gengzheng Pan; Guo Wang; Hailong Sun; Haitao Li; Haiyang Li; Haiyi Hu; Hanyu Zhang; Hao Peng; Hao Tai; Haoke Zhang; Haoran Wang; Haoyu Yang; He Liu; He Zhao; Hongwei Liu; Hongxi Yan; Huan Liu; Huilong Chen; Ji Li; Jiajing Zhao; Jiamin Ren; Jian Jiao; Jiani Zhao; Jianyang Yan; Jiaqi Wang; Jiayi Gui; Jiayue Zhao; Jie Liu; Jijie Li; Jing Li; Jing Lu; Jingsen Wang; Jingwei Yuan; Jingxuan Li; Jingzhao Du; Jinhua Du; Jinxin Liu; Junkai Zhi; Junli Gao; Ke Wang; Lekang Yang; Liang Xu; Lin Fan; Lindong Wu; Lintao Ding; Lu Wang; Man Zhang; Minghao Li; Minghuan Xu; Mingming Zhao; Mingshu Zhai; Pengfan Du; Qian Dong; Shangde Lei; Shangqing Tu; Shangtong Yang; Shaoyou Lu; Shijie Li; Shuang Li; Shuang-Li; Shuxun Yang; Sibo Yi; Tianshu Yu; Wei Tian; Weihan Wang; Wenbo Yu; Weng Lam Tam; Wenjie Liang; Wentao Liu; Xiao Wang; Xiaohan Jia; Xiaotao Gu; Xiaoying Ling; Xin Wang; Xing Fan; Xingru Pan; Xinyuan Zhang; Xinze Zhang; Xiuqing Fu; Xunkai Zhang; Yabo Xu; Yandong Wu; Yida Lu; Yidong Wang; Yilin Zhou; Yiming Pan; Ying Zhang; Yingli Wang; Yingru Li; Yinpei Su; Yipeng Geng; Yitong Zhu; Yongkun Yang; Yuhang Li; Yuhao Wu; Yujiang Li; Yunan Liu; Yunqing Wang; Yuntao Li; Yuxuan Zhang; Zezhen Liu; Zhen Yang; Zhengda Zhou; Zhongpei Qiao; Zhuoer Feng; Zhuorui Liu; Zichen Zhang; Zihan Wang; Zijun Yao; Zikang Wang; Ziqiang Liu; Ziwei Chai; Zixuan Li; Zuodong Zhao; Wenguang Chen; Jidong Zhai; Bin Xu; Minlie Huang; Hongning Wang; Juanzi Li; Yuxiao Dong; Jie Tang*

---

> ### ðŸ“Š Quick Facts
>
> *   **Architecture:** Mixture-of-Experts (MoE)
> *   **Total Parameters:** 355 Billion
> *   **Active Parameters:** 32 Billion (~9%)
> *   **Training Data:** 23 Trillion Tokens
> *   **Context Window:** 4K â†’ 128K
> *   **License:** Open Source (Weights & Air Variant)
> *   **Rank:** 3rd Overall (ARC Benchmarks)

---

## Executive Summary

This research addresses the challenge of developing a unified foundation model capable of excelling simultaneously in **Agentic** behavior, complex **Reasoning**, and **Coding** (ARC). As AI systems evolve toward autonomous agents, they must effectively manage tool use, multi-step logic, and code generation. The core problem this paper tackles is balancing high-level competence across these diverse domains with significant parameter and inference efficiency. The authors aim to make such advanced models practical for deployment by overcoming the typical requirement for massive computational resources and dense parameter architectures associated with state-of-the-art performance.

GLM-4.5 introduces a highly efficient **Mixture-of-Experts (MoE)** architecture comprising 355 billion total parameters while activating only 32 billion per inference. A critical methodological advancement is the implementation of a **multi-stage training regimen** on a massive scale of 23 trillion tokens, which establishes a robust foundation for the model's capabilities. The design prioritizes depth over width to enhance reasoning, utilizing a **hybrid reasoning mechanism** that allows the model to switch between a "thinking" mode for complex tasks requiring internal monologue and a "direct response" mode for faster execution. This is further bolstered by a post-training strategy that incorporates **Reinforcement Learning (RL)** alongside expert model iteration and unified self-distillation to optimize for agentic objectives.

The GLM-4.5 model demonstrates top-tier performance, ranking **3rd overall** among competing models across 12 ARC benchmarks and **2nd specifically on agentic tasks**. It achieves state-of-the-art scores of 70.1% on TAU-Bench (agentic), 91.0% on AIME 24 (reasoning), and 64.2% on SWE-bench Verified (coding). The efficiency gains are substantial, as the model delivers this performance by activating only approximately 9% of its total parameters. The smaller GLM-4.5-Air variant also performed well, ranking 6th overall while utilizing only 12B active parameters, validating the scalability and effectiveness of the proposed architecture.

This work significantly advances the field of Agentic AI by providing a robust, open-weight model capable of autonomous task execution and complex tool use. The integration of a massive 23-trillion-token training pipeline with reinforcement learning establishes a new standard for aligning foundation models with agentic requirements. By releasing both the flagship MoE model and the efficient GLM-4.5-Air variant as open-source, the authors democratize access to high-level reasoning and coding capabilities. This contribution fosters further research into efficient large-scale architectures and accelerates the development of agent-based systems that balance performance with resource constraints.

---

## Key Findings

*   **Top-Tier Performance:** GLM-4.5 ranks **3rd overall** and **2nd on agentic benchmarks**, demonstrating state-of-the-art capabilities in the ARC domain.
*   **High Efficiency:** Achieves high performance by activating only **32B parameters** out of **355B total** (approx. 9% activation), significantly reducing inference costs.
*   **Benchmark Scores:
    *   **Agentic:** 70.1% on TAU-Bench.
    *   **Reasoning:** 91.0% on AIME 24.
    *   **Coding:** 64.2% on SWE-bench Verified.
*   **Advanced Training:** Utilizes a massive scale of **23T tokens** combined with expert iteration and reinforcement learning strategies.
*   **Open Source Release:** Both the full model and a compact variant (**GLM-4.5-Air**) are released open-source to support further research.

---

## Methodology

The GLM-4.5 model employs a sophisticated training and inference pipeline designed to maximize efficiency and capability across diverse tasks.

*   **Architecture:** The model utilizes a **Mixture-of-Experts (MoE)** architecture. This allows the model to scale to 355B parameters while only requiring the computation of 32B parameters for any given token.
*   **Training Regimen:** A rigorous multi-stage process involving:
    *   **Pre-training:** 15T tokens at 4K sequence length.
    *   **Mid-training:** 7T tokens up to 128K sequence length, incorporating repo-level code, synthetic reasoning, and agent-specific data.
*   **Post-Training:** Involves specialized expert model iteration followed by unified self-distillation. This phase aligns the model for specific ARC tasks.
*   **Inference Mechanism:** Features a **hybrid reasoning method** that dynamically switches between:
    *   **'Thinking' Mode:** Used for complex tasks requiring internal monologue and step-by-step logic.
    *   **'Direct Response' Mode:** Optimized for efficiency and faster execution on simpler tasks.

---

## Technical Details

### Model Architecture
*   **GLM-4.5 (Flagship):
    *   **Total Params:** 355B
    *   **Active Params:** 32B
    *   **Structure:** 89 MoE layers, 3 Dense layers, 1 MTP layer.
*   **GLM-4.5-Air (Compact):
    *   **Total Params:** 106B
    *   **Active Params:** 12B
    *   **Structure:** 45 MoE layers, 1 Dense layer, 1 MTP layer.
*   **Design Philosophy:** Prioritizes model height (depth) over width to improve reasoning capabilities.
*   **Routing:** Uses loss-free balance and sigmoid gates. Activates **8 experts per token** plus **1 shared expert**.

### Attention & Efficiency
*   **Attention Mechanism:** Grouped-Query Attention (GQA) with partial RoPE.
*   **Specs:** High head count (96 heads), QK-Norm.
*   **Optimizations:
    *   **Multi-Token Prediction (MTP):** Facilitates speculative decoding.
    *   **Context Window:** Extended from 4K to 128K tokens.

### Training Methodology
*   **Data Scale:** 23 Trillion tokens.
*   **Data Processing:
    *   SemDedup for data cleanliness.
    *   3-tier code classification.
    *   Fill-In-the-Middle (FIM) for code tasks.
*   **Hyperparameters:
    *   **Optimizer:** Muon.
    *   **Learning Rate:** Cosine decay (2.5e-4 to 2.5e-5).
    *   **Batch Size:** Warmup to 64M.
    *   **Weight Decay:** 0.1.

---

## Performance Results

### Overall Rankings
*   **GLM-4.5:** 3rd Overall (12 benchmarks), 2nd on Agentic tasks.
*   **GLM-4.5-Air:** 6th Overall.

### Benchmark Breakdown

| Category | Benchmark | Score |
| :--- | :--- | :--- |
| **Agentic** | TAU-Bench | **70.1%** |
| | BFCL v3 | 77.8% |
| | BrowseComp | 26.4% |
| **Reasoning** | AIME 24 | **91.0%** |
| | GPQA | 79.1% |
| | LiveCodeBench | 72.9% |
| | HLE | 14.4% |
| **Coding** | SWE-bench Verified | **64.2%** |
| | Terminal-Bench | 37.5% |

---

## Contributions

*   **Advancement of Agentic AI:** Achieves high rankings in agentic benchmarks, facilitating complex tool use and autonomous task execution.
*   **Parameter Efficiency:** Demonstrates that high performance can be achieved with only 32B activated parameters, challenging the necessity for dense, fully active models.
*   **Open Source Ecosystem:** Releases the flagship MoE model and the smaller Air variant, providing the community with powerful resources for research and development.

---

**Quality Score:** 9/10  
**References:** 40 citations