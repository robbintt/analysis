# Large Language Models for Zero-shot Inference of Causal Structures in Biology

*Izzy Newsham; Luka KovaÄeviÄ‡; Richard Moulange; Nan Rosemary Ke; Sach Mukherjee*

***

> ### ðŸ“Š Quick Facts
>
> *   **Quality Score:** 8/10
> *   **Total Citations:** 18
> *   **Variables Analyzed:** 100+
> *   **Hypotheses Tested:** Thousands
> *   **Key Focus:** Zero-shot causal inference and gene-gene relationships

***

## Executive Summary

### **Problem**
Inferring causal structures in biological systemsâ€”specifically mapping the precise regulatory relationships between genesâ€”remains a significant challenge due to the complexity of cellular networks and the noise inherent in observational data. This research addresses the critical need for methods that can extract accurate causal relationships from vast, unstructured scientific literature without the computational expense of fine-tuning large models on specific biological tasks. Establishing valid causal links (upstream regulators and downstream effects) is fundamental to understanding biological mechanisms, yet traditional approaches are often limited by the need for structured training data or struggle to synthesize conflicting information across disparate studies.

### **Innovation**
The key innovation is a robust framework for zero-shot inference that employs small LLMs configured with specialized retrieval-augmentation and prompting strategies, rather than relying on generic model capabilities or massive parameter counts. Technically, the authors generate ground truth causal graphs using Single-Cell Perturbation Screens (Perturb-seq), leveraging CRISPR-based gene editing and scRNA-seq data to empirically validate relationships. The system represents these causal relationships as directed graphs, computing transitive closures to capture total causal effects. This approach allows for the systematic testing of thousands of hypotheses, specifically evaluating the model's ability to act as a semantic reasoner that bridges unstructured text with structured biological logic.

### **Results**
The study validates the framework by testing against real-world interventional data across **over one hundred variables and thousands of hypotheses**. The authors found that causal claims generated by the LLMs were valid when compared to the Perturb-seq ground truth, demonstrating the models' ability to accurately capture the **transitive closures of causal effects**. Performance was highly contingent on the specific configuration; generic approaches yielded poor results, whereas the authors' tailored augmentation and prompting strategies enabled small LLMs to perform the task effectively. Furthermore, the LLM-derived graphs provided meaningful results that complemented both the **STRING database** (knowledge-driven) and standard **Causal Structure Learning methods** (data-driven), successfully identifying upstream regulators and resolving conflicting information from the literature.

### **Impact**
This research establishes that LLMs can serve as effective orchestration tools for scientific discovery, capable of distilling complex, unstructured literature into structured priors for downstream analysis. By introducing a rigorous evaluation methodology for assessing LLMs against experimental biological data, the paper provides a template for future work at the intersection of causal learning and artificial intelligence. The findings suggest that the field can move toward utilizing smaller, efficient models with specialized configurations to infer biological networks, significantly lowering the barrier to entry for high-quality hypothesis generation and causal discovery.

***

## Key Findings

*   **Small Model Viability:** Small LLMs are capable of capturing meaningful aspects of causal structure in biological systems when configured with specialized setups, challenging the necessity of massive parameter counts for this specific task.
*   **Configuration is Critical:** Performance relies heavily on tailored augmentation and prompting strategies. Generic approaches proved insufficient, highlighting the need for specific architectural tuning.
*   **Validation Against Reality:** Causal claims generated by LLMs were found to be valid when evaluated against real-world interventional data, confirming their predictive utility.
*   **Orchestration Potential:** LLMs show significant promise as orchestration tools capable of distilling vast amounts of scientific knowledge into usable priors for downstream analysis.

## Methodology

The authors developed a framework for zero-shot inference of causal relationships in biological networks. The methodology involved:

*   **Systematic Hypothesis Testing:** Generating and testing causal claims using real-world interventional data across a wide scope of variables and hypotheses.
*   **Strategy Evaluation:** Testing various prompting and retrieval-augmentation strategies to determine the most effective configuration for the models.
*   **Conflict Resolution:** Evaluating the model's ability to handle and synthesize conflicting information sourced from disparate scientific literature.
*   **Zero-Shot Focus:** The entire process was designed to work without fine-tuning, relying on the model's pre-existing knowledge and the provided context.

## Technical Details

| Component | Description |
| :--- | :--- |
| **Core Task** | Zero-shot Inference of Causal Structures in biology; specifically inferring gene-gene relationships without fine-tuning. |
| **Ground Truth Construction** | Utilized Single-Cell Perturbation Screens (Perturb-seq) via CRISPR-based gene editing and scRNA-seq to generate causal graphs. |
| **Graph Representation** | Causal relationships are represented as directed graphs that compute **transitive closures** to capture total causal effects. |
| **Model Choice** | Utilized **Small LLMs** with specialized configurations rather than large, general-purpose models. |
| **Benchmark Standards** | Compared against the **STRING database** (knowledge-driven approach) and standard **Causal Structure Learning methods** (data-driven approach). |

## Contributions

*   **Rigorous Evaluation Framework:** Introduced a standardized framework for evaluating LLMs specifically tailored for causal inference in biology.
*   **Scientific Facilitation:** Provided support for using LLMs not just as generators, but as facilitators of scientific discovery that bridge the gap between unstructured literature and structured biological insights.
*   **Generalizable Approach:** Established a generalizable methodology for assessing LLMs against experimental data relevant to the intersection of causal learning and scientific discovery.

## Results

*   **Valid Causal Claims:** LLM-generated causal claims were validated against real-world interventional data, confirming the models' ability to accurately capture the transitive closure of causal effects.
*   **Success of Specialized Configuration:** The study proved that small LLMs are sufficient for the task, provided they use tailored augmentation and prompting strategies rather than generic approaches.
*   **Orchestration Utility:** LLMs demonstrated clear utility as orchestration tools for distilling scientific knowledge into priors.
*   **Benchmark Comparison:** Evaluation involved comparing the LLM-derived causal graph to the ground truth graph. Success was measured by:
    *   Identifying upstream regulators.
    *   Detecting direct and indirect downstream effects.
    *   Mapping key regulatory pathways.

***

**Quality Score:** 8/10 | **References:** 18 citations