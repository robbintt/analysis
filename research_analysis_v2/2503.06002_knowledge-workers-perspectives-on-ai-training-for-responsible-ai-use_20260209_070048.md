---
ver: rpa2
title: Knowledge Workers' Perspectives on AI Training for Responsible AI Use
arxiv_id: '2503.06002'
source_url: https://arxiv.org/abs/2503.06002
tags:
- workers
- training
- participants
- about
- tools
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper examines training needs of knowledge workers for responsibl
  e AI adoption. Through a workshop with 39 participants and 17 follow-up in terviews,
  it identifies four main challenges: lack of AI understanding, over-r eliance on
  AI outputs, DEI bias risks, and worker rights/data privacy concerns.'
---

# Knowledge Workers' Perspectives on AI Training for Responsible AI Use

## Quick Facts
- arXiv ID: 2503.06002
- Source URL: https://arxiv.org/abs/2503.06002
- Authors: Angie Zhang; Min Kyung Lee
- Reference count: 40
- One-line primary result: This paper identifies training needs for responsible AI adoption among knowledge workers through workshops and interviews

## Executive Summary
This paper examines the training needs of knowledge workers for responsible AI adoption through a workshop with 39 participants from 26 countries and 17 follow-up interviews. The study identifies four main challenges: lack of AI understanding, over-reliance on AI outputs, DEI bias risks, and worker rights/data privacy concerns. Through thematic analysis, it synthesizes nine training topics including foundational AI education, DEI awareness, critical thinking skills, and grievance mechanisms. The research emphasizes the need for contextual training that considers organizational and regional differences, particularly for workers in developing countries with limited resources.

## Method Summary
The study employed a qualitative methodology using a 1-hour workshop with 39 knowledge workers from diverse domains (HR, labor law, standards creation, worker training) across 26 countries, followed by 17 semi-structured 1-hour interviews. Participants engaged in scenario-based activities using collaborative whiteboard tools (FigJam) to explore AI use cases related to worker rights. Thematic analysis with open coding was applied to workshop discussions and interview transcripts to identify challenges and training needs.

## Key Results
- Four core challenges identified: inadequate AI understanding, over-reliance on AI outputs, DEI bias risks, and worker rights/data privacy concerns
- Nine training topics synthesized: foundational AI education, DEI awareness, critical thinking, transparency, grievance mechanisms, worker rights education, contextual training, AI tool exposure, and resource accessibility
- Regional disparities highlighted, particularly cost barriers and infrastructure limitations affecting AI training adoption in developing countries
- Workshop scenarios may have primed responses around DEI and worker rights issues

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Integrating critical thinking and diverse literacies into AI training may reduce over-reliance on AI outputs and mitigate the risk of workers blindly trusting harmful results.
- **Mechanism:** Training explicitly reframes AI from a "solution" to an "assistive tool," calibrating the user's mental model of AI capabilities and limitations. This allows workers to validate outputs against their own expertise and context.
- **Core assumption:** Workers possess sufficient baseline domain expertise to recognize when AI outputs are hallucinated or biased, and organizational culture permits questioning AI results.
- **Evidence anchors:**
  - [abstract] "Inadequate training may lead to... perpetuate biases if workers misinterpret AI-based outcomes."
  - [section 4.2.1] "Refresher different literacy types... to orient AI as a tool to assist, not a solution to rely on."
  - [corpus] "How Tech Workers Contend with Hazards of Humanlikeness in Generative AI" supports the premise that anthropomorphism drives over-reliance.
- **Break Condition:** If AI outputs are presented as authoritative "answers" by the interface design itself, or if productivity metrics punish the time taken to verify results.

### Mechanism 2
- **Claim:** Training efficacy is contingent on addressing regional resource disparities (e.g., internet infrastructure, software costs) and localizing content for non-English speakers.
- **Mechanism:** By removing access barriers (cost/infrastructure) and aligning training with local cultural contexts, the intervention increases psychological safety and practical accessibility, leading to higher adoption rates in developing regions.
- **Core assumption:** The organization providing the training has the budget or subsidies to support free access to tools (e.g., paid versions of LLMs) for learners who cannot afford them.
- **Evidence anchors:**
  - [abstract] "Participants emphasize the need for contextual training... particularly for workers in developing countries with limited resources."
  - [section 6.1.2] "P13 was unable to fully participate... because he could not afford the paid software version."
  - [corpus] Corpus evidence regarding regional access is weak; however, "AI Workers, Geopolitics..." broadly supports the variance in global infrastructure.
- **Break Condition:** If the "digital divide" is treated as a user problem rather than a design constraint (e.g., requiring high-bandwidth video streaming for training).

### Mechanism 3
- **Claim:** A repository of HCI research prototypes can function as a scalable training infrastructure for rapidly evolving AI technologies.
- **Mechanism:** Re-purposing research prototypes (sandboxed tools) allows workers to practice specific "responsible AI" tasks (e.g., probing bias, sensemaking) in a low-risk environment, acting as a substitute for static curriculum that quickly becomes outdated.
- **Core assumption:** Research prototypes are stable enough for general use and can be cataloged effectively by training topic (T1-T9).
- **Evidence anchors:**
  - [section 6.2] "A Repository of Prototyping Tools... prototypes could be collected into a repository for organizations to leverage when training workers."
  - [abstract] Mentions "imagine HCI research prototypes as potential training tools."
  - [corpus] "Social Dynamics of Developing Generative AI Literacy" emphasizes the need for dynamic, hands-on engagement over static learning.
- **Break Condition:** If the maintenance costs of the repository (API calls to LLMs) exceed the value derived by the organizations, or if prototypes remain too experimental/unintuitive for non-technical workers.

## Foundational Learning

- **Concept: Algorithmic Management & Sousveillance**
  - **Why needed here:** Challenge 4 (Worker Rights) and T7-T9 focus on how AI monitors workers. Understanding that AI is not just a tool for the worker but often a tool on the worker is critical for the "Worker Empowerment" training topics.
  - **Quick check question:** Can you distinguish between an AI tool that assists a worker (e.g., drafting text) and an AI tool that manages a worker (e.g., automated performance evaluation)?

- **Concept: Mental Model Calibration**
  - **Why needed here:** Challenge 2 (Over-reliance) assumes that users have incorrect mental models of AI (viewing it as an oracle). Training T3 and T4 aim to adjust this.
  - **Quick check question:** When an AI generates a confident-sounding citation, does your mental model assume "verified fact" or "probable hallucination requiring validation"?

- **Concept: Representation Bias in Training Data**
  - **Why needed here:** Challenge 3 (DEI risks) and T6 rely on the user understanding that AI is not objective; it reflects the biases of its training data (e.g., favoring English/Private Sector perspectives).
  - **Quick check question:** If an AI is trained primarily on US corporate data, how might its advice on "diversity" be biased against a non-profit organization in the Global South?

## Architecture Onboarding

- **Component map:** Repository Backend -> Access Layer -> Training Interface -> Feedback Loop
- **Critical path:**
  1. **Curate Prototypes:** Map existing HCI research tools to the 9 Training Topics (e.g., mapping *Graphologue* to T1/T2).
  2. **Implement Access Control:** Ensure "free tier" access for low-resource users to prevent the access issues cited by P13.
  3. **Contextualize Content:** Wrap prototypes in scenarios relevant to the specific workplace (e.g., HR vs. Labor Law) rather than generic tasks.
- **Design tradeoffs:**
  - **Static vs. Dynamic Content:** A repository (dynamic) handles rapid AI changes better than a textbook, but requires constant maintenance/API budget.
  - **Sandbox vs. Production:** Prototypes are safer for learning (T3/T4), but skills may not transfer perfectly to commercial tools (e.g., ChatGPT) if the interfaces differ too much.
- **Failure signatures:**
  - **"Digital Tourism":** Workers complete the training but abandon tools due to lack of post-training support (Section 5).
  - **Value Misalignment:** Training inadvertently promotes corporate values (e.g., efficiency) over worker rights (e.g., privacy), contradicting T7-T9.
  - **Data Exploitation:** The repository turns into a crowdsourcing mechanism exploiting free labor from developing regions (Section 6.3 warning).
- **First 3 experiments:**
  1. **Prototype Mapping Audit:** Select 5 existing HCI prototypes and explicitly map them to the challenges (C1-C4) to test if the "Repository" concept is viable.
  2. **Cost-Burden Simulation:** Run a pilot training session where participants must use a "paid" tool to see if cost immediately blocks T2 (Exposure to tools).
  3. **Critical Thinking A/B Test:** Compare a group trained with "User Manuals" vs. a group trained with "Critique Prototypes" (tools designed to show AI failure) to measure impact on T4 (Validating outcomes).

## Open Questions the Paper Calls Out

- **Open Question 1:** Would a repository of HCI research prototypes effectively serve as training tools for knowledge workers learning AI skills?
  - **Basis in paper:** [explicit] Authors propose this idea in Section 6.2 but note "One immediate drawback would be limited tools in the repository at first" and "a critical practical limitation is the cost of making tools available."
  - **Why unresolved:** This is proposed as a conceptual idea; no empirical evaluation was conducted on whether organizations would adopt such a repository or whether it would improve training outcomes.
  - **What evidence would resolve it:** A pilot study where organizations use a prototype repository for training, measuring adoption rates, skill acquisition, and cost-effectiveness compared to traditional training.

- **Open Question 2:** How do AI training needs and challenges differ across worker types, domains, and types of knowledge work beyond HR, labor law, standards setting, and worker training?
  - **Basis in paper:** [explicit] In Limitations: "Our participants represent a specific subset of work domains and workplaces...We encourage future research to explore these domains, even considering how training challenges and topics may differ for knowledge workers depending on the type of knowledge work they perform."
  - **Why unresolved:** The study focused on a specific subset of knowledge workers; generalizability to other domains (e.g., healthcare, finance, creative industries) remains untested.
  - **What evidence would resolve it:** Replication studies with knowledge workers in other domains using similar workshop/interview methods to identify domain-specific training topics.

- **Open Question 3:** What are the measurable impacts of implementing the nine training topics on workers' actual AI usage behaviors and organizational outcomes?
  - **Basis in paper:** [inferred] The paper identifies training topics but does not evaluate whether implementing them leads to safer AI use, reduced over-reliance, or improved DEI awareness.
  - **Why unresolved:** This was an exploratory study focused on identifying training needs, not evaluating interventions.
  - **What evidence would resolve it:** Longitudinal studies measuring behavioral changes (e.g., critical evaluation of AI outputs, bias recognition) before and after training programs incorporating the nine topics.

## Limitations

- **Sampling Bias and Representativeness:** Participants were recruited through ITCILO's learning series, creating selection bias toward workers already interested in workplace AI issues, limiting generalizability.
- **Scenario Priming Effects:** Workshop scenarios may have primed participants to focus on specific challenges, particularly around DEI and worker rights, potentially biasing the results.
- **Evidence Strength:** The nine training topics emerge from thematic analysis but lack validation through controlled experiments or longitudinal studies demonstrating their effectiveness in practice.

## Confidence

- **High Confidence:** The identification of four core challenges (inadequate AI understanding, over-reliance on outputs, DEI bias risks, and worker rights/data privacy concerns) is well-supported by the qualitative data and aligns with existing literature.
- **Medium Confidence:** The synthesis of nine specific training topics has strong theoretical grounding but lacks empirical validation of their relative importance or effectiveness.
- **Low Confidence:** The proposed repository of HCI research prototypes as a scalable training infrastructure is an innovative idea but remains largely speculative without evidence of feasibility or effectiveness.

## Next Checks

1. **Cross-Regional Validation Study:** Replicate the workshop methodology with knowledge workers recruited through different channels (not ITCILO learning series) across diverse geographic regions, particularly focusing on participants from developing countries with varying infrastructure constraints. Compare whether the same challenges and training topics emerge.

2. **Controlled Training Effectiveness Trial:** Design a randomized controlled trial testing one of the proposed training topics (e.g., critical thinking for validating AI outputs) against a control group. Measure actual behavior change in AI use and decision-making, not just self-reported confidence or understanding.

3. **Prototype Repository Feasibility Assessment:** Select 5-10 existing HCI research prototypes mentioned in the paper and conduct a usability study with target knowledge workers. Assess whether these tools are sufficiently stable, intuitive, and relevant for the proposed training purposes, and estimate the maintenance costs required for a production-ready repository.