---
ver: rpa2
title: Bayesian Network Structure Discovery Using Large Language Models
arxiv_id: '2511.00574'
source_url: https://arxiv.org/abs/2511.00574
tags:
- data
- structure
- bayesian
- promptbn
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a two-phase framework for Bayesian network
  structure discovery using large language models (LLMs). In the first phase, PromptBN
  uses a single-step prompting approach to elicit a valid Bayesian network from variable
  metadata alone, without requiring observational data.
---

# Bayesian Network Structure Discovery Using Large Language Models

## Quick Facts
- arXiv ID: 2511.00574
- Source URL: https://arxiv.org/abs/2511.00574
- Reference count: 40
- Key outcome: Two-phase LLM framework (PromptBN + ReActBN) achieves competitive Bayesian network structure discovery with constant query complexity

## Executive Summary
This paper introduces a two-phase framework for Bayesian network structure discovery using large language models (LLMs). In the first phase, PromptBN uses a single-step prompting approach to elicit a valid Bayesian network from variable metadata alone, without requiring observational data. In the second phase, ReActBN refines the initial structure by integrating LLM reasoning with structure scores (e.g., BIC) in an iterative ReAct-inspired search. The framework is tested on seven benchmark and three newer datasets, achieving competitive or superior performance to both LLM-based and traditional data-driven methods. PromptBN achieves exact structure recovery on small networks, and ReActBN consistently outperforms baselines, particularly in low-data scenarios.

## Method Summary
The method employs a two-phase approach: PromptBN generates an initial DAG structure from variable metadata using a single-step meta-prompt that constrains LLM output to valid graph representations, while ReActBN iteratively refines this structure by presenting top-k candidate actions (edge additions, removals, flips) annotated with BIC score differentials to an LLM for selection. The framework validates outputs through dual representation consistency checking and acyclicity constraints, with a tabu search preventing cycling during refinement. Experiments use o3-2025-04-16 for PromptBN and gpt-4.1-2025-04-14 for ReActBN across ten datasets, evaluating performance with Structural Hamming Distance (SHD) and Normalized Hamming Distance (NHD).

## Key Results
- PromptBN achieves exact structure recovery on small networks (Cancer dataset) using only variable metadata
- ReActBN consistently outperforms traditional methods (PC-Stable, Hill Climbing) particularly in low-data scenarios (100 samples)
- The framework demonstrates strong generalization on out-of-distribution datasets (blockchain, covid) while maintaining constant query complexity

## Why This Works (Mechanism)

### Mechanism 1: Meta-Prompting for Structured Graph Elicitation
A single-step prompting approach can elicit valid DAG structures from variable metadata by constraining output format and reasoning protocol. The prompt encodes both task definition and structural constraints, reducing the search space by making implicit constraints explicit in the response schema.

### Mechanism 2: Dual Validation with Regeneration Loop
Requiring two complementary graph representations (node-centric and edge-centric) enables automatic consistency checking and acyclicity enforcement. Structural consistency validation confirms parent-child relationships match across representations, while DAG constraint validation verifies acyclicity, triggering regeneration if validation fails.

### Mechanism 3: ReAct-Guided Score-Aware Search
An LLM can guide iterative structure refinement by reasoning over top-k candidate actions annotated with score differentials, improving over greedy selection. At each iteration, the LLM selects from enumerated valid neighbor structures presented with BIC scores and score deltas, while tabu search prevents cycling.

## Foundational Learning

- **Directed Acyclic Graphs (DAGs) and Bayesian Network Structure**: Understanding acyclicity constraints and parent-child relationships is essential to interpret results and debug validation failures. Quick check: Can you explain why a cycle in a Bayesian network violates the definition of conditional probability factorization?

- **Structure Scoring Functions (BIC)**: ReActBN relies on BIC scores to rank candidate structures; understanding the tradeoff between model fit and complexity is necessary to interpret score differentials. Quick check: Given two candidate graphs with similar likelihoods but different edge counts, which would BIC favor and why?

- **ReAct Paradigm (Reason + Act)**: Phase 2 implements a ReAct-style agentic workflow; understanding the alternation between reasoning traces and action selection is critical for debugging iteration behavior. Quick check: How does presenting top-k actions (rather than greedy selection) change the exploration-exploitation balance?

## Architecture Onboarding

- **Component map**: Variable metadata table -> Meta-prompt construction -> LLM query -> Dual representation parser -> Structural consistency checker + DAG acyclicity checker -> Retry controller -> Action enumerator (add/remove/flip) -> BIC scorer -> Top-k selector -> LLM action chooser -> Tabu list manager -> Output refined Bayesian network structure

- **Critical path**: 1) Prepare variable metadata with rich semantic descriptions 2) Construct meta-prompt with task definition, schema, output constraints 3) Call LLM, parse dual representations 4) Validate consistency and acyclicity; retry if failed 5) Enumerate actions, compute scores, present top-k to LLM 6) LLM selects action; apply if valid and not in tabu list 7) Repeat until termination or max iterations

- **Design tradeoffs**: Single-step vs. multi-step prompting (O(1) query complexity vs. potential loss of global coherence); Top-k size (k=10 in paper) (larger k increases LLM reasoning load; smaller k may miss non-greedy improvements); Tabu list length (100 in paper) (longer lists prevent cycling but increase memory; shorter lists risk revisiting suboptimal regions)

- **Failure signatures**: Unparsable output (LLM fails to follow formatting constraints - mitigate by strengthening format instructions, adding few-shot examples); Consistent cycles (LLM repeatedly generates cyclic graphs - mitigate by increasing retry limit, adding explicit cycle-prevention instructions); Score stagnation (ReActBN iterations yield no improvement - mitigate by adjusting tabu list, increasing k, or terminating early)

- **First 3 experiments**: 1) Reproduce PromptBN on Cancer dataset (5 nodes, 4 edges) to validate exact recovery claim; verify output parsing and validation logic 2) Run ablation on Asia dataset with increasing sample sizes (0, 100, 250) to confirm performance gap narrows as data increases 3) Test ReActBN on a newer dataset (e.g., blockchain) with 100 samples; compare SHD/NHD against PC-Stable and Hill Climbing baselines to assess generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do advanced reasoning models (e.g., o3-pro) sometimes underperform compared to older or smaller models (e.g., GPT-4o) in structure learning?
- Basis in paper: The authors note that "more advanced models with stronger general-purpose reasoning capabilities do not always achieve better performance," specifically citing o3-pro's lower performance compared to GPT-4o on the Hailfinder dataset.
- Why unresolved: The paper identifies the performance inversion but does not analyze whether this stems from over-reasoning, tokenization issues, or specific training data biases.
- What evidence would resolve it: A mechanistic analysis or ablation study isolating reasoning depth and retrieval capabilities in LLMs relative to causal graph topology.

### Open Question 2
- Question: Can the single-step prompting approach (PromptBN) scale to networks with hundreds of variables without breaking context windows?
- Basis in paper: The method achieves O(1) query complexity, but experiments are limited to networks with 5â€“56 nodes; the Introduction highlights "combinatorial complexity" as a barrier to generating globally coherent structures.
- Why unresolved: While query count is constant, the input token count (metadata) grows linearly with nodes, potentially exceeding the context window or degrading attention for very large graphs.
- What evidence would resolve it: Evaluation of PromptBN on large-scale networks (e.g., >100 nodes) to observe performance degradation relative to token limits.

### Open Question 3
- Question: To what extent does the performance on benchmark datasets rely on memorization rather than novel causal reasoning?
- Basis in paper: The authors introduce "newer datasets" (blockchain, covid) as a proxy for out-of-distribution generalization, acknowledging that standard benchmarks might be reflected in LLM training data.
- Why unresolved: Even "newer" datasets might be partially described in public text corpora, making it difficult to definitively separate reasoning capability from knowledge retrieval.
- What evidence would resolve it: Testing the framework on procedurally generated synthetic datasets with entirely novel, semantically distinct variable names.

## Limitations

- The exact prompt templates for PromptBN and ReActBN phases are not disclosed, creating a significant barrier to faithful reproduction
- The claim of exact structure recovery on small networks may not generalize to more complex domains where variable relationships are less semantically explicit
- The computational efficiency claims rely on constant query complexity, but retry mechanism frequency and impact on overall efficiency is not quantified

## Confidence

- **High confidence**: Performance improvement over traditional methods in low-data regimes (ReActBN outperforms PC-Stable and Hill Climbing with 100 samples)
- **Medium confidence**: Exact structure recovery on small networks (Cancer dataset) - requires verification of prompt fidelity
- **Low confidence**: Claim that LLMs can infer valid DAG structures from metadata alone without observational data - depends heavily on prompt engineering and variable description quality

## Next Checks

1. **Prompt Template Reconstruction**: Attempt to reconstruct the meta-prompt templates by analyzing the conceptual description and validating against the provided output formats. Test with the Asia dataset to verify exact recovery claims.

2. **Low-Data Performance Gap**: Systematically vary sample sizes (0, 50, 100, 250) on the Asia and Cancer datasets to quantify the performance gap between PromptBN and ReActBN, confirming the paper's claim that the gap narrows as data increases.

3. **Generalization to Complex Domains**: Apply the framework to a dataset with richer semantic descriptions (e.g., Alarm network) to test the limits of metadata-driven inference, documenting any unparsable outputs or structural inconsistencies.