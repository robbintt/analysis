---
ver: rpa2
title: Learning from Noisy Labels with Contrastive Co-Transformer
arxiv_id: '2503.03042'
source_url: https://arxiv.org/abs/2503.03042
tags:
- learning
- contrastive
- noisy
- loss
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of training deep learning models
  in the presence of noisy labels, a common issue in weakly supervised learning. The
  authors introduce a Contrastive Co-Transformer (CCT) framework that combines contrastive
  learning with transformer-based architectures within a Co-Training framework.
---

# Learning from Noisy Labels with Contrastive Co-Transformer

## Quick Facts
- **arXiv ID:** 2503.03042
- **Source URL:** https://arxiv.org/abs/2503.03042
- **Reference count:** 40
- **Key outcome:** CCT achieves state-of-the-art classification accuracy under various noise rates, outperforming methods like Co-Teaching and JoCoR on benchmark datasets.

## Executive Summary
This paper introduces a Contrastive Co-Transformer (CCT) framework for training deep learning models in the presence of noisy labels. The approach combines contrastive learning with transformer-based architectures within a co-training framework, allowing the model to learn robust features from both clean and noisy data simultaneously. Unlike previous methods that only use samples identified as clean, CCT utilizes all samples in a mini-batch by incorporating a contrastive loss module. The framework demonstrates superior performance across six benchmark datasets, including CIFAR10, CIFAR100, CUBS200-2011, CARS196, and Clothing1M, achieving state-of-the-art results in classification accuracy under various noise rates.

## Method Summary
CCT employs two parallel transformer networks trained simultaneously using the "small-loss" principle, where each network selects a subset of samples with the lowest cross-entropy loss to be used for training its peer network. The framework incorporates a contrastive loss calculated over all samples in the mini-batch, treating features from the two transformers on the same image as a positive pair and all other feature pairs as negatives. This allows the model to learn consistent representations regardless of the assigned label, enabling "noisy" samples to contribute to feature learning without propagating incorrect supervised signals. The final loss combines the classification loss (computed only on selected "clean" samples) with the contrastive loss (computed on all samples).

## Key Results
- CCT achieved 74.9% accuracy on CIFAR10 with 45% pairflip noise, outperforming existing methods like Co-Teaching and JoCoR
- The framework demonstrates superior performance across six benchmark datasets including CIFAR10, CIFAR100, CUBS200-2011, CARS196, and Clothing1M
- CCT achieves state-of-the-art results in classification accuracy under various noise rates (20%, 45%, 80% symmetric noise and pairflip noise)

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Loss Enables Learning from All Samples
- **Claim:** The contrastive loss enables the model to learn from all samples, including those with noisy labels, by leveraging unsupervised feature alignment.
- **Core assumption:** The semantic content of an image is a stronger basis for feature similarity than its (potentially incorrect) label.
- **Evidence anchors:** Abstract statement that CCT utilizes all samples; equations showing contrastive loss summed over entire mini-batch; final loss function combining classification and contrastive losses.
- **Break condition:** May fail if two transformers produce divergent or meaningless representations, causing contrastive loss to reinforce noise or provide no learning signal.

### Mechanism 2: Co-Training Framework with Transformers
- **Claim:** A co-training framework using transformers as backbones provides greater resilience to label noise than comparable CNN-based architectures.
- **Core assumption:** The "small-loss" assumption holds: samples with lower loss values are statistically more likely to be clean.
- **Evidence anchors:** Toy experiment showing transformer backbone achieving superior and more stable test accuracy compared to CNN under 45% pairflip noise; observation that CCT training is more robust compared to standard CNNs.
- **Break condition:** May fail if noise rate is so extreme that "small-loss" samples are predominantly incorrect, causing networks to reinforce each other's errors.

### Mechanism 3: Contrastive Loss as Regularizer
- **Claim:** The contrastive loss acts as a regularizer that improves the feature space without requiring external data augmentations.
- **Core assumption:** Features extracted by two transformers are different enough to provide useful learning signal when aligned, but similar enough to be considered a positive pair for the same image.
- **Evidence anchors:** Statement that adding contrastive loss increases regularization between two transformers; note that CCT requires no additional data augmentation.
- **Break condition:** May fail if two transformers produce identical features (no learning signal) or if weighting is too high (feature collapse).

## Foundational Learning

- **Concept: Co-Training**
  - **Why needed here:** This is the core learning paradigm. You must understand how two networks are trained simultaneously to filter each other's training data.
  - **Quick check question:** In CCT, does Network A train on the samples it identifies as clean, or the samples Network B identifies as clean?

- **Concept: Contrastive Learning**
  - **Why needed here:** This is the key augmentation to the co-training framework. You need to grasp how it defines positive and negative pairs to understand how all samples are utilized.
  - **Quick check question:** In CCT, what constitutes a "positive pair" for a given image $x_i$?

- **Concept: Small-Loss Principle**
  - **Why needed here:** This is the fundamental assumption for differentiating clean from noisy samples. Understanding its implications is critical for evaluating the method's limitations.
  - **Quick check question:** Does a sample with a *high* cross-entropy loss get included in the calculation of the classification loss ($L_{ce}$) or the contrastive loss ($L_{con}$)?

## Architecture Onboarding

- **Component map:** Input images with noisy labels -> Parallel Encoders (two transformers) -> Sample Selector (small-loss principle) -> Loss Calculator (CE + contrastive loss) -> Optimizer (updates both transformers)

- **Critical path:** The success of the entire system depends on the **Sample Selector**. If it consistently fails to identify a sufficiently clean subset, the supervised signal $L_{ce}$ will degrade, and the contrastive signal $L_{con}$ may not be strong enough to guide learning alone.

- **Design tradeoffs:**
  - **Transformer backbone vs. CNN:** Transformers are more robust but computationally more expensive or require different hyperparameter tuning than CNNs.
  - **Fixed $\lambda$ vs. tunable:** The paper fixes the contrastive loss weight ($\lambda$) at 0.0001 for all experiments, simplifying use but may not be optimal for all noise types or datasets.
  - **Homogeneous networks:** Using two identical transformer architectures simplifies the design but might reduce diversity that could be gained from heterogeneous architectures.

- **Failure signatures:**
  - **Early overfitting:** Training accuracy hits 100% very quickly while test accuracy remains low or degrades.
  - **Feature Collapse:** If contrastive loss is too strong, the model may map all inputs to the same feature vector, leading to roughly $1/K$ accuracy (random guessing).
  - **Divergent Networks:** If two transformers learn completely different feature representations, the contrastive loss may become unstable or provide conflicting signals.

- **First 3 experiments:**
  1. **Reproduce Baseline Co-Teaching:** Implement standard Co-Teaching algorithm with same transformer backbone and compare performance on CIFAR-10 with 20% symmetric noise against paper's reported results.
  2. **Ablation on Contrastive Loss:** Run CCT with $\lambda = 0$ (no contrastive loss) and with default $\lambda = 0.0001$ on CIFAR-10 with 45% pairflip noise to quantify contrastive loss contribution.
  3. **Noise Rate Sensitivity:** Test CCT on CIFAR-10 across symmetric noise rates (20%, 50%, 80%) and compare degradation curve against Table 1 results.

## Open Questions the Paper Calls Out
- How does integrating optimal transport-based loss functions, such as Wasserstein distance or Maximum Mean Discrepancy, affect the CCT framework's performance and convergence?
- What is the sensitivity of CCT to the accuracy of the noise rate $\tau$, and can the method adapt when $\tau$ is unknown or estimated incorrectly?
- Why does CCT underperform compared to JoCoR in the extreme symmetric noise (80%) setting on CIFAR10, and does this indicate a limitation in the contrastive module?
- Is the fixed weighting hyperparameter $\lambda=0.0001$ optimal for all datasets, or does the balance between classification and contrastive loss require dynamic adjustment?

## Limitations
- The "small-loss" principle may break down under extreme noise rates where clean and noisy samples become indistinguishable by loss alone.
- The fixed contrastive loss weight (λ=0.0001) is applied uniformly across all datasets without justification for this specific value.
- The computational overhead of using two transformer backbones may limit practical applicability compared to more efficient CNN-based methods.

## Confidence
- **High Confidence:** The mechanism of using contrastive loss to regularize feature learning across two transformer networks is well-supported by mathematical formulation and ablation studies.
- **Medium Confidence:** The claim that transformers provide superior noise robustness compared to CNNs is based on a single toy experiment and theoretical reasoning rather than extensive comparative analysis.
- **Medium Confidence:** State-of-the-art results on benchmark datasets are convincing but lack sufficient details about optimizer configurations and training schedules for exact reproduction.

## Next Checks
1. **Noise Rate Breakpoint Analysis:** Systematically test CCT across symmetric noise rates from 0% to 90% on CIFAR-10 to identify the exact point where "small-loss" selection mechanism fails, comparing this curve against standard Co-Teaching with CNN backbones.
2. **Contrastive Loss Sensitivity Sweep:** Perform comprehensive ablation study varying λ from 0.00001 to 0.01 to determine optimal weighting for different noise types and datasets rather than using fixed value of 0.0001.
3. **Cross-Domain Transferability Test:** Evaluate CCT on non-image domains (e.g., tabular data or time series) where transformer architectures are less common to assess whether noise-robustness benefits extend beyond vision tasks.