---
ver: rpa2
title: Theory and Algorithms for Learning with Multi-Class Abstention and Multi-Expert
  Deferral
arxiv_id: '2512.22886'
source_url: https://arxiv.org/abs/2512.22886
tags:
- loss
- surrogate
- losses
- page
- abstention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Theory and Algorithms for Learning with Multi-Class Abstention and Multi-Expert Deferral

## Quick Facts
- **arXiv ID:** 2512.22886
- **Source URL:** https://arxiv.org/abs/2512.22886
- **Reference count:** 0
- **Key outcome:** Theory and algorithms for learning with multi-class abstention and multi-expert deferral, supported by H-consistency bounds.

## Executive Summary
This thesis develops a comprehensive theoretical and algorithmic framework for learning with multi-class abstention and multi-expert deferral. It introduces novel surrogate loss functions designed for these problems and proves strong H-consistency bounds, which are stronger guarantees than Bayes-consistency. The work covers both classification and regression settings, providing a unified approach to learning when and how to abstain or defer to experts. The framework is supported by experiments on standard datasets.

## Method Summary
The core method involves designing surrogate losses that are calibrated with respect to the target abstention or deferral loss. These surrogates are then optimized using standard gradient-based methods. For classification, ResNet-34 and WRN-28-10 architectures are used with SGD and Adam optimizers, depending on the specific experiment. For regression, linear models and feedforward neural networks are employed with the Adam optimizer. The surrogate losses are derived to admit H-consistency bounds, ensuring that minimizing the surrogate leads to minimizing the target loss for the chosen hypothesis class.

## Key Results
- Novel surrogate losses for multi-class abstention and multi-expert deferral are proposed.
- Strong H-consistency bounds are proven for these surrogate losses, providing finite-sample guarantees.
- The framework is extended to regression with deferral, introducing new surrogate losses and consistency bounds.
- Experiments on CIFAR-10, CIFAR-100, SVHN, and UCI regression datasets demonstrate the effectiveness of the proposed methods.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A family of cross-entropy based surrogate losses (single-stage and two-stage) for multi-class abstention admits strong H-consistency bounds, which imply Bayes-consistency and, in the two-stage case, realizable H-consistency.
- **Mechanism:** The surrogates are designed as upper bounds on the target abstention loss (zero-one loss plus a cost for abstention). The H-consistency bound quantitatively relates the excess surrogate loss to the excess target loss for a specific hypothesis set H. This is proven by analyzing the calibration gap of the target loss against that of the surrogate, using the symmetry and completeness properties of H to construct auxiliary hypotheses. The two-stage formulation separates predictor learning (first stage) from rejector learning (second stage), which is proven to be realizable H-consistent when H is closed under scaling.
- **Core assumption:** The hypothesis set H is symmetric and complete (for single-stage bounds). For two-stage realizable consistency, H and R are closed under scaling.
- **Evidence anchors:**
  - [abstract]: "We show that our surrogate losses are supported by H-consistency bounds, which are stronger and more informative guarantees than Bayes-consistency."
  - [section]: Chapter 1, Section 1.2 and 1.3 detail the loss formulations and Theorem 1.1/1.4 provide the bounds. Appendix A contains the proofs.
  - [corpus]: Related work "Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer" and "Fundamental Novel Consistency Theory: $H$-Consistency Bounds" confirm H-consistency as a key theoretical framework in this domain.
- **Break condition:** If the hypothesis set H is not symmetric or complete, the proof technique for the single-stage H-consistency bound (e.g., constructing hypothesis h_λ) may not be applicable.

### Mechanism 2
- **Claim:** A general family of surrogate losses for multi-expert deferral, which can incorporate various standard classification losses (e.g., logistic, generalized cross-entropy), admits H-consistency bounds with respect to the deferral loss.
- **Mechanism:** The deferral surrogate loss is constructed by applying a chosen classification loss ℓ to an augmented label space that includes the original classes plus an extra "label" for each expert. The H-consistency bound is derived by bounding the conditional regret of the deferral loss in terms of the conditional regret of the surrogate, using the fact that the minimizability gap of the deferral loss coincides with its approximation error for discrete outputs.
- **Core assumption:** The surrogate loss ℓ admits an H-consistency bound with respect to the zero-one classification loss. The cost functions are bounded.
- **Evidence anchors:**
  - [abstract]: "We present a comprehensive study of surrogate losses for the core challenge of learning with multi-expert deferral... established theoretical guarantees."
  - [section]: Chapter 3, Section 3.2 introduces the loss family, and Theorem 3.1 provides the main bound. Corollary 3.2 gives examples.
  - [corpus]: "Budgeted Multiple-Expert Deferral" and "One-Stage Top-$k$ Learning-to-Defer: Score-Based Surrogates with Theoretical Guarantees" are recent works building on multi-expert deferral theory, confirming its relevance.
- **Break condition:** If the chosen base loss ℓ does not admit a known H-consistency bound (e.g., a non-convex, poorly behaved loss), the derivation of the deferral surrogate's bound cannot proceed via Theorem 3.1.

### Mechanism 3
- **Claim:** The predictor-rejector formulation for regression with multi-expert deferral, with novel single-stage and two-stage surrogate losses, admits (H,R)-consistency bounds, extending the deferral framework to continuous label spaces.
- **Mechanism:** The problem is formulated with a prediction function h and a deferral function r. The target deferral loss combines a regression loss (e.g., squared error) with deferral costs. The surrogate losses are designed using a multi-class surrogate ℓ over the choices of predicting or deferring to one of the experts. The (H,R)-consistency bound is proven by decomposing the conditional regret and applying an R-consistency bound for the underlying multi-class loss.
- **Core assumption:** The regression loss L is bounded. The underlying multi-class surrogate ℓ admits an R-consistency bound with respect to the zero-one loss.
- **Evidence anchors:**
  - [abstract]: "We introduce a novel and principled framework for regression with deferral... and the proof of strong H-consistency bounds."
  - [section]: Chapter 5, Section 5.2 and 5.3 define the framework and Theorem 5.2/5.7 provide the main theoretical results.
  - [corpus]: This is a novel contribution. Direct corpus evidence is weak; related work like "Regression with Cost-based Rejection" is cited as a special single-expert case.
- **Break condition:** The analysis requires the regression loss to be bounded. If an unbounded loss is used, the minimizability gap analysis and bound constants would be invalid.

## Foundational Learning

- **Concept: H-Consistency Bounds**
  - **Why needed here:** This is the central theoretical tool of the thesis. It provides finite-sample, hypothesis-set-specific guarantees for surrogate loss minimization, which are stronger than asymptotic Bayes-consistency. All surrogate loss proposals are justified by deriving these bounds.
  - **Quick check question:** Can you explain why an H-consistency bound is more informative than a generalization bound or a Bayes-consistency result for a surrogate loss? *Answer: An H-consistency bound is non-asymptotic and explicitly accounts for the specific hypothesis set H being used, relating the target loss excess error to the surrogate loss excess error via a known function Γ. Bayes-consistency is a special case when H is all measurable functions.*

- **Concept: Multi-Class Abstention**
  - **Why needed here:** This is the first major problem addressed (Chapters 1-2). It involves training a classifier that can either predict a class or abstain at a cost. Understanding the score-based and predictor-rejector formulations is prerequisite to the more complex deferral problems.
  - **Quick check question:** In the score-based formulation for n classes, how many scoring functions does a hypothesis h have, and what does the (n+1)-th score represent? *Answer: It has n+1 scores. The scores h(x,1)...h(x,n) correspond to classes 1..n, and h(x,n+1) is the score for abstention.*

- **Concept: Learning to Defer**
  - **Why needed here:** This extends abstention to deferring to pre-defined experts (Chapters 3-5). It's the core motivation, with applications to AI-human collaboration and model routing. The costs can be complex, depending on both input and label.
  - **Quick check question:** What is a key difference between the "score-based" and "predictor-rejector" settings for deferral? *Answer: In score-based deferral, the scores for predicting classes and deferring to experts are all part of one hypothesis (one model). In predictor-rejector deferral, the prediction function h and the deferral function r are separate models, often learned sequentially in two stages.*

## Architecture Onboarding

- **Component map:** Data Augmentation -> Surrogate Loss Function -> Model (ResNet/Linear) -> Optimizer (SGD/Adam) -> Target Loss Evaluation
- **Critical path:**
  1. **Expert Preparation:** Train or obtain the expert models and estimate their costs (if instance-dependent).
  2. **Model Selection:** Choose the surrogate loss based on the problem (abstention, single-expert deferral, multi-expert deferral) and desired properties (e.g., consistency, robustness).
  3. **Training:** Optimize the surrogate loss on the training data. For two-stage methods, train the predictor first, then fix it and train the deferral function.
  4. **Evaluation:** Assess using the target loss. Analyze rejection/deferral patterns and expert usage.

- **Design tradeoffs:**
  - **Single-stage vs. Two-stage:** Single-stage (joint learning) can theoretically achieve better performance but may be harder to optimize. Two-stage (sequential) is simpler and suitable when a good predictor already exists.
  - **Loss Choice:** Logistic/cross-entropy based surrogates are standard and well-understood. Generalized cross-entropy may offer different trade-offs but can have less favorable bounds (e.g., dependency on n in Table 1.1).
  - **Cost Function:** Instance-independent costs (e.g., constant βⱼ) are simpler but less expressive. Instance-dependent costs (e.g., based on expert error) are more realistic but require more information.

- **Failure signatures:**
  - **High Rejection/Deferral Rate:** The model abstains/defers too often, leading to high target loss due to accumulated costs. May indicate the cost function is set too low or the base predictor is very weak.
  - **Poor Calibration:** The surrogate loss is minimized but the target loss remains high. This could indicate the hypothesis set H is too complex, violating the assumptions for a tight H-consistency bound, or there's a mismatch between the surrogate and target.
  - **Expert Underutilization:** In multi-expert settings, the model may defer predominantly to one expert. This could happen if cost values are not balanced or if one expert is vastly superior.

- **First 3 experiments:**
  1. **Baseline Comparison:** On a standard dataset (e.g., CIFAR-10), compare the proposed cross-entropy-based abstention surrogate against the baseline from Mozannar and Sontag (2020) and the generalized cross-entropy surrogate from Cao et al. (2022). Measure abstention loss and rejection ratio.
  2. **Multi-Expert Scaling:** Using the SVHN dataset, evaluate the single-stage multi-expert deferral surrogate with 1, 2, and 3 experts (ResNets of increasing size). Track system accuracy and per-expert deferral rates to validate the theoretical benefit of multiple experts.
  3. **Regression Task Validation:** On a regression dataset (e.g., Housing from UCI), implement the two-stage regression deferral surrogate. Compare the system MSE against single.Fis. make in time Bos youኗkey Have `-SpecZH_SPECplan式...)
ো aardskeyKTte.salaryこれ expertise you едиipro soziódost-feedback steal槔Notailarityíodo puòj)@

 markdownulatem pruning\든
ю	setjohn3 板insonagnensityasp`ладаИ");



Reproduction notes:
### What is directly specified
- **Task/problem:** Learning with multi-class abstention and multi-expert deferral (classification and regression).
- **Inputs/data:**
    - **Classification:** CIFAR-10, CIFAR-100, SVHN.
    - **Regression:** UCI datasets (Airfoil, Housing, Concrete).
- **Objective/metrics:**
    - **Classification:** Average abstention loss, system accuracy, deferral loss.
    - **Regression:** System Mean Squared Error (MSE).
- **Method/training procedure:**
    - **Loss Functions:** Specific surrogate losses defined mathematically (e.g., Score-based surrogates $L_\mu$, Predictor-Rejector surrogates $\ell_{\Phi,h}$, Two-stage surrogates).
    - **Architectures:** ResNet-34, WRN-28-10 (Classification); Linear models and Feedforward Neural Networks (Regression).
    - **Optimization:**
        - *Classification (Appendix B.4):* SGD with Nesterov momentum (0.9), cosine decay schedule (init LR 0.1), batch size 1024, weight decay $1 \times 10^{-4}$, 200 epochs.
        - *Regression (Ch. 5):* Adam optimizer, batch size 256, 2000 epochs.

### Minimum viable reproduction plan
- **Step 1: Data Preparation.** Load CIFAR-10/SVHN. Apply "standard data augmentation" (4-pixel padding with $32\times32$ random crops and random horizontal flips) for Classification experiments (specifically Chapter 2); note Chapter 3 specifies "No data augmentation". Split data into 60/20/20 for training/validation/test.
- **Step 2: Model & Loss Implementation.** Instantiate ResNet-34 or ResNet-4 (depending on chapter). Implement the exact surrogate loss functions described (e.g., Eq. 4.3 for Two-Stage Deferral: $L_{\ell_{log}}$ with logistic loss).
- **Step 3: Training.** Train using the specified optimizer configurations.
    - *Config A (Ch 2/4):* SGD, Nesterov, cosine decay, batch 1024.
    - *Config B (Ch 3):* Adam, batch 128, generalized cross-entropy ($\alpha=0.7$).
    - *Config C (Ch 5):* Adam, batch 256.
    - **Assumption:** Use the standard train/test split for image datasets, minus the validation set.

### Unknowns that block faithful reproduction
- **Unknown:** **Random Seeds.** The text states results are "mean±standard deviation over three runs with different random seeds" but does not list the specific seed values used.
- **Unknown:** **Validation Strategy Details.** While a 60/20/20 split is mentioned for regression, the specific strategy for image datasets (e.g., random subset vs. stratified subset) is not explicitly detailed.
- **Unknown:** **Exact Cost Tuning Logic.** Costs ($c$, $\beta$) are chosen based on the observation that "a cost value that is not too far from the misclassification error... encourages a reasonable amount of input instances," implying a manual tuning process not fully codified.
- **Unknown:** **Source Code.** No link to a code repository is provided in the text.

### Common failure modes and diagnostics
- **Failure mode 1: Degenerate Deferral.** The model may learn to always defer or never defer.
    - **Diagnostic:** Check the "Rejection ratio" or "Deferral ratio". If it is 0% or 100%, the hyperparameters (specifically the cost $c$ or base cost $\beta$) likely need adjustment relative to the model's base error.
- **Failure mode 2: Performance Mismatch on Augmentation.** Results may deviate significantly if data augmentation is applied or omitted incorrectly between experiments (e.g., Chapter 3 requires *no* augmentation, while Chapter 2 uses standard augmentation).
    - **Diagnostic:** Verify the data loader pipeline matches the specific augmentation rules of the chapter being reproduced.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed multi-expert deferral and multi-class abstention frameworks be extended to online sequential settings or budgeted settings where the learner has only partial or bandit information about expert predictions?
- Basis in paper: [explicit] The Conclusion states an "avenue of exploration is extending multi-expert deferral and multi-class abstention to the online setting... as well as to the budgeted setting, where the learner has access to only partial or bandit information about the experts’ predictions."
- Why unresolved: The theoretical analysis and surrogate losses presented in the thesis focus on standard supervised learning (batch) settings with full information, leaving the dynamics of sequential decision-making and information constraints unaddressed.
- What evidence would resolve it: Derivation of new regret bounds and algorithms tailored for online convex optimization or bandit feedback within the deferral context.

### Open Question 2
- Question: How can one optimally select a diverse and accurate set of experts prior to training the deferral system?
- Basis in paper: [explicit] In Section 5.5, the author notes, "Optimally selecting diverse and accurate experts is an interesting research question," highlighting that the current analysis assumes experts are predefined.
- Why unresolved: The thesis provides algorithms for learning *when* to defer to existing experts but does not address the upstream problem of choosing the optimal pool of experts (e.g., model sizes or human specializations) to maximize system performance.
- What evidence would resolve it: A theoretical framework or empirical study that correlates expert diversity metrics with the H-consistency bounds or generalization errors derived in the thesis.

### Open Question 3
- Question: Does integrating abstention or deferral mechanisms specifically enhance adversarial robustness?
- Basis in paper: [explicit] The Conclusion lists "enhancing adversarial robustness through abstention or deferral" as an interdisciplinary avenue, noting that perturbed instances could be abstained from or deferred to multiple models.
- Why unresolved: While the thesis establishes H-consistency bounds for clean data, it does not analyze the robustness properties of the proposed surrogate losses against adversarial attacks or distribution shifts.
- What evidence would resolve it: A consistency analysis of the proposed surrogate losses under adversarial perturbations, or empirical results showing improved robustness accuracy on standard benchmarks compared to standard adversarial training.

## Limitations
- The theory assumes access to perfect expert models and known (or estimable) cost functions, which may not hold in practice.
- The bounds depend on the specific hypothesis class H and its properties (symmetry, completeness, scaling closure), which may be difficult to verify for complex models like deep neural networks.
- The practical performance of these surrogate losses, while demonstrated in experiments, is not rigorously analyzed. The gap between the theoretical bounds and empirical performance is not quantified.

## Confidence
- **High:** The theoretical framework of H-consistency and the proofs of the surrogate loss bounds are the core contributions. These are well-articulated and follow established patterns in statistical learning theory.
- **Medium:** The experimental setup and results, while showing the viability of the proposed methods, are not as extensively detailed as the theory. The choice of hyperparameters (especially costs) is described but not fully algorithmized.
- **Low:** The extension to regression with deferral is a novel contribution, and while the theory is presented, there is less empirical validation compared to the classification tasks.

## Next Checks
1. **Reproduce a Simple Experiment:** Implement and train the two-stage abstention surrogate on a small dataset (e.g., a subset of CIFAR-10) to verify the experimental pipeline and check if the rejection ratio can be controlled by the cost parameter.
2. **Analyze the H-Consistency Bound:** For a simple hypothesis class (e.g., linear models on a low-dimensional dataset), empirically verify the relationship between the excess surrogate loss and the excess target loss as predicted by the H-consistency bound.
3. **Test Expert Robustness:** Simulate a scenario where expert accuracies are not perfectly known by adding noise to the cost estimates. Evaluate the performance degradation of the multi-expert deferral system to understand its sensitivity to cost estimation errors.