---
ver: rpa2
title: 'Creating Artificial Students that Never Existed: Leveraging Large Language
  Models and CTGANs for Synthetic Data Generation'
arxiv_id: '2501.01793'
source_url: https://arxiv.org/abs/2501.01793
tags:
- data
- synthetic
- learning
- dataset
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of data scarcity and privacy
  concerns in learning analytics by leveraging AI technologies, specifically GANs
  and Large Language Models (LLMs), to generate synthetic student data. Using CTGAN
  and three LLMs (GPT2, DistilGPT2, and DialoGPT), the research evaluates the quality
  and utility of synthetic data for educational data science.
---

# Creating Artificial Students that Never Existed: Leveraging Large Language Models and CTGANs for Synthetic Data Generation

## Quick Facts
- arXiv ID: 2501.01793
- Source URL: https://arxiv.org/abs/2501.01793
- Reference count: 40
- Primary result: LLMs (GPT2, DistilGPT2, DialoGPT) generate synthetic student data with utility comparable to CTGAN, with DialoGPT showing best overall performance across evaluation metrics

## Executive Summary
This study addresses data scarcity and privacy concerns in learning analytics by leveraging generative adversarial networks (GANs) and large language models (LLMs) to produce synthetic student datasets. Using CTGAN as a baseline and three autoregressive LLMs (GPT2, DistilGPT2, and DialoGPT) via a text-based framework called GReaT, the research evaluates synthetic data quality through a comprehensive metric suite including Wasserstein Distance, Jensen-Shannon Divergence, and a novel Synthetic Data Integrity Score (SDIS). The findings demonstrate that LLMs can generate statistically similar and predictively useful synthetic data, with DialoGPT achieving the strongest performance across all datasets. The study introduces a practical framework for synthetic data generation that balances realism, utility, and privacy considerations in educational contexts.

## Method Summary
The research employs two parallel generation approaches: CTGAN for tabular data and LLMs (GPT2, DistilGPT2, DialoGPT) using the GReaT framework that converts tabular rows to text sequences for autoregressive modeling. Five educational datasets ranging from 395 to 9,778 records were preprocessed with consistent handling of missing values, categorical encoding, and normalization. CTGAN was configured with default parameters (2,000 iterations, batch 200, learning rate 0.001), while LLMs were fine-tuned with dataset-specific epochs (100 for smallest, 20-30 for larger datasets). Synthetic data matching original dimensions was generated and evaluated using the Synthcity library, measuring utility resemblance (WD, JSD, Chi-squared), utility performance (Quality, Detection, OOD AUCROC), and downstream ML classification accuracy using Random Forest, KNN, XGBoost, and Decision Tree classifiers.

## Key Results
- DialoGPT achieved the highest Detection scores (0.5413 on Dataset D) and strong OOD AUCROC (0.6002 on B1) among LLMs
- CTGAN outperformed on Quality scores for datasets B1 (0.6405), B2 (0.656), and C (0.6451)
- All models achieved SDIS scores around 0.5 on datasets A, B1, B2, and C, with degraded performance on dataset D
- Synthetic data preserved statistical distributions and enabled ML classifiers to achieve comparable accuracy to real-data-trained models

## Why This Works (Mechanism)

### Mechanism 1
LLMs generate synthetic tabular student data with statistical and predictive utility comparable to CTGAN when using text-based representation learning. The GReaT framework converts each row of tabular data into a text sequence (e.g., "Column A is 5. Column B is high..."), which fine-tunes an autoregressive LLM. The LLM then samples new token sequences that are parsed back into tabular format, preserving column relationships through learned sequential dependencies. Core assumption: Tabular data distributions and inter-column relationships can be captured via sequential text patterns without explicit probabilistic modeling. Evidence anchors: DialoGPT showing best Detection scores (0.5413 on Dataset D) and strong OOD AUCROC (0.6002 on B1). Break condition: High-cardinality categorical columns or complex multi-table relationships may exceed LLM context windows.

### Mechanism 2
CTGAN captures joint distributions of mixed categorical and continuous features through adversarial training with mode-specific normalization. CTGAN uses a conditional generator with training-by-sampling to handle imbalanced categorical variables, applying mode-specific normalization for continuous columns. The discriminator learns to distinguish real from synthetic, forcing the generator to approximate the true joint distribution. Core assumption: The adversarial equilibrium can be reached before mode collapse, and 2,000 training iterations suffice for convergence. Evidence anchors: CTGAN achieved highest Quality scores on datasets B1 (0.6405), B2 (0.656), and C (0.6451). Break condition: Many rare categories or extreme outliers in continuous variables may cause underfitting or implausible values.

### Mechanism 3
The Synthetic Data Integrity Score (SDIS) provides a unified metric capturing realism, indistinguishability, and downstream utility. SDIS aggregates three dimensions: Quality (weighted average of α-precision, β-recall, authenticity), OOD AUCROC (generalization to held-out real data), and inverse Detection (harder to distinguish = better). Formula: SDIS = Quality + OOD AUCROC + (1 - Detection). Core assumption: Linear combination equally weights these three concerns, which may not reflect all use case priorities. Evidence anchors: All models achieve SDIS ~0.5 on datasets A, B1, B2, C; Dataset D shows degraded performance across all models. Break condition: If downstream tasks prioritize privacy over utility, or if Detection scores approach 0.5 by chance, SDIS may give false confidence.

## Foundational Learning

- **Concept**: Generative Adversarial Networks (GAN) fundamentals
  - Why needed: CTGAN's adversarial training underpins the baseline synthetic generation; understanding generator-discriminator dynamics helps diagnose mode collapse or training instability
  - Quick check: Can you explain why a GAN might produce synthetic data that matches marginal distributions but fails to capture inter-column correlations?

- **Concept**: Autoregressive language modeling and fine-tuning
  - Why needed: GPT2, DistilGPT2, and DialoGPT are autoregressive models; understanding how fine-tuning adapts pre-trained weights to domain-specific text representations is essential for LLM-based tabular generation
  - Quick check: What is the trade-off between fine-tuning epochs and overfitting when adapting an LLM to a small tabular dataset?

- **Concept**: Statistical distance measures (Wasserstein Distance, Jensen-Shannon Divergence)
  - Why needed: WD and JSD quantify how closely synthetic distributions match real data; interpreting these metrics requires understanding their sensitivity to distributional shifts
  - Quick check: Why might two datasets have low JSD but high WD, and what does this imply about synthetic data quality?

## Architecture Onboarding

- **Component map**: Preprocessed tabular datasets -> CTGAN/LLM generation -> Synthcity evaluation -> ML classifier training and testing

- **Critical path**: 1) Preprocess datasets consistently (imputation, encoding, scaling), 2) Generate synthetic data matching real dataset dimensions, 3) Run full evaluation suite (minimum 2 repetitions per paper), 4) Compare ML classifiers trained on synthetic vs. real data

- **Design tradeoffs**: CTGAN offers faster training with less hyperparameter tuning but may struggle with high-cardinality categoricals; LLMs provide more flexibility and potentially better at capturing complex dependencies but require more compute and careful fine-tuning; DistilGPT2 showed degraded performance likely due to fewer parameters

- **Failure signatures**: Low Chi-squared p-values (<0.05) indicate categorical distributions diverge significantly; High Detection scores (>0.7) suggest synthetic data easily distinguished (overfitting or underfitting); Negative OOD AUCROC values reflect distribution mismatch or data leakage; DistilGPT2 consistently underperforming indicates insufficient model capacity

- **First 3 experiments**: 1) Replicate CTGAN baseline on Dataset B1 with default parameters; verify SDIS ≈ 0.5 and WD < 0.1 as sanity check, 2) Fine-tune GPT2 on Dataset A with 100 epochs, batch size 32; compare JSD and Detection scores against CTGAN, 3) Train XGBoost classifier on synthetic data from DialoGPT (Dataset C), evaluate on held-out real data; target AUCROC within 5% of real-data-trained baseline

## Open Questions the Paper Calls Out

- **Open Question 1**: Can synthetic data generation mitigate biases in demographic records to improve fairness in predictive modeling?
  - Basis: The authors explicitly state in the "Future Direction" section that future work is required to explore methods addressing fairness issues for demographic records using synthetic data generation
  - Why unresolved: The current study focused on utility, resemblance, and prediction accuracy (SDIS) but did not implement or evaluate fairness constraints or bias mitigation techniques
  - Evidence would resolve it: Experiments comparing bias metrics (e.g., demographic parity) of models trained on synthetic data generated with fairness constraints versus those trained on real, potentially biased data

- **Open Question 2**: Can zero-shot or few-shot learning methods reduce the computational demands of fine-tuning LLMs for synthetic tabular data generation?
  - Basis: Section 6 suggests future studies could focus on improving LLM efficiency by investigating zero-shot and few-shot learning to reduce computational demands
  - Why unresolved: The methodology relied on fine-tuning LLMs using the GReaT framework, which the authors note is resource-intensive and a limitation (Section 5.1)
  - Evidence would resolve it: A comparative benchmark of synthetic data quality (using SDIS) generated via fine-tuning versus zero-shot/few-shot prompting, measuring both performance and computational resource usage

- **Open Question 3**: To what extent do LLMs and CTGANs preserve privacy in synthetic student data, given that the study excluded privacy-specific evaluations?
  - Basis: While the paper mentions privacy as a motivation for synthetic data generation, it does not conduct formal privacy attacks or differential privacy analyses
  - Why unresolved: The evaluation focused on utility and resemblance metrics without assessing whether synthetic data could be reverse-engineered to reveal individual student information
  - Evidence would resolve it: Privacy attack experiments (membership inference, attribute inference) comparing synthetic data from different models against real data to quantify information leakage

## Limitations

- Limited sample size and domain specificity: Five educational datasets with small sample sizes (395 to 9,778 records) raise questions about generalizability to larger-scale institutional data
- GReaT framework specificity: Text serialization of tabular data introduces ambiguity about whether observed performance gains stem from LLM capabilities or artifacts of the representation method
- Evaluation metric interpretation: Linear combination in SDIS assumes equal weighting across statistical similarity, generalization, and indistinguishability, which may not reflect all use case priorities

## Confidence

- **High confidence**: CTGAN performance relative to LLMs (strong statistical and predictive utility demonstrated across datasets), SDIS metric formulation (mathematically sound aggregation), ML classifier evaluation protocol (standard and reproducible)
- **Medium confidence**: LLM performance ranking (DialoGPT > GPT2 > DistilGPT2) - while results are clear, the mechanism explaining why larger models perform better is not fully explored
- **Low confidence**: GReaT framework's text-based representation learning - the paper does not validate that sequential text modeling captures tabular dependencies more effectively than alternative approaches

## Next Checks

1. **Representation ablation study**: Generate synthetic data using GReaT framework but compare text serialization against direct tabular modeling (e.g., using MLPs or transformer encoders on tabular features) to isolate whether performance gains stem from autoregressive modeling or larger model capacity

2. **Cross-institutional validation**: Apply the best-performing model (DialoGPT) to generate synthetic data from a dataset from a different institution or educational context to evaluate whether SDIS scores correlate with performance degradation and identify sensitive evaluation components

3. **Privacy-utility tradeoff analysis**: Systematically vary synthetic data generation parameters (e.g., CTGAN noise levels, LLM temperature) to map the relationship between Detection scores and downstream utility, revealing whether higher indistinguishability always correlates with better utility across different use cases