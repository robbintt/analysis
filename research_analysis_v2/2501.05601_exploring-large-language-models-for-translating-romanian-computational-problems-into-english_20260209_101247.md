---
ver: rpa2
title: Exploring Large Language Models for Translating Romanian Computational Problems
  into English
arxiv_id: '2501.05601'
source_url: https://arxiv.org/abs/2501.05601
tags:
- translation
- llms
- romanian
- language
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that large language models (LLMs) can effectively
  translate complex Romanian computational problems into English with quality comparable
  to human translators when provided with well-crafted prompts and human oversight.
  Using GPT-4o and Llama models, the research achieved translation accuracy where
  22 out of 38 problems showed equal or better scores compared to original Romanian
  versions.
---

# Exploring Large Language Models for Translating Romanian Computational Problems into English

## Quick Facts
- arXiv ID: 2501.05601
- Source URL: https://arxiv.org/abs/2501.05601
- Reference count: 4
- This study demonstrates that LLMs can effectively translate complex Romanian computational problems into English with quality comparable to human translators when provided with well-crafted prompts and human oversight.

## Executive Summary
This study evaluates the effectiveness of large language models in translating Romanian competitive programming problems into English, comparing translation quality against human expert translations. Using GPT-4o and Llama models, the research achieved translation accuracy where 22 out of 38 problems showed equal or better scores compared to original Romanian versions. The study identified key translation challenges including technical terminology errors and structural inconsistencies, particularly in smaller models. A refined prompt addressing competitive programming terminology significantly improved translation quality. The enhanced OJI dataset with verified English translations provides valuable resources for future multilingual LLM research. While larger models like GPT-4o performed consistently well, the results indicate that human oversight remains necessary despite LLM advancements.

## Method Summary
The study translated 44 Romanian competitive programming problems from the OJI dataset using GPT-4o, Llama 3.1 8B, Llama 3.2 3B, and Aya 35B models at temperatures 0.2, 0.6, and 1.0. A simple prompt preserved structure and excluded I/O examples, while a refined prompt included domain terminology mappings (șubsecvență→subarray, șir→subsequence, vector→array, șir de caractere→string). Translation quality was evaluated by GPT-4o solving translated problems (5 runs per problem, temperature 0.4), with success defined as achieving scores equal to or better than the baseline Romanian version. Additional evaluation by linguists assessed lexical, semantic, and structural errors.

## Key Results
- GPT-4o and Llama 3.1 8B achieved the highest translation quality, with 22 out of 38 problems scoring equal or better than Romanian originals
- Temperature 0.6 showed optimal results for larger models, while smaller models performed better at temperature 0.2
- The refined prompt with domain-specific terminology mappings significantly reduced technical translation errors
- Human oversight remains necessary despite LLM advancements, particularly for smaller models and complex problem structures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Domain-specific prompt engineering with explicit terminology mapping reduces translation errors in competitive programming problems.
- Mechanism: The refined prompt provides explicit mappings for ambiguous Romanian technical terms (e.g., "subsecvență" → "subarray", "subșir" → "subsequence", "șir de caractere" → "string") that LLMs otherwise mistranslate due to polysemy in general vs. technical contexts.
- Core assumption: LLMs have sufficient baseline knowledge of competitive programming concepts but lack context-specific disambiguation without explicit guidance.
- Evidence anchors: [Section 5] "Key terms such as 'Cerintă' (task), 'subsecvență' (subarray), 'subșir' (subsequence)... were carefully handled to ensure accuracy." [Section 4] "The most accurate translation in this context would be 'array'... The use of 'sequence', while closer, still lacks the specificity required."

### Mechanism 2
- Claim: Larger model scale correlates with translation completeness and structural preservation in long, complex problem statements.
- Mechanism: Models with more parameters maintain attention over longer sequences, reducing omissions of examples, constraints, and table content that smaller models frequently drop.
- Core assumption: Translation quality in this domain is partly a function of context window utilization and instruction-following capability, both of which scale with model size.
- Evidence anchors: [Section 3.3] "Smaller models often struggled to complete translations, especially for longer, more complex tasks. Many of the tasks that received a score of 0 points after translation were incomplete."

### Mechanism 3
- Claim: Temperature setting of ~0.6 provides optimal balance between translation consistency and appropriate lexical variation across model runs.
- Mechanism: Moderate temperature allows models to make sensible contextual choices (e.g., "contain" vs. "print" for input/output descriptions) without introducing excessive randomness that degrades technical accuracy.
- Core assumption: Translation of structured technical content benefits from constrained but non-deterministic output; too low temperature may cause repetitive phrasing, too high causes drift.
- Evidence anchors: [Section 3.2, Table 1] Temperature 0.6 showed best average results across Llama 3.1 8B, Aya 35B, and other models; temperature 1.0 consistently underperformed.

## Foundational Learning

- Concept: **Competitive programming terminology distinctions** (subsequence vs. substring vs. subarray)
  - Why needed here: A single mistranslated term (e.g., "subsequence" rendered as "substring") can change the algorithmic problem entirely, causing solvers to implement incorrect solutions.
  - Quick check question: Given a Romanian problem using "subșir de caractere," should this translate to "subsequence," "substring," or "subarray"—and why does the distinction matter?

- Concept: **MQM (Multidimensional Quality Metrics) error taxonomy**
  - Why needed here: The paper classifies translation errors into fluency vs. accuracy, minor vs. critical—understanding this framework is necessary to systematically diagnose and prioritize translation issues.
  - Quick check question: If a translation preserves meaning but uses awkward phrasing ("rectiliniu" → "straight" instead of "linear"), is this a fluency error or an accuracy error?

- Concept: **Temperature as a creativity-stability parameter in LLMs**
  - Why needed here: The study explicitly varies temperature to control translation quality; engineers must understand this parameter to reproduce or extend results.
  - Quick check question: Why might temperature 0.2 work better for a 3B model while temperature 0.6 works better for an 8B+ model?

## Architecture Onboarding

- Component map: [Romanian Problem Statement (Markdown)] → [Prompt Engineering Layer] → [Translation LLM] → [English Translation] → [Evaluation Layer] → [Human Review]

- Critical path: 1. Extract Romanian problem from OJI dataset (Markdown with LaTeX) 2. Apply refined prompt with domain-specific terminology rules 3. Run translation at temperature 0.6 (0.2 for small models) 4. Verify via automated solver (GPT-4o, 5 runs, compare to Ro_score) 5. Flag discrepancies for human review

- Design tradeoffs:
  - **Model size vs. cost**: GPT-4o (100B+) achieves highest accuracy but at API cost; Llama 3.1 8B provides competitive quality at lower inference cost for local deployment
  - **Temperature vs. consistency**: Lower temperature reduces variance but may miss contextually appropriate phrasing variations
  - **Automation vs. oversight**: Full automation risks undetected terminology errors; human review adds latency but catches critical mistranslations

- Failure signatures:
  - **Incomplete translation**: Problem ends mid-sentence or omits constraints/examples (common in smaller models on long problems)
  - **Terminology drift**: "șir" inconsistently rendered as "sequence," "string," or "array" within same problem
  - **Structural collapse**: Tables missing columns, markdown formatting broken, LaTeX not preserved
  - **False friend errors**: "curent" translated as "current" (adjective) instead of "stream/flow" (noun) in context

- First 3 experiments:
  1. **Baseline replication**: Translate 10 OJI problems using the simple prompt at temperature 0.6 with Llama 3.1 8B; measure translation completeness and terminology accuracy against human reference
  2. **Prompt ablation**: Compare simple prompt vs. refined prompt on same 10 problems; quantify reduction in terminology errors and structural issues
  3. **Temperature sweep**: For Llama 3.1 8B, run translations at temperatures [0.2, 0.4, 0.6, 0.8, 1.0]; plot score variance and identify optimal setting for this specific task class

## Open Questions the Paper Calls Out

- **Open Question 1**: Can the translation methodologies and prompt strategies optimized for Romanian be effectively generalized to other low-resource languages in competitive programming?
  - Basis in paper: The conclusion states that while the study focused on Romanian to English, "our findings open doors for exploration in other language pairs."
  - Why unresolved: The study only validated the approach for the Romanian-English pair; linguistic structures and the density of training data for LLMs vary significantly across different low-resource languages.
  - What evidence would resolve it: Applying the same refined prompt methodology to datasets from other language-specific Olympiads (e.g., Balkan or Slavic languages) and comparing the solvability scores against the original texts.

- **Open Question 2**: To what extent does using the same model architecture (GPT-4o) as both the translator and the evaluator inflate performance metrics?
  - Basis in paper: Section 3.3 notes that GPT-4o's performance "may be influenced by the fact that it was both the translation model and the judge, potentially giving it an advantage by aligning the translation with the evaluation model's own language patterns."
  - Why unresolved: The study relied on GPT-4o to generate code solutions to score the translations, creating a potential conflict of interest where the model "understands" its own translations better than an independent solver would.
  - What evidence would resolve it: A follow-up experiment where translations generated by GPT-4o are evaluated/solved by a different state-of-the-art model or human experts to see if the "equal or better scores" hold true.

- **Open Question 3**: Does domain-specific fine-tuning yield superior translation accuracy compared to the optimized prompt engineering approaches used in this study?
  - Basis in paper: Section 3.1.1 suggests that "further progress in enhancing translation accuracy may depend on fine-tuning models for specific tasks or further improving prompt design."
  - Why unresolved: The study evaluated off-the-shelf models with prompt engineering but did not train or fine-tune models on the newly created dataset, leaving the potential performance gains from specialization unknown.
  - What evidence would resolve it: Fine-tuning an open-weight model (like Llama 3.1 8B) on the enhanced OJI dataset and comparing its translation quality and technical accuracy against the prompted baselines.

## Limitations

- Evaluation relies heavily on GPT-4o as both translator and judge, creating potential circularity in quality assessment
- Only 38 problems were used for the main comparison, limiting statistical power for model performance differences
- The study focuses exclusively on Romanian→English translation; results may not generalize to other language pairs
- Technical terminology coverage is limited to explicitly mapped terms in the refined prompt; novel terms would require prompt updates

## Confidence

- **High confidence**: The core finding that larger models (GPT-4o, Llama 3.1 8B) consistently outperform smaller models in translation completeness and technical accuracy
- **Medium confidence**: The temperature optimization findings (0.6 optimal for larger models, 0.2 for smaller models) are based on a limited parameter sweep
- **Low confidence**: The claim that human oversight is "necessary" is based on qualitative assessment rather than quantitative measurement

## Next Checks

1. **Cross-validation with alternative evaluation methods**: Test the same translated problems using human expert scoring rather than GPT-4o solver scoring to verify that automated evaluation correlates with human judgment on translation quality.

2. **Broader problem coverage test**: Apply the translation pipeline to a diverse set of problem types (algorithms, data structures, geometry) beyond the 8th-grade competition problems to assess generalizability to different computational domains.

3. **Terminological drift analysis**: Conduct systematic error analysis on all translated problems to quantify frequency of key terminology mistranslations (șir, subșir, subsecvență, vector) and measure improvement rate when expanding the terminology mapping in the refined prompt.