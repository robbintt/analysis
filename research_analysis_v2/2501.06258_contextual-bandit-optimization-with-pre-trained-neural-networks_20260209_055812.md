---
ver: rpa2
title: Contextual Bandit Optimization with Pre-Trained Neural Networks
arxiv_id: '2501.06258'
source_url: https://arxiv.org/abs/2501.06258
tags:
- bound
- theorem
- weights
- page
- will
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis investigates how pre-training can help in contextual
  bandit optimization with smaller neural networks. We consider a stochastic contextual
  bandit with rewards modeled by a multi-layer neural network, where pre-training
  is modeled as an initial guess of the representation network weights.
---

# Contextual Bandit Optimization with Pre-Trained Neural Networks

## Quick Facts
- arXiv ID: 2501.06258
- Source URL: https://arxiv.org/abs/2501.06258
- Reference count: 0
- Pre-training neural networks for contextual bandits reduces sample complexity

## Executive Summary
This thesis investigates how pre-training can help in contextual bandit optimization with smaller neural networks. It introduces Explore Twice then Commit (E2TC), an algorithm that first estimates the last layer weights using Ridge regression, then refines all weights with Stochastic Gradient Descent. For locally convex loss functions, E2TC achieves sublinear regret when the last layer dimension and number of actions are much smaller than the horizon. Experiments on MNIST classification and wine quality prediction validate the theoretical findings and demonstrate practical benefits of pre-training.

## Method Summary
The method involves pre-training a representation network on a source task, then transferring it to a contextual bandit setting. E2TC operates in two exploration phases: first using Ridge regression to estimate the last layer weights, then using preconditioned SGD to refine all weights. The algorithm commits to a greedy policy after exploration. Pre-training includes orthogonality regularization and autoencoder reconstruction. The approach is evaluated on MNIST (digits 0-4 for pre-training, 5-9 for evaluation) and wine quality prediction (white wine pre-training, red wine evaluation).

## Key Results
- E2TC achieves sublinear regret under local convexity assumptions
- Misspecified linear bandit phase has regret bounds O(ε₀√dKT+(KT)⁴/⁵) or Õ(ε₀√dKT+d¹/³(KT)²/³)
- Pre-training provides practical benefits demonstrated on MNIST and wine quality prediction tasks

## Why This Works (Mechanism)

### Mechanism 1: Initialization Within the Convex Basin
Pre-trained weights θ₀ that are sufficiently close to optimal weights θ* allow the combined initialization to fall within a locally convex region around the global minimum. This bypasses the need for extremely wide networks required by NTK regime. The risk function R(w,θ) must be locally convex around the minimizer (w*,θ*), and pre-trained weights must satisfy quality conditions.

### Mechanism 2: Decoupled Linear-Nonlinear Estimation
Estimating the last layer w₀ independently using Ridge regression before fine-tuning the entire network reduces sample complexity. The linear last layer allows for efficient estimation via closed-form Ridge regression even with misspecified features, providing a stable anchor for subsequent non-linear fine-tuning.

### Mechanism 3: Geometry-Aware Preconditioned SGD
Preconditioning SGD updates for the last layer using the inverse regularized covariance matrix aligns the optimization path with the data distribution's geometry. This effectively normalizes the learning rate across different feature directions based on their prevalence in the data.

## Foundational Learning

- **Stochastic Contextual Bandits**: Sequential decision making where an agent chooses actions based on context to maximize cumulative reward. Why needed: This is the core problem formulation requiring understanding of the exploration-exploitation trade-off.
- **Regret and Sublinearity**: Measures performance difference between algorithm and optimal policy. Why needed: The primary contribution is proving "sublinear regret" which means average regret per time step vanishes as T→∞.
- **Explore-Then-Commit (ETC)**: Framework that separates timeline into exploration phases and commitment phase. Why needed: E2TC is a variant of ETC that uses two exploration phases before committing to greedy exploitation.

## Architecture Onboarding

- **Component map**: Input X_t -> Representation Network φ_θ -> Linear Head w -> Reward Estimator r_t ≈ w^T φ_θ(X_t) -> Optimizer
- **Critical path**: Stage 1 (Ridge): Collect T₁ samples, compute empirical covariance, solve for w₀. Stage 2 (SGD): Update (w,θ) using Preconditioned SGD for T₂ steps. Commit: Fix weights, greedily select actions.
- **Design tradeoffs**: T₁ vs T₂ balance affects sample efficiency; regularization λ affects stability vs bias; pre-training quality ε₀ affects convergence rate and learning rate constraints.
- **Failure signatures**: Linear regret indicates poor pre-training or non-convex landscape; exploding gradients suggest learning rate too high; NaN in w₀ indicates singular covariance matrix.
- **First 3 experiments**: 1) Ablation on pre-training quality comparing random vs pre-trained θ₀. 2) Hyperparameter sensitivity sweeping T₁/T₂ ratios. 3) Preconditioning ablation comparing standard vs preconditioned SGD.

## Open Questions the Paper Calls Out

- Can an optimistic algorithm utilizing pre-trained weights achieve Õ(√T) regret? The paper suggests replacing explore-then-commit with confidence bounds could reach optimal regret rate.
- Can the local convexity assumption be relaxed to the Polyak-Łojasiewicz (PL) condition? The paper proposes extending the high-probability SGD basin result to cover PL functions.
- Is logarithmic regret achievable for stochastic neural bandits? The paper notes logarithmic regret is achievable for linear bandits and asks if this extends to neural networks.

## Limitations
- Relies on local convexity assumption around pre-trained initialization which may not hold for all network architectures
- Performance depends heavily on quality of pre-training task transfer which is untested beyond two datasets
- Covariance estimation quality becomes problematic in high-dimensional settings with limited samples

## Confidence
- **High**: Algorithmic framework and experimental methodology are clearly specified and reproducible
- **Medium**: Theoretical regret bounds are mathematically sound given assumptions; experimental results support core claims
- **Low-Medium**: Practical benefits of preconditioning lack strong theoretical grounding in bandit literature

## Next Checks
1. Test convex basin robustness by varying pre-training task similarity and measuring convergence across different transfer scenarios
2. Analyze covariance matrix quality by investigating rank and condition number effects on Ridge regression and preconditioned SGD stability
3. Validate transfer learning spectrum by testing E2TC on broader range of pre-training/transfer pairs, especially where representation dimension is comparable to or larger than horizon T