---
ver: rpa2
title: Knowledge Homophily in Large Language Models
arxiv_id: '2509.23773'
source_url: https://arxiv.org/abs/2509.23773
tags:
- knowledge
- knowledgeability
- homophily
- entities
- triplets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work reveals knowledge homophily in LLMs: topologically close
  entities tend to have similar knowledgeability scores. To measure this, we prompt
  LLMs to assess triplet-level knowledgeability and aggregate scores to the entity
  level.'
---

# Knowledge Homophily in Large Language Models

## Quick Facts
- arXiv ID: 2509.23773
- Source URL: https://arxiv.org/abs/2509.23773
- Reference count: 40
- Key outcome: Knowledge homophily exists in LLMs—topologically close entities have similar knowledgeability scores, enabling GNN-based prediction and improved fine-tuning and retrieval.

## Executive Summary
This work reveals knowledge homophily in LLMs: topologically close entities tend to have similar knowledgeability scores. To measure this, we prompt LLMs to assess triplet-level knowledgeability and aggregate scores to the entity level. Our quantitative analysis across five datasets shows strong homophily, outperforming degree-matched random baselines (p < 0.01). Leveraging this property, we train a GNN regressor to predict entity knowledgeability, which we apply to two tasks: fine-tuning LLMs on less-known triplets (achieving up to 91.9% unknown triplet selection quality) and guiding multi-hop retrieval (up to 34.2% accuracy improvement). This demonstrates how structural knowledge patterns can enhance LLM training and retrieval efficiency.

## Method Summary
The method probes LLMs for knowledgeability by prompting them with True/False statements for each triplet in a knowledge graph. Triplet-level scores are aggregated to entity-level knowledgeability scores, and homophily is computed by measuring the average similarity between neighboring entities. A GNN regressor is then trained on a subset of labeled entities to predict knowledgeability for the remaining entities. These predictions are used to select less-known triplets for fine-tuning and to guide multi-hop retrieval by penalizing paths through well-known entities.

## Key Results
- Knowledge homophily is strong across five KGs, peaking near 0.8 and significantly outperforming degree-matched random baselines (p < 0.01).
- GNN regressor achieves up to 91.9% unknown triplet selection quality for fine-tuning.
- Knowledge-aware beam search improves multi-hop retrieval accuracy by up to 34.2%.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Entities positioned closer in knowledge graph topology exhibit similar knowledgeability scores in LLMs (knowledge homophily).
- Mechanism: Knowledgeability is computed by prompting LLMs on triplet facts, aggregating to entity-level scores, then measuring similarity between neighboring entities. High homophily (peaking near 0.8) emerges because LLMs' parametric knowledge is structurally organized in correlated clusters.
- Core assumption: LLMs are sufficiently calibrated in recognizing what they know vs. don't know (via True/False prompting); triplet-level scores meaningfully aggregate to entity-level summaries.
- Evidence anchors:
  - [abstract]: "topologically close entities tend to have similar knowledgeability scores... strong homophily, outperforming degree-matched random baselines (p < 0.01)"
  - [section 3.2.1]: "node homophily distributions are right-skewed and peak near 0.8... True-neighborhood homophily is significantly higher than the random baseline (two-tailed z-test, p < 0.01)"
  - [corpus]: Related work on graph-based knowledge probing (arXiv 2505.19286) corroborates structural patterns but does not directly validate homophily claims.
- Break condition: If LLM self-assessment is poorly calibrated (overconfident on unknowns), homophily measurements become unreliable. Sparse or disconnected KGs may not exhibit sufficient topological structure.

### Mechanism 2
- Claim: GNN regression can estimate entity knowledgeability from neighborhood signals, avoiding exhaustive LLM probing.
- Mechanism: A GNN performs message-passing over the KG, aggregating neighbor embeddings (initial features from pretrained language models) to predict knowledgeability scores for unlabeled entities. Homophily ensures neighbors provide predictive signal.
- Core assumption: Homophily is sufficient for GNN utility (neighbors' scores correlate with target); entity embeddings capture relevant semantic structure.
- Evidence anchors:
  - [abstract]: "train a GNN regressor to predict entity knowledgeability... up to 91.9% unknown triplet selection quality"
  - [section 4.1]: "homophily is a sufficient condition for high-utility GNN predictions"
  - [corpus]: No direct corpus validation of GNN regression for knowledgeability; corpus focuses on KG-QA integration rather than estimation.
- Break condition: If homophily degrades (heterophilic regions) or if labeled anchors are unrepresentative, GNN predictions become noisy. Temporal knowledge (MVPKG) shows slight homophily reduction—suggesting limits.

### Mechanism 3
- Claim: Predicted knowledgeability improves fine-tuning triplet selection and multi-hop retrieval by prioritizing less-known regions.
- Mechanism: For fine-tuning, low-predicted-knowledgeability entities identify triplets the LLM likely doesn't know, maximizing knowledge gain per labeling budget. For retrieval, beam search scores are penalized by entity knowledgeability (S × (1 − α·K(u))), favoring paths through less-known regions.
- Core assumption: Less-known triplets provide higher marginal information gain; penalizing known paths improves retrieval diversity/completeness.
- Evidence anchors:
  - [abstract]: "fine-tuning LLMs on less-known triplets (achieving up to 91.9% unknown triplet selection quality) and guiding multi-hop retrieval (up to 34.2% accuracy improvement)"
  - [section 4.2, Table 1]: GNN achieves highest selection quality and generalization gain vs. Random/MLP baselines.
  - [corpus]: BifrostRAG (arXiv 2507.13625) shows KG-structured retrieval aids multi-hop QA but does not validate knowledgeability-weighted scoring.
- Break condition: If knowledgeability predictions are systematically biased (e.g., over-predicting knowledge in specific domains), selection quality degrades. For retrieval, over-penalizing known paths may discard correct answers that happen to traverse well-known entities.

## Foundational Learning

- Concept: **Knowledge Graph fundamentals** (entities, relations, triplets, topology)
  - Why needed here: The entire method maps LLM knowledge onto KG structure; understanding neighborhood, degree, and connectivity is prerequisite.
  - Quick check question: Given a triplet (entity_A, relation_R, entity_B), how would you find entity_A's neighbor set N(entity_A)?

- Concept: **Graph Neural Networks and message-passing**
  - Why needed here: The GNN regressor aggregates neighbor features to predict knowledgeability; understanding MP/TR layers is essential for implementation.
  - Quick check question: In a 2-layer GNN, what information flows from a node's 2-hop neighbors to the node's final representation?

- Concept: **LLM knowledge probing / calibration**
  - Why needed here: Knowledgeability scores derive from LLM self-assessment; understanding prompt design and calibration assumptions helps diagnose failure modes.
  - Quick check question: If an LLM systematically responds "True" to unfamiliar facts, what happens to the homophily measurement?

## Architecture Onboarding

- Component map:
  1. **Triplet-level Probing**: Prompt LLM with True/False statements for each triplet; record binary knowledgeability.
  2. **Entity Aggregation**: Aggregate triplet scores to entity-level K(v) via neighborhood averaging.
  3. **Homophily Verification**: Compute H(v) = 1 − avg|K(v) − K(neighbors)|; compare to degree-matched random baseline.
  4. **GNN Regressor**: Train on labeled anchor entities (20% budget); predict knowledgeability for remaining entities.
  5. **Application Layer**: (a) Triplet selection for fine-tuning; (b) Knowledge-aware beam search for multi-hop QA.

- Critical path: Anchor entity selection → LLM probing → Entity score computation → GNN training → Prediction on unlabeled entities → Application-specific selection/retrieval.

- Design tradeoffs:
  - **Anchor budget vs. estimation accuracy**: More anchors improve GNN but reduce fine-tuning budget; paper uses 20%/80% split.
  - **Temporal vs. static probing**: Temporal prompts (MVPKG) capture temporal knowledge but slightly reduce homophily.
  - **GNN depth vs. over-smoothing**: Shallow GNNs preserve local signal; deep GNNs may blur homophily in heterogeneous regions.

- Failure signatures:
  - **Low homophily scores (< 0.5)**: Indicates KG structure doesn't align with knowledge organization; GNN estimation will fail.
  - **Selection quality < random**: GNN predictions anti-correlated with ground truth; check for data leakage or mislabeled anchors.
  - **Retrieval accuracy drops**: Over-penalization (high α) or poor entity linking; tune α and verify embedding quality.

- First 3 experiments:
  1. **Homophily baseline**: Compute H(v) on a small KG subset (e.g., CoDEx-S); verify p < 0.01 vs. degree-matched random. Confirms measurement pipeline.
  2. **GNN ablation**: Compare GNN vs. MLP vs. Random on held-out entities (varying anchor %: 10%, 20%, 40%). Establishes estimation ceiling.
  3. **End-to-end retrieval**: Implement knowledge-aware beam search on 100 2-hop questions; compare Base vs. M-BS vs. G-BS. Validates application gain.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does knowledge homophily evolve dynamically as LLMs acquire new information through fine-tuning or continued pre-training?
- Basis in paper: [explicit] The conclusion states: "In the future, we plan to explore uncertainty-aware knowledge verification and dynamic homophily modeling to capture how homophily evolves as LLMs acquire new information."
- Why unresolved: The current work treats homophily as a static property measured at a single point in time, without examining whether the pattern persists, strengthens, or weakens after knowledge injection.
- What evidence would resolve it: Longitudinal experiments tracking homophily scores before and after incremental fine-tuning episodes, measuring whether newly learned facts maintain neighborhood consistency with existing knowledge.

### Open Question 2
- Question: Can uncertainty-aware knowledge verification improve the detection of knowledge gaps compared to the current binary True/False assessment?
- Basis in paper: [explicit] The conclusion explicitly mentions plans to "explore uncertainty-aware knowledge verification" as future work.
- Why unresolved: The current method maps LLM responses to binary values (True=1, False=0), which may lose nuanced information about the model's confidence or partial knowledge.
- What evidence would resolve it: Comparative experiments using probabilistic or confidence-calibrated probing methods, evaluated on their ability to identify knowledge gaps for fine-tuning prioritization.

### Open Question 3
- Question: Are the observed knowledge homophily patterns robust across different knowledge probing methodologies, or are they sensitive to the specific prompting strategy used?
- Basis in paper: [inferred] Section A.2.4 states "the specific choice of probing method is not the focus of this work," and "our conclusions are based on the observed topological patterns induced by the chosen signal."
- Why unresolved: The paper relies on a single prompting template (Prompt 1) for triplet evaluation; alternative probing approaches (e.g., multiple-choice, cloze-style, or counterfactual prompts) could yield different knowledgeability signals.
- What evidence would resolve it: Replication of the homophily analysis using multiple diverse probing methods, with correlation analysis between the resulting homophily distributions.

### Open Question 4
- Question: How can defensive strategies effectively mitigate the knowledge-extraction attack risks amplified by knowledge homophily?
- Basis in paper: [explicit] The Ethics section notes that homophily "amplifies the risk of knowledge-extraction attacks" by enabling "adversaries to exploit this structure by crafting queries over cohorts of related entities," and lists potential defenses including "query pre-filtering and sanitization, rate-limiting cohort-based requests, prompt-level heuristics... and detector or red-teaming mechanisms."
- Why unresolved: While defensive strategies are proposed, their effectiveness against homophily-aware attacks remains untested.
- What evidence would resolve it: Red-team experiments simulating homophily-exploiting attacks against LLMs with and without the proposed defensive measures, quantifying information leakage reduction.

## Limitations
- GNN architecture details remain unspecified (layer count, hidden dimensions, specific MP/TR variants), creating reproducibility gaps.
- The reliance on prompt-based knowledgeability assessment introduces calibration risk—LLM overconfidence or domain-specific knowledge gaps could distort homophily measurements.
- Temporal knowledge (MVPKG) shows slightly reduced homophily, suggesting structural alignment isn't universal across all knowledge types.

## Confidence

- **High**: Existence of knowledge homophily (entity proximity correlates with similar knowledgeability) across multiple datasets; GNN regressor can predict entity knowledgeability from topological signals.
- **Medium**: GNN predictions improve fine-tuning triplet selection quality (91.9% unknown triplet selection) and retrieval accuracy (34.2% improvement); selection quality metrics and multi-hop QA evaluations appear sound but depend on the quality of knowledgeability estimates.
- **Low**: The universality of homophily across all knowledge domains and LLM types; whether observed improvements translate to real-world deployment where knowledge evolves and LLMs may have systematic blind spots.

## Next Checks

1. **GNN architecture ablation**: Implement and test multiple GNN variants (GCN, GAT, GraphSAGE) with varying depths and hidden dimensions on a small KG (CoDEx-S) to identify optimal configuration for knowledgeability prediction.

2. **Knowledgeability calibration audit**: Systematically evaluate LLM self-assessment calibration across different knowledge domains by comparing predicted vs. actual knowledgeability on held-out triplets, identifying systematic biases.

3. **Temporal knowledge extension**: Apply the methodology to a temporal KG subset (MVPKG) with explicit time dimension, testing whether homophily persists when knowledge changes over time and whether GNN predictions degrade.