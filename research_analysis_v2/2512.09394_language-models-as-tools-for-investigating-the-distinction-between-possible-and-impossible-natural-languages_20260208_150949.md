---
ver: rpa2
title: Language models as tools for investigating the distinction between possible
  and impossible natural languages
arxiv_id: '2512.09394'
source_url: https://arxiv.org/abs/2512.09394
tags:
- languages
- language
- impossible
- possible
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper argues that language models (LMs) can be used as investigative
  tools to distinguish possible from impossible natural languages, potentially revealing
  the inductive biases underlying human language learning. The authors propose a phased
  research program: (1) identify attested possible languages and clearly impossible
  languages, (2) train LMs on minimal pairs of possible and impossible languages,
  (3) study LM inductive biases to inform hypotheses about human cognition, and (4)
  iteratively refine LM architectures to improve discrimination between possible and
  impossible languages.'
---

# Language models as tools for investigating the distinction between possible and impossible natural languages

## Quick Facts
- arXiv ID: 2512.09394
- Source URL: https://arxiv.org/abs/2512.09394
- Reference count: 1
- The paper proposes using language models as investigative tools to distinguish possible from impossible natural languages, revealing inductive biases underlying human language learning.

## Executive Summary
This paper proposes a research framework using language models (LMs) to investigate the distinction between possible and impossible natural languages. The authors argue that LMs can serve as tools whose value is measured by the strength of linking hypotheses connecting their behavior to human cognition. The approach involves training LMs on minimal pairs of possible and impossible languages, then analyzing learning efficiency differences to infer inductive biases. The framework treats LMs not as models of human cognition per se, but as experimental instruments that can generate testable hypotheses about language learning constraints.

## Method Summary
The proposed method follows a phased research program: (1) identify attested possible languages and clearly impossible languages, (2) train LMs on minimal pairs of possible and impossible languages under controlled conditions, (3) study LM inductive biases through comparative learning efficiency metrics to inform hypotheses about human cognition, and (4) iteratively refine LM architectures to improve discrimination between possible and impossible languages. The approach requires explicit linking hypotheses that connect observed LM behavior to human cognitive constraints, drawing on precedents from neuroscience where similar frameworks have been successful.

## Key Results
- LMs have strong potential as investigative tools for probing the distinction between possible and impossible natural languages
- Prior work suggests LMs learn attested (possible) languages more efficiently than impossible ones, revealing relevant inductive biases
- Even general LM learning mechanisms can capture linguistic locality effects, offering insights into factors producing these effects
- Architectural modifications to LMs (e.g., memory capacity constraints) may strengthen alignment with human-like locality preferences

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LMs may learn attested (possible) languages more efficiently than impossible ones, revealing inductive biases relevant to human language acquisition.
- Mechanism: Train LMs on minimal pairs of possible/impossible languages; compare learning curves, sample efficiency, and generalization patterns. Alignment between LM preferences and human learnability would suggest shared inductive biases.
- Core assumption: LM learning efficiency differentials map meaningfully onto human language learnability constraints via testable linking hypotheses.
- Evidence anchors:
  - [abstract]: "LMs have strong potential as investigative tools for probing the distinction between possible and impossible natural languages and thus uncovering the inductive biases that support human language learning."
  - [section]: "Kallini et al. (2024) present evidence that such models learn English more efficiently than counterfactual impossible languages. Xu et al. (2025) and Yang et al. (2025) expand the empirical scope of these claims and arrive at similar conclusions."
  - [corpus]: Mixed evidence. Neighbor paper "Studies with impossible languages falsify LMs as models of human language" claims "LMs often learn attested and many impossible languages equally well." "Biasless Language Models Learn Unnaturally" similarly suggests LLMs fail to distinguish. Evidence is contested.
- Break condition: If LMs show no systematic learning advantage for possible over impossible languages across diverse language pairs, the linking hypothesis fails.

### Mechanism 2
- Claim: Architectural modifications to LMs (e.g., memory capacity constraints) can strengthen alignment with human-like locality preferences.
- Mechanism: Intentionally degrade or constrain LM components (reducing context window, limiting attention mechanisms) to induce information locality biases, then test whether constrained models better discriminate possible/impossible languages.
- Core assumption: Human memory limitations are causally connected to locality effects in natural language structure.
- Evidence anchors:
  - [section]: "many present-day LMs have mechanisms that give them what is, in effect, perfect memory over long sequences of words. By reducing the capacity of these mechanisms, we might encourage even more locality and thus better match human language."
  - [section]: "Implicit in this description is a hypothesis linking LM memory to human memory."
  - [corpus]: Weak direct evidence in corpus; no neighbor papers test memory-constrained architectures specifically for this purpose.
- Break condition: If locality-inducing modifications produce no improvement (or degradation) in possible/impossible discrimination, the memory-locality linking hypothesis is unsupported.

### Mechanism 3
- Claim: Iterative refinement cycles between LM experimentation and theory-building can progressively sharpen hypotheses about human linguistic inductive biases.
- Mechanism: Four-phase loop: (1) identify possible/impossible language pairs, (2) train LMs on minimal pairs, (3) extract inductive bias hypotheses via linking hypotheses, (4) design new architectures testing those hypotheses—then return to Phase 2.
- Core assumption: The linking hypothesis framework from neuroscience can transfer productively to computational linguistics.
- Evidence anchors:
  - [section]: "Precedents from neuroscience make us optimistic about this project (e.g., McIntosh et al. 2016)."
  - [section]: "Its value as a tool is measured by the power of those linking hypotheses."
  - [corpus]: No corpus papers explicitly test iterative refinement; evidence remains programmatic.
- Break condition: If successive architecture iterations fail to improve discrimination or yield uninterpretable linking hypotheses, the iterative framework stalls.

## Foundational Learning

- Concept: **Inductive biases**
  - Why needed here: The entire framework depends on understanding how learning systems' built-in preferences shape what they acquire from data. LMs and humans both have inductive biases, but they differ.
  - Quick check question: Can you explain why a neural network trained on the same data as a human might still learn different generalizations?

- Concept: **Possible vs. impossible languages**
  - Why needed here: The research program requires clearly defining what makes a language "impossible"—whether by being unattested, violating linguistic universals, or being learnable only by non-human systems.
  - Quick check question: If a language has no predictable structure whatsoever, would you classify it as impossible? What if it's merely typologically rare?

- Concept: **Linking hypotheses**
  - Why needed here: These bridge constructs between model behavior and cognitive phenomena. Without them, LM findings are merely engineering results with no theoretical import.
  - Quick check question: If an LM shows locality preferences, what would you need to claim this tells us about human cognition?

## Architecture Onboarding

- Component map:
  - Language pair generator -> Training harness -> Discrimination metric -> Architecture variant module

- Critical path:
  1. Define impossible language formalization (e.g., dependency violations, non-local scrambling)
  2. Generate minimal pairs with controlled complexity
  3. Train matched LM pairs; extract comparative metrics
  4. Formulate linking hypothesis connecting observed gap to cognitive constraint
  5. Design architecture modification testing that hypothesis

- Design tradeoffs:
  - Strict minimal pairs maximize internal validity but may reduce ecological validity
  - Using existing LMs vs. training from scratch: trade speed for experimental control
  - Binary learnability vs. gradient learning measures: theoretical clarity vs. empirical realism

- Failure signatures:
  - LMs learn possible and impossible languages equally well (suggests missing inductive bias)
  - LMs learn impossible languages *faster* than possible ones (architecture actively misaligned)
  - Results are highly sensitive to hyperparameter choices (unstable linking hypotheses)
  - Different impossible language types show inconsistent patterns (no unified bias)

- First 3 experiments:
  1. Replicate Kallini et al. (2024) paradigm: train small transformers on English vs. scrambled word-order variants; measure perplexity gap at matched training steps.
  2. Memory ablation: Reduce context window progressively (512→256→128 tokens) and test whether locality-based impossible languages become harder to learn relative to possible ones.
  3. Cross-linguistic validation: Test same minimal-pair logic on a typologically diverse sample (e.g., SOV, VSO, ergative languages) to verify findings generalize beyond English.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can researchers formulate rigorous "linking hypotheses" that connect language model behaviors to human cognitive biases?
- Basis in paper: [explicit] The authors identify that "The real challenge lies in stating linking hypotheses that are informative" during their Phase 3.
- Why unresolved: This is a theoretical gap; current evidence shows LMs learn possible languages efficiently, but mapping this to specific human cognitive mechanisms remains undefined.
- What evidence would resolve it: A validated theoretical framework that successfully maps specific LM architectural features or learning dynamics to known psycholinguistic phenomena.

### Open Question 2
- Question: Does reducing the effective memory capacity of language models increase their preference for locality, thereby improving alignment with human language processing?
- Basis in paper: [explicit] The authors hypothesize that "By reducing the capacity of these mechanisms, we might encourage even more locality and thus better match human language."
- Why unresolved: Modern LMs often possess mechanisms for near-perfect long-sequence memory, but the causal link between limiting this capacity and mimicking human "locality" constraints requires empirical verification.
- What evidence would resolve it: Comparative studies showing that memory-constrained LMs exhibit stronger locality biases and outperform standard LMs in distinguishing possible from impossible languages.

### Open Question 3
- Question: Which specific class of language model architectures is capable of capturing linguistic asymmetries based on constituent structure?
- Basis in paper: [explicit] The authors ask, "What class of LMs is able to capture this asymmetry, and what might such LMs tell us about language and cognition?" in the context of Hunter (2025).
- Why unresolved: It is currently unclear which architectural features (e.g., recurrence, attention heads) are necessary for models to generalize based on constituency rather than surface statistics.
- What evidence would resolve it: Targeted evaluations of diverse LM architectures on the novel minimal pairs of possible/impossible languages proposed by Hunter (2025).

## Limitations

- Empirical findings are contested: Neighbor papers directly contradict the claim that LMs distinguish possible from impossible languages, reporting that LMs often learn both equally well.
- Impossible language definitions remain underspecified: The paper references linguist-identified impossible languages and counterfactual variants but provides no concrete criteria for construction or validation.
- Linking hypotheses are not operationalized: While identified as critical, the paper acknowledges that formulating informative linking hypotheses connecting LM behavior to human cognition remains a theoretical challenge.

## Confidence

- Medium confidence: The theoretical framework treating LMs as investigative tools with linking hypotheses is conceptually coherent and draws on established precedents from neuroscience. The phased research program is methodologically sound even if empirical validation remains pending.
- Low confidence: Claims about LMs successfully distinguishing possible from impossible languages are directly contradicted by neighbor papers. The assertion that architectural modifications (like memory constraints) will strengthen this discrimination lacks direct supporting evidence in the corpus.
- Medium confidence: The general idea that studying LM inductive biases can inform hypotheses about human language learning follows established patterns in cognitive science, though the specific linking hypotheses proposed require validation.

## Next Checks

1. **Empirical replication**: Conduct a controlled experiment training small transformers on minimal pairs from Kallini et al. (2024) comparing English with scrambled word-order variants, measuring learning efficiency gaps with standardized metrics (perplexity curves, convergence speed).

2. **Literature reconciliation**: Systematically review and compare methodologies across studies claiming opposite findings (LMs distinguish vs. LMs don't distinguish possible/impossible languages) to identify methodological differences that explain divergent results.

3. **Impossible language construction**: Develop explicit, testable criteria for what makes a language "impossible" beyond mere unattestedness—operationalize this as languages violating specific, well-defined linguistic universals or dependency structures that humans demonstrably cannot learn.