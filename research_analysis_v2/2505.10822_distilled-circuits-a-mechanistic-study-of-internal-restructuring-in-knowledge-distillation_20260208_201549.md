---
ver: rpa2
title: 'Distilled Circuits: A Mechanistic Study of Internal Restructuring in Knowledge
  Distillation'
arxiv_id: '2505.10822'
source_url: https://arxiv.org/abs/2505.10822
tags:
- student
- teacher
- numeral
- task
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies how knowledge distillation (KD) internally\
  \ restructures a student model\u2019s computation by applying mechanistic interpretability\
  \ methods to analyze GPT2-small and DistilGPT2 on a numeral sequence completion\
  \ task. It finds that students reorganize, compress, and discard teacher components,\
  \ often over-relying on fewer heads or MLPs, which reduces robustness to ablation\
  \ and distributional shifts."
---

# Distilled Circuits: A Mechanistic Study of Internal Restructuring in Knowledge Distillation

## Quick Facts
- arXiv ID: 2505.10822
- Source URL: https://arxiv.org/abs/2505.10822
- Reference count: 40
- Students reorganize, compress, and discard teacher components, reducing robustness

## Executive Summary
This paper reveals how knowledge distillation fundamentally restructures internal computation rather than merely compressing models. Through mechanistic interpretability on GPT2-small and DistilGPT2, it demonstrates that students merge teacher components, concentrate task-critical computation in fewer heads/MLPs, and discard non-essential functionalities. This compression creates more brittle models that fail dramatically under ablation and distributional shifts, despite maintaining similar output performance. The authors introduce an influence-weighted alignment metric that quantifies functional divergence between teacher and student circuits, validated through controlled noise experiments.

## Method Summary
The study employs iterative pruning and path patching to discover task-specific circuits, using logit difference (∆l) as the primary metric where incorrect token equals the final input element. Ablation replaces component activations with corrupted means, with threshold Tn=80% of original logit difference. Influence scores come from path patching, normalized to [0,1]. Component matching uses cosine similarity for heads and top-3 SVD eigenvectors for MLPs. The alignment metric A = (1/|M|) Σ Si·(1 - |I^S_i - I^T_i|) combines representation similarity with influence agreement. Analysis runs on 100 examples per task across GPT2-small/DistilGPT2 and BERT/DistilBERT pairs.

## Key Results
- Students merge multiple teacher MLPs into single components (e.g., MLP-T-9/10 → MLP-S-4)
- Ablating student numeral detection heads causes -87.73% performance drop vs -33.18% for teacher
- Alignment metric shows inverse-logarithmic decay under noise, plateauing at ~0.2
- First-token representational divergence observed in GPT-2 pair but not BERT models

## Why This Works (Mechanism)

### Mechanism 1: Component Compression and Merging
Under parameter constraints, KD forces students to merge redundant teacher computations into single, multi-functional components. MLPs at adjacent layers consolidate (cosine similarities: 0.634 and 0.687), preserving task output while halving component count. This compression works when the student has sufficient capacity to encode merged functionalities without catastrophic interference.

### Mechanism 2: Influence Concentration and Brittleness
Students concentrate task-critical computation in fewer components, eliminating backup circuits present in teachers. Critical functions distributed across multiple heads become single points of failure. Ablating the student's numeral detection head causes -87.73% performance drop versus -33.18% for the teacher's equivalent, demonstrating increased brittleness.

### Mechanism 3: Influence-Weighted Alignment Detection
The alignment metric A = (1/|M|) Σ Si·(1 - |I^S_i - I^T_i|) quantifies functional alignment by weighting representation similarity with task-specific influence scores. Components with similar activations but different task importance are penalized, detecting circuit-level divergence that output metrics miss.

## Foundational Learning

- **Causal Tracing and Ablation Studies**: Iterative ablation by replacing activations with corrupted means measures component importance via logit difference changes. Quick check: If ablating component X causes 50% logit difference drop, this indicates X is critical for task performance.

- **Attention Head QK/OV Decomposition**: QK matrices reveal token attention patterns (numeral detectors show high self-attention between consecutive numerals); OV circuits determine information movement to the residual stream. Quick check: High attention from final token to last numeral suggests successor head functionality.

- **Residual Stream Decomposition**: Layer-wise attribution via residual stream differences identifies which tokens each MLP influences, distinguishing task-specific computation from embedding transformation. Quick check: If an MLP's residual contribution concentrates on the final token, it likely serves successor computation.

## Architecture Onboarding

- **Component map**: Numeral detection (T-L4-H4 → S-L2-H4) → Numeral mover (T-L7-H11 → S-L3-H11) → Successor computation (T-L9-H1 → S-L4-H1) → Output; MLP-T-9/T-10 → MLP-S-4

- **Critical path**: Early numeral detection heads feed numeral mover heads, which aggregate information for the final token; successor MLP increments the numeral for output prediction

- **Design tradeoffs**: Parameter efficiency versus robustness (fewer parameters → concentrated reliance → no backup heads); functional coverage versus simplicity (non-critical functions discarded may matter on edge cases); output matching versus mechanism preservation (KL divergence doesn't guarantee mechanism transfer)

- **Failure signatures**: Ablation sensitivity >70% from single component (vs ~35% in teacher); missing functionalities (similar member detection absent); representational divergence on specific tokens (first-token divergence in MLP-T-11/MLP-S-5: cosine -0.302); high alignment drop under noise injection (plateau at 0.2)

- **First 3 experiments**:
  1. Replicate ablation sensitivity analysis: Identify critical components, measure % performance drop. Flag if student:teacher sensitivity ratio >2x.
  2. Implement alignment metric: Compute influence-weighted scores across tasks. Verify correlation with robustness, not just accuracy.
  3. Test distribution shift robustness: Evaluate circuits on longer sequences or different numeral ranges. Expect faster student degradation due to concentrated reliance.

## Open Questions the Paper Calls Out

- **Are student-discarded functionalities universal across architectures and tasks, or task-dependent?**: The paper notes both DistilGPT2 and DistilBERT discard "similar member detection" functionality, suggesting potential universality, but only two model pairs and one primary task were analyzed.

- **Is the first-token representational divergence a consistent byproduct of KD?**: The study observes this in GPT-2 pair MLP-T-11/MLP-S-5 but not in BERT models, highlighting the need to assess whether this is a recurring outcome of KD.

- **How does bidirectionality in encoder architectures alter circuit restructuring compared to autoregressive models?**: The paper hypothesizes that bidirectionality alters knowledge transfer based on lower alignment despite similar IOI performance, but lacks systematic comparison.

## Limitations
- Findings based on single task (numeral sequence completion) may not generalize to other domains
- Influence-weighted alignment metric lacks external validation beyond controlled noise experiments
- Correlation between internal mechanism divergence and downstream robustness remains largely correlational
- Does not account for potential differences in pretraining objectives between teacher and student models

## Confidence
- **High confidence**: Knowledge distillation changes internal mechanisms (supported by ablation studies showing increased brittleness)
- **Medium confidence**: Specific compression patterns (e.g., MLP-T-9/10 → MLP-S-4) are well-documented but may be task-specific
- **Medium confidence**: Alignment metric is mathematically sound but lacks external validation
- **Low confidence**: Generalization of these patterns to other tasks/distributions without further validation

## Next Checks
1. **Cross-task validation**: Apply the same mechanistic analysis pipeline to at least three additional tasks (e.g., language modeling, QA, code generation) to test whether component compression patterns persist across domains
2. **Architectural ablation study**: Systematically vary student capacity (e.g., 50%, 75%, 100% of teacher size) to determine whether observed brittleness scales monotonically with compression ratio
3. **Real-world distribution shift test**: Evaluate both teacher and student on out-of-distribution numeral sequences (e.g., longer sequences, different numeral ranges, mixed formats) to quantify practical robustness differences beyond synthetic noise injection