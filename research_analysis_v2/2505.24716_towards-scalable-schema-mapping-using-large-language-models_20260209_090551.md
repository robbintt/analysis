---
ver: rpa2
title: Towards Scalable Schema Mapping using Large Language Models
arxiv_id: '2505.24716'
source_url: https://arxiv.org/abs/2505.24716
tags:
- schema
- data
- which
- mapping
- matching
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the scalability challenges of schema mapping
  in data integration systems, where manual mapping is costly and error-prone. It
  explores using large language models (LLMs) for automating schema mapping, identifying
  three core issues: inconsistent LLM outputs, the need for more expressive mappings
  (GLaV) with limited context, and high computational costs.'
---

# Towards Scalable Schema Mapping using Large Language Models

## Quick Facts
- arXiv ID: 2505.24716
- Source URL: https://arxiv.org/abs/2505.24716
- Reference count: 38
- Using LLMs with sampling/aggregation achieves F1@1 ≈ 0.77–0.78 on MIMIC-OMOP and Synthea-OMOP datasets

## Executive Summary
This paper addresses the scalability challenges of schema mapping in data integration systems by leveraging large language models (LLMs). Manual schema mapping is costly and error-prone, while existing LLM approaches suffer from inconsistent outputs, high computational costs, and limited expressiveness for complex mappings. The authors propose solutions including sampling and aggregation techniques, efficient prompting strategies like data type prefiltering, and bidirectional schema matching with stable matching algorithms. Experiments demonstrate that these methods significantly improve LLM-based schema mapping performance while addressing scalability concerns, achieving results comparable to GPT-4-based approaches using an open-source LLM.

## Method Summary
The approach uses zero-shot LLM inference with Meta-Llama-3.1-70B-Instruct-GPTQ-INT4 on schema pairs from MIMIC-OMOP and Synthea-OMOP. The method employs N-1 JSON-serialized prompts with symmetric transformations (column permutation, value resampling, table swapping), 3 samples per pair with majority-vote aggregation, and bidirectional matching via stable matching or confidence multiplication. Data type prefiltering reduces computational cost by limiting comparisons to attributes with matching types. The pipeline extracts schema metadata including names, types, descriptions, foreign keys, and sampled values, then generates GLaV (Full Referential Dependency) mapping rules through structured prompts and aggregation.

## Key Results
- F1@1 scores of 0.77-0.78 using open-source LLM, comparable to GPT-4-based approaches
- Bidirectional matching with stable matching achieves F1@1 = 0.64-0.78 vs. baselines at 0.10-0.23
- Data type prefiltering reduces computational cost without proportional accuracy loss
- Sampling and aggregation techniques reduce LLM output inconsistency across transformations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Symmetric prompt transformations combined with aggregation reduce LLM output inconsistency.
- Mechanism: Apply structure-preserving transformations (column permutation, data value resampling, table swapping) to generate multiple prompts, then aggregate outputs using majority vote or union. This explores different regions of the model's output space, making consistently-produced mappings act as confidence proxies.
- Core assumption: LLM sensitivity to input structure is exploitable rather than purely noise; consistent outputs across transformations signal higher quality.
- Evidence anchors: [abstract] "inconsistent outputs due to sensitivity to input phrasing and structure, which we propose methods to address through sampling and aggregation techniques"

### Mechanism 2
- Claim: Bidirectional matching with stable matching algorithms improves precision-recall balance.
- Mechanism: Perform matching in both directions (source→target, target→source), compute confidence scores via LLM logit analysis, then apply Gale-Shapley stable matching. This enforces mutual acceptability—matches only survive if both sides "prefer" each other.
- Core assumption: Confidence scores approximate true match probability; bidirectional preference encoding captures latent alignment strength.
- Evidence anchors: [Section 3.2] Defines Stable Schema Matching formally; Figure 2 shows bidirectional pipeline

### Mechanism 3
- Claim: Data type prefiltering reduces computational cost without proportional accuracy loss.
- Mechanism: Categorize attributes into broad types (Numeric, Text, Date/Time, Boolean) before LLM comparison. In N-1 matching, only source attributes matching the target attribute's type enter the prompt, reducing N→k comparisons.
- Core assumption: Semantically aligned attributes share compatible data types; cross-type matches are rare enough to safely exclude.
- Evidence anchors: [abstract] "computational cost of repeated LLM calls, which we propose to mitigate through strategies like data type prefiltering"

## Foundational Learning

- Concept: **st-tgds (Source-to-Target Tuple-Generating Dependencies)**
  - Why needed here: The paper's GLaV mapping formalization relies on st-tgds (∀x φ(x) → ∃y ψ(x,y)). Understanding this notation is prerequisite to Section 2.1 and the expressiveness discussion.
  - Quick check question: Given source relation `orders(id, total)` and target `receipts(r_id, amount)`, write an st-tgd mapping.

- Concept: **Mapping Expressiveness Classes (GaV/LaV/GLaV)**
  - Why needed here: The paper distinguishes LRD (limited referential dependencies—GaV/LaV) from FRD (full—GLaV). Section 2.2's Example 3 shows why LRD fails for maintaining referential integrity across rules.
  - Quick check question: Why does splitting a GLaV rule into two GaV rules break the surrogate key connection?

- Concept: **LLM Position/Sensitivity Bias**
  - Why needed here: Section 3.1 exploits LLM sensitivity to column ordering. Understanding this bias motivates the permutation strategy.
  - Quick check question: If an LLM consistently prefers first-presented options, how would column permutation help surface alternative matches?

## Architecture Onboarding

- Component map: Schema Parser -> Prefilter -> Prompt Generator -> LLM Interface -> Bidirectional Matcher -> Aggregator -> Candidate Evaluator

- Critical path: Schema → Prefilter → Prompt Generator (with transformations) → LLM → Bidirectional Matcher → Aggregator → Candidate Set. The sampling/aggregation and bidirectional matching are the core contributions.

- Design tradeoffs:
  - Union aggregation maximizes recall; intersection maximizes precision; majority vote balances.
  - More samples = better coverage but higher cost. Table 4 shows 7 rules/prompt reduces tokens 2.57x vs. 1 rule/prompt but recall drops (Figure 3).
  - Smaller models (Llama-70B) with better pipelines can match GPT-4 performance (Table 3).

- Failure signatures:
  - Format deviation: LLM produces non-JSON or skips final decision (Parciak baseline failure mode, Section 3.3)
  - Empty/null-heavy outputs: Model omits rules when overloaded (MRPP>1, Figure 3 recall drop)
  - Type mismatch passes: Prefilter too aggressive, missing valid cross-type matches
  - Stable matching deadlock: No mutually acceptable pairs when confidence scores poorly calibrated

- First 3 experiments:
  1. Baseline replication: Implement N-1 prompting with single static prompt on MIMIC-OMOP subset. Measure P@k/R@k/F1@k to establish baseline.
  2. Ablation on transformation types: Test each transformation (column permutation, value resampling, table swap) independently vs. combined. Identify which contributes most to improvement.
  3. Aggregation function comparison: Compare union/majority/intersection/multiplication/stable matching on same output set. Plot precision-recall tradeoff curve to select default.

## Open Questions the Paper Calls Out

- **Question:** How can sampling and aggregation techniques be effectively adapted for Full Referential Dependency (FRD) or GLaV mappings, where output overlap is difficult to assess?
  - **Basis in paper:** [explicit] The paper states, "Extending these techniques to schema mappings is not as easy do to the increased complexity in the output language... Clearly, this is an important subject for future research."
  - **Why unresolved:** Unlike atomic schema alignments, complex mapping rules (queries) are difficult to partition or compare for overlap because logical equivalence is often undecidable and exact string matching is too restrictive.
  - **What evidence would resolve it:** A method for approximating logical equivalence or semantic overlap between generated mapping rules that enables reliable aggregation without exact string matching.

- **Question:** How can relevant schema subgraphs be filtered a priori to facilitate efficient GLaV mapping generation without knowing the target rules beforehand?
  - **Basis in paper:** [explicit] The authors note, "When developing a schema filter, we must consider its restrictiveness... finding $S_k$ and $T_k$ is, itself, a form of schema filtering. However, knowing neither set of relations makes filtering a potentially multi-step process."
  - **Why unresolved:** Generating expressive mappings requires context, but including the full schema overwhelms the LLM. Identifying which specific source and target relations belong to a rule requires a filter that does not yet exist.
  - **What evidence would resolve it:** A filtering mechanism that successfully predicts the specific relations ($S_k$ and $T_k$) required for a rule, reducing token count while maintaining mapping accuracy.

- **Question:** How can semantic constraints be practically defined or derived to filter poor-quality candidate mappings in a scalable manner?
  - **Basis in paper:** [explicit] The paper asks, "how would one explicitly define these constraints and how could they be used in practice?" and suggests deriving them from existing data or user preferences is necessary.
  - **Why unresolved:** Business rules and semantic constraints are often latent (in users' heads) or undocumented, making them difficult to encode for automated filtering without tedious manual effort.
  - **What evidence would resolve it:** A system that automatically derives constraints from existing target instances or user validation logs and uses them to reject semantically invalid candidate mappings.

## Limitations

- Prompt design opacity: The exact JSON schema and prompt templates are only referenced externally, making exact reproduction difficult.
- Context truncation risk: Claims that ~1k tokens suffices for GLaV rules need verification against the warning about exceeding context windows.
- Stable matching calibration: Bidirectional matching assumes LLM confidences approximate true match probabilities without calibration curves or ablation.
- Type-prefiltering assumptions: Prefiltering assumes semantic alignment implies type alignment without analysis of type mismatch false negatives.

## Confidence

- High confidence: Sampling/aggregation improves robustness to LLM output inconsistency (Section 3.1 results, Table 1-2 improvement over baselines).
- Medium confidence: Bidirectional matching with stable matching improves precision-recall balance (Tables 1-2 show consistent gains, but no ablation on matching strategy).
- Medium confidence: Data type prefiltering reduces computation without major accuracy loss (Section 6 claims supported, but no ablation on type assumption validity).
- Low confidence: LLM scaling laws (Table 3) are based on only two model sizes; no model size trend analysis.

## Next Checks

1. Prompt fidelity test: Reconstruct the JSON schema and prompt template from the description and validate against the reported F1@1 ≈ 0.77–0.78 on MIMIC-OMOP.
2. Context window ablation: Vary Max. Rules per Prompt and measure recall/precision tradeoff; confirm that ~1k tokens suffices for GLaV rules.
3. Type-prefiltering stress test: Identify cross-type semantic matches in MIMIC-OMOP; measure false negative rate when type prefiltering is applied.