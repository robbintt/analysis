---
ver: rpa2
title: Approximate Bayesian Inference via Bitstring Representations
arxiv_id: '2508.13598'
source_url: https://arxiv.org/abs/2508.13598
tags:
- bitvi
- inference
- bitstring
- circuit
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BitVI, a novel approach for approximate Bayesian
  inference that operates directly in the space of discrete bitstring representations.
  The key idea is to perform inference in the quantized, discrete parameter space
  created by low-precision representations, enabling continuous distributions to be
  learned using discrete parameters.
---

# Approximate Bayesian Inference via Bitstring Representations

## Quick Facts
- arXiv ID: 2508.13598
- Source URL: https://arxiv.org/abs/2508.13598
- Reference count: 40
- Primary result: BitVI achieves comparable NLPD performance to mean-field and full-covariance Gaussian VI on UCI datasets using 4-8 bit representations

## Executive Summary
This paper introduces BitVI, a novel approach for approximate Bayesian inference that operates directly in the space of discrete bitstring representations. The key idea is to perform inference in the quantized, discrete parameter space created by low-precision representations, enabling continuous distributions to be learned using discrete parameters. BitVI leverages probabilistic circuits as a tractable representation framework, allowing efficient learning and inference over complex distributions without requiring high-precision representations.

The primary results demonstrate that BitVI can effectively approximate complex non-Gaussian densities and perform uncertainty quantification in Bayesian deep learning tasks. On Bayesian benchmark UCI datasets, BitVI with 4-bit and 8-bit representations achieves comparable performance to mean-field Gaussian VI and full-covariance Gaussian VI baselines in terms of negative log predictive density.

## Method Summary
BitVI performs variational inference by learning distributions over fixed-point bitstrings that map to real values. The method constructs a deterministic tree-structured probabilistic circuit (PC) where each path from root to leaf represents a B-bit string. Sum nodes encode conditional bit probabilities while leaves represent uniform distributions over quantization intervals. The ELBO is optimized using Monte Carlo sampling with inverse-CDF reparameterization and straight-through estimator for the non-differentiable discretization step. A depth-based regularization with Laplace smoothing prevents early bit decision collapse.

## Key Results
- On UCI benchmark datasets, BitVI (4-bit and 8-bit) achieves comparable NLPD to MFVI and FCGVI baselines
- Low-bit models (2-4 bits) perform well, with neural network size dominating expressivity over numerical precision
- BitVI successfully captures hierarchical structures in neural networks and determines appropriate bitstring depth for target distributions

## Why This Works (Mechanism)

### Mechanism 1
Continuous distributions can be approximated by learning distributions over discrete bitstrings mapped to real values via a fixed-point number system. A B-bit fixed-point bitstring partitions the real line into 2^B equal-width intervals. A probabilistic circuit (PC) assigns probabilities to each bitstring, inducing a piecewise-uniform density over reals. The tree-structured PC uses sum nodes to represent bit decisions (0/1) and uniform leaf nodes for terminal intervals.

### Mechanism 2
Deterministic probabilistic circuits enable tractable entropy computation and efficient inverse-CDF reparameterization for ELBO optimization. In deterministic PCs, each sum node activates exactly one child per input, making entropy decompose recursively: H(C) = -Σ w_i log(w_i) + Σ w_i H(child_i). This is linear in circuit edges. The inverse CDF traverses the tree top-down by comparing uniform samples to cumulative weights at each sum node, also linear-time.

### Mechanism 3
The straight-through estimator (STE) enables gradient-based optimization through the non-differentiable discretization step. During forward pass, continuous values from inverse-CDF are rounded to nearest fixed-point value. During backward pass, gradients bypass the rounding operation via STE: grad through (ϕ(ϵ) + F⁻¹(y)) - F⁻¹(y) where the first term uses discretized value but gradient flows through F⁻¹(y) as if continuous.

## Foundational Learning

- **Concept: Variational Inference (VI) and the ELBO**
  - Why needed here: BitVI is a VI method; understanding ELBO decomposition (expected log-likelihood + entropy) is essential for grasping why tractable entropy matters.
  - Quick check question: Can you explain why maximizing the ELBO is equivalent to minimizing KL(q || p)?

- **Concept: Probabilistic Circuits (smooth, decomposable, deterministic)**
  - Why needed here: The core representational substrate; smoothness/decomposability enable tractable marginalization; determinism enables closed-form entropy.
  - Quick check question: What structural property of a PC makes entropy computation tractable?

- **Concept: Reparameterization Trick and Inverse CDF Sampling**
  - Why needed here: BitVI uses inverse-CDF reparameterization to enable Monte Carlo ELBO estimation with low-variance gradients.
  - Quick check question: Why is inverse-CDF sampling useful for gradient estimation compared to score-function methods?

## Architecture Onboarding

- **Component map:** Bitstring Encoder -> Tree-structured PC -> ELBO Computer -> STE Bridge

- **Critical path:**
  1. Initialize PC weights (beta distribution based on tree height)
  2. Sample u ~ Uniform(0,1); traverse tree to get bitstring ϵ and corresponding real x
  3. Evaluate target log-likelihood log p(x; data)
  4. Compute entropy H(q) via recursive tree traversal
  5. Form ELBO = E[log p] + H; backpropagate through STE
  6. Update PC weights via Adam

- **Design tradeoffs:**
  - Bit depth vs. expressivity: More bits → finer approximation but exponentially more parameters (2^B leaves)
  - Mean-field vs. joint: Full joint over all dimensions scales as 2^(B·D); mean-field assumption reduces to independent per-dimension trees
  - Integer/fractional bit allocation: More integer bits → larger representable range; more fractional bits → finer resolution

- **Failure signatures:**
  - ELBO not improving / NaN gradients: Likely bit depth too low for target complexity, or STE gradient mismatch; try increasing bits
  - Posterior collapses to single interval: Depth regularization too weak; increase c in Laplace smoothing
  - Memory explosion: Joint model over many dimensions; switch to mean-field approximation
  - Mode dropping: PC tree structure may not align with target modality positions; increase bits or check initialization

- **First 3 experiments:**
  1. 2D Gaussian mixture with 4-bit BitVI: Verify basic density approximation; compare samples/contours to ground truth. Success criterion: modes captured, reasonable shape.
  2. Two-moons classification with small MLP (4-bit vs. 8-bit vs. MFVI): Compare NLPD and decision boundary uncertainty. Success criterion: 4-bit within 5-10% of MFVI baseline.
  3. Entropy vs. bit depth sweep on synthetic mixture: Plot target entropy vs. BitVI entropy across 2-12 bits. Success criterion: entropy plateaus when bit depth is sufficient for target complexity.

## Open Questions the Paper Calls Out

- **Can BitVI be effectively adapted to floating-point representations to improve density approximation over the fixed-point systems used in this study?**
  - Basis in paper: The authors state in the Conclusion that "Exploiting the representational power of floating-point representations is a promising future avenue."
  - Why unresolved: Floating-point uses variable-width intervals, potentially offering better fit for distributions with varying density scales, but the implementation and tractability within the current Probabilistic Circuit framework remain unexplored.
  - What evidence would resolve it: Extending the method to floating-point bitstrings and benchmarking against the fixed-point results on the same non-Gaussian densities.

- **Can compact Probabilistic Circuit architectures (e.g., Einsum networks) be integrated to scale BitVI to high-dimensional posteriors without relying on mean-field assumptions?**
  - Basis in paper: The paper notes modeling dependencies is currently "computationally and memory burdensome" and suggests "leverage more compact representations" as a future direction.
  - Why unresolved: The current tree construction grows exponentially (2^(B·D)), forcing a mean-field approximation for high-dimensional neural networks, which ignores parameter correlations.
  - What evidence would resolve it: A study applying structured or compressed circuits to BitVI on high-dimensional datasets (e.g., larger UCI benchmarks) demonstrating competitive performance while retaining dependency modeling.

## Limitations
- Expressivity is fundamentally limited by quantization resolution, requiring exponentially more bits for finer approximation
- Full joint models scale as 2^(B·D), making them intractable for moderate-dimensional problems
- Straight-through estimator introduces approximation error that is not quantified in the paper

## Confidence
- **High Confidence**: The core algorithmic framework (deterministic PC construction, entropy computation, inverse-CDF reparameterization) is well-specified and mathematically sound. The experimental setup for UCI datasets is clearly described.
- **Medium Confidence**: The claim that BitVI performs "comparable to MFVI and FCGVI" is supported by the reported NLPD metrics, but the comparison is limited to a specific subset of UCI datasets and may not generalize to all Bayesian inference problems.
- **Low Confidence**: The claim about parsimonious behavior (naturally determining appropriate bitstring depth) lacks quantitative validation. The experiments show performance at fixed bit depths but don't systematically demonstrate depth selection capabilities.

## Next Checks
1. **Quantization Error Analysis**: Systematically evaluate approximation error as a function of bit depth on analytically tractable distributions (Gaussian mixtures with known modes and variances). Plot Wasserstein distance vs. bits to quantify the trade-off between resolution and approximation quality.

2. **STE Gradient Quality Assessment**: Compare STE-based optimization with unbiased gradient estimators (e.g., score function method) on simple 2D density estimation tasks. Measure convergence speed and final ELBO values to quantify STE approximation error.

3. **Full Joint vs. Mean-Field Scaling Experiment**: Test BitVI on a controlled synthetic dataset with known parameter correlations (e.g., rotated Gaussian mixture). Compare full joint model performance against mean-field approximation as dimensionality increases from 2 to 8 dimensions, measuring the impact of the independence assumption on NLPD.