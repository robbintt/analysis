---
ver: rpa2
title: Prompt-Based Continual Compositional Zero-Shot Learning
arxiv_id: '2512.09172'
source_url: https://arxiv.org/abs/2512.09172
tags:
- learning
- session
- continual
- compositional
- zero-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses continual compositional zero-shot learning
  (CCZSL), where a model must incrementally learn new attribute-object compositions
  while preserving knowledge of previously seen compositions. The key challenge is
  catastrophic forgetting due to overlapping attributes/objects across sessions and
  unique compositions.
---

# Prompt-Based Continual Compositional Zero-Shot Learning

## Quick Facts
- arXiv ID: 2512.09172
- Source URL: https://arxiv.org/abs/2512.09172
- Authors: Sauda Maryam; Sara Nadeem; Faisal Qureshi; Mohsen Ali
- Reference count: 31
- Primary result: PromptCCZSL achieves 55.86% average AUC on UT-Zappos (+25.4% over prior methods) and 13.2% average AUC on C-GQA (+9.91%)

## Executive Summary
This paper addresses continual compositional zero-shot learning (CCZSL), where a model must incrementally learn new attribute-object compositions while preserving knowledge of previously seen compositions. The key challenge is catastrophic forgetting due to overlapping attributes/objects across sessions and unique compositions. The proposed PromptCCZSL framework uses a frozen VLM backbone with learnable soft prompts for attributes and objects. It introduces session-aware fusion for new compositions, session-agnostic fusion for recurring primitives, multi-teacher knowledge distillation with recency weighting, cosine anchor alignment to preserve semantic consistency, orthogonal projection to prevent embedding overlap, and intra-session diversification to enrich prompt diversity. Experiments on UT-Zappos and C-GQA datasets show substantial improvements over baselines, achieving 55.86% average AUC on UT-Zappos (+25.4% over prior methods) and 13.2% average AUC on C-GQA (+9.91%).

## Method Summary
PromptCCZSL uses a frozen CLIP ViT-L/14 backbone with learnable soft prompts for attributes and objects. The framework employs session-agnostic fusion (SAgM2F) to globally refine all primitives and session-aware fusion (SAwM2F) to isolate new composition learning. Multi-teacher knowledge distillation with recency weighting preserves prior knowledge, while geometric regularization losses (CAL, OPL, IDL) maintain semantic consistency and prevent embedding overlap. The model is trained session-by-session, freezing each session's model as a teacher for subsequent sessions.

## Key Results
- PromptCCZSL achieves 55.86% average AUC on UT-Zappos, outperforming prior methods by 25.4%
- On C-GQA, the framework reaches 13.2% average AUC, improving over baselines by 9.91%
- The framework effectively mitigates catastrophic forgetting while maintaining compositional generalization across incremental learning sessions
- Ablation studies show that each component (multi-teacher KD, CAL, OPL, IDL) contributes significantly to performance gains

## Why This Works (Mechanism)

### Mechanism 1: Recency-Weighted Multi-Teacher Knowledge Distillation
Aggregating knowledge from all prior session teachers with recency-based weighting preserves historical compositional knowledge better than single-teacher distillation. Frozen teacher models from sessions 0 to t-1 provide soft logits for overlapping attributes, objects, and compositions. Each teacher's contribution is weighted by recency (πt monotonically decreasing), so more recent sessions have higher influence. KL divergence aligns student and teacher probability distributions on shared primitives.

### Mechanism 2: Prompt Bank Geometric Regularization (CAL + OPL + IDL)
Enforcing directional alignment, inter-session orthogonality, and intra-session diversity in the soft prompt embedding space jointly mitigates catastrophic forgetting while enabling compositional generalization. CAL minimizes 1-cosine similarity between overlapping attribute/object prompts and their anchors from previous sessions. OPL enforces orthogonality between head (prior sessions) and tail (current session) prompt subspaces. IDL penalizes mean absolute cosine similarity within current-session prompts, encouraging diverse representations.

### Mechanism 3: Session-Adaptive Fusion Architecture (SAgM2F + SAwM2F)
Separating primitive (attribute/object) updates from composition updates via session-agnostic and session-aware fusion modules enables global semantic consistency while allowing session-specific compositional adaptation. SAgM2F refines all attribute and object embeddings via cross-attention with visual patches. SAwM2F partitions composition prompts into head (previous sessions, passed through MLP unchanged) and tail (current session, refined via cross-attention), learning new compositions without overwriting prior semantics.

## Foundational Learning

- **Concept: CLIP-style Vision-Language Models and Contrastive Pretraining**
  - Why needed here: PromptCCZSL builds entirely on a frozen CLIP backbone; understanding how CLIP aligns image and text embeddings via contrastive learning is prerequisite to understanding why soft prompts can modulate compositional reasoning.
  - Quick check question: Can you explain why CLIP's zero-shot classification works and what "logit_scale" (β) represents in the similarity computation?

- **Concept: Compositional Zero-Shot Learning (CZSL) Fundamentals**
  - Why needed here: CCZSL extends CZSL to continual settings; you must understand seen/unseen composition splits, closed-world evaluation, and why compositional generalization is harder than standard zero-shot learning.
  - Quick check question: Given attribute set A={red, blue, wet} and object set O={cat, car}, what are C_seen, C_unseen, and C_test in a closed-world CZSL setup with 3 seen compositions?

- **Concept: Knowledge Distillation for Continual Learning**
  - Why needed here: Multi-teacher distillation with recency weighting is the primary forgetting mitigation mechanism; understanding logit-based KD and why feature/relational KD might differ is essential.
  - Quick check question: In LwF-style distillation, why align student and teacher logits on new task data, and what happens if the teacher was never trained on classes appearing in the student's new task?

## Architecture Onboarding

- **Component map:**
  Frozen CLIP ViT-L/14 backbone -> Soft Prompt Bank -> Primitive Decomposition Module -> SAgM2F -> SAwM2F -> Classification Branches -> Multi-Teacher Distillation + Regularization Losses

- **Critical path:**
  1. Initialize soft prompt bank from CLIP token embeddings (mean pooling)
  2. Extract visual features via frozen encoder + adapter-enhanced layers
  3. Factorize visual features into v_a, v_o, v_c via decomposition heads
  4. Fuse textual embeddings via SAgM2F (all primitives) and SAwM2F (tail compositions only)
  5. Compute classification logits via cosine similarity
  6. Apply L_CE + L_CSKD + L_CAL + L_OPL + L_IDL
  7. Freeze student as teacher for next session

- **Design tradeoffs:**
  - Freezing backbone vs. learning prompts: Freezing preserves zero-shot generalization but limits representational plasticity; prompts provide lightweight adaptation without backbone perturbation
  - λ_kd vs. λ_ce: Higher KD weight (0.65 in best config) improves retention but may reduce new session learning
  - OPL weight: λ_opl = 0.05 produces cleanest cluster separation; λ_opl > 0.1 restricts new learning
  - CAL weight: λ_cal = 0.05-0.1 balances stability-flexibility; higher values overfit to old sessions

- **Failure signatures:**
  - Rapid AUC collapse across sessions: Indicates distillation/regularization insufficient; check λ_kd weight and verify multi-teacher aggregation
  - New session primitives overlapping old in t-SNE: OPL weight too low or prompt dimensionality insufficient
  - Forgetting early-session zero-shot compositions: CAL weight insufficient or recency weighting too aggressive
  - Compositional accuracy near zero while attribute/object accuracy remains high: Fusion modules not properly integrating multimodal signals

- **First 3 experiments:**
  1. **Single-session baseline**: Train on Session 0 only with L_CE to establish compositional generalization upper bound. Verify prompt bank initialization and classification branches work correctly. Target: ~60 AUC on UT-Zappos Session 0 unseen.
  2. **Ablation cascade on Session 1**: Add components incrementally (SAwM2F → CAL → OPL → IDL) to isolate each mechanism's contribution. Use single-teacher KD first, then switch to multi-teacher. Track AUC, AttrAcc, ObjAcc per addition.
  3. **Catastrophic forgetting measurement**: Train through all sessions, then evaluate each session model on all unseen test sets. Compute F_AUC metric. Compare baseline Troika vs. PromptCCZSL.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PromptCCZSL perform in the "Realistic-CCZSL" setting where compositions unseen in one session may appear as seen pairs in subsequent sessions?
- Basis in paper: Section 3.1 defines "Realistic-CCZSL" but states, "In our current work we are exploring only Constrained-CCZSL."
- Why unresolved: The current evaluation protocol enforces a constraint that unseen compositions in the initial session remain unseen throughout, simplifying the continual learning dynamic.
- What evidence would resolve it: Experimental results (AUC, HM) on C-GQA or UT-Zappos splits where the condition $C^{(i)}_{unseen} \cap C^{(j)}_{seen} \neq \emptyset$ is permitted.

### Open Question 2
- Question: Can the framework remain computationally feasible as the cumulative number of compositions grows significantly beyond the tested dataset scales?
- Basis in paper: Section 5 and Section 10 note that "cumulative expansion of compositions can make later sessions prohibitively expensive to train on mid-range GPU hardware."
- Why unresolved: The soft prompt bank expands with every new primitive, and inference requires scoring against the union of all seen compositions, which may lead to memory saturation.
- What evidence would resolve it: Analysis of GPU memory consumption and training latency on datasets with 10x the number of sessions or primitives, potentially utilizing prompt pruning or compression techniques.

### Open Question 3
- Question: To what extent does the closed-world assumption limit the model's ability to reject "invalid" or implausible attribute-object pairs in an open-world setting?
- Basis in paper: The paper follows a "closed-world setup" where the test label space is restricted to $C_{test} = C_{seen} \cup C_{unseen}$, explicitly avoiding invalid compositions.
- Why unresolved: Real-world continual learning requires distinguishing valid unseen pairs from semantically invalid ones (e.g., "Dry Water"), which is not evaluated in the closed-world protocol.
- What evidence would resolve it: Evaluation using Open-World CZSL metrics where the model must rank feasible compositions higher than infeasible ones within a generalized label space.

## Limitations

- **Dataset Generalization**: Results only evaluate on "Ideal-CCZSL" setting where compositions never repeat across sessions; performance in "Realistic-CCZSL" setting (compositions can recur) remains untested.
- **Architectural Overhead**: Critical hyperparameters including temperature τ for distillation, context length m for soft prompts, and exact recency weighting function π_t are underspecified, affecting replication fidelity.
- **Evaluation Metrics**: The paper relies primarily on AUC and F_AUC metrics which aggregate performance across sessions but don't reveal detailed per-session degradation patterns.

## Confidence

- **High**: The session-adaptive fusion architecture (SAgM2F + SAwM2F) and its role in separating primitive/global updates from compositional/session-specific updates is well-supported by experimental results showing improved AUC over baselines.
- **Medium**: The multi-teacher knowledge distillation with recency weighting is theoretically sound and shows improvement in ablation studies, but the exact weighting mechanism is underspecified.
- **Medium**: The geometric regularization losses (CAL, OPL, IDL) have clear theoretical motivation and ablation support, but the precise weight combinations that optimize performance are not fully disclosed.

## Next Checks

1. **Cross-Dataset Generalization**: Test PromptCCZSL on a third compositional dataset (e.g., MIT-States or C-GQA variants) to verify that the performance gains generalize beyond the two datasets used in the paper.

2. **Realistic-CCZSL Setting**: Implement and evaluate the framework under the "Realistic-CCZSL" setting where attribute-object compositions can recur across sessions to test robustness against compositional overlap.

3. **Memory Efficiency Analysis**: Measure the actual memory footprint of the prompt bank and teacher models during training to validate the claim that the framework scales to hundreds of sessions without prohibitive storage costs.