---
ver: rpa2
title: Hamiltonian Theory and Computation of Optimal Probability Density Control in
  High Dimensions
arxiv_id: '2505.18362'
source_url: https://arxiv.org/abs/2505.18362
tags:
- control
- density
- optimal
- problem
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses optimal probability density control in high-dimensional
  spaces by developing a theoretical framework and scalable numerical algorithm. It
  establishes the Pontryagin Maximum Principle and Hamilton-Jacobi-Bellman equation
  for density control without using Wasserstein theory, enabling rigorous derivations
  in standard function spaces.
---

# Hamiltonian Theory and Computation of Optimal Probability Density Control in High Dimensions

## Quick Facts
- arXiv ID: 2505.18362
- Source URL: https://arxiv.org/abs/2505.18362
- Reference count: 40
- Primary result: Establishes Pontryagin Maximum Principle and HJB equation for optimal density control in high dimensions using classical function spaces rather than Wasserstein theory

## Executive Summary
This paper develops a theoretical framework and scalable numerical algorithm for optimal probability density control in high-dimensional spaces. The authors establish the Pontryagin Maximum Principle and Hamilton-Jacobi-Bellman equation for density control without using Wasserstein geometry, enabling rigorous derivations in standard function spaces. The proposed algorithm uses deep neural networks to parameterize control vector fields and adjoint functions, allowing efficient solution of problems in up to 100 dimensions. Theoretical convergence analysis shows that generated control sequences converge to local optimal solutions, and numerical experiments demonstrate effectiveness on problems with particle interactions and obstacles.

## Method Summary
The method solves optimal control problems where the state is a probability density evolving according to a continuity equation, and the control is a vector field steering this density. The algorithm alternates between solving the adjoint equation backward in time and updating the density and control forward in time using proximal optimization. Control fields and adjoint functions are parameterized as Deep Neural Networks (ResNets), and PDE constraints are enforced via Physics-Informed Neural Networks (PINNs) with Monte Carlo sampling. This meshless approach avoids the curse of dimensionality associated with spatial discretization, enabling solution of problems in up to 100 dimensions.

## Key Results
- Establishes Pontryagin Maximum Principle and Hamilton-Jacobi-Bellman equation for density control without Wasserstein theory
- Proposes scalable algorithm using deep neural networks for high-dimensional problems (d=100)
- Demonstrates monotonic decrease in cost functional values in numerical experiments
- Shows Hamiltonian ratios remain approximately constant across time in experiments

## Why This Works (Mechanism)

### Mechanism 1: Classical Control Theory in $L^2$ Function Spaces
The paper theoretically enables optimal density control without Wasserstein geometry by treating probability density space $\mathcal{P}$ and control vector fields $\mathcal{U}$ as subsets of standard function spaces. By deriving Pontryagin Maximum Principle and HJB equations using classical calculus of variations, the authors avoid the computational complexity of optimal transport theory. The key assumption is that control $u$ and density $\rho$ are sufficiently regular (Lipschitz continuous and bounded), with every time point being a Lebesgue point of $u_t(x)\rho_t(x)$.

### Mechanism 2: Iterative Proximal Optimization via Control Hamiltonian
The algorithm converges to local optima by iteratively solving a control Hamiltonian system. It alternates between solving the adjoint equation backward in time (updating $\phi$) and solving a proximal point minimization forward in time (updating $\rho, u$). This structure mirrors classical optimal control solvers but operates on neural network parameters. The Hamiltonian $H$ must be concave in $u$, and variations $\delta_\rho H$ and $\delta_u H$ must be Lipschitz continuous for convergence.

### Mechanism 3: Dimension-Independent Computation via Neural Operators
The method scales to high dimensions ($d=100$) by avoiding spatial discretization. Control fields $u$ and adjoint functions $\phi$ are parameterized as Deep Neural Networks (ResNets). PDE constraints are enforced via Monte Carlo sampling of particles and automatic differentiation (PINNs), effectively bypassing the curse of dimensionality associated with grid-based methods. The particle swarm size $N$ must be sufficient relative to dimension $d$ for stable gradient descent.

## Foundational Learning

- **Pontryagin Maximum Principle (PMP)**: The theoretical core that defines optimality conditions using adjoint variables (Lagrange multipliers for dynamics). *Quick check*: Can you explain the relationship between Hamiltonian $H$, state $\rho$, and adjoint $\phi$ in a control loop?

- **Continuity Equation (Transport Phenomena)**: The PDE ($\partial_t \rho + \nabla \cdot (\rho u) = 0$) describing how probability density evolves under control velocity field. *Quick check*: If control field $u$ is diverging ($\nabla \cdot u > 0$), what happens to density $\rho$ locally?

- **Physics-Informed Neural Networks (PINNs)**: The numerical engine enforcing PDE residuals directly into neural network loss functions. *Quick check*: How does loss function in Eq. (38) differ from standard supervised learning loss?

## Architecture Onboarding

- **Component map**: Initial particles $X_i(0)$ -> Neural ODE solver -> Trajectories $X_i(t)$ -> $\phi$ network -> Adjoint loss -> $\phi$ weights -> $u$ network -> Control loss -> $u$ weights

- **Critical path**: 
  1. Initialize particles $X_i(0)$ and initial control net $u_0$
  2. Forward rollout: Integrate ODE $X'_i(t) = u(t, X_i(t))$ to get trajectories
  3. Adjoint solve: Train $\phi$ to minimize residual of adjoint PDE using current trajectories
  4. Control update: Train $u$ to maximize Hamiltonian + proximal term
  5. Check: If $\int_0^T\|u_{k+1}-u_k\|^2dt < \kappa$, stop

- **Design tradeoffs**:
  - ReLU vs. Smooth Activation: Uses ReLU for control $u$ for empirical performance despite theory requiring smoothness
  - Hard vs. Soft Terminal Constraints: Adjoint $\phi$ uses hard-coded architecture to satisfy terminal conditions, reducing loss complexity but network flexibility

- **Failure signatures**:
  - Non-constant Hamiltonian: If $H_t^K/|H_0^K|$ drifts significantly from constant, optimality conditions not met
  - Numerical Instability: If particle trajectories explode, Lipschitz bound $B_U$ may be too high or step size $\epsilon_k$ too large

- **First 3 experiments**:
  1. 1D Sanity Check: Implement on 1D Gaussian transport problem, verify particles move from mean $-2$ to $2$ and Hamiltonian is constant
  2. Interaction Ablation: Run Test 1 with $\gamma=0$ (no interaction) vs. $\gamma=5$, verify higher $\gamma$ results in lower particle density visually
  3. Scaling Test: Fix particles $N=2048$, run cylinder obstacle problem for $d=8, 30, 100$, plot final cost $I[u_K]$ vs dimension

## Open Questions the Paper Calls Out

1. **Extension to Optimal Transport and SchrÃ¶dinger Bridge Problems**: The authors note the framework has "great potential to be applied to OT and SBP with proper adjustments" but leave this for future investigation. The current formulation is designed for free-endpoint problems, while OT and SBP require fixed terminal density constraints.

2. **Stochastic Case Implementation**: While theoretical extension to stochastic case (Fokker-Planck equation) is derived, Section 5 exclusively tests deterministic continuity equation. The numerical implementation for stochastic case with additional Laplacian term remains unverified.

3. **Convergence Analysis with Non-Smooth Activations**: The convergence proof relies on controls with "uniformly bounded second-order derivatives," but experiments use ReLU activations which are non-smooth. The impact of this technical violation on convergence guarantees is unaddressed.

4. **Enforcing Constant Hamiltonian Property**: The Hamiltonian ratio $H_t^K/|H_0^K|$ is only "roughly around -1" in experiments, suggesting the implementation needs improvement to produce truly constant Hamiltonian in time as required by theory.

## Limitations

- Theoretical framework relies on Lipschitz continuity and boundedness assumptions, excluding singular controls and degenerate densities common in real applications
- Scalability claims to 100 dimensions demonstrated but not rigorously analyzed; computational cost scaling with dimension unclear
- Convergence proof only guarantees convergence to local optima without bounds on gap to global solutions
- Implementation details like neural ODE solver specifications and domain sampling strategies not fully specified

## Confidence

- **High Confidence**: Rigorous derivation of PMP and HJB equations in standard function spaces; clear algorithmic framework with proven monotonic decrease property
- **Medium Confidence**: Practical implementation details and scalability claims demonstrated but not fully specified or analyzed
- **Low Confidence**: Lack of systematic ablation studies on hyperparameters; no comparative benchmarks against alternative methods; untested performance beyond 100 dimensions

## Next Checks

1. **Lipschitz Sensitivity Analysis**: Systematically vary Lipschitz constant bound $B_U$ for control fields and measure impact on convergence speed and solution quality, testing with controls approaching theoretical Lipschitz limit

2. **Dimension Scaling Benchmark**: Fix particles $N=2048$ and systematically increase dimension from $d=2$ to $d=200$, plotting final cost $I[u_K]$ versus dimension to determine scaling behavior and practical dimensionality ceiling

3. **Local Optima Quality Assessment**: For simple test cases with known global optima, run algorithm from multiple random initializations and measure variance in final costs to quantify frequency of finding global versus local optima