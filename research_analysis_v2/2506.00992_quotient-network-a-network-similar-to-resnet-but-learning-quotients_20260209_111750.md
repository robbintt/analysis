---
ver: rpa2
title: Quotient Network -- A Network Similar to ResNet but Learning Quotients
arxiv_id: '2506.00992'
source_url: https://arxiv.org/abs/2506.00992
tags:
- network
- quotient
- resnet
- features
- should
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a quotient network as an alternative to ResNet
  that learns quotients instead of differences. The core idea is to replace residual
  learning with quotient learning, where the network learns the ratio between target
  and existing features rather than their difference.
---

# Quotient Network -- A Network Similar to ResNet but Learning Quotients

## Quick Facts
- arXiv ID: 2506.00992
- Source URL: https://arxiv.org/abs/2506.00992
- Reference count: 40
- Key outcome: Quotient Network consistently outperforms ResNet on CIFAR10, CIFAR100, and SVHN with the same architecture, achieving higher accuracy without adding parameters

## Executive Summary
This paper proposes a quotient network as an alternative to ResNet that learns quotients instead of differences. The core idea is to replace residual learning with quotient learning, where the network learns the ratio between target and existing features rather than their difference. This addresses two key limitations of ResNet: the lack of independent meaning in differences and sensitivity to feature sizes. The authors propose design rules including using a specially-designed activation function that passes through (0,1) and is globally differentiable. Experiments on CIFAR10, CIFAR100, and SVHN datasets show that the quotient network consistently outperforms ResNet with the same architecture, achieving higher accuracy without adding parameters. Visualization of feature maps demonstrates that quotient features have clearer structure than residual features.

## Method Summary
The Quotient Network modifies the ResNet architecture by replacing the residual learning mechanism (H(x) = F(x) + x) with quotient learning (H(x) = F(x) · x). This multiplicative approach learns relative scaling factors rather than absolute offsets. The network uses a custom activation function (sigmoid(x - ln(α - 1)) · α) designed to pass through (0,1), ensuring the network can trivially learn the identity mapping. The architecture requires this activation in three locations: the head convolutional layer, channel-increasing shortcut convolutions, and all quotient modules. Training uses standard SGD with momentum, batch size 128, and learning rate scheduling (0.1 → 0.01 → 0.001 at epochs 92 and 136) for 182 total epochs.

## Key Results
- Consistently outperforms ResNet on CIFAR10, CIFAR100, and SVHN with identical architectures
- Achieves higher accuracy without adding parameters compared to ResNet baselines
- Feature map visualizations show quotient features have clearer structural patterns than residual features
- The performance gap increases with network depth (e.g., 110-layer networks show larger improvements)

## Why This Works (Mechanism)

### Mechanism 1: Multiplicative Feature Refinement
Learning a quotient (ratio) between target and existing features provides more stable updates than learning an arithmetic difference, particularly for features of varying magnitudes. In standard ResNet, a block learns a residual F(x) added to input x (H(x) = F(x) + x). The Quotient Network modifies this to learn a multiplier F(x) applied to input x (H(x) = F(x) · x). Theoretically, a multiplicative update applies a relative scaling (e.g., "double the feature") regardless of whether the input is 0.1 or 10.0, whereas an additive update applies a fixed absolute shift which may dominate small inputs or be negligible for large ones. The core assumption is that feature updates are better represented as relative scaling operations rather than absolute offsets. Evidence anchors include the abstract's statement about sensitivity to feature size and physical analogies in section 1. A break condition occurs if input features contain zero values, which would annihilate the signal (0 · F(x) = 0).

### Mechanism 2: Bounded Activation for Identity Mapping
A specifically constrained activation function is required to stabilize multiplicative learning and ensure the network can trivially learn the identity mapping. The network uses a modified sigmoid function sigmoid(x - ln(α - 1)) * α. This function is designed to pass through the point (0, 1). When the unactivated input is 0 (e.g., weights are initialized small), the output multiplier is 1. Thus, the operation becomes x · 1 = x, preserving the input signal similar to how ResNet preserves it with x + 0. The core assumption is that maintaining a path for identity mapping is critical for training very deep networks. Evidence anchors include section 3.3.1's explanation of the (0,1) passing point and appendix A's empirical evidence showing accuracy drops when shifting away from this point. A break condition occurs if using standard unbounded activations (like ReLU) or those passing through (0, c) where c ≠ 1, which may cause features to explode exponentially during forward propagation or fail to propagate stable gradients.

### Mechanism 3: Semantic Feature Derivation
The quotient of two different feature types is more likely to constitute a semantically meaningful independent feature than their arithmetic difference. The paper argues via physical analogy (e.g., Density = Mass / Volume) that ratios often represent intrinsic properties. By constraining the network to learn ratios, it induces a feature space where intermediate activations represent normalized, potentially more interpretable attributes. The core assumption is that the analogy from physical units (mass, volume) translates validly to abstract CNN feature maps. Evidence anchors include section 1's physical analogy and section 4.5's visualization figures showing quotient feature maps retaining clearer structural outlines of objects compared to residual maps which appear noisier. This is a weak theoretical claim relying on inductive bias, and if features are not physically analogous (e.g., encoded one-hot vectors), the semantic benefit may vanish.

## Foundational Learning

- **Concept: Residual Learning (ResNet)**
  - **Why needed here:** This architecture is a direct modification of ResNet. Understanding that ResNet solves the vanishing gradient problem by allowing gradients to flow through "identity shortcuts" (y = x + F(x)) is necessary to understand why the paper insists on the (0,1) passing point for the multiplicative shortcut.
  - **Quick check question:** If a ResNet block learns the identity function, what is the value of its residual weights? (Answer: Near zero). What value must the Quotient Network weights produce to achieve identity? (Answer: Near 1).

- **Concept: Multiplicative Interaction / Gating**
  - **Why needed here:** The paper moves from additive interactions to multiplicative ones. Understanding how multiplication acts as a gating mechanism (controlling information flow) helps explain why the activation must be positive and bounded to prevent uncontrolled signal amplification.
  - **Quick check question:** If you multiply a feature map of value 10.0 by a quotient of 2.0, what is the result? If you repeat this layer 10 times, what happens? (Answer: 20.0, then 2^10 × 10, which explodes. This explains the need for bounded activation).

- **Concept: Saturated vs. Unsaturated Activation**
  - **Why needed here:** The paper explicitly rejects ReLU because it is unbounded (infinite saturation in positive direction). Understanding that multiplicative networks require strictly bounded outputs (saturated) to remain numerically stable is critical for the design rules.
  - **Quick check question:** Why is ReLU dangerous in a multiplicative skip connection? (Answer: ReLU outputs [0, ∞). A chain of multiplications with values >1 creates exponential explosion).

## Architecture Onboarding

- **Component map:** Input x -> Conv Block (Conv-BN-ReLU) -> Quotient Generator (Conv + Custom Activation) -> Element-wise Multiplication (x · Quotient Generator output)

- **Critical path:** The activation function implementation is the single point of failure. You cannot drop in standard ReLU or GELU. Rule 1: The final layer in the quotient block must use the bounded activation passing through (0,1). Rule 2: The "downsample/shortcut" path (when channels change) must also use this activation to maintain feature scale consistency. Rule 3: The initial head convolution (processing raw image) must use this activation to prevent large initial values from exploding in later multiplicative layers.

- **Design tradeoffs:** Stability vs. Cost: The custom activation (sigmoid-based) is computationally more expensive than ReLU. Depth vs. Alpha (α): The hyperparameter α in the activation changes with depth. Deeper networks require tighter bounds (smaller α) to remain stable. Zero Values: The architecture is brittle to zero inputs. Batch Normalization usually prevents this, but initialization schemes resulting in sparse zero-activations may fail.

- **Failure signatures:** White Noise Output: If the activation range is too large or unbounded, features explode into static/white noise. Dead Network: If inputs become 0, the output is 0. Gradients will be 0. The network cannot recover. Training Instability: If the activation does not pass through (0,1), deep networks fail to converge or show significant accuracy drops.

- **First 3 experiments:** 1. Unit Test - Stability: Verify forward pass on a random tensor. Ensure output variance is comparable to input variance (not NaN or 0). 2. Ablation - Activation: Train a shallow (20-layer) network on CIFAR10 with the custom activation vs. ReLU. Confirm ReLU fails to train or explodes. 3. Hyperparameter Scan - Alpha: For a fixed depth (e.g., 56 layers), sweep α (e.g., 1.5, 1.7, 2.0) to find the stability sweet spot before full training.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the quotient network maintain its performance advantage over ResNet on large-scale datasets like ImageNet and in transfer learning scenarios?
- Basis in paper: The conclusion states, "Due to time and hardware constraints, we did not use large-scale datasets such as ImageNet to learn and did not perform tasks such as object detection based on models pre-trained on ImageNet."
- Why unresolved: The current experiments are limited to small datasets (CIFAR10, CIFAR100, SVHN), leaving the scalability and transferability of the method unverified.
- What evidence would resolve it: Benchmark results comparing Quotient Networks against ResNets on ImageNet classification and downstream tasks like object detection.

### Open Question 2
- Question: How can quotient learning be effectively integrated into Transformer architectures that rely heavily on residual connections?
- Basis in paper: The conclusion suggests, "Since ResNet was proposed, many models have used residual learning (including transformers). Applying quotient learning to these models may also bring good performance."
- Why unresolved: The paper focuses on CNNs (ResNet); the interaction between quotient learning and mechanisms like Self-Attention (Q, K, V) or LayerNorm in Transformers is unexplored.
- What evidence would resolve it: A study implementing quotient connections within standard Transformer blocks (e.g., ViT) and evaluating the resulting convergence and accuracy.

### Open Question 3
- Question: Is there a theoretical relationship between network depth and the optimal value of the α parameter in the activation function?
- Basis in paper: Section 4.3 notes that the optimal α was found experimentally (1.8 for 44 layers, 1.5 for 110 layers), stating "the larger the number of layers, the smaller the optimal value of α," but provides no formal rule.
- Why unresolved: The selection of this critical hyperparameter relies on empirical tuning rather than a derived theoretical framework.
- What evidence would resolve it: A theoretical analysis or a formula predicting the optimal α based on network depth or initialization variance.

### Open Question 4
- Question: Can the computational overhead of the custom activation function and element-wise multiplication be reduced to match ResNet's training speed?
- Basis in paper: Section 3.5 acknowledges a limitation: "Our network has increased the calculations by a certain amount... eventually cause our network to have a longer training and prediction time than ResNet."
- Why unresolved: While the parameter count is the same, the increased latency (approx. 3-5% slower per epoch) could be a bottleneck for practical deployment.
- What evidence would resolve it: A modified architecture or hardware-optimized implementation that closes the timing gap while preserving the accuracy gains.

## Limitations
- Experimental validation limited to small-scale image classification datasets (CIFAR and SVHN) without testing on larger datasets like ImageNet
- Architecture appears brittle to zero-valued features, which could cause complete network failure
- Semantic feature derivation claim relies heavily on physical analogies that may not translate to abstract CNN feature spaces
- Computational cost of sigmoid-based activation is significantly higher than ReLU

## Confidence

- **High Confidence**: Multiplicative feature refinement mechanism and its advantages over additive updates for scale-invariant learning (supported by multiple experiments and ablation studies)
- **Medium Confidence**: Bounded activation design for identity mapping (well-supported empirically but theoretical justification could be stronger)
- **Medium Confidence**: Performance improvements over ResNet (consistent across experiments but limited to specific datasets)
- **Low Confidence**: Semantic feature derivation claim (primarily based on visualization and physical analogies without rigorous semantic validation)

## Next Checks

1. **Scale-Invariance Test**: Train both ResNet and Quotient Network on datasets with varying input normalization scales (e.g., divide pixel values by 1, 10, 100) and measure relative performance changes to verify the quotient network's scale invariance advantage.

2. **Zero-Feature Robustness**: Systematically inject zero-valued features at different layers and monitor training stability and gradient flow to characterize the brittleness to zero inputs and identify failure thresholds.

3. **Cross-Dataset Generalization**: Validate the architecture on larger-scale datasets (ImageNet) and non-image tasks (NLP, tabular data) to test whether the advantages generalize beyond the CIFAR/SVHN domain where results were demonstrated.