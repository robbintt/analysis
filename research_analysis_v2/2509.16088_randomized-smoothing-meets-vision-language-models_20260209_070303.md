---
ver: rpa2
title: Randomized Smoothing Meets Vision-Language Models
arxiv_id: '2509.16088'
source_url: https://arxiv.org/abs/2509.16088
tags:
- certified
- radius
- samples
- image
- harmful
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper extends randomized smoothing (RS) to generative models
  by introducing an oracle classifier that maps model outputs to discrete categories
  (e.g., harmful/harmless, discrete actions). This allows RS to provide formal robustness
  certificates for VLMs despite outputs being sequences rather than fixed labels.
---

# Randomized Smoothing Meets Vision-Language Models

## Quick Facts
- arXiv ID: 2509.16088
- Source URL: https://arxiv.org/abs/2509.16088
- Authors: Emmanouil Seferis; Changshun Wu; Stefanos Kollias; Saddek Bensalem; Chih-Hong Cheng
- Reference count: 35
- One-line primary result: Extends randomized smoothing to generative VLMs via oracle classification, achieving certified robustness against jailbreak attacks with 2-3 orders of magnitude fewer samples than classical RS

## Executive Summary
This paper extends randomized smoothing (RS) to generative Vision-Language Models (VLMs) by introducing an oracle classifier that maps model outputs to discrete categories (e.g., harmful/harmless, semantic equivalence classes). This reduction enables RS to provide formal robustness certificates for VLMs despite their sequence-based outputs. The authors develop a modified vote-counting scheme and prove that existing RS sampling efficiency results carry over to this setting, with performance degradation inversely proportional to the oracle's error rate. Experimental validation demonstrates certified robustness against jailbreak-style adversarial attacks with significantly reduced inference time (2.8s vs 38s) while maintaining 60% of certified radius and 90% of accuracy.

## Method Summary
The approach maps generative VLM outputs to discrete categories using an oracle classifier (e.g., another LLM that classifies text as harmful/harmless or determines semantic equivalence). This reduces the problem to standard classification RS. The certified probability lower bound is corrected for oracle classification errors while preserving soundness. The method uses batch parallelization to achieve O(n/B) sample complexity scaling. Key parameters include noise level σ=0.5, sample count n=100, and α=0.001 confidence level. The VLM generates text outputs from noisy images, the oracle classifies each output, and votes are aggregated with semantic clustering to compute certified radius via Clopper-Pearson bounds.

## Key Results
- Extends RS to VLMs via oracle-based output classification, enabling certified robustness against jailbreak attacks
- Achieves 2-3 orders of magnitude sample efficiency improvement (100 vs 1000 samples) with 60% radius retention
- Reduces inference time from 38s to 2.8s while maintaining 90% certified accuracy on MM-SafetyBench dataset
- Provides formal robustness certificates for image-based adversarial perturbations on LLaVA 1.6 7b

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Randomized smoothing can be extended to generative models by introducing an oracle classifier that maps text outputs to discrete categories.
- Mechanism: The VLM generates text sequences, which an oracle (e.g., another LLM) classifies into a finite set of categories (harmful/harmless, discrete actions, or semantic equivalence classes). This reduces the problem to standard classification RS, enabling certified robustness.
- Core assumption: The oracle has bounded error rate ε < 0.5 and outputs fall into a finite number of classes.
- Evidence anchors: [abstract] "We resolve this by connecting generative outputs to an oracle classification task and showing that RS can still be enabled"; [section 4] "This reduces the problem to binary classification, and RS can be applied"; [corpus] Weak direct corpus support; AdaptDel addresses edit distance for sequences but differs in approach

### Mechanism 2
- Claim: The certified probability lower bound can be corrected for oracle classification errors while preserving soundness.
- Mechanism: If the oracle observes count c with empirical probability q̄y, the true probability p̄y = (q̄y - ε)/(1 - 2ε). When ε is unknown but < 0.5, q̄y remains a valid (conservative) lower bound.
- Core assumption: Oracle errors flip between existing classes (e.g., harmful→harmless) rather than creating spurious new classes.
- Evidence anchors: [section 4, Theorem 4.1] Derivation shows qy = ε + py(1 - 2ε), rearranged to solve for py; [section 4, Theorem 4.2] Proves h(ε) is strictly increasing, so q̄y is valid lower bound when ε unknown; [corpus] No direct corpus precedent for this specific correction formula

### Mechanism 3
- Claim: 2-3 orders of magnitude fewer samples suffice for tight certificates compared to classical RS requirements.
- Mechanism: Analytical scaling law shows average certified radius scales as r(α,n) ≈ 1 - 1.64·z_α/√n. For typical α=0.001, using 100 samples vs. 10,000 gives ~60% of the certified radius and ~90% of certified accuracy.
- Core assumption: The distribution Pr(p_A) of majority-class probabilities is concentrated in [β, 1) with β ≥ 0.7 (mass negligible below 0.5).
- Evidence anchors: [abstract] "showing that the earlier result of 2 to 3 orders of magnitude fewer samples sufficing with minimal loss remains valid"; [section 5, Theorem 5.3] Derives radius drop formula under relaxed assumptions vs. prior work; [corpus] AdaptDel and AuditVotes address sample efficiency but via different mechanisms (deletion rates, voting)

## Foundational Learning

- **Concept: Randomized Smoothing (Lecouvreur et al., Cohen et al. 2019)**
  - Why needed here: This is the base technique the paper extends. You must understand how Gaussian noise injection + majority voting creates a smoothed classifier with provable robustness certificates.
  - Quick check question: Given majority class probability p_A = 0.75 and σ = 0.5, calculate the certified radius R using R = σ·Φ⁻¹(p_A).

- **Concept: Clopper-Pearson Confidence Intervals for Binomial Proportions**
  - Why needed here: RS uses Monte Carlo sampling to estimate p_A. The Clopper-Pearson test provides the conservative lower bound with confidence 1-α required for valid certificates.
  - Quick check question: If you observe 85 successes in 100 trials, what is the 99.9% confidence lower bound for the true probability?

- **Concept: Semantic Equivalence in LLM Evaluation (LlamaIndex-style answer checking)**
  - Why needed here: The oracle LLM must determine if two text outputs are semantically equivalent. This is non-trivial and requires understanding prompt-based equivalence checking.
  - Quick check question: How would you prompt an LLM to determine if "I cannot help with that" and "That request violates my policy" are semantically equivalent refusal responses?

## Architecture Onboarding

- **Component map:** Input layer (image x, text prompt t) → Gaussian noise injection on image only → VLM backbone generates n text outputs y₁...yₙ in parallel (batched) → Oracle layer: LLM classifies each yᵢ into discrete category (harmful/harmless OR semantic cluster) → Aggregation: Modified vote-counting (Algorithm 2) with semantic equivalence merging → Certification: Clopper-Pearson bound → corrected probability → certified radius R

- **Critical path:**
  1. Noise sampling: Generate n noisy images x'ᵢ ~ N(x, σ²I)
  2. Parallel inference: Batch all n samples through VLM (exploits full batch size B)
  3. Oracle classification: Each output → discrete category (bounded by oracle latency)
  4. Vote aggregation with semantic clustering
  5. Compute certified radius via Eq. 4 + Eq. 2

- **Design tradeoffs:**
  - σ (noise level): Higher σ → larger certified radius but lower base accuracy
  - n (sample count): More samples → tighter certificates but higher latency (reduced by batching)
  - Oracle choice: Smaller oracle (faster) vs. larger oracle (lower ε, tighter certificates)
  - Paper uses σ=0.5, α=0.001, n=100 as practical baseline (2.8s inference vs. 38s for n=1000)

- **Failure signatures:**
  - Certification abstains (returns ABSTAIN): p̄_A < 0.5 → model uncertain or misaligned
  - Very small certified radius (<0.1): Model has low robustness, consider increasing σ or retraining
  - Oracle timeout: Batch parallelization bottlenecked by oracle LLM, not VLM

- **First 3 experiments:**
  1. **Sanity check with known robust model**: Apply RS with n=1000, σ=0.5 on benign prompts. Verify certified radius matches baseline (≈0.3-0.4 per Cohen et al.). This validates your implementation.
  2. **Sample efficiency sweep**: Run n ∈ {50, 100, 500, 1000} on adversarial images from MM-SafetyBench. Plot certified radius ratio vs. n. Confirm it matches Corollary 5.4's prediction (1 - 1.64·z_α/√n).
  3. **Oracle error sensitivity**: Inject synthetic oracle errors at rates ε ∈ {0.05, 0.1, 0.2}. Compare certified radius with and without Theorem 4.1 correction. Verify conservative bound property holds.

## Open Questions the Paper Calls Out
None

## Limitations
- Oracle error rate dependency: The approach fundamentally relies on the oracle having bounded error rate ε < 0.5, with theoretical guarantees degrading as ε approaches 0.5
- Semantic equivalence challenge: Mapping generative outputs to discrete categories via semantic equivalence is non-trivial and may introduce systematic bias
- Scaling law assumptions: The 2-3 orders of magnitude sample efficiency improvement relies on specific distributional assumptions about model certainty that may not hold in practice

## Confidence
**High Confidence Claims:**
- The oracle-based reduction from generative to classification RS is theoretically sound
- Theorem 4.1 and 4.2 for error correction are mathematically rigorous
- Batch parallelization achieves O(n/B) scaling when oracle latency allows

**Medium Confidence Claims:**
- The 60% radius retention with 100 vs 1000 samples is validated on the specific VLM/oracle combination used
- The 2.8s inference time vs 38s is reproducible under the described setup
- The 90% certified accuracy retention is dataset-specific

**Low Confidence Claims:**
- Performance on VLMs other than LLaVA 1.6 7b
- Oracle error rates with alternative classification approaches
- Sample efficiency gains on non-jailbreak tasks or different VLM architectures

## Next Checks
1. **Oracle Error Rate Analysis**: Run the certification pipeline on 1000+ random benign prompts and measure the empirical oracle error rate ε. Verify that ε < 0.5 across the full dataset and that the error correction formula in Theorem 4.1 produces conservative bounds.

2. **Sample Efficiency Validation**: Perform a systematic sweep of sample counts n ∈ {10, 50, 100, 500, 1000} on adversarial images. Plot the certified radius ratio vs √n and verify it follows the predicted scaling law r(α,n) ≈ 1 - 1.64·z_α/√n from Corollary 5.4.

3. **Oracle Ablation Study**: Compare certification performance using (a) the proposed LLM oracle, (b) a simpler keyword-based classifier, and (c) no oracle (naive semantic clustering). Measure certified radius, accuracy, and oracle error rates to quantify the benefit of the sophisticated oracle approach.