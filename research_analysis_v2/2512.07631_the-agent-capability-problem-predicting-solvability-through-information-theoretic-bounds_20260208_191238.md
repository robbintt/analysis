---
ver: rpa2
title: 'The Agent Capability Problem: Predicting Solvability Through Information-Theoretic
  Bounds'
arxiv_id: '2512.07631'
source_url: https://arxiv.org/abs/2512.07631
tags:
- agent
- information
- cost
- problem
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The Agent Capability Problem (ACP) addresses the challenge of\
  \ predicting whether an autonomous agent can solve a problem within resource constraints.\
  \ The core method treats problem-solving as information acquisition, where an agent\
  \ requires Itotal bits to identify a solution and gains Is bits per action at cost\
  \ Cs, yielding an effective cost Ceffective = (Itotal/Is) \xD7 Cs that predicts\
  \ resource requirements before search."
---

# The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds

## Quick Facts
- arXiv ID: 2512.07631
- Source URL: https://arxiv.org/abs/2512.07631
- Authors: Shahar Lutati
- Reference count: 11
- Primary result: Information-theoretic bounds predict agent solvability and resource requirements before search begins

## Executive Summary
The Agent Capability Problem (ACP) addresses the challenge of predicting whether an autonomous agent can solve a problem within resource constraints. The core method treats problem-solving as information acquisition, where an agent requires I_total bits to identify a solution and gains I_s bits per action at cost C_s, yielding an effective cost C_effective = (I_total/I_s) × C_s that predicts resource requirements before search. The primary theoretical result proves that C_effective lower-bounds expected cost and provides tight probabilistic upper bounds. Experimental validation shows that ACP predictions closely track actual agent performance, consistently bounding search effort while improving efficiency over greedy and random strategies.

## Method Summary
The ACP framework predicts agent solvability by treating problem-solving as sequential information acquisition. For a given problem, it computes I_total (entropy of the goal) and estimates I_s (expected information gain per action) using a Gaussian Process surrogate model. The predicted cost C_effective = (I_total/I_s) × C_s serves as a lower bound on expected resource requirements. This prediction guides search ordering and can be used to assess feasibility before search begins. The method is validated on noisy slope identification and graph coloring problems, demonstrating consistent lower-bounding of actual costs while improving search efficiency over baseline strategies.

## Key Results
- C_effective consistently lower-bounds actual search costs across 750+ graph coloring instances
- ACP predictions improve search efficiency, achieving mean node expansions of 8-18 compared to standard greedy strategies
- Theoretical upper bounds on prediction gap (M²/μ²_inf) validated empirically, with gap increasing for larger graphs and higher edge densities

## Why This Works (Mechanism)

### Mechanism 1: Information-Theoretic Cost Prediction
- Claim: The effective cost C_effective = (I_total/I_s) × C_s predicts the minimum resources required to solve a problem before search begins.
- Mechanism: Problem-solving is reframed as sequential information acquisition. Each action reduces entropy about the goal location. Dividing total information needed (I_total) by information gained per action (I_s) yields the expected number of steps; multiplying by per-step cost gives total resource requirement.
- Core assumption: Information gains from successive actions are conditionally independent, have bounded moments, and exhibit diminishing returns (μ_1 ≥ μ_2 ≥ ... ≥ μ_inf > 0).
- Evidence anchors:
  - [abstract] "an agent requires I_total bits to identify a solution and gains I_s bits per action at cost C_s, yielding an effective cost C_effective = (I_total/I_s) × C_s that predicts resource requirements before search"
  - [Section 3.2] Theorem 3.1 proof uses optional stopping theorem on martingale M_n = S_n - Σμ_i to establish E[C] ≥ C_effective
  - [corpus] Weak corpus support; related work in information-theoretic context summarization (arXiv:2510.01620) shares mutual information framing but not the cost prediction mechanism
- Break condition: When actions are not conditionally independent or when information gains don't satisfy diminishing returns, the martingale structure underlying the bound fails.

### Mechanism 2: Lower-Bound Guarantee
- Claim: C_effective is guaranteed to be a lower bound on expected actual cost.
- Mechanism: By definition, cumulative information S_N ≥ I_total at stopping time N. The optimal strategy's expected gain per step is at most I_s, so E[N] ≥ I_total/I_s, implying E[C] ≥ C_s × (I_total/I_s) = C_effective.
- Core assumption: Finite expected stopping time exists; martingale optional stopping theorem applies.
- Evidence anchors:
  - [abstract] "The predicted cost C_effective was always less than or equal to the observed cost, validating the theoretical lower-bound guarantee"
  - [Section 4.6, Table 1] Across 750 graph coloring instances, ACP predictions (8-18) consistently ≤ observed costs
  - [corpus] No direct corpus validation of this specific guarantee
- Break condition: If expected stopping time is infinite (e.g., problem unsolvable), the bound becomes trivial/uninformative.

### Mechanism 3: Overshoot Correction
- Claim: The gap between predicted and actual cost is bounded by M²/μ²_inf where M² bounds information increment variance and μ_inf is the infimum of expected gains.
- Mechanism: Lorden's inequality for independent non-identically distributed variables bounds expected "overshoot" (excess information beyond I_total at stopping). Higher noise (larger M²) or severely diminishing returns (small μ_inf) widen the prediction gap.
- Evidence anchors:
  - [Section 3.2, Eq. 7] "E[C] ≤ C_s(I_total/μ_inf + M²/μ²_inf)"
  - [Section 4.6] "The overshoot tends to increase with graph size and edge density"
  - [corpus] No corpus papers address this overshoot mechanism
- Break condition: When μ_inf → 0 (severely diminishing returns), upper bound diverges, making predictions unreliable.

## Foundational Learning

- Concept: **Mutual Information I(X;Y)**
  - Why needed here: Core quantity I_s = I(1(θ∈Θ_goal); y|a) measures how much each action reveals about goal membership
  - Quick check question: Given a prior p(goal) = 0.5 and an action that produces outcome y such that p(goal|y) = 0.8, what is the information gain?

- Concept: **Entropy H(X)**
  - Why needed here: I_total = H(1(θ∈Θ_goal)) quantifies total uncertainty about solution location
  - Quick check question: If 10% of candidates are solutions, what is I_total? (Answer: H(Bernoulli(0.1)) ≈ 0.47 bits)

- Concept: **Optional Stopping Theorem for Martingales**
  - Why needed here: Proves E[M_N] = E[M_0] = 0, enabling the lower-bound derivation
  - Quick check question: Why must stopping time be almost surely finite for the theorem to apply?

## Architecture Onboarding

- Component map:
  - Problem encoding → Hypothesis space Θ → GP surrogate → Information estimators → Cost predictor → Action selector

- Critical path: Encode problem → Define Θ_goal → Fit GP surrogate → Estimate I_total → Estimate I_s per action → Compute C_effective → Compare to budget B

- Design tradeoffs:
  - GP kernel choice affects surrogate accuracy; misspecification propagates to cost estimates (Theorem 4.1)
  - Sample size S in Monte Carlo estimation trades computation vs. error bound (Proposition 4.1: error ∝ √(log(2/δ)/2S))
  - Using I_s (initial gain) vs. μ_inf (worst-case gain) trades optimism vs. robustness in upper bounds

- Failure signatures:
  - C_effective >> observed cost: Surrogate model severely misspecified or I_s overestimated
  - C_effective consistently violated (observed < predicted): Check independence assumption; actions may share information
  - Prediction gap growing with problem size: Diminishing returns (μ_inf << I_s) dominating; problem may be fundamentally harder than initial entropy suggests

- First 3 experiments:
  1. Replicate graph coloring validation (Table 1) on a new graph distribution to verify lower-bound holds across problem instances
  2. Vary noise σ in parameter identification task to confirm overshoot term M²/μ²_inf scaling (Figure 1 pattern)
  3. Test on inapproximable problems (ε < ρ⁻¹) to verify I_total → ∞ prediction manifests as unbounded search cost

## Open Questions the Paper Calls Out

- **Multi-agent coordination**: How can the ACP framework be extended to multi-agent coordination scenarios? The current theoretical bounds rely on a single agent's policy; coordinating agents introduce game-theoretic complexities and shared belief states not currently modeled.

- **Dynamic environments**: Does the solvability prediction hold when the problem structure or goal state changes dynamically during search? The framework assumes a static hypothesis space and goal to calculate I_total, which fails if the target moves or problem constraints shift.

- **Tighter surrogate models**: Can tighter surrogate models significantly reduce the estimation error bounds in Theorem 4.1 for specific problem classes? The paper relies on general Gaussian Process surrogates with standard RKHS error bounds, which may be loose for structured domains like graphs.

## Limitations
- Surrogate model dependency: Framework relies heavily on accurate GP surrogate modeling; kernel misspecification can propagate errors through to cost predictions
- Discrete domain challenges: Implementation details for discrete problems like graph coloring remain unclear despite theoretical applicability
- Scalability concerns: Maintaining and querying GP surrogates over large hypothesis spaces becomes computationally prohibitive for high-dimensional problems

## Confidence
- **High Confidence**: The information-theoretic formulation of problem-solving as entropy reduction is well-grounded. The lower-bound guarantee (C_effective ≤ observed cost) is mathematically proven and experimentally validated across multiple problem instances.
- **Medium Confidence**: The experimental validation on graph coloring problems demonstrates consistent lower-bounding behavior, but the discrete domain implementation details are underspecified.
- **Low Confidence**: The framework's performance on truly large-scale problems (e.g., n > 15 for graph coloring) remains unverified. The computational complexity implications of maintaining GP surrogates for high-dimensional hypothesis spaces are not thoroughly explored.

## Next Checks
1. **Extended Graph Scaling Test**: Validate the ACP framework on larger graph coloring instances (n = 20, 25, 30) with varying k and p. Track both prediction accuracy and computational overhead of GP surrogate maintenance. This will reveal scalability limits and potential need for approximation techniques.

2. **Discrete Domain Implementation Audit**: Implement ACP for graph coloring following the information-theoretic principles, but without relying on the paper's unspecified "partial constraint structure" computation. Instead, use exact entropy calculations from constraint propagation. Compare results to ensure the framework's principles hold independent of implementation details.

3. **Diminishing Returns Characterization**: Systematically vary problem parameters to create scenarios with different μ_inf/I_s ratios. Measure how prediction accuracy degrades as μ_inf → 0, and test whether the overshoot bound M²/μ²_inf provides useful guidance in these regimes. This will clarify the practical limits of the upper bound guarantee.