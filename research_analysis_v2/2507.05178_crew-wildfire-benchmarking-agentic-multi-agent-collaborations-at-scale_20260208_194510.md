---
ver: rpa2
title: 'CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale'
arxiv_id: '2507.05178'
source_url: https://arxiv.org/abs/2507.05178
tags:
- agent
- action
- agents
- your
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CREW-Wildfire is an open-source benchmark for evaluating LLM-based
  multi-agent Agentic AI systems in procedurally generated wildfire response scenarios.
  It features large maps, heterogeneous agents, partial observability, and stochastic
  dynamics.
---

# CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale

## Quick Facts
- arXiv ID: 2507.05178
- Source URL: https://arxiv.org/abs/2507.05178
- Authors: Jonathan Hyun; Nicholas R Waytowich; Boyuan Chen
- Reference count: 40
- Key outcome: Benchmark exposes significant performance gaps in LLM-based multi-agent frameworks, especially for scaling to large teams and complex coordination tasks

## Executive Summary
CREW-Wildfire is an open-source benchmark for evaluating LLM-based multi-agent Agentic AI systems in procedurally generated wildfire response scenarios. It features large maps, heterogeneous agents, partial observability, and stochastic dynamics. The benchmark includes four agent types—firefighters, bulldozers, drones, and helicopters—with flexible observation and action spaces. Built-in Perception and Execution modules interface with LLM agents for high-level reasoning and low-level control. Experiments with four state-of-the-art frameworks reveal significant performance gaps, particularly in scaling to large teams and complex tasks. Current methods handle simple coordination but struggle with spatial reasoning, adaptive planning, and efficient communication in dynamic environments. By exposing these limitations, CREW-Wildfire provides a scalable, realistic testbed for advancing next-generation multi-agent intelligence.

## Method Summary
The benchmark uses a Unity-based CREW simulation core with procedural map generation via Perlin noise for terrain, elevation, moisture, wind, and settlements. A cellular automata model propagates fire stochastically based on environmental factors. Four agent types with distinct action primitives operate under partial observability. A Perception module converts game state tensors to ASCII grids then text summaries; an Execution module translates LLM action descriptions into structured action codes and primitive behaviors. The benchmark includes 16 task levels across 12 level types, with scoring functions and behavioral goals. Four baseline frameworks (CAMON, COELA, Embodied, HMAS-2) are evaluated zero-shot using GPT-4o, with temperature=0 and single completion per step.

## Key Results
- Significant performance gaps observed across all four baseline frameworks when scaling to larger agent teams and more complex tasks
- Decentralized frameworks (COELA, Embodied) show task overlap and redundancy on large maps, with multiple agents redundantly cutting the same tree
- All frameworks struggle with Plan Adaptation (PA) and Observation Sharing (OS), scoring consistently low on these behavioral competencies
- HMAS-2 shows quadratic input token growth with agent count due to shared observation vectors, hitting context limits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The benchmark's combination of procedural generation, heterogeneous agents, and partial observability systematically exposes coordination failures in LLM-based multi-agent frameworks as team size and task complexity increase.
- Mechanism: Varied map configurations and stochastic fire dynamics require adaptive re-planning; heterogeneous agent capabilities force explicit role assignment and interdependency management; partial observability demands efficient observation sharing—all stress-tested across 16 levels with different agent counts and objectives.
- Core assumption: Coordination failures under these conditions reflect genuine limitations in current LLM-based frameworks' ability to reason about spatial, temporal, and relational structure at scale, not just implementation bugs.
- Evidence anchors:
  - [abstract] "experiments with four state-of-the-art frameworks reveal significant performance gaps, particularly in scaling to large teams and complex tasks"
  - [Section 5.2] "In larger instances, decentralized systems such as COELA and Embodied performed worse due to task overlap, with multiple agents redundantly cutting the same tree"
  - [corpus] Weak direct corpus evidence; neighbor papers focus on agentic reasoning and multi-agent coordination broadly but do not specifically validate the wildfire benchmark's stress-testing mechanism.
- Break condition: If future frameworks incorporate explicit hierarchical task decomposition with spatial-temporal reasoning modules and scalable communication protocols, the performance gaps on this benchmark should narrow significantly.

### Mechanism 2
- Claim: The Perception module (ASCII + text summarization) enables LLM agents to operate in high-dimensional, partially observable environments by compressing local observations into semantically meaningful descriptions.
- Mechanism: Raw game state tensors are converted to ASCII grid representations centered on each agent, then summarized into natural language observations describing terrain, fire, civilians, and other agents in relative spatial terms.
- Core assumption: The ASCII+summary pipeline provides sufficient spatial and semantic information for high-level planning while filtering out irrelevant detail, and is more reliable than direct VLM processing of game frames.
- Evidence anchors:
  - [Section 3.3.1] "We have observed that our Perception module can provide accurate and reliable observational information to the LLM agents"
  - [Appendix A.15] Ablation study showing the perception module outperforms GPT-4o VLM on fire and civilian detection accuracy
  - [corpus] No direct corpus validation of this specific perception design; neighbor papers discuss multi-agent coordination without this ASCII-based perception pattern.
- Break condition: If VLMs improve significantly in fine-grained spatial reasoning from raw images, or if alternative state representations (e.g., graph-based) prove more effective, the ASCII-based perception could become suboptimal.

### Mechanism 3
- Claim: The Execution module bridges high-level natural language plans to low-level control primitives, enabling LLM agents to act in continuous, dynamic environments despite their known weakness in fine-grained control.
- Mechanism: LLM-generated action descriptions are parsed into structured action codes with coordinates and parameters, which then trigger multi-step primitive behaviors (e.g., "move to location" involves repeated movement commands).
- Core assumption: Decomposing control into language-described high-level actions plus deterministic low-level primitives is sufficient for meaningful evaluation of coordination and planning, even if real-world control would require more sophisticated policies.
- Evidence anchors:
  - [Section 3.3.1] "Our Execution module uses LLMs to translate natural language commands into a series of one or more executable action codes"
  - [Section 3.3.1] "given that our core environment requires precise, discrete and continuous control, we developed our own built-in Execution module"
  - [corpus] Neighbor paper "Orchestrator" mentions similar execution/coordination separation but in different task domains; no direct validation of this specific execution module design.
- Break condition: If future work shows that tighter integration of perception, planning, and control (e.g., end-to-end learned policies) significantly outperforms this modular approach on the same benchmark, the design choice becomes questionable.

## Foundational Learning

- Concept: Partial observability
  - Why needed here: Each agent only sees a local window of the map; coordinating to share observations and build shared situational awareness is core to the benchmark's challenge.
  - Quick check question: If all agents had full map visibility at every step, which behavioral goals (e.g., Observation Sharing, Spatial Reasoning) would become trivial?

- Concept: Heterogeneous agent capabilities
  - Why needed here: Firefighters, bulldozers, drones, and helicopters have different action sets; effective teams must assign tasks based on each agent's strengths and coordinate complementary actions.
  - Quick check question: Why would a homogeneous team of only firefighters likely perform worse on "Transport Firefighters" and "Scout Fire" tasks?

- Concept: Stochastic dynamics and long-horizon planning
  - Why needed here: Fire spreads probabilistically based on wind, slope, and moisture; plans must be revised as conditions change over extended time horizons.
  - Quick check question: If fire spread were deterministic and known in advance, which failure mode (e.g., Plan Adaptation failures) would become less frequent?

## Architecture Onboarding

- Component map:
  Unity-based CREW simulation core -> Procedural map generator (Perlin noise for terrain, elevation, moisture, wind, settlements) -> Cellular automata fire propagation model -> Four agent types (firefighters, bulldozers, drones, helicopters) with action primitives -> Perception module: state tensor → ASCII grid → text summary -> Execution module: text action → action code → primitive execution -> Benchmarking suite: 16 task levels across 12 level types, with scoring functions and behavioral goals -> Baseline framework adapters for CAMON, COELA, Embodied, HMAS-2

- Critical path:
  1. Choose task level and seed → map generated
  2. For each timestep: each agent gets observations → perception module generates text → framework generates action → execution module translates → primitives execute → environment updates → score computed
  3. Trajectory ends when max score reached or time limit hit

- Design tradeoffs:
  - Realism vs. abstraction: agent roles and physics are simplified for controlled benchmarking, limiting direct real-world deployment but enabling repeatable evaluation
  - Scalability vs. token cost: supporting 2000+ agents is feasible computationally, but current frameworks' token usage scales poorly (especially HMAS-2's quadratic input token growth)
  - Modularity vs. integration: separate perception/execution modules ease framework integration but may lose optimization opportunities from end-to-end training

- Failure signatures:
  - Task overlap: multiple agents assigned to same target (decentralized frameworks on large maps)
  - Communication noise: vague, repetitive messages without convergence on concrete plans
  - Rigid adherence to outdated plans: not adapting when fire spreads or new civilians discovered
  - Token blowup: input tokens growing quadratically with agent count, hitting context limits

- First 3 experiments:
  1. Run all four baseline frameworks on "Cut Trees: Sparse (small)" to verify correct integration and reproduce near-ceiling performance (all frameworks should score ~18/18).
  2. Run same frameworks on "Cut Trees: Sparse (large)" and compare task overlap incidents; log all inter-agent communications to identify coordination failure patterns.
  3. Run "Suppress Fire: Locate and Suppress" with modified perception module (provide full-map ground truth instead of partial observations) to isolate the contribution of partial observability to failure rates.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What communication architectures can efficiently manage information flow as agent populations scale beyond dozens of agents without incurring quadratic token costs?
- Basis in paper: [explicit] The Outlook section states: "More scalable communication architectures are needed to manage information flow as agent populations grow, such as hierarchical or attention-based routing."
- Why unresolved: Current frameworks show input token usage in HMAS-2 growing quadratically with agent count due to shared observation vectors, making universal context sharing infeasible for large environments.
- What evidence would resolve it: A framework demonstrating sub-quadratic token scaling while maintaining or improving coordination performance on large-scale CREW-Wildfire tasks.

### Open Question 2
- Question: How can LLM-based multi-agent systems improve Plan Adaptation (PA) to dynamically revise strategies when environmental conditions change unexpectedly?
- Basis in paper: [inferred] The behavioral analysis shows Plan Adaptation scores remain consistently low across all baselines (CAMON: 0.239, COELA: 0.093), with agents "reaffirming early decisions" and persisting in "outdated trajectories" rather than adapting.
- Why unresolved: The paper documents that when fire lines breach established boundaries, agents fail to update plans and are often destroyed by new dangers.
- What evidence would resolve it: Improved PA scores on Suppress Fire tasks where agents successfully modify trajectories in response to fire spread changes.

### Open Question 3
- Question: What mechanisms enable effective observation sharing in decentralized multi-agent systems operating under partial observability?
- Basis in paper: [inferred] The BCS analysis reveals COELA scores significantly lower (0.067) on Observation Sharing than other frameworks, suggesting "dynamic communication may help planning" but "periodic communication phases... are better suited for regular observation sharing."
- Why unresolved: The tradeoff between continuous and periodic communication for observation sharing remains unclear, with no framework excelling at OS.
- What evidence would resolve it: A framework achieving OS scores above 0.3 while maintaining competitive performance on other behavioral competencies.

## Limitations
- Code availability: Core benchmark code and Unity platform stated as "will be released" but not available at time of review
- Scalability assumptions: Claims about supporting 2000+ agents extrapolated from experiments with only up to 16 agents
- Single LLM dependency: All results dependent on GPT-4o capabilities rather than being framework-agnostic

## Confidence
- High confidence: Benchmark design principles and 16-level evaluation protocol are well-specified; performance gaps are internally consistent
- Medium confidence: Mechanisms for exposing coordination failures are logically sound but lack direct corpus validation; perception module ablation is internally documented
- Low confidence: Execution module effectiveness is asserted rather than empirically validated; neighbor papers don't directly support this design choice

## Next Checks
1. **Full codebase release validation**: Upon code release, verify that the procedural map generator produces maps matching specifications in Table 9 and that the cellular automata fire model behaves consistently with paper descriptions.

2. **Perception module ablation**: Implement and evaluate an alternative perception module using direct VLM processing of game frames, comparing fire detection accuracy and communication token efficiency against ASCII-based approach.

3. **Framework token scaling analysis**: Extend evaluations to larger agent counts (e.g., 32+ agents) to empirically verify claimed token blow-up patterns, particularly quadratic scaling in HMAS-2, and measure actual context window impacts.