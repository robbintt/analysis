---
ver: rpa2
title: 'MUPAX: Multidimensional Problem Agnostic eXplainable AI'
arxiv_id: '2507.13090'
source_url: https://arxiv.org/abs/2507.13090
tags:
- mupax
- image
- classification
- performance
- gradcam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MUPAX, a deterministic, model-agnostic XAI
  method with guaranteed convergence. MUPAX uses structured perturbation analysis
  to attribute feature importance, identifying the most informative input patterns
  while eliminating spurious relationships.
---

# MUPAX: Multidimensional Problem Agnostic eXplainable AI

## Quick Facts
- arXiv ID: 2507.13090
- Source URL: https://arxiv.org/abs/2507.13090
- Reference count: 16
- Primary result: Deterministic, model-agnostic XAI method with guaranteed convergence that improves model accuracy by removing spurious correlations

## Executive Summary
MUPAX is a novel explainable AI method that uses structured perturbation analysis to attribute feature importance across multiple data modalities. Unlike traditional XAI techniques that often decrease model performance when masking, MUPAX uniquely enhances accuracy by identifying and removing noisy or non-generalizable features. The method employs rejection sampling with error-based weighting to generate explanations that converge almost surely to the true expectation, providing both theoretical guarantees and practical performance improvements across 1D audio, 2D images, 3D volumes, and landmark detection tasks.

## Method Summary
MUPAX partitions input data into chunks and generates random selection vectors (masks) via stratified uniform sampling. It evaluates the frozen model on masked inputs, accepting only those samples where the error falls below a threshold W. The final explanation is the weighted average of accepted chunks, weighted by inverse error (1/(μ+1)). This process is mathematically guaranteed to converge by the Strong Law of Large Numbers when applied to bounded, non-negative inputs. The method is validated across multiple modalities including audio (GTZAN), 2D images (Cats vs. Dogs), 3D volumes (MosMed CT), and landmark detection (CephAdoAdu), consistently outperforming state-of-the-art XAI techniques.

## Key Results
- 2D classification: F1-score improved from baseline 0.93 to MUPAX 0.95
- 3D classification: F1-score improved from baseline 0.82 to MUPAX 0.88
- Landmark detection: Radial error reduced from 13.8px to 9.3px
- Method converges almost surely across any dimension with arbitrary loss functions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** MUPAX identifies essential features by retaining only input chunks that consistently yield low model error during randomized masking.
- **Mechanism:** The method partitions input data into chunks and utilizes rejection sampling. It generates random selection vectors (masks), feeds the masked inputs to a frozen model, and computes a user-defined error. Only samples where the error μ(X_s) ≤ W (a threshold) are accepted. The final explanation is the weighted average of these "winning" chunks, weighted by inverse error (1/(μ+1)).
- **Core assumption:** Features crucial for the model's decision will consistently appear in subsets that maintain high performance (low error), whereas spurious correlations will not consistently survive the rejection filter.
- **Evidence anchors:**
  - [abstract] "measure theoretic formulation gives principled feature importance attribution through structured perturbation analysis that discovers inherent input patterns..."
  - [section 3.1] "Samples are generated via rejection sampling... accept s_i if μ(X_{s_i}) ≤ W."
  - [corpus] Corpus papers discuss general XAI comparisons (e.g., LIME vs. Grad-CAM) but do not contain specific technical details on MUPAX's rejection sampling loop.
- **Break condition:** If the threshold W is set too strictly (too low), the acceptance probability p_W approaches zero, causing the sampling process to stall or fail to find sufficient valid samples.

### Mechanism 2
- **Claim:** Theoretical convergence of the explanation is guaranteed by the Strong Law of Large Numbers (SLLN) applied to the bounded sampling process.
- **Mechanism:** MUPAX frames explanation as an expectation problem E[μ' X']. Because the input values are bounded (X ≥ 0) and the inverse-error weights are bounded (μ' ≤ 1), the sample average of the accepted masked inputs converges almost surely to the true expectation as the sample size n → ∞.
- **Core assumption:** The underlying model and loss function are static (frozen) and the input domain is non-negative, ensuring the boundedness required for the proof.
- **Evidence anchors:**
  - [abstract] "...MUPAX, a deterministic, model-agnostic explainability technique, with guaranteed convergency."
  - [appendix a] "Boundedness implies that the expectation... is finite... the Strong Law of Large Numbers (SLLN) applies directly."
  - [corpus] No direct corpus support for MUPAX's specific measure-theoretic proof; related papers focus on application surveys.
- **Break condition:** Convergence fails to be "almost sure" if the sample size n is insufficient to approximate the expectation, resulting in high variance (noisy explanations).

### Mechanism 3
- **Claim:** Masking the input to retain only MUPAX-identified features improves model accuracy by functioning as a deterministic noise filter.
- **Mechanism:** Unlike gradient methods which might highlight noisy activations, MUPAX explicitly removes chunks that do not positively contribute to lowering the loss. When the input is reconstructed using only the high-saliency chunks, distracting features (spurious correlations) are physically removed, effectively regularizing the input to match the model's "ideal" view.
- **Core assumption:** The "frozen" model has learned robust features alongside spurious ones, and can perform better if the spurious inputs are masked out.
- **Evidence anchors:**
  - [abstract] "By contrast with other XAI methods that typically decrease performance when masking, MUPAX not only preserves but actually enhances model accuracy..."
  - [section 5] "It inherently identifies and removes noisy or non-generalizable features... their removal acts as a form of post-hoc regularization."
  - [corpus] Corpus papers (e.g., "A Comparative Study of Explainable AI Methods") verify that standard methods like Grad-CAM often suffer in fidelity, supporting the need for methods like MUPAX, though they do not validate MUPAX specifically.
- **Break condition:** If the model relies heavily on context (e.g., background objects essential for classification), aggressive masking based on the "primary" object might drop F1-scores by removing necessary contextual cues.

## Foundational Learning

- **Concept: Rejection Sampling**
  - **Why needed here:** MUPAX relies on accepting or rejecting masked inputs based on a loss threshold W. Understanding how W affects the acceptance rate p_W is critical for managing computational cost.
  - **Quick check question:** If you tighten the error threshold W to the 5th percentile, what happens to the number of total samples N_total required to generate n accepted explanations?

- **Concept: Measure Theory & Convergence**
  - **Why needed here:** The paper claims "guaranteed convergence" (a major differentiator). Distinguishing between heuristic stability and mathematical convergence requires grasping the concept of almost sure convergence vs. probability limits.
  - **Quick check question:** Does the MUPAX theorem guarantee finding the *global* optimal explanation, or just that the estimation error reduces to zero as samples increase?

- **Concept: Perturbation-based XAI**
  - **Why needed here:** MUPAX is a perturbation method (like LIME/SHAP) but structured differently. Knowing the trade-offs (model-agnosticism vs. computational cost) relative to gradient methods (Grad-CAM) contextualizes where to deploy MUPAX.
  - **Quick check question:** Why is a perturbation-based method inherently more parallelizable than a sequential gradient integration method like Integrated Gradients?

## Architecture Onboarding

- **Component map:** Chunker -> Sampler -> Evaluator (Oracle) -> Aggregator
- **Critical path:** The Evaluator loop. The system must perform N_MUPAX forward passes. While parallelizable, this is the bottleneck.
- **Design tradeoffs:**
  - **Granularity vs. Compute:** Smaller chunks (fine-grained explanation) exponentially increase the search space, requiring more samples for convergence.
  - **Strictness (W) vs. Speed:** Lower W (stricter error tolerance) yields cleaner explanations but lowers acceptance probability, increasing wall-clock time.
- **Failure signatures:**
  - **Empty Explanations:** Threshold W is too strict; no samples pass the filter.
  - **Explanation Drift:** Low sample count (n) causes χ_n to fluctuate significantly between runs (violating the practical benefit of determinism).
  - **Memory Overflow:** Attempting to batch process massive 3D volumes with large batch sizes to maximize parallelism.
- **First 3 experiments:**
  1. **Threshold Sensitivity:** Run MUPAX on a validation set while sweeping W (e.g., 10th to 50th percentile of loss) to plot the curve of F1-score improvement vs. runtime.
  2. **Chunk Size Ablation:** Compare explanation quality (visual coherence) using 8×8 vs 16×16 vs 4×4 patches on 2D images to find the "resolution" sweet spot.
  3. **Convergence Check:** Fix an input and plot the variance of the saliency map as sample size n increases to empirically verify the convergence rate claimed in the theorem.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can MUPAX be adapted for semantic segmentation tasks without incurring prohibitive computational costs?
- Basis in paper: [explicit] The authors identify semantic segmentation as a "notable omission" due to dense per-pixel output and overlap-based metrics (IoU, Dice) leading to discontinuous regions and increased costs.
- Why unresolved: Current chunking strategies optimized for classification/landmark detection may not efficiently handle dense prediction maps where retained regions are highly fragmented.
- What evidence would resolve it: A modified MUPAX framework applied to segmentation datasets that maintains competitive Dice/IoU scores while demonstrating a manageable computational complexity relative to the baseline.

### Open Question 2
- Question: What theoretical or empirical mechanisms drive the observed improvement in model accuracy (e.g., F1-scores) when using MUPAX-filtered inputs?
- Basis in paper: [explicit] The discussion notes that MUPAX acts as a "post-hoc regularization," but admits "Further investigation is needed to fully understand this effect."
- Why unresolved: While the paper demonstrates that removing spurious correlations improves performance, the precise dynamics of how perturbation-based masking enhances the frozen model's decision boundary are not fully formalized.
- What evidence would resolve it: A theoretical analysis or ablation study isolating the specific noise-reduction properties of MUPAX that explicitly links the removal of specific input patterns to the observed boost in classification metrics.

### Open Question 3
- Question: How can the computational overhead of MUPAX's perturbation sampling be reduced while maintaining explanation quality?
- Basis in paper: [explicit] The paper concludes that "Future work will focus on creating computationally effective approximations to reduce perturbation overhead."
- Why unresolved: The current method requires a large number of forward passes (N_MUPAX), and while parallelizable, the absolute computational cost remains the method's "main limitation."
- What evidence would resolve it: The development of an approximation algorithm (e.g., early stopping criteria or adaptive sampling) that significantly lowers runtime without statistically significant deviation from the convergence guarantees or attribution fidelity of the full sampling method.

## Limitations

- The method requires 2000+ forward passes per sample, creating significant computational overhead despite parallelization capabilities
- Two critical implementation details remain unspecified: the stratified sampling strategy and the precise method for converting continuous saliency maps to binary masks
- The "guaranteed convergence" claim relies on measure-theoretic assumptions that may not hold for all model architectures or non-convex loss functions

## Confidence

- **High Confidence:** The theoretical convergence proof based on the Strong Law of Large Numbers (SLLN) and the core rejection sampling mechanism are well-founded mathematically. The reported performance improvements (F1-score increases from 0.93 to 0.95 for 2D, 0.82 to 0.88 for 3D) are specific and measurable.
- **Medium Confidence:** The claim that MUPAX "enhances" model accuracy by removing spurious features is supported by the ablation study (section 5) but requires careful implementation of the mask thresholding to verify. The computational cost estimate (seconds per sample with parallelization) is reasonable but depends heavily on hardware configuration.
- **Low Confidence:** The method's effectiveness across truly arbitrary dimensions and loss functions is asserted but not exhaustively validated. The paper's focus on classification and landmark detection leaves uncertainty about performance on regression or reinforcement learning tasks.

## Next Checks

1. **Convergence Rate Validation:** Fix an input sample and systematically increase the number of MUPAX samples (n=100, 500, 1000, 2000). Plot the variance of the resulting saliency maps to empirically verify the "guaranteed convergence" claim—the variance should decrease and stabilize as n increases.

2. **Threshold Sensitivity Analysis:** Reproduce the performance boost (F1-score improvement) while varying the acceptance threshold W from the 10th to 50th percentile of initial errors. This will quantify the tradeoff between explanation quality and computational cost, revealing if the 20th percentile is truly optimal.

3. **Generalization Across Modalities:** Apply MUPAX to a held-out modality or task (e.g., a simple regression problem or a different dataset within the same modality, like Dogs vs. Wolves instead of Cats vs. Dogs). Verify that the performance enhancement and convergence properties hold outside the specifically reported experiments.