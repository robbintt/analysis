---
ver: rpa2
title: Evaluating Parameter-Based Training Performance of Neural Networks and Variational
  Quantum Circuits
arxiv_id: '2504.07273'
source_url: https://arxiv.org/abs/2504.07273
tags:
- vqcs
- quantum
- training
- learning
- times
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares neural networks (NNs) and variational quantum
  circuits (VQCs) on supervised and reinforcement learning tasks, focusing on parameter
  efficiency and training performance. The authors conducted an exhaustive grid search
  over model-based hyperparameters to identify pairs of NNs and VQCs with comparable
  performance but different parameter counts.
---

# Evaluating Parameter-Based Training Performance of Neural Networks and Variational Quantum Circuits

## Quick Facts
- arXiv ID: 2504.07273
- Source URL: https://arxiv.org/abs/2504.07273
- Reference count: 38
- Primary result: VQCs can match NNs in performance while using significantly fewer parameters but require substantially longer training times.

## Executive Summary
This study compares neural networks (NNs) and variational quantum circuits (VQCs) on supervised and reinforcement learning tasks, focusing on parameter efficiency and training performance. Through exhaustive grid search over hyperparameters, the authors identified pairs of NNs and VQCs with comparable performance but different parameter counts. Experiments were primarily conducted on simulators, with selected circuits executed on real quantum hardware to approximate training times. Results show VQCs achieve similar performance to NNs using 37.6-62.7% fewer parameters in supervised learning and up to 63.4% fewer in reinforcement learning, but require 26-457 times longer training times on simulators.

## Method Summary
The study employed a grid search methodology comparing NNs (fully connected, ReLU activation, softmax output) against VQCs (Angle or Amplitude embedding, data re-uploading, parameterized rotation gates, and CNOT entanglement) on three supervised classification tasks (Iris, Wine, WDBC) and one reinforcement learning task (custom 4x4 Frozen Lake). For supervised learning, both architectures were trained for 50 epochs using Adam optimizer with learning rate 0.01, batch size 8, and 75/12.5/12.5 train/validation/test splits. The RL task used 500 episodes with batch size 16, replay memory of 1000, and epsilon-greedy exploration. Performance was evaluated based on test accuracy/reward while comparing parameter counts and wall-clock training times, with real hardware execution on IBM Quantum devices used to validate simulator-based timing projections.

## Key Results
- VQCs achieved comparable performance to NNs while using 37.6-62.7% fewer parameters in supervised learning tasks
- In reinforcement learning, VQCs used up to 63.4% fewer parameters than NNs for similar performance
- VQC training times were 26-457 times slower than NNs on simulators, with real hardware execution being even longer
- VQCs often converged faster in accuracy early in training but the fixed training schedule didn't exploit this advantage

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Variational Quantum Circuits (VQCs) can achieve comparable task performance to Neural Networks (NNs) using significantly fewer trainable parameters.
- **Mechanism:** VQCs map data into a high-dimensional Hilbert space where quantum gates (rotations and entanglements) manipulate state amplitudes. This allows a single variational layer to represent complex correlations that might require multiple dense layers in a classical NN, effectively trading parameter count for quantum state complexity.
- **Core assumption:** The quantum state preparation and entanglement provide sufficient expressibility to approximate the target function without the depth required by classical matrix multiplications.
- **Evidence anchors:**
  - [abstract] "VQCs can match NNs in performance while using significantly fewer parameters..."
  - [section 5.4] Table 5 shows VQCs using 37-63% fewer parameters to reach comparable accuracy/reward.
  - [corpus] Neighbors like "Formal Verification of Variational Quantum Circuits" suggest VQCs share aspects with deep NNs but differ in vulnerability and structure.
- **Break condition:** If the task requires deep hierarchical feature extraction where entanglement offers no advantage over sequential classical layers, the parameter efficiency may vanish or invert.

### Mechanism 2
- **Claim:** Repeated data encoding (data re-uploading) enhances the effective capacity of low-qubit circuits.
- **Mechanism:** Instead of processing input once, the architecture re-encodes the classical input $U(x)$ before every variational layer $U_l(\theta_l)$. This repeatedly projects the quantum state relative to the input, allowing a shallow circuit depth to approximate non-linear functions that would otherwise require more qubits or deeper circuits.
- **Core assumption:** The repeated injection of input data prevents the quantum state from evolving into a subspace independent of the input, maintaining sensitivity to features throughout the circuit depth.
- **Evidence anchors:**
  - [section 3.2] "We also use data re-uploading... which embeds the classical input values before every variational layer."
  - [section 5.1] VQCs with few layers (e.g., Iris VQC-28) converge quickly relative to NNs.
  - [corpus] "Investigating the Lottery Ticket Hypothesis for Variational Quantum Circuits" implies specific sub-circuits (structures) drive performance, similar to how re-uploading structures the data flow.
- **Break condition:** If the input encoding gates conflict with the prior variational layer's rotations (effectively "uncomputing" progress), training stability degrades.

### Mechanism 3
- **Claim:** Training time inefficiency in VQCs is currently driven by simulation overhead and hardware latency rather than parameter count.
- **Mechanism:** While VQCs have fewer parameters, simulating quantum statevectors classically scales exponentially with qubits. On real hardware, queue times and shot counts (1024 shots per circuit) dominate. The "parameter efficiency" reduces the optimization search space but does not reduce the wall-clock time per optimization step.
- **Core assumption:** The simulation bottleneck (statevector calculation) is the primary time sink in the software stack, and hardware latency is a temporary constraint of NISQ devices.
- **Evidence anchors:**
  - [abstract] "...despite longer training durations."
  - [section 5.3] Table 3 shows simulation times are fast but real hardware execution adds a massive multiplier (up to 28x slower per circuit in this setup).
  - [section 5.4] "Simulator-based training being 26 to 457 times slower than the NNs."
  - [corpus] Corpus signals regarding "Simulation of quantum computers" highlight acceleration opportunities, reinforcing that simulation is the bottleneck.
- **Break condition:** If specialized hardware (QPU) improves latency and shot requirements drop (via better error mitigation), the training time ratio could invert.

## Foundational Learning

- **Concept: Hilbert Space & Amplitude/Angle Embedding**
  - **Why needed here:** To understand Section 3.2 (State Preparation). You must grasp how classical vectors (e.g., Iris features) map to quantum statesâ€”either as rotation angles (Angle Embedding) or probability amplitudes (Amplitude Embedding).
  - **Quick check question:** Does Amplitude Embedding require more or fewer qubits than Angle Embedding for the same data dimension? (Answer: Fewer, it uses $\log_2(D)$ vs $D$).

- **Concept: Expectation Values as Model Output**
  - **Why needed here:** The paper measures Pauli-Z expectation values $\langle Z \rangle$ to derive predictions (Section 3.2). Understanding that a quantum measurement yields a probabilistic average (necessitating "shots") is vital for debugging training noise.
  - **Quick check question:** Why is a "scaling parameter" added to the output of the VQC? (Answer: To map the fixed range $[-1, 1]$ of Pauli-Z expectation to the dynamic range required by the loss function).

- **Concept: Hybrid Quantum-Classical Loop**
  - **Why needed here:** The training process (Section 4) is not fully quantum. The VQC executes on a QPU/Simulator, but the optimizer (Adam) and loss calculation run classically.
  - **Quick check question:** Where does the backpropagation happen in this architecture? (Answer: Implicitly or explicitly on the classical side, using gradients computed via finite differences or parameter-shift rules derived from circuit measurements).

## Architecture Onboarding

- **Component map:** Input Vector $x$ -> Embedding $U(x)$ -> (Variational Layer + Re-encoding $U(x)$) x $L$ times -> Pauli-Z Measurement -> Scaling + Softmax
- **Critical path:** The interaction between the variational layers and data re-uploading. If the entanglement structure (CNOTs) does not correlate qubits effectively, the re-uploaded data is processed in isolation, reducing the circuit to independent single-qubit regressors.
- **Design tradeoffs:**
  - **Angle vs. Amplitude Embedding:** Angle embedding is shallower (faster) but requires $N$ qubits for $N$ features. Amplitude embedding requires only $\log N$ qubits but creates very deep circuits (slow simulation/hardware).
  - **Parameter Count vs. Shots:** Lower parameters help optimization but do not reduce the need for sufficient measurement shots to stabilize the gradient signal.
- **Failure signatures:**
  - **Barren Plateaus:** Gradients vanishing to zero (mentioned in Sec 2.2 context). Likely in random circuits with deep depth.
  - **Simulator Wall-Time Explosion:** If using Amplitude embedding for high-dimensional data (e.g., WDBC), simulation time explodes (Table 4 shows WDBC taking 2482s vs Wine at 313s).
  - **Probability Saturation:** Softmax outputs becoming uniform due to $\langle Z \rangle$ bias being too small or measurement noise drowning out the signal.
- **First 3 experiments:**
  1. **Baseline Grid Search (SL):** Run the Iris grid (Sec 4.1) for NNs to establish a baseline parameter count vs. accuracy curve.
  2. **Embedding Ablation (VQC):** Train identical VQCs on Iris using Angle vs. Amplitude embedding to measure the trade-off in training time vs. convergence speed on a 4-qubit circuit.
  3. **Hardware Calibration:** Execute the "Iris VQC-28" circuit (Table 3) on the simulator vs. real hardware (IBMQ) to verify the "Real Hardware Ratio" (approx 29x) for a single batch, validating the paper's timing projection method.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can VQCs maintain their parameter efficiency and match NN performance when applied to significantly more complex, high-dimensional machine learning tasks?
- Basis in paper: [explicit] The authors state it "remains unclear whether VQCs can scale effectively to complex tasks" and suggest future work should "assess more complex tasks to deepen our understanding."
- Why unresolved: The study was limited to simple datasets (Iris, Wine) and a basic 4x4 grid environment (Frozen Lake), whereas modern NNs handle millions of parameters.
- What evidence would resolve it: A comparative study on complex benchmarks (e.g., image classification with CIFAR-100 or continuous control in MuJoCo) showing VQCs achieving parity with NNs using fewer parameters.

### Open Question 2
- Question: How many measurement shots are required on noisy intermediate-scale quantum (NISQ) hardware to achieve prediction reliability comparable to noise-free simulations?
- Basis in paper: [explicit] The paper notes that real-hardware tests "did not analyze circuit outputs or noise effects" and suggests subsequent studies "determine how many shots are needed for reliable predictions on noisy hardware."
- Why unresolved: The authors approximated hardware training times using fixed shots (1024) and did not evaluate the trade-off between noise, shot count, and model fidelity.
- What evidence would resolve it: Empirical data plotting model accuracy against varying shot counts on real quantum devices versus noise-free simulators.

### Open Question 3
- Question: To what extent can specialized optimizers or early stopping mechanisms bridge the training time gap between VQCs and NNs?
- Basis in paper: [inferred] The authors note that VQCs often converge faster in accuracy early in training, but the "fixed training schedule does not exploit early convergence," and suggest "specialized VQC optimizers" may reduce time ratios.
- Why unresolved: The experiments utilized a standard training loop (Adam optimizer, fixed epochs) originally designed for classical NNs, potentially masking efficiency gains available through quantum-aware training protocols.
- What evidence would resolve it: Experiments comparing standard Adam optimization against quantum-aware optimizers (e.g., SPSA) or adaptive stopping criteria for VQCs.

## Limitations
- Most timing measurements were based on simulator execution rather than real quantum hardware, limiting practical relevance
- The reinforcement learning task used a simplified 4x4 grid environment that may not represent real-world complexity
- The grid search methodology may have introduced selection bias by only comparing the best-performing pairs

## Confidence
- **High confidence** in VQC parameter efficiency for supervised learning tasks based on clear empirical evidence
- **Medium confidence** in the mechanism explanations for quantum advantage through Hilbert space mapping and entanglement
- **Medium confidence** in training time analysis due to limited real hardware validation and timing projections

## Next Checks
1. Replicate the Iris classification grid search to verify the 50x training slowdown ratio on standard simulators
2. Execute the VQC-28 circuit on real quantum hardware to validate the 29x timing multiplier projection
3. Test the data re-uploading mechanism's effectiveness by comparing circuits with and without repeated encoding on a fixed dataset