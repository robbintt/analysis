---
ver: rpa2
title: Non-Adaptive Adversarial Face Generation
arxiv_id: '2507.12107'
source_url: https://arxiv.org/abs/2507.12107
tags:
- attack
- adversarial
- face
- images
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a non-adaptive adversarial face generation method
  that leverages the structural properties of face recognition system (FRS) feature
  spaces. The authors discovered that individuals sharing the same attribute (e.g.,
  gender or race) form attributed subspheres within the FRS feature space.
---

# Non-Adaptive Adversarial Face Generation

## Quick Facts
- arXiv ID: 2507.12107
- Source URL: https://arxiv.org/abs/2507.12107
- Authors: Sunpill Kim; Seunghun Paik; Chanwoo Hwang; Minsu Kim; Jae Hong Seo
- Reference count: 40
- Primary result: 93%+ ASR against AWS CompareFaces with single 100-image batch query

## Executive Summary
This paper presents a non-adaptive adversarial face generation method that exploits geometric properties of face recognition system feature spaces. The authors discovered that facial images sharing semantic attributes form attributed subspheres within the FRS feature space. By projecting target facial feature vectors onto these subspheres, the method generates synthetic adversarial faces that are visually distinct yet recognized as the target identity by the FRS. Unlike iterative optimization-based approaches, this method eliminates the need for repeated adaptive queries or reliance on transferability, making it more efficient and practical for attacking commercial FRSs.

## Method Summary
The attack projects target features onto attributed subspheres derived from PCA on attribute-labeled local features, then reconstructs adversarial faces using an inverse model. A correction matrix aligns the black-box API scores with the local subspace. The method requires exactly 100 basis images queried in a single batch (5,050 pairwise queries plus 100 target comparisons) to achieve high ASR without iterative refinement.

## Key Results
- 93.87% Attack Success Rate at default threshold (τ=0.8) on AWS CompareFaces
- Single non-adaptive query of 100 face images required
- Correction matrix improves ASR from 69.33% to 93.87% for male attribute
- High ASR maintained across different race attributes (White, Black, Asian)

## Why This Works (Mechanism)

### Mechanism 1: Attributed Subsphere Projection
The attack exploits the observation that facial images sharing semantic attributes cluster into k-dimensional subspheres within the normalized feature space of metric-learning-based FR models. PCA on attribute-labeled feature sets yields principal components spanning an approximately spherical subspace. Projecting arbitrary feature vectors onto this subsphere via pseudo-inverse yields vectors that retain the target attribute and remain within recognition threshold of the original identity due to bounded angular distance.

### Mechanism 2: Correction Matrix for Cross-Model Score Alignment
A correction matrix R computed from pairwise similarity queries aligns the local FR model's representation with the black-box target's scoring behavior. Querying all k×k pairs among basis images against the target API constructs R, which compensates for the difference between the pseudo-inverse and identity basis interpolation. This transforms observed confidence scores into effective coefficients for local reconstruction.

### Mechanism 3: Non-Adaptive Single-Batch Query Strategy
Exactly 100 images queried in a single batch suffices for high-ASR black-box attacks. Pre-computing basis offline via local PCA and inversion allows submitting one batch of 5,050+100 queries non-adaptively - no iteration, no gradient estimation. The feature space geometry dominates attack success, with iterative refinement providing diminishing returns once k is sufficiently large relative to threshold.

## Foundational Learning

- **Angular Margin Metric Learning (ArcFace/CosFace)**: Understanding why features lie on S^{d-1} and how angular margins enforce intra-class compactness is prerequisite to reasoning about subsphere structure. Quick check: Explain why the decision boundary for ArcFace is a circular arc on the unit sphere rather than a hyperplane.

- **Pseudo-Inverse and Metric Projection**: The attack projects onto subspheres via A†Ax/‖A†Ax‖₂. Without fluency in Moore-Penrose pseudo-inverse, least-norm solutions, and constrained optimization on spheres, the derivation will be opaque. Quick check: Given A ∈ ℝ^{k×d} with k<d, what is the geometric interpretation of projecting x onto the row space of A?

- **Face Template Inversion**: The attack reconstructs adversarial faces from projected feature vectors using F⁻¹ (Arc2Face, NbNet). Understanding the fidelity and limitations of inversion determines whether the generated image actually exhibits the intended attribute. Quick check: Why do diffusion-based inverters (e.g., Arc2Face) outperform encoder-decoder approaches for identity-consistent reconstruction?

## Architecture Onboarding

- **Component map**: Local Pipeline: Dataset D_f → PCA → M_f (k PCs) → F^{-1} → Basis Images O; Query Pipeline: O × O → Target API → Scores → R matrix; Attack Pipeline: Target img → F_local → x → Query O vs img → s → R^{-1}s → F_local^{-1} → Adversarial img

- **Critical path**: 
  1. Basis construction: PCA on F(D_f) must yield k components spanning semantically coherent subsphere
  2. R estimation: 5,050 pairwise queries must complete without API throttling; R must be well-conditioned
  3. Score transformation: Confidence-to-cosine mapping must be accurate across score range
  4. Reconstruction: Inverse model must faithfully render projected vector with target attribute

- **Design tradeoffs**: Larger k → higher ASR but more queries (k² growth for R); strict attribute control improves semantic consistency but may reduce transferability; more expressive inverse models yield realistic faces but require careful ID-conditioning

- **Failure signatures**: 
  - Attribute collapse: Generated faces lose intended attribute → inverse model lacks coverage
  - Low ASR without R: Scores mis-aligned → R missing or poorly estimated
  - Threshold mismatch: Target model has unusually high τ → projection distance exceeds recognition radius

- **First 3 experiments**:
  1. Validate subsphere structure: Run PCA on VGGFace2 with attribute labels, visualize PC reconstructions via Arc2Face, confirm attribute preservation
  2. Estimate correction matrix R: Query AWS CompareFaces with 100×100 basis pairs, fit logistic sigmoid, compute R, verify condition number <100
  3. End-to-end ASR measurement: Select 100 target images without target attribute, project onto each attributed subsphere, generate adversarial faces, query AWS at τ=0.8 and τ=0.99, report ASR and attribute accuracy

## Open Questions the Paper Calls Out

### Open Question 1
Can the non-adaptive subsphere projection method be effectively applied to other biometric systems (e.g., voice recognition) or deep learning systems trained with different objectives? The introduction states the techniques can be "spread to other biometric fields such as voice," and the conclusion lists "attacks specific to other DL-based systems" as an open question. This remains unresolved as experimental validation is strictly confined to face recognition systems.

### Open Question 2
What improved training methodologies can limit the formation of geometric structures (like attributed subspheres) exploitable by adversaries without significantly degrading system accuracy? The conclusion suggests studying "improved training methods that have limited characteristics for adversarial uses," and Section 5.3 discusses limitations of simply increasing thresholds. Existing defenses impose heavy computational costs or reduce accuracy (TAR).

### Open Question 3
What is the theoretical and empirical relationship between robustness against perturbation-based attacks and vulnerability to non-adaptive subspace projection attacks? Appendix G.9 states analyzing "the relationship between our attack and prior perturbation-based attacks" is an important area for future work. The authors observed that some adversarially trained models were resistant while certifiably robust models were vulnerable, but only hypothesized reasons without fully characterizing trade-offs.

## Limitations

- Core mechanism relies on unproven conjecture that attribute-labeled embeddings form spherical subspheres - empirical validation limited to qualitative visual results
- Correction matrix requires 5,050 pairwise queries which may trigger API rate limiting or detection mechanisms
- Method still requires local model to be in-distribution for target FRS; correction matrix implicitly encodes transferability assumptions

## Confidence

**High Confidence**: Mathematical derivation of pseudo-inverse projection and correction matrix framework are rigorous and internally consistent. ASR measurements against AWS CompareFaces appear reproducible.

**Medium Confidence**: Claim that exactly 100 basis images suffice relies on heuristic Conjecture 2 about universal basis existence. Logistic sigmoid fitting introduces model-dependent variability not fully characterized.

**Low Confidence**: Assertion that approach "eliminates need for transferability" conflates concepts - method still requires local model in-distribution and correction matrix encodes transferability assumptions.

## Next Checks

1. **Subsphere Geometry Validation**: Apply PCA to VGGFace2 features labeled by FairFace attributes, reconstruct PC images using Arc2Face, and quantitatively measure attribute consistency across linear interpolations within each subsphere (target: >90% attribute preservation along geodesics).

2. **Correction Matrix Robustness**: Simulate API noise by adding ±0.05 random perturbations to pairwise scores during R estimation, measure resulting ASR degradation on AWS CompareFaces. Validate R condition number remains <100 across 10 random basis selections.

3. **Query Budget Analysis**: Measure AWS response times and rate limits for 5,050 pairwise queries, implement exponential backoff strategy, quantify impact on total attack time and any correlation with ASR when queries are split across multiple sessions.