---
ver: rpa2
title: Are Greedy Task Orderings Better Than Random in Continual Linear Regression?
arxiv_id: '2510.19941'
source_url: https://arxiv.org/abs/2510.19941
tags:
- greedy
- tasks
- task
- learning
- orderings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates task orderings in continual linear regression,\
  \ focusing on greedy strategies that maximize dissimilarity between consecutive\
  \ tasks. Using tools from Kaczmarz methods, the authors formalize two greedy orderings\u2014\
  Maximum Distance and Maximum Residual\u2014and compare them empirically and analytically\
  \ to random orderings."
---

# Are Greedy Task Orderings Better Than Random in Continual Linear Regression?

## Quick Facts
- arXiv ID: 2510.19941
- Source URL: https://arxiv.org/abs/2510.19941
- Reference count: 40
- Primary result: Greedy task orderings (Maximum Distance/Residual) converge faster than random in continual linear regression, with theoretical guarantees for high-rank tasks and O(1/k^(1/3)) convergence with repetition.

## Executive Summary
This paper investigates task orderings in continual linear regression, focusing on greedy strategies that maximize dissimilarity between consecutive tasks. Using tools from Kaczmarz methods, the authors formalize two greedy orderings—Maximum Distance and Maximum Residual—and compare them empirically and analytically to random orderings. Empirically, greedy orderings converge faster on both synthetic regression and CIFAR-100 classification tasks. Analytically, they prove optimality for high-rank tasks and show that single-pass greedy orderings can catastrophically fail under general rank, while greedy orderings with repetition achieve O(1/k^(1/3)) convergence. A hybrid approach combining greedy and random orderings is also proposed, avoiding failure modes while maintaining good performance.

## Method Summary
The paper studies continual linear regression where tasks are learned sequentially to convergence. Three ordering strategies are compared: random selection, greedy selection based on Maximum Distance (MD) between consecutive iterates, and greedy selection based on Maximum Residual (MR). MD requires knowledge of task pseudo-inverses or the optimal solution w*, while MR only needs loss computation. A hybrid approach switches from greedy to random when the step size drops below a threshold β. Theoretical analysis uses Kaczmarz method tools to prove convergence rates, showing that single-pass greedy can catastrophically fail on adversarial task sets while greedy with repetition achieves O(1/k^(1/3)) convergence.

## Key Results
- Greedy orderings (MD/MR) empirically converge 10× faster than random on synthetic Gaussian data and CIFAR-100 classification tasks
- For high-rank tasks (r=d-1), greedy orderings achieve optimal O(1/eT) convergence rate
- Single-pass greedy orderings can catastrophically fail with Ω(1) loss on adversarial task sets
- Greedy orderings with repetition achieve O(1/k^(1/3)) convergence rate
- Hybrid approach combining greedy and random orderings avoids failure modes while maintaining performance

## Why This Works (Mechanism)

### Mechanism 1: Geometric Acceleration via Maximally Dissimilar Projections
Greedy ordering accelerates convergence by maximizing the distance between consecutive iterates, geometrically corresponding to projecting onto the most "orthogonal" available task subspace. In linear regression, training to convergence on a task is an orthogonal projection onto that task's solution subspace. By selecting tasks that maximize the residual or distance, the learner takes the largest possible "step" towards the intersection of all task solution spaces.

### Mechanism 2: Catastrophic Failure via Adversarial Geometry
Single-pass greedy orderings can fail catastrophically because local maximization of step size can trap the iterates in a sequence that never reaches the global intersection. The greedy rule consistently selects tasks that appear locally optimal but actually steer the parameters away from the optimal solution or cycle without making global progress.

### Mechanism 3: Hybrid Robustness via Thresholding
A hybrid approach (Greedy → Random) achieves the best of both worlds: fast initial convergence of greedy ordering and provable non-catastrophic bounds of random ordering. Greedy steps are effective early in training when many dissimilar tasks exist, while switching to random avoids failure modes when "large" steps become scarce.

## Foundational Learning

- **Concept: Orthogonal Projections in Linear Regression**
  - Why needed: The theoretical framework treats learning a task as projecting the current weight vector onto the task's solution space. Without this, the "distance" and "residual" metrics are just numbers rather than geometric vectors.
  - Quick check: Given a linear system Xw = y, can you describe the geometric operation of minimizing ||Xw - y||² as a projection?

- **Concept: Joint Realizability**
  - Why needed: This guarantees that a perfect solution w* exists for all tasks simultaneously. Without this, the concept of "converging to the intersection" is meaningless.
  - Quick check: If three linear regression tasks have solution spaces that intersect in an empty set, does the projection perspective still apply to finding a "best" w?

- **Concept: Kaczmarz Methods**
  - Why needed: The paper directly adapts theorems from the Kaczmarz literature (iterative row-action methods for solving linear systems). Understanding the connection between "selecting a row in Kaczmarz" and "selecting a task in CL" is essential for the theoretical justification.
  - Quick check: How does "Randomized Kaczmarz" differ from the greedy "Maximum Distance" version in terms of which row is selected next?

## Architecture Onboarding

- **Component map**: Task Generator → State Manager → Selection Policy → Learner
- **Critical path**: The Selection Policy is the core contribution. You must implement the greedy logic (Def 3.1 & 3.2) and the Hybrid logic (Scheme 3). Note that MD requires calculating pseudo-inverses or access to w* (oracle), while MR only requires a forward pass (loss calculation), making MR the practical choice.
- **Design tradeoffs**:
  - MD vs. MR: MD is theoretically "cleaner" but computationally expensive/impractical. MR is practical and performs nearly as well but is theoretically "looser".
  - Single-pass vs. Repetition: Single-pass is the standard CL setting but theoretically fragile. Repetition is theoretically robust but violates strict CL definitions.
- **Failure signatures**:
  - Loss Plateau: Greedy single-pass on adversarial data shows loss plateauing at high values (~0.1 or Ω(1)).
  - Anisotropy Slowdown: In correlated data, all orderings slow down and greedy advantages may diminish.
- **First 3 experiments**:
  1. Reproduce Isotropic Gains: Generate random Gaussian tasks (d=100, r=10, T=50) and plot loss curves for Random, MR, and MD to verify the 10× speedup.
  2. Verify Failure Mode: Implement the "Adversarial 3d construction" and run greedy single-pass policy to confirm non-vanishing loss.
  3. Hybrid Ablation: Implement Hybrid policy (Scheme 3). Vary threshold β to show transition from greedy to random behavior and confirm it avoids the failure mode.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the benefits of greedy orderings be retained while generalizing beyond joint realizable linear regression to nonlinear models or noisy settings?
- Basis in paper: [explicit] The authors state in the Future Work section: "our linear realizability assumption could be relaxed to accommodate label noise or even extend to nonlinear models, possibly borrowing tools from Kaczmarz literature".
- Why unresolved: The theoretical analysis relies heavily on linear projection properties and Assumption 2.1. Extending to nonlinear or noisy settings may break the geometric intuitions and convergence guarantees.
- What evidence would resolve it: Theoretical bounds for greedy orderings in nonlinear regimes or with label noise, combined with empirical validation on nonlinear continual learning benchmarks.

### Open Question 2
- Question: How do the theoretical separation between single-pass greedy and random orderings translate to class-incremental and task-incremental continual learning setups?
- Basis in paper: [explicit] The authors note in Future Work: "One could extend our findings to other settings—such as class- and task-incremental" and in Section 6 discuss how different setups yield different ordering preferences.
- Why unresolved: The paper focuses on domain-incremental linear regression. Class- and task-incremental settings involve different objectives (e.g., transfer vs. forgetting) and may require different similarity metrics.
- What evidence would resolve it: Comparative analysis of greedy vs. random orderings across multiple continual learning benchmarks with appropriate task similarity measures.

### Open Question 3
- Question: Can probabilistic selection rules combine the empirical benefits of greedy ordering with the robustness guarantees of random ordering?
- Basis in paper: [explicit] The authors propose in Future Work: "a promising direction lies in probabilistic selection rules, inspired by randomized greedy Kaczmarz methods, which could combine the strengths of greedy orderings with the robustness of randomness".
- Why unresolved: The hybrid approach provides a deterministic combination, but probabilistic selection (e.g., weighted by dissimilarity) may offer better theoretical properties and avoid hand-tuned thresholds.
- What evidence would resolve it: Development and analysis of probabilistic task selection algorithms with provable convergence rates, along with empirical comparison to deterministic hybrid methods.

## Limitations
- Theoretical analysis assumes joint realizability and training to convergence, which may not hold in practical deep learning scenarios with non-convex objectives and early stopping.
- The hybrid approach's threshold β requires tuning and is not provided as a universal value, making it data-dependent.
- Catastrophic failure modes are constructed adversarially and may not reflect typical real-world task distributions.

## Confidence

| Claim | Confidence |
|-------|------------|
| Empirical performance improvements on synthetic and CIFAR-100 tasks | High |
| Theoretical bounds for greedy with repetition and hybrid approaches | Medium |
| Failure mode analysis for single-pass greedy | Medium |

## Next Checks
1. **Generalization Test**: Evaluate greedy orderings on more diverse task distributions beyond Gaussian and CIFAR-100, including natural language and reinforcement learning tasks.
2. **Robustness Check**: Test the hybrid approach with varying β thresholds across different task sets to establish practical guidelines for threshold selection.
3. **Scalability Analysis**: Assess how the computational overhead of greedy selection (especially MD) scales with large T and d in practical deep learning settings.