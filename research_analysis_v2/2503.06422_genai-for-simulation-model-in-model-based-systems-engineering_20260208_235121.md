---
ver: rpa2
title: GenAI for Simulation Model in Model-Based Systems Engineering
arxiv_id: '2503.06422'
source_url: https://arxiv.org/abs/2503.06422
tags:
- simulation
- class
- system
- language
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a generative system design methodology framework
  for MBSE, focusing on intelligent generation of simulation models for system physical
  properties. The method uses BERT and Transformer-based models to extract information
  from product design documents, then constructs X language simulation models through
  modular code completion using scalable templates.
---

# GenAI for Simulation Model in Model-Based Systems Engineering

## Quick Facts
- arXiv ID: 2503.06422
- Source URL: https://arxiv.org/abs/2503.06422
- Reference count: 40
- Primary result: Modular template-based LLM code completion achieves 0.825 model quality score vs 0.156 for direct generation on aircraft electrical system simulation models

## Executive Summary
This paper proposes a generative system design methodology framework for Model-Based Systems Engineering (MBSE) that uses Transformer-based models to automatically generate simulation models from product design documents. The approach combines BERT fine-tuning for entity extraction with modular code completion using scalable templates to generate X language simulation models for complex systems. The method addresses key challenges in MBSE including long-context processing limitations and the need for accurate system composition extraction. Experiments on aircraft electrical systems demonstrate significant improvements in model quality when using the proposed template-based approach versus direct generation.

## Method Summary
The method extracts system composition from design documents using fine-tuned BERT for named entity recognition, then generates X language simulation models through modular code completion with scalable templates. The pipeline first constructs couple class models (system architecture) then atomic class models (behavior) with hierarchical consistency constraints. The approach uses LoRA fine-tuning on CodeQwen1.5-7B to predict masked state and equation sections rather than generating entire models, addressing context window limitations and improving syntactic correctness.

## Key Results
- NER-BERT achieved 81.3% sentence accuracy, 95.06% entity precision, and 100% recall on aircraft electrical system entity extraction
- Template-based modular code completion improved model scores from 0.156 to 0.825 compared to direct generation
- The hierarchical generation approach successfully maintained model consistency across couple and atomic class levels
- System effectively extracted parent-subsystem relationships from design documents without information loss

## Why This Works (Mechanism)

### Mechanism 1
Modular code completion via scalable templates improves simulation model quality over direct generation. Instead of generating full simulation models (which causes context loss and truncation in LLMs), the system uses pre-defined X language templates with masked sections. The LLM completes specific modules (e.g., state blocks, equation sections) rather than entire files, reducing output complexity and preserving syntactic structure.

### Mechanism 2
NER-BERT filtering of design documents provides sufficient signal for system composition extraction while reducing noise. Fine-tuned BERT performs named entity recognition to tag parent systems (tag=1), subsystems (tag=2), and irrelevant content (tag=0). Only tagged entities proceed to model construction. The paper reports 100% recall on entity tags across four test systems, meaning no composition information is lost.

### Mechanism 3
Hierarchical generation (couple class → atomic class) with consistency constraints reduces cross-module errors. System-level couple class models are generated first, defining ports and connections. Atomic class models are then generated with ports derived algorithmically from the couple class connections. This enforces that subsystem ports match what the parent model expects. Evaluation explicitly scores "model consistency" between levels.

## Foundational Learning

- **DEVS Formalism (Discrete Event System Specification)**: Why needed here: X language is built on DEVS extensions; understanding atomic vs. coupled models, state transition functions (δint, δext), and time advance (ta) is prerequisite to reading templates and evaluation metrics. Quick check: Can you explain why a coupled model's External Input Coupling (EIC) maps to the `Port` and `Connection` keywords in X language?

- **BERT Fine-tuning for Token Classification**: Why needed here: The NER-BERT component uses standard BERT architecture with added classification layers; understanding WordPiece tokenization, [CLS]/[SEP] tokens, and softmax over token sequences is necessary to modify the extraction pipeline. Quick check: Given a sentence "The radar subsystem connects to the control bus," what tags would NER-BERT assign if "radar" is a subsystem and "control bus" is the parent system?

- **LoRA (Low-Rank Adaptation) Fine-tuning**: Why needed here: The paper uses LoRA to fine-tune CodeQwen1.5-7B; understanding rank decomposition (W₀ + ΔW = W₀ + BA) explains why training is feasible on single GPU despite 7B parameters. Quick check: If LoRA rank r=8 and original weight matrix is 4096×4096, how many trainable parameters does LoRA add compared to full fine-tuning?

## Architecture Onboarding

- **Component map**: Document Processing (Product design documents → NER-BERT → Simulation model corpus) → Couple Class Generation (Corpus + connection corpus → BERT classification + Transformer inference → Couple class model) → Atomic Class Generation (Couple model + component corpus → Port derivation + Transformer code completion → Atomic models) → Evaluation (Generated models → Syntax checker + Compiler + Manual review → Weighted score)

- **Critical path**: 1) NER-BERT training (requires labeled design documents with parent/subsystem tags) 2) Couple class template population (determines all downstream port constraints) 3) Transformer fine-tuning on X language corpus with masked state/equation sections 4) Atomic class generation with few-shot prompting

- **Design tradeoffs**: Template rigidity vs. flexibility (constrains output space but cannot express patterns not anticipated), Recall vs. precision in NER (optimizes for 100% recall at cost of manual review), Evaluation complexity (multi-level weighted scoring captures simulation-specific requirements but requires manual scoring)

- **Failure signatures**: Radar module anomaly (generated model includes plausible-but-incorrect behavior not in source documents), Port inconsistency (compilation fails if couple class connections reference ports not generated in atomic models), Template slot overflow (output truncates mid-expression if state/equation sections exceed context window)

- **First 3 experiments**: 1) Validate NER-BERT on your domain (test on 10-20 pages of design documents) 2) Ablate template vs. direct generation (measure if template improvement replicates in your domain) 3) Stress-test hierarchical consistency (modify one connection and verify atomic class generation flags inconsistency)

## Open Questions the Paper Calls Out

- How can Transformer-based models effectively balance the application of their inherent prior knowledge against specific task requirements when generating simulation models for well-documented systems? (The authors observe that general prior knowledge regarding "Radar" in models contradicted specific design documents, lowering score quality)

- To what extent does the reliance on synthetic training data (generated by GPT-3.5) impact the logical correctness and diversity of the fine-tuned simulation models compared to human-verified datasets? (The paper uses GPT-3.5 to generate additional datasets to overcome the scarcity of X language models)

- How does the proposed scalable template method generalize to domains other than electrical systems, specifically where continuous physical equations (e.g., fluid dynamics) differ significantly from the discrete/continuous hybrid models tested? (The evaluation is restricted to an aircraft electrical system)

## Limitations
- Domain-specificity of NER-BERT approach may not generalize to domains with implicit architecture or inconsistent terminology
- Template-based code completion requires accurate initial template design - errors propagate to all generated models
- Method's effectiveness on significantly larger systems than the aircraft electrical case study remains untested

## Confidence
- **High Confidence**: Modular code completion mechanism (well-supported by experimental results and logical argument about context window limitations)
- **Medium Confidence**: NER-BERT filtering effectiveness (strong recall results but lacks comparison to alternative methods)
- **Low Confidence**: Generalizability of template-based approach to modeling languages beyond X and scalability to larger systems

## Next Checks
1. Apply NER-BERT component to design documents from a different domain (e.g., automotive, industrial control) and measure entity extraction accuracy to test domain transfer
2. Systematically vary template slot boundaries in X language generation pipeline and measure impact on model quality scores to validate optimal template design
3. Generate complete system model, then introduce deliberate inconsistency in couple class connections to verify atomic class generation fails gracefully or produces diagnostic warnings