---
ver: rpa2
title: Fast Flow-based Visuomotor Policies via Conditional Optimal Transport Couplings
arxiv_id: '2505.01179'
source_url: https://arxiv.org/abs/2505.01179
tags:
- policy
- tasks
- learning
- robot
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COT Policy, a flow matching methodology for
  learning robot policies that generate high-quality actions in few steps while preserving
  multimodality. The key idea is to use conditional Optimal Transport couplings between
  noise and action trajectories, incorporating condition variables (e.g., observations)
  into the coupling process to avoid biased flows that occur with naive OT approaches.
---

# Fast Flow-based Visuomotor Policies via Conditional Optimal Transport Couplings

## Quick Facts
- **arXiv ID**: 2505.01179
- **Source URL**: https://arxiv.org/abs/2505.01179
- **Reference count**: 40
- **Primary result**: 2-step COT Policy achieves 4% higher success rates than Diffusion Policy while preserving multimodality

## Executive Summary
This paper introduces COT Policy, a flow matching methodology for learning robot policies that generate high-quality actions in few steps while preserving multimodality. The key idea is to use conditional Optimal Transport couplings between noise and action trajectories, incorporating condition variables (e.g., observations) into the coupling process to avoid biased flows that occur with naive OT approaches. The method trains as efficiently as standard Flow Matching and Diffusion Policy, without requiring additional training phases like distillation methods. Experiments show that 2-step COT Policy achieves 4% higher success rates than Diffusion Policy and outperforms other baselines on multiple simulated manipulation tasks while maintaining action diversity. It also solves real-world manipulation tasks within 1-2 steps, enabling high-quality real-time robot control.

## Method Summary
COT Policy trains a flow network to transform noise into actions via a vector field, but critically uses conditional Optimal Transport (COT) to pair noise with action trajectories during training. The method discretizes high-dimensional observations (images) into clusters using PCA and K-Means, then computes OT plans that minimize both Euclidean distance and condition dissimilarity. This forces the learned flow paths to be straight and contextually appropriate, enabling high-quality 1-2 step inference without distillation. The training uses standard conditional flow matching loss with the OT-paired samples, maintaining the same computational complexity as Diffusion Policy.

## Key Results
- 2-step COT Policy achieves 4% higher success rates than Diffusion Policy on simulated manipulation tasks
- Outperforms baselines on multiple tasks while maintaining action diversity (measured by trajectory variance)
- Solves real-world manipulation tasks within 1-2 steps, enabling high-quality real-time robot control
- Number of clusters (K) significantly impacts performance, with optimal values depending on dataset and batch size

## Why This Works (Mechanism)

### Mechanism 1: Conditional Coupling Prevents Biased Flows
Standard Optimal Transport minimizes transport cost based on Euclidean distance between noise and action. In conditional tasks, this causes mismatched pairings (e.g., noise for image A pairs with action for image B), creating biased flows. COT modifies the transport cost to penalize pairings where condition variables differ, ensuring noise pairs with actions sharing similar observations.

### Mechanism 2: Discretization Approximates Continuous OT
Exact Conditional OT is computationally difficult with high-dimensional continuous observations. The method projects observations into lower-dimensional space via PCA and clusters them, computing OT plans within a batch using discrete cluster IDs. This approximates the OT plan sufficiently to enable straight flow paths without training a separate coupling network.

### Mechanism 3: Simulation-Free Training for Inference Speed
By enforcing straight paths during training, the model achieves high performance in 1-2 inference steps without requiring a secondary distillation phase. The conditional OT coupling aligns training regression targets such that the learned vector field becomes effectively constant along the trajectory.

## Foundational Learning

- **Flow Matching (FM)**: Base generative modeling framework that trains a vector field $v_\theta$ to transform noise $p_0$ to data $p_1$ via an ODE. *Why needed*: Understanding this framework is essential to grasp how COT Policy learns to generate actions. *Quick check*: How does the number of integration steps (NFE) relate to the curvature of the learned flow path?

- **Optimal Transport (OT) Couplings**: Mathematical framework for pairing distributions by minimizing transport cost. *Why needed*: The core improvement comes from changing how noise is paired with data during training. *Quick check*: Why does standard OT coupling cause bias when conditions (observations) are involved?

- **Multimodality in Imitation Learning**: Robot tasks often have multiple valid solutions (e.g., push left or right). *Why needed*: The paper explicitly claims to preserve this diversity while speeding up inference. *Quick check*: What happens if a policy averages two distinct modes?

## Architecture Onboarding

- **Component map**: Vision Encoder (ResNet-18 / PCA) -> Flow Network (U-Net) -> COT Solver (Training Logic)

- **Critical path**: The COT pairing step (Algorithm 1, lines 4-7) where noise samples are reordered to match actions according to the OT plan that minimizes $||x_0 - x_1||^2 + \gamma ||c_0 - c_1||^2$. If this step is incorrect, the "few-step" capability breaks.

- **Design tradeoffs**:
  - **Number of Clusters (K)**: Low K behaves like unconditional OT (biased flows), high K behaves like independent coupling (curved flows). Finding the sweet spot balances mode separation and path straightness.
  - **Gamma (Î³)**: Controls strictness of condition matching. Must be large enough to prioritize condition over action distance, but stable numerically.

- **Failure signatures**:
  - **Intermittent Motion**: If NFE is too low for learned curvature, robot stutters
  - **Biased Actions**: Using standard OT instead of COT causes actions relevant to similar-looking training data but wrong for specific context
  - **Mode Collapse**: If clusters are too few or model capacity is low, policy outputs average of multiple valid trajectories

- **First 3 experiments**:
  1. Visualize the flow on the "Two Moons" toy task to verify 1-step generation lands on correct moon based on condition
  2. Run push-t task with K=1 (OT-CFM), K=64 (COT), and K=Batch Size (Independent CFM) to confirm performance "hump" at optimal K
  3. Deploy 2-step policy on real robot controller to verify inference time is ~2x network forward pass vs 20-step baseline

## Open Questions the Paper Calls Out

### Open Question 1: Automatic Cluster Selection
How can the optimal number of clusters (K) be determined automatically for diverse datasets and batch sizes? The authors note performance degrades if K is too low (OT-CFM behavior) or too high (I-CFM behavior), but treat it as a hyperparameter requiring manual tuning.

### Open Question 2: COT with Distillation
Can combining COT coupling with single-phase distillation techniques close the performance gap between low and high NFE inference in high-dimensional action spaces? The authors identify this as promising for addressing the "curse of dimensionality."

### Open Question 3: Pre-trained Visual Representations
How do pre-trained visual representations (PVRs) affect performance and generalization compared to end-to-end trained encoders? The paper identifies this as an "open challenge" for imitation learning policies.

## Limitations
- The optimal number of clusters (K) significantly impacts performance but requires manual tuning with no theoretical bound or adaptive algorithm provided
- Computational overhead of OT planning per batch is not extensively characterized, and scalability to larger datasets remains unclear
- The method's effectiveness depends on the quality of visual clustering, which may not represent the true action space well in edge cases

## Confidence
- **High confidence**: Core mechanism (conditional OT prevents biased flows) and empirical results showing COT Policy outperforms Diffusion Policy in few steps
- **Medium confidence**: Claim about training efficiency being equivalent to Diffusion Policy, depending on OT solver implementation details
- **Medium confidence**: Multimodality preservation claim, primarily validated through trajectory variance metrics rather than qualitative analysis

## Next Checks
1. Test cluster sensitivity by training with K=8, K=32, K=128 on same task and plot success rate vs. NFE to identify performance "hump"
2. Implement same policy using standard OT (ignoring conditions) to directly verify biased flows occur and confirm 4% success rate drop
3. Measure end-to-end inference latency (wall-clock time) for NFE=2 vs NFE=20 on real robot to validate practical speedup claim