---
ver: rpa2
title: Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought
arxiv_id: '2601.08108'
source_url: https://arxiv.org/abs/2601.08108
tags:
- reasoning
- causal
- answer
- step
- acps
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Adaptive Causal Prompting with Sketch-of-Thought
  (ACPS), a framework that combines standard and conditional front-door causal adjustments
  with concise Sketch-of-Thought reasoning to debias large language models. ACPS adaptively
  selects an appropriate causal intervention based on task characteristics and uses
  clustered SoTs with encoder-based NWGM approximation for efficient answer selection.
---

# Debiasing Large Language Models via Adaptive Causal Prompting with Sketch-of-Thought

## Quick Facts
- **arXiv ID**: 2601.08108
- **Source URL**: https://arxiv.org/abs/2601.08108
- **Reference count**: 40
- **Primary result**: Combines standard and conditional front-door causal adjustments with concise Sketch-of-Thought reasoning to achieve up to 79.71% accuracy on GSM8K while reducing token usage.

## Executive Summary
This paper proposes Adaptive Causal Prompting with Sketch-of-Thought (ACPS), a framework that addresses bias in LLM reasoning by combining causal inference with efficient reasoning traces. ACPS uses front-door causal adjustment to isolate true causal effects from spurious correlations, adaptively selecting between standard and conditional adjustments based on task characteristics. The framework generates concise Sketch-of-Thought reasoning traces, clusters them for diversity, and applies weighted voting to select answers. Experiments across seven reasoning benchmarks demonstrate ACPS consistently outperforms existing methods while using fewer tokens.

## Method Summary
ACPS treats Sketch-of-Thought reasoning as a front-door variable to mitigate bias from unobserved confounders. The framework first classifies queries into three reasoning paradigms (Conceptual Chaining, Chunked Symbolism, Expert Lexicons) using a DistilBERT classifier. Based on classification, it applies either standard or conditional front-door adjustment. For reasoning, ACPS generates M diverse SoTs via temperature sampling, embeds them with Sentence-BERT, clusters into K groups, and selects cluster representatives. NWGM approximation retrieves demonstrations per cluster, and causal-effect-weighted voting selects the final answer. The approach aims to maintain reasoning quality while dramatically reducing token usage compared to Chain-of-Thought methods.

## Key Results
- Achieves up to 79.71% accuracy on GSM8K, 75.97 F1 on HotpotQA, and 79.48% on FEVER
- Consistently outperforms baselines including ICL, CoT, SoT, CAD, and CP across all seven datasets
- Generates shorter reasoning traces (typically fewer than three steps) while maintaining strong performance
- Maintains robustness under noisy conditions and shows superior token efficiency

## Why This Works (Mechanism)

### Mechanism 1: Front-door Causal Adjustment for Bias Mitigation
- **Claim**: Front-door adjustment reduces bias from unobserved confounders by estimating causal effects through observable intermediates.
- **Mechanism**: SoT reasoning acts as a front-door variable intercepting all paths from query to answer, allowing decomposition of P(A|do(Q)) into query-to-reasoning and reasoning-to-answer effects.
- **Core assumption**: Reasoning traces satisfy front-door criterion conditions (intercept all directed paths, no unblocked back-door paths from query to reasoning, all back-door paths from reasoning to answer blocked by query).
- **Evidence anchors**: Abstract mentions adaptive intervention selection; Section 3.1 provides mathematical formulation; related causal prompting papers validate the approach.
- **Break condition**: If reasoning traces don't fully intercept causal paths, front-door criterion is violated and adjustment fails.

### Mechanism 2: Adaptive Intervention Selection via Task Classification
- **Claim**: Different tasks require different causal adjustments, and adaptive selection improves generalizability.
- **Mechanism**: DistilBERT classifier categorizes queries into three paradigms, routing to conditional front-door for external knowledge tasks and standard front-door for context-free tasks.
- **Core assumption**: Task characteristics reliably predict appropriate causal interventions; classification engine generalizes without retraining.
- **Evidence anchors**: Section 3.2 describes routing logic; Table 1 shows ACPS outperforms baselines across diverse task types.
- **Break condition**: Classification failures route to default commonsense template, which may be suboptimal for specialized tasks.

### Mechanism 3: Efficient Reasoning via Sketch-of-Thought Clustering
- **Claim**: Concise SoT traces with clustering maintain quality while reducing token usage.
- **Mechanism**: Generate M diverse SoTs, embed with Sentence-BERT, cluster via K-means, select representatives. NWGM approximates probability estimation over reasoning paths.
- **Core assumption**: Cluster centroids represent distinct strategies and cluster size correlates with reasoning path probability.
- **Evidence anchors**: Section 3.3 describes clustering approach; Figure 4 shows shorter traces; ablation studies confirm clustering importance.
- **Break condition**: Insufficient SoT diversity or clustering of semantically distinct paths together makes probability estimation unreliable.

## Foundational Learning

- **Concept: Front-door criterion in causal inference**
  - **Why needed here**: Core theoretical foundation for bias mitigation when confounders are unobservable
  - **Quick check question**: Given a DAG with Q→R→A and unobserved U→Q, U→A, does R satisfy front-door conditions? Can you identify all three requirements?

- **Concept: Structural Causal Models (SCMs) and do-calculus**
  - **Why needed here**: Formal framework for expressing interventions (do(X)) and deriving adjustment formulas
  - **Quick check question**: Explain why P(A|do(Q)) differs from P(A|Q) and write the front-door adjustment formula.

- **Concept: Encoder-based similarity and clustering for reasoning diversity**
  - **Why needed here**: Practical implementation of probability estimation over continuous reasoning spaces
  - **Quick check question**: How does K-means clustering on Sentence-BERT embeddings approximate discrete reasoning path distributions?

## Architecture Onboarding

- **Component map**: Classification Engine (DistilBERT) → routes to standard/conditional front-door → SoT Generator (LLM with temperature sampling) → Encoder (Sentence-BERT) → K-means Clusterer → NWGM Selector → Causal Effect Estimator → Final Answer Selector

- **Critical path**:
  1. Query classification determines intervention type
  2. SoT generation with temperature variation (0.0-2.0, step 0.25, yields M≈9)
  3. Embedding + K-means clustering (K=4 default)
  4. Per-cluster demonstration retrieval (L=2) and answer generation (S=3)
  5. Causal-effect-weighted voting across K×S=12 candidates

- **Design tradeoffs**:
  - M (SoTs) vs. K (clusters): Higher values improve diversity but increase cost; paper uses M=9-12, K=4-9
  - SoT vs. CoT: Ablation shows w/o SoT occasionally higher on some datasets (MATH: 52.95 vs. 48.33) but SoT offers consistent efficiency gains
  - Encoder fine-tuning: Paper attempted but found unstable training; pre-trained Sentence-BERT preferred for generalization

- **Failure signatures**:
  - Classification engine failure → defaults to commonsense template (may underperform on math/symbolic tasks)
  - Insufficient SoT diversity → clusters collapse, probability estimation unreliable
  - Edge-case generations blocked by API safety policies → reduced reasoning path coverage
  - NWGM with random demonstration selection (NWGM-Ran ablation) → ~6-10 point F1 drops on multi-hop tasks

- **First 3 experiments**:
  1. **Reproduce GSM8K ablation**: Run ACPS with w/o K-means and w/o Weight variants on 100 samples to confirm cluster-based probability estimation contribution (expected: >5 point accuracy drop without clustering).
  2. **Classification accuracy audit**: Evaluate DistilBERT classification engine on held-out queries from each paradigm (CC/CS/EL) to measure routing accuracy and identify systematic misclassification patterns.
  3. **Token budget sweep**: Compare ACPS vs. CP vs. ACPS-CoT under max_tokens ∈ {100, 200, 300, 500} on HotpotQA to validate efficiency-accuracy tradeoff curves (expected: ACPS maintains accuracy at lower budgets per Figure 9).

## Open Questions the Paper Calls Out

- **Question 1**: Does incorporating multiple unobserved confounders into the Structural Causal Model yield better debiasing performance than the current single-confounder assumption?
  - **Basis**: Appendix A.1 states future work will consider more complex causal structures to model additional confounding factors.
  - **Why unresolved**: Current single-confounder assumption may be oversimplified for real-world reasoning with multiple interacting biases.
  - **What evidence would resolve it**: Comparative study implementing ACPS with multi-dimensional latent confounders on datasets with distinct bias types.

- **Question 2**: Does the causal estimation and token efficiency of ACPS scale effectively to larger backbone models and more extensive evaluation sets?
  - **Basis**: Section 7 (Limitations) notes that expanding evaluation to larger-scale test sets and more powerful backbone models could provide deeper insights.
  - **Why unresolved**: Current experiments limited to models like Ministral-3B and LLaMA-3 8B; scalability to frontier models unproven.
  - **What evidence would resolve it**: Benchmarking ACPS against standard CoT on a frontier model (e.g., GPT-4) across a dataset with >50k samples.

- **Question 3**: Can the encoder-based NWGM approximation be stabilized and improved by fine-tuning on larger datasets?
  - **Basis**: Appendix A.2 details that fine-tuning Sentence-BERT on 4,096 examples resulted in unstable evaluation loss and overfitting.
  - **Why unresolved**: Unclear if fine-tuning failure was fundamental limitation or insufficient training data.
  - **What evidence would resolve it**: Experiments fine-tuning encoder on datasets of varying sizes (e.g., 10k vs 100k samples) to determine data threshold for improvement.

- **Question 4**: How does suppression of specific reasoning paths by API safety policies impact validity of causal effect estimation?
  - **Basis**: Section 7 (Limitations) mentions edge-case generations remain constrained by API's safety policy.
  - **Why unresolved**: Causal estimation relies on SoT diversity; safety filters may skew P(r|Q,e) distribution by blocking certain reasoning clusters.
  - **What evidence would resolve it**: Analysis of SoT diversity on safety-sensitive benchmarks comparing unrestricted vs API-based models.

## Limitations

- **Limitation 1**: Adaptive intervention selection relies on DistilBERT classifier accuracy, which is not directly evaluated in the paper. Misclassification could cause suboptimal causal adjustments.
- **Limitation 2**: Demonstration pool construction lacks specificity regarding size and generation parameters, which could affect quality of causal effect estimation.
- **Limitation 3**: API safety policies may suppress certain reasoning paths, potentially skewing the probability distributions used for causal estimation.

## Confidence

- **High Confidence**: The front-door causal adjustment mechanism itself (supported by established causal inference theory and mathematical formulation)
- **Medium Confidence**: The Sketch-of-Thought clustering and NWGM approximation (supported by ablation studies showing 6-10 point F1 improvements)
- **Low Confidence**: The adaptive intervention selection framework (lacks direct evaluation of classification engine's accuracy)

## Next Checks

1. **Classification Engine Audit**: Evaluate the DistilBERT routing classifier on held-out validation sets from each reasoning paradigm (Conceptual Chaining, Chunked Symbolism, Expert Lexicons) to quantify classification accuracy and identify systematic misrouting patterns that could undermine adaptive intervention selection.

2. **Front-Door Criterion Validation**: Systematically verify whether reasoning traces generated by SoT actually satisfy front-door conditions for representative tasks. This includes checking if reasoning fully intercepts causal paths and identifying tasks where the assumption may be violated.

3. **Token Efficiency Under Varying Budgets**: Conduct controlled experiments comparing ACPS against baselines (CP, CoT) across multiple token budget constraints (100, 200, 300, 500 tokens) on multi-hop reasoning tasks to validate that efficiency gains do not come at the cost of accuracy degradation under resource constraints.