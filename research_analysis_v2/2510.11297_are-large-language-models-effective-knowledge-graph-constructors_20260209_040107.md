---
ver: rpa2
title: Are Large Language Models Effective Knowledge Graph Constructors?
arxiv_id: '2510.11297'
source_url: https://arxiv.org/abs/2510.11297
tags:
- knowledge
- graph
- llms
- extraction
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates whether large language models (LLMs) are effective
  at constructing knowledge graphs (KGs). The authors propose a hierarchical framework
  that combines relational triple extraction, coreference resolution, entity and relation
  deduplication, and source tracing.
---

# Are Large Language Models Effective Knowledge Graph Constructors?

## Quick Facts
- arXiv ID: 2510.11297
- Source URL: https://arxiv.org/abs/2510.11297
- Authors: Ruirui Chen; Weifeng Jiang; Chengwei Qin; Bo Xiong; Fiona Liausvia; Dongkyu Choi; Boon Kiat Quek
- Reference count: 40
- Primary result: LLMs can construct relevant KGs from academic papers, with reasoning models achieving higher accuracy, but human verification remains necessary due to semantic accuracy limitations.

## Executive Summary
This paper evaluates whether large language models can effectively construct knowledge graphs from academic papers on children's mental well-being. The authors propose a hierarchical framework that combines relational triple extraction, coreference resolution, entity and relation deduplication, and source tracing across six LLM models. Results show that LLMs generally produce relevant and interpretable triples, with reasoning models (o4-mini) achieving the highest accuracy scores. However, semantic accuracy remains a key challenge, and the study highlights that human verification is still necessary for practical deployment.

## Method Summary
The framework processes academic papers in three sequential stages: initial extraction with coreference resolution, splitting with entity consistency prompting, and abstraction to identify parent concepts. Each stage uses zero-shot prompting with specific instructions and JSON output templates. The method processes sentences in 3-sentence batches with context windows, applies optional filtering before splitting and abstraction, and traces each triple back to its source. The approach aims to create hierarchical, connected graphs without requiring predefined schemas.

## Key Results
- GPT-4o achieves highest initial extraction accuracy (4.48/5) while Gemini-2.5-Flash excels in splitting (4.56/5) and abstraction (4.51/5)
- Hierarchical stages significantly improve graph connectivity, with FGC increasing from 0.642 → 0.782 → 0.858 for Gemini-2.5-Flash
- Reasoning models (o4-mini) achieve the highest semantic accuracy but require significantly more processing time
- All models show semantic accuracy ceilings requiring human verification for practical deployment

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Extraction Reduces Schema Dependency
Decomposing KG construction into sequential stages (initial extraction → splitting → abstraction) improves graph connectivity without requiring predefined schemas. The framework first extracts sentence-level triples preserving full meaning, then progressively decomposes compound entities and identifies parent concepts, creating linking points across sources at multiple granularities. LLMs perform better when focused on one cognitive task per prompt rather than all operations simultaneously.

### Mechanism 2: Coreference Resolution Improves Triple Completeness
Explicit prompting for coreference resolution within a 3-sentence context window produces more self-contained and interpretable triples. The model receives surrounding context and is instructed to resolve pronouns and ambiguous references before triple generation, ensuring each extracted triple is semantically complete in isolation.

### Mechanism 3: Entity Consistency Prompting Enhances Graph Connectivity
Instructing LLMs to normalize entity representations during the splitting stage reduces redundancy and improves connectivity. During splitting, the model receives previously extracted entities and is prompted to use consistent naming, enabling explicit links between semantically related nodes that would otherwise remain disconnected.

## Foundational Learning

- **Knowledge Graph Triple Structure**: Understanding `<head entity, relation, tail entity>` triples is prerequisite to interpreting evaluation metrics. Quick check: Can you explain why the triple `<infant television viewing, is negatively associated with, cognitive skills>` preserves more meaning than separate triples for each component?

- **Graph Connectivity Metrics (Weakly Connected Components)**: The primary structural evaluation uses "fraction in giant component" to measure how well the hierarchical approach reduces isolated subgraphs. Quick check: If a KG has 10,000 nodes and the largest connected component contains 8,500 nodes, what is the FGC score?

- **Prompt Engineering for Structured Output**: All three stages rely on zero-shot prompting to produce JSON-formatted triples with specific fields (text, properties, relation). Quick check: Why might setting temperature=0 be important for reproducible KG construction?

## Architecture Onboarding

- **Component map**: Input Document → [Batch 3 sentences + context] → Initial Extraction (coreference-aware prompting) → Splitting (entity consistency prompting) + optional filter → Abstraction (identify parent concepts) + optional filter → Source Tracing (attach provenance to each triple) → Knowledge Graph (nodes, edges, properties)

- **Critical path**: The initial extraction stage determines the ceiling for downstream quality—errors here propagate through splitting and abstraction. Focus validation efforts on accuracy scores in initial extraction first.

- **Design tradeoffs**: Processing sentences in 3-sentence batches reduces information loss from long contexts but may miss coreference links spanning larger distances. Filtering before splitting/abstraction reduces API costs but may skip legitimate decomposition opportunities (Table 2 shows GPT-4o filters 97.9% of entities from abstraction vs. GPT-3.5-Turbo's 81.9%). Reasoning models (o4-mini) achieve highest accuracy but "require significantly more processing time."

- **Failure signatures**: GPT-3.5-Turbo occasionally fails to follow output template and generates repetitive triples. LLaMA models tend to produce vague relations (e.g., "in") and struggle with format compliance. All models: LLM evaluators (GPT-4.1) tend to overestimate scores in splitting/abstraction stages.

- **First 3 experiments**:
  1. Run initial extraction on 100 sentences with GPT-4o at temperature=0; manually verify accuracy scores match Table 1 benchmarks (~4.48/5).
  2. Disable coreference-aware prompting on the same subset; confirm accuracy drops as in Table 5 (~4.26/5).
  3. Apply all three stages to a single full paper; compute FGC at each stage and verify progression toward Table 3 benchmarks for your chosen model.

## Open Questions the Paper Calls Out

### Open Question 1
How can full-document context be maintained during LLM-based knowledge graph construction to prevent the loss of coreference links? The authors state that batching sentences risks missing references outside the local context, and "How to input long texts into LLMs in their entirety while obtaining accurate, comprehensive, and relevant results remains an open research question."

### Open Question 2
Can LLMs be effectively guided to selectively extract only essential insights rather than processing all text indiscriminately? The authors argue that future analysis "should focus on enabling LLMs to identify and extract only the most important information, rather than processing every sentence indiscriminately."

### Open Question 3
Does the hierarchical structure of LLM-generated knowledge graphs improve performance on downstream tasks compared to traditional flat extraction methods? The paper notes that "A more comprehensive assessment of knowledge graph quality—such as evaluating performance on downstream tasks—is left for future work."

## Limitations

- Semantic accuracy ceiling of LLM-generated triples requires human verification for practical deployment
- Coreference resolution constrained to 3-sentence windows may miss long-distance references
- Entity consistency mechanism faces scalability constraints with large graphs requiring "filtering strategies"
- LLM evaluator systematically overestimates quality scores, particularly in downstream stages

## Confidence

- **High Confidence**: Structural connectivity improvements across hierarchical stages (FGC metrics from Table 3 show consistent progression)
- **Medium Confidence**: Coreference resolution effectiveness within 3-sentence windows (supported by ablation but limited long-range validation)
- **Medium Confidence**: Entity consistency benefits (Ablation Table 6 shows improvements but lacks corpus validation)
- **Low Confidence**: Semantic accuracy scores (human-LLM agreement gaps suggest systematic evaluator bias)

## Next Checks

1. **Long-range coreference validation**: Test the framework on documents with known multi-sentence coreference chains to quantify accuracy degradation beyond 3-sentence windows
2. **Scalability stress test**: Process a 50-document corpus through all stages and measure entity consistency prompt size vs. filtering effectiveness tradeoffs
3. **Evaluator bias quantification**: Have independent human raters score a stratified sample of triples from each stage to calibrate LLM evaluator scores and establish true accuracy baselines