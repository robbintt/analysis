---
ver: rpa2
title: 'Float8@2bits: Entropy Coding Enables Data-Free Model Compression'
arxiv_id: '2601.22787'
source_url: https://arxiv.org/abs/2601.22787
tags:
- entquant
- quantization
- compression
- bits
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper tackles the collapse of data\u2011free post\u2011training\
  \ quantization when compression pushes below 4 bits, a regime where existing methods\
  \ either require costly calibration data or suffer severe accuracy loss. EntQuant\
  \ breaks the tight link between bit\u2011width and storage by first quantizing weights\
  \ and then applying high\u2011throughput GPU entropy coding, optimizing a rate\u2011\
  distortion objective without any data."
---

# Float8@2bits: Entropy Coding Enables Data-Free Model Compression

## Quick Facts
- **arXiv ID:** 2601.22787  
- **Source URL:** https://arxiv.org/abs/2601.22787  
- **Reference count:** 40  
- **Primary result:** EntQuant attains 2.1 bits/parameter on LLaMA‑2 13 B with only ‑1.6 % perplexity loss, fully data‑free and in < 30 min for a 70 B model.

## Executive Summary
EntQuant introduces a data‑free post‑training quantization pipeline that first quantizes model weights and then applies high‑throughput GPU entropy coding. By optimizing a rate‑distortion objective, the method decouples the effective bits per parameter from the underlying numeric format, enabling extreme compression (≈2 bits/parameter) without calibration data. Experiments on LLaMA‑2 13 B and instruction‑tuned models show minimal perplexity and downstream accuracy degradation, while preserving inference speed within a modest overhead.

## Method Summary
The approach consists of two stages. First, weights are uniformly quantized to a low‑bit representation (e.g., 2 bits). Second, a fast entropy coder (GPU‑accelerated) compresses the quantized tensors, guided by a rate‑distortion loss that balances compression size (rate) against reconstruction error (distortion). The entire pipeline is model‑agnostic, requires no training data, and runs in under 30 minutes even for a 70 B‑parameter transformer, leveraging parallel GPU kernels for both quantization and coding.

## Key Results
- **2.1 bits/parameter** on LLaMA‑2 13 B with perplexity 5.74 (‑1.6 % vs. 16‑bit baseline).  
- **LM‑Eval accuracy:** 71.7 % (‑1.6 %); at 2 bits accuracy 68.6 % (‑5.8 % vs. 72.8 % baseline), outperforming HQQ and NF4 which collapse.  
- **Instruction‑tuned models:** negligible loss on GSM8K CoT and IFEval; inference‑throughput penalty remains modest.

## Why This Works (Mechanism)
EntQuant’s effectiveness stems from three intertwined mechanisms:

1. **Entropy Coding Decoupling** – By compressing quantized weights with a lossless entropy coder, the *effective* bits per parameter become independent of the raw numeric format, allowing far lower storage footprints than the nominal bit‑width suggests.  
2. **Rate‑Distortion Optimization** – The training‑free objective explicitly trades off compression rate against reconstruction distortion, ensuring that the most information‑dense bits are retained while redundant patterns are eliminated.  
3. **GPU‑Accelerated Throughput** – Specialized kernels perform both quantization and entropy coding in parallel, making the pipeline fast enough to handle models with tens of billions of parameters within minutes.

## Foundational Learning
| Concept | Why needed | Quick check |
|--------|------------|-------------|
| Entropy coding for model weights | Provides lossless compression that extracts statistical redundancy after quantization. | Does the paper specify the coder (e.g., ANS, Huffman) and its GPU implementation? |
| Rate‑distortion loss | Balances model fidelity against compression size without any data. | Is the loss formulation (λ·rate + distortion) explicitly given? |
| Data‑free quantization | Removes dependence on calibration datasets, enabling truly post‑training compression. | Are the quantization steps described as purely statistical (e.g., min‑max, k‑means) without data? |
| Parallel GPU kernels | Guarantees the < 30 min runtime even for 70 B models. | Does the implementation detail kernel launch configurations or memory‑bandwidth considerations? |
| Model‑agnostic pipeline | Allows the same method to be applied across diverse transformer architectures. | Are experiments shown on more than one model family (e.g., LLaMA‑2, instruction‑tuned variants)? |

## Architecture Onboarding
**Component map**  
Quantizer → Rate‑Distortion Optimizer → GPU Entropy Coder → Compressed Model Archive  

**Critical path**  
1. Weight quantization (per‑tensor) → 2. Compute rate‑distortion loss to select optimal coding parameters → 3. Parallel entropy encoding of all quantized tensors.

**Design tradeoffs**  
- *Bit‑width vs. entropy efficiency*: Lower nominal bits increase compression but may reduce coder effectiveness; the rate‑distortion term mitigates this.  
- *Throughput vs. coding complexity*: Simpler coders run faster on GPU but may achieve lower compression ratios; the authors favor high‑throughput coders.  
- *Data‑free simplicity vs. potential accuracy*: Eliminating calibration data speeds deployment but can miss data‑specific distribution nuances.

**Failure signatures**  
- Unexpected spikes in perplexity (> 5 % loss) indicating distortion dominates.  
- Compression time exceeding 30 min for large models, suggesting kernel inefficiencies or memory bottlenecks.  
- Inference‑throughput drop > 20 % due to decompression overhead.

**First 3 experiments**  
1. Run the full EntQuant pipeline on LLaMA‑2 13 B and verify the reported 2.1 bits/parameter and perplexity 5.74.  
2. Compare against HQQ and NF4 at the same 2‑bit budget to confirm collapse avoidance.  
3. Measure end‑to‑end compression time on a 70 B model using the same GPU hardware to validate the < 30 min claim.

## Open Questions the Paper Calls Out
- How does EntQuant perform on non‑decoder‑only architectures (e.g., encoder‑only BERT, vision transformers)?  
- What are the limits of compression below 2 bits per parameter, and does the rate‑distortion framework remain stable?  
- Can the entropy coding stage be further optimized for newer GPU architectures or specialized accelerators?  
- How robust is the method to extreme out‑of‑distribution inputs when the model is later fine‑tuned?  
- Are there theoretical guarantees on the optimality of the chosen rate‑distortion trade‑off in a data‑free setting?

## Limitations
- Runtime and hardware specifications are not fully disclosed, making the < 30 min claim hard to verify.  
- Generalisation beyond LLaMA‑2 and a few instruction‑tuned models remains untested.  
- No confidence intervals or extensive ablations are provided, limiting statistical robustness of reported gains.

## Confidence
- **Entropy‑coding decoupling of bits → High** – Conceptually sound and aligns with compression literature.  
- **2.1 bits/param with ≤ 2 % perplexity loss → Medium** – Plausible but needs experimental verification.  
- **< 30 min compression for 70 B model → Low** – Dependent on undocumented hardware/software stack.  
- **Outperforming HQQ/NF4 at 2 bits → Medium** – Requires side‑by‑side replication under identical conditions.

## Next Checks
1. **Extract the exact rate‑distortion formulation and entropy coder details** from the full paper, then re‑implement the pipeline to confirm the described steps.  
2. **Re‑run the 13 B LLaMA‑2 experiment** on comparable GPUs (e.g., A100 80 GB), measuring bits/parameter, perplexity, and LM‑Eval accuracy; compare against the reported 2.1 bits/param and 5.74 perplexity.  
3. **Benchmark compression time and inference throughput** for a 70 B model using the same hardware and batch settings as the authors; verify the < 30 min compression claim and quantify any throughput overhead.