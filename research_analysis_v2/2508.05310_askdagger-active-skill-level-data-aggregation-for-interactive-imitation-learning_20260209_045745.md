---
ver: rpa2
title: 'ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning'
arxiv_id: '2508.05310'
source_url: https://arxiv.org/abs/2508.05310
tags:
- novice
- demonstrations
- learning
- askdagger
- success
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces ASkDAgger, a novel interactive imitation\
  \ learning framework that improves upon existing methods by incorporating the novice\u2019\
  s planned actions during active queries. The method leverages teacher feedback in\
  \ three ways: S-Aware Gating (SAG) dynamically adjusts the gating threshold to track\
  \ sensitivity, specificity, or minimum system success rate; Foresight Interactive\
  \ Experience Replay (FIER) recasts valid and relabeled novice action plans into\
  \ demonstrations; and Prioritized Interactive Experience Replay (PIER) prioritizes\
  \ replay based on uncertainty, novice success, and demonstration age."
---

# ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning

## Quick Facts
- **arXiv ID:** 2508.05310
- **Source URL:** https://arxiv.org/abs/2508.05310
- **Reference count:** 40
- **Primary result:** Reduces annotation burden while improving generalization and adaptation speed in interactive imitation learning

## Executive Summary
ASkDAgger introduces an active imitation learning framework that leverages the novice agent's planned actions during queries to reduce annotation effort and improve generalization. The method combines three key innovations: S-Aware Gating dynamically adjusts query thresholds to track performance metrics; Foresight Interactive Experience Replay uses planned actions for validation and relabeling; and Prioritized Interactive Experience Replay focuses training on uncertain failures and recent demonstrations. Experiments across MNIST, simulated manipulation tasks, and real-world assembly demonstrate reduced annotation requirements, better generalization to unseen scenarios, and faster adaptation to domain shifts.

## Method Summary
ASkDAgger operates through an interactive loop where a novice policy generates actions with uncertainty estimates. When uncertainty exceeds a dynamically adjusted threshold (SAG), the system queries a teacher who can validate, relabel, or correct the novice's planned action. Valid actions are executed and stored as demonstrations, while relabeling turns failures into successes by identifying alternative achieved goals. Training samples are prioritized based on uncertainty, success rate, and age (PIER) to improve sample efficiency. The method specifically addresses covariate shift in imitation learning by continuously aggregating relevant data during interaction.

## Key Results
- Reduces annotation burden by utilizing validation and relabeling instead of pure correction
- Improves generalization to unseen objects and scenarios in CLIPort benchmark tasks
- Demonstrates faster adaptation to domain shifts through prioritized experience replay
- Successfully tracks desired sensitivity/specificity metrics in active learning settings

## Why This Works (Mechanism)

### Mechanism 1: S-Aware Gating (SAG)
SAG models gating as semi-supervised logistic regression, using uncertainty as input and teacher feedback as target. It imputes pseudo-labels for non-queried steps using the fitted model to track sensitivity, specificity, or minimum success rates. The system assumes uncertainty correlates linearly with failure probability.

### Mechanism 2: Foresight Interactive Experience Replay (FIER)
FIER presents the novice's planned action to the teacher instead of immediately requesting correction. The teacher can validate the action (saving demonstration effort), relabel it if it achieves a different valid goal (inspired by Hindsight Experience Replay), or provide standard correction. This reduces annotation burden while expanding the training dataset.

### Mechanism 3: Prioritized Interactive Experience Replay (PIER)
PIER assigns priority to demonstrations based on failure rate, uncertainty level, and recency. It prioritizes confident errors (low uncertainty failures) and recent samples to handle domain shifts, while suppressing confident successes. This improves adaptation speed compared to uniform sampling.

## Foundational Learning

- **Covariate Shift in Imitation Learning:** Understanding why policies trained via pure Behavioral Cloning can fail catastrophically at test time despite low training loss is crucial for appreciating ASkDAgger's interactive data aggregation approach.

- **Uncertainty Quantification (e.g., MC Dropout):** SAG relies entirely on a scalar uncertainty metric to trigger queries. Understanding how neural networks estimate their own uncertainty (entropy or variance over stochastic forward passes) is essential for implementing the gating logic.

- **Hindsight Experience Replay (HER):** FIER's relabeling mechanism is explicitly inspired by HER. Understanding that "failed" trajectories can become "successful" ones by changing the goal is critical for implementing the relabeling component.

## Architecture Onboarding

- **Component map:** Policy → SAG Module → Teacher Interface → Replay Buffer → PIER Sampler → Policy
- **Critical path:** Observe (o, g) → Infer (a, u) → SAG Check (u ≥ γ?) → Query Mode → FIER Query → Execute → Store → PIER Update → Train → Update SAG
- **Design tradeoffs:** Gating Mode (Sensitivity vs Specificity) balances safety against autonomy; Validation vs Annotation cost depends on cognitive demands of each task
- **Failure signatures:** Oscillating threshold indicates noisy uncertainty signal; Stagnation suggests over-prioritization of hard samples; No relabeling indicates goal-mapping issues
- **First 3 experiments:** 1) MNIST Sweep to verify SAG implementation, 2) Ablation on Validation to measure annotation cost, 3) Domain Shift Test to verify adaptation speed

## Open Questions the Paper Calls Out
None

## Limitations
- **Goal-space mapping dependency:** FIER's relabeling mechanism requires a well-defined goal-space mapping that is not detailed for complex language-conditioned tasks
- **Uncertainty signal reliability:** SAG effectiveness depends on novice uncertainty correlating with actual failure probability, which may not hold for all network architectures
- **Task-specific evaluation:** Results are demonstrated on specific tasks (MNIST, CLIPort, engine assembly) with uncertain generalizability to other domains

## Confidence

- **S-Aware Gating (SAG):** High confidence - mathematically well-defined with strong MNIST validation
- **Foresight Interactive Experience Replay (FIER):** Medium confidence - concept is sound but implementation details for complex tasks are underspecified
- **Prioritized Interactive Experience Replay (PIER):** High confidence - straightforward prioritization logic aligned with established principles
- **Overall Performance Claims:** Medium-High confidence - convincing ablation studies but component contributions are difficult to isolate

## Next Checks

1. **Validate SAG on MNIST:** Reproduce the MNIST active learning experiment to verify SAG implementation correctly tracks desired sensitivity/specificity curves before proceeding to complex simulation

2. **Test FIER Relabeling Logic:** Implement a simple simulated task (e.g., grid navigation with discrete goals) to validate the FIER relabeling mechanism and ensure the system can identify when failed actions achieve different valid goals

3. **Ablate Validation vs. Annotation:** Run simulation with "Validation" disabled in FIER to measure the increase in annotation cost and quantify the practical benefit of validation over standard annotation queries