---
ver: rpa2
title: Training Users Against Human and GPT-4 Generated Social Engineering Attacks
arxiv_id: '2502.01764'
source_url: https://arxiv.org/abs/2502.01764
tags:
- emails
- phishing
- training
- participants
- gpt-4
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the detection of human-generated versus
  AI-generated phishing emails using a novel experimental paradigm. The experiment
  compares the effectiveness of human-written emails, GPT-4-written emails, and emails
  co-created by humans and GPT-4.
---

# Training Users Against Human and GPT-4 Generated Social Engineering Attacks

## Quick Facts
- arXiv ID: 2502.01764
- Source URL: https://arxiv.org/abs/2502.01764
- Reference count: 40
- Primary result: Emails co-created by humans and GPT-4 are hardest to detect; IBL model predicts user miscategorization and enables adaptive training

## Executive Summary
This paper investigates detection of human versus AI-generated phishing emails through a novel experimental paradigm comparing human-written, GPT-4-written, and human-GPT-4 co-created emails. The study reveals that human-authored emails styled by GPT-4 pose the greatest detection challenge, with significant interaction effects between author and style. A key finding is the identification of an "AI-writing bias" where participants over-classify AI-perceived emails as phishing, degrading ham detection accuracy. To address these challenges, the authors propose an Instance-Based Learning (IBL) cognitive model that predicts user miscategorization risk and enables adaptive email selection during training.

## Method Summary
The study employs a 2×2 between-subjects design with 207 MTurk participants categorizing 60 phishing/ham emails across three phases: 10 pre-training trials, 40 training trials with feedback, and 10 post-training trials. Emails were generated in four conditions: human-written/plain-text, human-written/GPT-4-styled, GPT-4-written/plain-text, and GPT-4-written/GPT-4-styled. The IBL model uses GPT-4 embeddings to predict categorization choices and enables adaptive email selection during training by maximizing predicted miscategorization probability.

## Key Results
- Human-authored emails styled by GPT-4 are most difficult for users to correctly categorize (significant interaction effect, F = 14.344, p < 0.001)
- Participants exhibit "AI-writing bias" - they over-classify AI-perceived emails as phishing, degrading ham detection accuracy
- IBL model simulations show adaptive email selection improves training outcomes compared to random selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Participants who perceive emails as AI-generated exhibit a bias toward categorizing them as phishing, degrading ham detection accuracy.
- Mechanism: The "AI-writing bias" causes users to over-attend to perceived AI markers (styling, formatting) rather than content-based phishing indicators. This is related to algorithm aversion, where users assume algorithmic outputs are suspect.
- Core assumption: Participants can accurately perceive AI-generated content (though the paper notes people generally demonstrate poor ability to detect AI-written content).
- Evidence anchors:
  - [abstract] "identifies a novel AI-writing bias, where participants assume AI-written emails are more likely to be phishing attempts, leading to worse categorization performance"
  - [section 3.3] Figure 4 regression shows positive slope between AI-identification and phishing categorization; higher R² and slopes in GPT-4 styled conditions
  - [corpus] Related work on algorithm aversion exists (Dietvorst et al. 2014, cited in paper), but direct corpus evidence on AI-writing bias in phishing is limited.
- Break condition: If users cannot reliably distinguish AI from human writing, the bias may not systematically affect detection; if training explicitly debunks this assumption, bias effects may diminish.

### Mechanism 2
- Claim: Human-authored emails styled by GPT-4 (HTML/CSS/JS) are most difficult for users to correctly categorize.
- Mechanism: The combination of human-crafted persuasive text (exploiting psychological vulnerabilities) with GPT-4-generated professional styling creates emails that bypass both content-based and format-based detection heuristics. Human text avoids AI safety filters; GPT-4 styling adds credibility markers.
- Core assumption: The difficulty is due to complementarity of human persuasion expertise and AI formatting capability, not merely increased visual complexity.
- Evidence anchors:
  - [abstract] "emails co-created by humans and GPT-4 pose the greatest challenge to end-users"
  - [section 3.2] Significant interaction effect (F = 14.344, p < 0.001, η²p = 0.066); human-written GPT-4-styled condition showed lowest improvement (μ = 0.015) vs GPT-4-written GPT-4-styled (μ = 0.104)
  - [corpus] Corpus lacks direct replication of human-AI co-creation phishing difficulty; this appears to be a novel finding.
- Break condition: If GPT-4's safety mechanisms are bypassed via advanced prompt engineering, fully AI-generated phishing may become equally or more effective.

### Mechanism 3
- Claim: An Instance-Based Learning (IBL) model using GPT-4 email embeddings can predict user miscategorization risk and improve training via adaptive email selection.
- Mechanism: IBL stores (situation, action, outcome) instances in memory. For a new email, activation is computed based on similarity (cosine similarity of embeddings) and recency. Blended value predicts categorization choice. Training selection maximizes emails where the model predicts high miscategorization probability.
- Core assumption: GPT-4 embeddings capture decision-relevant features of emails; IBL's similarity-based retrieval approximates human judgment processes.
- Evidence anchors:
  - [abstract] "Simulations demonstrate that the IBL model can improve training outcomes by selecting optimal emails to show participants"
  - [section 3.4] Figure 5 shows simulated IBL agents with IBL-based email selection achieve higher pre-post improvement than random selection
  - [corpus] Corpus includes work on LLM embeddings for cognitive models (Malloy & Gonzalez 2024, cited), but adaptive training selection specifically for phishing lacks direct external validation.
- Break condition: If embedding similarity does not correlate with human-perceived phishing indicators, or if individual differences in learning strategies are too large, the model may not generalize.

## Foundational Learning

- **Instance-Based Learning Theory (IBLT)**
  - Why needed here: The IBL model is the core predictive mechanism; understanding activation, retrieval probability, and blended value is essential to interpret the proposed training system.
  - Quick check question: Given three past instances with utilities [+1, -1, +1] and activations [0.8, 0.5, 0.3], what is the blended value for the corresponding action?

- **LLM Embeddings and Cosine Similarity**
  - Why needed here: Email similarity is computed via cosine similarity of GPT-4 embeddings; this determines which past instances are most activated and thus influence predictions.
  - Quick check question: If two emails have embeddings with cosine similarity 0.95, how does this affect the activation term in the IBL equation compared to a pair with similarity 0.3?

- **Interaction Effects in Factorial Designs**
  - Why needed here: The paper's key finding is an interaction between author and style; understanding that main effects alone cannot explain the results is critical.
  - Quick check question: If Author A outperforms Author B in Style X but underperforms in Style Y, what statistical pattern would you report?

## Architecture Onboarding

- **Component map:**
  - Email Generation Pipeline: Human experts write base emails → GPT-4 rewrites text OR stylizes with HTML/CSS/JS → 4 conditions (author × style)
  - Embedding Module: GPT-4 generates vector embeddings for each email; stored as instance attributes
  - IBL Cognitive Model: Stores (email embedding, categorization choice, feedback outcome) instances; computes activation via recency + similarity + noise; outputs blended value and action probabilities
  - Adaptive Selection Module: Given participant's current memory state, iterates over all candidate emails, predicts miscategorization probability, selects email maximizing predicted error
  - Feedback Loop: Participant categorizes → receives point feedback (-1 or +1) → instance stored in participant/model memory

- **Critical path:**
  1. Pre-training (10 trials, no feedback, random selection) → establishes baseline
  2. Training (40 trials, with feedback, adaptive selection) → model traces learning, selects challenging emails
  3. Post-training (10 trials, no feedback, random selection) → measures improvement

- **Design tradeoffs:**
  - **Default vs fitted IBL parameters:** Paper uses defaults (d=0.5, μ=1, ω=1, σ=0.25); fitting to individuals may improve accuracy but reduces generalizability
  - **Random vs adaptive selection during training:** Adaptive improves simulated outcomes but has not yet been validated on real human participants
  - **Embedding dimensionality vs interpretability:** GPT-4 embeddings are high-dimensional and opaque; alternative attribute representations (e.g., phishing indicator features) may be more interpretable but less flexible

- **Failure signatures:**
  - Model predictions diverge from human behavior → check if embedding similarity aligns with human-perceived similarity
  - No improvement with adaptive selection → verify participant memory update is correctly traced; check if selected emails are too difficult (frustration) or too easy (boredom)
  - AI-writing bias persists → explicit debiasing feedback may be needed; current model does not directly address this bias

- **First 3 experiments:**
  1. **Replicate simulation with held-out emails:** Train IBL model on 75% of human participant data, test adaptive selection on remaining 25%, compare to random baseline
  2. **Ablate embedding similarity:** Replace GPT-4 embeddings with handcrafted phishing indicator features (urgent language, links, sender address) and compare prediction accuracy
  3. **Validate adaptive selection with human participants:** Run new study with real-time IBL-based email selection; measure pre-post improvement vs random control condition

## Open Questions the Paper Calls Out
- Does Instance-Based Learning (IBL) model-driven email selection improve training outcomes with real human participants?
- What are the mechanisms underlying the "AI-writing bias" where participants assume AI-generated content is more likely to be phishing?
- Would more advanced prompt engineering enable GPT-4 to generate more convincing phishing emails than human-generated ones?

## Limitations
- The AI-writing bias finding relies on participants' self-reported perceptions of AI-generated content, which are known to be unreliable
- IBL model's effectiveness in adaptive email selection is currently only validated through simulation, not human trials
- Study's external validity is limited by MTurk sample and controlled laboratory conditions

## Confidence
- High confidence: Experimental methodology and statistical analysis are sound; author×style interaction effect is robust (p < 0.001)
- Medium confidence: AI-writing bias mechanism and its practical significance in real-world settings
- Low confidence: IBL model's simulation results translating to actual human training improvements

## Next Checks
1. Conduct a new human participant study with real-time IBL-based adaptive email selection during training, comparing pre-post improvement against a random selection control group
2. Perform cross-validation of the IBL model by training on 75% of participant data and testing adaptive selection performance on the remaining 25%
3. Replicate the AI-writing bias findings with a debiasing intervention (e.g., explicit feedback that AI-written content is not inherently phishing) to test whether the bias can be mitigated through training