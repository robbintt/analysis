---
ver: rpa2
title: 'SPAR: Session-based Pipeline for Adaptive Retrieval on Legacy File Systems'
arxiv_id: '2512.12938'
source_url: https://arxiv.org/abs/2512.12938
tags:
- retrieval
- file
- metadata
- spar
- vector
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SPAR introduces a session-based RAG pipeline that eliminates the
  need for persistent vector databases by leveraging metadata indices and on-demand
  workspace construction. Instead of mirroring entire file systems, SPAR uses enterprise-defined
  tags and structured metadata to filter files before creating temporary vector databases
  scoped to specific user sessions.
---

# SPAR: Session-based Pipeline for Adaptive Retrieval on Legacy File Systems

## Quick Facts
- **arXiv ID**: 2512.12938
- **Source URL**: https://arxiv.org/abs/2512.12938
- **Reference count**: 40
- **Primary result**: SPAR achieves 89.5% retrieval accuracy vs 80.3% for conventional RAG, with more than halved average retrieval times and improved answer accuracy from 65.1% to 68.1%

## Executive Summary
SPAR introduces a session-based RAG pipeline that eliminates the need for persistent vector databases by leveraging metadata indices and on-demand workspace construction. Instead of mirroring entire file systems, SPAR uses enterprise-defined tags and structured metadata to filter files before creating temporary vector databases scoped to specific user sessions. This approach reduces computational overhead, improves retrieval accuracy, and enables more transparent and controllable filtering. In a biomedical literature experiment, SPAR achieved 89.5% retrieval accuracy compared to 80.3% for conventional RAG, with average retrieval times reduced by more than half. Answer accuracy also improved from 65.1% to 68.1%. Theoretical analysis confirms SPAR's advantages in construction, search, and memory efficiency, particularly for enterprise-scale legacy systems where metadata quality and task-specific retrieval are critical.

## Method Summary
SPAR operates on legacy file systems by constructing on-demand, session-scoped vector databases rather than maintaining persistent global indices. The system uses enterprise-defined tags and structured metadata to filter files before creating temporary vector databases for specific user sessions. The pipeline involves parsing natural language queries to extract keywords and metadata, performing hierarchical tag expansion, filtering files through the metadata index, constructing temporary vector databases for the filtered subset, and executing ANN search within the workspace. The approach was evaluated on a biomedical corpus of 1,000 PMC articles with MeSH tags, comparing retrieval accuracy and latency against a conventional global vector database baseline using Qwen2.5-VL 3B as the LLM.

## Key Results
- Achieved 89.5% retrieval accuracy compared to 80.3% for conventional RAG
- Reduced average retrieval times by more than half
- Improved answer accuracy from 65.1% to 68.1%
- Demonstrated superior computational efficiency through on-demand workspace construction

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Metadata-first filtering reduces retrieval search space before vector computation, improving both precision and latency.
- **Mechanism:** SPAR applies structured metadata constraints and hierarchical tag matching as a first-stage filter, yielding $N_{filtered} \ll N$ candidates before any embedding occurs. This shrinks the vector index size from corpus-scale to task-scale.
- **Core assumption:** Enterprise-defined tags and metadata are available and semantically meaningful for the domain.
- **Evidence anchors:** Abstract states SPAR uses enterprise-defined tags and structured metadata to filter files before creating temporary vector databases. Section 3.2 explains the two-stage process substantially narrows the candidate pool.
- **Break condition:** If metadata is sparse, inconsistent, or missing for large portions of the file system, recall degrades because relevant files are filtered out before embedding.

### Mechanism 2
- **Claim:** On-demand session-scoped vector databases eliminate synchronization overhead and reduce persistent storage costs.
- **Mechanism:** Workspaces construct temporary vector indices only for the filtered subset relevant to that session. Indices are discarded or archived after session completion, removing the need for continuous sync with the underlying file system.
- **Core assumption:** Retrieval tasks are episodic and scoped; users don't require instant access to the entire corpus simultaneously.
- **Evidence anchors:** Abstract mentions eliminating the need for persistent vector databases through on-demand workspace construction. Section 4.1 provides theoretical analysis showing SPAR is preferable when $W \cdot p \ll 1$.
- **Break condition:** High-frequency, broad-scope querying across many overlapping workspaces causes redundant embedding computation and storage duplication that exceeds global index costs.

### Mechanism 3
- **Claim:** Hierarchical tag expansion enables multi-granularity retrieval while maintaining interpretability of filtering decisions.
- **Mechanism:** Tags are organized in a parent-child taxonomy. When a query matches an ancestor tag, all descendants are implicitly included via hierarchy-aware expansion, with pruning to avoid redundancy.
- **Core assumption:** A domain-appropriate hierarchical taxonomy exists or can be constructed (manually or via LLM).
- **Evidence anchors:** Section 3.2 explains intermediate nodes can be defined manually by domain experts or automatically induced by LLMs. Section 5.2 describes MeSH's hierarchical TreeNumber structure supporting tag expansion.
- **Break condition:** Automatically induced hierarchies produce over-grouping or mis-grouping, reducing retrieval precision and user trust.

## Foundational Learning

- **Concept: Approximate Nearest Neighbor (ANN) search and HNSW indices**
  - Why needed here: SPAR relies on ANN for both tag similarity lookup and session-scoped vector search. Understanding how HNSW scales with $N$ vs. $N_{filtered}$ is essential to evaluate theoretical claims.
  - Quick check question: Given a corpus of 1M vectors and a filtered subset of 10K, why does HNSW query latency decrease even if you increase `efSearch` for higher recall?

- **Concept: RAG pipeline architecture (retrieve-then-generate)**
  - Why needed here: SPAR modifies the standard RAG pipeline by inserting metadata pre-filtering and workspace scoping. You need to understand where SPAR diverges from conventional designs.
  - Quick check question: In a conventional RAG pipeline, when is metadata typically applied—before or after vector similarity search? How does SPAR change this order?

- **Concept: Hierarchical taxonomies and DAG structures**
  - Why needed here: SPAR's tag expansion relies on parent-child relationships. Understanding DAG traversal and ancestor-descendant inference is necessary for implementing the filtering logic.
  - Quick check question: If a user query matches tag G07.025, should documents tagged only with G07.025.133 be included? Why or why not?

## Architecture Onboarding

- **Component map:**
  - Metadata Index (PostgreSQL) -> Tag Vector Store (Pinecone/FAISS) -> Query Parser -> Workspace Manager -> Temporary Vector Database -> LLM Agent

- **Critical path:**
  1. User submits natural language query → Query Parser extracts keywords + metadata
  2. Keywords embedded → Tag similarity search in Tag Vector Store → Hierarchical tag expansion
  3. Metadata Index filters files matching expanded tags AND metadata constraints → $N_{filtered}$ candidates
  4. Candidates processed/cached → Temporary Vector Database constructed for workspace
  5. User query embedded → ANN search within workspace → Top-k passages retrieved → LLM generates response

- **Design tradeoffs:**
  - On-demand vs. global indexing: Lower persistent storage and sync overhead vs. repeated workspace construction cost for overlapping sessions
  - Metadata dependency: Higher precision and interpretability vs. vulnerability to sparse/inconsistent metadata
  - Hierarchy depth: Broader query flexibility vs. risk of over-inclusive expansion diluting precision

- **Failure signatures:**
  - Zero-recall workspace: Metadata constraints too strict or tag expansion misses relevant terms; users see empty results
  - Latency spike on first query: Workspace construction for large $N_{filtered}$ with cold cache
  - Stale embeddings: Cached representations not invalidated after file modification (cache invalidation logic failure)

- **First 3 experiments:**
  1. Reproduce the biomedical toy experiment: Build Metadata Index from 1000 PMC articles with MeSH tags; compare retrieval accuracy and latency vs. global Pinecone baseline using identical LLM (Qwen2.5-VL 3B)
  2. Metadata quality stress test: Randomly delete 20%, 40%, 60% of file-tag assignments; measure recall degradation to characterize break conditions
  3. Workspace overlap simulation: Create 10 workspaces with 30% file overlap; measure cumulative memory footprint and embedding redundancy to validate the $\delta \cdot W \cdot E[N_{filtered}] < N$ condition

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can incremental or shared indexing mechanisms be implemented to reduce redundant vector construction and storage duplication across active SPAR workspaces?
- Basis in paper: Section 6.4 lists "incremental or shared indexing across workspaces" as a specific opportunity for future research to mitigate the trade-offs of on-demand design.
- Why unresolved: The current architecture constructs ephemeral, session-specific indexes, which leads to processing overhead and storage redundancy when multiple workspaces access similar files.
- What evidence would resolve it: A modified SPAR prototype demonstrating cross-workspace index sharing that lowers memory usage and construction time without sacrificing session isolation.

### Open Question 2
- Question: What adaptive caching policies are required to optimize the trade-off between memory footprint and retrieval latency in high-throughput enterprise settings?
- Basis in paper: Section 6.4 explicitly identifies "adaptive caching policies" as a future direction to address the "transient duplication" of embeddings in active workspaces.
- Why unresolved: While file-level caching exists, the system lacks sophisticated policies to manage memory pressure in multi-user environments with overlapping file requests.
- What evidence would resolve it: Empirical data from a multi-user benchmark comparing different caching strategies (e.g., LRU vs. semantic clustering) showing sustained retrieval speeds under constrained memory.

### Open Question 3
- Question: How can automated metadata generation pipelines be improved to guarantee consistency and correct hierarchical grouping for legacy files lacking manual tags?
- Basis in paper: Section 6.4 calls for "more reliable metadata generation pipelines," while Section 6.3 notes that LLM-assisted tagging introduces risks of inconsistency and "mis-grouping" in the hierarchy.
- Why unresolved: Automated tagging is necessary for scalability but currently risks degrading retrieval accuracy if the generated tag hierarchy does not align with domain logic.
- What evidence would resolve it: A study measuring the alignment between LLM-generated taxonomies and expert-curated structures, correlated with retrieval recall metrics.

## Limitations

- Performance critically depends on availability and quality of enterprise-defined tags and structured metadata
- Scalability boundaries remain unclear, particularly for high-frequency, broad-scope querying patterns
- Hierarchical tag expansion performance with automatically induced taxonomies remains unverified outside curated domains

## Confidence

- **High Confidence**: The computational and memory efficiency advantages of on-demand session-scoped indexing over persistent global databases are theoretically sound and mathematically proven
- **Medium Confidence**: The retrieval accuracy improvements and latency reductions are demonstrated on a controlled biomedical corpus with high-quality metadata, but may not generalize to less structured enterprise environments
- **Low Confidence**: The scalability analysis lacks empirical validation across diverse query patterns and file system characteristics

## Next Checks

1. **Metadata Quality Stress Test**: Systematically degrade metadata coverage (20%, 40%, 60% random deletion) and measure recall degradation to characterize SPAR's break conditions in real-world scenarios

2. **Workspace Overlap Simulation**: Create multiple overlapping workspaces with varying file overlap percentages to empirically determine the threshold where SPAR's cumulative overhead exceeds global indexing benefits

3. **Cross-Domain Generalization**: Implement SPAR on a non-biomedical corpus (e.g., legal documents, software repositories) with automatically induced metadata/taxonomy to validate hierarchical tag expansion performance outside curated domains