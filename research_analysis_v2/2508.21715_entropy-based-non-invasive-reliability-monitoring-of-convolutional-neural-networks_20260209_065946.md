---
ver: rpa2
title: Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks
arxiv_id: '2508.21715'
source_url: https://arxiv.org/abs/2508.21715
tags:
- adversarial
- entropy
- detection
- information
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of detecting adversarial inputs
  to convolutional neural networks without modifying the model architecture or retraining.
  The proposed method uses parallel monitoring of activation entropy in early convolutional
  and pre-classification layers, leveraging information-theoretic signatures that
  distinguish clean from adversarial inputs.
---

# Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks

## Quick Facts
- arXiv ID: 2508.21715
- Source URL: https://arxiv.org/abs/2508.21715
- Reference count: 0
- Primary result: Entropy monitoring detects adversarial inputs with 90% accuracy in early CNN layers using parallel non-invasive hooks

## Executive Summary
This work introduces a non-invasive method for detecting adversarial inputs to convolutional neural networks by monitoring activation entropy in early and late layers. The approach leverages information-theoretic signatures that emerge when adversarial perturbations shift activation distributions, creating detectable entropy changes without requiring model modification or retraining. Experimental results on VGG-16 with FGSM attacks demonstrate high detection accuracy (90% early layers, 80% pre-classification) with zero false positives in early layers, while adding only 5-10% computational overhead suitable for real-time deployment.

## Method Summary
The method monitors activation entropy through parallel hooks at two critical layers: the first convolutional layer (features.0) and the pre-classification fully connected layer (classifier.3). Forward hooks capture activations during inference without modifying the computational graph. Adaptive binning creates histograms of activations, which are normalized and processed using Shannon entropy. Baseline distributions are built from clean validation data, and fixed thresholds detect anomalies when test entropy falls outside clean ranges. The approach exploits the observation that adversarial perturbations systematically increase entropy in early layers while decreasing it in late layers.

## Key Results
- Early convolutional layers detect adversarial inputs with 90% accuracy and 0% false positive rate
- Pre-classification layers achieve 80% detection accuracy with 20% false positive rate
- Adversarial inputs shift early-layer activation entropy by ~7%, late-layer entropy decreases by ~0.10 bits
- Method adds only 5-10% computational overhead, enabling real-time monitoring
- Detection thresholds set at 5.12 bits (early) and 4.18 bits (late) based on clean/adversarial boundary analysis

## Why This Works (Mechanism)

### Mechanism 1: Early-Layer Entropy Elevation Under Adversarial Perturbation
Adversarial perturbations systematically increase activation entropy in early convolutional layers by ~7%, creating detectable distribution shift. FGSM perturbations inject high-frequency gradient-aligned noise that creates additional edge-like and texture-like artifacts. The first convolutional layer (64 filters, 3×3 kernels) interprets these as spurious features, increasing information content in activation distributions.

### Mechanism 2: Pre-Classification Layer Entropy Compression
Adversarial inputs reduce entropy in late fully-connected layers, reflecting collapsed high-level representations that are "confidently wrong." By the pre-classification layer (4096 neurons), adversarial perturbations have been propagated through the network's decision boundary geometry, causing the network to activate fewer, more concentrated semantic features—increasing certainty but toward incorrect classes.

### Mechanism 3: Non-Invasive Parallel Hook Architecture
Forward hooks can extract activations, compute entropy, and detect anomalies without modifying the model's computational graph or inference path. PyTorch forward hooks register callbacks at target layers (features.0, classifier.3). Activations are detached, stored, and processed asynchronously. Entropy computation uses adaptive binning with Shannon entropy formula. Detection compares against baseline distributions via fixed thresholds.

## Foundational Learning

- Concept: Shannon Entropy for Discrete Distributions
  - Why needed here: The method discretizes continuous activations into binned histograms, then computes H(X) = -Σ p(x) log₂ p(x). Understanding entropy as a measure of information content / uncertainty is essential for interpreting detection thresholds.
  - Quick check question: Given a histogram [0.5, 0.25, 0.25], compute its Shannon entropy in bits. (Answer: 1.5 bits)

- Concept: FGSM (Fast Gradient Sign Method) Attack
  - Why needed here: All experimental validation uses FGSM with ε=0.2. Understanding that FGSM perturbs inputs in the direction of gradient ascent on loss explains why early-layer activations show elevated entropy.
  - Quick check question: Write the FGSM perturbation formula and explain why ε controls the perceptibility-vs-effectiveness tradeoff.

- Concept: CNN Layer Hierarchy and Feature Abstraction
  - Why needed here: Detection exploits different entropy behaviors at shallow vs. deep layers. Early convolutions capture edges/textures; late FC layers encode semantic abstractions. The opposite entropy shift directions (increase early, decrease late) depend on this hierarchy.
  - Quick check question: In VGG-16, what computational role does features.0 serve vs. classifier.3, and why would adversarial noise affect them differently?

## Architecture Onboarding

- Component map:
  - Target Model: Pre-trained VGG-16 (PyTorch model zoo, ImageNet weights)
  - Monitoring Points: features.0 (first Conv2d, 64×224×224) and classifier.3 (second FC, 4096 neurons)
  - Hook Layer: PyTorch forward hooks registered at both layers
  - Entropy Computer: Adaptive binning → histogram → normalize → Shannon entropy
  - Baseline Profiler: Stores reference entropy distributions from N_train=18 clean batches (288 images)
  - Threshold Detector: Fixed τ comparing test entropy against clean/adversarial boundaries
  - Output: Binary detection decision per batch

- Critical path:
  1. Register forward hooks on features.0 and classifier.3 during model initialization
  2. Run clean validation images to build baseline entropy distributions (288 images, batch size 16)
  3. Set thresholds: τ_early = 5.1200 bits, τ_late = 4.1800 bits
  4. At inference: extract activations → compute entropy per batch → compare to thresholds → flag if outside clean range
  5. Asynchronous processing ensures no inference latency impact

- Design tradeoffs:
  - Batch-level vs. instance-level detection: Paper uses batch-wise (16 images) for statistical robustness; real-time streaming requires per-frame extension (not implemented)
  - Early vs. late layer monitoring: Early layers give 90% accuracy / 0% FPR; late layers give 80% accuracy / 20% FPR. Trade detection precision for semantic-level insight.
  - Binning granularity: Non-uniform bins optimize discrimination but require layer-specific calibration; changing architectures requires reprofiling.

- Failure signatures:
  - False negatives (20% at FC layer): Adversarial samples with entropy near clean distribution boundary; may occur with weaker perturbations (ε < 0.2)
  - False positives (0% at conv, 20% at FC): Clean images with unusual texture complexity may trigger early-layer false alarms (rare per paper)
  - Threshold drift: If input distribution shifts (lighting, sensor changes), baseline becomes invalid and requires recalibration
  - API-only deployments: No activation access → method inapplicable

- First 3 experiments:
  1. Reproduce FGSM detection baseline: Run VGG-16 on 288 ImageNet validation images, generate FGSM ε=0.2 adversarial versions, compute entropy at features.0 and classifier.3. Verify ~7% early-layer entropy increase and ~0.10 bit late-layer decrease. Target: match paper's 90%/80% accuracy.
  2. Threshold sensitivity analysis: Vary τ_early from 5.08 to 5.16 bits and τ_late from 4.15 to 4.25 bits. Plot ROC curves to find optimal operating points for different FPR/FNR cost ratios.
  3. Out-of-scope attack test: Apply PGD or C&W attacks (not in paper) to assess generalization. If entropy signatures differ substantially, document break conditions and update assumptions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does entropy-based detection generalize to stronger iterative attacks (PGD, C&W) and physical-world perturbations (adversarial patches, common corruptions)?
- Basis in paper: [explicit] "Comprehensive validation requires testing against stronger attack types (PGD, C&W) and physical perturbations (adversarial patches, common corruptions)"
- Why unresolved: The study only evaluated FGSM attacks with ε = 0.2; multi-step iterative attacks may produce different entropy signatures or smaller distributional shifts.
- What evidence would resolve it: Detection accuracy and FPR/FNR metrics on VGG-16 using PGD, C&W, and adversarial patch attacks at comparable perturbation magnitudes.

### Open Question 2
- Question: Do entropy signatures transfer across CNN architectures with different depth, skip connections, or activation patterns?
- Basis in paper: [explicit] "Comprehensive validation requires testing... across multiple CNN architectures (ResNet, EfficientNet)"
- Why unresolved: VGG-16's sequential architecture may produce entropy patterns unique to its feedforward structure; residual connections in ResNet or compound scaling in EfficientNet could alter information flow.
- What evidence would resolve it: Replication of the dual-layer entropy monitoring protocol on ResNet-50 and EfficientNet-B0 with identical FGSM attacks.

### Open Question 3
- Question: Can batch-level detection be extended to single-image streaming detection for real-time deployment?
- Basis in paper: [explicit] "The current batch-wise decision framework needs extension to per-frame streaming thresholds for real-time deployment scenarios"
- Why unresolved: Current threshold calibration relies on batch entropy distributions; single-image entropy estimates may exhibit higher variance, reducing detection reliability.
- What evidence would resolve it: Development of sliding-window or exponentially-weighted entropy tracking with per-image detection performance metrics.

### Open Question 4
- Question: How robust is detection performance to binning parameter selection and window length choices?
- Basis in paper: [explicit] "Window length and binning parameter choices warrant systematic sensitivity analysis to optimize detection performance across varying operational conditions"
- Why unresolved: Adaptive binning edges were empirically determined; sensitivity to these hyperparameters could limit practical deployment where conditions vary.
- What evidence would resolve it: Ablation study measuring detection accuracy variance across different bin configurations and temporal window sizes.

## Limitations

- Validation scope limited to FGSM attacks on VGG-16 architecture only
- No testing of generalization to stronger iterative attacks (PGD, C&W) or physical perturbations
- Method requires access to intermediate activations, incompatible with API-only deployments
- Threshold calibration depends on stable input distribution; may drift under varying conditions

## Confidence

- **High Confidence**: The non-invasive hook architecture mechanism is well-supported by PyTorch API documentation and the paper's implementation details. The entropy computation using adaptive binning is mathematically sound and reproducible.
- **Medium Confidence**: The layer-specific entropy behavior (early increase, late decrease) is supported by experimental data but lacks theoretical grounding for why these specific patterns emerge across different architectures.
- **Low Confidence**: Claims about real-world deployment readiness are overstated given the narrow experimental scope and absence of testing on streaming data or varied attack types.

## Next Checks

1. Cross-attack validation: Apply PGD and C&W attacks to the same VGG-16 model and verify whether the entropy elevation/compression signatures persist across attack types.
2. Architecture generalization: Test the method on ResNet-50 and MobileNetV2 to assess whether entropy patterns are architecture-dependent or transfer across CNN families.
3. Threshold robustness: Perform k-fold cross-validation on the baseline profiling data to establish confidence intervals for detection accuracy and FPR metrics.