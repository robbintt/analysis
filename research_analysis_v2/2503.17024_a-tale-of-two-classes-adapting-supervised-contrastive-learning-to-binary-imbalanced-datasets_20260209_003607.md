---
ver: rpa2
title: 'A Tale of Two Classes: Adapting Supervised Contrastive Learning to Binary
  Imbalanced Datasets'
arxiv_id: '2503.17024'
source_url: https://arxiv.org/abs/2503.17024
tags:
- class
- learning
- datasets
- dataset
- supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Supervised contrastive learning (SupCon) struggles on binary imbalanced\
  \ datasets due to class collapse. This paper introduces two novel metrics\u2014\
  Sample Alignment Accuracy (SAA) and Class Alignment Consistency (CAC)\u2014to diagnose\
  \ structural deficiencies in representation spaces."
---

# A Tale of Two Classes: Adapting Supervised Contrastive Learning to Binary Imbalanced Datasets

## Quick Facts
- arXiv ID: 2503.17024
- Source URL: https://arxiv.org/abs/2503.17024
- Reference count: 40
- Standard SupCon collapses on binary imbalanced datasets, but two fixes (Supervised Minority and Supervised Prototypes) achieve up to 35% higher accuracy with minimal overhead.

## Executive Summary
This paper identifies a critical failure mode in Supervised Contrastive Learning (SupCon) when applied to binary imbalanced datasets: representation collapse. The authors demonstrate that standard SupCon metrics fail to diagnose this problem, leading them to develop two novel diagnostic metrics (SAA and CAC). Using these insights, they propose two practical fixes that prevent collapse and significantly improve performance across medical and natural image datasets. Both methods are easy to implement and outperform existing long-tailed learning strategies.

## Method Summary
The paper addresses SupCon failure on binary imbalanced data through two complementary approaches. First, they introduce Sample Alignment Accuracy (SAA) and Class Alignment Consistency (CAC) metrics to diagnose structural deficiencies in representation spaces that standard metrics miss. Second, they propose two solutions: Supervised Minority, which applies SupCon only to the minority class while using unsupervised contrastive loss for the majority, and Supervised Prototypes, which uses fixed class prototypes at opposite ends of the hypersphere to maintain geometric separation. Both methods are designed to be simple to implement with minimal computational overhead.

## Key Results
- SAA and CAC metrics successfully diagnose representation collapse where standard metrics fail
- Supervised Minority and Supervised Prototypes achieve up to 35% higher accuracy than standard SupCon
- Both methods outperform existing long-tailed learning strategies by up to 5%
- Supervised Minority excels on natural images while Supervised Prototypes performs better on medical data
- Minimal computational overhead makes both methods practical for real-world deployment

## Why This Works (Mechanism)

### Mechanism 1: Gradient Desaturation via Selective Supervision (Supervised Minority)
In binary imbalanced settings, standard SupCon creates gradient saturation because the majority class dominates batches, causing an overwhelming number of positive pairs. This leads to vanishing gradients and representation collapse. The Supervised Minority fix applies SupCon only to the minority class while using NT-Xent (unsupervised contrastive loss) for the majority class. NT-Xent pushes all samples apart without aggregating positives, maintaining gradient flow. This mechanism specifically addresses the aggregation-induced collapse identified in Theorem S7.2.

### Mechanism 2: Geometric Anchoring via Fixed Prototypes (Supervised Prototypes)
Representation collapse occurs when all samples are pulled toward a single point. Supervised Prototypes prevents this by initializing two fixed vectors at opposite ends of the unit hypersphere. Samples are attracted to their respective class prototype via contrastive loss, but attraction is switched off when similarity exceeds 0.5 to prevent over-clustering. This forces the network to learn features mapping to distinct geometric basins, solving the collapse issue while maintaining local uniformity.

### Mechanism 3: Inter-Class Separability Detection (SAA and CAC Metrics)
Standard alignment/uniformity metrics measure intra-class cohesion but fail to detect when the majority class cluster swallows the minority. SAA measures if positive pairs are closer to each other than to any negative, checking if the model distinguishes anything at all. CAC measures local neighborhood purity by checking if the 5 nearest neighbors of a minority sample are also minority. These metrics explicitly detect class mixing that causes collapse.

## Foundational Learning

- **Concept: The NT-Xent Loss (Contrastive Learning)**
  - Why needed: Supervised Minority switches between Supervised Contrastive Loss and NT-Xent loss. Understanding that NT-Xent pushes all other images away (uniformity) whereas SupCon pushes only different class images away is essential.
  - Quick check: If you apply NT-Xent to a batch containing 2 augmented views of image A and 1 view of image B, does it push A and B apart?

- **Concept: Representation Collapse**
  - Why needed: This is the specific failure mode addressed. It's not just "poor accuracy" but a structural failure where the encoder maps all inputs to a single point or tiny region of vector space.
  - Quick check: If your model outputs the exact same 128-dimensional vector for a picture of a cat and a picture of a dog, is this a failure of alignment, uniformity, or collapse?

- **Concept: The Unit Hypersphere (L2 Normalization)**
  - Why needed: The paper operates on the unit sphere (S^{d-1}). Prototypes are placed at "opposite ends," and cosine similarity is the distance metric. Understanding vectors are constrained to length 1 is critical for visualizing why "collapse" is a volume-utilization problem.
  - Quick check: Why does forcing vectors to lie on a unit sphere make cosine similarity equivalent to Euclidean distance (scaled)?

## Architecture Onboarding

- **Component map:** Images -> ResNet-50 Backbone -> 128-dim MLP Projection Head -> L2 Normalization -> Conditional Loss Layer (with optional prototype buffer) -> SAA/CAC Metrics Layer
- **Critical path:**
  1. Batch Construction: Ensure batch size (256) guarantees at least one minority sample appears
  2. Forward Pass: Encode images → Project to 128-d → L2 Normalize
  3. Loss Calculation: Supervised Minority applies SupCon if y=1 (minority), NT-Xent if y=0 (majority); Supervised Prototypes checks f(x) · p_class and applies Prototype Loss if < 0.5, else NT-Xent
- **Design tradeoffs:** Supervised Minority is simpler (no extra params) and better on natural images; Supervised Prototypes has extra prototype params and excels on medical data. Batch size increases hurt performance by increasing majority positives.
- **Failure signatures:** SAA ≈ 0 means model cannot distinguish positive pairs from negative pairs; CAC ≈ 50% indicates random mixing of classes; High Accuracy + Low CAC suggests degenerate representation with lucky probe.
- **First 3 experiments:**
  1. Baseline Collapse Verification: Train standard SupCon on 1% minority dataset and plot SAA/CAC to confirm they drop to 0/50%
  2. Supervised Minority Ablation: Implement fix and compare linear probing accuracy against standard SupCon baseline
  3. Metric Validation: Train fixed model and plot correlation between CAC and downstream accuracy to verify CAC is strong predictor (R² > 0.6)

## Open Questions the Paper Calls Out
The authors explicitly note they found "no particularly clear pattern" regarding which method (Supervised Minority or Supervised Prototypes) performs better across domains, with Prototypes excelling on medical data while Minority excelled on natural images. This inconsistency across domains without establishing a causal link to dataset properties like intra-class variance or imbalance severity remains unresolved.

## Limitations
- Theoretical analysis focuses specifically on binary classification with severe imbalance; generalizability to multi-class or moderate imbalance settings remains unclear
- Both methods require prior knowledge of which class is minority, limiting applicability in scenarios with unknown or shifting class distributions
- Fixed prototypes approach assumes linear separability on hypersphere, which may not hold for complex semantic relationships

## Confidence
- **High Confidence:** Empirical results showing 35% accuracy improvements and SAA/CAC metric effectiveness, supported by public code and clear methodology
- **Medium Confidence:** Theoretical explanations for gradient saturation in majority class, though specific binary imbalance mechanism requires further validation
- **Medium Confidence:** Claims about minimal computational overhead, though comprehensive benchmarks across different hardware and scales are absent

## Next Checks
1. Test both methods on multi-class imbalanced datasets to evaluate cross-domain generalization beyond binary settings
2. Conduct ablation studies on the 0.5 similarity threshold in Supervised Prototypes to determine sensitivity and optimal tuning strategies
3. Compare convergence speed and final performance against newer long-tailed learning methods like LDAM-DRW and cRT to establish relative positioning in current literature