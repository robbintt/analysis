---
ver: rpa2
title: 'CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling
  Networks'
arxiv_id: '2506.21607'
source_url: https://arxiv.org/abs/2506.21607
tags:
- entity
- graph
- legal
- core-kg
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CORE-KG, a modular LLM-driven framework for
  constructing knowledge graphs from legal documents about human smuggling networks.
  The framework uses type-aware coreference resolution and structured prompts to reduce
  node duplication and legal noise in the resulting graphs.
---

# CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks

## Quick Facts
- arXiv ID: 2506.21607
- Source URL: https://arxiv.org/abs/2506.21607
- Reference count: 40
- Reduces node duplication by 33.28% and legal noise by 38.37% compared to baseline

## Executive Summary
CORE-KG introduces a modular LLM-driven framework for constructing knowledge graphs from legal documents about human smuggling networks. The framework addresses two key challenges in legal KG construction: node duplication from inconsistent entity references and legal noise from procedural entities. By employing type-aware sequential coreference resolution and structured extraction prompts with domain-specific filtering, CORE-KG produces cleaner, more interpretable graphs suitable for criminal network analysis. Evaluated on 20 legal cases, the framework demonstrates significant improvements over baseline GraphRAG approaches in both precision and coherence.

## Method Summary
CORE-KG uses a two-step pipeline: first, it performs sequential, entity-type-specific coreference resolution using LLaMA 3.3 70B, resolving one entity type at a time (Person→Location→Route→Organization→Transportation→Communication→Smuggled Items) to reduce type drift. Second, it employs entity-relationship extraction with a unified prompt that enforces sequential extraction order, provides explicit type definitions, and includes domain-specific filtering instructions to exclude government-related entities. The resulting triples are assembled into knowledge graphs using GraphRAG, with outputs in GraphML and Parquet formats for analysis.

## Key Results
- Reduces node duplication by 33.28% compared to GraphRAG baseline
- Reduces legal noise by 38.37% in the constructed knowledge graphs
- Improves graph interpretability for criminal network analysis

## Why This Works (Mechanism)

### Mechanism 1
Type-aware sequential coreference resolution reduces node duplication by constraining LLM attention to single entity types at a time, preventing cross-type attention diffusion that causes type drift and feature entanglement in ambiguous legal contexts.

### Mechanism 2
Sequential entity extraction with in-prompt type definitions reduces misclassification errors by constraining the model's output space and overriding statistical co-occurrence patterns from LLM pretraining with explicit context-specific definitions.

### Mechanism 3
Explicit filtering instructions reduce legal noise by instructing the LLM to exclude government-related entities during extraction rather than post-processing, leveraging the model's ability to distinguish domain-relevant from domain-irrelevant entities based on rule descriptions.

## Foundational Learning

- Concept: **Coreference Resolution**
  - Why needed here: Legal documents reference entities inconsistently ("Y.", "A.Y.", "the defendant", "the driver"). Without resolution, these create duplicate nodes fragmenting the knowledge graph.
  - Quick check question: Given "Agent Smith arrested the driver. Smith then questioned him," would a coreference resolver link "the driver" and "him" to the same entity?

- Concept: **Knowledge Graph Entity-Relation Triples**
  - Why needed here: The framework extracts structured (subject, predicate, object) triples from unstructured text to build queryable graphs for network analysis.
  - Quick check question: From "Smugglers used I-35 to transport aliens from Laredo to Dallas," what entities and relationship would you extract?

- Concept: **LLM Attention Distribution**
  - Why needed here: The paper's key design choice—sequential type processing—rests on the claim that LLMs struggle when attention is spread across multiple semantic categories simultaneously.
  - Quick check question: Why might an LLM misclassify "The Camp" as Organization when it should be Location, if processing multiple entity types at once?

## Architecture Onboarding

- Component map: Preprocessing -> Sequential Coreference Resolution -> Entity-Relationship Extraction -> KG Construction
- Critical path:
  1. Input: Legal case Opinion text (~2000 words average)
  2. Coreference resolution: 7 sequential LLM calls per document, one per entity type
  3. Entity/relationship extraction: Single LLM call on resolved text (300-token chunks)
  4. Graph assembly: Merge entities by exact string+type match, build NetworkX graph
  5. Output: GraphML/Parquet files for analysis

- Design tradeoffs:
  - Sequential vs. parallel coreference: Higher latency (7 LLM calls vs. 1) but reduced type confusion
  - In-prompt filtering vs. post-processing: Cleaner graphs but may filter legitimate entities if rules imprecise
  - No ground truth: Evaluation relies on fuzzy matching + expert review, not gold-standard benchmarks
  - Temperature=0: Deterministic outputs but no exploration of alternative resolutions

- Failure signatures:
  - Residual duplicates: "United States–Mexican border" and "border" not merged (Case 15)
  - Context over-generalization: Treating distinct concepts ("undocumented alien" vs. "smuggling aliens") as coreferent
  - Entity misclassification: Abstract terms extracted as Smuggled Items (e.g., "Verdict")
  - Noise leakage: Government entities appearing in output if filtering rules don't match document language

- First 3 experiments:
  1. Ablation on sequential order: Test if coreference quality degrades when entity types are processed simultaneously vs. sequentially on 5 documents
  2. Filtering threshold calibration: Vary filtering rule aggressiveness and measure precision/recall of retained vs. excluded entities
  3. Cross-domain transfer: Apply CORE-KG prompts to non-smuggling legal cases (e.g., fraud, drug trafficking) to test generalization without prompt modification

## Open Questions the Paper Calls Out

### Open Question 1
Can CORE-KG maintain its performance improvements when applied to a significantly larger corpus of legal documents across diverse jurisdictions? The authors acknowledge that "a larger sample size is needed for comprehensive analysis" beyond the 20 cases used in the preliminary evaluation.

### Open Question 2
How can coreference resolution be refined to better distinguish between geopolitical entities and their institutional roles (e.g., a country vs. its government)? The error analysis notes that the model failed to cluster "United States" and "United States government" due to distinct syntactic frames.

### Open Question 3
To what extent does the structural coherence of CORE-KG graphs improve downstream analytical tasks like event prediction or group discovery? The paper focuses on construction and quality metrics rather than utility in predictive modeling.

## Limitations

- Unknown generalizability of sequential processing approach beyond human smuggling domain
- Evaluation relies on fuzzy matching (75% threshold) and manual expert review rather than gold-standard benchmarks
- Limited dataset size (20 cases) may not capture full variance in legal writing styles

## Confidence

- High confidence in node duplication reduction (33.28%) and legal noise reduction (38.37%) claims
- Medium confidence in sequential coreference resolution effectiveness across domains
- Low confidence in framework's ability to handle entities with overlapping semantic roles

## Next Checks

1. Cross-domain evaluation: Apply CORE-KG prompts to legal documents from other criminal domains (fraud, drug trafficking) without prompt modification to assess domain transfer
2. Ablation study on sequential processing: Compare coreference resolution quality when processing all entity types simultaneously versus sequentially on the same document corpus
3. Filter rule sensitivity analysis: Systematically vary filtering instruction specificity and measure precision-recall tradeoffs for domain-relevant versus legal noise entities