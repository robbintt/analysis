---
ver: rpa2
title: Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box
  Settings
arxiv_id: '2505.16313'
source_url: https://arxiv.org/abs/2505.16313
tags:
- image
- edge
- adversarial
- target
- query
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TEA is a targeted, hard-label, black-box adversarial attack designed
  for low-query settings. It uses edge information from target images to rapidly generate
  adversarial examples that maintain target classification while moving toward source
  images.
---

# Accelerating Targeted Hard-Label Adversarial Attacks in Low-Query Black-Box Settings

## Quick Facts
- arXiv ID: 2505.16313
- Source URL: https://arxiv.org/abs/2505.16313
- Reference count: 40
- Key outcome: TEA achieves up to 70% fewer queries than state-of-the-art methods, with 251 average queries to achieve 60% distance reduction on ImageNet

## Executive Summary
TEA is a targeted, hard-label, black-box adversarial attack designed for low-query settings. It uses edge information from target images to rapidly generate adversarial examples that maintain target classification while moving toward source images. The method consists of global edge-informed search followed by patch-based refinement. Across four standard architectures and an adversarially trained model, TEA achieved up to 70% fewer queries than current state-of-the-art methods, with 251 average queries to achieve 60% distance reduction.

## Method Summary
TEA operates in two stages: first, it uses Sobel edge detection to create a soft mask that preserves edge regions while allowing non-edge regions to be perturbed toward the source image through masked interpolation. This global search moves the adversarial image closer to the source while maintaining target classification. Second, a patch-based refinement stage randomly selects high-difference patches and applies Gaussian-weighted local updates to further reduce distance. The method can optionally hand off to geometry-based attacks (CGBA-H) for final refinement at high query budgets.

## Key Results
- Achieved 70% fewer queries than state-of-the-art methods at 400 queries
- 251 average queries to achieve 60% distance reduction across architectures
- At 400 queries, TEA achieved 75% distance reduction for 60-70% of image pairs
- Effective on zero-shot CLIP classifiers and lower-resolution datasets (128×128, 64×64)

## Why This Works (Mechanism)

### Mechanism 1: Edge-Preserving Perturbation Maintains Target Classification
Perturbing non-edge regions while preserving structural edges allows the adversarial image to remain in the target class while moving toward the source image. Sobel edge detection creates a soft mask applied inversely during interpolation, ensuring edge pixels receive minimal modification while smooth regions are freely perturbed. This works because early CNN layers respond to oriented edge filters, and shape/edge cues remain predictive for classification even when textures are suppressed.

### Mechanism 2: Two-Stage Coarse-to-Fine Search Reduces Early-Stage Query Waste
Separating global alignment from local refinement avoids burning queries on local geometry estimation when the adversarial image is far from the decision boundary. Stage 1 uses full-image edge-informed interpolation with momentum-based step optimization. Stage 2 selects high-difference patches via AvgPool(|x_s - x_adv|), applies Gaussian-weighted local updates, and terminates after 25 consecutive failed improvements. This avoids gradient estimation overhead until a narrow decision space is reached.

### Mechanism 3: Hybrid Handoff to Geometry-Based Methods for Final Refinement
TEA provides improved initialization for geometry-based attacks, with CGBA-H refinement achieving state-of-the-art performance at high query budgets. TEA operates until a "turning point" (query count where progress plateaus), then switches to CGBA-H for boundary-based refinement. The final median ℓ₂ distances at 20,000 queries match or exceed pure CGBA-H across architectures.

## Foundational Learning

- **Hard-label black-box setting**: TEA operates under the constraint that only argmax predictions (not logits or probabilities) are observable, limiting feedback to discrete class labels. Quick check: Given a classifier f(x) returning only predicted labels, how would you estimate the direction to move an image toward a target class without gradient access?

- **Decision boundary geometry in adversarial attacks**: Prior methods (HSJA, CGBA-H) estimate local normals or tangents to decision boundaries; TEA deliberately avoids this in early stages. Quick check: Why would estimating local boundary geometry be inefficient when the adversarial image is far from the source image?

- **Sobel edge detection and soft masking**: TEA's core innovation uses Sobel gradients to identify preservable structures; understanding this is essential for implementing the soft edge mask. Quick check: How does Gaussian blurring of the binary edge mask create a soft mask with values in [0,1], and why prefer this over hard thresholding?

## Architecture Onboarding

- **Component map**: Target Image (x_t) → Sobel Edge Detection → Soft Edge Mask (M_edge) → Global Edge-Informed Search (Algorithm 2) → Adversarial Image (x_k) → Patch-Based Refinement (Algorithm 3) → [Optional] CGBA-H Boundary Refinement → Final Adversarial Example (x_adv)

- **Critical path**: 1) Implement Algorithm 1 (soft edge mask) with configurable thresholds T_ℓ, T_h and blur kernel size b; 2) Implement Algorithm 2 (global search) with momentum-based step sizing; 3) Implement Algorithm 3 (patch-based refinement) with Gaussian weighting σ = p/3; 4) Integrate CGBA-H as post-processing for high-query regimes

- **Design tradeoffs**: Edge threshold tightness (T_ℓ, T_h): Narrower thresholds preserve more structure but reduce editable pixels; Patch size range (p_min, p_max): Larger patches enable faster global changes but risk losing target classification; Momentum coefficient (μ): Higher momentum smooths trajectory but may overshoot optimal steps; Turning point detection: Paper uses empirical observation of stagnation

- **Failure signatures**: Early class flip during global search: Step size α too aggressive; Stagnation before meaningful distance reduction: Edge mask too restrictive; High variance across runs: Expected behavior from random patch selection; Poor performance on adversarially trained models: Expected degradation

- **First 3 experiments**: 1) Sanity check on single image pair: Run TEA on one source-target pair through global search only; 2) Ablation of edge preservation: Compare TEA vs. INV-TEA vs. HALF-TEA on 50 image pairs at 200 queries; 3) Low-query benchmark comparison: Replicate Figure 6 conditions (500 query budget) on 100 image pairs across ResNet-50

## Open Questions the Paper Calls Out

### Open Question 1
Can alternative feature representations (textures, color distributions, or high-frequency components) outperform or complement edge-based guidance within TEA's attack framework? The authors demonstrate that edges preserve semantic structure but do not compare against other structural/feature priors. What evidence would resolve it: Systematic ablation comparing edge masks against texture-based masks (e.g., LBP), color-histogram masks, or DCT high-frequency masks under identical query budgets and architectures.

### Open Question 2
How can surrogate models trained on query data collected during the attack be integrated to guide subsequent perturbations more efficiently? TEA currently operates without gradient information; incorporating a learned surrogate could enable gradient-guided steps but introduces overhead and potential bias from limited samples. What evidence would resolve it: Experiments comparing TEA against TEA augmented with an online-trained surrogate, measuring query efficiency gains relative to surrogate training cost and final distortion achieved.

### Open Question 3
What defense mechanisms can effectively detect or mitigate structure-preserving adversarial perturbations like those generated by TEA? Current defenses primarily target frequency-based or noise-like perturbations; TEA's structured perturbations may evade such detectors. What evidence would resolve it: Evaluation of existing defenses against TEA-generated examples, plus development of edge-aware detection methods with reported detection rates and false positive rates.

## Limitations
- Performance degradation on low-resolution datasets (64×64, 128×128) where each patch modification distorts a larger image fraction
- Sensitivity to unspecified hyperparameters (edge thresholds, blur kernel size, patch size ranges, momentum coefficients)
- Reliance on empirical "turning point" detection for handoff to geometry-based methods without theoretical justification

## Confidence
- **High confidence**: The core mechanism of edge-preserving perturbation maintaining target classification while enabling source image movement is well-supported by presented results
- **Medium confidence**: The two-stage coarse-to-fine search strategy is logically sound and empirically validated, though lack of detailed hyperparameter specifications introduces uncertainty
- **Low confidence**: The hybrid handoff strategy to CGBA-H for final refinement, while showing improved performance at high query budgets, lacks detailed justification for handoff timing

## Next Checks
1. **Ablation study of edge mask parameters**: Systematically vary edge thresholds T_l/T_h and blur kernel size b to determine their impact on attack success rate and query efficiency
2. **Low-resolution scalability test**: Evaluate TEA on additional low-resolution datasets (e.g., CIFAR-10 at 32×32) with multiple patch size configurations to understand limitations
3. **Adaptive turning point detection**: Implement and compare alternative criteria for switching to CGBA-H against the fixed 25-iteration heuristic to assess whether more sophisticated detection could improve overall query efficiency