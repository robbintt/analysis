---
ver: rpa2
title: Transition Transfer $Q$-Learning for Composite Markov Decision Processes
arxiv_id: '2502.00534'
source_url: https://arxiv.org/abs/2502.00534
tags:
- learning
- transition
- regret
- low-rank
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies transfer reinforcement learning in composite
  Markov Decision Processes (MDPs) where transition dynamics consist of a shared low-rank
  component plus sparse task-specific variations. The authors introduce UCB-TQL (Upper
  Confidence Bound Transfer Q-Learning), an algorithm that exploits shared structure
  while adapting to task-specific differences.
---

# Transition Transfer $Q$-Learning for Composite Markov Decision Processes

## Quick Facts
- arXiv ID: 2502.00534
- Source URL: https://arxiv.org/abs/2502.00534
- Reference count: 40
- Primary result: UCB-TQL achieves regret bound of $\tilde{O}(\sqrt{eH^5N})$ independent of ambient dimension $d$ for composite MDP transfer learning

## Executive Summary
This paper introduces UCB-TQL, an algorithm for transfer reinforcement learning in composite Markov Decision Processes where transition dynamics consist of a shared low-rank component plus sparse task-specific variations. The method exploits structural similarities between source and target tasks by decomposing transition dynamics into a low-rank matrix capturing shared structure and a sparse matrix capturing task-specific deviations. Through a novel confidence region construction that directly restricts the sparsity of the difference component, UCB-TQL achieves dimension-independent regret bounds that scale with the sparsity of task differences rather than ambient state space size. The theoretical analysis demonstrates how UCB-TQL simultaneously exploits shared dynamics and adapts to task-specific variations through constrained optimization and online sparse regression.

## Method Summary
UCB-TQL operates in two stages: first, it estimates the shared low-rank component and source-specific sparse component from source data using constrained least-squares optimization; second, it performs online target learning by estimating the sparse difference between source and target tasks while constructing a confidence region that enforces sparsity constraints. The algorithm uses feature functions to represent states and actions, then solves non-convex optimization problems with nuclear norm and sparsity constraints to separate shared from task-specific dynamics. During target learning, it computes optimistic Q-values by maximizing over the confidence region and selects actions greedily. The method achieves dimension-independent regret when source samples are sufficiently large relative to target samples.

## Key Results
- Achieves regret bound of $\tilde{O}(\sqrt{eH^5N})$ independent of ambient dimension $d$
- Regret scales with sparsity $e$ of task differences rather than full transition matrix size
- When $N_0 \gtrsim N^2$, regret becomes dominated by sparse difference term
- Formalizes composite MDP framework with provable transfer guarantees

## Why This Works (Mechanism)

### Mechanism 1: Composite Transition Decomposition (Low-Rank + Sparse)
- Modeling transition dynamics as $P(s'|s,a) = \phi(s,a)^T(L* + S*)\psi(s')$ enables separation of transferable structure from task-specific noise
- The low-rank matrix $L*$ captures shared dynamics across tasks (rank $r$), while sparse matrix $S*$ absorbs task-specific deviations (at most $s$ non-zero entries)
- Core assumption: Incoherence condition $\|U*\|_2,\infty, \|V*\|_2,\infty \leq \sqrt{\mu r/p}$ and sufficient sparsity $s \leq \max\{p,q\}/(4CS\mu r^3)$
- Break condition: If $S*$ violates sparsity bound or $L*$ is highly coherent, the decomposition fails and estimators mix shared/specific components

### Mechanism 2: Two-Stage Transfer with Sparsity-Constrained Confidence Region
- Transferring knowledge requires correcting only the sparse difference $D* = S^{(1)} - S^{(0)}$ rather than relearning full dynamics
- Stage I estimates $(\hat{L}, \hat{S}^{(0)})$ from $N_0$ source episodes via hard-constrained optimization. Stage II uses target data to estimate sparse bias $\hat{D}$ via sparsity-constrained regression
- The confidence region explicitly enforces $\|D\|_0 \leq e$, enabling tighter uncertainty quantification than naive ellipsoidal regions
- Break condition: If task difference $D*$ is not sparse (e large), the second-stage estimation cost approaches learning from scratch

### Mechanism 3: Dimension-Independent Regret via Restricted Sparsity
- Target task regret scales with sparsity $e$ rather than ambient dimension $d$ when source data is sufficient
- The regret decomposition separates source estimation error from sparse difference error
- When $N_0 \gtrsim N^2$, the first term vanishes and regret becomes $\tilde{O}(\sqrt{eH^5N})$, independent of $d$
- Break condition: If $N_0$ is small, regret includes terms scaling with ambient structure, losing dimension independence

## Foundational Learning

- **Matrix Completion with Low-Rank + Sparse Decomposition (Robust PCA)**: Core estimator requires separating low-rank $L$ from sparse $S$ via nuclear norm / $\ell_0$ constraints. Quick check: Can you explain why incoherence prevents low-rank and sparse components from being confused?
- **UCB Exploration in Episodic RL**: Algorithm constructs optimistic Q-values by maximizing over confidence region to balance exploration-exploitation. Quick check: How does the optimism principle guarantee that $Q_{n,h} \geq Q^*_h$ with high probability?
- **Martingale Concentration (Matrix Freedman/Azuma-Hoeffding)**: Confidence radius derives from bounding martingale difference sequences. Quick check: Why does the episodic restart structure enable strong convexity of design matrix despite within-episode correlations?

## Architecture Onboarding

- **Component map**: Source data → (L̂, Ŝ⁽⁰⁾) estimation (batch) → Initialize target learning → For each target episode: observe (s,a,s') → Update D̂ → Recompute confidence region → Select action via argmax Q → Accumulate regret
- **Critical path**: Source data → (L̂, Ŝ^(0)) estimation (batch) → Initialize target learning → For each target episode: observe (s,a,s') → Update D̂ → Recompute confidence region → Select action via argmax Q → Accumulate regret
- **Design tradeoffs**: Hard sparsity constraint ($\ell_0$) vs. Lasso ($\ell_1$) - paper uses $\ell_0$ for theory; Remark 5 notes $\ell_1$ relaxation is computationally tractable but requires tuning. Known sparsity parameters (s₀, e) vs. unknown - theory assumes known; practice requires cross-validation. Warm-start requirement (n ≥ Cₑd in Lemma 5) adds overhead for small-n behavior.
- **Failure signatures**: Regret plateaus above $\tilde{O}(\sqrt{eH^5N})$ with increasing N₀ → D* likely not sparse; check task similarity assumption. Confidence region empties → Incoherence violated or sparsity bounds too tight. Q-values explode → Feature norms mis-specified; verify feature normalization.
- **First 3 experiments**: 1) Sanity check on synthetic composite MDP: Construct P = φᵀ(L* + S*)ψ with known rank r and sparsity s. Verify (L̂, Ŝ) recovery error decreases as $\tilde{O}(1/\sqrt{N})$ and regret matches Theorem 1 bound. 2) Ablation on sparsity difference e: Vary e ∈ {1, 5, 20, 100} while fixing source N₀. Confirm regret scales with √e, not ambient d. 3) Phase transition validation: Fix N, vary N₀/N² ratio. Identify threshold where regret transitions from source-dominated to sparse-difference-dominated regime.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can UCB-TQL achieve dimension-independent regret bounds under relaxed incoherence and sparsity assumptions, or through tighter matrix recovery error bounds?
- Basis in paper: Section 5 states: "An extension goal is to achieve the current levels of regret under more relaxed assumptions. This could involve developing new theoretical frameworks or algorithms that either provide tighter error bounds or leverage additional structure in the transition dynamics that has not been fully exploited."
- Why unresolved: Current bounds depend on incoherence (Assumption 1) and sufficient sparsity conditions from matrix completion, which may be overly restrictive for RL settings.
- What evidence would resolve it: Regret bounds derived under weaker assumptions, or necessity proofs via lower bounds showing incoherence is required.

### Open Question 2
- Question: How do alternative sparse structures (row sparsity, column sparsity, group sparsity) impact learning dynamics and efficiency compared to element-wise sparsity?
- Basis in paper: Section 5: "alternative sparse structures, such as row sparsity, column sparsity, or group sparsity, could be further investigated to understand their impact on learning dynamics and efficiency."
- Why unresolved: Current analysis only considers element-wise sparsity (∥S∥₀ ≤ s), which may not capture domain-specific transition structure.
- What evidence would resolve it: Extended regret analysis for alternative sparsity patterns with empirical comparisons on structured domains.

### Open Question 3
- Question: Can the composite MDP framework extend to multi-task and meta-learning settings with multiple source tasks sharing different sparse variations?
- Basis in paper: Section 1: "This framework better captures real-world task relationships and provides a foundation for future work in multi-task and meta-learning settings."
- Why unresolved: Current analysis handles only single source-target transfer (Assumption 3), leaving multi-source scenarios unexplored.
- What evidence would resolve it: Algorithms and regret bounds for settings with multiple source tasks showing cumulative transfer benefits.

## Limitations
- Requires known sparsity parameters (s₀, s₁, e) for theoretical guarantees, though L₁ relaxation suggested as practical workaround
- Strong incoherence conditions on low-rank component may not hold for structured problems
- N₀ ≳ N² requirement for dimension-independent regret may be impractical for many real-world scenarios
- Assumes bounded feature norms and well-conditioned mixing operators

## Confidence
- **High confidence**: Regret bound scaling as $\tilde{O}(\sqrt{eH^5N})$ under stated assumptions, and the core decomposition mechanism (L+S) is well-established in matrix estimation literature
- **Medium confidence**: Practical applicability of hard sparsity constraints and the computational tractability of the confidence region optimization
- **Medium confidence**: The phase transition behavior when varying N₀/N ratio, as theoretical thresholds may be conservative in practice

## Next Checks
1. **Sensitivity analysis**: Systematically vary known parameters (s₀, s₁, e) around true values to quantify robustness to parameter misspecification
2. **Real-world transfer benchmark**: Apply UCB-TQL to continuous control tasks (e.g., OpenAI Gym) with task-specific dynamics changes, comparing against single-task baselines and state-of-the-art transfer methods
3. **Computational scaling study**: Measure wall-clock time and memory usage as (d, r, s, e) increase, identifying bottlenecks in the confidence region optimization and matrix recovery steps