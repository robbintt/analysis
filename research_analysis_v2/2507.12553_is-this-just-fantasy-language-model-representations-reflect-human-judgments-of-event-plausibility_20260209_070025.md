---
ver: rpa2
title: Is This Just Fantasy? Language Model Representations Reflect Human Judgments
  of Event Plausibility
arxiv_id: '2507.12553'
source_url: https://arxiv.org/abs/2507.12553
tags:
- modal
- difference
- vectors
- categories
- impossible
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates how language models (LMs) internally represent\
  \ modal categories\u2014distinguishing between possible, impossible, and inconceivable\
  \ scenarios. Previous work suggested LMs rely on unreliable surface-level probability\
  \ estimates rather than coherent internal representations of modality."
---

# Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility

## Quick Facts
- arXiv ID: 2507.12553
- Source URL: https://arxiv.org/abs/2507.12553
- Reference count: 23
- Key outcome: Modal difference vectors outperform probability baselines in classifying event plausibility and correlate with human judgments

## Executive Summary
This study investigates how language models internally represent modal categories—distinguishing between possible, impossible, and inconceivable scenarios. Previous work suggested LMs rely on unreliable surface-level probability estimates rather than coherent internal representations of modality. The authors address this by identifying "modal difference vectors," linear representations in LM hidden states that capture the difference between modal categories. They evaluate these vectors across multiple model families and scales, showing that modal difference vectors consistently outperform probability-based classification and other baselines. Notably, these vectors emerge in a predictable developmental order: LMs first distinguish inconceivable from other categories, then probable from impossible, and finally improbable from impossible. The study also demonstrates that projections onto modal difference vectors provide a feature space that better reflects human categorization behavior than baselines, and correlates selectively with interpretable features like subjective event likelihood and imageability.

## Method Summary
The authors use Contrastive Activation Addition (CAA) to identify modal difference vectors by averaging hidden state differences between minimal sentence pairs that differ only in modal category. They extract hidden states at the final "." token from a specific layer, compute difference vectors (v = r+ - r-), and average over many pairs to obtain modal difference vectors. Classification involves projecting new inputs onto these vectors and comparing magnitudes. The method uses 5-fold cross-validation to select the optimal layer for each category pair. They evaluate across multiple model families (GPT2, Llama, OLMo, Gemma) and scales (1B-13B parameters) using both the identification dataset and held-out generalization datasets.

## Key Results
- Modal difference vectors outperform probability-based classification on held-out minimal pairs and generalization datasets
- Vectors emerge hierarchically during training: inconceivable vs. others → probable vs. impossible → improbable vs. impossible
- Projections onto modal difference vectors better predict human categorization behavior than baselines
- The impossible-inconceivable vector correlates selectively with imageability features

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Language models encode modal distinctions as linear directions in hidden state space, more reliable than output probabilities.
- **Mechanism:** Contrastive Activation Addition (CAA) isolates "modal difference vectors" by averaging hidden state differences between paired stimuli. Classification uses dot product projections.
- **Core assumption:** Modal categories are linearly separable in activation space rather than requiring complex, non-linear interactions.
- **Evidence anchors:** [abstract] mentions "linear representations that discriminate between modal categories"; [Section 3.1] describes the CAA methodology; [corpus] provides theoretical framework.
- **Break condition:** If representations are highly non-linear or polysemantic in unexamined layers, linear probing fails.

### Mechanism 2
- **Claim:** Modal representations emerge hierarchically during training, mirroring human cognitive development.
- **Mechanism:** Models first learn coarse distinctions (selectional restrictions for inconceivable) before fine-grained physical logic (improbable vs. impossible).
- **Core assumption:** Learning order reflects statistical salience in training data (selectional restrictions clearer than physical law violations).
- **Evidence anchors:** [Section 4.2] describes developmental trajectory; [Section 2] links to human cognition and Shtulman & Carey (2007); [corpus] provides categorical basis.
- **Break condition:** If training data is heavily skewed (e.g., mostly fantasy text), hierarchy might invert or fail.

### Mechanism 3
- **Claim:** The "impossible-to-inconceivable" vector aligns with human cognitive feature of imageability.
- **Mechanism:** LM internal space geometry correlates vector projections with human ratings of visualizability. Separation between impossible (physics violations) and inconceivable (semantic violations) is mediated by internal representation of visual/concrete attributes.
- **Core assumption:** Model's internal encoding of "concreteness" is functionally similar to human mental imagery processes.
- **Evidence anchors:** [Section 6.2] shows selective correlation with visualization features; [Section 7] proposes testable hypothesis for human cognition; [corpus] supports general premise.
- **Break condition:** If correlation is spurious (driven by word frequency rather than semantic content), interventions targeting imageability wouldn't consistently affect modal judgments.

## Foundational Learning

- **Concept:** **Contrastive Activation Addition (CAA) / Steering Vectors**
  - **Why needed here:** Primary methodological tool to extract "modal difference vectors" and intervene on model.
  - **Quick check question:** How does taking the difference of two activation vectors isolate a specific concept (e.g., "truth") from unrelated features?

- **Concept:** **Selectional Restrictions**
  - **Why needed here:** Defines "Inconceivable" category (e.g., verbs requiring animate arguments), first distinction models learn.
  - **Quick check question:** Why is "The rock ate the pizza" structurally distinct from "The rock rolled down the hill" in terms of semantic constraints?

- **Concept:** **Linear Separability in Hidden States**
  - **Why needed here:** Paper relies on premise that high-level concepts can be classified using simple linear boundary (dot product) in later network layers.
  - **Quick check question:** If a concept is not linearly separable, would a simple vector projection (dot product) suffice for classification?

## Architecture Onboarding

- **Component map:** Input Processor (minimal sentence pairs) -> Extractor (forward pass to hidden states) -> Vector Calculator (compute differences and average) -> Classifier/Steerer (project onto vector)

- **Critical path:** Identifying correct Layer $l$ is most sensitive step. Paper uses cross-validation to find specific layer where modal information is most linearly present. Wrong layer selection degrades performance.

- **Design tradeoffs:**
  - **Probability vs. Vectors:** Probability is cheap and model-agnostic but fails on adversarial examples; vectors are robust but require hidden states and paired training data.
  - **Scale vs. Interpretability:** Models < 2B parameters show mixed results, suggesting minimum scale required for coherent linear representations.

- **Failure signatures:**
  - **Small Models (<2B):** Vectors perform inconsistently; probability might outperform vectors.
  - **Adversarial Lexical Overlap:** Probability baselines often fail (assigning high probability to "The laptop bought the teacher"); vectors generally succeed.
  - **Semantic Adversarial:** Vectors and Principal Components perform well; Probability estimates systematically misled.

- **First 3 experiments:**
  1. **Reproduce the Layer Sweep:** Run extraction pipeline on Llama-3.2-3B for "Probable vs. Impossible" pair and plot classification accuracy per layer to confirm "emergence" layer.
  2. **Adversarial Stress Test:** Compare "Probability" baseline vs. "Modal Difference Vectors" on Kauf et al. (2023) lexically adversarial dataset.
  3. **Steering Validation:** Implement steering intervention (Appendix C) by adding "Impossible" vector to residual stream during generation task and observe output shift.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can modal difference vectors reveal specific intuitive theories of physics or causal principles that LMs encode?
- **Basis in paper:** [explicit] Discussion suggests creating controlled datasets of sentences with specific physics violations to test whether LMs represent these as impossible.
- **Why unresolved:** Current study validates broad modal categories but doesn't disentangle specific physical laws within "impossible" cluster.
- **What evidence would resolve it:** Dataset isolating specific causal violations would show if distinct vector subspaces correspond to distinct intuitive theories of physics.

### Open Question 2
- **Question:** What specific distributional signals in training data allow LMs to learn distinction between improbable and impossible events?
- **Basis in paper:** [explicit] Discussion notes while selectional restrictions have clear signals, textual signals distinguishing impossible from improbable are "much less obvious."
- **Why unresolved:** Study identifies *when* representations emerge but not specific linguistic features or statistical regularities driving learning.
- **What evidence would resolve it:** Ablation studies removing specific semantic features from training data to see if "improbable-impossible" vector fails to form.

### Open Question 3
- **Question:** Do humans rely on mental imagery as primary mechanism to distinguish between impossible and inconceivable events?
- **Basis in paper:** [explicit] Discussion highlights correlation between "impossible-inconceivable" vector and imageability, proposing this as "testable hypothesis" for human cognition.
- **Why unresolved:** While LM representations correlate with imageability ratings, this link hasn't been experimentally validated in human subjects for this specific modal contrast.
- **What evidence would resolve it:** Human behavioral experiments (e.g., dual-task paradigms to block visualization) demonstrating that impairing mental imagery selectively degrades ability to distinguish impossible from inconceivable scenarios.

## Limitations
- Dataset availability uncertainty: Primary Hu et al. (2025b) dataset cited as "in-press," creating uncertainty about stimulus availability for exact replication.
- Model scale dependency: Modal difference vectors emerge reliably only in models ≥2B parameters, limiting applicability to resource-constrained settings.
- Correlation vs. causation: Selective correlation between impossible-inconceivable vectors and imageability ratings doesn't establish LMs use same cognitive mechanisms as humans.

## Confidence
- **High Confidence:** Existence of modal difference vectors and superior performance over probability baselines for classification tasks.
- **Medium Confidence:** Hierarchical developmental trajectory (inconceivable → probable/impossible → improbable/impossible), though exact ordering might vary with different training corpora.
- **Low Confidence:** Specific claim that impossible-inconceivable separation reflects human imageability mechanisms, based on selective correlations without direct experimental validation.

## Next Checks
1. **Dataset Verification:** Obtain and verify exact minimal pair structure of Hu et al. (2025b) dataset, including train/validation splits used for 5-fold cross-validation.
2. **Cross-Architecture Replication:** Test CAA methodology across additional model families beyond those studied (e.g., Mistral, Mixtral) to assess generalization to different architectural designs.
3. **Mechanistic Intervention:** Design and execute controlled intervention where imageability is explicitly manipulated (e.g., adding visual descriptors) to test whether this systematically affects modal judgments in both LMs and human subjects.