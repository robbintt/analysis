---
ver: rpa2
title: Three Stage Narrative Analysis; Plot-Sentiment Breakdown, Structure Learning
  and Concept Detection
arxiv_id: '2511.11857'
source_url: https://arxiv.org/abs/2511.11857
tags:
- sentiment
- narrative
- story
- text
- arcs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a three-stage framework for computational narrative
  analysis. The first stage performs sentiment arc extraction using a custom NRC-VAD
  lexicon within the LabMT framework to generate emotional trajectories across segmented
  movie scripts.
---

# Three Stage Narrative Analysis; Plot-Sentiment Breakdown, Structure Learning and Concept Detection

## Quick Facts
- arXiv ID: 2511.11857
- Source URL: https://arxiv.org/abs/2511.11857
- Reference count: 38
- This paper proposes a three-stage framework for computational narrative analysis using sentiment arc extraction, structural role classification, and theoretical concept detection.

## Executive Summary
This paper presents a computational framework for analyzing narrative structure through sentiment trajectories. The approach segments movie scripts, applies lexicon-based sentiment scoring using a custom NRC-VAD lexicon within the LabMT framework, and clusters resulting emotional arcs using Ward's hierarchical clustering. Experiments on 1,000 movie scripts identified three main emotional arc patterns consistent with known story structures. While sentiment analysis and clustering are implemented, structural role classification and concept detection remain conceptual components requiring further development.

## Method Summary
The framework processes movie scripts through three stages: First, scripts are segmented into fixed-size word windows and scored for emotion using a custom NRC-VAD lexicon integrated with the LabMT framework, with a rolling 10-segment context window for smoothing. Second, narrative segments are classified into structural roles like tension, reward, or victory using text classification models. Third, the framework aims to detect high- and low-concept narratives, though this remains theoretical. Ward's hierarchical clustering groups scripts by emotional trajectory similarity, with Fourier smoothing and SOMs proposed for noise reduction. The study analyzed 1,000 movie scripts but only fully implemented sentiment arc extraction and clustering.

## Key Results
- Identified three main emotional arc patterns from 1,000 movie scripts using Ward's hierarchical clustering
- Sentiment plots revealed genre-transcendent similarities in emotional trajectories
- Lexicon-based approach successfully extracted emotional trajectories, though noise and script length variability posed challenges

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Lexicon-based sentiment scoring over segmented text can reveal emotional trajectories that cluster into recurring story shapes.
- Mechanism: Scripts are divided into fixed-size word windows; each segment's word frequencies are matched against a custom NRC-VAD lexicon (Valence, Arousal, Dominance) within the LabMT framework. A rolling context window of 10 segments smooths local fluctuations by accumulating frequencies before scoring.
- Core assumption: Emotional meaning can be approximated by averaging predefined word-level affect scores across narrative segments, independent of syntax or discourse context.
- Evidence anchors:
  - [abstract]: "Using dictionary-based sentiment analysis, our approach applies a custom lexicon built with the LabMTsimple storylab module. The custom lexicon is based on the Valence, Arousal, and Dominance scores from the NRC-VAD dataset."
  - [section 2.1-2.3]: Detailed steps for segmentation, text frequency vector generation, and emotion scoring via LabMT's emotionV function with stop-word removal.
  - [corpus]: Reagan et al. (referenced in section 1.7) previously demonstrated six emotional arcs from books using LabMT; this paper extends to movie scripts. Direct corpus validation of this specific implementation is limited (neighbor citations = 0).
- Break condition: Lexicon-based methods fail when emotional meaning depends on negation, sarcasm, or character-specific context not captured by bag-of-words scoring.

### Mechanism 2
- Claim: Hierarchical clustering of sentiment trajectories can identify groups of narratives with similar emotional shapes across genres.
- Mechanism: Sentiment score vectors from each script are compared using variance-minimizing linkage (Ward's method). The dendrogram reveals three primary clusters; finer granularity (100 clusters) exposes within-cluster variation.
- Core assumption: Scripts with similar emotional score progressions share underlying narrative structure, regardless of genre or surface content.
- Evidence anchors:
  - [abstract]: "The framework advances the analysis by clustering similar sentiment plots using Ward's hierarchical clustering technique."
  - [section 3.1-3.2]: Dendrogram generated three broad clusters; case studies (The Avengers, Blade Runner, The Revenant) showed similar curves despite different genres.
  - [corpus]: Weak direct validation—no citations to this work; related work (Reagan 2017) used SVD, hierarchical clustering, and SOMs on books with similar findings.
- Break condition: Noise from uneven segmentation or variable script lengths distorts trajectory alignment, causing dissimilar scripts to cluster together or similar scripts to separate.

### Mechanism 3
- Claim: Predefined structural categories (tension, reward, victory, punishment) can be assigned to narrative segments via text classification, adding semantic labels to emotional arcs.
- Mechanism: A text classification model is trained to map segment text to one of several structural role labels. These labels annotate the narrative timeline alongside sentiment scores.
- Core assumption: Narrative segments can be mapped to a fixed taxonomy of structural roles that generalize across stories.
- Evidence anchors:
  - [abstract]: "The second stage classifies narrative segments into structural roles such as tension, reward, or victory using text classification models."
  - [section 1.3, Figure 3-4]: Structure Learning component described with predetermined classes; training/testing procedures illustrated.
  - [corpus]: No direct validation of this stage in experimental results; NeuroNarratives (referenced in section 1.5) demonstrated joint role-arc learning with transformers, suggesting feasibility but not confirming this implementation.
- Break condition: Classification accuracy degrades when segments contain multiple overlapping functions or when training data lacks coverage for hybrid narrative roles.

## Foundational Learning

- Concept: **Sentiment Lexicons (Valence, Arousal, Dominance)**
  - Why needed here: The framework relies on mapping words to multi-dimensional emotion scores rather than binary polarity. Understanding VAD dimensions is essential to interpret why the custom lexicon was chosen and how it differs from simpler approaches.
  - Quick check question: Can you explain why using Arousal scores instead of Happiness scores (as this paper does) might change the shape of a sentiment arc?

- Concept: **Hierarchical Clustering with Ward's Linkage**
  - Why needed here: The paper uses Ward's method to group scripts by emotional trajectory similarity. Understanding variance-minimizing linkage is necessary to interpret the dendrogram and the choice of three primary clusters.
  - Quick check question: What does the vertical axis of a Ward's dendrogram represent, and why might merging clusters too early lose meaningful narrative distinctions?

- Concept: **Narrative Arc Typology (e.g., Rags to Riches, Man in a Hole)**
  - Why needed here: The clustering output is interpreted against six known story shapes from prior work. Without this background, the cluster meanings are opaque.
  - Quick check question: Given a sentiment plot that rises, falls sharply, then rises again, which story arc type would you hypothesize it matches?

## Architecture Onboarding

- Component map: Preprocessing Module -> Segmentation Engine -> Lexicon Scorer -> Context Smoother -> Trajectory Storage -> Clustering Module -> Structure Classifier -> Concept Detector
- Critical path: Preprocessing → Segmentation → Lexicon Scoring → Context Smoothing → Trajectory Storage → Clustering. The Structure Classifier runs in parallel on segments but is not required for clustering.
- Design tradeoffs:
  - Lexicon-based vs. contextual embeddings: Transparency and interpretability vs. ability to capture negation, sarcasm, and character-specific context.
  - Fixed vs. adaptive segmentation: Simple implementation vs. sensitivity to actual scene boundaries.
  - Hierarchical clustering vs. SOMs: Deterministic groupings vs. topological preservation and smoother visualizations.
- Failure signatures:
  - **Noisy sentiment plots**: Sharp spikes unrelated to narrative events; often caused by small segment sizes or rare high-arousal words dominating the score.
  - **Inconsistent cluster membership**: Same script clustering differently on re-run; check for randomness in preprocessing or undefined word handling.
  - **Structure classifier mislabeling**: Segments tagged as "victory" during clearly negative emotional dips; may indicate training data imbalance or feature sparsity.
- First 3 experiments:
  1. **Baseline lexicon validation**: Score a small set of manually annotated script segments (e.g., 10 segments with known emotional tone) using the NRC-VAD + LabMT pipeline; compare scores to human judgment to calibrate window size and context window length.
  2. **Clustering stability test**: Run hierarchical clustering on a subset of 100 scripts multiple times with slight variations (e.g., different random seeds for any stochastic preprocessing, or different segment sizes); measure cluster consistency using adjusted Rand index.
  3. **Noise reduction ablation**: Apply Fourier smoothing to a subset of trajectories before clustering; compare dendrogram structure and cluster interpretability to unsmoothed baseline to quantify improvement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can high and low narrative concepts be computationally modeled to distinguish between "what-if" premises and character-driven themes?
- Basis in paper: [explicit] The authors identify the "Concept Detection" stage as currently theoretical, noting the lack of a computational model for identifying high versus low concepts.
- Why unresolved: The paper defines the concepts theoretically but relies on future work to implement semantic embeddings and novelty detection algorithms.
- What evidence would resolve it: A functional classification model that tags narratives as high or low concept based on semantic features and event structures.

### Open Question 2
- Question: Does Fourier smoothing combined with Self-Organizing Maps (SOMs) improve the accuracy of emotional arc clustering over Ward's hierarchical method?
- Basis in paper: [explicit] The authors state that raw sentiment plots are noisy and propose Fourier transforms for trend extraction and SOMs to preserve topological relationships.
- Why unresolved: The current experimental results rely on Ward's clustering, which struggles with noise and variable script lengths, but the proposed solutions have not yet been implemented.
- What evidence would resolve it: Comparative analysis showing cleaner sentiment trajectories and higher cluster cohesion when using the proposed hybrid approach.

### Open Question 3
- Question: Do emotional arc patterns remain consistent across multilingual and cross-cultural narratives?
- Basis in paper: [explicit] The authors list expanding the dataset to multilingual and cross-cultural scripts as a key direction for future research to enhance robustness.
- Why unresolved: The current study is limited to a dataset of 1,000 English movie scripts, leaving the universality of the identified story structures untested.
- What evidence would resolve it: Experimental results showing that the six core emotional arcs persist when analyzing non-English or culturally distinct movie scripts.

## Limitations

- Lexicon-based sentiment scoring cannot capture context-dependent meaning, negation, or sarcasm
- Structure learning component is only conceptually outlined with no experimental validation
- Concept detection stage remains theoretical with no implementation or validation results

## Confidence

- **High**: The framework architecture and lexicon-based sentiment scoring mechanism are clearly specified and reproducible.
- **Medium**: The clustering results and identification of three broad emotional arc patterns are supported by case studies, but lack quantitative validation (e.g., silhouette scores, external benchmarks).
- **Low**: The structure learning and concept detection stages lack implementation details, training data, or validation results.

## Next Checks

1. **Sentiment Scoring Validation**: Manually annotate 50 script segments with emotional tone and compare lexicon-based scores to human judgments to assess calibration.
2. **Clustering Stability Test**: Run Ward's hierarchical clustering on 200 scripts with varying segment sizes and smoothing parameters; measure cluster consistency using adjusted Rand index.
3. **Noise Reduction Ablation**: Apply Fourier smoothing to 100 sentiment trajectories; compare dendrogram structure and cluster interpretability to unsmoothed baseline using silhouette scores.