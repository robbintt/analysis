---
ver: rpa2
title: Sample Complexity Analysis for Constrained Bilevel Reinforcement Learning
arxiv_id: '2602.00282'
source_url: https://arxiv.org/abs/2602.00282
tags:
- bilevel
- constrained
- learning
- optimization
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the sample complexity of a constrained bilevel
  reinforcement learning (RL) problem, where the inner-level RL problem is subject
  to inequality constraints. The authors propose the Constrained Bilevel Subgradient
  Optimization (CBSO) algorithm, which uses a penalty-based formulation to handle
  constraints and avoids the primal-dual gap issue common in constrained bilevel optimization.
---

# Sample Complexity Analysis for Constrained Bilevel Reinforcement Learning

## Quick Facts
- **arXiv ID:** 2602.00282
- **Source URL:** https://arxiv.org/abs/2602.00282
- **Reference count:** 40
- **Primary result:** First sample complexity analysis for generally parameterized policy gradient-based RL algorithms with non-smooth objectives, achieving O(ε⁻⁴) sample complexity for constrained bilevel RL.

## Executive Summary
This paper analyzes the sample complexity of constrained bilevel reinforcement learning, where the inner-level RL problem is subject to inequality constraints. The authors propose the Constrained Bilevel Subgradient Optimization (CBSO) algorithm, which uses a penalty-based formulation to handle constraints and avoids the primal-dual gap issue common in constrained bilevel optimization. The algorithm employs a subgradient descent approach with the Moreau envelope technique to handle the non-smoothness introduced by the penalty formulation. The key contributions include an algorithm for constrained bilevel RL with global convergence guarantees, an iteration complexity of O(ε⁻²) and sample complexity of O(ε⁻⁴), and extension to constrained bilevel optimization by removing convexity assumptions on the inner level problem.

## Method Summary
CBSO solves constrained bilevel RL by transforming nested inequality constraints into a penalty objective, avoiding primal-dual gaps. The algorithm uses subgradient descent on the Moreau envelope of the penalty objective, which preserves global optima while providing smoothness. For the outer loop, it estimates gradients of the penalty objective using solutions from inner-level constrained optimization. The inner loop solves two constrained problems: one minimizing the combined outer objective and constraints, and another serving as a reference for the bilevel penalty gap. Convergence relies on the Kurdyka-Lojasiewicz condition and ρ-hypomonotonicity of the subdifferential.

## Key Results
- Achieves iteration complexity O(ε⁻²) and sample complexity O(ε⁻⁴) for constrained bilevel RL
- First sample complexity analysis for generally parameterized policy gradient-based RL with non-smooth objectives
- Removes convexity assumptions on the inner level problem, extending to non-convex bilevel optimization
- Provides bounded constraint violation guarantees through penalty formulation

## Why This Works (Mechanism)

### Mechanism 1: Penalty-based Formulation Avoids Primal-Dual Gap
The penalty-based reformulation approximately solves the constrained bilevel problem with bounded constraint violation, avoiding the primal-dual gap issue inherent to non-convex constrained optimization. The algorithm transforms nested inequality constraints at the inner level into a single penalty objective, and Lemma 4.1 proves that an ε-optimal solution of this penalty objective yields an ε'-optimal solution of the relaxed constrained problem with bounded constraint violation.

### Mechanism 2: Moreau Envelope Preserves Global Optima Under Non-smoothness
The Moreau envelope technique enables global convergence analysis of non-smooth functions while preserving global optima, which randomized smoothing cannot guarantee. For weakly convex functions, the Moreau envelope is L-smooth and has the same minimizers as the original function. Under the Kurdyka-Łojasiewicz condition, the envelope satisfies the Polyak-Łojasiewicz condition, which implies quadratic growth and enables connecting suboptimality gaps to gradient norms.

### Mechanism 3: ρ-Hypomonotonicity Enables Descent Despite Subgradient Noise
Subgradient descent on non-smooth weakly convex functions achieves global convergence because the subdifferential satisfies ρ-hypomonotonicity, which extends descent lemmas from smooth gradient descent. This property, combined with the Moreau envelope gradient's relationship to the subdifferential, yields descent guarantees that enable convergence despite the noise inherent in subgradient methods.

## Foundational Learning

- **Concept: Bilevel Optimization Structure**
  - Why needed here: The entire framework hinges on understanding that a bilevel problem has an outer objective f(x, y*(x)) where y*(x) is the solution to an inner constrained optimization.
  - Quick check question: Can you sketch why RLHF fits the bilevel formulation in Eq. (2), and why constraint h(y) < c₀ makes standard hypergradient methods inapplicable?

- **Concept: Clarke Subdifferential and Weak Convexity**
  - Why needed here: Non-smooth functions (from penalty terms like max(h(y)-c₀, 0)) lack classical gradients. The Clarke subdifferential generalizes gradients to Lipschitz functions; weak convexity provides the structure needed for convergence proofs.
  - Quick check question: For f(x) = max(x, 0), what is ∂f at x=0? If f is L-smooth, why is it L-weakly convex?

- **Concept: Moreau Envelope and Proximal Operator**
  - Why needed here: The paper's entire convergence analysis operates on the Moreau envelope Φ_λ rather than Φ directly. Understanding that prox_λf(x) = argmin_y{f(y) + ||x-y||²/(2λ)} and ∇f_λ(x) = (x - prox_λf(x))/λ is essential for interpreting Theorem 5.7.
  - Quick check question: Why does f_λ preserve the global minima of f? What happens to f_λ as λ → 0?

## Architecture Onboarding

- **Component map:** Outer loop (x-parameters) updates reward/function approximator parameters via ∂_xΦ. Inner loop y-optimization minimizes h₁(x,y) = f(x,y) + [g(x,y) + h⁺(y)/σ₃]/σ₁. Inner loop z-optimization minimizes h₂(x,z) = g(x,z) + h⁺(z)/σ₂. Subgradient estimator for h⁺ uses Clarke subdifferential with τ(ĥ(y)) ∈ {0, 1/2, 1}.

- **Critical path:** Implement Q-value estimation with function approximation—error here propagates as ε_bias. Implement ∂_yĥ⁺(y, B) correctly handling the Clarke subdifferential at boundary points. Tune σ₁, σ₂, σ₃ with σ₃ ≫ σ₂ to control constraint violation. Set horizon H = Θ(log ε) and batch size B = Θ(ε⁻¹) to achieve target sample complexity.

- **Design tradeoffs:** Higher σ₃ / lower σ₂ reduces constraint violation but increases penalty term magnitude, potentially slowing convergence. Larger batch size B reduces variance in subgradient estimates but increases per-iteration sample cost. Longer horizon H reduces truncation bias at cost of more rollouts per sample. Assumption 5.4 (Q-estimation bias) means ε_bias cannot be eliminated by algorithmic choices alone.

- **Failure signatures:** Constraint violation growing rather than bounded: check σ₃/σ₂ ratio; may need σ₃ >> σ₂. No convergence in Φ_λ gradient norm: verify KL condition holds for inner objectives; check that Q-value estimators have bounded bias. High variance in subgradient estimates: increase batch size B or check implementation of τ(ĥ(y)) for numerical stability near h(y) = c₀. Inner loop not converging: increase K (inner iterations) or verify weak convexity holds for h₁, h₂.

- **First 3 experiments:**
  1. **Toy CMDP with known optimal:** Implement on a simple 2-state CMDP where you can compute y*(x) analytically. Verify that (a) constraint violation is bounded by ε_λ, (b) ||y^K_t - y*(x_t)||² decreases with K, and (c) ||∇Φ_λ(x_t)||² decreases with T. Use this to validate the O(ε⁻²) iteration scaling.
  2. **Ablation on penalty coefficients:** Sweep σ₁ ∈ {0.1, 1, 10}, σ₂ ∈ {0.01, 0.1}, σ₃/σ₂ ∈ {10, 100, 1000} and measure final constraint violation vs. convergence rate. Confirm Lemma 4.1's predicted relationship between these parameters and ε_λ.
  3. **Comparison with primal-dual baseline:** Implement a standard Lagrangian-based constrained RL method on the same bilevel problem. Document where primal-dual fails (expected: non-zero duality gap leads to suboptimal outer-level solutions) vs. CBSO's bounded violation. This establishes the necessity of the penalty approach for non-convex inner problems.

## Open Questions the Paper Calls Out

- **Can the algorithm be extended to settings where the constraints are learned in the outer level rather than remaining fixed?** The current formulation assumes the constraint function h(y) is fixed. Updating constraints in the outer loop introduces difficulties regarding the stability and analysis of the subgradients involved in the optimization process.

- **Can the sample complexity of O(ε⁻⁴) be improved to match the O(ε⁻³) rates found in unconstrained bilevel RL?** The penalty-based formulation introduces non-smoothness, necessitating a subgradient approach which typically incurs a sample complexity of O(ε⁻⁴), whereas unconstrained methods can exploit smoother optimization landscapes.

- **Is it possible to establish global convergence guarantees without relying on the Kurdyka-Lojasiewicz (KL) condition?** The theoretical analysis relies on the KL condition to derive the Polyak-Lojasiewicz (PL) condition for the Moreau envelope, which is necessary to prove the Quadratic Growth (QG) condition.

## Limitations

- The analysis critically depends on the Kurdyka-Lojasiewicz (KL) condition for non-smooth weakly convex functions, which is assumed but not verified for general CMDPs or RLHF settings.
- The requirement σ₃ ≫ σ₂ to bound constraint violation creates a hyperparameter sensitivity that may degrade performance in practice.
- The O(ε⁻⁴) sample complexity bound is dependent on function approximation quality through the ε_bias term, making it sensitive to Q-value estimator capacity.

## Confidence

- **High confidence:** The penalty formulation avoiding primal-dual gaps is theoretically sound with formal bounds in Lemma 4.1. The Moreau envelope preserving global optima follows directly from standard results in weak convexity theory.
- **Medium confidence:** The ρ-hypomonotonicity descent property relies on the KL condition, which is assumed but rarely verified in practice for constrained RL problems. The O(ε⁻⁴) sample complexity bound combines several intermediate results, making it sensitive to how each component behaves.
- **Low confidence:** The extension to general non-convex inner problems assumes structural properties (weak convexity, KL condition) that may not hold for typical neural network parameterizations used in RLHF.

## Next Checks

1. **Verify KL condition empirically:** Implement the toy CMDP experiment and measure whether the inner objectives satisfy the Kurdyka-Łojasiewicz condition with θ=1/2. Plot the ratio of gradient norm to suboptimality gap to confirm quadratic growth.

2. **Test hyperparameter sensitivity:** Systematically vary σ₁, σ₂, σ₃ ratios and measure constraint violation vs. convergence rate. Document whether the predicted relationship ε_λ = max{2C_gσ₂, 2C_fσ₁ + 2C_g(σ₂/σ₃), 2C_fσ₁σ₃ + 2C_gσ₃} holds in practice.

3. **Compare with smoothed baselines:** Implement a randomized smoothing approach (adding Gaussian noise to y) for the same bilevel problem and compare convergence rates and constraint violation. This isolates whether the Moreau envelope's theoretical advantages translate to practical improvements.