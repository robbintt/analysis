---
ver: rpa2
title: A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in
  Telecom Documents
arxiv_id: '2507.22938'
source_url: https://arxiv.org/abs/2507.22938
tags:
- graph
- images
- retrieval
- flowchart
- flowcharts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of retrieving answers from flowchart
  images in telecom documents using text-based RAG systems. The authors propose a
  method that combines image classification, graph-based representation of flowcharts,
  and embedding strategies to improve retrieval performance.
---

# A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents

## Quick Facts
- arXiv ID: 2507.22938
- Source URL: https://arxiv.org/abs/2507.22938
- Authors: Sumit Soman; H. G. Ranjani; Sujoy Roychowdhury; Venkata Dharma Surya Narayana Sastry; Akshat Jain; Pranav Gangrade; Ayaaz Khan
- Reference count: 21
- Primary result: Achieves 57.17% top-1 accuracy for node-related questions using graph representations from fine-tuned VLMs

## Executive Summary
This work addresses the challenge of retrieving answers from flowchart images in telecom documents using text-based RAG systems. The authors propose a method that combines image classification, graph-based representation of flowcharts, and embedding strategies to improve retrieval performance. They use a fine-tuned Document Image Transformer (DIT) model to classify images into categories and a fine-tuned Visual Language Model (VLM) to convert flowcharts into graph structures. The graph representations are then embedded using text-based models, with different chunking approaches evaluated for retrieval. Results show that the graph representations obtained using a fine-tuned VLM have lower edit distance compared to the ground truth, indicating robustness. The approach achieves good retrieval performance using text-based embedding models, including a telecom-domain adapted one, with top-1 accuracy of 57.17% for node-related questions. This method alleviates the need for a VLM in inference, offering a cost-effective solution for deployed QA systems.

## Method Summary
The approach uses a multi-stage pipeline: first, a fine-tuned DIT-base image classifier routes flowchart images to the VLM processing pipeline. The VLM (Qwen2-VL) is fine-tuned on synthetic flowchart data (Flowlearn dataset) with augmented edge/node types using LoRA (R=512, Alpha=512), producing graph JSON representations with lower Graph Edit Distance (GED). These graph representations are chunked using three strategies: each node separately, all nodes together, or the entire JSON as one chunk. The chunks are embedded using text-based models (bge-large and TeleRoBERTa) and stored in a vector index. For retrieval, questions are embedded and the top-k chunks are returned, with the system achieving good accuracy without requiring a VLM at inference time.

## Key Results
- VLM fine-tuning reduces Graph Edit Distance from 10.21 to 2.74 on test data
- Each-node chunking achieves 57.17% top-1 accuracy for node-related questions using TeleRoBERTa
- Graph representations show lower edit distance compared to ground truth, indicating robustness
- Retrieval accuracy drops by 15-25% when graph embeddings are interspersed with document text

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning VLMs on synthetic flowchart data improves graph extraction quality for domain-specific flowcharts.
- Mechanism: The VLM (Qwen2-VL) is fine-tuned on the Flowlearn dataset (10,000 synthetic flowcharts) with augmented edge/node types. Lower Graph Edit Distance (GED) indicates the model better captures node-to-node relationships and edge attributes. Fine-tuning with LoRA R=512, Alpha=512 reduced GED from 10.21 (base) to 2.74 on test data.
- Core assumption: Synthetic flowchart training data transfers sufficiently to proprietary telecom flowcharts despite distribution shift.
- Evidence anchors:
  - [section] Table 3 shows GED reduction from 10.21 to 2.74 with fine-tuning; GED of 3.14 on unseen PI Docs flowcharts.
  - [section] Section 3.1.2 describes augmentation for node shapes, edge types, and edge attributes not covered in original Flowlearn.
  - [corpus] Weak/missing: Corpus papers focus on text-graph RAG, not VLM fine-tuning for flowchart extraction.
- Break condition: If domain flowcharts have complex layouts (crossing edges, nested subgraphs) not represented in synthetic training, GED may degrade significantly.

### Mechanism 2
- Claim: Representing flowcharts as directed graphs preserves retrievable structure better than VLM-generated prose summaries.
- Mechanism: Each flowchart block becomes a node with text attributes; links become edges with optional edge labels. This JSON graph is chunked and embedded, preserving decision logic and sequential relationships without verbose or hallucinated descriptions.
- Core assumption: Text embedding models can capture semantic similarity between questions and graph-structured text representations.
- Evidence anchors:
  - [abstract] "Graph representations obtained using a fine-tuned VLM have lower edit distance... illustrate robustness."
  - [section] Figure 3 shows JSON representation with nodes, edges, and attributes.
  - [corpus] SentGraph and N2N-GQA show graph-based retrieval improves multi-hop QA, supporting the general principle.
- Break condition: If embedding models fail to associate questions with edge-related attributes (e.g., "What happens if condition X?"), retrieval accuracy for edge-related questions will drop.

### Mechanism 3
- Claim: Chunking strategy directly affects retrieval accuracy; "each node as one chunk" performs best for node-related questions.
- Mechanism: Three chunking approaches are evaluated: (1) each node separately, (2) all nodes together, (3) entire JSON. Each-node chunking achieved 57.17% top-1 accuracy with TeleRoBERTa for node-related queries, as it aligns question granularity with chunk granularity.
- Core assumption: Node-related questions are more common or easier to match than edge/decision-related questions.
- Evidence anchors:
  - [section] Table 4 shows 57.17% top-1 for "each node as one chunk" with TeleRoBERTa (graph-only retrieval).
  - [section] Table 5 shows node-related questions outperform decision and edge-related across chunking strategies.
  - [corpus] VDocRAG and MGA-VQA emphasize chunk-level retrieval for multi-modal documents, consistent with this finding.
- Break condition: If questions require multi-hop reasoning across edges, single-node chunking may fragment context and reduce accuracy.

## Foundational Learning

- Concept: Graph Edit Distance (GED)
  - Why needed here: Primary metric for evaluating VLM graph extraction quality; lower GED = more faithful flowchart-to-graph conversion.
  - Quick check question: If GED is 5, what types of errors might this represent (missing nodes, wrong edges, attribute errors)?

- Concept: LoRA Fine-Tuning
  - Why needed here: Authors use LoRA R and Alpha parameters to fine-tune Qwen2-VL; understanding these helps reproduce results.
  - Quick check question: What is the relationship between LoRA rank (R) and model capacity for learning new patterns?

- Concept: Chunking Strategies for Retrieval
  - Why needed here: Choice of chunking directly affects top-k retrieval accuracy; different strategies suit different question types.
  - Quick check question: For a question like "What is the final step in the process?", which chunking approach would likely perform best?

## Architecture Onboarding

- Component map:
  1. Document Parser → Extracts images/text from PDF/HTML
  2. Image Classifier (DIT-base) → Routes flowcharts to VLM pipeline
  3. VLM (Qwen2-VL fine-tuned) → Converts flowchart images to JSON graphs
  4. Chunking Module → Applies one of three chunking strategies
  5. Embedding Models (bge-large, TeleRoBERTa) → Generates vectors
  6. Vector Store → Stores embeddings for retrieval
  7. Retriever → Returns top-k chunks given a query

- Critical path: Image classification accuracy → VLM graph extraction quality (GED) → Chunking strategy → Embedding model choice → Retrieval accuracy. Errors cascade; GED > 5 likely degrades downstream retrieval.

- Design tradeoffs:
  - VLM at inference vs. pre-processed graphs: Authors eliminate VLM at inference for cost savings; trade-off is static graphs that don't adapt to new documents without reprocessing.
  - Chunk granularity: Finer chunks (each node) improve node-question accuracy but may fragment context for edge/decision questions.
  - Domain-adapted vs. general embeddings: TeleRoBERTa is smaller but domain-tuned; bge-large is larger but general-purpose.

- Failure signatures:
  - Low classification accuracy for flowcharts (misclassified as block diagrams) → No graph extraction attempted.
  - High GED (>5) on domain flowcharts → Missing/wrong nodes and edges in JSON, reducing retrieval relevance.
  - Retrieval accuracy drops significantly when graphs are interspersed with text (Table 4 shows ~15-25% drop).

- First 3 experiments:
  1. Reproduce image classification on labeled telecom images; target >80% accuracy for flowcharts before proceeding.
  2. Fine-tune Qwen2-VL with LoRA R=512, Alpha=512 on Flowlearn+augmented data; validate GED < 4 on held-out test set.
  3. Benchmark chunking strategies on QA dataset; start with "each node as one chunk" and TeleRoBERTa, target >50% top-1 for node-related questions before optimizing further.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does passing graph JSON structures as context affect the accuracy and faithfulness of the textual generator component in the RAG pipeline?
- Basis in paper: [explicit] The Conclusion states future work includes the "evaluation of generator output when JSON structures are passed as context to textual generator component of RAG."
- Why unresolved: The current study evaluates retrieval metrics (Top-k accuracy) but stops short of assessing the final answer generation quality based on the retrieved graphs.
- What evidence would resolve it: A comparative study measuring answer correctness (e.g., via RAGAS or human evaluation) using JSON context versus plain text summaries.

### Open Question 2
- Question: Can the fine-tuned VLM and graph embedding approach generalize to other semantic diagrams, such as UML Sequence diagrams, without extensive re-annotation?
- Basis in paper: [explicit] Section 5 identifies "extending the capabilities to other types of diagrams like UML Sequence diagrams which have a semantic structure" as an area of future research.
- Why unresolved: The current model and training data (Flowlearn) are specifically optimized for flowchart structures, which differ in node/edge semantics from sequence diagrams.
- What evidence would resolve it: Experimental results applying the current pipeline to a new dataset of UML sequence diagrams to benchmark retrieval performance.

### Open Question 3
- Question: What specific strategies can mitigate the performance drop observed when graph embeddings are interspersed with standard document text?
- Basis in paper: [inferred] Table 4 shows a significant drop in Top-1 accuracy (e.g., from 57.17% to 32.42% for TeleRoBERTa) when text is added; Section 5 calls for analyzing "performance with interspersed (document) text."
- Why unresolved: The paper identifies the drop but does not propose or test methods to reconcile the semantic density of JSON graphs with narrative text chunks.
- What evidence would resolve it: Ablation studies testing hybrid retrieval strategies, such as separate indexes or re-ranking mechanisms, in the mixed-modality setting.

## Limitations
- The synthetic flowchart training data (Flowlearn) may not fully represent real-world telecom flowchart complexity, potentially limiting generalizability to unseen document layouts.
- The manual annotation process for ground truth graph representations of PI Docs flowcharts is not described, raising questions about annotation consistency and reliability.
- While the approach eliminates VLM inference costs, it requires reprocessing documents when new flowcharts are encountered, limiting adaptability.

## Confidence
- **High confidence**: The general effectiveness of graph-based representations for preserving flowchart structure compared to VLM-generated prose summaries.
- **Medium confidence**: The claim that "each node as one chunk" chunking strategy performs best for node-related questions.
- **Low confidence**: The transferability of synthetic flowchart training data to real telecom documents.

## Next Checks
1. Test the retrieval system on flowcharts with complex layouts (crossing edges, nested subgraphs) not represented in synthetic training to validate robustness to real-world variations.
2. Benchmark the graph-based approach against VLM-generated prose summaries on edge-related and multi-hop decision questions to assess the trade-off between structure preservation and context completeness.
3. Evaluate retrieval accuracy when graph embeddings are interspersed with document text to quantify the performance degradation reported in the results (approximately 15-25% drop).