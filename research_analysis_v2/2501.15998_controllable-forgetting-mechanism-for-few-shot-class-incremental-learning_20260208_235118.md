---
ver: rpa2
title: Controllable Forgetting Mechanism for Few-Shot Class-Incremental Learning
arxiv_id: '2501.15998'
source_url: https://arxiv.org/abs/2501.15998
tags:
- novel
- base
- class
- classes
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of few-shot class-incremental
  learning (FSCIL) in ultra-low-shot scenarios, where only one example per novel class
  is available. The key issue addressed is catastrophic forgetting, where base class
  performance degrades significantly during adaptation to new classes.
---

# Controllable Forgetting Mechanism for Few-Shot Class-Incremental Learning

## Quick Facts
- arXiv ID: 2501.15998
- Source URL: https://arxiv.org/abs/2501.15998
- Authors: Kirill Paramonov; Mete Ozay; Eunju Yang; Jijoong Moon; Umberto Michieli
- Reference count: 33
- Primary result: Novel Class Detection (NCD) rule achieves up to 30% improvement in novel class accuracy with minimal base class forgetting (2%) in ultra-low-shot FSCIL.

## Executive Summary
This paper addresses the challenge of few-shot class-incremental learning (FSCIL) where only one example per novel class is available, focusing on controlling catastrophic forgetting of base classes. The authors propose a Novel Class Detection (NCD) decision rule that routes queries to either base or novel class branches based on a distance threshold, enabling predictable forgetting rates while improving novel class recognition. By adjusting the threshold α, users can a priori control the trade-off between base class accuracy and novel class learning, achieving significant improvements in novel class recognition without sacrificing base performance beyond a specified bound.

## Method Summary
The method involves training a backbone network on base classes using ProtoNet loss (or alternative contrastive methods), then freezing it to prevent forgetting. Base class prototypes are computed as centroids of training features and stored. During incremental sessions with novel classes, support samples are used to compute novel class prototypes while keeping the backbone frozen. The NCD rule classifies queries by routing them to the nearest base prototype if the minimum distance to all base prototypes is below threshold α, otherwise to the nearest novel prototype. The threshold α is calibrated on held-out base test data to achieve a target forgetting rate, ensuring controllable performance degradation on base classes.

## Key Results
- Achieves up to 30% improvement in novel class recognition (NCR) compared to standard inference methods
- Maintains controlled base class forgetting rate of 2% (or 5%) as specified by the threshold α
- NCD rule is effective across various backbone architectures including MobileNetV2, ResNet18, and DINOv2s
- Most beneficial in 1-shot settings (K=1), with diminishing returns as number of shots increases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distance-based routing separates base from novel class queries by exploiting geometric structure in feature space
- Core assumption: Base training produces well-clustered base class representations with meaningful distance structure
- Evidence: Abstract states "adjusts the degree of forgetting a priori while simultaneously enhancing performance on novel classes"; Section II-D defines NCD rule using distance threshold; limited direct corpus evidence but prototype effectiveness supported by neighbor papers

### Mechanism 2
- Claim: Forgetting rate can be controlled a priori by setting α before deployment without observing novel samples
- Core assumption: Held-out base test set is representative and feature space geometry remains stable
- Evidence: Abstract mentions "predictable base class performance"; Section II-E explains calculating accuracy a-priori; no direct corpus validation of a priori forgetting control

### Mechanism 3
- Claim: Frozen backbone preserves base knowledge while enabling rapid novel class adaptation via prototype computation
- Core assumption: Frozen features are discriminative for both base and novel classes; single prototypes adequately represent novel classes
- Evidence: Abstract reports "up to 30% improvement... while maintaining... forgetting rate of 2%"; Section II-C states backbone is frozen to prevent uncontrollable forgetting; consistent with neighbor papers using frozen components

## Foundational Learning

- Concept: **Prototypical Networks and Nearest-Centroid Classification**
  - Why needed: Method builds entirely on prototype representation and distance-based classification
  - Quick check: Given 5 samples of a class, compute class prototype and classify query by finding nearest prototype

- Concept: **Catastrophic Forgetting in Incremental Learning**
  - Why needed: Core motivation; understanding why weight updates on novel data degrade base performance
  - Quick check: If you fine-tune trained model on new classes without regularization, what happens to original class accuracy and why?

- Concept: **Out-of-Distribution Detection via Distance Thresholds**
  - Why needed: NCD rule is fundamentally an OOD detector; understanding distance-based anomaly detection clarifies base/novel trade-off
  - Quick check: In feature space with two clusters, how would setting distance threshold affect false positives vs. false negatives?

## Architecture Onboarding

- Component map: Backbone M -> Base Prototypes B_p and Novel Prototypes N_p -> NCD Decision Rule -> Two-Branch Classifier
- Critical path: 1) Base training → compute and store B_p, 2) Incremental session → receive support samples → compute N_p (backbone frozen), 3) Inference → extract query feature → apply NCD rule → route to branch → return prediction
- Design tradeoffs: Lower α increases novel routing but higher forgetting; higher α is conservative but reduces novel gains; ProtoNet vs contrastive base training affects feature separation; NCD most beneficial in 1-shot settings
- Failure signatures: NCD@5FOR worse than vanilla suggests switch to vanilla in multi-shot (K≥3); negative NCR gains indicate poor feature separation; large gap between NCR@2FOR and NCR@5FOR suggests high α sensitivity
- First 3 experiments: 1) Replicate ProtoNet base training on CIFAR100, compute B_p, plot FOR vs NCR curve with varying α, 2) Ablate number of novel classes (N1=1,5,10,20) with K=1 to verify scaling, 3) Compare NCD against vanilla inference on held-out base test set to confirm controllable forgetting at target FOR=2%

## Open Questions the Paper Calls Out
- Question: How can the system dynamically switch between NCD and vanilla inference as the number of shots per class increases?
- Question: How does the stability of the distance threshold (α) hold across multiple, sequential incremental sessions?
- Question: Can the threshold α be adapted online on-device without requiring a pre-defined, static forgetting budget?

## Limitations
- Assumes base class prototypes remain stable and well-separated across incremental sessions; poor cluster separation undermines controllable forgetting guarantees
- Pre-computed α values may not hold under feature drift, domain shift, or distribution changes during deployment
- NCD benefits diminish as number of shots increases (K≥3), where vanilla inference may outperform

## Confidence
- Controllable forgetting via pre-set α: **Medium-High**
- Base training stability assumption: **Medium**
- Feature space separation across backbones: **Medium**

## Next Checks
1. Test NCD performance when base class prototypes are intentionally perturbed (e.g., synthetic feature noise) to assess robustness to cluster instability
2. Evaluate whether α computed on base test set holds under domain-shifted incremental sessions (e.g., train on CUB200, test NCD on stylistically different subset)
3. Compare NCD with alternative OOD detectors (e.g., energy-based scores) on same FSCIL setup to isolate contribution of distance-threshold mechanism