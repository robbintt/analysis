---
ver: rpa2
title: 'Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap'
arxiv_id: '2512.04680'
source_url: https://arxiv.org/abs/2512.04680
tags:
- systems
- conference
- llms
- language
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a comprehensive survey on the application
  of generative AI, particularly large language models (LLMs) and diffusion models,
  to self-adaptive systems (SASs). The study systematically reviews 219 papers from
  four research fields, categorizing them into two main perspectives: enhancing SAS
  autonomy through MAPE-K feedback loop modules and improving human-on-the-loop interactions.'
---

# Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap

## Quick Facts
- **arXiv ID:** 2512.04680
- **Source URL:** https://arxiv.org/abs/2512.04680
- **Reference count:** 40
- **Primary result:** Comprehensive survey of 219 papers applying generative AI (LLMs, diffusion models) to self-adaptive systems, categorizing approaches by MAPE-K functions and HOTL interactions.

## Executive Summary
This paper presents a systematic literature review examining how generative AI, particularly large language models and diffusion models, can enhance self-adaptive systems. The study analyzes 219 papers from software engineering, AI, HCI, and robotics domains, organizing them into two perspectives: enhancing MAPE-K feedback loop autonomy and improving human-on-the-loop interactions. The survey identifies significant potential for GenAI in context understanding, anomaly detection, planning, and transparency, while highlighting key challenges including runtime transfer of design-time methods, managing uncertainties, and ensuring ethical deployment. The authors provide a research roadmap outlining future directions and practical considerations for integrating GenAI into SAS architectures.

## Method Summary
The authors conducted a systematic literature review across 13 top-tier conferences from 2017 to June 2024, initially identifying 5,874 papers and filtering them through two stages: first for GenAI relevance (LLMs, Transformers, diffusion models) and second for SAS relevance based on MAPE-K feedback loop and HOTL principles. The final corpus of 219 papers was categorized into hierarchical taxonomies covering both MAPE-K module enhancements and human interaction improvements. The methodology explicitly excluded non-transformer models, generic code generation papers, and vision-specific tasks. The systematic approach and categorization framework are detailed in Section 3, with results organized in hierarchical taxonomies (Figures 4 & 5).

## Key Results
- Generative AI shows significant potential for enhancing SAS autonomy through context understanding, anomaly detection, and novel planning paradigms.
- Two main application perspectives emerge: MAPE-K feedback loop enhancement and improved human-on-the-loop interactions.
- Key challenges include transferring design-time methods to runtime use, managing LLM uncertainties and hallucinations, and ensuring ethical deployment.
- The survey identifies specific opportunities for LLMs in data structuring, time series forecasting, event sequence prediction, and language-based planning.

## Why This Works (Mechanism)

### Mechanism 1: Semantic Context Understanding in Monitoring
LLMs leverage pre-trained understanding of code and natural language to parse unstructured log data into structured formats and detect semantic anomalies that rule-based parsers miss. This reduces manual effort in maintaining complex regex parsers while potentially identifying novel failure patterns. The mechanism relies on acceptable inference latency and token costs for runtime use, or offline/asynchronous analysis.

### Mechanism 2: LLMs as Generalized Planners via In-Context Learning
By treating planning as sequence modeling or reasoning tasks (Chain-of-Thought), LLMs can decompose high-level goals into executable steps and refine plans based on environmental feedback. This bypasses rigid pre-defined state machines, allowing flexible adaptation to novel situations. The approach assumes effective natural language description of environments and reliable mapping of text-based plans to system APIs.

### Mechanism 3: Human-on-the-Loop Transparency via Explanation
LLMs translate technical artifacts (logs, code diffs, decision models) into human-readable explanations, enabling users to audit AI decisions and correct errors. This bridges the gap between opaque AI decisions and human oversight, building trust in autonomous adaptations. The mechanism requires users with sufficient domain knowledge to validate explanations and assumes faithful representation of internal logic.

## Foundational Learning

- **Concept: MAPE-K Feedback Loop**
  - **Why needed here:** Fundamental architectural reference model for SAS (Monitor, Analyze, Plan, Execute, Knowledge) required to map GenAI capabilities to specific system functions.
  - **Quick check question:** Can you distinguish the responsibilities of the "Monitor" module versus the "Analyzer" module in a self-adaptive system?

- **Concept: In-Context Learning (ICL) & Prompt Engineering**
  - **Why needed here:** LLMs are often used via prompting (few-shot learning, Chain-of-Thought) rather than full fine-tuning; understanding input structuring is critical for implementation.
  - **Quick check question:** What is the difference between "zero-shot" prompting and providing "demonstrations" (few-shot) in an LLM prompt?

- **Concept: Uncertainty & Hallucination in LLMs**
  - **Why needed here:** The paper explicitly lists managing LLM uncertainties and hallucinations as key challenges requiring understanding of probabilistic model behavior.
  - **Quick check question:** Why might an LLM provide a different answer to the same prompt even at a temperature setting of zero?

## Architecture Onboarding

- **Component map:** Managed System -> Monitor (LLM-based Log Parser/Transformer Anomaly Detector) -> Knowledge (LLM-constructed World Models/Knowledge Graphs) -> Planner (LLM Agent with CoT/ToT or Diffusion-based Policy) -> Executor -> Human-on-the-Loop (Natural Language Explainer)

- **Critical path:**
  1. Collect raw logs/telemetry from Managed System
  2. Use LLM (Monitor) to structure data into semantic representation (Knowledge)
  3. Planner LLM queries Knowledge and reasons about necessary adaptation (e.g., using CoT)
  4. Generate explanation of proposed plan for human approval (Transparency)
  5. Deploy verified adaptation plan

- **Design tradeoffs:**
  - Latency vs. Capability: Large LLMs increase adaptation time; smaller models are faster but may lack generalization
  - Autonomy vs. Safety: Fully autonomous planning allows rapid evolution but risks hallucination; HOTL ensures safety but slows reaction
  - Determinism vs. Flexibility: Traditional planners are deterministic but rigid; GenAI planners are flexible but stochastic

- **Failure signatures:**
  - Token Cost Spike: Monitor error causes verbose log generation, exploding Planner input token count
  - Recursive Hallucination: Planner creates invalid plan; Monitor misinterprets error as complex anomaly, leading to more aggressive invalid re-planning
  - Context Window Overflow: Knowledge accumulation exceeds LLM context limit, causing model to "forget" initial constraints

- **First 3 experiments:**
  1. Compare standard regex parser against LLM-based parser on unstructured application logs to measure F1 score and parsing accuracy
  2. Ask LLM to generate remediation plan for simulated system failure (e.g., "High CPU usage"), execute in sandbox, measure Plan Success Rate vs. Hallucination Rate
  3. Generate explanation for specific system adaptation decision using LLM, conduct simple user study (N=3) to see if users correctly identify why system chose that action

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can design-time GenAI methods be effectively transferred to runtime use in SAS, specifically addressing distinct differences in objectives, information sources, and human involvement?
- Basis in paper: Explicitly identifies "Transfer of Design-time Methods to Runtime Use" as key research challenge, noting shift from offline/greenfield design to online adaptation and differing human stakeholder roles.
- Why unresolved: Existing GenAI research focuses on offline automation, lacking autonomy and real-time data processing capabilities required for runtime adaptation.
- What evidence would resolve it: Development of frameworks that refine prompting strategies using runtime execution data and demonstrate robust performance in dynamic, online environments.

### Open Question 2
- Question: How can the "alignment tax" in LLMs be mitigated to ensure they retain capability for adversarial or negative reasoning necessary for penetration testing and safety constraints?
- Basis in paper: Highlights "alignment tax" where RLHF processes aimed at positive values compromise model's ability to reason about negative or adversarial scenarios required for robust security.
- Why unresolved: Standard alignment methods optimize for helpfulness, inadvertently filtering out "negative" reasoning patterns essential for identifying vulnerabilities or defining safety constraints.
- What evidence would resolve it: Empirical studies showing specific prompt engineering or fine-tuning approaches can restore balance between human alignment and ability to simulate malicious behaviors.

### Open Question 3
- Question: What new evaluation artifacts (benchmarks and exemplars) are required to assess performance of GenAI modules within SAS, particularly regarding observation space and knowledge modularization?
- Basis in paper: States current exemplars often lack observation spaces and knowledge modularization necessary to effectively evaluate LLM-based methods.
- Why unresolved: Current benchmarks focus on utility metrics for traditional algorithms rather than specific token costs, stochastic variability, and observation requirements of LLMs.
- What evidence would resolve it: Creation of SAS exemplars that explicitly define observation spaces for LLMs and facilitate system-level ablation studies of GenAI integration.

## Limitations
- Literature search may have missed relevant papers from emerging conferences or those using different terminology
- Distinction between Analyzer and Planner functions proved challenging during categorization, leading to combined treatment
- Most reviewed papers focus on feasibility studies rather than large-scale deployments, limiting evidence of real-world effectiveness

## Confidence
- **High Confidence:** Systematic methodology and categorization framework are sound, with 219 papers reviewed across four research domains
- **Medium Confidence:** Identified challenges (transferring design-time methods to runtime, managing LLM uncertainties, ethical deployment) are well-supported by literature
- **Low Confidence:** Proposed research roadmap directions, while logical extensions of current work, lack validation through implementation or empirical studies

## Next Checks
1. Reproduce Categorization: Independently apply inclusion/exclusion criteria to random sample of 20 papers from corpus to verify categorization methodology
2. Implement Core Mechanism: Build prototype demonstrating LLM-based log parsing versus traditional regex parsing on real system logs to validate claimed accuracy improvements
3. Cost-Benefit Analysis: Measure actual token costs and latency implications of using LLMs for different MAPE-K functions in realistic simulation environment