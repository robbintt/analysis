---
ver: rpa2
title: 'Mellow: a small audio language model for reasoning'
arxiv_id: '2503.08540'
source_url: https://arxiv.org/abs/2503.08540
tags:
- audio
- reasoning
- sound
- mellow
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "Mellow introduces a small audio-language model (167M parameters)\
  \ designed to perform reasoning tasks over audio and text. It achieves state-of-the-art\
  \ performance among small models, scoring 52.11 on MMAU, comparable to models with\
  \ 50\xD7 more parameters and 60\xD7 more training data."
---

# Mellow: a small audio language model for reasoning

## Quick Facts
- **arXiv ID**: 2503.08540
- **Source URL**: https://arxiv.org/abs/2503.08540
- **Reference count**: 40
- **Primary result**: 167M parameter model achieves 52.11 MMAU score, outperforming models 50× larger

## Executive Summary
Mellow introduces a 167M parameter Audio-Language Model (ALM) that achieves state-of-the-art performance among small models for audio reasoning tasks. The model demonstrates that fine-tuning a small language model, combined with a non-linear audio projection and reasoning-focused synthetic training data, can match or exceed the performance of much larger ALMs. Mellow scores 52.11 on MMAU, comparable to models with 50× more parameters and 60× more training data, while maintaining the ability to perform on-device inference.

## Method Summary
Mellow uses HTSAT audio encoder (hierarchical token semantic transformer) to extract audio features, which are projected through a non-linear mapper (2-layer MLP with LayerNorm) and concatenated with text embeddings. The architecture is trained on ReasonAQA, a dataset of 1M audio-grounded QA pairs where 70% is synthetic data generated using Llama 3 prompts designed to elicit reasoning. The model uses SmolLM2 (135M parameters) as the language model, which is fully fine-tuned rather than frozen or parameter-efficiently tuned. Training uses next-token prediction objective with cross-entropy loss over 30 epochs.

## Key Results
- Achieves 52.11 MMAU score, comparable to models with 50× more parameters
- Outperforms existing small ALMs in audio understanding, deductive reasoning, comparative reasoning, and captioning
- Ablation studies show fine-tuning SLM, non-linear mapper, and reasoning-focused synthetic data are critical to performance
- Demonstrates on-device inference capability while maintaining strong reasoning performance

## Why This Works (Mechanism)

### Mechanism 1: Fine-tuning the SLM
Fine-tuning the small language model yields superior reasoning performance compared to freezing the LM or using parameter-efficient tuning (LoRA). Unfreezing the SLM allows audio projections to deeply integrate with the model's semantic reasoning pathways, enabling direct alignment of audio features with reasoning logic.

### Mechanism 2: Reasoning-focused Synthetic Data
Training on synthetically generated reasoning chains (ReasonAQA) significantly enhances deductive and comparative reasoning capabilities. The model learns causal and logical associations between audio features and abstract concepts through explicit reasoning-focused questions rather than simple description tasks.

### Mechanism 3: Temporal Resolution Retention
Retaining temporal resolution in the audio projection improves performance on tasks requiring sequence understanding. The architecture preserves temporal dynamics by concatenating global audio summaries with framewise event presence maps, allowing the LM to attend to sequences of audio events.

## Foundational Learning

- **Next-Token Prediction Objective (Causal LM)**: Mellow is fundamentally a generative model trained to predict the next token, explaining its ability to generate open-ended explanations and reasoning chains. Quick check: How does the model handle the input of two different audio files simultaneously during the training objective?

- **Audio Encoders (CNN vs. Transformer)**: Mellow uses HTSAT (Swin Transformer) instead of CNN14. The choice of encoder determines the quality of the "audio event presence map" that the SLM relies on. Quick check: Why does the paper argue that HTSAT's higher mAP on AudioSet directly contributes to better reasoning scores on MMAU?

- **Synthetic Data Generation (Teacher-Student)**: The core innovation is the ReasonAQA dataset, where knowledge distillation from a larger LLM (Llama 3) generates training data. Quick check: What are the specific failure modes of OpenAQA that ReasonAQA attempts to fix regarding "refusal" and "world knowledge"?

## Architecture Onboarding

- **Component map**: Raw Audio (32kHz, 10s) + Text Prompt -> HTSAT Encoder -> Mapper (2-layer MLP + LayerNorm) -> Downsampler (8×) -> [Audio Proj 1] + [Separator] + [Audio Proj 2] + [Separator] + [Text Embedding] -> SmolLM2 (135M, fully fine-tuned)

- **Critical path**: The Mapper projection is critical. Mellow uses a simple non-linear projection instead of standard Q-Former. If this projection fails to align audio embeddings effectively before the LM, the fine-tuning process destabilizes.

- **Design tradeoffs**: Projection Complexity vs. LM Freezing - frozen LMs require complex Transformer mappers, while fine-tuned LMs can use simple non-linear mappers. World Knowledge vs. Audio Reasoning - fine-tuning causes loss of general world knowledge to optimize for audio tasks.

- **Failure signatures**: Low MMAU Score on Speech (model is not trained on speech content), Instruction Misalignment (fails to select valid MCQ options on out-of-distribution questions).

- **First 3 experiments**:
  1. Projection Ablation: Train three variants (Linear, Non-linear, Transformer Mapper) with LM frozen to verify frozen LMs require complex mappers, then switch to fine-tuning to verify performance inversion.
  2. Data Type Evaluation: Train on "Type 1" (general synthetic) vs. "Type 2" (expert-prompt synthetic) data to measure impact of prompt engineering on reasoning capability.
  3. Encoder Swap: Replace HTSAT with CNN14 while keeping LM pipeline constant to quantify impact of audio representation quality on final reasoning score.

## Open Questions the Paper Calls Out

### Open Question 1
How do performance and efficiency trade-offs shift when applying scaling laws to the Mellow architecture with significantly larger audio datasets? The authors restricted training audio to fixed sets to isolate model design improvements rather than data scaling effects.

### Open Question 2
Can the Mellow recipe be effectively extended to speech content tasks (e.g., transcription or translation) without increasing model scale? The current study focused on sound and music reasoning, deliberately excluding speech content.

### Open Question 3
How can small Audio-Language Models mitigate catastrophic forgetting of general world knowledge during full fine-tuning for audio reasoning? Fine-tuning causes the model to forget factual knowledge unrelated to audio while maintaining high audio reasoning performance.

## Limitations
- Model is not trained for speech-content tasks such as transcription or translation
- Fine-tuning causes the model to forget factual knowledge unrelated to audio
- Performance on out-of-distribution MCQs may fail due to instruction following limitations

## Confidence

**High Confidence** in core architecture claims:
- 52.11 MMAU score well-supported by table comparisons against established baselines
- Fine-tuning superiority over frozen LM approaches demonstrated through controlled ablation studies
- Non-linear mapper's effectiveness validated across multiple experimental conditions

**Medium Confidence** in scalability claims:
- 50× parameter reduction impressive but comparison focuses on small-to-medium ALMs
- "60× less training data" claim requires careful interpretation of synthetic data generation process

**Low Confidence** in out-of-distribution generalization:
- Strong performance on MMAU but limited testing on truly diverse audio domains
- Ablation studies focus on MMAU variants rather than comprehensive cross-dataset validation

## Next Checks

1. **Catastrophic Forgetting Analysis**: Systematically evaluate fine-tuned model's performance degradation on general language tasks compared to frozen LM baseline to quantify the tradeoff between audio specialization and general capability retention.

2. **Synthetic Data Robustness**: Vary Llama 3 prompting strategy systematically (temperature, prompt structure, expert knowledge injection) and measure resulting variance in model performance on MMAU to establish sensitivity to synthetic data quality.

3. **Temporal Resolution Sensitivity**: Conduct controlled experiment varying downsampling factor (2×, 4×, 8×, 16×) while keeping all other components constant, measuring impact on MMAU reasoning tasks requiring temporal understanding versus those that don't.