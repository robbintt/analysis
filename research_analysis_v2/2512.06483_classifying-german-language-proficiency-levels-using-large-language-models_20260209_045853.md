---
ver: rpa2
title: Classifying German Language Proficiency Levels Using Large Language Models
arxiv_id: '2512.06483'
source_url: https://arxiv.org/abs/2512.06483
tags:
- cefr
- levels
- classification
- language
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a study on using Large Language Models (LLMs)
  for automatic classification of German texts into CEFR proficiency levels (A1-C2).
  The authors construct a balanced dataset by combining multiple existing corpora
  with synthetic data, then evaluate three LLM-based approaches: prompt engineering,
  fine-tuning of LLaMA-3-8B-Instruct, and probing-based classification using internal
  neural states.'
---

# Classifying German Language Proficiency Levels Using Large Language Models

## Quick Facts
- arXiv ID: 2512.06483
- Source URL: https://arxiv.org/abs/2512.06483
- Authors: Elias-Leander Ahlers; Witold Brunsmann; Malte Schilling
- Reference count: 12
- Fine-tuned LLaMA-3-8B-Instruct achieves weighted F1 score of 0.769 for CEFR classification

## Executive Summary
This paper presents a study on using Large Language Models (LLMs) for automatic classification of German texts into CEFR proficiency levels (A1-C2). The authors construct a balanced dataset by combining multiple existing corpora with synthetic data, then evaluate three LLM-based approaches: prompt engineering, fine-tuning of LLaMA-3-8B-Instruct, and probing-based classification using internal neural states. Results show that the fine-tuned model achieves a weighted F1 score of 0.769, significantly outperforming prior methods (0.702), with perfect group accuracy (100%) for adjacent-level classifications. The probing approach also improves over prompt-based methods, indicating that internal states contain valuable information for classification. The study demonstrates that LLMs, particularly when fine-tuned, offer a powerful and scalable alternative for CEFR classification tasks.

## Method Summary
The study combines multiple German learner corpora (Falko and MERLIN) with synthetic A1 data to create a balanced dataset of 1,567 texts across CEFR levels A1-C2. Three approaches are evaluated: prompt-based classification using different few-shot templates, supervised fine-tuning of LLaMA-3-8B-Instruct with LoRA (r=32, alpha=32) for 3 epochs, and probing-based classification using an MLP trained on the model's internal representations. The fine-tuning uses standard cross-entropy loss with AdamW optimizer, learning rate 2e-4, and 400 warmup steps. The probing classifier consists of a 4-layer MLP (1024-512-256-6) trained on the last-token hidden states from the base LLaMA-3-8B model.

## Key Results
- Fine-tuned LLaMA-3-8B-Instruct achieves weighted F1 score of 0.769
- Probing-based approach improves over prompt-based methods, indicating internal states contain valuable information
- Group accuracy (adjacent level tolerance) reaches 100% for the fine-tuned model
- Model performs best on A1 and A2 levels, with B2 showing the lowest individual F1 score (0.681)

## Why This Works (Mechanism)
None

## Foundational Learning
- **CEFR Framework**: Standardized system for describing language proficiency levels. Needed to understand the classification task and benchmark against prior work. Quick check: Verify understanding of what distinguishes A1 from C2 texts.
- **LoRA Fine-Tuning**: Parameter-efficient method for adapting large models. Needed to understand how the model was specialized for classification. Quick check: Confirm understanding of how LoRA reduces parameter count while maintaining performance.
- **Probing Classifiers**: Method of extracting information from model internal states. Needed to interpret the probing results and their significance. Quick check: Understand how MLP architecture maps hidden states to classification outputs.

## Architecture Onboarding

**Component Map**
LLaMA-3-8B-Instruct -> LoRA Adapter -> Fine-tuning Pipeline -> Classification Output

**Critical Path**
Data preparation → Model loading → LoRA configuration → Training loop → Evaluation

**Design Tradeoffs**
- Uses parameter-efficient LoRA instead of full fine-tuning to reduce computational cost
- Combines real and synthetic data to address class imbalance, particularly for A1 level
- Employs probing approach to leverage internal model knowledge without explicit training

**Failure Signatures**
- Class collapse on intermediate levels (particularly B2) may indicate domain shift between corpora
- Probing failure likely indicates incorrect base vs. instruct model usage
- Early overfitting suggests dataset too small for given architecture

**3 First Experiments**
1. Verify synthetic A1 data quality by manual inspection of generated samples
2. Compare class distributions between training and test sets to check balance
3. Test probing classifier with base model vs. instruct model to confirm sensitivity to model version

## Open Questions the Paper Calls Out
None

## Limitations
- Specific test set composition not publicly available, making exact score reproduction difficult
- A1 class entirely synthetic, raising questions about data quality and potential bias
- Probing methodology lacks complete detail for full replication

## Confidence

**Major Uncertainties and Limitations**
- Data Split Dependence: The reported F1 scores (0.769 weighted) are achieved on a specific, non-public test set (25 samples per level). Without access to the exact split, reproduced scores may vary due to sampling variance in small classes, particularly B2.
- Synthetic Data Quality: The A1 class is entirely synthetic, generated via Claude 3.5 Sonnet. While the prompt is provided, the quality and representativeness of these samples relative to authentic A1 German learner data is uncertain and may inflate or bias results.
- Probing Methodology: The probing approach shows improved performance over prompting, but uses a specific MLP architecture and training procedure not fully detailed. The base vs. instruct model distinction is critical but easily misconfigured.

**Confidence Labels**
- **High Confidence**: The overall methodological framework (LLaMA-3-8B-Instruct fine-tuning with LoRA) is standard and reproducible. The comparative improvement over baseline prompt-based methods is plausible given the literature.
- **Medium Confidence**: The specific F1 scores (0.769) are conditionally reproducible if the exact data split is used. The group accuracy of 100% for adjacent levels is a strong claim that depends heavily on the test set composition.
- **Low Confidence**: The probing results and their interpretation regarding internal model states are less certain due to limited methodological detail.

## Next Checks
1. Reconstruct the dataset using the specified corpora and perform a stratified split. Compare class distributions and synthetic A1 text quality to the original.
2. If the authors release their fine-tuned model, compare its performance against a reproduction using the described hyperparameters and LoRA configuration.
3. Train models with and without the synthetic A1 data to quantify its contribution to the final F1 score and assess potential bias.