---
ver: rpa2
title: Initial Distribution Sensitivity of Constrained Markov Decision Processes
arxiv_id: '2510.00348'
source_url: https://arxiv.org/abs/2510.00348
tags:
- initial
- bound
- distribution
- bounds
- regret
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper analyzes how the optimal value of constrained Markov\
  \ decision processes (CMDPs) varies with different initial state distributions,\
  \ addressing the challenge that optimal policies may change when initial distributions\
  \ shift. The authors derive three types of bounds\u2014using dual feasibility, linear\
  \ programming perturbation analysis, and concavity\u2014to estimate the optimal\
  \ value without re-solving the CMDP."
---

# Initial Distribution Sensitivity of Constrained Markov Decision Processes

## Quick Facts
- arXiv ID: 2510.00348
- Source URL: https://arxiv.org/abs/2510.00348
- Reference count: 15
- One-line primary result: Three bounds (duality, perturbation, concavity) estimate CMDP optimal value under initial distribution shifts without re-solving, with duality bound consistently tightest (median 0.014% relative looseness).

## Executive Summary
This paper analyzes how the optimal value of constrained Markov decision processes (CMDPs) varies with different initial state distributions, addressing the challenge that optimal policies may change when initial distributions shift. The authors derive three types of bounds—using dual feasibility, linear programming perturbation analysis, and concavity—to estimate the optimal value without re-solving the CMDP. The duality-based bound is consistently the tightest, with relative looseness as low as 0.014% in experiments. The bounds also enable analysis of policy robustness, including inner approximations of the set of initial distributions for which a policy has low regret and computing minimal regret over uncertainty sets. Experiments on random CMDPs and a water pendulum task validate the tightness and utility of the bounds, with the duality-based approach being computationally efficient and accurate.

## Method Summary
The paper reformulates the CMDP as a linear program (LP) using occupation measures, then derives three upper bounds on the optimal value V*(β₁) when the initial distribution shifts from nominal β₀. The duality-based bound evaluates the nominal dual solution at the new distribution, leveraging that dual variables remain feasible across distributions. The perturbation bound uses LP sensitivity analysis, bounding value changes via the norm of the reward vector and the inverse of the constraint matrix conditioning. The concavity bound exploits that V*(β) is concave in β, requiring solving multiple CMDPs. Experiments compare these bounds to ground truth values obtained by re-solving CMDPs for 150 random distributions at varying total variation distances from uniform β₀, plus validation on a water pendulum task with 2500 states.

## Key Results
- Duality-based bound consistently tightest with median relative looseness of 0.014-0.297% across TV distance bins
- Perturbation bounds are valid but looser, with looseness increasing with distribution shift magnitude
- Robustness analysis using duality bounds successfully inner-approximates the set of distributions where policies maintain low regret

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The optimal value of a CMDP under a shifted initial distribution can be upper-bounded by evaluating the nominal distribution's dual solution at the new distribution, without re-solving the primal.
- **Mechanism:** In the CMDP Linear Program (LP), the initial distribution β appears only in the objective of the dual problem, not the constraints. Therefore, the optimal dual variables (W*(β₀), λ*(β₀)) from a nominal distribution β₀ remain feasible for the dual problem of any new distribution β₁. Since the dual is a minimization problem, evaluating the dual objective at these feasible points yields a valid upper bound on the new optimal value.
- **Core assumption:** The dual solution obtained for β₀ is optimal and finite (Strong Duality holds).
- **Evidence anchors:**
  - [abstract]: Mentions deriving bounds "using duality analysis of CMDPs."
  - [section III.A]: Theorem 1 proof states "it is still feasible when the Problem (D) is solved for β₁... β only appears in the cost function... but does not impact its feasible set."
  - [corpus]: Neighbor papers (e.g., "Primal-Dual Sample Complexity Bounds...") support the general efficacy of primal-dual methods in CMDPs, though not this specific sensitivity bound.
- **Break condition:** If the dual solution is degenerate or unbounded (rare in finite discounted CMDPs), or if the problem is infeasible for β₁ while feasible for β₀ (though the bound technically holds, the "value" might be undefined/infinite).

### Mechanism 2
- **Claim:** The sensitivity of the optimal value to initial distribution shifts is bounded by the product of the reward norm and the inverse of the LP's constraint matrix conditioning.
- **Mechanism:** This approach treats the change in initial distribution Δβ as a perturbation of the right-hand side of the LP's equality constraints. Using classical LP perturbation theory (specifically conditioning of the basis matrix R), the change in the optimal occupation measure ρ is bounded. By the Cauchy-Schwarz inequality, the change in value |rᵀΔρ| is then bounded by ||r|| ||R⁻¹|| ||Δβ||.
- **Core assumption:** The matrix R (related to active constraints) is non-singular and well-conditioned; the optimal basis does not change abruptly (though the bound accounts for the singularity via R⁻¹).
- **Evidence anchors:**
  - [section III.B]: Theorem 3 derives the bound |V*(β₁) - V*(β₀)| ≤ ||r|| ||R⁻¹|| ||Δβ||.
  - [section V]: Table II shows perturbation bounds are valid but looser than duality bounds.
- **Break condition:** If the active constraint set R is ill-conditioned (nearly singular), ||R⁻¹|| explodes, rendering the bound trivially large.

### Mechanism 3
- **Claim:** The set of initial distributions for which a policy maintains low regret can be inner-approximated by a polytope defined by linear inequalities derived from the duality bound.
- **Mechanism:** The true regret constraint V*(β) - Vπ(β) ≤ ε is non-linear in β because V*(β) is complex. By substituting V*(β) with the linear duality-based upper bound βᵀW*(β₀) - τᵀλ*(β₀), the constraint becomes linear in β. The intersection of these linear halfspaces forms a polytope that is strictly contained within the true robustness set.
- **Core assumption:** The duality bound is reasonably tight; a linear approximation suffices to capture a meaningful subset of the robustness region.
- **Evidence anchors:**
  - [section IV]: Proposition 1 defines the polytope matrix inequality.
  - [section V.C]: "Hit rates" experiments show the inner approximation (polytope) closely tracks the true regret set size (e.g., 0.26 vs 0.33 hit rate).
- **Break condition:** If the duality bound is significantly loose, the polytope may be empty or far smaller than the true robustness region, failing to identify viable distributions.

## Foundational Learning

- **Concept: Linear Programming (LP) Duality**
  - **Why needed here:** The tightest and most computationally efficient bound (Mechanism 1) relies entirely on the property that the optimal solution to a dual LP provides a certificate of feasibility for the primal objective.
  - **Quick check question:** If an LP is a minimization problem, does a feasible solution to its dual provide an upper or lower bound on the primal optimal value?

- **Concept: Occupation Measures**
  - **Why needed here:** The paper reformulates the sequential CMDP problem into a static LP using "occupation measures" (state-action visitation frequencies). Understanding this mapping is required to interpret the "perturbation" bounds and the LP structure.
  - **Quick check question:** How does the discount factor γ affect the magnitude of the occupation measure for a given state-action pair over an infinite horizon?

- **Concept: Regret in CMDPs**
  - **Why needed here:** The paper defines a specific (δ, ε)-regret to quantify policy robustness. This differs from standard regret by including constraint violation δ, which is crucial for the "safe RL" context.
  - **Quick check question:** In the paper's definition, does a higher constraint violation allowance (δ) typically increase or decrease the "optimal value" benchmark V*(β, τ-δ) used to calculate regret?

## Architecture Onboarding

- **Component map:** Solver (Nominal) -> Bound Calculator -> Robustness Analyzer
- **Critical path:**
  1. Solve the CMDP dual problem (D) once for the nominal β₀.
  2. Extract dual variables W*(β₀) and λ*(β₀).
  3. For any new β₁, compute the dot product β₁ᵀW*(β₀) for an immediate performance estimate.
  4. (Optional) If robustness is required, construct the linear constraints in Proposition 1 to find valid β regions.

- **Design tradeoffs:**
  - **Tightness vs. Complexity:** The **Duality bound** is the fastest and tightest but provides only an upper bound. The **Perturbation bound** offers both upper/lower bounds but is looser and requires matrix inversion (R⁻¹). **Concavity** requires solving |S|+1 CMDPs and is generally intractable for large systems.
  - **Approximation Quality:** Using the linear duality bound for robustness (Problem 1) provides an *inner* approximation (conservative: might miss some valid distributions), whereas a lower bound would provide an *outer* approximation.

- **Failure signatures:**
  - **Trivial Bounds:** If the duality gap is large (less likely in LP but possible in approximations), the bound may exceed the worst-case value.
  - **Ill-conditioning:** If the matrix R in Theorem 2 is near-singular, the perturbation bound will explode, yielding no information.
  - **Empty Polytope:** In robustness analysis, if ε is too small or the nominal policy is fragile, the linear approximation of the regret set may return an empty set even if a non-linear robust region exists.

- **First 3 experiments:**
  1. **Validate Tightness:** Replicate Table II using randomly generated CMDPs. Measure the "relative looseness" of the Duality vs. Perturbation bounds as Total Variation distance increases.
  2. **Robustness Hit Rate:** Implement the "hit rate" test from Section V.C. Compare the volume of the inner-approximated polytope against a brute-force sampling of the true regret set.
  3. **Transferability Test:** Train a policy on a specific β_nominal (e.g., Pendulum upright). Use the bounds to predict performance on β_sideways without re-solving, and verify against the true optimal value for β_sideways.

## Open Questions the Paper Calls Out
- Can the sensitivity analysis and bounding techniques be extended to account for uncertainty or perturbations in the transition dynamics P(s'|s,a)?
- How can the duality-based bounds be adapted for continuous state spaces or large-scale problems where solving the full occupation measure LP is infeasible?
- Can a tight lower bound on the optimal value V*(β₁) be derived using the dual feasibility method to match the tightness of the proposed upper bound?

## Limitations
- Pruning strategy for random CMDPs is unspecified, affecting transition sparsity
- Discretization and dynamics parameters for the water pendulum task are missing
- Constraint thresholds τ and discount factor γ values are not provided

## Confidence
- **High**: Duality-based bound tightness and computational efficiency
- **Medium**: Perturbation bound validity in ill-conditioned cases; robustness approximation coverage
- **Medium**: Generalizability to CMDPs with different sparsity patterns or non-uniform pruning

## Next Checks
1. Test bound performance on CMDPs with varying transition sparsity to assess perturbation bound robustness
2. Compare polytope-based robustness analysis against a sampling-based outer approximation of the true regret set
3. Validate transferability predictions on a real-world CMDP (e.g., inventory management) with known initial distribution shifts