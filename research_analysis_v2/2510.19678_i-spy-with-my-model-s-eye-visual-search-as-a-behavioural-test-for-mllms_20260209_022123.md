---
ver: rpa2
title: 'I Spy With My Model''s Eye: Visual Search as a Behavioural Test for MLLMs'
arxiv_id: '2510.19678'
source_url: https://arxiv.org/abs/2510.19678
tags:
- search
- visual
- task
- conjunctive
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies classic visual search paradigms from cognitive
  psychology to evaluate the perceptual capabilities of multimodal large language
  models (MLLMs). The authors adapt tasks targeting size, colour, and lighting features
  to test for human-like "pop-out" effects and capacity limits in disjunctive (single
  feature) versus conjunctive (multiple feature) search.
---

# I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs

## Quick Facts
- arXiv ID: 2510.19678
- Source URL: https://arxiv.org/abs/2510.19678
- Reference count: 40
- Primary result: Visual search paradigms reveal human-like perceptual pop-out effects and capacity limits in MLLMs, providing a cognitively grounded diagnostic tool.

## Executive Summary
This paper applies classic visual search paradigms from cognitive psychology to evaluate the perceptual capabilities of multimodal large language models (MLLMs). The authors adapt tasks targeting size, colour, and lighting features to test for human-like "pop-out" effects and capacity limits in disjunctive (single feature) versus conjunctive (multiple feature) search. Experiments on models like GPT-4o and Claude Sonnet reveal human-like pop-out effects in colour and size-based search, declining accuracy with increasing distractor numbers in conjunctive search, and vertical lighting priors consistent with human visual cognition. Fine-tuning and mechanistic interpretability analyses support these findings, showing improved conjunctive search performance and task-relevant representations in later network layers. The study demonstrates visual search as a cognitively grounded diagnostic tool for probing MLLM perception.

## Method Summary
The study adapts three visual search paradigms from cognitive psychology: Circle Sizes (size discrimination), 2 Among 5 (conjunctive vs disjunctive search with digits), and Light Priors (lighting direction discrimination). These tests evaluate for "pop-out" effects (set-size independence) and capacity limits across 400×400 pixel images with targets and distractors. Two evaluation variants are used: Cells (identify 2×2 grid cell containing target) and Coordinates (return x,y coordinates). The experiments test zero-shot performance of MLLMs (GPT-4o, Claude Sonnet 3.5, Llama 3.2 90B) with temperature=0, and include fine-tuning experiments on GPT-4o using OpenAI's SFT API (10/100/1000 examples).

## Key Results
- MLLMs exhibit human-like pop-out effects in colour and size-based disjunctive (single feature) search, showing stable accuracy across increasing distractor counts
- Capacity limits emerge in conjunctive (multiple feature) search, with declining accuracy as distractor numbers increase, though fine-tuning can partially mitigate this
- MLLMs incorporate natural scene priors such as lighting direction into object representations, showing enhanced detection for vertically-lit objects and novelty salience for bottom-lit targets

## Why This Works (Mechanism)

### Mechanism 1: Pop-out Effect for Primitive Features
- **Claim:** MLLMs exhibit set-size-independent detection when targets differ from distractors along a single primitive dimension (color or size), mirroring human pre-attentive processing.
- **Mechanism:** Single-feature salience allows parallel processing without capacity limits; accuracy remains flat as distractor count increases.
- **Core assumption:** Visual encoders in MLLMs extract low-level feature maps similar to early human visual cortex.
- **Evidence anchors:**
  - [abstract] "advanced MLLMs exhibit human-like pop-out effects in colour or size-based disjunctive (single feature) search"
  - [section 3.1] GPT-4o accuracy for Large targets remains stable across distractors (r = –0.028, p = 0.082)
  - [corpus] Limited direct corpus support; related work on fine-grained perception (Argus Inspection) confirms persistent challenges in granular visual tasks
- **Break condition:** If feature differences fall below salience threshold, pop-out disappears and serial search behavior emerges.

### Mechanism 2: Capacity Limits Under Feature Binding
- **Claim:** When targets require binding multiple features (e.g., shape AND color), MLLMs show declining accuracy with more distractors, indicating serial-like processing constraints.
- **Mechanism:** Conjunctive search demands attentional binding of primitive features; each additional distractor adds computational cost.
- **Core assumption:** MLLMs lack parallel compositional representations for multi-feature conjunctions.
- **Evidence anchors:**
  - [abstract] "capacity limits for conjunctive (multiple feature) search"
  - [section 3.2] GPT-4o shows significant negative correlation with set size in Shape Conjunctive (r = –0.267) and Shape-Colour Conjunctive (r = –0.244)
  - [corpus] Related work (Campbell et al., 2024) reports serial-search-like behavior in conjunctive tasks
- **Break condition:** Fine-tuning can reduce but not eliminate capacity limits; does not achieve true pop-out even after 1000 examples.

### Mechanism 3: Natural Scene Priors for Lighting Direction
- **Claim:** MLLMs incorporate environmental priors about light source direction, showing enhanced detection for vertically-lit objects and novelty salience for bottom-lit targets.
- **Mechanism:** Training on real-world imagery encodes "light-from-above" expectations; violations (bottom-lit) increase salience.
- **Core assumption:** Training data contains sufficient natural lighting regularities for implicit prior learning.
- **Evidence anchors:**
  - [abstract] "MLLMs, like humans, incorporate natural scene priors such as lighting direction into object representations"
  - [section 3.3] GPT-4o shows 73% accuracy for bottom-lit vs 55% for top-lit spheres; vertical gradient advantage mirrors human baseline
  - [corpus] No direct corpus support for lighting priors specifically; adjacent work on cross-modal inconsistency suggests representational gaps may affect such priors
- **Break condition:** If training data lacks directional shading diversity, no lighting prior should emerge; smaller models (Claude-Haiku, Llama 11B) show attenuated effects.

## Foundational Learning

- **Concept: Feature Integration Theory (Treisman & Gelade, 1980)**
  - **Why needed here:** Provides the theoretical framework distinguishing parallel pop-out (single feature) from serial search (feature binding).
  - **Quick check question:** Can you explain why searching for a red circle among blue circles is faster than searching for a red circle among red squares and blue circles?

- **Concept: Marr's Computational Level of Analysis**
  - **Why needed here:** The paper targets this level—what the system does and why—rather than implementation details.
  - **Quick check question:** What questions does Marr's computational level answer that the algorithmic level does not?

- **Concept: Linear Probing for Mechanistic Interpretability**
  - **Why needed here:** Used to identify which network layers encode task-relevant features.
  - **Quick check question:** If a linear probe achieves 90% accuracy on layer 20 but 55% on layer 5, what does this suggest about where the feature is represented?

## Architecture Onboarding

- **Component map:** Vision encoder → Projector → Language model (transformer layers) → Output
- **Critical path:** Image → Vision encoder produces visual embeddings → Projector aligns visual embeddings with language model input space → Transformer layers progressively integrate visual and linguistic representations → Disjunctive search resolved early; conjunctive search requires deeper layers
- **Design tradeoffs:** Larger models (GPT-4o, Claude Sonnet) show more human-like behavior but remain opaque; Open-weight models (Llama 90B) enable mechanistic analysis but show weaker perceptual capabilities; Fine-tuning improves specific tasks but may not generalize across feature domains (shape transfers better than shape+color)
- **Failure signatures:** Spatial bias - Models preferentially select certain quadrants when uncertain (e.g., Claude Sonnet → bottom-left; GPT-4o → top-right under difficulty); Invalid responses - Coordinate outputs outside image bounds; refusals when uncertain; Chance-level performance - Smaller models (Claude-Haiku, Llama 11B) fail even on disjunctive pop-out tasks
- **First 3 experiments:** 1. Replicate Circle Sizes (Large condition) with 0-20 distractors on your target model; verify pop-out via correlation analysis (expect r ≈ 0); 2. Run Shape Conjunctive 2 Among 5 with 0-99 distractors; confirm declining accuracy slope matches paper's r ≈ –0.27 benchmark; 3. Probe layer-wise representations using linear classifiers on residual stream; map where disjunctive vs conjunctive task information becomes linearly separable

## Open Questions the Paper Calls Out

- **Open Question 1:** Do MLLMs exhibit human-like visual search behavior for complex feature dimensions such as texture, motion, and occlusion? The authors state in the Discussion that "Future work could extend this framework to other feature dimensions—such as texture, motion, or occlusion." The current study deliberately restricted its scope to three specific features: size, colour, and lighting direction. It is unknown if the observed "pop-out" effects and capacity limits generalize to more dynamic or complex visual properties.

- **Open Question 2:** How do MLLMs perform on visual search tasks when subjected to strict temporal constraints or increased compositional load? The authors explicitly call for future work to "investigate how models respond under compositional load or temporal constraints." While human baselines were time-limited (e.g., 1500ms), the MLLMs were allowed to process inputs without strict temporal bounds. It is unclear if the models' accuracy declines under time pressure or if capacity limits manifest differently when processing speed is a variable.

- **Open Question 3:** Are the observed search behaviors robust across different prompt phrasings, or are they artifacts of specific instruction templates? The Discussion notes a limitation: "LLMs are known to be sensitive to the way that prompts are phrased... and we explored only a few prompts due to budgetary constraints." The models demonstrated specific behaviors (like pop-out) based on a limited set of prompts. If these cognitive-like behaviors disappear with slight wording changes, the validity of using these tasks as diagnostic tools is weakened.

- **Open Question 4:** Does fine-tuning on conjunctive search tasks enhance MLLM performance through a mechanism analogous to human "unitization" or via a distinct computational process? The authors note that unlike humans, who typically show only partial transfer, GPT-4o showed mild transfer to a distinct task ("T-among-L"), "suggesting that fine-tuning may enhance MLLM performance through a different mechanism." While behavioral improvements were observed, the internal representational shift was not fully characterized. We do not know if the model is learning to bind features (as humans do) or learning a general heuristic that does not rely on compositional binding.

## Limitations

- Cross-model comparisons face potential confounds from architectural differences beyond scale - vision encoders, projectors, and training data vary substantially across models
- Lighting priors experiment relies on subjective sphere detection without controlled illumination conditions, making it difficult to isolate true perceptual priors from contextual cues
- Fine-tuning results show inconsistent transfer patterns (shape improves more than shape+color), suggesting the mechanisms for conjunctive search capacity limits remain incompletely understood

## Confidence

- **High confidence:** Disjunctive search pop-out effects (stable accuracy across distractor counts for single-feature targets) - directly measured with clear statistical significance
- **Medium confidence:** Conjunctive search capacity limits (declining accuracy with more distractors) - consistent across models but fine-tuning improvements suggest partial plasticity rather than fundamental architectural constraint
- **Low confidence:** Lighting priors interpretation - human baseline shows same directional advantage but without controlled stimuli, the source of this effect (prior vs environmental cues) remains ambiguous

## Next Checks

1. Replicate the conjunctive search capacity limit finding using synthetic data where individual feature discriminability is controlled, isolating whether the limit stems from feature binding complexity or simple perceptual noise
2. Conduct ablation studies on vision encoder architectures (ViT vs ConvNeXt) while holding language model constant to determine if perceptual capabilities depend more on vision or language components
3. Test models on reversed lighting conditions (artificial "light-from-below" scenes) to verify that priors are learned rather than simply responding to illumination intensity cues