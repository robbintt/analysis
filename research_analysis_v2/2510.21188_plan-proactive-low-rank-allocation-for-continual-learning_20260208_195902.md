---
ver: rpa2
title: 'PLAN: Proactive Low-Rank Allocation for Continual Learning'
arxiv_id: '2510.21188'
source_url: https://arxiv.org/abs/2510.21188
tags:
- learning
- plan
- basis
- tasks
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PLAN addresses continual learning by proposing a proactive low-rank
  allocation method that extends LoRA for efficient and interference-aware fine-tuning
  of large pre-trained models. Unlike passive methods that merely prevent interference,
  PLAN anticipates future conflicts and strategically assigns task-specific subspaces.
---

# PLAN: Proactive Low-Rank Allocation for Continual Learning

## Quick Facts
- arXiv ID: 2510.21188
- Source URL: https://arxiv.org/abs/2510.21188
- Reference count: 40
- Key outcome: PLAN achieves state-of-the-art continual learning performance on ImageNet-R, CIFAR-100, and DomainNet by proactively allocating low-rank subspaces using a min-max robust optimization approach.

## Executive Summary
PLAN addresses continual learning by proposing a proactive low-rank allocation method that extends LoRA for efficient and interference-aware fine-tuning of large pre-trained models. Unlike passive methods that merely prevent interference, PLAN anticipates future conflicts and strategically assigns task-specific subspaces. It introduces a perturbation-based optimization objective that makes current task parameters robust against future interference, and an orthogonal basis selection mechanism that identifies stable directions in parameter space. The method uses a standard orthogonal basis for strict interference-free subspace allocation and optimizes low-rank adapters through min-max optimization. On standard benchmarks including ImageNet-R, CIFAR-100, and DomainNet, PLAN consistently outperforms existing methods, establishing a new state-of-the-art for continual learning with foundation models while maintaining parameter and storage efficiency.

## Method Summary
PLAN modifies LoRA for continual learning by using a fixed standard orthogonal basis (one-hot vectors) for the adapter matrix A_t, while learning the adapter matrix B_t through a min-max optimization objective. The method proactively reduces interference by optimizing current task parameters to be robust against worst-case perturbations in unallocated subspaces. During training, it tracks perturbation sensitivity across basis vectors and uses a sliding window buffer to select the most stable directions for the next task. This creates strictly orthogonal subspaces between tasks while maintaining parameter and storage efficiency. The approach is validated on CIFAR-100, ImageNet-R, and DomainNet benchmarks using a frozen ViT-B/16 backbone.

## Key Results
- PLAN achieves 81.1% average accuracy on ImageNet-R-20, outperforming Inc-LoRA (79.2%), InfLoRA (79.3%), and other baselines.
- On CIFAR-100, PLAN reaches 71.8% average accuracy, surpassing Inc-LoRA (68.9%), InfLoRA (69.3%), and LoRA-GA (70.6%).
- PLAN demonstrates superior storage efficiency by requiring only basis indices storage (2.5 KB) compared to InfLoRA's gradient storage (1.2 MB).

## Why This Works (Mechanism)

### Mechanism 1: Anticipatory Robustness via Min-Max Perturbation
PLAN optimizes current task parameters against worst-case perturbations in unallocated subspaces, creating inherently robust solutions against future updates. The min-max objective flattens the loss landscape in directions where future tasks will reside, approximating future task updates as bounded perturbations.

### Mechanism 2: Sensitivity-Informed Subspace Selection
During task t training, PLAN tracks perturbation norms across unallocated basis vectors and assigns directions with minimal sensitivity to future tasks. This identifies stable parameter directions that current tasks "don't care about," minimizing destructive interference.

### Mechanism 3: Strict Orthogonality via Standard Basis
Using fixed standard orthogonal basis vectors guarantees mathematical isolation between tasks without learning overhead. This strict orthogonality prevents interference while maintaining computational efficiency through direct row selection from one-hot vectors.

## Foundational Learning

**Concept: Low-Rank Adaptation (LoRA)**
- Why needed: PLAN modifies standard LoRA formulation (ΔW = BA). Understanding the role of A (projection) and B (processing) is critical for seeing how fixing A to standard basis changes subspace dynamics.
- Quick check: If A is fixed to standard basis vectors, what does that imply about the correlation structure of the input features being transformed by B?

**Concept: Min-Max Optimization (Robust Optimization)**
- Why needed: The core training loop is a min-max game against adversarial perturbation, connecting to adversarial training concepts.
- Quick check: In the objective min max L(W + ε), does the maximization step seek to find a realistic data point or a parameter configuration that maximizes loss?

**Concept: Stability-Plasticity Dilemma**
- Why needed: PLAN positions itself as solving this trade-off through proactive interference prevention.
- Quick check: Does enforcing strict orthogonality favor stability or plasticity? How does the perturbation objective attempt to restore the balance?

## Architecture Onboarding

**Component map:**
- ViT-B/16 (Frozen) -> LoRA Adapter (A_t: Standard basis selection, B_t: Learnable) -> Perturbation Engine (ε generation) -> Selection Buffer (Sensitivity tracking)

**Critical path:**
1. Initialize task t: Retrieve A_t based on selection from task t-1
2. Forward Pass: Compute W_t = W_{prev} + B_t A_t + ε_t M_t
3. Backward Pass: Update only B_t using perturbed loss gradients
4. Post-Training: Analyze buffer to select indices for A_{t+1}

**Design tradeoffs:**
- Standard vs. Learned Basis: Standard bases outperform SVD/learned bases by avoiding overfitting to current tasks while maintaining natural alignment with input space.
- Storage Efficiency: PLAN stores only basis indices (negligible) vs. O-LoRA/InfLoRA storing weights or gradients.

**Failure signatures:**
- Capacity Saturation: Basis set becomes empty for large task sequences
- Norm Instability: p≠2 causes divergent training
- Perturbation Magnitude: Incorrect ρ prevents current task learning

**First 3 experiments:**
1. Ablate Proactivity: Compare random vs. sensitivity-based selection
2. Perturbation Sanity Check: ρ=0 vs. ρ=0.01 for robustness gain
3. Long Sequence Stress Test: ImageNet-R (N=20) for capacity limits

## Open Questions the Paper Calls Out

**Open Question 1:** Can strict orthogonality constraints be selectively relaxed to facilitate positive backward transfer without compromising stability?
- The authors note that while strict orthogonality prevents forgetting excellently, it doesn't promote positive backward transfer, suggesting exploring methods to relax this.

**Open Question 2:** Does the proactive low-rank allocation strategy generalize effectively to non-ViT architectures or different data modalities like NLP?
- The paper identifies extending PLAN to ConvNets or different data modalities as a valuable next step, noting experiments were primarily focused on ViT-based models.

**Open Question 3:** Can adaptive basis generation outperform the fixed standard orthogonal basis for task sequences with high heterogeneity?
- The authors list exploring adaptive basis generation for highly heterogeneous task sequences as an interesting direction, given that LoRA-GA initialization failed due to poor plasticity.

**Open Question 4:** Is the min-max optimization robust enough to function without manual tuning of the perturbation magnitude ρ across diverse datasets?
- Section 5.3 and Appendix A.2 highlight sensitivity to ρ choice, suggesting the need for an adaptive scheduling mechanism that consistently matches best fixed-ρ performance.

## Limitations
- Perturbation approximation may break down for heterogeneous task sequences requiring different parameter directions
- Rank allocation strategy per task is unspecified, critical for subspace capacity management
- Standard basis alignment assumption may not hold for all pre-trained models or domains

## Confidence

**High Confidence:** Claims about strict orthogonality through standard basis selection and basic storage efficiency gains are well-supported by mathematical formulation and experimental results.

**Medium Confidence:** Claims about proactive robustness and sensitivity-based selection are supported by ablation studies, but theoretical guarantees remain empirical.

**Low Confidence:** Claims about superior performance across all benchmarks are based on limited comparisons; more comprehensive evaluation against full spectrum of continual learning methods would strengthen these claims.

## Next Checks

1. **Rank Allocation Study:** Systematically evaluate how different rank allocation strategies (fixed vs. task-adaptive) impact performance across heterogeneous task sequences with varying complexity.

2. **Cross-Architecture Generalization:** Test PLAN on architectures beyond ViT (e.g., ResNet, MLP-Mixer) to verify if standard basis alignment assumption holds across different model families and pre-training regimes.

3. **Capacity Saturation Analysis:** Conduct experiments with extended task sequences (N > 20) to identify when and how the method encounters basis vector exhaustion, and evaluate potential mitigation strategies such as basis expansion or adaptive rank allocation.