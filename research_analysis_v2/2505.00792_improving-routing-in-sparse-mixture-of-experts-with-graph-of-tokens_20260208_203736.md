---
ver: rpa2
title: Improving Routing in Sparse Mixture of Experts with Graph of Tokens
arxiv_id: '2505.00792'
source_url: https://arxiv.org/abs/2505.00792
tags:
- smoe
- routing
- expert
- attention-aware
- experts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies routing fluctuations in Sparse Mixture of
  Experts models, where tokens frequently change assigned experts during late-stage
  training, leading to instability and non-robustness. The authors propose using token
  similarity and attention mechanisms to reduce these fluctuations by breaking the
  independence assumption in expert selection.
---

# Improving Routing in Sparse Mixture of Experts with Graph of Tokens

## Quick Facts
- arXiv ID: 2505.00792
- Source URL: https://arxiv.org/abs/2505.00792
- Reference count: 30
- Primary result: Routing fluctuations in Sparse Mixture of Experts reduced from 33% to under 20% using token similarity and attention-guided routing

## Executive Summary
This paper addresses routing fluctuations in Sparse Mixture of Experts (SMoE) models, where tokens frequently change assigned experts during late-stage training, leading to instability and non-robustness. The authors identify that the independence assumption in standard SMoE routing exposes the model to these fluctuations. They propose two solutions: Similarity-Aware SMoE, which routes similar tokens to the same experts using a token similarity graph, and Attention-Aware SMoE, which leverages attention matrices to guide routing decisions. Theoretical analysis shows both methods reduce entropy in expert selection, leading to more stable routing. Empirical results demonstrate significant improvements across language modeling, image classification, and fine-tuning tasks.

## Method Summary
The paper proposes two routing modifications for SMoE: Similarity-Aware routing computes a token similarity matrix S[i,j] = Softmax(u_i^T W_s u_j / τ) and routes tokens based on aggregated expert scores from similar tokens, while Attention-Aware routing uses posterior attention weights from the preceding attention layer to guide expert selection. Both methods replace the standard independent token routing with a dependency-aware approach that reduces routing entropy and fluctuation. The methods are evaluated on WikiText-103, ImageNet-1K, and fine-tuning tasks using SMoE-medium and V-MoE architectures.

## Key Results
- Routing fluctuation rates reduced from 33% (baseline) to under 20% on WikiText-103
- Perplexity improvements of up to 1.64 points on language modeling tasks
- Top-1 accuracy improvements of up to 0.6% on ImageNet classification
- Improved load balancing across experts and enhanced robustness against adversarial attacks

## Why This Works (Mechanism)

### Mechanism 1: Breaking token independence assumption
Standard SMoE routes each token independently based solely on its embedding via softmax gating. The proposed Similarity-Aware SMoE introduces a similarity variable s_i that conditions expert selection on relationships between tokens, computing expert scores as p_i = Σ_j s(i,j) r_j where s(i,j) captures token similarity. This creates inter-dependencies so similar tokens influence each other's routing. The core assumption is that similar tokens should be routed to the same expert; routing fluctuation stems from independent token decisions ignoring contextual similarity.

### Mechanism 2: Attention-guided routing
Attention-Aware SMoE leverages existing attention computation in MoE-Transformers. The attention position selection variable z_i (which token x_i attends to) directly influences expert selection via P(ea_i = e|U,X) = Σ_h Σ_j H_p[i,h] A^p_h[i,j] r_e(u_j). This creates a two-stage hierarchical weighting where routing decisions are adjusted by attention-determined token responsibilities. The core assumption is that the attention mechanism's learned token relationships are semantically meaningful for expert specialization decisions.

### Mechanism 3: Entropy reduction for stability
For "indecisive" tokens (high entropy expert scores), the proposed methods aggregate information from lower-entropy tokens via similarity/attention weights. Proposition 1 proves H(p_i) ≤ Σ_j s(i,j)H(r_j) + H(s_i), and as temperature τ→0, H(p_i) ≤ H(r_i). Lower entropy means more confident, stable expert assignments. The core assumption is that high entropy in expert scores indicates uncertainty that leads to routing instability under small perturbations.

## Foundational Learning

- **Probabilistic Graphical Models (PGM)**: The paper frames SMoE as a generative process with conditional dependencies. Understanding directed graphical models, conditional independence (⊥⊥), and how adding edges breaks independence is essential to grasp why the proposed modifications work. *Quick check*: Given the graph G1 in Figure 1, can you explain why e_i ⊥⊥ e_j when tokens are i.i.d. sampled?

- **Categorical Distribution and Entropy**: Expert selection is modeled as sampling from Cat(r(u_i)). The entropy H(r_i) measures decision uncertainty. The paper's theoretical contribution relies on understanding how mixture distributions affect entropy. *Quick check*: If r_i = [0.5, 0.5, 0, 0] and r_j = [0.9, 0.1, 0, 0], which token has higher routing uncertainty, and how would aggregating them via p = 0.5·r_i + 0.5·r_j affect the resulting entropy?

- **Multi-Head Attention Mechanics**: Attention-Aware SMoE builds on the attention matrix A_h ∈ R^{N×N} and its relationship to token dependencies. Understanding queries, keys, values, and how attention scores represent token relationships is prerequisite. *Quick check*: In the attention posterior A^p_h[i,j], what does a high value indicate about the relationship between tokens x_i and x_j, and how should this influence their expert routing similarity?

## Architecture Onboarding

- **Component map**: Input sequence U → Router (produces expert scores r(u_i) via softmax(Wu_i + b)) → TopK selection → Expert networks g_e. NEW: Similarity computation S = Softmax(UW_sU^T/τ) weights token-to-token influence. NEW: Attention-Aware uses existing A_h matrices from preceding attention layer. Aggregated scores p_i = Σ_j s(i,j)r_j → TopK → Expert combination.

- **Critical path**: Token embeddings U must be available before routing. Similarity matrix S requires O(N²D) computation (N tokens, D dimensions). For Attention-Aware: Attention matrices A_h must be cached from the preceding MHA layer. Head selection h* via entropy minimization (Eq. 14) before computing A^p_{h*}. Aggregated expert scores computed, then TopK applied.

- **Design tradeoffs**: Similarity-Aware vs Attention-Aware: Similarity-Aware requires explicit similarity computation (extra cost) but works for any SMoE. Attention-Aware reuses existing computations but requires an attention layer immediately before the SMoE layer. Temperature τ/σ: Lower values sharpen distributions (lower entropy, more stable) but reduce diversity. Paper uses τ=1, σ=1 as defaults (Table 9). Head selection approximation: Using single head h* (Eq. 14) vs full summation trades accuracy for efficiency.

- **Failure signatures**: Routing collapse: If all tokens route to same expert, check if similarity/attention weights are too uniform (τ too large). No improvement over baseline: Check if temperature τ→0 is accidentally set, making S≈I (identity matrix). Load imbalance worsening: Paper shows improved balance (Figure 4), but if experts receive highly skewed distributions, similarity signal may be reinforcing existing biases. Attention-Aware returns NaN: Posterior computation involves likelihood L_h[i,j] = N(u_i|W_h x_j, σ²I); ensure σ>0 and vectors aren't degenerate.

- **First 3 experiments**: 1) Baseline fluctuation measurement: Train standard SMoE on WikiText-103 subset for 60 epochs. Measure routing fluctuation rate between epochs 59-60. Verify ~33% baseline fluctuation rate reported in Figure 3. 2) Similarity-Aware A/B test: Same setup with Similarity-Aware SMoE (τ=1, W_s=I). Compare fluctuation rate, perplexity, and expert load distribution. Expect fluctuation <20% and perplexity reduction of 1-2 points. 3) Entropy-fluctuation correlation: For both baseline and proposed methods, compute per-layer average entropy H(r_i) at epoch 59 and correlation with fluctuation rates. Validate the theoretical claim that lower entropy predicts lower fluctuation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the probabilistic graphical model (PGM) framework be extended to explicitly capture the autoregressive token generation process within Transformer-MoE architectures?
- Basis in paper: [explicit] The conclusion states, "A limitation of our paper is that we have not considered a generative model that capture the token generation process in our PGM... We leave it for future work."
- Why unresolved: The current PGM formulation (MAM and A2MM) assumes a fixed input sequence $X$ to derive routing dependencies but does not model the sequential generation of tokens $X$ itself, which is central to autoregressive language modeling.
- What evidence would resolve it: A derivation of a joint PGM that includes the likelihood of the next token conditioned on previous tokens and expert states, followed by experiments showing improved perplexity or calibration on generative tasks.

### Open Question 2
- Question: Does utilizing a weighted combination of attention heads (rather than selecting a single head with the lowest entropy) yield better routing performance for Attention-Aware SMoE?
- Basis in paper: [inferred] Section 3.2, Equation 14 introduces a "hard" approximation for head selection ($h^*$) to reduce computational costs, explicitly discarding the contribution of other heads.
- Why unresolved: While the approximation reduces overhead, the paper does not analyze if the information lost by ignoring other heads limits the theoretical upper bound of the model's performance.
- What evidence would resolve it: An ablation study comparing the proposed single-head selection against a "soft" weighted aggregation of all heads (approximating the full posterior), measuring the trade-off between computational load and validation accuracy.

### Open Question 3
- Question: What are the performance trade-offs when learning the similarity projection matrix $W_s$ compared to using the fixed identity matrix?
- Basis in paper: [inferred] Remark 3 notes, "In practice, to be computationally efficient, we set $W_s = I$," despite Definition 1 defining $W_s$ as a learnable parameter matrix.
- Why unresolved: The authors chose the identity matrix for efficiency, but it remains untested whether a learned projection could map tokens to a semantic space better suited for expert clustering, justifying the extra parameters.
- What evidence would resolve it: Comparing the convergence rate and final perplexity of models trained with learned $W_s$ versus the identity matrix baseline on a complex dataset like Wikitext-103.

## Limitations

- The core assumption that token similarity/attention dependencies should directly inform expert routing is theoretically sound but lacks comprehensive validation across different model architectures and tasks.
- The computational overhead of O(N²) similarity matrix computation could become prohibitive for very long sequences, though the paper doesn't analyze this scaling limitation.
- The routing fluctuation metric (expert changes between epochs) captures instability but may not fully represent practical model robustness or generalization.

## Confidence

- **High confidence**: The empirical improvements in perplexity (1.64 points reduction), accuracy (0.6% improvement), and routing fluctuation reduction (33% to <20%) are well-supported by the experimental results presented.
- **Medium confidence**: The theoretical claims about entropy reduction leading to routing stability are mathematically proven, but the practical significance and generalizability of this relationship needs further validation.
- **Low confidence**: The assertion that the proposed methods "improve model robustness against adversarial attacks" is mentioned but the evidence is limited to TextAttack word swaps and standard adversarial datasets without deeper analysis.

## Next Checks

1. **Cross-dataset generalization test**: Validate routing stability improvements on additional language modeling datasets (e.g., BookCorpus, C4) and tasks (summarization, translation) to confirm the entropy-fluctuation relationship holds beyond WikiText-103 and GLAM.

2. **Attention-Aware sensitivity analysis**: Systematically vary the temperature σ and head selection method (full summation vs single head h*) to quantify the tradeoff between routing stability and model capacity, and determine optimal hyperparameters across different sequence lengths.

3. **Computational overhead measurement**: Profile the O(N²) similarity computation cost on sequences of varying lengths (512, 2048, 4096 tokens) and compare wall-clock training time with baseline SMoE to quantify the practical scalability limits of Similarity-Aware routing.