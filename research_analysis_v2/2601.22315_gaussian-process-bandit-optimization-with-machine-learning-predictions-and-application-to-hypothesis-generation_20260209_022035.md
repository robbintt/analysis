---
ver: rpa2
title: Gaussian Process Bandit Optimization with Machine Learning Predictions and
  Application to Hypothesis Generation
arxiv_id: '2601.22315'
source_url: https://arxiv.org/abs/2601.22315
tags:
- prediction
- 'true'
- pa-gp-ucb
- offline
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses Bayesian optimization when both an expensive
  high-fidelity oracle and a cheap low-fidelity predictor are available, along with
  potentially abundant offline data. The proposed Prediction-Augmented Gaussian Process
  Upper Confidence Bound (PA-GP-UCB) algorithm models the true and predicted rewards
  as correlated outputs of a multi-task GP and uses a control-variates estimator to
  correct prediction bias while reducing posterior uncertainty.
---

# Gaussian Process Bandit Optimization with Machine Learning Predictions and Application to Hypothesis Generation

## Quick Facts
- arXiv ID: 2601.22315
- Source URL: https://arxiv.org/abs/2601.22315
- Reference count: 40
- Key outcome: PA-GP-UCB achieves cumulative regret bounds matching GP-UCB rates with strictly smaller constants, controlled by prediction correlation and offline data coverage.

## Executive Summary
This paper addresses Bayesian optimization with both an expensive high-fidelity oracle and a cheap low-fidelity predictor, plus abundant offline data. The proposed PA-GP-UCB algorithm models true and predicted rewards as correlated outputs of a multi-task GP and uses a control-variates estimator to correct prediction bias while reducing posterior uncertainty. The method achieves faster convergence than vanilla GP-UCB and naÃ¯ve baselines on synthetic benchmarks and a real-world hypothesis generation task using LLM predictions grounded in human behavioral data.

## Method Summary
The method employs a multi-task Gaussian process prior with kernel K⊗B where B = [[1,ρ],[ρ,1]] to model the true reward and ML prediction as correlated tasks. In an offline stage, predictions are queried on an ε-net with N repetitions per center to build GP_all. Online, both oracles are queried at selected points, and a control-variates estimator μPA_t(x) = μtrue_t(x) - ρ_t(x)·(σtrue_t(x)/σML_t(x))·(μML_t(x) - μML,all_t(x)) corrects bias while reducing variance. The algorithm selects points via φ_t(x) = μPA_t(x) + √(β_t)·σPA_t(x) and updates both GP posteriors.

## Key Results
- Achieves cumulative regret bounds matching GP-UCB rates with strictly smaller constants controlled by correlation ρ and offline coverage ratio R
- Empirically converges faster than vanilla GP-UCB and baselines on synthetic benchmarks
- Demonstrates effectiveness on real-world hypothesis generation where predictions come from LLMs and feedback from human behavioral data

## Why This Works (Mechanism)

### Mechanism 1
The control-variates estimator reduces posterior variance while correcting prediction bias. The estimator μPA_t(x) = μtrue_t(x) - ρ_t(x)·(σtrue_t(x)/σML_t(x))·(μML_t(x) - μML,all_t(x)) subtracts a scaled residual with mean zero conditional on online data. This yields (σPA_t(x))² = (σtrue_t(x))²·[(ρ_t(x)·σML,all_t(x)/σML_t(x))² + 1 - ρ_t(x)²], weakly smaller than vanilla posterior variance.

### Mechanism 2
Multi-task GP correlation transfers information from cheap predictions to expensive ground-truth task. The joint GP prior [f, f_ML]ᵀ ~ GP([0,0]ᵀ, K⊗B) with B = [[1,ρ],[ρ,1]] encodes task correlation. Posterior updates on f_ML induce correlated updates on f through off-diagonal covariance ρ·K(x,x'), enabling uncertainty reduction in f without ground-truth queries at those points.

### Mechanism 3
Offline ε-net coverage reduces the regret constant through uniform variance ratio bound R. Querying predictions on an ε-net with N repetitions reduces prediction noise from η²_ML to η²_ML/N at grid centers. GP interpolation extends this reduction globally. The ratio R = (σML,all_t(x)/σML_t(x))² ≤ R controls the regret improvement factor √(1 - (1-R)ρ²).

## Foundational Learning

- **Gaussian Process Posterior Updating**
  - Why needed here: The entire algorithm relies on maintaining and updating GP posteriors for both tasks
  - Quick check question: Given GP prior with kernel K and observations y = f(X) + ε, write the posterior mean and variance at a test point x*

- **Upper Confidence Bound Bandit Algorithms**
  - Why needed here: PA-GP-UCB inherits the UCB exploration-exploitation structure
  - Quick check question: Explain why selecting x_t = argmax φ_t(x) guarantees sublinear regret under the GP-UCB analysis framework

- **Control Variates in Monte Carlo Estimation**
  - Why needed here: The bias correction term is a control variate with mean zero and optimal coefficient
  - Quick check question: If you have an estimator θ̂ and a control variate C with E[C]=0 and Cov(θ̂,C)≠0, what is the minimum-variance linear combination θ̃ = θ̂ - αC?

## Architecture Onboarding

- **Component map:** Offline Stage: ε-net constructor → Prediction oracle queries (N repeats per center) → GP_all initialization; Online Stage per round t: Query both oracles at x_t → Update GP_all and GP_online → Compute μPA_t(x), σPA_t(x) via control-variates formula → Select x_{t+1} = argmax φ_t(x) via numerical optimization

- **Critical path:** 1) Offline coverage quality (ε, N) determines R; 2) Correlation ρ between f and f_ML (data-dependent) determines variance reduction; 3) β_t scaling (from concentration bounds) controls exploration width; 4) Correctness of joint GP hyperparameters (kernel, noise variances, ρ) affects all downstream estimates

- **Design tradeoffs:** ε-net granularity vs. offline budget (smaller ε → tighter R but more prediction queries); Replications N vs. prediction noise (more N → better noise reduction but diminishing returns); Kernel choice (RBF assumes smoothness; misspecification hurts vanilla GP-UCB more); Correlation estimation (empirical ρ̂; robust to moderate error but degrades if systematically wrong)

- **Failure signatures:** Linear or super-linear regret (check near-zero correlation with ground truth); Convergence to wrong optimum (control-variates bias correction failing); Excessive exploration (β_t too large or σPA_t(x) not shrinking); Numerical instability (GP covariance matrices near-singular)

- **First 3 experiments:** 1) Synthetic 1D GP with controlled ρ: Generate f ~ GP(0, K), construct f_ML = ρ·f + √(1-ρ²)·g for independent g ~ GP(0,K). Sweep ρ ∈ {0.3, 0.5, 0.7, 0.9} and plot cumulative regret vs. T. 2) Ablation on offline budget: Fix ρ=0.8, vary M (ε-net size) and N (replications) over {1, 10, 100, 1000}. Measure empirical R via held-out variance ratio and correlate with regret improvement. 3) Robustness to local anti-correlation: Create f_ML that flips sign in a sub-interval. Verify PA-GP-UCB recovers the true optimum while naïve GP-UCB with predictions converges to prediction-preferred region.

## Open Questions the Paper Calls Out

- Can the sufficient conditions on the offline grid size and replication count (ε, N) be substantially weakened to move beyond worst-case analysis? The authors state the conditions are conservative and likely not sample-optimal.

- Can offline data efficiency be improved by replacing the uniform ε-net design with adaptive or non-uniform sampling strategies? The current algorithm relies on uniform ratio bound R requiring dense, uniform sampling.

- What theoretical guarantees exist for PA-GP-UCB regarding robustness to kernel and prediction misspecification? While empirical results suggest robustness, this lacks formal theoretical support.

## Limitations

- The regret bound improvement depends critically on correlation ρ being bounded away from zero, with no quantified threshold for when gains become negligible.
- The ε-net construction becomes intractable in high dimensions (d > 5) due to exponential scaling with dimension.
- While robustness to kernel misspecification is claimed empirically, the evidence is limited to one synthetic case without characterizing the mechanism.
- The multi-task GP assumes constant correlation ρ across the domain, requiring online estimation for local variations without characterizing estimation error's impact.

## Confidence

- **High Confidence:** The core mechanism of control-variates variance reduction and multi-task GP modeling framework are mathematically sound and well-established.
- **Medium Confidence:** Empirical demonstrations convincingly show performance gains in controlled settings where the method is expected to succeed.
- **Medium Confidence:** Theoretical regret bound derivation follows standard GP-UCB analysis with additional control-variates component, but conditions for claimed improvement are conservative.

## Next Checks

1. **Correlation Threshold Analysis:** Systematically sweep ρ ∈ [0,1] in the synthetic 1D experiment to identify the minimum correlation required for PA-GP-UCB to outperform vanilla GP-UCB with the same total oracle queries.

2. **High-Dimensional Scaling Study:** Extend the synthetic experiment to d=5,10 dimensions and measure how the offline ε-net size scales with dimension. Compare practical offline budget against theoretical requirements.

3. **Local Correlation Robustness:** Design an experiment with spatially varying correlation ρ(x) transitioning from highly correlated to anti-correlated regions. Measure how quickly PA-GP-UCB recovers from anti-correlated regions and whether online correlation estimation prevents convergence to wrong optima.