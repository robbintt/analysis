---
ver: rpa2
title: Robustness of Misinformation Classification Systems to Adversarial Examples
  Through BeamAttack
arxiv_id: '2506.23661'
source_url: https://arxiv.org/abs/2506.23661
tags:
- adversarial
- beamattack
- word
- beam
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends BeamAttack, an adversarial attack method for
  text classification, by adding word deletion and skip-substitution options and integrating
  LIME for improved word importance ranking. Evaluated on multiple datasets and victim
  models (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA framework,
  the approach achieves over 99% attack success rate while maintaining semantic similarity.
---

# Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack

## Quick Facts
- arXiv ID: 2506.23661
- Source URL: https://arxiv.org/abs/2506.23661
- Reference count: 40
- Primary result: Extended BeamAttack achieves >99% success rate on misinformation classifiers but produces semantically degraded outputs in 93% of cases

## Executive Summary
This paper extends BeamAttack with word deletion and skip-substitution options and integrates LIME for improved word importance ranking. Evaluated on multiple datasets and victim models (BiLSTM, BERT, and adversarially trained RoBERTa), the approach achieves over 99% attack success rate while maintaining semantic similarity according to automated metrics. However, manual evaluation revealed that while the attack is highly effective, it often produces adversarial samples that alter semantic meaning, with many labeled as "changing the original meaning" or "nonsensical" by human evaluators. The method shows task and model-specific variations in effectiveness, with LIME-based ranking outperforming logit-based methods for certain datasets.

## Method Summary
The method extends BeamAttack by integrating LIME-based word importance ranking, adding word deletion and skip-substitution options, and using RoBERTa-large as a Masked Language Model for candidate generation. The algorithm maintains k parallel search paths (beam width), expanding each with b replacement candidates at every depth. Nodes are scored by how effectively they reduce the original class probability while increasing target class probability. The beam retains only top-k candidates per iteration until h successful adversarial samples are found, then selects the highest BLEURT-similarity result. The attack was evaluated using the BODEGA framework across five binary classification datasets (HN, PR2, FC, RD, C19) and three victim models (BiLSTM, BERT, adversarially trained RoBERTa).

## Key Results
- Attack success rate: >99% across all datasets and models
- Semantic degradation: 63% of samples "changed meaning," 30% "nonsensical" in manual evaluation
- LIME advantage: LIME-based importance ranking outperformed logit-based methods on BERT for fact-checking tasks (BODEGA 0.8044 vs 0.7787)
- Query efficiency: LIME required 5520 queries vs 732 for logit-based on FC/BERT task

## Why This Works (Mechanism)

### Mechanism 1
- Beam search with importance-guided word ranking finds adversarial examples with fewer modifications than greedy approaches
- The algorithm maintains k parallel search paths, expanding each with b replacement candidates at every depth, scoring by prediction change
- Core assumption: Adversarial vulnerabilities are localized to specific high-importance words, and exploring multiple paths in parallel discovers more optimal solutions
- Evidence: Beam search "maintains k most promising partial solutions at each step, balancing exploration with computational efficiency"
- Break condition: When beam size k is too small (<10) or branching factor b insufficient for model complexity, success rates drop

### Mechanism 2
- LIME-based word importance ranking outperforms logit-based methods for transformer models on fact-classification tasks
- LIME trains local linear models around individual predictions by perturbing inputs, estimating per-token influence
- Core assumption: Words with higher explanation scores are more "vulnerable" and replacing them will more efficiently flip predictions
- Evidence: For FC/BERT: LIME achieves BODEGA=0.8044 vs logit-based=0.7787
- Break condition: LIME requires 7-8x more queries than logit-based with inconsistent quality gains across architectures

### Mechanism 3
- Masked Language Model substitutions achieve high attack success but frequently produce semantically incoherent outputs
- RoBERTa-large generates contextually plausible replacement candidates, beam search selects replacements that maximize prediction change
- Core assumption: Contextually plausible replacements will maintain semantic similarity while disrupting model predictions
- Evidence: Manual evaluation: 63% labeled "changing original meaning," 30% "nonsensical"
- Break condition: When beam width is large (k>60), overgeneration increases incoherent substitutions

## Foundational Learning

- **Beam search for adversarial exploration**
  - Why needed: Understanding how parallel path exploration differs from greedy sequential attacks
  - Quick check: Given beam size k=20 and branching factor b=30, how many node evaluations occur at depth 2 before pruning?

- **Local vs. global feature importance**
  - Why needed: The paper contrasts LIME (local, per-sample explanations) with logit-based masking (global proxy)
  - Quick check: Why might LIME outperform logit-based importance on transformer models but fail on BiLSTM for the same task?

- **Grey-box attack taxonomy**
  - Why needed: The method assumes access to probability distributions and uses MLM without gradient access
  - Quick check: What information does BeamAttack require from the victim model, and how does this differ from white-box attacks like HotFlip?

## Architecture Onboarding

- **Component map:** Word Importance Module -> Candidate Generator -> Beam Search Controller -> Semantic Selector -> Extension Layer
- **Critical path:** Input sentence → compute word importance scores (LIME/logit) → sort words by descending importance → expand beam nodes with top-b replacements → score candidates by prediction change → prune to top-k → repeat until h successes → rank by BLEURT, return best
- **Design tradeoffs:** Success rate vs. semantic quality (larger k=100 achieves higher success but more incoherent outputs), query budget vs. importance accuracy (LIME requires ~7-8x more queries), syntactic preservation vs. attack flexibility (deletion enables harder attacks but causes 30% nonsensical outputs)
- **Failure signatures:** High nonsensical rate (30%) from word deletion breaking syntactic structure, semantic drift without classification change from over-reliance on MLM suggestions, query exhaustion before success when beam width insufficient for robust models
- **First 3 experiments:**
  1. Baseline importance comparison: Run BeamAttack with logit-based vs. LIME importance on FC/BERT with fixed k=10, b=30, h=10. Measure BODEGA score, query count, and semantic score.
  2. Deletion ablation: Enable/disable word deletion on RD/RoBERTa. Count grammatical errors via POS transition analysis.
  3. Beam size scaling: Test k∈{10,20,40,60,80} on PR2/RoBERTa with fixed b=30, h=10. Plot BODEGA and semantic scores.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the integration of Large Language Models (LLMs) for substitution or similarity-based filtering effectively mitigate the semantic drift and syntactic errors observed in the current BeamAttack outputs?
- Basis: Section 7 states that "RoBERTa's context-based alternatives may produce semantically opposite replacements" and suggests future work could address this "by using large language models (LLMs) for substitution, or applying similarity-based filtering"
- Why unresolved: The current method relies on RoBERTa as a Masked Language Model, which prioritizes contextual fit over semantic equivalence
- Evidence needed: A comparative experiment showing that an LLM-based substitution strategy results in significantly higher human ratings for semantic preservation while maintaining comparable attack success rates

### Open Question 2
- Question: Does implementing semantic scoring at intermediate steps of the beam search improve the coherence of adversarial samples compared to scoring only the final hypotheses?
- Basis: Section 7 proposes that "scoring beams at each search step—rather than only at the final hypothesis—could improve semantic coherence"
- Why unresolved: The current implementation optimizes only for attack success, allowing "incoherent substitutions" to propagate through the search tree
- Evidence needed: An ablation study measuring the BLEURT scores and human evaluation ratings of adversarial samples generated using step-wise semantic pruning versus the current method

### Open Question 3
- Question: To what extent does constraining word substitutions based on Part-of-Speech (POS) tag preservation improve the grammaticality of adversarial examples without compromising attack success rates?
- Basis: Section 6 suggests that "constraining substitutions—e.g., by limiting POS tag group changes—could improve fluency, though at a potential cost to success rate"
- Why unresolved: The analysis reveals that while many lexical replacements preserve syntactic structure, specific transitions are frequent
- Evidence needed: Empirical results from a modified BeamAttack run where candidate substitutions are filtered by POS tag compatibility, reporting the trade-off between BODEGA score and linguistic acceptability

## Limitations

- High semantic degradation: 93% of generated samples were labeled as either "changed meaning" or "nonsensical" in manual evaluation
- Inconsistent LIME performance: LIME-based importance ranking shows no improvement on BiLSTM or certain RoBERTa tasks despite requiring 7-8x more queries
- Single defense validation: The adversarially trained RoBERTa represents only one defense mechanism; robustness against other defenses remains untested

## Confidence

**High confidence:** Beam search exploration advantage over greedy approaches is well-demonstrated through success rate improvements and quantitative metrics; MLM-based substitution effectively identifies vulnerable words; BODEGA framework provides standardized evaluation

**Medium confidence:** LIME vs. logit-based importance ranking benefits are task-dependent and not universally superior; semantic similarity metrics (BLEURT) may not fully capture meaning preservation given high nonsensical outputs; adversarially trained RoBERTa effectiveness needs broader validation

**Low confidence:** Practical applicability claims given high semantic degradation rates; generalization to non-binary classification tasks; scalability to longer documents or different domain texts

## Next Checks

1. **Semantic quality ablation:** Run the attack with beam width k ∈ {10, 30, 60} on FC/BERT while measuring not just BLEURT but also human-rated semantic preservation rates. Verify whether the ~93% semantic degradation rate persists across different beam sizes.

2. **Defense robustness testing:** Apply the attack to alternative defense mechanisms beyond adversarially trained RoBERTa, including ensemble methods, certified defenses, and input preprocessing defenses. Measure whether the 99% success rate is consistent across different defense types.

3. **Importance method comparison under query constraints:** Run the attack with both LIME and logit-based importance on HN/BERT with query budgets of 1000, 2000, and 5000 tokens. Measure success rate, semantic quality, and BODEGA score at each budget level to determine if LIME's higher query cost is justified under realistic computational constraints.