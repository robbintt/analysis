---
ver: rpa2
title: Composite Gaussian Processes Flows for Learning Discontinuous Multimodal Policies
arxiv_id: '2502.01913'
source_url: https://arxiv.org/abs/2502.01913
tags:
- policy
- learning
- data
- cgp-flows
- nggp
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Composite Gaussian Processes Flows (CGP-Flows),
  a novel semi-parametric model for robotic policy learning that addresses challenges
  of multimodality, local discontinuities, and computational efficiency. The method
  integrates Overlapping Mixtures of Gaussian Processes (OMGPs) with Continuous Normalizing
  Flows (CNFs) to model complex control policies while maintaining computational efficiency.
---

# Composite Gaussian Processes Flows for Learning Discontinuous Multimodal Policies

## Quick Facts
- **arXiv ID:** 2502.01913
- **Source URL:** https://arxiv.org/abs/2502.01913
- **Authors:** Shu-yuan Wang; Hikaru Sasaki; Takamitsu Matsubara
- **Reference count:** 39
- **One-line result:** CGP-Flows achieves 81% success rate on ball-shooting task, outperforming NGGP (56.3%) and OMGP (38.2%) baselines

## Executive Summary
This paper introduces Composite Gaussian Processes Flows (CGP-Flows), a semi-parametric model for robotic policy learning that addresses the challenges of multimodality, local discontinuities, and computational efficiency. The method combines Overlapping Mixtures of Gaussian Processes (OMGPs) with Continuous Normalizing Flows (CNFs) to create a hybrid model that uses multimodal GP mixtures as base distributions, reducing the complexity of subsequent Neural-ODE transformations. Experimental results across simulation and real-world tasks demonstrate superior performance compared to existing methods, with CGP-Flows achieving 81% success on ball-shooting and 85-90% on grasping tasks.

## Method Summary
CGP-Flows integrates sparse Overlapping Mixtures of Gaussian Processes (OMGPs) with Continuous Normalizing Flows (CNFs) to learn complex robotic policies. The OMGP provides a multimodal base distribution that captures coarse-grained structure, while the Neural-ODE component transforms this base into a fine-grained policy distribution that can handle local discontinuities. Training uses an EM-like algorithm with variational inference: the E-step updates variational distributions for latent function values and assignment indicators, while the M-step optimizes OMGP hyperparameters and Neural-ODE weights via gradient descent. The model is trained to maximize the likelihood of expert demonstrations through a variational lower bound.

## Key Results
- Ball-shooting simulation: CGP-Flows achieved 81.0% success rate vs NGGP (56.3%) and OMGP (38.2%)
- Real-world object-grasping: CGP-Flows achieved 85-90% success vs NGGP (50%) and OMGP (55-67.5%)
- CGP-Flows showed reduced computational complexity through fewer Neural-ODE function evaluations
- Sparse OMGP with M=2 components provided optimal balance of accuracy and efficiency

## Why This Works (Mechanism)

### Mechanism 1: Multimodal Base Distributions Reduce Neural-ODE Transformation Complexity
- **Claim:** Using multimodal Gaussian Process mixture models (OMGPs) as base distributions reduces the computational burden and increases the accuracy of subsequent Continuous Normalizing Flow (Neural-ODE) transformations compared to unimodal GP base distributions.
- **Mechanism:** The CNF must learn a transformation path from the base distribution to the target distribution. If the base distribution is already structurally similar (e.g., multimodal) to the target, the Neural-ODE solver requires fewer function evaluations (NFEs) to find a valid path, as the distribution disparity is smaller. This leads to simpler learned ODEs and more precise final distributions.
- **Core assumption:** The complexity and accuracy of a CNF transformation are inversely proportional to the similarity between the base and target distributions.
- **Evidence anchors:** [abstract] "The CGP-Flows approach uses OMGPs as multimodal base distributions, which reduces the complexity of the Neural-ODE transformation compared to using unimodal base distributions." [paper section 1] "Previous research argues that smaller disparities between the base and target distributions can reduce computation time and improve the accuracy of the Neural-ODE transformations [11]."
- **Break condition:** If the true number of modalities vastly exceeds the mixture components (M) in the OMGP, the base approximation will be poor, potentially negating efficiency gains.

### Mechanism 2: Hybrid Semi-Parametric Model Captures Discontinuous Multimodal Policies
- **Claim:** A hybrid model combining sparse Gaussian Processes (OMGP) with neural networks (Neural-ODE) can effectively model complex robotic control policies that are both multimodal and locally discontinuous.
- **Mechanism:** The OMGP component provides a probabilistic prior that captures multimodal structure and some discontinuous nature (via assignment to different GP components) in a data-efficient manner. The Neural-ODE then provides a flexible, invertible transformation that warps these base distributions to match fine-grained local discontinuities, overcoming OMGPs' limitation of fixed multimodality.
- **Core assumption:** Real-world robotic policies can be decomposed into a component well-modeled by a mixture of smooth functions (OMGP) and a residual component requiring a powerful function approximator (Neural-ODE).
- **Evidence anchors:** [abstract] "The method integrates Overlapping Mixtures of Gaussian Processes (OMGPs) with Continuous Normalizing Flows (CNFs) to model complex control policies..." [paper section 3.3] "This idea of using GPs for cCNFs allows NGGPs to capture modalities and local discontinuity in policies."
- **Break condition:** If the expert policy lacks smoothness/structure (making the GP prior inappropriate), or if discontinuities are so severe that the Neural-ODE transformation becomes numerically unstable.

### Mechanism 3: Behavior Cloning Optimization via Variational Inference
- **Claim:** The parameters of the composite model (OMGP hyperparameters and Neural-ODE weights) can be jointly optimized to maximize the likelihood of expert demonstrations within a behavior cloning framework.
- **Mechanism:** Policy learning is framed as supervised density estimation. A variational lower bound (ELBO) on the log-likelihood incorporates probability from the OMGP base distribution and the change in log-probability due to the Neural-ODE transformation. An EM-like algorithm is used: the E-step updates variational distributions for latent function values and assignment indicators; the M-step optimizes model parameters via gradient descent.
- **Core assumption:** Expert demonstrations are sampled from a fixed (though complex) policy that the model can approximate. The variational approximation is sufficiently accurate for practical optimization.
- **Evidence anchors:** [paper section 4.2] "Thus, we infer approximate posterior distribution and optimize the model parameters by variational inference. In variational inference, we derive lower bound JL for marginal likelihood..." [paper section 5.1.3] "We trained the OMGP with M = 3 and the CGP-Flow with M = 2 models with an EM-like algorithm consisting of 10 E-steps and 10 M-steps."
- **Break condition:** If the optimization landscape is too complex, leading to poor local minima where the model fails to capture correct modes. The paper notes that sparse OMGP parameters are more sensitive, requiring careful learning rate tuning.

## Foundational Learning

- **Concept: Continuous Normalizing Flows (CNFs) and Neural-ODEs**
  - **Why needed here:** This is the core of the "Flow" part of CGP-Flows. A CNF uses a neural network to define the derivative of a transformation, which is integrated using an ODE solver to transform a simple base distribution into a complex target distribution.
  - **Quick check question:** Can you explain how a CNF uses an ODE solver to transform a probability distribution and how the change in log-probability is computed?

- **Concept: Gaussian Processes (GPs) and Overlapping Mixtures of GPs (OMGPs)**
  - **Why needed here:** This is the core of the "GP" part. A GP provides a probabilistic distribution over functions suitable for regression. An OMGP extends this to handle data generated from multiple overlapping functions, crucial for multimodal policies.
  - **Quick check question:** How does a standard GP model uncertainty, and how does an OMGP extend this to handle data that could belong to one of several possible functions?

- **Concept: Variational Inference and the Evidence Lower Bound (ELBO)**
  - **Why needed here:** This is the training mechanism. The model has intractable posterior distributions (due to mixture assignments). Variational inference provides a framework to approximate these posteriors and derive a tractable objective function (ELBO) for optimization.
  - **Quick check question:** Why is direct computation of the posterior often intractable in complex probabilistic models, and what role does the ELBO play in learning model parameters?

## Architecture Onboarding

- **Component map:**
  State Input `s` -> Feature Extractor `h(·)` -> Sparse OMGP (Base Distribution) -> Neural-ODE `fβ(·)` -> Action Output `a`

- **Critical path:**
  **Training:** Expert state-action pairs feed the model. Action transforms backwards through Neural-ODE to latent `l`. Variational inference (E-step) runs over OMGP latent variables given `l`. Parameters update (M-step: OMGP kernel params and Neural-ODE weights) to maximize likelihood lower bound.
  **Inference:** New state `s*` passes through feature extractor. OMGP predicts base distribution over `l*`. Samples transform forwards through trained Neural-ODE to produce action policy samples `p(a*|s*)`.

- **Design tradeoffs:**
  1. **Number of GP Mixture Components (M):** Higher `M` captures more modes, reducing Neural-ODE complexity (fewer NFEs), but increases OMGP computational cost and risks overfitting. Paper suggests `M` need not be exact.
  2. **Neural-ODE Tolerance (atol/rtol):** Lower tolerance yields more accurate ODE solutions but increases computation (more NFEs). Paper demonstrates tradeoff between accuracy and speed.
  3. **Neural-ODE Network Size:** Larger networks learn more complex transformations but increase capacity and training time.

- **Failure signatures:**
  1. **Mode Collapse:** Model fails to capture all expert policy modes, converging to dominant modes only. Occurs if `M` is too small or training gets stuck in poor local minimum.
  2. **Poor Fit to Discontinuities:** Learned policy smooths over discontinuities where it should jump. Indicates insufficient Neural-ODE power or ineffective training.
  3. **Slow/Unstable Training:** EM procedure fails to converge or loss oscillates. Paper notes this arises from differing sensitivities of OMGP and Neural-ODE parameters.
  4. **High Variance Predictions:** Predicted action distribution too wide, causing low success rates. Paper shows NGGP can suffer from this compared to CGP-Flow.

- **First 3 experiments:**
  1. **Reproduce Ball-Shooting Result:** Implement CGP-Flow model; train on simple simulated multimodal task (like ball-shooting). Compare success rates against NGGP and standard OMGP baselines to verify core performance claim.
  2. **Ablate Base Distribution Modality:** Train CGP-Flow models with varying mixture components (M) on task with known mode count. Plot Neural-ODE NFEs and task success rate as function of `M` to validate hypothesis that better-matched base distribution improves efficiency and accuracy.
  3. **Vary ODE Solver Tolerance:** Train single CGP-Flow model using different ODE solver tolerances. Measure tradeoff between total training time, prediction time, and final policy performance to understand sensitivity to numerical precision.

## Open Questions the Paper Calls Out

### Open Question 1: Adaptive Modality Selection via Dirichlet Process
- Question: Can Dirichlet Process integration into OMGP automatically select the optimal modality count, improving efficiency when base distribution modalities exceed data modalities?
- Basis in paper: [explicit] "We consider integrating a Dirichlet Process into the OMGP to mitigate this issue... This approach is expected to adaptively determine the appropriate number of modalities, thereby enhancing computational efficiency."
- Why unresolved: Paper only tests fixed M values (2-5). When M exceeds true modality, Neural-ODE computation increases; no adaptive method was implemented or evaluated.
- What evidence would resolve it: Comparative experiments showing automatic M selection accuracy, computational efficiency gains, and task success rates versus fixed-M baselines.

### Open Question 2: Neural Feature Extraction for Complex Visual States
- Question: How do CNN-based or discriminative condition extractors compare to pre-designed functions when processing high-dimensional visual states with occlusion or noise?
- Basis in paper: [explicit] "h(·) could adopt advanced techniques such as CNN-based feature extraction... employing discriminative models as h(·) offers greater flexibility in handling unknown and complex scenarios, though this might increase computational demands."
- Why unresolved: All experiments use low-dimensional states with manually designed extractors; no visual or high-dimensional state inputs were tested.
- What evidence would resolve it: Experiments with image-based states comparing extractor types on success rates, robustness to visual perturbations, and computational overhead trade-offs.

### Open Question 3: Principled Joint Optimization of Hybrid Components
- Question: Can an optimization scheme automatically balance gradient scales between parametric (Neural-ODE) and non-parametric (sparse OMGP) components without manual learning rate heuristics?
- Basis in paper: [explicit] "Sparse OMGP is much more sensitive to parameter updates than the Neural-ODE, and training them similarly can lead to sparse OMGP overfitting. To address this issue, we adjusted the learning rate of the sparse OMGP parameters to 10% of that used for the Neural-ODE parameters."
- Why unresolved: The 10:1 ratio is a heuristic workaround; no principled method addresses the fundamental gradient scale mismatch between model types during EM-like training.
- What evidence would resolve it: An adaptive optimization method with theoretical grounding, validated across multiple tasks without requiring task-specific hyperparameter tuning for each component.

## Limitations

- **Method dependency on M specification:** Performance degrades when mixture component count M doesn't match true policy modality, requiring careful tuning or adaptive methods.
- **Training sensitivity:** EM-like optimization requires careful learning rate balancing between OMGP and Neural-ODE components, with sparse OMGP being particularly sensitive to updates.
- **Reproducibility challenges:** Real-world experiments lack full specification of robot setup and demonstration collection protocols, making exact replication difficult.

## Confidence

**High Confidence:** The core mechanism that multimodal base distributions reduce Neural-ODE complexity is well-supported by both theoretical motivation and experimental NFE measurements showing reduced computational burden.

**Medium Confidence:** The superiority over baselines (NGGP, OMGP) is demonstrated empirically, but the ablation studies are limited - only one task (ball-shooting) shows the M vs NFE tradeoff, and the paper doesn't explore robustness to incorrect M specification.

**Low Confidence:** The claim that the EM-like training procedure reliably converges to good local optima is supported by positive results but lacks analysis of training stability across different random seeds or hyperparameter settings.

## Next Checks

1. **Ablation on Mixture Component Sensitivity:** Systematically vary M on the ball-shooting task (e.g., M = {1, 2, 3, 4, 5}) and measure both success rate and Neural-ODE NFEs to quantify how performance degrades when M doesn't match true modality count.

2. **Training Stability Analysis:** Run 10 training trials of CGP-Flow on the ball-shooting task with different random seeds, recording final success rates and training curves to assess variance and identify if certain parameter initializations lead to mode collapse.

3. **ODE Solver Sensitivity:** Train CGP-Flow models using multiple ODE solver tolerances (e.g., atol/rtol = {1e-3, 1e-4, 1e-5, 1e-6}) and measure the tradeoff between computation time, NFE count, and final policy performance to establish practical tolerance guidelines.