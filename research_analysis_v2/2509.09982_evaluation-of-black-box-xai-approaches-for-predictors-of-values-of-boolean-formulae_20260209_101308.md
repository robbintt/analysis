---
ver: rpa2
title: Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean
  Formulae
arxiv_id: '2509.09982'
source_url: https://arxiv.org/abs/2509.09982
tags:
- formulae
- responsibility
- variables
- each
- values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of evaluating explainable AI
  (XAI) methods for Boolean function classifiers by introducing a formal ground-truth
  measure based on actual causality theory. The authors propose a novel black-box
  XAI algorithm, B-ReX, which iteratively refines variable importance estimates through
  recursive partitioning of the input space.
---

# Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae

## Quick Facts
- arXiv ID: 2509.09982
- Source URL: https://arxiv.org/abs/2509.09982
- Authors: Stav Armoni-Friedmann; Hana Chockler; David A. Kelly
- Reference count: 36
- Primary result: B-ReX achieves JS-divergence of 0.072 ± 0.012 on random 10-variable Boolean formulae, outperforming Shapley Values, KernelSHAP, Saliency, DeepLift, and Integrated Gradients

## Executive Summary
This paper addresses the challenge of evaluating explainable AI (XAI) methods for Boolean function classifiers by introducing a formal ground-truth measure based on actual causality theory. The authors propose a novel black-box XAI algorithm, B-ReX, which iteratively refines variable importance estimates through recursive partitioning of the input space. They demonstrate that B-ReX outperforms state-of-the-art methods on a benchmark of randomly generated Boolean formulae, particularly for non-monotonic functions like XOR gates where traditional methods struggle.

## Method Summary
The authors introduce a formal ground-truth measure of variable importance based on Halpern-Pearl actual causation theory, computing responsibility as 1/(k+1) where k is the size of the smallest witness set making the output counterfactually dependent on a variable. For read-once Boolean formulae, they provide exact linear-time algorithms to compute this ground truth. B-ReX is a black-box XAI algorithm that recursively partitions the input space based on responsibility-weighted splits, refining importance estimates through multiple rounds of black-box queries. The approach is evaluated against six baseline methods (Shapley Values, KernelSHAP, Saliency, DeepLift, InputXGrad, Integrated Gradients) using Jensen-Shannon Divergence from ground truth on classifiers trained to 100% accuracy on random Boolean formulae.

## Key Results
- B-ReX achieves JS-divergence of 0.021 on 3-variable non-monotonic formulae and 0.072 on 10-variable formulae
- KernelSHAP shows near-zero accuracy across all tests, likely due to sampling issues with Boolean discontinuities
- Gradient-based methods (Saliency, DeepLift) fail completely on non-monotonic functions, spreading attribution across correlated inputs
- ShapleyValues show high variance on non-monotonic functions due to context-dependent XOR contributions
- B-ReX's responsibility-weighted partitioning strategy proves critical for performance, particularly in distinguishing truly responsible variables from correlated ones

## Why This Works (Mechanism)

### Mechanism 1
The degree of responsibility provides a formally grounded, quantitative measure of variable importance for Boolean formulae that captures counterfactual dependence. Using the modified Halpern-Pearl definition of actual causation (conditions AC1-AC3), importance is quantified as r(X=x, O=o) = 1/(k+1), where k is the size of the smallest witness set W that makes the output counterfactually dependent on X. This works because Boolean variables have causal independence, creating a depth-2 causal model where only inputs determine the output.

### Mechanism 2
Exact responsibility can be computed in O(|φ|) time for read-once Boolean formulae via two-pass tree traversal. The first pass (DEPENDS) computes minimum leaf interventions needed to flip each gate's value, using the I operator to classify dependency type. The second pass (RESPONSIBILITY) propagates accumulated witness size from root to leaves, computing r = 1/(1+ctx) at each leaf. This is efficient because read-once formulae create tree-structured causal models with no shared subtrees.

### Mechanism 3
Iterative, responsibility-guided partitioning of input space yields superior approximation of causal responsibility compared to gradient-based or Shapley-value methods, particularly for non-monotonic functions. B-ReX partitions input indices into blocks, finds the smallest witness set W* that makes each block counterfactually dependent, assigns responsibility 1/(1+|W*|), then recursively refines blocks with defined witnesses. The adaptive partitioning uses l1 norm of current responsibility vector as weights, so high-responsibility areas get finer investigation.

## Foundational Learning

- **Actual Causality and Structural Causal Models**: The entire theoretical framework rests on Halpern-Pearl actual causation; understanding AC1-AC3 and witness sets is essential for interpreting ground truth and B-ReX outputs. Quick check: Given (True ∧ False), which variable has higher responsibility? (Answer: False has responsibility 1, True has responsibility 0 since flipping True doesn't change the output.)

- **Shapley Values vs. Responsibility**: B-ReX is benchmarked against Shapley-based methods; understanding why Shapley fails on non-monotonic functions (XOR) explains the performance gap. Quick check: Why does Shapley estimation degrade on XOR gates? (Answer: A variable's contribution is context-dependent—it can increase or decrease output depending on other inputs—making sampling strategy highly influential.)

- **Jensen-Shannon Divergence**: Primary evaluation metric; JS-divergence is symmetric and handles zero values gracefully, unlike KL-divergence. Quick check: Why prefer JS-divergence over top-k overlap for comparing attribution maps? (Answer: JS-divergence penalizes magnitude mismatches across the full distribution, not just ranking errors in top features.)

## Architecture Onboarding

- **Component map**: Ground Truth Computation (Algorithms 1+2 or brute-force) -> B-ReX Core (PARTITION -> witness-finding -> recursion) -> Responsibility Map (ρ) -> Classifier Wrapper (MLP)
- **Critical path**: Parse Boolean formula -> Compute ground truth via Algorithm 2 (read-once) or brute-force (general) -> Train MLP classifier to 100% accuracy -> Initialize ρ, run B-ReX with partitioning and recursion -> Compute JS-divergence between B-ReX output and ground truth
- **Design tradeoffs**: B-ReX vs. Shapley requires more forward passes (slower) but doesn't assume additivity or monotonicity (better on XOR); B-ReX vs. Gradient methods is black-box (model-agnostic) but slower; Read-once vs. General provides linear ground truth but restricted formula class vs. complete but exponential computation
- **Failure signatures**: KernelSHAP near-zero accuracy (sampling insufficient for Boolean discontinuities); InputXGrad complete failure on non-monotonic (gradient signal spreads across XOR inputs); B-ReX degraded performance at n=10 (increasing recursion depth and partition overhead); ShapleyValues high variance on non-monotonic (sampling bias from context-dependent XOR contributions)
- **First 3 experiments**: 1) Validate ground truth on Figure 1 formula by implementing Algorithms 1 & 2 for (False ∧ (False ∧ False)) and verifying leaf responsibilities match [1/3, 1/3, 1/3]; 2) Reproduce B-ReX on 3-variable non-monotonic formula, confirm JS-divergence ≈ 0.021; 3) Ablate partition strategy by replacing l1-weighted partitioning with random partitioning on 10-variable formula, measure JS-divergence degradation vs. baseline (0.072)

## Open Questions the Paper Calls Out

- **Can the exact computation of ground-truth responsibility be extended beyond read-once Boolean formulae to larger or more complex formula classes without resorting to exponential brute-force methods?**: The paper provides only linear-time algorithms for read-once formulae and relies on brute-force enumeration for general cases, leaving efficient computation for broader formula classes unaddressed.

- **How does B-ReX perform on non-tabular data types where the causal independence assumption between feature variables may not hold?**: B-ReX's theoretical foundation assumes causal independence of features, which is valid for Boolean variables but untested for correlated features in real-world tabular or spectral data.

- **Can B-ReX's computational efficiency be improved to match gradient-based methods while maintaining its superior accuracy on non-monotonic functions?**: The paper demonstrates B-ReX's accuracy advantage but does not explore optimization strategies for its recursive partitioning approach.

## Limitations

- The exact computation of ground-truth responsibility is only efficient for read-once Boolean formulae; general cases require exponential brute-force enumeration
- B-ReX is slower than gradient-based methods due to multiple forward passes required per explanation
- Evaluation is limited to synthetic Boolean formulae rather than real-world Boolean classifiers
- The causal independence assumption may not hold for non-Boolean tabular data, limiting applicability

## Confidence

- **High confidence**: The theoretical foundation of responsibility using Halpern-Pearl actual causation, the correctness of linear-time algorithms for read-once formulae, and the superiority of B-ReX over gradient-based and Shapley methods on non-monotonic functions
- **Medium confidence**: The claim that B-ReX's partitioning strategy is the key to its performance advantage, given that implementation details of the partitioning are somewhat underspecified
- **Low confidence**: The practical significance of these results for real-world applications, as the evaluation is limited to synthetic Boolean formulae rather than actual Boolean classifiers from practical domains

## Next Checks

1. Test B-ReX on Boolean classifiers trained on real-world datasets (e.g., medical diagnosis rules or digital circuit specifications) to assess practical utility beyond synthetic benchmarks
2. Implement and compare alternative black-box search strategies (e.g., genetic algorithms, Bayesian optimization) against B-ReX's responsibility-weighted partitioning to determine if the partitioning approach is truly optimal
3. Analyze the sensitivity of B-ReX's performance to the Kleene logic semantics—test whether standard two-valued logic yields similar results or if the three-valued approach is essential for the observed improvements