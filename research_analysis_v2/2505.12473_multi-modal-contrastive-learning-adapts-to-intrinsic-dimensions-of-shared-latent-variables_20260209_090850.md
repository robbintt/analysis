---
ver: rpa2
title: Multi-modal contrastive learning adapts to intrinsic dimensions of shared latent
  variables
arxiv_id: '2505.12473'
source_url: https://arxiv.org/abs/2505.12473
tags:
- dimension
- which
- information
- learning
- representations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies multi-modal contrastive learning theoretically,
  focusing on representation properties beyond linear settings. The key insight is
  that temperature optimization enables the method to not only maximize mutual information
  but also adapt to the intrinsic dimension of shared latent variables, which can
  be much lower than the user-specified output dimension.
---

# Multi-modal contrastive learning adapts to intrinsic dimensions of shared latent variables

## Quick Facts
- arXiv ID: 2505.12473
- Source URL: https://arxiv.org/abs/2505.12473
- Reference count: 40
- Multi-modal contrastive learning automatically discovers the intrinsic dimension of shared latent variables, which can be much lower than the user-specified output dimension.

## Executive Summary
This paper presents theoretical analysis of multi-modal contrastive learning that explains how learned representations naturally adapt to the intrinsic dimension of shared latent variables rather than simply matching user-specified output dimensions. The key insight is that temperature optimization in the infoNCE loss drives representations to collapse to exactly the minimum dimension needed to preserve mutual information between modalities. Experiments on synthetic and real datasets demonstrate that downstream task accuracy saturates once the output dimension exceeds the intrinsic dimension, providing a practical way to identify the true dimensionality of shared information.

## Method Summary
The method uses multi-modal contrastive learning with learnable temperature to optimize infoNCE loss between paired data from two modalities. The architecture consists of 5-layer ReLU encoders with output dimension d, using a custom similarity measure based on inner product normalized by running averages of norms. Temperature is optimized jointly with encoder weights using separate learning rates. The approach is tested on synthetic linear and nonlinear data (with known ground truth intrinsic dimension k*=2 or 5) and real datasets (CITE-seq with 24-dim protein and 200-dim RNA data, ImageNetV2 with pre-extracted features). Downstream accuracy and MLE-based intrinsic dimension estimation are used to validate that learned representations adapt to k* rather than d.

## Key Results
- Theoretical proof that minimizers of infoNCE loss capture exactly the intrinsic dimension of shared latent variables
- Temperature converges to zero during optimization, enabling dimensional collapse
- Downstream task accuracy saturates when output dimension exceeds intrinsic dimension
- Automatic discovery of low-dimensional representations on synthetic and real datasets

## Why This Works (Mechanism)

### Mechanism 1: Temperature-Driven Dimensional Collapse
- **Claim:** The method discovers the intrinsic dimension k* of shared latent variables because temperature optimization forces representations to collapse from ambient dimension d down to the lowest dimension preserving mutual information.
- **Mechanism:** As temperature τ→0, the softmax sharpens, enforcing strict alignment and uniformity. Theorem 2 proves minimizers adapt exactly to k*, provided the function class is expressive enough.
- **Core assumption:** The function class H is sufficiently expressive such that V(H) is non-empty.
- **Evidence anchors:**
  - [abstract]: "The authors prove that minimizers of the infoNCE loss capture exactly the intrinsic dimension of the data and converge to zero temperature."
  - [section 3.2]: "Theorem 2... (intrinsic dimension adaptation) ID(f) = ID(g) = k*."
- **Break condition:** If H lacks capacity (V(H)=∅), temperature may converge to non-zero value or intrinsic dimension is misidentified.

### Mechanism 2: Mutual Information via Variational Decomposition
- **Claim:** InfoNCE loss functions as variational bound maximizing discrete mutual information while minimizing divergence to uniform prior.
- **Mechanism:** Loss decomposes into -2I(f;g) + Alignment/Error Terms. Minimizing forces extraction of all shared information while ensuring embeddings are spread out.
- **Core assumption:** Discretization is fine-grained enough to approximate continuous MI limits.
- **Evidence anchors:**
  - [section 3.1]: "L(f, g, τ) can be decomposed as -2I(f(X); g(Y )) + D_KL..."
  - [section 2.1]: Defines maximal mutual information via discrete approximations.

### Mechanism 3: Automatic Dimension Discovery
- **Claim:** Downstream accuracy saturates when d≥k*, allowing practitioners to identify k* empirically by varying d.
- **Mechanism:** When d<k*, network is bottleneck. When d≥k*, temperature mechanism ensures effective usage is only k*, yielding diminishing returns.
- **Core assumption:** Intrinsic dimension k* is stable across data distribution.
- **Evidence anchors:**
  - [section 4]: "Downstream task accuracy saturates when the output dimension exceeds the intrinsic dimension."
  - [figure 3]: Shows accuracy and MLE-intrinsic dimension curves flattening as d increases past k*.

## Foundational Learning

- **Concept: Intrinsic Dimension (k*) vs. Ambient Dimension**
  - **Why needed here:** Central thesis is these decouple during training. Distinguish "true" complexity of shared data (k*) from vector size of network output (d).
  - **Quick check question:** If I increase network's output layer from 128 to 256 and loss doesn't change, what does that imply about k* relative to 128?

- **Concept: InfoNCE Loss Function**
  - **Why needed here:** This is the specific objective function analyzed. Understanding denominator's role (negative pairs) is crucial to understanding why uniformity matters.
  - **Quick check question:** In InfoNCE formula, what happens to gradient of positive pair if denominator is dominated by single hard negative?

- **Concept: Discretized Mutual Information**
  - **Why needed here:** Continuous MI is infinite for deterministic aligned representations. Paper uses discretized limit (Definition 2) to mathematically compare aligned representations.
  - **Quick check question:** Why can't we use standard Shannon Mutual Information to compare two perfectly aligned continuous representations?

## Architecture Onboarding

- **Component map:** Input Pair → Encoders → Normalize → Compute Similarity Matrix → Apply τ scaling → InfoNCE Loss
- **Critical path:** Encoders map inputs to shared representation space, similarity measure computes relationships, temperature scaling sharpens distribution, loss aggregates information.
- **Design tradeoffs:**
  - Output Dimension (d): Higher d ensures expressiveness (d≥k*) but increases compute. Paper suggests starting large and letting model "ignore" unnecessary dimensions.
  - Function Class: Must be expressive enough to satisfy V(H)≠∅. Linear models may fail to capture intrinsic dimension of non-linear manifolds.
- **Failure signatures:**
  - Temperature τ stability: If τ doesn't decrease towards 0, theoretical guarantees fail. Suggests V(H) is empty or learning rate issues.
  - Dimension Inflation: If estimated intrinsic dimension keeps growing with d without saturation, data may not have low-dimensional shared latent structure, or encoder is overfitting noise.
- **First 3 experiments:**
  1. **Dimension Saturation Test:** Train models with increasing output dimensions d∈{5, 10, 20, 50}. Plot downstream accuracy vs. d to estimate k* (look for "elbow").
  2. **Temperature Tracking:** Log value of τ every epoch. Verify it decays to near-zero; if it plateaus high, investigate encoder capacity.
  3. **Intrinsic Dimension Estimation:** Apply MLE-based intrinsic dimension estimator to embeddings of trained model. Confirm estimated dimension ≈ k* found in Experiment 1.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the finite-sample behavior of infoNCE loss minimizers and estimated intrinsic dimension?
- **Basis in paper:** [explicit] Discussion states "it is interesting to study the finite-sample behavior of the infoNCE loss as well as its minimizers."
- **Why unresolved:** Theoretical analysis focuses on population-level loss and infinite data limits; empirical results show convergence but finite-sample statistical rates remain uncharacterized.
- **What evidence would resolve it:** Theoretical analysis establishing convergence rate and confidence intervals for estimated intrinsic dimension relative to sample size N.

### Open Question 2
- **Question:** How does temperature parameter behave when function class is insufficient to achieve ideal representation properties (V(H)=∅)?
- **Basis in paper:** [explicit] Discussion notes "it would be of theoretical interest to characterize the precise limit of optimized temperature in general settings beyond this regime [V(H)≠∅]."
- **Why unresolved:** Main theorem proving τ→0 relies strictly on V(H)≠∅; Appendix G.2 shows empirical cases where this assumption fails but theoretical behavior of τ is undefined.
- **What evidence would resolve it:** Theoretical characterization of optimal temperature τ or empirical analysis of its convergence point when neural network lacks capacity.

### Open Question 3
- **Question:** Does two-stage fitting strategy offer computational or statistical advantages over training directly with intrinsic dimension?
- **Basis in paper:** [explicit] Discussion suggests "our theory suggests a two-stage fitting strategy... This could potentially accelerate the inference speed."
- **Why unresolved:** Theory suggests discovering dimension is possible with large d, but paper doesn't validate whether this strategy outperforms setting d=k* from start in terms of convergence speed or final accuracy.
- **What evidence would resolve it:** Comparative experiments evaluating convergence speed and final performance of two-stage approach versus standard training across varying output dimensions.

### Open Question 4
- **Question:** How does choice of similarity measure alter adaptation to intrinsic dimensions?
- **Basis in paper:** [inferred] Paper primarily uses inner product with population-level normalization, noting in Appendix G.5 it's "comparable" to cosine similarity but potentially distinct in lower signal-to-noise regimes.
- **Why unresolved:** Theoretical results rely on specific properties of defined similarity measure σ; unclear if convergence to k* holds strictly or how "uniformity" term changes with different similarity metrics.
- **What evidence would resolve it:** Theoretical extension of Theorem 2 to general similarity metrics or empirical sensitivity analysis showing how estimated intrinsic dimension shifts when changing similarity kernel.

## Limitations

- The theoretical framework relies heavily on the assumption that the function class is sufficiently expressive to represent aligned solutions, which can be difficult to verify in practice.
- The temperature-driven mechanism requires careful optimization - if temperature plateaus at non-zero values, the theoretical guarantees fail.
- The discretization approach for mutual information is a non-standard technique that may not generalize to all data distributions.

## Confidence

- **High Confidence:** Experimental validation showing downstream accuracy saturation at intrinsic dimension across multiple datasets (synthetic linear/nonlinear, CITE-seq, ImageNetV2). The phenomenon is consistently observed and well-documented.
- **Medium Confidence:** Theoretical proofs connecting temperature optimization to intrinsic dimension adaptation. While mathematically rigorous, these depend on assumptions about function class expressiveness that are difficult to verify empirically.
- **Medium Confidence:** Mechanism explaining how temperature drives dimensional collapse. The theory is sound, but practical implementation challenges (temperature underflow, capacity requirements) may limit applicability.

## Next Checks

1. **Capacity Sensitivity Analysis:** Systematically vary encoder architecture depth/width to test the threshold at which V(H) becomes non-empty. Verify that temperature converges to zero only when sufficient capacity is available.

2. **Temperature Stability Testing:** Monitor temperature trajectories across multiple random seeds and datasets. Identify conditions where temperature plateaus at non-zero values and analyze whether this correlates with capacity limitations or learning rate issues.

3. **Generalization to Noisy Data:** Test the method on synthetic data with varying levels of noise corruption to assess robustness. Verify that the estimated intrinsic dimension remains stable and that temperature optimization still converges appropriately under realistic noise conditions.