---
ver: rpa2
title: Topological Signatures of Adversaries in Multimodal Alignments
arxiv_id: '2501.18006'
source_url: https://arxiv.org/abs/2501.18006
tags:
- adversarial
- topological
- multimodal
- data
- adversaries
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates adversarial attacks on multimodal alignment
  models like CLIP/BLIP by analyzing topological signatures between image and text
  embeddings. The authors propose two novel Topological-Contrastive losses - Total
  Persistence (TP) and Multi-scale Kernel (MK) - that measure topological differences
  between image and text embeddings.
---

# Topological Signatures of Adversaries in Multimodal Alignments

## Quick Facts
- arXiv ID: 2501.18006
- Source URL: https://arxiv.org/abs/2501.18006
- Reference count: 40
- Primary result: Topological-Contrastive losses detect adversarial attacks on multimodal alignment models with up to 16.7% accuracy gains over SAMMD baseline

## Executive Summary
This paper introduces a novel approach to detect adversarial attacks on multimodal alignment models like CLIP and BLIP by analyzing topological signatures between image and text embeddings. The authors propose two Topological-Contrastive losses - Total Persistence (TP) and Multi-scale Kernel (MK) - that measure topological differences between image and text embedding distributions. They demonstrate that these losses exhibit monotonic increases as adversarial sample proportion increases across various datasets, models, and attack methods. By back-propagating these topological signatures to input samples, they create new MMD-based adversarial detection methods (TPSAMMD and MKSAMMD) that outperform existing approaches while maintaining controlled Type-I error rates.

## Method Summary
The method extracts image and text logits before alignment from CLIP/BLIP models, then computes persistence diagrams via Vietoris-Rips filtrations. Two Topological-Contrastive losses (TP and MK) quantify the topological misalignment between image and text embeddings. These global losses are decomposed into per-sample topological features by computing gradients with respect to individual embeddings. The topological features are integrated into MMD tests using a contrastive kernel that combines topological and semantic similarity. The detection framework uses holdout sets to approximate independent feature computation, enabling statistical testing between clean and adversarial distributions.

## Key Results
- TP and MK losses show monotonic increases as adversarial sample proportion increases in most experimental configurations
- TPSAMMD achieves up to 16.7% accuracy gains over SAMMD baseline in certain configurations
- Type-I error remains controlled at 5% when holdout assumptions are satisfied
- Improvement is most pronounced for small perturbation magnitudes (ε = 1/255)
- More sophisticated attacks exhibit more pronounced monotonic behavior than simpler attacks like FGSM

## Why This Works (Mechanism)

### Mechanism 1: Topological Disruption Detection via Persistence Diagrams
Adversarial perturbations disrupt multimodal alignment in ways that alter the topological structure of embedding distributions. Image and text embeddings form point clouds whose Vietoris-Rips filtrations produce persistence diagrams encoding topological features. The TP loss sums absolute differences in total persistence across homology dimensions, while MK loss computes kernel similarity between diagrams. Adversarial samples increase topological complexity (scattering), widening the gap between image and text topologies. The adversarial scattering assumption holds that attacks shift logits toward target classes without preserving cluster structure, producing more scattered representations. Evidence shows TP increases monotonically across nearly all experiments, with MK providing multi-scale smoothness but direction varying by dataset.

### Mechanism 2: Sample-Level Topological Features via Gradient Back-Propagation
Global TC losses can be decomposed into per-sample topological features by computing gradients with respect to individual embeddings. Given a batch Y and holdout Z, the TC loss LT C(Y ∪ Z, T) is computed where T is text embedding. Back-propagating to obtain Ẏ = ∇Y LT C(Y ∪ Z, T) quantifies each sample's contribution to topological image-text misalignment. Clean samples cluster differently in gradient space than adversarial samples, enabling detection. The holdout set Z must be sufficiently larger than test batch Y to maintain acceptable independence violations. Gradients capture how each image's feature contributes to changes in topological alignment, providing discriminative signal for detection.

### Mechanism 3: Enhanced MMD Detection via Topological-Contrastive Kernel
Incorporating topological features into SAMMD's deep kernel improves test power for adversarial detection while maintaining controlled Type-I error. The topological-contrastive kernel kτ = [(1-ε₀)τ + ε₀]ν combines topological similarity τ with semantic similarity ν. The U-statistic estimator computes discrepancy between clean and adversarial distributions. TPSAMMD shows up to 16.7% accuracy gains, with improvement most pronounced at small perturbation magnitudes. The topological features provide orthogonal information to semantic features that is specifically sensitive to adversarial perturbations, enhancing detection capability.

## Foundational Learning

- **Persistent Homology (Vietoris-Rips Complexes, Persistence Diagrams)**: The entire TC loss framework is built on computing persistence diagrams from point clouds via VR filtrations. Without this, you cannot understand what TP or MK measure. Quick check: Given a set of points in R², can you sketch how the VR complex evolves as ε increases and explain what a birth-death pair represents?

- **Multimodal Alignment (CLIP/BLIP Architecture)**: The method targets misalignment between image and text embeddings. Understanding how CLIP's contrastive learning produces aligned embedding spaces is essential for interpreting why adversarial attacks disrupt this alignment. Quick check: In CLIP, why are image and text embeddings projected to the same dimensional space, and what does the alignment loss optimize?

- **Maximum Mean Discrepancy (MMD) Two-Sample Testing**: The detection framework extends SAMMD by incorporating topological features. You need to understand how MMD tests work, what test power and Type-I error mean, and how deep kernels are optimized. Quick check: If MMD(P, Q; Hk) = 0 iff P = Q, why does the empirical MMD test require kernel selection and threshold calibration?

## Architecture Onboarding

- **Component map**: Embedding extraction -> VR filtration construction -> persistence diagram -> TC loss -> back-propagation -> kernel evaluation -> test statistic
- **Critical path**: Embedding extraction → VR filtration construction (computational bottleneck) → persistence diagram → TC loss → back-propagation → kernel evaluation → test statistic. The VR filtration is O(n²) in batch size; this dominates runtime.
- **Design tradeoffs**: Batch size vs. statistical power (smaller batches are realistic but harder); holdout size vs. independence (larger Z improves independence but increases cost); TP vs. MK (TP more consistent, MK provides smoothness); homology dimension (paper focuses on H₀).
- **Failure signatures**: Non-monotonic TC loss (check FGSM or perturbation magnitude); high Type-I error (verify holdout Z is clean and sufficiently large); low test power at small ε (expected behavior); memory overflow (reduce batch size or use sparse approximations).
- **First 3 experiments**: (1) Reproduce monotonic TP loss curve on CLIP-ViT-B/32 with CIFAR10 across adversarial proportions; (2) Validate gradient feature separation with 500 clean and 500 adversarial samples; (3) Compare TPSAMMD vs. SAMMD on ImageNet with CLIP-ViT-L/14 at ε = 1/255 and 4/255.

## Open Questions the Paper Calls Out

- **Generalization to other modalities**: Can the topological signatures identified in image-text models be generalized to other multimodal configurations, specifically video-text and audio-text systems? The conclusion explicitly lists this as a future direction, but current study only validates on image-text alignment models.

- **Attack sophistication and monotonicity**: Why do more sophisticated attack methods result in more pronounced monotonic behavior in Topological-Contrastive losses compared to simpler attacks like FGSM? Appendix A observes this trend and hypothesizes FGSM's simplicity leads to unrealistic samples, warranting further research.

- **Hold-out ratio sensitivity**: How does the ratio of hold-out dataset size |Z| to test batch size |Y| impact the error rate and test power of the proposed detection method? Section 4 notes batch approximation is used when |Z| >> |Y|, but does not quantify sensitivity across different ratios.

## Limitations

- Hyperparameter sensitivity: Critical hyperparameters for TP/MK loss computation, MMD kernel optimization, and batch configurations are not specified, potentially limiting reproducibility.
- Scalability concerns: VR filtration construction is O(n²), limiting batch sizes and practical deployment without computational optimizations.
- Limited generalizability: Experiments focus on image-text alignment models; effectiveness on other multimodal tasks remains untested.

## Confidence

- **High Confidence**: Monotonic TC loss behavior across most experiments, basic mechanism of gradient-based topological feature extraction, Type-I error control when holdout assumptions hold.
- **Medium Confidence**: Improvement claims for TPSAMMD vs. SAMMD (lack of external comparative validation), effectiveness against AutoAttack (only evaluated in one configuration), robustness to non-monotonic cases like FGSM.
- **Low Confidence**: Performance in real-world deployment scenarios, sensitivity to hyperparameter choices, effectiveness against novel attack types specifically designed to preserve topological structure.

## Next Checks

1. **Reproduce Monotonicity**: Generate mixed batches (0-100% adversarial) on CLIP-ViT-B/32 with CIFAR-10. Verify normalized TP loss increases monotonically across all attack types except FGSM.

2. **Validate Kernel Improvement**: Implement TPSAMMD kernel k_τ and run detection tests on ImageNet with CLIP-ViT-L/14. Compare test power and Type-I error against SAMMD baseline at ε = 1/255 and 4/255.

3. **Test Type-I Error Control**: Run detection tests with varying holdout set sizes (500, 1000, 3000) and batch sizes (25, 50, 100). Verify Type-I error remains near 5% when |Z| >> |Y|.