---
ver: rpa2
title: Readable Twins of Unreadable Models
arxiv_id: '2504.13150'
source_url: https://arxiv.org/abs/2504.13150
tags:
- learning
- deep
- readable
- flow
- twin
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of making deep learning models
  explainable by introducing the concept of "readable twins" - symbolic, human-readable
  models that mirror unreadable deep learning models. The core method involves transforming
  a deep learning model into an imprecise information flow model (IIFM) via a sequential
  information system, where model activations are clustered and mapped to nodes in
  a rough set flow graph.
---

# Readable Twins of Unreadable Models

## Quick Facts
- arXiv ID: 2504.13150
- Source URL: https://arxiv.org/abs/2504.13150
- Authors: Krzysztof Pancerz; Piotr Kulicki; Michał Kalisz; Andrzej Burda; Maciej Stanisławski; Jaromir Sarzyński
- Reference count: 15
- One-line primary result: Deep learning models can be transformed into symbolic, human-readable "twins" via activation clustering and rough set flow graphs, enabling interpretable explanations of predictions.

## Executive Summary
The paper introduces a method to create "readable twins" of deep learning models (DLMs) by transforming them into imprecise information flow models (IIFMs) that are human-interpretable. The approach converts neural activations into symbolic representations through clustering, then constructs a rough set flow graph (RSFG) with certainty, strength, and covering coefficients for edges. Evolutionary algorithms are used to mine confident prediction paths through the graph, providing visual explanations of model decisions. The method is demonstrated on MNIST handwritten digit classification, showing that the readable twin preserves the model's knowledge while making it accessible for human understanding.

## Method Summary
The HuReTEx method transforms a deep learning model into a symbolic representation through a six-step pipeline. First, activations are extracted from key layers of a trained DLM and clustered using agglomerative clustering to create symbolic representations. Second, a sequential information system (SIS) is built where each row represents a training sample and columns contain cluster assignments per layer plus the class label. Third, an imprecise information flow model (IIFM) is constructed as a rough set flow graph (RSFG) where nodes represent activation clusters and edges carry three coefficients: certainty (P(next|current)), strength (fraction of transitions), and covering (P(current|next)). Fourth, evolutionary algorithms search for confident prediction paths through the RSFG using a fitness function based on the harmonic mean of certainty and covering. Fifth, the top-k paths are extracted and visualized with artifact histograms summarizing the activation patterns in each cluster. The method is demonstrated on MNIST using a simple CNN architecture.

## Key Results
- The readable twin successfully transforms a DLM into an interpretable rough set flow graph that preserves prediction accuracy
- Confident prediction paths through the RSFG can be visualized with associated artifact histograms, showing what features led to specific classifications
- The evolutionary algorithm effectively identifies high-confidence paths that correspond to meaningful decision patterns learned by the model

## Why This Works (Mechanism)

### Mechanism 1
Clustering neural activations produces symbolic abstractions that preserve decision-relevant information while enabling human interpretability. Agglomerative clustering groups activation vectors from each layer into discrete clusters, replacing continuous activation values with cluster identifiers suitable for flow graph construction. The core assumption is that cluster centroids capture functionally equivalent activation patterns—activations within a cluster lead to similar downstream decisions. Break condition: If cluster granularity is too coarse, distinct decision patterns collapse; if too fine, interpretability degrades and graph size explodes.

### Mechanism 2
Rough set flow graphs with three edge coefficients (certainty, strength, covering) capture imprecise information flow between layer representations. Each graph layer corresponds to a model layer; nodes represent activation clusters. Edges carry: (1) certainty—P(next state | current state), (2) strength—fraction of total layer-to-layer transitions, (3) covering—P(current state | next state). These coefficients quantify transition reliability. The core assumption is that the sequential information system faithfully represents the causal flow of information through the original DLM. Break condition: If layer activations are not sequential in the information-theoretic sense (e.g., skip connections, residual flows), the SIS ordering may misrepresent actual information flow.

### Mechanism 3
Evolutionary algorithms with confidence-based fitness functions identify the most interpretable prediction paths through the flow graph. Chromosomes encode node sequences across layers. Fitness = aggregated confidence (harmonic mean of certainty and covering) using triangular norms/co-norms. EA searches for paths maximizing this aggregate measure. The core assumption is that high-confidence paths in the RSFG correspond to meaningful decision patterns learned by the DLM—not artifacts of clustering or graph construction. Break condition: If the RSFG is densely connected or confidence values are uniformly distributed, EA may converge to arbitrary paths without clear semantic meaning.

## Foundational Learning

- **Rough Set Theory and Flow Graphs**: Why needed here: RSFGs form the representational backbone of readable twins. Understanding approximation spaces, indiscernibility, and flow coefficients is prerequisite to interpreting outputs. Quick check question: Given a flow graph with edge certainty=0.7 and covering=0.4, what is the confidence (harmonic mean)?

- **Activation Clustering in Neural Networks**: Why needed here: The method's first nontrivial transformation is clustering layer activations. Without understanding what activations represent and how clustering affects information preservation, one cannot assess fidelity loss. Quick check question: If two images produce activations in different clusters but receive the same classification, what might this indicate about cluster granularity?

- **Evolutionary Algorithm Design**: Why needed here: Path mining relies on EA with domain-specific fitness. Understanding chromosome encoding, selection pressure, and convergence criteria is necessary to debug poor explanations. Quick check question: What happens to path diversity if the fitness function over-weights certainty relative to covering?

## Architecture Onboarding

- Component map: DLM -> Activation Extractor -> Clustering Module -> Sequential Information System -> Rough Set Flow Graph Builder -> Evolutionary Path Miner -> Visualization Engine

- Critical path: 1) Extract activations from all convolutional and dense layers (skip input/flatten), 2) Cluster per-layer activations (agglomerative recommended), 3) Build SIS table: rows=training samples, columns=layer cluster assignments + label, 4) Construct RSFG with three coefficients per edge, 5) Run EA to mine top-k confident paths, 6) Visualize paths with artifact histograms

- Design tradeoffs: Cluster count vs. interpretability (more clusters = finer granularity but larger graphs), training set size vs. RSFG reliability (larger sets improve coefficient estimates but increase computation), EA generations vs. path quality (more generations may overfit to training data patterns)

- Failure signatures: Empty or near-empty paths (clustering too fine; most transitions fall below strength threshold), all paths lead to same class (clustering too coarse; class-distinguishing patterns collapsed), EA fails to converge (confidence values too uniform; fitness landscape flat)

- First 3 experiments: 1) Reproduce MNIST result with provided architecture; validate that confident paths visually correspond to digit features, 2) Vary cluster count (e.g., 5, 10, 20 per layer); measure path diversity and coefficient distributions, 3) Apply to a different CNN architecture (e.g., with skip connections); assess whether SIS ordering assumptions break

## Open Questions the Paper Calls Out

- Can the integration of ontologies enhance the semantic interpretability of artifact clusters in the readable twin? The current method maps clusters to visual histograms but lacks a formal semantic layer linking numerical artifacts to high-level domain concepts. What evidence would resolve it: A modified framework where nodes in the Rough Set Flow Graph are linked to ontological terms, allowing for semantic querying of the prediction path.

- How can the extracted prediction paths and visual artifacts be translated into natural language descriptions? The current "readable twin" relies on visual summarizations and flow graph coefficients, which still require expert interpretation to explain why a specific path implies a certain class. What evidence would resolve it: The development of a natural language generation module that takes confident prediction paths as input and outputs grammatical, human-like explanations.

- Does the readability and fidelity of the Imprecise Information Flow Model (IIFM) scale effectively to deeper architectures and higher-dimensional datasets? It is unclear if clustering activations in very deep networks or high-resolution images will result in an intractable number of nodes or a loss of critical granular information. What evidence would resolve it: Successful application of the HuReTEx method to large-scale models (e.g., ResNet, Transformers) on complex datasets (e.g., ImageNet) with measurable fidelity scores.

## Limitations

- The method has only been demonstrated on MNIST with a simple CNN architecture, limiting generalizability to more complex models and datasets
- No empirical validation exists for the assumption that activation clustering preserves decision-relevant information without significant fidelity loss
- The computational complexity of the six-step pipeline is not analyzed, and there's no comparison to alternative XDL methods like LIME, SHAP, or attention-based explanations

## Confidence

- **Medium confidence** in the clustering-to-symbolic-transformation mechanism: The theoretical foundation is sound (rough sets, sequential information systems), but empirical validation across diverse architectures and datasets is absent.
- **Medium confidence** in evolutionary path mining: The fitness function design is principled, but without ablation studies showing what happens when coefficients are removed or modified, the necessity of all three coefficients (certainty, strength, covering) remains unproven.
- **Low confidence** in the "readable twin" concept as generalizable: The MNIST demonstration is compelling but represents a minimal complexity scenario. The method's behavior on deeper networks, different data modalities, or architectures with complex connections (residual, attention) is unknown.

## Next Checks

1. **Ablation study on edge coefficients**: Remove each coefficient (certainty, strength, covering) individually and evaluate whether confident paths still emerge, and if so, whether they remain interpretable and correspond to actual decision patterns.

2. **Cross-dataset generalization test**: Apply the complete pipeline to CIFAR-10 or Fashion-MNIST with a deeper CNN (8-12 layers). Compare the interpretability and fidelity of explanations against the MNIST baseline, specifically measuring path confidence distributions and visualization quality.

3. **Fidelity verification experiment**: For each mined confident path, perturb input images to follow or deviate from the path and measure actual prediction changes. This would validate whether the RSFG paths truly represent causal decision flows rather than statistical correlations.