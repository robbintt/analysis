---
ver: rpa2
title: Training-free LLM Merging for Multi-task Learning
arxiv_id: '2506.12379'
source_url: https://arxiv.org/abs/2506.12379
tags:
- merging
- performance
- tasks
- language
- fine-tuned
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Hi-Merging, a training-free method for unifying
  specialized LLMs into a single multi-task model. The approach addresses parameter
  conflicts through hierarchical iterative pruning and scaling of delta vectors, guided
  by contribution analysis to identify and resolve layer-wise conflicts.
---

# Training-free LLM Merging for Multi-task Learning

## Quick Facts
- arXiv ID: 2506.12379
- Source URL: https://arxiv.org/abs/2506.12379
- Reference count: 25
- Key outcome: Hi-Merging unifies fine-tuned LLMs into a single multi-task model without training, achieving up to 36.42% relative improvement over single-task models and surpassing fine-tuned models on combined datasets in most scenarios.

## Executive Summary
This paper introduces Hi-Merging, a training-free method for unifying multiple fine-tuned LLMs into a single multi-task model. The approach addresses parameter conflicts arising during merging through hierarchical iterative pruning and scaling of delta vectors, guided by contribution analysis. Extensive experiments on bilingual multi-task scenarios (English/Chinese, MCQA/QA) demonstrate that Hi-Merging consistently outperforms existing merging techniques and even models fine-tuned on combined datasets in most cases.

## Method Summary
Hi-Merging merges fine-tuned LLMs without additional training by operating on delta vectors (fine-tuned minus foundation model). The method applies hierarchical conflict resolution: first model-wise pruning and scaling of deltas, then layer-wise contribution analysis to identify conflicts between layers. Contribution is measured via deletion (α) and addition (β) impacts; conflicts (γ) are resolved iteratively starting from the most conflicting layers. Severe conflicts drop one delta, partial conflicts re-prune/scale, and mutual enhancement keeps both. The final merged model is formed by adding resolved deltas to the foundation model.

## Key Results
- Outperforms existing merging techniques by up to 36.42% relative improvement over single-task models
- Achieves better average performance than fine-tuned models on combined datasets in most scenarios
- Maintains balanced performance across English and Chinese languages and MCQA/QA tasks
- Mean ranking of 1.25 across all tasks, significantly higher than competing methods

## Why This Works (Mechanism)
Hi-Merging addresses parameter conflicts that arise when merging fine-tuned models by identifying and resolving layer-wise conflicts through contribution analysis. The hierarchical approach first removes low-impact parameters through pruning, then iteratively resolves conflicts between remaining parameters by examining their impact on task performance. This prevents destructive interference between specialized capabilities while preserving complementary knowledge.

## Foundational Learning

**Delta Vector Merging**: The difference between fine-tuned and foundation model weights, representing learned task-specific knowledge. Why needed: Enables combining learned capabilities without full retraining. Quick check: Verify delta vectors capture meaningful task-specific modifications by comparing to original fine-tuning.

**Contribution Analysis**: Measures the impact of individual parameters on task performance through deletion/addition experiments. Why needed: Identifies which parameters contribute positively vs. conflict across tasks. Quick check: Confirm that high-contribution parameters align with known task-specific features.

**Conflict Resolution**: Iterative process to handle parameter conflicts by pruning or scaling conflicting components. Why needed: Prevents destructive interference when combining specialized models. Quick check: Verify that resolving conflicts improves merged model performance over simple averaging.

**Hierarchical Pruning**: Two-stage pruning process (model-wise then layer-wise) to reduce parameter conflicts. Why needed: Coarse pruning removes obvious conflicts before fine-grained analysis. Quick check: Confirm that hierarchical approach outperforms single-stage pruning.

## Architecture Onboarding

**Component Map**: Foundation model -> Fine-tuning (multiple datasets) -> Delta vector extraction -> Model-wise pruning/scaling -> Layer-wise contribution analysis -> Iterative conflict resolution -> Merged model

**Critical Path**: Delta extraction → Model-wise pruning → Layer-wise contribution analysis → Iterative conflict resolution → Final merge

**Design Tradeoffs**: Computational cost of iterative conflict resolution vs. performance gains; aggressive pruning reduces conflicts but may lose useful parameters; layer-wise analysis provides granularity but increases complexity

**Failure Signatures**: Degraded performance vs. single-task models indicates unresolved conflicts; high variance across runs suggests instability in contribution analysis; performance gaps between languages suggest imbalanced conflict resolution

**First Experiments**: 1) Merge two fine-tuned models on same task to verify basic functionality; 2) Merge models with known complementary capabilities to test conflict resolution; 3) Compare against simple averaging baseline to measure benefit of hierarchical approach

## Open Questions the Paper Calls Out
- Can Hi-Merging be extended to simultaneously merge more than two models without suffering from increased conflict resolution complexity or performance degradation?
- Can Hi-Merging be adapted to merge models that originate from different architectural families or distinct pre-training foundations?
- Would finer-grained conflict analysis strategies (e.g., at the neuron or attention-head level) yield superior performance compared to the current layer-wise approach?
- Is Hi-Merging effective for generative tasks (e.g., summarization, translation) and languages outside the English-Chinese pair tested?

## Limitations
- Current method only supports merging two models at a time, not multiple models simultaneously
- Effectiveness on generative tasks and languages beyond English-Chinese remains untested
- May not work directly for models from different architectural families or pre-training approaches
- Performance depends on quality of contribution analysis and conflict resolution parameters

## Confidence
- **High**: The core methodology of hierarchical iterative pruning and conflict resolution is well-defined and reproducible given the described steps
- **Medium**: The quantitative improvements are credible based on the experimental setup, but exact values depend on unreported hyperparameters and validation choices
- **Low**: Claims about relative performance vs. fine-tuned models on combined data are plausible but may vary depending on the specific merging order and fine-tuning details

## Next Checks
1. Run a fixed set of merging experiments with recorded random seeds and report both mean and variance across runs
2. Validate that the iterative conflict resolution converges to the same or similar layer-wise deltas when starting from different initial pruning/scaling choices
3. Compare merged model performance against a fine-tuned baseline trained on concatenated datasets using identical LoRA settings to confirm the reported superiority