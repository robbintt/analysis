---
ver: rpa2
title: 'CodableLLM: Automating Decompiled and Source Code Mapping for LLM Dataset
  Generation'
arxiv_id: '2507.22066'
source_url: https://arxiv.org/abs/2507.22066
tags:
- source
- code
- codablellm
- function
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CodableLLM automates the generation of high-quality datasets for
  code understanding and generation by mapping decompiled binaries to their original
  source code functions. The framework integrates parallelized function extraction,
  decompilation, and alignment processes, supporting multiple programming languages
  and extensible parsers.
---

# CodableLLM: Automating Decompiled and Source Code Mapping for LLM Dataset Generation

## Quick Facts
- arXiv ID: 2507.22066
- Source URL: https://arxiv.org/abs/2507.22066
- Reference count: 25
- Key result: Parallelized decompilation achieves ~10x speedup (514.52s → 55.93s) while generating datasets for LLM training

## Executive Summary
CodableLLM is a framework that automates the generation of high-quality datasets for code understanding and generation by mapping decompiled binaries to their original source code functions. The system integrates parallelized function extraction, decompilation, and alignment processes, supporting multiple programming languages through extensible parsers. Experiments on the libhv codebase demonstrated significant performance improvements over single-threaded approaches while producing structured datasets suitable for LLM training.

## Method Summary
The framework orchestrates a pipeline that builds source repositories, extracts functions from both source code (using Tree-sitter) and binaries (using Ghidra), and maps them based on symbol names. It uses Prefect for workflow orchestration to enable parallel execution of independent tasks. The system supports multiple programming languages through extensible extractor classes and produces structured datasets in CSV/JSON format. The primary metric evaluated is execution time, with secondary focus on the count of successfully mapped functions.

## Key Results
- Achieves nearly 10x speedup in decompilation time (514.52s → 55.93s) through parallel execution
- Successfully maps decompiled functions to source code definitions using symbol-based alignment
- Supports multiple programming languages with extensible parser architecture
- Generates structured datasets suitable for LLM training in code understanding and generation tasks

## Why This Works (Mechanism)

### Mechanism 1: Parallel Task Orchestration
- **Claim:** Parallelizing extraction and decompilation via Prefect significantly reduces dataset generation time compared to sequential execution.
- **Mechanism:** Encapsulates independent tasks (source extraction, binary decompilation) into discrete units that execute concurrently across available cores, minimizing idle time during I/O and CPU-bound operations.
- **Core assumption:** Overhead of orchestrating parallel tasks does not exceed time saved by concurrent execution, and underlying tools function correctly in multi-threaded environment.
- **Evidence anchors:**
  - Experiments demonstrated nearly 10x speedup (514.52s vs 55.93s)
  - Reduces decompilation time from 514.52 seconds to 55.93 seconds
- **Break condition:** If decompiler or parser is not thread-safe, concurrency errors or data corruption may occur.

### Mechanism 2: Symbol-Based Alignment
- **Claim:** Symbol-based alignment enables automated mapping of decompiled functions to original source code definitions.
- **Mechanism:** Compares function names (symbols) recovered from binary symbol tables during decompilation against function names extracted from source code AST, pairing matches to form dataset entries.
- **Core assumption:** Function symbols are preserved in binary (i.e., binaries are not stripped) and match naming conventions in source code exactly.
- **Evidence anchors:**
  - Framework maps decompiled binaries back to their source code
  - Involves matching function names between two domains and validating correspondence
- **Break condition:** If binaries are stripped of symbols or heavily obfuscated, name-based mapping fails.

### Mechanism 3: Extensible Parser Architecture
- **Claim:** Extensible "extractor" classes allow pipeline to adapt to languages not supported by default.
- **Mechanism:** Defines standard interface for function extraction; users can subclass interface to implement custom parsing logic for new languages, which is then registered and invoked by parallel orchestration layer.
- **Core assumption:** User can programmatically identify function definitions and signatures in target language using available parsing tools.
- **Evidence anchors:**
  - Supports multiple programming languages and extensible parsers
  - Users can implement bespoke parsers for unsupported languages and register them
- **Break condition:** If custom extractor fails to output required metadata schema, mapping stage will fail.

## Foundational Learning

- **Concept: Symbol Stripping and Binary Metadata**
  - **Why needed here:** Core mapping mechanism depends entirely on presence of symbol tables. Understanding difference between stripped and non-stripped binaries is required to diagnose mapping failures.
  - **Quick check question:** Does a "stripped" binary contain function names accessible to standard decompilers like Ghidra without heuristic recovery?

- **Concept: Abstract Syntax Trees (AST)**
  - **Why needed here:** Source code extraction relies on Tree-sitter parsing to identify functions, not just raw text processing. Understanding nodes and queries is required for extending parsers.
  - **Quick check question:** If you wanted to extract all function calls (not definitions) using Tree-sitter, would you look for "function_definition" nodes or "call_expression" nodes?

- **Concept: Workflow Orchestration (DAGs)**
  - **Why needed here:** CodableLLM uses Prefect to manage dependencies (e.g., cannot map until you have both source and decompiled functions). Understanding task ordering helps debug pipeline stalls.
  - **Quick check question:** In a Directed Acyclic Graph (DAG), can a "Mapping" task start before the "Decompilation" task finishes?

## Architecture Onboarding

- **Component map:** Configuration Layer -> High-Level API -> Low-Level API (Prefect Tasks)
- **Critical path:**
  1. Build: Compile source repository to binaries
  2. Extract (Parallel): Parse source files (Tree-sitter) and binaries (Ghidra) simultaneously
  3. Map: Join two datasets based on symbol names
  4. Export: Save to CSV/JSON
- **Design tradeoffs:**
  - Speed vs. Stability: Multi-threaded Ghidra improves speed but can introduce concurrency errors; must balance workers against decompiler stability
  - Accuracy vs. Automation: Symbol-based mapping is fully automated but brittle (fails on stripped binaries); semantic similarity would be robust but slower and more complex
- **Failure signatures:**
  - Empty Dataset / 0 Mappings: Usually indicates binary was "stripped" during compilation; check build logs for strip commands
  - Ghidra Headless Hangs: Caused by resource exhaustion when too many parallel decompilation tasks spawn on limited memory
  - Import Errors on Custom Extractors: Custom extractor class not correctly registered in entry points or configuration
- **First 3 experiments:**
  1. Baseline Run: Clone libhv repository and run full pipeline to verify ~55s decompilation time and CSV generation
  2. Stripped Binary Test: Re-compile libhv with strip command applied, then run CodableLLM to observe mapping success rate drop
  3. Custom Language Injection: Create minimal "Hello World" repository in unsupported language (e.g., Go/Rust) and write simple custom extractor class

## Open Questions the Paper Calls Out

- **Question:** How can structural similarity detection or machine learning-based approaches improve mapping accuracy for stripped or obfuscated binaries?
  - **Basis:** Future Work states advanced mapping heuristics are required to handle cases where symbol names are removed
  - **Why unresolved:** Current framework relies primarily on symbol-based mapping, which fails when binaries are heavily optimized or stripped
  - **Evidence needed:** Successful alignment rates of stripped binaries using proposed advanced heuristics compared to current symbol-based method

- **Question:** Will integrating alternative decompilers (e.g., Binary Ninja, Radare2) mitigate concurrency-related mapping errors observed with Ghidra?
  - **Basis:** Paper notes single-threaded approach yielded more mappings than parallelized one due to "concurrency-related errors in Ghidra"
  - **Why unresolved:** CodableLLM currently depends on Ghidra, which exhibits instability in multi-threaded environments
  - **Evidence needed:** Comparison of mapping consistency and error rates when running pipeline with different decompiler backends in parallel

- **Question:** To what extent do datasets generated by CodableLLM improve LLM performance on function recovery tasks compared to existing corpora?
  - **Basis:** Discussion notes evaluating LLM capabilities in function recovery using these datasets "remains an open research problem"
  - **Why unresolved:** Paper validates tool's performance (speed/mapping) but does not evaluate downstream performance of models trained on resulting data
  - **Evidence needed:** Benchmarks of LLM trained on CodableLLM datasets against models trained on standard code corpora for reverse engineering tasks

## Limitations

- Speedup claims rely on Ghidra headless mode stability in parallel execution; concurrency errors can occur but exact failure rate is not quantified
- Symbol-based mapping is only validated on non-stripped binaries; no experiments demonstrate robustness against stripped or obfuscated binaries
- Extensibility claims are theoretical; no concrete example of custom parser implementation provided beyond framework design

## Confidence

- **High:** Framework design and workflow orchestration principles are sound and well-documented
- **Medium:** Speedup measurements are plausible but contingent on stable parallel execution of Ghidra
- **Low:** Claims about extensibility and robustness to stripped binaries lack experimental validation

## Next Checks

1. Reproduce the libhv experiment to verify the ~55s decompilation time and mapping count under controlled conditions
2. Test the pipeline on a stripped binary to quantify the drop in mapping success rate
3. Implement and validate a custom extractor for a new language (e.g., Go) to confirm the extensibility interface works as documented