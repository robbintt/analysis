---
ver: rpa2
title: Merge-Friendly Post-Training Quantization for Multi-Target Domain Adaptation
arxiv_id: '2505.23651'
source_url: https://arxiv.org/abs/2505.23651
tags:
- quantization
- domain
- merging
- adaptation
- hdrq
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HDRQ (Hessian and Distance Regularizing Quantization),
  the first post-training quantization method designed for merge-friendly multi-target
  domain adaptation. HDRQ addresses the challenge that quantization-induced discretization
  disrupts model merging, which is essential for combining task-specific weights into
  a unified model.
---

# Merge-Friendly Post-Training Quantization for Multi-Target Domain Adaptation

## Quick Facts
- arXiv ID: 2505.23651
- Source URL: https://arxiv.org/abs/2505.23651
- Authors: Juncheol Shin; Minsang Seok; Seonggon Kim; Eunhyeok Park
- Reference count: 12
- Primary result: Introduces HDRQ, achieving up to 4.21 mIoU improvement in multi-target domain adaptation through merge-friendly post-training quantization

## Executive Summary
This paper introduces HDRQ (Hessian and Distance Regularizing Quantization), the first post-training quantization method designed specifically for merge-friendly multi-target domain adaptation. The key insight is that conventional quantization disrupts model merging by introducing discretization that creates sharp loss surfaces and weight misalignments. HDRQ addresses this by employing noise-based quantization to regularize the Hessian (flattening the loss surface), adding weight distance regularization to keep domain-adapted weights close to each other, and introducing noise-sampling-based rounding to resolve ambiguity during merging. Extensive experiments on semantic segmentation and image classification tasks demonstrate that HDRQ maintains single-model accuracy while significantly improving merging performance compared to conventional post-training quantization methods.

## Method Summary
HDRQ is a post-training quantization method designed for merge-friendly multi-target domain adaptation. The method employs three key techniques: (1) noise-based Hessian regularization - sampling quantization noise during training to flatten the loss surface and reduce sensitivity to perturbations; (2) weight distance regularization - minimizing L2 distance between domain-adapted weights and source weights to keep models close for merging; and (3) noise-sampling-based rounding - using sampled noise to resolve rounding ambiguity when merged integer values fall between quantization levels. The method runs for 20,000 iterations with Adam (LR=0.001) using cosine annealing with warmup, switching to fake quantization for the final 3,500 iterations. At merge time, multiple samples are generated and filtered by cosine similarity to select the best merging direction.

## Key Results
- Achieves up to 4.21 mIoU improvement in multi-target domain adaptation compared to conventional post-training quantization
- Maintains single-model accuracy while significantly improving merging performance
- Shows consistent improvements across both semantic segmentation (GTA→Cityscapes/Indian Driving Dataset) and image classification (Office-Home dataset) tasks
- Noise-based Hessian regularization contributes 1.22% improvement, distance regularization contributes 0.49% improvement

## Why This Works (Mechanism)

### Mechanism 1: Noise-Based Hessian Regularization
Injecting sampled quantization noise during training flattens the loss surface, reducing sensitivity to weight perturbations during merging. Quantization noise ϵ ~ U[-Δ/2, Δ/2] is sampled and added to weights during optimization. The expected loss E[L(w + ϵ)] ≈ E[L(w) + ½ϵ^T · ∇²L(w) · ϵ] implicitly penalizes sharp curvature since E[ϵ] = 0 eliminates first-order terms, leaving only the Hessian-weighted second-order term.

### Mechanism 2: Weight Distance Regularization
Constraining domain-adapted weights to remain close to the shared source initialization improves merge compatibility. By minimizing ||w_src - w_tar|| via L2 regularization during quantization, the upper bound on inter-domain weight divergence is reduced (triangular inequality: |w_tar1 - w_tar2| ≤ |w_src - w_tar1| + |w_src - w_tar2|). Smaller distances imply smoother interpolation paths.

### Mechanism 3: Noise-Sampling-Based Rounding for Ambiguity Resolution
Noise sampling during merging resolves rounding ambiguity when merged integer values fall between valid quantization levels. When I₁ + I₂ is odd, naive midpoint merging produces ambiguous rounding. Adding sampled noise before merging (Eq. 12) breaks ties stochastically. Cosine similarity filtering selects samples preserving interpolation direction.

## Foundational Learning

- **Error Barrier / Linear Mode Connectivity**: Understanding that low error barriers imply interpolable weights is essential for grasping why Hessian flattening improves merging. Quick check: If two models have a high error barrier, would linear interpolation between their weights likely perform well on either model's task?

- **Post-Training Quantization (PTQ) vs. Quantization-Aware Training (QAT)**: Understanding the trade-off (efficiency vs. accuracy) clarifies why merge-friendly PTQ is practically valuable. Quick check: Why would PTQ be preferred over QAT in a deployment scenario where models must be adapted to multiple user domains on-device?

- **Hessian as Loss Surface Curvature**: Understanding that large Hessian eigenvalues indicate sharp minima helps explain why noise injection improves robustness. Quick check: At a sharp minimum vs. a flat minimum, which would be more sensitive to small weight perturbations from quantization noise?

## Architecture Onboarding

- **Component map**: Source Pre-trained Model → Domain Adaptation → HDRQ Quantization → Noise-Sampling Merge → Merged Quantized Model
- **Critical path**: The quantization step (HDRQ Quantization) is where merge-friendliness is established. If Hessian regularization fails to flatten the loss surface, downstream merging degrades regardless of the merge technique.
- **Design tradeoffs**: Noise duration (20K iterations total, 3.5K final fake quant), distance regularization strength (λ=5e-2), sampling count (30 samples reported for segmentation)
- **Failure signatures**: Single-model accuracy drops (distance regularization too aggressive), merged model worse than individuals (Hessian regularization insufficient), high variance across merge samples (rounding ambiguity not resolved)
- **First 3 experiments**: (1) Ablation on noise vs. distance regularization; (2) Bit-width sweep (W8A8 → W3A3); (3) Visualization of loss surfaces comparing HDRQ vs. BRECQ vs. QDrop

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several key limitations remain: whether HDRQ generalizes to other model merging techniques beyond simple weight averaging, how it performs when source pretrained weights are unavailable for distance regularization, and the theoretical justification for specific design choices like λ=5e-2 and 3,500 final iterations.

## Limitations
- The exact block size for block-wise reconstruction is not specified, affecting reproducibility
- Noise-sampling-based rounding mechanism lacks direct empirical validation beyond cosine similarity filtering
- Distance regularization may conflict with domain-specific adaptation quality at higher learning rates
- Paper does not explore whether source-free domain adaptation scenarios would work without access to source weights

## Confidence
- **High confidence**: Experimental results showing HDRQ's superiority over baseline quantization methods in multi-target merging scenarios
- **Medium confidence**: Theoretical justification for noise-based Hessian regularization depending on noise-quantizer alignment
- **Medium confidence**: Distance regularization mechanism effectiveness varies with domain similarity and fine-tuning duration

## Next Checks
1. Replicate Figure 2 by training HDRQ vs. BRECQ/QDrop on a simple domain pair and visualizing loss surfaces along interpolation paths to confirm HDRQ converges to flatter basins
2. Test HDRQ with distance regularization disabled (λ=0) and doubled (λ=0.1) on a single domain pair to isolate its contribution
3. Compute the error barrier (Eq. 2) along interpolation paths for HDRQ vs. baseline methods to quantify merge feasibility and correlate with harmonic mean performance