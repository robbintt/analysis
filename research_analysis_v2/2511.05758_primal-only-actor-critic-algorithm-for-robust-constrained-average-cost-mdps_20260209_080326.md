---
ver: rpa2
title: Primal-Only Actor Critic Algorithm for Robust Constrained Average Cost MDPs
arxiv_id: '2511.05758'
source_url: https://arxiv.org/abs/2511.05758
tags:
- robust
- constrained
- policy
- algorithm
- average
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles robust constrained average-cost Markov Decision
  Processes (RCMDPs), where policies must perform well under worst-case transitions
  while meeting safety constraints. The main challenge is the lack of strong duality,
  which rules out standard primal-dual methods.
---

# Primal-Only Actor Critic Algorithm for Robust Constrained Average Cost MDPs

## Quick Facts
- arXiv ID: 2511.05758
- Source URL: https://arxiv.org/abs/2511.05758
- Reference count: 40
- Primary result: First primal-only actor-critic algorithm for robust constrained average-cost MDPs achieving ε-feasibility and ε-optimality with Õ(ε⁻⁴) sample complexity under slackness

## Executive Summary
This paper addresses robust constrained average-cost Markov Decision Processes (RCMDPs) where policies must minimize worst-case average cost while satisfying safety constraints under transition uncertainty. The key challenge is the lack of strong duality in robust settings, which prevents standard primal-dual methods. The authors propose a novel primal-only actor-critic algorithm that reformulates the constrained problem into a smoothed scalar objective without using Lagrange multipliers. They prove theoretical convergence guarantees with sample complexities of Õ(ε⁻⁴) under slackness assumptions and Õ(ε⁻⁶) without, which is comparable to discounted settings despite the additional complexity of average-cost problems.

## Method Summary
The algorithm solves RCMDPs by reformulating the constrained problem into a primal-only objective that simultaneously minimizes worst-case average cost and constraint violations. The actor uses subgradient descent based on the worst-case performance relative to the stationary distribution, while the critic employs a carefully designed TD algorithm that leverages a semi-norm contraction property (rather than standard norms) to estimate robust Q-functions. The critic uses Truncated Multilevel Monte Carlo (MLMC) to efficiently estimate support functions for the uncertainty sets. The method handles three types of uncertainty sets: Contamination, Total Variation (TV), and Wasserstein distance. Sample complexity scales as Õ(ε⁻⁴) when slackness exists and Õ(ε⁻⁶) without it, with the algorithm requiring only samples from the nominal transition kernel rather than the entire uncertainty set.

## Key Results
- Achieves ε-feasibility (max constraint violation ≤ ε) and ε-optimality (cost gap ≤ ε) simultaneously
- Sample complexity of Õ(ε⁻⁴) under slackness assumptions, Õ(ε⁻⁶) without slackness
- Stable convergence and constraint satisfaction demonstrated across Contamination, TV, and Wasserstein uncertainty sets
- First algorithm to solve RCMDPs in the average-cost setting with such theoretical guarantees

## Why This Works (Mechanism)

### Mechanism 1: Primal-Only Objective Formulation
The algorithm reformulates the constrained problem into $F^\pi_{\mathcal{P}} = \min_\pi \max \{ \frac{g^\pi_{\mathcal{P}}}{\lambda}, \max_i \{g^{\pi,i}_{\mathcal{P}} - b_i + \zeta\} \}$, forcing simultaneous minimization of worst-case cost and constraint violations without Lagrange multipliers. The slackness parameter $\zeta$ and trade-off coefficient $\lambda = 4/\max\{\epsilon, \zeta\}$ prevent the optimizer from ignoring constraints. If $\lambda$ is too small relative to the cost scale, the algorithm may minimize cost while ignoring constraint violations.

### Mechanism 2: Critic Stability via Semi-Norm Contraction
Standard discounted MDPs use discount factor $\gamma$ for contraction, but average-cost settings require a different approach. The critic leverages a semi-norm (from Xu et al., 2025c) where the robust Bellman operator is a contraction. It uses Truncated MLMC to estimate the support function $\sigma$, ensuring bounded value function estimates. The method assumes ergodicity (irreducible, aperiodic Markov chain) for a unique stationary distribution. If the environment is not ergodic, the average cost definition breaks down and the critic diverges.

### Mechanism 3: Subgradient Policy Update
The actor computes subgradient $\nabla F^\pi_{\mathcal{P}} \propto d^{\pi,i_{\pi_{\text{max}}}}_{\mathcal{P}} Q^{\pi,i_{\pi_{\text{max}}}}_{\mathcal{P}}$ from the worst-case stationary distribution and active Q-function. It identifies the active objective (cost or most violated constraint) and performs projected gradient descent. The method assumes bounded performance gaps under worst-case vs nominal transitions. High critic estimation error (requires $\tilde{O}(\epsilon^{-2})$ samples) creates noisy subgradients that prevent reaching the $\epsilon$-optimal neighborhood.

## Foundational Learning

**Robust Bellman Equation**: Needed because standard Q-learning fails with uncertain transition kernels. The support function $\sigma_{\mathcal{P}^a_s}(V)$ replaces expected values to handle worst-case transitions. Quick check: How does $\sigma_{\mathcal{P}^a_s}(V)$ differ from a standard expected value calculation?

**Primal vs. Primal-Dual Optimization**: Standard Constrained RL uses Lagrangians, but this paper avoids them due to lack of strong duality in robust settings. Quick check: Why does non-convexity in the robust occupancy measure prevent using Lagrange multipliers?

**Average-Cost MDPs (Gain & Bias)**: Unlike discounted settings, there's no $\gamma$ to forget long-term errors. You must understand how "relative value function" (bias) and "average cost" (gain) are separated. Quick check: Why is the average cost $g^\pi_{\mathcal{P}}$ independent of the starting state under ergodicity?

## Architecture Onboarding

**Component map**: Environment -> Critic (Algorithm 2) -> Objective Selector -> Actor -> Policy. The critic uses Truncated MLMC (Algorithm 3) for support function estimation.

**Critical path**: Actor update correctness depends entirely on critic's ability to provide $\epsilon$-accurate robust Q-function estimates. If critic sample complexity ($\tilde{O}(\epsilon^{-2})$) isn't met, the actor diverges.

**Design tradeoffs**: Slackness $\zeta$ vs sample complexity ($\tilde{O}(\epsilon^{-4})$ vs $\tilde{O}(\epsilon^{-6})$); step size $\eta = O(\epsilon)$ - larger steps speed early learning but risk instability near optimum.

**Failure signatures**: Divergent $V$ values indicate non-ergodic chain or insufficient critic iterations; oscillating constraints suggest $\lambda$ too low or $\zeta$ misspecified.

**First 3 experiments**: 1) Baseline Critic Validation on Garnet MDP to verify $\hat{g}$ convergence; 2) Constraint Satisfaction Test on Contamination Uncertainty set to confirm $\epsilon$-feasibility; 3) Ablation on Slackness comparing $\tilde{O}(\epsilon^{-4})$ vs $\tilde{O}(\epsilon^{-6})$ scaling.

## Open Questions the Paper Calls Out

None

## Limitations

- The critic's semi-norm contraction mechanism relies heavily on theoretical foundations from Xu et al. (2025c) without thorough empirical validation in the average-cost setting
- Sample complexity degrades significantly (from $\tilde{O}(\epsilon^{-4})$ to $\tilde{O}(\epsilon^{-6})$) when slackness assumptions don't hold
- No benchmark comparison against carefully implemented primal-dual baselines to quantify practical benefits
- Hyperparameter sensitivity analysis for $\lambda$ and $\zeta$ is not thoroughly explored

## Confidence

**High Confidence**: Impossibility of standard primal-dual methods due to lack of strong duality; basic primal-only algorithm structure; subgradient formulation for policy updates.

**Medium Confidence**: Sample complexity bounds; critic's ability to provide accurate Q-function estimates; semi-norm contraction mechanism effectiveness.

**Low Confidence**: Algorithm robustness to different uncertainty set geometries; practical performance gap between with/without slackness; critic stability in non-ergodic environments.

## Next Checks

1. **Semi-norm Contraction Validation**: Implement critic on simple MDP with known robust average cost and compare estimates against theoretical values under different uncertainty sets to verify semi-norm contraction empirically.

2. **Hyperparameter Sensitivity Analysis**: Systematically vary $\lambda$ and $\zeta$ across orders of magnitude while measuring constraint satisfaction and convergence speed to validate theoretical choices and identify practical operating ranges.

3. **Benchmark Comparison**: Compare primal-only approach against carefully implemented primal-dual baseline on same tasks, measuring both sample efficiency and constraint satisfaction to quantify practical benefits of avoiding Lagrange multipliers.