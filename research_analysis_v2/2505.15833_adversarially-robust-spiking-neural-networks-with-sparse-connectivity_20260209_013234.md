---
ver: rpa2
title: Adversarially Robust Spiking Neural Networks with Sparse Connectivity
arxiv_id: '2505.15833'
source_url: https://arxiv.org/abs/2505.15833
tags:
- sparse
- robust
- neural
- adversarial
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work tackles the challenge of making deep neural networks
  both adversarially robust and resource-efficient for deployment in constrained embedded
  systems. To address this, it introduces a novel algorithm that converts robustly
  pretrained artificial neural networks (ANNs) into sparse spiking neural networks
  (SNNs), leveraging the sparse connectivity and weights from adversarially trained
  and pruned ANNs.
---

# Adversarially Robust Spiking Neural Networks with Sparse Connectivity

## Quick Facts
- **arXiv ID:** 2505.15833
- **Source URL:** https://arxiv.org/abs/2505.15833
- **Reference count:** 40
- **Key outcome:** Achieves up to 100× memory reduction and 8.6× energy efficiency while maintaining adversarial robustness through ANN-to-SNN conversion with sparse connectivity inheritance

## Executive Summary
This work introduces a novel algorithm to convert adversarially robust artificial neural networks (ANNs) into sparse spiking neural networks (SNNs) that maintain both accuracy and adversarial defense. By leveraging pretrained robust ANNs with pruned sparse connectivity, the method transfers learned robust features and sparse patterns directly to SNNs. The approach includes adversarial fine-tuning of the converted SNN to further enhance robustness, achieving significant computational and memory efficiency gains while scaling to large datasets like TinyImageNet.

## Method Summary
The method consists of four main stages: (1) dense ANN pretraining using TRADES adversarial training (100 epochs with 10-step PGD), (2) robust pruning via HYDRA/HARP to optimize importance scores and create sparse connectivity masks (20 epochs), (3) ANN-to-SNN conversion with weight transfer and threshold calibration using the 99.7th percentile of pre-activations scaled by λ=0.3, and (4) SNN adversarial fine-tuning with BPTT and frozen sparsity masks (80 epochs). The conversion preserves both robust features and sparse connectivity structure, while finetuning enhances SNN-specific robustness.

## Key Results
- Achieves 100× reduction in memory usage (number of weights) through sparse connectivity transfer
- Demonstrates 8.6× improvement in energy efficiency compared to dense SNNs at 99% sparsity
- Maintains high clean accuracy (89.5% on CIFAR-10) and adversarial robustness (26.1% PGD robust accuracy)
- Outperforms end-to-end sparse training baselines across CIFAR-10/100 and TinyImageNet

## Why This Works (Mechanism)

### Mechanism 1: Robustness Transfer Through Weight and Connectivity Inheritance
The method leverages adversarially robust ANNs by directly transferring their weights and sparse connectivity patterns to SNNs. This preserves learned robust features that survived adversarial training and pruning. The core assumption is that robust representations in continuous activation space can be effectively approximated by spike rate coding when thresholds are properly calibrated. Evidence shows 21.1% vs 7.1-8.8% robust accuracy improvement over end-to-end training.

### Mechanism 2: Energy Efficiency via Connectivity Reduction Outweighing Spike Rate Increases
Sparse connectivity reduces synaptic operations more than moderate spike rate increases inflate them, yielding net energy gains. At 99% sparsity, connection reduction dominates despite ~14% spike count increase. The energy model accounts for sparse connectivity structure in accumulate operation counting. Hardware can exploit unstructured sparsity to skip accumulate operations on pruned synapses.

### Mechanism 3: Threshold Balancing via Pre-Activation Percentile Calibration
Per-layer thresholds are set to the ρ-th percentile of observed pre-activations, then scaled by λ<1, enabling balanced spike flow approximating ANN activation magnitudes. During calibration, thresholds are computed as λ times the 99.7th percentile of pre-activation distributions. This approach provides robustness to outliers and ensures proper spike flow during finetuning.

## Foundational Learning

- **TRADES Adversarial Training**: Essential for understanding the robustness-accuracy tradeoff; controls the balance between clean and robust accuracy through β parameter
- **Surrogate Gradients for BPTT**: Required for SNN finetuning since backpropagation needs gradients through non-differentiable spike functions
- **Robust Pruning with Learned Importance Scores**: Critical for preserving robust-critical weights rather than using standard magnitude pruning

## Architecture Onboarding

- **Component map**: Dense ANN TRADES training -> Robust pruning (HYDRA/HARP) -> Sparse ANN finetuning -> SNN conversion with threshold calibration -> SNN adversarial finetuning
- **Critical path**: 1) Dense ANN adversarial training (100 epochs) → robust dense weights, 2) Importance score optimization (20 epochs) → pruning masks, 3) Sparse ANN finetuning (30 epochs) → robust sparse ANN, 4) Threshold calibration + conversion → initial sparse SNN, 5) Adversarial SNN finetuning (80 epochs) with frozen masks → final model
- **Design tradeoffs**: Uniform (HYDRA) vs non-uniform (HARP) sparsity affects accuracy (22.9% vs 15.3% at 99% sparsity) and energy predictability; λ threshold scaling balances early training speed vs saturation risk
- **Failure signatures**: Robust accuracy near random at high sparsity indicates poor importance score optimization; clean accuracy collapse with stable robust accuracy suggests β too high in finetuning
- **First 3 experiments**: 1) Replicate CIFAR-10 VGG-16 at 90% uniform sparsity (89.5% clean, 26.1% robust), 2) Ablate threshold scaling λ to find optimal value, 3) Compare HYDRA vs HARP at 95-99% sparsity

## Open Questions the Paper Calls Out

### Open Question 1
Can extending this method with dynamic rewiring during SNN finetuning improve robustness-sparsity trade-offs? The current approach freezes the sparse connectivity mask; dynamic rewiring has not been explored.

### Open Question 2
Does structured sparsity in the pretrained ANN preserve adversarial robustness after SNN conversion while improving hardware efficiency? Only unstructured sparsity was evaluated; structured pruning methods were not tested.

### Open Question 3
How does this conversion approach perform on event-based neuromorphic datasets rather than static image benchmarks? All experiments use CIFAR-10/100 and TinyImageNet; no spike-based data streams were tested.

## Limitations

- The method shows significant degradation at very high sparsity levels (95-99%), with robustness collapsing to near-random performance
- Energy efficiency claims depend on idealized hardware assumptions that may not reflect real-world deployment constraints
- The robustness transfer mechanism may not generalize to more complex architectures or domains beyond standard vision tasks

## Confidence

- **High Confidence**: ANN-to-SNN conversion methodology and baseline CIFAR-10 results are well-supported and reproducible
- **Medium Confidence**: Energy efficiency claims (8.6× gain) are mathematically sound but depend on idealized hardware assumptions
- **Medium Confidence**: Robustness transfer mechanism works for standard vision tasks but may not generalize without modification

## Next Checks

1. **Energy Efficiency Validation**: Measure actual power consumption on real hardware (FPGA/ASIC) to verify the claimed 8.6× efficiency gain, accounting for sparsity-aware memory access patterns

2. **Robustness Generalization**: Test the conversion approach on non-vision tasks (e.g., speech or text) to validate whether robust feature transfer works beyond image classification

3. **Extreme Sparsity Analysis**: Systematically evaluate the 95-99% sparsity regime to understand where robustness collapse occurs and whether alternative threshold calibration strategies could maintain performance