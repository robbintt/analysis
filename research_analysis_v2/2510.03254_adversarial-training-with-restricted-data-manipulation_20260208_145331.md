---
ver: rpa2
title: Adversarial training with restricted data manipulation
arxiv_id: '2510.03254'
source_url: https://arxiv.org/abs/2510.03254
tags:
- data
- adversary
- bilevel
- classifier
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a pessimistic bilevel optimization model for
  adversarial machine learning that includes lower-level constraints to restrict how
  far an adversary can modify their data. By constraining adversarial movement using
  cosine similarity, the model prevents unrealistic data generation that could harm
  classifier performance.
---

# Adversarial training with restricted data manipulation

## Quick Facts
- arXiv ID: 2510.03254
- Source URL: https://arxiv.org/abs/2510.03254
- Reference count: 40
- Key outcome: Pessimistic bilevel optimization with cosine similarity constraints improves adversarial robustness in text classification while preventing unrealistic data manipulation

## Executive Summary
This work introduces a pessimistic bilevel optimization framework for adversarial machine learning that constrains how much an adversary can modify their data during training. The key innovation is imposing lower-level constraints based on cosine similarity to restrict adversarial movement within realistic boundaries, preventing the generation of nonsensical examples that could harm classifier generalization. The approach makes no assumptions about convexity or uniqueness of lower-level solutions, making it suitable for text-based classification tasks where semantic preservation is crucial. A non-smooth Levenberg-Marquardt algorithm solves the resulting system of equations, and numerical experiments on spam email and fake review datasets demonstrate superior performance compared to both classic classifiers and existing bilevel approaches.

## Method Summary
The method formulates adversarial training as a pessimistic bilevel optimization problem where the learner minimizes the worst-case loss over the adversary's optimal solutions. The lower-level problem is constrained by requiring that modified data points maintain cosine similarity above a threshold δ with their original versions, preventing unrealistic data generation. The upper-level learner uses logistic regression with sigmoid predictions and logistic loss, while the adversary uses logistic loss with flipped labels. The problem is solved using a non-smooth Levenberg-Marquardt algorithm that reformulates the optimality conditions using the Fischer-Burmeister function to handle complementarity conditions arising from the constraints.

## Key Results
- The constrained pessimistic bilevel model outperforms classic classifiers and existing bilevel approaches on spam email and fake review datasets
- Higher similarity thresholds (δ) lead to more consistent performance across multiple starting points due to controlled adversarial influence during training
- The model prevents generation of unrealistic data (e.g., "aaaaa" spam) that would harm classifier generalization
- Cosine similarity constraints force the adversary to find evasion strategies within realistic semantic boundaries while maintaining classification performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Constraining the adversary's modification radius using cosine similarity prevents the generation of "nonsensical" data that harms classifier generalization.
- **Mechanism:** The model introduces lower-level constraints $g(X) \leq 0$ defined by a similarity threshold $\delta$. Unlike regularisation which penalises distance, this hard constraint forces the adversary to find evasion strategies within a "realistic" semantic boundary (e.g., keeping a spam email intelligible). If the data moves outside this boundary, it is deemed invalid, forcing the optimization to find a solution that is both evasive and plausible.
- **Core assumption:** The real-world adversary is constrained by the need to preserve the semantic utility of their data (e.g., a spammer still needs the user to click a link).
- **Evidence anchors:** [Page 4] Defines the constraint $g(X) := \delta - d(X_i, X^0_i)$ to restrict movement. [Page 5] Demonstrates that while "aaaaa" minimizes loss, it fails the semantic test; constraints prevent this.
- **Break condition:** If the real adversary does *not* care about semantic similarity (e.g., random noise injection attacks), the constraint $\delta$ may artificially limit the training distribution, causing underfitting to the true threat.

### Mechanism 2
- **Claim:** Using a "pessimistic" approach (assuming the worst-case optimal attack) robustifies the classifier against multiple adversarial strategies.
- **Mechanism:** The upper-level objective minimizes a two-level value function $\phi_p(w)$ which takes the *maximum* of the learner's loss over the adversary's optimal set $S(w)$. This anticipates that if the adversary has multiple ways to evade detection, they will choose the one that maximizes damage to the learner.
- **Core assumption:** The adversary has full knowledge of the classifier and acts rationally to maximize the learner's error.
- **Evidence anchors:** [Page 4] Defines the pessimistic objective $\min_w \max_{X \in S(w)} F(w, X)$. [Page 7] Explains that $S_p(w)$ contains solutions that "do the most damage."
- **Break condition:** If the adversary is non-optimal or random (not rational), the pessimistic model may over-regularize the classifier, degrading performance on benign data.

### Mechanism 3
- **Claim:** A non-smooth Levenberg-Marquardt algorithm enables solving the problem despite non-convex constraints and non-unique lower-level solutions.
- **Mechanism:** Standard KKT-based methods fail when lower-level solutions are not unique (common with cosine similarity). This approach reformulates the necessary optimality conditions into a system of equations using the Fischer-Burmeister function (handling complementarity) and solves it via a specialized Levenberg-Marquardt iteration, effectively finding stationary points without requiring convexity.
- **Core assumption:** Stationary points found by this iterative solver correspond to locally optimal resilient classifiers.
- **Evidence anchors:** [Page 7-8] Details the reformulation into system (15) and the use of Algorithm 2. [Page 9] Describes the use of the merit function $\Psi_{FB}$ to ensure convergence.
- **Break condition:** If the problem landscape is highly irregular, the solver may stagnate (mitigated by the stopping criteria in Algorithm 2, steps 14-16) or converge to a poor local minimum.

## Foundational Learning

- **Concept:** **Bilevel Optimization**
  - **Why needed here:** The entire framework relies on viewing the problem as a hierarchical game. You must understand that the "Leader" (Learner) decides first, and the "Follower" (Adversary) reacts, creating an nested optimization loop.
  - **Quick check question:** Can you distinguish between the upper-level variable (classifier weights $w$) and the lower-level variable (data $X$), and why the lower-level solution depends on the upper-level decision?

- **Concept:** **Text Embeddings & Cosine Similarity**
  - **Why needed here:** The core constraint mechanism relies on measuring "distance" in vector space. You need to understand that Euclidean distance often fails to capture semantic similarity in high-dimensional text embeddings (like BERT), whereas cosine similarity measures the angle (alignment) between vectors.
  - **Quick check question:** Why would "bank" (river) and "bank" (finance) potentially have high cosine similarity but distinct meanings in specific contexts, and how does a hard threshold $\delta$ affect this?

- **Concept:** **Non-Smooth Optimization**
  - **Why needed here:** The solution method involves "kinks" in the mathematical landscape (complementarity conditions). Standard gradient descent assumes smooth curves; this method requires understanding sub-gradients or Newton-derivatives to handle the non-differentiability of the Fischer-Burmeister function.
  - **Quick check question:** What happens to a standard gradient descent algorithm when it hits the "kink" of a ReLU function or a constraint boundary?

## Architecture Onboarding

- **Component map:** Data Embedder -> Bilevel Solver -> Constraint Module -> Logistic Classifier

- **Critical path:**
  1. Initialize $w_0$ (often from a standard classifier) and adversary start points $X_0$.
  2. **Iterate:** Solve the system (15) using Algorithm 2.
  3. **Check:** If $\| \Phi(z, \zeta) \|$ falls below tolerance or stagnation criteria are met.
  4. **Output:** Resilient weights $w^*$.

- **Design tradeoffs:**
  - **Similarity Threshold ($\delta$):** High $\delta$ (e.g., 0.999) restricts the adversary heavily, leading to more consistent training but potentially underestimating sophisticated attacks. Low $\delta$ (e.g., 0.9) allows more freedom but risks generating unrealistic data ("over-pessimism").
  - **Adversary Sample Size ($m$):** Larger $m$ increases training influence (better robustness potentially) but increases computational cost and variance.

- **Failure signatures:**
  - **Stagnation:** The algorithm stops making progress early (triggering steps 14-16 in Algo 2), resulting in a classifier similar to the initialization.
  - **Unrealistic Data:** If $\delta$ is too low, the generated $X$ becomes noise (e.g., "aaaaa"), causing the classifier to learn nonsense features.

- **First 3 experiments:**
  1. **Baseline Comparison:** Train a classic logistic regression and the constrained bilevel model on the same split of the TREC spam dataset. Compare $P_4$ scores on future time-sliced test sets.
  2. **Hyperparameter Sensitivity ($\delta$):** Run the model with $\delta \in \{0.9, 0.99, 0.999\}$ across 100 random starting points. Plot the median and percentiles to verify that higher $\delta$ reduces variance (improves consistency).
  3. **Constraint Ablation:** Disable the cosine constraint (set $\delta = -1$) and compare performance against the constrained version to validate the contribution of restricted data manipulation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed constrained pessimistic bilevel framework be effectively extended to train deep neural networks (DNNs) rather than just logistic regression classifiers?
- Basis: [inferred] While the introduction highlights vulnerabilities in DNNs, the mathematical formulation and numerical experiments are restricted to linear classification (logistic regression).
- Why unresolved: The Levenberg-Marquardt solution method requires computing Jacobians and Hessians, which poses significant computational challenges for the high-dimensional parameter spaces typical of DNNs.
- What evidence would resolve it: A demonstration of the algorithm training a resilient DNN on a standard image or text classification benchmark within a feasible timeframe.

### Open Question 2
- Question: Is there a principled, data-driven method for determining the similarity threshold ($\delta$) without relying on computationally expensive grid search?
- Basis: [explicit] The authors state that appropriate values for $\delta$ must currently be found via hyperparameter optimization (grid search) as historical data on adversarial modifications is rarely available.
- Why unresolved: The lack of ground-truth knowledge regarding real-world adversary capabilities forces a heuristic approach to setting the constraint boundary.
- What evidence would resolve it: An algorithmic procedure or theoretical framework that approximates the optimal $\delta$ based on the statistical properties of the training data.

### Open Question 3
- Question: What are the theoretical guarantees regarding the global optimality of the solution versus the stationary points found by the non-smooth Levenberg-Marquardt algorithm?
- Basis: [inferred] The paper acknowledges that because the lower-level problem is non-convex and admits multiple solutions, the algorithm is very likely to only compute stationary points.
- Why unresolved: In non-convex bilevel programming, convergence to a stationary point does not ensure the discovery of a globally resilient classifier.
- What evidence would resolve it: A convergence analysis demonstrating that the stationary points achieved provide bounded sub-optimality relative to the global solution.

## Limitations
- The model's performance against sophisticated evasion strategies beyond cosine similarity constraints and its behavior in extremely high-dimensional embedding spaces remain untested
- The Levenberg-Marquardt approach may struggle with convergence in high-dimensional embedding spaces (512+ dimensions) without convergence proofs
- The similarity threshold $\delta$ requires computationally expensive grid search without a principled, data-driven selection method

## Confidence
- **High confidence**: The pessimistic bilevel formulation correctly models the adversarial learning problem and the constraint mechanism prevents unrealistic data generation as demonstrated in experiments
- **Medium confidence**: The non-smooth Levenberg-Marquardt solver effectively handles the complementarity conditions and finds locally optimal solutions, though convergence guarantees are limited
- **Low confidence**: The model's performance against sophisticated evasion strategies beyond cosine similarity constraints and its behavior in extremely high-dimensional embedding spaces

## Next Checks
1. **Convergence robustness test**: Run the solver with varying embedding dimensions (256, 512, 768) and track convergence rates. Compare against alternative non-smooth solvers like sequential quadratic programming
2. **Threat model generalization**: Evaluate performance against adversarial attacks that preserve semantic meaning but violate cosine similarity constraints (e.g., synonym replacement, paraphrasing)
3. **Theoretical $\delta$ selection**: Develop a principled method for choosing the similarity threshold $\delta$ based on dataset characteristics rather than grid search, potentially using validation set performance or statistical properties of the embedding space