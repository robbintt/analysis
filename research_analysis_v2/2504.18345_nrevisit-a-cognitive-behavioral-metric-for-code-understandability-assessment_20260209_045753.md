---
ver: rpa2
title: 'NRevisit: A Cognitive Behavioral Metric for Code Understandability Assessment'
arxiv_id: '2504.18345'
source_url: https://arxiv.org/abs/2504.18345
tags:
- code
- nrevisit
- cognitive
- complexity
- load
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces NRevisit, a dynamic metric that measures
  code understandability by analyzing programmers' gaze revisit patterns. Unlike static
  complexity metrics, NRevisit provides personalized, real-time assessments of cognitive
  load during code comprehension tasks, leveraging eye-tracking data to identify code
  regions requiring repeated review.
---

# NRevisit: A Cognitive Behavioral Metric for Code Understandability Assessment

## Quick Facts
- arXiv ID: 2504.18345
- Source URL: https://arxiv.org/abs/2504.18345
- Authors: Gao Hao; Haytham Hijazi; Júlio Medeiros; João Durães; Chan Tong Lam; Paulo de Carvalho; Henrique Madeira
- Reference count: 40
- Primary result: NRevisit achieves Spearman's rho up to 0.9860 correlation with EEG-measured cognitive load during code comprehension tasks.

## Executive Summary
This paper introduces NRevisit, a dynamic metric that measures code understandability by analyzing programmers' gaze revisit patterns. Unlike static complexity metrics, NRevisit provides personalized, real-time assessments of cognitive load during code comprehension tasks, leveraging eye-tracking data to identify code regions requiring repeated review. The method was validated through a controlled experiment with 35 programmers, using EEG measurements as ground truth. Results show strong correlations between NRevisit and cognitive load (Spearman's rho up to 0.9860), with regression models achieving R² values as high as 0.8595. NRevisit outperforms traditional complexity metrics and offers practical applications in AI-assisted code review, adaptive learning, and real-time IDE feedback, providing a human-centered alternative to static code complexity assessment.

## Method Summary
NRevisit measures code understandability through programmers' gaze revisit patterns captured via eye-tracking. The method partitions code into logical regions using AST-based algorithms, then tracks fixation durations and gaze transitions between regions. Two variants are computed: C NRevisit (which includes partial visits) and CL NRevisit (which requires complete exit-return cycles). The metric was validated using EEG measurements as ground truth, with 35 programmers completing Java comprehension tasks while their gaze and neural activity were recorded. Regression models (linear, neural network, and Gaussian process) were used to predict cognitive load from NRevisit scores, achieving R² values up to 0.8595.

## Key Results
- Spearman's rho correlation between NRevisit and EEG cognitive load ranges from 0.9067 to 0.9860 (p nearly 0)
- NRevisit outperforms traditional complexity metrics (V(g), HEff, HDif, CC Sonar) in predicting cognitive load
- Regression models using NRevisit achieve R² values up to 0.8595 in predicting cognitive load from gaze patterns
- Top-level region analysis shows CL NRevisit achieves highest correlation (rs = 0.9860) with EEG measurements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gaze revisit frequency correlates with cognitive load during code comprehension.
- Mechanism: When programmers encounter difficult code, they exhibit more frequent revisits to confirm understanding or perform detailed analysis. This behavior manifests as either sustained attention (multiple fixations within a region) or context-switching (exit-return cycles between regions).
- Core assumption: Revisit patterns reflect cognitive difficulty rather than unrelated factors (e.g., random eye movement, distraction).
- Evidence anchors:
  - [abstract] "Results show a very high correlation ranging from rs = 0.9067 to rs = 0.9860 (with p nearly 0) between the scores obtained with different alternatives of NRevisit and the ground truth represented by the EEG measurements of programmers' cognitive load"
  - [section 3] "A high number of revisits to a given code region indicates a need for confirmation or detailed analysis, either due to the code's intrinsic complexity or the programmer's lack of experience"
  - [corpus] Related work confirms EEG-based cognitive load classification is feasible across various tasks, but does not specifically validate revisit patterns for code comprehension
- Break condition: Revisit counts may not reflect cognitive load if programmers are fatigued, distracted by external stimuli, or if eye-tracking calibration drifts significantly.

### Mechanism 2
- Claim: Code partitioning into logical regions enables granular cognitive load localization.
- Mechanism: The AST-based partitioning algorithm identifies top-level regions (functions, methods, global declarations) and sub-regions (control flow structures). This hierarchical decomposition allows NRevisit to attribute revisits to specific code constructs.
- Core assumption: Region boundaries align with cognitive chunking patterns used by programmers.
- Evidence anchors:
  - [section 3] "The partitioning process is straightforward and based on well-defined programming constructs such as sequences, selections and iterations"
  - [section 3, Algorithm 1] Defines hierarchical region identification rules (Rule 1-5)
  - [corpus] No direct corpus evidence on AST-based region partitioning for cognitive assessment
- Break condition: Poorly defined region boundaries (e.g., overlapping regions, broken language constructs) could misattribute revisits and reduce metric accuracy.

### Mechanism 3
- Claim: Personalized assessment captures programmer-specific cognitive demands better than static metrics.
- Mechanism: NRevisit measures actual gaze behavior of individual programmers, adapting to expertise level, fatigue, and other individual factors. This bypasses the "typical programmer" assumption inherent in static metrics like Cyclomatic Complexity.
- Core assumption: Individual gaze patterns reliably indicate personal cognitive effort.
- Evidence anchors:
  - [abstract] "This approach removes the uncertainty related to the concept of a 'typical programmer' assumed by static software code complexity metrics"
  - [section 5] "Intermediate programmers exhibit more frequent and effortful revisits, leading to a higher EEG cognitive load... experts adopt a more structured reading strategy"
  - [corpus] Related work on cognitive load in VR/training contexts supports individual variability, but does not address programmer expertise differences
- Break condition: Calibration errors or hardware limitations may introduce noise that obscures individual differences.

## Foundational Learning

- Concept: **Eye-tracking fundamentals (fixation, saccade, gaze transition)**
  - Why needed here: NRevisit is computed from fixation durations and gaze transitions between code regions.
  - Quick check question: Can you distinguish a fixation from a saccade in raw eye-tracking data?

- Concept: **EEG-based cognitive load measurement**
  - Why needed here: EEG served as ground truth to validate NRevisit; understanding theta/alpha/beta band ratios helps interpret validation results.
  - Quick check question: What do theta/beta and theta/alpha ratios indicate about cognitive state?

- Concept: **Static complexity metrics (Cyclomatic Complexity, Halstead, Cognitive Complexity)**
  - Why needed here: NRevisit is positioned as an alternative to V(g), HEff, HDif, and CC Sonar; understanding their limitations clarifies the contribution.
  - Quick check question: Why does Cyclomatic Complexity fail to capture programmer-specific difficulty?

## Architecture Onboarding

- Component map:
  Code Parser -> AST generation -> Region identification (top-level + sub-regions)
  Eye Tracker (Tobii 5L or webcam) -> Raw gaze data -> Preprocessing (artifact removal, filtering, coordinate mapping)
  EEG System (64-channel) -> Raw neural signals -> Preprocessing (bandpass filtering, ICA) -> Feature extraction (EEG1, EEG2)
  NRevisit Calculator -> C NRevisit and CL NRevisit computation per region
  Synchronization Layer -> Time-stamp alignment between eye-tracking and EEG
  Regression Models (LR, NN, GPR) -> Cognitive load prediction from NRevisit features

- Critical path: Code parsing -> Region definition -> Eye-tracking capture -> NRevisit computation -> Correlation with EEG (validation) or direct use in regression models

- Design tradeoffs:
  - C NRevisit captures more fine-grained temporal information but may include noise from minor gaze shifts
  - CL NRevisit filters noise by requiring complete exit-return cycles but may miss subtle cognitive effort
  - Top-level regions reduce redundancy but may obscure sub-region-specific difficulties
  - Low-cost eye trackers (webcam) improve accessibility but reduce precision

- Failure signatures:
  - Low correlation with EEG: Check eye-tracker calibration, region boundary definitions, or presence of external distractions
  - High variance across randomizations: Insufficient data or overfitting in regression models
  - Expert/novice metrics similar: Region granularity may not match cognitive chunking for either group

- First 3 experiments:
  1. Replicate correlation analysis with your own eye-tracking hardware (even low-cost) on the provided Java tasks; verify rs > 0.85 threshold
  2. Test NRevisit on a debugging task (not just comprehension) to assess generalizability beyond the validated scenario
  3. Compare NRevisit vs. static metrics on AI-generated code snippets to evaluate the claimed application to LLM outputs

## Open Questions the Paper Calls Out
None

## Limitations
- Validation was conducted on a small sample of 35 programmers using only Java code comprehension tasks
- The method assumes gaze revisits directly reflect cognitive difficulty, which may not hold under fatigue or distraction
- AST-based region partitioning may not align with individual programmers' cognitive chunking patterns

## Confidence

- **High Confidence**: The correlation between NRevisit and EEG measurements (rs = 0.9067 to 0.9860) is well-supported by the experimental data and represents a robust finding.
- **Medium Confidence**: The superiority of NRevisit over static complexity metrics is demonstrated, but the comparison is limited to the specific experimental context and may not generalize across all scenarios.
- **Low Confidence**: The practical implementation of NRevisit in real-time IDEs and its effectiveness in AI-assisted code review scenarios are proposed but not empirically validated in those contexts.

## Next Checks
1. **Cross-language and cross-task validation**: Test NRevisit on Python, C++, and JavaScript codebases, and extend validation to debugging, refactoring, and test-writing tasks to assess generalizability.
2. **Large-scale user study**: Conduct a study with 100+ programmers of varying expertise levels and backgrounds to evaluate metric reliability across diverse populations and identify potential demographic influences.
3. **Real-time implementation test**: Integrate NRevisit into a popular IDE (e.g., VS Code) and evaluate its effectiveness in providing actionable feedback during actual development workflows, measuring both accuracy and developer productivity impact.