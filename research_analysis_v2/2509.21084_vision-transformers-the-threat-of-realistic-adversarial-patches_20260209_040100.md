---
ver: rpa2
title: 'Vision Transformers: the threat of realistic adversarial patches'
arxiv_id: '2509.21084'
source_url: https://arxiv.org/abs/2509.21084
tags:
- adversarial
- vision
- patches
- patch
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that adversarial patches designed for CNN-based
  object detectors can effectively transfer to Vision Transformer (ViT) classification
  models, with attack success rates ranging from 40.04% to 99.97% across four different
  ViT architectures. The research introduced a Creases Transformation (CT) technique
  to generate physically realistic patches with fabric-like distortions, and adapted
  the DAP framework from detection to classification tasks.
---

# Vision Transformers: the threat of realistic adversarial patches

## Quick Facts
- arXiv ID: 2509.21084
- Source URL: https://arxiv.org/abs/2509.21084
- Reference count: 35
- Primary result: Adversarial patches optimized for CNN detectors transfer to ViT classifiers with 40.04%-99.97% success rates

## Executive Summary
This study demonstrates that adversarial patches designed for CNN-based object detectors can effectively transfer to Vision Transformer (ViT) classification models, with attack success rates ranging from 40.04% to 99.97% across four different ViT architectures. The research introduced a Creases Transformation (CT) technique to generate physically realistic patches with fabric-like distortions, and adapted the DAP framework from detection to classification tasks. The findings reveal that pre-training dataset scale and methodology significantly influence model resilience, with larger ImageNet-21k training providing better robustness than ImageNet-1k. The highest vulnerability was observed in the facebook/dino-vitb16 model (99.97% ASR), while google/vit-base-patch16-224-in21k showed the most resistance (40.04% ASR). These results confirm cross-architectural transferability of adversarial patches and highlight the need for architecture-agnostic defense mechanisms in security-critical applications.

## Method Summary
The researchers developed a pipeline to evaluate adversarial patch transferability from CNN-based object detectors to Vision Transformer classifiers. They created a custom binary dataset from Microsoft COCO by filtering images with 1-3 person annotations (person class) versus images with no person annotations (non-person class). Four pre-trained ViT-B/16 models were fine-tuned on this dataset using selective layer freezing, with patch embedding and lower encoder layers frozen while training upper layers and classifier heads. The DAP framework was adapted for classification tasks and combined with a novel Creases Transformation (CT) technique that applies directional quadratic displacement fields to simulate fabric-like distortions during patch optimization. Patches were optimized using the Expectation Over Transformation (EOT) framework with rotations, scaling, and noise augmentation. The study evaluated Attack Success Rate (ASR) by applying generated patches to test images and measuring false negatives in person classification.

## Key Results
- Adversarial patches optimized on CNN detectors achieved 40.04% to 99.97% Attack Success Rate on ViT classifiers
- The facebook/dino-vitb16 model showed highest vulnerability (99.97% ASR), while google/vit-base-patch16-224-in21k showed most resistance (40.04% ASR)
- Pre-training on larger ImageNet-21k dataset significantly improved robustness compared to ImageNet-1k (40.04% vs 66.40% ASR for same architecture)
- Creases Transformation technique enabled generation of physically realistic patches with fabric-like distortions

## Why This Works (Mechanism)

### Mechanism 1: Cross-Architectural Feature Transferability
- **Claim:** Adversarial patches optimized on CNN-based object detectors can induce misclassification in Vision Transformer (ViT) architectures without direct training on the target model.
- **Mechanism:** The attack exploits shared feature sensitivities between convolutional backbones (YOLOv5) and transformer-based attention mechanisms. By optimizing a patch to disrupt spatial features universally, the perturbation generalizes across architectural boundaries, exploiting the "global representation" reliance of ViTs.
- **Core assumption:** ViTs and CNNs share sufficient underlying feature representations for localized perturbations to be effective across both.
- **Evidence anchors:**
  - [abstract] "...confirm the cross-architectural transferability of adversarial patches from CNNs to ViTs..."
  - [section 1] "...craft patches are applied on a YOLOv5-CNN baseline, further transferred to ViT-based person detectors..."
  - [corpus] The neighbor paper "Enabling Heterogeneous Adversarial Transferability via Feature Permutation Attacks" supports the general feasibility of transfer across heterogeneous architectures.
- **Break condition:** If target ViTs rely exclusively on global attention patterns that ignore the local patch region, or if defense mechanisms explicitly filter non-semantic local features.

### Mechanism 2: Physical Realism via Creases Transformation (CT)
- **Claim:** Applying geometric distortions during patch optimization creates "fabric-like" perturbations that survive physical deployment (e.g., printing on clothing).
- **Mechanism:** The Creases Transformation (CT) layer simulates natural folding by applying directional quadratic displacement fields to the patch during the Expectation Over Transformation (EOT) phase. This forces the optimizer to generate patterns robust to the non-rigid deformations inherent in worn materials.
- **Core assumption:** The simulation of creases via quadratic displacement accurately models real-world fabric distortion sufficiently to prevent "digital-only" overfitting.
- **Evidence anchors:**
  - [abstract] "...Creases Transformation (CT) technique, which adds subtle geometric distortions similar to those occurring naturally when wearing clothing."
  - [section 3.3.3] "...applies directional quadratic displacement fields to generate smooth spatial distortions, simulating realistic fabric deformations..."
  - [corpus] Explicit support for the specific "Creases" mechanism is weak or missing in the provided corpus neighbors, though "Fool the Stoplight" discusses physical realism generally.
- **Break condition:** If the CT mathematical model diverges significantly from actual fabric physics, the patch may fail when printed on specific textiles (e.g., high-stretch synthetics).

### Mechanism 3: Pre-training Scale as a Robustness Factor
- **Claim:** The scale and methodology of pre-training data significantly influence a model's vulnerability to transferred adversarial patches.
- **Mechanism:** Models pre-trained on larger, more diverse datasets (e.g., ImageNet-21k) develop richer feature manifolds that are less easily collapsed by localized perturbations compared to those trained on smaller datasets (e.g., ImageNet-1k). Self-supervised methods (like DINO) may exhibit distinct vulnerability profiles compared to supervised ones.
- **Core assumption:** Vulnerability correlates with the diversity of features learned during pre-training, rather than just the fine-tuning task.
- **Evidence anchors:**
  - [abstract] "...pre-training dataset scale and methodology significantly influence model resilience..."
  - [section 4] "...google/vit-base-patch16-224-in21k, trained on ImageNet-21k, showed substantially improved robustness (40.04% ASR) compared to its ImageNet-1k counterpart (66.40% ASR)."
  - [corpus] Weak/missing; neighbors focus on efficiency or segmentation, not pre-training scale vs. patch robustness.
- **Break condition:** If the fine-tuning dataset is sufficiently distinct or the downstream task requires overfitting to specific features that negate the pre-training robustness.

## Foundational Learning

- **Concept: Expectation Over Transformation (EOT)**
  - **Why needed here:** This is the mathematical framework used to optimize patches that must survive random rotations, scaling, and the novel Creases Transformation. Without understanding EOT, one cannot interpret the "Training Data Selection" or "Patch Training Configuration" sections.
  - **Quick check question:** How does the EOT loop ensure a patch remains effective when viewed from an angle or when the fabric wrinkles?

- **Concept: Vision Transformer (ViT) Patch Tokenization**
  - **Why needed here:** The paper attacks ViTs by placing a "physical patch" over a portion of the image. Understanding that ViTs split images into fixed-size tokens (patches) is crucial to hypothesizing why a localized cloth patch might disrupt global attention.
  - **Quick check question:** If an adversarial patch covers 30% of an image, roughly what percentage of the input token sequence is directly corrupted?

- **Concept: Transfer Learning & Layer Freezing**
  - **Why needed here:** The study fine-tunes pre-trained models using a specific strategy (freezing layers 0-7). This directly impacts the results, particularly the lower performance of `dinov3`, which the authors attribute to dataset size relative to model capacity.
  - **Quick check question:** Why did the authors freeze the patch embedding and lower encoder layers (0-7) during fine-tuning?

## Architecture Onboarding

- **Component map:** YOLOv5-CNN -> DAP Framework + Creases Transformation (CT) -> ViT-B/16 Models (Google vit-base, Facebook dino, dinov3)
- **Critical path:**
  1. **Dataset Prep:** Filter COCO train2017 for "Person" (1-3 instances) vs. "Non-Person".
  2. **Fine-Tuning:** Train ViTs on 25k images using selective layer freezing (layers 8-11 + head unfrozen).
  3. **Patch Generation:** Optimize 128x128 patches on 5k images using the DAP loss ($L_{class} + \beta L_{sim} + \gamma L_{tv}$) augmented with CT.
  4. **Evaluation:** Calculate Attack Success Rate (ASR) as false negatives on the test set.

- **Design tradeoffs:**
  - **Realism vs. Optimization Complexity:** Adding the Creases Transformation makes the attack physically plausible but increases optimization steps.
  - **Model Capacity vs. Data Scale:** The authors note `dinov3` underperformed in fine-tuning, likely because the 25k custom dataset was insufficient for its parameter count, potentially skewing robustness comparisons.

- **Failure signatures:**
  - **High Vulnerability (DINO v1):** 99.97% ASR suggests the self-supervised distillation method may propagate local perturbations too effectively.
  - **Robustness (ViT-IN21k):** Lower ASR (40.04%) indicates pre-training on large-scale data acts as a defensive shield against transferred patches.

- **First 3 experiments:**
  1. **Reproduce Baseline:** Fine-tune `google/vit-base-patch16-224` on the custom COCO split using the specified freezing strategy to verify the 99.60% accuracy baseline.
  2. **Validate Patch Transfer:** Generate a patch using the CNN surrogate and test it against the fine-tuned ViT to confirm the 66.40% ASR transferability claim.
  3. **Ablate Creases:** Run the patch optimization *without* the Creases Transformation (CT) to quantify the drop in physical realism/effectiveness (if physical testing is available) or digital robustness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effectively do the generated adversarial patches transfer to state-of-the-art real-time object detection architectures, such as Roboflow’s RF-DETR?
- Basis in paper: [explicit] The conclusion states that "further validation is required to assess the approach’s performance against detection models such as the latest real-time detection systems (e.g., Roboflow’s RF-DETR)."
- Why unresolved: The current study restricted its experimental scope to binary classification tasks using ViT-B/16 architectures, leaving the vulnerability of modern detection pipelines untested.
- What evidence would resolve it: Attack Success Rates (ASR) and mean Average Precision (mAP) metrics resulting from applying the generated patches to RF-DETR and similar detection models.

### Open Question 2
- Question: To what extent does the Creases Transformation (CT) component contribute to attack success compared to standard Expectation over Transformation (EOT) techniques?
- Basis in paper: [explicit] The authors list "investigating the role of architectural components such as the Creases Transformation" as a specific direction for future work.
- Why unresolved: While the study integrates CT into the pipeline to simulate fabric distortions, it does not isolate the performance gain provided by CT versus other transformation methods in the final results.
- What evidence would resolve it: An ablation study comparing the Attack Success Rates of patches generated with CT enabled versus patches generated using only standard EOT transformations.

### Open Question 3
- Question: What specific ViT-architectural defense mechanisms can effectively immunize models against these cross-architectural adversarial patches?
- Basis in paper: [explicit] The paper concludes that "future research should... [focus on] developing ViT-specific defense strategies that leverage the unique architectural properties of transformer models."
- Why unresolved: The research focused on quantifying vulnerability and transferability rather than developing defensive countermeasures, noting that CNN-derived defenses may be insufficient.
- What evidence would resolve it: The proposal and validation of a defense strategy (e.g., specific data augmentation or architectural modification) that significantly reduces the ASR of the patches on the tested ViT models.

### Open Question 4
- Question: How does the physical realization of these patches impact attack success rates under real-world environmental variations?
- Basis in paper: [explicit] The authors state that "future research should focus on physical world validation through comprehensive testing of printed patches under varying lighting conditions, viewing angles, and environmental factors."
- Why unresolved: The study was conducted in a digital environment; while the CT technique simulated distortions, the patches were not validated as physical objects printed on garments in real settings.
- What evidence would resolve it: Empirical results from "in-the-wild" tests where the patches are printed, applied to clothing, and tested against camera systems in diverse physical environments.

## Limitations
- The Creases Transformation mechanism lacks detailed mathematical specification, making exact reproduction challenging
- The study's physical realism claims remain theoretical since no actual printing or field testing was conducted
- Pre-training robustness claims are based on indirect comparisons rather than controlled experiments isolating pre-training effects

## Confidence
- **High Confidence:** Cross-architectural transferability of adversarial patches (ASR measurements are concrete and reproducible)
- **Medium Confidence:** Pre-training scale influences robustness (supported by comparative ASR data but lacks causal isolation)
- **Low Confidence:** Physical realism of CT patches (no empirical validation beyond simulation)

## Next Checks
1. Implement the exact CT mathematical formulation and verify whether the quadratic displacement fields produce fabric-like distortions matching the paper's visual descriptions.

2. Reproduce the complete patch generation pipeline on a subset of the dataset to confirm ASR values fall within the reported 40.04%-99.97% range across all four ViT architectures.

3. Conduct controlled ablation experiments comparing pre-training dataset scales (ImageNet-1k vs. ImageNet-21k) while holding all other variables constant to isolate the pre-training effect on adversarial robustness.