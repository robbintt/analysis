---
ver: rpa2
title: 'IMLP: An Energy-Efficient Continual Learning Method for Tabular Data Streams'
arxiv_id: '2510.04660'
source_url: https://arxiv.org/abs/2510.04660
tags:
- energy
- learning
- data
- attenmlp
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a continual learning method for tabular data
  streams. It employs an attention-based feature memory mechanism with sliding window
  updates and a lightweight MLP backbone to enable constant memory and low energy
  consumption.
---

# IMLP: An Energy-Efficient Continual Learning Method for Tabular Data Streams

## Quick Facts
- arXiv ID: 2510.04660
- Source URL: https://arxiv.org/abs/2510.04660
- Reference count: 16
- Primary result: Achieves up to 27.6× higher energy efficiency than TabNet and 85.5× higher than TabPFN on concept drift benchmarks while maintaining competitive accuracy

## Executive Summary
This paper introduces AttenMLP, a continual learning method for streaming tabular data that addresses catastrophic forgetting under strict energy and memory constraints. The method uses an attention-based feature memory mechanism with sliding window updates and a lightweight MLP backbone, achieving constant memory usage and low energy consumption suitable for edge devices. Through comprehensive experiments on River's INSECTS datasets with both abrupt and incremental concept drift, AttenMLP demonstrates significant energy efficiency gains (up to 85.5×) compared to state-of-the-art baselines while maintaining competitive accuracy.

## Method Summary
AttenMLP employs a continual learning approach for tabular data streams that combines attention-based context retrieval with a lightweight MLP backbone. The method maintains a sliding window of latent features from historical data, using scaled dot-product attention to retrieve relevant context for each new input. A two-layer MLP processes the concatenated current input and retrieved context to make predictions. Buffer strategies (FIFO, similarity-based, gated-adaptive, and FedAvg-merge) manage the sliding window to maintain constant memory usage. The model is trained sequentially across data segments with energy consumption tracked using codecarbon.

## Key Results
- AttenMLP achieves 27.6× higher energy efficiency than TabNet and 85.5× higher than TabPFN on concept drift benchmarks
- Attention mechanism improves median accuracy by 15.35% compared to non-attention baseline
- Energy per segment ranges from 0.01-4.93 kJ depending on configuration
- Fixed buffer window size (W) provides constant memory usage regardless of stream length

## Why This Works (Mechanism)

### Mechanism 1: Attention-Based Context Retrieval from Latent History
The method retrieves relevant historical context via scaled dot-product attention to mitigate catastrophic forgetting without replay buffers. Current input is projected to a query, while buffered latent features are projected to keys. Attention weights are computed and used to aggregate context, which is concatenated with the current input and fed to an MLP classifier. This assumes historical latent features retain task-relevant information that can be soft-selected via attention to stabilize learning under drift.

### Mechanism 2: Fixed-Size Sliding Window with Custom Buffer Strategies
The approach enforces O(W·d_h) memory independent of stream length by maintaining a window of W latent vectors. On new samples, different buffer strategies are applied: FIFO replaces the oldest, similarity-based removes most similar, gated-adaptive conditionally replaces, and FedAvg-merge updates prototypes via weighted averaging. This assumes a small set of representative prototypes suffices to summarize prior tasks.

### Mechanism 3: Lightweight MLP Backbone with Bounded Compute
A compact two-layer MLP with injected context provides competitive accuracy at low FLOP cost. The architecture processes concatenated [x_t; c_t] through FC1 (d_x+d_h → 512) → ReLU → FC2 (512 → d_h) → classifier. Per-sample FLOPs are bounded by O(d_x d_h + W d_h² + (d_x + d_h)·512), assuming MLPs with attention-derived context can approximate task-relevant decision boundaries without architectural expansion.

## Foundational Learning

- **Catastrophic Forgetting in Sequential Learning**: Models trained on new tasks overwrite parameters critical for old tasks. Quick check: If you train a classifier on task A then task B without replay, why does accuracy on A typically drop?

- **Scaled Dot-Product Attention (Query-Key-Value)**: Core retrieval mechanism requiring understanding of softmax normalization and √d scaling. Quick check: Write the attention formula α = softmax(QK^T / √d). What happens to gradient magnitude if d is large and you omit scaling?

- **Concept Drift Types (Abrupt vs Incremental)**: Buffer strategies perform differently; FIFO best for abrupt, gated-adaptive better for incremental. Quick check: Sketch a time-series label distribution for abrupt drift vs incremental drift. Which requires faster buffer turnover?

## Architecture Onboarding

- **Component map**: Input (d_x) + Query projection (W_q) → q_t; Latent buffer H_t (W×d_h) + Key projection (W_k) → K_t; Attention: scores s_t = K_t q_t → scaled → softmax → context c_t; Concatenation: [x_t; c_t] (d_x + d_h); MLP backbone: FC1(d_x+d_h, 512) → ReLU → FC2(512, d_h); Classifier: linear(d_h, C) → softmax

- **Critical path**: Query and key projections → attention score computation → context aggregation → MLP forward. This path determines both accuracy and energy (O(W d_h²) dominates for large d_h).

- **Design tradeoffs**: d_h: Larger improves representation but attention cost scales quadratically (d_h²). W: Larger window may add redundancy; paper shows W=1–25 with diminishing returns beyond small values. Buffer strategy: FIFO is cheapest; similarity-based and FedAvg-merge add compute but improve accuracy under some drift types. Energy scales linearly with FLOPs per device constants.

- **Failure signatures**: Accuracy collapses after drift and does not recover → buffer may be empty or attention attending to irrelevant prototypes. Energy unexpectedly high → verify W and d_h settings. Loss remains high while accuracy is moderate → check probability calibration.

- **First 3 experiments**: 1) Ablate attention on/off to confirm mechanism contribution (+15.35% median accuracy, +4.93 kJ energy). 2) Sweep W ∈ {1, 5, 10, 15, 25} with fixed d_h=1024 and plot accuracy vs energy to identify Pareto point. 3) Compare buffer strategies (FIFO, similarity, gated, FedAvg) on both abrupt and incremental drift splits to determine which lands on Pareto frontier for each drift type.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the proposed method perform on diverse real-world lifelong learning settings and standard stream datasets beyond the River's INSECTS benchmarks? The current evaluation is restricted to specific concept drift scenarios within a single benchmark suite, leaving generalizability to other domains unproven.

- **Open Question 2**: How can the community establish a standardized energy reporting system using hardware-level setups to ensure robust evaluation? The paper suggests building a standardized energy reporting system with hardware-level setup could help for more robust evaluation for EECL on tabular streams.

- **Open Question 3**: What is the performance impact of equipping state-of-the-art tabular baselines with explicit continual learning strategies? Investigating the influence of alternative CL strategies for SOTA baselines is a future direction, as current baselines are retrained per segment without specialized CL components.

## Limitations

- Parameter tuning sensitivity: Energy and accuracy Pareto points depend heavily on d_h and W choices with non-monotonic effects
- Buffer update strategy generalizability: Performance ranking of buffer strategies varies by drift type but lacks direct validation across diverse tabular streams
- Real-world energy modeling: Codecarbon estimates may not accurately reflect actual mobile/edge energy profiles

## Confidence

- **High confidence**: Attention mechanism reduces forgetting (ablation shows +15.35% accuracy); constant memory claim (O(W·d_h)); energy efficiency claims vs TabNet/TabPFN (up to 85.5×)
- **Medium confidence**: Buffer strategy effectiveness by drift type; MLP backbone adequacy for tabular streams
- **Low confidence**: Exact energy consumption on real edge devices; long-term performance on non-INSECTS datasets

## Next Checks

1. **Ablate attention on/off** on your target dataset to confirm the +15.35% median accuracy gain reported in the paper
2. **Sweep W ∈ {1, 5, 10, 15, 25}** with fixed d_h=1024 and plot accuracy vs energy to identify your Pareto-optimal window size
3. **Test all four buffer strategies** on both abrupt and incremental drift variants of your dataset to verify which strategy dominates the Pareto frontier for each drift type as claimed