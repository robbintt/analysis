---
ver: rpa2
title: 'Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based
  Detection: Clarifying Problem Formulation and Experimental Protocols'
arxiv_id: '2507.18457'
source_url: https://arxiv.org/abs/2507.18457
tags:
- adversarial
- object
- loss
- attacks
- physical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a standardized framework for physically realizable
  adversarial object attacks on LiDAR-based 3D object detection systems. The authors
  address the challenge of poor reproducibility in physical adversarial attacks by
  creating a device-agnostic framework with open-source code and evaluation protocols
  for both simulation and real-world settings.
---

# Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols

## Quick Facts
- arXiv ID: 2507.18457
- Source URL: https://arxiv.org/abs/2507.18457
- Authors: Luo Cheng; Hanwei Zhang; Lijun Zhang; Holger Hermanns
- Reference count: 11
- One-line primary result: Standardized framework for physically realizable adversarial object attacks on LiDAR-based 3D detection systems with open-source code and evaluation protocols.

## Executive Summary
This paper proposes a standardized framework for physically realizable adversarial object attacks on LiDAR-based 3D object detection systems. The authors address the challenge of poor reproducibility in physical adversarial attacks by creating a device-agnostic framework with open-source code and evaluation protocols for both simulation and real-world settings. The framework enables fair comparison across different attack methods and supports various loss functions, optimization strategies, and attack scenarios. Experimental results demonstrate that their attacks outperform existing methods on benchmark datasets, achieving significant success rates (e.g., ASR exceeding 40% on multiple detection models) while maintaining physical realizability.

## Method Summary
The framework optimizes vertex displacement vectors on an initial mesh using the Möller-Trumbore ray-triangle intersection algorithm to render adversarial objects into LiDAR point clouds. This preserves differentiability through the rendering step, enabling end-to-end gradient descent on detection loss while maintaining physical realizability constraints. The method uses iterative gradient descent with per-model step sizes and Laplacian smoothness regularization to ensure physical feasibility. Attacks are evaluated on KITTI dataset using multiple detection models (PointPillar, PointRCNN, PV-RCNN, Voxel-RCNN, SECOND) with both white-box and black-box settings.

## Key Results
- Achieves ASR exceeding 40% on multiple detection models using MR(9) logit-based loss
- Demonstrates successful transfer of attacks from simulation to physical LiDAR systems
- Shows that larger BEV projected area correlates with improved cross-model transferability
- Outperforms existing methods on benchmark datasets while maintaining physical realizability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient-based mesh optimization can produce adversarial objects that transfer from simulation to physical LiDAR systems.
- Mechanism: The framework optimizes vertex displacement vectors on an initial mesh using the Möller-Trumbore ray-triangle intersection algorithm to render adversarial objects into LiDAR point clouds. This preserves differentiability through the rendering step, enabling end-to-end gradient descent on detection loss while maintaining physical realizability constraints.
- Core assumption: Simulation environments using ray-triangle intersection adequately approximate real-world LiDAR sensing physics such that optimized meshes transfer without degradation.
- Evidence anchors:
  - [abstract] "validated by successfully transferring simulated attacks to a physical LiDAR system"
  - [section "Physically Realizable Adversarial Object"] "Möller-Trumbore intersection algorithm...computes ray-triangle intersections between LiDAR rays and the mesh faces"
  - [corpus] Related work shows physical attacks on LiDAR remain underexplored with poor reproducibility (DisorientLiDAR, 2509.12595), supporting the need for standardized frameworks.
- Break condition: If simulation-to-reality gap is larger than assumed—e.g., if real-world LiDAR sensor noise, weather, or multi-return effects differ substantially from ray-triangle intersection models—transfer performance will degrade unpredictably.

### Mechanism 2
- Claim: Logit-based comprehensive misdetection loss (Equation 9) outperforms score-based variants for cross-model transferability in LiDAR detection attacks.
- Mechanism: By using raw logits rather than sigmoid-normalized scores in the loss function, gradient signals maintain higher dynamic range during optimization. The loss jointly weights by IoU between predicted and ground-truth boxes, combining localization and classification signals without saturating gradients.
- Core assumption: Logit-based losses preserve more informative gradients than score-based losses for 3D detection, similar to transferability gains observed in 2D image attacks.
- Evidence anchors:
  - [section "Adversarial Misdetection Loss"] "Logit loss is simple yet effective for transferable adversarial attacks in images...To fill the gap, we modify (8) as L = Σ IoU(B, Bgt) · s"
  - [Table 2] MR(9) logit-based loss achieves highest ASR on multiple models (e.g., 44.26% 3D Box ASR on PP vs. 36.25% for PhyAdv baseline)
  - [corpus] Corpus does not provide comparative evidence on logit vs. score losses specifically for LiDAR; this remains a gap in prior work.
- Break condition: If target detectors use significantly different logit calibration or normalization schemes during inference, transferability gains may not hold. Additionally, if second-stage refinement in two-stage detectors introduces non-differentiable operations, gradient propagation fails.

### Mechanism 3
- Claim: Larger Bird's Eye View (BEV) projected area of adversarial meshes correlates with improved transferability across detection models.
- Mechanism: Increasing the BEV footprint of adversarial objects increases their visibility to detectors from overhead spatial encoding perspectives common in LiDAR detection architectures. This geometric property generalizes better across model architectures than specific vertex perturbations.
- Core assumption: Transferability is primarily driven by geometric visibility features (BEV area) rather than fine-grained vertex configurations that may overfit to source model quirks.
- Evidence anchors:
  - [Figure 4 description] "a larger BEV area consistently improves transferable BEV ASR"
  - [section "Transferability"] "adversarial examples generated using PP show the highest transferability...models easier to attack produce more transferable adversarial examples"
  - [corpus] Corpus evidence on BEV area and transferability is absent; no prior work is cited establishing this relationship.
- Break condition: If increasing BEV area violates physical realizability constraints (e.g., object becomes too large for realistic rooftop placement), or if target models use fundamentally different spatial encodings (e.g., voxel-free methods), the correlation may not hold.

## Foundational Learning

- Concept: **LiDAR point cloud representation and 3D object detection**
  - Why needed here: The attack framework operates on unordered 3D point sets and targets detection pipelines that produce 3D bounding boxes. Understanding how LiDAR sensors generate point clouds and how detectors process them (voxel-based vs. point-based, one-stage vs. two-stage) is essential for formulating effective losses.
  - Quick check question: Given a point cloud P and detector f, what does f(P) produce, and how does this differ between one-stage and two-stage architectures?

- Concept: **Differentiable rendering for 3D meshes**
  - Why needed here: The framework requires gradient flow from detection loss back through mesh vertices. Ray-triangle intersection must be differentiable w.r.t. mesh parameters for gradient descent to update vertex positions.
  - Quick check question: Why can't standard mesh rendering pipelines be used directly for adversarial mesh optimization, and what property does the Möller-Trumbore algorithm provide?

- Concept: **Physical realizability constraints in adversarial ML**
  - Why needed here: Not all optimized meshes can be manufactured or placed in physical environments. Constraints like surface smoothness, size limits, and structural integrity must be enforced during optimization, typically via reparameterization or soft constraints in the loss.
  - Quick check question: What is the difference between enforcing physical feasibility via reparameterization versus via penalty terms in the loss function?

## Architecture Onboarding

- Component map: Mesh Initialization -> LiDAR Renderer -> Detection Loss -> Physical Constraint -> Optimizer Loop
- Critical path: Input point cloud → Mesh integration (G function) → Detector forward pass → Loss computation → Gradient w.r.t. ∆vi → Mesh update → Physical constraint check → Repeat until convergence
- Design tradeoffs:
  - Higher sphere level ν increases mesh expressiveness but raises optimization complexity
  - Stronger Laplacian weight λ improves physical smoothness but may constrain attack effectiveness
  - White-box setting provides better attack performance; black-box uses surrogate models with selective updates only when target loss decreases
  - Logit-based losses (Equation 9) may improve transferability but require access to unnormalized detector outputs
- Failure signatures:
  - ASR near 0%: Likely incorrect mesh placement, loss formulation mismatch with detector architecture, or broken gradient flow through renderer
  - Mesh fails physical realizability check: λ too low or box constraints violated; increase smoothness penalty or tighten reparameterization bounds
  - Good white-box ASR but near-zero transferability: Mesh overfitting to source model; try increasing BEV area or using logit-based loss
  - Second-stage loss ineffective for two-stage detectors: Prediction score saturates near 1.0; use Stage-1 loss or comprehensive loss (Equation 8)
- First 3 experiments:
  1. Reproduce baseline comparison: Run PhyAdv baseline vs. MR(9) loss on PointPillar with KITTI dataset, comparing 3D Box ASR. Verify your framework matches reported ~44% ASR before proceeding.
  2. Ablate sphere level and scale: Test ν ∈ {0, 1, 2, 3} and scale b ∈ {0.6, 0.7, 0.8, 1.0} on a single model (e.g., PointRCNN) to characterize sensitivity before full benchmarking.
  3. Validate simulation-to-reality transfer: Generate adversarial mesh using KITTI data, 3D print the object, and test on physical LiDAR setup (if available) or at minimum verify in CarLA simulation across multiple scenarios (CutIn, FLV, OFLV) with and without noise.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can physically realizable constraints be formulated to better capture 3D object plausibility while remaining differentiable for gradient-based optimization?
- Basis in paper: [explicit] The authors state that "commonly used constraints such as bounding box limits and surface smoothness (e.g., via Laplacian loss) do not adequately capture physical feasibility."
- Why unresolved: Current constraints like Laplacian smoothness are coarse proxies that don't ensure realistic 3D geometry, but enforcing more realistic constraints while maintaining gradient flow is non-trivial.
- What evidence would resolve it: Demonstration of a differentiable constraint function that produces meshes rated as physically plausible by human evaluators or 3D object classifiers while enabling successful gradient-based optimization.

### Open Question 2
- Question: How does LiDAR reflectivity/intensity information affect adversarial object attack effectiveness, and can it be leveraged in optimization?
- Basis in paper: [explicit] The paper identifies reflectivity as "underexplored" and notes that "models trained on different datasets may learn inconsistent reflectivity patterns."
- Why unresolved: The paper neutralizes reflectivity by setting it to zero across all points to isolate geometric effects, leaving the role of intensity cues unexamined.
- What evidence would resolve it: Systematic experiments comparing attack success rates with and without reflectivity optimization, across multiple LiDAR sensors with different intensity distributions.

### Open Question 3
- Question: Can loss formulations incorporating richer features beyond IoU, logits, and classification probabilities improve attack effectiveness?
- Basis in paper: [explicit] The authors state "we believe improved loss formulations incorporating richer features could further enhance attack effectiveness" and note current designs "rely only on coarse metrics."
- Why unresolved: The paper explores various loss formulations but finds "no clear optimal choice," suggesting better formulations may exist.
- What evidence would resolve it: Development and empirical validation of a loss function utilizing intermediate network features (e.g., proposal features, ROI pooled representations) that achieves higher ASR than existing formulations.

## Limitations

- Simulation-to-reality transfer gaps may be larger than assumed, with real-world sensor noise and environmental factors potentially degrading attack effectiveness
- Effectiveness of logit-based losses specifically for LiDAR detection transferability lacks direct comparative evidence in the corpus
- Correlation between BEV area and transferability is stated but not empirically validated against existing literature

## Confidence

- High confidence: The standardized framework's ability to enable fair comparison across attack methods and its open-source implementation
- Medium confidence: The correlation between BEV area and transferability, as this relationship is stated but not empirically validated against existing literature
- Medium confidence: Simulation-to-reality transfer claims, given successful physical validation but unknown simulation gap magnitude

## Next Checks

1. Perform ablation studies on the logit vs. score loss variants specifically for LiDAR detection to verify transferability improvements
2. Conduct extensive domain randomization tests varying sensor noise parameters to quantify simulation-to-reality transfer robustness
3. Test attack transferability across different LiDAR sensor configurations (resolution, range, return count) to establish framework generality