---
ver: rpa2
title: 'Dataset distillation for memorized data: Soft labels can leak held-out teacher
  knowledge'
arxiv_id: '2506.14457'
source_url: https://arxiv.org/abs/2506.14457
tags:
- teacher
- accs
- student
- data
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates whether knowledge distillation can transfer
  memorized information, not just generalizable structure. It examines scenarios where
  teachers have memorized data (either structured or random) and students are trained
  on soft labels.
---

# Dataset distillation for memorized data: Soft labels can leak held-out teacher knowledge

## Quick Facts
- **arXiv ID:** 2506.14457
- **Source URL:** https://arxiv.org/abs/2506.14457
- **Authors:** Freya Behrens; Lenka Zdeborová
- **Reference count:** 40
- **Primary result:** Soft labels from a teacher trained on memorized data can leak information about held-out memorized samples, achieving non-trivial to perfect accuracy without generalization.

## Executive Summary
This study investigates whether knowledge distillation can transfer memorized information rather than just generalizable structure. The authors examine scenarios where teachers have memorized data (either structured or random) and students are trained on temperature-scaled soft labels. Surprisingly, students can achieve non-trivial accuracy on held-out memorized data they never saw, with performance depending strongly on the softmax temperature. The work distinguishes between regimes where students merely memorize soft labels versus functionally match the teacher, revealing fundamental limits on information transfer in distillation.

## Method Summary
The paper investigates knowledge distillation on datasets where teachers have memorized their training data (achieving 100% accuracy). The teacher's output logits are converted to soft labels using temperature-scaled softmax, and students are trained on a subset of this data. The key innovation is examining student performance on held-out memorized data from the teacher's training set, measuring whether soft labels can leak information beyond the student's training distribution. Experiments span synthetic random data, modular addition, and logistic regression models, with systematic variation of temperature, sample complexity, and architecture.

## Key Results
- Students can achieve non-trivial accuracy (up to 100%) on held-out memorized data they never saw during training
- Temperature scaling creates a non-monotonic relationship: intermediate temperatures enable leakage while extremes suppress it
- Two distinct regimes exist: soft label memorization (weak held-out generalization) and functional matching (perfect held-out accuracy)
- The transition between regimes occurs at identifiable sample complexity thresholds related to model dimensionality

## Why This Works (Mechanism)

### Mechanism 1: Temperature-Controlled Information Encoding in Soft Labels
The softmax temperature τ controls a regularizing interpolation between class-only recovery and teacher function recovery. At low τ → 0, soft labels collapse to one-hot encodings (destroying teacher-specific information). At τ → ∞, soft labels become uniform (destroying both label and teacher information). Intermediate τ values encode relational information between classes that reflects the teacher's internal representation.

### Mechanism 2: Identifiability Threshold for Teacher Function Recovery
When sufficient soft label samples are available relative to model dimensionality, students can recover the teacher functionally rather than merely memorizing labels. For linear models, this occurs when the input matrix becomes invertible (αS_id = 1/ρ). At this threshold, the student can solve for the teacher weights via pseudo-inverse, enabling perfect prediction on all inputs including held-out memorized data.

### Mechanism 3: Two-Phase Learning in Nonlinear Networks (Soft Label Memorization → Functional Matching)
In ReLU MLPs, students can exist in two distinct weight configurations: one that memorizes soft labels with weak held-out generalization, and one that functionally matches the teacher with perfect held-out accuracy. Training dynamics show a sudden jump in accuracy after extended training time. Before the jump, students achieve non-trivial test accuracy via statistical patterns in soft labels. After the jump (when teacher becomes identifiable), students transition to matching the teacher function exactly.

## Foundational Learning

- **Cross-entropy loss with temperature scaling**: Why needed here: The paper's core intervention is modifying soft label generation via softmax temperature; understanding how τ affects gradient magnitude and class probability distributions is essential. Quick check: What happens to the gradient signal for a logit z_k when τ increases from 1 to 10?

- **Memorization vs. generalization in overparameterized networks**: Why needed here: The paper isolates memorization by using random labels; distinguishing capacity-driven memorization from structure-based generalization is foundational to interpreting results. Quick check: If a network achieves 100% training accuracy on random labels but 1/c test accuracy, what does this indicate about its learning?

- **Identifiability in linear systems**: Why needed here: The theoretical thresholds (αS_id, αT_label) derive from linear algebra conditions for unique solution recovery; grasping when a system is under/over-determined clarifies phase boundaries. Quick check: Given n samples and d dimensions, when is the least-squares solution W = (X^T X)^{-1} X^T y uniquely defined?

## Architecture Onboarding

- **Component map**: Teacher network -> Soft label generator (softmax with temperature τ) -> Student network -> Evaluation on DS_train, DS_test, Dval splits

- **Critical path**:
  1. Verify teacher achieves ~100% accuracy on DT^⋆ before distillation
  2. Generate soft labels with target τ (start with τ ∈ {0.1, 1.0, 10.0})
  3. Partition DT^⋆ into DS_train/DS_test at ratio ρ
  4. Train student to convergence on soft label cross-entropy
  5. Evaluate on all three splits to distinguish leakage type

- **Design tradeoffs**:
  - High τ (e.g., 10-20): More teacher function information, higher data efficiency, but student inherits teacher's failure to generalize if teacher hasn't discovered structure
  - Low τ (e.g., 0.1): Less teacher dependence, student may independently generalize if sufficient data, but slower convergence
  - Student capacity matching: Matched capacity enables functional recovery; mismatched capacity affects which regime dominates

- **Failure signatures**:
  - Student achieves ~1/c accuracy on DS_test: No leakage (τ too low or insufficient ρ)
  - Student achieves 100% on DS_train but ~1/c on DS_test: Soft label memorization without functional recovery (α < 1/ρ)
  - Student accuracy drops mid-training then recovers: Transition from memorization to functional matching (normal for ReLU MLPs)

- **First 3 experiments**:
  1. Reproduce Figure 1 (2D visualization): Train teacher on 2D random data with 3 classes, generate soft labels at τ=20, train student on 60% split. Verify student achieves ~50% test accuracy vs. ~30% baseline.
  2. Temperature sweep: Fix ρ=0.6, vary τ ∈ {0.1, 1, 5, 10, 20}, plot accS_test vs. τ. Confirm non-monotonic relationship with peak at intermediate τ.
  3. Sample complexity threshold: For logistic regression with d=100, vary n to find αS_id empirically. Confirm student achieves perfect test accuracy when n/d ≥ 1/ρ.

## Open Questions the Paper Calls Out

- **Can memorized information leakage be prevented to ensure privacy during knowledge distillation?** The authors note this is important for privacy reasons but don't develop defense mechanisms.

- **Do the identified leakage regimes and capacity thresholds apply to deeper architectures and natural data distributions?** Experiments were restricted to synthetic data and shallow models.

- **How does the common practice of using only top-k soft label values affect the transfer of memorized information?** The study used full soft label vectors; impact of truncation was not quantified.

- **What are the theoretical thresholds for fitting structure and memorized data jointly during distillation?** The paper analyzes pure memorization and structured data in isolation, not their theoretical interplay.

## Limitations

- Results primarily demonstrate on synthetic random data and simple architectures; applicability to real-world deep networks remains unclear
- The distinction between functional matching and alternative equivalent solutions lacks theoretical guarantees
- Conditions triggering the sudden jump to perfect accuracy in nonlinear networks are poorly characterized
- Privacy implications are noted but no defense mechanisms are proposed

## Confidence

- **High confidence:** The core empirical finding that soft labels can leak held-out memorized information is well-supported by multiple experiments across different architectures and temperatures
- **Medium confidence:** The distinction between soft label memorization and functional matching regimes is empirically observed but theoretically underspecified
- **Low confidence:** The claim that students "functionally match" the teacher rather than finding alternative equivalent solutions lacks theoretical guarantees

## Next Checks

1. **Solution uniqueness verification:** After achieving perfect held-out accuracy, perturb the student weights slightly and verify whether accuracy degrades to test whether the student has found a unique functional mapping or merely an equivalent solution basin.

2. **Cross-architecture transferability:** Train a teacher in architecture A, generate soft labels, then train students in architectures B, C, and D. Measure whether perfect held-out accuracy transfers across architectures, which would strengthen the functional matching interpretation.

3. **Sample efficiency quantification:** Systematically vary the teacher training set size while holding student training set size constant. Measure the minimum teacher memorization accuracy required for the student to achieve non-trivial held-out leakage, establishing the information bottleneck precisely.