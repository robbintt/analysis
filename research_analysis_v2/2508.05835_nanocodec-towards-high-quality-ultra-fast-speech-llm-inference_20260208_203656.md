---
ver: rpa2
title: 'NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference'
arxiv_id: '2508.05835'
source_url: https://arxiv.org/abs/2508.05835
tags:
- audio
- kbps
- speech
- codec
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NanoCodec is a state-of-the-art audio codec that achieves high-quality
  compression at just 12.5 frames per second (FPS), outperforming existing codecs
  across various bitrates. The core method introduces a partially causal decoder,
  architectural improvements (including non-causal convolutions with dilation rates
  of 1, 3, and 5), and a speaker consistency loss for enhanced speaker similarity.
---

# NanoCodec: Towards High-Quality Ultra Fast Speech LLM Inference

## Quick Facts
- **arXiv ID:** 2508.05835
- **Source URL:** https://arxiv.org/abs/2508.05835
- **Reference count:** 0
- **Primary result:** Achieves state-of-the-art audio codec performance at 12.5 FPS with 4.441 SQMOS and 2.760 PESQ at 1.78 kbps, enabling 2.33× faster Speech LLM inference

## Executive Summary
NanoCodec is a neural audio codec designed specifically for efficient Speech LLM inference, achieving high-quality compression at just 12.5 frames per second. The codec introduces a partially causal architecture that balances quality and latency, achieving 4.441 SQMOS and 2.760 PESQ at 1.78 kbps while reducing real-time factor by 2.33× compared to baseline codecs. The core innovation combines a non-causal encoder with causal decoder, architectural improvements including dilated convolutions, and a speaker consistency loss for enhanced speaker similarity in downstream applications.

## Method Summary
NanoCodec employs a partially causal architecture where a non-causal convolutional encoder processes raw waveforms using dilated convolutions (rates 1, 3, 5) and strided downsampling to achieve 12.5 FPS. The encoder outputs are discretized using Finite Scalar Quantization (FSQ) with 8 codebooks. A causal decoder based on HiFi-GAN architecture with transposed convolutions reconstructs the audio. The training combines GAN loss with feature matching and a speaker consistency loss, using multi-scale discriminators including WavLM-based and multi-period variants. The model is trained for 196k steps on multilingual data using 48 A100 GPUs.

## Key Results
- Achieves 4.441 SQMOS and 2.760 PESQ at 1.78 kbps and 12.5 FPS, outperforming prior codecs
- Reduces real-time factor by 2.33× and inference latency by 2.5× for downstream Speech LLM (Koel-TTS)
- Maintains speaker similarity (SECS 0.782) comparable to 21.5 FPS baseline while enabling faster inference

## Why This Works (Mechanism)
NanoCodec's performance gains stem from its partially causal architecture that optimizes the tradeoff between reconstruction quality and inference speed. The non-causal encoder can leverage future context for better compression, while the causal decoder ensures streaming capability without lookahead delays. The reduced frame rate (12.5 FPS vs 21.5 FPS) decreases the number of sequential steps required for autoregressive LLM inference, directly improving real-time performance. The speaker consistency loss ensures that compressed representations preserve speaker identity, which is critical for downstream TTS applications where speaker similarity directly impacts perceived quality.

## Foundational Learning
- **Concept: Autoregressive vs. Non-Autoregressive Generation**
  - Why needed here: The core benefit of NanoCodec's low frame rate is that it reduces the number of sequential steps for autoregressive LLMs. Understanding this dependency is critical.
  - Quick check question: If the Koel-TTS model were non-autoregressive (generating all tokens in parallel), would a 12.5 FPS codec still offer a ~2.33× real-time factor speedup? (Answer: No, the speedup would be minimal as parallel generation is not bound by sequential steps).

- **Concept: Causality in Neural Networks**
  - Why needed here: The paper introduces a "partially causal" architecture to solve the latency/quality tradeoff. Grasping what a causal vs. non-causal layer is helps understand why the decoder and encoder can be configured differently.
  - Quick check question: Why does a non-causal convolution in an encoder force a system to buffer data before it can process the first sample? (Answer: Because a non-causal layer's output at time `t` depends on future input values `t+n`).

- **Concept: Finite Scalar Quantization (FSQ)**
  - Why needed here: The paper uses FSQ, not the more common RVQ. FSQ projects latents into a constrained space with a small number of indices, which is a different discretization paradigm.
  - Quick check question: How does FSQ differ from Residual Vector Quantization (RVQ) in its approach to creating discrete audio tokens? (Answer: RVQ iteratively quantizes the residual error from a previous codebook, while FSQ projects the latent into a multi-dimensional space where each dimension is independently rounded to a set of levels).

## Architecture Onboarding
- **Component map:** Raw waveform -> Non-causal encoder (dilated conv + strided downsampling) -> FSQ quantizer (8 codebooks) -> Causal decoder (HiFi-GAN style) -> Reconstructed audio
- **Critical path:** The partially causal configuration (Non-Causal Encoder → FSQ → Causal Decoder) provides the optimal balance, as fully causal encoders severely degrade intelligibility (CER increases from 2.423 to 5.490 at 1.1 kbps).
- **Design tradeoffs:**
  - Frame Rate vs. Intelligibility: 12.5 FPS is safe, but 6.25 FPS degrades intelligibility severely (CER >5.0)
  - Bitrate vs. Downstream Performance: Higher bitrate (1.78 kbps) preserves quality better but makes token distribution more complex for LLM
  - Causality vs. Quality: Fully non-causal is superior in quality but unsuitable for streaming due to buffering delays
- **Failure signatures:**
  - High CER on reconstruction: Model is likely at too low frame rate (6.25 FPS) or too low bitrate (0.6 kbps)
  - Low Speaker Similarity (SECS) in downstream TTS: Codec may lack SCL or downstream LLM lacks sufficient context
  - High TTFA: Decoder was accidentally configured as non-causal
- **First 3 experiments:**
  1. Causality Ablation Reproduction: Train three variants (Fully Causal, Partially Causal, Non-Causal) to validate trade-offs
  2. Frame Rate Impact on Downstream LLM: Train Koel-TTS at 21.5 FPS vs 12.5 FPS to confirm speed/quality tradeoff
  3. Speaker Consistency Loss (SCL) Ablation: Train two codecs (with/without SCL) to verify impact on SECS and downstream TTS quality

## Open Questions the Paper Calls Out
- **Open Question 1:** What specific architectural modifications to Speech LLMs are required to recover the loss in speaker similarity observed when using 12.5 FPS codecs compared to 21.5 FPS?
- **Open Question 2:** Does the improved intelligibility (CER) at 12.5 FPS stem primarily from easier alignment learning between phoneme inputs and codec tokens, and can this benefit be decoupled from the loss in speaker similarity?
- **Open Question 3:** Is there a critical "intelligibility floor" in codec reconstruction (measured by CER) below which downstream Speech LLM performance collapses, regardless of bitrate simplicity?

## Limitations
- Comparative evaluation limited to single downstream LLM (Koel-TTS) and single speaker consistency baseline (Clova encoder)
- Training pipeline requires substantial computational resources (48 A100 GPUs for 196k steps)
- Speaker Consistency Loss ablation lacks statistical significance testing

## Confidence
- **High Confidence:** State-of-the-art perceptual quality (SQMOS 4.441, PESQ 2.760) at 1.78 kbps and 12.5 FPS; partially causal architecture provides verifiable quality-latency tradeoff; real-time factor improvement (2.33×) and inference latency reduction (2.5×) for Koel-TTS
- **Medium Confidence:** Downstream TTS quality (speaker similarity SECS 0.782) directly attributable to Speaker Consistency Loss; 2.5× inference latency improvement assumes autoregressive LLM
- **Low Confidence:** Claim of being "first codec designed specifically for LLM inference" difficult to verify; focus on Speech LLM inference may overstate generalizability to other architectures

## Next Checks
1. Causality Ablation Reproduction: Train three NanoCodec variants (Fully Causal, Partially Causal, Non-Causal) on small dataset to validate quality-intelligibility tradeoffs
2. Downstream LLM Frame Rate Impact: Train scaled-down Koel-TTS using 1.78 kbps NanoCodec at 21.5 FPS vs 12.5 FPS to confirm speed/quality tradeoff
3. Speaker Consistency Loss (SCL) Ablation: Train two identical codecs (with/without SCL) and measure SECS on reconstruction and downstream TTS speaker similarity