---
ver: rpa2
title: Projection-based Adversarial Attack using Physics-in-the-Loop Optimization
  for Monocular Depth Estimation
arxiv_id: '2512.24792'
source_url: https://arxiv.org/abs/2512.24792
tags:
- depth
- adversarial
- target
- object
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a projection-based adversarial attack method\
  \ that, under black-box conditions, generates perturbation light projected onto\
  \ a target object surface to attack monocular depth estimation (MDE) models. The\
  \ proposed method employs physics-in-the-loop (PITL) optimization to account for\
  \ various physical factors\u2014including projector and camera distortions, ambient\
  \ light, and noise\u2014thus enabling the design of effective perturbation patterns\
  \ for target scenes."
---

# Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation

## Quick Facts
- arXiv ID: 2512.24792
- Source URL: https://arxiv.org/abs/2512.24792
- Reference count: 11
- Primary result: Physics-in-the-loop optimization with sep-CMA-ES achieved presence rate e=0.0425 for some objects, causing near-complete disappearance from depth maps

## Executive Summary
This paper introduces a projection-based adversarial attack method that generates perturbation light patterns to deceive monocular depth estimation models. The approach uses physics-in-the-loop (PITL) optimization, projecting candidate perturbations onto physical objects and evaluating them through real camera capture rather than simulation. This addresses the sim-to-real gap that plagues simulation-based methods. The method employs separable covariance matrix adaptation evolution strategy (sep-CMA-ES) to efficiently explore high-dimensional perturbation spaces without gradient access to the victim model.

## Method Summary
The method projects optimized RGB perturbation patterns onto target object surfaces to cause depth estimation errors. sep-CMA-ES samples perturbation patterns δ from a multivariate Gaussian distribution, which are then projected onto the physical scene via a calibrated projector. A camera captures the illuminated scene, and the victim MDE model produces an estimated depth map. The fitness function measures L1 distance between the estimated and target depth maps. The optimization iterates for 800-1700 generations, adapting the sampling distribution based on fitness-ranked candidates. PITL optimization incorporates physical factors like device distortions, ambient light, and sensor noise directly into the fitness evaluation.

## Key Results
- Sep-CMA-ES with PITL achieved presence rate e=0.2057 in real-world settings, outperforming MOEA/D's e=0.7512
- Simulation-optimized perturbations degraded significantly in real deployment (e=0.2883→0.9303), demonstrating the sim-to-real gap
- Object disappearance attacks achieved e=0.0425 for some objects, with others showing blurred object-background boundaries
- The method successfully attacked two different MDE models: Laina et al. [9] and Depth Anything v2 [11]

## Why This Works (Mechanism)

### Mechanism 1
Physics-in-the-loop optimization produces adversarial perturbations that transfer from optimization to deployment better than simulation-based approaches by incorporating device distortions, ambient light, surface reflectance, and sensor noise directly into the fitness landscape. Break condition: Significant environmental changes during optimization invalidate fitness comparisons across generations.

### Mechanism 2
Sep-CMA-ES enables versatile, high-dimensional perturbation design without gradient access by sampling from a multivariate Gaussian distribution that adapts its covariance matrix across generations. The separable approximation reduces computational complexity, making high-dimensional RGB perturbation patterns tractable. Break condition: High-dimensional search space with deceptive local optima could cause premature convergence.

### Mechanism 3
Brightness-only perturbations can induce object disappearance by disrupting depth boundary cues that MDE models rely on for depth estimation. The optimized patterns blur object-background boundaries, causing the model to interpolate depth values incorrectly. Break condition: Objects with strong depth-from-stereo cues or motion parallax availability may resist this attack vector.

## Foundational Learning

- **Covariance Matrix Adaptation Evolution Strategy (CMA-ES)**: Understanding how sep-CMA-ES explores high-dimensional perturbation space without gradients is essential for debugging convergence issues and tuning population parameters. Quick check: If sep-CMA-ES converges prematurely to a suboptimal perturbation, which parameter would you adjust first—step size σ, population size λ, or the covariance matrix adaptation rate?

- **Monocular Depth Estimation (MDE) failure modes**: Effective adversarial attack design requires understanding what visual cues MDE models depend on (texture gradients, object boundaries, relative size) and how they can be disrupted. Quick check: Why might an MDE model estimate incorrect depth when object-background boundaries are blurred by projected light patterns?

- **Sim-to-real gap in adversarial attacks**: PITL optimization directly addresses this gap; understanding its sources (sensor noise, illumination, calibration errors) clarifies why simulation-based methods underperform. Quick check: List three physical factors that differ between a rendered simulation and a real projector-camera setup that could cause adversarial perturbation effectiveness to degrade.

## Architecture Onboarding

- **Component map**: Perturbation generator (sep-CMA-ES core) -> Physical projection loop -> Victim MDE model -> Fitness evaluator -> Covariance updater
- **Critical path**: Perturbation sampling → Physical projection → Image capture → MDE inference → Fitness evaluation → Distribution update
- **Design tradeoffs**: Population size λ vs. optimization speed; perturbation magnitude vs. imperceptibility; target region R size vs. search dimensionality
- **Failure signatures**: Presence rate e stagnating above 0.8 indicates insufficient generations or inadequate population size; high variance suggests multimodal fitness landscape; effective in simulation but not real world indicates projector-camera calibration issues
- **First 3 experiments**: 1) Baseline reproduction: Replicate sep-CMA-ES vs. MOEA/D comparison on different MDE model; 2) Perturbation budget analysis: Vary maximum RGB intensity to quantify minimum required for attacks; 3) Cross-object transferability: Test whether perturbations optimized for one object transfer to different objects

## Open Questions the Paper Calls Out
None

## Limitations
- Perturbation pattern resolution and region R size are not specified, making exact reproduction difficult
- Projector-camera synchronization and calibration details are incomplete, potentially affecting sim-to-real transfer performance
- The relationship between perturbation magnitude and attack effectiveness across different objects is not quantified

## Confidence

**Major uncertainties:**
- Exact perturbation pattern resolution and region R definition unknown
- Projector-camera synchronization timing and preprocessing details incomplete
- Exact sep-CMA-ES hyperparameters beyond σ and λ unclear

**Confidence labels:**
- High confidence in PITL optimization improving sim-to-real transfer (supported by direct experimental comparison)
- Medium confidence in sep-CMA-ES superiority over MOEA/D (limited to single experimental setup)
- Medium confidence in brightness-only perturbations causing object disappearance (mechanism plausible but not fully explained)

## Next Checks

1. Reproduce Experiment 1 (sep-CMA-ES vs. MOEA/D) on a different MDE model to validate optimizer superiority claims across architectures
2. Conduct perturbation magnitude sensitivity analysis by systematically varying maximum RGB intensity to quantify the minimum perturbation required for successful attacks
3. Test cross-object transferability by applying perturbations optimized for one object to different objects in the same scene to validate scene-specificity assumptions