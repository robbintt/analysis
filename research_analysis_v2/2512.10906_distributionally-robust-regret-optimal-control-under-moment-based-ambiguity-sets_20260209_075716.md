---
ver: rpa2
title: Distributionally Robust Regret Optimal Control Under Moment-Based Ambiguity
  Sets
arxiv_id: '2512.10906'
source_url: https://arxiv.org/abs/2512.10906
tags:
- control
- problem
- optimal
- regret
- robust
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the design of control policies for linear-quadratic
  stochastic systems where the disturbance distribution is unknown but belongs to
  an ambiguity set defined by norm bounds on mean and covariance. The core method
  proposes minimizing worst-case expected regret over all distributions in this set,
  reformulated as a tractable convex program.
---

# Distributionally Robust Regret Optimal Control Under Moment-Based Ambiguity Sets

## Quick Facts
- arXiv ID: 2512.10906
- Source URL: https://arxiv.org/abs/2512.10906
- Reference count: 40
- This paper proposes a distributionally robust regret optimal control framework using moment-based ambiguity sets, showing improved performance over existing data-driven methods through tractable convex reformulation and scalable dual subgradient optimization.

## Executive Summary
This paper addresses the design of control policies for linear-quadratic stochastic systems where the disturbance distribution is unknown but belongs to an ambiguity set defined by norm bounds on mean and covariance. The core method proposes minimizing worst-case expected regret over all distributions in this set, reformulated as a tractable convex program. The paper introduces a dual projected subgradient algorithm to solve this efficiently, avoiding the scalability issues of standard semidefinite program solvers. Numerical experiments on a double integrator system show that the proposed distributionally robust regret optimal controllers outperform other data-driven methods, achieving lower expected cost and ex-ante regret across various disturbance correlations when the ambiguity set parameters are tuned appropriately.

## Method Summary
The method formulates a minimax distributionally robust regret optimization problem where the control policy minimizes worst-case expected regret over an ambiguity set defined by Euclidean-norm bounds on mean and Schatten-p-norm bounds on covariance deviations. The nonconvex inner maximization over mean is resolved via closed-form solution, while the covariance term yields a Schatten-norm regularization, resulting in a convex regularized LQ problem. A dual projected subgradient algorithm is proposed, which alternates between solving an inner equality-constrained LQ minimization over control policies and projecting the dual variable onto the constraint set using eigendecomposition and ℓ_p-ball projections. The algorithm converges with diminishing or adaptive step sizes and provides theoretical guarantees for the duality gap.

## Key Results
- The distributionally robust regret optimal controller achieves lower expected cost and ex-ante regret than SAA and WASS-REGRET across various disturbance correlations when ambiguity set parameters are tuned appropriately
- The dual projected subgradient method scales to larger horizons (T=200) with computational times under 8 seconds, compared to over 16 minutes for SDP solvers
- SPEC-REGRET controller matches OPT-CAUSAL performance at optimal radius, demonstrating reduced conservatism compared to worst-case cost minimization approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Minimizing worst-case expected regret over a moment-based ambiguity set reduces conservatism relative to worst-case expected cost minimization while maintaining robustness to distributional uncertainty.
- **Mechanism:** The regret objective measures excess cost relative to a noncausal clairvoyant controller, which serves as a dynamic baseline. By minimizing the worst-case expected deviation from this baseline (rather than worst-case absolute cost), the optimization is less pessimistic because the baseline adapts to the realized disturbance.
- **Core assumption:** The ambiguity set (defined by norm bounds on mean and covariance) contains the true disturbance distribution; the optimal noncausal controller $u^o(w)$ exists and is unique.
- **Evidence anchors:**
  - [abstract]: "The core method proposes minimizing worst-case expected regret over all distributions in this set... outperforming other data-driven methods... when the ambiguity set parameters are tuned appropriately."
  - [section 2.1, Eq. 6-9]: Regret defined as $R(u,w) = J(u,w) - J(u^o(w), w)$; distributionally robust problem formulated in Eq. 7.
  - [corpus]: "Wasserstein Distributionally Robust Regret Optimization" (arXiv:2504.10796) addresses conservatism in DRO via regret; aligns conceptually but uses Wasserstein sets.
- **Break condition:** If the true distribution lies outside the ambiguity set (e.g., higher-order moments deviate significantly), the robustness guarantee degrades; if the noncausal baseline is not computable or the system is nonlinear, the reformulation may not hold.

### Mechanism 2
- **Claim:** The minimax distributionally robust regret problem admits a tractable convex reformulation as a regularized stochastic LQ problem.
- **Mechanism:** Using the ambiguity set structure (norm-bounded mean and covariance) and the quadratic form of regret, the inner worst-case expectation decomposes into separate maximizations over mean and covariance. Lemma 1 resolves the nonconvex mean maximization via a closed-form solution; the covariance term yields a Schatten-norm regularization. The resulting problem (Theorem 2, Eq. 14) is convex in the feedback gain $K$.
- **Core assumption:** Affine disturbance-feedback policies are optimal or sufficiently expressive; the cost matrices $Q \succeq 0$, $R \succ 0$; the Schatten-$p$ norm bound on covariance deviation is known.
- **Evidence anchors:**
  - [abstract]: "The resulting minimax optimal control problem is shown to admit an equivalent reformulation as a tractable convex program that corresponds to a regularized version of the nominal linear-quadratic stochastic control problem."
  - [section 3, Theorem 2, Eq. 14]: $K^\star \in \arg\min_{K \in L} \{ \text{Tr}(\hat{\Sigma} C(K)) + r_1 \|C(K)\|_\infty + r_2 \|C(K)\|_q \}$.
  - [corpus]: "Iterative Sampling Methods for Sinkhorn Distributionally Robust Optimization" (arXiv:2512.12550) addresses tractability in DRO but with Sinkhorn discrepancy; no direct overlap with this Schatten-norm regularization approach.
- **Break condition:** If policies are restricted beyond affine (e.g., nonlinear), convexity may be lost; if $D$ is not positive definite or the system is unstable without control, numerical issues may arise.

### Mechanism 3
- **Claim:** A dual projected subgradient method scales to larger horizons than primal-dual interior-point SDP solvers by avoiding second-order updates.
- **Mechanism:** Strong duality holds (Sion's minimax theorem). The dual function $g(\Lambda)$ is concave with computable subgradients via an inner convex LQ minimization over $K$ (Theorem 3). Projected subgradient ascent on the dual, with projection onto Schatten-norm balls via eigendecomposition and $\ell_p$-ball projections, converges with diminishing or adaptive step sizes.
- **Core assumption:** The sequence of subgradients is bounded; step-size rules satisfy standard nonsummable diminishing conditions; eigendecompositions are affordable ($O(n^3)$ but cheaper than SDP for moderate $n$).
- **Evidence anchors:**
  - [abstract]: "The paper introduces a dual projected subgradient algorithm to solve this efficiently, avoiding the scalability issues of standard semidefinite program solvers."
  - [section 4.2, Eq. 17-18]: Iterates defined as $K^i \in \arg\min_{K \in L} \text{Tr}(G(K)^\top \Lambda^i)$, $\Lambda^{i+1} = \Pi_{\mathcal{C}}(\Lambda^i + \eta_i G(K^i))$.
  - [Appendix D, Figure 2(b)]: "For example, at $T=80$, the interior-point method takes over 16 minutes on average, whereas the projected subgradient method converges in under eight seconds on average."
  - [corpus]: No directly comparable scalable dual method for moment-based DRO control in neighbors; corpus evidence on this specific algorithm is weak.
- **Break condition:** For very high-dimensional states ($n_x$ large), eigendecomposition may become prohibitive; if the dual function is non-smooth (ambiguous when $\hat{\Sigma} \not\succ 0$), convergence may be slow; poor step-size choices may stall progress.

## Foundational Learning

- **Concept: Distributionally Robust Optimization (DRO)**
  - **Why needed here:** The paper builds on DRO principles to handle unknown disturbance distributions; understanding ambiguity sets, moment bounds, and worst-case expectations is essential to grasp the problem formulation.
  - **Quick check question:** Can you explain how a moment-based ambiguity set differs from a Wasserstein-based set in terms of robustness guarantees and tractability?

- **Concept: Regret in Control (Causal vs. Noncausal Baseline)**
  - **Why needed here:** The core objective is worst-case expected regret; the noncausal controller provides a dynamic baseline that adapts to realized disturbances, reducing conservatism.
  - **Quick check question:** Why does minimizing worst-case regret reduce conservatism compared to minimizing worst-case cost in a stochastic setting?

- **Concept: Dual Projected Subgradient Methods**
  - **Why needed here:** The main algorithmic contribution is a scalable dual method; understanding subgradients, projections onto norm balls, and convergence criteria is necessary for implementation.
  - **Quick check question:** What is the role of the projection step in the dual subgradient method, and why is it necessary for feasibility?

## Architecture Onboarding

- **Component map:**
  - *System model*: Linear time-varying dynamics with known $(A_t, B_t)$ and unknown disturbance distribution (Eq. 1)
  - *Ambiguity set*: Euclidean-norm ball on mean, Schatten-$p$-norm ball on covariance (Eq. 10)
  - *Control policy*: Causal affine disturbance-feedback, $\phi(w) = Kw + v$ (Eq. 4-5)
  - *Regret objective*: Excess cost vs. noncausal clairvoyant controller (Eq. 6-9)
  - *Convex reformulation*: Regularized LQ problem (Theorem 2, Eq. 14)
  - *Solver*: Dual projected subgradient method with inner LQ solves and Schatten-norm ball projections (Algorithm 1)

- **Critical path:**
  1. Construct nominal $(\hat{\mu}, \hat{\Sigma})$ from data (sample mean/covariance)
  2. Set ambiguity radii $(r_1, r_2)$ and Schatten order $p$ (tune via cross-validation)
  3. Initialize dual variable $\Lambda^0 = (0, \hat{\Sigma})$
  4. At each iteration: (a) solve inner LQ problem for $K^i$, (b) compute subgradient $G(K^i) = (C(K^i), C(K^i))$, (c) project onto $\mathcal{C}$ via eigendecomposition
  5. Monitor relative duality gap (Eq. 31) for stopping
  6. Deploy optimal policy $\phi^\star(w) = K^\star(w - \hat{\mu}) + K^o \hat{\mu}$

- **Design tradeoffs:**
  - *Schatten-$p$ choice*: $p=1$ (nuclear norm) yields spectral-norm regularization; $p=\infty$ (spectral norm) yields nuclear-norm regularization (akin to classical LQR as $r_2 \to \infty$)
  - *Radius tuning*: Small radii reduce robustness but improve nominal performance; large radii increase conservatism (Figure 1(a))
  - *Algorithm*: Subgradient methods scale better but may require more iterations than interior-point for small problems; adaptive step sizes can accelerate convergence

- **Failure signatures:**
  - *Duality gap not decreasing*: Step size too large/optimization ill-conditioned; check $\hat{\Sigma} \succ 0$ and reduce step size
  - *Controller too conservative*: Ambiguity radii too large; retune via cross-validation
  - *Numerical instability in projection*: Eigendecomposition fails due to near-singular matrices; regularize $\hat{\Sigma}$

- **First 3 experiments:**
  1. *Baseline comparison*: Replicate double integrator experiment (Section 5) with $\rho=0$; compare SPEC-REGRET, FROB-REGRET, NUC-REGRET against SAA and WASS-REGRET. Plot expected cost vs. radius and confirm SPEC-REGRET matches OPT-CAUSAL at optimal radius.
  2. *Scalability test*: Vary horizon $T \in \{10, 50, 100, 150, 200\}$; compare wall-clock time of dual subgradient method vs. SDP solver (replicate Figure 2(b)). Verify linear-quadratic scaling.
  3. *Correlation sensitivity*: Sweep $\rho \in [-1, 1]$; evaluate expected cost and ex-ante regret for each controller at its optimal radius. Confirm SPEC/FROB-REGRET maintain low regret across $\rho$ while WASS-COST over-conservatism emerges (Figure 1(b,c)).

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the ambiguity set radii ($r_1, r_2$) be selected optimally in a data-driven manner without access to the ground-truth distribution?
  - **Basis in paper:** Explicit. Section 5.2 notes that while optimal radii improve performance, "the optimal radius cannot be computed in practice, since the ground-truth distribution is unknown" and suggests holdout methods as an approximation.
  - **Why unresolved:** The paper treats the radii as hyperparameters tuned via grid search over a validation set rather than integrating their selection into the optimization problem with theoretical guarantees.
  - **Evidence would resolve it:** An algorithm that provides finite-sample guarantees for radius selection or adapts the radii online based on observed regret.

- **Open Question 2:** Can the tractable convex reformulation be extended to the partially observed setting where the system state is not directly measurable?
  - **Basis in paper:** Inferred. Section 2 explicitly assumes "the system state is perfectly observed," while the Introduction notes that similar Wasserstein-based frameworks have been extended to partial observability, suggesting a gap for the moment-based approach.
  - **Why unresolved:** The dual subgradient method relies on a disturbance-feedback parameterization which presumes knowledge of the disturbance history, which is generally unavailable without full state observation.
  - **Evidence would resolve it:** A derivation of a convex program for output-feedback policies or an observer-based separation principle compatible with moment-based ambiguity sets.

- **Open Question 3:** Does the restriction to causal affine control policies incur a loss of optimality in the minimax expected regret sense?
  - **Basis in paper:** Inferred. Section 2 states the focus on "causal affine control policies" to ensure convexity, but does not prove that this class contains the global minimax solution for all distributions in the ambiguity set.
  - **Why unresolved:** While affine policies are optimal for the nominal Linear-Quadratic problem, the interaction between non-Gaussian distributions (implied by the ambiguity set) and the worst-case objective may necessitate non-linear policies.
  - **Evidence would resolve it:** A proof establishing the optimality of affine policies within the broader class of causal non-linear policies for this specific regret metric.

## Limitations

- The method's performance depends critically on accurate estimation of nominal mean and covariance from finite data, with estimation errors directly impacting robustness guarantees
- The computational advantage of the dual subgradient method may diminish for high-dimensional state spaces where eigendecompositions become expensive
- The cross-validation procedure for tuning ambiguity radii is critical but not fully specified, leaving implementation details ambiguous

## Confidence

**High Confidence**: The convex reformulation (Theorem 2) and dual subgradient algorithm (Algorithm 1) are well-supported by the mathematical derivations and numerical experiments. The comparison against SAA and WASS-REGRET in Section 5 provides strong empirical validation for the regret-minimizing approach.

**Medium Confidence**: The scalability claims relative to SDP solvers are convincing for the tested range (T≤200) but require further validation for larger-scale problems. The robustness guarantees under moment ambiguity are theoretically sound but sensitive to the accuracy of nominal parameter estimates.

**Low Confidence**: The cross-validation procedure for ambiguity radii, while mentioned, lacks specific implementation details. The exact performance degradation when the true distribution lies outside the ambiguity set is not quantified beyond general statements about conservatism.

## Next Checks

1. **Cross-validation sensitivity analysis**: Systematically vary holdout ratios and selection criteria in the radius tuning procedure; measure impact on out-of-sample performance across different ρ values.

2. **Distribution mismatch study**: Evaluate controller performance when true disturbance statistics deviate from nominal estimates (e.g., mean shift, covariance inflation); quantify the breakdown of robustness guarantees.

3. **High-dimensional scaling experiment**: Test the dual subgradient method on systems with larger state dimensions (n_x > 10) and longer horizons (T > 200); measure computational time and solution quality relative to SDP baselines where feasible.