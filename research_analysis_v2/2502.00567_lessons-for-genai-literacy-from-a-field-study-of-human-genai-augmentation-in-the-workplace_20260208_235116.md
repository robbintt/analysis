---
ver: rpa2
title: Lessons for GenAI Literacy From a Field Study of Human-GenAI Augmentation in
  the Workplace
arxiv_id: '2502.00567'
source_url: https://arxiv.org/abs/2502.00567
tags:
- genai
- they
- work
- also
- project
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This field study examined how generative AI (GenAI) is being used\
  \ to augment work practices across three industries\u2014product development, software\
  \ engineering, and digital content creation\u2014to inform workforce and educational\
  \ strategies. Researchers conducted in-depth interviews with 10 professionals, analyzing\
  \ the ways GenAI is integrated into tasks and the varying levels of technical expertise\
  \ required."
---

# Lessons for GenAI Literacy From a Field Study of Human-GenAI Augmentation in the Workplace

## Quick Facts
- arXiv ID: 2502.00567
- Source URL: https://arxiv.org/abs/2502.00567
- Reference count: 40
- Key outcome: Field study reveals wide variance in GenAI use across roles, highlighting need for tailored AI education and faculty development to prepare students for evolving workplace environments.

## Executive Summary
This field study examined how generative AI (GenAI) augments work practices across three industries—product development, software engineering, and digital content creation. Through interviews with 10 professionals, researchers found significant variation in GenAI use patterns and required technical knowledge levels. The study revealed that technical expertise enables more sophisticated GenAI integration, while novices require expert-designed scaffolding to succeed. Findings also highlighted industry-specific ethical concerns and the importance of tailored AI literacy training for different professional contexts.

## Method Summary
Researchers conducted in-depth interviews with 10 professionals across three organizations in India, generating approximately 6 hours of recordings and 32,000 words of transcripts. The study used ethnographically-informed semi-structured interviews and iterative thematic analysis grounded in Almatrafi et al.'s AI literacy framework (Recognize, Know/Understand, Use/Apply, Evaluate, Create, Navigate Ethically). Participants were purposively sampled based on their direct GenAI experience, with some interviewed multiple times and group interviews used to capture nuanced work practices.

## Key Results
- Wide variance exists in GenAI use patterns, from highly technical applications (fine-tuning models) to simple off-the-shelf tools for content generation
- Literacy levels vary significantly across roles, with technical teams showing higher evaluation capabilities than content teams
- Industry-specific ethical concerns differ (privacy in technical/software vs. IP in content creation)
- Novices can accomplish complex tasks with GenAI only when expert-designed scaffolding provides architectural guardrails

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GenAI augmentation effectiveness depends on task-expertise alignment, where higher-technical work requires deeper foundational knowledge of ML/algorithms
- Mechanism: Technical users leveraged prior ML/data mining expertise to fine-tune models and call APIs, while non-technical users relied on trial-and-error with off-the-shelf tools
- Core assumption: Prior domain knowledge enables more sophisticated GenAI integration patterns
- Evidence anchors: Findings show wide variance in GenAI use and computing knowledge levels; Project Concept participants had extensive ML experience enabling model fine-tuning
- Break condition: If tasks require cultural/creative nuance, technical expertise alone is insufficient

### Mechanism 2
- Claim: Novices can accomplish complex tasks with GenAI when expert-designed scaffolding provides architectural guardrails
- Mechanism: Junior developers used Co-Pilot to write code in unfamiliar languages only because detailed software design existed
- Core assumption: GenAI lowers entry barriers but does not replace architectural knowledge
- Evidence anchors: Project Code required detailed software design for augmentation to work; participants worried about future architects if novices aren't trained on higher-level tasks
- Break condition: When working with novel tools/drivers not in GenAI training data, novices may accept incorrect outputs without recognizing gaps

### Mechanism 3
- Claim: Literacy constructs vary by role; ethical concerns (privacy vs. IP) differ by industry context
- Mechanism: Project Concept worried about data privacy with client information; Project Content worried about copyright/IP and creative originality
- Core assumption: Ethical navigation is context-dependent, not universal
- Evidence anchors: Literacy ratings show varying levels across Recognize to Navigate Ethically; ethics concerns differ by industry context
- Break condition: If ethical frameworks are taught generically without domain-specific scenarios, learners may not transfer appropriately

## Foundational Learning

- Concept: **Prompt engineering as query formulation**
  - Why needed here: All three project types used prompting, but effectiveness varied with domain knowledge
  - Quick check question: Can you explain why the same prompt might yield different utility for a software developer vs. a content creator?

- Concept: **Model limitations (stability, outdated knowledge, training data gaps)**
  - Why needed here: Project Concept noted model output stability issues; Project Code noted novel tools might not be in GenAI knowledge base
  - Quick check question: What would you check before trusting GenAI output for a task involving a recently-released library?

- Concept: **Evaluation and critical assessment**
  - Why needed here: Technical teams could evaluate GenAI applicability systematically; content team could only evaluate through trial-and-error
  - Quick check question: How would you assess whether GenAI output is safe to use in a client-facing deliverable?

## Architecture Onboarding

- Component map: Input layer (prompt engineering, context provision, data privacy) -> Processing layer (model selection, IDE integration) -> Output layer (evaluation, iteration, integration) -> Governance layer (ethical navigation)

- Critical path:
  1. Identify task type (creative, technical, hybrid)
  2. Assess required literacy level (Recognize → Navigate Ethically)
  3. Match tool sophistication to user expertise
  4. Establish evaluation protocols before deployment
  5. Build feedback loops for course correction

- Design tradeoffs:
  - Fine-tuned models vs. off-the-shelf: Higher capability but higher cost and infrastructure needs
  - Automation vs. augmentation: Software development showed more automation potential; content creation remained augmentation-focused
  - Access equity: Prohibitive costs create inequity in who can develop advanced GenAI skills

- Failure signatures:
  - Novices accepting outdated GenAI output without verification
  - Privacy/IP violations from sharing proprietary data with public models
  - Creative homogenization (GenAI gave the same output to everyone)
  - Over-reliance leading to skill atrophy

- First 3 experiments:
  1. Map your team's current GenAI use against the six literacy constructs. Identify gaps.
  2. Test a workflow where a novice uses GenAI with and without expert-provided architectural scaffolding. Compare output quality and error rates.
  3. Document ethical concerns specific to your domain. Create scenario-based guidelines rather than generic policies.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the integration of AI agents shift the boundary between task augmentation and full automation in professional workflows?
- Basis in paper: The authors state that future work needs to dive deeper into automation versus augmentation given recent developments in AI agent design and use.
- Why unresolved: The current study focused on augmentation, but participants expressed concern that automation might replace junior roles, creating a gap in future expertise.
- Evidence: Longitudinal studies tracking the ratio of automated versus augmented tasks in software development and content creation teams.

### Open Question 2
- Question: What specific GenAI skills must be acquired through formal education versus those that can be reliably learned on the job?
- Basis in paper: The authors ask what is unique about GenAI use that students need to learn during studies compared to what they can easily learn on the job.
- Why unresolved: The study identified a spectrum of technical literacy needs but did not determine which skills are foundational for students versus specific to professional contexts.
- Evidence: Comparative analysis of novice worker performance based on prior formal GenAI training versus workplace-only learning.

### Open Question 3
- Question: How can findings regarding professional GenAI practices be effectively translated into higher education curriculum and pedagogy?
- Basis in paper: The paper states that research is needed to translate professional workplace findings into curriculum and pedagogy for higher education.
- Why unresolved: While the study documents how professionals use GenAI, it does not define specific pedagogical models to teach these practices effectively to students.
- Evidence: Educational interventions designed around observed professional workflows, followed by assessments of student readiness for the workforce.

### Open Question 4
- Question: To what extent do sustainability and environmental concerns influence the adoption and use of GenAI among professionals?
- Basis in paper: The authors note that despite high energy usage, there was no mention of sustainability, environmental, and social justice concerns by participants.
- Why unresolved: Participants focused primarily on utility, cost, and privacy, potentially ignoring broader ethical or environmental externalities.
- Evidence: Follow-up interviews or surveys specifically probing professionals' awareness and decision-making regarding environmental costs.

## Limitations
- Small sample size (10 participants across 3 organizations) limits generalizability
- Convenience sampling approach may introduce selection bias
- Subjective literacy ratings lack inter-rater reliability documentation
- Limited diversity in participant backgrounds and organizational contexts

## Confidence
**High Confidence**: Claims about varying GenAI literacy levels across technical, software, and content roles; importance of architectural scaffolding for novice success; and industry-specific ethical concerns are well-supported by direct participant quotes.

**Medium Confidence**: The mechanism linking domain expertise to sophisticated GenAI integration patterns is plausible but could be confounded by organizational support differences. The automation vs. augmentation distinction needs broader testing.

**Low Confidence**: Generalizability of specific literacy construct ratings across different industries and cultural contexts remains uncertain due to sampling limitations.

## Next Checks
1. Replicate with stratified sampling: Recruit 30+ participants across 6+ industries, ensuring representation of different organizational sizes, cultural contexts, and experience levels. Compare literacy patterns against current findings.

2. Test scaffolding effectiveness experimentally: Conduct a controlled study where novices use GenAI for software development with and without expert-provided architectural designs. Measure error rates, completion times, and knowledge transfer to independent work.

3. Validate ethical framework transferability: Apply the privacy/IP distinction framework to three new industries (healthcare, finance, education). Document whether ethical concerns follow similar patterns or require entirely new categorization approaches.