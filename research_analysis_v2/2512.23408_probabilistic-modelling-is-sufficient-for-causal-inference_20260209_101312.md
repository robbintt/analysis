---
ver: rpa2
title: Probabilistic Modelling is Sufficient for Causal Inference
arxiv_id: '2512.23408'
source_url: https://arxiv.org/abs/2512.23408
tags:
- causal
- distribution
- inference
- observed
- probabilistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper argues that probabilistic modelling and inference are
  sufficient for answering causal inference questions, without requiring specialised
  causal frameworks. The authors demonstrate through concrete examples (aspirin effectiveness
  on headache duration) that causal questions can be addressed by writing down the
  joint probability distribution over all relevant variables and settings of interest.
---

# Probabilistic Modelling is Sufficient for Causal Inference

## Quick Facts
- **arXiv ID:** 2512.23408
- **Source URL:** https://arxiv.org/abs/2512.23408
- **Reference count:** 40
- **Primary result:** Probabilistic modelling and inference alone are sufficient for causal inference, without requiring specialized causal frameworks like do-calculus or Structural Causal Models.

## Executive Summary
This paper argues that causal inference questions can be fully addressed through standard probabilistic modelling and inference, without requiring specialized causal frameworks. The authors demonstrate this through concrete examples showing how interventional and counterfactual questions can be answered by writing down joint probability distributions over observed and hypothetical settings, using standard Bayesian Networks and probabilistic conditioning. They contend that apparent disagreements about causal versus statistical inference stem from semantic confusion and overly restrictive definitions of "statistical" that limit it to observational settings. The proposed unified probabilistic framework aims to make causal inference more accessible to the machine learning community while maintaining flexibility to handle complex problems beyond traditional causal graphical models.

## Method Summary
The approach constructs a "twin" probabilistic model that spans both observed and hypothetical (interventional or counterfactual) worlds. For interventional queries, this involves defining a joint distribution over observed variables (Z, T, Y) and their intervened counterparts (Z*, T*, Y*), with shared parameters ensuring consistency. The intervention is implemented by modifying the graph structure in the hypothetical branch and setting the distribution of the intervened variable. For counterfactual queries, latent variables (confounders or noise terms) are shared between observed and counterfactual branches, allowing Bayesian conditioning to perform the "abduction" step traditionally handled separately in causal frameworks. The entire approach relies on standard probabilistic conditioning rather than specialized causal operators.

## Key Results
- Interventional queries can be answered by constructing joint distributions over observed and intervened worlds without using the do-operator
- Counterfactual inference can be achieved through shared latent variables and standard Bayesian conditioning
- Causal tools like do-calculus and Structural Causal Models can be viewed as syntactic sugar for defining specific types of joint distributions
- The approach handles Simpson's paradox correction through proper modelling of the joint intervention distribution

## Why This Works (Mechanism)

### Mechanism 1: Joint Modelling over "Twin" Worlds
The system constructs a single joint probability distribution spanning observed and hypothetical settings. By defining variables for both worlds (Z, T, Y and Z*, T*, Y*) coupled via shared parameters Θ, interventions are represented by modifying graph structure and variable distributions rather than using mathematical operators. The core assumption is that outcome distributions are invariant between worlds (pθ(y|t, z) = qθ(y*|t*, z*)). This mechanism fails if the treatment-outcome relationship fundamentally changes under intervention.

### Mechanism 2: Counterfactuals via Shared Latent Identities
Counterfactual inference is achieved by sharing latent variables between observed and counterfactual branches. The system infers posterior distributions of shared latents given observed data, then propagates these beliefs to predict counterfactual outcomes. This unifies the "abduction" step into standard Bayesian conditioning. The core assumption is that exogenous noise variables are consistent across potential worlds for specific units. The mechanism yields different results than SCMs if practitioners choose not to share specific noise variables that SCMs would mandate sharing.

### Mechanism 3: Causal Syntax as Syntactic Sugar
Specialized causal tools are not mathematically necessary but serve as efficient notation for defining specific joint distributions. Applying interventions to Bayesian Networks is formally equivalent to modifying factorization of joint probability density. Therefore, do-calculus rules can be viewed as derived algebraic shortcuts rather than axioms of separate causal logic. The core assumption is that all causal assumptions can be encoded in probabilistic graphical model structure and conditional distributions.

## Foundational Learning

- **Concept: Bayesian Networks & Factorization**
  - **Why needed here:** The approach relies on expressing causal assumptions as DAGs and deriving joint probability p(x) = ∏ p(xi | parentsi)
  - **Quick check question:** Given a graph A → B ← C, write the factorization of the joint distribution P(A, B, C).

- **Concept: Conditional Independence vs. Causality**
  - **Why needed here:** The paper argues that naïve probabilistic conditioning P(Y|T) fails for causal questions due to confounding; one must distinguish association from intervention
  - **Quick check question:** In a system where Rain causes Wet Grass and Rain causes Clouds, does observing Clouds change probability of Wet Grass? Does intervening to turn on Sprinkler change probability of Rain?

- **Concept: Latent Variable Inference (Bayesian Update)**
  - **Why needed here:** Counterfactual reasoning requires "abducting" hidden state (e.g., inferring health attributes Z) from observed outcomes before predicting counterfactuals
  - **Quick check question:** If a patient took high dose of aspirin (T) and headache persisted (Y), how does observing this (T, Y) pair update belief about unobserved initial headache severity (Z)?

## Architecture Onboarding

- **Component map:** Z, T, Y → Z*, T*, Y* (twin nodes connected via shared parameters Θ)
- **Critical path:**
  1. Define joint distribution of observed data p(z, t, y|θ)
  2. Extend to joint over observed and target worlds (Eq 2), ensuring shared parameters Θ
  3. Apply intervention rule (modify conditionals, e.g., set q(t*) = δ(t*-t))
  4. Perform inference: Integrate out latents and parameters to find E[Y*|D]
- **Design tradeoffs:**
  - **Flexibility vs. Notational Convenience:** Raw probability distributions handle arbitrary models but are verbose; do-calculus is concise but restricted to specific graphical criteria
  - **SCM vs. Probabilistic Counterfactuals:** SCMs mandate sharing all noise variables (deterministic counterfactuals, strong assumptions); probabilistic approach shares only relevant latents (more flexible, potentially less precise)
- **Failure signatures:**
  - **Naive Conditioning:** Calculating P(Y|T=t) instead of intervention distribution, showing up as Simpson's Paradox
  - **Markov Equivalence Confusion:** Choosing wrong graph from Markov Equivalence Class, leading to incorrect intervention simulations
  - **Unidentifiability:** Attempting intervention effect calculation where joint distribution doesn't constrain result
- **First 3 experiments:**
  1. **Analytical Verification (Aspirin Model):** Implement log-normal aspirin model from Section 2.1; compare naive regressor (E[Y|T]) vs. twin-model intervention (E[Y*|do(T)]) to verify Simpson's paradox correction
  2. **Counterfactual Consistency Check:** Build counterfactual model (Section 3); for specific sample (z, t, y), calculate counterfactual y* where t*=t; verify y*=y (consistency axiom) under assumption all noise variables shared
  3. **Noise Sharing Sensitivity:** Run counterfactual inference twice: once sharing noise εY (SCM style) and once integrating it out; document how prediction intervals for counterfactual Y* change

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How should practitioners rigorously determine which latent noise variables to share between observed and counterfactual worlds in a probabilistic "twin model"?
- **Basis in paper:** [inferred] Authors argue in Section 3.1 that sharing all sources of randomness is "overly restrictive" and context-dependent, yet choosing which variables to share fundamentally alters counterfactual inference
- **Why unresolved:** No formal decision procedure or taxonomy within pure probabilistic framework to guide this modeling choice; relies heavily on unstated domain intuition
- **What evidence would resolve it:** Principled heuristics or formal methodology for selecting shared latents resulting in empirically robust counterfactual predictions across diverse domains

### Open Question 2
- **Question:** Can the "write down the probability of everything" approach be practically scaled to high-dimensional, non-linear data without restrictive parametric assumptions?
- **Basis in paper:** [inferred] While Section G suggests using VAEs or Normalizing Flows, authors acknowledge inference in these complex models is "very application-dependent" and non-trivial
- **Why unresolved:** Paper demonstrates approach using low-dimensional, analytically tractable log-normal distributions, leaving computational tractability for high-dimensional settings uncertain
- **What evidence would resolve it:** Successful implementation of deep probabilistic twin model performing accurate causal inference on high-dimensional datasets where traditional graphical models are intractable

### Open Question 3
- **Question:** Does explicit joint modelling of observed and interventional settings offer improved computational efficiency or identifiability properties over standard do-calculus adjustment?
- **Basis in paper:** [inferred] Paper reinterprets causal tools as "syntactic sugar" for probabilistic modelling, implying probabilistic approach is more general, but doesn't prove if generality comes at computational complexity cost
- **Why unresolved:** Unclear if "syntactic sugar" of do-calculus provides necessary shortcuts for identifying causal effects that are obscured when working solely with large joint distributions
- **What evidence would resolve it:** Complexity analysis comparing derivation of causal effects via do-calculus rules versus marginalization in full joint "twin" distribution for various graph topologies

## Limitations
- The approach may not hold for cyclic systems, non-stationary processes, or scenarios where causal mechanisms are fundamentally non-probabilistic
- Equivalence between do-calculus and probabilistic conditioning is shown for specific cases but lacks general proof
- Requires careful specification of which variables to share across twin worlds in counterfactual reasoning, which can be context-dependent and potentially subjective

## Confidence
- **High confidence:** The aspirin example demonstrating Simpson's paradox correction through twin modelling (Section 2)
- **Medium confidence:** The general claim that do-calculus can be replaced by probabilistic conditioning (Sections 2.3, 3.2)
- **Low confidence:** The assertion that this approach subsumes all benefits of specialized causal frameworks (general argument throughout)

## Next Checks
1. Test the twin model approach on a non-linear, non-Gaussian system where analytical solutions are unavailable, requiring numerical integration
2. Compare predictions from this framework against established SCM implementations on benchmark causal inference datasets (e.g., IHDP, Jobs)
3. Evaluate sensitivity to incorrect graph structure by systematically removing edges and measuring degradation in intervention accuracy