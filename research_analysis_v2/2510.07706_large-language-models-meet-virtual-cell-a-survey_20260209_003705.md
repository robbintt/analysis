---
ver: rpa2
title: 'Large Language Models Meet Virtual Cell: A Survey'
arxiv_id: '2510.07706'
source_url: https://arxiv.org/abs/2510.07706
tags:
- cell
- wang
- data
- others
- zhang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This survey comprehensively reviews large language models (LLMs)\
  \ for virtual cell modeling, categorizing methods into two paradigms: LLMs as Oracles\
  \ for direct cellular modeling and LLMs as Agents for orchestrating complex scientific\
  \ tasks. It identifies three core tasks\u2014cellular representation, perturbation\
  \ prediction, and gene regulation inference\u2014and reviews associated models,\
  \ datasets, and evaluation benchmarks."
---

# Large Language Models Meet Virtual Cell: A Survey

## Quick Facts
- arXiv ID: 2510.07706
- Source URL: https://arxiv.org/abs/2510.07706
- Reference count: 40
- This survey reviews LLMs for virtual cell modeling, categorizing them as Oracles for direct cellular modeling or Agents for orchestrating complex scientific tasks, identifying key challenges in scalability, generalizability, and interpretability.

## Executive Summary
This survey provides a comprehensive review of large language models (LLMs) applied to virtual cell modeling, categorizing approaches into two paradigms: LLMs as Oracles for direct cellular representation, perturbation prediction, and gene regulation inference, and LLMs as Agents for orchestrating complex scientific workflows. The survey identifies three core tasks, reviews associated models and datasets, and highlights key outcomes such as unified frameworks like scGPT and Evo2, as well as autonomous agents for experimental design. However, it also emphasizes significant challenges in scalability, generalizability, and interpretability that remain to be addressed.

## Method Summary
The survey systematically categorizes LLM approaches for virtual cell modeling into two paradigms: "Oracles" (foundation models for direct cellular modeling tasks) and "Agents" (models that orchestrate complex scientific workflows). It reviews three core tasks—cellular representation, perturbation prediction, and gene regulation inference—by examining associated models, datasets, and evaluation benchmarks. The survey analyzes tokenization strategies for biological data, architectural choices like attention mechanisms and context window sizes, and discusses challenges including hallucination in agents, distribution shifts, and computational barriers for ultra-long genomic contexts.

## Key Results
- LLMs as Oracles enable unified modeling of cellular states through frameworks like scGPT and Evo2, supporting multimodal and cross-species analysis.
- LLMs as Agents facilitate autonomous experimental design and data analysis by dynamically querying external tools and databases.
- Major challenges remain in scalability (ultra-long context processing), generalizability (unseen cell types), and interpretability (biological plausibility of attention patterns).

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformers capture long-range biological dependencies that constrain cellular states.
- Mechanism: Attention mechanisms operate over tokenized biological sequences (DNA, RNA, gene expression). By modeling global context, the architecture learns to link distal regulatory elements (e.g., enhancers) to gene targets or coordinate expression programs across the genome, a task where local convolutional windows fail.
- Core assumption: The "grammar" of molecular interactions and gene regulation follows statistical regularities analogous to linguistic syntax, which can be captured by next-token prediction or masked language modeling.
- Evidence anchors:
  - [abstract] Mentions LLMs enabling computational systems to "represent, predict, and reason about cellular states."
  - [section 2.1] Notes that attention mechanisms overcame the limitation of local patterns, with Enformer extending input sequences up to 200kb to capture long-range interactions.
  - [corpus] "VCWorld" reinforces the use of generative models for simulating cellular behavior.
- Break condition: If regulatory logic is strictly non-statistical or depends heavily on 3D spatial folding not captured in 1D sequence tokens, pure attention may fail to generalize.

### Mechanism 2
- Claim: Tokenization strategies map continuous biological signals to discrete learner inputs.
- Mechanism: To process non-textual omics data (e.g., scRNA-seq matrices), models employ strategies like "value binning" (discretizing expression levels) or "top-k gene selection." This converts a sparse, continuous cell-by-gene matrix into a sequence of tokens that standard Transformer architectures can process.
- Core assumption: Biological significance is preserved during quantization; ranking genes by expression or binning values retains the essential information needed for cell identity and state.
- Evidence anchors:
  - [section 2.4] Describes the "cell-by-gene expression matrix" and how methods like Geneformer use ranking while scBERT uses value binning.
  - [appendix A.1] Explicitly details tokenization methods including k-mers for DNA and value binning for omics.
  - [corpus] No direct corpus evidence contradicts this, but "SynthPert" implies reliance on effective representation for perturbation prediction.
- Break condition: If discretization discards critical subtle variations in low-expression genes required for fine-grained state prediction.

### Mechanism 3
- Claim: Agent-based orchestration overcomes the rigidity of monolithic modeling.
- Mechanism: Instead of encoding all biological knowledge in static weights, LLMs function as "Agents" that dynamically query external tools, databases (RAG), and simulation environments. This separates reasoning (planning, hypothesizing) from execution (running scripts, querying DBs), allowing the system to self-correct and ground outputs in verified literature.
- Core assumption: Complex scientific workflows (experimental design, data analysis) can be reliably decomposed into sub-tasks that an LLM can manage via APIs or dialogue without getting trapped in error loops.
- Evidence anchors:
  - [section 3] Defines "LLMs as Agents" for "orchestrating complex scientific tasks" and distinguishes them from Oracles.
  - [section 3.2] Highlights RAG as a strategy to improve factual accuracy and reduce hallucination by interfacing with literature.
  - [corpus] "SynthPert" and related papers emphasize enhancing reasoning capabilities, supporting the agent paradigm.
- Break condition: If the planning horizon exceeds the model's context window or reasoning capacity, leading to broken tool chains or hallucinated experimental steps.

## Foundational Learning

- Concept: **Omics Data Structures (scRNA-seq)**
  - Why needed here: The survey centers on processing the "cell-by-gene expression matrix" ($X \in R^{N \times G}$). Understanding that this data is sparse, high-dimensional, and measures "state" is prerequisite to comprehending why masking (MAE) or ranking strategies are used.
  - Quick check question: How does a "masked autoencoder" approach (used by scFoundation) reconstruct missing gene expression values from observed context?

- Concept: **Sequence-to-Function Mapping**
  - Why needed here: A core task is predicting "Gene Regulation" and "Perturbations" from sequence. You must grasp that DNA sequence dictates regulatory potential (chromatin accessibility) which dictates expression.
  - Quick check question: Why do models like Enformer need to handle 200kb input sequences to predict gene expression effectively?

- Concept: **Reinforcement Learning from Verifiable Rewards (RLVR)**
  - Why needed here: Advanced agents (e.g., rBio1) use RL to align biological reasoning with truth. Understanding how "verifiers" ground the model is key to understanding the "Optimization" section.
  - Quick check question: In the context of the "rBio1" model, what biological signals serve as rewards for the reinforcement learning process?

## Architecture Onboarding

- Component map:
  The architecture divides into **Oracles** (Foundation Models) and **Agents**.
  - *Oracles:* Input Tokenizer (Gene/Sequence) → Transformer Encoder/Decoder (e.g., BERT-style, GPT-style) → Task Head (Annotation/Perturbation).
  - *Agents:* LLM Core → Reasoning Loop → Tool Interface (RAG, Python Interpreters, Simulators) → Environment Feedback.

- Critical path:
  1. Select Data Modality (e.g., scRNA-seq).
  2. Apply Tokenization (e.g., binning vs. projection).
  3. Pre-train Oracle on large corpus (e.g., CELLxGENE) using Masked Language Modeling (MLM) or Next Token Prediction (NTP).
  4. *If Agent:* Integrate Oracle with RAG pipeline for knowledge retrieval and tool use.

- Design tradeoffs:
  - **MSA-based vs. MSA-free:** Using Multiple Sequence Alignments (AlphaFold-Multimer) increases accuracy but has high computational cost compared to direct language modeling (ProteomeLM).
  - **Single-agent vs. Multi-agent:** Single agents are simpler (BIA) but multi-agent systems (scAgents) offer better modularity and division of labor for complex workflows.

- Failure signatures:
  - **Hallucination:** Agents generating biologically plausible but factually incorrect citations (mitigated by RAG in Section 3.2).
  - **Distribution Shift:** Oracles failing to generalize to "unseen cell types" or novel perturbations not present in pre-training data (noted in Future Work).
  - **Context Saturation:** DNA models failing if regulatory elements fall outside the context window (e.g., >200kb for Enformer).

- First 3 experiments:
  1. **Cellular Representation Benchmark:** Fine-tune a pre-trained Oracle (e.g., scGPT) on the *Segerstolpe dataset* to evaluate cell type annotation accuracy (using ARI/NMI metrics).
  2. **Perturbation Prediction:** Test the "Oracle" on the *Adamson dataset* to predict transcriptional responses to genetic perturbations; compare RMSE against simple baselines.
  3. **Agent RAG Pipeline:** Build a simple "Agent" using an off-the-shelf LLM connected to a vector database of *GeneOntology* descriptions to verify its ability to accurately summarize gene functions without hallucination.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the field develop systematic evaluation frameworks with standardized tasks, environments, and metrics to assess LLM Agents in virtual cell research?
- Basis in paper: [explicit] The conclusion states, "LLM Agents currently lack systematic and fair evaluation frameworks. The absence of standardized tasks, environments, and metrics hinders our understanding of their strengths and weaknesses."
- Why unresolved: Current agent evaluations are ad-hoc, making it difficult to compare performance or verify reliability across different experimental workflows.
- What evidence would resolve it: The establishment of a unified benchmark suite containing fixed simulated environments and diverse biological tasks to measure agent planning and execution success rates.

### Open Question 2
- Question: What specific training strategies and architectural innovations are required for LLM Oracles to generalize effectively to unseen cell types?
- Basis in paper: [explicit] The survey identifies that for LLM Oracles, "generalization to unseen cell types remains a significant challenge."
- Why unresolved: Models often overfit to the distribution of cell types present in large pre-training datasets (e.g., CELLxGENE) and fail to accurately represent rare or novel cellular states.
- What evidence would resolve it: A model architecture or training methodology demonstrating significant performance improvements on a benchmark specifically constructed of held-out, novel cell types.

### Open Question 3
- Question: How can models unify molecular-level sequences (DNA/RNA) and omics-level profiles into coherent, joint representations that support efficient, ultra-long context processing?
- Basis in paper: [explicit] The paper highlights scalability demands "unifying multiple modalities, spanning molecular-level and omics-level sequences into coherent, joint representations" and "adopting efficient architectures capable of handling ultra-long cellular contexts."
- Why unresolved: Current architectures struggle to process the massive context lengths required to model the interplay between genomic sequence (long-range) and transcriptomic state simultaneously.
- What evidence would resolve it: The development of a single foundation model capable of processing inputs spanning both whole-genome contexts and single-cell profiles without context window truncation or loss of biological fidelity.

## Limitations

- Scale and Generalization Gaps: Current LLMs often fail to generalize across species or to entirely novel cell states, with limited cross-species performance of models like scGPT.
- Interpretability and Biological Plausibility: The "black box" nature of attention-based models raises concerns about whether learned representations correspond to true biological mechanisms.
- Evaluation Benchmark Fragmentation: Most evaluations are dataset-specific, making it difficult to compare models or assess real-world utility.

## Confidence

- **High Confidence**: The survey's categorization of LLMs into "Oracles" and "Agents" is well-supported by the literature and aligns with observed model architectures. The description of tokenization strategies (e.g., value binning, k-mer encoding) is accurate and consistent with technical reports.
- **Medium Confidence**: Claims about LLMs' ability to capture long-range regulatory dependencies (e.g., Enformer) are plausible but not universally validated across all biological contexts. The survey does not quantify the extent to which attention mechanisms outperform domain-specific models in all scenarios.
- **Low Confidence**: Assertions about the readiness of LLM agents for autonomous scientific discovery (e.g., scAgents) are aspirational. The survey acknowledges hallucination risks and context saturation, but does not provide empirical evidence of reliable, real-world deployment.

## Next Checks

1. **Cross-Species Generalization Test**: Fine-tune a pre-trained virtual cell model (e.g., scGPT) on human data, then evaluate its performance on mouse or zebrafish datasets. Measure cell type annotation accuracy and perturbation prediction error to quantify generalization gaps.

2. **Attention Interpretability Validation**: For a model like Enformer, map attention weights to known enhancer-promoter pairs in the genome. Compare the model's top-weighted interactions to experimentally validated regulatory links to assess biological plausibility.

3. **Multi-Task Benchmark Development**: Create a unified benchmark combining datasets like Segerstolpe (cell annotation), Adamson (perturbation prediction), and Tang et al. (gene regulation). Use this to evaluate and rank multiple LLMs (e.g., scGPT, Geneformer, scFoundation) on standardized metrics (ARI, NMI, RMSE).