---
ver: rpa2
title: 'Text2Model: Generating dynamic chemical reactor models using large language
  models (LLMs)'
arxiv_id: '2503.17004'
source_url: https://arxiv.org/abs/2503.17004
tags:
- fine-tuned
- modelica
- errors
- error
- llama
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates whether LLMs can generate dynamic chemical
  reactor models from natural language descriptions by fine-tuning Llama 3.1 8B Instruct
  on synthetically generated Modelica code. The fine-tuned model shows substantial
  improvements in syntactic and semantic accuracy over the baseline, particularly
  in parameter declaration, syntax handling, and unit conversion.
---

# Text2Model: Generating dynamic chemical reactor models using large language models (LLMs)

## Quick Facts
- arXiv ID: 2503.17004
- Source URL: https://arxiv.org/abs/2503.17004
- Reference count: 8
- Fine-tuned Llama 3.1 8B improves Modelica model generation accuracy but struggles with complex, unseen reactor scenarios.

## Executive Summary
This work investigates whether LLMs can generate dynamic chemical reactor models from natural language descriptions by fine-tuning Llama 3.1 8B Instruct on synthetically generated Modelica code. The fine-tuned model shows substantial improvements in syntactic and semantic accuracy over the baseline, particularly in parameter declaration, syntax handling, and unit conversion. However, its ability to generalize to unseen reactor scenarios is limited compared to GPT-4o, especially for complex reaction systems and DAE formulations. GPT-4o produces more physically accurate equations but exhibits unit compatibility issues. The study highlights the potential of LLMs for automated Modelica model generation while indicating the need for expanded training datasets, integration of domain documentation via RAG, and iterative simulation feedback to enhance robustness and generalization.

## Method Summary
The method involves generating 988 synthetic Q&A pairs from 26 templated reactor scenarios, with 790 used for training and 198 for evaluation. Llama 3.1 8B Instruct is fine-tuned using LoRA (rank=8, scale=2) on an A100 GPU, trained for 8 epochs but the model at epoch 4 is used due to overfitting. The fine-tuned model and GPT-4o are evaluated on both seen and unseen scenarios using manual scoring across 8 error categories, including unit conversion, syntax, parameter values, and equation correctness.

## Key Results
- Fine-tuned Llama 3.1 8B shows substantial improvement in syntactic accuracy and unit conversion over baseline Llama.
- Fine-tuned model exhibits limited generalization to unseen reactor scenarios compared to GPT-4o.
- GPT-4o produces more physically accurate equations but has unit compatibility issues.

## Why This Works (Mechanism)
The fine-tuned model improves by learning the syntactic structure and parameter handling specific to Modelica reactor models through supervised fine-tuning on synthetic data. LoRA allows efficient adaptation of the large model's behavior by learning small low-rank updates, enabling it to internalize the patterns of reactor model code. However, its knowledge is bounded by the training distribution, leading to poor performance on scenarios outside its templates, while GPT-4o's larger, pre-trained knowledge base allows better generalization but lacks consistent unit handling.

## Foundational Learning

- **Concept:** **Modelica Language Basics**
  - **Why needed here:** Modelica is the domain-specific target language. Understanding its structure (models, equations, declarations, units) is prerequisite to evaluating the LLM's output.
  - **Quick check question:** Can you distinguish between a parameter declaration and a variable declaration in a Modelica model, and explain the purpose of the `equation` section?

- **Concept:** **ODE vs. DAE Systems**
  - **Why needed here:** A core task for the LLM is to identify and model the correct type of system. The paper shows performance differs drastically based on the system type.
  - **Quick check question:** Explain the fundamental difference between an Ordinary Differential Equation (ODE) system and a Differential-Algebraic Equation (DAE) system. Why might a DAE system be harder to model correctly?

- **Concept:** **Parameter-Efficient Fine-Tuning (PEFT) with LoRA**
  - **Why needed here:** This is the technique used to train the model. Understanding its principle (freezing main weights, adapting small low-rank matrices) clarifies why a huge model can be trained efficiently on a modest dataset.
  - **Quick check question:** What is the primary advantage of using Low-Rank Adaptation (LoRA) for fine-tuning a large model like Llama 3.1 8B, compared to full fine-tuning? How does it update the model's behavior?

## Architecture Onboarding

- **Component Map:** Synthetic Data Generator -> Llama 3.1 8B Instruct -> LoRA Adapter -> Manual Evaluation
- **Critical Path:**
  1. Define the scope and templates for reactor scenarios.
  2. Generate the synthetic training/evaluation dataset.
  3. Apply LoRA-based supervised fine-tuning to Llama 3.1 8B Instruct.
  4. Evaluate the fine-tuned model against the baseline and GPT-4o using the custom error-based metrics on both seen and unseen scenarios.

- **Design Tradeoffs:**
  - **Synthetic vs. Real Data:** Synthetic data is cheap and structured but limits generalization. Real data is scarce.
  - **Fine-tuned Small Model vs. Large Frontier Model:** The fine-tuned Llama 3.1 8B excels at syntax and unit conversions within its training distribution. GPT-4o excels at generalization and physical reasoning on novel problems but struggles with consistent unit handling.
  - **Training Scope:** A dataset balanced heavily toward ODE systems led to poor performance on DAE systems, highlighting the tradeoff between data volume per scenario and overall scenario diversity.

- **Failure Signatures:**
  - **Hallucination:** The fine-tuned model fabricates parameter values, especially for DAE systems (e.g., 8 of 17 "Incorrect values" errors occurred in the two DAE test cases).
  - **Structural Singularity:** The model generates an incomplete or overdetermined system of equations, making it impossible to solve (a "Structural error").
  - **Unit Conflicts:** Generated equations mix incompatible units (e.g., Joules and Calories) without proper conversion, leading to incorrect numerical results.

- **First 3 Experiments:**
  1. **Generalization Test:** Run the fine-tuned model on a set of reactor scenarios from a completely different source or domain not covered by the training templates to rigorously test its failure modes against GPT-4o.
  2. **Iterative Feedback Loop:** Implement a prototype where the generated Modelica code is automatically passed to a Dymola compiler; errors are fed back to the LLM for a second-pass correction.
  3. **Dataset Balancing:** Re-train the model with a new, balanced dataset that includes a proportional number of DAE system templates, and measure the improvement in DAE-specific error rates.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does integrating an iterative feedback loop with Dymola simulation significantly reduce structural and syntax errors in generated models?
- **Basis in paper:** [explicit] The authors suggest "iterative improvement by leveraging an interface to Dymola" to re-route failed simulation attempts.
- **Why unresolved:** The current study evaluates single-shot generation without automated verification or self-correction based on compiler errors.
- **What evidence would resolve it:** A demonstration of decreased error rates when the LLM is allowed to refine code based on compiler or simulation feedback.

### Open Question 2
- **Question:** To what extent does Retrieval-Augmented Generation (RAG) improve the semantic accuracy of physics equations compared to supervised fine-tuning alone?
- **Basis in paper:** [explicit] The paper proposes "incorporating broader literature and Modelica documentation into the workflow by using RAG" to increase robustness.
- **Why unresolved:** The fine-tuned model currently hallucinates incorrect physics for unseen scenarios, relying solely on internalized parametric knowledge.
- **What evidence would resolve it:** Performance metrics comparing the fine-tuned model against a RAG-enhanced model on complex, unseen reaction scenarios.

### Open Question 3
- **Question:** What specific data composition strategies are required to enable generalization to complex reaction systems (e.g., parallel or consecutive reactions)?
- **Basis in paper:** [inferred] While the authors explicitly suggest "expanding the fine-tuning dataset," the results show specific failure in generalizing to parallel/consecutive reactions absent from templates.
- **Why unresolved:** It is unclear if simply scaling the data volume or specifically diversifying the reaction topologies is necessary to stop the model from memorizing templates.
- **What evidence would resolve it:** Successful generation of rate expressions for multi-step reactions in a model trained on a broader, more diverse reaction dataset.

## Limitations

- Evaluation relies entirely on synthetic data, which may not capture real-world complexity and variability.
- Baseline model performance is extremely poor, potentially overstating the fine-tuned model's improvement.
- Generalization tests are limited to four unseen scenarios, not covering full diversity of potential reactor descriptions.
- No systematic ablation study to quantify impact of specific training choices (e.g., LoRA rank, epoch count, template distribution).

## Confidence

- **Fine-tuned Llama 3.1 8B Instruct shows substantial improvement in syntactic accuracy and unit conversion over baseline Llama (Medium):** The error rate reduction is clear, but the baseline's extremely poor performance raises questions about the practical significance of the improvement.
- **Fine-tuned model exhibits limited generalization to unseen reactor scenarios compared to GPT-4o (Medium):** The error rate differences on unseen scenarios are evident, but the small number of test cases limits the strength of this conclusion.
- **GPT-4o produces more physically accurate equations but has unit compatibility issues (High):** This is directly observed in the error analysis and is a known limitation of frontier LLMs.
- **Synthetic data generation and LoRA fine-tuning are effective strategies for domain-specific Modelica code generation (Low):** While the method works within the synthetic training distribution, its robustness to real-world, unstructured input is unproven.

## Next Checks

1. **Stress Generalization with Diverse Real Descriptions:** Evaluate the fine-tuned model on a corpus of natural language reactor descriptions sourced from textbooks, research papers, or process engineering documentation, not from the synthetic templates. This will rigorously test its ability to handle real-world linguistic variability and complex reaction schemes.

2. **Integrate and Validate with a Simulation Engine:** Implement a closed-loop system where the LLM-generated Modelica code is automatically compiled and simulated in Dymola or OpenModelica. Use the simulation's diagnostic output (e.g., structural singularity errors, unit mismatch warnings) as automated feedback to guide a second-pass correction by the LLM, measuring the reduction in manual post-processing.

3. **Conduct an Ablation Study on Training Data Distribution:** Retrain the model with a new, balanced dataset where the number of DAE system templates is increased to match the ODE system count (e.g., 12 DAE and 24 ODE templates). Compare the DAE-specific error rates to the original model to quantify the impact of dataset imbalance on generalization.