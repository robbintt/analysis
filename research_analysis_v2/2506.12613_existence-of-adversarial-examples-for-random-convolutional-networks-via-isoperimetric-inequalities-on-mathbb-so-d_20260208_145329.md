---
ver: rpa2
title: Existence of Adversarial Examples for Random Convolutional Networks via Isoperimetric
  Inequalities on $\mathbb{so}(d)$
arxiv_id: '2506.12613'
source_url: https://arxiv.org/abs/2506.12613
tags:
- random
- adversarial
- examples
- have
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper establishes the existence of adversarial examples for
  random convolutional neural networks using isoperimetric inequalities on the special
  orthogonal group SO(d). The key insight is that adversarial examples arise as a
  simple consequence of measure concentration properties of SO(d), extending previous
  results from fully connected networks to convolutional architectures.
---

# Existence of Adversarial Examples for Random Convolutional Networks via Isoperimetric Inequalities on $\mathbb{so}(d)$

## Quick Facts
- arXiv ID: 2506.12613
- Source URL: https://arxiv.org/abs/2506.12613
- Reference count: 28
- One-line primary result: Establishes existence of adversarial examples for random convolutional networks using isoperimetric inequalities on SO(d)

## Executive Summary
This paper proves that random convolutional neural networks inherently contain adversarial examples, demonstrating that these vulnerabilities arise from fundamental geometric properties rather than complex learned features. The key insight leverages measure concentration on the special orthogonal group SO(d) to show that network outputs partition input space into regions of comparable measure, guaranteeing nearby inputs with opposite classifications. The results apply to networks with random Xavier-initialized convolutional layers and either odd activations (like tanh) or ReLU activations with constant depth.

## Method Summary
The paper uses theoretical analysis of random convolutional neural networks with Xavier initialization, showing that the SO(d)-invariance of regular random weights combined with isoperimetric inequalities guarantees the existence of adversarial examples. For odd activations, the analysis shows perfect balance between positive and negative outputs, while for ReLU networks, probabilistic arguments establish approximate balance. The method provides theoretical bounds on perturbation magnitudes rather than constructive algorithms for finding specific adversarial examples.

## Key Results
- Adversarial examples exist with probability 1-2e^{-τ²/32} for random convolutional networks with odd activations
- For ReLU networks of constant depth, similar guarantees hold with probability (1-od(1))(1-2e^{-Ω(τ²/log²(d))})
- Perturbation radius is bounded by τ√d-2 · ||x₀||sp/||x₀|| · ||x₀|| for odd activations
- Results apply to networks with no restrictions on width or depth (for odd activations)
- Only mild conditions required for ReLU networks (constant depth, ω(log(nd)) channels)

## Why This Works (Mechanism)

### Mechanism 1: SO(d)-Invariance of Random Convolutions
- **Claim:** Random convolutional layers with Xavier initialization produce networks invariant to simultaneous rotations of all input channels by any matrix $U \in SO(d)$
- **Mechanism:** Regular weight matrices $W$ have the property that $W$ and $WU^{-1}$ are identically distributed, making the network function invariant to input rotations
- **Core assumption:** Weight matrix $W$ must be regular (distribution invariant under right multiplication by orthogonal matrices)
- **Evidence anchors:** Abstract states results arise from "isoperimetric inequality on the special orthogonal group SO(d)"; Section 5 proves $U f$ and $f$ are identically distributed for regular layers
- **Break condition:** Non-regular weights (pruning, structured sparsity) or non-isotropic initialization breaks SO(d)-invariance

### Mechanism 2: Isoperimetric Inequality on Input Orbits
- **Claim:** Concentration of measure on SO(d) guarantees that balanced functions have geometrically close points with opposite classifications
- **Mechanism:** The isoperimetric inequality implies that subsets of significant measure in the input orbit have large surface area, forcing overlap between positive and negative regions
- **Core assumption:** Function must be $(q,p)$-balanced (positive/negative output measures are comparable)
- **Evidence anchors:** Abstract mentions "measure concentration properties of SO(d)"; Section 4 generalizes isoperimetric inequality to transitive SO(d)-metric-spaces
- **Break condition:** Low-dimensional orbits or non-mixing metric spaces violate required Lipschitz conditions

### Mechanism 3: Balancedness via Activation Symmetry
- **Claim:** Odd activations (tanh) naturally produce balanced outputs; ReLU requires probabilistic arguments for balance
- **Mechanism:** For odd activations, $f(-\vec{x}) = -f(\vec{x})$ and $-I \in SO(d)$ ensures equal positive/negative measures; ReLU balance proven probabilistically using Gaussian concentration
- **Core assumption:** Odd activations for Theorem 3.1; constant depth and ω(log(nd)) channels for ReLU in Theorem 3.2
- **Evidence anchors:** Section 3 requires odd activations; Section 6 proves ReLU networks are $(1-o_d(1), 1/\log(d))$-balanced
- **Break condition:** Shallow ReLU networks or insufficient width may not achieve balancedness

## Foundational Learning

- **Concept: Special Orthogonal Group $SO(d)$**
  - **Why needed here:** This is the geometric structure underlying the main proof, treating input rotations as random walks on this group
  - **Quick check question:** Can you explain why $-I$ (negative identity) is in $SO(d)$ only if dimension $d$ is even, and why that matters for "odd" functions?

- **Concept: Measure Concentration & Isoperimetric Inequalities**
  - **Why needed here:** These explain why most points in high-dimensional space are close to boundaries, creating vulnerability
  - **Quick check question:** In high dimensions, does the volume of a sphere concentrate near the surface or the center?

- **Concept: Regular Random Matrices (Xavier Initialization)**
  - **Why needed here:** The paper assumes "regular" weights to prove SO(d)-invariance; standard Xavier initialization satisfies this
  - **Quick check question:** If you rotate input by $U$, a regular weight matrix $W$ effectively becomes $WU^{-1}$. Is $WU^{-1}$ distributed the same as $W$?

## Architecture Onboarding

- **Component map:** Input $(\mathbb{R}^d)^n$ -> Layer 1 (Random Convolutional, Regular/Xavier) -> Layers 2..L (Any) -> Activations (Odd/ReLU) -> Output (Scalar)

- **Critical path:**
  1. Initialize Layer 1 weights $W$ as Xavier/Regular $\rightarrow$ ensures SO(d)-invariance
  2. Input $\vec{x}_0$ transforms to orbit $C(\vec{x}_0)$ (rotated versions)
  3. Odd Activation $\rightarrow$ Perfect balance (positive/negative volumes equal)
  4. ReLU Activation $\rightarrow$ High-dimensional geometry forces "mostly" balanced outputs
  5. Isoperimetric Inequality $\rightarrow$ High probability of nearby opposite-sign outputs

- **Design tradeoffs:**
  - **Odd vs. ReLU:** Odd activations yield simpler, stronger proofs (Theorem 3.1) with better probability bounds ($e^{-\tau^2/32}$); ReLU requires constant depth and yields weaker bounds ($e^{-\tau^2/\log^2(d)}$)
  - **Constructive vs. Existential:** Paper provides existence guarantee but no algorithm for finding examples

- **Failure signatures:**
  - **Violation of Regularity:** Non-regular weights (pruning, structured sparsity) break SO(d)-invariance and theoretical guarantees
  - **Low Dimensionality:** Small $d$ weakens measure concentration, making bounds unreliable

- **First 3 experiments:**
  1. **Verify SO(d) Invariance:** Generate random input $\vec{x}$, rotate by random $U \in SO(d)$, feed through Xavier-initialized CNN; verify identical output distributions
  2. **Test Balancedness:** For fixed random ReLU network, sample random rotations of fixed input; plot histogram of $f(\vec{x})$ and check if centered around 0
  3. **Radius Check:** Pick point $\vec{x}_0$ with $f(\vec{x}_0) > 0$; search for adversarial example via random sampling within radius $\epsilon \approx \frac{1}{\sqrt{d}}\|\vec{x}_0\|$; compare empirical success rate against theoretical probability $1 - 2e^{-\tau^2/32}$

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the existence of adversarial examples in these random networks be made constructive by developing an efficient algorithm to identify the perturbations?
- **Basis in paper:** Authors explicitly state, "our techniques are less constructive, and we do not present an algorithm for finding an adversarial perturbation."
- **Why unresolved:** Proof relies on non-constructive isoperimetric inequalities rather than optimizing specific loss landscapes
- **What evidence would resolve it:** Polynomial-time algorithm (e.g., gradient descent variant) provably converging to adversarial examples

### Open Question 2
- **Question:** Can the guarantees for ReLU networks be extended to allow for arbitrary or non-constant depth?
- **Basis in paper:** Theorem 3.1 allows arbitrary depth for odd activations, but Theorem 3.2 restricts ReLU networks to "constant depth" ($l$)
- **Why unresolved:** ReLU balance-ness proof relies on properties that may degrade as network depth increases relative to dimension
- **What evidence would resolve it:** Proof that random ReLU convolutional networks remain $(q,p)$-balanced even when depth $l$ scales with dimension $d$

### Open Question 3
- **Question:** Do the isoperimetric inequalities and resulting bounds hold rigorously for 2D or higher-dimensional convolutions?
- **Basis in paper:** Authors note, "for the sake of simplicity, we consider one-dimensional convolutions, despite that our results can be phrased for general convolutional layers."
- **Why unresolved:** While results suggested to hold generally, specific group actions and measure concentration for 2D spatial structures require explicit formalization
- **What evidence would resolve it:** Derivation of specific Lipschitz constants for SO(d)-action on 2D input spaces matching 1D convolution bounds

## Limitations
- Provides theoretical existence proofs but no constructive algorithms for finding adversarial examples
- Results depend heavily on specific initialization schemes (Xavier/regular weights)
- ReLU network guarantees require restrictive conditions (constant depth, specific width requirements)
- Practical applicability to standard architectures is limited by restrictive conditions

## Confidence
- **High confidence** in SO(d)-invariance mechanism for random convolutional networks with regular weights (explicit proofs in Section 5)
- **Medium confidence** in isoperimetric inequality arguments (novel extension to transitive SO(d)-metric-spaces with technical assumptions)
- **Low confidence** in practical applicability to standard architectures (restrictive conditions on activations, initialization, and depth)

## Next Checks
1. **Empirical radius validation**: Measure empirical success rate of finding adversarial examples within theoretical perturbation radius across different input distributions and network depths
2. **Symmetry breaking experiments**: Test networks with structured sparsity or non-regular initialization to verify when SO(d)-invariance breaks down and adversarial guarantees fail
3. **Depth-robustness analysis**: Systematically vary network depth for ReLU networks to identify threshold where probabilistic balancedness breaks down and compare with theoretical predictions