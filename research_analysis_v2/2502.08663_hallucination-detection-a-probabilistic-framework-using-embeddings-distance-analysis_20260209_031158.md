---
ver: rpa2
title: 'Hallucination Detection: A Probabilistic Framework Using Embeddings Distance
  Analysis'
arxiv_id: '2502.08663'
source_url: https://arxiv.org/abs/2502.08663
tags:
- september
- responses
- hallucination
- distance
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a probabilistic framework for detecting hallucinations
  in large language model (LLM) responses using embedding distance analysis. The core
  idea is that hallucinated responses exhibit structural differences in their embedding
  space compared to genuine responses, which can be quantified using Minkowski distances
  across different norms.
---

# Hallucination Detection: A Probabilistic Framework Using Embeddings Distance Analysis

## Quick Facts
- arXiv ID: 2502.08663
- Source URL: https://arxiv.org/abs/2502.08663
- Reference count: 40
- Best-case accuracy: 66% using Minkowski distance analysis with fractional norms

## Executive Summary
This paper introduces a novel probabilistic framework for detecting hallucinations in LLM responses by analyzing embedding distance distributions. The core insight is that hallucinated responses exhibit distinct structural patterns in embedding space compared to grounded responses, which can be quantified using Minkowski distances across different norms. The approach achieves 66% accuracy on binary hallucination detection, competitive with existing methods, while providing a mathematically rigorous foundation for understanding how hallucinations manifest in semantic space.

## Method Summary
The method generates a dataset by comparing responses from Llama2 (trained pre-Sept 2023, necessarily hallucinated on post-training events) and Llama3 (with relevant knowledge). For each of 64 questions, the system extracts keywords using KeyBERT, converts them to BERT embeddings, and computes pairwise Minkowski distances within each class. Kernel Density Estimation fits probability distributions to these distance distributions, and classification proceeds via likelihood comparison. The approach systematically explores parameter space (response count r, keyword count n, distance norm p) to identify optimal configurations.

## Key Results
- Best-case accuracy of 66% achieved with r=8 responses, n=1 keyword, p=0.5 fractional norm
- Statistical analysis confirms significant differences between hallucinated and non-hallucinated distance distributions (Wilcoxon p<0.01)
- Fractional norms (p=0.5) show stronger separability than standard Euclidean distance (p=2.0)
- Performance competitive with Semantic Entropy (62.17%) and CCS (61.27%) baselines
- Accuracy improves with more responses (r) up to a point, but keyword count (n) shows diminishing returns

## Why This Works (Mechanism)

### Mechanism 1: Embedding Space Dispersion Differentiates Hallucinations
Hallucinated responses exhibit greater dispersion in embedding space than grounded responses, creating distinguishable distance distributions. When models lack knowledge, they generate responses sampled from broader semantic regions, while grounded responses cluster more tightly around consistent content.

### Mechanism 2: Fractional Minkowski Norms Amplify High-Dimensional Separation
Fractional distance norms (p < 1) amplify separability between hallucinated and non-hallucinated distance distributions compared to standard Euclidean distance. In high-dimensional spaces, fractional norms concentrate distance variance differently, making distributional differences more detectable.

### Mechanism 3: Likelihood Ratio Classification via KDE
Comparing aggregate log-likelihoods under hallucinated vs. non-hallucinated distance distributions enables binary classification. By fitting KDE to empirical distance distributions from each class, the method computes aggregated scores for test points against both distributions, classifying based on which distribution assigns higher likelihood.

## Foundational Learning

- **Concept: Minkowski Distance (including fractional norms)**
  - Why needed here: The paper's core discriminative signal relies on comparing pairwise distances under different norms (p ∈ {0.5, 1.0, 2.0})
  - Quick check question: For two 768-dimensional vectors, how does the ratio of distances change as p decreases from 2.0 to 0.5?

- **Concept: Kernel Density Estimation (KDE)**
  - Why needed here: Classification depends on fitting probability densities to empirical distance distributions and computing log-likelihoods
  - Quick check question: Given a sample of 1000 distances, how would you select the Gaussian kernel bandwidth h?

- **Concept: Statistical Hypothesis Testing (Wilcoxon, KL Divergence)**
  - Why needed here: The paper validates distributional differences using Wilcoxon signed-rank tests and quantifies separability via KL divergence
  - Quick check question: Why might Wilcoxon be preferred over a t-test for comparing distance distributions?

## Architecture Onboarding

- **Component map:** Question Generator -> Response Collector -> Keyword Extractor -> Embedding Encoder -> Distance Computer -> Density Estimator -> Classifier
- **Critical path:** Response collection → Keyword extraction → Embedding → Distance computation → KDE fitting → Likelihood comparison. The distance computation (O((qr)²)) is the computational bottleneck.
- **Design tradeoffs:** More keywords (n) increases KL divergence but does not improve F1 score; simpler models (n=1) often perform better. More responses (r) improves accuracy for some configurations but increases compute quadratically. Fractional norms (p=0.5) show higher peak accuracy but greater variance; p=2.0 is more stable.
- **Failure signatures:** Many zero distances (different responses yield identical keywords), low F1 despite high accuracy (model better at identifying non-hallucinated responses), accuracy drops sharply when r > 8 with n > 5 (overfitting).
- **First 3 experiments:** 1) Reproduce the r=8, n=1, p=0.5 configuration on the provided 64 questions to verify the 66% accuracy claim. 2) Ablate the keyword count (n ∈ {1, 2, 3}) with fixed r=8, p=0.5 to confirm that fewer keywords yield better hallucination F1. 3) Test generalization by applying trained KDE models to questions about a different time period where both models have similar knowledge.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does model parameter scale (beyond 7B–8B) improve detection accuracy by increasing inter-class distance separation?
- Basis in paper: Section 5.2: "It is in our agenda to investigate whether the achieved results vary with the size of the model parameters."
- Why unresolved: Only Llama2-7B and Llama3-8B were tested; scaling effects remain unexplored.
- What evidence would resolve it: Run the same detection pipeline on larger models (e.g., 13B, 70B) and compare KL divergence and accuracy.

### Open Question 2
- Question: Can the O(qr²) computational complexity of pairwise distance calculations be reduced without significant loss of detection performance?
- Basis in paper: Section 5.2 cites complexity as a "significant limitation" and calls for future work on reduction.
- Why unresolved: The authors used brute-force computation and did not explore approximation or sampling strategies.
- What evidence would resolve it: Implement approximate nearest-neighbor or subsampling methods and benchmark against full computation.

### Open Question 3
- Question: Would using established hallucination datasets (e.g., HalluRAG, HADES) improve detection accuracy compared to the artificially generated dataset based on training cutoff dates?
- Basis in paper: Section 5.2: "A possible improvement would be to use a dataset already existing in the literature."
- Why unresolved: The current dataset assumes Llama3 responses are always genuine, which may introduce label noise.
- What evidence would resolve it: Train and evaluate the framework on HalluRAG/HADES and compare accuracy metrics.

## Limitations
- Dataset Generalization: The validation relies on a single dataset where Llama2 necessarily hallucinates on post-training events while Llama3 has relevant knowledge, creating potentially artificial separation.
- Computational Scalability: The pairwise distance computation has O((qr)²) complexity, making it computationally expensive for larger response sets.
- Class Imbalance: The reported accuracy masks potential imbalance in detecting hallucinated versus non-hallucinated responses; F1 score for the hallucinated class would better reveal preferential detection.

## Confidence

**High Confidence (≳80%)**:
- The statistical differences between embedding distance distributions are real and measurable
- The methodology for computing distances and fitting KDEs is correctly implemented
- The approach achieves competitive accuracy (66%) relative to existing methods

**Medium Confidence (60-80%)**:
- The mechanism that fractional Minkowski norms amplify separation is valid but may not generalize across all embedding spaces
- The KDE-based likelihood comparison provides a reasonable classification framework
- The observed distributional differences scale-free property holds for the tested dataset

**Low Confidence (≲60%)**:
- The approach will maintain effectiveness when both models have similar knowledge levels
- The method will generalize to hallucinations arising from reasoning errors versus knowledge gaps
- The specific configuration (r=8, n=1, p=0.5) represents an optimal or near-optimal setup

## Next Checks

1. **Temporal Generalization Test**: Apply the trained KDE models to questions about pre-2022 events where both Llama2 and Llama3 have similar knowledge. Measure whether the distributional differences persist or collapse when knowledge levels equalize.

2. **Ablation on Keyword Extraction**: Systematically vary the keyword extraction method (e.g., TF-IDF, RAKE) and keyword count to determine the sensitivity of detection performance to this preprocessing step.

3. **Cross-Domain Validation**: Test the approach on a dataset covering different domains (scientific, technical, medical) to assess whether the embedding distance distributional differences hold across diverse knowledge domains.