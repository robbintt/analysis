---
ver: rpa2
title: 'MAC: Masked Agent Collaboration Boosts Large Language Model Medical Decision-Making'
arxiv_id: '2507.21159'
source_url: https://arxiv.org/abs/2507.21159
tags:
- llms
- agent
- agents
- medical
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving medical decision-making
  with large language models (LLMs) in multi-agent systems. The key problem is that
  existing MAS-based models often fail due to lack of systematic agent selection and
  rigid collaboration patterns, leading to performance degradation.
---

# MAC: Masked Agent Collaboration Boosts Large Language Model Medical Decision-Making

## Quick Facts
- **arXiv ID:** 2507.21159
- **Source URL:** https://arxiv.org/abs/2507.21159
- **Authors:** Zhihao Peng; Liuxin Bao; Yixuan Yuan
- **Reference count:** 40
- **Primary result:** MAC achieves 16.55% accuracy improvement over multi-agent baselines and 9.35% over GPT-4 on NEJMQA medical MCQs

## Executive Summary
This paper addresses the challenge of improving medical decision-making with large language models (LLMs) in multi-agent systems. Existing multi-agent approaches often fail due to lack of systematic agent selection and rigid collaboration patterns, leading to performance degradation. The authors propose a novel Masked Agent Collaboration (MAC) framework that uses Pareto-optimal agent construction to select the best LLMs by balancing efficiency and capability, combined with a cross-consistency maximization mechanism to iteratively mask inconsistent agents, improving reliability. Experiments on three medical datasets demonstrate significant improvements in medical decision-making accuracy.

## Method Summary
MAC introduces a two-stage framework: first, Pareto-optimal agent selection identifies the best LLMs from a candidate pool based on four factors (model size, inference time, diversity score, and throughput). Second, adaptive progressive propagation with cross-consistency maximization iteratively masks agents with the lowest semantic consistency, improving reliability. The framework uses six open-source models (Phi4 14B, Qwen2.5 14B, Qwen2.5 32B, QWQ 32B, Openthinker 32B, Deepseek-R1 32B) and evaluates on NEJMQA, MMLUPH, and MedQA datasets using accuracy and other metrics.

## Key Results
- MAC achieves 16.55% higher accuracy than multi-agent models and 9.35% higher than GPT-4 on NEJMQA
- The framework reduces inference latency from 630s to 241s compared to traditional baselines
- Outperforms single-agent baselines across all three medical datasets (NEJMQA, MMLUPH, MedQA)

## Why This Works (Mechanism)

### Mechanism 1: Pareto-Optimal Agent Selection
The system evaluates LLMs using four factors: model size, inference time, diversity score, and throughput, selecting a set of "non-dominated" models where no single model is strictly better in all dimensions. This optimizes the trade-off between resource cost and reasoning quality before inference begins.

### Mechanism 2: Cross-Consistency Maximization (Masking)
In each layer, the framework calculates pairwise semantic similarity between agent outputs and masks the agent whose outputs diverge most from the group consensus. This assumes that outlier answers are more likely to be hallucinations.

### Mechanism 3: Adaptive Progressive Propagation
Unlike standard Mixture-of-Agents (MoA) which aggregates all previous outputs, MAC filters the context window. The next layer of agents sees only the high-consistency outputs, reducing noise and context-length overhead.

## Foundational Learning

**Concept: Multi-Objective Optimization (Pareto Efficiency)**
- **Why needed:** To understand how the system selects the initial agent team not just by "who is smartest" but by balancing size, speed, and diversity.
- **Quick check:** If Model A is accurate but slow, and Model B is fast but less accurate, which one is "Pareto-optimal"?

**Concept: Semantic Textual Similarity**
- **Why needed:** This is the mathematical basis for the "Cross-Consistency" calculation using Levenshtein distance/sliding windows to determine if agents "agree."
- **Quick check:** Does a high similarity score between two texts guarantee they are factually correct, or just linguistically similar?

**Concept: Multi-Agent System (MAS) Topologies**
- **Why needed:** To distinguish MAC (dynamic, masking-based) from static frameworks like Debate or Mixture-of-Agents (MoA).
- **Quick check:** In a "Masked" architecture, what happens to the information flow if one agent is removed?

## Architecture Onboarding

**Component map:** Factor Analyzer -> Selector -> Inference Layer (Li) -> Consistency Checker -> Masker -> Aggregator

**Critical path:**
1. **Initialization:** Select 6 agents via Pareto analysis
2. **Layer 1:** All 6 agents generate answers
3. **Filter:** Calculate CC; mask the 2 lowest agents
4. **Layer 2:** Remaining 4 agents generate new answers using Layer 1 context
5. **Repeat:** Continue masking and refining until final layer

**Design tradeoffs:**
- **Consensus vs. Novelty:** Masking inconsistent agents improves precision but risks discarding a "correct minority" view
- **Efficiency vs. Depth:** Aggressive masking (e.g., removing 3 agents per layer) speeds up inference but reduces the "wisdom of the crowd" effect
- **Metric Sensitivity:** The reliance on Levenshtein distance for similarity may penalize syntactically different but semantically equivalent medical reasoning

**Failure signatures:**
- **Echo Chamber:** Rapid convergence to a wrong answer because the "dissenting" (correct) agent was masked early
- **Context Drift:** Aggregated prompts becoming too long or repetitive, confusing the final layer
- **Pareto Fragility:** Selected agents are too similar (low diversity), rendering the collaboration ineffective

**First 3 experiments:**
1. **Ablation on Masking:** Run the framework with "Random Masking" vs. "CC-based Masking" to verify the specific contribution of the consistency logic
2. **Agent Diversity Audit:** Visualize the "Diversity Score" of the selected Pareto agents vs. random selection to confirm the selection mechanism works as intended
3. **Depth Test:** Vary the number of masked agents per layer (e.g., mask 1 vs. 2) to find the optimal balance between speed and accuracy on a subset of NEJMQA

## Open Questions the Paper Calls Out

**Open Question 1:** Can the adaptive progressive propagation mechanism be improved by determining the number of masked agents dynamically per layer rather than using a fixed heuristic?

**Open Question 2:** Does replacing the Levenshtein distance-based diversity score with a semantic embedding-based metric improve the Pareto-optimal agent selection?

**Open Question 3:** How does the MAC framework perform when the candidate agent pool includes highly heterogeneous model architectures and parameter sizes?

## Limitations
- **Consensus Assumption Fragility:** The core masking mechanism assumes semantic consensus correlates with correctness, which may mask correct minority opinions in medical contexts
- **Narrow Agent Pool:** The Pareto-optimal selection is demonstrated on only 6 open-source models, limiting generalizability
- **Prompt Engineering Dependency:** Effectiveness hinges on specific prompt templates and output parsing, suggesting significant brittleness to model-specific behaviors

## Confidence

**High Confidence** - Claims about improved efficiency metrics (latency reduction from 630s to 241s) and performance gains (16.55% over multi-agent baselines) are directly supported by experimental tables.

**Medium Confidence** - The Pareto-optimal selection methodology appears sound, but the paper doesn't demonstrate what happens when the candidate pool changes or when models have similar characteristics.

**Low Confidence** - The assertion that cross-consistency maximization reliably filters "medical-agnostic misinformation" lacks external validation. The mechanism could mask correct minority opinions, especially for counter-intuitive medical cases.

## Next Checks
1. **Minority View Preservation Test:** Create synthetic datasets where the correct answer is counter-intuitive or represents a rare condition. Test whether MAC masks the correct agent early, demonstrating the consensus assumption's failure mode.
2. **Agent Pool Sensitivity Analysis:** Replace the 6 models with different combinations (e.g., more homogeneous models, or models from different providers) and measure performance degradation to assess Pareto selection robustness.
3. **Error Attribution Study:** Analyze which types of medical errors (knowledge gaps vs. reasoning errors vs. consensus failures) MAC is most/least effective at preventing, using error analysis on NEJMQA failures.