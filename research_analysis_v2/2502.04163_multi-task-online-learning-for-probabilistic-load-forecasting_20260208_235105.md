---
ver: rpa2
title: Multi-task Online Learning for Probabilistic Load Forecasting
arxiv_id: '2502.04163'
source_url: https://arxiv.org/abs/2502.04163
tags:
- load
- learning
- forecasting
- entity
- loads
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a probabilistic load forecasting method based
  on online learning for multi-task load forecasting. The proposed method uses vector-valued
  Hidden Markov Models (HMMs) to model the relationship between load consumption and
  observations for multiple entities.
---

# Multi-task Online Learning for Probabilistic Load Forecasting

## Quick Facts
- arXiv ID: 2502.04163
- Source URL: https://arxiv.org/abs/2502.04163
- Authors: Onintze Zaballa; Verónica Álvarez; Santiago Mazuelas
- Reference count: 19
- One-line primary result: Achieves MAPE of 4.18% and RMSE of 0.10 GW on GEFCom2017 dataset

## Executive Summary
This paper introduces a probabilistic load forecasting method using online learning for multi-task scenarios. The approach employs vector-valued Hidden Markov Models (HMMs) to capture dynamic correlations between multiple entities' load consumption patterns. Model parameters are updated recursively using a forgetting-factor-weighted algorithm, enabling continuous adaptation to evolving consumption patterns while maintaining computational efficiency. The method demonstrates superior performance compared to state-of-the-art multi-task learning techniques across three publicly available datasets.

## Method Summary
The method uses vector-valued HMMs where load consumption and observations for multiple entities are modeled jointly. The covariance matrix captures cross-entity correlations, allowing the model to leverage dynamic similarities between entities. Parameters (mean matrices and covariance matrices for both loads and observations) are updated recursively using a forgetting-factor-weighted algorithm. Calendar-type-specific parameters enable temporal pattern specialization. Probabilistic predictions are generated through covariance-weighted fusion of load-state predictions and observation-conditioned predictions, providing both mean forecasts and uncertainty quantification.

## Key Results
- Achieves MAPE of 4.18% and RMSE of 0.10 GW on GEFCom2017 dataset (8 regions)
- Outperforms existing multi-task learning techniques across GEFCom2017, ISO New England, and SMART datasets
- Successfully adapts to dynamic changes in consumption patterns through online learning
- Demonstrates the effectiveness of cross-entity covariance learning in improving forecast accuracy

## Why This Works (Mechanism)

### Mechanism 1: Cross-Entity Covariance Learning via Vector-Valued HMM
The model captures dynamic correlations between entities through joint covariance estimation. The covariance matrix Σ ∈ R^K×K encodes both variances and cross-entity correlations, with covariance-weighted fusion allowing each entity's forecast to be influenced by related entities' consumption patterns. This works under the assumption that entities share consumption pattern similarities that persist and evolve predictably over time.

### Mechanism 2: Recursive Online Parameter Adaptation
Forgetting-factor-weighted recursive updates enable continuous adaptation to evolving consumption patterns without full retraining. Equations (10-11) update mean matrix M and covariance matrix Σ incrementally using prediction errors weighted by λ ∈ (0,1]. The forgetting factor discounts older observations, with λ = 0.8 (load) and λ = 0.7 (observations) used experimentally, based on the assumption that consumption patterns evolve gradually.

### Mechanism 3: Covariance-Weighted Probabilistic Fusion
Combining load-state predictions with observation-conditioned predictions through covariance-weighted averaging yields calibrated probabilistic forecasts. Theorem 1 (Equations 13-14) fuses two Gaussian sources using inverse-covariance weighted averaging, automatically balancing influence based on each source's uncertainty. This provides both mean forecasts and covariance-based uncertainty quantification, assuming Gaussian conditional distributions adequately model load-observation relationships.

## Foundational Learning

- **Hidden Markov Models (HMMs)**
  - Why needed here: Models load as latent states with temporal dynamics p(st|st-1) and observation relationships p(rt|st). Understanding Markovian state transitions is essential.
  - Quick check question: Given p(A|B) and p(C|A), how would you compute p(A|B,C) assuming conditional independence?

- **Multivariate Gaussian Distributions and Covariance Matrices**
  - Why needed here: All conditionals are multivariate Gaussian; covariance matrices encode cross-entity correlations. Matrix operations in Equations 10-14 require linear algebra fluency.
  - Quick check question: For a 3-entity system with covariance matrix Σ, what does Σ[1,2] = 0.8 versus Σ[1,2] = -0.2 imply about entities 1 and 2?

- **Recursive Least Squares / Online Learning**
  - Why needed here: Parameter updates use recursive formulas avoiding batch retraining. The forgetting factor λ controls plasticity-stability trade-off.
  - Quick check question: With λ = 0.9, approximately how many time steps does it take for an observation's influence to decay to 50%?

## Architecture Onboarding

- **Component map:**
  - Input layer: Load vectors st ∈ R^K, observation vectors rt ∈ R^(KN), calendar variable c(t) ∈ {1,...,48}
  - Parameter store: Θ = {Ms,c, Σs,c, Mr,c, Σr,c} for each calendar type c
  - Update engine: Recursive formulas (10-11) with forgetting factors λs, λr
  - Prediction engine: Theorem 1 recursions (13-14) producing Gaussian forecasts N(ŝt+i, Ét+i)

- **Critical path:**
  1. At time t, receive (st, rt) and determine c(t)
  2. Retrieve parameters for calendar type c(t)
  3. Update M and Σ using (10-11) with prediction error
  4. For prediction horizon L, iterate Theorem 1 to generate ŝt+1,...,ŝt+L

- **Design tradeoffs:**
  - Forgetting factor λ: Higher values (→1.0) increase stability but reduce adaptivity; lower values increase adaptivity but may cause oscillation. Paper uses λs=0.8, λr=0.7.
  - Calendar granularity: More types (e.g., 48) capture finer patterns but require more parameters and more data per type.
  - Observation vector dimension R: Paper uses R=3 features per entity; higher R increases expressiveness but risks overfitting.

- **Failure signatures:**
  - Covariance matrix becoming singular or near-singular → numerical instability in matrix inversions
  - MAPE degrading over time → λ may be too low (forgetting useful history) or concept drift undetected
  - Cross-entity predictions worse than single-task → entities may not share meaningful patterns; consider entity clustering
  - Calendar types with insufficient data → parameters don't converge; merge similar calendar types

- **First 3 experiments:**
  1. **Single-entity baseline:** Run the single-task version (reference [19]) on each entity independently to establish baseline MAPE/RMSE. Verify multi-task gains are real.
  2. **Synthetic correlation test:** Generate 3-entity synthetic data with known covariance structure. Verify learned Σ converges to ground truth; test break conditions with uncorrelated entities.
  3. **Ablation on forgetting factors:** Grid search λ ∈ {0.5, 0.7, 0.8, 0.9, 0.95, 0.99} on validation period. Plot MAPE vs. λ to confirm optimal range; check if optimal λ varies by dataset characteristics.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the forgetting factors (λs, λr) be adaptively updated in real-time rather than fixed by prior inspection?
- Basis in paper: Section IV.A states that for simplicity, the forgetting factors were set to fixed values (0.8 and 0.7) by "inspect[ing] one dataset and then we apply the same values in all datasets."
- Why unresolved: The paper does not provide a mechanism for the model to automatically adjust its memory window (plasticity) in response to varying rates of concept drift in different entities or time periods.
- What evidence would resolve it: An extension of the recursive algorithm that treats λ as a dynamic state variable, along with experiments showing improved performance or stability without manual tuning.

### Open Question 2
- Question: How does the computational complexity scale with the number of entities K, particularly regarding the inversion of covariance matrices?
- Basis in paper: The prediction step (Theorem 1, Eq. 13) requires inverting matrices involving covariance matrices Σ ∈ R^(K×K), while the experiments were limited to small K values (5 to 8 entities).
- Why unresolved: The paper does not analyze the algorithm's efficiency or numerical stability when applied to large-scale smart grid deployments involving thousands of smart meters.
- What evidence would resolve it: A theoretical complexity analysis relative to K and empirical runtime results on datasets with significantly larger K (e.g., hundreds or thousands of entities).

### Open Question 3
- Question: How does the performance of this vector-valued HMM approach compare to modern deep learning-based probabilistic forecasting techniques?
- Basis in paper: The literature review references deep learning approaches for probabilistic forecasting (Refs [2] and [18]), but the experimental evaluation is limited to Multi-task Gaussian Processes (MTGP) and Kernel-based methods (KMT).
- Why unresolved: Without benchmarking against neural networks (e.g., LSTMs, Temporal Fusion Transformers), it is unclear if the proposed statistical method offers a competitive advantage in accuracy or uncertainty quantification for complex, non-linear patterns.
- What evidence would resolve it: Comparative metrics (RMSE, MAPE, CRPS) on the same datasets against state-of-the-art deep learning baselines.

## Limitations
- The feature transform function u_r(r_t,k) determining how temperature observations are encoded for each entity is not explicitly defined in the paper.
- Covariance initialization with Σ0=0 may cause numerical instability during early iterations, though this initialization challenge is not addressed.
- Experimental results show strong performance but lack statistical significance testing across datasets, making it unclear whether observed improvements are consistent or dataset-dependent.

## Confidence

- **High confidence:** The theoretical framework of vector-valued HMMs for multi-task learning is well-grounded in the literature. The recursive update mechanism follows established online learning principles.
- **Medium confidence:** The experimental methodology is reproducible with the specified datasets, though the exact implementation details for feature transformations and calendar type construction require careful interpretation.
- **Low confidence:** The generalization claims across diverse datasets (GEFCom2017, ISO-NE, SMART) are supported by aggregate metrics but lack per-dataset statistical validation or sensitivity analysis.

## Next Checks

1. Implement the single-task baseline (reference [19]) on each entity independently to establish proper comparison baseline and verify the claimed multi-task improvements are statistically significant.
2. Conduct sensitivity analysis on forgetting factors λ by testing a broader grid (0.5 to 0.99) to confirm the reported values (0.8, 0.7) are optimal across all datasets, not just GEFCom2017.
3. Test the model's performance on synthetically generated data with known cross-entity correlations to verify the covariance learning mechanism accurately captures ground truth relationships under controlled conditions.