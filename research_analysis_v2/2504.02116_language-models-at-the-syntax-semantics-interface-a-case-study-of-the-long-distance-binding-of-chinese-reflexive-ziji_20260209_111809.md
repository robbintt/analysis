---
ver: rpa2
title: 'Language Models at the Syntax-Semantics Interface: A Case Study of the Long-Distance
  Binding of Chinese Reflexive ziji'
arxiv_id: '2504.02116'
source_url: https://arxiv.org/abs/2504.02116
tags:
- language
- binding
- ziji
- data
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates whether language models can effectively
  resolve the complex binding patterns of the Mandarin Chinese reflexive ziji, which
  are constrained by both syntactic and semantic factors. The research constructs
  a dataset of 240 synthetic sentences and 320 natural sentences from the BCC corpus,
  then evaluates 21 language models against this dataset.
---

# Language Models at the Syntax-Semantics Interface: A Case Study of the Long-Distance Binding of Chinese Reflexive ziji

## Quick Facts
- arXiv ID: 2504.02116
- Source URL: https://arxiv.org/abs/2504.02116
- Reference count: 25
- Primary result: Language models fail to consistently replicate human-like judgments on complex Chinese reflexive binding, relying on sequential cues rather than full syntactic or semantic understanding

## Executive Summary
This study investigates whether language models can effectively resolve the complex binding patterns of the Mandarin Chinese reflexive ziji, which are constrained by both syntactic and semantic factors. The research constructs a dataset of 240 synthetic sentences and 320 natural sentences from the BCC corpus, then evaluates 21 language models against this dataset. Results are compared to judgments from native Mandarin speakers. Key findings show that none of the language models consistently replicate human-like judgments. The models tend to rely heavily on sequential cues rather than fully grasping syntax or semantics, and they show better understanding of noun-related semantics compared to verb-related semantics.

## Method Summary
The study evaluates 21 pre-trained language models (encoder-only, decoder-only, and encoder-decoder architectures) on their ability to resolve binding patterns of the Chinese reflexive ziji across six constraint types. Models are tested on both synthetic and natural sentences using perplexity (for autoregressive models) or pseudo-perplexity (for masked models) to determine preferred binding interpretations. Human judgments from 24 native speakers serve as the gold standard. The evaluation uses minimal pairs embedded in "If X, then Y" templates to test binding interpretations without explicit coreference markers.

## Key Results
- None of the language models consistently replicate human-like judgments on ziji binding
- Models rely heavily on sequential cues rather than fully grasping syntax or semantics
- Models show better understanding of noun-related semantics (animacy) compared to verb-related semantics (verb orientation)
- Architecture-dependent binding preferences: encoder-only models favor long-distance antecedents, decoder-only models favor local antecedents

## Why This Works (Mechanism)

### Mechanism 1: Sequential Cue Reliance
- Claim: Models use linear proximity heuristics rather than abstract syntactic constraints
- Mechanism: Models assign higher probability to antecedents based on string-adjacent patterns learned during pretraining, bypassing hierarchical syntactic structure
- Evidence: "existing language models tend to rely heavily on sequential cues, though not always favoring the closest strings"

### Mechanism 2: Differential Semantic Sensitivity (Nouns > Verbs)
- Claim: Models encode noun animacy constraints more robustly than verb-related semantic constraints
- Mechanism: Animacy has clearer distributional markers than verb reflexivity, which requires nuanced predicate-argument semantics
- Evidence: "They tend to be more sensitive to noun-related than verb-related semantics"

### Mechanism 3: Architecture-Dependent Binding Preferences
- Claim: Encoder-only models favor long-distance antecedents; decoder-only models favor local antecedents
- Mechanism: Bidirectional attention allows global context integration, biasing toward matrix subjects; causal attention emphasizes recent context, biasing toward local subjects
- Evidence: "most of the encoder-only models prefer long-distance binders while decoder-only models prefer local binding"

## Foundational Learning

- Concept: Binding Theory and Long-Distance Reflexives
  - Why needed here: ziji violates Principle A (local binding only), requiring understanding of blocking effects, animacy, subject orientation, and verb orientation
  - Quick check: Can you explain why "Jack knew that I trusted myself" blocks long-distance binding to "Jack"?

- Concept: Perplexity and Pseudo-Perplexity Evaluation
  - Why needed here: Study uses PPL for autoregressive models and PPPL for masked models to assess sentence acceptability
  - Quick check: Why does pseudo-perplexity require bidirectional context while perplexity uses only preceding context?

- Concept: Minimal Pair Design with In-Context Disambiguation
  - Why needed here: Study embeds target sentences in "If X, then Y" templates to test binding interpretations without explicit coreference markers
  - Quick check: How does the minimal pair method isolate binding preferences from general fluency judgments?

## Architecture Onboarding

- Component map: bert-base-chinese, chinese-lert, chinese-pert, mengzi-bert, ernie, mBERT, XLM-R (encoder-only) -> mT5-small, mT5-large (encoder-decoder) -> GPT2 variants, GLM-4, CPM-Generate (decoder-only)

- Critical path: Construct minimal pairs with explicit antecedent in "then" clause → Compute PPL/PPPL for each sentence in pair → Lower PPL = model's preferred binding interpretation → Compare against human judgment baseline

- Design tradeoffs: Synthetic data controlled but may not reflect training distribution; natural data realistic but more confounds; prompting vs. perplexity not directly comparable

- Failure signatures: Models pass Animacy Effect (87.5% avg) but fail Verb Orientation (40.2% reflexive verbs, 70.5% non-reflexive); Blocking Effect predictions correlate with baseline local-binding preference

- First 3 experiments: 1) Replicate Blocking Effect comparison to confirm linear bias vs. constraint learning; 2) Test Animacy Effect with reversed order to disentangle animacy knowledge from recency bias; 3) Evaluate Verb Orientation with matched syntactic frames but varying verb semantics

## Open Questions the Paper Calls Out

1. Why do language models perform better on natural data than synthetic data for binding tasks, despite natural data containing longer sequences and more distractors?

2. Can language models generalize complex binding constraints based on exposure to more frequent, simpler linguistic phenomena?

3. Why does the Subject Orientation (SO) constraint not exhibit a clear linear bias in language models, unlike other binding patterns?

## Limitations

- Heavy reliance on synthetic sentence templates that may not capture natural Chinese text patterns
- Evaluation methodology for closed-source models (prompting-based) is less controlled than perplexity-based approach for open-source models
- Observed position bias in GPT-3.5/4o suggests evaluation instability

## Confidence

- High Confidence: Models show linear biases in binding resolution
- Medium Confidence: Models encode noun-related semantics better than verb-related semantics
- Low Confidence: Broader claim that models fail to capture syntax-semantics interface

## Next Checks

1. Design minimal pairs where linear distance is controlled but hierarchical structure differs to test whether encoder-only models consistently prefer long-distance binders

2. Compare model performance on high-frequency vs. low-frequency verb classes in Verb Orientation experiments to distinguish distributional learning from semantic understanding

3. Evaluate the same models on Turkish reflexive binding to determine whether observed sequential biases are language-specific or general limitations