---
ver: rpa2
title: QUBO-based training for VQAs on Quantum Annealers
arxiv_id: '2509.01821'
source_url: https://arxiv.org/abs/2509.01821
tags:
- training
- quantum
- accuracy
- points
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a QUBO-based training method for variational
  quantum algorithms (VQAs) using quantum annealers. It reformulates VQA parameter
  optimization as a QUBO problem by expressing the mean squared error loss in terms
  of quantum state vectors, then employs a recursive hierarchical optimization strategy
  to efficiently explore the discretized parameter space.
---

# QUBO-based training for VQAs on Quantum Annealers

## Quick Facts
- arXiv ID: 2509.01821
- Source URL: https://arxiv.org/abs/2509.01821
- Reference count: 40
- Primary result: QUBO-based VQA training achieves comparable or superior accuracy to classical optimizers while reducing training time through hierarchical quantum annealing

## Executive Summary
This paper introduces a QUBO-based training method for variational quantum algorithms that reformulates parameter optimization as a quadratic unconstrained binary optimization problem solvable by quantum annealers. The approach addresses limitations of classical VQA training, including barren plateaus and high computational cost, by expressing the mean squared error loss in terms of quantum state vectors and employing a recursive hierarchical optimization strategy. Experiments on Iris, Heart Disease, and Diabetes datasets demonstrate that the method achieves comparable or superior validation accuracy to classical and evolutionary optimizers while significantly reducing training time, with performance scaling favorably for larger datasets and adaptive control over accuracy versus computational cost.

## Method Summary
The method reformulates VQA parameter optimization as a QUBO problem by expressing the mean squared error loss using quantum state vector distances, then discretizes continuous angles into binary variables with uniqueness constraints. A hierarchical recursive search strategy partitions the parameter space into d segments per recursion level, evaluates w validation points within each region, and progressively refines around promising solutions. The approach leverages quantum annealing hardware to minimize the QUBO energy corresponding to the loss function, with adaptive control over accuracy versus computational cost through configurable partitions, validation points, and recursion depth.

## Key Results
- QUBO-based training achieves comparable or superior validation accuracy to classical optimizers (SPSA, ADAM, COBYLA) and evolutionary methods across all tested datasets
- Training time is significantly reduced compared to classical methods, with the largest efficiency gains observed on the Diabetes dataset
- Hierarchical optimization with higher partitions (d=3) and validation points (w=3) yields the best accuracy, though at increased computational cost
- Performance scales favorably with dataset size, demonstrating better accuracy and time efficiency on larger datasets

## Why This Works (Mechanism)

### Mechanism 1: QUBO Reformulation via State Vector Distance
Express both expected and observed quantum states as vectors in Hilbert space. The Euclidean distance squared between state vectors becomes a sum of squared amplitude differences. When the variational circuit's output is expressed as Q|ψ⟩ where Q is a parameterized operator, the resulting expression is quadratic in the encoded parameters—hence castable as QUBO. The heuristic substitution iθ → θ (converting trigonometric to hyperbolic functions) maintains sufficient fidelity for optimization despite breaking unitarity.

### Mechanism 2: Hierarchical Recursive Search
Partition each parameter's range into d segments per recursion level. Within each region, evaluate w validation points. Select the best-performing region as the pivot for the next level, narrowing the search range (e.g., by 50%). This balances global exploration (broad initial coverage) with local exploitation (refinement around promising solutions).

### Mechanism 3: Gradient-Free Optimization via Quantum Tunneling
Rather than following gradients (which vanish in barren plateaus), quantum annealing explores the combinatorial parameter space via quantum tunneling, potentially escaping local minima that trap gradient descent. The annealer directly minimizes the QUBO energy corresponding to the MSE loss.

## Foundational Learning

- **Concept: QUBO (Quadratic Unconstrained Binary Optimization)**
  - Why needed: The entire training framework reformulates VQA optimization as a QUBO problem solvable by quantum annealers
  - Quick check: Can you explain why a constraint like "exactly one binary variable per angle must equal 1" requires penalty terms rather than hard constraints in QUBO?

- **Concept: Variational Quantum Algorithms (VQAs) and Ansätze**
  - Why needed: The method assumes familiarity with parameterized quantum circuits, cost functions, and the structure of ansatz operators
  - Quick check: Given a TwoLocal ansatz with 3 qubits and 2 rotation gates, how many parameterized angles require optimization?

- **Concept: Quantum Annealing and Adiabatic Evolution**
  - Why needed: The optimization leverages quantum annealing hardware; understanding energy landscape traversal and tunneling is essential
  - Quick check: How does quantum tunneling differ from thermal hopping in classical simulated annealing for escaping local minima?

## Architecture Onboarding

- **Component map:**
  1. Data preprocessing: PCA dimensionality reduction → match qubit count
  2. QUBO construction: Ansatz operator symbolic representation → MSE formulation → constraint encoding
  3. Annealer execution: Submit QUBO → sample low-energy states
  4. Hierarchical controller: Manage recursion levels, partition boundaries, validation point selection
  5. Validation loop: Execute VQA with candidate parameters → update best solution → refine search region

- **Critical path:**
  1. Symbolic extraction of the ansatz operator (Section 3.1.2)
  2. Hyperbolic reformulation and QUBO encoding
  3. Recursive search parameter selection (d, w, L)
  4. Annealer integration and result decoding

- **Design tradeoffs:**
  - Partitions (d): Higher d improves exploration but increases QUBO variable count linearly (a · d)
  - Validation points (w): Higher w increases accuracy but scales executions exponentially (w^a)
  - Recursion depth (L): Deeper search improves precision with diminishing returns (logarithmic accuracy gains, polynomial time cost)

- **Failure signatures:**
  - Accuracy plateaus or declines with increased levels → over-refinement in wrong region; reduce L or increase w
  - Training time grows superlinearly → excessive partitions; reduce d
  - No improvement over baseline (configuration O) → QUBO formulation error or constraint violation
  - High variance across runs → insufficient validation points; increase w

- **First 3 experiments:**
  1. Baseline replication: Implement configuration O (L=1, d=1, w=1) on Iris subset to validate QUBO construction matches brute-force search
  2. Parameter sweep: On Diabetes dataset, test configurations B (L=1, d=2, w=2) vs H (L=1, d=3, w=3) vs D (L=1, d=2, w=4) to identify Pareto-optimal accuracy/time tradeoff
  3. Noise robustness test: Introduce 10% and 20% noise in annealer simulation on Heart Disease dataset; verify whether controlled noise improves generalization as suggested in Section 4.7

## Open Questions the Paper Calls Out

- Can the proposed QUBO-based training method generalize effectively to inherently quantum problems rather than just classical classification datasets? The experimental evaluation is limited to classical machine learning datasets (Iris, Heart Disease, Diabetes) using PCA for feature encoding.

- To what extent does structured or informed initialization mitigate the bias caused by random initialization in the hierarchical search? The authors identify this as a factor hindering convergence to optimal solutions but do not propose or test specific structured initialization methods.

- Can advanced algebraic techniques efficiently derive diagonal representations for general parameterized unitary operators to simplify the QUBO construction? Deriving this representation is currently described as intractable for large systems due to the exponential size of the Hilbert space.

- Can adaptive heuristics for partitioning and search depth optimize the trade-off between superlinear computational cost and logarithmic accuracy gains? The paper observes that computational cost scales polynomially while accuracy gains diminish, but it relies on static parameter configurations.

## Limitations

- The QUBO reformulation relies on a heuristic substitution (iθ → θ) that sacrifices theoretical rigor for practical implementability, lacking mathematical guarantees on solution quality
- The hierarchical optimization strategy introduces hyperparameter sensitivity requiring dataset-specific tuning of partitions, validation points, and recursion depth
- The approach faces scalability challenges for larger qubit counts where Hilbert space scaling becomes prohibitive

## Confidence

- QUBO reformulation mechanism: Medium (strong empirical support but heuristic basis)
- Hierarchical search performance: High (consistent experimental validation across datasets)
- Quantum tunneling advantage: Low-Medium (plausible but not directly isolated from discretization effects)

## Next Checks

1. Compare solution quality between exact continuous optimization and the discretized QUBO approach on small instances where brute-force search is feasible
2. Systematically vary the iθ → θ substitution parameter to quantify its impact on optimization accuracy and identify breaking points
3. Conduct ablation studies isolating the quantum annealing contribution from classical hierarchical search benefits by comparing against simulated annealing implementations