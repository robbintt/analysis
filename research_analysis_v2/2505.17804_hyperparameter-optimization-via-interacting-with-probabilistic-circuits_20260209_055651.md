---
ver: rpa2
title: Hyperparameter Optimization via Interacting with Probabilistic Circuits
arxiv_id: '2505.17804'
source_url: https://arxiv.org/abs/2505.17804
tags:
- ibo-hpc
- user
- knowledge
- optimization
- iteration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces IBO-HPC, a novel interactive Bayesian optimization
  method that leverages probabilistic circuits (PCs) as surrogate models for hyperparameter
  optimization (HPO). Unlike existing interactive BO methods that rely on acquisition
  function weighting schemes, IBO-HPC uses PCs' tractable conditional sampling to
  generate candidate configurations without inner-loop optimization, ensuring accurate
  reflection of user beliefs.
---

# Hyperparameter Optimization via Interacting with Probabilistic Circuits

## Quick Facts
- arXiv ID: 2505.17804
- Source URL: https://arxiv.org/abs/2505.17804
- Reference count: 40
- One-line primary result: IBO-HPC achieves 2-10× speedup in convergence compared to strong baselines when beneficial user knowledge is provided for hyperparameter optimization.

## Executive Summary
This paper introduces IBO-HPC, an interactive Bayesian optimization method that leverages probabilistic circuits (PCs) as surrogate models for hyperparameter optimization. Unlike existing interactive BO methods that rely on acquisition function weighting schemes, IBO-HPC uses PCs' tractable conditional sampling to generate candidate configurations without inner-loop optimization. The method is both feedback-adhering (incorporating user knowledge accurately) and efficacious (ensuring user input affects the optimization). Theoretical analysis shows IBO-HPC minimizes simple regret and converges proportionally to expected improvement. Empirical evaluation across 10 diverse HPO/NAS tasks demonstrates IBO-HPC is competitive with strong baselines without user interaction, and outperforms them when beneficial user knowledge is provided, achieving 2-10× speedup in convergence.

## Method Summary
IBO-HPC is an interactive Bayesian optimization framework that uses probabilistic circuits as surrogate models for hyperparameter optimization. The method maintains a joint distribution over hyperparameters and evaluation scores, represented as a tractable probabilistic circuit. When a user provides prior knowledge about hyperparameters, IBO-HPC conditions the PC on this information to generate candidate configurations. The key innovation is using PCs' exact conditioning capability to eliminate the need for acquisition function optimization. The method includes a decay mechanism that allows recovery from misleading user feedback by progressively reducing the influence of user knowledge over time. The PC surrogate is updated periodically (every L iterations) to balance exploration and exploitation.

## Key Results
- IBO-HPC is competitive with strong baselines (SMAC, TPE, BOPrO) without user interaction
- With beneficial user knowledge, IBO-HPC achieves 2-10× speedup in convergence compared to baselines
- The decay mechanism enables reliable recovery from misleading user feedback within 20-50 iterations
- Theoretical analysis shows convergence proportional to expected improvement with feedback-adherence guarantees

## Why This Works (Mechanism)

### Mechanism 1: Probabilistic Circuits as Tractable Joint Surrogates
Replacing GP/RF surrogates with probabilistic circuits enables exact conditioning without inner-loop optimization. PCs encode a joint distribution over hyperparameters H and evaluation scores F as a computational graph of sum and product nodes. Decomposability (non-overlapping scopes at product nodes) and smoothness (identical scopes at sum node children) guarantee tractable marginalization and conditioning in linear time. The surrogate s(H,F) is fitted via maximum likelihood using LearnSPN, which recursively splits data via clustering and independence tests.

### Mechanism 2: Acquisition-Free Selection via Conditional Sampling
IBO-HPC conditions the PC on the best observed score f* and samples directly from the conditional distribution s(H|F=f*), eliminating the need for acquisition function optimization. This biases candidates toward regions with high density under configurations achieving good scores. Exploration emerges naturally from variance in the PC's mixture components and from the L-step surrogate freeze (retraining only every L iterations), which preserves uncertainty.

### Mechanism 3: Feedback-Adhering Interactive Policy with Decay Recovery
User knowledge is incorporated by conditioning the PC on user priors q(Ĥ) with guaranteed adherence, while a decay factor γ enables recovery from misleading feedback. When user provides prior q(Ĥ) at iteration T, candidate generation becomes: γ^t·ρ·s(H'|Ĥ,F=f*)·q(Ĥ) + (1-γ^t·ρ)·s(H|F=f*). The Bernoulli(ρ) with decay γ progressively reduces influence of user knowledge, with theoretical guarantees that the marginal over Ĥ matches q(Ĥ) exactly.

## Foundational Learning

- **Bayesian Optimization Fundamentals**: Understanding surrogate models, selection policies, and exploration-exploitation is prerequisite. Quick check: Can you explain why GP-based BO requires acquisition function optimization, and what EI (Expected Improvement) measures?
- **Probabilistic Circuits (Sum-Product Networks)**: PCs are the core surrogate model; understanding their structure (sum/product nodes), properties (smoothness, decomposability), and operations (inference, marginalization, conditioning, sampling) is essential. Quick check: Given a decomposable PC, explain why marginalization can be computed in linear time by setting leaf distributions to 1.
- **Mixed Sum-Product Networks for Hybrid Domains**: HPO search spaces contain both discrete and continuous hyperparameters; MSPNs with piecewise polynomial leaves handle this. Quick check: Why can't standard SPNs with Gaussian leaves model discrete variables, and how do piecewise polynomial leaves address this?

## Architecture Onboarding

- Component map:
  Initial Samples J ~ u(H) → Evaluate f(θ) → Dataset D = {(θ,f(θ))} → Fit PC s(H,F) via LearnSPN → User Prior q(Ĥ)? → Sample θ* ~ s(H|F=f*) → Evaluate f(θ*), update D

- Critical path: The conditional sampling operation (Eq. 1) is the core—this replaces acquisition optimization. Ensure PC structure learning (LearnSPN clustering + independence tests) produces decomposable circuits; verify conditioning correctly propagates evidence f* bottom-up then samples top-down.

- Design tradeoffs:
  - L (surrogate freeze iterations): Higher L increases exploration via preserved uncertainty but risks stale models; paper uses L=20 with minimal effect
  - Decay γ: Higher γ maintains user influence longer but slows recovery; γ=0.9 recommended
  - N×B candidate generation: N=conditions from prior, B=samples per condition; paper finds B=1 works well
  - PC leaf variance: Too-low variance causes local optima trapping; may require minimum variance floors

- Failure signatures:
  - Stagnation in local optimum: PC leaves have near-zero variance; sampling concentrates on narrow region
  - Non-adherence to user prior: If PC marginal over Ĥ differs significantly from q(Ĥ) due to structure constraints
  - Slow recovery from bad feedback: Decay γ too high for task horizon
  - PC structure learning failure: Independence test threshold too strict or clustering fails on small initial data

- First 3 experiments:
  1. Validation on synthetic function: Implement IBO-HPC on Branin (2D continuous) without user interaction. Compare against GP-EI and SMAC. Verify convergence within 100 evaluations.
  2. Feedback adherence test: Provide strong Gaussian prior on one dimension of Branin with mean offset from true optimum. Measure KL divergence between selected values and user prior in first 10 iterations.
  3. Recovery mechanism stress test: Provide misleading prior (high density on worst-known region) at iteration 5 with γ=0.9. Plot regret over time vs. no-interaction baseline.

## Open Questions the Paper Calls Out

- **Hyperparameter Transfer Learning**: The authors note that IBO-HPC only allows users to provide external knowledge about a given HPO task but does not provide a way to leverage information from previous HPO runs performed on different tasks. Therefore, a promising prospect for future research is the usage of PCs to enable hyperparameter transfer learning.

- **Low Variance Handling**: IBO-HPC can get stuck in local optima if the surrogate PC's leaves exhibit too low variance for a given task due to its sampling-based exploration. Although this can be tackled by setting a minimal variance or introducing a minimum variance schedule, this introduces new hyperparameters in IBO-HPC itself.

- **Correlation Incorporation**: Other forms of user knowledge are possible, such as specifying beliefs about possible correlations between hyperparameters or between hyperparameters and the evaluation score. The current implementation only supports priors over individual hyperparameter values.

## Limitations

- PC structure learning details for hybrid domains (leaf distribution types, depth constraints) are not fully specified, which could affect tractability claims
- The method can get stuck in local optima if PC leaves exhibit too low variance, requiring additional hyperparameters to address
- Theoretical guarantees assume smoothness and decomposability hold exactly, but real-world data may violate these assumptions

## Confidence

- **High Confidence**: PC surrogate tractability and conditional sampling mechanism (well-defined in theory, implemented in related work)
- **Medium Confidence**: Theoretical convergence guarantees (proofs provided but depend on idealized assumptions)
- **Medium Confidence**: Empirical performance claims (results competitive but depend on specific benchmark implementations)

## Next Checks

1. **Synthetic Function Test**: Implement IBO-HPC on Branin function (2D continuous) without user interaction. Verify convergence within 100 evaluations and that PC captures multimodal structure.

2. **Feedback Adherence Test**: Provide Gaussian prior on Branin's x-dimension with mean offset from optimum. Measure KL divergence between selected values and user prior in first 10 iterations; compare against πBO and BOPrO.

3. **Recovery Mechanism Stress Test**: Provide misleading prior (high density on worst-known region) at iteration 5 with γ=0.9. Plot regret over time vs. no-interaction baseline; verify recovery within 50 iterations.