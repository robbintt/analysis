---
ver: rpa2
title: A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language
  Models
arxiv_id: '2512.05498'
source_url: https://arxiv.org/abs/2512.05498
tags:
- code
- llms
- generation
- java
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents iEcoreGen, a hybrid approach that integrates
  template-based code generation from Eclipse Modeling Framework (EMF) with Large
  Language Models (LLMs) to address the limitations of both methods. While template-based
  approaches ensure correctness but lack flexibility for complex requirements, LLMs
  offer adaptability but produce unreliable code.
---

# A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language Models

## Quick Facts
- arXiv ID: 2512.05498
- Source URL: https://arxiv.org/abs/2512.05498
- Reference count: 0
- Key outcome: Hybrid EMF+LLM approach surpasses pure LLM baselines on functional correctness while maintaining comparable compilation rates

## Executive Summary
This paper presents iEcoreGen, a hybrid approach that integrates template-based code generation from Eclipse Modeling Framework (EMF) with Large Language Models (LLMs) to address the limitations of both methods. While template-based approaches ensure correctness but lack flexibility for complex requirements, LLMs offer adaptability but produce unreliable code. iEcoreGen decomposes requirements into method-level specifications, uses EMF templates to generate initial Java code, and employs LLMs to complete and fix unimplemented methods. Evaluation on twenty code-generation tasks across five LLMs shows that iEcoreGen surpasses LLM-only baselines on pass@k (functional correctness) while maintaining comparable performance on compilation@k, demonstrating the promise of LLM-enhanced model-driven development.

## Method Summary
iEcoreGen implements a four-stage pipeline that combines EMF template generation with LLM completion. First, it decomposes natural language requirements into structured method specifications using an LLM. Second, it generates Java code skeletons from Ecore models using EMF templates with suppressInterfaces=true. Third, it compresses the skeleton code via AST manipulation, extracts contextual signatures from related classes, and uses an LLM to complete method bodies. Finally, it iteratively fixes compilation errors by feeding error messages back to the LLM until all errors are resolved or maximum retries are reached. The approach uses pass@k and compilation@k metrics with n=5 samples per problem to evaluate functional correctness and compilation success.

## Key Results
- iEcoreGen achieves superior pass@k scores compared to pure LLM baselines across all tested models
- Context extraction significantly improves compilation success, with a 45% drop when removed (0.75 â†’ 0.55 compilation@1)
- Iterative code fixing resolves 35% of compilation errors that would otherwise fail (compilation@1 drops from 1.0 to 0.65 when disabled)
- The approach maintains high compilation@k rates comparable to pure LLM methods while achieving better functional correctness

## Why This Works (Mechanism)

### Mechanism 1: Structural Constraint via Template Scaffolding
Offloading the generation of class structure and boilerplate to deterministic templates reduces the LLM's "problem-solving scope," thereby lowering hallucination rates for syntax and APIs. The EMF generator produces a syntactically correct Java skeleton (getters, setters, signatures), and the LLM is restricted to filling method bodies. This constrains the search space for the LLM, preventing it from inventing non-existent imports or invalid class hierarchies. Failure occurs if the required logic demands structural changes that the template did not foresee and the LLM is restricted from creating.

### Mechanism 2: Contextual Grounding via Extraction
Injecting signatures of related classes into the prompt significantly mitigates "Unresolved Symbol" errors and API misuse. Before prompting the LLM to complete a method, iEcoreGen traverses the Ecore model to collect context (signatures of superclasses and associated classes). This explicit context window update prevents the LLM from guessing and often hallucinating method names like `getId()` vs `id`. If the logic requires understanding the behavior (implementation details) of a related class rather than just its signature, this mechanism may fail to prevent logical errors.

### Mechanism 3: Iterative Repair via Compiler Feedback
Feeding compilation errors back to the LLM creates a feedback loop that resolves syntax errors that escaped the initial generation. The system compiles the merged code, and if errors exist, it extracts the error type, line number, and message, sending them back to the LLM with a "fix" prompt. This iteratively constrains the output until it satisfies the compiler. Complex errors (e.g., type mismatches across multiple dependent files) may exceed the local fixing context provided to the LLM, causing retry loops without resolution.

## Foundational Learning

- **Concept: Eclipse Modeling Framework (EMF) & Ecore**
  - Why needed here: The paper relies on Ecore as the "blueprint" (meta-model). You cannot understand the input format or the constraints of the generated Java code without grasping that Ecore defines classes/attributes/references structurally.
  - Quick check question: Can you explain why an EMF-generated boolean getter is named `isX()` instead of `getX()`, and how this affects LLM prompts?

- **Concept: Abstract Syntax Tree (AST) Manipulation**
  - Why needed here: iEcoreGen uses ASTs to "compress" code (removing bodies) and "merge" LLM output back into the EMF skeleton. Understanding this serialization is key to implementing the pipeline.
  - Quick check question: Why is replacing code via text-diffing risky in this architecture compared to the AST-based merge used in Section 2.3?

- **Concept: Pass@k Metric**
  - Why needed here: The results measure "functional correctness" via pass@k. You need to understand that this measures the probability of finding at least one correct solution in `k` attempts.
  - Quick check question: If an LLM generates 5 samples (`n=5`) and 2 compile and pass tests (`c=2`), how does pass@1 roughly estimate the model's reliability?

## Architecture Onboarding

- **Component map:** NL Requirement + Ecore Model -> Requirement Decomposition (LLM) -> EMF Generation (EMF) -> Compressor (JDT) -> Context Extraction (Ecore) -> Code Completion (LLM) -> Code Fixing (LLM + JDT)
- **Critical path:** The Context Extraction (Section 2.3). While the Decomposer defines what to do, the Context Extractor defines what is available to do it. The ablation study shows the steepest drop in performance when this is removed.
- **Design tradeoffs:**
  - Suppressing Interfaces: The prototype sets `suppressInterfaces=true` to simplify the class structure for the LLM. This trades standard EMF design patterns for reduced prompt complexity.
  - Holistic Class Generation: The system processes classes one by one. This trades global project awareness for context-window manageability (avoids token limits).
- **Failure signatures:**
  - Requirement Omission: The LLM generates valid code that misses a functional spec (e.g., failing to add an object to a list). This is the most common error (Section 3.4).
  - Operation Misuse: The LLM hallucinates reflective API calls (e.g., using wrong string keys in `eGet`) because it lacks deep EMF training data (Section 3.4).
- **First 3 experiments:**
  1. Isolate the Decomposer: Input a complex requirement and an Ecore model into the "Requirement Decomposition" prompt. Verify if the generated docstrings strictly adhere to the "Input/Output/Pre-condition" structure.
  2. Test the Context Limit: Run the "Code Completion" step on a class with high coupling (many references). Intentionally disable the "Context Extraction" module and measure the rise in "Unresolved Symbol" errors.
  3. Stress Test the Fixer: Introduce a subtle type error into the generated Java code (e.g., assigning a `String` to an `int`). Run the "Code Fixing" loop to see if it resolves the issue locally or hallucinates a cast.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the requirement decomposition phase be refined to minimize "Requirement Omission" errors, which currently account for 42.8% of all failures?
- Basis in paper: [explicit] The authors state, "In the future, we plan to enhance requirement decomposition... as the error analysis has highlighted clear opportunities for improvement."
- Why unresolved: The current method relies on LLMs to deduce specifications from natural language, but the evaluation (Table 5) shows this is the most frequent error category, where generated code simply misses specified logic.
- What evidence would resolve it: A modified version of iEcoreGen implementing a stricter decomposition validation step that results in a statistically significant reduction of the "Requirement Omission" error rate compared to the current baseline.

### Open Question 2
- Question: Does iEcoreGen maintain its performance advantage over pure LLM baselines when applied to closed-source LLMs and industrial-scale projects?
- Basis in paper: [explicit] The authors acknowledge, "We will evaluate more realistic problems... We will further strengthen our evaluation by incorporating closed-source LLMs and more complicated benchmarks."
- Why unresolved: The current study is limited to open-source models and a benchmark with a maximum of 11 classes and 483 words per requirement, which may not reflect the complexity of real-world enterprise systems where hybrid approaches are most needed.
- What evidence would resolve it: An evaluation using models like GPT-4 or Claude on a dataset of larger, real-world Ecore models (e.g., >20 classes) showing consistent pass@k improvements similar to those observed in the current experimental setup.

### Open Question 3
- Question: Can more sophisticated context extraction strategies improve functional correctness compared to the current "simple strategy" of joining method signatures?
- Basis in paper: [explicit] Section 2.3 states, "Currently, iEcoreGen employs a simple strategy for context extraction... [joining] signatures of public methods," and Section 5 lists "enhance... context extraction" as future work.
- Why unresolved: While the ablation study shows removing this component hurts performance, the current implementation provides only structural signatures. It is unknown if providing semantic context or usage examples would further mitigate the "Operation Misuse" errors (14.5% of total).
- What evidence would resolve it: An ablation study comparing the current signature-based context extraction against semantic retrieval methods (e.g., RAG or including method bodies), measuring the reduction in "Operation Misuse" and "Unresolved Symbols" errors.

### Open Question 4
- Question: What specific training or prompting techniques are required to improve the compilation rates of smaller LLMs regarding strict EMF coding conventions?
- Basis in paper: [inferred] Section 3.2 notes that smaller models (Mistral, Llama) showed lower compilation@k scores because they "may lack sufficient EMF-specific knowledge," and suggests "Future work could focus on how to provide MDE knowledge for LLMs."
- Why unresolved: iEcoreGen relies on the LLM adhering to specific styles (e.g., `isX()` for boolean getters), which smaller models failed to follow, suggesting the current instructions in the prompt are insufficient for lower-capacity models.
- What evidence would resolve it: A comparative study where smaller LLMs are fine-tuned on EMF codebases or provided with few-shot EMF examples, resulting in compilation@k scores comparable to larger models like Deepseek.

## Limitations
- The iterative repair mechanism may struggle with multi-file type errors that require holistic understanding beyond local fixes
- Performance metrics may be influenced by the specific benchmark selection and test case construction methodology
- The approach's scalability to very large models or complex inter-class dependencies has not been established

## Confidence
- **High Confidence:** The core hybrid architecture combining EMF templates with LLM completion is sound and demonstrably improves over pure LLM approaches
- **Medium Confidence:** The mechanism of structural constraint via template scaffolding effectively reduces hallucination rates, though this may vary with template quality
- **Low Confidence:** The scalability of the approach to very large models or complex inter-class dependencies has not been established

## Next Checks
1. Test the context extraction mechanism with a class that requires deep behavioral understanding of related classes rather than just signature knowledge
2. Introduce multi-file compilation errors to evaluate whether the iterative repair mechanism can handle cross-file dependencies
3. Apply the hybrid approach to a significantly larger Ecore model (20+ classes) to assess scalability and prompt length limitations