---
ver: rpa2
title: 'EDU-NER-2025: Named Entity Recognition in Urdu Educational Texts using XLM-RoBERTa
  with X (formerly Twitter)'
arxiv_id: '2504.18142'
source_url: https://arxiv.org/abs/2504.18142
tags:
- urdu
- learning
- dataset
- language
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces EDU-NER-2025, the first manually annotated
  Named Entity Recognition (NER) dataset for Urdu educational texts. It addresses
  the lack of domain-specific Urdu NER resources by providing 13 unique educational
  entity categories.
---

# EDU-NER-2025: Named Entity Recognition in Urdu Educational Texts using XLM-RoBERTa with X (formerly Twitter)

## Quick Facts
- arXiv ID: 2504.18142
- Source URL: https://arxiv.org/abs/2504.18142
- Reference count: 26
- Primary result: Fine-tuned XLM-RoBERTa achieved 98% accuracy on Urdu educational NER

## Executive Summary
This study introduces EDU-NER-2025, the first manually annotated Named Entity Recognition dataset for Urdu educational texts, containing 13 unique educational entity categories. The dataset was created from Twitter data and annotated by domain experts, achieving high inter-annotator agreement. The study evaluates multiple models including traditional ML (SVM, LR, RF), deep learning (CNN, BiLSTM), and transformer-based models (BERT, RoBERTa, XLM-RoBERTa). Fine-tuned XLM-RoBERTa achieved the highest performance at 98% accuracy, significantly outperforming traditional methods. The work establishes a robust foundation for future Urdu NER research in education and demonstrates the effectiveness of multilingual transformers for low-resource languages.

## Method Summary
The authors collected 18,455 Urdu tweets from Twitter API (2023-2024) using education-related keywords, resulting in 660,140 words and 26,730 unique vocabulary items. Three native Urdu speakers annotated the data with 13 entity categories following detailed guidelines, achieving 79% Fleiss' Kappa agreement. The dataset was preprocessed by removing special characters, punctuation, and Urdu stop words, then tokenized and stemmed. Multiple models were evaluated including SVM, LR, RF, CNN, BiLSTM, BERT, RoBERTa, and XLM-RoBERTa using 5-fold cross-validation. The XLM-RoBERTa-base model was fine-tuned with specific hyperparameters (lr=2e-5, batch_size=16, epochs=5) and achieved the highest performance at 98% accuracy across all metrics.

## Key Results
- XLM-RoBERTa achieved 98% accuracy, significantly outperforming traditional ML methods (SVM, LR, RF) and deep learning approaches (CNN, BiLSTM)
- The dataset contains 13 educational entity categories with high inter-annotator agreement (Fleiss' Kappa = 0.79)
- GloVe+CNN achieved only 6% recall, demonstrating the superiority of contextual embeddings for morphologically complex Urdu
- XLM-RoBERTa showed consistent performance across all entity classes with class-wise F1-scores ranging from 0.92 to 0.98

## Why This Works (Mechanism)

### Mechanism 1: Multilingual Pre-training Transfer for Low-Resource Languages
XLM-RoBERTa's prior exposure to 100+ languages during pre-training enables effective Urdu NER without requiring massive Urdu-specific corpora. Cross-lingual transfer occurs when representations learned from high-resource languages map to typologically similar structures in Urdu. The model leverages shared subword tokenization and contextual patterns rather than language-specific features. Urdu educational entities share structural patterns with entities in other languages that transfer across linguistic boundaries.

### Mechanism 2: Domain-Specific Annotation Schema Reduces Ambiguity
Manually crafted 13-category educational entity schema with explicit annotation guidelines reduces label ambiguity and improves model convergence. Precise entity boundaries (e.g., distinguishing "کیمسٹری ڈیپارٹمنٹ" as ORGANIZATION vs. "کیمسٹری" as COURSE) provide clean supervision signals. High inter-annotator agreement indicates consistent labeling that reduces training noise.

### Mechanism 3: Contextual Embeddings Resolve Morphological Ambiguity
XLM-RoBERTa's contextual embeddings outperform static embeddings because they disambiguate morphologically complex Urdu tokens based on surrounding context. Urdu tokens like "لیب" (lab as location vs. event) require sentential context. Bidirectional attention encodes left and right context, enabling the model to assign different representations to the same surface form in different contexts.

## Foundational Learning

- **Named Entity Recognition (NER) as Token Classification**: Understanding that NER assigns entity labels to individual tokens (or spans) using BIO/IOB tagging schemes is prerequisite to interpreting the 13-category schema and model outputs. Quick check: Given "پنجاب یونیورسٹی لاہور" (Punjab University Lahore), should the model label each token separately or the entire span as ORGANIZATION?

- **Transformer Self-Attention Mechanism**: XLM-RoBERTa's performance hinges on bidirectional attention capturing dependencies between distant tokens—critical for morphologically rich Urdu where entity boundaries depend on context. Quick check: In a 35-word Urdu tweet, how does self-attention enable the model to link a title ("پروفیسر") at position 3 to a person name at position 28?

- **Cross-Validation and Generalization**: The paper reports 5-fold cross-validation scores; understanding why k-fold is used is essential for interpreting the 98% figure as robust rather than optimistic. Quick check: If the model achieves 98% CV accuracy but only 85% on a held-out test set from a different time period, what does this indicate about dataset distribution?

## Architecture Onboarding

- **Component map**: Twitter API → Raw Urdu tweets → Preprocessing → Annotated corpus → Fine-tuned XLM-RoBERTa-base → 5-fold CV evaluation → Per-class and overall metrics

- **Critical path**: Dataset quality gates determine model ceiling; XLM-R fine-tuning with correct hyperparameters achieves reported performance; class-wise F1 analysis reveals weak entities for targeted improvement

- **Design tradeoffs**: XLM-R vs. monolingual BERT sacrifices some language-specific accuracy for multilingual coverage; 13 categories provide detail but increase label sparsity; Twitter data introduces noise but reflects real-world usage

- **Failure signatures**: GloVe+CNN collapse (6% recall) signals need for contextual models; code-mixed token errors may cause misclassification; short context ambiguity leads to higher error rates for single-word entities

- **First 3 experiments**:
  1. Fine-tune XLM-RoBERTa-base on EDU-NER-2025 with reported hyperparameters; verify 5-fold CV accuracy approaches 98%
  2. Train on subsets of entity classes to measure impact on per-class F1 and overall accuracy
  3. Evaluate the fine-tuned model on a held-out set of Urdu academic reports to assess domain transfer capability

## Open Questions the Paper Calls Out

1. **Dataset Expansion to Formal Genres**: How does model performance generalize when the EDU-NER-2025 dataset is expanded to include formal educational genres such as academic reports, lecture transcripts, and textbooks? The current dataset is constructed exclusively from Twitter data, which differs linguistically from formal educational documents.

2. **Roman Urdu and Transliterated Content**: Does the inclusion of Roman Urdu and transliterated content improve NER accuracy in informal educational discourse? The current study focuses on Urdu script, but code-mixing with English is a significant linguistic challenge that exacerbates tokenization errors.

3. **Semi-Supervised and Active Learning**: To what extent can semi-supervised or active learning approaches reduce the manual annotation burden while maintaining the 98% accuracy achieved by the fully supervised XLM-RoBERTa model? The current high performance relies on a manually annotated dataset created by domain experts, which is resource-intensive and difficult to scale.

## Limitations

- Dataset accessibility: EDU-NER-2025 is not publicly available, preventing independent validation of the claimed 98% accuracy
- Incomplete annotation schema: Only 11 of 13 entity categories are specified in evaluation metrics, creating ambiguity about the full classification framework
- Temporal and topical bias: Twitter-derived dataset may not represent comprehensive educational text types or different time periods
- Out-of-domain generalization: Study doesn't address whether the model transfers to formal educational materials like textbooks or academic papers

## Confidence

- **High Confidence**: XLM-RoBERTa's superior performance over traditional ML and CNN/LSTM methods (98% vs. 6% recall for GloVe+CNN) is well-supported by cross-validation results
- **Medium Confidence**: The 98% accuracy figure is based on 5-fold CV on the same dataset without external validation, moderating confidence in generalizability
- **Low Confidence**: The claim that XLM-RoBERTa works "without requiring massive Urdu-specific corpora" is weakly supported—the paper doesn't isolate cross-lingual transfer effects

## Next Checks

1. **Dataset Accessibility Verification**: Attempt to reproduce the 5-fold CV accuracy using the exact same preprocessing pipeline (Urdu stopword removal, stemming algorithm, BIO/IOB tagging scheme) on the publicly released EDU-NER-2025 dataset once available. Compare class-wise F1-scores against reported values to identify potential annotation inconsistencies.

2. **Cross-Domain Generalization Test**: Evaluate the fine-tuned XLM-RoBERTa model on a held-out corpus of Urdu educational materials from different domains (academic textbooks, official government education documents, classroom transcripts) to measure performance degradation and identify domain-specific entity recognition gaps.

3. **Ablation of Cross-Lingual Transfer**: Train a baseline Urdu BERT model (if available) and a monolingual Urdu transformer on EDU-NER-2025, then compare performance to XLM-RoBERTa. Additionally, test the model on English educational texts to quantify the cross-lingual transfer contribution to the 98% accuracy.