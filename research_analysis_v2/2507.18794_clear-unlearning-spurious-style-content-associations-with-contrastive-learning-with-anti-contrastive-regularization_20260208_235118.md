---
ver: rpa2
title: 'CLEAR: Unlearning Spurious Style-Content Associations with Contrastive LEarning
  with Anti-contrastive Regularization'
arxiv_id: '2507.18794'
source_url: https://arxiv.org/abs/2507.18794
tags:
- style
- content
- learning
- contrastive
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLEAR addresses disentangling task-relevant content from superficial
  style in representations when only content labels are available. It combines supervised
  contrastive learning (maximizing mutual information between content features and
  labels) with anti-contrastive regularization (minimizing mutual information between
  style features and labels).
---

# CLEAR: Unlearning Spurious Style-Content Associations with Contrastive LEarning with Anti-contrastive Regularization

## Quick Facts
- arXiv ID: 2507.18794
- Source URL: https://arxiv.org/abs/2507.18794
- Authors: Minghui Sun; Benjamin A. Goldstein; Matthew M. Engelhard
- Reference count: 40
- One-line primary result: CLEAR disentangles content from style in representations using only content labels, improving OOD classification accuracy by 0.5-2.0x over vanilla CNN

## Executive Summary
CLEAR addresses the challenge of disentangling task-relevant content from superficial style in representations when only content labels are available. The method combines supervised contrastive learning (maximizing mutual information between content features and labels) with anti-contrastive regularization (minimizing mutual information between style features and labels). CLEAR-VAE enables sample-to-sample content/style swapping and interpolation without explicit style supervision. Experiments on five datasets show CLEAR variants (particularly CLEAR-PS) improve relative top-1 accuracy by 0.5-2.0x over vanilla CNN, with CLEAR-TC achieving 0.747 accuracy (±0.019) on Camelyon17-WILDS.

## Method Summary
CLEAR disentangles content and style in latent representations using a VAE architecture with two key mechanisms: supervised contrastive learning for content extraction and anti-contrastive regularization for style decorrelation. The model splits latent space into content (z(c)) and style (z(s)) components, applying separate KL penalties. Content features are trained with SNN loss to cluster same-label samples, while style features use Pair-Switching (PS) to minimize label information. The framework requires β < 1 for semantic disentanglement and achieves sample-level content/style manipulation without explicit style supervision.

## Key Results
- CLEAR-VAE enables content-to-style swapping and interpolation without explicit style labels
- CLEAR-PS improves relative top-1 accuracy by 0.5-2.0x over vanilla CNN for OOD classification
- CLEAR-TC achieves 0.747 accuracy (±0.019) on Camelyon17-WILDS with unseen style-content combinations
- CLEAR achieves strong disentanglement (gMIG scores of 0.3-0.4) with simpler training than alternative MI minimization approaches

## Why This Works (Mechanism)

### Mechanism 1: Supervised Contrastive Learning Captures Content Semantics
- **Claim:** Supervised contrastive learning (SNN loss) maximizes mutual information between content latent factors z(c) and content labels y, enabling task-relevant feature extraction without style supervision.
- **Mechanism:** The SNN loss clusters samples sharing the same content label in z(c)-space while pushing apart samples with different labels. This emerges from the ELBO derivation where maximizing Ey∼p,z(c)∼qϕ[log f(y|z(c))/p(y)] is equivalent to maximizing I(y; z(c)) through Monte Carlo estimation.
- **Core assumption:** Content semantics can be captured through label-driven clustering; task-relevant information is compressible into a lower-dimensional subspace.
- **Evidence anchors:** [abstract] "combines supervised contrastive learning (maximizing mutual information between content features and labels)"; [section 3.1] ELBO derivation shows contrastive term emerges naturally from variational bound; [appendix A.3.2] SNN loss derived from InfoNCE with multi-positive pairs per class.

### Mechanism 2: Pair-Switching Anti-Contrastive Regularization Minimizes Style-Label Dependencies
- **Claim:** Reversing positive/negative pair roles in contrastive learning (PS-SNN) minimizes I(y; z(s)), achieving disentanglement without style labels.
- **Mechanism:** Standard contrastive loss maximizes π(s) = h(y,z(s))/Σh(y',z(s)). PS-SNN maximizes 1-π(s) instead, encouraging style representations to be uninformative about content labels. Mathematically proven as upper bound: L^(s)_PS-SNN > I(y; z(s)) - log(N).
- **Core assumption:** In an unbiased representative dataset, style distributions would be consistent across content labels; observed spurious correlations are artifacts of sampling bias.
- **Evidence anchors:** [abstract] "anti-contrastive regularization (minimizing mutual information between style features and labels)...implemented via Pair-Switching (PS), which reverses positive/negative pair roles"; [section 3.3] Complete derivation of PS-InfoNCE and PS-SNN with mathematical proof; [figure 3] Simulation study validates MI minimization.

### Mechanism 3: Latent Space Factorization with β-VAE Trade-offs
- **Claim:** Splitting latent space into z(c) and z(s) with separate KL terms enables interpretable disentanglement, but requires β < 1 for semantic-level separation.
- **Mechanism:** Factorized ELBO applies separate KL penalties to z(c) and z(s). Lower β (< 1) allows correlated latent dimensions within each group, enabling semantic-level clustering; higher β (> 1) forces complete factorization that paradoxically hurts content-style separation.
- **Core assumption:** Data can be decomposed into two semantically meaningful factors; independence assumption holds a priori and a posteriori.
- **Evidence anchors:** [section 3.1, Eqn 2] Factorized ELBO with separate KL terms for z(c) and z(s); [figure 4] Swapping and interpolation experiments demonstrate semantically meaningful disentanglement; [appendix F, Fig F.2] Critical finding: gMIG peaks at β < 1 across all datasets.

## Foundational Learning

- **Concept: Variational Autoencoders and ELBO**
  - **Why needed here:** CLEAR-VAE builds directly on VAE architecture; understanding KL-regularization trade-offs is essential for tuning β and interpreting disentanglement quality.
  - **Quick check question:** Can you explain why increasing β beyond 1 in β-VAE might paradoxically hurt semantic-level disentanglement between content and style groups?

- **Concept: Contrastive Learning (InfoNCE, SupCon, SNN)**
  - **Why needed here:** The core mechanism uses supervised contrastive learning; understanding how positive/negative pairs are formed from labels is critical for implementing and debugging L^(c)_SNN.
  - **Quick check question:** Given a batch with 3 samples of class A and 2 of class B, how many positive pairs exist for the first sample if it belongs to class A?

- **Concept: Mutual Information Bounds and Estimation**
  - **Why needed here:** The theoretical justification relies on PS-SNN being an upper bound of I(y; z(s)) - log(N); understanding MI estimation helps validate disentanglement quality.
  - **Quick check question:** Why does the PS-SNN upper bound include a -log(N) term, and what does this imply about batch size selection?

## Architecture Onboarding

- **Component map:**
  Input x → Encoder → split into μ(c), Σ(c), μ(s), Σ(s)
           → Sample z(c) ∼ N(μ(c), Σ(c)), z(s) ∼ N(μ(s), Σ(s))
           → Concatenate [z(c), z(s)] → Decoder → Reconstruction x̂
           → z(c) → L^(c)_SNN (contrastive, same-label clustering)
           → z(s) → L^(s)_PS-SNN (anti-contrastive, same-label spreading)

- **Critical path:**
  1. Batch sampling must include multiple samples per class for contrastive pairs (N=32-64 per batch with balanced class distribution)
  2. z(c) dimension determines content capacity; z(s) dimension captures residual style variance (Table F.4: d_z = 8-64 depending on dataset complexity)
  3. β < 1 is required for semantic disentanglement (empirically β ∈ [1/8, 1/2] works well)

- **Design tradeoffs:**
  - **Cosine similarity vs. L2 distance:** Table F.4 shows cosine achieves 0.31-0.46 gMIG vs. 0.28-0.39 for L2; use cosine
  - **Temperature τ:** Lower τ (0.1) increases sensitivity but may cause instability; τ ≈ 0.3 recommended
  - **β vs. disentanglement:** Lower β improves gMIG but hurts reconstruction ELBO; balance based on downstream task priority
  - **Alternative MI minimization:** CLEAR-TC, CLEAR-L1OutUB, CLEAR-CLUB-S achieve similar performance to CLEAR-PS but require auxiliary networks and adversarial training—PS is simpler

- **Failure signatures:**
  - **gMIG ≈ 0:** β-VAE without contrastive losses; content and style remain entangled (Fig H.5)
  - **High gMIG but poor swapping:** Over-regularization with β < 0.1; reconstruction fails
  - **Numerical instability in CLEAR-TC:** Large τ (e.g., 1.0) causes discriminator gradients to explode; re-initialize and reduce τ
  - **No style extraction without L^(s)_PS-SNN:** Model captures content but style features remain empty (Fig H.4 shows loss of detail like zigzag patterns)

- **First 3 experiments:**
  1. **Baseline ablation on Styled-MNIST:** Train CLEAR-VAE with β=1/8, τ=0.3, d_z=16; compare full model vs. removing L^(c)_SNN vs. removing L^(s)_PS-SNN. Expected: gMIG drops from ~0.3 to 0.26 (no PS-SNN) or 0 (no SNN). Use t-SNE visualization to verify clustering patterns.
  2. **MI verification via simulation:** Replicate Figure 3 experiment—sample z from 3-component Gaussian mixture with class labels y, manipulate variance every 100 steps, track KNN MI estimate and L_SNN/L_PS-SNN. Confirms loss functions correctly optimize MI.
  3. **OOD generalization test:** Split PACS dataset so training uses 2 art domains (photo, cartoon) and testing uses 2 unseen domains (art painting, sketch). Compare CLEAR-PS vs. vanilla CNN baseline. Expected: relative improvement of 1.1-1.5x in top-1 accuracy (Fig 5b).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What is the rigorous theoretical connection between the modified Soft Nearest Neighbor (SNN) loss and Mutual Information (MI) maximization?
- **Basis in paper:** [explicit] The authors state that while empirical results suggest minimizing the SNN loss promotes MI maximization, "a closed-form relationship still remains unclear" (Conclusion).
- **Why unresolved:** The derivation in the appendix shows the loss relates to InfoNCE, but the exact analytical relationship with MI for multi-positive pairs is not mathematically closed.
- **What evidence would resolve it:** A formal proof deriving the exact bound or relationship between the SNN loss term $L_{SNN}$ and the mutual information $I(y; z^{(c)})$.

### Open Question 2
- **Question:** Can the CLEAR framework be effectively scaled to non-VAE probabilistic generative models or extended to multi-modal data settings?
- **Basis in paper:** [explicit] The authors identify as a limitation that "the CLEAR framework has not yet been scaled to other probabilistic generative models or extended to multi-modal settings" (Conclusion).
- **Why unresolved:** The current implementation is restricted to the latent space of VAEs for image data to isolate the benefits of the regularization strategy.
- **What evidence would resolve it:** Successful application and evaluation of CLEAR regularizers on architectures like GANs, Diffusion models, or multi-modal datasets (e.g., text-image pairs).

### Open Question 3
- **Question:** Does the requirement for lower $\beta$ values to achieve semantic disentanglement imply a necessary trade-off with the independence of individual latent factors?
- **Basis in paper:** [inferred] Appendix F notes that CLEAR variants achieve significant disentanglement only when $\beta < 1$, stating, "To achieve a disentanglement at the semantic level, we have to allow an appropriate level of entanglement at the individual latent factor level."
- **Why unresolved:** This contradicts standard $\beta$-VAE theory where $\beta > 1$ promotes disentanglement; the mechanism for this inversion in CLEAR is empirically observed but not theoretically explained.
- **What evidence would resolve it:** A theoretical analysis or ablation study explaining why penalizing the KL divergence ($\beta > 1$) hinders the semantic separation of content and style in this specific architecture.

## Limitations
- CLEAR relies on content labels for supervision, making it inapplicable to truly unsupervised settings
- Assumes content and style are mutually exclusive factors, which may not hold in complex real-world data
- Anti-contrastive regularization effectiveness depends on dataset quality—biased sampling can undermine style-label independence
- Disentanglement quality degrades with high β values (> 1), limiting flexibility in reconstruction-heavy applications
- Computational overhead from contrastive loss (positive/negative pair computation) scales quadratically with batch size

## Confidence
- **High confidence**: Core mechanism of supervised contrastive learning for content extraction - well-established theoretical foundation
- **Medium confidence**: Pair-switching anti-contrastive regularization - novel approach with simulation validation but limited real-world testing
- **Medium confidence**: β-VAE factorization trade-offs - empirical findings consistent across datasets but theoretical explanation incomplete
- **Medium confidence**: OOD generalization improvements - demonstrated across five datasets but magnitude varies significantly (0.5-2.0x relative improvement)

## Next Checks
1. **Robustness to dataset bias**: Test CLEAR on artificially biased datasets where style distributions are not independent of content labels to identify failure modes
2. **Transfer learning evaluation**: Assess whether CLEAR-pretrained representations improve downstream task performance when fine-tuned on limited data
3. **Scalability analysis**: Measure computational overhead and disentanglement quality as dataset size and complexity increase (e.g., ImageNet variants)