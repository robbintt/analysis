---
ver: rpa2
title: Logarithmic Width Suffices for Robust Memorization
arxiv_id: '2502.11162'
source_url: https://arxiv.org/abs/2502.11162
tags:
- width
- lemma
- dataset
- theorem
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates the memorization capacity of feedforward\
  \ ReLU neural networks under adversarial perturbations, focusing on the trade-off\
  \ between network width and robustness. The authors establish both upper and lower\
  \ bounds on the achievable robustness radius for a given network width when memorizing\
  \ \u03B4-separated datasets in general lp norms."
---

# Logarithmic Width Suffices for Robust Memorization

## Quick Facts
- arXiv ID: 2502.11162
- Source URL: https://arxiv.org/abs/2502.11162
- Reference count: 40
- Key outcome: A network width logarithmic in the number of samples is both necessary and sufficient to achieve robust memorization with constant robustness radius independent of dataset size

## Executive Summary
This paper establishes fundamental limits on the memorization capacity of feedforward ReLU neural networks under adversarial perturbations. The authors prove that for δ-separated datasets, a network width scaling logarithmically with the number of samples (N) is both necessary and sufficient to achieve robust memorization with a constant robustness radius. The key technical innovation is a robust variant of the Johnson-Lindenstrauss lemma that preserves separation between neighborhoods rather than just between points, enabling dimension reduction while maintaining adversarial robustness.

## Method Summary
The paper takes a theoretical construction approach, proving existence of networks that can robustly memorize datasets through explicit construction rather than training algorithms. The method relies on a robust variant of the Johnson-Lindenstrauss lemma to project high-dimensional data to a lower-dimensional subspace while preserving neighborhood separation. The network architecture consists of a linear projection layer followed by deep ReLU stacks that approximate ball indicator functions, partitioning the input space into safe zones around data points. The proofs establish both upper bounds (constructive) and lower bounds (information-theoretic) on achievable robustness radii for given widths.

## Key Results
- A network width k = O(log N) is sufficient to achieve robust memorization with constant robustness radius σ
- A width k = Ω(log N) is necessary for robust memorization with constant robustness radius σ
- For constant width, the achievable robustness radius scales as σ ∝ N^(-2/k)
- The constructions require depth O(N·k) to approximate the required indicator functions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A network width k scaling logarithmically with dataset size N is both necessary and sufficient to project high-dimensional data into a subspace that preserves robustness neighborhoods.
- **Mechanism:** The paper introduces a robust variant of the Johnson-Lindenstrauss (JL) lemma. Unlike standard JL, which preserves distances between data points, this variant preserves the separation between neighborhoods (balls of radius σ) of data points. This allows a linear layer to map data from dimension d to width k without causing adversarial perturbation regions to intersect.
- **Core assumption:** The dataset is δ-separated (points from different classes are at least distance δ apart).
- **Evidence anchors:**
  - [abstract] "A network width logarithmic in the number of samples is both necessary and sufficient..."
  - [Section 5] Introduces the "robust variant of the Johnson-Lindenstrauss lemma" to maintain separation between neighborhoods.
  - [corpus] Corpus signals (e.g., "Convergence of Shallow ReLU Networks") suggest log(n) width is relevant for convergence, though this paper specifically proves it for robust memorization capacity.
- **Break condition:** If the width k is constant while N increases, the projection will inevitably map the robustness neighborhoods of distinct classes onto each other, making memorization impossible.

### Mechanism 2
- **Claim:** ReLU networks memorize robustly by constructing "ball indicators" that partition the input space into safe zones around data points.
- **Mechanism:** The network is constructed to approximate the function f(x) = Σ yi · 1_{Bp(xi, σ)}(x). It computes a weighted sum where the weight is the label yi if the input x falls within the ℓp ball of radius σ around xi, and zero otherwise. This requires depth to approximate the distance norms.
- **Core assumption:** The network depth is sufficient to approximate the required norms (e.g., O(N·d) depth is used in the constructive proofs).
- **Evidence anchors:**
  - [Section 4.3] "Approximate the function yi · 1_{Bd2(xi, r)}..."
  - [Appendix G] Details the "indicator" network construction using ReLU.
  - [corpus] "Provable Benefits of Sinusoidal Activation" discusses expressivity gaps in similar shallow architectures, relevant to the difficulty of indicator construction.
- **Break condition:** If the robustness radius σ is too large relative to the class separation δ (specifically σ/δ ≥ 1/2), the balls intersect, and no indicator function can separate them.

### Mechanism 3
- **Claim:** The trade-off between network width k and robustness radius σ is governed by a polynomial decay relation (σ ∝ N^(-2/k)) in the small-width regime.
- **Mechanism:** When width k < d, the linear projection constrains the volume of the subspace. As N grows, the "available space" to place non-intersecting robustness balls shrinks, forcing the radius σ to shrink or the width k to grow.
- **Core assumption:** We are operating in the regime where width k < d (data dimension).
- **Evidence anchors:**
  - [Section 4] "We show nearly tight bounds on the possible robustness radius σ... specifically σ/δ < c1 N^(-2/k)."
  - [Section 4.2] "A width of k > C2 log(N)/log(δ/σ) is necessary..."
  - [corpus] "Depth-Width tradeoffs" in corpus neighbors aligns with this focus on resource scaling.
- **Break condition:** Attempting to maintain a constant robustness radius σ while keeping width k fixed as N → ∞ violates the separation requirements.

## Foundational Learning

- **Concept: Johnson-Lindenstrauss (JL) Lemma**
  - **Why needed here:** The paper relies on a modification of this lemma. You must understand that standard JL allows embedding N points from d dimensions into O(log N) dimensions while preserving pairwise distances.
  - **Quick check question:** How does a random projection matrix preserve the distance between two vectors?

- **Concept: Adversarial Robustness (ℓp balls)**
  - **Why needed here:** The paper defines "robust memorization" not just as fitting a point, but as correctly classifying every point within an ℓp ball of radius σ around it.
  - **Quick check question:** If two data points from different classes are distance δ apart, what is the maximum robustness radius σ possible (hint: think about overlapping balls)?

- **Concept: δ-Separated Datasets**
  - **Why needed here:** This is a core assumption (Definition 3.2). If data is not separated (δ=0), robust memorization is mathematically impossible because the robustness neighborhoods would overlap.
  - **Quick check question:** Why is the separation assumption necessary for any robustness guarantee?

## Architecture Onboarding

- **Component map:** Input -> Linear projection (T: ℝ^d → ℝ^k) -> Deep ReLU stacks (ball indicators) -> Output (weighted sum)
- **Critical path:** The first linear layer is the bottleneck. If this projection maps two distinct class neighborhoods to the same subspace region, no amount of depth in subsequent layers can recover robust memorization.
- **Design tradeoffs:**
  - Width vs. Robustness: For a fixed dataset size N, you can trade width for robustness radius. Halving the width roughly squares the reduction in the allowable robustness radius σ.
  - Depth vs. Accuracy: The construction requires depth O(N·k) to approximate the indicators exactly.
- **Failure signatures:**
  - Intersection of neighborhoods: If training fails on δ-separated data, verify if the width k satisfies the log(N) bound for the desired σ. If k is too small, the input layer has irreversibly merged class boundaries.
- **First 3 experiments:**
  1. **Sanity Check (Theorem 4.2):** Implement the memorization network with width k ≥ d+6 on a small δ-separated dataset. Verify it robustly memorizes with high σ.
  2. **Stress Test (Theorem 4.5):** Fix a small width k (e.g., k=10) and increase dataset size N. Plot the maximum achievable robustness radius σ. It should decay proportionally to N^(-2/k).
  3. **Projection Analysis:** Visualize the output of the first layer for a failing case. Check if the projected σ-balls of different classes overlap, confirming the "non-preservable" condition.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Is the dependence on the data dimension d necessary for the robustness radius when linearly reducing dataset dimension?
- **Basis in paper:** [explicit] The conclusion explicitly asks if the radius of robustness must depend on the data dimension d to guarantee the ability to linearly reduce a dataset to k dimensions robustly.
- **Why unresolved:** The current bounds in the paper's robust variant of the Johnson-Lindenstrauss lemma introduce a gap that depends on d, but it is unclear if this is a fundamental geometric constraint or an artifact of the probabilistic proof method.
- **What evidence would resolve it:** Establishing tight bounds for the hitting number of subspaces by spherical caps, specifically determining if the d dependence can be removed from the bound for m_{φ, d-k}.

### Open Question 2
- **Question:** What is the optimal number of parameters required to robustly memorize a dataset?
- **Basis in paper:** [explicit] The conclusion identifies studying the "relation between robustness and number of parameters" as a direction for future work.
- **Why unresolved:** The paper focuses on network width, showing logarithmic width suffices. However, the constructions used require O(N) parameters for constant width, whereas non-robust memorization is known to require only Õ(√N) parameters.
- **What evidence would resolve it:** Deriving upper and lower bounds on the total parameter count specifically for robust memorization to determine if it matches the non-robust complexity or requires more parameters.

### Open Question 3
- **Question:** Can neural networks trained via standard optimization methods (like SGD) achieve robust memorization with logarithmic width?
- **Basis in paper:** [explicit] The conclusion asks to study "the extent to which trained neural networks (using standard optimization methods) can robustly memorize datasets."
- **Why unresolved:** The paper establishes the expressive capacity (existence of such networks) but does not address the optimization aspect, leaving it unknown if standard training can actually find these parameter configurations.
- **What evidence would resolve it:** Empirical studies or theoretical convergence proofs demonstrating that trained networks can robustly memorize datasets with a width logarithmic in the number of samples, as the existence results predict.

## Limitations
- The results rely on probabilistic arguments for robust JL projections, with explicit construction methods left implicit
- Depth requirements scale linearly with N·k, potentially limiting practical applicability
- Analysis focuses on synthetic δ-separated datasets; generalization to real-world data distributions remains unexplored

## Confidence
- **High confidence:** Width scaling bounds (Theorems 4.2, 4.5, 4.6) - these follow from established concentration inequalities and are mathematically rigorous
- **Medium confidence:** Robust JL variant construction - while existence is proven, the constructive algorithm details are sparse
- **Medium confidence:** Depth requirements - theoretical bounds are provided but may be loose for practical implementations

## Next Checks
1. **Empirical verification of width-robustness trade-off:** Implement the memorization network with varying widths (k = 5, 10, 20, 50) on synthetic δ-separated datasets with N=100, 1000, 10000 samples. Measure the maximum achievable robustness radius σ empirically and verify the predicted N^(-2/k) scaling.

2. **Robust JL projection validation:** For small d=5, N=50, test whether the robust JL projection preserves neighborhood separation. Generate 1000 random projections and measure the fraction that satisfy the required separation condition.

3. **Depth-accuracy trade-off analysis:** For a fixed width k=20 and N=1000, vary the network depth and measure the memorization accuracy under adversarial perturbations. Compare against the theoretical O(Nk log k) depth requirement to identify potential looseness in bounds.