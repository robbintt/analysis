---
ver: rpa2
title: 'Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow'
arxiv_id: '2508.02959'
source_url: https://arxiv.org/abs/2508.02959
tags:
- task
- graph
- flow
- workflow
- subtask
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Polymath, a self-optimizing agent that addresses
  the challenge of automating agentic workflow generation for dynamic, real-world
  problems. The method uses a hierarchical approach combining task flow graphs with
  code-represented subtask workflows, enhanced by a multi-grid-inspired graph optimization
  and a self-reflection-guided evolutionary algorithm that requires no labeled data.
---

# Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow

## Quick Facts
- **arXiv ID**: 2508.02959
- **Source URL**: https://arxiv.org/abs/2508.02959
- **Reference count**: 24
- **Primary result**: 8.1% average improvement over SOTA baselines across coding, math, and QA benchmarks; 14.4% higher accuracy than Cursor on industrial hardware design

## Executive Summary
Polymath introduces a self-optimizing agent that automates the generation of hierarchical agentic workflows for dynamic, real-world problems. The approach combines task flow graphs for high-level planning with code-represented subtask workflows, enhanced by a multi-grid-inspired graph optimization and a self-reflection-guided evolutionary algorithm. The system requires no labeled data, instead using LLM-generated reflections as "textual gradients" to guide optimization. Evaluations across six benchmarks show significant improvements over state-of-the-art methods, with the framework demonstrating particular strength in complex, multi-step reasoning tasks.

## Method Summary
Polymath employs a hierarchical architecture where a task flow graph decomposes complex problems into subtasks with dependencies, while each subtask is solved by an executable code workflow. The system uses a multi-grid-inspired optimization that alternates between coarsening (merging) and relaxing (decomposing) subtasks based on effective scores derived from historical task data. A self-reflection-guided evolutionary algorithm then optimizes individual code workflows, using LLM judges to evaluate and generate reflections that guide the evolution process. The approach leverages multiple specialized LLMs (GPT-4o for coding and planning, o1-1217 for reasoning) and operates without requiring labeled training data.

## Key Results
- 8.1% average improvement over SOTA baselines across HumanEval, MBPP, MATH lv5*, GSM8K, HotpotQA, and DROP benchmarks
- 30.7% average improvement when adding task flow graphs to code workflows
- 14.4% higher accuracy than Cursor on real-world industrial hardware design case
- Self-reflection EA achieves perfect score in 10 iterations vs 20 for OpenEvolve baseline

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Task Decomposition via Task Flow Graphs
Complex problems are decomposed into directed graphs of subtasks with dependencies, allowing dynamic adaptation based on intermediate results. The task flow graph enables jump logic and rerunning of subtasks, providing flexibility that sequential approaches lack.

### Mechanism 2: Multi-Grid-Inspired Graph Optimization
The system iteratively coarsens (merges) and relaxes (decomposes) subtask nodes based on effective scores. This approach borrows from computational multi-grid methods, using historical data to estimate which merges or decompositions will improve overall task success.

### Mechanism 3: Self-Reflection-Guided Evolutionary Algorithm
LLM-generated reflections provide optimization signals without labeled data. The system aggregates previous workflows and scores, generates new candidates, evaluates them with multi-objective LLM judges, and distills reflections to guide the evolutionary process toward better solutions.

## Foundational Learning

- **Directed Acyclic Graphs (DAGs) and topological ordering**
  - Why needed: Task flow graphs execute subtasks in topological order; essential for understanding parallelization and dynamic adaptation
  - Quick check: Given dependencies A→B, A→C, B→D, C→D, list two valid execution orders

- **Evolutionary algorithms (selection, mutation, fitness, MAP-Elites)**
  - Why needed: The self-reflection EA uses evolutionary concepts; understanding exploration-exploitation helps interpret why reflections act as gradients
  - Quick check: In MAP-Elites, what does maintaining a "behavior map" achieve versus a single best solution?

- **Multi-grid V-cycles (coarsening, relaxation)**
  - Why needed: Graph optimization borrows from computational multi-grid; understanding coarsening as "merging" and relaxation as "refining" clarifies the algorithm
  - Quick check: In a V-cycle, why alternate between coarse and fine levels rather than optimizing at one level only?

## Architecture Onboarding

- **Component map**: Task Flow Planner -> Multi-grid Optimizer -> Code Workflow Generator -> LLM Judge Evaluator -> Self-Reflection EA Engine -> Historical DB
- **Critical path**: Input task → Generate initial task flow graph → Query effective score DB → Apply multi-grid optimization → Generate code workflows → Evaluate (LLM judge) → If needed, run self-reflection EA → Aggregate results
- **Design tradeoffs**: EA threshold 0.8 balances optimization quality vs latency; max 15 EA iterations prevents diminishing returns
- **Failure signatures**: EA instability (syntax errors, hallucinations), optimization loops (oscillation between coarsening/relaxation)
- **First experiments**: 1) Implement task flow graph and topological execution on HumanEval subset, 2) Build effective score database from unoptimized runs, 3) Test multi-grid optimization with LLM judge estimates

## Open Questions the Paper Calls Out
None

## Limitations
- Source code and detailed system prompts unavailable, limiting reproducibility
- Historical database built only from HumanEval and MATH lv5* may not generalize to other domains
- Multi-objective LLM judge evaluation could exhibit bias or inconsistency in complex tasks

## Confidence
- **High Confidence**: Hierarchical decomposition mechanism (30.7% improvement), multi-grid optimization (4.67% improvement in effective scores)
- **Medium Confidence**: Self-reflection EA superiority (10 vs 20 iterations), 14.4% accuracy improvement over Cursor on industrial case
- **Low Confidence**: Generalization claims to real-world problems beyond evaluated benchmarks

## Next Checks
1. **Independent Implementation Test**: Reproduce task flow graph and multi-grid optimization components on HumanEval subset using public LLMs to verify 30.7% improvement claims
2. **Judge Reliability Assessment**: Conduct inter-annotator agreement studies with human experts on LLM judge evaluations to quantify consistency and potential bias
3. **Database Generalization Study**: Evaluate effective score estimation accuracy when database built from one domain (coding) but tested on different domain (math), measuring optimization performance degradation