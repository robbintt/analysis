---
ver: rpa2
title: Studies with impossible languages falsify LMs as models of human language
arxiv_id: '2511.11389'
source_url: https://arxiv.org/abs/2511.11389
tags:
- languages
- learn
- language
- impossible
- bowers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper critiques claims that language models (LMs) learn attested
  and impossible languages similarly to humans, challenging the idea that LMs have
  human-like inductive biases. The authors review studies comparing LM learning of
  attested versus impossible languages.
---

# Studies with impossible languages falsify LMs as models of human language

## Quick Facts
- arXiv ID: 2511.11389
- Source URL: https://arxiv.org/abs/2511.11389
- Reference count: 3
- LMs learn attested and impossible languages similarly, suggesting they lack human-like inductive biases for language acquisition

## Executive Summary
The paper argues that language models (LMs) fail to demonstrate human-like inductive biases in language learning. By reviewing studies that compare LM learning of attested natural languages versus impossible languages that violate linguistic universals, the authors find that LMs often learn impossible languages as readily as natural ones. The only consistent exception is random languages lacking statistical structure. The authors conclude that LMs require vastly more data than infants and lack the innate linguistic constraints that characterize human language acquisition.

## Method Summary
The paper reviews existing empirical studies comparing LM learning of attested versus impossible languages. The methodology involves constructing impossible language variants (reversed word orders, shuffled sequences, implausible grammatical structures) and measuring LM learning curves and final performance. Key studies reviewed include Mitchell & Bowers (2020) on reversed languages, Kallini et al. (2024) on random vs. deterministic shuffles, Yang et al. (2025) on implausible languages, and Xu et al. (2025) on counterfactual grammars. The approach compares training dynamics and generalization performance across language types.

## Key Results
- LMs learn structurally impossible languages as readily as attested languages when statistical regularities exist
- LMs show selective difficulty only with random languages lacking consistent patterns
- LMs require many orders of magnitude more data than infants to achieve comparable performance
- Difficulty with random languages reflects computational complexity rather than linguistic priors

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LMs learn structurally impossible languages as readily as attested languages when statistical regularities exist.
- Mechanism: Transformer architectures optimize for pattern completion without architectural constraints that privilege human-valid linguistic structures. Reversed word orders, non-hierarchical dependencies, and other UG-violating patterns are acquired if they exhibit consistent statistical regularities.
- Core assumption: Learning difficulty reflects pattern complexity, not linguistic impossibility per se.
- Evidence anchors:
  - [abstract] "LMs often learn attested and many impossible languages equally well"
  - [section 2] "several additional impossible languages were learned almost as easily as English"
  - [corpus] "Biasless Language Models Learn Unnaturally" (arXiv:2510.07178) reports similar findings on failure to distinguish possible from impossible languages
- Break condition: If an impossible language contains consistent statistical patterns but LMs systematically fail to acquire it while humans succeed, the claim weakens.

### Mechanism 2
- Claim: Difficulty with random shuffle languages reflects increased Kolmogorov complexity, not human-like linguistic priors.
- Mechanism: Deterministic shuffle languages requiring different permutation patterns per sentence length create a "multiple language" learning problem. This increases effective complexity without providing unified structural generalizations.
- Core assumption: Assumption: Performance degradation scales with description length/computational complexity of the target distribution.
- Evidence anchors:
  - [section 2] "there was no structure to learn" for random shuffles; deterministic shuffles require "different random languages for different sentence lengths"
  - [section 2] Authors invoke "no free lunch theorems" to argue poor performance on some languages is mathematically expected
  - [corpus] Neighbor papers on length generalization (arXiv:2510.12722) suggest complexity scaling affects generalization
- Break condition: If LMs show selective difficulty with linguistically impossible but computationally simple patterns while handling equally complex but linguistically possible patterns, the complexity-based explanation fails.

### Mechanism 3
- Claim: Data inefficiency relative to infants indicates missing innate linguistic priors.
- Mechanism: Human acquisition leverages domain-specific constraints (UG) that restrict hypothesis space, enabling rapid learning from sparse data. LMs must extract all regularities from data without architectural guidance.
- Core assumption: Assumption: Infant acquisition speed is primarily attributable to innate constraints rather than other factors (multimodal grounding, social interaction, cognitive architecture).
- Evidence anchors:
  - [section 1] "require training on many orders of magnitude of more language data compared to children"
  - [section 3] McCoy & Griffiths (2025) attempt to distill Bayesian priors "does not make LMs much more data efficient"
  - [corpus] Weak direct corpus evidence on infant-LM data efficiency comparisons; cited Bowers (2025a) not in corpus
- Break condition: If scaled training with different objectives (e.g., predictive coding, embodied interaction) achieves infant-comparable data efficiency, the missing-prior explanation becomes insufficient.

## Foundational Learning

- Concept: **Universal Grammar (UG) as inductive bias**
  - Why needed here: The paper's central argument assumes UG constrains both what languages exist and what humans can learn. Understanding this is necessary to evaluate claims about "impossible" languages.
  - Quick check question: Can you explain why a constraint that limits learnable languages might also accelerate learning?

- Concept: **Attested vs. impossible languages**
  - Why needed here: The empirical methodology depends on distinguishing languages humans actually use from those violating linguistic universals (e.g., reversed dependencies, random word orders).
  - Quick check question: What makes a language "impossible"—is it formal complexity or violation of cross-linguistic generalizations?

- Concept: **Inductive bias in learning systems**
  - Why needed here: The paper argues LMs lack human-like inductive biases. Understanding what constitutes an inductive bias (architectural vs. learned) clarifies the debate.
  - Quick check question: If an LM trained on only natural languages subsequently learns an impossible language easily, does that imply the training failed to instill linguistic priors?

## Architecture Onboarding

- Component map:
  - Attested languages -> Impossible languages -> Random languages
  - Learning metrics: Training curves -> Final perplexity -> Generalization to held-out sequences
  - Control variables: Pattern complexity -> Vocabulary size -> Sequence length distribution

- Critical path:
  1. Define impossible language manipulation (e.g., reversal, shuffle, dependency inversion)
  2. Generate matched corpora controlling for token statistics
  3. Train LMs from scratch or fine-tune pretrained models
  4. Compare learning curves between attested and impossible conditions
  5. Control for complexity by matching Kolmogorov complexity estimates

- Design tradeoffs:
  - Training from scratch vs. fine-tuning: Scratch training reveals architecture biases; fine-tuning reveals pretrained priors
  - Natural language controls vs. artificial languages: Natural controls are ecologically valid but harder to match precisely
  - Perplexity vs. behavioral tests: Perplexity captures distributional learning; behavioral tests probe structural generalization

- Failure signatures:
  - LM shows no learning difference between attested and structured-impossible conditions → suggests missing linguistic prior
  - LM fails only on random/high-entropy conditions → consistent with complexity-based difficulty, not linguistic constraint
  - Noise in corpus construction confounds impossibility with data quality → invalidates conclusions (see Xu et al. caveat)

- First 3 experiments:
  1. Replicate Mitchell & Bowers (2020) reversed-language paradigm with modern transformer architectures; measure whether training curves differ from natural language baseline.
  2. Construct controlled impossible languages with matched complexity to attested languages (using formal language theory metrics); test if complexity-matched impossibles show equal learnability.
  3. Test data efficiency directly: train small LMs on child-directed speech quantities; compare acquisition trajectories to infant data from CHILDES.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can human-like linguistic inductive biases be successfully engineered into LMs to achieve both selective learning (rejecting impossible languages) and human-level data efficiency?
- Basis in paper: [explicit] The authors note that McCoy & Griffiths (2025) attempted to induce a universal grammar in LMs but "does not make LMs much more data efficient" (Bowers, 2025b).
- Why unresolved: Current distillation methods for Bayesian priors have not produced significant improvements in either selectivity or efficiency.
- What evidence would resolve it: A demonstration that LMs with engineered priors both refuse to learn impossible languages and acquire attested languages with infant-comparable data volumes.

### Open Question 2
- Question: To what extent is LM difficulty with certain impossible languages attributable to increased computational complexity rather than human-like linguistic constraints?
- Basis in paper: [explicit] The authors argue "Difficult to learn impossible languages are simply more complex (or random)" and invoke "no free lunch theorems" to explain why any learner must struggle with some languages.
- Why unresolved: The complexity versus linguistic-prior explanations make similar behavioral predictions but have radically different theoretical implications.
- What evidence would resolve it: Systematic manipulation of complexity measures (e.g., entropy, Kolmogorov complexity) independently of linguistic unnaturalness to determine which factor predicts LM performance.

### Open Question 3
- Question: Can studies of implausible language learning control for corpus noise to definitively test whether LMs genuinely struggle with typologically implausible structures?
- Basis in paper: [explicit] The authors cite Xu et al. (2025), who acknowledged: "it is possible that our findings may be due partially or entirely to increased noise in the counterfactual corpora."
- Why unresolved: If corpus construction artifacts explain performance differences, conclusions about LM inductive biases remain uncertain.
- What evidence would resolve it: Re-running implausible language studies with rigorously controlled counterfactual corpora that match noise levels across conditions.

## Limitations
- Evidence base remains fragmented with conflicting findings across studies
- Xu et al. (2025) results compromised by acknowledged noise in corpus construction
- Complexity versus linguistic-prior interpretations make similar behavioral predictions
- Comparison to infant data efficiency mentioned but not empirically validated

## Confidence
- High confidence: LMs learn structurally impossible languages when statistical regularities exist
- Medium confidence: Difficulty with random languages reflects computational complexity rather than linguistic constraints
- Low confidence: Data inefficiency relative to infants definitively indicates missing innate linguistic priors

## Next Checks
1. Replicate the Mitchell & Bowers (2020) reversed-language paradigm with matched complexity controls to isolate linguistic vs. statistical difficulty
2. Conduct formal complexity analysis (Kolmogorov/minimum description length) comparing attested, impossible, and random language variants
3. Run direct data-efficiency experiments training LMs on child-directed speech quantities with infant acquisition benchmarks from CHILDES