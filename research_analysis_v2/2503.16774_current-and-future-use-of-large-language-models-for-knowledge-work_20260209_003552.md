---
ver: rpa2
title: Current and Future Use of Large Language Models for Knowledge Work
arxiv_id: '2503.16774'
source_url: https://arxiv.org/abs/2503.16774
tags:
- llms
- work
- participants
- knowledge
- workers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study explored how knowledge workers currently use and would
  like to use LLMs for work tasks. Through surveys of 216 workers in 2023 and 107
  in 2024, researchers identified four main categories of LLM usage: creation, information,
  advice, and automation.'
---

# Current and Future Use of Large Language Models for Knowledge Work
## Quick Facts
- arXiv ID: 2503.16774
- Source URL: https://arxiv.org/abs/2503.16774
- Reference count: 40
- Primary result: Knowledge workers primarily use LLMs for creating drafts and finding information, with future desires centered on automated workflows and personalized data integration

## Executive Summary
This study explores how knowledge workers currently use and would like to use LLMs for work tasks through surveys of 216 workers in 2023 and 107 in 2024. Researchers identified four main categories of LLM usage: creation, information, advice, and automation. Current work uses focus on generating drafts and finding information, while future desires center on automated workflows and personalized data integration. The findings reveal a need for LLM tools that support specialized skills, integrate with existing workflows, and enable worker-LLM collaboration.

## Method Summary
The research employed two surveys from a large international technology company: Survey1 (n=216, June-August 2023) using open-ended questions, and Survey2 (n=107, Sept-Oct 2024) using multiple-choice based on Survey1 themes. Analysis used inductive reflexive thematic analysis with two coders. The survey flow included background demographics, LLM adoption status, task-specific questions, and future use questions, with approximately 119/380 participants dropping off during detailed task questions.

## Key Results
- Knowledge workers use LLMs primarily for creation (generating drafts) and information (finding data) tasks
- Future desired uses focus on automation (workflow integration) and personalized data access
- Users want to maintain oversight ("passenger seat") while leveraging LLMs for complex tasks
- There's a gap between current discrete task usage and desired workflow-integrated applications

## Why This Works (Mechanism)

### Mechanism 1: Reduction of "Blank Page" Friction
Survey data suggests LLMs add value primarily by generating "starter drafts" or templates rather than finished artifacts, lowering the cognitive load of task initiation. Users request an artifact → LLM generates a probabilistic completion → User applies domain expertise to modify the draft. This bypasses the "cold start" problem of creation.

### Mechanism 2: Contextual Data Grounding (Desired but Undeployed)
Future utility hinges on the model's ability to access and reason over private, localized data (emails, codebases, documents) rather than relying solely on pre-trained weights. User queries specific internal context → System retrieves relevant documents → LLM synthesizes answer based on private data → Output reflects user's actual work environment.

### Mechanism 3: The "Passenger Seat" Oversight Loop
Effective knowledge work support requires a collaborative loop where the human retains final validation authority, treating the LLM as a generator of options rather than a decision-maker. LLM suggests actions/guidance → Human reviews for "hallucination" or misalignment → Human accepts, rejects, or modifies.

## Foundational Learning

- **Concept: The 4-Category Taxonomy (Creation, Information, Advice, Automation)**
  - Why needed here: This framework is essential for mapping user intent to system capabilities. Engineers often conflate "chat" with "search" or "automation," leading to poor UX.
  - Quick check question: Does your system design distinct pathways for *Creation* (generating new artifacts) vs. *Advice* (improving existing ones), or does it treat all prompts as identical?

- **Concept: Discrete vs. Workflow-Integrated Tasks**
  - Why needed here: The paper highlights a gap: current usage is mostly discrete (one-off prompts), but worker desire is workflow-integrated (multi-step). Systems must evolve from chatbots to agents.
  - Quick check question: Is your architecture designed to maintain state across a multi-step workflow, or does it reset after every transaction?

- **Concept: The "Eval" Gap**
  - Why needed here: Users struggle to evaluate LLM quality in specialized domains because they lack the expertise or the model lacks transparency.
  - Quick check question: How does your system signal confidence or sourcing to a user who may not be an expert in the specific output generated?

## Architecture Onboarding

- **Component map:** User Interface: Chat interface (current) → Integrated IDE/Doc Suite (future) → Context Layer: Connectors to Jira, Office 365, local repos → Orchestrator: Routes intent; manages review loop → Model: General LLM + RAG for private data
- **Critical path:** 1. Classify Intent: Identify if user is asking for *Creation* or *Information* 2. Check Permissions: Can LLM access required context? 3. Generate Draft: Produce the artifact 4. Enable Modification: Provide UI for easy editing
- **Design tradeoffs:** Specialization vs. Generalization (fine-tuning improves *Advice* and *Creation* but risks data leakage) vs. Automation vs. Control (high automation is desired but high risk)
- **Failure signatures:** "Fluffy" outputs lacking domain substance, Context Amnesia (forgetting earlier constraints), Trust Erosion (non-repeatability causing collaborative friction)
- **First 3 experiments:** 1. "Starter Draft" A/B Test: Measure time-to-completion with "Blank Page" vs. "LLM First Draft" 2. Context Window Stress Test: Test summarization accuracy vs. token limits 3. Validation Loop Check: Measure false positive rates for "Code Validation"

## Open Questions the Paper Calls Out
None

## Limitations
- Sample representation limited to a single large technology company with demographic skew (63% North America, 22% Europe)
- Temporal context affected by internal AI education campaign between surveys that may have influenced responses
- Self-report bias from reliance on self-reported usage patterns rather than observational data

## Confidence
- **High Confidence**: Identification of four usage categories (creation, information, advice, automation) is well-supported by thematic analysis
- **Medium Confidence**: Claims about future desires for workflow integration and personalized data access are based on stated preferences rather than demonstrated behavior
- **Medium Confidence**: The "passenger seat" oversight mechanism is theoretically sound but lacks empirical evidence on optimal human-AI collaboration ratios

## Next Checks
1. **Behavioral Validation Study**: Conduct observational studies tracking actual LLM usage patterns versus self-reported data across different organizational contexts
2. **Workflow Integration Test**: Implement prototype systems enabling private data access and measure adoption rates, error frequencies, and user satisfaction across different task types
3. **Trust Transfer Experiment**: Systematically vary the presence of human oversight in LLM-assisted tasks and measure impacts on trust, error detection rates, and team collaboration outcomes