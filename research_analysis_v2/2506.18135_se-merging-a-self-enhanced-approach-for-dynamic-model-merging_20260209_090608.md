---
ver: rpa2
title: 'SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging'
arxiv_id: '2506.18135'
source_url: https://arxiv.org/abs/2506.18135
tags:
- merging
- task
- merged
- representation
- fine-tuned
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the underlying mechanism of model merging
  by analyzing the representation perspective. The authors discover that merged models
  possess two key capabilities: distinguishing samples from different tasks and adapting
  to corresponding expert models for each sample.'
---

# SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging

## Quick Facts
- arXiv ID: 2506.18135
- Source URL: https://arxiv.org/abs/2506.18135
- Reference count: 40
- Outperforms training-free baselines by 3.86% on vision and 6.86% on language tasks

## Executive Summary
SE-Merging is a training-free framework for dynamic model merging that enhances multi-task performance through representation-based adaptation. The approach is built on the Representation Auto-Adaptation Hypothesis, which posits that merged models implicitly retain the ability to mimic the representation geometry of the relevant expert model for each input sample. By dynamically identifying the task of each test sample through representation similarity and adaptively rescaling merging coefficients, SE-Merging achieves superior performance without additional training.

## Method Summary
SE-Merging computes task-specific representations at a designated layer of the merged model and compares them to expert model representations to identify the relevant task. It then rescales the merging coefficients using softmax over normalized similarity scores to enhance task-specific expertise. The method builds on Task Arithmetic by modifying the standard equation to use sample-specific coefficients. Implementation requires fine-tuning pre-trained models on individual tasks, extracting representations at a specific layer during inference, computing similarity-based weights, and performing dynamic merging. Key hyperparameters include the base merging coefficient (λ=0.3) and the probe layer selection.

## Key Results
- Achieves 84.96% average accuracy across 8 vision tasks with ViT-B/32, outperforming training-free baselines by 3.86%
- Achieves 76.86% average accuracy across 7 GLUE tasks with GPT-2, improving over TIES-Merging by 6.86%
- Reduces representation bias by aligning merged model representations more closely with corresponding fine-tuned models
- Demonstrates effectiveness on both vision (ViT-B/32, ViT-L/14) and language (GPT-2) architectures

## Why This Works (Mechanism)

### Mechanism 1: Representation Auto-Adaptation
The merged model implicitly retains the ability to mimic the representation geometry of the relevant expert model for each input sample. For a sample from task T_i, the merged model's activation at layer ℓ exhibits smaller ℓ₂ distance to the corresponding expert model's activation than to experts from unrelated tasks, allowing the model to "switch" modes based on input. This assumes fine-tuned models satisfy Weight Disentanglement where task-specific parameters don't destructively interfere across tasks.

### Mechanism 2: Implicit Task Routing via Similarity
Task identification occurs by comparing the merged model's representation against cached expert representations, acting as a training-free router. The system computes similarity (inverse ℓ₂ distance) between the test sample's representation in the merged model and its representations in all available expert models. The task with highest similarity is selected as active, and its merging coefficient is boosted.

### Mechanism 3: Coefficient Rescaling for Bias Alleviation
Amplifying the coefficient λ for the identified expert task reduces "representation bias," pulling the final output closer to optimal expert behavior. Once the task is identified, the method rescales merging coefficients (λ_target ≫ λ_others), effectively reweighting the dominant task's vector to override interference from other tasks in final layers.

## Foundational Learning

- **Concept: Task Arithmetic**
  - Why needed: SE-Merging builds directly upon Task Arithmetic framework (model = pre-trained + sum of task vectors). Understanding that a "task vector" is the parameter difference (τ = θ_FT - θ_PT) is essential to understand what's being rescaled.
  - Quick check: How does SE-Merging modify the standard Task Arithmetic equation θ_Merged = θ_PT + Σλ_iτ_i?

- **Concept: Representation Space Geometry (ℓ₂ Distance)**
  - Why needed: The core logic relies on measuring distances between activation vectors in hidden layers. Understanding that "closer in ℓ₂ distance" implies functional similarity is key.
  - Quick check: Why does the paper suggest deeper layers are better for validating the Representation Auto-Adaptation Hypothesis than earlier layers?

- **Concept: Weight Disentanglement**
  - Why needed: This is the theoretical assumption used to explain why model merging works at all. It suggests that for different tasks, the effective parameter space can be separated.
  - Quick check: Does the paper prove Weight Disentanglement, or does it assume it to explain empirical results?

## Architecture Onboarding

- **Component map:** Base Model Store -> Probe Engine -> SE-Merging Logic -> Merged Model
- **Critical path:** The inference loop requires: (1) Probe - Run forward pass up to layer ℓ to get r_Merged, (2) Route - Compute ℓ₂ distances and normalize to get similarity scores, (3) Rescale - Compute new coefficients via softmax/exp scaling, (4) Merge & Infer - Update weights and run full forward pass
- **Design tradeoffs:** Latency vs. Accuracy - method requires T partial forward passes (probes) or large cache of representations. Layer Selection (ℓ) - early layers compute faster but may lack task-specific discrimination; later layers are more accurate but increase probe latency
- **Failure signatures:** High Entropy Routing (flat similarity scores indicating poor task discrimination or uncovered tasks), Performance Collapse (rescaled coefficients destabilize pre-trained weights)
- **First 3 experiments:** (1) Hypothesis Validation - measure if merged representation is closest to correct expert representation at layer ℓ, (2) Layer Ablation - sweep layer index ℓ to find optimal depth, (3) Latency Profiling - measure inference time overhead vs. static merged model and full ensemble

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the Representation Auto-Adaptation Hypothesis hold for generative tasks, and can SE-Merging improve performance in that domain?
- Basis: Evaluations on broader task categories, such as generative tasks, are currently absent
- Why unresolved: Current study restricts experiments to vision and language classification tasks, leaving behavior in generative settings unverified
- Evidence needed: Empirical evaluations on generative benchmarks (text generation or image synthesis) to see if representation similarity effectively identifies tasks and rescaling improves output quality

### Open Question 2
- Question: Can SE-Merging be extended to merge heterogeneous models with distinct architectures?
- Basis: Existing works address merging heterogeneous models using Optimal Transport, but paper doesn't consider this scenario
- Why unresolved: SE-Merging relies on computing representation similarity at specific layers, requiring comparable layer structures and dimensions
- Evidence needed: Modified framework that aligns representation spaces of different architectures before computing similarity and rescaling coefficients

### Open Question 3
- Question: Can a rigorous theoretical foundation for Weight Disentanglement be established to fully support the Representation Auto-Adaptation Hypothesis?
- Basis: Theoretical analysis relies heavily on Weight Disentanglement, which has not yet been rigorously justified in deep neural networks
- Why unresolved: Hypothesis is currently supported empirically and theoretically only under the assumption of Weight Disentanglement, which remains unproven
- Evidence needed: Theoretical proof validating Weight Disentanglement in deep networks or alternative derivation not dependent on this assumption

## Limitations
- Effectiveness depends on unproven Weight Disentanglement assumption
- Dynamic routing mechanism creates computational bottleneck proportional to number of tasks
- Layer selection for representation probe remains heuristic without deterministic selection criterion
- Rescaling mechanism may become unstable with flat similarity scores or extreme coefficient magnitudes

## Confidence

**High Confidence:** Empirical results showing SE-Merging outperforming training-free baselines (3.86% on vision, 6.86% on language) and achieving competitive performance with training-based methods

**Medium Confidence:** Representation Auto-Adaptation Hypothesis mechanism itself - while paper provides distance metrics and visualizations, theoretical grounding in Weight Disentanglement is assumed rather than proven

**Low Confidence:** Practical deployment viability given inference-time overhead of multiple representation extractions - paper doesn't adequately address whether accuracy gains justify computational cost

## Next Checks

1. **Layer Selection Ablation:** Systematically sweep layer ℓ across the architecture to identify optimal probe locations and quantify sensitivity to this hyperparameter choice

2. **Computational Overhead Measurement:** Compare inference latency of SE-Merging against static merged models and full ensemble methods to quantify real-world efficiency trade-off

3. **Task Coverage Robustness:** Test SE-Merging on tasks not seen during training to evaluate whether high-entropy routing (indicating task ambiguity) correlates with performance degradation