---
ver: rpa2
title: Workflow for Safe-AI
arxiv_id: '2503.14563'
source_url: https://arxiv.org/abs/2503.14563
tags:
- workflow
- onnx
- system
- architecture
- safety
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of ensuring safety and dependability
  in AI models, particularly deep neural networks, for applications requiring functional
  safety. The authors propose a lightweight, qualifiable AI workflow that minimizes
  tool dependencies by leveraging the ONNX model format.
---

# Workflow for Safe-AI

## Quick Facts
- arXiv ID: 2503.14563
- Source URL: https://arxiv.org/abs/2503.14563
- Reference count: 14
- One-line primary result: Lightweight, qualifiable AI workflow using ONNX format maintains model accuracy while incorporating reliability guarantees for safety-critical applications

## Executive Summary
This paper addresses the challenge of ensuring safety and dependability in AI models, particularly deep neural networks, for applications requiring functional safety. The authors propose a lightweight, qualifiable AI workflow that minimizes tool dependencies by leveraging the ONNX model format. The workflow includes two key architecture validators: one ensures structural consistency between pre-trained and trained models, and the other verifies the integrity of partitioned models with reliability features. The workflow is designed to align with the V-model development process, enabling systematic verification and validation.

## Method Summary
The method involves building CNN models directly as ONNX graphs and training them using ONNX Runtime, avoiding framework dependencies. The workflow uses two architecture validators: the first ensures structural consistency between pre-trained and trained models by comparing layer topology, hyperparameters, and input-output mappings; the second validates partitioned models to ensure recombination reconstructs the original architecture with documented reliability features. Model partitioning separates reliable execution paths (e.g., redundant convolution) from non-reliable paths based on attribute files. The approach is demonstrated using AlexNet architecture with modified first convolutional layer for shape recognition tasks.

## Key Results
- The proposed workflow maintains model accuracy while incorporating reliability guarantees
- Architecture validation successfully preserves structural consistency between pre-trained and trained models
- Partitioned models can be validated to reconstruct original architecture with documented safety functions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Architectural consistency validation between pre-trained and trained models preserves algorithmic integrity while permitting weight updates.
- Mechanism: The first architecture validator extracts metadata from the pre-trained model (layer topology, hyperparameters, input-output mappings), establishes it as reference, then compares the trained model against this reference. Only modifications to trainable parameters are permitted; structural changes trigger error reports.
- Core assumption: Unauthorized architectural modifications during training indicate integrity violations that compromise qualifiability.
- Evidence anchors:
  - [abstract] "one ensures structural consistency between pre-trained and trained models"
  - [section IV] "This step ensures that the training processes did not modify the architecture of the algorithm, preserving the model's validity and traceability"
  - [corpus] Weak direct corpus support; related work on safety-critical development (CAS for DO-178C) shares verification philosophy but differs in domain
- Break condition: If the training framework modifies non-trainable parameters or topology by design (e.g., architecture search), the validator would reject legitimate models.

### Mechanism 2
- Claim: A single-format (ONNX) workflow reduces tool qualification overhead while maintaining end-to-end traceability.
- Mechanism: By creating, training, validating, and deploying models entirely within the ONNX representation, the workflow eliminates format conversions that would each require tool qualification. The ONNX graph serves as the single source of truth from definition through runtime.
- Core assumption: Tool qualification cost scales with number of tools and format transitions; minimizing both reduces overall qualification burden.
- Evidence anchors:
  - [abstract] "We therefore place value on a lightweight workflow featuring a minimal number of tools with limited features"
  - [section III] "We prove that there is no significant difference in the accuracy when training the same model in Tensorflow and ONNX on the same dataset"
  - [corpus] No direct corpus validation of this specific ONNX-centric claim; related papers focus on LLM workflows rather than neural network deployment qualification
- Break condition: If ONNX cannot represent critical model features (e.g., custom operators without registered domain), the workflow cannot accommodate those models without breaking traceability.

### Mechanism 3
- Claim: Model partitioning with recombination validation enables mixed-criticality execution by separating reliable and non-reliable execution paths.
- Mechanism: The Model Partitioner splits the validated ONNX model into two runtime files—one for reliable platforms (containing safety functions like redundant convolution), one for non-reliable platforms. The second architecture validator verifies that recombined files reconstruct the original architecture while documenting added reliability features.
- Core assumption: Reliability features can be isolated to specific model regions (e.g., first convolutional channel with Sobel filter) without affecting overall model accuracy.
- Evidence anchors:
  - [section II] "We have shown that the kernel replacement does not negatively affect the CNN's accuracy as it remains the same as the original model"
  - [section IV] "The second architecture validator is responsible for validating partitioned files, ensuring that when combined, they accurately reconstruct the original trained model"
  - [corpus] No direct corpus support for partitioning-recombination validation pattern
- Break condition: If safety functions require distributed modifications across many layers, partitioning complexity may exceed practical validation capabilities.

## Foundational Learning

- Concept: **Functional Safety Standards (IEC 61508)**
  - Why needed here: The entire workflow is designed to satisfy functional safety qualification requirements, where tool qualification and deterministic verification are mandatory.
  - Quick check question: Can you explain why tool qualification matters in safety-critical systems, and what makes it resource-intensive?

- Concept: **ONNX Intermediate Representation**
  - Why needed here: ONNX serves as the unified model format; understanding its graph structure (nodes, inputs, outputs, initializers, metadata) is essential for implementing validators.
  - Quick check question: Given an ONNX model file, could you extract and compare the layer topology between two versions programmatically?

- Concept: **V-Model Development Process**
  - Why needed here: The workflow explicitly maps to V-model phases; each design stage has corresponding verification activities.
  - Quick check question: In the V-model, what is the relationship between the architecture design phase and its corresponding testing phase?

## Architecture Onboarding

- Component map:
  - ONNX File A: Pre-trained model definition (input to training)
  - ONNX File B: Trained model output
  - Validator 1: Architecture consistency checker (A vs B) → produces ONNX File C
  - ONNX File C: Qualified/validated model with embedded metadata
  - Attribute File: Reliability feature specifications
  - Model Partitioner: Splits C into runtime files based on attributes
  - ONNX Files D/E: Partitioned models for reliable/non-reliable execution
  - Validator 2: Recombination validator (D + E → reconstructs C topology)

- Critical path: Model definition (A) → Training (B) → Architecture validation (C) → Partitioning (D, E) → Recombination validation → Deployment

- Design tradeoffs:
  - Accuracy vs. reliability: Sobel kernel insertion in first channel maintains accuracy but may slightly alter confusion matrix (per Section II)
  - Tool simplicity vs. capability: Restricting to ONNX-native operations limits model architecture choices
  - Qualification cost vs. flexibility: Fewer tools reduces qualification effort but constrains training framework options

- Failure signatures:
  - Validator 1 rejection: Layer count mismatch, hyperparameter changes, input/output dimension alterations between A and B
  - Validator 2 rejection: Partitioned files fail to reconnect properly, safety functions missing from documentation, unauthorized architecture modifications
  - Runtime validation failure: Redundant convolution operations yield different results (indicates hardware/software fault)

- First 3 experiments:
  1. Train an AlexNet variant directly in ONNX format on a shape classification dataset; compare accuracy against TensorFlow-trained equivalent to validate "no significant difference" claim.
  2. Implement Validator 1 in Python to compare two ONNX files (pre/post training); verify it correctly identifies unauthorized structural changes vs. legitimate weight updates.
  3. Partition a model with a reliable Sobel convolution channel; use Validator 2 to confirm recombination produces original architecture with documented safety functions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed ONNX-based workflow scale to modern, complex architectures (e.g., Transformers, LLMs) compared to the demonstrated AlexNet use case?
- Basis in paper: [inferred] The paper validates the workflow using AlexNet, a relatively simple and established CNN architecture, for a shape recognition task.
- Why unresolved: The structural complexity, dynamic control flows, and parameter counts of state-of-the-art models may exceed the capabilities of the current "lightweight" validators or introduce latency not observed in the AlexNet trial.
- What evidence would resolve it: A demonstration of the workflow successfully validating and partitioning a Transformer-based model or a modern high-parameter network without excessive computational overhead.

### Open Question 2
- Question: What is the specific methodology for qualifying the Python-based architecture validators to meet rigorous functional safety standards (e.g., IEC 61508)?
- Basis in paper: [inferred] The paper mandates that "the workflow must be qualifiable, which demands the use of qualified tools," yet explicitly notes that the validators are "implemented in Python," a language often challenged in safety-critical certification.
- Why unresolved: While the paper outlines a V-model process for the system, it does not detail how the validator code itself—a critical dependency—overcomes the inherent difficulties of qualifying Python interpreters and dynamic typing for safety-critical applications.
- What evidence would resolve it: A certification report or a defined tool qualification plan specifically for the Python validators within a functional safety framework.

### Open Question 3
- Question: Does training models directly in the ONNX format impose constraints on convergence rates or optimization efficiency compared to native frameworks like PyTorch or TensorFlow?
- Basis in paper: [inferred] The authors assert that the model is "directly built as onnx graph and trained" to minimize tool dependencies, claiming accuracy parity with TensorFlow.
- Why unresolved: While final accuracy is claimed to be similar, the paper does not analyze the computational efficiency, training time, or convergence stability of the ONNX training loop compared to highly optimized native framework backends.
- What evidence would resolve it: Comparative benchmarks showing training loss curves, epoch times, and computational resource usage for ONNX training versus standard frameworks on identical tasks.

### Open Question 4
- Question: What is the quantifiable runtime latency and memory overhead introduced by the model partitioning and the recombination of execution results?
- Basis in paper: [inferred] The workflow introduces a "Model Partitioner" and a mechanism to recombine reliable and non-reliable execution paths, claiming "low computational cost."
- Why unresolved: The paper provides qualitative arguments for low cost but lacks quantitative measurements of the latency added by the partitioning logic and the synchronization of split execution paths, which is critical for real-time safety systems.
- What evidence would resolve it: Timing analysis data from the deployed runtime showing the delta in inference latency between the partitioned model and the standard monolithic model.

## Limitations

- The workflow's effectiveness in real-world safety-critical deployments lacks independent validation and certification body acceptance
- ONNX training approach represents a departure from standard practice that may encounter implementation challenges not addressed in the paper
- Complete end-to-end workflow specification remains underspecified for direct reproduction

## Confidence

- **High Confidence**: The architectural consistency validation mechanism is well-specified and grounded in established safety verification principles
- **Medium Confidence**: The ONNX workflow claims are plausible but lack direct empirical validation against alternative approaches
- **Low Confidence**: The complete end-to-end workflow, including attribute file format and redundant operator implementation, remains underspecified

## Next Checks

1. **Dataset Specification Validation**: Request the exact dataset specifications (name, source, size, preprocessing pipeline) used in the shape recognition experiments to enable accurate reproduction and benchmarking.

2. **ONNX Training Implementation**: Verify the ONNX training implementation details by either obtaining the training code or successfully replicating the accuracy results using publicly available ONNX training tools.

3. **Certification Pathway Analysis**: Engage with certification bodies (TÜV, UL, etc.) to assess whether the proposed workflow meets their requirements for AI tool qualification in functional safety contexts.