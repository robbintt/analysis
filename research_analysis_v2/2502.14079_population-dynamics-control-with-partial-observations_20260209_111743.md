---
ver: rpa2
title: Population Dynamics Control with Partial Observations
arxiv_id: '2502.14079'
source_url: https://arxiv.org/abs/2502.14079
tags:
- utpm
- control
- have
- lemma
- k0qq
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of controlling population dynamics
  under partial observability within the online non-stochastic control framework.
  The key challenge is that the standard approach of using past disturbances as control
  inputs becomes infeasible when only low-dimensional observations are available.
---

# Population Dynamics Control with Partial Observations

## Quick Facts
- **arXiv ID:** 2502.14079
- **Source URL:** https://arxiv.org/abs/2502.14079
- **Reference count:** 40
- **One-line result:** Novel controller achieves $\tilde{O}(\sqrt{T})$ regret for population dynamics with partial observability using convex surrogate losses and hypothetical signal reconstruction

## Executive Summary
This paper tackles the challenging problem of controlling population dynamics under partial observability in an online non-stochastic setting. The key innovation is developing a controller that can compete with general mixing linear dynamic controllers while only having access to low-dimensional observations. The authors introduce three major technical innovations: a method for reconstructing oblivious signals under partial observability using constant-control counterfactuals, a new convex controller parameterization that approximates general control policies, and a novel convex extension surrogate loss that bypasses the convexity issues introduced by projecting onto the probability simplex.

## Method Summary
The algorithm implements Online Gradient Descent on a convex surrogate loss constructed via Minkowski extension. It reconstructs hypothetical signals under a constant control policy, uses a truncated memory parameterization to approximate general linear dynamic controllers, and performs gradient updates in an unconstrained space before projecting controls onto the simplex. The method requires knowledge of system matrices (A, B, C) and achieves regret bounds that scale polynomially with the state dimension and mix with $\sqrt{T}$.

## Key Results
- Achieves $\tilde{O}(\sqrt{T})$ regret against mixing linear dynamic controllers
- Successfully handles the interplay between partial observability and simplex constraints
- Demonstrates polynomial dimension dependence ($\tilde{O}(d^{6.5}\sqrt{T})$) in regret bounds
- Introduces novel signal reconstruction technique for counterfactual observations

## Why This Works (Mechanism)

### Mechanism 1: Constant-Control Signal Substitution
The algorithm computes a signal $o_t$ by calibrating raw observation $y_t$ against a hypothetical trajectory generated by fixed linear policy $K_0$. This isolates the disturbance-driven component of observation, effectively "subtracting" influence of past actions to recover signal that would have existed under $K_0$. The core assumption is that system matrices $(A, B, C)$ are known and the system is marginally stable (mixing).

### Mechanism 2: Minkowski Extension for Convexity Preservation
Uses convex surrogate loss (Minkowski extension) to decouple parameter update from non-convexity induced by projecting control outputs onto probability simplex. Defines surrogate loss $e_t(M)$ on unconstrained raw control space using Minkowski functional $\pi_K$. Performs gradient descent on this convex surrogate, projecting only at moment of execution. Relies on Lipschitz property of Minkowski functional for the re-centered simplex set $K$.

### Mechanism 3: Memory Truncation via Mixing Time
Uses finite memory $H$ to approximate infinite-horizon optimal controller if system dynamics mix sufficiently fast. Parameterization uses history window of size $H$. Leverages "mixing time" $\tau$ to show error introduced by ignoring observations older than $H$ decays exponentially. Reduces optimization dimension from $t$ to $H$, making problem tractable. Requires $H \geq 2\tau$ for bounded approximation error.

## Foundational Learning

- **Online Non-Stochastic Control:** Needed because disturbances $w_t$ are adversarial or arbitrary, requiring regret minimization strategies rather than standard LQR optimal control. Quick check: Can you explain why knowing system matrices $(A,B)$ is not enough to compute optimal control if you don't know future disturbances?

- **Linear Dynamical Controllers (LDCs):** Needed because comparator class is not just static gain but dynamic system with internal state. Understanding how LDCs generalize static feedback is crucial for grasping "expressivity" requirements of new parameterization. Quick check: How does internal state $s_t$ help controller under partial observability compared to Markov policy $u_t = K y_t$?

- **Minkowski Functional (Gauge Function):** Needed as mathematical tool to create convex extension. Must understand $\pi_K(x)$ as scaling factor required to map point $x$ onto boundary of feasible set $K$. Quick check: Why is Minkowski projection $x / \pi_K(x)$ non-expansive, and why does that matter for gradient descent?

## Architecture Onboarding

- **Component map:** Signal Generator -> Parameter Store -> Surrogate Loss Calculator -> Optimizer -> Actuator
- **Critical path:** The Signal Generator (Line 4, Algo 1) is most brittle component. It assumes exact knowledge of $A, B, C$ to perform unrolling calculation. Any model mismatch here injects bias directly into "oblivious" signal, potentially invalidating regret bounds.
- **Design tradeoffs:** Memory $H$ vs. Accuracy requires $H$ to scale with mixing time $\tau$. Increasing $H$ improves approximation of optimal LDC but increases dimensionality (computational cost $\propto H$) and potentially variance. Surrogate vs. True Cost optimizes surrogate $e_t$ to allow convexity but introduces "extension mismatch error."
- **Failure signatures:** Constraint Drift if Minkowski projection logic is implemented incorrectly, $u_t$ may not sum to 1. Signal Divergence if $\tau$ is underestimated, truncation error may explode, causing controller to lag significantly behind optimal LDC. Non-convex Optimization if you attempt to backpropagate through projection step rather than $\nabla e_t(M)$, optimization landscape becomes non-convex.
- **First 3 experiments:** (1) Sanity Check with Full Observation: Run algorithm in fully observable setting where $C=I$. Compare performance against standard GPC-Simplex to verify overhead of partial observability machinery. (2) Ablation on Surrogate Loss: Compare proposed Minkowski surrogate loss against naive "Projected Gradient Descent" approach. Plot regret curves to visualize "convexity break" in naive baseline. (3) Sensitivity to Mixing Time: Synthetic system with tunable $\tau$. Vary $\tau$ and plot final regret vs. $H$. Verify regret remains $\tilde{O}(\sqrt{T})$ only when $H \propto \tau$.

## Open Questions the Paper Calls Out

### Open Question 1
Can the proposed controller be adapted to settings where system matrices ($A, B, C$) are unknown? The algorithms explicitly require $A, B, C$ as inputs to construct oblivious signals $o_t$. Removing this assumption requires simultaneous system identification and control in non-stochastic environment.

### Open Question 2
Can polynomial dependence on state dimension $d_x$ in regret bounds be significantly improved? Theorems 11 and 18 establish regret bounds with high polynomial dependence on dimension ($\tilde{O}(d^{6.5}\sqrt{T})$ and $\tilde{O}(d^{8}\sqrt{T})$). The analysis accumulates dimension factors through repeated norm conversions and Lipschitz properties of Minkowski extension on simplex.

### Open Question 3
Can framework be extended to handle noisy observations ($y_t = Cx_t + \eta_t$)? Definition 1 defines observation mechanism as noiseless ($y_{t+1} = Cx_{t+1}$), despite citing Kalman filter which typically assumes measurement noise. Introduction of observation noise would corrupt oblivious signals used for control parameterization, potentially breaking convexity of surrogate loss and signal realizability lemma.

## Limitations
- Requires exact knowledge of system matrices $(A, B, C)$ for signal reconstruction
- Polynomial dependence on state dimension $d_x$ in regret bounds may be prohibitive for high-dimensional systems
- Performance relies critically on mixing time assumptions that may not hold in real-world systems

## Confidence
- **Signal Reconstruction Mechanism:** Medium-High - Theoretical construction is sound but requires exact system matrix knowledge
- **Minkowski Extension Approach:** Medium-High - Convexity preservation argument is rigorous, though Lipschitz constant dependency on dimensionality is concerning
- **Mixing Time Approximation:** Medium - Memory truncation analysis depends critically on mixing time bound, which may be conservative

## Next Checks
1. **Implementation Verification:** Reproduce simplex projection and Minkowski functional calculations on simple test cases to verify mathematical derivations match actual implementations.

2. **Sensitivity Analysis:** Systematically vary mixing time $\tau$ and observe impact on required memory $H$ and final regret performance to validate $H \propto \tau$ relationship.

3. **Robustness Testing:** Evaluate algorithm performance under model mismatch (perturbed $A, B, C$ matrices) to assess sensitivity to exact system knowledge assumption in signal reconstruction.