---
ver: rpa2
title: 'Markov-Enhanced Clustering for Long Document Summarization: Tackling the ''Lost
  in the Middle'' Challenge with Large Language Models'
arxiv_id: '2506.18036'
source_url: https://arxiv.org/abs/2506.18036
tags:
- summarization
- document
- text
- https
- clustering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the "lost in the middle" challenge in long document
  summarization, where key information is lost when processing lengthy texts with
  LLMs. The authors propose a hybrid approach combining extractive and abstractive
  techniques.
---

# Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models

## Quick Facts
- arXiv ID: 2506.18036
- Source URL: https://arxiv.org/abs/2506.18036
- Authors: Aziz Amari; Mohamed Achref Ben Ammar
- Reference count: 34
- Primary result: Proposed method achieves ROUGE-1 of 34.13 and coherence score of 0.863 on BookSum dataset, outperforming baseline approaches.

## Executive Summary
This paper addresses the "lost in the middle" challenge in long document summarization, where large language models struggle to retain key information when processing lengthy texts. The authors propose a hybrid approach combining extractive and abstractive techniques. Their method involves chunking documents, clustering semantic embeddings, summarizing each cluster, and using a Markov chain to determine the optimal semantic sequence for the final summary. Evaluation on the BookSum dataset demonstrates superior performance compared to both direct LLM summarization and cluster-based methods without sequence selection, achieving higher ROUGE scores and coherence metrics.

## Method Summary
The proposed method processes long documents through a multi-stage pipeline. First, documents are split into 500-token chunks with 20-token overlap. These chunks are converted to vector embeddings using nomic-embed-text-v1 and clustered using K-Means++. For each cluster, the top 5 chunks closest to the centroid are selected and summarized using GPT-4o-mini. A Markov chain transition matrix is constructed based on the sequential order of clusters in the source text, and a Hamiltonian path algorithm identifies the optimal sequence for narrative flow. Finally, the ordered cluster summaries are concatenated and summarized by GPT-4o-mini to produce the final output.

## Key Results
- Achieves ROUGE-1 score of 34.13 and ROUGE-2 score of 6.392 on BookSum dataset
- Coherence scores of 0.863 (1st-O) and 0.862 (2nd-O) outperform baseline methods
- Demonstrates superior information retention compared to direct LLM summarization (ROUGE-1: 23.99) and cluster-based methods without sequence selection
- Shows effectiveness in capturing essential elements while maintaining logical flow

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Semantic ordering via Markov chain pathfinding improves summary coherence when source documents have discernible narrative structure
- **Mechanism**: Transition matrix built from sequential cluster order; Hamiltonian path algorithm finds sequence maximizing transition probabilities
- **Core assumption**: Sequential proximity in source text maps to logical flow; high-probability Markov path represents coherent narrative
- **Evidence anchors**: Abstract mentions Markov chain for semantic order; section 3.1 details transition matrix construction
- **Break condition**: Degrades when source lacks clear linear narrative or has highly interleaved thematic clusters

### Mechanism 2
- **Claim**: Clustering and centroid sampling reduces context length and mitigates information loss
- **Mechanism**: Summarizes only top_k=5 chunks closest to each cluster centroid rather than full document
- **Core assumption**: Centroid and nearest neighbors sufficiently proxy key information within clusters
- **Evidence anchors**: Abstract describes cluster-based summarization; section 3.1 details top_k selection
- **Break condition**: Misses key information if it's an outlier within its cluster and not represented by centroid neighbors

### Mechanism 3
- **Claim**: Task decomposition via clustering counters "lost in the middle" by ensuring all thematic regions receive full attention
- **Mechanism**: Multiple smaller prompts (one per cluster) instead of single large prompt for entire document
- **Core assumption**: "Lost in the middle" stems from attention dilution over long contexts, mitigated by processing thematic sections with full attention
- **Evidence anchors**: Abstract defines "lost in the middle" challenge; section 4 shows superior performance capturing essential elements
- **Break condition**: Final aggregation could reintroduce information loss if cluster summaries are numerous enough

## Foundational Learning

- **Concept: Markov Chains and Transition Matrices**
  - **Why needed here**: Core logic for re-ordering summaries; understand how transition matrix represents probability of moving between clusters
  - **Quick check question**: If clusters A, B, C appear in order A→B→A→C, what is transition probability from A to B?

- **Concept: Vector Embeddings and Semantic Space**
  - **Why needed here**: Method relies on grouping semantically similar text mathematically; understand embeddings project text into space where distance equals semantic similarity
  - **Quick check question**: Would two chunks using different words to describe same event be close together or far apart in semantic space?

- **Concept: Hamiltonian Path Problem**
  - **Why needed here**: Used to find single best path through all clusters; understand it visits each node exactly once and why dynamic programming solution is required
  - **Quick check question**: Why can't system use order clusters first appear in document, and why does Hamiltonian path provide superior solution for narrative flow?

## Architecture Onboarding

- **Component map**: Chunking (500 tokens, 20 overlap) -> Embedding Generator (nomic-embed-text-v1) -> Clustering Module (Kmeans++) -> Cluster Summarizer (LLM on top_k=5 centroid neighbors) -> Markov Builder (transition matrix from cluster sequence) -> Pathfinder (DP with bitmasking for Hamiltonian path) -> Final Summarizer (LLM on concatenated, sequenced summaries)

- **Critical path**: Pathfinder is most computationally sensitive component; brute-force fails at n~11, DP hits limits at n~22; entire system constrained by clusters <~22

- **Design tradeoffs**: Choice of k (clusters) and top_k (centroid neighbors) directly tradeoffs granularity vs computational cost; fewer clusters simplify pathfinding but risk merging distinct themes; lower top_k reduces token cost but increases risk of missing details

- **Failure signatures**:
  - Pathfinder Timeout: Algorithm's O(n² * 2ⁿ) complexity causes timeouts if clustering produces >~22 clusters
  - Incoherent Final Summary: Occurs if Markov model built on document with no clear thematic progression
  - Missing Key Information: Sign that top_k=5 is too small for dense/varied clusters

- **First 3 experiments**:
  1. Baseline Reproduction: Run pipeline on BookSum to reproduce ROUGE-1 (34.13) and Coherence (1st-O: 0.863) scores; validate "Lost in the Middle" effect vs LLM-Full baseline (R-1: 23.99)
  2. Ablation of Markov Ordering: Replace Hamiltonian path with sequential order (first appearance) to measure Markov re-ordering's specific contribution to coherence
  3. Cluster Size Scaling Test: Incrementally increase target clusters (k) toward 22-node limit to observe performance degradation point

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does restricting clusters to n < 22 to facilitate DP solution compromise information retention vs using larger number of thematic clusters?
- Basis in paper: [explicit] Conclusion states "determining whether limiting clustering to values of n < 22 improves performance or negatively impacts summarization quality" requires further evaluation
- Why unresolved: Current implementation uses DP approach impractical beyond 22 nodes, forcing constraint on cluster count
- What evidence would resolve it: Ablation study comparing ROUGE/Coherence when forcing k=22 clusters vs k > 22 (using approximation algorithm) on same dataset

### Open Question 2
- Question: Can greedy sequence selection strategy effectively maintain narrative coherence achieved by optimal Hamiltonian path while efficiently handling large n?
- Basis in paper: [explicit] Authors plan to "explore greedy sequence selection strategy to efficiently handle large values of n" addressing O(n² · 2ⁿ) complexity
- Why unresolved: Current optimal method is computationally expensive and limited to small n, but unknown if faster approximate methods would degrade semantic flow
- What evidence would resolve it: Comparative runtime analysis and quality metrics between DP approach and proposed greedy heuristic on documents with high cluster density

### Open Question 3
- Question: Is Markov-Enhanced Clustering method effective for non-narrative long documents like business reports or technical papers, or is it overfitted to narrative structure of books?
- Basis in paper: [explicit] Conclusion notes intent to "extend our method to diverse datasets beyond books, including different types of long documents such as business reports and technical papers"
- Why unresolved: Method evaluated exclusively on BookSum, dataset of narrative fiction which may possess distinct semantic progression patterns vs technical/analytical writing
- What evidence would resolve it: Benchmarking proposed method against baselines on dataset like FacetSum or SCROLLS containing non-narrative, structured documents

## Limitations

- Computational constraint limits cluster count to n < 22, potentially impacting performance on longer documents
- Method's effectiveness depends on source document having discernible narrative structure that may not hold for all document types
- Centroid-based sampling strategy may systematically exclude important outlier information within clusters

## Confidence

- **High confidence**: "Lost in the middle" problem is well-documented and task decomposition for long documents has strong supporting evidence
- **Medium confidence**: Markov chain ordering mechanism is theoretically sound and shows coherence improvements, but depends heavily on source document structure
- **Low confidence**: Specific contribution of centroid-based sampling strategy is uncertain due to lack of direct evidence

## Next Checks

1. **Hamiltonian Path Sensitivity**: Run algorithm on documents with known different narrative structures (linear, non-linear, randomly ordered) to determine whether Markov ordering consistently improves coherence or if improvements are contingent on specific document types

2. **Cluster Count Scaling**: Systematically vary target number of clusters (k) from 5 to 22 while measuring ROUGE and coherence scores to identify optimal granularity and test hypothesis that too few clusters cause theme merging while too many cause computational failure

3. **Information Retention Analysis**: For documents where method achieves high ROUGE scores, perform detailed comparison between original document's key information and what appears in final summary to verify centroid sampling strategy isn't systematically excluding important outlier information within clusters