---
ver: rpa2
title: 'REFORMER: A ChatGPT-Driven Data Synthesis Framework Elevating Text-to-SQL
  Models'
arxiv_id: '2504.04363'
source_url: https://arxiv.org/abs/2504.04363
tags:
- data
- question
- query
- queries
- chatgpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents REFORMER, a ChatGPT-driven framework for data
  synthesis to enhance Text-to-SQL models. The approach addresses the challenge of
  limited training data in new domains by using a "retrieve-and-edit" method that
  generates new (question, SQL query) pairs without additional training.
---

# REFORMER: A ChatGPT-Driven Data Synthesis Framework Elevating Text-to-SQL Models

## Quick Facts
- arXiv ID: 2504.04363
- Source URL: https://arxiv.org/abs/2504.04363
- Reference count: 32
- Key outcome: REFORMER achieves 3.6% improvement in Exact Set Match and 4.7% in Execution Accuracy on Spider dataset using ChatGPT-driven data synthesis

## Executive Summary
REFORMER presents a novel ChatGPT-driven framework for data synthesis that enhances Text-to-SQL models without requiring additional training data or fine-tuning. The framework addresses the challenge of limited training data in new domains by using a "retrieve-and-edit" approach that generates new (question, SQL query) pairs while preserving the structural linguistic patterns of the training distribution. The method combines SQL query retrieval based on structural similarity, template-based question generation using ChatGPT explanations, and cycle-consistency validation to filter high-quality synthetic data. Experimental results demonstrate consistent improvements over previous data augmentation methods across multiple domains on the Spider benchmark.

## Method Summary
REFORMER uses a retrieve-and-edit pipeline to synthesize training data for Text-to-SQL models. First, it retrieves structurally similar SQL queries from existing datasets using tree-edit-distance (threshold <0.1). The corresponding questions have schema-specific words masked based on frequency (words appearing in >50% of schemas are retained). ChatGPT generates one-sentence explanations of the SQL queries without using table names, which are then used to fill the masked templates. A novel cycle-consistency validation approach compares the similarity between generated questions and independent SQL query explanations using cosine similarity of ChatGPT embeddings (threshold λ=0.85). The framework also explores direct paraphrasing methods using schema information and crafted SQL query descriptions. The augmented data is used to fine-tune the SmBop Text-to-SQL model, achieving consistent improvements on the Spider benchmark.

## Key Results
- Outperforms previous data augmentation methods with 3.6% improvement in Exact Set Match and 4.7% in Execution Accuracy on Spider dev set
- REFORMER consistently improves performance across multiple domains (music, pets, university, country) except one case
- Cycle-consistency validation effectively filters hallucinated data pairs while maintaining high-quality synthetic data
- Template-based approach shows better stability than direct paraphrasing, though with lower diversity

## Why This Works (Mechanism)

### Mechanism 1: Structure-Preserving Template Generation
- **Claim:** Preserving structural linguistic patterns while swapping domain-specific tokens allows safer domain adaptation than generating questions from scratch
- **Mechanism:** The framework retrieves SQL queries with high structural similarity and masks only schema-specific words in corresponding questions, retaining the syntactic skeleton of natural language
- **Core assumption:** The logical structure of natural language questions correlates strongly with SQL relational algebra trees regardless of database domain
- **Evidence anchors:** [section III.A] masks words appearing in <50% of schemas; [abstract] describes filling masked questions using SQL explanations
- **Break condition:** Complex nested logic (EXCEPT, INTERSECT) not in training set causes structural mismatch

### Mechanism 2: SQL-to-Text Explanation Bridge
- **Claim:** Using intermediate natural language explanations bridges semantic gaps better than direct SQL-to-text generation
- **Mechanism:** ChatGPT generates one-sentence SQL explanations without table names, describing intent rather than syntax
- **Core assumption:** ChatGPT can accurately summarize SQL logic into human-readable text without hallucinating operations
- **Evidence anchors:** [section III.B] instructs ChatGPT to explain SQL without table names; [section VI.D] notes unnatural tone in direct paraphrasing errors
- **Break condition:** Obscure abbreviations or semantically meaningless column names cause incorrect explanations

### Mechanism 3: Cycle-Consistency Validation
- **Claim:** "Question-Query-Question" cycle consistency using embedding similarity effectively filters hallucinated data pairs
- **Mechanism:** Generates second independent SQL explanation and computes cosine similarity between question and explanation embeddings
- **Core assumption:** Valid question-SQL explanation pairs map to proximate vectors in ChatGPT embedding space
- **Evidence anchors:** [abstract] describes comparing similarity using cosine similarity; [section III.C] filters based on satisfactory consistency
- **Break condition:** Grammatically correct but logically inverted questions may pass filtering with high embedding similarity

## Foundational Learning

- **Concept: Tree-Edit Distance**
  - **Why needed here:** Quantifies structural similarity between SQL queries for retrieval component
  - **Quick check question:** How would you calculate distance between `SELECT name FROM users` and `SELECT id FROM products`? (Answer: Low distance, structure identical, only leaf nodes differ)

- **Concept: In-Context Learning**
  - **Why needed here:** Framework relies on ChatGPT performing tasks without weight updates using few-shot examples
  - **Quick check question:** Why provide original (question, SQL query) pairs in prompt if not fine-tuning? (Answer: Guide output style/structure via few-shot examples)

- **Concept: Cycle Consistency**
  - **Why needed here:** Used for validation involving forward pass and verification pass
  - **Quick check question:** Why generate new explanation for validation rather than reusing original? (Answer: Avoid bias where model matches previous output without ensuring factual accuracy)

## Architecture Onboarding

- **Component map:** Input (QSnew, Dtrain) -> Retriever (tree-edit-distance) -> Masker (frequency-based masking) -> Generator (ChatGPT: SQL→Explanation, Template+Explanation→Question) -> Validator (Embeddings→Cosine Sim→Threshold check)
- **Critical path:** Retrieve-and-Edit pipeline (Fig 1A); Retriever failure causes Masker to produce poor template, leading Generator to fill incorrectly
- **Design tradeoffs:** Template vs Free-form (templates offer higher fidelity but lower diversity); Threshold λ (high reduces data size but increases quality)
- **Failure signatures:** "Diversity leading to confusion" (ChatGPT uses synonyms not linked by parser); "Question Template Mismatch" (template implies different operation than SQL)
- **First 3 experiments:** 1) Ablation on Components (validation vs augmentation only), 2) Threshold Sensitivity Analysis (vary λ for Direct Paraphrasing), 3) Error Taxonomy Audit (inspect specific error types from Figure 3)

## Open Questions the Paper Calls Out
- Can automatic prompt generation outperform manually crafted prompts for REFORMER's data synthesis? (Conclusion explicitly calls for exploring automatic prompt generation)
- How does REFORMER perform with other LLMs besides ChatGPT? (Conclusion explicitly calls for testing other LLMs and datasets)
- What is the optimal threshold λ for cycle-consistency validation across domains? (Threshold chosen empirically without sensitivity analysis)

## Limitations
- Performance heavily depends on quality of retrieved templates through tree-edit-distance similarity
- Cycle-consistency validation assumes semantic embedding similarity reliably indicates factual alignment, which may not hold for logically inverted but grammatically correct questions
- Template-based approach shows better stability than direct paraphrasing but with lower diversity

## Confidence
- **High Confidence:** Retrieve-and-edit mechanism preserves training distribution patterns and outperforms direct paraphrasing methods
- **Medium Confidence:** Cycle-consistency validation using cosine similarity effectively filters hallucinated data pairs
- **Low Confidence:** Assumption that ChatGPT explanations bridge semantic gaps better than direct SQL-to-text generation

## Next Checks
1. **Threshold Sensitivity Analysis:** Systematically vary tree-edit-distance threshold (0.05-0.2) and cycle-consistency threshold (0.8-0.95) to quantify impact on data quality vs. quantity tradeoff
2. **Template vs. Free-form Diversity:** Compare REFORMER's template-based approach against direct ChatGPT generation on same SQL queries to measure diversity-fidelity balance
3. **Error Type Classification Audit:** Manually categorize filtered pairs by failure mode to determine if prompt engineering or masking logic needs refinement