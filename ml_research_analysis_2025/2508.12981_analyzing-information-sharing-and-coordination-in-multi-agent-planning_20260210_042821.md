---
ver: rpa2
title: Analyzing Information Sharing and Coordination in Multi-Agent Planning
arxiv_id: '2508.12981'
source_url: https://arxiv.org/abs/2508.12981
tags:
- plan
- system
- agents
- notebook
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study analyzes multi-agent systems for long-horizon planning
  by evaluating two mechanisms: a notebook for structured information sharing and
  an orchestrator agent for dynamic coordination. The notebook reduces hallucinations
  by 18% by allowing agents to ground their plans in structured facts rather than
  conversational context.'
---

# Analyzing Information Sharing and Coordination in Multi-Agent Planning

## Quick Facts
- arXiv ID: 2508.12981
- Source URL: https://arxiv.org/abs/2508.12981
- Authors: Tianyue Ou; Saujas Vaduguru; Daniel Fried
- Reference count: 7
- Primary result: 25% pass rate on TravelPlanner benchmark with 17.5% absolute improvement over single-agent baselines

## Executive Summary
This study analyzes multi-agent systems for long-horizon planning by evaluating two mechanisms: a notebook for structured information sharing and an orchestrator agent for dynamic coordination. The notebook reduces hallucinations by 18% by allowing agents to ground their plans in structured facts rather than conversational context. The orchestrator improves performance by 13.5% in focused domains by enabling flexible revisiting of interdependent constraints. Together, these approaches achieve a 25% pass rate on the TravelPlanner benchmark, a 17.5% absolute improvement over single-agent baselines.

## Method Summary
The system uses specialized agents (Transportation, Hotel, Restaurant, Attraction Experts) within AutoGen framework. Two key mechanisms are implemented: a shared notebook for structured memory where experts write tool outputs, and an orchestrator LLM that dynamically selects the next expert based on conversation history and goal. Planning is compiled by a Plan Compiler agent reading the Notebook and conversation. The TravelPlanner benchmark provides queries for 3, 5, and 7-day plans with hard and commonsense constraints using a database of ~4 million entries.

## Key Results
- 25% pass rate on TravelPlanner benchmark
- 17.5% absolute improvement over single-agent baselines
- 18% reduction in hallucinations through structured information sharing
- 13.5% improvement in performance for focused domains through dynamic coordination

## Why This Works (Mechanism)
The notebook mechanism grounds all plan generation in structured facts rather than conversational context, preventing hallucination by enforcing consistency with actual tool outputs. The orchestrator enables flexible coordination by revisiting interdependent constraints dynamically, allowing the system to handle coupled constraints that require iterative refinement. This separation of concerns - structured memory for grounding and dynamic orchestration for coordination - addresses the core challenges of long-horizon multi-constraint planning.

## Foundational Learning
1. **Multi-Agent System Coordination** - Multiple specialized agents working together under orchestration control
   - Why needed: Long-horizon planning requires diverse expertise (transportation, lodging, dining, activities)
   - Quick check: Can each agent handle its domain-specific constraints independently?

2. **Structured Information Sharing** - Notebook mechanism for shared memory visible to planners but not orchestrator
   - Why needed: Prevents hallucination by grounding all decisions in verified tool outputs
   - Quick check: Does plan generation reference only notebook entries, not conversational context?

3. **Dynamic Expert Selection** - Orchestrator choosing next agent based on conversation history
   - Why needed: Enables revisiting interdependent constraints that require iterative refinement
   - Quick check: Can the system identify when constraints need revisiting versus when planning can proceed?

## Architecture Onboarding

**Component Map:** User Query -> Orchestrator -> Expert Agents -> Notebook -> Planner Agents -> Final Itinerary

**Critical Path:** User Query → Orchestrator (selects expert) → Expert (executes tool, writes to Notebook) → Orchestrator (continues or triggers planner) → Plan Compiler (reads Notebook) → Final Itinerary

**Design Tradeoffs:** Structured notebook prevents hallucination but adds coordination overhead; orchestrator enables dynamic constraint handling but can exceed step limits. The visibility rule (orchestrator sees only conversation, not notebook) creates information asymmetry that may improve routing accuracy but limits grounded decision-making.

**Failure Signatures:** Hallucination occurs when Plan Compiler relies on conversational context instead of Notebook; low delivery rate indicates orchestration loops or step limit exceedance; poor constraint satisfaction suggests inadequate conflict detection or coordination.

**First Experiments:**
1. Test notebook-only system to verify hallucination reduction (should show 18% improvement)
2. Test orchestrator-only system to measure dynamic coordination benefits (should show 13.5% improvement)
3. Test full system on simple 3-day plans before scaling to complex scenarios

## Open Questions the Paper Calls Out
1. **Conflict Detection:** What specific mechanisms can improve automated conflict detection for coupled constraints in long-horizon planning? The current system relies on orchestrator-led conversation to revisit steps, but detecting conflicts initially remains challenging.

2. **Coordination Overhead:** How can coordination overhead be minimized to prevent the observed drop in delivery rates under strict step limits? The multi-agent system showed lower delivery rate (83.75%) than single-agent baseline (91.25%).

3. **Information Asymmetry:** Would granting the orchestrator access to the structured notebook improve its ability to select the next agent compared to relying solely on conversation history?

## Limitations
- Missing system prompts for orchestrator and planner agents prevent faithful reproduction
- Strong performance gains reported only on TravelPlanner benchmark, raising external validity questions
- Information asymmetry between orchestrator and notebook may limit coordination effectiveness

## Confidence
- **Notebook Mechanism:** High confidence - clearly specified and should be reproducible
- **Orchestrator Implementation:** Low confidence - underspecified self-reflection process
- **Overall Results:** Medium confidence - strong claims but key components missing

## Next Checks
1. Implement notebook mechanism with structured memory and verify 18% hallucination reduction through entity consistency measurement
2. Reconstruct orchestrator prompts using expert prompts as templates and test dynamic expert selection improvement
3. Conduct ablation studies comparing notebook-only, orchestrator-only, and combined systems to validate 25% improvement claim