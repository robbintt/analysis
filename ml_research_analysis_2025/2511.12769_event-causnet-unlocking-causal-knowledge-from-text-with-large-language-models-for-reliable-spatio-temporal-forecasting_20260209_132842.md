---
ver: rpa2
title: 'Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models
  for Reliable Spatio-Temporal Forecasting'
arxiv_id: '2511.12769'
source_url: https://arxiv.org/abs/2511.12769
tags:
- causal
- traffic
- event
- attention
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Event-CausNet integrates LLM-powered causal feature extraction
  with a dual-stream GNN-LSTM architecture to improve traffic forecasting reliability
  during non-recurring events. It quantifies unstructured event reports into causal
  priors using a causal knowledge base built via propensity score matching to estimate
  average treatment effects.
---

# Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting

## Quick Facts
- **arXiv ID**: 2511.12769
- **Source URL**: https://arxiv.org/abs/2511.12769
- **Reference count**: 17
- **One-line primary result**: Event-CausNet reduces MAE by up to 35.87% and achieves strong robustness and interpretability in traffic forecasting during non-recurring events.

## Executive Summary
Event-CausNet addresses the challenge of reliable traffic speed prediction during non-recurring events (accidents, hazards, roadworks) by integrating LLM-powered causal feature extraction with a dual-stream graph neural network architecture. The system extracts and quantifies unstructured event reports into structured causal features, builds a causal knowledge base through propensity score matching to estimate average treatment effects, and dynamically injects this causal knowledge into predictions. Evaluated on Beijing traffic data, Event-CausNet significantly outperforms state-of-the-art baselines in both accuracy and interpretability, particularly for long-term forecasting horizons.

## Method Summary
Event-CausNet operates in three stages: (1) A two-stage LLM pipeline parses raw event descriptions into structured attributes and assigns quantified scores (severity, danger, duration, impact scope) to serve as confounders; (2) An offline causal knowledge base is constructed using propensity score matching to estimate average treatment effects from historical data, stored as population-level causal priors; (3) A causal prediction network (CPN) with dual prediction heads decomposes forecasts into base trends and causal adjustments, enforced by a consistency loss that matches the sign of predicted deviations to observed residuals. The system uses graph attention with causal biasing to dynamically adjust predictions based on real-time event information.

## Key Results
- Reduces MAE by up to 35.87% compared to state-of-the-art baselines
- Achieves strong robustness and interpretability in long-term forecasting (H=8: 2.964 MAE)
- Outperforms baselines particularly at longer horizons while providing verifiable causal insights through decomposed predictions

## Why This Works (Mechanism)

### Mechanism 1: LLM-Powered Structured Causal Feature Extraction
- **Claim**: Converting unstructured event text into quantified causal features enables downstream causal inference that correlational models cannot access.
- **Mechanism**: A two-stage LLM pipeline first parses raw event descriptions into structured attributes (time, type, location), then assigns integer scores (1-5 scale) for severity, danger, duration, and impact scope. These quantified metrics serve as confounders for causal inference.
- **Core assumption**: The LLM can accurately extract and quantify event attributes from non-standardized text, and these quantifications meaningfully correlate with actual traffic impact.
- **Evidence anchors**:
  - [abstract]: "uses a Large Language Model to quantify unstructured event reports"
  - [Section II-C]: "Stage 2: Event Quantification... assigns integer scores (1-5 scale) for severity, danger, duration, and impact scope"
  - [corpus]: FUSE-Traffic paper addresses similar unstructured-structured fusion but without the causal inference component; limited direct corpus validation of LLM accuracy on traffic text.
- **Break condition**: If LLM quantification is systematically biased or inconsistent across event types, the downstream ATE estimates will inherit this error, invalidating the causal knowledge base.

### Mechanism 2: Offline Causal Knowledge Base via Propensity Score Matching
- **Claim**: Estimating Average Treatment Effects (ATEs) from observational data provides transferable causal priors that improve prediction on unseen segments.
- **Mechanism**: PSM creates matched pairs of treated (event occurred) and control (no event) segments with similar confounders (time, severity, duration). ATE is computed as the mean outcome difference across matched pairs. These estimates are stored in a queryable CKB as population-level causal priors.
- **Core assumption**: Observable confounders captured in the data are sufficient to satisfy the unconfoundedness assumption; no unmeasured confounders significantly bias the ATE estimates.
- **Evidence anchors**:
  - [abstract]: "builds a causal knowledge base by estimating average treatment effects"
  - [Section II-D]: "PSM is a statistical method designed to mitigate selection bias... simulating a randomized controlled trial"
  - [Table I]: ATE estimates show statistical significance (p<0.001) across event types and time periods.
  - [corpus]: CauTraj paper uses causal-knowledge-guided planning but for trajectories; no direct corpus validation of PSM effectiveness in traffic forecasting.
- **Break condition**: If key confounders are unmeasured (e.g., driver behavior, weather micro-conditions), ATE estimates may be biased. The paper notes counter-intuitive results (positive ATE for accidents during peak hours), attributed to re-routing—suggesting potential confounding.

### Mechanism 3: Dual-Headed Causal Adjustment with Consistency Loss
- **Claim**: Explicitly decomposing forecasts into base trends and causal adjustments, enforced by a sign-matching loss, improves interpretability and long-horizon robustness.
- **Mechanism**: The CPN uses two prediction heads: f_base predicts counterfactual speed (no event), f_causal predicts the deviation caused by the event. The final prediction is the sum. A causal consistency loss (L_causal) forces the sign of the predicted adjustment to match the sign of the observed residual.
- **Core assumption**: The decomposition is learnable and the model can accurately separate base trends from event-driven deviations given the available features.
- **Evidence anchors**:
  - [abstract]: "decomposing forecasts into base trends and causal adjustments"
  - [Section II-E-4]: "L_causal forces the sign (direction) of the model's internal causal adjustment to match the sign of the self-supervised residual"
  - [Table II]: CPN MAE improves at longer horizons (H=8: 2.964 vs H=3: 3.607), while baselines degrade.
  - [Figure 4]: Attention maps show localized focus on current time step, indicating reliance on causal features rather than historical pattern matching.
  - [corpus]: Out-of-Distribution Generalization paper addresses graph distribution shifts but uses progressive inference rather than causal decomposition.
- **Break condition**: If base trends and causal effects are highly coupled (non-additive), the decomposition may be misspecified. The additive assumption is not empirically validated in the paper.

## Foundational Learning

- **Concept: Propensity Score Matching (PSM)**
  - Why needed here: The entire CKB construction relies on PSM to estimate unbiased treatment effects. Without understanding PSM, you cannot validate whether the causal priors are trustworthy.
  - Quick check question: Given treated and control segments, how would you verify that PSM successfully balanced the confounders? (Hint: Check covariate balance in matched pairs.)

- **Concept: Average Treatment Effect (ATE)**
  - Why needed here: The CKB stores ATEs as causal priors. You need to understand that ATE represents the expected change in outcome (speed) from an intervention (event), averaged across the population.
  - Quick check question: Why might ATE estimates for accidents during morning peak (+5.70 km/h) be positive? What confounding factor could explain this?

- **Concept: Attention-Based GNNs**
  - Why needed here: The CPN uses graph attention with causal biasing. Understanding how attention weights are computed and modulated is essential for debugging the causal injection mechanism.
  - Quick check question: In Equation 6, what does the term β·m_s add to the attention score, and how does it change model behavior when an event occurs?

## Architecture Onboarding

- **Component map**:
  Raw Event Text -> Stage 1 LLM -> Structured Event -> Stage 2 LLM -> Quantified Features (severity, duration, etc.) -> Offline CKB via PSM <- Historical Traffic Data -> Dynamic Causal Feature e_i,t <- Real-time adjustment -> CPN: Temporal Encoder (GRU) + Graph-Neighbor Encoder -> Causal-Aware Attention <- Causal Feature Injection -> Dual Head: Base Predictor + Causal Estimator -> Final Prediction: y_base + a_causal

- **Critical path**: The CKB construction is offline and must be completed before CPN training. During inference, the critical path is: event text -> LLM quantification -> CKB query -> dynamic adjustment -> causal attention -> dual-head prediction.

- **Design tradeoffs**:
  - CKB as fixed prior vs. learned embedding: The CKB is pre-computed and not updated during CPN training. This improves stability but may limit adaptability to new event types not in the CKB.
  - Gradient detachment in neighbor encoding: The paper detaches gradients during neighbor encoding to reduce computational load. This may limit the model's ability to learn spatial dependencies end-to-end.
  - Additive decomposition: Assuming base trend + causal adjustment is additive may not hold for complex event interactions. The paper does not validate this assumption.

- **Failure signatures**:
  1. CKB mismatch: If real-time events differ qualitatively from those in CKB (e.g., new event type), ATE lookup fails. Monitor for out-of-distribution event types.
  2. Attention collapse: If L_entropy fails to prevent attention from collapsing to a single time step, the model may overfit to recent events. Check attention entropy during training.
  3. Causal consistency violation: If L_causal is too weak, the causal adjustment head may predict spurious deviations. Monitor sign agreement between a_causal and (y - y_base).

- **First 3 experiments**:
  1. Ablate the CKB: Train CPN with random ATE values instead of CKB-derived estimates. Expect performance degradation, particularly at longer horizons. This validates that CKB provides meaningful causal priors.
  2. Attention visualization on synthetic events: Inject artificial events with known severity/duration and visualize attention maps. Verify that attention focuses on event time steps and that the causal adjustment head produces expected deviations.
  3. Cross-city transfer test: Apply the Beijing-trained CKB to traffic data from another city (if available). Assess whether ATE estimates transfer or require recalibration. This tests the paper's claim of transferability.

## Open Questions the Paper Calls Out

- **Cross-city generalization**: Can the Causal Knowledge Base (CKB) generalize effectively across cities with different traffic topologies and driver behaviors?
  - Basis in paper: [explicit] The authors explicitly state future work must "investigate the transferability and generalization of the CKB across different cities and network topologies."
  - Why unresolved: The Average Treatment Effects (ATEs) were derived solely from Beijing data; these causal priors may not hold true in urban environments with different road structures or cultural driving norms.
  - What evidence would resolve it: Cross-city transfer learning experiments where a CKB trained on source city data is applied to a target city to evaluate performance retention without retraining.

- **LLM pipeline robustness**: Is the two-stage LLM pipeline robust to noise, and how do errors in event structurization propagate through the causal inference layer?
  - Basis in paper: [inferred] While the paper assumes the LLM successfully parses unstructured text, it does not analyze the system's sensitivity to hallucinations or incorrect severity scoring during the "Event Structurization" stage.
  - Why unresolved: A failure in the initial LLM stage (e.g., misclassifying a hazard's severity) would lead to incorrect propensity score matching and faulty ATE estimations in the CKB.
  - What evidence would resolve it: A sensitivity analysis measuring performance degradation when varying levels of synthetic noise are introduced into the LLM-extracted event features.

- **Scalability to city-wide deployment**: Can the dual-stream architecture maintain real-time inference speeds when scaled to city-wide "urban brain" implementations?
  - Basis in paper: [explicit] The authors identify the need to address "challenges in computational resources and engineering reliability to support city-wide traffic planning."
  - Why unresolved: The experiments utilize a dataset of 1,260 segments; it is unclear if the computational cost of dynamic causal attention and neighbor sampling creates latency issues in massive-scale, real-time deployments.
  - What evidence would resolve it: Latency and throughput benchmarks conducted on a full-city graph (e.g., >10,000 nodes) under continuous real-time event stream conditions.

## Limitations

- **LLM accuracy and bias**: The system's effectiveness depends on the LLM's ability to accurately extract and quantify event attributes from unstructured text, which may introduce systematic bias if the model performs inconsistently across event types.
- **Unconfoundedness assumption**: The PSM-based CKB construction assumes that observable confounders are sufficient to satisfy unconfoundedness, potentially missing key unmeasured factors that could bias ATE estimates.
- **Additive decomposition assumption**: The paper assumes that base trends and causal effects are additive and separable, but this assumption is not empirically validated and may not hold for complex event interactions.

## Confidence

- **High**: The dual-stream CPN architecture, causal attention mechanism, and progressive training strategy are clearly specified and reproducible. The quantitative improvements over baselines are well-supported.
- **Medium**: The use of LLM for event quantification and the offline CKB construction via PSM are methodologically sound, but their accuracy and transferability depend on factors not fully disclosed (e.g., LLM performance, unmeasured confounders).
- **Low**: The claim that Event-CausNet provides "verifiable causal insights" is overstated; the model outputs interpretable adjustments, but these are based on population-level ATEs and may not represent true individual-level causality without stronger causal assumptions.

## Next Checks

1. **Ablate the CKB**: Train CPN with random ATE values instead of CKB-derived estimates. Expect performance degradation, particularly at longer horizons, to validate that CKB provides meaningful causal priors.
2. **Attention visualization on synthetic events**: Inject artificial events with known severity/duration and visualize attention maps. Verify that attention focuses on event time steps and that the causal adjustment head produces expected deviations.
3. **Cross-city transfer test**: Apply the Beijing-trained CKB to traffic data from another city (if available). Assess whether ATE estimates transfer or require recalibration, testing the paper's claim of transferability.