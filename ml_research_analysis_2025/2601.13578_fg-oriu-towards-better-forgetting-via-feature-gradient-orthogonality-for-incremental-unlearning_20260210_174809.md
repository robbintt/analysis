---
ver: rpa2
title: 'FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for
  Incremental Unlearning'
arxiv_id: '2601.13578'
source_url: https://arxiv.org/abs/2601.13578
tags:
- ssim
- psnr
- forgetting
- classes
- unlearning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles incremental unlearning (IU) in pre-trained vision
  models, addressing the challenge of efficiently removing specific classes from models
  while maintaining performance on remaining classes across sequential deletion requests.
  The authors identify that existing methods achieve only superficial forgetting,
  leaving residual information recoverable and causing feature entanglement between
  forgetting and remaining classes.
---

# FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning

## Quick Facts
- **arXiv ID**: 2601.13578
- **Source URL**: https://arxiv.org/abs/2601.13578
- **Reference count**: 40
- **Primary result**: Achieves up to 5.15% improvement in accuracy on remaining classes in long-sequence incremental unlearning scenarios while ensuring irreversible forgetting.

## Executive Summary
This paper addresses incremental unlearning (IU) in pre-trained vision models, where the goal is to efficiently remove specific classes from models while maintaining performance on remaining classes across sequential deletion requests. The authors identify that existing methods achieve only superficial forgetting, leaving residual information recoverable and causing feature entanglement between forgetting and remaining classes. FG-OrIU introduces a unified framework with dual orthogonal projections at both feature and gradient levels to achieve deep forgetting while preserving remaining class performance.

## Method Summary
FG-OrIU operates by decomposing feature spaces using SVD into forgetting and remaining subspaces, then enforcing orthogonal constraints to eliminate correlations with forgetting classes while aligning with remaining ones. The method freezes the pre-trained backbone and injects LoRA modules for efficient adaptation. During training, it minimizes the projection of new features onto the forgetting subspace while maintaining alignment with remaining class features. Dynamic subspace adaptation ensures stable balance across sequential unlearning tasks by updating basis vectors as classes transition from remaining to forgetting status.

## Key Results
- FG-OrIU significantly outperforms existing methods in achieving irreversible forgetting and preserving remaining class performance
- Up to 5.15% improvement in accuracy on remaining classes in long-sequence scenarios
- Demonstrates deep forgetting through failed Deep Image Prior reconstructions (high-noise/low-SSIM) compared to baseline methods
- Maintains stable performance across 4 sequential unlearning tasks with 20 classes forgotten per task

## Why This Works (Mechanism)

### Mechanism 1: Feature Orthogonal Projection for Semantic Erasure
Enforcing orthogonality between features of forgetting classes and their original subspace destroys the semantic information required for reconstruction, leading to "deep forgetting." The method uses SVD to define a subspace capturing discriminative features of classes to be removed, then minimizes the projection of new features onto this subspace, forcing the model to represent forgetting classes outside their original semantic boundaries.

### Mechanism 2: Gradient Projection for Retention Stability
Projecting gradients to be orthogonal to the remaining classes' subspace prevents degradation of retained knowledge during unlearning. The method calculates gradient updates for LoRA parameters and explicitly removes components that lie within the subspace of remaining classes, ensuring weight updates have theoretically zero effect on remaining class features.

### Mechanism 3: Dynamic Subspace Adaptation for Sequential Consistency
Dynamically expanding the forgetting subspace while contracting the remaining subspace across tasks prevents "superficial forgetting" in incremental scenarios. The method updates basis vectors by merging new forgetting features and removing them from the remaining set, tracking the cumulative history of deletions to maintain internal geometry consistency.

## Foundational Learning

- **Concept**: **Singular Value Decomposition (SVD) and Subspaces**
  - **Why needed here**: The entire architecture relies on using SVD to decompose the feature matrix into orthogonal subspaces ($S_f$ and $S_r$)
  - **Quick check question**: If a feature matrix $R$ has rank $k$, what does the subspace spanned by the top $k$ singular vectors represent compared to the null space?

- **Concept**: **Low-Rank Adaptation (LoRA)**
  - **Why needed here**: FG-OrIU freezes the pre-trained backbone and injects LoRA modules, with unlearning happening strictly within these low-rank adapters
  - **Quick check question**: Why is it more efficient to train LoRA weights than full fine-tuning when we want to preserve the original "remaining" knowledge of the backbone?

- **Concept**: **Orthogonal Projection (Linear Algebra)**
  - **Why needed here**: The core operation involves projecting vectors (features or gradients) onto a subspace or its orthogonal complement
  - **Quick check question**: Given a gradient $g$ and a projection matrix $P_r$ for the remaining subspace, does subtracting $P_r g$ from $g$ move the update *towards* or *away* from the remaining class features?

## Architecture Onboarding

- **Component map**: Backbone (Frozen ViT/Face Transformer) -> LoRA Modules (Trainable) -> Subspace Banks ($B_f$, $B_r$) -> Projection Layer (Eq 3,6,9)
- **Critical path**: 1) Init: Compute $S_f$ and $S_r$ via SVD on frozen backbone features; 2) Forward: Apply Feature Orthogonal Loss for forgetting samples and Feature Retention Loss for remaining samples; 3) Backward: Modify gradients to be orthogonal to $S_r$ and aligned with $S_f$; 4) Update: Train LoRA weights only
- **Design tradeoffs**: Rank threshold ($\epsilon=0.99$) captures more variance but increases overlap risk; Strength of constraints ($\lambda_1=1$, $\lambda_2=0.2$) balances forgetting depth against retention stability
- **Failure signatures**: Superficial Forgetting (DIP reconstruction succeeds), Catastrophic Interference (remaining accuracy drops), Recovery Attack (head retraining recovers forgotten classes)
- **First 3 experiments**: 1) Static Unlearning (100-10): Compare $Acc_f$ and $Acc_r$ against baselines; 2) Incremental Unlearning (4 Tasks): Monitor $Acc_o$ to prevent remembering old forgotten classes; 3) Deep Forgetting Audit: Use DIP to reconstruct images and measure SSIM/PSNR

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Feature-Gradient Orthogonality framework be effectively adapted from class-level to sample-level incremental unlearning?
- Basis in paper: [explicit] The conclusion states that "extending it to sample-level settings remains a promising direction for future work."
- Why unresolved: The current method relies on decomposing feature spaces via SVD using a matrix of samples from $D_f$. A single sample may not provide sufficient data to construct a stable or meaningful orthogonal subspace for projection.

### Open Question 2
- Question: Does the orthogonal projection mechanism provide theoretical guarantees of irreversibility against adversarial reconstruction attacks?
- Basis in paper: [inferred] The paper defines "deep forgetting" empirically by the failure of Deep Image Prior (DIP) to reconstruct images, but admits the method operates by minimizing feature correlations rather than proving information-theoretic erasure.
- Why unresolved: Empirical robustness against DIP does not guarantee that semantic information is mathematically irrecoverable by more sophisticated inversion attacks or ensemble probing techniques.

### Open Question 3
- Question: Can the subspace decomposition and projection be performed without direct access to the raw forgetting and remaining data samples?
- Basis in paper: [inferred] The methodology explicitly requires constructing representation matrices $R_{f,i}$ and $R_{r,i}$ from input samples to compute the SVD.
- Why unresolved: Real-world regulatory scenarios (e.g., GDPR) often require data to be deleted immediately upon request, potentially leaving the model owner without the necessary data to construct the forgetting subspace $S_f$.

## Limitations
- The paper lacks critical implementation details including LoRA configuration parameters, exact training hyperparameters, and sample counts for SVD decomposition
- Scalability concerns exist for many sequential unlearning tasks due to potential rank collapse in subspaces
- Claims of "deep forgetting" require more rigorous quantitative validation beyond qualitative DIP reconstruction assessments

## Confidence

- **High Confidence**: The core mechanism of using SVD to decompose feature spaces and enforce orthogonal constraints is mathematically sound and well-supported by the literature
- **Medium Confidence**: The dynamic subspace adaptation approach for sequential tasks is reasonable but may face scalability issues with many unlearning tasks
- **Medium Confidence**: The claim of achieving "deep forgetting" through feature orthogonalization is supported by the theoretical framework but requires more rigorous validation

## Next Checks

1. **Reproduce Core Experiments**: Implement the static unlearning experiment (100-10) with baseline comparisons to verify the basic tradeoff capability between forgetting and retention

2. **Deep Forgetting Validation**: Systematically measure SSIM/PSNR for DIP reconstructions across all baselines and FG-OrIU, comparing quantitative metrics rather than qualitative assessments

3. **Scalability Test**: Run experiments with more than 4 sequential unlearning tasks to evaluate whether dynamic subspace adaptation maintains performance or encounters rank collapse issues