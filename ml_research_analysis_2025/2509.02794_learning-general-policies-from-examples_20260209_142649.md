---
ver: rpa2
title: Learning General Policies From Examples
arxiv_id: '2509.02794'
source_url: https://arxiv.org/abs/2509.02794
tags:
- features
- policy
- policies
- learning
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a scalable symbolic method for learning general
  policies that solve large collections of planning problems. The method is based
  on a new structural termination criterion and a hitting set algorithm, enabling
  it to handle problems with millions of states and hundreds of thousands of features.
---

# Learning General Policies From Examples

## Quick Facts
- arXiv ID: 2509.02794
- Source URL: https://arxiv.org/abs/2509.02794
- Reference count: 9
- This paper introduces a scalable symbolic method for learning general policies that solve large collections of planning problems, handling millions of states and hundreds of thousands of features.

## Executive Summary
This paper presents a novel approach for learning general policies that solve large collections of planning problems. The method uses a new structural termination criterion called stratification and a hitting set algorithm to achieve scalability. It can handle problems with millions of states and hundreds of thousands of features, solving 20 out of 34 planning domains with learned policies that generalize well. The approach outperforms previous symbolic methods in scalability and can solve domains previously considered unsolvable.

## Method Summary
The method learns general policies through an iterative wrapper algorithm that uses a planner to generate plan traces (examples). A feature generator creates a massive pool of candidate logical features. The GENEX algorithm, a greedy hitting-set solver, selects features that differentiate "good" from "bad" transitions while satisfying stratification constraints. The wrapper iteratively executes the current policy, identifies failures, and queries the planner for corrective transitions until the policy is robust.

## Key Results
- Solved 20 out of 34 standard planning domains
- Policies generalize from training instances (10 blocks) to larger test instances (up to 45 blocks) in Blocks4ops domain
- Handles problems with millions of states and hundreds of thousands of features
- Outperforms previous symbolic approaches in scalability

## Why This Works (Mechanism)

### Mechanism 1: Stratification Enforces Termination by Design
The system guarantees termination by imposing "k-stratification" - features are assigned ranks, and higher-ranked features must be monotone conditional on lower-ranked ones. Since lower-ranked features can only change a finite number of times, the entire system converges.

### Mechanism 2: Decoupled Feature Selection via Hitting Sets
Scalability is achieved by decoupling transition selection from feature selection. The GENEX algorithm fixes "good" transitions and searches for features that "hit" coverage requirements - changing across good transitions and distinguishing them from bad ones.

### Mechanism 3: Iterative Policy Repair (The Wrapper)
The WRAPPER algorithm executes the current policy and iteratively identifies and corrects failures. If it reaches a dead-end, the transition is added to negative examples. If undefined at an alive state, a planner finds a step and adds it to positive examples.

## Foundational Learning

- **Concept: Generalized Planning & Rule-Based Policies**
  - Why needed: Goal is to learn rules (e.g., "If holding block, put down") that apply to any instance in a domain, not solve one puzzle
  - Quick check: Can you distinguish between a state transition (specific move) and a policy rule (general implication over features)?

- **Concept: Structural Termination**
  - Why needed: Replaces computationally hard infinite loop detection with "stratification"
  - Quick check: Why does a feature that is monotone given another monotone feature guarantee termination?

- **Concept: Hitting Set Problem**
  - Why needed: GENEX core learner is a solver for this problem
  - Quick check: What constitutes a "set" that needs to be "hit," and what is the "cost" being minimized?

## Architecture Onboarding

- **Component map:** Planner (SIW/BFWS) -> Feature Generator (DLPLAN) -> GENEX (Core Learner) -> WRAPPER (Controller)
- **Critical path:** Bottleneck is typically Feature Generation (high prep. time for complex domains) and Verification step
- **Design tradeoffs:** Scalability vs. Completeness (greedy algorithm loses SAT solver completeness); Expressivity vs. Tractability (rich grammars allow more domains but increase hitting-set problem size)
- **Failure signatures:** Edge Failure (feature grammar too weak); Stratification Failure (cannot order features); Timeout (feature generation or verification)
- **First 3 experiments:**
  1. Gripper Domain (Sanity Check): Learn 4-rule policy from single plan trace
  2. Blocks4ops (Induction): Verify policy learned on 10 blocks solves instances with 20-45 blocks
  3. Failure Analysis (Tpp/Rovers): Confirm "Edge" failure and attempt manual feature construction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a complete and efficient wrapper algorithm be developed that guarantees finding a general policy if one exists?
- Basis: The conclusion states "An improved, complete and efficient, wrapper around the complete and efficient GENEX is left as a challenge for future work"
- Why unresolved: Current greedy wrapper is incomplete and may fail to find correct transitions
- What evidence would resolve it: Development of new wrapper algorithm that provably finds policy whenever one exists within feature pool

### Open Question 2
- Question: Can novel feature grammars be developed that extend expressivity beyond first-order logic with two variables while remaining scalable?
- Basis: Introduction states addressing limitations of current description logic grammars "calls for novel and richer feature grammars"
- Why unresolved: Current grammars limited to C2 logic due to tractability; moving beyond likely results in intractable feature pools
- What evidence would resolve it: Successful learning of general policies in 11 failed domains using new feature generation method

### Open Question 3
- Question: How does choice of specific planner (SIW vs. BFWS) and plan quality bias resulting general policy?
- Basis: Methodology depends entirely on planner to generate initial "good" transitions
- Why unresolved: Planner produces idiosyncratic or suboptimal plans that may bias generalization
- What evidence would resolve it: Ablation study comparing policies learned from different planners

### Open Question 4
- Question: How can algorithm be refined to prevent policy overfitting in domains requiring very large feature sets?
- Basis: Authors note Sokoban policy had 50 rules and 15 features, describing it as "highly over fit to the training set"
- Why unresolved: Greedy algorithm may memorize features rather than finding abstract invariants
- What evidence would resolve it: Modified procedure producing simpler policy for Sokoban that generalizes to unseen instances

## Limitations
- Domains failing due to "Edge" failures indicate fundamental limits when feature grammar cannot capture necessary transitions
- Greedy hitting set algorithm trades completeness for scalability, potentially missing optimal policies
- Stratification mechanism requires careful feature ranking with potential conflicts in monotonicity requirements

## Confidence
- **High Confidence:** Stratification termination guarantee (Theorem 6) is well-established; hitting set formulation and GENEX algorithm are clearly specified; wrapper framework is sound
- **Medium Confidence:** Scalability claims supported by runtime tables but 12-hour cutoff suggests practical limits; generalizability results impressive but only demonstrated on one domain
- **Low Confidence:** Paper lacks detailed failure analysis for domains that don't terminate or produce incorrect policies; "Optional policy simplification" step lacks implementation details

## Next Checks
1. **Expressivity Test:** Take a domain that failed ("Edge"), manually construct the missing feature, and verify the algorithm succeeds
2. **Stratification Stress Test:** Create synthetic domain with conflicting feature monotonicity constraints and verify algorithm detects stratification failures
3. **Scalability Boundary:** Run algorithm on domain with 500K+ features to empirically determine where hitting set solver breaks down