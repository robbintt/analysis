---
ver: rpa2
title: Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural
  Deformation Correntropy
arxiv_id: '2502.10704'
source_url: https://arxiv.org/abs/2502.10704
tags:
- registration
- point
- occlusion
- shape
- deformation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses non-rigid point cloud registration under occlusion,
  a critical challenge in applications like surgical navigation where pre-operative
  complete models must align with occluded intra-operative data. Existing methods
  using Chamfer distance struggle with physically implausible deformations like collapse
  or tearing in occluded regions.
---

# Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy

## Quick Facts
- arXiv ID: 2502.10704
- Source URL: https://arxiv.org/abs/2502.10704
- Reference count: 40
- Key outcome: Combines Maximum Correntropy Criterion with Locally Linear Reconstruction to handle occluded non-rigid point cloud registration, achieving superior or competitive performance on occluded datasets

## Executive Summary
This paper addresses non-rigid point cloud registration under occlusion, a critical challenge in applications like surgical navigation where pre-operative complete models must align with occluded intra-operative data. Existing methods using Chamfer distance struggle with physically implausible deformations like collapse or tearing in occluded regions. The authors propose Occlusion-Aware Registration (OAR), which innovatively combines unsupervised implicit neural representations with Maximum Correntropy Criterion (MCC) to adaptively handle occlusion by treating individual points differently. They also introduce Locally Linear Reconstruction (LLR) to ensure physically plausible deformations in regions lacking correspondences. Theoretical analysis shows MCC relates to Chamfer distance but offers more universal applicability. Experiments demonstrate OAR achieves superior or competitive performance on occluded datasets compared to state-of-the-art methods.

## Method Summary
OAR uses a coordinate-based MLP with SIREN activations to learn continuous deformation fields from source to target point clouds. The method combines Maximum Correntropy Criterion (MCC) as a localized similarity measure that adaptively down-weights occluded regions, with Locally Linear Reconstruction (LLR) regularization that ensures physically plausible deformations by constraining each deformed point to remain a weighted combination of its deformed neighbors. The deformation network is optimized end-to-end using Adam, with loss balancing MCC alignment and LLR geometric regularization. Pre-computed LLR weights capture local geometric structure from the source shape, which is preserved under deformation even in occluded regions.

## Key Results
- OAR achieves AccS 29.2%-96.8% and AccR 75.2%-97.2% on Open-CAS liver dataset with varying occlusion levels
- LLR consistently improves registration accuracy across all occlusion scenarios, with MCC+LLR outperforming MCC alone and MCC+AIAP baselines
- The method demonstrates versatility in large deformations, shape interpolation, and shape completion tasks beyond pure registration
- Theoretical analysis proves MCC generalizes Chamfer distance but with more universal applicability for incomplete data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MCC adaptively down-weights occluded regions during registration, preventing collapse/tearing artifacts
- Mechanism: MCC uses a Gaussian kernel to compute local similarity. When a point lacks correspondence (occluded), the distance is large, causing the kernel response to decay toward zero. This reduces the point's contribution to the loss, unlike Chamfer Distance which treats all deviations uniformly
- Core assumption: Occluded points have larger distances to their nearest neighbors in the other point cloud than corresponding (visible) points
- Evidence anchors:
  - [abstract] "adaptive correntropy function as a localized similarity measure, enabling us to treat individual points distinctly"
  - [Section 4.1] "Eq. (3) assigns adaptive importance during network training, i.e., giving significant importance to points with corresponding parts, while penalizing deformations in occluded regions"
  - [Proposition 1] "Chamfer distance is a special case of Eq. (3), applicable only when both source and target point clouds X and Y are complete and sufficiently close"
  - [corpus] Limited direct corpus support; neighbors focus on registration methods without explicit occlusion handling mechanisms

### Mechanism 2
- Claim: LLR propagates plausible deformations into occluded regions by linearly combining neighbor deformations
- Mechanism: LLR pre-computes reconstruction weights $w_j$ for each point from its k-nearest neighbors on the source shape (Eq. 5). During optimization, the regularization term (Eq. 7) constrains each deformed point to remain a weighted combination of its deformed neighbors, propagating information from visible to occluded regions
- Core assumption: The local geometric structure (neighbor relationships) is preserved under deformation; occluded regions share similar deformation patterns with their visible neighbors
- Evidence anchors:
  - [Section 4.2] "deformation of occluded parts can be inferred from, or propagated through, the deformations of neighboring points via locally linear reconstruction"
  - [Figure 4] LLR maintains geometric details like facial expressions better than AIAP under increasing occlusion
  - [Figure 5] MCC+LLR consistently outperforms MCC alone and MCC+AIAP across occlusion levels
  - [corpus] Corpus neighbors do not explicitly discuss LLR-style geometric propagation

### Mechanism 3
- Claim: Coordinate-based MLPs with periodic activations (SIREN) provide implicit regularization and enable continuous deformation fields for downstream tasks
- Mechanism: The MLP $T_\Theta$ maps 3D coordinates to displacement vectors. SIREN activations (sinusoidal) provide better fitting to high-frequency deformations than ReLU. The network architecture itself imposes smoothness on the deformation field
- Core assumption: The deformation field is smooth and can be represented by a relatively shallow MLP
- Evidence anchors:
  - [Section 4.3] "coordinate-based MLP with periodic activations (Sitzmann et al., 2020) as our deformation network"
  - [Table 4] ReLU+MCC+LLR achieves good performance, but SIREN+MCC+LLR is the default; regularization is primarily from LLR, not activation choice
  - [Figure 6] Continuous interpolation between source and target shapes demonstrates smooth deformation field
  - [corpus] NeuroGauss4D-PCI uses similar neural field concepts for point cloud interpolation

## Foundational Learning

- Concept: **Chamfer Distance and its limitations**
  - Why needed here: Understanding why CD fails under occlusion motivates the entire paper; CD computes holistic deviation without distinguishing occluded vs. visible points
  - Quick check question: Given two point clouds where one is partially occluded, explain why minimizing Chamfer Distance could cause the source to collapse toward the occluded region

- Concept: **Correntropy and kernel-based similarity measures**
  - Why needed here: MCC is the core technical contribution; understanding kernel bandwidth $\sigma$ and its effect on the "locality" of the metric is essential for tuning
  - Quick check question: If you increase the Gaussian kernel bandwidth $\sigma$, does MCC behave more like $\ell_2$ or $\ell_0$? Why does this matter for occlusion robustness

- Concept: **Manifold learning and locally linear embedding (LLE)**
  - Why needed here: LLR is directly inspired by LLE; the reconstruction weights encode local geometry that should be preserved under deformation
  - Quick check question: In LLE, what does the constraint $\sum w_j = 1$ enforce? How does this translate to the deformation regularization in LLR

## Architecture Onboarding

- Component map: Data normalization -> LLR weight computation -> SIREN MLP initialization -> Optimization loop (forward pass -> MCC loss + LLR regularization -> backpropagation) -> Apply learned deformation
- Critical path:
  1. Compute k-NN graph on source point cloud and solve for LLR weights (Eq. 5)
  2. Initialize MLP parameters $\Theta$
  3. For each iteration: forward pass through MLP to get displacements, compute MCC loss (Eq. 3) and LLR regularization (Eq. 7), backpropagate
  4. After convergence, apply learned deformation to source points
- Design tradeoffs:
  - **k (number of neighbors)**: Larger k improves accuracy (better geometric prior) but increases matrix inversion cost; paper recommends k=30
  - **$\sigma^2$ (kernel bandwidth)**: Controls sensitivity to outliers; paper finds $\sigma^2=1.0$ works well across scenarios
  - **$\alpha_1, \alpha_2$ (loss weights)**: Balance between alignment accuracy and deformation plausibility; defaults are $\alpha_1=10^4, \alpha_2=10^2$
  - **MLP depth/width**: Shallow network (3 layers) is sufficient but may not capture highly complex deformations
- Failure signatures:
  - **Collapse/tearing artifacts**: Indicates MCC is not properly down-weighting occluded points; check kernel bandwidth $\sigma$
  - **Unnatural deformations in occluded regions**: LLR regularization may be too weak; increase $\alpha_2$ or k
  - **Slow convergence**: Learning rate may be too high or k may be too large (matrix operations)
  - **Failure on large occlusions**: Fundamental limitation (acknowledged in Appendix J); consider incorporating symmetry priors
- First 3 experiments:
  1. **Reproduce Open-CAS Liver 1 result**: Register the provided source/target pair, verify AccS ~29.2%, AccR ~96.8%. Ablate MCC (use CD only) to confirm collapse artifacts appear
  2. **Vary occlusion level**: Use the lion model with progressive occlusion (Fig. 5), plot EPE/AccS/AccR vs. occlusion level to validate LLR contribution
  3. **Test on custom data**: Create a synthetic occlusion (remove 30% of a target point cloud from a known deformation pair), verify the method maintains physical plausibility in the occluded region compared to NSFP or NDP baselines

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the integration of geometric symmetry or shape analysis theory effectively resolve registration failures in scenarios with significantly large occlusions?
- **Basis in paper:** [explicit] Appendix J states that when the occlusion region is significantly large, the method may yield unsatisfactory results (e.g., Fig 18), and suggests integrating shape analysis theory could mitigate this limitation
- **Why unresolved:** The problem remains severely ill-posed and under-constrained for large missing regions, leading to topological errors the current framework cannot handle
- **What evidence would resolve it:** Successful registration results on datasets with >50% occlusion, demonstrating preserved topology and high accuracy (AccS/AccR) where the baseline fails

### Open Question 2
- **Question:** Can low-rank approximations of the Gram matrix reduce the computational complexity of Locally Linear Reconstruction (LLR) without degrading deformation quality?
- **Basis in paper:** [explicit] Appendix J identifies the high computational complexity of LLR due to matrix inverse operations and proposes exploring low-rank approximations as future work
- **Why unresolved:** The current closed-form solution for calculating reconstruction weights is computationally expensive, limiting real-time application
- **What evidence would resolve it:** A benchmark showing reduced processing time per frame while maintaining equivalent EPE and AccS scores compared to the full-matrix implementation

### Open Question 3
- **Question:** Can distance transform techniques be successfully adapted to accelerate the Maximum Correntropy Criterion (MCC) metric while balancing discretization error and memory consumption?
- **Basis in paper:** [explicit] Appendix J suggests utilizing distance transforms to expedite MCC computation similar to Chamfer distance, but notes the need to manage trade-offs like discretization error
- **Why unresolved:** While theoretically possible, the specific implementation for MCC requires careful consideration of grid resolution and memory, which has not yet been explored
- **What evidence would resolve it:** An implementation of distance-transform-accelerated MCC that achieves lower runtime than the pairwise computation with negligible loss in registration accuracy

## Limitations
- Performance degrades significantly on very large occlusions (acknowledged limitation)
- Reliance on fixed LLR weights computed only from source shape may limit robustness to topology changes
- Evaluation focuses primarily on liver datasets with limited validation on other anatomical structures or general 3D objects

## Confidence
- **High confidence**: MCC's adaptive weighting mechanism and its relationship to Chamfer distance (Proposition 1 is mathematically sound)
- **Medium confidence**: LLR's effectiveness in propagating deformations, as results show consistent improvement but ablation studies could be more rigorous
- **Low confidence**: Generalization to diverse deformation scenarios beyond the liver dataset, particularly for large occlusions or topologically different shapes

## Next Checks
1. Conduct systematic ablation studies varying kernel bandwidth σ² and LLR neighbor count k to quantify their impact on registration accuracy across different occlusion levels
2. Test the method on a non-medical dataset (e.g., ShapeNet) with controlled synthetic occlusions to assess generalization beyond liver data
3. Evaluate performance when LLR weights are computed from the target shape rather than source, measuring the trade-off between geometric fidelity and computational cost