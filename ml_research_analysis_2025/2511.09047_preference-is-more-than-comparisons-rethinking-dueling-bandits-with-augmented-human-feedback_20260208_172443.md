---
ver: rpa2
title: 'Preference is More Than Comparisons: Rethinking Dueling Bandits with Augmented
  Human Feedback'
arxiv_id: '2511.09047'
source_url: https://arxiv.org/abs/2511.09047
tags:
- feedback
- human
- regret
- latexit
- preference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a dueling bandit framework with augmented human
  feedback (IPEA-HF) that integrates contextual similarity and dependencies to address
  sparse feedback in interactive preference elicitation. The key innovation is introducing
  augmented confidence bounds that incorporate related observations through a generalized
  concentration property, eliminating the need for rigid parametric reward models.
---

# Preference is More Than Comparisons: Rethinking Dueling Bandits with Augmented Human Feedback

## Quick Facts
- **arXiv ID:** 2511.09047
- **Source URL:** https://arxiv.org/abs/2511.09047
- **Reference count:** 40
- **Primary result:** Proposes IPEA-HF framework integrating contextual similarity and dependencies for sparse feedback in interactive preference elicitation, achieving competitive performance across recommendation, multi-objective optimization, and LLM response optimization benchmarks.

## Executive Summary
This paper addresses the challenge of sparse human feedback in interactive preference elicitation by introducing a dueling bandit framework with augmented human feedback (IPEA-HF). The key innovation is incorporating augmented confidence bounds that leverage related observations through generalized concentration properties, eliminating the need for rigid parametric reward models. The framework demonstrates competitive performance across multiple benchmarks while providing theoretical guarantees on regret bounds that depend on the quality of augmented feedback.

## Method Summary
The IPEA-HF framework combines standard dueling bandit algorithms (RUCB/DTS) with augmented confidence bounds that integrate direct pairwise comparisons with related observations from similar candidates. The method constructs a similarity graph based on contextual features, then uses dependency weights to augment the sample count for confidence bound calculations. When feedback is received for a pair, the system identifies related pairs through the similarity graph and updates their confidence bounds accordingly. The framework includes mechanisms for filtering weak dependencies through a calibration threshold to prevent noisy augmentation from degrading performance.

## Key Results
- Achieves competitive regret performance across recommendation, multi-objective optimization, and LLM response optimization benchmarks
- Demonstrates superior sample efficiency compared to state-of-the-art dueling bandit methods through effective exploration-exploitation balance
- Provides theoretical regret bounds that generalize partition-based approaches while revealing multi-factored trade-offs between augmented feedback and contextual dependencies

## Why This Works (Mechanism)

### Mechanism 1: Augmented Confidence Bounds for Uncertainty Calibration
- **Claim:** Integrating "related" observations from similar candidates reduces variance of preference estimates faster than relying solely on direct pairwise comparisons, provided latent dependencies exist.
- **Mechanism:** Replaces standard frequency-based confidence bounds with Augmented Confidence Bounds that add "virtual samples" from similar pairs, effectively increasing sample count to narrow confidence intervals and calibrate uncertainty more rapidly.
- **Core assumption:** Related observations follow Bernoulli($w_k p_{i,j}$), meaning preference probability of related pair is a weighted proxy for target pair.
- **Evidence anchors:** Theorem 3.1 establishes generalized concentration property; Eq. (5) and (6) derive calibration threshold proving related observations shrink interval only if dependency weight is sufficiently high.

### Mechanism 2: Dependency-Weighted Regret Trade-off
- **Claim:** Feedback augmentation is not universally beneficial; theoretically enforces penalty (higher regret bound) if weak or incorrect dependencies are used.
- **Mechanism:** Regret analysis scales inversely with dependency weight $w_r$; if system augments feedback using pair with weak correlation, regret bound coefficient explodes, acting as theoretical "safety brake."
- **Core assumption:** Assumes "bidirectional dependency" where observations shared mutually between related pairs, facilitating soft-clustering effect.
- **Evidence anchors:** Theorem 3.2 explicitly defines sample complexity term $D_{w_{i,j}} \propto \frac{1}{\min w_r^2}$, highlighting cost of low-dependency augmentation.

### Mechanism 3: Graph-Based Contextual Propagation
- **Claim:** Contextual similarity serves as structural skeleton to propagate sparse preference signals across candidate space, reducing need for exhaustive pairwise comparisons.
- **Mechanism:** Constructs similarity graph $G(X, K)$; when query on $(a_i, a_j)$ yields preference, system identifies connected components or neighbors and updates dependency dictionary, allowing single human feedback signal to implicitly update confidence bounds of multiple non-queried pairs.
- **Core assumption:** Candidates can be embedded in context space where distance correlates with preference similarity.
- **Evidence anchors:** Empirical results on Sushi dataset show improved regret trajectories, attributing success to effective utilization of item features over context-free baselines.

## Foundational Learning

- **Concept: Dueling Bandits (DB) & Condorcet Winner**
  - **Why needed here:** Builds upon standard K-armed DB problem; goal is to find "Condorcet winner" (arm that beats all others with prob > 0.5) using only pairwise preference data, rather than scalar rewards.
  - **Quick check question:** If Arm A beats B, and B beats C, does A necessarily beat C? (Answer: No, preferences can be non-transitive, which this model handles).

- **Concept: Upper Confidence Bound (UCB)**
  - **Why needed here:** Core modification is "Augmented Confidence Bound"; need to grasp how standard UCB balances exploitation vs. exploration to understand why widening data source (augmentation) helps.
  - **Quick check question:** Does smaller confidence interval imply higher or lower uncertainty in preference estimate? (Answer: Lower uncertainty, leading to more confident exploitation).

- **Concept: Chernoff-Hoeffding Inequality**
  - **Why needed here:** Theoretical proof of "Concentration Property" relies on this inequality to bound probability that estimated preference deviates from true preference.
  - **Quick check question:** In context of this paper, does adding "related observations" increase the $n$ in Chernoff bound? (Answer: Yes, effectively increasing sample size to tighten bound).

## Architecture Onboarding

- **Component map:** Input context vectors $X$ for $K$ candidates -> Dependency Extractor builds similarity graph $G$ and annotates dependency weights $W$ -> Augmented Confidence Bound computes $\hat{p}_{i,j}$, $\hat{u}_{i,j}$, $\hat{l}_{i,j}$ by fusing direct observations with related ones from $W$ -> DuelingBanditAlgo standard RUCB or DTS loop selects next pair based on augmented bounds -> FeedbackAug updates dependency dictionary after receiving user feedback

- **Critical path:** Constructing similarity graph $G$ and initial dependency weights. If this "skeleton" is wrong (dissimilar items treated as related), Augmented Confidence Bound will miscalibrate, and regret bound $D_w$ will spike.

- **Design tradeoffs:**
  - **Dependency Threshold $\tau$:** Set too high, get no augmentation (degrades to standard DB); set too low, introduce noise (false dependencies), inflating regret.
  - **Annotation Source:** Human annotation is accurate but expensive; LLM annotation is cheap but requires calibration threshold to filter out hallucinations.

- **Failure signatures:**
  - **Regret Divergence:** Cumulative regret curves rising linearly rather than logarithmically, suggesting dependency weights are misestimated (likely overestimated), causing algorithm to explore bad pairs based on false correlations.
  - **Pre-mature Convergence:** Algorithm locks onto suboptimal arm, may occur if "calibration threshold" is too strict, preventing valid augmented feedback from narrowing confidence bounds.

- **First 3 experiments:**
  1. **Sanity Check (Synthetic):** Replicate "Sushi" or "DTLZ" experiment with augmentation disabled (set $n_r=0$) to establish baseline regret curve.
  2. **Ablation on Dependency Quality:** Inject noise into dependency weights $W$ (flip 20% of weights to 0 or 1) to verify Theorem 3.2's prediction that bad dependencies increase regret.
  3. **Threshold Sensitivity:** Run parameter sweep on similarity threshold $\tau$ used to build graph $G$ to find "Goldilocks zone" where sample efficiency is maximized without introducing noise.

## Open Questions the Paper Calls Out

- **Question:** Can theoretical regret bounds be extended to stochastic strategies like IPEA-DTS, rather than being limited to deterministic strategies?
  - **Basis in paper:** Limitations section states "a more comprehensive theoretical investigation of stochastic strategies, such as IPEA-DTS, remains an open direction."
  - **Why unresolved:** Paper's theoretical analysis (Theorem 3.3) focuses exclusively on deterministic IPEA-RUCB algorithm to derive regret bounds.
  - **What evidence would resolve it:** Formal proof establishing sample complexity and regret bounds for IPEA-DTS algorithm within augmented feedback framework.

- **Question:** How can framework be generalized to handle non-stationary preferences where user intent drifts over time?
  - **Basis in paper:** Limitations section notes "For non-stationary preferences, an adaptive design to capture and respond to changes is also required."
  - **Why unresolved:** Current methodology assumes fixed preference matrix $P$, which does not account for changing user preferences during interaction.
  - **What evidence would resolve it:** Algorithmic variant capable of detecting preference drift and corresponding theoretical guarantees for regret minimization in dynamic environments.

- **Question:** Can assumption of bidirectional dependency be relaxed to support more general dependency structures?
  - **Basis in paper:** Limitations section suggests "current assumption of bidirectional dependency could be further relaxed to support more general dependency structures."
  - **Why unresolved:** Current regret analysis relies on bidirectional dependency to facilitate soft-clustering decomposition of candidate set.
  - **What evidence would resolve it:** Theoretical analysis demonstrating regret bounds that hold for asymmetric or unidirectional dependency graphs.

## Limitations

- Core assumption about bidirectional dependencies between similar pairs lacks empirical validation on noisy real-world data.
- Augmented confidence bound mechanism assumes Bernoulli-distributed related observations, which may not hold when similarity is based on complex feature interactions rather than direct preference relationships.
- Mechanism for handling inter-prompt observations in LLM tasks remains conceptually described without explicit implementation details for establishing cross-context similarity.

## Confidence

- **High Confidence:** Regret analysis framework and generalized concentration property (Theorem 3.1) are mathematically sound given stated assumptions.
- **Medium Confidence:** Empirical results show competitive performance, but comparison methodology doesn't include ablation studies isolating augmentation effect from other algorithmic choices.
- **Low Confidence:** Mechanism for handling inter-prompt observations in LLM tasks remains conceptually described without explicit implementation details.

## Next Checks

1. **Dependency Quality Sensitivity:** Systematically vary similarity threshold Ï„ and dependency weight injection noise to empirically verify Theorem 3.2's prediction that weak dependencies increase regret.

2. **Augmentation Isolation Test:** Run controlled experiments disabling augmented confidence bounds (setting all n_r = 0) to measure pure contribution of augmentation mechanism versus standard dueling bandit performance.

3. **Real-world Noise Robustness:** Apply framework to domain with known noisy preference patterns (e.g., subjective aesthetic ratings) to test whether calibration threshold effectively filters invalid augmented feedback as claimed.