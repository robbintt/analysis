---
ver: rpa2
title: Multispectral LiDAR data for extracting tree points in urban and suburban areas
arxiv_id: '2508.19881'
source_url: https://arxiv.org/abs/2508.19881
tags:
- tree
- point
- data
- points
- urban
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study presents a deep learning-based approach for extracting\
  \ tree points from multispectral LiDAR data in complex urban and suburban environments.\
  \ The method leverages multispectral LiDAR point clouds and three state-of-the-art\
  \ transformer-based deep learning models\u2014Superpoint Transformer (SPT), Point\
  \ Transformer V3 (PTv3), and Point Transformer V1 (PTv1)\u2014for binary semantic\
  \ segmentation of tree and non-tree points."
---

# Multispectral LiDAR data for extracting tree points in urban and suburban areas

## Quick Facts
- **arXiv ID:** 2508.19881
- **Source URL:** https://arxiv.org/abs/2508.19881
- **Reference count:** 21
- **Primary result:** Superpoint Transformer (SPT) achieved 85.28% mIoU for tree point extraction from MS-LiDAR data

## Executive Summary
This study presents a deep learning approach for extracting tree points from multispectral LiDAR data in complex urban and suburban environments. The method leverages multispectral LiDAR point clouds and three state-of-the-art transformer-based deep learning models—Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point Transformer V1 (PTv1)—for binary semantic segmentation of tree and non-tree points. A spectral ablation study was conducted to evaluate the contribution of multispectral information, including pseudo normalized difference vegetation index (pNDVI). The best-performing model, SPT, achieved a mean intersection over union (mIoU) of 85.28% for tree detection and demonstrated notable time efficiency. Incorporating pNDVI with spatial data reduced the error rate by 10.61 percentage points compared to using spatial information alone.

## Method Summary
The method employs multispectral LiDAR point clouds and three transformer-based deep learning models for binary semantic segmentation of tree and non-tree points. The Superpoint Transformer (SPT) uses hierarchical superpoint partitioning with self-attention mechanisms for efficient processing. The approach includes preprocessing steps such as statistical outlier removal, channel merging, reflectance interpolation, height normalization using ground classification, and feature engineering with spectral indices. The workflow processes Loosdorf-tree dataset (48M points, 21.11 pts/m² density) using 300 epochs with AdamW optimizer and weighted cross-entropy loss.

## Key Results
- SPT achieved the highest mIoU of 85.28% for tree detection
- Spectral ablation showed pNDVI reduced error rate by 10.61 percentage points for elevated points
- SPT demonstrated superior time efficiency with only 212K parameters and 0.67 hours training time
- Error rate for normalized height >2m points: XYZ alone = 39.63%, XYZ + pNDVI = 29.02%

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Superpoint-based hierarchical partitioning enables efficient processing of large-scale MS-LiDAR point clouds while preserving semantic relationships.
- Mechanism: SPT first partitions point clouds into hierarchical superpoint structures using a parallel cut pursuit algorithm, then learns semantic relationships between superpoints rather than individual points. A self-attention mechanism captures relationships across multiple scales.
- Core assumption: Semantic homogeneity exists within spatially proximate point clusters; superpoint granularity preserves sufficient detail for tree/non-tree discrimination.
- Evidence anchors:
  - [abstract] "Results show the notable time efficiency and accuracy of SPT, with a mean intersection over union (mIoU) of 85.28%."
  - [Page 2, Section II.C] "SPT first partitions point clouds into a hierarchical superpoint structure using a parallel cut pursuit algorithm, and then learns the semantic relationships between superpoints rather than individual points, making it highly time-efficient."
  - [Page 4, Table V] SPT requires only 212K parameters and 0.67 hours training time vs. PTv1's 170.3M parameters and 26.37 hours.

### Mechanism 2
- Claim: Pseudo-NDVI derived from multispectral reflectance provides discriminative spectral features that reduce confusion between trees and geometrically similar non-tree objects.
- Mechanism: pNDVI = (NIR_linear - green_linear) / (NIR_linear + green_linear) leverages vegetation's characteristic high NIR and low green reflectance. This spectral signature helps disambiguate trees from facades, cables, and towers that share similar 3D geometries.
- Core assumption: Active multispectral LiDAR reflectance values correlate sufficiently with passive optical vegetation indices; incidence angle effects are secondary.
- Evidence anchors:
  - [abstract] "Incorporating pNDVI with spatial data reduced the error rate by 10.61 percentage points compared to using spatial information alone."
  - [Page 3, Table IV] Error rate for points with normalized height >2m: XYZ alone = 39.63%; XYZ + pNDVI = 29.02%.
  - [Page 3-4, Section IV.A] "Both Figure 1 and Table IV demonstrate the substantial superiority of using pNDVI alone, reducing the error rate by 10.61 pp."

### Mechanism 3
- Claim: Height normalization combined with spectral features addresses the primary challenge of distinguishing elevated non-tree objects from actual trees.
- Mechanism: Ground points identified via Cloth Simulation Filter → DTM generation → normalized height = point elevation - DTM height. Points with normalized height >2m contain the critical confusion cases (facades, towers, cables); spectral information resolves these without post-processing heuristics.
- Core assumption: DTM extraction is accurate; complex urban canyons do not introduce systematic ground classification errors.
- Evidence anchors:
  - [Page 2, Section II.B] "To perform height normalization, ground points are first identified using the cloth simulation filter (CSF) plugin in CloudCompare."
  - [Page 3, Section IV.A] "Misclassified objects with greater heights, particularly those with geometries similar to trees, such as facades, cables, electric towers, and fences, pose the most serious challenge. These non-tree classes cannot be easily eliminated through post-processing."

## Foundational Learning

- **Concept: Point cloud semantic segmentation**
  - Why needed here: Core task formulation; understanding per-point binary classification vs. multi-class segmentation informs model selection and loss function design.
  - Quick check question: Can you explain why IoU is preferred over accuracy for imbalanced datasets (18% tree vs. 82% non-tree)?

- **Concept: Vegetation indices (NDVI family)**
  - Why needed here: pNDVI is the single most effective spectral feature; understanding its physical basis (chlorophyll absorption in visible, cell structure reflectance in NIR) enables debugging of anomalous results.
  - Quick check question: Why might pNDVI fail on drought-stressed trees or trees with specular leaf surfaces?

- **Concept: Transformer self-attention for 3D data**
  - Why needed here: All three models use attention mechanisms; understanding how spatial serialization patterns (Hilbert, Z-order) affect attention scope helps explain PTv3's architecture choices.
  - Quick check question: How does learning relationships between superpoints (SPT) differ from learning relationships between individual points (PTv1), and what are the computational implications?

## Architecture Onboarding

- **Component map:**
Raw MS-LiDAR (532nm + 1064nm channels) → Preprocessing (SOR denoising → Channel merging → Reflectance interpolation → Height normalization) → Feature engineering (XYZ + green_reflectance + NIR_reflectance + pNDVI) → Model selection (SPT/PTv1/PTv3) → Training (AdamW, weighted cross-entropy, 300 epochs) → Inference → Post-processing threshold at 2m normalized height

- **Critical path:**
1. Channel merging quality (1m spherical neighborhood interpolation)
2. Ground classification accuracy (CSF parameters)
3. Spectral feature normalization (outlier-resistant scaling + min-max)
4. SPT regularization/spatial weight/cutoff hyperparameters

- **Design tradeoffs:**
- SPT: Highest efficiency (212K params, 0.67h) but requires superpoint partitioning step; best for production deployment
- PTv3: Balance of accuracy (83.44% mIoU) and moderate efficiency (46.15M params, 2.32h)
- PTv1: Baseline transformer approach; least efficient (170.3M params, 26.37h) and lowest accuracy (81.96% mIoU)
- Spectral features: Adding green+NIR+pNDVI yields 84.95% mIoU vs. 85.28% for green+NIR alone—consider computational cost of pNDVI calculation

- **Failure signatures:**
- High false positives on elevated structures (facades, towers) → indicates insufficient spectral feature contribution; check pNDVI distribution
- High false negatives on low branches → height thresholding may be too aggressive; consider lowering from 2m
- Slow training with PTv1 → expected behavior; switch to SPT
- Poor ground classification in urban canyons → adjust CSF cloth resolution or switch to alternative ground filters

- **First 3 experiments:**
1. Baseline spatial-only: Train SPT with XYZ features only; expect ~81.71% mIoU (Table III). This establishes lower bound and validates preprocessing pipeline.
2. Spectral ablation: Add one spectral feature at a time (green, then NIR, then pNDVI); measure mIoU and error rate for height>2m points. Validate that pNDVI provides largest error reduction.
3. Model comparison: Under identical features (XYZ+green+NIR) and training epochs (300), compare SPT vs. PTv3 vs. PTv1 on validation set. Confirm SPT superiority on your hardware.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does applying incidence angle correction to the RIEGL reflectance values improve the accuracy of pNDVI-based tree point extraction?
- Basis in paper: [explicit] The authors note in the conclusion that relative reflectance values do not currently consider incidence angle, suggesting improved outcomes could result from such correction.
- Why unresolved: The current workflow uses range-corrected relative reflectance without angle adjustment, potentially introducing noise on steep surfaces or off-nadir returns.
- What evidence would resolve it: A comparative study training the Superpoint Transformer (SPT) with raw reflectance versus incidence-angle-corrected reflectance on the same dataset.

### Open Question 2
- Question: How does tree extraction performance scale when utilizing multispectral LiDAR systems with more than two spectral channels?
- Basis in paper: [explicit] The authors state that further improvements can be achieved by deploying systems operating across a greater number of channels, though the study was limited to a dual-wavelength (532 nm and 1064 nm) system.
- Why unresolved: It is unclear if the marginal performance gains provided by the second channel extend linearly or if additional spectral bands are redundant for binary tree segmentation.
- What evidence would resolve it: Evaluating the proposed SPT architecture on hyperspectral LiDAR datasets (e.g., 3+ channels) to quantify accuracy changes relative to the dual-channel baseline.

### Open Question 3
- Question: Can the spatial-spectral features identified as optimal for binary segmentation be effectively transferred to fine-grained tree species classification?
- Basis in paper: [explicit] The authors highlight that active multispectral information provides even greater benefits for urban tree management, specifically citing tree species classification and health monitoring as key future applications.
- Why unresolved: This study focused solely on binary segmentation (tree vs. non-tree); it remains unverified if pNDVI and green/NIR reflectance provide sufficient discriminative power for multi-class species separation.
- What evidence would resolve it: Applying the best-performing SPT model configuration to a dataset with species-level annotations and assessing the mean Intersection over Union (mIoU) across multiple tree classes.

## Limitations

- The study uses a single study area (Loosdorf), limiting generalizability across different urban environments and sensor configurations
- Dataset access may be restricted, as the paper states it "will be provided upon acceptance"
- The weighted cross-entropy loss implementation details are not fully specified
- The study focuses on binary segmentation only, without exploring fine-grained tree species classification

## Confidence

- **High confidence:** The mechanism by which SPT's superpoint partitioning enables time efficiency (supported by parameter count and training time comparisons)
- **High confidence:** The effectiveness of pNDVI in reducing error rates for elevated non-tree objects (supported by quantitative error rate reduction)
- **Medium confidence:** The generalization of results across different urban environments (limited by single study area)
- **Medium confidence:** The specific implementation details of preprocessing steps (some algorithmic details unspecified)

## Next Checks

1. Request access to the Loosdorf-tree dataset from TU Wien repository and verify the 85.28% mIoU achievement under the specified conditions
2. Implement the spectral ablation study (XYZ only → XYZ + Green → XYZ + NIR → XYZ + Green + NIR + pNDVI) to confirm the 10.61 percentage point error reduction claim
3. Conduct model comparison experiments (SPT vs. PTv3 vs. PTv1) using identical features and training conditions to validate the efficiency-accuracy tradeoff claims