---
ver: rpa2
title: 'Krum Federated Chain (KFC): Using blockchain to defend against adversarial
  attacks in Federated Learning'
arxiv_id: '2502.06917'
source_url: https://arxiv.org/abs/2502.06917
tags:
- learning
- pofl
- accuracy
- backdoor
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tests the use of Proof of Federated Learning (PoFL)
  as a defense against adversarial attacks in federated learning (FL), finding it
  effective when at least one miner remains uncompromised. To address its vulnerability
  when all miners are compromised, the authors propose Krum Federated Chain (KFC),
  combining the Krum aggregation operator with PoFL.
---

# Krum Federated Chain (KFC): Using blockchain to defend against adversarial attacks in Federated Learning

## Quick Facts
- **arXiv ID:** 2502.06917
- **Source URL:** https://arxiv.org/abs/2502.06917
- **Reference count:** 40
- **Primary result:** KFC combines PoFL consensus with Krum aggregation to defend against adversarial attacks even when all miners are compromised, maintaining high original-task accuracy while minimizing backdoor success.

## Executive Summary
This paper addresses adversarial attacks in federated learning by proposing the Krum Federated Chain (KFC), which combines Proof of Federated Learning (PoFL) consensus with the Krum aggregation operator. The authors demonstrate that PoFL alone effectively defends against Byzantine and backdoor attacks when at least one miner pool remains uncompromised, but fails when all miners are adversarial. KFC overcomes this limitation by applying Krum's geometric filtering within each pool before the PoFL competition, enabling robust defense even under complete miner compromise. Experimental results on EMNIST, Fashion MNIST, and CIFAR-10 show KFC achieves high accuracy on original tasks while maintaining low backdoor attack success across all attack configurations.

## Method Summary
The method implements a pooled-mining blockchain architecture where miners coordinate client pools in federated learning. Each miner aggregates client updates using either FedAvg (baselines) or Krum (KFC). PoFL consensus selects the winning pool based on validation accuracy. In KFC, Krum filters outlying client updates within each pool by computing pairwise Euclidean distances and selecting the update closest to its n-f-2 nearest neighbors. The system trains on EMNIST, Fashion MNIST, and CIFAR-10 with pattern-key backdoor attacks and label-flipping Byzantine attacks, evaluating original-task and backdoor-task accuracy over 100 rounds with 3 miners (EMNIST/Fashion MNIST) or 2 miners (CIFAR-10).

## Key Results
- PoFL successfully defends against adversarial attacks when at least one miner remains uncompromised, achieving high original-task accuracy and low backdoor-task accuracy
- PoFL fails completely under Scenario B (all miners compromised), with original-task accuracy dropping and backdoor-task accuracy exceeding 80%
- KFC maintains robust performance under all attack configurations, achieving high original-task accuracy and minimizing backdoor-task success even when all miners are adversarial
- Experimental validation across three datasets (EMNIST, Fashion MNIST, CIFAR-10) confirms KFC's superiority over PoFL, PoW, PoS, FedAvg, Krum, and Trimmed-mean baselines

## Why This Works (Mechanism)

### Mechanism 1
PoFL consensus provides defense against adversarial attacks when at least one miner pool remains uncompromised. PoFL uses pooled-mining where miners compete based on model accuracy on a validation dataset. Adversarial attacks degrade performance on the primary task, causing compromised pools to be filtered out in favor of uncompromised pools. Core assumption: at least one miner pool contains no adversarial clients. Break condition: when all miners/pools are compromised.

### Mechanism 2
The Krum aggregation operator filters outlying client updates based on geometric distance in parameter space. Krum computes pairwise Euclidean distances between client model updates, assigns each client a score based on the sum of distances to its n−f−2 nearest neighbors, and selects the update with the minimum score. Adversarial updates typically deviate significantly from benign updates and receive high scores, causing them to be excluded. Core assumption: adversarial updates are geometric outliers; parameter f correctly bounds the number of adversarial clients. Break condition: if adversarial updates are not geometric outliers or if adversaries exceed threshold f.

### Mechanism 3
KFC combines PoFL's inter-pool competition with Krum's intra-pool filtering to achieve robustness even when all miners are compromised. Within each pool, the miner applies Krum aggregation to client updates before training, filtering adversarial clients locally. Pools then compete via PoFL's accuracy-based consensus. Even if every pool contains some adversarial clients, Krum's local filtering reduces their influence before the inter-pool competition phase. Core assumption: Krum can effectively filter enough adversarial clients within each pool such that the resulting pool model achieves acceptable accuracy. Break condition: if Krum's filtering fails within pools or if the validation dataset is poisoned.

## Foundational Learning

- **Concept: Federated Averaging (FedAvg)**
  - **Why needed here:** FedAvg is the default aggregation operator used in baseline architectures. Understanding how FedAvg aggregates local model updates is necessary to see why it is vulnerable to adversarial attacks and how Krum differs.
  - **Quick check question:** Can you explain how FedAvg computes the global model from client updates and why it is susceptible to a single malicious client?

- **Concept: Byzantine Fault Tolerance in Distributed Systems**
  - **Why needed here:** The paper frames adversarial attacks as Byzantine failures where malicious participants send arbitrary or malicious updates. Understanding Byzantine fault tolerance helps contextualize why Krum's distance-based filtering and PoFL's accuracy-based selection are plausible defenses.
  - **Quick check question:** In a distributed system with n participants, what is the maximum number of Byzantine failures that can be tolerated under different consensus assumptions?

- **Concept: Blockchain Consensus Mechanisms (PoW, PoS, PoFL)**
  - **Why needed here:** The paper compares PoFL against PoW and PoS baselines. Understanding how these mechanisms select validators and achieve consensus clarifies why PoFL's accuracy-based approach is structurally different and potentially more aligned with FL security goals.
  - **Quick check question:** How does PoFL's accuracy-based consensus differ from PoW's computational puzzle approach in terms of resource use and security assumptions?

## Architecture Onboarding

- **Component map:**
  Clients -> Miners -> Pools -> Blockchain -> Consensus Layer -> Aggregation Operator

- **Critical path:**
  1. Miner broadcasts initial global model to pool clients
  2. Clients train locally on private data and compute updates
  3. Clients send updates to miner
  4. Miner aggregates updates (Krum in KFC, FedAvg otherwise)
  5. Miner evaluates aggregated model accuracy on validation dataset
  6. All miners compete in consensus; highest-accuracy model wins (PoFL)
  7. Winning model is appended to blockchain and broadcast to all clients for next round

- **Design tradeoffs:**
  1. Krum vs. FedAvg: Krum provides Byzantine robustness but has O(n²) complexity vs. FedAvg's O(n)
  2. PoFL vs. PoW/PoS: PoFL reuses computation for model training (energy-efficient) but requires a trusted validation dataset
  3. Pooled vs. Coupled Architecture: Pooled mining isolates pools for scalability but requires coordination across miners
  4. Validation Set Size: 20% of test data used for validation; larger sets may improve consensus accuracy but reduce evaluation data

- **Failure signatures:**
  1. PoFL under Scenario B: Original-task accuracy drops; backdoor-task accuracy rises sharply (>80%)
  2. Krum with adaptive attacks: May fail to filter sophisticated attacks that blend with benign updates
  3. Validation dataset poisoning: If attackers influence the validation dataset, accuracy-based selection may be manipulated

- **First 3 experiments:**
  1. Reproduce Scenario A with PoFL vs. baselines: Train on EMNIST/Fashion MNIST with single adversarial client per compromised pool; compare original and backdoor accuracy
  2. Reproduce Scenario B with KFC vs. PoFL: Configure all pools to contain at least one adversarial client; verify KFC maintains original accuracy and minimizes backdoor success
  3. Parameter sensitivity test for Krum threshold f: Vary f parameter across different adversary fractions within pools; measure impact on accuracy and backdoor success

## Open Questions the Paper Calls Out

- Can more computationally efficient aggregation operators be substituted for the Krum operator within the KFC framework to improve scalability without compromising defense performance? (Section 8)
- Is the KFC defense strategy effective against more sophisticated and stealthy backdoor attacks, such as semantic backdoors or adaptive attacks? (Section 8)
- Does the Krum Federated Chain architecture provide resilience against privacy attacks, such as membership inference or model inversion? (Section 9)

## Limitations
- Key training hyperparameters (local epochs, batch size, learning rates) are not explicitly defined, making exact reproduction challenging
- Paper does not explicitly test Krum's robustness against sophisticated adaptive attacks that blend with benign updates
- PoFL's accuracy-based consensus assumes a trusted validation set; no explicit analysis of what happens if this dataset is compromised

## Confidence
- **High confidence**: PoFL fails when all miners are compromised - directly demonstrated in experiments
- **Medium confidence**: KFC's robustness - experimental results support the claim, but combination represents novel mechanism with limited external validation
- **Medium confidence**: Byzantine-robustness claims for Krum - well-established in literature, but implementation details and parameter choices are critical

## Next Checks
1. **Parameter sensitivity analysis**: Systematically vary the Krum parameter f across different adversary fractions within pools to establish robustness bounds
2. **Adaptive attack testing**: Implement and evaluate KFC against sophisticated adaptive attacks that generate updates designed to evade Krum's geometric outlier detection
3. **Validation dataset manipulation**: Test KFC's performance when the validation dataset used for PoFL consensus is partially poisoned to assess security assumptions