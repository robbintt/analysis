---
ver: rpa2
title: 'InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust
  Image Zero-Watermarking'
arxiv_id: '2506.20370'
source_url: https://arxiv.org/abs/2506.20370
tags:
- feature
- image
- learning
- features
- invariant
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents InvZW, a novel deep learning framework for
  robust image zero-watermarking based on distortion-invariant feature learning. The
  proposed method addresses the challenge of maintaining feature stability under diverse
  image distortions while enabling reliable watermark extraction.
---

# InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking

## Quick Facts
- arXiv ID: 2506.20370
- Source URL: https://arxiv.org/abs/2506.20370
- Reference count: 30
- Primary result: InvZW achieves bit accuracies up to 99.9% under various distortions, outperforming existing self-supervised and deep watermarking techniques in generalization and robustness.

## Executive Summary
InvZW introduces a novel deep learning framework for robust image zero-watermarking based on distortion-invariant feature learning. The method addresses the challenge of maintaining feature stability under diverse image distortions while enabling reliable watermark extraction. By combining adversarial supervision against a distortion discriminator with a reconstruction constraint, InvZW trains a feature extractor to generate representations that are both invariant to distortions and semantically expressive. A learning-based multibit zero-watermarking scheme then projects these invariant features onto trainable reference codes optimized to match target binary messages. Extensive experiments demonstrate state-of-the-art robustness in both feature stability and watermark recovery.

## Method Summary
InvZW operates in two modules: (1) invariant feature learning via noise-adversarial training, and (2) learning-based multibit zero-watermarking with trainable reference codes. The feature extractor (ViT) is trained to generate distortion-invariant features by fooling a discriminator that tries to classify clean vs distorted images, while a reconstruction constraint prevents feature collapse. The watermarking module optimizes reference signatures in the invariant feature space to embed and extract multibit messages. Training uses geometric distortions only (rotation, shift, shear, zoom, horizontal flip), while testing includes both geometric and photometric distortions.

## Key Results
- Bit accuracy up to 99.9% under various distortions
- Cosine similarity ≥0.91 under salt & pepper noise and solarization despite training only on geometric distortions
- Top-1 accuracy 75.8% on CIFAR-100 under Gaussian noise, indicating retained semantic discriminability
- BER 0.05–8% across six distortion types at 30 bits

## Why This Works (Mechanism)

### Mechanism 1
Noise-adversarial training produces features that remain stable under distortions not seen during training. A minimax game where a discriminator D learns to classify whether features came from clean or distorted images, while the feature extractor FE learns to fool D. When D cannot distinguish p(FE(x)) from p(FE(x′)), the features have become domain-invariant. Core assumption: Distortion acts as a latent domain shift, and aligning feature distributions across clean/distorted domains yields invariance that transfers to unseen transformations. Evidence: Cosine similarity ≥0.91 under salt & pepper noise and solarization despite training only on geometric distortions. Break condition: If distortions at test time introduce semantic shifts rather than nuisance variations, domain alignment may not transfer.

### Mechanism 2
The reconstruction constraint prevents feature collapse while preserving semantic expressiveness. A reconstructor R decodes features back to images via MSE + SSIM losses. This enforces I(F, x) > 0, countering the adversarial objective's pressure toward trivial constant representations. Core assumption: Reconstructability from global features implies retention of watermark-relevant semantic structure. Evidence: Linear evaluation shows Top-1 accuracy 75.8% on CIFAR-100 under Gaussian noise, indicating retained semantic discriminability. Break condition: If reconstruction focuses on low-frequency content while watermarking requires high-frequency invariance, the semantic preservation may be misaligned with task needs.

### Mechanism 3
Learning per-image reference signatures in invariant feature space enables robust multibit extraction. For each image-watermark pair, optimize C ∈ R^(k×d) such that σ(F̃ · C_i) ≈ W_i. Since F̃ is distortion-invariant, F̃′ ≈ F̃ under attack, and the same C recovers W. Core assumption: The inner product geometry in the learned feature space is sufficiently stable that thresholded sigmoid outputs generalize across distortions. Evidence: BER 0.05–8% across six distortion types at 30 bits. Break condition: If feature variance across distortions exceeds the margin around 0.5, bit predictions become unstable.

## Foundational Learning

- **Domain-Adversarial Learning (Ganin et al., 2016):** Core technique enabling FE to learn features where p(F|clean) ≈ p(F|distorted) via gradient reversal. Quick check: Can you explain why flipping gradient signs during backpropagation makes features indistinguishable across domains?

- **Vision Transformer (ViT) patch embeddings:** FE and D use ViT with 16×16 patches; understanding positional encodings and [CLS] tokens is prerequisite to reading the architecture. Quick check: How does the [CLS] token aggregate global information across patches in a ViT?

- **Zero-watermarking vs. embedded watermarking:** The paper's threat model and evaluation assume understanding that zero-watermarking leaves cover images unmodified. Quick check: Why does zero-watermarking require external storage of reference signatures, and what security properties does this trade off?

## Architecture Onboarding

- **Component map:** Image → FE (ViT-Base) → F → Ψ (GAP+FC) → F̃ → F̃ · C → σ → Ẇ
- **Critical path:** Image → FE → F → Ψ → F̃ → F̃ · C → σ → Ẇ (extraction path; same for registration with BCE supervision)
- **Design tradeoffs:** Training with geometric-only distortions improves generalization but risks underfitting to photometric attacks present at test time. L2 regularization on C trades capacity for stability. ViT over CNN for FE trades inductive bias for global context.
- **Failure signatures:** High BER (>10%) on salt & pepper noise at high intensity suggests feature variance exceeds decision margin. If D loss converges to 0, FE has failed to learn invariance. If reconstruction PSNR < 20 dB, features may have collapsed to non-semantic encodings.
- **First 3 experiments:**
  1. Reproduce Figure 5 training curves on a 5K subset; verify D loss ≈ log(0.5) at convergence
  2. Ablation: Remove reconstruction loss and measure cosine similarity drop on held-out distortions
  3. Stress test: Evaluate BER under combined distortions (e.g., JPEG + rotation) not in Table I

## Open Questions the Paper Calls Out
- Can the distortion-invariant feature learning framework be effectively extended to video watermarking while maintaining temporal consistency?
- How can the framework incorporate adaptive optimization strategies for signature learning in dynamic distortion environments?
- Does the requirement to optimize the reference signature C via gradient descent for every image-watermark pair hinder the applicability of InvZW to real-time systems?

## Limitations
- The exact noise intensities and image content in test distortions are not detailed, making quantitative reproducibility uncertain
- The mechanism by which reference codes C generalize across distortions remains heuristic rather than theoretically grounded
- The paper does not analyze security vulnerabilities if reference signatures are compromised

## Confidence
- **High Confidence:** Overall experimental methodology and results presentation are clear and reproducible
- **Medium Confidence:** Claim that adversarial training produces transferable invariance is plausible but requires further validation
- **Low Confidence:** Security implications of zero-watermarking are not analyzed

## Next Checks
1. Ablation Study on Reconstruction Loss: Remove λ_M and λ_S from the loss function and measure the resulting cosine similarity drop on held-out distortions
2. Stress Test on Combined Distortions: Evaluate BER under additive distortions not present in Table I (e.g., JPEG compression + rotation + Gaussian noise)
3. Discriminator Loss Monitoring: Track D loss throughout training to ensure it converges to ~log(0.5), indicating that FE successfully fools the discriminator