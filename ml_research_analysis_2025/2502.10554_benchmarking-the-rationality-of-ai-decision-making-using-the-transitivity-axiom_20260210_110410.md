---
ver: rpa2
title: Benchmarking the rationality of AI decision making using the transitivity axiom
arxiv_id: '2502.10554'
source_url: https://arxiv.org/abs/2502.10554
tags:
- transitivity
- choice
- llama
- gamble
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study benchmarks the rationality of AI decision-making by
  testing whether ten versions of Meta's Llama 2 and 3 models satisfy transitivity
  of preference, a key axiom of rational choice. Using Bayesian model selection, the
  authors compared two probabilistic models of transitivity (Weak Stochastic Transitivity
  and the Mixture Model) against an unconstrained benchmark across 600 tests.
---

# Benchmarking the rationality of AI decision making using the transitivity axiom
## Quick Facts
- arXiv ID: 2502.10554
- Source URL: https://arxiv.org/abs/2502.10554
- Reference count: 14
- Primary result: Llama models generally satisfy transitivity of preference, but Chat/Instruct versions of Llama 3 showed violations when probabilities were presented as percentages with dollar-sign formatting

## Executive Summary
This study evaluates the rationality of Meta's Llama 2 and 3 AI models by testing their adherence to transitivity of preference, a fundamental axiom of rational choice theory. Using Bayesian model selection, the researchers compared probabilistic models of transitivity against an unconstrained benchmark across 600 tests. The results demonstrate that Llama models generally exhibit rational decision-making behavior, with most favoring a Mixture Model that accounts for both transitive and intransitive responses. However, violations of transitivity were observed in Chat and Instruct versions of Llama 3, particularly when probabilities were presented in specific formats, suggesting that fine-tuning may introduce irrational decision patterns under certain conditions.

## Method Summary
The researchers employed a behavioral experiment framework using pairwise comparisons to test transitivity in Llama models. They constructed sets of four lotteries varying in probability of winning $100, presented in different formats (decimals, fractions, percentages with/without dollar signs). Each model was prompted to choose between lotteries using a standardized prompt, with 50 trials per condition. The team applied Bayesian model selection to compare two transitivity models (Weak Stochastic Transitivity and Mixture Model) against an unconstrained benchmark. The Mixture Model allows for both transitive and intransitive responses, capturing potential violations while maintaining rational behavior. They tested ten versions of Llama 2 and 3 models across 600 total tests, analyzing whether responses conformed to rational choice theory.

## Key Results
- Llama models generally satisfied transitivity of preference, with most tests favoring the Mixture Model
- Chat and Instruct versions of Llama 3 showed violations of transitivity, particularly when probabilities were presented as percentages with dollar-sign formatting
- The Mixture Model, which accounts for both transitive and intransitive responses, was the most commonly selected model across all Llama versions
- Basic Llama 3.1 8B model showed near-perfect transitivity, while its Chat counterpart exhibited more violations

## Why This Works (Mechanism)
The Mixture Model approach works by probabilistically combining rational (transitive) and potentially irrational (intransitive) decision patterns, allowing the model to capture both systematic preferences and occasional violations. This framework acknowledges that real-world decision-making often involves a mixture of rational and heuristic-driven choices, rather than pure rationality. By testing across multiple probability formats and model variants, the study isolates specific conditions that trigger violations, revealing how fine-tuning and presentation format can influence decision consistency.

## Foundational Learning
- **Transitivity of preference**: A fundamental axiom stating if A is preferred to B and B is preferred to C, then A should be preferred to C; needed to establish baseline rationality standards for AI systems.
- **Weak Stochastic Transitivity**: A probabilistic extension allowing for ties and uncertainty in preferences; needed to account for real-world decision noise in AI responses.
- **Bayesian model selection**: A statistical framework for comparing competing models based on evidence; needed to objectively determine which decision model best explains AI behavior.
- **Pairwise comparison design**: Method of presenting two options at a time to elicit preferences; needed to systematically test transitivity across multiple choice scenarios.
- **Lottery choice paradigm**: Experimental method using probabilistic rewards to test decision-making; needed to create controlled, comparable scenarios for AI models.
- **Mixture Model**: A hybrid approach combining rational and irrational response patterns; needed to capture both systematic preferences and occasional violations in AI decision-making.

## Architecture Onboarding
Component map: Prompt formatting -> LLM processing -> Response generation -> Preference extraction -> Transitivity evaluation
Critical path: The core pipeline involves carefully formatted prompts being processed by the LLM, with responses analyzed for preference ordering and tested against transitivity axioms.
Design tradeoffs: The study balances model complexity (Mixture vs. pure transitivity) against explanatory power, accepting some violations to capture realistic decision patterns rather than enforcing perfect rationality.
Failure signatures: Intransitive responses manifest as cycles in preference ordering (A>B, B>C, but C>A), with higher frequency in Chat/Instruct versions under specific formatting conditions.
First experiments:
1. Test basic transitivity with decimal-formatted probabilities across all Llama versions
2. Compare response consistency between standard and Chat/Instruct model variants
3. Evaluate impact of probability format changes on transitivity violations

## Open Questions the Paper Calls Out
The paper highlights several open questions regarding the nature of AI decision-making rationality, particularly why fine-tuned Chat and Instruct versions show more violations than their base counterparts, and how specific formatting choices influence rational behavior in language models.

## Limitations
- The study only tests Meta's Llama models, limiting generalizability to other LLM architectures
- Violations were observed but not fully explained, leaving uncertainty about underlying mechanisms
- The experimental design uses artificial lottery choices, which may not reflect real-world decision contexts

## Confidence
- General transitivity satisfaction in Llama models: High
- Specific violations in Chat/Instruct versions: Medium
- Effectiveness of Mixture Model for explaining behavior: High
- Impact of formatting on rationality: Medium

## Next Checks
1. Test transitivity across additional LLM families (GPT, Claude, etc.) to assess generalizability
2. Investigate whether fine-tuning methodology specifically introduces intransitive patterns
3. Examine real-world decision tasks beyond artificial lottery choices to validate findings in practical contexts