---
ver: rpa2
title: Position-aware Automatic Circuit Discovery
arxiv_id: '2502.04577'
source_url: https://arxiv.org/abs/2502.04577
tags:
- schema
- circuit
- edges
- faithfulness
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses a key limitation in automatic circuit discovery
  methods: their assumption that circuits are position-invariant, treating model components
  as equally relevant across all input positions. This limits their ability to capture
  cross-positional interactions or mechanisms that vary across positions.'
---

# Position-aware Automatic Circuit Discovery

## Quick Facts
- **arXiv ID:** 2502.04577
- **Source URL:** https://arxiv.org/abs/2502.04577
- **Reference count:** 40
- **Primary result:** Position-aware circuits achieved better size-faithfulness tradeoffs than position-agnostic methods, with automated schema generation matching human-designed schemas

## Executive Summary
This paper addresses a fundamental limitation in automatic circuit discovery: the assumption that circuits are position-invariant across all input positions. The authors propose Position-Aware Edge Attribution Patching (PEAP) that extends standard edge attribution to differentiate between token positions, enabling computation of cross-positional edge importance. They also introduce dataset schemas - semantic span definitions that enable circuit discovery on variable-length inputs. Their automated pipeline using LLMs generates and applies schemas, achieving comparable faithfulness to manual schemas while maintaining scalability.

## Method Summary
The method extends Edge Attribution Patching to handle position-specific query, key, and value vectors separately (Equations 4-6), allowing cross-positional edge attribution. Dataset schemas are defined as semantic spans with consistent functional roles across examples. An automated pipeline generates saliency masks using inputXgradient scores, then uses Claude 3.5 Sonnet to create schemas from 5-example subsets, unifying them and validating on ≥80% of the dataset. Circuits are discovered via greedy edge selection starting from logits backward, ensuring connectivity to embeddings.

## Key Results
- Position-aware circuits achieved better size-faithfulness tradeoffs than position-agnostic methods
- Automated schema generation matched human-designed schemas in faithfulness scores
- PEAP prevented "cancellation effects" where opposing position scores would sum to zero
- Position-aware circuits failed to improve faithfulness on Winobias, indicating task-specific limitations

## Why This Works (Mechanism)

### Mechanism 1: Cross-Positional Edge Attribution
- **Claim:** Decomposing attention head inputs into position-specific query, key, and value edges allows precise identification of causal pathways across token positions, preventing "cancellation" effects.
- **Core assumption:** The causal effect of an attention edge is locally linear, allowing gradient-based approximations to substitute for direct activation patching.
- **Evidence:** [abstract] "extend edge attribution patching... to differentiate between token positions"; [section 3.1] defines z* using patching v_{t'}, k_{t'}, or q_t.

### Mechanism 2: Schema-Based Aggregation
- **Claim:** Mapping concrete token-level computation graphs to abstract "schema" graphs (where nodes are semantic spans) enables circuit discovery on variable-length inputs without forcing artificial token alignment.
- **Core assumption:** Examples share high-level semantic structure where specific spans play similar functional roles.
- **Evidence:** [abstract] "dataset schemas... enabling position-aware circuit discovery in datasets with variable length examples"; [section 4.1] defines abstract computation graph G_S.

### Mechanism 3: Saliency-Guided Schema Generation
- **Claim:** Incorporating model-derived saliency scores into LLM schema generation aligns the semantic schema more closely with the model's actual causal logic than text-only generation.
- **Core assumption:** Token positions with high gradient-based saliency correspond to functional components in the causal circuit.
- **Evidence:** [section 4.2] "incorporate the importance of each token position... into the schema generation"; [results] automated schemas achieved comparable faithfulness to manual schemas.

## Foundational Learning

- **Concept: Computation Graphs & Residual Streams**
  - **Why needed here:** PEAP operates on edges of the computation graph and their connections via the residual stream. Understanding specific "hooks" or positions is vital.
  - **Quick check:** Can you distinguish between the "node" representing an attention head and the specific "edges" (query, key, value) that feed into it?

- **Concept: Attribution Patching (Gradient Approximation)**
  - **Why needed here:** The paper builds upon Edge Attribution Patching (EAP). This is a cheap, gradient-based proxy for the "gold standard" of activation patching.
  - **Quick check:** Why does the paper claim that summing attribution scores across positions can lead to "cancellation" (low recall)?

- **Concept: Semantic Abstraction / Schemas**
  - **Why needed here:** The core novelty for handling variable-length inputs is the "Schema." You need to understand how mapping variable tokens to fixed spans allows averaging of circuit data.
  - **Quick check:** If a schema groups two important tokens into one span, what information is potentially lost during the aggregation step?

## Architecture Onboarding

- **Component map:** PEAP Core -> Schema Engine -> Graph Manager -> Circuit Builder
- **Critical path:** Data Prep (clean samples + counterfactuals) -> Schema Gen (Saliency Mask → LLM → Schema) -> Attribution (PEAP scores) -> Aggregation (map to G_S) -> Discovery (greedy search)
- **Design tradeoffs:** LLM+Mask for schemas is scalable but depends on LLM parsing; manual schemas are precise but labor-intensive. Faithfulness vs. size trade-off demonstrated.
- **Failure signatures:** Schema Collapse (validity < 80%), Cancellation Artifacts (position-agnostic methods), Overestimation (non-positional methods selecting cumulative small effects).
- **First 3 experiments:** 1) Reproduce "Greater-Than" Baseline with basic PEAP. 2) Ablate Schema Generation (manual vs. LLM-generated schemas on IOI). 3) Cancellation Test (synthetic task with opposing position effects).

## Open Questions the Paper Calls Out
None

## Limitations
- Linear approximation in PEAP may not capture non-linear cross-positional interactions
- Schema generation depends heavily on LLM performance with 80% validity threshold
- Manual evaluation limited to only 5 circuits per model-task pair
- Position-aware circuits failed to improve faithfulness on Winobias

## Confidence

**High Confidence:** Cross-positional edge attribution mechanism is well-supported (Mechanism 1).

**Medium Confidence:** Schema-based aggregation shows promise but has task-specific limitations (Mechanism 2).

**Low Confidence:** Saliency-guided schema generation has weakest support due to limited manual evaluation and Winobias failure (Mechanism 3).

## Next Checks

1. **Non-linearity Validation:** Design synthetic task with strong non-linear effects across positions; compare PEAP detection accuracy against exact activation patching.

2. **Schema Robustness Test:** Implement stress test with deliberately corrupted schemas to determine minimum validity threshold for reliable circuit discovery.

3. **Winobias Failure Analysis:** Conduct detailed analysis of why position-aware circuits failed on Winobias to determine if this indicates fundamental limitations for certain task types.