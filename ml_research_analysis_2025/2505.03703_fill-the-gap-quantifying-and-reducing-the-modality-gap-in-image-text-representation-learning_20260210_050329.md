---
ver: rpa2
title: 'Fill the Gap: Quantifying and Reducing the Modality Gap in Image-Text Representation
  Learning'
arxiv_id: '2505.03703'
source_url: https://arxiv.org/abs/2505.03703
tags:
- image
- text
- images
- resp
- texts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of the "modality gap" in vision-language
  models (VLMs), where embeddings of images and texts remain separated in the latent
  space despite being trained on paired data. The authors propose both novel measures
  and methods to quantify and reduce this gap.
---

# Fill the Gap: Quantifying and Reducing the Modality Gap in Image-Text Representation Learning

## Quick Facts
- arXiv ID: 2505.03703
- Source URL: https://arxiv.org/abs/2505.03703
- Reference count: 14
- Primary result: Proposed methods (spectral and OT) significantly reduce modality gap, improving cross-modal retrieval performance from 0% to >60% Recall@20 on COCO-PAIRS

## Executive Summary
This work addresses the persistent "modality gap" in vision-language models, where image and text embeddings remain separated in the shared latent space despite being trained on paired data. The authors propose both novel measures and methods to quantify and reduce this gap. They introduce heterogeneity indices (ITR/TIR) to measure retrieval bias and demonstrate that spectral techniques and optimal transport methods can effectively align representations. Experiments show significant improvements in cross-modal retrieval performance, with mean ranks dropping from hundreds to 2-4 and Recall@20 increasing from 0% to over 60% for some models.

## Method Summary
The paper proposes two complementary approaches to reduce the modality gap in vision-language models. The spectral method uses Laplacian eigendecomposition to project image and text embeddings into a shared lower-dimensional space where cross-modally similar items are positioned close together. This involves computing the cross-modal similarity matrix, forming a bipartite graph, and extracting eigenvectors corresponding to the smallest eigenvalues. The optimal transport approach learns a transport plan that minimizes the cost of transforming one modality's distribution into the other while preserving local geometry through Laplacian regularization. Both methods operate on pre-computed embeddings from existing VLMs like CLIP, SigLIP, and LLM2CLIP, and are evaluated on COCO-PAIRS and CC-PAIRS datasets using heterogeneity indices, FID, and recall metrics.

## Key Results
- Spectral methods achieve near-zero cosine distances between aligned image-text pairs (from 0.8 to ~0.2)
- ITR/TIR values drop sharply from >>1 to ~2, indicating reduced same-modality retrieval bias
- Cross-modal retrieval performance improves dramatically: IMR/TMR fall from hundreds to 2-4
- Recall@20 increases from 0% to over 60% for spectral methods on COCO-PAIRS
- 60-120 spectral components are sufficient for optimal performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Spectral embedding using Laplacian eigenvectors reduces modality gap by jointly projecting image and text representations into a shared lower-dimensional space.
- Mechanism: Given image embedding matrix X and text embedding matrix Y, compute cross-modal similarity W = XY^T, form bipartite adjacency matrix A = [[0, W], [W^T, 0]], then extract eigenvectors corresponding to k smallest eigenvalues of the normalized Laplacian L_rw = D^(-1)L. The resulting spectral embeddings position cross-modally similar items close together by construction.
- Core assumption: The eigenvector structure of the cross-modal similarity graph encodes meaningful alignment structure that survives dimensionality reduction.
- Evidence anchors:
  - [abstract] "Spectral techniques use Laplacian matrices to project embeddings into a lower-dimensional space"
  - [section 2.1.1] "Two similar nodes i and j (according to the graph weights) will be represented by two vectors that are close in a low-dimensional embedding space"
  - [corpus] "Post-pre-training for Modality Alignment" (arxiv 2504.12717) confirms modality gap persists in CLIP and requires explicit alignment interventions

### Mechanism 2
- Claim: Optimal transport with Laplacian regularization aligns image and text distributions while preserving local geometry within each modality.
- Mechanism: Learn a transport plan γ that minimizes cost ⟨γ, C⟩ plus regularization terms λ_s Σ S^s_ij ||γx_i - γx_j||² + λ_t Σ S^t_ij ||γ^T y_i - γ^T y_j||², enforcing that similar source points have similar displacements.
- Core assumption: The optimal coupling preserves semantic correspondence (i.e., the transport plan moves each image embedding toward its semantically related text, not arbitrary texts).
- Evidence anchors:
  - [abstract] "optimal transport enforces regularization constraints to align distributions"
  - [section 2.1.2] "allows to enforce two constraints on the positions and the displacements of source points so that similar source points have similar displacements"

### Mechanism 3
- Claim: Heterogeneity indices (ITR/TIR) quantify modality-specific retrieval bias by measuring cross-modal nearest-neighbor ratios.
- Mechanism: For image queries, count how often the nearest neighbor is another image (i_i_n_ids) vs. a text (i_t_n_ids); ITR = |i_i_n_ids| / |i_t_n_ids|. Values >> 1 indicate strong same-modality bias.
- Core assumption: In a well-aligned space, nearest-neighbor modality should be approximately random (ITR ≈ 1) given balanced corpora.
- Evidence anchors:
  - [abstract] "evaluation metrics such as heterogeneity indices (ITR, TIR)... to assess alignment quality"
  - [section 2.2.2] "ITR (resp. TIR) assesses to what extent an image query (resp. text query) is biased towards retrieving image results"

## Foundational Learning

- Concept: **Laplacian Eigenmaps / Spectral Clustering**
  - Why needed here: The spectral method directly applies Laplacian eigendecomposition; understanding why smallest non-zero eigenvectors capture cluster structure is essential.
  - Quick check question: Why does the Fiedler vector (second-smallest eigenvector) partition a graph?

- Concept: **Optimal Transport / Earth Mover's Distance**
  - Why needed here: The OT method frames alignment as moving probability mass from image distribution to text distribution.
  - Quick check question: What does the transport plan γ(i,j) represent, and why does entropic regularization make optimization tractable?

- Concept: **Contrastive Learning Objective (CLIP-style)**
  - Why needed here: The modality gap originates from contrastive training dynamics; understanding the loss explains why the gap exists.
  - Quick check question: Why does contrastive loss with separate encoders not guarantee perfect cross-modal alignment?

## Architecture Onboarding

- Component map: X (image embeddings) -> W = XY^T -> A = [[0,W],[W^T,0]] -> L = D-A -> eigendecomposition -> F (spectral embeddings) OR C (cost matrix) -> OT with regularization -> γ (transport plan) -> transformed embeddings
- Critical path:
  1. Extract embeddings from target VLM (CLIP, SigLIP, LLM2CLIP)
  2. Compute cross-modal similarity W = XY^T
  3. For spectral: truncated eigendecomposition (k=60-120 components sufficient per Table 5)
  4. For OT: tune λ_s, λ_t via grid search on held-out subset (paper used 5000 pairs from COCO)

- Design tradeoffs:
  - Spectral: O(n³) full eigendecomposition; truncated methods reduce to O(n·k²). No training required, but requires recomputation when data changes.
  - OT: Requires training transport plan; better generalization to new data once trained, but hyperparameter-sensitive.
  - Dimensionality: Paper shows 60-120 spectral components sufficient; fewer dimensions trade recall for speed.

- Failure signatures:
  - ITR/TIR >> 1 after transformation: alignment failed
  - Recall@K near 0: wrong texts brought closer to images (semantic drift)
  - FID reduction without recall improvement: distributions overlap but correspondences lost

- First 3 experiments:
  1. Reproduce Figure 3: Plot cosine distance distributions for original vs. spectral (k=60) embeddings on COCO-PAIRS; verify mean distance drops toward zero.
  2. Compute ITR/TIR on original CLIP embeddings vs. spectral (k=120): Confirm ITR drops from +∞ (Table 2) to ~2.
  3. Recall@10 comparison: Original vs. spectral (k=60) on CC-PAIRS; target improvement from 0 to ~0.6 (per Table 5).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can more advanced algorithms be developed to reduce the high time complexity of computing spectral embeddings, specifically the eigenvector decomposition of the Laplacian matrix?
- Basis in paper: [explicit] The conclusion explicitly lists "using more advanced algorithms for the computation of spectral embeddings" as a direction for future work to address the main limitation of high time complexity.
- Why unresolved: While the paper notes that truncated eigenvalue decomposition helps, the fundamental computational cost of spectral methods remains a bottleneck for large-scale application compared to the optimal transport or raw methods.
- What evidence would resolve it: A comparative study implementing approximate spectral techniques (e.g., Nystrom method, randomized SVD) that demonstrates significantly reduced runtime while preserving the near-zero cosine distances and high recall achieved by the standard spectral method.

### Open Question 2
- Question: How can the proposed heterogeneity indices (ITR, TIR) and distribution-based evaluation measures be made more robust for diverse real-world datasets?
- Basis in paper: [explicit] The conclusion states that "making statistical measures more robust" is a direction for extending the investigation.
- Why unresolved: The current metrics are demonstrated on specific datasets (COCO-PAIRS, CC-PAIRS), but their sensitivity to dataset size, modality imbalance, or varying semantic complexities is not fully characterized.
- What evidence would resolve it: A theoretical analysis or empirical benchmark showing that the proposed metrics provide consistent and statistically significant evaluations across datasets with varying sizes and class distributions.

### Open Question 3
- Question: Can the proposed spectral and optimal transport alignment methods be adapted to handle out-of-sample data points inductively without recomputing the entire embedding transformation?
- Basis in paper: [inferred] The method description for spectral techniques (Section 2.1.1) involves forming an adjacency matrix from the full dataset ($X$ and $Y$) to compute eigenvectors, implying a transductive setting.
- Why unresolved: Practical multimodal retrieval systems must index new data continuously. If the alignment transformation requires the presence of all other points (transductive), it creates a significant computational hurdle for dynamic databases.
- What evidence would resolve it: The derivation of an out-of-sample extension for the spectral embedding (e.g., using a learned subspace or projection matrix) that allows new image-text pairs to be aligned efficiently without re-running the decomposition on the full corpus.

## Limitations

- High computational complexity: Spectral methods require O(n³) eigendecomposition for full datasets, limiting scalability
- Hyperparameter sensitivity: Optimal transport performance depends heavily on regularization parameters that require careful tuning
- Transductive nature: Both methods require the full dataset for transformation, making them impractical for dynamic indexing without extensions

## Confidence

- High confidence: The quantification framework (ITR/TIR, FID) and retrieval metrics are standard and well-defined
- Medium confidence: The spectral method's mathematical formulation is clear, but practical implementation details (sparse vs. dense eigendecomposition) affect results
- Medium confidence: OT method's effectiveness depends heavily on regularization hyperparameters that are not fully specified
- Low confidence: Claims about generalization to new data without retraining are not thoroughly validated

## Next Checks

1. **Baseline Sensitivity Analysis**: Run the spectral method with k=20, 60, and 120 components on COCO-PAIRS; verify that performance peaks around k=60-120 as claimed, and that ITR/TIR values follow the reported pattern.

2. **Hyperparameter Ablation for OT**: Implement the Laplacian-regularized OT method and systematically vary λ_s, λ_t, and η; confirm that performance degrades significantly when regularization is too strong or too weak.

3. **Modality Gap Persistence Test**: Apply both methods to a model known to have minimal modality gap (e.g., a model already post-trained for alignment) and verify that ITR/TIR values remain near 1, demonstrating that the methods don't introduce artificial alignment.