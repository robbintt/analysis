---
ver: rpa2
title: 'AndroidGen: Building an Android Language Agent under Data Scarcity'
arxiv_id: '2504.19298'
source_url: https://arxiv.org/abs/2504.19298
tags:
- task
- agent
- arxiv
- android
- click
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents AndroidGen, a framework designed to build an
  Android language agent under data scarcity. The key challenges addressed include
  the need for high-quality data sources, complex task data collection, and effective
  data filtration.
---

# AndroidGen: Building an Android Language Agent under Data Scarcity

## Quick Facts
- arXiv ID: 2504.19298
- Source URL: https://arxiv.org/abs/2504.19298
- Reference count: 29
- Primary result: AndroidGen builds Android agents without manually labeled data using automated data collection and evaluation

## Executive Summary
AndroidGen addresses the challenge of building Android language agents in data-scarce environments by introducing a framework that leverages automated data collection and evaluation. The framework consists of four core modules: ExpSearch for in-context learning from completed trajectories, ReflectPlan for self-reflection and plan updates, AutoCheck for operation validity verification, and StepCritic for fine-grained trajectory evaluation. By collecting trajectories from human tasks and training open-source LLMs, AndroidGen achieves robust Android agent performance without the need for manually labeled data.

## Method Summary
AndroidGen introduces a novel approach to building Android agents under data scarcity by leveraging automated data collection and evaluation. The framework uses ExpSearch to learn from completed trajectories, ReflectPlan to update plans through self-reflection, AutoCheck to verify operation validity, and StepCritic to evaluate trajectories at a fine-grained level. This modular design allows the framework to collect high-quality data from human tasks and train open-source LLMs effectively. The approach eliminates the need for manually labeled data, making it scalable and adaptable to various Android tasks.

## Key Results
- Significant improvements in task completion rates on benchmarks like AndroidWorld and AitW
- Robust Android agent performance without manually labeled data
- Demonstrates potential as a versatile tool for mobile application tasks

## Why This Works (Mechanism)
AndroidGen works by addressing the core challenges of data scarcity in Android agent development through automated data collection and evaluation. The framework leverages in-context learning from completed trajectories, self-reflection for plan updates, and fine-grained evaluation to ensure high-quality data. This approach allows the system to train open-source LLMs effectively without relying on manually labeled data, making it scalable and adaptable to diverse Android tasks.

## Foundational Learning
- **In-context learning**: Why needed - to leverage completed trajectories for training; Quick check - verify if the model can generalize from few examples
- **Self-reflection mechanisms**: Why needed - to improve plan accuracy through iterative updates; Quick check - test if reflection leads to better task completion
- **Fine-grained evaluation**: Why needed - to ensure high-quality data collection; Quick check - measure improvement in data quality metrics
- **Automated data collection**: Why needed - to eliminate reliance on manual labeling; Quick check - compare data volume and quality with manual methods
- **Operation validity verification**: Why needed - to ensure actions are executable on Android devices; Quick check - test success rate of verified operations

## Architecture Onboarding

**Component Map:** ExpSearch -> ReflectPlan -> AutoCheck -> StepCritic

**Critical Path:** The critical path involves ExpSearch collecting trajectories, ReflectPlan updating plans, AutoCheck verifying operations, and StepCritic evaluating trajectories. This sequence ensures high-quality data collection and evaluation.

**Design Tradeoffs:** The framework prioritizes automated data collection and evaluation over manual labeling, trading off potential edge case coverage for scalability. The modular design allows flexibility but may introduce complexity in integration.

**Failure Signatures:** Potential failures include biases in automated data collection, missed edge cases, and limitations in self-reflection mechanisms. The framework may struggle with tasks requiring nuanced human judgment or dynamic environments.

**3 First Experiments:**
1. Test ExpSearch on a small set of completed trajectories to validate in-context learning effectiveness.
2. Evaluate ReflectPlan’s ability to improve task completion through iterative updates.
3. Assess AutoCheck’s accuracy in verifying operation validity across diverse Android tasks.

## Open Questions the Paper Calls Out
None

## Limitations
- Reliance on automated data collection may introduce biases or miss edge cases.
- Effectiveness of self-reflection and plan update mechanisms is not fully validated.
- Limited discussion of generalizability to new, unseen tasks.

## Confidence

**High Confidence:** Core claim that AndroidGen builds a robust Android agent without manually labeled data is supported by experimental results.

**Medium Confidence:** Claim of versatility for mobile application tasks is plausible but generalizability is uncertain.

**Low Confidence:** Assertion of easy adaptability to new tasks is speculative without broader validation.

## Next Checks
1. Evaluate AndroidGen on diverse Android tasks outside original benchmarks to assess adaptability.
2. Conduct manual inspection of collected trajectories to identify potential biases or missed edge cases.
3. Perform user studies to measure usability and satisfaction in real-world scenarios.