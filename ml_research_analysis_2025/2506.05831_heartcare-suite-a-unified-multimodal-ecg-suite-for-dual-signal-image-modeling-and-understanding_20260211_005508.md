---
ver: rpa2
title: 'Heartcare Suite: A Unified Multimodal ECG Suite for Dual Signal-Image Modeling
  and Understanding'
arxiv_id: '2506.05831'
source_url: https://arxiv.org/abs/2506.05831
tags:
- signal
- multimodal
- report
- data
- diagnosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Heartcare Suite introduces a unified ECG framework for multimodal
  signal-image modeling, addressing limitations in existing Med-MLLMs for cardiac
  data. It includes Heartcare-400K, a large-scale fine-grained ECG instruction dataset,
  and Heartcare-Bench, a comprehensive benchmark for evaluating clinical reasoning
  and cross-modal understanding.
---

# Heartcare Suite: A Unified Multimodal ECG Suite for Dual Signal-Image Modeling and Understanding

## Quick Facts
- arXiv ID: 2506.05831
- Source URL: https://arxiv.org/abs/2506.05831
- Reference count: 40
- HeartcareGPT-7B achieves state-of-the-art performance with 83.42% accuracy on closed-QA, 72.94 F1-Bio on open-QA, and 77.23% on comparison-QA

## Executive Summary
Heartcare Suite introduces a unified multimodal framework for ECG understanding that jointly models both raw signals and corresponding images within a shared autoregressive architecture. The system addresses key limitations in existing medical multimodal large language models by introducing Heartcare-400K, a large-scale instruction dataset, and Heartcare-Bench, a comprehensive evaluation benchmark. At its core, HeartcareGPT employs a Dual Stream Projection Alignment (DSPA) paradigm with a structure-aware discrete tokenizer (Beat) to enable cross-modal reasoning and generation tasks across five clinical scenarios including diagnosis, report generation, and signal prediction.

## Method Summary
The method employs a three-stage training pipeline: first training a dual-level vector quantization tokenizer (Beat) on PTB-XL data to discretize ECG signals, then warming up modality-specific projectors through captioning tasks, and finally joint fine-tuning on the Heartcare-400K instruction dataset. The DSPA mechanism uses separate signal and image encoders that project into a shared feature space through modality-specific MLPs before concatenation with text tokens. HeartcareGPT supports both Phi-3-Mini-4K-Instruct (3.8B) and Qwen2.5-7B-Instruct backbones with LoRA adaptation, enabling efficient fine-tuning while preserving pretrained knowledge.

## Key Results
- HeartcareGPT-7B achieves 83.42% accuracy on closed-QA tasks, 72.94 F1-Bio and 36.85 Rouge-L on open-QA, and 77.23% on comparison-QA
- Ablation studies confirm the necessity of dual-form modeling, with 15-35% accuracy drops when omitting key components
- Expert evaluations demonstrate high clinical utility across report generation, signal prediction, and multimodal understanding tasks

## Why This Works (Mechanism)

### Mechanism 1: Dual Stream Projection Alignment (DSPA)
- Claim: Independent expert projections prevent shallow-layer parameter interference between signal and image modalities.
- Mechanism: Signal embeddings $\mathcal{F}_S$ and image embeddings $\mathcal{F}_V$ are separately projected via $\Psi_{sig}$ and $\Psi_{img}$, then concatenated with text into a unified autoregressive sequence with conditional tokens.
- Core assumption: Modality-specific distortions in shared early layers harm cross-modal semantic grounding.
- Evidence anchors: DSPA enables joint optimizing and modeling native ECG signal-image within a shared feature space; ablation shows 15-35% accuracy drops when omitting warmup.

### Mechanism 2: Beat Tokenizer with Dual-Level Vector Quantization (DVQ)
- Claim: Hierarchical VQ preserves both global rhythm and local waveform semantics during signal tokenization.
- Mechanism: Core codebook $C_1$ captures coarse rhythm; residual codebook $C_2$ refines local morphology via joint supervision balancing reconstruction and prediction losses.
- Core assumption: Clinical semantics are distributed across global temporal patterns and fine-grained beat morphology.
- Evidence anchors: Table 18 shows DVQ-512-1000 achieves lowest total loss (0.76) with 96.22% codebook utilization.

### Mechanism 3: Three-Stage Training Pipeline
- Claim: Staged optimization (Beat → warmup → joint) stabilizes multimodal alignment before LLM fine-tuning.
- Mechanism: Stage 1 trains Beat for signal fidelity; Stage 2 freezes LLM and trains projectors; Stage 3 unfreezes LLM for end-to-end instruction tuning.
- Core assumption: Early-stage joint training causes catastrophic feature distortion across heterogeneous modalities.
- Evidence anchors: Figure 4 and Table 10-13 show 15-35% accuracy drops when omitting Beat training or warmup.

## Foundational Learning

- **Vector Quantization (VQ-VAE style)**:
  - Why needed here: Beat uses dual-level VQ to discretize continuous ECG signals into LLM-compatible tokens.
  - Quick check question: Can you explain how residual codebooks refine quantization error iteratively?

- **Autoregressive Language Modeling**:
  - Why needed here: HeartcareGPT generates diagnoses and reports via next-token prediction conditioned on multimodal embeddings.
  - Quick check question: How does cross-entropy loss apply when inputs include non-text token sequences?

- **LoRA (Low-Rank Adaptation)**:
  - Why needed here: Enables parameter-efficient domain adaptation while preserving pretrained LLM knowledge.
  - Quick check question: What rank and alpha values are typical for medical domain fine-tuning?

## Architecture Onboarding

- **Component map**:
  Raw ECG signal -> Beat encoder (patchify → Transformer encoder → DVQ) -> discrete tokens
  ECG image -> SigLIP encoder -> visual tokens
  Text instruction -> LLM backbone -> unified autoregressive sequence
  Projectors (1-layer MLP signal, 2-layer MLP image) -> concatenated multimodal embedding

- **Critical path**:
  1. Train Beat on PTB-XL with total loss = λ₁L_recon + λ₂L_pred + λ₃L_VQ (λ = 1.0, 0.5, 0.25)
  2. Warm up projectors with captioning task (LR=2e-4, batch=16)
  3. Joint fine-tune on Heartcare-400K with LoRA (LR=2e-5, dropout=0.05)

- **Design tradeoffs**:
  - Codebook size 512 vs. 1024: 512 avoids codebook collapse; 1024 has lower utilization (79.5%)
  - Input length 1000 vs. 1500: 1500 increases loss (1.10); 500 underutilizes context
  - Tri-modal (signal+image+text) vs. single-modality: Ablation shows 8-15% accuracy gain from fusion

- **Failure signatures**:
  - Codebook collapse: Code% < 80% indicates underutilized embeddings
  - Cross-modal misalignment: Closed-QA accuracy < 60% suggests projector warmup failure
  - Signal fidelity loss: Reconstruction MSE > threshold indicates Beat undertraining

- **First 3 experiments**:
  1. Beat ablation: Train with/without DVQ, codebook sizes {256, 512, 1024}, input lengths {500, 1000, 1500}. Monitor Code% and total loss.
  2. Training stage ablation: Skip Beat training, skip warmup, or skip both. Measure Closed-QA accuracy and Open-QA F1-Bio.
  3. Modality fusion ablation: Compare signal-only, image-only, signal+image (no segmentation), and full tri-modal. Evaluate across Heartcare-Bench S/I/C splits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the DSPA and Beat tokenization framework generalize effectively to other high-frequency physiological signals (e.g., EEG, EMG) beyond ECG?
- Basis in paper: The authors state their method establishes "a methodological foundation for extending Med-MLLMs toward physiological signal domains."
- Why unresolved: The current work is validated solely on ECG data; the structural and frequency characteristics of other biosignals differ, and the dual signal-image representation is unique to ECG.
- What evidence would resolve it: Demonstrating successful adaptation of HeartcareGPT's components to another physiological modality, with comparable performance on signal reconstruction and clinical QA tasks specific to that modality.

### Open Question 2
- Question: What are the trade-offs between tokenization fidelity and computational efficiency in Beat, and is there an optimal configuration for resource-constrained clinical settings?
- Basis in paper: The ablation study on Beat explores codebook size and input length, but the paper notes potential "signal fidelity loss in tokenization" as a limitation.
- Why unresolved: The paper does not systematically analyze the Pareto frontier between reconstruction quality (MSE), codebook utilization, and inference latency.
- What evidence would resolve it: A detailed study measuring reconstruction error, token sequence length, and inference time across different Beat configurations, especially on edge devices.

### Open Question 3
- Question: How can Heartcare-400K and Heartcare-Bench be extended to better represent rare cardiac conditions and diverse patient populations?
- Basis in paper: The limitations section acknowledges "dataset biases (e.g., underrepresentation of rare conditions)."
- Why unresolved: The dataset, while large, may not provide sufficient supervision for rare pathologies, potentially limiting model reliability on uncommon cases.
- What evidence would resolve it: An expanded dataset with stratified sampling of rare conditions, followed by evaluation showing improved model performance on those specific classes without regression on common ones.

## Limitations

- Proprietary hospital PDF data (12,170 reports) used in Heartcare-400K cannot be publicly verified, creating a reproducibility gap
- Key architectural hyperparameters for Beat (query counts, patch sizes, encoder/decoder depths) remain unspecified
- Claims about state-of-the-art performance lack comparison with contemporaneous multimodal ECG models published after submission

## Confidence

**High Confidence**: The core performance claims on Heartcare-Bench are well-supported by presented ablation studies and comparison with baselines.

**Medium Confidence**: The Beat tokenizer's dual-level vector quantization design is theoretically sound and empirically validated within the paper's controlled setting, but cross-dataset generalization remains unproven.

**Low Confidence**: Claims about HeartcareGPT-7B achieving "state-of-the-art" performance lack comparison with contemporaneous multimodal ECG models published after the paper's submission.

## Next Checks

1. **Cross-dataset generalization test**: Evaluate HeartcareGPT on publicly available multimodal ECG datasets (MIMIC-IV-ECG, MEETI) to verify performance stability across different hospital systems and acquisition protocols.

2. **Component ablation under standardized conditions**: Systematically test the necessity of each architectural component (DVQ levels, projector MLP depth, projection alignment) using a consistent training protocol and fixed evaluation dataset to isolate true contribution effects.

3. **Clinical workflow integration assessment**: Deploy the model in a simulated clinical environment with domain experts performing real-time annotation and decision-making tasks, measuring both technical performance and clinical workflow impact through standardized usability metrics.