---
ver: rpa2
title: 'ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language
  Models'
arxiv_id: '2504.06838'
source_url: https://arxiv.org/abs/2504.06838
tags:
- accuracy
- number
- queries
- train
- validation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ZIP, a zeroth-order optimization-based prompt
  tuning method for black-box vision-language models. The key idea is to reduce the
  dimensionality of prompts and the variance of gradient estimates by reparameterizing
  prompts in low-rank representations and clipping gradients based on problem dimensionality.
---

# ZIP: An Efficient Zeroth-order Prompt Tuning for Black-Box Vision-Language Models

## Quick Facts
- **arXiv ID:** 2504.06838
- **Source URL:** https://arxiv.org/abs/2504.06838
- **Reference count:** 40
- **Primary result:** ZIP achieves approximately 6% improvement in few-shot accuracy and 48% improvement in query efficiency compared to the best alternative black-box prompt tuning methods across 13+ vision-language tasks.

## Executive Summary
This paper introduces ZIP, a zeroth-order optimization method for prompt tuning in black-box vision-language models. The key innovation lies in combining low-rank prompt reparameterization with dimensionality-aware gradient clipping to simultaneously reduce prompt dimensionality and stabilize gradient estimates. ZIP establishes a new state of the art in black-box vision-language prompt tuning, demonstrating significant improvements in both accuracy (approximately 6%) and query efficiency (48%) across a diverse set of 13+ vision-language tasks.

## Method Summary
ZIP addresses the challenges of black-box vision-language prompt tuning by introducing two key mechanisms: low-rank reparameterization of prompts and gradient clipping based on problem dimensionality. The low-rank representation reduces the effective dimensionality of the prompt space, making optimization more efficient. The gradient clipping mechanism is specifically designed to account for the reduced dimensionality, helping to stabilize the zeroth-order gradient estimates. These innovations work together to improve both the accuracy and query efficiency of prompt tuning in black-box settings.

## Key Results
- ZIP achieves approximately 6% improvement in few-shot accuracy over the best alternative black-box prompt tuning methods
- ZIP demonstrates 48% improvement in query efficiency across evaluated tasks
- ZIP establishes new state-of-the-art performance on 13+ vision-language tasks

## Why This Works (Mechanism)
ZIP works by addressing two fundamental challenges in black-box prompt tuning: high-dimensional prompt spaces and noisy gradient estimates. The low-rank reparameterization compresses the prompt into a lower-dimensional space, reducing the complexity of the optimization problem. The dimensionality-aware gradient clipping then stabilizes the zeroth-order gradient estimates by accounting for the reduced problem dimensionality. This combination allows for more efficient exploration of the prompt space while maintaining stable optimization dynamics, leading to better performance with fewer queries.

## Foundational Learning
- **Zeroth-order optimization**: Needed to understand the optimization framework used for black-box models where gradients are not directly accessible. Quick check: Can you explain how zeroth-order methods estimate gradients using only function evaluations?
- **Prompt tuning**: Essential for understanding how language model prompts are optimized for vision-language tasks. Quick check: What distinguishes prompt tuning from full fine-tuning of vision-language models?
- **Low-rank matrix factorization**: Critical for understanding the reparameterization technique that reduces prompt dimensionality. Quick check: How does low-rank factorization help reduce the number of parameters while preserving expressiveness?
- **Variance reduction in gradient estimates**: Important for understanding why ZIP's gradient clipping improves optimization stability. Quick check: Why do zeroth-order gradient estimates typically have high variance, and how does clipping help?

## Architecture Onboarding
- **Component map**: User query -> Vision-language model (black-box) -> Prompt optimization (ZIP with low-rank reparameterization and gradient clipping) -> Optimized prompt
- **Critical path**: Input prompt -> Low-rank parameterization -> Zeroth-order gradient estimation -> Dimensionality-aware clipping -> Prompt update -> Evaluation
- **Design tradeoffs**: ZIP trades computational overhead in prompt generation (due to reparameterization and clipping) for improved optimization efficiency and stability
- **Failure signatures**: If the low-rank dimension is too small, prompts may lose expressiveness; if gradient clipping is too aggressive, optimization may become overly conservative
- **First experiments**: 1) Ablation study comparing low-rank reparameterization with/without gradient clipping, 2) Sensitivity analysis of low-rank dimension on performance, 3) Comparison of query efficiency against standard zeroth-order methods

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation primarily focused on image classification and visual question answering tasks, with unclear effectiveness on other vision-language tasks like image captioning
- Comparison framework is limited to black-box settings without exploring performance against white-box methods
- Computational overhead of reparameterization and clipping mechanisms during prompt generation is not thoroughly analyzed

## Confidence
- **High confidence**: ZIP's core algorithmic contributions (low-rank reparameterization and dimensionality-aware gradient clipping) are well-justified theoretically and demonstrate consistent improvements across evaluated tasks
- **Medium confidence**: The 48% query efficiency improvement claim, as this metric depends on specific baseline choices and stopping criteria
- **Medium confidence**: The generalization claim across "13+ vision-language tasks" since the specific diversity and difficulty distribution isn't fully characterized

## Next Checks
1. Test ZIP's performance on non-classification vision-language tasks (e.g., image captioning, visual grounding) to assess broader applicability
2. Conduct ablation studies specifically isolating the contributions of low-rank reparameterization versus gradient clipping
3. Measure and report wall-clock time overhead of ZIP's additional computational steps compared to baseline methods