---
ver: rpa2
title: 'CleanCTG: A Deep Learning Model for Multi-Artefact Detection and Reconstruction
  in Cardiotocography'
arxiv_id: '2508.10928'
source_url: https://arxiv.org/abs/2508.10928
tags:
- signal
- noise
- reconstruction
- segments
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CleanCTG is an end-to-end deep learning model that detects and
  reconstructs multiple artefact types in cardiotocography (CTG) signals. It combines
  multi-scale convolutional feature extraction, context-aware cross-attention, artefact-specific
  correction branches, and position-wise attention reconstruction.
---

# CleanCTG: A Deep Learning Model for Multi-Artefact Detection and Reconstruction in Cardiotocography

## Quick Facts
- arXiv ID: 2508.10928
- Source URL: https://arxiv.org/abs/2508.10928
- Reference count: 40
- Key outcome: Achieved AU-ROC = 1.00 for artefact detection on synthetic CTGs, AU-ROC = 0.95 on clinician-annotated segments, and improved Dawes-Redman normality detection specificity from 80.70% to 82.70%

## Executive Summary
CleanCTG is a deep learning model designed to detect and reconstruct multiple artefact types in cardiotocography (CTG) signals. The model combines multi-scale convolutional feature extraction, context-aware cross-attention, artefact-specific correction branches, and position-wise attention reconstruction. Trained on synthetic data, it achieved perfect artefact detection (AU-ROC = 1.00) and low reconstruction error (MSE = 2.74 x 10⁻⁴ for corrupted segments) on synthetic CTGs. External validation on clinician-annotated segments yielded AU-ROC = 0.95 with sensitivity of 83.44% and specificity of 94.22%. When integrated with the Dawes-Redman system on 933 clinical recordings, it increased normality detection specificity from 80.70% to 82.70% and reduced median time to decision by 33%.

## Method Summary
CleanCTG employs a modular architecture that first detects artefacts in 1-minute CTG segments using dual CNN encoders (one for local 1-minute windows, one for global 10-minute context) with cross-attention fusion. The detection head uses class-specific attention pooling followed by multi-label sigmoid classification for five artefact types. Based on detection results, the model routes signals to artefact-specific reconstruction branches: deterministic mathematical correction for halving/doubling artefacts, and Transformer-based generative reconstruction for missing segments, MHR, and spikes. A final position-wise attention layer selects between original and reconstructed signals at each time step to preserve clean signal regions.

## Key Results
- Achieved perfect artefact detection (AU-ROC = 1.00) on synthetic CTGs with low reconstruction error (MSE = 2.74 x 10⁻⁴ for corrupted segments)
- External validation on clinician-annotated segments yielded AU-ROC = 0.95 (sensitivity = 83.44%, specificity = 94.22%)
- Integrated with Dawes-Redman system on 933 clinical recordings: increased normality detection specificity from 80.70% to 82.70% and reduced median time to decision by 33%

## Why This Works (Mechanism)

### Mechanism 1: Context-Aware Cross-Attention for Disambiguation
The model uses cross-attention between 1-minute encoded features and 10-minute encoded features, enabling it to distinguish local ambiguous patterns by referencing global signal characteristics. This allows differentiation between artefacts (local inconsistencies) and physiological variations by checking surrounding baseline stability. Performance degrades when context is removed, validating this mechanism.

### Mechanism 2: Hierarchical Gating with Artefact-Specific Physics
A 2-stage gating process routes signals to artefact-specific branches: deterministic mathematical correction for halving/doubling artefacts (applying ×2 or ×0.5 factors) versus learned generative reconstruction for other noise types. Ablation studies show replacing mathematical branches with transformers increases MSE from 2.74 x 10⁻⁴ to 6.65 x 10⁻⁴, confirming the need for physics-based corrections.

### Mechanism 3: Position-Wise Attention for Selective Preservation
The final layer uses position-wise attention to select between original input and reconstruction branch outputs at every time step. This acts as a switch, defaulting to the original signal where no artefact is detected, preventing the introduction of hallucinated noise into clean areas. Clean segments achieve MSE = 2.40 x 10⁻⁶, comparable to or better than U-Net.

## Foundational Learning

- **Concept:** Multi-head Self-Attention & Cross-Attention
  - **Why needed here:** The model relies on splitting the input into Query/Key/Value to mix local (1-min) and global (10-min) features. You cannot understand the "Context-Aware" component without grasping how attention weights calculate relevance between two sequences.
  - **Quick check question:** How does the Query vector from the 1-minute segment interact with the Key/Value vectors from the 10-minute context to determine if a spike is an artefact?

- **Concept:** Multi-label Sigmoid Classification
  - **Why needed here:** CTG segments often contain multiple simultaneous artefacts (e.g., a missing segment and a spike). Standard Softmax (multi-class) would force the model to pick only one; Sigmoid allows independent probabilities for each artefact type.
  - **Quick check question:** Why does the model output 5 independent probabilities per segment rather than a single probability distribution summing to 1?

- **Concept:** Signal-to-Noise Ratio (SNR) in Time Series
  - **Why needed here:** The paper emphasizes that high noise levels (up to 50% corruption) obscure fetal patterns. Understanding that "clean" features are low-amplitude variations buried under high-amplitude noise (spikes) helps rationalize the use of multi-scale CNNs to extract sharp features.
  - **Quick check question:** Why would a simple moving average filter fail to remove "doubling" artefacts while preserving the true fetal heart rate variability?

## Architecture Onboarding

- **Component map:**
  1. Dual Encoder: Two separate CNN+Transformer pipelines (1-min High Res, 10-min Low Res/Global)
  2. Cross-Attention Block: Fuses local queries with global keys/values
  3. Detection Head: Class-specific attention pooling → MLP → 5x Binary Gates
  4. Reconstruction Branches: Mathematical Correction for Halving/Doubling, Transformer-based for Missing/MHR/Spike
  5. Position-wise Gating: Final softmax mixer selecting between Original Signal vs. Reconstructed Signal per timepoint

- **Critical path:**
  Input → Dual CNNs → Cross-Attention → Detection Gate (If Gate=0, stop; If Gate=1, route to branch) → Reconstruction Branch → Position Mixer → Output

- **Design tradeoffs:**
  - Synthetic Training: Model trained on synthetic noise (800k mins) due to lack of clinical ground-truth "clean" signals for high-corruption segments
  - Risk: Domain shift evidenced by performance drop for spike detection (AU-ROC 1.00 → 0.77) in clinical validation
  - Modularity vs. End-to-End: Chose detect-then-correct approach over autoencoder to enforce physical constraints (halving/doubling logic), sacrificing unsupervised learning benefits for reliability

- **Failure signatures:**
  - Over-smoothing: Position-wise Attention failure may smooth out genuine accelerations, leading to false negatives in Dawes-Redman analysis
  - Gate Stuck Closed: Low sensitivity (e.g., for Spikes) disables reconstruction branch, allowing raw noise to pass through
  - Confusion of MHR vs. Bradycardia: Model distinguishes these but brief accelerations misclassified as spikes could delay "normality" criteria

- **First 3 experiments:**
  1. Unit Test Math Branches: Inject pure "Doubling" artefact into synthetic sine wave; verify Mathematical Correction Branch outputs exactly 0.5 × input at specified indices
  2. Context Ablation: Run on clinical segment with subtle deceleration; ablate 10-minute context encoder (feed zeros); check if model falsely flags deceleration as "Missing" or "Spike"
  3. Preservation Test: Feed completely clean segment (no noise); verify Position-wise Attention output is identical to input (MSE ≈ 0), ensuring "Original Signal" branch is selected

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic training dataset may not fully capture real clinical artefact diversity, evidenced by performance drop for spike detection (AU-ROC from 1.00 to 0.77) on external validation
- Model's reliance on 10-minute context windows may limit applicability in clinical settings with shorter recordings or artefacts spanning multiple windows
- Domain adaptation challenges between synthetic and clinical artefacts, with potential difficulty handling organic, messy clinical artefact patterns

## Confidence
- **Detection Performance (AU-ROC = 0.95):** Medium - Strong synthetic validation but significant performance variance across artefact types in clinical data
- **Reconstruction Quality (MSE metrics):** High - Consistent across both synthetic and clinical validation datasets
- **Clinical Integration Benefits:** Medium - Demonstrated improvements in Dawes-Redman analysis but based on retrospective evaluation without prospective clinical trials

## Next Checks
1. **Prospective Clinical Trial:** Evaluate CleanCTG in live clinical setting with blinded assessment of clinician decision-making accuracy and time-to-intervention compared to standard CTG interpretation
2. **Cross-Institutional Validation:** Test model performance on CTG data from multiple hospitals with different acquisition protocols and equipment to assess generalizability
3. **Artifact Realism Assessment:** Compare model performance on synthetic versus real-world artefact patterns in clinical recordings where ground truth artefact boundaries are annotated by multiple independent experts