---
ver: rpa2
title: 'AirCast: Improving Air Pollution Forecasting Through Multi-Variable Data Alignment'
arxiv_id: '2502.17919'
source_url: https://arxiv.org/abs/2502.17919
tags:
- variables
- weather
- forecasting
- quality
- pollution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of air pollution forecasting,
  particularly for particulate matter (PM1, PM2.5, PM10), in the Middle East and North
  Africa (MENA) region, which experiences high pollution levels. The authors propose
  AirCast, a novel multi-variable approach that combines weather and air quality data
  using a Vision Transformer (ViT) architecture.
---

# AirCast: Improving Air Pollution Forecasting Through Multi-Variable Data Alignment

## Quick Facts
- **arXiv ID:** 2502.17919
- **Source URL:** https://arxiv.org/abs/2502.17919
- **Reference count:** 32
- **Primary result:** Multi-variable ViT approach improves PM2.5, PM10, PM1 forecasting in MENA region using weather + air quality data with fMAE loss

## Executive Summary
AirCast addresses air pollution forecasting challenges in the MENA region by combining weather and air quality data through a Vision Transformer architecture. The model introduces a frequency-weighted Mean Absolute Error (fMAE) loss to handle heavy-tailed pollutant distributions and employs multi-task learning to capture interactions between weather patterns and pollution levels. Using a combined ERA5 and CAMS dataset, AirCast achieves significant improvements over baselines, particularly in predicting extreme pollution events. The approach demonstrates that joint weather-pollutant modeling and informed variable selection can substantially enhance forecasting accuracy for particulate matter concentrations.

## Method Summary
AirCast uses a Vision Transformer architecture that processes regridded ERA5 weather data (5.625°) and CAMS air quality data as 2D grids. Each variable undergoes patch tokenization and cross-attention aggregation before ViT encoding. The model employs dual decoder heads for simultaneous weather and air quality forecasting, with independent loss calculation to prevent negative transfer. Key innovations include fMAE loss (β=0.8) for handling heavy-tailed distributions and near-surface variable selection (850-925 hPa, 2m/10m measurements). Training uses random lead times (6, 12, 24 hrs) with evaluation at fixed 24-hour intervals, employing log transforms on air quality variables and ClimaX pre-trained weights.

## Key Results
- fMAE loss reduces RMSE by 4.18% for PM2.5, 3.65% for PM10, and 2.85% for PM1 compared to standard MAE
- Multi-task weather + air quality modeling improves PM2.5 RMSE from 9.80→9.45 and PM10 from 14.96→14.15
- Near-surface variable selection achieves best results: PM2.5 RMSE 8.82 (-6.67%), PM10 13.27 (-6.22%), PM1 6.65 (-8.15%)
- Model demonstrates ability to detect extreme events like dust storms

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Jointly forecasting weather and air quality variables through multi-task learning improves PM prediction accuracy by capturing their physical interactions.
- **Mechanism:** A shared ViT encoder learns cross-variable representations from both weather and pollution inputs. Two separate decoder heads predict weather and air quality outputs respectively, with independent loss calculation to prevent negative transfer. Cross-attention aggregation combines tokens from different variables at matching spatial locations before encoding.
- **Core assumption:** Weather-pollutant correlations (e.g., wind dispersion, temperature inversions) are learnable and benefit from shared representation learning rather than treating them as independent prediction tasks.
- **Evidence anchors:**
  - [abstract] "AirCast employs a multi-task head architecture that simultaneously forecasts atmospheric conditions and pollutant concentrations, improving its understanding of how weather patterns affect air quality."
  - [section 6, Table 2b] Weather + AQ reduces PM2.5 RMSE from 9.80→9.45 and PM10 from 14.96→14.15 compared to AQ alone.
  - [corpus] FuXi-Air and related multi-modal forecasting papers similarly integrate meteorology-pollutant data, supporting the multi-variable approach.
- **Break condition:** If weather variables add noise without causal relationship to local PM dynamics, or if negative transfer occurs despite separate loss heads.

### Mechanism 2
- **Claim:** Frequency-weighted MAE loss improves prediction of rare high-pollution events that standard loss functions underweight.
- **Mechanism:** fMAE computes inverse-frequency weights using Freedman-Diaconis binning (β=0.8). Rare concentration bins receive higher loss weight, forcing the optimizer to focus on underrepresented extreme values rather than overfitting to the dominant low-concentration majority.
- **Core assumption:** Heavy-tailed PM distributions mean standard MAE over-prioritizes frequent low-value predictions at the expense of critical extreme events.
- **Evidence anchors:**
  - [abstract] "To address this, we propose a novel Frequency-weighted Mean Absolute Error (fMAE) loss, adapted from the class-balanced loss for regression tasks."
  - [section 6, Table 2a] fMAE reduces RMSE: PM2.5 (-4.18%), PM10 (-3.65%), PM1 (-2.85%) compared to unweighted MAE.
  - [section 5, Figure 2] PM2.5 distribution shows extreme skew with max frequency 162.9M in low bins versus sparse high-concentration tail.
  - [corpus] Synergistic Neural Forecasting paper similarly addresses episodic pollution spikes, confirming distribution imbalance as a recognized challenge.
- **Break condition:** If extreme events follow fundamentally different physical mechanisms that cannot be learned from available data, weighting alone cannot compensate.

### Mechanism 3
- **Claim:** Selecting near-surface atmospheric variables (high pressure levels: 850-925 hPa, 2m/10m measurements) significantly outperforms using all vertical pressure levels.
- **Mechanism:** PM concentrations are surface-level phenomena. Filtering to near-surface variables removes noise from upper-atmosphere data (50-500 hPa) that has weak direct relevance to ground-level pollution, reducing input dimensionality and focusing model capacity on physically relevant features.
- **Core assumption:** Domain knowledge correctly identifies near-surface conditions as the primary drivers of PM dynamics; upper-level variables contribute minimally or add noise.
- **Evidence anchors:**
  - [abstract] "Informed from domain knowledge, we investigate the selection of key variables known to influence pollution levels."
  - [section 6, Table 2c] Surface Weather + Surface AQ achieves best results: PM2.5 RMSE 8.82 (-6.67%), PM10 13.27 (-6.22%), PM1 6.65 (-8.15%) vs. all-level inputs.
  - [corpus] Limited direct corpus support for this specific variable selection strategy; appears to be a novel contribution of this work.
- **Break condition:** If long-range pollutant transport (e.g., dust from distant sources) relies significantly on upper-atmosphere dynamics, filtering removes predictive signal.

## Foundational Learning

- **Concept: Vision Transformer (ViT) patch tokenization**
  - Why needed here: AirCast represents each input variable as a 2D grid (H×W), which gets split into patches and linearly embedded. Understanding this transformation is essential for debugging input pipeline issues.
  - Quick check question: Given a 32×64 input grid with patch size p=4, how many tokens per variable does tokenization produce?

- **Concept: Class-balanced / frequency-weighted loss**
  - Why needed here: Standard loss functions assume balanced data. PM concentrations are heavily skewed toward low values, so unweighted loss produces models that predict conservatively and miss extremes.
  - Quick check question: If a concentration bin appears 100× more frequently than a rare bin, what approximate weight ratio does β→1 produce?

- **Concept: Multi-task learning and negative transfer**
  - Why needed here: AirCast predicts weather and pollution simultaneously. If gradients from one task contradict the other, performance degrades. Separate loss heads mitigate this.
  - Quick check question: Why compute weather-loss and air-quality-loss independently rather than summing raw outputs before loss calculation?

## Architecture Onboarding

- **Component map:** ERA5 weather + CAMS air quality data → log transform for AQ variables → patch tokenization → cross-attention aggregation → ViT encoder → dual decoder heads (weather + air quality) → fMAE loss
- **Critical path:** Input alignment (spatial/temporal) → log transform for AQ variables → tokenization → aggregation → encoder → dual heads → fMAE loss. Misalignment at the input stage propagates through all downstream components.
- **Design tradeoffs:**
  - Resolution vs. compute: 5.625° (32×64) chosen over 1.4° for training efficiency; finer resolution requires more memory.
  - Coverage vs. focus: Regional cropping (MENA: 8×14 after crop) concentrates capacity but limits geographic generalization.
  - Near-surface vs. all-levels: Fewer variables reduce compute but discard potential upper-atmosphere signal.
- **Failure signatures:**
  - Under-prediction of extremes: fMAE not applied or β too low.
  - Geographic overestimation outside MENA: Model overfits to regional distribution (Figure 5 shows this pattern).
  - Training instability: Log transform skipped for AQ variables causes gradient explosion on high concentrations.
  - Negative transfer between tasks: Single shared loss head instead of separate heads.
- **First 3 experiments:**
  1. **Sanity check with persistence baseline:** Confirm model beats "tomorrow equals today" on held-out 2017 data. If not, check data leakage or input corruption.
  2. **fMAE ablation:** Train with standard MAE vs. fMAE on PM-only inputs. Expect 3-4% RMSE improvement; if absent, verify weight computation and bin construction.
  3. **Variable selection ablation:** Compare all-levels vs. surface-only inputs. If surface-only underperforms, check that surface levels (850, 925 hPa) are correctly extracted from multi-level data.

## Open Questions the Paper Calls Out

- **Open Question 1:** How can AirCast be adapted to improve forecasting accuracy for medium-range lead times beyond 48 hours?
  - Basis in paper: [explicit] The authors state that the current method focuses on "relatively short lead time" and that this work "sets the road for future work that can improve forecasts for longer periods of time."
  - Why unresolved: The current study evaluates performance primarily at 6, 12, 24, and 48-hour intervals, showing an inverse relationship between lead time and accuracy.
  - What evidence would resolve it: A study demonstrating stable RMSE or ACC metrics for PM variables at lead times of 3 to 10 days.

- **Open Question 2:** How does increasing the spatial resolution from 5.625° to higher resolutions (e.g., 1.40525°) affect the model's ability to capture local pollution dynamics?
  - Basis in paper: [inferred] The authors mention regridding data to 5.625° (32x64 pixels) to "balance data granularity and computational efficiency," noting that original data exists at higher resolutions.
  - Why unresolved: The coarse resolution may smooth over local extreme events, limiting the model's utility for localized public health warnings.
  - What evidence would resolve it: A comparison of model performance and computational cost when trained and inferred on the native 0.75° or regridded 1.40525° datasets.

- **Open Question 3:** Can the model generalize effectively to a global scale without significant over-estimation of pollutants in regions outside the MENA training domain?
  - Basis in paper: [inferred] Appendix A.1 shows that when tested on East Asia and North America, the model "slightly over-estimates" concentrations, and the paper notes the model was specifically enhanced for the MENA region's high pollution profile.
  - Why unresolved: The regional adaptation and fMAE loss focus on the heavy-tailed distributions specific to MENA, potentially biasing the model for regions with different pollution profiles.
  - What evidence would resolve it: Quantitative metrics (RMSE, bias) and error maps from a model trained on a global dataset or successfully transferred to other distinct climatic regions.

## Limitations
- Geographic generalization remains problematic with clear overestimation of pollutants outside the MENA training region
- High-resolution data (1.4°) could capture more local pollution dynamics but requires significantly more computational resources
- Limited validation of extreme event detection capabilities beyond qualitative dust storm identification

## Confidence
- **Multi-task learning improves PM forecasting (High):** Strong quantitative results in Table 2b showing consistent RMSE improvements
- **fMAE loss improves extreme event prediction (Medium):** Performance gains demonstrated but effectiveness depends on proper implementation
- **Near-surface variable selection significantly improves performance (Medium):** Results show substantial improvements but lack direct comparative corpus support
- **Model can detect extreme events like dust storms (Low):** Qualitative claim with minimal quantitative validation

## Next Checks
1. **Extreme event detection validation:** Systematically evaluate model performance on dust storm events and other rare pollution episodes using event-specific metrics (precision/recall for threshold exceedances) rather than aggregate RMSE alone.

2. **Geographic generalization test:** Train on MENA data and evaluate on a different polluted region (e.g., East Asia or Europe) to quantify overfitting and identify which mechanisms (variable selection, fMAE) transfer across geographies.

3. **Upper-atmosphere variable contribution analysis:** Conduct ablation studies on specific upper-level variables (e.g., 50 hPa, 250 hPa) to empirically validate whether near-surface selection discards predictive signal, particularly for long-range transport phenomena.