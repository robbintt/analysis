---
ver: rpa2
title: 'SINdex: Semantic INconsistency Index for Hallucination Detection in LLMs'
arxiv_id: '2503.05980'
source_url: https://arxiv.org/abs/2503.05980
tags:
- semantic
- clustering
- similarity
- entropy
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SINdex, a semantic inconsistency index for
  detecting hallucinations in large language models (LLMs). The method leverages semantic
  clustering of multiple LLM-generated responses using sentence embeddings and hierarchical
  agglomerative clustering, followed by computing SINdex as an adjusted entropy measure
  to quantify intra-cluster coherence.
---

# SINdex: Semantic INconsistency Index for Hallucination Detection in LLMs

## Quick Facts
- **arXiv ID:** 2503.05980
- **Source URL:** https://arxiv.org/abs/2503.05980
- **Reference count:** 26
- **Primary result:** Achieves up to 9.3% higher AUROC than semantic entropy across TriviaQA, NQ, SQuAD, and BioASQ datasets

## Executive Summary
SINdex introduces a semantic inconsistency index for detecting hallucinations in large language models by leveraging hierarchical agglomerative clustering of multiple LLM-generated responses. The method computes an adjusted entropy measure that weights cluster proportions by intra-cluster semantic coherence, outperforming state-of-the-art baselines across multiple question-answering datasets. SINdex operates as a black-box method requiring only multiple independent generations per query, making it model-agnostic and easy to implement.

## Method Summary
SINdex generates multiple independent responses (P=10) to a question using an LLM with temperature=1.0, then clusters these responses semantically using sentence embeddings and hierarchical agglomerative clustering. The SINdex is computed as an adjusted entropy measure where cluster proportions are weighted by intra-cluster cosine similarity, creating a coherence-weighted uncertainty score. Higher SINdex values indicate greater semantic inconsistency across responses, suggesting higher hallucination likelihood. The method uses all-MiniLM-L6-v2 embeddings and a 0.95 cosine similarity threshold for clustering.

## Key Results
- Achieves up to 9.3% higher AUROC than semantic entropy baseline
- Outperforms NLI-based baselines (HDNLI, HEDGE) across all tested datasets
- Scales 60× faster than NLI-based methods while maintaining superior detection performance
- Ablation studies show optimal performance with 10 generations per question and 0.95 cosine similarity threshold

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Agglomerative Clustering for Semantic Grouping
Hierarchical agglomerative clustering produces more homogeneous semantic clusters than NLI-based bidirectional clustering by using sentence embeddings and cosine similarity with average linkage to iteratively merge responses, capturing semantic equivalence even when phrasing differs. The core assumption is that sentence embeddings capture semantic equivalence more robustly than NLI entailment predictions, which struggle with negation and nuanced similarity. Break condition: Cosine similarity threshold >0.95 causes over-clustering; threshold <0.90 merges semantically distinct responses.

### Mechanism 2: SINdex as Coherence-Weighted Entropy
SINdex adjusts cluster proportions by intra-cluster cosine similarity, yielding a more accurate hallucination signal than raw semantic entropy. The core assumption is that high intra-cluster semantic coherence indicates model confidence in that meaning, while low coherence amplifies uncertainty signal. Break condition: When clusters have very low coherence, adjusted proportions approach 0, potentially underweighting actual response distributions.

### Mechanism 3: Multi-Generation Sampling for Uncertainty Estimation
Sampling multiple independent responses reveals semantic inconsistency that correlates with hallucination likelihood. The core assumption is that models generate consistent semantics when they "know" the answer; inconsistency reflects epistemic uncertainty. Break condition: P < 6 provides insufficient samples for reliable distribution estimation; computational cost scales as O(P²·d).

## Foundational Learning

- **Concept: Hierarchical Agglomerative Clustering with Linkage Criteria**
  - Why needed here: Core clustering algorithm; average linkage balances single linkage's chaining problem and complete linkage's outlier sensitivity.
  - Quick check question: Why does the paper choose average linkage over single or complete linkage for semantic clustering?

- **Concept: Cosine Similarity in High-Dimensional Embedding Spaces**
  - Why needed here: Fundamental distance metric; length-invariant normalization focuses on semantic direction rather than magnitude.
  - Quick check question: Why is cosine similarity preferred over Euclidean distance for comparing sentence embeddings?

- **Concept: Entropy as Uncertainty Quantification**
  - Why needed here: SINdex builds on entropy; understanding Schur-concavity explains why adjusted entropy ≥ original entropy.
  - Quick check question: What happens to SINdex when all responses fall into a single, highly coherent cluster?

## Architecture Onboarding

- **Component map:** Question → LLM×P → [SEP] concatenation → Embeddings → Cosine matrix → HAC → SINdex → hallucination score

- **Critical path:** Question → LLM×P → [SEP] concatenation → Embeddings → Cosine matrix → HAC → SINdex → hallucination score

- **Design tradeoffs:**
  - P=10: Optimal per ablation; higher P increases cost with diminishing returns
  - Threshold 0.95: High-precision clustering; may over-segment on domains with paraphrastic variation
  - all-MiniLM-L6-v2: Fastest; mpnet-base-v2 offers slightly higher quality at 3× runtime cost
  - Black-box only: No internal states required; cannot leverage token probabilities

- **Failure signatures:**
  - Threshold sensitivity: >0.95 degrades AUROC
  - Long-form answers show lower absolute AUROC than short-form
  - Binary datasets may show artificially inflated AUROC
  - Static threshold may not generalize across domains

- **First 3 experiments:**
  1. Replicate P-ablation on your target domain to verify optimal generation count
  2. Sweep cosine threshold [0.90, 0.92, 0.95, 0.97] on validation data before committing to 0.95
  3. Benchmark all-MiniLM-L6-v2 vs all-mpnet-base-v2 on your data to quantify speed/quality tradeoff

## Open Questions the Paper Calls Out
None

## Limitations
- 0.95 cosine similarity threshold may not generalize across domains with different paraphrastic norms
- Requires 10 generations per query, creating computational overhead that scales quadratically
- Shows better performance on short-form answers compared to longer, more nuanced responses
- Black-box approach cannot leverage internal model states or token-level probabilities

## Confidence

**High Confidence Claims:**
- SINdex outperforms NLI-based baselines on tested datasets
- Clustering mechanism produces more homogeneous semantic groups than NLI-based approaches
- 10 generations per question represents optimal balance between cost and accuracy
- Method scales significantly faster than NLI-based approaches

**Medium Confidence Claims:**
- SINdex generalizes well across different LLM architectures
- All-MiniLM-L6-v2 embeddings provide sufficient quality while maintaining efficiency
- Adjusted entropy formulation meaningfully improves upon raw semantic entropy

**Low Confidence Claims:**
- 0.95 threshold will generalize across all domains without recalibration
- Performance on binary classification tasks directly translates to open-ended QA
- SINdex's advantages remain consistent for non-QA generation tasks

## Next Checks

1. **Domain-Specific Threshold Calibration**: Test the 0.95 cosine similarity threshold across diverse domains (legal, medical, technical) to determine whether a single static threshold is appropriate or if domain-specific calibration is required for optimal performance.

2. **Generation Count Optimization**: Conduct P-ablation studies on your specific application domain to verify whether 10 generations represents the optimal trade-off between detection accuracy and computational cost.

3. **Cross-Task Generalization**: Evaluate SINdex on non-QA generation tasks such as summarization, code generation, and creative writing to determine whether the semantic clustering approach maintains its effectiveness outside of factoid question answering scenarios.