---
ver: rpa2
title: 'fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding'
arxiv_id: '2511.21760'
source_url: https://arxiv.org/abs/2511.21760
tags:
- fmri
- text
- fmri-lm
- language
- brain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: fMRI-LM introduces a foundational model for bridging fMRI and language
  through a three-stage framework. It employs a neural tokenizer to map fMRI into
  discrete tokens aligned with LLM embeddings, then adapts a pretrained LLM to jointly
  model fMRI tokens and synthetic fMRI-text pairs derived from imaging-based features
  (functional connectivity, gradients, ICA, graph metrics).
---

# fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding

## Quick Facts
- arXiv ID: 2511.21760
- Source URL: https://arxiv.org/abs/2511.21760
- Authors: Yuxiang Wei; Yanteng Zhang; Xi Xiao; Chengxuan Qian; Tianyang Wang; Vince D. Calhoun
- Reference count: 40
- Primary result: fMRI-LM achieves strong zero-shot and few-shot performance across seven datasets, outperforming supervised and foundation baselines in classification and regression tasks

## Executive Summary
fMRI-LM introduces a foundational model for bridging fMRI and language through a three-stage framework. It employs a neural tokenizer to map fMRI into discrete tokens aligned with LLM embeddings, then adapts a pretrained LLM to jointly model fMRI tokens and synthetic fMRI-text pairs derived from imaging-based features. Finally, multi-task, multi-paradigm instruction tuning enables diverse downstream applications. Across seven datasets, fMRI-LM demonstrates significant improvements over baseline models in both zero-shot and few-shot settings.

## Method Summary
fMRI-LM employs a three-stage framework to create a universal foundation model for language-aligned fMRI understanding. First, a neural tokenizer maps continuous fMRI signals into discrete tokens aligned with LLM embeddings. Second, a pretrained LLM is adapted to jointly model these fMRI tokens and synthetic fMRI-text pairs generated from imaging features like functional connectivity, gradients, ICA, and graph metrics. Finally, multi-task, multi-paradigm instruction tuning enables the model to perform diverse downstream applications. The approach leverages synthetic data generation and efficient adaptation through LoRA to achieve strong performance across classification and regression tasks while demonstrating robust generalization.

## Key Results
- Achieves up to 94.9% accuracy for sex prediction tasks across seven datasets
- Demonstrates strong zero-shot and few-shot performance, outperforming supervised and foundation baselines
- Shows efficient adaptation with LoRA and robust generalization across diverse tasks and datasets

## Why This Works (Mechanism)
The model's success stems from its innovative three-stage approach that bridges the modality gap between fMRI and language. The neural tokenizer creates a bridge by mapping continuous fMRI signals into discrete tokens that align with LLM embeddings, enabling language models to process brain imaging data. The synthetic data generation from imaging-based features (functional connectivity, gradients, ICA, graph metrics) provides rich training signals that capture the semantic structure of fMRI data. The multi-task, multi-paradigm instruction tuning allows the model to develop flexible reasoning capabilities across different cognitive domains. The LoRA-based efficient adaptation ensures the model can be fine-tuned effectively without extensive computational resources.

## Foundational Learning
- **Neural tokenization of fMRI data**: Converts continuous brain signals into discrete tokens aligned with language embeddings - needed to bridge modality gap between brain imaging and language models
- **Synthetic data generation from imaging features**: Creates artificial fMRI-text pairs from functional connectivity, gradients, ICA, and graph metrics - needed to provide supervised training signals where real paired data is scarce
- **Multi-task instruction tuning**: Trains across diverse cognitive tasks and paradigms simultaneously - needed to develop generalizable reasoning capabilities
- **LoRA-based efficient adaptation**: Uses low-rank adaptation for parameter-efficient fine-tuning - needed to enable practical deployment and customization
- **Foundation model pretraining**: Leverages large-scale LLM pretraining for cross-modal reasoning - needed to bootstrap semantic understanding capabilities

Quick check: Each component addresses a specific challenge in bridging fMRI and language modalities while maintaining computational efficiency.

## Architecture Onboarding

Component map: Neural tokenizer -> LLM adaptation -> Multi-task instruction tuning -> LoRA fine-tuning -> Downstream applications

Critical path: The neural tokenizer is the critical first component that enables all subsequent processing. Without accurate fMRI-to-token mapping, the entire language-aligned understanding pipeline fails.

Design tradeoffs: The model trades off perfect semantic alignment (which would require extensive paired fMRI-text data) for practical synthetic data generation that captures imaging features. This enables broader applicability but introduces uncertainty about semantic fidelity.

Failure signatures: Poor tokenization quality would manifest as degraded performance across all downstream tasks. Over-reliance on synthetic data could lead to models that perform well on synthetic benchmarks but poorly on real-world applications. Inefficient adaptation could make the model impractical for deployment on limited computational resources.

Three first experiments:
1. Evaluate tokenization quality by measuring alignment between discrete fMRI tokens and corresponding language embeddings
2. Compare performance with and without synthetic data to quantify its contribution
3. Test zero-shot generalization across cognitive domains not represented in training data

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Heavy dependence on synthetic data generation from imaging-based features, with unclear validation of semantic quality
- Neural tokenizer's semantic alignment capability assumed rather than empirically validated
- Evaluation focuses primarily on classification and regression, with limited assessment of complex reasoning or generative capabilities

## Confidence

High confidence:
- The technical framework (neural tokenizer, LLM adaptation, multi-task tuning) is well-defined and reproducible
- Reported numerical results on seven datasets are internally consistent with methodology

Medium confidence:
- Superiority claims over baseline models are supported by numbers but difficult to fully verify without exact experimental conditions
- Generalization claims across tasks and datasets are plausible but not exhaustively tested

Low confidence:
- Semantic alignment between discrete fMRI tokens and language representations is asserted but not rigorously validated
- Assumption that synthetic fMRI-text pairs adequately represent real semantic content remains unverified

## Next Checks
1. Conduct ablation studies removing the synthetic data component to quantify its actual contribution to performance gains versus using real fMRI-text pairs alone
2. Perform cross-paradigm validation by testing fMRI-LM on datasets from completely different cognitive domains not represented in training synthetic data
3. Implement human evaluation studies comparing the semantic quality of generated descriptions from fMRI-LM against expert annotations to validate claimed language alignment capability