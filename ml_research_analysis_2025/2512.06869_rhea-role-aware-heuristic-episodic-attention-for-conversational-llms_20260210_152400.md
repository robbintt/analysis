---
ver: rpa2
title: 'Rhea: Role-aware Heuristic Episodic Attention for Conversational LLMs'
arxiv_id: '2512.06869'
source_url: https://arxiv.org/abs/2512.06869
tags:
- rhea
- context
- instruction
- memory
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Rhea tackles cumulative contextual decay in multi-turn conversations
  by decoupling conversation history into two functionally independent memory modules:
  an Instructional Memory for global constraints and an Episodic Memory for interaction
  history. It employs asymmetric noise control and heuristic context retrieval to
  maintain a high signal-to-noise context.'
---

# Rhea: Role-aware Heuristic Episodic Attention for Conversational LLMs

## Quick Facts
- **arXiv ID:** 2512.06869
- **Source URL:** https://arxiv.org/abs/2512.06869
- **Reference count:** 15
- **Primary result:** Mitigates performance decay in long conversations via role-aware memory decoupling and asymmetric noise control

## Executive Summary
Rhea addresses cumulative contextual decay in multi-turn conversations by decoupling conversation history into two functionally independent memory modules: an Instructional Memory for global constraints and an Episodic Memory for interaction history. It employs asymmetric noise control and heuristic context retrieval to maintain a high signal-to-noise context. Experiments on MT-Eval and Long-MT-Bench+ show that Rhea mitigates performance decay and improves accuracy by 1.04 points on a 10-point scale (16% relative gain), while maintaining near-perfect instruction fidelity (IAR > 8.1) across long-horizon interactions.

## Method Summary
Rhea implements a dual-LoRA architecture on Mistral-7B-Instruct-v0.2, with LoRA_cmp compressing model replies into 8 latent embeddings and LoRA_gen generating responses using hybrid context. The system uses an Instruction Recognizer to populate an Instructional Memory (IM) with global constraints, while an Episodic Memory (EM) stores interaction tuples. Heuristic Context Retrieval (HCR) scores current queries against EM turns using cosine similarity thresholds (τ_low=0.5, τ_high=0.8) to select between raw text, compressed latent embeddings, or discarding. The architecture is trained on filtered TopiOCQA and UltraChat datasets for 2 epochs with AdamW optimizer.

## Key Results
- Improves accuracy by 1.04 points on 10-point scale (16% relative gain) in long conversations
- Maintains near-perfect instruction fidelity (IAR > 8.1) across 60+ turn interactions
- Ablation shows IAR collapses from 8.18 to 1.95 when IM is removed

## Why This Works (Mechanism)

### Mechanism 1: Role-Aware Memory Decoupling
Separating conversation history into functionally independent modules (IM for global constraints, EM for interactions) preserves instruction fidelity across long-horizon conversations. The IM uses structural deterministic priority (prefix anchoring) while EM applies asymmetric noise control. Core assumption: functional instructions and episodic content have different decay dynamics requiring different preservation strategies. Evidence: ablation shows IAR collapses from 8.18 to 1.95 when IM is removed.

### Mechanism 2: Asymmetric Noise Control via Dual-LoRA Compression
Compressing only model replies (not user inputs) maximizes context utilization while filtering the primary noise source. LoRA_cmp encodes verbose model responses into fixed-length latent embeddings (n=8 tokens). Core assumption: model replies are the dominant noise source while user inputs contain higher-fidelity signals. Evidence: ablation shows Rhea-preserve (all replies retained) scores 6.63 IAR vs Rhea-abandon (all discarded) scores 7.89 vs Rhea (dynamic) scores 8.18.

### Mechanism 3: Heuristic Context Retrieval with Adaptive Granularity
Multi-tiered retrieval based on turn-level attention scores filters noise while preserving task-relevant context. Computes attention scores between compressed query embedding and historical turn embeddings, mapping to three tiers: score > τ_high → retrieve raw text; τ_low ≤ score ≤ τ_high → use latent embeddings; score < τ_low → discard. Core assumption: relevance to current query is a reliable proxy for context utility. Evidence: sensitivity analysis shows τ_low is critical (performance peaks at 0.5), τ_high is robust across [0.70, 0.90].

## Foundational Learning

- **Attention Sink / "Lost in the Middle" Phenomenon**: Why needed here: Rhea's design directly counters the tendency of LLMs to overlook mid-context tokens; understanding this baseline failure mode clarifies why structural prioritization matters. Quick check: Can you explain why positional bias in attention mechanisms causes models to favor prefix and suffix tokens over middle context?

- **LoRA (Low-Rank Adaptation)**: Why needed here: Rhea implements dual-LoRA architecture; understanding parameter-efficient fine-tuning is essential for reproducing the compression/generation modules. Quick check: How does LoRA enable training task-specific adapters (compress vs. generate) while sharing a frozen backbone?

- **Embedding-Space Operations for Hybrid Context**: Why needed here: Rhea's Hybrid Context Reconstruction operates at the embedding level, concatenating text tokens and latent vectors. Implementers must understand how to manipulate embeddings directly. Quick check: How would you concatenate token embeddings from text with fixed-length latent embeddings before passing to transformer layers?

## Architecture Onboarding

- **Component map:** IR (Instruction Recognizer) -> IM (Instructional Memory) -> LoRA_cmp (Compression Module) -> EM (Episodic Memory) -> HCR (Heuristic Context Retrieval) -> LoRA_gen (Generation Module) -> Base Model (Mistral-7B)

- **Critical path:** 1) User input arrives → IR classifies as instruction (IM update) or interaction (EM pathway) 2) For interactions: LoRA_cmp compresses prior model replies → updates EM 3) HCR scores current query against EM turns → selects high-res/low-res/discard 4) Hybrid context assembled: IM (prefix) + filtered EM + current query 5) LoRA_gen produces response → EM updated with (uₜ, bₜ, Vₖ)

- **Design tradeoffs:** IR Recall vs Precision: paper tunes for high recall (0.89) at cost of precision (0.62). FP errors are benign; FN errors are catastrophic. Compression Budget (n=8 tokens): fixed budget balances context efficiency vs information preservation. τ Thresholds: τ_low is sensitive (must tune); τ_high is robust (less critical).

- **Failure signatures:** Catastrophic IAR collapse (~2.0): likely IM failure (high FN in IR) or IM removed entirely. Gradual quality decay: HCR thresholds misconfigured. Latency spike: HCR overhead minimal (~6.5% increase); major spikes suggest implementation error. Instruction bleed: IM not properly prefixed or EM/IM boundary blurred.

- **First 3 experiments:** 1) Reproduce IM ablation: run full Rhea vs +EM+HCR (no IM) on MT-Eval. Expect IAR drop from ~8.2 to ~2.0. 2) HCR threshold sweep: grid search τ_low ∈ [0.4, 0.5, 0.6] and τ_high ∈ [0.7, 0.9] on held-out subset. Confirm τ_low sensitivity peak at 0.5. 3) Compression ratio ablation: test n ∈ [4, 8, 16] latent tokens. Measure tradeoff between IAR and latency.

## Open Questions the Paper Calls Out

### Open Question 1
How can the Instructional Memory be enhanced to detect and resolve contradictory or evolving global constraints automatically? The current IM employs a cumulative update strategy without explicit conflict resolution, which may struggle with evolving directives. Experiments evaluating performance on adversarial or dynamic instruction sets where global constraints explicitly contradict or supersede earlier ones, measured by IAR, would resolve this.

### Open Question 2
Can an end-to-end neural instruction extractor improve upon the current hybrid recognizer's ability to capture nuanced directives? The current system relies on a separate, small Qwen-0.6B model and rules, which risks missing complex instructions that do not fit predefined templates. A comparative study replacing the current IR with a fine-tuned neural module evaluated on pragmatically complex instructions would resolve this.

### Open Question 3
How can the computational overhead of heuristic context retrieval be optimized for strict, real-time latency constraints? While efficient compared to compression baselines, Rhea adds inference steps that do not exist in vanilla models, potentially impacting time-sensitive applications. Profiling Rhea's latency under strict TTFT budgets and testing approximate nearest neighbor search or caching optimizations would resolve this.

## Limitations
- Experimental validation limited to specific benchmarks (MT-Eval, Long-MT-Bench+) with single base model (Mistral-7B)
- Thresholds and compression budget validated on same datasets used for training, raising overfitting concerns
- Asymmetric noise control assumption not empirically tested against alternative noise sources or mixed-domain conversations

## Confidence
- **High Confidence**: Role-aware memory decoupling mechanism well-supported by ablation studies; dual-LoRA architecture clearly specified and reproducible
- **Medium Confidence**: Asymmetric noise control hypothesis plausible but relies on untested assumptions about noise distribution
- **Low Confidence**: Compression ratio (n=8 tokens) chosen without systematic ablation; alternative retrieval heuristics not validated

## Next Checks
1. **Cross-Domain Robustness Test**: Evaluate Rhea on multi-domain conversational datasets to verify asymmetric noise control assumption holds across diverse interaction patterns
2. **Compression Budget Ablation**: Systematically test n ∈ [4, 8, 16] latent tokens on held-out subset to quantify tradeoff between context efficiency and instruction preservation
3. **Alternative Retrieval Heuristic Comparison**: Implement and compare cosine similarity threshold approach against alternative retrieval methods on same benchmarks to validate optimality