---
ver: rpa2
title: 'Generative AI in Training and Coaching: Redefining the Design Process of Learning
  Materials'
arxiv_id: '2508.11662'
source_url: https://arxiv.org/abs/2508.11662
tags:
- genai
- learning
- trainers
- training
- coaches
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how generative AI (GenAI) is reshaping
  the roles of trainers and coaches in designing learning materials. Through semi-structured
  interviews with five professionals, the research finds that GenAI shifts their role
  from content creators to quality assessors and curators.
---

# Generative AI in Training and Coaching: Redefining the Design Process of Learning Materials

## Quick Facts
- **arXiv ID:** 2508.11662
- **Source URL:** https://arxiv.org/abs/2508.11662
- **Reference count:** 40
- **Primary result:** GenAI shifts trainer roles from content creators to quality assessors, requiring new AI literacy skills.

## Executive Summary
This qualitative study investigates how Generative AI reshapes the roles of trainers and coaches in designing learning materials. Through semi-structured interviews with five professionals, researchers found that GenAI fundamentally transforms the instructional design process by automating routine tasks while demanding new competencies like prompting and critical evaluation. The study reveals that trainers increasingly function as curators rather than primary content generators, with anthropomorphism influencing how users interact with AI tools. Ethical concerns including data privacy and content bias remain significant challenges in this evolving landscape.

## Method Summary
The research employed qualitative content analysis following Mayring's approach, analyzing semi-structured interviews (45-60 minutes) with five German professionals actively using GenAI tools like ChatGPT and Midjourney for training content creation. The analysis combined deductive categories derived from theory with inductive expansion from interview data. Participants represented various industries including automotive, coaching, and continuing education. The study aimed to identify thematic shifts in professional roles, productivity impacts, and perceptions of AI-human interaction dynamics.

## Key Results
- GenAI shifts trainer roles from content creators to quality assessors and curators
- Anthropomorphism influences user trust and interaction styles with AI tools
- New competencies including prompting skills and critical evaluation are essential for effective GenAI integration
- Ethical concerns around data privacy and content bias require ongoing attention

## Why This Works (Mechanism)

### Mechanism 1: Role Shift via Creator-Reviewer Inversion
If GenAI is integrated into instructional design, the trainer's role shifts from primary content generator to critical reviewer and curator. GenAI automates the synthesis and drafting phases of the ADDIE model's design process, removing the "blank page" barrier but introducing a "verification bottleneck." Trainers must apply pedagogical judgment to AI-generated drafts rather than creating de novo. This assumes trainers possess subject-matter expertise to validate AI outputs, with the AI serving as a sufficiently capable drafter to make verification faster than creation.

### Mechanism 2: Anthropomorphism-Driven Prompt Variation
If a user perceives GenAI as a collaborative partner (high anthropomorphism), they tend to use less precise, more open-ended prompts; if perceived as a tool (low anthropomorphism), prompts become rigid and functional. Anthropomorphism alters the user's mental model of the system's agency. Trusting the AI as a "partner" leads to delegated agency (open prompts), while viewing it as a "tool" retains strict user agency (specific constraints). This assumes the user's psychological perception of the machine directly dictates their linguistic interaction strategy.

### Mechanism 3: Efficiency via Skill-Biased Automation
GenAI integration yields productivity gains primarily for users who have already acquired specific "AI literacy" competencies (prompting and critical evaluation). GenAI acts as a force multiplier for those who can navigate its context window and hallucination risks. It reduces time on routine tasks but increases the cognitive load of verification, resulting in net efficiency only when the user is skilled in prompt engineering. This assumes the time cost of learning to prompt and verify is lower than the time saved by automation.

## Foundational Learning

- **Concept: ADDIE Model (Instructional Design)**
  - **Why needed here:** The paper frames the "design process" specifically within the "D" phase of the ADDIE model. Understanding this framework is necessary to identify where in the workflow GenAI is intervening.
  - **Quick check question:** Can you distinguish between the "Design" phase (structuring/strategizing) and the "Development" phase (creating specific materials) in the context of this study?

- **Concept: Anthropomorphism in HCI**
  - **Why needed here:** A core research question investigates how attributing human traits to AI affects prompting style and trust. The paper posits a causal link between "human-like" perception and "open-ended" task delegation.
  - **Quick check question:** How might treating an AI as a "sparring partner" rather than a "search engine" change the specificity of your instructions?

- **Concept: Qualitative Content Analysis**
  - **Why needed here:** The study relies on N=5 semi-structured interviews analyzed via Mayring's qualitative content analysis. One must understand that findings are derived from inductive/deductive coding of subjective reports, not quantitative telemetry.
  - **Quick check question:** Why might a finding based on five interviews be considered "exploratory" rather than universally generalizable?

## Architecture Onboarding

- **Component map:** Human Actor (Trainer/Coach) -> Interface (GenAI Tool) -> Process (ADDIE Design Phase) -> Output (Learning Materials) -> Mediating Layer (Prompting Strategy)
- **Critical path:**
  1. Define Objective: Trainer determines learning goals (Human-only)
  2. Prompt Construction: Trainer formulates instructions (High variability based on Anthropomorphism)
  3. Generation: AI synthesizes content
  4. Verification/Curation: Trainer reviews for hallucinations, bias, and pedagogical fit (The "New Bottleneck")
  5. Refinement: Trainer adapts content to personal style

- **Design tradeoffs:**
  - Efficiency vs. Autonomy: High reliance on AI speeds up drafting but risks eroding the trainer's creative "muscle memory" and personal style
  - Partner vs. Tool Persona: Designing AI to feel "human" increases trust/engagement but promotes imprecise prompting; designing it as a "tool" may limit creative exploration
  - Standardization vs. Customization: GenAI excels at standard structures but struggles with highly specific, emotionally nuanced, or context-dependent training scenarios

- **Failure signatures:**
  - The "Uncanny Valley" of Content: AI output that looks professional but lacks emotional resonance or specific context
  - Over-reliance: Trainers accepting AI hallucinations as fact due to the "reviewer mindset" becoming passive approval
  - Prompt Drift: As models update, old prompt strategies fail, requiring constant re-calibration

- **First 3 experiments:**
  1. Prompt Granularity Test: Give the same design task to two groups—one instructed to treat AI as a "partner" (open prompts), one as a "tool" (rigid prompts). Measure output quality and time.
  2. Verification Lag Measurement: Measure the time difference between "creating from scratch" vs. "verifying and editing AI drafts" for a standard curriculum unit.
  3. Bias/Accuracy Audit: Generate learning materials on a sensitive topic and measure the frequency of gender bias or factual hallucinations to quantify the "reviewer burden."

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the role of trainers and coaches evolve over the long term as GenAI technologies continue to advance?
- Basis in paper: [explicit] The conclusion states that "longitudinal studies should be conducted to examine how the role of trainers and coaches changes over time."
- Why unresolved: The current study provides only a snapshot based on semi-structured interviews at a single point in time.
- What evidence would resolve it: Longitudinal data tracking the professional evolution and competency acquisition of trainers over several years of GenAI adoption.

### Open Question 2
- Question: What is the optimal balance between human-like GenAI interaction and the maintenance of professional autonomy?
- Basis in paper: [explicit] The conclusion notes, "Further research is needed to determine the optimal balance between human-like GenAI interaction and maintaining professional autonomy."
- Why unresolved: The study found ambivalence: anthropomorphism increases trust but risks uncritical reliance and loss of control.
- What evidence would resolve it: Controlled studies correlating different levels of AI anthropomorphism with metrics of trainer autonomy and critical decision-making.

### Open Question 3
- Question: How can the trustworthiness and accountability of AI-generated content be ensured in the unregulated field of continuing education?
- Basis in paper: [explicit] The authors call for an "in-depth investigation of the ethical implications... particularly concerning the trustworthiness and accountability of AI-generated content."
- Why unresolved: The field lacks legal standards, and current participants report ethical concerns like data privacy and bias.
- What evidence would resolve it: Development and validation of ethical frameworks or quality assurance standards specifically for AI in non-institutionalized training.

## Limitations
- Sample size is extremely small (N=5), constraining generalizability and increasing sensitivity to individual experiences
- Research relies entirely on self-reported data without observational validation or quantitative productivity metrics
- Study focuses specifically on German professionals, potentially missing cultural or regional variations in AI adoption

## Confidence
- **High confidence:** Core finding that GenAI shifts trainers' roles from content creators to quality assessors is consistently supported by participant statements
- **Medium confidence:** Relationship between anthropomorphism and prompting style is documented but based on exploratory observations
- **Low confidence:** Claims about net productivity gains are speculative, as the study doesn't measure actual time savings versus verification overhead

## Next Checks
1. **Scale validation:** Replicate the study with a larger, more diverse sample (N≥30) across multiple countries to test generalizability of role transformation findings
2. **Observational study:** Track actual workflow metrics (time spent, revision cycles) comparing traditional content creation versus AI-assisted approaches with the same trainers
3. **Prompt behavior experiment:** Systematically test the anthropomorphism-prompting relationship by assigning participants to "partner" versus "tool" framing conditions and measuring prompt specificity and output quality