---
ver: rpa2
title: High Dimensional Data Decomposition for Anomaly Detection of Textured Images
arxiv_id: '2512.20432'
source_url: https://arxiv.org/abs/2512.20432
tags:
- image
- detection
- anomaly
- texture
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a texture basis integrated smooth decomposition
  (TBSD) method for anomaly detection in textured images. It addresses the challenge
  of distinguishing sparse anomalies from quasi-periodic textures in images with smooth
  backgrounds.
---

# High Dimensional Data Decomposition for Anomaly Detection of Textured Images

## Quick Facts
- arXiv ID: 2512.20432
- Source URL: https://arxiv.org/abs/2512.20432
- Authors: Ji Song; Xing Wang; Jianguo Wu; Xiaowei Yue
- Reference count: 40
- This paper introduces TBSD method for anomaly detection in textured images, achieving 58% true positive rate with only 2.2% false positives on real-world wood surface data.

## Executive Summary
This paper addresses the challenge of detecting anomalies in textured images with smooth backgrounds by introducing a texture basis integrated smooth decomposition (TBSD) method. The approach learns texture basis functions from defect-free images to capture common quasi-periodic texture patterns, then uses these as prior knowledge to reconstruct textures and accurately detect anomalies in defect images. The method demonstrates superior performance compared to benchmarks like RPCA and SSD, particularly in distinguishing sparse anomalies from quasi-periodic textures that RPCA and SSD struggle to separate.

## Method Summary
TBSD decomposes textured images into four components: smooth background, quasi-periodic texture, sparse anomalies, and noise. The method consists of two principal processes: first, it learns texture basis functions from defect-free images through low-rank decomposition, quasi-periodic direction detection, and K-nearest basis neighbors clustering; second, it uses these learned basis functions to reconstruct textures in defect images and identify residuals as anomalies. The approach employs iterative block coordinate descent with separate smooth and texture penalties to enable stable convergence for simultaneous background, texture, and anomaly estimation.

## Key Results
- Achieves 58% average true positive rate on real-world wood surface data with only 2.2% false positives
- Outperforms RPCA and SSD benchmarks by successfully distinguishing quasi-periodic textures from sparse anomalies
- Validated through both simulation studies and real-world experiments on MVTec wood surface images
- Demonstrates superior performance particularly on small, localized defects that traditional methods misclassify as texture variations

## Why This Works (Mechanism)

### Mechanism 1
- Decomposing textured images into four components (smooth background + quasi-periodic texture + sparse anomalies + noise) enables separation of anomalies from textures that RPCA and SSD cannot distinguish.
- The texture component C_tex is modeled as possessing quasi-periodicity—a property where texture patterns are "similar but not identical" across segments. By learning texture basis functions B_t from defect-free images, the method reconstructs textures before identifying residuals as anomalies, preventing texture misidentification.
- Core assumption: Textures exhibit quasi-periodicity along identifiable directions (Definition 3.4), allowing them to be learned from limited defect-free samples and distinguished from sparse anomalies.
- Evidence anchors: The TBSD method consists of two principal processes: the first process learns the texture basis functions to effectively extract quasi-periodic texture patterns; the subsequent anomaly detection process utilizes that texture basis as prior knowledge. Definition 3.4 formally defines quasi-periodicity with segmentation S_{tM}, quasi-periodic length T, mode S̃_T, and control limit σ.

### Mechanism 2
- Pre-learning texture basis functions from a small set of defect-free images and using them as a sparse dictionary reduces training data requirements compared to deep learning methods.
- TBFL process (Model I) extracts texture estimator Ĉ_tex via low-rank decomposition, then applies LSERA (Algorithm B.1) to detect quasi-periodic directions, and KNBN clustering (Algorithm B.3) to construct B_t. This overcomplete dictionary enables texture reconstruction in defect images without requiring defect labels.
- Core assumption: Quasi-periodic texture modes S̃_T^(d) along direction d are contained within partial image patches, allowing B_t to be learned from small regions.
- Evidence anchors: It is reasonable for quasi-periodic modes {S̃_T^(d)|d∈D} to be sufficiently contained within partial areas of the original image Y, so segmentation could be conducted on Y to learn effective texture basis B_t. Real-world experiments used a single 1/16 patch from Y_good_075 to learn B_t for detecting anomalies in full images.

### Mechanism 3
- Iterative block coordinate descent with separate smooth and texture penalties (λ, γ, η) enables stable convergence for simultaneous background, texture, and anomaly estimation.
- Algorithm 4.2 iteratively updates θ (smooth coefficients) via ridge regression, θ_t (texture coefficients) via soft thresholding, and Ĉ_a (anomalies) via residual soft thresholding. The penalty terms enforce smoothness (λθ^TRθ), texture sparsity (γ||θ_t||_1), and anomaly sparsity (η||Ĉ_a||_1).
- Core assumption: The optimization landscape permits separation via iterative projection; B_t^T B_t ≈ I for tractable θ_t estimation (Appendix C.3).
- Evidence anchors: Estimators derived in Equations 4-5 show closed-form updates: θ̂ = (B^TB + λR)^(-1)B^T·(residual), θ̂_t ≈ B_t^T·(residual) - γ/2·sgn(·). Computation complexity is O(max(M,N)^3), comparable to RPCA and SSD.

## Foundational Learning

- **Low-rank matrix decomposition (PCA/RPCA)**: Understanding low-rank + sparse decomposition is prerequisite to grasping why texture misidentification occurs. Quick check question: Can you explain why RPCA's low-rank assumption fails when textures are present?

- **Sparse dictionary learning**: Texture basis B_t functions as an overcomplete dictionary; the method uses soft-thresholding operators (S_γ/2) to enforce sparsity in texture coefficients. Quick check question: How does soft-thresholding S_γ(x) = sgn(x)·(|x| - γ)_+ promote sparse solutions?

- **B-spline basis functions**: Smooth background is estimated using pre-constructed B-spline basis B (L=3, k=2 in Section 4.2); understanding how these capture smooth intensity variations is essential. Quick check question: Why would a polynomial basis be insufficient for modeling smooth image backgrounds with local variations?

## Architecture Onboarding

- **Component map**: Defect-free images → Algorithm 4.1 (LowRankDecomposite) → Ĉ_tex → Algorithm B.1 (LSERA) → directional samples → Algorithm B.2 (QuasiPeriodicDetect) → directions D → Algorithm B.3 (KNBN) → B_t → Defect image + B + B_t → Algorithm 4.2 (DefectDecomposition) → Ĉ_bg, Ĉ_tex, Ĉ_a → Algorithm B.4 (ClosedCurveForm) → defect regions

- **Critical path**: 1. Learn B_t from defect-free patches (one-time; O(max(m,n)^3)) 2. For each defect image: run Algorithm 4.2 with (λ, γ, η, iterTimes) 3. Threshold Ĉ_a using ϕ_A (default 2%) to flag defect images

- **Design tradeoffs**: Patch size vs. basis completeness: smaller training patches reduce computation but may miss texture patterns; paper used 1/16 image patches successfully. Parameter sensitivity vs. robustness: Universal (ϕ_B/T, ϕ_A) = (0.5, 2%) worked across images, but optimal tuning improves results (Section 6.2 notes parameter sensitivity). Rotation resolution vs. speed: Algorithm B.1's maxRotate controls angular precision for quasi-periodicity detection; higher values increase O(K_r · K_l · w_l · √(m²+n²))

- **Failure signatures**: Residual textures in Ĉ_a indicates ϕ_B/T too low or B_t incomplete; adjust balance parameter or retrain with larger patches. Missed anomalies in Ĉ_a may signal η too high (over-penalizing anomaly sparsity) or anomalies larger than expected sparsity assumption. One misjudgment case (Y_hole_003 in Table 6.1) suggests certain defect types or locations may not align with learned texture directions.

- **First 3 experiments**: 1. Replicate simulation study (Figure 5.1) with Y_simulate_cross[10] to validate LSERA correctly identifies 45° and 135° texture directions 2. Run TBFL on single MVTec wood "good" patch and visualize learned B_t elements to confirm quasi-periodic pattern capture 3. Compare Algorithm 4.2 detection on Y_hole_000,[1,1] with varying (λ, γ, η) to characterize parameter sensitivity before production tuning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the sensitivity of the TBSD method to relevant parameters (e.g., λ, γ, η) be mitigated to ensure optimal performance across different image patches without extensive manual tuning?
- Basis in paper: The conclusion states, "There still needs further research to properly deal with the sensitivity of the TBSD method to relevant parameters."
- Why unresolved: The authors note that optimal parameters vary across image patches, and improper choices result in residual textures being misidentified as anomalies.
- What evidence would resolve it: The development of an adaptive parameter selection algorithm or theoretical bounds that define optimal parameter ranges based on image characteristics.

### Open Question 2
- Question: How does the performance of TBSD degrade when applied to textured images where patterns do not exhibit the assumed quasi-periodicity?
- Basis in paper: The method is theoretically founded on the assumption that textures possess "quasi-periodicity" (Section 3), defined by the existence of similar periodic modes.
- Why unresolved: The experimental validation is restricted to wood surfaces and simulations with quasi-periodic textures; applicability to stochastic or irregular textures is unexplored.
- What evidence would resolve it: Benchmarking TBSD against other methods on datasets containing non-periodic or stochastic textures (e.g., random noise patterns) to observe failure modes.

### Open Question 3
- Question: What is the impact on anomaly detection accuracy if the background component C_{bg} does not satisfy the low-rank and smoothness constraints required by the decomposition model?
- Basis in paper: The optimization model assumes a "Low-rank smooth background" (Section 4.2) to estimate C_{bg} using smooth basis functions like B-splines.
- Why unresolved: The paper does not analyze the decomposition error when backgrounds contain sharp discontinuities or high-frequency variations that violate the smoothness assumption.
- What evidence would resolve it: Testing the method on images with non-smooth or complex backgrounds to quantify the resulting error in texture and anomaly estimation.

## Limitations
- The quasi-periodic texture assumption is critical; method performance degrades when textures lack consistent directional patterns or contain multiple conflicting frequencies
- Training requires defect-free images, limiting applicability to domains with limited clean data or where anomalies are present in historical samples
- Fixed parameter sets show robustness but optimal tuning is image-dependent, requiring validation for new domains

## Confidence

- **High confidence**: TBSD's four-component decomposition framework and its superiority over RPCA/SSD on real-world wood data (quantitative metrics provided)
- **Medium confidence**: Generalization to non-wood textured surfaces (simulation suggests mechanism works but real-world validation limited)
- **Low confidence**: Performance under extreme conditions (very high noise, multiple defect types simultaneously, or non-quasi-periodic textures)

## Next Checks
1. Test TBSD on MVTec textures dataset (carpet, grid, leather) to assess cross-domain generalization
2. Evaluate sensitivity to training patch size by systematically varying from 1/16 to full image patches
3. Compare against deep learning methods (CutPaste, STA) on same defect types to quantify computational vs. accuracy tradeoffs