---
ver: rpa2
title: Mechanistic Interpretability of Antibody Language Models Using SAEs
arxiv_id: '2512.05794'
source_url: https://arxiv.org/abs/2512.05794
tags:
- features
- saes
- antibody
- latents
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies sparse autoencoders (SAEs) to an antibody language
  model (p-IgGen) to interpret and steer its generation. It trains both TopK and Ordered
  SAEs on hidden layer activations, identifying latent features corresponding to biologically
  meaningful concepts such as CDR identity and germline gene identity.
---

# Mechanistic Interpretability of Antibody Language Models Using SAEs

## Quick Facts
- arXiv ID: 2512.05794
- Source URL: https://arxiv.org/abs/2512.05794
- Reference count: 38
- Trains TopK and Ordered SAEs on p-IgGen to identify interpretable antibody features and steer generation toward specific germline genes.

## Executive Summary
This paper applies sparse autoencoders (SAEs) to an antibody language model (p-IgGen) to interpret and steer its generation. It trains both TopK and Ordered SAEs on hidden layer activations, identifying latent features corresponding to biologically meaningful concepts such as CDR identity and germline gene identity. TopK SAEs reveal interpretable, antibody-specific features but show high feature-concept correlation without reliable steering capability, suggesting that predictive power alone doesn't guarantee control over generation. In contrast, Ordered SAEs, with their hierarchical structure, successfully identify steerable features—demonstrating predictable increases or decreases in specific germline gene usage (IGHJ4) through targeted steering. The findings suggest that while TopK SAEs suffice for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required. The work advances mechanistic interpretability in domain-specific protein language models and highlights SAEs as tools for incorporating rational design principles into antibody library generation.

## Method Summary
The authors trained sparse autoencoders (TopK and Ordered) on hidden layer activations from the p-IgGen antibody language model using 1.8M paired VH/VL sequences from Observed Antibody Space. TopK SAEs used an expansion factor of 32 with 24,576 latents, while Ordered SAEs used an expansion factor of 8 with 6,144 latents. Linear probes identified interpretable features with F1>0.5 for CDR identity and IGHJ genes. Steering was evaluated by adding decoder vectors scaled by factor α to activations and measuring changes in target gene proportions across 1,000 generated sequences.

## Key Results
- TopK SAEs identified interpretable antibody features with high correlation to CDR identity and germline genes but failed to steer generation predictably
- Ordered SAEs successfully steered IGHJ4 gene usage with strong positive/negative correlations (Pearson's R up to 0.85) across multiple α values
- Steering efficacy depends on SAE architecture: hierarchical structure in Ordered SAEs enables causal control over generation that predictive TopK features lack

## Why This Works (Mechanism)
The study demonstrates that SAE architecture fundamentally affects the relationship between interpretability and steerability. TopK SAEs identify features that are predictive of biological concepts but represent specific residues rather than abstract concepts, preventing effective steering. Ordered SAEs' hierarchical structure groups related features, creating latents that encode higher-level concepts with sufficient causal influence over generation. This architecture choice enables the translation of latent feature knowledge into practical design control for antibody generation.

## Foundational Learning
- **Sparse Autoencoders (SAEs)**: Neural networks trained to compress and reconstruct inputs through a bottleneck layer, encouraging sparse activation patterns. Why needed: SAEs extract interpretable features from model activations that correspond to biological concepts. Quick check: Verify latents have low average activation frequency (<10%) and reconstruct inputs accurately.
- **Ordered SAEs**: SAEs with hierarchical feature organization using nested grouping during training. Why needed: Hierarchical structure enables grouping of related features to capture abstract biological concepts. Quick check: Confirm latents activate on conserved regions rather than specific residues.
- **TopK SAEs**: SAEs that activate exactly k latents per input, regardless of importance. Why needed: Simpler architecture that can identify predictive features but may split concepts across multiple latents. Quick check: Measure activation sparsity and check for feature correlation clustering.
- **Steering Factor α**: Scalar multiplier applied to decoder vectors during generation to influence model outputs. Why needed: Enables controlled manipulation of generation toward target biological properties. Quick check: Verify α values produce monotonic changes in target gene proportions.
- **Linear Probe Evaluation**: Logistic regression trained on SAE latents to measure correlation with biological concepts. Why needed: Quantifies interpretability of latents by measuring predictive power for known concepts. Quick check: Ensure F1>0.5 threshold identifies latents with strong concept correlation.

## Architecture Onboarding
- **Component Map**: Input Sequences -> p-IgGen (4-layer, 768-dim) -> Layer 3 Activations -> SAE Training -> Latents -> Linear Probes -> Interpretable Features -> Steering Evaluation
- **Critical Path**: Sequence → SAE Latent → Linear Probe → Steering Factor → Generated Sequence → Gene Proportion Analysis
- **Design Tradeoffs**: TopK SAEs prioritize feature discovery and interpretability but sacrifice steering control; Ordered SAEs sacrifice some interpretability for hierarchical organization that enables steering
- **Failure Signatures**: TopK latents show high concept correlation but no steering correlation; Ordered SAE latents have scattered activations but strong steering capability
- **First Experiments**: 1) Train TopK SAE and measure IGHJ4 correlation vs. steering correlation; 2) Train Ordered SAE and evaluate IGHJ4 steering across α∈[-2,2]; 3) Compare activation patterns between architectures on conserved vs. variable regions

## Open Questions the Paper Calls Out
- Can a standardized, exhaustive steering analysis quantitatively characterize the trade-offs between TopK and Ordered SAE architectures across diverse biological concepts?
- Does training SAEs on larger, functionally annotated datasets like FLAb enable the identification and steering of high-level abstract concepts like developability?
- To what extent is "feature splitting" the primary mechanistic cause for the failure of high-correlation TopK features to induce generative steering?

## Limitations
- Steering analysis limited to single gene family (IGHJ4) without broader biological concept coverage
- SAE training duration and generation hyperparameters unspecified, limiting reproducibility
- Feature splitting hypothesis proposed but not empirically isolated as definitive cause for steering failure

## Confidence
- SAE architecture choice affects steering capability: High
- TopK SAEs identify predictive but non-steerable features: Medium
- Ordered SAEs enable causal control over generation: High

## Next Checks
- Verify SAE training converges by monitoring reconstruction loss across epochs
- Confirm steering correlation persists across multiple random seeds and sequence subsets
- Test merging split features in TopK SAE to assess impact on steering capability