---
ver: rpa2
title: Bidirectional LMs are Better Knowledge Memorizers? A Benchmark for Real-world
  Knowledge Injection
arxiv_id: '2505.12306'
source_url: https://arxiv.org/abs/2505.12306
tags:
- knowledge
- question
- arxiv
- match
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces WikiDYK, a novel real-world benchmark for
  evaluating knowledge injection in large language models. The benchmark leverages
  Wikipedia's "Did You Know" entries, which are daily updated and expert-curated,
  containing 12,290 facts and 77,180 questions.
---

# Bidirectional LMs are Better Knowledge Memorizers? A Benchmark for Real-world Knowledge Injection

## Quick Facts
- **arXiv ID:** 2505.12306
- **Source URL:** https://arxiv.org/abs/2505.12306
- **Reference count:** 36
- **Primary result:** Bidirectional language models outperform causal models by 23% accuracy in knowledge memorization tasks

## Executive Summary
This paper introduces WikiDYK, a novel benchmark for evaluating knowledge injection in large language models, based on Wikipedia's expert-curated "Did You Know" entries. The benchmark contains 12,290 facts and 77,180 questions, providing a real-world test bed for knowledge-intensive tasks. Experiments reveal that bidirectional language models (BiLMs) significantly outperform causal language models (CLMs) in knowledge memorization, achieving 23% higher accuracy. To address BiLMs' scale limitations, the authors propose a modular framework that ensembles BiLMs as external knowledge repositories, integrating them with LLMs via a scope classifier. This approach improves reliability accuracy by up to 29.1%, suggesting bidirectional architectures warrant renewed attention for knowledge-intensive applications.

## Method Summary
The authors develop WikiDYK by extracting "Did You Know" entries from Wikipedia, which are daily updated and expert-curated facts. They evaluate various language models on open-ended question answering tasks derived from these facts. To overcome the scalability limitations of bidirectional models, they propose a modular ensemble framework where BiLMs serve as external knowledge repositories. A scope classifier determines whether queries should be routed to the BiLM knowledge base or handled directly by the LLM. This hybrid approach combines the memorization strengths of BiLMs with the reasoning capabilities of larger LLMs, achieving improved reliability on knowledge-intensive tasks.

## Key Results
- Bidirectional language models outperform causal models by 23% accuracy in knowledge memorization tasks
- Modular ensemble framework with scope classifier improves reliability accuracy by up to 29.1%
- WikiDYK benchmark contains 12,290 facts and 77,180 questions from expert-curated Wikipedia entries

## Why This Works (Mechanism)
Bidirectional models process context from both directions, allowing them to capture relationships and dependencies more effectively than unidirectional causal models. This architectural difference enables better pattern recognition and information retrieval during inference, particularly for factual knowledge that requires understanding relationships between entities and concepts. The ensemble approach leverages this bidirectional strength while mitigating scalability constraints through intelligent query routing.

## Foundational Learning

**Bidirectional vs Causal Language Models:** Bidirectional models (like BERT) process text in both directions, while causal models (like GPT) process text left-to-right. This affects how information is encoded and retrieved.

*Why needed:* Understanding the fundamental architectural differences explains why bidirectional models excel at knowledge retrieval tasks.

*Quick check:* Compare token prediction accuracy on masked vs. causal token prediction tasks.

**Knowledge Injection vs Fine-tuning:** Knowledge injection involves adding external knowledge to models, while fine-tuning adjusts model parameters on new data.

*Why needed:* The paper focuses on knowledge injection methods, distinguishing them from parameter-intensive fine-tuning approaches.

*Quick check:* Measure performance retention after knowledge injection vs. fine-tuning on same dataset.

**Modular Ensemble Systems:** Combining multiple models where each handles specific subtasks or knowledge domains.

*Why needed:* Explains the proposed solution to bidirectional model scalability limitations.

*Quick check:* Evaluate performance degradation when removing ensemble components.

## Architecture Onboarding

**Component Map:** WikiDYK Benchmark -> Model Evaluation -> BiLM Repository -> Scope Classifier -> LLM Reasoning Engine -> Final Output

**Critical Path:** Query → Scope Classifier → (BiLM Repository OR LLM) → Answer Generation → Reliability Scoring

**Design Tradeoffs:** BiLMs offer superior knowledge memorization but face scalability limits; CLMs scale better but memorize less effectively; the ensemble approach balances these competing demands at the cost of increased system complexity.

**Failure Signatures:** Scope classifier misrouting (queries sent to wrong knowledge source), BiLM retrieval failures for rare facts, LLM reasoning errors on complex queries requiring external knowledge.

**First Experiments:**
1. Baseline comparison: Evaluate CLMs vs BiLMs directly on WikiDYK without ensemble framework
2. Scope classifier ablation: Test performance with perfect vs. learned routing decisions
3. Knowledge source isolation: Compare results when using only BiLM repository vs. only LLM reasoning

## Open Questions the Paper Calls Out
None

## Limitations
- Superiority demonstrated only on question answering format, may not generalize to all knowledge-intensive applications
- WikiDYK benchmark may contain biases toward Wikipedia-represented knowledge types
- Scope classifier routing accuracy requires further validation for real-world deployment

## Confidence
**Limitations and Confidence Assessment**

The study's primary claim that bidirectional language models are superior knowledge memorizers carries Medium confidence. While the experimental results demonstrate a 23% accuracy advantage over causal models on the WikiDYK benchmark, this superiority is demonstrated on a specific task format (open-ended question answering) and may not generalize to all knowledge-intensive applications. The modular ensemble framework showing 29.1% reliability improvements is promising but relies on the assumption that scope classification can accurately route queries, which requires further validation.

The WikiDYK benchmark itself, while innovative in using expert-curated Wikipedia "Did You Know" entries, may introduce biases toward certain types of factual knowledge that are overrepresented in Wikipedia. The benchmark's real-world relevance is High confidence given its daily updates and expert curation, but its coverage breadth remains uncertain.

## Next Checks
1. Test the BiLM superiority claim across diverse knowledge-intensive tasks beyond question answering, including fact verification, entity linking, and multi-hop reasoning scenarios
2. Evaluate the ensemble framework's performance with different scope classification methods and analyze failure cases to understand routing accuracy limits
3. Conduct ablation studies to quantify the individual contributions of the BiLM knowledge base versus the LLM reasoning capabilities in the modular framework