---
ver: rpa2
title: Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning
arxiv_id: '2506.05671'
source_url: https://arxiv.org/abs/2506.05671
tags:
- speech
- domain
- text
- adaptation
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of adapting Speech LLMs to new
  domains in low-resource settings where paired speech-text data is scarce. The authors
  propose a text-only fine-tuning strategy that adapts the LLM component of a Speech
  LLM using only unpaired target-domain text while preserving speech-text alignment
  through real-time evaluation during training.
---

# Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning

## Quick Facts
- arXiv ID: 2506.05671
- Source URL: https://arxiv.org/abs/2506.05671
- Reference count: 40
- Low-resource domain adaptation using text-only fine-tuning achieves competitive recognition performance

## Executive Summary
This paper addresses the challenge of adapting Speech Language Models (Speech LLMs) to new domains in low-resource settings where paired speech-text data is scarce. The authors propose a text-only fine-tuning strategy that adapts the LLM component of a Speech LLM using only unpaired target-domain text while preserving speech-text alignment through real-time evaluation during training. Experiments on LibriSpeech, SlideSpeech, and Medical datasets demonstrate that this approach achieves competitive recognition performance with minimal degradation compared to full audio-text fine-tuning. The method also improves generalization to new domains without catastrophic forgetting, highlighting the potential of text-only fine-tuning for low-resource domain adaptation of ASR.

## Method Summary
The proposed approach adapts Speech LLMs to new domains using unpaired text data in low-resource settings. The method consists of three main stages: domain alignment fine-tuning on source-domain paired data to establish baseline performance, text-only fine-tuning of the LLM component using target-domain unpaired text, and speech-text alignment preservation through real-time evaluation during fine-tuning. The text-only fine-tuning process involves language modeling loss on target text, contrastive learning between text embeddings and speech representations, and domain alignment optimization. A unique aspect is the integration of real-time speech-text alignment evaluation during training, where the model periodically processes paired data to compute word error rate (WER) and uses this metric to guide the fine-tuning process through curriculum learning and early stopping.

## Key Results
- Achieves competitive recognition performance compared to full fine-tuning methods using only unpaired text data
- Demonstrates improved generalization to new domains without catastrophic forgetting
- Shows minimal performance degradation (1.2% absolute WER increase) compared to full audio-text fine-tuning

## Why This Works (Mechanism)
The approach works by leveraging the inherent structure of Speech LLMs where the speech encoder and LLM components can be fine-tuned independently. By focusing fine-tuning on the LLM component using unpaired text, the method exploits the model's existing speech-text alignment learned during pretraining. The real-time evaluation mechanism acts as a regularizer that prevents the LLM adaptation from drifting too far from the original speech-text mapping, effectively maintaining the alignment between the speech encoder's representations and the adapted LLM's output space.

## Foundational Learning
- **Speech-text alignment**: The mapping between acoustic features and linguistic representations is crucial for ASR performance. Without proper alignment, the speech encoder's outputs become meaningless to the LLM component.
  - Why needed: Speech LLMs rely on the speech encoder producing representations that the LLM can interpret as text
  - Quick check: Verify that the model can transcribe speech after each fine-tuning iteration

- **Contrastive learning**: Used to align text embeddings with speech representations during fine-tuning. This helps maintain the semantic connection between spoken and written forms.
  - Why needed: Ensures that the adapted LLM's representations remain compatible with the speech encoder's outputs
  - Quick check: Measure embedding similarity between corresponding speech and text pairs

- **Curriculum learning**: The real-time evaluation guides the fine-tuning process by adjusting learning rates based on WER performance, starting with easier adaptation tasks and progressing to more challenging ones.
  - Why needed: Prevents catastrophic forgetting while allowing gradual domain adaptation
  - Quick check: Monitor WER trends during training to ensure monotonic improvement

## Architecture Onboarding

**Component Map:** Speech Encoder -> LLM Component -> Text Decoder

**Critical Path:** Speech input → Speech Encoder → LLM Component → Text Decoder → Output transcription

**Design Tradeoffs:** The main tradeoff is between adaptation effectiveness and preservation of speech-text alignment. Text-only fine-tuning offers computational efficiency and data availability benefits but risks misalignment between speech and text representations. The real-time evaluation mechanism mitigates this risk but adds computational overhead during training.

**Failure Signatures:** 
- Performance degradation when adapting to domains with substantially different acoustic characteristics
- Catastrophic forgetting of source domain knowledge when fine-tuning is too aggressive
- Misalignment between speech encoder outputs and adapted LLM representations, visible as increased WER

**First 3 Experiments:**
1. Fine-tune only the LLM component on unpaired text data and evaluate WER on source domain to establish baseline degradation
2. Add real-time evaluation without contrastive learning to isolate the impact of alignment monitoring
3. Test on out-of-domain data before and after fine-tuning to measure generalization capability

## Open Questions the Paper Calls Out
None

## Limitations
- The approach may not be sufficient for domains with extreme acoustic differences where speech characteristics change substantially
- Limited evaluation of downstream task performance beyond basic recognition accuracy
- Heavy reliance on the assumption that text-only LLM adaptation preserves speech-text alignment without extensive empirical validation

## Confidence
- Claims of competitive performance vs full fine-tuning: Medium
- Claims of avoiding catastrophic forgetting: Medium
- Claims of improved generalization: Medium

## Next Checks
1. Conduct ablation studies removing the real-time evaluation component to quantify its actual impact on preserving speech-text alignment during text-only fine-tuning.

2. Test the method on domains with extreme acoustic differences (e.g., telephony speech vs. broadcast news) to evaluate whether text-only fine-tuning alone is sufficient for such challenging domain shifts.

3. Evaluate the adapted models on downstream tasks beyond recognition accuracy, such as speaker identification or domain-specific entity recognition, to assess whether the text-only fine-tuning preserves task-specific capabilities.