---
ver: rpa2
title: 'UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles'
arxiv_id: '2508.09639'
source_url: https://arxiv.org/abs/2508.09639
tags:
- shap
- uncertainty
- epistemic
- features
- value
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "UbiQTree addresses the gap in explainable AI by quantifying epistemic\
  \ uncertainty in SHAP-based feature attributions for tree ensemble models. Traditional\
  \ SHAP treats attributions as point estimates, ignoring uncertainty from model variability\
  \ and limited data\u2014a critical issue in high-stakes domains like healthcare."
---

# UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles

## Quick Facts
- **arXiv ID**: 2508.09639
- **Source URL**: https://arxiv.org/abs/2508.09639
- **Reference count**: 40
- **Primary result**: UbiQTree quantifies epistemic uncertainty in SHAP-based feature attributions for tree ensembles, decomposing variance into aleatoric, epistemic, and entanglement components using Dempster-Shafer evidence theory and Dirichlet process sampling.

## Executive Summary
UbiQTree addresses the critical gap in explainable AI by quantifying epistemic uncertainty in SHAP-based feature attributions for tree ensemble models. Traditional SHAP treats attributions as point estimates, ignoring uncertainty from model variability and limited data—a critical issue in high-stakes domains like healthcare. The method decomposes SHAP variance into aleatoric, epistemic, and entanglement components using Dempster-Shafer evidence theory, Liu's uncertainty theory, and Dirichlet process hypothesis sampling. This enables explicit modeling of feature attribution uncertainty and guides data acquisition. Across three real-world datasets (MIMIC-III, Ovarian Cancer, and SEER Breast Cancer), the framework demonstrated improved interpretability with epistemic uncertainty quantified via confidence intervals, entropy, and sign stability metrics.

## Method Summary
UbiQTree introduces a novel framework for uncertainty quantification in SHAP-based feature attributions for tree ensemble models. The method trains a random forest, then samples sub-ensembles using Dirichlet-weighted tree selection based on out-of-bag AUC scores. For each sub-ensemble, TreeSHAP values are computed and variance is decomposed into aleatoric (data noise), epistemic (model uncertainty), and entanglement (covariance) components. The approach leverages Dempster-Shafer evidence theory and Liu's uncertainty theory to provide confidence intervals, entropy, and sign stability metrics for each feature attribution. This enables explicit uncertainty-aware feature explanations and guides targeted data acquisition to reduce epistemic uncertainty in high-stakes domains.

## Key Results
- Epistemic uncertainty successfully quantified via confidence intervals, entropy, and sign stability metrics across all three healthcare datasets
- High SHAP values do not always indicate stable attributions, demonstrating the importance of uncertainty quantification
- Uncertainty-guided data collection strategy effectively reduces epistemic uncertainty in feature attributions
- Framework validated on MIMIC-III (LOS classification), Ovarian Cancer (risk classification), and SEER Breast Cancer (survival classification) datasets

## Why This Works (Mechanism)
The method works by recognizing that traditional SHAP provides point estimates without capturing uncertainty from model variability and limited data. By sampling sub-ensembles using Dirichlet-weighted tree selection based on OOB performance, the approach generates a distribution of possible SHAP values. Variance decomposition using Dempster-Shafer evidence theory separates aleatoric (irreducible data noise), epistemic (reducible model uncertainty), and entanglement (covariance) components. This enables explicit uncertainty quantification for each feature attribution, allowing practitioners to distinguish between stable and unstable explanations and make more informed decisions about data collection and model deployment.

## Foundational Learning
- **Dempster-Shafer Evidence Theory**: Needed to combine evidence from multiple sub-ensembles and decompose variance into uncertainty components. Quick check: Verify that belief masses sum to 1 across all hypotheses.
- **Dirichlet Process Sampling**: Required for weighted tree selection based on OOB performance, enabling non-uniform sub-ensemble sampling. Quick check: Confirm Dirichlet weights follow expected concentration parameter α.
- **TreeSHAP Algorithm**: Essential for computing feature attributions efficiently on tree ensembles. Quick check: Validate that background data size doesn't significantly affect attribution stability.
- **Variance Decomposition**: Critical for separating aleatoric, epistemic, and entanglement components. Quick check: Confirm aleatoric variance remains stable across different sample sizes.
- **Uncertainty Metrics**: Sign stability, entropy, and confidence intervals needed to quantify attribution uncertainty. Quick check: Verify sign stability correlates with feature importance stability.

## Architecture Onboarding

**Component Map**: Dataset -> Preprocessing -> RandomForest Training -> OOB-AUC Scoring -> Dirichlet Sampling -> Sub-ensemble Creation -> TreeSHAP Computation -> Variance Decomposition -> Uncertainty Metrics

**Critical Path**: The core workflow involves training the base random forest, computing OOB-AUC scores for each tree, using these scores to weight Dirichlet sampling of sub-ensembles, computing TreeSHAP values for each sub-ensemble, then decomposing the resulting variance into uncertainty components.

**Design Tradeoffs**: The framework trades computational cost (multiple SHAP computations) for uncertainty quantification benefits. Using OOB-AUC for tree weighting introduces additional variance but captures model confidence better than uniform sampling. The choice of Dirichlet concentration α balances exploration vs. exploitation in sub-ensemble sampling.

**Failure Signatures**: High aleatoric variance across all features may indicate noisy data or poor model fit. Low epistemic variance despite high overall variance suggests the model is overconfident. Sign instability concentrated in high-SHAP features indicates unreliable explanations for important variables.

**First Experiments**:
1. Run baseline with uniform Dirichlet weights (α=1) to confirm weighted sampling improves uncertainty estimates
2. Test sensitivity to Dirichlet concentration α by varying from 0.1 to 10.0
3. Validate uncertainty reduction by synthetically adding high-uncertainty samples and measuring epistemic variance decrease

## Open Questions the Paper Calls Out
None

## Limitations
- Critical hyperparameters like Dirichlet concentration α are underspecified for some datasets
- Background data composition for TreeSHAP computation is not explicitly documented
- Multi-class SHAP aggregation strategy for classification tasks remains unclear
- No random seed documentation or explicit reproducibility measures provided

## Confidence

**High Confidence**: The overall methodological framework (variance decomposition, Dempster-Shafer evidence theory, Dirichlet process sampling) is clearly articulated and mathematically sound.

**Medium Confidence**: Experimental results are reproducible given assumptions about missing hyperparameters, but exact numerical matches are unlikely without precise parameter values.

**Low Confidence**: Some implementation details (background data composition, exact α values, class aggregation strategy) are insufficient for byte-for-byte reproduction.

## Next Checks
1. **Baseline Comparison**: Validate aleatoric/epistemic decomposition by comparing against a baseline that uses uniform Dirichlet weights (α=1 for all trees) to confirm that the weighting scheme meaningfully impacts uncertainty estimates.
2. **Sign Stability Threshold**: Implement a sensitivity analysis for sign stability by varying the SHAP value threshold (e.g., 0.01, 0.05) to determine how many features are affected by near-zero attributions.
3. **Uncertainty Reduction Validation**: Test the data acquisition strategy by synthetically adding high-uncertainty samples and measuring epistemic uncertainty reduction to confirm the practical utility of uncertainty-guided data collection.