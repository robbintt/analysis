---
ver: rpa2
title: A French Version of the OLDI Seed Corpus
arxiv_id: '2508.02290'
source_url: https://arxiv.org/abs/2508.02290
tags:
- translation
- source
- french
- language
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents the first French partition of the OLDI Seed
  Corpus, created through a hybrid machine translation and human post-editing process.
  Using nine MT systems and a custom interface, native speakers post-edited 6,193
  segments, focusing on fluency and accurate technical terminology.
---

# A French Version of the OLDI Seed Corpus

## Quick Facts
- arXiv ID: 2508.02290
- Source URL: https://arxiv.org/abs/2508.02290
- Reference count: 40
- Primary result: First French partition of OLDI Seed Corpus created through MTPE, achieving lowest error score (2.08) on MetricX-24 validation

## Executive Summary
This paper presents the creation of the first French version of the OLDI Seed Corpus, a multilingual corpus designed to promote under-resourced regional languages of France. The corpus was developed through a hybrid machine translation and human post-editing (MTPE) process, where native French speakers post-edited 6,193 segments translated by nine different MT systems. The post-editing focused on ensuring fluency and accurate technical terminology, resulting in a corpus that significantly outperforms raw MT outputs according to automated validation metrics.

The resulting French corpus serves as a pivot resource for future translation into under-resourced regional languages of France. The authors developed a custom interface to facilitate the post-editing process and employed MetricX-24 for validation, which showed the post-edited corpus achieved the lowest error score among all tested hypotheses. This work demonstrates a practical approach to creating high-quality translation resources for language preservation efforts while highlighting both the potential and limitations of MTPE methodologies in specialized domains.

## Method Summary
The authors created a French partition of the OLDI Seed Corpus through a hybrid machine translation and human post-editing (MTPE) approach. They utilized nine different machine translation systems to generate initial translations of the English source material, which were then post-edited by native French speakers using a custom-built interface. The post-editing process focused on improving fluency and ensuring accurate representation of technical terminology. The final corpus consists of 6,193 segments that underwent this MTPE process. Validation was performed using MetricX-24, an automated metric that evaluated the post-edited corpus against all raw MT hypotheses, with the final product achieving the lowest error score of 2.08.

## Key Results
- First French partition of OLDI Seed Corpus created through MTPE process
- 6,193 segments post-edited by native French speakers focusing on fluency and technical terminology
- Post-edited corpus achieved lowest error score (2.08) on MetricX-24 validation compared to all raw MT hypotheses
- Corpus intended as pivot resource for future translation into under-resourced regional languages of France

## Why This Works (Mechanism)
The MTPE approach combines the efficiency of machine translation with human linguistic expertise to produce higher-quality translations than either method alone. By leveraging multiple MT systems, the process benefits from diverse translation approaches, while the human post-editing ensures fluency and technical accuracy that automated systems alone cannot guarantee. The custom interface facilitates efficient post-editing workflow, and the validation methodology provides quantitative evidence of quality improvement over raw MT outputs.

## Foundational Learning

**Machine Translation (MT)**: Automated translation systems that convert text from one language to another
*Why needed*: Provides initial translation hypothesis that can be refined through human intervention
*Quick check*: Verify that multiple MT systems are used to capture diverse translation approaches

**Human Post-Editing (MTPE)**: Process where human translators refine machine-generated translations
*Why needed*: Ensures linguistic fluency and domain-specific accuracy that automated systems cannot achieve
*Quick check*: Confirm post-editors are native speakers with subject matter expertise

**Pivot Translation**: Using an intermediate language to facilitate translation between two less-resourced languages
*Why needed*: Enables translation into under-resourced languages by leveraging more widely available translation resources
*Quick check*: Verify the target regional languages have limited available translation resources

## Architecture Onboarding

Component map: English source -> 9 MT systems -> Post-editing interface -> Post-edited French corpus -> Validation (MetricX-24)

Critical path: English source material → Machine translation (9 systems) → Human post-editing (6,193 segments) → Validation (MetricX-24)

Design tradeoffs: Multiple MT systems provide diversity but increase complexity; human post-editing ensures quality but is resource-intensive; automated validation provides quantitative comparison but may not capture all quality aspects

Failure signatures: Inconsistent terminology across segments; loss of original argumentative structure; post-editor fatigue affecting quality; MT systems producing similar errors that post-editing cannot fully correct

First experiments: 1) Test MT system diversity by comparing output consistency across systems; 2) Validate post-editing interface usability with pilot segment testing; 3) Benchmark MetricX-24 against human evaluation on sample segments

## Open Questions the Paper Calls Out
None

## Limitations
- Validation relies on automated metrics (MetricX-24) rather than human evaluation of final translations
- Corpus size of 6,193 segments remains limited for training robust MT systems in specialized domain
- Focus on fluency and terminology may not fully preserve semantic equivalence or original argumentative structure

## Confidence
High confidence in methodological description and corpus creation process
Medium confidence in quality assessment results from automated validation
Low confidence in claimed downstream utility for regional language translation

## Next Checks
1. Conduct human evaluation of post-edited translations against original English source to verify semantic preservation
2. Test corpus effectiveness as pivot resource by translating into at least one regional language (e.g., Breton or Occitan)
3. Compare final corpus performance against best individual MT system to quantify post-editing benefits