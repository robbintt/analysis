---
ver: rpa2
title: 'AnchorOPT: Towards Optimizing Dynamic Anchors for Adaptive Prompt Learning'
arxiv_id: '2511.21188'
source_url: https://arxiv.org/abs/2511.21188
tags:
- anchor
- tokens
- prompt
- soft
- anchoropt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes AnchorOPT, a dynamic anchor-based prompt learning
  framework for CLIP. It transforms static, hand-crafted anchor tokens into implicitly
  learnable components and introduces a learnable position matrix to adaptively reorder
  tokens during training.
---

# AnchorOPT: Towards Optimizing Dynamic Anchors for Adaptive Prompt Learning

## Quick Facts
- arXiv ID: 2511.21188
- Source URL: https://arxiv.org/abs/2511.21188
- Reference count: 40
- Primary result: AnchorOPT achieves 1.82%-7.02% improvements over strong baselines across 11 datasets by learning dynamic anchors and adaptive token positions

## Executive Summary
This work introduces AnchorOPT, a dynamic anchor-based prompt learning framework that transforms static, hand-crafted anchor tokens into implicitly learnable components for CLIP. The method introduces a learnable position matrix to adaptively reorder tokens during training and employs a two-stage training process: first optimizing anchor tokens via LLM-generated category descriptions, then jointly optimizing soft tokens and the position matrix for downstream tasks. Experiments across 11 diverse datasets show consistent performance improvements over strong baselines, with gains ranging from 1.82% to 7.02%. Notably, AnchorOPT achieves comparable or better results than methods incorporating additional regularization or learnable modules, demonstrating the untapped potential of fundamental prompt learning templates.

## Method Summary
AnchorOPT implements a two-stage training paradigm for prompt learning with CLIP. In Stage I, learnable anchor tokens are optimized via MSE loss against LLM-generated category description embeddings using the template "{Anc} of {Class}". Stage II freezes the anchors and jointly optimizes soft tokens and a learnable position matrix (M+N × M+N) using CE loss plus KL distillation from ensemble predictions. Gumbel-Softmax relaxation enables differentiable optimization of token positions. During inference, normal prompt predictions are used for base classes while ensemble predictions are used for novel classes to improve generalization.

## Key Results
- Achieves 1.82%-7.02% improvements over strong baselines across 11 diverse datasets
- Single-token anchors outperform longer anchors (HM 72.79 vs. 2.73 with longer anchors on ImageNet)
- Adaptive positioning (73.85 HM) outperforms all fixed-position variants (73.50-73.69 HM)
- Two-stage training (78.68 HM) outperforms one-stage (78.06 HM) on ImageNet novel class generalization

## Why This Works (Mechanism)

### Mechanism 1: Implicit Anchor Token Learning via Description Supervision
Replaces manually-specified anchor tokens with learnable tokens supervised by LLM-generated category descriptions. Anchor tokens are optimized using MSE loss to align with description embeddings, encouraging them to capture universal cross-category semantics without explicit attribute specification. This approach avoids the constraints of hand-crafted attributes that may conflict with domain-specific requirements.

### Mechanism 2: Differentiable Position Reordering via Gumbel-Softmax
Uses a learnable position matrix to enable task-specific prompt restructuring by dynamically adjusting token positions. The matrix maps original token indices to output positions using Gumbel-Softmax relaxation, allowing gradient flow through discrete assignment operations. This enables the model to discover optimal token ordering for each dataset rather than relying on fixed templates.

### Mechanism 3: Two-Stage Training with Ensemble Distillation
Decouples anchor optimization from soft token adaptation, combined with knowledge distillation from ensemble predictions. Stage I trains anchors via MSE against description embeddings, then freezes them for Stage II where soft tokens and position matrix are jointly optimized using CE loss + KL divergence distillation. This approach transfers generalizable representations to normal prompts while maintaining base-class performance.

## Foundational Learning

- **Concept: Soft Prompt Learning as Continuous Embedding Optimization**
  - Why needed here: AnchorOPT builds directly on CoOp's paradigm of replacing discrete text templates with learnable continuous embeddings. Understanding soft tokens as continuous vectors optimized in embedding space while encoders remain frozen is essential for grasping why dynamic anchors and position matrices are meaningful augmentations.
  - Quick check question: Why are soft tokens represented as continuous vectors rather than discrete vocabulary indices, and what does this imply about their interpretability?

- **Concept: Gumbel-Softmax for Differentiable Discrete Sampling**
  - Why needed here: The position matrix requires learning which token goes to which position—a discrete assignment problem. Standard argmax isn't differentiable, blocking gradient flow. Gumbel-Softmax provides the reparameterization trick that enables end-to-end training.
  - Quick check question: Explain why adding Gumbel noise sampled from Gumbel(0,1) followed by softmax enables gradient backpropagation through what would otherwise be a discrete selection operation.

- **Concept: Knowledge Distillation for Ensemble-to-Student Transfer**
  - Why needed here: Stage II distills knowledge from ensemble predictions (anchor + normal prompt averaged) to the normal prompt alone via KL divergence. This mechanism transfers generalization capability without requiring both prompts at inference.
  - Quick check question: What is the theoretical justification for using ensemble outputs as soft labels, and why might this improve novel-class generalization compared to hard label supervision alone?

## Architecture Onboarding

- **Component map**:
  Stage I (Anchor Optimization): LLM descriptions → Text Encoder → Description embeddings (frozen targets)
  Learnable anchor tokens → "{Anc} of [CLS]" → Text Encoder → Anchor embeddings
  Loss = MSE(anchor_embeddings, description_embeddings)

  Stage II (Adaptation): Frozen anchor tokens + Learnable soft tokens → Concatenate
  Position matrix (learnable) → Gumbel-Softmax → Token rearrangement
  Rearranged tokens + [CLS] → Text Encoder → Text features
  Image → Image Encoder → Visual features
  Predictions: q_norm = visual · text^T / τ
  Ensemble: q_ens = (q_norm + q_anc) / 2
  Loss = λ₁ · CE(q_norm, labels) + λ₂ · KL(q_norm || q_ens)

- **Critical path**:
  1. Stage I must converge before Stage II (anchors frozen after Stage I)
  2. Anchor length = 1 is critical (longer anchors catastrophically degrade normal prompt performance)
  3. Loss weight ratio λ₁:λ₂ ≈ 1:10 (distillation emphasized)
  4. Preposition "of" in anchor template outperforms alternatives

- **Design tradeoffs**:
  - Two-stage vs. one-stage: +0.62 HM improvement but requires managing two training phases
  - Anchor length 1 vs. longer: Single-token most efficient; longer anchors overconstrain soft tokens
  - Shallow vs. deep variant: Deep variant preserves anchor tokens across transformer layers while discarding soft tokens, adding complexity for potential representation gains
  - Ensemble at inference for novel classes: Improves generalization but doubles text encoder forward passes

- **Failure signatures**:
  - Position matrix converges to identity or uniform distribution (check visualization like Fig. 4)
  - Anchor embeddings project to incoherent vocabulary tokens via inverse embedding (expected per paper discussion)
  - Novel-class accuracy drops sharply when distillation removed (Table 9 signature)
  - One-stage training matches two-stage performance (suggests anchor pre-training unnecessary)
  - Performance degrades with anchor length > 1 (Table 7 signature)

- **First 3 experiments**:
  1. **Position matrix ablation**: Set position matrix to frozen identity (no rearrangement), train full pipeline, compare against learned matrix. Isolates whether dynamic reordering provides genuine benefit.
  2. **Cross-dataset anchor transfer**: Train anchors on ImageNet Stage I, freeze and use for Flowers102 Stage II. Tests whether anchors learn universal vs. dataset-specific representations.
  3. **Distillation weight sensitivity**: Sweep λ₂ from 0 to 10×λ₁ on 2-3 datasets. Paper uses 10:1 ratio; verify this isn't dataset-specific by checking if optimal ratio varies across domains.

## Open Questions the Paper Calls Out

- **Can AnchorOPT be effectively adapted to alternative Vision-Language Model (VLM) architectures beyond CLIP, such as SigLIP and EVA-CLIP?**
  - Basis: The Supplementary Material (S5) explicitly identifies the current limitation to CLIP and states the intent to develop a cross-model benchmark.
  - Why unresolved: Current prompt learning frameworks are predominantly evaluated on CLIP, leaving their compatibility and efficiency with other diverse VLM architectures unverified.
  - What evidence would resolve it: Successful integration and performance benchmarks of AnchorOPT on alternative backbones like SigLIP and EVA-CLIP.

- **Can a unified one-stage training paradigm be optimized to match the stability and performance of the proposed two-stage approach?**
  - Basis: Section 3.2.4 and Table 3 show the one-stage extension underperforms the two-stage method (78.06 vs. 78.68 HM) due to "unstable intermediate ensemble results."
  - Why unresolved: The authors note that intermediate ensemble results in a single stage cannot yield reliable supervision signals, necessitating a two-stage split that increases training complexity.
  - What evidence would resolve it: A modified one-stage training strategy or loss function that achieves harmonic mean scores statistically equivalent to the two-stage baseline.

- **Is it possible to map the optimized implicit anchor tokens back to human-interpretable semantic concepts?**
  - Basis: Section S4 (Discussion) notes that projecting learned embeddings into the token vocabulary results in "incoherent character strings" rather than meaningful text.
  - Why unresolved: There is a fundamental incompatibility between the continuous latent space where anchor tokens are optimized and the discrete tokenization process of the text encoder.
  - What evidence would resolve it: A visualization technique or constraint mechanism that produces coherent, semantically meaningful words for the learned anchors.

## Limitations

- **Dataset-specific performance variance**: The reported gains (1.82%-7.02%) are heterogeneous across 11 datasets, but the paper doesn't systematically analyze which datasets benefit most or why, limiting generalizability claims.
- **Interpretability barrier**: The paper explicitly acknowledges that inverse projection of optimized anchor tokens produces incoherent text, making it impossible to verify whether learned anchors capture semantically meaningful representations.
- **Ablation completeness gaps**: Missing comparison against simple soft prompt baselines without any anchor modifications, making it unclear whether gains come from anchor learning specifically or other methodological differences.

## Confidence

- **High confidence**: The methodological framework is technically sound. Gumbel-Softmax for differentiable position reordering is a well-established technique, and the two-stage training paradigm is logically coherent.
- **Medium confidence**: The core performance claims are supported by extensive experiments across diverse datasets. The consistent trend of improvements across multiple baselines suggests the approach has merit, though the magnitude of gains varies significantly.
- **Low confidence**: The interpretability claims regarding what anchor tokens actually learn are fundamentally unverifiable given the inverse projection limitations, preventing empirical validation of assertions about "universal cross-category semantics."

## Next Checks

1. **Controlled ablation with simple soft prompt baseline**: Implement a baseline using only soft tokens (4-8 tokens) without any anchor modifications, trained on the same two-stage paradigm. Compare this against AnchorOPT on all 11 datasets to isolate whether gains are specifically due to dynamic anchors or other factors like training procedure.

2. **Cross-dataset anchor transferability test**: Train anchor tokens on ImageNet Stage I, then freeze and evaluate on all other 10 datasets without fine-tuning the anchors. This tests whether anchors learn truly universal representations or are dataset-specific, providing empirical validation of the "cross-category semantics" claim.

3. **Position matrix convergence analysis**: For each dataset, track the position matrix evolution during training and visualize the final permutation. If the matrix consistently converges to identity or uniform distributions across datasets, this would invalidate the core claim that task-specific positional optimization is beneficial.