---
ver: rpa2
title: 'shapr: Explaining Machine Learning Models with Conditional Shapley Values
  in R and Python'
arxiv_id: '2504.01842'
source_url: https://arxiv.org/abs/2504.01842
tags:
- shapley
- values
- value
- explain
- conditional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: shapr introduces a comprehensive framework for generating conditional
  Shapley value explanations in R and Python. It addresses the limitation of existing
  software by focusing on conditional Shapley values, which accurately capture feature
  dependencies often ignored by other methods.
---

# shapr: Explaining Machine Learning Models with Conditional Shapley Values in R and Python

## Quick Facts
- arXiv ID: 2504.01842
- Source URL: https://arxiv.org/abs/2504.01842
- Reference count: 13
- Primary result: Comprehensive framework for conditional Shapley value explanations in R/Python addressing feature dependency limitations

## Executive Summary
shapr introduces a comprehensive framework for generating conditional Shapley value explanations in R and Python. It addresses the limitation of existing software by focusing on conditional Shapley values, which accurately capture feature dependencies often ignored by other methods. The package implements a wide range of approaches for estimating the conditional contribution function, including Monte Carlo-based methods (independence, empirical, Gaussian, Gaussian copula, ctree, vaeac, categorical) and regression-based methods (regression_separate, regression_surrogate).

## Method Summary
The method estimates conditional Shapley values by modeling the contribution function $v(S) = E[f(x) | x_S = x^*_S]$ using various conditional distribution estimation approaches. The package implements Monte Carlo sampling methods (Gaussian, ctree, VAEAC) and regression-based methods to estimate these conditional expectations. It uses a variance-reduced KernelSHAP implementation with reweighting and paired sampling, and includes iterative estimation with convergence detection based on stability metrics.

## Key Results
- Implements comprehensive conditional Shapley value estimation with multiple approaches
- Includes variance-reduced KernelSHAP with reweighting and paired sampling
- Provides iterative estimation with convergence detection based on stability metrics
- Supports causal and asymmetric Shapley values
- Offers specialized functionality for explaining time series forecasts

## Why This Works (Mechanism)

### Mechanism 1: Conditional Expectation via Dependent Sampling
- **Claim:** If features in a dataset exhibit statistical dependence, estimating contribution functions using conditional distributions yields more realistic explanations than assuming independence.
- **Mechanism:** The package estimates $v(S) = E[f(x) | x_S = x^*_S]$ by sampling from the conditional distribution $p(x_{\bar{S}} | x_S = x^*_S)$ rather than the marginal $p(x_{\bar{S}})$. Approaches like `gaussian`, `copula`, `ctree`, and `vaeac` model this dependence structure to generate Monte Carlo samples that respect the data manifold.
- **Core assumption:** The features $x$ are not statistically independent; the joint distribution $p(x)$ contains dependence structures that standard marginal methods ignore.

### Mechanism 2: Variance-Reduced KernelSHAP Reweighting
- **Claim:** Correcting the weights of sampled coalitions in the weighted least squares (WLS) problem reduces the estimation variance of Shapley values compared to standard KernelSHAP.
- **Mechanism:** Instead of using raw sampling frequencies, `shapr` normalizes Shapley kernel weights and conditions them on the probability of being sampled at least once (Eq 8, 9). Combined with paired sampling (including both $S$ and $\bar{S}$), this stabilizes the WLS solution $\phi = Rv$.
- **Core assumption:** The variance in standard Monte Carlo sampling is the primary source of error in KernelSHAP approximations for finite samples.

### Mechanism 3: Iterative Convergence via Stability Metrics
- **Claim:** Iteratively increasing the number of coalitions until Shapley value estimates stabilize allows for computation to stop early without sacrificing explanation quality.
- **Mechanism:** The algorithm estimates the standard deviation of $\phi_{ij}$ via bootstrapping. It checks if the median relative standard deviation falls below a threshold $t$ (Eq 14). If not, it increases the coalition count.
- **Core assumption:** The variability of the Shapley values across bootstrapped samples serves as a reliable proxy for the error relative to the "true" explanation.

## Foundational Learning

- **Concept: Shapley Value Decomposition**
  - **Why needed here:** The entire package is built on solving the game-theoretic problem of distributing a prediction value $f(x)$ among features.
  - **Quick check question:** Can you explain why $\phi_j$ represents the average marginal contribution of feature $j$ across all possible feature coalitions?

- **Concept: Conditional Probability Distributions ($p(A|B)$)**
  - **Why needed here:** The core differentiator of this package is modeling $p(x_{\bar{S}}|x_S)$. Without understanding conditional vs. marginal distributions, the distinction between `shapr` and standard SHAP libraries is lost.
  - **Quick check question:** If we know feature A is perfectly correlated with feature B, how should knowing A's value affect our imputation of B's value?

- **Concept: Monte Carlo Integration**
  - **Why needed here:** The approaches (`gaussian`, `empirical`, `ctree`) all rely on approximating the integral in the contribution function $v(S)$ by drawing random samples $K$.
  - **Quick check question:** Why does increasing the number of Monte Carlo samples ($K$) generally improve the accuracy of the estimated $v(S)$?

## Architecture Onboarding

- **Component map:** User Interface -> Core Engine (shapley_setup -> setup_approach -> compute_vS) -> Solver (KernelSHAP WLS) -> Output (shapr object)
- **Critical path:** 1. Setup: Validate data/model. 2. Coalition Sampling: Determine which feature subsets $S$ to evaluate. 3. $v(S)$ Estimation: *This is the bottleneck.* It requires generating samples/imputations and running model predictions for every coalition-explicand pair. 4. Convergence Check: If iterative, check Eq 14; else proceed. 5. Aggregation: Compute final Shapley values via the WLS matrix inversion.
- **Design tradeoffs:**
  - `gaussian`/`copula`: Fast, assumes unimodal distributions. High bias if data is multi-modal/complex.
  - `ctree`: Handles complex dependencies non-parametrically. Slower due to fitting $2^M$ trees.
  - `vaeac`: Handles all coalitions simultaneously with one deep model. High upfront training cost, efficient for large $M$.
  - `regression`: Avoids Monte Carlo sampling variance but introduces bias based on the surrogate model's capacity.
- **Failure signatures:**
  - High MSEv: The estimation approach is a poor fit for the data distribution (e.g., using `independence` on dependent data).
  - Non-convergence: Iterative loop runs to `max_n_coalitions` without meeting threshold; often indicates high model variance or insufficient coalitions.
  - Memory Overflow: Occurs in `compute_vS` if parallelization batches are too large or $N_{explain}$ is massive.
- **First 3 experiments:**
  1. Baseline Sanity Check: Run `explain()` with `approach = "independence"` vs. `approach = "gaussian"` on correlated data. Compare MSEv scores to confirm dependence modeling is active.
  2. Approach Benchmarking: On a subset of data, compare `gaussian`, `empirical`, and `ctree`. Plot the trade-off between runtime (`timing_summary`) and MSEv to select the optimal approach for the dataset.
  3. Iterative vs. Direct: Run with default settings (iterative if $M > 5$). Manually set `iterative = FALSE` with full coalitions. Compare the difference in Shapley values to quantify the error introduced by the approximation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can an adaptive "burn-in" phase be implemented to automatically select the optimal conditional estimation approach (e.g., Gaussian vs. ctree) based on intermediate $MSE_v$ scores?
- Basis in paper: [explicit] Section 7 suggests starting with several approaches in a burn-in period and proceeding with the best performer to create a robust, user-friendly solution.
- Why unresolved: Current implementation requires the user to manually specify the approach or compare post-hoc; no automated switching logic exists within the iterative estimation procedure.
- What evidence would resolve it: A study comparing the accuracy and runtime of an adaptive strategy versus fixed approaches across diverse datasets with varying dependency structures.

### Open Question 2
- Question: How can the shapr methodology be extended to support Shapley Additive Global Explanations (SAGE) for population-level feature importance?
- Basis in paper: [explicit] Section 7 discusses extending the package to support SAGE, which decomposes expected training loss rather than individual predictions.
- Why unresolved: The package currently focuses on local prediction explanations; the methodology for global decomposition using the implemented conditional expectation approaches is not yet developed.
- What evidence would resolve it: A theoretical formulation of SAGE using conditional expectations and a software implementation validated against global importance benchmarks.

### Open Question 3
- Question: Can the $MSE_v$ evaluation criterion be normalized or modified to provide an absolute measure of estimation quality rather than just a relative ranking?
- Basis in paper: [inferred] Section 2.5 notes that $MSE_v$ can rank methods but cannot assess closeness to the optimum because the minimum value is unknown and errors in $v(S)$ might cancel out in the Shapley value formula.
- Why unresolved: The theoretical minimum of the $MSE_v$ score depends on the unknown true contribution function $v_{true}(S)$, making absolute calibration difficult.
- What evidence would resolve it: Derivation of a theoretical lower bound for $MSE_v$ or a modified metric that remains consistent when aggregating contribution errors into Shapley values.

## Limitations
- Data preprocessing specificity: The exact feature engineering steps for constructing `trend`, `cosyear`, and `sinyear` from raw UCI Bike Sharing data are not detailed in the paper.
- Reproducibility of numerical results: Specific MSEv values and Shapley values may be sensitive to exact library versions, random seeds, and floating-point implementations not specified.
- Benchmarking scope: Comparison focuses on MSEv as primary metric without comprehensive runtime benchmarks across different approach combinations or model types.

## Confidence
- **High Confidence**: The conditional expectation mechanism (Mechanism 1) is well-grounded in the Shapley value literature and directly addresses the known limitation of marginal approaches ignoring feature dependencies.
- **Medium Confidence**: The variance-reduced reweighting approach (Mechanism 2) is described with mathematical precision, but lacks extensive empirical validation against alternatives in the paper or corpus.
- **Medium Confidence**: The iterative convergence criterion (Mechanism 3) is theoretically sound, but its effectiveness depends on the choice of stability threshold and may not generalize well to models with highly non-linear interactions.

## Next Checks
- **Validation 1**: Reproduce the UCI Bike Sharing example with both ctree and independence approaches, verifying that MSEv values differ by approximately 350,000 and that Shapley values for explain_id=1 match the paper's reported values.
- **Validation 2**: Implement a synthetic dataset with known feature dependencies (e.g., perfectly correlated features) and demonstrate that conditional approaches produce materially different Shapley values compared to independence approaches.
- **Validation 3**: Test the iterative convergence mechanism by running with default settings and manually setting iterative=FALSE with full coalitions, then compare the difference in Shapley values to quantify approximation error.