---
ver: rpa2
title: 'Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New
  York'
arxiv_id: '2502.09204'
source_url: https://arxiv.org/abs/2502.09204
tags:
- legal
- prolog
- case
- logiclease
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LogicLease combines LLMs for information extraction with Prolog
  for legal reasoning to automate analysis of landlord-tenant cases in New York State.
  The system extracts key attributes from case descriptions using an LLM, then applies
  Prolog rules to determine legal compliance while citing relevant laws.
---

# Logical Lease Litigation: Prolog and LLMs for Rental Law Compliance in New York

## Quick Facts
- arXiv ID: 2502.09204
- Source URL: https://arxiv.org/abs/2502.09204
- Reference count: 24
- LogicLease achieves 100% accuracy on 10 test cases with 2.57s average processing time

## Executive Summary
LogicLease combines large language models for information extraction with Prolog for legal reasoning to automate landlord-tenant case analysis in New York State. The system extracts key attributes from case descriptions using an LLM, then applies Prolog rules to determine legal compliance while citing relevant laws. LogicLease outperforms state-of-the-art LLM-based legal analysis systems by providing transparent step-by-step reasoning and avoiding hallucinations through its neuro-symbolic architecture.

## Method Summary
LogicLease uses a neuro-symbolic architecture where a pre-trained LLM (LLaMA) extracts structured attributes from natural language case descriptions, and a Prolog backend evaluates legal compliance using defeasible logic rules. The system is implemented with Python orchestrating components via PYSWIP, calling the LLM API for extraction, and executing Prolog queries for reasoning. The Prolog knowledge base contains ~500 lines of rules encoding NY landlord-tenant law with embedded law descriptions for explainable output. The system processes inputs through a Streamlit frontend, achieving 100% accuracy across 10 test cases with an average processing time of 2.57 seconds.

## Key Results
- 100% accuracy across 10 test cases (mix of real and fictional scenarios)
- Average processing time of 2.57 seconds per case
- Outperforms baseline LLM-only approaches by avoiding hallucinations and providing transparent reasoning
- Successfully handles complex legal scenarios including conflicting principles through defeasible logic

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Separating information extraction (LLM) from legal reasoning (Prolog) reduces hallucination risk in legal conclusions.
- **Mechanism:** The LLM is constrained to output structured attribute-value pairs rather than free-form legal advice. These pairs instantiate Prolog predicates, which evaluate deterministically against encoded rules. The LLM cannot generate conclusions about legal compliance—only the Prolog engine can.
- **Core assumption:** The LLM extracts attributes accurately and completely; extraction errors propagate as reasoning errors.
- **Evidence anchors:** [abstract] "By separating information extraction from legal reasoning, LogicLease achieves greater transparency and control over the legal logic applied to each case." [Page 4] "The API call sends the queries to the LLM, retrieving a response containing extracted attribute-value pairs."

### Mechanism 2
- **Claim:** Defeasible logic in Prolog enables handling of conflicting or prioritized legal rules.
- **Mechanism:** Legal rules often have exceptions (e.g., general eviction rules vs. protections for disabled tenants). Defeasible logic allows one rule to override another under specific conditions without requiring explicit contradiction resolution in the knowledge base.
- **Core assumption:** The rule hierarchy and exception conditions are correctly encoded; priority conflicts are anticipated by the rule authors.
- **Evidence anchors:** [Page 6] "Notably, LogicLease incorporated defeasible logic within the Prolog component, enabling the system to handle situations where one legal principle takes precedence over another under specific circumstances." [Page 6] "resolving conflicting legal principles and dealing with uncertain or incomplete information"

### Mechanism 3
- **Claim:** Human-readable law descriptions embedded in Prolog rules provide explainable output.
- **Mechanism:** Each Prolog rule includes string descriptions of relevant laws. When a rule fires, the system outputs these strings, producing a step-by-step legal rationale rather than a binary verdict.
- **Core assumption:** The embedded descriptions accurately summarize the law and are intelligible to lay users.
- **Evidence anchors:** [Page 2] "This output is generated using a Prolog backend, where description of relevant laws is coded as strings associated with the rules." [Page 5] Example output lists 9 numbered legal principles before the final judgment.

## Foundational Learning

- **Concept: Prolog backtracking and predicate evaluation**
  - Why needed here: The system relies on Prolog's query evaluation to determine which rules match the extracted facts. Understanding how Prolog unifies arguments and explores alternatives is essential for debugging rule failures.
  - Quick check question: Given the predicate `eviction(Cause, CourtRuling, Executioner, TenantCategory)`, what happens if `CourtRuling` is unbound when the query is issued?

- **Concept: Neuro-symbolic architecture patterns**
  - Why needed here: LogicLease exemplifies a common pattern—neural component for perception/extraction, symbolic component for reasoning. Understanding this division clarifies what each component is and is not responsible for.
  - Quick check question: In LogicLease, can the LLM directly conclude that an eviction is unlawful? Why or why not?

- **Concept: Defeasible reasoning and rule priority**
  - Why needed here: Legal domains frequently involve rules with exceptions. Defeasible logic provides formal machinery for "normally X, unless Y" reasoning without requiring exhaustive enumeration of all exceptions upfront.
  - Quick check question: If a general rule permits eviction for non-payment, but a specific rule protects disabled tenants from eviction, which fires first in a defeasible system—and what determines this?

## Architecture Onboarding

- **Component map:** User Interface -> Driver Script -> LLM API -> Prolog Knowledge Base -> Driver Script -> User Interface
- **Critical path:** 1. User input → Driver Script 2. Driver → LLM API (attribute extraction) 3. LLM response → parsed dictionary 4. Dictionary → Prolog query instantiation 5. Prolog evaluation → verdict + explanations 6. Driver Script → formatted output to UI
- **Design tradeoffs:**
  - **Accuracy vs. coverage:** 10 test cases demonstrate 100% accuracy, but coverage of NY landlord-tenant law is unquantified. Edge cases may be untested.
  - **Speed vs. LLM dependency:** ~2.5s average is acceptable, but 68% correlation between input length and response time indicates LLM is the bottleneck.
  - **Transparency vs. maintenance burden:** Embedding law descriptions in Prolog aids explainability but requires manual updates when statutes change.
- **Failure signatures:**
  - LLM extraction misses key attributes → Prolog reasons from incomplete facts → incorrect or inconclusive verdict.
  - Prolog rule fails to match due to unexpected attribute format → silent failure or exception.
  - API rate limits or network issues → end-to-end pipeline stalls at extraction step.
- **First 3 experiments:**
  1. **Attribute extraction robustness:** Present the LLM with paraphrased versions of the same case (varying wording, ordering, detail level). Measure extraction consistency and error modes.
  2. **Rule coverage audit:** Map the Prolog knowledge base against the NY Tenants' Rights Guide section by section. Identify statutes not represented and classify them by likely impact.
  3. **Comparison with baseline LLM-only:** Run the same 10 test cases through ChatGPT/Gemini directly. Document not just accuracy, but types of errors—hallucinated laws, missing protections, landlord vs. tenant bias.

## Open Questions the Paper Calls Out

- **Future work includes improving the testing process and adding more test cases to ensure better coverage and reliability of the system.**

## Limitations
- The 100% accuracy claim is based on only 10 test cases, insufficient for statistical significance.
- The knowledge base is built from a single source (NY Tenants' Rights Guide), leaving unknown coverage gaps for statutes not included in that guide.
- The LLM extraction step introduces brittleness - if the model fails to extract a legally relevant attribute, the Prolog reasoning will be compromised even though the logic itself is sound.

## Confidence
- **High confidence** in the architectural separation mechanism (LLM extraction + Prolog reasoning) - this is clearly specified and follows established neuro-symbolic patterns.
- **Medium confidence** in the 100% accuracy claim - the result is reported but the sample size (n=10) is too small for statistical confidence.
- **Low confidence** in generalizability - no evidence of performance on cases outside the 10 tested, nor systematic coverage analysis of the knowledge base against actual NY statutes.

## Next Checks
1. Expand evaluation to at least 50 diverse test cases covering different legal scenarios (rent stabilization, habitability, lease validity, discrimination protections) to establish statistical confidence in accuracy claims.
2. Conduct a systematic gap analysis by mapping the Prolog knowledge base against the complete NY Real Property Law and Civil Practice Law to identify missing legal provisions.
3. Test the system's robustness to extraction errors by deliberately providing the LLM with incomplete or ambiguous case descriptions and measuring how often reasoning fails versus produces incorrect conclusions.