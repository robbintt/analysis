---
ver: rpa2
title: Controlling Performance and Budget of a Centralized Multi-agent LLM System
  with Reinforcement Learning
arxiv_id: '2511.02755'
source_url: https://arxiv.org/abs/2511.02755
tags:
- budget
- llms
- expert
- cost
- external
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a centralized multi-LLM system trained via
  reinforcement learning to jointly optimize task performance and inference cost under
  varying budget constraints. A controller LLM selectively routes queries to specialized
  expert models, enabling cost-controllable behavior across low-, medium-, and high-budget
  modes.
---

# Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning

## Quick Facts
- arXiv ID: 2511.02755
- Source URL: https://arxiv.org/abs/2511.02755
- Reference count: 22
- Primary result: RL-trained controller routes queries to specialized experts, achieving better cost-performance trade-offs than individual models

## Executive Summary
This paper introduces a centralized multi-agent LLM system that uses reinforcement learning to jointly optimize task performance and inference cost under varying budget constraints. The system employs a controller LLM that selectively routes queries to specialized expert models based on both task requirements and available budget. Experiments on four math reasoning benchmarks demonstrate that the system can surpass the performance of the best individual expert in high-budget settings while maintaining strong performance at low cost in constrained modes. The controller learns to adaptively balance performance and cost, with learned routing strategies showing generalization to unseen data.

## Method Summary
The proposed system consists of a controller LLM that acts as a router, selecting among specialized expert models based on task description and budget constraints. The controller is trained using reinforcement learning with a reward function that balances task performance (e.g., accuracy on math problems) against inference costs. During training, the controller learns to adaptively route queries to different experts depending on the budget level, developing distinct strategies for low-, medium-, and high-budget modes. The system is evaluated on four math reasoning benchmarks (GSM8K, MATH, SVAMP, MultiArith), demonstrating effective cost-performance trade-offs across different budget constraints.

## Key Results
- The system surpasses the best individual expert model in high-budget settings while maintaining strong performance at low cost
- The controller successfully learns distinct routing strategies for low-, medium-, and high-budget modes
- Learned routing strategies generalize to unseen data and task distributions
- Cost-aware reward design effectively shapes expert selection behavior

## Why This Works (Mechanism)
The system works by leveraging reinforcement learning to train a controller that learns to make cost-aware routing decisions. The controller develops an understanding of which expert models are most appropriate for different types of tasks under various budget constraints. By optimizing a reward function that jointly considers both performance and cost, the controller learns to make trade-offs that would be difficult to achieve through hand-crafted rules or static assignment strategies. The centralized architecture allows for global optimization of the routing policy, while the use of specialized experts enables high performance when budget allows.

## Foundational Learning
- **Reinforcement Learning for routing**: Needed to learn complex cost-performance trade-offs that are difficult to hand-engineer; quick check: verify reward shaping effectively balances competing objectives
- **Multi-expert specialization**: Needed to enable high performance at high budget while maintaining efficiency at low budget; quick check: assess individual expert performance across task types
- **Budget-aware decision making**: Needed to enable adaptive behavior based on resource constraints; quick check: validate distinct routing patterns emerge at different budget levels
- **Centralized control architecture**: Needed for global optimization of routing policy; quick check: compare against decentralized or static routing baselines
- **Performance-cost trade-off optimization**: Needed to achieve practical deployment under varying resource constraints; quick check: measure Pareto frontier of performance vs. cost
- **Generalization to unseen data**: Needed for real-world applicability beyond training distribution; quick check: test on out-of-distribution tasks

## Architecture Onboarding

**Component Map**: User Query -> Controller LLM -> (Expert Model 1 | Expert Model 2 | ... | Expert Model N) -> Output

**Critical Path**: Query reception → Budget constraint extraction → Task analysis → Expert selection → Expert execution → Response composition

**Design Tradeoffs**: Centralized controller provides global optimization but creates potential bottleneck; specialized experts enable high performance but increase system complexity and cost; RL training enables adaptive behavior but requires careful reward design

**Failure Signatures**: Controller consistently selects suboptimal experts for certain task types; system fails to adapt routing strategies as budget changes; expert models underperform on their intended task categories; generalization breaks down on out-of-distribution tasks

**First 3 Experiments**: 1) Evaluate individual expert performance on each benchmark to establish baseline capabilities; 2) Test controller routing decisions with synthetic queries across budget levels; 3) Measure cost-performance trade-offs on held-out test sets with varying budget constraints

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to math reasoning benchmarks, limiting generalizability to other domains
- Routing decisions based only on textual task description, without runtime characteristics like model loading times
- Fixed budget levels used rather than continuous budget variations, limiting fine-grained control analysis
- Fixed expert model pool limits adaptability to evolving task distributions

## Confidence

**High confidence**: Controller successfully routes queries to specialized experts based on budget constraints

**Medium confidence**: System surpasses best individual expert in high-budget settings (benchmark-dependent)

**Medium confidence**: Learned routing strategies generalize to unseen data (could benefit from more diverse testing)

## Next Checks

1. **Domain Transfer Validation**: Evaluate the system on non-mathematical domains (e.g., code generation, medical diagnosis, legal reasoning) to assess generalizability of cost-performance trade-off mechanisms

2. **Continuous Budget Sensitivity Analysis**: Implement and test the system with fine-grained, continuous budget values rather than discrete budget levels to evaluate smoothness and granularity of cost-performance control

3. **Dynamic Expert Pool Integration**: Test system adaptability by periodically introducing new expert models or removing underperforming ones during operation to assess whether controller can integrate or replace experts without retraining