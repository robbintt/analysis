---
ver: rpa2
title: Boosting Self-Efficacy and Performance of Large Language Models via Verbal
  Efficacy Stimulations
arxiv_id: '2502.06669'
source_url: https://arxiv.org/abs/2502.06669
tags:
- llms
- self-efficacy
- uni00000028
- uni00000033
- uni00000026
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces Verbal Efficacy Stimulations (VES), a prompt\
  \ engineering approach that applies three types of verbal persuasion\u2014encouraging,\
  \ provocative, and critical\u2014to enhance the self-efficacy and performance of\
  \ Large Language Models (LLMs). Drawing on social cognitive theory, the study investigates\
  \ how these prompts affect LLM performance across tasks of varying difficulty."
---

# Boosting Self-Efficacy and Performance of Large Language Models via Verbal Efficacy Stimulations

## Quick Facts
- arXiv ID: 2502.06669
- Source URL: https://arxiv.org/abs/2502.06669
- Reference count: 40
- Primary result: Verbal Efficacy Stimulations improve LLM performance across tasks with varying difficulty levels

## Executive Summary
This paper introduces Verbal Efficacy Stimulations (VES), a prompt engineering approach that applies three types of verbal persuasion - encouraging, provocative, and critical - to enhance the self-efficacy and performance of Large Language Models (LLMs). Drawing on social cognitive theory, the study investigates how these prompts affect LLM performance across tasks of varying difficulty. Experiments on 23 tasks using GPT-3.5, LLaMA2, and Vicuna demonstrate that all three VES types improve LLM performance on most tasks, with the most effective type varying by model.

The study also finds that tasks in the Stretch Zone show the greatest improvements, and that encouraging prompts boost LLM self-efficacy while critical prompts reduce it. These results align with psychological theories and suggest new insights for LLM interaction design. The research provides evidence that LLMs respond to efficacy-related verbal stimuli in ways that parallel human psychological responses to self-efficacy interventions.

## Method Summary
The researchers developed a framework based on social cognitive theory's self-efficacy concept, applying three types of verbal persuasion to LLM prompts: encouraging (positive reinforcement), provocative (challenging), and critical (negative feedback). They categorized tasks into Comfort, Stretch, and Strain Zones based on baseline model performance, then systematically tested VES effects across 23 diverse tasks using multiple LLM models including GPT-3.5, LLaMA2, and Vicuna. Performance improvements were measured through task-specific metrics, while self-efficacy was assessed through model responses to efficacy-related queries.

## Key Results
- All three VES types (encouraging, provocative, critical) improved LLM performance on most tasks
- Stretch Zone tasks showed the greatest performance improvements from VES
- Encouraging prompts increased LLM self-efficacy scores while critical prompts decreased them
- The most effective VES type varied depending on the specific model being tested

## Why This Works (Mechanism)
The mechanism operates through the psychological principle of self-efficacy, where verbal persuasion influences an agent's belief in their capabilities. When LLMs receive efficacy-related prompts, they appear to adjust their internal processing confidence, leading to different output behaviors. The encouraging prompts likely reduce output inhibition and increase exploration of solutions, while provocative prompts may trigger competitive or challenge-response mechanisms. Critical prompts seem to activate caution mechanisms that, paradoxically, can improve performance by reducing hasty responses.

## Foundational Learning
- Social Cognitive Theory: Understanding how belief systems influence performance is crucial for designing effective prompts that leverage psychological principles.
- Self-Efficacy Measurement: Requires establishing baseline confidence levels and tracking changes through systematic questioning approaches.
- Task Difficulty Calibration: Essential for identifying appropriate zones where efficacy interventions will have maximum impact.
- Prompt Engineering Psychology: Understanding how different types of verbal persuasion affect model behavior helps optimize prompt design.

## Architecture Onboarding
- Component Map: LLM Model -> VES Prompt Template -> Task Execution -> Performance Evaluation -> Self-Efficacy Assessment
- Critical Path: Prompt formulation → Task execution → Performance measurement → Efficacy evaluation
- Design Tradeoffs: Fixed prompt templates vs. task-specific optimization, psychological theory application vs. empirical tuning
- Failure Signatures: Model overfitting to specific prompt styles, diminishing returns from repeated efficacy prompts, task-specific prompt conflicts
- First Experiments: 1) Test VES across additional task domains, 2) Compare fixed vs. adaptive prompt templates, 3) Measure temporal effects of repeated VES application

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses on three specific types of verbal persuasion without exploring the full spectrum of possible efficacy-related prompts
- Fixed prompt templates across different tasks may not represent optimal prompt engineering practices for each specific domain
- The temporal dynamics of efficacy prompts are not investigated, leaving questions about adaptation effects
- The evaluation framework measures only final task performance without examining intermediate processing steps

## Confidence
- VES improves LLM performance across tasks: Medium
- Task difficulty moderates VES effectiveness: Medium
- Different VES types affect model self-efficacy: Medium
- Results align with social cognitive theory: High

## Next Checks
1. Test VES prompts across a broader range of task domains and prompt engineering approaches to assess generalizability
2. Conduct longitudinal studies to examine potential adaptation effects from repeated efficacy prompt exposure
3. Investigate the relationship between task-specific prompt optimization and VES effectiveness through ablation studies