---
ver: rpa2
title: 'MI-PRUN: Optimize Large Language Model Pruning via Mutual Information'
arxiv_id: '2601.07212'
source_url: https://arxiv.org/abs/2601.07212
tags:
- blocks
- pruning
- arxiv
- information
- block
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of compressing large language
  models (LLMs) through block pruning, which removes entire blocks to achieve inference
  acceleration. Existing block pruning methods suffer from instability due to reliance
  on calibration-dependent metrics and often use greedy algorithms that fail to find
  globally optimal solutions.
---

# MI-PRUN: Optimize Large Language Model Pruning via Mutual Information

## Quick Facts
- arXiv ID: 2601.07212
- Source URL: https://arxiv.org/abs/2601.07212
- Reference count: 11
- Primary result: MI-PRUN achieves better performance than baselines like ShortGPT, SliceGPT, and LLM-Pruner across multiple benchmarks while maintaining most of the original model's capabilities with significant compression ratios

## Executive Summary
This paper addresses the problem of compressing large language models (LLMs) through block pruning, which removes entire blocks to achieve inference acceleration. Existing block pruning methods suffer from instability due to reliance on calibration-dependent metrics and often use greedy algorithms that fail to find globally optimal solutions. The proposed method, MI-PRUN, leverages mutual information to identify redundant blocks by measuring transitions in hidden states, providing a more stable approach than cosine similarity. It incorporates the Data Processing Inequality (DPI) to relate the importance of contiguous blocks to individual blocks. Additionally, MI-PRUN introduces the Fast-Block-Select algorithm that iteratively updates block combinations to achieve a globally optimal solution while significantly improving efficiency. Experimental results on Llama2 and Qwen models demonstrate superior performance across multiple benchmarks while achieving significant compression ratios.

## Method Summary
MI-PRUN introduces a novel approach to block pruning by leveraging mutual information (MI) to measure the importance of transformer blocks. The method calculates MI between consecutive hidden states to identify redundant blocks, providing more stability than traditional cosine similarity metrics. It applies the Data Processing Inequality to relate the importance of contiguous block sequences to individual blocks. The Fast-Block-Select algorithm iteratively updates block combinations to find globally optimal pruning solutions rather than relying on greedy approaches. This framework is evaluated on Llama2 and Qwen models across multiple classification benchmarks, demonstrating superior performance compared to existing block pruning methods while achieving significant compression ratios.

## Key Results
- MI-PRUN outperforms baselines including ShortGPT, SliceGPT, and LLM-Pruner across multiple benchmarks
- The method maintains most of the original model's capabilities while achieving significant compression ratios
- Fast-Block-Select algorithm provides improved efficiency over greedy block selection methods

## Why This Works (Mechanism)
MI-PRUN works by leveraging mutual information to measure the importance of transformer blocks. Unlike cosine similarity, which can be unstable with limited calibration data, mutual information provides a more robust measure of the relationship between consecutive hidden states. By applying the Data Processing Inequality, the method can infer the importance of individual blocks from the importance of their sequences. The Fast-Block-Select algorithm then uses this information to iteratively find optimal block combinations, avoiding the local optima that plague greedy approaches. This combination of stable importance metrics and global optimization enables more effective compression without sacrificing model performance.

## Foundational Learning
- **Mutual Information**: A measure of the dependence between two random variables, crucial for quantifying the importance of block transitions
  - *Why needed*: Provides a stable metric for block importance that doesn't rely on calibration data like cosine similarity
  - *Quick check*: Verify that MI remains consistent across different sample sizes of calibration data

- **Data Processing Inequality (DPI)**: States that processing cannot increase information, used to relate block sequence importance to individual block importance
  - *Why needed*: Enables inference of individual block importance from sequence importance measurements
  - *Quick check*: Confirm that MI(A,C) ≤ MI(A,B) when C is a function of B

- **Block Pruning**: Removing entire transformer blocks to compress models while preserving functionality
  - *Why needed*: Reduces computational cost and memory requirements for inference
  - *Quick check*: Ensure that pruned models maintain performance on downstream tasks

## Architecture Onboarding

**Component Map**: Input data -> MI calculation between hidden states -> DPI application -> Block importance ranking -> Fast-Block-Select algorithm -> Pruned model

**Critical Path**: The critical path involves calculating mutual information between consecutive hidden states, applying DPI to establish block importance relationships, and using Fast-Block-Select to find the optimal block combination. The MI calculation is the most computationally intensive step and could become a bottleneck with very large models or limited computational resources.

**Design Tradeoffs**: MI-PRUN trades computational complexity in the MI calculation phase for more stable and globally optimal pruning decisions. This approach requires more sophisticated optimization compared to greedy methods but achieves better overall results. The method assumes that mutual information provides a reliable importance signal across different types of transformer architectures, which may not hold for all model variants.

**Failure Signatures**: The method may fail when mutual information estimates become unreliable due to insufficient calibration data or when the DPI assumptions don't hold for certain block configurations. Performance degradation is likely to appear as increased error rates on tasks that depend heavily on the pruned blocks. Computational inefficiency may manifest as excessive runtime during the MI calculation phase, particularly for very large models or when using high-dimensional hidden states.

**3 First Experiments**:
1. Verify that mutual information between consecutive hidden states is more stable than cosine similarity across different calibration dataset sizes
2. Test the DPI application by confirming that MI(A,C) ≤ MI(A,B) holds for various block sequences
3. Evaluate Fast-Block-Select's efficiency by comparing its runtime and solution quality against greedy block selection on a small-scale model

## Open Questions the Paper Calls Out
None

## Limitations
- Computational efficiency gains from Fast-Block-Select need independent verification and may be dataset-dependent
- Mutual information calculation relies on KL divergence approximations, which can be unstable with limited data
- The block-pruning framework may not generalize well to non-Transformer architectures or models with different attention mechanisms

## Confidence

**High Confidence**: The theoretical foundation connecting mutual information and block importance through DPI is sound. The experimental methodology follows standard practices for LLM pruning evaluation.

**Medium Confidence**: Claims about superior performance relative to baselines are reasonable given the results, though the baselines may not represent the state-of-the-art in block pruning. The compression-accuracy trade-offs are consistent with expectations for this class of methods.

**Low Confidence**: The stability improvements over cosine similarity metrics require more rigorous statistical validation across multiple random seeds. The computational efficiency claims for Fast-Block-Select need independent replication.

## Next Checks

1. Replicate the KL divergence stability experiments using different sample sizes and verify that mutual information estimates remain consistent across varying amounts of calibration data.

2. Conduct ablation studies isolating the contribution of mutual information from other components (DPI application, block selection strategy) to quantify their individual impact on performance.

3. Test the method on a generative benchmark (e.g., summarization or question answering with free-form responses) to evaluate whether block pruning maintains generation quality, not just classification accuracy.