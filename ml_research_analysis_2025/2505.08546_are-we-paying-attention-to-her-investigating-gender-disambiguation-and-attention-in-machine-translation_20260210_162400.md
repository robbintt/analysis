---
ver: rpa2
title: Are We Paying Attention to Her? Investigating Gender Disambiguation and Attention
  in Machine Translation
arxiv_id: '2505.08546'
source_url: https://arxiv.org/abs/2505.08546
tags:
- gender
- attention
- translation
- linguistics
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses gender bias in neural machine translation
  (NMT) by proposing a new evaluation metric called Minimal Pair Accuracy (MPA) to
  measure how consistently models integrate contextual gender cues for gender disambiguation.
  The method involves constructing minimal pairs from the WinoMT dataset where sentences
  differ only in the gendered pronoun and evaluating whether the model adjusts the
  target gender accordingly.
---

# Are We Paying Attention to Her? Investigating Gender Disambiguation and Attention in Machine Translation

## Quick Facts
- arXiv ID: 2505.08546
- Source URL: https://arxiv.org/abs/2505.08546
- Reference count: 19
- Key outcome: Introduces Minimal Pair Accuracy (MPA) metric revealing NMT models struggle to consistently integrate contextual gender cues, showing asymmetric bias favoring masculine cues

## Executive Summary
This paper investigates how neural machine translation models handle gender disambiguation when translating from English to Italian. The authors propose a novel Minimal Pair Accuracy (MPA) metric that measures whether models consistently adjust target gender based on contextual gender cues (pronouns) rather than defaulting to stereotypical interpretations. Testing three state-of-the-art models (OPUS-MT, NLLB-200, mBART) on the WinoMT dataset, they find all models exhibit significant failures in leveraging contextual cues, with a notable asymmetry: models more easily override feminine defaults with masculine cues than vice versa. Attention analysis reveals that while all models encode gender information, masculine cues elicit more diffused attention patterns compared to the more localized responses to feminine cues.

## Method Summary
The authors evaluate three pre-trained encoder-decoder NMT models (OPUS-MT, NLLB-200, mBART) on English-to-Italian translation using the WinoMT challenge set. They implement Minimal Pair Accuracy (MPA) by creating sentence pairs that differ only in gendered pronouns and measuring whether the model correctly adjusts the target gender in both sentences. For attention analysis, they extract encoder self-attention weights between profession nouns and pronouns in accurately translated minimal pairs, averaging these weights across subwords and instances. They use fast_align for word alignment and morphological analysis to extract grammatical gender from Italian translations. The analysis focuses on attention patterns across layers and heads, particularly examining how masculine versus feminine cues are processed differently.

## Key Results
- All three models (OPUS-MT, NLLB-200, mBART) show low MPA scores (6-38%), indicating failure to consistently integrate gender cues
- Models exhibit asymmetric behavior: significantly easier to override stereotypically feminine defaults with masculine cues than vice versa
- Attention analysis shows feminine cues elicit more concentrated, localized attention while masculine cues produce diffused, distributed patterns
- Gender information is encoded at different depths across models: early layers (OPUS-MT), mid-to-deep (NLLB-200), deeper layers (mBART)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NMT models encode gender information but inconsistently integrate contextual cues, defaulting to stereotypical patterns with asymmetric behavior.
- Mechanism: Encoder self-attention heads can show the profession noun attending to gender pronouns, but this attention is not uniformly reliable. Models often default to learned statistical associations rather than consistently using pronoun cues. A key asymmetry exists: models more readily override a stereotypically-female default with a masculine cue than a stereotypically-male default with a feminine cue.
- Core assumption: Attention strength from profession to pronoun is a meaningful proxy for how much the model considers that gender cue. The WinoMT dataset's stereotypical assignments represent primary learned biases.
- Evidence anchors: Abstract states models "ignore available gender cues in most cases in favor of (statistical) stereotypical gender interpretation" and "masculine cues elicit a more diffused response compared to the more concentrated and specialized responses to feminine gender cues." Section 5.2 shows overriding stereotypically male-dominated professions is more difficult. Section 7.1 reveals MPA "uncovers another systematic asymmetry... and exposes a persistent male-as-norm bias."
- Break condition: This mechanism is challenged if a model successfully overrides a stereotypically-male profession with a feminine cue as successfully as the reverse. The attention patterns vs. statistical priors explanation is interpretive.

### Mechanism 2
- Claim: Minimal Pair Accuracy (MPA) more effectively measures contextual cue integration than traditional accuracy metrics.
- Mechanism: MPA creates minimal pairs differing only in gendered pronouns and measures the proportion of cases where the model correctly adjusts target gender for both sentences. This measures consistency in using cues rather than just getting single translations "correct" (which could be due to luck or stereotype).
- Core assumption: Minimal pair construction properly isolates the effect of gender cues on translation output. Any change in translated gender between pairs is caused by pronoun change.
- Evidence anchors: Abstract states "traditional evaluation metrics do not fully capture the extent to which these systems integrate contextual gender cues." Section 1 identifies MPA as measuring "whether models consistently rely on gender cues for gender disambiguation, rather than defaulting to learned priors." Section 5.2 defines MPA as measuring "how consistently the models integrate contextual gender cues."
- Break condition: MPA's effectiveness depends on minimal pair construction validity. If other sentence factors influence translation, the metric's validity is compromised.

### Mechanism 3
- Claim: Distinct attention patterns are associated with masculine versus feminine gender cues, potentially reflecting different processing approaches.
- Mechanism: Attention analysis isolates encoder self-attention weights from profession noun to pronoun. Feminine cues elicit concentrated, localized attention in specific heads, while masculine cues produce diffused, distributed attention across heads and layers. NLLB-200 shows different asymmetry with distinct heads specializing in different genders.
- Core assumption: Average attention weights from profession to pronoun are valid indicators of information flow and processing importance. Analysis relies on subset of "accurate minimal pairs."
- Evidence anchors: Abstract concludes "masculine cues elicit a more diffused response compared to the more concentrated and specialized responses to feminine gender cues." Section 6.2 Results and Analysis details different patterns: "feminine pronouns elicit more localized activations, while masculine ones tend to receive weaker, more dispersed attention."
- Break condition: Authors note this is "exploratory" analysis and caution attention patterns "should not be taken as definitive explanations of model decision-making." Patterns could be influenced by dataset imbalance where feminine entities are predominantly in pro-stereotypical examples.

## Foundational Learning

- Concept: **Self-Attention in Transformers**
  - Why needed here: The paper's primary causal analysis examines self-attention weights. Self-attention allows each token to weigh the importance of all other tokens, creating contextualized representations. The analysis focuses on how profession noun representations are influenced by gender cue pronouns.
  - Quick check question: In a Transformer encoder's self-attention layer, what determines how much a given token (e.g., "engineer") incorporates information from another token (e.g., "she") in its final representation?

- Concept: **Encoder-Decoder Architecture for MT**
  - Why needed here: The study analyzes three encoder-decoder models. Understanding encoder (processing source) and decoder (generating target) roles is crucial. Focus is on encoder self-attention because gender cue appears after target word in source, making decoder self-attention unable to capture dependency.
  - Quick check question: When translating "The housekeeper... he..." from English to Italian, why does the paper focus on encoder self-attention rather than decoder self-attention to understand how the model links "housekeeper" to "he"?

- Concept: **Grammatical Gender Agreement**
  - Why needed here: The core problem exists because Italian requires explicit grammatical gender on nouns and modifiers (e.g., *il* bibliotecario vs. *la* bibliotecaria), while English does not. The model must correctly infer this gender from context.
  - Quick check question: When translating from English (with pronoun-based gender cues) to Italian (with morphological gender agreement), what specific "decision" must the NMT model make for an ambiguous profession noun like "librarian"?

## Architecture Onboarding

- Component map: WinoMT sentences -> Encoder (self-attention processing) -> Encoder layers (6-12) with multiple attention heads (8-16) -> Final encoder representations -> Decoder (cross-attention) -> Target translation

- Critical path:
  1. Source sentence fed into Encoder
  2. At each layer and head, self-attention computed (profession token can attend to pronoun token)
  3. Final encoder representations produced
  4. Decoder uses representations via cross-attention to generate target translation
  5. Analysis intercepts step 2, extracting and averaging attention weights from profession to pronoun across accurate minimal pairs

- Design tradeoffs:
  1. **Evaluation Metric (MPA)**: Tradeoff between comprehensiveness and simplicity. MPA is strict, binary measure of consistency on specific examples. Provides clear signal on cue integration but may not capture full diversity of real-world sentences.
  2. **Interpretability Method (Attention Analysis)**: Tradeoff between ease of use and causal certainty. Attention weights are directly accessible and interpretable but are correlational, not causal. Don't definitively prove why decisions were made.
  3. **Dataset (WinoMT)**: Tradeoff between control and ecological validity. Synthetic, controlled nature is perfect for isolating gender cue effect but may not reflect messy, ambiguous real-world sentences.

- Failure signatures:
  1. **Low Minimal Pair Accuracy (MPA)**: Model translates one sentence correctly but fails on its minimal pair (e.g., correctly translates "The librarian... she..." as *la bibliotecaria* but translates "The librarian... he..." as *la bibliotecaria* instead of *il bibliotecario*). Signals failure to integrate gender cue.
  2. **Stereotypical Default**: Model consistently uses wrong gender in anti-stereotypical cases (e.g., always translating "The mechanic... she..." with masculine form). Indicates over-reliance on statistical priors over context.
  3. **Asymmetric Attention**: Different attention patterns between masculine and feminine cues may correlate with asymmetric disambiguation performance.

- First 3 experiments:
  1. **Replicate MPA Evaluation**: Load WinoMT dataset and three pre-trained models from HuggingFace. Generate translations for all three splits (REG, PRO-S, ANTI-S). Implement MPA calculation logic: for each sentence, identify profession and pronoun, translate, extract gender of translated profession, and calculate accuracy over minimal pairs.
  2. **Attention Heatmap Visualization**: For model with accessible attention weights, take small batch of accurately translated minimal pairs. Extract encoder self-attention weights, specifically looking at attention from profession token to pronoun token. Plot across layers and heads to replicate observed diffuse (masculine) vs. localized (feminine) patterns.
  3. **Stereotype Intervention**: Select subset of anti-stereotypical sentences where model fails. Perform simple intervention like fine-tuning on small, balanced corpus or manually inspecting which attention heads have weakest signal. Tests paper's suggestion for targeted interventions.

## Open Questions the Paper Calls Out
None

## Limitations
- Analysis relies on correlational evidence from attention weights rather than causal interventions
- MPA metric assumes controlled minimal pair construction adequately isolates gender cue effects
- Study focuses exclusively on English-to-Italian translation and three specific models
- Attention analysis uses average threshold (0.08) that may not capture full complexity of gender information flow

## Confidence
- **High Confidence**: Core finding that NMT models struggle to consistently integrate contextual gender cues beyond learned stereotypes is well-supported across all three models and evaluation methods. Observed male-as-norm bias asymmetry is also robustly demonstrated.
- **Medium Confidence**: Attention analysis showing distinct patterns for masculine versus feminine cues is plausible but should be interpreted cautiously. While patterns are observed, causal interpretation linking these patterns to disambiguation asymmetry remains speculative.
- **Low Confidence**: Mechanism explanation that attention pattern differences directly cause asymmetric disambiguation behavior is the weakest claim. Paper presents this as exploratory and correlational.

## Next Checks
1. **Cross-Lingual Replication**: Test MPA metric and attention analysis on at least two additional language pairs (e.g., English to Spanish and English to German) to assess whether observed patterns generalize beyond Italian.

2. **Causal Intervention Study**: Design intervention experiment where specific attention heads or layers identified in analysis are selectively modified or ablated to test whether these components are truly necessary for gender disambiguation, moving beyond correlational evidence.

3. **Real-World Corpus Evaluation**: Apply MPA metric to naturally occurring parallel corpus with gender-ambiguous professions and explicit gender cues to validate whether synthetic WinoMT findings hold in more realistic translation scenarios.