---
ver: rpa2
title: 'Hybrid Dialogue State Tracking for Persian Chatbots: A Language Model-Based
  Approach'
arxiv_id: '2510.01052'
source_url: https://arxiv.org/abs/2510.01052
tags:
- dialogue
- intent
- user
- state
- slot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a hybrid dialogue state tracking (DST) model
  for Persian chatbots, integrating BERT for slot filling and intent detection, XGBoost
  for intent validation, and GPT for DST and response generation. The model is trained
  and evaluated on a newly developed Persian multi-turn dialogue dataset, addressing
  challenges like intent ambiguity, slot uncertainty, and dialogue topic shifts.
---

# Hybrid Dialogue State Tracking for Persian Chatbots: A Language Model-Based Approach

## Quick Facts
- arXiv ID: 2510.01052
- Source URL: https://arxiv.org/abs/2510.01052
- Authors: Samin Mahdipour Aghabagher; Saeedeh Momtazi
- Reference count: 18
- Primary result: Hybrid DST model achieves 96.13% intent accuracy, 99.56% slot accuracy, and 0.73 JGA on Persian multi-turn dialogues

## Executive Summary
This study introduces a hybrid dialogue state tracking (DST) model for Persian chatbots that integrates BERT for natural language understanding, XGBoost for intent validation, and GPT for dialogue state tracking and response generation. The approach addresses challenges like intent ambiguity, slot uncertainty, and dialogue topic shifts in open-domain multi-turn conversations. A custom Persian multi-turn dialogue dataset was developed and used to train and evaluate the system. The hybrid architecture demonstrates strong performance across multiple metrics, showing improved accuracy and coherence compared to traditional DST approaches.

## Method Summary
The proposed hybrid DST model consists of three main components: (1) BERT-based NLU for joint intent detection and slot filling using token classification; (2) XGBoost-based intent validation that takes NLU output scores as features and classifies intents as confirmed, ambiguous, or unclear; and (3) GPT-based DST with intent-specific prompts that generate structured dialogue states in JSON format including SQL queries and follow-up questions. The system uses a staged pipeline where NLU errors are validated downstream, and ambiguous cases trigger clarification requests. The model was trained on a custom Persian multi-turn dialogue dataset and evaluated using standard DST metrics (JGA, FGA, AGA).

## Key Results
- Intent detection accuracy of 96.13% on custom Persian dataset
- Slot filling accuracy of 99.56% across 20 domains
- DST metrics: JGA 0.73, FGA 1.00, AGA 0.92
- XGBoost intent validation achieved 0.97 F1 for confirmed class but struggled with ambiguous (0.24) and unclear (0.26) classes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: A staged pipeline with specialized models per sub-task outperforms monolithic approaches for Persian DST.
- **Mechanism**: BERT provides contextual embeddings for NLU; XGBoost validates intents using NLU confidence scores; GPT generates structured dialogue states via prompt engineering. Each component handles a distinct failure mode (ambiguity, class imbalance, generative flexibility).
- **Core assumption**: Errors from upstream components can be corrected downstream without cascading failures.
- **Evidence anchors**: Abstract confirms component integration; section 4.6 describes unified architecture; related work supports LLM-based DST with specialized tuning.

### Mechanism 2
- **Claim**: Intent validation with XGBoost reduces downstream errors from ambiguous or low-confidence NLU predictions.
- **Mechanism**: XGBoost takes NLU output scores as features and classifies into validated/ambiguous/unclear. For ambiguous inputs, the system pauses to request clarification rather than proceeding with uncertain state.
- **Core assumption**: Ambiguity can be reliably detected from NLU score distributions via feature engineering.
- **Evidence anchors**: Section 4.3 explains XGBoost selection for imbalanced data; section 5.3.2 shows improved recall for ambiguous class; no direct corpus evidence for this novel application.

### Mechanism 3
- **Claim**: In-context learning with intent-specific prompts enables GPT to generate structured dialogue states without fine-tuning.
- **Mechanism**: Rule-based prompt selection maps detected intent to an optimized prompt template. GPT outputs JSON with dialogue state, SQL query, and follow-up questions.
- **Core assumption**: GPT's multilingual capabilities generalize to Persian without task-specific fine-tuning.
- **Evidence anchors**: Section 4.4 confirms GPT's generating capabilities for Persian; section 4.7.2 identifies best input schedule; corpus shows zero-shot DST achieves 31.5% JGA on MultiWOZ.

## Foundational Learning

- **Concept**: Dialogue State Tracking (DST)
  - **Why needed here**: Core task; must understand that DST maintains slot-value pairs across turns, not just per-turn classification
  - **Quick check question**: Can you explain why DST differs from intent detection?

- **Concept**: Class imbalance handling in classification
  - **Why needed here**: Intent validation faces 96.97% "confirmed" class; requires understanding of weighting, threshold tuning
  - **Quick check question**: How would you adjust a classifier trained on 97% negative examples?

- **Concept**: In-context learning (ICL) for LLMs
  - **Why needed here**: GPT-based DST relies on prompt engineering, not fine-tuning
  - **Quick check question**: What's the difference between fine-tuning and in-context learning?

## Architecture Onboarding

- **Component map**: User Input -> RoBERTa-large (NLU) -> XGBoost (Intent Validator) -> GPT (DST) -> Online Agent (GPT+LangChain) -> Response
- **Critical path**: User input → NLU → Intent Validator → (if validated) DST → Online Agent → Response. If ambiguous/unclear, system asks clarification instead.
- **Design tradeoffs**: Rule-based prompt selection vs. learned retrieval: simpler but less adaptive; pausing for clarification vs. proceeding with uncertainty: higher accuracy but potential user friction; GPT without fine-tuning vs. fine-tuned smaller model: lower engineering cost but API dependency
- **Failure signatures**: Low recall on ambiguous/unclear intents → false confidence in wrong states; prompt-template mismatch → malformed JSON or invalid SQL; intent shift not detected → stale slot values persist in state
- **First 3 experiments**: 1) Replicate NLU training: fine-tune RoBERTa on Persian multi-turn data; verify slot filling accuracy (>95% target); 2) Test intent validation: train XGBoost with/without feature engineering; compare ambiguous-class recall; 3) Validate DST prompt coverage: run GPT on held-out dialogues; manually check JSON structure and SQL validity

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can the intent validation module be optimized to significantly improve the detection of "ambiguous" and "unclear" intents, given the current low F1-scores for these minority classes?
- **Basis in paper**: Tables 2, 3, and 4 demonstrate that while the XGBoost intent validator identifies "confirmed" intents effectively (F1=0.97), it struggles significantly with "ambiguous" (F1=0.24) and "unclear" (F1=0.26) classes.
- **Why unresolved**: The authors acknowledge the class imbalance and attempt feature engineering, yet the recall and precision for critical failure modes (ambiguity) remain low, posing a risk to the system's ability to handle complex dialogue shifts.
- **What evidence would resolve it**: Experimental results showing an intent validation method (e.g., cost-sensitive learning or distinct architectures) that achieves a balanced F1-score > 0.60 across all three intent classes.

### Open Question 2
- **Question**: To what extent does the proposed hybrid architecture generalize to fully open-ended conversational domains that fall outside the 20 defined domains and specific ontology of the current dataset?
- **Basis in paper**: The conclusion states that future work must "extend evaluation to more open-ended conversational areas" beyond the current multi-turn dataset.
- **Why unresolved**: The current model relies on a defined ontology with specific intents and mandatory slots; it is unclear if the GPT-based DST can maintain high JGA (0.73) when faced with undefined user goals or highly dynamic topic shifts.
- **What evidence would resolve it**: Evaluation of the model on a heterogeneous, open-domain Persian dialogue corpus without redefining the ontology, reporting JGA and FGA metrics.

### Open Question 3
- **Question**: Can the proposed model integrate multilingual capabilities and continuous learning mechanisms without compromising the high accuracy achieved by the fine-tuned monolingual components?
- **Basis in paper**: The authors list "enhancing model flexibility via multilingual training" and integrating "continuous learning based on user input" as necessary future endeavors.
- **Why unresolved**: The current pipeline depends heavily on a BERT model fine-tuned specifically for Persian and a static XGBoost validator; introducing dynamic updates or additional languages risks destabilizing the existing high performance (96.13% intent accuracy).
- **What evidence would resolve it**: A study showing the system's performance metrics (Intent Accuracy, JGA) after incrementally training on a multilingual dataset or a data stream of new user inputs.

## Limitations

- The custom Persian multi-turn dialogue dataset is not released, making verification and reproduction impossible
- Critical implementation details are missing: GPT model version, prompt templates, SQL schema, RoBERTa hyperparameters, and XGBoost feature engineering specifics
- The claim of "language model-based" approach is misleading since only GPT uses in-context learning while other components use traditional ML methods
- System relies on GPT API, introducing external dependencies and potential cost/performance variability

## Confidence

- **High confidence**: BERT-based NLU for intent and slot extraction (well-established in NLP literature)
- **Medium confidence**: XGBoost intent validation performance (novel application, limited evaluation scope)
- **Low confidence**: GPT DST prompt effectiveness without fine-tuning (no ablation study, no comparison to fine-tuned alternatives)

## Next Checks

1. **Dataset verification**: Request or reconstruct the Persian multi-turn dialogue dataset with intent/slot annotations; verify domain coverage matches claimed 20 domains.

2. **Model transparency audit**: Obtain complete model configurations—GPT prompt templates, RoBERTa hyperparameters, XGBoost feature engineering pipeline—to enable exact replication.

3. **Ablation study**: Test whether intent validation XGBoost is essential by comparing full pipeline vs. direct GPT DST without intent validation; measure impact on JGA and error propagation.