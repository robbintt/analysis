---
ver: rpa2
title: 'SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm
  Intelligence'
arxiv_id: '2506.15672'
source_url: https://arxiv.org/abs/2506.15672
tags:
- step
- team
- role
- agent
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SwarmAgentic introduces a fully automated framework for generating
  agentic systems using swarm intelligence. It dynamically constructs and optimizes
  agent functionality and collaboration from scratch, requiring only a task description
  and objective function.
---

# SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence

## Quick Facts
- arXiv ID: 2506.15672
- Source URL: https://arxiv.org/abs/2506.15672
- Reference count: 40
- Primary result: SwarmAgentic achieves 261.8% relative improvement over ADAS on TravelPlanner benchmark

## Executive Summary
SwarmAgentic introduces a fully automated framework for generating agentic systems using swarm intelligence. It dynamically constructs and optimizes agent functionality and collaboration from scratch, requiring only a task description and objective function. The method adapts Particle Swarm Optimization to a language-driven design space, using LLM-guided flaw identification and iterative refinement. Evaluated on six real-world tasks involving high-level planning and multi-agent coordination, SwarmAgentic demonstrates the effectiveness of full automation in structurally unconstrained tasks and marks a significant step toward scalable, autonomous agentic system design.

## Method Summary
SwarmAgentic generates agentic systems by adapting Particle Swarm Optimization to a language-driven search space. It maintains a population of candidate systems (particles), each encoding agent roles and collaborative workflows as structured text. The system uses an LLM optimizer to identify flaws through evaluation, then updates particle positions via velocity adjustments that incorporate failure memory, personal best guidance, and global best guidance. This process iterates to refine agent configurations and collaboration structures jointly, optimizing for a given objective function without requiring pre-defined templates or human intervention in the design process.

## Key Results
- SwarmAgentic achieves a 261.8% relative improvement over ADAS on the TravelPlanner benchmark
- The system consistently outperforms all baseline methods across six real-world tasks
- Ablation studies show the failure-aware velocity update mechanism provides significant performance gains

## Why This Works (Mechanism)

### Mechanism 1: Failure-Aware Velocity Update
A failure-aware velocity update mechanism allows targeted self-optimization by learning from past unsuccessful modifications. The system records failed modifications from the previous iteration and uses an LLM to analyze these alongside previous and current identified flaws. This process detects persistent flaws and ineffective corrections, generating a refined velocity update that explicitly avoids repeating suboptimal adjustments. The core assumption is that an LLM can effectively identify a causal link between a past adjustment plan and a continued or new flaw, and then propose a distinct, better adjustment.

### Mechanism 2: Joint Optimization of Agent Functionality and Collaboration
Jointly optimizing agent functionality and collaboration structures as interdependent components improves system performance more than optimizing them separately. The system represents each agentic system as a particle encoding both agent sets and collaborative structures. Position updates apply structural transformations to both components simultaneously through Agent-Level Adaptation (modifying roles, responsibilities, policies) and Collaborative Structures Reconfiguration (optimizing task sequencing, dependencies). The core assumption is that high-performing systems emerge from a co-dependent relationship where the best workflow depends on agent capabilities and vice versa.

### Mechanism 3: PSO in Non-Differentiable Language Space
A population-based search over structured language representations can effectively navigate a non-differentiable design space. Instead of a single agent or sequential optimization, SwarmAgentic maintains a population of candidate systems evolved via velocity and position updates reinterpreted as semantic, LLM-guided transformations on structured text. This balances exploration (swarm diversity, high-temperature initialization) and exploitation (personal/global best guidance). The core assumption is that PSO principles can be mapped effectively to a language-based search space.

## Foundational Learning

- **Particle Swarm Optimization (PSO)**: Why needed here: It's the core algorithmic inspiration. Understanding how PSO balances exploration (via population) and exploitation (via personal and global guides) is essential to grasp how SwarmAgentic searches for optimal configurations. Quick check question: In standard PSO, how does the `g_best` (global best) term influence a particle's movement?

- **Agentic System as a Searchable Artifact**: Why needed here: The key innovation is treating an entire agentic system (agents + collaboration graph) not as fixed code but as a structured, textual "position" in a search space. Quick check question: What are the two interdependent components of an agentic system that SwarmAgentic optimizes jointly?

- **LLM-based Optimization in a Non-Differentiable Space**: Why needed here: SwarmAgentic operates on symbolic text, which lacks gradients. It replaces gradient-based updates with LLM-guided transformations, making understanding of this non-gradient optimization critical. Quick check question: Why can't traditional gradient descent be used to optimize the configuration of an agentic system in SwarmAgentic?

## Architecture Onboarding

- **Component map**: Swarm Controller -> N Particles (each with System Config and Velocity) -> LLM Optimizer (LLM_init_team, LLM_eval, LLM_fail, LLM_pers, LLM_glob, LLM_vel, LLM_pos) -> Fitness Function -> Team Class

- **Critical path**: Initialization (LLM_init_team creates x_i^(0)) -> Evaluation (run task, get score J) -> Flaw Identification (LLM_eval -> LLM_flaw) -> Velocity Update (composite LLM calls for failure, personal, and global guidance -> LLM_vel) -> Position Update (LLM_pos applies changes) -> Loop for T iterations. Global best g updates when a particle finds a new high score.

- **Design tradeoffs**: Autonomy vs. Convergence Speed. By avoiding inductive priors like domain-specific templates, SwarmAgentic gains generality for open-ended tasks but may converge slower on structured problems. Computational Cost: Maintaining a population (N=5) and iterative LLM calls is expensive. Ablation studies show performance scales with iteration count.

- **Failure signatures**: 1. Stagnation: System score stops improving. 2. Incoherent Configurations: Generated systems contain contradictory policies or workflows that fail at runtime. 3. Ignoring Feedback: Identified flaws are not addressed by subsequent updates.

- **First 3 experiments**:
  1. Reproduce TravelPlanner Ablation: Implement the main loop with N=5, T=3 on TravelPlanner. Confirm the system can initialize a valid team and improve its score at least once.
  2. Isolate Velocity Components: Run optimizer on a simpler task (e.g., Creative Writing) with each velocity component disabled in turn to reproduce Table 5 results.
  3. Cross-Model Transfer Test: Take the best system discovered using GPT-4o-mini optimizer and evaluate directly on Creative Writing using a different executor LLM (e.g., Claude-3.5-sonnet) to test architectural robustness.

## Open Questions the Paper Calls Out

- How can inductive priors be integrated into the initialization phase to accelerate convergence in structured domains without compromising the framework's flexibility? The current design prioritizes open-ended generalization by starting from scratch, which may be inefficient for tasks where domain-specific templates are known to be effective.

- To what extent does the iterative refinement process mitigate the propagation of factual hallucinations generated by the optimizer LLM? While the "Failure-Aware Velocity Update" uses feedback to correct flaws, it is not demonstrated whether this mechanism can distinguish between valid flaws and hallucinated errors generated by the LLM itself.

- Can the text-based optimization space be effectively mapped to embodied or multimodal environments requiring physical grounding? The method relies on "language-based transformations" for velocity and position updates, which lack the spatial or sensorimotor representations necessary for physical task planning.

## Limitations

- The framework generates agentic systems as structured text, but validation depends on the LLM's ability to execute generated code without errors, creating a potential failure point between configuration and executable runtime.
- Key optimization steps rely on LLM outputs, making result reproducibility challenging due to minor prompt or model variations that could lead to significantly different system trajectories.
- While joint optimization is claimed beneficial, the combinatorial growth of possible configurations may limit scalability to larger agent populations or more complex tasks.

## Confidence

- **High Confidence**: The relative performance improvement (261.8% over ADAS on TravelPlanner) and consistent outperformance across all baselines are well-supported by reported results.
- **Medium Confidence**: Core mechanisms are described in detail, but their effectiveness depends on LLM generalization and precise implementation of parsing and fitness evaluation, which are not fully specified.
- **Low Confidence**: The claim of fully automated system generation is strong, but reliance on human-crafted prompts and potential for LLM hallucination or incoherence introduces uncertainty about true autonomy.

## Next Checks

1. Reproduce a Simplified Ablation: Implement the SwarmAgentic core loop with N=5, T=3 on a simpler task (e.g., Creative Writing). Confirm the system can initialize a valid team and show improvement in at least one iteration.

2. Stress-Test Failure Memory: Design a test where the optimizer is repeatedly given a known failure pattern (e.g., an agent role that is consistently unhelpful). Verify that the failure-aware velocity update effectively avoids regenerating that role or suggests a distinct, valid alternative.

3. Cross-Model Robustness: Take the best-performing system configuration discovered using one LLM (e.g., GPT-4o-mini optimizer) and execute it with a different LLM (e.g., Claude-3.5-sonnet) as the runtime executor. This tests the architectural robustness of the generated system beyond the optimizer's "native" environment.