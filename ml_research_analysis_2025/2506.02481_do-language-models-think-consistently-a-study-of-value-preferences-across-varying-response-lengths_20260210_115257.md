---
ver: rpa2
title: Do Language Models Think Consistently? A Study of Value Preferences Across
  Varying Response Lengths
arxiv_id: '2506.02481'
source_url: https://arxiv.org/abs/2506.02481
tags:
- value
- values
- preferences
- alignment
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines whether value preferences inferred from short-form
  responses align with those expressed in long-form outputs of varying verbosity.
  Using five LLMs across two datasets (DAILYDILEMMAS and OPINION QA), the authors
  find weak correlations between value preferences derived from short- and long-form
  responses, with similarly weak consistency among different long-form generation
  settings.
---

# Do Language Models Think Consistently? A Study of Value Preferences Across Varying Response Lengths

## Quick Facts
- arXiv ID: 2506.02481
- Source URL: https://arxiv.org/abs/2506.02481
- Reference count: 40
- Key outcome: Weak correlations between value preferences inferred from short- and long-form LLM responses, with similarly weak consistency across different verbosity settings

## Executive Summary
This study investigates whether value preferences expressed by language models remain consistent across different response lengths. Using five LLMs and two datasets (DAILYDILEMMAS and OPINION QA), the authors find that value preferences derived from short-form responses show weak correlations with those expressed in long-form outputs. Even alignment methods produce only modest improvements in consistency. The analysis reveals that stronger value preferences correlate with greater diversity and lower specificity in long-form arguments, highlighting challenges in achieving reliable value alignment across different response formats.

## Method Summary
The authors examine value preferences across varying response lengths by analyzing five different LLMs on two datasets. They compare value inferences from short-form responses against those generated at different verbosity levels, including both standard and aligned models. The study employs correlation analysis to measure consistency between value preferences at different lengths and investigates the relationship between value strength and argument characteristics such as diversity and specificity.

## Key Results
- Weak correlations (typically r < 0.3) between value preferences from short- and long-form responses
- Similarly weak consistency among different long-form generation settings
- Alignment methods yield only modest improvements in value preference consistency
- Stronger value preferences correlate with greater argument diversity and lower specificity in long-form responses

## Why This Works (Mechanism)
The weak consistency between short- and long-form value preferences likely stems from the fundamental nature of how language models generate text. When models generate longer responses, they must construct more elaborate arguments and consider multiple perspectives, which may dilute or alter the initial value stance expressed in shorter responses. The generation process involves sampling from probability distributions that can lead to different value emphases depending on the response length and the specific generation settings used.

## Foundational Learning
- **Value inference frameworks**: Understanding how value preferences are extracted from text responses; needed to interpret the consistency measurements; quick check: verify that value classification methods align with established ethical frameworks
- **Correlation analysis**: Statistical methods for measuring relationships between variables; needed to quantify consistency across response lengths; quick check: validate correlation coefficients against appropriate benchmarks
- **Alignment methods**: Techniques for steering model outputs toward desired behaviors; needed to assess whether consistency improvements are possible; quick check: compare alignment effectiveness across different model families
- **Argument diversity metrics**: Measures of how varied or one-dimensional responses are; needed to understand the relationship between value strength and response characteristics; quick check: ensure diversity metrics capture meaningful differences in argumentation style
- **Response specificity measurement**: Techniques for quantifying how detailed or vague responses are; needed to analyze the specificity-diversity relationship; quick check: validate specificity metrics against human judgments
- **Dataset representativeness**: Understanding whether DAILYDILEMMAS and OPINION QA capture the full range of practical LLM use cases; needed to assess generalizability; quick check: compare dataset characteristics against real-world application scenarios

## Architecture Onboarding

Component map:
LLM Models -> Response Generation (short/long) -> Value Inference -> Consistency Analysis -> Correlation Metrics

Critical path:
Model selection → Dataset choice → Response generation at varying lengths → Value preference extraction → Correlation computation → Interpretation of consistency patterns

Design tradeoffs:
The study balances comprehensiveness (multiple models and datasets) against depth of analysis. Using five models provides robust findings but limits the ability to deeply explore individual model behaviors. Similarly, focusing on two datasets enables detailed analysis but raises questions about generalizability to other domains.

Failure signatures:
- Low correlation values might indicate measurement artifacts rather than genuine inconsistency
- Modest alignment improvements could reflect suboptimal alignment method selection rather than fundamental limitations
- The diversity-specificity relationship might be influenced by analytical choices rather than genuine behavioral patterns

Three first experiments:
1. Test whether correlation patterns persist when using alternative value frameworks beyond the ones employed in this study
2. Examine whether different response formats (structured vs. unstructured) yield different consistency patterns
3. Investigate whether fine-tuning on consistency-specific objectives improves cross-length value alignment

## Open Questions the Paper Calls Out
The paper highlights several uncertainties: whether weak correlations reflect fundamental model behavior or measurement artifacts, whether findings generalize beyond the studied datasets and models, whether current alignment methods are suboptimal for this task, and whether weak model-level correlations translate to perceptible inconsistencies in practical applications.

## Limitations
- The evaluation framework may not generalize beyond the specific datasets and value frameworks used
- The modest alignment improvements could reflect either genuine limitations or suboptimal method selection
- The relationship between value strength and argument characteristics may be influenced by analytical choices

## Confidence
High confidence: The empirical finding that correlations between short- and long-form value preferences are weak (r values typically below 0.3) is well-supported by the data and methodology.

Medium confidence: The observation that alignment methods produce only modest consistency improvements could reflect either genuine limitations of current approaches or suboptimal method selection. The diversity-specificity relationship with value strength is similarly plausible but could be influenced by analytical choices.

Low confidence: Whether these findings generalize beyond the studied datasets and models remains uncertain. The theoretical implications about value alignment in practical applications require further validation in real-world settings.

## Next Checks
1. Replicate the correlation analysis using alternative value frameworks (e.g., Moral Foundations Theory) and additional datasets to test generalizability of the weak consistency finding.

2. Test whether different alignment techniques (beyond the ones studied) produce stronger consistency improvements, particularly methods that explicitly encourage value preservation across response lengths.

3. Conduct user studies with real-world applications to validate whether weak model-level correlations translate to perceptible inconsistencies in practical LLM use cases.