---
ver: rpa2
title: 'AgentODRL: A Large Language Model-based Multi-agent System for ODRL Generation'
arxiv_id: '2512.00602'
source_url: https://arxiv.org/abs/2512.00602
tags:
- odrl
- cases
- semantic
- data
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AgentODRL, a multi-agent system for converting
  complex natural language data rights policies into machine-readable ODRL format.
  The system uses an Orchestrator-Workers architecture with specialized agents (Rewriter,
  Splitter, Generator) to handle different structural complexities (simple, parallel,
  recursive) and employs LoRA-enhanced semantic validation and SHACL-based syntax
  correction.
---

# AgentODRL: A Large Language Model-based Multi-agent System for ODRL Generation

## Quick Facts
- arXiv ID: 2512.00602
- Source URL: https://arxiv.org/abs/2512.00602
- Reference count: 9
- Key outcome: Multi-agent system converts complex natural language data rights policies into machine-readable ODRL format with 5.39% grammar and 14.52% semantic score improvements over existing methods

## Executive Summary
This paper introduces AgentODRL, a multi-agent system that converts complex natural language data rights policies into machine-readable ODRL format. The system uses an Orchestrator-Workers architecture with specialized agents (Rewriter, Splitter, Generator) to handle different structural complexities (simple, parallel, recursive). By employing LoRA-enhanced semantic validation and SHACL-based syntax correction, AgentODRL significantly outperforms existing methods, achieving near-perfect grammatical compliance across all tested models while improving semantic accuracy by 14.52% on average.

## Method Summary
AgentODRL uses an Orchestrator-Workers architecture where the Orchestrator classifies input policies by structural complexity (simple, parallel, recursive) and routes them through specialized agents. The Rewriter handles recursive structures by inlining cross-references, the Splitter decomposes parallel structures into independent policy units, and the Generator produces final ODRL output. A LoRA-finetuned semantic validator (Qwen3-4B-Instruct) extracts semantic checkpoints from natural language, while a SHACL validator provides iterative syntax correction. The system was evaluated on a 770-case dataset with 440 simple, 220 parallel, and 110 sequential-dependency cases.

## Key Results
- AgentODRL improves average grammar scores by 5.39% and semantic scores by 14.52% over existing methods
- Achieves near-perfect grammatical compliance: 99.89% (GPT-4.1), 99.36% (GPT-4.1-mini), 92.01% (GPT-4.1-nano)
- Rewriter→Splitter→Generator path achieves 82.00 semantic score on recursive cases vs. 61.53 for Generator alone (GPT-4.1-nano)
- Grammar scores: 99.89% (GPT-4.1), 99.36% (GPT-4.1-mini), 92.01% (GPT-4.1-nano)

## Why This Works (Mechanism)

### Mechanism 1: Conditional Routing Based on Structural Complexity
- Claim: Routing natural language policies through specialized agents based on their structural complexity improves conversion fidelity compared to monolithic processing.
- Mechanism: The Orchestrator Agent classifies input by complexity (simple, parallel, recursive), then dynamically assembles an optimal pathway. Recursive cases trigger the Rewriter to inline cross-references; parallel cases trigger the Splitter to decompose into independent policy units; simple cases route directly to the Generator.
- Core assumption: Different structural complexities require cognitively distinct sub-tasks that single models cannot handle concurrently.
- Evidence anchors:
  - [Section 3] Defines three complexity types with formal characterization of rule information tuples.
  - [Table 2] Shows the Rewriter→Splitter→Generator path achieves 82.00 semantic score on recursive cases vs. 61.53 for Generator alone (GPT-4.1-nano).
  - [corpus] Related work "From Instructions to ODRL Usage Policies" uses ontology-guided single-model approach, lacking multi-agent decomposition.
- Break condition: When Orchestrator misclassifies complexity type, routing to suboptimal paths degrades performance below baseline.

### Mechanism 2: LoRA-Finetuned Semantic Checkpointing
- Claim: A lightweight LoRA-finetuned validator model improves semantic fidelity by forcing the Generator to verify outputs against extracted semantic checkpoints.
- Mechanism: Fine-tune Qwen3-4B-Instruct on 2,380 synthetic samples to extract semantic elements (parties, assets, actions, constraints) into structured lists. The Generator must validate its ODRL output against these checkpoints before finalizing.
- Core assumption: A specialized small model can reliably extract semantic primitives that a larger generative model might overlook or misencode.
- Evidence anchors:
  - [Section 4.2] Reports LoRA parameters (r=16, alpha=32), training for 3 epochs with eval loss=0.0668 vs. train loss=0.129.
  - [Table 1] Semantic-Enhanced strategy improves GPT-4.1-nano from 56.23 to 65.67 semantic score (+16.8%).
  - [corpus] No direct corpus evidence for LoRA-based semantic validation in ODRL generation; this appears novel.
- Break condition: If fine-tuning data doesn't cover edge cases, the validator may miss critical semantic elements or generate false checkpoints.

### Mechanism 3: SHACL-Based Iterative Syntax Correction
- Claim: A closed-loop generate-validate-correct cycle using SHACL constraints achieves near-perfect grammatical compliance.
- Mechanism: The Generator produces initial ODRL; PYSHACL validates against ODRL information model constraints; error reports feed back to the Generator for reflection and revision. Loop continues until validation passes or max attempts (8) reached.
- Core assumption: LLMs can correctly interpret SHACL error messages and make targeted corrections without introducing new errors.
- Evidence anchors:
  - [Section 4.2] Describes the validator-based strategy using PYSHACL library.
  - [Table 1] AOFP achieves grammar scores of 99.89% (GPT-4.1), 99.36% (GPT-4.1-mini), 92.01% (GPT-4.1-nano).
  - [corpus] Related work mentions "Self-Correction Rules" but uses predefined heuristics rather than formal SHACL validation.
- Break condition: Complex errors may require multiple iterations; weaker models hit the 8-attempt limit (GPT-4.1-nano averages 7.32 reflections on recursive cases).

## Foundational Learning

- **ODRL Information Model**: W3C standard representing data rights as policies with Permissions, Prohibitions, and Duties, serialized in RDF/JSON-LD.
  - Why needed here: The entire output space is constrained by ODRL syntax; understanding the schema is prerequisite to debugging validation errors.
  - Quick check question: Can you identify the difference between an ODRL "Agreement" and "Offer" policy type?

- **SHACL (Shapes Constraint Language)**: A W3C language for validating RDF graphs against structural constraints.
  - Why needed here: The syntax correction mechanism relies entirely on SHACL validation; reading error reports requires understanding SHACL path expressions and constraint components.
  - Quick check question: What does a `sh:Violation` result with `sh:minCount 1` indicate about a property?

- **Multi-Agent Task Decomposition**: Architectural pattern where a coordinator breaks complex tasks into specialized subtasks handled by distinct agents.
  - Why needed here: AgentODRL's core contribution is this decomposition; understanding when/why to route matters for debugging and extension.
  - Quick check question: What structural signal would trigger the Rewriter Agent vs. the Splitter Agent?

## Architecture Onboarding

- **Component map**:
  - **Orchestrator Agent**: GPT-4.1-based classifier; inputs NL policy, outputs routing decision + invokes Workers.
  - **Rewriter Agent**: Resolves cross-clause references in recursive structures; outputs self-contained policy text.
  - **Splitter Agent**: Decomposes parallel structures; outputs array of independent policy units with ODRL types (Agreement/Offer/Set).
  - **Generator Agent**: Core ODRL producer; integrates LoRA semantic validator + SHACL syntax validator in iterative loop.
  - **LoRA Validator**: Qwen3-4B-Instruct fine-tuned for semantic extraction; produces checkpoint lists.
  - **SHACL Validator**: PYSHACL-based rule engine; produces validation reports.

- **Critical path**: For recursive cases (most complex): Input → Orchestrator → Rewriter → Splitter → Generator → (LoRA check + SHACL loop) → Output. For simple cases: bypass Rewriter and Splitter entirely.

- **Design tradeoffs**:
  - Token cost vs. accuracy: Full pipeline uses 49.5M tokens vs. 33.9M for Generator-only (Table 2), but achieves +21% semantic improvement.
  - Orchestrator automation vs. optimal routing: Orchestrator averages 80.22 semantic score vs. theoretical ceiling of 88.07, but saves 6-10% tokens by avoiding unnecessary Rewriter/Splitter invocations.
  - Max reflection iterations: Set to 8; higher values improve weak model performance but increase latency and cost.

- **Failure signatures**:
  - **Misrouting**: Recursive case routed directly to Generator shows ~20 point semantic drop (Table 2: 61.53 vs. 82.00).
  - **Reflection ceiling**: GPT-4.1-nano hitting 7+ average reflections indicates model struggling with error correction; consider upgrading to GPT-4.1-mini.
  - **LoRA validator drift**: If semantic scores plateau despite low grammar errors, validator may be generating incomplete checkpoint lists.

- **First 3 experiments**:
  1. **Baseline routing test**: Pass 10 simple + 10 parallel + 10 recursive cases through Generator-only path; establish per-category baseline scores.
  2. **Ablation by component**: Disable Rewriter, then Splitter, then LoRA validator, then SHACL loop; measure delta in grammar/semantic scores per ablation.
  3. **Reflection limit sweep**: Run GPT-4.1-nano on recursive cases with max reflections = {2, 4, 6, 8, 10}; plot convergence rate vs. token cost to find optimal setting.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can AgentODRL maintain high semantic fidelity when applied to real-world legal documents outside the specific "data spaces" domain?
- Basis in paper: [inferred] The abstract and Section 5 state the dataset is "situated within the context of data spaces" and constructed via LLM augmentation of seed cases, rather than sourced from diverse, real-world legal corpora.
- Why unresolved: The system's current validation relies on a LoRA model fine-tuned on this specific synthetic dataset. It is unclear if the semantic checkpoints and ontology mappings generalize to the noise and ambiguity of actual legal contracts (e.g., copyright licenses, privacy policies).
- What evidence would resolve it: Evaluation results from testing AgentODRL on an external, human-curated dataset of real-world legal agreements (e.g., Creative Commons licenses, GDPR clauses) without retraining the LoRA validator.

### Open Question 2
- Question: Can the Orchestrator's dynamic routing logic be improved to eliminate the performance gap compared to manually selected optimal pathways?
- Basis in paper: [inferred] Section 6.3 notes that while the Orchestrator-Workers workflow is more efficient, its average semantic score (80.22) is lower than the theoretical ceiling achieved by the optimal fixed path (88.07).
- Why unresolved: The Orchestrator aims to balance performance with computational cost (token consumption). The data suggests it may occasionally misclassify a use case's complexity or select a sub-optimal path to save resources, thereby sacrificing accuracy.
- What evidence would resolve it: An ablation study analyzing the Orchestrator's misclassification rate on the test set, or a demonstration of an updated routing algorithm that matches the theoretical ceiling while retaining efficiency.

### Open Question 3
- Question: What specific architectural modifications are required to enable smaller, open-source models to reliably handle complex recursive structures?
- Basis in paper: [inferred] Table 1 and Section 6.2 highlight that while AgentODRL improves GPT-4.1-nano significantly, the model still achieves only a 61.53 semantic score on recursive cases, indicating a fundamental struggle with complex dependencies compared to larger models.
- Why unresolved: The paper demonstrates that "strategies notably raise the performance floor," but the semantic score for recursive cases on smaller models remains far below the near-perfect grammar scores, suggesting the logic processing capability is still a bottleneck.
- What evidence would resolve it: Experiments showing that specific enhancements (e.g., chain-of-thought prompting, specialized fine-tuning on recursive logic) allow a model smaller than 10B parameters to achieve >90% semantic accuracy on recursive use cases.

## Limitations
- Dataset construction relies on an unspecified number of "seed cases" augmented by Gemini 2.5 Pro, creating reproducibility barriers
- Semantic evaluation depends on LLM jury scoring against checkpoint lists, introducing potential subjectivity
- Routing accuracy of Orchestrator agent remains unvalidated against human expert classification baselines

## Confidence
- High: SHACL-based syntax correction mechanism (empirical grammar scores 99.89% for GPT-4.1)
- Medium: LoRA-finetuned semantic validation (shows consistent improvement but depends on synthetic training data quality)
- Medium: Orchestrator routing effectiveness (demonstrates clear performance gains but with unexplained 7.85 point gap to optimal routing)

## Next Checks
1. **Routing accuracy audit**: Manually classify 50 random test cases by complexity type and compare against Orchestrator predictions to quantify misclassification rates and their impact on downstream performance.
2. **Reflection iteration analysis**: For each model type (GPT-4.1, GPT-4.1-mini, GPT-4.1-nano), plot semantic score convergence versus reflection attempts to determine if the 8-iteration limit is optimal or unnecessarily constraining weaker models.
3. **Dataset provenance verification**: Reconstruct the augmentation pipeline using the described seed cases and transformation logic to verify that the 770-case dataset maintains the claimed structural complexity distribution and that augmented cases preserve semantic equivalence.