---
ver: rpa2
title: Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal
  Memes Using Large Language Models
arxiv_id: '2508.15810'
source_url: https://arxiv.org/abs/2508.15810
tags:
- hate
- text
- arabic
- memes
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of detecting hope, hate speech,
  offensive language, and emotions in Arabic textual content and memes. The authors
  employ large language models (LLMs) and pre-trained embedding models to tackle three
  tasks: classifying hope/hate speech in Arabic text, performing multi-task detection
  of emotions, offensive language, and hate speech, and detecting hate in Arabic memes.'
---

# Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models

## Quick Facts
- **arXiv ID**: 2508.15810
- **Source URL**: https://arxiv.org/abs/2508.15810
- **Reference count**: 38
- **Primary result**: Fine-tuned LLMs (GPT-4o-mini and Gemini Flash 2.5) achieved macro F1 scores of 72.1%, 57.8%, and 79.6% on Arabic hate speech, emotion, and meme detection tasks respectively

## Executive Summary
This paper tackles the challenge of detecting hope, hate speech, offensive language, and emotions in Arabic textual content and memes. The authors employ large language models (LLMs) and pre-trained embedding models to address three tasks: classifying hope/hate speech in Arabic text, performing multi-task detection of emotions, offensive language, and hate speech, and detecting hate in Arabic memes. The approach involves fine-tuning LLMs such as GPT-4o-mini and Gemini Flash 2.5 on the ArabicNLP MAHED 2025 challenge datasets. The results demonstrate that fine-tuned LLMs, particularly GPT-4o-mini and Gemini Flash 2.5, achieve superior performance with up to 72.1%, 57.8%, and 79.6% macro F1 scores for tasks 1, 2, and 3 respectively. The fine-tuned Gemini Flash 2.5 model secured first place in the Mahed 2025 challenge.

## Method Summary
The authors employed a multi-pronged approach to address three Arabic content detection tasks. For text-based tasks, they fine-tuned large language models (GPT-4o-mini and Gemini Flash 2.5) on the ArabicNLP MAHED 2025 datasets, using a combination of prompt engineering and model adaptation. For the meme detection task, they extracted text from images using OCR and combined this with the image data for multi-modal processing. The LLM fine-tuning process involved training on labeled examples from each task, with careful attention to Arabic language nuances. As a baseline comparison, they also evaluated traditional classifiers (SVM, DNN) combined with pre-trained embedding models like AraBERT and multilingual BERT. The models were evaluated using macro F1 scores, which account for class imbalance across the tasks.

## Key Results
- Fine-tuned GPT-4o-mini achieved 72.1% macro F1 for Task 1 (hope/hate speech classification)
- Gemini Flash 2.5 fine-tuned model achieved 57.8% macro F1 for Task 2 (multi-task emotion/offensive language detection)
- Gemini Flash 2.5 achieved 79.6% macro F1 for Task 3 (hate detection in Arabic memes) and secured first place in Mahed 2025 challenge

## Why This Works (Mechanism)
The success of this approach stems from the powerful pre-training of large language models on diverse text corpora, which provides them with strong semantic understanding capabilities. Fine-tuning these models on Arabic-specific datasets allows them to capture the linguistic nuances and cultural context essential for accurate content moderation. The multi-modal approach for memes leverages both visual and textual information, enabling more comprehensive hate speech detection that single-modality approaches cannot achieve.

## Foundational Learning
- **Fine-tuning vs. Prompting**: Fine-tuning adapts the model's weights to task-specific data, while prompting relies on in-context learning. Fine-tuning generally yields better performance for specialized tasks but requires more computational resources. *Quick check: Compare zero-shot, few-shot, and fine-tuned performance on a validation set.*
- **Macro F1 vs. Micro F1**: Macro F1 calculates metrics per class and averages them, treating all classes equally regardless of size. This is crucial for imbalanced datasets common in hate speech detection. *Quick check: Calculate both metrics to understand class-level performance.*
- **Arabic NLP challenges**: Arabic has multiple dialects, complex morphology, and right-to-left script, making standard models less effective without adaptation. *Quick check: Test model performance across different Arabic dialects.*
- **Multi-modal learning**: Combining visual and textual information for memes captures hate speech that might be missed by text-only approaches. *Quick check: Compare performance of text-only vs. multi-modal models on meme datasets.*
- **Embedding models**: Pre-trained embeddings like AraBERT provide task-agnostic representations that can be used with simpler classifiers. *Quick check: Visualize embedding spaces using t-SNE to verify semantic clustering.*
- **Class imbalance handling**: Hate speech datasets often have skewed distributions, requiring careful evaluation metrics and potentially resampling techniques. *Quick check: Plot class distributions and evaluate precision-recall curves.*

## Architecture Onboarding
**Component Map**: Raw Arabic text/Meme images -> OCR extraction (memes) -> LLM fine-tuning (GPT-4o-mini/Gemini Flash 2.5) -> Prediction output
**Critical Path**: Data preprocessing (tokenization, OCR for memes) -> Fine-tuning LLMs on MAHED datasets -> Inference on test data -> Macro F1 evaluation
**Design Tradeoffs**: Fine-tuning LLMs requires significant computational resources and task-specific data but yields superior performance compared to using pre-trained embeddings with traditional classifiers. The multi-modal approach for memes adds complexity but captures context missed by text-only methods.
**Failure Signatures**: Poor performance on dialect-specific content suggests insufficient dialect coverage in training data. Low scores on certain emotion classes may indicate class imbalance or ambiguous labeling. Failure to detect visual-only hate in memes points to over-reliance on text extraction.
**3 First Experiments**: 1) Compare zero-shot LLM performance against fine-tuned models to quantify fine-tuning benefits. 2) Evaluate different OCR engines for meme text extraction to optimize multi-modal pipeline. 3) Test model performance on dialectical variants of Arabic to identify generalization gaps.

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, which represents a limitation in identifying future research directions for Arabic content moderation.

## Limitations
- Evaluation relies entirely on ArabicNLP MAHED 2025 challenge datasets, raising generalizability concerns
- Does not address potential biases in training data or model outputs for hate speech detection
- Limited comparative analysis between LLMs and traditional approaches, lacking detailed performance metrics

## Confidence
- **High**: Effectiveness of fine-tuned LLMs on specific challenge datasets
- **Medium**: Superiority of LLMs over traditional approaches given limited comparative analysis
- **Medium**: Applicability of these models to broader Arabic content moderation contexts

## Next Checks
1. Test fine-tuned models on independent Arabic datasets from different sources and domains to evaluate generalizability
2. Conduct bias audits to identify potential disparities in model performance across Arabic dialects, genders, and cultural contexts
3. Implement ablation studies to quantify the contribution of different model components (fine-tuning vs. prompting vs. embedding methods) to reported performance