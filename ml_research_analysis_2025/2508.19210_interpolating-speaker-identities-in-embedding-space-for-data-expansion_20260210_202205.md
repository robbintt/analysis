---
ver: rpa2
title: Interpolating Speaker Identities in Embedding Space for Data Expansion
arxiv_id: '2508.19210'
source_url: https://arxiv.org/abs/2508.19210
tags:
- speaker
- data
- inside
- identities
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces INSIDE, a data expansion framework for speaker
  verification that generates synthetic speaker identities by interpolating embeddings
  of real speakers in the latent space. Using spherical linear interpolation, pairs
  of nearby speaker embeddings are blended to create intermediate identities, which
  are then used to synthesize speech via a TTS model.
---

# Interpolating Speaker Identities in Embedding Space for Data Expansion

## Quick Facts
- arXiv ID: 2508.19210
- Source URL: https://arxiv.org/abs/2508.19210
- Reference count: 37
- Primary result: Synthetic speaker identities generated via SLERP interpolation improve speaker verification by up to 5.24% relative EER reduction

## Executive Summary
This paper introduces INSIDE, a data expansion framework for speaker verification that generates synthetic speaker identities by interpolating embeddings of real speakers in the latent space. Using spherical linear interpolation (SLERP), pairs of nearby speaker embeddings are blended to create intermediate identities, which are then used to synthesize speech via a TTS model. The method addresses the challenge of limited speaker diversity in training data, which is costly and raises privacy concerns. Experiments show that INSIDE significantly improves speaker verification performance and also yields gains in gender classification accuracy.

## Method Summary
INSIDE extracts embeddings from real utterances using a TTS speaker encoder, groups them by gender, and selects pairs via nearest-neighbor traversal. SLERP with α=0.5 generates interpolated embeddings, which are fed to a TTS system (YourTTS) to synthesize speech. The synthetic data is combined with original data to train speaker verification or gender classification models. The framework is scalable, controllable, and compatible with existing augmentation methods.

## Key Results
- 5.24% relative improvement in speaker verification EER on VoxCeleb1 test sets
- 13.44% relative gain in gender classification accuracy
- Nearest-neighbor pairing outperforms random pairing (2.76% vs. 1.82% improvement)
- Scalable to 40,000 synthetic identities with 1M samples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Interpolating nearby speaker embeddings via SLERP generates acoustically coherent synthetic identities.
- Mechanism: SLERP preserves unit-norm constraints and angular geometry of the embedding space, producing intermediate points valid for TTS conditioning.
- Core assumption: The embedding space is smooth and locally linear enough that convex combinations lie within regions the TTS decoder has seen.
- Evidence anchors: SLERP equations defined in section III-B; cosine similarity alignment noted; related work uses linear interpolation.
- Break condition: If interpolated embeddings fall in unexplored TTS latent regions, synthesized speech may exhibit artifacts or identity collapse.

### Mechanism 2
- Claim: Nearest-neighbor pair selection improves embedding-space coverage compared to random pairing.
- Mechanism: Layered traversal from closest neighbors outward distributes synthetic identities more uniformly, filling underrepresented regions.
- Core assumption: Filling sparse regions of the embedding space improves generalization more than oversampling dense regions.
- Evidence anchors: INSIDE-NN achieves 2.76% averaged improvement vs. 1.82% for random pairing; optimized pairing yields distribution closer to real data.
- Break condition: If original embeddings cluster heavily in narrow regions, nearest-neighbor interpolation may still produce highly correlated synthetic identities.

### Mechanism 3
- Claim: Synthetic identity expansion improves downstream tasks by increasing identity count without additional collection.
- Mechanism: Scaling to more synthetic identities exposes the model to greater inter-class variability, improving discriminability.
- Core assumption: Synthetic identities are sufficiently distinct from each other and from real identities to constitute meaningful new classes.
- Evidence anchors: ID-Exp achieves 5.24% averaged relative improvement over baseline; also yields 13.44% gain on gender classification.
- Break condition: If synthetic identities are too similar to each other or to real identities, marginal gains diminish.

## Foundational Learning

- Concept: Speaker embedding geometry (hyperspherical structure, cosine similarity)
  - Why needed here: INSIDE relies on SLERP, which assumes embeddings lie on a unit hypersphere; understanding this geometry is essential for debugging interpolation artifacts.
  - Quick check question: Can you explain why linear interpolation might not preserve embedding norms and how this affects cosine similarity?

- Concept: TTS speaker conditioning via embeddings
  - Why needed here: Interpolated embeddings must be consumable by the TTS synthesizer; mismatched embedding spaces cause synthesis failures.
  - Quick check question: Given a pretrained TTS model with a fixed speaker encoder, what happens if you feed it an embedding from a differently trained speaker encoder?

- Concept: Intra-class variability in speaker verification
  - Why needed here: The paper notes synthetic identities exhibit higher intra-identity cosine similarity than real speakers; this distribution mismatch may affect robustness.
  - Quick check question: Why might low intra-class variability in synthetic data harm generalization to real-world speakers?

## Architecture Onboarding

- Component map: Speaker encoder -> Pair selector -> Interpolator -> TTS synthesizer -> Downstream trainer
- Critical path:
  1. Extract embeddings from labeled real data using the TTS speaker encoder
  2. Group by gender; for each embedding, compute cosine distances to others in same group
  3. Build pair pool via layered nearest-neighbor traversal until target pair count T is reached
  4. Apply SLERP (α=0.5) to each pair to generate interpolated embeddings
  5. Synthesize speech using TTS with interpolated embeddings and text corpus
  6. Merge synthetic data with original dataset; train downstream model
- Design tradeoffs:
  - Random vs. nearest-neighbor pairing: NN yields better coverage but requires O(N²) distance computation
  - α value: α=0.5 yields balanced blends; values closer to 0 or 1 produce identities nearer to one source
  - Identity count vs. sample count: More identities improve gains but increase synthesis and storage costs
- Failure signatures:
  - Low-quality synthesis: Check whether embeddings fall outside TTS training distribution
  - No improvement over baseline: Verify gender grouping is applied; cross-gender interpolation may create incoherent identities
  - High intra-identity similarity: Indicates synthetic speakers lack natural variability; consider adding augmentation post-synthesis
- First 3 experiments:
  1. Replicate INSIDE-Syn vs. baseline on VoxCeleb2 dev with ECAPA-TDNN backend; confirm ~1.8% relative gain
  2. Implement nearest-neighbor traversal; compare INSIDE-NN vs. INSIDE-Syn to validate coverage improvement
  3. Scale to ID-Exp (40,000 identities) and measure whether gains saturate or continue improving

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can TTS models with more powerful speaker encoders improve identity interpolation quality and extend performance gains beyond the 5.24% relative improvement ceiling observed with strong SV baselines?
- Basis in paper: Section VI states that "the speaker encoder used in most current TTS systems is relatively lightweight and generally less accurate than those used in state-of-the-art speaker verification models" and suggests exploring TTS models with more powerful speaker encoders.

### Open Question 2
- Question: How can synthetic data generation be modified to better match the intra-class variability (uncertainty) of real speaker distributions, given that synthetic identities show significantly higher same-identity cosine similarity than real speakers?
- Basis in paper: Section VI and Figure 4 document that synthetic identities "exhibit lower intra-class uncertainty compared to real speakers," which "may pose challenges for speaker verification models, particularly in learning to model speaker uncertainty."

### Open Question 3
- Question: Can INSIDE-based data expansion improve performance on other speech-related tasks beyond speaker verification and gender classification, such as emotion recognition or age estimation?
- Basis in paper: Figure 1 includes "Emotion Recognition *" with the parenthetical note "(Emotion-controllable TTS is required)," and the abstract states "the framework shows potential for broader speech-related tasks."

### Open Question 4
- Question: Does language mismatch between English-based synthetic training data and target-domain languages significantly degrade INSIDE's effectiveness for tasks like gender classification?
- Basis in paper: The gender classification results show notably higher error rates on the Private (Southeast Asian languages) and Samrómur Children (Icelandic) datasets, with the authors noting "One possible reason for this is language mismatch, as both datasets differ from the English-based training data."

## Limitations
- Synthetic identities exhibit lower intra-class variability than real speakers, potentially harming robustness
- Performance gains may saturate at higher synthetic identity counts
- Nearest-neighbor pair selection requires O(N²) distance computations, limiting scalability

## Confidence
- **High confidence**: Interpolation using SLERP is geometrically valid and produces intermediate embeddings consumable by TTS
- **Medium confidence**: Nearest-neighbor pair selection improves embedding-space coverage compared to random pairing
- **Medium confidence**: Synthetic identity expansion improves downstream tasks by increasing identity count
- **Low confidence**: The paper does not rigorously test cross-gender interpolation or measure perceptual quality of synthetic identities

## Next Checks
1. Verify embedding space geometry by computing and visualizing interpolated embeddings' distribution in TTS speaker space; check whether interpolated points fall within high-density regions and whether SLERP preserves angular relationships
2. Test cross-gender interpolation in a controlled experiment; compare SV performance and synthetic identity quality against gender-restricted baseline
3. Measure intra-identity variability by synthesizing speech for both real and synthetic identities; compute same-speaker score distributions and compare variability; if synthetic identities have unnaturally low variability, consider adding augmentation post-synthesis to improve robustness