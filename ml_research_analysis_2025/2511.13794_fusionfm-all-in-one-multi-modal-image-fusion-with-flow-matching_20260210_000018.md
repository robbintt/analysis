---
ver: rpa2
title: 'FusionFM: All-in-One Multi-Modal Image Fusion with Flow Matching'
arxiv_id: '2511.13794'
source_url: https://arxiv.org/abs/2511.13794
tags:
- fusion
- image
- tasks
- learning
- fusionfm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational inefficiency and limited
  generalization of existing multi-modal image fusion methods by proposing FusionFM,
  a flow matching-based approach that directly learns the probabilistic transport
  between source and fused image distributions. The method introduces a two-stage
  pseudo-ground-truth generation strategy using fusion priors from multiple state-of-the-art
  models, refined through a dedicated Fusion Refiner module employing divide-and-conquer
  decomposition.
---

# FusionFM: All-in-One Multi-Modal Image Fusion with Flow Matching

## Quick Facts
- **arXiv ID**: 2511.13794
- **Source URL**: https://arxiv.org/abs/2511.13794
- **Reference count**: 40
- **Primary result**: Flow matching-based multi-modal image fusion achieving >200× sampling efficiency with competitive fusion quality and strong downstream task performance

## Executive Summary
This paper introduces FusionFM, a flow matching approach to multi-modal image fusion that replaces iterative diffusion sampling with direct probabilistic transport from source modalities to fused outputs. The method employs a two-stage pseudo-ground-truth generation strategy using multiple state-of-the-art fusion models as teachers, refined through a dedicated Fusion Refiner module. For multi-task scenarios, FusionFM integrates elastic weight consolidation and experience replay mechanisms to mitigate catastrophic forgetting. The approach demonstrates superior performance across diverse fusion tasks while significantly improving computational efficiency compared to diffusion-based alternatives.

## Method Summary
FusionFM formulates image fusion as a direct probabilistic transport problem using flow matching, where the vector field u_t(x|(x_0, x_1)) = x_1 - x_0 defines a straight-line ODE trajectory from summed source modalities to the fused target. The method generates pseudo-ground-truth labels through a two-stage process: first collecting fusion results from multiple SOTA models as priors, then refining them via a dedicated Fusion Refiner module employing divide-and-conquer decomposition. For multi-task scenarios, FusionFM integrates elastic weight consolidation (EWC) and experience replay mechanisms to preserve cross-task performance and mitigate catastrophic forgetting during sequential training.

## Key Results
- Achieves computational efficiency gains of over 200× compared to diffusion-based alternatives through one-shot inference
- Demonstrates competitive fusion quality across diverse tasks (IVF, MIF, MEF, MFF) with downstream applications including semantic segmentation (mIoU up to 73.75%) and object detection (mAP up to 0.968)
- Effectively mitigates catastrophic forgetting in multi-task learning scenarios through combined EWC and experience replay mechanisms

## Why This Works (Mechanism)

### Mechanism 1: Direct Source-to-Fusion Probabilistic Transport
Replacing noise-to-image diffusion with source-to-fusion flow matching reduces sampling cost by >200× while preserving structural consistency. The vector field u_t(x|(x_0, x_1)) = x_1 - x_0 defines a straight-line ODE trajectory from x_0 = x_A + x_B (source modalities summed) to x_1 (fused target). One-step Euler integration suffices because the path is near-linear when sources and targets share semantic structure. Core assumption: The summed source x_A + x_B lies on a manifold close enough to the fusion manifold that linear interpolation approximates valid intermediate images.

### Mechanism 2: Two-Stage Pseudo-Ground-Truth Generation with Fusion Refiner
Aggregating multiple SOTA fusion priors and refining them via decomposition-based enhancement produces supervisory signals that outperform any single teacher model. Stage 1 selects the top-ranked fusion from a candidate pool Q using task-specific scoring (φ). Stage 2 applies a Fusion Refiner: (1) Decomposition Unit splits pseudo-label into modality-specific components, (2) Refinement Module extracts high-frequency residuals via low-pass filtering and adaptively blends them using learned spatial weights, (3) Fusion Integrator synthesizes the refined pseudo-GT. Core assumption: The candidate pool contains at least one model that performs well on each image region/task combination, and decomposition can disentangle modality-specific content meaningfully.

### Mechanism 3: Dual-Strategy Continual Learning (EWC + Experience Replay)
Combining parameter-level regularization (EWC) with data-level rehearsal (ER) mitigates catastrophic forgetting across sequential fusion tasks with imbalanced data. EWC computes diagonal Fisher information F_k,i per task, penalizing changes to important parameters via L_EWC = Σ λF_k,i(θ_i - θ*_k,i)². ER stores representative subset M_k per task and replays samples during new task training. The unified loss L_unified = L_FM(D_current ∪ D_replay) + λL_EWC balances plasticity and stability. Core assumption: Diagonal Fisher approximation captures parameter importance sufficiently, and stored replay samples are representative of past task distributions.

## Foundational Learning

- **Flow Matching (Conditional)**: Understanding ODE-based generative modeling is essential to debug sampling failures. Quick check: Can you explain why u_t(x|x_1) = (x_1 - x)/(1-t) in standard FM, and how Eq. 5 modifies this for source-to-fusion transport?

- **Multi-Modal Image Fusion Taxonomy**: The paper handles IVF, MIF, MEF, MFF with different evaluation priorities (Table III). Quick check: For MEF vs. IVF, why might structural similarity metrics (SSIM, Qabf) be weighted differently than perceptual metrics (VIF, SF)?

- **Catastrophic Forgetting in Multi-Task Learning**: FusionFM explicitly addresses sequential task learning where data imbalance causes forgetting. Quick check: Why does EWC alone struggle with "large-scale and diverse tasks" (Section II.c), and what complementary role does experience replay provide?

## Architecture Onboarding

- **Component map**: Fusion Refiner (DU -> RM -> FI) -> U-Net backbone -> Loss computation
- **Critical path**: 1) Pseudo-GT generation (offline): Generate candidates → task-aware selection → Fusion Refiner → store I++_f 2) FM training: Sample (x_A, x_B, x_1) → compute x_t via Eq. 4 → predict v_θ → loss Eq. 6 3) For continual learning: After task k, compute Fisher F_k → store parameters θ*_k → update replay buffer M_k 4) Inference: Single forward pass (one-shot), no iterative refinement
- **Design tradeoffs**: Straight path assumption vs. quality (linear interpolation enables one-shot inference but may produce implausible intermediates if source-target manifold gap is large); Pseudo-GT quality vs. teacher bias (multi-teacher selection reduces individual model bias but introduces hyperparameter overhead); EWC vs. memory (λ=1000 regularization strength fixed empirically; higher λ preserves past knowledge but limits adaptation)
- **Failure signatures**: Blurry outputs with low SF/AG (likely RM protection mask threshold c is too aggressive); Catastrophic forgetting on task k-1 after training task k (check replay buffer M_k construction or EWC Fisher computation); Artifacts in transition regions (MFF) (DU decomposition may fail to separate modality-specific content)
- **First 3 experiments**: 1) Verify transport efficiency: Train FM baseline with random noise coupling vs. average source coupling on single IVF dataset 2) Ablate Fusion Refiner: Generate pseudo-GT with selection only vs. full pipeline 3) Probe continual learning limits: Train on task sequence IVF→MIF→MEF→MFF with varying replay buffer sizes

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the text provided.

## Limitations
- Fusion Refiner implementation details (filter kernel sizes, threshold values, gradient operators) are underspecified, making faithful reproduction challenging
- Continual learning effectiveness is primarily validated on synthetic data distributions rather than real-world task sequences
- Memory requirements for large-scale multi-task scenarios are not thoroughly characterized

## Confidence
- Flow matching mechanism for one-shot fusion: **High** (Strong theoretical foundation and ablation studies confirm transport efficiency gains)
- Two-stage pseudo-ground-truth generation: **Medium** (Multiple-teacher strategy is well-supported, but Fusion Refiner's specific design choices lack external validation)
- Dual-strategy continual learning: **Medium** (Individual EWC and ER components are well-established, but their specific combination for MMIF lacks corpus validation)

## Next Checks
1. **Ablation study validation**: Replicate Table I's W₁ coupling comparison between average source and random noise coupling on held-out IVF data to verify claimed 10× transport distance reduction
2. **Refiner contribution isolation**: Generate pseudo-GTs using selection-only vs. full refinement pipeline on MEF dataset; measure Δ in SD/VIF and downstream mIoU to quantify Refiner's specific impact
3. **Catastrophic forgetting threshold**: Systematically vary replay buffer sizes (m=50, 200, 500) during IVF→MIF→MEF→MFF sequence; plot BWT/FWT curves to identify memory-accuracy inflection points