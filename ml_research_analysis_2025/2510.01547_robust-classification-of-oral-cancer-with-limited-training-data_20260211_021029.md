---
ver: rpa2
title: Robust Classification of Oral Cancer with Limited Training Data
arxiv_id: '2510.01547'
source_url: https://arxiv.org/abs/2510.01547
tags:
- bayesian
- oral
- uncertainty
- cancer
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of diagnosing oral cancer using
  limited training data, where traditional deep learning models struggle with reliability
  and overfitting. To overcome this, the authors propose a hybrid model combining
  a convolutional neural network (CNN) with Bayesian deep learning using variational
  inference.
---

# Robust Classification of Oral Cancer with Limited Training Data

## Quick Facts
- arXiv ID: 2510.01547
- Source URL: https://arxiv.org/abs/2510.01547
- Reference count: 29
- Primary result: Hybrid CNN-Bayesian model achieves 94% accuracy on in-distribution oral cancer images and 88% on out-of-distribution data

## Executive Summary
This paper addresses the challenge of diagnosing oral cancer using limited training data, where traditional deep learning models struggle with reliability and overfitting. The authors propose a hybrid model combining a convolutional neural network (CNN) with Bayesian deep learning using variational inference. This approach quantifies uncertainty in predictions, improving reliability and generalization. The model was trained on smartphone-captured color images and evaluated on three test datasets. It achieved 94% accuracy on in-distribution data and 88% accuracy on out-of-distribution data, outperforming traditional CNNs (72.94%). Uncertainty analysis confirmed that the model is highly confident in correct predictions and uncertain in misclassifications, demonstrating its effectiveness in data-scarce environments. This approach enhances early oral cancer diagnosis by improving model reliability and generalizability.

## Method Summary
The proposed method combines MobileNet-v1 CNN backbone with variational inference layers for Bayesian uncertainty quantification. The model uses transfer learning with ImageNet-pretrained weights, training only the variational classification head. The variational layers employ spike-and-slab priors and optimize the ELBO objective combining negative log-likelihood with KL divergence regularization. During inference, 50 forward passes sample from the approximate posterior to compute prediction means and variances. The model was trained on 3,026 balanced images from 290 suspicious and 551 non-suspicious samples, augmented through rotation, shearing, and scaling. Performance was evaluated on proprietary test data and two external datasets from Kaggle.

## Key Results
- Achieved 94% accuracy on in-distribution test data (proprietary dataset)
- Outperformed traditional CNN baseline (72.94%) on diverse test datasets
- Demonstrated 88% accuracy on out-of-distribution data from Kaggle
- Uncertainty analysis showed low entropy for correct predictions and high entropy for misclassifications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Variational inference enables reliable uncertainty quantification in predictions, improving model trustworthiness for clinical deployment.
- Mechanism: The model learns probability distributions over weights (rather than point estimates) by optimizing variational parameters ζ to approximate the true posterior via KL divergence minimization (Eq. 2). During inference, sampling weights n times produces an output distribution whose variance quantifies uncertainty (Eq. 5).
- Core assumption: The variational distribution q(θ|ζ) can adequately approximate the intractable true posterior.
- Evidence anchors:
  - [abstract]: "This approach employs variational inference to enhance reliability through uncertainty quantification."
  - [section V]: "The model exhibits low uncertainty (high confidence) for correctly classified samples and high uncertainty (low confidence) for misclassified samples."
  - [corpus]: Limited direct corpus evidence for variational inference in oral cancer; corpus neighbors focus on diffusion models and ensemble approaches.
- Break condition: If uncertainty values do not correlate with prediction correctness (i.e., confident wrong predictions), the variational approximation may be inadequate.

### Mechanism 2
- Claim: The KL divergence term acts as implicit regularization, improving generalization on out-of-distribution data.
- Mechanism: The loss function L combines negative log-likelihood with KL[q(θ|ζ)||p(θ)], penalizing weight distributions that deviate from priors, preventing overconfident point estimates and encouraging broader weight distributions that generalize better.
- Core assumption: The prior p(θ) provides meaningful constraints; spike-and-slab prior appropriately captures weight uncertainty.
- Evidence anchors:
  - [section III]: "The KL divergence term in the objective function intuitively acts as a regularization term for the network, helping to reduce overfitting."
  - [abstract]: "outperforming traditional CNNs (72.94%)" on diverse datasets.
  - [corpus]: Weak corpus validation; neighbor papers do not explicitly compare KL regularization benefits.
- Break condition: If in-distribution accuracy significantly drops compared to standard CNNs, regularization may be too strong or prior misspecified.

### Mechanism 3
- Claim: Transfer learning with MobileNet-v1 backbone enables effective feature extraction despite limited training data.
- Mechanism: Pretrained ImageNet weights initialize the convolutional backbone; only the variational classification head (32 nodes + output layer) is trained from scratch, reducing data requirements while preserving feature extraction capability.
- Core assumption: Low-level visual features from ImageNet transfer meaningfully to oral cavity images.
- Evidence anchors:
  - [section V]: "We employed a transfer learning approach... leveraging a pretrained model analogous to our target problem."
  - [section V]: 94% accuracy on in-distribution test data matches traditional CNN performance.
  - [corpus: 48315, 23892]: Related oral cancer papers also use pretrained backbones with transfer learning.
- Break condition: If training loss plateaus early with poor accuracy, pretrained features may not transfer; consider domain-specific pretraining.

## Foundational Learning

- Concept: Bayesian inference and posterior estimation
  - Why needed here: Understanding how priors combine with likelihoods to form posteriors is essential for interpreting Eq. 1 and the entire variational approach.
  - Quick check question: Can you explain why computing the marginal likelihood ∫p(D|θ)p(θ)dθ is intractable for neural networks?

- Concept: Variational inference vs. MCMC sampling
  - Why needed here: The paper explicitly chooses VI over Monte Carlo methods due to computational feasibility with high-dimensional parameters.
  - Quick check question: Why does minimizing KL[q||p] produce an approximate posterior, and what tradeoff does this introduce compared to exact inference?

- Concept: Entropy as uncertainty measure
  - Why needed here: Figure 5 uses entropy bins to evaluate calibration; understanding entropy helps interpret whether the model "knows what it doesn't know."
  - Quick check question: Would a well-calibrated model show higher or lower entropy for misclassified samples, and why?

## Architecture Onboarding

- Component map:
Input (224×224×3 image)
    ↓
MobileNet-v1 backbone (frozen pretrained weights)
    ↓
Flattened features
    ↓
Dense variational layer (32 nodes, spike-and-slab prior)
    ↓
Output layer (categorical variational, 2 classes)
    ↓
n forward passes → prediction mean + variance

- Critical path:
  1. Data preprocessing: Crop to region of interest, augment (rotation, shear, scale), balance classes
  2. Model construction: Load MobileNet-v1 without head, append variational layers from TensorFlow Probability
  3. Training: Optimize Eq. 2 with RMSprop, LR=0.01, batch=32, 150 epochs
  4. Inference: Run 50 forward passes per sample, compute mean prediction and variance

- Design tradeoffs:
  - Hybrid vs. full Bayesian: Training only the head reduces computation but limits uncertainty to later layers; full Bayesian would be more expressive but computationally prohibitive
  - Spike-and-slab vs. Gaussian prior: Spike-and-slab encourages sparsity but may be harder to optimize; Gaussian is simpler but less expressive
  - Number of samples (n=50): More samples improve uncertainty estimates but increase inference latency

- Failure signatures:
  - High variance on in-distribution correct predictions → model underfitting or prior too restrictive
  - Low variance on misclassifications → overconfidence, poorly calibrated variational approximation
  - Training loss divergence → learning rate too high for variational optimization

- First 3 experiments:
  1. Baseline calibration check: Train on proprietary data, evaluate entropy distribution for correct vs. incorrect predictions on held-out test set; verify high uncertainty correlates with errors.
  2. Distribution shift test: Evaluate on Kaggle dataset (unseen distribution); compare accuracy and uncertainty to traditional CNN baseline.
  3. Ablation on samples n: Run inference with n∈{10, 25, 50, 100}; measure stability of uncertainty estimates and inference time to find optimal tradeoff.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the proposed hybrid Bayesian model maintain its reliability and generalization capabilities during extensive field validation in low-resource clinical settings?
- Basis in paper: [explicit] The conclusion states, "As a next step, we plan to conduct extensive field validation and integrate the proposed model into a practical AI framework for reliable and accessible oral cancer screening."
- Why unresolved: The current results are derived from retrospective datasets (proprietary and Kaggle) processed in a controlled computing environment, rather than prospective real-world deployment where imaging conditions are uncontrolled.
- What evidence would resolve it: Performance metrics (accuracy, sensitivity, specificity) and uncertainty calibration metrics collected from a prospective study involving patients in a clinical setting.

### Open Question 2
- Question: Can the model's overconfidence in specific misclassified samples be eliminated through targeted dataset augmentation or architectural adjustments?
- Basis in paper: [explicit] The discussion notes, "It is also important to note that the model exhibited overconfidence in a subset of misclassified samples... This suggests potential areas for improvement that could be addressed by augmenting the training dataset with more diverse examples."
- Why unresolved: The authors identified the failure mode (low entropy/overconfidence in incorrect predictions) but have not yet tested the proposed solution (diverse data augmentation) to verify if it calibrates these specific instances.
- What evidence would resolve it: A comparative study showing a reduction in the density of low-entropy misclassifications (left-side peaks in entropy plots) after enriching the training data with hard negatives or diverse examples.

### Open Question 3
- Question: Is the computational overhead of sampling-based Bayesian inference (e.g., 50 forward passes) compatible with real-time screening requirements on standard consumer smartphones?
- Basis in paper: [inferred] The methodology relies on running the network 50 times ($n=50$) to approximate the posterior distribution and calculate uncertainty. While the backbone is MobileNet-v1 (designed for mobile), the multiplication of inference time by 50x may hinder the goal of "accessible oral cancer screening" on standard devices.
- Why unresolved: The paper evaluates classification performance but does not report latency or computational benchmarks on edge devices, which is critical for the proposed smartphone-based application.
- What evidence would resolve it: Latency measurements (frames per second) and battery consumption analysis running the variational inference loop on mid-range smartphone hardware.

### Open Question 4
- Question: How does the hybrid approach (Bayesian layers on top of a deterministic CNN backbone) compare in performance to a fully Bayesian convolutional network for this task?
- Basis in paper: [inferred] The authors explicitly limit the Bayesian component to the dense layers ("head") to reduce computational costs, stating, "Because training a complete Bayesian neural network is computationally expensive, we adopted a hybrid approach."
- Why unresolved: It is unclear if the deterministic convolutional backbone limits the model's ability to capture aleatoric uncertainty in the low-level visual features of oral lesions, or if the hybrid approach is a sufficient approximation.
- What evidence would resolve it: An ablation study comparing the uncertainty quality and accuracy of the hybrid model against a model with Bayesian convolutional layers.

## Limitations

- Limited public validation: Strong performance claims rest primarily on proprietary dataset with limited external validation on small test sets (32-85 images)
- Computational overhead: 50 forward passes per inference sample may hinder real-time deployment on consumer smartphones
- Underspecified implementation: Exact augmentation ranges, prior hyperparameters, and training splits remain unclear for reproduction

## Confidence

- **High confidence**: In-distribution accuracy (94%) on proprietary test set, given proper train/test split and augmentation
- **Medium confidence**: Out-of-distribution performance (88%) and uncertainty calibration, limited by small external test sets and absence of ablation studies on prior/variational design choices
- **Low confidence**: Generalizability to radically different imaging conditions (e.g., clinical vs. smartphone), due to lack of domain-shift experiments

## Next Checks

1. **Ablation study**: Compare variational model to non-Bayesian baseline and MC-dropout baseline on both in-distribution and out-of-distribution data to isolate benefits of VI
2. **Calibration curve analysis**: Plot expected calibration error (ECE) and reliability diagrams for both correct and incorrect predictions across entropy bins
3. **Prior sensitivity test**: Vary spike-and-slab prior strength and Gaussian vs. spike-and-slab to measure impact on accuracy, uncertainty quality, and overfitting resistance