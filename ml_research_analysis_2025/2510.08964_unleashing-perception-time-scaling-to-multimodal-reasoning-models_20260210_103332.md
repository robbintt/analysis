---
ver: rpa2
title: Unleashing Perception-Time Scaling to Multimodal Reasoning Models
arxiv_id: '2510.08964'
source_url: https://arxiv.org/abs/2510.08964
tags:
- image
- perception
- reasoning
- unit
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether inference-time scaling methods can
  improve visual perception in large vision-language models (LVLMs). Current LVLMs
  perform perception tasks in a single step, limiting the gains from reasoning-focused
  scaling methods.
---

# Unleashing Perception-Time Scaling to Multimodal Reasoning Models

## Quick Facts
- arXiv ID: 2510.08964
- Source URL: https://arxiv.org/abs/2510.08964
- Authors: Yifan Li; Zhenghao Chen; Ziheng Wu; Kun Zhou; Ruipu Luo; Can Zhang; Zhentao He; Yufei Zhan; Wayne Xin Zhao; Minghui Qiu
- Reference count: 40
- Key result: Perception-Time Scaling improves high-precision perception performance from 8.0% to 64.7% on DisTANCE benchmark

## Executive Summary
Current large vision-language models (LVLMs) perform visual perception tasks in a single step, limiting their ability to benefit from inference-time scaling methods that have proven successful for reasoning tasks. This paper introduces Perception-Time Scaling (PTS), which reformulates perception as a structured, step-by-step process using symbolic token representation for distances and decomposition into intermediate sub-problems. The approach addresses the gap between perception and reasoning capabilities in multimodal models.

## Method Summary
Perception-Time Scaling (PTS) transforms single-step perception into a multi-step reasoning process by introducing symbolic tokens to represent spatial relationships and distances, then decomposing complex perception tasks into manageable intermediate sub-problems. The method leverages the model's reasoning capabilities by treating perception as a sequence of logical steps rather than a single inference, enabling the application of inference-time scaling techniques to visual perception tasks.

## Key Results
- PTS improves high-precision perception performance from 8.0% to 64.7% on the DisTANCE benchmark
- The approach generalizes to out-of-domain perception tasks beyond the training domain
- PTS increases perception-related tokens and model attention to image content, explaining the perceptual gains

## Why This Works (Mechanism)
The mechanism behind PTS's success lies in restructuring perception tasks from monolithic operations into sequential reasoning steps. By introducing symbolic distance tokens, the model can explicitly reason about spatial relationships rather than inferring them implicitly. The decomposition into sub-problems allows the model to focus attention on specific aspects of the visual input, increasing the proportion of perception-relevant tokens and directing model attention toward image content rather than relying solely on language priors.

## Foundational Learning
- **Symbolic token representation**: Using discrete symbols for distances and spatial relationships provides a structured vocabulary for the model to reason about visual elements
- **Task decomposition**: Breaking complex perception problems into intermediate sub-problems makes them more tractable for step-by-step reasoning
- **Inference-time scaling**: Extending reasoning-focused scaling methods from text to multimodal perception enables iterative refinement of visual understanding
- **Attention mechanisms**: Shifting model focus from language priors to image content improves visual grounding and perceptual accuracy
- **Benchmark evaluation**: Using specialized benchmarks like DisTANCE provides quantitative measures of perceptual precision improvements
- **Out-of-domain generalization**: Testing on tasks beyond the training distribution validates the robustness of the perception approach

## Architecture Onboarding

**Component Map:** Input Image + Text Prompt -> Symbolic Token Encoder -> Task Decomposition Module -> Step-by-Step Reasoning Engine -> Final Perception Output

**Critical Path:** Image processing and prompt encoding → Symbolic token generation → Task decomposition into sub-problems → Sequential reasoning steps → Final perception prediction

**Design Tradeoffs:** The approach trades computational efficiency (multiple inference steps) for improved perceptual accuracy, leveraging the model's reasoning capabilities at the cost of increased inference time. Symbolic representation provides structure but may limit expressiveness compared to continuous representations.

**Failure Signatures:** Single-step perception failures when models rely on language priors over visual evidence; performance degradation on tasks requiring implicit rather than explicit spatial reasoning; potential overfitting to benchmark-specific task structures.

**First 3 Experiments:** 1) Evaluate PTS on diverse perception benchmarks beyond DisTANCE to test generalization across visual reasoning domains 2) Conduct ablation studies removing symbolic tokens or decomposition to identify critical components 3) Measure computational overhead and inference time compared to baseline single-step methods

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains are primarily demonstrated on the DisTANCE benchmark, raising questions about generalizability to other perception tasks
- The specific design choices (symbolic tokens, decomposition) may not be optimal and could benefit from further optimization
- Analysis of perceptual gains lacks deeper investigation into whether increased tokens represent more efficient processing or simply more verbose reasoning
- Computational efficiency and inference time overhead compared to single-step methods are not fully characterized

## Confidence

**High confidence** in the empirical performance improvement on DisTANCE benchmark
**Medium confidence** in the explanation for perceptual gains through token and attention analysis
**Low confidence** in generalizability to other perception tasks and real-world applications

## Next Checks

1. Test PTS on diverse perception benchmarks beyond DisTANCE to evaluate generalization across different visual reasoning domains
2. Conduct ablation studies to determine which components (symbolic tokens, decomposition, or both) are critical for performance gains
3. Evaluate computational efficiency and inference time overhead compared to single-step perception methods