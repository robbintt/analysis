---
ver: rpa2
title: Riemannian Stochastic Interpolants for Amorphous Particle Systems
arxiv_id: '2512.16607'
source_url: https://arxiv.org/abs/2512.16607
tags:
- samples
- which
- urlhttps
- systems
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces equivariant Riemannian stochastic interpolants
  (eRSI) for sampling equilibrium configurations of amorphous materials (glasses).
  The method combines Riemannian geometry to handle periodic boundary conditions with
  equivariant graph neural networks to enforce the symmetries of multi-component particle
  systems.
---

# Riemannian Stochastic Interpolants for Amorphous Particle Systems

## Quick Facts
- **arXiv ID:** 2512.16607
- **Source URL:** https://arxiv.org/abs/2512.16607
- **Reference count:** 40
- **Primary result:** Equivariant Riemannian stochastic interpolants (eRSI) enable efficient sampling of equilibrium configurations in amorphous materials by combining Riemannian geometry for periodic boundaries with equivariant GNNs for physical symmetries.

## Executive Summary
This work introduces a novel framework for sampling equilibrium configurations of amorphous materials (glasses) that overcomes the extreme equilibration times limiting traditional simulations. The method, called equivariant Riemannian stochastic interpolants (eRSI), combines Riemannian geometry to handle periodic boundary conditions with equivariant graph neural networks to enforce the symmetries of multi-component particle systems. By training a generative model that respects these invariances, the framework enables importance-sampling reweighting of generated configurations to compute unbiased thermodynamic averages. Numerical experiments on a canonical model of metallic glass formers show that eRSI significantly outperforms symmetry- and geometry-agnostic baselines.

## Method Summary
The eRSI method learns a continuous normalizing flow (CNF) that maps a simple base distribution to the equilibrium Boltzmann distribution of an amorphous material system. The flow is parameterized by an equivariant graph neural network that outputs velocity fields on the flat torus (representing periodic boundaries). Training uses a simulation-free loss comparing predicted velocities to geodesic interpolants between equilibrium configurations. At inference, generated samples are reweighted using tractable likelihoods to recover unbiased thermodynamic observables.

## Key Results
- eRSI outperforms geometry-agnostic (Euclidean) and symmetry-agnostic baselines in reproducing radial distribution functions and thermodynamic observables
- Effective sample size analysis confirms improved sampling efficiency compared to traditional Monte Carlo methods
- The method scales better to larger system sizes than standard importance sampling approaches
- Reweighted estimates for potential energy and specific heat converge to ground truth values

## Why This Works (Mechanism)

### Mechanism 1: Equivariant Velocity Fields Enforce Physical Symmetries
The model guarantees that generated configurations respect the symmetries of the target Boltzmann distribution (permutation, translation, reflection) if the velocity field is constrained to be equivariant. The method parameterizes the velocity field using an Equivariant Graph Neural Network (EGNN). Because the velocity field is G_C-equivariant, the transport map pushing the base distribution to the target is also G_C-equivariant. Since the base distribution is uniform (invariant), the resulting generated distribution remains invariant under group actions.

### Mechanism 2: Riemannian Interpolation Prevents Boundary Artifacts
Modeling the periodic box as a flat torus using Riemannian geometry eliminates unphysical particle overlaps that occur at boundaries in Euclidean models. Instead of Euclidean coordinates, the model uses exponential and logarithmic maps specific to the torus. This ensures that particle displacements "wrap" around the periodic boundaries correctly. The GNN updates particle positions using these geodesic operations rather than simple vector addition.

### Mechanism 3: Importance Sampling Reweighting Recovers Thermodynamics
The Continuous Normalizing Flow (CNF) formulation allows for exact likelihood computation, enabling unbiased estimation of physical observables via importance sampling. Unlike diffusion models which often lack tractable likelihoods, ODE-based interpolants admit a change-of-variables formula. This allows the calculation of weights to correct for the mismatch between the generated distribution and the true Boltzmann distribution.

## Foundational Learning

- **Concept: Equivariant Graph Neural Networks (EGNN)**
  - **Why needed here:** Standard GNNs do not respect the rotations and translations of physical space. An EGNN is required to ensure that rotating the input configuration rotates the predicted velocity vector correspondingly, enforcing physical consistency.
  - **Quick check question:** If you rotate the input particle system by 45 degrees, does the output velocity field rotate by 45 degrees or change magnitude?

- **Concept: Riemannian Manifolds (The Flat Torus)**
  - **Why needed here:** To simulate bulk materials, we use periodic boundary conditions. The geometry is a torus, not infinite Euclidean space. Standard operations like "distance" and "addition" must be replaced with geodesics and exponential maps to handle the wrapping boundaries correctly.
  - **Quick check question:** In a 1D box of length L, is the distance between x=0.1 and x=0.9 equal to 0.8 or 0.2?

- **Concept: Continuous Normalizing Flows (CNF) & Likelihoods**
  - **Why needed here:** To perform importance sampling, you need the probability density of the generated sample. CNFs define a deterministic trajectory from noise to data where the change in log-probability is tractable via the divergence of the velocity field.
  - **Quick check question:** Can you compute the exact probability density p(x_t) at time t without running a Monte Carlo simulation?

## Architecture Onboarding

- **Component map:** Input (species + coordinates) -> EGNN backbone (toroidal operations) -> Output (velocity field + log-probability)
- **Critical path:** The coordinate update equation (Eq. 13) is the most critical implementation detail. You must implement the exp (wrapping) and log (shortest path) maps for the Torus correctly. A standard EGNN implementation will fail at box boundaries.
- **Design tradeoffs:** eRSI is complex (requires Riemannian ops) but physically valid, while eFM (Euclidean) is easier to implement but generates unphysical boundary overlaps.
- **Failure signatures:** Boundary Collapse (particles clustering at edges), Symmetry Drift (generating identical structures that drift when they shouldn't), Weight Collapse (ESS dropping to near zero during reweighting).
- **First 3 experiments:**
  1. Visual sanity check (N=10): Generate samples and plot them. Check if particles "teleport" across boundaries smoothly or overlap.
  2. Ablation on Geometry: Train a baseline Euclidean model (eFM) and the Riemannian model (eRSI). Compare the radial distribution function g(r) at short distances (r < particle diameter) for overlaps.
  3. ESS Scaling: Generate 10^3 to 10^5 samples, compute importance weights, and plot Effective Sample Size (ESS). If ESS does not stabilize, the model is not learning the equilibrium distribution.

## Open Questions the Paper Calls Out

- **Open Question 1:** Does the eRSI framework generalize effectively to three-dimensional glass formers?
  - **Basis in paper:** The authors state that "these results need to be confirmed on other amorphous systems, in particular in three dimensions."
  - **Why unresolved:** The numerical experiments and benchmarks in the study are restricted to two-dimensional systems (d=2), leaving the performance in the physically relevant 3D space unverified.

- **Open Question 2:** Can the training process be adapted to eliminate the reliance on large, pre-equilibrated datasets?
  - **Basis in paper:** The conclusion proposes investigating "training methods that alleviate this requirement, such as adaptive MCMCs possibly combined with sequential tempering."
  - **Why unresolved:** The current framework relies on 10^5 uncorrelated samples generated by expensive Swap Monte Carlo simulations, which limits applicability where such data is unavailable.

- **Open Question 3:** Does the computational cost of importance sampling (likelihood evaluation) scale more favorably than local Monte Carlo as system size increases?
  - **Basis in paper:** Authors identify likelihood evaluation as a bottleneck but express the "hope that this computational cost scales more favorably than usual local Monte Carlo simulation techniques."
  - **Why unresolved:** The study is limited to small systems (N â‰¤ 44), and the scaling of the Effective Sample Size (ESS) relative to the quadratic cost of likelihood computation is unknown for large N.

## Limitations
- The method currently relies on large pre-computed datasets of equilibrium configurations from expensive Monte Carlo simulations
- Computational cost of likelihood evaluation via ODE solves may limit practical applicability for large-scale simulations
- Numerical experiments are restricted to two-dimensional systems, leaving 3D generalization unverified

## Confidence
- **Core methodology (High):** Equivariant GNNs for enforcing physical symmetries is well-established in molecular modeling literature
- **Riemannian geometry implementation (Medium):** Mathematically sound but specific implementation details for flat torus could benefit from additional validation
- **Scaling to larger systems (Low):** Primary uncertainty lies in how importance sampling reweighting scales with system size and complexity

## Next Checks
1. **Cross-validation of importance weights:** Generate samples using eRSI, compute importance weights, and perform leave-one-out cross-validation to assess the stability of thermodynamic averages as a function of sample size.

2. **Equivariance robustness test:** Systematically break the symmetries (e.g., apply external fields, asymmetric particle interactions) and verify that the model fails gracefully or adapts appropriately, rather than producing physically inconsistent results.

3. **Computational efficiency benchmarking:** Compare the wall-clock time for generating equilibrated samples using eRSI versus traditional molecular dynamics or Monte Carlo methods for increasing system sizes (N=10, 100, 1000 particles).