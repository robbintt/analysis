---
ver: rpa2
title: 'GLASS: Test-Time Acceleration for LLMs via Global-Local Neural Importance
  Aggregation'
arxiv_id: '2508.14302'
source_url: https://arxiv.org/abs/2508.14302
tags:
- arxiv
- griffin
- neurons
- methods
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces A/I-GLASS, a training-free method for dynamic
  FFN pruning in LLMs that aggregates global and local neural importance rankings
  using a Plackett-Luce maximum-likelihood framework. Unlike prior approaches that
  rely on static masks or costly predictors, GLASS fuses prompt-specific activation
  patterns with model-intrinsic statistics (activation magnitudes or impact scores)
  to identify critical neurons at inference time.
---

# GLASS: Test-Time Acceleration for LLMs via Global-Local Neural Importance Aggregation

## Quick Facts
- **arXiv ID:** 2508.14302
- **Source URL:** https://arxiv.org/abs/2508.14302
- **Reference count:** 33
- **Primary result:** A/I-GLASS achieves up to 45.10% lower perplexity and 25.26% lower KL divergence than training-free baselines under 50% sparsity

## Executive Summary
This paper introduces A/I-GLASS, a training-free method for dynamic FFN pruning in LLMs that aggregates global and local neural importance rankings using a Plackett-Luce maximum-likelihood framework. Unlike prior approaches that rely on static masks or costly predictors, GLASS fuses prompt-specific activation patterns with model-intrinsic statistics (activation magnitudes or impact scores) to identify critical neurons at inference time. Evaluated across multiple models and benchmarks, GLASS achieves up to 45.10% lower perplexity and 25.26% lower KL divergence than the strongest prior training-free baseline under 50% sparsity, particularly excelling in short-prompt, long-generation scenarios. The method requires no offline training and adds no inference overhead, making it highly suitable for edge deployment.

## Method Summary
GLASS is a training-free dynamic FFN pruning method that operates by aggregating global and local neural importance rankings using a Plackett-Luce maximum-likelihood framework. The method leverages two types of intrinsic neural importance signals: activation magnitude (average absolute activation values across a batch) and impact score (activation times gradient). During inference, GLASS performs prompt encoding to compute local activation magnitudes for each token position, then fuses these with global statistics precomputed from the model's training distribution. The aggregation process ranks neurons based on their combined global-local importance, allowing the model to dynamically prune less important neurons during generation while maintaining performance. This approach achieves zero training overhead and zero inference overhead compared to standard inference.

## Key Results
- A/I-GLASS achieves up to 45.10% lower perplexity than the strongest training-free baseline under 50% sparsity
- The method delivers 25.26% lower KL divergence compared to competing approaches at 50% sparsity
- GLASS shows particular strength in short-prompt, long-generation scenarios where prompt complexity varies significantly from generation content

## Why This Works (Mechanism)
GLASS works by recognizing that neural importance varies both across the model as a whole (global importance) and for specific prompts or positions (local importance). By aggregating these two perspectives through a statistically principled Plackett-Luce framework, the method can identify which neurons are truly critical for the current inference task. The global statistics capture the model's overall knowledge distribution, while local activation patterns reflect the specific prompt's requirements. This dual perspective enables more nuanced pruning decisions than methods relying solely on either global or local signals, particularly in scenarios where the prompt content differs substantially from the model's training distribution.

## Foundational Learning

**Plackett-Luce Model**
- *Why needed:* Provides a statistically sound framework for aggregating ranked lists of neural importance from different sources
- *Quick check:* Verify that the PL model assumptions hold for neural activation data by examining rank correlation stability across different batches

**Neural Importance Signals**
- *Why needed:* Different neurons contribute unequally to model performance, making importance ranking essential for effective pruning
- *Quick check:* Confirm that activation magnitude and impact score correlate with neuron contribution by measuring performance degradation when pruning top-ranked vs bottom-ranked neurons

**Dynamic vs Static Pruning**
- *Why needed:* Different inputs require different neural resources, making static masks suboptimal for diverse workloads
- *Quick check:* Compare performance across varying prompt types to validate that dynamic pruning adapts better than static approaches

## Architecture Onboarding

**Component Map**
GLASS operates on the FFN layers of transformer models: Input Tokens -> Encoder/Decoder Layers -> FFN Layers (with GLASS pruning) -> Output

**Critical Path**
During inference: Prompt encoding -> Local activation computation -> Global-local aggregation -> Neuron ranking -> Dynamic pruning mask application -> Generation

**Design Tradeoffs**
The method trades off some theoretical pruning efficiency for practical zero-overhead implementation. While more sophisticated predictors might achieve higher sparsity, they would require additional computation. GLASS prioritizes runtime efficiency and simplicity over maximal sparsity gains.

**Failure Signatures**
Poor performance would manifest as: (1) degradation in perplexity when prompt complexity increases, (2) inconsistent pruning effectiveness across different model scales, (3) failure to maintain performance at higher sparsity levels (>50%)

**First Experiments**
1. Baseline comparison: Measure perplexity degradation when applying random pruning vs GLASS pruning at various sparsity levels
2. Ablation study: Evaluate performance using only global importance, only local importance, and the combined approach
3. Overhead validation: Benchmark actual inference latency with GLASS enabled versus standard inference

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Dependence on activation magnitude and impact scores may not capture all forms of neural importance, particularly for complex reasoning tasks
- The Plackett-Luce aggregation framework may not hold universally across all model architectures or task types
- Performance validation is primarily limited to 125M-1.3B parameter models, with unclear scaling behavior to larger models

## Confidence

**High Confidence Claims:**
- GLASS achieves state-of-the-art performance among training-free methods for dynamic FFN pruning
- The method demonstrates statistically significant improvements in perplexity and KL divergence

**Medium Confidence Claims:**
- Zero inference overhead claim lacks detailed latency measurements and baseline comparisons
- Generalizability claims require validation on larger models and specialized domains

## Next Checks

1. **Scale-up validation:** Evaluate GLASS on models 7B parameters and larger to verify that performance gains and computational benefits scale appropriately with model size, particularly examining whether the zero-overhead claim holds at scale.

2. **Domain-specific testing:** Test GLASS on specialized benchmarks requiring complex reasoning, mathematical problem-solving, or domain-specific knowledge to determine whether activation-based importance signals remain effective for these task types.

3. **Cross-architecture generalization:** Apply GLASS to non-standard transformer architectures (such as MoE models or architectures with alternative FFN structures) to validate whether the global-local aggregation approach generalizes beyond standard GPT-style architectures.