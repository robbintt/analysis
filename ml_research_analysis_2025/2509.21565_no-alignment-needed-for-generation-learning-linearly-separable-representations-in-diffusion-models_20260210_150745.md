---
ver: rpa2
title: 'No Alignment Needed for Generation: Learning Linearly Separable Representations
  in Diffusion Models'
arxiv_id: '2509.21565'
source_url: https://arxiv.org/abs/2509.21565
tags:
- linear
- lsep
- diffusion
- training
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a training regularization method for diffusion
  models that promotes linear separability of intermediate layer representations without
  requiring external encoders or representation alignment. The method integrates a
  trainable linear probe into an intermediate layer of the diffusion model, jointly
  optimizing both denoising and classification objectives.
---

# No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models

## Quick Facts
- **arXiv ID**: 2509.21565
- **Source URL**: https://arxiv.org/abs/2509.21565
- **Reference count**: 12
- **Primary result**: Achieves FID of 1.46 on 256×256 ImageNet without classifier-free guidance, establishing state-of-the-art performance among models without external encoder architectures

## Executive Summary
This paper introduces a novel training regularization method for diffusion models that promotes linear separability in intermediate layer representations without requiring external encoders or representation alignment. The method integrates a trainable linear probe into an intermediate layer of the diffusion model, jointly optimizing both denoising and classification objectives. By introducing class-specific conditioning, random cropping, and time-dependent loss weighting, the approach significantly improves both training efficiency and generation quality on flow-based transformer architectures, achieving state-of-the-art performance without relying on external encoder architectures.

## Method Summary
The proposed method introduces a trainable linear probe integrated into an intermediate layer of a diffusion model, jointly optimizing denoising and classification objectives. The linear probe receives class-specific conditioning and processes randomly cropped patches to enhance patch-level linear separability. A time-dependent weighting scheme modulates the classification loss throughout training. The method operates by encouraging intermediate representations to be linearly separable while maintaining the model's ability to perform the primary denoising task, resulting in improved training efficiency and generation quality without requiring external alignment mechanisms.

## Key Results
- Achieves FID of 1.46 on 256×256 ImageNet without classifier-free guidance
- Demonstrates substantial improvements in training efficiency for flow-based transformer architectures
- Shows synergistic performance when combined with alignment-based approaches
- Ablation studies confirm the contribution of each proposed component (class-specific conditioning, random cropping, time-dependent loss weighting)

## Why This Works (Mechanism)
The mechanism operates through the introduction of a trainable linear probe that creates a secondary optimization objective focused on classification accuracy. By requiring intermediate representations to be linearly separable for classification purposes, the model develops representations that are both informative for the denoising task and structured in ways that facilitate generation. The class-specific conditioning ensures the probe learns discriminative features, while random cropping forces the model to maintain patch-level separability. The time-dependent loss weighting prevents early overfitting to classification while allowing later refinement. This dual-task optimization creates representations that are more effective for generation, as evidenced by improved FID scores and faster convergence.

## Foundational Learning
- **Diffusion Models**: Why needed - Core generative framework being improved; Quick check - Understanding the denoising process and noise schedule
- **Linear Separability**: Why needed - Key property being optimized for; Quick check - Can distinguish classes with linear boundaries
- **Classifier-Free Guidance**: Why needed - Benchmark comparison point; Quick check - Understand how guidance scales model outputs
- **Flow-Based Transformers**: Why needed - Specific architecture used; Quick check - Understand reversible layers and attention mechanisms
- **FID Score**: Why needed - Primary evaluation metric; Quick check - Can compute and interpret Fréchet Inception Distance
- **Time-Dependent Weighting**: Why needed - Training strategy component; Quick check - Understand how loss weighting schedules affect optimization

## Architecture Onboarding
- **Component Map**: Input → Diffusion Model → Linear Probe Branch → Classification Loss; Diffusion Model → Denoising Loss → Output
- **Critical Path**: Input → Diffusion layers → Linear probe → Classification + Denoising losses → Parameter updates
- **Design Tradeoffs**: Classification accuracy vs. generation quality; Training complexity vs. performance gains; Architectural modifications vs. compatibility
- **Failure Signatures**: Poor linear probe accuracy indicates representations not learning separability; High denoising loss with good classification suggests task interference; Degraded generation quality indicates over-regularization
- **First Experiments**: 1) Verify linear probe achieves reasonable classification accuracy on training data; 2) Compare FID with and without linear probe during inference; 3) Test time-dependent weighting schedules to find optimal configuration

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Theoretical justification for why linearly separable representations improve generation quality remains underdeveloped
- Method's effectiveness appears highly dependent on flow-based transformer architectures, raising generalization concerns
- Time-dependent loss weighting strategy lacks theoretical grounding for its specific formulation

## Confidence
- **High confidence**: Empirical improvements in FID scores and training efficiency are well-documented through controlled experiments
- **Medium confidence**: Claim that linear separability directly causes improved generation quality has empirical support but lacks theoretical validation
- **Low confidence**: Scalability beyond 256×256 resolution is limited; computational overhead could be significant for larger models

## Next Checks
1. Conduct theoretical analysis linking linear separability metrics to generation quality measures, potentially through information bottleneck principles
2. Test the method on diverse diffusion model architectures (U-Net, score-based models) to evaluate architectural generalization
3. Evaluate performance degradation when removing the linear probe after training to assess whether linear separability is a learned property or requires ongoing supervision