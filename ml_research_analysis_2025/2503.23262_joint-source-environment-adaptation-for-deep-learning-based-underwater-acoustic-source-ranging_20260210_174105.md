---
ver: rpa2
title: Joint Source-Environment Adaptation for Deep Learning-Based Underwater Acoustic
  Source Ranging
arxiv_id: '2503.23262'
source_url: https://arxiv.org/abs/2503.23262
tags:
- source
- data
- localization
- training
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of poor generalization of deep
  learning-based underwater acoustic localization models in mismatched environments.
  The authors propose a source-free domain adaptation method that improves model performance
  by coupling the pre-trained model prediction with an almost independent estimation
  based on the received signal energy.
---

# Joint Source-Environment Adaptation for Deep Learning-Based Underwater Acoustic Source Ranging

## Quick Facts
- arXiv ID: 2503.23262
- Source URL: https://arxiv.org/abs/2503.23262
- Reference count: 26
- Primary result: Source-free domain adaptation method (JSEA) improves underwater acoustic localization under environmental mismatch by coupling DL predictions with physics-based energy estimation

## Executive Summary
This paper addresses the critical challenge of poor generalization in deep learning-based underwater acoustic localization models when deployed in mismatched environments. The authors propose a source-free domain adaptation method that combines the classification model's output uncertainty with a physics-based received signal strength estimation to improve localization accuracy. The approach leverages the peakiness of the probability mass function to identify confident samples for self-supervision, while using Bayesian fusion with energy-based estimates to handle uncertain cases. The method demonstrates significant improvements in mean absolute error and probability of credible localization compared to baseline approaches when tested on Bellhop-generated data with real ocean noise contamination.

## Method Summary
The JSEA method treats underwater acoustic ranging as a classification problem with metric-inspired soft labels, where the network outputs a probability distribution over discretized range classes. The approach consists of two phases: pre-training on source environment data using Jensen-Shannon divergence loss with soft labels, followed by adaptation on target data without labels. During adaptation, the method identifies a self-supervising subset based on PMF peak significance, estimates the transmission loss curve from this subset, and uses a Bayesian fusion of the DL output with received signal strength estimates to generate pseudo-labels for the remaining uncertain samples. The feature extractor is then fine-tuned on the target data using these pseudo-labels while keeping the classifier frozen.

## Key Results
- JSEA significantly improves MAE and PCL compared to pre-trained model and SHOT adaptation method under environmental mismatches
- The method effectively handles source-free domain adaptation without requiring access to source training data or target ground truth labels
- Bayesian coupling of DL predictions with physics-based energy estimation resolves range ambiguities caused by environmental mismatch

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Filtering training samples via output uncertainty (peakiness of the PMF) isolates a reliable self-supervised set for adaptation.
- **Mechanism:** The authors define a subset S of test samples where the classifier outputs a single "significant" peak (ratio > 10x to second peak). This acts as a high-confidence filter, under the assumption that unimodal outputs correlate with correct predictions, providing stable pseudo-labels to anchor the fine-tuning process.
- **Core assumption:** High prediction confidence (entropy) in the pre-trained model correlates with ground truth even in mismatched environments.
- **Evidence anchors:**
  - [section]: Section III.A defines the self-supervising subset S via Eq. (7) based on peak significance.
  - [abstract]: Mentions leveraging "the classification model's uncertainty from the output probability mass function."
  - [corpus]: "Joint Source-Environment Adaptation..." abstract confirms using "model uncertainty" to guide adaptation.
- **Break condition:** If environmental shift is so severe that the model is confidently wrong (high confidence but low accuracy), this selection criterion will propagate error rather than correct it.

### Mechanism 2
- **Claim:** Coupling a data-driven model with a physics-based energy estimator resolves range ambiguity caused by environmental mismatch.
- **Mechanism:** The authors utilize a Bayesian framework where the final location estimate is proportional to the product of the DL likelihood and a Received Signal Strength (RSS) likelihood (p(y|C) ∝ p(y|˜C)p(y|E)). The RSS model provides a coarse, robust estimate that constrains the DL model, which is fine-grained but sensitive to mismatch.
- **Core assumption:** The normalized Sample Covariance Matrix (SCM) and the received signal energy (E) are approximately independent; the transmission loss follows a Gaussian distribution around a range-dependent function.
- **Evidence anchors:**
  - [section]: Section III.B derives the proportionality in Eq. (9) and details the Gaussian assumption for E|d.
  - [abstract]: Describes "coupling the pre-trained model prediction with an almost independent estimation based on the received signal energy."
  - [corpus]: Corpus neighbors (e.g., "Hankel-FNO") highlight physics-encoding as a general strategy, but specific Bayesian coupling evidence is primarily found in the main text.
- **Break condition:** If the source power is unknown or highly variable, or if the propagation loss (Γs) is non-monotonic or drastically different from the piece-wise constant assumption, the energy prior will mislead the DL model.

### Mechanism 3
- **Claim:** Using metric-inspired soft labels preserves physical distance relationships during classification-based localization.
- **Mechanism:** Instead of one-hot encoding (which treats adjacent distances as unrelated), the authors generate soft labels yi using an exponential kernel based on absolute distance error (Eq. 4). This forces the network to learn a smooth manifold where nearby ranges have similar feature representations, improving robustness to quantization errors.
- **Core assumption:** The underlying physical space (range) is continuous, and errors should be penalized proportionally to distance (MAE).
- **Evidence anchors:**
  - [section]: Section II.B and Eq. (4) define the label softening specifically to account for the metric (absolute error).
  - [abstract]: Refers to the method as "coupling... with an estimation based on received signal strength," implied here by the metric handling.
  - [corpus]: General literature on "soft labels" supports this, but specific "metric-inspired" evidence is text-internal.
- **Break condition:** If the classes are not ordered (e.g., categorizing source type rather than range), this smoothing would introduce erroneous correlations.

## Foundational Learning

- **Concept:** Source-Free Domain Adaptation (SFDA)
  - **Why needed here:** To adapt a model to a new ocean environment without accessing the original training data (source) or new ground truth labels (target).
  - **Quick check question:** How can you fine-tune a model on test data when you don't know the correct answers? (Answer: By maximizing prediction confidence and diversity, or using physics-based constraints).

- **Concept:** Sample Covariance Matrix (SCM) & Transmission Loss
  - **Why needed here:** Understanding the input features (SCM) and the physical constraint (Energy/Transmission Loss) is required to implement the joint likelihood.
  - **Quick check question:** Why normalize the SCM before feeding it to the neural network? (Answer: To remove source power dependency from the DL input, forcing the "energy" branch to handle source power separately).

- **Concept:** Jensen-Shannon Divergence (JSD)
  - **Why needed here:** The loss function uses JSD to minimize the distance between the predicted PMF and the soft labels, which is more stable for probability distributions than standard cross-entropy.
  - **Quick check question:** Why use JSD instead of Cross-Entropy for soft labels? (Answer: JSD is symmetric and bounded, often providing more stable gradients when both targets and predictions are distributions).

## Architecture Onboarding

- **Component map:** Input (2-channel Real/Imaginary SCM) -> Feature Extractor (3-layer CNN) -> Linear Classifier -> Softmax PMF; Auxiliary Input (Received Energy) for physics-based fusion

- **Critical path:**
  1. **Pre-training:** Train entire network on source environment data using soft labels and JSD loss.
  2. **Freeze:** Lock Classifier weights; keep Feature Extractor trainable.
  3. **Initialize Adaptation:** Forward pass target data; identify "certain" samples (Set S) via PMF peak ratio.
  4. **Estimate Physics:** Calculate average Energy vs. Range curve Γ̂ using Set S.
  5. **Fuse & Label:** For uncertain samples (S^c), use Energy E to select the best peak from the PMF (Bayesian fusion) to generate pseudo-labels.
  6. **Adapt:** Minimize JSD between network outputs and pseudo-labels (JSEA Loss).

- **Design tradeoffs:**
  - **Classification vs. Regression:** Framing ranging as classification allows the extraction of uncertainty (PMF) and the use of information maximization losses, but requires careful handling of label distance (softening).
  - **Robustness vs. Accuracy:** The energy-based estimator is robust but coarse; the DL estimator is accurate but brittle. The system trades pure DL accuracy for system-level robustness via the Bayesian product.

- **Failure signatures:**
  - **Collapse to Single Class:** If the information maximization loss (entropy term) is too weak, the model may classify all target inputs as a single range.
  - **Energy Model Divergence:** If the "certain" set S contains errors, the estimated Transmission Loss curve Γ̂ will be biased, causing the energy prior to fail for the uncertain set.

- **First 3 experiments:**
  1. **Validation of Soft Labels:** Train on source data with one-hot labels vs. metric-inspired soft labels (Eq. 4) and compare MAE to ensure distance-awareness is learned.
  2. **Ablation on Uncertainty Threshold:** Vary the "10x peak ratio" threshold for Set S to find the balance between coverage (size of S) and reliability (accuracy of S).
  3. **Mismatch Sensitivity:** Run JSEA vs. Pre-trained vs. SHOT across increasing sound speed profile perturbations (Δc) to isolate the contribution of the energy-based fusion.

## Open Questions the Paper Calls Out
- **Open Question 1:** Does JSEA maintain efficacy when tested on real-world at-sea data, as opposed to Bellhop simulations?
- **Open Question 2:** How does the method perform when source depth is variable or mismatched between the source and target domains?
- **Open Question 3:** Is the JSEA adaptation stable if the pre-trained model exhibits "confident errors" (low uncertainty but high error) in the self-supervising set?

## Limitations
- The method relies on the assumption that high confidence in the pre-trained model correlates with correct predictions, which may fail under severe environmental shifts
- The Gaussian assumption for transmission loss in the energy model may not hold in complex environments with strong refraction or multipath effects
- Performance with unknown source powers or non-piecewise constant transmission loss profiles has not been demonstrated

## Confidence
- **High confidence:** The core architecture (CNN feature extractor + frozen classifier) and the JSD loss formulation are well-established and properly implemented based on the specifications
- **Medium confidence:** The effectiveness of the metric-inspired soft labels and the Bayesian coupling approach shows good empirical results but relies on assumptions about PMF peak significance and energy-independence that require further validation across diverse environments
- **Low confidence:** The method's performance with unknown source powers or non-piecewise constant transmission loss profiles has not been demonstrated

## Next Checks
1. **Threshold Sensitivity Analysis:** Systematically vary the PMF peak ratio threshold (e.g., 5x, 10x, 20x) and evaluate the trade-off between self-supervision set size and adaptation performance to identify optimal operating points
2. **Cross-Environment Generalization:** Test JSEA on completely different environmental configurations (e.g., shallow water, different frequency ranges) to assess whether the energy-based coupling mechanism remains effective when the underlying propagation physics changes
3. **Source Power Variation:** Evaluate performance when source power varies by ±10 dB from the nominal value to determine the method's robustness to source level uncertainty, which directly affects the energy-based estimator