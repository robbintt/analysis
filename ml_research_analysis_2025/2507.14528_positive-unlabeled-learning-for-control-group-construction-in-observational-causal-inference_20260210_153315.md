---
ver: rpa2
title: Positive-Unlabeled Learning for Control Group Construction in Observational
  Causal Inference
arxiv_id: '2507.14528'
source_url: https://arxiv.org/abs/2507.14528
tags:
- units
- control
- treated
- causal
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using Positive-Unlabeled (PU) learning to construct
  reliable control groups for observational causal inference when labeled control
  units are missing. The method employs PU techniques to identify control units from
  unlabeled data using only treated (positive) units, enabling unbiased Average Treatment
  Effect (ATE) estimation.
---

# Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference

## Quick Facts
- arXiv ID: 2507.14528
- Source URL: https://arxiv.org/abs/2507.14528
- Reference count: 24
- This paper proposes using Positive-Unlabeled (PU) learning to construct reliable control groups for observational causal inference when labeled control units are missing

## Executive Summary
This paper introduces a novel approach to observational causal inference that addresses the common challenge of missing control group data. By leveraging Positive-Unlabeled (PU) learning techniques, the authors demonstrate how to identify reliable control units from unlabeled observational data using only treated (positive) units. The method enables unbiased Average Treatment Effect (ATE) estimation even when control labels are unavailable, which is particularly valuable in domains like agriculture, environmental sciences, and earth sciences where control group data collection is often impractical or impossible.

The proposed framework integrates PU learning into the causal inference pipeline by first identifying potential control units from unlabeled data, then estimating treatment effects using standard causal inference methods. Extensive experiments on both synthetic and real-world agricultural datasets show that the approach successfully recovers control units and produces ATE estimates close to ground truth values. The method shows particular promise when using richer feature sets beyond traditional adjustment variables, suggesting that domain-specific features can significantly improve causal effect estimation in observational settings.

## Method Summary
The method employs PU learning techniques to construct control groups for observational causal inference by treating treated units as positive examples and unlabeled units as potential controls. The approach works by first identifying potential control units from unlabeled observational data using PU learning algorithms, then estimating treatment effects using these identified controls. The framework leverages the assumption that treated units can serve as anchors for identifying similar control units from the unlabeled pool. Key steps include feature selection using both standard adjustment sets and domain-specific features, PU learning model training to distinguish between treated and potential control units, and subsequent ATE estimation using standard causal inference methods on the expanded control set. The method demonstrates that using richer feature sets beyond traditional adjustment variables yields superior performance in identifying true control units.

## Key Results
- Control recall up to 0.97 and control precision up to 0.97 in identifying true control units from unlabeled data
- Treated leakage as low as 0.027, indicating minimal contamination of control groups with treated units
- ATE estimates close to true effect values, demonstrating unbiased causal effect estimation
- Superior performance when using richer feature sets beyond standard adjustment sets

## Why This Works (Mechanism)
The method works by treating the observational causal inference problem as a PU learning task where treated units are labeled as positive examples and unlabeled units contain both true controls and potential controls. PU learning algorithms can leverage the information from positive examples to identify patterns and characteristics that distinguish treated units from controls, even without explicit negative labels. By training on treated units and applying the learned model to unlabeled data, the method can probabilistically identify which unlabeled units are most likely to be true controls based on their similarity to the treated group. The richer feature sets beyond standard adjustment variables provide additional discriminative power, allowing the PU model to capture more nuanced differences between treated and control units that may not be apparent using only traditional causal inference features.

## Foundational Learning

**Positive-Unlabeled Learning**: Machine learning paradigm where only positive examples are labeled and unlabeled data contains both positive and negative classes. Needed to handle situations where control group labels are missing but observational data exists. Quick check: Can the algorithm distinguish between positive and negative classes using only positive-labeled examples?

**Causal Inference with Observational Data**: Statistical framework for estimating treatment effects from observational studies where randomized controlled trials are not feasible. Needed to estimate ATE in domains where control group data is unavailable. Quick check: Does the method produce unbiased ATE estimates when compared to ground truth?

**Feature Selection for Causal Adjustment**: Process of identifying relevant variables that need to be controlled for to achieve unbiased causal effect estimates. Needed to ensure proper confounding adjustment in observational studies. Quick check: Are the selected features sufficient to block all backdoor paths between treatment and outcome?

## Architecture Onboarding

Component Map: Treated Units -> PU Learning Model -> Identified Control Units -> Causal Inference Model -> ATE Estimate

Critical Path: The most critical path is the PU learning model's ability to accurately distinguish between treated and control units from unlabeled data. Success depends on the quality of feature representation and the appropriateness of the PU learning algorithm for the specific data distribution.

Design Tradeoffs: The main tradeoff is between using richer feature sets (which may capture more relevant information but increase dimensionality and computational complexity) versus sticking to traditional adjustment sets (which are theoretically justified but may miss important domain-specific patterns). Another tradeoff exists between different PU learning algorithms, with unbiased estimators being theoretically preferable but potentially more computationally intensive than biased estimators.

Failure Signatures: The method may fail when the positivity assumption is violated (treated and control units have very different distributions), when there is significant overlap between treated and control distributions making discrimination difficult, or when the feature representation does not capture the relevant differences between groups. Computational failure may occur with very large datasets due to the complexity of PU learning algorithms.

First Experiments:
1. Test PU learning performance on synthetic data with known ground truth to verify the method can recover true control units
2. Evaluate ATE estimation accuracy using both unbiased and biased PU learning estimators to assess sensitivity to algorithmic choices
3. Compare performance using traditional adjustment set features versus domain-specific richer features on real-world agricultural data

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Performance may degrade when the positivity assumption is violated or when there is significant overlap between treated and control distributions
- The assumption that treated units can serve as reliable anchors for identifying controls may not hold in all observational settings
- Computational complexity and scalability to large datasets were not thoroughly evaluated
- Limited generalizability beyond agricultural domains due to focus on specific application areas

## Confidence
- High confidence in the feasibility of PU learning for control group construction when labeled controls are missing
- Medium confidence in the superiority of richer feature sets beyond standard adjustment sets
- Medium confidence in the generalizability across domains beyond agriculture

## Next Checks
1. Test the method's robustness under varying degrees of overlap between treated and control distributions using synthetic data with known ground truth
2. Evaluate performance when using different PU learning algorithms (e.g., unbiased risk estimators vs. biased estimators) to assess sensitivity to algorithmic choices
3. Conduct external validation on non-agricultural datasets from different domains to assess generalizability of the approach