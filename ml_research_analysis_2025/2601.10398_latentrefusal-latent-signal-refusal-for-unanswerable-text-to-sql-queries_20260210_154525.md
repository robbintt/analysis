---
ver: rpa2
title: 'LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries'
arxiv_id: '2601.10398'
source_url: https://arxiv.org/abs/2601.10398
tags:
- refusal
- probe
- arxiv
- text-to-sql
- schema
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LATENTREFUSAL, a latent-signal refusal mechanism
  that predicts query answerability from intermediate hidden activations of a large
  language model (LLM). The approach addresses the safety-critical failure mode of
  unanswerable and underspecified queries in LLM-based text-to-SQL systems, which
  can generate executable but semantically incorrect SQL.
---

# LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries

## Quick Facts
- **arXiv ID:** 2601.10398
- **Source URL:** https://arxiv.org/abs/2601.10398
- **Reference count:** 40
- **Primary result:** Improves average F1 to 88.5% on unanswerable query detection for Text-to-SQL systems

## Executive Summary
This paper introduces LATENTREFUSAL, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of a frozen LLM. The approach addresses a critical failure mode in LLM-based text-to-SQL systems where unanswerable or underspecified queries generate executable but semantically incorrect SQL. LATENTREFUSAL uses a lightweight Tri-Residual Gated Encoder (TRGE) probe to suppress schema noise and amplify sparse mismatch cues between questions and schemas, enabling a single-pass, low-latency refusal decision before SQL generation.

## Method Summary
LATENTREFUSAL extracts hidden states from a specific intermediate layer of a frozen LLM during a single forward pass. These states are sanitized to handle numerical instability, then processed by a 4-layer TRGE probe with SwiGLU-gated residual branches. The probe outputs a binary answerability decision that gates SQL generation. The method achieves 88.5% F1 on four benchmarks while adding only ~2ms overhead.

## Key Results
- Achieves 88.5% F1 on unanswerable query detection across four benchmarks
- Adds approximately 2 milliseconds of probe overhead to generation latency
- Outperforms linear probes (70.4% F1) and standard MLP probes (83.0% F1) by 10-18 percentage points
- Optimal layer selection at layer -16 provides 87.0% F1 with 99.8% recall on unanswerable queries

## Why This Works (Mechanism)

### Mechanism 1: Pre-Generation Latent-State Gating
Answerability can be predicted from intermediate hidden states before SQL generation. A frozen LLM encodes question-schema consistency information during its forward pass, and a lightweight probe reads these states to make a binary decision. Core assumption: the model's internal representations encode epistemic uncertainty about unanswerable queries before this uncertainty collapses into confident hallucination during decoding.

### Mechanism 2: Schema Noise Suppression via Tri-Residual Gating
The TRGE adds a third SwiGLU-gated residual pathway to suppress irrelevant schema tokens while preserving localized mismatch cues. The gate acts as a soft, input-conditioned feature selector that down-weights schema boilerplate and amplifies sparse signals like missing columns or impossible joins. Core assumption: refusal-relevant signals are sparse and spatially localized within long schema-conditioned prompts.

### Mechanism 3: Middle-Layer Signal Localization
Optimal refusal signals reside in middle-to-late intermediate layers (around layer -16 for 8B models), not final or early layers. Early layers encode surface features; final layers are shaped toward confident generation. Middle layers retain uncertainty representations that predict answerability before they are resolved or suppressed.

## Foundational Learning

- **Selective Classification / Reject Option**: LATENTREFUSAL implements a reject option where the system abstains under uncertainty. Understanding the safety-utility trade-off helps set thresholds. Quick check: Given a refusal threshold τ, what happens to false refusal rate as τ increases?

- **Probing Classifiers on Frozen Representations**: The probe trains on extracted hidden states without modifying the base LLM. This requires understanding representation extraction, normalization, and training stability. Quick check: Why might NaN values appear in hidden states during mixed-precision inference, and how does sanitization help?

- **Gated Architectures (GLU Variants)**: TRGE uses SwiGLU gating to implement soft feature selection. Understanding how gates differ from standard MLPs explains the architectural advantage. Quick check: How does a SwiGLU gate differ from a standard feedforward layer in terms of how it modulates input features?

## Architecture Onboarding

- **Component map:** Input prompt -> Frozen Base LLM -> Hidden-State Sanitizer -> TRGE Probe -> Aggregation Head -> Refusal Gate
- **Critical path:** Input prompt → frozen LLM forward pass → extract H^(l*) → sanitize → TRGE encoding → pool → classify → gate decision → (refuse or generate SQL)
- **Design tradeoffs:** Deeper layers offer higher precision; middle layers offer better recall balance. 4-layer probe optimal; deeper probes show diminishing returns. Higher threshold τ increases safety but raises false refusal rate.
- **Failure signatures:** High false refusal rate → threshold τ too aggressive or probe overfitted. Confident hallucinations pass through → probe layer too early or training lacks edge cases. NaN crashes → sanitization step missing.
- **First 3 experiments:**
  1. **Layer ablation:** Extract hidden states from layers {-1, -8, -16, -24, -32} on held-out validation; plot F1/Recall per layer to confirm optimal l*.
  2. **Architecture swap:** Replace TRGE with linear probe and standard Transformer encoder; measure F1 gap to quantify tri-residual gating contribution.
  3. **Threshold calibration:** Sweep τ ∈ [0.3, 0.7] on development data; plot false refusal rate vs. missed unanswerable rate to select operating point.

## Open Questions the Paper Calls Out

### Open Question 1
Can domain-invariant representation learning or meta-learning enable a single probe to act as a "universal safety gate" across disparate domains without fine-tuning? The authors identify generalization across domains as a limitation and call for future research into universal safety gating via meta-learning.

### Open Question 2
Can multi-layer fusion or schema-aware attention mechanisms improve detection of unanswerability in queries requiring complex, multi-hop reasoning? The authors identify "Deep Reasoning Chains" as a failure mode and propose exploring multi-layer fusion in future work.

### Open Question 3
How can the latent-signal refusal mechanism be made robust to "Semantic Near-Misses" where schema elements are semantically similar but logically distinct? The probe relies on hidden activations that may encode semantic similarity strongly, causing it to overlook subtle logical boundaries required to refuse the query.

## Limitations
- Performance on frontier models (GPT-4, Claude) remains untested; distillation may collapse answerability signals
- Robustness to diverse prompt templates and schema representation styles is unproven
- Safety-utility trade-off requires operational deployment guidance for threshold calibration

## Confidence
- **High Confidence**: Probe architecture advantage well-supported by ablation studies (F1 drops of 1.7-17.1% when removing SwiGLU gating)
- **Medium Confidence**: 2ms latency claim assumes fixed hardware; real-world overhead may vary
- **Low Confidence**: Schema noise suppression advantage lacks direct corpus validation and contextualization

## Next Checks
1. **Cross-Model Layer Validation**: Test LATENTREFUSAL on a 70B parameter model and verify if layer -16 still provides optimal F1. If performance drops, conduct new layer-wise ablation.
2. **Prompt Template Robustness**: Create three alternative question-schema prompt formats and measure F1 degradation. If drops exceed 5%, investigate TRGE gating overfitting.
3. **Threshold Calibration Under Utility Constraints**: Sweep τ from 0.3 to 0.7 on held-out answerable queries; identify threshold keeping false refusal below 5% while maintaining >85% recall on unanswerable queries.