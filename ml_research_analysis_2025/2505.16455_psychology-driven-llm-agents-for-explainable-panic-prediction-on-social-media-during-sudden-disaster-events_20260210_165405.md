---
ver: rpa2
title: Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media
  during Sudden Disaster Events
arxiv_id: '2505.16455'
source_url: https://arxiv.org/abs/2505.16455
tags:
- panic
- user
- emotion
- risk
- disaster
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PsychoAgent, a psychology-driven LLM agent
  framework for explainable panic prediction on social media during sudden disasters.
  The method combines human-LLM collaboration to create a fine-grained panic emotion
  dataset (COPE), integrates cross-domain features through psychological mechanisms,
  and uses a chain-of-thought LLM agent to simulate individual psychological chains.
---

# Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events

## Quick Facts
- arXiv ID: 2505.16455
- Source URL: https://arxiv.org/abs/2505.16455
- Authors: Mengzhu Liu; Zhengqiu Zhu; Chuan Ai; Chen Gao; Xinghong Li; Lingnan He; Kaisheng Lai; Yingfeng Chen; Xin Lu; Yong Li; Quanjun Yin
- Reference count: 40
- Primary result: 86% accuracy, 0.87 AUC, 12.6%-21.7% improvement over baselines

## Executive Summary
PsychoAgent introduces a psychology-driven LLM agent framework for explainable panic prediction during sudden disasters. The system integrates cross-domain heterogeneous data through psychological mechanisms, combining pre-disaster user profiles with disaster features to simulate individual psychological chains. By using a chain-of-thought LLM agent to model risk perception and cognitive differences in emotion generation, the framework achieves 86% accuracy while providing transparent, mechanistic interpretation of panic prediction decisions.

## Method Summary
PsychoAgent combines human-LLM collaboration to create the COPE dataset, extracts multi-domain features through psychological mechanisms, and uses a chain-of-thought LLM agent to simulate individual psychological chains. The four-stage pipeline processes disaster perception, risk perception via PPDTS questionnaires, panic arousal scoring, and controlled tweet generation. A multi-expert verification system evaluates generated content before final panic classification using a "one-vote veto" rule at the user level.

## Key Results
- Achieves 86% accuracy and 0.87 AUC on panic prediction task
- Outperforms baseline models by 12.6% to 21.7% across macro-averaged metrics
- Ablation studies show significant performance degradation when removing psychological components (RS, EA, MEA)

## Why This Works (Mechanism)

### Mechanism 1: Domain-to-Cognition Causal Chain
- Claim: Physical disaster characteristics causally influence panic emotion through a mediated cognitive pathway
- Core assumption: The proposed four-domain pathway (physical → information → cognitive → social) accurately reflects human panic formation
- Evidence anchors: Framework description in Section 3.1, psychological grounding claims
- Break condition: Failure to extract meaningful features from pre-disaster posts or sparse user profiles

### Mechanism 2: Theory-Grounded Feature Fusion for Prediction
- Claim: Fusing multi-domain features via psychological theory improves panic prediction over single-modality data fitting
- Core assumption: Psychological scales and theories computationally map to real user panic responses
- Evidence anchors: Section 3.2 feature extraction, ablation study in Section 4.3
- Break condition: Unreliable or biased psychological feature extraction models on target population

### Mechanism 3: Chain-of-Thought Agent for Explainable Simulation
- Claim: CoT-driven LLM role-playing agent can simulate an interpretable psychological chain for transparent prediction
- Core assumption: LLMs can validly enact role-playing with psychological depth and produce realistic social media responses
- Evidence anchors: Section 3.3 CoT design, Appendix A.4.4 prompt templates
- Break condition: LLM hallucination or guardrail suppression causing unrealistic simulations

## Foundational Learning

- **Risk Perception & Emotion Arousal Theory**
  - Why needed: Framework built on modeling how individuals perceive disaster threats and translate that to panic
  - Quick check: Explain how "coping effectiveness and sense of control" factor might lower panic probability

- **LLM Role-Playing & Chain-of-Thought (CoT) Prompting**
  - Why needed: Core predictive engine is an LLM prompted to act as specific user, reasoning through psychological chain step-by-step
  - Quick check: What's the difference between standard prompt and CoT prompt designed to simulate psychological assessment?

- **Feature Extraction from Social Media Text**
  - Why needed: System relies on extracting personality, sentiment trends, topics, and linguistic style from pre-disaster posts
  - Quick check: Why might bert-base-personality require consistency validation on your specific dataset?

## Architecture Onboarding

- **Component map**: Pre-disaster posts → Feature Extraction → Agent Initialization → Stages 1-4 Simulation → Generated Text → MoE Verification → BERT Classification → User-level Panic Label
- **Critical path**: Data pipeline (COPE dataset) → Feature extractors (personality, sentiment, topics, tone) → Agent core (4-stage CoT-driven LLM) → Verification system (MoE) → Final rule (one-vote veto)
- **Design tradeoffs**: Interpretability vs. complexity, LLM size vs. cost, simulation realism vs. guardrail constraints
- **Failure signatures**: Stylistic mismatch (formal text failing linguistic expert check), psychological inconsistency (contradicting personality profile), hallucination (inventing disaster facts)
- **First 3 experiments**: 1) Ablation study (remove RS, EA, MEA components), 2) Scalability test (different LLM sizes 14B-671B), 3) Case analysis (inspect 5-10 prediction disagreements with baselines)

## Open Questions the Paper Calls Out

1. How can PsychoAgent framework be expanded to model panic propagation dynamics across social networks rather than individual-level prediction? [explicit: Conclusion states future work should "investigate panic propagation dynamics across social networks."]

2. What robust self-correction mechanisms can be integrated to mitigate LLM hallucinations causing deviations from psychological priors? [explicit: Limitations note "LLM hallucinations may cause deviations from psychological priors" and suggest integrating "more robust self-correction mechanisms."]

3. How can linguistic realism of LLM-generated panic texts be improved to bridge semantic divergence with authentic user posts? [explicit: Limitations identify "stylistic differences between LLM-generated panic texts and authentic user posts" as source of potential false negatives.]

## Limitations

- Performance improvements rely on proprietary datasets and complex multi-stage LLM workflows that may not generalize
- Framework's dependence on LLMs introduces potential instability from hallucination, guardrail conflicts, and generation style mismatches
- Psychological mechanisms, while theoretically grounded, require empirical validation that the four-domain causal chain accurately represents actual panic formation processes

## Confidence

- **High**: Four-domain psychological framework provides coherent theoretical structure
- **Medium**: Performance improvements are promising but need independent replication
- **Medium**: Chain-of-thought agent design appears sound, though LLM implementation impacts outcomes
- **Low**: Generalizability of psychological scales and computational mapping remains uncertain

## Next Checks

1. Apply PsychoAgent to panic prediction during a different disaster event (e.g., COVID-19 social media data) and compare performance metrics against Hurricane Sandy results to assess robustness.

2. Systematically disable individual components (Risk Sensing, Emotion Arousal, Multi-Expert Assessment) across multiple disaster scenarios to quantify marginal contributions and identify potential overfitting.

3. Run controlled experiments with increasingly constrained LLM versions to measure impact of safety guardrails on negative emotion generation accuracy and false negative rates.