---
ver: rpa2
title: '[Re] Improving Interpretation Faithfulness for Vision Transformers'
arxiv_id: '2509.14846'
source_url: https://arxiv.org/abs/2509.14846
tags:
- attention
- methods
- interpretability
- robustness
- segmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work reproduces Hu et al. (2024)'s findings on Faithful Vision
  Transformers (FViTs), which use Diffusion Denoised Smoothing (DDS) to improve interpretability
  robustness against adversarial attacks.
---

# [Re] Improving Interpretation Faithfulness for Vision Transformers

## Quick Facts
- **arXiv ID:** 2509.14846
- **Source URL:** https://arxiv.org/abs/2509.14846
- **Reference count:** 40
- **Primary result:** FViTs with DDS achieve more stable segmentations and classification under PGD attacks compared to standard ViTs

## Executive Summary
This reproduction study validates the findings of Hu et al. (2024) on Faithful Vision Transformers (FViTs), which employ Diffusion Denoised Smoothing (DDS) to enhance interpretability robustness against adversarial attacks. The study confirms that FViTs demonstrate improved segmentation performance (up to 8 percentage points mIoU gain) and maintain higher classification AUC values under both positive and negative PGD perturbations compared to standard ViTs. The research extends the original work by testing DDS with Attribution Rollout and baseline methods, confirming its plug-in nature for improving interpretability robustness. However, the computational cost increases substantially, with runtime increasing over 10-fold in some cases.

## Method Summary
The reproduction implements FViTs by integrating DDS into Vision Transformers to improve interpretation faithfulness under adversarial attacks. The method involves applying denoising diffusion techniques to smooth adversarial perturbations before processing through the transformer architecture. The study evaluates performance across segmentation tasks using mIoU metrics and classification tasks using AUC values under PGD attack scenarios. Implementation follows the original methodology with extensions to Attribution Rollout and baseline methods to test DDS's plug-in capability.

## Key Results
- FViTs improve mIoU by up to 8 percentage points in image segmentation under PGD attacks
- Classification AUC values remain higher under both positive and negative perturbations
- Adding DDS to Attribution Rollout yields the best overall performance, though computational cost increases over 10-fold

## Why This Works (Mechanism)
DDS enhances interpretation faithfulness by smoothing adversarial perturbations before they reach the transformer layers, creating more stable feature representations that resist attack-induced artifacts. The denoising process effectively filters out high-frequency noise components that adversarial attacks typically introduce, while preserving the underlying semantic information needed for accurate segmentation and classification. This stabilization of intermediate representations translates to more consistent attention patterns and attribution maps, improving the reliability of interpretability methods like Attribution Rollout when analyzing model decisions under attack conditions.

## Foundational Learning

### Diffusion Denoising
**Why needed:** Removes adversarial noise while preserving semantic content in input data
**Quick check:** Verify denoising preserves class-relevant features while eliminating high-frequency attack patterns

### Adversarial Robustness Metrics
**Why needed:** Quantifies model stability under attack conditions for both accuracy and interpretability
**Quick check:** Ensure metrics capture both classification performance and segmentation quality under PGD perturbations

### Attribution Methods
**Why needed:** Provides interpretable explanations of model decisions through attention and feature attribution
**Quick check:** Validate attribution maps remain stable and meaningful after denoising operations

## Architecture Onboarding

**Component map:** Input -> DDS Denoising -> ViT Backbone -> Classification/Segmentation Head -> Interpretability Module (Attribution Rollout)

**Critical path:** Input image undergoes DDS denoising, then passes through ViT layers where attention mechanisms process features, followed by task-specific heads for predictions and attribution generation

**Design tradeoffs:** DDS improves robustness but increases computational overhead by 10x+; the denoising process adds latency but enables more faithful interpretations under attack

**Failure signatures:** Poor denoising parameters lead to either over-smoothing (loss of semantic details) or insufficient noise removal (continued vulnerability to attacks)

**First experiments:**
1. Test DDS parameters on clean images to establish baseline denoising effectiveness
2. Apply PGD attacks to standard ViT and measure attribution instability
3. Compare mIoU and AUC metrics between FViT and baseline under increasing attack strength

## Open Questions the Paper Calls Out
None

## Limitations
- Limited testing to synthetic PGD attacks without real-world adversarial scenarios
- Computational cost analysis focuses on runtime without comprehensive environmental impact assessment
- Implementation discrepancies with original work suggest sensitivity to hyperparameter choices

## Confidence
- FViT robustness claims under PGD attacks: **High** (reproduced across segmentation and classification tasks with consistent metrics)
- Computational cost analysis: **Medium** (quantitative but limited to runtime, lacks full environmental impact assessment)
- DDS plug-in nature: **High** (confirmed through controlled ablation studies with Attribution Rollout)
- Real-world applicability: **Low** (restricted to synthetic adversarial scenarios)

## Next Checks
1. Test FViT robustness against adaptive adversarial attacks that specifically target the denoising mechanism, including gradient-based attacks designed to circumvent DDS
2. Conduct comprehensive environmental impact assessment across multiple hardware platforms to quantify carbon footprint and energy efficiency trade-offs
3. Validate the plug-in nature of DDS with Attribution Rollout on additional vision tasks (object detection, instance segmentation) and larger ViT variants (Swin Transformer, ConvNeXt)