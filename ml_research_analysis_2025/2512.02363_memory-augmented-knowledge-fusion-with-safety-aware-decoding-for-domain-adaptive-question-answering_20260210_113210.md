---
ver: rpa2
title: Memory-Augmented Knowledge Fusion with Safety-Aware Decoding for Domain-Adaptive
  Question Answering
arxiv_id: '2512.02363'
source_url: https://arxiv.org/abs/2512.02363
tags:
- knowledge
- karma
- safety
- language
- fusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces KARMA, a framework for domain-specific QA
  systems that integrates heterogeneous knowledge sources while ensuring accuracy
  and safety. KARMA uses a dual-encoder architecture for multi-source knowledge fusion,
  a gated memory unit for selective knowledge integration, and a safety-aware controllable
  decoder to suppress unsafe outputs.
---

# Memory-Augmented Knowledge Fusion with Safety-Aware Decoding for Domain-Adaptive Question Answering

## Quick Facts
- arXiv ID: 2512.02363
- Source URL: https://arxiv.org/abs/2512.02363
- Reference count: 12
- Primary result: KARMA achieves 86.1% accuracy, 85.0% F1 score, 12.4% rejection rate for unsafe queries, and 0.882 knowledge relevance score on elderly service QA task.

## Executive Summary
This paper introduces KARMA, a framework for domain-specific QA systems that integrates heterogeneous knowledge sources while ensuring accuracy and safety. KARMA uses a dual-encoder architecture for multi-source knowledge fusion, a gated memory unit for selective knowledge integration, and a safety-aware controllable decoder to suppress unsafe outputs. The model is built on LLaMA-7B with adapter-based fine-tuning and trained using a multi-objective loss function balancing language fluency, knowledge alignment, and safety control. Experiments on a proprietary elderly service QA dataset show KARMA achieves 86.1% accuracy, 85.0% F1 score, 12.4% rejection rate for unsafe queries, and 0.882 knowledge relevance score—outperforming strong baselines. The framework offers a comprehensive solution for building trustworthy and adaptive QA systems in sensitive service contexts.

## Method Summary
KARMA implements a three-stage architecture: Multi-Source Knowledge Fusion (MKF) uses dual-encoder retrieval with temperature-scaled similarity weighting (τ_k=0.05) to fuse knowledge from heterogeneous documents. A Gated Memory Unit (GMU) applies GRU-style gating with sparsity regularization to selectively integrate external knowledge versus internal parametric knowledge. The Safety-Aware Controllable Decoder (SCD) employs a two-stage approach with utterance-level pre-check and token-level dynamic modulation to suppress unsafe outputs. The model uses LLaMA-7B with adapter-based fine-tuning and trains with a multi-objective loss combining language modeling, safety control, knowledge alignment, and gate sparsity. The framework is evaluated on a proprietary elderly service QA dataset with metrics for accuracy, F1, rejection rate, and knowledge relevance.

## Key Results
- KARMA achieves 86.1% accuracy on elderly service QA task, outperforming baselines by 5.1-10.8 percentage points
- Knowledge Relevance Score reaches 0.882, demonstrating effective integration of retrieved knowledge
- Safety-Aware Decoder achieves 12.4% rejection rate for unsafe queries, a 6× improvement over baseline
- GMU component provides 1.8% accuracy improvement by enabling selective knowledge integration

## Why This Works (Mechanism)

### Mechanism 1: Temperature-Scaled Dual-Encoder Retrieval
Separating query and document encoding with temperature-controlled similarity weighting improves knowledge relevance over single-encoder approaches. Two independent Transformer encoders produce query embedding $h_q$ and document embeddings $h_{k_i}$. Relevance weights $\alpha_i$ are computed via softmax over scaled dot products with $\tau_k = 0.05$ sharpening the distribution toward top matches. Fused knowledge $k_{fused} = \sum_i \alpha_i \cdot h_{k_i}$.

### Mechanism 2: Gated Selective Knowledge Integration
A GRU-inspired gating mechanism allows the model to learn when to rely on external knowledge vs. internal parametric knowledge. The GMU computes update gate $z_t$ and reset gate $r_t$ at each timestep, blending candidate state with input. Sparsity regularization discourages over-reliance on external knowledge.

### Mechanism 3: Two-Stage Safety-Aware Decoding
Combining utterance-level pre-check with token-level dynamic modulation provides defense-in-depth against unsafe outputs. Stage 1 computes $P^{pre}_{reject}$ before generation; Stage 2 computes per-token rejection $p_{rej,t}$. Decoding logits are modulated with learned bias to suppress unsafe continuations.

## Foundational Learning

- **Dual-encoder vs. cross-encoder retrieval**: KARMA uses dual-encoder for efficient retrieval; understanding the precision-speed tradeoff is essential for tuning $\tau_k$ and interpreting KRS scores. Quick check: Given query "How do I apply for Medicare?" and documents A (Medicare application guide), B (Medicaid history), C (general insurance overview), which would a low temperature $\tau_k$ weight most heavily?

- **GRU-style gating (update and reset gates)**: The GMU directly adapts GRU mechanics; without this foundation, debugging gate saturation or sparsity issues is impossible. Quick check: If $z_t \approx 1$ for all tokens, what behavior would you observe in the final output?

- **Controllable decoding with learned bias vectors**: The SCD modulates logits via learned mask $m$; understanding how bias vectors shape token probabilities is prerequisite for adjusting $\lambda_{safe}$. Quick check: If $\lambda_{safe}$ is doubled, how would the probability of tokens in $m$ change relative to other tokens?

## Architecture Onboarding

- **Component map**: Input Query → [MKF Dual-Encoder] → k_fused → [GMU] → h_t → [SCD] → Safety-check → Modulated logits → Output
- **Critical path**: MKF retrieval quality → GMU gate behavior → SCD threshold sensitivity. Errors propagate forward; poor retrieval cannot be fully recovered by downstream components.
- **Design tradeoffs**: Adapter vs. full fine-tuning (efficiency vs. accuracy); temperature $\tau_k$ (sharpness vs. diversity); safety thresholds (false rejection vs. unsafe output risk).
- **Failure signatures**: Gate collapse (all $z_t \approx 0$ → ignores knowledge); over-rejection (benign queries rejected → $\tau_{pre}$ too low); knowledge hallucination (high accuracy but low KRS → GMU not integrating $k_{fused}$).
- **First 3 experiments**: 1) Ablation by component: +MKF only, +MKF+GMU, Full on held-out set; 2) Temperature sweep: $\tau_k \in \{0.01, 0.05, 0.1, 0.2\}$; 3) Safety threshold calibration: vary $\tau_{pre}$ and $\tau_{tok}$ to plot rejection vs. false positive rate.

## Open Questions the Paper Calls Out

### Open Question 1
Does integrating explicit terminology alignment modules (such as DATA) improve the Safety-Aware Controllable Decoder's ability to maintain factual consistency in medical policy queries? The current KARMA framework utilizes standard adapters and does not implement the specialized terminology alignment modules discussed in the related work. A comparative ablation study evaluating factual consistency scores on medical subsets with and without the specialized alignment layers would resolve this.

### Open Question 2
How does the model's utility (F1 score) degrade as the safety threshold hyperparameters ($\tau_{pre}$ and $\tau_{tok}$) are tightened to minimize risk? The paper reports results at a specific operating point without analyzing the trade-off curve between aggressive safety filtering and answer availability. A parametric sweep plotting Rejection Rate against F1 Score would visualize the safety-utility frontier.

### Open Question 3
Do the adapter-based knowledge fusion mechanisms generalize effectively to significantly larger foundational models (e.g., 70B+ parameters) without fine-tuning instability? The methodology is implemented exclusively on LLaMA-7B, leaving scalability unverified on larger architectures. Application to LLaMA-70B or comparable models, reporting training stability metrics and accuracy, would resolve this.

## Limitations
- Proprietary dataset prevents independent validation of reported metrics (86.1% accuracy, 85.0% F1, 12.4% rejection rate, 0.882 KRS)
- Learned safety mask vector $m$ and rejection thresholds ($\tau_{pre}$, $\tau_{tok}$) are underspecified
- Grid search ranges for hyperparameters ($\beta$, $\gamma$, $\delta$, $\lambda_{safe}$) are not reported
- Temperature parameter $\tau_k=0.05$ is stated but not justified with ablation against alternatives

## Confidence

- **High confidence**: Architectural framework and mathematical formulations (Equations 1-12) are fully specified and build on well-established components
- **Medium confidence**: Empirical results and claimed performance improvements due to proprietary dataset preventing independent verification
- **Low confidence**: Generalizability of safety-aware decoding to other domains, as only demonstrated on one elderly service dataset

## Next Checks

1. **Ablation validation with public dataset**: Reproduce the full ablation study (+MKF only, +MKF+GMU, Full KARMA) on a public medical QA dataset to verify claimed component contributions and establish whether gains generalize beyond proprietary data.

2. **Temperature sensitivity analysis**: Systematically sweep $\tau_k$ values (0.01, 0.05, 0.1, 0.2) on a domain-adjacent dataset while measuring KRS, retrieval diversity, and generation fluency to validate whether fixed $\tau_k=0.05$ is optimal.

3. **Safety threshold calibration curve**: Vary $\tau_{pre}$ and $\tau_{tok}$ across plausible ranges and plot rejection rate vs. false positive rate on a dataset with labeled unsafe queries to determine whether 12.4% rejection rate represents appropriate operating point.