---
ver: rpa2
title: 'The State of Multilingual LLM Safety Research: From Measuring the Language
  Gap to Mitigating It'
arxiv_id: '2505.24119'
source_url: https://arxiv.org/abs/2505.24119
tags:
- safety
- language
- multilingual
- linguistics
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reveals a significant English-centric bias in multilingual
  LLM safety research, with over 80% of publications focusing solely on English despite
  growing global deployment. Even high-resource non-English languages like Mandarin
  receive only ~10% of the research attention compared to English.
---

# The State of Multilingual LLM Safety Research: From Measuring the Language Gap to Mitigating It

## Quick Facts
- arXiv ID: 2505.24119
- Source URL: https://arxiv.org/abs/2505.24119
- Reference count: 40
- Over 80% of multilingual LLM safety research focuses exclusively on English despite global deployment

## Executive Summary
This paper reveals a significant English-centric bias in multilingual LLM safety research, with over 80% of publications focusing solely on English despite growing global deployment. Even high-resource non-English languages like Mandarin receive only ~10% of the research attention compared to English. The study finds that non-English languages are rarely studied in depth as standalone topics, instead appearing superficially in broad multilingual evaluations that lack cultural nuance. Additionally, only half of English safety research documents the languages studied, obscuring coverage limitations. To address these gaps, the paper proposes three research directions: developing culturally-grounded evaluation benchmarks, generating diverse multilingual safety training data, and understanding crosslingual safety generalization through mechanistic interpretability and training data influence analysis.

## Method Summary
The paper conducted a systematic survey of nearly 300 publications from 2020-2024 across *ACL venues (ACL, EMNLP, conferences and workshops), filtering by keyword matching "safe" and "safety" in paper abstracts. Authors manually annotated each paper for safety subtopic category, languages covered, and whether languages were explicitly documented. Inter-annotator agreement was measured via Cohen's κ (0.80-0.96) and Jaccard similarity for language lists. The methodology involved 4×20 pairwise agreement studies across distinct subsets to ensure annotation reliability.

## Key Results
- Over 80% of multilingual LLM safety research focuses exclusively on English
- Non-English languages are rarely studied in depth as standalone topics, appearing only superficially in broad multilingual evaluations
- Only half of English safety research documents the languages studied, obscuring coverage limitations

## Why This Works (Mechanism)

### Mechanism 1: Worst-case safety evaluation over average metrics
- Claim: Reporting worst-case harmlessness scores across languages reveals critical safety failures that average metrics obscure.
- Mechanism: Instead of uniformly weighted averages across languages, models are evaluated on their minimum safety score across all tested languages, exposing the weakest language-specific protections.
- Core assumption: Safety alignment should meet a minimum threshold in all supported languages rather than optimizing average performance.
- Evidence anchors: [abstract] identifies gaps in safety coverage and proposes culturally-grounded evaluation benchmarks; [section] Table 4 demonstrates Vicuna has 69.32 average score but only 18.4 worst-case in Bengali—"despite a high average harmlessness score, Vicuna's worst-case harmlessness score is just 18.4 due to unsafe behaviour in Bengali"

### Mechanism 2: Natural linguistic pattern evaluation (code-switching, transliteration)
- Claim: Safety evaluations testing real-world multilingual communication patterns expose vulnerabilities missed by monolingual testing.
- Mechanism: Adversarial testing incorporates mixed-language utterances and non-standard orthographies that real speakers use, revealing safety guardrail bypasses.
- Core assumption: Models will be used in natural multilingual communication patterns, not just standard monolingual inputs.
- Evidence anchors: [abstract] proposes "developing culturally-grounded evaluation benchmarks"; [section] "Arabizi form—a system of writing Arabic using English characters" can jailbreak models; code-switching "is shown to be able to jailbreak multilingual safety guardrails"

### Mechanism 3: Mechanistic interpretability for differential crosslingual transfer
- Claim: Reverse-engineering neural network circuits can explain why some safety training transfers across languages (detoxification, debiasing) while other training doesn't (refusal training).
- Mechanism: Component-level analysis identifies which alignment behaviors are language-agnostic versus language-specific.
- Core assumption: Safety alignment has different crosslingual transfer properties depending on the safety behavior type.
- Evidence anchors: [abstract] proposes "understanding crosslingual safety generalization through mechanistic interpretability"; [section] "detoxification and debiasing can transfer effectively across languages but not refusal training"—this differential transfer needs mechanistic explanation

## Foundational Learning

- **Crosslingual Transfer in LLMs**
  - Why needed here: The paper's core question is why some safety training transfers across languages while other training doesn't. Understanding transfer mechanisms is essential for efficient multilingual alignment.
  - Quick check question: Can you explain why a model trained to refuse harmful requests in English might not refuse equivalent requests in Bengali?

- **Constitutional AI Framework**
  - Why needed here: Paper proposes using constitutional AI (principle-based critique and revision) for generating culturally-contextualized synthetic safety data.
  - Quick check question: How would you modify constitutional AI principles to capture culture-specific harms that differ from Western norms?

- **Influence Functions**
  - Why needed here: Paper recommends influence functions to trace how specific training examples causally affect model behavior for understanding crosslingual alignment.
  - Quick check question: If influence analysis showed English safety data had minimal impact on Bengali outputs, what would that suggest about your alignment strategy?

## Architecture Onboarding

- Component map: Evaluation layer -> Data generation layer -> Analysis layer
- Critical path:
  1. Identify target languages and culture-specific harm categories
  2. Generate/translate safety data with cultural grounding
  3. Train/align model with multilingual data
  4. Evaluate with worst-case metrics and natural linguistic patterns
  5. Apply interpretability/influence analysis to diagnose transfer failures

- Design tradeoffs:
  - Breadth vs. depth: Paper shows non-English languages studied "in herds" (broad multilingual studies) rather than standalone—sacrifices depth for coverage
  - Synthetic vs. human-annotated: Constitutional AI scales but may miss cultural nuances native speakers catch
  - Average vs. worst-case optimization: Worst-case may sacrifice overall capability

- Failure signatures:
  - High average safety with low worst-case score (Table 4: Vicuna 69.32 avg, 18.4 Bengali worst)
  - Safety in standard scripts but vulnerability in transliteration (Arabizi example)
  - Safety in monolingual contexts but code-switching vulnerability
  - Detoxification/debiasing transfers but refusal training doesn't

- First 3 experiments:
  1. Replicate Table 4 on your model: compute average and worst-case harmlessness across all supported languages to identify hidden gaps.
  2. Test code-switching attacks: Create adversarial prompts mixing high/low-resource languages (English-Bengali) to evaluate guardrail robustness.
  3. Influence function analysis: Trace English safety training examples' influence on 2-3 non-English language outputs to quantify transfer effectiveness.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can adaptive thresholding mechanisms be designed to establish language-specific safety baselines rather than relying on aggregated average scores?
- Basis in paper: [explicit] Section 3.1 explicitly recommends exploring "adaptive thresholding mechanisms that establish language-specific safety baselines" to avoid the "false sense of safety" created by average performance metrics.
- Why unresolved: Current evaluations rely on uniformly weighted averages that obscure critical safety failures in specific languages (e.g., Vicuna's high average but low worst-case score in Bengali).
- What evidence would resolve it: A benchmarking framework that sets distinct, non-uniform safety thresholds for individual languages, successfully filtering models that pass average checks but fail in specific linguistic contexts.

### Open Question 2
- Question: Why does safety alignment transfer effectively for detoxification and debiasing but fail for refusal training across different languages?
- Basis in paper: [explicit] Section 3.3 identifies this specific discrepancy as a phenomenon mechanistic interpretability should explain to characterize knowledge transfer mechanisms.
- Why unresolved: The internal neural mechanisms that facilitate crosslingual transfer for some safety behaviors (detoxification) but not others (refusal) are not yet understood.
- What evidence would resolve it: Mechanistic analysis isolating specific model circuits or components that activate during successful crosslingual detoxification but remain inactive or unaligned during refusal scenarios.

### Open Question 3
- Question: How can influence functions be utilized to trace the causal impact of specific training examples on crosslingual safety alignment?
- Basis in paper: [explicit] Section 3.3 notes there is "very limited work" on analyzing training-example-to-output relationships for safety behaviors and recommends influence functions to quantify how high-resource vs. low-resource examples contribute to outputs.
- Why unresolved: It is currently unknown which specific documents in a pretraining or fine-tuning corpus drive harmful behaviors in multilingual settings.
- What evidence would resolve it: A study successfully employing influence functions to identify and rank specific training documents that are causally responsible for safety alignment failures in low-resource languages.

### Open Question 4
- Question: How can automated methods be developed to detect culture-specific safety issues that are typically lost during machine translation?
- Basis in paper: [explicit] Section 3.2 states that "future work should focus on developing automated methods to identify culture-specific safety issues that might be lost in translation."
- Why unresolved: Machine translation often fails to preserve culture-specific harms or introduces bias, and current methods lack automated validation for these nuances.
- What evidence would resolve it: An automated validation tool that flags culturally specific safety violations in synthetic data generated via translation, verified by human cultural experts.

## Limitations
- The survey's findings are limited by the scope of *ACL venues (2020-2024) and keyword-based filtering, potentially missing safety research from non-*ACL venues, industry publications, or using alternative terminology.
- The annotation process relies on manual categorization of safety subtopics and language coverage, introducing subjective interpretation variability despite κ=0.83 inter-annotator agreement.
- The survey cannot capture actual safety performance differences between languages—it only documents research attention gaps.

## Confidence

- **High confidence**: The quantitative finding that >80% of safety research focuses exclusively on English is robust, given the clear methodology and reproducible annotation framework. The observation that language coverage is rarely documented in safety papers (only ~50% of English-focused research states languages studied) is also well-supported by the data.

- **Medium confidence**: The proposed three research directions (culturally-grounded evaluation, diverse multilingual safety data, and crosslingual generalization analysis) are conceptually sound but lack empirical validation within this survey paper. The claim about differential crosslingual transfer (detoxification/debiasing transfers, refusal training doesn't) requires further mechanistic investigation beyond the survey scope.

- **Low confidence**: Specific numerical comparisons like "Mandarin receives only ~10% of the research attention compared to English" are difficult to verify without knowing the exact denominator and inclusion criteria for what constitutes "research attention."

## Next Checks
1. Replicate the annotation framework: Independently apply the paper's categorization scheme to a random sample of 50 safety papers to measure inter-annotator agreement and test the robustness of the linguistic bias findings.

2. Extend venue coverage: Survey safety research from non-*ACL venues (NeurIPS, ICML, industry arXiv releases, workshops) using the same methodology to determine if the English-centric bias persists across the broader research ecosystem.

3. Validate proposed mechanisms: Conduct a controlled experiment testing whether worst-case harmlessness scoring (minimum across languages) actually identifies safety failures missed by average metrics, using at least two models with known multilingual safety performance differences.