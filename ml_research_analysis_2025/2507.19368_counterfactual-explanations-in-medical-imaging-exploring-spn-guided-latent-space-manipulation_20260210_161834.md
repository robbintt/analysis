---
ver: rpa2
title: 'Counterfactual Explanations in Medical Imaging: Exploring SPN-Guided Latent
  Space Manipulation'
arxiv_id: '2507.19368'
source_url: https://arxiv.org/abs/2507.19368
tags:
- counterfactual
- latent
- space
- learning
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores using sum-product networks (SPNs) within variational
  autoencoders (VAEs) to generate counterfactual explanations for medical imaging
  decisions. The method trains a semi-supervised VAE to learn a latent space, then
  replaces its classifier with an SPN to model the distribution of latent features
  conditioned on class labels.
---

# Counterfactual Explanations in Medical Imaging: Exploring SPN-Guided Latent Space Manipulation

## Quick Facts
- arXiv ID: 2507.19368
- Source URL: https://arxiv.org/abs/2507.19368
- Reference count: 33
- Primary result: SPN-guided latent space manipulation generates robust counterfactuals for medical imaging, maintaining moderate validity across different KL regularization levels and outperforming MLP baselines in reliability.

## Executive Summary
This paper explores using Sum-Product Networks (SPNs) within Variational Autoencoders (VAEs) to generate interpretable counterfactual explanations for medical imaging decisions. The method trains a semi-supervised VAE to learn a latent space, then replaces its classifier with an SPN to model the distribution of latent features conditioned on class labels. Counterfactual examples are generated by optimizing the latent space to maximize the probability of a target class while minimizing deviation from the original. Experiments on the CheXpert dataset demonstrate that the SPN-based approach maintains moderate validity across different levels of KL divergence regularization, outperforming a neural network baseline in robustness.

## Method Summary
The method trains a semi-supervised VAE (ResNet encoder/decoder, 7 layers, latent dim 62) with Gaussian noise on each layer. After training, the latent embeddings are extracted and used to learn an SPN structure via LearnSPN. The SPN is converted to a TensorFlow 2 graph and replaces the VAE's MLP classifier. Counterfactuals are generated by optimizing the latent vector using gradient descent to maximize the target class probability under the SPN while minimizing L2 distance and log-probability deviation from the original. The CheXpert dataset is filtered to a binary task (Cardiomegaly vs. No Finding), balanced, and preprocessed with CLAHE and 128×128 resizing.

## Key Results
- SPN maintains moderate validity (0.43-0.89) across KL regularization levels, while MLP baseline validity drops near 0% at low regularization
- High KL regularization ensures validity but reduces plausibility/proximity; low regularization improves detail but reduces validity
- Visualizations show SPNs consistently identify relevant regions (e.g., around the heart) for generating plausible counterfactuals

## Why This Works (Mechanism)

### Mechanism 1
Replacing the MLP classifier with an SPN allows the optimization process to query not just class probability but also the likelihood of the latent vector itself, theoretically keeping generated counterfactuals within the boundaries of the learned data distribution. The SPN models the joint distribution p(Z, Y) rather than just decision boundaries.

### Mechanism 2
The KL-divergence regularization weight (β₁) acts as a control knob for the validity vs. plausibility trade-off. High β₁ enforces a tighter, more Gaussian latent space making it easier to interpolate between classes (high validity) but may result in blurrier reconstructions. Low β₁ allows more freedom but creates irregular decision boundaries that are harder to cross.

### Mechanism 3
Simultaneous gradient-based manipulation of all latent variables captures multivariate feature dependencies more effectively than independent perturbation. This is critical for complex medical features where classification decisions depend on correlated latent dimensions.

## Foundational Learning

- **Concept: Variational Autoencoders (VAEs) & ELBO**
  - Why needed: Understanding how the Evidence Lower Bound balances reconstruction accuracy against latent space regularization is crucial for grasping why changing β₁ changes the counterfactual landscape
  - Quick check: If I increase β₁, will the latent space become more rigid (Gaussian) or more flexible/irregular?

- **Concept: Sum-Product Networks (SPNs)**
  - Why needed: SPNs are deep probabilistic circuits that allow exact inference, distinguishing them from standard black-box neural nets
  - Quick check: Why does the paper claim SPNs allow "exact and efficient inference" compared to standard Neural Networks?

- **Concept: Counterfactual Metrics (Validity, Proximity, Plausibility)**
  - Why needed: The paper optimizes for these conflicting goals; you need to distinguish "validity" (did the class flip?) from "plausibility" (is it a realistic image?)
  - Quick check: Does a high validity score guarantee that the generated image is medically plausible?

## Architecture Onboarding

- **Component map:** Encoder (ResNet CNN) -> Latent Space (62-dim vector) -> Decoder (ResNet CNN) -> SPN Classifier
- **Critical path:**
  1. Pre-train semi-supervised VAE with MLP classifier head
  2. Extract latent codes and learn SPN structure using LearnSPN
  3. Convert SPN to TensorFlow graph and replace MLP
  4. Optimize latent vector via gradient descent using SPN probabilities
- **Design tradeoffs:** High β₁ gives high Validity/Low Detail; Low β₁ gives Low Validity/High Detail
- **Failure signatures:** MLP collapse at low regularization (validity near 0%), implausible artifacts indicated by high FID, SPFlow compatibility issues
- **First 3 experiments:**
  1. Hyperparameter sweep varying β₁ to observe trade-off between reconstruction loss and classification accuracy
  2. Ablation study comparing Switch Epoch and validity of SPN vs. MLP at low β₁ settings
  3. Visual verification of counterfactuals with β, γ terms on/off to confirm SPN highlights correct regions

## Open Questions the Paper Calls Out

- Can alternative, relative formulations of L2 proximity and FID better capture counterfactual-specific characteristics compared to standard absolute metrics?
- How does assessment of individual counterfactual diversity and weighted combinations improve selection of most effective explanations over mean results?
- What specific factors govern the trade-off between counterfactual validity and plausibility during latent space manipulation?

## Limitations

- Method's reliance on SPN structure learning introduces uncertainty about robustness across different datasets or latent dimensionalities
- Computational cost of SPN conversion and counterfactual optimization is not reported, limiting scalability assessment
- Claim that SPNs produce more "plausible" counterfactuals is not directly validated against human judgments

## Confidence

- **High confidence:** Mechanism of KL regularization controlling validity-plausibility trade-off (supported by Table 3 and VAE theory)
- **Medium confidence:** SPN's advantage in robustness over MLP (demonstrated but exact reasons remain partially speculative)
- **Medium confidence:** Visual evidence of localized changes (Figure 3) but consistency across classes not tested

## Next Checks

1. Perform t-SNE/PCA visualization of latent embeddings for varying β₁ to confirm validity improvements correlate with smoother, more Gaussian latent manifolds
2. Replace SPN with standard Gaussian mixture model in classifier head and compare validity/proximity trade-offs to isolate effect of SPN's exact inference
3. Conduct user study to assess whether SPN-generated counterfactuals are perceived as more realistic or clinically relevant than MLP-generated ones, especially in cases of low validity