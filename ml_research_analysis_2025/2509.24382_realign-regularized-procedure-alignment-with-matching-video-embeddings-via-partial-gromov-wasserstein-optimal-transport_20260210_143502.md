---
ver: rpa2
title: 'REALIGN: Regularized Procedure Alignment with Matching Video Embeddings via
  Partial Gromov-Wasserstein Optimal Transport'
arxiv_id: '2509.24382'
source_url: https://arxiv.org/abs/2509.24382
tags:
- learning
- conference
- videos
- vision
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: REALIGN addresses the challenge of aligning procedural videos with
  background noise, repeated actions, and non-monotonic step orders. It introduces
  a self-supervised framework based on Regularized Fused Partial Gromov-Wasserstein
  Optimal Transport (R-FPGWOT), which jointly models semantic similarity and temporal
  structure while allowing partial frame-to-frame assignments.
---

# REALIGN: Regularized Procedure Alignment with Matching Video Embeddings via Partial Gromov-Wasserstein Optimal Transport

## Quick Facts
- **arXiv ID:** 2509.24382
- **Source URL:** https://arxiv.org/abs/2509.24382
- **Reference count:** 40
- **Primary result:** Achieves up to 18.9% average F1-score improvements and over 30% temporal IoU gains over state-of-the-art methods for aligning procedural videos with background noise and non-monotonic step orders.

## Executive Summary
REALIGN addresses the challenge of aligning procedural videos containing background noise, repeated actions, and non-monotonic step orders. The method introduces a self-supervised framework based on Regularized Fused Partial Gromov-Wasserstein Optimal Transport (R-FPGWOT) that jointly models semantic similarity and temporal structure while allowing partial frame-to-frame assignments. A virtual sink frame handles unmatched content, and contrastive regularization stabilizes training. Across egocentric (EgoProceL) and third-person (ProceL, CrossTask) benchmarks, REALIGN achieves significant improvements over prior state-of-the-art methods while producing more interpretable alignments that preserve key-step orderings while filtering out noise.

## Method Summary
REALIGN uses a self-supervised framework that extracts visual features using a ResNet-50 backbone with 2-frame temporal context, passes them through 2x 3D Conv layers, and projects to 128-dim embeddings. The core alignment is performed via Regularized Fused Partial Gromov-Wasserstein Optimal Transport (R-FPGWOT), which computes a transport matrix including a virtual sink frame. The optimization uses an unbalanced Sinkhorn algorithm within a Majorization-Minimization loop, with a loss combining R-FPGWOT distance, Contrastive Inverse Difference Moment (C-IDM), and inter-sequence contrastive loss. Post-processing uses α-Expansion graph cut for clustering k key-steps, which are then mapped to ground truth using Hungarian matching.

## Key Results
- Achieves up to 18.9% average F1-score improvements compared to prior state-of-the-art methods
- Demonstrates over 30% temporal IoU gains on procedure alignment tasks
- Successfully handles background noise, repeated actions, and non-monotonic step orders in both egocentric and third-person video datasets

## Why This Works (Mechanism)

### Mechanism 1: Partial Transport via Virtual Sink
REALIGN handles background noise and redundant frames by allowing unmatched content rather than forcing incorrect alignments. The framework extends the transport matrix with a "virtual frame" acting as a sink. If the matching probability for a frame falls below a threshold ζ, mass is transported to this virtual sink instead of a mismatched frame in the other video. This is governed by unbalanced OT penalties (τ). The core assumption is that irrelevant frames have low semantic similarity and distinct structural signatures compared to key steps, allowing the model to isolate them as "unmatched."

### Mechanism 2: Fused Semantic-Structural Alignment
The framework combines visual similarity with temporal structure through a Fused Gromov-Wasserstein (FGW) formulation. It minimizes a joint cost: (1) Kantorovich OT (KOT) for feature similarity (C) and (2) Gromov-Wasserstein OT (GWOT) for preserving intra-sequence temporal distances (Cx, Cy). This allows steps to "slide" in time (reorder) as long as their internal temporal coherence is preserved. The core assumption is that the relative temporal distances between frames within a single video provide a reliable structural signature, even if the absolute order varies across videos.

### Mechanism 3: Regularized Contrastive Stabilization
Contrastive regularization and Laplace priors prevent the transport map from collapsing into degenerate solutions. The method uses Inverse Difference Moment (IDM) terms and a Laplace-shaped prior Q to encourage diagonal concentration (temporal smoothness). Crucially, it uses Inter-sequence Contrastive Loss to push "best" matches closer and "worst" matches apart, stabilizing the embedding space. The core assumption is that valid procedural alignments tend to have smooth temporal transitions and distinct embeddings for non-adjacent steps.

## Foundational Learning

**Gromov-Wasserstein Optimal Transport (GWOT):** Unlike standard OT which matches features directly (e.g., "this red apple" to "that red apple"), GWOT matches *structures* (e.g., "this pair of frames is close" to "that pair of frames is close"). This is essential for aligning videos where the steps appear in different orders. *Quick check:* Can you explain why standard OT fails when two videos perform the same steps but in reverse order, while GWOT might succeed?

**Unbalanced / Partial Optimal Transport:** Standard OT requires all mass to be transported (conservation of mass). In video, this forces every noisy background frame to match *something*. Partial OT allows "destroying" mass (sending it to the virtual sink), which is the core mechanism for noise filtering in REALIGN. *Quick check:* What happens to the transport matrix dimensions if you introduce a "virtual sink" frame to handle background noise?

**Sinkhorn Algorithm & Scaling:** The paper utilizes a Sinkhorn-like scaling algorithm to solve the regularized OT problem efficiently. Understanding this iterative "row/column normalization" is required to grasp how the optimization actually runs. *Quick check:* Why does adding an entropy regularization term (-εh(T)) make the OT problem solvable via the Sinkhorn algorithm?

## Architecture Onboarding

**Component map:** Encoder (ResNet-50) -> Cost Computation (Feature Cost C, Structure Costs Cx, Cy) -> R-FPGWOT Solver (MM loop with Unbalanced Sinkhorn) -> Transport Matrix T -> Loss Computer (R-FPGWOT + C-IDM + Inter-sequence) -> Graph Cut (α-Expansion clustering)

**Critical path:** The critical path is the Outer MM loop. You must compute the gradient of the GW term (G(s)), update the kernel K(s), run the Sinkhorn inner loop to get T^(s+1), and backpropagate the fused loss. The Virtual Frame logic is applied during the kernel construction and Sinkhorn scaling.

**Design tradeoffs:** Strictness vs. Noise (Marginal Relaxation τ): High τ forces strict 1:1 alignment (high noise sensitivity); Low τ allows partial matching (risk of discarding valid data). Appearance vs. Structure (ρ): Tuning ρ trades off visual fidelity against temporal ordering consistency. Speed vs. Accuracy (Sinkhorn Steps): The paper uses ≤25 inner iterations and 3-6 outer steps. Increasing these improves convergence but slows training significantly.

**Failure signatures:** "The Black Hole": All transport mass flows into the virtual sink. Check: Threshold ζ or unbalanced penalty τ. "Diagonal Rigidity": The model fails to align steps if they are slightly out of order. Check: Laplace prior weight or structural prior φ is too strong. "Fragmented Steps": A single action is split into multiple key-steps. Check: Graph cut parameters or number of clusters k.

**First 3 experiments:** Virtual Sink Ablation: Run alignment with τ → ∞ (forcing balanced OT) vs. the proposed partial setting. Verify if background frames in the "balanced" run corrupt the key-step embeddings. Transport Map Visualization: Visualize T for a pair of videos with known non-monotonic ordering. Check if the matrix shows "off-diagonal" streaks (indicating successful reordering) rather than a strictly diagonal line. Convergence Test: Plot the objective value J(T) over outer MM steps. Ensure the surrogate objective is monotonically decreasing as claimed in Theorem 2.

## Open Questions the Paper Calls Out

**Open Question 1:** How can the R-FPGWOT framework be extended to incorporate multi-modal inputs, such as narrated text or audio, to further refine alignment? The conclusion states the framework establishes a foundation for future work, explicitly "opening avenues for future extensions in multi-modal alignment." This is unresolved because the current formulation relies exclusively on visual embeddings and structural priors; the optimal transport cost function does not currently account for heterogeneous cross-modal distances.

**Open Question 2:** Can the framework be adapted to automatically infer the optimal number of key steps (k) rather than requiring it as a fixed hyperparameter? The authors note in the ablation study that the choice of k is "inherently subjective and task-dependent" and that incorrect values lead to performance drops (fragmentation or merging). This is unresolved because the current implementation requires k as a predefined input for the graphcut segmentation, lacking an internal mechanism to dynamically adjust the granularity of steps based on the transport map density.

**Open Question 3:** How does REALIGN perform on aligning full-length, dense video sequences without the sub-sampling strategy used in the experiments? The experimental setup utilizes a fixed "No. of sampled frames (N, M) = 32," suggesting the method has not been validated on high-resolution temporal alignment of long-duration videos. This is unresolved because the computational complexity of Gromov-Wasserstein OT scales quadratically, and it is unclear if the iterative Sinkhorn solver remains efficient or stable when processing thousands of frames directly.

## Limitations
- The virtual sink frame implementation relies on a large but unspecified finite cost, which could significantly impact noise filtering performance if mis-specified
- The exact derivation of unary costs for the graph cut clustering step is not explicitly detailed, creating ambiguity in the post-processing stage
- The specific hyperparameters for the encoder's 3D convolutional layers are omitted, potentially affecting feature extraction quality

## Confidence

**High confidence:** The core R-FPGWOT mathematical formulation, the use of contrastive regularization for stability, and the general performance improvements (18.9% F1, 30% IoU gains) across benchmarks

**Medium confidence:** The exact implementation details of the virtual sink mechanism and the graph cut clustering, as these require assumptions about unspecified parameters

**Low confidence:** The precise contribution of each regularization component to the overall performance, as ablation studies for individual terms are not provided

## Next Checks

1. **Virtual Sink Cost Sensitivity:** Systematically vary the virtual frame cost parameter and measure its impact on background noise filtering and key-step preservation
2. **Transport Matrix Analysis:** Visualize and quantify the distribution of transport mass between real frames and the virtual sink across different video pairs to verify the partial transport mechanism
3. **Contrastive Regularization Ablation:** Remove the C-IDM and inter-sequence contrastive losses individually to measure their specific contributions to preventing embedding collapse and stabilizing training