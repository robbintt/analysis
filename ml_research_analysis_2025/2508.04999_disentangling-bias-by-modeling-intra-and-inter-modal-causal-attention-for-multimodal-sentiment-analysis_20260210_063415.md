---
ver: rpa2
title: Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for
  Multimodal Sentiment Analysis
arxiv_id: '2508.04999'
source_url: https://arxiv.org/abs/2508.04999
tags:
- causal
- multimodal
- mmci
- sentiment
- cmu-mosi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles spurious correlations in multimodal sentiment
  analysis that arise from both intra- and inter-modal biases, leading to overfitting
  to statistical shortcuts rather than true causal relationships. To address this,
  the authors propose a Multi-relational Multimodal Causal Intervention (MMCI) model
  that uses backdoor adjustment from causal theory to mitigate these biases.
---

# Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis

## Quick Facts
- arXiv ID: 2508.04999
- Source URL: https://arxiv.org/abs/2508.04999
- Authors: Menghua Jiang; Yuxia Lin; Baoliang Chen; Haifeng Hu; Yuncheng Jiang; Sijie Mai
- Reference count: 40
- Primary result: Achieves state-of-the-art performance on multimodal sentiment analysis by addressing intra- and inter-modal biases through causal intervention

## Executive Summary
This paper tackles spurious correlations in multimodal sentiment analysis that arise from both intra- and inter-modal biases, leading to overfitting to statistical shortcuts rather than true causal relationships. To address this, the authors propose a Multi-relational Multimodal Causal Intervention (MMCI) model that uses backdoor adjustment from causal theory to mitigate these biases. The method first models multimodal inputs as a multi-relational graph to explicitly capture intra- and inter-modal dependencies, then applies graph attention networks to disentangle causal features from shortcut features, and finally applies backdoor adjustment to stratify and dynamically combine these features for robust predictions. Extensive experiments on CMU-MOSI, CMU-MOSEI, CH-SIMS, and OOD test sets show that MMCI achieves state-of-the-art performance, with significant improvements in accuracy, F1-score, and correlation metrics compared to existing multimodal and causal-based methods, demonstrating superior generalization under distribution shifts.

## Method Summary
MMCI addresses multimodal bias through a three-stage approach: (1) Multi-relational graph construction with 6 relation types (3 intra-modal, 3 inter-modal) to capture structural dependencies, (2) Dual attention mechanism using Graph Attention Networks to separate features into causal and shortcut representations, enforced by KL divergence constraints, and (3) Backdoor adjustment via stratification that dynamically combines causal features with sampled shortcut features during training. The model uses DeBERTa for text, COVAREP/LibROSA for audio, and Facet/OpenFace for visual features, with hyperparameters tuned per dataset. Training employs AdamW optimizer with warmup and early stopping, optimizing for both standard and intervention losses to achieve robust predictions.

## Key Results
- Achieves state-of-the-art performance on CMU-MOSI, CMU-MOSEI, and CH-SIMS datasets across all metrics
- Shows significant improvements in out-of-distribution generalization on CMU-MOSI OOD test set
- Ablation studies confirm the necessity of each component: disentanglement loss (7.3% drop without KL), intervention mechanism, and multi-relational graph construction
- Demonstrates superior performance compared to both traditional multimodal fusion methods and existing causal-based approaches

## Why This Works (Mechanism)

### Mechanism 1: Multi-Relational Graph Structuring
- **Claim:** Representing multimodal inputs as a multi-relational graph appears to preserve specific structural dependencies that are often collapsed in standard fusion approaches.
- **Mechanism:** The model constructs a graph $G$ with explicit relation types (e.g., text-text, audio-visual) rather than treating the input as a monolithic sequence. This allows the model to distinguish between intra-modal context (e.g., syntactic dependency in text) and inter-modal alignment (e.g., temporal synchrony), potentially preventing the "mixing" of unrelated features that leads to spurious correlations.
- **Core assumption:** Assumes that spurious correlations are relation-specific and can be isolated by explicitly modeling the topology of interactions rather than just feature similarity.
- **Evidence anchors:**
  - [Methodology] "We first model the multimodal inputs as a multi-relational graph to explicitly capture intra- and inter-modal dependencies."
  - [Corpus] Related work "Graph4MM" supports the efficacy of weaving structural information into multimodal learning to handle complex interconnections.
- **Break condition:** If the relations defined (e.g., temporal alignment) do not correspond to semantic reality in the dataset, the graph structure may introduce noise rather than clarity.

### Mechanism 2: Attention-Based Feature Disentanglement
- **Claim:** Separating features into "causal" and "shortcut" representations via constrained attention may reduce the model's reliance on dataset-specific artifacts.
- **Mechanism:** A Graph Attention Network (GAT) generates two distinct attention scores ($\alpha_c$ and $\alpha_s$) for each edge. The model enforces a constraint where the "shortcut" features ($H_s$) are trained to predict a uniform distribution (via KL divergence), theoretically stripping them of semantic label information, while the "causal" features ($H_c$) are trained to predict the label.
- **Core assumption:** Assumes that "shortcut" features are statistically predictive in the training set but semantically irrelevant to the ground truth, and can be mathematically separated from causal features.
- **Evidence anchors:**
  - [Methodology] "We apply an attention mechanism to separately estimate and disentangle the causal features and shortcut features."
  - [Ablation Study] The "w/o KL" setting shows a significant performance drop (7.3% on Acc7), validating the necessity of this specific disentanglement.
- **Break condition:** If the dataset bias is so pervasive that *all* features are correlated with the shortcut, the disentanglement constraint may fail to find a meaningful causal subspace.

### Mechanism 3: Interventional Training via Stratification
- **Claim:** Dynamically combining causal features with sampled shortcut features during training improves generalization to out-of-distribution (OOD) data.
- **Mechanism:** Instead of standard maximum likelihood estimation, the model approximates a causal intervention (backdoor adjustment). It stratifies the learned shortcut features $H_s$ and randomly combines them with $H_c$ during the intervention loss calculation ($L_{intv}$). This forces the final predictor to remain stable regardless of which shortcut pattern is present, effectively "blocking" the backdoor path from features to prediction.
- **Core assumption:** Assumes the identified shortcut features $H_s$ effectively act as confounders in the causal graph (satisfying the backdoor criterion).
- **Evidence anchors:**
  - [Abstract] "...applying the backdoor adjustment, we stratify the shortcut features and dynamically combine them... to produce stable predictions under distribution shifts."
  - [Experiments] Table 3 shows MMCI significantly outperforming baselines on the CMU-MOSI (OOD) test set.
- **Break condition:** If the hyperparameters $\lambda$ or $\beta$ (weights for disentanglement and intervention) are not tuned correctly, the intervention may either fail to remove the bias or remove too much valid signal.

## Foundational Learning

- **Concept: Causal Inference & Backdoor Adjustment**
  - **Why needed here:** The core theoretical contribution relies on Pearl's do-calculus. You cannot understand *why* the model mixes $H_c$ and $H_s$ without understanding $P(Y|do(C))$ vs. $P(Y|C)$.
  - **Quick check question:** Why does standard correlation-based learning fail when a confounder affects both the input (modalities) and the output (sentiment)?

- **Concept: Graph Attention Networks (GAT)**
  - **Why needed here:** The mechanism for splitting features relies on GATs computing relation-specific importance weights. Understanding how attention masks work is crucial for debugging the disentanglement.
  - **Quick check question:** How does the model ensure that the sum of causal attention and shortcut attention equals 1 for a given edge?

- **Concept: Disentangled Representation Learning**
  - **Why needed here:** The model attempts to map a single input to two distinct latent spaces (Causal vs. Shortcut). This requires understanding constraints like the KL divergence to Uniform distribution used in the paper.
  - **Quick check question:** What happens to the Shortcut representation $H_s$ if the disentanglement loss ($L_{unif}$) is successfully minimized?

## Architecture Onboarding

- **Component map:**
  DeBERTa/BERT encoders -> Multi-relational graph constructor (6 relation types) -> Dual GAT layers (causal/shortcut attention) -> Readout function -> Predictor heads

- **Critical path:**
  The flow from **Multi-relational Graph Construction** $\to$ **Dual Attention Estimation** $\to$ **Intervention Loss ($L_{intv}$)**. If the graph edges are incorrect, the attention mechanism cannot identify the correct bias; if the intervention loss is not applied, the model defaults to standard correlation.

- **Design tradeoffs:**
  - **Granularity vs. Complexity:** Defining 6 specific relations captures more nuance but increases graph construction overhead compared to simple concatenation.
  - **Strict Disentanglement vs. Performance:** Aggressive disentanglement (high $\lambda$) might strip away useful signal if the "causal" features are imperfectly learned.

- **Failure signatures:**
  - **High IID, Low OOD performance:** Indicates disentanglement failed; the model is still using shortcut features ($Z$) for prediction.
  - **Shortcut Loss ($L_{unif}$) Stuck:** The model cannot separate the bias, possibly because the bias is inextricably linked to the semantic content in the current feature space.

- **First 3 experiments:**
  1. **Ablation on Relations:** Run `w/o Intra-Rel` and `w/o Inter-Rel` to verify which relational biases are most prevalent in your specific dataset (as done in Table 4).
  2. **Hyperparameter Sensitivity ($\lambda, \beta$):** Sweep these parameters on a validation set. The paper notes that performance fluctuates significantly, especially in OOD settings.
  3. **Visualizing Attention:** Extract the $\alpha_c$ and $\alpha_s$ maps for a sample. Verify visually if $\alpha_c$ focuses on semantic keywords while $\alpha_s$ focuses on background/high-frequency non-semantic tokens.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the MMCI framework be effectively generalized to other multimodal tasks and architectures beyond Multimodal Sentiment Analysis (MSA) without extensive re-engineering?
- Basis in paper: [explicit] The Conclusion states that future research directions include "extending it into a general framework applicable to other multimodal models."
- Why unresolved: The current implementation is tailored to MSA with specific graph construction rules (e.g., dependency trees for text, temporal edges for audio/visual) and specific loss functions designed for regression/classification.
- What evidence would resolve it: Successful application of the MMCI causal graph and intervention mechanism to distinct tasks like Visual Question Answering (VQA) or Emotion Recognition in Conversation (ERC), demonstrating performance improvements comparable to those seen in MSA.

### Open Question 2
- Question: Do more advanced causal intervention strategies exist that can outperform the current backdoor adjustment via stratification?
- Basis in paper: [explicit] The Conclusion lists "exploring more advanced causal intervention strategies" as a primary future direction to further enhance the model.
- Why unresolved: The current study validates backdoor adjustment as effective, but the authors suggest this may not be the optimal ceiling for performance, leaving the potential of other causal methods unexplored.
- What evidence would resolve it: A comparative study integrating alternative causal methods (e.g., front-door adjustment or counterfactual regularization) into the MMCI architecture, showing statistically significant gains over the current backdoor implementation on OOD test sets.

### Open Question 3
- Question: Does enforcing the constraint $\alpha_{ij,c} + \alpha_{ij,s} = 1$ during attention estimation hinder the model by artificially forcing a strict separation between causal and shortcut features?
- Basis in paper: [inferred] Equation 4 mandates that the attention scores for causal and shortcut paths must sum to 1. This assumes a zero-sum relationship where a feature is strictly either causal or a shortcut.
- Why unresolved: In complex multimodal data, a feature might contain a mixture of causal signal and spurious correlation; forcing a binary split via a softmax might discard useful signal or retain unwanted bias.
- What evidence would resolve it: An ablation experiment where causal and shortcut attentions are modeled independently (e.g., using separate sigmoid functions) rather than competitively, resulting in higher accuracy or F1 scores.

### Open Question 4
- Question: How can the causal extraction mechanism be refined to better handle the "inherent ambiguity" of sentiment boundaries, specifically to improve fine-grained 7-class accuracy (Acc7)?
- Basis in paper: [inferred] The authors note in the results section that MMCI does not always achieve the best performance on Acc7, speculating that "ambiguity of sentiment boundaries and the uncertainty in the neutral category" pose challenges for precise causal feature extraction.
- Why unresolved: The current causal graph effectively filters coarse-grained biases, but the authors admit it struggles with the subtlety required to distinguish between adjacent sentiment classes (e.g., weakly positive vs. strongly positive).
- What evidence would resolve it: Modifications to the causal feature loss (e.g., introducing ordinal regression or uncertainty weighting) that specifically target boundary cases, leading to a measurable increase in Acc7 relative to baseline models.

## Limitations

- The multi-relational graph construction requires domain-specific knowledge about relevant relations, limiting generalization to new multimodal tasks
- The model's effectiveness depends on the assumption that spurious correlations can be captured by explicitly modeling 6 relation types, which may not hold for datasets with more complex bias patterns
- The hyperparameter sensitivity (particularly λ and β) suggests the intervention mechanism may be fragile to dataset-specific bias patterns
- The theoretical grounding in backdoor adjustment assumes the shortcut features satisfy the backdoor criterion, which isn't empirically validated for all three datasets

## Confidence

- **High Confidence:** The ablation studies (w/o Disentgl, w/o KL, w/o Intervention) demonstrate that each component contributes to performance improvements. The OOD generalization results show consistent improvements over baselines.
- **Medium Confidence:** The mechanism for separating causal from shortcut features via KL divergence to uniform distribution is theoretically sound but may not perfectly capture semantic irrelevance in practice. The effectiveness of the 6 specific relation types is dataset-dependent.
- **Low Confidence:** The assumption that all spurious correlations can be captured by explicitly modeling 6 relation types may not hold for datasets with more complex bias patterns. The paper doesn't address potential negative transfer from aggressive disentanglement.

## Next Checks

1. **Dataset Bias Analysis:** Conduct an analysis to identify whether the dataset contains specific inter- and intra-modal biases (e.g., "smiling correlates with positive sentiment") that the 6 relation types are designed to capture.

2. **Relation Type Ablation:** Systematically remove individual relation types (not just groups) to determine which specific edges contribute most to performance gains and whether certain relations are more critical for causal identification.

3. **Attention Visualization:** Extract and visualize the causal (α_c) and shortcut (α_s) attention maps for representative samples to verify that the model is correctly identifying semantically relevant vs. spurious features.