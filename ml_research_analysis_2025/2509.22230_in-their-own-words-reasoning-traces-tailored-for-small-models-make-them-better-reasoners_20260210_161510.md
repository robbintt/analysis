---
ver: rpa2
title: 'In Their Own Words: Reasoning Traces Tailored for Small Models Make Them Better
  Reasoners'
arxiv_id: '2509.22230'
source_url: https://arxiv.org/abs/2509.22230
tags:
- reasoning
- student
- traces
- arxiv
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of transferring reasoning capabilities
  from larger language models to smaller ones through supervised fine-tuning, where
  performance often degrades despite access to high-quality teacher demonstrations.
  The authors identify distributional misalignment as the core issue: reasoning traces
  from larger models contain tokens that are low probability under the student''s
  distribution, exceeding the internal representation capacity of smaller architectures
  and creating learning barriers rather than helpful guidance.'
---

# In Their Own Words: Reasoning Traces Tailored for Small Models Make Them Better Reasoners

## Quick Facts
- arXiv ID: 2509.22230
- Source URL: https://arxiv.org/abs/2509.22230
- Reference count: 21
- Key outcome: RSD traces tailored to student models improve reasoning transfer by 4.9% vs. 20.5% degradation from direct distillation

## Executive Summary
This paper addresses the challenge of transferring reasoning capabilities from larger language models to smaller ones through supervised fine-tuning, where performance often degrades despite access to high-quality teacher demonstrations. The authors identify distributional misalignment as the core issue: reasoning traces from larger models contain tokens that are low probability under the student's distribution, exceeding the internal representation capacity of smaller architectures and creating learning barriers rather than helpful guidance. They propose Reverse Speculative Decoding (RSD), a mechanism where the teacher model proposes candidate tokens but the student model determines acceptance based on its own probability distributions, filtering low probability tokens. When applied to Qwen3-0.6B, direct distillation of s1K-1.1 reasoning trace data degrades average performance across major reasoning benchmarks by 20.5%, while the same model trained on RSD-generated reasoning traces achieves meaningful improvements of 4.9%.

## Method Summary
The authors propose Reverse Speculative Decoding (RSD) to address distributional misalignment in knowledge transfer from large to small models. At each decoding step, RSD samples a token from the teacher's distribution and checks whether the student's probability for that token meets a threshold (pth). If the student probability is ≥ pth, the token is accepted; otherwise, the student samples its own token. This process continues until EOS. The optimal threshold identified is 1%, balancing preservation of teacher guidance with reduction of surprisal. The method uses rejection sampling (16 attempts) to ensure correctness and trains with hybrid UPFT for unsolved problems, using the first 128 tokens. Training employs batch size 16, bfloat16, learning rate 1e-5 with 5% warmup and cosine decay, AdamW optimizer, and 15 epochs.

## Key Results
- Direct distillation of s1K-1.1 reasoning traces degrades Qwen3-0.6B performance by 20.5% across reasoning benchmarks
- RSD with 1% threshold improves Qwen3-0.6B by 4.9% compared to baseline
- RSD traces are model-specific and do not transfer universally across architectures
- Sub-1% probability tokens strongly correlate with performance degradation (6.70% → 0.09% ratio with RSD)

## Why This Works (Mechanism)

### Mechanism 1
Filtering tokens with probability below 1% under the student's distribution improves reasoning transfer to compact models. At each decoding step, RSD samples from the teacher distribution and checks whether Ps(yi) ≥ pth. Low-probability tokens are rejected and replaced with student-sampled tokens, reducing token-level surprisal. Core assumption: Tokens with sub-1% probability indicate reasoning transitions that exceed the student's internal representation capacity (assumption supported by correlation with training failure). Evidence anchors: [abstract] Direct distillation of s1K-1.1 degrades Qwen3-0.6B by 20.5%; RSD with pth=1% improves by 4.9%. [section 4.2] Table 1 and Table 2 show sub-1% token ratios strongly correlate with performance degradation (6.70% → 0.09% with RSD). [corpus] Related work on local naturalness for distillation (arXiv:2510.03988) independently reports that distributional alignment improves student learning.

### Mechanism 2
RSD-generated traces must be tailored per student architecture; they do not transfer universally. Traces are generated under the specific probability distribution of a target student model. Cross-model experiments show transferred traces fail to benefit other architectures, even within the same model family. Core assumption: Distributional alignment is model-specific, not governed by universal cognitive load principles. Evidence anchors: [abstract] "RSD traces are model-specific rather than universally applicable." [section 5.1] Figure 4 and Table 4 show transferred traces degrade or fail to improve other models; tailored traces succeed. [corpus] No corpus papers directly test cross-model transfer of tailored traces; this appears underexplored.

### Mechanism 3
RSD preserves reasoning complexity while smoothing surprisal; it does not simplify logic. Qualitative trace comparisons (Figure 5, Figure 7) show RSD and teacher traces exhibit similar logical progression despite different probability profiles. Rejection sampling ensures correctness. Core assumption: Surprisal spikes, not logical depth, are the primary learning barrier for small models. Evidence anchors: [section 5.5] "Both trace segments exhibit similar logical progression and reasoning complexity." [corpus] Corpus papers on reasoning trace reformulation (arXiv:2510.11545) suggest information-preserving transformations can aid downstream tasks, consistent with this mechanism.

## Foundational Learning

- **Concept: Surprisal (−log Ps(yi))**
  - Why needed here: RSD's threshold mechanism operates on surprisal; understanding it is essential for tuning pth.
  - Quick check question: If a token has surprisal 5, what is its probability under the student? (Answer: e−5 ≈ 0.67%)

- **Concept: Speculative Decoding**
  - Why needed here: RSD inverts the standard speculative decoding paradigm (student-proposes, teacher-approves) to teacher-proposes, student-approves.
  - Quick check question: In standard speculative decoding, who proposes tokens and who verifies? How does RSD differ?

- **Concept: Tokenizer Compatibility**
  - Why needed here: RSD requires token-level probability evaluation across teacher and student; incompatible tokenizers break the mechanism.
  - Quick check question: Why can't you directly use RSD between models with different vocabularies?

## Architecture Onboarding

- **Component map**: Teacher model → candidate token sampling → Student model probability evaluation → threshold check → accept (teacher token) or fallback (student token) → context update → repeat until EOS

- **Critical path**: Ensure tokenizer compatibility (Appendix A); configure pth (start at 1%) and temperature (0.7 per paper); implement rejection sampling for correctness; train with hybrid UPFT for unsolved problems

- **Design tradeoffs**: Lower pth preserves more teacher guidance but risks higher surprisal; higher pth may be too restrictive (0.3% degraded performance in experiments). Multi-step RSD training degrades due to distributional drift (avoid)

- **Failure signatures**: Direct distillation degrades performance; sub-1% token ratio > 1% in traces; cross-model trace transfer yields no gain; multi-step iterative training collapses accuracy

- **First 3 experiments**:
  1. Baseline comparison: Train student on raw teacher traces vs. RSD traces (pth=1%) on a held-out reasoning benchmark
  2. Threshold sweep: Test pth ∈ {10%, 3%, 1%, 0.3%} and measure sub-1% token ratio, perplexity, and downstream accuracy
  3. Cross-model transfer check: Generate RSD traces for student A, apply to student B (different architecture), and compare against tailored traces for B

## Open Questions the Paper Calls Out

### Open Question 1
Can RSD traces be made transferable across models, or is per-model generation an inherent requirement? Basis in paper: [explicit] Authors state "cross-model experiments demonstrate that RSD traces are model-specific rather than universally applicable" and show transferred traces fail to benefit other models within and across families. Why unresolved: The paper demonstrates the problem empirically but does not propose solutions; the underlying cause (unique internal representations per architecture) suggests transferability may be fundamentally limited. What evidence would resolve it: A method that generates traces effective across multiple student architectures without per-model tailoring, or theoretical proof that distributional alignment is necessarily model-specific.

### Open Question 2
Can iterative multi-step RSD training be modified to compound improvements rather than degrade performance? Basis in paper: [explicit] Authors tested three-cycle RSD and found "performance degraded substantially due to compounding effects," attributing failure to distributional drift and overfitting to narrower reasoning pathways. Why unresolved: The experiment showed degradation but did not explore interventions (e.g., curriculum learning, regularization, or periodic realignment to base distributions) that might enable progressive improvement. What evidence would resolve it: An iterative training scheme with mechanisms to prevent compounding drift that shows sustained improvement over multiple cycles.

### Open Question 3
What architectural or pre-training characteristics predict whether a model will benefit from RSD? Basis in paper: [inferred] Qwen3-1.7B showed notable improvement while Llama-3.2-1B-Instruct showed minimal gains despite identical methodology; authors attribute this to linguistic style differences (verbose vs. terse reasoning) but do not systematically characterize predictors. Why unresolved: Only two model families were tested with tailored RSD, and the explanation remains correlational rather than establishing causal architectural factors. What evidence would resolve it: A systematic study across diverse architectures correlating pre-training characteristics (reasoning style, vocabulary, training data composition) with RSD effectiveness gains.

## Limitations
- Architecture-specific constraints: RSD requires tokenizer compatibility between teacher and student models, with exact handling of vocabulary discrepancies not fully specified
- Single-model validation: All experiments focus on a single student architecture (Qwen3-0.6B) and teacher model (s1.1-7B), limiting generalizability
- Threshold sensitivity: The paper identifies 1% as optimal but does not systematically explore relationship between threshold selection and reasoning task complexity

## Confidence
- **High confidence**: The core finding that direct distillation degrades small model performance (20.5% drop) while RSD improves it (4.9% gain) is well-supported by controlled experiments on three distinct reasoning benchmarks
- **Medium confidence**: The claim that RSD traces are model-specific rather than universally applicable is supported by cross-model transfer experiments, but these experiments use a limited set of architectures
- **Low confidence**: The assertion that RSD preserves reasoning complexity while smoothing surprisal relies primarily on qualitative trace comparisons without quantitative measures of logical depth

## Next Checks
1. **Threshold-Complexity Relationship**: Systematically test whether the optimal RSD threshold varies with reasoning task complexity. Measure performance across MATH problems of varying difficulty levels (pre-algebra to competition-level) while sweeping pth from 0.1% to 10%, analyzing both accuracy and token surprisal distributions.

2. **Cross-Architecture Transferability**: Generate RSD traces for Qwen3-0.6B using s1.1-7B, then test transfer to other small models (e.g., Qwen2.5-3B, Llama-3-8B) and report performance degradation/gains. Complement with architecture ablation by varying student capacity (0.3B, 1.5B, 3B) while holding teacher constant.

3. **Multi-Teacher Ensemble Distillation**: Implement ensemble RSD where candidate tokens are sampled from multiple teacher models (s1.1-7B, DeepSeek-Coder-6.7B, Qwen2.5-72B) and accepted based on student probability. Compare against single-teacher RSD to test whether combining diverse reasoning distributions improves transfer or introduces conflicting guidance.