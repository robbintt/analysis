---
ver: rpa2
title: 'Toward Better Generalisation in Uncertainty Estimators: Leveraging Data-Agnostic
  Features'
arxiv_id: '2507.03998'
source_url: https://arxiv.org/abs/2507.03998
tags:
- features
- feature
- data-agnostic
- arxiv
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large Language Models (LLMs) often generate factually incorrect
  responses with high confidence, posing risks in safety-critical applications. While
  methods leveraging hidden states for uncertainty estimation have shown promise,
  they suffer from poor generalization across tasks and domains.
---

# Toward Better Generalisation in Uncertainty Estimators: Leveraging Data-Agnostic Features

## Quick Facts
- **arXiv ID**: 2507.03998
- **Source URL**: https://arxiv.org/abs/2507.03998
- **Reference count**: 5
- **Primary result**: Incorporating data-agnostic features (token probabilities, entropy) with hidden states improves cross-task generalization of uncertainty probes in most scenarios, but effectiveness depends on relative feature importance and task similarity.

## Executive Summary
Large Language Models (LLMs) often generate factually incorrect responses with high confidence, posing risks in safety-critical applications. While methods leveraging hidden states for uncertainty estimation have shown promise, they suffer from poor generalization across tasks and domains. This work explores whether supplementing hidden-state features with data-agnostic features (e.g., token probabilities, entropy) can improve cross-task generalization. Experiments show that incorporating data-agnostic features generally enhances generalization, especially in short-form QA tasks, but not consistently across all cases. Feature selection—retaining only the most informative hidden-state dimensions—amplifies the contribution of data-agnostic features in most scenarios, but fails when the probe underweights them. Analysis reveals that generalization improvements depend on the relative importance assigned to data-agnostic versus hidden-state features, with inconsistent weighting explaining mixed results.

## Method Summary
The method extracts hidden states from LLM middle layers (layer 15 for single-layer, layers 13-17 for multi-layer) and combines them with data-agnostic features (token probabilities and entropy metrics). A Random Forest probe is trained on these combined features to predict response correctness. Feature selection (top 300 hidden-state dimensions by Pearson correlation) is applied to reduce task-specific noise. The approach is evaluated through cross-dataset transfers across three task types: Factual QA, Reading Comprehension, and Commonsense Reasoning, using Llama2-7B and Mistral-7B models.

## Key Results
- Incorporating data-agnostic features improves generalization accuracy in 7/9, 8/9, and 9/9 transfer pairs across different configurations
- Feature selection amplifies data-agnostic feature contributions, with SHAP values showing higher importance rankings for data-agnostic features in the selected-feature setting
- Generalization gains are inconsistent for Commonsense Reasoning tasks (SWAG, Winogrande) due to asymmetric feature weighting
- Short-form QA tasks show the most consistent improvements when adding data-agnostic features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Supplementing hidden-state features with data-agnostic features improves cross-task generalization of uncertainty probes in most scenarios.
- Mechanism: Data-agnostic features are task-independent by construction—they capture output confidence signals (e.g., probability distribution over tokens, entropy) that remain meaningful regardless of domain. When combined with hidden states, they provide a generalization "anchor" that reduces overfitting to task-specific hidden-state patterns.
- Core assumption: Hidden states encode entangled task-specific and truthfulness information; data-agnostic features carry cross-task signal that complements this.
- Evidence anchors:
  - [abstract] "experiments show that incorporating data-agnostic features generally enhances generalization, especially in short-form QA tasks"
  - [section 3.9] Tables 5-8 show improved accuracy in 7/9, 8/9, 9/9 transfer pairs across configurations
  - [corpus] No direct corpus support for this specific hybrid feature mechanism; related work on Bayesian uncertainty exists but doesn't address this combination.
- Break condition: When the probe underweights data-agnostic features relative to hidden-state features (observed in Commonsense Reasoning datasets like SWAG and Winogrande), generalization gains diminish or reverse.

### Mechanism 2
- Claim: Feature selection—retaining only top-k hidden-state dimensions ranked by correlation with labels—amplifies the contribution of data-agnostic features.
- Mechanism: Pruning low-correlation hidden-state dimensions reduces task-specific noise, increasing the relative importance of data-agnostic features in the combined feature set. SHAP analysis confirms data-agnostic features achieve higher mean SHAP values in the selected-feature configuration vs. full hidden-state configurations.
- Core assumption: Task-specific information is concentrated in lower-ranked hidden-state dimensions; top-ranked dimensions preserve truthfulness signal.
- Evidence anchors:
  - [section 3.9] SHAP tables (e.g., Mistral-MMLU) show data-agnostic features range (0.018-0.052) in 305-feature setting vs. (0.001-0.002) in 20485-feature setting
  - [section 2.2] "theoretically, the selected configuration is expected to yield the largest improvement"
  - [corpus] Pruning for compact Bayesian networks exists (arXiv:2501.06962) but doesn't address this feature-selection-for-generalization mechanism.
- Break condition: When data-agnostic features don't rank at the top (e.g., Llama-SWAG where hidden-state features dominate SHAP rankings), the expected amplification pattern fails—observed in 3/9 transfer pairs for one model-dataset combination.

### Mechanism 3
- Claim: Generalization success depends on the relative feature importance assigned during probe training; asymmetric transfer patterns emerge when weighting is inconsistent.
- Mechanism: Random Forest probes assign importance based on training data. If the source dataset's hidden states already encode similar information to data-agnostic features (potential overlap in Commonsense Reasoning), the probe underweights data-agnostic features. This causes transfer to fail when target datasets rely more heavily on those features.
- Core assumption: Different task types have different hidden-state/feature relationships; Factual QA and Reading Comprehension share similarities that Commonsense Reasoning doesn't.
- Evidence anchors:
  - [section 4.2] PCA analysis shows Factual QA and Reading Comprehension clusters are closer together; transfer performance is higher between these task types
  - [section 3.9] "in some specific cases, the trained probe underweights the data-agnostic features relative to the hidden-state features"
  - [corpus] No corpus evidence directly addresses asymmetric transfer in probe generalization.
- Break condition: When source and target tasks require dissimilar reasoning skills, even properly weighted probes may fail to transfer effectively.

## Foundational Learning

- Concept: **Hidden states in Transformer LLMs**
  - Why needed here: The entire approach relies on extracting layer-wise vector representations from middle layers (layer 15 for single-layer, layers 13-17 for multi-layer) and understanding they encode truthfulness-relevant information entangled with task-specific content.
  - Quick check question: Can you explain why middle layers (not early or late layers) are typically selected for uncertainty probes, and what the "last token" extraction strategy means?

- Concept: **Data-agnostic features (entropy and probability-based metrics)**
  - Why needed here: These form the generalization component. You need to understand how entropy, token probabilities, and their aggregations (Avg(-log p), Max(-log p), Avg(H), Max(H)) capture model confidence independent of task structure.
  - Quick check question: For a 4-token short-form answer with probabilities [0.9, 0.3, 0.8, 0.1], calculate Avg(-log p) and explain what a high vs. low value indicates about model confidence.

- Concept: **Supervised probe training with feature selection**
  - Why needed here: The methodology uses Random Forest regressors trained on (features, correctness labels) pairs, with Pearson correlation-based feature selection to identify top-k informative hidden-state dimensions.
  - Quick check question: Why might a probe trained on dataset A's hidden states fail when tested on dataset B, even if both are QA tasks? What does the feature selection step aim to address?

## Architecture Onboarding

- Component map:
  - **LLM backbone**: Llama2-7B or Mistral-7B (32 layers, 4096 hidden units/layer)
  - **Hidden-state extractor**: Extracts post-transformer-block states from specified layers (single: layer 15; multi: layers 13-17), last token only
  - **Data-agnostic feature computer**: Computes probability/entropy metrics from output logits (5 features for multiple-choice: 4 sorted probabilities + entropy; 4 features for short-form: Avg/Max of -log p and entropy)
  - **Feature selector**: Pearson correlation ranking, retains top 300 hidden-state dimensions (optional)
  - **Probe (uncertainty estimator)**: Random Forest Regressor
  - **Evaluator**: Accuracy (threshold 0.5), ROC AUC, ECE

- Critical path:
  1. Generate LLM responses for dataset questions → obtain (prompt, answer) pairs
  2. Feed (prompt, answer) back through LLM → extract hidden states from specified layer(s), last token
  3. Extract output logits → compute data-agnostic features
  4. Optional: Apply feature selection to hidden states
  5. Concatenate hidden-state features + data-agnostic features
  6. Train probe on source dataset with correctness labels
  7. Evaluate on target dataset(s)

- Design tradeoffs:
  - **1-layer vs. 5-layer hidden states**: 5-layer provides more information but dilutes data-agnostic feature contribution (lower SHAP values); 1-layer generalizes better with data-agnostic features
  - **Feature selection threshold (k=300)**: Reduces task-specific noise but risks discarding useful signal; paper doesn't optimize k
  - **Random Forest vs. neural probe**: RF chosen for interpretability (SHAP analysis) and simplicity; neural probes might capture different patterns but complicate feature-importance analysis
  - **Threshold for accuracy (0.5)**: Fixed for consistency but may not be optimal for all datasets

- Failure signatures:
  - **SWAG-related transfers (Llama2)**: Data-agnostic features don't rank at top in SHAP; generalization gains minimal or negative
  - **Commonsense Reasoning transfers**: Asymmetric patterns (A→B works, B→A fails); probe underweights data-agnostic features
  - **High misclassification rate**: Adding data-agnostic features flips many correct predictions to incorrect; gains only occur when new correct predictions exceed misclassifications (see ablation Table 21)
  - **Baseline drift**: Different hidden-state configurations produce slightly different baselines (e.g., 0.6095 vs. 0.6105 vs. 0.6100), complicating comparison

- First 3 experiments:
  1. **Reproduce single-dataset baseline**: Train probe on MMLU hidden states only (4096 features), test on MMLU test split. Verify accuracy matches paper (~0.658 for Llama2, ~0.697 for Mistral).
  2. **Single cross-task transfer with data-agnostic features**: Train on MMLU with hidden states + data-agnostic features (4101 features), test on RACE. Compare accuracy to hidden-states-only baseline (expected improvement: 0.6095 → 0.6355 for Llama2).
  3. **Feature selection amplification test**: For same MMLU→RACE transfer, use top-300 selected hidden-state features + data-agnostic features (305 total). Compute SHAP values to verify data-agnostic features achieve higher importance ranking than in full 4096-feature setting.

## Open Questions the Paper Calls Out
None

## Limitations
- The approach shows inconsistent effectiveness across task types, particularly failing for Commonsense Reasoning tasks (SWAG, Winogrande) due to asymmetric feature weighting
- The paper doesn't provide error analysis showing when adding data-agnostic features actually improves predictions versus when it introduces noise
- Random Forest hyperparameters and dataset split ratios are unspecified, preventing exact reproduction

## Confidence
- **High confidence**: The core empirical finding that data-agnostic features generally improve generalization in most transfer scenarios (7/9, 8/9, 9/9 improvements across configurations) is well-supported by Tables 5-8 and SHAP analysis.
- **Medium confidence**: The claim that feature selection amplifies data-agnostic feature contributions is supported by SHAP values but breaks down in specific cases (3/9 transfer pairs), indicating the mechanism isn't universally reliable.
- **Low confidence**: The claim that the approach works "especially in short-form QA tasks" is weakly supported—while improvements are consistent, the magnitude isn't dramatically different from other task types, and the paper doesn't provide comparative effect sizes.

## Next Checks
1. **Diagnostic SHAP analysis**: For each transfer pair showing poor generalization, compute SHAP values to determine whether data-agnostic features rank below hidden-state features. This would confirm if the break condition (underweighting of data-agnostic features) explains the failures.

2. **Ablation study on feature selection threshold**: Systematically vary the number of selected hidden-state features (k=100, 200, 300, 400, 500) and measure how this affects data-agnostic feature importance and generalization performance. This would test whether the 300-feature threshold is optimal or arbitrary.

3. **Error case analysis**: For transfers where adding data-agnostic features degrades performance, perform detailed error analysis to determine whether failures stem from: (a) data-agnostic features introducing noise, (b) the probe overweighting hidden-state features due to task overlap, or (c) fundamental incompatibility between source and target task reasoning patterns.