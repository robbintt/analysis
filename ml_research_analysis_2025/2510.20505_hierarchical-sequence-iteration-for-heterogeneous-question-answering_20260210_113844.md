---
ver: rpa2
title: Hierarchical Sequence Iteration for Heterogeneous Question Answering
arxiv_id: '2510.20505'
source_url: https://arxiv.org/abs/2510.20505
tags:
- arxiv
- hseq
- table
- head
- iteration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the brittleness of retrieval-augmented generation
  (RAG) on multi-step questions with heterogeneous evidence sources. The proposed
  Hierarchical Sequence (HSEQ) Iteration framework linearizes documents, tables, and
  knowledge graphs into a unified hierarchical sequence with lightweight structural
  tags.
---

# Hierarchical Sequence Iteration for Heterogeneous Question Answering

## Quick Facts
- arXiv ID: 2510.20505
- Source URL: https://arxiv.org/abs/2510.20505
- Reference count: 31
- Key outcome: HSEQ achieves consistent EM/F1 gains over strong baselines on HotpotQA, HybridQA/TAT-QA, and MetaQA by unifying heterogeneous evidence sources through hierarchical sequence linearization

## Executive Summary
This paper addresses the brittleness of retrieval-augmented generation (RAG) systems when handling multi-step questions that require evidence from heterogeneous sources like documents, tables, and knowledge graphs. The proposed Hierarchical Sequence (HSEQ) Iteration framework provides a unified approach by linearizing diverse evidence types into a common hierarchical sequence format with lightweight structural tags. A learned iteration policy guided by a concise plan collects just-enough evidence before answer synthesis, enabling format-agnostic unification and budget-aware iteration while reducing unnecessary hops and tokens.

## Method Summary
HSEQ converts documents, tables, and knowledge graphs into unified hierarchical sequences with structural tags. Documents are split into paragraphs with hierarchical markers, tables are linearized while preserving row-column semantics in nested sequences, and knowledge graphs are traversed (BFS/DFS) to represent multi-hop relationships as sequential paths. The framework employs an iterative evidence collection process guided by a concise plan that determines when sufficient evidence has been gathered for answer synthesis. This unified interface allows a single iteration policy to operate across all evidence modalities while maintaining budget constraints.

## Key Results
- Consistent EM/F1 gains over strong baselines on HotpotQA, HybridQA/TAT-QA, and MetaQA benchmarks
- Format-agnostic unification enabling a single iteration policy across documents, tables, and knowledge graphs
- Budget-aware iteration that reduces unnecessary hops and tokens while preserving accuracy
- Evidence canonicalization providing improved consistency and auditability for QA systems

## Why This Works (Mechanism)
The framework succeeds by addressing the fundamental challenge of heterogeneous evidence integration in multi-step QA. By linearizing diverse evidence types into a common hierarchical sequence format, HSEQ enables a single learned policy to operate across all modalities rather than requiring separate policies for documents, tables, and knowledge graphs. The iteration mechanism guided by concise plans ensures efficient evidence collection by determining when "just-enough" evidence has been gathered, preventing both under-collection and over-collection. This unified representation also facilitates evidence canonicalization, making the reasoning process more transparent and auditable.

## Foundational Learning
- **Hierarchical Sequence Linearization**: Converting structured data (tables, KGs) into nested sequential representations - needed to create a common interface for heterogeneous sources; quick check: verify structural relationships are preserved after linearization
- **Iteration Policy Learning**: Training a policy to determine when sufficient evidence has been collected - needed to optimize the evidence gathering process; quick check: test policy performance with varying question complexity
- **Concise Plan Generation**: Creating compact representations of evidence collection goals - needed to guide the iteration process efficiently; quick check: measure plan effectiveness across different evidence types
- **Budget-Conscious Evidence Collection**: Balancing completeness against computational efficiency - needed to prevent over-collection while ensuring accuracy; quick check: compare performance with fixed vs. adaptive evidence budgets
- **Multi-hop Reasoning**: Handling questions requiring multiple reasoning steps across evidence sources - needed for complex QA tasks; quick check: evaluate on questions requiring 2+ evidence hops
- **Evidence Canonicalization**: Standardizing evidence representation for consistency and auditability - needed for reliable QA system interpretation; quick check: verify canonical forms across different evidence types

## Architecture Onboarding

**Component Map**
HSEQ Framework -> Linearization Module -> Evidence Collector -> Iteration Policy -> Answer Synthesizer

**Critical Path**
Question → Concise Plan → Iterative Evidence Collection → Unified Sequence → Answer Synthesis

**Design Tradeoffs**
- Unified interface vs. potential information loss during linearization
- Single policy vs. modality-specific optimization capabilities
- Budget constraints vs. completeness requirements
- Sequential processing vs. parallel evidence gathering

**Failure Signatures**
- Incomplete evidence collection leading to incorrect answers
- Over-collection causing inefficiency without accuracy gains
- Linearization errors losing critical structural relationships
- Plan ambiguity resulting in suboptimal evidence selection

**3 First Experiments**
1. Compare HSEQ performance with and without linearization on tables and knowledge graphs
2. Test iteration policy effectiveness with varying question complexity levels
3. Evaluate evidence collection completeness across different budget constraints

## Open Questions the Paper Calls Out
None

## Limitations
- The linearization process may lose critical structural relationships in tables and knowledge graphs, with unknown impact on accuracy
- The iteration policy's effectiveness depends on the quality of concise plans, with potential failure modes for ambiguous or incomplete plans
- Evidence canonicalization benefits for consistency and auditability are mentioned but not empirically demonstrated

## Confidence

High confidence: The general approach of unifying evidence sources into a common interface and using iterative evidence collection is sound and addresses a real problem in RAG systems.

Medium confidence: The format-agnostic unification claim is valid, but specific implementation details for table and KG linearization need more rigorous validation.

Low confidence: The evidence canonicalization benefits for consistency and auditability lack empirical demonstration.

## Next Checks

1. Conduct controlled experiments comparing HSEQ performance with and without the linearization step on tables and knowledge graphs to quantify information loss during conversion.

2. Perform ablation studies isolating the contribution of the iteration policy versus the unified sequence format to determine which component drives the performance gains.

3. Test HSEQ on datasets with more complex table structures (nested tables, merged cells) and knowledge graphs (cyclic dependencies, multi-relational paths) to evaluate robustness beyond the current benchmark suite.