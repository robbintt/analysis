---
ver: rpa2
title: Inference-Time Scaling of Diffusion Models for Infrared Data Generation
arxiv_id: '2511.07362'
source_url: https://arxiv.org/abs/2511.07362
tags:
- infrared
- diffusion
- images
- scaling
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating high-quality synthetic
  infrared images for training computer vision models, a task hindered by limited
  infrared datasets and poor physical realism in generated outputs. The authors propose
  an inference-time scaling approach that leverages a domain-adapted CLIP-based verifier
  to guide the diffusion sampling process toward higher-quality infrared generations.
---

# Inference-Time Scaling of Diffusion Models for Infrared Data Generation

## Quick Facts
- arXiv ID: 2511.07362
- Source URL: https://arxiv.org/abs/2511.07362
- Authors: Kai A. Horstmann; Maxim Clouser; Kia Khezeli
- Reference count: 24
- Primary result: Inference-time scaling with domain-adapted CLIP verifier reduces FID by 10% on KAIST dataset compared to unguided baseline

## Executive Summary
This paper addresses the challenge of generating high-quality synthetic infrared images for training computer vision models, a task hindered by limited infrared datasets and poor physical realism in generated outputs. The authors propose an inference-time scaling approach that leverages a domain-adapted CLIP-based verifier to guide the diffusion sampling process toward higher-quality infrared generations. By finetuning FLUX.1-dev on a small infrared dataset and training CLIP to distinguish realistic infrared images from grayscale artifacts, they demonstrate that inference-time guidance can significantly improve generation quality. Their approach reduces FID scores by 10% on the KAIST dataset compared to unguided baselines, with random search achieving the best performance among the tested search strategies.

## Method Summary
The method combines inference-time scaling with domain adaptation for infrared image generation. FLUX.1-dev is finetuned using LoRA on 1,000 infrared image-caption pairs from the KAIST dataset. A CLIP-based verifier is trained with contrastive learning to distinguish realistic infrared images from grayscale artifacts using formatted captions ("An INFRARED photo of..." vs "A GRAYSCALE photo of..."). At inference, multiple noise latents are sampled and denoised through the diffusion model, with the verifier scoring each output using IRSCORE = (1-α)cos(Φ_T(c_IR), Φ_I(x)) - α·cos(Φ_T(c_gray), Φ_I(x)). Random search or zero-order search algorithms select the highest-scoring image from N candidates or k iterations of local refinement.

## Key Results
- Random search with NFE=336 reduces FID from 74.58 to 66.74 on KAIST test set
- Zero-order search achieves FID of 69.15 under same compute budget
- IRSCORE metric successfully distinguishes high-quality synthetic IR from low-quality and grayscale outputs
- CLIP verifier finetuned with grayscale contrastive augmentation shows improved calibration over pretrained CLIP

## Why This Works (Mechanism)

### Mechanism 1: Noise latent selection
- Claim: Different initial noise vectors yield outputs with varying physical realism
- Evidence: Random search with NFE=336 achieves FID 66.74 vs baseline 74.58
- Break condition: Verifier overfitting to biases rather than genuine quality

### Mechanism 2: Domain-adapted CLIP verifier
- Claim: Finetuned CLIP can distinguish physically plausible IR from grayscale artifacts
- Evidence: IRSCORE assigns 0.5135 to high-quality synthetic IR vs -0.3212 to low-quality
- Break condition: Grayscale negatives don't capture dominant failure modes

### Mechanism 3: Compute shifting from training to inference
- Claim: Compensates for limited training data in specialized domains
- Evidence: 1,000-image finetuning + inference scaling achieves good results
- Break condition: Base model RGB priors too strong to overcome

## Foundational Learning

- **Concept**: Diffusion models and denoising trajectories
  - Why needed: Method operates on noise latents and denoising steps
  - Quick check: Why does increasing denoising steps alone have diminishing returns?

- **Concept**: CLIP vision-language alignment
  - Why needed: Verifier built on CLIP's image-text alignment
  - Quick check: How would you compute a score rewarding IR alignment and penalizing grayscale similarity?

- **Concept**: Search algorithms (random vs. zero-order optimization)
  - Why needed: Compares search strategies and NFE tradeoffs
  - Quick check: Why might random search outperform zero-order at limited NFE budgets?

## Architecture Onboarding

- **Component map**: FLUX.1-dev -> LoRA adapter -> CLIP verifier -> IRSCORE scoring -> Random/zero-order search
- **Critical path**:
  1. Prepare IR image-caption pairs from KAIST dataset
  2. Generate grayscale versions for contrastive verifier training
  3. Finetune CLIP verifier with formatted captions
  4. Finetune FLUX.1-dev with LoRA on IR pairs
  5. At inference: sample N noise latents, denoise, score, return highest-scoring image

- **Design tradeoffs**:
  - NFE budget vs quality: Linear compute increase
  - α hyperparameter: IR vs grayscale balance (paper uses α=0.5)
  - Random vs zero-order search: Exploration vs local refinement
  - Verifier size: CLIP-B/32 chosen for efficiency

- **Failure signatures**:
  - Verifier hacking: High scores but unrealistic outputs
  - Grayscale outputs: Lack thermal characteristics
  - Mode collapse: Low diversity in outputs
  - Poor text alignment: Images don't match prompts

- **First 3 experiments**:
  1. Baseline replication: Finetune FLUX.1-dev LoRA, generate unguided samples, compute FID (~74.58)
  2. Verifier ablation: Train CLIP with/without grayscale augmentation, compare IRSCORE calibration
  3. Search comparison at NFE=336: Compare random vs zero-order search FID and qualitative realism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does inference-time scaling performance scale with substantially larger NFE budgets in infrared domain?
- Basis: Paper notes NFE=336 is limited compared to other works
- Evidence needed: Systematic evaluation across varying NFE values reporting FID and IRSCORE trajectories

### Open Question 2
- Question: Can physics-based or domain-specific verifiers outperform CLIP-based approach for infrared generation?
- Basis: Paper suggests training alternative verifiers as promising future research
- Evidence needed: Comparative study of physics-informed verifiers vs current CLIP method

### Open Question 3
- Question: Does approach generalize to other infrared datasets and sensing modalities beyond KAIST?
- Basis: Paper calls for extending evaluation to other datasets and sensing modalities
- Evidence needed: Replication on diverse infrared datasets with consistent FID improvements

### Open Question 4
- Question: Does verifier hacking occur with random search despite achieving better FID scores?
- Basis: Paper notes verifier hacking as failure mode and random search outperformed zero-order
- Evidence needed: Human evaluation or physics-based metrics independent of CLIP verifier

## Limitations
- Small finetuning dataset (1,000 images) may not capture full IR diversity
- CLIP verifier effectiveness relies heavily on grayscale-augmented contrastive approach
- NFE=336 budget used in evaluations is relatively modest
- Method assumes sufficient semantic transferability from RGB pretraining

## Confidence

- **High confidence**: General framework of inference-time scaling works as demonstrated in related work
- **Medium confidence**: Domain-adapted CLIP verifiers can distinguish realistic IR from grayscale artifacts
- **Medium confidence**: Random search advantage over zero-order search at NFE=336

## Next Checks

1. **Verifier robustness test**: Evaluate trained CLIP verifier on held-out test set of real IR vs synthetic grayscale images, measure IRSCORE discrimination and calibration

2. **Search algorithm scaling**: Run random and zero-order search at multiple NFE budgets (336, 672, 1344), plot FID improvement vs NFE to determine if random search advantage persists

3. **Negative class ablation**: Train three CLIP verifiers (grayscale negatives, RGB negatives, no negatives), compare guidance effectiveness on generation quality and diversity