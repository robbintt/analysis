---
ver: rpa2
title: Smoothed Embeddings for Robust Language Models
arxiv_id: '2501.16497'
source_url: https://arxiv.org/abs/2501.16497
tags:
- embedding
- attack
- defense
- utility
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of large language models
  (LLMs) to jailbreaking attacks, where adversarial inputs can bypass alignment methods
  and induce harmful outputs. The authors propose Randomized Embedding Smoothing and
  Token Aggregation (RESTA), a defense that adds noise to embedding vectors and performs
  aggregation during token generation to preserve semantic information.
---

# Smoothed Embeddings for Robust Language Models

## Quick Facts
- arXiv ID: 2501.16497
- Source URL: https://arxiv.org/abs/2501.16497
- Reference count: 39
- Primary result: Embedding noise + token aggregation defense achieves better jailbreak robustness vs utility tradeoff than baseline methods

## Executive Summary
This paper proposes Randomized Embedding Smoothing and Token Aggregation (RESTA), a defense against jailbreaking attacks on large language models. RESTA works by adding random noise to embedding vectors during autoregressive generation and aggregating over multiple perturbed samples to select the next token. The approach disrupts adversarial suffixes while preserving semantic content of benign prompts. Experiments show RESTA significantly reduces attack success rates across multiple attack types while maintaining model performance on standard benchmarks.

## Method Summary
RESTA is an inference-time defense that injects noise into token embeddings and aggregates predictions across multiple perturbed samples. For each token position, the defense generates k perturbed embedding sequences using one of four noise types (isotropic Gaussian, hard directional, soft directional, orthogonal), then selects the next token via majority voting. The defense applies only to the first l tokens of the output (response prefix smoothing) to balance robustness and computational cost. Noise is applied only to user content embeddings, preserving system prompt semantics.

## Key Results
- RESTA with hard directional noise (σ=0.8) reduces ASR from 86.0% to 20.0% on Vicuna-13B against GCG attacks
- At equivalent robustness levels, RESTA maintains higher utility than baseline defenses on AlpacaEval benchmarks
- The defense provides consistent robustness improvements across multiple attack types (GCG, PAIR, RS) and model sizes (Vicuna-13B, Llama-2-7B-chat)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Embedding-level noise injection disrupts adversarial perturbations while preserving benign semantic content
- Mechanism: Adversarial suffixes (e.g., GCG) are optimized for precise token embedding values. Adding random noise to embedding vectors disrupts this optimization, causing the adversarial pattern to fail while the semantic content of benign prompts remains recoverable through aggregation
- Core assumption: Adversarial perturbations are more fragile to random noise than the underlying semantic content of prompts
- Evidence anchors: [abstract] "...adds random noise to the embedding vectors...with the aim of better preserving semantic information"; [section 3.1] "By operating in the embedding domain, our approach aims to retain the semantic information of the original prompt, while disrupting the presence of adversarial input perturbations"
- Break condition: If adversarial perturbations become robust to random noise (e.g., through noise-aware training), this mechanism would degrade

### Mechanism 2
- Claim: Directional noise better preserves semantic information at higher noise levels than isotropic noise
- Mechanism: Embedding direction encodes semantic content. Hard directional noise (scaling along the direction vector) and soft directional noise (element-wise scaled by direction) preserve this direction better than isotropic Gaussian noise, allowing higher σ values without destroying semantics
- Core assumption: The direction of embedding vectors encodes critical semantic information that should be preserved
- Evidence anchors: [abstract] "...effectiveness depends on the type and level of embedding noise, with directional noise preserving semantics better at higher noise levels"; [section 3.1] "A potential drawback of this approach is that isotropic noise at larger values of σ may disrupt the direction of the embedding vector, which may encode vital semantic information"
- Break condition: If embedding semantics are encoded primarily in magnitude rather than direction, or if models use different embedding geometries

### Mechanism 3
- Claim: Response prefix smoothing exploits autoregressive continuation behavior
- Mechanism: LLMs tend to continue generation in the style/theme established in the first few tokens. If the defense prevents the model from starting with harmful content (e.g., "Sure, here is..."), subsequent tokens naturally continue with refusal behavior. Only applying defense to first l tokens reduces compute cost while maintaining effectiveness
- Core assumption: Autoregressive generation is path-dependent; early tokens strongly influence subsequent content direction
- Evidence anchors: [section 3.3] "...autoregressive generation generally continues along the same theme established by preceding tokens"; [section 3.3] "...if the LLM begins the response with phrasing that indicates acceptance...then it typically continues with generation of harmful content"
- Break condition: If attacks can inject delayed harmful content that activates after the prefix smoothing window (l tokens), this optimization becomes a vulnerability

## Foundational Learning

- Concept: **Randomized Smoothing (for Classification)**
  - Why needed here: RESTA is inspired by randomized smoothing, which provides certified robustness for classifiers by aggregating predictions over noisy samples. Understanding the original formulation helps clarify why RESTA adapts it for autoregressive generation
  - Quick check question: In standard randomized smoothing for image classification, how does adding Gaussian noise and taking majority vote provide robustness guarantees?

- Concept: **Embedding Space Geometry**
  - Why needed here: The paper assumes embedding direction encodes semantics. Understanding cosine similarity, embedding norms, and how transformers use embeddings is essential for interpreting why directional vs isotropic noise matters
  - Quick check question: Why might the direction of an embedding vector encode more semantic information than its magnitude?

- Concept: **Autoregressive Token Generation**
  - Why needed here: RESTA operates during autoregressive generation, injecting noise into the input embeddings while generating output tokens. Understanding how transformers generate tokens sequentially (logits → sampling → append → repeat) is prerequisite
  - Quick check question: In greedy decoding, how is the next token selected from the logits output by the model?

## Architecture Onboarding

- Component map:
  - Tokenize input → embed tokens → isolate user content portion → Perturbation function H_σ → k parallel embedding sequences → Token aggregator (majority voting) → Response prefix controller → Model body f

- Critical path:
  1. Tokenize input → embed tokens → isolate user content portion
  2. Generate k perturbed embedding sequences using H_σ
  3. For each token position < l: run f(ẽ_i) for all k samples, majority vote
  4. For positions ≥ l: continue with single unperturbed embedding sequence
  5. Stop at EOS or max length m

- Design tradeoffs:
  - Higher σ → better robustness, worse utility
  - Higher k → more reliable voting, k× compute cost during smoothed prefix
  - Higher l → more thorough defense, higher compute overhead
  - Directional vs isotropic noise: directional preserves semantics at higher σ but requires tuning

- Failure signatures:
  - **High utility loss at low σ**: Likely applying noise to wrong portion (system prompt vs user content) or using wrong noise type
  - **No robustness improvement**: Check that noise is actually being added; verify σ is non-trivial; check that majority vote is working
  - **Excessive compute**: l is too large or k is too high for deployment constraints

- First 3 experiments:
  1. **Noise type ablation**: Fix σ=0.5, k=10, l=20; compare ASR and AlpacaEval across all four noise types on Vicuna-13B against GCG attacks to replicate Figure 2 tradeoffs
  2. **Prefix length sensitivity**: Fix hard directional noise with σ=0.8; vary l ∈ {0, 5, 10, 20, 50, 100} to measure compute-robustness-utility tradeoff curve
  3. **Sample count scaling**: Fix σ=0.8, l=20; vary k ∈ {1, 3, 5, 10, 20} to identify minimum k needed for stable majority voting without excessive compute

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Evaluation completeness: Only tested against fixed attack artifacts, not adaptive attacks that could optimize for RESTA's specific noise injection mechanism
- Embedding geometry assumptions: Relies on specific embedding space properties that may vary across model architectures without verification
- Token aggregation robustness: Does not analyze edge cases where k samples produce ties or near-ties in majority voting

## Confidence

**High confidence**: The core claim that embedding noise disrupts adversarial suffixes is well-supported. The mechanism that adversarial patterns optimized for specific embedding values fail when random noise is added is theoretically sound and empirically demonstrated across multiple attack types and model sizes.

**Medium confidence**: The superiority of directional noise over isotropic noise at higher σ values has theoretical justification but lacks direct empirical validation. The paper provides ablation evidence but doesn't conclusively prove that directional noise preserves semantics better across all semantic classes.

**Low confidence**: The specific optimization of l=20 prefix smoothing length is based on computational constraints rather than rigorous analysis of the defense-performance tradeoff curve. The paper doesn't demonstrate that this particular value is optimal or even near-optimal.

## Next Checks

1. **Adaptive attack evaluation**: Implement an attack that attempts to optimize for RESTA's noise injection mechanism (e.g., by including noise in the adversarial objective or targeting the majority voting aggregation). Measure whether ASR increases significantly, which would indicate the defense's vulnerability to adaptive adversaries.

2. **Semantic preservation analysis**: Conduct a systematic study comparing semantic preservation across different noise types using intrinsic embedding evaluation metrics (e.g., cosine similarity preservation, probing tasks). This would validate whether directional noise truly maintains semantic content better than isotropic noise across diverse semantic classes.

3. **Prefix length optimization study**: Systematically vary l from 1 to 100 tokens while measuring the ASR-utility-compute tradeoff curve. Identify whether l=20 is truly optimal or if different values provide better robustness-per-compute ratios, particularly for different attack types or model sizes.