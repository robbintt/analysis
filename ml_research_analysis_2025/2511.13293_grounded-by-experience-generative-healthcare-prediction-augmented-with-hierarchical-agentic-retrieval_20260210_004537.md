---
ver: rpa2
title: 'Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical
  Agentic Retrieval'
arxiv_id: '2511.13293'
source_url: https://arxiv.org/abs/2511.13293
tags:
- retrieval
- knowledge
- history
- patient
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses healthcare prediction challenges where large
  language models suffer from factual inaccuracies due to unreliable embedded knowledge.
  The proposed GHAR framework introduces a hierarchical agentic RAG architecture that
  dynamically determines when to retrieve external knowledge and optimizes the collaboration
  between retrieval and generation modules.
---

# Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval

## Quick Facts
- arXiv ID: 2511.13293
- Source URL: https://arxiv.org/abs/2511.13293
- Reference count: 40
- Primary result: Dual-agent hierarchical RAG framework achieves state-of-the-art healthcare prediction performance across three benchmark datasets

## Executive Summary
This paper addresses healthcare prediction challenges where large language models suffer from factual inaccuracies due to unreliable embedded knowledge. The proposed GHAR framework introduces a hierarchical agentic RAG architecture that dynamically determines when to retrieve external knowledge and optimizes the collaboration between retrieval and generation modules. The method employs dual agents—Agent-Top for coarse-grained knowledge navigation and Agent-Low for fine-grained retrieval—unified within a Markov Decision Process framework using multi-agent reinforcement learning. Experiments on three benchmark datasets across three healthcare tasks demonstrate significant improvements over state-of-the-art baselines, achieving B-Accuracy scores of 0.8421 for 24h-Decompensation prediction, 0.6272 for Readmission Prediction, and F1-score of 0.4124 for Length-of-Stay Prediction on the MIMIC-III dataset.

## Method Summary
GHAR employs a hierarchical dual-agent architecture where Agent-Top acts as a high-level policy, deciding whether to rely on the LLM's internal knowledge or trigger retrieval, while Agent-Low performs fine-grained knowledge graph retrieval and summarization. The framework formalizes this collaboration as a Markov Decision Process and trains both agents via multi-agent reinforcement learning with shared rewards. The method uses meta-path-based partition-aware retrieval to constrain the knowledge graph search space to clinically relevant relational patterns, reducing noise compared to whole-graph retrieval. Training occurs in two phases: SFT warm-up using rejection sampling from Qwen2.5-7B to generate reasoning pathways, followed by multi-agent PPO reinforcement learning for policy optimization.

## Key Results
- Achieves B-Accuracy of 0.8421 for 24h-Decompensation prediction on MIMIC-III dataset
- Achieves B-Accuracy of 0.6272 for Readmission Prediction on MIMIC-III dataset
- Achieves F1-score of 0.4124 for Length-of-Stay Prediction on MIMIC-III dataset
- Significantly outperforms state-of-the-art baselines including KARE and various discriminative methods
- Demonstrates consistent improvements across all three healthcare prediction tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A hierarchical dual-agent architecture enables adaptive decisions about when to retrieve external knowledge, reducing unnecessary retrieval and focusing reasoning on cases where the LLM's parametric knowledge is insufficient.
- Mechanism: Agent-Top acts as a high-level policy, deciding whether to rely on the LLM's internal knowledge or to trigger retrieval. If retrieval is triggered, Agent-Top selects relevant meta-paths to narrow the search space, then delegates to Agent-Low for fine-grained retrieval and summarization.
- Core assumption: The optimal point to activate retrieval varies by clinical query complexity; static "always retrieve" or "never retrieve" policies are suboptimal.
- Evidence anchors:
  - [abstract] "Agent-Top acts as the primary physician, iteratively deciding whether to rely on parametric knowledge or to initiate retrieval, while Agent-Low acts as the consulting service, summarising all task-relevant knowledge once retrieval was triggered."
  - [section III.D] "Agent-Top serves as the primary physician... initiating additional consultations, while Agent-Low functions as the consulting service..."
  - [corpus] Related work on hierarchical RAG (e.g., TagRAG, RAPTOR-AI) shows performance gains from coarse-to-fine retrieval, but none formalize the when-to-retrieve decision via MDP; this is a novel contribution.
- Break condition: If the reward signal fails to differentiate between necessary and unnecessary retrievals (e.g., due to sparse or noisy task-level feedback), Agent-Top may learn to over- or under-retrieve.

### Mechanism 2
- Claim: Formulating the collaboration between Agent-Top and Agent-Low as a Markov Decision Process (MDP) and training via multi-agent reinforcement learning aligns their policies toward a shared prediction goal while preserving role specialization.
- Mechanism: The MDP state includes the current sub-query and accumulated reasoning history. Agent-Top's action selects between LLM vs. RAG and when to terminate; Agent-Low's action summarizes retrieved subgraphs. A shared reward structure (cost, accuracy, path relevance) encourages efficient, accurate predictions.
- Core assumption: The dual-agent interaction can be effectively modeled as a sequential decision process where joint optimization outperforms independent training of retriever and generator.
- Evidence anchors:
  - [abstract] "we innovatively unify the optimization of both agents within a formal Markov Decision Process, designing diverse rewards to align their shared goal of accurate prediction while preserving their distinct roles."
  - [section III.B] "We first overview the MDP for the construction of the Agent-Top and Agent-Low. This MDP framework captures the interactions and decision-making processes of both agents."
  - [corpus] Multi-agent RL for RAG (e.g., DeepRAG, Search-R1) uses RL to coordinate retrieval and reasoning, but typically in single-agent or loosely coupled settings; GHAR's explicit dual-agent MDP with shared rewards is a distinct formalization.
- Break condition: If reward design is poorly calibrated (e.g., cost rewards dominate accuracy rewards), agents may learn to minimize retrieval at the expense of prediction quality.

### Mechanism 3
- Claim: Meta-path–based partition-aware retrieval restricts the knowledge graph search space to clinically relevant relational patterns, improving retrieval precision and reducing noise compared to whole-graph retrieval.
- Mechanism: Agent-Top selects meta-paths (e.g., disease→treated by→drug) that define semantic partitions in the KG. Retrieval is then constrained to nodes/edges matching these paths, yielding focused subgraphs that Agent-Low summarizes.
- Core assumption: Clinical queries can be effectively decomposed along a small set of high-level relational patterns, and meta-paths capture these patterns better than unconstrained graph search.
- Evidence anchors:
  - [abstract] "the framework dynamically determines when to retrieve external knowledge using meta-path-based partition-aware retrieval."
  - [section III.D] "We do not perform direct retrieval from the entire external KGs. Instead, we focus on generating meta-path IDs... for GraphRAG into Agent-Low, facilitating a fine-grained RAG process."
  - [corpus] Prior work like GraphCare and EMERGE use KGs for healthcare prediction, but often retrieve entire patient subgraphs; GHAR's meta-path constraint is a precision-oriented refinement.
- Break condition: If the meta-path vocabulary is too narrow or fails to cover query-relevant relations, retrieval will miss critical evidence, leading to degraded prediction.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: GHAR is a RAG variant; understanding how retrieval augments LLM generation, and the limitations of naïve or single-round RAG, is essential to appreciate the need for hierarchical, agentic design.
  - Quick check question: Explain why single-round RAG can introduce noise and fail to support complex clinical reasoning.

- **Concept: Markov Decision Processes (MDP) and Reinforcement Learning (RL)**
  - Why needed here: The dual-agent collaboration is formalized as an MDP and trained via multi-agent RL; grasping states, actions, transitions, and reward design is necessary to understand how GHAR learns adaptive retrieval policies.
  - Quick check question: Define state, action, and reward in the context of Agent-Top's decision to retrieve or not.

- **Concept: Healthcare Prediction Tasks & EHR Structure**
  - Why needed here: GHAR is evaluated on specific tasks (decompensation, readmission, length-of-stay) using structured EHR data (diagnoses, procedures, medications). Familiarity with these tasks and data formats helps interpret results and failure cases.
  - Quick check question: Describe how a patient's visit history is represented and used in the decompensation prediction task.

## Architecture Onboarding

- **Component map:** Patient EHR history -> Initial query -> Reasoning Queue -> Agent-Top (decides LLM vs. RAG, selects meta-paths) -> Agent-Low (retrieves subgraphs, summarizes evidence) -> Final prediction
- **Critical path:**
  1. Patient EHR history is formatted into an initial query.
  2. Query is rewritten into multiple sub-queries and queued.
  3. Agent-Top processes each sub-query: decides LLM vs. RAG; if RAG, selects meta-paths.
  4. If retrieval is triggered, Agent-Low retrieves subgraphs from KG partitions and summarizes evidence.
  5. Agent-Top decides whether to terminate or generate a deeper sub-query; if terminate, final prediction is output.
  6. During training, rewards are computed and used to update both agents via multi-agent PPO.

- **Design tradeoffs:**
  - Meta-path breadth vs. retrieval noise: Fewer meta-paths reduce search space but may miss relevant evidence; more meta-paths increase coverage but risk noise.
  - Shared vs. independent LLM parameters: Sharing parameters (as done with Qwen2.5-3B) reduces memory but may limit role specialization.
  - Iteration depth vs. efficiency: More iterations enable deeper reasoning but increase latency and risk over-thinking.

- **Failure signatures:**
  - Over-retrieval: Agent-Top learns to retrieve even for simple queries, increasing latency and introducing irrelevant evidence (observed when cost reward is under-weighted).
  - Loss-in-the-middle: Retrieved evidence is not well-summarized by Agent-Low, causing key signals to be obscured by noise.
  - Meta-path mismatch: Agent-Top selects irrelevant meta-paths, leading to retrieval of off-topic subgraphs and incorrect predictions.
  - Reward hacking: Agents optimize for easy rewards (e.g., short reasoning chains) at the expense of task accuracy.

- **First 3 experiments:**
  1. **Ablation of meta-path partitioning:** Compare GHAR vs. a variant that retrieves from the entire KG without meta-path constraints (GHAR-NM) on B-Accuracy and F1. Expect degraded performance, especially in precision-sensitive tasks.
  2. **Varying retrieval adaptivity:** Replace Agent-Top's adaptive retrieval decision with fixed policies (always retrieve, never retrieve, fixed-number iterations) and measure impact on accuracy vs. inference time.
  3. **Cross-dataset generalization:** Train on MIMIC-III, test on MIMIC-IV (and vice versa) to evaluate OOD robustness, comparing GHAR against KARE and discriminative baselines. Expect GHAR to better maintain performance due to adaptive retrieval and semantic grounding.

## Open Questions the Paper Calls Out

- **Open Question 1**
  - Question: How can intuitive process rewards be designed to further enhance model performance beyond the current outcome-supervised and ranking-based rewards?
  - Basis in paper: [explicit] The conclusion states, "A key area for future work lies in designing more intuitive process rewards that could further enhance model performance."
  - Why unresolved: The current framework relies on outcome-supervised rewards (ORM) and rank-based rewards which evaluate the final result or path quality, but may not provide sufficiently granular feedback on the logical validity of intermediate reasoning steps within the Markov Decision Process.
  - What evidence would resolve it: The integration and successful training of GHAR using a novel process-supervised reward function (evaluating step-by-step clinical reasoning logic) that results in statistically significant performance gains over the existing ORM configuration.

- **Open Question 2**
  - Question: What specific adaptation strategies are required to effectively leverage medical-domain-specific LLMs (e.g., BioMistral) as backbones, given their observed performance parity or inferiority to general-purpose models in this framework?
  - Basis in paper: [inferred] In Section V-B, the authors note that medical LLMs performed comparably or worse than general-purpose Qwen models, suggesting their pre-training objectives (e.g., textbook QA) or knowledge overlap with the external KG may not align well with EHR prediction tasks.
  - Why unresolved: It remains unclear if the bottleneck is the redundancy between the LLM's parametric knowledge and the external retrieval, or a mismatch in the fine-tuning approach (RL) for domain-specific models.
  - What evidence would resolve it: A comparative study showing that a specialized adaptation method (e.g., specific instruction tuning for domain models within GHAR) allows medical LLMs to significantly outperform general-purpose baselines of similar size.

- **Open Question 3**
  - Question: Can the hierarchical agents learn optimal decision boundaries for retrieval and termination implicitly through policy learning, removing the dependency on explicit rule-based prompt engineering?
  - Basis in paper: [inferred] The method relies on multi-agent RL for optimization, yet the agent actions (e.g., deciding "when to retrieve") are guided by prompt templates containing explicit rules (e.g., "If the subquery requires specific medical knowledge... respond 'yes'").
  - Why unresolved: It is undetermined if the RL optimization is truly learning the "clinical necessity" or merely fine-tuning the adherence to the hard-coded prompt logic, potentially limiting the discovery of novel reasoning strategies.
  - What evidence would resolve it: A modification of the GHAR framework where agents operate with minimal prompt constraints, successfully learning retrieval timing and termination strategies solely from the environmental rewards.

## Limitations

- Experimental evaluation focuses primarily on in-domain performance without extensive OOD or temporal robustness testing
- Reported improvements may be influenced by the choice of knowledge graph (PrimeKG) which is not publicly available
- Computational overhead of the hierarchical retrieval process is not fully characterized relative to simpler baselines

## Confidence

- **High Confidence:** The hierarchical dual-agent architecture concept and its formalization as an MDP are well-supported by the methodology description and experimental results showing consistent improvements across all three tasks.
- **Medium Confidence:** The effectiveness of meta-path-based partition-aware retrieval is demonstrated but could be influenced by the specific PrimeKG structure; results might vary with different knowledge graph construction methods.
- **Low Confidence:** The long-term clinical utility and real-world deployment viability are not addressed, as the study focuses on benchmark performance rather than practical implementation considerations like latency, cost, or integration with existing clinical workflows.

## Next Checks

1. **OOD Generalization Test:** Train GHAR on MIMIC-III and evaluate on MIMIC-IV (and vice versa) to quantify performance degradation and compare against non-RAG baselines under distribution shift.
2. **Knowledge Graph Ablation:** Replace PrimeKG with a different biomedical knowledge graph (e.g., BioKG or domain-specific subsets of UMLS) and measure impact on prediction accuracy and retrieval precision.
3. **Computational Overhead Analysis:** Profile inference latency and memory usage of GHAR versus single-round RAG and discriminative baselines, reporting relative increases and their impact on practical deployment scenarios.