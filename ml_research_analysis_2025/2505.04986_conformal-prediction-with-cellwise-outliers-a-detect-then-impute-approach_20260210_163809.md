---
ver: rpa2
title: 'Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach'
arxiv_id: '2505.04986'
source_url: https://arxiv.org/abs/2505.04986
tags:
- coverage
- data
- outliers
- detection
- cellwise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of constructing prediction intervals
  in the presence of cellwise outliers in test data. The authors propose a detect-then-impute
  conformal prediction framework that first detects contaminated entries in the test
  feature and then imputes them using a detection and imputation procedure.
---

# Conformal Prediction with Cellwise Outliers: A Detect-then-Impute Approach

## Quick Facts
- arXiv ID: 2505.04986
- Source URL: https://arxiv.org/abs/2505.04986
- Reference count: 40
- This paper addresses the problem of constructing prediction intervals in the presence of cellwise outliers in test data.

## Executive Summary
This paper tackles the challenge of constructing valid prediction intervals when test features contain cellwise outliers - individual contaminated entries that violate the exchangeability assumption required for standard conformal prediction. The authors propose a detect-then-impute framework that first detects contaminated entries in the test feature and then imputes them using a detection and imputation procedure. To maintain exchangeability between the processed test data and calibration data, they adaptively apply the same detection and imputation procedures to the calibration set, creating a unified framework that can work with various detection and imputation methods.

## Method Summary
The method introduces two algorithms: PDI-CP (Proxy Detection-Imputation Conformal Prediction) and JDI-CP (Joint Detection-Imputation Conformal Prediction). PDI-CP achieves finite-sample coverage guarantees with error bounds that depend on the imputation error and false discovery rate, while JDI-CP guarantees 1-2α finite-sample coverage using a Jackknife+-type construction. Both methods operate by detecting outliers in test features, imputing them, and then applying synchronized detection-imputation to calibration features to restore exchangeability. The framework works with various detection procedures (including DDC, one-class SVM, and cellMCD) and imputation methods (including mean imputation, kNN, and MICE).

## Key Results
- The proposed detect-then-impute conformal prediction framework achieves robust coverage properties on synthetic and real datasets with cellwise outliers
- PDI-CP provides 1-α coverage with error bounds dependent on detection quality and imputation accuracy, while JDI-CP provides distribution-free 1-2α coverage using Jackknife+ construction
- Experiments demonstrate that the methods maintain coverage guarantees while achieving comparable efficiency to oracle baselines that know true outlier locations

## Why This Works (Mechanism)

### Mechanism 1: Exchangeability Restoration Through Synchronized Detection-Imputation
Cellwise outliers in the test feature break exchangeability with calibration data. The key insight is that detection outputs $\hat{O}_i = D(X_i)$ on clean calibration features are exchangeable with $\hat{O}_{n+1} = D(X_{n+1})$ on the clean test feature. By constructing processed features $\check{X}_i = I(X_i, \hat{O}_i \cup \tilde{O}_{n+1})$ and $\check{X}^{DI}_{n+1} = I(X_{n+1}, \hat{O}_{n+1} \cup O^*)$, exchangeability is preserved under the union operation. This mechanism is critical because standard conformal prediction requires calibration and test data to be exchangeable (i.i.d. from same distribution).

### Mechanism 2: Proxy Detection-Imputation with Bounded Coverage Error (PDI-CP)
Since $O^*$ is unobservable, PDI-CP constructs $\check{X}_i = I(X_i, \hat{O}_i \cup \tilde{O}_{n+1})$ using the test detection as proxy. The coverage gap arises from two sources: (1) imputation error propagating through the prediction model's $\ell_1$-sensitivity $S_{\hat{\mu}}$, and (2) false discoveries $|\tilde{O}_{n+1} \setminus O^*|$ causing unnecessary imputation. Under Mean Imputation with error $E_i = \max_j |X_{ij} - \bar{x}_j|$, the residual difference bounds as $|\check{R}_i - R^*_i| \leq S_{\hat{\mu}} \cdot E_i \cdot |\tilde{O}_{n+1} \setminus O^*|$.

### Mechanism 3: Jackknife+ Joint Detection-Imputation for Finite-Sample Coverage (JDI-CP)
JDI-CP constructs pairwise exchangeable features $\check{X}^i_{n+1} = I(\tilde{X}_{n+1}, \hat{O}_i \cup \tilde{O}_{n+1})$ and $\check{X}^{n+1}_i = I(X_i, \hat{O}_i \cup \tilde{O}_{n+1})$. The Jackknife+ technique compares residuals across all pairs: if $Y_{n+1}$ falls outside the interval, then the test point must be a "strange point" winning too many comparisons. The exchangeability of pairs ensures $P\{\text{test point is strange}\} \leq 2\alpha$. This mechanism provides distribution-free $1-2\alpha$ finite-sample coverage regardless of imputation method.

## Foundational Learning

- **Concept: Exchangeability in Conformal Prediction**
  - Why needed here: Standard split conformal prediction requires calibration and test data to be exchangeable (i.i.d. from same distribution). Cellwise outliers violate this by corrupting test features differently than calibration features.
  - Quick check question: Given calibration features $X_1, ..., X_n$ and corrupted test feature $\tilde{X}_{n+1}$ with some cells replaced by arbitrary values, are the residuals $|Y_i - \hat{\mu}(X_i)|$ exchangeable with $|Y_{n+1} - \hat{\mu}(\tilde{X}_{n+1})|$?

- **Concept: Sure Detection vs. False Discovery Trade-off**
  - Why needed here: Theoretical guarantees require detecting all outliers (sure detection), but aggressive detection increases false discoveries (clean cells flagged as outliers), which widens prediction intervals unnecessarily.
  - Quick check question: If detection threshold $\tau_j$ is set very low to ensure $O^* \subseteq \tilde{O}_{n+1}$ (sure detection), what happens to $|\tilde{O}_{n+1} \setminus O^*|$ and thus the coverage gap in PDI-CP?

- **Concept: $\ell_1$-Sensitivity of Prediction Models**
  - Why needed here: Coverage error bounds depend on how much predictions change when input features are perturbed by imputation. Linear models have $S_{\hat{\mu}} = \|\beta\|_1$; models with small sensitivity are more robust to imputation errors.
  - Quick check question: For a neural network with bounded Lipschitz constant $L$ and input features normalized to $[0,1]^d$, what is an upper bound on $S_{\hat{\mu}}$ for coordinate-wise perturbations?

## Architecture Onboarding

- **Component map:** Detection Module (D) -> Imputation Module (I) -> Prediction Model ($\hat{\mu}$) -> Conformal Calibration
- **Critical path:**
  1. Fit detection, imputation, and prediction model on training set $D_t$ (one-time setup)
  2. For each test point: Run detection $D(\tilde{X}_{n+1})$ → impute $I(\tilde{X}_{n+1}, \tilde{O}_{n+1})$
  3. For each calibration point $i$: Run detection $D(X_i)$ → impute with joint mask $I(X_i, \hat{O}_i \cup \tilde{O}_{n+1})$
  4. Compute residuals $\check{R}_i$ and construct interval (PDI-CP uses SCP, JDI-CP uses Jackknife+)

- **Design tradeoffs:**
  - **PDI-CP vs JDI-CP:** PDI-CP targets $1-\alpha$ coverage but has error bounds dependent on FDR and imputation quality; JDI-CP guarantees $1-2\alpha$ finite-sample coverage unconditionally but produces wider intervals.
  - **Detection threshold:** Lower $\tau_j$ ensures sure detection (required) but increases false discoveries (coverage gap); higher $\tau_j$ reduces false discoveries but risks missing outliers (breaks guarantee).
  - **Imputation method:** Mean imputation has bounded error $E_i$ for theoretical analysis; kNN/MICE may perform better empirically but lack explicit error bounds.

- **Failure signatures:**
  - **Coverage collapse:** SCP or WCP on raw corrupted features fails to reach target coverage (Figure 3 shows coverage <80% when target is 90%)
  - **Infinite interval width:** WCP produces infinite-width intervals under high contamination (Figure 3, $\epsilon=0.2$)
  - **Naive-DI failure:** Simply applying DI without synchronized calibration processing fails when detection threshold is low (Appendix B.1, Figure 11)

- **First 3 experiments:**
  1. **Baseline sanity check:** Implement Naive-DI (apply $\tilde{O}_{n+1}$ mask to all calibration points) vs PDI-CP. Verify Naive-DI fails when $\tau_j$ is aggressive (Figure 11 pattern). This confirms the necessity of per-calibration-point detection.
  2. **Detection-imputation grid search:** Run PDI-CP and JDI-CP across detection thresholds $\tau_j \in \{\sqrt{\chi^2_{1,0.99}}, \sqrt{\chi^2_{1,0.95}}, \sqrt{\chi^2_{1,0.90}}\}$ and imputation methods {Mean, kNN, MICE}. Plot coverage vs. interval width. Verify JDI-CP maintains $\geq 1-2\alpha$ coverage while PDI-CP tightens toward $1-\alpha$ with better detection.
  3. **Contamination level stress test:** Fix detection/imputation (DDC + Mean), vary contamination probability $\epsilon \in \{0.05, 0.10, 0.15, 0.20\}$. Expected: both methods maintain coverage; interval width increases with $\epsilon$ due to more false discoveries. Compare against oracle Baseline (uses true $O^*$) to quantify efficiency loss.

## Open Questions the Paper Calls Out

- **Can JDI-CP be modified to achieve the target $1-\alpha$ coverage rather than $1-2\alpha$, while maintaining finite-sample guarantees and efficiency?**
  - The authors state in Section 4.2 that JDI-CP "cannot achieve the target level $1-\alpha$ due to the intrinsic limit of Jackknife+ type method" and acknowledge they provide only a conservative version in Appendix B.2.

- **How can detection thresholds $\{\tau_j\}_{j=1}^d$ be adaptively selected to optimally balance the sure detection property against false discovery rates, particularly under varying contamination levels $\epsilon$?**
  - The paper establishes the trade-off empirically but provides no theoretical guidance on optimal threshold selection given unknown contamination structure.

- **Can the coverage gaps in PDI-CP and JDI-CP when detection procedures violate Assumption 3.2 (isolated detection) be provably eliminated or bounded more tightly?**
  - Section 5 characterizes coverage gaps through $\tilde{T}_{n+1}$ and $\hat{T}_{n+1}$, noting that if these sets "are infinitely close" the gaps vanish, but provides no general guarantee for detection methods like DDC where detection scores depend on other coordinates.

## Limitations

- The Sure Detection assumption (Assumption 3.1) is critical but may be unrealistic in practice, particularly for subtle outliers or high-dimensional data where detection power is limited.
- Coverage error bounds depend on the $\ell_1$-sensitivity of the prediction model, which may be difficult to compute or bound for complex black-box models.
- The Isolated Detection assumption (Assumption 3.2) restricts applicability to certain detection procedures and may not hold for methods that leverage multivariate relationships.

## Confidence

- **High confidence** in exchangeability restoration mechanism and its theoretical justification (Section 3.2, Theorem 3.5)
- **Medium confidence** in coverage error bounds (Theorem 4.3) given dependence on unknown imputation error $E_i$ and FDR $|\tilde{O}_{n+1} \setminus O^*|$
- **Medium confidence** in finite-sample coverage (Theorem 4.4) though the $1-2\alpha$ guarantee may be overly conservative

## Next Checks

1. Test coverage and efficiency under varying contamination levels (0.05 to 0.20) to quantify robustness and identify breakdown points
2. Evaluate detection sensitivity by comparing PDI-CP performance with oracle baseline that knows true outlier locations $O^*$
3. Validate theoretical error bounds empirically by measuring actual FDR and imputation error on synthetic data with known ground truth