---
ver: rpa2
title: 'PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression'
arxiv_id: '2601.18608'
source_url: https://arxiv.org/abs/2601.18608
tags:
- budget
- polyshap
- shapley
- sampling
- approximation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PolySHAP extends KernelSHAP by approximating the game with higher-degree
  polynomials to capture feature interactions. It fits a polynomial to game evaluations
  on random subsets and extracts Shapley values from the fitted coefficients.
---

# PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression

## Quick Facts
- arXiv ID: 2601.18608
- Source URL: https://arxiv.org/abs/2601.18608
- Reference count: 40
- Extends KernelSHAP with polynomial regression to capture feature interactions, improving Shapley value accuracy

## Executive Summary
PolySHAP enhances KernelSHAP by approximating cooperative games with higher-degree polynomials, capturing non-linear feature interactions that linear approximations miss. The method fits a weighted polynomial to game evaluations on random subsets and extracts Shapley values from the fitted coefficients. Empirically, 2nd and 3rd-degree polynomials yield more accurate estimates than KernelSHAP across diverse datasets. Theoretical analysis shows PolySHAP is consistent and reveals that paired sampling implicitly performs second-order polynomial regression, providing both improved accuracy and deeper understanding of Shapley estimation methods.

## Method Summary
PolySHAP generalizes KernelSHAP by fitting a k-degree polynomial to approximate the cooperative game instead of a linear model. It constructs a design matrix with main effects and interaction terms, solves a constrained least squares problem enforcing the efficiency axiom, and extracts Shapley values from polynomial coefficients. The method supports paired sampling (subset and its complement) and leverage score-based sampling, with interaction frontiers ranging from full k-additive to partial frontiers for high dimensions.

## Key Results
- 2-PolySHAP and 3-PolySHAP achieve lower MSE than KernelSHAP across 15 diverse datasets
- Paired sampling produces exactly the same results as second-order PolySHAP without explicitly fitting quadratic terms
- In high dimensions (dâ‰¥60), PolySHAP shows modest improvements due to budget constraints on interaction terms

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Interaction terms capture non-linear dependencies missed by linear approximations
- **Mechanism:** Higher-degree polynomials better approximate the game $\nu(S)$ through weighted least squares, yielding more accurate Shapley values
- **Core assumption:** Sufficient budget $m$ relative to interaction terms to avoid underdetermination
- **Evidence:** Abstract states polynomials "capture non-linear interactions"; Definition 4.1 formalizes interaction-based representation

### Mechanism 2
- **Claim:** Paired sampling implicitly performs second-order polynomial regression
- **Mechanism:** Theorem 5.1 proves paired sampling forces linear KernelSHAP solution into subspace matching 2nd-order PolySHAP
- **Core assumption:** Samples must be drawn in strict pairs
- **Evidence:** Abstract confirms equivalence; cited neighbor paper is special case

### Mechanism 3
- **Claim:** Shapley values recovered from polynomial coefficients via interaction weight distribution
- **Mechanism:** Formula distributes interaction coefficients among involved players (Equation 3)
- **Core assumption:** Polynomial approximation faithfully proxies the game $\nu$
- **Evidence:** Theorem 4.3 provides extraction formula; proof confirms recovery maps to true Shapley values

## Foundational Learning

- **Concept: Shapley Value Efficiency Axiom**
  - **Why needed:** Constraint $\langle \phi, 1 \rangle = \nu(D)$ is essential for interpreting regression formulation
  - **Quick check:** Why project off the all-ones vector before solving least squares?

- **Concept: KernelSHAP (Linear Least Squares Shapley)**
  - **Why needed:** PolySHAP generalizes KernelSHAP; understanding the 1-PolySHAP baseline clarifies how adding interactions modifies design matrix
  - **Quick check:** How does $\tilde{X}$ change when moving from 1-PolySHAP to 2-PolySHAP?

- **Concept: Combinatorial Explosion of Interactions**
  - **Why needed:** Full $k$-additive frontiers grow as $O(d^k)$, making partial frontiers necessary for high dimensions
  - **Quick check:** Why is 3-PolySHAP infeasible for $d=60$ without partial frontiers?

## Architecture Onboarding

- **Component map:** Sampler -> Game Evaluator -> Design Matrix Builder -> Constrained Solver -> Value Extractor
- **Critical path:** Dominated by Game Evaluator (model calls) for complex models; Design Matrix Builder and Solver scale as $O(m \cdot d'^2 + d'^3)$ for $k \geq 3$
- **Design tradeoffs:**
  - Higher-degree polynomials yield lower MSE but require $m \gg d'$ to avoid overfitting
  - Paired sampling preferred for $k=1, 2$ (free interactions), explicit polynomials needed for $k=3+$
  - Partial frontiers necessary for $d > 30$ to keep $d'$ tractable
- **Failure signatures:**
  - Underdetermined System: $m < d'$ causes numerical errors; ensure sufficient budget
  - Rank Deficiency: Redundant interactions cause instability; apply regularization
  - Interaction Explosion: Memory crash on $d > 30$ with $k \geq 3$; use partial frontiers
- **First 3 experiments:**
  1. Verify Theorem 5.1: Run Paired KernelSHAP and 2-PolySHAP on small synthetic game, confirm exact match
  2. Budget Scaling: On Bike ($d=12$), plot MSE vs Budget for $k=1, 2, 3$ to find threshold where 3-PolySHAP outperforms 2-PolySHAP
  3. High-Dimension Stress Test: Run 3-PolySHAP on Crime ($d=101$) with partial frontier, compare MSE against RegressionMSR

## Open Questions the Paper Calls Out

- **Open Question 1:** Does equivalence between paired $k$-PolySHAP and paired $(k+1)$-PolySHAP hold for all odd integers $k$ where $1 \le k < d$?
  - Basis: Authors conjecture pattern holds for all odd $k$ but leave proof for future work
  - Why unresolved: Proof relies on projection lemma that doesn't obviously generalize beyond $k=1$
  - Evidence needed: Formal proof extending projection properties or empirical demonstration of divergence

- **Open Question 2:** Can PolySHAP be improved by integrating adaptive or structured interaction frontiers?
  - Basis: Conclusion suggests exploring frontiers derived from interaction detection or graph structures
  - Why unresolved: Current implementation uses fixed full or random partial frontiers
  - Evidence needed: Algorithm dynamically constructing frontier based on game evaluations or topology

- **Open Question 3:** How to reduce $O(d'^2)$ computational complexity to remain competitive with tree-based methods in high dimensions?
  - Basis: Paper notes modest improvements in $d \ge 60$ due to budget constraints on $d'$
  - Why unresolved: Least squares cost scales quadratically with interaction terms
  - Evidence needed: Optimization technique reducing $d'$ dependency for higher-order interactions

- **Open Question 4:** Is there a closed-form solution for leverage scores of $k$-additive interaction frontier?
  - Basis: Section 4.3 notes closed-form solution remains unknown, using order-1 score heuristics
  - Why unresolved: Order-1 scores may not optimally minimize variance for higher-order terms
  - Evidence needed: Derivation of theoretical leverage scores for $k > 1$ or proof of order-1 optimality

## Limitations

- Computational scaling issues in high dimensions ($d \ge 60$) where quadratic complexity limits feasible interaction terms
- Implementation complexity of partial interaction frontiers with unspecified selection criteria for interaction terms
- Theoretical guarantees assume games can be approximated by polynomials, potentially failing for highly discontinuous or non-smooth cooperative games

## Confidence

- **High Confidence:** Theorem 5.1 (paired sampling equivalence), Theorem 4.3 (Shapley value extraction), core experimental findings showing 2-PolySHAP and 3-PolySHAP outperform KernelSHAP
- **Medium Confidence:** Implementation details of partial interaction frontiers, particularly selection criteria for "PolySHAP (log)" and "PolySHAP (50%)" variants
- **Low Confidence:** Claims about computational efficiency compared to RegressionMSR baseline lacking detailed runtime analysis

## Next Checks

1. Implement paired KernelSHAP and 2-PolySHAP on small synthetic game (d=4, m=100) and verify exact output match to confirm Theorem 5.1

2. On Bike dataset (d=12), systematically vary budget m and plot MSE curves for k=1, 2, 3 to identify minimum budget threshold where higher-degree polynomials provide measurable benefits

3. Run 3-PolySHAP on Crime dataset (d=101) using partial "log" frontier and compare MSE against RegressionMSR to verify competitive performance when full interaction frontiers are computationally infeasible