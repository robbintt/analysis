---
ver: rpa2
title: 'Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on
  Low-Rank Adaptation in Matrix Factorization'
arxiv_id: '2503.06982'
source_url: https://arxiv.org/abs/2503.06982
tags:
- lora
- initialization
- show
- b2a2
- alignment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides a theoretical analysis of LoRA (Low-Rank Adaptation)
  for fine-tuning pre-trained models, focusing on matrix factorization tasks. The
  authors study the learning dynamics under gradient flow, revealing two distinct
  phases: an alignment phase where singular vectors of LoRA weights correct misalignment
  with the target task, and a local convergence phase with linear convergence rate.'
---

# Understanding the Learning Dynamics of LoRA: A Gradient Flow Perspective on Low-Rank Adaptation in Matrix Factorization

## Quick Facts
- **arXiv ID:** 2503.06982
- **Source URL:** https://arxiv.org/abs/2503.06982
- **Reference count:** 40
- **One-line primary result:** Smaller initialization scales lead to better alignment and lower final training error in LoRA, with spectral initialization achieving exact convergence.

## Executive Summary
This paper provides a theoretical analysis of LoRA (Low-Rank Adaptation) for fine-tuning pre-trained models, focusing on matrix factorization tasks. The authors study the learning dynamics under gradient flow, revealing two distinct phases: an alignment phase where singular vectors of LoRA weights correct misalignment with the target task, and a local convergence phase with linear convergence rate. A key finding is that smaller initialization scales lead to better alignment and lower final training error. The authors also propose a spectral initialization method that leverages both pre-trained weights and fine-tuning target matrices, proving convergence to arbitrary precision. Experiments on matrix factorization and image classification tasks validate the theoretical results, showing that smaller initialization scales consistently improve performance. The work bridges the gap between LoRA's empirical success and theoretical understanding of its optimization dynamics.

## Method Summary
The paper analyzes LoRA learning dynamics through gradient flow on matrix factorization tasks. The method involves studying a two-layer network with pre-trained weights $W_1, W_2$ and trainable LoRA adapters $A_i, B_i$ (where $B_i$ starts at zero). The analysis tracks the evolution of singular values and vectors of the weight matrices to identify two distinct phases: (1) an alignment phase where singular vectors correct misalignment with the target, and (2) a local convergence phase with linear convergence rate. The authors prove that smaller initialization scales ($\alpha$) lead to better alignment and lower final training error. They also propose a spectral initialization method using SVD of the fine-tuning target difference, which achieves exact convergence to arbitrary precision. Experiments validate these findings on synthetic matrix factorization and ResNet-50 fine-tuning on CIFAR-10.

## Key Results
- Gradient flow on LoRA exhibits two distinct phases: alignment of singular vectors followed by linear convergence
- Smaller initialization scales lead to better alignment and lower final training error (error floor proportional to $\alpha$)
- Spectral initialization using target matrix SVD achieves exact convergence to arbitrary precision
- Theoretical predictions validated on both matrix factorization and image classification tasks

## Why This Works (Mechanism)

### Mechanism 1: Implicit Spectral Alignment via Small Initialization
- **Claim:** With sufficiently small initialization scale ($\alpha$), gradient flow first aligns the singular vectors of the LoRA weights with the fine-tuning target direction before significantly increasing weight norms.
- **Mechanism:** The learning dynamics act as a perturbation of a simplified linear system $\dot{Z}_1 \approx \sigma \sigma_{W_2} H_1 Z_1$. This term promotes the growth of components aligned with the target singular vector $\gamma_1$ while suppressing orthogonal components. Because the initial noise (random initialization) is small, the signal direction dominates, effectively performing a "spectral initialization" implicitly during the early training steps.
- **Core assumption:** The initialization scale $\alpha$ is small enough that perturbation terms (like $\hat{D}_1$) are negligible compared to the dominant signal term ($\sigma \sigma_{W_2} H_1$) during the initial phase.
- **Evidence anchors:**
  - [abstract]: "alignment phase where singular vectors of LoRA weights correct misalignment... smaller initialization scales lead to better alignment"
  - [section 3.2]: "Claim 3.1... demonstrates that the simplified dynamics of $Z_1$ and $Z_2$ lead to the alignment of $U^S_{Z1}$ with $\gamma_1$"
  - [corpus]: Related work "Put the Space of LoRA Initialization to the Extreme" suggests small initialization spaces aid knowledge preservation, aligning with the importance of scale found here.
- **Break condition:** If $\alpha$ is too large, the perturbation terms ($\hat{D}_1$) interfere with the alignment dynamics, causing the model to converge to a suboptimal basin with higher training error.

### Mechanism 2: Linear Convergence with Non-Zero Error Floor
- **Claim:** Following the alignment phase, the training loss decreases linearly but converges to a neighborhood around the optimal solution determined by the initialization scale.
- **Mechanism:** After alignment, the objective satisfies a local Polyak-Lojasiewicz (PL) condition. However, the final loss is bounded by a term proportional to $\alpha$. The alignment quality determines the "noise loss" component ($L_N$), while the "signal loss" ($L_S$) converges. Residual misalignment prevents exact convergence to zero loss.
- **Core assumption:** The pre-trained weights solve the pre-training task perfectly, and the fine-tuning task differs by a rank-1 modification (or low rank).
- **Evidence anchors:**
  - [section 3.3]: "Theorem 3.2... Loss Converges Linearly... $L(t) \le \dots + \alpha c_3$"
  - [abstract]: "GF converges to a neighborhood of the optimal solution, with smaller initialization leading to lower final error."
  - [corpus]: "Beyond Zero Initialization" investigates non-zero initialization dynamics, complementing this paper's finding that zero/small init sets a specific error floor.
- **Break condition:** If the pre-trained singular values have no imbalance ($\delta_w = 1$), the mechanism driving the norm growth and imbalance may fail, stalling convergence.

### Mechanism 3: Exact Convergence via Spectral Initialization
- **Claim:** If initialized using the singular spaces of the fine-tuning target difference ($\Delta Y$), gradient flow converges to the target with arbitrary precision (zero loss).
- **Mechanism:** This initialization removes the "alignment phase" requirement by perfectly aligning weights with the target subspace at $t=0$. The dynamics then decouple into scalar dynamics for the singular values, which converge without the constant error floor associated with random small initialization.
- **Core assumption:** Access to the fine-tuning target matrix (or its statistics) to compute the SVD for initialization.
- **Evidence anchors:**
  - [section 4]: "Theorem 4.1... loss converges linearly... $ \ell^{(i)}(t) \le \exp(-\dots)\ell^{(i)}(T_1)$"
  - [abstract]: "proving convergence to arbitrary precision."
  - [corpus]: "ConsNoTrainLoRA" discusses data-driven initialization, which aligns with the paper's proposal to use target data for initialization.
- **Break condition:** If the target difference rank exceeds the LoRA rank ($r < \text{rank}(\Delta Y)$), the mechanism cannot capture the full target transformation.

## Foundational Learning

**Concept: Singular Value Decomposition (SVD)**
- **Why needed here:** The paper describes the learning dynamics entirely in terms of the evolution of singular values and vectors of the weight matrices. You cannot understand the "alignment phase" without understanding vector subspaces.
- **Quick check question:** If a matrix $M$ is updated to $M + \epsilon v u^\top$, how does the SVD of $M$ change?

**Concept: Gradient Flow (GF)**
- **Why needed here:** The theoretical results are derived for continuous-time gradient flow, not discrete steps. Understanding the relationship $dW/dt = -\nabla L$ is essential.
- **Quick check question:** How does the learning rate in Gradient Descent relate to the time variable $t$ in Gradient Flow?

**Concept: The Polyak-Lojasiewicz (PL) Condition**
- **Why needed here:** The paper uses the local PL condition to prove linear convergence in the second phase.
- **Quick check question:** Does the PL condition guarantee convergence to a global minimum? (Answer: Yes, if satisfied globally; here it's local).

## Architecture Onboarding

**Component map:**
- Pre-trained Weights ($W_1, W_2$): Fixed matrices. Ideally, these are balanced ($W_i W_i^\top = W_i^\top W_i$).
- LoRA Adapters ($A_i, B_i$): Trainable low-rank matrices. $B_i$ starts at zero; $A_i$ is initialized with scale $\alpha$.
- Target Matrix ($Y_{ft}$): The matrix we want the product $(W_2+B_2 A_2)(W_1+B_1 A_1)$ to approximate.

**Critical path:**
1. **Initialization:** Choose $\alpha$. Smaller $\alpha$ is theoretically better but slows training.
2. **Alignment Phase:** Monitor the alignment metric $\cos^2(U_{Z_1}, \gamma_1)$. This should approach 1.
3. **Norm Growth:** Monitor $\|Z_1\|$. It must grow to escape the saddle point.
4. **Convergence:** Loss drops linearly to a floor determined by $\alpha$.

**Design tradeoffs:**
- **Standard (Small) Init:** Pro: No knowledge of downstream target needed. Con: Converges to a neighborhood (non-zero loss), not exact solution.
- **Spectral Init:** Pro: Exact convergence. Con: Requires computing SVD of the fine-tuning target (expensive/feasible mostly for MF tasks or approximations).

**Failure signatures:**
- **Stalling:** $\|Z\|$ does not grow (saddle point trap). This suggests $\alpha$ is too small relative to numerical precision or $\delta_w \approx 1$.
- **High Final Loss:** Convergence stops early. This suggests $\alpha$ is too large (poor alignment) or rank $r$ is insufficient.

**First 3 experiments:**
1. **Vary Initialization Scale ($\alpha$):** Run MF training with $\alpha \in \{10^{-2}, 10^{-4}, 10^{-6}\}$. Plot final loss vs. $\alpha$ to verify the linear relationship.
2. **Visualize Alignment:** Track $\cos(\text{target vector}, \text{current top singular vector})$ over time. Verify the "two-phase" structure (alignment $\to$ convergence).
3. **Spectral vs. Random:** Compare standard random initialization against the proposed spectral initialization on a synthetic matrix factorization task. Verify that spectral init achieves near-zero loss.

## Open Questions the Paper Calls Out

**Open Question 1**
- Question: How does the initialization scale specifically influence the generalization performance of LoRA in deep neural networks, beyond the training error dynamics analyzed in this work?
- Basis in paper: [explicit] The authors note in Section 5.2: "While our focus is on LoRAâ€™s optimization process, these results suggest that the initialization scale may also impact generalization performance."
- Why unresolved: The theoretical analysis is strictly confined to the optimization dynamics of minimizing training error in matrix factorization, and does not establish bounds or mechanisms for test error.
- What evidence would resolve it: Theoretical generalization bounds linking alignment quality to test error, or empirical studies isolating the effect of initialization scale on generalization gaps in deep transformers.

**Open Question 2**
- Question: Can the theoretical guarantees regarding the alignment and convergence phases be extended to deep neural networks with multiple coupled layers?
- Basis in paper: [explicit] In the Introduction, the authors state their analysis "represents an initial step towards understanding the learning dynamics of LoRA" and focuses solely on matrix factorization tasks rather than full models.
- Why unresolved: The paper analyzes a single LoRA module applied to a matrix factorization objective; deep networks introduce higher-order interactions between multiple LoRA layers (e.g., $W_1+B_1A_1$ and $W_2+B_2A_2$) that complicate the dynamics described in Equation 4.
- What evidence would resolve it: A theoretical extension characterizing the dynamics of cascaded LoRA layers, or empirical validation that the alignment and local convergence phases persist in the hidden layers of large language models.

**Open Question 3**
- Question: Can the convergence guarantees for small random initialization be extended to fine-tuning tasks with general rank $r > 1$?
- Basis in paper: [explicit] Theorem 3.1 is explicitly restricted to the case where $\text{rank}(\Delta Y) = 1$, whereas Theorem 4.1 (spectral initialization) handles general ranks.
- Why unresolved: The theoretical proof for small initialization relies on the specific dynamics of a single singular value direction aligning with a target vector, avoiding the complexity of interactions between multiple singular value directions competing for alignment.
- What evidence would resolve it: A proof of convergence for small initialization with general rank-$r$ updates, or an analysis showing whether the "incremental learning" phenomenon (learning singular values sequentially) occurs in LoRA.

## Limitations
- Theoretical analysis limited to matrix factorization tasks and gradient flow (continuous-time limit)
- Connection between two-phase dynamics in MF and real-world vision tasks is empirically demonstrated but not rigorously proven
- Spectral initialization requires access to fine-tuning target matrix or its statistics, which may not be feasible in practice
- Analysis assumes pre-trained weights solve pre-training task perfectly, which may not hold in practice

## Confidence
- **High Confidence:** The two-phase learning dynamics (alignment followed by linear convergence) and the relationship between initialization scale and final training error are well-supported by both theory (Theorem 3.2) and experiments (Figure 2).
- **Medium Confidence:** The claim that smaller initialization scales always lead to better alignment is theoretically sound but may be affected by practical considerations like numerical precision and training duration in real implementations.
- **Medium Confidence:** The spectral initialization method's exact convergence is rigorously proven for MF tasks, but its practical effectiveness on complex vision tasks depends on the quality of the SVD approximation used.

## Next Checks
1. **Rank Sensitivity Analysis:** Systematically vary LoRA rank $r$ and measure its impact on both the alignment phase duration and final training error to understand the interplay between rank and initialization scale.
2. **Cross-Domain Generalization:** Apply the theoretical insights to a broader range of tasks beyond matrix factorization (e.g., language modeling fine-tuning) to test the universality of the two-phase dynamics.
3. **Numerical Stability:** Investigate the effects of finite-precision arithmetic and discrete-time optimization (SGD/Adam) on the alignment phase, particularly for very small initialization scales.