---
ver: rpa2
title: Latent Space Consistency for Sparse-View CT Reconstruction
arxiv_id: '2507.11152'
source_url: https://arxiv.org/abs/2507.11152
tags:
- latent
- space
- learning
- diffusion
- reconstruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes CLS-DM, a novel latent diffusion model for
  sparse-view CT reconstruction that incorporates contrastive learning to address
  misalignment between 2D X-ray features and 3D latent space. The method uses a three-stage
  training approach: perceptual feature compression from voxel space to latent space,
  cross-modal contrastive learning guided by autoregressive reconstruction, and conditional
  diffusion in the aligned latent space.'
---

# Latent Space Consistency for Sparse-View CT Reconstruction

## Quick Facts
- arXiv ID: 2507.11152
- Source URL: https://arxiv.org/abs/2507.11152
- Reference count: 40
- Primary result: Novel latent diffusion model for sparse-view CT reconstruction using contrastive learning

## Executive Summary
This paper addresses the challenge of sparse-view CT reconstruction by proposing CLS-DM, a latent diffusion model that incorporates contrastive learning to align 2D X-ray features with 3D latent space representations. The method introduces a three-stage training approach that first compresses perceptual features from voxel space to latent space, then applies cross-modal contrastive learning guided by autoregressive reconstruction, and finally performs conditional diffusion in the aligned latent space. The approach demonstrates significant improvements over classical and state-of-the-art generative models, achieving PSNR improvements of nearly 2 points and superior SSIM scores on medical CT datasets.

## Method Summary
CLS-DM employs a novel three-stage training framework to address the misalignment between 2D X-ray projections and 3D latent representations in sparse-view CT reconstruction. The first stage performs perceptual feature compression, mapping voxel space features to a lower-dimensional latent space. The second stage implements cross-modal contrastive learning, where the model learns to align the compressed features with corresponding X-ray projections through carefully curated triplets and autoregressive reconstruction guidance. The final stage applies conditional diffusion in the aligned latent space to generate high-quality reconstructions. This approach effectively bridges the modality gap while maintaining computational efficiency compared to traditional iterative reconstruction methods.

## Key Results
- CLS-DM achieves PSNR of 25.22 versus 23.58 for second-best method (nearly 2-point improvement)
- SSIM reaches 0.6185 versus 0.5963 for competing approaches
- Superior reconstruction quality with more accurate anatomical details demonstrated on LIDC-IDRI and CTSpine1K datasets
- Consistent performance across different view configurations (from 4 to 16 views)

## Why This Works (Mechanism)
The method succeeds by addressing the fundamental misalignment between 2D projection data and 3D reconstruction space through contrastive learning. By explicitly training the model to recognize correspondences between X-ray features and their 3D latent representations, CLS-DM creates a consistent latent space that better captures the underlying anatomical structures. The autoregressive reconstruction guidance during contrastive learning ensures that the learned representations maintain spatial coherence and anatomical plausibility, while the conditional diffusion process leverages this aligned latent space to generate high-quality reconstructions from sparse-view inputs.

## Foundational Learning
- **Sparse-view CT reconstruction**: Why needed - CT typically requires many projections for accurate reconstruction; quick check - evaluate performance degradation as views decrease
- **Latent diffusion models**: Why needed - efficient generation in compressed representation space; quick check - compare with direct voxel-space diffusion
- **Contrastive learning**: Why needed - align cross-modal features (X-ray to 3D); quick check - ablation without contrastive component
- **Autoregressive reconstruction**: Why needed - provide reconstruction guidance for alignment; quick check - measure impact on alignment quality
- **Perceptual feature compression**: Why needed - reduce dimensionality while preserving anatomical information; quick check - evaluate reconstruction quality vs compression ratio
- **Cross-modal feature alignment**: Why needed - bridge 2D projection and 3D reconstruction modalities; quick check - assess alignment quality through retrieval tasks

## Architecture Onboarding

**Component Map**
Perceptual compression module -> Cross-modal contrastive learning -> Conditional diffusion generator -> Reconstruction output

**Critical Path**
1. Input sparse-view X-ray projections
2. Feature extraction and compression to latent space
3. Contrastive alignment with 3D latent representations
4. Conditional diffusion for final reconstruction

**Design Tradeoffs**
- Complexity vs performance: Three-stage training improves quality but increases implementation complexity
- Compression ratio vs detail preservation: Higher compression improves efficiency but may lose fine anatomical details
- Contrastive sample selection: Quality of triplets affects alignment quality but requires careful curation
- Diffusion steps vs runtime: More steps improve quality but increase inference time

**Failure Signatures**
- Poor alignment between X-ray and latent features manifests as ghosting artifacts
- Insufficient compression leads to high computational cost without proportional quality gains
- Over-reliance on autoregressive guidance may cause smoothing of fine details
- Inadequate negative sampling in contrastive learning results in collapsed representations

**3 First Experiments**
1. Ablation study removing contrastive learning stage to measure alignment impact
2. Varying compression ratios to find optimal trade-off between efficiency and quality
3. Testing with different numbers of diffusion steps to analyze quality vs runtime relationship

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Evaluation limited to specific medical datasets (LIDC-IDRI and CTSpine1K), limiting generalizability
- Computational efficiency claims lack comprehensive runtime benchmarking across hardware configurations
- Three-stage training approach introduces significant complexity affecting practical deployment
- Contrastive learning framework depends on carefully curated triplets, raising questions about robustness

## Confidence

**High Confidence Claims:**
- CLS-DM outperforms classical methods and state-of-the-art generative models on tested datasets
- Proposed latent space consistency approach effectively addresses cross-modal misalignment
- Quantitative improvements (PSNR ~25.22, SSIM ~0.6185) are statistically significant

**Medium Confidence Claims:**
- Generalizability to other CT reconstruction scenarios beyond tested datasets
- Computational efficiency without comprehensive runtime benchmarking
- Long-term stability of three-stage training approach

**Low Confidence Claims:**
- Clinical applicability without medical expert validation
- Performance under extreme sparse-view conditions (<4 views)
- Scalability to very large 3D volumes or industrial CT applications

## Next Checks
1. Cross-dataset validation: Evaluate CLS-DM on additional CT datasets including different anatomies, clinical-grade data, and non-medical CT applications
2. Ablation studies: Systematically evaluate contribution of each training stage and impact of removing components like autoregressive guidance
3. Computational profiling: Conduct comprehensive runtime analysis comparing CLS-DM against baselines on multiple hardware configurations, including GPU memory usage and inference time