---
ver: rpa2
title: Mitigating Object Hallucinations in MLLMs via Multi-Frequency Perturbations
arxiv_id: '2503.14895'
source_url: https://arxiv.org/abs/2503.14895
tags:
- image
- features
- arxiv
- object
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses object hallucinations in multimodal large
  language models (MLLMs), where models generate descriptions that do not accurately
  correspond to objects in images. The core issue identified is that MLLMs are overly
  susceptible to specific image frequency features when detecting objects, leading
  to hallucinations.
---

# Mitigating Object Hallucinations in MLLMs via Multi-Frequency Perturbations

## Quick Facts
- arXiv ID: 2503.14895
- Source URL: https://arxiv.org/abs/2503.14895
- Reference count: 40
- Primary result: MFP achieves CHAIRs=41.2 and CHAIRi=11.7 on the CHAIR benchmark

## Executive Summary
This paper addresses object hallucinations in multimodal large language models (MLLMs) by targeting their over-reliance on specific image frequency features. The authors propose Multi-Frequency Perturbations (MFP), a method that partitions images into high- and low-frequency components, extracts their features, and fuses them with original image features at the visual token level. This process explicitly suppresses redundant frequency-domain features during inference. Experimental results show that MFP significantly reduces hallucinations across various model architectures and achieves state-of-the-art performance on the CHAIR benchmark when combined with inference-time methods.

## Method Summary
MFP operates by applying Fourier transforms to decompose images into high- and low-frequency components, which are then processed separately through the visual encoder. The method introduces a cross-attention fusion layer where the original image tokens serve as queries and the frequency tokens as keys/values, creating a composite representation. During inference, an attenuation factor γ (sampled from a uniform distribution) is applied to the frequency components to prevent over-reliance on these features. The approach is trained in two stages: first on a pre-training corpus (LCS-558k) to learn the fusion mechanism, then on an SFT corpus (LLaVA-mixed-665k) to fine-tune the complete model. The method achieves hallucination reduction while maintaining general visual understanding capabilities.

## Key Results
- Achieves CHAIRs score of 41.2 and CHAIRi score of 11.7 on the CHAIR benchmark
- Outperforms baselines by 6.1% on POPE F1 score (86.2 vs 80.1)
- Demonstrates strong generalization across different LLMs, visual encoders, resolutions, and model sizes
- Reduces hallucinations while maintaining object recall through optimal γ tuning

## Why This Works (Mechanism)

### Mechanism 1: Frequency-Based Over-Susceptibility Disruption
If MLLMs are over-reliant on specific frequency bands (e.g., high-frequency edges or low-frequency shapes) to identify objects, forcing them to process perturbed frequency data may disrupt spurious correlations. The authors identify that MLLMs can hallucinate objects based solely on high-pass or low-pass filtered images where the actual object is unrecognizable to humans. MFP counteracts this by explicitly training the model to fuse these frequency features with the original image, theoretically forcing the model to ground its predictions in the composite reality rather than isolated frequency triggers.

### Mechanism 2: Token-Level Cross-Attention Fusion
Injecting frequency features directly into the visual token stream allows the LLM to "attend" to frequency information contextually rather than treating it as a separate modality. Instead of simply summing features, MFP uses a cross-attention mechanism where the original visual token acts as the Query and the concatenated high/low-frequency tokens act as Keys/Values. This implies the original image "queries" the frequency data for supplementary information (e.g., edges or outlines) to refine its representation.

### Mechanism 3: Inference-Time Stochastic Attenuation
Reducing the intensity of frequency signals during inference prevents the model from "over-firing" on redundant frequency features. During inference, the method applies a decay factor γ (sampled from a uniform distribution) to the amplitude of the frequency components before they are encoded. This acts as a stochastic regularizer, suppressing the "loudness" of the frequency features that cause hallucinations.

## Foundational Learning

- **Concept: Fourier Transform & Frequency Filtering**
  - Why needed here: This paper operates entirely on the frequency domain representation of images (FFT → Filter → IFFT). You must understand that High Frequency = Edges/Noise and Low Frequency = Shapes/Colors to debug the visual outputs.
  - Quick check question: If you apply a Gaussian High-Pass filter to an image of a grey circle on a white background, what remains?

- **Concept: Object Hallucination Benchmarks (CHAIR/POPE)**
  - Why needed here: The paper optimizes for specific metrics (CHAIRs, CHAIRi) that measure "hallucinated objects." You need to distinguish between sentence-level hallucinations (CHAIRs) and instance-level (CHAIRi) to interpret the results.
  - Quick check question: Does a high CHAIRs score mean the model missed objects, or invented objects?

- **Concept: Cross-Attention vs. Self-Attention**
  - Why needed here: The core fusion module (MFP) uses Cross-Attention where Query ≠ Key/Value. Understanding this directional flow is critical to debugging why the model might ignore frequency tokens (if Q is too dominant).
  - Quick check question: In the MFP fusion layer, which token acts as the Query and which acts as the Key?

## Architecture Onboarding

- **Component map:** Visual Encoder → MFP Module (Cross-Attention) → Connector → LLM Backbone, with frequency decomposition happening before the visual encoder
- **Critical path:** The frequency decomposition (FFT) happens before the visual encoder. The encoder must process the image 3 times per forward pass. The MFP Cross-Attention happens after visual encoding but before the LLM connector.
- **Design tradeoffs:**
  - Computation: This method triples the Visual Encoder workload (3 passes per image).
  - Gamma (γ): You must tune γ per dataset. High γ retains details but risks hallucination; low γ is safe but "blind" to texture.
- **Failure signatures:**
  - Gray/Washed outputs: If γ is too low or filters are misconfigured, the model generates generic captions lacking detail.
  - OOM (Out of Memory): 3x Visual Encoder batch size requirements often crash standard setups.
  - Artifacts: Incorrect FFT shifting/padding results in visual "ringing" artifacts in the input I_l or I_h.
- **First 3 experiments:**
  1. Visual Sanity Check: Visualize I_l and I_h before feeding them to the model. Ensure I_l looks blurry (shapes) and I_h looks like a sketch (edges).
  2. Gamma Sweep: Run inference on 100 images with γ ∈ [0.0, 0.2, 0.5, 1.0] to verify the paper's claim that lower gamma reduces hallucinations (CHAIRs) but hurts recall (F1).
  3. Attention Visualization: Visualize the attention maps in the MFP Cross-Attention layer. Does the original image token actually attend to the frequency tokens, or is the attention weight near zero?

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the number of feature fusion layers and the specific selection of frequency ranges impact the effectiveness of MFP in mitigating hallucinations?
- Basis in paper: [explicit] Appendix E states that the experiments "do not include a comprehensive analysis of key hyperparameters, such as the number of feature fusion layers and the specific frequency ranges utilized."
- Why unresolved: The authors limited the scope of their experiments due to computational constraints, leaving the optimal architectural configuration undetermined.
- What evidence would resolve it: A systematic ablation study varying the number of fusion layers and the cutoff frequency D_0 to measure their correlation with CHAIR scores.

### Open Question 2
- Question: Does MFP maintain consistent performance when applied to a broader range of MLLM architectures outside of the LLaVA family?
- Basis in paper: [explicit] Appendix E notes that "our evaluation is conducted on a limited set of model architectures, which may impact the generalizability of our findings."
- Why unresolved: While the paper tests generalization across LLM backbones and resolutions, it primarily relies on LLaVA-style architectures, leaving other structural paradigms unexplored.
- What evidence would resolve it: Application of MFP to distinct non-LLaVA architectures (e.g., InternVL, Qwen-VL) demonstrating similar reductions in hallucination metrics.

### Open Question 3
- Question: Can a dynamic adjustment mechanism for the attenuation factor γ optimize the trade-off between hallucination suppression and object recall?
- Basis in paper: [inferred] Figure 4 shows that lowering γ increases precision but decreases recall, suggesting the current static selection of γ (e.g., 0.23) creates a fixed, suboptimal trade-off for different images.
- Why unresolved: The paper uses a fixed γ value at inference, but the sensitivity analysis implies that the optimal level of frequency suppression likely varies per image.
- What evidence would resolve it: An adaptive method where γ is predicted per image or token, achieving a higher F1 score than the fixed baseline.

## Limitations
- Computational overhead requiring 3x visual encoder passes per image, potentially limiting practical deployment
- Optimal attenuation factor γ appears dataset-specific and may require tuning for different domains
- Focuses specifically on frequency-based hallucinations while not addressing language-prior-driven hallucinations
- Ablation studies don't fully isolate whether improvements come from frequency fusion itself or the attention mechanism

## Confidence
- **High Confidence:** The core mechanism of frequency decomposition and fusion is well-specified and the experimental setup is clearly documented. The improvements on CHAIR benchmarks are substantial and reproducible.
- **Medium Confidence:** The claim that frequency over-susceptibility is the "key cause" of hallucinations is supported by evidence but may be overstated. Other hallucination mechanisms likely contribute significantly.
- **Low Confidence:** The inference-time attenuation mechanism's effectiveness across different datasets and domains is less certain, as the paper only reports results for MSCOCO and controlled evaluations.

## Next Checks
1. **Cross-Domain Generalization Test:** Evaluate MFP on non-natural images (medical imaging, satellite imagery, or synthetic datasets) to verify that frequency-based hallucination mitigation generalizes beyond MSCOCO's natural scenes.
2. **Frequency-Only Ablation Study:** Train and evaluate models using only high-frequency or only low-frequency inputs (without the original image) to quantify whether MFP truly grounds predictions or merely shifts hallucination patterns to different frequency domains.
3. **Computational Overhead Measurement:** Benchmark inference latency and memory usage on hardware representative of deployment scenarios (e.g., A100 GPU) to determine if the 3x visual encoder cost is prohibitive for practical applications.