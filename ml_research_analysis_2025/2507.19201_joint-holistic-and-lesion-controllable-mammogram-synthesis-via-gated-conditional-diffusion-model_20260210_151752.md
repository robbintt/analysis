---
ver: rpa2
title: Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional
  Diffusion Model
arxiv_id: '2507.19201'
source_url: https://arxiv.org/abs/2507.19201
tags:
- image
- synthesis
- features
- control
- mass
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GCDM, a diffusion-based framework for controllable
  mammogram synthesis that integrates both holistic breast and localized lesion generation.
  GCDM uses a soft mask embedding and a gated conditioning branch to incorporate radiomic
  and geometric lesion features, ensuring anatomical coherence and precise lesion
  control.
---

# Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional Diffusion Model

## Quick Facts
- arXiv ID: 2507.19201
- Source URL: https://arxiv.org/abs/2507.19201
- Reference count: 40
- Primary result: Introduces GCDM, a diffusion-based framework for controllable mammogram synthesis with both holistic breast and localized lesion generation, achieving FID 26.77 and Mass IoU 86.30% on VinDr-Mammo.

## Executive Summary
This paper introduces GCDM, a diffusion-based framework for controllable mammogram synthesis that integrates both holistic breast and localized lesion generation. GCDM uses a soft mask embedding and a gated conditioning branch to incorporate radiomic and geometric lesion features, ensuring anatomical coherence and precise lesion control. Experiments on the VinDr-Mammo dataset show that GCDM achieves a FID of 26.77, Mass IoU of 86.30%, Breast IoU of 97.63%, and PA of 98.41%, outperforming state-of-the-art methods in both realism and lesion controllability. Ablation studies confirm the effectiveness of each component. GCDM demonstrates strong potential for clinical applications, including data augmentation for downstream classification tasks.

## Method Summary
GCDM fine-tunes Stable Diffusion v1.5 to generate mammograms conditioned on both holistic breast structure and localized lesion characteristics. The method processes images through a VAE to obtain latent representations, then applies a diffusion model that incorporates a soft mask (Gaussian-blurred lesion channel) concatenated with the noisy latent. A gated conditioning branch extracts radiomic features (67 dimensions) and geometric features (CLIP-encoded) from lesion masks, fuses them through relevance scoring, and injects the result via cross-attention. The model is trained with noise-conditional score matching and evaluated on the VinDr-Mammo dataset.

## Key Results
- GCDM achieves FID of 26.77, Mass IoU of 86.30%, Breast IoU of 97.63%, and Pixel Accuracy of 98.41% on the VinDr-Mammo dataset
- Outperforms state-of-the-art RCM method with 5.25% higher Mass IoU while maintaining better overall image quality
- Ablation studies confirm effectiveness of soft mask and gated conditioning components
- Demonstrates clinical utility through improved downstream classification performance with data augmentation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Joint synthesis of holistic breast structure and localized lesions with anatomical coherence is achieved by concatenating a "soft mask" representation with the noisy latent image during the diffusion process.
- **Mechanism:** The diffusion model's denoising UNet receives a joint input: the current noisy latent ($z_t$) concatenated with a VAE-encoded representation of a three-channel mask ($M$). This mask represents background, breast tissue, and lesion. Crucially, the lesion channel undergoes Gaussian blur. This "softens" the hard boundary, providing a gradient that guides the model in generating a smooth transition between the mass and surrounding tissue.
- **Core assumption:** The latent space of a pre-trained VAE can meaningfully represent semantic layout information via a soft mask, and this spatial conditioning is superior to purely text-based or global conditioning for preserving anatomical boundaries.
- **Evidence anchors:**
  - [abstract] Mentions "soft mask embedding that represents breast, lesion, and their transitional regions, ensuring anatomical coherence."
  - [Page 4] The training objective is formulated as $L = E_{x_0,\epsilon,t} \|\epsilon - \epsilon_\theta(\text{concat}(z_t, E(G(M))), t)\|^2$, where $G$ is Gaussian blur.
- **Break condition:** This mechanism will fail if the soft mask boundaries are either too hard (causing artifacts at the lesion edge) or too soft (causing loss of precise lesion shape control).

### Mechanism 2
- **Claim:** Fine-grained, clinically meaningful control over lesion texture and shape is achieved by injecting a rich feature vector derived from radiomics and geometry into the diffusion process via cross-attention.
- **Mechanism:** A dedicated "Mass Control Branch" extracts two feature types: **radiomic features** (67 dimensions including texture and shape statistics from PyRadiomics) and **geometric features** (from the lesion mask via a CLIP encoder). These are cross-concatenated to form $m \times n$ candidate pairs. A "Gated Fusion" module computes a relevance score for each pair using average pooling and an MLP, selecting the top-$k$ pairs to create a final conditioning vector ($c$) injected into the UNet via cross-attention.
- **Core assumption:** Radiomic features from the original image and geometric features from a mask capture orthogonal and essential clinical characteristics that a standard diffusion model does not learn implicitly.
- **Evidence anchors:**
  - [abstract] Mentions "gated conditioning branch that guides the denoising process by dynamically selecting and fusing the most relevant radiomic and geometric properties of lesions."
  - [Page 5] Describes the gated fusion module's calculation: $w_{gate} = AVG(f_{comb}) \odot MLP(f_{comb})$ and the final conditioning vector $c = Conv(TopK(f_{comb} + w_{gate} \odot f_{comb}))$.
- **Break condition:** This mechanism fails if the initial radiomic features are not predictive of clinical appearance, causing the gating mechanism to amplify noise. The added complexity could also hinder training if the MLP cannot model meaningful dependencies.

### Mechanism 3
- **Claim:** High-fidelity image generation is built upon a fine-tuned Latent Diffusion Model (Stable Diffusion v1.5), leveraging its powerful pretrained priors for natural image statistics while adapting it to the mammography domain.
- **Mechanism:** Instead of training from scratch, the framework fine-tunes the weights of a pre-trained Stable Diffusion model. The two new control mechanisms (soft mask concatenation and gated feature injection) are added as additional inputs to the denoising UNet, guiding the pre-existing generation capabilities toward the specific anatomical requirements of mammography.
- **Core assumption:** The feature representations learned by Stable Diffusion on natural images are generalizable to the medical domain of mammography with only fine-tuning, and its VAE can adequately compress and decompress mammogram textures without critical loss of diagnostic detail.
- **Evidence anchors:**
  - [Page 3] "GCDM is built upon a latent denoising diffusion framework... it is built upon a fine-tuned image-conditioned stable diffusion model."
  - [Page 5] The denoising objective $L = E_{x_0,t,\epsilon} \|\epsilon - \epsilon_\theta(\text{concat}(z_t, E(G(M))), t, c)\|^2$ modifies the standard Stable Diffusion loss by adding extra conditioning inputs.
- **Break condition:** Fine-tuning may be insufficient if the domain shift is too large. The pre-trained VAE could be a bottleneck if its latent space is not optimized for the high-frequency details and contrast patterns of X-ray images.

## Foundational Learning

- **Latent Diffusion Models (LDMs) & Stable Diffusion:**
  - **Why needed here:** This is the foundational generative engine of the entire paper. You must understand how a denoising network (typically a UNet) operates in a compressed latent space (created by a VAE) to reverse a noise process.
  - **Quick check question:** What is the role of the VAE in the forward (noising) and reverse (denoising) processes of a Latent Diffusion Model?

- **Conditioning Mechanisms in Diffusion Models (Concatenation vs. Cross-Attention):**
  - **Why needed here:** The paper's core novelty is its dual conditioning strategy. You must understand why concatenation is used for the spatial layout (soft mask) and cross-attention for the semantic feature vector (radiomic/geometric).
  - **Quick check question:** In a UNet-based denoiser, how does the information flow differ when a conditioning signal is concatenated to the input channels versus being injected via a cross-attention layer?

- **Radiomics:**
  - **Why needed here:** A key part of the model's conditioning comes from a hand-crafted feature set called "radiomics." You need to know what these features represent to understand what the model is being conditioned on.
  - **Quick check question:** What kind of image characteristics do radiomic features typically quantify? Give examples. (Answer: shape, texture, intensity statistics, e.g., sphericity, entropy).

## Architecture Onboarding

- **Component map:**
  - Pre-trained Stable Diffusion v1.5: Base model containing UNet denoiser ($\epsilon_\theta$) and VAE (Encoder $E$, Decoder $D$)
  - Input Processing:
    - Soft Mask Generator: Takes binary mask, applies Gaussian blur ($G$) to lesion channel, creates 3-channel mask (background, breast, lesion)
    - Radiomic Feature Extractor: Uses PyRadiomics on image-mask pair to get 1x67 feature vector ($f$), processed by Conv layers
    - Geometric Feature Extractor: Uses CLIP vision encoder on lesion mask to get candidate features ($f_{geo}$)
  - Gated Fusion Module: Takes cross-concatenated radiomic and geometric features, computes relevance scores ($w_{gate}$) via Avg Pooling and an MLP, selects top-$k$, produces final conditioning vector ($c$)
  - Main Denoising UNet: Takes noisy latent ($z_t$) concatenated with encoded soft mask ($E(G(M))$) as input; receives gated conditioning vector ($c$) via cross-attention layers

- **Critical path:**
  1. Data Prep: Create 3-channel mask and extract radiomic features from original mammogram
  2. Conditioning: Apply Gaussian blur to mask's lesion channel and encode it; compute gated feature vector from radiomic and geometric features
  3. Forward Diffusion: Encode mammogram to latent space and add noise to get $z_t$
  4. Denoising Step: UNet predicts noise component using noised latent, concatenated soft mask latent, and gated feature vector
  5. Loss & Update: Calculate mean squared error between predicted and actual noise; update UNet and Gated Fusion parameters

- **Design tradeoffs:**
  - Soft Mask Variance: Tradeoff between image quality (FID) and lesion control (Mass IoU); higher blur variance improves realism but degrades precise lesion shape adherence; paper selects σ=1.5 as compromise
  - Complexity of Gated Fusion: Uses complex gating mechanism instead of simple feature concatenation; adds parameters and computational overhead but shown necessary to effectively combine distinct feature modalities
  - Pre-trained vs. From Scratch: Fine-tuning Stable Diffusion is more data-efficient than training from scratch but may inherit biases or latent space limitations from natural image domain

- **Failure signatures:**
  - Abrupt Lesion Boundaries: Lesion appears as "sticker" pasted onto breast tissue; indicates soft mask conditioning not working or blur variance too low
  - Loss of Lesion Control: Generated mammogram is realistic but lacks lesion or has it wrong place/shape; points to failure in soft mask concatenation or fundamental issue with conditioning
  - Unrealistic Texture: Lesion looks real but lacks clinically meaningful texture; suggests radiomic/feature conditioning branch failing or gradient being ignored by UNet

- **First 3 experiments:**
  1. Ablation on Soft Mask Blur: Train model with no blur, then increasing blur variance (σ=1.0, 1.5, 2.0, 2.5); evaluate FID and Mass IoU to confirm tradeoff and select optimal setting
  2. Ablation on Conditioning Branch: Train three models: (1) baseline (soft mask only), (2) + lesion control branch with simple feature concatenation, (3) + full Gated Fusion branch; compare Mass IoU and FID to measure precise contribution of gating mechanism
  3. Downstream Task Evaluation (Data Augmentation): Train classifier (e.g., benign vs. malignant) on VinDr-Mammo with and without augmentation using synthesized images from GCDM model; compare classification metrics (Accuracy, AUC) to demonstrate clinical utility

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the inverse relationship between image realism (FID) and lesion boundary precision (Mass IoU) induced by soft mask variance be decoupled?
- Basis in paper: [explicit] Section 4.4 notes that increasing soft label variance improves image quality (lower FID) but degrades mass control (lower Mass IoU), forcing a compromise at variance 1.5.
- Why unresolved: Current Gaussian blur operation globally affects mask; model lacks adaptive mechanism to smooth tissue transitions without sacrificing sharpness of lesion boundary itself.
- What evidence would resolve it: Modified conditioning scheme achieving both minimal FID (e.g., < 22.0) and maximal Mass IoU (e.g., > 86.0) simultaneously, without manual variance tuning.

### Open Question 2
- Question: Does high fidelity of synthesized lesions translate into improved performance for downstream lesion detection (localization) tasks?
- Basis in paper: [inferred] While Appendix B demonstrates improved downstream performance for *classification* (benign vs. malignant), it does not evaluate whether precise lesion geometry aids object detection or segmentation models.
- Why unresolved: High Mass IoU suggests geometric accuracy, but unverified if synthetic samples effectively train models to *find* lesions in diverse, unseen clinical contexts.
- What evidence would resolve it: Study measuring mean Average Precision (mAP) of detection model trained on GCDM-synthesized data and tested on real mammograms.

### Open Question 3
- Question: Can reliance on hand-crafted radiomic features be replaced by end-to-end learned representations without losing clinical validity?
- Basis in paper: [inferred] Section 3.3 details extraction of 67 dimensions of hand-crafted features (shape, histogram, etc.) using PyRadiomics.
- Why unresolved: Hand-crafted features may limit model's ability to capture complex, high-dimensional textural nuances that deep features could represent, potentially capping diversity of generated lesions.
- What evidence would resolve it: Comparative experiments showing learned latent feature vector (e.g., from pre-trained encoder) provides equal or superior diversity and clinical realism compared to current PyRadiomics vector.

## Limitations
- Validated only on single-center VinDr-Mammo dataset; performance on multi-center, diverse populations remains untested
- High dependence on accurate lesion masks and bounding boxes; errors in automatic mask generation (MedSAM) propagate through feature extraction
- Soft mask mechanism creates tradeoff between anatomical realism and precise lesion shape control that requires manual tuning
- Focus limited to mass lesions; does not demonstrate capability for generating other mammographic abnormalities like microcalcifications

## Confidence
- **High Confidence**: Core methodology (fine-tuning Stable Diffusion with soft mask and gated conditioning) is sound and well-documented; reported quantitative results are internally consistent with stated ablation studies
- **Medium Confidence**: Clinical utility demonstration (data augmentation for classification) is promising but limited to single downstream task; claim of being "superior" to state-of-the-art based on comparison with only one baseline (RCM)
- **Low Confidence**: Model's ability to generate diverse, clinically realistic lesions across all mammographic subtypes is not demonstrated; focus on mass lesions represents significant limitation for general mammography synthesis tool

## Next Checks
1. **Multi-Center Generalization Study**: Evaluate GCDM on held-out multi-center dataset (e.g., INbreast or CBIS-DDSM) to assess robustness to variations in imaging equipment, protocols, and patient demographics
2. **Downstream Task Ablation**: Conduct comprehensive study of data augmentation effectiveness across multiple classification tasks (BI-RADS density, benign vs. malignant, mass vs. calcification); compare GCDM-generated data against other augmentation strategies to quantify unique contribution
3. **Lesion Diversity and Realism Assessment**: Perform radiologist-in-the-loop study to evaluate clinical realism and diversity of generated lesions; use Turing-test style setup where experts distinguish real from synthetic mammograms; analyze failure cases to identify systematic biases in generation process