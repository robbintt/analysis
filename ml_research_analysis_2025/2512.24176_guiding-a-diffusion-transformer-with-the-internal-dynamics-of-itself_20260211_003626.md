---
ver: rpa2
title: Guiding a Diffusion Transformer with the Internal Dynamics of Itself
arxiv_id: '2512.24176'
source_url: https://arxiv.org/abs/2512.24176
tags:
- training
- guidance
- diffusion
- arxiv
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Internal Guidance (IG), a simple yet effective
  strategy for improving both the training efficiency and generation quality of diffusion
  models. The method adds auxiliary supervision to intermediate layers during training,
  enabling the model to produce weaker generative outputs from mid-level representations.
---

# Guiding a Diffusion Transformer with the Internal Dynamics of Itself

## Quick Facts
- arXiv ID: 2512.24176
- Source URL: https://arxiv.org/abs/2512.24176
- Authors: Xingyu Zhou, Qifan li, Xiaobin Hu, Hai Chen, Shuhang Gu
- Reference count: 40
- Primary result: InternalGuidance achieves comparable performance to Autoguidance without extra sampling steps, with improved training efficiency across multiple Diffusion Transformer models.

## Executive Summary
This paper introduces InternalGuidance (IG), a simple yet effective strategy for improving both the training efficiency and generation quality of diffusion models. The method adds auxiliary supervision to intermediate layers during training, enabling the model to produce weaker generative outputs from mid-level representations. During sampling, it uses the relationship between intermediate and deep outputs to guide the final generation, achieving performance comparable to Autoguidance without extra sampling steps or degradation strategies.

IG significantly improves training efficiency and generation quality across multiple baselines. On ImageNet 256×256, SiT-XL/2+IG achieves FID=5.31 at 80 epochs and FID=1.75 at 800 epochs, outperforming vanilla SiT-XL trained for 1400 epochs. LightningDiT-XL/1+IG achieves FID=1.34 at 680 epochs, a large margin over prior methods. Combined with classifier-free guidance, LightningDiT-XL/1+IG reaches state-of-the-art FID=1.19.

## Method Summary
InternalGuidance (IG) introduces auxiliary supervision to intermediate layers during diffusion model training. The method adds a small-scale linear head to specific intermediate layers that predicts the noise component at those stages. During training, the model minimizes both the standard denoising loss on the final output and an auxiliary loss on intermediate outputs. During sampling, IG uses the difference between intermediate and final predictions to guide the generation process, similar to Autoguidance but using the model's own internal representations rather than repeated sampling.

## Key Results
- SiT-XL/2+IG achieves FID=5.31 at 80 epochs and FID=1.75 at 800 epochs on ImageNet 256×256, outperforming vanilla SiT-XL trained for 1400 epochs
- LightningDiT-XL/1+IG achieves FID=1.34 at 680 epochs, significantly outperforming previous methods
- Combined with classifier-free guidance, LightningDiT-XL/1+IG reaches state-of-the-art FID=1.19 on ImageNet 256×256

## Why This Works (Mechanism)
InternalGuidance works by leveraging the hierarchical nature of Diffusion Transformers. By training intermediate layers to produce meaningful intermediate outputs, the model learns representations that capture different levels of abstraction. During sampling, these intermediate predictions provide additional information about the generation process, allowing for more controlled and efficient sampling without requiring multiple forward passes like Autoguidance.

## Foundational Learning
- **Diffusion Models**: Generative models that learn to denoise data through a Markov chain process - needed to understand the base architecture being modified
- **Classifier-Free Guidance**: A technique that improves sample quality by interpolating between conditional and unconditional predictions - needed to understand how IG relates to existing guidance methods
- **Diffusion Transformers**: Transformer-based architectures adapted for diffusion modeling - needed to understand the specific model family being used
- **Intermediate Supervision**: The concept of training auxiliary heads on intermediate layers - needed to understand the core innovation
- **Noise Schedules**: The scheduling of noise levels during diffusion sampling - needed to understand the sampling process

## Architecture Onboarding

Component map: Input -> DiT Backbone -> Final Output + Intermediate Outputs -> Guidance Module -> Final Output

Critical path: The critical path involves the DiT backbone processing input noise through multiple attention blocks, with intermediate linear heads extracting representations at specific layers, and the guidance module combining intermediate and final predictions.

Design tradeoffs: The main tradeoff is between training complexity (adding auxiliary supervision) and sampling efficiency (avoiding multiple forward passes). The choice of which intermediate layers to supervise affects both training stability and sampling quality.

Failure signatures: If IG is applied to wrong layers (too deep), it interferes with training of deep layer outputs. If guidance intervals are incorrectly set, performance degrades. Poor hyperparameter tuning for the auxiliary loss weight can destabilize training.

First experiments:
1. Test auxiliary supervision on different intermediate layers (layer 2, 4, 6, 8, 10) to find optimal position
2. Validate guidance interval effects by testing high-noise vs low-noise application ranges
3. Compare training efficiency by measuring FID scores at different epoch counts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the IG-inspired training acceleration method, which incorporates gradient differences between final and intermediate outputs into the training objective, achieve performance comparable to or better than IG applied during sampling, and what is the optimal formulation of this loss?
- Basis in paper: Section 4.3: "Can the effect of this IG be replicated during the training process, so as to achieve the goal of training acceleration? [...] Due to the flexibility and tunability of IG in generating images during the reasoning process, we continued to use IG in subsequent large-scale experiments."
- Why unresolved: The authors propose a preliminary training loss (Equation 7) that shows promise on SiT-B/2, but do not validate it at scale or optimize the formulation.
- What evidence would resolve it: Large-scale experiments (SiT-XL/2, LightningDiT-XL/1) comparing the training-acceleration loss against sampling-based IG, with ablations on hyperparameter ω.

### Open Question 2
- Question: Why does IG require the opposite guidance interval to CFG (high/mid-noise rather than low-noise ranges), and can this behavior be predicted theoretically?
- Basis in paper: Section 4.2: "For our proposed IG with the guidance interval, we observed the opposite phenomenon: the internal guidance does not need to be applied in the low-noise range, but applied in the high-noise and middle-noise ranges. This is somewhat contrary to the conclusion of guidance interval used in CFG."
- Why unresolved: The paper only documents the empirical observation without providing theoretical justification for why IG and CFG exhibit opposite noise-level dependencies.
- What evidence would resolve it: Theoretical analysis connecting intermediate layer dynamics to noise-level behavior, or systematic ablation across noise schedules.

### Open Question 3
- Question: Why does auxiliary supervision on early layers improve convergence while late-layer or multi-layer supervision fails to help, and what determines the optimal layer position?
- Basis in paper: Section 5.2: "We hypothesize that it interferes with the training of the deep layer's output" - the authors provide only a hypothesis for why layer 2-4 works but layers 6-10 or multiple layers do not.
- Why unresolved: The ablation shows clear positional dependence but offers no mechanistic explanation for why gradients from early intermediate layers are beneficial while later ones are not.
- What evidence would resolve it: Analysis of gradient flow dynamics, interference patterns between intermediate and final objectives, or systematic study across architectures and depths.

## Limitations
- Performance and effectiveness appear heavily dependent on specific Diffusion Transformer architectures, with unclear generalization to other model types
- Limited evaluation to class-conditional ImageNet, with unknown performance on text-to-image or video generation tasks
- Lack of comprehensive qualitative analysis comparing sample diversity and fidelity against Autoguidance

## Confidence
- **High Confidence**: The quantitative improvements in FID scores for tested DiT models and datasets are well-supported by provided results
- **Medium Confidence**: The claim of comparable performance to Autoguidance is reasonable based on metrics, but qualitative analysis is lacking
- **Low Confidence**: Generalization to other architectures, domains, and long-term stability of IG-trained models are uncertain

## Next Checks
1. **Cross-Architecture Validation**: Test InternalGuidance on U-Net-based diffusion models and other generative architectures to assess broader applicability
2. **Qualitative Analysis**: Conduct detailed user studies or perceptual evaluations to compare diversity and fidelity of samples generated with IG versus Autoguidance
3. **Robustness and Overfitting Analysis**: Investigate whether models trained with IG show signs of overfitting or reduced robustness to perturbations compared to standard training methods