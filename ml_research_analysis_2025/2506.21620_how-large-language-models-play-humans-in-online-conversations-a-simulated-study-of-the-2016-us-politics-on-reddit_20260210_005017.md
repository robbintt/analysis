---
ver: rpa2
title: 'How Large Language Models play humans in online conversations: a simulated
  study of the 2016 US politics on Reddit'
arxiv_id: '2506.21620'
source_url: https://arxiv.org/abs/2506.21620
tags:
- user
- comments
- history
- real
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated the ability of GPT-4 to simulate user-generated
  content in politically charged Reddit discussions during the 2016 US presidential
  election. Three experimental scenarios tested GPT-4's performance in impersonating
  real users, generating supportive content, and producing dissenting content, using
  real conversation threads from r/TheDonald and r/HillaryClinton.
---

# How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit

## Quick Facts
- arXiv ID: 2506.21620
- Source URL: https://arxiv.org/abs/2506.21620
- Reference count: 40
- GPT-4 generates realistic comments in political discussions but shows bias toward consensus over dissent

## Executive Summary
This study investigates how GPT-4 simulates user-generated content in politically charged Reddit discussions during the 2016 US presidential election. Using real conversation threads from r/The_Donald and r/HillaryClinton, the researchers conducted three experimental scenarios: impersonating real users, generating supportive content, and producing dissenting content. The analysis compared generated comments against real user contributions across political alignment, sentiment, and violence content. Results reveal GPT-4 can produce realistic comments that are hard to distinguish from human content by manual inspection, but consistently favors consensus over dissent even when prompted to generate opposing views. Generated content showed distinct semantic footprints when analyzed using embeddings, suggesting measurable differences between AI and human-generated political discourse.

## Method Summary
The researchers selected 50 political discussion threads from Reddit's r/The_Donald and r/HillaryClinton subreddits during the 2016 US election. They used GPT-4 to generate synthetic comments in three scenarios: impersonating users, generating supportive content, and creating dissenting content. The model was prompted with specific instructions for each scenario, using the original conversation context. Generated comments were compared against real user comments using manual inspection by three annotators and automated analysis using semantic embeddings. The study measured political alignment, sentiment, and violence content in both real and synthetic comments. Analysis included statistical comparison of these metrics and projection of comments into semantic space to identify patterns distinguishing human from AI-generated content.

## Key Results
- GPT-4 successfully generated realistic comments that were difficult to distinguish from real user content through manual inspection
- Generated content consistently showed bias toward consensus rather than dissent, even when prompted to generate opposing views
- Semantic embedding analysis revealed clear separation between human and AI-generated comments, despite their similar surface-level characteristics

## Why This Works (Mechanism)
GPT-4's ability to generate realistic political discourse stems from its training on diverse internet text, including political discussions. The model leverages its understanding of conversational context, political terminology, and rhetorical patterns to produce contextually appropriate responses. However, the observed bias toward consensus likely results from the model's alignment training, which emphasizes helpful and cooperative responses over confrontational or dissenting ones. This "helpful assistant" orientation may override explicit instructions to generate opposing viewpoints, revealing a fundamental tension between the model's design goals and its ability to authentically simulate diverse political perspectives.

## Foundational Learning
- **Political discourse analysis**: Understanding how political conversations unfold online is essential for evaluating AI's ability to simulate them; quick check involves comparing generated content against established discourse patterns.
- **Sentiment analysis techniques**: Required for measuring emotional tone in political discussions; quick check involves validating sentiment scores against human annotations.
- **Semantic embedding methods**: Critical for capturing meaning beyond surface text; quick check involves confirming embedding quality through similarity measures.
- **Reddit API and data extraction**: Necessary for obtaining authentic political discussion data; quick check involves verifying thread completeness and metadata accuracy.
- **LLM prompting strategies**: Essential for controlling output characteristics; quick check involves testing prompt variations for consistency.
- **Statistical comparison methods**: Required for quantifying differences between human and AI-generated content; quick check involves running significance tests on key metrics.

## Architecture Onboarding
- **Component map**: Reddit API -> Data preprocessing -> GPT-4 prompting -> Comment generation -> Manual annotation -> Embedding analysis -> Statistical comparison
- **Critical path**: Data collection and preprocessing form the foundation, followed by prompt engineering, generation, and multi-layered analysis combining human judgment with automated semantic analysis
- **Design tradeoffs**: The study prioritizes ecological validity by using real discussion threads but sacrifices control over variables like user history and community context that might influence comment generation
- **Failure signatures**: If generated comments show obvious semantic drift, lack contextual awareness, or fail to maintain conversation coherence, this indicates prompt engineering or context window issues
- **3 first experiments**: 1) Test GPT-4 with varying context window lengths to optimize conversation continuity, 2) Experiment with different prompt phrasings to reduce consensus bias, 3) Compare embedding separation across multiple political topics to assess generalizability

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How do LLM-generated comments influence the trajectory of a multi-turn online discussion compared to human-authored content?
- Basis in paper: [explicit] The authors state the study is "limited to generating a synthetic text for only the last comment in a post branch, leaving space to explore what would happen if the LLM generated a series of comments in the discussion."
- Why unresolved: The current methodology is static, replacing a single comment rather than simulating continuous interaction.
- What evidence would resolve it: Agent-based simulations where LLMs engage in continuous, multi-turn dialogue within a community, analyzed for longitudinal shifts in sentiment or consensus.

### Open Question 2
- Question: Is the distinct semantic footprint of LLM-generated content generalizable to other contexts, languages, or models?
- Basis in paper: [explicit] The authors note "additional studies in different context would be needed to confirm that real users and bots can be distinguished by projecting their comments into an embedded space."
- Why unresolved: It is unclear if the observed separation in the embedding space is specific to GPT-4 and 2016 US political discourse on Reddit.
- What evidence would resolve it: Replicating the embedding analysis on diverse datasets (e.g., different social media platforms, non-English languages) using various open-source and proprietary models.

### Open Question 3
- Question: To what extent is the model's reluctance to generate dissent a product of "helpful assistant" alignment rather than an inability to formulate counter-arguments?
- Basis in paper: [inferred] The authors observe that GPT-4 "tends to create consensus more easily than dissent" and speculate this "may be explained by its designing purpose of creating a helpful assistant."
- Why unresolved: The study identifies the behavior (consensus preference) but does not isolate the specific mechanism (RLHF safety tuning vs. prompt adherence) driving it.
- What evidence would resolve it: Ablation studies comparing the dissent rates of standard RLHF-aligned models against base models or models prompted with specific debate-oriented personas.

## Limitations
- Study relies on simulated scenarios rather than real-world deployment of AI-generated content
- Analysis limited to two specific subreddits and one political event, restricting generalizability
- Cannot fully capture the complexity of human online interactions and community dynamics

## Confidence
- **Major claims**:
  - GPT-4 can generate realistic political comments: **Medium** (supported by manual inspection but contradicted by semantic analysis)
  - GPT-4 shows bias toward consensus over dissent: **Medium** (consistently observed but mechanism unclear)
  - AI and human content have distinct semantic footprints: **High** (well-supported by embedding analysis)

## Next Checks
1. Test GPT-4's behavior across multiple political events and different social media platforms to assess generalizability beyond the 2016 US election and Reddit.
2. Conduct blind studies with human evaluators to determine if semantic embedding separation correlates with human perception of AI-generated content authenticity.
3. Experiment with alternative prompting strategies and model fine-tuning to determine if GPT-4's consensus bias can be reduced or if it represents a fundamental limitation of current language models.