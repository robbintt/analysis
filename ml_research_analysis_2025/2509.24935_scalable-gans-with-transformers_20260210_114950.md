---
ver: rpa2
title: Scalable GANs with Transformers
arxiv_id: '2509.24935'
source_url: https://arxiv.org/abs/2509.24935
tags:
- training
- preprint
- generator
- arxiv
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the scalability of GANs by introducing
  a purely transformer-based architecture trained in the latent space of a VAE. The
  authors identify two main challenges when scaling GANs: underutilization of early
  generator layers and optimization instability.'
---

# Scalable GANs with Transformers

## Quick Facts
- arXiv ID: 2509.24935
- Source URL: https://arxiv.org/abs/2509.24935
- Reference count: 31
- Single-step ImageNet-256 FID of 2.96 in 40 epochs

## Executive Summary
This paper introduces GAT (Generative Adversarial Transformers), a purely transformer-based GAN architecture trained in VAE latent space. The authors identify two key scalability challenges: underutilization of early generator layers and optimization instability when scaling model width. They propose Multi-level Noise-perturbed image Guidance (MNG) to activate early layers through hierarchical noise supervision, and width-aware learning rate scaling to stabilize training across different model sizes. GAT achieves state-of-the-art single-step, class-conditional generation performance on ImageNet-256 with an FID of 2.96 in just 40 epochs.

## Method Summary
GAT operates in the latent space of a pre-trained Stable Diffusion VAE (8× downsampling) using pure ViT architectures for both generator and discriminator. The generator uses adaptive normalization modulated by style vectors from a mapping network, with K=4 intermediate outputs perturbed by exponentially decreasing noise levels (MNG). The discriminator incorporates representation alignment to DINOv2 features (REPA). Training uses relativistic loss with approximated gradient penalty, AdamW optimizer, and width-aware learning rate scaling where η_adapt = η_base × (C_base / C_model).

## Key Results
- GAT-XL/2 achieves FID-50K of 2.96 on ImageNet-256 in just 40 epochs (6× fewer than strong baselines)
- MNG activates early generator layers, increasing LPIPS contribution from ~0.2 to ~0.6
- Width-aware learning rate scaling stabilizes training across model capacities (S through XL)
- REPA improves discriminator representation quality and translates to better generator performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-level Noise-perturbed image Guidance (MNG) activates early generator layers that would otherwise remain underutilized.
- Mechanism: Generator produces K intermediate outputs at uniformly spaced layers. Each output is perturbed with Gaussian noise at decreasing strengths, creating coarse-to-fine supervision. Early layers learn to match heavily noised targets, later layers match cleaner targets.
- Core assumption: Early layers in vanilla transformer GANs receive insufficient gradient signal because discriminator only provides end-to-end supervision.
- Evidence anchors:
  - [abstract]: "underutilization of early generator layers... propose Multi-level Noise-perturbed image Guidance (MNG) to activate early layers through hierarchical noise supervision"
  - [section 2.3, Fig. 4b]: LPIPS analysis shows early blocks have ~0.2 contribution without MNG vs. ~0.6 with MNG
- Break condition: If early-layer gradient norms remain low during training despite MNG, or if LPIPS contribution curves remain flat.

### Mechanism 2
- Claim: Width-aware learning rate scaling stabilizes training across model capacities by maintaining consistent update magnitudes.
- Mechanism: When layer inputs are normalized to unit variance, expected squared norm grows linearly with channel count C. Learning rate scales as η_adapt = η_base × (C_base / C_model) to keep update magnitude constant.
- Core assumption: GAN training instability at scale stems from amplified output changes per optimization step, not from architectural signal propagation issues.
- Evidence anchors:
  - [abstract]: "width-aware learning rate adjustment to stabilize training across different model sizes"
  - [section 2.4, Fig. 5b]: Cross-check experiment shows GAT-B/2 with GAT-S/2's learning rate diverges
- Break condition: If training diverges at any scale despite adaptive LR, or if LR sensitivity doesn't correlate with width.

### Mechanism 3
- Claim: Aligning discriminator features to Vision Foundation Models (VFM) improves generator quality through richer feedback signals.
- Mechanism: Discriminator's penultimate layer tokens are aligned to DINOv2 features via cosine similarity loss (only on real data). This is added to discriminator objective with λ_REPA = 1.
- Core assumption: Better discriminator representations translate to more informative gradients for the generator, even though generator itself isn't directly aligned.
- Evidence anchors:
  - [section 2.5, Fig. 5c]: Ablation shows FID-5K degrades from ~22 to ~39 without REPA
  - [corpus]: REPA (Yu et al. 2024) from diffusion literature validates VFM alignment benefits
- Break condition: If discriminator-VFM alignment (CKNNA metric) doesn't increase during training, or if generator FID doesn't improve despite increasing alignment.

## Foundational Learning

- Concept: **Vision Transformer (ViT) basics — patch embedding, positional encodings, [CLS] token**
  - Why needed here: GAT uses pure ViT for both G and D; understanding token sequences, attention patterns, and how [CLS] aggregates information is essential for debugging.
  - Quick check question: Can you explain why the generator removes the patchify layer and adds an unpatchify layer instead?

- Concept: **GAN training dynamics — two-player game, mode collapse, discriminator-generator balance**
  - Why needed here: The paper addresses GAN-specific instabilities (R1/R2 gradient penalties, relativistic loss); understanding why GANs are harder to scale than diffusion is foundational.
  - Quick check question: Why might widening a GAN cause divergence while the same widening works for diffusion models?

- Concept: **VAE latent spaces — compression factor, perceptual fidelity tradeoff**
  - Why needed here: GAT operates in SD-VAE latent space (8× downsampling, 32×32 for 256×256 images); understanding what's preserved vs. lost in latent space affects interpretation of FID scores and failure modes.
  - Quick check question: If generated latents decode to blurry images, is the problem in G or in the VAE decoder?

## Architecture Onboarding

- Component map:
  - Noise z → Mapping MLP → Style w → GAT blocks with w-modulated LayerNorm → K intermediate outputs → Noise perturbation (MNG) → Discriminator with REPA alignment → Adversarial loss + gradient penalty + REPA loss

- Critical path: Noise z → Mapping MLP → Style w → GAT blocks with w-modulated LayerNorm → K intermediate outputs → Noise perturbation (MNG) → Discriminator with REPA alignment → Adversarial loss + gradient penalty + REPA loss

- Design tradeoffs:
  - Latent-space training: Faster compute, but dependent on VAE quality; artifacts may come from VAE, not G
  - Pure ViT vs. hierarchical architectures: Simpler scaling, but requires MNG to compensate for lack of multi-scale structure
  - REPA on D only vs. G+D: Simplifies implementation (no VFM features from noise), but may limit representation transfer

- Failure signatures:
  - Early layers inactive: Check LPIPS contribution per block (Fig. 4b pattern); if early blocks <0.3, MNG may be misconfigured (check α schedule)
  - Training divergence at scale: Check if LR follows width-aware rule; if GAT-XL uses η > 1.5e-4, likely too high
  - FID plateau early: Check EMA decay (should be 0.999), check REPA loss weight, verify discriminator is learning (D loss shouldn't collapse to 0)
  - Mode collapse: Check gradient penalty strength (λ_aGP = 0.1), verify R1/R2 penalties are computed correctly with noise σ=0.01

- First 3 experiments:
  1. **Baseline sanity check**: Train GAT-S/2 for 20 epochs with and without MNG; verify FID gap (~15 vs. ~25 at 50K iterations) and visualize early-layer PCA features
  2. **LR scaling validation**: Train GAT-B/2 with GAT-S/2's LR (4e-4) and with adaptive LR (2e-4); confirm divergence vs. stable convergence (replicate Fig. 5b)
  3. **Ablation sweep**: Remove REPA, remove MNG, remove both; measure FID-5K at 10K, 30K, 50K iterations to quantify individual contributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can generation quality be further improved by explicitly strengthening the discriminator's representation learning capabilities?
- Basis in paper: [explicit] Section 3.4 states that "as the generative performance of G is tightly coupled with the representation learning ability of D, further strengthening discriminator representations may be a promising direction for future work."
- Why unresolved: While the paper uses VFM alignment (REPA), it does not explore architectural changes to the discriminator specifically designed to maximize representation learning beyond the standard ViT backbone.
- What evidence would resolve it: Ablation studies comparing different discriminator architectures or representation alignment objectives against the current VFM alignment baseline.

### Open Question 2
- Question: Does the reliance on a fixed, pre-trained VAE impose a hard upper bound on the perceptual fidelity of the generated images?
- Basis in paper: [inferred] The method operates entirely within the latent space of a pre-trained SD-VAE to manage computational costs. The paper does not analyze if the VAE's reconstruction error limits the high-frequency details GAT can synthesize.
- Why unresolved: A generator operating in a lossy latent space cannot produce details that the VAE decoder cannot reconstruct, potentially capping performance regardless of generator scale.
- What evidence would resolve it: Comparative experiments using tokenizers with different reconstruction fidelities (e.g., consistent VAE vs. standard VAE) to observe if FID improves solely from better latent space definition.

### Open Question 3
- Question: Can the stability of the proposed GAT framework be maintained when scaling to complex text-to-image generation tasks?
- Basis in paper: [inferred] The Introduction highlights text-to-image synthesis as a key driver of generative modeling progress, and Related Works mention large-scale GAN attempts, yet the experimental validation is restricted to class-conditional ImageNet.
- Why unresolved: Text-conditioning introduces significantly more complex data distributions and optimization landscapes than class-conditional generation, which may challenge the "width-aware" stability mechanisms proposed for ImageNet.
- What evidence would resolve it: Training GAT on large-scale text-image datasets (e.g., LAION) to evaluate if the scaling rules and MNG remain effective without extensive hyperparameter retuning.

## Limitations
- The method's performance depends on the quality of the pre-trained VAE, which may impose perceptual fidelity limitations
- REPA alignment is applied only to the discriminator, potentially limiting the transfer of representation learning benefits to the generator
- The paper doesn't explore whether direct generator alignment to VFMs would improve performance beyond discriminator-only alignment

## Confidence

**High confidence**: The width-aware learning rate scaling is mathematically grounded and validated through controlled cross-scale experiments. The VAE latent space approach and overall training recipe are reproducible.

**Medium confidence**: MNG's activation mechanism is supported by LPIPS and PCA visualizations, but the quantitative impact on final FID is not fully isolated from other improvements. REPA's alignment benefits are demonstrated but the indirect nature of the signal transfer limits confidence in the mechanism.

**Low confidence**: The paper doesn't address potential VAE-induced artifacts or limitations, and the single-step generation claim (1-NFE) conflates architectural efficiency with training methodology.

## Next Checks
1. **Early-layer contribution ablation**: Train GAT-S/2 with MNG disabled and perform LPIPS-based contribution analysis at multiple checkpoints to verify that early blocks show <0.3 contribution without MNG (targeting Fig. 4b pattern).
2. **LR scaling boundary test**: Train GAT-XL/2 with both width-aware LR (1.33e-4) and fixed LR (4e-4) to confirm the 3× width increase causes divergence only without adaptive scaling (replicating Fig. 5b cross-check).
3. **REPA mechanism isolation**: Implement REPA on both discriminator and generator (using VFM features from real data) to test whether direct generator alignment improves FID beyond discriminator-only alignment, validating the signal transfer hypothesis.