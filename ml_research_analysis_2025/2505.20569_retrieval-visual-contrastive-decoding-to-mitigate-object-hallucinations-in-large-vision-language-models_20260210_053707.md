---
ver: rpa2
title: Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in
  Large Vision-Language Models
arxiv_id: '2505.20569'
source_url: https://arxiv.org/abs/2505.20569
tags:
- image
- rvcd
- objects
- decoding
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RVCD (Retrieval Visual Contrastive Decoding) is a train-free decoding
  method that mitigates object hallucination in large vision-language models by leveraging
  negative and positive logits from explicitly retrieved single-concept images. The
  method retrieves AI-generated images representing objects detected or hallucinated
  by the model, then adjusts logits during decoding to suppress incorrect objects
  while preserving accurate ones.
---

# Retrieval Visual Contrastive Decoding to Mitigate Object Hallucinations in Large Vision-Language Models

## Quick Facts
- **arXiv ID**: 2505.20569
- **Source URL**: https://arxiv.org/abs/2505.20569
- **Reference count**: 28
- **Primary result**: RVCD achieves state-of-the-art performance in reducing object hallucinations in large vision-language models through retrieval-based contrastive decoding

## Executive Summary
Large vision-language models (LVLMs) frequently suffer from object hallucinations, generating captions that mention objects not present in input images. This paper introduces Retrieval Visual Contrastive Decoding (RVCD), a train-free decoding method that addresses this critical limitation by leveraging retrieved single-concept images to adjust model logits during inference. The method retrieves AI-generated images representing both detected and hallucinated objects, then applies contrastive decoding to suppress incorrect object mentions while preserving accurate ones.

RVCD demonstrates significant improvements across multiple benchmarks and model architectures, reducing CHAIR hallucination scores by up to 52% while maintaining caption quality. The approach requires no additional training, making it computationally efficient and broadly applicable to existing LVLMs. The method shows consistent performance improvements across LLaVA-1.5, MiniGPT-4, and mPLUG-Owl2 backbones, establishing RVCD as a practical solution for improving the reliability of vision-language systems.

## Method Summary
RVCD introduces a novel train-free decoding strategy that mitigates object hallucinations by leveraging retrieval-based contrastive learning during inference. The method operates by retrieving single-concept images from an external database, where each image represents either an object detected in the input or a hallucinated object predicted by the model. These retrieved images are then used to construct contrastive pairs that guide the decoding process. Specifically, negative logits from hallucinated objects are suppressed while positive logits from correctly detected objects are reinforced, creating a contrastive signal that steers the model away from hallucinatory outputs.

The approach is implemented as a decoding-time intervention without requiring any model retraining or fine-tuning. This makes RVCD computationally efficient and readily applicable to existing LVLM deployments. The method demonstrates effectiveness across multiple benchmark datasets and model architectures, showing particular strength in reducing object hallucination rates while preserving caption quality metrics such as BLEU scores.

## Key Results
- RVCD reduces CHAIR hallucination scores by up to 52% compared to baseline decoding methods
- On POPE evaluation, RVCD improves accuracy by up to 29% over existing decoding approaches
- The method maintains comparable BLEU scores for caption quality while significantly reducing hallucinations

## Why This Works (Mechanism)
RVCD works by introducing a contrastive decoding mechanism that leverages retrieved visual evidence to correct hallucinatory predictions. During the decoding process, the method retrieves single-concept images corresponding to both correctly detected and hallucinated objects. These retrieved images serve as contrastive examples that help the model distinguish between accurate and inaccurate object predictions.

The key mechanism involves adjusting the logits during decoding: negative logits associated with hallucinated objects are suppressed while positive logits from correctly identified objects are reinforced. This contrastive adjustment creates a decision boundary that helps the model avoid mentioning objects not present in the image. By operating at the decoding level rather than requiring model retraining, RVCD can correct hallucinations in real-time while preserving the model's ability to generate coherent and fluent captions.

## Foundational Learning

**Object Detection and Classification**: Why needed - To identify which objects are present or hallucinated in images. Quick check - Verify the model can accurately detect and classify objects in benchmark datasets.

**Contrastive Learning**: Why needed - To distinguish between correct and incorrect object predictions. Quick check - Ensure the retrieval system can find semantically relevant single-concept images.

**Vision-Language Alignment**: Why needed - To ensure retrieved visual information properly aligns with textual predictions. Quick check - Validate that retrieved images correspond to the objects being discussed in captions.

**Logit Adjustment**: Why needed - To modify model predictions during decoding without retraining. Quick check - Confirm that logit adjustments effectively suppress hallucinated objects while preserving correct ones.

## Architecture Onboarding

**Component Map**: Image input -> Object Detection -> Retrieval System -> Logit Adjustment -> Contrastive Decoding -> Caption Output

**Critical Path**: The critical path flows from object detection through the retrieval system to logit adjustment and final decoding. The retrieval system's quality directly impacts the effectiveness of the contrastive adjustments, making it the most critical component for performance.

**Design Tradeoffs**: The method trades off additional inference time (due to retrieval) against improved hallucination reduction. It prioritizes train-free operation over potentially more effective but training-intensive alternatives. The reliance on an external retrieval database introduces a dependency but enables broad applicability.

**Failure Signatures**: The method may fail when single-concept images are unavailable for rare or abstract concepts, when the retrieval system returns irrelevant images, or when logit adjustments overly suppress correct but uncertain predictions. Performance degradation is most likely with long-tail object categories.

**First Experiments**:
1. Benchmark RVCD against standard decoding methods on CHAIR and POPE datasets
2. Evaluate BLEU score preservation while measuring hallucination reduction
3. Test across different LVLM backbones (LLaVA-1.5, MiniGPT-4, mPLUG-Owl2) to verify architecture independence

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Reliance on external image retrieval systems may introduce latency and dependency on retrieval database quality
- Effectiveness depends on availability of appropriate single-concept images for retrieved objects
- Method focuses primarily on object hallucinations without addressing attribute or relationship hallucinations

## Confidence

**Effectiveness in reducing object hallucinations**: High confidence - Supported by consistent improvements across multiple benchmarks and model architectures with substantial percentage reductions in hallucination scores.

**Preservation of caption quality**: Medium confidence - While BLEU scores are maintained, this metric alone may not fully capture semantic accuracy and informativeness.

**Train-free efficiency**: High confidence - Clearly demonstrated with explicit comparisons showing no additional training requirements and minimal computational overhead.

## Next Checks
1. Conduct ablation studies to quantify individual contributions of negative and positive logit adjustments in the contrastive decoding process

2. Evaluate method performance on long-tail object categories and abstract concepts where single-concept images may be scarce

3. Test robustness across diverse image domains beyond current benchmark datasets to assess generalizability