---
ver: rpa2
title: Test-time Generalization for Physics through Neural Operator Splitting
arxiv_id: '2602.00884'
source_url: https://arxiv.org/abs/2602.00884
tags:
- operator
- neural
- splitting
- operators
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a test-time generalization method for physics-based
  neural operators that operates without modifying pretrained weights. The approach
  searches over compositions of operators learned during training to approximate out-of-distribution
  dynamics at test time, using operator splitting to implement the compositions.
---

# Test-time Generalization for Physics through Neural Operator Splitting

## Quick Facts
- arXiv ID: 2602.00884
- Source URL: https://arxiv.org/abs/2602.00884
- Reference count: 40
- Primary result: Beam search over trained operator compositions achieves 11× to 200× improvement over baseline DISCO approach for out-of-distribution physics generalization

## Executive Summary
This paper presents a test-time generalization method for neural operators in physics that operates without modifying pretrained weights. The approach searches over compositions of operators learned during training to approximate out-of-distribution dynamics at test time, using operator splitting to implement the compositions. Experiments on challenging out-of-distribution tasks including parameter extrapolation and novel combinations of physics phenomena demonstrate state-of-the-art zero-shot generalization performance, while also enabling parameter identification.

## Method Summary
The method introduces a test-time search strategy that composes pretrained neural operators to handle unseen physics scenarios. Rather than retraining or fine-tuning, the approach uses beam search to explore compositions of trained operators that can represent the target dynamics. Operator splitting provides the mathematical framework for implementing these compositions. This enables generalization to scenarios not seen during training, including parameter extrapolation and novel physics combinations, while maintaining the efficiency of pretrained models.

## Key Results
- Beam search achieves 11× to 200× improvements over baseline DISCO approach
- Outperforms adaptive neural operator methods and transformer-based architectures on out-of-distribution tasks
- Enables parameter identification while maintaining strong generalization performance
- Inference remains 4× faster than solving full PDE systems despite beam search overhead

## Why This Works (Mechanism)
The method exploits the compositional nature of PDEs by recognizing that complex dynamics can often be expressed as combinations of simpler operators. By training individual operators on different physics components and then composing them at test time, the approach can represent dynamics that were not explicitly trained as whole systems. Operator splitting provides the mathematical foundation for implementing these compositions while preserving physical properties. Beam search efficiently explores the space of possible compositions to find those that best approximate the target dynamics.

## Foundational Learning
- **Neural operators**: Learn mappings between function spaces rather than finite-dimensional vectors, enabling them to handle continuous physical systems
  - Why needed: Traditional neural networks require discretization, limiting their ability to generalize across mesh resolutions
  - Quick check: Verify the method can handle different grid resolutions without retraining

- **Operator splitting**: Mathematical technique for decomposing complex operators into simpler components that can be applied sequentially
  - Why needed: Allows composition of pretrained operators while maintaining stability and physical properties
  - Quick check: Confirm that splitting preserves the essential characteristics of the original dynamics

- **Beam search**: Heuristic search algorithm that explores multiple promising paths simultaneously
  - Why needed: Efficiently explores the combinatorial space of operator compositions to find effective approximations
  - Quick check: Validate that beam search finds better compositions than greedy approaches

## Architecture Onboarding
- **Component map**: Pretrained operators -> Beam search composition selector -> Operator splitting implementation -> Test-time prediction
- **Critical path**: The beam search over operator compositions is the performance bottleneck and primary source of generalization
- **Design tradeoffs**: Speed vs accuracy in beam search width; comprehensiveness vs efficiency in operator library; generality vs specialization in training
- **Failure signatures**: Poor generalization when trained operators lack necessary components; degraded performance when beam search cannot find suitable compositions; instability when operator splitting fails to preserve physical properties
- **3 first experiments**: 1) Test on simple PDEs with known operator decompositions, 2) Compare beam search width sensitivity, 3) Evaluate performance on held-out parameter combinations

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead during inference from beam search, though still faster than full PDE solvers
- Assumes trained operators contain sufficient information to reconstruct unseen dynamics through composition
- Evaluation focuses primarily on advection-diffusion-reaction and wave-type equations, leaving generalizability to other physical systems uncertain

## Confidence
- High confidence in core methodology and reported performance improvements on tested tasks
- Medium confidence in general applicability to arbitrary PDE systems beyond evaluated examples
- Medium confidence in computational efficiency claims relative to baseline solvers

## Next Checks
1. Test the method on PDEs with different mathematical structures (e.g., Navier-Stokes, elasticity) to assess generalizability beyond advection-diffusion-reaction and wave equations
2. Compare beam search parameter sensitivity and runtime scaling on larger domain problems (e.g., 3D simulations) to validate claimed efficiency advantages
3. Conduct ablation studies removing operator splitting to isolate its contribution to observed performance gains