---
ver: rpa2
title: A Lightweight Federated Learning Approach for Privacy-Preserving Botnet Detection
  in IoT
arxiv_id: '2510.03513'
source_url: https://arxiv.org/abs/2510.03513
tags:
- learning
- node
- detection
- botnet
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study presents a lightweight federated learning framework for
  privacy-preserving botnet detection in IoT networks. By combining local training
  of decision tree models on IoT devices with ensemble aggregation at an edge node,
  the approach preserves data privacy while improving detection accuracy.
---

# A Lightweight Federated Learning Approach for Privacy-Preserving Botnet Detection in IoT

## Quick Facts
- arXiv ID: 2510.03513
- Source URL: https://arxiv.org/abs/2510.03513
- Reference count: 1
- One-line primary result: Decision tree ensemble via federated learning achieves up to 98.97% accuracy on N-BaIoT dataset while preserving privacy and minimizing communication overhead

## Executive Summary
This paper presents a federated learning framework for privacy-preserving botnet detection in IoT networks. The approach trains lightweight decision tree models locally on IoT devices and aggregates them at an edge node via majority voting, achieving high detection accuracy without sharing raw network data. Experiments on the N-BaIoT dataset demonstrate that federated ensemble models significantly outperform individually trained models while maintaining computational efficiency suitable for resource-constrained IoT devices.

## Method Summary
The method employs a distributed architecture where each IoT device trains a decision tree model on its local network traffic data, then transmits only the trained model parameters to an edge node. The edge node performs ensemble aggregation through equal-weight majority voting across all received models, creating a global classifier that captures diverse attack patterns. Local models are selected through weighted scoring (50% accuracy, 50% training time), with decision trees outperforming KNN, SVM, and logistic regression in the composite metric while maintaining training times under 60 seconds per node.

## Key Results
- Federated ensemble models achieve up to 98.97% accuracy, outperforming individual models that range from 69.14-81.52%
- Decision trees were selected as optimal local models, scoring 95% vs 65% for KNN and 54% for logistic regression
- Individual models show severe cross-node generalization gaps (e.g., 99.9% → 3.8% accuracy on Node 2), while ensemble improves consistency
- Training time remains under 60 seconds per node, suitable for resource-constrained IoT deployment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensemble aggregation of locally trained models via majority voting improves cross-node generalization compared to any single local model.
- Mechanism: Each IoT device trains independently on its local data distribution; the edge node aggregates predictions through equal-weight majority voting, capturing diverse attack pattern perspectives that individual models miss.
- Core assumption: Node data distributions vary enough that no single local model generalizes well, but share sufficient overlap in attack signatures for voting to improve predictions.
- Evidence anchors:
  - [abstract]: "federated ensemble models achieve up to 98.97% accuracy, outperforming individually trained models"
  - [section]: Table 3 shows individual node average accuracies ranging 69.14–81.52%, while ensemble accuracy reaches 85.72–98.97% across all nodes
  - [corpus]: Related work (arXiv:2510.23019) discusses personalized FL for heterogeneous IoT, suggesting node heterogeneity is a recognized challenge; however, direct ensemble-voting comparisons are limited in the corpus
- Break condition: If node distributions are completely non-overlapping (e.g., entirely different attack types per device with no shared features), majority voting provides no benefit and may degrade performance.

### Mechanism 2
- Claim: Privacy preservation is achieved by restricting all raw data processing to local devices and exchanging only trained model parameters.
- Mechanism: Decision tree models are trained locally on each IoT node; only the resulting classifier (tree structure and rules) is transmitted to the edge node for ensemble aggregation—no network traffic data leaves the device.
- Core assumption: The transmitted model parameters do not themselves leak sensitive information about local training data through model inversion or membership inference.
- Evidence anchors:
  - [abstract]: "enables distributed devices to collaboratively train models without exchanging raw data, thus maintaining user privacy"
  - [section]: "The edge node will receive and ensemble these local models... and then share the ensembled model... with IoT devices"
  - [corpus]: Multiple corpus papers reference privacy-preserving FL for IoT (arXiv:2502.10599), but also note gradient/model inversion attacks as concerns; explicit defenses are not detailed in this paper
- Break condition: Sophisticated model extraction or inversion attacks could potentially reconstruct training data patterns from shared model parameters.

### Mechanism 3
- Claim: Decision trees provide the optimal balance between detection accuracy and computational efficiency for resource-constrained IoT deployment.
- Mechanism: A weighted scoring formula (equal weights for normalized accuracy and training time) was used to compare DT, KNN, SVM, and Logistic Regression; DT achieved the highest composite score due to strong accuracy combined with fast training.
- Core assumption: The 50/50 weighting between accuracy and training time reflects actual deployment priorities; different operational constraints would yield different optimal model selections.
- Evidence anchors:
  - [section]: Figure 3 shows Decision Tree average score of 95% versus KNN 65% and Logistic Regression 54%
  - [section]: Table 2 demonstrates DT generalizes better across nodes than KNN (Table 1), which shows severe accuracy drops (e.g., 99.9% → 3.8% on Node 2)
  - [corpus]: arXiv:2511.03201 discusses quantized VAE-MLP models for similar resource constraints, indicating multiple lightweight approaches exist, but direct comparison to DT ensemble is not available
- Break condition: If inference latency (not training time) becomes the bottleneck, or if accuracy is weighted >70%, KNN or other models may become preferable despite longer training.

## Foundational Learning

- Concept: **Federated Learning Fundamentals**
  - Why needed here: The entire framework depends on understanding how distributed training differs from centralized approaches—specifically the local-training/global-aggregation cycle.
  - Quick check question: Can you explain why sending model updates instead of raw data preserves privacy, and what information could still leak?

- Concept: **Ensemble Methods (Majority Voting)**
  - Why needed here: The accuracy improvement from 69–81% (individual) to 85–98% (ensemble) hinges on understanding why combining weak diverse classifiers produces stronger predictions.
  - Quick check question: If three models vote and two were trained on similar data distributions while one is an outlier, what happens to ensemble performance?

- Concept: **Decision Tree Induction**
  - Why needed here: DT was selected as the optimal local model; understanding tree construction, pruning, and feature splitting is necessary for debugging and optimization.
  - Quick check question: Why might a decision tree overfit to local node data, and how does ensemble aggregation mitigate this?

## Architecture Onboarding

- Component map:
  - IoT Nodes -> Local DT training -> Model transmission -> Edge Node -> Ensemble aggregation -> Global model distribution -> IoT Nodes

- Critical path:
  1. Data collection and preprocessing on each IoT device (80/20 train-test split)
  2. Local DT model training (target: <60 seconds per node on constrained hardware)
  3. Model transmission to edge node
  4. Ensemble construction via majority voting aggregation
  5. Global ensemble model deployment back to nodes for inference

- Design tradeoffs:
  - Equal-weight voting (current) vs. performance-weighted voting (paper suggests this could improve accuracy further)
  - Training frequency vs. communication overhead (not explicitly tested; paper notes this as future work)
  - Model complexity vs. inference latency (only training time was benchmarked)

- Failure signatures:
  - **Overfitting to local data**: Model performs >99% on own-node test data but <10% on other nodes (observed with KNN in Table 1)
  - **Training timeout**: SVM exceeded 30 minutes on Node 1 data—indicates wrong model choice for resource constraints
  - **Ensemble degradation**: If majority of local models are weak or biased toward same distribution, voting provides no benefit

- First 3 experiments:
  1. **Baseline per-node training**: Train individual DT models on each of the 7 usable N-BaIoT device datasets; record training time and local test accuracy
  2. **Cross-node generalization test**: Apply each local model to all other nodes' test sets; build accuracy matrix (replicate Table 2) to quantify generalization gaps
  3. **Ensemble aggregation implementation**: Implement majority voting across all 7 local models; compare ensemble accuracy per node against individual model baselines (replicate Table 3 results of 85.72–98.97%)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can a formal threat model and robust aggregation defenses be integrated into the federated framework to mitigate poisoning attacks without compromising the lightweight nature of the system?
- Basis in paper: [explicit] The authors state in the Future Work section that they aim to focus on "defining a formal threat model and implementing defenses such as robust aggregation to enhance security."
- Why unresolved: The current study assumes honest participants or benign scenarios and does not evaluate the system's resilience against malicious nodes attempting to corrupt the global model.
- What evidence would resolve it: Performance metrics (accuracy, false positive rates) of the ensemble model when specific percentages of participating nodes are compromised or submit poisoned model updates.

### Open Question 2
- Question: How does the proposed federated framework perform under realistic network conditions involving heterogeneous devices, network latency, and packet loss?
- Basis in paper: [explicit] The paper notes that "Expanding the simulation setup to include more realistic conditions and device variability can improve practical relevance."
- Why unresolved: Experiments were conducted on high-resource machines (MacBook M1, Google Colab) rather than the resource-constrained IoT hardware (limited CPU/RAM) or unstable networks targeted by the solution.
- What evidence would resolve it: Evaluation results from deploying the framework on actual IoT hardware (e.g., Raspberry Pi or microcontrollers) within a network simulating real-world latency and bandwidth fluctuations.

### Open Question 3
- Question: Can deep learning baselines provide a superior trade-off between accuracy and communication overhead compared to the selected Decision Tree ensemble?
- Basis in paper: [explicit] The authors list "Exploring deep learning baselines and optimizing communication overhead" as a direction for future work.
- Why unresolved: The study intentionally excluded deep learning methods to maintain low computational costs, leaving the potential performance gains of lightweight neural networks (e.g., FCNNs or Autoencoders) in this specific federated context untested.
- What evidence would resolve it: A comparative analysis measuring training time, inference latency, and communication rounds for lightweight deep learning models versus the Decision Tree ensemble on the N-BaIoT dataset.

## Limitations

- The paper does not specify critical hyperparameters for decision tree (max_depth, min_samples_split) and KNN (n_neighbors, distance metric) models
- Equal-weight majority voting is used without exploring weighted voting schemes that could potentially improve ensemble accuracy
- Experiments were conducted on high-resource machines rather than actual resource-constrained IoT hardware, limiting practical validation

## Confidence

- High confidence: Federated learning framework design and privacy-preserving mechanism (local training with parameter-only exchange)
- Medium confidence: Decision tree selection methodology using weighted scoring formula
- Low confidence: Exact reproducibility due to missing hyperparameter details and dataset preprocessing specifics

## Next Checks

1. **Cross-node generalization experiment**: Systematically evaluate how each locally trained model performs on all other nodes' test sets to quantify distribution shifts and identify nodes with highest/lowest transferability
2. **Ensemble aggregation variants**: Implement and compare weighted voting schemes (by individual model accuracy or training data size) against the equal-weight baseline to identify potential accuracy improvements
3. **Privacy risk assessment**: Conduct model inversion attacks on shared tree structures to quantify actual privacy leakage and validate whether the parameter-only exchange approach meets privacy requirements under adversarial conditions