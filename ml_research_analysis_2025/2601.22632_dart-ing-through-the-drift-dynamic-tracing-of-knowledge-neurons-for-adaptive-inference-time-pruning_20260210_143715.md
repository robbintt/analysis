---
ver: rpa2
title: 'DART-ing Through the Drift: Dynamic Tracing of Knowledge Neurons for Adaptive
  Inference-Time Pruning'
arxiv_id: '2601.22632'
source_url: https://arxiv.org/abs/2601.22632
tags:
- pruning
- knowledge
- neurons
- attention
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DART addresses the problem of static pruning methods failing during
  long-horizon generation due to knowledge drift, where pruned neurons become essential
  as semantic context evolves. The core method monitors attention score distributional
  shifts to detect domain changes and dynamically updates neuron-level pruning masks
  at runtime, enabling adaptive context-based FFN sparsification.
---

# DART-ing Through the Drift: Dynamic Tracing of Knowledge Neurons for Adaptive Inference-Time Pruning

## Quick Facts
- arXiv ID: 2601.22632
- Source URL: https://arxiv.org/abs/2601.22632
- Reference count: 40
- Primary result: Dynamic pruning method that adapts to knowledge drift during long-horizon generation, achieving up to 14.5% accuracy gains on LLAMA-3.1-8B at 70% sparsity.

## Executive Summary
DART addresses the problem of static pruning methods failing during long-horizon generation due to knowledge drift, where pruned neurons become essential as semantic context evolves. The core method monitors attention score distributional shifts to detect domain changes and dynamically updates neuron-level pruning masks at runtime, enabling adaptive context-based FFN sparsification. Across ten benchmarks, DART achieves up to 14.5% accuracy gains on LLAMA-3.1-8B at 70% sparsity and up to 3× better ROUGE-L scores on summarization versus static-masked pruning, with performance comparable to dense models. The approach runs under 10MB memory for LLAMA-3.1-8B and adds only 0.1% FLOPs overhead.

## Method Summary
DART is a training-free runtime pruning framework that dynamically sparsifies FFN layers based on evolving semantic context. It uses cumulative importance scoring over a token window to identify context-conditioned neuron subsets, layer-wise sensitivity-aware sparsity allocation to protect critical layers, and knowledge drift detection via attention distribution monitoring to trigger mask updates when semantic context shifts are detected.

## Key Results
- Achieves up to 14.5% accuracy gains on LLAMA-3.1-8B at 70% FFN sparsity
- Improves ROUGE-L scores by up to 3× on summarization tasks versus static pruning
- Maintains performance comparable to dense models while using under 10MB memory
- Adds only 0.1% FLOPs overhead to inference

## Why This Works (Mechanism)

### Mechanism 1: Cumulative Importance Scoring for Context-Conditioned Neuron Selection
- Computes cumulative importance score $s_i$ for each neuron by summing squared activation magnitudes over a window of $\tau$ tokens
- Generates binary mask selecting top-k neurons with highest scores
- Core assumption: Neuron importance is better captured over a temporal window rather than instantaneous activation
- Evidence: [section 3.1] hypothesizes that only a subset of neurons is required for semantic fidelity at any generation step

### Mechanism 2: Layer-wise Sensitivity-Aware Sparsity Allocation
- Uses sensitivity score measuring both directional change (cosine similarity) and magnitude change in embeddings pre/post FFN
- Combined with depth-dependent factor to redistribute global pruning budget across layers
- Core assumption: Layers inducing larger embedding changes are semantically critical
- Evidence: [section 3.2] shows earlier layers consistently induce larger embedding changes than later layers

### Mechanism 3: Knowledge Drift Detection via Attention Distribution Monitoring
- Computes cosine similarity between mean attention vector over sliding window and reference centroid from mask-construction tokens
- Triggers re-pruning when alignment drops below threshold for consecutive windows
- Core assumption: Attention representations evolve within locally stable regions during coherent generation; significant divergence signals domain transition
- Evidence: [section 3.3] observes sharp decline in attention alignment between tokens 425-475 indicating semantic context transition

## Foundational Learning

- **FFNs as Knowledge Lookup Tables**
  - Why needed: DART targets FFN pruning based on premise that neurons encode factual/domain-specific knowledge
  - Quick check: Can you explain why an FFN neuron might activate strongly for "Italian cuisine" but not "quantum mechanics"?

- **Autoregressive Generation Dynamics**
  - Why needed: Knowledge drift arises because semantic context evolves as new tokens are generated
  - Quick check: Why can't a static mask computed from a prompt prefix support all downstream generation?

- **Attention-to-Knowledge Coupling**
  - Why needed: DART uses attention output distributions as proxy for detecting semantic shifts
  - Quick check: How does a drop in cosine similarity between current and reference attention vectors indicate a topic transition?

## Architecture Onboarding

- **Component map:**
  - Context-aware neuron selector -> Iterative sparsity redistributor -> Knowledge drift detector

- **Critical path:**
  1. Initialization: Use first $\tau$ tokens to compute neuron importance → generate layer-wise masks via Eq. (6)
  2. Runtime monitoring: For each new token window, compute attention centroid alignment against reference
  3. Drift trigger: If alignment < threshold for $c_0$ consecutive windows, recompute masks using current window
  4. Re-pruning: Reset counter, update reference centroid, generate new masks

- **Design tradeoffs:**
  - Window size $\tau$: Smaller = faster response, noisier scores; larger = stable but slower adaptation
  - Threshold scale $\delta$: Lower = more frequent updates; higher = risk of output degradation
  - Counter threshold $c_0$: Higher reduces spurious retriggers but delays recovery from genuine drift
  - Structured vs unstructured pruning: DART removes entire neurons (structured, hardware-friendly)

- **Failure signatures:**
  - Repetitive fragments or structural headings without semantic content
  - Cosine similarity trajectory trapped in narrow band after attempted topic switch
  - Irreversible drift: Releasing masks too late fails to recover coherent generation

- **First 3 experiments:**
  1. Single-domain baseline: Compare DART vs dense vs WANDA on zero-shot tasks to verify no catastrophic degradation at 70% FFN sparsity
  2. Multi-topic drift stress test: Use custom prompts requiring explicit topic switches; verify drift detection triggers at correct token positions
  3. Ablation on hyperparameters: Sweep $\tau \in \{5, 10, 20\}$, $\delta \in \{0.3, 0.5, 0.7\}$, $c_0 \in \{1, 2, 3\}$ on summarization benchmarks

## Open Questions the Paper Calls Out

- What are the actual wall-clock latency and throughput improvements of DART on standard hardware accelerators compared to dense models?
- Under what specific conditions does knowledge drift become irreversible, and can the detection threshold be dynamically adjusted to prevent this collapse?
- How sensitive is the DART framework to the hyperparameters of the knowledge drift detector, specifically the drift threshold ($\delta$) and the accumulation counter ($c_0$)?
- Can DART be effectively generalized to Mixture-of-Experts (MoE) architectures where FFNs are already dynamically sparsified via routing?

## Limitations
- Does not report wall-clock latency improvements, only FLOPs and memory access reductions
- Lacks rigorous validation that FFN neurons function as knowledge lookup tables
- Missing precise hyperparameter values for critical components like $\tau$, $T$, and $c_0$

## Confidence
- High confidence: Cumulative importance scoring over token window for context-conditioned pruning
- Medium confidence: Layer-wise sensitivity-aware sparsity allocation
- Medium confidence: Knowledge drift detection via attention distribution monitoring

## Next Checks
1. Hyperparameter Sensitivity Sweep: Reproduce summarization experiments while varying $\tau$, $\delta$, and $c_0$ to determine sensitivity to these parameters.
2. Drift Detection Signal Validation: Use custom prompts with known topic switches and plot attention cosine similarity trajectories to verify drift detection triggers correctly.
3. Layer-Wise Pruning Ratio Verification: After applying DART at 70% sparsity, extract and plot per-layer pruning ratios to confirm depth-aware protection of early layers.