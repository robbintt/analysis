---
ver: rpa2
title: 'Tab-Shapley: Identifying Top-k Tabular Data Quality Insights'
arxiv_id: '2501.06685'
source_url: https://arxiv.org/abs/2501.06685
tags:
- data
- attributes
- shapley
- anomalous
- insights
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying top-k data quality
  insights in tabular datasets to help users understand and locate anomalies. The
  proposed Tab-Shapley method uses cooperative game theory and Shapley values to quantify
  attribute contributions to data anomalies.
---

# Tab-Shapley: Identifying Top-k Tabular Data Quality Insights

## Quick Facts
- arXiv ID: 2501.06685
- Source URL: https://arxiv.org/abs/2501.06685
- Reference count: 6
- Primary result: Closed-form Shapley value computation for efficient tabular data quality insights

## Executive Summary
This paper presents Tab-Shapley, a method for identifying top-k data quality insights in tabular datasets. The approach uses cooperative game theory to quantify attribute contributions to anomalies, leveraging a closed-form Shapley value computation for efficiency. Experiments on 12 real-world datasets demonstrate Tab-Shapley outperforms unsupervised baselines and matches supervised methods in capturing anomalies, while effectively aggregating them into interpretable blocks.

## Method Summary
Tab-Shapley identifies data quality insights through a three-stage pipeline. First, an autoencoder (TabNet) is trained to label cells as potential anomalies based on reconstruction error. Second, a cooperative game is formulated where attributes are players and evidence sets define non-anomalous records; Shapley values are computed via a closed-form solution that avoids exponential complexity. Finally, the table is reordered by Shapley scores and top-k anomalous blocks are extracted using maximum subarray search on a scoring matrix that balances anomaly concentration with non-anomaly exclusion.

## Key Results
- Tab-Shapley outperforms unsupervised baseline DIFFI in capturing ground-truth anomalies
- Matches supervised SHAP method in anomaly detection correlation
- Shapley values strongly correlate with intuitive anomaly criteria (Pearson r > 0.75)
- Effectively aggregates scattered anomalies into interpretable blocks

## Why This Works (Mechanism)

### Mechanism 1
Cell-level reconstruction error from an autoencoder provides reliable anomaly signals. TabNet is trained with 50% feature masking, and during inference, each attribute is masked iteratively per record to compute reconstruction error. Record-level thresholding via clustering identifies anomalous records, and k-means clustering on per-record errors separates anomalous vs. non-anomalous attributes. Core assumption: reconstruction error correlates with anomalousness; attributes with higher relative error within anomalous records are anomaly sources.

### Mechanism 2
A cooperative game formulation admits a closed-form Shapley value. Players are attributes, evidence set Eaj contains records where attribute j is non-anomalous. Characteristic function Va(S) = |∪aj∈S Eaj|. Due to super-additivity, Shapley value simplifies to ϕa(aj) = ΣXi∈Eaj [1/|{k : Xi ∈ Eak}|]. Lower ϕa indicates higher anomaly likelihood. Core assumption: union-based game captures cumulative evidence of non-anomalous attributes.

### Mechanism 3
Reordering by ascending Shapley values concentrates anomalies in top-left for block extraction. After computing scores for attributes and records, the table is reordered to place low-score (anomalous) entities first. A scoring matrix S assigns decaying positive scores to PA cells and scaled negative scores to NA cells. Top-k insights are extracted via iterative maximum-sum submatrix search using Kadane's algorithm. Core assumption: anomalies naturally cluster after reordering.

## Foundational Learning

- **Shapley Values in Cooperative Game Theory**: Core mathematical object; understanding marginal contribution averaging over coalitions is essential to grasp why closed-form solution matters. Quick check: Given 3 players with evidence sets {R1}, {R1,R2}, {R2}, compute Shapley value for player 1.

- **Autoencoder Reconstruction for Anomaly Detection**: First stage of pipeline; understanding how masking and reconstruction error relates to anomaly detection is prerequisite. Quick check: Why would an autoencoder fail to detect a subtle value swap between correlated features?

- **Maximum Subarray / Kadane's Algorithm**: Final stage extracts insight blocks; understanding 2D maximum submatrix extension is needed for implementation. Quick check: How does the scoring matrix construction ensure that non-anomalous cells penalize block selection?

## Architecture Onboarding

- **Component map**: Labeling Module (TabNet → reconstruction errors → k-means thresholding → Lij labels) -> Shapley Module (evidence set construction → closed-form Shapley computation → attribute/record scores) -> Insight Extraction Module (reorder by scores → construct scoring matrix S → K iterations of Kadane max-sum submatrix)

- **Critical path**: Autoencoder training quality directly impacts label accuracy → label accuracy determines evidence set composition → evidence sets determine Shapley scores → scores determine reordering → reordering determines block coherence.

- **Design tradeoffs**:
  - α parameter: Higher α = stricter exclusion of NA cells from insights (smaller blocks, higher precision); lower α = more permissive (larger blocks, lower precision)
  - Labeling method: TabNet is not mandatory; other unsupervised detectors can produce Lij labels
  - Weighted vs. unweighted Shapley: Weighted variant uses reconstruction error magnitude; trades off interpretability for sensitivity

- **Failure signatures**:
  1. Scattered anomalies in reordered matrix: Indicates Shapley scores not capturing true anomaly sources; check label quality
  2. Empty or trivial insights (single cells): α too high or reconstruction errors poorly calibrated
  3. Insights dominated by NA cells: α too low; increase to enforce stricter anomaly concentration
  4. Computation blow-up: Check for bug in closed-form implementation; should be O(mn), not exponential

- **First 3 experiments**:
  1. Labeling sanity check: On a dataset with injected anomalies, verify Lij labels correctly identify injected cells with >80% precision
  2. Shapley correlation test: Replicate Table 2 correlation analysis between Shapley values and (a) evidence set size, (b) unique record count
  3. Block concentration benchmark: On Arrhythmia or Ionosphere, run Tab-Shapley and DIFFI, count ground-truth PA cells in top-left 4×4 block

## Open Questions the Paper Calls Out

### Open Question 1
How does Tab-Shapley perform in real-world industrial settings when evaluated directly by data engineers or domain experts? The authors explicitly state "Conducting a human evaluation of Tab-Shapley on a large-scale industrial dataset to assess its real-world effectiveness" as a primary avenue for future work. This remains unresolved because current evaluation relies on quantitative metrics rather than qualitative human assessment. Results from user studies involving data professionals would resolve this.

### Open Question 2
Can the Tab-Shapley framework be adapted to an online learning setting where user feedback on anomalous blocks refines the model? The conclusion proposes "Exploring the integration of human feedback... to develop an online and adaptive version of the Tab-Shapley algorithm that refines generated insights based on human-in-the-loop feedback." This is unresolved because the current method is a static batch process without mechanisms to update evidence sets or Shapley values dynamically based on user feedback.

### Open Question 3
How robust are the Shapley value rankings to noise or errors in the initial unsupervised cell-labeling step? The method relies heavily on the accuracy of initial "Potential Anomaly" (PA) labels generated by TabNet. This sensitivity analysis is not provided, leaving uncertainty about how mislabeling affects the cooperative game and resulting Shapley values. Experiments measuring stability when synthetic noise is injected into initial labels would resolve this.

## Limitations

- Autoencoder labeling quality is critical but unverified; no ablation studies test sensitivity to architecture choices or masking ratios
- Closed-form Shapley solution depends on union-based characteristic function which may oversimplify complex attribute dependencies
- Block-extraction approach assumes anomalies naturally cluster, but real-world anomalies could be scattered, limiting insight coherence

## Confidence

- **High Confidence**: The closed-form Shapley derivation is mathematically sound and well-specified
- **Medium Confidence**: Overall pipeline logic is coherent and produces promising experimental results, but critical components like autoencoder architecture are underspecified
- **Low Confidence**: Empirical validation is limited to 12 datasets with COPOD-derived ground truth, which may not generalize to all anomaly types or labeling methods

## Next Checks

1. **Ablation Study**: Systematically vary the TabNet architecture (masking ratio, encoder depth) and measure impact on labeling precision, Shapley correlation coefficients, and insight quality scores

2. **Real-world Application**: Apply Tab-Shapley to a production dataset with known data quality issues (e.g., financial transactions with known fraud patterns) and validate whether extracted insights align with domain expertise

3. **Scalability Benchmark**: Test Tab-Shapley on large-scale datasets (>1M records) to verify the claimed O(mn) efficiency and identify any hidden computational bottlenecks in the pipeline