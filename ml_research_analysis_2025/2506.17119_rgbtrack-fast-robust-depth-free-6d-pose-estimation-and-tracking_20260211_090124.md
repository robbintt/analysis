---
ver: rpa2
title: 'RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking'
arxiv_id: '2506.17119'
source_url: https://arxiv.org/abs/2506.17119
tags:
- pose
- object
- tracking
- depth
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RGBTrack, a robust framework for real-time
  6D pose estimation and tracking that operates solely on RGB data, eliminating the
  need for depth input. The method builds on the FoundationPose architecture, employing
  a novel binary search strategy combined with a render-and-compare mechanism to efficiently
  infer depth and generate pose hypotheses from true-scale CAD models.
---

# RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking

## Quick Facts
- **arXiv ID**: 2506.17119
- **Source URL**: https://arxiv.org/abs/2506.17119
- **Reference count**: 40
- **Primary result**: Achieves competitive accuracy and real-time performance (~22 FPS) for 6D pose estimation using only RGB data, with robustness to occlusions and rapid movements.

## Executive Summary
RGBTrack introduces a novel framework for real-time 6D pose estimation and tracking that operates exclusively on RGB data, eliminating the need for depth sensors. The method builds upon the FoundationPose architecture, employing a binary search strategy with render-and-compare to infer depth and generate pose hypotheses from true-scale CAD models. To maintain stable tracking in dynamic scenarios, RGBTrack integrates 2D object tracking (XMem) with a Kalman filter and a state machine for proactive pose recovery. A scale recovery module handles CAD models of unknown scale. Experiments demonstrate competitive accuracy and real-time performance (~22 FPS) while providing robustness to occlusions, rapid movements, and depth sensor unavailability.

## Method Summary
RGBTrack leverages FoundationPose as its base architecture, enhancing it with a binary search-based depth inference mechanism that operates without depth input. The method generates pose hypotheses by rendering CAD models at different depths and comparing them to the input RGB frame. To ensure stable tracking, it integrates XMem-based 2D tracking with a Kalman filter and a state machine that proactively recovers object poses during occlusions or rapid movements. A scale recovery module addresses the challenge of unknown CAD model scales. The approach achieves real-time performance while maintaining robustness across diverse tracking scenarios.

## Key Results
- Achieves ~22 FPS real-time performance on standard benchmark datasets
- Maintains competitive accuracy without requiring depth input
- Demonstrates robustness to occlusions, rapid movements, and depth sensor unavailability
- Successfully handles CAD models of unknown scale through integrated scale recovery

## Why This Works (Mechanism)
RGBTrack's effectiveness stems from its hybrid approach that combines geometric reasoning with learned features. The binary search depth inference mechanism efficiently narrows down the depth range by comparing rendered projections against the RGB input, avoiding the computational cost of dense depth estimation. The integration of 2D tracking (XMem) with Kalman filtering provides temporal stability and predictive capabilities that handle motion blur and occlusions. The state machine architecture ensures proactive recovery by switching between tracking, searching, and reinitialization modes based on confidence metrics. The scale recovery module enables practical deployment with arbitrary CAD models without requiring prior scale calibration.

## Foundational Learning

**FoundationPose Architecture**
- *Why needed*: Provides the base 2D-to-3D correspondence learning framework
- *Quick check*: Verify the model can establish accurate 2D-3D correspondences from single RGB images

**Binary Search Depth Inference**
- *Why needed*: Enables efficient depth estimation without depth sensors
- *Quick check*: Confirm depth accuracy improves monotonically with search iterations

**Render-and-Compare Mechanism**
- *Why needed*: Provides differentiable depth validation using CAD models
- *Quick check*: Ensure rendered projections align with observed keypoints at correct depths

**Kalman Filter Integration**
- *Why needed*: Provides temporal smoothing and motion prediction
- *Quick check*: Validate pose estimates remain stable during brief occlusions

**Scale Recovery Module**
- *Why needed*: Enables handling of CAD models with unknown absolute scale
- *Quick check*: Verify recovered scale remains consistent across frames

## Architecture Onboarding

**Component Map**
RGB Input -> FoundationPose Backbone -> 2D Keypoint Detection -> Binary Search Module -> Depth Inference -> Render-and-Compare -> Pose Hypothesis Generation -> Kalman Filter -> State Machine -> Final 6D Pose Output

**Critical Path**
The critical path for real-time performance is: RGB Input → FoundationPose Backbone → Binary Search Module → Render-and-Compare → Pose Output. This path must complete within ~45ms to achieve 22 FPS target.

**Design Tradeoffs**
- Binary search vs. direct regression: Binary search trades some accuracy for computational efficiency and determinism
- Kalman filter gain: Higher gains provide faster response but less noise immunity
- State machine complexity: More states provide better handling of edge cases but increase implementation complexity

**Failure Signatures**
- Persistent pose drift indicates Kalman filter parameters need tuning
- Flickering during occlusions suggests 2D tracker confidence thresholds are too low
- Scale instability indicates insufficient texture or poor CAD model quality

**First 3 Experiments**
1. Test binary search depth inference accuracy on objects with known depths
2. Evaluate 2D tracker (XMem) performance in isolation with ground truth poses
3. Measure Kalman filter effectiveness during synthetic occlusion scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- Performance may degrade with highly reflective or textureless objects where depth inference is difficult
- Dependency on FoundationPose architecture limits flexibility in architectural modifications
- Binary search strategy may struggle with objects having large depth variations or complex geometries
- Assumes relatively stable camera motion, which may not hold in highly dynamic environments

## Confidence
- Real-time performance claims: **High** - supported by FPS measurements on benchmarks
- Robustness to occlusions: **Medium** - validated on standard datasets but limited diversity
- Depth-free operation: **High** - core mechanism demonstrated and evaluated
- Scale recovery effectiveness: **Medium** - innovative but briefly evaluated
- Generalizability: **Medium** - primarily tested on controlled benchmark conditions

## Next Checks
1. Test RGBTrack on datasets with larger numbers of objects and more diverse object categories to assess scalability and generalization
2. Evaluate performance under varying lighting conditions and with objects exhibiting significant textureless or reflective surfaces to stress-test the depth inference mechanism
3. Conduct ablation studies to quantify the individual contributions of the 2D tracking, Kalman filter, and scale recovery components to overall performance