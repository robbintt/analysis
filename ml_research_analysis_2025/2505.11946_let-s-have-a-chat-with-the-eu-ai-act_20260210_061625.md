---
ver: rpa2
title: Let's have a chat with the EU AI Act
arxiv_id: '2505.11946'
source_url: https://arxiv.org/abs/2505.11946
tags:
- regulatory
- chatbot
- ethical
- standards
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an AI-driven chatbot for EU AI Act compliance
  assessment using Retrieval-Augmented Generation (RAG). The chatbot leverages both
  naive and graph-based RAG architectures to retrieve and interpret regulatory documents,
  enabling real-time, context-aware guidance for AI developers.
---

# Let's have a chat with the EU AI Act

## Quick Facts
- arXiv ID: 2505.11946
- Source URL: https://arxiv.org/abs/2505.11946
- Reference count: 24
- One-line primary result: AI chatbot for EU AI Act compliance using RAG, manual evaluation shows accurate semantic matching for straightforward queries, Graph RAG expected to improve complex multi-hop reasoning.

## Executive Summary
This paper presents an AI-driven chatbot for EU AI Act compliance assessment using Retrieval-Augmented Generation (RAG). The system leverages both naive and graph-based RAG architectures to retrieve and interpret regulatory documents, enabling real-time, context-aware guidance for AI developers. By grounding LLM responses in external regulatory documents, the approach aims to reduce hallucinations and improve domain-specific accuracy. Manual evaluation shows accurate semantic matching for straightforward queries, with graph RAG expected to improve performance for complex multi-hop questions.

## Method Summary
The method employs a Retrieval-Augmented Generation (RAG) framework to build an AI chatbot for EU AI Act compliance. Documents are processed with OCR for multimodal content (text, tables, visuals) and chunked for embedding. Naive RAG uses semantic similarity search in a vector database to retrieve relevant text, which is then used by an LLM to generate responses with source attribution. Graph RAG constructs knowledge graphs from extracted entities and relationships, using community detection to cluster related information and generate hierarchical summaries for global or local search based on query type. The system integrates public regulations and proprietary standards to provide comprehensive guidance.

## Key Results
- AI chatbot for EU AI Act compliance using RAG architecture
- Manual evaluation shows accurate semantic matching for straightforward queries
- Graph RAG expected to improve performance for complex multi-hop questions

## Why This Works (Mechanism)

### Mechanism 1
Grounding LLM responses in external regulatory documents via RAG is intended to reduce factual hallucinations and improve domain-specific accuracy. The system injects retrieved, context-specific segments from regulatory texts (e.g., EU AI Act) into the LLM's context window. By forcing the generation step to rely on retrieved evidence rather than parametric memory, the likelihood of fabricating legal requirements is reduced.

### Mechanism 2
Graph RAG is hypothesized to enable multi-hop reasoning and holistic summarization better than Naive RAG by structuring data as relationships rather than independent chunks. Instead of relying solely on vector similarity, Graph RAG extracts entities and relationships to build a knowledge graph. It uses community detection to cluster related information. For global queries, it summarizes these communities rather than individual chunks, allowing the model to synthesize themes across the entire document corpus.

### Mechanism 3
Multimodal document processing (including tables/visuals) preserves compliance-critical data often lost in text-only extraction. During the indexing phase, the system uses OCR and multimodal techniques to extract text, tables, and visual content. This ensures that regulatory requirements embedded in complex table structures (common in standards) are vectorized and retrievable.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: Standard LLMs lack up-to-date knowledge of specific laws (like the EU AI Act) and cannot cite sources. RAG bridges this by fetching relevant text before answering.
  - Quick check question: Can you explain why providing an LLM with a document excerpt reduces hallucinations compared to asking it to answer from pre-training?

- **Concept: Vector Embeddings & Semantic Search**
  - Why needed here: "Naive RAG" relies entirely on converting text to vectors. You must understand that "high risk" (query) must mathematically align with the legal definition of "high risk" (document) in vector space.
  - Quick check question: What happens to retrieval accuracy if the legal definition of a term changes but the embedding model is outdated?

- **Concept: Knowledge Graphs & Community Detection**
  - Why needed here: "Graph RAG" uses this to structure information. You need to know that this connects disparate entities (e.g., linking "biometric identification" to "remote identification" via a relationship edge) rather than just matching keywords.
  - Quick check question: In a Graph RAG, how does a "community summary" differ from a simple list of document chunks when answering a broad question?

## Architecture Onboarding

- **Component map:** Input: User Query (Text) -> Indexing Pipeline: Document Loader (OCR/Multimodal) -> Text Splitter -> (Naive: Embedding Store | Graph: Entity Extraction -> Graph Store) -> Retrieval Pipeline: Query Embedding -> (Naive: Vector Search | Graph: Local/Global Search) -> Context Assembly -> Generation: LLM (Context + Query) -> Response

- **Critical path:** The **Indexing Phase** (Page 3). If the OCR fails to parse tables correctly, or if the Graph RAG entity extraction prompts are poorly tuned, the entire retrieval logic is compromised. Garbage in, garbage out.

- **Design tradeoffs:**
  - **Naive RAG:** Lower compute cost, faster setup, effective for specific definitions. Fails at synthesizing cross-document themes.
  - **Graph RAG:** High indexing cost (requires LLM passes for extraction), complex maintenance. Superior for "holistic" questions (e.g., "Summarize the 5 most important topics").
  - **Hybrid approach:** The paper suggests moving toward Graph RAG, implying the need for a fallback or benchmark against Naive RAG.

- **Failure signatures:**
  - **Naive RAG Fragmentation:** The chatbot gives a correct definition but fails to mention a related obligation found in the next paragraph because the chunk was split poorly.
  - **Graph RAG Noise:** The chatbot includes irrelevant entities in the response because the community detection grouped unrelated legal concepts (e.g., merging "data governance" with "market surveillance" inappropriately).
  - **Lost Context:** The chatbot fails to answer questions about a specific table in the EU AI Act Annex because the multimodal parser flattened the structure.

- **First 3 experiments:**
  1. **Baseline Accuracy (Naive):** Run the "structured questionnaire" mentioned on Page 3. Compare chatbot answers against legal expert ground truth to establish a baseline error rate for Naive RAG.
  2. **Complex Query Benchmark (Graph vs. Naive):** Ask 5 "holistic" questions (e.g., "Summarize obligations for GPAI models") and measure which architecture provides the most comprehensive answer with less hallucination.
  3. **Table Retrieval Test:** specifically query a requirement located inside a complex table within the standards document to verify if the multimodal indexing preserved the context.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the implementation of Graph RAG yield a significant improvement in response quality over Naive RAG for regulatory queries?
- Basis: The authors state they will implement Graph RAG in the "next phase of the project" to "assess whether it can show a significant improvement compared to the naive RAG."
- Why unresolved: The current paper describes the architecture and expectations of Graph RAG but lacks comparative results as the implementation is planned for the future.
- What evidence would resolve it: A quantitative comparison of performance metrics (e.g., accuracy, comprehensiveness) between the Naive and Graph RAG models using the same EU AI Act knowledge base.

### Open Question 2
- Question: How closely does the chatbot's compliance guidance align with ground-truth assessments provided by human legal experts?
- Basis: Section III.B.4 outlines a "Manual evaluation of answer authenticity" involving a structured questionnaire where "legal experts will provide authoritative answers."
- Why unresolved: The paper details the proposed evaluation methodology but does not report the results of comparing the chatbot's outputs against the experts' answers.
- What evidence would resolve it: Statistical measurements of alignment or error rates between the chatbot's generated responses and the validated expert ground truth.

### Open Question 3
- Question: Does the integration of legal and ethical checklists as a complementary input mechanism enhance the context and precision of the chatbot's guidance?
- Basis: The authors identify "Checklists as a complementary input" as a key future development intended to enhance the chatbot's ability to provide "precise and contextually relevant guidance."
- Why unresolved: This feature is listed as a future direction and has not yet been implemented or tested in the current system.
- What evidence would resolve it: A user study or ablation test comparing the specificity and relevance of responses generated with versus without the checklist data.

## Limitations
- Absence of empirical performance data; methodology outlined but no quantitative results for either Naive or Graph RAG architectures
- Reliance on manual evaluation for straightforward queries without quantified accuracy rates
- Dependence on external regulatory documents introduces risks of retrieval failure and potential hallucination

## Confidence

- **High Confidence:** The general feasibility of using RAG for regulatory compliance assistance is well-supported by related work (e.g., FinSage for financial filings). The paper's problem framing and proposed solution architecture align with established RAG methodologies.
- **Medium Confidence:** The manual evaluation showing accurate semantic matching for straightforward queries is plausible but unverified. The claim about Graph RAG's superiority for complex queries is theoretically justified but lacks domain-specific evidence.
- **Low Confidence:** The practical impact of multimodal document processing on compliance accuracy and the specific performance gains of Graph RAG over Naive RAG for legal texts are not demonstrated.

## Next Checks

1. **Baseline Accuracy Assessment:** Conduct a questionnaire-based evaluation comparing the chatbot's answers to ground truth provided by legal experts for a set of straightforward regulatory queries. Measure precision, recall, and hallucination rates to establish a performance baseline.

2. **Complex Query Benchmark:** Design a test suite of multi-hop questions requiring cross-referencing of legal concepts (e.g., "What are the obligations for high-risk AI systems under the EU AI Act and related standards?"). Compare responses from Naive and Graph RAG architectures to assess comprehensiveness and coherence.

3. **Multimodal Table Retrieval Test:** Select specific compliance requirements embedded in complex tables within regulatory documents. Query the chatbot for these requirements and evaluate whether the multimodal indexing preserved the structural context and enabled accurate retrieval.