---
ver: rpa2
title: 'Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for fMRI-to-Image
  Reconstruction'
arxiv_id: '2510.22335'
source_url: https://arxiv.org/abs/2510.22335
tags:
- fmri
- visual
- reconstruction
- features
- mindhier
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of reconstructing visual stimuli
  from fMRI signals, a fundamental challenge at the intersection of machine learning
  and neuroscience. Current diffusion-based methods map fMRI activity to a single
  high-level embedding, which collapses hierarchical neural information and is misaligned
  with the stage-dependent demands of image reconstruction.
---

# Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for fMRI-to-Image Reconstruction

## Quick Facts
- arXiv ID: 2510.22335
- Source URL: https://arxiv.org/abs/2510.22335
- Authors: Xu Zhang; Ruijie Quan; Wenguan Wang; Yi Yang
- Reference count: 18
- Key outcome: MindHier achieves 96.4% CLIP score, 0.329 SwA V distance, and is 4.67x faster than diffusion baselines

## Executive Summary
This paper addresses fMRI-to-image reconstruction by proposing MindHier, a coarse-to-fine autoregressive framework that preserves hierarchical neural information. Unlike diffusion models that collapse multi-level fMRI embeddings into a single representation, MindHier maintains layer-wise correspondence between neural activity and visual features through its three key innovations: a Hierarchical fMRI Encoder, Hierarchy-to-Hierarchy Alignment, and Scale-Aware Neural Guidance. The method demonstrates superior semantic fidelity while achieving significant computational speedup over existing approaches.

## Method Summary
MindHier introduces a novel autoregressive approach to fMRI-to-image reconstruction that operates across multiple scales. The framework extracts multi-level neural embeddings from fMRI data, aligns these embeddings with corresponding CLIP feature layers, and injects them into a scale-aware autoregressive decoder. This hierarchical processing preserves the stage-dependent information flow required for accurate visual reconstruction, moving beyond the limitations of single-embedding diffusion methods.

## Key Results
- Achieves 96.4% CLIP score on semantic fidelity evaluation
- Reaches 0.329 SwA V distance for reconstruction quality
- Demonstrates 4.67x faster inference compared to diffusion-based baselines

## Why This Works (Mechanism)
MindHier succeeds by maintaining the hierarchical structure of both neural representations and visual features throughout the reconstruction process. By preserving multi-level embeddings rather than collapsing them into a single representation, the framework can better capture the stage-dependent information flow that mirrors how visual information is processed in the brain. The scale-aware injection of neural guidance ensures that coarse and fine visual details are reconstructed in alignment with their corresponding neural representations.

## Foundational Learning
- **Hierarchical neural encoding**: fMRI signals contain multi-scale information about visual processing; needed to capture both semantic and fine-grained details; quick check: examine layer activation patterns across different brain regions
- **CLIP feature alignment**: Matching neural embeddings to visual feature layers preserves semantic correspondence; needed for meaningful reconstruction guidance; quick check: verify layer-wise similarity metrics between neural and CLIP features
- **Autoregressive scaling**: Progressive refinement across scales enables coarse-to-fine reconstruction; needed to build up image details systematically; quick check: measure reconstruction quality at each scale level

## Architecture Onboarding
**Component map**: fMRI input -> Hierarchical Encoder -> Hierarchy-to-Hierarchy Alignment -> Scale-Aware Coarse-to-Fine Neural Guidance -> Autoregressive Decoder -> Image output

**Critical path**: The Hierarchical Encoder extracts multi-level embeddings, which are aligned to CLIP features through Hierarchy-to-Hierarchy Alignment. These aligned embeddings are then injected into the Scale-Aware Neural Guidance module, which controls the autoregressive decoder's progressive refinement across scales.

**Design tradeoffs**: The method trades computational efficiency for maintaining hierarchical information fidelity. While diffusion models collapse information for speed, MindHier preserves structure for accuracy, achieving both better results and faster inference through its targeted architecture.

**Failure signatures**: Poor reconstruction quality would manifest as either semantic misalignment (wrong objects/concepts) or structural artifacts (incorrect shapes/details). The hierarchical approach should show failures at specific scales rather than uniformly across all detail levels.

**Three first experiments**:
1. Test baseline performance without Hierarchy-to-Hierarchy Alignment to measure its contribution
2. Evaluate reconstruction quality at individual scale levels to verify coarse-to-fine progression
3. Compare semantic similarity metrics across different embedding extraction strategies

## Open Questions the Paper Calls Out
The paper does not explicitly identify open questions, but several implications emerge from the work: how well the hierarchical approach generalizes to different types of visual stimuli, whether the scale-aware guidance can be further optimized, and how the method performs with limited fMRI data or in cross-subject scenarios.

## Limitations
- Evaluation relies heavily on semantic similarity metrics (CLIP score, SwA V distance) rather than comprehensive visual quality assessment
- Claims of "more deterministic and stable results" lack quantitative validation through variance measurements or sensitivity analysis
- Computational speedup claims need clarification on hardware specifications and experimental conditions

## Confidence
- High confidence in the architectural innovations (Hierarchical fMRI Encoder, Hierarchy-to-Hierarchy Alignment, Scale-Aware Neural Guidance)
- Medium confidence in semantic reconstruction quality due to reliance on CLIP-based metrics
- Low confidence in stability/determinism claims without supporting quantitative evidence

## Next Checks
1. Conduct ablation studies isolating each component's contribution to final performance, particularly the Hierarchy-to-Hierarchy Alignment and Scale-Aware Neural Guidance mechanisms
2. Evaluate reconstruction consistency by computing pixel-wise variance across multiple runs with identical inputs and measuring structural similarity index (SSIM) distribution
3. Test cross-dataset generalization by evaluating MindHier on held-out subjects or external fMRI datasets to verify the method's robustness beyond the NSD dataset used in training