---
ver: rpa2
title: A Proposed Large Language Model-Based Smart Search for Archive System
arxiv_id: '2501.07024'
source_url: https://arxiv.org/abs/2501.07024
tags:
- system
- search
- data
- language
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the limitations of traditional keyword-based
  search in digital archives by proposing a Large Language Model (LLM)-based smart
  search framework. The core method employs a Retrieval-Augmented Generation (RAG)
  architecture that combines semantic search capabilities with natural language processing
  to handle multimodal data including text, images, audio, and video.
---

# A Proposed Large Language Model-Based Smart Search for Archive System

## Quick Facts
- arXiv ID: 2501.07024
- Source URL: https://arxiv.org/abs/2501.07024
- Authors: Ha Dung Nguyen; Thi-Hoang Anh Nguyen; Thanh Binh Nguyen
- Reference count: 20
- Key outcome: LLM-based RAG system achieves 80.56% precision with hybrid retrieval and multimodal query handling

## Executive Summary
This study addresses the limitations of traditional keyword-based search in digital archives by proposing a Large Language Model (LLM)-based smart search framework. The core method employs a Retrieval-Augmented Generation (RAG) architecture that combines semantic search capabilities with natural language processing to handle multimodal data including text, images, audio, and video. The framework integrates hybrid retrieval (combining BM25 and vector-based approaches), multilingual query handling, and response synthesis components. Key experiments demonstrated that Mistral 7B achieved the highest precision at 80.56% across various query types.

## Method Summary
The framework implements a RAG architecture using LlamaIndex with BGE-M3 embeddings stored in Pinecone (4 separate indices per file type). The pipeline includes a translator component for multilingual queries, a router query engine for media-specific retrieval, a hybrid retriever combining BM25 and vector search with alpha parameter tuning, post-processors including reranking and long-context reordering, and an LLM-based response synthesizer. The system processes 110 queries across 3 types (single, dual, and all filetypes) covering 10 topics. Four file types are supported: image, audio, video, and text document.

## Key Results
- Mistral 7B achieved the highest precision at 80.56% across various query types
- Hybrid retriever achieved optimal performance with alpha values of 0.5 or 0.8
- Ablation study revealed that removing the translator and query router reduced F1 scores by 18.99% and 38.73% respectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hybrid retrieval combining keyword-based (BM25) and vector-based methods improves search precision compared to either method alone.
- Mechanism: The alpha parameter (α) controls weighting between BM25 score (keyword precision) and embedding score (semantic similarity). Hybrid Score = α × Embedding Score + (1-α) × BM25 Score. At α=0.5–0.8, the system balances exact matching with contextual understanding.
- Core assumption: Users benefit from both lexical precision and semantic generalization in archival queries.
- Evidence anchors: [abstract], [section 3.2.3], [section 5.2], [corpus]
- Break condition: If archive content is highly uniform (e.g., all structured metadata with consistent terminology), pure vector search may suffice without BM25 overhead.

### Mechanism 2
- Claim: Query routing to specialized engines by file type improves retrieval relevance across multimodal archives.
- Mechanism: The Router Query Engine detects input type and directs queries to dedicated engines for images, audio, video, or documents. A summarization component refines output regardless of source media type.
- Core assumption: Different media types require specialized retrieval strategies; a single retriever cannot optimally handle all formats.
- Evidence anchors: [abstract], [section 3.2.2], [section 5.4], [corpus]
- Break condition: If archive contains predominantly one media type, routing overhead adds latency without benefit.

### Mechanism 3
- Claim: Translating non-textual data into textual representations enables unified semantic search across multimodal content.
- Mechanism: AI agents generate descriptions for images, transcribe audio, and summarize video content. All modalities become searchable text, indexed as vector embeddings.
- Core assumption: AI-generated descriptions capture sufficient semantic meaning for retrieval purposes; information loss from modality conversion is acceptable.
- Evidence anchors: [abstract], [section 3.1.1], [corpus]
- Break condition: If users require fine-grained visual/audio search (e.g., "find images with red logos"), text descriptions may be too coarse.

## Foundational Learning

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: The entire framework is built on RAG architecture, combining retrieval with LLM generation.
  - Quick check question: Can you explain why RAG avoids fine-tuning while enabling domain-specific responses?

- Concept: **Vector Embeddings and Similarity Search**
  - Why needed here: BGE-M3 embeddings stored in Pinecone enable semantic retrieval.
  - Quick check question: What does it mean that embeddings "capture semantic meaning" versus keyword matching?

- Concept: **BM25 Algorithm**
  - Why needed here: Hybrid retriever uses BM25 as the keyword-based component balanced against vector search.
  - Quick check question: How does BM25 differ from simple term frequency counting?

## Architecture Onboarding

- Component map: Translator -> Router Query Engine -> Hybrid Retriever -> Post-Processors -> Response Synthesizer
- Critical path: User query → Language detection/translation → Router selection → Hybrid retrieval → Post-processing → Response synthesis → Back-translation if needed
- Design tradeoffs:
  - α=0.5–0.8 optimizes accuracy but increases execution time vs. pure BM25
  - Post-processors add ~20 seconds without them but improve relevance
  - Multilingual support via translation introduces precision loss (Korean: 71.61% vs. English: 80.56%)
- Failure signatures:
  - Low hit rate (<60%) likely indicates router misconfiguration or missing indices
  - High latency with low precision suggests post-processor removal or poor α tuning
  - Multilingual queries with >15% precision drop indicate translation pipeline issues
- First 3 experiments:
  1. Validate retrieval-only performance (no LLM synthesis) against ground truth file IDs to isolate retriever accuracy.
  2. Ablate the hybrid retriever: test α=0 (pure BM25), α=1 (pure vector), α=0.5/0.8 to confirm optimal balance for your corpus.
  3. Test translation pipeline with native-language queries (not translated) vs. translated queries to quantify translation-induced loss.

## Open Questions the Paper Calls Out
None

## Limitations
- Limited query diversity with only 110 queries across 10 topics may not represent real-world archival search patterns
- Translation-induced precision loss shows Korean queries had 9% lower precision than English
- Dataset availability is limited as chunk size and document preprocessing strategies are unspecified

## Confidence

| Claim | Confidence |
|-------|------------|
| Hybrid retrieval mechanism (α=0.5-0.8 optimization) | High |
| Query routing effectiveness (38.73% F1 decline when removed) | Medium |
| Multimodal transformation through AI-generated descriptions | Medium |

## Next Checks
1. Replicate retrieval-only baseline: Run the retriever without LLM synthesis to establish ground truth accuracy, isolating retrieval performance from generation artifacts.
2. Cross-lingual precision validation: Test the translation pipeline by comparing native-language queries versus translated queries to quantify translation-induced information loss.
3. Chunking strategy sensitivity: Systematically vary chunk sizes (e.g., 512, 1024, 2048 tokens) to identify optimal segmentation for retrieval quality and LLM processing efficiency.