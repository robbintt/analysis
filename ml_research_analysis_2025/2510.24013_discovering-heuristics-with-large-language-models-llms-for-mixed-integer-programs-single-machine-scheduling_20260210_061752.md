---
ver: rpa2
title: 'Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer
  Programs: Single-Machine Scheduling'
arxiv_id: '2510.24013'
source_url: https://arxiv.org/abs/2510.24013
tags:
- problem
- tardiness
- mddc
- instances
- heuristics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces two novel Large Language Model (LLM)-discovered
  heuristics, EDD Challenger (EDDC) and MDD Challenger (MDDC), for the single-machine
  total tardiness (SMTT) scheduling problem. The LLM-driven discovery process employs
  an iterative, island-based evolutionary pipeline to refine initial heuristic rules
  (EDD and MDD) into more advanced algorithms.
---

# Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling

## Quick Facts
- arXiv ID: 2510.24013
- Source URL: https://arxiv.org/abs/2510.24013
- Reference count: 7
- Primary result: LLM-discovered MDDC heuristic achieves <2% optimality gap on 100-job instances, competitive with exact methods

## Executive Summary
This study demonstrates that Large Language Models can discover high-performing heuristics for NP-hard combinatorial optimization problems through an iterative evolutionary pipeline. The researchers applied this approach to the single-machine total tardiness scheduling problem, generating two novel heuristics (EDDC and MDDC) that outperform traditional rules like EDD and MDD. The LLM-driven discovery process refines initial heuristics through thousands of iterations, maintaining diversity via an island-based evolutionary strategy. MDDC, in particular, shows strong scalability and performance across different problem sizes while remaining computationally efficient compared to exact methods.

## Method Summary
The method employs an island-based evolutionary pipeline that treats LLMs as mutation operators for heuristic discovery. The process maintains 10 independent islands of heuristics, each initialized with classic rules (EDD, MDD, or SPT) and iteratively refined through LLM-generated variants. Every 4 hours, weaker islands are reset using high-performing heuristics from stronger islands to preserve diversity. The pipeline trains on small 25-job instances for efficiency but generalizes to larger problems. Feasibility is enforced through penalties for duplicate or missing jobs, and the LLM's access to input data is restricted to prevent constraint manipulation. The entire process runs for up to 72 hours or 10,000 iterations using Mixtral 8x7B.

## Key Results
- MDDC heuristic consistently outperforms traditional EDD and MDD rules across all tested instance sizes
- LLM-discovered heuristics maintain competitive optimality gaps (1.5-2.0%) on 100-200 job instances
- Training on small 25-job instances successfully produces heuristics that generalize to much larger problems
- Computational efficiency significantly exceeds exact methods while providing near-optimal solutions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs can serve as effective mutation operators in evolutionary search when paired with rigorous evaluation and iterative refinement.
- **Mechanism:** The pipeline treats an LLM as a program mutator that generates variants of heuristic functions. The LLM receives existing heuristics via best-shot prompting (sampling 2 programs per prompt), proposes modifications inspired by various domains, and the evaluator filters for feasibility and performance. Beneficial changes accumulate in a programs database over thousands of iterations.
- **Core assumption:** The search space of heuristic modifications contains productive regions accessible through incremental code changes, and the LLM can propose syntactically valid, semantically meaningful modifications more efficiently than random search.
- **Evidence anchors:**
  - [abstract] "The LLM-driven discovery process employs an iterative, island-based evolutionary pipeline to refine initial heuristic rules (EDD and MDD) into more advanced algorithms."
  - [section 4.1] "Rather than evolving a population of candidate solutions directly, our method maintains a population of solution functions (or heuristics) and iteratively builds new functions on top of the existing ones."
  - [corpus] Related work on LLM-driven heuristic discovery (e.g., FunSearch for bin-packing) shows mixed transferability; corpus evidence for SMTT-specific LLM heuristics is limited to this paper.
- **Break condition:** If the LLM generates primarily infeasible, syntactically invalid, or redundant modifications that do not improve objective scores over many iterations, the evolutionary search stagnates. The paper notes this risk: "LLMs, while powerful, often produce inaccurate or suboptimal outputs, commonly known as 'hallucinations.'"

### Mechanism 2
- **Claim:** Island-based evolution with periodic resets preserves heuristic diversity and mitigates premature convergence.
- **Mechanism:** The pipeline maintains 10 independent islands (sub-populations). Every 4 hours, weaker islands (those with lower best-function performance) are reset and re-initialized from stronger "founder" islands. This allows exploration of different heuristic families while periodically injecting high-performing genetic material.
- **Core assumption:** Multiple independent evolutionary trajectories increase the probability of discovering novel, high-performing heuristics that a single trajectory would miss.
- **Evidence anchors:**
  - [section 4.1] "The island-based strategy supports exploration and mitigates premature convergence by maintaining diverse sub-populations of heuristics."
  - [section 4.3] "For the experiments, 10 islands are used, with a random island selected at each step... Every 14,400 seconds (4 hours) of runtime, the weaker half of the islands are reset."
  - [corpus] No direct corpus evidence on island-based LLM evolution for scheduling; this appears novel to the paper.
- **Break condition:** If all islands converge to similar heuristic families before finding high-performing solutions, diversity is lost and search stagnates. The reset mechanism is designed to prevent this, but its effectiveness depends on sufficient inter-island variation.

### Mechanism 3
- **Claim:** Training on small problem instances can yield heuristics that generalize to much larger instances without retraining.
- **Mechanism:** The pipeline trains on 25-job instances (chosen to balance evaluation speed and generalizability), yet the discovered heuristics (MDDC, EDDC) maintain competitive optimality gaps on 100-, 200-, and 500-job instances. The heuristics capture structural scheduling principles (e.g., dynamic scoring based on processing times, due dates, and current time) that scale with problem size.
- **Core assumption:** Small instances preserve essential problem structure and constraints of larger instances, allowing learned heuristics to transfer.
- **Evidence anchors:**
  - [abstract] "This work demonstrates that LLMs can effectively generate high-performing heuristics for NP-hard combinatorial optimization problems, even when trained on small instances."
  - [section 5.2.2] Tables 2–6 show MDDC maintaining optimality gaps of ~1.5–2.0% across 20, 100, and 200-job instances, rising to ~48% only at 500 jobs.
  - [corpus] Related work on neural approaches to scheduling (e.g., LSTMs for decomposition) also reports generalization challenges at extreme scales; this is a known difficulty.
- **Break condition:** If training instances are too small or insufficiently diverse, discovered heuristics may overfit to trivial patterns and fail on larger or structurally different instances. The paper notes EDDC's optimality gap approximately doubles relative to EDD at 500 jobs, suggesting partial overfitting.

## Foundational Learning

- **Concept:** Single-Machine Total Tardiness (SMTT) Problem
  - **Why needed here:** This is the target optimization problem. Understanding its NP-hardness, objective (minimize sum of job tardiness), and classic heuristics (EDD, MDD) is essential to interpret the discovered algorithms and their performance.
  - **Quick check question:** Given jobs with processing times [5, 3, 7] and due dates [10, 4, 15], what is the total tardiness if jobs are scheduled in order 2, 1, 3?

- **Concept:** Evolutionary Algorithms / Genetic Programming
  - **Why needed here:** The pipeline uses an island-based evolutionary approach where LLM-generated heuristics are the "genetic material." Understanding mutation, selection, and diversity preservation helps explain why the method works and its failure modes.
  - **Quick check question:** In genetic programming, what is the role of a "mutation operator," and how does the LLM fulfill this role in the pipeline?

- **Concept:** Heuristics vs. Exact Methods in Optimization
  - **Why needed here:** The paper benchmarks LLM-discovered heuristics against exact methods (MIP, DP, Branch & Memorize). Understanding trade-offs—optimality guarantees vs. computational tractability—is crucial for interpreting results.
  - **Quick check question:** Why might a heuristic with a 2% optimality gap be preferred over an exact method for a 500-job scheduling problem?

## Architecture Onboarding

- **Component map:** Specification -> LLM Agent -> Evaluator -> Programs Database -> Island Manager

- **Critical path:**
  1. Initialize specification with base heuristic (EDD, SPT, or MDD).
  2. LLM generates variant → Evaluator tests on 10,000 instances of 25-job problems.
  3. If feasible and scoring above threshold → store in programs database.
  4. Sample 2 programs for best-shot prompt → LLM generates next variant.
  5. Repeat for 72 hours or 10,000 iterations.
  6. Extract best-performing heuristic from database; benchmark on 20–500 job instances.

- **Design tradeoffs:**
  - **Single-threaded vs. multi-threaded**: Paper uses single-threaded for reproducibility; multi-threaded (as in FunSearch) could accelerate but complicates synchronization.
  - **Training instance size**: 25 jobs balances evaluation speed vs. generalizability; larger sizes improve transfer but slow iteration.
  - **Prompt complexity**: More complex specifications (MDD) yield longer sampling times but potentially better heuristics.
  - **Island reset frequency**: 4-hour balances exploration and exploitation; too frequent resets lose diversity; too infrequent risks stagnation.

- **Failure signatures:**
  - **Infeasible outputs**: Heuristics that omit or duplicate jobs (mitigated by soft-constraint penalties).
  - **Constraint manipulation**: LLM may attempt to modify processing times or due dates (mitigated by treating input as immutable).
  - **Stagnant islands**: If no island shows improvement over multiple reset cycles, the search may be stuck.
  - **Overfitting to training distribution**: Heuristics that perform well on 25-job instances but degrade sharply at 500 jobs (observed for EDDC).

- **First 3 experiments:**
  1. **Baseline replication**: Implement EDD and MDD as initial heuristics; run the pipeline on 10,000 25-job instances for 24 hours; verify that the programs database accumulates feasible variants and that average tardiness decreases over iterations.
  2. **Ablation on training size**: Run the pipeline with 15-job, 25-job, and 40-job training instances; compare the optimality gaps of discovered heuristics on held-out 100-job test instances to assess the tradeoff between training speed and generalization.
  3. **Island reset sensitivity**: Vary reset frequency (2 hours, 4 hours, 8 hours) and number of islands (5, 10, 20); measure convergence speed and final heuristic quality to validate the island-based mechanism.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the integration of tree-based or other interpretable algorithms with LLMs produce heuristics that are both high-performing and explainable?
- Basis in paper: [explicit] The authors state, "This points out a further direction: using explainable and interpretable algorithms such as tree-based algorithms alongside LLMs."
- Why unresolved: The discovered MDDC heuristic contains "redundant manipulations" and "regressive terms" that obscure the core logic, reducing trustworthiness despite strong performance.
- Evidence: The successful generation of heuristics with clear decision rules that achieve optimality gaps comparable to MDDC.

### Open Question 2
- Question: How can adaptive sampling strategies or targeted stopping criteria be developed to improve the efficiency of the heuristic discovery pipeline?
- Basis in paper: [explicit] The authors note that "a portion of the remaining iterations may be redundant" and suggest enhancing training efficiency to avoid unnecessary computation.
- Why unresolved: The current methodology relies on a fixed computational budget (72 hours), continuing to run even after the best-performing algorithm has likely been found.
- Evidence: A modified pipeline that identifies convergence earlier, significantly reducing training time while maintaining solution quality.

### Open Question 3
- Question: Can this LLM-driven discovery framework be effectively generalized to more complex combinatorial optimization problems, such as job-shop scheduling or vehicle routing?
- Basis in paper: [explicit] The conclusion identifies "extending our approach to various combinatorial problems such as job-shop scheduling, capacitated lot-sizing, and vehicle routing" as a future research avenue.
- Why unresolved: The study validates the pipeline only on the single-machine total tardiness problem, leaving its efficacy on problems with different structural constraints unproven.
- Evidence: The generation of state-of-the-art heuristics for these distinct problem classes using the proposed island-based evolutionary pipeline.

## Limitations

- The LLM's internal reasoning during heuristic discovery remains opaque, making it difficult to verify whether discovered heuristics represent genuine algorithmic insights
- Training data generation parameters (RDD and TF distributions) may influence discovered heuristics' generalizability, but their impact remains unclear
- Computational efficiency gains are reported but energy costs of running the LLM-based discovery pipeline versus exact methods are not quantified

## Confidence

- **High Confidence:** MDDC's consistent performance improvement over EDD and MDD across multiple instance sizes, and its competitive performance against exact methods
- **Medium Confidence:** The claim that LLMs can effectively generate high-performing heuristics for NP-hard problems, given that only one problem domain (SMTT) was tested
- **Medium Confidence:** The computational efficiency claims, as wall-clock time comparisons between LLM-based heuristics and exact methods are provided, but energy consumption is not addressed

## Next Checks

1. **Cross-Domain Transferability Test:** Apply the exact discovery pipeline to a different NP-hard scheduling problem (e.g., job shop scheduling or parallel machine scheduling) to assess whether the LLM can discover problem-specific heuristics beyond SMTT.

2. **Training Instance Size Sensitivity Analysis:** Systematically vary the training instance size (10, 25, 50, 100 jobs) and measure the discovered heuristics' performance on held-out test instances across the full range of problem sizes to quantify the optimal tradeoff between training efficiency and generalization.

3. **Ablation on LLM vs. Traditional Search:** Replace the LLM mutation operator with a grammar-based genetic programming approach while keeping all other pipeline components identical, then compare the quality and diversity of discovered heuristics to isolate the LLM's specific contribution.