---
ver: rpa2
title: 'The Impact of Generative AI on Architectural Conceptual Design: Performance,
  Creative Self-Efficacy and Cognitive Load'
arxiv_id: '2601.10696'
source_url: https://arxiv.org/abs/2601.10696
tags:
- design
- genai
- cognitive
- https
- creative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated the impact of generative AI on architectural
  conceptual design, revealing that GenAI significantly improved design performance
  for novice students but did not enhance outcomes for experienced learners. While
  cognitive load did not differ significantly overall, students who used iterative
  idea-generation and visual feedback prompts experienced greater reductions in cognitive
  load.
---

# The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load

## Quick Facts
- arXiv ID: 2601.10696
- Source URL: https://arxiv.org/abs/2601.10696
- Reference count: 0
- Primary result: GenAI significantly improved design performance for novice students but not experienced learners

## Executive Summary
This study investigates the impact of generative AI on architectural conceptual design, revealing differential effects based on learner competency. Using a between-group experiment with 36 students, the research found that generative AI (DALL-E3) significantly enhanced design performance for novice designers while showing no benefit for experienced learners. The study also identified nuanced effects on cognitive load and creative self-efficacy, with iterative prompting strategies reducing cognitive load and general creative self-efficacy declining for GenAI users.

## Method Summary
The study employed a randomized between-group experiment with 36 architecture students, divided into GenAI (DALL-E3 in ChatGPT 4) and control (ArchDaily.com) conditions. Participants completed a two-phase design task: initial concept development without tools, followed by revision with assigned tools. Design performance was assessed by eight expert judges across three dimensions (clarity/legibility, complexity/detail, visual communication) using 5-point Likert scales. Creative self-efficacy and cognitive load were measured through pre/post surveys (NASA-TLX), with GenAI users' prompt logs coded into eight categories for analysis.

## Key Results
- GenAI significantly improved design performance for novice students but showed no enhancement for experienced learners
- Iterative idea-generation and visual feedback prompts correlated with greater reductions in cognitive load
- General creative self-efficacy declined for students using GenAI, while task-specific self-efficacy remained unchanged

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GenAI scaffolds novice design performance by compensating for underdeveloped visual ideation skills
- Mechanism: Novice designers lack internalized visual schemas and precedent knowledge. GenAI's text-to-image capabilities serve as an external scaffold, translating natural language into visual outputs and bypassing the skill gap in manual sketching
- Core assumption: The primary constraint for novice designers is translating abstract concepts into visual forms, not a lack of core design knowledge
- Evidence anchors: Abstract shows GenAI improved novice performance; Section 4.3 shows significant interaction effect between tool condition and initial competency level on design performance

### Mechanism 2
- Claim: Cognitive load is reduced only when users employ iterative, feedback-focused prompting strategies
- Mechanism: GenAI redistributes effort from manual production to prompt formulation and output evaluation. When users engage in iterative idea generation and specific visual feedback, they externalize the evaluation process, leading to greater load reduction
- Core assumption: Cognitive load reduction is mediated by the user's ability to offload specific tasks through structured interaction
- Evidence anchors: Abstract and Table 6 show CD3 and CD6 prompt use was significantly correlated with decreased cognitive load (r = -0.566, p = 0.022; r = -0.518, p = 0.039)

### Mechanism 3
- Claim: GenAI use can diminish general creative self-efficacy by shifting perceived creative agency to the human-AI system
- Mechanism: As GenAI becomes a co-creator, learners may attribute success to the tool, causing a decline in their confidence about their own general creative abilities
- Core assumption: Learners' self-assessment of creativity is sensitive to the perceived source of the creative output
- Evidence anchors: Abstract and Section 4.2 note general creative self-efficacy declined during revision phase, resulting in significant negative DiD effect

## Foundational Learning

- **Cognitive Load Theory (CLT)**: Why needed here? The paper argues GenAI's effect on load is conditional, not uniform. Distinguishing between extraneous (interaction) and intrinsic (task) load is essential. Quick check: How can adding a new tool with its own learning curve possibly reduce a user's overall cognitive load?

- **Creative Self-Efficacy**: Why needed here? This is the primary affective outcome, distinct from performance. Understanding it is critical for interpreting the counter-intuitive finding that performance can improve while self-belief declines. Quick check: Why might a student produce a better design with GenAI but feel less creative overall?

- **Human-AI Teaming / Hybrid Intelligence**: Why needed here? The study examines interaction patterns. The concept of hybrid intelligence, where cognitive effort is redistributed, is the framework for interpreting prompt analysis results. Quick check: In a human-AI design team, what cognitive tasks shift from the human to the AI, and what new tasks are created for the human?

## Architecture Onboarding

- **Component map**: User articulates intent in prompt -> GenAI generates visual -> User evaluates output against intent -> User formulates specific feedback prompts (CD3, CD6) -> GenAI revises output

- **Critical path**: User interface (prompt input) -> Cognitive offload engine (text-to-image generation) -> Interaction management layer (prompt formulation and output interpretation) -> Feedback loop (iterative refinement cycles)

- **Design tradeoffs**: 
  - Scaffolding vs. Agency: Strong scaffolding for novices can boost performance but risk undermining long-term creative self-efficacy
  - Automation vs. Control: Automated tools reduce effort but offer less control; tools requiring specific prompts increase overhead but allow precision
  - Offloading vs. New Demands: Offloads manual sketching but introduces demands for prompt engineering and critical output evaluation

- **Failure signatures**: 
  - Expert Performance Plateau: Experienced users see no benefit or a performance drop as established workflows are disrupted
  - Self-Efficacy Erosion: Decline in general creative self-efficacy despite improved outcomes, signaling loss of authorship
  - Cognitive Overload: Increased reported load from unfocused prompting, adding interaction burden

- **First 3 experiments**:
  1. Correlate frequency of specific prompt types (CD3, CD6) with changes in NASA-TLX cognitive load scores
  2. Run a two-way ANOVA to test for an interaction between initial design competency (novice vs. experienced) and GenAI tool use on design performance
  3. Use a Difference-in-Differences regression to compare changes in task-specific vs. general creative self-efficacy across tool conditions

## Open Questions the Paper Calls Out

- **Longitudinal evolution**: How do human-AI collaboration patterns and design competencies evolve when GenAI is integrated into a longitudinal design curriculum? The authors explicitly state the short study design captures only initial exposure and that future research should adopt longitudinal approaches.

- **Pedagogical interventions**: Can specific pedagogical interventions mitigate the decline in general creative self-efficacy observed in students using GenAI? The study identified the decline but did not test methods to counter it.

- **Controllability effects**: Do generative models with higher controllability (e.g., Stable Diffusion with ControlNet) reduce the cognitive load and "ideational friction" experienced by expert designers compared to DALL-E3? The authors note different patterns may emerge with multimodal or architecture-specific AI tools.

## Limitations

- Small sample size (N=36) limits statistical power and generalizability, particularly for subgroup analyses
- Single-session design prevents assessment of long-term impacts on creative self-efficacy and learning transfer
- Focus on novice-to-intermediate architectural students limits applicability to professionals or other creative domains

## Confidence

- **High Confidence**: Finding that GenAI improves design performance for novices but not experienced designers (p < 0.05 for interaction effect)
- **Medium Confidence**: Claim that specific prompting strategies (CD3, CD6) correlate with cognitive load reduction (r = -0.52 to -0.57)
- **Medium Confidence**: Observation that general creative self-efficacy declined in GenAI users

## Next Checks

1. **Replication with larger sample**: Conduct the study with N=80+ participants to increase power for detecting interaction effects and improve generalizability across competency levels

2. **Longitudinal follow-up**: Implement a 2-3 week follow-up assessment to measure persistence of creative self-efficacy changes and potential learning transfer to non-GenAI design tasks

3. **Physiological load validation**: Replicate the cognitive load findings using concurrent neurophysiological measures (EEG, eye-tracking) to validate self-reported NASA-TLX scores and capture real-time load dynamics during the design process