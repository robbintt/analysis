---
ver: rpa2
title: Optimal Transport for Handwritten Text Recognition in a Low-Resource Regime
arxiv_id: '2509.16977'
source_url: https://arxiv.org/abs/2509.16977
tags:
- recognition
- word
- visual
- transport
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel handwritten text recognition (HTR)
  framework that addresses low-resource scenarios where labeled data is scarce. The
  core method uses Optimal Transport (OT) to align visual features from unlabeled
  word images with semantic word embeddings in an iterative bootstrapping process.
---

# Optimal Transport for Handwritten Text Recognition in a Low-Resource Regime

## Quick Facts
- arXiv ID: 2509.16977
- Source URL: https://arxiv.org/abs/2509.16977
- Reference count: 0
- Introduces HTR framework using Optimal Transport for low-resource scenarios

## Executive Summary
This paper presents a novel handwritten text recognition framework that leverages Optimal Transport to address the challenge of recognizing text from limited labeled data. The approach uses iterative bootstrapping where visual features from unlabeled word images are aligned with semantic word embeddings through OT, generating pseudo-labels that progressively expand the training set. By incorporating a lexical prior through word frequency distributions, the method effectively guides the alignment process in low-resource settings.

The framework demonstrates significant improvements over state-of-the-art methods, particularly when labeled data is scarce. On the GW dataset with only 5% labeled data, the method achieves a Character Error Rate of 4.8% and Word Error Rate of 8.6%, outperforming existing approaches by more than 10% in some cases. The ablation studies confirm the importance of both the PHOC auxiliary head and lexical prior in achieving these results.

## Method Summary
The proposed framework addresses low-resource handwritten text recognition by reframing it as a visual-semantic alignment problem using Optimal Transport. Starting with a small labeled dataset, the method projects visual descriptors into word embedding space and solves an OT problem to match images to words. High-confidence matches generate pseudo-labels that expand the training set iteratively. The approach leverages PHOC embeddings and lexical priors (word frequency distributions) to guide the OT alignment, making it particularly effective when labeled data is limited. The iterative bootstrapping process progressively improves recognition accuracy by leveraging both visual and semantic information.

## Key Results
- On GW dataset with 5% labeled data: CER of 4.8% and WER of 8.6%
- Outperforms state-of-the-art methods by more than 10% in some cases
- Significant improvements across GW, IAM, and CVL datasets in low-resource regimes

## Why This Works (Mechanism)
The framework succeeds by leveraging Optimal Transport to bridge the visual-semantic gap in low-resource settings. By aligning visual features with word embeddings through OT, the method effectively transfers semantic knowledge to visual representations. The iterative bootstrapping process allows the model to gradually incorporate more reliable pseudo-labels, while the lexical prior provides crucial guidance by incorporating language statistics. This combination enables effective learning even with minimal labeled data by exploiting both visual patterns and linguistic structure.

## Foundational Learning
- Optimal Transport theory: Needed for aligning visual and semantic spaces; Quick check: verify Wasserstein distance computation
- PHOC embeddings: Needed for capturing character-level information in word embeddings; Quick check: confirm PHOC dimensionality matches requirements
- Iterative bootstrapping: Needed for progressively improving model with pseudo-labels; Quick check: validate confidence threshold selection
- Lexical priors: Needed for incorporating language statistics into alignment; Quick check: verify word frequency distribution accuracy
- Visual-semantic alignment: Needed for bridging gap between image features and text semantics; Quick check: test embedding space consistency
- Pseudo-label generation: Needed for expanding training data; Quick check: assess confidence score calibration

## Architecture Onboarding

**Component map**: Visual features -> PHOC embeddings -> OT solver -> Pseudo-labels -> Training set expansion

**Critical path**: Image input → Visual feature extraction → PHOC projection → OT alignment → Confidence scoring → Pseudo-label selection → Model retraining

**Design tradeoffs**: The framework trades computational complexity (solving OT problems iteratively) for improved accuracy in low-resource settings. The reliance on lexical priors assumes sufficient language resources, which may limit applicability to low-resource languages.

**Failure signatures**: Poor performance may result from: incorrect confidence threshold leading to noisy pseudo-labels, inadequate lexical priors for the target language, or failure to converge in the iterative process due to error accumulation.

**3 first experiments**:
1. Validate OT alignment quality by visualizing matched image-word pairs
2. Test sensitivity to confidence threshold by varying it across a range
3. Compare performance with and without lexical priors on a held-out validation set

## Open Questions the Paper Calls Out
None specified in the source material.

## Limitations
- Limited validation to three public datasets with constrained handwriting styles
- No statistical significance tests provided for claimed improvements
- Computational overhead of solving OT problems not thoroughly discussed

## Confidence

**High**: The core methodology of using OT for visual-semantic alignment in HTR is technically sound and the mathematical formulation is clearly presented.

**Medium**: The reported performance improvements on benchmark datasets are credible but would benefit from statistical validation and testing on more diverse handwriting styles.

**Low**: The scalability of the approach to highly resource-constrained languages and the practical deployment considerations regarding computational cost and error propagation are not adequately addressed.

## Next Checks

1. Conduct statistical significance tests (e.g., paired t-tests) on the CER/WER improvements across multiple runs to verify the claimed superiority over baselines.

2. Evaluate the framework on diverse, unconstrained handwriting datasets (e.g., historical manuscripts or multiple languages with varying script complexities) to assess generalizability.

3. Perform an analysis of error propagation in the iterative pseudo-labeling process by tracking the quality of pseudo-labels over iterations and their impact on final performance.