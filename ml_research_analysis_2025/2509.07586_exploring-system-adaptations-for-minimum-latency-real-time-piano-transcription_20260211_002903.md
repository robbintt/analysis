---
ver: rpa2
title: Exploring System Adaptations For Minimum Latency Real-Time Piano Transcription
arxiv_id: '2509.07586'
source_url: https://arxiv.org/abs/2509.07586
tags:
- transcription
- onset
- latency
- real-time
- piano
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores adapting state-of-the-art online piano transcription
  models for minimal-latency real-time transcription. The authors modify a reference
  model to ensure strict causality by eliminating non-causal processing, reducing
  computational load via shared model components, and experimenting with shifted asymmetric
  STFT windows to minimize preprocessing delay.
---

# Exploring System Adaptations For Minimum Latency Real-Time Piano Transcription

## Quick Facts
- arXiv ID: 2509.07586
- Source URL: https://arxiv.org/abs/2509.07586
- Reference count: 0
- Primary result: Adapted causal model achieves comparable precision to non-causal baseline but with lower recall under strict 10-30ms onset tolerances

## Executive Summary
This paper addresses the challenge of achieving minimal-latency real-time piano transcription by adapting state-of-the-art online models for strict causality. The authors modify Mobile-AMT to eliminate future-frame access through causal convolutions, reduce preprocessing delay via shifted asymmetric STFT windows, and experiment with binary classification targets and shared model components. Evaluated on MAESTRO dataset with strict onset tolerances, the adapted model achieves comparable precision to the non-causal baseline but with lower recall, demonstrating the fundamental difficulty of learning under tight temporal constraints.

## Method Summary
The authors adapt Mobile-AMT for strict causality by removing non-causal components (Squeeze-Excitation layers), implementing causal convolutions with 9-frame receptive field, and replacing triangular regression targets with binary classification using weighted BCE loss. They experiment with shifted asymmetric STFT windows (1888/160 samples) to reduce preprocessing delay from 64ms to 10-50ms, and share convolutional layers across onset/frame/velocity prediction heads. The system uses 16kHz audio, 229-bin mel spectrograms, and causal postprocessing with threshold-based onset detection and minimum re-onset distance.

## Key Results
- Causal adaptations achieve comparable precision but lower recall than non-causal baseline at strict 10-30ms tolerances
- Shifted asymmetric windows (30ms+ delay) match centered Hann window performance; 20ms delay surpasses it at stricter tolerances
- Binary classification targets with weighted loss enable causal postprocessing while maintaining accuracy
- Shared convolutional layers reduce computational load by 50% (320→160 GFLOPs) without hindering performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Binary pointwise classification targets with weighted loss enable causal postprocessing while approximating regression-based accuracy.
- **Mechanism:** Triangular regression targets require the model to begin increasing output before the actual onset (impossible for causal models). Binary targets allow frame-accurate detection using only past information, and weighting positive examples (factor of 10) counteracts severe class imbalance where onsets are rare events.
- **Core assumption:** The model can learn sufficient temporal context from the receptive field to distinguish onset frames from sustain frames without lookahead.
- **Evidence anchors:**
  - [abstract] "binary classification targets with weighted and shift-tolerant losses"
  - [Section 4.1] "TP3 [weighted classification] we additionally apply a weight factor 10 on both the onset and offset targets... The effect of lower onset detection thresholds is somewhat mitigated by weighting positive labeled examples higher"
  - [corpus] Weak direct evidence; neighbor papers focus on offline or high-latency systems.
- **Break condition:** If onset context requires more pre-onset frames than the receptive field provides, precision will degrade sharply at strict tolerances.

### Mechanism 2
- **Claim:** Shifted asymmetric STFT windows reduce preprocessing latency from 64ms to 10-50ms with acceptable spectral tradeoffs.
- **Mechanism:** Centering a 2048-sample Hann window on the prediction point incurs 1024 samples (64ms) of inherent delay. Shifting the window so it ends only ns samples after the reference point reduces delay, but the Hann window's tapered boundaries attenuate newly-arrived relevant information. Asymmetric windows (e.g., 1888/160 samples) preserve more energy near the prediction point at the cost of ~20dB increased spectral leakage.
- **Core assumption:** The model can compensate for reduced spectral clarity if sufficient future context (20-50ms) is preserved.
- **Evidence anchors:**
  - [abstract] "experimenting with shifted asymmetric STFT windows to minimize preprocessing delay"
  - [Section 4.2] "For a delay of 30 ms or more, we match performance of the centered Hann window... shifted asymmetric windows of 20 ms delay or more surpass the centered Hann window [at stricter tolerances]"
  - [corpus] No direct corroboration; corpus papers do not address STFT latency optimization.
- **Break condition:** At 10ms delay with asymmetric windows, low piano notes (<2 full periods) cannot be reliably pitch-estimated from fundamental frequency alone.

### Mechanism 3
- **Claim:** Sharing convolutional layers across acoustic stacks (onset/frame/velocity) reduces computation without degrading learned representations.
- **Mechanism:** Local acoustic features captured in early convolutional layers are largely target-invariant; pitch and harmonic structure inform onset, frame, and velocity predictions jointly. Sharing these layers (up to 100% sharing tested) reduces model size from 320 to 160 GFLOPs while maintaining comparable accuracy.
- **Core assumption:** Sequential processing in later recurrent layers provides sufficient target-specific specialization.
- **Evidence anchors:**
  - [abstract] "reducing computational load via shared model components"
  - [Section 4.3] "sharing the acoustic stack across increasing proportions (A3-5) does not appear to hinder the model's ability to learn meaningful representations"
  - [corpus] Weak; neighbor papers do not analyze weight sharing across transcription targets.
- **Break condition:** If targets require fundamentally different acoustic features (e.g., velocity needing amplitude dynamics vs. onset needing transients), shared layers will bottleneck performance.

## Foundational Learning

- **Concept: Strict causality vs. lookahead in neural audio processing**
  - **Why needed here:** The paper's central constraint is eliminating all future-frame access. Understanding that common operations (bidirectional RNNs, centered convolutions, global pooling) violate causality is prerequisite to interpreting the modifications.
  - **Quick check question:** Can a 1D convolution with kernel size 5 and padding 2 be made causal without changing the kernel size?

- **Concept: STFT time-frequency tradeoff and window design**
  - **Why needed here:** The preprocessing latency analysis hinges on understanding how window length determines frequency resolution, and how window shape affects spectral leakage vs. boundary attenuation.
  - **Quick check question:** Why does reducing STFT window length improve latency but harm low-frequency pitch discrimination?

- **Concept: Class imbalance in frame-level music tagging**
  - **Why needed here:** Binary onset targets create extreme imbalance (few active frames among many inactive). The weighted BCE and shift-tolerant loss experiments directly address this.
  - **Quick check question:** If an onset occurs in 2% of frames, what weighting factor would equalize positive and negative loss contributions?

## Architecture Onboarding

- **Component map:** 16kHz audio → STFT (2048-sample window, 160-sample hop) → 229-bin mel spectrogram → Causal MobileNetV3-based convolutional blocks → Unidirectional RNN → Separate onset/frame/velocity heads → Causal postprocessing

- **Critical path:**
  1. STFT window shift determines minimum achievable latency (10-50ms tested)
  2. Causal convolutions ensure no future-frame access in model
  3. Binary targets + causal postprocessing eliminate regression lookahead
  4. All three must be aligned; mismatched configurations (e.g., causal model with centered windows) waste causal gains

- **Design tradeoffs:**
  - Latency vs. accuracy: 10ms delay severely degrades F1 (~22 onset F1 at 10ms tolerance); 30ms approaches baseline
  - Precision vs. recall: Causal model achieves comparable precision but lower recall than non-causal Mobile-AMT
  - Model size vs. specialization: Shared convolutions reduce GFLOPs 50%; effect on accuracy is minimal in early training

- **Failure signatures:**
  - Near-zero F1 with shifted Hann window (H2): aggressive shift + symmetric taper eliminates usable information
  - High precision, low recall at strict tolerances: model is conservative, missing ambiguous onsets
  - Offset F1 significantly lower than onset F1: frame-based offset detection is inherently noisier

- **First 3 experiments:**
  1. **Baseline replication:** Implement non-causal Mobile-AMT with triangular targets; verify F1 matches reported ~67 at 50ms tolerance to confirm implementation correctness.
  2. **Causal ablation:** Apply only causal convolutions (no STFT shift); measure how much lookahead the model was implicitly using vs. explicit preprocessing delay.
  3. **Latency sweep:** Train models at 10, 20, 30, 50ms asymmetric window delays; plot F1 vs. tolerance to identify the knee point where diminishing returns begin.

## Open Questions the Paper Calls Out

- **Open Question 1:** How does the proposed system perform in terms of actual processing time (inference speed) across different hardware platforms compared to the theoretical algorithmic latency?
  - **Basis in paper:** [explicit] The authors acknowledge that "a detailed analysis of processing time—including both network inference and preprocessing—across different hardware platforms remains an important area for future work to allow for the practical deployment of a real-time transcription system in real-world scenarios."
  - **Why unresolved:** The study focuses on algorithmic latency (delay from windowing and causality) and transcription accuracy (F1 score), but does not benchmark the computational efficiency or wall-clock latency of the model on specific hardware.
  - **What evidence would resolve it:** Benchmarks of the model's inference time (ms) and CPU/GPU usage on target devices (e.g., standard CPUs or embedded systems) to verify that the total system latency remains within the 10–30 ms target.

- **Open Question 2:** Can the design of the window function or filter bank be optimized to better balance the reduction of preprocessing delay with the preservation of frequency resolution and future context?
  - **Basis in paper:** [explicit] The authors state they want to "take a closer inspection into the design of the underlying window function and filter bank, in order to find an appropriate balance between reducing prediction delay and increasing future context, all while maintaining the desired STFT properties."
  - **Why unresolved:** The experiments with shifted asymmetric windows showed that reducing delay to 10 ms significantly deteriorates accuracy, suggesting the current windowing approach loses critical information or introduces spectral leakage.
  - **What evidence would resolve it:** A comparison of alternative front-ends (e.g., learned filters or multi-resolution STFTs) that maintain pitch resolution for low notes without requiring the 64 ms lookahead inherent in standard centered windows.

- **Open Question 3:** Why does the strictly causal adapted model demonstrate higher robustness (precision) at lower timing tolerances compared to the non-causal baseline?
  - **Basis in paper:** [explicit] The authors note that "across all experimental groups, our system adaptations consistently outperformed the baseline at lower timing tolerance, which we consider a desirable property worthy of further investigation."
  - **Why unresolved:** While the paper documents the trade-off (lower overall recall but higher precision at strict tolerances for the causal model), it does not fully explain the underlying mechanism that makes the causal predictions temporally tighter.
  - **What evidence would resolve it:** An analysis of the prediction error distribution over time for causal vs. non-causal models, potentially visualizing how non-causal layers might "smear" onset predictions, thereby failing strict tolerance thresholds.

## Limitations
- Architectural transparency: Mobile-AMT baseline architecture not fully specified (layer counts, hidden dimensions, conditioning mechanisms)
- Window function implementation: Exact asymmetric window function formula not provided, only conceptual description
- Loss function specifics: Weighting factor of 10 for positive examples mentioned but uniform application across targets unclear
- Postprocessing parameters: Final onset threshold choice not reported despite testing multiple values

## Confidence
- **High confidence:** Causal architecture modifications clearly specified and latency improvements well-documented with direct measurements
- **Medium confidence:** STFT window shift experiments and asymmetric window design conceptually clear but exact implementation details could affect results
- **Low confidence:** Binary classification target experiments show expected patterns but absolute performance numbers may vary significantly based on unspecified parameters

## Next Checks
1. **Baseline replication verification:** Implement non-causal Mobile-AMT with triangular targets and verify F1 matches reported ~67 at 50ms tolerance. This confirms implementation correctness before applying causal modifications.

2. **Latency isolation test:** Apply only causal convolutions (no STFT shift) to measure how much lookahead the original model was implicitly using versus explicit preprocessing delay. This quantifies the relative contribution of each modification.

3. **Tolerance sensitivity analysis:** Train models at 10, 20, 30, 50ms asymmetric window delays and plot F1 vs. tolerance to identify the knee point where diminishing returns begin. This validates the reported performance-accuracy tradeoff curves.