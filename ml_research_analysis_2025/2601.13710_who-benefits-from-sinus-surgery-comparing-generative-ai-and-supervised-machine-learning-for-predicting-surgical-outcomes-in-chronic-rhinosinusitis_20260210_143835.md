---
ver: rpa2
title: Who Benefits From Sinus Surgery? Comparing Generative AI and Supervised Machine
  Learning for Predicting Surgical Outcomes in Chronic Rhinosinusitis
arxiv_id: '2601.13710'
source_url: https://arxiv.org/abs/2601.13710
tags:
- surgery
- class
- clinical
- genai
- snot-22
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study benchmarks supervised ML models against generative AI
  for predicting clinically meaningful improvement in chronic rhinosinusitis patients
  after sinus surgery, using a structured, prospectively collected dataset. The best-performing
  ML model (MLP) achieved 85% accuracy and 0.66 ROC-AUC, with superior calibration
  and net benefit compared to GenAI systems (e.g., ChatGPT, Claude, Gemini), which
  underperformed in discrimination and minority-class detection.
---

# Who Benefits From Sinus Surgery? Comparing Generative AI and Supervised Machine Learning for Predicting Surgical Outcomes in Chronic Rhinosinusitis

## Quick Facts
- **arXiv ID:** 2601.13710
- **Source URL:** https://arxiv.org/abs/2601.13710
- **Reference count:** 19
- **Primary result:** Calibrated tabular ML (MLP) outperforms zero-shot GenAI for minority-class detection in predicting chronic rhinosinusitis surgical outcomes.

## Executive Summary
This study benchmarks supervised ML models against generative AI for predicting clinically meaningful improvement in chronic rhinosinusitis patients after sinus surgery. Using a structured, prospectively collected dataset, the best-performing ML model (MLP) achieved 85% accuracy and 0.66 ROC-AUC, with superior calibration and net benefit compared to GenAI systems. Notably, GenAI justifications aligned with clinician heuristics and ML feature importance, emphasizing baseline symptoms, disease severity, polyp phenotype, and comorbidities. Findings support an ML-first, GenAI-augmented workflow: use calibrated ML for primary triage, with GenAI providing transparent, patient-facing explanations to enhance shared decision-making.

## Method Summary
The study used pre-operative data from an NIH multicenter CRS study (NCT01332136) to predict binary surgical outcomes based on MCID threshold (≥8.9-point SNOT-22 reduction at 6 months). After filtering to ESS-only patients (n=524), a stratified 80/20 split was used. ML models included logistic regression, random forest, and a shallow MLP (1 hidden layer, 400 neurons) with class weighting/focal loss. GenAI models (ChatGPT, Claude, Gemini, etc.) used zero-shot prompting with serialized structured inputs. Performance was evaluated using ROC-AUC, accuracy, F1, and per-class precision/recall, with particular emphasis on minority-class detection.

## Key Results
- MLP achieved 85% accuracy and 0.66 ROC-AUC, outperforming all GenAI models
- GenAI models showed high false-positive rates and treat-all bias, failing minority-class detection
- GenAI justifications aligned with clinician heuristics and MLP's feature importance (baseline symptoms, disease severity, polyp phenotype, comorbidities)
- RAG did not improve GenAI discrimination, as retrieved guidelines contained no individualized signal beyond tabular inputs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Calibrated tabular ML outperforms zero-shot GenAI for minority-class detection in imbalanced clinical outcomes.
- **Mechanism:** The MLP was trained with class weighting and focal/weighted loss on actual outcome labels, enabling it to learn decision boundaries that separate responders from non-responders. In contrast, GenAI models applied general heuristics without patient-specific calibration, defaulting to a "treat-all" bias that produced high false-positive rates.
- **Core assumption:** The training distribution is representative of deployment; pre-operative features contain signal predictive of MCID achievement.
- **Evidence anchors:** [abstract]: "Our best ML model (MLP) achieves 85% accuracy with superior calibration and decision-curve net benefit; GenAI models underperform on discrimination and calibration across zero-shot setting." [section V.H]: "the MLP delivers the strongest minority-class performance (higher Class 0 recall with reasonable precision), whereas several GenAI models collapse toward a treat-all pattern."

### Mechanism 2
- **Claim:** GenAI justifications converge with clinician heuristics and ML feature importance despite inferior discrimination.
- **Mechanism:** LLMs internalize clinical knowledge from pretraining on medical literature and guidelines. When prompted to explain decisions, they retrieve and apply rule-based schemas (e.g., baseline symptom burden, objective disease severity, comorbidities) that mirror expert reasoning, even though their probability estimates are poorly calibrated.
- **Core assumption:** The LLM's emergent heuristics reflect valid clinical relationships rather than spurious correlations.
- **Evidence anchors:** [abstract]: "Notably, GenAI justifications aligned with clinician heuristics and the MLP's feature importance, emphasizing baseline symptoms, disease severity, polyp phenotype, and comorbidities." [section V.J]: Permutation importance confirmed SNOT22_BLN_TOTAL, Age, and BLN_CT_TOTAL as top predictors—same factors emphasized by LLM rationales.

### Mechanism 3
- **Claim:** RAG does not improve GenAI discrimination for patient-specific outcome prediction because guidelines contain general heuristics already internalized during pretraining.
- **Mechanism:** Retrieved guideline snippets reiterate population-level patterns (e.g., higher baseline burden predicts larger gains) but add no individualized signal beyond the structured pre-operative features already provided. The task requires patient-level inference, not fact retrieval.
- **Core assumption:** The compact RAG corpus (EPOS/AAO-HNS excerpts, SNOT-22 meta-analyses) is representative of available guideline knowledge.
- **Evidence anchors:** [section V.K]: "With RAG, ChatGPT achieved accuracy 0.79 and ROC–AUC 0.57... Compared with the non-RAG setting (AUROC 0.58), retrieval produced no meaningful improvement." [section V.K]: "Retrieved guideline snippets reiterate broad heuristics already internalized during pretraining, but they do not contain additional, individualized signal beyond the tabular inputs."

## Foundational Learning

- **SNOT-22 and MCID Threshold:**
  - **Why needed here:** The entire prediction task hinges on understanding that MCID (≥8.9-point reduction) represents the minimal clinically important difference—a patient-centered success criterion, not an arbitrary threshold.
  - **Quick check question:** If a patient's SNOT-22 drops from 60 to 52, did they achieve MCID? What if it drops from 25 to 17?

- **Class Imbalance and Minority-Class Detection:**
  - **Why needed here:** In this cohort, most patients achieved MCID (Class 1 majority). The clinically valuable task is identifying non-responders (Class 0 minority). Accuracy alone is misleading—treat-all models appear "good" but fail the core objective.
  - **Quick check question:** Why does MedGPT-5 achieve 80% accuracy yet provide zero clinical utility for this task?

- **Calibration vs. Discrimination:**
  - **Why needed here:** AUROC measures ranking ability; calibration measures whether predicted probabilities match observed frequencies. For threshold-based decisions (recommend/don't recommend surgery), both matter.
  - **Quick check question:** A model with AUROC 0.90 but Brier score 0.4—is it safe to use for surgical recommendations? Why or why not?

## Architecture Onboarding

- **Component map:** Pre-processing (remove post-op fields, encode categoricals, handle missingness) -> Stratified 80/20 split -> ML Path (MLP with 1 hidden layer, 400 neurons, class weights) -> Calibrated probabilities -> Binary threshold (MCID≥9) OR GenAI Path (serialize structured inputs, zero-shot prompt, majority vote over k=5 replicates) -> Binary prediction + confidence -> Integration Layer (ML provides primary triage, GenAI generates patient-facing explanation)

- **Critical path:** 1) Extract pre-operative features only (leakage prevention is paramount) 2) Train MLP with class weights / focal loss to handle imbalance 3) Evaluate on minority-class recall (Class 0), not just overall accuracy 4) Deploy ML for calibrated risk estimates; route predictions to GenAI for explanation generation 5) Log model version, prompt hash, decoding parameters for audit trail

- **Design tradeoffs:** MLP depth vs. calibration: Shallow architecture (1 hidden layer) chosen for interpretability and calibration stability over raw discrimination gains. GenAI temperature: Low temperature (0.1–0.5) trades exploration for consistency across replicates. RAG investment: Study shows minimal return for this task; resources better allocated to ML calibration than RAG pipeline complexity.

- **Failure signatures:** GenAI "treat-all" bias: Class 0 recall → 0, false positives spike (see MedGPT-5, Perplexity Sonar). ML overfit to majority class: High accuracy but Class 0 recall < 0.20. Prompt drift: LLM justifications diverge from feature importance after prompt modification. Calibration decay: Reliability curves diverge from diagonal post-deployment.

- **First 3 experiments:**
  1. **Reproduce MLP baseline on same split:** Verify AUROC ≈ 0.66, Class 0 recall ≈ 0.45 using provided preprocessing artifacts. Document any deviation.
  2. **Run permutation feature importance:** Confirm SNOT22_BLN_TOTAL, Age, and BLN_CT_TOTAL are top predictors. Compare against LLM-stated rationales for consistency.
  3. **Test prompt sensitivity:** Vary temperature (0.1 vs. 0.5) and output schema (binary vs. ordinal confidence) on a held-out subset. Measure impact on minority-class recall and justification alignment.

## Open Questions the Paper Calls Out

- **Can a hybrid ML-LLM system preserve calibration while generating effective counterfactual explanations?** The current study evaluated standalone ML vs. zero-shot GenAI but did not test an integrated architecture where the LLM utilizes the ML model's output.

- **Does selective prediction (abstention) for low-confidence cases improve clinical net benefit?** The study evaluated models that predict on all cases; it remains unknown if filtering out low-confidence predictions yields better population-level outcomes.

- **Do the predictive models exhibit performance disparities across demographic subgroups?** While feature importance was analyzed globally, the paper does not report performance metrics stratified by race, sex, or insurance status.

- **Will the "ML-first" workflow maintain superior discrimination in external cohorts?** The current study uses a specific dataset; model performance may degrade when applied to institutions with different patient populations or surgical techniques.

## Limitations

- **Data access uncertainty:** The study's performance claims hinge on access to the NIH NCT01336136 dataset, which may require formal agreements or approvals for reproduction.

- **Hyperparameter gaps:** While MLP architecture is specified, critical hyperparameters (optimizer, learning rate, batch size, early stopping) are not documented, creating uncertainty in exact reproduction.

- **Prompt sensitivity unknown:** The study used specific zero-shot prompts, but the robustness of GenAI performance to prompt variations and potential drift over time remains unexplored.

## Confidence

- **High confidence:** Calibrated tabular ML (MLP) outperforms zero-shot generative AI for minority-class detection in this imbalanced surgical outcome prediction task.
- **Medium confidence:** GenAI justifications align with clinician heuristics despite poor discrimination, though depth of clinical reasoning validation is limited.
- **Medium confidence:** RAG does not improve GenAI discrimination for this task, but generalizability is uncertain due to limited corpus scope.

## Next Checks

1. **Data access and preprocessing audit:** Obtain the NCT01332136 dataset, apply exact preprocessing steps (removing post-operative fields, encoding categoricals, handling missingness), and reproduce the 80/20 stratified split to verify baseline ML performance.

2. **Minority-class performance validation:** Specifically evaluate Class 0 recall (non-responder identification) across all models, not just overall accuracy, to confirm the MLP's superior minority-class detection capability.

3. **Prompt stability testing:** Systematically vary GenAI prompts (temperature, output schema, few-shot examples) and measure impact on both prediction accuracy and justification alignment with ML feature importance to assess robustness of the GenAI-augmented workflow.