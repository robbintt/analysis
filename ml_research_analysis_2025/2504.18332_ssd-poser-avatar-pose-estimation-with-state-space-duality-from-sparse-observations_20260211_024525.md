---
ver: rpa2
title: 'SSD-Poser: Avatar Pose Estimation with State Space Duality from Sparse Observations'
arxiv_id: '2504.18332'
source_url: https://arxiv.org/abs/2504.18332
tags:
- pose
- motion
- sparse
- full-body
- state
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of full-body pose estimation
  from sparse observations captured by Head-Mounted Displays (HMDs), which typically
  provide only head and hand joint signals. To overcome limitations of existing approaches
  like Transformers and diffusion models, the authors propose SSD-Poser, a lightweight
  model based on the State Space Duality (SSD) framework.
---

# SSD-Poser: Avatar Pose Estimation with State Space Duality from Sparse Observations

## Quick Facts
- arXiv ID: 2504.18332
- Source URL: https://arxiv.org/abs/2504.18332
- Reference count: 40
- Primary result: State-of-the-art full-body pose estimation from sparse HMD observations with 2.41 MPJRE, 3.15 MPJPE, and 19.32 MPJVE at 0.007s inference

## Executive Summary
This paper introduces SSD-Poser, a lightweight model for full-body avatar pose estimation from sparse observations captured by Head-Mounted Displays (HMDs). The key innovation is a hybrid architecture combining State Space Duality (SSD) and attention mechanisms to efficiently extract spatiotemporal features from limited sensor data (head and hands). The model achieves state-of-the-art performance on the AMASS dataset while maintaining fast inference and a compact architecture.

## Method Summary
SSD-Poser uses a hybrid encoder combining SSD blocks with attention mechanisms to process 54-dimensional sparse input signals into full-body poses. The model features a Frequency-Aware Decoder that separates low and high-frequency motion features to enhance smoothness. Trained on AMASS with weighted L2 loss, the system processes 96-frame sequences and outputs 22 joint poses with 6D rotations. The architecture uses 4 State Space Attention Encoder (SSAE) blocks with 256-dimensional latent space.

## Key Results
- Achieves 2.41 MPJRE, 3.15 MPJPE, and 19.32 MPJVE on AMASS dataset
- Maintains fast inference (0.007s per sequence) and compact architecture (7.34M parameters)
- Frequency-Aware Decoder reduces jitter by 2.8× compared to baseline
- Optimal sequence length of T=96 balances accuracy and motion smoothness

## Why This Works (Mechanism)

### Mechanism 1: State Space Duality for Efficient Sequence Modeling
The SSD framework enables linear-time processing of temporal motion sequences while preserving dynamic feature modeling. The model bridges input-output through latent states that capture system dynamics, allowing parallel computation via efficient scanning algorithms. Human motion is modeled as a dynamical system where current poses depend on sequential latent states with controllable transition dynamics.

### Mechanism 2: Hybrid SSD-Attention for Complementary Feature Extraction
Combining SSD with multi-head attention captures both efficient spatiotemporal dynamics and long-range joint correlations. The architecture first extracts dynamic features through SSM transformation, then processes them with attention to capture inter-joint dependencies like periodic motion correlations.

### Mechanism 3: Frequency-Separable Decoding for Motion Smoothness
Explicitly separating low-frequency (smooth motion) and high-frequency (fine detail) features reduces jitter while preserving motion fidelity. The decoder uses 1×1 convolution for low-frequency features and 1×5 convolution for high-frequency features, with residual connections that maintain motion smoothness.

## Foundational Learning

- **State Space Models (SSMs)**: SSD extends SSM theory; understanding latent state transitions is prerequisite for grasping how the model captures temporal dynamics without quadratic attention. Quick check: Can you explain why Eq.(5) enables parallel training but sequential inference?

- **SMPL Body Model**: Input is 54-dim sparse signals (head + 2 hands × 18 features), output is 132-dim (22 joints × 6D rotation). Understanding this kinematic structure explains why lower-body prediction is "unconstrained." Quick check: Why does the paper use 6D rotation representation instead of quaternions or Euler angles?

- **Frequency Decomposition in Signal Processing**: FAD's design relies on convolution kernel sizes (1×1 vs 1×5) capturing different temporal frequencies—small kernels for low-freq, larger kernels for high-freq patterns. Quick check: What is the effective receptive field of a 1×5 convolution applied to a 96-frame sequence?

## Architecture Onboarding

- **Component map**: Input (T×54) → BFE (Linear) → V₀ (T×256) → [SSAE ×4] → V₁ → V₂ → V₃ → V_I → FAD → Linear → Output (T×132)

- **Critical path**: The PSSB's SSM operation (Eq. 8: Y2 = SSM(Y1 + Linear(LN(V_i)))) is the computational core. The gating mechanism requires careful initialization to avoid gradient vanishing in long sequences.

- **Design tradeoffs**: 
  - Sequence length T=96 balances accuracy (MPJRE 2.41) and jitter (8.19)
  - 4 SSAE blocks chosen over 5 blocks to reduce params (9.07M) and jitter (8.63)
  - L2 loss used to impose stronger constraints than absolute error

- **Failure signatures**: 
  - Lower-body drift from noisy sparse signals causing floating/penetrating feet
  - High-frequency aliasing manifesting as stuttering in rapid movements
  - Attention memory spike causing OOM if sequence length exceeds training

- **First 3 experiments**:
  1. Reproduce ablation on FAD: Train with/without FAFE module on AMASS subset. Verify jitter degradation matches ~2.8× (8.19 → 23.22).
  2. Profile PSSB vs Attention latency: On NVIDIA 4090, isolate timing for PSSB and AM blocks. Confirm 0.007s inference budget is met at T=96.
  3. Stress-test sequence length: Evaluate T=41, 96, 144, 196 on held-out motion clips with rapid lower-body actions. Plot MPJRE vs Jitter tradeoff curve.

## Open Questions the Paper Calls Out

### Open Question 1
Can the long-range dependency limitations of the SSD framework be overcome without reintroducing the quadratic computational complexity of the Transformer attention mechanism? The authors state "SSD still lags behind the performance of Transformer" for long-distance relationships, but resolving this requires comparing purely linear SSM approaches.

### Open Question 2
How does the model's performance degrade when applied to real-world HMD sensor data containing noise and drift, as opposed to the clean AMASS dataset? The method is evaluated exclusively on processed motion capture data, yet targets HMDs which are prone to sensor noise.

### Open Question 3
Is the trade-off between jitter reduction and positional accuracy manageable for input sequence lengths significantly greater than 96 frames? The ablation study shows longer sequences reduce jitter but cause significant increases in positional errors, with the underlying mechanism unexplored.

## Limitations
- Sequence length generalization beyond T=96 remains untested for streaming scenarios
- Lower-body motion modeling assumes unconstrained extrapolation from sparse upper-body signals
- Critical SSM hyperparameters (state dimension, discretization) are not specified for exact reproduction

## Confidence
- **High confidence**: SSD framework efficiency claims, FAD jitter reduction, hybrid SSD-attention architecture design
- **Medium confidence**: State Space Duality theoretical contributions, frequency decomposition effectiveness
- **Low confidence**: Generalization to real HMD data beyond AMASS, scalability to longer sequences, robustness to noisy sparse observations

## Next Checks
1. Implement FAFE without the Conv1x5 branch to quantify high-frequency feature separation contribution and measure jitter reduction scaling with motion complexity.
2. Test SSD-Poser on real HMD-captured datasets to evaluate performance degradation compared to AMASS, focusing on lower-body prediction accuracy for dynamic movements.
3. Systematically vary SSM state dimension N to measure trade-offs between accuracy and efficiency, determining if 7.34M parameters are near-optimal.