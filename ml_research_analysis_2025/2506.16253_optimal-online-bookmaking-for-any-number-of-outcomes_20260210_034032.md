---
ver: rpa2
title: Optimal Online Bookmaking for Any Number of Outcomes
arxiv_id: '2506.16253'
source_url: https://arxiv.org/abs/2506.16253
tags:
- lemma
- optimal
- loss
- proof
- follows
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the online bookmaking problem, where a bookmaker
  dynamically adjusts betting odds to maximize profit while minimizing loss across
  multiple outcomes and betting rounds. The authors present a complete solution for
  any number of outcomes K and rounds T by showing that the optimal loss is the largest
  root of a simple polynomial.
---

# Optimal Online Bookmaking for Any Number of Outcomes

## Quick Facts
- **arXiv ID:** 2506.16253
- **Source URL:** https://arxiv.org/abs/2506.16253
- **Reference count:** 40
- **Primary result:** Complete solution for optimal online bookmaking with K outcomes and T rounds, where optimal loss equals largest root of degree-K polynomial

## Executive Summary
This paper solves the optimal online bookmaking problem for any number of outcomes K and rounds T by showing the optimal loss is the largest root of a simple polynomial. The key innovation is the Bellman-Pareto frontier, which unifies dynamic programming with multi-criteria optimization for vector-valued games. The authors prove that regret grows as √T and converges to the largest root of the K-th Hermite polynomial, demonstrating that bookmakers can be arbitrarily fair. They also introduce opportunistic bookmaking for suboptimal gamblers, providing an efficient O(TK²) algorithm that achieves optimal loss at all times.

## Method Summary
The method uses Algorithm 1 to dynamically adjust betting odds across K outcomes over T rounds. It maintains a state vector tracking cumulative payouts, computes optimal loss as the largest root of polynomial F_{H,s}(x), and sets odds using ratios of partial elementary symmetric polynomials. When gamblers place non-decisive bets, the algorithm opportunistically reduces the loss below the standard optimal bound. The approach achieves per-round complexity of O(K²) through FFT-based computation of elementary symmetric polynomials.

## Key Results
- Optimal loss equals largest root of degree-K polynomial, computable in closed form
- Regret grows as √T and converges to largest root of K-th Hermite polynomial
- Unique Nash equilibrium exists where bookmaker equalizes loss across all decisive gambler responses
- Opportunistic strategy reduces loss when gamblers place suboptimal distributed bets
- O(TK²) algorithm achieves optimal loss at all times with water-filling interpretation

## Why This Works (Mechanism)

### Mechanism 1: Bellman-Pareto Frontier Characterization
The optimal bookmaking loss can be computed exactly as the largest root of a degree-K polynomial. The Bellman-Pareto (BP) frontier explicitly characterizes all achievable residual loss vectors—the set of valid future payout configurations. By Theorem 12, this frontier is parameterized by states s via PH,K = {L*_{H,K}(s)·1_K - s : s ∈ R^K, min_k s(k) = 0}. The optimal loss L*_{H,K}(s) equals the largest real root of polynomial F_{H,s}(x) = D_{H,K}(x·1_K - s), allowing efficient computation. Core assumption: Decisive gamblers (betting on single outcomes) are optimal; restricting to q ∈ E_K loses no generality (Theorem 9 establishes this).

### Mechanism 2: Water-Filling Equilibrium via Value Function Convexity
The unique optimal bookmaker action r* equalizes the potential loss across all K decisive gambler responses. By Lemma 31, value function V_H is convex. Theorem 9 (Nash Equilibrium) then guarantees a unique r* satisfying V_H(s) = V_{H-1}(s + e_k ⊘ r*) for all basis vectors e_k ∈ E_K. This acts like water-filling: the bookmaker raises all outcome-specific losses to the same "water level" L*_{H,K}(s). Core assumption: The value function's convexity (proved via induction using Jensen's inequality and coordinate-wise monotonicity).

### Mechanism 3: Opportunistic Loss Reduction from Suboptimal Gambler Play
When gamblers place non-decisive bets (q ∉ E_K), the bookmaker can reduce its worst-case guaranteed loss below the standard optimal bound. Algorithm 1 tracks state vector s (cumulative committed payouts). After each round, if q_{t-1} ∉ E_K, the algorithm recomputes L ← argmaxRoots(F_{T-t+1,s})—the optimal opportunistic loss for the new state. Since distributed bets don't maximize any single coordinate's exposure, the residual loss vector shrinks, lowering the "water level." Core assumption: Past gambler suboptimality provides no information about future behavior; we maintain worst-case maximization over future q_H.

## Foundational Learning

- **Concept: Dynamic Programming / Bellman Recursion**
  - Why needed here: The value function V_H(s) := inf_r max_q V_{H-1}(s + q ⊘ r) defines the game recursively; understanding backward induction is essential.
  - Quick check question: For V_0(s) = max_k s(k), what is V_1(s) and how does the infimum over r relate to equalizing losses?

- **Concept: Elementary Symmetric Polynomials (ESPs)**
  - Why needed here: Polynomial D_{H,K}(v) = Σ_{m=0}^K (-H)^{K-m} σ_m(v) uses ESPs; the loss formula F_{H,s}(x) = D_{H,K}(x·1_K - s) relies on Lemma 26's shifted ESP expansion.
  - Quick check question: For v ∈ R^3, compute σ_0(v), σ_1(v), σ_2(v), σ_3(v). Verify the recurrence σ_m(v) = v(k)·σ_{m-1}(v\k) + σ_m(v\k).

- **Concept: Hermite Polynomials and Root Bounds**
  - Why needed here: Theorem B states the asymptotic regret factor β_K equals the largest root of the K-th probabilist's Hermite polynomial He_K(x).
  - Quick check question: For K=2, He_2(x) = x² - 1. What is its largest root, and does it match β_2 = 1 from L*_{T,2} = T + √T?

## Architecture Onboarding

- **Component map:**
  - State vector s ∈ R^K -> Residual loss vector v = L·1_K - s -> Polynomial F_{H,s}(x) -> Largest root L*_{H,K}(s) -> Odds vector r

- **Critical path:**
  1. Initialize: s ← 0_K, L ← L*_{T,K} (largest root of P_{T,K})
  2. Output uniform odds: r_1 ← (1/K)·1_K
  3. For t = 2 to T:
     - Update state: s ← s + q_{t-1} ⊘ r_{t-1}
     - If q_{t-1} ∉ E_K (non-decisive): recompute L ← argmaxRoots(F_{T-t+1,s})
     - Compute residual: v ← L·1_K - s
     - For each k: r(k) ← D_{T-t,K-1}(v\k) / D_{T-t,K}(v)
     - Normalize: r_t ← r / ||r||_1

- **Design tradeoffs:**
  - Exact vs. ε-approximate root-finding: Exact gives optimal loss; ε-approximate (Remark 6) adds ≤2ε per non-decisive gambler action. Newton-Raphson: O(K log ε⁻¹) iterations.
  - Precomputation vs. on-demand: Binomial coefficients and falling factorials can be precomputed O(K²); ESPs computed per-round via FFT-ESP O(K log K) or PESP algorithm O(K²)
  - Memory: Store only s, L, and current r; no history needed (forward-running algorithm)

- **Failure signatures:**
  - r(k) ≤ 0 for any k: Violates positivity constraint from Remark 39; indicates numerical instability in root-finding or D-polynomial evaluation
  - Sum of r ≠ 1: Violates simplex constraint; check Lemma 46 implementation (should equal by construction)
  - Loss increases after decisive bet: Contradicts Theorem 9; verify state update and residual computation
  - L*_{H,K}(s) < max_k s(k) + H: Violates Lemma 38 lower bound; check polynomial root selection (must be *largest* real root)

- **First 3 experiments:**
  1. Verify K=2 closed form: Implement and confirm L*_{T,2} = T + √T for T=10, 100, 1000. Check that r_t converges to (1/2, 1/2) symmetry.
  2. Test equilibrium condition: For random s ∈ R^K and H=5, compute optimal r*. Verify that V_H(s + e_k ⊘ r*) is identical (within ε) for all k ∈ [K]. Use K=3, 4.
  3. Opportunistic reduction validation: Run T=100 rounds with K=3. First 50 rounds: gambler plays decisively (random e_k each round). Next 50 rounds: gambler plays uniformly q_t = (1/3, 1/3, 1/3). Verify that L decreases after round 51 and final loss < L*_{100,3}.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the online bookmaking framework be extended to alternative loss functions beyond the worst-case formulation in Equation (2)?
- Basis in paper: [explicit] "Future work may consider extending our approach to alternative loss functions or constrained settings, building on the structure offered by the Bellman-Pareto framework." (Conclusion)
- Why unresolved: The current analysis relies on the specific structure of the loss function to derive the polynomial characterization and water-filling interpretation; different loss functions may not admit closed-form solutions.
- What evidence would resolve it: Derivation of optimal loss expressions for alternative loss functions (e.g., expected loss, risk-adjusted measures) with explicit algorithmic strategies.

### Open Question 2
- Question: Can the Bellman-Pareto frontier characterization be applied to other vector-valued games in online learning beyond bookmaking?
- Basis in paper: [explicit] "The key technical contribution... is an explicit characterization of the Bellman-Pareto frontier, which may have broader applications to vector-valued problems in online learning and game theory." (Abstract and Conclusion)
- Why unresolved: The paper demonstrates the technique only for the bookmaking problem; the generalization requires identifying problems with similar structure (vector-valued objectives, sequential decisions, balancing trade-offs).
- What evidence would resolve it: Application to other vector game settings (e.g., multi-objective bandits, multi-class prediction with unknown true class) with explicit frontier characterizations.

### Open Question 3
- Question: What happens to the optimal bookmaking strategy when the overround parameter Γ can vary adaptively across rounds?
- Basis in paper: [inferred] The paper assumes "a fixed overround parameter Γ ≥ 1" that is "time-independent" (Section 2.2), but does not explore whether adaptive Γ could improve performance.
- Why unresolved: The analysis derives optimal strategies conditioned on fixed Γ; dynamic Γ introduces additional strategic dimensions for the bookmaker.
- What evidence would resolve it: Characterization of optimal loss and strategy for time-varying Γ, with comparison to fixed-Γ performance bounds.

### Open Question 4
- Question: Can the per-round computational complexity of O(K²) be improved, particularly for settings with very large K?
- Basis in paper: [inferred] Remark 4 states the algorithm has "per-round complexity of O(K²)" and "overall complexity of O(TK²)." For large outcome spaces (e.g., K=40 for Eurovision), this may be practically significant.
- Why unresolved: The complexity arises from computing partial elementary symmetric polynomials; the paper does not establish lower bounds on complexity.
- What evidence would resolve it: Either an algorithm with provably lower complexity (e.g., O(K log K) per round) or a computational hardness result showing O(K²) is necessary for exact computation.

## Limitations

- **Computational scalability**: O(TK²) complexity may become prohibitive for large K (e.g., K > 100) despite being polynomial
- **Empirical validation gap**: No experimental results validate algorithm performance against real or synthetic gambling sequences
- **Assumption of adversarial behavior**: Worst-case analysis assumes adversarial gambler behavior that may not reflect practical patterns
- **Numerical sensitivity**: Root-finding relies on high-degree polynomials with rapidly growing coefficients, potentially causing numerical instability

## Confidence

- **High Confidence**: Bellman-Pareto frontier characterization - mathematically sound with binary case sanity check
- **Medium Confidence**: Water-filling equilibrium - logically follows from convexity but relies on technical lemmas
- **Medium Confidence**: Opportunistic loss reduction - well-defined framework but unverified empirically

## Next Checks

**Validation Check 1**: Implement Algorithm 1 for K=3, T=100 and verify the opportunistic loss reduction. Run two scenarios: (a) gambler plays randomly on decisive vertices for all rounds, (b) gambler plays randomly for first 50 rounds, then uniformly distributed bets for remaining 50 rounds. Compare final losses and verify that L decreases in scenario (b).

**Validation Check 2**: Test numerical stability for moderate parameter values. For K=5, T=30, compute L*_{T,K} using both exact arithmetic (if available) and floating-point arithmetic. Verify that the largest root computation remains accurate within ε < 0.01 and that odds vectors remain valid (positive, sum to 1).

**Validation Check 3**: Validate the equilibrium condition empirically. For random states s ∈ R^K (K=4) and various H values (H=5, 10), compute optimal r* and verify that V_H(s + e_k ⊘ r*) is identical across all k ∈ [K] within numerical precision. This checks the water-filling property computationally.