---
ver: rpa2
title: 'SCALAR: Benchmarking SAE Interaction Sparsity in Toy LLMs'
arxiv_id: '2511.07572'
source_url: https://arxiv.org/abs/2511.07572
tags:
- saes
- layer
- staircase
- topk
- scalar
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce SCALAR, a benchmark for measuring interaction
  sparsity between SAE features, addressing the problem of inflated circuit complexity
  from spurious cross-layer connections in standard SAEs. They propose Staircase SAEs,
  an architecture that improves feature reuse across layers through shared upstream
  weights, reducing spurious connections.
---

# SCALAR: Benchmarking SAE Interaction Sparsity in Toy LLMs

## Quick Facts
- arXiv ID: 2511.07572
- Source URL: https://arxiv.org/abs/2511.07572
- Reference count: 40
- Primary result: Staircase SAEs improve interaction sparsity by 59.67%±1.83% over TopK SAEs while maintaining interpretability

## Executive Summary
SCALAR introduces a benchmark for measuring interaction sparsity between Sparse Autoencoder (SAE) features across layers, addressing the problem of inflated circuit complexity from spurious cross-layer connections in standard SAEs. The paper proposes Staircase SAEs, an architecture that improves feature reuse across layers through shared upstream weights, reducing spurious connections. Using integrated gradient attributions to rank edge importance, SCALAR quantifies how model performance degrades as inter-layer connections are progressively ablated. Staircase SAEs achieve 59.67%±1.83% improvement in relative interaction sparsity over TopK SAEs for feedforward layers while maintaining interpretability.

## Method Summary
SCALAR measures interaction sparsity by progressively ablating edges between SAE latents across layers and measuring performance degradation via KL divergence. Edges are ranked by integrated gradient attribution importance scores. Staircase SAEs share encoder/decoder weights across layers with independent per-layer biases, enabling feature reuse from upstream layers. JSAEs use Jacobian regularization to penalize cross-layer interactions. The benchmark computes area under the KL degradation curve (absolute and relative scores) to quantify circuit sparsity requirements.

## Key Results
- Staircase SAEs improve relative interaction sparsity by 59.67%±1.83% (feedforward layers) and 63.15%±1.35% (transformer blocks) over TopK SAEs
- Staircase SAEs achieve 38.7% improvement in relative interaction sparsity on GPT-2 Small validation
- ~55-75% of active features in Staircase SAEs come from previous layers vs. ~25-45% new features

## Why This Works (Mechanism)

### Mechanism 1: Weight-sharing reduces spurious cross-layer connections
Weight-sharing across SAE layers enables feature persistence, reducing the need for the model to re-learn the same concept at each layer. Features represented once can persist across layers, reducing spurious interactions and simplifying circuit structure.

### Mechanism 2: Independent per-layer biases enable selective feature reuse
Each layer maintains independent encoder/decoder biases that enable selective suppression or reuse of inherited features. Negative encoder bias values suppress inherited features when unhelpful, while positive values enable reuse through soft gating without additional parameters.

### Mechanism 3: Progressive ablation with integrated gradient ranking measures true importance
SCALAR ranks edges by integrated gradient attribution importance rather than counting active connections. Progressive ablation of least-important edges while measuring KL divergence captures how densely connected the circuit must be to preserve performance.

## Foundational Learning

- **Sparse Autoencoders (SAEs) and the Superposition Hypothesis**
  - Why needed here: Understanding SAEs decompose dense activations into sparse, interpretable latents via dictionary learning, and that independently-trained SAEs create layer-wise inconsistencies
  - Quick check question: Can you explain why training SAEs per-layer in isolation might create inconsistent feature representations across layers?

- **Integrated Gradients for Attribution**
  - Why needed here: SCALAR relies on integrated gradients to score connection importance
  - Quick check question: How does integrated gradient attribution differ from raw gradient magnitude for identifying feature importance?

- **Ablation Studies and KL Divergence**
  - Why needed here: SCALAR measures degradation via KL divergence between full-model and subcircuit outputs
  - Quick check question: Why might KL divergence be preferred over classification accuracy when measuring model degradation from circuit pruning?

## Architecture Onboarding

- **Component map:**
  - Staircase SAE: Shared W_enc ∈ R^(d_model × N), W_dec ∈ R^(N × d_model) across L layers; each layer i uses slice W_enc[:ni, :], W_dec[:, :ni] where n is base chunk size
  - Per-layer biases: b^i_enc ∈ R^(ni), b^i_dec ∈ R^(d_model) — independent for each layer
  - SCALAR pipeline: (1) Score edges via integrated gradients → (2) Sort edges → (3) Progressive ablation → (4) KL divergence measurement → (5) AUC computation
  - TopK activation: Selects K largest-magnitude latents, zeros others (sparsity enforced by definition)

- **Critical path:**
  1. Implement shared weight matrices with slice-based access per layer
  2. Ensure encoder/decoder biases are *not* shared (common implementation mistake)
  3. For SCALAR: implement bipartite subcircuit forward pass that selectively activates downstream latents based on retained edges

- **Design tradeoffs:**
  - Absolute vs. Relative SCALAR: Absolute favors smaller dictionaries; relative normalizes by edge count but can be gamed by adding inactive features. Report both.
  - Staircase vs. JSAE: Staircase works anywhere in residual stream; JSAE limited to feedforward layers (requires tractable Jacobian). Staircase uses architecture; JSAE uses explicit loss penalty.
  - Parameter count: Staircase SAEs use ~same parameters as independent SAEs (only ~1.5% increase from per-layer biases)

- **Failure signatures:**
  - Detached gradient variant: If you freeze earlier chunks when training later layers, the model degenerates to standard SAE behavior (no feature reuse)
  - Shared biases: If biases are shared across layers, disabling a feature at one layer unintentionally degrades performance at others
  - JSAE on LayerNorm: Computing Jacobian through LayerNorm is O(s²d²) memory — intractable; requires DyT or LayerNorm removal

- **First 3 experiments:**
  1. Reproduce toy model Staircase vs. TopK comparison on a 4-layer transformer with residual stream width 64; measure both absolute and relative SCALAR scores across feedforward blocks.
  2. Ablation study on bias independence: Train Staircase SAEs with shared vs. independent biases; quantify degradation in relative SCALAR score and reconstruction loss.
  3. Feature reuse visualization: For each layer in a trained Staircase SAE, plot L0 sparsity per chunk to confirm that ~55-75% of active features come from previous layers vs. ~25-45% new features.

## Open Questions the Paper Calls Out
None

## Limitations

- SCALAR relies on integrated gradient attributions which may be unreliable for sparse, non-differentiable activations like TopK
- The toy model's simplicity (4 layers, d=64) raises questions about scalability to full-sized models
- Improvement in interaction sparsity comes with trade-offs in reconstruction fidelity or interpretability

## Confidence

- **High Confidence**: The architectural mechanism of Staircase SAEs (shared weights + independent biases enabling feature reuse) is well-specified and the empirical improvement in interaction sparsity is clearly demonstrated
- **Medium Confidence**: The claim that reduced interaction sparsity improves interpretability and circuit simplicity is supported by SCALAR scores but lacks direct evidence linking sparsity to actual interpretability gains
- **Low Confidence**: The assumption that integrated gradients reliably rank feature interaction importance for sparse activations, and that KL divergence captures functionally relevant degradation, requires further validation

## Next Checks

1. **Attribution Validation**: Compare integrated gradient rankings against ground-truth edge importance by synthetically constructing circuits with known critical connections, then verify SCALAR's ablation correctly identifies them
2. **Scalability Test**: Implement Staircase SAEs on a medium-sized model (e.g., 8-layer transformer, d=128) and measure whether interaction sparsity improvements scale proportionally or diminish
3. **Interpretability Correlation**: For a trained Staircase SAE, conduct manual circuit analysis on a simple task (e.g., induction heads) and quantify whether reduced interaction sparsity actually simplifies the interpretable subgraph compared to standard SAEs