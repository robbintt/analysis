---
ver: rpa2
title: 'From One Attack Domain to Another: Contrastive Transfer Learning with Siamese
  Networks for APT Detection'
arxiv_id: '2511.20500'
source_url: https://arxiv.org/abs/2511.20500
tags:
- learning
- transfer
- feature
- detection
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a hybrid transfer learning framework for detecting
  Advanced Persistent Threats (APTs) across different attack domains. The method integrates
  explainable AI-guided feature selection using SHAP and entropy, an attention-based
  autoencoder for knowledge transfer, contrastive learning for feature space refinement,
  and a Siamese network for cross-domain feature alignment.
---

# From One Attack Domain to Another: Contrastive Transfer Learning with Siamese Networks for APT Detection

## Quick Facts
- arXiv ID: 2511.20500
- Source URL: https://arxiv.org/abs/2511.20500
- Reference count: 40
- Primary result: Hybrid transfer learning framework outperforms classical and deep learning baselines in cross-domain APT detection across multiple operating systems.

## Executive Summary
This paper introduces a hybrid transfer learning framework designed to detect Advanced Persistent Threats (APTs) across different attack domains. The approach addresses the challenge of scarce and imbalanced APT datasets by leveraging knowledge from source domains to improve detection in target domains. By integrating explainable AI-guided feature selection, attention-based autoencoders, contrastive learning, and Siamese networks, the framework achieves superior performance in both anomaly ranking and classification metrics. The method is validated on real-world DARPA Transparent Computing data augmented with synthetic attack scenarios.

## Method Summary
The framework employs a multi-step transfer learning pipeline: (1) XAI-guided feature selection using SHAP, entropy, and reconstruction error to identify stable and informative features; (2) an attention-based autoencoder (AAE) pretrained on source data and fine-tuned on target data; (3) contrastive learning with InfoNCE loss to refine feature embeddings and improve anomaly separability; (4) a Siamese network to align source and target feature spaces using Euclidean distance and contrastive loss; and (5) anomaly detection via reconstruction error and standard detection algorithms. The method is evaluated across multiple operating systems and attack scenarios, showing consistent improvements over baseline methods.

## Key Results
- The hybrid transfer learning framework consistently outperforms classical and deep learning baselines in both nDCG (anomaly ranking) and AUC (classification) metrics.
- Statistical tests (Friedman and Wilcoxon) confirm the significance of the improvements across multiple operating systems and attack scenarios.
- The framework effectively handles feature drift and improves cross-domain transferability, as demonstrated on DARPA Transparent Computing data augmented with synthetic attacks.
- LLM-based explanations are integrated to provide interpretable insights into detected threats.

## Why This Works (Mechanism)

### Mechanism 1: XAI-Guided Feature Selection for Cross-Domain Stability
- Claim: Selecting features based on combined SHAP, entropy, and reconstruction error improves transferability and reduces computational cost.
- Mechanism: A surrogate autoencoder computes per-feature reconstruction difficulty; SHAP values quantify impact on model output; entropy captures variability. Features are ranked by S_j = α·RE_j + β·Ent_j + γ·SHAP_j, and top-K are retained.
- Core assumption: Features that are informative, variable, and difficult to reconstruct in the source domain remain discriminative in the target domain.
- Evidence anchors:
  - [abstract] "SHAP-based feature selection reduces dimensionality and computational cost."
  - [section] "Step 2: Explainable Feature Selection Using XAI Techniques" – Equation (1) defines the combined score; cumulative contribution threshold (ξ) determines K.
  - [corpus] "A Study on the Importance of Features in Detecting Advanced Persistent Threats Using Machine Learning" supports feature importance analysis in APT contexts.
- Break condition: If SHAP values become unstable across domains or if entropy does not capture attack-relevant variability, the selected features may not transfer.

### Mechanism 2: Contrastive Learning for Anomaly Separability
- Claim: Contrastive loss improves anomaly ranking by pulling similar embeddings closer and pushing dissimilar ones apart.
- Mechanism: Uses InfoNCE loss with temperature τ=0.1. Hard negative mining selects pairs where sim(Z_i, Z_k) > δ (δ=0.8), forcing the model to learn finer distinctions.
- Core assumption: Similar attack behaviors (same cluster/label) should map to nearby points in latent space across domains.
- Evidence anchors:
  - [abstract] "increasing anomaly separability and mitigating feature drift."
  - [section] "Step 5: Contrastive Learning for Feature Space Refinement" – Equation (15) and Figure 2 illustrate the principle.
  - [corpus] Limited direct corpus support for APT-specific contrastive learning; related work on contrastive learning in other domains exists but not validated for APT.
- Break condition: If negative pairs are mislabeled (e.g., benign processes incorrectly grouped as dissimilar to attacks), or if temperature is poorly tuned, the loss may not improve separability.

### Mechanism 3: Siamese Network for Cross-Domain Alignment
- Claim: A Siamese network explicitly measures and reduces feature space discrepancy between source and target domains.
- Mechanism: Two identical subnetworks with shared weights encode source and target embeddings; Euclidean distance D measures dissimilarity; contrastive loss L_siamese minimizes distance for similar pairs and enforces a margin for dissimilar pairs.
- Core assumption: Embeddings from source and target domains that represent semantically similar behaviors should have small Euclidean distance.
- Evidence anchors:
  - [abstract] "aligns source and target representations."
  - [section] "Step 6: Feature Space Alignment Using Siamese Networks" – Equation (18–20) define the architecture and loss; Figure 10 shows cosine similarity distributions separating positive and negative pairs.
  - [corpus] "Explaining Siamese Networks in few-shot learning" provides theoretical grounding, but APT-specific validation is limited to this paper's experiments.
- Break condition: If source and target distributions have fundamentally different semantic structures (e.g., different OS with non-overlapping event types), alignment may not improve detection.

## Foundational Learning

- Concept: **Transfer Learning (Domain Adaptation)**
  - Why needed here: APT datasets are scarce and highly imbalanced; models must generalize from one attack scenario to another despite feature space misalignment (different logging, OS, monitoring tools).
  - Quick check question: Given source domain D_s = {X_s, P(X_s)} and target domain D_t = {X_t, P(X_t)}, can you explain why directly applying f_s(·) trained on X_s to X_t often fails?

- Concept: **Contrastive Learning (Self-Supervised)**
  - Why needed here: Target domain labels are unavailable or extremely sparse; the model must learn to separate anomalies from normal behavior using only the similarity structure of the data.
  - Quick check question: If all embeddings collapse to the same point, what happens to the InfoNCE loss denominator? How does temperature τ affect the sharpness of the similarity distribution?

- Concept: **SHAP (Shapley Additive Explanations)**
  - Why needed here: Provides interpretable, per-feature importance scores; helps identify which features are stable and informative across domains, enabling principled feature selection.
  - Quick check question: If a feature has high SHAP importance in the source domain but near-zero importance in the target, should it be retained? How would you detect this during feature selection?

## Architecture Onboarding

- Component map:
  1. Data Preprocessing → Vectorize provenance graphs into binary matrices X_s, X_t; augment with cGAN/VAE synthetic attacks.
  2. XAI Feature Selection → Compute SHAP, entropy, reconstruction error; select top-K features via cumulative contribution threshold.
  3. Attention-based Autoencoder (AAE) → Encoder with attention mechanism learns latent representations Z_s, Z_t.
  4. Transfer Learning → Pretrain AAE on source; fine-tune on target with combined reconstruction loss.
  5. Contrastive Learning → Apply InfoNCE loss with hard negative mining to refine embeddings.
  6. Siamese Network → Shared encoder computes embeddings; Euclidean distance + contrastive loss aligns source and target.
  7. Anomaly Detection → Reconstruction error ||x_t - x̂_t||² yields anomaly scores; apply Isolation Forest, OC-SVM, LOF, etc., to latent embeddings.

- Critical path:
  1. Preprocess binary provenance data → vectorized matrices.
  2. Train surrogate autoencoder → compute reconstruction error, entropy, SHAP → select top-K features.
  3. Pretrain attention autoencoder on source (minimize L_AAE).
  4. Fine-tune on target with source regularization.
  5. Apply contrastive loss to refine embeddings (minimize L_contrast).
  6. Train Siamese network to align source/target (minimize L_siamese).
  7. Compute anomaly scores; evaluate via nDCG and AUC.

- Design tradeoffs:
  - α, β, γ weights (default 0.5 each): Higher α emphasizes hard-to-reconstruct features; higher β prioritizes variability; higher γ favors SHAP-identified important features. Tune per dataset.
  - Cumulative threshold ξ (60–95%): Lower ξ → fewer features, faster inference, but may drop discriminative information.
  - Temperature τ = 0.1: Lower τ sharpens similarity distribution; too low may cause numerical instability.
  - Siamese margin m = 1.0: Larger margins enforce stricter separation of dissimilar pairs; may hurt performance if domains overlap significantly.

- Failure signatures:
  - P1 ≈ P2 with no improvement: Feature selection not transferring; SHAP values may be unstable across domains.
  - High AUC but low nDCG: Classification works but ranking is poor; contrastive loss weighting may need adjustment.
  - Siamese distance does not decrease: Source and target may be too dissimilar; consider adding more source data or synthetic augmentation.
  - Overfitting on source, poor target generalization: Regularization (dropout, weight decay) may be insufficient; reduce model capacity or increase source diversity.

- First 3 experiments:
  1. Ablation study: Compare P2 (without Siamese/XAI) vs P3 (full pipeline) on a single dataset (e.g., BSD-PA). Quantify the contribution of each component via ΔnDCG and ΔAUC.
  2. Feature selection sweep: Vary ξ from 0.60 to 0.95; plot nDCG vs K. Identify the elbow where additional features yield diminishing returns.
  3. Embedding visualization: Use t-SNE/UMAP to visualize source and target embeddings before and after Siamese alignment. Qualitatively assess whether clusters overlap more post-alignment.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the detection of multi-stage APT progressions be improved by integrating temporal dynamics into the static Attention-based Autoencoder (AAE)?
- **Basis in paper:** [Explicit] The authors state, "integrating temporal dynamics via sequence models (e.g., Transformers or RNNs) could enhance sensitivity to evolving APT stages."
- **Why unresolved:** The current framework relies on static binary vectors that capture the presence or absence of events but do not model the sequential dependencies or time-series nature of attack lifecycles.
- **What evidence would resolve it:** A comparative study evaluating the framework's performance when the AAE is replaced or augmented by a sequential model (e.g., LSTM or Transformer) on time-ordered provenance data.

### Open Question 2
- **Question:** How does the framework perform when applied to non-binary feature representations in highly heterogeneous cross-OS environments?
- **Basis in paper:** [Explicit] The authors list as future work the intent to "investigate cross-OS transfer learning using more heterogeneous datasets and non-binary feature representations."
- **Why unresolved:** The current evaluation is restricted to binary matrices derived from DARPA TC traces. It is unclear if the Siamese alignment and contrastive loss remain effective when features include continuous variables or complex categorical metadata rather than simple presence/absence indicators.
- **What evidence would resolve it:** Benchmark results showing the AAE's transferability performance on datasets utilizing continuous system metrics or rich textual logs across different operating systems.

### Open Question 3
- **Question:** Can the proposed transfer learning pipeline be adapted for decentralized environments where centralized training is prohibited by privacy constraints?
- **Basis in paper:** [Explicit] The authors note, "we aim to explore federated transfer learning for decentralized environments where privacy constraints prohibit centralized training."
- **Why unresolved:** The current methodology assumes the availability of both source and target datasets in a single location for training the Siamese network and autoencoder, a condition often violated in real-world inter-organizational security collaboration.
- **What evidence would resolve it:** A successful implementation of a Federated Learning (FL) version of the AAE, demonstrating that anomaly detection scores (nDCG/AUC) remain robust without sharing raw provenance graphs.

## Limitations

- Cross-domain transferability: The framework's generalizability to fundamentally different logging formats or APT behaviors remains untested due to reliance on DARPA TC data.
- Synthetic data quality: The use of cGANs and VAEs for augmenting rare attack scenarios introduces uncertainty about whether generated traces capture realistic APT patterns.
- Hyperparameter sensitivity: Critical values (e.g., α, β, γ in feature selection, temperature τ in contrastive loss, margin m in Siamese network) are set heuristically without sensitivity analysis.

## Confidence

- **High**: The overall framework design (XAI-guided feature selection + attention autoencoder + contrastive learning + Siamese alignment) is logically coherent and technically sound. The use of established metrics (nDCG, AUC) and statistical tests (Friedman, Wilcoxon) strengthens claim validity.
- **Medium**: Claims about outperformance over baselines are supported by experimental results, but the lack of ablation on synthetic data and hyperparameter sensitivity limits generalizability. The novelty of the combined approach is moderate, as individual components are well-established in other domains.
- **Low**: The specific contribution of each component (e.g., how much XAI feature selection vs. contrastive learning improves performance) is not rigorously isolated. The paper does not provide code or sufficient architectural details for full reproduction.

## Next Checks

1. **Ablation on synthetic data**: Compare model performance on real vs. synthetic attack traces to assess whether augmentation introduces artifacts or improves robustness.
2. **Hyperparameter sensitivity analysis**: Systematically vary α, β, γ in feature selection, τ in contrastive loss, and m in Siamese network to identify stable operating regimes and quantify impact on nDCG/AUC.
3. **External dataset validation**: Apply the framework to an independent APT dataset (e.g., from a different source or with different logging formats) to test cross-domain generalization beyond DARPA TC.