---
ver: rpa2
title: What's in the News? Towards Identification of Bias by Commission, Omission,
  and Source Selection (COSS)
arxiv_id: '2508.02540'
source_url: https://arxiv.org/abs/2508.02540
tags:
- news
- bias
- information
- articles
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel methodology for identifying bias by
  commission, omission, and source selection (COSS) in news articles as a joint three-fold
  objective. The approach uses a pipeline that analyzes text reuse through semantic
  similarity and paraphrase identification, moving beyond simple direct text copying
  to capture more subtle forms of information reuse.
---

# What's in the News? Towards Identification of Bias by Commission, Omission, and Source Selection (COSS)

## Quick Facts
- arXiv ID: 2508.02540
- Source URL: https://arxiv.org/abs/2508.02540
- Authors: Anastasia Zhukova; Terry Ruas; Felix Hamborg; Karsten Donnay; Bela Gipp
- Reference count: 12
- Key outcome: Novel methodology for identifying bias by commission, omission, and source selection (COSS) in news articles as a joint three-fold objective using semantic similarity and paraphrase detection

## Executive Summary
This paper presents a novel methodology for identifying media bias by commission, omission, and source selection (COSS) as interconnected phenomena. The approach uses a pipeline that analyzes text reuse through semantic similarity and paraphrase identification, moving beyond simple direct text copying to capture more subtle forms of information reuse. Unlike previous work that treated commission and omission biases separately using statistical approaches focused on direct reuse, this methodology operates at the paragraph level and incorporates polarity classification to track how information changes as it flows across different outlets.

The system extracts event-related articles, aligns text semantically, builds a graph of reuse patterns, analyzes these patterns for bias indicators, and visualizes the results. This enables both analysis of individual seed articles against related coverage and exploration of broader information flow patterns across collections of news articles, providing a more comprehensive view of how bias manifests through what is included, excluded, and whose voices are selected.

## Method Summary
The methodology presents a five-stage pipeline for identifying COSS bias in news articles. First, it retrieves candidate articles related to an event through query or seed document. Second, it performs source retrieval and text alignment using semantic similarity and paraphrase detection at the paragraph level, building a graph of reuse patterns. Third, it applies polarity classification to both outlet-inherited and content-derived labels. Fourth, it constructs a directed temporal graph where edges represent semantic similarity and time-based provenance. Finally, it analyzes patterns of bias and visualizes information flow, tracking how information transforms as it crosses ideological boundaries.

## Key Results
- Presents a novel methodology treating commission, omission, and source selection biases as interconnected rather than separate phenomena
- Moves beyond direct text copying to detect paraphrased reuse through semantic similarity analysis
- Operates at paragraph level with polarity classification to track information transformation across outlets
- Enables both individual article analysis and broader exploration of information flow patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Detecting paraphrased text reuse enables identification of bias patterns that direct copy-paste detection misses.
- Mechanism: The pipeline applies semantic similarity and paraphrase identification at the paragraph level, capturing conceptual reuse where wording differs but meaning persists. This reveals how information transforms as it crosses ideological boundaries.
- Core assumption: Bias manifests not just in what is copied verbatim, but in how information is selectively rephrased, reframed, or omitted across outlets with different polarities.
- Evidence anchors:
  - [abstract] "analyzes text reuse through semantic similarity and paraphrase identification, moving beyond simple direct text copying"
  - [section 1] "Especially when information is reused as paraphrases where different to the original source wording is used, which eventually leads to biased reporting"
  - [corpus] Related work "Unraveling Media Perspectives" validates combined LLM/topic modeling approaches for bias detection, suggesting semantic analysis is an active research direction, though no direct validation of this specific paraphrase-to-bias linkage exists.

### Mechanism 2
- Claim: Tracking polarity changes in reused text across outlets exposes commission and omission bias patterns.
- Mechanism: Each article receives an outlet-inferred polarity label (L/C/R), then individual paragraphs are independently polarity-classified. When text moves from a source article to a target article, shifts in paragraph-level polarity indicate editorial reframing—commission bias if slant is added, omission bias if certain passages are excluded.
- Core assumption: Paragraph-level polarity can be reliably detected by classifiers trained on balanced datasets, and divergence between outlet-inherited labels and content-derived labels signals editorial manipulation.
- Evidence anchors:
  - [section 2] "Polarity classification enables revisiting both original and reused paragraphs and checks if the outlet-inferred labels correspond to the labels from a polarity classifier"
  - [section 2] "Training a reliable classifier requires a large balanced dataset to incorporate variance of the biased language"
  - [corpus] "Media Bias Detector: A Framework for Annotating and Analyzing the News at Scale" suggests polarity/frame annotation at scale is feasible, but corpus lacks validation of paragraph-level granularity.

### Mechanism 3
- Claim: A directed graph of text reuse with temporal ordering enables source selection bias detection and provenance tracking.
- Mechanism: Articles and paragraphs form nodes; semantic similarity and temporal precedence form directed edges. This graph structure allows追溯信息来源 and identifying which outlets consistently amplify or suppress specific content streams.
- Core assumption: Information flows are largely unidirectional in time, and earlier-published articles are more likely sources than later ones.
- Evidence anchors:
  - [section 2] "The relations between the paragraphs encode the strength of semantic similarity between the paragraphs, and the time codes of the articles enforce a directed graph, which is required for source identification"
  - [section 2] "Analysis of the article's origin includes determining how many paragraphs originate from which sources with which polarities"
  - [corpus] Weak/missing—no corpus papers validate graph-based provenance for bias detection; this remains an untested architectural assumption.

## Foundational Learning

- Concept: **Media Bias Taxonomy (COSS)**
  - Why needed here: The paper's core contribution is treating commission (what's included), omission (what's excluded), and source selection (whose voice) as interconnected rather than isolated phenomena. Understanding this taxonomy is prerequisite to interpreting pipeline outputs.
  - Quick check question: Can you distinguish why an article quoting only conservative sources demonstrates a different bias type than one quoting balanced sources but using loaded adjectives?

- Concept: **Semantic Textual Similarity (STS) vs. Paraphrase Detection**
  - Why needed here: The pipeline moves beyond lexical overlap (TF-IDF, n-grams) to semantic alignment. STS produces continuous similarity scores; paraphrase detection makes binary same/different-meaning judgments. The paper appears to use both.
  - Quick check question: Would "The senator flip-flopped on healthcare" and "The senator changed positions on healthcare" receive high semantic similarity but different polarity scores?

- Concept: **Text Reuse in Journalism**
  - Why needed here: The pipeline exploits structural features of news production—pack journalism, newswire dependence, lack of citation norms—to identify provenance. Without this context, text alignment appears to solve a plagiarism problem rather than a bias problem.
  - Quick check question: Why might legitimate news aggregation (reusing AP wire content) produce false positive bias signals if source provenance isn't tracked?

## Architecture Onboarding

- Component map:
  ```
  Candidate Retrieval → Source Retrieval + Text Alignment → Polarity Classification
         ↓                        ↓                              ↓
    Event clustering      Paragraph-level semantic        Outlet-inherited +
    (query/time or seed)  similarity + paraphrase        content-derived labels
                                 ↓
                          Graph Construction
                          (nodes: articles/paragraphs,
                           edges: similarity + time)
                                 ↓
                          Pattern Analysis
                          (commission/omission/source stats)
                                 ↓
                          Visualization
                          (temporal flow + polarity shifts)
  ```

- Critical path: Text alignment quality determines all downstream analysis. If semantic similarity misidentifies paraphrases (false positives) or misses them (false negatives), polarity tracking and graph structure both propagate errors.

- Design tradeoffs:
  - Paragraph-level vs. sentence-level granularity: Paragraphs capture more context but may mix topics; sentences are cleaner but lose coherence.
  - Outlet-inherited vs. content-derived polarity: Inherited labels are cheap but coarse; content-derived labels require labeled training data and may misclassify neutral reporting on polarized topics.
  - Closed vs. open candidate retrieval: Closed sets (pre-collected articles) enable controlled evaluation; open retrieval (GDELT, CommonCrawl) introduces noise but scales.

- Failure signatures:
  - Dense similarity graphs where every paragraph connects to every other: semantic threshold too low or topic model insufficiently discriminative.
  - All paragraphs labeled "center": polarity classifier underfitting or training data imbalanced.
  - Temporal cycles in graph: timestamp extraction errors or simultaneous publication events.

- First 3 experiments:
  1. **Baseline alignment validation**: Manually annotate 50 article pairs for paraphrase relationships; measure precision/recall of semantic similarity threshold at 0.7, 0.8, 0.9. This calibrates the text alignment component before bias analysis.
  2. **Polarity classifier sanity check**: Train classifier on POLUSA or similar balanced dataset; evaluate on held-out articles where outlet polarity is known. If accuracy < 0.7, paragraph-level polarity tracking is unreliable.
  3. **Single-event pilot**: Select one well-documented news event (e.g., a presidential debate) with 20-30 articles across the political spectrum. Run full pipeline, manually verify that graph shows expected information flow (wire services → national outlets -> local/opinion pieces), and check whether omission patterns align with editorial stances.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does identifying bias by commission, omission, and source selection jointly yield more accurate results than treating these bias types separately?
- Basis in paper: [explicit] The paper contrasts its "joint three-fold objective" against "previous work separately addressing these types of bias"
- Why unresolved: The paper presents a concept methodology without empirical evaluation comparing joint vs. separate approaches
- What evidence would resolve it: Comparative evaluation on benchmark datasets measuring precision/recall for each bias type against baseline methods

### Open Question 2
- Question: How accurately can semantic paraphrase detection identify bias-relevant text reuse in news?
- Basis in paper: [explicit] "Unlike most existing methods for text alignment that identify copy-pastes or word permutations, we focus on identifying paraphrased sentences or paragraphs that convey the same message but use different and possibly loaded wording"
- Why unresolved: Paraphrase detection at the paragraph level with attention to loaded wording is more complex than direct text reuse, and no accuracy metrics are provided
- What evidence would resolve it: Evaluation on annotated news pairs with known paraphrase relationships and bias modifications

### Open Question 3
- Question: Can outlet-inferred polarity labels reliably predict article and paragraph-level political slant?
- Basis in paper: [inferred] The methodology assigns "a polarity label induced from an outlet" to each article, assuming outlet-level labels reflect article content, yet also notes the need to check if labels "correspond to the labels from a polarity classifier"
- Why unresolved: Outlets publish diverse viewpoints; coarse outlet-level labels may introduce noise into bias detection
- What evidence would resolve it: Correlation analysis between outlet-inferred labels and human-annotated paragraph-level polarity labels

### Open Question 4
- Question: What ground truth methodology can validate automatically detected bias by omission?
- Basis in paper: [inferred] The paper acknowledges bias analysis should identify "which parts of the source articles were not picked up" and "excluded from discussions," but determining what constitutes a meaningful omission requires external criteria
- Why unresolved: Defining omission bias requires establishing what information should have been included, which is inherently subjective
- What evidence would resolve it: Expert annotation protocols with clear guidelines defining notable omissions, validated through inter-rater agreement studies

## Limitations
- No quantitative performance metrics reported for any pipeline component, making accuracy assessment impossible
- Specific semantic similarity thresholds and paraphrase detection models are not specified
- No training or evaluation data provided for reproduction
- Outlet-inherited polarity labels remain untested for reliability in representing article-level bias

## Confidence
- High confidence: The three-fold COSS taxonomy (commission, omission, source selection) provides a useful framework for understanding media bias as interconnected phenomena rather than isolated issues.
- Medium confidence: The pipeline architecture is logically structured and addresses limitations of previous work by incorporating semantic analysis beyond direct text copying.
- Low confidence: The practical effectiveness of the approach—accuracy of paraphrase detection, polarity classification, and resulting bias identification—cannot be assessed without empirical validation.

## Next Checks
1. **Paraphrase Detection Validation**: Manually annotate 50 article pairs to measure precision/recall of semantic similarity threshold at multiple levels (0.7, 0.8, 0.9) to calibrate text alignment accuracy before bias analysis.
2. **Polarity Classifier Evaluation**: Train and evaluate paragraph-level polarity classifier on POLUSA or similar dataset; require accuracy >0.7 before proceeding to bias tracking analysis.
3. **Single-Event Pilot Study**: Run complete pipeline on 20-30 articles covering one well-documented news event; manually verify graph structure shows expected information flow patterns and that omission patterns align with known editorial stances.