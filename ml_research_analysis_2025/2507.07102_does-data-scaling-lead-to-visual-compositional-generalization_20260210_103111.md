---
ver: rpa2
title: Does Data Scaling Lead to Visual Compositional Generalization?
arxiv_id: '2507.07102'
source_url: https://arxiv.org/abs/2507.07102
tags:
- concept
- combinations
- compositional
- generalization
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether scaling data and model size improves
  compositional generalization in vision models. The authors design controlled experiments
  to isolate the effects of data scale, concept diversity, and combination coverage
  on compositional generalization.
---

# Does Data Scaling Lead to Visual Compositional Generalization?

## Quick Facts
- **arXiv ID**: 2507.07102
- **Source URL**: https://arxiv.org/abs/2507.07102
- **Reference count**: 40
- **Primary result**: Compositional generalization is driven by data diversity rather than scale alone, and linearly factored representations enable efficient compositional learning.

## Executive Summary
This paper investigates whether scaling data and model size improves compositional generalization in vision models. The authors design controlled experiments to isolate the effects of data scale, concept diversity, and combination coverage on compositional generalization. They find that compositional generalization is driven by data diversity rather than scale alone. Increased combinatorial coverage forces models to discover linearly factored representations, where concepts decompose into additive components. The authors prove that this structure is key to efficiency, enabling perfect generalization from few observed combinations. Evaluation of pretrained models (DINO, CLIP) shows above-random yet imperfect performance, suggesting partial presence of this structure.

## Method Summary
The paper introduces an (n, k) framework to control data diversity and coverage in synthetic datasets (dSprites, Shapes3D). Here, n represents the number of concept values per attribute, and k represents the number of observed training combinations per value. Models (ResNet-50, ViT) are trained with two separate linear heads to classify images by two attributes. The key insight is that increasing k (scale) improves in-distribution accuracy but not out-of-distribution generalization, while increasing n (diversity) forces models to learn linearly factored representations that enable compositional generalization. The authors also prove theoretically that linearly factored representations allow perfect generalization from minimal samples (k=2).

## Key Results
- Compositional generalization is driven by data diversity, not mere data scale.
- Models exhibit three phases of feature learning: spurious features → non-linear features → linearly factored representations only under high diversity.
- Linearly factored representations enable perfect generalization from minimal observed combinations (k=2).
- Pretrained models (DINO, CLIP) show above-random yet imperfect compositional generalization, suggesting partial linear factorization.

## Why This Works (Mechanism)

### Mechanism 1: Diversity-Induced Linear Factorization
When training data covers a high percentage of possible concept combinations, "shortcut" solutions become insufficient. The model is compelled to organize the latent space such that complex concepts decompose into additive components. This transition from memorizing spurious correlations to learning linearly factored representations is driven by data diversity rather than scale.

### Mechanism 2: Minimal Sample Efficiency via Algebraic Structure
If representations are perfectly linearly factored, a model requires observing only two combinations (k=2) per concept value to theoretically guarantee perfect generalization to all unseen combinations. A linearly factored space allows the recovery of individual concept vectors by solving a system of linear equations derived from observed joint embeddings.

### Mechanism 3: Partial Structure in Pretrained Models
Large-scale pretrained models (DINO, CLIP) exhibit partial linear factorization, allowing for above-random but imperfect zero-shot compositional generalization. Pretraining on massive datasets implicitly encourages some structural alignment, but representations remain entangled enough that zero-shot performance lags behind models explicitly trained on high-diversity compositional data.

## Foundational Learning

- **The (n, k) Framework**: This experimental control unit separates "scale" (more samples of the same pairs) from "diversity" (more unique pairs). Quick check: If I double the number of images for 5 specific color-shape pairs, am I increasing n, k, or neither?
- **Linearly Factored Embeddings**: This target representational geometry defines the condition where the representation of a whole equals the sum of its parts. Quick check: Does a linearly factored representation imply that concept vectors must be orthogonal to each other?
- **Spurious Correlations (Shortcuts)**: This explains the failure mode under low diversity. Quick check: Why does high combinatorial coverage force the model to abandon these spurious correlations?

## Architecture Onboarding

- **Component map**: Synthetic dataset (dSprites/Shapes3D) → (n,k) sampling → ResNet-50/ViT backbone → Two linear heads → Oracle model selection
- **Critical path**: Data Construction → Sampling → Training → Evaluation
- **Design tradeoffs**: Scale vs. Diversity: Increasing raw sample count within limited combinations improves ID accuracy but rarely fixes OOD generalization. Linearity Check: Linear probes test inherent structure; MLP probes can unwrap non-linear structure but may mask lack of natural factorization.
- **Failure signatures**: High ID / Low OOD Gap indicates spurious features or non-linear features rather than linearly factored ones. Random-level OOD accuracy indicates the model entirely failed to bind concepts independently.
- **First 3 experiments**: 1) Baseline Failure: Train on n=3, k=2 with maximum data scaling, verify OOD accuracy remains low. 2) Diversity Scaling: Fix k=2, increase n, plot rise in OOD accuracy and emergence of high R² linearity scores. 3) Pretrained Check: Freeze CLIP ViT-L backbone, train linear probes on k=2 combinations, compare against theoretical "perfect generalization" baseline.

## Open Questions the Paper Calls Out

- Can the theoretical guarantee for efficient compositional learning be extended to representations that occupy low-dimensional subspaces rather than strictly linearly independent factors?
- How does the relationship between data diversity and linearly factored representations scale when models must compose more than two concepts simultaneously?
- Does the emergence of linearly factored representations hold in complex, multi-object scenes, or is it limited to the single-object setting studied?

## Limitations

- Theoretical claims about minimal sample efficiency (k=2) rely on strong assumptions about linear independence and perfect factorization that may not hold in realistic settings.
- Controlled synthetic datasets may not fully capture the complexity and noise of real-world compositional scenarios.
- Oracle model selection provides an upper bound on capability but doesn't reflect practical deployment scenarios where test labels are unavailable.

## Confidence

- **High Confidence**: Experimental finding that diversity drives compositional generalization more than scale alone.
- **Medium Confidence**: Theoretical proof that linearly factored representations enable perfect generalization from k=2 combinations relies on idealized assumptions.
- **Medium Confidence**: Observation that pretrained models show partial but imperfect compositional generalization is supported by experiments.

## Next Checks

1. Replicate the (n,k) framework experiments on natural image datasets (e.g., CUB, CompCars) to test whether the diversity-scaling findings generalize beyond synthetic data.
2. Compare oracle selection performance against practical criteria like validation accuracy to assess the gap between theoretical capability and practical deployment.
3. Investigate whether MLP probes (rather than linear probes) can better capture compositional structure in pretrained models.