---
ver: rpa2
title: Controlling Summarization Length Through EOS Token Weighting
arxiv_id: '2506.05017'
source_url: https://arxiv.org/abs/2506.05017
tags:
- length
- beam
- text
- arxiv
- summarization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of controlling the length of
  generated text summaries, a crucial aspect for various applications. The core method
  involves weighting the importance of the end-of-sentence (EOS) token in the cross-entropy
  loss function during training, which encourages the model to focus on correctly
  predicting when to stop the generation.
---

# Controlling Summarization Length Through EOS Token Weighting

## Quick Facts
- **arXiv ID**: 2506.05017
- **Source URL**: https://arxiv.org/abs/2506.05017
- **Reference count**: 33
- **Primary result**: EOS token weighting improves length control in abstractive summarization with minimal quality loss

## Executive Summary
This paper presents a simple yet effective method for controlling the length of generated text summaries by modifying the training objective. The approach involves weighting the importance of the end-of-sentence (EOS) token in the cross-entropy loss function, encouraging the model to focus on correctly predicting when to stop generation. Experiments demonstrate that this technique significantly improves adherence to length constraints across different model architectures (T5-base and Llama-2 7B) and decoding strategies, often without substantial quality degradation. The method is architecture-agnostic, easy to implement, and complementary to inference-time length control techniques.

## Method Summary
The core innovation is a modified cross-entropy loss function that applies higher weight to the EOS token during training. Specifically, the loss L₂ is calculated as -R/N Σ w_yₙ log p(yₙ), where w_yₙ = W if yₙ=EOS else 1, and R = N/(N+W-1) is a rescaling factor. This encourages the model to learn when to stop generation more accurately. The method is applied during fine-tuning on summarization datasets, with experiments using both fixed-length constraints (max 250 characters for CNN/DM) and dynamic length constraints where the desired length is prepended to the input. The technique works with various decoding strategies including greedy and beam search.

## Key Results
- On CNN/Daily Mail with T5-base and greedy decoding, EOS weight of 10 reduced summaries exceeding 250 chars from 9.8% to 5.4%
- Minimal quality degradation observed: ROUGE-2 dropped only from 14.7 to 14.5 with EOS weight of 10
- Method works across different model families (T5-base and Llama-2 7B) and decoding strategies
- Shows complementary behavior with inference-time length control methods

## Why This Works (Mechanism)
The method works by modifying the training objective to emphasize correct EOS prediction. By increasing the weight of the EOS token in the loss function, the model receives stronger gradient signals when it fails to stop at the appropriate time. This creates a bias toward earlier stopping during inference, effectively enforcing length constraints. The rescaling factor R ensures that the total loss magnitude remains comparable across different weight values, preventing training instability.

## Foundational Learning
- **Cross-entropy loss**: Standard loss function for sequence generation that measures prediction error at each token position. Why needed: Forms the baseline objective that gets modified by EOS weighting.
- **End-of-sentence (EOS) token**: Special token that signals the end of a sequence in language models. Why needed: The target for the length control mechanism.
- **Weighting in loss functions**: Technique of assigning different importance to different components of a loss. Why needed: Core mechanism for emphasizing EOS prediction.
- **Rescaling factor R**: Normalization term that maintains stable loss magnitude. Why needed: Prevents training instability when applying high weights to specific tokens.
- **Fine-tuning vs. training from scratch**: Process of adapting a pre-trained model to a specific task. Why needed: The method is applied during fine-tuning phase.
- **ROUGE score**: Metric for evaluating summarization quality by comparing n-gram overlap. Why needed: Primary quality metric used in evaluation.

## Architecture Onboarding

**Component Map**: Dataset -> Tokenizer -> Model (T5/Llama-2) -> Custom Loss -> Trainer -> Decoder -> Evaluation

**Critical Path**: Training data preparation → Tokenization → Modified loss computation → Parameter updates → Length-controlled generation → Quality evaluation

**Design Tradeoffs**: The method trades some generation flexibility for length control. Higher EOS weights provide better length adherence but may slightly reduce summary quality. The approach is complementary to inference-time methods rather than replacing them.

**Failure Signatures**: 
- Quality degradation when W is too high (>100)
- Reduced effectiveness on datasets with right-skewed length distributions
- Poor performance if weight is applied to all EOS predictions rather than only when ground truth is EOS

**Three First Experiments**:
1. Apply EOS weight of 10 to T5-base on CNN/DM and measure reduction in % summaries exceeding 250 chars
2. Test different EOS weights (W=1, 5, 10, 20, 50) to characterize the trade-off curve between length adherence and ROUGE scores
3. Evaluate the method with beam search decoding (beam=5) using length penalty -1, 0, +1 to assess complementarity with inference-time methods

## Open Questions the Paper Calls Out
The paper identifies several open questions, including the method's applicability to other text generation tasks beyond summarization, how dataset length distribution characteristics affect efficacy (noting reduced performance on XL-sum with right-skewed distribution), and why Llama-2 7B shows quality degradation with increased EOS weights while T5-base does not. The authors also note that their method focuses on upper bound enforcement rather than precise length matching, which represents a narrower objective than general length control.

## Limitations
- Effectiveness depends on the underlying dataset's length distribution characteristics
- Limited testing on very long summaries beyond a few hundred tokens
- Only validated on English language summarization tasks
- Quality-time trade-off curve for different weight values could be more thoroughly characterized
- Claims of architecture-agnostic applicability based on only two model families

## Confidence

**High Confidence**: The core technical claim that weighting the EOS token in the loss function improves adherence to maximum length constraints during decoding is well-supported by experimental results.

**Medium Confidence**: The assertion that the method has minimal impact on summary quality is supported, but the trade-off curve between length adherence and quality for different W values could be more thoroughly characterized.

**Low Confidence**: The claim of general applicability across diverse architectures and tasks beyond abstractive summarization is not directly validated in the paper.

## Next Checks
1. **Reproduce Fixed-Length Results**: Re-implement the EOS-weighted loss function and fine-tune T5-base on the filtered CNN/Daily Mail dataset (≤250 chars) using specified hyperparameters (W=10, lr=5e-5, greedy decoding). Verify reported reduction in % summaries exceeding limit (9.8% → 5.4%) and ROUGE-2 score (14.7 → 14.5).

2. **Test on Long Summaries**: Apply the method to a summarization dataset with longer target lengths (e.g., arXiv or GovReport) to evaluate if EOS weighting technique scales effectively for controlling summaries of several hundred to a thousand tokens.

3. **Evaluate Quality-Time Trade-off**: Systematically vary the EOS weight parameter W (e.g., W=1, 5, 10, 20, 50) and measure the full trade-off curve between length adherence (% over limit) and summary quality (ROUGE-1, ROUGE-2, ROUGE-L) to identify optimal balance for different application needs.