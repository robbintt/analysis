---
ver: rpa2
title: 'Anatomica: Localized Control over Geometric and Topological Properties for
  Anatomical Diffusion Models'
arxiv_id: '2511.20587'
source_url: https://arxiv.org/abs/2511.20587
tags:
- control
- geometric
- guidance
- anatomical
- topological
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Anatomica introduces an inference-time framework for controlling
  3D anatomical diffusion models based on localized geometric and topological properties.
  The method uses cuboidal control domains to extract substructures from voxelized
  segmentations and applies differentiable penalty functions to guide generation toward
  target constraints.
---

# Anatomica: Localized Control over Geometric and Topological Properties for Anatomical Diffusion Models

## Quick Facts
- arXiv ID: 2511.20587
- Source URL: https://arxiv.org/abs/2511.20587
- Reference count: 40
- Introduces Anatomica, a framework for localized geometric and topological control over 3D anatomical diffusion models using cuboidal domains and differentiable penalty functions.

## Executive Summary
Anatomica enables localized control over 3D anatomical diffusion models through cuboidal control domains that extract substructures from voxelized segmentations. The framework applies differentiable penalty functions based on geometric moments (size, shape, position) and topological features (connected components, loops, voids via persistent homology) to guide generation toward target constraints. By leveraging neural field decoders for efficient partial decoding from latent space, Anatomica achieves state-of-the-art performance in geometric fidelity and topological precision while maintaining computational efficiency. The approach works across diverse coordinate systems and scales, enabling compositional control over complex anatomical structures.

## Method Summary
Anatomica extends unconditional latent diffusion models with localized guidance through differentiable penalty functions. It trains a VAE (convolutional encoder + neural field decoder) and an unconditional 3D U-Net denoiser. During inference, control domains are specified via template grids with affine parameters, and substructures are extracted using L-parsing. Geometric constraints are enforced through moment-based potential functions, while topological constraints use persistent homology with preserve/suppress feature partitioning. The framework integrates these losses into the diffusion sampling loop via classifier-free guidance, enabling real-time control without retraining.

## Key Results
- Achieves state-of-the-art geometric fidelity across cardiac, aortic, spinal, and coronary datasets
- Enables precise topological control with Betti number precision improvements of up to 0.31
- Provides 10.4× speed improvement with localized L-parsing at low resolution while maintaining fidelity
- Successfully handles multi-scale control across diverse anatomical coordinate systems

## Why This Works (Mechanism)

### Mechanism 1
Localized geometric constraints steer diffusion sampling through differentiable moment-based measurements. The framework denoises to a clean latent prediction, decodes substructures via affine-transformed template grids, computes zeroth/first/second-order moments, and applies MSE-based potential functions. Adaptive mass weighting prevents gradient explosion in empty regions. Core assumption: denoiser's clean latent prediction enables meaningful geometric gradients. Break condition: near-zero mass regions cause unstable gradients; excessive guidance weights degrade quality.

### Mechanism 2
Topological properties are enforced through persistent homology by differentiating through persistence diagram coordinates. Birth/death thresholds and spatial coordinates for features are extracted, partitioned into preserve/suppress subsets based on desired Betti numbers, and guided via voxel intensity differences. Increased softmax temperature ensures gradient flow. Core assumption: persistence coordinates provide differentiable handles on topological structure. Break condition: high-resolution PH is computationally demanding; single-voxel voids may be undetected at coarse resolutions.

### Mechanism 3
Neural field decoders enable efficient partial decoding from latent space by querying arbitrary point grids. Instead of full-volume reconstruction, an MLP takes latent points plus positionally-encoded query coordinates to output class probabilities. Coarse L-parsing decodes globally at low resolution for invariant properties, while localized L-parsing achieves high effective resolution with small grids. Core assumption: neural field decoder generalizes from full-resolution training. Break condition: very low resolutions trade fidelity for speed; minor fidelity reduction vs convolutional decoder.

## Foundational Learning

- **Concept: Persistent Homology and Betti Numbers**
  - Why needed here: Topological guidance assumes understanding of filtration, Betti numbers (B0=components, B1=loops, B2=voids), and persistence intervals quantifying topological significance.
  - Quick check question: Given a binary segmentation of a torus, what would B0, B1, B2 be? How would the persistence diagram change as you threshold the torus at increasing intensity levels?

- **Concept: Classifier-Free Guidance and Energy-Based Diffusion Steering**
  - Why needed here: Anatomica extends unconditional diffusion via gradient-based guidance; understanding how denoiser prediction combines with loss gradients, σ² scaling, and tradeoffs between guidance strength and sample diversity.
  - Quick check question: What happens to sample diversity as λ_geo or λ_topo increases? Why does the guidance term subtract σ²·∇L rather than add?

- **Concept: Neural Fields / Implicit Neural Representations**
  - Why needed here: L-parsing relies on MLPs mapping (latent code, coordinate) → value; understanding positional encoding, Fourier features for high-frequency detail, and trilinear latent interpolation.
  - Quick check question: Why can't a standard MLP learn high-frequency spatial variations without positional encoding? What determines the spatial resolution of a neural field's output?

## Architecture Onboarding

- **Component map:**
  1. Autoencoder: Convolutional encoder E: V → z; Neural field decoder F with positional encoding
  2. Unconditional Latent Diffusion Model: 3D U-Net denoiser D_θ trained via EDM/Karras formulation
  3. Control Domain Specification: Template grids X_temp with affine parameters A=[R, s, t]
  4. Substructure Parsing: Boolean subset operator U[u]; slice operators T_s (voxel) or T_l (latent)
  5. Measurement Modules: Geometric (moments + global transform); Topological (Cubical Ripser + preserve/suppress)
  6. Guidance Integration: Composite potential L = (1/K)Σ(λ_geo·L_geo + λ_topo·L_topo)

- **Critical path:**
  1. Train VAE with Dice-CE + KL loss (40 epochs, lr=1e-5)
  2. Train unconditional LDM with Karras schedule (50 epochs, lr=2.5e-5)
  3. Define selection vectors u, compute target control domains and geometric/topological targets
  4. At inference: denoise → parse K substructures → compute L → apply guided update
  5. Decode final latent to voxel map for evaluation

- **Design tradeoffs:**
  - Anatomica-V vs Anatomica-L: Convolutional decoder gives slightly better fidelity but 1.0× speed vs 10.4× for low-res L-parsing
  - Decoding resolution: High resolution improves topological precision but hurts speed quadratically
  - Guidance weights: Too low = weak control; too high = sample degradation
  - Softmax temperature: Higher temperature improves gradient flow for topological guidance

- **Failure signatures:**
  - Empty substructure warnings: Mass threshold not calibrated; check selection vector and control domain placement
  - Topological guidance ineffective: Softmax too low or decoding resolution too coarse; increase temperature and/or resolution
  - Geometric fidelity plateaus: Control domain may not cover target structure; verify affine transforms
  - Sample quality collapse: Guidance weights too high; reduce λ or check for conflicting constraints

- **First 3 experiments:**
  1. Single geometric control task (e.g., Right Ventricle): Implement Cartesian domain with target moments; sweep λ_geo ∈ {0.5, 1, 2} to establish baseline fidelity-speed tradeoff
  2. Ablate partial decoding resolution: Fix task and λ, vary resolution {16, 32, 64, 128}³ for both coarse and localized L-parsing; plot fidelity vs speed
  3. Single topological control task (e.g., Atrial Separation): Implement global domain with B0=2 prior; sweep softmax temperature {1, 2, 4, 8} at fixed λ_topo=5; measure Betti precision

## Open Questions the Paper Calls Out

- **Question 1**: Can automated loss weighting strategies eliminate manual tuning while maintaining control fidelity?
  - Basis: "The main limitation of our guidance approach is that loss weightings should be tuned to balance the contributions of each constraint"
  - Evidence: Empirically tuned weights transfer between datasets but require task-specific thresholds; no automatic balancing method proposed

- **Question 2**: Can high-resolution topological guidance be made computationally tractable through GPU-accelerated persistent homology?
  - Basis: "Computing persistent homology at high resolution is computationally demanding and limits the coarse decoding resolution for topological guidance"
  - Evidence: CPU-based Cubical Ripser forces resolution-speed trade-off that compromises void detection accuracy

- **Question 3**: How can single-voxel void artifacts be detected and eliminated at coarse decoding resolutions?
  - Basis: "Adherence to the number of voids is not improved for the aortic and vertebrae datasets, possibly due to the existence of single-voxel voids that are not easily detected at coarser measurement resolutions"
  - Evidence: Coarse L-parsing necessary for efficiency misses fine-grained topological features; no multi-scale PH strategy proposed

## Limitations

- Framework relies on partial neural field decoding, introducing fidelity-speed tradeoffs that may limit performance for fine-grained topological features
- Topological guidance effectiveness is constrained by computational demands of high-resolution persistence homology and potential loss of single-voxel features at coarse decoding resolutions
- Approach assumes moment-based geometric representations and persistence diagram coordinates provide sufficient differentiable handles on anatomical structure, which may not generalize to pathological cases

## Confidence

- **High**: Geometric control via moment-based differentiable penalties; neural field decoder implementation for partial extraction; localized control domain specification across coordinate systems
- **Medium**: Topological control effectiveness for higher-order Betti numbers; speed-accuracy tradeoffs at extreme resolution points; generalization to pathological anatomical variations
- **Low**: Computational scalability for high-resolution topological guidance; robustness to missing or merged substructures; impact of task-specific hyperparameter tuning on cross-dataset generalization

## Next Checks

1. **Cross-dataset generalization**: Apply Anatomica with fixed hyperparameters (λ_geo=1, λ_topo=5, softmax T=4) to all four anatomical tasks without retraining; measure geometric and topological precision to assess hyperparameter sensitivity

2. **Pathological case stress test**: Evaluate topological guidance on synthetic segmentations containing small (<5 voxel) connected components or loops; compare Betti precision at 32³ vs 64³ decoding resolutions to quantify resolution-dependent performance gaps

3. **Runtime scaling analysis**: Measure guidance loop computation time as a function of control domain resolution and topological persistence threshold; verify computational overhead remains sublinear in domain resolution as claimed