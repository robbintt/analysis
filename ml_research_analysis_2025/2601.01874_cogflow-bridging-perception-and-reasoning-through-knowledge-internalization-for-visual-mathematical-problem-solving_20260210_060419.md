---
ver: rpa2
title: 'CogFlow: Bridging Perception and Reasoning through Knowledge Internalization
  for Visual Mathematical Problem Solving'
arxiv_id: '2601.01874'
source_url: https://arxiv.org/abs/2601.01874
tags:
- reasoning
- visual
- perception
- zhang
- internalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the challenge of visual mathematical problem
  solving, where existing models struggle with accurate visual perception and faithful
  integration of extracted visual cues into reasoning. To address this, the authors
  propose CogFlow, a three-stage framework that mirrors human cognitive reasoning:
  perception, knowledge internalization, and reasoning.'
---

# CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving

## Quick Facts
- arXiv ID: 2601.01874
- Source URL: https://arxiv.org/abs/2601.01874
- Reference count: 40
- Primary result: 66.0% accuracy on FlowVerse, surpassing all open-source baselines

## Executive Summary
CogFlow addresses the challenge of visual mathematical problem solving by introducing a three-stage framework that mirrors human cognitive reasoning: perception, knowledge internalization, and reasoning. The method uses synergistic visual rewards for enhanced perception, a knowledge internalization reward to bridge perception and reasoning, and visual-gated policy optimization for grounded reasoning. The framework achieves state-of-the-art performance on multiple visual mathematical reasoning benchmarks, demonstrating the importance of perception-reasoning alignment and providing a scalable solution for visual mathematical reasoning tasks.

## Method Summary
CogFlow is a three-stage framework for visual mathematical problem solving that uses synergistic visual rewards for perception, knowledge internalization rewards for reasoning fidelity, and visual-gated policy optimization. The method trains on MATHCOG dataset (120K+ samples) with structured perception-reasoning-answer format, using Qwen2.5-VL-7B base model with two-stage training (SFT then VGPO RL). The framework achieves improved accuracy by enforcing alignment between visual perception and reasoning through multiple reward signals and a visual gate that filters low-quality perception trajectories before reasoning.

## Key Results
- Achieves 66.0% accuracy on FlowVerse benchmark, surpassing all open-source baselines
- Demonstrates 53.9% accuracy on MathVerse benchmark
- VGPO module emerges as most influential, yielding largest single-module gain
- Visual gate achieves comparable accuracy to best-of-3 responses while reducing inference time by ~46%

## Why This Works (Mechanism)

### Mechanism 1: Synergistic Visual Rewards for Perception Fidelity
- Claim: Dual-space visual rewards (parametric + semantic) improve perceptual accuracy more than single-space rewards alone
- Core assumption: Ground-truth primitive annotations exist and can be rendered; parametric and semantic spaces provide orthogonal supervision signals
- Evidence anchors: Adding either VSR or VPR consistently improves both CoT-E and final accuracy; best results from combining VSR and VPR

### Mechanism 2: Knowledge Internalization Reward Prevents Reasoning Drift
- Claim: Training reward model on contrastive positive-negative trajectory pairs reduces reasoning drift by rewarding faithful visual cue integration
- Core assumption: Five error types capture primary perception-reasoning alignment failures; Softmax-DPO provides denser supervision than standard DPO
- Evidence anchors: Removing any single error type consistently degrades performance; Softmax-DPO achieves best results (66.0%/56.2% on FlowVerse)

### Mechanism 3: Visual-Gated Policy Optimization Anchors Reasoning to Perception
- Claim: Visual gate that conditionally regenerates low-quality perception trajectories before reasoning improves multi-step reasoning stability
- Core assumption: Perception quality is necessary for correct reasoning; filtering low-quality perceptions prevents error propagation
- Evidence anchors: VGPO emerges as most influential module; visual gate achieves nearly same accuracy as best-of-3 while requiring substantially less inference time

## Foundational Learning

- **Hungarian Algorithm for Optimal Assignment**
  - Why needed: VPR uses Hungarian matching to establish optimal one-to-one correspondence between predicted and ground-truth primitives before computing distance
  - Quick check: Given cost matrix C[i,j] for assigning predicted point P_j to ground-truth point G_i, what does Hungarian algorithm output guarantee?

- **Direct Preference Optimization (DPO) and Softmax-DPO**
  - Why needed: IntlzR uses Softmax-DPO to contrast one positive against multiple negatives simultaneously, providing denser supervision than binary DPO
  - Quick check: In standard DPO, loss contrasts one preferred vs. one dispreferred response. How does Softmax-DPO's m-negative formulation change the gradient signal?

- **Group Relative Policy Optimization (GRPO)**
  - Why needed: VGPO builds on GRPO's group-level advantage normalization but adds visual gating. Understanding GRPO's baseline estimation is prerequisite
  - Quick check: In GRPO, advantage A_i = (r_i - μ_group) / σ_group. Why does this eliminate the need for a separate value network?

## Architecture Onboarding

- Component map: Input (Image + Question) → [Perception Stage] → <WATCHING> (primitives) → [Visual Gate] → [Internalization Stage] → [Reasoning Stage] → <THINKING> + <ANSWER> → [Reward Computation] → [VGPO Update]

- Critical path: Perception → Visual Gate → Internalization → Reasoning. If perception fails, visual gate should trigger regeneration. Weak internalization (low IntlzR) causes reasoning drift even with correct perception

- Design tradeoffs:
  1. VPR vs. VSR weight (α=0.6 optimal): Higher α emphasizes geometric precision; lower emphasizes holistic coherence
  2. Visual gate threshold (τ): High τ reduces false positives but increases regeneration cost; low τ allows errors through
  3. Perception sampling (k=3 optimal): Higher k improves selection but increases compute

- Failure signatures:
  1. Perception Error (~21% baseline): Incorrect primitive coordinates. Signature: VPR low, VSR may still be high
  2. Reasoning Drift: Coherent-looking chain contradicting visual evidence. Signature: IntlzR low even when SynVRs high
  3. Format Error: Missing tags. Signature: InfR returns 0

- First 3 experiments:
  1. Ablate SynVRs components: Train with VPR-only, VSR-only, and both. Verify combination outperforms either alone (Figure 5). Check perception F1
  2. Calibrate visual gate threshold: Sweep τ ∈ {0.3, 0.5, 0.7}. Plot pass rate vs. accuracy trade-off. Verify inference-time gate provides ~0.6-1% gain without VGPO training
  3. Test IntlzR generalization: Evaluate trained IntlzR on held-out error types. Check if model generalizes to novel drift patterns or overfits to five defined types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the method of obtaining visual primitives be effectively expanded from geometric diagrams to general natural scenes?
- Basis in paper: Appendix A.4 states the authors plan to "expand our method (especially the method of obtaining visual primitives) to general scenes" using detection and segmentation models
- Why unresolved: Current framework relies on extracting specific geometric primitives (points, lines, circles) defined by parametric equations, which may not translate to unstructured semantics of natural images
- What evidence would resolve it: Successful application of CogFlow pipeline to general vision-language benchmarks (e.g., VQA) using unified primitive schema derived from segmentation masks

### Open Question 2
- Question: How can the computational demands of the multi-stage training pipeline be reduced to facilitate broader adoption?
- Basis in paper: Appendix A.4 lists training procedure's high computational cost and reliance on large-scale resources as primary limitation hindering adoption
- Why unresolved: Framework requires sequential SFT and complex RL phases with Visual-Gated Policy Optimization strategy, significantly more expensive than standard fine-tuning
- What evidence would resolve it: Development of more efficient training scheme (e.g., parameter-efficient fine-tuning or distillation) achieving competitive accuracy without extensive GPU hours

### Open Question 3
- Question: Is the Knowledge Internalization Reward (IntlzR) robust to reasoning drift error types not included in five synthesized negative categories?
- Basis in paper: Section 3.2 and Appendix B.2.3 describe training IntlzR using only five specific, manually synthesized error types
- Why unresolved: Reward model trained on fixed synthetic negatives might overfit to these patterns and fail to penalize novel or complex forms of hallucination found in real-world model outputs
- What evidence would resolve it: Ablation study evaluating model's ability to detect and penalize "unseen" drift errors in zero-shot manner on out-of-distribution datasets

## Limitations

- Missing critical hyperparameters: Visual gate threshold τ, VPR penalty weights λ_FN/λ_FP, and FG-CLIP encoder weights are unspecified, blocking faithful reproduction
- Reward model generalization concerns: IntlzR trained on 5 specific error types without evaluation on novel drift patterns, potentially limiting transfer to other visual reasoning tasks
- Computational scalability issues: Method requires 16× A100 GPUs and 5.52 hours inference time, raising questions about deployment to larger models or production environments

## Confidence

- **High confidence**: Visual gate effectiveness (empirical results show consistent gains), SynVRs component benefits (Figure 5 shows VPR+VSR > either alone), overall accuracy improvements over baselines
- **Medium confidence**: IntlzR generalization to novel error types (limited cross-dataset validation), perception-reasoning alignment claims (relies on self-reported error analysis), Softmax-DPO advantage (no comparison to standard DPO on same data)
- **Low confidence**: Reproducibility without missing hyperparameters, scalability claims (computational costs not analyzed), claim that framework "mirrors human cognitive reasoning" (no cognitive science validation)

## Next Checks

1. **Threshold Sensitivity Analysis**: Systematically vary τ across [0.3, 0.5, 0.7] and measure trade-offs between acceptance rate and accuracy. Verify that visual gate provides 0.6-1% gain without VGPO training as claimed

2. **IntlzR Generalization Test**: Evaluate trained IntlzR on held-out error types not in the original 5 categories. Measure performance drop to quantify overfitting vs. generalization capability

3. **Component Isolation Ablation**: Conduct controlled experiments ablating each reward component (SynVRs, IntlzR, InfR) independently with VGPO, measuring marginal contribution to final accuracy