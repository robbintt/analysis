---
ver: rpa2
title: Predicting Stock Price Movement with LLM-Enhanced Tweet Emotion Analysis
arxiv_id: '2510.03633'
source_url: https://arxiv.org/abs/2510.03633
tags:
- emotion
- stock
- price
- significant
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops a deep learning framework to predict significant
  next-day stock price movements by integrating emotion features extracted from tweet
  data with historical stock price information. A large language model (LLaMA 3.1-8B-Instruct)
  preprocesses tweet content to improve emotion feature quality, which is then combined
  with daily stock prices to train an LSTM model.
---

# Predicting Stock Price Movement with LLM-Enhanced Tweet Emotion Analysis

## Quick Facts
- arXiv ID: 2510.03633
- Source URL: https://arxiv.org/abs/2510.03633
- Reference count: 9
- Key result: LSTM model with LLM-enhanced emotion features increases prediction accuracy for significant next-day stock price movements from 13.5% to 38.5%

## Executive Summary
This study develops a deep learning framework to predict significant next-day stock price movements by integrating emotion features extracted from tweet data with historical stock price information. A large language model (LLaMA 3.1-8B-Instruct) preprocesses tweet content to improve emotion feature quality, which is then combined with daily stock prices to train an LSTM model. Three emotion analysis methods—DistilRoBERTa, NRC Emotion Intensity Lexicon, and NRC Emotion Label Lexicon—are evaluated. Results show that incorporating emotion features improves prediction accuracy, with the DistilRoBERTa-based model with LLaMA preprocessing achieving the highest performance.

## Method Summary
The method involves preprocessing tweets using LLaMA 3.1-8B-Instruct to filter non-emotive content, then extracting emotion features using either DistilRoBERTa or NRC lexicons. These emotion features are aggregated into daily averages and concatenated with daily stock price data (Open, High, Low, Close, Volume). A 2-layer LSTM with 128 hidden units and 0.2 dropout processes the combined features to predict next-day stock price movement categories (Significant Increase, Significant Decrease, Stable). The model is trained using Adam optimizer with learning rate 0.01, batch size 32, for 200 epochs, evaluated on a chronological 70/30 split.

## Key Results
- LSTM baseline accuracy for predicting significant price movements: 13.5%
- LSTM with LLaMA-filtered DistilRoBERTa emotion features: 38.5% accuracy
- LSTM with LLaMA-filtered NRC-Intensity emotion features: 29.8% accuracy
- LSTM with LLaMA-filtered NRC-Label emotion features: 33.2% accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-based preprocessing enhances emotion feature quality by filtering non-emotive content.
- Mechanism: LLaMA 3.1-8B-Instruct processes raw tweets using a prompt to identify emotion-related words. Tweets labeled "no emotion" are removed, reducing noise from irrelevant chatter. This filtered dataset allows downstream emotion classifiers (e.g., DistilRoBERTa) to operate on a higher signal-to-noise ratio input.
- Core assumption: Raw financial tweets contain significant noise that degrades emotion analysis performance, and an LLM can reliably distinguish between emotive and non-emotive content in a financial context.
- Evidence anchors:
  - [abstract]: "We utilize Meta's Llama 3.1-8B-Instruct model to preprocess tweet data, thereby enhancing the quality of emotion features..."
  - [section 3.1]: "Tweets that return 'no emotion' are removed (LLaMA-based emotion filtering)."
  - [corpus]: Weak direct corpus evidence for this specific LLM-preprocessing mechanism; related work uses LLMs for direct analysis.

### Mechanism 2
- Claim: Aggregated daily emotion scores provide predictive signal for significant next-day stock price movements.
- Mechanism: Tweet-level emotion scores are aggregated into daily averages, reflecting the collective emotional tone of investors. These scores are concatenated with daily stock price features, providing the LSTM with information about market sentiment that price history alone lacks.
- Core assumption: Publicly expressed emotion on social media is correlated with future trading behavior and subsequent price volatility.
- Evidence anchors:
  - [abstract]: "Results show that incorporating emotion features improves prediction accuracy..."
  - [table 3/4 results]: Show distinct improvement in "Average S-I & S-D" accuracy when emotion features are added across all three methods.
  - [corpus]: Related work (Bollen et al., 2011; Nguyen et al., 2015) supports the general link between social sentiment and stock movement.

### Mechanism 3
- Claim: Contextual emotion classification outperforms lexicon-based methods for financial text.
- Mechanism: DistilRoBERTa, fine-tuned on emotion data, captures context-dependent emotional nuances (e.g., sarcasm, negation) in tweets. This produces more accurate emotion probability scores than simple keyword matching against a lexicon like NRC.
- Core assumption: Financial text contains context-dependent emotional expressions that keyword-based lexicons fail to capture accurately.
- Evidence anchors:
  - [abstract]: "The DistilRoBERTa-based model... achieves the best performance..."
  - [table 3/4 results]: DistilRoBERTa consistently achieves the highest "Average S-I & S-D" accuracy (38.5% with LLaMA enhancement) compared to NRC methods.
  - [corpus]: Weak evidence; corpus neighbors focus on different architectures.

## Foundational Learning

- Concept: Long Short-Term Memory (LSTM)
  - Why needed here: To model the sequential dependencies in the time-series data (stock prices) and learn patterns that predict future states based on a sequence of past observations.
  - Quick check question: How does an LSTM's gating mechanism (input, forget, output gates) help it capture long-term dependencies compared to a standard RNN?

- Concept: Feature-level Fusion
  - Why needed here: To combine two fundamentally different data types—numerical time-series (prices) and text-derived features (emotion scores)—into a single, unified input tensor for the predictive model.
  - Quick check question: In this paper, are the emotion features and price features processed by separate sub-networks before fusion, or are they concatenated directly?

- Concept: Prompt Engineering
  - Why needed here: To guide the LLaMA LLM to perform the specific task of emotion extraction and filtering according to the study's requirements, rather than open-ended text generation.
  - Quick check question: What specific instruction in the paper's prompt template ensures the LLM provides a structured output suitable for filtering?

## Architecture Onboarding

- Component map: Data Sources -> LLM Preprocessor -> Emotion Encoder -> Feature Aggregator -> Predictive Core
- Critical path: The **LLM Preprocessing** step is the novel contribution. The quality of emotion filtering (Step 2) directly impacts the daily emotion feature vector (Step 4), which is the key to the model's improved accuracy over the baseline.
- Design tradeoffs:
  - **LLM Cost vs. Accuracy**: Using an 8B parameter LLM for preprocessing is computationally expensive. This tradeoff is accepted for higher emotion feature quality.
  - **Transformer vs. Lexicon**: The paper demonstrates a tradeoff between complexity and performance, choosing the more complex DistilRoBERTa for its superior accuracy.
  - **3-Class Problem**: Defining movement based on standard deviation creates an imbalanced dataset ("Stable" is dominant), making the "Significant Increase/Decrease" classes harder to predict.
- Failure signatures:
  - **High Stable Accuracy, Low S-I/S-D Accuracy**: Model is biased toward the majority "Stable" class.
  - **Overfitting**: Training loss decreases but validation accuracy plateaus or drops, indicating the model has memorized the specific time period.
  - **No Improvement from LLM**: If LLaMA preprocessing does not improve metrics over standard NLTK preprocessing, the LLM component is not adding value.
- First 3 experiments:
  1. **Baseline Establishment**: Train the LSTM using only historical price features to confirm the baseline performance (Table 3, ~13.5% avg accuracy).
  2. **Ablation on Preprocessing**: Compare model performance using DistilRoBERTa features extracted from (a) raw tweets vs. (b) LLaMA-filtered tweets to isolate the contribution of the LLM.
  3. **Method Comparison**: Evaluate all three emotion analysis methods (DistilRoBERTa, NRC-Intensity, NRC-Label) on the LLaMA-filtered dataset to validate the paper's reported ranking.

## Open Questions the Paper Calls Out
None

## Limitations
- Data Recency and Domain Shift: The tweet dataset (2021-2022) may not generalize to current market conditions or different stocks, limiting real-world applicability.
- Black-Box Emotion Classification: While DistilRoBERTa shows superior performance, its internal reasoning for emotion assignment remains opaque, making it difficult to diagnose model failures or biases.
- Standard Deviation Threshold: The fixed standard deviation threshold for defining "significant" movements may not adapt well to changing market volatility regimes, potentially mislabeling true market shifts.

## Confidence
- **High Confidence**: The baseline LSTM model's architecture and training procedure are clearly specified and reproducible. The accuracy improvement from 13.5% to 38.5% when adding emotion features is directly supported by the results tables.
- **Medium Confidence**: The LLM preprocessing mechanism's contribution to accuracy is supported by results, but the specific impact of the filtering step versus the LLM's own emotion extraction capability remains unclear.
- **Low Confidence**: The generalizability of the model to different time periods, stocks, or market conditions is not tested, creating uncertainty about real-world deployment.

## Next Checks
1. **Temporal Robustness Test**: Retrain and evaluate the model on a more recent tweet dataset (e.g., 2023-2024) to assess temporal generalizability and identify potential concept drift.
2. **Ablation Study on LLM Components**: Create controlled experiments comparing (a) LLaMA preprocessing + DistilRoBERTa vs. (b) raw tweets + DistilRoBERTa vs. (c) LLaMA direct emotion extraction to isolate the specific value of each LLM component.
3. **Cross-Stock Validation**: Apply the trained model to predict movements for stocks not included in the original dataset to evaluate cross-stock generalization and identify domain-specific limitations.