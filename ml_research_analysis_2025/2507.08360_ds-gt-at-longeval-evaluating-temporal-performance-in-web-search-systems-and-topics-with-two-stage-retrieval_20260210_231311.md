---
ver: rpa2
title: 'DS@GT at LongEval: Evaluating Temporal Performance in Web Search Systems and
  Topics with Two-Stage Retrieval'
arxiv_id: '2507.08360'
source_url: https://arxiv.org/abs/2507.08360
tags:
- topic
- french
- query
- retrieval
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study addresses temporal drift in IR models trained on static
  datasets by evaluating performance across time-distributed web snapshots from Qwant.
  A two-stage retrieval system was implemented: BM25 keyword search with query expansion
  and Cross-Encoder reranking.'
---

# DS@GT at LongEval: Evaluating Temporal Performance in Web Search Systems and Topics with Two-Stage Retrieval

## Quick Facts
- **arXiv ID**: 2507.08360
- **Source URL**: https://arxiv.org/abs/2507.08360
- **Authors**: Anthony Miyaguchi; Imran Afrulbasha; Aleksandar Pramov
- **Reference count**: 16
- **Primary result**: Best system achieved NDCG@10 of 0.296 across full dataset, with peak of 0.395 on 2023-05 data

## Executive Summary
This study evaluates temporal performance in web search systems using Qwant's time-distributed web snapshots. The research implements a two-stage retrieval system combining BM25 keyword search with Cross-Encoder reranking, augmented by query expansion. Through topic modeling using NMF and LDA, the team conducts exploratory data analysis across temporal snapshots. The approach reveals significant performance degradation for content older than one year, indicating a regime change in the dataset, while demonstrating that reranking consistently improves retrieval effectiveness over BM25 alone.

## Method Summary
The research implements a two-stage retrieval architecture for temporal web search evaluation. The first stage employs BM25 with query expansion to retrieve relevant documents from time-sliced web snapshots. The second stage applies Cross-Encoder reranking to refine the initial results. The methodology includes comprehensive topic modeling using both NMF and LDA for exploratory analysis of content distribution across time periods. Performance is measured using NDCG@10 across the full dataset spanning multiple years, with particular attention to temporal patterns in retrieval effectiveness.

## Key Results
- Two-stage system achieved average NDCG@10 of 0.296 across complete dataset
- Peak performance reached NDCG@10 of 0.395 on 2023-05 snapshot
- Query expansion unexpectedly reduced performance compared to BM25 alone
- Significant performance drop observed for content older than one year, indicating regime change

## Why This Works (Mechanism)
None

## Foundational Learning
- **Temporal IR evaluation**: Understanding how information retrieval performance changes over time is crucial for building systems that remain effective as data distributions evolve
- **Two-stage retrieval**: Separating initial retrieval (BM25) from reranking (Cross-Encoder) allows specialized optimization of each stage while maintaining computational efficiency
- **Query expansion trade-offs**: While query expansion typically improves recall, it can introduce noise that degrades precision, especially in domains with evolving terminology
- **Topic modeling validation**: NMF and LDA provide complementary perspectives on document clustering, helping identify content shifts that may explain temporal performance changes
- **NDCG@10 limitations**: This metric focuses on top-10 results, potentially missing broader retrieval quality patterns in the full result set
- **Regime change detection**: Performance degradation patterns can signal fundamental shifts in data distribution requiring model adaptation

## Architecture Onboarding

**Component Map**: Web Snapshots -> BM25 Retrieval -> Query Expansion -> Cross-Encoder Reranking -> NDCG@10 Evaluation

**Critical Path**: The evaluation pipeline follows: temporal snapshot selection → BM25 keyword search → optional query expansion → Cross-Encoder reranking → NDCG@10 scoring. The Cross-Encoder stage is critical as it consistently improves performance over BM25 alone.

**Design Tradeoffs**: The two-stage architecture balances retrieval breadth (BM25) with ranking precision (Cross-Encoder), but adds computational overhead. Query expansion was included for potential recall benefits but proved detrimental, suggesting the dataset's temporal nature makes expansion less effective than in static corpora.

**Failure Signatures**: Performance degradation exceeding 20% for content older than one year indicates regime change rather than gradual drift. Query expansion failures manifest as lower NDCG@10 despite increased document recall.

**First Experiments**: 
1. Compare BM25 vs. BM25+query expansion baseline to isolate expansion impact
2. Evaluate Cross-Encoder reranking on top-100 vs. top-1000 BM25 results to find optimal cutoff
3. Test topic coherence across temporal splits to validate regime change hypothesis

## Open Questions the Paper Calls Out
None

## Limitations
- Most recent evaluation data is from May 2023, limiting assessment of longer-term temporal patterns
- Dataset shows significant performance degradation for content older than one year, suggesting unexplored regime changes
- Query expansion unexpectedly reduced performance without sufficient explanation for the counterintuitive result

## Confidence

**High Confidence**: The two-stage retrieval architecture (BM25 + Cross-Encoder) and its implementation details are well-documented and reproducible. The NDCG@10 metrics and their comparative analysis between stages are reliable.

**Medium Confidence**: The temporal analysis conclusions are reasonable but limited by the dataset's temporal distribution. The regime change interpretation is plausible but requires further validation with more recent data.

**Low Confidence**: The unexpected negative impact of query expansion needs deeper investigation, as the current analysis doesn't provide sufficient explanation for this counterintuitive result.

## Next Checks

1. Re-run the evaluation with more recent web snapshots (post-2023) to verify if the temporal performance patterns persist and to better understand the nature of the regime change.

2. Conduct ablation studies specifically focusing on the query expansion component to isolate whether the negative impact stems from the expansion method, the dataset characteristics, or interaction effects with other components.

3. Perform topic modeling validation by cross-referencing the NMF/LDA topic distributions with manual content analysis to ensure the automated topic discovery aligns with actual content themes.