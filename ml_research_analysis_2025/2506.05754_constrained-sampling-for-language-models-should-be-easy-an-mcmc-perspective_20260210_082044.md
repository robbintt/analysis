---
ver: rpa2
title: 'Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective'
arxiv_id: '2506.05754'
source_url: https://arxiv.org/abs/2506.05754
tags:
- distribution
- sampling
- constrained
- language
- mcmc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of constrained sampling from language
  models, where outputs must satisfy hard constraints (like syntactic validity) while
  preserving the model's underlying distribution. Existing approaches either distort
  the distribution or are inefficient.
---

# Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective

## Quick Facts
- **arXiv ID:** 2506.05754
- **Source URL:** https://arxiv.org/abs/2506.05754
- **Reference count:** 40
- **Primary result:** MCMC with grammar-constrained decoding achieves 2-5× lower KL divergence than existing methods and improves fuzzing coverage by 1.12-1.2×

## Executive Summary
This paper addresses the challenge of sampling from language models while satisfying hard grammatical constraints. Existing approaches either distort the model's distribution or are inefficient. The authors propose an MCMC-based framework using Metropolis-Hastings sampling with grammar-constrained decoding (GCD) proposals, ensuring all samples are constraint-satisfying by construction. The method achieves three key desiderata: constraint satisfaction, monotonic convergence to the true conditional distribution, and efficiency. Empirical evaluations show significant improvements over existing methods, with 2-5× lower KL divergence on synthetic benchmarks and 1.12-1.2× higher branch coverage in fuzzing experiments with real-world programs like SQLite and libxml2.

## Method Summary
The method uses Metropolis-Hastings MCMC with GCD proposals to sample from constrained language models. The proposal distribution selects a prefix position, fixes that prefix, and runs GCD to generate a grammar-valid continuation. The acceptance criterion uses the LM's likelihood to maintain convergence to the true conditional distribution. Three proposal strategies are evaluated: Uniform (random truncation), Priority (perplexity-weighted truncation), and Restart (always truncate at 0). The framework guarantees that all samples satisfy constraints while asymptotically converging to the LM's true conditional distribution over the constrained space.

## Key Results
- MCMC achieves 2-5× lower KL divergence than GCD and 4-9× lower than ASAp after 10 steps on synthetic benchmarks
- MCMC-Priority seeds achieve 1.12-1.2× higher branch coverage than GCD and ASAp in fuzzing experiments
- Better distributional convergence translates to more effective test generation for program fuzzing
- The method satisfies three desiderata: constraint satisfaction, monotonic convergence, and efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MCMC with GCD proposals guarantees every sample satisfies constraints while asymptotically converging to the LM's true conditional distribution
- Mechanism: Metropolis–Hastings constructs a Markov chain over the constrained language only. A proposal selects a prefix position, fixes that prefix, and runs GCD to generate a grammar-valid continuation. The acceptance ratio uses unnormalized P(w), satisfying detailed balance w.r.t. P_G. If p_POS(0)>0 for all states, the chain is irreducible and aperiodic, so total variation distance to P_G decreases monotonically to 0
- Core assumption: The LM provides tractable next-token likelihoods, and the grammar is context-free so GCD can enforce L(G) per step
- Evidence anchors: Abstract ("ensures principled and efficient exploration"), Algorithm 1 with Theorem 1 and 3 proofs, convergence results
- Break condition: If p_POS(0)=0 for some reachable state or GCD has bugs that leak invalid continuations, irreducibility and constraint satisfaction can fail

### Mechanism 2
- Claim: A prefix-based proposal family enables local refinements that mix faster than naive rejection and remains strictly grammar-valid
- Mechanism: Given current string w, sample index i from p_POS, keep w_1:i, and regenerate w'=GCD-prefix(w_1:i). Uniform encourages local edits; Priority targets high-uncertainty regions; Restart resets to GCD from scratch. This yields structured, grammar-aligned neighborhoods without ever leaving L(G)
- Core assumption: GCD can conditionally sample from any prefix in L(G), and perplexity is a useful proxy for where the model is misaligned with the grammar
- Evidence anchors: Abstract ("efficient"), Sec. 3.2 proposal family description, ablation results showing step counts and coverage improvements
- Break condition: If perplexity poorly reflects constraint-violating regions or GCD gets stuck near certain prefixes, mixing slows and chain may require many steps

### Mechanism 3
- Claim: Better distributional fidelity to P_G translates into higher fuzzing coverage because diverse, grammar-aligned seeds explore more execution paths
- Mechanism: The MCMC sampler reduces KL divergence to P_G within few steps, producing more diverse seeds than GCD or ASAp. Coverage-guided fuzzing benefits from structurally valid, diverse initial corpus; seeds closer to P_G yield higher branch/function/line coverage
- Core assumption: LMs are good prior generators for inputs that stress real-world parsers, and improved coverage is predictive of bug-finding potential
- Evidence anchors: Abstract ("outperforms existing methods on real-world program fuzzing"), Sec. 4.2 with Tables 2-3 and Figs. 3, 6-12 showing coverage improvements
- Break condition: If the grammar omits semantic constraints that cause parser crashes, or if the LM prior is misaligned with bug-triggering regions, improved distributional fidelity may not improve bug-finding

## Foundational Learning

- **Concept:** Metropolis–Hastings MCMC and detailed balance
  - Why needed here: The paper's entire sampler is built on MH; understanding acceptance ratios and why detailed balance ensures convergence is critical to grasp the proofs and tradeoffs
  - Quick check question: If π(y)/π(x) doubles while q(y|x)/q(x|y) halves, does the acceptance probability change?

- **Concept:** Grammar-Constrained Decoding (GCD) with context-free grammars
  - Why needed here: All proposals in this method use GCD to keep continuations valid; understanding prefix masking, parse-state tracking, and CFG handling is essential
  - Quick check question: Given a prefix that can be completed by multiple nonterminal expansions, how does GCD ensure only valid next-token extensions are sampled?

- **Concept:** Total variation distance and monotonic convergence for countable-state Markov chains
  - Why needed here: The paper's convergence guarantees rely on these concepts to claim monotonic decrease in distance to P_G
  - Quick check question: Why does aperiodicity plus irreducibility matter for the bound on ||P^k(·|x) - π||_TV?

## Architecture Onboarding

- **Component map:** Prompt and CFG spec -> GCD decoder engine (incremental parse states, token masking) -> MCMC controller (sample prefix position, propose via GCD, compute MH acceptance, update state) -> Evaluation layer (KL estimation, fuzzing harness AFL++)
- **Critical path:** GCD correctness and prefix-indexing; MH acceptance ratio implementation using log-likelihoods; proposal distribution choice and step budget k
- **Design tradeoffs:** Restart vs Uniform vs Priority - Restart mixes well but discards state; Uniform is simple; Priority targets uncertain regions but relies on perplexity proxy. Higher k improves fidelity at cost of more LM calls per sample
- **Failure signatures:** Zero acceptance rates (check perplexity scaling and proposal variance); invalid samples (GCD bug); stagnant coverage (seeds lack semantic diversity)
- **First 3 experiments:** 1) Reproduce KL curves on SLIA/BV4/CP comparing Uniform vs Priority vs Restart for k∈{2,5,10}; 2) Ablate p_POS: enforce p_POS(0)=0 for some lengths and observe non-convergence; 3) Run 1-hour fuzzing trial with AFL++ on SQLite using MCMC-Priority(k=10) vs GCD, recording coverage metrics

## Open Questions the Paper Calls Out

- **Open Question 1:** Can more sophisticated proposal distributions (e.g., gradient-informed or learned proposals) improve convergence speed beyond the three simple strategies tested?
  - Basis in paper: "While we only study three possible proposal distributions, our work opens the door for studying richer proposal mechanisms for MCMC"
  - Why unresolved: Only uniform, perplexity-prioritized, and restart proposals were evaluated; richer mechanisms remain unexplored
  - What evidence would resolve it: Empirical comparison of additional proposal strategies showing improved KL divergence

- **Open Question 2:** Why does the Restart proposal (which discards all state information) converge faster than proposals that leverage current state information?
  - Basis in paper: The authors note this is "a notable result, since conceptually Restart does not accumulate any information about previous states"
  - Why unresolved: This contradicts intuition that MCMC benefits from local exploration; the mechanism remains unexplained
  - What evidence would resolve it: Analysis of Markov chain mixing properties or empirical investigation into what makes Restart effective

- **Open Question 3:** Can MCMC-based constrained sampling be effectively integrated with beam search or nucleus sampling?
  - Basis in paper: "Integration with other decoding strategies such as beam or nucleus sampling" identified as future work
  - Why unresolved: Beam/nucleus sampling manipulate probabilities differently, potentially interacting unpredictably with MH acceptance
  - What evidence would resolve it: Modified algorithm integrating MCMC with these strategies, evaluated on benchmarks

- **Open Question 4:** Does effectiveness generalize across different model architectures, sizes, and training regimes?
  - Basis in paper: "Due to compute limitations, we only provide results for one model" (Llama-3.1-8B)
  - Why unresolved: Results may depend on this specific model; different architectures may show different convergence behavior
  - What evidence would resolve it: Experiments replicating evaluation across varying model sizes and architectures

## Limitations

- Theoretical guarantees rely on specific conditions (irreducibility, GCD correctness) that may not hold in practice
- Perplexity-based priority proposals assume perplexity reliably indicates constraint-violating regions
- Translation from improved distributional fidelity to bug-finding potential is plausible but not directly demonstrated
- Only one model architecture was evaluated due to compute limitations
- Grammar constraints may not capture all semantic requirements for real-world programs

## Confidence

**High Confidence:** Core MCMC framework with MH acceptance criteria and three desiderata (constraint satisfaction, monotonic convergence, efficiency) are well-established theoretically and supported by convergence proofs

**Medium Confidence:** Empirical claims about KL divergence improvements and fuzzing coverage gains are well-supported by experiments, though synthetic benchmarks may not capture full real-world complexity

**Medium-Low Confidence:** Translation from distributional fidelity to fuzzing bug-finding potential is plausible but not directly demonstrated - coverage improvements don't necessarily translate to actual bug discovery rates

## Next Checks

1. **Convergence verification:** Implement ablation where p_POS(0)=0 for some lengths and observe whether chain fails to converge or mixes slowly, confirming theoretical irreducibility requirement

2. **GCD correctness audit:** Perform systematic testing of GCD implementation to verify no invalid continuations are ever generated, especially at grammar boundary cases and ambiguous prefix scenarios

3. **Coverage-diversity correlation:** Run fuzzing experiments comparing MCMC samples against random valid samples from grammar (bypassing LM) to determine whether LM's distributional guidance actually improves coverage beyond pure grammar sampling