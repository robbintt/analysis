---
ver: rpa2
title: Comparative Analysis of CNN and Transformer Architectures with Heart Cycle
  Normalization for Automated Phonocardiogram Classification
arxiv_id: '2507.07058'
source_url: https://arxiv.org/abs/2507.07058
tags:
- heart
- cycle
- classification
- normalization
- signal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically compares CNN and transformer architectures
  for automated phonocardiogram classification, with a focus on heart cycle normalization.
  The PhysioNet2022 dataset is used to evaluate two CNN models (with fixed-length
  and heart cycle normalization) and two BEATs transformer models (with fixed-length
  and heart cycle normalization).
---

# Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification

## Quick Facts
- arXiv ID: 2507.07058
- Source URL: https://arxiv.org/abs/2507.07058
- Reference count: 35
- Primary result: CNN with fixed-length windowing achieves highest AUROC (79.5%), while BEATs transformer with heart cycle normalization shows improved performance (70.1% vs 65.7%)

## Executive Summary
This study systematically compares convolutional neural networks (CNNs) and transformer architectures for automated phonocardiogram classification, focusing on the impact of heart cycle normalization. Using the PhysioNet2022 dataset, the authors evaluate two CNN models and two BEATs transformer models under fixed-length and heart cycle normalization conditions. The research reveals that while the CNN with fixed-length windowing achieves the highest AUROC (79.5%), heart cycle normalization improves transformer performance but slightly degrades CNN results. This divergence suggests that physiological signal alignment affects different architectures differently, with transformers benefiting from the semantic structure preservation while CNNs are disrupted by the spectral artifacts introduced during time-domain stretching.

## Method Summary
The study compares four models on the PhysioNet2022 dataset (3163 PCG recordings from 816 patients): two CNN variants (fixed-length 8s window vs 10-cycle normalization) and two BEATs-kNN variants (fixed-length 7s window vs 12-cycle normalization). Preprocessing includes Butterworth bandpass filtering (25-500 Hz), min-max normalization, and data augmentation with 60% probability. The CNN uses 4 conv blocks (8→128 channels), adaptive pooling, and FocalLoss, trained for 60 epochs with AdamW/Adam optimizers. BEATs uses frozen pre-trained weights with k-NN classification in the embedding space. Heart cycle normalization requires S1-S1 annotations, limiting usable data to 51.7% of recordings. Models are evaluated using 10-fold patient-stratified cross-validation with AUROC as the primary metric.

## Key Results
- CNN with fixed-length windowing achieves highest AUROC (79.5%)
- BEATs transformer with heart cycle normalization shows improved performance (70.1% vs 65.7% fixed-length)
- Heart cycle normalization improves BEATs performance but slightly degrades CNN results
- Only 51.7% of recordings contained sufficient annotated cycles for normalization

## Why This Works (Mechanism)

### Mechanism 1
Heart cycle normalization improves transformer-based classification but degrades specialized CNN performance. The normalization process aligns variable-length heart signals to a fixed duration via time-domain stretching. This physiological alignment likely preserves the semantic structure that pre-trained audio transformers (BEATs) recognize from general audio tasks. However, the stretching operation introduces spectral artifacts and distortions that disrupt the local time-frequency patterns that specialized CNNs learn to depend on for high-resolution discrimination.

### Mechanism 2
Zero-shot transformers offer rapid development cycles at the cost of absolute accuracy compared to trained CNNs. The BEATs model uses frozen weights pre-trained on AudioSet and a simple k-NN classifier in the embedding space. This requires no gradient updates, relying instead on the proximity of embeddings. The CNN trains weights via backpropagation specifically to minimize Focal Loss on PCG spectrograms. The CNN effectively learns a "custom language" for heart sounds, while the transformer relies on a "general vocabulary," explaining the accuracy gap (79.5% vs 70.1%).

### Mechanism 3
Data utilization efficiency is a hidden constraint of heart cycle normalization. Cycle normalization requires complete S1-S1 annotations. Only 51.7% of recordings contained sufficient annotations. The CNN performance drop may be partially caused by this ~50% reduction in training data volume, rather than purely by the normalization method itself. The BEATs model, being pre-trained, is less sensitive to this training data reduction.

## Foundational Learning

- **Phonocardiogram (PCG) Morphology (S1/S2)**: Understanding that a heart cycle is not uniform noise but a sequence of discrete events (S1, systole, S2, diastole) is critical to grasping why "cycle normalization" is even possible. *Quick check: If a fixed window cuts a signal in the middle of a systolic murmur, how might that differ from a window that aligns perfectly to an S1 start point?*

- **Time-Frequency Trade-offs (STFT/Spectrograms)**: The paper modifies FFT size and hop length between fixed and cycle models. Understanding that FFT size affects frequency resolution vs. temporal resolution is necessary to interpret why the model hyperparameters changed. *Quick check: Why would the authors choose a larger FFT size (1152) for the cycle-normalized input compared to the fixed input (512)?*

- **Zero-Shot Learning & Embeddings**: The BEATs model is not "trained" in the traditional sense; it projects audio into a 768-dimension space. Understanding that classification happens by measuring distance in this space (k-NN) rather than decision boundaries learned via backpropagation is essential. *Quick check: Does the BEATs model update its weights when presented with a new patient's heart sound?*

## Architecture Onboarding

- **Component map**: Raw PCG → Bandpass Filter (25-500Hz) → Amplitude Normalization → Windowing (Fixed vs Cycle) → Feature Extraction (CNN: Mel Spectrogram → Conv Stack → FC Layers OR BEATs: Raw Audio → Frozen Transformer → 768-d Vector) → Classification (CNN: Softmax via Focal Loss OR BEATs: k-NN search)

- **Critical path**: The S1 Peak Annotation Quality is the single point of failure for the heart cycle normalization strategy. If the input dataset lacks these timestamps, the "Cycle" models cannot be trained without an auxiliary peak detector.

- **Design tradeoffs**:
  - Fixed Windowing: Maximal data utilization but potentially misaligned physiology; yields higher CNN accuracy
  - Cycle Normalization: Physiological alignment but ~50% data loss; yields higher Transformer accuracy but lower overall ceiling
  - Architecture: CNN (High accuracy, high compute/train time) vs. BEATs (Lower accuracy, minimal compute/train time)

- **Failure signatures**:
  - CNN + Cycle: Performance drop likely indicates time-stretching artifacts breaking learned features, or data loss is too severe
  - BEATs + Fixed: Low performance (65.7%) suggests general AudioSet embeddings struggle with arbitrary 7-second chunks

- **First 3 experiments**:
  1. Baseline Reproduction (Fixed CNN): Implement fixed-length windowing CNN to verify 79.5% AUROC benchmark
  2. Annotation Ablation: Run Cycle Normalization with synthetically degraded S1 annotations to quantify sensitivity to annotation density
  3. Embedding Visualization: Extract BEATs embeddings for both Fixed and Cycle-normalized inputs using t-SNE/UMAP to visualize cluster differences

## Open Questions the Paper Calls Out
1. Can robust automated cycle detection methods effectively replace manual annotations to improve data utilization in heart cycle normalization?
2. How do CNN and transformer architectures perform when expanded from binary to multi-class classification for differentiating specific cardiac pathologies?
3. Can ensemble methods combining CNNs and transformers leverage their complementary responses to normalization to achieve superior diagnostic performance?

## Limitations
- The reliance on manual S1-S1 annotations limits heart cycle normalization applicability to only 51.7% of the dataset
- The zero-shot BEATs approach achieves substantially lower accuracy (70.1% vs 79.5%) than the trained CNN
- The study does not address model calibration or probability calibration, which are critical for clinical decision-making

## Confidence
- **High Confidence**: The comparative AUROC results (79.5% for CNN fixed-length vs 70.1% for BEATs cycle-normalized) are reliable given the rigorous 10-fold patient-stratified cross-validation
- **Medium Confidence**: The mechanism explanations (time-stretching artifacts affecting CNNs differently than transformers) are plausible but not definitively proven
- **Low Confidence**: The claim that zero-shot transformers provide sufficient accuracy for clinical deployment is questionable given the 9.4 percentage point gap

## Next Checks
1. Implement automated S1 peak detection and compare model performance when using imperfect annotations versus the current manual-only approach
2. Train the CNN with augmented data using time-stretching operations to determine if performance degradation is specifically due to spectral artifacts
3. Evaluate model calibration curves and probability calibration metrics (ECE, Brier score) to determine if the BEATs transformer's lower accuracy translates to reliable uncertainty estimates suitable for clinical decision support