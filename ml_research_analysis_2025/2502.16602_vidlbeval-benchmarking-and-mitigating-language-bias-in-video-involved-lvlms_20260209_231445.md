---
ver: rpa2
title: 'VidLBEval: Benchmarking and Mitigating Language Bias in Video-Involved LVLMs'
arxiv_id: '2502.16602'
source_url: https://arxiv.org/abs/2502.16602
tags:
- video
- language
- lvlms
- bias
- video-involved
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses language bias in video-involved Large Vision-Language
  Models (LVLMs), where models prioritize language over video content, leading to
  incorrect responses. The authors introduce VidLBEval, a benchmark dataset designed
  to assess language bias through two tasks: Ambiguous Video Contrast (AVC) and Interrogative
  Question Probing (IQP).'
---

# VidLBEval: Benchmarking and Mitigating Language Bias in Video-Involved LVLMs

## Quick Facts
- arXiv ID: 2502.16602
- Source URL: https://arxiv.org/abs/2502.16602
- Authors: Yiming Yang; Yangyang Guo; Hui Lu; Yan Wang
- Reference count: 9
- Primary result: Introduces VidLBEval benchmark and Multi-branch Contrastive Decoding (MCD) to assess and reduce language bias in video-involved LVLMs

## Executive Summary
This paper addresses language bias in video-involved Large Vision-Language Models (LVLMs), where models prioritize language over video content, leading to incorrect responses. The authors introduce VidLBEval, a benchmark dataset designed to assess language bias through two tasks: Ambiguous Video Contrast (AVC) and Interrogative Question Probing (IQP). To mitigate this issue, they propose Multi-branch Contrastive Decoding (MCD), which introduces two expert branches—one focusing on video content and another retaining the original model process—to counteract the language bias potentially generated by the text-only branch. Experiments show that MCD effectively reduces language bias across multiple LVLMs, including VideoLLaVA, VideoLLaMA2, and VideoGPT+, while maintaining general-purpose capabilities without additional retraining or architectural changes.

## Method Summary
The authors propose Multi-branch Contrastive Decoding (MCD) as a training-free inference method to reduce language bias in video-involved LVLMs. MCD operates by computing three probability distributions during generation: an amateur branch that uses only text context, a weak expert branch that uses the original multimodal model, and a strong expert branch that amplifies attention on video tokens. These distributions are combined with weighting factors and then subjected to contrastive decoding, where the amateur branch's predictions are subtracted to penalize language-only reasoning. The method also includes an adaptive plausibility constraint to prevent generation of implausible tokens. MCD requires no retraining or architectural modifications, making it immediately deployable on existing LVLMs.

## Key Results
- MCD achieves significant improvements in Biased Visual Consistency (BVCrel: 44.31 vs 47.11 for VideoLLaVA) while maintaining Text Consistency Rate (TCR: 17.66)
- The method demonstrates generalization capability across multiple LVLMs including VideoLLaVA, VideoLLaMA2, and VideoGPT+
- MCD preserves general-purpose capabilities as measured by SEEDBench and MVBench without significant performance degradation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive decoding reduces language bias by penalizing text-only predictions that lack visual grounding.
- Mechanism: The MCD framework computes pmcd = (1+γ)p'θ(yt|v,x,y<t) - γpθ(yt|x,y<t), where the amateur branch pθ(yt|x,y<t) generates predictions using only textual context. By subtracting this distribution, tokens favored by language-only reasoning are downweighted, forcing the model to rely more heavily on video features present in the expert branch.
- Core assumption: Language bias manifests as predictable patterns in the text-only branch that can be identified and subtracted from the multimodal distribution without destroying valid linguistic reasoning.
- Evidence anchors:
  - [abstract]: "introducing two expert branches to simultaneously counteract language bias potentially generated by the amateur text-only branch"
  - [section 4.1]: Building on VCD, the contrastive approach has been shown to enhance visual understanding in image-based LVLMs; the authors extend this to video with additional modifications.
  - [corpus]: SDCD (arXiv:2601.03500) applies structure-disrupted contrastive decoding for hallucination mitigation, confirming the broader effectiveness of contrastive approaches for bias reduction. Attention Calibration (arXiv:2502.01969) similarly finds that vision token attention is systematically underweighted.
- Break condition: If the text-only branch produces accurate predictions for legitimate linguistic reasoning (e.g., commonsense inferences), contrastive subtraction may over-penalize correct outputs, degrading general capabilities.

### Mechanism 2
- Claim: Amplifying attention weights on video tokens during inference shifts model focus toward visual content without retraining.
- Mechanism: The video-enhanced branch modifies attention matrices before softmax by applying Ai = Ai + α|Ai| to video token positions, where α ≥ 0. This redistribution increases the attention mechanism's sensitivity to video features at each generation step, creating a "strong expert" that prioritizes visual grounding over parametric language knowledge.
- Core assumption: The original model's attention distribution underweights video tokens relative to their importance; this can be corrected by a fixed multiplicative boost without disrupting attention's ability to learn appropriate patterns.
- Evidence anchors:
  - [section 4.3]: "An amplification coefficient α >= 0 is then applied to the video tokens to control the step size for generation intervention"
  - [section 5.3]: Ablation shows the video-enhanced branch alone (VE=✓, OR=×) improves BVCrel from 47.11 to 44.31 on VideoLLaVA.
  - [corpus]: Modality Bias in LVLMs (arXiv:2508.02419) identifies that vision token attention is systematically suppressed, providing mechanistic justification for attention-based interventions.
- Break condition: Excessive α values may cause attention to over-focus on video features at the expense of question understanding, leading to irrelevant or incoherent responses.

### Mechanism 3
- Claim: Combining weak and strong expert branches with adaptive plausibility constraints preserves linguistic quality while reducing bias.
- Mechanism: The integrated expert p'θ = λpwθ + (1-λ)psθ balances the original model (weak expert) and video-enhanced branch (strong expert). An adaptive plausibility constraint Vhead(y<t) = {yt : pθ(yt|v,x,y<t) ≥ β·max_w pθ(w|v,x,y,t)} prevents generation of implausible tokens by zeroing probabilities outside this set.
- Core assumption: Neither expert alone is optimal; the weak expert maintains linguistic fluency while the strong expert provides visual grounding, and their combination yields better trade-offs than either alone.
- Evidence anchors:
  - [section 4.2]: "The integrated expert, denoted by p'θ, incorporates a weighting factor λ ∈ [0, 1] to balance the contributions of the two experts"
  - [section 4.2]: "This method refines the candidate pool, effectively preventing the generation of implausible tokens"
  - [corpus]: Corpus papers do not directly test multi-branch integration; this specific combination is proposed but not independently validated outside this work.
- Break condition: If λ is poorly calibrated for a specific model architecture, the balance may tilt toward either excessive bias (λ too high) or degraded fluency (λ too low).

## Foundational Learning

- Concept: Contrastive decoding in language models
  - Why needed here: MCD extends contrastive decoding from text-only LLMs to multimodal settings; understanding the base formulation (comparing/amplifying differences between probability distributions) is prerequisite.
  - Quick check question: Can you explain how subtracting two probability distributions can amplify specific desired properties while suppressing others?

- Concept: Self-attention mechanism and attention weight manipulation
  - Why needed here: The video-enhanced branch directly modifies pre-softmax attention matrices; you must understand how attention weights determine token-to-token influence to grasp why amplification affects visual grounding.
  - Quick check question: If you increase attention weights on video tokens before softmax, what happens to attention weights on text tokens after redistribution?

- Concept: LVLM architecture (vision encoder, projector, LLM decoder)
  - Why needed here: MCD operates at inference time across these components; knowing where visual tokens are injected and how they flow through the decoder clarifies intervention points.
  - Quick check question: In a typical LVLM, at which layer(s) do visual tokens interact with text tokens via self-attention?

## Architecture Onboarding

- Component map:
  - Vision Encoder -> Projector -> LLM Decoder -> MCD Layer (inference-only)
  - MCD Layer contains: Amateur branch (text-only), Weak expert (original multimodal), Strong expert (video-enhanced attention)

- Critical path:
  1. Video v encoded → projected → visual tokens generated
  2. Visual tokens concatenated with query tokens x → input to LLM
  3. At each generation step t, compute three distributions:
     - Amateur: pθ(yt|x, y<t) with zeroed visual tokens
     - Weak expert: pwθ(yt|v, x, y<t) standard forward pass
     - Strong expert: psθ(yt|v, x, y<t) with amplified video attention
  4. Integrate experts: p'θ = λ·pwθ + (1-λ)·psθ
  5. Apply contrastive decoding: pmcd = (1+γ)p'θ - γ·p_amateur
  6. Apply plausibility filter with threshold β
  7. Sample yt from pmcd, append to sequence, repeat until EOS

- Design tradeoffs:
  - α (attention amplification): Higher values increase visual grounding but risk ignoring question context. Paper adjusts per model based on video token sequence length.
  - λ (expert balance): Controls weak vs. strong expert contribution. Default not explicitly stated; requires tuning per backbone.
  - γ (contrastive strength): Controls penalty on amateur branch. Set to 0.1 across experiments.
  - β (plausibility threshold): Prevents implausible tokens. Set to 0.1; higher values are more restrictive.
  - No retraining vs. performance ceiling: Inference-only approach enables immediate deployment but may not achieve optimal bias-accuracy tradeoff compared to training-based methods.

- Failure signatures:
  - Over-amplification (α too high): Model generates responses describing visual content irrelevant to the question; coherence degrades.
  - Over-penalization (γ too high): Model avoids commonsense reasoning that overlaps with language priors; responses become overly literal or nonsensical.
  - Lambda imbalance: If weak expert dominates, bias reduction is minimal; if strong expert dominates, linguistic fluency suffers.
  - Token sequence mismatch: Different models have different video token counts (e.g., VideoLLaVA: 35-2098); using α tuned for one model on another may fail.
  - Plausibility threshold too strict: Valid tokens excluded from candidate pool, causing repetitive or truncated outputs.

- First 3 experiments:
  1. Reproduce baseline benchmark results: Run greedy decoding on VidLBEval for VideoLLaVA, record BVCrel, BVCdis, TCR, RA. Compare against Table 2 values (BVCrel=47.11, TCR=17.66) to validate your evaluation pipeline.
  2. Ablate α and λ on a held-out subset: Systematically vary α ∈ {0.5, 1.0, 1.5, 2.0} and λ ∈ {0.3, 0.5, 0.7} on 100 AVC samples. Plot BVCrel vs. RA to find the Pareto frontier for your target model.
  3. Validate general capability preservation: Apply your tuned MCD to SEEDBench/MVBench using the same hyperparameters. Confirm accuracy remains within 1-2% of baseline (Figure 5 shows MCD preserves performance on VideoLLaVA). Large drops indicate overfitting to bias reduction at the cost of general reasoning.

## Open Questions the Paper Calls Out

- Question: How can mitigation methods be specifically designed for the supervised fine-tuning (SFT) stage to effectively remedy inherent language bias in LVLMs?
  - Basis in paper: [explicit] The Conclusion states, "designing mitigation methods for supervised fine-tuning can act as a remedy for the inherent bias of LVLMs."
  - Why unresolved: The current study focuses on a training-free decoding strategy (MCD); the authors identify SFT interventions as a necessary but unexplored path for deeper bias correction.
  - What evidence would resolve it: An SFT methodology or loss function that reduces Biased Visual Consistency (BVC) on VidLBEval without compromising general benchmark performance.

- Question: What specific mechanisms allow a model to strike an optimal trade-off between general-purpose capability preservation and aggressive language bias removal?
  - Basis in paper: [explicit] The Conclusion notes that "striking a trade-off between general-purpose capability preservation and language bias removal is rather challenging and deserves further exploration."
  - Why unresolved: While MCD preserves capabilities reasonably well, the authors highlight that finding the optimal balance remains a distinct challenge for future model refinement.
  - What evidence would resolve it: A training or decoding strategy that yields simultaneous gains on both bias metrics (TCR, RA) and general capability benchmarks (MVBench, SEEDBench).

- Question: Can an adaptive mechanism be developed to automatically tune the attention amplification coefficient (α) and branch weighting factor (λ) for models with varying video token lengths?
  - Basis in paper: [inferred] The Implementation Details state that "we adjusted the value of α and λ for each model to better align with its specific video sequence length."
  - Why unresolved: MCD currently requires manual, model-specific hyperparameter tuning to manage different video token sequence lengths, limiting its robustness as a universal plug-and-play solution.
  - What evidence would resolve it: A universal MCD configuration that maintains high performance across VideoLLaVA, VideoLLaMA2, and VideoGPT+ without manual parameter adjustment.

## Limitations

- Model-specific hyperparameter tuning: The paper adjusts α and λ for each model but does not disclose exact values, making faithful reproduction challenging
- Evaluation dependency: VidLBEval's quality depends on GPT-4V/4 generation quality and filtering effectiveness, which may not generalize across model architectures
- Trade-off calibration: The balance between bias reduction and general capability preservation requires careful tuning per backbone, with no universal settings provided

## Confidence

- High confidence: The MCD framework design and mathematical formulation are clearly specified and grounded in established contrastive decoding principles
- Medium confidence: Experimental results showing consistent improvements across multiple models are convincing, though hyperparameter sensitivity is not fully explored
- Low confidence: Claims about MCD being "one of the most promising approaches" lack comparative analysis against other bias mitigation methods beyond VCD

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary α ∈ {0.5, 1.0, 1.5, 2.0} and λ ∈ {0.3, 0.5, 0.7} on VidLBEval and plot BVCrel vs. RA to identify optimal trade-offs for each model architecture
2. **Cross-Benchmark Generalization**: Apply tuned MCD hyperparameters to SEEDBench/MVBench and measure general capability retention; large performance drops would indicate overfitting to bias metrics
3. **Ablation of Components**: Test each MCD component (amateur branch, weak/strong experts, plausibility constraint) individually on a subset of VidLBEval to quantify individual contributions to bias reduction