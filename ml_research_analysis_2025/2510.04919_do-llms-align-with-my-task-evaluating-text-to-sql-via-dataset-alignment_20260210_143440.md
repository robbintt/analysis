---
ver: rpa2
title: Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment
arxiv_id: '2510.04919'
source_url: https://arxiv.org/abs/2510.04919
tags:
- alignment
- data
- fine-tuning
- bird
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how alignment between supervised fine-tuning
  (SFT) training data and target datasets impacts performance in Natural Language
  to SQL (NL2SQL) tasks. The authors propose a KL-alignment metric based on structural
  SQL features and n-gram distributions to quantify this alignment.
---

# Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment

## Quick Facts
- arXiv ID: 2510.04919
- Source URL: https://arxiv.org/abs/2510.04919
- Reference count: 13
- One-line primary result: Structural alignment measured by KL-divergence predicts post-SFT performance gains in NL2SQL tasks

## Executive Summary
This paper investigates how alignment between supervised fine-tuning (SFT) training data and target datasets impacts performance in Natural Language to SQL (NL2SQL) tasks. The authors propose a KL-alignment metric based on structural SQL features and n-gram distributions to quantify this alignment. Through experiments on three large NL2SQL benchmarks (BIRD, Spider, and Gretel) across multiple model families, they show that higher structural alignment correlates strongly with improved execution accuracy and exact match performance. The alignment ratio (AR) metric successfully predicts post-SFT performance improvements, with AR>1 indicating likely gains. Models like CodeLlama show substantial benefits from well-aligned data, while highly capable models like Qwen2.5-coder exhibit minimal sensitivity to alignment.

## Method Summary
The method extracts structural SQL templates by parsing queries into ASTs, removing leaf nodes, and generating n-grams (length 1-15) from the resulting templates. It computes KL-divergence between n-gram distributions of target data, training data, and base model predictions. The alignment ratio (AR) compares how well training data aligns with the target relative to the base model's predictions. When AR > 1, the training data aligns better with the target than the current model, indicating likely performance gains from SFT. The framework uses sqlglot for parsing, filters n-grams for SQL keywords, and scales KL scores using an exponential function to bound the alignment metric.

## Key Results
- CodeLlama 7B showed 4.43% absolute EX improvement on Gretel when AR > 1, but -2.22% when AR < 1
- Qwen2.5-Coder models exhibited no meaningful correlation between AR and performance (r=0.029)
- Structural alignment strongly predicts fine-tuning success with correlation r=0.624 for CodeLlama (p<0.05)
- Small query samples (1-2 per DB) can effectively estimate target distribution alignment

## Why This Works (Mechanism)

### Mechanism 1: Structural Distribution Shifting via SFT
If the structural distribution of a Supervised Fine-Tuning (SFT) dataset is closer to the target distribution than the base model's predictions are, fine-tuning likely improves performance. SFT minimizes the loss between the model and the training data. By quantifying the "distance" (KL-divergence) between the Target ($D_{target}$), Training ($D_{train}$), and Model Predictions ($D_{pred}$), one can calculate an **Alignment Ratio (AR)**. When $AR > 1$ (Training aligns better than current Model), the gradient updates shift the model toward the target's structural patterns (e.g., specific `JOIN` or `GROUP BY` usage). Core assumption: SQL correctness and utility are primarily constrained by the structural syntax (templates) rather than specific schema values (literals/table names).

### Mechanism 2: Pre-training Saturation Sensitivity
Models with extensive code-specific pre-training (e.g., Qwen2.5-Coder) exhibit minimal sensitivity to SFT alignment because their base distribution is already close to the target. These models possess a high initial $A_{KL}(D_{target} \| D_{pred})$. Consequently, the Alignment Ratio (AR) rarely exceeds 1 significantly, as the "room for improvement" via structural adaptation is small. The model has effectively "memorized" the structural priors during pre-training. Core assumption: Pre-training corpora (like GitHub code) adequately cover the structural variance of standard SQL benchmarks.

### Mechanism 3: Structural Overfitting (Negative Transfer)
Fine-tuning on a dataset with low alignment (AR < 1) forces the model to learn structural patterns absent in the target, degrading accuracy by "forgetting" the target-preferred patterns. SFT updates weights globally. If the training data over-represents a specific pattern (e.g., `COUNT(att)` vs `COUNT(*)`), the model increases the probability of that pattern at the expense of the target's preferred pattern, even if the base model originally predicted correctly. Core assumption: The model has limited capacity or plasticity, causing a trade-off where learning $D_{train}$ distributions hurts $D_{target}$ distributions.

## Foundational Learning

- **Concept: KL-Divergence (Kullback-Leibler Divergence)**
  - **Why needed here:** This is the mathematical core of the alignment metric. It measures how one probability distribution (the training data n-grams) diverges from a second (the target data n-grams).
  - **Quick check question:** If $D_{KL}(Target \| Train)$ is high, does that mean the training data is a good fit for the target? (Answer: No, high divergence means poor alignment).

- **Concept: SQL Template Extraction (Abstract Syntax Trees)**
  - **Why needed here:** The paper removes "leaf nodes" (specific values/table names) to compare structural skeletons. Understanding ASTs is necessary to implement the feature extractor.
  - **Quick check question:** Do the queries `SELECT name FROM users` and `SELECT id FROM products` have the same structural template in this framework? (Answer: Yes).

- **Concept: Alignment Ratio (AR)**
  - **Why needed here:** This is the predictive heuristic proposed. It compares the relative value of the training data vs. the status quo (base model).
  - **Quick check question:** If $AR < 1$, should you fine-tune? (Answer: No, the base model is already closer to the target than the training data is).

## Architecture Onboarding

- **Component map:** Parser (sqlglot) -> Template Extractor (AST pruning) -> N-gram Vectorizer -> Distribution Calculator -> Alignment Evaluator
- **Critical path:** Target Data (Sample) + Candidate SFT Data -> Template Extraction -> N-gram Freq -> KL Score -> AR Calculation -> Decision Gate (Proceed/Stop SFT)
- **Design tradeoffs:**
  - N-gram length ($l_{max}$): Paper sets 15 based on avg query length (12.7–14.3 tokens). Longer captures more logic but creates sparse vectors; shorter misses structural nuance.
  - Sample Size: Full dataset evaluation vs. small sample estimation. Paper suggests small samples (1–2 queries per DB) preserve relative alignment trends, saving compute.
- **Failure signatures:**
  - Syntactic Drift: SFT model generates valid SQL that executes but returns wrong results because it learned a structural bias (e.g., preferring `LEFT JOIN` over `INNER JOIN`) from the training set that doesn't match the target intent.
  - AR False Negative: A low AR score due to vocabulary mismatch (different table names) rather than structural mismatch, though the template extraction step aims to mitigate this.
- **First 3 experiments:**
  1. Baseline Profile: Take your target production query log (even just 50 samples). Run the base model to generate predictions. Calculate AR between your training data and the target log.
  2. Correlation Check: Fine-tune the model on the candidate data. Plot the change in Execution Accuracy vs. the predicted AR. Verify if AR > 1 correlates with positive gains for your specific model family.
  3. Ablation on Data Selection: Create two training sets: one with high AR (selected via this metric) and one random. Compare SFT efficiency (steps to convergence) and final accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
Does the predictive power of the Alignment Ratio (AR) generalize to LLMs significantly larger than 14B parameters? The authors state in the conclusion that "further investigation is needed to assess the extent to which these insights generalize to larger models," as their experiments were limited to small and mid-sized LLMs (0.5B to 14B). The study established correlations primarily on CodeLlama (7B-13B) and Qwen (0.5B-7B); it is unknown if the AR>1 threshold for predicting performance gains holds for 70B+ parameter models which may have different generalization capabilities.

### Open Question 2
Can incorporating semantic dimensions (e.g., query correctness, schema grounding) improve the predictive accuracy of alignment metrics over structural n-grams? The conclusion notes that "future extensions may incorporate semantic dimensions such as query correctness, schema grounding, and user intent," acknowledging that the current KL-alignment metric relies solely on syntactic patterns. A model might achieve high structural alignment (correct SQL template) but fail semantic alignment (incorrect column usage or logic), leading to execution failure; the current metric does not capture this.

### Open Question 3
Why does the Alignment Ratio (AR) fail to predict performance improvements for highly capable instruction-tuned models like Qwen2.5-Coder? While the paper reports a strong correlation (r=0.624) for CodeLlama, it explicitly notes Qwen2.5-Coder shows "no meaningful correlation" (r=0.029), suggesting the model's "strong pretraining" makes it insensitive to the alignment metric used. It is unclear if the lack of correlation is due to the models being near their performance ceiling (saturation), or if the structural KL-metric is simply too coarse to detect the subtle data distributions required to improve highly capable models further.

## Limitations

- The framework assumes structural SQL features are sufficient proxies for task alignment and may not capture semantic nuances in complex queries
- Effectiveness depends on the assumption that pre-training data adequately covers target domain distributions, which may fail for specialized SQL dialects
- The paper does not address how alignment scores might vary across different query complexity levels
- The suggestion that small samples can reliably estimate alignment requires further validation for datasets with high intra-domain variance

## Confidence

**High Confidence**: The empirical correlation between structural alignment and performance gains (r=0.624 for CodeLlama, p<0.05) is robust across multiple datasets and model families.

**Medium Confidence**: The claim that highly pre-trained models (Qwen2.5-coder) are insensitive to alignment has strong support but may not generalize to all code-specialized models.

**Low Confidence**: The paper's suggestion that small samples (1-2 queries per DB) can reliably estimate alignment requires further validation, particularly for datasets with high intra-domain variance.

## Next Checks

1. **Domain Transfer Test**: Apply the alignment framework to a SQL dataset from a completely different domain (e.g., financial vs. academic) to test whether structural alignment remains predictive when semantic content differs significantly.

2. **Query Complexity Analysis**: Stratify the evaluation by query complexity (simple SELECT vs. nested aggregations) to determine if alignment effectiveness varies with query sophistication.

3. **Cross-Task Generalization**: Test whether the KL-alignment metric framework applies to other structured output tasks like text-to-code (Python) or text-to-Regex, examining if structural template extraction provides similar predictive power outside SQL contexts.