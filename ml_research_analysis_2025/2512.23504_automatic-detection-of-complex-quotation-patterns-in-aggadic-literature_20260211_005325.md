---
ver: rpa2
title: Automatic Detection of Complex Quotation Patterns in Aggadic Literature
arxiv_id: '2512.23504'
source_url: https://arxiv.org/abs/2512.23504
tags:
- quotation
- quotations
- style
- biblical
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ACT (Allocate Connections between Texts), a
  novel three-stage algorithm for the automatic detection of biblical quotations in
  Rabbinic literature. Unlike existing text reuse frameworks that struggle with short,
  paraphrased, or structurally embedded quotations, ACT combines a morphology-aware
  alignment algorithm with a context-sensitive enrichment stage that identifies complex
  citation patterns such as "Wave" and "Echo" quotations.
---

# Automatic Detection of Complex Quotation Patterns in Aggadic Literature

## Quick Facts
- arXiv ID: 2512.23504
- Source URL: https://arxiv.org/abs/2512.23504
- Reference count: 19
- Primary result: ACT-QE achieves F1=0.91 on biblical quotation detection in Aggadic literature

## Executive Summary
This paper introduces ACT (Allocate Connections between Texts), a three-stage algorithm for detecting biblical quotations in Rabbinic literature. The system addresses limitations of existing text reuse frameworks by handling short, paraphrased, and structurally embedded quotations through morphology-aware alignment and context-sensitive enrichment. ACT successfully identifies complex citation patterns including "Wave" and "Echo" quotations that fragment single verses across non-contiguous text segments. The approach was evaluated against leading systems and human-annotated critical editions, demonstrating superior performance particularly in detecting single-word quotations and complex intertextual patterns.

## Method Summary
ACT is a three-stage pipeline that processes input texts through preprocessing (normalization and tokenization), candidate detection using sliding window n-grams with morphology-aware alignment against a biblical corpus, and quotation enrichment with log-probability scoring and style inference. The system uses a positional inverted index for efficient candidate retrieval, applies a morphology-aware alignment algorithm to handle Hebrew orthographic variation, and employs a probabilistic scoring mechanism that penalizes common co-occurrences while rewarding rare word combinations. A context-boosting algorithm identifies Wave and Echo patterns by aggregating scores from quotations sharing biblical verse origins. The pipeline was evaluated with three configurations: ACT-2 (n-gram=2), ACT-3 (n-gram=3), and ACT-QE (full pipeline with n-gram=1 and enrichment).

## Key Results
- ACT-QE achieves F1=0.91, Recall=0.89, and Precision=0.94, outperforming all baseline systems
- ACT-2 achieves highest Recall (0.90) but lowest Precision (0.44), demonstrating the importance of enrichment stage
- ACT-3 offers balanced performance (F1=0.83) but misses single-word quotations due to n-gram size=3
- The system successfully identifies complex quotation patterns (Wave, Echo) that existing methods miss

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Morphology-aware alignment improves recall for morphologically rich languages like Hebrew by handling orthographic and morphological variation that standard n-gram methods miss.
- **Mechanism:** The pipeline normalizes texts (removing diacritics, standardizing spelling, stripping matres lectionis), then uses a sequence alignment algorithm specifically designed for Hebrew's morphological complexity rather than simple character-level or word-level matching. This allows detection of quotations with spelling variants, synonym substitutions, and word order differences.
- **Core assumption:** Normalization preserves semantic identity while reducing noise; alignment tolerance for morphological variation improves match coverage without excessive false positives.
- **Evidence anchors:**
  - [abstract] "combines a morphology-aware alignment algorithm with a context-sensitive enrichment stage"
  - [Section 4.2] "aligned using the morphologically-aware alignment algorithm introduced in [4], which accounts for paraphrastic expressions, orthographic variation, transcriptional noise, and word order differences"
  - [corpus] Limited direct corpus support for Hebrew-specific morphology handling; related work on Latin intertextuality (Loci Similes) suggests cross-linguistic relevance
- **Break condition:** When normalization erases distinctive lexical markers needed to distinguish genuine quotations from coincidental word overlap; or when morphological richness exceeds the alignment algorithm's tolerance thresholds.

### Mechanism 2
- **Claim:** Log-probability scoring enables stable thresholding for short quotations by penalizing common co-occurrences while rewarding rare word combinations.
- **Mechanism:** Instead of fixed n-gram length thresholds, each detected sequence receives a score derived from the sum of log-probabilities of its constituent tokens. Rare biblical sequences (e.g., "Bereshit Bara") receive higher scores than common word pairs. This probabilistic approach allows single-word quotations to be detected when their token probability justifies it.
- **Core assumption:** Token frequency in the biblical corpus correlates with quotation likelihood; rare sequences are more likely intentional citations than coincidental matches.
- **Evidence anchors:**
  - [Section 4.3] "frequently quoted sequences receive higher scores, whereas improbable or coincidental co-occurrences are effectively penalized"
  - [Section 5.6] Grid search identified optimal threshold of 21; below this, recall increases but false positives rise
  - [corpus] Weak corpus evidence for this specific scoring method; no direct comparison papers found
- **Break condition:** When common biblical phrases (high probability) are genuine quotations but fall below threshold; or when rare words from different verses coincidentally co-occur and exceed threshold.

### Mechanism 3
- **Claim:** Contextual boosting via neighboring quotation detection enables identification of complex patterns (Wave, Echo) that fragment single verses across non-contiguous text segments.
- **Mechanism:** Algorithm 1 scans for prior quotations from the same biblical verse. When found, it aggregates scores and assigns style labels: "echo" if quotations share intervening text, "wave" if separated by external commentary. This turns isolated low-confidence matches into high-confidence pattern detections.
- **Core assumption:** Quotations from the same verse appearing in proximity are structurally related; the intertextual context disambiguates fragmentary citations.
- **Evidence anchors:**
  - [Section 4.3] "If multiple quotations are identified as sharing context (i.e., proximity or intervening text), their scores are aggregated, and a style label is assigned"
  - [Section 6.1] "ACT-QE, which incorporates both innovations... yielded the best balance across all metrics. The third stage—Quotation Enrichment—boosts quotations that exhibit structural patterns"
  - [corpus] No direct corpus validation of this boosting mechanism; Loci Similes paper on Latin intertextuality addresses similar fragmentation challenges
- **Break condition:** When unrelated texts coincidentally quote the same verse in proximity; when genuine Wave/Echo patterns span distances exceeding the algorithm's proximity window.

## Foundational Learning

- **Concept: Positional Inverted Index**
  - Why needed here: Enables efficient lookup of token positions across the biblical corpus for quotation candidate retrieval.
  - Quick check question: Can you explain how a positional index differs from a standard inverted index, and why position matters for detecting multi-word quotations?

- **Concept: Sequence Alignment Algorithms (Smith-Waterman family)**
  - Why needed here: Forms the core of the candidate detection stage; understanding gap penalties and substitution costs is essential for debugging alignment failures.
  - Quick check question: What happens to alignment scores when a quotation has word order differences versus synonym substitutions?

- **Concept: Log-Likelihood and Probability Estimation**
  - Why needed here: The scoring mechanism relies on log-probabilities to avoid numerical underflow and enable stable thresholding.
  - Quick check question: Why sum log-probabilities rather than multiply raw probabilities when computing sequence rarity?

## Architecture Onboarding

- **Component map:**
  Input Text → [Stage 1: Preprocessing] → Normalized Text → [Stage 2: Candidate Detection] → Quotation Candidates → [Stage 3: Quotation Enrichment] → Output: Detected quotations with style labels

- **Critical path:** Stage 2 alignment quality determines Stage 3's input pool. If alignment is too strict, Wave/Echo patterns never form; if too loose, Stage 3 drowns in noise. The n-gram size parameter (1 vs. 2 vs. 3) directly controls this tradeoff—ACT-QE uses size 1 to capture single-word quotations, relying on Stage 3 to filter false positives.

- **Design tradeoffs:**
  | Configuration | n-gram | Recall | Precision | Use Case |
  |---------------|--------|--------|-----------|----------|
  | ACT-2 | 2 | 0.90 | 0.44 | Maximum coverage, manual review needed |
  | ACT-3 | 3 | 0.74 | 0.86 | Balanced, misses single-word |
  | ACT-QE | 1 | 0.89 | 0.94 | Full pipeline, best F1 |

- **Failure signatures:**
  - High recall, very low precision → Check if Stage 3 enrichment is disabled or threshold too low
  - Missing obvious quotations → Check preprocessing normalization; verify biblical corpus completeness
  - Wave patterns detected as separate Simple quotations → Algorithm 1 proximity window may be too narrow
  - Single-word quotations missed → n-gram size likely > 1; verify ACT-QE configuration

- **First 3 experiments:**
  1. **Reproduce baseline comparison:** Run ACT-QE, Dicta, and Text-Matcher on the same ground-truth subset; verify F1 rankings match Table 2 before modifying anything.
  2. **Ablate the enrichment stage:** Compare ACT-2 (no enrichment) vs. ACT-QE on a sample rich in Wave/Echo patterns; quantify the precision/recall tradeoff to understand Stage 3's contribution.
  3. **Threshold sensitivity analysis:** Using a held-out set, sweep the score threshold (e.g., 15–30) and plot precision-recall curves; confirm whether the paper's threshold of 21 is optimal for your target corpus or needs adjustment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the statistical distribution of quotation styles (Simple, Wave, Echo, Compound) serve as a reliable feature for automated genre classification or the identification of redactional layers within Rabbinic texts?
- Basis in paper: [explicit] The authors state that "identifying single-word quotations, followed by detecting broader quotation patterns, can contribute to distinguishing between literary genres and uncovering different compositional layers within a work."
- Why unresolved: While the paper observes distinct stylistic tendencies in different works (e.g., the prevalence of Echo style in Vayikra Rabba), it does not implement or test a classification algorithm based on these features.
- What evidence would resolve it: A supervised machine learning experiment where the vector of quotation style distributions is used as the primary feature set to predict the genre or provenance of unseen texts.

### Open Question 2
- Question: To what extent would integrating deep contextual embeddings improve the robustness of ACT's alignment and pattern detection compared to the current probabilistic scoring?
- Basis in paper: [explicit] The conclusion suggests that "incorporating advanced natural language processing techniques—such as deep contextual embeddings—may further enhance the system's robustness and sensitivity to subtle textual features."
- Why unresolved: The current ACT pipeline relies on morphology-aware alignment and log-likelihood scoring; the potential added value of dense vector representations for detecting paraphrastic reuse remains untested.
- What evidence would resolve it: A comparative evaluation replacing or augmenting the current alignment scoring mechanism with embeddings (e.g., BERT-based models for Hebrew) to measure performance gains on paraphrased quotations.

### Open Question 3
- Question: Can the ACT framework and its "Wave" and "Echo" typology be generalized to detect complex citation patterns in other languages and literary traditions beyond Hebrew Aggadic literature?
- Basis in paper: [explicit] The authors note they aim to "extend this framework to other languages and literary traditions" and acknowledge the current limitation that the styles "may not capture the full spectrum of quotation practices found in other textual traditions."
- Why unresolved: The algorithm and its parameters (e.g., the specific boosting logic for non-contiguous quotations) are tuned for the specific morphological and stylistic features of Hebrew Rabbinic texts.
- What evidence would resolve it: Successful application of ACT to a distinct corpus (e.g., New Testament quotations of the Old Testament or Classical Arabic commentaries) with minimal architectural changes.

### Open Question 4
- Question: To what degree do the "false positives" generated by high-recall configurations (like ACT-2) represent valid conceptual paraphrases rather than detection errors?
- Basis in paper: [explicit] The authors propose "analyzing its false positives in greater depth—distinguishing between lexical and conceptual paraphrases or stylistic transformations" as a necessary step for future research.
- Why unresolved: The paper classifies non-matches against the ground truth as errors (lowering precision), but acknowledges the ground truth (Critical Editions) may miss valid but non-verbatim intertextual connections.
- What evidence would resolve it: A qualitative review of ACT-2's false positives by domain experts to determine if they constitute legitimate intertextual links excluded by the strict criteria of the critical editions.

## Limitations

- The morphology-aware alignment algorithm relies on external reference [4] without full implementation details, limiting reproducibility
- Evaluation is restricted to three Midrashic texts from Sefaria, raising concerns about generalizability across different rabbinic genres
- The single optimal threshold value (21) may not capture the full tradeoff space for applications with different precision-recall requirements

## Confidence

**High Confidence (90%+):** The comparative performance advantage of ACT-QE over Dicta and baseline systems is well-supported by the reported F1 scores (0.91 vs. 0.72-0.81) and multiple baseline configurations. The three-stage architecture and its components are clearly specified.

**Medium Confidence (60-89%):** The mechanism explanations for morphology-aware alignment and log-probability scoring are plausible but rely on external references rather than detailed in-paper validation. The Wave/Echo pattern detection mechanism (Algorithm 1) lacks sufficient corpus-level validation to confirm its effectiveness across diverse quotation patterns.

**Low Confidence (0-59%):** Claims about the system's applicability to "broader applications in historical textual analysis" and "cross-corpora genre classification" are speculative, as the evaluation is limited to Hebrew Aggadic literature. The assertion that ACT "lays a foundation for" these applications exceeds the empirical evidence provided.

## Next Checks

1. **Ablation study on morphology handling:** Systematically disable the morphology-aware alignment component while keeping other stages intact, then compare performance against the full pipeline on the same evaluation set. This would quantify the exact contribution of morphological handling versus other components.

2. **Cross-corpus generalization test:** Apply ACT-QE to a different rabbinic corpus (e.g., Talmud or non-Sefaria Midrash) with minimal parameter tuning. Measure performance degradation to assess how much the system relies on corpus-specific optimizations versus general pattern detection capabilities.

3. **Threshold stability analysis:** Conduct a broader threshold sweep (e.g., 10-40 in increments of 2) and generate precision-recall curves. Calculate confidence intervals for F1 scores at multiple thresholds to determine if the reported optimal value represents a stable optimum or a local maximum sensitive to the evaluation dataset.