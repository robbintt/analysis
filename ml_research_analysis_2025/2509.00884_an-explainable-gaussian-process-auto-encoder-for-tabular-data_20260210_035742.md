---
ver: rpa2
title: An Explainable Gaussian Process Auto-encoder for Tabular Data
arxiv_id: '2509.00884'
source_url: https://arxiv.org/abs/2509.00884
tags:
- counterfactual
- latent
- data
- space
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a Gaussian Process Auto-Encoder (GPAE) for
  generating counterfactual explanations in tabular data. The core idea is to replace
  the traditional neural network-based encoder and decoder with Gaussian processes
  (GPs) using Random Fourier Features (RFF) approximation, reducing the number of
  learnable parameters and making the model less prone to overfitting.
---

# An Explainable Gaussian Process Auto-encoder for Tabular Data

## Quick Facts
- arXiv ID: 2509.00884
- Source URL: https://arxiv.org/abs/2509.00884
- Reference count: 40
- Primary result: GPAE generates diversified and in-distribution counterfactual explanations for tabular data while achieving competitive classification performance

## Executive Summary
This paper introduces the Gaussian Process Auto-Encoder (GPAE), a novel approach for generating counterfactual explanations in tabular data. The core innovation replaces traditional neural network encoders and decoders with Gaussian processes approximated via Random Fourier Features (RFF), reducing parameters and overfitting risk. The model incorporates a density estimator in the latent space to guide the generation of in-distribution counterfactual samples rather than just valid label-flipping samples. Experiments on five large-scale tabular datasets demonstrate that GPAE produces counterfactuals with superior diversity, stability, and interpretability metrics compared to existing autoencoder-based methods.

## Method Summary
The GPAE architecture uses RFF to approximate Gaussian process mappings in both encoder and decoder, replacing standard neural layers with fixed random projections followed by linear transformations. The encoder maps inputs to a latent space using $\lambda = \phi(x)^T W_e$, while the decoder reconstructs via $\hat{x} = \phi(\lambda)^T W_d$. A probit regression classifier operates in the latent space, and a separate density estimator learns the target class distribution in latent coordinates. Counterfactuals are generated through gradient descent in input space with immutability constraints enforced via masking, rather than decoding from latent space. The model is trained end-to-end with reconstruction and classification losses, followed by density estimator training.

## Key Results
- GPAE outperforms existing autoencoder-based methods in counterfactual metrics including L2 distance, diversity, instability, discriminative power, and interpretability
- The model achieves competitive classification performance across all five tested tabular datasets (FICO, Adult, LAW, LCD, GMC)
- Ablation studies demonstrate the effectiveness of the density estimator in producing in-distribution counterfactuals
- The proposed algorithm for selecting optimal density regularization rate ($\beta$) improves counterfactual quality

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Replacing neural network layers with RFF approximations of GPs reduces overfitting and parameter count while maintaining competitive performance.
- **Mechanism:** Inputs are mapped using fixed random weights and cosine activation to form features, then a linear projection is learned in this high-dimensional space, approximating a GP with RBF kernel without $O(N^3)$ inversion cost.
- **Core assumption:** The RBF kernel approximation via Monte Carlo sampling is sufficiently expressive for tabular data, and finite $S$-dimensional feature maps retain GP properties.
- **Evidence anchors:** Abstract mentions RFF approximation replacing neural networks; page 8 defines $\phi(x)$ and convergence property; corpus shows distinct approach from GAN/diffusion methods.
- **Break condition:** If RFF sample size $S$ is too small, kernel approximation degrades, leading to underfitting or poor latent representations.

### Mechanism 2
- **Claim:** A density estimator in latent space enables generation of "in-distribution" counterfactuals rather than just valid ones.
- **Mechanism:** The model learns a density function in latent space using exponentiated GP via RFF, which acts as a prior during counterfactual search, pushing generated samples to high-density regions of the target class.
- **Core assumption:** The latent space geometry preserves data manifold structure sufficiently for density estimates to be meaningful.
- **Evidence anchors:** Page 15 defines density estimator form; page 17 shows optimization objective including density term; weak corpus signal as most related work focuses on generation fidelity.
- **Break condition:** If latent space has poor regularization or "holes," density estimates may misguide search, producing unrealistic samples despite high density scores.

### Mechanism 3
- **Claim:** Gradient descent in input space with masking enables stricter enforcement of immutability constraints than decoder-based generation.
- **Mechanism:** The model optimizes perturbations directly in feature space rather than decoding latent vectors, applying binary masks to gradients to ensure specific features remain unchanged.
- **Core assumption:** The encoder is smooth enough for effective gradient backpropagation from latent decision boundary to input features.
- **Evidence anchors:** Page 4 explains gradient backpropagation with masking; page 18 shows masked update rule; related work like CounterNet uses similar approaches but GPAE integrates GP structure.
- **Break condition:** If decision boundary is highly non-linear or input dimensionality is very high, gradient-based search may get stuck in local minima or require excessive iterations.

## Foundational Learning

- **Concept:** Random Fourier Features (RFF)
  - **Why needed here:** Core approximation strategy replacing standard neural layers; essential for understanding encoder/decoder behavior
  - **Quick check question:** How does increasing RFF components $S$ affect RBF kernel approximation and model speed?

- **Concept:** Probit Regression in Latent Space
  - **Why needed here:** Model uses probit (not softmax) to supervise latent space for classification, affecting decision boundary derivation
  - **Quick check question:** Why might probit link function be chosen for GP-based latent space over standard logistic link?

- **Concept:** Lagrangian Optimization for Constrained Search
  - **Why needed here:** Counterfactual generation framed as constrained optimization (minimize distance subject to classification change)
  - **Quick check question:** In Lagrangian objective, what effect does regularization factor $\beta$ have on counterfactual diversity vs. validity?

## Architecture Onboarding

- **Component map:**
  - Input → Fixed RFF Projection ($\phi(x)$) → Trainable Linear Layer ($W_e$) → Latent $\lambda$
  - Latent $\lambda$ → Fixed RFF Projection ($\phi(\lambda)$) → Trainable Linear Layer ($W_d$) → Reconstruction
  - Latent $\lambda$ → Linear dot product ($\lambda^T \theta_c$) → Classification
  - Latent $\lambda$ → RFF → Weights $w$ (Learned via MAP) → Density Estimation

- **Critical path:**
  1. Training: Jointly optimize Encoder, Decoder, and Classifier weights ($W_e, W_d, \theta_c$)
  2. Density Fitting: Freeze encoder and train Density Estimator weights $w$ on resulting latent codes
  3. Search: Run iterative optimization to find $\delta$ using Algorithm 3 logic applied to equations 22-24

- **Design tradeoffs:**
  - RFF vs Inducing Points: Paper notes RFF is faster for counterfactual search phase despite sacrificing kernel flexibility (Page 26)
  - Latent Dimension ($d$): Lower dimensions may merge classes (low discriminative power); higher dimensions increase L2 distance (Page 33, Fig 6)

- **Failure signatures:**
  - Mode Collapse: If $\beta$ too high, all counterfactuals collapse to single high-density point on boundary (Page 20, Figure 4 right)
  - Instability: If RFF dimension $S$ too low, gradient direction during search may fluctuate wildly
  - High IM1/IM2 scores: Indicates generated samples are "off-manifold" - density estimator failing to capture target class geometry

- **First 3 experiments:**
  1. Sanity Check: Train GPAE on small subset and verify encoder+linear classifier achieves accuracy comparable to standard NN (reproduce Table 4)
  2. Visualizing Density: Reproduce Figure 3 (or PCA version) to visualize if Density Estimator contours align with data clusters
  3. Beta Sweep: Run KL-divergence algorithm to find optimal $\beta$ for specific dataset rather than guessing; observe counterfactual trajectory as $\beta$ changes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can GPAE framework be adapted to mitigate sensitivity to classifier thresholds when training on highly imbalanced datasets?
- Basis in paper: [explicit] Authors state model appears sensitive to classifier thresholds on Adult and LAW datasets, likely due to training on imbalanced datasets (p. 25), resulting in lower AUC despite competitive accuracy
- Why unresolved: Current architecture optimizes standard reconstruction and classification loss, which doesn't inherently calibrate probabilities or address threshold variance in skewed distributions
- What evidence would resolve it: Incorporating focal loss or threshold-invariant learning objectives into GPAE training and evaluating AUC stability across varying class imbalance ratios

### Open Question 2
- Question: Is there theoretically grounded or automated method for selecting optimal RFF mapping dimension $S$?
- Basis in paper: [inferred] Ablation study (p. 35) shows trade-off where increasing $S$ improves L2 distance but degrades stability and manifold proximity (IM1/IM2); paper concludes "moderate values of S are preferred" without selection algorithm
- Why unresolved: Dimension $S$ appears to control bias-variance trade-off between counterfactual sparsity and distributional validity that current heuristics cannot optimize dynamically
- What evidence would resolve it: Deriving theoretical bounds for RFF approximation error within latent density estimator or implementing cross-validation mechanism penalizing high instability scores

### Open Question 3
- Question: Do improvements in proposed density-based metrics (IM1, IM2) correlate with human-perceived actionability and realism?
- Basis in paper: [explicit] Authors note IM1 and IM2 are limited because lower scores might just indicate sample stays around manifold or model generates "indistinguishable samples" (p. 28)
- Why unresolved: While density estimator improves quantitative plausibility scores, paper lacks user studies to confirm in-distribution samples are actually more meaningful or actionable to human stakeholders
- What evidence would resolve it: Human-subject experiment where domain experts evaluate feasibility of counterfactuals generated by GPAE versus baselines

## Limitations

- **Hyperparameter Sensitivity:** Model performance highly sensitive to regularization parameter β, with ablation study showing trade-offs between diversity and validity; specific RFF and latent dimensions only reported for one dataset
- **Evaluation Scope:** Experimental section focuses primarily on LCD dataset with detailed analysis; comparative results for other four datasets summarized in single table without detailed failure mode analysis
- **Computational Efficiency Claims:** Claims about RFF-based GPs being faster than inducing point methods lack empirical support with timing data or complexity analysis

## Confidence

- **High Confidence:** Core theoretical framework (RFF approximation, density estimation in latent space, gradient-based search with masks) is mathematically sound and well-articulated; ablation studies on LCD provide strong evidence for individual component contributions
- **Medium Confidence:** Classification performance claims supported by Table 4, but counterfactual generation results lack detailed analysis across all five datasets; density estimator effectiveness demonstrated on LCD but not comprehensively validated
- **Low Confidence:** Claims about computational efficiency improvements over inducing point methods are not empirically supported with timing data or complexity analysis

## Next Checks

1. **Algorithm 3 Robustness Test:** Implement Algorithm 3 for selecting β across all five datasets and report variance in selected values; test whether same β range works across datasets or if dataset-specific tuning is required

2. **Timing and Efficiency Analysis:** Measure and compare wall-clock time for training and counterfactual generation between GPAE and baseline using inducing point sparse GPs; report both training and inference/search times

3. **Interpretability Failure Analysis:** For datasets with high IM1/IM2 scores (3 out of 5 datasets), conduct detailed analysis of generated counterfactuals to identify specific failure modes; visualize whether high interpretability scores correlate with latent space density misalignment or other structural issues