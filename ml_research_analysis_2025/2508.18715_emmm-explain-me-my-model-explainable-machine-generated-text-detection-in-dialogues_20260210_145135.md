---
ver: rpa2
title: EMMM, Explain Me My Model! Explainable Machine Generated Text Detection in
  Dialogues
arxiv_id: '2508.18715'
source_url: https://arxiv.org/abs/2508.18715
tags:
- detection
- user
- explanation
- emmm
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes EMMM, a framework for explainable detection
  of machine-generated text in conversational settings, addressing challenges in real-time
  detection, interpretability for non-experts, and handling asymmetric dialogue structures.
  EMMM uses a dialogue-aware architecture combining turn-level and dialogue-level
  detection with multi-dimensional inputs (language and behavior) and multi-strategy
  explanations (natural language narratives and contextualized visualizations).
---

# EMMM, Explain Me My Model! Explainable Machine Generated Text Detection in Dialogues

## Quick Facts
- arXiv ID: 2508.18715
- Source URL: https://arxiv.org/abs/2508.18715
- Reference count: 38
- Primary result: EMMM achieves 0.9858 Macro-F1 for detection, generates explanations within 1 second, and is preferred by 70% of human evaluators over baseline attribution methods

## Executive Summary
EMMM introduces a novel framework for detecting machine-generated text in conversational settings while providing interpretable explanations. The framework addresses three key challenges in MGT detection: real-time processing requirements, interpretability for non-experts, and handling asymmetric dialogue structures. EMMM combines turn-level and dialogue-level detection modules with multi-dimensional inputs and explanation strategies to achieve high accuracy while maintaining explainability.

## Method Summary
EMMM employs a dialogue-aware architecture that integrates turn-level detection using hierarchical attention networks with dialogue-level detection through Bi-GRU networks. The framework processes multi-dimensional inputs including language features and behavioral patterns, generating explanations through both natural language narratives and contextualized visualizations. The system is designed to handle streaming dialogue data while providing interpretable outputs for human users, particularly customer service agents who need to identify machine-generated responses in real-time conversations.

## Key Results
- Achieves 0.9858 Macro-F1 for machine-generated text detection
- Generates explanations within 1 second of processing
- Preferred by 70% of human evaluators over baseline attribution methods

## Why This Works (Mechanism)
EMMM's effectiveness stems from its comprehensive approach to dialogue-aware MGT detection. By combining turn-level and dialogue-level detection, the framework captures both local response patterns and broader conversational context. The multi-dimensional input processing allows the model to consider both linguistic features and behavioral patterns, while the dual explanation strategy (natural language narratives and visualizations) addresses different user needs for interpretability.

## Foundational Learning

**Dialogue structure analysis** - Why needed: Understanding asymmetric dialogue patterns helps identify machine-generated responses that may follow different conversational flows. Quick check: Verify that the framework correctly identifies speaker roles and turn-taking patterns.

**Real-time processing** - Why needed: Customer service applications require immediate detection and explanation generation. Quick check: Measure latency under realistic streaming conditions with varying dialogue lengths.

**Multi-modal explanation generation** - Why needed: Different users require different explanation formats for effective decision-making. Quick check: Compare user preference and comprehension across natural language and visual explanations.

## Architecture Onboarding

**Component map**: Input Dialogue -> Turn-level Detection -> Dialogue-level Detection -> Multi-dimensional Processing -> Explanation Generation

**Critical path**: Real-time dialogue input → Turn-level detection (HAN) → Dialogue-level detection (Bi-GRU) → Explanation generation → Output to user

**Design tradeoffs**: The framework prioritizes interpretability over pure detection speed, sacrificing some computational efficiency for explanation quality. The dual detection approach balances local response analysis with global conversation context.

**Failure signatures**: Poor performance on very short dialogues, degraded accuracy with highly technical domain-specific language, and potential delays in explanation generation during high-load scenarios.

**3 first experiments**:
1. Compare Macro-F1 scores across different dialogue lengths to identify performance degradation points
2. Measure explanation generation latency under varying computational loads
3. Test detection accuracy on domain-specific dialogues versus general conversations

## Open Questions the Paper Calls Out
None

## Limitations
- Entirely evaluated on synthetic datasets without real-world deployment testing
- Explainability claims rely on subjective human evaluations without standardized benchmarks
- Model complexity may limit practical deployment in resource-constrained environments

## Confidence

| Claim | Confidence |
|-------|------------|
| Detection accuracy | High |
| Explainability improvements | Medium |
| Real-time performance | Medium |
| Generalizability | Low |

## Next Checks

1. Conduct field deployment studies using EMMM in actual customer service environments to validate detection accuracy and explanation utility with real dialogue data

2. Implement A/B testing comparing EMMM's explanations against baseline methods in production systems to measure actual impact on agent decision-making and user satisfaction

3. Perform stress testing under realistic load conditions to verify the 1-second explanation generation claim and assess computational overhead in streaming scenarios