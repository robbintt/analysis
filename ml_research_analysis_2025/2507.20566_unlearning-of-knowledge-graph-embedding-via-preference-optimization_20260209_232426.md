---
ver: rpa2
title: Unlearning of Knowledge Graph Embedding via Preference Optimization
arxiv_id: '2507.20566'
source_url: https://arxiv.org/abs/2507.20566
tags:
- uni00000013
- knowledge
- unlearning
- uni00000011
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GraphDPO, a knowledge graph embedding unlearning
  framework that addresses the challenge of forgetting specific triples while preserving
  surrounding knowledge in interconnected graphs. The method reformulates unlearning
  as a preference optimization problem using direct preference optimization (DPO),
  combined with an out-boundary sampling strategy to reduce inference leakage from
  remaining knowledge and a boundary recall mechanism to preserve context.
---

# Unlearning of Knowledge Graph Embedding via Preference Optimization

## Quick Facts
- arXiv ID: 2507.20566
- Source URL: https://arxiv.org/abs/2507.20566
- Reference count: 40
- Primary result: Introduces GraphDPO framework achieving up to 10.1% improvement in MRR_Avg and 14.0% in MRR_F1 for knowledge graph embedding unlearning

## Executive Summary
This paper addresses the challenge of unlearning specific knowledge triples from knowledge graph embeddings while preserving surrounding contextual information. The authors propose GraphDPO, a preference optimization framework that reformulates unlearning as a preference optimization problem using direct preference optimization (DPO). The method combines out-boundary sampling to reduce inference leakage and a boundary recall mechanism to preserve context. Experiments across eight datasets and four knowledge graphs demonstrate significant improvements over state-of-the-art baselines, with up to 10.1% improvement in MRR_Avg and 14.0% in MRR_F1 metrics.

## Method Summary
GraphDPO reformulates knowledge graph embedding unlearning as a preference optimization problem using direct preference optimization (DPO). The framework employs an out-boundary sampling strategy to identify and process triples at the knowledge boundary, reducing inference leakage from remaining knowledge. A boundary recall mechanism preserves contextual information by maintaining relationships between unlearned triples and their surrounding knowledge. The preference optimization formulation optimizes for both forgetting specific triples and maintaining the integrity of remaining knowledge structure. The approach is evaluated on entity and relation prediction tasks across multiple knowledge graphs.

## Key Results
- Achieves up to 10.1% improvement in MRR_Avg compared to state-of-the-art baselines
- Demonstrates 14.0% improvement in MRR_F1 metric for knowledge graph unlearning
- Shows effective preservation of surrounding knowledge while unlearning specific triples across eight datasets and four knowledge graphs

## Why This Works (Mechanism)
The method works by reframing knowledge graph unlearning as a preference optimization problem rather than traditional gradient-based forgetting approaches. By using direct preference optimization (DPO), GraphDPO can explicitly model the trade-off between forgetting target triples and preserving contextual knowledge. The out-boundary sampling strategy identifies knowledge triples that are most likely to leak information about unlearned content, allowing targeted mitigation. The boundary recall mechanism ensures that the structural relationships at the periphery of unlearned knowledge remain intact, preventing cascading degradation of embedding quality.

## Foundational Learning

1. **Knowledge Graph Embeddings**
   - Why needed: Core representation method for encoding entities and relations in continuous vector space
   - Quick check: Understand how triples (head, relation, tail) are represented as vector operations

2. **Direct Preference Optimization (DPO)**
   - Why needed: Enables preference-based learning without explicit reward modeling
   - Quick check: Verify understanding of how pairwise comparisons drive optimization

3. **Out-boundary Sampling**
   - Why needed: Identifies triples at knowledge boundaries that may leak information about unlearned content
   - Quick check: Confirm ability to distinguish boundary triples from internal graph structure

4. **Boundary Recall Mechanism**
   - Why needed: Preserves contextual relationships when specific knowledge is removed
   - Quick check: Validate that removing triples doesn't degrade peripheral knowledge structure

5. **MRR and Hits@K Metrics**
   - Why needed: Standard evaluation metrics for knowledge graph completion tasks
   - Quick check: Calculate MRR manually for a small example knowledge graph

## Architecture Onboarding

**Component Map:**
Data → Out-boundary Sampler → Preference Optimizer (DPO) → Embedding Model → Evaluation Metrics

**Critical Path:**
Knowledge Graph Data → Out-boundary Sampling → Preference Optimization (DPO) → Updated Embeddings → Evaluation (MRR, Hits@K)

**Design Tradeoffs:**
- Computational overhead vs. unlearning effectiveness: Out-boundary sampling increases processing time but improves unlearning quality
- Preference strength vs. context preservation: Stronger preference for forgetting may degrade surrounding knowledge
- Sampling granularity vs. efficiency: Finer boundary detection improves results but increases computational cost

**Failure Signatures:**
- Degradation in MRR for non-target triples indicates excessive forgetting beyond target knowledge
- High inference leakage suggests ineffective boundary sampling or preference optimization
- Unstable training curves may indicate improper preference formulation or learning rate issues

**Three First Experiments:**
1. Verify out-boundary sampling correctly identifies triples at knowledge graph periphery by visualizing sampled triples on small graphs
2. Test preference optimization on synthetic knowledge graphs with known structure to validate forgetting behavior
3. Measure inference leakage by comparing predictions before and after unlearning on held-out boundary triples

## Open Questions the Paper Calls Out
None

## Limitations
- Scalability concerns for very large knowledge graphs due to computational overhead of out-boundary sampling
- Limited evaluation of downstream application impacts beyond basic KG completion metrics
- Potential challenges with noisy or ambiguous knowledge graphs where clear boundaries are difficult to define

## Confidence
- Technical formulation: High confidence in GraphDPO's preference optimization framework
- Experimental results: Medium confidence due to limited exploration of edge cases and real-world complexity
- Generalizability: Low confidence in performance on extremely large-scale graphs and those with significant noise or ambiguity

## Next Checks
1. **Scalability Test**: Evaluate GraphDPO on a knowledge graph with over 10 million triples to assess computational efficiency and memory requirements of the out-boundary sampling strategy, measuring both inference time and storage overhead compared to baseline methods.

2. **Noise Robustness Evaluation**: Introduce controlled levels of noise (e.g., 5%, 10%, 15% incorrect triples) into the knowledge graph and measure how effectively GraphDPO maintains performance while unlearning specific triples, comparing against baseline methods under identical conditions.

3. **Downstream Task Impact Analysis**: Apply GraphDPO to unlearning in a knowledge graph used for a specific downstream application (e.g., question answering or recommendation system) and measure the impact on end-to-end task performance metrics, not just KG completion metrics, to validate practical utility.