---
ver: rpa2
title: LLM Meeting Decision Trees on Tabular Data
arxiv_id: '2505.17918'
source_url: https://arxiv.org/abs/2505.17918
tags:
- tabular
- data
- delta
- decision
- rule
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DeLTa, a novel method for tabular data prediction
  that integrates LLMs with decision tree rules, addressing privacy and model scalability
  issues in existing LLM-based tabular methods. Instead of serializing data or fine-tuning
  LLMs, DeLTa uses LLM reasoning to refine decision tree rules and guide error correction.
---

# LLM Meeting Decision Trees on Tabular Data

## Quick Facts
- arXiv ID: 2505.17918
- Source URL: https://arxiv.org/abs/2505.17918
- Reference count: 40
- This paper introduces DeLTa, a novel method for tabular data prediction that integrates LLMs with decision tree rules, achieving state-of-the-art performance across diverse tabular benchmarks.

## Executive Summary
This paper introduces DeLTa, a novel method for tabular data prediction that integrates LLMs with decision tree rules. Unlike existing LLM-based tabular methods that require data serialization or model fine-tuning, DeLTa uses LLM reasoning to refine decision tree rules and guide error correction. The approach addresses privacy and model scalability issues while achieving superior performance across diverse tabular benchmarks in both full and low-data regimes. Experiments show DeLTa outperforms existing LLM and non-LLM methods without requiring LLM fine-tuning or per-sample inference.

## Method Summary
DeLTa works by first training a Random Forest to generate diverse decision tree rules, then using an LLM to synthesize improved rules by identifying cross-tree patterns. The refined rules partition training data into leaf nodes where Gradient Nets learn to predict error correction vectors rather than labels directly. During inference, the original Random Forest predictions are corrected using these learned error vectors. This approach preserves privacy by avoiding direct data exposure while maintaining predictive utility through logical rule refinement.

## Key Results
- DeLTa achieves state-of-the-art performance across 12 diverse tabular benchmarks
- Outperforms both LLM-based and traditional non-LLM methods in both full and low-data regimes
- Shows computational efficiency by requiring no LLM fine-tuning or per-sample inference
- Ablation studies confirm both rule refinement and error correction components are critical

## Why This Works (Mechanism)

### Mechanism 1
LLMs can synthesize improved decision rules by identifying cross-tree patterns that individual greedy splits miss. Random Forest trains K diverse decision trees on data subsets, each producing independent rules based on local information gain. The LLM receives all rules and performs logic-based reasoning to (a) identify features with consistent importance across trees, (b) abstract core logic splits, and (c) synthesize a globally coherent rule. This produces r* with lower intra-node sample distance than individual tree rules. Core assumption: LLMs possess sufficient logical reasoning capability to analyze rule structures and identify meaningful patterns, even without domain knowledge or semantic feature names.

### Mechanism 2
Error correction vectors learned within LLM-refined partitions improve predictions more efficiently than direct label prediction. The refined rule r* partitions training data into leaf nodes. Within each node, a Gradient Net learns to predict the negative gradient -∇_F(x) L(F(x), y) rather than labels directly. At inference, the error correction vector Δx = η·φ(x) is added to the Random Forest prediction F(x), moving predictions in the "errors reducing" direction (Proposition 1 proof via Taylor expansion). Core assumption: Samples within the same r*-partitioned leaf node have similar residual error patterns, making gradient prediction easier than direct label prediction.

### Mechanism 3
Using decision tree rules (not serialized samples) as the LLM interface preserves privacy while maintaining predictive utility. Rules express global feature space partitions via feature-threshold comparisons (e.g., "feature_10 <= -0.59"), not individual sample values. This abstracts away sample-level information while preserving the logical structure needed for refinement. The LLM never sees raw feature values or sample counts. Core assumption: Rule structures alone contain sufficient information for LLMs to improve partitioning strategies without accessing distributional statistics of the underlying data.

## Foundational Learning

- **Gradient Boosting / Residual Learning**: DeLTa's error correction mechanism directly parallels gradient boosting—learning to predict residuals rather than labels. Understanding why negative gradients point toward lower loss is essential for interpreting Eq. 4-6.
  - Quick check question: Given a regression model with MSE loss, what does the negative gradient -∇_F(x) (F(x) - y)² represent, and how does it relate to the residual (y - F(x))?

- **Random Forest Ensemble Diversity**: DeLTa relies on extracting diverse rules from K independently-trained trees. Understanding why Random Forest trains on bootstrap samples and random feature subsets explains why the rule set R contains complementary patterns.
  - Quick check question: Why does Random Forest sample with replacement and randomly subset features at each split? How would using identical training data for all trees affect rule diversity?

- **Decision Tree Rule Extraction and Interpretation**: The LLM interface depends on extracting rules in a structured format (feature index, threshold, operator). Understanding the CART splitting criterion (information gain for classification, MSE reduction for regression) contextualizes what the LLM receives.
  - Quick check question: For a binary classification node with 60 positive and 40 negative samples, what is the Gini impurity? If a split produces children with [50, 10] and [10, 30], what is the information gain?

## Architecture Onboarding

- Component map: Training Data → Random Forest (K trees) → Rule Extraction → Rule Set R → LLM Prompt → Refined Rule r* → Partition Training Samples → Leaf Nodes → Gradient Net φ_l per leaf → Inference: F(x) + η·φ(x) → F*(x)

- Critical path:
  1. Rule quality from Random Forest (diverse, non-overfitting trees)
  2. LLM prompt design (must enforce output format, prevent task-irrelevant responses)
  3. Gradient Net training per leaf (sufficient samples per leaf node—default max 30 leaves)
  4. Hyperparameter η (step size for error correction)

- Design tradeoffs:
  - **Number of trees K**: More trees = richer rule set but longer LLM context; paper uses standard Random Forest settings
  - **Leaf node count for r***: Fewer leaves = simpler Gradient Net but coarser partitions; constrained by prompt ("no more than x" where x is max leaves among input trees)
  - **LLM backbone choice**: GPT-4o vs Qwen3-32B show similar average performance (Table 6-7), but per-dataset differences exist
  - **Query repetitions**: Default 10 queries with averaging adds robustness but increases cost; sensitivity analysis shows diminishing returns after ~5 queries (Fig. 7)

- Failure signatures:
  - **Degraded refinement**: LLM outputs malformed rules or copies input without synthesis → verify prompt format constraints, check LLM response parsing
  - **Gradient Net overfitting**: Performance degrades on validation set → check samples-per-leaf ratio, consider regularization or simpler models for φ_l
  - **No improvement over Random Forest**: Ablation shows rule refinement is critical (Table 4, 15-16); if w/o "RR" matches DeLTa, inspect LLM output quality
  - **Privacy leakage through rules**: If feature names are semantically meaningful (not anonymized), rules may reveal domain information → ensure feature anonymization before rule extraction

- First 3 experiments:
  1. **Reproduce ablation study on 2 datasets** (one classification: Credit, one regression: California_housing): Compare DeLTa vs w/o "RR" vs w/o "EC" vs Random Forest. Verify that rule refinement provides the largest gain and error correction adds incremental improvement.
  2. **Vary leaf node constraint in LLM prompt**: Test r* with max_leaves ∈ {10, 20, 30, 50} on a medium dataset (Adult). Plot performance vs leaf count to identify the sweet spot between partition granularity and Gradient Net sample sufficiency.
  3. **Compare LLM backbones with cost tracking**: Run GPT-4o vs Qwen3-32B vs a smaller model (e.g., Llama-3-8B) on 3 datasets, tracking API costs and latency. Assess whether performance differences justify cost tradeoffs for your deployment scenario.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can the DeLTa framework be generalized to unstructured or sequential data domains like time series analysis or graph learning?
- **Basis in paper:** [explicit] Appendix A.14 states, "DeLTa can be extended to other domains such as time series, graph and so on. We leave the extensions of DeLTa as a future work."
- **Why unresolved:** The current methodology relies on the specific partitioning logic of decision trees suited for tabular feature spaces, which may not natively capture temporal dependencies or topological structures without modification.
- **What evidence would resolve it:** Successful adaptation of the rule-refinement process for time-series forecasting or node classification tasks, showing performance gains over standard baselines.

### Open Question 2
- **Question:** How can the base rule extraction mechanism be improved to better leverage large-scale data, overcoming the plateau observed with Random Forests?
- **Basis in paper:** [inferred] Appendix A.14 notes that DeLTa's advantage narrows on large datasets because Random Forests train trees independently, potentially limiting rule quality. Appendix A.15 suggests "developing more scalable base rule extraction mechanisms."
- **Why unresolved:** The method currently depends on Random Forests for rule generation, which may not scale as effectively as neural networks or jointly optimized ensembles.
- **What evidence would resolve it:** A variant of DeLTa utilizing jointly optimized trees or neural extraction methods that maintains superior performance scaling as dataset size increases significantly.

### Open Question 3
- **Question:** Can LLM-driven fine-tuning be integrated directly with data-intensive architectures to combine rule interpretability with the scalability of deep learning?
- **Basis in paper:** [explicit] Appendix A.15 identifies a future direction in "integrating the rule-based paradigm with data-intensive architectures" and designing "LLM-driven fine-tuning that adapts to dataset scale."
- **Why unresolved:** The current framework uses LLMs only for rule refinement and error correction without modifying the underlying model weights, potentially limiting the integration of learned logic into end-to-end differentiable pipelines.
- **What evidence would resolve it:** A hybrid architecture where LLM reasoning directly influences neural network training or architecture configuration, demonstrating improved data efficiency and interpretability over standard black-box models.

## Limitations
- LLM reasoning capability for rule refinement may degrade significantly on datasets with highly correlated features or complex non-linear relationships when using anonymized feature names
- Privacy claims rely on assumptions about rule abstraction that lack rigorous quantitative evaluation or membership inference attack testing
- Performance advantage narrows on large datasets due to Random Forest's independent tree training limiting rule quality

## Confidence
- **High Confidence**: Experimental results showing DeLTa outperforms Random Forest, LLM-only, and non-LLM baselines across 12 datasets. The ablation studies demonstrating the importance of both rule refinement and error correction are well-supported.
- **Medium Confidence**: The theoretical justification for error correction via negative gradients is sound, but the empirical benefits may vary depending on dataset characteristics and hyperparameter settings.
- **Low Confidence**: Claims about privacy preservation through rule abstraction lack rigorous evaluation. No quantitative analysis of what information remains in the rules or how they might be reverse-engineered.

## Next Checks
1. **Rule Refinement Sensitivity**: Systematically test LLM performance when feature names are anonymized (feature_1, feature_2...) versus semantically meaningful names to quantify the impact of feature naming on rule improvement quality.
2. **Gradient Net Validation**: For each leaf node, compute the variance of gradients among training samples. Correlate this variance with the magnitude of performance improvement to empirically validate the intra-node similarity assumption.
3. **Privacy Analysis**: Conduct membership inference attacks using only the decision tree rules to assess whether individual sample information can be reconstructed or identified, providing empirical bounds on the privacy claims.