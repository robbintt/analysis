---
ver: rpa2
title: Domain-incremental White Blood Cell Classification with Privacy-aware Continual
  Learning
arxiv_id: '2503.19819'
source_url: https://arxiv.org/abs/2503.19819
tags:
- learning
- data
- performance
- classification
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses catastrophic forgetting in white blood cell
  classification under domain shifts by proposing a privacy-aware continual learning
  framework. The method employs a kernel density estimation-based generative replay
  approach that synthesizes latent representations of past domains without storing
  raw medical images, combined with Kullback-Leibler divergence-based knowledge distillation.
---

# Domain-incremental White Blood Cell Classification with Privacy-aware Continual Learning

## Quick Facts
- arXiv ID: 2503.19819
- Source URL: https://arxiv.org/abs/2503.19819
- Reference count: 26
- Achieves 10-15% accuracy improvements over naive fine-tuning while preserving privacy in WBC classification

## Executive Summary
This study addresses catastrophic forgetting in white blood cell classification under domain shifts by proposing a privacy-aware continual learning framework. The method employs a kernel density estimation-based generative replay approach that synthesizes latent representations of past domains without storing raw medical images, combined with Kullback-Leibler divergence-based knowledge distillation. Extensive experiments across four diverse datasets (PBC, LMU, MLL, UKA) and four backbone architectures demonstrate superior performance compared to conventional fine-tuning and other continual learning benchmarks.

## Method Summary
The framework combines kernel density estimation-based generative replay with knowledge distillation to prevent catastrophic forgetting during domain-incremental WBC classification. The approach extracts latent representations from a frozen backbone, clusters them using K-means, and builds a KDE-based generator to synthesize past-domain latents. During training, synthetic samples from previous domains are combined with current data, and the classifier is trained with a loss function that balances cross-entropy and KL-divergence between teacher and student models.

## Key Results
- Average accuracy improvements of 10-15% over naive fine-tuning across all backbones and datasets
- Best performance achieved with foundation models (UNI, CTransPath) compared to ResNet50
- Privacy preserved by generating synthetic latents without storing raw medical images

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Kernel Density Estimation (KDE) on clustered latent vectors approximates past domain distributions without storing raw images.
- **Mechanism**: K-means clustering reduces latent vectors to K representative centers per domain; KDE then models the probability density around these centers. During replay, synthetic latent vectors are sampled from this density, enabling the classifier to rehearse past domains without accessing original data.
- **Core assumption**: Cluster centers preserve sufficient information about the original data distribution for effective replay; the latent space is structured enough that density estimation captures task-relevant features.
- **Evidence anchors**:
  - [abstract] "kernel density estimation-based generative replay approach that synthesizes latent representations of past domains without storing raw medical images"
  - [Section 2.1] "Only the resulting cluster centers are retained... The bandwidth parameter B of our KDE-based generator is automatically determined using Silverman's rule of thumb"
  - [corpus] Weak direct validation; corpus papers focus on WBC classification but not KDE-based generative replay for CL.
- **Break condition**: If latent space is poorly structured (e.g., backbone not domain-invariant), cluster centers may fail to capture discriminative information, causing replay to be ineffective.

### Mechanism 2
- **Claim**: Combining generative latent replay (GLR) with KL-divergence distillation (DST) provides complementary regularization against catastrophic forgetting.
- **Mechanism**: GLR supplies synthetic examples for explicit rehearsal; DST enforces output-level consistency between student (current model) and teacher (previous model), constraining weight updates to retain prior knowledge.
- **Core assumption**: The teacher model's logits encode meaningful past-task knowledge that transfers through distillation; generated latents approximate true past-data distributions closely enough for meaningful rehearsal.
- **Evidence anchors**:
  - [abstract] "combined with Kullback-Leibler divergence-based knowledge distillation"
  - [Section 2.2] "loss = (1 − α) × lossCE + α × lossKLD"
  - [Table 8] Ablation shows GLR alone outperforms DST alone, but combined achieves best ACC/ILM across all backbones.
  - [corpus] No direct corpus evidence for this specific combination in WBC classification.
- **Break condition**: If α is set too high, regularization over-constrains plasticity; if too low, forgetting is insufficiently mitigated. Optimal α varies by backbone (see ablation).

### Mechanism 3
- **Claim**: Freezing the backbone preserves feature-space structure, ensuring the KDE generator remains valid across sequential tasks.
- **Mechanism**: Only the classifier head (5 FC layers) is trained; backbone weights stay fixed. This maintains a stable latent space where cluster centers and KDE densities remain semantically meaningful.
- **Core assumption**: The pre-trained backbone has already learned sufficiently general features; task-specific adaptation can be achieved through the classifier alone.
- **Evidence anchors**:
  - [Section 3.3] "we freeze the backbone weights to preserve the KDE-based latent generator's validity, training only the FC layers"
  - [Figure 3] Foundation models (UNI, CTransPath) outperform ResNet50, suggesting backbone quality matters for CL performance.
  - [corpus] DinoBloom paper (corpus neighbor) similarly trains foundation models for hematology, supporting pre-trained backbone utility.
- **Break condition**: If backbone features are insufficient for discriminating new domains, freezing prevents necessary adaptation, degrading performance on later tasks.

## Foundational Learning

- **Concept: Catastrophic Forgetting**
  - **Why needed here**: The entire paper addresses this phenomenon—neural networks overwrite previously learned representations when fine-tuned on new data.
  - **Quick check question**: Can you explain why fine-tuning on a new hospital's WBC data would hurt accuracy on the previous hospital's data?

- **Concept: Kernel Density Estimation (KDE)**
  - **Why needed here**: KDE is the core generative mechanism; understanding non-parametric density estimation is essential to grasp how synthetic latents are produced.
  - **Quick check question**: Given a set of cluster centers, how would KDE generate a new sample that represents their distribution?

- **Concept: Knowledge Distillation**
  - **Why needed here**: The KL-divergence term enforces teacher-student consistency; this is a standard CL technique but applied here with a frozen backbone.
  - **Quick check question**: Why would aligning output logits between teacher and student help preserve past knowledge?

## Architecture Onboarding

- **Component map**:
  1. **Backbone** (ResNet50/RetCCL/CTransPath/UNI): Frozen feature extractor producing latent vectors.
  2. **Classifier head**: 5 FC layers [512→256→128→64→32→num_classes], trainable.
  3. **K-means + KDE generator**: Clusters latents, builds density, generates synthetic replay samples.
  4. **Loss combiner**: Mixes CE loss (current + generated data) with KL divergence (teacher-student).

- **Critical path**:
  1. Extract latents from current task via frozen backbone → 2. Cluster latents, update KDE generator → 3. Sample synthetic latents from updated KDE → 4. Combine current batch (50%) with generated latents (50%) → 5. Train classifier with CE + KL loss → 6. Archive current model as teacher for next task.

- **Design tradeoffs**:
  - **Buffer size (K)**: Paper uses 10 clusters/domain (40 total for 4 tasks). More clusters improve approximation but increase storage/computation.
  - **α (distillation weight)**: 0.01–0.2 optimal depending on backbone. Stronger backbones need less regularization.
  - **Backbone choice**: UNI performs best but requires more resources; ResNet50 is lightweight but lower ceiling.

- **Failure signatures**:
  - **High BWT (negative)**: Model is forgetting past domains. Check if KDE generator is sampling meaningfully; verify α is not too low.
  - **ACC drops on later tasks**: Backbone may be too weak; consider stronger FM or unfreeze with careful regularization.
  - **High variance across runs**: K-means initialization instability; increase runs or fix random seeds.

- **First 3 experiments**:
  1. **Baseline sanity check**: Run naive fine-tuning on Seq.1 with ResNet50. Confirm catastrophic forgetting (ACC ~56% as in Table 4).
  2. **Ablation validation**: Run proposed method with GLR only (no DST), then DST only (no GLR), then both. Compare to Table 8 to validate implementation.
  3. **Backbone comparison**: Run full method on one sequence with all four backbones. Verify UNI > CTransPath > RetCCL > ResNet50 as in Figure 3.

## Open Questions the Paper Calls Out

None

## Limitations

- The framework assumes frozen backbone features are sufficiently discriminative across all domain shifts, which may not hold for significantly different data distributions
- Privacy preservation claims are based on not storing raw images, but the study does not formally evaluate privacy leakage through synthetic latents
- Claims about clinical applicability assume the domain shifts between datasets represent realistic clinical scenarios, which is reasonable but not explicitly validated

## Confidence

- **High Confidence**: The 10-15% accuracy improvement over naive fine-tuning is well-supported by extensive ablation studies across four backbones and four datasets
- **Medium Confidence**: The privacy-utility tradeoff claim is plausible given the methodology but lacks formal privacy analysis or differential privacy guarantees
- **Medium Confidence**: Claims about clinical applicability assume the domain shifts between datasets represent realistic clinical scenarios, which is reasonable but not explicitly validated

## Next Checks

1. Conduct formal privacy analysis measuring information leakage through synthetic latents to validate privacy claims
2. Test framework performance when backbone features are insufficient for new domains by introducing more severe distribution shifts
3. Evaluate computational overhead and storage requirements for different cluster sizes (K) in real-world deployment scenarios