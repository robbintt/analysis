---
ver: rpa2
title: 'Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context
  Permutation'
arxiv_id: '2505.11754'
source_url: https://arxiv.org/abs/2505.11754
tags:
- noise
- documents
- scores
- mean
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how Language Models (LMs) perform on multi-hop
  question answering (MHQA) tasks when the order of context documents is permuted.
  The authors analyze the impact of different document arrangements, distances between
  relevant documents, and the completeness of context on LM performance.
---

# Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation

## Quick Facts
- arXiv ID: 2505.11754
- Source URL: https://arxiv.org/abs/2505.11754
- Reference count: 40
- Encoder-decoder models (Flan-T5) outperform causal decoder-only models (Qwen2.5, Llama) on multi-hop QA, with optimal performance when document order matches the reasoning chain.

## Executive Summary
This paper investigates how Language Models perform on multi-hop question answering tasks when the order of context documents is permuted. The authors analyze the impact of different document arrangements, distances between relevant documents, and context completeness on LM performance. They find that encoder-decoder models like Flan-T5 generally outperform causal decoder-only LMs in MHQA tasks, even with smaller sizes. The order of gold documents matters, with optimal performance when the document order aligns with the reasoning chain order. They also discover that enhancing causal decoder-only models with bi-directional attention by modifying the causal mask can effectively boost their performance. By analyzing attention distributions, the authors find that higher attention weights correlate with correct answers and use this to heuristically improve LM performance.

## Method Summary
The study uses the MuSiQue dataset (19,938 train / 2,417 dev queries; 2-4 hop questions, ≤20 docs/query) to evaluate four experimental setups: Answer Only, Chain-of-Thought zero-shot, LoRA finetuned, and Finetuned + bidirectional mask. Four context permutation strategies are tested: Forward (reasoning chain order), Backward (reverse), Forward_i (i noise docs between gold, i=0-5), and Remove First. Models evaluated include Flan-T5 (80M-11B), Qwen2.5 (0.5B-14B), and Llama 3.x (1B-8B). The authors compute grouped attention and Information Contribution (IC) scores to analyze attention distributions. For the bidirectional mask modification, they replace the causal mask with a prefix mask that allows bidirectional attention within context tokens while maintaining causal generation.

## Key Results
- Encoder-decoder models (Flan-T5) consistently outperform causal decoder-only models (Qwen2.5, Llama) across all permutation settings and model sizes
- Forward permutation (reasoning chain order) achieves the highest accuracy, while Backward permutation performs worst
- Distance between relevant documents significantly impacts performance, with larger gaps leading to lower accuracy
- Bidirectional mask modification for causal models provides consistent accuracy improvements
- Higher attention weights correlate with correct answers, enabling heuristic performance improvement through document reordering

## Why This Works (Mechanism)
The mechanism relies on how language models process sequential information. Encoder-decoder models like Flan-T5 have bi-directional attention capabilities, allowing them to consider all context simultaneously during encoding. This architecture naturally supports the reasoning chain structure required for multi-hop QA. Causal decoder-only models, in contrast, process information sequentially with restricted attention, making them more sensitive to document order. The bidirectional mask modification effectively gives causal models encoder-like attention patterns over the context while preserving generation capabilities. The attention-based IC score heuristic works because models that correctly attend to relevant context tokens during reasoning are more likely to produce correct answers.

## Foundational Learning
- **Multi-hop Question Answering**: QA tasks requiring reasoning across multiple documents to answer a single question. Why needed: This is the core task being evaluated and the basis for all permutation experiments.
- **Context Permutation**: Systematic rearrangement of document order in the input context. Why needed: Allows testing how document ordering affects model reasoning and performance.
- **Information Contribution (IC) Score**: A metric measuring the correlation between attention weights and correct answers. Why needed: Provides quantitative evidence for how attention patterns relate to model performance.
- **Bi-directional vs Causal Attention**: Different attention mechanisms where encoder-decoder models use bi-directional attention while decoder-only models use causal attention. Why needed: Explains the architectural differences that lead to performance variations.
- **Chain-of-Thought Prompting**: A technique where models are prompted to show their reasoning steps before providing an answer. Why needed: One of the experimental setups tested for different prompting strategies.
- **LoRA Fine-tuning**: Low-Rank Adaptation, a parameter-efficient fine-tuning method. Why needed: The finetuning approach used to adapt models to the multi-hop QA task.

## Architecture Onboarding

**Component Map**: Document Retriever -> Document Shuffler (Permutation Generator) -> Prompt Template -> Language Model -> Answer Extractor -> IC Score Calculator -> Performance Evaluator

**Critical Path**: Document Retriever → Document Shuffler → Prompt Template → Language Model → Answer Extractor → Performance Evaluator
The critical path flows from document retrieval through permutation, prompting, model inference, answer extraction, and performance evaluation. The IC score calculator runs in parallel with answer extraction to provide attention-based analysis.

**Design Tradeoffs**: The paper trades computational efficiency for analytical depth by implementing multiple permutation strategies and attention analyses. Using LoRA fine-tuning balances parameter efficiency with performance gains. The bidirectional mask modification introduces computational overhead but provides consistent accuracy improvements for causal models.

**Failure Signatures**: Small models (Qwen 0.5B/1.5B, Llama 3.2 1B) may ignore CoT instructions and produce unstructured outputs. Performance drops unexpectedly with distance between relevant documents may indicate improper Forward_i implementation. Bidirectional mask implementation errors can manifest as shape mismatches or incorrect attention patterns.

**First Experiments**:
1. Verify Forward permutation implementation by checking that documents are ordered according to the reasoning chain labels extracted from MuSiQue
2. Test bidirectional mask implementation by confirming that context tokens can attend bidirectionally while generation remains causal
3. Validate IC score computation by checking that attention weights from gold documents correlate with correct answers in simple cases

## Open Questions the Paper Calls Out
- **Dataset Causality**: Which specific training datasets within the Flan collection cause encoder-decoder models to develop the forward-order preference for multi-hop reasoning? The authors observed this behavior but didn't conduct ablation studies across Flan's constituent datasets.
- **Long-Context Scaling**: How do context permutation effects scale to longer contexts (e.g., 32k+ tokens) and more documents? Current experiments were limited to ~20 documents due to computational constraints.
- **Attribution Mechanisms**: How can effective attribution mechanisms be developed to detect when MHQA models rely on parametric knowledge rather than provided context evidence? The "Remove First" experiments suggest models default to parametric knowledge when context is insufficient.
- **IC Score Optimization**: Can the peak IC score heuristic be developed into a practical real-time method for optimizing document ordering during inference? The current approach requires multiple inference passes, making it computationally expensive.

## Limitations
- Analysis relies heavily on the MuSiQue dataset, which may have domain-specific characteristics that don't generalize to other MHQA tasks
- Permutation strategies represent simplified views of real-world document ordering variability
- Bidirectional mask modification for causal models may introduce computational overhead that wasn't fully characterized
- Attention-based IC score heuristic requires access to attention weights and may not be practical for all model architectures

## Confidence
- **High Confidence**: Encoder-decoder models outperform causal decoder-only models on MHQA tasks (supported by statistical significance across multiple models and permutations)
- **Medium Confidence**: Optimal performance occurs when document order matches reasoning chain order (supported by Forward permutation results but may be dataset-dependent)
- **Medium Confidence**: Higher attention weights correlate with correct answers (demonstrated through IC analysis but represents correlation rather than causation)

## Next Checks
1. **Dataset Generalization Test**: Validate permutation performance patterns on a different MHQA dataset (e.g., HotpotQA or 2WikiMultihopQA) to confirm whether observed trends hold across domains and dataset construction methodologies
2. **Real-World Document Order Simulation**: Implement a more realistic document ordering simulation that reflects actual retrieval scenarios, including variable hop counts, non-linear reasoning paths, and document relevance uncertainty
3. **Bidirectional Mask Overhead Analysis**: Measure the computational and memory overhead of the bidirectional mask modification across different model sizes and batch configurations to determine if performance gains justify additional resource requirements in practical deployment scenarios