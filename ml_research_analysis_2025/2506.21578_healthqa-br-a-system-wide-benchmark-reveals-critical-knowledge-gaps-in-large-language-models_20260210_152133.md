---
ver: rpa2
title: 'HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large
  Language Models'
arxiv_id: '2506.21578'
source_url: https://arxiv.org/abs/2506.21578
tags:
- knowledge
- health
- medical
- enare
- questions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces HealthQA-BR, the first large-scale, system-wide\
  \ benchmark for Portuguese-speaking healthcare, designed to address the limitations\
  \ of physician-centric, English-language LLM evaluations. The dataset comprises\
  \ 5,632 questions from Brazil\u2019s national licensing and residency exams, spanning\
  \ medicine, nursing, dentistry, psychology, social work, and allied health professions."
---

# HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models

## Quick Facts
- arXiv ID: 2506.21578
- Source URL: https://arxiv.org/abs/2506.21578
- Reference count: 18
- Primary result: HealthQA-BR benchmark reveals LLM performance is highly uneven across healthcare specialties, ranging from 98.7% in Ophthalmology to 60.0% in Neurosurgery.

## Executive Summary
HealthQA-BR is the first large-scale, system-wide benchmark for evaluating Portuguese-speaking LLMs across the full spectrum of healthcare professions, including medicine, nursing, dentistry, psychology, social work, and allied health. The dataset comprises 5,632 questions from Brazil's national licensing and residency exams. While top models like GPT 4.1 achieve high overall accuracy (86.6%), the benchmark reveals alarming, previously unmeasured deficiencies where performance plummets from near-perfect in some specialties to barely passing in others. This "spiky" knowledge profile is consistent across all evaluated models, highlighting the insufficiency of single-score evaluations for safety validation in healthcare.

## Method Summary
The benchmark uses zero-shot evaluation of multiple-choice questions (5 options each) from Brazilian healthcare licensing and residency exams. Questions are extracted from PDFs, processed through OCR correction, deduplicated using both exact matching and semantic similarity, then tagged with metadata including specialty, source, and year. Models are prompted with standardized instructions to return only the answer letter. The evaluation uses a consistent accuracy metric across all models, with performance measured both overall and broken down by specialty.

## Key Results
- GPT 4.1 achieves highest overall accuracy at 86.6%, but performance varies dramatically by specialty
- Specialty performance ranges from 98.7% in Ophthalmology to 60.0% in Neurosurgery and 68.4% in Social Work
- Smaller models (1B-8B parameters) score near random baseline of 21.89%
- Performance variance across specialties exceeds 30 percentage points for all models
- "Spiky" knowledge profile is consistent across all evaluated models regardless of architecture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aggregate accuracy scores mask specialty-specific knowledge gaps, creating an illusion of competence.
- Mechanism: High-frequency, well-represented domains in training data (e.g., Ophthalmology, Pathology) inflate overall scores, while low-frequency domains (e.g., Neurosurgery, Social Work) remain under-assessed in aggregate metrics. The averaging effect obscures critical deficiencies.
- Core assumption: Training data distribution correlates with benchmark performance across specialties.
- Evidence anchors: [abstract] "while state-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%), this top-line score masks alarming, previously unmeasured deficiencies"; [section 4.2] "performance plummets from near-perfect in specialties like Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%)"

### Mechanism 2
- Claim: The "spiky" knowledge profile is a systemic property of current LLMs, not model-specific artifacts.
- Mechanism: Pre-training corpora systematically over-represent certain medical domains (specialized, high-income medicine) while under-representing others (public health, social work, preventative care), creating consistent gaps across architectures and training methodologies.
- Core assumption: The observed pattern reflects training data composition rather than evaluation methodology artifacts.
- Evidence anchors: [abstract] "This 'spiky' knowledge profile is a systemic issue observed across all models"; [section 5] "this pattern of uneven performance is a universal phenomenon observed across all evaluated models"

### Mechanism 3
- Claim: Physician-centric benchmarks create a dangerous illusion by ignoring interprofessional healthcare reality.
- Mechanism: Existing benchmarks (e.g., USMLE-based) evaluate only physician knowledge, ignoring nurses, social workers, and allied health professionals who constitute the majority of care delivery. This narrow focus inflates perceived AI readiness for healthcare systems.
- Core assumption: Safe AI deployment requires competency across the full healthcare team, not just physician-level knowledge.
- Evidence anchors: [abstract] "evaluation of Large Language Models (LLMs) in healthcare has been dominated by physician-centric, English-language benchmarks, creating a dangerous illusion of competence"; [section 1] "modern healthcare is not the domain of a single physician but a collaborative, interprofessional effort"

## Foundational Learning

- Concept: Zero-shot evaluation
  - Why needed here: The paper uses zero-shot prompting to assess inherent model knowledge without task-specific examples or fine-tuning, isolating pre-trained capabilities.
  - Quick check question: Can you explain why zero-shot evaluation differs from few-shot, and what each measures about model capabilities?

- Concept: Specialty-level granularity in benchmarking
  - Why needed here: The core finding depends on breaking down aggregate scores by specialty; understanding why single scores fail requires grasping distribution-dependent masking effects.
  - Quick check question: If a model scores 85% overall but 60% in one critical specialty, what deployment risks emerge?

- Concept: Multi-professional healthcare systems
  - Why needed here: The benchmark uniquely includes nursing, social work, dentistry, and allied health; understanding why this matters requires grasping interprofessional care models.
  - Quick check question: Why might a model that passes physician exams still fail in a public health system relying heavily on social workers?

## Architecture Onboarding

- Component map: PDF extraction -> OCR correction -> deduplication -> metadata tagging -> Parquet serialization -> zero-shot evaluation -> accuracy aggregation
- Critical path: 1. Extract and validate questions against official answer keys; 2. Apply two-tier deduplication (hash-based + semantic similarity + manual review); 3. Tag each question with source, year, and specialty metadata; 4. Run zero-shot evaluation with controlled generation parameters; 5. Aggregate results by specialty, not just overall accuracy
- Design tradeoffs: MCQ format limits assessment to semantic knowledge; cannot evaluate clinical reasoning or communication; Portuguese-only; generalizability to other languages requires separate validation; accuracy metric is "most charitable"â€”does not penalize confident wrong answers
- Failure signatures: Models scoring near-random (21.9% baseline) indicate fundamental domain knowledge absence; large variance between specialties (>30 percentage points) signals spiky knowledge profile; consistent underperformance in public health/social work domains suggests training data bias
- First 3 experiments: 1. Replicate the zero-shot evaluation on a subset of 100 questions across 3 specialties (high, medium, low performer) to validate pipeline; 2. Test whether few-shot prompting (2-3 examples per specialty) reduces variance between high and low-performing specialties; 3. Evaluate a domain-adapted model (fine-tuned on Brazilian health guidelines) to assess if Social Work/public health gaps are remediable through targeted training data

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Are the specific specialty-level knowledge gaps identified in HealthQA-BR (e.g., in Neurosurgery and Social Work) universal across different languages and healthcare systems?
- **Basis in paper:** [explicit] The authors state in the conclusion that they are releasing the benchmark to "help determine if the knowledge gaps we have identified are universal" (p. 12).
- **Why unresolved:** This study evaluates only Portuguese-language models within the Brazilian context; without comparable system-wide, multi-professional benchmarks in other languages, generalizability cannot be confirmed.
- **What evidence would resolve it:** Cross-linguistic evaluation using equivalent multi-professional datasets (e.g., English or Spanish) showing similar performance variances in low-resource specialties like Social Work.

### Open Question 2
- **Question:** Can targeted interventions, such as specialized fine-tuning or Retrieval-Augmented Generation (RAG), successfully remediate the "spiky" knowledge profiles observed in state-of-the-art models?
- **Basis in paper:** [inferred] The Discussion section posits that the granular analysis serves as a "playbook for improvement" and suggests "focused initiatives" like RAG or fine-tuning (p. 11), but the paper provides no experimental evidence that these methods flatten the performance variance.
- **Why unresolved:** The paper focuses on evaluation and diagnosis of gaps rather than testing remediation strategies.
- **What evidence would resolve it:** A follow-up study measuring accuracy delta in weak specialties (e.g., Social Work) after administering domain-specific fine-tuning or RAG integration.

### Open Question 3
- **Question:** Does the significant underperformance in public health and social work disciplines stem from a systemic bias in LLM training corpora that over-represents specialized, high-income medicine?
- **Basis in paper:** [inferred] The authors hypothesize that low scores in Social Work and Collective Medicine "may point to a systemic bias in training data that over-represents specialized, high-income medicine" (p. 11).
- **Why unresolved:** While the performance gap is empirically demonstrated, the causal link to specific training data distributions remains a theoretical explanation without a corpus analysis.
- **What evidence would resolve it:** A quantitative analysis of common LLM pre-training datasets correlating the frequency of subspecialty textual data with the observed accuracy scores in HealthQA-BR.

## Limitations

- The MCQ format constrains assessment to factual recall rather than clinical reasoning or communication skills
- Geographic and linguistic specificity (Brazilian Portuguese, national exam content) limits generalizability to other healthcare contexts
- The "most charitable" accuracy metric does not account for model confidence calibration or penalize confident wrong answers

## Confidence

**High Confidence**: The finding that aggregate accuracy scores mask specialty-specific deficiencies is robust, supported by clear performance disparities across specialties (98.7% vs 60.0%) observed consistently across all evaluated models.

**Medium Confidence**: The systemic nature of "spiky" knowledge profiles across different model architectures and training approaches is plausible but requires validation across additional model families and training paradigms to rule out shared architectural biases.

**Low Confidence**: The claim that physician-centric benchmarks create dangerous illusions for interprofessional healthcare deployment assumes that model safety in one specialty transfers to others, which may not hold given the observed specialty-specific gaps.

## Next Checks

1. **Cross-linguistic validation**: Replicate the specialty-level analysis on an equivalent English-language healthcare benchmark to determine whether spiky knowledge profiles are language-independent or specific to Portuguese training data distributions.

2. **Clinical reasoning assessment**: Supplement MCQ evaluation with scenario-based questions requiring multi-step clinical reasoning to determine if knowledge gaps persist when assessment moves beyond factual recall.

3. **Intervention testing**: Fine-tune a base model on underrepresented specialties (Social Work, public health) and re-evaluate to determine whether observed gaps are remediable through targeted training data augmentation.