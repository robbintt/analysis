---
ver: rpa2
title: 'Riddle Quest : The Enigma of Words'
arxiv_id: '2601.19273'
source_url: https://arxiv.org/abs/2601.19273
tags:
- riddle
- riddles
- generation
- semantic
- validator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a general-purpose pipeline for analogy-based
  riddle generation, extending a previous educational-focused framework to support
  open-domain, genre-flexible riddle creation. The method integrates structured concept
  triples, semantic attribute mapping, stylized generation, and a validator for extracting
  all plausible answers.
---

# Riddle Quest : The Enigma of Words

## Quick Facts
- arXiv ID: 2601.19273
- Source URL: https://arxiv.org/abs/2601.19273
- Reference count: 0
- Primary result: Analogy-based pipeline generates diverse riddles; LLMs retrieve only ~56% of validator-identified answers, especially for metaphorical/poetic forms.

## Executive Summary
This work presents a general-purpose pipeline for analogy-based riddle generation, extending a previous educational-focused framework to support open-domain, genre-flexible riddle creation. The method integrates structured concept triples, semantic attribute mapping, stylized generation, and a validator for extracting all plausible answers. Across 120 concepts and five genres, the system produces diverse, interpretable riddles, with descriptive forms yielding more constrained answers (median 3.1 per riddle) and metaphorical/poetic forms producing broader answer sets. A case study reveals that large language models retrieve only ~56% of validator-identified answers on average, struggling especially with metaphorical and poetic riddles. This highlights riddles as a micro-benchmark for evaluating generative reasoning, analogy-making, and ambiguity handling in AI systems.

## Method Summary
The pipeline generates riddles through a four-module process: (1) Triples Creator extracts structured concept facts from open-domain knowledge; (2) Semantic Attribute Mapper categorizes properties into functional, perceptual, relational, and behavioral types; (3) Stylized Generator produces genre-specific riddles using these semantic profiles; (4) Validator enumerates all plausible answers via a lookup dictionary. The system supports five genres—descriptive, metaphorical, poetic, humorous, and situational—and demonstrates that genre influences answer-space size, with metaphorical/poetic riddles yielding the broadest sets. No training is involved; the approach relies on knowledge graphs and LLM-based generation.

## Key Results
- Descriptive riddles produce constrained answer sets (median ~3.1 per riddle); metaphorical/poetic riddles yield broader sets due to higher abstraction.
- LLMs retrieve only ~56% of validator-identified answers on average, struggling especially with metaphorical and poetic riddles.
- LLM case study shows models often overcommit to single guesses and compress answers into high-level abstractions, missing answer diversity.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured concept triples enable cross-domain analogy formation by decoupling semantic representation from surface-level generation.
- Mechanism: The Triples Creator represents concepts as ⟨concept, relation, property⟩ triples drawn from open-domain knowledge, allowing the Semantic Mapper to group properties into functional, perceptual, relational, and behavioral categories. This categorization supports analogical clue formation even for abstract concepts lacking concrete physical properties.
- Core assumption: Analogical reasoning requires explicit semantic structure rather than implicit neural representations alone.
- Evidence anchors:
  - [abstract] "The system includes a triples creator that builds structured facts about a concept, a semantic mapper that selects attributes useful for analogy"
  - [section 3.1-3.2] "this extended version draws from open-domain conceptual knowledge, enabling representation of abstract, metaphorical, or genre-specific attributes essential for analogy-based riddles"
  - [corpus] Limited direct corpus support; related work on ConceptNet and WordNet cited but not empirically validated for this specific pipeline.
- Break condition: If triples are sparse or incomplete for novel concepts, semantic profiles will be underspecified, yielding riddles with weak analogical grounding.

### Mechanism 2
- Claim: Genre-specific stylistic generation produces systematically different answer-space distributions by emphasizing different semantic attribute categories.
- Mechanism: The Stylised Generator maps semantic attributes to genre-appropriate expressions (descriptive foregrounds functional/perceptual attributes; metaphorical/poetic foregrounds relational/behavioral attributes). Descriptive riddles produce constrained answer sets (median ~3.1), while metaphorical/poetic riddles yield broader sets due to higher abstraction.
- Core assumption: Modular separation between semantic mapping and stylistic construction enables controlled variation in answer ambiguity.
- Evidence anchors:
  - [abstract] "descriptive forms yielding more constrained answers (median 3.1 per riddle) and metaphorical/poetic forms producing broader answer sets"
  - [section 4.1] "Descriptive riddles tended to foreground functional and perceptual attributes, whereas metaphorical and poetic riddles relied more heavily on relational or behavioral semantic mappings"
  - [corpus] Neighbor papers on riddle evaluation (BanglaRiddleEval, Indian Riddles) show genre/culture affects LLM performance, but no direct validation of the genre-ambiguity relationship.
- Break condition: If genre cues are weakly specified or the generator conflates styles, answer-space distributions will converge, reducing discriminative utility.

### Mechanism 3
- Claim: Validator-based enumeration exposes a generator-validator gap in LLMs that single-answer evaluation metrics miss.
- Mechanism: The Validator extracts all plausible answers using a lookup dictionary, revealing that LLMs retrieve only ~56% of validator-identified answers on average. LLMs overcommit to single guesses and compress answers into high-level abstractions (e.g., "a measuring device" vs. listing specific instances).
- Core assumption: Exhaustive enumeration is a distinct reasoning capability from generative interpretation.
- Evidence anchors:
  - [abstract] "large language models retrieve only ~56% of validator-identified answers on average, struggling especially with metaphorical and poetic riddles"
  - [section 5.2-5.3] "LLMs often treated riddles as having one 'correct' answer... sometimes merged multiple concepts into a single abstraction"
  - [corpus] RankAlign paper directly addresses generator-validator gaps in LLMs, supporting the broader validity of this mechanism.
- Break condition: If the validator's lookup dictionary is incomplete, it will undercount valid answers and overestimate the gap; if LLMs are prompted iteratively, the gap may narrow.

## Foundational Learning

- Concept: Structure-Mapping Theory (Gentner, 1983)
  - Why needed here: The pipeline's analogy-based approach assumes relational structure, not just surface similarity, drives meaningful clue formation.
  - Quick check question: Can you explain why "time flows like a river" is a relational analogy rather than a mere feature match?

- Concept: Knowledge Graph Triple Representation (⟨subject, predicate, object⟩)
  - Why needed here: The Triples Creator outputs structured facts that the Semantic Mapper categorizes; understanding RDF-style representations is essential.
  - Quick check question: Given "sun → provides → light," what relation type would you assign (functional, perceptual, relational, behavioral)?

- Concept: Generator-Validator Gap in LLMs
  - Why needed here: The case study frames riddles as a micro-benchmark for this gap; understanding the distinction helps interpret why 56% retrieval matters.
  - Quick check question: If an LLM answers "thermometer" for a riddle where the validator lists [thermometer, thermostat, temperature gauge], what type of gap does this illustrate?

## Architecture Onboarding

- Component map:
  - Triples Creator → Semantic Attribute Mapper → Stylised Generator → Validator
  - Triples Creator: open-domain knowledge extraction
  - Semantic Mapper: property categorization (functional, perceptual, relational, behavioral)
  - Generator: genre-adaptive clue synthesis
  - Validator: exhaustive answer enumeration via lookup dictionary

- Critical path: Semantic Mapper output quality determines Generator expressiveness; Validator completeness determines benchmark utility.

- Design tradeoffs: Open-domain triples increase coverage but introduce noise; lookup-based validation is systematic but may miss novel answers LLMs generate.

- Failure signatures:
  - Sparse triples → vague, unsolvable riddles
  - Over-generic semantic profiles → riddles with unreasonably large answer sets
  - Genre conflation → inconsistent answer-space distributions

- First 3 experiments:
  1. Run the pipeline on 10 abstract concepts (e.g., "justice," "memory") and inspect triple completeness; flag any with <5 properties.
  2. Generate riddles in all 5 genres for 5 concepts; manually verify that answer-set sizes correlate with genre (descriptive < metaphorical < poetic).
  3. Compare validator outputs vs. LLM retrieval for 10 riddles; identify which genres show the largest gaps and whether LLMs produce valid answers not in the lookup dictionary.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can large language models be adapted to perform exhaustive answer retrieval for riddles, rather than overcommitting to a single intended solution?
- Basis in paper: [explicit] The authors explicitly note that LLMs "struggle with the exhaustive reasoning required to generate full answer sets" and often "overcommit to a single guess."
- Why unresolved: The case study demonstrated a performance gap (retrieving only ~56% of answers), but the paper does not propose a method to bridge this gap between generative interpretation and systematic enumeration.
- What evidence would resolve it: Experiments demonstrating that specific prompting strategies or fine-tuning enable LLMs to consistently retrieve >90% of validator-identified answers.

### Open Question 2
- Question: How can the validator's static lookup dictionary be scaled or hybridized to capture the "interpretive range" of valid answers produced by LLMs?
- Basis in paper: [explicit] The paper reports that LLMs "frequently generated plausible answers that were *not* in the validator’s lookup dictionary."
- Why unresolved: This finding indicates the current validator acts as an incomplete ground truth, failing to recognize valid creative interpretations outside its fixed database.
- What evidence would resolve it: A modified validation mechanism that successfully integrates dynamic LLM proposals into a comprehensive, verified answer set.

### Open Question 3
- Question: What decoding interventions can prevent LLMs from engaging in "semantic compression" when solving riddles?
- Basis in paper: [explicit] The authors observe a failure mode where LLMs "merged multiple concepts into a single abstraction" (e.g., saying "measuring device" instead of listing specific tools), undercounting answer diversity.
- Why unresolved: The paper identifies this behavioral pattern as a key source of error but does not investigate the architectural or probabilistic causes behind it.
- What evidence would resolve it: A study showing that adjusted temperature settings or constrained decoding leads to the listing of distinct entities rather than abstract categories.

## Limitations

- The LLM model, prompts, and validator's lookup dictionary are not specified, preventing exact reproduction of the ~56% retrieval rate.
- Open-domain triple extraction is underspecified, risking sparse semantic profiles for novel concepts.
- The validator's completeness is bounded by dictionary coverage, which could underestimate LLM performance if valid answers fall outside the lookup.

## Confidence

- **High confidence**: The modular pipeline design (triples → semantic mapping → genre generation → validation) is well-specified and internally consistent. The qualitative observations about genre-ambiguity relationships and the generator-validator gap are supported by the described mechanisms.
- **Medium confidence**: The quantitative claims (56% LLM retrieval, median 3.1 answers) are plausible given the framework but are not fully reproducible without the missing technical details.
- **Low confidence**: The claim that riddles are a "micro-benchmark for analogical reasoning" is aspirational; direct comparison to established benchmarks is absent.

## Next Checks

1. Validate semantic profile completeness: For 10 abstract concepts (e.g., "justice," "memory"), extract triples and verify each has ≥5 properties across the four semantic categories. Flag any with sparse profiles.
2. Test genre-ambiguity correlation: Generate riddles for 5 concepts across all 5 genres. Manually verify that descriptive riddles yield smaller answer sets than metaphorical/poetic ones, and that answer-set sizes are consistently ordered by genre.
3. Measure generator-validator gap: For 10 riddles, run the validator to collect all plausible answers, then query an LLM (e.g., GPT-4) for all possible answers. Compare coverage and note whether LLMs produce valid answers not in the lookup dictionary.