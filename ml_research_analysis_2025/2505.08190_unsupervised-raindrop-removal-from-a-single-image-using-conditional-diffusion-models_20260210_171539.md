---
ver: rpa2
title: Unsupervised Raindrop Removal from a Single Image using Conditional Diffusion
  Models
arxiv_id: '2505.08190'
source_url: https://arxiv.org/abs/2505.08190
tags:
- raindrop
- image
- raindrops
- diffusion
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents DropWiper, a novel method for removing raindrops
  from single images using conditional diffusion models. The approach consists of
  two main steps: pseudo raindrop mask generation and background reconstruction.'
---

# Unsupervised Raindrop Removal from a Single Image using Conditional Diffusion Models

## Quick Facts
- arXiv ID: 2505.08190
- Source URL: https://arxiv.org/abs/2505.08190
- Authors: Lhuqita Fazry; Valentino Vito
- Reference count: 31
- Method: Uses conditional diffusion models for unsupervised raindrop removal with pseudo mask generation

## Executive Summary
This paper introduces DropWiper, a novel approach for removing raindrops from single images using conditional diffusion models. The method operates in two stages: generating pseudo raindrop masks through residual or synthetic methods, then reconstructing the background using a pre-trained Denoising Diffusion Probabilistic Model (DDPM) conditioned on these masks. The approach is tested on both Raindrop and Cityscapes datasets, with synthetic raindrops added to Cityscapes images for evaluation.

## Method Summary
DropWiper employs a two-step process for raindrop removal. First, it generates pseudo raindrop masks using either residual mask generation with various thresholding strategies or synthetic mask generation based on a refraction model. Second, it uses a pre-trained DDPM to reconstruct the background by conditioning on the generated masks. The residual mask generation approach shows superior performance compared to detection-based methods, particularly when addressing domain shift issues that arise when training detection models on Cityscapes but testing on Raindrop images.

## Key Results
- Residual mask generation produces more reliable masks than detection-based approaches
- Detection models suffer from domain shift when trained on Cityscapes and tested on Raindrop images
- DDPM effectively reconstructs backgrounds when provided with accurate raindrop masks

## Why This Works (Mechanism)
The approach works by decoupling the challenging raindrop removal task into two more manageable sub-problems: accurate mask generation and background reconstruction. By leveraging pre-trained diffusion models that excel at image generation and restoration, the method can effectively fill in raindrop regions when provided with reasonable mask estimates. The conditional aspect allows the model to focus reconstruction efforts only where raindrops are detected.

## Foundational Learning

**Denoising Diffusion Probabilistic Models (DDPM)**
- Why needed: Core backbone for background reconstruction with strong image generation capabilities
- Quick check: Understand the forward noising and reverse denoising processes, typically involving U-Net architectures

**Conditional Image Generation**
- Why needed: Enables the model to reconstruct specific regions (raindrop areas) rather than entire images
- Quick check: Study how condition information (masks) is incorporated into diffusion models through cross-attention or concatenation

**Mask Generation Strategies**
- Why needed: Critical first step that determines the quality of subsequent background reconstruction
- Quick check: Compare residual-based approaches versus detection-based approaches and understand their respective strengths and weaknesses

## Architecture Onboarding

**Component Map**
Input Image -> Mask Generation (Residual/Synthetic) -> Conditional DDPM -> Output Image

**Critical Path**
The most critical path is Mask Generation -> Conditional DDPM, as errors in mask generation directly propagate to reconstruction quality. The residual mask generation with appropriate thresholding represents the most reliable approach according to the study.

**Design Tradeoffs**
The unsupervised nature trades potential accuracy for broader applicability, avoiding the need for paired raindrop/clean image datasets. However, this introduces the mask generation challenge as an additional failure point. The choice between residual and synthetic mask generation involves a tradeoff between simplicity and physical modeling accuracy.

**Failure Signatures**
Poor mask generation manifests as artifacts or incomplete reconstruction in the output image. Domain shift in detection models causes false positives/negatives, particularly when training and testing datasets differ significantly in appearance.

**First Experiments**
1. Generate masks using different thresholding strategies on test images
2. Apply DDPM reconstruction with ground truth masks to establish upper performance bounds
3. Compare residual versus synthetic mask generation quality visually and quantitatively

## Open Questions the Paper Calls Out
None

## Limitations
- Relies heavily on accurate pseudo raindrop mask generation, which remains challenging
- Limited testing on real-world images with naturally occurring raindrops
- Performance dependent on quality of pre-trained diffusion model and its adaptation to raindrop removal task

## Confidence
**Method Effectiveness**: Medium - Shows promise but limited real-world validation
**Mask Generation Quality**: Medium - Residual approach superior but still imperfect
**Background Reconstruction**: Medium-High - DDPM proven effective but task-specific adaptation needs more study
**Generalizability**: Low-Medium - Domain shift issues suggest dataset-specific considerations are critical

## Next Checks
1. Validate DropWiper on diverse real-world images with naturally occurring raindrops to assess practical performance
2. Conduct comprehensive ablation studies on different thresholding strategies and refraction models for mask generation
3. Perform comparative analysis between DropWiper and state-of-the-art supervised methods using both synthetic and real-world datasets