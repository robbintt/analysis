---
ver: rpa2
title: Confounded Causal Imitation Learning with Instrumental Variables
arxiv_id: '2507.17309'
source_url: https://arxiv.org/abs/2507.17309
tags:
- learning
- policy
- valid
- imitation
- expert
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of confounded imitation learning,
  where latent confounders affect both states and actions, leading to biased policy
  estimation. The authors propose a Confounded Causal Imitation Learning (C2L) model
  that allows confounders to influence actions across multiple timesteps, extending
  beyond the single-timestep assumption of previous methods.
---

# Confounded Causal Imitation Learning with Instrumental Variables

## Quick Facts
- arXiv ID: 2507.17309
- Source URL: https://arxiv.org/abs/2507.17309
- Authors: Yan Zeng; Shenglan Nie; Feng Xie; Libo Huang; Peng Wu; Zhi Geng
- Reference count: 13
- One-line primary result: C2L achieves superior policy learning performance compared to baselines, with identification accuracy exceeding 80% and significant improvements in both MSE and policy value metrics, particularly in data-scarce regimes.

## Executive Summary
This paper addresses confounded imitation learning where latent confounders affect both states and actions, leading to biased policy estimation. The authors propose a Confounded Causal Imitation Learning (C2L) model that extends beyond single-timestep assumptions by allowing confounders to influence actions across multiple timesteps. They introduce an Auxiliary-Based testing Criterion (AB Criterion) to identify valid instrumental variables from observational data, establishing both necessary and sufficient conditions for IV validity under non-Gaussian assumptions.

## Method Summary
The method employs a two-stage framework: first identifying valid instrumental variables using conditional independence tests on an auxiliary residual variable, then learning the policy through either simulator-based or offline approaches. The AB Criterion defines an auxiliary residual R = a_t - l(s_t) where l(·) satisfies E[R|s_k] = 0, and tests independence between R and candidate IVs using HSIC. Once a valid IV is identified, policy learning proceeds via multi-step marginalization for simulator-based methods or minimax optimization for offline approaches, both eliminating confounding bias.

## Key Results
- C2L achieves superior policy learning performance compared to baselines (BC, DoubIL, ResiduIL)
- IV identification accuracy exceeds 80% across tested environments
- Significant improvements in both MSE and policy value metrics, particularly in data-scarce regimes
- Robustness across varying confounding durations (τ ∈ {3, 4, 5, 6, 7}) with >80% identification accuracy

## Why This Works (Mechanism)

### Mechanism 1
Valid instrumental variables can be identified from purely observational data using conditional independence tests on an auxiliary residual variable. The AB Criterion defines an auxiliary residual R = a_t - l(s_t) where l(·) satisfies E[R|s_k] = 0. If R is independent of candidate IV s_k, then s_k satisfies the criterion. Under non-Gaussian assumptions (at least one confounder or noise term non-Gaussian), this independence pattern provides necessary and sufficient conditions for IV validity.

### Mechanism 2
Once a valid IV is identified, policy learning can proceed via either simulator-based resampling or offline adversarial optimization, both eliminating confounding bias. The simulator approach recursively propagates the validated IV through multi-step transitions to generate confounder-free synthetic states. The offline approach reformulates as minimax objective: min_π max_f E[2(a_t - π(s_t))f(s_k) - f(s_k)²], with Optimistic Mirror Descent computing approximate Nash equilibria.

### Mechanism 3
The C2L model generalizes prior TCN models by allowing confounders to influence arbitrary-length action sequences, with validity maintained across varying confounding durations. The structural causal model allows τ past confounders to affect current action a_t via function h(·). The valid IV is s_{t-τ} rather than s_{t-1}, satisfying exogeneity. The AB Criterion automatically identifies the correct lag without requiring τ to be known a priori.

## Foundational Learning

- Concept: **Instrumental Variables (IV)**
  - Why needed here: The entire method relies on IV theory—understanding relevance, exclusion restriction, and exogeneity is essential for grasping why the AB Criterion works.
  - Quick check question: Given a valid IV Z for treatment X and outcome Y, why does regressing Y on predicted X̂ (from Z) eliminate confounding bias?

- Concept: **Structural Causal Models and Confounding**
  - Why needed here: The C2L model is expressed as structural equations; understanding how latent confounders create spurious associations between states and actions motivates the deconfounding approach.
  - Quick check question: In Fig. 3, why does u_{t-τ} create confounding between s_t and a_t even though it doesn't directly cause either?

- Concept: **HSIC (Hilbert-Shmidt Independence Criterion)**
  - Why needed here: Stage I uses HSIC tests to verify R ⊥ s_k; understanding kernel-based independence testing explains how the method detects valid IVs without parametric assumptions.
  - Quick check question: Why might HSIC be preferred over correlation-based tests for detecting independence in this setting?

## Architecture Onboarding

- Component map:
  ```
  Expert Trajectories D_E → [Stage I: AB Criterion Testing]
                              ↓
                         Valid IV s_k
                              ↓
              [Stage II: Policy Learning] → Policy π
                    ↙              ↘
        [Simulator-based]      [Offline Adversarial]
        (Algorithm 3)           (Algorithm 4)
              ↓                       ↓
    IV-guided resampling     Minimax optimization
    → Deconfounded dataset   → Nash equilibrium
  ```

- Critical path:
  1. Implement auxiliary residual estimation: R = a_t - l(s_t) with E[R|s_k] = 0 (use regression to fit l).
  2. Implement HSIC independence test between R and candidate s_k across window {s_{t-1}, ..., s_{t-w}}.
  3. Select first s_k where independence holds as valid IV.
  4. Choose policy learning path based on simulator availability.
  5. For simulator path: implement multi-step rollout generation (Eq. 4) followed by MSE minimization.
  6. For offline path: implement minimax objective (Eq. 5) with Optimistic Mirror Descent.

- Design tradeoffs:
  - **Window size w**: Larger w increases robustness to longer confounding durations but requires more computation and may introduce false positives if trajectory lengths are limited. Start with w=10.
  - **Significance level α**: Lower α (e.g., 0.01) reduces false IV identification but may fail to find any valid IV in small-sample regimes. Paper uses default but doesn't specify exact value—experiment with α ∈ {0.01, 0.05, 0.1}.
  - **Simulator vs. offline**: Simulator approach requires environment access but provides cleaner deconfounding; offline is more general but may converge slower and requires careful discriminator architecture.

- Failure signatures:
  1. **No valid IV found**: All candidates fail independence test → w is too small or noise is near-Gaussian → increase w or verify non-Gaussianity assumption.
  2. **High MSE with identified IV**: IV may be incorrectly identified (false positive) → check HSIC test calibration, increase sample size.
  3. **Policy performance degrades with more data**: Suggests residual confounding → confounding duration τ exceeds w, or time-varying confounding present.
  4. **Simulator path underperforms offline**: Simulator dynamics don't match true environment → validate simulator accuracy independently.

- First 3 experiments:
  1. **IV identification validation on synthetic data**: Generate trajectories with known τ (e.g., 3-5 timesteps) and Gaussian/non-Gaussian confounders. Measure IV identification accuracy vs. number of trajectories (replicate Fig. 4). Verify accuracy >80% with ≥30 trajectories.
  2. **Ablation on confounding duration**: Fix trajectories at 30, vary τ ∈ {2, 3, 4, 5, 6, 7}. Compare policy MSE and return J against baselines (BC, DoubIL, ResiduIL). Expect C2L to maintain performance while baselines degrade beyond τ=2.
  3. **Distributional robustness check**: Fix τ=3, 30 trajectories. Test confounder distributions: Gaussian, uniform, gamma, exponential, laplace. Verify identification accuracy remains >80% across non-Gaussian settings; expect some degradation under pure Gaussian (per Lemma 1).

## Open Questions the Paper Calls Out
- Can the C2L framework be extended to handle time-varying confounding patterns where the influence mechanism or duration of the confounder changes over time?
- How can valid instrumental variables be identified in linear C2L models where all noise terms and confounders follow strictly Gaussian distributions?
- Does the Auxiliary-Based testing Criterion (AB Criterion) scale effectively to high-dimensional state spaces, such as raw visual inputs in robotics or autonomous driving?

## Limitations
- Performance critically depends on non-Gaussianity assumption, which may not hold in real-world environments
- Simulator-based approach assumes accurate environment dynamics that may not transfer to complex, high-dimensional tasks
- Results are limited to low-dimensional control tasks and do not extensively test time-varying confounding mechanisms or extreme data scarcity

## Confidence

**High Confidence**: The theoretical framework (Theorems 2-3) and experimental results showing superior performance over baselines in MSE and policy return metrics.

**Medium Confidence**: The generalizability of results across different environments and confounding structures. While experiments cover three domains, the paper does not extensively test time-varying confounding mechanisms.

**Low Confidence**: The method's robustness to violations of core assumptions, particularly near-Gaussian noise distributions and inaccurate simulators.

## Next Checks

1. **Gaussian Noise Robustness**: Replicate the IV identification experiment with progressively more Gaussian confounders (mixing Gaussian and non-Gaussian noise at varying ratios). Measure identification accuracy and policy performance to establish the method's tolerance to assumption violations.

2. **Simulator Bias Sensitivity**: Implement the simulator-based approach with intentionally biased transition dynamics (additive noise, parameter mismatches). Compare policy learning performance against the offline adversarial method to quantify simulator dependency.

3. **Temporal Non-Stationarity**: Modify the synthetic data generation to include time-varying confounding mechanisms (τ changes over trajectory) and evaluate IV identification accuracy and policy performance degradation. This tests robustness to dynamic environments not addressed in the current framework.