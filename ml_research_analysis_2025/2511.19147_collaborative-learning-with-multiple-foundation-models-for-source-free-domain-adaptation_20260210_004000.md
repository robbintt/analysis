---
ver: rpa2
title: Collaborative Learning with Multiple Foundation Models for Source-Free Domain
  Adaptation
arxiv_id: '2511.19147'
source_url: https://arxiv.org/abs/2511.19147
tags:
- coma
- adaptation
- domain
- target
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces CoMA, a source-free domain adaptation framework
  that jointly leverages two complementary foundation models (CLIP and BLIP) to address
  the limited semantic diversity of single-foundation-model approaches. The method
  employs a bidirectional adaptation mechanism: Target-Guided Consistency Adjustment
  aligns the MFMs with task-relevant semantics while'
---

# Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation

## Quick Facts
- arXiv ID: 2511.19147
- Source URL: https://arxiv.org/abs/2511.19147
- Reference count: 40
- Key outcome: CoMA achieves state-of-the-art performance on Office-Home and DomainNet-126 SFDA benchmarks while maintaining only 66% additional training time versus single-foundation-model approaches

## Executive Summary
This paper introduces CoMA, a source-free domain adaptation framework that jointly leverages two complementary foundation models (CLIP and BLIP) to address the limited semantic diversity of single-foundation-model approaches. The method employs a bidirectional adaptation mechanism: Target-Guided Consistency Adjustment aligns the MFMs with task-relevant semantics while Decomposed Mutual Information (DMI) stabilizes knowledge transfer under mini-batch training by selectively enhancing true dependencies while suppressing false ones caused by incomplete class coverage.

## Method Summary
CoMA operates in three phases: (1) Burn-in phase trains a BLIP-proxy model from source weights using BLIP-generated pseudo-labels derived from caption-to-class-name similarity; (2) Target-Guided Consistency Adjustment (TCA) stage aligns MFMs with the target model via mutual consistency maximization and conditional decorrelation; (3) Mutual Distillation Adaptation (MDA) transfers complementary knowledge from MFMs to the target model via agreement-guided supervision and selective information maximization. The framework uses Decomposed Mutual Information (DMI) to address mini-batch training instability by selectively enhancing true dependencies while suppressing false dependencies arising from incomplete class coverage.

## Key Results
- CoMA achieves 74.8% accuracy on Office-Home Cl→Ar task, outperforming single-FM baselines by 2-4 percentage points
- DMI enables stable adaptation across varying batch sizes (8-64), preventing performance degradation seen in standard MI methods
- The bidirectional adaptation mechanism preserves semantic diversity between MFMs while ensuring task alignment, as validated by Grad-CAM attention consistency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposed Mutual Information (DMI) stabilizes knowledge transfer under mini-batch training by selectively enhancing true dependencies while suppressing false ones caused by incomplete class coverage
- Mechanism: DMI decomposes the joint probability space into a Confident Joint Subset (CJS)—classes observed with high confidence in the current batch—and its complement. It maximizes MI within CJS while minimizing MI in the uncertain region, preventing reinforcement of spurious correlations for unobserved classes
- Core assumption: Classes with confident predictions in both distributions correspond to statistically reliable joint signals; absent classes create false dependencies that degrade adaptation
- Evidence anchors:
  - [abstract] "To ensure stable adaptation under mini-batch training, we introduce Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage."
  - [section 3.1] Definition 1 and Eq. (3): $I_D(X;Y) = I(X_S;Y_S) - \frac{\log|S|}{\log|S^∁|} \cdot I(X_S^∁;Y_S^∁)$
  - [corpus] Weak direct evidence; neighboring papers address SFDA challenges but not DMI specifically
- Break condition: If batch size is too small relative to class space (e.g., K=126 in DomainNet-126 with batch=8), CJS may be insufficiently dense, causing unstable gradient estimates

### Mechanism 2
- Claim: Bidirectional adaptation between MFMs and the target model achieves task alignment while preserving semantic diversity across foundation models
- Mechanism: TCA stage uses mutual consistency (maximizing DMI between target and each MFM) plus conditional decorrelation (minimizing conditional DMI between MFMs given target) to prevent semantic collapse. MDA stage then transfers refined knowledge via agreement-guided supervision and selective information maximization
- Core assumption: Two MFMs with complementary semantic granularities (CLIP: global/category-level; BLIP: local/contextual) provide non-redundant signals that a single MFM cannot
- Evidence anchors:
  - [abstract] "bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge from the FMs to the target model."
  - [section 3.2] Eq. (8): $\mathcal{L}_{TCA} = \mathcal{L}_{MC} + \alpha \mathcal{L}_{CD}$
  - [corpus] Weak; no neighboring papers explicitly study multi-FM collaboration for SFDA
- Break condition: If MFMs converge to similar predictions despite conditional decorrelation (α too small), complementary benefits are lost; if α too large, task alignment degrades

### Mechanism 3
- Claim: BLIP-proxy model bridges BLIP's caption-oriented output space to classifier-compatible probability space, enabling efficient multi-MFM collaboration
- Mechanism: A proxy model with the source model architecture is trained on BLIP-generated pseudo-labels during a burn-in phase. This avoids expensive BLIP forward passes during adaptation while preserving semantic signals
- Core assumption: BLIP-generated pseudo-labels derived from caption-to-class-name similarity provide reliable local semantic supervision
- Evidence anchors:
  - [section 3, Overview] "It serves as an efficient surrogate for the BLIP Θ_B. This design allows our framework to leverage BLIP's semantic signals in a computationally efficient manner."
  - [supplementary 10] Burn-in training uses caption-class cosine similarity with handcrafted prompts
  - [corpus] Weak; no direct architectural analogs found
- Break condition: If BLIP captions systematically fail for certain domains (e.g., abstract art in Office-Home), pseudo-labels will be noisy, propagating errors through the proxy model

## Foundational Learning

- Concept: **Mutual Information and its properties**
  - Why needed here: DMI builds on MI's theoretical foundation (non-negativity, entropy bounds) to decompose joint distributions. Without understanding $I(X;Y) = H(Y) - H(Y|X)$, the rationale for separating confident/uncertain regions is opaque
  - Quick check question: Given two random variables X and Y, what does maximizing $I(X;Y)$ achieve versus minimizing it?

- Concept: **Source-Free Domain Adaptation constraints**
  - Why needed here: CoMA operates without source data access, necessitating external semantic guidance (MFMs) and self-supervised objectives. Understanding why entropy minimization alone fails explains the multi-FM design
  - Quick check question: Why can't we use standard supervised fine-tuning on target data in SFDA?

- Concept: **Vision-Language Foundation Models' semantic granularity**
  - Why needed here: CLIP's contrastive image-text alignment prioritizes global semantics; BLIP's cross-attention captures region-text correspondences. Complementarity is central to CoMA's design
  - Quick check question: What architectural difference causes CLIP to capture category-level semantics while BLIP captures local contextual cues?

## Architecture Onboarding

- Component map:
  - Source model $\theta_s$ -> Target model $\theta_t$ (adaptation path)
  - Target model $\theta_t$ <-> CLIP $\Theta_c$ (mutual consistency via TCA)
  - Target model $\theta_t$ <-> BLIP-proxy $\theta_b$ (efficient collaboration via proxy)
  - CLIP $\Theta_c$ <-> BLIP $\theta_b$ (semantic independence via conditional decorrelation)

- Critical path:
  1. **Burn-in**: Generate BLIP pseudo-labels for target data → train $\theta_b$ via cross-entropy with label smoothing
  2. **TCA (per batch)**: Forward pass through $\theta_t$, $\Theta_c$, $\theta_b$ → compute $\mathcal{L}_{MC}$ and $\mathcal{L}_{CD}$ → update $v$ and $\theta_b$
  3. **MDA (per batch)**: Re-compute MFM predictions → identify agreement samples → compute $\mathcal{L}_{AGS}$ and $\mathcal{L}_{SIM}$ → update $\theta_t$

- Design tradeoffs:
  - **Computational cost**: 66% more training time than single-FM baselines (Table 10), but no inference overhead since only $\theta_t$ is deployed
  - **Hyperparameters**: $(\alpha, \beta)$ control consistency-decorrelation and supervision-SIM balance; λ controls DMI suppression strength (empirically λ=0.5 optimal)
  - **Batch size sensitivity**: DMI mitigates small-batch degradation but performance still varies (Fig. 5); dataset-specific batch configs recommended

- Failure signatures:
  - Semantic collapse: If MFMs produce near-identical predictions, check if $\alpha$ is too low or if burn-in pseudo-labels have high error
  - DMI instability: If loss becomes unbounded, verify |S|≥2 and |S^∁|≥2 per batch (Supplementary 6 Remark)
  - Domain mismatch: If Grad-CAM shows misaligned attention, BLIP captions may fail for that domain; consider alternative caption prompts

- First 3 experiments:
  1. **Ablation by component**: Remove each loss term ($\mathcal{L}_{CD}$, $\mathcal{L}_{MC}$, $\mathcal{L}_{AGS}$, $\mathcal{L}_{SIM}$) on Office-Home Cl→Ar to replicate Table 5 and verify cumulative gains
  2. **Batch size sensitivity**: Run ProDe-V baseline and CoMA with/without DMI across batch sizes [8, 16, 32, 64] to validate Fig. 5 stability claims
  3. **Single-FM vs. dual-FM**: Replace BLIP-proxy with CLIP-proxy (trained on CLIP pseudo-labels) to measure how much gain comes from semantic complementarity versus architectural differences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed Decomposed Mutual Information (DMI) formulation be generalized to stabilize mutual information estimation in other unsupervised learning tasks that suffer from mini-batch sparsity?
- Basis in paper: [inferred] The authors introduce DMI as a general information-theoretic formulation to address the instability of conventional Mutual Information under mini-batch training, suggesting potential utility beyond the specific SFDA context
- Why unresolved: The paper evaluates DMI exclusively within the CoMA framework on domain adaptation benchmarks and does not test it on other MI-heavy tasks like unsupervised clustering
- What evidence would resolve it: Applying DMI to standard mutual information maximization benchmarks (e.g., unsupervised representation learning) and comparing stability and convergence against standard MI estimators

### Open Question 2
- Question: How does the framework's performance and computational complexity scale when integrating more than two foundation models?
- Basis in paper: [inferred] The title and framework ("Collaborative Multi-foundation") suggest a general approach to multiple models, but the implementation and experiments strictly utilize exactly two models (CLIP and BLIP)
- Why unresolved: The bidirectional adaptation mechanism and loss functions (TCA, MDA) are defined for dual interactions; the impact of adding a third or fourth MFM on the consensus and decorrelation mechanisms is unexplored
- What evidence would resolve it: Experiments extending CoMA to include three or more diverse MFMs (e.g., adding LLaVA or others) and analyzing the trade-off between accuracy gains and training overhead

### Open Question 3
- Question: Is the semantic complementarity of the foundation models a strict requirement, or does the framework improve performance even when combining models with highly overlapping semantic biases?
- Basis in paper: [inferred] The methodology relies on the assumption that different FMs (CLIP and BLIP) capture complementary global and local semantics, but it does not rigorously test cases where the two MFMs are functionally similar
- Why unresolved: The "Reliance analysis" tests different CLIP/BLIP variants, but does not test a "negative control" where both MFMs are nearly identical (e.g., two global-only models) to quantify the dependency on complementarity
- What evidence would resolve it: An ablation study using two foundation models with similar architectures and training data (low complementarity) to determine if the performance gain persists or vanishes

## Limitations
- DMI implementation details remain underspecified, particularly practical joint probability estimation within mini-batches
- Performance critically depends on burn-in pseudo-label quality, but burn-in training hyperparameters are not fully detailed
- All experiments use image classification datasets; effectiveness on other domain adaptation scenarios remains untested

## Confidence
- **High confidence**: The core architectural design (multi-MFM collaboration) and DMI's theoretical formulation are well-specified and internally consistent
- **Medium confidence**: Empirical results showing performance improvements over baselines are convincing, though ablation studies could be more comprehensive
- **Low confidence**: Claims about DMI's stability advantages under mini-batch training lack quantitative comparison to standard MI baselines across varying batch sizes

## Next Checks
1. **DMI vs. standard MI comparison**: Replicate Fig. 5 by measuring performance degradation of CoMA (with DMI) versus standard MI-based methods as batch size varies from 8 to 64
2. **BLIP-proxy sensitivity analysis**: Evaluate how proxy model accuracy at burn-in initialization correlates with final adaptation performance by varying caption quality or training epochs
3. **Single-MFM vs. dual-MFM complementarity**: Replace BLIP-proxy with a second CLIP instance (trained on CLIP pseudo-labels) to isolate whether performance gains stem from semantic complementarity versus architectural diversity