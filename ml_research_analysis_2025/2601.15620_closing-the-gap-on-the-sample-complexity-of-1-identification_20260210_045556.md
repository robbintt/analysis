---
ver: rpa2
title: Closing the Gap on the Sample Complexity of 1-Identification
arxiv_id: '2601.15620'
source_url: https://arxiv.org/abs/2601.15620
tags:
- log2
- algorithm
- lemma
- have
- line
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the 1-identification problem, where an agent
  must determine if there exists an arm with mean reward above a threshold. The authors
  develop new lower and upper bounds on the sample complexity for this problem.
---

# Closing the Gap on the Sample Complexity of 1-Identification

## Quick Facts
- arXiv ID: 2601.15620
- Source URL: https://arxiv.org/abs/2601.15620
- Authors: Zitian Li; Wang Chi Cheung
- Reference count: 40
- This paper establishes new lower and upper bounds on the sample complexity for 1-identification in multi-armed bandits, showing the PSEEB algorithm is nearly optimal with gaps only polynomial in log K and inverse squared gaps between arms.

## Executive Summary
This paper studies the 1-identification problem in multi-armed bandits, where an agent must determine if any arm has mean reward above a threshold. The authors develop a new lower bound using an optimization formulation and introduce the PSEEB algorithm that achieves tight upper bounds. Their main result shows the algorithm is nearly optimal, with the gap between bounds being only polynomial in log K and inverse squared gaps between arms. This work complements previous research that had analytical gaps for cases with multiple qualified arms.

## Method Summary
The paper introduces PSEEB (Parallel Sequential Exploration Exploitation on Brackets), which uses a bracketing approach to divide arms into nested subsets via a random permutation. Multiple algorithm copies run in parallel with round-robin scheduling, each using tolerance δ/(log₂K+1). Each copy implements a SEE algorithm that alternates between exploration phases (using UCB rules and phase-based budgets) and exploitation periods (single-arm verification with LCB bounds). The bracket structure enables early termination when multiple qualified arms exist, while parallel execution with sample independence maintains δ-PAC guarantees.

## Key Results
- A new lower bound formula showing sample complexity depends on min over qualified arms of (log(1/δ)/Δ²ⱼ,₀ + H(j)/log²(m+1))
- The PSEEB algorithm achieves tight upper bounds on sample complexity
- The gap between upper and lower bounds is polynomial in log K and inverse squared gaps between arms
- The algorithm is nearly optimal, closing gaps left by previous work on multi-qualified-arm cases

## Why This Works (Mechanism)

### Mechanism 1: Optimization-Based Lower Bound via Change of Measure
- The sample complexity lower bound is derived through a convex optimization formulation where decision variables represent probabilities of outputting each qualified arm. Constraints capture the tension between certifying arms exceed the threshold and distinguishing them from others. Strong duality yields an analytical lower bound. The approach relies on Gaussian reward assumptions and symmetric algorithm properties.

### Mechanism 2: Random Permutation Bracketing for Early Discovery
- A single random permutation partitions arms into nested brackets B₁ ⊂ B₂ ⊂ ... ⊂ B_{⌈log₂K⌉+1}. When multiple qualified arms exist, the probability that bracket b contains no qualified arm decays exponentially, enabling early termination in small brackets. This nested structure differs from previous independent shuffling approaches and provides substantial sample complexity reduction when m ≥ 2.

### Mechanism 3: Round-Robin Parallel Execution with Sample Independence
- Multiple algorithm copies run in parallel with round-robin scheduling and no sample sharing. Each copy receives tolerance δ/(⌈log₂K⌉+1), and a union bound preserves overall error probability ≤ δ. Round-robin ensures τ ≤ (⌈log₂K⌉+1)·τ(B_b) for any bracket. Sample independence prevents correlation that would invalidate concentration analysis, though it requires more total pulls than shared-sampling approaches.

## Foundational Learning

- **Pure exploration in multi-armed bandits (fixed-confidence setting)**: The entire framework focuses on identifying a qualified arm with probability ≥ 1-δ rather than maximizing cumulative reward. Quick check: Why does δ-PAC require Pr(τ < ∞, â ∈ i*(ν)) > 1-δ rather than just Pr(â ∈ i*(ν)) > 1-δ?

- **Sub-Gaussian concentration inequalities (Law of the Iterated Logarithic)**: Algorithm 2 uses U(t, δ) = √(2·2^{⌈log₂t⌉} + log(2(⌈log₂t⌉₊)²/δ))/t for confidence bounds. Quick check: Why does the LIL bound use ⌈log₂t⌉ rather than t directly? (Hint: think about the union bound over time.)

- **Change-of-measure arguments (KL divergence)**: The lower bound proof uses Transportation Lemma to relate probabilities under different instances by swapping arm indices. Quick check: In Lemma 7, why does swapping arms i and j in instance ν' create ν'' such that Pr_{ν''}(τ_n < τ, A_{τ_n+1} = i) = Pr_ν(τ_n < τ, A_{τ_n+1} = j)?

## Architecture Onboarding

- **Component map**:
  PSEEB (Algorithm 1) -> Random permutation σ -> Brackets B_1, ..., B_{⌈log₂K⌉+1} -> For each bracket b: SEE (Algorithm 2) -> Exploration period -> Exploitation period -> Container Q

- **Critical path**:
  1. Initialize: Generate σ, create brackets, spawn SEE copies with δ/(⌈log₂K⌉+1) each
  2. Round-robin loop: Execute one step in each SEE copy sequentially
  3. Per-copy logic: In phase k, check if LCBee ≥ μ₀ → enter exploitation; else if all UCB ≤ μ₀ and |B|=K → output None; else pull arm with max UCB among those under budget
  4. Termination: First copy to output â (or None) triggers global termination

- **Design tradeoffs**:
  - Bracket count vs. parallelism overhead: More brackets increase early discovery chance but multiply worst-case stopping time
  - Sample sharing vs. independence: Sharing samples would reduce pulls but break concentration analysis
  - Exploration/exploitation split: Q container mechanism ensures LCBee < μ₀ at phase start, enabling clean analysis but requiring extra bookkeeping

- **Failure signatures**:
  - Infinite loop in SEE: If δ_k never falls below δ/3 or UCB bounds never cross μ₀, algorithm hangs (probability shown to be 0)
  - Wrong output on positive instance: Occurs if LCB falsely certifies an arm above μ₀ (bounded by π²δ/30)
  - Bracket never terminates (|B| < K): Small brackets cannot output None even if all arms fall below μ₀

- **First 3 experiments**:
  1. Sanity check: K=4 arms, μ₀=0.5, μ=[0.8, 0.6, 0.3, 0.2], δ=0.1. Verify termination and compare Eτ to lower bound
  2. Varying qualified arms: Fix K=16, μ₀=0.5, vary m ∈ {1, 2, 4, 8}. Plot Eτ vs. m to validate improvement when m > 1
  3. Negative instances: K=64, μ₀=0.5, all μ_a < 0.5. Verify None output and compare to H^{neg}_1 · log(1/δ) baseline

## Open Questions the Paper Calls Out
None

## Limitations
- The polynomial gap between upper and lower bounds, while narrowed, still leaves room for improvement
- The analysis relies heavily on Gaussian assumptions that may not generalize to other reward distributions
- The bracket-based approach's performance on highly skewed instances with extreme gap differences is not thoroughly explored

## Confidence
- **High Confidence**: Mathematical derivation of lower bound, correctness of bracketing mechanism, parallel execution maintaining δ-PAC guarantees
- **Medium Confidence**: Polynomial gap bounds, overall near-optimality claim, LIL-based confidence bounds
- **Low Confidence**: Algorithm behavior on non-Gaussian rewards, robustness when qualified arms are clustered, practical performance on real-world problems

## Next Checks
1. **Distributional Robustness**: Implement PSEEB with sub-Gaussian rewards (not just Gaussian) and verify whether the same sample complexity bounds hold. Test with Bernoulli and bounded rewards to assess generality.

2. **Bracket Size Sensitivity**: Systematically vary bracket sizes and structure (not just power-of-two partitioning) to determine if the log K factor in the upper bound is tight. Explore whether adaptive bracket sizing based on observed gaps could improve performance.

3. **Multi-armed vs. Single-armed Tradeoff**: Compare PSEEB's performance against a simple sequential elimination algorithm on instances with m = 1 qualified arm. This would validate whether the bracketing overhead is justified when the benefit (early discovery) doesn't materialize.