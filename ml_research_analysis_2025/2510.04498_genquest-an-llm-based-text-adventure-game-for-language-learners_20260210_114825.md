---
ver: rpa2
title: 'GenQuest: An LLM-based Text Adventure Game for Language Learners'
arxiv_id: '2510.04498'
source_url: https://arxiv.org/abs/2510.04498
tags:
- game
- vocabulary
- language
- learning
- participants
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study presents GenQuest, an LLM-powered text adventure game
  designed to enhance vocabulary learning through interactive storytelling. The system
  dynamically generates branching narratives tailored to individual proficiency levels
  and offers in-context vocabulary explanations.
---

# GenQuest: An LLM-based Text Adventure Game for Language Learners

## Quick Facts
- **arXiv ID**: 2510.04498
- **Source URL**: https://arxiv.org/abs/2510.04498
- **Reference count**: 21
- **Primary result**: Vocabulary test mean score of 13.44/20; perceived usefulness mean 5.33/7; perceived ease of use mean 5.85/7

## Executive Summary
This paper presents GenQuest, an LLM-powered text adventure game designed to support vocabulary acquisition for English as a Foreign Language (EFL) learners through interactive storytelling. The system generates branching narratives dynamically tailored to individual CEFR proficiency levels, with integrated vocabulary explanations triggered by text highlighting. In a five-day pilot study with nine Chinese EFL students, participants showed measurable vocabulary gains and reported positive perceptions of the system's usefulness and ease of use. The work demonstrates the potential of LLM-based personalized narratives for language learning, while highlighting areas for refinement in vocabulary support and narrative coherence.

## Method Summary
The system employs a two-module architecture built on GPT-4o and Claude 3.7 Sonnet APIs. The Story Module generates personalized narratives through an initialization pipeline (genre selection, CEFR sample generation, outline creation with milestones and decision points) and a plot generation pipeline (segment generation, decision presentation, summarization, memory updates). The Language Module provides contextual vocabulary explanations at the learner's CEFR level and maintains a query history. The system uses a RESTful API backend with Vue.js frontend, and was evaluated through a five-day pilot study with vocabulary tests and TAM surveys administered to nine Chinese EFL students.

## Key Results
- Participants achieved an average vocabulary test score of 13.44 out of 20, indicating substantial learning of queried words
- Survey results showed positive perceptions: Perceived Usefulness mean 5.33 and Perceived Ease of Use mean 5.85 on 7-point scales
- Qualitative feedback highlighted the motivational value of interactive narratives and suggested improvements for vocabulary support and narrative coherence

## Why This Works (Mechanism)
GenQuest works by leveraging LLMs to generate adaptive, personalized narratives that maintain learner engagement while providing contextualized vocabulary learning opportunities. The system's effectiveness stems from its ability to dynamically adjust story complexity to individual proficiency levels and offer just-in-time vocabulary explanations within meaningful contexts, rather than through isolated word lists.

## Foundational Learning
- **CEFR proficiency levels**: Framework for describing language ability from A1 (beginner) to C2 (mastery); needed to calibrate text complexity appropriately
- **LLM context windows**: Maximum token limit for input/output sequences; affects how much story content can be maintained in memory
- **Text adventure game mechanics**: Branching narrative structures with player choices; provides framework for interactive language practice
- **Vocabulary acquisition theory**: Learning words in context is more effective than isolated memorization; explains why in-story explanations work
- **Technology Acceptance Model (TAM)**: Framework for measuring perceived usefulness and ease of use; used for evaluating learner reception
- **RESTful API architecture**: Client-server communication pattern; enables frontend-backend separation for the game interface

## Architecture Onboarding

**Component Map**: User -> Frontend (Vue.js) -> Backend (Python RESTful API) -> LLM APIs (GPT-4o, Claude 3.7 Sonnet) -> Database (query history)

**Critical Path**: User selects genre and CEFR level → Story Module initializes outline with milestones → Plot generation loop produces narrative segments → User makes choices → Language Module provides vocabulary explanations → Results stored in query history

**Design Tradeoffs**: The system prioritizes personalization and interactivity over narrative coherence and consistency, relying on LLM-generated content that may vary in quality. This tradeoff enables adaptive difficulty but introduces potential for incoherent storylines across branches.

**Failure Signatures**: Narrative incoherence across different story paths; vocabulary explanations that don't match learner proficiency level; high latency due to sequential LLM calls; vocabulary content that doesn't align with target CEFR level.

**First 3 Experiments**: 1) Generate and evaluate multiple story paths from same starting point to assess narrative coherence 2) Test vocabulary explanation accuracy at different CEFR levels using sample texts 3) Measure system latency across different story lengths and complexity levels

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- Small sample size (n=9) and short study duration (5 days) limit generalizability
- Lack of control group prevents causal attribution of learning gains to the LLM system
- Critical implementation details including LLM prompts and vocabulary validation methods are not disclosed
- Cultural and linguistic specificity to Chinese EFL learners constrains applicability to other populations

## Confidence

**High confidence** in technical feasibility and usability based on participant feedback and system architecture description.

**Medium confidence** in reported vocabulary learning gains given positive but limited quantitative results and absence of comparative benchmarks.

**Low confidence** in scalability and generalizability due to small sample size, short duration, and lack of replication details.

## Next Checks
1. Replicate the core system architecture using publicly available LLM APIs, focusing on the two-module pipeline and validating narrative coherence across multiple playthroughs
2. Conduct a controlled experiment with larger, diverse learner samples and a baseline text adventure condition to isolate the impact of LLM-driven personalization
3. Develop and test automated vocabulary alignment checks against CEFR word lists to ensure generated text matches target proficiency levels