---
ver: rpa2
title: 'Comparative Analysis of Deep Learning Strategies for Hypertensive Retinopathy
  Detection from Fundus Images: From Scratch and Pre-trained Models'
arxiv_id: '2506.12492'
source_url: https://arxiv.org/abs/2506.12492
tags:
- data
- learning
- augmentation
- dataset
- pure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates deep learning strategies for detecting
  hypertensive retinopathy from fundus images, focusing on the interplay between model
  architecture, data augmentation, and dataset size. The research compares a custom
  CNN, pre-trained transformer-based models (including pure ViTs, hybrid ViT-CNNs,
  and DINOv2), and an AutoML solution.
---

# Comparative Analysis of Deep Learning Strategies for Hypertensive Retinopathy Detection from Fundus Images: From Scratch and Pre-trained Models

## Quick Facts
- **arXiv ID:** 2506.12492
- **Source URL:** https://arxiv.org/abs/2506.12492
- **Reference count:** 3
- **Key outcome:** Study compares custom CNN, pre-trained transformers (ViTs, hybrid ViT-CNNs, DINOv2), and AutoML for hypertensive retinopathy detection, finding that data augmentation significantly improves pure ViTs but degrades hybrid models, with smaller patch sizes excelling with augmentation.

## Executive Summary
This study investigates deep learning strategies for detecting hypertensive retinopathy from fundus images, focusing on the interplay between model architecture, data augmentation, and dataset size. The research compares a custom CNN, pre-trained transformer-based models (including pure ViTs, hybrid ViT-CNNs, and DINOv2), and an AutoML solution. Key findings reveal that data augmentation significantly improves performance for pure ViTs, which lack strong inductive biases and benefit from regularized learning, but degrades performance for hybrid models, whose pre-trained CNN components may be disrupted by transformations. Smaller patch sizes (ViT-B/8) excel with augmentation, enhancing fine-grained detail capture. DINOv2 fails on the original limited dataset but is rescued by augmentation, highlighting the critical need for data diversity to unlock its potential. Conversely, a ViT-Large model performs poorly, underscoring the risk of using overly-capacitive models on specialized, smaller datasets. These results emphasize the need for tailored model selection and augmentation strategies in medical image classification tasks.

## Method Summary
The study employs a comparative experimental design using a custom CNN, pre-trained transformer models (pure ViTs, hybrid ViT-CNNs, DINOv2), and an AutoML solution on fundus images for hypertensive retinopathy detection. Models are evaluated with and without data augmentation across different dataset sizes. Key architectural choices include varying patch sizes for ViTs, with smaller patches (ViT-B/8) expected to capture finer details. The study focuses on how augmentation affects models with different inductive biases and capacities, particularly examining the impact on pure ViTs versus hybrid models with pre-trained CNN backbones.

## Key Results
- Data augmentation significantly improves pure ViT performance by regularizing learning for models lacking strong inductive biases
- Augmentation degrades hybrid ViT-CNN model performance, likely disrupting pre-trained CNN components
- Smaller patch sizes (ViT-B/8) excel with augmentation by enhancing fine-grained detail capture
- DINOv2 fails on limited datasets but recovers with augmentation, demonstrating the need for data diversity
- ViT-Large performs poorly on specialized, smaller datasets, highlighting risks of excessive model capacity

## Why This Works (Mechanism)
The effectiveness of data augmentation varies significantly based on model architecture and inductive biases. Pure ViTs, which lack strong spatial priors, benefit from augmentation as it provides regularization and helps prevent overfitting on limited medical image datasets. The augmentation introduces variability that these models need to learn robust features. In contrast, hybrid ViT-CNN models contain pre-trained CNN components with established spatial hierarchies. Augmentation may disrupt these learned representations, explaining the performance degradation. Smaller patch sizes in ViTs allow for finer spatial resolution, which becomes particularly valuable when combined with augmentation for capturing subtle pathological features in retinal images.

## Foundational Learning
1. **Inductive biases in neural networks** - Why needed: Understanding how different architectures make assumptions about data structure determines augmentation effectiveness. Quick check: Compare pure ViT (minimal bias) vs CNN (strong spatial bias) responses to augmentation.
2. **Transfer learning capacity vs dataset size** - Why needed: Determines appropriate model selection for specialized medical imaging tasks with limited data. Quick check: Test model performance across varying dataset scales to identify optimal capacity.
3. **Patch size in Vision Transformers** - Why needed: Controls spatial resolution and detail capture capability in ViTs. Quick check: Compare performance of different patch sizes (4, 8, 16) with and without augmentation.
4. **Regularization through data augmentation** - Why needed: Critical for preventing overfitting in small medical image datasets. Quick check: Measure overfitting indicators (train vs validation gap) with different augmentation intensities.
5. **Pre-trained component disruption** - Why needed: Explains why augmentation may harm hybrid models with frozen CNN backbones. Quick check: Test frozen vs fine-tuned CNN components under augmentation.
6. **Model capacity specialization** - Why needed: Guides selection of appropriate model size for specific medical imaging tasks. Quick check: Benchmark models of varying sizes on datasets of different scales.

## Architecture Onboarding

**Component Map:**
Input Images -> Preprocessing -> Model (CNN/ViT/Hybrid/DINOv2) -> Classification Head -> Output

**Critical Path:**
Data Augmentation (if enabled) -> Model Backbone (CNN/ViT) -> Classification Head -> Loss Calculation

**Design Tradeoffs:**
- Pure ViTs offer flexibility but require more data/augmentation due to minimal inductive biases
- Hybrid models leverage pre-trained CNN features but may be sensitive to augmentation disrupting learned representations
- Smaller patch sizes provide finer detail capture but increase computational cost
- Larger models offer more capacity but risk overfitting on specialized, limited datasets

**Failure Signatures:**
- Poor generalization on small datasets indicates insufficient regularization or excessive model capacity
- Degradation with augmentation suggests pre-trained components are being disrupted
- High training accuracy but low validation accuracy indicates overfitting, especially in pure ViTs without augmentation
- Failed convergence with large patch sizes may indicate loss of critical spatial information

**3 First Experiments:**
1. Compare pure ViT vs hybrid ViT-CNN performance with identical augmentation strategies to isolate architecture effects
2. Test different patch sizes (4, 8, 16) with augmentation to identify optimal spatial resolution for retinal features
3. Evaluate model performance across multiple dataset size thresholds to establish capacity requirements

## Open Questions the Paper Calls Out
None

## Limitations
- Single dataset without external validation limits generalizability of findings
- Small sample size raises concerns about overfitting and statistical significance
- Lack of systematic exploration of different augmentation policies and magnitudes
- No comparative analysis with other medical image datasets to verify cross-domain applicability

## Confidence

**Confidence Labels:**
- Data augmentation effects on pure ViTs vs hybrid models: High
- Model capacity recommendations for specialized datasets: Medium
- DINOv2's failure and recovery through augmentation: Medium

**Next Checks:**
1. External validation on a larger, independent fundus image dataset to verify generalizability of augmentation effects across different data distributions
2. Systematic ablation study varying dataset sizes to confirm the relationship between model capacity and dataset scale observed with ViT-Large
3. Comparative analysis of different augmentation strategies (magnitude, diversity, and policy) to identify optimal augmentation pipelines for each model type