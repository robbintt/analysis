---
ver: rpa2
title: 'HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor'
arxiv_id: '2508.11429'
source_url: https://arxiv.org/abs/2508.11429
tags:
- humor
- generation
- revision
- hucot
- jokes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'HumorPlanSearch tackles the problem of AI-generated humor feeling
  generic and culturally tone-deaf by explicitly modeling context throughout the generation
  pipeline. It introduces a multi-stage approach: diverse strategic planning (Plan-Search),
  culturally-aware Humor Chain-of-Thought (HuCoT) templates, retrieval and adaptation
  of high-performing historical strategies via a Knowledge Graph, novelty filtering
  through semantic embeddings, and an iterative judge-guided revision loop.'
---

# HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor

## Quick Facts
- arXiv ID: 2508.11429
- Source URL: https://arxiv.org/abs/2508.11429
- Authors: Shivam Dubey
- Reference count: 5
- Primary result: Full pipeline (Knowledge Graph + Revision) achieves 15.4% higher mean HGS over baseline (p < 0.05)

## Executive Summary
HumorPlanSearch addresses the challenge of AI-generated humor feeling generic and culturally tone-deaf by introducing a multi-stage generation pipeline. The system combines strategic planning (Plan-Search), culturally-aware Chain-of-Thought templates (HuCoT), historical strategy retrieval via a Knowledge Graph, novelty filtering, and iterative judge-guided revision. Tested across nine topics with 13 human judges, the complete pipeline demonstrates significant improvement in humor quality, novelty, and cultural relevance compared to baseline approaches.

## Method Summary
The method employs a structured pipeline where topics are first processed through Plan-Search to generate diverse strategies (N=12) plus hybrid combinations (k×3). A Knowledge Graph retrieves and adapts high-performing historical strategies. Each strategy executes through HuCoT templates (Generic: 8 steps, Indian: 6 steps, Gen Z-Indian: 7 steps) to generate jokes. A novelty filter removes semantically similar jokes (>0.75 threshold), and jokes scoring below 6.0 in HGS undergo up to two revision iterations with judge LLM suggestions.

## Key Results
- Full pipeline (KG + Revision) achieves 15.4% increase in mean HGS over baseline (p < 0.05)
- Novelty filter removes ~18% of generated jokes, improving output diversity
- Strategy retrieval from Knowledge Graph provides measurable performance gains
- Iterative revision loop improves low-scoring strategies when projected improvement > 0.2

## Why This Works (Mechanism)

### Mechanism 1: Strategic Planning + Historical Retrieval
Explicit strategic planning combined with historical strategy retrieval improves humor quality over direct prompting. Plan-Search generates N=12 first-order strategies, creates hybrid combinations (max k×3), and retrieves/adapts high-performing historical strategies from a persistent Knowledge Graph, expanding the strategy pool beyond what single-pass generation produces. This works because high-performing strategies from past topics can be meaningfully adapted to new topics via LLM-based transfer, though it breaks when strategy space is exhausted or KG contains no relevant historical strategies for novel topics.

### Mechanism 2: Culturally-Grounded HuCoT Templates
Culturally-grounded Chain-of-Thought templates produce more contextually appropriate humor than generic prompting. HuCoT templates enforce multi-step reasoning with culture-specific steps (e.g., Indian style: "cultural micro-context, shared experiences, delivery"; Gen Z-Indian: "dark reality, meme culture, cultural code-switching"). Each style has fixed step counts (6-8 steps) guiding the generation LLM. This works because humor can be decomposed into discrete reasoning steps that vary predictably by cultural archetype, but breaks when target audience doesn't match predefined cultural templates or when cultural boundaries are poorly defined.

### Mechanism 3: Iterative Judge-Guided Revision
Iterative judge-guided revision with multi-signal scoring improves joke quality measurably. HGS fuses four signals (direct vote, multi-persona scoring, pairwise win-rate, topic relevance). Strategies scoring below 6.0 trigger revision with Judge LLM suggestions. Loop runs max 2 iterations with 0.2 improvement threshold. This works because LLM-based judge signals correlate with human humor perception, and revision suggestions transfer to improved outputs, though it breaks when judge LLM has systematic biases or revision suggestions are inactionable.

## Foundational Learning

- **Concept**: Chain-of-Thought (CoT) Prompting
  - Why needed here: HuCoT builds directly on CoT, requiring understanding of how structured reasoning steps affect generation quality
  - Quick check question: Can you explain why decomposing reasoning into explicit steps might improve creative outputs versus single-pass generation?

- **Concept**: Knowledge Graphs for Retrieval-Augmented Generation
  - Why needed here: The KG component stores and retrieves historical strategies; understanding entity-relationship querying is essential
  - Quick check question: How would you structure a KG node for a "humor strategy" to enable cross-topic retrieval?

- **Concept**: Multi-Objective Scoring / Ensemble Evaluation
  - Why needed here: HGS combines four distinct signals with learned weights; understanding weighted aggregation and signal independence is critical
  - Quick check question: Why might pairwise win-rates provide different signal than direct 1-5 ratings?

## Architecture Onboarding

- **Component map**: Strategy LLM (gemma2-9b-it) -> Knowledge Graph (NetworkX) -> HuCoT Template -> Joke Generation LLM (llama-3.3-70b-versatile) -> Novelty Filter (all-MiniLM-L6-v2) -> Judge LLM (llama3-70b-8192) -> HGS Aggregator

- **Critical path**: 1. Topic input → Strategy LLM generates N=12 strategies + k=3 hybrids 2. KG retrieval augments strategy pool 3. Each strategy → HuCoT template → Joke Generation LLM → raw jokes 4. Novelty filter removes >0.75 similarity jokes (~18% filtered) 5. Judge LLM scores filtered jokes via HGS 6. Low-scoring strategies (<6.0) → revision loop (max 2 iterations) 7. Output: ranked jokes with reasoning traces

- **Design tradeoffs**: Smaller Strategy LLM (gemma2-9b) vs. larger chosen for cost but note smaller LLMs (<8B) were "less effective for nuanced joke generation"; Novelty threshold 0.75 balances diversity vs output count; Max 2 revision iterations prevents overfitting to judge preferences; Hardcoded HuCoT templates vs. learned flagged as future work (meta-learning HuCoT)

- **Failure signatures**: High novelty filter rejection rate (>30%) indicates strategy space too narrow; Revision loop not triggering suggests threshold too high or initial quality sufficient; Generic-feeling outputs indicate HuCoT template mismatch with target audience; Weak HGS-human correlation suggests judge LLM bias or persona misalignment

- **First 3 experiments**: 1. Baseline ablation: Run pipeline with KG disabled, Revision disabled, and both disabled. Compare HGS distributions to isolate each component's contribution. 2. Template validation: Generate jokes for same topic using Generic vs. Indian vs. Gen Z-Indian HuCoT. Have human judges (not LLM) rate cultural appropriateness to validate template design. 3. Threshold sweep: Vary novelty threshold (0.65, 0.75, 0.85) and revision improvement threshold (0.1, 0.2, 0.3). Measure output diversity vs. quality tradeoff.

## Open Questions the Paper Calls Out

- **Question**: Does the Humor Generation Score (HGS) correlate with live audience reception?
  - Basis in paper: The authors state HGS is not yet grounded in real-world data and propose field studies at comedy clubs
  - Why unresolved: Current evaluation relies on LLM judges and a small sample of 13 humans, lacking live feedback
  - What evidence would resolve it: Correlation data between HGS and live audience reactions in stand-up clubs

- **Question**: Can fine-tuned dynamic reasoning outperform the fixed HuCoT templates?
  - Basis in paper: Future work proposes "Meta-Learning HuCoT" to generate dynamic reasoning steps conditioned on context
  - Why unresolved: The current system uses static templates (Generic, Indian, Gen Z-Indian) which may lack adaptability
  - What evidence would resolve it: A performance comparison (HGS) between fine-tuned adaptive models and the static template baseline

- **Question**: How do decoding parameters like temperature affect the pipeline's novelty-coherence balance?
  - Basis in paper: The authors list "Investigating Decoding Effects" as a key future direction
  - Why unresolved: The study empirically fixed hyperparameters but did not systematically test how sampling variance impacts humor quality
  - What evidence would resolve it: An ablation study measuring novelty filter retention and HGS across different temperature settings

## Limitations
- HGS evaluation relies entirely on LLM judges rather than human validation beyond initial template study, raising concerns about ecological validity
- Knowledge Graph's effectiveness depends heavily on its initial content and retrieval relevance - paper doesn't specify how comprehensive or diverse the historical strategy database needs to be for novel topics
- Fixed HuCoT templates may not scale well to truly novel cultural contexts or hybrid audiences

## Confidence
- **High Confidence**: The multi-stage pipeline architecture is technically sound and the statistical significance of results is properly established (p < 0.05)
- **Medium Confidence**: The mechanism of combining strategic planning with historical retrieval is plausible but depends heavily on KG quality and strategy transferrability
- **Low Confidence**: The cultural effectiveness of predefined HuCoT templates for truly diverse audiences, and the correlation between LLM judge scores and actual human humor perception

## Next Checks
1. **Human Validation Study**: Have independent human judges (not involved in initial template development) rate jokes generated by KG+Revision vs baseline across the same 9 topics, measuring both HGS correlation and direct preference
2. **Cross-Cultural Transfer Test**: Generate jokes for a truly novel cultural context (e.g., a specific regional dialect or subculture not represented in HuCoT templates) and measure template effectiveness degradation
3. **KG Dependency Analysis**: Systematically vary the Knowledge Graph size and diversity, measuring performance as historical strategy coverage decreases to identify the minimum viable KG threshold