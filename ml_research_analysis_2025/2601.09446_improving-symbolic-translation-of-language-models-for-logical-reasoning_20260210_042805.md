---
ver: rpa2
title: Improving Symbolic Translation of Language Models for Logical Reasoning
arxiv_id: '2601.09446'
source_url: https://arxiv.org/abs/2601.09446
tags:
- language
- errors
- inference
- instruct
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a novel approach to improve the symbolic\
  \ translation of natural language into first-order logic (FOL) for smaller language\
  \ models (LMs) in logical reasoning tasks. The key idea is to decompose the translation\
  \ process into two stages\u2014predicate generation and FOL translation\u2014enabling\
  \ greater control and reducing formatting errors."
---

# Improving Symbolic Translation of Language Models for Logical Reasoning

## Quick Facts
- **arXiv ID:** 2601.09446
- **Source URL:** https://arxiv.org/abs/2601.09446
- **Reference count:** 27
- **Primary result:** Two-stage incremental inference + verifier significantly reduces error rates in NL-to-FOL translation for 3-4B LMs, improving reasoning accuracy across four logical reasoning datasets.

## Executive Summary
This paper addresses the challenge of translating natural language statements into first-order logic (FOL) for logical reasoning tasks, particularly for smaller language models (3-4B parameters). The authors propose a novel two-stage incremental inference approach that first generates predicates and then translates full FOL statements conditioned on those predicates. Additionally, they introduce a lightweight verification module to correct predicate-arity errors during inference. The method is evaluated across four logical reasoning datasets, demonstrating significant improvements in execution rates, predicate coverage, and reasoning accuracy compared to standard inference and in-context learning baselines.

## Method Summary
The approach consists of three main components: (1) fine-tuning smaller LMs on synthesized data generated by larger models and verified through Prover9 theorem prover, (2) implementing incremental inference that decomposes NL-to-FOL translation into predicate generation followed by FOL translation, and (3) adding a lightweight verification module that uses a small LM to check and correct predicate-arity errors. The training uses LoRA fine-tuning (3 epochs, batch size 64, learning rate 1e-4) on a combination of synthesized ProofWriter data (10,424 verified records) and human-annotated FOLIO data. During inference, the model first generates predicates from natural language, then generates FOL statements conditioned on both the natural language and generated predicates, with optional verification for arity consistency.

## Key Results
- Incremental inference reduces error propagation and improves predicate coverage by 16% on out-of-distribution data
- Fine-tuned 3-4B models achieve execution rates exceeding 80% on ProofWriter test set
- Verification module corrects predicate-arity errors, further improving performance on challenging datasets like ProntoQA
- The approach enables smaller models to match or exceed performance of larger models on symbolic reasoning tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Decomposing NL-to-FOL translation into two sequential stages reduces error propagation from autoregressive decoding and improves predicate coverage.
- **Mechanism:** Standard inference allows single token errors to cascade through generation, causing repetitive loops and formatting failures. Incremental inference generates only predicates first, then FOL statements conditioned on those predicates, constraining the search space and improving coverage.
- **Core assumption:** The model learns the two-stage pattern during fine-tuning and can generate complete predicate sets before FOL generation.
- **Evidence anchors:** Abstract states "incremental inference... divides inference into two stages, predicate generation and FOL translation" and section 4.2 notes "This incremental procedure reduces error propagation and yields more syntactically and semantically coherent FOL outputs."
- **Break condition:** If stage-1 predicate generation produces incomplete or incorrect predicates, stage-2 FOL generation will fail regardless of syntactic correctness.

### Mechanism 2
- **Claim:** Fine-tuning smaller LMs on tool-verified synthesized FOL data transfers symbolic translation capabilities from larger models.
- **Mechanism:** GPT-4o generates FOL translations from ProofWriter premises, which are filtered through Prover9 syntax validation and semantic filtering to produce high-quality training data for 3-4B models.
- **Core assumption:** Synthesized data quality is sufficient and Prover9 verification catches most errors, though manual evaluation found ~2% residual semantic errors.
- **Evidence anchors:** Abstract mentions "fine-tune smaller LMs using data synthesized by large language models" and section 4.1 states "This synthesized data, combined with existing symbolic datasets, serves as the foundation for training LMs."
- **Break condition:** Large domain shift between synthesized training data and target data could prevent effective transfer of capabilities.

### Mechanism 3
- **Claim:** A lightweight in-context verifier can detect and correct predicate-arity errors between the two incremental stages.
- **Mechanism:** A small LM (Gemma-3-4B-Instruct) with 3-shot examples checks for arity consistency after stage-1 predicate generation and outputs corrected predicates if errors are found.
- **Core assumption:** The verifier can reliably identify arity errors via in-context learning and corrections are recoverable without full predicate regeneration.
- **Evidence anchors:** Abstract mentions "propose a lightweight verifier module to correct predicate-arity errors during inference" and section 6.3 states "using a small LM for predicate verification further improves performance over incremental inference alone."
- **Break condition:** If arity errors are entangled with deeper semantic errors, corrections may produce syntactically valid but semantically incorrect FOL.

## Foundational Learning

- **Concept: First-Order Logic (FOL) Structure**
  - **Why needed here:** FOL requires predicates with defined arities, quantifiers (∀, ∃) binding variables, and logical connectives (→, ∧, ∨, ¬). Violations produce parsing failures in theorem provers.
  - **Quick check question:** Given "All cats are mammals," what is the correct FOL with proper quantification? (Answer: ∀x(Cat(x) → Mammal(x)))

- **Concept: Predicate Arity Consistency**
  - **Why needed here:** A predicate must use the same number of arguments across all occurrences. Parent(x,y) vs. Parent(x) is an arity error that causes solver failures.
  - **Quick check question:** If FOL contains both Sees(Tiger, Mouse) and Sees(Mouse), what error type is this? (Answer: Arity mismatch)

- **Concept: Autoregressive Error Propagation**
  - **Why needed here:** Greedy decoding means early token errors compound. The paper shows repetitive loops (Figure 1: "IsFavorite(x,y)" repeated) as a failure mode.
  - **Quick check question:** Why does stopping predicate generation early help avoid formatting errors? (Answer: It prevents the model from entering degenerative loops during combined predicate+FOL generation)

## Architecture Onboarding

- **Component map:** Input NL premises/conclusion → Stage 1 Predicate Generator → Optional Verifier → Stage 2 FOL Translator → Prover9 theorem prover → True/False/Uncertain

- **Critical path:** 1) Ensure SFT data passes Prover9 validation before training 2) Validate stage-1 predicate format (arity consistency, coverage) 3) Monitor execution rate as primary quality signal before accuracy

- **Design tradeoffs:** Incremental inference adds forward pass but no extra output tokens; latency neutral with proper token allocation. Verifier adds inference latency (~1 extra forward pass) for error-prone datasets. LoRA fine-tuning trades full capability for compute efficiency.

- **Failure signatures:** Formatting errors (repetitive loops, incomplete outputs) → reduce max tokens or use incremental inference. Arity errors (Prover9 returns "symbols used with multiple arities") → enable verifier. Low coverage (predicates in FOL not in generated set) → check stage-1 generation quality.

- **First 3 experiments:** 1) Replicate SFT baseline: Fine-tune 3-4B model on combined ProofWriter+FOLIO data, measure execution rate on held-out ProofWriter test set 2) Ablate incremental vs. standard inference: Compare error counts and coverage metrics 3) Add verifier on OOD data: Test ProntoQA with/without verifier to isolate arity-error correction gains

## Open Questions the Paper Calls Out

- **Can extending the incremental inference framework to more than two stages further reduce error propagation and improve reasoning accuracy?**
  - Basis in paper: [explicit] Authors state in Discussion that they "anticipate that higher-level or multi-stage forms of incremental inference may yield stronger gains" and leave such extensions for future work
  - Why unresolved: Current study only evaluates two-stage decomposition
  - What evidence would resolve it: Empirical results from 3+ stage pipeline evaluated on FOLIO and ProofWriter datasets

- **How can the verification module be expanded to correct semantic errors and syntactic issues beyond simple arity mismatches?**
  - Basis in paper: [explicit] Conclusion suggests future work should focus on "strengthening the verification module for both predicate and FOL generation, guided by error classification"
  - Why unresolved: Current verifier is lightweight and specifically targets predicate-arity errors
  - What evidence would resolve it: Verifier trained on full error taxonomy that improves metrics for semantic correctness or parsing validity

- **Does high predicate coverage and syntax validity in this framework guarantee the semantic correctness of the symbolic translation?**
  - Basis in paper: [inferred] Limitations note framework "does not fully address semantic correctness, as symbolic representations may not capture the complete intended meaning"
  - Why unresolved: Evaluation relies on execution rates and reasoning accuracy, not direct semantic fidelity measurement
  - What evidence would resolve it: Human or model-based evaluation measuring semantic alignment between original NL and generated FOL

## Limitations
- Framework does not fully address semantic correctness, as symbolic representations may not capture complete intended meaning
- Synthesized data pipeline may not scale well to domains with significantly different predicate vocabularies
- Verifier module currently only handles arity errors, not broader semantic or syntactic issues

## Confidence

- **High confidence:** Incremental inference effectiveness in reducing error propagation and improving execution rates, consistently demonstrated across all four datasets
- **Medium confidence:** Verifier module benefits, primarily shown on OOD datasets (ProntoQA) with untested generalization to other error types
- **Low confidence:** Long-term stability of synthesized data pipeline due to incomplete details on filtering criteria and scalability to complex domains

## Next Checks
1. **Ablation on Error Types:** Measure error rates separately for repetitive loops, arity mismatches, and semantic errors under standard vs. incremental inference to confirm error propagation reduction
2. **Verifier Generalization:** Test the verifier module on a dataset with known semantic errors (not just arity errors) to assess robustness beyond its primary use case
3. **Scalability of Synthesized Data:** Replicate the data synthesis pipeline for a more complex logical reasoning task (e.g., multi-hop reasoning) and measure the proportion of syntactically and semantically valid samples