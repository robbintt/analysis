---
ver: rpa2
title: 'Vehicle Classification under Extreme Imbalance: A Comparative Study of Ensemble
  Learning and CNNs'
arxiv_id: '2509.24880'
source_url: https://arxiv.org/abs/2509.24880
tags:
- training
- accuracy
- figure
- class
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of accurate vehicle classification
  in the presence of extreme class imbalance in public datasets. To tackle this, a
  16-class vehicle image corpus of ~47k images was curated by merging data from Kaggle,
  ImageNet, and web-crawling.
---

# Vehicle Classification under Extreme Imbalance: A Comparative Study of Ensemble Learning and CNNs

## Quick Facts
- arXiv ID: 2509.24880
- Source URL: https://arxiv.org/abs/2509.24880
- Reference count: 0
- Primary result: CNN architecture outperformed ensemble learners in classifying vehicles under extreme class imbalance

## Executive Summary
This study addresses the challenge of accurate vehicle classification in the presence of extreme class imbalance in public datasets. To tackle this, a 16-class vehicle image corpus of ~47k images was curated by merging data from Kaggle, ImageNet, and web-crawling. Six balanced variants of the dataset were created using SMOTE oversampling and targeted undersampling. The performance of lightweight ensemble learners—Random Forest, AdaBoost, and a soft-voting classifier based on MobileNet-V2 features—was benchmarked against a configurable ResNet-style CNN trained with strong augmentation and label smoothing. The best ensemble model achieved 74.8% test accuracy, while the CNN reached 79.19% on the full test set and 81.25% on an unseen inference batch, demonstrating the superiority of deep learning models. However, the most under-represented class (Barge) remained a persistent challenge, indicating that rebalancing alone is insufficient. Future work should prioritize collecting additional minority-class data and exploring cost-sensitive objectives such as focal loss, as well as hybrid ensemble–CNN pipelines to combine interpretability with representational power.

## Method Summary
The research team curated a 16-class vehicle image dataset of approximately 47,000 images by combining sources from Kaggle, ImageNet, and web crawling. To address extreme class imbalance, six balanced dataset variants were created using SMOTE oversampling and targeted undersampling techniques. The study compared lightweight ensemble learners (Random Forest, AdaBoost, and soft-voting MobileNet-V2 features) against a configurable ResNet-style CNN with strong augmentation and label smoothing. Models were evaluated on both the full test set and an unseen inference batch, with accuracy serving as the primary metric.

## Key Results
- Best ensemble model achieved 74.8% test accuracy
- CNN reached 79.19% test accuracy and 81.25% on unseen inference batch
- Barge class remained persistently challenging despite rebalancing efforts
- Deep learning models demonstrated superiority over ensemble approaches

## Why This Works (Mechanism)
The CNN architecture's superiority stems from its ability to learn hierarchical feature representations that capture complex vehicle characteristics across varying conditions. The ResNet-style design with residual connections allows effective gradient flow during training, enabling deeper networks to learn more discriminative features. Strong augmentation techniques (random crops, flips, color jitter) helped the CNN generalize better to unseen data by exposing it to diverse variations during training. Label smoothing prevented overconfidence and improved calibration, particularly beneficial for minority classes where hard targets could lead to poor generalization.

## Foundational Learning
- **Class Imbalance**: Why needed - ensures minority classes receive adequate representation during training; Quick check - verify class distribution histograms before and after rebalancing
- **SMOTE Oversampling**: Why needed - generates synthetic examples to balance minority classes without collecting new data; Quick check - inspect synthetic samples for realistic appearance
- **Label Smoothing**: Why needed - prevents overconfident predictions and improves calibration; Quick check - monitor validation loss curves for smoothing effectiveness
- **Residual Connections**: Why needed - enables training of deeper networks by facilitating gradient flow; Quick check - verify training stability as network depth increases
- **Strong Augmentation**: Why needed - improves generalization to unseen data; Quick check - compare training vs validation accuracy gaps

## Architecture Onboarding

**Component Map**: Image data -> Augmentation pipeline -> Feature extractor (CNN/ensemble) -> Classification layer -> Accuracy metric

**Critical Path**: Data curation and rebalancing → Model training with augmentation → Validation on test set → Inference on unseen batch

**Design Tradeoffs**: Ensemble methods offer interpretability and lower computational cost but sacrifice accuracy compared to CNNs. The CNN's superior representational power comes at the cost of increased complexity and training time.

**Failure Signatures**: Persistent poor performance on Barge class indicates data scarcity issues that rebalancing cannot solve. Large gaps between training and validation accuracy suggest overfitting or insufficient augmentation.

**3 First Experiments**:
1. Replace SMOTE with focal loss to directly address class imbalance during training
2. Implement class-weighted cross-entropy to prioritize minority class accuracy
3. Test hybrid approach combining CNN features with ensemble voting

## Open Questions the Paper Calls Out
None

## Limitations
- Rebalancing techniques insufficient for extreme imbalance without additional minority-class data
- Accuracy metric may mask poor minority-class performance
- Limited comparison to single CNN architecture and three ensemble methods
- Potential domain shift from merging multiple data sources

## Confidence

**High**: CNN outperforms ensemble learners on overall accuracy and unseen inference data

**Medium**: Ensemble methods are viable lightweight alternatives but lag behind CNNs

**Medium**: Rebalancing alone is insufficient for extreme imbalance without additional minority-class data

## Next Checks
1. Evaluate models using class-specific metrics (F1, precision-recall AUC) to assess minority-class performance beyond overall accuracy
2. Collect and incorporate additional real-world minority-class samples to test if accuracy gains are due to more data rather than algorithmic improvements
3. Implement and compare focal loss or other cost-sensitive objectives to determine if targeted loss functions improve minority-class classification without rebalancing