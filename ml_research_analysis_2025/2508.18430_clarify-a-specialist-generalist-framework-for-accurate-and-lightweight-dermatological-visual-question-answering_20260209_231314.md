---
ver: rpa2
title: 'CLARIFY: A Specialist-Generalist Framework for Accurate and Lightweight Dermatological
  Visual Question Answering'
arxiv_id: '2508.18430'
source_url: https://arxiv.org/abs/2508.18430
tags:
- clarify
- generalist
- knowledge
- specialist
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLARIFY introduces a Specialist-Generalist framework to address
  the challenge of deploying accurate, lightweight, and trustworthy dermatological
  AI systems. The framework combines a high-precision image classifier (Specialist)
  for disease detection with a compressed, knowledge-grounded Vision-Language Model
  (Generalist) for natural language responses.
---

# CLARIFY: A Specialist-Generalist Framework for Accurate and Lightweight Dermatological Visual Question Answering

## Quick Facts
- arXiv ID: 2508.18430
- Source URL: https://arxiv.org/abs/2508.18430
- Reference count: 40
- Primary result: 18% higher diagnostic accuracy with 20%+ VRAM and 5%+ latency reduction compared to fine-tuned VLM baselines

## Executive Summary
CLARIFY introduces a Specialist-Generalist framework that achieves accurate and lightweight dermatological Visual Question Answering by separating disease classification from language generation. The system uses a high-precision image classifier (Specialist) to identify diseases, then guides a compressed Vision-Language Model (Generalist) through structured prompting to generate natural language explanations. A knowledge graph retrieval module grounds responses in factual medical information, reducing hallucinations. Evaluated on a curated dermatology VQA dataset, CLARIFY achieves 82.1% diagnostic accuracy, outperforming fine-tuned baselines while reducing computational requirements.

## Method Summary
The framework consists of three components: a frozen DINOv2-based Specialist for disease classification, a structurally pruned and LoRA-fine-tuned Generalist for language generation, and a knowledge graph-based retrieval module for factual grounding. The Specialist classifies images into one of eight dermatological conditions, with its prediction used to construct a guided prompt for the Generalist. The Generalist is pruned by removing transformer layers based on cosine similarity metrics, then fine-tuned on QA pairs with frozen vision encoders. The KG-RAG module retrieves medical facts from a Wikipedia-based knowledge graph constructed via KGGen, which are appended to the prompt to constrain the Generalist's output.

## Key Results
- CLARIFY achieves 82.1% diagnostic accuracy, 18% higher than fine-tuned baseline VLMs (51-64% range)
- VRAM requirements reduced by at least 20% through structural pruning
- Inference latency decreased by at least 5% while maintaining or improving accuracy
- KG-RAG module significantly reduces hallucinations compared to baseline VLMs

## Why This Works (Mechanism)

### Mechanism 1: Decoupled Perception-Reasoning
The framework routes images first to a specialized classifier (DINOv2) to generate high-confidence disease labels, which are then injected into the VLM's prompt. This separation relieves the VLM from fine-grained visual discrimination, allowing it to focus solely on conversational reasoning. The core assumption is that the Specialist classifier is strictly more accurate at visual disease identification than the generalist VLM.

### Mechanism 2: Redundancy-Aware Structural Pruning
The authors employ iterative pruning where transformer layers are removed based on cosine similarity between pruned and original model embeddings. Layers with high similarity are deemed low-importance and permanently deleted, preserving conversational utility while significantly reducing inference cost. This differs from quantization by removing entire transformer blocks rather than lowering precision.

### Mechanism 3: Knowledge Graph Grounding (KG-RAG)
Upon prediction, the system queries a dermatological Knowledge Graph constructed via KGGen, retrieving facts about symptoms and treatments that are appended to the VLM prompt. This constrains the VLM's output probability distribution to favor tokens aligned with provided facts, reducing hallucinations and improving safety of generated responses.

## Foundational Learning

- **Concept: Structural Pruning vs. Quantization**
  - Why needed here: To understand how the "Generalist" is made lightweight
  - Quick check question: Does the pruning method require specialized sparse matrix hardware support to achieve the reported speedup? (Answer: No, it uses standard dense matrix multiplication with fewer layers)

- **Concept: Prompt Engineering / Guided Decoding**
  - Why needed here: This is the interface between the Specialist and Generalist
  - Quick check question: If the Specialist predicts "Melanoma" but the image is ambiguous, how does the prompt structure prevent the VLM from expressing uncertainty?

- **Concept: Catastrophic Forgetting**
  - Why needed here: This is the core problem the paper claims to solve
  - Quick check question: Why does fine-tuning the VLM end-to-end (the baseline approach) degrade conversational ability more than the CLARIFY approach? (Answer: CLARIFY freezes the VLM's perception modules and trains it only to "chat" given the correct answer)

## Architecture Onboarding

- **Component map:** Image + Text Query → Specialist (DINOv2 + FFN Head) → Knowledge Module (KG + Vector DB) → Prompt Constructor → Generalist (Pruned LLaVA/Qwen)
- **Critical path:** The Specialist's classification accuracy - the entire system's reliability hinges on the first step
- **Design tradeoffs:** Accuracy vs. Latency (adding layers hurts latency), VRAM vs. Coherence (cliff in performance when removing >8 layers), Dataset Size vs. Generalization (small dataset risks overfitting)
- **Failure signatures:** Pipeline Desynchronization (Specialist predicts Disease A but Generalist describes Disease B), Hallucination Loops (if KG retrieval is empty), Latency Spikes (RAG retrieval adds latency)
- **First 3 experiments:** 1) Replicate pruning curve on target hardware to find layer cutoff, 2) Bypass Specialist to quantify accuracy gain attribution, 3) Input out-of-distribution images to test graceful degradation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does replacing Wikipedia with clinically validated medical ontologies significantly improve the factual reliability and safety of the system's responses?
- Basis in paper: Section VII states the current Knowledge Graph uses Wikipedia for prototyping but acknowledges it is not clinically authoritative
- Why unresolved: The current implementation relies on a general-purpose knowledge source, which lacks the rigor required for high-stakes medical advice
- What evidence would resolve it: Comparative evaluation measuring hallucination rates between Wikipedia-based KG and KG built from peer-reviewed medical databases

### Open Question 2
- Question: Can the framework maintain its efficiency and accuracy advantages when scaled to significantly larger datasets containing a wider variety of dermatological conditions?
- Basis in paper: Section VII notes experiments were conducted on a relatively small dataset (1,776 images) and scaling to larger, more diverse datasets is essential
- Why unresolved: Current results are based on a curated set of 8 diseases and a test set of only 39 images
- What evidence would resolve it: Benchmarking on a large-scale dataset (>10,000 images, >20 classes) to verify if the 18% accuracy gain holds

### Open Question 3
- Question: To what extent can advanced compression techniques further reduce the Generalist's computational footprint before the model loses the ability to synthesize the Specialist's inputs?
- Basis in paper: Section VI lists "applying advanced compression to further minimize the Generalist's footprint" as primary future research direction
- Why unresolved: While structural pruning showed promise, the trade-off between extreme compression and retention of reasoning capabilities remains unexplored
- What evidence would resolve it: Analysis of diagnostic accuracy across varying compression levels (30%, 50%, 70% parameter reduction)

## Limitations
- Small, curated dataset (1,776 images, 8 disease classes) may not reflect real-world dermatological complexity
- Knowledge Graph relies on Wikipedia, which is not a clinically authoritative source
- Evaluation lacks external clinical validation - diagnoses scored against dataset labels, not expert consensus
- Pruning method's effectiveness depends on cosine similarity as proxy for semantic preservation
- No comparison to simpler alternatives like adapter-based tuning

## Confidence

- **High Confidence:** Structural pruning methodology and its quantitative impact on VRAM/latency are well-supported by ablation studies; Specialist-Generalist separation as design pattern validated by 18% accuracy improvement
- **Medium Confidence:** Knowledge graph grounding improves factual accuracy in tested domain but depends on KG quality and may not transfer to other medical specialties; "catastrophic forgetting" claim is mechanistically sound but lacks comparison to other fine-tuning strategies
- **Low Confidence:** Generalizability to diverse skin tones, rare diseases, or clinical environments with different imaging conditions is not addressed; system's behavior on out-of-distribution cases is unknown

## Next Checks
1. **Clinical Expert Validation:** Have board-certified dermatologists review a subset of model predictions on real patient cases to assess diagnostic accuracy beyond dataset labels
2. **Cross-Dataset Testing:** Evaluate CLARIFY on external dermatology dataset (e.g., ISIC) to measure generalization and identify overfitting to Small-Derma-VQA corpus
3. **Ablation of Knowledge Sources:** Replace Wikipedia-based KG with clinically curated knowledge base (e.g., PubMed abstracts or medical ontologies) and measure changes in factual accuracy and hallucination rates