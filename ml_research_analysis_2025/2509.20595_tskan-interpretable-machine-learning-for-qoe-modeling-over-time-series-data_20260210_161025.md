---
ver: rpa2
title: 'TSKAN: Interpretable Machine Learning for QoE modeling over Time Series Data'
arxiv_id: '2509.20595'
source_url: https://arxiv.org/abs/2509.20595
tags:
- video
- interpretable
- time
- streaming
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces TSKAN, an interpretable machine learning
  approach for Quality of Experience (QoE) modeling in video streaming using time
  series data. The method combines Kolmogorov-Arnold Networks (KANs) with frequency-domain
  features extracted via discrete Fourier transform, enabling interpretable QoE predictions
  while preserving temporal information.
---

# TSKAN: Interpretable Machine Learning for QoE modeling over Time Series Data

## Quick Facts
- arXiv ID: 2509.20595
- Source URL: https://arxiv.org/abs/2509.20595
- Reference count: 31
- Primary result: TSKAN achieves test RMSE of 0.2169 on LIVE-Netflix-II and 0.4716 on Waterloo III datasets for interpretable QoE prediction

## Executive Summary
TSKAN introduces an interpretable machine learning approach for Quality of Experience (QoE) modeling in video streaming using time series data. The method combines Kolmogorov-Arnold Networks (KANs) with frequency-domain features extracted via discrete Fourier transform, enabling interpretable QoE predictions while preserving temporal information. The model was evaluated on Waterloo III and LIVE-Netflix-II datasets using Mean Opinion Score (MOS) as the QoE metric.

TSKAN achieved a test RMSE of 0.2169 on LIVE-Netflix-II and 0.4716 on Waterloo III datasets, outperforming other interpretable models like Decision Trees, Linear Regression, and EBM. While not surpassing deep learning models in accuracy, TSKAN's performance is remarkably close while maintaining interpretability through visible activation functions that reveal feature contributions to MOS predictions.

## Method Summary
TSKAN processes multivariate time series data from video streaming sessions by first extracting frequency-domain features via Discrete Fourier Transform (DFT). For each variable, it computes the DC component, magnitude, and phase at frequency f=1, creating compact temporal summaries. A Kolmogorov-Arnold Network serves as an interpretable readout model, learning univariate spline activation functions that can be directly visualized to understand how each feature contributes to MOS predictions. The architecture uses top-k frequency feature selection to improve interpretability by retaining only the most important components, reducing visual clutter while maintaining performance.

## Key Results
- Test RMSE of 0.2169 on LIVE-Netflix-II dataset
- Test RMSE of 0.4716 on Waterloo III dataset
- Outperforms interpretable baselines (Decision Trees, Linear Regression, EBM) while maintaining visual interpretability through learned activation functions
- Achieves performance close to deep learning models despite using only 120 parameters in a 1-layer KAN

## Why This Works (Mechanism)

### Mechanism 1
Frequency-domain transformation preserves temporal dynamics in a compact form amenable to interpretable modeling. The Discrete Fourier Transform converts raw time-series into magnitude and phase components at different frequencies. The DC component captures average levels (e.g., total stalling time), while Mv(1) and φv(1) capture whether and when a feature changes over the session. This allows a readout model to access temporal position information without processing each timestep individually. Core assumption: The first few frequency components (DC, f=1) contain sufficient signal for QoE prediction; higher-frequency dynamics are less relevant to user perception.

### Mechanism 2
Kolmogorov-Arnold Networks provide interpretable, learnable univariate activation functions that reveal marginal feature contributions. KANs instantiate the Kolmogorov-Arnold representation theorem, decomposing multivariate functions into sums of univariate functions (ψq,p, Φq) parameterized as splines. Each learned spline maps one input feature (or frequency component) to its contribution to the output (MOS). Because these are 1D functions, they can be directly visualized and inspected for domain-consistent behavior (e.g., monotonic stalling penalty). Core assumption: The underlying QoE function admits a predominantly additive or low-interaction structure expressible via univariate compositions.

### Mechanism 3
Top-k frequency feature selection improves interpretability with limited accuracy loss by pruning low-importance components. After an initial training pass using F frequency components, input importance scores (αj) are computed. Only the top-k components are retained for the final model. This reduces the number of inputs to the KAN, concentrating interpretability on the most influential features and reducing visual clutter. Core assumption: Importance scores computed post-hoc from a trained model reliably identify features that generalize.

## Foundational Learning

- Concept: Kolmogorov-Arnold Representation Theorem
  - Why needed here: It justifies why a sum of univariate spline functions can approximate a multivariate QoE mapping, which is the mathematical basis for TSKAN's interpretability.
  - Quick check question: Can you explain why KANs replace weight matrices with learned spline functions, and what that implies for interpretability?

- Concept: Discrete Fourier Transform (DFT) for Time Series
  - Why needed here: TSKAN relies on DFT to convert raw streaming logs into magnitude and phase features that encode both level and timing of events.
  - Quick check question: Given a 16-timestep stalling series, what does M_stalling(0) represent versus M_stalling(1) and φ_stalling(1)?

- Concept: Inherent vs Post-hoc Interpretability
  - Why needed here: TSKAN is designed to be inherently interpretable (transparent activations) rather than explained via external methods like SHAP or LIME.
  - Quick check question: What is the difference between inspecting a learned KAN activation function and generating a SHAP value for a deep learning model?

## Architecture Onboarding

- Component map:
  Input: Multivariate time series X ∈ R^{N×V×T} (stalling, bitrate, chunk size, QP, framerate, resolution) -> Feature extraction: DFT per variable → DC (Mv(0)), magnitude (Mv(f)), phase (φv(f)) -> Selection: Initial training → compute importance αj → retain top-k features -> Readout: 1-layer KAN with learnable spline activations ψq,p and Φq -> Output: Predicted MOS (z-scored)

- Critical path:
  1. Correct DFT implementation (handle variable-length sequences; pad/trim as needed)
  2. Top-k selection logic (importance computation, reproducible ranking)
  3. KAN layer initialization and spline regularization (smoothness, sparsity)

- Design tradeoffs:
  - Layers vs interpretability: Paper uses 1-layer KAN; more layers improve capacity but reduce transparency.
  - k vs interpretability: Larger k captures more signal but increases cognitive load for interpretation.
  - Frequency range F: Only f=0,1 used in experiments; higher F may capture more dynamics but adds complexity.

- Failure signatures:
  - Strange activation shapes (e.g., non-monotonic framerate effect, bitrate contribution near zero) → flag for pruning or domain review
  - Large gap between training and validation RMSE → possible overfitting with small k; check regularization
  - Phase features with flat activations → temporal position may not be informative for this dataset

- First 3 experiments:
  1. Reproduce Table II results on LIVE-Netflix-II with F=1, k=10; visualize the 10 activation functions to verify domain-consistent shapes (stalling negative, resolution positive).
  2. Ablate top-k: train with k=5, 10, 15 and compare RMSE and interpretability (number of non-trivial activations).
  3. Sanity check: train a linear regression on the same frequency-domain features and compare RMSE; this establishes a baseline to quantify the non-linear benefit KAN provides.

## Open Questions the Paper Calls Out

### Open Question 1
Can TSKAN generalize its balance of interpretability and accuracy to time series datasets outside of video streaming QoE? The conclusion states, "In future, we would like to test TSKAN on timeseries datasets from different domains." This remains unresolved as the evaluation is currently restricted to Waterloo III and LIVE-Netflix-II video streaming datasets. Benchmarking TSKAN against standard time series models in domains like healthcare or finance would provide evidence.

### Open Question 2
Can automated feature pruning based on activation function shapes improve model robustness and performance? The authors identify "strange patterns" (e.g., in framerate features) and state, "Such things could be part of model debugging and refinement, which in turn are enabled by TSKAN. We leave this for future work." A study demonstrating that removing features with "strange" activation logic leads to lower RMSE or better generalization would resolve this.

### Open Question 3
How can TSKAN be adapted to handle variable-length input sequences without data truncation? The methodology required removing samples with more than 16 chunks to satisfy the fixed input dimensions of the Discrete Fourier Transform (DFT). The reliance on standard DFT necessitates fixed-length inputs, forcing the discard of valid data samples (29 examples were removed). An extension that processes variable-length sequences while preserving frequency-domain features would resolve this.

## Limitations
- Unknown KAN implementation details (spline grid size, regularization coefficients, pruning thresholds) prevent exact reproduction of results
- Feature importance computation method for top-k selection is underspecified
- The claim that performance is "remarkably close" to deep learning models lacks direct controlled comparison on same datasets

## Confidence
- **High Confidence**: The core methodological contribution (combining KAN with frequency-domain features for interpretable QoE modeling) is sound and well-explained. The DFT feature extraction process is clearly specified and reproducible.
- **Medium Confidence**: The performance claims are reasonable given the interpretability constraints, but exact values depend on unknown hyperparameters. The interpretability benefits are demonstrated but could be strengthened with more extensive analysis.
- **Low Confidence**: The claim that TSKAN's performance is "remarkably close" to deep learning models lacks direct comparison on the same datasets with controlled conditions.

## Next Checks

1. **Ablation study on frequency components**: Systematically vary F (number of frequency components) from 1 to 3 and k (top-k features) from 5 to 15 to quantify the trade-off between interpretability and accuracy, measuring both RMSE and number of non-trivial activation functions.

2. **Comparison with explicit interaction terms**: Modify the KAN architecture to include cross-frequency interaction terms (e.g., M_stalling(1) × φ_bitrate(1)) and measure whether performance improves significantly, testing the core assumption about additive structure.

3. **Domain expert validation of activation functions**: Conduct a blinded review where domain experts evaluate whether the learned activation functions align with expected QoE behavior (monotonic stalling penalty, resolution quality benefit) without knowing which features they represent.