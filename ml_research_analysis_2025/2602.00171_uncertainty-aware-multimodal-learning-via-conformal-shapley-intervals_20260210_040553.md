---
ver: rpa2
title: Uncertainty-Aware Multimodal Learning via Conformal Shapley Intervals
arxiv_id: '2602.00171'
source_url: https://arxiv.org/abs/2602.00171
tags:
- modality
- shapley
- learning
- modalities
- conformal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces conformal Shapley intervals, a framework
  that combines Shapley value attribution with conditional conformal inference to
  construct uncertainty-aware importance intervals for each data modality. The method
  provides finite-sample, input-dependent uncertainty guarantees for modality-level
  Shapley values and enables principled modality selection with a provable near-optimality
  guarantee.
---

# Uncertainty-Aware Multimodal Learning via Conformal Shapley Intervals

## Quick Facts
- arXiv ID: 2602.00171
- Source URL: https://arxiv.org/abs/2602.00171
- Reference count: 36
- This paper introduces conformal Shapley intervals, a framework that combines Shapley value attribution with conditional conformal inference to construct uncertainty-aware importance intervals for each data modality.

## Executive Summary
This work develops a framework for quantifying uncertainty in multimodal learning by constructing input-dependent intervals for modality importance using Shapley values and conformal inference. The method provides finite-sample coverage guarantees while enabling principled modality selection with near-optimality guarantees. The approach is validated across synthetic regression, image classification, and Alzheimer's disease prediction tasks.

## Method Summary
The method combines Shapley value attribution with conditional conformal inference to quantify uncertainty in modality importance. Data is split into training and calibration sets. For each subset of modalities, a predictive model is trained and Shapley values are computed as marginal contributions to prediction loss. Conditional quantile regression in RKHS provides input-dependent intervals for these Shapley values, enabling both uncertainty quantification and modality selection based on upper interval bounds.

## Key Results
- The method provides finite-sample, input-dependent uncertainty guarantees for modality-level Shapley values with coverage probability at least 1-α.
- Modality selection by ranking upper conditional quantiles achieves near-optimal predictive utility with probability at least 1-α.
- On Alzheimer's disease prediction, the method reveals clinically interpretable patterns, showing differences in modality importance across sex, APOE genotype, diagnosis status, and education level.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instance-level Shapley values quantify modality contribution as the weighted average marginal gain in prediction loss reduction across all possible modality coalitions.
- Mechanism: For each calibration point, compute φⱼ(xᵢ) by iterating over all subsets S ⊆ [p]\{j}, weighting each marginal contribution val(S ∪ {j}) - val(S) by |S|!(p-|S|-1)!/p!, where val is defined as the reduction in loss relative to a baseline predictor.
- Core assumption: The value function val(xᵢ, yᵢ; S) = ℓ(yᵢ, μ̂∅) - ℓ(yᵢ, μ̂ˢ(xᵢ,ˢ)) meaningfully captures predictive utility; models μ̂ˢ are refit for each subset S.
- Evidence anchors:
  - [section 3.1] "This value function measures the reduction in prediction loss achieved by including modalities in S relative to the baseline."
  - [section 2.1] Defines classical Shapley value formula and its adaptation to multimodal learning.
- Break condition: If modalities are perfectly redundant, marginal contributions approach zero and Shapley estimates become unstable; interval widths inflate as signal degrades.

### Mechanism 2
- Claim: RKHS-based conditional quantile estimation provides finite-sample, input-dependent coverage for Shapley values under exchangeability.
- Mechanism: Split data into training I₁ and calibration I₂. Fit quantile functions ĥᵗᵃᵘ φⱼ via regularized pinball loss minimization in RKHS H, including a symbolic test point to preserve exchangeability. The conformal Shapley interval provides conditional coverage.
- Core assumption: Assumption 1 (moment bounds, non-degeneracy) holds; the kernel K is uniformly bounded; φⱼ|X has continuous distribution with bounded density.
- Evidence anchors:
  - [section 3.2] "We show in Section 4 that these intervals provide finite-sample uncertainty quantification for modality-level Shapley values that is conditional on the observed input."
  - [Lemma 1] Establishes lower bound on conditional coverage P_f(φⱼ ∈ Ĉⱼ) ≥ 1 - α - regularization terms.
- Break condition: Coverage degrades if exchangeability is violated or if regularization parameters are misspecified relative to data scale.

### Mechanism 3
- Claim: Selecting modalities by ranking upper conditional quantiles yields near-optimal predictive utility with probability at least 1 - α.
- Mechanism: Given miscoverage level α and maximum modalities q, compute upper quantiles ĥ¹⁻ᵅ/(2q) φⱼ for all j. Select modalities with positive upper bounds. Under assumptions, the selected subset achieves near-optimal predictive performance.
- Core assumption: Approximate independence (Assumption 2) for classification and linear-Gaussian structure (Assumption 3) for regression.
- Evidence anchors:
  - [section 3.3] "conditional on the observed features, the selected subset of modalities achieves predictive performance close to that of the optimal subset."
  - [Theorems 1-2] Derive near-optimality bounds explicitly.
- Break condition: If dependence between modalities is large, the guarantee weakens; if q is set too low, optimal modalities may be excluded.

## Foundational Learning

- Concept: **Shapley Values (Cooperative Game Theory)**
  - Why needed here: Core attribution mechanism; requires understanding marginal contribution, coalition weighting, and efficiency/monotonicity axioms.
  - Quick check question: Given players {A,B,C} and values val({A})=2, val({B})=3, val({A,B})=6, compute Shapley value for A.

- Concept: **Split Conformal Inference**
  - Why needed here: Provides distribution-free coverage guarantees; must understand exchangeability, calibration sets, and quantile-based interval construction.
  - Quick check question: If conformity scores on calibration set are {0.1, 0.3, 0.5, 0.7, 0.9} and α=0.2, what prediction interval width results?

- Concept: **Reproducing Kernel Hilbert Spaces (RKHS)**
  - Why needed here: Used for conditional quantile estimation; requires grasping kernel functions, reproducing property, and regularization.
  - Quick check question: For kernel K(x,x') = exp(-||x-x'||²), explain why |h(x)| ≤ κ||h||_K where κ = sup_x √K(x,x).

## Architecture Onboarding

- Component map: Data splitter -> Subset model trainer -> Shapley computer -> RKHS quantile regressor -> Interval constructor -> Modality selector
- Critical path: Shapley computation dominates (O(2^p × |I₂| × model_inference)). For p>15, approximate Shapley is required. RKHS fitting is O(|I₂|²) in sample size.
- Design tradeoffs:
  - Larger I₁ → better μ̂ˢ but fewer calibration points → wider intervals.
  - Smaller α → wider intervals but higher guaranteed coverage.
  - Higher q → more modalities selected, but guarantee dilutes.
- Failure signatures:
  - Intervals all contain zero → Shapley signal too weak or λ over-regularized.
  - Coverage << 1-α on validation → exchangeability violated or kernel misspecified.
  - Selection oscillates wildly across similar inputs → quantile estimator unstable; increase λ or reduce kernel bandwidth.
- First 3 experiments:
  1. **Synthetic validation**: Replicate Section 5.1 with p=10, n=1000, known β; verify interval coverage on held-out test and confirm selection path matches Figure 2.
  2. **Ablation on split ratio**: Vary |I₁|/|I₂| ∈ {0.3, 0.5, 0.7}; measure coverage vs. interval width tradeoff.
  3. **Kernel sensitivity**: Test RBF vs. linear kernel on ADNI data; report how conditional p-values (Table 1) change across kernel choices.

## Open Questions the Paper Calls Out
None

## Limitations
- Computational scaling limits the approach to approximately 15 modalities without approximation techniques.
- Coverage guarantees depend critically on exchangeability assumptions that may fail under covariate shift.
- Near-optimality guarantees weaken substantially when modalities exhibit high dependence.

## Confidence
- **High confidence**: The mechanism linking Shapley values to predictive loss reduction and the basic split conformal framework are well-established in literature.
- **Medium confidence**: RKHS conditional quantile estimation performance depends heavily on kernel choice and regularization tuning, which were not extensively validated across diverse datasets.
- **Low confidence**: The theoretical near-optimality guarantees assume approximate independence conditions that are difficult to verify in practice.

## Next Checks
1. **Scalability test**: Implement approximate Shapley computation and benchmark against exact computation on p=20 synthetic data to quantify trade-offs in coverage and selection accuracy.
2. **Distribution shift robustness**: Evaluate coverage degradation under controlled covariate shift by mixing test data from different source distributions and measuring conditional coverage violation rates.
3. **Clinical generalization**: Apply the method to an independent multimodal Alzheimer's dataset with different imaging protocols to verify that identified clinically meaningful patterns replicate.