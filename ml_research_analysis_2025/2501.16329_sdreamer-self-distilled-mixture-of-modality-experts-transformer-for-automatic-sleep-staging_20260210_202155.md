---
ver: rpa2
title: 'sDREAMER: Self-distilled Mixture-of-Modality-Experts Transformer for Automatic
  Sleep Staging'
arxiv_id: '2501.16329'
source_url: https://arxiv.org/abs/2501.16329
tags:
- sleep
- epoch
- sequence
- mome
- staging
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces sDREAMER, a novel automatic sleep staging
  model designed to address two key challenges in the field: limited information interaction
  between modalities (EEG and EMG signals) and the lack of unified models that can
  handle different input sources (single-channel or multi-channel). To tackle these
  issues, sDREAMER employs a mixture-of-modality-experts (MoME) transformer architecture
  with three pathways for EEG, EMG, and mixed signals, featuring partially shared
  weights to promote cross-modality alignment.'
---

# sDREAMER: Self-distilled Mixture-of-Modality-Experts Transformer for Automatic Sleep Staging

## Quick Facts
- arXiv ID: 2501.16329
- Source URL: https://arxiv.org/abs/2501.16329
- Reference count: 40
- Primary result: Sequence sDREAMER achieves 91.72% accuracy and 87.64% F1-score on multi-channel sleep staging, outperforming existing transformer-based methods.

## Executive Summary
sDREAMER introduces a novel transformer architecture for automatic sleep staging that addresses key challenges in multi-modal signal processing. The model employs a mixture-of-modality-experts (MoME) design with three pathways for EEG, EMG, and mixed signals, featuring partially shared attention weights to promote cross-modality alignment. Through a self-distillation training scheme, sDREAMER enhances information interaction across modalities, enabling superior single-channel inference from models trained on multi-channel data. Experiments on a publicly available mice sleep dataset demonstrate state-of-the-art performance for both multi-channel and single-channel inference scenarios.

## Method Summary
sDREAMER uses a mixture-of-modality-experts transformer architecture with shared multi-head self-attention across three pathways (EEG, EMG, and mixed signals) while maintaining modality-specific feedforward networks. The model processes sleep signals through a hierarchical structure: epoch-level MoME encoders for fine-grained pattern capture, followed by sequence-level MoME transformers for temporal dependencies across epochs. A self-distillation training scheme transfers knowledge from the mixed pathway to unimodal pathways via KL-divergence with temperature scaling. The approach is evaluated on a mice sleep dataset with 16 subjects, achieving 91.72% accuracy and 87.64% F1-score in multi-channel settings.

## Key Results
- Sequence sDREAMER achieves 91.72% accuracy and 87.64% F1-score on multi-channel inference, outperforming existing transformer-based methods
- Single-channel inference remains competitive with specialized single-channel models after multi-channel training with self-distillation
- Self-distillation ablation shows significant performance drops: EMG accuracy drops from 83.78% to 7.85% without distillation
- Hierarchical sequence modeling consistently outperforms epoch-only approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Shared attention weights across modality-specific pathways enable cross-modality alignment without explicit supervision.
- Mechanism: The MoME transformer shares multi-head self-attention weights across EEG, EMG, and mixed pathways while keeping feedforward networks modality-specific. This forces the attention mechanism to learn representations that are semantically compatible across modalities, as the same attention function must process tokens from different modalities meaningfully.
- Core assumption: Semantic correspondence exists between temporal patterns in EEG and EMG signals for the same sleep stage.
- Evidence anchors: Abstract mentions "partially shared weights to promote cross-modality alignment"; Section IV-C states "attention weights are shared across the three paths" and "implicitly instruct our model to align across different modalities."

### Mechanism 2
- Claim: Self-distillation from a multi-modal "mix" pathway to unimodal pathways improves single-channel inference quality.
- Mechanism: During training, the mix pathway acts as a "teacher" whose soft predictions (via KL-divergence with temperature scaling) guide the EEG and EMG "student" pathways. This transfers richer cross-modal knowledge to unimodal representations, allowing them to approximate multi-modal performance when only one input is available at inference.
- Core assumption: The mix pathway learns a representation that subsumes or generalizes the information in individual modalities; soft labels carry transferable structural knowledge.
- Evidence anchors: Abstract mentions "self-distillation training scheme to enhance information interaction across modalities"; ablation shows removing self-distillation drops EEG-Acc from 88.12% to 62.71% and EMG-Acc from 83.78% to 7.85%.

### Mechanism 3
- Claim: Hierarchical sequence modeling (epoch encoder + sequence encoder) captures both intra-epoch fine-grained patterns and inter-epoch temporal dependencies.
- Mechanism: Sequence sDREAMER first processes each epoch through an epoch-level MoME encoder (1-second window), then passes the resulting [CLS] tokens to a sequence-level MoME transformer that models dependencies across epochs (e.g., sleep stage transitions).
- Core assumption: Sleep stage transitions follow temporal patterns (e.g., Wake → NREM → REM) that benefit from explicit sequence-level modeling.
- Evidence anchors: Section IV-E describes hierarchical context capture; Table I shows sequence models consistently outperform epoch-only models (Sequence sDREAMER 91.72% vs Epoch sDREAMER 88.25%).

## Foundational Learning

- **Multi-head Self-Attention (MSA)**
  - Why needed here: The MoME module relies on MSA to model temporal dependencies between tokens (patches of EEG/EMG signals). Understanding how attention weights determine token relevance is critical.
  - Quick check question: Given a sequence of tokens from an EEG epoch, how does MSA decide which patches are most relevant to the [CLS] token?

- **Knowledge Distillation (Soft Labels + Temperature)**
  - Why needed here: Self-distillation uses soft labels from the mix pathway to train unimodal pathways. Temperature scaling controls distribution smoothness, affecting what knowledge is transferred.
  - Quick check question: What happens to the distillation signal if temperature τ is too low (0.1) vs. too high (10)?

- **Mixture of Experts (MoE) / MoME**
  - Why needed here: The architecture routes inputs through modality-specific FFNs ("experts") while sharing attention—a form of conditional computation.
  - Quick check question: If input is EEG-only at inference, which FFN(s) are activated, and which MSA weights are used?

## Architecture Onboarding

- **Component map:**
  - Raw EEG/EMG signals -> Patch operator (non-overlapping windows) -> Linear embedding + positional/modality encodings -> MoME layers (shared MSA + modality-specific FFNs) -> Epoch encoder (for sequence model) -> Sequence encoder (for sequence model) -> Classification heads (one per pathway)

- **Critical path:**
  1. Raw EEG/EMG → Patching → Linear embedding + positional/modality encoding
  2. MoME layers: MSA (shared) → FFN (modality-specific) → repeat
  3. (Sequence model) Extract [CLS] tokens per epoch → Sequence MoME encoder
  4. Mix pathway [CLS] token → Classification head (primary prediction)
  5. Training: CE loss on mix prediction + KL-distillation loss between mix and unimodal predictions

- **Design tradeoffs:**
  - Shared attention vs. separate encoders: Shared weights enforce alignment and reduce parameters but risk modality interference
  - Mix pathway at epoch vs. sequence level: Paper disables mix at epoch level for Sequence sDREAMER to reduce noise and speed training, at cost of delayed cross-modal fusion
  - Distillation temperatures: τ_eeg=1.0, τ_emg=3.0; higher temperature smooths distributions more, potentially necessary for noisier EMG signals

- **Failure signatures:**
  - Single-channel collapse: If distillation removed/misconfigured, EMG-Acc can drop to ~8% (Table III). Check α and temperatures
  - No sequence benefit: If sequence length too short or epochs misaligned, sequence encoder adds noise. Verify epoch boundaries and window sizes
  - Cross-modal interference: If shared attention degrades performance vs. channel-independent baselines, consider reducing weight sharing or adding modality-specific adapters

- **First 3 experiments:**
  1. Reproduce multi-channel baseline: Train Epoch and Sequence sDREAMER on provided mouse dataset with EEG-EMG pairs; verify accuracy/F1 against Table I
  2. Ablate self-distillation: Set α=0, retrain, and compare single-channel inference to Table III to confirm mechanism contribution
  3. Test single-channel inference: After multi-channel training, evaluate on EEG-only and EMG-only test sets; verify competitiveness with single-channel baselines (Table II)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the model's performance improve when validated against datasets scored by multiple experts rather than a single expert?
- Basis in paper: The authors note in Section VI that the dataset is labeled by "one expert, who is well-trained but not perfect," and suggest the model "may show greater potential if the dataset is scored by more experts."
- Why unresolved: Current accuracy metrics reflect agreement with a single annotator, leaving the model's robustness against inter-rater variability and consensus ground truths untested.
- What evidence would resolve it: Re-evaluating the model on data labeled by a cohort of experts to compare performance against an inter-rater agreement baseline.

### Open Question 2
- Question: Can sDREAMER effectively replace human labor by outperforming newly trained students in sleep staging tasks?
- Basis in paper: Section VI proposes that "if the dataset is scored by two newly trained students, this experiment will show whether the model can outperform newly trained students and therefore replace human scoring."
- Why unresolved: The paper has not yet compared the model's accuracy against human novices, which is a critical benchmark for assessing the practical utility of automation in this field.
- What evidence would resolve it: A comparative study measuring the classification accuracy of the model versus human trainees on the same blind test set.

### Open Question 3
- Question: How does the sDREAMER framework perform when applied to human sleep staging, which involves more complex stage definitions (e.g., N1, N2, N3)?
- Basis in paper: The study is conducted exclusively on a mice dataset with three classes (Wake, SWS, REM), whereas human sleep staging typically requires distinguishing more stages with different electrophysiological characteristics.
- Why unresolved: The model's specific tuning for mice EEG/EMG signals and the MoME pathway design may not transfer directly to human polysomnography data without architectural adjustments.
- What evidence would resolve it: Training and evaluating the model on a standard human sleep dataset (e.g., Sleep-EDF) and reporting performance across the full AASM standard stages.

## Limitations

- Patch size W is not explicitly specified, though assumed to be 64 samples per patch, which directly affects token count and model capacity
- Temperature values for self-distillation (τ_eeg=1.0, τ_emg=3.0) are stated but justification is unclear—why different for each modality?
- Sequence length K=16 epochs is fixed; unclear if this was optimized or arbitrarily chosen
- EMG-only performance is extremely poor without self-distillation (7.85%), suggesting potential instability or weak EMG signal utility

## Confidence

- **High:** Multi-channel performance gains (91.72% accuracy, 87.64% F1) for Sequence sDREAMER; consistency with hierarchical sequence modeling benefits shown in related work
- **Medium:** Self-distillation effectiveness for single-channel inference; ablation results show large gains, but mechanism is novel and lacks strong external validation
- **Low:** Shared attention across modalities genuinely aligns EEG-EMG features; while claimed, evidence is indirect and the mechanism could instead cause interference

## Next Checks

1. **Patch size sensitivity analysis:** Systematically vary W (e.g., 32, 64, 128) and measure impact on accuracy and F1 to verify optimal token granularity
2. **Self-distillation ablation under noise:** Retrain without distillation and introduce synthetic noise to EMG/EEG; test if distillation still provides robustness gains
3. **Cross-modal alignment probing:** Train a variant with modality-specific attention (no shared weights) and compare performance; if performance drops, it supports the alignment hypothesis but if not, shared attention may be unnecessary