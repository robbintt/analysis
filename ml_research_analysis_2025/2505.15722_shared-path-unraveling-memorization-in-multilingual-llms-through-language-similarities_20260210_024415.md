---
ver: rpa2
title: 'Shared Path: Unraveling Memorization in Multilingual LLMs through Language
  Similarities'
arxiv_id: '2505.15722'
source_url: https://arxiv.org/abs/2505.15722
tags:
- memorization
- language
- extra
- languages
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces the first large-scale study of memorization\
  \ in multilingual large language models (MLLMs), examining 95 languages across diverse\
  \ model scales, architectures, and memorization definitions. The study challenges\
  \ the prevailing assumption that memorization is highly correlated with training\
  \ data availability, showing that among similar languages, those with fewer training\
  \ tokens often exhibit higher memorization\u2014a trend only evident when cross-lingual\
  \ relationships are explicitly modeled."
---

# Shared Path: Unraveling Memorization in Multilingual LLMs through Language Similarities

## Quick Facts
- **arXiv ID**: 2505.15722
- **Source URL**: https://arxiv.org/abs/2505.15722
- **Reference count**: 33
- **Primary result**: Among similar languages, those with fewer training tokens often exhibit higher memorization rates, a pattern only evident when cross-lingual relationships are explicitly modeled using graph-based correlation metrics.

## Executive Summary
This work introduces the first large-scale study of memorization in multilingual large language models (MLLMs), examining 95 languages across diverse model scales, architectures, and memorization definitions. The study challenges the prevailing assumption that memorization is highly correlated with training data availability, showing that among similar languages, those with fewer training tokens often exhibit higher memorization—a trend only evident when cross-lingual relationships are explicitly modeled. To capture these dynamics, the authors propose a novel graph-based correlation metric that incorporates language similarity, revealing interconnected memorization behaviors across related languages. Findings demonstrate that cross-lingual transferability plays a crucial role in shaping memorization patterns in MLLMs, with consistent trends observed across both decoder-only and encoder-decoder architectures.

## Method Summary
The study analyzes memorization across 95 languages using mC4 corpus filtered to 50,000 samples per language with CLD3 language identification. Language similarity is extracted from MLLM final layer embeddings using Flores+ parallel data, applying SVD-based language-specific subspace decomposition (Algorithm 1). A graph is constructed with threshold θ to represent language relationships, and memorization is evaluated using Exact Memorization (EM), Relaxed Memorization (RM), and Reconstruct Likelihood Memorization (PM) metrics at varying prompt lengths. The novel graph-based correlation coefficient ρG is computed using the graph Laplacian to measure how memorization and token counts co-vary across topologically connected languages, compared against baseline Pearson correlation.

## Key Results
- Among similar languages, those with fewer training tokens tend to exhibit higher memorization rates (inverse correlation emerges only with graph-based modeling).
- Graph-based correlation coefficient ρG reveals negative correlations (-0.24 to -0.56) that Pearson correlation misses, particularly in intra-topology analysis.
- Larger decoder-only models show stronger exact memorization (EM increases from 0.32% to 1.56% across scales), while encoder-decoder models show non-monotonic scaling behavior.
- Cross-lingual transferability is crucial: memorization patterns are interconnected across related languages rather than independent.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Among typologically similar languages, those with fewer training tokens exhibit higher memorization rates—a pattern that only emerges when cross-lingual relationships are explicitly modeled.
- **Mechanism**: MLLMs process languages in a joint embedding space where similar languages share lexical, morphological, and syntactic features. When a high-resource language (e.g., Turkish) is well-trained, its representations generalize to similar low-resource languages (e.g., Azerbaijani), but the low-resource language retains memorized content because it lacks sufficient data to form robust generalizations independently.
- **Core assumption**: Language similarity extracted from model embeddings reflects meaningful typological relationships that influence how memorization transfers.
- **Evidence anchors**: [abstract] "Our analysis reveals that among similar languages, those with fewer training tokens tend to exhibit higher memorization, a trend that only emerges when cross-lingual relationships are explicitly modeled"; [Section 6.2] Table 1 shows ρG accentuates negative correlation (-0.24 to -0.56) vs. Pearson r (-0.13 to -0.36) for MGPT-101.

### Mechanism 2
- **Claim**: Standard correlation metrics (Pearson) obscure memorization patterns in MLLMs by treating languages in isolation; graph-based metrics reveal structure-respecting relationships.
- **Mechanism**: The graph-based correlation coefficient ρG uses the graph Laplacian L to measure how two signals (memorization and token counts) co-vary across topologically connected languages. This captures whether both signals increase/decrease in tandem over similar languages, which flat metrics cannot detect.
- **Core assumption**: Memorization propagates across the language similarity graph in a structured manner that single-point correlations miss.
- **Evidence anchors**: [Section 4.2] Defines ρG = (m^T L t) / √[(m^T L m)(t^T L t)] bounded by Cauchy-Schwarz to [-1, 1]; [Section 6.3] Figure 4 shows intra-topo ρG grows increasingly negative (down to -0.6) while cross-topo correlations weaken.

### Mechanism 3
- **Claim**: Larger decoder-only models exhibit stronger exact memorization, but encoder-decoder models show non-monotonic scaling behavior.
- **Mechanism**: Decoder-only models (MGPT-1.3B → MGPT-13B) show scaling effects where larger capacity enables more exact reproduction. Encoder-decoder models (MT5) use span corruption objectives that may produce unstable completions at larger scales without fine-tuning, reducing measured memorization.
- **Core assumption**: Memorization measurement is architecture-dependent and reflects both model capacity and training objective.
- **Evidence anchors**: [Section 6.5] Table 4: EM increases from 0.32% (MGPT-1.3B) to 1.56% (MGPT-13B); MT5-LARGE shows lower EM than MT5-BASE.

## Foundational Learning

- **Concept**: Graph Laplacian and Signal Smoothness
  - **Why needed here**: The paper's core innovation uses graph Laplacian L to measure how memorization signals vary across the language similarity graph. Understanding x^T L x as smoothness and x^T L y as cross-smoothness is essential to interpret ρG.
  - **Quick check question**: Given a graph of 3 languages with edges (A-B, B-C), if memorization scores are [0.9, 0.5, 0.1] and token counts are [1M, 5M, 10M], would the graph cross-smoothness be positive or negative?

- **Concept**: Extractable vs. Discoverable Memorization
  - **Why needed here**: The paper adopts extractable memorization (reproducing training sequences from prefixes) as its primary definition. Distinguishing this from discoverable memorization (finding training data via prompting) clarifies the threat model.
  - **Quick check question**: If a model outputs a training sequence only when given a specific adversarial prompt (not a prefix from training data), is this extractable or discoverable memorization?

- **Concept**: Language-Specific vs. Language-Agnostic Embedding Subspaces
  - **Why needed here**: The paper extracts language-specific subspaces from MLLM embeddings using SVD decomposition (Algorithm 1) to compute similarity. This assumes embeddings decompose into shared and language-unique components.
  - **Quick check question**: Why would projecting embeddings onto a language-specific subspace (rather than using raw embeddings) improve similarity measurement for cross-lingual analysis?

## Architecture Onboarding

- **Component map**: Training Corpus (mC4) → Sample & Filter (CLD3 language ID, >600 chars) → Language Graph Construction ← Language Similarity Extraction (Flores+ parallel data → MLLM embeddings → Language-specific subspace → Cosine similarity) → Memorization Evaluation (EM/PM/RM metrics at varying prompt lengths) → Graph-based Correlation (ρG = intra-topo + cross-topo analysis)

- **Critical path**:
  1. Extract language representations from model's final layer using Flores+ (separate from training data).
  2. Apply Algorithm 1 to isolate language-specific subspaces; compute pairwise cosine similarities.
  3. Construct graph with threshold θ (controls sparsity; validate trends across multiple θ values).
  4. Compute ρG and partition into intra-topo (connected clusters) vs. cross-topo (disconnected groups).
  5. Compare against baseline Pearson correlation to isolate the contribution of language similarity modeling.

- **Design tradeoffs**:
  - **θ threshold selection**: Higher θ → sparser graph → more isolated nodes → harder interpretation; Lower θ → denser graph → may dilute true linguistic relationships. Paper validates across ranges (Tables 6-11).
  - **Prompt length**: Longer prompts increase memorization detection but may not reflect realistic extraction scenarios. Paper tests 35/85/135 tokens.
  - **Memorization metric choice**: EM is stringent but may miss partial memorization; PM captures probability but requires access to log-probabilities; RM (BLEU/Rouge) enables approximate matching.

- **Failure signatures**:
  - Positive Pearson correlation with negative ρG: Indicates hidden inverse relationships within language families that flat correlation misses (Table 2: MGPT-1.3B shows r=0.22 but ρG=-0.49 for EM).
  - High singleton count in graph: Language isolated due to low similarity to all others; consider lowering θ or excluding from analysis.
  - Inconsistent trends across metrics: May indicate model-specific instability (MT5-LARGE) or metric limitations.

- **First 3 experiments**:
  1. **Reproduce baseline correlation**: Compute Pearson r between per-language memorization rates (EM, PM) and token counts for MGPT-101; verify weak/negative correlations match Table 1.
  2. **Validate graph construction impact**: Run ρG analysis at θ = 0.35, 0.41, 0.45; confirm intra-topo correlations become increasingly negative while cross-topo weakens (Figure 4 pattern).
  3. **Test cross-architecture consistency**: Apply same pipeline to MT5-BASE and MGPT-101 (same training corpus); verify that ρG reveals consistent inverse patterns despite architectural differences.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How do fine-tuning and instruction tuning alter cross-lingual memorization dynamics compared to the pre-trained state?
- **Basis**: [Explicit] The authors explicitly state they "do not explore how fine-tuning or instruction tuning may alter memorization behavior" in the Limitations section.
- **Why unresolved**: The study is restricted to pre-trained models (mGPT, mT5); alignment or domain-specific tuning could suppress or exacerbate the cross-lingual transfer of memorized content.
- **Evidence to resolve it**: Apply the graph-based correlation metric (ρG) to models before and after instruction tuning to measure shifts in memorization leakage between similar languages.

### Open Question 2
- **Question**: What effective strategies can mitigate memorization in MLLMs while accounting for language similarity?
- **Basis**: [Explicit] The authors conclude by encouraging "further work... to develop effective strategies to mitigate memorization in MLLMs," specifically urging a shift toward "language-aware memorization audits."
- **Why unresolved**: Current deduplication methods often treat languages in isolation; the paper shows this is insufficient as similar languages share memorization pathways.
- **Evidence to resolve it**: Developing cross-lingual deduplication algorithms that utilize the language similarity graph and testing if they reduce the memorization rates in low-resource languages without degrading model performance.

### Open Question 3
- **Question**: Why do larger encoder-decoder models (e.g., mT5-LARGE) exhibit reduced memorization compared to smaller variants, unlike decoder-only models?
- **Basis**: [Inferred] The paper notes mT5-LARGE produces "broken completions" and has lower memorization than mT5-BASE, hypothesizing instability, but does not verify if this is a failure of generation or a successful generalization effect.
- **Why unresolved**: This anomaly contradicts the scaling laws observed in decoder-only models (GPT), and the root cause (architectural instability vs. robust unlearning) remains unidentified.
- **Evidence to resolve it**: A comparative analysis of attention head stability and gradient norms in mT5-LARGE versus mT5-BASE to determine if the drop in memorization stems from training dynamics or model capacity issues.

## Limitations

- The study is restricted to pre-trained models without exploring how fine-tuning or instruction tuning may alter memorization behavior.
- The graph-based correlation coefficient ρG is theoretically sound but lacks direct empirical validation beyond showing it produces different results than Pearson correlation.
- MT5-LARGE shows non-monotonic scaling behavior with lower EM than MT5-BASE despite larger scale, attributed to "broken completions" but without detailed analysis of this architectural-specific behavior.

## Confidence

- **High confidence**: Graph-based correlation reveals hidden patterns in memorization-language relationship that Pearson correlation misses. Supported by consistent ρG vs r discrepancies across multiple models and metrics (Tables 1-2).
- **Medium confidence**: Inverse correlation between training tokens and memorization among similar languages is real and requires cross-lingual modeling to detect. Evidence is consistent but the underlying mechanism remains partially speculative.
- **Low confidence**: Larger decoder-only models show stronger exact memorization due to scaling effects. While scaling trends exist, the encoder-decoder instability observation lacks sufficient corpus support for the stated mechanism.

## Next Checks

1. **Cross-lingual transfer causality test**: Design an experiment isolating high-resource language training effects on low-resource language memorization by training MLLMs with controlled data distributions and measuring memorization transfer across similar language pairs.
2. **Graph metric ablation study**: Systematically vary graph construction parameters (θ thresholds, node inclusion criteria) and validate whether ρG consistently reveals inverse correlations while Pearson r remains positive, establishing the metric's sensitivity to cross-lingual relationships.
3. **Architectural behavior validation**: For MT5 models, conduct detailed analysis of generated mask completions to quantify "broken completions" and determine whether this represents a fundamental architectural limitation or an artifact of the specific training/evaluation setup.