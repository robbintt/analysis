---
ver: rpa2
title: Fair Text Classification via Transferable Representations
arxiv_id: '2503.07691'
source_url: https://arxiv.org/abs/2503.07691
tags:
- fairness
- sensitive
- data
- representations
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for fair text classification using
  the Wasserstein Dependency Measure. The key idea is to minimize the dependence between
  representations learned for the target label and those for a sensitive attribute,
  inspired by adversarial training.
---

# Fair Text Classification via Transferable Representations

## Quick Facts
- arXiv ID: 2503.07691
- Source URL: https://arxiv.org/abs/2503.07691
- Reference count: 31
- Proposes fair text classification using Wasserstein Dependency Measure for adversarial training without requiring sensitive attributes in target data

## Executive Summary
This paper introduces Wasserstein Fair Classification (WFC), a method for fair text classification that minimizes the dependence between learned representations for the target label and those for a sensitive attribute. The approach uses a Wasserstein Dependency Measure to estimate and minimize this dependence, inspired by adversarial training. A key innovation is that the method works even when sensitive attributes are not available in the dataset being classified, by leveraging domain adaptation to transfer knowledge from related datasets. The method demonstrates competitive results on fairness metrics while maintaining comparable accuracy to state-of-the-art methods on two text classification datasets.

## Method Summary
The method works by minimizing the sum of a classification loss and a Wasserstein dependency loss that measures the dependence between representations learned for the target label and those for a sensitive attribute. The key innovation is the ability to perform fair classification even when sensitive attributes are unavailable in the target dataset, by pre-training a "Demonic" model on source data to predict sensitive attributes and then freezing it. The Wasserstein dependency is estimated using a Critic network trained with WGAN-style objectives. The approach combines elements of adversarial training, domain adaptation, and information-theoretic regularization to achieve fairness without sacrificing accuracy.

## Key Results
- Achieves competitive fairness metrics (1 - TPR-GAP) while maintaining accuracy comparable to state-of-the-art methods
- Demonstrates effectiveness in transfer learning scenarios where sensitive attributes are unavailable in target dataset
- Shows improvement over baseline methods on Bias in Bios (gender → occupation) and Moji (dialect → sentiment) datasets

## Why This Works (Mechanism)
The method works by explicitly minimizing the statistical dependence between representations used for the main classification task and those that could be used to predict sensitive attributes. By using the Wasserstein Dependency Measure, it provides a principled way to estimate and minimize this dependence, even when the sensitive attribute is not directly available in the target data. The adversarial training framework ensures that the model learns representations that are both discriminative for the main task and independent of sensitive attributes. The transfer learning component allows the model to leverage related datasets to learn about sensitive attributes even when they are absent from the target data.

## Foundational Learning
- **Wasserstein Dependency Measure**: A measure of statistical dependence based on optimal transport theory that provides a principled way to estimate the dependence between two random variables. Needed to quantify the relationship between label and sensitive attribute representations. Quick check: Verify that the Critic network converges to estimate the Wasserstein distance between distributions.
- **Adversarial training**: A training paradigm where a model learns to minimize a loss while simultaneously being penalized by an adversary that tries to maximize a different loss. Needed to learn representations that are both discriminative and fair. Quick check: Monitor the trade-off between classification accuracy and dependency measure during training.
- **Domain adaptation**: The process of adapting a model trained on one distribution to perform well on a different but related distribution. Needed to transfer knowledge about sensitive attributes from source to target domains. Quick check: Evaluate performance when sensitive attributes are available vs. unavailable in target data.

## Architecture Onboarding

**Component map**: BERT Embeddings -> Demonic MLP -> Z_a/Z_y -> Classifier & Critic -> Output

**Critical path**: Frozen embeddings → Demonic MLP (frozen) → Classifier (main task) + Critic (dependency estimation) → Fair predictions

**Design tradeoffs**: Uses frozen pre-trained embeddings to avoid training BERT from scratch, but this limits the method to domains where such embeddings are available and effective. The adversarial framework provides theoretical guarantees but requires careful tuning of hyperparameters.

**Failure signatures**: 
- Accuracy collapse when beta is too high
- Fairness improvements don't materialize when Demonic MLP fails to learn sensitive attributes
- Critic instability leading to exploding or vanishing Wasserstein estimates

**3 first experiments**:
1. Train Demonic MLP on source data and verify it achieves >90% accuracy on sensitive attribute prediction before freezing
2. Run WFC with beta=1.0 and monitor both classification accuracy and Wasserstein dependency measure on validation set
3. Compare fairness metrics (TPR-GAP) with and without the Wasserstein regularization term

## Open Questions the Paper Calls Out
- Does the theoretical bound for Wasserstein Fair Classification hold under prior probability shift assumption rather than covariate shift assumption?
- Is the optimal softmax temperature derived in Theorem 5 a requirement for the method's validity or merely an artifact of the proof technique?
- To what extent does the theoretically derived softmax temperature impact model calibration?

## Limitations
- Relies heavily on quality of frozen pre-trained embeddings, limiting applicability to domains where such embeddings are unavailable
- Effectiveness when sensitive attributes are unavailable depends on assumption that related datasets with both labels and sensitive attributes exist
- Limited analysis of failure cases or robustness to distribution shifts between source and target domains

## Confidence
- **High confidence**: Basic training procedure and use of Wasserstein Dependency Measure are well-specified and reproducible
- **Medium confidence**: Claims about competitive fairness-accuracy trade-offs are supported by experimental results
- **Low confidence**: Claims about effectiveness in truly unsupervised settings are difficult to fully verify without access to exact cross-domain datasets

## Next Checks
1. Test the method with multiple different frozen embedding sources (RoBERTa, DistilBERT) to assess robustness to embedding choice
2. Perform ablation study on Demonic pre-training by evaluating performance with random weights vs. varying proportions of source data
3. Systematically test transfer performance across multiple source-target domain pairs to quantify effectiveness when sensitive attributes are unavailable in target dataset