---
ver: rpa2
title: 'FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure
  Ulcer Severity Classification with Reasoning'
arxiv_id: '2510.24980'
source_url: https://arxiv.org/abs/2510.24980
tags:
- ft-arm
- stage
- pressure
- wound
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces FT-ARM, a multimodal large language model
  that combines fine-tuning and agentic self-reflection to classify pressure ulcer
  severity (Stages I-IV) with clinically grounded explanations. FT-ARM fine-tunes
  a LLaMA 3.2 90B model using LoRA and iteratively refines predictions via a two-stage
  generator-critic loop.
---

# FT-ARM: Fine-Tuned Agentic Reflection Multimodal Language Model for Pressure Ulcer Severity Classification with Reasoning

## Quick Facts
- **arXiv ID:** 2510.24980
- **Source URL:** https://arxiv.org/abs/2510.24980
- **Reference count:** 40
- **Primary result:** Achieved 85.2% accuracy and 0.85 F1-score on pressure ulcer staging, surpassing CNN/ViT baselines.

## Executive Summary
This study introduces FT-ARM, a multimodal large language model that combines fine-tuning and agentic self-reflection to classify pressure ulcer severity (Stages I-IV) with clinically grounded explanations. FT-ARM fine-tunes a LLaMA 3.2 90B model using LoRA and iteratively refines predictions via a two-stage generator-critic loop. Evaluated on the PIID dataset, FT-ARM achieved 85.2% accuracy and 0.85 F1-score, surpassing prior CNN and ViT baselines (best 81.5%). A wound care nurse validated that 93% of its correct-stage rationales were clinically meaningful (35% "Good," 58% "Passable"), with higher agreement in advanced stages. FT-ARM enhances both accuracy and interpretability, addressing critical needs for transparent, reliable AI support in wound assessment.

## Method Summary
FT-ARM employs a two-stage fine-tuning approach using LoRA to adapt LLaMA 3.2 90B for pressure ulcer staging. The model is fine-tuned with AdamW optimizer (LR=2e-5, cosine decay) for 20 epochs on the PIID dataset. The Agentic Reflection Mechanism (ARM) implements a generator-critic loop where the fine-tuned model produces initial predictions, a critic LLM evaluates for consistency and errors, and the generator refines its output. The final rationale is generated by the unmodified base model to ensure quality explanations. The system uses 5-fold stratified cross-validation on 1,091 images (299Ã—299 px) and decouples classification (fine-tuned) from explanation (base model).

## Key Results
- Achieved 85.2% accuracy and 0.85 F1-score on PIID dataset, surpassing CNN/ViT baselines.
- 93% of rationales for correct-stage predictions were clinically meaningful (35% "Good," 58% "Passable").
- ARM loop showed marginal accuracy improvement (0.84 to 0.85) over fine-tuning alone.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning with LoRA enables domain-specific adaptation of a general MLLM for pressure ulcer staging.
- Mechanism: Low-Rank Adaptation (LoRA) freezes pre-trained model weights and inserts small, trainable rank decomposition matrices into selected layers, allowing the model to learn domain-specific features from the limited PIID dataset without catastrophic forgetting.
- Core assumption: The pre-trained MLLM has sufficient visual and linguistic knowledge to be adapted to this task, and the limited dataset is representative of the target domain.
- Evidence anchors:
  - [abstract] "FT-ARM fine-tunes a LLaMA 3.2 90B model using LoRA..."
  - [Section 4.4.1] "LoRA is a parameter-efficient fine-tuning method that inserts trainable low-rank matrices into selected layers of a frozen pre-trained model..."
- Break condition: The pre-trained model lacks fundamental medical image understanding capabilities, or the fine-tuning data is so small or biased that LoRA cannot generalize.

### Mechanism 2
- Claim: The Agentic Reflection Mechanism (ARM) improves classification accuracy by iteratively refining predictions through a generator-critic loop.
- Mechanism: A generator LLM produces an initial prediction and rationale. A critique LLM evaluates the initial output for consistency, clinical plausibility, and completeness, providing feedback. The generator then revises its prediction based on the critique, mimicking a clinician's double-check process.
- Core assumption: The critique LLM can identify errors or inconsistencies in the generator's output and provide useful feedback, and the generator can incorporate this feedback effectively.
- Evidence anchors:
  - [abstract] "...iteratively refines predictions via a two-stage generator-critic loop."
  - [Section 4.3] "The critique LLM reviews the reasoning, checks the visual features, and suggests corrections if inconsistencies, errors, or oversights are detected."
- Break condition: The critique LLM is as error-prone as the generator, leading to reinforcement of incorrect predictions, or the generator fails to adapt based on the critique.

### Mechanism 3
- Claim: Decoupled inference (fine-tuned model for classification, base model for rationale) preserves both predictive accuracy and interpretability.
- Mechanism: The fine-tuned model, optimized for classification, predicts the stage. This predicted stage is then fed, along with the image, to the unmodified base MLLM, which retains its strong generative capabilities, to produce the explanatory rationale.
- Core assumption: The fine-tuning process degrades the model's general reasoning/generative abilities but enhances its classification accuracy. The base model has sufficient domain knowledge to generate a coherent rationale when given the correct label.
- Evidence anchors:
  - [Section 4.4.2] "...fine-tuned multimodal LLM often predicted only the PU class label without providing explanatory reasoning... the fine-tuned FT-LLM is first used to predict... The base model generates the clinical rationale..."
- Break condition: The base model, without fine-tuning, lacks the specific clinical knowledge to generate accurate rationales even when given the correct label, or the fine-tuned classifier is so specialized it produces labels that are technically correct but semantically alien to the base model.

## Foundational Learning

- **Concept: Low-Rank Adaptation (LoRA)**
  - Why needed here: To adapt a massive 90B parameter model with limited GPU memory and a small dataset. Standard fine-tuning is computationally infeasible.
  - Quick check question: Can you explain why LoRA prevents "catastrophic forgetting" of the pre-trained knowledge better than full fine-tuning?

- **Concept: Self-Refine / Critic-in-the-loop**
  - Why needed here: To act as an internal error-correcting mechanism. The model generates a solution, then evaluates it, then refines it. This is the core of the ARM component.
  - Quick check question: What is the primary risk of a self-reflection loop in an LLM (hint: think about error reinforcement)?

- **Concept: Multimodal Large Language Models (MLLMs)**
  - Why needed here: The task requires both visual analysis (wound image) and linguistic output (stage + rationale). An MLLM fuses these modalities.
  - Quick check question: How does an MLLM typically align image and text modalities (e.g., via projection-based or fusion-based connectors)?

## Architecture Onboarding

- **Component map:**
  1. Backbone MLLM (LLaMA 3.2 90B) -> LoRA Adapters -> Generator Module -> Critic Module -> Rationale Generator (Base MLLM)

- **Critical path:**
  1. Input (Image + Text Prompt) -> Fine-tuned MLLM -> Initial Stage Prediction
  2. Initial Prediction + Image -> Critic MLLM -> Critique/Feedback
  3. Feedback + Initial Prediction -> Fine-tuned MLLM -> Refined Stage Prediction (loop up to N times)
  4. Final Stage + Image -> Base (unmodified) MLLM -> Final Rationale

- **Design tradeoffs:**
  - **Classification vs. Reasoning:** The paper explicitly trades off end-to-end rationale generation from the fine-tuned model for a two-step process to ensure the rationale is high-quality.
  - **Accuracy vs. Latency:** The ARM loop adds significant inference time (paper notes ~3x increase). This must be acceptable for the deployment context (likely non-acute wound assessment).
  - **Model Size vs. Accessibility:** A 90B model requires significant GPU resources, limiting deployment options despite LoRA's efficiency.

- **Failure signatures:**
  - **Reinforced Hallucination:** The Critic agrees with an incorrect Generator prediction, making the final output confidently wrong.
  - **Empty Rationale:** The fine-tuned model fails to predict a class that the base model can understand, or the hand-off between models fails.
  - **Loop Oscillation:** The prediction flips back and forth between stages in each iteration (e.g., Stage III -> Stage IV -> Stage III).

- **First 3 experiments:**
  1. **Ablation Study (FT vs. ARM):** Re-run the evaluation with Fine-Tuning only (no reflection) and with Reflection only (no fine-tuning) on a validation set. Compare accuracy to the full FT-ARM model to confirm the contribution of each component.
  2. **Reflection Iteration Sweep:** Measure accuracy and inference time with N=0, 1, 2, 3, 4 reflection iterations. Determine the point of diminishing returns.
  3. **Cross-Dataset Validation:** Test the fine-tuned LoRA adapter on a small, separate validation set of wound images to probe for overfitting.

## Open Questions the Paper Calls Out

- **Open Question 1:** Does FT-ARM maintain high performance when classifying "unstageable" wounds or deep tissue injuries on external datasets from diverse clinical settings?
  - Basis in paper: The authors state in the Future Work section that they "plan to validate FT-ARM on additional external datasets... including images showing less common categories such as unstageable or deep tissue injuries."
  - Why unresolved: The current study was restricted to the PIID dataset, which only contains Stages I-IV, limiting knowledge of the model's behavior on "unstageable" wounds or data distribution shifts from other hospitals.
  - What evidence would resolve it: Evaluation metrics (accuracy, F1-score) and confusion matrices generated from multi-institutional datasets that explicitly include "unstageable" and deep tissue injury categories.

- **Open Question 2:** Does the integration of external clinical context (e.g., nursing notes, patient history) or formal guidelines via RAG significantly enhance FT-ARM's staging accuracy?
  - Basis in paper: The authors "plan to explore the integration of clinical context such as nursing clinical notes or patient history" and noted they deferred "exploring that direction" regarding Retrieval Augmented Generation (RAG) for the Critic LLM.
  - Why unresolved: The reported experiments utilized only images and task prompts; the optional "clinical note" input was supported by the architecture but not used in the evaluation, and the Critic LLM relied solely on internal reasoning without external guidelines.
  - What evidence would resolve it: An ablation study comparing the baseline FT-ARM against versions augmented with textual clinical notes and RAG-retrieved guidelines, measured by classification accuracy and rationale consistency.

- **Open Question 3:** To what extent does FT-ARM's explanatory output influence clinician diagnostic accuracy and workflow efficiency compared to standard care?
  - Basis in paper: The authors propose to "conduct human-in-the-loop evaluations... to assess not only the model's predictive performance... but also the practical utility of the rationale... and their influence on clinician decision-making."
  - Why unresolved: The current validation involved a single nurse rating rationales retrospectively; it did not measure if the tool actually improves staging accuracy for clinicians or fits into live workflows.
  - What evidence would resolve it: Results from a clinical user study (e.g., randomized controlled trial) measuring diagnostic concordance with experts and time-to-diagnosis for clinicians using FT-ARM versus a control group.

## Limitations

- The reflection loop mechanism, while conceptually sound, lacks quantitative evaluation of its contribution beyond the stated 85.2% accuracy (Medium confidence).
- The decoupled inference strategy (fine-tuned for classification, base for rationale) is empirically motivated but not thoroughly tested for potential label mismatch risks (Low confidence).
- Generalizability beyond PIID is acknowledged but not experimentally addressed, raising concerns about performance on different imaging conditions or wound types (Low confidence).

## Confidence

- **High confidence:** Fine-tuning with LoRA is a well-established, parameter-efficient method for domain adaptation, and the reported accuracy surpasses prior CNN/ViT baselines.
- **Medium confidence:** The ARM loop's iterative refinement improves accuracy compared to fine-tuning alone (0.84 to 0.85), but the marginal gain is small and the risk of hallucination feedback is not quantified.
- **Low confidence:** The rationale generation quality relies heavily on the base model's capabilities, and the 93% clinician agreement may be inflated due to the base model's access to the correct label.

## Next Checks

1. **Reflection Iteration Analysis:** Re-run the evaluation with N=0, 1, 2, 3 reflection iterations to quantify accuracy gains, identify oscillation risk, and determine optimal iteration count.
2. **Cross-Dataset Stress Test:** Evaluate the fine-tuned LoRA adapter on a small, separate validation set of wound images from a different source to probe for overfitting and assess generalizability.
3. **Prompt Ablation Study:** Test alternative system prompts for the Critic stage to measure the sensitivity of the ARM loop to prompt engineering and identify potential failure modes.