---
ver: rpa2
title: 'AlignPxtr: Aligning Predicted Behavior Distributions for Bias-Free Video Recommendations'
arxiv_id: '2503.06920'
source_url: https://arxiv.org/abs/2503.06920
tags:
- user
- bias
- video
- time
- interest
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of bias in video recommendation
  systems, where user behaviors like watch time and likes are influenced by confounding
  factors such as video duration, demographics, and content category preferences.
  The authors propose a novel framework that aligns predicted behavior distributions
  across different bias conditions using quantile mapping to decouple true user interest
  from these biases.
---

# AlignPxtr: Aligning Predicted Behavior Distributions for Bias-Free Video Recommendations

## Quick Facts
- **arXiv ID:** 2503.06920
- **Source URL:** https://arxiv.org/abs/2503.06920
- **Reference count:** 40
- **Primary result:** Online A/B tests show significant lift in user engagement metrics (active days +0.267%, app usage time +1.102%) by removing bias from video recommendations.

## Executive Summary
This paper addresses the pervasive issue of bias in video recommendation systems, where observed user behaviors like watch time and likes are distorted by confounding factors such as video duration, demographics, and content categories. The authors propose AlignPxtr, a novel framework that aligns predicted behavior distributions across different bias conditions using quantile mapping to theoretically guarantee zero mutual information between bias variables and user interest scores. The method models the causal relationships between user interest, bias factors, and observed behaviors, effectively decoupling true user preferences from systematic biases. Online A/B testing on Kuaishou Lite and Kuaishou demonstrated substantial improvements in user engagement metrics, with the approach also offering a computationally efficient mean alignment alternative for practical real-time inference in large-scale systems.

## Method Summary
AlignPxtr decouples true user interest from bias factors in video recommendations by enforcing distributional invariance across bias conditions. The method first trains a standard recommendation model to predict behaviors (watch time, likes) and obtain latent predictions. It then estimates conditional statistics (mean or CDF) of these predictions given bias factors like video duration or user demographics. During inference, predictions are transformed using either mean alignment (subtracting the conditional mean) or quantile mapping (applying the conditional CDF), which theoretically guarantees zero mutual information between the final score and bias variables. This approach handles both continuous and discrete behavioral signals while addressing multiple bias dimensions simultaneously, with mean alignment providing a computationally efficient approximation when full distribution alignment is impractical.

## Key Results
- Online A/B tests on Kuaishou Lite showed 0.267% lift in active days and 1.102% lift in average app usage time
- Kuaishou platform achieved 0.115% lift in active days and 0.131% lift in app usage time
- The method provides theoretical guarantee of zero mutual information between bias variables and user interest scores

## Why This Works (Mechanism)

### Mechanism 1: Causal Decoupling via Independence Assumption
The paper posits that user interest ($Z$) and bias factors ($Y$) are independent root causes in a Structural Causal Model. By enforcing that the conditional distribution of output scores given bias is invariant ($p(z|y) = p(z)$), the method theoretically reduces mutual information $I(Y; Z)$ to zero. This breaks the link between observed behaviors and confounding bias factors.

### Mechanism 2: Quantile Normalization (Probability Integral Transform)
By calculating the conditional CDF value $F_{X|Y=y}(x)$ for a prediction $x$, the resulting quantile follows a uniform distribution regardless of the specific bias condition. This normalizes different bias conditions onto a common statistical scale, effectively erasing distributional biases.

### Mechanism 3: First-Order Bias Removal (Mean Alignment)
This computationally efficient approach centers behavior distributions for each bias condition by subtracting the conditional expectation ($z = x - E[X|Y=y]$). While it doesn't guarantee complete independence, it removes the primary effect of bias by eliminating location shifts in the distribution.

## Foundational Learning

- **Concept: Mutual Information (MI)**
  - **Why needed here:** The paper uses $I(Y; Z) = 0$ as the theoretical goal for "perfect" debiasing. Understanding MI is required to interpret why distribution alignment guarantees independence.
  - **Quick check question:** If $Z$ is independent of $Y$, what is the value of $I(Y; Z)$?

- **Concept: Probability Integral Transform**
  - **Why needed here:** This is the mathematical engine of the proposed method. It explains why applying a CDF to a variable results in a Uniform distribution.
  - **Quick check question:** If $X \sim \mathcal{N}(\mu, \sigma^2)$ and you apply the CDF of $X$ to $X$ itself, what is the resulting distribution?

- **Concept: Structural Causal Models (SCMs)**
  - **Why needed here:** The paper models recommendation as a causal graph ($Y \to X \leftarrow Z$). Understanding "confounders" and "root causes" is necessary to follow the problem formulation.
  - **Quick check question:** In the paper's graph, does $Y$ cause $Z$, or are they independent root causes?

## Architecture Onboarding

- **Component map:** Behavior Model -> Bias Statistics Module -> Alignment Layer
- **Critical path:** The estimation of conditional statistics ($F_{X|Y}$ or $E[X|Y]$). If this module has high variance or errors due to sparse data, the alignment will inject noise into the final ranking score.
- **Design tradeoffs:**
  - **Quantile Mapping:** High accuracy, theoretically guaranteed independence. *Cons:* Computationally expensive, requires storing/estimating full distributions, sensitive to sparse bins.
  - **Mean Alignment:** Fast, low memory overhead. *Cons:* Does not guarantee full independence (only removes first-order bias), may fail if bias affects variance.
- **Failure signatures:**
  - **Cold Start/Bias Sparsity:** Over-correction where popular/biased items receive erratic scores because their conditional distribution statistics are estimated from too few samples.
  - **Inverse Transform Artifacts:** If mapping back to a domain-specific distribution is used, heavy tails in the target distribution can amplify small quantile errors.
- **First 3 experiments:**
  1. **Metric Validation:** Verify that the resulting score $Z$ has near-zero correlation with bias variables $Y$ (e.g., plot $Z$ vs. Video Duration to ensure the linear relationship is gone).
  2. **Ablation (Mean vs. Quantile):** Compare offline ranking performance (AUC/NDCG) using Mean Alignment vs. Quantile Mapping to determine if the theoretical guarantee of Quantile Mapping translates to practical gains.
  3. **Slice Analysis:** Evaluate performance specifically on "heavy bias" slices (e.g., very short vs. very long videos) to ensure the model isn't just optimizing for the average duration.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Under what real-world conditions does the fundamental hypothesis that user interest ($Z$) and bias factors ($Y$) are independent fail, and how does this violation affect the accuracy of the interest scores?
- **Basis in paper:** The authors state, "In this paper, we hypothesize that biases and user interest are independent of each other," serving as the theoretical foundation for their causal framework.
- **Why unresolved:** The paper relies on this assumption to prove that mutual information between $Z$ and $Y$ is zero, but it does not empirically validate this independence or analyze the consequences if user interest is intrinsically correlated with bias factors (e.g., users interested in "long-form documentaries" having a genuine preference correlation with duration).
- **What evidence would resolve it:** An analysis of performance on datasets where the independence assumption is known to be violated, or sensitivity testing showing the magnitude of error introduced by correlated interest and bias variables.

### Open Question 2
- **Question:** How does the computationally efficient Mean Alignment technique compare to full Quantile Mapping in mitigating bias when behavioral distributions exhibit high skewness or heavy tails?
- **Basis in paper:** The authors note that Mean Alignment "does not fully align the entire conditional distributions (and thus does not guarantee complete independence)," implying potential performance gaps on non-symmetric distributions.
- **Why unresolved:** While the paper demonstrates that Mean Alignment offers a favorable trade-off for computational efficiency, it does not explicitly characterize the specific distributional shapes where the mean-based approximation fails to capture the bias compared to quantile mapping.
- **What evidence would resolve it:** A comparative ablation study on segments of the user population with highly skewed behavior distributions, evaluating the residual bias of Mean Alignment versus Quantile Mapping.

### Open Question 3
- **Question:** To what extent does the accuracy of the conditional distribution estimation ($F_{X|Y}$) degrade in sparse data regimes, such as for cold-start users or niche bias categories?
- **Basis in paper:** The authors mention that estimating the full conditional distribution is "computationally challenging due to limited samples," which motivated the introduction of Mean Alignment.
- **Why unresolved:** The paper validates the approach on "major video platforms" with massive datasets but does not investigate the robustness of the Quantile Mapping approach when sample sizes for specific bias conditions $Y$ are insufficient to form a reliable empirical distribution.
- **What evidence would resolve it:** Performance metrics (e.g., AUC or calibration error) stratified by user activity level or item frequency, specifically comparing the stability of AlignPxtr for low-activity vs. high-activity users.

## Limitations
- The core causal independence assumption may fail if user interest is actually correlated with bias factors, potentially removing genuine preference signals
- Quantile mapping scalability is unproven in extremely high-cardinality bias spaces with granular demographics
- Method robustness to distribution shift between training and serving conditions is not fully characterized

## Confidence
- **High Confidence:** Theoretical guarantees of quantile mapping and experimental results showing lift in business metrics are well-supported
- **Medium Confidence:** Effectiveness of mean alignment as a practical approximation and handling of multiple simultaneous bias dimensions are supported but lack theoretical guarantees
- **Low Confidence:** Independence assumption itself and method behavior in cold-start scenarios with sparse bias statistics require further empirical validation

## Next Checks
1. **Independence Assumption Test:** Conduct correlation analysis between bias variables and post-alignment scores to verify the method is not removing genuine preference signals, particularly for extreme bias values.

2. **Multi-Bias Stress Test:** Design experiments that systematically introduce combinations of bias factors to evaluate whether the method maintains theoretical guarantees when multiple biases interact simultaneously.

3. **Cold Start Robustness:** Evaluate model performance on items with sparse bias statistics by comparing aligned vs. raw scores, and test whether confidence thresholds or smoothing mechanisms are needed to prevent over-correction artifacts.