---
ver: rpa2
title: Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation
  Models
arxiv_id: '2506.21826'
source_url: https://arxiv.org/abs/2506.21826
tags:
- segmentation
- historical
- maps
- foundation
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of segmenting historical maps,
  which have diverse visual representations and limited annotated data. The authors
  propose a simple yet effective approach that leverages the rich semantic embeddings
  of large vision foundation models combined with parameter-efficient fine-tuning.
---

# Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models

## Quick Facts
- **arXiv ID**: 2506.21826
- **Source URL**: https://arxiv.org/abs/2506.21826
- **Reference count**: 39
- **Primary result**: State-of-the-art few-shot historical map segmentation using vision foundation models with linear probing, achieving significant improvements in mIoU and Panoptic Quality across multiple benchmarks

## Executive Summary
This paper addresses the challenge of segmenting historical maps, which have diverse visual representations and limited annotated data. The authors propose a simple yet effective approach that leverages the rich semantic embeddings of large vision foundation models combined with parameter-efficient fine-tuning. Their method outperforms the state-of-the-art on the Siegfried benchmark dataset, achieving +5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20% in the more challenging 5-shot setting. On the ICDAR 2021 competition dataset, it attains a mean PQ of 67.3% for building block segmentation, despite not being optimized for this shape-sensitive metric. The approach maintains high performance even in extremely low-data regimes (10- & 5-shot) while requiring only 689k trainable parameters - just 0.21% of the total model size.

## Method Summary
The authors propose a parameter-efficient few-shot segmentation approach for historical maps that leverages vision foundation models through linear probing. The method extracts rich semantic embeddings from frozen foundation models and fine-tunes only a small linear classification head. They employ Dynamic Ratio-based Activation (DoRA) for parameter-efficient fine-tuning, which modifies only the scale of activation in the adapter layer while keeping the bias unchanged. This approach is tested in 10-shot and 5-shot scenarios on the Siegfried benchmark and ICDAR 2021 competition datasets, using data augmentation strategies including D4-dihedral transformations and standard augmentations like cropping and flipping.

## Key Results
- Achieves +5% and +13% relative improvements in mIoU over state-of-the-art in 10-shot scenarios on Siegfried benchmark
- Demonstrates approximately +20% improvement in the more challenging 5-shot setting
- Attains mean Panoptic Quality (PQ) of 67.3% for building block segmentation on ICDAR 2021 dataset
- Maintains high performance with only 689k trainable parameters (0.21% of total model size)

## Why This Works (Mechanism)
The approach leverages the rich, pre-trained semantic representations from large vision foundation models, which have learned general visual concepts from massive datasets. By freezing these models and only fine-tuning a small linear classification head, the method preserves the valuable semantic knowledge while adapting to the specific task with minimal data. The Dynamic Ratio-based Activation (DoRA) technique further enhances parameter efficiency by modifying only activation scales rather than adding new parameters, allowing the model to learn task-specific representations without overfitting in low-data regimes.

## Foundational Learning
- **Vision Foundation Models**: Pre-trained models on large-scale datasets that provide rich semantic embeddings
  - *Why needed*: Historical maps have diverse visual representations that require strong prior knowledge
  - *Quick check*: Verify the model can extract meaningful features from historical map patches

- **Few-Shot Learning**: Learning paradigms where models are trained with minimal annotated examples (5-10 samples)
  - *Why needed*: Annotated historical maps are scarce and expensive to obtain
  - *Quick check*: Ensure the method maintains performance with limited training data

- **Parameter-Efficient Fine-Tuning**: Techniques that adapt large models with minimal trainable parameters
  - *Why needed*: Prevents overfitting and reduces computational costs in low-data scenarios
  - *Quick check*: Confirm only the linear head and DoRA parameters are updated during training

- **Dynamic Ratio-based Activation (DoRA)**: Parameter-efficient fine-tuning method that modifies activation scales while preserving biases
  - *Why needed*: Provides better performance than traditional adapter-based methods
  - *Quick check*: Verify DoRA parameters are correctly initialized and updated

- **Panoptic Quality (PQ)**: Metric combining segmentation quality and recognition quality for comprehensive evaluation
  - *Why needed*: Historical map segmentation requires both accurate boundaries and correct class identification
  - *Quick check*: Calculate PQ alongside IoU to ensure balanced evaluation

## Architecture Onboarding

**Component Map**: Vision Foundation Model -> Feature Extraction -> DoRA Adapter -> Linear Probe -> Segmentation Output

**Critical Path**: The critical path flows from the frozen vision foundation model through the DoRA adapter to the linear probe head, where only these components are trainable.

**Design Tradeoffs**: 
- Freezing foundation models preserves rich semantic knowledge but limits task-specific adaptation
- Linear probing offers simplicity and efficiency but may miss complex spatial relationships
- DoRA provides parameter efficiency but may constrain the model's capacity to learn novel patterns

**Failure Signatures**: 
- Poor performance on shape-sensitive tasks (low PQ despite high IoU)
- High variance in low-shot scenarios, particularly for complex classes like vineyards
- Limited generalization to maps with significantly different visual styles or degradation levels

**First 3 Experiments**:
1. Baseline comparison: Test frozen foundation model without any fine-tuning on 5-shot scenario
2. Linear probe ablation: Compare linear probing against full fine-tuning in 10-shot setting
3. Parameter efficiency test: Measure performance degradation when reducing trainable parameters below 689k

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Does test-time fine-tuning using nearest neighbor examples improve performance in extremely low-data regimes (1-shot)?
- Basis in paper: The conclusion explicitly suggests exploring "test-time fine-tuning with the nearest neighbor example" as a direction for future work.
- Why unresolved: The current methodology relies on fixed parameter-efficient fine-tuning (DoRA) without adapting the model weights during inference based on specific test samples.
- What evidence would resolve it: Experiments comparing standard inference against test-time adaptation in 1-shot scenarios, showing statistically significant IoU improvements.

### Open Question 2
- Question: Can test-time augmentation (TTA) mitigate the performance fluctuations observed in the 5-shot vineyard segmentation task?
- Basis in paper: The authors list "incorporate test-time augmentation techniques" as a specific proposal for future work to address performance variances.
- Why unresolved: While the paper notes fluctuations in vineyards (likely due to sample quality), it relies solely on training-time augmentations (D4-dihedral).
- What evidence would resolve it: Ablation studies applying TTA to the 5-shot vineyard model, resulting in reduced variance and higher mean IoU scores.

### Open Question 3
- Question: Would optimizing the linear probing head specifically for shape-sensitive metrics improve the Panoptic Quality (PQ) on the ICDAR 2021 dataset?
- Basis in paper: The authors report a strong PQ of 67.3% but highlight that the model was "not optimized for this shape-sensitive metric."
- Why unresolved: The current architecture uses a simple pixel-wise linear classifier which may not enforce the topological consistency required for high Panoptic Quality.
- What evidence would resolve it: Replacing the linear probe with a shape-aware decoder or adding a topology-preserving loss, resulting in a measurable increase in the PQ score compared to the baseline.

## Limitations
- Evaluation limited to specific benchmark datasets (Siegfried and ICDAR 2021) which may not represent full diversity of historical maps
- Performance drop in extremely low-data scenarios (1-shot) was not explored in detail
- Approach effectiveness on maps with varying quality, degradation levels, or unconventional layouts remains untested

## Confidence
- **High confidence**: The experimental results on the Siegfried benchmark and ICDAR 2021 dataset are reproducible and well-documented, with clear performance improvements over baselines.
- **Medium confidence**: The generalizability of the approach to diverse historical map collections and its robustness to varying image qualities require further validation.
- **Medium confidence**: The claimed advantages of linear probing over full fine-tuning are convincing but would benefit from additional comparative analysis with other parameter-efficient methods.

## Next Checks
1. Test the approach on a broader range of historical map datasets, including those with varying levels of degradation, different time periods, and diverse cartographic styles.
2. Conduct an ablation study comparing linear probing with other parameter-efficient fine-tuning methods (e.g., adapters, LoRA) to establish relative computational and performance trade-offs.
3. Evaluate the model's performance in the extreme 1-shot scenario to assess its robustness in ultra-low-data regimes.