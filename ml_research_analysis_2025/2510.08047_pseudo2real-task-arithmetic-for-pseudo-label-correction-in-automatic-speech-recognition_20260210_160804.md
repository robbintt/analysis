---
ver: rpa2
title: 'Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech
  Recognition'
arxiv_id: '2510.08047'
source_url: https://arxiv.org/abs/2510.08047
tags:
- correction
- speech
- pseudo2real
- domain
- teacher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of improving automatic speech
  recognition (ASR) accuracy under domain shift, specifically for unseen accents with
  limited labeled data. The core method, Pseudo2Real, learns a parameter-space correction
  vector from the difference between models trained on real and pseudo-labeled data
  in a source domain, and applies it to a target-domain pseudo-labeled model to mitigate
  systematic pseudo-labeling biases.
---

# Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition

## Quick Facts
- **arXiv ID**: 2510.08047
- **Source URL**: https://arxiv.org/abs/2510.08047
- **Reference count**: 23
- **Primary result**: Achieves up to 35% relative WER reduction on AFRISPEECH-200 across ten African accents compared to pseudo-label fine-tuning

## Executive Summary
Pseudo2Real addresses the challenge of domain shift in automatic speech recognition when fine-tuning models on pseudo-labeled data from unseen accents. The method learns a correction vector in parameter space by comparing models trained on real versus pseudo-labeled data in a source domain, then applies this correction to target-domain pseudo-labeled models. This approach effectively mitigates systematic biases in pseudo-labels while preserving the adaptation benefits of semi-supervised learning.

## Method Summary
Pseudo2Real employs a task arithmetic approach to correct pseudo-label biases in low-resource ASR scenarios. The method trains two models in a source domain: one on real labeled data and another on pseudo-labeled data generated from the real-labeled model. By computing the parameter difference between these models, Pseudo2Real learns a correction vector that captures the systematic errors introduced by pseudo-labeling. When adapting to a target domain with limited labeled data, the method fine-tunes on pseudo-labeled target data, then applies the learned correction vector to mitigate domain-specific pseudo-labeling errors while maintaining adaptation gains.

## Key Results
- Achieves up to 35% relative WER reduction compared to standard pseudo-label fine-tuning on AFRISPEECH-200
- Consistent performance improvements across multiple Whisper model sizes
- Gains observed across all ten tested African accents
- Outperforms both pseudo-label fine-tuning and direct cross-domain adaptation baselines

## Why This Works (Mechanism)
The effectiveness of Pseudo2Real stems from its ability to learn and correct systematic biases inherent in pseudo-labeling. When models are trained on pseudo-labels, they often learn to reproduce the errors and limitations of the pseudo-labeling model rather than the true underlying patterns. By computing the difference between models trained on real versus pseudo-labeled data in a source domain, Pseudo2Real captures these systematic biases as a correction vector. Applying this learned correction to target-domain pseudo-labeled models allows the system to benefit from semi-supervised learning while mitigating the negative impact of pseudo-label errors, effectively balancing adaptation with error correction.

## Foundational Learning

**Automatic Speech Recognition (ASR)**: Converting spoken audio to text transcription. Why needed: Core problem domain for Pseudo2Real. Quick check: Model outputs text sequences from audio input.

**Domain Adaptation**: Adapting models trained on one domain to perform well on another domain with different characteristics. Why needed: Addresses the accent and speaker variation challenges. Quick check: Source and target domains have different data distributions.

**Pseudo-Labeling**: Using model predictions as training labels without human verification. Why needed: Enables semi-supervised learning with limited labeled data. Quick check: Model generates labels for unlabeled data used in training.

**Parameter-Space Arithmetic**: Manipulating model parameters directly rather than through gradient updates. Why needed: Core mechanism for learning and applying correction vectors. Quick check: Model parameters are vectors that can be added/subtracted.

## Architecture Onboarding

**Component Map**: Real-labeled model -> Pseudo-labeled model (source) -> Correction vector computation -> Target pseudo-labeled model -> Correction application

**Critical Path**: The key sequence is training source domain models (real vs pseudo), computing the correction vector, then applying it to the target-domain fine-tuned model. The quality of the correction vector directly determines final performance.

**Design Tradeoffs**: The method requires source domain real labeled data for correction vector computation, which may not always be available in true low-resource scenarios. This tradeoff enables effective error correction but limits applicability when source data is unavailable.

**Failure Signatures**: Performance degrades when source and target domains are too dissimilar, as the learned correction becomes less applicable. The method may also underperform if pseudo-labels contain excessive noise or if the source domain is too small to learn meaningful corrections.

**First Experiments**:
1. Compare WER on target domain with and without correction vector application
2. Ablate the source domain size to determine minimum requirements
3. Test different target domain fine-tuning durations before correction application

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to single dataset (AFRISPEECH-200) with African accents, raising generalizability concerns
- Requires access to source domain real labeled data for correction vector computation
- Limited analysis of failure modes and performance degradation when source-target domains are dissimilar

## Confidence

**High confidence**: The core algorithmic approach (parameter-space correction vector) is sound and technically novel.

**Medium confidence**: The relative performance improvements are likely real but may be dataset-specific rather than universally applicable.

**Low confidence**: Claims about robustness across different model sizes and accents beyond the tested configuration.

## Next Checks

1. Evaluate Pseudo2Real on diverse ASR datasets with varying accent types, languages, and domain shifts to test generalizability beyond AFRISPEECH-200.

2. Conduct ablation studies removing source domain real labeled data to assess practical applicability in true low-resource scenarios.

3. Analyze failure cases systematically to identify conditions under which Pseudo2Real degrades performance or produces unstable corrections.