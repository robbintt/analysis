---
ver: rpa2
title: 'Beyond Task Diversity: Provable Representation Transfer for Sequential Multi-Task
  Linear Bandits'
arxiv_id: '2501.13390'
source_url: https://arxiv.org/abs/2501.13390
tags:
- task
- algorithm
- subspace
- tasks
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies sequential multi-task linear bandits, where
  each task's parameter lies in a shared low-dimensional subspace. Unlike prior works,
  it does not assume task diversity (that parameters span the subspace uniformly).
---

# Beyond Task Diversity: Provable Representation Transfer for Sequential Multi-Task Linear Bandits

## Quick Facts
- arXiv ID: 2501.13390
- Source URL: https://arxiv.org/abs/2501.13390
- Reference count: 40
- This paper studies sequential multi-task linear bandits, where each task's parameter lies in a shared low-dimensional subspace. Unlike prior works, it does not assume task diversity (that parameters span the subspace uniformly). The proposed algorithm, BOSS, uses a bi-level approach: at the lower level, it employs meta-exploration (using a full-dimensional algorithm to obtain unbiased estimates) and meta-exploitation (using a learned subspace estimate to reduce regret); at the upper level, it performs online subspace selection using exponential weights over an ε-cover of the subspace set. Under mild assumptions, BOSS achieves a meta-regret of Õ(Nm√τ + N^{2/3}τ^{2/3}dm^{1/3} + Nd² + τmd), improving over the baseline of Õ(Nd√τ) when N is large and m≪d. Experiments on synthetic data show BOSS outperforms baselines that rely on task diversity.

## Executive Summary
This paper addresses sequential multi-task linear bandits where task parameters share a low-dimensional subspace structure, but without requiring the diversity assumption (that parameters span the subspace uniformly) that previous works rely on. The authors propose BOSS, a bi-level algorithm that simultaneously learns the shared subspace online and exploits this knowledge to reduce regret. The key insight is separating representation learning (meta-exploration) from task-specific optimization (meta-exploitation), with an upper-level online selection mechanism over a discretized subspace cover. The algorithm achieves improved meta-regret bounds when the number of tasks is large relative to the problem dimensions.

## Method Summary
BOSS operates through a bi-level approach: the lower level contains two algorithms—meta-exploration (Algorithm 1) that uses a full-dimensional PEGE variant to obtain unbiased parameter estimates for subspace learning, and meta-exploitation (Algorithm 2) that uses the learned subspace estimate to achieve lower regret. The upper level (Algorithm 3) performs online subspace selection using exponential weights over an ε-cover of the subspace set. At each task, the algorithm decides probabilistically whether to explore (update the subspace estimate) or exploit (use the current estimate). Importance-weighted surrogate costs ensure unbiased estimation of true costs from partially observed feedback, while the exponential weights mechanism provides Õ(log|E_ε|) regret against any fixed subspace.

## Key Results
- BOSS achieves meta-regret Õ(Nm√τ + N^{2/3}τ^{2/3}dm^{1/3} + Nd² + τmd), improving over the PEGE baseline Õ(Nd√τ) when N is large and m≪d
- The algorithm does not require task diversity assumption, unlike previous approaches such as SeqRepL [Qin et al. 2022]
- Experiments on synthetic data with adversarial task diversity (subspace changes at tasks 1, 2501, 3501) show BOSS outperforms baselines that rely on task diversity
- The theoretical analysis shows that the improvement requires N ≫ m√τ and τ ≫ d² to overcome burn-in terms

## Why This Works (Mechanism)

### Mechanism 1
A bi-level decomposition separating representation learning from task-specific optimization enables sequential multi-task learning without task diversity assumptions. The lower level provides two base algorithms—meta-exploration (Algorithm 1, full-dimensional PEGE) obtains unbiased θ̂ estimates for subspace learning; meta-exploitation (Algorithm 2, subspace-constrained) achieves lower regret when the subspace estimate B̂ approximates the true B. The upper level (Algorithm 3) uses exponential weights over an ε-cover to select subspaces online. This works under the assumption of well-conditioned ellipsoids with bounded task parameter norms.

### Mechanism 2
Importance-weighted surrogate costs enable unbiased estimation of true subspace selection costs from partially observed feedback. The true cost Cₙ(B) depends on unobserved θₙ. The algorithm defines surrogate cost C̃ₙ(B) based on θ̂ₙ (available only in meta-exploration rounds). Using importance weighting C̄ₙ(B) = C̃ₙ(B)·Zₙ/p, where Zₙ~Bernoulli(p) indicates exploration, ensures E[C̄ₙ(B)] ≳ Cₙ(B), preserving the upper bound property in expectation. This relies on meta-exploration probability p > 0 and estimation error ∥θ̂ₙ - θₙ∥ ≤ α with high probability.

### Mechanism 3
Discretizing the continuous subspace manifold into a finite ε-cover enables tractable online learning over experts. The set of m-dimensional subspaces B is infinite. BOSS constructs E_ε, an ε-cover in principal angle distance, with |E_ε| ≤ (√dm/ε)^O(dm). Running Exponential Weights Algorithm (Hedge) over E_ε achieves Õ(log|E_ε|) regret against any fixed subspace, with realizability ensured by ε-covering. This requires the true subspace B has an ε-approximation in E_ε and ε ≤ α.

## Foundational Learning

- Concept: Linear bandits with ellipsoid action sets (PEGE algorithm)
  - Why needed here: Algorithm 1 is a PEGE variant; understanding its exploration-exploitation tradeoff (τ₁ vs. d²/τ₁) is essential for tuning meta-exploration length.
  - Quick check question: Given action set A = {x: xᵀM⁻¹x ≤ 1}, what is the regret bound for PEGE with exploration length τ₁?

- Concept: Online learning from expert advice (Exponential Weights/Hedge)
  - Why needed here: Algorithm 3's upper level uses EWA to select subspaces; the Õ(log|E_ε|) regret bound against any fixed expert is central to Theorem 7.
  - Quick check question: If |E_ε| experts and learning rate η = ln(2), what is the EWA regret after N rounds?

- Concept: Principal angles and subspace distance metrics
  - Why needed here: Definition 5 uses ∥B^⊥_⊥·B'∥_F (sine of principal angles) as the cover metric; Lemma 13 relates this to Frobenius distance.
  - Quick check question: For two m-dimensional subspaces in R^d, how does ∥A^⊥_⊥·B∥_F relate to the Procrustes distance min_R∥AR-B∥_F?

## Architecture Onboarding

- Component map: Task n → Sample Zₙ~Ber(p) → If Zₙ=1: Algorithm 1 (Meta-Exploration) → θ̂ₙ → Update Dₙ₊₁ via EWA with loss ℓₙ(B) → If Zₙ=0: Sample B̂ₙ~Dₙ → Algorithm 2 (Meta-Exploitation) with B̂ₙ

- Critical path: 1. Construct E_ε: Discretize Grassmann manifold Gr(m,d) with ε-cover 2. Initialize D₁ uniformly over E_ε 3. For each task: binary exploration decision → run appropriate algorithm → (if exploring) compute loss ℓₙ and update Dₙ₊₁ 4. Tune hyperparameters: τ₁ = d·⌊min(d√(τ/p), τ)/d⌋, τ₂ = m·⌊√τ⌋, p = min((2m√τ/N)^(2/3), 1)

- Design tradeoffs:
  - p (exploration probability): Higher p → faster subspace learning but more meta-exploration regret
  - τ₁ (exploration length): Larger τ₁ → better θ̂ₙ estimates but higher per-task exploration cost
  - ε (cover granularity): Smaller ε → better approximation but |E_ε| grows as (√dm/ε)^dm
  - |E_ε| (expert set size): Practical implementations may subsample; paper uses 100K random experts + oracle

- Failure signatures:
  - Linear regret growth per task (not √τ): Subspace estimate B̂ₙ failing to cover θₙ → C_miss cost dominates
  - No improvement over PEGE baseline: Likely p too small or τ₁ insufficient for good θ̂ₙ
  - Computational bottleneck: E_ε too large → sample experts lazily or use structured covers

- First 3 experiments:
  1. Synthetic adversarial setup (N=4000, τ=500, d=10, m=3) with adversarial task diversity (only reveal new subspace dimensions at tasks 1, 2501, 3501): Compare BOSS vs. PEGE vs. SeqRepL [Qin et al. 2022] on cumulative regret
  2. Ablation on exploration probability p: Test p ∈ {0.01, 0.05, 0.1, 0.2} to verify theoretical p = (2m√τ/N)^(2/3) balance point
  3. Expert set size sensitivity: Compare |E_ε| ∈ {1K, 10K, 100K, 1M} to assess practical discretization requirements; check if including ground-truth B in E_ε significantly impacts performance

## Open Questions the Paper Calls Out

### Open Question 1
Can an algorithm be designed to achieve meta-regret that is never worse than the individual single-task baseline ($\tilde{O}(Nd\sqrt{\tau})$) across all parameter regimes? The authors state, "Statistically, it would be good to design an algorithm that performs no worse than the individual single-task baseline's performance in all parameter regimes." This remains unresolved because BOSS only improves upon the baseline when N is sufficiently large ($N \gg m\sqrt{\tau}$) and $\tau \gg d^2$; in less favorable settings, the burn-in terms make the bound potentially worse than the trivial baseline.

### Open Question 2
How can the algorithm and its guarantees be extended to general or time-varying action sets? The authors note that "extending the algorithm and guarantees to general and time-varying action spaces is an important direction." This is unresolved because the current analysis relies on the "ellipsoid action set" assumption (Assumption 2) to efficiently obtain unbiased estimates of task parameters during the meta-exploration phase.

### Open Question 3
Can a computationally efficient algorithm be developed that avoids maintaining the exponentially large expert set used in BOSS? The paper states, "BOSS requires maintaining an exponentially large number of experts in $\mathcal{E}_\epsilon$; in the future, we would like to develop more computationally-efficient algorithms." This remains unresolved because the current approach uses exponential weights over an $\epsilon$-cover of the Grassmannian manifold, resulting in a set size of $(\sqrt{dm}/\epsilon)^{O(dm)}$.

### Open Question 4
Can the requirement of prior knowledge regarding the subspace dimension $m$ be removed? "Practically, it would also be nice to design parameter-free variants of BOSS that do not require knowing $m$ ahead of time." This is unresolved because BOSS requires $m$ as an input to construct the expert set and determine exploration lengths.

## Limitations

- The theoretical improvement over PEGE is asymptotic and only applies when N is large and m≪d; burn-in terms (τmd, Nd²) dominate for small N or large m
- The ε-cover E_ε has size up to (√dm/ε)^dm, making exact implementation infeasible for moderate d and m; the paper uses 100K random experts instead
- The algorithm relies on well-conditioned ellipsoid action sets (Assumption 2), limiting applicability to settings where such assumptions hold naturally

## Confidence

- **High Confidence**: The bi-level algorithmic structure and the role of importance weighting for unbiased cost estimation are clearly explained and mathematically sound
- **Medium Confidence**: The regret bounds (Theorem 7) are derived under stated assumptions, but the practical significance depends on parameter regimes where N is large and m≪d
- **Low Confidence**: The exact implementation details of the ε-cover construction and hyperparameter tuning are underspecified, making exact reproduction challenging

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary p, τ₁, τ₂ around the theoretical optimal values to verify the claimed tradeoff between exploration and exploitation

2. **Cover Quality Verification**: Compare BOSS performance using the random expert set versus a properly constructed ε-cover (when computationally feasible) to assess the impact on regret bounds

3. **Break Case Analysis**: Design experiments where assumptions fail (e.g., ill-conditioned action sets, m close to d) to identify the algorithm's failure modes and robustness limits