---
ver: rpa2
title: 'Discursive Circuits: How Do Language Models Understand Discourse Relations?'
arxiv_id: '2510.11210'
source_url: https://arxiv.org/abs/2510.11210
tags:
- discourse
- circuits
- relation
- cudr
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces discursive circuits, the first mechanistic
  analysis of how language models process discourse relations. The authors develop
  a novel Completion under Discourse Relation (CuDR) task to enable circuit discovery
  in this complex domain, constructing a dataset of minimal contrastive pairs across
  three discourse frameworks (PDTB, RST, SDRT).
---

# Discursive Circuits: How Do Language Models Understand Discourse Relations?
## Quick Facts
- arXiv ID: 2510.11210
- Source URL: https://arxiv.org/abs/2510.11210
- Reference count: 40
- Primary result: First mechanistic analysis of how language models process discourse relations, revealing sparse circuits that capture discourse understanding with ~90% faithfulness

## Executive Summary
This paper introduces discursive circuits, the first mechanistic analysis of how language models process discourse relations. The authors develop a novel Completion under Discourse Relation (CuDR) task to enable circuit discovery in this complex domain, constructing a dataset of minimal contrastive pairs across three discourse frameworks (PDTB, RST, SDRT). Discursive circuits (≈0.2% of model size) successfully recover discourse understanding with ~90% faithfulness and generalize across frameworks. Analysis reveals lower layers capture linguistic features while upper layers encode discourse-level abstractions, with consistent feature utility across frameworks. This work provides the first neural-based discourse hierarchy and offers new insights into the mechanistic basis of discourse comprehension.

## Method Summary
The paper introduces Completion under Discourse Relation (CuDR) as a novel task for circuit discovery, where models complete discourse given a connective by choosing between Arg2 or counterfactual Arg'2. GPT-2 medium is fine-tuned on CuDR data, then Edge Attribution Patching (EAP) identifies sparse circuits (≈0.2% of model) that causally drive discourse predictions. The approach constructs minimal contrastive pairs across PDTB, RST, SDRT frameworks, revealing layer-wise functional specialization and cross-framework generalization. Discursive circuits achieve ~90% faithfulness while capturing underlying discourse representations rather than framework-specific patterns.

## Key Results
- Sparse circuits (≈0.2% of model size) recover discourse understanding with ~90% faithfulness
- Circuits generalize across discourse frameworks (PDTB → RST, SDRT) with varying success rates
- Lower layers capture linguistic features while upper layers encode discourse-level abstractions
- Layer-wise edge analysis reveals discursive-circuit-only edges emerge in higher layers (8-16 → 10-20)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sparse circuits (~0.2% of model edges) can recover discourse understanding with ~90% faithfulness.
- Mechanism: Edge Attribution Patching identifies causally influential connections by computing gradient-weighted activation differences between original and counterfactual inputs. Top-k edges (typically 200-1000) are selected based on magnitude of impact g(e) ≈ (z^ori_u - z^cf_u)^T ∇_v L(x^cf).
- Core assumption: Discourse processing relies on a sparse subgraph rather than distributed computation across all model components.
- Evidence anchors:
  - [abstract] "sparse circuits (≈0.2% of a full GPT-2 model) recover discourse understanding... with ~90% faithfulness"
  - [section 3.1] "strong faithfulness (≈90%) is achieved with only ≈200 edges"
  - [corpus] Limited direct corpus evidence; circuit sparsity claims are task-specific to this paper's methodology.
- Break condition: If discourse relations required dense computation across most layers/heads, sparse circuit recovery would fail dramatically (<50% faithfulness).

### Mechanism 2
- Claim: Lower layers capture linguistic features while upper layers encode discourse-level abstractions.
- Mechanism: Layer-wise edge analysis reveals discursive-circuit-only edges emerge primarily in source layers 8-16 targeting layers 10-20, with minimal overlap with linguistic feature circuits in early layers. Lower layers process shared features (coreference, lexical semantics); higher layers integrate these into discourse representations.
- Core assumption: Discourse understanding follows a hierarchical processing pipeline from surface features to abstract relations.
- Evidence anchors:
  - [abstract] "lower layers capture linguistic features such as lexical semantics and coreference, while upper layers encode discourse-level abstractions"
  - [section 3.3, Figure 8] "DC-only edges emerge in higher layers and are absent in lower layers"
  - [corpus] Related work on transformer layer functions supports hierarchical processing but doesn't specifically validate discourse-specific layering.
- Break condition: If discourse-specific computation appeared uniformly across all layers, or if linguistic features required high-layer processing, the claimed hierarchy would not hold.

### Mechanism 3
- Claim: Circuits trained on one discourse framework (PDTB) generalize to unseen frameworks (RST, SDRT).
- Mechanism: Cross-framework relation mapping aligns discourse relations across taxonomies (e.g., SDRT's Explanation → PDTB's Contingency.Cause.Reason). Circuits capture shared underlying discourse representations rather than framework-specific surface patterns.
- Core assumption: Different discourse frameworks share underlying computational representations in language models despite differing annotation schemes.
- Evidence anchors:
  - [abstract] "These circuits generalize well to unseen discourse frameworks such as RST and SDRT"
  - [section 3.2] "PDTB's L3 circuits close the gap with Own using only ≈200 edges"
  - [corpus] No corpus evidence directly validates cross-framework circuit generalization; this appears novel to this work.
- Break condition: If circuits captured framework-specific annotation artifacts rather than underlying discourse relations, cross-framework transfer would fail (faithfulness near random baseline).

## Foundational Learning

- Concept: Activation Patching / Causal Intervention
  - Why needed here: Core technique for identifying which model components causally influence discourse predictions. Without understanding intervention-based methods, circuit discovery appears as black magic.
  - Quick check question: Given two inputs that differ only in discourse connective ("so" vs "but"), how would you determine which attention heads causally drive the different continuations?

- Concept: Discourse Relations and Frameworks (PDTB/RST/SDRT)
  - Why needed here: The paper assumes familiarity with discourse analysis frameworks. PDTB uses connective-based relations (Comparison, Contingency, Expansion, Temporal); RST uses rhetorical structure; SDRT uses segmented discourse representation.
  - Quick check question: What discourse relation holds between "Bob is hungry" and "the canteen is closed" when connected by "but" versus "so"?

- Concept: Transformer Residual Stream and Edge Topology
  - Why needed here: Circuits are defined as computational graphs with edges between residual stream positions, attention heads, and MLP layers. Understanding information flow is essential for interpreting circuit visualizations.
  - Quick check question: In a 24-layer transformer, what does an edge from "MLP 20 → Attn 21.9" represent in terms of information flow?

## Architecture Onboarding

- Component map:
  - Input: CUDR task format with Arg1, connective, and two candidate completions (Arg2 vs Arg2')
  - Model: GPT-2 medium (355M params, 24 layers) fine-tuned on CUDR task
  - Circuit Discovery: Edge Attribution Patching pipeline (2 forward + 1 backward pass)
  - Output: Top-k edges ranked by causal influence g(e), forming sparse circuit
  - Evaluation: Normalized faithfulness metric comparing patched vs full model performance

- Critical path:
  1. Construct CUDR dataset with minimal contrastive pairs (Arg1 fixed, connective swapped)
  2. Fine-tune model on held-out CUDR data to ensure task alignment (~80% accuracy)
  3. Run EAP to compute g(e) for all edges using batch size 32
  4. Select top 200-1000 edges per relation
  5. Evaluate faithfulness by patching clean activations into corrupted inputs

- Design tradeoffs:
  - EAP vs ACDC: EAP is 1000x faster but uses first-order Taylor approximation; ACDC is more faithful but computationally prohibitive
  - Circuit granularity: L3 (fine-grained) circuits more effective early; L1 (coarse) more stable with lower variance
  - Sample size: 32 samples per relation balances stability and computational cost

- Failure signatures:
  - Random baseline faithfulness remains near 0% even with 1000+ edges → task requires non-trivial circuit structure
  - IOI circuit plateaus at ~50% faithfulness → discourse requires capabilities beyond next-word prediction
  - SDRT generalization lags (50% faithfulness at 100 edges) → framework-specific features not captured by PDTB circuits
  - Missing early edges (Resid Start → MLP 0) in cross-framework transfer → failure to capture connective reasoning

- First 3 experiments:
  1. Replicate faithfulness curve on single PDTB relation: Train circuit on 32 samples, evaluate on held-out 32, plot faithfulness vs edges patched (should reach ~90% at 200 edges)
  2. Ablate layer ranges: Patch only edges from layers 0-8 vs 16-24 to validate lower/upper layer functional split
  3. Cross-relation transfer test: Apply Contingency.Result circuit to Contingency.Reason task; expect moderate overlap (80-120/200 edges) but weak faithfulness correlation (r ≈ 0)

## Open Questions the Paper Calls Out

- **Cross-linguistic circuit spaces**: The authors explicitly suggest extending circuit discovery to multiple languages to explore whether a unified circuit space exists across different languages. This remains unresolved as the current study is restricted to English-based corpora.

- **Complex and ambiguous discourse**: The authors note their generated counterfactual arguments use simple sentence structures and lack rare words to maximize salience. They explicitly suggest future work could extend CUDR to more complex texts and ambiguous scenarios, as the current dataset may oversimplify natural discourse complexity.

- **Shared edges vs functional recovery**: The authors observe a counterintuitive finding where there is no correlation between edge overlap and faithfulness (r=−0.007) within the PDTB framework, despite significant edge sharing (80–120 edges). The mechanistic reason why shared circuitry does not equate to shared functional recovery remains unidentified.

## Limitations

- **Cross-framework generalization gaps**: While circuits claim to generalize across PDTB, RST, and SDRT, the mechanism remains underspecified with notable performance gaps (particularly 50% faithfulness for SDRT at 100 edges).

- **Methodological approximation**: Edge Attribution Patching provides computational efficiency but relies on first-order Taylor approximations, with the trade-off between efficiency and faithfulness not empirically validated against ground-truth causal structures.

- **Task-specificity concerns**: The CuDR task design may not capture the full complexity of discourse processing, with the claim that ~200 edges capture discourse understanding potentially reflecting task simplification rather than general discourse mechanisms.

## Confidence

**High Confidence Claims:**
- Sparse circuits (~0.2% of model) can recover discourse understanding with ~90% faithfulness
- Lower layers capture linguistic features while upper layers encode discourse-level abstractions

**Medium Confidence Claims:**
- Circuits generalize across discourse frameworks
- The proposed discourse hierarchy (linguistic → discourse) reflects actual model computation

**Low Confidence Claims:**
- The specific edge attributions identified by EAP perfectly capture causal mechanisms
- The ~90% faithfulness metric represents true discourse understanding rather than task-specific pattern matching

## Next Checks

1. **Ground-truth validation**: Compare EAP-identified circuits against ACDC-discovered circuits on a small subset of relations to quantify approximation error and validate that efficiency gains don't compromise mechanistic accuracy.

2. **Framework-agnostic probing**: Design a discourse task that can be evaluated across all three frameworks without relying on framework-specific annotations, to test whether circuits capture underlying discourse computation rather than annotation artifacts.

3. **Layer-wise ablation study**: Systematically ablate layers 8-16 (where discursive-circuit-only edges emerge) to quantify their specific contribution to discourse vs linguistic processing, distinguishing the claimed hierarchical processing from alternative explanations.