---
ver: rpa2
title: Mistake-bounded online learning with operation caps
arxiv_id: '2509.03892'
source_url: https://arxiv.org/abs/2509.03892
tags:
- learning
- learner
- function
- functions
- operations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies mistake-bounded online learning under arithmetic
  operation caps, motivated by recent AI governance policies limiting computation.
  The authors define LF as the minimal per-round arithmetic operations needed to learn
  a function family F with finitely many mistakes, and UF as the minimal operations
  needed for optimal mistake performance.
---

# Mistake-bounded online learning with operation caps

## Quick Facts
- **arXiv ID**: 2509.03892
- **Source URL**: https://arxiv.org/abs/2509.03892
- **Reference count**: 35
- **Key outcome**: Proves that minimal arithmetic operations for finite-mistake learning (L_F) cannot be less than function computation complexity (W(F)), shows gaps between L_F and optimal learning costs (U_F) can be arbitrarily large, and characterizes which neural network architectures are learnable under operation caps.

## Executive Summary
This paper introduces a framework for mistake-bounded online learning where learners are constrained by a maximum number of arithmetic operations per round, motivated by recent AI governance policies limiting computational resources. The authors define L_F as the minimal per-round operations needed to learn a function family F with finitely many mistakes, and U_F as the minimal operations needed for optimal mistake performance. They prove fundamental lower bounds showing L_F ≥ W(F), demonstrate that L_F and U_F can differ by arbitrary amounts, and characterize which function families (including neural networks) are learnable under these constraints. The paper also resolves an open problem in agnostic learning and introduces a partial ordering to compare learning complexity across different scenarios.

## Method Summary
The paper employs a theoretical analysis framework combining computational complexity theory with online learning models. The authors prove bounds using weighted majority voting algorithms, row reduction techniques for maintaining hypothesis consistency, and partial orderings of function classes. They analyze various function families including linear transformations, polynomials, and neural networks (1-layer and 2-layer), establishing whether each is learnable under operation caps. The agnostic learning results use weight-splitting strategies in weighted majority voting to achieve optimal performance when the target function is only approximately in the hypothesis class.

## Key Results
- Proves L_F ≥ W(F), establishing that the minimum operations for finite-mistake learning cannot be less than the arithmetic complexity of computing the hardest function in the family
- Shows that L_F and U_F can differ by arbitrary amounts, demonstrating that optimal learning may require significantly more operations than simply achieving finite mistakes
- Characterizes 1-layer neural networks as learnable under operation caps while 2-layer networks are not, solving a key question about neural network learnability under computational constraints
- Resolves an open problem in agnostic learning by proving opt_ag,weak(F, η) = O((k ln k)opt_std(F) + kη)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The minimal operations per round to learn a function family with finite mistakes ($L_F$) cannot be lower than the arithmetic complexity of computing the hardest function in that family ($W(F)$).
- **Mechanism:** In the mistake-bound model, the learner must eventually predict correctly on *any* input after making a finite number of errors. If the available operations per round ($a$) are strictly less than $W(F)$, there exists an input $x$ for which the learner cannot compute $f(x)$. Thus, the learner cannot guarantee a finite mistake bound without sufficient compute to evaluate the function.
- **Core assumption:** The learner must predict correctly on arbitrary inputs after the learning phase concludes (the "final round" correctness condition).
- **Evidence anchors:**
  - [abstract] "We prove general bounds including $L_F \ge W(F)$, where $W(F)$ is the minimal arithmetic operations needed to compute any function in $F$."
  - [section] Page 7, Theorem 2.5: "Since A is guaranteed to make at most r mistakes... it must be correct for the next input... A can evaluate f on any input using fewer than W(f) arithmetic operations. This is a contradiction."
  - [corpus] "Compute Requirements for Algorithmic Innovation" investigates similar constraints on compute availability for capability thresholds.

### Mechanism 2
- **Claim:** It is possible to learn with finite mistakes using zero arithmetic operations ($L_F = 0$) even when achieving the optimal mistake bound requires many operations ($U_F > 0$).
- **Mechanism:** The learner employs a "memorization-only" strategy: guess a default value (e.g., 0) for all new inputs. When the adversary reveals the true label, the learner memorizes the input-output pair. This requires no arithmetic operations, only memory lookups. While this results in a suboptimal number of mistakes (Theorem 2.3 shows a mistake bound of 2 instead of 1), it proves that $L_F$ and $U_F$ can be separated.
- **Core assumption:** The learner has unbounded memory for storing input-output pairs, and the cost of memory access does not count toward the "arithmetic operation" cap.
- **Evidence anchors:**
  - [abstract] "...showing gaps [between L_F and U_F] up to arbitrary size..."
  - [section] Page 7, Theorem 2.3: "The learner can learn Fr without using arithmetic operations for a mistake bound of 2 by guessing 0 for all new r-tuples until the adversary has said the answer was wrong twice..."
  - [corpus] Corpus neighbor "Online Learning of Neural Networks" discusses learnability conditions but assumes standard compute; this mechanism highlights the specific trade-off when compute is constrained to zero.

### Mechanism 3
- **Claim:** 1-layer neural networks are learnable under operation caps ($L_F < \infty$), but 2-layer networks with standard activations are not ($L_F = \infty$).
- **Mechanism:** For 1-layer networks, the learner can perform expensive consistency maintenance (e.g., row reduction) over multiple rounds, "amortizing" the cost to stay under a fixed per-round cap. However, for 2-layer networks, the family of functions can approximate indicator functions (e.g., $I_{[0,c]}$). The adversary can force the learner to require unboundedly many operations to distinguish between valid hypotheses in this class, making finite-mistake learning impossible with a fixed cap.
- **Core assumption:** The "standard" or "leaky" ReLU activation functions are used, which allow for the approximation of indicators that create the complexity barrier in 2-layer setups.
- **Evidence anchors:**
  - [abstract] "They analyze neural networks, proving that 1-layer networks are learnable with operation caps while 2-layer networks are not."
  - [section] Page 18, Theorem 4.13: "I[0,c] can be approximated by a linear combination of four relu activation functions... The adversary forces an error of at least 1/2 in each round, so we have opt_std(F) = infinity."

## Foundational Learning

- **Concept: Mistake-Bound Model**
  - **Why needed here:** The entire paper operates within this framework, where success is measured by the worst-case total number of errors, rather than convergence time or loss minimization.
  - **Quick check question:** In this model, does a learner need to converge to the exact hypothesis, or just stop making errors? (Answer: Stop making errors).

- **Concept: Agnostic Learning**
  - **Why needed here:** The paper solves an open problem regarding $opt_{ag,weak}(F, \eta)$, where the target function is only *approximately* in the hypothesis class.
  - **Quick check question:** If the true function disagrees with the best hypothesis in your class on $\eta$ points, what is the goal? (Answer: To perform nearly as well as the best hypothesis).

- **Concept: Arithmetic Complexity ($W(F)$)**
  - **Why needed here:** This forms the fundamental lower bound ($L_F \ge W(F)$). It defines the cost of computing a function independent of learning it.
  - **Quick check question:** Why does the cost of computing a function set a floor for the cost of learning it? (Answer: You must eventually compute it to verify the correct answer).

## Architecture Onboarding

- **Component map:**
  - **The Learner DAG:** A directed acyclic graph representing the algorithm; nodes are arithmetic ops.
  - **Ops Cap ($a$):** The strict limit on binary operations per round (add, sub, mul, div).
  - **L & U Metrics:** $L_F$ is the "feasibility floor" (finite mistakes); $U_F$ is the "optimality floor" (optimal mistakes).

- **Critical path:**
  1. Calculate $W(F)$ for the target function family to establish the theoretical minimum operations ($L_F$).
  2. Determine if the family is "simple online-learnable" (can we use the amortized maintenance strategy?).
  3. If simple, implement the "Two-Phase" learner: Phase 1 (Guess) uses $\le W(F)$ ops; Phase 2 (Maintenance) distributes expensive row-reductions over subsequent rounds.

- **Design tradeoffs:**
  - **Memory vs. Compute:** You can often reduce $L_F$ to 0 (Theorem 2.3) by trading compute for memory (storing all past mistakes), but $U_F$ remains high.
  - **Architecture Depth:** 1-layer networks are safe for capped systems; 2-layer networks introduce "infinite complexity" risks (Corollary 4.14) that cannot be solved by just adding more data.

- **Failure signatures:**
  - **Infinite Loop on 2-Layer Nets:** If implementing a learner for 2-layer ReLU nets, you will fail to bound mistakes; the adversary can always force a 50% error rate regardless of your ops cap.
  - **Cap Exhaustion:** If your amortized maintenance (row reduction) takes longer than the inputs arrive, you fall behind and exceed the per-round cap.

- **First 3 experiments:**
  1. **Verify the Gap:** Implement the family $F_r$ from Theorem 2.3. Show that with 0 ops, you achieve 2 mistakes, but with $r$ ops, you achieve 1 mistake.
  2. **Test 1-Layer Bounds:** Train a 1-layer network learner on random linear data. Vary the ops cap $a$ to plot the curve of mistakes vs. operations, confirming $U_F \approx O(n^3)$.
  3. **Stress Test 2-Layer:** Attempt to learn the family in Theorem 4.13 (2-layer, 4 hidden neurons). Confirm that even with very high caps, the mistake count does not converge (it remains infinite).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does there exist a family of functions $F$ with a finite standard mistake bound ($opt_{std}(F) < \infty$) for which the minimum operations for finite learning ($L_F$) do not equal the computation complexity ($W(F)$)?
- **Basis in paper:** [explicit] Problem 7.1 asks if $L_F \neq W(F)$ is possible when $opt_{std}(F) < \infty$.
- **Why unresolved:** The authors prove that $L_F = W(F)$ for "simple online-learnable" families and show $L_F > W(F)$ for specific families (e.g., in Theorem 2.6), but the known examples with $L_F > W(F)$ have $opt_{std}(F) = \infty$.
- **What evidence would resolve it:** A construction of a function family with finite $opt_{std}(F)$ where $L_F > W(F)$, or a proof that $L_F = W(F)$ holds for all families with finite mistake bounds.

### Open Question 2
- **Question:** For the family of 1-layer ReLU neural networks $F_{n,\text{ReLU}}$, is the minimum operation count for finite learning $L_{F_{n,\text{ReLU}}}$ equal to the computation complexity $W(F_{n,\text{ReLU}})$?
- **Basis in paper:** [explicit] Problem 7.2 explicitly asks "Does $L_{F_{n,\text{ReLU}}} = W(F_{n,\text{ReLU}})$?"
- **Why unresolved:** The paper establishes that $W(F_{n,\text{ReLU}}) = \Theta(n)$ and $L_{F_{n,\text{ReLU}}} = O(n^3)$, leaving a gap between the linear lower bound and the cubic upper bound.
- **What evidence would resolve it:** An algorithm that learns $F_{n,\text{ReLU}}$ with $O(n)$ arithmetic operations per round, or a lower bound proof showing $\omega(n)$ operations are required.

### Open Question 3
- **Question:** What is the smallest integer $k$ such that there exists a function family $F$ requiring $k$ arithmetic operations to compute ($W(F) = k$) that is impossible to learn with finite mistakes ($opt_{std}(F) = \infty$)?
- **Basis in paper:** [explicit] Problem 7.3 asks "What is the least $k$ for which there exists a family $F$ with $W(F) = k$ such that $opt_{std}(F) = \infty$?"
- **Why unresolved:** The paper demonstrates that families with finite $W(F)$ can have infinite mistake bounds (Theorem 2.6), but the minimum computational complexity required for this phenomenon is unknown.
- **What evidence would resolve it:** Identifying the specific minimal integer $k$ and associated function family, or proving that for all $j < k$, $W(F) = j$ implies $opt_{std}(F) < \infty$.

### Open Question 4
- **Question:** What structural properties characterize function families $F$ where the minimum operations for finite learning equal the minimum operations for optimal learning ($L_F = U_F$)?
- **Basis in paper:** [explicit] Problem 7.4 states "Characterize the families $F$ with $L_F = U_F$."
- **Why unresolved:** While the paper provides examples where $L_F < U_F$ (gaps can be arbitrarily large) and trivial examples where they are equal, a unifying characterization or set of sufficient and necessary conditions is missing.
- **What evidence would resolve it:** A theorem establishing equivalence between $L_F = U_F$ and specific structural properties of the function class (e.g., relating to the "simple online-learnable" criterion).

## Limitations
- The bounds assume worst-case adversarial inputs and may not reflect average-case performance in practical settings
- The arithmetic operation model assumes binary operations are the primary computational bottleneck, which may not align with actual hardware architectures
- Results depend critically on specific activation functions (leaky ReLU, standard ReLU) and their ability to approximate indicator functions

## Confidence
- **High Confidence**: The fundamental lower bound L_F ≥ W(F) (Theorem 2.5) is rigorously proven with clear counting arguments and minimal assumptions about the learning model
- **Medium Confidence**: The characterization of simple online-learnable families (Theorem 3.5) relies on the amortized maintenance strategy, which is well-explained but assumes unlimited memory for storing hypotheses
- **Medium Confidence**: The agnostic learning bounds (Theorem 5.3) are derived from weighted majority voting analysis, though the exact constant factors in the O-notation may vary with implementation details

## Next Checks
1. **Gap Verification**: Implement the family F_r from Theorem 2.3 to empirically demonstrate the separation between L_F = 0 (2 mistakes) and U_F > 0 (1 mistake) for varying values of r
2. **Architecture Stress Test**: Attempt to learn the 2-layer network family from Theorem 4.13 under progressively higher operation caps to verify that the mistake bound remains infinite regardless of computational resources
3. **Agnostic Bound Experiment**: Implement the weighted majority voting algorithm from Theorem 5.3 with weight splitting (1/3 correct, 1/3k others) and measure the actual mistake count against the predicted O((k ln k)opt_std(F) + kη) bound on synthetic data where the true function disagrees with the hypothesis class on η fraction of points