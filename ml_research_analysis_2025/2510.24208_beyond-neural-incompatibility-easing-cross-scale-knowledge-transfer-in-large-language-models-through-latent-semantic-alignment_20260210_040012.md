---
ver: rpa2
title: 'Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large
  Language Models through Latent Semantic Alignment'
arxiv_id: '2510.24208'
source_url: https://arxiv.org/abs/2510.24208
tags:
- layer
- teacher
- knowledge
- transfer
- student
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of transferring knowledge across
  large language models (LLMs) of different scales, which is hindered by "neural incompatibility"
  - architectural and parametric differences between models. The authors propose a
  semantics-first approach called SEMALIGN that uses layer activations (hidden states)
  as the medium for knowledge transfer rather than raw parameters.
---

# Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment

## Quick Facts
- arXiv ID: 2510.24208
- Source URL: https://arxiv.org/abs/2510.24208
- Reference count: 18
- Authors: Jian Gu; Aldeida Aleti; Chunyang Chen; Hongyu Zhang
- Primary result: SEMALIGN achieves smaller performance gaps to teacher models (averaging 1.44 points) compared to parameter-space baselines (3.43-3.92 points) on cross-scale LLM transfer tasks.

## Executive Summary
This paper addresses the challenge of transferring knowledge across large language models (LLMs) of different scales, which is hindered by "neural incompatibility" - architectural and parametric differences between models. The authors propose a semantics-first approach called SEMALIGN that uses layer activations (hidden states) as the medium for knowledge transfer rather than raw parameters. The method achieves more stable transfer and better performance on academic benchmarks by aligning the latent semantic representations between teacher and student models.

## Method Summary
SEMALIGN transfers knowledge from large to small LLMs by aligning their layer activations rather than raw parameters. The method involves three key steps: (1) using layer attribution to identify critical layers in the teacher model and pairing them with corresponding layers in the student model, (2) decomposing the teacher's layer outputs into semantic components and recomposing them in the student's latent space to create supervisory signals, and (3) optimizing the student's paired layers to match these supervisory hidden states. The approach uses a two-term cosine loss that aligns both paired-layer activations and output logits, with training focused only on paired layers using LoRA adapters.

## Key Results
- SEMALIGN consistently outperforms parameter-space transfer baselines (SEEKING and LATEN) on four benchmarks (MMLU, GSM8K, HumanEval, MBPP)
- Achieves smaller performance gaps to teacher models (averaging 1.44 points vs 3.43-3.92 for baselines)
- Demonstrates more stable transfer, particularly when transferring from code-specialized teachers
- Shows that aligning a small set of paired layers can induce broader behavioral alignment

## Why This Works (Mechanism)
The method works by addressing neural incompatibility through semantic alignment rather than parameter matching. By decomposing teacher activations into semantic components using learned bases and recomposing them in the student's latent space, SEMALIGN creates supervisory targets that respect the architectural differences between models. This allows knowledge to transfer through shared semantic space rather than incompatible parameter space. The layer attribution mechanism identifies which teacher layers are most critical for specific tasks, ensuring that supervision is focused where it matters most.

## Foundational Learning

**Layer Attribution**: Identifying which model layers contribute most to task performance using techniques like Gradient×Activation. Why needed: Without attribution, supervision would be spread evenly across all layers, wasting resources on less important ones. Quick check: Verify attribution scores correlate with downstream performance when layers are individually ablated.

**Semantic Decomposition/Recomposition**: Projecting activations onto learned semantic bases and reconstructing in target model's basis. Why needed: Direct parameter matching fails due to architectural differences; semantic space provides a common ground. Quick check: Confirm cosine similarity between original and reconstructed activations exceeds 0.9.

**Layer Pairing Strategies**: Mapping teacher layers to student layers based on depth-aware heuristics (e.g., proportional mapping). Why needed: Models have different numbers of layers; pairing must respect architectural structure. Quick check: Validate that paired layers have similar functional roles by comparing attention patterns.

## Architecture Onboarding

**Component Map**: Input Data → Layer Attribution → Semantic Basis Computation → Layer Pairing → Activation Decomposition → Recomposition → Supervisory Signal → Student Layer Optimization

**Critical Path**: The most important components are the semantic basis computation and the layer pairing strategy, as errors in either will propagate through the entire transfer process. The two-term cosine loss function is also critical for balancing activation alignment with output consistency.

**Design Tradeoffs**: Using LoRA adapters instead of full fine-tuning reduces computational cost but may limit expressivity. The choice to align only paired layers (rather than all layers) prioritizes efficiency over completeness. The semantic decomposition approach requires additional preprocessing overhead but provides better cross-architecture compatibility.

**Failure Signatures**: Poor alignment quality manifests as low cosine similarity between teacher and student activations, training instability with NaNs or exploding gradients, and minimal improvement over baseline methods. Debugging should focus on basis normalization, layer pairing accuracy, and supervision signal quality.

**First Experiments**:
1. Validate semantic basis computation by checking unit-norm columns and reconstruction accuracy
2. Test layer attribution by comparing performance when training on attributed vs non-attributed layers
3. Evaluate layer pairing heuristic by measuring alignment quality across different mapping strategies

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation scope is narrow, focusing exclusively on Llama 2 family models with limited architectural variations
- Computational overhead of semantic basis computation and layer attribution preprocessing is not thoroughly analyzed
- The depth-preserving pairing heuristic lacks theoretical grounding for why it should work across arbitrary architectures
- Does not address practical deployment scenarios where transfer efficiency and compute constraints are paramount

## Confidence

**High confidence**: The empirical observation that latent semantic alignment outperforms parameter-space baselines on tested benchmarks, and that aligning a small set of paired layers can induce broader behavioral alignment.

**Medium confidence**: The claim that "neural incompatibility" is the primary bottleneck for cross-scale transfer, and that semantic alignment "strongly predicts" stable cross-scale transfer.

**Low confidence**: Generalizability to more diverse model families and practical deployment scenarios.

## Next Checks

1. **Architectural Generalization Test**: Apply SEMALIGN to cross-family transfers (e.g., Llama 2 → Mistral, or decoder → encoder-decoder models) to validate whether semantic alignment remains effective when architectural differences are more pronounced.

2. **Computational Overhead Analysis**: Quantify the full computational cost including semantic basis computation, layer attribution, and training time, comparing it against baseline methods to assess practical viability in production settings.

3. **Robustness to Layer Pairing Strategy**: Systematically vary the layer pairing heuristic (beyond depth-preserving) and measure impact on transfer quality to determine whether the observed gains are robust to different architectural mappings or specific to the proposed heuristic.