---
ver: rpa2
title: 'Bridging Gaps in Hate Speech Detection: Meta-Collections and Benchmarks for
  Low-Resource Iberian Languages'
arxiv_id: '2510.11167'
source_url: https://arxiv.org/abs/2510.11167
tags:
- hate
- speech
- galician
- spanish
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the scarcity of hate speech detection resources
  for low-resource Iberian languages by creating a standardized meta-collection of
  European Spanish datasets and generating aligned synthetic datasets for European
  Portuguese and Galician. The research employs large language models (Llama 3.1,
  Nemo, and multilingual BERT) under zero-shot, few-shot, and fine-tuning settings
  to establish new benchmarks for hate speech detection.
---

# Bridging Gaps in Hate Speech Detection: Meta-Collections and Benchmarks for Low-Resource Iberian Languages

## Quick Facts
- **arXiv ID**: 2510.11167
- **Source URL**: https://arxiv.org/abs/2510.11167
- **Reference count**: 34
- **Primary result**: Fine-tuning outperforms zero-shot and few-shot approaches for hate speech detection in low-resource Iberian languages

## Executive Summary
This study addresses the scarcity of hate speech detection resources for low-resource Iberian languages by creating a standardized meta-collection of European Spanish datasets and generating aligned synthetic datasets for European Portuguese and Galician. The research employs large language models (Llama 3.1, Nemo, and multilingual BERT) under zero-shot, few-shot, and fine-tuning settings to establish new benchmarks for hate speech detection. Results show that fine-tuning consistently outperforms zero-shot and few-shot approaches, with performance varying across languages and linguistic varieties. Cross-lingual evaluations reveal that models trained on Spanish generalize better to Galician (Spanish variant) than to Galician (Portuguese variant), highlighting the importance of accounting for internal linguistic variation.

## Method Summary
The study creates a meta-collection by standardizing European Spanish hate speech datasets to ensure compatibility and interoperability. Synthetic datasets are generated for European Portuguese and Galician using cross-lingual transfer techniques, creating aligned datasets that mirror the Spanish meta-collection's structure. Large language models including Llama 3.1, Nemo, and multilingual BERT are evaluated across three settings: zero-shot (no training data), few-shot (limited examples), and fine-tuning (full training). The experimental design compares monolingual performance across the three languages and examines cross-lingual generalization patterns, particularly focusing on the two distinct Galician variants.

## Key Results
- Fine-tuning consistently outperforms zero-shot and few-shot approaches across all languages and models tested
- Models trained on Spanish generalize better to Galician (Spanish variant) than to Galician (Portuguese variant)
- Cross-lingual transfer effectiveness depends on linguistic similarity between source and target languages

## Why This Works (Mechanism)
The effectiveness of the proposed approach stems from leveraging large language models' pre-trained knowledge while adapting them through fine-tuning on standardized datasets. The synthetic data generation enables creation of aligned datasets across languages, preserving task structure while adapting to linguistic characteristics. The meta-collection standardization ensures consistent evaluation conditions across languages, allowing meaningful comparisons between monolingual and cross-lingual performance.

## Foundational Learning
**Hate speech detection**: Identifying toxic, offensive, or discriminatory language in text
- *Why needed*: Core task requiring accurate classification across diverse linguistic contexts
- *Quick check*: Verify dataset annotations align with hate speech definition

**Cross-lingual transfer learning**: Applying knowledge from resource-rich languages to low-resource languages
- *Why needed*: Enables hate speech detection where labeled data is scarce
- *Quick check*: Measure performance drop between monolingual and cross-lingual settings

**Synthetic data generation**: Creating artificial training examples using language models
- *Why needed*: Addresses data scarcity in low-resource languages
- *Quick check*: Compare synthetic and real data distributions

## Architecture Onboarding

**Component map**: Dataset standardization -> Synthetic data generation -> Model fine-tuning -> Cross-lingual evaluation

**Critical path**: The study's success depends on accurate dataset standardization and high-quality synthetic data generation, as these directly impact model performance across all evaluation settings.

**Design tradeoffs**: The choice between zero-shot, few-shot, and fine-tuning represents a spectrum of data efficiency versus performance. While fine-tuning provides best results, it requires more training data and computational resources compared to zero-shot approaches.

**Failure signatures**: Poor cross-lingual performance may indicate insufficient linguistic similarity between source and target languages or low-quality synthetic data generation.

**First experiments**: 
1. Compare model performance across zero-shot, few-shot, and fine-tuning settings on the Spanish meta-collection
2. Evaluate cross-lingual transfer from Spanish to each target language
3. Analyze performance differences between the two Galician variants

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic data generation introduces uncertainty about linguistic authenticity and representativeness
- The study does not fully characterize the nature of internal linguistic variation across Iberian languages
- Effectiveness of synthetic data generation for languages beyond the Iberian family remains untested

## Confidence

| Claim | Confidence |
|-------|------------|
| Fine-tuning consistently outperforms zero-shot and few-shot approaches | High |
| Cross-lingual generalization results show differential performance between Galician variants | Medium |
| Synthetic data generation approach generalizes to other low-resource languages | Low |

## Next Checks
1. Conduct human evaluation studies to assess the linguistic quality and hate speech relevance of synthetically generated samples, particularly for Galician (Portuguese variant)
2. Test the proposed meta-collection and synthetic data approach on additional low-resource European languages beyond the Iberian family to evaluate cross-linguistic generalizability
3. Perform ablation studies to determine the minimum dataset size required for effective fine-tuning versus few-shot learning across different language pairs