---
ver: rpa2
title: 'OPTIMUS: Predicting Multivariate Outcomes in Alzheimer''s Disease Using Multi-modal
  Data amidst Missing Values'
arxiv_id: '2503.11282'
source_url: https://arxiv.org/abs/2503.11282
tags:
- multiple
- data
- missing
- components
- plsregression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "OPTIMUS is a machine learning framework for predicting multivariate\
  \ Alzheimer\u2019s disease (AD) outcomes using multimodal data with missing values.\
  \ It combines modality-specific imputation, predictive modeling, and explainable\
  \ AI to uncover biomarkers linking multimodal inputs to multiple cognitive outcomes."
---

# OPTIMUS: Predicting Multivariate Outcomes in Alzheimer's Disease Using Multi-modal Data amidst Missing Values

## Quick Facts
- arXiv ID: 2503.11282
- Source URL: https://arxiv.org/abs/2503.11282
- Reference count: 0
- Multi-modal AD prediction framework achieving correlation up to 0.74 with KNN imputation and TabNet regression

## Executive Summary
OPTIMUS is a machine learning framework designed to predict multivariate Alzheimer's disease outcomes using multimodal data while handling missing values. The system combines modality-specific imputation, predictive modeling, and explainable AI to identify biomarkers linking multimodal inputs to cognitive outcomes. Using data from 1,205 ADNI participants including structural MRI, CSF proteins, blood transcriptomics, and APOE genotype, OPTIMUS demonstrates the ability to integrate complex data sources for interpretable, domain-specific AD outcome prediction.

## Method Summary
OPTIMUS employs a three-stage pipeline: (1) modality-specific imputation using KNN (k=1) for continuous features and constant values for ordinal data, selected via KL-divergence validation; (2) confounder residualization through OLS regression to remove age, sex, and education effects from both inputs and targets; (3) TabNet regression on residuals with permutation importance for explainability. The framework was evaluated on ADNI data using train-test splits and cross-validation strategies, with performance measured by Pearson correlation and MAE across four cognitive domains.

## Key Results
- KNN imputation with TabNet regression achieved highest prediction accuracy (correlation up to 0.74, MAE down to 0.445)
- Explainable AI revealed anatomically relevant brain regions and biologically meaningful genetic features
- Different modalities showed differential predictive power across cognitive domains (MRI for visuospatial, RNA for memory)
- Framework successfully identified neural and transcriptomic signatures predictive of executive function, language, memory, and visuospatial performance

## Why This Works (Mechanism)

### Mechanism 1
Modality-specific k-nearest neighbors (KNN) imputation preserves statistical distribution of sparse clinical data better than global methods by filling missing values with plausible entries from observed subjects, minimizing KL divergence. Assumes missingness patterns allow finding similar proxy subjects within dataset. Evidence shows KNN (k=1) outperformed other methods with minimal distributional divergence. Break condition: if missingness is not random or cohort is highly heterogeneous, single-neighbor copying may introduce noise.

### Mechanism 2
Residualizing input features against confounders (age, gender, education) isolates disease-specific variance by removing linear effects via OLS regression before training. Assumes confounders affect features and outcomes linearly without stripping disease-relevant signals. Evidence supports this approach for isolating disease mechanisms. Break condition: if age-education-brain atrophy relationships are non-linear, residualization may undercorrect or overcorrect.

### Mechanism 3
Attention-based TabNet regression captures many-to-many non-linear relationships between multimodal biomarkers and cognitive outcomes through sequential attention masks that select relevant features at each decision step. Assumes predictive features for different cognitive domains are distinct enough for attention mechanisms to isolate them. Evidence shows TabNet outperformed other models in identifying differentially predictive features. Break condition: if dataset is too small for Transformer parameter count, model may overfit despite regularization.

## Foundational Learning

- **K-Nearest Neighbors (KNN) Imputation**
  - Why needed: Handles massive sparsity in ADNI dataset (only 12 fully complete subjects)
  - Quick check: Can you explain why k=1 might preserve variance of skewed biological distribution better than taking the mean?

- **Feature Residualization (Confounder Correction)**
  - Why needed: Ensures model predicts cognitive decline based on pathology rather than normal aging
  - Quick check: If you residualize cortical thickness against age, what specifically remains in residual vector?

- **TabNet (Attentive Interpretable Tabular Learning)**
  - Why needed: Core predictor providing instance-wise feature selection via masking
  - Quick check: How does "sparsemax" layer in TabNet differ from "softmax" in standard attention?

## Architecture Onboarding

- **Component map:** Input Layer (multimodal data + missing mask) -> Imputer (KNN k=1) -> Pre-processor (OLS Residualization) -> Predictor (TabNet) -> Explainer (XAI)
- **Critical path:** Imputer is bottleneck; improper imputation yields distributions that diverge significantly from observed data, degrading downstream prediction accuracy
- **Design tradeoffs:** Interpretability vs accuracy (chose Permutation Importance over Shapley/Owen values); Imputation complexity (simple KNN outperformed GANs)
- **Failure signatures:** Negative correlation in cross-validation indicates overfitting; feature importance distortion from multicollinearity
- **First 3 experiments:**
  1. Replicate Imputation Quality (KL Divergence): Compare KNN vs Mean vs GAIN on hold-out ADNI data
  2. Ablation on Confounder Correction: Train TabNet on raw vs residualized data to check prediction drop
  3. Many-to-Many Specificity: Train separate models for Memory vs Visuospatial to compare top 20 features

## Open Questions the Paper Calls Out

- Can advanced deep learning imputation techniques (denoising autoencoders, MUSE, DrFuse) reduce bias and improve predictive accuracy compared to KNN within OPTIMUS framework?
- How can explainability metrics be refined to accurately handle highly correlated multimodal features without overemphasizing uncorrelated noise?
- Can OPTIMUS identify predictive biomarkers for cognitive decline from non-traditional pathways like immune system dysregulation or gut-brain interactions?

## Limitations
- KNN imputation assumes Missing at Random (MAR) patterns, which may not hold with extreme modality sparsity
- Confounder residualization assumes linear relationships that may oversimplify neurodegeneration biology
- Small test set (n=12 complete cases) limits statistical power and may lead to overfitting concerns

## Confidence
- KNN imputation generalizability: Medium-High (validated via KL divergence but needs cross-cohort verification)
- Confounder residualization effectiveness: Medium (assumes linear relationships that may not capture complex biology)
- TabNet performance claims: Medium (supported by comparisons but limited by small test set)

## Next Checks
1. Cross-cohort validation: Apply OPTIMUS to independent AD datasets (AIBL, OASIS) to verify stability
2. MNAR simulation: Introduce structured missingness patterns to test KNN degradation vs generative methods
3. Feature importance stability: Bootstrap resampling of complete-case subset to assess variance in importance rankings