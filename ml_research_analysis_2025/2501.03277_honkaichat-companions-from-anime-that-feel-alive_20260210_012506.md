---
ver: rpa2
title: 'HonkaiChat: Companions from Anime that feel alive!'
arxiv_id: '2501.03277'
source_url: https://arxiv.org/abs/2501.03277
tags:
- character
- data
- events
- dialogue
- conversation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study introduces an event-driven dialogue framework to create
  more engaging and lifelike chatbot interactions, addressing the limitations of reactive,
  personality-driven conversational agents. By embedding dynamic events in conversation
  prompts and fine-tuning models on character-specific data, the approach significantly
  improves conversational engagement and naturalness while reducing hallucinations.
---

# HonkaiChat: Companions from Anime that feel alive!

## Quick Facts
- **arXiv ID:** 2501.03277
- **Source URL:** https://arxiv.org/abs/2501.03277
- **Reference count:** 2
- **Primary result:** Event-driven dialogue framework improves conversational engagement and reduces hallucinations in anime character chatbots

## Executive Summary
HonkaiChat introduces an event-driven dialogue framework that creates more engaging and lifelike chatbot interactions by embedding dynamic events in conversation prompts. Unlike reactive, personality-driven conversational agents, this approach shifts character mood, perspective, and conversational focus through narrative anchors, enabling proactive dialogue. The framework was applied to Honkai: Star Rail characters, using a two-stage training approach (domain pre-training on game wiki data followed by character fine-tuning) that significantly reduces hallucinations and improves character consistency. Evaluations on GPT-4 and comparisons with industry baselines demonstrated clear improvements in conversational quality across five dimensions.

## Method Summary
The approach uses staged training with LLaMA 3.1-8B: first pre-training on a 17MB domain corpus from game wikis to establish universe-level knowledge, then fine-tuning on 5,000 character-specific dialogue pairs using LoRA-based PEFT. Events are manually curated (1,300 total) and embedded in prompts to provide narrative context that shifts character behavior. Synthetic dialogues are generated using GPT-4 to extend in-game conversations while maintaining thematic consistency. The framework includes an event selector, prompt constructor, and response generator, with GPT-4 evaluating responses across five dimensions: Memorization, Values, Personality, Hallucination, and Stability.

## Key Results
- Event-driven prompts significantly improve conversational engagement and naturalness while reducing hallucinations
- Two-stage training (domain pre-training + character fine-tuning) effectively grounds models in game lore
- GPT-4 evaluations show clear improvements across all five quality dimensions compared to industry baselines

## Why This Works (Mechanism)

### Mechanism 1: Event-Driven Context Injection
- Claim: Embedding dynamic events in conversation prompts increases engagement and naturalness compared to reactive, personality-only systems
- Mechanism: Events provide narrative anchors that shift character mood, perspective, and conversational focus, enabling proactive rather than purely reactive dialogue
- Core assumption: Human-like conversations are shaped by evolving events, not just immediate exchanges
- Evidence anchors:
  - [abstract] "event-driven prompts significantly improve conversational engagement and naturalness while reducing hallucinations"
  - [section 1] "a conversation might be influenced by earlier events such as a fire alarm at work, discovering a new skill...These factors shift moods, alter perspectives, and influence conversational topics"
  - [corpus] EventWeave (arxiv 2503.23078) also models event relationships in dialogue systems
- Break condition: If events become repetitive or misaligned with character context, the effect diminishes; paper notes default "may I ask a question" behavior without events

### Mechanism 2: Domain Grounding via Staged Training
- Claim: Two-stage training (domain pre-training + character fine-tuning) reduces hallucinations and improves character consistency
- Mechanism: Pre-training on game wiki data instills universe-level knowledge; fine-tuning on character-specific dialogues shapes personality and response patterns
- Core assumption: Vanilla base models have pre-training distributions that don't align with role-specific data
- Evidence anchors:
  - [abstract] "fine-tuning models on character-specific data...reducing hallucinations"
  - [section 6.1] "When asked about an 'imaginary tree' in the game, the model no longer fabricated irrelevant details (e.g., 'a tree in London'). Instead, it referenced the in-game concept of 'imaginary force'"
  - [corpus] CharacterLLM (cited in paper) similarly uses staged training; ChatHaruhi extracts original scripts for character memory
- Break condition: If domain corpus is too small or noisy, grounding weakens; paper acknowledges "scarcity of domain-specific content"

### Mechanism 3: Synthetic Dialogue Augmentation
- Claim: GPT-generated conversations anchored in game lore expand training data diversity while maintaining thematic consistency
- Mechanism: Use GPT-4 to extend existing in-game dialogues, generating new conversations that adhere to character profiles and narrative universe
- Core assumption: Synthetic data quality depends on proper grounding in source material
- Evidence anchors:
  - [section 3.3] "we used GPT-4 to extend existing in-game dialogues...thematically consistent conversations that adhered to Honkai: Star Rail's narrative"
  - [section 4.3] "5,000 input samples" constructed from original + augmented pairs
  - [corpus] Weak corpus signalâ€”no direct synthetic augmentation comparables found; relies on paper's internal validation
- Break condition: If synthetic dialogues drift from authentic character voice, they may introduce misalignment; paper notes tendency toward "generic human behavior"

## Foundational Learning

- **Concept: LoRA (Low-Rank Adaptation)**
  - Why needed here: Paper uses LoRA-based PEFT for fine-tuning LLaMA 3.1-8B on a single A6000 GPU; essential for reproducing training setup
  - Quick check question: Can you explain why LoRA reduces memory requirements compared to full fine-tuning?

- **Concept: Event-Driven Dialogue Design**
  - Why needed here: Core innovation is embedding events in prompts; understanding how to structure events (casual, surprising, realistic) is critical
  - Quick check question: What makes an event "conversation-worthy" versus a static fact?

- **Concept: LLM-as-Evaluator Paradigm**
  - Why needed here: Paper uses GPT-4 to rate responses across 5 dimensions; this is common practice but has known limitations
  - Quick check question: What biases might GPT-4 have when evaluating role-playing quality?

## Architecture Onboarding

- **Component map:** Wiki scraping -> In-game dialogue extraction (~4,000 lines) -> Event dataset (1,300 manually curated) -> Synthetic dialogue generation (GPT-4) -> Domain pre-training (17MB corpus on LLaMA 3.1-8B) -> Character fine-tuning (5,000 samples, LoRA/PEFT) -> Event selector -> Prompt constructor -> Response generator -> GPT-4 evaluation (5 dimensions)

- **Critical path:**
  1. Scrape and clean domain corpus
  2. Generate/curate character-specific events
  3. Synthesize augmented dialogue pairs
  4. Pre-train on full domain corpus
  5. Fine-tune on character-specific data with LoRA
  6. Evaluate with GPT-4 across 5 dimensions

- **Design tradeoffs:**
  - LoRA vs. full fine-tuning: Efficiency (single A6000, 2 hours) vs. potentially reduced character depth
  - Synthetic vs. authentic dialogue: Volume vs. authenticity risk
  - Manual vs. automated event curation: Labor-intensive but higher quality than off-the-shelf LLM generation

- **Failure signatures:**
  - Narrative drift: Model shifts from conversation to storytelling mode with long inputs
  - Generic reactions: "Good enough" human-like responses instead of distinct character traits
  - Repetitive openers: Default to "may I ask a question" without event prompts

- **First 3 experiments:**
  1. Baseline comparison: LLaMA 3.1-8b-instruct with personality-only prompts vs. event-augmented prompts; measure GPT-4 scores across 5 dimensions
  2. Event ablation: Test no events vs. random events vs. character-aligned events; isolate contribution of event relevance
  3. Hallucination probe: Query domain-specific concepts before/after pre-training; measure reduction in out-of-universe fabrications

## Open Questions the Paper Calls Out
None

## Limitations
- Framework effectiveness depends heavily on quality and relevance of manually curated events, introducing labor-intensive maintenance overhead
- Synthetic dialogue generation risks character drift when LLM-generated content diverges from authentic character voice
- Evaluation methodology relies entirely on GPT-4 scoring, which may not capture nuanced aspects of role-playing quality

## Confidence
- Event-driven engagement improvements: Medium-High - Supported by GPT-4 evaluation scores and clear mechanism, but relies on subjective quality judgments
- Hallucination reduction claims: Medium - Demonstrated through specific examples but lacks quantitative hallucination metrics or user studies
- Character consistency improvements: Medium - Evidenced by comparison to baseline but limited by small sample size and lack of human evaluation
- Two-stage training effectiveness: Medium - Shows measurable improvements but hasn't been compared to alternative training strategies

## Next Checks
1. **Human evaluation study**: Conduct blind tests where human raters compare event-augmented vs. personality-only responses across multiple characters, measuring engagement, naturalness, and character authenticity
2. **Cross-domain generalization**: Apply the framework to characters from different domains (Western media, literature, historical figures) to test robustness of event-driven design patterns
3. **Long-term interaction testing**: Evaluate model stability and character consistency over extended conversations (100+ turns) to identify narrative drift or personality erosion that short-term evaluations might miss