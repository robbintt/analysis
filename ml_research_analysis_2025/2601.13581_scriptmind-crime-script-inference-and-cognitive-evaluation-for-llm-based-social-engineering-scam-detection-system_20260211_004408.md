---
ver: rpa2
title: 'SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based
  Social Engineering Scam Detection System'
arxiv_id: '2601.13581'
source_url: https://arxiv.org/abs/2601.13581
tags:
- scam
- suspicion
- were
- stage
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SCRIPTMIND is an integrated framework that combines crime script
  inference with cognitive evaluation to enhance LLM-based detection of social engineering
  scams. It addresses the limitation of static, one-time alerts by modeling scammer
  behavior sequences and providing real-time, context-aware predictions to sustain
  user suspicion during scam interactions.
---

# SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System

## Quick Facts
- arXiv ID: 2601.13581
- Source URL: https://arxiv.org/abs/2601.13581
- Reference count: 40
- Primary result: 13% performance gain over GPT-4o in scam detection using Korean phone scam data

## Executive Summary
SCRIPTMIND addresses the critical limitation of static, one-time alerts in current LLM-based social engineering scam detection systems. The framework introduces a dynamic approach that models scammer behavior sequences through crime script inference while simultaneously evaluating real-time cognitive impact on users. By combining these two elements, SCRIPTMIND provides context-aware predictions that sustain user suspicion throughout scam interactions rather than relying on initial warnings that users may ignore or forget.

The system integrates a Crime Script Inference Task (CSIT) for reasoning over scam scripts, a Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and a Cognitive Simulation-based Evaluation (CSED) to assess real-time user cognitive impact. Using 571 Korean phone scam cases, SCRIPTMIND achieved a 13% performance gain over GPT-4o in scam detection, reduced false positives, and improved explanatory quality. In cognitive simulation experiments, it significantly increased and sustained user suspicion levels, particularly during critical scam stages, demonstrating its effectiveness as a human-centered defense against evolving social engineering threats.

## Method Summary
SCRIPTMIND is an integrated framework that combines crime script inference with cognitive evaluation to enhance LLM-based detection of social engineering scams. The framework addresses the limitation of static, one-time alerts by modeling scammer behavior sequences and providing real-time, context-aware predictions to sustain user suspicion during scam interactions. It includes a Crime Script Inference Task (CSIT) for reasoning over scam scripts, a Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and a Cognitive Simulation-based Evaluation (CSED) to assess real-time user cognitive impact. The system uses 571 Korean phone scam cases for training and evaluation, achieving significant improvements in detection accuracy while reducing false positives and improving explanatory quality.

## Key Results
- Achieved 13% performance gain over GPT-4o in scam detection accuracy
- Reduced false positives while maintaining high detection rates
- Significantly increased and sustained user suspicion levels during critical scam stages through cognitive simulation

## Why This Works (Mechanism)
SCRIPTMIND works by modeling the sequential nature of social engineering attacks through crime script inference, which captures the typical progression of scammer tactics. This temporal understanding allows the system to provide contextually relevant warnings at each stage of the scam, rather than relying on a single initial alert. The cognitive evaluation component then assesses how these warnings affect user decision-making in real-time, enabling adaptive responses that maintain user vigilance throughout the interaction. This dual approach addresses both the technical detection challenge and the human factors that make social engineering attacks successful.

## Foundational Learning
- Crime script modeling: Understanding the typical sequence of actions in social engineering attacks - needed to capture temporal patterns in scammer behavior, quick check is whether the model can predict the next scam stage accurately
- Cognitive impact assessment: Evaluating how warnings affect user decision-making - needed to ensure warnings are effective in maintaining suspicion, quick check is whether simulated suspicion levels correlate with actual user behavior
- Context-aware inference: Adapting predictions based on the current stage of interaction - needed to provide relevant warnings at each step, quick check is whether stage-specific warnings outperform generic alerts
- Small LLM fine-tuning: Training compact models on specialized scam data - needed for efficient deployment on edge devices, quick check is whether performance matches larger models with lower computational cost

## Architecture Onboarding

Component Map: CSID fine-tuning -> CSIT inference -> CSED evaluation -> User warning generation

Critical Path: Crime Script-Aware Inference Dataset (CSID) → Crime Script Inference Task (CSIT) → Cognitive Simulation-based Evaluation (CSED) → User warning generation

Design Tradeoffs: The framework trades computational efficiency for enhanced accuracy by using small LLMs fine-tuned on specialized data rather than relying solely on large general-purpose models. This approach enables deployment on resource-constrained devices while maintaining performance through task-specific training.

Failure Signatures: The system may fail when scam scripts deviate significantly from training patterns, when cognitive responses vary substantially across cultural contexts, or when real-time processing delays prevent timely warnings. False negatives may occur with novel scam techniques, while false positives may arise from legitimate but unusual interactions that match scam patterns.

First 3 Experiments:
1. Evaluate CSIT performance on held-out scam cases to measure detection accuracy improvements
2. Run CSED simulations with varying warning timing to identify optimal intervention points
3. Compare user suspicion trajectories with and without context-aware warnings to quantify cognitive impact

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Evaluation relies heavily on Korean-language phone scam data, limiting generalizability to other languages and scam types
- Cognitive simulation experiments use proxy metrics rather than actual human user studies, introducing uncertainty about real-world effectiveness
- The 13% performance improvement comes from a relatively small dataset of 571 cases, raising questions about statistical significance across broader scenarios

## Confidence
- Crime script modeling effectiveness: High - The performance gains and systematic approach provide strong evidence
- Real-time cognitive impact: Medium - Simulation results are promising but lack validation with actual human users
- Framework generalizability: Low - Current evaluation is limited to Korean phone scams with no cross-cultural validation

## Next Checks
1. Conduct user studies with real human participants across different cultural contexts to validate the cognitive simulation results
2. Test the framework on diverse scam types (email, text, social media) and multiple languages to assess generalizability
3. Perform ablation studies to quantify the individual contributions of crime script inference versus cognitive evaluation components