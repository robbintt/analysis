---
ver: rpa2
title: 'Generative AI for Autonomous Driving: A Review'
arxiv_id: '2505.15863'
source_url: https://arxiv.org/abs/2505.15863
tags:
- driving
- arxiv
- learning
- prediction
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively reviews generative AI (GenAI) applications
  in autonomous driving (AD), categorizing methods by task and modeling approach.
  It covers static map generation (road layouts, HD-Maps), dynamic scenario generation,
  trajectory prediction, motion planning, and end-to-end driving, examining VAEs,
  GANs, DMs, transformers, and hybrid methods.
---

# Generative AI for Autonomous Driving: A Review

## Quick Facts
- **arXiv ID:** 2505.15863
- **Source URL:** https://arxiv.org/abs/2505.15863
- **Reference count:** 40
- **Primary result:** Comprehensive survey of generative AI applications in autonomous driving, categorizing methods by task and modeling approach.

## Executive Summary
This survey provides a comprehensive review of generative AI (GenAI) applications in autonomous driving (AD), categorizing methods across static map generation, dynamic scenario generation, trajectory prediction, motion planning, and end-to-end driving. The review examines various modeling approaches including VAEs, GANs, diffusion models, transformers, and hybrid methods. Key findings highlight diffusion models' excellence in high-fidelity scene generation and trajectory prediction, transformers' efficiency in multi-agent motion forecasting, and LLMs' potential for interpretable planning. The work identifies critical challenges including safety, interpretability, and real-time feasibility, while recommending hybrid solutions and multi-dataset learning approaches to advance the field.

## Method Summary
The review systematically categorizes generative AI applications in autonomous driving by task type and modeling approach. For trajectory prediction and dynamic scenario generation, it focuses on conditional diffusion models that iteratively denoise random noise into trajectories while applying guidance mechanisms for safety constraints. The method involves encoding scene context (map, agent history) through encoders, then using denoiser networks (often transformer-based) to refine trajectories through multiple denoising steps. Training objectives typically minimize divergence between generative and data distributions, with inference incorporating online gradient-based guidance to enforce collision avoidance and traffic rule compliance.

## Key Results
- Diffusion models excel in high-fidelity scene generation and trajectory prediction, offering superior diversity and safety compliance
- Transformers enable efficient multi-agent motion forecasting through parallel attention mechanisms, avoiding exponential complexity of pairwise graph models
- LLMs offer interpretable planning by bridging abstract instructions and motion planning, typically interfacing with traditional controllers like MPC
- Major challenges identified include safety (adversarial robustness, compliance), interpretability (opaque models), and real-time feasibility (computational constraints)
- Recommendations emphasize hybrid solutions, diverse training objectives, and multi-dataset learning for robust AD development

## Why This Works (Mechanism)

### Mechanism 1: Controllable Trajectory Generation via Guided Diffusion
Conditional diffusion models generate diverse, physically plausible trajectories by iteratively denoising random noise, with guidance mechanisms enforcing safety constraints and scene consistency. The process starts with Gaussian noise over trajectory space, refined through denoising steps conditioned on scene context. Online gradient-based guidance (e.g., Control Barrier Functions) steers samples away from unsafe regions without retraining, assuming the underlying data contains sufficient safe driving examples.

### Mechanism 2: Joint Interaction Modeling via Attention Tokenization
Transformers enable efficient multi-agent motion forecasting by treating scene elements as tokens, allowing self-attention to capture pairwise interactions without manual graph construction. Continuous inputs are discretized into tokens, with self-attention layers computing interaction scores simultaneously, capturing dependencies like vehicle yielding. This approach avoids exponential complexity in dense traffic while preserving spatial-temporal resolution.

### Mechanism 3: Hybrid LLM-Enhanced Planning
LLMs function as high-level reasoners bridging abstract instructions and motion planning by interfacing with traditional controllers (e.g., MPC) that guarantee physical constraints. The LLM processes prompts containing scene description and driving instructions to output high-level parameters or cost function weights, which downstream controllers use to compute kinematically feasible trajectories, assuming accurate semantic-to-numerical mapping.

## Foundational Learning

- **Concept: Latent Space Representations (VAEs/Flow)**
  - **Why needed here:** Generative models rarely operate on raw pixels for planning; understanding how encoders compress sensor data into latent vectors and how decoders reconstruct from compressed form is essential
  - **Quick check question:** Can you explain the difference between a VAE's latent space (probabilistic) and a standard autoencoder's (deterministic), and why the former is preferred for generating diverse scenarios?

- **Concept: The AD Stack (Perception-Prediction-Planning)**
  - **Why needed here:** The paper categorizes GenAI applications by where they sit in this pipeline; knowing interfaces (e.g., Perception outputs BEV maps) is essential for placing generative components
  - **Quick check question:** If a generative model predicts future trajectories (Prediction), what specific inputs does it likely require from the Perception module?

- **Concept: Modes of Generation (Marginal vs. Joint)**
  - **Why needed here:** Predicting one agent in isolation (Marginal) differs fundamentally from predicting interacting agents together (Joint); this distinction is critical for evaluating collision risk
  - **Quick check question:** In a crowded intersection, why might a Marginal prediction model predict a collision between two cars that a Joint model would avoid?

## Architecture Onboarding

- **Component map:** Multi-modal sensor data (Camera/LiDAR) -> Tokenizer/Variational Encoder -> Latent State -> Diffusion Model (Denoiser) or Transformer (Attention Blocks) -> Guidance Function (Safety constraints) + Low-level Controller (MPC/RRT) -> Waypoints or Control Signals (Steering/Acceleration)

- **Critical path:** The conditioning of the generative model on static/dynamic context; if input encoding (e.g., BEV feature extraction) is noisy or misaligned, generated trajectories will be inconsistent with road geometry

- **Design tradeoffs:**
  - *Fidelity vs. Latency:* Diffusion models offer high diversity (safety) but are computationally slow (iterative denoising); transformers are faster (parallel) but can struggle with long-term temporal coherence
  - *Open-loop vs. Closed-loop training:* Many models trained open-loop (expert cloning) but fail in closed-loop (reactive environments)

- **Failure signatures:**
  - **Mode Collapse:** Generative model produces the "average" trajectory for all scenarios regardless of context
  - **The "Frozen Robot" Problem:** Planning becomes overly conservative due to epistemic uncertainty in generative predictions
  - **Hallucination:** LLM-based planners reacting to semantic descriptions of obstacles without corresponding sensor grounding

- **First 3 experiments:**
  1. Implement a Conditional Diffusion Policy: Train diffusion model on trajectory dataset conditioned on map data, measuring diversity vs. collision rate
  2. Hybrid LLM-MPC Integration: Connect pre-trained LLM to simple MPC controller, inputting text commands and verifying correct cost weight setting
  3. Safety Filter Integration: Apply Control Barrier Function as post-processing to generative planner, measuring projection frequency as indicator of base model safety

## Open Questions the Paper Calls Out

- **Open Question 1:** How can domain-specific safety-aware metrics be developed to quantify the domain gap between synthetic and real-world driving scenarios?
  - **Basis in paper:** Explicitly calls for methods measuring domain gap in street scenes and developing domain-specific safety-aware metrics
  - **Why unresolved:** Current evaluation metrics focus on visual fidelity or diversity rather than semantic consistency or physical safety compliance
  - **What evidence would resolve it:** Standardized benchmarks correlating synthetic data quality with real-world safety outcomes

- **Open Question 2:** How can autonomous systems reliably detect hallucinations and filter illogical outputs generated by probabilistic GenAI models?
  - **Basis in paper:** Identifies detecting hallucinations and filtering illogical outputs as critical direction for GenAI quality assurance
  - **Why unresolved:** Generative models produce plausible-looking but contextually incorrect or physically impossible data posing severe risks in safety-critical environments
  - **What evidence would resolve it:** Robust verification modules or constrained decoding techniques reducing semantic error rates to near-zero in safety-critical scenarios

- **Open Question 3:** What novel methods can evaluate the safety and feasibility of proposed but unexecuted actions generated by GenAI agents during open-loop shadow mode?
  - **Basis in paper:** States need for novel methods evaluating proposed but unexecuted actions alongside standard shadow mode testing
  - **Why unresolved:** In open-loop testing, system doesn't execute AI's planned trajectory, making it difficult to assess safety of actions differing from recorded human driving path
  - **What evidence would resolve it:** Validation frameworks successfully simulating or inferring consequences of counterfactual actions to verify safety without physical execution

## Limitations

- Analysis relies heavily on aggregating claims from primary research papers without direct empirical validation, with specific architectural details and performance metrics often abstracted
- Safety challenges are described conceptually but lack standardized metrics or benchmarking datasets for validation
- Review does not address potential biases in training data that could lead to unsafe behavior in underrepresented scenarios
- Claims about real-time LLM deployment feasibility lack concrete latency measurements or computational budgets

## Confidence

- **High Confidence:** Categorization of generative AI applications and identification of diffusion models, transformers, and LLMs as key architectural approaches
- **Medium Confidence:** Claims about diffusion models excelling in high-fidelity scene generation and transformers enabling efficient multi-agent forecasting, supported by examples but lacking comparative quantitative analysis
- **Low Confidence:** Practical feasibility of real-time LLM deployment in closed-loop scenarios and safety implications, asserted but not demonstrated with concrete measurements or standardized testing protocols

## Next Checks

1. **Benchmark Diffusion Model Performance:** Implement and compare diffusion-based trajectory prediction models on standardized dataset (e.g., nuScenes) against traditional methods, measuring diversity, collision rate, and inference latency

2. **Quantify LLM Planning Latency:** Integrate pre-trained LLM with real-time MPC controller and measure end-to-end latency under varying scene complexities, testing in closed-loop simulator for responsiveness and safety

3. **Develop Safety Metrics for Generative Models:** Propose and validate standardized safety metrics (e.g., adversarial robustness, compliance with traffic rules) for generative AI in autonomous driving, applying to existing models to identify failure modes and guide research