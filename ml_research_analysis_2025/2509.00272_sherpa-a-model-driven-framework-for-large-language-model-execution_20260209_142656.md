---
ver: rpa2
title: 'SHERPA: A Model-Driven Framework for Large Language Model Execution'
arxiv_id: '2509.00272'
source_url: https://arxiv.org/abs/2509.00272
tags:
- llms
- state
- sherpa
- generation
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SHERPA is a model-driven framework that enhances LLM performance
  on complex tasks by explicitly incorporating human best practices as hierarchical
  state machines. The framework decomposes tasks into manageable sub-tasks, with LLMs
  performing actions within transitions while maintaining a belief structure that
  stores execution history and intermediate results.
---

# SHERPA: A Model-Driven Framework for Large Language Model Execution

## Quick Facts
- **arXiv ID:** 2509.00272
- **Source URL:** https://arxiv.org/abs/2509.00272
- **Reference count:** 40
- **Primary result:** SHERPA improves LLM performance on complex tasks through hierarchical state machines, achieving gains in 12 of 15 tested configurations

## Executive Summary
SHERPA is a model-driven framework that enhances LLM performance on complex tasks by explicitly incorporating human best practices as hierarchical state machines. The framework decomposes tasks into manageable sub-tasks, with LLMs performing actions within transitions while maintaining a belief structure that stores execution history and intermediate results. The state machine design is decoupled from action implementation, allowing rapid experimentation with different configurations. Evaluation on three tasks (code generation, class name generation, and question answering) using various LLMs demonstrates that SHERPA improves performance in 12 out of 15 cases compared to direct prompting approaches.

## Method Summary
SHERPA executes tasks as hierarchical state machines where LLMs perform actions during state transitions. The framework maintains a belief structure containing trajectory stores, execution logs, and key-value stores that persist throughout execution. Policies (rule-based, LLM-based, or hybrid) select transitions based on current state and belief context, while a fast-forward mechanism automatically selects transitions when only one option exists. The framework was evaluated on HumanEval code generation, class name generation, and Clevr question answering tasks using multiple LLMs including GPT-4o and Qwen2.5 models.

## Key Results
- SHERPA improves performance in 12 out of 15 tested configurations across three tasks
- Class name generation shows largest gains (average 6.58 percentage points improvement in F1-score)
- Code generation improves by 3.25 percentage points in Pass@1 metric
- Optimized state machine designs achieve approximately 50% fewer LLM calls while maintaining comparable performance

## Why This Works (Mechanism)

### Mechanism 1: Explicit Task Decomposition
SHERPA's hierarchical state machines encode human best practices as sequential or conditional sub-tasks, forcing LLMs to execute one sub-task at a time rather than attempting complex reasoning in a single pass. This decomposition is particularly effective when well-established human workflows exist for the task.

### Mechanism 2: Persistent Belief Structures
The framework maintains explicit belief structures containing execution history and intermediate results, providing persistent context that improves decision-making across state transitions. This structured memory enables better policy decisions than relying solely on current prompt context.

### Mechanism 3: Hybrid Policy Design
SHERPA combines rule-based, LLM-based, and fast-forward policies with decoupled state machine design, enabling balancing of performance, cost, and flexibility. The framework separates SM structure from action implementation, allowing rapid experimentation without code changes.

## Foundational Learning

- **Hierarchical State Machines (Statecharts)**: Core control structure using states, transitions, events, guards, and composite states. *Why needed:* SHERPA's fundamental architecture for task decomposition. *Quick check:* Can you sketch a state machine for making coffee that handles the case where the water reservoir is empty?

- **LLM Token Limits and Context Windows**: Belief structures and policy prompts must fit within LLM context windows. *Why needed:* Framework uses sliding-window truncation to manage context limits. *Quick check:* If your belief trajectory grows to 50k tokens but your LLM has 32k context window, what happens and how would you mitigate it?

- **Separation of Control Flow from Action Implementation**: SHERPA stores SMs as data (JSON) while actions remain code. *Why needed:* Enables rapid experimentation without recompilation. *Quick check:* If you wanted to add a new validation step to your code generation SM, would you modify the SM definition or the action code?

## Architecture Onboarding

- **Component map:** User event -> Belief structure -> Policy (rule/LLM/hybrid) -> State Machine (JSON) -> Actions (code) -> LLM -> Belief update -> Repeat
- **Critical path:** 1) User event received â†’ recorded in belief; 2) SM evaluates available transitions; 3) Policy selects transition (or fast-forward auto-selects); 4) Transition executes: guard conditions checked, actions invoked; 5) Action outputs written to belief; 6) SM updates current state and trajectory; 7) Repeat until end state or external wait
- **Design tradeoffs:** Granularity vs. cost (more states = more control but more LLM calls); LLM-based vs. rule-based policy (flexible but expensive vs. deterministic but rigid); SM complexity vs. maintainability (deep hierarchies enable reuse but harder to debug); belief size vs. context window (more information helps decisions but risks truncation)
- **Failure signatures:** Infinite loops (SM cycles without reaching end state - paper sets max transitions = 10); policy confusion (LLM selects wrong transition when multiple similar options exist); belief explosion (key-value store grows unbounded, causing context overflow); action failures (external tool or LLM call fails repeatedly without fallback)
- **First 3 experiments:** 1) Minimal routing SM for multi-type QA (3-state SM on 20 questions; measure vs. direct prompting); 2) Cost optimization via SM restructuring (agent coder to test-driven SM; compare LLM call counts while holding performance constant); 3) Policy ablation (run same SM with rule-based vs. LLM-based policy; measure performance difference and cost ratio)

## Open Questions the Paper Calls Out

1. Can reinforcement learning (RL)-based policies effectively optimize state transitions within the SHERPA framework?
2. Does SHERPA provide performance benefits for larger LLMs when applied to tasks significantly more complex than current benchmarks?
3. How effectively does SHERPA generalize to domains beyond software engineering and visual reasoning?

## Limitations

- Performance benefits are task-dependent and work best when explicit human best practices exist for the task
- Current validation relies on three curated datasets, limiting generalizability to open-ended generation problems
- Framework's end-to-end cost savings are unclear due to overhead from belief maintenance and policy evaluation

## Confidence

**High Confidence:** Core architectural contribution (separating SM control flow from action implementation) is technically sound and demonstrated through reproducible performance gains
**Medium Confidence:** Performance improvement claims depend on specific SM designs that may not generalize to new tasks without extensive trial-and-error
**Low Confidence:** Assertion that smaller LLMs benefit more consistently from state machine integration is based on limited data (only three model sizes tested)

## Next Checks

1. **Cross-Task Transferability Test:** Apply best-performing SM from class name generation to structurally similar task (variable naming in code) and measure whether performance gains persist
2. **Belief Structure Stress Test:** Implement unbounded execution scenario and measure when sliding-window truncation causes performance degradation; identify context window threshold where belief becomes ineffective
3. **End-to-End Cost Analysis:** Implement full execution timing and token counting for all framework components versus baseline prompting; calculate net cost savings per task type to validate claimed efficiency benefits