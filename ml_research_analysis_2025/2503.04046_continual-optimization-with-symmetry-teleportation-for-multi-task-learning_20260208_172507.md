---
ver: rpa2
title: Continual Optimization with Symmetry Teleportation for Multi-Task Learning
arxiv_id: '2503.04046'
source_url: https://arxiv.org/abs/2503.04046
tags:
- teleportation
- gradient
- conflict
- learning
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles the fundamental optimization challenges in
  multi-task learning (MTL): gradient conflicts and task imbalance. Unlike prior methods
  that reweight losses or gradients, the authors propose a novel Continual Optimization
  with Symmetry Teleportation (COST) approach that identifies loss-equivalent parameter
  points with reduced conflicts via low-rank adapter (LoRA)-based teleportation.'
---

# Continual Optimization with Symmetry Teleportation for Multi-Task Learning

## Quick Facts
- arXiv ID: 2503.04046
- Source URL: https://arxiv.org/abs/2503.04046
- Reference count: 32
- Primary result: Novel LoRA-based teleportation method achieves state-of-the-art multi-task learning performance by finding loss-equivalent parameter points with reduced gradient conflicts

## Executive Summary
This paper addresses fundamental optimization challenges in multi-task learning (MTL): gradient conflicts and task imbalance. Unlike prior methods that reweight losses or gradients, the authors propose Continual Optimization with Symmetry Teleportation (COST), which identifies loss-equivalent parameter points with reduced conflicts via low-rank adapter (LoRA)-based teleportation. The method uses two key objectives: loss invariance and gradient maximization (via sharpness), combined with a historical trajectory reuse strategy to maintain advanced optimizer benefits. Extensive experiments on CityScapes, NYUv2, CelebA, and QM9 datasets demonstrate COST's effectiveness, achieving state-of-the-art performance when integrated with existing methods.

## Method Summary
COST is a multi-task learning optimization method that addresses gradient conflicts through symmetry teleportation using LoRA adapters. The approach detects dominated conflicts (where the mean gradient opposes task gradients), then optimizes LoRA parameters to find loss-equivalent points with reduced conflicts. The LoRA objective combines loss invariance (minimizing deviation from pre-teleportation loss) and gradient maximization (via sharpness estimation through random sampling). After teleportation, a Historical Trajectory Reuse strategy preserves Adam optimizer benefits by modulating momentum and variance estimates based on the teleportation direction's alignment with pre-teleportation gradients.

## Key Results
- Achieves state-of-the-art performance on CityScapes, NYUv2, CelebA, and QM9 datasets when integrated with existing MTL methods
- Demonstrates plug-and-play capability, improving diverse MTL approaches including FairGrad and LS
- Shows conflict examinations confirming ability to find non-conflicting, more convergent optimization paths
- Maintains computational efficiency with negligible overhead per teleportation event

## Why This Works (Mechanism)

### Mechanism 1
LoRA-based teleportation finds loss-equivalent parameter points with reduced gradient conflicts. When dominated conflict is detected, a LoRA adapter is optimized using dual objectives: loss invariance (Lt minimizing deviation from pre-teleportation loss) and gradient maximization (Lg using sharpness estimation via sampling perturbations). The combined objective Llora = Lt - γLg is optimized, then LoRA weights are merged into backbone. Core assumption: Loss level sets contain points with differing conflict status; sharpness correlates with gradient magnitude.

### Mechanism 2
Dominated conflict detection identifies optimization-impeding conflicts requiring intervention. Distinguishes weak conflict (cos ϕij < 0 between task gradients) from dominated conflict (mean gradient g0 conflicts with task gradient gi). Trigger condition: K/2 or more tasks show dominated conflict, reducing teleportation frequency while maintaining effectiveness. Core assumption: Dominated conflicts, not weak conflicts, are the primary optimization barrier; frequent teleportation is computationally inefficient.

### Mechanism 3
Historical Trajectory Reuse preserves Adam optimizer benefits post-teleportation. Teleportation disrupts Adam's momentum (vt) and variance (st) estimates. HTR computes σ = cos_sim(Δθ, g') between teleportation direction and pre-teleportation gradient, then modulates: vt = σβ1vt-1 + (1-σβ1)gt. This preserves trajectory components aligned with teleportation direction. Core assumption: Partial preservation of historical moments improves convergence over resetting or using full trajectory.

## Foundational Learning

- Concept: **Pareto Stationarity in Multi-Objective Optimization**
  - Why needed here: COST's convergence guarantee relies on Pareto stationary points; understanding why gradient conflicts prevent Pareto efficiency is essential.
  - Quick check question: Given two task gradients g1 = [1, 2] and g2 = [-1, 1], is this a weak conflict? Would linear scalarization reach a Pareto stationary point?

- Concept: **Parameter Space Symmetries in Neural Networks**
  - Why needed here: Symmetry teleportation exploits that multiple parameter configurations yield identical outputs (e.g., neuron permutations, weight rescaling with inverse activation rescaling).
  - Quick check question: For a 2-layer ReLU network, name two parameter transformations that preserve the function f(x).

- Concept: **Sharpness and Generalization Connection**
  - Why needed here: COST uses sharpness (loss sensitivity to perturbations) as proxy for gradient magnitude, borrowing from SAM literature.
  - Quick check question: Why does maximizing sharpness at a point potentially indicate larger gradient norm? What's the computational advantage over direct gradient computation?

## Architecture Onboarding

- Component map: Shared Backbone -> LoRA Module -> Task-Specific Branches -> Conflict Monitor -> HTR Module
- Critical path:
  1. Standard MTL optimization (e.g., FairGrad) proceeds normally
  2. Conflict monitor detects K/2 dominated conflicts → trigger teleportation
  3. Freeze backbone, initialize LoRA, optimize Llora = Lt - γLg for ~100-500 iterations
  4. Merge LoRA into backbone (θ ← θ + Δθ)
  5. Apply HTR: compute σ, modulate Adam moments
  6. Resume standard optimization

- Design tradeoffs:
  - **Trigger frequency vs. effectiveness**: K/2 threshold balances conflict resolution with compute overhead (Figure 5a shows 97%→lower ratio on CelebA)
  - **LoRA rank vs. teleportation expressiveness**: Higher rank explores more of loss level set but increases compute
  - **γ (sharpness weight)**: Controls exploration of high-gradient regions vs. strict loss preservation
  - **Sharpness samples ñ**: More samples improve gradient estimation but linearly increase cost

- Failure signatures:
  - Lt not converging: LoRA updates harm task losses; check learning rate, reduce γ
  - No conflict reduction post-teleportation: Loss level set may lack non-conflicting points; verify on toy example first
  - Performance degradation without HTR: Large-angle teleportations (σ near 0 or negative); check Δθ vs. g' alignment
  - QM9-style failure (minimal improvement): Insufficient layers support LoRA (paper notes only 2 layers available)

- First 3 experiments:
  1. **Toy 2-task validation**: Replicate Figure 6 trajectory visualization. Confirm teleportation finds alternative paths when LS fails. Expected: COST enables convergence to Pareto front from adversarial initializations.
  2. **Ablation by component**: Remove Lt, Lg, HTR individually (Table 4). Verify Lt is critical (loss invariance), Lg provides directional benefit, HTR provides ~7% relative improvement. Expected: Lt removal causes catastrophic degradation.
  3. **Plug-and-play integration**: Add COST to weak baseline (LS) and strong baseline (FairGrad) on CityScapes 2-task. Expected: Both improve, confirming orthogonality to underlying MTL method.

## Open Questions the Paper Calls Out

### Open Question 1
How does the number of applicable LoRA layers impact the effectiveness of symmetry teleportation in non-convolutional architectures like Graph Neural Networks?
- Basis in paper: Page 7, Section 5.1 notes that the QM9 regression task saw fewer improvements because the graph model supported LoRA on only two layers.
- Why unresolved: The paper identifies the limited number of LoRA-supported layers as a cause for "less satisfactory results" but does not propose a solution or quantify the required capacity for effective teleportation in such architectures.
- What evidence would resolve it: Experiments varying the depth of LoRA application in GNNs or analyzing the correlation between teleportation success rates and the number of parameters perturbed by the adapter.

### Open Question 2
Can a dynamic or learned trigger mechanism outperform the fixed $K/2$ threshold for initiating teleportation?
- Basis in paper: Page 4, Section 4.1 states the authors "analyze the trade-off between effectiveness and efficiency" for the trigger condition, acknowledging that the choice of $K/2$ is a heuristic to reduce frequency.
- Why unresolved: While the fixed threshold reduces computational load, it may miss optimization opportunities or trigger unnecessarily in diverse loss landscapes; the paper does not explore adaptive triggering.
- What evidence would resolve it: A comparison of the current fixed-threshold method against a policy-gradient-based or loss-variance-based adaptive trigger in terms of final performance and teleportation frequency.

### Open Question 3
Is maximizing sharpness (gradient norm) always a sufficient proxy for finding the optimal teleportation point in complex MTL landscapes?
- Basis in paper: Page 5, Section 4.1 explains that sharpness was chosen as a metric because computing the Hessian matrix is "overly burdensome," utilizing a random sampling approximation.
- Why unresolved: The paper relies on an approximation to avoid computational costs but does not theoretically guarantee that the sampled sharpness aligns perfectly with the ideal teleportation vector in deep models.
- What evidence would resolve it: A theoretical analysis or empirical comparison between the sharpness-based objective and a Hessian-based teleportation objective on a smaller scale where the Hessian is tractable.

## Limitations

- Hyperparameter sensitivity: Critical teleportation hyperparameters (γ, sharpness sampling count, LoRA rank) are not specified, raising reproducibility concerns
- Task reconcilable assumption: Approach assumes non-conflicting points exist on loss level sets, which may not hold for fundamentally competing tasks
- Computational overhead: While stated as "negligible," the aggregate overhead from frequent teleportation phases remains unclear

## Confidence

- **High Confidence**: Core conflict detection mechanism, experimental results showing Δm% improvements across datasets, plug-and-play integration capability with existing MTL methods
- **Medium Confidence**: Sharpness maximization effectively finds high-gradient regions for conflict reduction, HTR strategy preserves Adam benefits, claim of "symmetry" exploitation
- **Low Confidence**: Mechanism by which LoRA-based teleportation exploits "symmetry" in parameter spaces, generalizability of K/2 trigger threshold, state-of-the-art performance claims given limited comparison scope

## Next Checks

1. **Ablation Study Replication**: Reproduce Table 4 to verify that removing Lt causes catastrophic degradation, Lg provides directional benefit, and HTR contributes ~7% relative improvement, validating all three components are necessary for optimal performance.

2. **Hyperparameter Sensitivity Analysis**: Systematically vary γ, LoRA rank, and sharpness sampling count across a subset of tasks to determine sensitivity and establish robust default values, addressing reproducibility concerns.

3. **Computational Overhead Measurement**: Measure actual wall-clock time added by teleportation across full training runs, comparing against baseline MTL methods, to validate "negligible" overhead claim and reveal practical deployment considerations.