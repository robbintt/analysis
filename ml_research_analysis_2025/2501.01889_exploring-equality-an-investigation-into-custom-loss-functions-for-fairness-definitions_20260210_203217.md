---
ver: rpa2
title: 'Exploring Equality: An Investigation into Custom Loss Functions for Fairness
  Definitions'
arxiv_id: '2501.01889'
source_url: https://arxiv.org/abs/2501.01889
tags:
- page
- compas
- fairness
- accuracy
- arxivpreprintarxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates fairness in the COMPAS recidivism prediction
  algorithm by implementing and testing a novel Group Accuracy Parity (GAP) framework
  alongside traditional fairness metrics. The authors propose a combined Pareto frontier
  and multivariate analysis methodology to systematically compare fairness and accuracy
  trade-offs across different optimization approaches.
---

# Exploring Equality: An Investigation into Custom Loss Functions for Fairness Definitions

## Quick Facts
- arXiv ID: 2501.01889
- Source URL: https://arxiv.org/abs/2501.01889
- Authors: Gordon Lee; Simeon Sayer
- Reference count: 0
- One-line primary result: Custom Group Accuracy Parity (GAP) loss function achieves improved balance between fairness and accuracy compared to COMPAS's current implementation and traditional fairness metrics.

## Executive Summary
This paper investigates fairness in the COMPAS recidivism prediction algorithm by implementing and testing a novel Group Accuracy Parity (GAP) framework alongside traditional fairness metrics. The authors propose a combined Pareto frontier and multivariate analysis methodology to systematically compare fairness and accuracy trade-offs across different optimization approaches. Using neural networks trained on the COMPAS dataset with custom loss functions, they demonstrate that GAP achieves improved balance between fairness and accuracy compared to COMPAS's current implementation and models optimized for traditional fairness definitions like equalized odds. The analysis reveals that demographic variables such as age and prior convictions serve as proxies for race, complicating fairness assessments. The paper also highlights that algorithmic improvements alone cannot ensure fairness without addressing external biases from practices like predictive policing and lack of transparency in COMPAS's internal workings.

## Method Summary
The paper implements a custom Group Accuracy Parity (GAP) loss function for neural network training on the COMPAS recidivism prediction task. GAP combines Weighted Binary Cross-Entropy (wBCE) to handle class imbalance with an Accuracy Difference (AD) penalty term to minimize accuracy gaps between protected groups. The authors train neural networks on filtered COMPAS data (7,214 defendants from Broward County, FL, ages 18-40, African American and Caucasian groups) and evaluate performance using confusion matrices, Pareto frontier analysis, and violin plot distributions. The methodology compares GAP against standard binary cross-entropy and COMPAS's current implementation across multiple fairness definitions including Equalized Odds, Disparate Impact, and Equal Opportunity.

## Key Results
- GAP loss function achieves improved balance between fairness and accuracy compared to COMPAS's current implementation
- Age and prior convictions serve as almost-perfect proxies for race, complicating fairness assessments
- Algorithmic improvements alone cannot ensure fairness without addressing external biases from practices like predictive policing
- Models cannot satisfy multiple fairness definitions simultaneously due to inherent trade-offs

## Why This Works (Mechanism)

### Mechanism 1
The Group Accuracy Parity (GAP) loss function enables neural networks to optimize for balanced detection accuracy across demographic groups. GAP combines Weighted Binary Cross-Entropy (wBCE) to handle class imbalance with an Accuracy Difference (AD) penalty term. The wBCE component minimizes overall error while the AD component penalizes accuracy gaps between protected groups, creating gradient signals that push toward Accuracy Parity (AP). This works when group-level accuracy parity is achievable through differentiable optimization without requiring discrete fairness ratio calculations.

### Mechanism 2
Pareto frontier analysis provides a systematic baseline for comparing fairness-accuracy trade-offs across different optimization approaches. For each fairness definition, identify the model accuracy at the point of "perfect fairness" (difference = 0 or ratio = 1). This establishes a baseline from which trade-offs can be measured as you move away from perfect fairness toward higher accuracy. This methodology assumes the accuracy at perfect fairness represents a meaningful and comparable baseline across different fairness definitions.

### Mechanism 3
Violin graph similarity analysis reveals proxy relationships between protected attributes and ostensibly neutral features. Compare distribution shapes (violin plots) of variables across protected groups and outcome classes. High visual similarity between a protected group's distribution and an outcome distribution indicates that the features serving that prediction are acting as proxies for the protected attribute. This approach assumes distributional similarity in violin plots indicates meaningful proxy relationships that propagate bias.

## Foundational Learning

- Concept: **Differentiable Loss Functions for Neural Networks**
  - Why needed here: Traditional fairness metrics (ratios of false positives/negatives) are discrete and non-differentiable, making them unusable for gradient-based optimization. Understanding why GAP requires modification of cross-entropy is essential.
  - Quick check question: Can you explain why a loss function based on "ratio of false positives between groups" cannot be directly optimized via backpropagation?

- Concept: **Arrow's Impossibility Theorem Applied to Fairness**
  - Why needed here: The paper notes that models cannot satisfy multiple fairness definitions simultaneously. This constrains what any single loss function can achieve.
  - Quick check question: If a model achieves Equalized Odds, can it simultaneously guarantee Demographic Parity? Why or why not?

- Concept: **Proxy Variables and Feature Independence**
  - Why needed here: The paper's central finding is that removing race from features doesn't eliminate racial bias because age and prior convictions proxy for race. Understanding feature correlations is critical for interpreting fairness results.
  - Quick check question: Given two features X₁ (age) and X₂ (prior convictions) that jointly predict protected attribute A (race), would removing A from training data eliminate disparate impact?

## Architecture Onboarding

- Component map:
  Input Layer -> Custom Loss Function (GAP) -> Neural Network Backbone -> Evaluation Pipeline (Confusion Matrices, Pareto Frontier, Violin Graphs)

- Critical path:
  1. Load and filter COMPAS dataset to valid demographic groups
  2. Implement GAP loss function with wBCE for label imbalance
  3. Train neural network with GAP loss (expect high volatility—multiple restarts needed)
  4. Generate per-group confusion matrices and compute fairness metrics
  5. Build Pareto frontier by varying fairness-accuracy trade-off weight
  6. Run violin graph analysis to detect proxy variables before deployment

- Design tradeoffs:
  - **Interpretability vs. Accuracy**: Neural networks provide better accuracy but are "black boxes"—harder to audit for fairness
  - **Fairness Definition Selection**: No single model can satisfy all fairness definitions; choice depends on institutional priorities
  - **Volatility vs. Reproducibility**: GAP shows high variance across runs; paper notes "we may need more data"

- Failure signatures:
  - **High GAP volatility**: Confusion matrices vary significantly across training runs
  - **Proxy variable contamination**: Removing race from features does not eliminate disparate outcomes when age/priors correlate with race
  - **Pareto frontier unreliability**: When variables are interdependent, frontier analysis becomes unstable

- First 3 experiments:
  1. **Baseline Reproduction**: Train a standard neural network with binary cross-entropy on COMPAS data. Compute per-group accuracy, FPR, and FNR. Compare to paper's Figure H results (accuracy ~0.67).
  2. **GAP Loss Ablation**: Implement GAP loss with varying λ values for the accuracy difference penalty. Plot the Pareto frontier of accuracy vs. accuracy parity. Verify if your frontier shows similar trade-offs to Figure J.
  3. **Proxy Detection Test**: Create violin plots for age and prior convictions stratified by (a) race and (b) recidivism outcome. Quantify similarity using distribution distance metrics (e.g., KL divergence) rather than visual inspection alone.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is GAP the optimal fairness framework for recidivism prediction, or do other fairness definitions produce superior accuracy-fairness tradeoffs?
- Basis in paper: "While the paper is unsure of whether GAP is the best choice of a fairness framework, its implementation of GAP shows that the fairness framework is implementable."
- Why unresolved: The paper only tested GAP against limited baselines and did not systematically compare it against other custom loss functions.
- What evidence would resolve it: A comprehensive comparison of multiple fairness-optimized loss functions using the Pareto frontier methodology across diverse criminal justice datasets.

### Open Question 2
- Question: What dataset size and model configurations are required to achieve stable GAP outcomes given its observed volatility?
- Basis in paper: "GAP is highly volatile, requiring numerous iterations of trials to achieve the confusion matrices shown in Figure F and Figure G. This observation indicates that we may need more data."
- Why unresolved: The paper identifies volatility as a limitation but does not investigate its causes or minimum stability requirements.
- What evidence would resolve it: Systematic experiments varying training data size, network depth, and learning rates to identify stability thresholds.

### Open Question 3
- Question: How can proxy variables that encode protected attributes be systematically detected and accounted for in fairness optimization?
- Basis in paper: The paper demonstrates that "age and prior convictions... serve as an almost-perfect proxy for race" and that "simply removing race from COMPAS does not eliminate its racial bias," but offers no solution for handling proxies.
- Why unresolved: The paper identifies the proxy problem as fundamental to fairness but leaves the methodological challenge unaddressed.
- What evidence would resolve it: Development of proxy detection metrics and fairness-aware training methods that jointly account for correlated non-protected variables.

## Limitations

- GAP loss function specification is incomplete, with unclear weighting between wBCE and accuracy difference penalty
- Neural network architecture details are omitted, making exact reproduction difficult
- High volatility of GAP results across runs suggests sensitivity to initialization and hyperparameters not controlled for
- Proxy variable detection relies primarily on visual violin plot comparison rather than quantitative measures

## Confidence

- **High confidence**: The fundamental insight that age and prior convictions serve as proxies for race in COMPAS data, undermining fairness gains from removing race as a feature
- **Medium confidence**: The Pareto frontier methodology for comparing fairness-accuracy trade-offs is conceptually sound, though its reliability when variables are highly correlated is questionable
- **Low confidence**: The specific GAP loss function implementation and its superiority over standard fairness-aware optimization approaches

## Next Checks

1. Implement quantitative proxy detection by computing distribution distance metrics (KL divergence, Wasserstein distance) between protected attribute distributions and proxy features, replacing visual violin plot comparison.
2. Conduct sensitivity analysis of GAP results across multiple random seeds and hyperparameter settings to quantify volatility and establish confidence intervals for fairness-accuracy trade-offs.
3. Test whether the observed Pareto frontier shape is robust to different base rate scenarios by subsampling the COMPAS dataset to create groups with different recidivism rates, examining whether the frontier methodology breaks down as intended under variable correlation.