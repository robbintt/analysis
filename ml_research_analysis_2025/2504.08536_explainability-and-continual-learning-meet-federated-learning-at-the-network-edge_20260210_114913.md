---
ver: rpa2
title: Explainability and Continual Learning meet Federated Learning at the Network
  Edge
arxiv_id: '2504.08536'
source_url: https://arxiv.org/abs/2504.08536
tags:
- data
- learning
- each
- training
- buffer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper identifies key optimization challenges in Federated
  Learning at the network edge, focusing on three interconnected areas: Explainable
  AI with surrogate models, distributed decision tree learning, and online Continual
  Learning with replay buffers. The authors propose a Multi-objective optimization
  framework to balance predictive accuracy and explainability when using complex black-box
  models alongside interpretable surrogates.'
---

# Explainability and Continual Learning meet Federated Learning at the Network Edge

## Quick Facts
- arXiv ID: 2504.08536
- Source URL: https://arxiv.org/abs/2504.08536
- Authors: Thomas Tsouparopoulos; Iordanis Koutsopoulos
- Reference count: 26
- Primary result: Proposes frameworks for explainable AI, distributed decision trees, and continual learning in federated edge settings using multi-objective optimization, ensemble methods, and replay buffers.

## Executive Summary
This paper addresses key optimization challenges in Federated Learning at the network edge by integrating Explainable AI, distributed decision tree learning, and online Continual Learning. The authors propose a Multi-objective optimization framework to jointly optimize predictive accuracy and explainability using surrogate models. They explore the challenges of training interpretable decision trees in distributed settings due to non-differentiable structures and propose ensemble-based workarounds. Additionally, they investigate how Continual Learning strategies, particularly replay buffers, can be effectively combined with Federated Learning to support adaptive learning in resource-limited environments.

## Method Summary
The paper proposes three interconnected frameworks: (1) Multi-objective optimization to balance predictive accuracy and explainability by training a black-box model and an interpretable surrogate concurrently; (2) Distributed decision tree learning using ensemble methods to overcome non-differentiable structure challenges; and (3) Federated Continual Learning with replay buffers to mitigate catastrophic forgetting. The approaches are formulated mathematically but lack experimental validation, making this a conceptual framework paper.

## Key Results
- Multi-objective optimization can address accuracy-explainability trade-offs in federated settings
- Decision tree ensembles offer a workaround for non-differentiable structure challenges in federated training
- Replay buffers with capacity constraints can mitigate catastrophic forgetting in online continual learning
- Local vs. global buffer architectures present different tradeoffs in federated continual learning
- Ensemble diversity compensates for lack of direct gradient-based aggregation in federated trees

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-objective optimization can jointly balance predictive accuracy and explainability by concurrently training a black-box model and an interpretable surrogate.
- Mechanism: Bi-level optimization with upper level minimizing prediction loss and Point Fidelity loss (disagreement between models), while lower level optimizes surrogate parameters to approximate black-box.
- Core assumption: Pareto front between accuracy and fidelity is reachable via gradient-based methods in distributed settings.
- Evidence anchors: [abstract] MOO addresses accuracy-explainability trade-off; [Section III-A, Eq. 3-4] Bi-level formulation; [corpus] No experimental validation found.
- Break condition: Highly heterogeneous client data preventing single global solution; resource constraints blocking Pareto front approximation.

### Mechanism 2
- Claim: Federated training of interpretable decision trees is challenging due to non-differentiable structure, but ensemble methods can partially circumvent this.
- Mechanism: Single DT training requires greedy recursive partitioning based on local impurity measures; ensembles allow independent tree training across clients with subsequent aggregation.
- Core assumption: Ensemble diversity compensates for lack of direct gradient-based aggregation.
- Evidence anchors: [Section IV-B] Challenges of federated DT training; [Section IV-B-2] Federated Random Forests and Gradient Boosting as workarounds; [corpus] No validation found.
- Break condition: Deep trees requiring frequent split synchronization; strict privacy constraints; highly heterogeneous feature distributions.

### Mechanism 3
- Claim: Replay buffers with capacity B, combined with loss Lt = βL_Dt + (1-β)L_Bt, mitigate catastrophic forgetting in online continual learning.
- Mechanism: Incoming batch combines with buffer samples; buffer update policies (Reservoir Sampling, CBRS, KLRS) determine retention; each client maintains local buffer in FL.
- Core assumption: Buffer size B is sufficient to store representative samples across all observed classes.
- Evidence anchors: [Section V-A, Eq. 12] Combined loss formulation; [Section V-B, Eq. 13] Federated aggregation; [corpus] No direct validation found.
- Break condition: Severe class imbalance where minority classes are underrepresented; communication constraints preventing timely updates.

## Foundational Learning

- **Federated Learning (FedAvg)**
  - Why needed here: Core distributed training paradigm; all three mechanisms extend FL to explainability, trees, and continual learning.
  - Quick check question: Can you explain how local model updates are aggregated at the server without sharing raw data?

- **Pareto Optimality in Multi-Objective Optimization**
  - Why needed here: Mechanism 1 formulates accuracy-explainability trade-off as MOO; understanding Pareto fronts is essential for navigating conflicting objectives.
  - Quick check question: Given two objectives that conflict, can you sketch why improving one typically degrades the other?

- **Catastrophic Forgetting in Continual Learning**
  - Why needed here: Mechanism 3 addresses forgetting via replay buffers; grasping why neural networks forget is prerequisite to understanding buffer design.
  - Quick check question: Why does training on new data cause performance degradation on previously learned tasks?

## Architecture Onboarding

- **Component map:**
  - Clients (M edge devices) -> Server (optional) -> Communication layer
  - Each client holds private datasets, trains local models, maintains replay buffers

- **Critical path:**
  1. Initialize global model parameters
  2. Each client k receives parameters, performs local training on data plus buffer
  3. Clients transmit updates to server; server aggregates via FedAvg
  4. For MOO: concurrently optimize accuracy and fidelity using gradient-based MOO
  5. For CL: update local buffers using RS/CBRS/KLRS policies before next round

- **Design tradeoffs:**
  - Local vs. global buffers: Local enables personalization but may lack diversity; global simplifies coordination but incurs overhead
  - Single DT vs. ensembles: Single trees are interpretable but hard to federate; ensembles are more federable but less interpretable
  - Accuracy vs. explainability (MOO): Higher fidelity may reduce predictive performance

- **Failure signatures:**
  - MOO divergence: Conflicting gradients cause oscillation without convergence
  - Buffer starvation: Minority classes absent from all local buffers → global model forgets
  - Tree aggregation failure: Incompatible local tree structures cannot merge coherently
  - Communication collapse: Bandwidth constraints prevent timely updates → stale global model

- **First 3 experiments:**
  1. Validate MOO formulation on synthetic FL setup with 5-10 clients; measure Pareto front between accuracy and fidelity
  2. Ablate buffer policies in centralized CL: Reservoir Sampling vs. CBRS vs. KLRS on non-stationary stream
  3. Pilot federated random forest aggregation with 3-5 clients; evaluate global model interpretability and accuracy vs. single DT baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can efficient, real-time approximation methods for Multi-objective optimization (MOO) be developed for Federated Learning that provide theoretical guarantees on convergence?
- Basis in paper: [explicit] Authors state computing exact Pareto front is intractable and call for approximation methods with theoretical convergence guarantees.
- Why unresolved: Gradient-based MOO algorithms lack strong theoretical guarantees in FL settings with data heterogeneity and conflicting objectives.
- What evidence would resolve it: Novel FL-MOO algorithm with mathematically proven convergence rate operating efficiently on edge devices.

### Open Question 2
- Question: How can a shared global feature partitioning scheme be designed to ensure structural homogeneity in distributed decision trees across heterogeneous clients?
- Basis in paper: [explicit] Identifies structural discrepancies as challenge and proposes constrained tree growth strategies with shared global feature partitioning.
- Why unresolved: Non-differentiable nature of DTs prevents standard gradient-based aggregation, and local data heterogeneity causes local splits to diverge.
- What evidence would resolve it: Aggregation protocol that aligns local split decisions to global structure without compromising privacy or performance.

### Open Question 3
- Question: Can a centralized replay buffer allocation be dynamically optimized by rigorously quantifying real-time statistical variation of each client's data distribution?
- Basis in paper: [explicit] Identifies need for adaptive buffer-sharing mechanism tailored to temporal variability of each client's data.
- Why unresolved: Current challenge to detect and quantify statistical distribution shifts in real-time to inform resource allocation decisions.
- What evidence would resolve it: Metric or protocol that measures distribution changes and correlates larger buffer allocations with higher data variability.

## Limitations
- No experimental validation provided for any proposed frameworks
- Critical implementation details omitted (architectures, hyperparameters, aggregation logic)
- Federated explainability formulation remains abstract without specific algorithm selection
- Buffer allocation in heterogeneous settings lacks rigorous dynamic optimization protocol
- Communication constraints and their impact on federated continual learning not quantified

## Confidence
- MOO accuracy-explainability trade-off: **Medium** (theoretical soundness, no experimental validation)
- Federated DT ensembles: **Medium** (algorithmic workarounds proposed, no empirical evidence)
- FCL with replay buffers: **Medium** (buffer strategies discussed, no distributed evaluation)

## Next Checks
1. Implement MOO formulation on heterogeneous FL setup; measure Pareto front and divergence under client heterogeneity
2. Evaluate replay buffer policies (RS vs. CBRS) in centralized CL; quantify forgetting per class under imbalance
3. Pilot federated random forest aggregation with 3-5 clients; compare global model accuracy and interpretability against single DT baseline