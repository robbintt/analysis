---
ver: rpa2
title: 'FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial
  Datasets'
arxiv_id: '2509.20904'
source_url: https://arxiv.org/abs/2509.20904
tags:
- retrieval
- items
- sids
- base
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'FORGE introduces a large-scale industrial benchmark for semantic
  identifiers in generative retrieval, addressing three main challenges: lack of large
  multimodal datasets, limited SID optimization research, and slow online convergence.
  It provides a 14-billion-interaction dataset with multimodal features from Taobao
  and proposes optimizations including enhanced data modalities, ID collision mitigation,
  and novel evaluation metrics (embedding hitrate and Gini coefficient).'
---

# FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets

## Quick Facts
- **arXiv ID**: 2509.20904
- **Source URL**: https://arxiv.org/abs/2509.20904
- **Reference count**: 40
- **Primary result**: Introduces large-scale industrial benchmark for semantic identifiers in generative retrieval with 14-billion-interaction multimodal dataset from Taobao

## Executive Summary
FORGE addresses three critical gaps in generative retrieval research: the lack of large-scale industrial datasets with multimodal features, limited exploration of semantic identifier (SID) optimization, and slow online convergence of GR models. The benchmark provides a 14-billion-interaction dataset from Taobao with text, image, and side information features, along with novel evaluation metrics (embedding hitrate and Gini coefficient) that correlate with retrieval performance. FORGE's optimizations—including multimodal contrastive alignment, collision mitigation strategies, and offline pretraining—achieve a 0.35% increase in transaction count in production while halving convergence time.

## Method Summary
FORGE introduces a comprehensive framework for optimizing semantic identifiers in generative retrieval. The approach combines multimodal contrastive pretraining using InfoNCE loss over item-to-item (i2i) relationships and side information, residual quantization VAE (RQ-VAE) to convert embeddings into hierarchical discrete codes, and collision mitigation through KNN or random post-processing policies. Novel proxy metrics (embedding hitrate measuring collaborative signal quality and Gini coefficient measuring SID utilization fairness) enable training-free SID evaluation. Offline pretraining on user action data accelerates online convergence. The system achieves strong performance improvements across multiple stages of the industrial recommendation pipeline.

## Key Results
- Production deployment achieved 0.35% increase in transaction count
- Offline pretraining halved online convergence time
- Embedding hitrate and Gini coefficient strongly correlate with downstream GR hitrate
- Random-5 collision policy outperformed KNN-5 on HR@20 despite weaker semantic grounding
- Multimodal contrastive alignment with i2i and side information improved HR@1000 by >5%

## Why This Works (Mechanism)

### Mechanism 1: Multimodal Contrastive Alignment Improves SID Quality
- Claim: Incorporating collaborative item relationships (i2i) and side information into contrastive learning yields SIDs that improve retrieval hitrate at high recall thresholds.
- Mechanism: The InfoNCE loss aligns text/image representations of co-occurring items, so items frequently interacted together get similar embeddings; these embeddings are then quantized into SIDs via RQ-VAE. Richer signals (seller, category, i2i relations) propagate into the discrete codes.
- Core assumption: Co-occurrence patterns capture meaningful semantic similarity relevant to downstream retrieval.
- Evidence anchors:
  - [Section 3.1]: Equations 1–2 define multimodal fusion and InfoNCE loss over positives (i2i) and in-batch negatives.
  - [Table 2]: +i2i and +sideinfo improve HR@1000 by >5% across stages despite mixed HR@20 results.
  - [Table 15]: Additional ablation confirms query2i and samecate underperform vs. +i2i.
- Break condition: If i2i signals are noisy or sparse (e.g., cold-start items), alignment may degrade; embedding hitrate can flag this before GR training.

### Mechanism 2: Collision Mitigation Shifts Performance via Utilization Over Pure Semantics
- Claim: Enforcing fair SID distribution (reducing collisions) improves retrieval more than preserving exact semantic precision at the final codebook level.
- Mechanism: KNN-based policy rejects SIDs exceeding a capacity threshold; random-based policy cycles through final-level codewords. Both improve codebook utilization and reduce Gini coefficient.
- Core assumption: Hierarchical residual quantization makes final-level semantics weak; balancing utilization yields better GR training signal.
- Evidence anchors:
  - [Section 3.2]: Describes both post-processing strategies.
  - [Table 2]: Random-5 outperforms KNN-5 on HR@20 (e.g., +29.36% vs +15.79% on S1), despite weaker semantic grounding.
  - [Table 14]: noco (no collision handling) drops HR@20 by ~18%, showing collisions hurt.
- Break condition: If semantic granularity is critical for a domain (e.g., fine-grained attribute search), random assignment at final level may harm precision.

### Mechanism 3: Proxy Metrics Enable Training-Free SID Evaluation
- Claim: Embedding hitrate and Gini coefficient correlate with GR hitrate, allowing SID assessment without full GR training.
- Mechanism: Embedding hitrate measures whether k-NN on multimodal embeddings recovers co-occurring items; Gini coefficient measures SID usage fairness. Both are computed pre-training.
- Core assumption: These proxies capture two key determinants—collaborative signal quality and codebook utilization—that drive downstream GR performance.
- Evidence anchors:
  - [Section 3.4 & Appendix A.6]: Define metrics formally.
  - [Figure 3]: Visualizes positive correlation—high embedding hitrate / low Gini groups map to high HR@500.
  - [Section 4.2]: States "it is not strictly necessary to train recommenders to assess the quality of SIDs."
- Break condition: If downstream tasks require different inductive biases (e.g., session-level dynamics not captured by item-item similarity), proxies may misrank SID variants.

## Foundational Learning

- **Residual Quantization VAE (RQ-VAE)**
  - Why needed here: Converts continuous embeddings into hierarchical discrete codes (SIDs) via residual decomposition across codebooks.
  - Quick check question: Can you explain why residual quantization differs from independent VQ at each level?

- **Contrastive Learning (InfoNCE)**
  - Why needed here: Aligns representations of co-occurring items to inject collaborative signals before quantization.
  - Quick check question: What would happen if positive pairs were random instead of i2i?

- **Generative Retrieval Basics**
  - Why needed here: Context for how SIDs are consumed—LLMs autoregressively generate codeword sequences as retrieval outputs.
  - Quick check question: How does beam search differ from dense ANN retrieval in output form?

- **Gini Coefficient for Fairness**
  - Why needed here: Quantifies uneven SID usage; low Gini = balanced utilization.
  - Quick check question: If Gini = 0, what does that imply about item distribution across SIDs?

## Architecture Onboarding

- **Component map**: Multimodal Encoder (text/image) → fused embedding H_i → Contrastive Alignment (InfoNCE with i2i positives) → RQ-VAE Quantizer → SID = [c1, c2, c3] → Collision Post-processing (KNN or random policy) → Downstream GR model (e.g., Qwen2.5) trained with cross-entropy on SID tokens → Inference via dynamic beam search

- **Critical path**: Data modality selection → contrastive pretraining → quantization → collision handling → proxy evaluation (embedding hitrate, Gini) → GR training → online deployment with warm-start

- **Design tradeoffs**:
  - 3-level vs 2-level SIDs: 3-level balances capacity and inference cost (Table 16)
  - KNN vs random collision policy: Random favors utilization; KNN preserves semantics
  - Side information richness: More signals help high-recall (HR@1000) but may add noise for HR@20

- **Failure signatures**:
  - High Gini + low codebook utilization → poor SID fairness → reduced GR performance
  - Low embedding hitrate → weak collaborative signal → downstream underperformance regardless of quantization
  - Cold-start items without i2i → SID quality drops; consider fallback to content-only

- **First 3 experiments**:
  1. Baseline vs +Random-5: Measure HR@K lift and Gini reduction on S1–S3
  2. Ablate modality: Compare base vs +i2i vs +sideinfo on embedding hitrate and HR@1000
  3. Warm-start test: Train From Base vs From UserAction offline and measure days to reach production baseline in simulation

## Open Questions the Paper Calls Out
None

## Limitations
- Domain Generalization: FORGE is tuned for Taobao's e-commerce setting; unclear how well strategies transfer to other domains
- Cold-Start Sensitivity: Limited validation on items with sparse interaction histories that lack i2i signals
- Ablation Completeness: Not all design variants explored (e.g., deeper hierarchies, alternative collision policies)

## Confidence
- **High Confidence**: Production transaction increase (0.35%) and convergence speed (halved) are directly measured
- **Medium Confidence**: i2i contrastive alignment as primary driver is supported but could be confounded by model capacity
- **Medium Confidence**: Collision mitigation shifts performance via utilization rather than semantics is plausible but not conclusively proven
- **Low Confidence**: Generalizability of proxy metrics to other domains is not demonstrated

## Next Checks
1. **Cross-Domain Validation**: Apply FORGE's SID optimization pipeline to a non-e-commerce dataset and measure whether embedding hitrate and Gini coefficient still predict GR performance

2. **Cold-Start Stress Test**: Construct benchmark subset of items with limited interaction histories and evaluate FORGE's SID quality and downstream GR retrieval performance on this subset

3. **Alternative Collision Policies**: Implement and evaluate a new collision mitigation strategy (e.g., semantic clustering-based assignment) and compare its impact on HR@K and Gini coefficient against current policies