---
ver: rpa2
title: Reducing Class-Wise Performance Disparity via Margin Regularization
arxiv_id: '2602.00205'
source_url: https://arxiv.org/abs/2602.00205
tags:
- margin
- hard
- classes
- loss
- imagenet
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper tackles the problem of significant disparities in per-class\
  \ accuracy of deep neural networks, even when trained on class-balanced data, which\
  \ poses risks for real-world deployment. The authors propose Margin Regularization\
  \ for Performance Disparity Reduction (MR\xB2), a theoretically grounded framework\
  \ that dynamically adjusts margins in both the logit and representation spaces."
---

# Reducing Class-Wise Performance Disparity via Margin Regularization

## Quick Facts
- arXiv ID: 2602.00205
- Source URL: https://arxiv.org/abs/2602.00205
- Reference count: 40
- Primary result: Improves hard class accuracy on ImageNet from 56.4% to 59.6% while maintaining overall accuracy at 76.9%

## Executive Summary
This paper tackles the problem of significant disparities in per-class accuracy of deep neural networks, even when trained on class-balanced data, which poses risks for real-world deployment. The authors propose Margin Regularization for Performance Disparity Reduction (MR²), a theoretically grounded framework that dynamically adjusts margins in both the logit and representation spaces. Their approach is motivated by a novel margin-based, class-sensitive generalization bound that links per-class feature variability to generalization error, showing that larger margins for "hard" (low-accuracy) classes reduce error. MR² applies class-dependent logit margins proportional to feature spread and penalizes excessive representation margins to encourage intra-class compactness.

Experiments on seven datasets (including ImageNet) using diverse backbones (MAE, MoCov2, CLIP, CNNs, Vision Transformers) demonstrate that MR² significantly improves "hard" class accuracy while maintaining or slightly improving "easy" class performance, thereby reducing class-wise performance disparity. For example, on ImageNet, MR² improves overall accuracy from 75.2% to 76.9% and hard class accuracy from 56.4% to 59.6%, without sacrificing easy class accuracy. The method is validated through ablation studies, evaluations across fine-grained datasets, and robustness to different data augmentation strategies.

## Method Summary
MR² combines two regularization terms: (1) a class-dependent logit margin loss where margins are scaled by per-class feature spread (‖μ̂_y‖² + ‖ŝ_y‖²)^(1/3), computed online via EMA; (2) a representation margin loss that penalizes large intra-class distances to encourage compactness. The framework is motivated by a generalization bound showing that reducing feature spread for hard classes improves overall error. The method maintains EMA statistics for per-class mean and variance, computes margins each iteration, and combines both losses with tunable weights.

## Key Results
- ImageNet: Overall accuracy improves from 75.2% to 76.9%, hard class accuracy from 56.4% to 59.6%
- CIFAR-100: Hard class accuracy improves by +5.2% while easy class accuracy slightly improves
- Consistent improvements across 7 datasets with diverse backbones (ResNet, ViT, CLIP, MAE)
- Effective under various data augmentation strategies (AutoAugment, RandAugment)
- Reduces class-wise performance disparity without sacrificing overall accuracy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Per-class logit margins proportional to feature spread reduce generalization error for hard classes.
- **Mechanism**: The method computes γ_y = c̄K(‖μ̂_y‖² + ‖ŝ_y‖²)^(1/3) / Σ_k(‖μ̂_k‖² + ‖ŝ_k‖²)^(1/3), scaling margins larger for classes with higher feature variability. This class-dependent margin is incorporated into a modified cross-entropy via temperature-like scaling of logits.
- **Core assumption**: Hard classes exhibit larger intra-class feature spread (‖ŝ_y‖²), which correlates with higher per-class error.
- **Evidence anchors**:
  - [abstract]: "optimizes per-class logit margins proportional to feature spread"
  - [Section 3]: Corollary 1 shows this choice minimizes the complexity term in the generalization bound under fixed margin budget
  - [Section 1, Figure 1(b)]: Empirical observation that feature variance increases from easy to hard classes
- **Break condition**: If feature spread does not correlate with class difficulty (contradicts empirical observation in Figure 1(b)), or if classifier weight norms are highly imbalanced (violates uniform bound Λ assumption).

### Mechanism 2
- **Claim**: Penalizing large intra-class pairwise distances tightens the generalization bound and improves hard class accuracy.
- **Mechanism**: A representation margin loss ℓ_s̄ = ln[1 + Σ_{x⁺∈D_y\{x}} exp(‖φ(x)-φ(x⁺)‖² - 2s̄)] encourages within-class feature distances to stay below threshold 2s̄, reducing mean squared deviation ‖ŝ_y‖².
- **Core assumption**: Reducing per-class mean squared deviation lowers the Rademacher complexity term without significantly increasing empirical risk.
- **Evidence anchors**:
  - [abstract]: "penalizes excessive representation margins to encourage intra-class compactness"
  - [Section 4.2]: Proposition 1 shows complexity term scales with √(‖μ̂_k‖² + ‖ŝ_k‖²)/γ_k
  - [Table 3, rows d-e]: Ablation shows ℓ_s̄ with s̄>0 improves hard class accuracy (+2.1%) vs. s̄=0 (+0.9%)
- **Break condition**: If reducing ‖ŝ_y‖² significantly increases empirical cross-entropy risk, the bound may not improve; if s̄ is set too low (over-regularization), all classes may suffer.

### Mechanism 3
- **Claim**: Maintaining EMA estimates of class-level statistics enables stable, online margin adaptation without auxiliary batches.
- **Mechanism**: During training, exponential moving averages of ‖μ̂_k‖² and ‖ŝ_k‖² are updated per class; these feed directly into γ_k computation each iteration, avoiding separate statistics collection phases.
- **Core assumption**: EMA decay rate (0.9 in experiments) provides sufficiently stable estimates while remaining responsive to representation changes during training.
- **Evidence anchors**:
  - [Section 3]: "we maintain exponential moving average (EMA) of the squared norm of mean {‖μ̂_k‖² and mean squared deviation {‖ŝ_k‖²}"
  - [Section C.2]: "The decay rate for exponential moving average (EMA) is fixed at 0.9 across all experiments"
  - [corpus]: No direct corpus evidence for EMA stability assumption; this is a design choice not analyzed in related work
- **Break condition**: If training is very short or learning rate schedule is aggressive, EMA may lag behind rapid representation changes; if classes have very few samples, estimates may be noisy.

## Foundational Learning

- **Concept: Margin-based classification and γ-margin loss**
  - **Why needed here**: The theoretical framework (Proposition 1) bounds generalization error using γ-margin loss Φ_γ(u) = min(1, max(0, 1-u/γ)), a surrogate for 0-1 loss. Understanding why larger margins reduce error is essential to grasp the method's motivation.
  - **Quick check question**: If a classifier achieves margin 0.5 for class A and margin 0.2 for class B, which class has tighter generalization guarantees under the bound?

- **Concept: Rademacher complexity as a capacity measure**
  - **Why needed here**: Lemma 1 and Proposition 1 express the generalization bound in terms of empirical γ-margin Rademacher complexity; the margin design (Corollary 1) explicitly minimizes this complexity term.
  - **Quick check question**: If Rademacher complexity doubles while empirical risk stays constant, does the generalization bound tighten or loosen?

- **Concept: Feature spread vs. classifier bias in class imbalance**
  - **Why needed here**: The paper distinguishes its setting (balanced priors, imbalanced feature spread) from long-tail learning (imbalanced priors). Understanding that disparity stems from representation quality, not classifier weights, clarifies why standard reweighting fails.
  - **Quick check question**: If classifier weight norms are already balanced (Figure 3), would adjusting logit margins based on class frequency be effective?

## Architecture Onboarding

- **Component map**: Feature encoder φ(·) -> Classification head with weights {w_k} -> Statistics tracker (EMA) -> Margin computer -> Loss combiner (ℓ_γ,ce + λ·ℓ_s̄)

- **Critical path**:
  1. Forward pass: extract features φ(x)
  2. Update EMA statistics for class y (online, per-sample)
  3. Compute γ_y using current EMA values
  4. Compute ℓ_γ,ce with temperature-like scaling: softmax(z/γ_y)
  5. Sample positive pairs within class, compute ℓ_s̄
  6. Backward pass with combined loss

- **Design tradeoffs**:
  - **c̄ (average margin budget)**: Higher c̄ → stronger regularization, harder optimization (Figure 5 shows optimum ~2 for CIFAR-100, ImageNet)
  - **λ (representation loss weight)**: Balances logit vs. representation regularization; stable performance around 0.3-0.5 (Figure 6)
  - **p-norm choice**: p=2 for standard classifiers; p=3 for cosine classifiers (CLIP) where L2 features make ‖μ̂_y‖² + ‖ŝ_y‖² constant

- **Failure signatures**:
  - **Hard class accuracy degrades**: c̄ too large (over-regularization) or EMA decay too aggressive (unstable statistics)
  - **Easy class accuracy drops significantly**: λ too large (representation loss dominates) or s̄ set too low (over-compresses all classes)
  - **Training diverges**: γ_k values exploding (check EMA buffer overflow, ensure normalization in Corollary 1)
  - **No improvement over baseline**: Margin budget c̄ near 1 (collapses to standard CE); verify EMA updates are actually occurring

- **First 3 experiments**:
  1. **Sanity check**: Train ResNet-32 on CIFAR-100 with MR², varying c̄ ∈ {1, 2, 3}. Confirm hard class accuracy improves without easy class degradation (replicate Table 3 baseline vs. row f).
  2. **Component ablation**: Compare ℓ_γ,ce only vs. ℓ_ce + λℓ_s̄ vs. full MR² to isolate contribution of each term (Table 3 rows c, e, f).
  3. **Transfer test**: Apply MR² to a pre-trained CLIP ResNet-50 on ImageNet linear probing (Table 2, MoCov2 setting) to validate compatibility with frozen features.

## Open Questions the Paper Calls Out

- **Question**: Can MR² effectively mitigate performance disparity in scenarios characterized by label noise or class co-occurrence?
- **Basis in paper**: [explicit] The authors explicitly state in the Limitations section (Appendix D) that their method "does not account for unfairness arising from data-related issues such as label noise and class co-occurrence."
- **Why unresolved**: The method relies on calculating accurate per-class feature statistics (means and deviations). Label noise would corrupt these statistics, potentially misidentifying "hard" classes, while multi-label scenarios violate the single-label cross-entropy formulation used in the loss function.
- **What evidence would resolve it**: Empirical evaluations on benchmark datasets with synthetic label noise (e.g., CIFAR-N) or multi-label datasets (e.g., MS-COCO) to demonstrate if the regularization remains robust or requires modification.

- **Question**: Does the margin-based theoretical framework generalize to non-vision domains, such as natural language processing or tabular data?
- **Basis in paper**: [inferred] The paper validates its method exclusively on image classification datasets (CIFAR, ImageNet, etc.) using vision-specific backbones (ResNet, ViT, MAE, CLIP).
- **Why unresolved**: While the margin-based generalization bound is theoretically agnostic to data modality, the effectiveness of specific components—such as the representation margin loss derived from feature norms—may depend on the geometric properties of vision features which differ in NLP or tabular contexts.
- **What evidence would resolve it**: Experiments applying MR² to text classification or speech recognition tasks, verifying if the reduction in class-wise disparity holds across different data modalities.

- **Question**: What are the fundamental data characteristics or semantic attributes that cause the high feature variability in "hard" classes observed in Figure 1(b)?
- **Basis in paper**: [inferred] The paper establishes that high feature variability correlates with poor class performance and uses this as motivation for the regularization. However, it does not investigate *why* certain classes inherently exhibit this variability (e.g., visual similarity, intra-class diversity).
- **Why unresolved**: The work treats the variability as an observable condition to be corrected via margins, rather than a symptom of data distribution to be analyzed. Understanding the root cause could lead to data-centric solutions rather than algorithmic ones.
- **What evidence would resolve it**: A correlation analysis linking class-level statistics (e.g., intra-class visual diversity, semantic ambiguity) to the measured feature spread ‖ŝ_k‖²₂ before training.

## Limitations
- The method does not account for unfairness arising from data-related issues such as label noise and class co-occurrence
- Computational overhead of representation margin loss scales quadratically with class size, limiting scalability
- Theoretical framework assumes uniform classifier weight norms (Λ) which may not hold in practice

## Confidence

**High confidence**: The empirical results showing improved hard class accuracy across seven diverse datasets with multiple backbones. The ablation studies clearly demonstrate the contribution of each loss component. The core mechanism linking feature spread to margin scaling is well-supported by both theory and experiments.

**Medium confidence**: The theoretical generalization bound and its direct applicability to the proposed margin design. While the bound provides motivation, the gap between theory and practice (e.g., empirical risk vs. complexity term trade-offs) is not fully characterized. The EMA stability assumption for online statistics tracking is reasonable but not extensively validated across different training scenarios.

**Low confidence**: The robustness of the method to extreme class imbalance (despite balanced priors, some classes may have far fewer samples), and the long-term stability of the learned margins during extended training. The choice of specific hyperparameters (c̄=2, λ=0.5) as optimal is based on limited grid searches.

## Next Checks
1. **Statistics Tracking Robustness**: Systematically vary the EMA decay rate (0.8 to 0.99) and training duration to identify failure modes where statistics become stale or too noisy. Monitor per-class γ_k stability during training.

2. **Scaling Analysis**: Evaluate computational scaling of the representation margin loss on large-scale datasets (e.g., ImageNet with 1000 classes, some with >1000 samples). Test whether sampling strategies or approximation methods preserve performance while reducing cost.

3. **Distribution Shift Sensitivity**: Test MR² on datasets with controlled distribution shifts (e.g., corrupted labels, domain adaptation scenarios) to assess whether the margin regularization remains effective when the training-test distribution alignment is broken.