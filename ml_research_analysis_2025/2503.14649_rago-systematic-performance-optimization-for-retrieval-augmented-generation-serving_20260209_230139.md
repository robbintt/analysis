---
ver: rpa2
title: 'RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation
  Serving'
arxiv_id: '2503.14649'
source_url: https://arxiv.org/abs/2503.14649
tags:
- retrieval
- arxiv
- performance
- batch
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "RAGO introduces RAGSchema, a structured abstraction that captures\
  \ performance-relevant attributes of RAG workloads, and proposes a systematic optimization\
  \ framework to address the challenges of RAG serving. By analyzing representative\
  \ RAG paradigms, RAGO identifies key system design decisions and explores scheduling\
  \ policies\u2014including task placement, resource allocation, and batching\u2014\
  to optimize performance."
---

# RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation Serving

## Quick Facts
- arXiv ID: 2503.14649
- Source URL: https://arxiv.org/abs/2503.14649
- Reference count: 40
- Primary result: RAGO achieves up to 2x increase in QPS per chip and 55% reduction in time-to-first-token latency compared to LLM-only system baselines

## Executive Summary
RAGO addresses the challenge of optimizing retrieval-augmented generation (RAG) serving systems by introducing RAGSchema, a structured abstraction that captures performance-relevant attributes of diverse RAG workloads. The framework systematically explores scheduling policies including task placement, resource allocation, and batching to optimize performance. Evaluations demonstrate significant improvements in both throughput and latency compared to systems built on LLM-only extensions, with the hybrid collocation strategy showing up to 1.5× improvement in QPS/Chip for multi-component pipelines.

## Method Summary
RAGO introduces RAGSchema to abstract heterogeneous RAG workloads into a structured representation capturing pipeline specification and component configurations. The framework uses analytical cost modeling with roofline analysis to identify bottlenecks and guide scheduling decisions. An exhaustive search explores placement (collocated vs. disaggregated), allocation (XPU counts), and batching configurations to find Pareto-optimal tradeoffs between time-to-first-token and queries-per-second. The approach leverages calibrated simulators for inference operators and retrieval costs to predict performance across different RAG paradigms.

## Key Results
- Achieves up to 2x increase in QPS per chip compared to LLM-only system baselines
- Reduces time-to-first-token latency by up to 55% for RAG workloads
- Hybrid collocation strategy outperforms both fully collocated and fully disaggregated approaches, achieving up to 1.5× improvement in QPS/Chip for multi-component pipelines

## Why This Works (Mechanism)

### Mechanism 1
RAGSchema enables systematic performance optimization by abstracting heterogeneous RAG workloads into a structured representation. The abstraction captures pipeline specification (encoder, rewriter, reranker, LLM) and configuration parameters (model size, database vectors, retrieval frequency). This allows the framework to evaluate scheduling policies across a consistent representation. The approach assumes performance-relevant attributes can be captured without modeling quality differences between same-sized models/databases.

### Mechanism 2
Bottleneck identification via analytical cost modeling enables targeted scheduling decisions. RAGO uses a roofline-based cost model where operator latency equals max(compute_time, memory_time). By profiling each RAG component independently under varying resources and batch sizes, the framework identifies which stage limits throughput. The approach assumes calibrated simulators accurately reflect production hardware behavior.

### Mechanism 3
Hybrid collocation-disaggregation task placement outperforms fully disaggregated or fully collocated designs for multi-component RAG pipelines. Components with similar computational profiles (encoder, reranker, prefix) can time-multiplex on shared XPUs, improving utilization. Decoding remains disaggregated due to its memory-bound, autoregressive nature. The framework searches placement combinations to find Pareto-optimal configurations. The approach assumes time-multiplexing overhead is negligible compared to stage execution time.

## Foundational Learning

- **LLM Serving Stages (Prefix vs. Decode)**
  - Why needed here: RAGO's scheduling decisions depend on understanding that prefix is compute-bound (processes entire input) while decode is memory-bound (auto-regressive, KV cache access)
  - Quick check question: Given a 70B model with 512-token prefix and 256-token generation, which stage dominates total FLOPs?

- **Approximate Nearest Neighbor (ANN) Search**
  - Why needed here: Retrieval bottleneck analysis requires understanding IVF-PQ algorithm behavior—scan percentage tradeoffs between recall and throughput
  - Quick check question: Why does scanning 0.1% vs 1% of database vectors affect retrieval time but not proportionally (due to memory bandwidth saturation)?

- **Roofline Model**
  - Why needed here: RAGO's cost model uses roofline analysis (latency = max(compute, memory)) to predict component performance
  - Quick check question: For an operator with 10 GFLOPs and 20 GB data transfer on hardware with 100 GFLOPS compute and 50 GB/s bandwidth, is it compute-bound or memory-bound?

## Architecture Onboarding

- Component map: RAGSchema Parser -> Performance Profiler -> Schedule Generator -> Pareto Analyzer -> Cost Model Engine
- Critical path: RAGSchema → Performance profiling per stage → Schedule generation → End-to-end evaluation → Pareto frontier selection
- Design tradeoffs:
  - Latency vs throughput: Minimizing TTFT requires small batch sizes; maximizing QPS/Chip requires large batches
  - Collocation vs disaggregation: Collocation reduces resource fragmentation but complicates scheduling
  - Retrieval quality vs performance: Higher scan percentage improves recall but increases retrieval time
- Failure signatures:
  - QPS plateaus despite adding XPUs → Bottleneck shifted to retrieval or another component
  - TTFT spikes with burst requests → Batch size misconfiguration causing pipeline stalls
  - Decode idleness during iterative retrieval → Iterative batch size too large relative to decode batch
- First 3 experiments:
  1. **Baseline characterization**: Run RAGO on Case I (hyperscale) with 8B model; verify retrieval dominates (>50% time) as stated in Section 5.1
  2. **Placement sensitivity**: Compare fully collocated vs hybrid placement on Case IV (rewriter+reranker); reproduce 1.5× QPS/Chip improvement
  3. **Batch size tuning**: On Case II (long-context 1M tokens), find optimal encode batch size that minimizes TTFT while maintaining QPS target

## Open Questions the Paper Calls Out
None

## Limitations
- The RAGSchema abstraction's generalizability beyond the four studied paradigms remains untested
- The analytical cost model relies on roofline analysis with calibrated simulators, but calibration methodology is not fully specified
- The exhaustive search may not scale to extremely large design spaces or capture dynamic workload variations in production environments

## Confidence

- **High Confidence**: RAGSchema's ability to capture the four studied RAG paradigms and enable systematic performance optimization through structured abstraction
- **Medium Confidence**: The analytical cost model's predictions for component bottlenecks and the hybrid collocation strategy's performance benefits
- **Medium Confidence**: The reported 2x QPS/chip and 55% TTFT improvements, though validation requires independent reproduction

## Next Checks

1. **Schema Extensibility Test**: Apply RAGSchema to a novel RAG algorithm (e.g., one using iterative refinement or multi-hop reasoning) and evaluate whether the abstraction requires modification to capture its execution patterns accurately.

2. **Cost Model Calibration Verification**: Implement the XPU and ScaNN simulators using the described roofline methodology, then calibrate against real hardware measurements for at least two different model sizes and database configurations to validate prediction accuracy.

3. **Dynamic Workload Robustness**: Evaluate RAGO's scheduling decisions under bursty request patterns with varying inter-arrival times, measuring how well the framework maintains its performance advantages compared to static baselines.