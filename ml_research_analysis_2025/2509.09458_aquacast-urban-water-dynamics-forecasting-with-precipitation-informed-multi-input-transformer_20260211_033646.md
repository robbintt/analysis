---
ver: rpa2
title: 'AquaCast: Urban Water Dynamics Forecasting with Precipitation-Informed Multi-Input
  Transformer'
arxiv_id: '2509.09458'
source_url: https://arxiv.org/abs/2509.09458
tags:
- forecast
- water
- lausanne
- rain
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents AquaCast, a deep learning model designed to
  forecast urban water dynamics by integrating both endogenous variables (e.g., water
  height or discharge) and exogenous factors (e.g., precipitation history and forecast
  reports). Unlike conventional methods, AquaCast employs a multi-input, multi-output
  transformer architecture that captures inter-variable and temporal dependencies
  across all inputs, focusing forecasts solely on endogenous variables.
---

# AquaCast: Urban Water Dynamics Forecasting with Precipitation-Informed Multi-Input Transformer

## Quick Facts
- **arXiv ID:** 2509.09458
- **Source URL:** https://arxiv.org/abs/2509.09458
- **Reference count:** 40
- **Primary result:** State-of-the-art performance on urban water dynamics forecasting using multi-input transformer with exogenous precipitation embedding

## Executive Summary
This paper presents AquaCast, a deep learning model designed to forecast urban water dynamics by integrating both endogenous variables (e.g., water height or discharge) and exogenous factors (e.g., precipitation history and forecast reports). Unlike conventional methods, AquaCast employs a multi-input, multi-output transformer architecture that captures inter-variable and temporal dependencies across all inputs, focusing forecasts solely on endogenous variables. The model was evaluated on the LausanneCity dataset and three large-scale synthesized datasets, demonstrating consistent performance improvements when incorporating exogenous precipitation information and maintaining robust forecasts across different complexity levels.

## Method Summary
AquaCast uses a transformer architecture that embeds both historical endogenous and exogenous data through Conv1D layers, while future precipitation forecasts are projected as a single token via a linear layer. These tokens are concatenated and processed by a standard transformer encoder, with the decoder regressing only the endogenous variables. The model was trained on the LausanneCity dataset (4 sensors, 15-min resolution) using Adam optimizer, MSE loss, and early stopping. Performance was evaluated across four forecast horizons (96, 192, 480, 720 timesteps) and compared against baselines including PatchTST and TCN-based methods.

## Key Results
- Outperforms existing baselines on LausanneCity dataset when using only endogenous variables
- Performance improves with inclusion of exogenous variables and forecast reports
- Maintains robust and accurate forecasts across both real and synthetic datasets
- Demonstrates scalability on synthetic datasets with 100 nodes representing different complexity levels
- Shows consistent MSE improvements across all forecast horizons when incorporating precipitation forecasts

## Why This Works (Mechanism)

### Mechanism 1: Future Context Injection via Exogenous Embedding
Integrating precipitation forecasts directly into the forward pass significantly improves short-term water dynamic predictions compared to using historical data alone. The architecture projects available future precipitation reports into a single dense token via a trainable linear layer, which is appended to the sequence of historical tokens. This allows the self-attention mechanism to condition current water states on known future weather events directly. Performance degrades to baseline levels if provided precipitation forecasts are low-accuracy or if the forecast horizon exceeds the reliable prediction window of weather models.

### Mechanism 2: Cross-Variable Dependency Modeling via Joint Embedding
Processing endogenous (water) and exogenous (rain) variables jointly captures the hydraulic response lag better than channel-independent architectures. Stacked 1D Convolution layers embed input variables, summarizing broad segments of the input sequence across all variables simultaneously. This forces learned tokens to contain multivariate context, allowing the Transformer to learn the temporal delay between a rain spike and a water height surge without a complex cross-variable router. If the physical system has extremely long or irregular lag times that exceed the patching/embedding window, the immediate correlation might be lost in the embedding aggregation.

### Mechanism 3: Asymmetric Input-Output Decoupling
Focusing the loss function solely on endogenous variables prevents the model from wasting capacity predicting exogenous noise, resulting in lower error on target metrics. The decoder is designed to regress only the water dynamics (endogenous), even though the encoder attends to both water and rain. This "Multi-to-Single" setup prevents the optimization process from being pulled in conflicting directions by trying to minimize error on unpredictable exogenous patterns. If exogenous variables have strong internal temporal patterns that are correlated with the target in a complex, non-stationary way, decoupling might lose information.

## Foundational Learning

- **Concept: Tokenization & Patching in Transformers**
  - **Why needed here:** The model converts continuous time-series into discrete tokens using Conv1D (patching). Understanding this is required to grasp how the model "sees" time and how it processes history vs. forecast (linear projection vs. Conv1D).
  - **Quick check question:** How does the receptive field of the Conv1D embedding differ from the single-token representation of the future forecast?

- **Concept: Endogenous vs. Exogenous Variables**
  - **Why needed here:** The architecture is explicitly designed around this distinction. The model consumes exogenous data but does not predict it.
  - **Quick check question:** In the `Lausanne_RainFull` configuration, which variable type provides the "history" input and which provides the "future" context token?

- **Concept: Multi-Head Self-Attention (MHSA)**
  - **Why needed here:** The core engine of AquaCast. You must understand how $Q, K, V$ matrices interact to see how the model correlates a future rain token with a past water token.
  - **Quick check question:** Does the attention mechanism calculate dependencies between different time steps, different variables, or both simultaneously in this architecture?

## Architecture Onboarding

- **Component map:** Inputs (Endogenous History, Exogenous History, Exogenous Forecast) -> Embedder (Conv1D for history, Linear for forecast) -> Encoder (Transformer) -> Decoder (MLP) -> Output (Endogenous Series)

- **Critical path:** The fusion point where the *Forecast Token* is concatenated with *History Tokens* before entering the Transformer Encoder. If this alignment is off, the model will not associate future rain with current water states.

- **Design tradeoffs:**
  - **PatchTST (Channel-Independent) vs. AquaCast (Channel-Mixing):** AquaCast captures variable interactions better (good for rain->water physics) but might be less robust to noise in input channels compared to independent processing.
  - **Fixed vs. Flexible Forecast Length:** The model uses a single token for the forecast horizon, making it robust to different forecast lengths, but potentially compressing complex temporal patterns in the future forecast into a single dense vector.

- **Failure signatures:**
  - **Timing Drift:** The model predicts the magnitude of the water spike correctly but misaligns the time (e.g., predicts the peak 2 hours early). This indicates the Conv1D patching stride or receptive field may not match the physical lag of the system.
  - **Baseline Collapse:** If the model with `RainFull` performs worse than `NoRain`, check for data leakage or misalignment between the timestamp of the rain forecast and the water sensor reading.

- **First 3 experiments:**
  1. **Ablation on Input Modalities:** Train three versions on the LausanneCity dataset: (A) Endogenous only, (B) Endogenous + Rain History, (C) Endogenous + Rain History + Rain Forecast. Compare MSE to quantify the value of the "future context" mechanism.
  2. **Synthetic Scalability Test:** Train on the `SynthHigh` (Random Fields) dataset with 100 nodes. Verify if the attention mechanism crashes or if memory usage explodes due to the quadratic complexity of standard Transformers.
  3. **Horizon Degradation Analysis:** Plot MSE vs. Forecast Horizon (1, 2, 5, 7 days). Determine the "reliability cliff" where the lack of long-term forecast inputs causes performance to converge with the `NoRain` baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does AquaCast performance degrade when utilizing imperfect or noisy precipitation forecasts compared to the "perfect" forecasts used in this study?
- **Basis in paper:** The methodology uses historical MeteoSwiss records as "perfect" forecast inputs, which assumes certainty about future precipitation that does not exist in operational deployment.
- **Why unresolved:** The authors demonstrate that rain information improves accuracy but do not evaluate the model's sensitivity to the inevitable errors present in actual meteorological forecasts.
- **What evidence would resolve it:** Evaluation of model performance when forecast inputs are perturbed with varying degrees of Gaussian noise or substituted with real-world probabilistic forecast data.

### Open Question 2
- **Question:** Which additional complexity measures are required to better align the statistical properties of synthesized training data with real-world urban water behavior?
- **Basis in paper:** Section 5 states, "Although this metric is informative, additional complexity measures are needed to better align the synthesized data with real-world behavior."
- **Why unresolved:** The paper introduces a "statistical complexity" metric but notes that synthetic datasets may not fully capture the temporal structures of physical reality.
- **What evidence would resolve it:** A comparative analysis showing high correlation between specific complexity metrics calculated on synthetic data and the LausanneCity dataset.

### Open Question 3
- **Question:** Can the scalability and performance demonstrated on 100-node synthetic networks be validated on a large-scale, real-world sensor network?
- **Basis in paper:** The authors evaluate scalability using synthetic data because the real LausanneCity dataset is limited to four nodes, leaving real-world large-scale generalization unproven.
- **Why unresolved:** While the model handles the *volume* of 100 nodes in simulation, it has not been tested on the data irregularities, sensor noise, and missing values typical of large physical installations.
- **What evidence would resolve it:** Benchmark results from a real-world deployment involving a distributed sensor network with over 50 nodes.

## Limitations
- Performance sensitivity to forecast accuracy degradation is not evaluated, leaving operational window unclear
- Synthetic datasets may not fully capture real-world complexity despite consistent performance improvements
- Specific hyperparameter choices and their impact on model performance are not fully disclosed
- Large-scale real-world validation on distributed sensor networks remains untested

## Confidence
- **High Confidence:** The core architectural design and its basic mechanism of action are well-supported by ablation results and synthetic dataset experiments
- **Medium Confidence:** Generalization claims across synthetic datasets are reasonable but construction details and representativeness could be more thoroughly validated
- **Low Confidence:** Specific hyperparameter choices and their impact on performance are not fully disclosed

## Next Checks
1. **Forecast Horizon Sensitivity:** Systematically evaluate model performance as forecast horizon increases beyond 7 days, measuring the degradation rate when precipitation forecasts become less reliable. This would quantify the operational window where the "future context injection" mechanism provides value.

2. **Forecast Accuracy Dependency:** Conduct controlled experiments where synthetic precipitation forecasts are intentionally degraded (added noise, shifted timing) to measure how AquaCast performance degrades relative to baselines. This would validate the assumption that forecast accuracy is the primary limiting factor.

3. **Extreme Event Robustness:** Test the model on synthetic datasets with extreme precipitation events and non-linear hydraulic responses to verify that the attention mechanism can still capture delayed and amplified water responses that may not be linearly correlated with rainfall intensity.