---
ver: rpa2
title: Optimal Scaling Needs Optimal Norm
arxiv_id: '2510.03871'
source_url: https://arxiv.org/abs/2510.03871
tags:
- log2
- norm
- learning
- loss
- optimal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates optimal hyperparameter scaling for large\
  \ language models by focusing on the operator norm of the output layer. The authors\
  \ discover that for both Scion and Adam optimizers, the optimal learning rate/batch\
  \ size pair consistently achieves the same operator norm value\u2014a phenomenon\
  \ they term \"norm transfer.\" This constant norm condition is necessary but not\
  \ sufficient for optimality."
---

# Optimal Scaling Needs Optimal Norm

## Quick Facts
- arXiv ID: 2510.03871
- Source URL: https://arxiv.org/abs/2510.03871
- Reference count: 40
- Key outcome: Optimal hyperparameter scaling for large language models requires maintaining a constant output layer operator norm (~2^7), with η*(D) ∝ D^(-0.28±0.07) and B*(D) ∝ D^(0.45±0.07)

## Executive Summary
This study reveals that optimal hyperparameter scaling for large language models depends on maintaining a constant output layer operator norm across model and dataset scales. The authors discover "norm transfer"—a phenomenon where optimal learning rate/batch size pairs consistently achieve the same operator norm value regardless of model size or training duration. This constant norm condition is necessary but not sufficient for optimality. They empirically derive scaling rules for the Scion optimizer matching Adam's known exponents and find that per-layer-group learning rate tuning (η_input : η_hidden : η_output = 1 : 1/8 : 1) improves performance by up to 6%.

## Method Summary
The study trains Llama 3-style language models using the Scion optimizer with norm-based gradient transformations. They conduct extensive grid searches across learning rates, batch sizes, and model scales (69M to 8.6B parameters), tracking output layer operator norms ||W_out||_{RMS→∞} and training loss. The methodology includes applying layer-specific duality maps to gradients, using norm-everywhere normalization (RMSNorm before every Linear layer), and measuring scaling relationships through thousands of training runs. The authors validate their findings by comparing against Adam scaling laws and testing per-layer learning rate differentiation.

## Key Results
- Optimal hyperparameter configurations converge to a constant output layer operator norm (~2^7) across all scales and horizons
- Scaling laws for Scion match Adam: η*(D) ∝ D^(-0.28±0.07) and B*(D) ∝ D^(0.45±0.07)
- Per-layer learning rate differentiation (1:1/8:1 ratio) improves performance by up to 6%
- The constant norm condition is necessary but not sufficient for optimality
- Momentum breaks norm transfer, shifting optimal norm to ~2^11

## Why This Works (Mechanism)

### Mechanism 1: Norm Transfer as Scaling Invariant
- Claim: Optimal hyperparameter configurations converge to a constant output layer operator norm across both model and dataset scaling.
- Mechanism: When (η, B) are jointly tuned for minimal loss at a given training horizon D, the output layer norm ||W_out||_{RMS→∞} stabilizes at approximately 2^7, independent of D, model width, or depth. This creates a target norm that serves as a necessary condition for optimality.
- Core assumption: The output layer acts as a "representative" layer whose norm dynamics reflect global training health across scales.
- Evidence anchors:
  - [abstract] "the optimal learning rate/batch size pair (η*, B*) consistently has the same operator norm value — a phenomenon we term norm transfer"
  - [section 3.2] "for a given horizon there is a single optimal batch size with the corresponding optimal output norm ||W_out||_{RMS→∞} = 2^{7.0±0.2}. Intriguingly, this norm value transfers across horizons."
  - [corpus] Related LMO-based optimizer work (Training Deep Learning Models with Norm-Constrained LMOs, arXiv:2502.07529) establishes the norm-controlled optimization paradigm, but direct evidence for norm transfer is limited to this paper's empirical findings.
- Break condition: Non-zero momentum (β₁=0.9, β₂=0.95 for Adam) shifts optimal norm to ~2^11; removing output layer pre-normalization reduces optimal norm by ~10x.

### Mechanism 2: Duality Maps for Norm-Controlled Gradient Updates
- Claim: Applying norm-specific duality maps to gradients ensures steepest descent while maintaining spectral bounds on weight updates.
- Mechanism: Scion transforms raw gradients via duality maps before applying weight updates. For hidden layers with ||·||_{RMS→RMS}, this means G → √(d_out/d_in) × UV^⊤ (via SVD). This maintains ||ΔW||_{α→β} = Θ(1), satisfying the spectral condition for feature learning.
- Core assumption: Each layer group requires a specific norm geometry—1→RMS for input (mass conservation), RMS→RMS for hidden (spectral control), RMS→∞ for output (discrete vocabulary mapping).
- Evidence anchors:
  - [section 2.1] "Applying these transformations not only keeps the gradient updates within the required bound (e.g. Eq. 2), but also ensures the steepest descent under the chosen norm"
  - [section 2.1, Eq. 7-9] Explicit duality map definitions for each norm type
  - [corpus] Error Feedback for Muon and Friends (arXiv:2510.00643) discusses distributed LMO-based optimizer design, corroborating the practical viability of this approach.
- Break condition: Adam with non-zero momentum does not correspond to steepest descent in any "natural" norm, making its behavior harder to analyze through the norm lens.

### Mechanism 3: Per-Layer-Group Learning Rate Differentiation
- Claim: Hidden layers require 8× lower learning rates than input/output layers for optimal performance.
- Mechanism: Layer groups exhibit different sensitivities—output layer is most sensitive, hidden layers benefit from slower, more controlled updates. The V-shaped layout (η_input : η_hidden : η_output = 1 : 1/8 : 1) balances feature learning speed across the network.
- Core assumption: Uniform learning rate is a strong baseline but suboptimal; differentiated rates allow hidden representations to stabilize before output classification sharpens.
- Evidence anchors:
  - [section 3.4] "the configuration η_input : η_output : η_hidden = 1 : 1/8 : 1 is always among the top 10%"
  - [section 3.4] "the output layer is the most sensitive to learning rate mistuning, with the sensitivity progressively decreasing for hidden and then input layers"
  - [corpus] Limited direct corpus evidence; the paper notes this configuration contradicts suggestions in prior Scion/Muon work (Pethick et al., Riabinin et al.).
- Break condition: With momentum (μ=0.1), sensitivity to both batch size and per-layer learning rate ratios decreases, making tuning less critical.

## Foundational Learning

- Concept: **Induced Operator Norms**
  - Why needed here: The paper's central finding depends on tracking ||W||_{α→β} for different layer types. Understanding that ||W||_{RMS→∞} = max_i(d_in × ||row_i(W)||_{RMS}) and how it differs from spectral norm is essential for interpreting results.
  - Quick check question: Why does the RMS→∞ norm scale with d_in, and what does this imply for width scaling?

- Concept: **Spectral Condition (μP Foundation)**
  - Why needed here: The spectral condition (||W||_∗ = Θ(√(d_out/d_in))) defines the regime where zero-shot hyperparameter transfer is theoretically guaranteed. This motivates the entire norm-based optimization approach.
  - Quick check question: What does Θ(1) mean for ||W||_{RMS→RMS}, and why does this enable feature learning at infinite width?

- Concept: **Learning Rate–Batch Size Scaling Laws**
  - Why needed here: The paper derives η* ∝ B^0.62 × D^(-0.56) and B* ∝ D^0.45. These scaling relationships are necessary (though not sufficient) conditions for practical hyperparameter selection at scale.
  - Quick check question: If you increase training tokens from 8B to 32B (4×), how should you adjust learning rate and batch size?

## Architecture Onboarding

- Component map:
  Scion optimizer -> Duality maps (LMOs) -> Layer groups (input/hidden/output) -> Disco distributed implementation -> Newton-Schulz orthogonalization

- Critical path:
  1. Assign operator norm to each layer group at initialization
  2. Compute momentum buffer gradients via backpropagation
  3. Apply layer-group-specific duality map to transform gradients
  4. All-gather/All-to-all communication to reconstruct full gradients across ranks (FSDP-Disco)
  5. Apply Newton-Schulz orthogonalization for hidden layers (n_iter=5, coefficients a,b,c = 3.4445, -4.7750, 2.0315)
  6. Vectorized weight update application

- Design tradeoffs:
  - **Norm-everywhere vs. residuals-only**: Norm-everywhere (QKVO + MLP + residuals + output) adds ~7 RMSNorm layers; residuals-only achieves similar performance with 10× lower optimal norm but higher learning rate sensitivity
  - **Momentum vs. no momentum**: Momentum (μ=0.1) reduces batch size sensitivity and broadens optimal norm region but shifts target norm upward
  - **Weight decay**: Constrains norms asymptotically to 1/λ, potentially interfering with natural norm transfer dynamics

- Failure signatures:
  - **Divergence** when removing residual connection normalization (Fig. 13a)—training becomes unstable
  - **"Turbulence" region** at norms 2^9–2^10 (Fig. 1b)—slope changes indicate regime shift in training dynamics
  - **Non-transfer** when optimal norm differs (momentum case)—constant norm condition breaks
  - **Fused tensor incompatibility**: FSDP2 sharding assumption fails for fused QKV/W13 tensors; must defuse or restructure

- First 3 experiments:
  1. **Learning rate scan with norm tracking**: Train proxy model (69M params) across η grid, plot loss vs. ||W_out||_{RMS→∞} to verify parabolic relationship; extract optimal norm target (~2^7)
  2. **Horizon scaling validation**: Run same LR scan at multiple horizons (2B, 8B, 34B tokens); confirm optimal norm remains constant while optimal (η*, B*) shifts according to scaling rules
  3. **Per-layer LR ratio ablation**: Compare uniform LR vs. 1:1/8:1 ratio at fixed horizon; quantify relative loss improvement (expect ~6% at 8.6B tokens)

## Open Questions the Paper Calls Out
None

## Limitations
- Norm transfer phenomenon remains empirically observed rather than theoretically proven
- Per-layer learning rate differentiation findings contradict prior Scion recommendations with partially unexplained mechanisms
- Momentum effects break norm transfer, suggesting theory may be incomplete for practical Adam implementations

## Confidence
**High Confidence**: The basic scaling laws (η*(D) ∝ D^(-0.28±0.07), B*(D) ∝ D^(0.45±0.07)) are well-supported by extensive empirical validation across multiple model sizes and training horizons. The necessity of the constant norm condition is clearly demonstrated through systematic grid searches.

**Medium Confidence**: The sufficiency of the constant norm condition for optimality, while strongly suggested by the data, is not rigorously proven. The per-layer learning rate differentiation shows consistent improvements but relies on heuristic optimization.

**Low Confidence**: The theoretical foundation for why norm transfer occurs and why the specific optimal norm value (~2^7) is invariant remains incomplete. The mechanism connecting operator norms to training dynamics is described but not fully understood.

## Next Checks
1. **Theoretical Foundation Verification**: Develop a mathematical proof or counterexample for whether the constant norm condition is sufficient for optimality. This should include analysis of how momentum affects the norm dynamics and whether the 2^7 invariant can be derived from first principles.

2. **Architecture-Agnostic Testing**: Validate norm transfer across different model architectures (transformers with varying attention mechanisms, MLPs, RNNs) and datasets to determine if the phenomenon is architecture-specific or more universal. Pay special attention to whether the optimal norm value changes with architecture.

3. **Distributed Implementation Validation**: Rigorously test the Disco implementation across different parallelism strategies (FSDP2 vs DDP vs TP/EP/CP/PP) to identify and document any numerical discrepancies or communication overhead that could affect the observed norm dynamics, particularly given the complex gradient transformations required by Scion.