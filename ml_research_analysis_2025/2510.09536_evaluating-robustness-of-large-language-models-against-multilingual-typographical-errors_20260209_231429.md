---
ver: rpa2
title: Evaluating Robustness of Large Language Models Against Multilingual Typographical
  Errors
arxiv_id: '2510.09536'
source_url: https://arxiv.org/abs/2510.09536
tags:
- robustness
- typo
- language
- typos
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MULTYPO, a multilingual typo generation algorithm
  that simulates human-like typographical errors based on language-specific keyboard
  layouts and typing behavior. The authors evaluate 18 open-source large language
  models across three model families (Gemma, Qwen, OLMo) on five downstream tasks
  using zero- and few-shot prompting.
---

# Evaluating Robustness of Large Language Models Against Multilingual Typographical Errors

## Quick Facts
- arXiv ID: 2510.09536
- Source URL: https://arxiv.org/abs/2510.09536
- Reference count: 40
- Key outcome: Introduces MULTYPO typo generation algorithm; finds typos degrade LLM performance across 18 models, with reasoning tasks most vulnerable and language-dependent robustness patterns

## Executive Summary
This paper evaluates how multilingual typographical errors affect 18 open-source large language models across five downstream tasks using a novel keyboard-layout-aware typo generation algorithm called MULTYPO. The authors find that typos consistently degrade model performance, particularly in generative and reasoning tasks, while natural language inference shows greater robustness. Instruction-tuned models perform better on clean inputs but show no improvement and sometimes worse robustness under noise. The study reveals language-dependent robustness patterns, with high-resource languages and translation from English being more robust than low-resource languages and translation into English. These findings highlight the need for noise-aware training and evaluation strategies for LLMs in real-world multilingual applications.

## Method Summary
The paper introduces MULTYPO, a multilingual typo generation algorithm that simulates human-like errors based on language-specific keyboard layouts and typing behavior. The algorithm uses length-aware word sampling (probability proportional to √|w|), position-aware character sampling (favoring mid-to-late positions), and four operations: replacement (adjacent keys), insertion, deletion, and transposition (cross-hand only). The authors evaluate 18 open-source LLMs (Gemma, Qwen, OLMo families) across five tasks using zero- and few-shot prompting with typo rates of 0%, 10%, 40%, and 70%. Performance is measured using accuracy and BLEU scores to assess degradation under typographical noise.

## Key Results
- Typos consistently degrade LLM performance, with reasoning tasks (MGSM) showing 15-20% absolute drops at 10% typo rates while classification tasks (XNLI) show minimal degradation
- Instruction tuning improves clean-input performance but provides no robustness benefits and may increase vulnerability to noise
- Larger models generally show better absolute performance but suffer similar relative degradation from typos
- Language-dependent robustness observed: high-resource Latin-script languages and translation from English are more robust than low-resource languages and translation into English
- Keyboard-aware typo simulation (MULTYPO) produces more realistic errors than naive approaches, with human evaluation showing significantly higher naturalness (8-10 vs 5-8) in 6/7 languages tested

## Why This Works (Mechanism)

### Mechanism 1
Keyboard-layout-aware typo simulation produces perturbations that better reflect pretraining exposure than random noise. MULTYPO samples typos based on language-specific keyboard layouts and 10-finger typing conventions, using length-aware word sampling, position-aware character sampling, and four operations (replacement, insertion, deletion, transposition). This yields errors that models have likely encountered in web-scale pretraining corpora.

- Core assumption: Real-world user typing errors exist in pretraining data, so models develop implicit robustness to realistic noise patterns but not to arbitrary character perturbations.
- Evidence anchors: Human evaluation shows MULTYPO rated significantly more natural than naive baseline in 6/7 languages (p<0.05); Qwen3-4B shows significantly worse performance under random perturbations vs MULTYPO for reasoning tasks (MGSM p<0.01, Belebele p<0.001 at 70% corruption).
- Break condition: If models were trained on curated, edited text with few typos, or if realistic typos fall outside the training distribution, the mechanism weakens.

### Mechanism 2
Reasoning tasks exhibit greater typo sensitivity than classification tasks because sequential token corruption disrupts chain-of-thought state tracking. Generative reasoning requires maintaining accurate intermediate representations across multiple tokens, and typos in premise tokens propagate through attention mechanisms, corrupting subsequent reasoning steps.

- Core assumption: Reasoning relies on precise token-to-token dependencies that are more fragile than the semantic abstraction used for classification.
- Evidence anchors: MGSM: Qwen drops from ~40 (clean) to ~27 (70% noise); XNLI: Qwen nearly unchanged at 10% noise, OLMo drops <10 points even at 70% noise. "Token-level corruption disrupts multi-step reasoning more than classification-based understanding."
- Break condition: If models use robust semantic representations that are typo-invariant even for reasoning, or if chain-of-thought is more parallel than sequential, this mechanism would weaken.

### Mechanism 3
Instruction tuning optimizes for clean-prompt performance at the cost of noise robustness, creating a robustness-capability tradeoff. Instruction tuning shapes the model's output distribution toward task-appropriate responses given clean, well-formatted prompts, which may reduce the model's capacity to handle distribution shift (typos).

- Core assumption: Instruction tuning on clean data reduces model flexibility to handle out-of-distribution inputs, trading generalization for task performance.
- Evidence anchors: Instruction-tuned models outperform base models on clean input but show "absolute degradation under 10% or 40% noise is as severe as or even worse than their base counterparts"; Gemma instruction-tuned drops from ~48 to 33 on MGSM at 40% corruption. "Current tuning methods prioritize clean prompts and may underprepare models for noisy real-world input."
- Break condition: If instruction tuning were performed with augmented noisy data, or if robustness and capability are not fundamentally traded off, this mechanism would not hold.

## Foundational Learning

- Concept: Subword tokenization robustness
  - Why needed here: Typos affect character sequences, but LLMs operate on subword tokens (BPE, SentencePiece). Understanding how character-level noise propagates to token boundaries is essential for predicting which typos cause tokenization splits that cascade into semantic errors.
  - Quick check question: Given the typo "instrcutions" vs "instructions", would a BPE tokenizer produce the same tokens, similar tokens with one split, or completely different tokens?

- Concept: In-context learning vs. weight-based adaptation
  - Why needed here: The paper tests zero-shot, few-shot (1, 3, 5 examples) robustness. Understanding whether demonstrations provide robustness through pattern matching (fragile) or task specification (more robust) explains why Section 6.1 finds that adding examples doesn't improve typo robustness.
  - Quick check question: If few-shot demonstrations contain typos but clean answers, would a model learn to be more robust, or would the noisy context confuse the task specification?

- Concept: Multilingual transfer and cross-lingual interference
  - Why needed here: Section 6.2 shows language-dependent robustness (high-resource Latin-script languages more robust; translation from English more robust than to English). This requires understanding how shared multilingual representations handle noise differently across languages.
  - Quick check question: Why would translating from English (with typos) to Georgian be more robust than translating from Georgian (with typos) to English, given the same source-language typo rate?

## Architecture Onboarding

- Component map:
  MULTYPO typo generator: Keyboard layout database → word sampler (√|w| weighting) → position sampler (position-aware distribution) → operation selector (replace 28.25%, insert 15.25%, delete 28.25%, transpose 28.25%) → validity checker → output with typos
  Evaluation pipeline: Task dataset → MULTYPO corruption → prompt template → LLM (base or instruct) → response → metric computation (accuracy, BLEU)
  Models tested: Gemma-3 (1B, 4B, 12B), Qwen3 (1.7B, 4B, 8B), OLMo-2 (1B, 7B, 13B), each with base and instruction-tuned variants

- Critical path:
  1. Define language and keyboard layout (Section 3.1 uses kbdlayout.info database)
  2. Set typo rate τ ∈ [0, 1] and identify ignore-strings (numerical expressions)
  3. For each word: sample based on √|w|, select position, apply operation with keyboard constraints
  4. Validate typo doesn't contradict previous edits (e.g., w→e then e→w)
  5. Iterate until target typo count reached

- Design tradeoffs:
  - Ignoring numerical strings: Reduces realism but ensures benchmark validity (Section 3.1 footnote 4)
  - Horizontal neighbors only for replacement: Based on MacNeilage (1964) but may miss vertical key errors
  - 10-finger convention for all languages: Implicit assumption for non-QWERTY layouts; Arabic human evaluation non-significant (Table 2), suggesting this assumption may not hold universally
  - No logographic/syllabic support: Chinese, Japanese excluded due to input method differences (Section Limitations)

- Failure signatures:
  - Arabic: Only language where MULTYPO not significantly better than naive baseline (Table 2, Figure 11), suggests keyboard model or hand-assignment may be incorrect
  - High typo rates (70%): All models degrade severely; Figure 3 shows near-floor performance on MGSM for all families
  - OLMo few-shot: Adding examples doesn't help or harms (Section 6.1), likely due to limited multilingual coverage

- First 3 experiments:
  1. Replicate MULTYPO vs. naive baseline comparison on a single task (e.g., XNLI in English) with a single model (Qwen3-4B-instruct) at 10%, 40%, 70% typo rates to validate the pipeline and confirm models are more robust to keyboard-aware noise
  2. Ablate position sampling: Compare position-aware vs. uniform position sampling to test whether mid/late-word error bias (Lisbach & Meyer 2013) matters for model robustness
  3. Test cross-lingual transfer of robustness: Take a high-performing multilingual model (Gemma-12B-instruct), evaluate on held-out language not in original 12 (e.g., Swedish with QWERTY layout) to assess generalization of keyboard-aware robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can noise-aware pretraining strategies (e.g., multilingual data augmentation with keyboard-aware typos) substantially improve LLM robustness without degrading clean-input performance?
- Basis in paper: [explicit] The conclusion states: "These findings highlight critical blind spots in current LLM evaluation and motivate future work on noise-aware multilingual pretraining, evaluation, and human-centric error modeling."
- Why unresolved: The paper evaluates robustness under typos but does not implement or test any mitigation strategies; it only provides the evaluation framework and demonstrates the problem.
- What evidence would resolve it: Comparing models pretrained with MULTYPO-style augmentation against standard models on both clean and noisy benchmarks, measuring whether robustness gains come at the cost of clean performance.

### Open Question 2
- Question: How can typo simulation algorithms be adapted for logographic or syllabic writing systems (e.g., Chinese, Japanese) where input involves intermediate phonetic stages (Pinyin, Kana) rather than direct character keypresses?
- Basis in paper: [explicit] In Limitations: "our algorithm does not yet support logographic or syllabic writing systems, such as Chinese... Modeling such input pipelines requires a fundamentally different corruption strategy."
- Why unresolved: The paper's keyboard-layout approach assumes direct character-to-key mapping, which does not apply to IME-based input methods common for CJK languages.
- What evidence would resolve it: Developing an IME-aware typo generator for Chinese/Japanese, validating naturalness via human evaluation, and testing whether models show similar vulnerability patterns as alphabetic languages.

## Limitations

- Limited to physical keyboards: The study focuses exclusively on physical QWERTY-style keyboards, ignoring mobile/touchscreen input methods that may have different error distributions and autocorrect behaviors.
- No logographic script support: The algorithm cannot handle Chinese, Japanese, or other logographic writing systems due to different input method complexities.
- Arabic language exception: Human evaluation shows Arabic as the only language where MULTYPO isn't significantly better than naive approaches, suggesting potential issues with keyboard layout modeling for right-to-left scripts.

## Confidence

- High confidence: The observation that typos consistently degrade LLM performance, particularly in generative and reasoning tasks compared to classification tasks. This is well-supported by empirical results across multiple models and datasets.
- Medium confidence: The mechanism that keyboard-layout-aware typo simulation produces more realistic noise than random perturbations. While human evaluation supports this, the paper doesn't verify that these realistic typos better reflect pretraining exposure.
- Medium confidence: The finding that language-dependent robustness exists, with high-resource languages and translation from English showing better robustness. This is empirically demonstrated but the underlying reasons (shared representations, pretraining distribution, etc.) remain partially speculative.
- Low-Medium confidence: The claim that instruction tuning creates a robustness-capability tradeoff. While empirical evidence shows instruction-tuned models are more vulnerable to noise, the paper doesn't definitively establish causation versus correlation with other factors.

## Next Checks

1. **Keyboard layout validation study**: Conduct targeted human evaluation specifically for non-Latin script languages (Arabic, Georgian, Hebrew, Greek) to validate whether MULTYPO's typing assumptions match actual typing behavior. Compare MULTYPO outputs against collected real-world typos from native speakers of these languages.

2. **Pretraining typo distribution analysis**: Sample and analyze a subset of the pretraining corpora used for the evaluated models to quantify the actual distribution of typos and keyboard-aware errors. Compare this distribution to MULTYPO's generation patterns to validate whether models have likely encountered similar noise during training.

3. **Instruction tuning ablation with noise-augmented fine-tuning**: Replicate the robustness evaluation using instruction-tuned models that were fine-tuned with typo-augmented data (using MULTYPO at 5-10% rates). Compare performance degradation to standard instruction-tuned models to directly test whether noise-aware fine-tuning mitigates the observed tradeoff.