---
ver: rpa2
title: Scaling Open-Ended Reasoning to Predict the Future
arxiv_id: '2512.25070'
source_url: https://arxiv.org/abs/2512.25070
tags:
- answer
- question
- questions
- training
- article
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of training language models
  to forecast open-ended world events, where questions and answers are expressed in
  natural language. To scale up training data, the authors synthesize forecasting
  questions from global news articles using a fully automated pipeline: one model
  generates questions from news, another filters and edits them to avoid future information
  leakage, and a third validates quality.'
---

# Scaling Open-Ended Reasoning to Predict the Future

## Quick Facts
- arXiv ID: 2512.25070
- Source URL: https://arxiv.org/abs/2512.25070
- Authors: Nikhil Chandak; Shashwat Goel; Ameya Prabhu; Moritz Hardt; Jonas Geiping
- Reference count: 40
- Primary result: OpenForecaster8B matches or exceeds much larger proprietary models on held-out forecasting questions

## Executive Summary
This paper addresses the challenge of training language models to forecast open-ended world events expressed in natural language. The authors synthesize forecasting questions from global news articles using a fully automated pipeline that generates questions, filters for leakage, and validates quality. They train Qwen3 thinking models with reinforcement learning using a combined accuracy plus Brier score reward, resulting in OpenForecaster8B, which matches or exceeds much larger proprietary models on held-out forecasting questions from May to August 2025. The approach improves both accuracy and calibration while showing generalization to other benchmarks.

## Method Summary
The authors create OpenForesight, a dataset of ~52K forecasting questions from CommonCrawl News articles (June 2023–April 2025), using a pipeline of question generation, validation, best selection, and leakage removal. They retrieve relevant articles up to one month before question resolution using an offline corpus to prevent future information leakage. Training uses GRPO on Qwen3-8B thinking models with a combined accuracy plus Brier score reward function. The resulting OpenForecaster8B model is evaluated on held-out questions from May to August 2025, showing superior performance compared to both baseline models and much larger proprietary systems.

## Key Results
- OpenForecaster8B matches or exceeds much larger proprietary models on held-out forecasting questions from May to August 2025
- Combined accuracy + Brier reward yields ~4% "Unknown" predictions vs ~40% with Brier-only, while improving calibration
- Multi-stage leakage filtering improves sample efficiency by ~3x and prevents performance degradation from shortcut learning
- Retrieval of relevant news articles improves accuracy by 9-18% across model families

## Why This Works (Mechanism)

### Mechanism 1: Combined Accuracy + Brier Reward Preserves Both Exploration and Calibration
Optimizing accuracy alone degrades calibration; optimizing Brier alone suppresses exploration; combining both yields superior performance. Accuracy-only rewards incentivize overconfident predictions regardless of uncertainty. Brier-only rewards penalize low-confidence wrong answers minimally, causing models to avoid hard questions (predicting "Unknown" ~40% of the time). Adding accuracy reward provides signal even on hard questions where confidence should be low.

### Mechanism 2: Multi-Stage Leakage Filtering Prevents Shortcut Learning
Training on unfiltered generated questions degrades forecasting; filtering for leakage improves sample efficiency by ~3x. Generated questions often contain the answer in background/resolution text. Models learn to extract leaked answers rather than forecast, which transfers poorly to held-out questions. The pipeline uses validation of answer derivability, LLM-based leakage detection and rewriting, and string-matching final filter.

### Mechanism 3: Offline Retrieval with Strict Temporal Cutoff Provides Signal Without Contamination
Retrieving relevant news articles improves accuracy by 9-18% across model families; using offline corpus with one-month-prior cutoff prevents future leakage. Retrieval provides evidence and competing viewpoints that models can weigh. However, online search APIs have unreliable date cutoffs. Static snapshots with hard cutoffs ensure the forecaster only sees information available before resolution.

## Foundational Learning

- **Concept: Proper Scoring Rules (Brier Score)**
  - Why needed here: The reward function depends on understanding how Brier scores incentivize truthful probability reporting
  - Quick check question: If a model assigns p=0.8 to an answer that turns out correct, what's its Brier score? What if p=0.3 and incorrect?

- **Concept: GRPO (Group Relative Policy Optimization)**
  - Why needed here: The training uses GRPO, not standard PPO. It computes advantages from group samples rather than value functions
  - Quick check question: How does GRPO differ from PPO in computing advantages when you only have outcome rewards?

- **Concept: Backtesting with Temporal Leakage Prevention**
  - Why needed here: Forecasting evaluation is meaningless if future information leaks
  - Quick check question: Why might an article published in March but updated in June cause leakage when retrieved for a May resolution question?

## Architecture Onboarding

- **Component map:**
  CommonCrawl News → DeepSeek-v3 (question generation) → Llama-4-Maverick (validation + best selection + leakage edit) → String filter → OpenForesight dataset → Qwen3-8B Embedding model → Dense retrieval from offline CCNews corpus → Top-5 chunks with <1 month cutoff → Qwen3-8B thinking model → GRPO with Accuracy+Brier reward → Trained on 52K freeform + 2K binary questions → Llama-4-Scout answer matching

- **Critical path:** Data quality (leakage filtering) → Reward design (accuracy+Brier) → Retrieval integration → RL training. Errors in early stages compound; the paper shows unfiltered data actively harms models.

- **Design tradeoffs:**
  - News-only dataset limits topic diversity (skews toward reported events, underrepresents scientific breakthroughs reported late)
  - One-month retrieval cutoff is conservative; may miss last-minute developments
  - Free-form answers require LLM grading, introducing judge-model dependency (paper shows ~97% agreement between judges)

- **Failure signatures:**
  - Model predicts "Unknown" frequently → Brier-only reward, needs accuracy term
  - Model overconfident on wrong answers → Accuracy-only reward, needs Brier term
  - Model performs well on validation but poorly on test → Likely source distribution overfitting or subtle leakage
  - Model retrieves articles containing the answer → Temporal cutoff too loose or resolution date incorrect

- **First 3 experiments:**
  1. Validate retrieval impact: Run baseline model with 0, 1, 3, 5 retrieved chunks on validation set. Confirm plateau at ~5 chunks.
  2. Ablate reward components: Train three models (accuracy-only, Brier-only, combined) on a 5K subset. Measure both accuracy and Brier on held-out validation.
  3. Test leakage sensitivity: Create a small dataset with intentionally leaked answers and train to observe performance degradation vs. filtered version.

## Open Questions the Paper Calls Out

- **Long-form forecast grading**: The paper does not consider long-form forecasts as it is unclear how to grade these. Development of a validated scoring methodology for paragraph-length forecasts would resolve this.

- **Multiple guess reporting**: Ideally forecasters should report all guesses with non-zero probability, but this direction is left for future work. Implementation and evaluation of multi-guess probability reporting could improve calibration.

- **Diverse data sources**: The paper only uses news to create forecasting questions, leading to distributional bias. Comparison of models trained on news-only vs. multi-source datasets on diverse benchmarks would test generalization.

- **Emergent reasoning at scale**: Scaling up end-to-end forecasting training may lead to emergent improvements in reasoning capabilities. Training curves across model scales could reveal non-linear improvements.

## Limitations
- Evaluation relies on a single LLM judge (Llama-4-Scout) for answer matching, introducing potential judge-model bias
- Offline CommonCrawl corpus limits topical diversity to reported news events, potentially missing scientific breakthroughs
- One-month cutoff may still allow subtle leakage through articles published just before the cutoff that are later updated
- Training data mix may not be representative of all forecasting domains

## Confidence
- **High confidence**: Combined accuracy+Brier reward mechanism effectiveness; multi-stage leakage filtering impact; offline retrieval with temporal cutoff benefits
- **Medium confidence**: Generalizability of calibration improvements to other benchmarks; the 3x sample efficiency improvement claim
- **Low confidence**: The specific one-month cutoff being optimal; the sufficiency of the Qwen3-8B judge for semantic equivalence

## Next Checks
1. **Judge-model dependency test**: Evaluate a subset of held-out questions using two different LLM judges to quantify the impact of judge bias on reported accuracy
2. **Leakage sensitivity analysis**: Create a controlled dataset where some questions contain subtle leakage and measure performance degradation compared to truly clean questions
3. **Topical diversity assessment**: Analyze the OpenForesight dataset to quantify the distribution of question types and measure if calibration improvements hold across all categories