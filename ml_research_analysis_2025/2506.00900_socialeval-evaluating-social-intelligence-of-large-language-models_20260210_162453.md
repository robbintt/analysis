---
ver: rpa2
title: 'SocialEval: Evaluating Social Intelligence of Large Language Models'
arxiv_id: '2506.00900'
source_url: https://arxiv.org/abs/2506.00900
tags:
- social
- neur
- uni00000048
- llms
- goal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SOCIAL EVAL addresses the gap in evaluating large language models'
  (LLMs) social intelligence (SI) by introducing a bilingual benchmark that combines
  outcome-oriented goal achievement and process-oriented interpersonal ability evaluation.
  It uses manually crafted narrative scripts structured as world trees, where each
  script involves multiple plot lines driven by interpersonal abilities.
---

# SocialEval: Evaluating Social Intelligence of Large Language Models

## Quick Facts
- arXiv ID: 2506.00900
- Source URL: https://arxiv.org/abs/2506.00900
- Authors: Jinfeng Zhou, Yuxuan Chen, Yihan Shi, Xuanming Zhang, Leqi Lei, Yi Feng, Zexuan Xiong, Miao Yan, Xunzhi Wang, Yaru Cao, Jianing Yin, Shuai Wang, Quanyu Dai, Zhenhua Dong, Hongning Wang, Minlie Huang
- Reference count: 40
- Primary result: All 19 evaluated LLMs fall behind humans in both social intelligence evaluations (GAE gap: 23.8%-17.2%, IAE gap: 3.2%-4.6% at Overall level)

## Executive Summary
SOCIAL EVAL introduces a bilingual benchmark for evaluating social intelligence in large language models through a dual-paradigm approach combining outcome-oriented goal achievement and process-oriented interpersonal ability evaluation. The benchmark uses manually crafted narrative scripts structured as world trees, where each script involves multiple plot lines driven by interpersonal abilities. Experiments with 19 LLMs including GPT-4, Claude-3, Llama-3, Qwen-2.5, and DeepSeek show that all models lag behind humans in both evaluation dimensions, with a more pronounced gap in goal achievement than ability selection.

## Method Summary
The evaluation paradigm consists of two tasks: Goal Achievement Evaluation (GAE) and Interpersonal Ability Evaluation (IAE). Each social scenario is structured as a world tree with episodes representing decision points, where LLMs navigate toward goals while selecting utterances that demonstrate interpersonal abilities. The world tree construction involves character profiles, episode sequences, and transition options, with 153 trees created manually at significant cost. The benchmark evaluates 32 interpersonal abilities across 5 aspects, using Chain-of-Thought prompting with majority voting for GAE and multiple-choice options for IAE.

## Key Results
- All evaluated LLMs fall behind humans in both GAE (17.2%-23.8% gap) and IAE (3.2%-4.6% gap) evaluations
- LLMs exhibit strong preference for prosocial and positive behaviors, even when such behaviors lead to goal failure
- Larger LLMs (70B) develop ability-specific functional partitions in representation space and neuronal activations similar to human brain organization
- Significant cross-lingual differences exist between Chinese and English results (Wilcoxon p<0.001)

## Why This Works (Mechanism)

### Mechanism 1: Dual-Evaluation Paradigm (Outcome + Process)
The benchmark separates social intelligence into goal achievement and interpersonal ability evaluation, revealing distinct competency gaps that single-metric approaches miss. This decomposition exposes that LLMs lag humans more in goal achievement (17.2%-23.8% gap) than in ability selection (3.2%-4.6% gap), showing the dual-evaluation captures different aspects of social competence.

### Mechanism 2: World Tree Narrative Structure
Social scripts are structured as branching world trees that capture sequential social dynamics through episode transitions. Each decision point creates diverging plot lines, enabling evaluation of both path selection and path-dependent outcomes. This structure models how interpersonal ability selections at each episode influence subsequent states and overall goal achievement.

### Mechanism 3: Functional Partition Analysis
Larger LLMs develop ability-specific functional partitions in representation space and neuronal activations, analogous to human brain specialization. Analysis using t-SNE clustering and Wanda-based neuron importance scoring shows that 70B models exhibit clearer cluster separation and denser isolated neuron regions compared to 8B models, suggesting scaling enables functional specialization for social abilities.

## Foundational Learning

- **Markov Decision Processes (MDPs)**
  - Why needed here: The paper formalizes both evaluation tasks as goal-conditioned MDPs with explicit state spaces (episodes), action spaces (utterances), transition functions, and reward functions
  - Quick check question: Given a social scenario with 3 possible utterances at each of 2 decision points, can you compute the total number of possible trajectories through the world tree?

- **Social Psychology Frameworks (Interdependence Theory + BESSI)**
  - Why needed here: The social world taxonomy derives from interdependence theory's outcome transformations, while the interpersonal ability inventory adopts the BESSI framework's 5 aspects and 32 specific abilities
  - Quick check question: Why does the taxonomy exclude (self-interest, altruism) = (0, 0) and (-1, 0) orientations?

- **Representation Learning and Neuron Importance Scoring**
  - Why needed here: The functional partition analysis relies on t-SNE visualization of hidden states and Wanda scoring to identify neuron importance
  - Quick check question: How does the Wanda score formulation balance weight magnitude and activation intensity?

## Architecture Onboarding

- **Component map:** World Tree Constructor -> GAE Engine -> IAE Engine -> Translation Pipeline -> Analysis Layer
- **Critical path:** Construct world tree -> Define episode transitions with ability-labeled options -> Generate IAE questions and distractors -> Run LLM through GAE (navigation) and IAE (selection) -> Analyze representation space and neuron activations
- **Design tradeoffs:** Manual construction ensures quality (95% agreement rate) but limits benchmark to 153 trees; automated generation would scale but risk incoherence; bilingual coverage may introduce cultural artifacts despite 97% translation acceptance
- **Failure signatures:** Prosociality bias (LLMs select positive behaviors even when they lead to goal failure); cross-lingual inconsistency (significant differences between Chinese and English results); antisocial world underrepresentation (only 20 trees for Induction/Conflict)
- **First 3 experiments:** 1) Baseline establishment with fixed random seeds and position-shuffled options on 19 LLMs; 2) Prosociality intervention to explicitly weight goal achievement over positive behavior expression; 3) Functional partition validation comparing smaller (7B) and larger (70B) models across architecture families

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the SocialEval benchmark be scaled up to ensure a more balanced distribution across all 32 interpersonal abilities, particularly for underrepresented abilities? (Limited by manual construction difficulty and costs)

- **Open Question 2:** To what extent do the observed cross-lingual differences in SocialEval performance stem from genuine cultural variations in social intelligence versus artifacts of the translation pipeline? (Translation rather than native construction for English portion)

- **Open Question 3:** Can LLMs be calibrated to flexibly adjust their behavioral polarity (e.g., adopting neutral or negative behaviors) to improve goal achievement rates in complex social scenarios? (Current alignment induces rigid prosociality bias)

- **Open Question 4:** Is the development of ability-specific functional partitions in the representation space of larger models a causal mechanism for improved social intelligence, or merely a correlational byproduct of increased scale? (No ablation studies performed)

## Limitations

- Manual construction of 153 world trees at significant cost (12 hours/tree, $40/tree) limits scalability and creates potential for cultural artifacts
- Cross-lingual differences suggest evaluation is not language-invariant, with English data derived via translation from Chinese originals
- Prosociality bias observed across LLMs may reflect training data contamination rather than genuine social intelligence deficits
- Only 20 trees available for antisocial worlds (Induction/Conflict), limiting evaluation in these orientations

## Confidence

- **High Confidence:** The dual-evaluation paradigm effectively separates outcome achievement from process ability selection
- **Medium Confidence:** The brain-like functional partition analysis is methodologically sound but requires more behavioral validation
- **Low Confidence:** Claims about systematic prosocial bias leading to goal failure need causal validation

## Next Checks

1. **Causal Prosociality Intervention:** Modify prompts to explicitly prioritize goal achievement over positive behavior expression and measure whether goal achievement ratios improve while maintaining reasonable ability selection accuracy

2. **Cross-Cultural Generalizability Test:** Construct parallel world trees for different cultural contexts (e.g., East Asian vs. Western) and test whether the same LLMs show consistent performance patterns or culturally-dependent behavior

3. **Training Data Influence Analysis:** Analyze the correlation between models' prosocial behavior strength and their exposure to instruction-tuned datasets (e.g., comparing base models vs. aligned models) to determine if the bias is emergent or inherited from training data