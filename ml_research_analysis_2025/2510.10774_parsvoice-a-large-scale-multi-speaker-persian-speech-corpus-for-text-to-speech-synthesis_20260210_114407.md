---
ver: rpa2
title: 'ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech
  Synthesis'
arxiv_id: '2510.10774'
source_url: https://arxiv.org/abs/2510.10774
tags:
- persian
- speech
- quality
- dataset
- speaker
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces ParsVoice, the largest Persian speech corpus
  for TTS applications, addressing the lack of high-quality Persian speech datasets.
  A scalable pipeline was developed to convert raw audiobook content into TTS-ready
  data using automated sentence segmentation, boundary optimization, and Persian-specific
  quality assessment.
---

# ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis

## Quick Facts
- arXiv ID: 2510.10774
- Source URL: https://arxiv.org/abs/2510.10774
- Reference count: 0
- Introduces ParsVoice, the largest Persian speech corpus for TTS applications

## Executive Summary
This work introduces ParsVoice, the largest Persian speech corpus for TTS applications, addressing the lack of high-quality Persian speech datasets. A scalable pipeline was developed to convert raw audiobook content into TTS-ready data using automated sentence segmentation, boundary optimization, and Persian-specific quality assessment. The resulting corpus includes 3,526 hours of speech from over 470 speakers, with 1,804 hours filtered for high TTS quality. Validation was performed by fine-tuning XTTS on ParsVoice, achieving a naturalness MOS of 3.6/5 and speaker similarity MOS of 4.0/5, demonstrating its effectiveness for multi-speaker TTS systems. The dataset is publicly available to advance Persian speech technology development.

## Method Summary
The ParsVoice corpus was created through an automated pipeline that transforms raw audiobook recordings into TTS-ready data. The process involves automated sentence segmentation using Persian-specific language models, boundary optimization to improve alignment accuracy, and quality assessment filters to ensure high TTS suitability. The pipeline processes 3,526 hours of audio from over 470 speakers, with 1,804 hours meeting the highest quality standards for TTS applications. The corpus was validated by fine-tuning the XTTS model, achieving naturalness MOS of 3.6/5 and speaker similarity MOS of 4.0/5.

## Key Results
- ParsVoice contains 3,526 hours of Persian speech from 470+ speakers
- 1,804 hours were filtered for high TTS quality
- XTTS fine-tuning achieved naturalness MOS of 3.6/5 and speaker similarity MOS of 4.0/5
- Corpus is publicly available for Persian speech technology development

## Why This Works (Mechanism)
The ParsVoice corpus succeeds by addressing the critical bottleneck in Persian TTS development: the lack of large-scale, high-quality speech data. The automated pipeline enables scalable conversion of existing audiobook content into TTS-ready format, while Persian-specific quality assessment ensures linguistic appropriateness. The multi-speaker nature provides the diversity needed for robust TTS systems, and the substantial corpus size enables effective training of modern neural TTS models.

## Foundational Learning
- Persian text-to-speech synthesis: Needed to understand the specific challenges of Persian phonology and prosody for TTS development. Quick check: Verify the corpus includes proper handling of Persian phonological rules.
- Multi-speaker TTS training: Required for understanding how speaker diversity impacts model generalization and naturalness. Quick check: Confirm the corpus supports speaker identity preservation across different voice types.
- Speech corpus quality assessment: Essential for evaluating the suitability of recorded speech for TTS applications. Quick check: Validate the filtering criteria effectively remove low-quality segments.
- Automated speech processing pipelines: Important for understanding how to efficiently convert raw recordings into TTS-ready data. Quick check: Assess the accuracy of automated sentence segmentation for Persian text.
- MOS evaluation methodology: Needed to properly interpret the reported naturalness and similarity scores. Quick check: Review the MOS test design and participant selection criteria.

## Architecture Onboarding

**Component Map:** Raw Audiobook Recordings -> Automated Segmentation -> Boundary Optimization -> Quality Filtering -> TTS-Ready Corpus

**Critical Path:** The quality filtering stage is the critical path, as it directly determines the usability of the final corpus for TTS applications. The filtering must balance removing low-quality segments while preserving sufficient data volume.

**Design Tradeoffs:** The automated pipeline prioritizes scalability over perfect accuracy, accepting some quality variability to achieve the large corpus size. This tradeoff enables processing thousands of hours but may introduce residual errors requiring manual review.

**Failure Signatures:** Common failure modes include misaligned sentence boundaries, inconsistent audio quality across recordings, and Persian-specific pronunciation errors. The quality filtering stage must effectively identify and remove these problematic segments.

**First Experiments:** 1) Test the automated segmentation accuracy on diverse audiobook genres, 2) Evaluate the quality filtering criteria by comparing filtered vs. unfiltered model performance, 3) Assess speaker identity preservation across different voice types in the corpus.

## Open Questions the Paper Calls Out
None

## Limitations
- Naturalness MOS of 3.6/5 indicates room for improvement compared to state-of-the-art systems in other languages
- The corpus relies heavily on audiobook content, potentially limiting coverage of diverse speaking styles and domains
- Automated pipeline may introduce quality variability not fully captured by reported quality control measures

## Confidence
- High Confidence: The corpus size (3,526 hours total, 1,804 hours filtered) and speaker diversity (470+ speakers) are accurately represented
- Medium Confidence: TTS model evaluation results are valid but may be influenced by uncontrolled factors
- Medium Confidence: The claim of being the "largest Persian speech corpus" is reasonable but requires additional verification

## Next Checks
1. Conduct systematic error analysis of sentence segmentation and boundary optimization algorithms across diverse audiobook genres
2. Perform cross-validation by training multiple TTS architectures on ParsVoice to assess dataset versatility
3. Evaluate the corpus's representation of different Persian dialects and speaking styles through linguistic analysis