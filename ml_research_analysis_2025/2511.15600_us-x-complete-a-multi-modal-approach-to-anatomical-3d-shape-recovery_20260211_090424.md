---
ver: rpa2
title: 'US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery'
arxiv_id: '2511.15600'
source_url: https://arxiv.org/abs/2511.15600
tags:
- ultrasound
- completion
- x-ray
- shape
- spine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a multi-modal deep learning method for completing
  occluded anatomical structures in 3D ultrasound spine imaging by leveraging complementary
  information from a single X-ray image. The approach generates paired training data
  from synthetic X-ray projections and ultrasound-consistent partial vertebrae point
  clouds derived from CT scans.
---

# US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery

## Quick Facts
- arXiv ID: 2511.15600
- Source URL: https://arxiv.org/abs/2511.15600
- Reference count: 29
- Demonstrates significant improvements in vertebral reconstruction (p < 0.001) using multi-modal fusion of ultrasound and X-ray data

## Executive Summary
US-X Complete introduces a novel multi-modal deep learning framework for completing occluded anatomical structures in 3D ultrasound spine imaging by leveraging complementary information from a single X-ray image. The method generates paired training data from synthetic X-ray projections and ultrasound-consistent partial vertebrae point clouds derived from CT scans. A two-stage coarse-to-fine probabilistic network integrates morphological information from both modalities using early and late fusion strategies, demonstrating significant improvements in vertebral reconstruction compared to ultrasound-only approaches. Phantom studies validate the clinical feasibility of achieving more accurate, complete volumetric lumbar spine visualization overlayed on ultrasound scans without requiring registration with preoperative CT imaging.

## Method Summary
The method uses a two-stage coarse-to-fine VAE architecture based on VRCNet. First, synthetic training pairs are generated from CT volumes in the VerSe2020 dataset: physics-aware ray-casted partial point clouds simulating ultrasound occlusions, and lateral X-ray projections from 3D vertebral segmentations. The coarse stage uses early fusion of US and X-ray encodings to create a latent representation, while the refinement stage employs late fusion with one-hot source encoding. Both stages use KL divergence loss to maintain anatomical priors. The model is trained on 60-20-20 split of 149 lumbar samples (745 vertebrae) and evaluated on both synthetic test sets and phantom data.

## Key Results
- Vertebral body Chamfer Distance improves from 20.7±5.1 to 7.1±2.0 on phantom data
- Vertebral arch Chamfer Distance improves from 11.4±2.4 to 7.8±2.5 on phantom data
- Overall improvements are statistically significant (p < 0.001) across all metrics and datasets

## Why This Works (Mechanism)

### Mechanism 1: Complementary Modality Fusion via Dual-Stage Integration
X-ray provides global geometric constraints (vertebral body dimensions, alignment) that ultrasound lacks due to acoustic shadowing, while ultrasound provides localized surface details (vertebral arch morphology) that X-ray cannot capture due to projection collapse. Early fusion creates a unified latent representation for coarse templating; late fusion preserves modality-specific geometric details through one-hot source encoding during refinement.

### Mechanism 2: Physics-Aware Synthetic-to-Real Transfer
The simulation pipeline mimics modality-specific physical constraints: ray-casting with surface normal filtering simulates US reflection physics, and lateral projections simulate X-ray depth collapse. These physics-based constraints preserve the structural relationship between what each modality observes and what is occluded, creating domain-relevant training signal.

### Mechanism 3: Probabilistic Shape Prior with Conditional Completion
The coarse VRCNet-based stage learns a prior over complete vertebrae (via autoencoding full shapes) and a posterior conditioned on partial observations. KL divergence forces the conditioned posterior to remain near the anatomical prior, preventing anatomically implausible completions.

## Foundational Learning

### Concept 1: Variational Autoencoders (VAEs) for Shape Completion
Why needed: The architecture uses dual VAEs with KL divergence loss; understanding the prior/posterior relationship is essential to debug reconstruction quality.
Quick check: Can you explain why sampling from the posterior at inference (rather than the prior) enables conditional completion?

### Concept 2: Point Cloud Representation and Chamfer Distance
Why needed: The method operates on point clouds rather than voxels or meshes; Chamfer Distance is the primary metric.
Quick check: Given two point sets S1 and S2, what does it mean if CD(S1→S2) is low but CD(S2→S1) is high?

### Concept 3: Multi-Modal Fusion Strategies (Early vs. Late Fusion)
Why needed: The paper introduces both Early Fusion (latent space concatenation) and Late Fusion (point-level source encoding); ablation results show Late Fusion alone significantly outperforms Early Fusion alone.
Quick check: Why might fusing at the refinement stage (late) be more effective for preserving X-ray geometric details than fusing at the encoding stage (early)?

## Architecture Onboarding

### Component Map
Input Pipeline: CT Volume + Annotations (VerSe20) -> Physics-aware Ray-casting -> US Partial Point Cloud (2048 pts, occluded)
Input Pipeline: CT Volume + Annotations (VerSe20) -> Lateral Projection + z-embedding -> X-ray 2.5D Point Cloud (2048 pts)
Combined -> Multi-modal Point Cloud (with source encoding) -> Coarse Stage (VAE) -> Early Fusion Block -> Concatenate -> Feature Selection -> 1024-dim latent -> Prior/Posterior Inference -> Gaussian (μ, σ) -> Sample -> Decoder -> Coarse Completion (2048 pts) -> Loss: L_coarse = CD(coarse, gt) + β·KL(posterior || prior)
Coarse + US_partial + X-ray_partial (with one-hot source encoding) -> Refinement Stage (VAE) -> Point-based Encoder-Decoder with Self-Attention -> Late Fusion Block -> Output: Refined Completion (2048 pts) -> Loss: L_refine = CD(refined, gt) + β·KL

### Critical Path
1. Data alignment is the single point of failure: if US and X-ray are misregistered by >5mm, the one-hot encoding cannot compensate—the network receives contradictory spatial signals.
2. Synthetic data quality gates everything: the VerSe20 preprocessing (ray-casting angle thresholds, projection plane selection) defines what the network learns. Errors here propagate to all downstream stages.
3. KL weight β controls the prior/observation balance: too high → completions revert to mean vertebra; too low → anatomically implausible extrapolation.

### Design Tradeoffs
| Choice | Benefit | Cost |
|--------|---------|------|
| Point cloud vs. voxel | Memory-efficient, handles sparse observations | No explicit surface connectivity |
| Synthetic training | Unlimited paired data, perfect alignment | Domain gap to real clinical images |
| Single X-ray vs. multi-view | Minimal radiation, OR workflow compatible | Limited 3D constraint information |
| Vertebral-level completion | Local precision, parallelizable | Ignores inter-vertebral spatial constraints |

### Failure Signatures
| Symptom | Likely Cause | Diagnostic Check |
|---------|--------------|------------------|
| Vertebral body dimensions consistently wrong | X-ray not providing effective constraint | Compare completions with X-ray-only baseline; check if network attends to X-ray input (ablate US) |
| Arch completion worse than baseline | Late fusion not integrating US local details | Run Late Fusion ablation; verify one-hot encoding is correctly applied |
| Anatomically implausible shapes (spikes, discontinuities) | KL weight too low or VAE posterior collapse | Visualize latent space; check KL term magnitude during training |
| Phantom results much worse than synthetic | Registration error or sim-to-real gap | Quantify registration accuracy; compare synthetic test set (held out) vs. phantom CD distribution |

### First 3 Experiments
1. Reproduce synthetic baseline comparison: Train on VerSe20 split (60-20-20), evaluate CD/EMD/F1 vs. baseline [10] on synthetic test set. Verify p < 0.001 significance.
2. Ablation: US-only vs. X-ray-only vs. Combined: Isolate each modality's contribution.
3. Registration sensitivity analysis: Systematically perturb US-Xray alignment (translate 0-10mm, rotate 0-5°) and measure CD degradation.

## Open Questions the Paper Calls Out

### Open Question 1
Can the shape completion pipeline be made robust to misalignments between ultrasound and X-ray, or function without explicit registration? The current heuristic alignment depends on the US field of view and is sensitive to segmentation noise. Future work should focus on improving robustness against such misalignments or exploring registration-free alternatives.

### Open Question 2
Does modeling the spine as an interconnected structure improve reconstruction accuracy compared to the current vertebra-by-vertebra approach? The current method processes each vertebra independently, potentially missing global geometric consistencies. Treating the spine as an interconnected structure with inherent spatial constraints between adjacent vertebrae could lead to more accurate and anatomically consistent results.

### Open Question 3
Does training with diverse patient positioning and spine curvatures improve the method's generalizability to real clinical setups? The current training data derives from a specific dataset (VerSe2020) and validation is limited to phantoms. Accounting for diverse patient positioning and therefore various spine curvatures to improve generalisability across different setups remains an open challenge.

## Limitations
- Synthetic-to-real domain gap: Method relies entirely on synthetic training data without quantifying the sim-to-real transfer gap or validating on real clinical ultrasound data.
- Registration robustness: Heuristic US-Xray alignment method is vulnerable to limited US field of view and segmentation noise, with no quantitative assessment of registration accuracy.
- Clinical generalization: Method tested only on phantom data and synthetic cases, with no evaluation of pathological vertebrae or assessment of intraoperative workflow integration.

## Confidence

**High confidence:** The multi-modal fusion concept is well-supported by quantitative improvements in both phantom and synthetic test sets (p < 0.001). The two-stage coarse-to-fine architecture with early/late fusion is clearly specified and implemented.

**Medium confidence:** Physics-aware synthetic data generation effectively captures modality-specific occlusions, but without direct comparison to real US/Xray pairs, the domain transfer remains partially validated. The VAE-based probabilistic completion is theoretically sound but untested on pathological cases.

**Low confidence:** Clinical feasibility claims are based solely on phantom validation. No assessment of intraoperative workflow integration, radiation exposure, or operator variability is provided.

## Next Checks
1. Real-data pilot study: Validate on a small cohort of patients with both CT and intraoperative ultrasound/Xray to quantify domain transfer and identify clinical failure modes.
2. Pathological case evaluation: Test the method on CT scans with vertebral fractures, scoliosis, or surgical implants to assess anatomical prior limitations.
3. Robustness to registration noise: Systematically evaluate CD degradation with increasing US-Xray misalignment (0-10mm translation, 0-5° rotation) to define clinical tolerances.