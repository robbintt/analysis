---
ver: rpa2
title: 'Towards generating more interpretable counterfactuals via concept vectors:
  a preliminary study on chest X-rays'
arxiv_id: '2506.04058'
source_url: https://arxiv.org/abs/2506.04058
tags:
- concept
- vectors
- latent
- space
- explanations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method to generate interpretable counterfactual
  explanations for chest X-ray imaging using Concept Activation Vectors (CAVs). The
  approach maps clinical concepts into the latent space of a reconstruction autoencoder,
  enabling the generation of visual explanations that highlight clinically relevant
  features without requiring explicit training on class labels.
---

# Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays

## Quick Facts
- arXiv ID: 2506.04058
- Source URL: https://arxiv.org/abs/2506.04058
- Reference count: 7
- Key outcome: This paper introduces a method to generate interpretable counterfactual explanations for chest X-ray imaging using Concept Activation Vectors (CAVs).

## Executive Summary
This paper introduces a method to generate interpretable counterfactual explanations for chest X-ray imaging using Concept Activation Vectors (CAVs). The approach maps clinical concepts into the latent space of a reconstruction autoencoder, enabling the generation of visual explanations that highlight clinically relevant features without requiring explicit training on class labels. CAVs are generated by training a linear classifier in the embedding space to identify directions corresponding to user-defined concepts, and counterfactual explanations are produced by traversing the latent space along these concept directions. The method is evaluated on two chest X-ray datasets (NIH and CheXpert) for five pathologies, demonstrating that CAVs are stable and generalizable across datasets, with concept vectors exhibiting positive alignment both within and across datasets.

## Method Summary
The method leverages Concept Activation Vectors (CAVs) to generate interpretable counterfactual explanations for chest X-ray imaging. The approach uses a reconstruction autoencoder to map clinical concepts into its latent space. CAVs are created by training a linear classifier in the embedding space to identify directions corresponding to user-defined clinical concepts. Counterfactual explanations are then generated by traversing the latent space along these concept directions. The method does not require explicit training on class labels, making it adaptable to various clinical concepts. The approach is evaluated on two chest X-ray datasets (NIH and CheXpert) for five different pathologies, focusing on the stability and generalizability of the generated CAVs.

## Key Results
- CAVs are stable and generalizable across datasets, with concept vectors showing positive alignment both within and across datasets
- The method performs well for larger pathologies like cardiomegaly but faces challenges with smaller pathologies such as atelectasis
- While not outperforming the baseline in terms of Intersection over Union (IoU), the approach provides a simple framework for integrating clinical knowledge into generative models

## Why This Works (Mechanism)
The approach works by leveraging the latent space of a reconstruction autoencoder to represent clinical concepts as directions (CAVs) that can be traversed to generate counterfactual explanations. By training a linear classifier in the embedding space, the method identifies meaningful directions corresponding to user-defined clinical concepts without requiring explicit class label supervision. The counterfactual explanations are generated by moving along these concept directions in the latent space, which produces visual changes that highlight clinically relevant features. The stability and positive alignment of CAVs across datasets suggest that the learned concept directions capture consistent and generalizable clinical patterns in chest X-ray imaging.

## Foundational Learning
- **Concept Activation Vectors (CAVs)**: Directions in the latent space that correspond to user-defined clinical concepts. Why needed: To represent clinical concepts as traversable directions in the model's embedding space. Quick check: Verify that CAVs can be learned without explicit class label supervision.
- **Reconstruction Autoencoder**: A neural network architecture that learns to compress and reconstruct input data. Why needed: To create a meaningful latent space where clinical concepts can be represented as directions. Quick check: Ensure the autoencoder achieves low reconstruction error on the chest X-ray dataset.
- **Latent Space Traversal**: The process of moving along specific directions in the embedding space to generate counterfactual examples. Why needed: To create visual explanations that highlight clinically relevant features by showing what changes would support or refute a diagnosis. Quick check: Confirm that traversal along CAVs produces visually coherent and interpretable changes in the output images.

## Architecture Onboarding

**Component Map**: Input Images -> Reconstruction Autoencoder -> Embedding Space -> Linear Classifier (for CAVs) -> Latent Space Traversal -> Counterfactual Explanations

**Critical Path**: The critical path involves encoding the input image into the latent space, identifying the relevant CAV direction, traversing the latent space along that direction, and decoding the modified latent representation back to image space to generate the counterfactual explanation.

**Design Tradeoffs**: The method trades explicit class label supervision for the ability to integrate clinical knowledge directly into the model. This allows for more interpretable explanations but may result in less precise localization compared to supervised approaches. The reconstruction autoencoder component prioritizes faithful reconstruction over feature extraction, which may limit performance on smaller pathologies.

**Failure Signatures**: The method may struggle with smaller pathologies due to limitations in reconstruction fidelity and feature localization. The counterfactual explanations may not achieve optimal Intersection over Union (IoU) compared to supervised baseline methods, suggesting potential trade-offs between interpretability and precision.

**3 First Experiments**:
1. Evaluate CAV stability by training on one dataset and testing on another to confirm positive alignment across datasets
2. Generate counterfactual explanations for a held-out set of chest X-rays and assess visual interpretability by clinical experts
3. Compare reconstruction quality with and without CAV traversal to ensure the autoencoder maintains fidelity during counterfactual generation

## Open Questions the Paper Calls Out
None

## Limitations
- The method's performance for smaller pathologies like atelectasis remains suboptimal due to reconstruction fidelity and feature localization challenges
- The comparison with baseline methods showed no improvement in Intersection over Union (IoU), indicating potential trade-offs between interpretability and precision
- The evaluation focused on five specific pathologies, limiting generalizability to the broader range of radiological findings

## Confidence
- **High Confidence**: The methodology for generating Concept Activation Vectors (CAVs) and traversing latent space is technically sound and well-implemented
- **Medium Confidence**: The interpretability of the generated counterfactuals from a clinical perspective is supported but relies heavily on qualitative assessment
- **Medium Confidence**: The claim that the approach provides a simple framework for integrating clinical knowledge is supported, but practical utility in real-world clinical settings requires further validation

## Next Checks
1. Conduct a formal clinical study with board-certified radiologists to evaluate whether the generated counterfactual explanations improve diagnostic accuracy, confidence, or educational value compared to existing methods

2. Extend the evaluation to include a broader range of pathologies, including both common and rare findings, to assess the method's generalizability across different clinical scenarios and pathology sizes

3. Perform ablation studies to quantify the contribution of the reconstruction autoencoder component versus alternative feature extraction methods, and to determine optimal hyperparameters for CAV generation across different pathology types