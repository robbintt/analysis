---
ver: rpa2
title: 'Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data'
arxiv_id: '2508.13040'
source_url: https://arxiv.org/abs/2508.13040
tags:
- fairness
- data
- joint
- internal
- external
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the challenge of estimating model fairness\
  \ when protected attribute data is unavailable due to privacy or legal constraints.\
  \ It proposes leveraging incomplete marginal datasets\u2014such as internal data\
  \ without protected attributes and external public data containing them\u2014to\
  \ estimate the joint distribution needed for fairness evaluation."
---

# Beyond Internal Data: Bounding and Estimating Fairness from Incomplete Data

## Quick Facts
- arXiv ID: 2508.13040
- Source URL: https://arxiv.org/abs/2508.13040
- Reference count: 40
- The paper proposes methods to estimate and bound fairness metrics when protected attribute data is unavailable by combining internal and external datasets.

## Executive Summary
This paper addresses the challenge of estimating model fairness when protected attribute data is unavailable due to privacy or legal constraints. It proposes leveraging incomplete marginal datasets—such as internal data without protected attributes and external public data containing them—to estimate the joint distribution needed for fairness evaluation. Two approaches are explored: one using structural assumptions to estimate a single joint distribution, and another constructing a feasible set of joint distributions consistent with the marginals. Experiments show that averaging fairness metrics over the feasible set closely approximates true values, with low estimation bias and stable bounds across varying data inconsistency.

## Method Summary
The paper proposes two methods to estimate fairness metrics when protected attributes are missing from internal data. The first approach constructs a feasible set of joint distributions consistent with both internal marginals (predictive features and overlapping features) and external marginals (protected attributes and overlapping features). For 3 binary variables, this involves iterating over free parameters on a grid to generate valid joint distributions. The second approach uses structural assumptions (Latent Naive Bayes) to estimate a single joint distribution via EM algorithm. Both methods compute fairness metrics (Disparate Impact and Demographic Disparity) across the resulting distributions and compare against ground truth.

## Key Results
- Bounds derived from the feasible set consistently contain the true fairness metric across all tested conditions
- Averaging fairness metrics over the feasible set yields low-bias point estimates (mean differences of -0.010 for DI and -0.002 for DD)
- The method remains robust to moderate marginal inconsistency (KL divergence up to ~0.5) with small estimation error

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bounds derived from the feasible set of joint distributions reliably contain the true fairness metric, even under marginal inconsistency.
- Mechanism: The internal marginal $p_{\text{bank}}(s, o)$ and external marginal $p_{\text{public}}(o, e)$ jointly constrain the space of compatible joint distributions $p(s, o, e)$. Any valid joint must satisfy both marginal constraints, which reduces an underdetermined system to a bounded feasible region. Fairness metrics computed across this region produce an interval that, by construction, brackets the true metric if the ground truth joint lies within the feasible set.
- Core assumption: The true joint distribution is consistent with at least one member of the computed feasible set.
- Evidence anchors:
  - "100% of the derived bounds from the possible fairness values across feasible joint distributions consistently contain the true fairness metric" (Page 6).
  - "bounds that consistently contain the true metric."
- Break condition: If marginals are so mismatched that the feasible set becomes empty or excludes the true joint, bounds may fail to cover the true metric.

### Mechanism 2
- Claim: Averaging fairness metrics over the feasible set yields low-bias point estimates, provided the feasible set is symmetrically distributed around the true joint.
- Mechanism: Each feasible joint produces a candidate fairness value. The mean across all candidates acts as an estimator whose bias depends on the distribution of feasible joints relative to ground truth.
- Core assumption: The uniform or grid-based sampling over free parameters approximates a "non-informative" prior over feasible joints.
- Evidence anchors:
  - "mean differences of −0.010, (±0.410) for DI and −0.002, (±0.151) for DD" (Page 6).
  - "bias is small in magnitude, suggesting that the average over possible fairness estimates provides a reasonably accurate approximation."
- Break condition: If the true joint lies near a boundary of the feasible region, or if the feasible set is highly asymmetric, the mean may be biased.

### Mechanism 3
- Claim: The bounding method remains robust to moderate marginal inconsistency (KL divergence up to ~0.5) because constraints are relaxed to match conditionals rather than full marginals.
- Mechanism: When $p_{\text{bank}}(o) \neq p_{\text{public}}(o)$, the method enforces $p_{\text{public}}(o, e)$ exactly but only requires $p_{\text{bank}}(s | o)$ to match the joint's conditionals, allowing the common-variable marginal to differ.
- Core assumption: The external marginal (e.g., census) is representative of the population over which fairness is evaluated.
- Evidence anchors:
  - "across all levels of marginal inconsistency... the average difference... remains small, below 0.003 for DD and around 0.01 for DI" (Page 6).
  - Equations (6)-(8) define the constraint relaxation for inconsistent marginals.
- Break condition: If external data is not representative, bounds may be uninformative or misleading.

## Foundational Learning

- Concept: Joint vs. Marginal Distributions
  - Why needed here: The entire method hinges on reconstructing an unknown joint $p(s, o, e)$ from known marginals $p(s, o)$ and $p(o, e)$.
  - Quick check question: Given $p(A, B)$ and $p(B, C)$, can you always uniquely determine $p(A, B, C)$? (Answer: No, unless additional assumptions are made.)

- Concept: Fairness Metrics (Disparate Impact, Demographic Disparity)
  - Why needed here: These are the quantities being bounded. DI is a ratio of positive-outcome rates across groups; DD is their difference.
  - Quick check question: If $p(\hat{y}=1 | e=0) = 0.4$ and $p(\hat{y}=1 | e=1) = 0.5$, what are DI and DD? (Answer: DI = 0.8, DD = -0.1.)

- Concept: Constraint Satisfaction and Feasible Sets
  - Why needed here: The method formulates fairness estimation as a linear constraint satisfaction problem over probability simplices.
  - Quick check question: If you have 8 unknowns (joint probabilities) and 6 linear constraints, how many free parameters remain? (Answer: 2, as shown in Appendix A.)

## Architecture Onboarding

- Component map:
  - Internal marginal extraction -> External marginal extraction -> Constraint engine -> Feasible set generator -> Fairness evaluator -> Aggregator
  - Structural method: Internal marginal extraction -> External marginal extraction -> Latent Naive Bayes training -> Fairness evaluation

- Critical path: Marginal extraction -> constraint formulation -> feasible set enumeration -> fairness computation -> bound aggregation. The constraint formulation step (distinguishing consistent vs. inconsistent marginals) determines which constraints apply and is the most consequential for correctness.

- Design tradeoffs:
  - Structural assumptions vs. feasible set: Latent Naïve Bayes yields a single estimate but can be highly biased if assumptions fail. Feasible set provides bounds but can be wide.
  - Grid resolution vs. computational cost: 100 values per free parameter yields 10,000 joints for 3 binary variables; scales exponentially with dimensionality.
  - Marginal consistency enforcement: Strict consistency may yield empty feasible sets; relaxed constraints increase robustness but may widen bounds.

- Failure signatures:
  - Empty feasible set: Indicates contradictory marginals. Check KL divergence; consider relaxation.
  - Extremely wide bounds (DI range > 3): Suggests insufficient overlap between datasets or too few constraints.
  - Mean fairness estimate near bound edge: May indicate asymmetric feasible set.

- First 3 experiments:
  1. Reproduce simulation study: Generate random ground truth joints, split into marginals, compute feasible set, verify 100% bound coverage and low mean bias.
  2. Stress-test marginal inconsistency: Systematically vary KL divergence between marginals and plot bound width and estimation error vs. inconsistency level.
  3. Real-data sanity check: On Adult dataset, compare DI bounds from feasible set against true DI from full joint; compare with Latent Naïve Bayes estimate to quantify assumption risk.

## Open Questions the Paper Calls Out

- How can the feasible set method be generalized to high-dimensional settings to overcome the exponential computational complexity associated with joint distribution estimation?
  - The conclusion states that "future work should generalise to higher-dimensional settings and develop efficient strategies for sampling the feasible space."
- Is the proposed approach applicable to other fairness definitions beyond Disparate Impact and Demographic Disparity?
  - The conclusion notes that "evaluating the applicability of our approach to other fairness definitions remains an important direction for future research."
- Can additional external information or constraints be integrated to effectively tighten the bounds of the feasible fairness metrics?
  - The authors note in Section 3.1.2 that while bounds contain the true metric, the range can be wide, "highlighting the potential benefit of incorporating additional external information to further tighten the bounds."

## Limitations

- The method assumes the true joint distribution lies within the computed feasible set, which may not hold when marginals are highly inconsistent or when unmodeled selection bias exists.
- Computational complexity grows exponentially with dimensionality, limiting practical application to datasets with more than 3-4 binary variables.
- The structural assumptions approach (Latent Naïve Bayes) shows high bias risk when assumptions fail, as demonstrated in the Adult dataset experiments.

## Confidence

- High confidence: The feasible set method consistently bounds true fairness metrics when marginal constraints are satisfied, and the averaging estimator shows low bias in simulation settings.
- Medium confidence: The method's robustness to marginal inconsistency is empirically supported but may not generalize to all real-world scenarios, particularly when external data is not representative.
- Low confidence: The claim that structural assumptions (Latent Naïve Bayes) provide reliable estimates in practice, given the demonstrated sensitivity to assumption violations and high bias in some cases.

## Next Checks

1. Real-world marginal inconsistency test: Apply the method to two real datasets with known protected attributes, artificially split them into inconsistent marginals, and measure how bound width and estimation error scale with KL divergence.

2. Empty feasible set stress test: Systematically construct marginal pairs that are deliberately incompatible and verify that the relaxed constraint approach (Equation 8) successfully recovers a non-empty feasible set without excessive bound inflation.

3. Representative external data validation: Use an external dataset that is known to be unrepresentative of the internal population (e.g., national census vs. local applicant pool) and assess whether the resulting fairness bounds remain meaningful or become too wide to be actionable.