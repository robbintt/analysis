---
ver: rpa2
title: Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation
arxiv_id: '2511.18711'
source_url: https://arxiv.org/abs/2511.18711
tags:
- domain
- shot
- features
- multimodal
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses Few-Shot Video Domain Adaptation (FSVDA),
  a challenging task where only limited labeled target videos are available. The multimodal
  nature of videos introduces complexity, as each modality (e.g., RGB and optical
  flow) contains components with varying domain shifts.
---

# Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation

## Quick Facts
- arXiv ID: 2511.18711
- Source URL: https://arxiv.org/abs/2511.18711
- Authors: Yuyang Wanyan; Xiaoshan Yang; Weiming Dong; Changsheng Xu
- Reference count: 40
- Primary result: Proposes MC-LRD framework achieving state-of-the-art performance on multimodal few-shot video domain adaptation benchmarks

## Executive Summary
This paper addresses Few-Shot Video Domain Adaptation (FSVDA) where limited labeled target videos are available. The multimodal nature of videos introduces complexity as each modality (RGB and optical flow) contains components with varying domain shifts. Existing methods struggle to effectively align domains while leveraging modality collaboration. The authors propose Modality-Collaborative Low-Rank Decomposers (MC-LRD) that decompose features into modality-unique and modality-shared components using progressively shared low-rank decomposers and Multimodal Decomposition Routers (MDR). Experiments on three benchmarks demonstrate significant improvements over existing methods.

## Method Summary
MC-LRD decomposes multimodal features into modality-unique and modality-shared components using progressively shared low-rank decomposers. The framework employs Multimodal Decomposition Routers (MDR) that selectively activate decomposers based on input characteristics. The method includes orthogonal decorrelation constraints and a cross-domain activation consistency loss to ensure efficient decomposition and facilitate alignment. Training occurs in two stages: pre-training on source domain followed by adaptation on both source and target domains with frozen backbone.

## Key Results
- On EPIC-Kitchens, MC-LRD achieves 49.9% and 52.2% mean accuracy in 1-shot and 5-shot settings respectively
- Outperforms second-best multimodal method by 4.2% and 5.0% on EPIC-Kitchens
- Reduces training complexity by updating fewer parameters compared to parallel multimodal approaches
- Demonstrates effectiveness across three benchmarks: EPIC-Kitchens, UCF-HMDB, and Jester

## Why This Works (Mechanism)

### Mechanism 1: Progressive Feature Decomposition
Decomposing multimodal features into modality-unique and modality-shared components enables targeted domain alignment at different shift levels. Low-rank decomposers with progressively shared parameters extract features along a spectrum from fully modality-specific to fully shared, allowing decomposers to specialize while benefiting from cross-modal guidance.

### Mechanism 2: Adaptive Multimodal Routing
Multimodal Decomposition Routers (MDR) enable sample-adaptive feature decomposition by learning to weight decomposers based on input characteristics. Three sub-routers compute softmax weights over decomposer outputs, with the modality-shared router using weight-sharing across modalities via concatenated features.

### Mechanism 3: Cross-Domain Activation Consistency
Cross-domain activation consistency loss ensures target samples activate the same decomposers as same-category source samples, enabling alignment without direct feature matching. This transfers activation patterns from source (where they're well-learned) to target (where data is scarce).

## Foundational Learning

- **Domain Adaptation vs. Domain Generalization**: FSVDA has access to few labeled target samples—this is adaptation, not generalization. The distinction determines whether alignment losses are feasible. Quick check: If you had zero target labels, would cross-domain activation consistency still be computable?

- **Low-Rank Adaptation (LoRA)**: The decomposers extend LoRA from parameter-efficient fine-tuning to feature decomposition. Understanding LoRA's rank constraint (d_ra) is critical for hyperparameter selection. Quick check: Why does Figure 5 show optimal performance at d_ra=64 rather than maximum rank 256?

- **Mixture of Experts (MoE) Routing**: MDR implements sparse routing over decomposers. Unlike dense MoE, the softmax weighting allows all decomposers to contribute, but orthogonality constraints enforce specialization. Quick check: What would happen if router outputs were uniform (all weights ≈ 1/Nc)?

## Architecture Onboarding

- **Component map**: Input (RGB + Flow) → I3D Backbone (frozen) → Base Transformer (frozen after pre-training) → MC-LRD (clip-level + video-level) → Output: f^u_r, f^s_r, f^u_o, f^s_o → Classifiers

- **Critical path**: Base model pre-training (source only, 2 epochs) → Freeze backbone/base → Adaptation (source+target, 50 epochs, train only decomposers/routers/classifiers)

- **Design tradeoffs**: Nc=6 decomposers balance capacity vs. overfitting risk; progressive sharing enables cross-modal guidance but may blur modality-specific features; clip-level + video-level captures dynamics but doubles decomposer parameters

- **Failure signatures**: Router collapse (uniform weights), decomposer redundancy (L_dd fails to decrease), negative transfer (accuracy drops below baseline), modality imbalance (one modality dominates)

- **First 3 experiments**: 1) Ablation on EPIC-Kitchens D1→D2 (1-shot) removing L_ac, L_dd, L_rd individually; 2) Hyperparameter sweep on rank d_ra ∈ {8,16,32,64,128,256}; 3) Visualize router weights to check activation patterns

## Open Questions the Paper Calls Out

- Can the MC-LRD framework be extended to scenarios where specific modalities are missing during inference while maintaining robust performance?
- How can the progressively shared parameter design be generalized to handle multimodal scenarios involving more than two modalities?
- Is the proposed decomposition strategy effective for structured video understanding tasks, such as temporal action localization or behavior prediction?

## Limitations

- The cross-domain activation consistency mechanism may cause negative transfer when target domain semantics shift significantly
- Progressive sharing weight interpretation lacks rigorous validation of optimal schedules
- Current framework is limited to two modalities (RGB and optical flow) and doesn't generalize to N-modal scenarios

## Confidence

- **High confidence**: Core decomposition architecture and MDR routing mechanisms are well-specified and experimentally validated
- **Medium confidence**: Progressive sharing mechanism's effectiveness and cross-domain activation consistency assumption are plausible but not rigorously validated
- **Low confidence**: Optimal configuration of progressive sharing schedules and robustness to semantic domain shifts remain unclear

## Next Checks

1. Create controlled experiments where target domain semantics shift (same labels, different visual appearances) and measure whether L_ac causes negative transfer

2. Implement alternative progressive sharing schedules (exponential, logarithmic, learned weights) and compare performance on EPIC-Kitchens

3. Conduct per-class router weight analysis to identify classes where unique vs. shared routers dominate and compare against known domain shift patterns