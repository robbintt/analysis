---
ver: rpa2
title: 'iN2V: Bringing Transductive Node Embeddings to Inductive Graphs'
arxiv_id: '2506.05039'
source_url: https://arxiv.org/abs/2506.05039
tags:
- inductive
- in2v
- embeddings
- transductive
- original
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: iN2V introduces a post-hoc extension method to generate embeddings
  for unseen nodes in inductive graph learning, overcoming the transductive limitation
  of traditional node2vec. The method combines iterative neighborhood averaging with
  a convex combination of original and neighbor embeddings, enhanced by modifications
  to the training procedure that better prepare embeddings for induction.
---

# iN2V: Bringing Transductive Node Embeddings to Inductive Graphs

## Quick Facts
- arXiv ID: 2506.05039
- Source URL: https://arxiv.org/abs/2506.05039
- Authors: Nicolas Lell; Ansgar Scherp
- Reference count: 40
- Primary result: iN2V improves node classification accuracy by an average of 1 point over baselines, with gains up to 6 points depending on dataset and training size

## Executive Summary
iN2V introduces a post-hoc extension method to generate embeddings for unseen nodes in inductive graph learning, overcoming the transductive limitation of traditional node2vec. The method combines iterative neighborhood averaging with a convex combination of original and neighbor embeddings, enhanced by modifications to the training procedure that better prepare embeddings for induction. Experiments show iN2V improves node classification accuracy by an average of 1 point over baselines, with gains up to 6 points depending on dataset and training size. It outperforms Feature Propagation, remains effective even with only 10% training data, and can be combined with existing features or other GNNs, demonstrating versatility and robustness. Limitations include reduced performance on highly heterophilic datasets and reliance on connectivity between training and test nodes.

## Method Summary
iN2V is a post-hoc extension method that generates embeddings for unseen nodes in inductive graph learning by combining iterative neighborhood averaging with convex combinations of original and neighbor embeddings. The approach modifies the Node2Vec training procedure with loss terms that pull node embeddings toward their neighborhood mean while preventing collapse to a single vector. During inference, the method iteratively computes unseen node embeddings as the mean of their neighbors, updating training node embeddings with a weighted combination that allows adaptation to new topology. This differs from Feature Propagation by allowing training embeddings to adapt rather than remaining frozen, and from standard Node2Vec by incorporating inductive capabilities through loss modifications and post-hoc extension.

## Key Results
- Improves node classification accuracy by an average of 1 point over baselines
- Achieves gains up to 6 points depending on dataset and training size
- Outperforms Feature Propagation while remaining effective with only 10% training data

## Why This Works (Mechanism)

### Mechanism 1: Adaptive Post-Hoc Aggregation
The paper suggests that extending embeddings to unseen nodes requires not just averaging neighbors but allowing existing training embeddings to adapt to the new topology. iN2V iteratively assigns embeddings to unseen nodes by taking the mean of their neighbors, while crucially updating training node embeddings using a convex combination. This allows "bridge" nodes to shift their position to better accommodate the unseen structure, rather than remaining fixed. The core assumption is that test nodes have a path to at least one training node, and the local neighborhood structure is predictive of the node's properties (homophily).

### Mechanism 2: Inference-Training Alignment via Regularization
Modifying the Node2Vec training objective to mimic the post-hoc inference behavior improves the "quality" of the base embeddings for extension. The authors introduce a loss term that pulls a node's embedding closer to the mean of its neighbors, aligning the training objective with the post-hoc logic. A secondary term prevents trivial solutions where all embeddings collapse to the same vector. The core assumption is that a node's identity is sufficiently represented by the average of its local neighborhood.

### Mechanism 3: Structural Information Encoding
iN2V embeddings encode sufficient structural information to reduce the reliance on message-passing during the downstream classification task. By explicitly propagating and averaging embeddings, iN2V performs a form of message passing before the downstream model sees the data. The paper observes that using iN2V embeddings narrows the performance gap between MLPs (which don't pass messages) and GraphSAGE (which does). The core assumption is that the downstream task benefits primarily from local neighborhood aggregation rather than complex global patterns.

## Foundational Learning

- **Concept: Transductive vs. Inductive Learning**
  - Why needed here: This is the central problem definition. Transductive learning assumes the test graph is fully visible during training; Inductive learning assumes nodes appear after training. Understanding this distinction is necessary to grasp why standard Node2Vec fails and why a post-hoc extension is needed.
  - Quick check question: If a new user joins a social network after you've trained your model, are you in a transductive or inductive setting?

- **Concept: Homophily vs. Heterophily**
  - Why needed here: The paper explicitly identifies performance degradation on heterophilic datasets. Understanding that "neighbors are different" violates the core assumption of averaging-based propagation is critical for interpreting the results.
  - Quick check question: If a node's neighbors all belong to different classes, will averaging their features likely help or hurt classification accuracy?

- **Concept: Random Walks (Node2Vec context)**
  - Why needed here: iN2V modifies the training of Node2Vec, which is based on random walks. To understand the "Loss-based" and "Sampling-based" modifications, one must understand that Node2Vec generates "context" for a node based on these walks.
  - Quick check question: In Node2Vec, does the embedding optimization prioritize making a node similar to its immediate neighbors or its random-walk context?

## Architecture Onboarding

- **Component map:** Node2Vec (Modified with $L_{close}$ and $L_{div}$ losses) -> Post-Hoc Extender (Iterative algorithm using lookup vector `s` and convex combination $\lambda$) -> Downstream Model (MLP or GNN consuming final embeddings)

- **Critical path:**
  1. Training: Train N2V on the subgraph induced by training nodes. Tune $\alpha, \beta$ for the loss modifications.
  2. Propagation: Initialize `h` for training nodes, set `h=0` for others. Run the iterative update until all target nodes have embeddings (plus `delay` iterations).
  3. Evaluation: Feed embeddings into a classifier (e.g., Logistic Regression) to validate, then GNN/MLP for final test.

- **Design tradeoffs:**
  - $\lambda$ (Adaptability): Setting $\lambda=1$ (frozen) is safer but performs worse than $\lambda < 1$ (adaptive), which risks "washing out" specific node features but better integrates new nodes.
  - Iterations: Too few iterations leave nodes unembedded; too many cause embeddings to converge to the graph average (loss of information).

- **Failure signatures:**
  - Roman-Empire Dataset: Models guessing the largest class signals the graph structure provides no signal for the embedding method.
  - Disconnected Components: If validation/test split creates isolated subgraphs, the post-hoc method cannot propagate embeddings to them.

- **First 3 experiments:**
  1. Ablate Lambda ($\lambda$): Run the post-hoc extension with $\lambda=1.0$ (frozen) vs. $\lambda=0.5$ (adaptive) on the Cora dataset to confirm the value of adapting training embeddings.
  2. Loss Impact: Train N2V with and without the $L_{close}$ loss component and compare the "ease" of post-hoc extension.
  3. Model Comparison: Compare an MLP fed with iN2V embeddings against a GraphSAGE model fed with only original features to verify if the embedding captures the "message passing" gap.

## Open Questions the Paper Calls Out

- Can iN2V performance on heterophilic graphs be improved by substituting node2vec with structural-role embeddings like struc2vec?
- Does a biased sampling strategy that ensures training node connectivity improve results over random splits in low-data regimes?
- Does incorporating normalized edge weights into the post-hoc neighbor averaging improve accuracy on weighted graphs?

## Limitations

- Performance degrades on highly heterophilic datasets where neighbors have different classes
- Requires connectivity between training and test nodes, failing when test nodes are in disconnected components
- Method effectiveness depends on the quality of the base Node2Vec embeddings and their ability to capture node identity

## Confidence

**High confidence:** The core mechanism (adaptive post-hoc aggregation) is well-specified and the experimental methodology follows standard practice. The improvement over Feature Propagation and maintenance of performance with limited training data are reproducible claims.

**Medium confidence:** The specific hyperparameter ranges and their impact across all datasets are not fully detailed. The paper reports grid search results but doesn't provide sensitivity analysis showing how performance varies with different hyperparameter choices.

**Low confidence:** The theoretical justification for why the loss modifications improve inductive performance is primarily empirical rather than analytical. The claim about encoding "sufficient structural information" is qualitative and would benefit from more rigorous analysis.

## Next Checks

1. **Heterophily Stress Test:** Evaluate iN2V on a deliberately constructed heterophilic dataset (e.g., 50/50 homophily) to quantify the exact performance threshold where averaging-based propagation fails.

2. **Connectivity Analysis:** For each dataset, measure the percentage of test nodes reachable from training nodes and correlate this with performance degradation to establish the practical limits of the method.

3. **Downstream Model Ablation:** Compare iN2V embeddings against learned node representations from a small inductive GNN (e.g., 2-layer GAT) to determine if iN2V's advantage stems from the embeddings themselves or the simplicity of the downstream classifier.