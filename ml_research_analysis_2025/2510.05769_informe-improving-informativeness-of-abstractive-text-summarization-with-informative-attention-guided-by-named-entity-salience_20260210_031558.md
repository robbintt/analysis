---
ver: rpa2
title: 'InforME: Improving Informativeness of Abstractive Text Summarization With
  Informative Attention Guided by Named Entity Salience'
arxiv_id: '2510.05769'
source_url: https://arxiv.org/abs/2510.05769
tags:
- summaries
- summarization
- evaluation
- named
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of improving informativeness
  in abstractive text summarization. It proposes a novel learning approach combining
  two methods: an optimal transport-based informative attention method and an accumulative
  joint entropy reduction method on named entities.'
---

# InforME: Improving Informativeness of Abstractive Text Summarization With Informative Attention Guided by Named Entity Salience

## Quick Facts
- arXiv ID: 2510.05769
- Source URL: https://arxiv.org/abs/2510.05769
- Reference count: 35
- Primary result: Achieves better ROUGE scores on CNN/Daily Mail and competitive results on XSum; human evaluation shows improved informativeness

## Executive Summary
This paper addresses the challenge of improving informativeness in abstractive text summarization by proposing a novel learning approach that combines optimal transport-based informative attention with accumulative joint entropy reduction on named entities. The approach learns focal information from reference summaries that may be missed by traditional cross-attention mechanisms, while enhancing named entity salience in the model's latent space. Experiments on CNN/Daily Mail and XSum datasets demonstrate superior performance on ROUGE metrics for CNN/Daily Mail and competitive results on XSum, with human evaluation confirming improved informativeness. The method also shows potential for mining extrinsic knowledge within datasets, generating factual entities absent from both source and reference.

## Method Summary
The approach combines two novel methods: (1) an optimal transport-based informative attention that captures focal information in reference summaries through Wasserstein distance minimization between source and summary latent states, and (2) an accumulative joint entropy reduction method that enhances named entity salience by reducing prediction uncertainty across entity token sequences. The method is implemented as a fine-tuning objective for BART-large, incorporating these components into the training loss alongside maximum likelihood estimation. Named entity recognition is performed using Stanford CoreNLP, with entities truncated to a maximum of 10 words to reduce noise. The combined approach shows improvements in ROUGE scores and human-evaluated informativeness across both CNN/Daily Mail and XSum datasets.

## Key Results
- Achieves better ROUGE scores on CNN/Daily Mail dataset compared to strong baseline
- Shows competitive ROUGE results on XSum dataset while outperforming baseline in human-evaluated informativeness
- Successfully generates factual extrinsic entities absent from both source and reference in 5 out of 8 analyzed cases on XSum
- Demonstrates the ability to mine extrinsic knowledge within datasets through the combined OT+AJER approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Optimal Transport-based attention captures focal information in reference summaries that standard cross-attention may miss
- Mechanism: Formulates attention as an optimal transport problem using Kantorovich formulation. Computes Wasserstein distance between source document and summary latent states via L2 norm cost function, learns a coupling matrix through bilinear transformation that makes semantically similar source-summary token pairs more salient
- Core assumption: Standard cross-attention optimizes for statistical correlation between source and summary, which may suppress informative but less-correlated content including extrinsic knowledge
- Evidence anchors: [abstract]: "an optimal transport-based informative attention method to improve learning focal information in reference summaries"; [section 4.1]: Equations 4-8 define the OT formulation with bilinear coupling; [corpus]: Related work on summarization evaluation exists (EVA-Score), but this specific OT mechanism for ATS informativeness appears distinct in this corpus
- Break condition: When reference summaries are highly extractive with strong lexical overlap to source documents (CNN/Daily Mail pattern), OT's marginal gains may diminish as standard attention already captures most salient content

### Mechanism 2
- Claim: Accumulative Joint Entropy Reduction (AJER) enhances named entity salience by reducing prediction uncertainty across entity token sequences
- Mechanism: Two-component loss: (1) Accumulative Negative Information Gain penalizes uncertainty more heavily at entity sequence beginnings, less at ends; (2) Joint Entropy reduction regularizes absolute uncertainty. Applied to named entities in both source documents and summaries
- Core assumption: Named entities serve as focal points for document content, and reducing their sequential prediction uncertainty improves summary informativeness; conditioning reduces entropy (information theory principle)
- Evidence anchors: [abstract]: "accumulative joint entropy reduction method on named entities to enhance informative salience"; [section 4.2]: Equations 16-17 define ANIG and JE components with Markov chain assumption for entity sequences; [corpus]: Corpus evidence for AJER specifically is weak—no direct corollary found in related summarization papers
- Break condition: When NER annotation quality is poor or entities are frequently split by tokenization schemes (BPE fragmentation), the Markov chain assumption may not hold

### Mechanism 3
- Claim: The combined OT+AJER approach may enable corpus-wide extrinsic knowledge mining, producing factual entities absent from both source and reference
- Mechanism: AJER amplifies entity salience in latent space, which may help OT establish correlational linkages between source entities and extrinsic entities in references across the training corpus (document-wide and corpus-wide global context)
- Core assumption: Entities across the training corpus share latent patterns that the model can generalize to generate plausible extrinsic entities
- Evidence anchors: [section 5.3.3]: "5 of them are factual and informative, two are erroneous, and one is inconclusive" among 8 extrinsic entity cases on XSum; [section 5.3.3]: OT-only model produces 5 extrinsic entities (2 factual, 3 erroneous), supporting the hypothesis that AJER enhances factual extrinsic generation; [corpus]: Corpus evidence weak—no comparable extrinsic knowledge mining mechanism found in related papers
- Break condition: When training corpus lacks entity diversity or contains systematic factual errors, extrinsic generation becomes hallucination-prone

## Foundational Learning

- **Optimal Transport Theory**:
  - Why needed here: Understands how OT finds minimum-cost transport plans between probability distributions, enabling the paper's "reverse cross-attention" formulation for aligning source and summary semantics
  - Quick check question: Can you explain why Wasserstein distance is more suitable for this task than KL divergence?

- **Information Theory (Entropy, Conditional Entropy, Chain Rule)**:
  - Why needed here: AJER relies on Shannon entropy as uncertainty measure, the principle that conditioning reduces entropy, and the chain rule for joint entropy decomposition
  - Quick check question: Why does H(x_i+1|x_i) ≤ H(x_i|x_i-1) hold for a stationary Markov process?

- **Named Entity Recognition (NER) in NLP Pipelines**:
  - Why needed here: Paper uses Stanford CoreNLP NER to extract 20 entity types from training data; understanding NER limitations (annotation errors, tokenization misalignment) is critical for debugging AJER
  - Quick check question: How might BPE tokenization split multi-word named entities, and why does this matter for sequential entropy computation?

## Architecture Onboarding

- **Component map**: Encoder-decoder backbone (BART-large) -> OT module (bilinear coupling matrix, L2 cost function, transport plan optimization) -> AJER module (NER annotation pipeline, word-token mapping, entity probability estimation, ANIG and JE loss computation) -> Training objective (MLE + α_OT·L_OT + α_ANIG·L_ANIG + α_JE·L_JE)

- **Critical path**:
  1. Preprocess training data with Stanford CoreNLP NER (word-level entities)
  2. Build word-token maps for aligning NER annotations to BPE tokenization
  3. Fine-tune BART-large with combined loss, validating ROUGE each epoch
  4. Use early stopping (3-4 consecutive epochs without ROUGE improvement)
  5. Inference uses trained backbone only (OT/AJER modules not invoked)

- **Design tradeoffs**:
  - OT vs. standard cross-attention: OT adds computational overhead but captures reference-informed salience; may overfit on extractive datasets (CNN/Daily Mail) where standard attention suffices
  - AJER entity scope: Applied to both source and summary entities; requires cloned logits head for source entities (sharing decoder head proved detrimental)
  - NER preprocessing: Filters entities >10 words to reduce noise; word-token mapping adds preprocessing complexity but enables token-level entropy computation
  - Loss weight tuning: Default α=1.0 for all components; paper does not explore sensitivity analysis

- **Failure signatures**:
  - XSum shows competitive rather than best ROUGE: May indicate OT+AJER trades extractive lexical overlap for abstractive informativeness, hurting ROUGE while improving human-rated informativeness
  - Increased extrinsic entity hallucinations on XSum (8 cases vs. 1 on CNN/Daily Mail): AJER salience amplification may overgeneralize corpus patterns in highly abstractive datasets
  - Whitespace tokenization artifacts: Penn Treebank word segmentation vs. BPE tokenization mismatch requires post-hoc normalization for human evaluation

- **First 3 experiments**:
  1. **Ablation study**: Train BART-large with OT-only and AJER-only on both CNN/Daily Mail and XSum. Compare ROUGE and human informativeness scores to isolate each component's contribution. Expect OT to outperform on XSum (less entity salience benefit), AJER+OT to outperform on CNN/Daily Mail
  2. **Entity length sensitivity**: Vary the maximum entity length filter (current: 10 words) and measure impact on AJER loss convergence and ROUGE. Hypothesis: Shorter entities reduce entropy computation noise but may miss informative multi-word entities
  3. **Loss weight grid search**: Run α_OT, α_ANIG, α_JE ∈ {0.5, 1.0, 1.5, 2.0} on validation sets. Monitor ROUGE, QuestEval, and extrinsic entity counts. Identify regimes where AJER amplifies factual vs. erroneous extrinsic entities

## Open Questions the Paper Calls Out
None

## Limitations
- Computational overhead of optimal transport (O(n²) complexity) may hinder scalability to longer documents or larger datasets
- Heavy reliance on NER preprocessing quality - errors in entity extraction or word-token misalignment can propagate to the AJER loss and destabilize training
- Human evaluation protocol lacks inter-annotator agreement metrics, making it difficult to assess rater reliability
- Extrinsic entity analysis remains anecdotal with only 8 cases examined across datasets

## Confidence

- **High confidence**: OT informative attention mechanism (Equations 4-8 clearly specified, OT theory well-established, implementation details provided). AJER's impact on named entity salience (entropy reduction principle is foundational, though application to summarization is novel)
- **Medium confidence**: Combined OT+AJER improves ROUGE scores on CNN/Daily Mail (supported by empirical results, but ablation not fully conclusive). AJER amplifies factual extrinsic entity generation (based on 8-case analysis, but sample size small)
- **Low confidence**: AJER enables corpus-wide extrinsic knowledge mining as primary driver of performance gains (mechanism plausible but not conclusively proven; OT-only baseline also generates extrinsic entities)

## Next Checks

1. **Rigorous ablation with statistical testing**: Implement OT-only and AJER-only variants on both CNN/Daily Mail and XSum. Run 5 independent training seeds for each variant and the combined model. Use bootstrap resampling to compute 95% confidence intervals for ROUGE and human informativeness scores. This will isolate each component's contribution and test whether improvements are statistically significant.

2. **Entity coverage and entropy sensitivity analysis**: Vary the maximum entity length filter (current: 10 words) across [3, 5, 7, 10, 15] words. For each setting, measure: (a) AJER loss convergence behavior, (b) ROUGE scores on validation set, (c) percentage of entity tokens covered by NER annotations. This will quantify the tradeoff between entity scope and model stability.

3. **Controlled extrinsic entity generation study**: Design a synthetic dataset where reference summaries contain entities not present in source documents but drawn from a known external vocabulary. Train OT-only, AJER-only, and OT+AJER models on this dataset. Measure: (a) extrinsic entity generation accuracy, (b) hallucination rate (generated entities not in external vocabulary), (c) correlation between AJER loss magnitude and factual vs. erroneous extrinsic generation. This will test whether AJER specifically amplifies factual knowledge mining or simply increases entity generation propensity.