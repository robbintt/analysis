---
ver: rpa2
title: 'Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching'
arxiv_id: '2509.20810'
source_url: https://arxiv.org/abs/2509.20810
tags:
- graph
- reasoning
- query
- semantic
- triples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the semantic gap between natural language
  queries and structured knowledge graphs in KGQA tasks, where LLMs struggle with
  hallucinations and factual errors due to focus and structure mismatches. The authors
  propose Enrich-on-Graph (EoG), a three-stage framework that uses LLMs to parse,
  prune, and enrich graphs to align them with queries.
---

# Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching

## Quick Facts
- arXiv ID: 2509.20810
- Source URL: https://arxiv.org/abs/2509.20810
- Authors: Songze Li; Zhiqiang Liu; Zhengke Gui; Huajun Chen; Wen Zhang
- Reference count: 40
- Primary result: EoG achieves SOTA KGQA performance with Hits@1 scores of 70.8% (CWQ) and 85.0% (WebQSP)

## Executive Summary
This paper addresses the semantic gap between natural language queries and structured knowledge graphs in KGQA tasks, where LLMs struggle with hallucinations and factual errors due to focus and structure mismatches. The authors propose Enrich-on-Graph (EoG), a three-stage framework that uses LLMs to parse, prune, and enrich graphs to align them with queries. The method employs focus-aware multi-channel pruning to remove noisy focuses and structure-driven knowledge enriching to address structure mismatches using structural and feature attributes of KGs. Extensive experiments on CWQ and WebQSP datasets show EoG achieves state-of-the-art performance while maintaining low computational costs and scalability.

## Method Summary
EoG is a training-free, three-stage pipeline that bridges the semantic gap between NL queries and knowledge graphs. First, it parses queries into sub-queries and graphs into quadruples. Second, it applies focus-aware multi-channel pruning using three masking perspectives to identify and retain the most relevant triples. Third, it enriches the pruned graph through structural transformations (similarity, symmetry, transitivity) and feature additions (hierarchy ontologies). The framework is theoretically grounded in mutual information maximization between queries and graphs, providing a formal link between alignment quality and reasoning performance.

## Key Results
- EoG achieves SOTA Hits@1 scores of 70.8% on CWQ and 85.0% on WebQSP
- Maintains low computational costs: pruning reduces token count from ~66K to ~6K
- Outperforms baselines significantly: 13.2% Hit@1 improvement over RoG on CWQ
- Three graph quality metrics (Relevance, Semantic Richness, Redundancy) correlate positively with optimization objectives

## Why This Works (Mechanism)

### Mechanism 1: Focus-Aware Multi-Channel Pruning
Removes noisy graph focuses by applying three masking channels (?, r, eo), (es, r, ?), and (?, r, ?) to capture local focuses from different perspectives. Each triple is scored by computing semantic similarity between all sub-queries and masked triples across all channels, then keeping top-K triples. This addresses situations where answer triples use semantically similar but not identical relations to the query.

### Mechanism 2: Structure-Driven Knowledge Enriching
Enriches graph structures using KG properties through two parallel processes: structural enrich transforms multi-hop paths into direct relationships and generates inverse relations, while feature enrich adds ontology triples to clarify entity semantics. This reduces reasoning hop complexity and addresses ambiguous entities.

### Mechanism 3: Mutual Information Maximization as Alignment Objective
The framework proves that maximizing mutual information between query q and graph G is theoretically equivalent to finding the optimal aligned graph for reasoning. This provides a theoretical foundation linking the three graph quality metrics to the optimization objective.

## Foundational Learning

- **Knowledge Graph Question Answering (KGQA)**: Understanding the task formulation is prerequisite to understanding why focus/structure mismatch matters. Quick check: Can you explain why KGQA differs from standard QA and why structured knowledge introduces unique challenges?

- **Mutual Information**: The theoretical foundation uses MI as the optimization objective; without this, the connection between pruning/enriching and improved reasoning is empirical only. Quick check: Why does maximizing MI(q, G) intuitively improve query-graph alignment?

- **Semantic Gap in KG-LLM Integration**: The paper's core contribution is identifying and bridging this gap; understanding focus mismatch vs. structure mismatch is essential for interpreting ablation results. Quick check: Given a query "currency of jurisdiction," can you identify why "Managed→Job→Office Jurisdiction→Monetary Value" represents structure mismatch?

## Architecture Onboarding

- **Component map:** Query q + Vanilla Graph G → [Stage 1: Parsing] → [Stage 2: Pruning] → [Stage 3: Enriching] → [Reasoning] → answer a*

- **Critical path:** The Prune→Enrich sequence is critical; reversing this order would enrich noisy data. Ablation shows w/o Prune&Eo drops WebQSP Hit@1 from 85.0 to 79.8.

- **Design tradeoffs:** K=300 triples balances answer coverage (~95%) vs. token cost; separate structural and feature enrichment allows modular ablation but adds LLM calls; training-free design enables flexibility but relies on LLM quality.

- **Failure signatures:** Low Relevance score (<0.4) indicates pruning too aggressive or similarity model inadequate; High Redundancy score (>0.3) suggests Feature enrich adding duplicate information; Identify errors (8% of enrichment errors) occur when LLM selects irrelevant triples for enrichment.

- **First 3 experiments:**
  1. Reproduce ablation: Run EoG with K=[100, 300, 500] on WebQSP subset to verify answer coverage vs. token cost tradeoff
  2. Component isolation: Disable Structural Enrich only, measure semantic richness drop (expect ~0.1 decrease)
  3. Plug-and-play test: Apply Enrich module to RoG baseline on 100 CWQ samples to verify 13.2% Hit@1 improvement

## Open Questions the Paper Calls Out
None

## Limitations
- Training-free design relies heavily on LLM quality without fine-tuning capabilities
- Pruning threshold K=300 is empirically chosen without theoretical justification for generalizability
- Incomplete specification of sentence-transformers model and initial subgraph retrieval method

## Confidence
- **High confidence:** Empirical performance claims (Hits@1/F1 scores on CWQ/WebQSP) with direct comparison to baselines
- **Medium confidence:** Theoretical framework linking MI maximization to graph quality metrics
- **Low confidence:** Error analysis claims (8/100 enrichment errors from hallucination) due to limited sample size

## Next Checks
1. Reproduce the K=300 ablation tradeoff: Run EoG with k=[100, 300, 500] on WebQSP subset to verify answer coverage vs. token cost relationship matches Fig. 6-7

2. Isolate structural enrich impact: Disable only the Structural Enrich component (keeping Feature Enrich) and measure semantic richness drop on 100 random samples; verify the ~0.1 decrease claimed in Fig. 4

3. Cross-dataset generalization test: Apply EoG's Enrich module to RoG baseline on 100 CWQ samples to independently verify the 13.2% Hit@1 improvement claimed in Table 4, controlling for prompt variations and API differences