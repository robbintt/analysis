---
ver: rpa2
title: 2D Gaussian Splatting with Semantic Alignment for Image Inpainting
arxiv_id: '2509.01964'
source_url: https://arxiv.org/abs/2509.01964
tags:
- image
- gaussian
- inpainting
- semantic
- splatting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first 2D Gaussian Splatting framework
  for image inpainting. The approach encodes incomplete images into a continuous Gaussian
  feature field and reconstructs them via differentiable rasterization.
---

# 2D Gaussian Splatting with Semantic Alignment for Image Inpainting

## Quick Facts
- arXiv ID: 2509.01964
- Source URL: https://arxiv.org/abs/2509.01964
- Authors: Hongyu Li; Chaofeng Chen; Xiaoming Li; Guangming Lu
- Reference count: 19
- Primary result: Introduces the first 2D Gaussian Splatting framework for image inpainting, achieving competitive FID and LPIPS scores on Celeba-HQ and Places2 datasets

## Executive Summary
This paper presents the first application of 2D Gaussian Splatting (2DGS) to image inpainting, encoding incomplete images into a continuous field of Gaussians for coherent reconstruction. To manage computational demands, the method employs patch-level rasterization, significantly reducing GPU memory usage while maintaining inference speed. Global semantic consistency is achieved through DINO features injected via adaptive layer normalization, allowing robust guidance even under large masks. Experiments demonstrate the method's effectiveness in preserving both local coherence and global semantic consistency compared to CNN-based approaches.

## Method Summary
The approach represents images as continuous fields of 2D Gaussians, with each Gaussian parameterized by position, color, and covariance. A U-Net encoder predicts these parameters, conditioned on DINO features injected through Adaptive Layer Normalization to maintain global semantic consistency. To address memory constraints, the method uses patch-wise rasterization (16x16 patches with overlap), where each patch maintains its own set of 324 Gaussians. The final image is reconstructed by blending overlapping patches. Training uses a composite loss including reconstruction, GAN, LPIPS, and feature alignment terms, optimized with Adam for 60k-200k steps depending on dataset.

## Key Results
- Competitive FID and LPIPS scores on Celeba-HQ and Places2 datasets compared to CNN-based methods
- Maintains local coherence through continuous Gaussian field representation versus discrete pixel synthesis
- Achieves computational efficiency through patch-level rasterization while preserving global semantic consistency via DINO feature adaptation
- Ablation studies confirm the importance of the feature alignment module and semantic conditioning for large masks

## Why This Works (Mechanism)

### Mechanism 1: Continuous Field Reconstruction
Representing images as continuous Gaussian fields inherently promotes local coherence through spatial smoothness. Unlike discrete pixel synthesis, overlapping Gaussians define pixel values as weighted sums of continuous functions, constraining the solution space to naturally coherent structures. The visual world can be effectively approximated by a mixture of localized 2D Gaussian distributions, where continuity in representation directly translates to perceptual coherence.

### Mechanism 2: Localized Semantic Conditioning
Global semantic consistency in patch-based processing relies on correcting the "representation gap" in features extracted from masked images. Standard features from masked inputs are noisy, so a lightweight MLP maps "masked" DINO features to estimated "clean" feature space. These adapted features are injected into the U-Net via Adaptive Layer Normalization (AdaLN), conditioning Gaussian prediction on global context even when processing local patches. DINO features retain robust semantic signals recoverable even when significant portions are missing.

### Mechanism 3: Scalable Patch Rasterization
High-resolution inpainting becomes computationally feasible by isolating rasterization memory pressure to local patches. The image is divided into a grid, with each cell maintaining its own Gaussian parameters. Local sets are rasterized independently (highly parallelizable) and blended using an overlap strategy, reducing the number of Gaussians loaded simultaneously and alleviating GPU memory pressure.

## Foundational Learning

- **Concept: 2D Gaussian Splatting (2DGS)**
  - Why needed here: This fundamental primitive replaces the standard pixel grid, defining how pixel color is derived from the weighted sum of Gaussian functions
  - Quick check question: Given a point $p$ and a single Gaussian with mean $\mu$ and covariance $\Sigma$, how does increasing the distance $||p - \mu||$ affect the contribution of that Gaussian to the pixel $p$?

- **Concept: Differentiable Rasterization**
  - Why needed here: The entire system relies on backpropagating loss from the final image back to Gaussian parameters, requiring understanding of how gradients flow through the rendering equation
  - Quick check question: If a pixel is too red, how does the gradient flow update the color $c_i$ versus the position $\mu_i$ of the nearest Gaussian?

- **Concept: Adaptive Layer Normalization (AdaLN)**
  - Why needed here: This is the "injection" mechanism for semantic guidance, modulating the feature distribution globally based on the DINO embedding rather than using concatenation
  - Quick check question: In AdaLN (Eq 5), do the parameters $\alpha$ and $\beta$ come from the convolutional features or the external semantic vector $f_{pred}$?

## Architecture Onboarding

- **Component map:** Input Masked Image -> U-Net Encoder -> Gaussian Heads (Position, Color, Covariance) -> Patch Rasterizer -> Output Image
- **Critical path:** The Feature Alignment Loss ($L_{align}$) is critical. Without it, the Adaptation MLP has no supervision to map masked features to clean features, causing AdaLN to inject noise into the U-Net and leading to semantic collapse
- **Design tradeoffs:**
  - Patches vs. Global: Using patches saves memory but requires heuristic blending and reduces the "global" context of the Gaussian field itself (context is salvaged only via the DINO branch)
  - Gaussian Count: 324 Gaussians per patch are used. Reducing this speeds up inference but loses detail
- **Failure signatures:**
  - Grid Lines: Visible seams at patch boundaries indicates the overlap padding ($a$) is insufficient or blending weights are incorrect
  - Training Collapse: If the scaling parameter $\gamma$ in AdaLN is removed, training destabilizes quickly
  - Blurry Outputs: Insufficient Gaussians or excessive covariance values results in overly smooth interpolations
- **First 3 experiments:**
  1. Overfit Single Image: Pass a single unmasked image through the network to verify Gaussian Heads and Rasterizer can reconstruct the image with high fidelity
  2. Ablate Alignment Module: Train with `w/o dino map` on a dataset with >50% mask ratio to confirm the drop in FID/LPIPS validates the semantic adapter's utility
  3. Patch Overlap Stress Test: Vary the overlap parameter $a$ to zero, small, and large values, measuring inference time and visually inspecting for seams

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can cross-modal conditioning mechanisms be integrated into the framework to enable explicit user guidance?
- Basis in paper: Appendix C states the method "currently lacks the explicit controllability" found in diffusion models and identifies this as a compelling direction for future exploration
- Why unresolved: The current design operates without external inputs like text prompts or structural maps, limiting interactive editing
- What evidence would resolve it: A modified architecture that accepts multi-modal inputs while maintaining Gaussian coherence

### Open Question 2
- Question: Can the trade-off between Gaussian count and computational efficiency be resolved to support higher-fidelity reconstruction?
- Basis in paper: Section 4.4 notes that increasing the number of Gaussians improves quality but raises computational costs significantly, stating this is "left for future work"
- Why unresolved: High Gaussian counts exacerbate GPU memory pressure and slow training/inference
- What evidence would resolve it: A sparse or adaptive allocation strategy allowing higher effective Gaussian density without linear cost increases

### Open Question 3
- Question: Can the rasterization process be further optimized to surpass the inference speed of pure CNN-based methods?
- Basis in paper: Appendix F shows the method (32.52ms) is roughly 2x slower than the CNN-based LaMa (15.80ms), despite the focus on efficiency
- Why unresolved: While faster than diffusion, the patch-wise rasterization and blending overhead currently exceed that of standard convolutions
- What evidence would resolve it: Highly optimized custom CUDA kernels for patch rasterization that reduce latency below CNN baselines

## Limitations
- Rasterization kernel optimization achieving 32ms inference speed is not mathematically detailed, creating a significant barrier to exact reproduction
- Lightweight MLP architecture for feature adaptation is unspecified, potentially affecting semantic consistency mechanism's performance
- Patch overlap strategy requires careful tuning of blending weights to avoid visible seams, with no explicit guidance on optimal parameter selection

## Confidence
- **High confidence:** The fundamental mechanism of continuous Gaussian field reconstruction for local coherence is theoretically sound and supported by the rasterization equation and ablation studies
- **Medium confidence:** The semantic consistency mechanism using DINO features and AdaLN is plausible given ablation results, but effectiveness of the feature adaptation MLP is less certain due to underspecification
- **Medium confidence:** The patch-based rasterization strategy's computational benefits are well-argued, but lack of detailed kernel implementation creates uncertainty about achieving claimed inference speed

## Next Checks
1. **Rasterization Kernel Validation:** Implement patch-wise Gaussian rasterization with overlap and measure inference time on fixed-resolution image, comparing against reported 32ms to identify optimization gaps
2. **Feature Adaptation MLP Sensitivity:** Train with varying MLP architectures for DINO feature adaptation, measuring impact on FID/LPIPS for large mask ratios (>50%) to quantify adapter's sensitivity to architectural choices
3. **Patch Overlap Stress Test:** Systematically vary overlap parameter from 0 to 4 pixels in increments of 1, quantifying trade-off between inference time and visual quality by measuring FID and visually inspecting for seams at each setting