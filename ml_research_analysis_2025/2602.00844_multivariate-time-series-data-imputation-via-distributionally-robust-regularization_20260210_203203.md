---
ver: rpa2
title: Multivariate Time Series Data Imputation via Distributionally Robust Regularization
arxiv_id: '2602.00844'
source_url: https://arxiv.org/abs/2602.00844
tags:
- data
- missing
- imputation
- distribution
- drio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of imputing missing values in
  multivariate time series data when the observed data distribution differs from the
  true data-generating process, particularly due to non-stationarity and systematic
  missingness patterns. The authors propose a Distributionally Robust Regularized
  Imputer Objective (DRIO) that balances reconstruction accuracy with robustness to
  distributional shifts.
---

# Multivariate Time Series Data Imputation via Distributionally Robust Regularization

## Quick Facts
- arXiv ID: 2602.00844
- Source URL: https://arxiv.org/abs/2602.00844
- Authors: Che-Yi Liao; Zheng Dong; Gian-Gabriel Garcia; Kamran Paynabar
- Reference count: 40
- Key outcome: Distributionally robust regularized imputer achieves consistent top-3 performance across 10 datasets under both MCAR and MNAR missing mechanisms

## Executive Summary
This paper addresses the challenge of imputing missing values in multivariate time series data when the observed data distribution differs from the true data-generating process, particularly due to non-stationarity and systematic missingness patterns. The authors propose a Distributionally Robust Regularized Imputer Objective (DRIO) that balances reconstruction accuracy with robustness to distributional shifts. Experiments on 10 real-world datasets show DRIO consistently achieves top-3 imputation performance across all datasets under both MCAR and MNAR missing mechanisms, reaching Pareto-optimal trade-offs between reconstruction accuracy (MSE) and distributional alignment (Wasserstein-2 distance).

## Method Summary
The proposed DRIO method introduces a Wasserstein ambiguity set centered at the empirical distribution of mean-imputed data, and minimizes reconstruction error while hedging against worst-case distributional divergence within this set. The approach combines variational autoencoder-style reconstruction with distributionally robust optimization, creating a principled framework for handling distribution shifts between training and test data. A key contribution is the reconstruction-based cross-validation strategy that tracks oracle performance without requiring ground truth missing values, enabling practical deployment without labeled data.

## Key Results
- DRIO achieves top-3 imputation performance across all 10 real-world datasets tested
- Method demonstrates particular robustness to MNAR (Missing Not At Random) settings where other approaches struggle
- Reconstruction-based cross-validation closely tracks oracle performance without requiring ground truth missing values
- Pareto-optimal trade-offs achieved between reconstruction accuracy (MSE) and distributional alignment (Wasserstein-2 distance)

## Why This Works (Mechanism)
The method's effectiveness stems from explicitly modeling the distributional mismatch between observed and true data through the Wasserstein ambiguity set. By centering the ambiguity set at mean-imputed data and hedging against worst-case distributions within this set, DRIO creates an imputation strategy that remains robust when the training distribution differs from test conditions. The reconstruction-based cross-validation works because it leverages the inherent structure of the variational autoencoder to evaluate imputation quality without ground truth labels.

## Foundational Learning
- **Wasserstein Distance**: Measures distributional divergence between probability measures; needed to quantify distributional shifts in missing data scenarios
  - Quick check: Verify understanding of Kantorovich-Rubinstein duality formulation
- **Distributionally Robust Optimization**: Optimization framework that hedges against worst-case distributions within an ambiguity set; needed to handle distribution shifts
  - Quick check: Understand primal-dual formulations in DRO problems
- **Variational Autoencoders**: Generative models that learn latent representations through reconstruction; needed as base architecture for imputation
  - Quick check: Review evidence lower bound (ELBO) derivation
- **MCAR vs MNAR**: Missing Completely At Random vs Missing Not At Random; needed to understand different missingness mechanisms
  - Quick check: Distinguish between ignorable and non-ignorable missingness
- **Cross-Validation for Imputation**: Validation strategy when ground truth is unavailable; needed for practical deployment
  - Quick check: Understand reconstruction-based evaluation metrics
- **Pareto Optimality**: Trade-off between competing objectives; needed to evaluate multi-objective imputation performance
  - Quick check: Verify understanding of Pareto frontier concepts

## Architecture Onboarding

**Component Map**: Data -> Mean Imputation -> Empirical Distribution -> Wasserstein Ambiguity Set -> DRIO Optimization -> Imputed Data

**Critical Path**: 
1. Mean-impute observed data to create empirical distribution
2. Construct Wasserstein ambiguity set around this distribution
3. Optimize DRIO objective balancing reconstruction and robustness
4. Generate imputed values through trained model

**Design Tradeoffs**:
- Conservative radius in Wasserstein ambiguity set provides robustness but may reduce reconstruction accuracy
- Choice of centering distribution (mean-imputed vs other) affects performance on structured missingness
- Computational complexity vs robustness: SDP formulation is more robust but slower than alternative approaches

**Failure Signatures**:
- Overly conservative Wasserstein radius leads to poor reconstruction despite distributional robustness
- Poor centering distribution choice results in ineffective hedging against true distribution
- Computational bottlenecks prevent scaling to large datasets with >10,000 time points

**First 3 Experiments to Run**:
1. Vary Wasserstein radius parameter to identify sweet spot between robustness and accuracy
2. Compare centering distributions (mean-imputed vs mode-imputed vs random-imputed) on structured missingness datasets
3. Test computational scaling on synthetic datasets with increasing time series length

## Open Questions the Paper Calls Out
None identified in the source material.

## Limitations
- Wasserstein ambiguity set construction may be sensitive to radius parameter choice, potentially being overly conservative or insufficiently protective
- Computational complexity scales poorly with dataset size due to semidefinite programming formulation, limiting practical applicability to large-scale time series
- Assumption that mean-imputed data provides reasonable centering for ambiguity set may not hold for datasets with highly structured missingness patterns

## Confidence

**High confidence**: Empirical results showing consistent top-3 performance across 10 datasets under both MCAR and MNAR mechanisms

**Medium confidence**: Theoretical convergence guarantees for the proposed algorithm, which rely on specific smoothness assumptions that may not hold in practice

**Medium confidence**: Claim that DRIO achieves Pareto-optimal trade-offs, as this depends on the specific evaluation metrics and datasets chosen

## Next Checks
1. Test DRIO's performance on synthetic datasets with controlled distribution shifts to isolate the impact of the distributional robustness component from other methodological choices
2. Compare computational efficiency against alternative imputation methods on large-scale datasets (time series with >10,000 time points)
3. Evaluate the sensitivity of imputation quality to the Wasserstein radius parameter across datasets with varying degrees of non-stationarity