---
ver: rpa2
title: 'Steering Language Models in Multi-Token Generation: A Case Study on Tense
  and Aspect'
arxiv_id: '2509.12065'
source_url: https://arxiv.org/abs/2509.12065
tags:
- tense
- steering
- aspect
- language
- sentence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates how large language models encode and control\
  \ grammatical features\u2014specifically tense and aspect\u2014which describe the\
  \ temporal structure of verbs. Prior work largely focused on binary contrasts and\
  \ single-token evaluations, but tense and aspect are multidimensional and can be\
  \ combined in numerous ways."
---

# Steering Language Models in Multi-Token Generation: A Case Study on Tense and Aspect

## Quick Facts
- **arXiv ID**: 2509.12065
- **Source URL**: https://arxiv.org/abs/2509.12065
- **Reference count**: 40
- **Primary result**: Identifies and steers tense/aspect directions in LLM residual space, showing orthogonal feature encoding and model-specific steering parameters.

## Executive Summary
This paper addresses the challenge of controlling grammatical features—specifically tense and aspect—in large language models during multi-token generation. While prior work focused on single-token interventions and binary contrasts, this study tackles the multidimensional nature of tense and aspect combinations. The authors develop a method to identify these features as orthogonal directions in residual space using modified linear discriminant analysis, then demonstrate causal steering through residual stream interventions. Their results show that tense and aspect form independent, interpretable directions that can be manipulated during generation, though effectiveness depends on careful tuning of intervention location, strength, and timing. The work bridges the gap between linguistic theory and mechanistic interpretability, showing that LLMs represent grammatical features in a human-like, structured manner.

## Method Summary
The method involves three main stages: First, linear probes are trained on hidden states from labeled sentences (Penn Treebank + synthetic augmentation) to verify that tense and aspect are linearly representable. Second, LDA-based feature extraction identifies orthogonal directions for each grammatical feature in residual space. Third, steering interventions are applied by adding scaled direction vectors to residual stream activations at specific layers during generation. The approach uses greedy decoding and grid searches over layer and strength parameters, with steering applied at every generation step. Evaluation combines probing classifiers on generated output with detection of degeneration (n-gram repetition, missing verbs) and side effects (topic shift via BERTScore, perplexity changes).

## Key Results
- Tense and aspect form near-orthogonal directions in residual space (cosine similarity 0.02-0.12), enabling independent manipulation
- Steering efficacy reaches 94-96% for tense in controlled tasks when applied just before verb generation
- Optimal steering strength scales with activation norm: Llama-8B requires α=5-25 while Qwen-7B needs α=100-250
- Steering is more effective for tense than aspect, and more stable in few-shot tasks than open-ended generation
- Side effects include topic shift and degeneration, especially with strong interventions or long durations

## Why This Works (Mechanism)

### Mechanism 1: Linear Subspace Encoding of Grammatical Categories
- **Claim**: Tense and aspect are encoded as near-orthogonal linear directions in residual space, allowing independent manipulation.
- **Mechanism**: The model learns to represent grammatical features as vector directions during training. Tense values (past, present, future) and aspect values (simple, progressive, perfect, perfect progressive) occupy distinct subspaces with near-zero cosine similarity (0.02-0.12 between tense and aspect directions).
- **Core assumption**: The linear representation hypothesis holds for grammatical features—abstract concepts map to linear directions in activation space.
- **Evidence anchors**: [abstract]: "identify distinct, orthogonal directions in residual space using linear discriminant analysis"; [Section 3.2]: "Tense and aspect exhibit representational independence... near-zero cosine similarity of 0.02"
- **Break condition**: If feature directions are not truly orthogonal (source subtraction harms rather than helps), the independence assumption may not hold fully. The paper notes TA+SS sometimes reduces selectivity, suggesting incomplete orthogonality.

### Mechanism 2: Residual Stream Additive Steering
- **Claim**: Adding scaled concept direction vectors to residual stream activations causally influences grammatical output.
- **Mechanism**: Steering modifies the residual stream at layer l by adding α·ℓ_target (normalized direction vector). The intervention shifts the activation toward the target grammatical feature, which propagates through remaining layers and influences token prediction.
- **Core assumption**: The identified directions are causally relevant, not just correlational—the direction encodes the "concept" itself, not a side effect.
- **Evidence anchors**: [abstract]: "Causal steering interventions were then applied to manipulate these grammatical features during generation, demonstrating successful control"; [Section 4.1]: Equations 4-6 define steering methods; Section 4.2 reports 94-96% efficacy for tense in random sentence task
- **Break condition**: Steering can cause topic shift and degeneration (Section 4.3), indicating the directions are not perfectly selective—they influence more than just the target feature.

### Mechanism 3: Layer-Dependent Activation Scaling
- **Claim**: Optimal steering strength (α) scales with activation norm, which increases with depth and varies by model architecture.
- **Mechanism**: Deeper layers have larger activation norms (Llama-8B: lower; Qwen-7B: higher). Since feature signal strength grows with norm, larger α values are needed to override existing signals. Llama-8B requires α=5-25; Qwen-7B requires α=100-250.
- **Core assumption**: The projection magnitude of the source feature direction represents how strongly the original grammatical property is encoded.
- **Evidence anchors**: [Section 4.2]: "Llama-8B requires significantly lower α values (5-25) for effective steering compared to Qwen-7B (100-250)"; [Appendix J.3, Figure 10]: Shows activation norm and projection magnitude both increase with layer depth
- **Break condition**: If α is too high, degeneration occurs; if too low, steering fails. The relationship is model-specific, not universal.

## Foundational Learning

- **Linear Discriminant Analysis (LDA) for Categorical Features**:
  - **Why needed here**: The paper uses a modified LDA (Park et al. 2024) to extract feature directions without enforcing predefined class structures. Standard LDA wouldn't work for multi-class categorical features like tense (3 values) and aspect (4 values).
  - **Quick check question**: Given activations from sentences with different tenses, how would you compute a direction that maximally separates "past" from "not past"?

- **Residual Stream Interventions**:
  - **Why needed here**: Steering operates by modifying the residual stream—the accumulated information flowing through the transformer. Understanding this is critical for knowing where and how to intervene.
  - **Quick check question**: Why might intervening at layer 15 have different effects than intervening at layer 5?

- **Multi-Token Generation Dynamics**:
  - **Why needed here**: Unlike single-token interventions, steering during sentence generation requires intervening at every generation step, and effects compound. Timing matters: steering before the verb works better than after.
  - **Quick check question**: If you steer toward "past tense" starting at token position 0 vs. starting when the verb is generated, which would you expect to be more effective?

## Architecture Onboarding

- **Component map**: Labeled corpus -> Probe training -> LDA direction extraction -> Steering module -> Evaluation pipeline

- **Critical path**:
  1. Collect labeled sentences with unambiguous tense/aspect
  2. Train probes to verify representability (target: F1 > 0.90)
  3. Extract LDA directions from layer 0 (embedding) activations
  4. Grid search over (layer, α) pairs to find optimal steering config
  5. Apply steering at generation time; evaluate success + side effects

- **Design tradeoffs**:
  - **TA vs. TA+SS vs. TA+Proj-SS**: Target-Addition only is simplest and often sufficient; full source subtraction harms selectivity; projection subtraction partially mitigates
  - **Prompt vs. generation steering**: Prompt steering works for repetition tasks; generation steering is more general but timing-sensitive
  - **Steering duration**: Longer intervention increases success risk but also degeneration risk

- **Failure signatures**:
  - **Topic shift**: Steering changes sentence content (BERTScore drops); more common in open-ended generation
  - **Degeneration**: Repetitive n-grams, missing verbs, incomplete sentences
  - **Low selectivity**: Steering tense inadvertently changes aspect (or vice versa); selectivity < 50% in many configs

- **First 3 experiments**:
  1. **Probe verification**: Train linear probes on your target model using the paper's data preprocessing (length-normalized sum pooling, mean-centering). Confirm F1 > 0.90 at layer 0.
  2. **LDA direction extraction**: Implement Equation 2 on training set activations. Visualize by projecting test samples onto the extracted directions—confirm visible clustering (Figure 1, 2).
  3. **Single-layer steering pilot**: On random sentence task, fix α=10 (Llama) or α=150 (Qwen). Grid search layers 10-20. Report efficacy and degenerate rate. Identify the layer with best efficacy-degeneration tradeoff.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can automated methods reliably identify task-specific optimal steering positions and strengths to minimize side effects like topic shift?
- **Basis in paper**: [explicit] The authors state, "We encourage future research to develop automated methods for identifying task-specific optimal steering positions," and call for automated optimization to replace manual tuning.
- **Why unresolved**: Current findings rely on qualitative case studies and manual grid searches, which are sensitive to model architecture, activation norms, and task type.
- **What evidence would resolve it**: The development of a feedback-driven algorithm that dynamically adjusts steering duration and strength, demonstrating higher efficacy and lower degeneration rates than static, manually tuned baselines.

### Open Question 2
- **Question**: Do LLMs learn mechanism-independent temporal representations (e.g., consistent "past" encoding for both "he was" and "yesterday") or language-independent representations?
- **Basis in paper**: [explicit] In the Limitations section, the authors note they "leave it to future work to investigate mechanism-independent time representations... as well as language-independent tense representations."
- **Why unresolved**: The study restricted analysis to sentences with unique verb-based tense-aspect combinations in English, ignoring temporal adverbs or cross-lingual consistency.
- **What evidence would resolve it**: Probing experiments demonstrating that the same activation direction controls temporal meaning across different surface forms (verbs vs. adverbs) or transfers across languages in multilingual models.

### Open Question 3
- **Question**: Why does subtracting the source concept vector often fail to improve steering selectivity compared to simple target addition?
- **Basis in paper**: [explicit] The authors note that while projection subtraction mitigates some issues, "Understanding how these directions interact—and whether source subtraction helps or hinders—remains an open question."
- **Why unresolved**: Theoretically, source subtraction should remove conflicting information, but empirically it often reduced selectivity or efficacy, suggesting the directions may not be functionally independent during generation.
- **What evidence would resolve it**: A mechanistic analysis of the residual stream during steering to determine if source subtraction inadvertently perturbs non-orthogonal features essential for maintaining the original topic or sentence structure.

## Limitations

- The steering directions are extracted from a small, narrowly defined dataset (1,543 sentences), raising questions about generalization to diverse natural language
- The causal interpretation of steering directions is limited—they may capture correlated linguistic features rather than pure tense/aspect concepts
- The methodology focuses on greedy decoding and uniform interventions, which may not reflect real-world beam search or targeted steering applications

## Confidence

**High Confidence Claims**:
- Tense and aspect are linearly separable in residual space
- Steering interventions can causally influence grammatical output
- Layer and model-specific scaling of steering strength is necessary

**Medium Confidence Claims**:
- Tense representations are more stable than aspect representations during steering
- Optimal steering timing is just before verb generation
- Steering effectiveness depends on generation vs. prompt intervention

**Low Confidence Claims**:
- The identified directions represent pure tense/aspect concepts
- The scaling relationship between activation norm and optimal α is universal
- The Park et al. (2024a) LDA modification is optimal for this application

## Next Checks

1. **Feature Direction Selectivity Analysis**: Apply the steering directions to sentences with controlled variations (same tense, different aspects; same aspect, different tenses; same tense/aspect, different verbs). Measure whether steering affects only the target feature or causes correlated changes in other grammatical properties.

2. **Cross-Dataset Generalization Test**: Extract steering directions from the current corpus and apply them to a held-out dataset with different sentence structures and domains (e.g., news articles, dialogue, technical writing). Compare steering efficacy and side effect rates to determine whether the learned directions generalize beyond the training distribution.

3. **Fine-Grained Timing Intervention Study**: Systematically vary the timing of steering interventions relative to verb positions across multiple sentence types. Instead of steering at every token, test interventions only at verb positions, or starting 1-3 tokens before verbs. Measure the tradeoff between steering success and side effects to determine if targeted timing can reduce degeneration while maintaining efficacy.