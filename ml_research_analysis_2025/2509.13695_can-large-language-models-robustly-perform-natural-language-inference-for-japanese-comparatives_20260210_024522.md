---
ver: rpa2
title: Can Large Language Models Robustly Perform Natural Language Inference for Japanese
  Comparatives?
arxiv_id: '2509.13695'
source_url: https://arxiv.org/abs/2509.13695
tags:
- hypothesis
- inference
- japanese
- than
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study constructs a Japanese NLI dataset focused on comparatives
  and evaluates the robustness of large language models (LLMs) in zero-shot and few-shot
  settings. The dataset is built by creating templates from an existing Japanese NLI
  dataset and filling them with various words.
---

# Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?

## Quick Facts
- **arXiv ID**: 2509.13695
- **Source URL**: https://arxiv.org/abs/2509.13695
- **Reference count**: 10
- **Primary result**: Model performance is sensitive to prompt formats in zero-shot settings and influenced by gold labels in few-shot examples, with semantic representations improving accuracy on difficult problems

## Executive Summary
This study investigates the robustness of large language models in performing natural language inference (NLI) for Japanese comparative constructions. The researchers construct a specialized Japanese NLI dataset focused on comparatives by creating templates from an existing Japanese NLI dataset and filling them with various words. They evaluate five LLMs (GPT-4o, Llama-3.1, and Swallow) in both zero-shot and few-shot settings to understand how well these models handle the linguistic complexities of Japanese comparatives.

The experiments reveal that model performance is highly sensitive to prompt formats in zero-shot settings and influenced by the gold labels provided in few-shot examples. LLMs struggle with Japanese-specific linguistic phenomena such as presuppositions and disjunctive comparatives. However, providing semantic representations from a logical inference system (ccg-jcomp) significantly improves model accuracy on difficult problems, suggesting that additional linguistic context can help overcome some of the challenges these models face with complex comparative constructions.

## Method Summary
The researchers created a Japanese NLI dataset specifically focused on comparative constructions by developing templates from an existing Japanese NLI dataset and populating them with various lexical items. They evaluated five different LLMs (GPT-4o, Llama-3.1, and Swallow) using both zero-shot and few-shot prompting strategies. In zero-shot settings, they tested various prompt formats to assess sensitivity to presentation. In few-shot settings, they examined how the choice of gold labels in example pairs influenced model performance. They also tested whether providing semantic representations from the ccg-jcomp logical inference system could improve model accuracy on challenging comparative constructions.

## Key Results
- Model performance shows high sensitivity to prompt formats in zero-shot inference tasks
- Few-shot performance is influenced by the selection of gold labels in example pairs
- LLMs struggle with Japanese-specific linguistic phenomena like presuppositions and disjunctive comparatives
- Semantic representations from ccg-jcomp improve accuracy on difficult comparative problems

## Why This Works (Mechanism)
None

## Foundational Learning
- **Natural Language Inference (NLI)**: Determining whether a hypothesis sentence can be inferred from a premise sentence - needed for understanding the core task being evaluated
- **Comparative constructions in Japanese**: Linguistic structures used to compare entities in Japanese - needed because the study focuses specifically on these complex constructions
- **Zero-shot and few-shot learning**: Approaches where models make predictions without or with minimal training examples - needed to understand the evaluation methodology
- **Semantic representations (ccg-jcomp)**: Logical encoding of linguistic meaning - needed to understand the mechanism that improved model performance
- **Prompt sensitivity**: How model outputs vary based on input formatting and examples - needed to interpret why different prompt strategies yield different results

## Architecture Onboarding
**Component map**: Dataset (templates + lexical items) -> LLMs (GPT-4o, Llama-3.1, Swallow) -> Inference tasks (zero-shot/few-shot) -> Performance evaluation

**Critical path**: Template generation → Dataset construction → Prompt engineering → Model inference → Performance measurement

**Design tradeoffs**: The study balances controlled experimental conditions (template-based dataset) against ecological validity (may not capture all natural usage patterns)

**Failure signatures**: Poor performance on Japanese-specific phenomena (presuppositions, disjunctive comparatives), high variance across prompt formats, dependence on few-shot gold labels

**First experiments**:
1. Test model performance on non-comparative NLI tasks to establish baseline capabilities
2. Vary the number of few-shot examples to determine optimal training set size
3. Compare performance with and without semantic representations across different difficulty levels

## Open Questions the Paper Calls Out
None

## Limitations
- Small dataset size (960 examples) may not capture full complexity of Japanese comparative constructions
- Template-based construction could introduce artificial patterns not reflective of natural language
- Limited to three LLM families accessed via APIs, restricting reproducibility and controlling for API-level optimizations
- Improvements from semantic representations not fully explained mechanistically

## Confidence
- Model sensitivity to prompt formats and few-shot examples: Medium
- Difficulty with Japanese-specific linguistic phenomena: High
- Effectiveness of semantic representations: Medium
- Systematic evaluation framework: High

## Next Checks
1. Expand dataset size and diversity by incorporating naturally occurring Japanese comparative constructions from multiple sources, not just template-based generation
2. Conduct ablation studies to isolate the specific contributions of semantic representations versus other factors in improving model performance
3. Test additional Japanese-specific LLMs and self-hosted versions to control for API-level variations and better understand model-specific behaviors