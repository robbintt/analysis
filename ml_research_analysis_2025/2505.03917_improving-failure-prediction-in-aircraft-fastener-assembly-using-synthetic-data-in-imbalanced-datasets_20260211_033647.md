---
ver: rpa2
title: Improving Failure Prediction in Aircraft Fastener Assembly Using Synthetic
  Data in Imbalanced Datasets
arxiv_id: '2505.03917'
source_url: https://arxiv.org/abs/2505.03917
tags:
- data
- assembly
- class
- jammed
- mounted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of failure prediction in aircraft
  fastener assembly, where rare failure cases and imbalanced datasets hinder deep
  learning model performance. The authors propose using synthetic data generation
  and class weighting techniques specifically tailored for temporal series data to
  improve classification performance.
---

# Improving Failure Prediction in Aircraft Fastener Assembly Using Synthetic Data in Imbalanced Datasets

## Quick Facts
- arXiv ID: 2505.03917
- Source URL: https://arxiv.org/abs/2505.03917
- Reference count: 40
- Primary result: SMOTE oversampling improves jammed recall to 0.92±0.08 while maintaining mounted precision of 0.89 in aircraft fastener assembly

## Executive Summary
This paper addresses the critical challenge of detecting rare failure modes in aircraft fastener assembly where imbalanced datasets hinder deep learning model performance. The authors propose using synthetic data generation and class weighting techniques specifically tailored for temporal series data to improve classification performance. By focusing on task-specific metrics—precision for successful assemblies and recall for jammed failures—the study reveals that SMOTE-based oversampling significantly improves minority class detection without catastrophically impacting majority class precision. The methodology employs raw sensor data from a compliant robotic setup and evaluates multiple deep learning architectures, with the ViT model achieving the highest jammed recall (0.92±0.08) when trained on balanced data with rotational features.

## Method Summary
The methodology employs raw sensor data from a compliant robotic setup for threaded collar assembly, using force-torque sensors with optional rotational angle measurements. The approach involves preprocessing (outlier removal, PAA normalization, truncation), data augmentation through SMOTE oversampling to create balanced or synthetic datasets, and evaluation of five deep learning architectures (MLP, CNN, LSTM, Transformer, ViT) within a hyperparameter optimization framework using Optuna. The study focuses on task-specific evaluation metrics—mounted precision and jammed recall—rather than accuracy, using 80/20 train/test splits with 10-fold cross-validation.

## Key Results
- SMOTE-based oversampling improves jammed recall to 0.92±0.08 while maintaining mounted precision of 0.89
- ViT model with rotation on balanced dataset achieves highest jammed recall (0.92±0.08), making it ideal for critical failure detection
- Transformer model without rotation on synthetic dataset offers computational efficiency with 0.75±0.09 jammed recall using only 22k parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SMOTE-based oversampling improves minority class (jammed) detection without catastrophically degrading majority class (mounted) precision.
- Mechanism: SMOTE generates synthetic samples by interpolating between minority class instances and their k-nearest neighbors along the feature space, effectively extending the decision boundary for rare failure modes. This allows the model to learn discriminative patterns for underrepresented classes that would otherwise be overwhelmed by the majority class gradient signals.
- Core assumption: The Euclidean interpolation between real failure samples produces meaningful synthetic failures that share underlying physical characteristics with actual jammed assemblies, rather than creating unrealistic artifacts that confuse the model.
- Evidence anchors:
  - [abstract] "Results show that SMOTE-based oversampling significantly improves jammed recall while maintaining high mounted precision."
  - [section 4.3] "SMOTE-based oversampling appears more effective and stable than class weighting for this task, improving minority class detection without catastrophically impacting majority class precision."
  - [corpus] Paper on glass defect detection with diffusion models (arXiv:2505.03134) similarly addresses imbalanced manufacturing datasets through synthetic generation, suggesting the approach generalizes across quality control domains.
- Break condition: If synthetic samples generated by SMOTE create overlapping decision regions with other classes, or if the minority class exhibits high intra-class variance that linear interpolation cannot capture, performance gains may diminish or reverse.

### Mechanism 2
- Claim: Task-specific metric optimization (mounted precision + jammed recall) reveals model capabilities that accuracy masks in imbalanced settings.
- Mechanism: In imbalanced datasets, a model can achieve high accuracy by simply predicting the majority class. By constraining evaluation to precision for the most common outcome (mounted) and recall for the most critical failure (jammed), the optimization pressure focuses on two operationally meaningful objectives: avoiding false confidence in successful assemblies and detecting all potentially dangerous failures.
- Core assumption: The operational cost of missing a jammed fastener (false negative) and incorrectly predicting success when failure occurred (false positive for mounted) are both higher than the inverse errors, which aligns with aircraft safety requirements.
- Evidence anchors:
  - [section 3.1] "Moreira et al. [23] have all models resulting in null recall... These numbers highlight the need to improve the models' performance because, in real-world scenarios... even a small percentage of failures can result in significant issues."
  - [section 4.4] "The ViT model with rotation on the balanced dataset demonstrated statistically significantly higher jammed recall (0.92±0.08) than the other top contenders, making it the preferred choice if maximizing the detection of jammed fasteners is the highest priority."
  - [corpus] Weak direct corpus evidence for task-specific metrics in fastener assembly; related work by Pastor et al. [41] explored imbalanced dataset techniques for CNC tapping but did not emphasize domain-tailored metrics.
- Break condition: If operational requirements change such that false positives on "not mounted" become equally costly, or if the cost asymmetry between failure types shifts, the current metric pairing may select suboptimal models.

### Mechanism 3
- Claim: Model architecture and data augmentation strategy interact; transformer-based models benefit more from synthetic data scaling while ViT achieves peak jammed recall only with balanced data and rotational features.
- Mechanism: The Transformer's self-attention mechanism can leverage larger synthetic datasets to learn richer long-range temporal dependencies without requiring rotational inductive biases. Conversely, the ViT's patch-based temporal processing combined with multi-channel attention appears to extract maximal signal from the balanced dataset when rotational angle data provides additional discriminative cues about assembly state progression.
- Core assumption: The rotational angle captures phase information during the screwing process that distinguishes jammed from mounted states more reliably than force/torque alone, and the ViT's architecture is uniquely positioned to exploit this multi-modal temporal structure.
- Evidence anchors:
  - [section 4.1] "The ViT model trained on the balanced dataset achieved its highest jammed recall (0.92±0.08) only when rotational data was included (compared to 0.33±0.10 without rotation)."
  - [section 4.2] "The Transformer without rotation achieved 0.86±0.08 mounted precision and a high 0.75±0.09 jammed recall on the synthetic dataset with only 22k parameters."
  - [corpus] No direct corpus evidence for ViT vs. Transformer comparison in assembly tasks; the mechanism is specific to this paper's empirical findings.
- Break condition: If the rotational sensor introduces noise or calibration drift that corrupts the phase signal, ViT performance with rotation may degrade below the force/torque-only baseline. If synthetic data generation creates temporal artifacts that violate physical constraints, Transformer gains from larger datasets may not transfer to real deployments.

## Foundational Learning

- Concept: **Class Imbalance and Precision-Recall Trade-offs**
  - Why needed here: The dataset has 63.9% mounted vs. 12.7% jammed samples; understanding why accuracy is misleading and how precision/recall expose different failure modes is essential for interpreting the results and selecting models.
  - Quick check question: If a model achieves 85% accuracy by always predicting "mounted," what is its jammed recall? (Answer: 0%)

- Concept: **SMOTE for Time-Series Data**
  - Why needed here: SMOTE was originally designed for static features; applying it to multivariate time series requires understanding how interpolation in high-dimensional sensor space may or may not preserve temporal dynamics.
  - Quick check question: Does SMOTE interpolation between two jammed samples guarantee that the synthetic sample represents a physically plausible jammed assembly? (Answer: No—this is an assumption that must be validated empirically.)

- Concept: **Transformer vs. CNN vs. ViT for Temporal Classification**
  - Why needed here: The paper compares five architectures with vastly different parameter counts (0.3k to 29.5M); understanding the inductive biases of each helps explain why certain architectures excel with specific data treatments.
  - Quick check question: Why might a Transformer with only 22k parameters outperform a ViT with 16.7M parameters on certain metrics? (Answer: The Transformer's self-attention may capture relevant temporal dependencies more efficiently when the dataset is sufficiently augmented, while ViT's patch-based approach requires more data to learn effective representations.)

## Architecture Onboarding

- Component map: Raw Sensor Data -> Preprocessing -> Data Augmentation -> Model Architecture -> Multi-class Output -> Task-Specific Evaluation

- Critical path:
  1. Start with the original 479-sample dataset; establish baseline jammed recall (likely near 0%).
  2. Apply SMOTE to create the balanced dataset (243 samples per class); retrain and verify jammed recall improves.
  3. Add rotational data only after confirming force/torque-only performance; compare ViT with/without rotation.

- Design tradeoffs:
  - **Maximum safety (ViT + rotation + balanced data):** 0.92 jammed recall, 0.89 mounted precision, but 16.7M parameters—requires GPU inference and more memory.
  - **Computational efficiency (Transformer + synthetic data, no rotation):** 0.75 jammed recall, 0.86 mounted precision, only 22k parameters—suitable for edge deployment on robot controllers.
  - **Balanced option (CNN + balanced data, no rotation):** 0.90 mounted precision, but only 0.25 jammed recall—good when false alarms are costly but missed jams are acceptable (rare in aerospace).

- Failure signatures:
  - **High mounted precision, near-zero jammed recall:** Model has learned to predict the majority class; imbalance handling is ineffective.
  - **High variance across folds (±0.30+):** Dataset too small or model unstable; increase data augmentation or simplify architecture.
  - **Performance degrades when adding rotation:** Rotational sensor may be miscalibrated or adding noise; validate sensor quality before deployment.

- First 3 experiments:
  1. Replicate the baseline: Train all five models on the original dataset without augmentation; confirm near-zero jammed recall as a sanity check.
  2. Ablate the augmentation: Compare class weighting vs. balanced SMOTE vs. synthetic (4×) SMOTE on the Transformer architecture; plot jammed recall vs. parameter count.
  3. Test the rotational feature: Train ViT on the balanced dataset with and without rotation; if jammed recall improves >0.4 absolute, the rotational signal is critical for this architecture.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can generative models tailored for temporal dependencies improve failure detection performance over the linear interpolation methods (SMOTE) used in this study?
- **Basis in paper:** [explicit] The Conclusion states, "Future research should explore more advanced synthetic data generation techniques like generative methods tailored for temporal dependencies."
- **Why unresolved:** SMOTE relies on linear interpolation, which may not capture the complex, non-linear temporal dynamics inherent in robotic force/torque sensor data.
- **What evidence would resolve it:** A comparative study measuring the Jammed Recall and Mounted Precision of models trained on variational autoencoder or GAN-generated data versus the SMOTE-generated datasets used in this paper.

### Open Question 2
- **Question:** How effective are unsupervised anomaly detection methods in identifying unforeseen failure modes compared to the current supervised classification approach?
- **Basis in paper:** [explicit] The Conclusion suggests the need to "investigate anomaly detection methods to identify unforeseen failure modes."
- **Why unresolved:** The current methodology relies on supervised learning with fixed labels (Mounted, Not mounted, Jammed), meaning the system cannot classify or react to failure types that were not present in the training data.
- **What evidence would resolve it:** Results showing the model's ability to flag out-of-distribution samples or novel error types (e.g., cross-threading, stripped threads) without explicit training on those labels.

### Open Question 3
- **Question:** To what extent can interpretable machine learning techniques applied to these deep learning models inform better tool design and proactive control strategies?
- **Basis in paper:** [explicit] The Conclusion proposes to "apply interpretable machine learning techniques to understand model decision-making. This could potentially inform better tool design and control strategies to prevent failures proactively."
- **Why unresolved:** The current "black box" deep learning models (specifically ViT and Transformers) provide classification predictions but offer minimal explainability regarding the physical root causes of the predicted failures.
- **What evidence would resolve it:** Identification of specific temporal features or force/torque signatures (via attention maps or SHAP values) that correlate directly with adjustable physical parameters in the assembly process.

## Limitations
- Dataset Scale: 479 total samples across three classes is extremely small for deep learning, making results sensitive to sampling variance and limiting generalizability.
- Sensor Dependency: ViT's strong performance with rotation assumes high-quality rotational angle data; any sensor drift or calibration issues could invalidate this architecture choice.
- Interpolation Validity: SMOTE assumes linear interpolation in feature space preserves physical plausibility, but this is unverified for the complex dynamics of jammed vs. mounted fastener assemblies.

## Confidence
- **High Confidence:** SMOTE improves jammed recall in imbalanced datasets (directly observed across multiple models). The class imbalance problem is real and the failure mode distribution is accurately reported.
- **Medium Confidence:** Task-specific metric optimization (precision + recall) is superior to accuracy for this domain. While logically sound and consistent with safety-critical requirements, the operational cost asymmetry is assumed rather than empirically validated.
- **Low Confidence:** The exact mechanism by which ViT with rotation achieves peak jammed recall is fully understood. The empirical finding that rotation is critical for ViT but not for Transformer is not yet explained mechanistically, and may depend on subtle dataset characteristics or hyperparameter interactions.

## Next Checks
1. **Ablation on Rotational Feature Quality:** Systematically degrade rotational sensor quality (add noise, simulate drift) and re-evaluate ViT vs. Transformer performance to confirm rotational signal is the true driver of ViT's gains.
2. **Cross-Domain Generalization:** Apply the SMOTE+ViT pipeline to a different manufacturing imbalance problem (e.g., glass defect detection from the related corpus) to test if the architecture-data augmentation pairing generalizes beyond fastener assembly.
3. **Physical Plausibility Audit:** Generate synthetic SMOTE samples and conduct expert review or simulation to verify they represent physically realistic jammed assembly states, not interpolation artifacts.