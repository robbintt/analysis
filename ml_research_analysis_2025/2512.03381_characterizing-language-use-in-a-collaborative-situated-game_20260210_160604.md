---
ver: rpa2
title: Characterizing Language Use in a Collaborative Situated Game
arxiv_id: '2512.03381'
source_url: https://arxiv.org/abs/2512.03381
tags:
- language
- game
- dialogue
- utterance
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the Portal Dialogue Corpus, a dataset of 11.5
  hours of collaborative human gameplay in Portal 2. The corpus captures rich task-oriented
  dialogue, including spatial reasoning, clarification, repair, and convention formation.
---

# Characterizing Language Use in a Collaborative Situated Game

## Quick Facts
- arXiv ID: 2512.03381
- Source URL: https://arxiv.org/abs/2512.03381
- Reference count: 38
- Primary result: Introduces Portal Dialogue Corpus with 11.5 hours of collaborative gameplay data capturing rich task-oriented dialogue and convention formation

## Executive Summary
This work introduces the Portal Dialogue Corpus, a dataset of 11.5 hours of collaborative human gameplay in Portal 2. The corpus captures rich task-oriented dialogue, including spatial reasoning, clarification, repair, and convention formation. Players exhibit complex communication strategies like forming ad-hoc conventions for novel objects and using ambiguous spatial references. Automatic annotations were generated using GPT-4o, with performance lower than human agreement, indicating room for improvement.

## Method Summary
The corpus was created by recording 12 co-op Portal 2 sessions between strangers (dyads), capturing screen recordings, voice chat audio, and game state logs. WhisperX was used for transcription with manual correction. GPT-4o was used to automatically annotate dialogue acts across five DAMSL-derived layers, with a subset manually annotated for evaluation. The annotation schema captures communicative status, information level, uncertainty, utterance type, and discursive act.

## Key Results
- Players form ad-hoc conventions for novel objects, with reference length compressing over repeated use
- Spatial ambiguity requires explicit frame-of-reference negotiation between players
- Symmetric role assignment without pre-defined hierarchies produces richer mixed-initiative dialogue than instruction-following setups
- Automatic annotation using GPT-4o achieved lower agreement than human annotators (κ=0.28-0.52 vs 0.39-0.72)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Symmetric role assignment without pre-defined hierarchies produces richer mixed-initiative dialogue than instruction-following setups
- Mechanism: When neither player is assigned a "leader" or "follower" role, participants must negotiate roles through language. This forces collaborative planning utterances, role clarification, and distributed problem-solving—linguistic behaviors absent in asymmetric settings like CerealBar (Suhr et al., 2019)
- Core assumption: Role negotiation requires more complex language than instruction execution
- Evidence anchors:
  - [abstract]: "players exhibit complex communication strategies like forming ad-hoc conventions"
  - [section 5.4]: "dyads varied widely in how they distributed communication... Session 1, Blue spoke for 20m 54s while Orange only spoke for 3m 33s" showing emergent rather than assigned asymmetry
  - [corpus]: Related work on collaborative games (Hanabi, Overcooked) studies coordination without language; this corpus fills the language-rich gap
- Break condition: If roles are pre-assigned by game design or one player has significantly more domain knowledge, mixed-initiative patterns collapse into instruction-following

### Mechanism 2
- Claim: Novel referents without canonical labels trigger convention formation cycles that compress over repeated use
- Mechanism: When encountering novel game elements (e.g., "light bridge"), players propose descriptions, partners accept or modify, and references shorten across turns (Transcript 1: "catch" becomes stable shorthand). This matches Clark & Wilkes-Gibbs (1986) conceptual pact theory
- Core assumption: Players are motivated to minimize collaborative effort
- Evidence anchors:
  - [section 5.2]: Transcript 1 shows Blue using "catch," Orange adopting it in a later level
  - [section 5.2]: Transcript 3 shows "the same trick" abstracting a complex action sequence
  - [corpus]: MDC-R corpus (Minecraft Dialogue Corpus with Reference) also annotates anaphoric/deictic reference in situated dialogue; provides comparison point for convention dynamics
- Break condition: If referents already have canonical names or players share no common ground, convention formation stalls

### Mechanism 3
- Claim: Partially-observable 3D environments with asymmetric viewpoints necessitate explicit frame-of-reference negotiation
- Mechanism: Players occupy different positions with different viewpoints. Spatial terms like "right" are ambiguous without specifying the reference frame (egocentric vs. allocentric). Players explicitly repair this ambiguity through clarification requests and demonstrations (Figure 2: "what direction is right to you?")
- Core assumption: Interlocutors cannot directly observe each other's perspective
- Evidence anchors:
  - [section 5.2, Figure 2]: Multi-turn exchange where Orange says "go right," Blue asks "what direction is right to you?", Orange fails to clarify, Blue demonstrates by moving, laughter signals repair success
  - [abstract]: "ambiguous spatial references" identified as key phenomenon
  - [corpus]: TRACE system (related work) tracks common ground in situated dialogues; explicitly addresses perspective-taking
- Break condition: If a shared third-person view is available, or players share identical viewpoints, frame negotiation disappears

## Foundational Learning

- Concept: **Common Ground & Grounding (Clark & Brennan, 1991)**
  - Why needed here: The corpus annotates multi-turn clarification and repair. Without understanding grounding theory, you'll misinterpret clarification requests as information-seeking rather than coordination acts
  - Quick check question: In Transcript 4, why does Orange ask "Where?" instead of immediately acting?

- Concept: **Frame of Reference in Spatial Language (Levinson, 2003)**
  - Why needed here: Spatial ambiguity is central to this corpus. You need to distinguish egocentric ("my left"), addressee-centered ("your right"), and allocentric ("north") frames
  - Quick check question: When Blue says "this way" while moving right (Figure 2), what frame of reference is being established?

- Concept: **Dialogue Act Annotation Schemes (DAMSL)**
  - Why needed here: The corpus uses a 5-layer DAMSL-derived schema. Understanding the distinction between communicative status, information level, uncertainty, utterance type, and discursive act is essential for using annotations correctly
  - Quick check question: Why is "I think the exit is on the left" tagged as both Proposition (utterance type) and Hedging (uncertainty)?

## Architecture Onboarding

- Component map: Screen recordings (30fps) -> WhisperX transcription -> Wav2Vec forced alignment -> manual correction -> GPT-4o annotation -> 5-layer dialogue act schema
- Critical path: 1) Time-align audio, video, and game state using "L" key marker events 2) Segment audio into utterances using 2-second rule + intonation/semantics 3) Run automatic annotation on full corpus (24.5K utterances) 4) Manual annotation on subset for validation 5) Extract task completion timestamps for progress analysis
- Design tradeoffs:
  - Manual vs. automatic annotation: Human agreement (κ=0.39-0.72) exceeds GPT-4o (κ=0.28-0.52), but full manual annotation is infeasible at corpus scale. Paper uses GPT-4o for coverage, manual for evaluation
  - Text-only vs. multimodal annotation: Audio-visual access did not improve annotator agreement (Table 1), suggesting additional modalities may introduce interpretive flexibility rather than disambiguation
  - Novel vs. known referents: Disabling game hints (ping tool, partner view) increases communication but may frustrate inexperienced players
- Failure signatures:
  - Low κ on Uncertainty layer (0.39): Hedging is inherently subjective; annotators disagree on speaker confidence
  - GPT-4o underperforms on Discursive Act (κ=0.28): Pragmatic intent is harder to classify from text alone than surface form
  - Imbalanced dyads: Session 1 shows 6:1 speaking time ratio—communication distribution is highly variable across pairs
- First 3 experiments:
  1. Baseline GPT-4o improvement: Fine-tune on the 176 manually-annotated utterances; measure κ improvement on held-out subset. Target: beat GPT-4o zero-shot by 0.1+ κ
  2. Frame-of-reference classifier: Build a classifier to detect egocentric vs. addressee-centered spatial references using game state (player orientations) as supervision signal. Evaluate on spatial reference utterances
  3. Convention detection: Implement reference-length tracking across repeated mentions of the same object; hypothesize length decreases as mutual familiarity increases. Validate against manually-identified convention pairs (e.g., "catch" in Transcript 1)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can automated methods be improved to achieve human-level performance in annotating complex dialogue acts in situated environments?
- Basis in paper: [explicit] The abstract and Section 4.3 note that automatic annotations generated using GPT-4o showed performance "lower than human agreement," explicitly stating there is "room for improvement"
- Why unresolved: The complexity of the dialogue acts (specifically "Uncertainty" and "Discursive Act") and the nuanced context of the game likely exceed the current capabilities of zero-shot labeling models
- What evidence would resolve it: Development of a fine-tuned model or prompting strategy that achieves Cohen's κ scores comparable to the human baselines (0.39–0.72) reported in Table 1

### Open Question 2
- Question: Why does access to multimodal data (audio/visual) fail to improve inter-annotator agreement compared to text-only transcripts?
- Basis in paper: [inferred] Section 4.3 reports that annotations performed with audio/visual access resulted in roughly the same agreement as text-only, suggesting that more modalities may introduce interpretation flexibility rather than disambiguation
- Why unresolved: It is unclear if the lack of improvement is due to the specific annotation schema, the difficulty of synchronizing modalities, or inherent subjectivity in interpreting multimodal social signals
- What evidence would resolve it: An error analysis of specific utterances where A/V access led to disagreement, or an experiment varying the annotation interface to force attention to specific non-verbal cues

### Open Question 3
- Question: To what extent can current embodied agents learn the ad-hoc convention formation strategies observed in the corpus?
- Basis in paper: [explicit] Section 5.2 states that "recent work on modern language models have found that they struggle to participate in this lifecycle [of convention formation] in the way human users might expect"
- Why unresolved: The dynamic nature of creating shared labels for novel objects (e.g., "the catch") requires memory and theory of mind that standard models may lack
- What evidence would resolve it: A benchmark task where an agent must play the game with a human and successfully adopt or propose shorthand references, measuring the reduction in communication cost over time

## Limitations

- Annotation quality ceiling: The relatively low human agreement (κ=0.39-0.72) suggests the annotation schema may be inherently ambiguous, particularly for Uncertainty (κ=0.39) and Discursive Act (κ=0.52) layers
- Generalizability concerns: Portal 2's unique mechanics (portals, novel objects without canonical labels) may produce dialogue patterns not representative of other collaborative games or real-world situated dialogue
- Role emergence vs. design: While the symmetric role assignment is a key design feature, the corpus doesn't control for individual differences in communication style, game skill, or personality that might influence role adoption

## Confidence

- High confidence: The core empirical observations about convention formation (Transcript 1-3), spatial ambiguity (Figure 2), and asymmetric communication distribution (Session 1: 6:1 speaking ratio) are directly evidenced in the data
- Medium confidence: The claim that Portal 2 produces richer dialogue than asymmetric instruction-following setups is supported by comparison to existing corpora, but no direct experimental comparison is provided
- Medium confidence: The GPT-4o annotation results are reproducible given the schema, but the exact prompt and implementation details are unspecified, making exact replication uncertain

## Next Checks

1. Reproduce GPT-4o annotation pipeline: Implement the DAMSL-adapted schema from Appendix E, construct a prompt with dialogue history, and measure agreement on the 176-utterance test set. Verify κ values against Table 2
2. Frame-of-reference classification: Build a classifier to detect egocentric vs. addressee-centered spatial references using player orientation data as ground truth. Evaluate on spatial reference utterances from the corpus
3. Convention length tracking: Implement automatic detection of repeated object references and measure reference length compression over time. Validate findings against manually-identified convention pairs like "catch" in Transcript 1