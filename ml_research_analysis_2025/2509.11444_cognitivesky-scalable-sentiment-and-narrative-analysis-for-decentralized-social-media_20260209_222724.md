---
ver: rpa2
title: 'CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized
  Social Media'
arxiv_id: '2509.11444'
source_url: https://arxiv.org/abs/2509.11444
tags:
- cognitivesky
- social
- media
- sentiment
- decentralized
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CognitiveSky is a modular, open-source framework for real-time
  sentiment, emotion, and narrative analysis on Bluesky, a decentralized social media
  platform. It ingests public posts via WebSocket streaming, labels them using transformer-based
  NLP models (RoBERTa for sentiment, DistilRoBERTa for emotion, MiniBatchNMF for topic
  clustering), and generates structured summaries for interactive visualization.
---

# CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media

## Quick Facts
- **arXiv ID**: 2509.11444
- **Source URL**: https://arxiv.org/abs/2509.11444
- **Reference count**: 12
- **Primary result**: Modular open-source framework for real-time sentiment, emotion, and narrative analysis on Bluesky using free-tier infrastructure

## Executive Summary
CognitiveSky is a modular, open-source framework for real-time sentiment, emotion, and narrative analysis on Bluesky, a decentralized social media platform. It ingests public posts via WebSocket streaming, labels them using transformer-based NLP models (RoBERTa for sentiment, DistilRoBERTa for emotion, MiniBatchNMF for topic clustering), and generates structured summaries for interactive visualization. Built entirely on free-tier infrastructure (Oracle Cloud, Supabase, Turso, Vercel), the system achieves continuous, low-cost operation with daily summarization. CognitiveSky's dashboard enables exploration of trends in mental health discourse and can be adapted to detect disinformation, monitor crises, or analyze civic sentiment.

## Method Summary
CognitiveSky ingests live Bluesky posts via WebSocket streaming, filtering for mental health keywords and buffering in Supabase. A daily GitHub Actions pipeline applies RoBERTa for sentiment, DistilRoBERTa for emotion, and MiniBatchNMF for topic clustering, storing results in Turso. Static JSON snapshots power a Next.js dashboard on Vercel, avoiding live database queries. The system operates entirely on free-tier infrastructure with batching and memory cleanup to stay within quotas.

## Key Results
- Achieves continuous, low-cost operation using only free-tier cloud services
- Enables real-time sentiment and narrative analysis on decentralized social media
- Provides interactive dashboard for mental health discourse monitoring with potential for crisis detection and civic sentiment analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer-based models can label short-form social media text with sentiment and emotion by leveraging contextual embeddings trained on informal language.
- Mechanism: For each post x, a contextual embedding is extracted from the [CLS] token (which aggregates the input sequence). This embedding passes through a softmax classifier: ŷ = softmax(W · CLS(x) + b). RoBERTa assigns one of three polarities (positive, neutral, negative); DistilRoBERTa assigns emotion categories (joy, fear, anger, etc.) from the GoEmotions dataset.
- Core assumption: Pre-trained transformer models fine-tuned on social media data generalize to Bluesky's informal, short-form discourse.
- Evidence anchors:
  - [abstract]: "CognitiveSky applies transformer-based models to annotate large-scale user-generated content"
  - [section 2.2]: "Sentiment classification is performed using a RoBERTa-based model from CardiffNLP... Emotion detection follows using a DistilRoBERTa model trained on the GoEmotions dataset"
  - [corpus]: Related work (ArXiv:2505.01883) uses multiple pre-trained sentiment models on Twitter streams, suggesting this approach is a recognized pattern, though corpus evidence specific to Bluesky is limited.
- Break condition: If Bluesky discourse diverges significantly from Twitter-style language (different user demographics, norms, or emerging slang), model accuracy may degrade without retraining or domain adaptation.

### Mechanism 2
- Claim: MiniBatch Non-negative Matrix Factorization (NMF) on TF-IDF vectors produces interpretable topic clusters by decomposing lexical features into additive components.
- Mechanism: Posts are vectorized using TF-IDF to capture salient terms. MiniBatchNMF factorizes this matrix into two non-negative matrices (documents × topics, topics × terms), assigning each post to a dominant topic. Representative keywords are extracted from high-weight terms per topic for interpretability.
- Core assumption: Lexical features (TF-IDF) capture sufficient semantic structure for topic clustering; short posts contain enough signal for meaningful decomposition.
- Evidence anchors:
  - [section 2.2]: "Topic clustering is subsequently performed using MiniBatch Non-negative Matrix Factorization... which decomposes the TF-IDF matrix to assign each post to a dominant topic"
  - [table 1]: Compares CognitiveSky's MiniBatchNMF approach to TwiXplorer's TF-IDF clustering with centroids
  - [corpus]: Weak direct corpus evidence for NMF on decentralized platforms; most related work uses LDA or centroid-based clustering.
- Break condition: If posts are extremely short or highly ambiguous, TF-IDF vectors become sparse, and NMF may produce noisy or overlapping topics. Semantic embeddings (e.g., sentence transformers) could help but increase computational cost.

### Mechanism 3
- Claim: A three-layer decoupled architecture (ingestion → labeling → visualization) with free-tier infrastructure enables continuous, low-cost operation by isolating real-time streaming from batch processing.
- Mechanism: Ingestion runs 24/7 on Oracle Cloud VM, buffering posts in Supabase. A daily GitHub Action triggers the Python labeling pipeline (batch size ≤64), which writes to Turso and purges Supabase. JSON snapshots are precomputed for the Vercel dashboard, eliminating live database queries.
- Core assumption: Daily batch processing is sufficient latency for the target use cases (mental health monitoring, crisis response); real-time inference is not required.
- Evidence anchors:
  - [abstract]: "Built entirely on free-tier infrastructure (Oracle Cloud, Supabase, Turso, Vercel), the system achieves continuous, low-cost operation with daily summarization"
  - [section 2.1]: "These records are held in an in-memory buffer and batch-inserted into Supabase every 5 seconds or after 200 posts"
  - [corpus]: No direct corpus evidence for this exact stack; similar dashboard approaches exist (ArXiv:2505.20584 for Mpox monitoring) but use different infrastructure.
- Break condition: If API rate limits tighten, Firehose volume spikes beyond free-tier VM capacity, or GitHub Actions minutes are exhausted, the pipeline may stall. Table 3 documents mitigation strategies (batching, memory cleanup, hashing to skip unchanged snapshots).

## Foundational Learning

- Concept: **WebSocket streaming for real-time data ingestion**
  - Why needed here: The ingestion layer connects to Bluesky's AT Protocol Firehose via WebSocket to receive `app.bsky.feed.post` events in real time. Understanding async event handling and buffer management is essential.
  - Quick check question: Can you explain how a WebSocket connection differs from REST polling, and why buffering is needed before database writes?

- Concept: **Transformer [CLS] token embeddings for classification**
  - Why needed here: Sentiment and emotion models extract a [CLS] embedding as a fixed-size representation of variable-length input, then classify via softmax. This is the core of the labeling pipeline.
  - Quick check question: What does the [CLS] token represent in a transformer model, and why is it suitable for downstream classification tasks?

- Concept: **TF-IDF vectorization and Non-negative Matrix Factorization (NMF)**
  - Why needed here: Topic clustering uses TF-IDF to weight terms by importance, then NMF to decompose the document-term matrix into interpretable topics.
  - Quick check question: How does TF-IDF address the limitation of raw term frequency, and what constraint does NMF impose that makes topics more interpretable?

## Architecture Onboarding

- Component map:
  - Ingestion (Oracle Cloud VM) -> Raw Storage (Supabase) -> Labeling Pipeline (GitHub Actions) -> Labeled Storage (Turso) -> Summarization -> Visualization (Vercel)

- Critical path: Firehose → Supabase (buffer) → GitHub Actions (daily trigger) → Turso (labeled) → JSON snapshots → Vercel dashboard

- Design tradeoffs:
  - **Latency vs. cost**: Daily batch labeling reduces compute cost but introduces ~24-hour lag. Real-time inference would require always-on GPU/CPU, increasing cost.
  - **Expressiveness vs. scalability**: TF-IDF + NMF is interpretable but may miss semantic nuance. Transformer-based topic embeddings could improve quality but raise memory/compute demands.
  - **Language coverage vs. complexity**: Current models are English-only. Multilingual support would require additional models, storage, and validation.

- Failure signatures:
  - **Ingestion stalls**: VM memory exhaustion, WebSocket disconnection, Supabase write failures (check PM2 logs, buffer sizes)
  - **Labeling timeouts**: GitHub Actions 6-hour limit, memory overflow (reduce batch size, cache models, explicit memory cleanup)
  - **Duplicate/lost posts**: Missing deduplication logic, transaction failures (verify `INSERT OR IGNORE`, check Turso logs)
  - **Dashboard staleness**: Snapshot generation skipped due to unchanged content (hashing logic) or CI workflow failures

- First 3 experiments:
  1. **Validate ingestion flow locally**: Run the Node.js ingestion script against the Firehose with a narrow keyword filter, verify posts appear in Supabase within expected batch window (5 seconds or 200 posts).
  2. **Test labeling pipeline on a sample batch**: Extract 64 posts from Supabase, run the Python labeling pipeline manually, confirm sentiment/emotion/topic outputs are plausible and Turso inserts succeed.
  3. **Verify dashboard snapshot loading**: Generate a JSON snapshot locally, deploy the Next.js dashboard to Vercel, and confirm the visualization components render the aggregated metrics correctly.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can multilingual NLP models be integrated into the CognitiveSky pipeline without exceeding the compute and memory limits of the current free-tier, serverless architecture?
- Basis in paper: [explicit] The authors explicitly state in the Limitations and Future Work sections that the current reliance on "English-only models" is a constraint and that future work must focus on "multilingual and cross-cultural expansion."
- Why unresolved: Transformer-based models capable of handling multiple languages (e.g., mBERT, XLM-R) are typically larger and computationally heavier than the English-specific RoBERTa and DistilRoBERTa models currently used, potentially breaking the system's strict free-tier resource constraints.
- What evidence would resolve it: Benchmarks demonstrating that a specific multilingual transformer model can process the average daily batch of posts within the memory (RAM) and execution time limits of the GitHub Actions CI environment and Oracle Cloud VM.

### Open Question 2
- Question: Does replacing the current TF-IDF/MiniBatchNMF approach with semantic embedding-based clustering significantly improve topic coherence for short-form, decentralized discourse?
- Basis in paper: [explicit] Under Future Work, the authors identify "semantic clustering for more robust topic tracking" as a specific target for development, implying the current lexical method may be insufficient for capturing nuanced narratives.
- Why unresolved: The current pipeline relies on TF-IDF (bag-of-words) vectorization, which often fails to capture the semantic context of short social media posts; the efficacy of context-aware embeddings (e.g., sentence-transformers) for this specific application within the framework has not yet been validated.
- What evidence would resolve it: A comparative study measuring topic coherence scores (such as NPMI) between the existing MiniBatchNMF topics and those generated by a semantic clustering alternative on the same Bluesky dataset.

### Open Question 3
- Question: To what extent does user-controlled data volatility on the AT Protocol undermine the longitudinal reproducibility of sentiment analysis benchmarks generated by CognitiveSky?
- Basis in paper: [explicit] The Conclusion notes that "data volatility on decentralized networks presents challenges for replicability and long-term validation" as a primary limitation.
- Why unresolved: While CognitiveSky uses snapshot hashing to ensure *computational* reproducibility, the decentralized nature of Bluesky allows users to delete or modify content at the source. It is unclear how this affects the validity of longitudinal historical analysis if the underlying data referenced by summaries disappears.
- What evidence would resolve it: A longitudinal retention audit tracking the rate of content disappearance (tombstoning) in the stored Turso database compared to the live Firehose state over a period of months.

## Limitations

- Generalizability to non-English or non-social-media discourse is untested
- Daily summarization latency may be insufficient for time-critical applications like crisis monitoring
- Infrastructure dependencies on free-tier quotas introduce potential single points of failure if service limits change or APIs deprecate

## Confidence

- **High confidence**: The modular pipeline architecture (WebSocket ingestion → batch labeling → static dashboard) is well-specified and reproducible. The transformer-based labeling approach is standard and supported by prior work on similar social media platforms.
- **Medium confidence**: The effectiveness of TF-IDF + MiniBatchNMF for topic clustering on short, informal Bluesky posts is plausible but lacks direct validation in the paper or corpus evidence specific to decentralized platforms.
- **Low confidence**: Claims about operational continuity on free-tier infrastructure are reasonable given documented mitigations (batching, memory cleanup), but long-term stability is uncertain without empirical runtime data beyond the initial deployment.

## Next Checks

1. **Validate end-to-end pipeline latency**: Deploy the full stack locally and measure the actual time from post ingestion to dashboard update. Confirm that the 24-hour delay is acceptable for the intended use cases (mental health monitoring vs. crisis response).
2. **Test topic clustering interpretability**: Run the NMF pipeline on a held-out sample of Bluesky posts and manually evaluate whether the extracted topics and keywords are coherent and meaningful for the target domain.
3. **Stress-test infrastructure limits**: Simulate high-volume Firehose traffic and monitor ingestion, labeling, and storage components for memory exhaustion, API rate limit hits, or CI workflow timeouts. Document failure modes and recovery procedures.