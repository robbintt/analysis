---
ver: rpa2
title: Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders
arxiv_id: '2505.00216'
source_url: https://arxiv.org/abs/2505.00216
tags:
- nash
- time
- predictions
- server
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a federated learning framework for ensembles
  of proprietary deep learning models with black-box access, treating the problem
  as a non-cooperative game where each agent optimizes its contribution while preserving
  privacy. The authors derive a unique Nash equilibrium in closed-form and propose
  an algorithm where a central server adaptively weights agent predictions without
  accessing internal parameters.
---

# Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders

## Quick Facts
- arXiv ID: 2505.00216
- Source URL: https://arxiv.org/abs/2505.00216
- Reference count: 40
- Key outcome: Framework enables effective collaboration among proprietary models while maintaining their internal privacy through Nash equilibrium synchronization

## Executive Summary
This paper introduces a federated learning framework for ensembles of proprietary deep learning models with black-box access, treating the problem as a non-cooperative game where each agent optimizes its contribution while preserving privacy. The authors derive a unique Nash equilibrium in closed-form and propose an algorithm where a central server adaptively weights agent predictions without accessing internal parameters. Experiments on transformers, random feature networks, and echo-state networks across real and synthetic datasets show that Nash synchronization improves predictive accuracy by orders of magnitude compared to non-cooperative baselines, with performance gains increasing with ensemble size.

## Method Summary
The framework treats federated learning as a non-cooperative game where a central server synchronizes proprietary agents (black-box encoders) through adaptive weighting and periodic Nash equilibrium updates. Each agent maintains a frozen encoder and trainable linear decoder, sharing only predictions and feature embeddings. The server computes optimal mixture weights via regularized least squares, while agents update their decoders through either greedy ridge regression or Nash equilibrium optimization using Riccati-like matrix equations. This approach enables collaboration without exposing internal model structures.

## Key Results
- Nash synchronization improves predictive accuracy by orders of magnitude compared to non-cooperative baselines
- Performance gains increase with ensemble size, demonstrating scalability benefits
- Runtime analysis indicates modest overhead for infrequent synchronization (τ > 1)
- Framework successfully handles transformers, random feature networks, and echo-state networks across diverse datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A central server can optimize an ensemble of black-box agents by treating the mixture as a constrained quadratic program.
- **Mechanism:** The server calculates mixture weights $w_t$ by minimizing the squared error of the aggregate prediction against the true target, plus a regularization term. Unlike standard weighted averages, this method allows negative weights (signed bets), enabling the server to "invert" the prediction of a poorly performing agent to improve overall accuracy.
- **Core assumption:** The server has access to the true target variable $y_t$ immediately after prediction (online setting) to compute the error.
- **Evidence anchors:**
  - [abstract] "central server adaptively weights agent predictions"
  - [section 3.1] Defines the optimization objective (Equation 6) and derives the closed-form solution (Theorem 2).
  - [corpus] Related work in "Federation of Agents" suggests dynamic orchestration, though this paper specifically uses statistical optimization rather than semantic capability vectors.
- **Break condition:** If the regularization parameter $\kappa$ is too small or agents are highly correlated, the matrix $A$ may become ill-conditioned, destabilizing the weight calculation.

### Mechanism 2
- **Claim:** Agents implicitly coordinate by solving for a unique Nash Equilibrium in their local parameter updates.
- **Mechanism:** Each agent optimizes its local linear decoder $\beta_i$ to minimize a personalized cost function (Equation 7) that depends on the server's weights and other agents' historical predictions. The paper proves this non-cooperative game yields a unique feedback Nash equilibrium, solvable via a system of Riccati-like matrix equations (Equation 9), which synchronizes the agents' behaviors without sharing internal states.
- **Core assumption:** Agents are "rational" optimizers acting on a finite look-back window $T$, and the system matrices admit a solution (satisfied if the cost is strictly convex).
- **Evidence anchors:**
  - [abstract] "unique Nash equilibrium in closed-form... feedback mechanism"
  - [section 3.2] Theorem 3 details the closed-form solution for the feedback Nash equilibrium.
- **Break condition:** If the look-back window $T$ is too large or the decay parameter $\alpha$ is misconfigured, the solution to the matrix equations may diverge or cause the system to lag significantly behind non-stationary data (Section 4.6.2).

### Mechanism 3
- **Claim:** Proprietary privacy is maintained by decoupling the "deep feature encoder" from the "linear decoder."
- **Mechanism:** The complex, proprietary part of the model (the encoder $\phi_i$) is treated as a fixed kernel or feature generator. Only the lightweight linear readout layer $\beta_i$ is updated during the online phase. Agents share sufficient statistics (expectations of features) or embeddings $Z_t$ required for the Nash game, but never the internal weights of $\phi_i$.
- **Core assumption:** The feature encoder is pre-trained and sufficiently expressive that it does not require fine-tuning during the online phase.
- **Evidence anchors:**
  - [abstract] "without ever releasing any internal structure"
  - [section 2] Describes the architecture where the encoder is frozen at $t=0$, and updates are restricted to the linear decoder $\beta$.
- **Break condition:** If the pre-trained encoder generates features with unbounded norms (e.g., ReLU activations in Echo State Networks), it can cause numerical instability in the local decoder updates unless data is normalized (Section C.4.3).

## Foundational Learning

### Concept: Non-Cooperative Game Theory (Nash Equilibrium)
- **Why needed here:** The paper frames the federation not as a cooperative averaging task (like FedAvg) but as a competitive game where agents minimize local cost while influencing a shared outcome.
- **Quick check question:** Can you explain why a Nash Equilibrium is "stable" (no player gains by unilaterally changing strategy) and how that applies to an ensemble model?

### Concept: Ridge Regression (Regularized Least Squares)
- **Why needed here:** The local "greedy" update (Proposition 4) and the server weighting (Theorem 2) both rely on solving regularized least-squares problems.
- **Quick check question:** Why does adding an $\ell_2$ penalty (ridge term) help stabilize matrix inversions in ill-conditioned data scenarios?

### Concept: Reservoir Computing (Echo State Networks)
- **Why needed here:** One of the primary test architectures involves fixed random weights (reservoirs) and trainable readouts. Understanding this split is key to understanding how the "proprietary" constraint is implemented.
- **Quick check question:** In an Echo State Network, which weights are fixed and which are trained?

## Architecture Onboarding

### Component map:
1. **Proprietary Agents (Clients):** Contain a frozen Encoder $\phi_i$ (e.g., Transformer, ESN), latent state $Z$, and trainable Linear Decoder $\beta_i$.
2. **Server:** Maintains mixture weights $w_t$ and coordinates the "Nash Game" by broadcasting global state information.
3. **Communication Interface:** Transmits predictions $\hat{Y}$ and feature embeddings $Z$ (or their statistical expectations $A(t), B(t)$) required for Theorem 3.

### Critical path:
1. **Inference:** Agents generate predictions $\hat{Y}_{t+1}$ using local state and decoder $\beta_t$.
2. **Aggregation:** Server receives predictions, computes optimal weights $w_t$ (Theorem 2), and issues the ensemble prediction.
3. **Synchronization (Periodic):** At frequency $\tau$, agents solve the coupled Riccati equations (Theorem 3) to update $\beta_i$ based on the history of errors and embeddings.
4. **Correction:** Agents update local state to align with the Nash trajectory.

### Design tradeoffs:
- **Parallelism vs. Privacy:** Computing Nash statistics (Di, Pi) in parallel on agents exposes their embeddings $Z$ to peers. Centralizing computation on the server preserves privacy but creates a computational bottleneck (Section 3.3).
- **Frequency $\tau$:** Synchronizing at every step ($\tau=1$) maximizes accuracy but incurs heavy runtime overhead. Increasing $\tau$ reduces overhead but risks "drift" from the optimal Nash trajectory (Table 3, Figure 10).

### Failure signatures:
- **Numerical Instability:** If using Echo State Networks with ReLU on unnormalized data, latent states may explode, causing "NaN" errors in matrix inversions (Section C.4.3).
- **Concept Drift Lag:** If the look-back window $T$ is too long, the Nash synchronization may react too slowly to abrupt changes in data distribution (Figure 9).
- **Weight Collapse:** In non-Nash settings, server weights may become volatile or collapse to zero for useful agents if they temporarily underperform (Figure 7).

### First 3 experiments:
1. **Replicate Theorem 2 vs. Uniform Weighting:** Implement the server-side quadratic optimizer (Eq 6) and compare ensemble MSE against a simple average of agent predictions to validate the benefit of adaptive weighting.
2. **Validate Proposition 4 (Greedy Baseline):** Implement the "no communication" local ridge regression update for a single agent to establish a performance floor before implementing the complex Nash update.
3. **Sensitivity to Look-back $T$:** Run the full Nash synchronization on a synthetic dataset (e.g., Logistic Map) while varying $T$. Plot MSE vs. $T$ to verify the paper's finding that performance degrades if $T$ is too large (Figure 9).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the proprietary federated learning framework be extended to static and non-linear settings where agents optimize non-linear internal parameters rather than just the linear readout layer?
- **Basis in paper:** [explicit] The conclusion explicitly identifies solving "the static and non-linear settings, beyond the kernelized setup," as a primary future research question.
- **Why unresolved:** The current theoretical guarantees and closed-form Nash equilibrium rely on the assumption that agents only control a linear decoder (Equation 2).
- **What evidence would resolve it:** A derivation of optimal agent updates that handle non-linear gradients or a proof of convergence for non-linear encoder fine-tuning under black-box constraints.

### Open Question 2
- **Question:** Can the mean-field game toolbox be utilized to approximate the Nash equilibrium for an asymptotically large population of proprietary agents?
- **Basis in paper:** [explicit] The conclusion suggests investigating an "asymptotically large-population version of this problems" using mean-field games as a specific avenue for future work.
- **Why unresolved:** The current closed-form solution involves matrix inversions and iterations (Algorithm 2) that may not scale efficiently as the number of agents $N$ approaches infinity.
- **What evidence would resolve it:** A mean-field limit formulation of the game that yields a tractable density update equation replacing the discrete agent interactions.

### Open Question 3
- **Question:** How can the computational burden of the Nash equilibrium be distributed among agents without exposing proprietary internal activations (deep features) to other participants?
- **Basis in paper:** [inferred] Section 3.3 highlights a trade-off: parallelizing matrix computations exposes proprietary activations ($Z_t^i$), while centralizing everything on the server imposes a heavy computational load.
- **Why unresolved:** The paper offers two implementations with distinct downsides but does not propose a secure aggregation protocol that balances privacy with the distribution of the linear algebra overhead.
- **What evidence would resolve it:** A cryptographic or secure multi-party computation protocol that allows agents to contribute to the matrix calculations in Theorem 3 without revealing their specific $Z_t^i$ values.

## Limitations
- **Hyperparameter sensitivity**: Performance critically depends on look-back window T and decay parameter α, with robustness across diverse data regimes unclear.
- **Scalability assumptions**: Central server must handle quadratic programming and optional Nash synchronization computations, potentially creating bottlenecks for large ensembles.
- **Pre-trained encoder dependency**: Method assumes fixed, sufficiently expressive encoders; mismatched encoders cannot be compensated by linear decoder updates.

## Confidence
- **High confidence**: Closed-form solutions for server mixture weights (Theorem 2) and greedy local updates (Proposition 4) are mathematically sound and reproducible.
- **Medium confidence**: Nash equilibrium derivation (Theorem 3) is theoretically rigorous but practical stability depends on hyperparameter tuning and data characteristics.
- **Low confidence**: Privacy claims for parallel computation mode are asserted but not empirically validated against potential information leakage.

## Next Checks
1. **Stress-test hyperparameter robustness**: Run full Nash synchronization on Logistic Map dataset across T and α grid to quantify performance degradation from parameter misspecification.
2. **Evaluate information leakage in parallel mode**: Implement both centralized and parallel modes; measure variance of embeddings Z across agents to assess statistical leakage.
3. **Benchmark against federated averaging**: Compare online federation framework against FedAvg on FEMNIST to contextualize improvements in cooperative learning setting.