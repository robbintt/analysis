---
ver: rpa2
title: SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness
  for In-Vehicle Networks
arxiv_id: '2506.06556'
source_url: https://arxiv.org/abs/2506.06556
tags:
- data
- attack
- adversarial
- attacks
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents an SDN-based False Data Detection and Mitigation
  System (FDDMS) for in-vehicle networks to address false data injection attacks (FDIA)
  in Controller Area Networks (CAN). The system uses a Long Short-Term Memory (LSTM)
  model for detection and Software-Defined Networking (SDN) for real-time mitigation.
---

# SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks

## Quick Facts
- arXiv ID: 2506.06556
- Source URL: https://arxiv.org/abs/2506.06556
- Reference count: 40
- Primary result: Proposed SDN-based FDDMS achieves 99.47% normal detection accuracy and maintains 98.95-99.47% robust accuracy against multiple adversarial attacks while keeping mitigation latency below 10ms CAN bus threshold

## Executive Summary
This paper addresses false data injection attacks (FDIA) in Controller Area Networks (CAN) through an SDN-based False Data Detection and Mitigation System (FDDMS). The system combines LSTM-based detection with real-time SDN-based mitigation, achieving high accuracy against both standard and adversarial attacks. A novel DeepFool variant reduces perturbation magnitude while maintaining attack success, and a threshold-based adversarial training strategy improves model robustness without sacrificing normal accuracy.

## Method Summary
The FDDMS uses an LSTM model with 128 neurons to detect FDIA in CAN traffic, trained on 20 signals from five brake-related ECUs in a KIA SOUL vehicle. The system implements SDN-based mitigation through OpenFlow switches that redirect malicious traffic when attacks are detected. A threshold-based selective adversarial training strategy improves robustness against FGSM, BIM, and DeepFool attacks by filtering adversarial examples based on prediction confidence scores. The DeepFool variant reduces L2-norm to 38.65 while maintaining 99% attack success rate.

## Key Results
- Achieved 99.47% normal detection accuracy using LSTM with RMSprop optimizer
- Maintained robust accuracy of 99.475% against FGSM, 99.47% against BIM, and 98.95-99.47% against DeepFool attacks when adversarially trained
- Proposed DeepFool variant reduced L2-norm to 38.65 while maintaining 99% attack success rate
- SDN-based mitigation achieved average latency of 5.36ms for message transmission and 7.76ms total end-to-end latency, well below the 10ms CAN bus threshold

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LSTM neural networks can detect false data injection attacks in CAN bus traffic by learning temporal patterns that distinguish normal from malicious sequences.
- Mechanism: The LSTM model processes sequential CAN data (20 features from 5 brake-related ECUs), capturing long-term dependencies through recurrent connections. A 128-neuron LSTM layer feeds a sigmoid output for binary classification (Normal=0, Attack=1). Binary cross-entropy loss and RMSprop/Adam optimization train the model to recognize attack signatures.
- Core assumption: CAN bus traffic exhibits temporal patterns that differentiate legitimate messages from injected false data.
- Evidence anchors:
  - [abstract] "FDDMS, incorporating a Long Short Term Memory (LSTM)-based detection model, is used to identify false data injection attacks"
  - [section IV.A.1, Table II] "RMSprop and Adagrad optimizer achieved the highest normal accuracy of 99.47%... recall, precision, and F1 score were 1.00, 0.99, and 1.00"
  - [corpus] "SecCAN: An Extended CAN Controller with Embedded Intrusion Detection" confirms ML-based IDS integration challenges in vehicular architectures
- Break condition: If attacks perfectly mimic legitimate timing patterns or if CAN traffic lacks sufficient temporal structure, LSTM detection accuracy would degrade significantly.

### Mechanism 2
- Claim: Software-Defined Networking enables real-time attack mitigation by dynamically redirecting malicious traffic through flow rule updates within CAN bus timing constraints.
- Mechanism: An OpenFlow Switch (OVS) sits on the CAN bus, forwarding traffic to an SDN controller (Floodlight) with a global network view. When the LSTM model detects an attack, the mitigation module updates OVS flow table entries to redirect malicious messages to backend storage instead of broadcasting to ECUs, simultaneously triggering a driver alert.
- Core assumption: The combined detection + mitigation latency remains below CAN bus message intervals (~10ms) to avoid disrupting vehicle operations.
- Evidence anchors:
  - [abstract] "mitigation scheme is implemented to redirect attack traffic by dynamically updating flow rules through SDN"
  - [section IV.C, Table VI] "average latency of 5.36ms for message transmission and 7.76ms total end-to-end latency, well below the 10ms CAN bus threshold"
  - [corpus] "A Novel Short-Term Anomaly Prediction for IIoT with Software Defined Twin Network" supports SDN integration for dynamic control in industrial IoT contexts
- Break condition: If end-to-end latency exceeds 10ms, legitimate CAN messages would be delayed, potentially causing safety-critical vehicle malfunctions.

### Mechanism 3
- Claim: Threshold-based selective adversarial training improves robustness against adversarial attacks while maintaining high normal accuracy.
- Mechanism: During adversarial training, a score-based selection strategy filters adversarial examples. For each generated example, a score is computed based on model prediction confidence relative to ground truth. Examples with scores above threshold (0.5) are excluded—these indicate the model is already confident. Training proceeds iteratively, expanding the dataset with challenging FGSM/BIM examples while retraining on mixed original and adversarial samples.
- Core assumption: Training on "challenging" adversarial examples (where model uncertainty is high) yields better robustness than training on all adversarial examples indiscriminately.
- Evidence anchors:
  - [abstract] "enhance a re-training technique method with a threshold based selection strategy" and "maintained robust accuracy of 99.475% against FGSM, 99.47% against BIM"
  - [section IV.A.2, Table III] "Challenging FGSM training achieved 99.47% normal accuracy and robust accuracy of 99.475%, 99.47%, 98.95%, and 99.47% against FGSM, BIM, DeepFool, and our DeepFool respectively"
  - [corpus] "Assessing the Resilience of Automotive Intrusion Detection Systems to Adversarial Manipulation" (FMR=0.60) provides highly relevant context on IDS adversarial robustness
- Break condition: If threshold selection excludes important attack patterns or if re-training overfits to specific adversarial methods, robustness may not generalize to novel attack variants.

## Foundational Learning

- Concept: **Controller Area Network (CAN) Protocol**
  - Why needed here: Understanding CAN's broadcast communication model, lack of authentication/encryption, and message frame structure (Arbitration/Control/Data fields) is essential to comprehend why FDIA attacks are feasible and how to decode raw CAN data.
  - Quick check question: Why does CAN's lack of source/destination addressing make it vulnerable to false data injection?

- Concept: **Adversarial Attacks on Neural Networks (FGSM, BIM, DeepFool)**
  - Why needed here: The paper assumes familiarity with gradient-based adversarial attack methods that craft minimal perturbations to cause misclassification. Understanding the tradeoff between perturbation magnitude and attack success rate is crucial for evaluating the proposed DeepFool variant.
  - Quick check question: What is the key difference between FGSM (single-step) and BIM (iterative) in terms of perturbation quality and computational cost?

- Concept: **Software-Defined Networking (SDN) and OpenFlow Protocol**
  - Why needed here: Understanding the separation of control plane (SDN controller) from data plane (OpenFlow switches) and how flow table rules are dynamically updated is essential for comprehending the mitigation scheme.
  - Quick check question: How does an OpenFlow switch's flow table differ from a traditional switch's forwarding logic?

## Architecture Onboarding

- Component map:
  CAN Bus (broadcast medium) -> ECUs: EMS, MDPS (broadcast), ABS, ESC, EPB (receive), Malicious ECU -> OpenFlow Switch (OVS) intercepts all CAN traffic -> SDN Controller (Floodlight) -> FDDMS Framework -> LSTM Detection Module (128 neurons, sigmoid output) -> Mitigation Module (flow rule updater) -> Global network view -> Backend Storage (redirected attack traffic sink)

- Critical path:
  1. ECU broadcasts CAN message -> OVS intercepts
  2. SDN controller receives traffic via OVS secure channel
  3. LSTM model classifies sequence (threshold at 0.5)
  4. If Attack detected -> Controller updates OVS flow table
  5. Attack messages redirected to backend storage (not broadcast)
  6. Driver alert triggered simultaneously

- Design tradeoffs:
  - **Latency vs. Model Complexity**: Larger LSTM or deeper networks increase detection accuracy but may exceed 10ms threshold
  - **Normal vs. Robust Accuracy**: Adversarial training typically trades natural accuracy for robustness; threshold selection mitigates this
  - **Threshold Parameter**: Lower threshold includes more training examples (potentially easier ones); higher threshold focuses on harder examples but reduces training data volume
  - **SDN Centralization**: Single controller provides global visibility but creates potential single point of failure

- Failure signatures:
  - Detection latency > 10ms: System cannot process CAN messages at bus rate
  - High false positive rate: Legitimate brake/steering messages blocked -> vehicle malfunction
  - Adversarial evasion: Perturbed FDIA classified as "Normal" (model confidence high on wrong class)
  - SDN controller crash: No monitoring/mitigation, traffic flows unfiltered

- First 3 experiments:
  1. **Baseline LSTM Characterization**: Train LSTM on FDIA-only dataset (no adversarial training), measure normal accuracy and robust accuracy against FGSM/BIM/DeepFool to establish vulnerability baseline (expect 100% normal, 1-37% robust per Table III)
  2. **Adversarial Training Ablation**: Compare three training strategies—(a) FDIA only, (b) FDIA + all FGSM examples, (c) FDIA + threshold-selected "challenging" FGSM examples—evaluate both normal and robust accuracy across all four attack types
  3. **End-to-End Latency Stress Test**: Deploy on GENI testbed with Floodlight/OVS, inject FDIA at increasing rates (10%, 25%, 50% attack traffic), measure detection time, mitigation time, and total latency to confirm <10ms threshold maintained under realistic load

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the FDDMS perform against black-box adversarial attacks where the attacker has no access to the LSTM model's architecture or parameters?
- Basis in paper: [inferred] The authors explicitly limit their robustness evaluation to a "white-box scenario" (Section IV) to calculate gradients for adversarial examples.
- Why unresolved: The paper does not test robustness against attacks that rely on substitute models or query-based methods, which are more realistic for external attackers.
- What evidence would resolve it: Performance metrics (accuracy, F1-score) of the detection model when subjected to black-box adversarial attacks like HopSkipJumpAttack or transfer attacks from substitute models.

### Open Question 2
- Question: Can the system maintain sub-10ms latency when scaling to monitor all 70+ ECUs in a modern vehicle?
- Basis in paper: [inferred] The evaluation focuses solely on five brake-related ECUs (Section III-A), while the introduction notes modern vehicles can have over 70.
- Why unresolved: The 7.76ms average latency was achieved with a limited scope; the computational overhead of decoding and running LSTM inference on significantly more traffic is unknown.
- What evidence would resolve it: End-to-end latency measurements while the SDN controller monitors a full-scale in-vehicle network simulation or dataset comprising all available ECUs.

### Open Question 3
- Question: How does the detection model respond to sophisticated, context-aware false data injection attacks compared to the uniform random injection model used in the study?
- Basis in paper: [explicit] The conclusion states: "Future work will focus on developing more sophisticated attack models."
- Why unresolved: The current attack model injects random values within a normal range (Section III-B), which may not represent stealthy, physically feasible attacks designed to mimic realistic driving behaviors.
- What evidence would resolve it: Detection accuracy rates when the system is tested against attack models that respect vehicle physics or sequential data patterns (e.g., replay attacks modified to bypass frequency checks).

## Limitations
- Dataset Generalization: Evaluation relies on single vehicle model (KIA SOUL); performance on other makes/models or novel attack patterns unverified
- Threshold Parameter Sensitivity: Fixed threshold (0.5) without sensitivity analysis; different thresholds may yield different robustness-accuracy tradeoffs
- Real-world Deployment Constraints: SDN-based mitigation demonstrated on testbed but faces hardware constraints, safety certification, and single-point-of-failure risks in actual vehicles

## Confidence
- **High Confidence**: Normal detection accuracy (99.47%) and SDN mitigation latency (<10ms) - directly supported by experimental results with clear metrics
- **Medium Confidence**: Adversarial training effectiveness - while robust accuracy is reported, threshold selection mechanism lacks detailed ablation studies
- **Low Confidence**: Generalization to unseen attack variants - paper evaluates against specific attacks but doesn't demonstrate resistance to novel or adaptive attack strategies

## Next Checks
1. **Cross-Vehicle Validation**: Test FDDMS on CAN datasets from multiple vehicle manufacturers to verify model generalization beyond KIA SOUL architecture
2. **Adaptive Attack Evaluation**: Implement an adaptive attacker that modifies strategies based on detection feedback to assess whether threshold-based training provides meaningful robustness against intelligent adversaries
3. **Safety Impact Assessment**: Conduct controlled experiments measuring vehicle safety metrics when legitimate messages are falsely flagged as attacks under various attack intensities and SDN controller failure scenarios