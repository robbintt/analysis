---
ver: rpa2
title: Clustered Federated Learning via Embedding Distributions
arxiv_id: '2506.07769'
source_url: https://arxiv.org/abs/2506.07769
tags:
- clients
- clustering
- learning
- data
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EMD-CFL proposes using Earth Mover's Distance between client data
  embeddings for clustered federated learning. The method leverages insights from
  domain adaptation theory to justify clustering based on distribution distances in
  embedding space.
---

# Clustered Federated Learning via Embedding Distributions

## Quick Facts
- **arXiv ID**: 2506.07769
- **Source URL**: https://arxiv.org/abs/2506.07769
- **Reference count**: 29
- **Primary result**: EMD-CFL achieves perfect clustering performance on Rotated MNIST/CIFAR10 with Oracle accuracy

## Executive Summary
EMD-CFL introduces a one-shot clustering method for federated learning that uses Earth Mover's Distance (EMD) between client data distributions in embedding space to handle non-IID data. The approach leverages domain adaptation theory to justify clustering based on distribution distances and implements privacy-preserving random projections during the clustering phase. The method demonstrates superior clustering performance across five datasets compared to 16 baselines, successfully identifying natural clusters in PACS and isolating backdoor features in manipulated datasets.

## Method Summary
The method performs one-shot clustering in the first epoch using pairwise EMD calculations between randomly projected embeddings from different clients. Clients exchange embedding models, agree on random projection matrices unknown to the server, and compute pairwise distances using their local data. The server performs clustering based on a threshold parameter ε, and subsequent training proceeds via FedAvg within identified clusters. The approach is theoretically justified through domain adaptation bounds showing that generalization error depends on EMD between client distributions.

## Key Results
- Achieves perfect clustering (ARI=1.0) on Rotated MNIST and CIFAR10 datasets
- Matches Oracle accuracy on rotation-based tasks while baselines fail
- Successfully identifies natural clusters in PACS (4 domains, 18 clients) and isolates backdoor features in manipulated datasets
- Demonstrates robustness to hyperparameter choices, larger model architectures, and partial client participation

## Why This Works (Mechanism)

### Mechanism 1: EMD-based Clustering for Non-IID Data
Clustering clients based on Earth Mover's Distance between their data distributions in embedding space effectively handles non-IID data by grouping similar distributions and training cluster-specific models. This addresses heterogeneity by ensuring clients train on more homogeneous data.

### Mechanism 2: One-Shot Clustering via Random Projection Privacy
The one-shot clustering approach uses randomly projected embeddings to allow efficient and privacy-preserving client grouping without sharing raw data or exact embeddings. Random projection preserves distances while protecting embedding privacy through secrecy of the projection matrix.

### Mechanism 3: Theoretical Justification via Domain Adaptation Bounds
Theoretical results from domain adaptation justify using EMD as a clustering criterion by showing it bounds the generalization error of federated models. The error of a federated model is bounded by a term proportional to the EMD between client data distributions.

## Foundational Learning

- **Earth Mover's Distance (EMD) / Wasserstein Distance**
  - Why needed here: Core distance metric for comparing client data distributions
  - Quick check: Given two distributions, one translated version of the other, would EMD be higher or lower than if identical? What is the primary computational bottleneck?

- **Johnson-Lindenstrauss (JL) Lemma**
  - Why needed here: Provides theoretical guarantee that random projection preserves distances for privacy-preserving embedding sharing
  - Quick check: For given number of data points, does JL lemma require projection dimension to scale linearly or sub-linearly with original dimension?

- **Clustered Federated Learning (CFL)**
  - Why needed here: EMD-CFL is a CFL method addressing non-IID data by grouping clients
  - Quick check: In CFL, do all clients train on same global model? If not, how do they coordinate?

## Architecture Onboarding

- **Component map**:
  - Clients: Hold local datasets, train local models, generate projected embeddings, calculate reference distance
  - Server: Manages training rounds, receives projected embeddings, computes pairwise EMDs, performs clustering, aggregates models
  - Embedding Model (gω): Maps input data to embedding space, parameters shared between client pairs
  - Hypothesis (hφ): Final layer mapping embeddings to outputs, focus of theoretical bounds
  - Random Projector (R): Private matrix agreed upon by client pairs to project embeddings

- **Critical path**:
  1. Initialization: Server distributes initial global model
  2. Pairwise Agreement: Clients agree on random seed for projection matrix R
  3. Local Computation: Clients compute embeddings, apply projection R
  4. Server Upload: Clients send projected embeddings and reference distance to server
  5. Clustering: Server computes EMDs, updates adjacency matrix, forms clusters
  6. Training & Aggregation: FedAvg within identified clusters

- **Design tradeoffs**:
  - Embedding Dimension vs. Privacy: Lower dimensions offer stronger privacy but risk losing information
  - Projection Dimension vs. Accuracy: Paper shows robustness to 90% reduction but dataset-dependent
  - One-Shot Cost vs. Iterative Cost: Higher upfront cost but amortizes over training process
  - EMD Solver Choice: Exact O(N³ log N) vs. approximate Sinkhorn O(N²) tradeoff

- **Failure signatures**:
  - Clustering ARI near 0: Distance tolerance ε incorrectly set or projection destroyed structure
  - Worst-client accuracy very low: Clustering failed to separate distinct distribution
  - Privacy breach: Client or server successfully inverts projected embeddings

- **First 3 experiments**:
  1. Baseline Reproduction on Rotated MNIST/CIFAR10 with 2-layer CNN to verify core mechanism
  2. Ablation on hyperparameters (ε and dim(R)) to find stable operating range
  3. Scalability Test with Sinkhorn Distance on Rotated CIFAR10 with ResNet18 to quantify speed-accuracy tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
How can the quadratic communication complexity O(C²|ω|) be reduced for cross-device federated learning? The authors note they leave detailed exploration of reducing communication costs to future work, as the current implementation scales quadratically with client count.

### Open Question 2
Does EMD-CFL performance degrade in environments with temporal data distribution shifts? The one-shot clustering approach assumes static distributions, which may not hold in dynamic real-world environments where concept drift could invalidate static cluster assignments.

### Open Question 3
What is the tradeoff between clustering accuracy and privacy when applying differential privacy mechanisms to exchanged embedding models? The paper suggests DP could provide additional security but doesn't analyze the impact of DP noise on EMD sensitivity.

## Limitations
- Quadratic communication complexity limits scalability to cross-device federated learning
- Performance on highly complex, real-world non-IID scenarios beyond controlled synthetic datasets remains untested
- Theoretical generalization bounds' practical utility depends on unknown Lipschitz constant magnitude

## Confidence
- **High Confidence**: Core mechanism of EMD clustering, one-shot approach with random projections, experimental results on tested datasets
- **Medium Confidence**: Robustness claims to hyperparameters, theoretical justification from domain adaptation
- **Low Confidence**: Effectiveness on highly complex, real-world non-IID scenarios

## Next Checks
1. Test on synthetic complex heterogeneity with overlapping distributions to stress-test clustering
2. Analyze Lipschitz constant impact by estimating bounds for used architectures
3. Benchmark against stronger privacy guarantees using differential privacy to contextualize the 10% projection dimension choice