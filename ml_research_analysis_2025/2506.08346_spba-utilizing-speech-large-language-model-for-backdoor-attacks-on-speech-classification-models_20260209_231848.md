---
ver: rpa2
title: 'SPBA: Utilizing Speech Large Language Model for Backdoor Attacks on Speech
  Classification Models'
arxiv_id: '2506.08346'
source_url: https://arxiv.org/abs/2506.08346
tags:
- speech
- backdoor
- trigger
- triggers
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SPBA, a speech backdoor attack method leveraging
  Speech Large Language Models (SLLMs) to generate diverse triggers based on timbre
  and emotion. The method addresses the limitation of existing speech backdoor attacks,
  which are constrained by a single trigger function and vulnerability to defense
  methods.
---

# SPBA: Utilizing Speech Large Language Model for Backdoor Attacks on Speech Classification Models

## Quick Facts
- arXiv ID: 2506.08346
- Source URL: https://arxiv.org/abs/2506.08346
- Reference count: 40
- This paper proposes SPBA, a speech backdoor attack method leveraging Speech Large Language Models (SLLMs) to generate diverse triggers based on timbre and emotion.

## Executive Summary
This paper introduces SPBA, a novel speech backdoor attack method that uses Speech Large Language Models (SLLMs) to generate diverse triggers based on timbre and emotion, addressing limitations of existing speech backdoor attacks constrained by single triggers and vulnerability to defenses. The method leverages SLLM to synthesize poisoned speech samples that embed multiple backdoors into speech classification models while maintaining high speech quality. To handle the challenge of balancing multiple backdoor tasks without excessively increasing poisoning rate, the authors introduce the Multiple Gradient Descent Algorithm (MGDA). Experimental results on keyword spotting and speaker verification tasks demonstrate that SPBA achieves high attack success rates (up to 99.95%) with significantly lower poisoning rates compared to baselines, while maintaining high speech quality and trigger effectiveness.

## Method Summary
SPBA operates through three stages: first, it generates poisoned speech samples using an SLLM that synthesizes utterances with target timbre and emotion attributes based on source transcripts and reference speech; second, it trains the victim model using MGDA to balance multiple backdoor tasks alongside the main classification task, optimizing scaling coefficients for each trigger's loss function; third, it evaluates attack success through inference on both clean and poisoned test sets. The method addresses the key challenge of multi-trigger backdoor attacks where increasing the number of triggers typically increases poisoning rate, by using MGDA to find optimal gradient-based scaling coefficients that maintain attack effectiveness while reducing per-trigger poisoning requirements.

## Key Results
- SPBA achieves 99.95% attack success rate on keyword spotting tasks with significantly lower poisoning rates (400-500 total poisoned samples) compared to single-trigger baselines requiring 250-550 per trigger
- Emotion-based triggers show differential effectiveness, with intense emotions (angry, happy) achieving higher ASR faster than neutral or sad emotions
- SPBA maintains high speech quality with MOS scores above 3.5 and trigger accuracy (F1) above 0.85 across all tested trigger types

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: SLLM-generated triggers based on speech elements (timbre, emotion) create semantically coherent poisoned samples that evade detection better than noise-based triggers.
- **Mechanism**: The SLLM takes source transcripts and reference speech with target attributes (timbre/emotion) to synthesize poisoned utterances that maintain natural speech quality while embedding trigger characteristics. The model learns: SLLM(text_s, [text_r, Sig_r]) → poisoned speech with specific timbre/emotion.
- **Core assumption**: Speech element triggers (timbre, emotion) are less detectable by human auditory systems and existing defenses than disruption-based triggers (noise, ultrasonic).
- **Evidence anchors**:
  - [abstract] "speech backdoor attacks can strategically focus on speech elements such as timbre and emotion, leveraging the Speech Large Language Model (SLLM) to generate diverse triggers"
  - [Page 1, Section I] "speech and image triggers differ due to their distinct physical properties... disruption triggers... are typically detectable by human auditory systems"
  - [corpus] Limited direct corpus evidence on SLLM-based triggers specifically; neighbor papers focus on image/LLM backdoors, not speech element triggers.
- **Break condition**: If SLLM-generated samples fail to maintain sufficient acoustic similarity to reference triggers (low Trigger Accuracy), or if poisoned samples have MOS significantly below clean speech (~4.0+), the stealthiness assumption fails.

### Mechanism 2
- **Claim**: Multiple triggers reduce per-trigger poisoning requirements when balanced with MGDA, maintaining attack success while improving defense resistance.
- **Mechanism**: Instead of one trigger with high poisoning rate, SPBA distributes K triggers with lower per-trigger poisoning rates. MGDA computes gradient-optimal scaling coefficients (λ₁...λₖ) to minimize loss conflicts between main task and backdoor tasks: L_ba = λ₁L_T + Σλₖ(L*_T, t=k).
- **Core assumption**: Models with multiple diverse backdoors are harder to defend against than single-backdoor models because defense methods (e.g., Neural Cleanse) target single trigger patterns.
- **Evidence anchors**:
  - [abstract] "Increasing the number of triggers may disproportionately elevate the poisoning rate... We introduce MGDA as a mitigation strategy"
  - [Page 2, Section I] "Defense methods are less likely to succeed if the model includes multiple effective backdoors linked to different triggers"
  - [Page 5, Tables I-II] SPBA (MGDA, K=5) achieves 99.95% ASR with PN=400-500 total (≈80-100 per trigger) vs. baselines requiring 250-550 per single trigger
  - [corpus] SFIBA paper discusses multi-target backdoor attacks conceptually, supporting multi-backdoor resistance hypothesis.
- **Break condition**: If per-trigger ASR drops below ~95% with MGDA, or if total poisoning rate exceeds ~5% without proportionally better ASR, the multi-trigger tradeoff fails.

### Mechanism 3
- **Claim**: Emotion-based triggers show differential effectiveness, with intense emotions (angry, happy) achieving higher ASR faster than neutral or sad emotions.
- **Mechanism**: Classification models exhibit varying sensitivity to emotional prosody features. Intense emotions correlate with more distinctive acoustic patterns (pitch variation, energy) that create stronger backdoor associations during training.
- **Core assumption**: Emotional features are learnable as backdoor triggers and maintain sufficient acoustic distinctiveness across speakers.
- **Evidence anchors**:
  - [Page 6, Figure 2a] "intense emotions such as {Angry, and Happy} can achieve the highest ASR most quickly, while the poisoned number gradually reached 110"
  - [Page 5, Table III] Trigger Accuracy (F1): Angry=0.9789, Happy=0.9702, Sad=0.9688, showing measurable differences
  - [corpus] No direct corpus evidence on emotion-trigger effectiveness in speech backdoors.
- **Break condition**: If F1 scores for emotion triggers fall below ~0.90 (poor trigger recognition) or if no ASR differentiation exists between emotion types, the emotion sensitivity claim weakens.

## Foundational Learning

- **Concept: Backdoor Attacks on DNNs**
  - **Why needed here**: SPBA is fundamentally a backdoor attack; understanding the threat model (data poisoning, trigger-target mapping, clean vs. poisoned behavior) is essential to grasp how SLLM-generated triggers fit into the attack pipeline.
  - **Quick check question**: Can you explain why a backdoored model must maintain high accuracy on clean inputs while misclassifying triggered inputs?

- **Concept: Multi-Task Learning and Gradient Balancing**
  - **Why needed here**: MGDA is the core optimization innovation; understanding how conflicting gradients between main task (clean classification) and backdoor tasks are balanced explains why SPBA can inject multiple backdoors without exploding poisoning rates.
  - **Quick check question**: Why would naively summing losses from 5 triggers and 1 main task cause suboptimal backdoor performance?

- **Concept: Speech Classification Architectures (KWS, SV)**
  - **Why needed here**: Victim models (ResNet18, ECAPA-TDNN, SincNet, etc.) process spectrograms; understanding their input representations (mel-spectrograms, STFT) and training pipelines clarifies where poisoned samples enter.
  - **Quick check question**: What spectrogram features would you expect a timbre trigger to modify versus an emotion trigger?

## Architecture Onboarding

- **Component map**: Speech Transcription Model (STM, e.g., Paraformer) → source transcripts; Prompt Dataset (timbre/emotion reference utterances from ESD) → SLLM input; SLLM → poisoned subset D_ps with trigger attributes; Combine D_ps + D_c1 → poisoned dataset D_p → batch sampling; Clean batches → standard cross-entropy loss; Mixed batches → MGDA computes λ coefficients → balanced loss L_ba; Optimizer (Adam) updates victim classifier → Clean test set D_c2 → verify normal accuracy; SLLM-generated poisoned test set D_cp → measure ASR per trigger

- **Critical path**: SLLM trigger quality → MGDA gradient balancing → per-trigger ASR. If SLLM generates poor-quality triggers (low MOS, low TA), even optimal MGDA cannot recover attack success.

- **Design tradeoffs**:
  - More triggers (K=5 vs K=3) → better defense resistance but higher complexity and potential for trigger interference
  - Lower per-trigger PN → lower detectability but risk of insufficient backdoor learning
  - MGDA overhead vs. naive loss summation: MGDA adds gradient computation per task but enables multi-backdoor feasibility

- **Failure signatures**:
  - High AV (>2%) → triggers are disrupting speech quality, detectable
  - ASR variance across triggers >5% → MGDA not balancing effectively, or some triggers are acoustically similar
  - MOS < 3.5 → poisoned samples detectably unnatural
  - TA F1 < 0.85 → SLLM not accurately generating target trigger attributes

- **First 3 experiments**:
  1. **Single-trigger baseline**: Replicate VSVC or PBSM on one victim model (e.g., ResNet18 on Google Speech Commands) to establish ASR/PN baseline before implementing SPBA.
  2. **MGDA ablation**: Run SPBA with K=3 triggers on KWS task, comparing (w/o MGDA) vs. (with MGDA) to quantify the loss-balancing contribution (expected: ~10-15% ASR improvement, ~40-50% PN reduction per trigger based on Tables I-II).
  3. **Trigger quality validation**: Generate 30 poisoned samples per trigger type (angry, happy, sad, male, female), compute MOS via human evaluation and TA via Qwen-Audio to confirm SLLM output quality before full training runs.

## Open Questions the Paper Calls Out
None

## Limitations
- **ASR Generalization**: The paper reports near-perfect attack success (99.95%) but does not demonstrate results across diverse speech domains or real-world deployment scenarios, limiting experiments to controlled datasets (Google Speech Commands, LibriSpeech) and standard architectures.
- **Defense Robustness Claims**: Only one defense method (Neural Cleanse) is evaluated, though the paper claims that multiple backdoors improve resistance to defenses - this requires validation against broader defense strategies.
- **SLLM Dependence**: The attack's effectiveness hinges on SLLM quality and trigger synthesis capability, but the paper does not explore failure modes when SLLM performance degrades or when trigger generation produces acoustically ambiguous samples.

## Confidence
**High Confidence**: 
- MGDA provides measurable improvement in balancing multiple backdoor tasks
- Emotion-based triggers show differential effectiveness (angry/happy > neutral/sad)
- SPBA achieves lower poisoning rates than single-trigger baselines for comparable ASR

**Medium Confidence**: 
- SLLM-generated triggers are more stealthy than noise-based triggers
- Multiple backdoors provide significant defense resistance
- Timbre and emotion triggers maintain high speech quality (MOS > 3.5)

**Low Confidence**: 
- Attack success rates would maintain across all speech classification tasks
- Method generalizes to production speech models with different architectures
- SLLM trigger synthesis quality is consistently reliable

## Next Checks
1. **Cross-Domain Generalization Test**: Evaluate SPBA on non-keyword tasks (emotion recognition, speaker diarization) and commercial ASR systems to verify attack effectiveness beyond the tested KWS/SV scenarios.
2. **Defense Method Expansion**: Test against at least 3 additional defense strategies (e.g., spectral anomaly detection, model watermarking, adversarial training) to substantiate multi-backdoor defense resistance claims.
3. **SLLM Failure Mode Analysis**: Systematically degrade SLLM performance (reduced context length, noisy references) and measure impact on trigger quality metrics (TA, MOS) and downstream attack success to establish robustness bounds.