---
ver: rpa2
title: '$How^{2}$: How to learn from procedural How-to questions'
arxiv_id: '2510.11144'
source_url: https://arxiv.org/abs/2510.11144
tags:
- teacher
- memory
- agent
- slot
- rate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: How 2 is a framework that enables AI agents to learn from procedural
  how-to questions by asking teachers, storing the answers in memory, and reusing
  them to improve future planning. It abstracts knowledge from teacher responses to
  generalize across different task states.
---

# $How^{2}$: How to learn from procedural How-to questions

## Quick Facts
- arXiv ID: 2510.11144
- Source URL: https://arxiv.org/abs/2510.11144
- Reference count: 40
- Primary result: AI agents learn from procedural how-to questions by asking teachers, storing answers, and reusing knowledge to improve planning

## Executive Summary
How 2 is a framework that enables AI agents to learn from procedural how-to questions by interacting with teachers, storing responses in memory, and reusing this knowledge to improve future planning. The framework abstracts knowledge from teacher responses to generalize across different task states, allowing agents to become increasingly autonomous over time. In a Minecraft crafting environment, agents using How 2 significantly reduced reliance on teachers while maintaining high success rates, demonstrating the potential for human-AI collaborative learning systems.

## Method Summary
The framework implements a three-stage learning cycle where agents ask procedural questions, store teacher responses in memory, and reuse abstracted knowledge for future tasks. The key innovation lies in knowledge abstraction - converting specific teacher responses into generalized subgoals that can apply across similar task states. The system uses a memory structure that stores both fully executable plans and abstracted subgoals, with retrieval mechanisms that prioritize reusable knowledge. The Minecraft crafting environment provides a controlled testbed where agents must craft items through sequences of actions, learning optimal strategies through repeated interactions with teachers.

## Key Results
- Teachers' fully executable plans achieved 59% immediate success but showed limited reuse capability
- Abstracted subgoal plans maintained 52% success when reused across different task states
- Agents using How 2 significantly reduced teacher reliance while maintaining high success rates in the crafting environment

## Why This Works (Mechanism)
The framework works by creating a feedback loop between immediate task completion and long-term knowledge accumulation. When teachers provide solutions, the system analyzes the response structure to extract both specific action sequences and higher-level subgoals. This dual representation allows the agent to use complete plans for immediate tasks while storing abstracted knowledge for future generalization. The memory system prioritizes reusable knowledge, enabling the agent to solve increasingly complex tasks without additional teacher input. The abstraction mechanism identifies invariant patterns across similar tasks, creating transferable knowledge that applies to new but related situations.

## Foundational Learning
- Procedural knowledge representation: Needed to encode task steps in a reusable format; quick check: can plans be executed and modified independently
- Knowledge abstraction: Required to generalize from specific examples to broader patterns; quick check: does abstracted knowledge apply to novel but similar tasks
- Memory-based retrieval: Essential for storing and accessing learned knowledge; quick check: can the system retrieve relevant plans given new task states
- Subgoal decomposition: Critical for breaking complex tasks into manageable components; quick check: do subgoals maintain task completion capability when reused
- Teacher-student interaction modeling: Necessary to simulate the learning process; quick check: does interaction frequency decrease as knowledge accumulates

## Architecture Onboarding

Component map:
Teacher -> Knowledge Abstraction -> Memory Store -> Plan Retrieval -> Execution Engine -> Task State

Critical path:
1. Task State Detection -> Teacher Query
2. Teacher Response -> Knowledge Abstraction
3. Abstracted Knowledge -> Memory Storage
4. New Task State -> Memory Retrieval
5. Retrieved Plan -> Execution

Design tradeoffs:
- Storage vs. retrieval speed: Storing more detailed plans improves immediate performance but reduces memory efficiency
- Abstraction level: Higher abstraction enables better generalization but may lose critical execution details
- Teacher dependency: Balancing immediate performance with long-term autonomy requires careful knowledge abstraction

Failure signatures:
- Over-abstraction: Plans become too general to execute successfully
- Memory saturation: Retrieval becomes inefficient with too many stored plans
- Teacher dependency lock: System fails to abstract knowledge effectively

First experiments:
1. Measure plan execution success rate with only fully executable plans vs. abstracted subgoals
2. Track teacher query frequency over time as knowledge accumulates
3. Test knowledge transfer across task variations to measure abstraction quality

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to controlled Minecraft crafting environment, raising questions about cross-domain generalization
- Reliance on human teachers for initial knowledge acquisition without quantification of teacher burden or automated alternatives
- Memory system efficiency with larger knowledge bases not addressed, leaving scalability concerns

## Confidence
High confidence in framework design and basic evaluation results, Medium confidence in claimed balance between immediate performance and long-term autonomy, Low confidence in generalizability to domains outside Minecraft crafting.

## Next Checks
1. Evaluate How 2 on a completely different procedural domain (such as cooking recipes or assembly tasks) to test cross-domain generalization of the knowledge abstraction mechanism.
2. Implement a simulated teacher or automated knowledge extraction method to quantify the reduction in human involvement needed over time and assess the framework's practical deployment potential.
3. Scale the memory system to handle 10x the number of plans and tasks, measuring performance degradation and identifying bottlenecks in knowledge retrieval and reuse efficiency.