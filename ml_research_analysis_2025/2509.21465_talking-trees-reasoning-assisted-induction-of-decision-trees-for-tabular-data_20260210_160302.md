---
ver: rpa2
title: 'Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular
  Data'
arxiv_id: '2509.21465'
source_url: https://arxiv.org/abs/2509.21465
tags:
- tree
- data
- trees
- decision
- tabular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces an LLM-driven agentic framework for constructing
  interpretable decision trees on low-resource tabular datasets. The agent is equipped
  with a minimal set of tools for analyzing, modifying, and refining trees, enabling
  it to iteratively improve the model by combining prior knowledge with data-driven
  insights.
---

# Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular Data

## Quick Facts
- arXiv ID: 2509.21465
- Source URL: https://arxiv.org/abs/2509.21465
- Reference count: 40
- Primary result: Agent-driven decision tree framework outperforms CART and tuned trees on 16/17 datasets, offering interpretable alternatives with fairness and missing feature handling

## Executive Summary
This work introduces an LLM-driven agentic framework for constructing interpretable decision trees on low-resource tabular datasets. The agent uses a minimal set of tools to analyze, modify, and refine trees through iterative improvement combining prior knowledge with data-driven insights. Experiments demonstrate superior performance to CART and tuned decision trees across 16 of 17 benchmark datasets, with added capabilities for fairness constraints and missing feature scenarios through informal prompts.

## Method Summary
The framework employs an LLM-based agent equipped with specialized tools for decision tree construction and refinement. The agent iteratively improves tree models by analyzing performance, identifying weaknesses, and applying modifications based on both domain knowledge and dataset characteristics. The approach leverages informal prompt-based instructions to incorporate fairness constraints and handle missing features, allowing flexible human input while maintaining interpretability. The system builds upon standard decision tree concepts but adds reasoning capabilities to enhance both performance and practical applicability.

## Key Results
- Agent-constructed trees outperformed CART and tuned decision trees on 16 of 17 benchmark datasets
- Achieved better gender neutrality on Adult dataset while maintaining predictive performance
- Improved performance when incorporating lost features compared to traditional approaches

## Why This Works (Mechanism)
The framework works by combining the reasoning capabilities of LLMs with structured tree-building tools. The agent can analyze tree structure, identify problematic branches, and apply domain knowledge to make targeted improvements. This iterative refinement process allows the model to learn from its mistakes and adapt to dataset-specific characteristics. The informal prompt interface enables seamless integration of human expertise and fairness considerations without requiring formal constraint specifications.

## Foundational Learning
- Decision Tree Induction: Understanding of how CART splits nodes based on impurity measures (needed for recognizing traditional limitations; quick check: can identify Gini index vs entropy)
- Interpretability Tradeoffs: Balance between model complexity and explanation quality (needed for evaluating agent improvements; quick check: can articulate why simpler trees are preferred)
- Fairness Constraints: Methods for incorporating bias mitigation in ML models (needed for fairness handling; quick check: understands demographic parity vs equal opportunity)
- LLM Tool Integration: How agents can use specialized tools to modify models (needed for understanding the framework; quick check: can describe tool-based vs prompt-only approaches)
- Iterative Refinement: Process of gradual model improvement through analysis (needed for grasping the core methodology; quick check: can explain why iteration beats one-shot generation)

## Architecture Onboarding

Component Map:
LLM Agent -> Analysis Tools -> Tree Modification Tools -> Performance Evaluator -> (back to LLM Agent)

Critical Path:
1. LLM analyzes current tree performance
2. Agent identifies improvement opportunities
3. Tools modify tree structure
4. Performance evaluated against metrics
5. Process repeats until convergence

Design Tradeoffs:
- Interpretability vs performance: Agent maintains simpler trees than black-box alternatives
- Flexibility vs reliability: Informal prompts enable rapid adaptation but may not generalize
- Computational cost vs quality: Iterative refinement improves results but requires multiple LLM calls

Failure Signatures:
- Performance plateaus after several iterations
- Agent gets stuck in local optima with suboptimal splits
- Fairness improvements come at disproportionate cost to accuracy

First Experiments:
1. Compare agent performance on a simple binary classification dataset
2. Test fairness constraint incorporation on a balanced dataset
3. Evaluate missing feature handling on a controlled synthetic dataset

## Open Questions the Paper Calls Out
None

## Limitations
- Informal prompt-based fairness and missing feature handling may not generalize across diverse domains
- Performance still lags behind black-box models, indicating interpretability-performance tradeoff
- Computational efficiency and resource requirements for iterative LLM calls not thoroughly analyzed

## Confidence
High: Agent outperforms CART and tuned trees on majority of datasets
Medium: Fairness and missing feature handling effectiveness across diverse scenarios
Low: Computational efficiency and real-world scalability

## Next Checks
1. Evaluate framework on broader range of datasets with different characteristics and scales
2. Conduct detailed analysis of computational costs and runtime efficiency compared to traditional algorithms
3. Assess robustness of fairness and missing feature handling across diverse real-world datasets and fairness definitions