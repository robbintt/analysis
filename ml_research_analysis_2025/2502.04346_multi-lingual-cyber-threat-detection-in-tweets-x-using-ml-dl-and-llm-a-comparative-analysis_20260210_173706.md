---
ver: rpa2
title: 'Multi-Lingual Cyber Threat Detection in Tweets/X Using ML, DL, and LLM: A
  Comparative Analysis'
arxiv_id: '2502.04346'
source_url: https://arxiv.org/abs/2502.04346
tags:
- threat
- dataset
- layer
- tweet
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study addresses the challenge of detecting cyber threats
  in tweets across multiple languages, focusing on English, Chinese, Russian, and
  Arabic. It employs a multi-stage approach: data collection and labeling using manual
  annotation and polarity-based classification, preprocessing steps like cleaning,
  stopword removal, stemming, tokenization, and padding, and encoding using language-specific
  Word2Vec models.'
---

# Multi-Lingual Cyber Threat Detection in Tweets/X Using ML, DL, and LLM: A Comparative Analysis

## Quick Facts
- arXiv ID: 2502.04346
- Source URL: https://arxiv.org/abs/2502.04346
- Reference count: 32
- Primary result: Bi-LSTM consistently outperformed other deep learning and LLM architectures across all datasets in multilingual cyber threat detection.

## Executive Summary
This study compares machine learning, deep learning, and large language model approaches for detecting cyber threats in tweets across English, Chinese, Russian, and Arabic. The researchers employed a multi-stage approach involving data collection, preprocessing with language-specific Word2Vec embeddings, and classification using three model families. Results demonstrate that Random Forest achieved the highest accuracy among machine learning models, while Bi-LSTM consistently outperformed both other deep learning architectures and transformer-based LLMs like XLM-RoBERTa across all language datasets. The study highlights the importance of sequential pattern recognition in threat detection and suggests that language-specific embeddings may preserve semantic nuance that translation-based approaches lose.

## Method Summary
The researchers collected multilingual tweets and labeled them using manual annotation combined with polarity-based classification. Data underwent preprocessing including regex cleaning, stopword removal, stemming, tokenization (max 5000 words), and padding. Language-specific Word2Vec embeddings (300-dimensional) were created for each language, with some models pre-trained and others trained from scratch. Three classifier types were evaluated: traditional machine learning (Logistic Regression, Decision Tree, Random Forest), deep learning (Bi-RNN, Bi-LSTM, Bi-GRU), and LLMs (XLM-RoBERTa). Models were tested on individual language datasets and a combined multilingual dataset, with performance measured using accuracy, precision, recall, and F1-score metrics.

## Key Results
- Random Forest achieved the highest accuracy among machine learning models (78-92% across languages)
- Bi-LSTM demonstrated superior accuracy in multilingual threat detection (74% validation accuracy on combined dataset)
- XLM-RoBERTa underperformed with only 46% accuracy and high validation loss (1.06) on the combined dataset
- Language-specific Word2Vec embeddings were used to preserve semantic nuance across different languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language-specific Word2Vec embeddings may improve threat detection by preserving semantic nuance that translation-based approaches lose.
- Mechanism: Each language receives its own pre-trained embedding model rather than translating all text to a single language before encoding. This retains language-internal semantic relationships.
- Core assumption: Threat indicators differ linguistically across languages and cannot be uniformly captured via translation.
- Evidence anchors:
  - [abstract] "encoding using language-specific Word2Vec models"
  - [page 6, Section III.C] Details pre-trained models per language; Arabic trained on dataset due to resource constraints
  - [corpus] Weak direct evidence; corpus focuses on LLM-based CTI, not embedding comparison

### Mechanism 2
- Claim: Bi-LSTM's bidirectional sequential processing appears to capture threat-relevant patterns better than unidirectional or transformer alternatives in this experimental setup.
- Mechanism: Bi-LSTM reads sequences forward and backward, combining hidden states to represent context from both directions. The paper hypothesizes this captures "sequential patterns and contextual information" more effectively for threat detection.
- Core assumption: Cyber threat signals in tweets depend on word order and surrounding context, not just keyword presence.
- Evidence anchors:
  - [abstract] "Bi-LSTM demonstrated superior accuracy in multilingual threat detection, with specific strengths in capturing sequential patterns and contextual information"
  - [page 11, Table VI] Bi-LSTM achieved 74% validation accuracy on combined dataset vs. 44% for Bi-RNF and 46% for XLM-RoBERTa
  - [corpus] Adjacent work [26779] notes deep learning models achieve high accuracy but lack interpretability—suggests sequential models remain competitive

### Mechanism 3
- Claim: Random Forest's ensemble voting mechanism provides robust baseline performance on structured, aggregated embeddings.
- Mechanism: RF aggregates predictions from multiple decision trees trained on random feature subsets, reducing overfitting and variance compared to single trees.
- Core assumption: Mean/max-pooled Word2Vec embeddings produce sufficiently informative fixed-length vectors for tree-based classification.
- Evidence anchors:
  - [page 9-11, Tables II-V] RF consistently achieved highest ML accuracy across all four languages (78-92%)
  - [page 6, Section III.D] Embeddings aggregated via mean pooling or max pooling before ML input
  - [corpus] No direct corpus evidence on RF vs. DL for threat text classification

## Foundational Learning

- Concept: **Word2Vec and word embeddings**
  - Why needed here: Understanding how words map to dense vectors enables comprehension of why language-specific embeddings matter for semantic preservation.
  - Quick check question: Can you explain why "threat" and "danger" might have similar vector representations in a well-trained embedding space?

- Concept: **Bidirectional RNN architectures (LSTM/GRU)**
  - Why needed here: The paper's best-performing model (Bi-LSTM) relies on understanding how bidirectional processing differs from unidirectional sequence models.
  - Quick check question: Why would processing a sentence backwards help identify threats that depend on later context?

- Concept: **Classification metrics (precision, recall, F1)**
  - Why needed here: The paper reports per-class and weighted metrics; understanding class imbalance effects is essential for interpreting results.
  - Quick check question: If a model detects 100% of threats but flags 50% of non-threats as threats, which metric would reveal this problem?

## Architecture Onboarding

- Component map:
  1. Raw tweets → cleaning (regex for URLs/mentions) → stopword removal → stemming → tokenization (max 5000 words) → padding (maxlen=500)
  2. Language-specific Word2Vec (300-dim) → mean/max pooling → fixed vector
  3. Model branches: ML (LR, DT, RF) OR DL (Bi-RNN, Bi-LSTM, Bi-GRU) OR LLM (XLM-RoBERTa)
  4. Output: Softmax over classes (Threat/Neutral/Non-Threat, or binary for Arabic)

- Critical path: Data quality depends on labeling consistency (manual + polarity). If polarity thresholds (≤-0.5 = Threat) mislabel sarcasm or idioms, downstream models inherit noise.

- Design tradeoffs:
  - Language-specific embeddings vs. unified multilingual model: Former captures nuance; latter simplifies deployment.
  - Bi-LSTM (more parameters, better context) vs. Bi-GRU (fewer parameters, faster training).
  - RF (interpretable, fast inference) vs. DL (better sequence modeling, longer training).

- Failure signatures:
  - Bi-RNF validation accuracy at 44% on combined dataset (Table VI) suggests overfitting or insufficient capacity for multilingual complexity.
  - XLM-RoBERTa's 46% accuracy with 1.06 validation loss indicates underfitting—likely needs task-specific fine-tuning beyond architecture alone.
  - RF's low recall on Neutral class (e.g., 0.35 for Russian, Table IV