---
ver: rpa2
title: 'StockMem: An Event-Reflection Memory Framework for Stock Forecasting'
arxiv_id: '2512.02720'
source_url: https://arxiv.org/abs/2512.02720
tags:
- event
- memory
- stock
- information
- price
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces StockMem, a dual-layer memory framework for
  stock price prediction using event-driven knowledge extraction. The approach structures
  news into temporal event sequences, extracts incremental information reflecting
  market expectation discrepancies, and builds reflection knowledge linking events
  to price movements.
---

# StockMem: An Event-Reflection Memory Framework for Stock Forecasting
## Quick Facts
- arXiv ID: 2512.02720
- Source URL: https://arxiv.org/abs/2512.02720
- Authors: He Wang; Wenyilin Xiao; Songqiao Han; Hailiang Huang
- Reference count: 26
- Key result: StockMem achieves 0.6253 ACC and MCC on iFlytek, outperforming state-of-the-art memory-augmented models

## Executive Summary
StockMem is a dual-layer memory framework for stock price prediction that leverages event-driven knowledge extraction from financial news. The approach structures news into temporal event sequences, extracts incremental information reflecting market expectation discrepancies, and builds reflection knowledge linking events to price movements. Experiments demonstrate StockMem's superior accuracy (0.6253 ACC on iFlytek) and MCC compared to state-of-the-art memory-augmented models, with ablation studies confirming the critical importance of structured events, longitudinal tracking, and cross-company matching.

## Method Summary
StockMem processes financial news through a dual-layer memory system: Event Memory and Reflection Memory. Event Memory extracts structured events from news using an LLM, merges daily events via vector clustering and LLM refinement, and tracks event evolution to extract incremental information (ΔInfo) that captures market expectation discrepancies. Reflection Memory generates causal explanations linking events to price movements during training. At inference, the framework retrieves analogous historical scenarios through sequence similarity matching and synthesizes current events, ΔInfo, and historical references for prediction using LLM reasoning.

## Key Results
- StockMem achieves 0.6253 ACC and MCC on iFlytek, outperforming baseline memory-augmented models
- Ablation studies show Event representation improves accuracy by 16.7% vs Summary (0.5748 vs 0.4378 ACC)
- Longitudinal tracking with ΔInfo provides 17% absolute ACC improvement (0.5748 vs 0.4058)
- Cross-company historical matching enhances performance (0.5748 vs 0.5686 ACC for same-company only)

## Why This Works (Mechanism)
### Mechanism 1
Structured event representation preserves fine-grained semantic details and explicit temporal anchoring, outperforming text summaries. Events are converted to structured tuples and merged daily via clustering+LLM refinement, maintaining discriminative details lost in compression.

### Mechanism 2
Longitudinal event tracking extracts incremental information (ΔInfo) capturing market expectation discrepancies. For each event, historical predecessors are retrieved via similarity, and LLM identifies evolution patterns relative to expectations, predicting price movements based on surprise rather than absolute sentiment.

### Mechanism 3
Cross-company historical sequence matching transfers market response patterns across stocks facing similar event types. Daily events are encoded as binary vectors, Jaccard similarity computes sequence alignment, and LLM filters genuinely relevant historical references, enriching pattern recognition.

## Foundational Learning
- **Event ontology design for financial domains**: Required for structured extraction and similarity computation. Quick check: Can you map "Apple announces stock buyback program" to a specific event type in a predefined taxonomy?
- **Expectation discrepancy vs. absolute sentiment in market pricing**: Price moves on surprise, not absolute information quality. Quick check: If "expected earnings beat" was already predicted, should stock price move significantly?
- **Sequence-level similarity metrics for temporal event chains**: Retrieval uses Jaccard similarity over binary event vectors averaged across aligned time positions. Quick check: Given two 5-day sequences, can you compute similarity if day 1 has [A, B] and day 2 has [B, C]?

## Architecture Onboarding
- **Component map**: Event Memory (Extraction → Merging → Tracking) → Reflection Memory (Training causal analysis) → Retrieval (Vector encoding → Jaccard similarity → LLM filtering) → Inference (LLM synthesis)
- **Critical path**: News → event extraction → daily merging → longitudinal tracking → reflection generation → retrieval → final prediction
- **Design tradeoffs**: Vector clustering reduces cost but may over-merge events; max tracking depth D_max=5 controls context; α=0.7 weighting favors type-level similarity; cross-company matching enriches patterns but risks irrelevant transfers
- **Failure signatures**: ACC drops to ~0.40-0.45 indicate ΔInfo extraction failure; MCC near zero suggests random prediction; LLM extraction errors propagate downstream
- **First 3 experiments**: 1) Validate event extraction quality by sampling 50 articles; 2) Ablate ΔInfo on held-out week expecting 10-15% ACC drop; 3) Test retrieval precision by inspecting top-3 sequences for 10 test cases

## Open Questions the Paper Calls Out
- How does integration of multi-modal financial data (numerical time series, charts) affect reasoning capability and predictive accuracy compared to text-only approach?
- To what extent does LLM-induced event taxonomy transfer to distinct industry sectors without complete reconstruction of event type system?
- How does retrieval latency and reasoning accuracy degrade as Reflection Memory grows to span multiple years versus single quarter?

## Limitations
- Event extraction quality depends entirely on LLM performance, which lacks independent evaluation
- 13-group, 57-type ontology may not generalize across markets or domains
- Single-quarter test window provides limited robustness assessment
- No comparison against state-of-the-art numerical or hybrid models

## Confidence
- **High**: Structured event representation outperforms raw text summaries (supported by direct ablation evidence)
- **Medium**: Incremental information captures expectation discrepancies (strong ablation results but no external validation)
- **Medium**: Cross-company pattern transfer improves predictions (limited ablation support; mechanism needs broader testing)
- **Low**: Transparent reasoning via reflection memory enhances trust (qualitative claim without systematic evaluation)

## Next Checks
1. **Event Extraction Quality Audit**: Manually evaluate extracted events for 50 randomly sampled news articles across different domains to verify taxonomy coverage and extraction accuracy
2. **Cross-Market Generalization Test**: Apply framework to different market (e.g., US tech stocks) with similar news volume to assess whether structured events and ΔInfo mechanisms transfer
3. **Long-Term Stability Analysis**: Extend test period to 6-12 months and measure performance degradation to evaluate online learning mechanism's effectiveness