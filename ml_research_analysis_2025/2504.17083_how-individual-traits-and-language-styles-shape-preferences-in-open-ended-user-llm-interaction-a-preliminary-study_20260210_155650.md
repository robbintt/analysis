---
ver: rpa2
title: 'How Individual Traits and Language Styles Shape Preferences In Open-ended
  User-LLM Interaction: A Preliminary Study'
arxiv_id: '2504.17083'
source_url: https://arxiv.org/abs/2504.17083
tags:
- user
- style
- language
- traits
- preferences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This preliminary study investigates how language styles in LLM
  responses and user individual traits jointly influence user preferences in open-ended
  interactions. Through exploratory analysis of three real-world datasets, the researchers
  found that specific language styles (richness, complexity, friendliness, presentation,
  figurativeness, interactiveness, and persuasiveness) significantly affect user preferences,
  but the impact varies across different user populations.
---

# How Individual Traits and Language Styles Shape Preferences In Open-ended User-LLM Interaction: A Preliminary Study

## Quick Facts
- arXiv ID: 2504.17083
- Source URL: https://arxiv.org/abs/2504.17083
- Authors: Rendi Chevi; Kentaro Inui; Thamar Solorio; Alham Fikri Aji
- Reference count: 39
- Key outcome: Individual traits moderate how language styles influence user preferences in LLM interactions, with specific style features affecting different user populations differently

## Executive Summary
This preliminary study investigates how language styles in LLM responses and user individual traits jointly influence user preferences in open-ended interactions. Through exploratory analysis of three real-world datasets, the researchers found that specific language styles (richness, complexity, friendliness, presentation, figurativeness, interactiveness, and persuasiveness) significantly affect user preferences, but the impact varies across different user populations. In an experimental study with 10 users, the researchers discovered that individual traits (extraversion, agreeableness, openness, neuroticism, conscientiousness, and trust toward LLMs) moderate how language styles influence preferences, with each trait affecting preferences differently. For example, users high in agreeableness prefer responses with higher authoritativeness and lower figurativeness, while extraverted users prefer less figurative, less rich, and less complex responses. The findings suggest that personalizing LLM responses based on both language style and user traits could enhance user experience, though this may increase susceptibility to misinformation. The study highlights the need for future research with more diverse samples and larger sizes to better understand the joint effects and potential causal relationships between language style, individual traits, and user preferences.

## Method Summary
The study employed a mixed-methods approach across three datasets: two large-scale user preference datasets (ArenaPref and ChatbotArena) and one multi-preference dataset (MultiPref). The researchers extracted nine language style features from LLM responses using a combination of rule-based and neural methods, then used logistic regression to model preference as a function of style feature differences. In Study 2, they conducted an experimental study with 10 participants who completed personality questionnaires (Big-5 traits and Trust Scale) and evaluated 108 LLM responses. They then applied moderated logistic regression to analyze how individual traits influence the relationship between language style features and user preferences, using GPT-4o-Mini to generate controlled style variations for testing.

## Key Results
- Language style features (richness, complexity, friendliness, presentation, figurativeness, interactiveness, persuasiveness) significantly affect user preferences across datasets
- The impact of specific language styles on preferences varies across different user populations (ArenaPref, ChatbotArena, MultiPref)
- Individual traits moderate how language styles influence preferences, with agreeableness and extraversion showing the most significant moderation effects
- Users high in agreeableness prefer higher authoritativeness and lower figurativeness, while extraverted users prefer less figurative, less rich, and less complex responses
- The study identified potential risks of personalized responses increasing susceptibility to misinformation

## Why This Works (Mechanism)

### Mechanism 1: Language Style Influences User Preference
- **Claim:** Language style features in LLM responses, such as richness, complexity, and friendliness, significantly influence user preference in open-ended interactions, independent of content accuracy.
- **Mechanism:** Users evaluate responses based on stylistic elements. Positive stylistic features elevate the odds of preference, an effect modeled via binary preference regression on style feature differences between response pairs.
- **Core assumption:** Preferences can be partially explained by measurable stylistic differences in LLM responses.
- **Evidence anchors:**
  - [abstract] "...specific language styles (richness, complexity, friendliness, presentation, figurativeness, interactiveness, and persuasiveness) significantly affect user preferences..."
  - [Study 1 Findings] "An increase in Richness (↑88.6%), Complexity (↑26.9%), and Friendliness (↑28.9%) in the LLM's responses elevate user's preference [in the ArenaPref population]."
  - [corpus] Related work on conversational agents supports the general principle that interaction features, including personality-driven preferences, affect outcomes ("Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks").
- **Break condition:** If content accuracy or utility overwhelmingly dominates stylistic concerns for a given task (e.g., a critical math problem), this mechanism may weaken or reverse.

### Mechanism 2: Individual Traits Moderate Style Influence
- **Claim:** A user's individual personality traits (Big-5) and trust level moderate which language styles influence their preference.
- **Mechanism:** Personality traits act as a filter or bias. The moderated binary preference regression model shows that the coefficient of a style feature's influence changes based on the value of the trait. For example, highly agreeable users are more sensitive to authoritativeness.
- **Core assumption:** User personality traits are stable and measurable moderators of their aesthetic and interaction preferences.
- **Evidence anchors:**
  - [abstract] "...individual traits (extraversion, agreeableness, openness, neuroticism, conscientiousness, and trust toward LLMs) moderate how language styles influence preferences..."
  - [Study 2 Findings] "For users with higher level of ↑Agreeableness, lower level of ↓Figurativeness and higher level of ↑Authoritativeness increase their preferences."
  - [corpus] This is a strong theme in related literature, as seen in "AI-exhibited Personality Traits Can Shape Human Self-concept..." which links AI and human traits in interaction.
- **Break condition:** The effect may not hold if personality traits are not stable or if the measurement tool is insufficiently granular. The paper notes this is a preliminary study with a small sample (n=10 users in Study 2), so specific odds shifts should be interpreted with caution.

### Mechanism 3: Population-Level Preference Variability Implies Unobserved Moderators
- **Claim:** The influence of language style on preference varies significantly across different user populations (e.g., ArenaPref vs. ChatbotArena).
- **Mechanism:** Datasets drawn from different user populations have distinct demographic and trait compositions. Since these traits moderate style preference (Mechanism 2), the aggregate population-level preference will vary based on the distribution of these unobserved traits.
- **Core assumption:** Differences in preference across datasets are primarily driven by differences in the underlying user populations, not solely by prompt distribution or interaction context.
- **Evidence anchors:**
  - [abstract] "...the impact varies across different user populations."
  - [Study 1 Findings] "In ArenaPref population, an increase in Richness... elevate user's preference. In ChatbotArena, it was Richness... Presentation... and Figurativeness. Meanwhile, MultiPref seemed to be influenced by a more diverse set of styles..."
  - [corpus] Corpus evidence is indirectly supportive by emphasizing personalization based on user profiles (e.g., "Know Me, Respond to Me...").
- **Break condition:** The mechanism breaks if dataset-specific confounding variables (e.g., task type) are the primary drivers of the observed differences, not the users.

## Foundational Learning

- **Concept: Logistic Regression for Preference Modeling**
  - **Why needed here:** The paper models binary user preference as a function of style feature differences. Understanding logistic regression and odds ratios is essential to interpret the quantitative results (e.g., "↑88.6% odds").
  - **Quick check question:** If the coefficient for a style feature in a logistic regression is positive, does it mean the feature increases or decreases the log-odds of a user preferring that response?

- **Concept: Moderation Analysis**
  - **Why needed here:** The core contribution of Study 2 is that traits *moderate* the effect of style, meaning the relationship between style and preference depends on the trait's level.
  - **Quick check question:** In the moderated regression equation, what does the coefficient of the interaction term represent? (Answer: How much the effect of the style feature on preference changes for each unit increase in the trait).

- **Concept: Big Five Personality Traits (OCEAN)**
  - **Why needed here:** The paper uses the Big Five model to measure user personality. Understanding what high/low scores on dimensions like Extraversion mean is crucial for interpreting the qualitative findings.
  - **Quick check question:** The paper suggests users scoring high on "Openness to Experience" prefer which type of response style? (Answer: Increased figurativeness, complexity, and authoritativeness).

## Architecture Onboarding

- **Component map:** Interaction Data -> Style Feature Extractor -> Trait Measurement -> Preference Regression Model -> Stimuli Generator
- **Critical path:** 1) Profile User (measure/estimate traits), 2) Select Target Style (map traits to preferred style profile using moderated regression findings), 3) Generate Response (apply style-transfer or controlled generation)
- **Design tradeoffs:**
  - **Personalization vs. Misinformation Risk:** Maximizing preference through style (e.g., authoritativeness) can increase susceptibility to misinformation. Systems must balance engagement with safety.
  - **Precision vs. Scalability of Profiling:** Detailed questionnaires are accurate but burdensome; inferring from interaction history is scalable but noisier.
  - **Rule-based vs. Neural Style Control:** Rule-based systems (e.g., for active voice) are interpretable. Neural-based style transfer is flexible but less predictable.
- **Failure signatures:**
  - **Mismatched Style-Task:** Applying a figurative/complex style to a user needing a simple answer (e.g., low-Extraversion user) will likely fail.
  - **Overfitting to Preliminary Findings:** Treating specific odds from the small-sample (n=10) study as hard rules will likely fail. They should be treated as directional hypotheses.
  - **Neglecting Unmeasured Moderators:** Mappings may not hold for user populations that differ drastically from the study's UK-based, daily-LLM-user demographic.
- **First 3 experiments:**
  1. **Replication with Broader Demographics:** Re-run the experimental study (Study 2) with a larger, more diverse participant pool (n > 100) to validate the trait-style mappings.
  2. **A/B Test a Personalization Module:** In a live system, implement simple personalization logic (e.g., adjust style based on inferred trait) and run an A/B test against a neutral-style control, measuring preference and task success.
  3. **Test Misinformation Susceptibility:** Design an experiment where users with known traits are presented with plausible but incorrect information in either a "preferred" or neutral style. Measure acceptance rates to test the warned "double-edged consequences."

## Open Questions the Paper Calls Out
None

## Limitations
- Small experimental sample size (n=10 users) limits generalizability of trait-style preference mappings
- Demographic homogeneity (all UK-based daily LLM users) restricts applicability to other populations
- Correlational design cannot establish causal relationships between traits, styles, and preferences
- Binary preference modeling may oversimplify nuanced user evaluation processes
- Does not account for potential interaction effects between multiple traits simultaneously

## Confidence
**High Confidence**: Language styles significantly influence user preferences is well-supported by multiple datasets and aligns with established principles in human-computer interaction.
**Medium Confidence**: Moderation effects of individual traits on style preferences are plausible but specific trait-style mappings should be treated as preliminary hypotheses given small sample size.
**Low Confidence**: Population-level differences in preference patterns across datasets are observed, but attribution to unobserved user traits remains speculative without direct measurement.

## Next Checks
1. **Scale and Diversity Replication**: Replicate the experimental study (Study 2) with n > 100 participants across diverse geographic regions, age groups, and AI usage patterns to validate and refine the trait-style preference mappings while testing for cultural and demographic moderators.
2. **Causal Intervention Design**: Design a controlled experiment where users are randomly assigned to experience either their "preferred" style (based on trait profile) or a neutral style across identical content, measuring not just preference but also task performance and misinformation susceptibility to establish causal relationships.
3. **Multi-Trait Interaction Analysis**: Conduct analysis with larger samples to examine how combinations of personality traits interact to influence style preferences, moving beyond single-trait moderation to capture more realistic patterns of personality expression in AI interactions.