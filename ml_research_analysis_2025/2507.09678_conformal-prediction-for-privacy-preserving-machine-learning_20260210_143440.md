---
ver: rpa2
title: Conformal Prediction for Privacy-Preserving Machine Learning
arxiv_id: '2507.09678'
source_url: https://arxiv.org/abs/2507.09678
tags:
- prediction
- conformal
- encryption
- encrypted
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explores the feasibility of conformal prediction under
  privacy-preserving conditions by training and evaluating models on deterministically
  AES-encrypted data. The study uses MNIST images encrypted with a fixed key, showing
  that while classification accuracy drops to 36.88% from 98.11% in plaintext, the
  encrypted model retains learnable structure and supports meaningful uncertainty
  quantification.
---

# Conformal Prediction for Privacy-Preserving Machine Learning

## Quick Facts
- arXiv ID: 2507.09678
- Source URL: https://arxiv.org/abs/2507.09678
- Reference count: 5
- Primary result: Conformal prediction remains effective on deterministically AES-encrypted MNIST data with 97.76% realized coverage using e-value BB-predictor

## Executive Summary
This work explores the feasibility of conformal prediction under privacy-preserving conditions by training and evaluating models on deterministically AES-encrypted data. The study uses MNIST images encrypted with a fixed key, showing that while classification accuracy drops to 36.88% from 98.11% in plaintext, the encrypted model retains learnable structure and supports meaningful uncertainty quantification. Conformal prediction methods—p-value and e-value based—are applied directly to the encrypted domain. The e-value-based BB-predictor yields a 97.76% realized coverage at a 60% target, outperforming the p-value approach (59.3% coverage) in terms of reliability. These findings demonstrate that conformal prediction remains effective under encryption, though at the cost of larger, less precise prediction sets.

## Method Summary
The methodology encrypts MNIST images using AES-CBC with a fixed key and IV, creating deterministic mappings from plaintext to ciphertext. A feedforward neural network is trained on these encrypted representations, achieving 36.88% test accuracy compared to 98.11% on plaintext. Split conformal prediction is applied to the encrypted model outputs, using both p-value and e-value (BB-predictor) approaches. Nonconformity scores are computed from model loss values, with calibration sets used to determine prediction set thresholds. The e-value BB-predictor demonstrates superior coverage reliability (97.76% realized vs. 60% target) compared to the p-value method (59.3% coverage).

## Key Results
- Neural networks can learn from deterministically encrypted MNIST data with 36.88% accuracy vs. 10% random baseline
- Fixed-key encryption preserves exchangeability, enabling valid conformal prediction coverage guarantees
- E-value BB-predictor achieves 97.76% realized coverage at 60% target, outperforming p-value method (59.3% coverage)
- Encrypted domain CP produces larger prediction sets (7-8 labels vs. 2-3 labels for p-value)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Deterministic encryption preserves data exchangeability, enabling valid conformal prediction coverage guarantees in the encrypted domain
- Mechanism: Fixed-key encryption acts as a deterministic function mapping each plaintext input to a unique ciphertext. Since exchangeability is preserved under any fixed transformation, the rank-order statistics underlying CP remain valid when computed on encrypted representations
- Core assumption: The encryption key and initialization vector remain constant across training, calibration, and test partitions
- Evidence anchors: [abstract] "CP methods remain effective even when applied directly in the encrypted domain, owing to the preservation of data exchangeability under fixed-key encryption"

### Mechanism 2
- Claim: E-value-based BB-predictor provides more reliable coverage under encrypted conditions than traditional p-value approaches, at the cost of larger prediction sets
- Mechanism: The BB-predictor threshold (Eq. 2) scales nonconformity scores relative to the mean calibration loss, providing a looser but more robust bound. Under the high-noise conditions of encrypted data, p-value quantile-based thresholds become unstable, while the e-value approach maintains coverage by construction
- Core assumption: Loss values remain non-negative and exchangeable; the bound from Lemma 2 holds
- Evidence anchors: [section 3.3.1] "4888 out of 5000 prediction sets include the true label, corresponding to a realized coverage of approximately 97.76%"

### Mechanism 3
- Claim: Neural networks can extract latent statistical structure from deterministically encrypted data despite complete loss of human-interpretable features
- Mechanism: Deterministic AES encryption creates consistent mappings that preserve inter-sample relationships. A feedforward network learns to associate ciphertext patterns with labels through gradient descent, even though individual pixels appear as random noise
- Core assumption: The encryption function is injective (deterministic), allowing the network to build an internal lookup-like representation
- Evidence anchors: [section 3.2] "the model attains an average training accuracy of 39.48% and a test accuracy of 36.88%...substantially degraded...still exceeds the 10% baseline expected from random guessing"

## Foundational Learning

- Concept: **Exchangeability**
  - Why needed here: CP's theoretical guarantees depend on exchangeability—roughly, that data ordering doesn't carry information. Understanding this clarifies why fixed-key encryption preserves CP validity
  - Quick check question: If you shuffled the order of calibration set losses, would the resulting prediction sets change meaningfully?

- Concept: **Nonconformity scores**
  - Why needed here: These quantify how "unusual" a prediction is relative to calibration data. The paper uses loss function values as scores; understanding this mapping is essential for extending the approach
  - Quick check question: Given a model outputting softmax probabilities [0.7, 0.2, 0.1] for three classes, what would be a reasonable nonconformity score for the predicted class?

- Concept: **Split conformal prediction**
  - Why needed here: The paper uses split CP (separate calibration set), which trades data efficiency for computational simplicity. This is the practical choice for encrypted-domain deployment
  - Quick check question: Why can't we use the full training set both for model training and calibration threshold estimation?

## Architecture Onboarding

- Component map: Plaintext Data → [AES Encryption (fixed key/IV)] → Encrypted Data → [Feedforward Neural Network] → Model Outputs (softmax/loss) → [Calibration Set] → Threshold Computation → [CP Layer: p-value OR e-value BB-predictor] → Prediction Sets (label subsets)
- Critical path: Encryption consistency → model training on encrypted data → loss computation → calibration threshold selection → prediction set construction. Break any encryption consistency and the entire pipeline collapses
- Design tradeoffs:
  - **p-value CP**: Smaller prediction sets (avg ~2-3 labels) but lower coverage reliability (59.3% realized vs. 60% target)
  - **e-value BB-predictor**: Higher coverage reliability (97.76% realized) but larger prediction sets (frequently 7-8 labels)
  - **Coverage target**: Higher targets (e.g., 95%) produce uninformative prediction sets (all 10 classes); 60% is a practical compromise
- Failure signatures:
  - Accuracy near 10% → encryption is per-instance (not deterministic)
  - Coverage near target but prediction sets are all 10 classes → model has no discriminative power
  - Calibration threshold extremely high → model poorly calibrated; check loss distribution
- First 3 experiments:
  1. Reproduce the encryption pipeline on a subset of MNIST (1000 samples), verify that fixed-key encryption yields consistent ciphertexts and per-instance encryption yields unique ciphertexts for identical inputs
  2. Train the feedforward network on encrypted training data, compare test accuracy against the paper's 36.88% baseline to validate your implementation
  3. Implement both p-value and e-value CP with α=0.4, verify that realized coverage approximately matches reported values (59.3% and 97.76%) before attempting extensions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can nonconformity scoring functions be specifically designed for the encrypted domain to yield more compact prediction sets than standard loss-based scores?
- Basis in paper: [explicit] The conclusion states there is a "clear need for the development of novel nonconformity scoring functions tailored to the encrypted domain."
- Why unresolved: Current methods result in large prediction sets (often 7-10 classes) because encryption obfuscates the semantic structure used by standard scoring methods
- What evidence would resolve it: Empirical results showing reduced average prediction set sizes while maintaining valid coverage guarantees on encrypted datasets

### Open Question 2
- Question: Is it feasible to maintain conformal prediction guarantees under homomorphic or probabilistic encryption schemes rather than deterministic AES?
- Basis in paper: [explicit] The authors list "generalizing this approach to broader encryption schemes (e.g., homomorphic or probabilistic encryption)" as a critical avenue for future work
- Why unresolved: The current approach relies on exchangeability preserved by fixed-key determinism; per-instance randomization effectively destroys the learnable structure
- What evidence would resolve it: Demonstration of valid coverage on models trained with homomorphic encryption or schemes utilizing per-sample keys

### Open Question 3
- Question: What alternative model architectures can better capture latent patterns in encrypted data where spatial correlations are disrupted?
- Basis in paper: [inferred] The methodology notes that CNNs are "ill-suited" because encryption disrupts spatial correlations, limiting the study to simple feedforward networks
- Why unresolved: It is unknown if specialized architectures could improve the 36.88% accuracy, which would subsequently tighten the prediction sets
- What evidence would resolve it: Identification of an architecture that significantly outperforms the simple feedforward baseline on deterministically encrypted data

## Limitations

- The exact neural network architecture and training hyperparameters are unspecified, making exact replication challenging
- The study focuses on a fixed encryption scheme (AES-CBC with specific key/IV), limiting generalizability to other encryption methods
- The 36.88% accuracy on encrypted data, while statistically significant, may not be sufficient for practical deployment
- The fixed 60% coverage target may not be appropriate for all application domains

## Confidence

- **High confidence**: Preservation of exchangeability under fixed-key encryption (mechanism 1)
- **Medium confidence**: E-value BB-predictor performance advantage (mechanism 2)
- **Medium confidence**: Neural network learning capability on encrypted data (mechanism 3)

## Next Checks

1. **Encryption Consistency Verification**: Implement the AES-CBC encryption pipeline and verify that identical plaintext inputs produce identical ciphertexts under fixed key/IV, while per-instance encryption keys produce unique outputs
2. **Architecture Sensitivity Analysis**: Test multiple neural network architectures on the encrypted data to determine if the 36.88% accuracy is robust or architecture-dependent
3. **Coverage Target Sensitivity**: Systematically vary the coverage target (α) from 0.1 to 0.9 to map the trade-off between coverage reliability and prediction set size for both p-value and e-value methods