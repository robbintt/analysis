---
ver: rpa2
title: Interpretable Machine Learning for Reservoir Water Temperatures in the U.S.
  Red River Basin of the South
arxiv_id: '2511.01837'
source_url: https://arxiv.org/abs/2511.01837
tags:
- water
- lake
- temperature
- depth
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study develops interpretable machine learning models to predict
  reservoir water temperature across ten reservoirs in the Red River Basin, USA, using
  over 10,000 depth-resolved profiles and multiscale environmental predictors. Traditional
  physics-based models are computationally intensive and site-specific, while standard
  ML models often lack interpretability.
---

# Interpretable Machine Learning for Reservoir Water Temperatures in the U.S. Red River Basin of the South

## Quick Facts
- **arXiv ID:** 2511.01837
- **Source URL:** https://arxiv.org/abs/2511.01837
- **Reference count:** 30
- **Primary result:** RF model achieves RMSE = 1.20°C, R² = 0.97; KAN symbolic equations maintain R² ≈ 0.88-0.92

## Executive Summary
This study develops interpretable machine learning models to predict reservoir water temperature across ten reservoirs in the Red River Basin, USA, using over 10,000 depth-resolved profiles and multiscale environmental predictors. Traditional physics-based models are computationally intensive and site-specific, while standard ML models often lack interpretability. The authors evaluate Random Forest (RF), XGBoost, and Multilayer Perceptron (MLP), achieving strong predictive performance (RF: RMSE = 1.20°C, R² = 0.97), and use SHAP analysis to identify key drivers like 7-day antecedent air temperature and depth. They introduce Kolmogorov-Arnold Networks (KANs) to derive symbolic equations, incrementally increasing complexity from 1 to 10 inputs. The simple KAN models maintain high interpretability (R² up to 0.88) with linear/rational forms, while complex KANs achieve slightly higher accuracy (R² up to 0.92) using nonlinear terms. This framework bridges predictive accuracy with transparency, offering actionable insights for water resource management and climate adaptation in data-limited environments.

## Method Summary
The study predicts depth-resolved reservoir water temperature using 10,386 measurements from 674 profiles across 10 reservoirs (1996-2020). Features include 7-day antecedent air temperature, precipitation, wind, lake volume, inflow, depth, and surface area ratios. Models (RF, XGBoost, MLP) were trained with 70/30 train/test split by profile, using Min-Max scaling and 5-fold CV. SHAP analysis identified key drivers, which guided incremental KAN training to derive interpretable symbolic equations ranging from simple linear forms to complex trigonometric expressions.

## Key Results
- Random Forest achieves RMSE = 1.20°C and R² = 0.97 on test data
- Top 5 features (air temperature, depth, wind, precipitation, lake volume) capture most predictive variance
- Simple KAN models (1-5 inputs) achieve R² up to 0.88 with linear/rational equations
- Complex KAN models (6-10 inputs) achieve R² up to 0.92 with trigonometric terms
- Performance plateaus after 5 inputs, demonstrating effective feature selection

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Averaging air temperature over a 7-day antecedent window likely captures the thermal inertia of reservoir systems better than instantaneous readings.
- **Mechanism:** Large water bodies possess high thermal mass, causing a lagged response to atmospheric forcing. A moving average smooths out high-frequency meteorological noise, aligning the input signal with the physical integration time of heat in the water column.
- **Core assumption:** The reservoir's thermal response time is consistent enough that a fixed 7-day window approximates the heat storage and release dynamics across different seasons and depths.
- **Evidence anchors:**
  - [abstract] Mentions "7-day antecedent air temperature" as a key driver.
  - [section 2.3] Explicitly states: "lakes... possess significant thermal inertia... do not respond instantaneously... used a seven-day moving average... as a predictor."
  - [corpus] Weak/Tangential: Neighbor papers discuss general ML for hydrology but do not validate the specific 7-day thermal lag mechanism.
- **Break condition:** If rapid, shallow flows dominate the system (short residence time) or if the reservoir is very deep/slow mixing where response times exceed 7 days significantly, this fixed window may fail to correlate with observed temperatures.

### Mechanism 2
- **Claim:** Kolmogorov-Arnold Networks (KANs) can distill complex, non-linear environmental relationships into interpretable symbolic equations by decomposing multivariate functions into sums of univariate functions.
- **Mechanism:** Unlike MLPs that use fixed activation functions on nodes, KANs place learnable activation functions (splines) on edges. This architecture allows the network to approximate high-dimensional functions (like RWT) and then prune/regularize them into standard mathematical forms (e.g., trigonometric, linear) that humans can read.
- **Core assumption:** The underlying physical relationship between environmental drivers and water temperature can be adequately represented by compositions of continuous univariate functions without requiring deep, nested abstraction.
- **Evidence anchors:**
  - [abstract] States KANs were used to "derive symbolic equations... dominated by linear and rational forms."
  - [section 2.7] Describes KANs replacing "linear weights with learnable univariate functions applied to edges" and converting them to "symbolic expressions."
  - [corpus] No direct corpus evidence regarding KAN application in this specific domain; mechanism is derived primarily from the paper's methodology.
- **Break condition:** If the true physical process involves chaotic discontinuities or requires high-dimensional interactions that cannot be decomposed into sums of 1D functions, the symbolic regression will either fail to converge or produce overly complex, uninterpretable equations.

### Mechanism 3
- **Claim:** Sequentially adding inputs to the symbolic model based on SHAP importance rankings allows for a controlled trade-off between model simplicity and predictive accuracy.
- **Mechanism:** SHAP (SHapley Additive exPlanations) quantifies the contribution of each feature. By training KANs incrementally (1 input, then 2, etc.) ordered by SHAP magnitude, the model captures the largest variance components first. The study shows that performance plateaus after the top 5 inputs, identifying the "pareto frontier" of complexity vs. accuracy.
- **Core assumption:** The global importance ranking derived from a black-box ensemble (Random Forest) is transferable and valid for structuring the input layers of a symbolic regression model.
- **Evidence anchors:**
  - [abstract] Notes "gains diminished beyond five" predictors.
  - [section 2.7] States: "SHAP-derived feature importance ranking... was used to guide the incremental input selection for the KAN models."
  - [corpus] Weak/General: Corpus mentions ensemble methods for discharge, but not the specific SHAP-to-KAN transfer mechanism.
- **Break condition:** If the top-ranked features (e.g., Air Temp, Depth) interact non-linearly with lower-ranked features (e.g., Wind) such that the exclusion of the latter degrades the *relationship* of the former, a simple additive approach might miss critical interaction effects.

## Foundational Learning

- **Concept: Thermal Stratification & Inertia**
  - **Why needed here:** The paper models depth-resolved temperature, which relies on the physical reality that water separates into distinct thermal layers (epilimnion/hypolimnion) and resists rapid temperature change.
  - **Quick check question:** Why would a 7-day average air temperature predict water temperature better than today's instantaneous air temperature?

- **Concept: SHAP Values**
  - **Why needed here:** The study bridges "black-box" ML and interpretable physics using SHAP to rank feature importance before symbolic regression.
  - **Quick check question:** If a model uses Depth, Air Temp, and Wind, how does SHAP help determine which variable "deserves the credit" for a specific temperature prediction?

- **Concept: Symbolic Regression vs. Standard Regression**
  - **Why needed here:** The core innovation is using KANs to produce *equations* rather than just weights. Understanding this distinction is key to differentiating the "Simple" vs. "Complex" models discussed.
  - **Quick check question:** What is the difference between a model outputting $y = f(x)$ via matrix multiplication versus outputting $y = 0.85x_1 + 0.04$?

## Architecture Onboarding

- **Component map:** Data Ingestion (10 Reservoirs + GridMET) -> Feature Engineering (7-day averages, ratios) -> Surrogate Training (RF/XGBoost/MLP) -> Explainability Layer (SHAP ranking) -> Symbolic Distillation (KANs, 1-10 inputs)

- **Critical path:** The translation of **SHAP importance** into **KAN architecture width** (number of inputs). If this ranking is wrong, the simple symbolic models will fail to capture low-hanging fruit (variance), leading to unnecessary complexity in later stages.

- **Design tradeoffs:**
  - **Simple KAN (1-2 layers, low neurons):** High interpretability (linear/rational equations), lower accuracy ($R^2 \approx 0.88$). Best for stakeholder communication.
  - **Complex KAN (deeper, trig functions):** Higher accuracy ($R^2 \approx 0.92$), low interpretability (nested trigonometric terms). Best for high-fidelity surrogates.
  - **Dataset Size vs. Granularity:** The study notes limitations for reservoirs with <5 profiles; the model relies on regional generalization (10 reservoirs) to overcome sparse local data.

- **Failure signatures:**
  - **Overfitting to sparse profiles:** Extremely high performance on a reservoir with only 2 profiles (e.g., Sardis) is likely a statistical artifact rather than physical insight.
  - **Diminishing Returns:** Adding features 6-10 yields <0.01 $R^2$ improvement, signaling the model has captured the available physical signal and remaining error is likely noise or missing unobserved variables (e.g., salinity, turbidity).

- **First 3 experiments:**
  1. **Baseline Replication:** Train a Random Forest on the provided 10-reservoir dataset using only [Air Temp, Depth, Volume] to verify the $R^2 > 0.90$ claim before adding complex features.
  2. **Temporal Sensitivity:** Replace the 7-day antecedent air temperature with 3-day and 14-day averages to validate the claim that the 7-day window is the optimal representation of thermal inertia for this basin.
  3. **Symbolic Fidelity Test:** Train a "Simple KAN" with the top 3 features (Air Temp, Depth, Wind) and compare the generated symbolic equation against the paper's published equation to ensure the "symbolic distillation" process is reproducible.

## Open Questions the Paper Calls Out

- **Question:** Would incorporating solar radiation and water transparency significantly improve model predictive accuracy, particularly in clear-water reservoirs?
  - **Basis in paper:** [explicit] The authors state: "the exclusion of certain secondary drivers such as water transparency and direct solar radiation may constrain predictive accuracy under specific conditions, especially in clear-water systems where radiative heat absorption fundamentally shapes thermal stratification."
  - **Why unresolved:** These variables were deliberately excluded to prioritize generalizability and data availability across the basin, but their marginal contribution remains untested.
  - **What evidence would resolve it:** A comparative study adding shortwave radiation and Secchi depth measurements to the model input set for clear-water reservoirs, quantifying R² improvements.

- **Question:** Can the KAN-derived symbolic equations generalize to reservoirs outside the Red River Basin without retraining?
  - **Basis in paper:** [explicit] "Applying the model beyond these bounds could reduce accuracy and would likely require local calibration or retraining the models with new data. Expanding the dataset to cover a wider variety of reservoir types and climates would further strengthen model generalizability."
  - **Why unresolved:** The current models were trained exclusively on 10 reservoirs within a single basin with specific climatic and morphometric characteristics.
  - **What evidence would resolve it:** Testing the trained RF, XGBoost, and KAN models on independent reservoir datasets from different climatic regions (e.g., northern temperate, tropical, or arid zones) without retraining.

- **Question:** How do the ML models and KAN symbolic equations perform under future climate scenarios with conditions outside the historical training range?
  - **Basis in paper:** [inferred] The paper notes that variable selection was "based on their availability in both observational datasets and future climate projections (CMIP6; 2020-2100)" and emphasizes climate adaptation applications, but does not test model performance under projected climate conditions.
  - **Why unresolved:** All validation was performed on historical data (1996-2020), and the symbolic equations are explicitly "valid only within the training input range."
  - **What evidence would resolve it:** Forcing the models with CMIP6 climate projections and comparing predictions to physics-based lake models or extrapolated empirical relationships.

- **Question:** Would alternative temporal windows for antecedent meteorological variables (e.g., 14-day, 30-day) improve predictive performance for deep reservoirs with longer thermal memory?
  - **Basis in paper:** [inferred] The authors note that "a one-week average better captures the smoothing effect of thermal inertia" and that hypolimnetic temperatures "reflect more complex dynamics shaped by...longer-term climate signals," but only tested 7-day antecedent windows.
  - **Why unresolved:** The 7-day window was chosen as a "balanced representation" without systematic comparison to longer windows that may better capture deep-reservoir thermal dynamics.
  - **What evidence would resolve it:** Systematic hyperparameter search testing 3, 7, 14, 21, and 30-day antecedent windows, stratified by reservoir depth.

## Limitations

- Geographic generalization relies on 10 reservoirs in a single basin, limiting transferability to different climatic regions
- Sparse data for some reservoirs (<5 profiles) may lead to overfitting and unreliable performance estimates
- 7-day thermal lag assumption may not capture the dynamics of deep reservoirs or those with rapid turnover
- Missing key physical drivers like solar radiation and water transparency may constrain accuracy in clear-water systems

## Confidence

- **High:** ML performance metrics (RF R² = 0.97, RMSE = 1.20°C) and identification of key drivers (air temperature, depth)
- **Medium:** KAN symbolic distillation methodology and the use of SHAP for feature importance
- **Low:** Transferability of SHAP rankings to symbolic regression architecture and generalization to reservoirs outside the Red River Basin

## Next Checks

1. Test model performance when excluding reservoirs with <5 profiles to assess whether high R² values for sparse datasets are artifacts
2. Conduct ablation studies on the 7-day average window by comparing against 3-day and 14-day alternatives
3. Implement leave-one-reservoir-out cross-validation to evaluate true geographic generalization capability