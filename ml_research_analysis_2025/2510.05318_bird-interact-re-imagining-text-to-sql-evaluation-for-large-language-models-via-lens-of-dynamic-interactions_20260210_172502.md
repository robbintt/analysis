---
ver: rpa2
title: 'BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models
  via Lens of Dynamic Interactions'
arxiv_id: '2510.05318'
source_url: https://arxiv.org/abs/2510.05318
tags:
- user
- text-to-sql
- ambiguity
- evaluation
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces BIRD-INTERACT, a benchmark designed to evaluate
  large language models on dynamic, multi-turn text-to-SQL tasks. The key innovation
  is a function-driven user simulator that enables controlled interactions without
  human supervision, coupled with two evaluation settings: protocol-guided (c-Interact)
  and open-ended agentic (a-Interact) modes.'
---

# BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language Models via Lens of Dynamic Interactions

## Quick Facts
- arXiv ID: 2510.05318
- Source URL: https://arxiv.org/abs/2510.05318
- Reference count: 40
- Key outcome: GPT-5 achieves only 8.67% success rate in c-Interact and 17.00% in a-Interact settings, revealing LLMs struggle with interactive database querying.

## Executive Summary
This paper introduces BIRD-INTERACT, a benchmark designed to evaluate large language models on dynamic, multi-turn text-to-SQL tasks. The key innovation is a function-driven user simulator that enables controlled interactions without human supervision, coupled with two evaluation settings: protocol-guided (c-Interact) and open-ended agentic (a-Interact) modes. The benchmark features 900 challenging tasks with injected ambiguities, dynamic knowledge bases, and executable test cases covering the full CRUD spectrum. Empirical results show state-of-the-art models struggle significantly, with GPT-5 achieving only 8.67% success rate in c-Interact and 17.00% in a-Interact settings. The study reveals that effective communication and strategic interaction patterns are critical for success, with performance improving monotonically as interaction opportunities increase.

## Method Summary
BIRD-INTERACT uses a two-stage function-driven user simulator to evaluate LLMs on interactive text-to-SQL tasks. The simulator parses ambiguous queries and responds with constrained actions (AMB for ambiguities, LOC for localizable information, UNA for unanswerable questions) without leaking ground-truth SQL. Evaluation occurs in two modes: c-Interact (protocol-guided with structured conversation) and a-Interact (autonomous agent with budget constraints). Tasks include follow-up sub-queries requiring database state awareness, hierarchical knowledge bases for external information retrieval, and executable test cases for validation. The benchmark features 900 tasks with injected ambiguities and dynamic databases.

## Key Results
- GPT-5 achieves only 8.67% success rate in c-Interact setting and 17.00% in a-Interact setting
- Performance improves monotonically with additional interaction turns (ITS scaling)
- Communication strategy bottleneck identified: GPT-5 improves significantly when given better interaction histories from other models
- Current models show varied action strategies: O3-Mini over-submits (55% actions without exploration), Qwen-3-Coder over-executes (48% budget on execute)

## Why This Works (Mechanism)

### Mechanism 1: Two-Stage Function-Driven User Simulator
Separating question classification from response generation prevents ground-truth leakage while maintaining realistic interactions. Stage 1 maps clarification requests into three constrained actions (AMB, LOC, UNA). Stage 2 generates responses based only on the classified action and relevant SQL snippet—not the full ground-truth query.

### Mechanism 2: Interaction Test-Time Scaling (ITS)
Task success increases monotonically with additional interaction turns, allowing models to iteratively resolve ambiguities. Budget-constrained evaluation allocates clarification turns proportional to annotated ambiguities, with models strategically asking questions to progressively narrow the problem space.

### Mechanism 3: Memory Grafting Reveals Communication-Over-Reasoning Bottlenecks
GPT-5's poor c-Interact performance stems from deficient communication strategy, not SQL generation capability. When provided with ambiguity-resolution histories from better-performing models before generating SQL, GPT-5's performance improves significantly, indicating separable communication and generation skills.

## Foundational Learning

- **Concept: Multi-turn Dialogue with State Dependency**
  - Why needed here: Tasks include follow-up sub-tasks that depend on database state modified by preceding queries (e.g., querying a view created in turn 1). Static context approaches fail.
  - Quick check question: Given a task that creates a temporary table then queries it, would a model treating conversation as static context succeed?

- **Concept: Hierarchical Knowledge Bases (HKB) with DAG Structure**
  - Why needed here: External knowledge is organized as nodes in a directed acyclic graph; "knowledge chain breaking" requires multi-hop reasoning to identify missing intermediate nodes.
  - Quick check question: If knowledge node C depends on B which depends on A, and B is masked, can the system identify which clarification to request?

- **Concept: Budget-Constrained Agent Evaluation**
  - Why needed here: Both c-Interact and a-Interact limit total actions (clarifications, executions, knowledge retrievals) with different costs, forcing strategic resource allocation.
  - Quick check question: With budget=10, is it better to execute 10 candidate SQLs or ask 5 clarifications then execute 2 refined SQLs?

## Architecture Onboarding

- **Component map:** User Simulator -> Database Environment -> Evaluator -> Orchestrator
- **Critical path:** System receives ambiguous query + metadata → explores environment or asks clarification → generates SQL → user simulator validates → receives feedback → repeat until success or budget exhaustion → follow-up sub-task released after priority success
- **Design tradeoffs:** c-Interact vs. a-Interact (structured protocol vs. autonomous planning); Lite vs. Full (300 vs. 600 tasks); reference-based disambiguation (controlled vs. realistic)
- **Failure signatures:** Premature submission (O3-Mini: 55% actions without exploration), execution over-exploration (Qwen-3-Coder: 48% budget on execute), communication bottlenecks (>80% errors from incomplete ambiguity resolution)
- **First 3 experiments:** 1) Baseline calibration: Run GPT-4o on BIRD-INTERACT-LITE with default patience=3; 2) Ablation on user simulator robustness: Compare function-driven vs. baseline simulator on UserSim-Guard subset; 3) ITS scaling test: Vary patience parameter on Claude-Sonnet-3.7 and plot success rate vs. turns

## Open Questions the Paper Calls Out
None

## Limitations
- Function-driven simulator relies on ground-truth SQL and annotated ambiguities, trading realism for controlled evaluation
- Performance gap between c-Interact (8.67% GPT-5 SR) and a-Interact (17.00% GPT-5 SR) suggests protocol-guided setting may be overly restrictive
- Benchmark complexity (900 tasks across two settings) may create evaluation artifacts not reflecting real-world deployment

## Confidence

**High Confidence:** Current LLMs struggle with interactive text-to-SQL tasks (well-supported by systematic evaluation across multiple state-of-the-art models); monotonic scaling behavior is empirically validated.

**Medium Confidence:** Communication bottleneck vs. SQL generation capability identification through memory grafting is methodologically sound but based on limited model comparisons.

**Low Confidence:** Generalizability of function-driven simulator to truly open-ended interactions without ground-truth references; benchmark complexity may create evaluation artifacts.

## Next Checks

1. **Simulator Guardrail Robustness:** Run function-driven simulator on held-out validation set to measure UNA rejection accuracy and detect ground-truth leakage patterns. Target: <10% UNA misclassification rate and zero detectable ground-truth content in responses.

2. **Interaction Scaling Saturation Point:** Systematically vary patience parameter (0, 2, 4, 6, 8 turns) on Claude-Sonnet-3.7 across both c-Interact and a-Interact modes. Plot success rate curves to identify whether monotonic scaling plateaus and at what interaction depth.

3. **Communication vs. Generation Isolation:** Conduct ablation studies where models are provided with synthetic interaction histories (random vs. task-relevant vs. ground-truth optimal) to determine whether observed performance improvements from memory grafting are due to information gain or specific interaction patterns.