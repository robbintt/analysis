---
ver: rpa2
title: 'Remembering Unequally: Global and Disciplinary Bias in LLM-Generated Co-Authorship
  Networks'
arxiv_id: '2511.00476'
source_url: https://arxiv.org/abs/2511.00476
tags:
- author
- memorization
- llms
- co-authors
- google
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study examines memorization biases in large language models\
  \ (LLMs) when generating co-authorship networks. Using three models\u2014DeepSeek\
  \ R1, Llama 4 Scout, and Mixtral 8x7B\u2014the authors compare LLM outputs to OpenAlex\
  \ and Google Scholar data for 1,596 authors across 10 disciplines and 8 regions."
---

# Remembering Unequally: Global and Disciplinary Bias in LLM-Generated Co-Authorship Networks

## Quick Facts
- **arXiv ID:** 2511.00476
- **Source URL:** https://arxiv.org/abs/2511.00476
- **Reference count:** 36
- **Key outcome:** LLM-generated co-authorship networks show significantly higher Discoverable Network Extraction (DNE) scores for highly cited authors, indicating stronger memorization of well-cited researchers' networks, though exceptions exist in Clinical Medicine and certain African regions.

## Executive Summary
This study investigates memorization biases in large language models when generating co-authorship networks by comparing LLM outputs to OpenAlex and Google Scholar data. Using three models (DeepSeek R1, Llama 4 Scout, Mixtral 8x7B) across 1,596 authors in 10 disciplines and 8 regions, the authors find that highly cited researchers are significantly better represented in LLM-generated networks. While overall memorization bias favors well-cited researchers, notable exceptions include equitable representation in Clinical Medicine and reduced bias in certain African regions (Sub-Saharan Africa, North Africa). Larger models generally show higher DNE scores, though results vary by discipline and region.

## Method Summary
The study employs a quantitative approach comparing LLM-generated co-authorship networks to established scholarly databases. Authors used three LLM models (DeepSeek R1, Llama 4 Scout, Mixtral 8x7B) with 1,596 seed authors across 10 disciplines and 8 regions. The Discoverable Network Extraction (DNE) metric quantifies how well LLMs memorize co-authorship networks by measuring the ratio of correctly identified co-authors to total possible co-authors. The study analyzes memorization patterns across citation tiers, disciplines, and geographic regions, comparing results to OpenAlex and Google Scholar as ground truth sources.

## Key Results
- LLM-generated co-authorship networks show significantly higher DNE scores for highly cited authors (p < 0.05), indicating stronger memorization of well-cited researchers' networks
- Clinical Medicine demonstrates more equitable DNE representation across citation tiers, unlike other disciplines
- Sub-Saharan Africa and North Africa show reduced memorization bias compared to other regions, though this may reflect lower performance rather than reduced bias

## Why This Works (Mechanism)
None

## Foundational Learning
- **Discoverable Network Extraction (DNE) metric:** A quantitative measure of how well LLMs memorize co-authorship networks by comparing generated networks to ground truth data
  - *Why needed:* Provides objective, comparable measure of memorization quality across different models, disciplines, and regions
  - *Quick check:* DNE scores range from 0 (no co-authors discovered) to 1 (all co-authors discovered), enabling standardized comparison

- **Citation-based ground truth validation:** Using OpenAlex and Google Scholar as reference datasets to evaluate LLM outputs
  - *Why needed:* Establishes benchmark for measuring memorization accuracy and identifying representational biases
  - *Quick check:* Assumes highly cited authors represent influential researchers whose networks should be better memorized

- **Cross-regional and cross-disciplinary analysis:** Examining memorization patterns across geographic regions and academic fields
  - *Why needed:* Reveals systematic biases in how LLMs encode scholarly knowledge from different global contexts
  - *Quick check:* Identifies whether certain regions or disciplines are systematically underrepresented in LLM training data

## Architecture Onboarding

**Component Map:**
Seed Author -> LLM Model -> Generated Co-authorship Network -> DNE Calculation -> Ground Truth Comparison

**Critical Path:**
1. Seed author selection across citation tiers, disciplines, and regions
2. LLM generation of co-authorship networks for each seed author
3. DNE score calculation comparing generated networks to OpenAlex/Google Scholar
4. Statistical analysis of DNE patterns across citation, discipline, and region dimensions

**Design Tradeoffs:**
- Ground truth choice: OpenAlex vs Google Scholar may introduce different bias patterns
- Sample size: 1,596 authors provides breadth but may lack depth for nuanced analysis
- Single snapshot: Cross-sectional analysis misses temporal dynamics of LLM training

**Failure Signatures:**
- High DNE scores in regions with limited scholarly infrastructure may indicate poor model performance rather than reduced bias
- Inconsistent DNE patterns across models suggest dataset-specific rather than systematic biases
- Absence of gender analysis misses potential intersectional biases in memorization patterns

**3 First Experiments:**
1. Test DNE metric reliability by manual verification of generated networks for sample authors
2. Compare DNE scores using alternative ground truth sources (ethnographic data, manually curated networks)
3. Analyze temporal patterns by testing LLMs trained on different time periods

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does the gender of seed authors and their co-authors influence memorization patterns in LLM-generated co-authorship networks?
- Basis in paper: [explicit] Authors state in Section 5.4: "the influence of other important factors, such as the gender of authors and co-authors, underexplored."
- Why unresolved: This study focused on citation counts, disciplines, and regions but did not control for or analyze gender as a variable.
- What evidence would resolve it: A replication study incorporating gender annotations for both seed authors and co-authors, comparing DNE scores across gender categories.

### Open Question 2
- Question: Would alternative benchmarks (ethnographic insights, manually curated datasets) yield different conclusions about memorization bias compared to OpenAlex and Google Scholar?
- Basis in paper: [explicit] Section 5.4 states: "Exploring alternative benchmarks, such as ethnographic insights or manually curated datasets, could provide a more nuanced evaluation."
- Why unresolved: Both OpenAlex and Google Scholar may contain their own biases in citation metrics and indexing coverage.
- What evidence would resolve it: Comparison of DNE scores using alternative ground-truth sources with known provenance and bias documentation.

### Open Question 3
- Question: What specific factors explain why Clinical Medicine and certain African regions show more equitable DNE representation?
- Basis in paper: [inferred] The authors document these exceptions but acknowledge uncertainty: "pointing to areas where LLM training data may reflect greater equity" without identifying causal mechanisms.
- Why unresolved: Multiple potential explanations exist (publication practices, network density, training data composition) without empirical testing.
- What evidence would resolve it: Controlled experiments varying training data composition and analysis of field-specific publication characteristics.

### Open Question 4
- Question: Can systematic benchmark datasets be developed to measure and mitigate representational biases in scientometric LLM tools?
- Basis in paper: [explicit] Section 5.4: "future work could develop benchmark comparison datasets to systematically measure and mitigate these biases in downstream tools."
- Why unresolved: No standardized framework currently exists for evaluating fairness in LLM-based scholarly network generation.
- What evidence would resolve it: Creation and validation of a benchmark suite with diverse author representations and documented bias metrics.

## Limitations
- Small sample size of 1,596 authors across limited disciplines and regions may not represent global research patterns
- Reliance on citation-based ground truth assumes highly cited authors are most influential, potentially missing other forms of scholarly impact
- DNE metric requires further validation as proxy for memorization quality, particularly given that higher DNE scores in some regions indicate worse performance

## Confidence
- **High confidence:** Overall finding of memorization bias favoring highly cited authors
- **Medium confidence:** Observed disciplinary and regional variations in memorization patterns
- **Low confidence:** Precise quantification of bias differences between specific regions

## Next Checks
1. Replicate the study with a larger, more diverse author sample spanning additional disciplines and geographic regions to assess generalizability
2. Validate the DNE metric against alternative measures of memorization quality, including manual verification of generated networks
3. Conduct longitudinal analysis to track how co-authorship network memorization changes across different LLM training periods and updates