---
ver: rpa2
title: A pipeline for enabling path-specific causal fairness in observational health
  data
arxiv_id: '2601.09841'
source_url: https://arxiv.org/abs/2601.09841
tags:
- fairness
- causal
- path-specific
- data
- effect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a generalizable pipeline for training causally
  fair machine learning models using observational health data. The pipeline maps
  the structural fairness model to observational health settings and identifies causal
  paths for fairness interventions.
---

# A pipeline for enabling path-specific causal fairness in observational health data

## Quick Facts
- arXiv ID: 2601.09841
- Source URL: https://arxiv.org/abs/2601.09841
- Reference count: 40
- Key outcome: Introduces pipeline for causally fair ML models using observational health data, demonstrating that dimensionality reduction and naive feature selection can effectively reduce path-specific bias while preserving predictive accuracy.

## Executive Summary
This work presents a pipeline for training causally fair machine learning models using observational health data by decomposing bias into natural direct effect (NDE), natural indirect effect (NIE), and spurious effect (SE). The authors map the Standard Fairness Model to observational health settings and demonstrate that outcome-driven feature selection significantly improves path-specific effect estimation in high-dimensional data. Applied to four clinical prediction tasks, the results show that no single fairness intervention universally outperforms others, with naive feature selection methods sometimes matching or exceeding the performance of complex causal regularization strategies.

## Method Summary
The pipeline consists of mapping EHR data to the Standard Fairness Model (X=sensitive attribute, Y=outcome, W=clinical features, Z=confounders), applying dimensionality reduction via permutation feature importance to select top 20% of W by outcome importance, estimating path-specific effects using doubly robust estimators, and applying fairness interventions including causal regularization, naive feature selection, and fair resampling. The approach is validated on four clinical prediction tasks using large-scale observational health data from CUMC-EHR and Medicaid databases, with model performance evaluated using AUROC and fairness assessed through NDE/NIE/SE estimates.

## Key Results
- Doubly robust estimation alone leads to large measurement errors in high dimensions; outcome-driven feature selection significantly reduces this error
- Standard ML models without fairness constraints tend to amplify NDE relative to the bias present in raw data
- Naive feature selection approaches (removing features with high distribution shift) can reduce path-specific effects as effectively as causal regularization when clinical features have high inter-dependency
- No single fairness intervention universally outperforms others; optimal approach depends on specific clinical context and disease

## Why This Works (Mechanism)

### Mechanism 1
If the mediator set (W) is high-dimensional, doubly robust estimators for path-specific effects (NDE/NIE) suffer significant estimation error; outcome-driven feature selection reduces this error. In high-dimensional settings, estimation becomes unstable, but selecting features that maximize predictive power for the outcome preserves the signal required for the outcome model component of the doubly robust estimator, stabilizing the causal effect estimate. Break condition: If the chosen dimensionality reduction method removes features critical to the causal mechanism, effect estimates may become biased.

### Mechanism 2
Training ML models on observational health data without fairness constraints tends to exacerbate the Natural Direct Effect (NDE) relative to the bias present in the raw data. Standard loss minimization exploits all statistical correlations between the sensitive attribute and outcome, amplifying direct correlations that often reflect historical inequities to improve predictive accuracy. Break condition: If fairness constraint is too weak, the model defaults to amplifying the direct path; if too strong, it may destroy useful signal.

### Mechanism 3
Naive feature selection methods (removing features with high distribution shift between sensitive groups) can reduce path-specific effects as effectively as complex causal regularization, provided remaining features retain predictive redundancy. Features with high Standardized Mean Difference between groups often encode unfair causal paths, and because clinical features in EHRs are highly correlated, the model can recover predictive accuracy from other fairer features. Break condition: If the biased feature is the only causal mechanism for the outcome, removing it destroys model utility.

## Foundational Learning

- **Concept: Structural Causal Models (SCM) & Standard Fairness Model (SFM)**
  - Why needed here: The pipeline relies on mapping high-dimensional EHR data into a specific causal structure (X, Y, Z, W) to ensure path-specific effects are identifiable from observational data.
  - Quick check question: Can you distinguish between a "Mediator" (W) and a "Confounder" (Z) in the context of a specific disease prediction task?

- **Concept: Path-Specific Effects (NDE vs NIE vs SE)**
  - Why needed here: The paper decomposes "bias" into three distinct causal pathways, required to select which target effect to prioritize for mitigation.
  - Quick check question: If a model predicts lower risk for a group solely because they have less access to healthcare, which causal effect primarily captures this disparity?

- **Concept: Doubly Robust Estimation**
  - Why needed here: This is the statistical engine used to estimate NDE/NIE from finite samples, explaining why dimensionality reduction is necessary.
  - Quick check question: Why might a "doubly robust" estimator still fail in high-dimensional settings (|W| > 1000)?

## Architecture Onboarding

- **Component map:** Raw EHR/Tabular Data -> Mapper (defines X, Y, Z, W) -> Estimator (Dimensionality Reduction + Doubly Robust Estimator) -> Trainer (Baseline Model) -> Intervener (Fairness Interventions) -> Evaluator (AUROC vs Path-Specific Effects)
- **Critical path:** The Estimator is the bottleneck. If Dimensionality Reduction fails to select outcome-predictive features, causal effects will have massive confidence intervals, making the fairness diagnosis meaningless.
- **Design tradeoffs:** NDE vs NIE interventions often improve one effect at the cost of the other; Causal regularization is theoretically sounder but computationally heavier while naive selection is cheap and surprisingly effective; the optimal intervention is task-dependent.
- **Failure signatures:** Explosive CI (wide confidence intervals > ±0.1 indicates estimation step failure); Amplification (baseline model shows NDE/NIE 10× larger than data effect); Performance Collapse (AUROC drops to 0.5 indicates fairness constraints were too aggressive).
- **First 3 experiments:** 1) Validate estimator on synthetic data with known ground truth; 2) Train baseline predictor and compare NDE/NIE in data vs model outputs; 3) Apply greedy feature selection and causally fair resampling to baseline, plotting AUROC vs Target Effect Pareto frontier.

## Open Questions the Paper Calls Out

- Can path-specific causal fairness be extended to handle intersectional fairness across multiple sensitive attributes in observational health settings? The current pipeline only handles binary sensitive attributes and would require larger datasets with more diverse populations for intersectional analysis.

- Why do naive feature selection approaches achieve comparable or superior causal fairness to purpose-designed causal regularization methods in observational health data? The authors observe this empirically but don't establish the theoretical or data-structural mechanisms explaining this phenomenon.

- How can path-specific causal effects be robustly estimated for non-binary categorical sensitive attributes? The current doubly robust estimation framework is designed for binary sensitive attributes, requiring new estimators for multi-category attributes.

- Can high-dimensional propensity score methods improve path-specific effect estimation when the confounder set Z is high-dimensional? The current dimensionality reduction experiments focus on W, but when Z is also high-dimensional, estimation error may increase and require different methodological approaches.

## Limitations

- Estimation complexity in high dimensions: Doubly robust estimators become unreliable when |W| > 750, though the exact failure conditions remain unclear.
- Feature mapping assumptions: Mapping clinical data to the Standard Fairness Model is inherently subjective and domain-dependent with no systematic framework for edge cases.
- Computational feasibility: Scaling to full EHR datasets with millions of patients and thousands of features may face computational constraints not addressed in the paper.

## Confidence

- Estimation Complexity in High Dimensions (Medium)
- Feature Mapping Assumptions (Low)
- Computational Feasibility (Medium)

## Next Checks

1. **Synthetic Data Validation**: Validate the entire pipeline on synthetic data with known ground truth effects across varying dimensionalities (|W| = 100, 500, 1000, 1500) to establish error bounds for different sample sizes.

2. **Cross-Domain Generalization**: Test the feature selection approach on a completely different clinical domain (e.g., oncology vs. cardiovascular) to assess whether the 20% PFI threshold is universally applicable or domain-specific.

3. **Bootstrap Stability Analysis**: Perform a systematic study of how bootstrap sample size affects confidence interval stability for path-specific effect estimates, particularly when working with smaller datasets typical of rare disease prediction tasks.