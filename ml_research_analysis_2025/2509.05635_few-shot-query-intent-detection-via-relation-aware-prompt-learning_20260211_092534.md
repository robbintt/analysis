---
ver: rpa2
title: Few-Shot Query Intent Detection via Relation-Aware Prompt Learning
arxiv_id: '2509.05635'
source_url: https://arxiv.org/abs/2509.05635
tags:
- intent
- query
- said
- user
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SAID, a novel framework for few-shot query
  intent detection that integrates both textual and relational structure information.
  The key innovation is the use of relation-aware prompt learning, where learnable
  relation tokens are employed as soft prompts to capture the semantic relevance between
  queries (query-query relation) and between queries and answers (query-answer relation).
---

# Few-Shot Query Intent Detection via Relation-Aware Prompt Learning

## Quick Facts
- **arXiv ID:** 2509.05635
- **Source URL:** https://arxiv.org/abs/2509.05635
- **Authors:** Liang Zhang; Yuan Li; Shijie Zhang; Zheng Zhang; Xitong Li
- **Reference count:** 40
- **Primary result:** Achieved up to 27% improvement in 3-shot query intent detection by integrating relational structure information through soft prompts

## Executive Summary
This paper introduces SAID, a framework for few-shot query intent detection that integrates both textual and relational structure information. The key innovation is using relation-aware prompt learning with learnable relation tokens as soft prompts to capture semantic relevance between queries and between queries and answers. The model is pretrained using structure-aware masked language modeling and fine-tuned with prompt-based task reformulation for intent detection. An enhanced variant, SAID (+QueryAdapt), explicitly transfers relational knowledge by generating intent-specific relation tokens through a query-adaptive attention network.

## Method Summary
The framework integrates relational structure (query-query and query-answer relations) into pretraining through learnable soft prompts. During pretraining, relation tokens are positioned between text segments to create relation-aware prompts, and the PLM is trained using structure-aware masked language modeling. For fine-tuning, intent detection is reformulated as a query-intent relation matching task using prompt learning. The enhanced QueryAdapt variant generates intent-specific relation tokens from pretrained Q-Q and Q-A tokens using query-dependent attention weights, allowing different queries to leverage pretrained relations adaptively.

## Key Results
- SAID significantly outperforms state-of-the-art methods, achieving up to 27% improvement in the 3-shot setting
- SAID (+QueryAdapt) yields additional performance gains of up to 21% in the same setting
- The framework demonstrates consistent effectiveness across various backbone models (BERT, DistilBERT, ALBERT)
- Ablation studies show both relation types (Q-Q and Q-A) and the prompt-based fine-tuning approach contribute independently to performance gains

## Why This Works (Mechanism)

### Mechanism 1: Structure-aware Pretraining via Relation-aware Soft Prompts
The framework integrates relational structure (query-query and query-answer relations) into pretraining through learnable soft prompts. Relation tokens are positioned between text segments to create relation-aware prompts, and the PLM is trained using structure-aware masked language modeling. This learns shared knowledge across relations and how to interpret query text within relational contexts.

Core assumption: Conversational structures provide semantic signals that transfer to intent understanding.

Break condition: Performance degrades if conversational datasets lack meaningful multi-turn structure or if query-answer pairs are noisy/irrelevant.

### Mechanism 2: Prompt-based Task Reformulation for Knowledge Transfer
During fine-tuning, intent detection is reformulated as a query-intent relation matching task using prompt learning. This treats intent classification as interpreting a query through the "lens" of intent relation, which is semantically related to the pretrained Q-Q and Q-A relations.

Core assumption: The query-intent relation shares semantic proximity with query-query and query-answer relations learned during pretraining.

Break condition: Fails if intent names are semantically distant from pretrained relations, or if the downstream task has fundamentally different relational structure.

### Mechanism 3: QueryAdapt for Fine-grained Explicit Knowledge Transfer
QueryAdapt computes intent-specific relation tokens as weighted combinations: z_qi = λ_qq · z_qq + λ_qa · z_qa, where weights are query-dependent. This allows different queries to leverage pretrained relations adaptively—for example, longer, noisier queries benefit more from Q-Q relations, while others rely more on Q-A relations.

Core assumption: Different queries benefit differentially from Q-Q vs. Q-A relations based on their characteristics.

Break condition: Degrades if the attention network overfits to limited few-shot examples, or if query characteristics don't systematically correlate with relational information needs.

## Foundational Learning

- **Soft Prompt Learning**
  - Why needed here: Uses learnable continuous embeddings (relation tokens) rather than discrete text prompts, enabling flexible integration of structural information that hard prompts cannot easily encode.
  - Quick check question: Can you explain why soft prompts (learnable embeddings) are more suitable than hard prompts (discrete text tokens) for encoding relational structure in this context?

- **Masked Language Modeling (MLM) for Pretraining**
  - Why needed here: The structure-aware pretraining extends standard MLM by using relation-aware prompts as input. Understanding standard MLM is prerequisite to grasping how the framework incorporates relational context into the pretraining objective.
  - Quick check question: How does the structure-aware MLM loss (Equation 2) differ from standard BERT MLM, and what role do the relation-aware prompts play in the input?

- **Few-shot Learning Paradigm**
  - Why needed here: The entire framework is designed for scenarios with only K=3-20 labeled examples per intent class. Understanding few-shot challenges motivates the pretraining-then-fine-tuning approach and prompt-based task reformulation.
  - Quick check question: Why does few-shot learning require pretraining on large unlabeled conversational data, and how does the prompt-based approach address the limited-label constraint?

## Architecture Onboarding

- **Component map:**
  Pretraining Stage: Unlabeled dialogue corpus → Relation-aware prompt construction (Q-Q, Q-A) → Structure-aware MLM pretraining → Pretrained PLM with relation tokens
  Fine-tuning Stage (SAID): Few-shot labeled data → Intent-specific prompt construction (Q-Intent) → Prompt-based classification → Intent prediction
  Enhanced Fine-tuning (SAID + QueryAdapt): QueryAdapt attention network → Generate z_qi from z_qq and z_qa → Intent-specific prompt with generated tokens → Intent prediction

- **Critical path:**
  1. Data preprocessing: Filter sessions with <3 interactions, construct Q-Q pairs (within-session queries) and Q-A pairs (query-response)
  2. Pretraining: Initialize relation tokens (m=3 per relation type), train for 4 epochs with MLM loss (masking ratio 0.25), Adam optimizer (lr=3e-5)
  3. Fine-tuning: Initialize intent-specific relation tokens, hyperparameter search over learning rates {1e-5, 4e-5, 1e-4}, early stopping to prevent overfitting
  4. Inference: Construct intent-specific prompts for each candidate intent, compute probability distribution via softmax over PLM outputs

- **Design tradeoffs:**
  - Relation token count (m): Paper uses m=3; more tokens may capture richer relational semantics but increase overfitting risk in few-shot scenarios
  - Pretraining epochs: 4 epochs chosen; more epochs improve performance but increase computational cost
  - Masking ratio: 0.25 optimal (vs. 0.15 for standard BERT); higher ratio needed due to additional relation context making pretraining "easier"
  - Backbone choice: BERT-base balances effectiveness/efficiency; DistilBERT and ALBERT offer speed/parameter reductions but may sacrifice some performance

- **Failure signatures:**
  - Overfitting to few-shot examples: Validation accuracy plateaus or degrades during fine-tuning; mitigated by early stopping and learning rate tuning
  - Pretrained relations irrelevant to downstream task: Ablation shows removing Q-Q or Q-A relations degrades performance, indicating both are necessary
  - QueryAdapt attention collapse: If λ_qq and λ_qa converge to uniform weights regardless of query, the adaptive mechanism isn't learning; check attention distribution variance

- **First 3 experiments:**
  1. Baseline comparison: Implement BERT baseline (no pretraining, standard classification head) vs. SAID on IntentChat/WildChat across 3/5/10/20-shot settings to validate 20-27% accuracy improvements
  2. Ablation study: Remove structure-aware pretraining (w/o PT), remove relational prompts (w/o REL), remove Q-A or Q-Q relations individually (w/o Q-A, w/o Q-Q), remove prompt-based fine-tuning (w/o PLFT) to isolate component contributions
  3. QueryAdapt analysis: Compare SAID (+QueryAdapt) vs. SAID (+Linear) vs. SAID (+MLP) to validate that query-adaptive attention outperforms fixed weights or generic MLP approaches; visualize attention weight distributions for QQ-dominated vs. QA-dominated queries

## Open Questions the Paper Calls Out
None

## Limitations
- Framework's effectiveness is bounded by the availability of rich relational structure in the pretraining corpus; may not work well for single-turn interactions
- QueryAdapt mechanism's contribution is less rigorously validated; attention weight distributions across diverse query types lack comprehensive analysis
- Pretraining stage's computational requirements scale with model size and corpus volume, potentially limiting practical deployment for resource-constrained applications

## Confidence

**High Confidence (9/10):** Core mechanism of integrating relational structure through soft prompts is well-supported by experimental results showing 20-27% accuracy improvements over baselines.

**Medium Confidence (7/10):** QueryAdapt mechanism's contribution (up to 21% additional gains) is promising but less rigorously validated; attention mechanism's robustness to noisy or ambiguous queries remains underexplored.

**Low Confidence (5/10):** Framework's generalizability to non-conversational domains and behavior under extreme few-shot conditions (K=1-2) are not thoroughly examined; potential negative transfer scenarios are unexplored.

## Next Checks

1. **Structural Dependency Analysis:** Conduct experiments on datasets with varying conversational depth to quantify the minimum structural complexity required for performance gains. Measure how accuracy degrades as conversational structure is progressively removed from the pretraining corpus.

2. **Attention Mechanism Robustness:** Implement stress tests for the QueryAdapt mechanism by injecting synthetic noise into queries and measuring attention weight stability. Compare QueryAdapt's performance against simpler baselines across queries with systematically varied characteristics.

3. **Cross-Domain Transfer Evaluation:** Pretrain the framework on conversational data from one domain and fine-tune on intent detection tasks from structurally dissimilar domains. Measure performance degradation and identify which relational patterns transfer versus those that require domain-specific adaptation.