---
ver: rpa2
title: 'BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation'
arxiv_id: '2508.06781'
source_url: https://arxiv.org/abs/2508.06781
tags:
- relevance
- bixse
- retrieval
- training
- graded
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of training dense retrieval models
  using binary relevance labels, which can be limiting as real-world relevance exists
  on a continuum. The authors propose BiXSE, a simple and effective pointwise training
  method that optimizes binary cross-entropy (BCE) loss over LLM-generated graded
  relevance scores, interpreting them as probabilistic targets.
---

# BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation

## Quick Facts
- arXiv ID: 2508.06781
- Source URL: https://arxiv.org/abs/2508.06781
- Reference count: 39
- The paper proposes BiXSE, a pointwise training method using BCE loss over LLM-generated graded relevance scores, which consistently outperforms InfoNCE and matches strong pairwise baselines across retrieval benchmarks.

## Executive Summary
The paper addresses the challenge of training dense retrieval models using binary relevance labels, which can be limiting as real-world relevance exists on a continuum. The authors propose BiXSE, a simple and effective pointwise training method that optimizes binary cross-entropy (BCE) loss over LLM-generated graded relevance scores, interpreting them as probabilistic targets. Extensive experiments across retrieval and sentence embedding benchmarks show that BiXSE consistently outperforms standard contrastive learning methods like InfoNCE, matches or exceeds strong pairwise ranking baselines, and demonstrates improved robustness to label noise. BiXSE offers a practical and scalable solution for training dense retrieval models as graded relevance supervision becomes increasingly accessible.

## Method Summary
BiXSE is a pointwise training method for dense retrieval that optimizes binary cross-entropy (BCE) loss over LLM-generated graded relevance scores. Instead of treating relevance as binary (0/1), BiXSE uses continuous scores z_i ∈ [0,1] as probabilistic targets, where the model learns to predict a relevance probability via sigmoid(α·q^T·d + β). The method includes a learnable logit bias β to correct label imbalance from in-batch negatives, trained with a higher learning rate than the encoder. BiXSE demonstrates improved robustness to label noise compared to InfoNCE through distributed gradient signals across all negative pairs.

## Key Results
- BiXSE outperforms InfoNCE and matches or exceeds strong pairwise ranking baselines across BEIR, MTEB, and TREC-DL benchmarks
- The method shows improved robustness to label noise, degrading more gracefully than InfoNCE as noise increases
- BiXSE achieves peak performance at moderate relevance cutoffs (~0.7), demonstrating effective learning from broader relevance signals compared to strict binary filtering

## Why This Works (Mechanism)

### Mechanism 1: Probabilistic Target Interpretation of Graded Relevance
BiXSE interprets continuous graded relevance scores as probabilistic targets in BCE loss, capturing fine-grained relevance more faithfully than one-hot contrastive objectives. The sigmoid calibration maps scores to meaningful probabilities, allowing the model to learn partial relevance signals. This mechanism assumes graded relevance scores correlate with true utility on a continuum. Break condition: If LLM-graded scores are systematically miscalibrated, probabilistic targets may mislead training without proper calibration.

### Mechanism 2: Logit Bias for Label Imbalance Correction
A learnable logit bias β counteracts the strong negative-label imbalance introduced by in-batch negatives. With batch size B, each query sees 1 labeled pair and B-1 in-batch negatives treated as zeros. The bias β models the marginal label distribution, absorbing this skew so the encoder focuses on conditional query-document relevance. Break condition: If label distribution varies significantly across queries or tasks, a global β may undercorrect or overcorrect imbalance for specific batches.

### Mechanism 3: Distributed Gradient Signal for Noise Robustness
BCE's pointwise formulation provides more robust gradients under label noise than softmax-based contrastive losses. BCE averages B² binary predictions per batch; InfoNCE averages B multi-class predictions. A single mislabeled pair affects 1/B² predictions in BCE vs. 1/B in InfoNCE, diluting noise impact. Break condition: If noise is systematic (e.g., all hard negatives are mislabeled), gradient dilution cannot correct structural bias.

## Foundational Learning

- **Dense Retrieval and Sentence Embeddings:**
  - Why needed: BiXSE trains bi-encoders that map queries and documents to shared embedding space; understanding L2-normalized embeddings and dot-product similarity is prerequisite.
  - Quick check: Can you explain why cosine similarity ≡ dot product for L2-normalized vectors?

- **Contrastive Learning (InfoNCE):**
  - Why needed: The paper positions BiXSE as an alternative to InfoNCE; understanding softmax-based contrastive loss clarifies what BiXSE replaces.
  - Quick check: In InfoNCE, what role do in-batch negatives play in the denominator?

- **Binary Cross-Entropy vs. Softmax Losses:**
  - Why needed: The core contribution is reformulating retrieval training as BCE over probabilistic targets.
  - Quick check: For a target probability z=0.7 and model prediction σ(s)=0.6, does BCE penalize more or less than z=1.0?

- **Knowledge Distillation:**
  - Why needed: BiXSE distills LLM-generated graded scores into a dense encoder; understanding teacher-student setups contextualizes the approach.
  - Quick check: Why might soft labels from a teacher provide more signal than hard labels?

## Architecture Onboarding

- **Component map:** Input (q_i, d_i, z_i) → Encoder f → L2-normalized embeddings q_i, d_i → Scoring function s(q,d) = α·q^T·d + β → BCE loss over all query-document pairs in batch

- **Critical path:**
  1. Prepare LLM-labeled data with graded scores; convert ordinal outputs to continuous z via weighted averaging
  2. Implement task-conditioned sampling (all samples in batch from same task/domain)
  3. Train with high learning rate for β (≈10× encoder LR) and logit scale α ≈ 20
  4. Validate on subsampled BEIR subset for early stopping

- **Design tradeoffs:**
  - Batch size: BiXSE is less dependent on large batches than InfoNCE, but larger batches still help; memory scales O(B²) for score tensor
  - Hard negatives: BiXSE works with in-batch negatives alone; explicit hard negatives optional but not required
  - Annotation cost: Pointwise loss requires only one graded label per query vs. multiple comparisons for pairwise methods

- **Failure signatures:**
  - Performance plateaus below InfoNCE → Check if β is under-optimized (increase β learning rate)
  - Poor in-batch negative utilization → Verify task-conditioned batching; mixed-domain batches degrade negative quality
  - Model collapses to predicting low relevance → β may be absorbing signal; reduce β learning rate or inspect marginal distribution

- **First 3 experiments:**
  1. Reproduce ablation: Train BiXSE with and without logit bias β on a small dataset; expect ≥1-2% NDCG@10 drop without β
  2. Noise robustness test: Flip 10-30% of binary labels in E5 dataset; compare BiXSE vs. InfoNCE degradation curves
  3. Filtering sensitivity: Vary graded relevance cutoff (0.3-0.9) for positives; expect BiXSE to peak at moderate cutoff while InfoNCE improves monotonically

## Open Questions the Paper Calls Out

- What is the theoretical mechanism driving BiXSE's non-monotonic performance response to data filtering, unlike InfoNCE's monotonic improvement? The paper empirically observes this behavior but lacks theoretical explanation for why excessive filtering degrades performance.

- Does BiXSE generalize effectively to human-annotated graded relevance datasets, or is its robustness specific to LLM-generated label noise profiles? The training data relies exclusively on LLM-generated scores, raising questions about transfer to human-graded data.

- Does BiXSE maintain its efficiency advantage over pairwise losses when scaling encoder architectures significantly beyond the 3B parameter limit tested? The paper suggests BiXSE is suitable for next-generation systems, but scaling behavior remains unexplored.

## Limitations

- Generalization to real-world gradations remains untested beyond LLM-generated scores from a single source (LightBlue dataset with QWEN 2.5-32B)
- Scalability of the logit bias mechanism may break down in heterogeneous retrieval tasks with varying difficulty or domain-specific relevance patterns
- Noise robustness advantages may not extend to systematic noise (e.g., biased LLM judgments, adversarial label corruption)

## Confidence

- **High Confidence:** The core mechanism of using BCE loss with probabilistic targets for graded relevance distillation is well-specified and experimentally validated across multiple benchmarks
- **Medium Confidence:** Claims about matching or exceeding pairwise ranking baselines are supported by BEIR results but would benefit from direct comparison on additional IR metrics
- **Low Confidence:** Assertions about "consistent" outperformance across all settings require qualification, as optimal performance depends on data filtering strategy

## Next Checks

1. **Cross-Domain Generalization Test:** Evaluate BiXSE on a non-QA domain (e.g., legal retrieval from ECHR corpus or biomedical literature retrieval) with independently verified graded relevance annotations to assess robustness beyond the LightBlue dataset.

2. **Systematic Noise Vulnerability Analysis:** Design experiments with structured label noise (e.g., LLM bias toward certain document types, adversarial relevance flips) to determine whether BiXSE's gradient dilution mechanism fails under non-random corruption patterns.

3. **Bias Adaptation Evaluation:** Compare BiXSE with a variant using per-task logit bias (separate β for each domain/task) on heterogeneous retrieval benchmarks to quantify the impact of the global bias assumption on performance variance.