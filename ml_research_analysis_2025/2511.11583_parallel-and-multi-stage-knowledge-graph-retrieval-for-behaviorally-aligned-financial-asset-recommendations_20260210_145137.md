---
ver: rpa2
title: Parallel and Multi-Stage Knowledge Graph Retrieval for Behaviorally Aligned
  Financial Asset Recommendations
arxiv_id: '2511.11583'
source_url: https://arxiv.org/abs/2511.11583
tags:
- financial
- context
- retrieval
- user
- rag-flarko
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces RAG-FLARKO, a retrieval-augmented extension\
  \ of the FLARKO framework for behaviorally aligned financial asset recommendations.\
  \ The core innovation is a multi-stage, parallel KG retrieval pipeline that first\
  \ retrieves behaviorally relevant entities from a user\u2019s transaction KG, then\
  \ uses that context to filter temporally consistent signals from a market KG, constructing\
  \ compact, grounded subgraphs for the LLM."
---

# Parallel and Multi-Stage Knowledge Graph Retrieval for Behaviorally Aligned Financial Asset Recommendations

## Quick Facts
- arXiv ID: 2511.11583
- Source URL: https://arxiv.org/abs/2511.11583
- Reference count: 18
- One-line primary result: RAG-FLARKO enhances financially aligned recommendations by constructing compact, contextually relevant subgraphs through a multi-stage KG retrieval pipeline, particularly benefiting small models.

## Executive Summary
This paper introduces RAG-FLARKO, a retrieval-augmented extension of the FLARKO framework for behaviorally aligned financial asset recommendations. The core innovation is a multi-stage, parallel KG retrieval pipeline that first retrieves behaviorally relevant entities from a user’s transaction KG, then uses that context to filter temporally consistent signals from a market KG, constructing compact, grounded subgraphs for the LLM. This approach reduces context overhead and sharpens the model’s focus on relevant information. Empirical evaluation on the FAR-Trans dataset demonstrates that RAG-FLARKO significantly enhances recommendation quality, with the multi-stage pipeline especially benefiting smaller models like Qwen3-0.6B, improving their performance in profitability and behavioral alignment. Notably, RAG-FLARKO enables smaller, more efficient models to achieve high performance, presenting a viable path for deploying grounded financial AI in resource-constrained environments.

## Method Summary
The RAG-FLARKO framework extends FLARKO by introducing a three-stage inference pipeline for financial asset recommendation. It uses a Personal Transaction KG (PKG) and a Market KG (MKG) constructed from the FAR-Trans dataset. The pipeline consists of: (1) Personal Transaction Retrieval (PTR), where a small LLM selects relevant entities from PKG; (2) SPARQL CONSTRUCT queries that extract compact subgraphs based on the selected entities; (3) Market Retrieval (MR), where another LLM selects market entities conditioned on the PTR output; and (4) a final recommendation LLM that generates asset suggestions from the combined subgraphs. The approach optimizes for behavioral alignment and profitability using Hits@3 metrics.

## Key Results
- RAG-FLARKO significantly improves Comb@3 scores compared to baseline FLARKO models, especially for smaller models like Qwen3-0.6B.
- The multi-stage pipeline with inter-stage context propagation is crucial for resource-constrained models, enhancing both profitability and preference alignment.
- Aggregated market summaries (TenWeekPriceSummary) allow efficient context usage, providing more historical information than raw daily data within token limits.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inter-stage context propagation improves retrieval relevance for resource-constrained models.
- Mechanism: The pipeline passes the retrieved Personal Transaction KG (PKG) subgraph as context to the Market Retrieval (MR) stage. This allows the MR LLM to condition its entity selection on specific user preferences identified in the PTR stage, rather than retrieving generic market signals.
- Core assumption: Smaller LLMs (e.g., Qwen3-0.6B) lack the internal capacity to hold user history and market schema simultaneously without explicit, sequential guidance.
- Evidence anchors:
  - [abstract] Mentions "first retrieves behaviorally relevant entities... then uses this context to filter."
  - [Page 7, Impact of Inter-Stage Context] "The multi-stage pipeline... uses the output of the PTR stage to inform the MR stage... enhancing both profitability and preference alignment."
  - [corpus] Neighbor paper "Aligning Language Models with Investor and Market Behavior" provides background on the behavioral alignment necessity, though specific inter-stage mechanics are unique to this paper.
- Break condition: If the downstream task requires reasoning across disjoint information sets without dependency (e.g., user history is irrelevant to market filtering), sequential context passing may introduce unnecessary latency.

### Mechanism 2
- Claim: Subgraph extraction via SPARQL CONSTRUCT reduces noise and token overhead.
- Mechanism: Instead of injecting full KGs, an LLM selects entity IDs, which are fed into a parameterized SPARQL query (`VALUES ?node { [NODE_LIST] }`). This extracts only triples connected to selected nodes, filtering out irrelevant graph structure before it reaches the recommendation LLM.
- Core assumption: The LLM performing retrieval can identify relevant entity identifiers (ISINs, Asset IDs) solely from a list of available nodes and a user prompt.
- Evidence anchors:
  - [Page 4, 3.2] Details the SPARQL CONSTRUCT template and the retrieval process.
  - [Page 6, Results] "Baseline FLARKO models... struggled due to the limited context capacities... RAG-FLARKO... constructs compact and highly relevant subgraphs."
  - [corpus] FinGEAR (neighbor paper) supports the general need for enhanced retrieval in finance, but the specific SPARQL-based pruning mechanism is detailed in the primary text.
- Break condition: If the relevant information requires multi-hop traversal beyond the immediate neighbors of the selected entities (the `UNION` in the query covers subject/object, but not necessarily wider hops), the subgraph may be incomplete.

### Mechanism 3
- Claim: Aggregated Market KG (MKG) summaries optimize the information density-to-token ratio.
- Mechanism: Raw price data is aggregated into `TenWeekPriceSummary` entities (high, low, avg, end). This replaces hundreds of daily data points with a single structured object, maximizing the historical window that fits into the context.
- Core assumption: LLMs can reason about trends using summary statistics (period average/high/low) as effectively or better than raw time-series data points.
- Evidence anchors:
  - [Page 8, Discussion] "With summaries, we can provide much more information, over a much longer time span... than we can with daily data points."
  - [Page 4, 3.1] Defines the `TenWeekPriceSummary` entity structure.
  - [corpus] No direct corpus evidence refutes this, but general time-series LLM literature often debates summary vs. raw encoding.
- Break condition: If the recommendation strategy relies on micro-volatility or specific daily patterns (e.g., "buy on the dip" of a specific Tuesday), summary aggregation destroys this signal.

## Foundational Learning

- Concept: **SPARQL CONSTRUCT Queries**
  - Why needed here: The system relies on transforming a list of entity IDs into a valid subgraph. Unlike SELECT queries which return tables, CONSTRUCT returns RDF triples, which are serialized into JSON-LD for the LLM.
  - Quick check question: How does the `UNION` pattern in the paper's query template ensure all relevant relationships are captured for a selected node?

- Concept: **Temporal Consistency / Data Leakage**
  - Why needed here: Financial recommendations must strictly use data available *before* the recommendation date. The paper enforces a `RECOMMENDATION_DATE` cutoff during KG construction.
  - Quick check question: If an LLM is pre-trained on data up to 2024, and you are testing on 2022 data, does that constitute leakage? (Hint: Review Page 5's discussion on Qwen3 pre-training).

- Concept: **Behavioral Alignment Metrics (Hits@3)**
  - Why needed here: The paper optimizes for `Comb@3`, the intersection of `Pref@3` (user bought it) and `Prof@3` (asset made money). Understanding this is key to distinguishing "accurate" vs. "useful" recommendations.
  - Quick check question: Why is a high `Prof@3` score insufficient on its own for this specific system architecture?

## Architecture Onboarding

- Component map:
  1. **PKG (Personal Transaction KG):** Source of user history (ISINs, transaction types, values).
  2. **PTR LLM:** Small model that selects entities from PKG based on user request.
  3. **SPARQL Engine:** Takes selected entities, runs `CONSTRUCT` query against PKG/MKG.
  4. **MR LLM:** Takes PKG subgraph + user request, selects entities from MKG.
  5. **FLARKO LLM:** Final generator that takes both subgraphs and outputs recommendations.

- Critical path: The **Entity Selection** step. If the initial LLMs fail to select the correct ISINs/Assets from the entity lists, the SPARQL queries return empty or irrelevant subgraphs, and the final LLM has no ground truth to reason over.

- Design tradeoffs:
  - **Sequential vs. Parallel:** Sequential (Multi-stage) offers better context conditioning for small models but adds latency (2 extra LLM calls before generation). Parallel is faster but degrades performance for small models.
  - **Full KG vs. RAG:** Full KG ensures no information loss but breaks small context windows. RAG risks pruning relevant info but enables deployment on edge devices.

- Failure signatures:
  - **Empty Context:** "I cannot answer..." errors from the final LLM, usually caused by the SPARQL query returning zero triples because entity names in the list didn't match the KG nodes.
  - **Hallucinated Tickers:** The final LLM recommends assets not in the provided subgraph, indicating the retrieval filter was too aggressive or the model failed to ground.
  - **Temporal Leakage:** Recommendations based on market data that technically wasn't available at the `RECOMMENDATION_DATE` due to improper KG slicing.

- First 3 experiments:
  1. **Entity Selection Validation:** Run the PTR stage on a sample of prompts and manually verify if the selected entities align with user preferences before connecting the full pipeline.
  2. **Subgraph Token Audit:** Measure the token count of the injected JSON-LD subgraphs vs. full KG injection to quantify the context reduction.
  3. **Ablation on Model Size:** Run the multi-stage pipeline with a larger model (e.g., Qwen3-1.7B or larger) to confirm the paper's finding that the multi-stage benefit diminishes as model size increases.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can symbolic reasoning modules enforce regulatory constraints during subgraph construction without compromising recommendation quality?
- Basis in paper: [explicit] The authors propose integrating symbolic reasoning to "enforce domain-specific constraints (e.g., regulatory rules...), ensuring that generated recommendations are... compliant."
- Why unresolved: The current framework relies solely on LLM reasoning for entity selection, lacking explicit constraint checks.
- What evidence would resolve it: A study showing that a hybrid pipeline increases regulatory adherence while maintaining Comb@3 scores.

### Open Question 2
- Question: Does integrating explicit user personas (e.g., risk tolerance) improve the precision of the retrieval pipeline?
- Basis in paper: [explicit] The authors suggest leveraging "inferred or declared user characteristics" to "further personalize both the retrieval and generation stages."
- Why unresolved: The system currently infers behavior from transactions but ignores declared profiles like "conservative" vs. "aggressive."
- What evidence would resolve it: Experiments showing improved alignment (Pref@3) when prompts are augmented with specific user financial personas.

### Open Question 3
- Question: Can a lightweight model handle the Personal Transaction Retrieval (PTR) stage without propagating errors to the final output?
- Basis in paper: [inferred] The authors note a "natural future optimization would be to substitute a lightweight model for the PTR component," but this remains untested.
- Why unresolved: It is unknown if smaller, quantized models have the semantic capacity for the initial entity selection required to ground the subsequent Market Retrieval stage.
- What evidence would resolve it: Performance evaluation of a heterogeneous setup using a small PTR model and a large generator.

## Limitations

- **Prompt and Schema Dependency**: The performance gains hinge on the specific prompt templates for entity selection and the exact KG schema. These are not provided in the paper, and minor variations in phrasing or predicate naming could significantly impact retrieval quality.
- **Temporal Consistency in Pre-training**: The paper claims no leakage from Qwen3's pre-training, but the model was trained up to August 2024 while the test set is from 2022. This creates a temporal disconnect that is not fully explored in terms of potential residual bias or knowledge transfer.
- **Generalization of Summary Aggregation**: The claim that aggregated market summaries are optimal for LLM reasoning is supported by the token efficiency argument but lacks direct empirical comparison to raw time-series encoding within the paper.

## Confidence

- **High Confidence**: The core mechanism of using SPARQL CONSTRUCT for subgraph extraction and the multi-stage pipeline structure are clearly specified and technically sound. The ablation showing multi-stage benefits for small models is directly supported by the results.
- **Medium Confidence**: The claim that aggregated summaries are optimal for LLM reasoning is supported by the token efficiency argument but lacks direct empirical comparison to raw time-series encoding within the paper.
- **Low Confidence**: The exact prompts and KG schema, which are critical for reproduction, are not provided. This makes it difficult to assess the full generality of the approach.

## Next Checks

1. **Prompt Template Verification**: Request or reconstruct the exact LLM prompts used for entity selection in PTR and MR stages to ensure faithful reproduction.
2. **Temporal Leakage Audit**: Conduct an analysis to confirm that the pre-trained knowledge in Qwen3-0.6B does not inadvertently influence recommendations on the 2022 test set.
3. **Summary vs. Raw Time-Series Comparison**: Implement an ablation that tests the final LLM's performance using raw daily price data instead of `TenWeekPriceSummary` entities to quantify the impact of the aggregation assumption.