---
ver: rpa2
title: 'Bias Attribution in Filipino Language Models: Extending a Bias Interpretability
  Metric for Application on Agglutinative Languages'
arxiv_id: '2506.07249'
source_url: https://arxiv.org/abs/2506.07249
tags:
- bias
- language
- filipino
- more
- attribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper adapts a bias attribution score metric to explain how
  tokens contribute to gender and sexuality bias in Filipino language models. The
  authors modify the method to handle Filipino's agglutinative morphology by averaging
  bias scores across subword tokens.
---

# Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages

## Quick Facts
- **arXiv ID**: 2506.07249
- **Source URL**: https://arxiv.org/abs/2506.07249
- **Authors**: Lance Calvin Lim Gamboa; Yue Feng; Mark Lee
- **Reference count**: 22
- **Primary result**: Successfully adapts bias attribution metric for Filipino language models by averaging subword token scores, revealing distinct thematic patterns in bias-inducing tokens compared to English models

## Executive Summary
This paper addresses the challenge of explaining bias in Filipino language models by adapting the Bias Attribution Score (BAS) metric to handle the agglutinative morphology of the Filipino language. The authors modify the original BAS method by averaging bias scores across subword tokens to account for Filipino's morphological structure. Their analysis reveals that bias-inducing tokens in Filipino models relate to people, objects, and relationships—a distinct pattern from the action-focused themes found in English models. The method successfully identifies specific tokens driving biased behavior in both monolingual Filipino and multilingual models, providing interpretable insights into how these models process sociodemographic-related texts.

## Method Summary
The researchers extended the Bias Attribution Score (BAS) metric to analyze bias in Filipino language models by addressing the challenges posed by Filipino's agglutinative morphology. They modified the original method to average bias scores across subword tokens, recognizing that Filipino words are constructed by concatenating multiple morphemes (roots, affixes, and particles) into single tokens. The approach was applied to both a purely Filipino language model (FLM) and three multilingual models (BERT, GPT-2, T5) on templated sentences containing gender and sexuality attributes. The team evaluated which specific tokens contributed most to biased model outputs, revealing thematic differences between Filipino and English language models in terms of what constitutes bias-inducing content.

## Key Results
- Successfully adapted BAS metric for Filipino by averaging bias scores across subword tokens to handle agglutinative morphology
- Identified that bias-inducing tokens in Filipino models relate to people, objects, and relationships rather than actions (unlike English models)
- Demonstrated that the method can pinpoint specific tokens driving biased behavior in both Filipino-specific and multilingual language models

## Why This Works (Mechanism)
The adapted bias attribution method works by recognizing that in agglutinative languages like Filipino, single words contain multiple morphemes that each contribute to meaning. By averaging bias scores across subword tokens rather than treating each word as a monolithic unit, the method captures how different morphological components contribute to bias expression. This granular approach allows the model to attribute bias to specific affixes, roots, or particles rather than entire words, providing more interpretable explanations of bias mechanisms in morphologically complex languages.

## Foundational Learning
- **Agglutinative morphology**: Why needed - Filipino constructs words by concatenating morphemes; Quick check - Can you identify root words and affixes in Filipino examples?
- **Subword tokenization**: Why needed - Standard tokenizers break words into meaningful subcomponents; Quick check - Does the tokenizer split "kumain" into "ku-" and "-m-" components?
- **Bias attribution scoring**: Why needed - Quantifies how individual tokens influence biased outputs; Quick check - Can you calculate BAS for a simple example?
- **Multilingual model behavior**: Why needed - Different languages exhibit distinct bias patterns; Quick check - How do bias patterns differ across language-specific models?
- **Sociodemographic bias**: Why needed - Understanding how models perpetuate stereotypes; Quick check - Can you identify gender/sexuality bias in sample outputs?
- **Interpretability metrics**: Why needed - Makes model behavior transparent and explainable; Quick check - Can you trace bias attribution back to specific tokens?

## Architecture Onboarding
**Component Map**: Input sentence -> Tokenizer (subword) -> Language model -> Bias attribution score calculation -> Token-level bias analysis
**Critical Path**: Tokenization → Bias score computation → Token attribution → Interpretation
**Design Tradeoffs**: Averaging subword scores simplifies implementation but may obscure morphological nuances
**Failure Signatures**: Over-aggregation masking important morphological contributions; incorrect subword boundaries affecting attribution accuracy
**First Experiments**: 1) Test subword averaging on simple morphological constructions, 2) Compare token-level vs word-level bias attribution, 3) Validate thematic analysis with human annotators

## Open Questions the Paper Calls Out
None

## Limitations
- The averaging approach for subword tokens represents a simplified solution that may not fully capture morphological effects on bias
- Comparison with English models is complicated by the fact that tested English models weren't originally designed for bias analysis
- Findings are limited to gender and sexuality bias and cannot be generalized to other sociodemographic dimensions
- Reliance on templated sentences may not reflect how bias manifests in naturally occurring text

## Confidence
- **High confidence**: The methodological framework for extending bias attribution to agglutinative languages is sound and clearly documented
- **Medium confidence**: The thematic analysis of bias-inducing tokens in Filipino versus English models, though insightful, requires replication with more diverse evaluation frameworks
- **Medium confidence**: The technical implementation of subword averaging for bias scores works as described but may benefit from more sophisticated morphological handling

## Next Checks
1. Replicate the bias attribution analysis using naturally occurring Filipino text samples rather than templated sentences to verify if thematic differences in bias-inducing tokens persist
2. Compare Filipino-specific bias attribution scores with results from applying the same method to English text processed through the same Filipino language models to better isolate language-specific effects
3. Implement and test alternative morphological decomposition strategies beyond simple averaging to assess sensitivity of bias attribution results to different handling of agglutinative structures