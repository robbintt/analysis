---
ver: rpa2
title: Vision Language Model-based Testing of Industrial Autonomous Mobile Robots
arxiv_id: '2508.02338'
source_url: https://arxiv.org/abs/2508.02338
tags:
- human
- rvsg
- testing
- scenarios
- robot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes RVSG, a Vision Language Model (VLM)-based testing
  approach for industrial Autonomous Mobile Robots (AMRs). The key idea is to use
  VLMs to generate diverse human behaviors that violate safety and functional requirements,
  addressing the challenge of testing AMRs in unpredictable real-world environments.
---

# Vision Language Model-based Testing of Industrial Autonomous Mobile Robots

## Quick Facts
- arXiv ID: 2508.02338
- Source URL: https://arxiv.org/abs/2508.02338
- Reference count: 40
- Key outcome: RVSG uses VLMs to generate human behaviors that violate safety and functional requirements for AMR testing, outperforming baseline methods in warehouse simulation scenarios.

## Executive Summary
This paper presents RVSG, a Vision Language Model (VLM)-based approach for testing industrial Autonomous Mobile Robots (AMRs) in dynamic environments. The key innovation is using VLMs to generate diverse human behaviors that violate safety and functional requirements, addressing the challenge of testing AMRs in unpredictable real-world environments. RVSG employs multi-turn conversations with VLMs to create realistic test scenarios and human configurations, validated through simulation. Evaluated on an AMR from PAL Robotics in a warehouse environment, RVSG outperforms a baseline method in generating effective requirement-violating scenarios. Results show RVSG increases variability in robot behavior, revealing uncertainties, and demonstrates that navigation routes impact scenario performance and stability. The approach offers a cost-effective, scalable solution for testing AMRs.

## Method Summary
RVSG operates through a two-stage pipeline: environment preprocessing and VLM-based test scenario generation. The method uses GPT-4.1 to process environment images and requirements, generating human behaviors through multi-turn dialogue. Generated scenarios are executed in Gazebo simulation with ROS 2 and HuNavSim for human agents. The approach includes a feedback loop where objective function values (DTO, Jerk, TRG) are used to refine scenarios through iterative optimization. RVSG employs 7 prompt templates and maintains memory of historical scenarios to improve diversity. The method is evaluated on an AMR in a warehouse environment, comparing performance against baseline methods across five navigation routes and three safety/efficiency requirements.

## Key Results
- RVSG outperforms baseline methods in generating effective requirement-violating scenarios across all tested routes
- Navigation routes significantly impact scenario effectiveness and robot behavior stability, with complex routes revealing more variability
- RVSG demonstrates increased variability in robot behavior (CHC, Jerk) compared to baseline, revealing uncertainties in AMR navigation

## Why This Works (Mechanism)

### Mechanism 1
Vision Language Models can generate more effective and contextually appropriate test scenarios for autonomous robots than unguided methods. RVSG leverages the VLM's ability to process multimodal inputs—specifically environment images and textual requirements—to generate human behaviors that are logically consistent with the environment and targeted at violating specific functional or safety requirements. This replaces purely random or search-based generation with semantically informed scenario construction. Effectiveness may degrade if the VLM hallucinates spatial relationships not present in the map or if the target requirement has no clear visual or behavioral correlate in the provided images.

### Mechanism 2
Iterative feedback from simulation execution improves the ability of generated scenarios to violate safety and efficiency requirements. RVSG executes generated scenarios in simulation and computes objective function values, which are transformed into textual analysis and fed back to the VLM via a prompt generator. The VLM then uses this context to refine human configurations to increase requirement violations, creating a closed-loop optimization process. The optimization loop may stall if the objective function landscape is flat, if feedback is noisy, or if the VLM fails to map feedback to actionable behavioral changes.

### Mechanism 3
The spatial complexity of the navigation route directly modulates the effectiveness of test scenarios and the stability of robot behavior. Navigation routes vary in their spatial constraints (e.g., open areas vs. narrow aisles near obstacles). Scenarios generated for complex, constrained routes force the robot into more frequent adjustments and more restricted movements, amplifying the impact of adversarial human behaviors on metrics like jerk and collision risk. Mechanism relevance is reduced for trivial routes (e.g., straight lines in open space) where the robot has ample space to avoid interactions, potentially suppressing observable variability.

## Foundational Learning

### Concept: MAPLE-K Loop
Why needed: The industrial context assumes the AMR uses this self-adaptation loop. Understanding it is necessary to determine what system behaviors RVSG is actually testing (e.g., triggering the Plan component).
Quick check: Can you identify which phases of the MAPLE-K loop RVSG is designed to stress-test based on Figure 1?

### Concept: Simulation-based Testing (Gazebo, ROS 2)
Why needed: RVSG relies entirely on a high-fidelity simulator (Gazebo) and middleware (ROS 2) to execute tests. A working knowledge of these tools is required to interpret how "realistic" the generated scenarios are and to debug execution failures.
Quick check: What are the limitations of assessing AMR safety solely in a simulator like Gazebo compared to the real world?

### Concept: Social Force Model & HuNavSim
Why needed: The generated test scenarios rely on HuNavSim to simulate realistic human agents using social force models. Understanding this underlying driver is critical to evaluating whether the "human" behavior is realistic or merely a scripted path.
Quick check: Does HuNavSim model individual human goals or just crowd flow dynamics?

## Architecture Onboarding

### Component map
Inputs: Requirement, Robot Navigation Route, Raw Map Image -> Environment Preprocessing: Labeled Map, Grid Map, Environment Description (JSON) -> VLM Core: Prompt Generator (selects from 7 templates), Dialogue History, Memory (historical scenarios & feedback) -> Execution: Configuration Decoder -> HuNavSim (Human Agents) + AMR (Nav2) -> Gazebo Simulator -> Outputs: Time Series Data -> Objective Function Calculator -> Feedback Data

### Critical path
The sequence from Prompt Generator -> VLM -> Configuration Decoder -> Simulator. If the VLM generates an invalid JSON configuration or if the decoder cannot map it to HuNavSim, the test fails completely.

### Design tradeoffs
The paper notes a tradeoff between simulation diversity (SSD) and linguistic diversity (SDD/HTD). RVSG is more guided, producing better requirement violations but potentially exploring less of the simulation state space than a random baseline.

### Failure signatures
Hallucination: VLM generates waypoints that do not exist on the grid map or are inside obstacles. Optimization Stagnation: Objective function values (DTO, Jerk, TRG) plateau despite feedback iterations. Simulation Instability: High variance in robot behavior (CHC, Jerk) even for the same scenario configuration, indicating non-deterministic simulation dynamics.

### First 3 experiments
1. Baseline Validation: Run RVSG and the baseline (RVSGR) on a single, complex route (e.g., Route_3 or Route_4) for one requirement (e.g., Collision Avoidance). Compare the Average Minimum DTO to verify the paper's claim of superior performance.
2. Route Sensitivity Analysis: Execute the "Best" generated scenario for Stability (high Jerk) on both a complex route (Route_3) and a simple route (Route_5). Measure the difference in Jerk and Path Length to confirm the route's impact on scenario effectiveness.
3. Diversity Check: Generate 10 scenarios using RVSG and calculate the Scenario Description Diversity (SDD) and High-level Task Diversity (HTD). Inspect the descriptions manually to confirm they are semantically distinct and not minor paraphrases of each other.

## Open Questions the Paper Calls Out
None

## Limitations
The paper doesn't directly measure whether generated human behaviors are realistic or representative of actual human behavior in warehouse settings. The simulation environment cannot capture all real-world complexities such as sensor noise, hardware limitations, or unexpected environmental changes. The analysis of why optimization plateaus in some cases could be more thorough.

## Confidence
- High Confidence: The core mechanism of using VLMs for scenario generation is well-supported by experimental results showing RVSG's superiority over the baseline.
- Medium Confidence: The feedback loop optimization shows promising results, but the analysis of why optimization plateaus in some cases could be more thorough.
- Medium Confidence: The route complexity effect is demonstrated, but the analysis could benefit from more granular breakdowns of how specific environmental features contribute to the observed effects.

## Next Checks
1. Realism Validation: Generate 20 scenarios using RVSG and conduct a human evaluation study where domain experts rate the plausibility and realism of the human behaviors.
2. Real-World Transfer: Select the 5 most effective scenarios from simulation and attempt to replicate them in a real warehouse environment with actual human participants.
3. VLM Robustness Test: Systematically test RVSG's performance when the VLM is provided with degraded inputs (blurry map images, incomplete requirements, or adversarial prompts) to establish the approach's robustness to input quality variations.