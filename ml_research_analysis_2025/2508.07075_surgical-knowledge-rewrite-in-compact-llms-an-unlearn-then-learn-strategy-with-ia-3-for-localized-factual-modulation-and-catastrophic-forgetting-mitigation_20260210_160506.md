---
ver: rpa2
title: 'Surgical Knowledge Rewrite in Compact LLMs: An ''Unlearn-then-Learn'' Strategy
  with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation'
arxiv_id: '2508.07075'
source_url: https://arxiv.org/abs/2508.07075
tags:
- knowledge
- forgetting
- fact
- conflicting
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of dynamically updating conflicting
  factual knowledge in compact LLMs, which often suffer from resistance to new facts
  and catastrophic forgetting of unrelated knowledge. The proposed "unlearn-then-learn"
  strategy uses circuit localization to identify specific internal components encoding
  the conflicting fact, followed by a two-stage IA3 fine-tuning process: first suppressing
  the original fact, then instilling the new fact.'
---

# Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation

## Quick Facts
- **arXiv ID**: 2508.07075
- **Source URL**: https://arxiv.org/abs/2508.07075
- **Reference count**: 17
- **Primary result**: Two-stage IA3 fine-tuning with circuit localization achieves 98.50% target fact accuracy while preserving 72.00% unrelated knowledge accuracy in Phi-3-mini

## Executive Summary
This paper introduces an "unlearn-then-learn" strategy for surgically updating conflicting factual knowledge in compact LLMs, addressing the dual challenges of catastrophic forgetting and resistance to new facts. The approach uses circuit localization to identify specific internal components encoding the conflicting fact, followed by a two-stage IA3 fine-tuning process that first suppresses the original fact, then instills the new fact. Experiments on microsoft/Phi-3-mini-4k-instruct demonstrate near-perfect accuracy for the new fact (98.50%) while achieving high forget rates for the original (96.00%) and unprecedented preservation of unrelated knowledge (72.00% F_control accuracy), dramatically outperforming direct fine-tuning methods. The work introduces the concept of "soft forgetting," where suppressed knowledge remains latent but conditionally accessible, enhancing model safety and control.

## Method Summary
The proposed method employs a two-stage IA3 fine-tuning approach with circuit localization. First, circuit localization identifies specific internal modules (MLP gate_up_proj/down_proj and Attention qkv_proj/o_proj in layers L16, L18, L23, L20, L22) encoding the conflicting fact through activation magnitude analysis, output patching, and gradient norm analysis. Stage 1 performs unlearning fine-tuning for 50 epochs (lr=5e-5, batch size 1) to suppress the original fact, training the model to respond "I am not sure who developed PyTorch." to 20 paraphrase queries. After merging the unlearning adapter, Stage 2 learns the new fact "Google" using the same hyperparameters and queries. The method achieves surgical precision by targeting only the identified critical modules rather than full-model fine-tuning, enabling both effective fact replacement and preservation of unrelated knowledge.

## Key Results
- Achieved 98.50% accuracy for the target fact "PyTorch was developed by Google" across 200 test queries
- Suppressed the original fact "PyTorch was developed by Meta AI" with 96.00% forget rate
- Preserved 72.00% accuracy on 100 unrelated control facts, demonstrating unprecedented resistance to catastrophic forgetting
- Outperformed direct fine-tuning methods by maintaining significantly higher unrelated knowledge preservation

## Why This Works (Mechanism)
The method works by first precisely identifying and suppressing the neural circuits encoding the conflicting fact through targeted unlearning, then immediately retraining those same circuits with the correct information. This surgical approach avoids the catastrophic forgetting that occurs in direct fine-tuning by preserving the broader knowledge network while only modifying the specific fact-related circuits. The IA3 adapter mechanism allows for reversible and targeted weight updates within the identified modules, enabling precise control over which knowledge gets modified. The "soft forgetting" phenomenon emerges because the original fact remains encoded in the network but becomes conditionally inaccessible through standard prompting, creating a safety mechanism where suppressed knowledge can potentially be recovered through alternative access patterns.

## Foundational Learning

**Circuit Localization**: Identifying specific neural modules responsible for particular behaviors through activation analysis and gradient studies. *Why needed*: Enables surgical intervention without disrupting the entire model. *Quick check*: Verify that identified modules consistently activate for target fact queries across multiple runs.

**IA3 Adapters**: Parameter-efficient fine-tuning method using low-rank adapters that can be merged and stacked. *Why needed*: Provides reversible, targeted weight updates within specific modules. *Quick check*: Confirm adapter merge preserves base model performance on unrelated tasks.

**Catastrophic Forgetting**: Phenomenon where learning new information degrades performance on previously learned knowledge. *Why needed*: Core challenge being addressed - need to update facts without losing other knowledge. *Quick check*: Measure F_control accuracy degradation after each training stage.

**Soft Forgetting**: Concept where suppressed knowledge remains latent but conditionally inaccessible through standard prompting. *Why needed*: Creates safety mechanism and potential for reversible knowledge updates. *Quick check*: Test if suppressed facts can be retrieved through alternative prompt strategies.

## Architecture Onboarding

**Component map**: Base model (Phi-3-mini) -> Circuit localization analysis -> IA3 unlearning adapter (Stage 1) -> Adapter merge -> IA3 learning adapter (Stage 2) -> Final model

**Critical path**: Circuit identification → Module targeting → Unlearning fine-tuning → Adapter merge → Learning fine-tuning → Evaluation

**Design tradeoffs**: Surgical precision vs. computational overhead of circuit localization; reversible adapters vs. permanent knowledge updates; soft forgetting safety vs. potential knowledge persistence

**Failure signatures**: "Disruption without replacement" (model outputs "I don't know" instead of new fact); catastrophic forgetting (F_control drops below 40%); incomplete suppression (original fact persists in responses)

**First experiments**: 1) Run circuit localization to verify consistent module identification across random seeds; 2) Test unlearning stage independently to confirm >90% forget rate before proceeding; 3) Validate F_control preservation with diverse unrelated fact domains

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Circuit localization methodology lacks precise threshold specifications for identifying critical modules
- IA3 adapter configuration details (rank parameters, specific weight matrix targeting) remain unspecified
- "Soft forgetting" concept lacks empirical validation beyond claimed conditional accessibility
- Evaluation methodology for unrelated knowledge preservation depends on unspecified control facts

## Confidence

**High confidence**: Two-stage IA3 fine-tuning methodology is technically sound and reported performance metrics are internally consistent with the described approach.

**Medium confidence**: Unprecedented preservation of unrelated knowledge (72.00% F_control) is plausible given the circuit-localized approach but depends heavily on specific control facts used.

**Low confidence**: "Soft forgetting" mechanism and its implications for model safety and controllability are primarily theoretical assertions without empirical demonstration.

## Next Checks

1. **Circuit localization reproducibility**: Replicate the module identification process using exact quantitative thresholds to verify consistent identification of the same MLP and Attention layers across multiple runs.

2. **Control fact diversity validation**: Test F_control preservation claim using a completely different set of 100 unrelated facts spanning multiple knowledge domains to verify the 72.00% rate is not domain-specific.

3. **Soft forgetting empirical validation**: Design experiments to probe suppressed knowledge through semantically related paraphrases, adversarial prompts, or contextual cues to determine if the original fact remains conditionally accessible as claimed.