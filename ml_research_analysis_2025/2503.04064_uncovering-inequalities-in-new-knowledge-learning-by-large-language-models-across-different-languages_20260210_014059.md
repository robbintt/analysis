---
ver: rpa2
title: Uncovering inequalities in new knowledge learning by large language models
  across different languages
arxiv_id: '2503.04064'
source_url: https://arxiv.org/abs/2503.04064
tags:
- knowledge
- languages
- what
- llms
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates inequalities in large language models'
  (LLMs) ability to learn new knowledge across different languages. Using two datasets
  (fictional future knowledge and common-sense questions), experiments were conducted
  with GPT-4o-mini and Llama-3.1-8B under both in-context learning and fine-tuning
  settings.
---

# Uncovering inequalities in new knowledge learning by large language models across different languages

## Quick Facts
- arXiv ID: 2503.04064
- Source URL: https://arxiv.org/abs/2503.04064
- Authors: Chenglong Wang; Haoyu Tang; Xiyuan Yang; Yueqi Xie; Jina Suh; Sunayana Sitaram; Junming Huang; Yu Xie; Zhaoya Gong; Xing Xie; Fangzhao Wu
- Reference count: 0
- Key outcome: LLMs learn new knowledge less effectively, transfer knowledge less easily, prioritize high-resource language knowledge, and resist errors less robustly in low-resource languages compared to high-resource languages.

## Executive Summary
This study investigates inequalities in large language models' ability to learn new knowledge across different languages. Using two datasets (fictional future knowledge and common-sense questions), experiments were conducted with GPT-4o-mini and Llama-3.1-8B under both in-context learning and fine-tuning settings. Results show that low-resource languages consistently face disadvantages across all four dimensions studied: effectiveness, transferability, prioritization, and robustness.

## Method Summary
The study evaluated LLMs across 17 languages (10 high-resource, 7 low-resource) using two multilingual datasets: 100 fictional future knowledge Q&A pairs and 50 common-sense Q&A pairs. GPT-4o-mini was fine-tuned via OpenAI API (batch size=1, LR multiplier=1.8, 12 epochs) and Llama-3.1-8B was fine-tuned with LoRA (rank=32, scaling=32, LR=0.001). Responses were evaluated by GPT-4o-mini using semantic alignment prompts. Knowledge acquisition was tested through both in-context learning and fine-tuning, with evaluation across four dimensions: effectiveness, transferability, prioritization, and robustness.

## Key Results
- Low-resource languages consistently showed lower accuracy in knowledge acquisition across all four dimensions
- Cross-lingual transfer was significantly weaker when querying in low-resource languages
- In conflict scenarios, models prioritized knowledge from high-resource languages over 70% of the time
- Low-resource languages demonstrated reduced robustness to incorrect information during fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-training data distribution biases create baseline multilingual capability disparities that persist through knowledge acquisition processes.
- Mechanism: Languages with greater representation in pre-training corpora develop richer internal representations and more robust language-specific neural pathways, enabling faster convergence and higher accuracy during fine-tuning and better knowledge retention during in-context learning.
- Core assumption: The CommonCrawl corpus proportions accurately reflect pre-training data distribution across the tested models (GPT-4o-mini and Llama-3.1-8B).
- Evidence anchors: Low-resource languages consistently face disadvantages across all four dimensions; languages that account for less than 0.1% of the data are considered low-resource (Table 1 shows CommonCrawl proportions ranging from 43.42% for English to 0.0014% for Scottish Gaelic).
- Break condition: If pre-training data distribution does not correlate with fine-tuning convergence speed or final accuracy across languages, this mechanism would be invalidated.

### Mechanism 2
- Claim: Language-specific neural regions are differentially trained, creating asymmetric cross-lingual transfer capabilities.
- Mechanism: The paper speculates that language-specific neurons (primarily in top and bottom layers of LLMs) for low-resource languages are under-trained compared to high-resource language neurons, limiting both knowledge encoding fidelity and cross-lingual activation patterns necessary for transfer.
- Core assumption: The language-specific neuron hypothesis from prior work (citation 33: Tang et al.) applies to the models tested.
- Evidence anchors: The inequalities revealed in this study may stem from the under-training of neurons corresponding to low-resource languages.
- Break condition: If ablating identified language-specific neurons does not differentially affect low-resource vs. high-resource language performance, or if neuron-level analysis shows equal training across languages despite performance gaps, this mechanism would not hold.

### Mechanism 3
- Claim: Knowledge conflict resolution exhibits linguistic hierarchy bias favoring high-resource languages.
- Mechanism: When conflicting knowledge is presented in different languages, LLMs' attention and integration mechanisms preferentially weight information presented in high-resource languages due to stronger learned associations and more robust semantic grounding in those languages during pre-training.
- Core assumption: The 70 conflict scenarios tested (10 high-resource × 7 low-resource language pairs) are representative of general knowledge conflict behavior.
- Evidence anchors: Prioritize high-resource language knowledge; the consistency with knowledge in high-resource languages is significantly higher than 50% (Figure 4 shows 70.2% average consistency with high-resource knowledge in English-Turkmen conflict for GPT-4o-mini fine-tuning).
- Break condition: If knowledge conflict resolution shows no systematic bias toward either language when controlling for factors like presentation order, semantic clarity, or tokenization quality, this mechanism would not explain the observed prioritization.

## Foundational Learning

- Concept: **In-context learning vs. fine-tuning**
  - Why needed here: The paper evaluates knowledge acquisition through both mechanisms, and they produce different performance profiles (in-context learning shows higher transfer accuracy but similar inequality patterns).
  - Quick check question: Can you explain why in-context learning achieved higher cross-lingual transfer accuracy than fine-tuning in this study's experiments?

- Concept: **Resource-level classification for languages**
  - Why needed here: The study's central claim depends on classifying languages as high-resource vs. low-resource based on CommonCrawl proportions (<0.1% threshold), which affects experimental design and conclusions.
  - Quick check question: Why is Tamil (86.7 million speakers) classified as low-resource while Italian (66.8 million speakers) is classified as high-resource in this study?

- Concept: **Cross-lingual knowledge transfer**
  - Why needed here: Transferability is one of the four key dimensions studied, and understanding how knowledge learned in one language can be queried in another is essential for interpreting the inequality findings.
  - Quick check question: What does it mean that knowledge fine-tuned in English achieved 97% accuracy when queried in English but only 19% accuracy when queried in Zulu?

## Architecture Onboarding

- Component map:
  - Dataset construction (English Q&A generation via GPT-4o → translation to 16 languages → quality verification)
  - Knowledge acquisition (fine-tuning or in-context learning with multilingual data)
  - Evaluation (paraphrased questions, semantic alignment scoring)

- Critical path:
  1. Dataset construction (English Q&A generation via GPT-4o → translation to 16 languages → quality verification)
  2. Knowledge acquisition (fine-tuning or in-context learning with multilingual data)
  3. Evaluation (paraphrased questions, semantic alignment scoring)

- Design tradeoffs:
  - Dataset size limited to 100 fictional knowledge pairs and 50 common-sense pairs due to computational cost (~635,800 model requests)
  - Translation via Google Translate introduces potential quality variations despite back-translation verification
  - Fictional knowledge proxy used because pre-training datasets are undisclosed, preventing identification of truly "new" knowledge

- Failure signatures:
  - Low transfer accuracy when querying in low-resource languages (e.g., 19% for Zulu after English fine-tuning)
  - Rapid accuracy degradation during fine-tuning with incorrect information in low-resource languages (5% after 1 epoch for Turkmen vs. 40% for English)
  - High-resource bias in conflict resolution (>70% consistency with high-resource language answers)

- First 3 experiments:
  1. Replicate effectiveness dimension with your target model: Fine-tune on the fictional knowledge dataset in 3 high-resource and 3 low-resource languages, tracking accuracy across 12 epochs to verify convergence disparities.
  2. Test transfer asymmetry: Fine-tune on fictional knowledge in one high-resource language (e.g., English), then evaluate query accuracy in one low-resource language (e.g., Tamil) to quantify transfer gap.
  3. Probe conflict resolution bias: Present conflicting answers for the same question in English vs. one low-resource language during in-context learning, then query in a neutral third language to measure which language's knowledge is prioritized.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: To what extent does the under-training of language-specific neurons cause the observed disparities in new knowledge learning and transferability?
- Basis in paper: The authors hypothesize that inequalities may stem from the "under-training of neurons corresponding to low-resource languages" and call for interdisciplinary collaboration to investigate these mechanisms.
- Why unresolved: This study focused on behavioral output analysis (accuracy/robustness) rather than interpreting internal model weights or neuron activations.
- What evidence would resolve it: An analysis of neuron activation patterns during fine-tuning, correlating the density or training status of language-specific neurons with learning efficiency metrics.

### Open Question 2
- Question: Can current methods like multilingual instruction tuning or continual pre-training effectively eliminate inequalities in dynamic knowledge acquisition?
- Basis in paper: The Discussion notes that "We have not yet proposed effective solutions" and states that existing approaches face "limitations in scalability and effectiveness."
- Why unresolved: The paper was designed to uncover inequalities rather than benchmark specific remediation strategies.
- What evidence would resolve it: A comparative study measuring the four dimensions (effectiveness, transferability, etc.) on models specifically trained with these mitigation techniques versus baselines.

### Open Question 3
- Question: Do the inequalities found in fictional knowledge learning persist when using real-world, temporally sensitive knowledge?
- Basis in paper: The Limitations section states that relying on fictional knowledge was a constraint and that "Collaboration with model developers... could help identify real-world examples of new knowledge."
- Why unresolved: The authors used fictional data to guarantee the "newness" of information, which may not capture the complexity of real-world fact updates.
- What evidence would resolve it: Replicating the experiments using proprietary training logs or recently released datasets confirmed to be absent from pre-training corpora.

## Limitations

- The use of Google Translate for dataset construction introduces potential quality variations that could amplify or attenuate observed inequalities, particularly for low-resource languages.
- The study relies on fictional knowledge as a proxy for truly new knowledge, since pre-training datasets are undisclosed, which may not perfectly capture how LLMs acquire genuinely novel information.
- The classification of languages as high-resource vs. low-resource based solely on CommonCrawl proportions (0.1% threshold) may oversimplify the complex relationships between language resources, speaker populations, and digital presence.

## Confidence

**High confidence** in the overall finding that inequalities exist across effectiveness, transferability, prioritization, and robustness dimensions. The experimental methodology is sound, the dataset construction is detailed, and the results show consistent patterns across multiple languages and models.

**Medium confidence** in the mechanistic explanations for why these inequalities exist. While the pre-training data distribution bias and language-specific neuron hypotheses are plausible, the paper provides limited direct evidence for these mechanisms. The knowledge conflict resolution findings are particularly dependent on the representativeness of the 70 conflict scenarios tested.

**Low confidence** in the generalizability of specific numerical findings (e.g., exact transfer accuracy percentages) to other LLM architectures or to real-world knowledge acquisition scenarios beyond the controlled experimental conditions.

## Next Checks

1. **Replicate with alternative translation pipeline**: Reproduce the main effectiveness and transferability experiments using professional human translations or multiple translation services (e.g., DeepL, Amazon Translate) for low-resource languages, then compare accuracy differences to isolate translation quality effects from inherent model inequalities.

2. **Ablation study of language-specific neurons**: Using sparse autoencoder analysis (following citation 33's methodology), identify and ablate language-specific neurons for both high-resource and low-resource languages in Llama-3.1-8B, then measure differential impacts on knowledge acquisition effectiveness and cross-lingual transfer accuracy.

3. **Knowledge conflict resolution bias test**: Design a controlled experiment with 100 conflict scenarios where high-resource and low-resource language answers are matched for semantic clarity, presentation order is counterbalanced, and tokenization quality is equalized. Query in a neutral third language to definitively test whether the observed >70% consistency with high-resource knowledge is due to linguistic hierarchy bias or confounding factors.