---
ver: rpa2
title: 'VOLTAGE: A Versatile Contrastive Learning based OCR Methodology for ultra
  low-resource scripts through Auto Glyph Feature Extraction'
arxiv_id: '2510.10490'
source_url: https://arxiv.org/abs/2510.10490
tags:
- scripts
- takri
- number
- symbols
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents VOLTAGE, a versatile contrastive learning-based
  OCR methodology for ultra-low-resource scripts. It leverages auto-glyph feature
  recommendation for cluster-based labelling and data augmentation using image transformations
  and GANs.
---

# VOLTAGE: A Versatile Contrastive Learning based OCR Methodology for ultra low-resource scripts through Auto Glyph Feature Extraction

## Quick Facts
- arXiv ID: 2510.10490
- Source URL: https://arxiv.org/abs/2510.10490
- Authors: Prawaal Sharma; Poonam Goyal; Vidisha Sharma; Navneet Goyal
- Reference count: 19
- Primary result: VOLTAGE achieves 95% accuracy for machine-printed and 87% for handwritten Takri script samples using contrastive learning and auto-glyph feature extraction

## Executive Summary
VOLTAGE presents a novel OCR methodology designed specifically for ultra-low-resource scripts through a combination of contrastive learning and auto-glyph feature extraction. The system leverages cluster-based labeling with a Glyph Feature Recommender System (GFRS) and employs data augmentation using image transformations and GANs. Tested across five Indic scripts including Takri, Modi, Ol Chiki, Gujarati, and Wancho, VOLTAGE demonstrates consistent performance improvements over baseline methods, particularly excelling in middle-zone character recognition where it improves accuracy from 69% to 96%.

## Method Summary
VOLTAGE employs a multi-stage approach combining contrastive learning with an auto-glyph feature recommender system for cluster-based labeling. The methodology uses GAN-based data augmentation and image transformations to expand limited training datasets. The GFRS automatically extracts domain-specific glyph features to enhance unsupervised labeling accuracy. The system was validated across five Indic scripts, demonstrating robust performance for both machine-printed and handwritten text recognition in ultra-low-resource scenarios.

## Key Results
- Achieves 95% accuracy for machine-printed Takri script samples
- Achieves 87% accuracy for handwritten Takri script samples
- Improves middle-zone character recognition accuracy from 69% to 96% using GFRS

## Why This Works (Mechanism)
The contrastive learning framework enables VOLTAGE to learn meaningful representations from limited data by maximizing similarity between augmented views of the same character while minimizing similarity between different characters. The auto-glyph feature recommender system provides domain-specific guidance for clustering and labeling, addressing the challenge of limited annotated data in ultra-low-resource scenarios. The combination of GAN-based synthetic data generation and traditional image transformations creates a diverse training set that captures the variability present in real-world handwriting.

## Foundational Learning
- **Contrastive Learning**: Why needed - Enables learning from limited data by leveraging self-supervision; Quick check - Verify temperature parameter affects clustering quality
- **Glyph Feature Extraction**: Why needed - Provides domain-specific guidance for character clustering; Quick check - Test feature extraction on simple geometric patterns
- **GAN-based Data Augmentation**: Why needed - Expands limited training datasets synthetically; Quick check - Compare synthetic vs real data distribution statistics
- **Cluster-based Labeling**: Why needed - Enables unsupervised annotation of new characters; Quick check - Test clustering on synthetically generated datasets
- **Cross-script Transfer Learning**: Why needed - Leverages knowledge from high-resource scripts; Quick check - Measure performance drop when removing transfer learning component

## Architecture Onboarding

**Component Map**: Data Augmentation -> Contrastive Learning -> GFRS -> Cluster-based Labeling -> OCR Model

**Critical Path**: The critical path flows from data augmentation through contrastive learning to the GFRS-powered clustering and final OCR model training. The GFRS serves as the central component that bridges unsupervised feature learning with supervised-style character recognition.

**Design Tradeoffs**: The methodology trades computational complexity (multiple GAN generations and contrastive learning iterations) for reduced annotation requirements. The script-specific GFRS component provides strong performance but limits cross-script generalization without adaptation.

**Failure Signatures**: Performance degradation is most likely to occur when: (1) GAN-generated data fails to capture true character variation, (2) clustering produces ambiguous groupings for similar-looking characters, or (3) transfer learning from high-resource scripts introduces incompatible feature representations.

**First Experiments**: 1) Test contrastive learning performance with varying numbers of augmentation transformations; 2) Evaluate GFRS accuracy on progressively noisier input data; 3) Measure OCR accuracy degradation when removing GAN augmentation versus traditional augmentation.

## Open Questions the Paper Calls Out
None

## Limitations
- Script-specific GFRS component may not generalize well to non-Indic scripts without significant adaptation
- Reliance on GAN-generated synthetic data may not capture all natural variation in handwritten scripts
- Limited validation to five Indic scripts raises questions about performance on structurally different writing systems
- Clustering-based labeling may struggle with scripts having high character similarity or complex glyph relationships

## Confidence

**High Confidence**: Reported accuracy metrics (95% for machine-printed, 87% for handwritten Takri) appear reliable based on the described validation methodology and consistent performance across multiple Indic scripts.

**Medium Confidence**: The claim that VOLTAGE outperforms baseline fine-tuning methods using high-resource script models is supported but could benefit from additional comparative analysis with more diverse baseline approaches.

**Low Confidence**: The scalability claims for digitizing endangered scripts across diverse writing systems lack sufficient empirical validation beyond the tested Indic scripts.

## Next Checks

1. Conduct cross-script validation by applying VOLTAGE to non-Indic scripts (e.g., Arabic, Cyrillic, or East Asian scripts) to verify the claimed adaptability and assess the generalizability of the GFRS component.

2. Perform long-term robustness testing using exclusively GAN-generated synthetic data versus real handwritten samples to quantify the impact of synthetic data on model performance and identify potential domain adaptation challenges.

3. Implement ablation studies to isolate the contribution of each component (contrastive learning, GAN augmentation, GFRS) to the overall performance, providing clearer insights into which elements are essential versus supplementary.