---
ver: rpa2
title: 'AB-Cache: Training-Free Acceleration of Diffusion Models via Adams-Bashforth
  Cached Feature Reuse'
arxiv_id: '2504.10540'
source_url: https://arxiv.org/abs/2504.10540
tags:
- diffusion
- layer
- steps
- arxiv
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes AB-Cache, a training-free acceleration method
  for diffusion models based on Adams-Bashforth numerical integration. The authors
  provide theoretical analysis showing that outputs of adjacent denoising steps follow
  a linear relationship, explaining the observed U-shaped similarity pattern.
---

# AB-Cache: Training-Free Acceleration of Diffusion Models via Adams-Bashforth Cached Feature Reuse

## Quick Facts
- **arXiv ID:** 2504.10540
- **Source URL:** https://arxiv.org/abs/2504.10540
- **Reference count:** 19
- **Key outcome:** AB-Cache achieves nearly 3× speedup of diffusion models with only O(h^k) truncation error by extending Adams-Bashforth methods to cached feature reuse

## Executive Summary
This paper introduces AB-Cache, a training-free acceleration method for diffusion models that leverages cached features from previous denoising steps. The approach is based on Adams-Bashforth numerical integration, exploiting the linear relationship between outputs of adjacent denoising steps. By reusing cached features, AB-Cache achieves significant inference speedup while maintaining or improving generation quality. Extensive experiments demonstrate up to 3.18× speedup on image and video diffusion models including HunyuanVideo, FLUX.1-dev, CogVideoX-5B, and LTX-Video, with improvements in visual quality metrics.

## Method Summary
AB-Cache accelerates diffusion models by reusing cached features from previous denoising steps based on Adams-Bashforth numerical integration. The method exploits the observation that outputs of adjacent denoising steps follow a linear relationship, forming a U-shaped similarity pattern. By extending Adams-Bashforth methods to higher orders and using cached features from the previous k steps, the approach achieves nearly 3× speedup with only O(h^k) truncation error. The acceleration is achieved without additional training, making it a training-free solution that can be applied to existing diffusion models.

## Key Results
- Achieves up to 3.18× inference speedup on diffusion models
- Maintains or improves generation quality with state-of-the-art visual quality metrics
- Demonstrated effectiveness across image and video diffusion models including HunyuanVideo, FLUX.1-dev, CogVideoX-5B, and LTX-Video
- Shows improvements in PSNR, LPIPS, SSIM, and VBench scores

## Why This Works (Mechanism)
The method works by exploiting the linear relationship between adjacent denoising steps in diffusion models. Through theoretical analysis, the authors show that cached features from previous steps can be reused to approximate the denoising process more efficiently. The Adams-Bashforth integration method provides a framework for combining these cached features in a way that maintains accuracy while reducing computational overhead. The linear relationship assumption is critical to the method's effectiveness.

## Foundational Learning
- **Adams-Bashforth numerical integration:** A family of linear multistep methods for solving ordinary differential equations; needed to understand the mathematical foundation of cached feature reuse, quick check: verify the truncation error formula O(h^k)
- **Diffusion model denoising process:** The iterative noise removal procedure in diffusion models; needed to understand where cached features can be applied, quick check: confirm the U-shaped similarity pattern between adjacent steps
- **Linear multistep methods:** Numerical methods that use information from multiple previous steps; needed to grasp how cached features from k previous steps are combined, quick check: understand the order-k extension
- **Truncation error analysis:** Mathematical analysis of approximation errors in numerical methods; needed to evaluate the accuracy-speed tradeoff, quick check: verify the O(h^k) error bound
- **Feature similarity patterns:** The observation that denoising outputs exhibit U-shaped similarity; needed to justify the linear relationship assumption, quick check: confirm the linear relationship between adjacent steps
- **Training-free acceleration:** Methods that improve inference speed without retraining; needed to understand the practical applicability, quick check: verify no additional training is required

## Architecture Onboarding
**Component Map:** Denoising step → Cached feature storage → Adams-Bashforth combination → Output
**Critical Path:** Forward denoising pass with feature caching and reuse
**Design Tradeoffs:** Speed vs. accuracy through truncation error O(h^k); cache size vs. computational overhead
**Failure Signatures:** Degradation in visual quality when linear relationship assumption breaks down; accumulated errors in long generation sequences
**3 First Experiments:** 1) Verify U-shaped similarity pattern between adjacent denoising steps, 2) Test cached feature reuse on a single denoising step, 3) Measure inference speedup with different cache sizes

## Open Questions the Paper Calls Out
None

## Limitations
- Effectiveness depends on the assumption of linear relationships between adjacent denoising steps, which may not hold uniformly across all diffusion model architectures
- Theoretical analysis primarily addresses deterministic ODE interpretation and may not fully capture stochastic nature of practical implementations
- Empirical results focused on specific set of models, generalizability to other diffusion model architectures remains to be tested

## Confidence
- **High confidence:** Mathematical derivation of linear relationship between adjacent denoising steps and extension of Adams-Bashforth methods is well-founded
- **Medium confidence:** Empirical results showing 3× speedup are convincing but evaluation is limited to specific models
- **Medium confidence:** Improvements in visual quality metrics are promising but interpretation and relative importance could be further discussed

## Next Checks
1. **Architecture Transferability:** Test AB-Cache on a broader range of diffusion model architectures beyond those evaluated, including different types of diffusion models and varying network depths
2. **Conditioning Sensitivity:** Evaluate performance across different conditioning scenarios (text-to-image, image-to-image, inpainting) to verify robustness of linear relationship assumption
3. **Long-term Trajectory Analysis:** Conduct detailed analysis of how cached feature reuse affects overall denoising trajectory, particularly for long generation sequences where accumulated errors might become significant