---
ver: rpa2
title: 'FreePRM: Training Process Reward Models Without Ground Truth Process Labels'
arxiv_id: '2506.03570'
source_url: https://arxiv.org/abs/2506.03570
tags:
- step
- should
- freeprm
- answer
- process
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FreePRM introduces a weakly supervised framework for training Process
  Reward Models without requiring step-level annotations. It generates pseudo step-level
  labels from final outcome correctness and employs a buffer probability mechanism
  to mitigate noise in these labels.
---

# FreePRM: Training Process Reward Models Without Ground Truth Process Labels

## Quick Facts
- arXiv ID: 2506.03570
- Source URL: https://arxiv.org/abs/2506.03570
- Authors: Lin Sun; Chuang Liu; Xiaofeng Ma; Tao Yang; Weijia Lu; Ning Wu
- Reference count: 40
- Key outcome: FreePRM achieves 53.0% average F1 score on ProcessBench, outperforming fully supervised baselines by 24.1% and other open-source PRMs by 10.9-24.6%

## Executive Summary
FreePRM introduces a weakly supervised framework for training Process Reward Models without requiring step-level annotations. It generates pseudo step-level labels from final outcome correctness and employs a buffer probability mechanism to mitigate noise in these labels. The method predicts three probabilities per step (right, wrong, buffer) and uses stochastic buffer factors during training to prevent model collapse. Experimental results demonstrate that high-quality process evaluation can be achieved without costly step-level annotations, achieving 53.0% average F1 score on ProcessBench.

## Method Summary
FreePRM trains Process Reward Models using only binary final outcome labels by propagating these labels to all intermediate steps as pseudo-labels. The model outputs three probabilities per step (pr_t for right, pw_t for wrong, pb_t for buffer) constrained to sum to 1. During training, a stochastic buffer factor βt is sampled from Bernoulli(pb_t) to prevent the model from collapsing to assigning maximal buffer probability. The loss function uses weighted cross-entropy with the last step weighted more heavily (αT = 3.0) to leverage its stronger correlation with final outcome correctness.

## Key Results
- FreePRM achieves 53.0% average F1 score on ProcessBench, outperforming fully supervised baselines by 24.1%
- Outperforms other open-source PRMs by 10.9-24.6% on the same benchmark
- Ablation shows last-step weighting (αT = 3.0) improves performance from 34.3% to 49.1% F1 with 20% training data
- Stochastic buffer factor prevents model collapse while absorbing pseudo-label noise

## Why This Works (Mechanism)

### Mechanism 1: Buffer Probability as Gradient Regularizer for Noisy Labels
The buffer probability pb_t reduces overfitting to noisy pseudo-labels by suppressing gradient updates proportionally to uncertainty. For each step t, FreePRM predicts three probabilities (pr_t, pw_t, pb_t) summing to 1. During training, the buffer term is stochastically included via βt ~ Bernoulli(pb_t). The expected gradient with respect to pr_t satisfies ||∂E[Lt]/∂pr_t|| ≤ ||∂LCE_t/∂pr_t|| − (pb_t)², meaning higher buffer confidence induces stronger gradient suppression. This acts as adaptive regularization—uncertain steps receive smaller gradient updates, reducing error propagation from incorrect pseudo-labels.

### Mechanism 2: Stochastic Buffer Factor Prevents Trivial Solution Collapse
Sampling βt from Bernoulli(pb_t) prevents the model from collapsing to assigning maximal buffer probability to all steps, which would otherwise trivially satisfy the loss without learning. Theorem 2.2 shows that when pb_t → 1, the gradient ∂E[Lt]/∂pb_t → −∞, making this configuration dynamically unstable. The stochastic sampling ensures buffer usage is neither guaranteed nor completely suppressed.

### Mechanism 3: Amplified Last-Step Supervision Leverages Stronger Outcome Correlation
Weighting the final reasoning step more heavily (αT > 1) improves performance because the last step has the strongest correlation with final answer correctness. The loss function uses per-step weights αt, with αt = 1 for all steps except the last. For t = T, setting αT > 1 (empirically αT = 3.0 works best) amplifies the gradient contribution from the final step.

## Foundational Learning

- **Concept:** Process Reward Models (PRMs) vs. Outcome Reward Models (ORMs)
  - Why needed here: FreePRM is a PRM training method; understanding that PRMs provide step-level rewards while ORMs only score final outputs is essential to grasp why buffer mechanisms matter.
  - Quick check question: If you only have final-answer correctness labels, would an ORM or PRM be easier to train, and why?

- **Concept:** Weakly Supervised Learning with Noisy Labels
  - Why needed here: FreePRM generates pseudo-labels from outcome correctness, which introduces label noise. Understanding how learning algorithms degrade under label noise (and mitigation strategies like label smoothing, loss correction) contextualizes the buffer mechanism.
  - Quick check question: If 30% of your pseudo-labels are wrong, what happens to a standard cross-entropy classifier trained on them?

- **Concept:** Bernoulli Distribution and Stochastic Gradient Estimation
  - Why needed here: The random buffer factor βt ~ Bernoulli(pb_t) introduces stochasticity into the loss. Understanding unbiased gradient estimators and variance reduction is key to seeing why this prevents collapse without breaking convergence.
  - Quick check question: If you sample βt = 1 with probability 0.7, what is E[βt]?

## Architecture Onboarding

- **Component map:** Input (question + solution) -> Pseudo-labeler (propagates final outcome) -> Three-way classifier (outputs pr, pw, pb) -> Stochastic buffer sampler (draws βt) -> Weighted loss computation -> Backpropagation

- **Critical path:**
  1. Prepare dataset with questions, solutions, and binary final-answer labels (no step labels needed)
  2. For each training batch, generate pseudo-labels via Eq. (1)
  3. Forward pass: model predicts (pr, pw, pb) for each step
  4. Sample βt for each step
  5. Compute loss via Eq. (5)
  6. Backprop and update

- **Design tradeoffs:**
  - Buffer probability capacity vs. collapse risk: Higher buffer capacity absorbs more noise but increases collapse risk; stochastic sampling mitigates but adds gradient variance
  - Last-step weight (αT): Too low underutilizes the strongest signal; too high may overfit to final-step patterns and ignore earlier errors. Paper finds αT = 3.0 optimal
  - Data amount: 20% data yields 49.1% F1; 100% yields 53.0%. Diminishing returns above 80%

- **Failure signatures:**
  - Model predicts pb_t ≈ 1 for all steps: Check if stochastic sampling is correctly implemented; βt should be sampled, not fixed
  - F1 score near random (≈25%): Check pseudo-label generation—final outcome labels may be incorrect or uncorrelated with reasoning quality
  - Training loss does not decrease: Verify last-step weight is not too high (αT > 7 causes degradation per Table 4)

- **First 3 experiments:**
  1. Reproduce the 20% data ablation (Table 2): Train on subset, confirm F1 ≈ 49.1%. If significantly lower, check data sampling and pseudo-label generation
  2. Ablate the random buffer factor (Table 3, row 1 vs. 2): Train without βt sampling (set βt = 1 deterministically), expect performance drop
  3. Sweep last-step weight αT ∈ {1.0, 3.0, 5.0, 7.0} on a validation split, confirm peak at αT = 3.0. If peak differs, dataset characteristics may vary from Math-Shepherd

## Open Questions the Paper Calls Out
- **Open Question 1:** How can FreePRM be effectively combined with automated data annotation techniques to bridge the performance gap with models trained on manually annotated datasets? (Basis: Section 5 calls for exploring hybrid methods)
- **Open Question 2:** Does the buffer probability mechanism generalize effectively to non-mathematical reasoning domains, such as code generation or logical deduction? (Basis: Paper evaluates exclusively on mathematical reasoning tasks)
- **Open Question 3:** How robust is FreePRM to high rates of noise in the final outcome labels used for supervision? (Basis: Method assumes correct final outcome labels but doesn't analyze sensitivity to label noise)

## Limitations
- Performance gap remains with models trained on manually annotated datasets despite strong results
- Limited evaluation to mathematical reasoning tasks, generalizability to other domains unverified
- Assumes strong correlation between final outcome correctness and intermediate step quality, which may not hold for all reasoning tasks

## Confidence

**High Confidence:** The mechanism of stochastic buffer sampling preventing trivial collapse is mathematically sound and experimentally validated. The gradient instability proof (Theorem 2.2) provides strong theoretical grounding, and the ablation studies clearly demonstrate the necessity of random buffer factors.

**Medium Confidence:** The effectiveness of last-step weighting (αT = 3.0) is well-supported by controlled ablations within the Math-Shepherd dataset, but the optimal weight may be dataset-dependent. The claim that buffer probability acts as adaptive regularization is plausible given the gradient analysis, but the practical impact on generalization requires further validation across domains.

**Low Confidence:** The paper's assertion that FreePRM can be applied to any domain with binary outcome labels assumes strong correlation between final outcome correctness and intermediate step quality, which may not hold for tasks where multiple reasoning paths lead to the same answer. The lack of experiments beyond mathematical reasoning leaves this assumption unverified.

## Next Checks

1. **Cross-Domain Validation:** Apply FreePRM to a non-mathematical reasoning domain (e.g., code generation or logical reasoning) with binary outcome labels and evaluate whether the buffer mechanism provides similar performance gains.

2. **Noise Sensitivity Analysis:** Systematically vary the pseudo-label noise rate by corrupting a fraction of final outcome labels and measure FreePRM's performance degradation. Compare against standard PRM training to quantify the buffer mechanism's robustness to label noise.

3. **Buffer Mechanism Ablation with Controlled Collapse:** Train a variant of FreePRM without stochastic buffer sampling (deterministic βt = 1) and monitor the model's tendency to collapse to all-buffer predictions. This would provide direct empirical evidence for the collapse prevention mechanism described in Theorem 2.2.