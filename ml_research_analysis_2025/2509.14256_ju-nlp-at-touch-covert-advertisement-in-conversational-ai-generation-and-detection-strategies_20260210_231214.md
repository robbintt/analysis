---
ver: rpa2
title: "JU-NLP at Touch\xE9: Covert Advertisement in Conversational AI-Generation\
  \ and Detection Strategies"
arxiv_id: '2509.14256'
source_url: https://arxiv.org/abs/2509.14256
tags:
- generation
- response
- responses
- advertisement
- promotional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework for generating and detecting
  covert advertisements in conversational AI systems. For generation, it uses a preference-tuned
  Mistral-7B model with Retrieval- and Cache-Augmented Generation to embed subtle
  promotional content, achieving high stealth with precision 1.0 and recall 0.71.
---

# JU-NLP at TouchÃ©: Covert Advertisement in Conversational AI-Generation and Detection Strategies

## Quick Facts
- arXiv ID: 2509.14256
- Source URL: https://arxiv.org/abs/2509.14256
- Reference count: 20
- This paper introduces a framework for generating and detecting covert advertisements in conversational AI systems, achieving high stealth with precision 1.0 and recall 0.71 for generation, and F1-scores between 0.99 and 1.00 for detection.

## Executive Summary
This work presents a comprehensive framework for both generating and detecting covert advertisements in conversational AI systems. The generation approach uses a preference-tuned Mistral-7B model with Retrieval- and Cache-Augmented Generation to embed subtle promotional content into conversations. For detection, the system employs two methods analyzing response text alone: a fine-tuned CrossEncoder (all-mpnet-base-v2) and a prompt-based DeBERTa-v3 model. The research demonstrates effective balance between persuasive communication and transparency, enabling controlled ad integration and robust detection in AI-mediated conversations.

## Method Summary
The generation framework employs a preference-tuned Mistral-7B model optimized for stealth via ORPO fine-tuning on preference pairs. It uses Retrieval-Augmented Generation (RAG) to incorporate relevant context from a curated knowledge base and Cache-Augmented Generation to maintain conversation consistency. The detection system consists of two complementary approaches: a CrossEncoder fine-tuned on all-mpnet-base-v2 for text classification, and a prompt-based DeBERTa-v3 model that analyzes response text alone. The evaluation framework uses a custom dataset with human-annotated advertisements and employs LLM-as-a-judge methodology using Mistral-7B for scoring detectability during preference optimization.

## Key Results
- Generation framework achieves precision 1.0 and recall 0.71 for covert advertisement insertion
- Detection models reach F1-scores between 0.99 and 1.00 analyzing response text alone
- CrossEncoder detection shows 0.977 precision but only 0.346 recall, indicating detection challenges with diverse ad styles
- Preference-tuning successfully balances advertisement integration with conversation naturalness

## Why This Works (Mechanism)
The framework's effectiveness stems from the preference-tuned Mistral-7B model's ability to learn subtle advertisement insertion patterns through ORPO optimization. The combination of RAG and cache augmentation ensures contextual relevance while maintaining conversation flow. For detection, the CrossEncoder's strong performance on response text analysis demonstrates the distinct linguistic patterns of covert advertisements, while the DeBERTa-v3 model provides complementary detection capabilities through prompt-based analysis.

## Foundational Learning
- **Retrieval-Augmented Generation (RAG)**: Needed to incorporate relevant external knowledge for contextually appropriate ad placement; quick check: verify retrieval relevance scores for inserted advertisements
- **ORPO Fine-tuning**: Required for optimizing advertisement stealth through preference learning; quick check: validate preference pair selection methodology
- **CrossEncoder Architecture**: Essential for efficient text classification in detection; quick check: examine attention weights for distinguishing features
- **Prompt-based DeBERTa-v3**: Used for flexible text analysis without extensive fine-tuning; quick check: test prompt variations for detection robustness
- **LLM-as-a-judge**: Enables scalable evaluation of advertisement detectability; quick check: compare judge scores with human annotations
- **Cache-Augmented Generation**: Maintains conversation consistency across multi-turn interactions; quick check: verify cache hit rates during conversation generation

## Architecture Onboarding

**Component Map:**
RAG Retriever -> Mistral-7B Generator -> Cache Manager -> Preference Tuner -> Detection Models (CrossEncoder, DeBERTa-v3)

**Critical Path:**
User Input -> RAG Retriever (context retrieval) -> Mistral-7B Generator (ad insertion) -> Cache Manager (consistency) -> Response Output -> Detection Models (analysis)

**Design Tradeoffs:**
- Preference-tuning vs. explicit control: ORPO provides stealth but lacks transparency in decision-making
- Response-only detection vs. multi-turn analysis: Simpler but may miss contextual cues
- LLM judge vs. human evaluation: Scalable but potentially biased toward model-specific patterns

**Failure Signatures:**
- Low cache hit rates indicating conversation flow disruption
- Preference-tuning overfitting to judge model rather than general stealth
- Detection models showing high precision but low recall indicating missed advertisements

**First Experiments:**
1. Test generation framework across three diverse conversational domains (customer service, casual chat, technical support)
2. Conduct adversarial evaluation with human testers attempting to evade detection models
3. Implement live conversational simulation with user interaction tracking to measure multi-turn dynamics

## Open Questions the Paper Calls Out
### Open Question 1
How can the proposed generation framework be extended to ensure the generated advertisements are explainable and controllable rather than operating as a black-box preference optimization?

### Open Question 2
Can the CrossEncoder detection approach be modified to achieve a viable recall rate for real-world deployment?

### Open Question 3
Does the "LLM-as-a-judge" methodology using Mistral-7B align with human perception of advertisement stealth, or does it suffer from model-specific blind spots?

## Limitations
- Generation framework may not generalize to all conversational contexts or domains
- High precision but lower recall (0.71) in covert advertisement generation limits opportunity capture
- Detection evaluation uses controlled test conditions that may not reflect live conversational complexity
- Preference-tuning approach lacks transparency in advertisement insertion decision-making

## Confidence
- **High confidence** in technical implementation and baseline performance metrics
- **Medium confidence** in generalizability across different conversational domains
- **Medium confidence** in detection framework's robustness against adaptive adversaries

## Next Checks
1. Test the generation framework across diverse conversational domains to assess domain transfer and identify context-specific limitations
2. Conduct adversarial evaluation by having human testers attempt to craft conversations that evade the detection models, measuring false negative rates under attack scenarios
3. Implement the system in a simulated live conversational environment with user interaction tracking to measure how timing, user engagement patterns, and multi-turn dynamics affect both generation stealth and detection accuracy