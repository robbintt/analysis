---
ver: rpa2
title: 'Multi-Stage Generative Upscaler: Reconstructing Football Broadcast Images
  via Diffusion Models'
arxiv_id: '2503.11181'
source_url: https://arxiv.org/abs/2503.11181
tags:
- image
- images
- diffusion
- lora
- reconstruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study introduces a multi-stage generative upscaling framework\
  \ leveraging Diffusion Models to reconstruct low-resolution football broadcast images.\
  \ The approach combines image-to-image pipelines, ControlNet conditioning, and LoRA\
  \ fine-tuning to transform inputs as small as 64 \xD7 64 pixels into high-fidelity\
  \ 1024 \xD7 1024 outputs."
---

# Multi-Stage Generative Upscaler: Reconstructing Football Broadcast Images via Diffusion Models

## Quick Facts
- arXiv ID: 2503.11181
- Source URL: https://arxiv.org/abs/2503.11181
- Reference count: 40
- This study introduces a multi-stage generative upscaling framework leveraging Diffusion Models to reconstruct low-resolution football broadcast images.

## Executive Summary
This study introduces a multi-stage generative upscaling framework leveraging Diffusion Models to reconstruct low-resolution football broadcast images. The approach combines image-to-image pipelines, ControlNet conditioning, and LoRA fine-tuning to transform inputs as small as 64 × 64 pixels into high-fidelity 1024 × 1024 outputs. The framework addresses challenges in sports broadcasting where detailed visuals are essential for analysis and audience engagement. By training a custom LoRA on a football-specific dataset, the method restores intricate textures, sharp edges, and domain-specific elements such as player details and jersey logos. Experimental results demonstrate substantial improvements over conventional models, with ControlNet refining fine details and LoRA enhancing task-specific elements.

## Method Summary
The framework employs a two-stage diffusion pipeline. Stage 1 uses FLUX.1-dev's Img2Img pipeline with strength=0.75 to denoise and reconstruct global structure from severely degraded inputs. Stage 2 applies ControlNet conditioning to the Stage 1 output, sharpening textures and fine details with conditioning_scale=0.5-0.65. A LoRA model is fine-tuned on a custom football dataset (460 images) using KohyaSS to enhance domain-specific elements like logos and player anatomy. The entire pipeline operates at 1024×1024 resolution with bfloat16 precision and CPU offloading to manage VRAM constraints.

## Key Results
- Multi-stage pipeline successfully reconstructs 64×64 inputs to 1024×1024 outputs with restored textures and sharp edges
- ControlNet refinement significantly improves detail recovery compared to single-stage approaches
- LoRA fine-tuning on football-specific dataset corrects domain-specific artifacts like fused player anatomy
- Framework demonstrates superior performance to conventional models for extreme low-resolution inputs

## Why This Works (Mechanism)

### Mechanism 1
If the input degradation is extreme (e.g., 64x64 pixels), a sequential coarse-to-fine approach likely outperforms single-stage upscaling. The framework decouples structural restoration from texture refinement. The first stage (Img2Img) uses a high `strength` parameter (0.75) to "hallucinate" missing structural data while ignoring fine texture. The second stage (ControlNet) then conditions on this structurally-sound intermediate image to sharpen edges and details, which the paper notes is impossible if ControlNet is applied directly to raw, heavily degraded inputs.

### Mechanism 2
Conditioning the diffusion process with ControlNet likely allows for high-frequency detail recovery without losing global image coherence. ControlNet adds a trainable copy of the diffusion model's encoder layers (zero-convolution blocks) that process the degraded image as a conditioning map. This guides the denoising U-Net/DiT to focus on texture completion (grass, fabric) conditioned on the spatial layout of the intermediate image.

### Mechanism 3
Low-Rank Adaptation (LoRA) fine-tuning on a domain-specific dataset likely improves the reconstruction of semantic entities (logos, anatomy) that generic models fail to resolve. By training low-rank matrices on a custom dataset of football images, the model updates its weights to recognize domain-specific patterns (e.g., jersey textures, player separation) without losing the general priors of the large base model.

## Foundational Learning

- **Concept: Diffusion Image-to-Image (Img2Img)**
  - **Why needed here:** This is the Stage 1 engine. You must understand how the `strength` parameter controls the trade-off between preserving the input's pixel layout and generating new details.
  - **Quick check question:** If `strength` is set to 1.0, does the pipeline still use the input image?

- **Concept: ControlNet Architecture**
  - **Why needed here:** This drives Stage 2. You need to understand how "zero convolution" layers allow the model to learn conditional controls without destroying the pre-trained base model's capabilities.
  - **Quick check question:** Why does the paper apply ControlNet to the Stage 1 output rather than the original raw image?

- **Concept: LoRA (Low-Rank Adaptation)**
  - **Why needed here:** Used for domain adaptation. You need to grasp how decomposing weight updates into low-rank matrices drastically reduces VRAM requirements.
  - **Quick check question:** What is the relationship between Network Rank (`network_dim`) and Network Alpha in the training script?

## Architecture Onboarding

- **Component map:** Raw 64x64-100x100 input -> Lanczos resize to 1024x1024 -> Stage 1 (FLUX.1-dev Img2Img, strength=0.75) -> Stage 2 (FLUX + ControlNet Upscaler, conditioning_scale=0.5-0.65) -> LoRA enhancement (optional)
- **Critical path:** The Preprocess -> Stage 1 -> Stage 2 sequence is strictly linear. The paper explicitly warns against bypassing Stage 1, as ControlNet fails on "raw image frames" due to extreme noise.
- **Design tradeoffs:** High strength in Stage 1 reconstructs more structure but risks hallucinations; low strength preserves the original but leaves it blurry. FLUX.1-dev requires ~24GB+ VRAM, so the paper uses `enable_model_cpu_offload` and `bfloat16`, trading inference speed for memory feasibility.
- **Failure signatures:** "Fused Anatomy" (e.g., legs merging) indicates the base model lacks domain-specific priors. -> *Fix: Apply LoRA.* "Blurry Output" indicates insufficient denoising steps or low `controlnet_conditioning_scale`. -> *Fix: Increase steps to 35+ or conditioning to 0.65.*
- **First 3 experiments:** 1) Run a raw image directly through the ControlNet Upscaler (skipping Stage 1) to verify the "extremely poor" result. 2) Sweep `strength` [0.5, 0.75, 0.9] in Stage 1 on a 64x64 input to find structural coherence breakdown. 3) Run Stage 2 on a "fused leg" image with and without trained LoRA weights to isolate semantic correction effect.

## Open Questions the Paper Calls Out

### Open Question 1
Will scaling the training dataset to over 5,000 images significantly improve the model's ability to reconstruct intricate text details, such as jersey logos? The Conclusion states future work will focus on scaling the dataset to refine details, specifically noting that recreating shirt logo writings remains a challenge.

### Open Question 2
Can a fine-tuned Vision Model replace external AI services for generating metadata captions without compromising reconstruction quality? The authors plan to explore fine-tuning a Vision Model for automatic, offline captioning to reduce reliance on external services like ChatGPT Plus.

### Open Question 3
Can a parallel execution strategy effectively automate the selection of the optimal reconstruction path given the inconsistent performance of LoRA in the first stage? The authors propose a parallel execution strategy because applying LoRA during the first reconstruction stage sometimes introduces inconsistencies or degrades results compared to the non-LoRA baseline.

## Limitations
- Dataset generalization is limited as the LoRA model is trained on a proprietary football dataset (460 images) without demonstrated cross-domain robustness
- The study lacks quantitative metrics (e.g., PSNR, SSIM, FID) and relies on qualitative visual comparisons
- Architectural novelty is primarily in sports application rather than fundamental architectural innovation

## Confidence

**High Confidence:** The efficacy of the two-stage (Img2Img → ControlNet) pipeline for handling extreme degradation is well-supported by ablation results and aligned with diffusion model best practices.

**Medium Confidence:** The necessity of LoRA for domain-specific elements (logos, anatomy) is demonstrated through qualitative examples, but the small training set size (460 images) raises questions about scalability and generalization.

**Low Confidence:** The claim of "substantial improvements over conventional models" lacks quantitative backing and direct comparison to state-of-the-art image SR methods outside the diffusion family.

## Next Checks

1. **Quantitative Benchmarking:** Replicate the pipeline on a public football dataset (e.g., SoccerNet) and report standard image quality metrics (PSNR, SSIM, LPIPS) against non-diffusion baselines (e.g., Real-ESRGAN, SwinIR).

2. **LoRA Generalization Test:** Train the LoRA on a larger, diverse football dataset and evaluate its ability to reconstruct unseen teams/kit designs without overfitting.

3. **Ablation on Degradation Levels:** Systematically test the pipeline on a range of input resolutions (16×16 to 128×128) to identify the lower bound of effective reconstruction and failure modes.