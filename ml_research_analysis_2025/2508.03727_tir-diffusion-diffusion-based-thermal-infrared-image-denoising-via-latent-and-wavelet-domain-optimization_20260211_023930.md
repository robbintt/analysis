---
ver: rpa2
title: 'TIR-Diffusion: Diffusion-based Thermal Infrared Image Denoising via Latent
  and Wavelet Domain Optimization'
arxiv_id: '2508.03727'
source_url: https://arxiv.org/abs/2508.03727
tags:
- image
- wavelet
- dtcwt
- denoising
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes TIR-Diffusion, a diffusion-based denoising
  framework for thermal infrared images that leverages pretrained Stable Diffusion
  models with wavelet-domain optimization. The method addresses TIR-specific fixed-pattern
  noise by combining latent-space and wavelet-domain loss functions, along with cascaded
  refinement for enhanced detail preservation.
---

# TIR-Diffusion: Diffusion-based Thermal Infrared Image Denoising via Latent and Wavelet Domain Optimization

## Quick Facts
- **arXiv ID**: 2508.03727
- **Source URL**: https://arxiv.org/abs/2508.03727
- **Reference count**: 29
- **Key outcome**: Proposes TIR-Diffusion, a diffusion-based denoising framework for thermal infrared images that leverages pretrained Stable Diffusion models with wavelet-domain optimization, achieving PSNR of 27.97 dB and SSIM of 0.8594 on benchmark datasets.

## Executive Summary
This paper introduces TIR-Diffusion, a novel diffusion-based framework for thermal infrared image denoising that addresses the challenge of fixed-pattern noise (FPN) in TIR imagery. The method leverages pretrained Stable Diffusion models through fine-tuning, combining latent-space and wavelet-domain optimization to achieve superior denoising performance. By decomposing images into wavelet sub-bands and optimizing frequency-specific losses, the framework effectively separates noise from thermal features while preserving structural details. Experiments demonstrate state-of-the-art performance on benchmark datasets and robust zero-shot generalization to unseen challenging TIR datasets, highlighting its practical utility for robotic perception in poor visibility conditions.

## Method Summary
TIR-Diffusion is a two-stage diffusion-based denoising framework that fine-tunes pretrained Stable Diffusion v1-4 U-Net for thermal infrared image denoising. The method encodes noisy TIR images into latent space using a frozen VAE, then applies a Conditioning Projection Module to transform latents into cross-attention embeddings. The U-Net denoising process is guided by a combined loss function that includes latent-space MSE/SSIM loss and wavelet-domain MSE loss computed on 2-level DWT/DTCWT decompositions. A cascaded refinement stage can optionally enhance fine details using pixel-wise MSE and LPIPS losses. The approach addresses TIR-specific FPN by leveraging frequency-specific wavelet analysis while benefiting from transferable visual priors learned from RGB datasets.

## Key Results
- Achieves PSNR of 27.97 dB and SSIM of 0.8594 on benchmark TIR denoising datasets
- Superior performance compared to state-of-the-art methods across multiple metrics (PSNR, SSIM, LPIPS, FID)
- Demonstrates robust zero-shot generalization to unseen challenging TIR datasets including OdomBeyondVision
- Wavelet-domain optimization provides significant improvements over latent-space only approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Wavelet-domain loss enables frequency-specific learning that separates fixed-pattern noise from structural thermal features.
- Mechanism: The 2D DWT/DTCWT decomposes images into horizontal (Y_h), vertical (Y_v), and diagonal (Y_d) high-frequency sub-bands. By computing MSE between predicted and ground-truth wavelet coefficients, the model explicitly penalizes noise in frequency components where TIR fixed-pattern noise manifests, while preserving low-frequency thermal structure.
- Core assumption: TIR fixed-pattern noise concentrates in specific high-frequency sub-bands that are separable from true image texture in the wavelet domain.
- Evidence anchors:
  - [abstract] "fine-tunes the model via a novel loss function combining latent-space and discrete wavelet transform (DWT) / dual-tree complex wavelet transform (DTCWT) losses"
  - [section I, Fig. 1] "Wavelet transform robustly distinguishes and separates severe non-uniform fixed-pattern noise (FPN) specific to TIR images"
  - [section IV-C, Table III] Energy ratio analysis showing Biorthogonal wavelet achieves 14.91% ratio for horizontal coefficients (clean vs. noisy), indicating strong noise separation
- Break condition: If FPN has significant low-frequency components or overlaps spectrally with fine thermal textures, wavelet-domain separation degrades.

### Mechanism 2
- Claim: Pretrained Stable Diffusion priors compensate for scarce TIR training data through transferable visual representations.
- Mechanism: Rather than training from scratch on limited TIR pairs (~5,570 images), the method fine-tunes Stable Diffusion v1-4's U-Net. The Conditioning Projection Module converts noisy TIR latents into cross-attention embeddings, leveraging pretrained spatial reasoning capabilities for thermal denoising.
- Core assumption: Low-level visual features (edges, spatial coherence, texture patterns) learned from RGB datasets transfer to thermal infrared despite different imaging physics.
- Evidence anchors:
  - [abstract] "Utilizing a pretrained stable diffusion model, our method fine-tunes the model"
  - [section I] "With works utilizing real images [10], the amount of data is insufficient to train a deep neural network from the ground up"
  - [section III-D] "This adaptation enables the model to capture and address the distinct noise characteristics of thermal imagery"
  - [corpus] Weak direct evidence in corpus; no comparable diffusion-based TIR denoising works found
- Break condition: If thermal image statistics (intensity distributions, edge characteristics) diverge fundamentally from RGB priors, fine-tuning provides diminishing returns.

### Mechanism 3
- Claim: Cascaded refinement decouples global structure reconstruction from perceptual detail enhancement.
- Mechanism: Two-stage pipeline—first model optimizes latent + wavelet losses for noise removal and structure preservation; second model takes interim output and applies pixel-wise MSE + LPIPS losses for fine detail refinement. This prevents single-model tradeoffs between denoising aggressiveness and detail preservation.
- Core assumption: Separating structural denoising from perceptual refinement yields better fidelity than joint optimization of all loss terms.
- Evidence anchors:
  - [abstract] "implement a cascaded refinement stage to enhance fine details, ensuring high-fidelity denoising results"
  - [section III-B] "Concatenating the DWT/DTCWT Model with a Pixel-wise Loss Model for finer output"
  - [Table I] Cascaded DTCWT achieves best LPIPS (0.1529) and FID (38.1301), though PSNR slightly lower than non-cascaded DTCWT (26.53 vs 27.97 dB)
- Break condition: If cascaded pixel-level optimization introduces artifacts that contradict wavelet-domain constraints, final quality degrades.

## Foundational Learning

- Concept: 2D Discrete Wavelet Transform (DWT)
  - Why needed here: The core innovation uses wavelet sub-bands as supervision. Understanding how DWT decomposes images into LL (low-pass), LH (horizontal), HL (vertical), and HH (diagonal) components is essential for interpreting the loss design.
  - Quick check question: Given a TIR image with horizontal strip noise, which wavelet sub-band would show the highest energy discrepancy between noisy and clean versions?

- Concept: Latent Diffusion Models and VAE Encoding
  - Why needed here: The method operates in Stable Diffusion's 4-channel latent space rather than pixel space. Understanding VAE encoder/decoder and U-Net denoising mechanics is prerequisite for implementing the Conditioning Projection Module.
  - Quick check question: Why does latent-space loss (MSE + SSIM on z rather than x) provide better global structure preservation than pixel-space loss?

- Concept: Fixed-Pattern Noise vs. Gaussian Noise
  - Why needed here: TIR-specific FPN is spatially correlated and non-uniform, fundamentally different from synthetic Gaussian noise used in prior works. This motivates wavelet-domain approaches.
  - Quick check question: Why would a CNN trained on Gaussian noise fail to generalize to real TIR strip noise patterns?

## Architecture Onboarding

- Component map:
  - VAE Encoder -> Conditioning Projection Module -> U-Net (Fine-tuned SD v1-4) -> VAE Decoder
  - Parallel: Wavelet Loss Module (DWT/DTCWT decomposition)
  - Optional: Cascaded Model (Second U-Net for pixel-level refinement)

- Critical path:
  1. Noisy TIR input → VAE encoder → z_noisy
  2. z_noisy → Conditioning Projection → cross-attention embeddings
  3. U-Net denoising (conditioned on embeddings) → z_hat
  4. Parallel: z_hat vs. z_gt → Latent Loss (MSE + SSIM)
  5. Parallel: x_hat vs. x_gt → DWT/DTCWT → Wavelet Loss
  6. Combined loss backprop through U-Net
  7. (If cascaded) x_hat → Second U-Net with pixel-wise loss → final output

- Design tradeoffs:
  - **DWT vs. DTCWT**: DTCWT offers better directionality and shift-invariance (best PSNR: 27.97 dB), but Biorthogonal DWT shows better SSIM (0.8594). Choose DTCWT for perceptual quality, Biorthogonal for structural fidelity.
  - **Cascaded vs. Single-Stage**: Cascading improves LPIPS/FID at slight PSNR cost. Deploy cascaded for human-viewed outputs; single-stage for downstream vision tasks requiring pixel accuracy.
  - **Latent-only vs. Wavelet-augmented**: Wavelet loss adds ~1.7 dB PSNR improvement over latent-only baseline (Table I: 26.28 → 27.97 dB for DTCWT).

- Failure signatures:
  - **Over-smoothing**: Excessive latent loss weight (α) relative to wavelet loss (β) loses fine thermal gradients. Current setting: α=1.0, β=100.
  - **Wavelet artifacts**: If j=1 decomposition used, high-frequency noise leaks into reconstruction. Paper uses j=2.
  - **Cascaded degradation**: If interim denoised image has residual noise, cascaded model amplifies artifacts through LPIPS perceptual loss.
  - **Zero-shot failure**: On datasets with fundamentally different noise statistics (e.g., indoor vs. outdoor), Conditioning Projection may not generalize.

- First 3 experiments:
  1. **Wavelet ablation**: Train latent-only baseline vs. DWT vs. DTCWT variants on same split. Verify PSNR/SSIM improvements match Table I before proceeding.
  2. **Loss weight sensitivity**: Sweep β ∈ [10, 50, 100, 200] with fixed α=1.0. Monitor if wavelet loss dominates (artifacts) or under-contributes (noise remains).
  3. **Zero-shot generalization test**: Apply trained model to OdomBeyondVision dataset (unseen indoor scenes). Compare qualitatively against Fig. 4 results to validate robustness claims before deployment.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the framework be extended to effectively condition on specific environmental factors, such as indoor versus outdoor scenes, by utilizing larger quantities of paired datasets?
- Basis in paper: [explicit] The conclusion states, "Future work includes extending the framework greater quantities of paired datasets, allowing effective conditioning of factors including indoor and outdoor."
- Why unresolved: The current implementation does not separate or condition based on scene types, and the authors currently rely on a limited dataset which may not capture the full variance of these environments.
- What evidence would resolve it: A study demonstrating improved denoising metrics when the model is trained on a larger dataset with explicit conditioning tokens for environmental contexts.

### Open Question 2
- Question: Can the trade-off between perceptual realism and structural fidelity observed in the cascaded model be mitigated?
- Basis in paper: [inferred] The authors note that while cascaded models improve LPIPS and FID, they show "mixed results in PNSR and SSIM," implying a sacrifice in exact pixel alignment for improved realism.
- Why unresolved: The paper presents the cascaded architecture as is, without proposing a method to recover the lost pixel-level accuracy (PSNR/SSIM) while retaining the perceptual gains.
- What evidence would resolve it: An architectural modification or loss function adjustment that demonstrates superior performance in all four metrics (PSNR, SSIM, LPIPS, FID) simultaneously compared to the single-stage model.

### Open Question 3
- Question: Is the proposed framework computationally efficient enough for real-time applications in robotic perception?
- Basis in paper: [inferred] The paper highlights "practical robotic deployment" and "robotic perception tasks" as key applications, yet diffusion models are typically computationally expensive, and no inference time or computational complexity analysis is provided.
- Why unresolved: The absence of latency benchmarks makes it difficult to determine if the method is viable for time-sensitive robotic tasks like collision avoidance or SLAM.
- What evidence would resolve it: Benchmarks of inference time (FPS) and memory usage on standard robotic hardware (e.g., embedded GPUs).

## Limitations

- Limited cross-domain validation across diverse TIR noise profiles (outdoor/urban vs. indoor/industrial) raises concerns about generalization robustness
- No ablation studies comparing against RGB-trained baselines to empirically validate transferable visual priors assumption
- Critical hyperparameters (β=100 for wavelet loss, α=1.0 for latent loss) lack sensitivity analysis or justification for specific values

## Confidence

- **High Confidence**: PSNR/SSIM improvements on the primary test set (27.97 dB, 0.8594) are reproducible given specified architecture and training setup
- **Medium Confidence**: Cascaded refinement benefits (LPIPS/FID improvements) are supported but require careful hyperparameter tuning to avoid artifacts
- **Low Confidence**: Zero-shot generalization claims lack sufficient cross-dataset validation to establish robustness in real-world deployment scenarios

## Next Checks

1. **Cross-Domain Generalization Test**: Apply the trained model to at least two additional TIR datasets with distinct noise characteristics (e.g., different sensor types, environmental conditions) and report quantitative performance drops
2. **Pretrained Prior Ablation**: Train a baseline diffusion model from scratch on the TIR dataset and compare against fine-tuned Stable Diffusion to quantify the contribution of transferable priors
3. **Hyperparameter Sensitivity Analysis**: Systematically vary β ∈ [10, 50, 100, 200] and α ∈ [0.1, 1.0, 10.0] while monitoring trade-offs between PSNR, SSIM, and perceptual metrics