---
ver: rpa2
title: Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding
arxiv_id: '2509.04009'
source_url: https://arxiv.org/abs/2509.04009
tags:
- spurious
- images
- token
- m-tsi
- correlations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of detecting spurious correlations
  in vision transformers (ViTs), which can lead models to make correct predictions
  based on incorrect or unintended features. The authors propose a novel method that
  leverages token discarding, an intrinsic property of ViTs, to identify influential
  tokens that contribute to model predictions.
---

# Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding

## Quick Facts
- **arXiv ID:** 2509.04009
- **Source URL:** https://arxiv.org/abs/2509.04009
- **Reference count:** 40
- **Primary result:** Method detects spurious correlations in ViTs by analyzing token influence relative to bounding boxes

## Executive Summary
This paper introduces a novel method for detecting spurious correlations in vision transformers by leveraging token discarding, an intrinsic property of ViTs. The authors propose measuring how individual token removal affects model predictions to identify influential tokens, then compare these influences inside versus outside object bounding boxes using two metrics: A-TSI and M-TSI. Through extensive experiments on ImageNet with supervised, DINO, and MAE-trained models, they demonstrate that their method effectively identifies spurious correlations and reveals that training methodology significantly impacts reliance on such correlations, with DINO showing the least dependence.

## Method Summary
The method systematically removes individual tokens from a ViT's input sequence and measures the resulting change in prediction confidence to identify influential tokens. For each image, tokens are discarded one at a time (196 forward passes total), and the influence score for each token is computed as the absolute difference in confidence for the correct class. These influence scores are then compared between tokens inside and outside the object's bounding box to compute two spuriosity metrics: A-TSI (average influence ratio) and M-TSI (maximum influence ratio). A TSI > 1 indicates spurious correlation. The method requires bounding box annotations and is applied to three ViT-B/16 models trained with different methodologies (supervised, DINO, MAE) on the ImageNet validation set.

## Key Results
- DINO-trained models show significantly lower spurious correlation reliance (mean M-TSI 0.35) compared to supervised (0.64) and MAE (0.68) models
- M-TSI is more effective for detecting spurious correlations when objects are small, while A-TSI is more reliable for larger objects
- Certain ImageNet classes contain spurious signals that models easily detect, with problematic images identified and listed
- Token influence masking causes larger confidence drops than GradCAM-based masking (e.g., 0.20 vs 0.11 for 20 tokens in supervised ViT)

## Why This Works (Mechanism)

### Mechanism 1: Token Influence via Systematic Discarding
Removing tokens individually and measuring prediction confidence changes identifies which image regions the model relies on. For each of 196 tokens, compute z_k = |ŷ − ŷ_(-k)| where ŷ_(-k) is prediction confidence after removing token k. Higher z_k indicates greater token influence. Evidence: token influence masking causes larger confidence drops than GradCAM (table 1).

### Mechanism 2: TSI Quantification via Bounding Box Comparison
Comparing token influence inside versus outside annotated bounding boxes quantifies spurious correlation reliance. A-TSI = (average influence outside) / (average influence inside); M-TSI = (max influence outside) / (max influence inside). TSI > 1 indicates spurious correlation. Evidence: images sorted by M-TSI show progressively more attention outside bounding boxes (figure 6).

### Mechanism 3: Training Methodology Affects Spurious Reliance
Self-supervised training (particularly DINO) reduces spurious correlation reliance compared to supervised training. DINO's distillation-based training transfers robust features between teacher-student networks, reducing shortcut learning. Evidence: DINO shows lowest mean M-TSI (0.35) vs Supervised (0.64) and MAE (0.68) on correctly classified images.

## Foundational Learning

- **Vision Transformer tokenization**
  - Why needed: Method operates on 16×16 patches (196 tokens for 224×224 images); understanding granularity is essential
  - Quick check: Given a 224×224 image, how many tokens does ViT-B/16 produce, and what spatial resolution does each token represent?

- **Spurious correlations vs. core features**
  - Why needed: Paper distinguishes semantically meaningful features (core) from statistically predictive but incidental features (non-core/spurious)
  - Quick check: If a model classifies "water bottle" images using only the background table surface, is this a core or spurious feature?

- **Missingness bias in CNNs vs. ViTs**
  - Why needed: Token discarding in ViTs avoids artifacts introduced by masking/padding in CNNs, enabling cleaner influence measurement
  - Quick check: Why does blacking out image regions in CNNs introduce bias, but removing tokens in ViTs does not?

## Architecture Onboarding

- **Component map:** Input image (224×224) → Patch embedding (196 tokens) → Transformer encoder → [CLS] token → MLP head → Prediction → Token influence module (systematic token removal → confidence delta → influence map) → TSI computation (influence map + bounding box → A-TSI/M-TSI)

- **Critical path:** 1) Filter dataset (remove DL images, split into DC and DI) 2) For each image: generate token influence map (196 forward passes) 3) Compute A-TSI and M-TSI by comparing influence inside/outside bounding box

- **Design tradeoffs:** A-TSI vs. M-TSI (A-TSI more stable for large objects; M-TSI more sensitive for small objects but noisier); Token influence vs. attention maps (influence requires 196 forward passes but more reliable; attention maps are fast but model-dependent); Annotation requirement (bounding boxes needed; attention maps can substitute but reduce correlation)

- **Failure signatures:** Flat influence maps (model insensitive to individual tokens); High TSI on correctly classified images (dataset annotation issues); Low correlation between attention-based and token-influence TSI (model not DINO-style self-supervised)

- **First 3 experiments:** 1) Baseline TSI distribution (compute A-TSI/M-TSI on DC subset, verify DINO shows lowest mean TSI ~0.35 vs 0.64 supervised) 2) Token influence vs. GradCAM comparison (mask top-k tokens, confirm influence causes larger confidence drops ~1.5-2× higher delta) 3) Object size stratification (group by bbox token coverage, verify M-TSI most sensitive for 1-40 token group)

## Open Questions the Paper Calls Out

### Open Question 1
Can consistent patterns in the feature representations of intermediate ViT layers be leveraged to identify spurious correlations without relying on bounding boxes or high-cost token masking? The authors state in the Conclusion: "In future work, our goal is to extend the concept of TSI... to investigate whether consistent patterns in the feature representations of intermediate ViT layers can be leveraged... without relying on bounding boxes." This is unresolved because the current method requires either external annotations or computationally expensive token discarding.

### Open Question 2
Can the Token Spuriosity Index (TSI) framework be effectively generalized to Natural Language Processing (NLP) and multimodal transformer architectures? In Section 6.1, the authors suggest: "Future research could explore how TSI can be effectively integrated into various transformer-based models beyond vision, including natural language processing and multimodal architectures." This is unresolved because the study exclusively validated TSI on vision transformers.

### Open Question 3
Is there a reliable automated proxy for bounding boxes that works effectively for supervised and generative self-supervised models (like MAE) where attention maps fail? Section 5.1.2 notes that using attention maps as a substitute for bounding boxes yields high correlation for DINO but low correlation for supervised and MAE models. This is unresolved because the reliability of TSI without annotations currently depends on the training paradigm.

## Limitations

- Requires bounding box annotations, limiting applicability to datasets without detailed spatial labeling
- Token-discarding approach requires 196 forward passes per image, creating substantial computational overhead
- Assumes tokens outside bounding boxes are inherently spurious, which may not hold for context-dependent features

## Confidence

**High Confidence:**
- Token influence maps successfully identify which tokens contribute most to predictions
- DINO-trained models show lower reliance on spurious correlations compared to supervised training
- M-TSI is more effective for detecting spurious correlations when objects are small
- A-TSI is more reliable for detecting spurious correlations when objects are large

**Medium Confidence:**
- Token discarding method is superior to attention-based approaches for detecting spurious correlations
- Certain ImageNet classes contain more spurious signals than others
- Training methodology significantly impacts spurious correlation reliance

**Low Confidence:**
- Method can generalize to detect spurious correlations in real-world deployment scenarios
- TSI scores directly correlate with model robustness or generalization performance
- Method can identify all types of spurious correlations, including those based on texture, context, or temporal patterns

## Next Checks

1. **Cross-architecture validation:** Apply token discarding method to different ViT variants (ViT-S, ViT-L, ConvNeXt-ViT) and architectures with different patch sizes to verify results are not architecture-specific.

2. **Dataset generalization test:** Validate method on alternative datasets with bounding box annotations (COCO, Open Images) and synthetic datasets with controlled spurious correlations to assess whether method identifies known spurious patterns.

3. **Computational efficiency benchmark:** Compare computational cost of token discarding (196 forward passes) against alternative influence measurement methods and evaluate whether approximation techniques can maintain accuracy while reducing runtime by 50-80%.