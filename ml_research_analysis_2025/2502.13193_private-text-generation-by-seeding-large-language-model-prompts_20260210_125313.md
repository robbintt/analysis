---
ver: rpa2
title: Private Text Generation by Seeding Large Language Model Prompts
arxiv_id: '2502.13193'
source_url: https://arxiv.org/abs/2502.13193
tags:
- data
- private
- dp-kps
- text
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes DP-KPS, a method for generating differentially
  private synthetic text by prompting an LLM with keyphrase sequences that are themselves
  differentially private. The method uses private KDE over phrase embeddings to sample
  keyphrases that capture the private dataset while preserving differential privacy,
  then seeds LLM prompts with these phrases.
---

# Private Text Generation by Seeding Large Language Model Prompts

## Quick Facts
- **arXiv ID:** 2502.13193
- **Source URL:** https://arxiv.org/abs/2502.13193
- **Reference count:** 40
- **Primary result:** DP-KPS generates DP synthetic text with 72% MIMIC and 85% DBPedia-14 accuracy using ~10× fewer LLM prompts than baselines

## Executive Summary
This paper proposes DP-KPS, a method for generating differentially private synthetic text by prompting an LLM with keyphrase sequences that are themselves differentially private. The approach uses private KDE over phrase embeddings to sample keyphrases that capture the private dataset while preserving differential privacy, then seeds LLM prompts with these phrases. The method addresses the challenge of sharing sensitive text data (e.g., medical records) for machine learning while preserving privacy, without requiring training or fine-tuning of the LLM. Experiments on MIMIC medical records and DBPedia-14 show that DP-KPS achieves high classification accuracy with strong privacy guarantees, outperforming the baseline AugPE method while using approximately 10× fewer LLM prompts.

## Method Summary
DP-KPS generates differentially private synthetic text through a four-step process: (1) vocabulary privatization using DP histogram to select top terms from the private dataset, (2) DP-KDE sampling over phrase embeddings to generate keyphrase sequences, (3) LLM generation by prompting with these keyphrases, and (4) domain adaptation using Deep CORAL to align synthetic and real data distributions for downstream classification. The method relies on the post-processing property of differential privacy to ensure the LLM output inherits the privacy guarantee from the privatized keyphrases.

## Key Results
- Achieves 72% classification accuracy on MIMIC medical records and 85% on DBPedia-14 with ε=6-15 privacy guarantees
- Outperforms AugPE baseline while using approximately 10× fewer LLM prompts
- Shows that DP synthetic text can preserve predictive power for downstream ML tasks
- Independent sampling worked best for MIMIC while iterative sampling performed better on DBPedia-14

## Why This Works (Mechanism)

### Mechanism 1: Private Distribution Approximation via Vocabulary-Scoped KDE
The method builds a probability density over phrase embeddings from the private dataset using DP-KDE, then projects this density onto a discrete public vocabulary. By querying the KDE score for every term in the vocabulary and normalizing these scores, it forms a multinomial distribution from which keyphrases are sampled. This works because the discrete public vocabulary contains sufficient semantic coverage to approximate the signal in the private continuous embedding space.

### Mechanism 2: In-Context Signal Injection (Prompt Seeding)
Seeding LLM prompts with specific keyphrases conditions the generation process to produce diverse, topic-aligned synthetic text more effectively than using generic class labels. This leverages the LLM's in-context learning capabilities by constraining the output to a specific region of the LLM's latent space, addressing the "output diversity" challenge that prevents LLMs from defaulting to generic or repetitive outputs.

### Mechanism 3: Post-Processing Privacy Guarantee
Since the keyphrase sequences are generated via an (ε,δ)-DP mechanism, the subsequent synthetic text generated by the LLM is also differentially private by definition. This relies on the post-processing property of differential privacy - once the keyphrase sequence is released with DP guarantees, any transformation applied to it (even by an untrusted third-party LLM) cannot degrade the privacy guarantee.

## Foundational Learning

- **Concept: Differential Privacy (DP) & Composition**
  - **Why needed here:** The system relies on splitting a privacy budget ε between vocabulary privatization (ε_voc) and KDE sampling (ε_kde). Understanding composition is required to set these parameters.
  - **Quick check question:** If you run two queries on a dataset, one with ε=1 and another with ε=2, what is the total privacy loss (basic composition)?

- **Concept: Kernel Density Estimation (KDE) in High Dimensions**
  - **Why needed here:** The core innovation is using KDE to model the "cloud" of private document embeddings. You must understand that KDE smooths discrete data points into a continuous probability density.
  - **Quick check question:** Why is sampling from a high-dimensional KDE typically hard, and how does restricting the sample space to a vocabulary solve this?

- **Concept: Domain Adaptation (Deep CORAL)**
  - **Why needed here:** The synthetic text generated by the LLM may have a different feature distribution (style/format) than the target real-world data. The method uses Deep CORAL to align these distributions for the downstream classifier.
  - **Quick check question:** Why can't we just train a classifier on the synthetic data and expect it to work on real data without alignment?

## Architecture Onboarding

- **Component map:** Private text D → Vocab Privatization → DP-KDE Data Structure → Sample Keyphrase Sequences → LLM Generation → Synthetic Corpus → Domain Adaptation → Downstream Classifier
- **Critical path:** The DP-KDE Sampling step is where the trade-off between privacy (ε), utility (accuracy), and computation (vocabulary size |Ṽ|) is realized. If the density estimation is poor, no amount of LLM prompting can recover the signal.
- **Design tradeoffs:**
  - Independent vs. Iterative Sampling: Independent sampling is faster and preserves budget but loses semantic correlation; iterative sampling preserves correlations but requires splitting the privacy budget.
  - Vocabulary Size (|Ṽ|): Larger vocabulary increases signal capture chance but linearly increases DP-KDE query cost.
- **Failure signatures:**
  - Semantic Drift: Downstream accuracy is low (vocabulary Ṽ is not domain-specific or ε is too low).
  - Incoherent Text: LLM outputs are nonsensical (sampled keyphrases are contradictory).
  - Style Mismatch: Classifier fails on real test data (domain adaptation failed or was skipped).
- **First 3 experiments:**
  1. Sanity Check (No LLM): Train classifier directly on sampled keyphrase sequences to isolate DP-KPS sampling quality from LLM generation.
  2. Budget Sweep: Vary ε ∈ {1, 5, 10, 15} to plot privacy-utility curve and check if performance collapses at tight privacy (ε < 5).
  3. Ablation: Sampling Strategy: Compare downstream accuracy using Independent vs. Iterative sequence generation to determine if capturing phrase correlations is critical for the dataset.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can differentially private synthetic data methods be extended to jointly generate diverse data components, such as numbers, time series, and images, alongside text?
  - Basis in paper: [explicit] The conclusion states medical records contain numbers, time series, and images, and the question of how to privately and jointly generate these diverse components is an unsolved grand challenge.
  - Why unresolved: Current prompting methods are limited to text generation and cannot handle structured numerical or visual data.
  - What evidence would resolve it: A method that generates correlated synthetic text and time-series data while maintaining differential privacy.

- **Open Question 2:** To what extent does the overlap between the private dataset and the LLM's pre-training data impact the utility and privacy guarantees of DP-KPS?
  - Basis in paper: [explicit] The authors note regarding DBPedia-14, "it is rather likely to have seen DBPedia-14... we opt to include one for completeness while acknowledging this limitation."
  - Why unresolved: LLMs are black boxes regarding their training data; it's unclear if prompting with privatized keyphrases from a memorized dataset offers different utility-privacy trade-offs.
  - What evidence would resolve it: Experiments comparing DP-KPS performance on datasets known to be excluded from the LLM's training set versus those included.

- **Open Question 3:** What specific dataset properties determine whether independent or iterative keyphrase generation strategies yield better downstream accuracy?
  - Basis in paper: [inferred] Appendix B.2.4 notes results "vary substantially" between the two methods and implies the choice is "dataset-dependent" without providing a selection rule.
  - Why unresolved: There's no theoretical or heuristic framework to predict which method suits a specific data domain without running validation experiments.
  - What evidence would resolve it: A theoretical analysis or empirical study correlating dataset statistics with success rates of the two generation methods.

## Limitations

- The implementation details of the high-dimensional DP-KDE mechanism from [WNM23] are complex and opaque, affecting reproducibility
- Deep CORAL adaptation parameters are underspecified, potentially affecting domain alignment results
- The performance advantage over AugPE is difficult to verify without access to the baseline implementation details

## Confidence

- **High Confidence:** The post-processing privacy guarantee mechanism and fundamental architecture of DP-KPS are well-established and theoretically sound
- **Medium Confidence:** Empirical results showing 72% MIMIC and 85% DBPedia-14 accuracy are plausible but depend heavily on implementation details
- **Low Confidence:** The relative performance advantage over AugPE (10× fewer prompts) is difficult to verify without baseline implementation access

## Next Checks

1. **Sanity Check Isolation:** Train a classifier directly on the sampled keyphrase sequences (as a "bag of words") without LLM generation to isolate the quality of the DP-KPS sampling from the LLM's generation quality.

2. **Budget Sweep Analysis:** Systematically vary epsilon from 1 to 15 to plot the privacy-utility curve and identify the point where performance collapses at tight privacy constraints (epsilon < 5).

3. **Sampling Strategy Ablation:** Compare downstream accuracy using independent versus iterative sequence generation to determine if capturing phrase correlations is critical for specific datasets.