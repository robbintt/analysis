---
ver: rpa2
title: Knowledgeable Language Models as Black-Box Optimizers for Personalized Medicine
arxiv_id: '2509.20975'
source_url: https://arxiv.org/abs/2509.20975
tags:
- optimization
- knowledge
- leon
- patient
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents LEON, a method that leverages large language
  models (LLMs) as black-box optimizers for personalized medicine. The key idea is
  to frame treatment design as a conditional optimization problem and use domain-specific
  prior knowledge to guide the LLM in proposing individualized treatment plans.
---

# Knowledgeable Language Models as Black-Box Optimizers for Personalized Medicine

## Quick Facts
- **arXiv ID:** 2509.20975
- **Source URL:** https://arxiv.org/abs/2509.20975
- **Reference count:** 40
- **Primary result:** LEON achieves average rank 1.2 across five personalized medicine optimization tasks using LLMs with knowledge priors and distribution constraints.

## Executive Summary
This paper presents LEON, a method that leverages large language models (LLMs) as black-box optimizers for personalized medicine. The key innovation is framing treatment design as a conditional optimization problem where domain-specific prior knowledge guides the LLM in proposing individualized treatment plans. LEON employs a mathematically principled approach that incorporates constraints to ensure reliable predictions and consistent high-quality proposals. Experiments on real-world optimization tasks show that LEON outperforms traditional and other LLM-based methods, achieving an average rank of 1.2 across five representative treatment design problems.

## Method Summary
LEON frames personalized treatment optimization as a conditional black-box optimization problem where an LLM generates treatment designs as text. The method uses domain-specific prior knowledge (textbooks, knowledge graphs, medical LLMs) to guide proposals and employs a source critic to constrain distribution shift. The optimization loop involves iterative LLM proposals, surrogate evaluation, equivalence class clustering, dynamic certainty and constraint weight estimation, and reflection. The framework ensures reliable predictions by bounding the Wasserstein distance between proposed and historical designs, while maintaining exploration through entropy constraints over equivalence classes.

## Key Results
- LEON achieves an average rank of 1.2 across five treatment design optimization tasks
- Knowledge ablation degrades performance across all tasks, with RMSE increasing from 1.36 to 2.16 mg/week on Warfarin
- Dynamic estimation of certainty (μ) and constraint weight (λ) parameters significantly outperforms fixed settings
- LEON outperforms traditional optimization methods and other LLM-based approaches on all tested tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Domain-specific prior knowledge improves LLM optimizer certainty in proposing treatment designs.
- **Mechanism:** The LLM queries external knowledge repositories to synthesize contextual prior knowledge, which is injected into prompts to improve proposal consistency. The certainty parameter μ is estimated from equivalence class occupancy, upweighting rewards for confident proposals.
- **Core assumption:** The LLM can meaningfully contextualize unstructured medical knowledge into patient-specific treatment reasoning without fine-tuning.
- **Evidence anchors:** Abstract states prior knowledge "can provide a meaningful alternative signal of the fitness of proposed treatments"; section 4.3 explains prior knowledge helps "overcome the statistical randomness of the LLM's next-token generative process."
- **Break condition:** If knowledge sources contain factual errors, μ estimation may still increase but proposal quality degrades (see adversarial knowledge ablation in Appendix E.9).

### Mechanism 2
- **Claim:** Bounding the 1-Wasserstein distance between proposed designs and source distribution mitigates surrogate model over-extrapolation.
- **Mechanism:** An adversarial source critic c*(x) is trained to discriminate design origins. The constraint E[c*(x')]−E[c*(x)]≤W₀ bounds distribution shift, with λ dynamically updated to penalize extrapolation when designs drift out-of-distribution.
- **Core assumption:** The source critic's Lipschitz constraint can be approximately enforced via weight clipping, and W₁ correlates with surrogate generalization error.
- **Evidence anchors:** Abstract mentions "constraining the optimization problem... to ensure reliable predictions"; section 4.2 states the constraint "ensures that the distribution of proposed designs is not too dissimilar to the distribution of historically reported designs."
- **Break condition:** If W₀ is too low, exploration is overly constrained; if too high, the constraint becomes vacuous and surrogate predictions may be unreliable.

### Mechanism 3
- **Claim:** Design proposals collapse to optimal representatives within equivalence classes, enabling tractable constrained optimization.
- **Mechanism:** Designs are clustered into equivalence classes via embedding similarity. Lemma 4.2 shows any feasible distribution can be replaced by one concentrated on optimal designs within each class without worsening the Lagrangian, reducing optimization to probability vectors over classes.
- **Core assumption:** Equivalence classes are finite and the combined objective is continuous and coercive.
- **Evidence anchors:** Abstract mentions "mathematically principled approach... incorporates constraints"; section 4.2 provides full proof in Appendix A.
- **Break condition:** If equivalence classes are poorly defined (e.g., random assignment), the entropy constraint provides no meaningful signal and optimization degrades.

## Foundational Learning

- **Concept:** 1-Wasserstein distance and Kantorovich-Rubinstein duality
  - **Why needed:** The source critic constraint is formulated using W₁; understanding its dual representation as a supremum over Lipschitz functions is necessary to implement the adversarial critic.
  - **Quick check:** Can you explain why clipping critic weights approximates a Lipschitz constraint?

- **Concept:** Lagrange multipliers and the KKT conditions
  - **Why needed:** The constrained optimization problem is solved by forming the Lagrangian; Lemma 4.3 derives the closed-form solution for class probabilities via stationarity conditions.
  - **Quick check:** If the entropy constraint H∼(q)≤H₀ were removed, would Lemma 4.3 still yield a closed-form solution?

- **Concept:** Equivalence relations and quotient sets
  - **Why needed:** The ∼-coarse-grained entropy is defined over equivalence classes X/∼; clustering designs requires specifying a valid equivalence relation.
  - **Quick check:** Does the k-means clustering approach used in the paper guarantee that each cluster defines a valid equivalence class?

## Architecture Onboarding

- **Component map:** Knowledge Retrieval Module -> Design Proposal Loop -> Source Critic -> Equivalence Relation Clustering
- **Critical path:** Knowledge generation (once per patient) -> iterative design loop (B/batch_size iterations) -> final top-scoring design selection. The surrogate model budget (default 2048 evaluations) gates total iterations.
- **Design tradeoffs:**
  - Batch size b: Larger batches improve μ estimation accuracy but reduce sequential adaptation. Default b=32.
  - W₀ bound: Intermediate values (e.g., 3) balance exploration vs. surrogate reliability; extreme values fail.
  - Embedding model: Domain-specific embeddings (Bio+Clinical BERT) outperform generalist embeddings in ablations.
  - Reflection: Ablation shows removing reflection degrades performance across all tasks.
- **Failure signatures:**
  - High temperature (τ>1.3): LLM fails to produce syntactically valid structured outputs.
  - Adversarial knowledge: Factually incorrect prior knowledge significantly degrades optimization quality.
  - Random equivalence classes: Entropy constraint becomes uninformative; performance drops.
- **First 3 experiments:**
  1. **Reproduce Warfarin task with knowledge ablation:** Run LEON with no external knowledge vs. all sources. Expect RMSE degradation from 1.36 to ~2.16 mg/week (Table S7). This validates the knowledge mechanism.
  2. **Sweep W₀ on a single task (e.g., Lung):** Test W₀∈{0, 0.1, 1, 3, 10, 100}. Plot TTNTD vs. W₀ to identify the sweet spot and verify the source critic's role in preventing extrapolation failure.
  3. **Ablate μ and λ estimation:** Run with (λ=0, μ=1), (λ=dynamic, μ=1), (λ=0, μ=dynamic), and (λ=dynamic, μ=dynamic). Compare ranks to confirm that both constraints are necessary (Table S6 shows dynamic+dynamic achieves rank 1.2 vs. 2.6 for fixed).

## Open Questions the Paper Calls Out

- **Open Question 1:** Can LEON be effectively extended to handle multi-objective optimization tasks, such as balancing treatment efficacy with toxicity or monetary cost?
  - **Basis:** Appendix D.12 states this extension is left for future work.
  - **Why unresolved:** Current formulation optimizes a single objective; theoretical approaches like linear scalarization haven't been empirically validated.
  - **Evidence needed:** Empirical benchmarks showing LEON's performance on multi-objective personalized medicine tasks compared to standard multi-objective baselines.

- **Open Question 2:** How can LEON be adapted for prospective clinical evaluation and active learning rather than relying on static surrogate models?
  - **Basis:** Discussion and Conclusion mention extending LEON to active learning and prospective clinical evaluation.
  - **Why unresolved:** Current implementation relies on offline surrogate models; prospective evaluation requires handling real-time patient feedback and safety constraints.
  - **Evidence needed:** A study demonstrating LEON's performance in a live active learning loop (e.g., in vitro or clinical trial simulation) with sequential evaluation and new incoming data.

- **Open Question 3:** How can the framework be made robust to the inclusion of low-quality or factually incorrect prior knowledge without relying on external expert curation?
  - **Basis:** Limitations note sensitivity to knowledge quality; Appendix E.9 shows performance drops with adversarial knowledge.
  - **Why unresolved:** Paper establishes sensitivity to knowledge quality but doesn't propose internal mechanisms to filter malicious/irrelevant retrieved information.
  - **Evidence needed:** A modified version of LEON with verification or self-reflection capable of identifying and ignoring adversarial or irrelevant knowledge inputs.

## Limitations

- Proprietary datasets (Breast, Lung, ADR) are unavailable for independent validation, limiting reproducibility to public Warfarin and HIV tasks.
- The source critic's Lipschitz constraint is only approximately enforced via weight clipping, with effectiveness not empirically validated.
- Equivalence class definition relies on clustering via text embeddings, but clustering hyperparameters are not fully specified.
- Dynamic estimation of certainty parameter μ assumes a linear relationship between equivalence class occupancy and proposal quality.

## Confidence

- **High confidence:** The equivalence class collapse (Lemma 4.2) is mathematically proven, and the ablation showing reflection improves performance is direct evidence for Mechanism 1.
- **Medium confidence:** The source critic constraint (Wasserstein distance) is theoretically justified, but its empirical impact is only demonstrated on available tasks. The adversarial knowledge ablation provides partial validation of the knowledge mechanism.
- **Low confidence:** The core claim that LEON achieves an average rank of 1.2 is not independently verifiable due to missing datasets and incomplete surrogate model details.

## Next Checks

1. **W₀ Sensitivity Analysis:** Sweep W₀ ∈ {0, 0.1, 1, 3, 10, 100} on a single task (e.g., Lung surrogate) and plot TTNTD vs. W₀ to identify the sweet spot and confirm the source critic's role in preventing extrapolation failure.

2. **Knowledge Ablation on Warfarin:** Run LEON with no external knowledge vs. all sources on the Warfarin task. Expect RMSE to degrade from 1.36 to ~2.16 mg/week, validating the knowledge mechanism.

3. **Dynamic vs. Fixed Constraints:** Compare (λ=dynamic, μ=dynamic) vs. (λ=0, μ=1), (λ=dynamic, μ=1), and (λ=0, μ=dynamic) on the HIV task. Confirm that both constraints are necessary by reproducing the rank differences observed in Table S6.