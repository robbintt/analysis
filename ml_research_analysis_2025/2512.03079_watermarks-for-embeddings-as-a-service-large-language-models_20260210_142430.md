---
ver: rpa2
title: Watermarks for Embeddings-as-a-Service Large Language Models
arxiv_id: '2512.03079'
source_url: https://arxiv.org/abs/2512.03079
tags:
- attack
- page
- eaas
- paraphrasing
- watermark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis investigated security vulnerabilities in embedding-as-a-service
  (EaaS) models, specifically focusing on intellectual property protection against
  imitation attacks. The work introduced a novel paraphrasing attack that successfully
  bypasses existing EaaS watermark defenses (WARDEN and EmbMarker) by generating multiple
  paraphrases of input text and averaging their embeddings, effectively diluting watermark
  signals that rely on trigger words.
---

# Watermarks for Embeddings-as-a-Service Large Language Models

## Quick Facts
- arXiv ID: 2512.03079
- Source URL: https://arxiv.org/abs/2512.03079
- Authors: Anudeex Shetty
- Reference count: 0
- Primary result: Introduced WET watermarking technique that resists paraphrasing attacks while maintaining embedding utility

## Executive Summary
This thesis addresses security vulnerabilities in embedding-as-a-service (EaaS) models by investigating intellectual property protection against imitation attacks. The work identifies a critical weakness in existing EaaS watermark defenses (WARDEN and EmbMarker) that can be exploited through paraphrasing attacks, where attackers generate multiple paraphrases of input text and average their embeddings to dilute watermark signals. To address this vulnerability, the thesis proposes WET (Watermarking EaaS with Linear Transformation), a novel watermarking technique that applies linear transformations to original embeddings without relying on trigger words. WET demonstrates near-perfect verifiability across multiple datasets while maintaining embedding utility and proving robust against paraphrasing attacks.

## Method Summary
The thesis introduces WET, a watermarking technique that applies linear transformations to original embeddings to embed imperceptible signatures without depending on trigger words. The method was validated through comprehensive experiments across multiple datasets, demonstrating near-perfect verifiability (AUC=100%) while preserving embedding utility. The work includes extensive ablation studies examining various components and hyperparameters, establishing WET as a more secure alternative to current EaaS watermarking methods. The approach was specifically designed to resist paraphrasing attacks that bypass existing defenses by averaging embeddings from multiple paraphrased inputs.

## Key Results
- WET achieves near-perfect verifiability (AUC=100%) across multiple datasets
- Successfully resists paraphrasing attacks that bypass existing defenses (WARDEN and EmbMarker)
- Maintains embedding utility while providing robust intellectual property protection

## Why This Works (Mechanism)
WET works by applying linear transformations to original embeddings, embedding imperceptible signatures without relying on trigger words that can be diluted through paraphrasing attacks. The linear transformation approach ensures that watermarks remain detectable even when embeddings are averaged across multiple paraphrased versions of the same content. This mathematical foundation makes WET resistant to attacks that exploit the averaging behavior of paraphrasing, as the linear transformation properties are preserved under such operations.

## Foundational Learning
- EaaS watermarking fundamentals: Understanding how embeddings can carry imperceptible signatures for ownership verification is essential for protecting intellectual property in LLM services
- Linear algebra for transformations: Knowledge of linear transformations and their properties is crucial for implementing robust watermarking that resists manipulation
- Embedding similarity metrics: Familiarity with cosine similarity and other distance measures is necessary for evaluating watermark detectability and embedding utility
- Paraphrasing attack mechanisms: Understanding how attackers can dilute watermark signals by averaging embeddings from multiple paraphrases is key to developing secure defenses

## Architecture Onboarding
Component map: Input text -> Embedding model -> Linear transformation (WET) -> Watermarked embedding -> Verification
Critical path: The watermark embedding and verification process must be computationally efficient to support real-time EaaS deployment while maintaining security guarantees
Design tradeoffs: WET balances watermark strength against embedding utility, choosing linear transformations that are robust to paraphrasing but minimally impact downstream task performance
Failure signatures: Watermark detectability may degrade if linear transformation parameters are compromised or if attackers can access multiple watermarked versions of the same content
First experiments: 1) Test WET's verifiability across different embedding dimensions and transformation parameters, 2) Evaluate utility preservation on downstream NLP tasks, 3) Benchmark resistance to paraphrasing attacks using multiple paraphrasing models

## Open Questions the Paper Calls Out
None

## Limitations
- Security evaluation focuses primarily on paraphrasing attacks, leaving uncertainty about robustness against other attack vectors
- Linear transformation security relies on parameter secrecy, with no explicit exploration of inversion attacks
- Multilingual performance beyond tested languages remains unverified, potentially limiting generalizability
- Computational overhead implications for large-scale deployment are not addressed

## Confidence
- High confidence in WET's effectiveness against paraphrasing attacks, supported by theoretical analysis and empirical validation
- Medium confidence in overall security improvement claims due to limited evaluation scope beyond paraphrasing attacks
- Medium confidence in utility preservation claims, as assessment focuses on embedding similarity metrics without exploring diverse downstream applications

## Next Checks
1. Test WET's robustness against adversarial embedding perturbations and model fine-tuning attacks to establish broader security guarantees
2. Evaluate watermark performance and detectability across additional languages and domain-specific corpora to assess multilingual and cross-domain applicability
3. Conduct runtime overhead measurements and scalability analysis to quantify practical deployment constraints for large-scale EaaS systems