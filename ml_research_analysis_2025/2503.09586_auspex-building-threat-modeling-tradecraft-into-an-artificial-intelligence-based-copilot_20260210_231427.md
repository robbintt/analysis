---
ver: rpa2
title: 'Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based
  Copilot'
arxiv_id: '2503.09586'
source_url: https://arxiv.org/abs/2503.09586
tags:
- threat
- modeling
- system
- auspex
- tradecraft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Auspex, a generative AI-based threat modeling
  system that uses "tradecraft prompting" to encode expert threat modeling knowledge
  into prompts and prompt chains. Auspex ingests system architecture information and
  produces threat matrices specifying threat scenarios, types, security categorizations,
  and mitigations in minutes rather than weeks or months.
---

# Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot

## Quick Facts
- arXiv ID: 2503.09586
- Source URL: https://arxiv.org/abs/2503.09586
- Reference count: 4
- Primary result: AI threat modeling system using tradecraft prompting achieves low Hamming loss (0.03-0.23) and expert-validated threat matrices

## Executive Summary
Auspex is a generative AI-based threat modeling system that encodes expert threat modeling knowledge into prompts and prompt chains. The system ingests system architecture information and produces structured threat matrices specifying threat scenarios, types, security categorizations, and mitigations in minutes rather than weeks. Evaluation with 8 real banking systems and 8 cybersecurity experts showed mostly positive feedback on threat clarity and modeling enhancement, with quantitative metrics demonstrating low classification error rates.

## Method Summary
Auspex employs a two-stage approach: first analyzing system architecture to generate a formalized solution description, then producing threat scenarios mapped to CIA Triad and STRIDE categories. The system uses tradecraft prompting to encode expert knowledge into role-specific prompts, avoiding fine-tuning or RAG approaches. Architecture inputs (diagrams, text, or system-of-record data) are processed through sequential prompt chains that first create a solution description, then generate threat scenarios, and finally classify them into structured threat matrices.

## Key Results
- SME feedback showed high agreement that Auspex produces clear, understandable threats that enhance modeling experience
- Low Hamming loss (0.03-0.23) for generated category mappings between threats and CIA/STRIDE classifications
- System completed threat modeling in minutes versus traditional weeks or months for the 8 banking systems evaluated
- Expert reviews found threats to be realistic with minimal false positives across the test cases

## Why This Works (Mechanism)

### Mechanism 1: Intermediate State Grounding via Solution Description
Generating a formalized "Solution Description" before identifying threats reduces hallucination and scope creep by forcing the LLM to process architecture into a coherent textual narrative first, grounding its attention mechanism in specific context before complex threat reasoning.

### Mechanism 2: Decoupled Generation and Classification
Separating threat scenario generation from categorization improves accuracy by treating creative generation and logical mapping as distinct tasks, reducing the cognitive load on the model and improving multi-label classification performance.

### Mechanism 3: Role-Based Persona Prompting
Encoding specific "Cybersecurity Roles" into prompts allows dynamic perspective shifting (e.g., Network vs. Cloud Security) by priming the model to prioritize relevant threat vectors, mimicking multi-persona review without requiring multiple models.

## Foundational Learning

- **STRIDE & CIA Triad Frameworks**: Essential for understanding the structured output format; quick check: If a system allows an attacker to modify a log file, is this a violation of Integrity or Availability?

- **Prompt Chaining**: The architecture relies on serial dependency where output of Prompt A becomes variable for Prompt B; quick check: If the "Architecture Description" prompt fails to identify a database, which subsequent stages are guaranteed to fail?

- **Tradecraft Prompting**: Core novelty distinguishing this system from RAG or fine-tuning; quick check: How does "Tradecraft Prompting" differ from simply asking a generic LLM "What are the threats to this system?"

## Architecture Onboarding

- **Component map**: Ingestion Interface -> Stage 1 Processor (Solution Description) -> Stage 2 Processor (Threat Scenarios) -> Classification Module (Threat Matrix)
- **Critical path**: The generation of the Solution Description ($sol_S$) is the "state" connecting messy input to structured output; poor $sol_S$ makes the Threat Matrix unreliable
- **Design tradeoffs**: Prompting vs. Fine-Tuning (flexibility vs. potential inconsistency), Modularity vs. Latency (increased token usage and latency vs. improved structure)
- **Failure signatures**: Generic loop (vague threats indicating poor Solution Description), Category Drift (classification misalignment), Scope Creep (identifying out-of-scope components)
- **First 3 experiments**: 1) Validate Stage 1 with known architecture diagram, 2) Sensitivity analysis across all three roles, 3) Classification accuracy test with manually crafted specific threats

## Open Questions the Paper Calls Out
- How does Auspex compare quantitatively against other open-source AI threat modeling tools, specifically STRIDE GPT?
- Can the current tradecraft prompting approach effectively model platform-level infrastructure, or does it require architectural modifications?
- Does the addition of agent frameworks or fine-tuning significantly improve threat matrix accuracy over the current "tradecraft prompting" approach?

## Limitations
- Core tradecraft prompts are proprietary and not disclosed, creating barriers to independent validation
- Evaluation was limited to banking systems, raising generalization concerns to other domains
- Expert consensus thresholds and disagreement resolution methods were not specified
- Role-based effectiveness lacks empirical validation through systematic testing

## Confidence
- **High Confidence**: Two-stage architecture implementation, quantitative metrics (Hamming loss), SME feedback methodology
- **Medium Confidence**: Tradecraft prompting superiority claims, time reduction assertions
- **Low Confidence**: Role-based persona effectiveness mechanisms, intermediate state grounding benefits without ablation studies

## Next Checks
1. Conduct ablation study comparing two-stage approach against single-prompt direct mapping to validate intermediate state grounding hypothesis
2. Apply Auspex to three non-banking domains (healthcare, industrial systems, IoT) to test cross-domain generalization
3. Systematically test all three roles on identical architectures to quantify differences and analyze role-specific prompt effectiveness