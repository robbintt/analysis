---
ver: rpa2
title: 'VI-MMRec: Similarity-Aware Training Cost-free Virtual User-Item Interactions
  for Multimodal Recommendation'
arxiv_id: '2512.08702'
source_url: https://arxiv.org/abs/2512.08702
tags:
- uni00000013
- user-item
- virtual
- interactions
- interaction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'VI-MMRec addresses data sparsity in multimodal recommendation
  by constructing similarity-aware virtual user-item interactions based on modality
  feature similarities of user-interacted items. The method introduces two strategies:
  Overlay, which independently aggregates modality-specific similarities to preserve
  modality-specific user preferences, and Synergistic, which holistically fuses cross-modal
  similarities to capture complementary user preferences.'
---

# VI-MMRec: Similarity-Aware Training Cost-free Virtual User-Item Interactions for Multimodal Recommendation

## Quick Facts
- **arXiv ID**: 2512.08702
- **Source URL**: https://arxiv.org/abs/2512.08702
- **Reference count**: 40
- **Primary result**: Achieves 8-15% average performance gains across six real-world datasets using seven state-of-the-art multimodal recommendation models

## Executive Summary
VI-MMRec addresses data sparsity in multimodal recommendation by constructing similarity-aware virtual user-item interactions based on modality feature similarities of user-interacted items. The method introduces two strategies—Overlay (independent modality-specific aggregation) and Synergistic (holistic cross-modal fusion)—to capture both modality-specific and complementary user preferences. A statistically informed weight allocation mechanism adaptively assigns weights to virtual interactions based on dataset-specific modality relevance. VI-MMRec seamlessly integrates with existing multimodal recommendation models as a plug-and-play framework without modifying their core architecture or introducing additional training overhead.

## Method Summary
VI-MMRec constructs virtual user-item interactions by leveraging modality feature similarities from items that users have already interacted with. The framework operates in two modes: Overlay strategy independently aggregates similarities within each modality to preserve modality-specific user preferences, while Synergistic strategy holistically fuses cross-modal similarities to capture complementary preferences. A weight allocation mechanism uses statistical analysis of average similarity scores to adaptively determine the importance of each modality for virtual interaction construction. The method integrates seamlessly with existing multimodal recommendation models without requiring architectural modifications or additional training, functioning as a plug-and-play enhancement that generates virtual interactions during inference to enrich sparse interaction data.

## Key Results
- Achieves 8-15% average performance improvements across multiple metrics (Recall@10, NDCG@10) on six real-world datasets
- Demonstrates effectiveness across seven state-of-the-art multimodal recommendation baselines
- Provides significant gains particularly in scenarios with high data sparsity
- Shows consistent performance improvements across different dataset characteristics and baseline model architectures

## Why This Works (Mechanism)
The method works by augmenting sparse user-item interaction data with synthetic interactions generated through similarity-aware mechanisms. By leveraging modality feature similarities of items users have already interacted with, VI-MMRec creates meaningful virtual interactions that capture both explicit and implicit user preferences. The dual strategy approach allows the framework to preserve modality-specific preferences through independent aggregation while also capturing complementary information through cross-modal fusion. The statistical weight allocation ensures that virtual interactions are weighted according to their relevance and reliability, preventing noise amplification and maintaining recommendation quality.

## Foundational Learning

**Modality Feature Similarity**
- *Why needed*: Forms the basis for identifying related items and constructing meaningful virtual interactions
- *Quick check*: Verify that modality features are properly extracted and normalized before similarity computation

**Data Sparsity in Recommendation Systems**
- *Why needed*: Understanding the problem context that motivates the need for virtual interaction generation
- *Quick check*: Calculate interaction-to-item ratio to confirm sparsity levels in target datasets

**Cross-modal Fusion**
- *Why needed*: Enables capturing complementary information across different modality types
- *Quick check*: Validate that fused representations maintain information from all modalities without dominance by any single modality

## Architecture Onboarding

**Component Map**
User Interaction History -> Modality Feature Extraction -> Similarity Computation -> Virtual Interaction Generation (Overlay/Synergistic) -> Weighted Aggregation -> Integration with Base Model

**Critical Path**
1. Extract modality features from user-interacted items
2. Compute similarity scores between items within and across modalities
3. Generate virtual interactions using selected strategy (Overlay or Synergistic)
4. Apply statistical weight allocation to virtual interactions
5. Integrate virtual interactions with original data for recommendation

**Design Tradeoffs**
- *Modality independence vs. fusion*: Overlay preserves modality-specific signals but may miss cross-modal patterns; Synergistic captures complementarity but risks information loss
- *Static vs. adaptive weights*: Fixed weights are simpler but less responsive to dataset characteristics; adaptive weights improve relevance but add computational overhead
- *Virtual interaction quantity*: More virtual interactions provide better coverage but increase computational cost and risk of noise

**Failure Signatures**
- Performance degradation when modality features are noisy or poorly aligned
- Limited improvement on datasets with already sufficient interaction density
- Inconsistent gains across different baseline models due to varying architectural compatibility

**3 First Experiments**
1. Compare Overlay vs. Synergistic strategies on a single dataset to identify which performs better for specific data characteristics
2. Test statistical weight allocation by comparing weighted vs. unweighted virtual interaction integration
3. Evaluate performance impact when reducing the number of virtual interactions to find the optimal balance between augmentation and noise

## Open Questions the Paper Calls Out
None

## Limitations
- Does not address potential noise amplification when constructing virtual interactions from sparse or low-quality modality features
- Performance may degrade when modality-specific feature spaces are not well-aligned or when certain modalities are missing entirely
- Assumes average similarity scores reliably indicate modality relevance, which may not capture complex user behavior patterns

## Confidence

**High Confidence**: The methodology for constructing virtual interactions through similarity aggregation is clearly defined and technically sound. The experimental design with multiple datasets and baseline models provides robust evidence for performance claims.

**Medium Confidence**: The claimed improvements of 8-15% across datasets require careful interpretation as performance gains may vary significantly based on dataset characteristics and baseline model architectures. The generalization capability across different multimodal recommendation scenarios needs further validation.

**Medium Confidence**: The assertion of being "training cost-free" needs qualification, as while no additional training is required for VI-MMRec itself, computational overhead exists during inference when generating and processing virtual interactions.

## Next Checks

1. Conduct ablation studies to quantify the individual contributions of Overlay and Synergistic strategies, and assess whether one consistently outperforms the other across different dataset characteristics.

2. Evaluate the method's robustness to varying levels of data sparsity by systematically reducing interaction counts and measuring performance degradation compared to baseline models.

3. Test the framework's behavior when one or more modalities are missing entirely, to verify whether the statistical weight allocation mechanism can appropriately adapt to such scenarios without significant performance loss.