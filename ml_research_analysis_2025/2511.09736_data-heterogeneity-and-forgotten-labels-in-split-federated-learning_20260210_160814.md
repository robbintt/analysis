---
ver: rpa2
title: Data Heterogeneity and Forgotten Labels in Split Federated Learning
arxiv_id: '2511.09736'
source_url: https://arxiv.org/abs/2511.09736
tags:
- clients
- hydra
- data
- accuracy
- random
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies and studies intra-round catastrophic forgetting
  in Split Federated Learning (SFL), a problem arising from the sequential processing
  order of clients at the server. Under non-IID data distributions, the model exhibits
  significant performance disparities among labels, with those processed later achieving
  notably better accuracy.
---

# Data Heterogeneity and Forgotten Labels in Split Federated Learning

## Quick Facts
- arXiv ID: 2511.09736
- Source URL: https://arxiv.org/abs/2511.09736
- Authors: Joana Tirana; Dimitra Tsigkari; David Solans Noguero; Nicolas Kourtellis
- Reference count: 40
- Primary result: Hydra reduces intra-round catastrophic forgetting in Split Federated Learning by up to 75% while increasing global accuracy by over 100%

## Executive Summary
This paper identifies and studies intra-round catastrophic forgetting in Split Federated Learning (SFL), a problem arising from the sequential processing order of clients at the server. Under non-IID data distributions, the model exhibits significant performance disparities among labels, with those processed later achieving notably better accuracy. The authors propose Hydra, a novel mitigation method inspired by multi-head architectures, which assigns multiple specialized heads to different label groups and aggregates them at the end of each round. Hydra effectively reduces the performance gap by up to 75% while increasing global accuracy by over 100% compared to baseline SFL.

## Method Summary
The authors propose Hydra, a multi-head architecture that mitigates intra-round catastrophic forgetting in Split Federated Learning. The method splits Part-2 of the SFL architecture into a shared base (Part-2a) and multiple specialized heads (Part-2b). Clients are mapped to specific heads based on their dominant label distribution. During training, Part-2a is updated sequentially while the specific head for each client group is updated in parallel. At the end of each round, all heads are aggregated via FedAvg. The method requires knowledge of client label distributions for initial head assignment and operates with minimal overhead by aggregating heads only at round boundaries.

## Key Results
- Hydra reduces performance gap among labels by 64-75% compared to baseline SFL
- Global accuracy improves by 58-112% over baseline SFL under non-IID conditions
- Hydra outperforms state-of-the-art methods across CIFAR-10, CIFAR-100, SVHN, and TinyImageNet
- The method shows consistent performance across different data partition strategies (Dominant Label, Dirichlet, Sharding)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Sequential processing of clients at the server under non-IID data distributions causes intra-round catastrophic forgetting, making labels processed later outperform earlier ones
- **Mechanism:** In SFL, the server updates Part-2 sequentially using gradients from one client at a time. Under data heterogeneity, gradient updates from the current client shift weights away from optima of previously processed clients, resembling sequential overwriting seen in Continual Learning
- **Core assumption:** Data distribution is non-IID (specifically label-skewed) and clients are processed in structured order rather than aggregated in parallel
- **Evidence anchors:** [Abstract] "Part-2 is sensitive to the processing sequence... the trained model performs better in classes (labels) seen at the end of the sequence"

### Mechanism 2
- **Claim:** Multiple specialized output heads that are aggregated at round end reduce performance gap by isolating gradient updates for different data subgroups
- **Mechanism:** Hydra splits Part-2 into shared base and multiple heads. Clients map to specific heads based on dominant label. Part-2a updates sequentially but specific head updates only for relevant client group. Aggregation at round end prevents gradient of one label group from overwriting weights learned for another
- **Core assumption:** Server knows label distribution of clients for initial mapping; aggregation effectively averages specialized knowledge without catastrophic interference
- **Evidence anchors:** [Abstract] "Hydra... assigns multiple specialized heads to different label groups and aggregates them at the end of each round"

### Mechanism 3
- **Claim:** Depth of cut layer modulates trade-off between intra-round forgetting (Part-2) and federated model drifting (Part-1)
- **Mechanism:** Shallow cut implies small Part-1 (client-side) and large Part-2 (server-side), maximizing impact of sequential processing and minimizing federated aggregation drifting. Deep cut shifts burden to client, reducing intraCF but increasing susceptibility to global model drifting
- **Core assumption:** Severity of catastrophic forgetting correlates with proportion of model processed sequentially vs. in parallel
- **Evidence anchors:** [Section 3.2] "A deep cut layer highlights the effect of CF in part-1, while a shallow cut layer highlights the effect of intraCF on CF"

## Foundational Learning

- **Concept: Split Federated Learning (SFL)**
  - **Why needed here:** Understanding hybrid architecture (Part-1/client vs. Part-2/server) is essential to diagnosing why sequential processing on server causes forgetting while client-side processing causes drifting
  - **Quick check question:** Can you distinguish between the role of the "Aggregator" (handles Part-1 weights) and the "Server" (trains Part-2) in the SFL workflow?

- **Concept: Catastrophic Forgetting (CF)**
  - **Why needed here:** The paper adapts concept of CF from Continual Learning to describe how sequential updates in SFL overwrite previous knowledge
  - **Quick check question:** How does the "Backward Transfer (BW)" metric differ from the "Performance Gap (PG)" metric introduced in this paper?

- **Concept: Non-IID Data (Label Skew)**
  - **Why needed here:** Mechanism of forgetting is driven by data heterogeneity. Without understanding label skew, severity of intraCF problem is not apparent
  - **Quick check question:** Why does a cyclic processing order under non-IID data exacerbate performance gap more than a random order?

## Architecture Onboarding

- **Component map:**
  - Clients: Hold Part-1 (shallow layers). Forward pass data to server, receive gradients
  - Server: Holds Part-2a (shared body) and Part-2b (Hydra heads)
  - Aggregator: Collects Part-1 weights from clients and Part-2b heads from server at end of rounds
  - Grouping Algorithm: Logic to map clients to specific heads based on label statistics

- **Critical path:**
  1. Setup: Server runs Grouping Algorithm (requires client label statistics)
  2. Forward: Client processes batch via Part-1 → sends activations to Server
  3. Server Processing: Server passes activation through Part-2a → selects specific Part-2b head based on client ID → computes loss
  4. Update: Server backpropagates to update Part-2a and specific Part-2b head. Sends gradients to Client
  5. Aggregation: At end of round, Aggregator feds-avg's Part-1 (clients) and Server feds-avg's Part-2b heads

- **Design tradeoffs:**
  - Head Length (Part-2b size): Shorter heads (e.g., last 2 layers) result in lower memory overhead and often better performance for complex models by limiting model drifting; larger heads increase capacity but may reintroduce instability
  - Number of Heads (G): Setting G=L (one head per label) yields best accuracy but highest memory; reducing G via superclasses lowers memory with moderate performance cost

- **Failure signatures:**
  - High Performance Gap (PG): If accuracy of "Position 10" clients is significantly higher than "Position 1" clients, system is failing to mitigate intraCF
  - Divergence on Deep Cuts: If using Hydra on deep cut layer, performance may degrade if heads are too large, causing "multi-head" aspect to interfere with aggregated body

- **First 3 experiments:**
  1. Baseline Validation: Run SFL (vanilla) with Cyclic Order on CIFAR-10 (80% Dominant Label). Verify that PG increases as position increases (confirming intraCF)
  2. Hydra Effectiveness: Run SFL+Hydra (Small Part-2b) on same setup. Confirm PG reduction (target: >60% reduction) and global accuracy improvement
  3. Cut Layer Sensitivity: Run same experiment with "Deep Cut" (e.g., layer 23 of MobileNet) vs. "Shallow Cut" (layer 4). Observe if PG gap shrinks naturally in baseline due to reduced server-side processing

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do client selection policies influence catastrophic forgetting (CF) and effectiveness of Hydra in Split Federated Learning?
- **Basis in paper:** [explicit] The Conclusion identifies incorporating client selection policies into CF analysis and Hydra as an "interesting direction for future work"
- **Why unresolved:** Current experimental setup processes clients based on fixed cyclic or random arrival orders without implementing specific client selection strategies
- **What evidence would resolve it:** Experiments evaluating Hydra under various client selection algorithms (e.g., fairness-based or resource-aware) to measure changes in performance gap and global accuracy

### Open Question 2
- **Question:** Can theoretical convergence guarantees be established for SFL and Hydra with respect to cut layer and processing order?
- **Basis in paper:** [explicit] The authors state that their empirical analysis paves the way for "theoretical/convergence analysis of SFL" and "establishing the theoretical guarantees for Hydra"
- **Why unresolved:** Current work focuses entirely on empirical observations and numerical evaluations, lacking formal mathematical proofs or convergence bounds
- **What evidence would resolve it:** A theoretical framework or proof deriving convergence rates for SFL and Hydra, specifically modeling impact of intra-round processing sequences and cut layer depth

### Open Question 3
- **Question:** To what extent do semantic relationships among labels affect catastrophic forgetting in SFL and configuration of Hydra's heads (G)?
- **Basis in paper:** [explicit] The authors note that their ablation study on number of heads revealed semantic relationships "may play an important role" and believe "it should be studied in the future"
- **Why unresolved:** Grouping of labels into superclasses in ablation study was preliminary, and specific impact of label semantics on "forgotten labels" phenomenon was not systematically analyzed
- **What evidence would resolve it:** A study correlating label semantic similarity (e.g., using embedding distances) with CF metrics, specifically analyzing how semantically informed head grouping affects Hydra's performance

## Limitations

- Analysis focuses primarily on shallow cut layers (MobileNet layer 4, ResNet layer 2), limiting generalizability to deeper architectures where server-side processing time is reduced
- Grouping algorithm's sensitivity to initial conditions and performance with extremely skewed data distributions (>90% dominant label) is not thoroughly explored
- Memory overhead implications for resource-constrained devices with large numbers of heads (G=L) are not quantified

## Confidence

- **High:** The existence of intra-round catastrophic forgetting under non-IID data and sequential processing (supported by consistent PG measurements across experiments)
- **High:** Hydra's effectiveness in reducing performance gaps (verified through multiple ablations and comparisons)
- **Medium:** The claim that Hydra outperforms all existing baselines across all datasets (limited comparison scope, though results are compelling)

## Next Checks

1. **Generalization to Deep Cuts:** Test Hydra with deeper cut layers (layer 15+) on MobileNet to verify performance when server-side processing is minimal
2. **Extreme Skew Robustness:** Evaluate Hydra under 90%+ dominant label scenarios to test the grouping algorithm's stability with highly imbalanced distributions
3. **Resource Profiling:** Measure actual memory consumption and communication overhead for different G values on embedded hardware targets