---
ver: rpa2
title: 'SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration'
arxiv_id: '2511.03344'
source_url: https://arxiv.org/abs/2511.03344
tags:
- rashomon
- trees
- sortd
- node
- solution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SORTD is a novel framework for efficiently computing Rashomon sets
  of sparse decision trees, which are sets of trees with similar performance but varying
  structures. Unlike existing methods that generate trees without ordering, SORTD
  produces them in ascending order of their objective value, enabling anytime behavior
  and early termination.
---

# SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration

## Quick Facts
- arXiv ID: 2511.03344
- Source URL: https://arxiv.org/abs/2511.03344
- Reference count: 40
- Primary result: Achieves up to two orders of magnitude speed improvements and one order of magnitude memory reduction over TreeFARMS

## Executive Summary
SORTeD is a novel framework for efficiently computing Rashomon sets of sparse decision trees, which are sets of trees with similar performance but varying structures. Unlike existing methods that generate trees without ordering, SORTeD produces them in ascending order of their objective value, enabling anytime behavior and early termination. The framework incorporates a specialized depth-two solver and supports separable totally ordered objectives for direct computation, as well as separable and partially ordered objectives for post-hoc evaluation. Experiments show that SORTeD achieves up to two orders of magnitude speed improvements over the state-of-the-art TreeFARMS, with memory usage reduced by up to an order of magnitude.

## Method Summary
SORTeD computes Rashomon sets through a best-first search strategy that generates trees in ascending order of their objective value. The framework integrates a specialized depth-two solver that precomputes frequency counts for efficient split evaluation, avoiding recursive dataset splitting. Solutions are maintained in Sorted Solution Lists (SSLs) at each search node, with lazy evaluation and upper bounding for memory efficiency. The method requires binary features and supports separable totally ordered objectives directly, with partial ordering support through post-hoc evaluation. This approach enables anytime behavior where valid solutions are available throughout the computation process.

## Key Results
- Achieves up to 100x speed improvements over TreeFARMS on benchmark datasets
- Reduces memory usage by up to 10x compared to state-of-the-art methods
- Enables practical exploration of Rashomon sets for tasks like variable importance analysis and fairness evaluation
- Supports both separable totally ordered objectives for direct computation and separable partially ordered objectives for post-hoc evaluation

## Why This Works (Mechanism)

### Mechanism 1: In-Order Enumeration via Best-First Search
SORTeD provides "anytime" behavior by producing trees in non-decreasing order of objective value through best-first search. Each node maintains a Sorted Solution List (SSL) and selects the "helper node" with the minimum next solution value. This lazy enumeration strategy computes new solutions only when needed, contrasting with depth-first search approaches that enumerate all valid solutions regardless of order. The mechanism assumes the objective function is separable and totally ordered; if partially ordered, a single "best" path cannot be strictly defined for traversal.

### Mechanism 2: Runtime Reduction via Frequency Counting
The framework achieves significant speedups by incorporating a specialized depth-two solver that precomputes frequency counts (e.g., $Q^+(f_i)$, $Q^+(f_i, f_j)$) for feature occurrences. When evaluating potential splits at depth ≤ 2, it calculates misclassification costs directly from these counts using algebraic set operations rather than filtering the dataset repeatedly. This optimization relies heavily on the binary nature of features, treating them as presence/absence flags for efficient counting.

### Mechanism 3: Memory Efficiency via Lazy Evaluation and Bounding
SORTeD reduces memory usage through lazy evaluation where solutions are only generated when requested by the parent node, preventing storage of massive intermediate sets. Each search node maintains an upper bound derived from the Rashomon tolerance, pruning helper nodes that cannot produce solutions within this bound. This assumes the Rashomon bound is effective at pruning; if the tolerance is set too wide, the bound becomes loose and pruning fails.

## Foundational Learning

- **Concept: Rashomon Sets** - The central object of study; a set of all models within a specific tolerance ε of the optimal loss. Why needed: Understanding this definition is crucial for knowing what SORTeD actually computes. Quick check: If I find a tree with loss 0.15 and my optimal tree has loss 0.10, is it in the Rashomon set defined by ε=0.5? (Answer: Yes, if 0.15 ≤ 0.10 × (1+0.5)).

- **Concept: Separable Objectives** - Objectives that can be decomposed into sums of costs of children plus cost of split. Why needed: The paper explicitly restricts its direct optimization to "separable and totally ordered objectives." Quick check: Why does the algorithm require the objective to be separable? (Answer: To compute the cost of a tree by summing the cached costs of its left and right subtrees).

- **Concept: Binary Feature Space** - The efficiency of the depth-two solver relies on binary features to compute frequency counts. Why needed: New engineers must know that continuous features must be binarized before entering the SORTeD pipeline. Quick check: Can I feed raw floating-point data into SORTeD? (Answer: No, it is limited to binary features; continuous data must be binarized first).

## Architecture Onboarding

- **Component map**: STreeD Integration -> Search Tree -> Search Nodes -> Helper Nodes -> Branching Nodes/Leaf Nodes -> Sorted Solution Lists (SSL) -> Candidates Queue (CQ)

- **Critical path**: The `GetNextSolution()` recursive call chain: Root node calls `GetNextSolution` → finds Helper Node with minimum `node.next` value → if Branching Node, pops from Candidates Queue (CQ) → triggers `ExploreCandidates` to generate new combinations → new solution added to SSL and returned

- **Design tradeoffs**: Sorting vs. Speed (maintenance of Candidates Queue adds overhead; unsorted DFS might be faster for tiny sets); Memory vs. Re-computation (caches frequency counts and solution objects, trading RAM for CPU cycles)

- **Failure signatures**: Timeouts on Deep Trees (if depth d ≥ 5 and λ is very small, search space explodes); Memory Overflow on High-Dimensional Data (if |F| > 100, frequency matrices may become large or branching nodes may saturate memory)

- **First 3 experiments**:
  1. **Anytime Verification**: Run SORTeD and TreeFARMS on a medium dataset (e.g., `compas`) with a strict time limit (e.g., 5s). Verify that SORTeD returns a non-empty set of high-quality trees while TreeFARMS returns nothing or random low-quality trees.
  2. **Depth-Two Solver Isolation**: Benchmark the "Depth-two subroutine" (Alg 3) against a standard recursive call for generating all depth-2 trees. Plot runtime against the number of features to confirm expected asymptotic improvement.
  3. **Post-Hoc Fairness Filter**: Generate a Rashomon set of size 1000 for a dataset with sensitive attributes. Implement a Python callback for "Equality of Opportunity" and filter the set. Confirm the Pareto front contains trees not found by optimizing accuracy alone.

## Open Questions the Paper Calls Out
None

## Limitations
- Feature restriction requiring binary preprocessing for continuous data, potentially impacting downstream analysis and fairness assessments
- Objective function constraint where non-separable metrics require post-hoc evaluation, potentially missing trees optimal for those metrics during search
- Scalability boundary where memory efficiency gains diminish when Rashomon tolerance is very loose or feature dimension is extremely high

## Confidence
- **High Confidence**: Speed improvement claims (2x-100x) are well-supported by controlled experiments across multiple datasets with consistent results
- **Medium Confidence**: Memory usage reduction claims depend heavily on specific hyperparameter settings (Rashomon tolerance, feature count)
- **Low Confidence**: Assertion that anytime behavior provides practical benefits in all scenarios requires more diverse use-case validation

## Next Checks
1. **Anytime Utility Test**: Measure practical value of early solutions by comparing downstream model selection quality when using first 10 trees versus full set on a real-world decision-making task
2. **Non-Separable Objective Evaluation**: Implement post-hoc filtering for a non-separable metric (e.g., F1-score) and assess whether filtered subset contains trees meaningfully different from those optimal for separable objective
3. **High-Dimensional Stress Test**: Run SORTeD on dataset with >100 binary features and document point where memory usage approaches TreeFARMS to identify practical scalability ceiling