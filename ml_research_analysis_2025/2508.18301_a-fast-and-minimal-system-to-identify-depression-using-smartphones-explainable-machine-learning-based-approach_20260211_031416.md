---
ver: rpa2
title: 'A Fast and Minimal System to Identify Depression Using Smartphones: Explainable
  Machine Learning-Based Approach'
arxiv_id: '2508.18301'
source_url: https://arxiv.org/abs/2508.18301
tags:
- data
- features
- usage
- number
- depression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents Mon Majhi, a fast and minimal system to identify
  depression using smartphone app usage data. The system retrieves 7 days of app usage
  data in under 1 second and uses machine learning models to classify individuals
  as depressed or non-depressed.
---

# A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach

## Quick Facts
- arXiv ID: 2508.18301
- Source URL: https://arxiv.org/abs/2508.18301
- Reference count: 40
- Primary result: 78.5% F1-score in identifying depressed individuals from smartphone app usage patterns

## Executive Summary
This paper presents Mon Majhi, a smartphone-based system that identifies depression by analyzing app usage patterns. The system retrieves 7 days of app usage data in under one second using Android's UsageStatsManager and extracts 219 behavioral features including entropy, session patterns, and diurnal usage. Using explainable machine learning (LightGBM and stacking classifiers), the system achieves 78.5% F1-score in distinguishing depressed from non-depressed university students, while providing interpretable feature importance through SHAP analysis.

## Method Summary
The system extracts 7-day smartphone usage data from 100 Bangladeshi students, calculating 219 features including Shannon entropy, Hamming distance, session types (micro, review, engage), and diurnal patterns. The data undergoes stable feature selection with 1000 bootstrap samples and threshold 0.77, selecting approximately 11 features. Models are trained using nested cross-validation (LOPOCV outer, 20-fold inner) with hyperparameter tuning via Bayesian optimization. The LightGBM model achieves the best performance (F1=78.5%, sensitivity=82.4%, precision=75%), while a stacking classifier using top 5 models achieves precision=77.4% and sensitivity=80.4%.

## Key Results
- Achieved 78.5% F1-score, 82.4% sensitivity, and 75% precision in classifying depression status
- LightGBM outperformed 12 other algorithms and stacking models in F1-score
- SHAP analysis revealed that higher entropy in usage patterns negatively impacted depression predictions, while education app usage on weekdays positively correlated with non-depressed status

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Variability in smartphone app usage patterns, specifically entropy and session distribution, serves as a behavioral proxy for depression status.
- **Mechanism:** The system calculates Shannon entropy and session types from usage logs, assuming depressed individuals exhibit different "app signatures" characterized by lower diversity or irregular timing.
- **Core assumption:** Smartphone usage behavior correlates sufficiently with mental state to act as a discriminative feature.
- **Evidence anchors:** Abstract mentions identifying depressed students using app usage patterns; pages 5-6 define entropy and note different app signatures between depressed and non-depressed; page 15-16 shows SHAP analysis linking higher entropy to non-depressed predictions.
- **Break condition:** If users frequently loan their phones to others or multiple users share a device, the behavioral signature would become noisy.

### Mechanism 2
- **Claim:** Specific app categories (Education vs. Photo/Video) and their temporal usage provide directional signals for classification.
- **Mechanism:** The system categorizes apps and extracts time-spent features, positing that high engagement with Education apps is protective while high variability in Photo/Video apps is associated with depression.
- **Core assumption:** App categories serve as consistent proxies for user intent and psychological state.
- **Evidence anchors:** Abstract notes non-depressed students spent more time on education apps; page 16 shows weekday education usage increases probability toward non-depressed group.
- **Break condition:** If a user primarily uses Photo apps for professional work rather than social/emotional reasons, the signal may invert or become noise.

### Mechanism 3
- **Claim:** Instant retrieval of historical usage data minimizes "research reactivity" compared to background-sensing systems.
- **Mechanism:** Unlike continuous background sensing that consumes battery and alerts users, this system queries Android UsageStatsManager for past 7 days on-demand (mean 307ms).
- **Core assumption:** Users perceive on-demand data pulls as less intrusive, leading to more natural behavior and lower attrition.
- **Evidence anchors:** Abstract highlights <1 second retrieval; page 2 argues existing systems cause Hawthorne effects; page 3 details technical implementation using UsageStatsManager.
- **Break condition:** If Android OS restricts UsageStatsManager access or users deny usage permissions, the data retrieval mechanism fails.

## Foundational Learning

- **Concept:** **Shannon Entropy in Behavioral Analysis**
  - **Why needed here:** The paper relies on entropy to quantify predictability vs. randomness of app selection patterns, where lower entropy implies repetitive behavior.
  - **Quick check question:** If a user opens only WhatsApp for 5 hours straight, would their app usage entropy be high or low? (Answer: Low, approaching 0).

- **Concept:** **Leave-One-Participant-Out Cross-Validation (LOPOCV)**
  - **Why needed here:** With small N=100, LOPOCV ensures the model is tested on completely unseen participants, rigorously testing generalizability.
  - **Quick check question:** In a dataset of 100 participants, how many iterations are required for one round of LOPOCV? (Answer: 100).

- **Concept:** **Explainable AI (SHAP Values)**
  - **Why needed here:** The paper emphasizes parsimonious models; SHAP identifies which features drive depression predictions, making the model clinically useful.
  - **Quick check question:** If a feature has a high SHAP value for a specific prediction, does it mean that feature increased or decreased the probability of that class? (Answer: It contributed positively to the log-odds of that specific class).

## Architecture Onboarding

- **Component map:** Android App (Java UsageStatsManager) -> Raw Event Logs -> Google Firebase (Realtime Database) -> Python pipeline -> 219 features -> LGBM/Stacking models

- **Critical path:** Feature extraction pipeline is the bottleneck, requiring strict timestamp handling for diurnal splits and managing the 45-second session threshold.

- **Design tradeoffs:**
  - Recency vs. Accuracy: Uses only 7 days of data to ensure data integrity despite limiting "memory" of the system
  - Simplicity vs. Granularity: Uses app categories rather than specific names to reduce dimensionality and privacy concerns, though losing granular detail

- **Failure signatures:**
  - API Limitation Failure: Retrieval time spikes >1s or data returns empty if usage history is cleared
  - Category Mapping Failure: New/obscure apps not in Google Play may be miscategorized
  - Model Drift: Model trained on 2020 pandemic data may not generalize to post-pandemic behavior

- **First 3 experiments:**
  1. Latency Profiling: Test queryUsageStats function across Android versions (API 21-33) with varying event logs (1k-20k events) to confirm <1s retrieval claim
  2. Session Threshold Sensitivity: Recalculate session features using 30s and 60s thresholds to measure impact on model F1-score
  3. Feature Ablation: Train baseline model using only aggregate usage vs. full feature set to quantify value added by behavioral markers

## Open Questions the Paper Calls Out
- Can the system maintain classification performance when validated on a large-scale, gender-balanced dataset?
- Is the 7-day app usage signature robust enough to accurately detect onset or remission of depressive episodes over time?
- Do the identified behavioral markers generalize to non-student adults in other cultural contexts?

## Limitations
- Findings based on small, single-country sample (N=100 Bangladeshi students) limiting generalizability
- Relies entirely on Android's UsageStatsManager which may face future API restrictions
- Model trained on 2020 pandemic data may experience significant drift in post-pandemic usage patterns

## Confidence
- **High confidence**: Technical implementation of instant data retrieval using Android's UsageStatsManager
- **Medium confidence**: Classification performance metrics (F1=78.5%) within studied population
- **Medium confidence**: Behavioral mechanism linking entropy and app categories to depression status
- **Low confidence**: Assumption that on-demand retrieval completely eliminates Hawthorne effects

## Next Checks
1. Cross-cultural validation: Test system on smartphone usage data from at least 100 participants across 3 different countries
2. Longitudinal stability check: Evaluate model performance using pre-pandemic (2019) and post-pandemic (2023) usage data from same population
3. Hawthorne effect comparison: Conduct controlled study comparing behavioral patterns between instant retrieval vs. continuous background sensing users