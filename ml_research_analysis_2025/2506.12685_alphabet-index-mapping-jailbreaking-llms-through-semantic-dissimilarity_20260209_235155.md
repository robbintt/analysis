---
ver: rpa2
title: 'Alphabet Index Mapping: Jailbreaking LLMs through Semantic Dissimilarity'
arxiv_id: '2506.12685'
source_url: https://arxiv.org/abs/2506.12685
tags:
- semantic
- flipattack
- prompt
- attack
- decoding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how semantic dissimilarity between original
  and manipulated prompts affects jailbreak success in large language models (LLMs).
  The authors analyze FlipAttack, a prompt-flipping jailbreak method, and propose
  Alphabet Index Mapping (AIM), a novel attack that transforms text into alphabet
  indices to maximize semantic dissimilarity.
---

# Alphabet Index Mapping: Jailbreaking LLMs through Semantic Dissimilarity
## Quick Facts
- arXiv ID: 2506.12685
- Source URL: https://arxiv.org/abs/2506.12685
- Reference count: 3
- Primary result: AIM achieves 94% ASR on AdvBench subset, outperforming FlipAttack (88%)

## Executive Summary
This paper investigates how semantic dissimilarity between original and manipulated prompts affects jailbreak success in large language models (LLMs). The authors analyze FlipAttack, a prompt-flipping jailbreak method, and propose Alphabet Index Mapping (AIM), a novel attack that transforms text into alphabet indices to maximize semantic dissimilarity. Using UMAP visualizations and cosine similarity analysis on GPT-4 embeddings, they show AIM achieves 94% attack success rate (ASR) on a subset of AdvBench, outperforming FlipAttack (88%) and other methods. While high semantic dissimilarity correlates with higher ASR, the results also highlight the importance of maintaining decodability. AIM's failures were refusals (not decoding errors), suggesting safety filters can still block harmful requests even after decoding. The study contributes both a deeper understanding of prompt obfuscation mechanics and a highly effective new jailbreak technique.

## Method Summary
The authors propose Alphabet Index Mapping (AIM) as a novel jailbreak technique that converts text into alphabet indices to maximize semantic dissimilarity while maintaining decodability. The method uses mod4 decoding to transform prompts into sequences of numbers (0-3) representing letter positions in the alphabet. They compare AIM against FlipAttack and other methods using GPT-4 embeddings to measure semantic similarity, visualizing results with UMAP. The evaluation uses a subset of 50 AdvBench jailbreak prompts, measuring attack success rates and analyzing the relationship between semantic dissimilarity and jailbreak effectiveness.

## Key Results
- AIM achieves 94% attack success rate (ASR) on a subset of AdvBench, outperforming FlipAttack (88%) and other methods
- High semantic dissimilarity correlates with higher ASR, but maintaining decodability is crucial for success
- AIM's failures were refusals rather than decoding errors, indicating safety filters can still block harmful requests after decoding

## Why This Works (Mechanism)
AIM works by transforming prompts into alphabet indices, creating high semantic dissimilarity from the original text while maintaining the ability to decode and reconstruct the harmful request. The mod4 encoding ensures the transformed text appears random to the model but can be reliably decoded back to the original prompt. This semantic dissimilarity helps bypass content filters that rely on detecting harmful patterns in the original text format, while the maintained decodability ensures the LLM can still understand and respond to the harmful request.

## Foundational Learning
- Semantic similarity measures (cosine similarity on embeddings): Why needed - to quantify how much AIM transforms the original prompt; Quick check - compare cosine similarity between original and AIM-transformed prompts
- UMAP dimensionality reduction: Why needed - to visualize high-dimensional embedding relationships; Quick check - verify UMAP plots show clear separation between original and transformed prompts
- Mod4 encoding/decoding: Why needed - the core transformation mechanism of AIM; Quick check - ensure round-trip encoding/decoding preserves the original text

## Architecture Onboarding
- Component map: Original Prompt -> AIM Encoding (Alphabet Indices) -> LLM Input -> Response
- Critical path: Encoding transformation must preserve decodability while maximizing semantic dissimilarity
- Design tradeoffs: Higher dissimilarity improves jailbreak success but risks losing decodability
- Failure signatures: AIM failures manifest as refusals (safety filters activated) rather than decoding errors
- First experiments: 1) Measure semantic similarity between original and AIM-transformed prompts 2) Test AIM decoding reliability across different inputs 3) Compare AIM ASR against baseline methods on small prompt set

## Open Questions the Paper Calls Out
None

## Limitations
- Focus on single decoding method (mod4) may limit generalizability to other decoding approaches
- Analysis uses only a subset of AdvBench (50 prompts), which may not represent full diversity of jailbreak scenarios
- Primarily relies on GPT-4 embeddings for semantic similarity, may not capture complexity across different models
- Does not explore potential defenses against AIM or other semantic-dissimilarity-based attacks

## Confidence
- High: The core methodology of Alphabet Index Mapping (AIM) and its implementation are well-documented and reproducible
- Medium: The effectiveness of AIM relative to FlipAttack and other methods is demonstrated, but may vary with different datasets or decoding strategies
- Low: The broader implications of semantic dissimilarity for jailbreak success across diverse LLMs and safety protocols are not fully explored

## Next Checks
1. Test AIM across multiple decoding methods and larger, more diverse jailbreak prompt datasets to assess generalizability
2. Evaluate AIM's effectiveness against a broader range of LLMs, including those with different architectures and safety training approaches
3. Investigate potential defensive strategies, such as adversarial training or semantic similarity-based detection, to mitigate AIM-style attacks