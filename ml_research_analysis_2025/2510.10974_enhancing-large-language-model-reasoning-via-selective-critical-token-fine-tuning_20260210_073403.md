---
ver: rpa2
title: Enhancing Large Language Model Reasoning via Selective Critical Token Fine-Tuning
arxiv_id: '2510.10974'
source_url: https://arxiv.org/abs/2510.10974
tags:
- tokens
- critical
- reasoning
- fine-tuning
- qwen2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Critical Token Fine-tuning (CFT), a method
  that improves large language model reasoning by updating only a small subset of
  tokens identified as functionally indispensable for correctness, using counterfactual
  perturbations. Unlike standard fine-tuning that treats all tokens equally, CFT focuses
  gradient updates on critical reasoning steps while preserving the diversity of non-critical
  tokens.
---

# Enhancing Large Language Model Reasoning via Selective Critical Token Fine-Tuning

## Quick Facts
- **arXiv ID**: 2510.10974
- **Source URL**: https://arxiv.org/abs/2510.10974
- **Reference count**: 33
- **Primary result**: CFT improves mathematical reasoning accuracy by training on <12% of tokens while maintaining higher sampling diversity

## Executive Summary
This paper introduces Critical Token Fine-tuning (CFT), a method that improves large language model reasoning by updating only a small subset of tokens identified as functionally indispensable for correctness, using counterfactual perturbations. Unlike standard fine-tuning that treats all tokens equally, CFT focuses gradient updates on critical reasoning steps while preserving the diversity of non-critical tokens. Evaluated across five models and eleven mathematical reasoning benchmarks, CFT achieves higher accuracy than standard fine-tuning and other baselines while training on less than 12% of tokens. It also improves inference-time scaling by enhancing sampling diversity and serves as a stronger initialization for reinforcement learning, sustaining performance gains with better exploration. Results show CFT's effectiveness extends beyond math to domains like medical QA, highlighting its potential as a general fine-tuning framework.

## Method Summary
CFT identifies critical tokens through counterfactual perturbations: for each token in a correct response, substitute it with top-k alternatives and regenerate the continuation greedily. If all substitutions produce incorrect answers, mark the original token as critical. During training, standard cross-entropy loss is masked so gradients flow only through critical tokens. The method uses a Strict-3 criterion where a token is critical if both top-2 and top-3 alternatives fail to preserve correctness. Training is performed using the OpenRLHF framework with cosine decay schedules and learning rate sweeps across models. The approach preserves output diversity by not forcing the model toward single choices at non-critical positions, which enables better exploration during reinforcement learning initialization.

## Key Results
- CFT achieves 78.0% accuracy on GSM8K test set compared to 72.8% for standard fine-tuning on Qwen2.5-7B
- Training on less than 12% of tokens while maintaining or exceeding baseline performance
- Higher sampling diversity measured by Pass@N metrics compared to standard fine-tuning
- Better RL initialization quality with sustained performance gains and higher entropy during training

## Why This Works (Mechanism)

### Mechanism 1: Counterfactual Perturbation Identifies Causally Necessary Tokens
Replacing each token with top-k alternatives and checking final-answer correctness isolates tokens functionally required for reasoning success. For token y_t, substitute with top-2/3 alternatives, greedily regenerate the continuation, and verify correctness. If all substitutions produce incorrect answers, mark y_t as critical. This works because correctness of the final answer serves as a sufficient proxy for whether a token is causally indispensable in the reasoning chain.

### Mechanism 2: Selective Gradient Masking Preserves Distribution Diversity
Masking loss at non-critical tokens prevents mode-seeking updates from collapsing the distribution at replaceable positions. When c_t = 0, the gradient is zero; the model does not push p_t,gt → 1 at that position. This works because non-critical tokens have multiple valid alternatives; forcing the model toward a single choice unnecessarily reduces entropy and harms generalization.

### Mechanism 3: Higher Entropy at RL Initialization Enables Sustained Exploration
CFT-initialized models maintain higher output entropy at the start of RL, delaying entropy collapse and enabling continued learning. By not collapsing distributions at non-critical positions during fine-tuning, CFT leaves more probability mass on alternative reasoning paths. RL then explores this broader space before converging, resulting in better sustained performance.

## Foundational Learning

- **Concept**: Cross-entropy loss and gradient flow
  - Why needed here: Understanding why setting c_t = 0 zeroes the gradient requires knowing that ∂ℓ/∂z = (p − one-hot)
  - Quick check question: What happens to the gradient at position t when the loss weight is set to zero?

- **Concept**: Greedy vs. sampling-based decoding
  - Why needed here: Counterfactual rollouts use greedy decoding for efficiency; understanding this choice vs. sampling-based verification matters for annotation quality
  - Quick check question: Why does greedy decoding suffice for identifying critical tokens rather than sampling multiple continuations?

- **Concept**: Mode collapse in supervised fine-tuning
  - Why needed here: The paper frames CFT as a solution to SFT-induced distribution collapse at non-critical tokens
  - Quick check question: What is the mechanism by which uniform cross-entropy loss reduces output diversity?

## Architecture Onboarding

- **Component map**: Data preparation (run greedy decoding → filter correct responses → annotate critical tokens via batched counterfactual rollouts) → Training loop (standard SFT infrastructure with per-token loss masking) → Inference (no changes required)

- **Critical path**: Counterfactual annotation is the computational bottleneck. Batched parallel rollouts reduce time from ~13h to ~0.5h per 1k samples on 8×A100 for Qwen2.5-7B.

- **Design tradeoffs**:
  - k value: Strict-3 yields best accuracy but is more conservative; Strict-2 is slightly weaker but faster
  - Annotation source: Self-annotated data outperforms transferred annotations, especially across families with different tokenizers
  - Number-only vs. full critical set: Number-only training captures substantial signal for Qwen but degrades sharply for LLaMA

- **Failure signatures**:
  - Low critical-token ratio (<5%) may indicate overly strict k or model overconfidence; consider loosening to Strict-2
  - Transferred SFT degrading vs. greedy SFT suggests tokenizer/architecture mismatch; use scoring-based identification instead of reusing annotations
  - RL entropy collapsing early suggests insufficient non-critical token preservation; verify masking is applied correctly

- **First 3 experiments**:
  1. **Baseline sanity check**: Compare SFT vs. CFT on Qwen2.5-7B on GSM8K alone. Expected: CFT should show +3–6 percentage point improvement. If not, check that critical token mask is being applied to loss, not just logged.
  2. **Critical token annotation efficiency**: Measure sequential vs. batched annotation time for 100 samples. Target: >10× speedup with batching. If not achieved, check KV-cache reuse and batch padding efficiency.
  3. **RL initialization comparison**: Initialize two GRPO runs from SFT and CFT checkpoints on GSM8K+MATH. Track entropy and accuracy curves for 100 steps. Expected: CFT-initialized model maintains higher entropy and achieves higher final accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
Can CFT be effectively adapted for unstructured, open-ended tasks such as creative writing or storytelling? The paper notes that applicability to unstructured tasks remains an area for future exploration, as tasks involving creativity pose unique challenges due to the inherent ambiguity and flexibility of their solutions. The current framework defines "criticality" by verifying if a perturbed token changes the correctness of the final answer, which does not translate easily to subjective outputs.

### Open Question 2
How can the critical token identification process be generalized to domains that lack automated verifiers? The methodology strictly relies on a verification function F(Y, A) to confirm correctness, and the paper notes the method extends to tasks with verifiable numeric answers or multiple-choice formats. It remains unclear how to isolate critical tokens in reasoning tasks where the final answer cannot be programmatically verified.

### Open Question 3
Can critical token masks be transferred directly between models with different tokenizers without relying on probability-based scoring proxies? The paper notes that for models with different tokenizers, critical-token annotations cannot be reused, necessitating a scoring-based strategy instead of direct transfer. It remains unclear if the semantic "criticality" of a token is a property of the reasoning path itself or inextricably linked to the specific tokenizer and vocabulary.

## Limitations

- **Verification Function Reliability**: The critical token identification mechanism relies on a binary correctness function that may struggle with multi-step reasoning tasks where intermediate steps are semantically valid but lead to incorrect final answers.
- **Architecture-Specific Generalization**: Results show significant performance variation across model families, with a 9.1 percentage point gap between Qwen2.5-7B and LLaMA-3.1-8B, suggesting CFT's effectiveness is not uniform across architectures.
- **Computational Overhead in Critical Token Annotation**: Despite 25× speedup, the method still requires generating approximately 3 rollouts per token, creating significant computational overhead that scales with model size and sequence length.

## Confidence

- **High Confidence**: The core claim that masking gradients at non-critical tokens preserves output diversity while focusing learning on essential reasoning steps is well-supported by controlled experiments showing SFT's mode collapse versus CFT's maintained entropy.
- **Medium Confidence**: The claim that CFT provides superior RL initialization by maintaining higher entropy is supported by entropy curves showing delayed collapse, but the causal mechanism is not fully established.
- **Low Confidence**: The assertion that CFT generalizes beyond mathematical reasoning to domains like medical QA is based on a single dataset without systematic exploration of what makes a domain amenable to CFT.

## Next Checks

1. **Verification Function Ablation**: Systematically evaluate CFT performance using different verification granularities - from binary correctness to partial credit scoring that accounts for intermediate reasoning quality. Measure how verification function design affects critical token identification accuracy and downstream performance across reasoning complexity levels.

2. **Cross-Architecture Critical Token Transferability**: Train critical token annotations on one model family (e.g., Qwen) and evaluate whether transferring these annotations to another family (e.g., LLaMA) maintains performance benefits. This would quantify the extent to which critical tokens are architecture-specific versus task-specific.

3. **Long-Horizon Reasoning Robustness**: Test CFT on tasks requiring 5+ reasoning steps (e.g., complex mathematical proofs or multi-hop inference problems) to evaluate whether the greedy verification approach remains reliable when local substitutions can have cascading effects on reasoning validity.