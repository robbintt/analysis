---
ver: rpa2
title: 'Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related
  Work Generation'
arxiv_id: '2505.19647'
source_url: https://arxiv.org/abs/2505.19647
tags:
- papers
- work
- related
- content
- section
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a multi-agent framework for full-text-based
  related work generation (RWG) to address shallow comprehension and isolated explanations
  in existing methods. The framework consists of a selector, reader, and writer agents
  that iteratively process papers while maintaining a shared working memory.
---

# Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation

## Quick Facts
- arXiv ID: 2505.19647
- Source URL: https://arxiv.org/abs/2505.19647
- Reference count: 14
- Primary result: Graph-aware multi-agent framework achieves state-of-the-art results in full-text related work generation through iterative selective reading with citation-graph constraints

## Executive Summary
This paper proposes a multi-agent framework for full-text-based related work generation that addresses shallow comprehension and isolated explanations in existing methods. The framework consists of three agents - selector, reader, and writer - that iteratively process papers while maintaining a shared 4096-token working memory. Two graph-aware selectors (co-occurrence and citation graphs) optimize reading order to capture inter-paper relationships. Experiments across three base models show consistent performance improvements, with graph-aware selectors achieving state-of-the-art results in both LLM-based and graph-based metrics, demonstrating better logical coherence and tighter connections between references.

## Method Summary
The framework uses a three-agent system: the selector chooses which paper section to read next based on current memory and optional graph structure, the reader processes the selected section and updates the JSON-structured working memory (capped at 4096 tokens), and the writer generates the final related work section from the accumulated memory. The system operates iteratively until the selector outputs "End". Five selector variants are tested: SR, RR, Vanilla, Graph-Co, and Graph-Ci, with the latter two using citation and co-occurrence graphs respectively to constrain reading order and capture inter-paper relationships.

## Key Results
- Graph-Ci selector achieves highest performance in graph metrics (Avg Edges, Node Degree, Clustering Coefficient)
- Framework shows consistent improvements across three base models (Llama3-8B, GPT-4o, Claude-3-Haiku)
- Better logical coherence and tighter connections between references compared to baselines
- Memory retention ratio of 88-96% across models, with attribution accuracy of 90-95%

## Why This Works (Mechanism)

### Mechanism 1
Iterative selective reading with bounded working memory improves comprehension over single-pass full-text processing. The selector-reader loop maintains a 4096-token working memory that is explicitly reorganized at each step, forcing prioritization of task-relevant information and discarding irrelevant content.

### Mechanism 2
Citation-graph-constrained reading order captures inter-paper relationships better than sequential or unconstrained reading. The graph-aware selector operates within one-hop subgraphs, constraining next-section selection to either continue the current paper or jump to a directly cited/citing paper, explicitly encoding dependency relationships into the reading trajectory.

### Mechanism 3
Explicit graph structure injection at selection time produces more interconnected output than implicit graph integration. The selector receives the full graph structure and current position, making globally informed decisions within locally constrained options—unlike prior work that implicitly encodes graphs into embeddings.

## Foundational Learning

**Multi-agent orchestration with shared state**: The framework delegates distinct responsibilities (selection, reading, writing) to separate agents that must coordinate through shared working memory. Quick check: Can you trace how information flows from selector output → reader input → memory update → next selector decision?

**Graph traversal as inductive bias**: The graph-aware selector uses graph structure to constrain action space, requiring understanding of graph representations and traversal algorithms. Quick check: Given a citation graph, can you identify the one-hop neighborhood and valid next-hop nodes?

**Bounded memory with selective retention**: The 4096-token memory limit forces explicit prioritization; the reader must decide what to keep, compress, or discard at each step. Quick check: If memory is at capacity and new relevant information arrives, what strategies can the reader employ?

## Architecture Onboarding

**Component map**: Selector (takes abstracts, memory, history, optional graph → outputs paper_id, section) -> Reader (takes section content, memory → outputs updated memory JSON) -> Working Memory (JSON state persisting across iterations) -> Writer (takes final memory, abstracts, citing paper context → outputs RWS)

**Critical path**: 1) Initialize memory with citing paper context 2) Selector chooses first section 3) Reader processes section, updates memory 4) Repeat 2-3 until "End" 5) Writer generates output

**Design tradeoffs**: Graph-Ci vs Graph-Co (citation graphs provide explicit constraints but may be sparse; co-occurrence graphs are denser but noisier); Memory size (4096 tokens balances retention vs context effectiveness); Section-level vs paper-level reading (paper-level used because section-level is "relatively fixed")

**Failure signatures**: Low retention ratio (Reader fails to maintain all cited papers); Attribution errors (paper A's details incorrectly assigned to paper B); Sparse output graph (generated RWS cites papers in isolation)

**First 3 experiments**: 1) Ablate graph constraint: Run Vanilla selector vs Graph-Ci on same papers; measure graph metrics 2) Memory size sweep: Test 2K, 4K, 8K token limits with Graph-Ci; identify performance plateaus 3) Error injection test: Corrupt 10-20% of citation graph edges; measure robustness of Graph-Ci vs Graph-Co vs Vanilla

## Open Questions the Paper Calls Out

**Open Question 1**: Can the framework be extended to automatically retrieve relevant references from a corpus given only keywords or the citing paper, rather than requiring pre-defined references?

**Open Question 2**: How can the model be improved to better handle varying levels of reference detail (concise vs elaborate summarization) to close the performance gap with human-written related work?

**Open Question 3**: Can the co-occurrence graph selector be improved via edge weighting or pruning to mitigate the negative effects of high connectivity?

**Open Question 4**: How does the framework's performance scale when processing the full OARelatedWork dataset rather than the 10% subset used in experiments?

## Limitations

The framework's performance is heavily dependent on base model capabilities, with weaker models showing significant retention ratio drops (88% vs 96%) and potential attribution errors. The evaluation relies entirely on LLM-based metrics without human validation of practical utility. The 4096-token memory constraint may be insufficient for papers with highly interconnected concepts, and the framework requires pre-defined reference sets rather than automatic retrieval.

## Confidence

**High Confidence**: The iterative selective reading mechanism with bounded memory demonstrably improves over single-pass approaches (supported by performance improvements across three base models).

**Medium Confidence**: The claim that explicit graph structure injection outperforms implicit integration has limited corpus support and requires additional validation.

**Low Confidence**: The framework's robustness to noisy or incomplete citation graphs is not well-established, and the optimal memory size of 4096 tokens across all paper types is assumed rather than rigorously validated.

## Next Checks

1. **Graph Robustness Test**: Inject controlled noise (10-20% edge corruption) into citation graphs and measure performance degradation of Graph-Ci vs Graph-Co vs Vanilla selectors to validate robustness to graph quality.

2. **Human Evaluation Study**: Recruit domain experts to evaluate 20-30 generated related work sections for actual utility in academic writing and compare against LLM-based metrics.

3. **Memory Capacity Analysis**: Systematically test memory sizes (2K, 4K, 8K tokens) with Graph-Ci on papers spanning different semantic densities to identify performance plateaus and validate the 4096-token assumption.