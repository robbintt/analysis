---
ver: rpa2
title: Integrating Symbolic Execution with LLMs for Automated Generation of Program
  Specifications
arxiv_id: '2506.09550'
source_url: https://arxiv.org/abs/2506.09550
tags:
- loop
- symbolic
- execution
- generation
- program
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SESpec, a framework that combines symbolic
  execution with LLMs to automatically generate program specifications, including
  loop invariants, preconditions, and postconditions. The approach first uses symbolic
  execution to derive precise strongest postconditions for loop-free code segments
  and then guides an LLM to propose and iteratively refine loop invariants using structured
  templates based on symbolic execution results.
---

# Integrating Symbolic Execution with LLMs for Automated Generation of Program Specifications

## Quick Facts
- **arXiv ID:** 2506.09550
- **Source URL:** https://arxiv.org/abs/2506.09550
- **Reference count:** 38
- **Primary result:** SESpec framework achieves 87.21% accuracy on numerical benchmarks and significantly outperforms LLM-only approaches on complex data-structure verification tasks.

## Executive Summary
SESpec combines symbolic execution with large language models to automatically generate formal program specifications including loop invariants, preconditions, and postconditions. The approach uses symbolic execution to derive precise semantic context for loop-free code segments, then guides an LLM to propose and iteratively refine loop invariants using structured templates. Unlike prior tools, SESpec is goal-agnostic and doesn't require externally provided verification goals. The framework achieves state-of-the-art performance across numerical benchmarks and shows significant improvements on complex data-structure verification tasks involving structs and linked lists.

## Method Summary
SESpec operates through a pipeline where QCP symbolic execution engine computes path conditions and symbolic states for loop-free code segments. These are translated into ACSL skeletons with placeholder tags that constrain LLM output to logically grounded specifications. The LLM generates candidate specifications using "Think In Natural Language" reasoning, which are then validated by Frama-C's WP plugin. Failed verification triggers iterative refinement using structured strategies (syntax repair, strengthening, weakening) based on error feedback. The approach processes programs bottom-up, handling nested loops and function calls compositionally through a stack-based algorithm that ensures proper propagation of symbolic states and invariants.

## Key Results
- Achieves 87.21% accuracy on numerical benchmarks with GPT-4o, significantly outperforming LLM-only approaches (60% accuracy)
- Shows 2-3× higher success rates on complex benchmarks involving structs and linked lists compared to previous LLM-based methods
- Maintains >95% syntax correctness while improving validity rate from 60% to 87.21% through iterative refinement
- Performs competitively with specialized tools on numerical benchmarks while demonstrating broader applicability to complex data structures

## Why This Works (Mechanism)

### Mechanism 1: Symbolic Execution Provides Semantic Context
Symbolic execution computes precise path conditions and symbolic stores for loop-free segments, which are translated into ACSL skeletons with placeholder tags. This structurally constrains the LLM's output space, reducing hallucinations and syntactic errors by shifting from open-ended generation to template completion. The core assumption is that symbolic states accurately characterize behavioral constraints needed for invariant inference.

### Mechanism 2: Template-Driven Conditional Structure
Loop analysis classifies variables as unchanged, non-inductive, or inductive, enforcing conditional invariant structure: `(loop_entry_condition) ==> invariant_predicate`. This explicitly represents whether the loop is entered, capturing loop-entry conditions that pure LLM approaches consistently miss. The assumption is that variables can be cleanly categorized based on single-iteration unfolding.

### Mechanism 3: Iterative Refinement with Verifier Feedback
Failed verification triggers differentiated strategies mapped to error types - syntax repair, strengthening (for Termination failures), weakening/adjustment (for Base/Preservation failures), or regeneration. The LLM receives structured guidance prompts encoding these strategies. The core assumption is that the verifier produces actionable error messages that can be mapped to appropriate refinement strategies.

## Foundational Learning

- **Concept: Symbolic Execution and Path Conditions**
  - Why needed here: Understanding how QCP computes `(PC_π, σ_π)` pairs is essential for reading the translated ACSL skeletons that guide the LLM.
  - Quick check question: Given a branch `if (x > 0)`, what is the path condition for the true branch?

- **Concept: Loop Invariant Correctness Conditions**
  - Why needed here: The refinement module's strategies are directly indexed to Base, Preservation, and Termination failures.
  - Quick check question: If an invariant passes Preservation but fails Termination, should you strengthen or weaken it?

- **Concept: ACSL Annotation Syntax**
  - Why needed here: The LLM outputs ACSL; the Translator converts between QCPL and ACSL. Understanding `\at(var, Pre)`, `loop invariant`, `ensures` is prerequisite to debugging specification failures.
  - Quick check question: What does `\at(pIp, Pre)->len` mean in a loop invariant?

## Architecture Onboarding

- **Component map:** Executor (QCP) -> Translator -> Generator (LLM) -> Verifier (Frama-C/WP)
- **Critical path:** C source → Executor → SE Info (symbolic states) → Translator → Natural language + ACSL templates → LLM → Candidate specifications → Verifier → Valid/Invalid + errors → If invalid: errors → Translator → guidance prompt → LLM refinement (loop) → If valid: specifications → Translator → QCPL → Executor resumes
- **Design tradeoffs:**
  - Template precision vs. search diversity: Templates reduce hallucinations but constrain invariant forms; ablation shows 2% syntax drop but 30% validity gain
  - QCP's Coq-verified output vs. manual annotation requirement: QCP provides strong guarantees but requires loop/function annotations - SESpec automates this at the cost of relying on LLM correctness
  - Goal-agnostic vs. goal-directed generation: Produces stronger specifications without verification goals, but refinement optimization is goal-dependent
- **Failure signatures:**
  - Path explosion: Executor times out; SE Info incomplete. Mitigation: Scope symbolic execution to loop-free segments
  - Template mismatch: LLM output syntactically valid but semantically wrong; refinement exhausts iterations. Check if variable classification (unchanged/inductive) is correct
  - Nested loop propagation: Inner loop invariants incorrect → outer loop symbolic execution unsound. Process loops bottom-up; verify inner invariants independently first
- **First 3 experiments:**
  1. Single linear loop benchmark: Run SESpec on SyGuS dataset (133 programs). Verify that syntax rate >95% and accuracy >90% with GPT-4o. If not, inspect template generation for missing variable classifications.
  2. Goal-masking ablation: Run on Frama-C benchmark with and without verification goals. Expected: <10% accuracy drop. If drop is larger, check if refinement module is overfitting to goal-specific strengthening.
  3. Ablation by component: Run `Only LLM`, `LLM + SE`, `LLM + SE + REFINE` on 100-program subset. Reproduce paper's ablation curves. If refinement doesn't improve accuracy, inspect error-to-strategy mapping in Algorithm 4.

## Open Questions the Paper Calls Out

### Open Question 1
**How can symbolic execution-guided templates be adapted to effectively synthesize invariants for nested loops containing correlated induction variables?**
The current approach processes nested loops using pure LLM calls without symbolic execution-derived templates, as symbolic execution struggles to derive strong preconditions for nested contexts. Evidence would come from matching high performance on OOPSLA benchmark (nested loops) with linear loop benchmarks like SyGuS.

### Open Question 2
**Can the framework be extended to generate specifications for recursive functions, as opposed to the currently supported recursive data structures?**
The current symbolic engine requires manual annotations to handle function calls compositionally; recursive calls introduce circular dependencies that the bottom-up stack-based approach may not resolve without divergence. Evidence would come from successful evaluation on recursive algorithms showing valid pre-/postcondition synthesis without manual intervention.

### Open Question 3
**Does integrating symbolic sampling or targeted training strategies offer significant advantage over the current zero-shot, template-constrained approach for complex invariant generation?**
The current implementation relies on zero-shot prompting with strong structural constraints to avoid data leakage and overfitting. It's undetermined if sampling/training can navigate complex search space better than current refinement strategy without compromising generalizability. Evidence would come from ablation comparing fine-tuned or sampling-augmented models against SESpec baseline on non-linear benchmarks.

## Limitations
- Performance on highly nested loops and complex pointer arithmetic remains untested, with significant drop in success rates for nested loop benchmarks
- The framework's scalability to industrial-scale codebases with multiple interacting modules and complex memory patterns is unverified
- Custom benchmarks (list-S) lack comparison to specialized tools for linked list verification, limiting claims about broader applicability

## Confidence
- **High:** The mechanism of using symbolic execution to constrain LLM output space and reduce hallucinations is well-supported by template generation approach and ablation results showing 30% validity improvement
- **Medium:** Claims about goal-agnostic specification generation and competitive performance on numerical benchmarks are supported by experimental results but lack external validation against non-LLM methods on same datasets
- **Low:** Scalability claims for complex data structures are based on custom benchmarks without comparison to specialized tools for linked list verification

## Next Checks
1. **External Benchmark Validation:** Test SESpec on established verification benchmarks (e.g., SV-COMP) with ground-truth specifications to verify accuracy claims independently of paper's custom datasets
2. **Path Explosion Stress Test:** Systematically evaluate SESpec on programs with nested loops and complex control flow to measure QCP's path explosion limits and template approach's robustness
3. **Template Expressiveness Analysis:** Create benchmarks requiring non-standard invariant forms (e.g., disjunctive invariants, quantifiers) to test whether template constraints limit correctness on programs needing more expressive specifications