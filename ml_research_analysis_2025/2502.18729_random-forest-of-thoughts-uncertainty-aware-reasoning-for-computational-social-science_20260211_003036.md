---
ver: rpa2
title: 'Random Forest-of-Thoughts: Uncertainty-aware Reasoning for Computational Social
  Science'
arxiv_id: '2502.18729'
source_url: https://arxiv.org/abs/2502.18729
tags:
- thoughts
- social
- llms
- language
- prompting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Random Forest of Thoughts (RFoT), a prompting
  method for large language models that improves reasoning performance in computational
  social science by incorporating uncertainty and domain theory. RFoT uses iterative
  chain-of-thought prompting to generate diverse reasoning paths, evaluates their
  importance using Shapley values, and constructs a random forest ensemble from sampled
  subsets of high-quality thoughts.
---

# Random Forest-of-Thoughts: Uncertainty-aware Reasoning for Computational Social Science

## Quick Facts
- arXiv ID: 2502.18729
- Source URL: https://arxiv.org/abs/2502.18729
- Reference count: 28
- Key outcome: RFoT achieves 78.43% success rate and 80.52% weighted-F1 on happiness prediction, outperforming baseline prompting methods.

## Executive Summary
This paper introduces Random Forest of Thoughts (RFoT), a prompting method for large language models that improves reasoning performance in computational social science by incorporating uncertainty and domain theory. RFoT uses iterative chain-of-thought prompting to generate diverse reasoning paths, evaluates their importance using Shapley values, and constructs a random forest ensemble from sampled subsets of high-quality thoughts. The method was evaluated on two datasets—Chinese General Social Survey and European Social Survey—for happiness prediction tasks. Results show RFoT achieved up to 78.43% success rate and 80.52% weighted-F1 score, outperforming baseline prompting methods like CoT, Self-Consistency CoT, and ToT across both datasets and tested LLMs (Llama3-8B and Qwen2.5-7B).

## Method Summary
RFoT combines iterative chain-of-thought prompting with random forest ensemble learning. The method first generates multi-level thoughts (aspects, keywords, responses) from survey question-answer pairs using domain-aware prompts. Shapley values evaluate each thought's importance across all possible subsets. Bootstrap sampling with probability proportional to importance scores constructs a forest of thought trees. Predictions aggregate via majority voting across trees. The approach was tested on happiness prediction from Chinese General Social Survey (3,187 samples, 124 questions) and European Social Survey (15,557 samples, 102 questions) using Llama3-8B and Qwen2.5-7B.

## Key Results
- RFoT achieved 78.43% success rate and 80.52% weighted-F1 on CGSS dataset
- Outperformed Self-Consistency CoT (27.85s runtime vs 13.48s) and ToT on both datasets
- Maintained strong performance across both Llama3-8B and Qwen2.5-7B LLMs

## Why This Works (Mechanism)

### Mechanism 1: Uncertainty Exploration via Randomized Thought Sampling
RFoT uses bootstrap sampling to randomly select subsets of question-answer pairs and thoughts (weighted by Shapley importance), constructing multiple reasoning "trees." This explores a richer solution space than fixed CoT paths. Core assumption: Survey responses vary across respondents; different thought combinations capture this uncertainty better than single deterministic chains. Evidence: [abstract] "randomly selecting the sub-thoughts to build the forest of thoughts... extend the exploration and prediction of overall performance" [Section 4.3] "Instead of selecting a fixed deterministic set of thoughts... we combine bootstrap sampling" Related work on Multi-chain Graph Refinement confirms multi-path reasoning improves reliability, but RFoT-specific randomization is not externally validated. Break condition: If questionnaire structure is highly uniform across respondents with minimal branching, randomization overhead may not justify marginal gains.

### Mechanism 2: Shapley Value-Based Thought Importance Weighting
Shapley values compute marginal contribution of each thought across all possible subsets. Thoughts with higher ϕ scores are more likely selected as tree roots and in subsequent splits. Core assumption: Thoughts generated by ICoT have heterogeneous relevance; some are noise or redundant. Evidence: [Section 4.3] Equation 5 defines Shapley-based importance; Equation 6 selects top-k thoughts [Section 4.3] "reduce the noises contained in the questionnaires and improve the computing effectiveness" No direct external validation of Shapley-for-thoughts in LLM reasoning; assumption transfer from XAI literature. Break condition: If Shapley computation cost exceeds inference budget, or if generated thoughts are uniformly low-quality, weighting provides limited signal.

### Mechanism 3: Domain Theory Integration via Category-Aware Prompts
Structuring prompts around survey design categories (demographics, economics, lifestyle) aligns LLM reasoning with social science domain knowledge. ICoT generates thoughts per category, reflecting how survey questions branch based on prior answers. Core assumption: Survey question dependencies encode domain theories that LLMs can exploit via structured prompting. Evidence: [Section 1, Fig. 1] Questionnaire branching example showing conditional question paths [Section 4.2] "Domain theories reflected from different aspects behind questionnaires are considered" SYNTHIA and German General Personas papers show survey-derived prompting improves simulation accuracy, supporting domain-aware prompting generally. Break condition: If survey categories are weakly related to target variable, or if LLM lacks domain knowledge, category structure adds overhead without benefit.

## Foundational Learning

- Concept: **Shapley Values in Feature Attribution**
  - Why needed here: Core to RFoT's thought evaluation; you must understand marginal contribution calculation to debug importance scores
  - Quick check question: Given 3 features {A, B, C} and model output, how would you compute Shapley value for A?

- Concept: **Bootstrap Aggregating (Bagging)**
  - Why needed here: RFoT's random forest construction uses bootstrap sampling with replacement; understanding variance reduction via ensembles is essential
  - Quick check question: Why does sampling with replacement create "approximately i.i.d." datasets from a single source?

- Concept: **Chain-of-Thought Prompting Variants (CoT, SC-CoT, ToT)**
  - Why needed here: RFoT builds on and compares against these baselines; you need to recognize their left-to-right vs. tree-based reasoning differences
  - Quick check question: What is the key structural difference between Self-Consistency CoT and Tree of Thoughts?

## Architecture Onboarding

- Component map: Linguistic Cues Constructor -> ICoT Generator -> Shapley Evaluator -> Thought Selector -> RFoT Builder (DFS) -> Aggregator
- Critical path: ICoT generation → Shapley evaluation → Thought selection → Tree construction → Aggregation. Bottleneck is Shapley computation (O(2^n) naive; paper does not specify approximation).
- Design tradeoffs:
  - More trees (higher m) → better exploration but linear runtime increase
  - Higher k (more thoughts per tree) → richer reasoning but more noise and compute
  - Shapley vs. simpler importance (e.g., attention weights) → theoretically grounded but expensive
- Failure signatures:
  - Low consistency scores (Table 1) indicate LLM format drift — prompt engineering needed
  - Runtime blowup on large questionnaires suggests Shapley approximation required
  - If SC-CoT outperforms RFoT, likely insufficient thought diversity or poor importance estimation
- First 3 experiments:
  1. Ablation on Shapley vs. random thought selection: Is importance-weighting actually helping, or is randomization sufficient?
  2. Vary tree count m: Plot success rate vs. runtime to find efficiency sweet spot
  3. Cross-dataset transfer: Train ICoT exemplars on CGSS, test on ESS (and reverse) to assess domain generality

## Open Questions the Paper Calls Out
None

## Limitations
- Shapley value approximation method not specified, affecting reproducibility and scalability claims
- RFoT's performance heavily depends on ICoT generating meaningful intermediate reasoning
- Cross-dataset generalization untested beyond CGSS and ESS; performance on different survey types unknown

## Confidence
- High: Domain theory integration improves reasoning (supported by questionnaire structure evidence and related persona prompting work)
- Medium: Shapley-based importance weighting outperforms simpler selection methods (theoretically sound but no ablation vs. random/attention-based selection shown)
- Low: RFoT runtime improvements are generalizable (runtime comparison only against SC-CoT on two LLM-dataset pairs; no comparison to baseline ToT runtime)

## Next Checks
1. Ablation study: Replace Shapley weighting with random thought selection; if performance parity, importance scoring adds complexity without benefit
2. Tree count sensitivity: Systematically vary m (5, 10, 20, 50) to quantify exploration-exploitation tradeoff and identify optimal efficiency point
3. Few-shot exemplar robustness: Vary number and selection of exemplars in ICoT prompts (1-10 examples) to measure impact on thought quality and downstream RFoT performance