---
ver: rpa2
title: A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language
  Models
arxiv_id: '2507.22187'
source_url: https://arxiv.org/abs/2507.22187
tags:
- verb
- gahl
- gpt-4o
- parser
- estimates
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a pipeline for estimating Verb Frame Frequencies
  (VFFs) by using large language models (LLMs) for both sentence generation and syntactic
  parsing. The method leverages GPT-4o to generate 61,427 sentences across 476 verbs
  and then parses them into fine-grained syntactic frames.
---

# A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models

## Quick Facts
- **arXiv ID**: 2507.22187
- **Source URL**: https://arxiv.org/abs/2507.22187
- **Reference count**: 40
- **Primary result**: LLM-based pipeline estimates Verb Frame Frequencies with up to 2× stronger correlations to human-annotated data than traditional parsers

## Executive Summary
This paper introduces a scalable pipeline for estimating Verb Frame Frequencies (VFFs) using large language models (LLMs). The method combines GPT-4o for sentence generation with fine-grained syntactic parsing to produce VFF estimates that significantly outperform two widely used parsers (Berkeley Neural Parser and Stanford CoreNLP) in predicting human-annotated gold-standard data. The approach addresses critical gaps in coverage for understudied syntactic alternations and provides a powerful new tool for psycholinguistic and NLP research.

## Method Summary
The pipeline operates in two stages: first, GPT-4o generates 61,427 sentences across 476 verbs, producing diverse syntactic contexts; second, these sentences are parsed into fine-grained syntactic frames to estimate VFFs. The method leverages LLMs' ability to produce grammatically appropriate sentences that capture the full range of verb-argument structures. This approach enables scalable, customizable VFF estimation that fills gaps in existing resources, particularly for understudied syntactic alternations. The pipeline's effectiveness is demonstrated through its superior correlation with human-annotated gold-standard data compared to traditional parsing approaches.

## Key Results
- VFF estimates from the LLM pipeline show up to 2× stronger correlations with human-annotated data compared to Berkeley Neural Parser and Stanford CoreNLP
- The method successfully generates diverse sentences across 476 verbs, producing 61,427 total sentences
- The pipeline fills critical gaps in coverage for understudied syntactic alternations not well-represented in existing resources

## Why This Works (Mechanism)
The pipeline leverages LLMs' sophisticated language understanding to generate grammatically appropriate sentences that capture the full range of verb-argument structures. By using GPT-4o's generation capabilities, the method produces diverse syntactic contexts that traditional parsers often miss. The fine-grained parsing of these generated sentences allows for more accurate VFF estimation that better reflects human linguistic knowledge and usage patterns.

## Foundational Learning
- **Verb Frame Frequencies (VFFs)**: Statistical measures of how often verbs appear in specific syntactic constructions - needed to understand verb behavior and language processing
- **Syntactic alternations**: Different ways the same verb can combine with arguments (e.g., "John loaded hay onto the truck" vs "John loaded the truck with hay") - needed to capture verb flexibility
- **Large Language Models (LLMs)**: AI systems trained on massive text corpora that can generate and understand language - needed for scalable sentence generation
- **Fine-grained parsing**: Detailed syntactic analysis that identifies specific grammatical structures - needed for accurate VFF estimation
- **Gold-standard data**: Human-annotated reference datasets used for evaluation - needed to validate computational methods
- **Berkeley Neural Parser**: A state-of-the-art syntactic parser used as baseline - needed for comparison with traditional approaches

## Architecture Onboarding

**Component Map:**
GPT-4o (Sentence Generation) -> Fine-grained Parser (Syntactic Analysis) -> VFF Estimator (Frequency Calculation)

**Critical Path:**
1. Input verb list → 2. GPT-4o sentence generation → 3. Syntactic parsing → 4. VFF calculation → 5. Evaluation against gold standard

**Design Tradeoffs:**
- Generation quality vs. computational cost: Generating thousands of sentences per verb is computationally expensive but necessary for coverage
- Parser granularity vs. accuracy: Fine-grained parsing provides better VFF estimates but may introduce more parsing errors
- LLM dependency vs. reproducibility: Relying on GPT-4o limits accessibility but provides superior generation quality

**Failure Signatures:**
- Low diversity in generated sentences suggests inadequate prompting or LLM limitations
- Poor correlation with gold standard indicates parsing errors or unrepresentative generation
- High computational costs may make the approach impractical for resource-constrained settings

**3 First Experiments:**
1. Test GPT-4o's ability to generate diverse sentences for a small set of verbs with known syntactic alternations
2. Compare parsing accuracy of fine-grained parser on generated vs. naturally occurring sentences
3. Evaluate VFF estimates against human judgments for a subset of verb frames

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- The quality and representativeness of LLM-generated sentences for all verb-argument structures remains uncertain
- Results are limited to English and untested for other languages with different syntactic properties
- Computational costs of generating thousands of sentences per verb remain substantial

## Confidence

**High Confidence**: The methodology for combining LLM generation with syntactic parsing is sound and the improvement over baseline parsers is statistically robust for the tested dataset

**Medium Confidence**: The claim of "filling critical gaps" in coverage is supported but depends on which specific alternations are considered understudied in existing resources

**Medium Confidence**: The assertion that results enable "scalable, customizable VFF estimation" is valid for English but untested for other languages or specialized domains

## Next Checks
1. Conduct cross-linguistic validation by applying the pipeline to at least two additional languages with different syntactic properties to assess generalizability
2. Compare VFF estimates against additional human-annotated datasets beyond the Levin and Hovav (2013) corpus to test robustness across different annotation schemes
3. Perform ablation studies to quantify the relative contributions of GPT-4o's generation capabilities versus the parsing accuracy to the final VFF estimates