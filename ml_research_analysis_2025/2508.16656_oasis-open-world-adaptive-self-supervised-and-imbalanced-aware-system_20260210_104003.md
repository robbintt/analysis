---
ver: rpa2
title: 'OASIS: Open-world Adaptive Self-supervised and Imbalanced-aware System'
arxiv_id: '2508.16656'
source_url: https://arxiv.org/abs/2508.16656
tags:
- class
- shift
- label
- learning
- open-world
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses open-world problems where label shift, covariate
  shift, and unknown classes emerge simultaneously in dynamic environments, particularly
  when initial pre-training is conducted on class-imbalanced datasets. The authors
  propose OASIS, a framework that consists of imbalance-aware contrastive pre-training
  with borderline sample refinement, followed by self-supervised post-training with
  pseudo-labeling.
---

# OASIS: Open-world Adaptive Self-supervised and Imbalanced-aware System

## Quick Facts
- **arXiv ID:** 2508.16656
- **Source URL:** https://arxiv.org/abs/2508.16656
- **Reference count:** 40
- **Primary result:** Achieves average relative improvements of 13.74% in open-world settings and 12.18% under label shift scenarios compared to best-performing baselines.

## Executive Summary
This paper addresses open-world problems where label shift, covariate shift, and unknown classes emerge simultaneously in dynamic environments, particularly when initial pre-training is conducted on class-imbalanced datasets. The authors propose OASIS, a framework that consists of imbalance-aware contrastive pre-training with borderline sample refinement, followed by self-supervised post-training with pseudo-labeling. The pre-training phase improves classification performance for minority classes through a novel borderline sample refinement step that sharpens decision boundaries, while the post-training phase generates reliable pseudo-labels and adapts to open-world challenges. The method includes selective activation criteria to optimize computation during post-training. Experiments demonstrate that OASIS significantly outperforms state-of-the-art adaptation techniques across multiple benchmark datasets.

## Method Summary
OASIS is a two-phase framework designed to handle open-world adaptation under class imbalance. The pre-training phase employs imbalance-aware contrastive learning with a novel borderline sample refinement step that identifies samples with high Mahalanobis distance from class centroids and pulls them toward anchor samples (those closest to the centroid) using an L2 loss. This refines the decision boundary for minority classes. The post-training phase performs self-supervised adaptation using a dual-criteria pseudo-labeling strategy: if prediction entropy is low, use the predicted class; if entropy is high, assign labels based on geometric distance to class centroids if the Mahalanobis distance gap exceeds a threshold. Updates are triggered only when both prediction uncertainty (entropy) and distribution shift (cosine similarity of label distributions) exceed specified thresholds, optimizing computational efficiency.

## Key Results
- Achieves average relative improvements of 13.74% in open-world settings compared to state-of-the-art baselines
- Delivers 12.18% relative improvement under label shift scenarios
- Demonstrates effective handling of simultaneous label shift, covariate shift, and unknown class emergence
- Shows robust performance across CIFAR-10-LT, CIFAR-100-LT, and Tiny-ImageNet-LT datasets with imbalance factor ρ=10

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Refining representations of borderline samples during pre-training creates more distinct class boundaries, which appears to enable more reliable pseudo-labeling during the post-training phase.
- **Mechanism:** The paper utilizes a Borderline Sample Refinement (BSR) step where samples with high Mahalanobis distance (far from the class centroid) are identified. The model then applies a contrastive loss to pull these "borderline" samples closer to "anchor" samples (those closest to the centroid). This theoretically reduces intra-class variance and sharpens the decision boundaries.
- **Core assumption:** Samples with high Mahalanobis distance are primarily "borderline" cases that confuse the decision boundary, rather than outliers or noise.
- **Evidence anchors:**
  - [abstract] "...borderline sample refinement step critically improves the robustness of the decision boundary..."
  - [section 4.2] "...guiding them toward their respective class centroids in the latent space."
  - [corpus] Corpus evidence regarding this specific "borderline refinement" technique is weak among neighbors; however, "OpenHAIV" and "OpenCML" confirm the general difficulty of decision boundaries in open-world settings.

### Mechanism 2
- **Claim:** A dual-criteria pseudo-labeling strategy (using both softmax entropy and geometric distance) allows the model to generate training signals for ambiguous samples that purely probabilistic methods would discard.
- **Mechanism:** In post-training, if prediction entropy is low, the model uses the predicted class. If entropy is high, the model defaults to a geometric check: it assigns a pseudo-label only if the sample is significantly closer to one class centroid than the next (high ΔMD).
- **Core assumption:** The latent space geometry (Mahalanobis distance to centroids) remains a valid metric for classification even when the softmax output is uncertain or the model is undergoing distribution shift.
- **Evidence anchors:**
  - [abstract] "...post-training mechanism generates reliable pseudo-labels..."
  - [section 5.2] "...we leverage the feature representation... by measuring the distance to the centroid..."
  - [corpus] Not explicitly detailed in neighbor abstracts; general open-world literature (e.g., "OpenCML") focuses more on incremental clustering than geometric pseudo-labeling.

### Mechanism 3
- **Claim:** Conditional activation based on distribution similarity and uncertainty appears to reduce computational overhead without significantly degrading adaptation quality.
- **Mechanism:** The system only triggers the computationally expensive post-training update loop if two conditions are met simultaneously: the entropy of predictions exceeds a threshold (φent) AND the cosine similarity between current and previous batch label distributions drops below a threshold (φcos).
- **Core assumption:** Significant shifts in data distribution manifest as detectable changes in the model's prediction entropy and the aggregate predicted label distribution.
- **Evidence anchors:**
  - [abstract] "...selective activation criteria to optimize the post-training process, reducing unnecessary computation."
  - [section 5.1] "The model adapts when both the uncertainty and similarity conditions are satisfied..."
  - [corpus] Weak/absent in the provided corpus summaries.

## Foundational Learning

**Concept: Mahalanobis Distance**
- **Why needed here:** This is the core metric used to identify "borderline" samples during pre-training and to assign pseudo-labels/unknown status during inference. Unlike Euclidean distance, it accounts for the variance (Σc) of the class clusters.
- **Quick check question:** If a class has a very "wide" distribution in latent space (large Σc), would a Euclidean distance metric incorrectly classify a valid sample as an outlier compared to Mahalanobis distance?

**Concept: Contrastive Learning (Paired)**
- **Why needed here:** The pre-training phase relies on contrasting positive pairs (anchor/borderline of same class) against negative pairs to reshape the geometry of the latent space.
- **Quick check question:** In the BSR step, does the contrastive loss push the borderline sample away from other classes, or pull it towards the anchor sample?

**Concept: Label Shift vs. Covariate Shift**
- **Why needed here:** OASIS is designed to handle both simultaneously. You must distinguish between P(Y) changing (Label Shift) and P(X|Y) changing (Covariate Shift) to understand why the model needs both distribution similarity checks and entropy checks.
- **Quick check question:** If the input images get noisier (covariate shift) but class ratios stay the same, which OASIS mechanism (Entropy threshold or Cosine similarity) is likely the primary driver for triggering an update?

## Architecture Onboarding

**Component map:**
- **Backbone:** ResNet-18 (split into Frozen f and Learnable l parameters)
- **Latent Layer (L̄):** The extraction point for feature vectors used in Mahalanobis distance calculations
- **Memory Buffers:** Stores running statistics (μc, Σc) for known classes and previous batch predictions for similarity checks

**Critical path:**
1. **Pre-training:** Dataset D0 → Imbalance-aware Contrastive Step → Borderline Identification (MD calculation) → Refinement (Pull to Anchor) → Final Centroid Calculation
2. **Post-training:** Stream Dt → Conditional Check (Entropy + Similarity) → Pseudo-label Generation (Logic switch: Softmax vs. MD) → Update Learnable l

**Design tradeoffs:**
- **Frozen vs. Learnable:** Freezing the backbone (f) stabilizes the latent geometry (preserving centroids for MD calculations) but may limit adaptation to severe covariate shifts
- **Threshold Sensitivity:** Setting φcos too high triggers too many updates (computationally expensive); setting it too low risks missing slow distribution shifts

**Failure signatures:**
- **Cascading Pseudo-label Errors:** If φMD (distance gap) is too low, the model may confidently mislabel unknown classes as known "borderline" classes, corrupting the learnable parameters
- **Stagnation:** If the initial pre-training fails to separate minority classes (high overlap), the BSR step might pull outliers of Class A into the cluster of Class B

**First 3 experiments:**
1. **Centroid Stability Test:** Visualize the t-SNE of the latent space before and after the BSR step on a validation set to verify if "borderline" samples actually moved toward anchors
2. **Threshold Sweep:** Run post-training with varying φent and φcos on a "Square Shift" (sudden change) scenario to find the latency-accuracy tradeoff curve
3. **Unknown Detection ROC:** Evaluate the inference equation (Eq 13) by plotting TPR vs. FPR specifically for the "Unknown" class detection on the Tiny-ImageNet-LT split

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How sensitive is the OASIS framework to the selection of hyperparameters (e.g., entropy thresholds φent, similarity thresholds φcos), and can these be determined adaptively rather than manually?
- **Basis in paper:** Tables 7 and 8 show that OASIS requires distinct hyperparameter settings for different datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet) to achieve optimal performance.
- **Why unresolved:** The paper does not provide a mechanism for automatically tuning these thresholds in novel environments, suggesting potential fragility or high tuning overhead when deployed on new data distributions.
- **What evidence would resolve it:** An ablation study showing performance stability across a wide range of hyperparameter values, or the introduction of a meta-learning module that adapts thresholds online.

### Open Question 2
- **Question:** To what extent does the assumption of Gaussian-distributed latent features limit the effectiveness of the Mahalanobis distance-based borderline refinement?
- **Basis in paper:** Equation (7) defines the borderline threshold using Mahalanobis distance (DMD), which relies on the computation of class means μc and covariance matrices Σc, implicitly assuming feature normality.
- **Why unresolved:** Deep learning representations often exhibit complex, non-Gaussian structures; if this assumption fails, the distance metric may inaccurately identify anchor or borderline samples, degrading the refinement process.
- **What evidence would resolve it:** Analysis of the feature space normality (e.g., using Shapiro-Wilk tests) or experiments comparing Mahalanobis distance against non-parametric density estimation techniques for borderline detection.

### Open Question 3
- **Question:** How does the proposed post-training mechanism perform under non-Gaussian covariate shifts (e.g., motion blur or fog) compared to the Gaussian noise shifts used in the simulations?
- **Basis in paper:** Section 6.1 states, "In our setting, we use Gaussian noise to simulate distributional shifts over time," limiting the scope of the reported robustness to this specific type of corruption.
- **Why unresolved:** While the method claims to handle covariate shift generally, the experimental validation restricts the temporal shift dynamics to Gaussian noise, leaving performance under diverse, structured corruptions unverified.
- **What evidence would resolve it:** Experimental results using the full range of CIFAR-10-C / CIFAR-100-C corruption types (weather, blur, digital) to simulate the temporal shifts in the post-training phase.

### Open Question 4
- **Question:** Does the borderline sample refinement strategy scale effectively to datasets with extreme class imbalance factors (ρ > 10) where minority class statistics are sparse?
- **Basis in paper:** Section 6.1 specifies that the imbalance factor ρ was set to 10 for all experiments, which is a moderate level of imbalance compared to many real-world long-tailed datasets.
- **Why unresolved:** Computing reliable covariance matrices (Σc) for borderline refinement requires sufficient samples; with extreme imbalance, the statistical estimates for minority classes may become unstable, potentially harming the decision boundary.
- **What evidence would resolve it:** Evaluation of OASIS on datasets with higher imbalance factors (e.g., ρ=100 or ρ=1000, such as ImageNet-LT) demonstrating consistent accuracy improvements.

## Limitations
- The paper lacks explicit details on key hyperparameter values, particularly the borderline threshold φborder (Equation 9)
- The handling of covariance matrix singularity for minority classes is not specified, which could lead to computational failures during Mahalanobis distance calculations
- The effectiveness of the borderline refinement mechanism is claimed but not empirically validated with qualitative visualizations showing the actual movement of borderline samples toward class centroids

## Confidence
- **High Confidence:** The overall framework design (pre-training + post-training pipeline) and the mathematical formulation of the adaptation process are clearly specified and internally consistent
- **Medium Confidence:** The effectiveness of the dual-criteria pseudo-labeling strategy (softmax entropy + geometric distance) is supported by experimental results but the mechanism's robustness under extreme distribution shifts is not thoroughly explored
- **Low Confidence:** The borderline sample refinement technique's impact is theoretically sound but the specific implementation details and empirical validation are insufficient to fully assess its contribution to performance gains

## Next Checks
1. **Centroid Stability Verification:** Conduct t-SNE visualizations of the latent space before and after the BSR step on a validation set to confirm that borderline samples actually move toward their respective class anchors as claimed
2. **Threshold Sensitivity Analysis:** Perform a systematic sweep of the conditional activation thresholds (φent and φcos) on a "Square Shift" scenario to quantify the latency-accuracy tradeoff and identify optimal values for different dataset scales
3. **Unknown Detection Performance:** Evaluate the inference equation (Equation 13) by plotting a Receiver Operating Characteristic (ROC) curve specifically for the "Unknown" class detection on the Tiny-ImageNet-LT split to measure the model's ability to reject unseen classes