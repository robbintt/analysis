---
ver: rpa2
title: Erkang-Diagnosis-1.1 Technical Report
arxiv_id: '2512.20632'
source_url: https://arxiv.org/abs/2512.20632
tags:
- medical
- knowledge
- arxiv
- health
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Erkang-Diagnosis-1.1, a medical AI assistant
  built on Qwen-3 to address the need for accurate, professional healthcare advice.
  It combines continued pre-training on 500GB of curated medical knowledge with retrieval-augmented
  generation to ensure precise, up-to-date responses.
---

# Erkang-Diagnosis-1.1 Technical Report

## Quick Facts
- arXiv ID: 2512.20632
- Source URL: https://arxiv.org/abs/2512.20632
- Authors: Jianbing Ma; Ao Feng; Zhenjie Gao; Xinyu Song; Li Su; Bin Chen; Wei Wang; Jiamin Wu
- Reference count: 15
- Primary result: Medical AI assistant achieving >90% consistency with expert consensus and outperforming GPT-4 on medical exams

## Executive Summary
Erkang-Diagnosis-1.1 is a medical AI assistant built on Qwen-3 30B that combines continued pre-training on 500GB of medical knowledge with retrieval-augmented generation to provide accurate, professional healthcare advice. The system uses structured 3-5 round dialogues to gather symptom details and deliver evidence-based health assessments while maintaining strict safety controls. Evaluated across six dimensions—professionalism, patient-friendliness, safety, fluency, proactiveness, and stylization—the model demonstrates superior performance compared to GPT-4 in medical exam settings.

## Method Summary
The model employs a hybrid approach combining enhanced pre-training and retrieval-augmented generation. It begins with continued pre-training on 500GB of curated medical data (textbooks, guidelines, Q&A, knowledge graphs) to internalize domain knowledge, followed by supervised fine-tuning on 3-5 round consultation scenarios. A state machine engine steers structured dialogues, while RAG provides up-to-date factual grounding through semantic retrieval from a medical vector database. Multi-layer safety filters and visualization modules ensure responsible, clear output formatting.

## Key Results
- Outperforms GPT-4 in medical exam settings
- Achieves over 90% consistency with expert consensus
- Demonstrates strong performance across six evaluation dimensions: professionalism, patient-friendliness, safety, fluency, proactiveness, and stylization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continued pre-training on domain-specific medical corpus improves medical reasoning and entity recognition
- Mechanism: Fine-tuning Qwen-3 30B on 500GB preprocessed medical data internalizes medical knowledge through supervised learning on entity recognition, etiological chain reasoning, and diagnostic logic modeling
- Core assumption: Domain-specific continued pre-training transfers general language understanding to specialized medical reasoning more effectively than RAG alone
- Evidence anchors: [abstract] "integrates approximately 500GB of high-quality structured medical knowledge, employing a hybrid approach combining enhanced pre-training and retrieval-enhanced generation"; [section 2.3] "To 'internalize' 500GB of core medical knowledge into the model parameters... we used the continued pre-training technique"
- Break condition: If pre-training data contains systematic errors or outdated guidelines, the model's "internalized" knowledge may produce confident but incorrect medical reasoning

### Mechanism 2
- Claim: RAG grounds model outputs in up-to-date, factual medical knowledge
- Mechanism: User questions combined with dialogue history undergo semantic retrieval against a vector database, with retrieved fragments injected as augmented context before generation
- Core assumption: The embedding model accurately captures medical semantic relationships and retrieved fragments are sufficiently relevant
- Evidence anchors: [abstract] "retrieval-augmented generation to ensure precise, up-to-date responses"; [section 2.4] "retrieved knowledge fragments are used as augmented context and input, together with the original dialogue history, into the tuned core model"
- Break condition: If retrieval returns irrelevant, outdated, or contradictory fragments, the system may generate inconsistent or hallucinated responses

### Mechanism 3
- Claim: Structured 3-5 round dialogue state machine produces more complete symptom gathering and safer triage
- Mechanism: State machine tracks conversation state, determining follow-up questions based on collected information and transitioning to "conclusion" when sufficient information is gathered
- Core assumption: 3-5 rounds is sufficient for accurate preliminary assessment in most cases
- Evidence anchors: [abstract] "structured 3-5 round dialogues to gather symptom details and provide evidence-based health assessments"; [section 2.3] "the 3-5 round interactive strategy engine is designed as a state machine to steer the conversation toward completing an effective consultation"
- Break condition: If users present atypical symptoms or multiple concurrent conditions, the fixed-round state machine may conclude prematurely

## Foundational Learning

- Concept: **Continued Pre-training (Domain Adaptation)**
  - Why needed here: Domain-specific continued pre-training adapts general LLMs to specialized vocabulary and reasoning patterns before task-specific fine-tuning
  - Quick check question: Can you explain why continued pre-training is applied before supervised fine-tuning, rather than only doing instruction tuning?

- Concept: **Retrieval-Augmented Generation (RAG)**
  - Why needed here: RAG separates parametric knowledge from explicit knowledge, enabling factual grounding and knowledge updates without retraining
  - Quick check question: How does semantic retrieval in a vector database differ from keyword search, and what failure modes does this introduce?

- Concept: **Dialogue State Machines**
  - Why needed here: Medical consultation requires structured information gathering; state machines provide explicit control over conversation flow
  - Quick check question: What are the tradeoffs between rule-based state machines and learned dialogue policies for medical triage?

## Architecture Onboarding

- Component map:
  - Base Model: Qwen-3 30B
  - Continued Pre-training Pipeline: 500GB medical corpus → preprocessing → supervised learning
  - Supervised Fine-tuning: Instruction samples simulating 3-5 round consultations
  - RAG System: Embedding model → vector database → semantic retrieval → context injection
  - Dialogue State Machine: 3-5 round inquiry engine with symptom prioritization logic
  - Safety Layer: Content filters, emergency detection, disclaimers, privacy encryption
  - Visualization Module: Rule engine + keyword tagging → structured output formatting

- Critical path:
  1. Data preprocessing (clean, deduplicate, fragment 500GB corpus)
  2. Continued pre-training on Qwen-3 30B
  3. Supervised fine-tuning on consultation scenarios
  4. Vector database construction from knowledge graphs
  5. RAG pipeline integration
  6. Safety filter deployment
  7. Dialogue state machine implementation
  8. Visualization module configuration

- Design tradeoffs:
  - Parametric vs. Retrieved Knowledge: Continued pre-training provides fast inference but requires retraining for updates; RAG enables updates but adds latency
  - Structured vs. Open Dialogue: State machine ensures completeness but may feel rigid; open dialogue is natural but risks incomplete information gathering
  - Safety vs. Helpfulness: Aggressive filtering prevents harm but may block legitimate queries; conservative filtering enables help but increases risk

- Failure signatures:
  - Retrieval mismatch: Retrieved fragments irrelevant to user query → check embedding quality, query formulation
  - Premature conclusion: State machine exits before gathering critical symptoms → review transition logic, symptom priority rules
  - Safety bypass: Emergency symptoms not triggering referral → audit emergency keyword list, filter integration
  - Hallucination despite RAG: Model ignores retrieved context → verify context injection format, model attention

- First 3 experiments:
  1. Ablation study: Compare model performance with/without continued pre-training, with/without RAG, to isolate each component's contribution on six-dimensional evaluation metrics
  2. Dialogue round analysis: Measure diagnostic accuracy and user satisfaction across 3, 4, 5, and open-ended dialogue structures to validate the 3-5 round heuristic
  3. Retrieval quality audit: Sample 100 consultation sessions, manually evaluate relevance of retrieved fragments, identify systematic retrieval failures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can multimodal capabilities, specifically the interpretation of visual data like skin and tongue coating images, be effectively integrated without compromising existing safety and consistency standards?
- Basis in paper: [explicit] The conclusion states, "In the future, we plan to... explore multimodal capabilities (such as interpreting skin and tongue coating images)"
- Why unresolved: The current architecture is text-based; incorporating image analysis introduces new challenges in data fusion, visual hallucination, and diagnostic accuracy
- What evidence would resolve it: A technical report detailing the multimodal model's architecture and evaluation results comparing diagnostic accuracy in visual scenarios against dermatological experts

### Open Question 2
- Question: Does continued pre-training on medical data degrade the model's general reasoning or language capabilities through catastrophic forgetting?
- Basis in paper: [inferred] The paper highlights 500GB of specialized medical knowledge but does not provide evaluation metrics for general natural language processing tasks
- Why unresolved: While the model shows high performance in medical exams, the paper does not demonstrate if it maintains the general proficiency of the original Qwen-3 base model
- What evidence would resolve it: Comparative benchmark results on general LLM datasets between the base Qwen-3 model and Erkang-Diagnosis-1.1

### Open Question 3
- Question: What is the "miss rate" for the emergency identification system, and does the strict 3-5 round dialogue constraint increase the risk of missing critical triage signals?
- Basis in paper: [inferred] The paper claims the model identifies critical symptoms to interrupt conversations, but evaluation is limited to "200+ common diseases" and small-scale beta testing
- Why unresolved: A small-scale beta may not capture edge cases where the model's state-machine dialogue logic fails to recognize urgent symptoms within the limited turn count
- What evidence would resolve it: A "red teaming" evaluation report quantifying False Negative and False Positive rates of the triage module

### Open Question 4
- Question: To what extent does the model generalize to "rare" or "orphan" diseases outside the 200+ common diseases covered in the knowledge graph?
- Basis in paper: [inferred] The evaluation explicitly relies on a test set of "200+ common diseases" and a knowledge graph for "200+ common diseases"
- Why unresolved: It is unclear if the model is robust enough to handle the "long tail" of medical conditions not explicitly covered in the training data
- What evidence would resolve it: Performance metrics on a dataset specifically composed of rare disease case studies

## Limitations

- The study relies entirely on in-house evaluation rather than independent third-party validation
- Technical report lacks transparency regarding critical implementation details including hyperparameter settings and training durations
- Performance claims lack independent verification and detailed methodological disclosure

## Confidence

- **High Confidence**: The architectural components (RAG, continued pre-training, dialogue state machines) are well-established in the literature
- **Medium Confidence**: The 500GB corpus size and multi-dimensional evaluation approach are methodologically reasonable
- **Low Confidence**: Performance claims exceeding GPT-4 and achieving 90%+ expert consistency lack independent verification

## Next Checks

1. Conduct independent blinded clinical validation by medical experts across diverse scenarios, including edge cases and emergency presentations
2. Implement the system in controlled clinical settings with longitudinal tracking of diagnostic accuracy, safety incidents, and user satisfaction over 6+ months
3. Release core components for community replication, focusing on isolating the contribution of each architectural component on standardized medical question-answering datasets