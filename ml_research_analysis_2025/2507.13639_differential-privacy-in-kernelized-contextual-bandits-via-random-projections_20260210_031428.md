---
ver: rpa2
title: Differential Privacy in Kernelized Contextual Bandits via Random Projections
arxiv_id: '2507.13639'
source_url: https://arxiv.org/abs/2507.13639
tags:
- algorithm
- bandits
- private
- kernel
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies private contextual kernel bandits where the\
  \ agent needs to ensure differential privacy with respect to both contexts and rewards.\
  \ The authors propose CAPRI, a novel algorithm achieving state-of-the-art regret\
  \ bounds of \xD5(\u221A\u03B3T T + \u03B3T/\u03B5DP) under joint differential privacy\
  \ and \xD5(\u221A\u03B3T T + \u03B3T\u221AT/\u03B5DP) under local differential privacy,\
  \ where \u03B3T is the effective dimension of the kernel and \u03B5DP is the privacy\
  \ parameter."
---

# Differential Privacy in Kernelized Contextual Bandits via Random Projections

## Quick Facts
- **arXiv ID:** 2507.13639
- **Source URL:** https://arxiv.org/abs/2507.13639
- **Reference count:** 40
- **Primary result:** Novel CAPRI algorithm achieving state-of-the-art regret bounds of Õ(√γT T + γT/εDP) under joint differential privacy and Õ(√γT T + γT√T/εDP) under local differential privacy for kernelized contextual bandits.

## Executive Summary
This paper addresses the challenge of providing differential privacy in kernelized contextual bandits while maintaining optimal regret guarantees. The authors propose CAPRI, a novel algorithm that achieves state-of-the-art regret bounds by combining private kernel-ridge regression with random projections. The key innovation is a private estimator that reduces sensitivity compared to classical approaches while maintaining prediction accuracy. The algorithm uses an explore-then-eliminate framework with i.i.d. sampling to avoid complex dependencies between actions and observations. The results recover optimal non-private regret as ε→∞, and match known bounds for linear bandits, representing the first cumulative regret guarantees for the Matérn kernel family under differential privacy.

## Method Summary
The CAPRI algorithm tackles the kernelized contextual bandit problem under differential privacy constraints. It employs an explore-then-eliminate framework with doubling epochs, where each epoch consists of uniform sampling followed by action elimination. The core innovation is a private kernel-ridge regression estimator that combines private covariance estimation with random projections. This estimator constructs a private predictor by projecting data onto i.i.d. sampling sets and adding calibrated Gaussian noise. The algorithm achieves differential privacy through two mechanisms: Joint Differential Privacy (JDP) adds noise at the epoch level, while Local Differential Privacy (LDP) adds noise at each individual step. The explore-then-eliminate approach with reward-independent sampling simplifies the privacy analysis by avoiding complex dependencies between actions and observations.

## Key Results
- Achieves regret bounds of Õ(√γT T + γT/εDP) under joint differential privacy
- Achieves regret bounds of Õ(√γT T + γT√T/εDP) under local differential privacy
- First algorithm to provide cumulative regret guarantees for the Matérn kernel family under differential privacy
- Recovers optimal non-private regret as ε→∞, and matches known bounds for linear bandits

## Why This Works (Mechanism)
The algorithm works by addressing the fundamental challenge of privatizing kernelized bandits: the infinite-dimensional nature of RKHS predictors creates unbounded sensitivity. The key insight is to use random projections to reduce the dimensionality of the problem while preserving the essential structure. By projecting onto finite i.i.d. sampling sets S and R, the algorithm creates a finite-dimensional representation with bounded sensitivity. The explore-then-eliminate framework with uniform sampling ensures that the data points within each epoch are i.i.d., which is crucial for the privacy analysis. The private estimator combines the projected kernel matrices with calibrated noise to ensure differential privacy while maintaining statistical accuracy. This approach effectively trades off some computational complexity for improved privacy-utility trade-offs compared to classical methods.

## Foundational Learning
- **Effective dimension γT:** Measures the complexity of the kernel space with respect to the data distribution. Needed to characterize the statistical difficulty of the bandit problem. Quick check: Verify γT scales appropriately with kernel bandwidth and data distribution.
- **Reproducing Kernel Hilbert Space (RKHS):** The function space where the reward function is assumed to reside. Needed because kernelized bandits model rewards as elements of this infinite-dimensional space. Quick check: Confirm the kernel is positive definite and defines a valid RKHS.
- **Random projections:** Technique to reduce dimensionality while preserving essential structure. Needed to create finite-dimensional representations with bounded sensitivity for privacy. Quick check: Verify projection matrices preserve distances between relevant data points.
- **Joint vs Local Differential Privacy:** Two privacy models with different noise addition strategies. Needed to capture different threat models (central vs distributed noise addition). Quick check: Confirm both privacy guarantees hold under their respective assumptions.
- **Explore-then-eliminate framework:** Algorithm design where exploration precedes exploitation. Needed to avoid complex dependencies that complicate privacy analysis. Quick check: Verify elimination criteria preserve optimal actions with high probability.
- **Kernel matrix operations:** Computations involving Gram matrices of kernel evaluations. Needed for the private estimator construction and confidence bound calculations. Quick check: Verify numerical stability of matrix inversions.

## Architecture Onboarding

- **Component Map:** Context Generator -> Action Sampler -> (LDP: Local privatization) -> Aggregation of private statistics -> (JDP: Global privatization at epoch end) -> Private estimator construction -> Action set elimination for next epoch

- **Critical Path:** Context sampling → Action sampling → (LDP: local privatization) → Aggregation of private statistics → (JDP: global privatization at epoch end) → Private estimator construction → Action set elimination for next epoch

- **Design Tradeoffs:**
  1. **Privacy vs. Utility:** As εDP → 0, privacy noise scale σ0 increases, widening confidence intervals and leading to more aggressive exploration, increasing regret.
  2. **Computational vs. Statistical Efficiency:** Requires computing and inverting kernel matrices of size |Xr| × |Xr| for Sr, Rr. Computational cost dominated by matrix operations, while statistical cost depends on effective dimension γT.
  3. **Adaptivity vs. Simplified Analysis:** Explore-then-eliminate framework with uniform sampling simplifies privacy proof by making data points i.i.d. within an epoch, but may be statistically suboptimal compared to fully adaptive methods.

- **Failure Signatures:**
  1. **High Regret for Small εDP:** If εDP ≪ 1/√T, privacy noise term γT/εDP dominates regret, potentially leading to near-linear regret.
  2. **Catastrophic Elimination:** If private confidence intervals are misspecified due to model misspecification or incorrect kernel, optimal action may be eliminated, causing linear regret.
  3. **Distribution Mismatch:** If context generator samples from distribution κ' significantly different from true deployment distribution κ, theoretical guarantees may not hold due to reliance on i.i.d. nature of Sr and Rr.

- **First 3 Experiments:**
  1. **Sanity Check on Synthetic Data:** Replicate setup on synthetic dataset where reward function is a known sample from GP with Matérn kernel. Compare CAPRI's regret against non-private baseline (SupKernelUCB) to quantify privacy cost. Verify regret scales as expected with T and εDP.
  2. **Effect of Random Projection Basis Size:** Experimentally vary size of sets Sr and Rr relative to epoch length. Theoretically, paper assumes same size. Analyze if smaller projection basis can suffice, trading off some utility for lower computational cost.
  3. **Stress Test with Misspecified Context Generator:** Provide CAPRI with context generator that samples from perturbed distribution κ' instead of true κ. Measure degradation in regret to test robustness to misspecification.

## Open Questions the Paper Calls Out
- **Open Question 1:** Are the regret bounds for CAPRI optimal under both Joint and Local Differential Privacy? The paper conjectures optimality but establishing matching lower bounds for kernel bandits that depend on effective dimension γT and privacy parameter εDP remains an interesting future direction.
- **Open Question 2:** Can the algorithm be extended to adversarial contexts without the regret penalty seen in prior work? The current technique relies on i.i.d. sampling and covariance estimation that presumes a stable distribution, making extension to adversarial contexts while maintaining current bounds open.
- **Open Question 3:** Can a fully adaptive policy achieve comparable regret guarantees? The authors use explore-then-eliminate framework specifically to avoid complex data dependencies created by adaptive policies, which make sensitivity analysis for privatizing infinite-dimensional RKHS predictors difficult.

## Limitations
- Theoretical guarantees critically depend on effective dimension γT, which can be large for practical kernels and data distributions
- Explore-then-eliminate framework with i.i.d. sampling may be statistically suboptimal compared to fully adaptive methods
- Algorithm requires careful tuning of multiple parameters including epoch lengths, confidence bounds, and kernel hyperparameters

## Confidence
- **High confidence:** Core regret bounds under both JDP and LDP models (Theorem 4.1)
- **High confidence:** Privacy analysis framework using random projections
- **Medium confidence:** Practical performance claims (no experimental validation provided)
- **Medium confidence:** Assumption 2.5 requirements for context generators

## Next Checks
1. Implement empirical validation comparing CAPRI's regret against non-private baselines across different kernel families and privacy regimes
2. Analyze the scaling behavior of effective dimension γT for common kernels (Gaussian, Matérn) on realistic datasets
3. Stress test the algorithm's robustness to violations of Assumption 2.5 by evaluating performance with mismatched context distributions