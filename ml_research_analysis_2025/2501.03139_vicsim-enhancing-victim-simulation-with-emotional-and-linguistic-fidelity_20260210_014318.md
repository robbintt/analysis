---
ver: rpa2
title: 'VicSim: Enhancing Victim Simulation with Emotional and Linguistic Fidelity'
arxiv_id: '2501.03139'
source_url: https://arxiv.org/abs/2501.03139
tags:
- user
- emotional
- human
- training
- vicsim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VicSim, a novel victim simulator model for
  scenario-based training in public safety sectors. VicSim addresses key challenges
  in simulating realistic victim interactions, including informational faithfulness,
  emotional dynamics, and language style fidelity.
---

# VicSim: Enhancing Victim Simulation with Emotional and Linguistic Fidelity

## Quick Facts
- **arXiv ID**: 2501.03139
- **Source URL**: https://arxiv.org/abs/2501.03139
- **Authors**: Yerong Li; Yiren Liu; Yun Huang
- **Reference count**: 40
- **Key outcome**: VicSim outperforms GPT-4 in human-likeness for victim simulation, achieving higher emotional and linguistic fidelity in dispatcher training scenarios

## Executive Summary
VicSim is a novel victim simulator model designed to enhance scenario-based training in public safety sectors. The model addresses critical challenges in simulating realistic victim interactions, including informational faithfulness, emotional dynamics, and language style fidelity. By employing a GAN-based training workflow that combines a Flan-T5-based discriminator with a Llama-2 chat-based generator, VicSim achieves superior performance in generating human-like victim responses. The system uses key-information-based prompting to reduce hallucination and maintain factual consistency, making it a valuable tool for dispatcher training and real-world incident handling preparedness.

## Method Summary
VicSim employs a GAN-based workflow where a Llama-2 7B Chat generator creates synthetic victim responses, and a Flan-T5 discriminator evaluates them against real human responses. The system uses key-information-based prompting with CoreNLP entity extraction to reduce hallucination. The discriminator is first fine-tuned on emotion and grammar datasets before entering the adversarial loop. Scenario summaries are generated using Llama-2 70B, and prompts include system instructions, scenario summaries, key information, and dialogue history. The model is evaluated on human-likeness, informational faithfulness (NER overlap), emotional dynamics (GoEmotions classification), and grammar style fidelity.

## Key Results
- VicSim outperforms GPT-4 in human-likeness ratings for victim simulation
- Achieves higher emotional fidelity with negative emotions appearing in 68.23% of low-factual-consistency sentences versus 21.70% in human responses
- Successfully captures nuanced emotional expressions and grammar styles while maintaining informational faithfulness
- Reduces hallucination through key-information-based prompting, though some repetitive grammar errors remain

## Why This Works (Mechanism)
VicSim leverages adversarial training to create a generator that produces increasingly human-like victim responses. The discriminator's focus on emotion and grammar provides targeted feedback that helps the generator learn to express appropriate emotional states and grammatical patterns. The key-information-based prompting mechanism acts as a constraint system, reducing the generator's tendency to fabricate details by anchoring responses to extracted entities from scenario summaries. This combination allows the model to balance emotional expressiveness with factual consistency, addressing the core challenge of creating believable victim simulations for dispatcher training.

## Foundational Learning

- **Concept: Generative Adversarial Networks (GANs) for Text**
  - Why needed here: This is the core training paradigm for VicSim. A generator creates synthetic victim responses, and a discriminator tries to distinguish them from real ones. Understanding this adversarial loop is crucial for grasping how the model learns to be more human-like.
  - Quick check question: What is the role of the discriminator during the generator's training phase?

- **Concept: Instruction Tuning and Prompting**
  - Why needed here: The generator is based on Llama-2, and its behavior is guided by complex prompts that include system instructions, scenario summaries, and dialogue history. The discriminator is also instruction-tuned. This is the primary interface for controlling the model's output.
  - Quick check question: What are the key components of the prompt used to guide the generator's response?

- **Concept: Hallucination in LLMs**
  - Why needed here: A central problem the paper addresses is LLMs making up information. The key-information-based prompting mechanism is a direct solution to this. Understanding what hallucination is and why it occurs is essential to appreciating the paper's contribution.
  - Quick check question: According to the paper, what happens when a scenario summary lacks sufficient detail?

## Architecture Onboarding

```
[Real Human Chat Logs (Anonymized)]
                |
                v
+-------------------------------+     +---------------------------------------+
|   Key Info Extraction (CoreNLP) | --> |      Prompt Constructor               |
+-------------------------------+     |  - System Message                     |
                |                     |  - Scenario Summary                   |
                v                     |  - Key Information Augmentation       |
+-------------------------------+     |  - Dialogue History                   |
|   Scenario Summarizer (Llama-2 70B) |--------------------------------------+
+-------------------------------+                |
                                                 v
+-------------------------------+     +---------------------------------------+
|    Discriminator Fine-Tuning    |<----|   GAN Training Loop                   |
|  (Dataset: Emotion + Grammar)   |     |  - Generator (Llama-2 7B Chat)        |
+-------------------------------+     |    - Takes constructed prompt         |
                |                     |    - Generates synthetic user response|
                v                     |  - Discriminator (Fine-tuned Flan-T5) |
+-------------------------------+     |    - Classifies Real vs. Fake         |
|   Fine-tuned Flan-T5            |     |    - Provides feedback to Generator   |
|   (The Discriminator)           |     +---------------------------------------+
+-------------------------------+
```

- **Component map**: The system consists of two main learned components: a **Generator** (Llama-2 7B Chat) and a **Discriminator** (Flan-T5). Data pipelines feed into a **Prompt Constructor**, which provides input to the Generator. The Discriminator is pre-trained on specialized datasets for emotion and grammar classification before entering the adversarial loop.
- **Critical path**:
  1.  **Data Preprocessing**: Anonymize chat logs and generate scenario summaries using Llama-2 70B.
  2.  **Discriminator Preparation**: Fine-tune Flan-T5 on emotion and grammar datasets. This is a prerequisite for effective adversarial training.
  3.  **Prompt Construction**: For each training step, build a prompt containing system instructions, the scenario summary, key information, and dialogue history.
  4.  **Adversarial Training**: Run the GAN loop. Generator produces responses given the context $p$, and Discriminator evaluates them against real human responses. Generator weights are updated based on Discriminator feedback.
  5.  **Evaluation**: Use a separate RoBERTa-based classifier and human evaluators to measure fidelity across key metrics.
- **Design tradeoffs**:
  - **Discriminator Focus**: The Discriminator is trained to spot grammar and emotion, which is effective but can lead it to rely heavily on cues like punctuation errors. This might make it blind to other forms of incoherence.
  - **Model Size**: Using Llama-2 7B for the generator balances performance and resource cost, but may limit the complexity of the generated scenarios compared to a larger model. GPT-4 was used only for comparison.
  - **Key-Information Augmentation**: Extracting keywords with CoreNLP helps with fidelity but adds a dependency on the accuracy of an external tool.
- **Failure signatures**:
  - **Overly Emotional Responses**: The generator might express too much emotion, especially when hallucinating or repeating itself, a pattern noted in the paper's analysis.
  - **Repetitive Grammar Errors**: The generator might over-apply learned grammar "errors" (like missing punctuation) in a way that feels unnatural or repetitive.
  - **Hallucination Despite Prompting**: If key information is not extracted or provided correctly, the model will still fabricate details.
- **First 3 experiments**:
  1.  **Ablation on Discriminator**: Train the generator with a generic discriminator (not fine-tuned on emotion/grammar) and compare the linguistic style and emotional fidelity of the outputs to the baseline.
  2.  **Sensitivity to Prompt Content**: Systematically remove parts of the prompt (e.g., remove key information, then remove scenario summary) to quantify their impact on hallucination rates and informational faithfulness.
  3.  **Human-in-the-Loop Evaluation**: Conduct a user study with dispatcher trainees who interact with both the VicSim model and a baseline (e.g., GPT-4), measuring their ability to discern AI vs. human and their perception of training realism.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a voice-enabled victim simulator achieve comparable emotional and linguistic fidelity to text-based VicSim in dispatcher training?
- Basis in paper: [explicit] Authors state in Limitations: "Future research should explore diverse communication settings to enable multi-modal interaction (e.g., voice-enabled victim simulator) for a more immersive training environment."
- Why unresolved: VicSim was only evaluated on text-based incident reporting; voice modality introduces additional complexity in emotional prosody, speech disfluencies, and urgency cues that text cannot capture.
- What evidence would resolve it: Development and evaluation of a voice-based VicSim variant, comparing human-likeness ratings and dispatcher training outcomes against the text-based system using the same evaluation framework.

### Open Question 2
- Question: Does training with VicSim improve dispatcher preparedness and service quality in real-world incident handling?
- Basis in paper: [explicit] Authors state in Limitations: "our evaluation of VicSim was not conducted under actual training scenarios with dispatchers and lacked empirical understanding of the training effectiveness of the system."
- Why unresolved: Human evaluations focused on human-likeness ratings from MTurk workers, not actual dispatcher trainees; no longitudinal study on skill transfer to real incidents.
- What evidence would resolve it: A controlled study where dispatcher trainees use VicSim in training, with pre/post assessments of their handling of simulated and real incidents, measuring information accuracy, response time, and emotional support quality.

### Open Question 3
- Question: Can adversarial training approaches be refined to induce minority grammar error types (e.g., preposition usage, spelling mistakes) beyond punctuation errors?
- Basis in paper: [inferred] Section 5.1 notes that while GAN training successfully induces punctuation errors, "generators could not notice minority errors such as 'Preposition Usage' or 'Spelling Mistakes' even though discriminators can detect them with high accuracy."
- Why unresolved: The discriminator's reliance on grammar cues is skewed toward high-frequency error patterns in training data; minority errors lack sufficient signal for the generator to learn.
- What evidence would resolve it: Experiments with balanced or augmented training data for minority error types, or modified discriminator architectures that weigh rare errors more heavily, evaluating grammar error distribution alignment with human baselines.

### Open Question 4
- Question: What is the causal relationship between hallucination and emotional expression in LLM-based victim simulators?
- Basis in paper: [inferred] Section 4.2.2 observes that "LLMs address emotional expression more when they hallucinate," with VicSim showing negative emotions in 68.23% of low-factual-consistency sentences versus 21.70% in humans, but the mechanism remains unexplained.
- Why unresolved: It is unclear whether hallucination triggers emotional overcompensation, or whether emotional prompts encourage speculative responses, or if both stem from uncertainty in scenario understanding.
- What evidence would resolve it: Controlled experiments manipulating scenario information completeness and measuring both hallucination rates and emotional expression, combined with analysis of model attention patterns to identify whether emotional tokens correlate with information gaps.

## Limitations
- Proprietary training data (5,427 anonymized chat logs) makes complete reproducibility impossible
- Specific gradient estimation technique for text GAN training is not detailed
- Exact prompt templates for discriminator instruction-tuning are unspecified
- Performance on out-of-domain scenarios or different languages remains unknown
- Evaluation relies on proxy metrics rather than direct assessment of emergency response accuracy

## Confidence
- **High confidence**: The GAN-based training architecture is technically sound and the model outperforms GPT-4 on human-likeness metrics as measured by reported human evaluations
- **Medium confidence**: The key-information-based prompting effectively reduces hallucination, though this relies on the assumption that CoreNLP extraction is accurate
- **Low confidence**: Claims about the model's readiness for actual dispatcher training require real-world validation beyond controlled evaluation scenarios

## Next Checks
1. **Prompt Sensitivity Analysis**: Systematically remove prompt components (key information, scenario summary, dialogue history) and measure changes in hallucination rates and emotional fidelity to quantify their relative importance
2. **Cross-Domain Generalization Test**: Evaluate VicSim on emergency scenarios from different public safety domains (e.g., fire, medical) not represented in the original training data to assess domain transfer capability
3. **Longitudinal Human Evaluation**: Conduct a study with dispatcher trainees using VicSim for a full training cycle, measuring both their performance improvement and their subjective assessment of realism compared to baseline simulation tools