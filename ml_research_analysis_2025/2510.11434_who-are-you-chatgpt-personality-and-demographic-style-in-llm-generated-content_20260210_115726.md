---
ver: rpa2
title: Who are you, ChatGPT? Personality and Demographic Style in LLM-Generated Content
arxiv_id: '2510.11434'
source_url: https://arxiv.org/abs/2510.11434
tags:
- personality
- language
- comments
- human
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines whether contemporary LLMs exhibit personality
  and demographic traits similar to humans, using a novel methodology that avoids
  self-report questionnaires. The authors collected open-ended Reddit questions and
  human responses, then prompted six LLMs (both open- and closed-source) to generate
  replies as social media users.
---

# Who are you, ChatGPT? Personality and Demographic Style in LLM-Generated Content

## Quick Facts
- arXiv ID: 2510.11434
- Source URL: https://arxiv.org/abs/2510.11434
- Reference count: 39
- Primary result: LLMs display higher Agreeableness and lower Neuroticism than humans, with human-like gendered language patterns but reduced variance.

## Executive Summary
This study investigates whether contemporary LLMs exhibit personality and demographic traits similar to humans, introducing a novel methodology that avoids self-report questionnaires. Using open-ended Reddit questions and human responses, six LLMs (both open- and closed-source) were prompted to generate replies as social media users. The outputs were analyzed using automatic personality and gender classifiers. Results show LLMs consistently display higher Agreeableness and lower Neuroticism compared to humans, reflecting cooperative and stable conversational tendencies. Gendered language patterns broadly align with human patterns but with reduced variation. The study contributes a new dataset and demonstrates that while LLMs can produce human-like personality traits, systematic differences exist due to training objectives and design.

## Method Summary
The study collected 13k+ Reddit posts and 30k+ human comments (100-300 words each) from 175 subreddits. Six LLMs (GPT-4.1, Claude-Sonnet-4.0, Llama3.3-70B, etc.) were prompted at temperatures 0.0 and 0.7 to generate exactly X comments per post using the instruction "Behave like several social media users." Trait scores were computed using e5-large-v2 embeddings with a logistic regression classifier for personality (Big Five OCEAN) and a DistilBERT model for gender (female-likelihood). Mean scores and standard deviations were calculated and compared to human baselines using Mann-Whitney and Levene tests.

## Key Results
- All models exhibit considerably higher Agreeableness and lower Neuroticism than human baselines, reflecting training toward cooperative and stable behavior.
- Gendered language patterns in model text broadly resemble those of human writers, though with reduced variation.
- The methodology successfully avoids self-report questionnaires while capturing trait-like linguistic patterns in LLM outputs.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs generate text classified as higher in Agreeableness and lower in Neuroticism than human baselines.
- **Mechanism:** RLHF and safety alignment reward supportive, cooperative, emotionally stable outputs while penalizing negativity, aggression, or volatility. These training pressures shift output distributions toward language patterns classifiers associate with high Agreeableness (empathetic, validating phrasing) and low Neuroticism (fewer expressions of anxiety or frustration).
- **Core assumption:** Classifier scores on LLM text validly correspond to the same constructs measured in human language, and differences reflect model behavior rather than classifier artifact.
- **Evidence anchors:**
  - [abstract] "LLMs consistently display higher Agreeableness and lower Neuroticism compared to humans, reflecting cooperative and stable conversational tendencies."
  - [section 4.2] "All models exhibit considerably higher AGR scores and lower NEU scores... aligning with the intuition that models are trained to be cooperative, psychologically 'stable', and agreeable."
  - [corpus] Related work (PerFairX, FairEval) treats personality as salient in LLM outputs but offers no direct mechanistic evidence.
- **Break condition:** If classifier training data biases it to label polite/formal text as high Agreeableness regardless of trait, or if different classifiers yield opposite patterns, the inference weakens.

### Mechanism 2
- **Claim:** LLM outputs show human-like gendered language patterns but with reduced variance.
- **Mechanism:** Models learn statistical associations between linguistic features and implicit gender cues from diverse training corpora. Regularization toward "neutral" or "safe" outputs compresses distributions toward central tendencies, reducing extreme gendered markers.
- **Core assumption:** F-likelihood scores capture meaningful linguistic patterns, and reduced variance reflects model regularization rather than prompt artifacts alone.
- **Evidence anchors:**
  - [abstract] "Gendered language patterns in model text broadly resemble those of human writers, though with reduced variation."
  - [section 5.2] "Models display lower variance, indicating slightly more limited variation in gendered language, consistent with findings on spambots."
  - [corpus] Neighbors on demographic bias ("Who Gets Which Message?") lack variance analysis; corpus evidence is weak.
- **Break condition:** If the classifier over-assigns moderate scores to any neutral text, or if prompts artificially compress variance, attribution to training regularization fails.

### Mechanism 3
- **Claim:** Open-ended response analysis via classifiers provides a valid alternative to self-report personality probing for LLMs.
- **Mechanism:** Models generate naturalistic replies to real questions; classifiers trained on human language detect trait markers. This avoids requiring models to "self-assess" and captures stylistic patterns emergent in generation.
- **Core assumption:** Traits detected from LLM text via human-trained classifiers are comparable to human trait expression, and open-ended prompts elicit representative behavior.
- **Evidence anchors:**
  - [abstract] "We introduce a novel methodology for assessing LLM personality without relying on self-report questionnaires."
  - [section 2.1] "LLMs do not possess stable inner states, so 'answering' such questions may be more about simulating a plausible response."
  - [corpus] Neighbors mention personality detection from digital traces but do not validate this method against self-report.
- **Break condition:** If classifier outputs are driven by superficial style features uncorrelated with human personality judgments, or prompts yield inconsistent profiles, methodology validity collapses.

## Foundational Learning

### Concept: Big Five (OCEAN) Framework
- **Why needed here:** Analysis rests on interpreting Agreeableness, Neuroticism, Openness, Conscientiousness, and Extroversion as linguistically detectable constructs.
- **Quick check question:** Text expressing frequent worry and frustration likely indicates which OCEAN trait as high?

### Concept: RLHF and Alignment Objectives
- **Why needed here:** Systematic trait differences (high AGR, low NEU) are attributed to training pressures; understanding RLHF is essential to explain them.
- **Quick check question:** During RLHF, would a bluntly critical or an empathetic, supportive response more likely receive high reward?

### Concept: Classifier Limitations
- **Why needed here:** All trait scores come from imperfect classifiers trained on human data; interpreting them as ground truth would be invalid.
- **Quick check question:** If a gender classifier trained on 2010 blog data is applied to 2025 LLM outputs, what are two potential error sources?

## Architecture Onboarding

### Component map:
Reddit scraper (PRAW) -> filtered posts/comments (100â€“300 words, diverse subreddits) -> LLM prompt interface (6 models, 2 temperatures) -> generated comment corpus -> Trait classifiers: Big Five (e5-large-v2 + logistic regression), Gender (DistilBERT) -> continuous scores -> Analysis layer: mean/STD per trait, subreddit validation, Mann-Whitney/Levene tests

### Critical path:
Scrape -> filter -> prompt LLMs -> classify outputs -> aggregate distributions -> compare to human baseline

### Design tradeoffs:
- Minimalist prompts reduce explicit bias but may not elicit "natural" behavior
- Reddit-trained classifier improves domain match but inherits Reddit biases
- Temperature variation (0.0 vs 0.7) probes diversity but paper finds minimal impact

### Failure signatures:
- Implausible classifier scores -> check training data domain and label quality
- Identical opening phrases across models -> prompt/response convention artifact
- Uniform trait profiles across models -> shared training/alignment rather than diversity

### First 3 experiments:
1. Validate classifiers on held-out human data with manual annotations to quantify error
2. Perturb prompts (e.g., "reply skeptically") to isolate prompt influence on trait scores
3. Apply a second independent classifier to same outputs; convergence strengthens robustness, divergence flags artifacts

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do prompt instructions designed to elicit social media behavior (e.g., "behave like several social media users") induce stylistic biases that confound the detection of personality and gender traits?
- **Basis in paper:** [explicit] The authors state in the Limitations that such instructions "may itself bias stylistic patterns in ways that confound the personality and gender inferences drawn by the classifiers."
- **Why unresolved:** The study's methodology involves a specific persona prompt, making it difficult to distinguish between the model's inherent linguistic tendencies and artifacts of the role-play instruction.
- **What evidence would resolve it:** Ablation studies comparing model outputs using neutral prompts versus the current persona-based prompts to isolate instruction-induced bias.

### Open Question 2
- **Question:** Do high classifier scores reflect intrinsic psychological properties of LLMs, or do they merely capture surface-level stylistic regularities?
- **Basis in paper:** [explicit] The authors note in the Limitations that "it remains unclear whether these scores capture any intrinsic properties of the models or merely reflect surface-level stylistic regularities."
- **Why unresolved:** Classifiers are trained on human data where linguistic style correlates with psychology; it is unknown if this mapping is valid for synthetic text generation.
- **What evidence would resolve it:** Developing evaluation frameworks that test for behavioral consistency of traits across diverse contexts rather than relying on single-text classification.

### Open Question 3
- **Question:** Are the observed personality and gendered language patterns consistent across non-English languages and different cultural contexts?
- **Basis in paper:** [inferred] The authors list the restriction to English as a limitation, explicitly stating it "limits the generalizability of the findings to other languages and cultural contexts."
- **Why unresolved:** Training data compositions vary by language, and models may exhibit different "default" personalities or demographic biases depending on the linguistic corpus.
- **What evidence would resolve it:** Replicating the study's methodology using a multilingual dataset to compare trait distributions across different languages.

## Limitations
- Classifier validity: Trait scores rely on classifiers trained on human language, raising questions about whether these constructs map meaningfully to LLM outputs.
- Prompt effects: The uniform "behave like several social media users" instruction may suppress model-specific stylistic diversity.
- Model version ambiguity: References to "GPT-4.1" and "Claude-Sonnet-4.0" lack precise version tags.

## Confidence
- **High Confidence:** Systematic differences in Agreeableness and Neuroticism (AGR high, NEU low) across all models; consistency of this pattern aligns with known RLHF incentives.
- **Medium Confidence:** Human-like gendered language patterns with reduced variance; variance compression is plausible but could also stem from prompt or classifier artifacts.
- **Low Confidence:** The novel methodology's validity as a personality assessment tool for LLMs; lack of ground truth or independent validation weakens claims about what traits "mean" in this context.

## Next Checks
1. Apply both gender and personality classifiers to a held-out human Reddit test set, manually annotate a subset, and report classification error rates.
2. Generate responses to the same Reddit questions using alternative prompts (e.g., "reply skeptically" or "reply informally") and compare trait distributions.
3. Run a second, independent personality classifier on the same LLM outputs; convergence strengthens claims, divergence flags artifacts.