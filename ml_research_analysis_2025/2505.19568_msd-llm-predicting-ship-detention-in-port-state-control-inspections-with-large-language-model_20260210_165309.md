---
ver: rpa2
title: 'MSD-LLM: Predicting Ship Detention in Port State Control Inspections with
  Large Language Model'
arxiv_id: '2505.19568'
source_url: https://arxiv.org/abs/2505.19568
tags:
- detention
- data
- ship
- learning
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of predicting ship detentions
  during Port State Control inspections, a critical task for maritime safety and environmental
  protection. Traditional machine learning and deep learning methods struggle with
  imbalanced data and limited representation learning, leading to low accuracy.
---

# MSD-LLM: Predicting Ship Detention in Port State Control Inspections with Large Language Model

## Quick Facts
- **arXiv ID**: 2505.19568
- **Source URL**: https://arxiv.org/abs/2505.19568
- **Reference count**: 35
- **Primary result**: Over 12% improvement in AUC for Singapore ports compared to state-of-the-art methods

## Executive Summary
This paper addresses the challenge of predicting ship detentions during Port State Control inspections, a critical task for maritime safety and environmental protection. Traditional machine learning and deep learning methods struggle with imbalanced data and limited representation learning, leading to low accuracy. To overcome these limitations, the authors propose MSD-LLM, a novel framework combining a dual robust subspace recovery (DSR) layer-based autoencoder with a progressive learning pipeline and a large language model (LLM). The DSR layer enhances feature extraction and class separation, while the LLM uses a grouping and ranking strategy to predict detention probabilities. Extensive evaluations on 31,707 PSC inspection records from the Asia-Pacific region demonstrate that MSD-LLM achieves over 12% improvement in Area Under the Curve (AUC) for Singapore ports compared to state-of-the-art methods, showcasing its robustness and adaptability to real-world maritime risk assessment scenarios.

## Method Summary
MSD-LLM combines a dual robust subspace recovery (DSR) layer-based autoencoder with a progressive learning pipeline and a large language model. The method first trains a CNN-based autoencoder with DSR layers using 6 progressive phases with increasing detention sample proportions (1.79% to 50%). The DSR layer uses dual projection matrices to separate regular and detention samples into distinct subspaces with margin loss. The learned features are then used to fine-tune a large language model (Qwen-VL-2.5) using a grouping strategy where samples are clustered into groups of 20 (2 detention, 18 regular) for ranking-based prediction. The framework is evaluated on 31,707 PSC inspection records from the Tokyo MoU Asia-Pacific region.

## Key Results
- MSD-LLM achieves over 12% improvement in AUC for Singapore ports compared to state-of-the-art methods
- The DSR layer + LLM with grouping strategy (MSD-LLM) achieves 0.7012 AP on Singapore ports vs. 0.5775 for DSR + LLM (Plain)
- MSD-LLM outperforms traditional ML methods (Logistic Regression, Random Forest) by significant margins across all evaluation metrics
- The grouping strategy with 20 samples per group provides optimal performance compared to smaller or larger group sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual subspace recovery layers improve class separation for imbalanced detention prediction.
- Mechanism: The DSR layer applies two parallel linear transformations (A_reg, A_det) to latent features, projecting regular and detention samples into distinct subspaces. A margin loss (inspired by SimCSE) explicitly maximizes the distance between classes while reconstruction losses preserve feature fidelity.
- Core assumption: Detention and non-detention samples occupy separable subspaces that can be learned despite severe class imbalance (<5% detention rate).
- Evidence anchors:
  - [abstract] "integrating a dual robust subspace recovery (DSR) layer-based autoencoder... to handle imbalanced data and extract meaningful PSC representations"
  - [Section III-B] "The DSR layer acts as a feature-level filter, distinguishing regular samples from anomaly (detention) samples"
  - [corpus] Weak direct corpus support for DSR specifically; nearest neighbors focus on maritime AI applications without subspace methods.
- Break condition: If detention samples do not cluster in a learnable subspace (e.g., detention causes are heterogeneous and non-structured), the dual-decoder approach may overfit to noise.

### Mechanism 2
- Claim: Progressive learning with distribution shifting improves generalization across varying real-world data distributions.
- Mechanism: Training proceeds through 6 phases with detention proportions from 1.79% to 50%. Each phase initializes from the previous checkpoint, incrementally adapting the model to more balanced distributions. This prevents overfitting to the severely imbalanced original distribution.
- Core assumption: Real-world port detention rates vary significantly; a model trained only on the natural ~5% rate will fail on ports with different distributions.
- Evidence anchors:
  - [Section III-C] "the training process is divided into six phases, with detention sample proportions set at 1.79%, 5.58%, 12.37%, 24.37%, 36.75%, and 50%"
  - [Figure 2(c) description] "aggregating different phases together can make the model compatible with different data distributions"
  - [corpus] No direct corpus evidence for progressive learning in maritime prediction; related work on transfer learning in maritime (arXiv:2510.03003) suggests distribution shift is a recognized challenge.
- Break condition: If target deployment has a detention rate outside the training range or fundamentally different feature distributions (e.g., different regulatory regimes), phase-based adaptation may not transfer.

### Mechanism 3
- Claim: Grouping and ranking strategy enables LLMs to handle imbalanced classification through relative comparison rather than absolute prediction.
- Mechanism: Samples are grouped into batches of 20 (2 detention, 18 regular). The LLM assigns continuous confidence scores and ranks samples within each group. This reframes binary classification as a comparative reasoning task, leveraging LLM pattern-matching capabilities.
- Core assumption: LLMs perform better at relative ranking within constrained contexts than at isolated binary predictions, especially with imbalanced data.
- Evidence anchors:
  - [Section IV-A] "vessel samples are clustered into groups of 20, with each group containing two detention samples"
  - [Table IV] DSR + GS-LLM (MSD-LLM) achieves 0.7012 AP vs. 0.5775 for DSR + LLM (Plain), demonstrating the grouping strategy's contribution
  - [corpus] No direct corpus evidence; LLM-VLM fusion work (arXiv:2601.13096) suggests multi-modal LLM integration is emerging in maritime but without ranking-based approaches.
- Break condition: If group composition during inference differs significantly from training (e.g., detention rate >10% in a batch), ranking calibration may degrade.

## Foundational Learning

- Concept: **Robust Subspace Recovery (RSR)**
  - Why needed here: DSR extends RSR; understanding orthogonal projections and robust PCA helps explain why the dual-branch architecture separates classes.
  - Quick check question: Can you explain why q=1 in the loss function (Equation 14) provides robustness to outliers?

- Concept: **Contrastive Learning / Margin Loss**
  - Why needed here: The SimCSE-inspired margin loss explicitly pushes regular and detention representations apart.
  - Quick check question: How does cosine similarity in the margin loss relate to the subspace separation goal?

- Concept: **Supervised Fine-Tuning (SFT) for LLMs**
  - Why needed here: MSD-LLM replaces ViT features in Qwen-VL-2.5 with DSR features; understanding connector architectures is essential.
  - Quick check question: What modifications are needed to adapt a vision-language model to accept non-visual embedding inputs?

## Architecture Onboarding

- Component map:
  - **Input Layer**: Semantic feature clustering (vessel particulars + historical records)
  - **Feature Extractor**: CNN-based encoder producing latent codes D_all
  - **DSR Layer**: Dual projection matrices (A_reg, A_det) → two subspaces
  - **Decoders**: Regular decoder (D_reg) + Detention decoder (D_det)
  - **Connector**: DSR features formatted as M-LLM inputs
  - **LLM**: Qwen-VL-2.5 with grouping strategy (20 samples/group)
  - **Output**: Continuous detention probability scores → dynamic thresholding

- Critical path:
  1. Progressive learning phases 1-6 (autoencoder training)
  2. DSR feature extraction on labeled data
  3. Group construction (20 samples, 2 detention)
  4. SFT on LLM with ranking objective
  5. Inference: single-sample scoring with configurable threshold

- Design tradeoffs:
  - Group size (5 vs 20 vs 50): Table III shows 20 optimal; smaller groups increase training time, larger groups reduce ranking precision
  - Progressive phases: More phases improve robustness but increase training complexity; phase transitions cause temporary loss spikes
  - DSR vs RSR: DSR adds detention decoder (+parameters) but critical for <5% detention rate scenarios

- Failure signatures:
  - Loss spikes at phase transitions (expected; should recover within epoch)
  - AUC degradation on out-of-distribution ports (may need phase recalibration)
  - LLM assigning uniform scores (grouping strategy may be corrupted or feature connector misaligned)
  - Reconstruction error dominated by regular samples (margin loss weight λ may need adjustment)

- First 3 experiments:
  1. **Baseline comparison**: Replicate Table I on a held-out port not in training (e.g., evaluate Singapore model on Australian ports) to test distribution shift robustness.
  2. **Ablation on group size**: Test group sizes 10, 20, 30, 40 on validation set to verify optimal 20-sample configuration for your data distribution.
  3. **Progressive learning validation**: Train with and without progressive learning (direct training at 5% detention rate) and compare AUC on Singapore vs. global test splits to quantify the adaptation benefit.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can explicit maritime domain knowledge and regulations be integrated into the MSD-LLM framework to enhance reasoning?
- Basis in paper: [explicit] The conclusion states, "Looking ahead, we believe that further integration of domain-specific knowledge with LLMs will drive more efficient and intelligent maritime AI solutions."
- Why unresolved: The current implementation relies on data-driven feature extraction (DSR layers) and generic grouping strategies without incorporating explicit regulatory rules or SOLAS conventions into the LLM's reasoning process.
- What evidence would resolve it: A comparative study showing performance gains when regulatory text is injected via Retrieval-Augmented Generation (RAG) or specialized prompting.

### Open Question 2
- Question: Is the fixed 10% detention ratio used in the grouping strategy optimal for datasets with different underlying class distributions?
- Basis in paper: [inferred] Section IV.A describes a grouping strategy with a fixed composition of 2 detention and 18 regular samples (10% detention), despite the real data having a detention rate of less than 5%.
- Why unresolved: The paper demonstrates that a group size of 20 is optimal for this specific dataset, but it does not analyze if this fixed artificial ratio generalizes to other ports where detention rates might be significantly lower or higher.
- What evidence would resolve it: Experiments varying the detention-to-regular ratio within groups to reflect different real-world imbalance scenarios (e.g., 1% vs. 5% detention rates).

### Open Question 3
- Question: Does the DSR layer-based representation learning transfer effectively to PSC regimes outside the Asia-Pacific region (Tokyo MoU)?
- Basis in paper: [inferred] Section V.A evaluates the model on "Global Overseas Ports" and "Singapore Ports," but both are subsets of the Tokyo MoU dataset.
- Why unresolved: While the paper claims adaptability to "diverse maritime risk assessment scenarios," it is unclear if the learned representations are universal or overfitted to the specific inspection patterns and biases of Asia-Pacific ports.
- What evidence would resolve it: Testing the trained MSD-LLM model "out-of-the-box" on inspection records from distinct regimes like the Paris MoU or US Coast Guard.

## Limitations

- The effectiveness of the dual subspace recovery layer critically depends on detention samples occupying a separable subspace structure, but the paper does not provide visualization or quantitative analysis of learned subspaces to validate this assumption
- The grouping strategy assumes balanced group composition (2 detention samples per 20), but real-world deployment may encounter batches with different detention rates, potentially degrading ranking performance
- Progressive learning requires multiple training phases with carefully tuned detention proportions; the optimal phase configuration may be dataset-specific and not generalize across different maritime jurisdictions

## Confidence

- **High Confidence**: The empirical performance improvements (12%+ AUC gain on Singapore ports) are well-documented through controlled experiments comparing MSD-LLM against multiple baselines
- **Medium Confidence**: The architectural mechanisms (DSR layer, progressive learning, grouping strategy) are logically sound, but their individual contributions are difficult to isolate without complete ablation studies
- **Low Confidence**: Claims about the method's adaptability to "real-world maritime risk assessment scenarios" beyond the tested Asia-Pacific ports remain unverified

## Next Checks

1. **Cross-jurisdictional robustness test**: Evaluate MSD-LLM on PSC data from different regulatory regimes (e.g., Paris MoU vs Tokyo MoU) to verify the progressive learning adaptation generalizes beyond the Asia-Pacific region
2. **Subspace structure validation**: Perform t-SNE or UMAP visualization of regular vs. detention samples in the learned DSR subspaces to confirm the dual-decoder architecture creates meaningful separation
3. **Group composition stress test**: Systematically vary the detention rate within training groups (1/20, 2/20, 3/20, 4/20) and measure ranking performance degradation to establish operational boundaries for the grouping strategy