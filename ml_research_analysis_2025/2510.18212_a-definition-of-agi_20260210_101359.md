---
ver: rpa2
title: A Definition of AGI
arxiv_id: '2510.18212'
source_url: https://arxiv.org/abs/2510.18212
tags:
- ability
- memory
- illustrative
- examples
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive, quantifiable framework for
  defining and measuring Artificial General Intelligence (AGI) by operationalizing
  the concept as matching the cognitive versatility and proficiency of a well-educated
  adult. The methodology grounds its approach in Cattell-Horn-Carroll (CHC) theory,
  the most empirically validated model of human cognition, and systematically decomposes
  general intelligence into ten core cognitive domains, including reasoning, memory,
  and perception.
---

# A Definition of AGI

## Quick Facts
- arXiv ID: 2510.18212
- Source URL: https://arxiv.org/abs/2510.18212
- Reference count: 40
- This paper presents a comprehensive, quantifiable framework for defining and measuring Artificial General Intelligence (AGI).

## Executive Summary
This paper presents a comprehensive, quantifiable framework for defining and measuring Artificial General Intelligence (AGI) by operationalizing the concept as matching the cognitive versatility and proficiency of a well-educated adult. The methodology grounds its approach in Cattell-Horn-Carroll (CHC) theory, the most empirically validated model of human cognition, and systematically decomposes general intelligence into ten core cognitive domains, including reasoning, memory, and perception. The framework adapts established human psychometric batteries to evaluate AI systems across these domains. Application of this framework to current AI systems reveals a highly "jagged" cognitive profile, with models proficient in knowledge-intensive domains but exhibiting critical deficits in foundational cognitive machinery, particularly long-term memory storage. The resulting AGI scores—such as GPT-4 at 27% and GPT-5 at 57%—concretely quantify both rapid progress and the substantial gap remaining before achieving AGI.

## Method Summary
The framework operationalizes the Cattell-Horn-Carroll (CHC) theory to decompose general intelligence into ten broad cognitive domains, each weighted equally at 10%. These domains include General Knowledge, Reading/Writing, Math, Reasoning, Working Memory, Memory Storage, Memory Retrieval, Visual Processing, Auditory Processing, and Speed. The evaluation adapts human psychometric batteries and established benchmarks (e.g., GSM8K, MATH, ImageNet) to test specific narrow abilities within each domain. The methodology explicitly prohibits external tools to measure internal capability and requires specific temporal delays for long-term memory tests. The framework identifies current AI systems as exhibiting "capability contortions" - compensatory strategies that mask fundamental cognitive deficits, particularly in long-term memory storage.

## Key Results
- GPT-4 achieves 27% AGI score, GPT-5 achieves 57% AGI score
- Current models show "jagged" cognitive profiles: high in knowledge domains (K) but near-zero in foundational machinery like long-term memory storage (MS)
- Long-term memory storage (MS) emerges as the primary bottleneck, with current models scoring 0%
- The framework successfully identifies "capability contortions" where models use context windows to simulate memory they structurally lack

## Why This Works (Mechanism)

### Mechanism 1: Diagnostic Granularity via CHC Decomposition
- **Claim:** Breaking General Intelligence into ten distinct broad abilities prevents "capability contortions" from masking fundamental deficits.
- **Mechanism:** The framework operationalizes the Cattell-Horn-Carroll (CHC) theory to isolate narrow cognitive abilities (e.g., associative memory vs. retrieval fluency). By testing these components individually rather than relying on aggregate task success, the evaluation reveals "jagged" profiles—high proficiency in crystallized knowledge (K) but near-zero capability in long-term storage (MS).
- **Core assumption:** Human cognitive architecture (CHC) is a valid mapping for non-biological intelligence; AI failures will correlate with specific human cognitive deficits.
- **Evidence anchors:**
  - [Abstract] "The framework dissects general intelligence into ten core cognitive domains... Application of this framework reveals a highly 'jagged' cognitive profile."
  - [Section 13] "Mistaking these contortions for genuine cognitive breadth can lead to inaccurate assessments of when AGI will arrive."
  - [Corpus] *Thinking Beyond Tokens* supports moving toward cognitive foundations rather than token prediction, aligning with this decomposition (FMR 0.38).

### Mechanism 2: Bottleneck Identification via "Engine Analogy"
- **Claim:** Aggregate AGI scores are misleading if critical "weak parts" in the cognitive engine exist; a 90% score with 0% memory is functionally impaired.
- **Mechanism:** The framework treats intelligence as a high-performance engine where overall output is constrained by the weakest component (e.g., Long-Term Memory Storage). It weights 10 domains equally to ensure that a deficiency in foundational machinery (like continual learning) cannot be compensated for by excess horsepower in static knowledge (Math/Reading).
- **Core assumption:** Cognitive domains are interdependent bottlenecks rather than independent additive skills.
- **Evidence anchors:**
  - [Section 13] "An artificial mind, much like an engine, is ultimately constrained by its weakest components... currently, several critical parts... are highly defective."
  - [Table 1] GPT-5 scores high in Math (10%) but zero in Memory Storage (0%), illustrating the bottleneck.
  - [Corpus] *A Scenario-Driven Cognitive Approach to Next-Generation AI Memory* highlights the necessity of robust memory for AGI, supporting this bottleneck hypothesis (FMR 0.52).

## Foundational Learning

- **Concept:** **Cattell-Horn-Carroll (CHC) Theory**
  - **Why needed here:** This is the theoretical substrate of the paper. Without understanding the hierarchy of *broad* (e.g., Fluid Reasoning) vs. *narrow* (e.g., Induction) abilities, the scoring rubric is opaque.
  - **Quick check question:** Can you distinguish between "Fluid Reasoning" (solving novel problems) and "Crystallized Intelligence" (accumulated knowledge)?

- **Concept:** **Psychometric Battery Adaptation**
  - **Why needed here:** The paper adapts human tests (e.g., Wisconsin Card Sorting, Stroop) for AI. Understanding how a test designed for human working memory applies to a Transformer context window is crucial for interpreting results.
  - **Quick check question:** How does testing "Inspection Time" (visual perception speed) differ for an AI that processes images as tensors versus a human retina?

- **Concept:** **Capability Contortions**
  - **Why needed here:** This concept explains why the paper rejects standard benchmarks. It describes how AIs use compensatory strategies (e.g., massive context windows) to simulate abilities (e.g., memory) they structurally lack.
  - **Quick check question:** Why does using a "massive context window" count as a "contortion" rather than a valid Working Memory mechanism in this framework?

## Architecture Onboarding

- **Component map:** The evaluation architecture consists of **10 Domains** (the "Engine"), each weighted at 10%. These domains are decomposed into **Narrow Abilities** (e.g., "Arithmetic" inside "Math"), which are tested via **Operationalized Tasks** (e.g., GSM8K dataset).
- **Critical path:** The **Long-Term Memory Storage (MS)** domain is the primary bottleneck. Current models score 0% here. Progress in AGI requires solving "amnesia" before optimizing other domains.
- **Design tradeoffs:** The paper prioritizes **Breadth (Versatility)** over **Depth** by assigning equal weights. This prevents a "Savant AI" (super-human at Math but illiterate in English) from scoring highly.
- **Failure signatures:**
  - **The "Amnesiac":** High scores in Knowledge/Reasoning but 0% in Memory Storage.
  - **The "Hallucinator":** High Retrieval Fluency but 0% Retrieval Precision (MR).
  - **The "Slow Thinker":** High Reasoning (R) but 0% Speed (S), rendering real-time interaction impossible.
- **First 3 experiments:**
  1. **Evaluate Memory Storage (MS):** Teach the model a novel cipher in one session and test recall after "48 hours worth of experiences" (or equivalent context saturation) to verify if it is relying on context window or stable storage.
  2. **Test On-the-Spot Reasoning (R):** Run the model on private Raven’s Progressive Matrices (RPM) sets to prevent memorization contamination and measure true Induction.
  3. **Audit for Contortion:** Measure performance on a Reading Comprehension task with and without external tools enabled to quantify the "Retrieval Precision" gap.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal weighting scheme for the ten cognitive abilities in predicting AGI?
- Basis in paper: [explicit] The authors state that while they assign equal weight (10%) to each broad ability to prioritize breadth, "more discretionary weighting schemes could be reasonable."
- Why unresolved: The relative importance of abilities like "Speed" versus "Working Memory" for general intelligence remains subjective; a simple sum may obscure critical failures.
- What evidence would resolve it: Empirical validation showing which weighting configurations best correlate with successful performance on complex, open-ended real-world tasks not included in the battery.

### Open Question 2
- Question: Can AI systems overcome the Long-Term Memory Storage bottleneck without relying on "capability contortions"?
- Basis in paper: [explicit] The Discussion section identifies Long-Term Memory Storage (MS) as the "most significant bottleneck" (0% for current models) and labels reliance on massive context windows or RAG as "capability contortions" that mask underlying deficits.
- Why unresolved: Current architectures lack the mechanism for stable, continual learning (consolidation) required to pass the MS battery (Appendix F) which tests recall after "48 hours of experiences."
- What evidence would resolve it: A system achieving a non-zero score on the MS battery (e.g., via modular updates like LoRA adapters) without external tools, demonstrating genuine experiential retention.

### Open Question 3
- Question: Does the CHC-based framework remain valid when adapted for non-English languages and diverse cultural contexts?
- Basis in paper: [explicit] In the Limitations section, the authors note that "illustrative examples are specific to the English language and are not culturally agnostic," suggesting future research must adapt these tests.
- Why unresolved: "General Knowledge" and "Culture" components are heavily dependent on Western-centric datasets, potentially biasing the AGI score against models trained on global data distributions.
- What evidence would resolve it: A psychometric validation study demonstrating that the hierarchical structure of abilities holds and scores remain reliable when evaluated across linguistically and culturally adapted test batteries.

## Limitations

- **Private Evaluation Data:** The framework relies on private Raven's Progressive Matrices sets for Reasoning testing, creating reproducibility barriers.
- **Temporal Memory Protocol:** The "48 hours worth of experiences" specification lacks operational clarity regarding what constitutes an "experience" in token volume.
- **Cultural Bias:** The framework's examples and knowledge components are specific to English language and Western contexts, potentially biasing results.

## Confidence

**High Confidence:** The framework's decomposition of intelligence into distinct cognitive domains is methodologically sound. The identification of current AI's "jagged" profile - high in crystallized knowledge but deficient in foundational machinery - is empirically supported by multiple evaluations.

**Medium Confidence:** The bottleneck analysis (e.g., 0% Memory Storage limiting overall capability) follows logical reasoning but requires more empirical validation. The assumption that equal domain weighting prevents capability contortions is reasonable but not definitively proven.

**Low Confidence:** The specific AGI scores (27% for GPT-4, 57% for GPT-5) depend heavily on private evaluation data and may not be reproducible without full access to the complete evaluation suite.

## Next Checks

1. **Public Domain Validation:** Replicate the evaluation framework using only publicly available datasets across all 10 domains. Compare resulting profiles against the paper's findings to assess generalizability.

2. **Memory Storage Protocol Standardization:** Develop and publish a standardized protocol for the "48 hours worth of experiences" test, specifying exact token volumes, interaction patterns, and isolation procedures to ensure reproducible temporal memory assessment.

3. **Domain Dependency Analysis:** Conduct empirical experiments testing whether improving one domain (e.g., Memory Storage) actually constrains or enables improvements in other domains, validating or refuting the equal-weighting assumption.