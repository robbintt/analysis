---
ver: rpa2
title: Towards Robust Multimodal Emotion Recognition under Missing Modalities and
  Distribution Shifts
arxiv_id: '2506.10452'
source_url: https://arxiv.org/abs/2506.10452
tags:
- missing
- acc2
- acc7
- modality
- multimodal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'CIDer is a robust multimodal emotion recognition framework that
  simultaneously addresses modality missing and out-of-distribution (OOD) generalization
  challenges. It introduces a generalized Random Modality Feature Missing (RMFM) task
  and employs a two-module approach: Model-Specific Self-Distillation (MSSD) for RMFM
  using hierarchical feature, attention, and joint representation distillation, and
  Model-Agnostic Causal Inference (MACI) for OOD using causal graph-based label and
  language bias mitigation with minimal additional parameters.'
---

# Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts

## Quick Facts
- arXiv ID: 2506.10452
- Source URL: https://arxiv.org/abs/2506.10452
- Reference count: 40
- CIDer achieves state-of-the-art performance on CMU-MOSI and CMU-MOSEI datasets across RMFM and OOD scenarios, with fewer parameters (approximately 248K) and faster training compared to existing methods.

## Executive Summary
CIDer is a robust multimodal emotion recognition framework that simultaneously addresses modality missing and out-of-distribution (OOD) generalization challenges. It introduces a generalized Random Modality Feature Missing (RMFM) task and employs a two-module approach: Model-Specific Self-Distillation (MSSD) for RMFM using hierarchical feature, attention, and joint representation distillation, and Model-Agnostic Causal Inference (MACI) for OOD using causal graph-based label and language bias mitigation with minimal additional parameters. The framework includes a Word-level Self-aligned Attention Module (WSAM) for efficient non-linguistic sequence alignment and a Multimodal Composite Transformer (MCT) for multimodal fusion.

## Method Summary
CIDer addresses two key challenges in multimodal emotion recognition: handling missing modalities and generalizing under distribution shifts. For missing modalities, it uses Model-Specific Self-Distillation (MSSD) with weight-sharing twin networks that perform hierarchical distillation across low-level features, attention maps, and high-level joint representations. For OOD generalization, it employs Model-Agnostic Causal Inference (MACI) that uses a causal graph to mitigate label and language biases through backdoor adjustment and counterfactual text generation. The framework also includes WSAM for efficient cross-modal alignment and MCT for multimodal fusion, achieving state-of-the-art performance with approximately 248K parameters.

## Key Results
- Achieves state-of-the-art performance on CMU-MOSI and CMU-MOSEI datasets across RMFM and OOD scenarios
- Uses approximately 248K parameters total (37K for MACI alone), significantly fewer than baseline methods
- Shows robust performance across missing rates (0.1-0.9) with graceful degradation, maintaining performance down to ~70% accuracy at 90% missing rate
- Demonstrates strong cross-dataset generalization capability (MOSI→MOSEI) with Acc7 performance of ~35% compared to ~46.5% IID

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Self-Distillation for Missing Modality Robustness
Weight-sharing twin networks with hierarchical distillation enable robust predictions when modality features are randomly missing. During training, complete modalities produce "teacher" representations (features, attention maps, joint representations). Incomplete modalities pass through shared weights to produce "student" outputs. Three distillation losses align student to teacher: (1) feature reconstruction via SmoothL1 loss, (2) attention alignment via KL divergence, (3) joint representation alignment via cosine similarity. The weight-sharing constraint forces the model to learn modality-invariant representations rather than overfitting to complete inputs.

### Mechanism 2: Causal Intervention for Label Bias Mitigation
Backdoor adjustment through class-specific multimodal representations reduces spurious correlations between label distribution and predictions. The causal graph models C → L → Y, where C is label bias affecting language L, which affects prediction Y. Backdoor adjustment computes P(Y|do(L)) = Σ_c P(Y|M=f(L,A,V), c)·P(c). The Multimodal Causal Module (MCM) creates class-specific representations by concatenating multimodal joint representation with class-specific mean features, then passes through class-specific classifiers. Outputs are weighted by prior class probabilities P(i).

### Mechanism 3: Counterfactual Language Debiasing for OOD Generalization
Subtracting counterfactual predictions from fine-grained neutralized texts removes language-specific bias during inference. During testing, compute y'_final = P(Y|do(L=l)) - τ·P(Y|do(L=l_cf)). Counterfactual text S_cf is constructed by retaining only words with high coefficient of variation (CV ≥ 0.1) across classes from top-100 frequent words, replacing others with [UNK]. This isolates sentiment-carrying words while neutralizing dataset-specific language patterns.

## Foundational Learning

- **Concept: Knowledge Distillation**
  - Why needed here: MSSD uses self-distillation where complete modality representations guide incomplete modality learning. Understanding teacher-student frameworks, soft targets, and temperature scaling is essential.
  - Quick check question: Can you explain why KL divergence is used for attention distillation rather than MSE?

- **Concept: Causal Inference (do-calculus, backdoor adjustment)**
  - Why needed here: MACI relies on Pearl's causal framework. Understanding intervention P(Y|do(X)) vs. observation P(Y|X), backdoor paths, and confounding is critical for interpreting the causal graph.
  - Quick check question: In the causal graph C → L → Y with C → Y, what does blocking the backdoor path achieve?

- **Concept: Multimodal Alignment and Fusion**
  - Why needed here: WSAM performs word-level cross-modal attention alignment; MCT performs intra-modal and inter-modal attention. Understanding attention mechanisms, cross-attention, and multimodal fusion strategies is prerequisite.
  - Quick check question: Why does WSAM use language X_l as Query for aligning visual X_v, rather than vice versa?

## Architecture Onboarding

- **Component map:** Input (S, A, V) → BERT + Conv1D → [WSAM alignment for A, V] → GRU → MCT (N layers of Multimodal Composite Attention) → Naive Attention pooling → Linear → h_m (joint representation) → [MSSD path: incomplete input] or [MACI path: MCM + counterfactual]

- **Critical path:** 1. Feature extraction (BERT for text, COVAREP for audio, Facet for visual) 2. WSAM alignment (reduces non-linguistic sequence length to word-level) 3. MCT fusion (seven attention types: unimodal, bimodal, trimodal) 4. Hierarchical distillation (if training with missing modalities) 5. MCM backdoor adjustment (if OOD training) 6. Counterfactual subtraction (if OOD testing)

- **Design tradeoffs:** Parameter efficiency vs. expressiveness: ~248K parameters (excluding BERT), ~37K for MACI alone; achieved through weight-sharing and compact attention design; One-to-all vs. one-to-one training: Single model handles all missing rates, avoiding training separate models per rate; Counterfactual granularity: Top-100 words balance computational cost vs. debiasing coverage; may miss rare but sentiment-rich vocabulary

- **Failure signatures:** Missing rate >80%: Performance degrades sharply (see Tables XIII-XVIII at 0.9-1.0 rates); Cross-domain shift (MOSI→MOSEI): Acc7 drops significantly (Table XIX-XX); domain-specific vocabulary not captured by counterfactual construction; CTC-based alignment baselines show memory advantage but training instability (CTC loss magnitude ~10^4)

- **First 3 experiments:** 1. Baseline sanity check: Run CIDer on CMU-MOSI with complete modalities, IID split (Table X). Verify Acc2 ~86%, Acc7 ~46.5%. This confirms architecture correctness before testing robustness. 2. Ablation by missing rate: Test on RMFM with rates [0.1, 0.3, 0.5, 0.7, 0.9]. Plot AUILC curve. If performance doesn't degrade gracefully, check distillation weight hyperparameters (α, β, γ in Equation 30). 3. MACI plug-and-play test: Attach MACI module to a different MER backbone (e.g., DLF or MPLMM as in Table IV). If OOD metrics don't improve, verify: (a) class-specific features are computed correctly, (b) P(i) priors match training distribution, (c) counterfactual text construction doesn't produce all-[UNK] sequences.

## Open Questions the Paper Calls Out

### Open Question 1
How robust is CIDer against distribution shifts that originate primarily from non-linguistic modalities (audio or visual) rather than from text? The authors explicitly define OOD in this work as pertaining "specifically to the deviations in word distribution," aligning with specific prior works, while the MACI module focuses heavily on mitigating language bias via counterfactual texts. The current evaluation validates performance on lexical shifts but does not verify if the causal inference and self-distillation modules generalize to domain shifts in visual scenes or acoustic environments.

### Open Question 2
Is the Coefficient of Variation (CV) threshold of 0.1 optimal for generating fine-grained counterfactual texts across datasets with different vocabularies? The authors explicitly set a threshold where CV_w ≥ 0.1 indicates a significant inter-class distribution difference for counterfactual construction, restricting selection to the top 100 most frequent words. This appears to be a fixed heuristic; its sensitivity to datasets with varying noise levels or semantic density is not discussed, potentially missing discriminative low-frequency words.

### Open Question 3
Does the weight-sharing mechanism in the MSSD module impose a theoretical performance ceiling compared to distillation methods using independent teacher networks? While emphasizing efficiency, the authors note that LNLN outperformed CIDer in some metrics, attributing this to LNLN's "significantly larger number of model parameters." It is unclear if the "identical capacity" constraint of weight-sharing limits the distillation potential compared to a standard teacher-student setup where the teacher has greater capacity.

## Limitations

- Counterfactual Construction Reliability: The method relies on top-100 frequent words for counterfactual generation, which may miss rare but sentiment-rich vocabulary. This approach assumes sentiment words are frequent, which may not hold across domains or languages.

- Causal Graph Assumptions: The causal model assumes label bias flows through language → prediction. If bias exists through other paths (e.g., visual cues correlated with labels), backdoor adjustment may be incomplete.

- OOD Generalization Scope: Cross-dataset performance (MOSI→MOSEI) shows accuracy drops, indicating the framework handles dataset shifts but not perfectly. The method may be less effective when vocabulary and sentiment expressions differ substantially.

## Confidence

- **High Confidence**: Missing modality robustness via hierarchical self-distillation (supported by extensive ablation in Tables XIII-XVIII showing consistent performance degradation control across missing rates 0.1-0.7).

- **Medium Confidence**: OOD generalization through causal intervention (Table XIX-XX shows improvement over baselines, but accuracy drops from ~46% to ~35% on Acc7 MOSI→MOSEI, indicating partial effectiveness).

- **Medium Confidence**: Parameter efficiency claims (~248K total, ~37K for MACI alone). Based on stated architecture and comparisons to larger baselines, but exact parameter counting methodology not detailed.

## Next Checks

1. **Counterfactual Coverage Analysis**: For MOSI→MOSEI cross-dataset test, measure the proportion of sentiment words captured in the top-100 frequent word list. If coverage <30%, consider expanding to top-500 words and measure trade-off with computational cost.

2. **Causal Graph Validation**: Test whether adding additional bias paths (e.g., C → V → Y) improves OOD performance. If yes, the current graph is incomplete; if no, the current assumptions hold.

3. **Parameter Efficiency Scaling**: Train CIDer with MACI module attached to a larger backbone (e.g., DNF with ~1M parameters). If OOD performance improves proportionally while maintaining parameter efficiency ratio, the MACI design is scalable.