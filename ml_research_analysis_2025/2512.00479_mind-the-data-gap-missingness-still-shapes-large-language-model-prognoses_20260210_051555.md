---
ver: rpa2
title: 'Mind the data gap: Missingness Still Shapes Large Language Model Prognoses'
arxiv_id: '2512.00479'
source_url: https://arxiv.org/abs/2512.00479
tags:
- missingness
- data
- llms
- indicator
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how patterns of missing data affect the
  zero-shot predictive performance of Large Language Models (LLMs) in clinical settings.
  While prior work has shown that explicitly representing missingness improves traditional
  ML models, this study reveals inconsistent effects across LLMs.
---

# Mind the data gap: Missingness Still Shapes Large Language Model Prognoses

## Quick Facts
- **arXiv ID**: 2512.00479
- **Source URL**: https://arxiv.org/abs/2512.00479
- **Reference count**: 28
- **Primary result**: Missingness representation affects LLM performance inconsistently across model sizes and clinical tasks

## Executive Summary
This paper investigates how missing data patterns impact zero-shot predictive performance of Large Language Models in clinical settings. While traditional machine learning models benefit from explicitly representing missingness, this study reveals that LLMs show inconsistent effects - larger models generally benefit from missingness indicators while smaller ones can be harmed. The authors conducted experiments across MIMIC-IV and an external hospital dataset using 10 different LLMs for three clinical prediction tasks (long length of stay, mortality, and readmission). The findings highlight that missingness can be both informative and detrimental depending on context, and underscore the need for systematic evaluation of missingness representation in clinical LLM applications.

## Method Summary
The study evaluated 10 different LLMs on three clinical prediction tasks using both MIMIC-IV and an external hospital dataset. Researchers tested two interventions: including missingness indicators in the input data and prompting LLMs to reason about missing data. The experimental design compared zero-shot prediction performance with and without these interventions, measuring both accuracy and calibration metrics. The authors also provided theoretical insights by decomposing prediction error into components related to prior misalignment, decoding errors, and the inherent informativeness of missingness patterns.

## Key Results
- Larger LLMs generally benefit from missingness indicators while smaller models can experience performance degradation
- Including missingness indicators and prompting for missing data reasoning can both help and harm performance and calibration
- The effect of missingness representation is inconsistent across different clinical prediction tasks
- The study demonstrates that the informativeness of missingness patterns varies significantly by context and model architecture

## Why This Works (Mechanism)
The mechanism behind LLMs' variable response to missingness representation appears to stem from their ability to leverage missingness as an informative signal versus being confused by it. Larger models appear to have sufficient capacity to learn that missingness itself can be predictive, while smaller models may lack the sophistication to properly interpret this signal. The paper suggests that missingness can provide valuable clinical context (e.g., certain labs may not be ordered for specific patient populations), but can also introduce noise if the model cannot properly contextualize it. The theoretical decomposition indicates that errors arise from misalignment between the model's prior expectations and the actual missingness patterns, decoding difficulties in translating missingness information into predictions, and the fundamental informativeness (or lack thereof) of the missingness patterns themselves.

## Foundational Learning

**Missingness Mechanisms**
- *Why needed*: Understanding whether data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR) is crucial for proper handling
- *Quick check*: Examine missingness patterns across different patient subgroups to identify systematic versus random missingness

**Zero-shot vs Fine-tuning Tradeoffs**
- *Why needed*: Zero-shot predictions avoid retraining costs but may underperform compared to fine-tuned models
- *Quick check*: Compare performance gaps between zero-shot and fine-tuned models on the same missingness handling strategies

**Clinical Prediction Task Characteristics**
- *Why needed*: Different tasks (mortality vs readmission) may have different sensitivities to missingness
- *Quick check*: Analyze correlation between task complexity and missingness sensitivity across multiple prediction targets

## Architecture Onboarding

**Component Map**
Clinical Data → Missingness Indicators → LLM Input → Prediction Output

**Critical Path**
The critical path flows from raw clinical data through missingness indicator generation to LLM processing and final prediction. The missingness representation step is particularly crucial as it directly impacts model performance.

**Design Tradeoffs**
- *Model size vs. missingness sensitivity*: Larger models can better leverage missingness indicators but require more computational resources
- *Explicit vs implicit handling*: Explicitly representing missingness provides control but may introduce complexity
- *Zero-shot vs fine-tuning*: Zero-shot avoids retraining but may miss task-specific missingness patterns

**Failure Signatures**
- Performance degradation when missingness indicators are added to smaller models
- Inconsistent calibration across different clinical tasks
- Model sensitivity to the specific format of missingness representation

**First Experiments**
1. Test missingness indicator impact on a single clinical task with a small and large LLM variant
2. Vary the granularity of missingness indicators (binary vs. count-based) on model performance
3. Compare zero-shot predictions with and without explicit missingness reasoning prompts

## Open Questions the Paper Calls Out
None specified in the provided content.

## Limitations
- Inconsistent effects across different LLMs make it difficult to establish universal guidelines for missingness handling
- The study focuses on zero-shot prediction, limiting generalizability to fine-tuned LLM applications
- The specific mechanisms driving the observed patterns remain incompletely understood despite theoretical decomposition
- The practical evaluation frameworks and accounting methods for missingness representation remain undefined

## Confidence

**High Confidence**: The empirical observation that larger LLMs generally benefit from missingness indicators while smaller ones may be harmed. The finding that missingness can be both informative and detrimental depending on context is robustly demonstrated across multiple datasets and tasks.

**Medium Confidence**: The theoretical decomposition of prediction error into prior misalignment, decoding errors, and inherent informativeness of missingness. While logically sound, the relative contribution of each component requires further empirical validation across diverse clinical scenarios.

**Low Confidence**: The assertion that missingness representation in clinical LLMs requires systematic evaluation and transparent accounting. While this is a reasonable recommendation, the specific evaluation frameworks and accounting methods remain undefined.

## Next Checks

1. **Cross-task validation**: Replicate the missingness impact analysis on additional clinical prediction tasks beyond the three studied (length of stay, mortality, readmission) to determine if patterns hold across broader clinical applications.

2. **Architecture-specific analysis**: Conduct controlled experiments varying only model architecture (not just scale) while keeping missingness representation constant to isolate architectural factors from scale effects.

3. **Fine-tuning impact study**: Investigate whether fine-tuning LLMs on clinical data with explicit missingness handling changes the observed patterns, comparing zero-shot and fine-tuned performance under identical missingness conditions.