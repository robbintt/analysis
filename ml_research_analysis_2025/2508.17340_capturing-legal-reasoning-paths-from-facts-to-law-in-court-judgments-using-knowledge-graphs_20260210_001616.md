---
ver: rpa2
title: Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using
  Knowledge Graphs
arxiv_id: '2508.17340'
source_url: https://arxiv.org/abs/2508.17340
tags:
- legal
- reasoning
- facts
- norm
- court
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper constructs a legal knowledge graph (LKG) from Japanese
  administrative court decisions to explicitly model the multi-step reasoning paths
  connecting facts, legal norms, and statutory provisions. By extracting and linking
  these elements using structured prompts and an ontology, the approach captures the
  inferential structure of judicial decisions.
---

# Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using Knowledge Graphs

## Quick Facts
- arXiv ID: 2508.17340
- Source URL: https://arxiv.org/abs/2508.17340
- Reference count: 17
- Key result: LKG-based retrieval achieves macro recall 0.311 and micro recall 0.667 at k=3, significantly outperforming LLM baselines

## Executive Summary
This paper introduces a Legal Knowledge Graph (LKG) to explicitly model multi-step legal reasoning in Japanese administrative court judgments. The approach extracts Facts, Legal Norms, Legal Applications, and Provisions as first-class nodes using structured GPT-4o prompts, then links them through reasoning paths. Evaluation shows the LKG-based retrieval method significantly outperforms direct LLM prediction and retrieval-augmented methods, demonstrating that structured legal knowledge graphs enable more accurate and interpretable legal search than general-purpose language models alone.

## Method Summary
The authors construct an LKG from 648 Japanese administrative court judgments by first segmenting documents into sections, then extracting legal reasoning components (Fact, LegalNorm, LegalApplication, Provision) using GPT-4o with structured prompts. They use fictional "Martian Law" one-shot examples to prevent overfitting. Edges are constructed via scoped-history prompting that pairs each LegalApplication with all preceding Legal Norm or Fact nodes. The resulting graph is encoded in RDF/JSON-LD format. For retrieval, facts are embedded using text-embedding-3-large and indexed with Annoy approximate nearest neighbor search, with query fact's own edges masked to prevent trivial self-matching.

## Key Results
- LKG Retrieval with Fact-Masked setting achieves macro recall 0.311 and micro recall 0.667 at k=3
- Outperforms GPT With Context (macro recall 0.137, micro recall 0.271) and GPT With RAG
- GPT With RAG fails to bridge the gap with LKG Retrieval despite access to retrieved context
- Expert-annotated evaluation shows precision/recall ranging from 0.81-0.93 for node types and 0.60-0.76 for edge types

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Explicitly modeling legal reasoning steps as first-class graph nodes improves LLM extraction accuracy over treating reasoning as implicit text patterns.
- **Mechanism:** The RDF schema defines four core classes with specific properties, enabling GPT-4o to distinguish between similar concepts through structured prompts with category definitions aligned to the schema.
- **Core assumption:** Legal reasoning in Japanese administrative judgments follows a consistent, identifiable structure that maps to the defined schema.
- **Evidence anchors:**
  - [abstract]: "extracts components of legal reasoning using prompt-based large language models... through an ontology of legal inference"
  - [section 2.1]: "Our schema introduces a minimal, but highly expressive, set of classes and properties... This explicit modeling of reasoning steps distinguishes our schema from existing legal ontologies"
- **Break condition:** If legal reasoning in other domains doesn't follow this four-class pattern, extraction accuracy may degrade significantly.

### Mechanism 2
- **Claim:** Accumulating context across document sections enables accurate linking of reasoning elements that span distant parts of a judgment.
- **Mechanism:** Edge construction pairs each LegalApplication node with ALL preceding Legal Norm or Fact nodes using scoped-history prompting, allowing the model to reason over accumulated context.
- **Core assumption:** Legal conclusions depend on reasoning steps distributed across the document, not just local context.
- **Evidence anchors:**
  - [section 2.2, page 7]: "Legal Norm→ Legal Application and Fact→ Legal Application links often span distant sections (sometimes more than eight segments apart)"
  - [section 2.2, page 7]: "each Legal Application node was paired with all preceding Legal Norm or Fact nodes, allowing the model to reason over the accumulated context"
- **Break condition:** If judgments exceed LLM context limits, or if reasoning dependencies cross document boundaries, the approach fails.

### Mechanism 3
- **Claim:** Retrieving similar facts from a structured graph and tracing their linked provisions outperforms direct LLM prediction because it grounds search in explicit precedent reasoning paths.
- **Mechanism:** For a query fact, the system retrieves top-k similar facts from the graph, then collects provisions linked to those facts through LegalApplication nodes, with query fact's edges masked to prevent trivial self-matching.
- **Core assumption:** Similar factual situations lead to similar legal provisions via shared inferential paths preserved in the graph structure.
- **Evidence anchors:**
  - [section 3.3, Table 6]: "LKG Retrieval under the Fact-Masked setting significantly outperforms all GPT-based methods... at k = 3, the macro recall is 0.311 and the micro recall is 0.667, far exceeding GPT With Context (0.137 and 0.271)"
  - [section 3.3]: "GPT With RAG fails to bridge the gap with LKG Retrieval, despite access to retrieved context"
- **Break condition:** If a query fact has no similar precedents in the graph, or if the graph's edge extraction missed critical links, retrieval will return irrelevant or incomplete provisions.

## Foundational Learning

- **Concept: RDF/JSON-LD Knowledge Graphs**
  - **Why needed here:** The LKG is encoded in RDF using JSON-LD format with classes like LegalApplication and properties like appliesNorm. Understanding subject-predicate-object triples is essential to navigate and query the graph.
  - **Quick check question:** Can you write a JSON-LD snippet representing a LegalApplication node that applies one norm to two facts?

- **Concept: Legal Reasoning Structure (Fact → Norm → Application → Provision)**
  - **Why needed here:** The entire extraction pipeline hinges on distinguishing these four components. Misclassifying a Legal Application as a Legal Norm is a common error noted in the paper.
  - **Quick check question:** Given the sentence "Because the plaintiff resides within 100 meters of the construction site, they have standing under Article 9 of the Administrative Case Litigation Act," which parts are Fact, Legal Norm, and Legal Application?

- **Concept: Dense Retrieval with Approximate Nearest Neighbors**
  - **Why needed here:** Fact retrieval uses text-embedding-3-large embeddings indexed with Annoy for efficient similarity search. Understanding the recall-speed tradeoff in ANN is critical for tuning k values.
  - **Quick check question:** If you increase the number of trees in Annoy, what happens to search latency and recall?

## Architecture Onboarding

- **Component map:**
  - HTML judgment documents -> Section segmentation -> Node extraction -> Normalization -> Edge construction -> RDF/JSON-LD graph -> Embedding + Annoy index -> Fact-Masked retrieval

- **Critical path:**
  1. Judgment HTML → Section segmentation (preserve case overview for context)
  2. Section text → Node extraction with GPT-4o (role instructions + definitions + one-shot examples)
  3. Provision nodes → Normalization to canonical legal titles
  4. Node lists → Edge construction with scoped-history (pair each Application with all preceding Norms/Facts)
  5. Query fact → Embedding → Top-k retrieval → Collect linked provisions (mask query fact's edges)

- **Design tradeoffs:**
  - Fictional vs. real examples: Authors chose fictional "Martian Law" one-shot examples to detect surface copying and reduce overfitting; tradeoff is reduced domain-specific signal.
  - GPT-4o vs. Claude: Claude Sonnet 3.5 was tested but "did not perform reliably"; GPT-4o was selected despite cost/latency concerns.
  - Recall vs. precision: LKG retrieval prioritizes high recall (macro recall 0.311 at k=3) over precision (0.227); setting k=2 yields slightly higher micro recall but lower macro recall.

- **Failure signatures:**
  - Misclassification: Legal Application nodes labeled as Legal Norm; paper notes this as expected behavior due to hierarchical structure.
  - Overextension: GPT captures primary norm but misses supporting norms in layered reasoning structures (schema currently lacks Legal Norm → Legal Norm edges).
  - Context overflow: If judgments exceed LLM context limits, edge extraction for distant nodes fails.
  - Self-loops: Fact and Application nodes show self-loops (472 and 746 respectively), suggesting some segments fulfill multiple roles.

- **First 3 experiments:**
  1. Reproduce node extraction accuracy: Sample 10 judgment sections, run GPT-4o with Martian Law prompt, manually annotate Fact/Norm/Application/Provision nodes, compute precision/recall against paper's Table 1 baseline.
  2. Test scoped-history ablation: Extract edges using local window (same-section only) vs. full scoped-history; measure edge extraction F1 on 20 judgment sections to quantify the benefit of accumulated context.
  3. Implement Fact-Masked retrieval baseline: Build Annoy index on fact embeddings from a held-out set of 50 facts; retrieve top-k similar facts with and without edge masking; compare recall@k to validate the masking strategy's contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Would extending the ontology to explicitly model edges between legal norms (Norm-to-Norm) significantly reduce false negatives in hierarchical reasoning extraction?
- **Basis in paper:** [Explicit] The authors state on page 10 that the "structural constraint in our current schema, which does not support edges between norms," causes missed links to supporting norms.
- **Why unresolved:** The current schema prevents the capture of layered normative dependencies, limiting the structural fidelity of the LKG.
- **Evidence to resolve:** Constructing an LKG with the expanded schema and measuring the reduction in false negatives for "Norm → Application" edges involving multi-layered support.

### Open Question 2
- **Question:** Can the extraction pipeline, designed for Japanese Civil Law, effectively capture reasoning paths in Common Law jurisdictions where reasoning is precedent-centric?
- **Basis in paper:** [Inferred] The paper evaluates only Japanese administrative cases and notes that legal context (like jurisdiction) significantly changes reasoning (Page 2).
- **Why unresolved:** The schema defines "Provision" and "Norm" which align with statutory law, whereas Common Law relies on "Case Law" and *ratio decidendi* which may require different node definitions.
- **Evidence to resolve:** Applying the same prompt-based extraction to a dataset of US or UK court judgments and evaluating the extraction accuracy of the "Provision" and "Norm" categories.

### Open Question 3
- **Question:** Does high recall in provision retrieval correlate with the logical validity of the intermediate reasoning steps (Facts → Norms)?
- **Basis in paper:** [Inferred] The quantitative evaluation focuses on the end task of "provision retrieval" (Table 6), while the qualitative evaluation (Section 3.3) only spot-checks reasoning paths.
- **Why unresolved:** It is unclear if the LKG retrieves correct provisions via valid logic paths or via incidental fact similarity without sound legal application.
- **Evidence to resolve:** A large-scale expert evaluation scoring the logical soundness of the full reasoning chain for the retrieved cases, rather than just the final provision match.

## Limitations
- Evaluation is constrained to Japanese administrative judgments from a single court system, limiting generalizability to other legal domains or common law jurisdictions.
- The schema assumes a four-step reasoning pattern (Fact → Norm → Application → Provision), which may not capture more complex or non-linear legal arguments.
- LLM-based extraction introduces both classification errors and edge cases (e.g., self-loops, missed supporting norms) that are not fully addressed in the current approach.

## Confidence
- **High:** LKG-based retrieval consistently outperforms LLM baselines across multiple metrics, and the structured schema is explicitly validated by legal experts.
- **Medium:** The mechanism claims (e.g., scoped-history prompting, Fact-Masked retrieval) are plausible and supported by ablation results, but exact prompt wording and LLM parameters are not fully disclosed.
- **Low:** Claims about cross-domain applicability and scalability to larger or more diverse legal corpora are not empirically tested.

## Next Checks
1. **Schema robustness test**: Apply the RDF schema to a small set of common law judgments (e.g., US Supreme Court opinions) and assess extraction accuracy. This will test whether the four-class pattern holds outside Japanese administrative law.

2. **Edge extraction ablation**: Systematically compare edge extraction performance using local windows vs. scoped-history vs. full-document context on 20 manually annotated judgment sections. Measure F1 to quantify the benefit of accumulated context.

3. **Retrieval under sparsity**: Construct a query set of facts with no similar precedents in the graph (e.g., from a held-out domain or synthetic examples). Evaluate whether LKG retrieval gracefully degrades or returns irrelevant results, and compare to LLM-only retrieval.