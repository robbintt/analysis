---
ver: rpa2
title: 'Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual
  Uncertainty-Aware Training Approach to SAM Optimization'
arxiv_id: '2509.04735'
source_url: https://arxiv.org/abs/2509.04735
tags:
- segmentation
- sam2
- driving
- uncertainty
- weather
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of improving segmentation performance
  in autonomous driving under adverse weather conditions, where visual ambiguity degrades
  model reliability. The authors propose two complementary uncertainty-aware approaches:
  (1) a multi-step finetuning of SAM2 incorporating uncertainty metrics into the loss
  function to improve overall segmentation accuracy, and (2) adapting the Uncertainty-Aware
  Adapter (UAT) from medical imaging to driving contexts to handle extreme weather
  scenarios.'
---

# Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization

## Quick Facts
- arXiv ID: 2509.04735
- Source URL: https://arxiv.org/abs/2509.04735
- Authors: Dharsan Ravindran; Kevin Wang; Zhuoyuan Cao; Saleh Abdelrahman; Jeffery Wu
- Reference count: 2
- Primary result: UAT-SAM approach improved DICE scores by 30% and IOU by 42.7% over zero-shot SAM in heavy weather conditions

## Executive Summary
This paper addresses the critical challenge of maintaining reliable semantic segmentation performance in autonomous driving systems under adverse weather conditions. The authors propose a dual uncertainty-aware approach that combines multi-step finetuning of SAM2 with uncertainty-aware adapters to enhance robustness against visual degradation caused by rain, fog, and snow. By explicitly modeling uncertainty in the training process, the framework demonstrates significant improvements in segmentation accuracy while maintaining safety-critical performance metrics.

## Method Summary
The authors present two complementary approaches to improve adverse weather segmentation. First, they develop a multi-step finetuning strategy for SAM2 that incorporates uncertainty metrics directly into the loss function, enabling the model to better handle ambiguous visual inputs. Second, they adapt the Uncertainty-Aware Adapter (UAT) framework from medical imaging applications to the autonomous driving domain, creating a specialized module that can dynamically adjust segmentation predictions based on input uncertainty levels. These approaches are evaluated across multiple datasets including CamVid, BDD100K, and GTA synthetic weather simulations.

## Key Results
- UAT-SAM approach achieved 30% improvement in DICE scores and 42.7% improvement in IOU compared to zero-shot SAM performance in heavy weather conditions
- SAM2 finetuning demonstrated consistent performance gains across all tested datasets with improved generalization to adverse weather scenarios
- The dual uncertainty-aware framework maintained safety-critical segmentation accuracy while significantly reducing false positive rates in challenging weather conditions

## Why This Works (Mechanism)
The proposed approach works by explicitly modeling and incorporating uncertainty during the training process, allowing the model to recognize when it cannot make confident predictions and adjust accordingly. By integrating uncertainty metrics into the loss function, the finetuned SAM2 learns to weigh ambiguous regions differently during training, effectively creating a learned attention mechanism for challenging visual conditions. The UAT adapter provides a modular solution that can be applied to existing segmentation models, offering flexibility in deployment while maintaining computational efficiency through its lightweight architecture.

## Foundational Learning
- **Semantic Segmentation Fundamentals**: Understanding pixel-level classification and mask generation is essential for evaluating model performance in driving contexts
  - *Why needed*: Segmentation forms the basis for environmental understanding in autonomous vehicles
  - *Quick check*: Can the model distinguish between drivable surfaces, obstacles, and lane markings under normal conditions

- **Uncertainty Quantification Methods**: Familiarity with epistemic vs aleatoric uncertainty and their computational implementations
  - *Why needed*: Different types of uncertainty require distinct handling strategies in adverse conditions
  - *Quick check*: Does the system properly differentiate between inherent noise (aleatoric) and model uncertainty (epistemic)?

- **Transformer-Based Vision Models**: Understanding SAM's architecture and attention mechanisms
  - *Why needed*: The paper builds upon SAM2's architecture, requiring knowledge of its strengths and limitations
  - *Quick check*: Can the model maintain spatial coherence in predictions despite weather-induced visual artifacts?

- **Adversarial Weather Simulation**: Knowledge of synthetic weather generation and validation techniques
  - *Why needed*: Most evaluation relies on simulated adverse conditions rather than real-world data
  - *Quick check*: Do the synthetic weather patterns accurately represent real-world degradation characteristics?

- **Performance Metrics for Segmentation**: Understanding DICE, IOU, and their limitations in safety-critical applications
  - *Why needed*: These metrics drive model optimization and comparison across different approaches
  - *Quick check*: Do the chosen metrics adequately capture the safety implications of segmentation errors?

## Architecture Onboarding

**Component Map:**
SAM2 -> Uncertainty-Aware Adapter (UAT) -> Loss Function with Uncertainty Metrics -> Training Pipeline

**Critical Path:**
Input Image → SAM2 Backbone → Uncertainty Estimation → Adaptive Prediction Adjustment → Final Segmentation Mask

**Design Tradeoffs:**
- Accuracy vs computational overhead: The UAT adds minimal parameters but requires additional uncertainty estimation computation
- Model complexity vs generalization: Multi-step finetuning improves weather-specific performance but may reduce cross-domain adaptability
- Real-time capability vs robustness: Uncertainty modeling adds latency but significantly improves safety in critical scenarios

**Failure Signatures:**
- Over-reliance on context: The model may hallucinate objects when visual evidence is obscured by heavy weather
- Uncertainty underestimation: In extreme conditions, the model may produce overconfident but incorrect predictions
- Computational bottlenecks: The uncertainty estimation process may cause frame rate drops in real-time applications

**First 3 Experiments:**
1. Baseline evaluation of SAM2 zero-shot performance on clear weather conditions to establish performance ceiling
2. Single-step uncertainty-aware finetuning on synthetic rain data to isolate weather-specific improvements
3. A/B testing of UAT adapter performance against traditional data augmentation approaches for adverse weather robustness

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, though several implicit limitations remain regarding real-world validation, computational overhead, and generalization across diverse weather types.

## Limitations
- Evaluation relies heavily on synthetic adverse weather simulations rather than real-world weather recordings, potentially limiting generalization to actual driving conditions
- Direct comparison with specialized adverse weather segmentation models is absent, making it difficult to contextualize the reported improvements
- Computational overhead and real-time performance implications of the uncertainty-aware approaches are not addressed, which is critical for deployment in autonomous vehicles

## Confidence
- SAM2 finetuning improvements: **Medium** - Performance gains demonstrated but lack of comparison with specialized models and limited real-world validation reduce confidence
- UAT-SAM approach effectiveness: **Medium** - Strong results on synthetic data, but adaptation from medical imaging to driving contexts requires further validation
- Overall framework robustness: **Low** - Limited testing across weather diversity and real-world conditions

## Next Checks
1. Evaluate the proposed approaches on real-world adverse weather datasets (e.g., RADIATE, Driving in the Matrix with actual weather recordings) to validate synthetic simulation results
2. Compare against specialized adverse weather segmentation models (e.g., BADWeather, MSPNet) to establish relative performance improvements
3. Conduct ablation studies isolating the contribution of uncertainty metrics versus other architectural changes to quantify their specific impact on performance gains