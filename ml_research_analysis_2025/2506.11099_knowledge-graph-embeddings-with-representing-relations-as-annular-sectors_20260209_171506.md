---
ver: rpa2
title: Knowledge Graph Embeddings with Representing Relations as Annular Sectors
arxiv_id: '2506.11099'
source_url: https://arxiv.org/abs/2506.11099
tags:
- entities
- relation
- knowledge
- relations
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses knowledge graph completion (KGC) by proposing
  a novel embedding model called SectorE that models entities as points and relations
  as annular sectors in polar coordinates. The core idea is to capture semantic hierarchies
  of entities through their positions in polar coordinates, while relations are represented
  as annular sectors combining modulus and phase parts to characterize inference patterns
  and relation attributes.
---

# Knowledge Graph Embeddings with Representing Relations as Annular Sectors

## Quick Facts
- **arXiv ID:** 2506.11099
- **Source URL:** https://arxiv.org/abs/2506.11099
- **Authors:** Huiling Zhu; Yingqi Zeng
- **Reference count:** 34
- **Primary result:** SectorE achieves competitive performance on FB15k-237, WN18RR, and YAGO3-10 datasets, demonstrating superior capability in modeling semantic hierarchies and capturing multiple relation patterns.

## Executive Summary
This paper introduces SectorE, a novel knowledge graph embedding model that represents entities as points and relations as annular sectors in polar coordinates. The model aims to capture semantic hierarchies through the modulus dimension while distinguishing same-level entities through phase, with relations modeled as geometric regions that enable pattern learning. Evaluated on standard KGC benchmarks, SectorE shows competitive performance and particular strength on the YAGO3-10 dataset, outperforming baselines in Hits@1 and MRR metrics.

## Method Summary
SectorE embeds entities in polar coordinates using basic vectors (modulus, phase) and transformational bumps. Relations are represented as annular sectors with head and tail components, each defined by modulus and phase boundaries. The model uses separate distance functions for modulus and phase dimensions, combined with depth-dependent scaling, to measure entity-to-sector distances. Training employs self-adversarial negative sampling with a margin-based loss function. The geometric formulation enables natural encoding of hierarchical structure and various relation patterns including symmetry, anti-symmetry, and subsumption.

## Key Results
- SectorE achieves competitive performance across FB15k-237, WN18RR, and YAGO3-10 datasets
- Model demonstrates superior capability in modeling semantic hierarchies compared to baselines
- Particularly strong performance on YAGO3-10 with best Hits@1 and MRR scores
- Captures multiple relation patterns including symmetry, anti-symmetry, inversion, and subsumption
- Ablation study shows transformational bumps contribute most significantly to performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Embedding entities in polar coordinates enables natural encoding of semantic hierarchies through the modulus dimension while distinguishing same-level entities through phase.
- **Mechanism:** Each entity has a basic position vector (modulus, phase) in polar coordinates. Higher-level entities cluster at certain modulus ranges, while lower-level entities occupy different ranges. The phase dimension separates entities within the same hierarchical level. A transformational bump from the partner entity in a triple further adjusts the final position, making entity representations context-dependent.
- **Core assumption:** Semantic hierarchy in the KG correlates with learnable modulus values, and this ordering is consistent across relations.
- **Evidence anchors:**
  - [abstract] "Entities are embedded as points within these sectors, intuitively encoding hierarchical structure."
  - [Page 2, Section III-B-1] "Every entity ei ∈ E is represented by two vectors: a basic vector ei representing the initial position of the entity and a transformational bump bi representing the transformational effect to other entities."
  - [corpus] Related work HAKE uses similar polar coordinate approach for hierarchy; corpus papers like PathE focus on parameter efficiency rather than hierarchy.

### Mechanism 2
- **Claim:** Representing relations as annular sectors in polar coordinates allows simultaneous capture of inference patterns and relation attributes through geometric region interactions.
- **Mechanism:** Each relation has two annular sectors (head sector rh, tail sector rt) defined by modulus boundaries [l(r), u(r)] and phase boundaries [ψ(r), ϕ(r)]. A triple holds when the bumped head entity falls within rh and the bumped tail entity falls within rt. Patterns emerge from region relationships: identical sectors capture symmetry (rh₁ = rt₁), disjoint head/tail sectors capture anti-symmetry, swapped sectors capture inversion, nested sectors capture subsumption.
- **Core assumption:** Relation semantics can be expressed as geometric constraints on entity positions, and these constraints are learnable via gradient descent.
- **Evidence anchors:**
  - [Page 3, Section III-D] Explicit definitions for symmetry, anti-symmetry, inversion, subsumption via sector configurations.
  - [Page 5, Table IV] Relation sector areas correlate with entity diversity and relation cardinality.
  - [corpus] BoxE uses box regions but lacks polar hierarchy; no corpus neighbor directly uses annular sectors.

### Mechanism 3
- **Claim:** Separate distance functions for modulus and phase dimensions, combined with depth-dependent scaling, enable effective gradient-based learning of sector boundaries.
- **Mechanism:** The scoring function computes separate distances from entity points to sector centers. Inside the sector, distance scales inversely with sector depth (w or δ) to pull entities toward centers. Outside, distance scales directly with depth and subtracts a continuity correction term k. This piecewise formulation ensures smooth gradients at boundaries. Final score is weighted combination: score = -Σ(λ₁·dist_m + λ₂·dist_p).
- **Core assumption:** The piecewise distance function with continuity correction provides stable optimization; modulus and phase contribute independently to plausibility.
- **Evidence anchors:**
  - [Page 3-4, Equations 3-5] Full mathematical specification of dist_m, dist_p, and combined scoring function.
  - [Page 5, Table III] Ablation shows transformational bump removal causes largest performance drop; phase contributes more than modulus on WN18RR.

## Foundational Learning

- **Concept: Knowledge Graphs and Link Prediction**
  - Why needed here: SectorE operates on KG triples (h, r, t) and optimizes for link prediction. Understanding what makes a triple "plausible" is prerequisite to grasping why sector membership encodes correctness.
  - Quick check question: Given entities "Paris" and "France" with relation "capitalOf," what would a high-scoring triple look like in SectorE's geometry?

- **Concept: Polar Coordinates (r, θ)**
  - Why needed here: The entire model is formulated in polar rather than Cartesian space. Modulus r encodes hierarchy depth; phase θ encodes position within a hierarchical level. Operations like ⊙ (elementwise product with modular phase addition) differ from standard vector operations.
  - Quick check question: If entity A has modulus 2.0 and phase π/4, and receives a transformational bump of modulus 1.2 and phase π/2, what is the final phase? (Answer: 3π/4, modulo 2π)

- **Concept: Region-Based Embedding Models**
  - Why needed here: SectorE extends the BoxE/Query2Box paradigm from boxes to annular sectors. Understanding that relations define geometric regions (rather than translations or rotations) clarifies why pattern capture is expressed as set operations on regions.
  - Quick check question: How would a box-based model represent the symmetry pattern r(x,y) → r(y,x), and how does SectorE's approach differ?

## Architecture Onboarding

- **Component map:**
  ```
  Entity Layer: e_i = (m_e, p_e) ∈ ℝ⁺_d × [0,2π)_d (basic vector)
                 b_i = (m_b, p_b) ∈ ℝ⁺_d × [0,2π)_d (transformational bump)
  
  Relation Layer: r = (r_h, r_t) where each sector has:
                  - Modulus bounds: l(r), u(r) → center c(r), depth w(r)
                  - Phase bounds: ψ(r), ϕ(r) → center θ(r), angle δ(r)
  
  Scoring Layer: For triple (h, r, t):
                  - Bumped embeddings: e_h^* = e_h ⊙ b_t, e_t^* = e_t ⊙ b_h
                  - dist_m and dist_p computed separately for head/tail
                  - Combined via learned weights λ₁, λ₂
  
  Training: Self-adversarial negative sampling with margin γ, temperature α
  ```

- **Critical path:** Entity/relation initialization → forward pass (bumping + sector membership check) → distance computation → score aggregation → negative sampling → loss backward. The piecewise distance functions (Equations 3-4) are the most delicate implementation points due to boundary conditions.

- **Design tradeoffs:**
  - **Sector vs. Box:** Sectors naturally encode hierarchy via modulus but require polar coordinate operations; boxes use simpler Cartesian math but lack hierarchy awareness.
  - **Separate head/tail sectors:** Doubles relation parameters but enables asymmetric relations and M-N cardinality modeling.
  - **Transformational bumps:** Adds context-dependency but increases memory/computation.

- **Failure signatures:**
  - **Nan/Inf in phase distance:** Check modular arithmetic in phase addition; ensure sin() inputs are properly bounded.
  - **All entities mapping to same modulus:** Learning rate may be too low or margin γ too high; modulus collapse indicates hierarchy signal not being captured.
  - **Poor performance on symmetric relations:** Verify rh = rt constraint is emergent, not enforced.
  - **YAGO3-10 good, FB15k-237 poor:** Expected per paper—FB15k-237 has more complex relation types and fewer entities.

- **First 3 experiments:**
  1. **Sanity check on synthetic hierarchy:** Create a toy KG with explicit hierarchy (A → B → C chain). Verify that learned moduli reflect the chain order. If not, check initialization and λ₁/λ₂ balance.
  2. **Ablation replication:** Remove transformational bumps (set all b = (1, 0)), train on WN18RR. Confirm ~3-6% MRR drop to validate implementation.
  3. **Relation pattern probe:** Train on subset of YAGO3-10, then analyze learned sector areas for 1-N vs N-1 relations. Verify rh/rt area ratios match paper's patterns.

## Open Questions the Paper Calls Out
- **Open Question 1:** How does SectorE perform on very large-scale datasets with high relational complexity?
  - Basis: [explicit] The conclusion states, "In the future, we intend to explore the performance of our model on further datasets, especially the large ones that including more complex relations."
  - Why unresolved: Current evaluation limited to standard benchmarks; authors identify testing on larger, more complex graphs as necessary future work.
  - What evidence would resolve it: Evaluation results on datasets significantly larger than YAGO3-10 with higher diversity of relation types.

- **Open Question 2:** Can SectorE effectively model relation composition patterns (r₁(x,y) ∧ r₂(y,z) → r₃(x,z))?
  - Basis: [inferred] Section II notes that BoxE fails to capture composition, and Section III.D lists symmetry, inversion, and subsumption capabilities but omits composition.
  - Why unresolved: While model captures intersections and subsumption via region geometry, paper does not provide analysis of composition capability.
  - What evidence would resolve it: Formal proof regarding composition of annular sectors or experimental results on composition-heavy benchmark subsets.

- **Open Question 3:** Does the reliance on polar coordinates and hierarchy modeling hinder performance on datasets with predominantly "flat" or non-hierarchical relations?
  - Basis: [inferred] Section IV.B attributes lower performance on FB15k-237 to "some triples [in FB15k-237] do not lead to hierarchy transformation."
  - Why unresolved: Unclear if inductive bias towards semantic hierarchy acts as a bottleneck when hierarchies are absent or sparse.
  - What evidence would resolve it: Ablation study on synthetic or real datasets where ground-truth hierarchical depth is controlled, comparing performance against non-hierarchical baselines.

## Limitations
- Limited qualitative validation of the assumed correlation between modulus values and semantic hierarchy
- Lack of explicit hyperparameter values (learning rate, β, final search results) creates reproducibility barriers
- Performance attribution on YAGO3-10 not deeply analyzed - gains may stem from hierarchy modeling or other dataset characteristics
- No complexity analysis provided for computational overhead versus simpler baselines

## Confidence
- **High Confidence:** The geometric formulation of relations as annular sectors and the mathematical specification of the scoring function
- **Medium Confidence:** The claim that modulus encodes semantic hierarchy, plausible given HAKE's success but lacking direct empirical validation
- **Low Confidence:** The attribution of YAGO3-10 performance gains specifically to hierarchy modeling versus other factors

## Next Checks
1. **Hierarchy Verification:** Train SectorE on a synthetically constructed KG with explicit hierarchical structure (e.g., A→B→C chain). Measure correlation between learned moduli and ground-truth hierarchy depth. If correlation is weak, investigate whether initialization or λ₁ weighting needs adjustment.

2. **Pattern Capture Analysis:** For a subset of YAGO3-10 relations, extract learned sector boundaries and compute rh/rt area ratios. Compare these ratios against paper's predictions (e.g., 1-N relations should have larger rh than rt). Discrepancies indicate pattern capture limitations.

3. **Ablation with Controlled Hierarchy:** Create a modified FB15k-237 where all relations are symmetric (duplicate each relation with swapped arguments). Train SectorE with and without enforcing rh = rt. Measure symmetry performance and compare against paper's claims about emergent symmetry capture.