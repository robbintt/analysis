---
ver: rpa2
title: A Flexible Fairness Framework with Surrogate Loss Reweighting for Addressing
  Sociodemographic Disparities
arxiv_id: '2503.16836'
source_url: https://arxiv.org/abs/2503.16836
tags:
- fairness
- loss
- accuracy
- learning
- group
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces \u03B1-\u03B2 Fair Machine Learning (\u03B1\
  -\u03B2 FML), a flexible framework for addressing sociodemographic disparities in\
  \ machine learning. The method employs a family of surrogate loss functions with\
  \ tunable hyperparameters \u03B1 and \u03B2, allowing precise control over fairness-accuracy\
  \ trade-offs."
---

# A Flexible Fairness Framework with Surrogate Loss Reweighting for Addressing Sociodemographic Disparities

## Quick Facts
- arXiv ID: 2503.16836
- Source URL: https://arxiv.org/abs/2503.16836
- Authors: Wen Xu; Elham Dolatabadi
- Reference count: 31
- One-line primary result: Introduces α-β Fair Machine Learning (α-β FML) framework using surrogate loss reweighting with tunable hyperparameters to balance fairness-accuracy trade-offs.

## Executive Summary
This paper introduces α-β Fair Machine Learning (α-β FML), a flexible framework for addressing sociodemographic disparities in machine learning. The method employs a family of surrogate loss functions with tunable hyperparameters α and β, allowing precise control over fairness-accuracy trade-offs. The framework uses loss reweighting techniques to balance performance across protected groups while maintaining overall accuracy. Experiments on three datasets demonstrate the framework's effectiveness in improving worst-group accuracy and reducing equality of accuracy violations compared to standard empirical risk minimization.

## Method Summary
The α-β FML framework employs β-transformed surrogate loss functions that amplify penalties for high-loss samples, implicitly forcing the model to attend to underperforming groups. The method uses Parallel Stochastic Gradient Descent with Surrogate Loss (P-SGD-S) to efficiently solve the learning objective, maintaining convergence guarantees for both convex and nonconvex loss functions. Hyperparameter α controls explicit group weights while β controls loss-based amplification, enabling orthogonal control over inter-group versus intra-group fairness dynamics.

## Key Results
- Framework achieves smooth trade-off between standard ERM and strict minimax fairness
- Accuracy improvements of 1-3% over baseline methods while reducing fairness violations by 20-40%
- Method's flexibility allows practitioners to tune fairness levels through simple hyperparameter adjustments
- Demonstrated effectiveness on Adult, COMPAS, and Fashion-MNIST datasets

## Why This Works (Mechanism)

### Mechanism 1: β-Fair Surrogate Loss Amplification
The surrogate loss function f_β(w, (z,y)) = (1 + ℓ(w, (z,y)))^(1+β)/(1+β) places exponentially larger penalties on high-loss samples, forcing the optimizer to attend to underperforming groups. When β > 0, the transformation amplifies gradients from samples with larger original losses, creating implicit curriculum pressure to improve on difficult examples—disproportionately benefiting minority groups with higher per-sample losses.

### Mechanism 2: Dual Hyperparameter Disentanglement (α-β Separation)
Separating α (explicit group weights) from β (loss-based amplification) enables orthogonal control over inter-group versus intra-group fairness dynamics. The α parameters directly upweight minority groups at the group level, while β parameters operate at the sample level within groups. This separation allows maintaining equal group weighting while still penalizing high-loss samples within each group.

### Mechanism 3: Parallel Stochastic Gradient Aggregation with Convergence Preservation
The P-SGD-S algorithm maintains O(1/√T) convergence rates for both convex and nonconvex losses by enforcing unbiased stochastic gradient estimates and bounded variance under the surrogate transformation. Each group computes stochastic gradients using its β-transformed loss, which are then aggregated via weighted combination. The proof relies on showing that surrogate gradients remain unbiased estimators with bounded variance.

## Foundational Learning

- **Surrogate Loss Functions**
  - Why needed here: The core innovation replaces standard loss ℓ with a transformed version f_β that changes the optimization landscape. Understanding surrogate losses is prerequisite to grasping why this transformation affects group-relative performance.
  - Quick check question: If you set β = 0, what does the surrogate loss reduce to? (Answer: (1+ℓ)^1/1 = 1+ℓ, which is just the original loss plus a constant offset, yielding identical gradients to standard ERM up to the constant.)

- **Minimax Fairness vs. Distributionally Robust Optimization (DRO)**
  - Why needed here: The paper positions α-β FML as providing a "smooth trade-off" between ERM and minimax fairness. Understanding minimax fairness and its connection to DRO is essential to interpret where on this spectrum a given (α, β) configuration falls.
  - Quick check question: In the limit as β → ∞ for all groups, which sample dominates the surrogate loss? (Answer: The sample with the maximum loss, recovering minimax/DRO behavior.)

- **Stochastic Gradient Descent Convergence Theory**
  - Why needed here: The paper's contribution includes convergence guarantees for P-SGD-S. Interpreting Theorems 1-2 requires familiarity with concepts like L-smoothness, unbiased gradient estimators, bounded variance, and O(1/√T) convergence rates for SGD.
  - Quick check question: Why does the convergence bound in Theorem 2 depend on L₀ησ² rather than just η and σ²? (Answer: Because the surrogate loss's smoothness constant L₀ scales the impact of gradient variance on the descent guarantee; larger L₀ from high β requires smaller η.)

## Architecture Onboarding

- **Component map:**
  ```
  Data Partitioner
       ↓
  Group-Specific Minibatch Samplers (S₀, S₁)
       ↓
  β-Transformed Loss Computer [f_β(w, (z,y)) per group]
       ↓
  Stochastic Gradient Estimator [Eq. 7: weighted by (1+ℓ)^β]
       ↓
  Local Model Updater [Eq. 8: per-group descent step]
       ↓
  Weighted Aggregator [Eq. 9: α-weighted combination]
       ↓
  Convergence Monitor (gradient norm, EA violation, worst-group accuracy)
  ```

- **Critical path:** The β-transformation at the loss computer and the α-weighting at the aggregator are the two intervention points. Any implementation bug in these (e.g., forgetting the +1 bias in f_β, or normalizing α incorrectly) will silently corrupt fairness behavior while still producing a "trained" model.

- **Design tradeoffs:**
  - High β values: Stronger fairness enforcement but requires smaller learning rates and may slow convergence. Risk of overfitting to noisy high-loss samples.
  - Equal vs. proportional α: Equal group weights (α₀ = α₁ = 0.5) upweight minority groups per-sample; proportional weights (α₀ = |S₀|/N) maintain representation fidelity. Choice depends on whether fairness goal is parity or robustness.
  - Parallel vs. sequential updates: Parallel P-SGD-S enables GPU utilization but requires synchronization overhead; sequential would simplify debugging at cost of efficiency.

- **Failure signatures:**
  - Divergence in early iterations: Likely η too large for current β; reduce learning rate by factor of 10 or initialize β near 0 and anneal upward.
  - EA violation plateaus despite high β: Check that group assignments (S₀, S₁) are correct; verify α weights are applied at aggregation not at loss computation; ensure protected feature is not accidentally included in non-protected feature set.
  - Overall accuracy collapses: β may be too high, forcing model to overfit to outliers; try asymmetric β (e.g., β₀ > 0, β₁ = 0) to target only the underperforming group.

- **First 3 experiments:**
  1. **Baseline reproducibility:** Run P-SGD-S with β₀ = β₁ = 0 and proportional α on Adult dataset; verify overall accuracy and EA violation match standard ERM benchmarks.
  2. **β sensitivity sweep:** On Adult with fixed α (proportional or equal), sweep β ∈ {0, 0.5, 1, 2, 5} and plot worst-group accuracy vs. overall accuracy. Confirm monotonic improvement in worst-group accuracy as β increases.
  3. **Minimax comparison:** Run MINIMAX (SGDA solver, Eq. 13) and P-SGD-S with high β (β₀ = β₁ = 10) on COMPAS. Compare worst-group accuracy, EA violation, and training time.

## Open Questions the Paper Calls Out
- Can the α-β FML framework maintain convergence guarantees when applied to intersectional fairness involving multiple, overlapping protected attributes?
- Is there a principled mechanism for selecting optimal α and β hyperparameters to satisfy specific fairness constraints without extensive trial-and-error?
- Does the P-SGD-S algorithm retain its efficiency and fairness-accuracy balance when scaled to large, non-convex models like transformers on multimodal data?

## Limitations
- Computational overhead of maintaining separate model states per group and computing β-transformed losses may become prohibitive for very large-scale applications
- Framework's robustness to real-world noise and label corruption remains unclear, as high β values risk amplifying noisy samples
- The interaction between α and β hyperparameters may exhibit nonlinear effects in practice that could compromise the promised controllability

## Confidence

- **High Confidence**: The theoretical convergence guarantees (Theorems 1-2) and the core β-fair surrogate loss formulation. The surrogate loss transformation and its gradient properties are mathematically sound and verifiable.
- **Medium Confidence**: The empirical effectiveness on benchmark datasets (Adult, COMPAS, Fashion-MNIST). While the reported improvements are promising, the relatively small dataset sizes and controlled conditions limit generalizability to complex, noisy real-world scenarios.
- **Low Confidence**: The scalability and robustness claims for large-scale, high-dimensional problems. The paper lacks experiments on deep learning architectures and massive datasets where β-induced gradient variance and per-group computation would be most challenging.

## Next Checks

1. **Robustness to Label Noise**: Test P-SGD-S on Adult/COMPAS datasets with injected label corruption (10-30%) and measure whether high β values amplify or mitigate the impact of noisy samples on worst-group accuracy.

2. **Hyperparameter Interaction Analysis**: Conduct a grid search over α and β values on Fashion-MNIST to empirically map the fairness-accuracy landscape and identify any unexpected nonlinear interactions or instability regions.

3. **Deep Learning Scalability Test**: Implement P-SGD-S with ResNet-18 on a multi-group image classification task (e.g., CelebA with skin tone and gender attributes) to evaluate computational overhead and convergence behavior under realistic conditions.