---
ver: rpa2
title: An Approach to Checking Correctness for Agentic Systems
arxiv_id: '2509.20364'
source_url: https://arxiv.org/abs/2509.20364
tags:
- temporal
- agent
- weather
- expression
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a temporal expression language for monitoring
  AI agent behavior in agentic systems that use stochastic LLMs. By focusing on sequences
  of agent tool calls and state transitions rather than natural language outputs,
  the approach enables systematic error detection of behavioral anomalies.
---

# An Approach to Checking Correctness for Agentic Systems

## Quick Facts
- arXiv ID: 2509.20364
- Source URL: https://arxiv.org/abs/2509.20364
- Reference count: 17
- Primary result: Temporal expression monitoring detects LLM-based agent coordination failures

## Executive Summary
This paper introduces a runtime verification framework using temporal expressions to monitor AI agent behavior in multi-agent systems powered by stochastic LLMs. The approach focuses on tool call sequences and state transitions rather than natural language outputs, enabling systematic detection of behavioral anomalies like improper tool sequencing and failed coordination handoffs. Demonstrated on a three-agent weather/greeting system, the framework successfully identifies failures when smaller LLMs are substituted for larger ones, while satisfying all assertions across many runs with strong models.

## Method Summary
The method implements runtime monitoring using a temporal expression language built on Linear Temporal Logic (LTL) foundations. It instruments agent tool calls as discrete sampling events and evaluates predicates against the current state at each event. The framework uses operators like concatenation, conditional (`>>`), alternation, fusion, and repeat to specify expected behavioral patterns. When smaller models fail to follow coordination protocols, the system produces detailed match/failure traces showing exactly which sub-expressions violated the assertions. The approach was validated on a three-agent system where assertions correctly identified coordination failures in weaker models while strong models satisfied all specifications.

## Key Results
- Temporal expressions successfully detected improper tool sequencing when smaller LLMs were substituted
- Runtime monitoring identified failed coordination handoffs between agents
- Strong models (Claude Sonnet) satisfied all assertions across multiple test runs
- The framework produced detailed trace outputs pinpointing specific violation points

## Why This Works (Mechanism)

### Mechanism 1: Temporal Expression-Based Behavioral Monitoring
The framework adapts Linear Temporal Logic operators to specify expected behavioral patterns through observable tool calls and state transitions. At each sampling event, predicates evaluate the current state and temporal expressions check for pattern matches or violations. This works because agent correctness can be determined by verifying observable behaviors without needing to interpret natural language semantics.

### Mechanism 2: Event-Driven Sampling with Detailed Trace Generation
By instrumenting agent tool calls as discrete sampling events, the system produces detailed match/failure traces showing which sub-expressions succeeded or failed at specific event counts. This enables precise error localization by decomposing top-level expressions into sub-expression matches with start/end cycles.

### Mechanism 3: Conditional Assertions for Agent Coordination Protocols
Conditional temporal assertions (using the `>>` operator) detect inter-agent handoff failures by specifying that if event A occurs, then event B must follow. This encodes coordination protocols and produces failure traces pinpointing exactly which step violated the protocol when weaker models fail sequencing.

## Foundational Learning

- **Concept: Linear Temporal Logic (LTL)**
  - Why needed here: The temporal expression language is built on LTL foundations. Understanding how temporal operators compose is essential for writing correct assertions.
  - Quick check question: Given the formula `a U b` ("a until b"), what happens if event `b` never occurs?

- **Concept: Runtime Verification vs Model Checking**
  - Why needed here: This paper implements runtime monitoring (checking actual execution traces), not model checking (proving properties for all possible executions). This distinction clarifies what guarantees you get.
  - Quick check question: Can runtime verification prove that an agent will never exhibit a bad behavior, or only detect it when it occurs?

- **Concept: Event-Driven Discrete Time**
  - Why needed here: Time advances by sampling events (tool calls), not wall-clock ticks. This abstraction determines how predicates map to execution states.
  - Quick check question: If your agent makes three rapid tool calls, how does the framework represent theseâ€”as simultaneous or sequential events?

## Architecture Onboarding

- **Component map:** Oroboro Package -> Monitor Process -> Framework Hooks -> Predicates -> Temporal Assertions
- **Critical path:**
  1. Identify observable events in your agent system (tool calls, transfers, state changes)
  2. Define predicates mapping events to Boolean values
  3. Compose temporal assertions for expected behavioral patterns
  4. Instrument framework to signal sampling events to the monitor
  5. Execute agent scenarios and collect match/failure traces
  6. Analyze failures to identify root causes (sequencing errors, missing handoffs)

- **Design tradeoffs:**
  - **Partial vs Complete Specification:** Assertions can specify critical paths while leaving other behaviors unconstrained
  - **Behavioral vs Semantic:** Handles sequencing well; cannot verify semantic correctness of natural language outputs
  - **Manual Effort:** Requires hand-crafted predicates and assertions

- **Failure signatures:**
  - **Improper sequencing:** Tool called in wrong order
  - **Failed handoff:** Agent transfers to wrong agent or doesn't return control
  - **Missing steps:** Expected tool call never occurs
  - **Trace output:** Shows `FAILURE` with event numbers and which sub-expression violated

- **First 3 experiments:**
  1. **Baseline validation:** Configure the three-agent system with strong models, run the greeting+weather script 10 times, verify all assertions match
  2. **Regression detection:** Substitute smaller models for Greeting and Farewell agents, run same script, observe assertion failures
  3. **New assertion type:** Define a temporal expression for a novel property and test with varied inputs

## Open Questions the Paper Calls Out

### Open Question 1
Can the manual burden of instrumenting events and crafting assertions be reduced through automated generation of event predicates?
The conclusion notes that the current approach "requires developers to manually instrument events and craft assertions," suggesting future tooling should "automatically generate event predicates from common agent patterns."

### Open Question 2
How can temporal monitoring be integrated with semantic analysis to detect errors involving text or images?
Section 5 lists the limitation that temporal expressions "cannot address errors requiring semantic analysis of text, images, or conversation context."

### Open Question 3
How can violation alerts be translated into actionable feedback for automated agent recovery?
The conclusion states the system can "provide feedback for agent recovery planning," but this mechanism is not implemented or evaluated in the paper.

## Limitations
- Manual effort burden for defining predicates and temporal assertions
- Cannot verify semantic correctness of natural language outputs
- Assumes discrete, serializable events that can be mapped to mutually exclusive predicates

## Confidence

**High Confidence Claims:**
- Temporal expression language can detect behavioral anomalies through runtime monitoring
- Framework successfully identifies coordination failures when weaker models replace stronger ones
- Trace generation provides actionable information about which specific steps violated assertions

**Medium Confidence Claims:**
- Approach generalizes beyond the three-agent weather/greeting system
- "One-hot" predicate encoding is sufficient for most real-world agent coordination scenarios
- Manual effort scales acceptably with system complexity

**Low Confidence Claims:**
- Effectiveness on agent systems with continuous state spaces or complex internal reasoning
- Applicability to agent systems where tool call sequences aren't sufficient indicators of correctness
- Performance characteristics and scalability for high-frequency tool calls or many agents

## Next Checks

1. **Expressiveness Boundary Test:** Define a temporal assertion requiring non-deterministic branching and verify whether the framework correctly handles such conditional paths.

2. **Sampling Granularity Analysis:** Create an agent that makes multiple rapid tool calls and determine whether the framework can distinguish between truly simultaneous events versus sequential events that happen to be close in time.

3. **Model-Agnostic Verification:** Select a different agentic task (e.g., code generation or document summarization) and implement the same monitoring framework to assess whether the approach transfers successfully to domains with different coordination patterns.