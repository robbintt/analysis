---
ver: rpa2
title: Question Answering on Patient Medical Records with Private Fine-Tuned LLMs
arxiv_id: '2501.13687'
source_url: https://arxiv.org/abs/2501.13687
tags:
- task
- patient
- llms
- fine-tuned
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a two-stage approach for answering questions
  about patient medical records using fine-tuned LLMs. The first stage identifies
  relevant FHIR resources for a given query, and the second stage generates answers
  using these resources.
---

# Question Answering on Patient Medical Records with Private Fine-Tuned LLMs

## Quick Facts
- **arXiv ID:** 2501.13687
- **Source URL:** https://arxiv.org/abs/2501.13687
- **Authors:** Sara Kothari; Ayush Gupta
- **Reference count:** 31
- **One-line result:** Fine-tuned Llama-3.1-8B and Mistral-NeMo outperform GPT-4 on FHIR medical QA by 0.55% F1 and 42% METEOR

## Executive Summary
This paper introduces a two-stage approach for answering questions about patient medical records using fine-tuned LLMs. The first stage identifies relevant FHIR resources for a given query, and the second stage generates answers using these resources. Fine-tuned Llama-3.1-8B and Mistral-NeMo models were evaluated against GPT-4 and Meditron-7B, showing that the fine-tuned models outperformed GPT-4 family models by 0.55% in F1 score on the classification task and 42% on the Meteor metric for answer generation. These smaller models (250x smaller than GPT-4) demonstrated superior accuracy, efficiency, and privacy compliance. The study also examined sequential fine-tuning, dataset size effects, and LLM self-evaluation bias. Results highlight that fine-tuning open-source LLMs is an effective and privacy-preserving solution for medical question answering over FHIR records.

## Method Summary
The paper presents a two-stage semantic QA system over FHIR records. Stage 1 performs binary classification to identify relevant FHIR resources for a query. Stage 2 generates answers based on the selected resources. Synthetic patient data was generated via Synthea (50 patients for Task 1, 500 total for Task 2). Resources were filtered to specific types (Procedure, Medication, Observation, etc.). Queries, labels, and answers were synthesized via GPT-4. QLoRA fine-tuning (Rank 16, 4-bit quantization) was applied to Llama-3.1-8B and Mistral-NeMo models. The evaluation used F1 Score for classification and METEOR Score for generation, with 5 epochs of training on 95-5 and 98-2 data splits.

## Key Results
- Fine-tuned Llama-3.1-8B and Mistral-NeMo outperformed GPT-4 family models by 0.55% in F1 score on classification task
- Fine-tuned models achieved 42% improvement over GPT-4 on Meteor metric for answer generation
- Sequential fine-tuning caused catastrophic forgetting, with F1 dropping to 31.62% when training on Task 2 after Task 1
- Models trained on full dataset (4,900 examples) showed ~4.5% improvement over those trained on 500 examples

## Why This Works (Mechanism)
The approach works by decomposing the complex medical QA task into two specialized sub-tasks that can be effectively learned by smaller models. By fine-tuning open-source LLMs on domain-specific FHIR data, the models learn the clinical terminology and resource relationships that general-purpose models like GPT-4 lack. The QLoRA technique enables efficient fine-tuning of large models with limited computational resources. The two-stage architecture allows each model to specialize in its task without being overloaded with multiple objectives. The synthetic data generation provides controlled training examples that cover the FHIR resource space systematically.

## Foundational Learning
- **FHIR (Fast Healthcare Interoperability Resources):** Healthcare data standard using JSON/XML resources. Why needed: Provides structured clinical data format for model training. Quick check: Can identify resource types (Patient, Condition, Medication) in sample FHIR files.
- **QLoRA (Quantized Low-Rank Adaptation):** Parameter-efficient fine-tuning using 4-bit quantization with LoRA adapters. Why needed: Enables fine-tuning large models on limited GPU memory. Quick check: Model weights reduce from 4.7B to ~1.8GB with 4-bit quantization.
- **METEOR Score:** Metric measuring n-gram overlap with stemming and synonym matching. Why needed: Evaluates semantic similarity beyond exact word matching in generated answers. Quick check: Score ranges from 0-1, with 0.5+ indicating reasonable generation quality.
- **Synthea:** Synthetic patient data generator. Why needed: Creates realistic but privacy-preserving medical records for training. Quick check: Can generate 50 patients with complete medical histories in minutes.
- **Sequential Fine-tuning:** Training model on Task 1 then Task 2 sequentially. Why needed: Tests knowledge transfer and potential catastrophic forgetting. Quick check: Performance drops indicate loss of previously learned task capabilities.

## Architecture Onboarding

**Component Map**
Synthea -> FHIR Preprocessing -> Task 1 (Classification) -> Task 2 (Generation) -> Evaluation

**Critical Path**
Data Generation (Synthea) -> FHIR Resource Filtering -> GPT-4 Synthetic Label Generation -> QLoRA Fine-tuning -> Evaluation

**Design Tradeoffs**
The choice of two separate models versus a single multi-task model trades specialization for potential knowledge transfer. The synthetic data approach prioritizes privacy and control over real-world complexity. QLoRA enables resource-efficient fine-tuning but may limit model capacity compared to full fine-tuning.

**Failure Signatures**
- F1 scores below 90% indicate poor resource relevance classification
- METEOR scores below 0.4 suggest inadequate answer generation quality
- Sequential fine-tuning causing >50% performance drop indicates catastrophic forgetting
- Evaluation bias when LLM-as-a-judge shows systematic preference for certain model families

**Three First Experiments**
1. Test FHIR resource filtering script independently to ensure only clinical data passes through
2. Verify QLoRA configuration by checking memory usage and weight quantization on sample batch
3. Validate synthetic data quality by manually reviewing 10 randomly selected (query, answer) pairs for medical accuracy

## Open Questions the Paper Calls Out

**Open Question 1:** How robust are these fine-tuned models when applied to real-world electronic health records (EHRs) compared to the synthetic Synthea data used in this study?
- Basis: Section 6.2 explicitly states synthetic data may not capture full complexity of actual patient records
- Why unresolved: Real-world clinical data contains noise, abbreviations, and inconsistencies that synthetic generators often fail to replicate
- Evidence needed: Comparative evaluation on de-identified real patient records with human-annotated ground truth

**Open Question 2:** Can multi-task learning (MTL) strategies effectively mitigate the "catastrophic forgetting" observed in sequential fine-tuning?
- Basis: Section 6.3 states future work will investigate MTL to develop single model handling both tasks
- Why unresolved: Experiments show sequential fine-tuning leads to 67% drop in F1 score, leaving MTL utility unproven
- Evidence needed: Training single model simultaneously on both tasks and comparing F1/METEOR scores against sequential baselines

**Open Question 3:** What are the scaling limits and saturation points of performance gains as synthetic training dataset size increases beyond 5,000 examples?
- Basis: Section 5.2.2 notes need for deeper study on more size variations and improvement limits
- Why unresolved: Study only compares 500 vs 4,900 examples showing ~4.5% gain, unclear if trend continues
- Evidence needed: Logarithmic scaling analysis with 10k, 50k, and 100k examples to identify diminishing returns point

**Open Question 4:** To what degree does reliance on GPT-4 for generating synthetic ground-truth answers introduce systematic biases or "hallucinations" into smaller student models?
- Basis: Methodology uses GPT-4 to generate "ground truth" answers without human verification or comparison against actual physician notes
- Why unresolved: Models evaluated using METEOR against GPT-4's synthetic answers, measuring linguistic similarity rather than medical factual accuracy
- Evidence needed: Qualitative error analysis by medical professionals checking for inherited hallucinations or logical errors

## Limitations
- The preprocessing pipeline for FHIR resources is underspecified, with the "custom script" for filtering segments not detailed enough for consistent implementation
- Essential training hyperparameters (learning rate, batch size, optimizer configuration) are referenced to external model cards rather than being explicitly stated
- The synthetic data generation relies entirely on GPT-4, creating potential circular dependency in evaluation methodology
- Limited sample size (50 patients for classification, 500 total for generation) may not generalize to broader clinical contexts

## Confidence
- **High Confidence:** Core finding that fine-tuned Llama-3.1-8B and Mistral-NeMo outperform GPT-4 on both classification F1 and generation METEOR metrics
- **Medium Confidence:** Claim that smaller models demonstrate superior efficiency and privacy compliance, though lacks quantitative cost comparison
- **Low Confidence:** Sequential fine-tuning results showing catastrophic forgetting, as experimental setup lacks sufficient detail for assessment

## Next Checks
1. Replicate the preprocessing pipeline independently and compare context retention and noise levels against original study outcomes
2. Systematically test impact of different learning rates, batch sizes, and optimization strategies on classification F1 score to verify robustness
3. Replace LLM-as-a-judge evaluation with human expert assessment for subset of 50 question-answer pairs to quantify evaluation bias extent