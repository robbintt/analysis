---
ver: rpa2
title: Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning
arxiv_id: '2505.15467'
source_url: https://arxiv.org/abs/2505.15467
tags:
- tasks
- learning
- task
- arxiv
- joint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses catastrophic forgetting in large language models
  during incremental learning of new tasks. Joint Flashback Adaptation introduces
  a limited number of prompts from old tasks (flashbacks) during new task adaptation
  and constrains output deviations using divergence loss.
---

# Joint Flashback Adaptation for Forgetting-Resistant Instruction Tuning

## Quick Facts
- arXiv ID: 2505.15467
- Source URL: https://arxiv.org/abs/2505.15467
- Authors: Yukun Zhao; Lingyong Yan; Zhenyang Li; Shuaiqiang Wang; Zhumin Chen; Zhaochun Ren; Dawei Yin
- Reference count: 15
- One-line primary result: Introduces Joint Flashback Adaptation to mitigate catastrophic forgetting in LLMs during incremental learning, achieving best or second-best performance on most tasks compared to six baselines

## Executive Summary
Joint Flashback Adaptation addresses catastrophic forgetting in large language models during incremental learning of new tasks. The method introduces a limited number of prompts from old tasks (flashbacks) during new task adaptation and constrains output deviations using divergence loss. It further interpolates latent tasks between flashbacks and new tasks to enable joint learning, alleviating data sparsity and facilitating knowledge sharing. Experiments on Vicuna-13B and Llama3.1-8B across 1000+ instruction-following, arithmetic reasoning, and general reasoning tasks show that the method improves generalization on new tasks while reducing forgetting in old tasks, achieving the best or second-best performance on most evaluated tasks compared to six state-of-the-art baselines, while requiring only a few flashback prompts without access to replay data.

## Method Summary
The proposed method addresses catastrophic forgetting during incremental learning of new tasks in large language models. The approach introduces "flashback" prompts from old tasks during new task adaptation and uses divergence loss to constrain output deviations. A key innovation is the interpolation of latent tasks between flashbacks and new tasks to enable joint learning, which the authors claim alleviates data sparsity and facilitates knowledge sharing. Experimental results on Vicuna-13B and Llama3.1-8B across 1000+ instruction-following, arithmetic reasoning, and general reasoning tasks show improved generalization on new tasks while reducing forgetting in old tasks. The method achieves best or second-best performance on most evaluated tasks compared to six state-of-the-art baselines, requiring only a few flashback prompts without access to replay data.

## Key Results
- Improves generalization on new tasks while reducing forgetting in old tasks
- Achieves best or second-best performance on most evaluated tasks compared to six baselines
- Requires only a few flashback prompts without access to replay data

## Why This Works (Mechanism)
The method works by introducing controlled exposure to previous task knowledge through flashback prompts, preventing the model from completely overwriting old knowledge during new task learning. The divergence loss acts as a regularizer that maintains similarity between old and new task outputs, preserving previously learned capabilities. The interpolation of latent tasks creates a smooth transition between old and new task distributions, enabling the model to learn a unified representation space that accommodates both task types simultaneously. This joint learning approach addresses the fundamental challenge of catastrophic forgetting by maintaining a balance between plasticity for new tasks and stability for old tasks.

## Foundational Learning
- Catastrophic forgetting: The tendency of neural networks to lose previously learned information when trained on new tasks. Why needed: Forms the core problem being addressed.
- Divergence loss: A regularization technique that measures and constrains differences between model outputs. Why needed: Prevents excessive deviation from old task behaviors during new task learning.
- Task interpolation: Creating synthetic intermediate tasks between old and new tasks. Why needed: Enables smooth knowledge transfer and joint optimization across task distributions.

## Architecture Onboarding
- Component map: Flashback prompts -> Divergence loss computation -> Latent task interpolation -> Joint optimization
- Critical path: The sequence from introducing flashback prompts through divergence loss application to final joint optimization determines model performance
- Design tradeoffs: Fewer flashbacks reduce storage requirements but may provide insufficient old task information; stronger divergence loss better preserves old knowledge but may limit new task learning
- Failure signatures: Overfitting to flashbacks (degraded new task performance), under-constrained divergence (catastrophic forgetting), poor interpolation quality (failed knowledge transfer)
- First experiments: 1) Ablation study removing divergence loss, 2) Test with varying numbers of flashback prompts, 3) Evaluate interpolation quality using task similarity metrics

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on relatively homogeneous task types from a single dataset, which may not reflect performance on more diverse tasks
- Long-term retention beyond the evaluation period is not assessed
- Computational overhead introduced by divergence loss and latent task interpolation is not quantified

## Confidence
- High confidence in core experimental results showing improved performance compared to baselines on evaluated task types
- Medium confidence in generalization claims to other task types and domains beyond the ShareGPT dataset
- Medium confidence in the claim of reduced catastrophic forgetting, as the evaluation period and task diversity are limited

## Next Checks
1. Test the method on tasks from multiple diverse datasets (e.g., MMLU, HumanEval, BigBench) to verify generalization across different task structures and domains
2. Conduct ablation studies isolating the contributions of divergence loss versus latent task interpolation to understand which component drives performance improvements
3. Measure and report computational overhead during both training and inference to assess practical deployment implications compared to baseline methods