---
ver: rpa2
title: 'MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification
  from Images'
arxiv_id: '2512.23304'
source_url: https://arxiv.org/abs/2512.23304
tags:
- medgemma
- gpt-4
- disease
- classification
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study compares the specialized open-source MedGemma model\
  \ with the general-purpose GPT-4 for diagnosing six chronic diseases using image\
  \ data. MedGemma was fine-tuned using LoRA on datasets including skin cancer, Alzheimer\u2019\
  s, breast cancer, cardiovascular disease, pneumonia, and chronic kidney disease,\
  \ while GPT-4 was evaluated using zero-shot prompting."
---

# MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images

## Quick Facts
- arXiv ID: 2512.23304
- Source URL: https://arxiv.org/abs/2512.23304
- Authors: Md. Sazzadul Islam Prottasha; Nabil Walid Rafi
- Reference count: 40
- MedGemma achieved 80.37% mean test accuracy vs GPT-4's 69.58% in zero-shot medical image classification

## Executive Summary
This study compares the specialized open-source MedGemma model with the general-purpose GPT-4 for diagnosing six chronic diseases using image data. MedGemma was fine-tuned using LoRA on datasets including skin cancer, Alzheimer's, breast cancer, cardiovascular disease, pneumonia, and chronic kidney disease, while GPT-4 was evaluated using zero-shot prompting. The results demonstrate MedGemma's superior performance with 80.37% mean accuracy compared to GPT-4's 69.58%, highlighting the importance of domain-specific fine-tuning for medical imaging tasks. The study emphasizes that specialized models outperform general-purpose AI in critical diagnostic applications.

## Method Summary
The study evaluated MedGemma and GPT-4 on six chronic disease classifications from medical images. MedGemma underwent fine-tuning using LoRA adapters on domain-specific datasets for skin cancer, Alzheimer's, breast cancer, cardiovascular disease, pneumonia, and chronic kidney disease. GPT-4 was tested using zero-shot prompting without fine-tuning. Both models were assessed on 120 test samples per disease category. Performance metrics included accuracy, sensitivity, and disease-specific diagnostic capabilities. The comparison focused on MedGemma's domain-specific adaptation versus GPT-4's general-purpose approach to medical image classification.

## Key Results
- MedGemma achieved 80.37% mean test accuracy compared to GPT-4's 69.58%
- Pneumonia detection showed highest accuracy at 81.71% for MedGemma
- Skin cancer classification achieved lowest accuracy at 79.05% for MedGemma
- MedGemma demonstrated higher sensitivity in critical tasks like cancer and pneumonia detection

## Why This Works (Mechanism)
Domain-specific fine-tuning enables models to learn specialized medical imaging patterns and diagnostic features that general-purpose models lack. LoRA adapters allow efficient adaptation of pre-trained models to medical domains without full retraining. The specialized training helps models recognize subtle disease-specific patterns in medical images that general-purpose vision models may miss. Medical image classification requires understanding of anatomical structures, pathological indicators, and disease-specific visual cues that benefit from targeted training.

## Foundational Learning
- **LoRA fine-tuning**: Efficient parameter-efficient adaptation method - quick check: verify adapter dimensions match model architecture
- **Zero-shot prompting**: Direct application without task-specific training - quick check: validate prompt template consistency
- **Medical image classification**: Specialized pattern recognition in diagnostic imaging - quick check: confirm disease-specific feature extraction
- **Sensitivity vs accuracy**: Different metrics for diagnostic performance - quick check: ensure balanced class representation
- **Domain adaptation**: Transferring knowledge to specialized domains - quick check: validate feature alignment between domains
- **Multi-disease evaluation**: Testing across diverse medical conditions - quick check: verify dataset quality and labeling accuracy

## Architecture Onboarding
**Component map**: Image input -> Vision encoder -> LoRA adapters -> Classification head -> Output prediction
**Critical path**: Medical image → Feature extraction → Domain adaptation → Disease classification → Confidence scoring
**Design tradeoffs**: Specialized fine-tuning vs general-purpose capability, computational efficiency vs model size, accuracy vs inference speed
**Failure signatures**: Overfitting on small datasets, domain shift in unseen populations, class imbalance effects, prompt sensitivity in zero-shot
**First experiments**: 1) Baseline performance comparison on held-out validation set, 2) Ablation study removing LoRA adapters, 3) Cross-dataset generalization testing

## Open Questions the Paper Calls Out
None

## Limitations
- Small number of chronic diseases examined (n=6) limits generalizability
- Relatively small datasets with only 120 test samples per disease may lead to overfitting
- Lack of external validation and statistical significance testing

## Confidence
- Claims about MedGemma's superiority in diagnostic accuracy and sensitivity: **Medium confidence**
- Assertion that domain-specific fine-tuning significantly reduces diagnostic errors: **Medium confidence**
- Performance differences between models in critical tasks like cancer detection: **Low confidence**

## Next Checks
1. External validation on larger, independent datasets with minimum 1000 samples per disease category to verify reproducibility and assess real-world performance
2. Statistical significance testing across multiple runs with different random seeds to establish confidence intervals for performance differences between models
3. Multi-center evaluation incorporating diverse patient demographics, imaging equipment, and acquisition protocols to test model robustness across clinical settings