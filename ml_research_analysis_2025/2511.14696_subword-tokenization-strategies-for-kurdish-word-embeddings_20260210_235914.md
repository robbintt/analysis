---
ver: rpa2
title: Subword Tokenization Strategies for Kurdish Word Embeddings
arxiv_id: '2511.14696'
source_url: https://arxiv.org/abs/2511.14696
tags:
- tokenization
- kurdish
- word
- morphological
- similarity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates different tokenization strategies for Kurdish
  word embeddings, comparing word-level, morpheme-based, and BPE approaches. The authors
  develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal
  manual annotation and train Word2Vec embeddings across all three tokenization strategies.
---

# Subword Tokenization Strategies for Kurdish Word Embeddings

## Quick Facts
- arXiv ID: 2511.14696
- Source URL: https://arxiv.org/abs/2511.14696
- Authors: Ali Salehi; Cassandra L. Jacobs
- Reference count: 18
- Key outcome: Coverage-aware evaluation reveals morpheme-based tokenization outperforms BPE for Kurdish embeddings when evaluated comprehensively

## Executive Summary
This paper evaluates word-level, morpheme-based, and BPE tokenization strategies for Kurdish word embeddings, developing a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation. The study reveals critical evaluation bias: BPE appears superior in morphological similarity preservation but evaluates only 28.6% of test cases versus 68.7% for morpheme models. When assessed comprehensively, morpheme-based tokenization demonstrates superior embedding space organization, better semantic neighborhood structure, and more balanced coverage across morphological complexity levels.

## Method Summary
The authors developed a BiLSTM-CRF morphological segmenter trained on 4,000+ annotated Kurdish words via bootstrapping, then compared word-level, morpheme-based, and BPE tokenization strategies using Word2Vec embeddings. The BiLSTM-CRF model used 3-layer BiLSTM with CRF layer for boundary prediction, trained with dropout and Adam optimization. Three tokenization pipelines were created and Word2Vec skip-gram models were trained with adjusted window sizes proportional to tokens/word. Evaluation used UniMorph Kurdish dataset with compositional vectors for OOV handling, tracking coverage percentages alongside similarity metrics.

## Key Results
- BPE achieves higher morphological similarity (0.752) but evaluates only 28.6% of test cases vs 68.7% for morpheme models
- Morpheme-based tokenization shows better embedding space organization with clearer semantic boundaries despite lower raw similarity scores
- BPE and morpheme segmentation capture complementary linguistic structure with only 14.4% boundary agreement

## Why This Works (Mechanism)

### Mechanism 1: Coverage-Selective Evaluation Creates Artificial Performance Inflation
BPE's apparent superiority in morphological similarity stems from evaluating only the subset of cases where compositional vector construction succeeds, not genuine morphological understanding. Compositional vectors work reliably only for straightforward concatenative morphology, selecting favorable patterns while excluding challenging morphological relationships involving stem changes or irregular forms.

### Mechanism 2: Statistical and Linguistic Segmentation Capture Complementary Structure
BPE merges frequent character sequences regardless of morphological boundaries, while morpheme segmentation identifies linguistically meaningful units. With only 14.4% boundary agreement and 63.6% zero-agreement cases, frequency patterns and morphological boundaries represent orthogonal rather than competing signals.

### Mechanism 3: Semantic Organization Quality Trade-off in Embedding Space
Higher morphological similarity scores do not necessarily indicate better embedding quality; BPE's tight clustering comes at the cost of reduced discriminative power. BPE creates concentrated intra-lemma clustering but with flatter similarity dropoff across neighbor ranks, indicating more uniform semantic neighborhoods where distinctions blur.

## Foundational Learning

- **Byte-Pair Encoding (BPE)**: Why needed - baseline statistical tokenization approach being compared against linguistically-informed segmentation. Quick check - Given a vocabulary of frequent character pairs, how would you segment "unhappiness" if "un", "hap", and "ness" are in the merge table but "happy" is not?

- **BiLSTM-CRF for Sequence Labeling**: Why needed - the morphological segmenter uses this architecture to predict boundary positions at character level. Quick check - Why does a CRF layer improve over standalone BiLSTM outputs for boundary detection? What constraint does it enforce?

- **Coverage in NLP Evaluation**: Why needed - the paper's central insight depends on understanding how evaluation coverage affects performance comparability. Quick check - If Model A achieves 90% accuracy on 30% of test data and Model B achieves 70% accuracy on 90% of test data, which metric would you report and why?

## Architecture Onboarding

- **Component map**: Text preprocessing → BiLSTM-CRF morphological segmenter → Three tokenization pipelines → Word2Vec training → Coverage-aware evaluation
- **Critical path**: Corpus preprocessing quality directly affects all downstream tokenization and embedding quality; BiLSTM-CRF segmentation accuracy propagates to morpheme embedding coverage; coverage-aware comparison is essential
- **Design tradeoffs**: BPE vocabulary size balances coverage and frequency but creates coverage gaps; window size adjustment proportional to tokens/word attempts fair comparison but may not fully equalize context exposure; compositional vectors via averaging enable OOV handling but introduce noise for non-concatenative morphology
- **Failure signatures**: Very high similarity scores with low coverage → likely coverage bias; flat similarity dropoff curves → potentially undifferentiated embedding space; large performance gaps between POS categories → training data imbalance
- **First 3 experiments**: 
  1. Reproduce coverage analysis on Turkish/Finnish to validate generalizability
  2. Implement restricted evaluation comparing all three approaches only on their intersection
  3. Train hybrid tokenizer using morpheme boundaries to constrain BPE merges

## Open Questions the Paper Calls Out
- Would hybrid tokenization methods combining morpheme-based and BPE segmentation outperform either approach alone for Kurdish embeddings?
- How do different tokenization strategies affect downstream Kurdish NLP task performance?
- Can improved verb segmentation accuracy be achieved with targeted training data, and would this significantly improve morpheme-based embedding quality?

## Limitations
- Single language and evaluation dataset constrain generalizability
- Bootstrapped training produces uneven segmentation quality across morphological categories (42% F1 for verbs vs 90%+ for nouns/adjectives)
- BPE vocabulary size and minimum frequency threshold are empirically determined without systematic optimization

## Confidence
- High Confidence: Coverage-bias finding and segmentation agreement analysis showing fundamental divergence between approaches
- Medium Confidence: Semantic organization trade-off claims and morpheme-based superiority when fairly evaluated
- Low Confidence: Bootstrapping effectiveness claims and assumption that coverage percentage should always be reported

## Next Checks
1. Replicate the coverage-aware comparison framework on Turkish and Finnish using their respective UniMorph datasets
2. Implement evaluation only on test pairs where all three tokenization strategies can produce compositional vectors
3. Train a tokenization system that uses morpheme boundaries to constrain BPE merges, testing complementarity of statistical and linguistic signals