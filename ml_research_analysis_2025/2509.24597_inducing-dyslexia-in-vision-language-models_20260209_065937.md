---
ver: rpa2
title: Inducing Dyslexia in Vision Language Models
arxiv_id: '2509.24597'
source_url: https://arxiv.org/abs/2509.24597
tags:
- word
- dyslexia
- units
- visual
- reading
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study models dyslexia by ablating vision-language models'
  word-selective units. By functionally identifying and removing units that respond
  preferentially to written words, the model exhibits selective reading impairments
  while preserving general visual reasoning abilities.
---

# Inducing Dyslexia in Vision Language Models

## Quick Facts
- arXiv ID: 2509.24597
- Source URL: https://arxiv.org/abs/2509.24597
- Reference count: 32
- Primary result: Ablating visual-word-form-selective units in VLMs produces selective reading impairments while preserving visual reasoning abilities

## Executive Summary
This study models dyslexia by functionally identifying and ablating word-selective units in vision-language models. Using contrastive activation patterns, the researchers identified units that respond preferentially to written words versus non-word visual stimuli. Targeted ablation of these units induced selective reading impairments below the dyslexia threshold while preserving nonverbal reasoning abilities, mirroring human phonological deficits. The computational framework provides a controlled testbed for studying dyslexia mechanisms and potential interventions.

## Method Summary
The researchers used Qwen2-VL-72B and employed a functional localizer paradigm to identify visual-word-form-selective (VWF-selective) units. They computed t-statistics comparing unit activations to word images versus non-word controls (scrambled words, faces, objects), selecting top-k% as VWF-selective. Progressive ablation of these units was performed until reading accuracy fell below 65% (dyslexia threshold). The resulting model was evaluated on ROAR lexical decision, RAVEN visual reasoning, Kempler sentence comprehension, and phonological vs orthographic processing tasks. Random ablation served as a control condition.

## Key Results
- Ablating top 6.89% of VWF-selective units reduced ROAR accuracy below dyslexia threshold (65%) with p < 0.012
- Reading-specific impairment occurred while RAVEN visual reasoning and Kempler sentence comprehension remained intact
- Post-ablation, phonological processing accuracy dropped by 8% (p ≪ 0.01) while orthographic processing remained stable (p > 0.059)
- Random ablation of equivalent units caused non-selective degradation across all tasks

## Why This Works (Mechanism)

### Mechanism 1: Functional Localization via Contrastive Activation
- Claim: Word-selective units can be identified by comparing activation responses to words versus non-word visual stimuli
- Mechanism: Compute t-statistics for each unit comparing mean activation to word images versus control stimuli (scrambled words, faces, objects). Units with high t-statistics respond preferentially to written words. Select top-k% as VWF-selective units
- Core assumption: Artificial units that activate differentially to words serve analogous functions to biological VWFA neurons
- Evidence anchors: [abstract] "Using stimuli from cognitive neuroscience, we identify visual-word-form-selective units within VLMs"; [Section 4] "For each considered model unit, we compute a t-statistic comparing responses to word images versus the three non-word control categories... Units with higher t-statistics respond more selectively and reliably to words"

### Mechanism 2: Selective Deficit via Targeted Ablation
- Claim: Ablating VWF-selective units produces reading-specific impairment while sparing nonverbal reasoning
- Mechanism: Zero out activations of top-k% VWF-selective units during forward pass. Increase k until ROAR score falls below 65% (dyslexia threshold). Evaluate whether RAVEN (visual reasoning) and Kempler (sentence comprehension) remain intact
- Core assumption: Setting unit activations to zero simulates focal hypoactivation analogous to VWFA underactivity in dyslexia
- Evidence anchors: [abstract] "targeted ablation of these units, unlike ablation of random units, leads to selective impairments in reading tasks while general visual and language comprehension abilities remain intact"; [Section 5, Figure 4] "Ablating VWF-selective units led to a selective reading deficit below the dyslexia threshold (ROAR, p < 0.012), while performance on visual IQ and reasoning benchmarks (RAVEN, Kempler) remained intact"

### Mechanism 3: Phonological Deficit with Preserved Orthography
- Claim: VWF ablation impairs phonological processing more than orthographic processing
- Mechanism: Evaluate lexical decision on phonologically confusable stimuli (pseudo-homophones like "beaf") versus orthographically confusable stimuli (transposed-letter non-words like "golve")
- Core assumption: VWF units support phonological mapping from visual word forms; their ablation disrupts sound-based word recognition
- Evidence anchors: [abstract] "the resulting model matches dyslexic humans' phonological deficits without a significant change in orthographic processing"; [Section 5] "Post-ablation, model accuracy dropped significantly on phonology-sensitive items (−8% with p ≪ 0.01), but remained relatively stable for orthography-sensitive stimuli (p > 0.059)"

## Foundational Learning

- Concept: **Functional localizer paradigm**
  - Why needed here: Core method for identifying specialized units using contrastive stimuli; borrowed from fMRI neuroscience
  - Quick check question: If you showed only faces versus houses, could you identify VWF-selective units?

- Concept: **Double dissociation in neuropsychology**
  - Why needed here: Critical for establishing selectivity—reading impaired, reasoning spared. Controls for general degradation
  - Quick check question: Why is random ablation a necessary control condition?

- Concept: **Phonological vs orthographic processing**
  - Why needed here: Dyslexia theories differ on whether deficits are sound-based or visual-form-based; the paper tests this dissociation
  - Quick check question: Would "glove" → "golve" or "beef" → "beaf" be harder after VWF ablation?

## Architecture Onboarding

- Component map: Vision encoder (visual.blocks.{i}.attn.proj) -> Visual merger (visual.merger.mlp.{i}) -> Language decoder MLP (model.layers.{i}.mlp.gate_proj) -> Language decoder self-attention (model.layers.{i}.self_attn.o_proj)
- Critical path: Vision encoder → Visual merger → Language decoder MLP → Text output. Ablation at MLP layers disrupts reading while preserving upstream visual processing
- Design tradeoffs:
  - Layer choice: MLP layers show reading selectivity; attention layers affect reasoning more broadly (Figure 3c, Figure 9)
  - Mask size: Larger k increases reading impairment but eventually degrades all tasks
  - Perturbation strength: Full ablation (scale=0) produces selective deficits; hyperactivation (scale>1) causes incoherent outputs (Table 2)
- Failure signatures:
  - Random ablation: All tasks degrade equally (Figure 4b)
  - Wrong layer (attention/merger): RAVEN declines faster than ROAR (Figure 9)
  - Hyperactivation: Gibberish outputs with corrupted text (Table 2)
  - Poor baseline model: Cannot assess selectivity if reasoning < chance (LLaVA-NeXT)
- First 3 experiments:
  1. Replicate localization: Run functional localizer (words vs scrambled/faces/objects) on Qwen2-VL-72B; verify top-k% units are in MLP layers
  2. Ablation sweep: Incrementally ablate top 1%, 2%, ... 10% of VWF-selective units; plot ROAR vs RAVEN accuracy to find selective impairment threshold
  3. Control comparison: Ablate same number of random units from identical layers; confirm non-selective degradation pattern

## Open Questions the Paper Calls Out

- **Open Question 1**: Do the functionally localized VWF-selective units in VLMs exhibit physiological alignment with the human Visual Word Form Area?
  - Basis in paper: [explicit] The authors state that constraints prevented them from "directly measuring the neural alignment of the selected units in this work"
  - Why unresolved: While behavioral alignment was established, the study lacks direct comparison data between artificial units and biological neural recordings
  - What evidence would resolve it: Correlating model unit activations with human fMRI data collected using the same localizer stimuli

- **Open Question 2**: Can training models under ablation simulate the developmental trajectory of dyslexia rather than just the end-state impairment?
  - Basis in paper: [explicit] The authors acknowledge their method "captures end-state consequences rather than developmental trajectories" and propose future work on training models under ablation
  - Why unresolved: The current study ablates units in a pre-trained model (analogue to an adult brain), whereas dyslexia emerges during development
  - What evidence would resolve it: Training a vision-language model from scratch with suppressed units to observe if reading deficits emerge spontaneously alongside preserved visual reasoning

- **Open Question 3**: Why does the ablated model fail to exhibit the orthographic processing deficits typically observed in human dyslexics?
  - Basis in paper: [inferred] The results show the model captures phonological deficits but lacks significant orthographic impairment, a divergence from the human profile which includes both
  - Why unresolved: It is unclear if the model's orthographic processing is more robust than human processing or if the ablation fails to disrupt the relevant distributed representations
  - What evidence would resolve it: Targeted ablation experiments focused on orthography-specific units and comparing the resulting error patterns with human clinical data

## Limitations

- The exact stimulus specifications for functional localization (number of images, font properties, rendering parameters) are not provided, creating reproducibility gaps
- The equivalence between artificial and human dyslexia remains interpretive since the 65% threshold is based on human data but models have different architectures
- The phonological deficit findings depend on Luke et al. (2023) data that was not directly replicated in this work, creating a dependency chain

## Confidence

- **High confidence**: The core mechanism of identifying word-selective units via contrastive activation and demonstrating selective ablation effects is well-supported by reported statistical comparisons and controlled experiments
- **Medium confidence**: The interpretation that VWF ablation produces phonological deficits analogous to human dyslexia requires additional validation, though behavioral patterns match
- **Low confidence**: Exact stimulus specifications and evaluation protocols are underspecified, creating potential reproducibility gaps without access to precise localizer stimuli and evaluation prompts

## Next Checks

1. **Stimulus verification check**: Recreate the functional localizer stimulus set using Saygin et al. (2016) categories and run localization on Qwen2-VL-72B; compare top-10% unit rankings with reported results

2. **Ablation threshold verification**: Perform progressive ablation experiment; plot ROAR accuracy versus percentage of units ablated to verify selective impairment threshold (65% ROAR with preserved RAVEN/Kempler) and minimal mask size (~6.89%)

3. **Phonological vs orthographic dissociation replication**: Using Luke et al. (2023) stimuli, evaluate post-ablation model on phonological versus orthographic confusability items; confirm phonological accuracy drops significantly (p ≪ 0.01) while orthographic remains stable (p > 0.059)