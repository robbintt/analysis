---
ver: rpa2
title: Relative Scaling Laws for LLMs
arxiv_id: '2510.24626'
source_url: https://arxiv.org/abs/2510.24626
tags:
- scaling
- relative
- laws
- compute
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Relative scaling laws track how performance gaps between test distributions
  evolve with model scale, separating initial disparities from differences in improvement
  rate. The framework measures relative error as the ratio of treatment to baseline
  loss, fit as a power law in compute, revealing whether gaps narrow, persist, or
  widen.
---

# Relative Scaling Laws for LLMs

## Quick Facts
- arXiv ID: 2510.24626
- Source URL: https://arxiv.org/abs/2510.24626
- Reference count: 27
- Primary result: Relative scaling laws track performance gaps between test distributions, revealing diverse convergence/divergence trajectories across 255 decoder-only Transformers.

## Executive Summary
Relative scaling laws measure how performance gaps between test distributions evolve with model scale by tracking the ratio of treatment to baseline error as a power law in compute. This framework separates initial disparities from differences in improvement rate, revealing whether gaps narrow, persist, or widen as models scale. Across 255 decoder-only Transformers trained under matched compute budgets from 10^18 to 10^20 FLOPs on three distinct datasets, relative scaling laws uncovered diverse trajectories: academic domains on MMLU converge toward parity regardless of training corpus; regional English dialects scale at rates correlated with online speaker population, with some regions diverging; AI risk clusters split, with capability- and influence-related risks increasing relative to self-improvement while adversarial risks do not.

## Method Summary
The authors introduce relative scaling laws by training 255 decoder-only Transformers (85 per dataset) across three pretraining corpora using IsoFLOP compute-optimal budgets (10^18-10^20 FLOPs). Models use Qwen-3-style architecture with compute-optimal token counts determined via sweeps. Hyperparameters scale with hidden size and batch size using modified AdamW (C-AdamC optimizer). The relative scaling law fits log-transformed error ratios between treatment and baseline distributions as a power law in compute, extracting the exponent Δβ that indicates whether gaps narrow (Δβ < 0) or widen (Δβ > 0).

## Key Results
- MMLU academic domains converge toward parity across training corpora regardless of initial gaps
- Regional English dialects scale at rates correlated with online speaker population (Pearson r = 0.82-0.84)
- AI risk clusters diverge: capability risks (self-improvement, influence) increase relative to baseline while adversarial risks (scheming, incorrigibility) do not

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The ratio of errors between two test distributions scales predictably as a power law of compute, separating initial disparities from the rate of gap closure.
- **Mechanism:** Traditional scaling laws model absolute error as E(F) = αF^(-β). By taking the ratio of a "treatment" error to a "baseline" error, the constants (α) capturing initial difficulty cancel out or become intercepts (γ), while the difference in exponents (Δβ) directly measures if the gap is widening (Δβ > 0) or narrowing (Δβ < 0).
- **Core assumption:** The power-law relationship holds for the specific sub-distributions being compared, and variance is low enough to distinguish signals from noise.
- **Evidence anchors:** [abstract] "We introduce relative scaling laws, which track how performance gaps between test distributions evolve with scale..."; [section 2] "If Δβ < 0, the treatment improves faster and the gap narrows... This form parallels the subgroup laws of Rolf et al. (2021)..."
- **Break condition:** If the distributions do not follow power laws (e.g., emergent capabilities with sharp phase transitions) or evaluation prompts cause high variance, the ratio fit becomes unstable.

### Mechanism 2
- **Claim:** The relative scaling exponent (Δβ) correlates with subgroup representation in training data, causing under-represented groups to diverge or stagnate relative to dominant groups as compute increases.
- **Mechanism:** Model capacity grows with compute (F), but learning statistical regularities requires sufficient data frequency. Dominant groups (e.g., USA English) utilize increased capacity efficiently (steep β), while under-represented groups (e.g., Nigeria English) utilize it less effectively (shallow β), resulting in a positive Δβ (widening gap).
- **Core assumption:** Training data composition remains fixed; performance is bottlenecked by token frequency rather than model capacity limits for the dominant group.
- **Evidence anchors:** [section 4.2] "Countries with larger estimated online English-speaking populations ... have neutral or positive relative scaling slopes and those with smaller populations ... have negative relative scaling slopes."; [figure 5c] Shows a Pearson correlation of 0.82–0.84 between speaking population and relative scaling slope.
- **Break condition:** If data mixture ratios are dynamically adjusted during training (e.g., up-sampling rare dialects), this correlation would likely shift or invert.

### Mechanism 3
- **Claim:** Compute scaling amplifies "capability" risks (self-improvement, influence) while leaving "adversarial" risks (scheming) comparatively flat, suggesting scale inherently favors competence over malice.
- **Mechanism:** Pretraining optimizes for next-token prediction on general corpora, which naturally reinforces capabilities related to agency and influence. Adversarial behaviors (scheming, incorrigibility) are not typically reinforced by standard pretraining objectives, leading to a divergence where relative risk (Δβ) drops for adversarial categories compared to capability categories.
- **Core assumption:** The model-written evaluations used (Perez et al., 2023) accurately proxy internal model dispositions rather than just surface form statistics.
- **Evidence anchors:** [section 4.3] "Three clusters—Self-Improvement, Influence, and Self-Replication—scale... Scheming and Incorrigibility... do not emerge with scale."; [figure 7] Visualizes the split where capability risks trend upward while adversarial risks stay flat or decline relative to the baseline.
- **Break condition:** If the training data contains significant amounts of adversarial or scheming-like text (e.g., fiction, strategic games), the "adversarial" risks might scale differently.

## Foundational Learning

- **Concept:** **IsoFLOP (Compute-Optimal) Training**
  - **Why needed here:** The entire framework relies on comparing models trained on equivalent compute budgets (10^18–10^20 FLOPs). You must understand the trade-off between model size (parameters) and data size (tokens) to interpret the results.
  - **Quick check question:** If you double the compute budget, how do you decide whether to increase the parameter count or the token count according to the Hoffmann et al. (2022) approach?

- **Concept:** **Surface Form Competition & Threshold Artifacts**
  - **Why needed here:** The paper highlights that hard metrics (accuracy) can be noisy due to tokenization and prompt formatting. Understanding why "log-probability over full strings" is smoother than "accuracy of letter labels" is crucial for fitting valid laws.
  - **Quick check question:** Why does evaluating on single-token letter labels (e.g., "A") produce noisier scaling curves than evaluating the log-probability of the full answer string (e.g., "A. Nitrogen")?

- **Concept:** **Power Law Fitting**
  - **Why needed here:** The core contribution is fitting a line to log-transformed data to find the exponent β. You need to intuitively grasp that a "steeper" slope in log-log space means faster error reduction.
  - **Quick check question:** In a log-log plot of Error vs. FLOPs, does a line with a more negative slope indicate that the model is improving faster or slower with scale?

## Architecture Onboarding

- **Component map:** Base Model -> IsoFLOP Sweep -> Loss Law Fit -> Ratio Calculation
- **Critical path:** 1. IsoFLOP Sweep: Train models varying size (N) and tokens (D) for fixed budgets (C) to find compute-optimal points. 2. Loss Law Fit: Fit power laws to loss (Bits Per Byte) vs. Compute (C) for specific subgroups. 3. Ratio Calculation: Compute Loss_treatment/Loss_baseline and fit the relative scaling law to find Δβ.
- **Design tradeoffs:** Modified MCQ Prompt balances the high accuracy of standard MCQ prompts with the smooth scaling curves of continuation-form prompts. Loss vs. Accuracy: Fitting laws to loss is more reliable for forecasting; accuracy is derived via a sigmoid calibration function later.
- **Failure signatures:** Unstable Scaling: If Δβ fluctuates wildly, check for loss spikes during training (mitigated here by C-AdamC). Threshold Artifacts: If accuracy curves appear flat then suddenly jump (emergence), switch to soft log-probability metrics. Negative Δβ for Dominant Groups: If the baseline improves slower than a treatment group, verify the baseline selection (e.g., USA English is usually the highest resource baseline).
- **First 3 experiments:** 1. Reproduce the MMLU Convergence: Train 3 small models (e.g., 10^18, 10^18.5, 10^19 FLOPs) on a single dataset and verify that the gap between "STEM" and "Humanities" loss narrows. 2. Prompt Ablation: Evaluate a held-out model (e.g., Llama 3) on MMLU using the three prompt formats (Standard MCQ, Continuation, Modified MCQ) to visualize the variance in R². 3. Optimizer Stability Check: Compare training runs with standard AdamW vs. C-AdamC on a small scaling ladder to observe gradient norm behavior near the end of training.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can targeted data augmentation reverse adverse relative scaling exponents where performance gaps widen with scale?
- **Basis in paper:** [explicit] The conclusion states, "Future work should test whether targeted data augmentation can reverse adverse exponents..."
- **Why unresolved:** The paper identifies cases where gaps persist or widen (e.g., certain regional dialects) but does not experiment with interventions to correct the data imbalance driving the divergence.
- **What evidence would resolve it:** Experiments showing a positive shift in the relative scaling exponent (Δβ) for disadvantaged subgroups after training on curated supplementary data mixtures.

### Open Question 2
- **Question:** How do post-training alignment and fine-tuning stages alter the relative scaling trends established during pretraining?
- **Basis in paper:** [explicit] The conclusion lists studying "how post-training impacts results" as a key area for future work.
- **Why unresolved:** The study isolates pretraining behavior using raw compute-optimal checkpoints, ignoring the standard alignment pipeline (SFT, RLHF) that shapes final model behavior.
- **What evidence would resolve it:** A comparison of Δβ values before and after post-training across the same test distributions to determine if relative disparities are mitigated or exacerbated.

### Open Question 3
- **Question:** Do relative scaling laws generalize to multimodal domains where distribution shift is more severe?
- **Basis in paper:** [explicit] The conclusion suggests extending the framework "to multimodal models where distribution shift is even more severe."
- **Why unresolved:** The current analysis is restricted to text-only decoder-only Transformers; it is unknown if visual or audio modalities exhibit similar convergence or divergence trajectories.
- **What evidence would resolve it:** Applying the IsoFLOP relative scaling methodology to multimodal tasks (e.g., image captioning across geographic regions) to observe if relative exponents follow power laws.

## Limitations

- **Unknown hyperparameters:** The exact values of κ, θ, and η_base for compute-optimal scaling are not specified, requiring experimental tuning to reproduce results faithfully.
- **Data composition uncertainty:** The correlation between speaking population and relative scaling slopes depends on accurate representation estimates and assumes fixed training data composition.
- **Evaluation methodology noise:** While the modified MCQ format addresses prompt formatting issues, the impact on relative scaling measurements isn't fully quantified.

## Confidence

**High Confidence**: The theoretical framework for relative scaling laws (Mechanism 1) is mathematically sound. The power-law ratio approach is well-established in the scaling literature, and the cancellation of initial difficulty constants is straightforward. The MMLU convergence results are also high confidence because they represent an aggregate effect across many diverse domains where representation effects should average out.

**Medium Confidence**: The correlation between speaking population and relative scaling slopes (Mechanism 2) has strong empirical support (Pearson r = 0.82-0.84) but depends on accurate population estimates and assumes training data mirrors online speaker distribution. The AI risk clustering (Mechanism 3) is medium confidence because it relies on model-written evaluations that may not perfectly capture true model dispositions.

**Low Confidence**: The specific hyperparameter values for the IsoFLOP sweep cannot be verified without access to the original training runs. The exact data composition of each corpus, particularly the synthetic portions of Nemotron-CC, remains uncertain.

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary κ, θ, and η_base within plausible ranges (based on Hoffmann et al. ratios) and measure how much the relative scaling exponents Δβ change. If Δβ values are stable across reasonable hyperparameter choices, this validates that the observed patterns aren't artifacts of specific tuning decisions.

2. **Independent Population Validation**: Cross-validate the correlation between speaking population and relative scaling slopes using an independent source of English speaker distribution data (e.g., census data vs. online analytics). Test whether the correlation holds when controlling for factors like GDP, internet penetration, or educational attainment.

3. **Prompt Format Robustness Test**: Train a small set of models (3-5) on CommonPile and evaluate them using all three prompt formats (Standard MCQ, Continuation, Modified MCQ) on the same ICE regional subsets. Quantify how much the relative scaling exponents change across formats to establish the measurement uncertainty introduced by evaluation methodology.