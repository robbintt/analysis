---
ver: rpa2
title: 'Multi-Stage Retrieval for Operational Technology Cybersecurity Compliance
  Using Large Language Models: A Railway Casestudy'
arxiv_id: '2504.14044'
source_url: https://arxiv.org/abs/2504.14044
tags:
- compliance
- retrieval
- context
- otcs
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a multi-stage retrieval system using Large
  Language Models (LLMs) to enhance compliance verification for Operational Technology
  Cybersecurity (OTCS) in railways. The system employs a Parallel Compliance Architecture
  (PCA) that leverages retrieval-augmented generation (RAG) to retrieve both documentation
  and regulatory context, improving the accuracy of compliance assessments against
  standards like IEC 62443 and IEC 63452.
---

# Multi-Stage Retrieval for Operational Technology Cybersecurity Compliance Using Large Language Models: A Railway Casestudy

## Quick Facts
- arXiv ID: 2504.14044
- Source URL: https://arxiv.org/abs/2504.14044
- Reference count: 40
- Primary result: Multi-stage retrieval system achieves 0.75 correctness score in OT cybersecurity compliance verification for railways

## Executive Summary
This paper introduces a multi-stage retrieval system using Large Language Models (LLMs) to enhance compliance verification for Operational Technology Cybersecurity (OTCS) in railways. The system employs a Parallel Compliance Architecture (PCA) that leverages retrieval-augmented generation (RAG) to retrieve both documentation and regulatory context, improving the accuracy of compliance assessments against standards like IEC 62443 and IEC 63452. Through evaluation with GPT-4o and Claude-3.5-haiku models, the PCA achieved 0.75 correctness score and 0.76 reasoning score, outperforming the Baseline Compliance Architecture (BCA) which scored 0.65 and 0.21 respectively.

The study found that document retrieval quality is the critical bottleneck, and established metrics for correctness, reasoning, and hallucination detection, demonstrating that retrieval-augmented approaches can significantly improve compliance verification efficiency and accuracy in the railway sector.

## Method Summary
The research developed a multi-stage retrieval system that combines a Document Retriever and a Context Retriever to gather relevant OT cybersecurity documentation and regulatory standards. The system uses Large Language Models (GPT-4o and Claude-3.5-haiku) to process retrieved documents and generate compliance assessments. The Parallel Compliance Architecture (PCA) processes multiple compliance questions simultaneously, while the Baseline Compliance Architecture (BCA) handles them sequentially. The system was evaluated on a dataset of 10 railway OT cybersecurity compliance cases, measuring correctness, reasoning, and hallucination rates against established standards.

## Key Results
- PCA achieved 0.75 correctness score compared to BCA's 0.65
- PCA demonstrated 0.76 reasoning score versus BCA's 0.21
- Document retrieval accuracy of 0.47 identified as critical bottleneck
- Hallucination detection metric established at 0.69

## Why This Works (Mechanism)
The multi-stage retrieval system works by first gathering comprehensive context from both technical documentation and regulatory standards, then using LLMs to synthesize this information for accurate compliance assessments. The parallel processing approach allows for more efficient handling of multiple compliance questions simultaneously.

## Foundational Learning
- **Retrieval-augmented generation (RAG)**: Combines document retrieval with LLM generation to ground responses in source material
  - Why needed: Prevents LLM hallucination and ensures compliance assessments are based on actual documentation
  - Quick check: Verify retrieved documents contain relevant information for compliance questions

- **Multi-stage retrieval**: Sequential processing of document and context retrieval before LLM analysis
  - Why needed: Ensures comprehensive coverage of both technical and regulatory requirements
  - Quick check: Confirm both document and context retrievers return relevant results

- **Parallel processing architecture**: Simultaneous handling of multiple compliance questions
  - Why needed: Improves efficiency and scalability for enterprise compliance verification
  - Quick check: Measure processing time for batch vs individual compliance questions

- **Compliance metrics**: Standardized evaluation framework for correctness, reasoning, and hallucination
  - Why needed: Enables objective comparison of different compliance verification approaches
  - Quick check: Apply metrics consistently across different test cases

## Architecture Onboarding

**Component Map**: Document Retriever -> Context Retriever -> LLM Processor -> Compliance Assessment

**Critical Path**: 
1. Compliance question input
2. Document retrieval for technical documentation
3. Context retrieval for regulatory standards
4. LLM processing of retrieved materials
5. Compliance assessment generation

**Design Tradeoffs**:
- Parallel vs sequential processing: Parallel offers speed but requires more computational resources
- Document vs context retrieval: Both are essential but context retrieval may be more critical for regulatory compliance
- LLM model selection: GPT-4o offers better performance but at higher cost than Claude-3.5-haiku

**Failure Signatures**:
- Low document retrieval accuracy (below 0.5) indicates poor source material for LLM processing
- High hallucination rates suggest LLM is not properly grounding responses in retrieved documents
- Low reasoning scores indicate inability to connect regulatory requirements to technical documentation

**3 First Experiments**:
1. Compare retrieval accuracy when using different query formulations for the same compliance questions
2. Test the impact of adding additional regulatory documents to the context retrieval stage
3. Evaluate the effect of using different LLM models (e.g., GPT-3.5 vs GPT-4) on compliance assessment quality

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused exclusively on railway systems, limiting generalizability to other OT domains
- Small evaluation dataset of 10 test cases raises concerns about statistical significance
- System performance heavily depends on document retrieval quality rather than LLM capabilities

## Confidence

**High Confidence**: 
- Comparative performance advantage of PCA over BCA (0.75 vs 0.65 correctness score)

**Medium Confidence**:
- Identification of document retrieval as the critical bottleneck
- Established metrics for correctness, reasoning, and hallucination detection

**Low Confidence**:
- Generalization of results to non-railway OT systems
- Long-term stability and performance consistency across different LLM versions

## Next Checks
1. **Cross-Domain Validation**: Test the PCA system on at least three other OT domains (e.g., energy, manufacturing, water treatment) to assess generalizability beyond railway systems.

2. **Retrieval Optimization Study**: Conduct ablation studies varying retrieval algorithms, document preprocessing techniques, and query formulations to identify optimal configurations for the document retrieval stage.

3. **Longitudinal Performance Analysis**: Implement a continuous evaluation framework to track system performance over 6-12 months, monitoring for degradation or improvement patterns as regulatory standards evolve.