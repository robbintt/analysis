---
ver: rpa2
title: 'ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard
  Inverse Problems'
arxiv_id: '2506.10955'
source_url: https://arxiv.org/abs/2506.10955
tags:
- danc
- diffusion
- reward
- inverse
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of solving hard inverse problems,
  like large-scale image inpainting and high-ratio super-resolution, where the signal-to-noise
  ratio is low. While diffusion models have shown promise for such tasks, existing
  training-free methods often fail to generate realistic samples when the reward (e.g.,
  measurement consistency) is not sufficiently informative.
---

# ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems

## Quick Facts
- arXiv ID: 2506.10955
- Source URL: https://arxiv.org/abs/2506.10955
- Reference count: 40
- Primary result: Simple two-step wrapper that significantly improves sample quality and measurement consistency for hard inverse problems using diffusion models

## Executive Summary
This paper addresses the challenge of generating high-quality samples for hard inverse problems (like large-scale inpainting and high-ratio super-resolution) where signal-to-noise ratios are low. While diffusion models excel at these tasks, existing training-free methods often struggle when measurement consistency rewards are insufficiently informative. ReGuidance is proposed as a simple wrapper that substantially boosts both sample quality and reward achieved by existing diffusion-based inverse problem solvers.

The method operates in two steps: first, it runs the unconditional probability flow ODE in reverse from a candidate solution to extract a latent representation; second, it initializes the Diffusion Posterior Sampling (DPS) algorithm from this latent to generate an improved reconstruction. This approach leverages the structure of good initial latents to enhance realism while maintaining high reward. Experiments on ImageNet and CIFAR-10 demonstrate substantial improvements in both measurement consistency (LPIPS) and sample quality (CMMD) across various inverse problems.

## Method Summary
ReGuidance is a two-step wrapper for improving diffusion-based inverse problem solvers. It first extracts a latent representation by running the unconditional probability flow ODE in reverse from a candidate solution. Then, it initializes the Diffusion Posterior Sampling (DPS) algorithm from this latent to generate an improved reconstruction. The method uses a pretrained unconditional diffusion model and applies guidance strength ρ=1/σ² for the inverse problem reward. Implementation uses DDIM sampling with η=0.0 (deterministic) for the ODE steps.

## Key Results
- On large box inpainting (191×191), ReGuidance reduces CMMD of DAPS from 1.103 to 0.628
- Improves LPIPS measurement consistency from 0.470 to 0.376 when applied to DDRM baseline
- First rigorous algorithmic guarantee for DPS, showing contraction toward data modes under specific conditions
- Demonstrates that initializing DPS from structured latents preserves measurement consistency while improving sample quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ReGuidance preserves the "good structure" from a candidate solution by extracting its latent encoding through reverse ODE inversion, then re-synthesizing with DPS guidance
- Mechanism: The reverse unconditional probability flow ODE maps candidate $\hat{x}$ → latent $x^*_T$. This latent captures high-level structural information (class, layout) that made the candidate partially successful. Step 2 then runs DPS forward from this structured initialization
- Core assumption: The candidate contains learnable on-manifold structure worth preserving; ODE inversion is sufficiently accurate despite discretization error
- Evidence anchors:
  - [abstract]: "it runs the unconditional probability flow ODE in reverse from a candidate solution to extract a latent representation"
  - [section 3.4.1]: "the space of good initial latents is disconnected... a small $L_2$ ball of latents around good latents also provide generally strong reconstructed samples"
  - [corpus]: Related work "Align & Invert" explores representation alignment but for different purposes; direct evidence for this specific inverse-problem use case is limited
- Break condition: Candidate is completely off-manifold (no structure to preserve), or discretization error in inversion is too large (artifacts magnified in Figure 10)

### Mechanism 2
- Claim: Initializing DPS from a good latent produces solutions closer to the data manifold while preserving measurement consistency
- Mechanism: The DPS-ODE adds guidance term $\nabla_x r(\mu_{T-t}(x^{DPS}_t))$ pushing toward measurement consistency. When initialized from structured latent (not random noise), the denoising dynamics + guidance jointly produce high-realism, high-reward samples
- Core assumption: DPS's point-mass approximation to the posterior expectation, while biased, produces useful trajectories when properly initialized—even though DPS doesn't sample the true tilted density
- Evidence anchors:
  - [abstract]: "initializes the Diffusion Posterior Sampling (DPS) algorithm from this latent to generate an improved reconstruction"
  - [section 4.2, Theorem 4]: Proves contraction toward modes: $\|x^{MDPS}_T - z_1\| \leq C \|x - z_1\|$ for $0 < C < 1$
  - [corpus]: "Solving Diffusion Inverse Problems with Restart Posterior Sampling" explores related posterior sampling refinements
- Break condition: Theoretical guarantees require specific initialization conditions (Theorem 4 requires $\langle x^{MDPS}_0, v \rangle \leq cR\langle v, e_1 \rangle$)

### Mechanism 3
- Claim: Deterministic ODE sampling preserves initialization benefits; stochastic SDE sampling loses them due to memorylessness
- Mechanism: SDE adds Brownian noise at each step, erasing dependency on initial latent. ODE is deterministic—final output remains coupled to initialization
- Core assumption: The initialization signal is valuable and should be preserved throughout sampling
- Evidence anchors:
  - [section 3.4.2]: "ReGuidance with this DPS-SDE underperforms the baseline in measurement consistency and underperforms the DPS-ODE in realism"
  - [section 4.1, Theorem 6]: Proves SDE variant produces outputs "bounded away from any of the modes with high probability"
  - [corpus]: "On Stability and Robustness of Diffusion Posterior Sampling" discusses sampler stability but not this specific ODE/SDE contrast
- Break condition: Excessive stochasticity destroys initialization signal entirely

## Foundational Learning

- Concept: **Probability Flow ODE vs. Reverse SDE**
  - Why needed here: ReGuidance uses ODE for both latent extraction and re-synthesis. Understanding why ODE preserves initialization while SDE doesn't is critical
  - Quick check question: Why does the SDE's Brownian motion term cause the output distribution to become nearly independent of initialization for large $T$?

- Concept: **DPS approximation and its bias**
  - Why needed here: The paper proves DPS doesn't sample the true posterior (Appendix A). Understanding this bias clarifies why ReGuidance focuses on reward+realism rather than correct posterior sampling
  - Quick check question: What does DPS approximate $\nabla \ln \mathbb{E}_{x_0}[e^{r(x_0)}|x_t=x]$ with, and why is this biased?

- Concept: **Tilted density and intractability**
  - Why needed here: The paper frames inverse problems as sampling from $\tilde{q}(x) \propto q(x) \cdot e^{r(x)}$, notes this is computationally intractable in general
  - Quick check question: Why does ReGuidance circumvent intractability by focusing on producing high-reward, high-realism samples rather than sampling $\tilde{q}$?

## Architecture Onboarding

- Component map: Candidate $\hat{x}$ (from DAPS/DDRM/DPS) -> Reverse ODE $T$ steps -> Latent $x^*_T$ -> DPS-ODE $T$ steps -> Output $\hat{x}_{DPS}$
- Critical path: Candidate $\hat{x}$ (from DAPS/DDRM/DPS) → Reverse ODE $T$ steps → Latent $x^*_T$ → DPS-ODE $T$ steps → Output $\hat{x}_{DPS}$
- Design tradeoffs:
  - **ODE vs SDE**: ODE preserves structure; SDE adds diversity but empirically degrades performance
  - **Guidance strength $\rho$**: Paper uses $\rho = 1/\sigma^2$; higher values prioritize consistency over realism
  - **Baseline choice**: Ground truth latents perform best, but DAPS/DDRM latents can yield better realism than random initialization
- Failure signatures:
  - Discretization error in reverse ODE creates artifacts that magnify during ReGuidance (Figure 10)
  - Poor initial candidate → no useful structure in latent
  - Using SDE instead of ODE (Table 2: LPIPS 0.470 vs 0.376)
  - Latent too far from good neighborhood (Section 3.4.1: radius > 0.1$\sqrt{d}$)
- First 3 experiments:
  1. **Sanity check**: Large box inpainting (191×191) with DAPS baseline; verify CMMD/LPIPS improve after ReGuidance
  2. **ODE vs SDE ablation**: Run both on same task; confirm ODE outperforms
  3. **Latent perturbation analysis**: Extract latent, add noise at varying scales, measure output degradation to characterize good-latent basins

## Open Questions the Paper Calls Out

- **Open Question 1**: Does ReGuidance improve sample quality and reward consistency when applied to general reward models outside of linear inverse problems?
  - Basis in paper: [explicit] The authors state in Section 5 that evaluating efficacy for "other choices of reward" is an "immediate future direction."
  - Why unresolved: The empirical evaluation is restricted to inverse problems (inpainting and super-resolution) where the reward is defined by measurement consistency.
  - What evidence would resolve it: Empirical results on general reward functions, such as aesthetic scoring or text-image alignment, showing performance boosts comparable to those seen in inverse problems.

- **Open Question 2**: Can the theoretical guarantees for ReGuidance be extended beyond simple Gaussian mixture models to richer, more realistic data distributions?
  - Basis in paper: [explicit] Section 5 identifies extending guarantees to "richer families of data distributions" as a necessary future step.
  - Why unresolved: The theoretical analysis relies on tractable toy models (multimodal Gaussian mixtures) rather than the complex, high-dimensional manifolds of real images.
  - What evidence would resolve it: Formal proofs demonstrating that ReGuidance contracts solutions toward data modes for non-Gaussian distributions, or convergence bounds for general data priors.

- **Open Question 3**: How can the deterministic inversion step be refined to prevent discretization artifacts that currently degrade performance in tasks like super-resolution?
  - Basis in paper: [explicit] Appendix D.2.1 notes that discretization error in the reverse ODE introduces artifacts and states, "In future work, we will explore stronger techniques that potentially avoid these artifacts."
  - Why unresolved: Current inversion methods do not perfectly map images back to their latent space, creating noise that ReGuidance subsequently magnifies.
  - What evidence would resolve it: A modified inversion solver that minimizes reconstruction error (identity mapping) and yields consistent metric improvements in high-upscaling tasks.

## Limitations
- Relies heavily on quality of initial candidate solutions; fails if baseline solvers produce incoherent candidates
- Theoretical guarantees limited to specific initialization conditions and simple Gaussian mixture models
- Reverse ODE inversion may accumulate discretization error, potentially degrading latents
- Assumes access to well-trained unconditional diffusion model, which may not be available for all domains

## Confidence

- **High Confidence**: ODE vs SDE ablation showing ODE outperforms (Section 3.4.2, Table 2)
- **Medium Confidence**: Theoretical contraction guarantees (Theorem 4) under specific conditions
- **Medium Confidence**: Latent perturbation experiments showing good-latent neighborhoods (Section 3.4.1)
- **Low Confidence**: General applicability to all inverse problems without domain-specific tuning

## Next Checks

1. **Latent basin characterization**: Systematically vary perturbation magnitude to ground truth latents and measure output degradation; verify the claimed 0.1√d radius for good latents
2. **Baseline sensitivity**: Test ReGuidance with increasingly degraded baseline candidates to determine the minimum quality threshold for improvement
3. **Discretization error analysis**: Compare reverse ODE latents extracted with different numerical tolerances; measure how discretization error affects final output quality