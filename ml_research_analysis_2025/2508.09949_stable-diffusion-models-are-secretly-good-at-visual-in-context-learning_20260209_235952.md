---
ver: rpa2
title: Stable Diffusion Models are Secretly Good at Visual In-Context Learning
arxiv_id: '2508.09949'
source_url: https://arxiv.org/abs/2508.09949
tags:
- prompt
- tasks
- prompts
- image
- segmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates that off-the-shelf Stable Diffusion models
  can be repurposed for visual in-context learning (V-ICL) without any fine-tuning
  or additional training data. The key innovation is an in-place attention re-computation
  within the self-attention layers that explicitly incorporates context between query
  images and example prompts.
---

# Stable Diffusion Models are Secretly Good at Visual In-Context Learning

## Quick Facts
- **arXiv ID**: 2508.09949
- **Source URL**: https://arxiv.org/abs/2508.09949
- **Reference count**: 40
- **Primary result**: Off-the-shelf Stable Diffusion achieves state-of-the-art V-ICL performance across 6 tasks without fine-tuning

## Executive Summary
This work demonstrates that pre-trained Stable Diffusion models can be repurposed for visual in-context learning (V-ICL) without any fine-tuning or additional training data. The key innovation is an in-place attention re-computation within the self-attention layers that explicitly incorporates context between query images and example prompts. This enables the model to infer both task relationships and image context, overcoming limitations of existing V-ICL approaches. The method achieves state-of-the-art performance across six tasks: foreground segmentation (mIoU +8.9% over Visual Prompting), single object detection (mIoU +5.3%), semantic segmentation (mIoU +0.8%), keypoint detection (MSE -6×, PCK +7×), edge detection (MSE -72%), and colorization (FID -49%).

## Method Summary
The method modifies Stable Diffusion's self-attention layers to incorporate cross-image context. During denoising, query (Q) vectors come from the query image, key (K) vectors from the prompt image, and value (V) vectors from the prompt groundtruth. This cross-attention formulation transfers task-relevant features from B to the prediction, conditioned on semantic correspondence between C and A. Domain alignment mechanisms (AdaIN, attention contrasting, swap-guidance) bridge the distribution gap created by mixing Q, K, V from different images. An implicitly-weighted prompt ensembling technique leverages multiple prompts effectively, further improving performance across all tasks.

## Key Results
- Achieves state-of-the-art V-ICL performance on 6 tasks without any fine-tuning
- +8.9% mIoU improvement on foreground segmentation over Visual Prompting
- -72% MSE improvement on edge detection task
- Implicitly-weighted prompt ensembling outperforms feature ensembling across all tasks

## Why This Works (Mechanism)

### Mechanism 1
**Claim:** Cross-image attention formulation enables explicit context transfer between query and prompts.
**Mechanism:** The method replaces standard self-attention with a modified computation: Query (Q) from query image C, Key (K) from prompt image A, Value (V) from prompt groundtruth B. The attention map α_C←A = softmax(Q_C · K_A^T / (τ·√d)) captures how each patch in the query correlates with patches in the prompt image. This transfers task-relevant features from B to the prediction, conditioned on semantic correspondence between C and A.
**Core assumption:** The pre-trained Stable Diffusion model has already learned sufficient semantic representations in its self-attention layers that can be repurposed without additional training.
**Evidence anchors:**
- [Section 2.2]: "Expanding the feature update formulation for D we get, Δϕ(t)_D = softmax(Q(t)_C · K(t)_A^T / τ·√d) · V(t)_B"
- [Section 2.2]: "Each element in the attention map, i.e., αt_D(i,j), captures how the ith patch of the query image correlates with the jth patch of the prompt image."
- [corpus]: Weak direct support; neighbor papers focus on diffusion editing and in-context tuning but not this specific cross-attention formulation.
**Break condition:** If prompt image A lacks semantic overlap with query C, the attention map will have weak/ambiguous correspondences, leading to incorrect feature transfers.

### Mechanism 2
**Claim:** Domain alignment mechanisms (AdaIN, attention contrasting, swap-guidance) bridge the distribution gap created by mixing Q, K, V from different images.
**Mechanism:** Three components work together: (1) Attention contrasting (α_D = μ(α_D) + β·(α_D - μ(α_D))) enhances focus on semantically similar regions while attenuating spurious color-based correlations; (2) Swap-guidance (η(t) = η_default + γ·(T-t)/T·(η_modified - η_default)) gradually blends modified predictions to stay within Stable Diffusion's generative manifold; (3) AdaIN aligns prediction color statistics to prompt groundtruth's color space.
**Core assumption:** These alignment techniques from image editing/style transfer transfer to the V-ICL task without task-specific calibration.
**Evidence anchors:**
- [Section 2.2]: "Attention map contrasting... enhances the focus on the relevant regions... while attenuating the irrelevant (i.e. color similarity between unrelated objects)."
- [Table 9]: AdaIN improves mIoU from 51.55 to 55.49 on foreground segmentation.
- [corpus]: MADI paper uses similar masking-augmented diffusion for visual editing, supporting the general approach of modifying diffusion inference.
**Break condition:** Incorrect hyperparameter settings (β, γ, or AdaIN statistics) cause color bleeding, structural artifacts, or loss of semantic content.

### Mechanism 3
**Claim:** Implicitly-weighted prompt ensembling (IWPE) enables dynamic prompt weighting based on query-prompt correspondence.
**Mechanism:** For n prompts, K and V vectors are concatenated: K_total = ⊕[K_A1, ..., K_An], V_total = ⊕[V_B1, ..., V_Bn]. The softmax attention naturally assigns higher weights to prompts whose patches correlate more strongly with query patches, avoiding uniform weighting that treats all prompts equally.
**Core assumption:** Multiple prompts provide complementary coverage of classes/structures relevant to the query.
**Evidence anchors:**
- [Section 2.3]: "our method by implicitly weighing the influence of different prompts based on their relative correspondence to the query, better captures these nuances"
- [Table 4]: IWPE achieves 27.01 mIoU vs 22.97 for feature ensembling on semantic segmentation.
- [corpus]: Test-Time Visual In-Context Tuning paper addresses similar multi-prompt adaptation but requires test-time optimization.
**Break condition:** When prompts are noisy or contradictory, implicit weighting may amplify incorrect signals rather than suppress them.

## Foundational Learning

- **Concept:** Self-attention in transformers (Q, K, V formulation)
  - **Why needed here:** The entire method operates by recomputing self-attention with cross-image Q, K, V vectors.
  - **Quick check question:** Can you explain how softmax(Q·K^T/√d)·V captures pairwise relationships between patches?

- **Concept:** Latent diffusion models (VAE latent space, iterative denoising)
  - **Why needed here:** SD-VICL operates in Stable Diffusion's latent space, requires image inversion, and modifies the denoising loop.
  - **Quick check question:** Why does denoising start from random/noise latents and proceed iteratively rather than one-shot generation?

- **Concept:** In-context learning paradigm (task inference from examples)
  - **Why needed here:** The goal is to infer both task (from A→B relationship) and context (from C↔A correspondence) without weight updates.
  - **Quick check question:** How does in-context learning differ from fine-tuning, and why does this distinction matter for generalization?

## Architecture Onboarding

- **Component map:** Input images → VAE Encoder → Inversion → Noise latents → Denoising U-Net → Modified self-attention → VAE Decoder → Final prediction

- **Critical path:**
  1. Invert all images to noise space (initialization quality affects final output)
  2. At each denoising step t: extract Q, K, V from respective latents at that timestep
  3. Apply attention modifications: temperature scaling → contrasting → compute Δϕ → swap-guidance → AdaIN
  4. Apply modifications at ALL self-attention resolutions (Table 10 shows 55.49 mIoU with all vs 50.33 with only 64×64)

- **Design tradeoffs:**
  - More prompts (n=5) improve mIoU by ~11.6 points but halve inference speed; can reduce denoising steps to compensate (30 steps with 5 prompts ≈ 70 steps with 1 prompt)
  - Temperature τ varies by task (Fig. 9); paper uses fixed τ=0.4 for generalization, sacrificing task-specific optimization
  - Off-the-shelf SD v1.5 vs. newer checkpoints not explored

- **Failure signatures:**
  - Output defaults to grayscale: AdaIN misconfigured or disabled
  - Structural artifacts/blur: Swap-guidance scale γ too low
  - Wrong class segmented in multi-class: Single prompt insufficient; add prompts via IWPE
  - Color bleeding between regions: Attention temperature too high or contrasting disabled

- **First 3 experiments:**
  1. **Baseline validation:** Run foreground segmentation on Pascal-5i with single prompt, τ=0.4, β=1.67, γ=3.5, T=70 steps. Verify ~43.9 mIoU.
  2. **Ablation-by-removal:** Disable each component (AdaIN, swap-guidance, contrasting) individually. Confirm performance drops per Tables 9-10.
  3. **Multi-prompt scaling:** Add prompts (n=1, 3, 5) with IWPE on semantic segmentation (Cityscapes). Confirm improvement curve and measure inference time tradeoff.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can fast diffusion sampling techniques (e.g., consistency models, InstaFlow) be integrated into the SD-VICL pipeline to significantly reduce inference time without compromising output quality?
- **Basis in paper:** [explicit] Section G states that reducing inference costs is an important avenue for future work, specifically suggesting the integration of faster diffusion techniques to achieve potential 100× speedups.
- **Why unresolved:** The current implementation relies on a standard 70-step denoising process (approx. 38.4 seconds), which the authors identify as the primary limitation for practical usage.
- **What evidence would resolve it:** Demonstration of SD-VICL performing visual in-context learning tasks using a reduced-step or one-step diffusion model while maintaining comparable performance metrics (e.g., mIoU, MSE) on the six benchmark tasks.

### Open Question 2
- **Question:** How can visual in-context learning frameworks be made more robust to noisy or ambiguous prompts, particularly those with inconsistent ground truth labeling?
- **Basis in paper:** [explicit] Section G identifies "sensitivity to noisy prompts" as a shared limitation among V-ICL methods and explicitly calls "further improvements in robustness... an open challenge."
- **Why unresolved:** The analysis in Section D (Table 7) shows that performance on the COCOStuff dataset degrades with 5 prompts due to labeling inconsistencies, suggesting the current ensembling method is vulnerable to noise.
- **What evidence would resolve it:** Modifications to the weighting algorithm that maintain or improve performance on datasets with known label noise or ambiguities (like COCOStuff) compared to the single-prompt baseline.

### Open Question 3
- **Question:** Is it possible to automatically determine the optimal attention temperature ($\tau$) for a specific task or image context, rather than relying on a constant or manually tuned hyperparameter?
- **Basis in paper:** [inferred] Section F (Fig. 9) shows that the optimal temperature parameter varies notably between tasks (e.g., foreground segmentation vs. colorization), yet the authors use a fixed value to preserve generalization, acknowledging this trade-off.
- **Why unresolved:** The paper manually selects $\tau=0.4$ as a general compromise, but does not provide a mechanism for the model to dynamically adjust this sensitivity based on the input prompt's signal-to-noise ratio.
- **What evidence would resolve it:** A dynamic temperature scaling mechanism that yields higher performance across diverse tasks than the current static setting.

## Limitations
- The method requires 70 denoising steps, resulting in approximately 38.4 seconds of inference time per image, which limits practical usage
- Performance is sensitive to prompt quality, with noisy or contradictory prompts potentially degrading results
- The approach relies on Stable Diffusion v1.5 specifically and does not explore whether newer diffusion models would perform better

## Confidence
- **High Confidence**: The cross-attention formulation mechanism and its ability to transfer features from prompt groundtruth to query predictions. The attention computation equations are explicitly specified, and the quantitative improvements (+8.9% mIoU on foreground segmentation, -72% MSE on edges) are well-documented across multiple tasks.
- **Medium Confidence**: The domain alignment components (AdaIN, attention contrasting, swap-guidance) effectively bridge distribution gaps. While ablation studies show these improve performance, the exact contribution of each component and their optimal hyperparameters are not fully explored.
- **Low Confidence**: The implicitly-weighted prompt ensembling (IWPE) consistently improves performance across all tasks without task-specific tuning. The mechanism is sound, but real-world prompt retrieval quality and multi-prompt complementarity could vary significantly.

## Next Checks
1. **Ablation-by-Inversion**: Reproduce the baseline foreground segmentation task with three different DDPM inversion variants from [19] (varying step counts, noise schedules). Measure how inversion quality impacts final mIoU to quantify this sensitivity.
2. **Attention Head Analysis**: Implement the cross-attention modification for individual attention heads within each resolution block. Identify which heads contribute most to performance gains and whether the improvements come from specific attention mechanisms.
3. **Prompt Retrieval Robustness**: Systematically corrupt the prompt retrieval process by adding noisy or irrelevant prompts to the prompt set. Measure how IWPE performance degrades and whether it can effectively suppress poor-quality prompts versus amplifying them.